{"title": [], "abstractContent": [{"text": "WordNet, a widely used sense inventory for Word Sense Disambiguation(WSD), is often too fine-grained for many Natural Language applications because of its narrow sense distinctions.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 0, "end_pos": 7, "type": "DATASET", "confidence": 0.9683827757835388}, {"text": "Word Sense Disambiguation(WSD)", "start_pos": 43, "end_pos": 73, "type": "TASK", "confidence": 0.7633163034915924}]}, {"text": "We present a semi-supervised approach to learn similarity between WordNet synsets using a graph based recursive similarity definition.", "labels": [], "entities": []}, {"text": "We seed our framework with sense similarities of all the word-sense pairs, learnt using supervision on human-labelled sense clusterings.", "labels": [], "entities": []}, {"text": "Finally we discuss our method to derive coarse sense inventories at arbitrary granularities and show that the coarse-grained sense inventory obtained significantly boosts the disambiguation of nouns on standard test sets.", "labels": [], "entities": []}], "introductionContent": [{"text": "With different applications requiring different levels of word sense granularity, producing sense clustered inventories with the requisite level of sense granularity has become important.", "labels": [], "entities": []}, {"text": "The subtleties of sense distinctions captured by WordNet are helpful for language learners and in machine translation of languages as diverse as Chinese and English ().", "labels": [], "entities": [{"text": "WordNet", "start_pos": 49, "end_pos": 56, "type": "DATASET", "confidence": 0.9300106763839722}, {"text": "machine translation", "start_pos": 98, "end_pos": 117, "type": "TASK", "confidence": 0.7051883935928345}]}, {"text": "On the other hand, for tasks like Document Categorization and Information Retrieval), it maybe sufficient to know if a given word belongs to a coarsely defined class of WordNet senses.", "labels": [], "entities": [{"text": "Document Categorization", "start_pos": 34, "end_pos": 57, "type": "TASK", "confidence": 0.8996302485466003}, {"text": "Information Retrieval", "start_pos": 62, "end_pos": 83, "type": "TASK", "confidence": 0.7468658089637756}]}, {"text": "Using the fine grained sense inventory of WordNet maybe detrimental to the performance of these applications.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 42, "end_pos": 49, "type": "DATASET", "confidence": 0.9620818495750427}]}, {"text": "Thus developing a framework which can generate sense inventories with different granularities can improve the performance of many applications.", "labels": [], "entities": []}, {"text": "To generate a coarse sense inventory, many researchers have focused on generating coarse senses for each word by merging the fine-grained senses)).", "labels": [], "entities": []}, {"text": "This approach has two problems.", "labels": [], "entities": []}, {"text": "First, it requires a stopping criterion for each word -for example the number of final classes.", "labels": [], "entities": []}, {"text": "The right number of classes for each word cannot usually be predetermined even if the application is known.", "labels": [], "entities": []}, {"text": "So such systems cannot be used to derive coarse senses for all the words.", "labels": [], "entities": []}, {"text": "Second, inconsistent sense clusters are obtained because coarse senses are independently generated for each word.", "labels": [], "entities": []}, {"text": "This leads to transitive closure errors and suggests that for deriving consistent coarse senses, instead of clustering senses for each word separately we should cluster synsets.", "labels": [], "entities": []}, {"text": "We propose a framework that derives a coarse sense inventory by learning a synset similarity metric.", "labels": [], "entities": []}, {"text": "We focus on coarsening the noun synsets of WordNet and show that the obtained coarse-grained sense inventory greatly improves the noun sense disambiguation.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 43, "end_pos": 50, "type": "DATASET", "confidence": 0.9554819464683533}, {"text": "noun sense disambiguation", "start_pos": 130, "end_pos": 155, "type": "TASK", "confidence": 0.702834963798523}]}, {"text": "Our approach closely resembles () for supervised learning of synset similarity.", "labels": [], "entities": []}, {"text": "But to learn similarity between synset pairs which do not share a word we use a variant of the SimRank framework () and avoid giving them zero similarity.", "labels": [], "entities": []}, {"text": "Thus the similarity learnt is more than a binary decision and is reflective of a more comprehensive semantic similarity between the synsets.", "labels": [], "entities": []}, {"text": "The use of SimRank for learning synset similarity is inspired by the success of graph-centrality algorithms in WSD.", "labels": [], "entities": [{"text": "learning synset similarity", "start_pos": 23, "end_pos": 49, "type": "TASK", "confidence": 0.6561038196086884}]}, {"text": "We do not modify the WordNet ontology, unlike, as it may introduce spurious relations and remove some manually encoded information.", "labels": [], "entities": []}, {"text": "In section 2, we discuss past work in sense clustering.", "labels": [], "entities": [{"text": "sense clustering", "start_pos": 38, "end_pos": 54, "type": "TASK", "confidence": 0.7402383685112}]}, {"text": "In section 3 and 4, we describe our framework of learning synset similarity using SimRank.", "labels": [], "entities": []}, {"text": "In section 5, we discuss our methodology of producing coarse senses using the learnt similarity metric.", "labels": [], "entities": []}, {"text": "Section 6 describes the experimental setup and evaluates the framework described.", "labels": [], "entities": []}, {"text": "Section 7 contains conclusions and discusses the directions for future work.", "labels": [], "entities": []}], "datasetContent": [{"text": "Since our methodology depends upon the availability of labelled judgements of synset relatedness, a dataset with a high Inter-Annotator agreement is required.", "labels": [], "entities": []}, {"text": "We use the manually labelled mappings from the Omega ontology 2 () to the WordNet senses, provided by the OntoNotes project ().", "labels": [], "entities": [{"text": "WordNet senses", "start_pos": 74, "end_pos": 88, "type": "DATASET", "confidence": 0.958507239818573}]}, {"text": "The OntoNotes dataset creation involved a rigorous iterative annotation process producing a coarse sense inventory which guarantees at least 90% InterTagger agreement on the sense-tagging of the sample sentences used in the annotation process.", "labels": [], "entities": [{"text": "OntoNotes dataset creation", "start_pos": 4, "end_pos": 30, "type": "DATASET", "confidence": 0.8245388865470886}]}, {"text": "Thus we expect the quality of the final clustering of senses and the derived labelled judgements to be reasonably high.", "labels": [], "entities": []}, {"text": "We use OntoNotes Release 3.0 3 for extracting WordNet sense clusters.", "labels": [], "entities": [{"text": "extracting WordNet sense clusters", "start_pos": 35, "end_pos": 68, "type": "TASK", "confidence": 0.6474364101886749}]}, {"text": "The dataset consists of senses for selected words in sense files.", "labels": [], "entities": []}, {"text": "The senses in OntoNotes are mapped to WordNet senses, if a good mapping between senses exists.", "labels": [], "entities": []}, {"text": "The steps involved in extraction are as follows: 1.", "labels": [], "entities": [{"text": "extraction", "start_pos": 22, "end_pos": 32, "type": "TASK", "confidence": 0.9604182243347168}]}, {"text": "OntoNotes has mappings to 4 WordNet versions: 1.7, 2.0, 2.1 and 3.0.", "labels": [], "entities": [{"text": "OntoNotes", "start_pos": 0, "end_pos": 9, "type": "DATASET", "confidence": 0.8742015957832336}]}, {"text": "We mapped all the senses 5 to WordNet 3.0. 2. Validating clusters on WN3.0: \u2022 We removed the sense files which did not contain all the senses of the word i.e. the clustering was not complete.", "labels": [], "entities": [{"text": "WordNet 3.0. 2.", "start_pos": 30, "end_pos": 45, "type": "DATASET", "confidence": 0.9317672848701477}, {"text": "WN3.0", "start_pos": 69, "end_pos": 74, "type": "DATASET", "confidence": 0.9629961252212524}]}, {"text": "\u2022 We removed the sense files in which the clusters had a clash i.e. one sense belonged to multiple clusters.", "labels": [], "entities": []}, {"text": "3. We removed instances that were present in both positive and negative examples.", "labels": [], "entities": []}, {"text": "This situation arises because the annotators were working with word senses and there were inconsistent sense clusters.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Statistics of Pairwise Classification Dataset ob- tained from OntoNotes", "labels": [], "entities": [{"text": "OntoNotes", "start_pos": 72, "end_pos": 81, "type": "DATASET", "confidence": 0.8677927255630493}]}, {"text": " Table 2: Information Gain and Gain Ratio Based Evalua- tion", "labels": [], "entities": []}, {"text": " Table 3: Feature Ablation Study", "labels": [], "entities": [{"text": "Ablation", "start_pos": 18, "end_pos": 26, "type": "METRIC", "confidence": 0.8841552138328552}]}, {"text": " Table 4: Improvement in Senseval-3 WSD performance using Connected Component Clustering Vs Random Cluster- ing at the same granularity", "labels": [], "entities": [{"text": "WSD", "start_pos": 36, "end_pos": 39, "type": "TASK", "confidence": 0.7555454969406128}]}]}