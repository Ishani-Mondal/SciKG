{"title": [{"text": "Multi-Task Learning for Improved Discriminative Training in SMT", "labels": [], "entities": [{"text": "SMT", "start_pos": 60, "end_pos": 63, "type": "TASK", "confidence": 0.9361535310745239}]}], "abstractContent": [{"text": "Multi-task learning has been shown to be effective in various applications, including discriminative SMT.", "labels": [], "entities": [{"text": "Multi-task learning", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.7772351205348969}, {"text": "SMT", "start_pos": 101, "end_pos": 104, "type": "TASK", "confidence": 0.7209731936454773}]}, {"text": "We present an experimental evaluation of the question whether multi-task learning depends on a \"natu-ral\" division of data into tasks that balance shared and individual knowledge, or whether its inherent regularization makes multi-task learning a broadly applicable remedy against overfitting.", "labels": [], "entities": []}, {"text": "To investigate this question, we compare \"natural\" tasks defined as sections of the International Patent Classification versus \"ran-dom\" tasks defined as random shards in the context of patent SMT.", "labels": [], "entities": [{"text": "International Patent Classification", "start_pos": 84, "end_pos": 119, "type": "DATASET", "confidence": 0.9446361263593038}, {"text": "patent SMT", "start_pos": 186, "end_pos": 196, "type": "TASK", "confidence": 0.5059243887662888}]}, {"text": "We find that both versions of multi-task learning improve equally well over independent and pooled baselines, and gain nearly 2 BLEU points over standard MERT tuning.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 128, "end_pos": 132, "type": "METRIC", "confidence": 0.9995877146720886}]}], "introductionContent": [{"text": "Multi-task learning is motivated by situations where a number of statistical models need to be estimated from data belonging to different tasks.", "labels": [], "entities": [{"text": "Multi-task learning", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.8497363924980164}]}, {"text": "It is assumed that the data are not completely independent of one another as they share some commonalities, yet they differ enough to counter a simple pooling of data.", "labels": [], "entities": []}, {"text": "The goal of multi-task learning is to take advantage of commonalities among tasks by learning a shared model without neglecting individual knowledge.", "labels": [], "entities": []}, {"text": "For example, present an optical character recognition scenario where data consist of samples of handwritten characters from several writers.", "labels": [], "entities": [{"text": "character recognition", "start_pos": 32, "end_pos": 53, "type": "TASK", "confidence": 0.7572048604488373}]}, {"text": "While the styles of different writers vary, it is expected that there are also commonalities on a pixel-or strokelevel that are shared across writers.", "labels": [], "entities": []}, {"text": "present a scenario where data from search engine query logs are available for different countries.", "labels": [], "entities": []}, {"text": "While the rankings for some queries will have to be country-specific (they cite \"football\" as a query requiring different rankings in the US and the UK), a large fraction of queries will be country-insensitive.", "labels": [], "entities": []}, {"text": "present multi-task learning for statistical machine translation (SMT) of patents from different classes (so-called sections) according to the International Patent Classification (IPC) . While the vocabulary may differ between the different IPC sections, specific legal jargon and atypical textual structure will be shared across IPC sections.", "labels": [], "entities": [{"text": "statistical machine translation (SMT) of patents", "start_pos": 32, "end_pos": 80, "type": "TASK", "confidence": 0.8213375210762024}, {"text": "International Patent Classification (IPC)", "start_pos": 142, "end_pos": 183, "type": "DATASET", "confidence": 0.9101941684881846}]}, {"text": "As shown in the cited works, treating data from different writers, countries, or IPC classes as data from different tasks, and applying generic multi-task learning to the specific scenario, improves learning results over learning independent or pooled models.", "labels": [], "entities": []}, {"text": "The research question we ask in this paper is as follows: Is multi-task learning dependent on a \"natural\" task structure in the data, where shared and individual knowledge is properly balanced?", "labels": [], "entities": []}, {"text": "Or can multi-task learning be seen as a general regularization technique that prevents overfitting irrespective of the task structure in the data?", "labels": [], "entities": []}, {"text": "We investigate this research question on the example of discriminative training for patent translation, using the algorithm for multi-task learning with 1 // 2 regularization presented by.", "labels": [], "entities": [{"text": "patent translation", "start_pos": 84, "end_pos": 102, "type": "TASK", "confidence": 0.7348785251379013}]}, {"text": "We compare multi-task learning on \"natural\" tasks given by IPC sections to multitask learning on \"random\" tasks given by random shards and to baseline models trained on independent tasks and pooled tasks.", "labels": [], "entities": [{"text": "IPC sections", "start_pos": 59, "end_pos": 71, "type": "DATASET", "confidence": 0.9287731945514679}]}, {"text": "We find that both versions of multi-task learning improve over independent or pooled training.", "labels": [], "entities": []}, {"text": "However, differences between multi-task learning on IPC tasks and random tasks are small.", "labels": [], "entities": []}, {"text": "This points to a more general regularization effect of multi-task learning and indicates abroad applicability of multi-task learning techniques.", "labels": [], "entities": []}, {"text": "Another advantage of the 1 // 2 reg-ularization technique of is a considerable efficiency gain due to parallelization and iterative feature selection that makes the algorithm suitable for big data applications and for large-scale training with millions of sparse features.", "labels": [], "entities": []}, {"text": "Last but not least, our best result for multitask learning improves by nearly 2 BLEU points over the standard MERT baseline.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 80, "end_pos": 84, "type": "METRIC", "confidence": 0.9995738863945007}, {"text": "MERT baseline", "start_pos": 110, "end_pos": 123, "type": "DATASET", "confidence": 0.6942180395126343}]}], "datasetContent": [{"text": "In single-task tuning mode, systems are tuned on the eight independent data sets separately, the pooled data set, and the independent data sets con-: BLEU4 results for standard perceptron with 1 regularization baseline using sparse rule features, tuned on independent, pooled and pooled-cat sets.", "labels": [], "entities": [{"text": "BLEU4", "start_pos": 150, "end_pos": 155, "type": "METRIC", "confidence": 0.9982444047927856}]}, {"text": "Prefixed superscripts denote a significant improvement over the result in the same row indicated by the superscript.", "labels": [], "entities": [{"text": "Prefixed", "start_pos": 0, "end_pos": 8, "type": "METRIC", "confidence": 0.9673320651054382}]}, {"text": "Testing is done on each of the eight IPC sections separately, and on a pooled test set of 2,000 sentences where all sections are equally represented.", "labels": [], "entities": []}, {"text": "Furthermore, we report average test results over runs for all independent data sets.", "labels": [], "entities": []}, {"text": "Results for the MERT baseline are shown in: Neither pooling nor concatenating independent sets leads to significant performance improvements on all sets with averaged scores being nearly identical.", "labels": [], "entities": [{"text": "MERT baseline", "start_pos": 16, "end_pos": 29, "type": "DATASET", "confidence": 0.7780031859874725}]}, {"text": "Evaluation results obtained with the standard perceptron algorithm show improvements over MERT in single-task tuning mode.", "labels": [], "entities": [{"text": "MERT", "start_pos": 90, "end_pos": 94, "type": "METRIC", "confidence": 0.7190572023391724}]}, {"text": "The gain on pooled-cat data shows that in contrast to MERT training on 12 dense features, discriminative training using large feature sets is able to benefit from large data sets.", "labels": [], "entities": []}, {"text": "However, since the pooled-cat scenario increases computation time by a factor of 8, it is quite infeasible when used with large sets of sparse features.", "labels": [], "entities": []}, {"text": "Single-task tuning on a small set of pooled data seems to show overfitting behavior.", "labels": [], "entities": []}, {"text": "shows evaluation results fora regularization baseline that applies 1 regularization with clipping to the the single-task tuned standard perceptron in.", "labels": [], "entities": []}, {"text": "We see gains in BLEU on independent and pooled-cat tuning data, but not on the small pooled data set.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 16, "end_pos": 20, "type": "METRIC", "confidence": 0.9988604784011841}]}, {"text": "Multi-task tuning for the standard perceptron is shown in the right half of: BLEU4 results for margin-perceptron algorithm using sparse rule features, tuned in single-task mode on independent tasks, and in multi-task mode on eight tasks taken from IPC sections or by random (re)sharding.", "labels": [], "entities": [{"text": "BLEU4", "start_pos": 77, "end_pos": 82, "type": "METRIC", "confidence": 0.9922158122062683}]}, {"text": "Prefixed superscripts denote a significant improvement over the result in the same row indicated by the superscript.", "labels": [], "entities": [{"text": "Prefixed", "start_pos": 0, "end_pos": 8, "type": "METRIC", "confidence": 0.9673320651054382}]}, {"text": "single-task tuning on small data.", "labels": [], "entities": [{"text": "single-task tuning", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.6794171333312988}]}, {"text": "We see improvements in BLEU over single-task tuning on small and large tuning data sets.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 23, "end_pos": 27, "type": "METRIC", "confidence": 0.9985016584396362}]}, {"text": "Concerning our initial research questions, we see that the performance difference between \"natural\" tasks (IPC) and \"random\" tasks is not conclusive.", "labels": [], "entities": []}, {"text": "However, multitask learning using 1 // 2 regularization consistently outperforms the standard perceptron under 1 regularization as shown in and MERT tuning as shown in. shows the evaluation results of the margin-perceptron algorithm.", "labels": [], "entities": [{"text": "MERT tuning", "start_pos": 144, "end_pos": 155, "type": "METRIC", "confidence": 0.954656571149826}]}, {"text": "Evaluation results on single-task tuning show that this algorithm improves over the standard perceptron, even in its 1 -regularized version, on all tuning sets.", "labels": [], "entities": []}, {"text": "Results for multi-task tuning show improvements over the same scenario for the standard perceptron).", "labels": [], "entities": [{"text": "multi-task tuning", "start_pos": 12, "end_pos": 29, "type": "TASK", "confidence": 0.7566802799701691}]}, {"text": "This means that the improvements due to the orthogonal regularization techniques in example space and feature space, namely large-margin learning and multitask learning, add up.", "labels": [], "entities": []}, {"text": "A comparison between single-task and multi-task tuning modes of the margin-perceptron shows again for the latter scenarios.", "labels": [], "entities": []}, {"text": "Differences between multi-task learning on IPC classes versus random sharding or resharding are again small, with the best overall result obtained by multi-task learning of the marginperceptron on IPC classes.", "labels": [], "entities": []}, {"text": "Overall, our best multi-task learing result is nearly 2 BLEU points better than MERT training.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 56, "end_pos": 60, "type": "METRIC", "confidence": 0.9996631145477295}, {"text": "MERT", "start_pos": 80, "end_pos": 84, "type": "METRIC", "confidence": 0.7413011193275452}]}, {"text": "The algorithm to achieve this result is efficient due to parallelization and due to iterative feature selection.", "labels": [], "entities": []}, {"text": "As shown in the last rows of , the average size is around 400K features for independently tuned models and around 1.6M features for models tuned on pooled-cat data.", "labels": [], "entities": []}, {"text": "In multi-task learning, models can be iteratively cut to 100K shared features whose weights are tuned in parallel.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: BLEU4 results of MERT baseline using dense  features for three different tuning sets: independent (sepa- rate tuning sets for each IPC class), pooled and pooled-cat  (concatenated independent sets). Significant superior per- formance over other systems in the same row is denoted by  prefixed numbers. The first row shows, e.g., that the result  of pooled 1 is significantly better than independent 0 , and  pooled-cat 2 .", "labels": [], "entities": [{"text": "BLEU4", "start_pos": 10, "end_pos": 15, "type": "METRIC", "confidence": 0.9862587451934814}, {"text": "MERT baseline", "start_pos": 27, "end_pos": 40, "type": "DATASET", "confidence": 0.7207180112600327}]}, {"text": " Table 3: BLEU4 results for standard perceptron with 1 reg- ularization baseline using sparse rule features, tuned on in- dependent, pooled and pooled-cat sets. Prefixed superscripts  denote a significant improvement over the result in the same  row indicated by the superscript.", "labels": [], "entities": [{"text": "BLEU4", "start_pos": 10, "end_pos": 15, "type": "METRIC", "confidence": 0.989984393119812}]}, {"text": " Table 4: BLEU4 results for standard perceptron algorithm using sparse rule features, tuned in single-task mode on independent,  pooled, and pooled-cat sets, and in multi-task mode on eight tasks taken from IPC sections or by random (re)sharding. Prefixed  superscripts denote a significant improvement over the result in the same row indicated by the superscript.", "labels": [], "entities": [{"text": "BLEU4", "start_pos": 10, "end_pos": 15, "type": "METRIC", "confidence": 0.992665708065033}, {"text": "Prefixed", "start_pos": 247, "end_pos": 255, "type": "METRIC", "confidence": 0.9666456580162048}]}, {"text": " Table 5: BLEU4 results for margin-perceptron algorithm using sparse rule features, tuned in single-task mode on independent  tasks, and in multi-task mode on eight tasks taken from IPC sections or by random (re)sharding. Prefixed superscripts denote  a significant improvement over the result in the same row indicated by the superscript.", "labels": [], "entities": [{"text": "BLEU4", "start_pos": 10, "end_pos": 15, "type": "METRIC", "confidence": 0.992407500743866}]}]}