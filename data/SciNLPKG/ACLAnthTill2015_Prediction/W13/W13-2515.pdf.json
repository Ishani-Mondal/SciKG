{"title": [{"text": "Gathering and Generating Paraphrases from Twitter with Application to Normalization", "labels": [], "entities": [{"text": "Normalization", "start_pos": 70, "end_pos": 83, "type": "TASK", "confidence": 0.6228364706039429}]}], "abstractContent": [{"text": "We present anew and unique paraphrase resource, which contains meaning-preserving transformations between informal user-generated text.", "labels": [], "entities": []}, {"text": "Sentential paraphrases are extracted from a comparable corpus of temporally and topically related messages on Twitter which often express semantically identical information through distinct surface forms.", "labels": [], "entities": []}, {"text": "We demonstrate the utility of this new resource on the task of paraphrasing and normalizing noisy text, showing improvement over several state-of-the-art paraphrase and normalization systems 1 .", "labels": [], "entities": [{"text": "paraphrasing and normalizing noisy text", "start_pos": 63, "end_pos": 102, "type": "TASK", "confidence": 0.7898435115814209}]}], "introductionContent": [{"text": "Social media services provide a massive amount of valuable information and demand NLP tools specifically developed to accommodate their noisy style.", "labels": [], "entities": []}, {"text": "So far not much success has been reported on a key NLP technology on social media data: paraphrasing.", "labels": [], "entities": []}, {"text": "Paraphrases are alternative ways to express the same meaning in the same language and commonly employed to improve the performance of many other NLP applications.", "labels": [], "entities": []}, {"text": "In the case of Twitter, Petrovi\u00b4c showed improvements on first story detection by using paraphrases extracted from WordNet.", "labels": [], "entities": [{"text": "first story detection", "start_pos": 57, "end_pos": 78, "type": "TASK", "confidence": 0.8377960721651713}, {"text": "WordNet", "start_pos": 115, "end_pos": 122, "type": "DATASET", "confidence": 0.9468955993652344}]}, {"text": "Learning paraphrases from tweets could be especially beneficial.", "labels": [], "entities": []}, {"text": "First, the high level of information redundancy in Twitter provides a good opportunity to collect many different expressions.", "labels": [], "entities": [{"text": "information redundancy", "start_pos": 25, "end_pos": 47, "type": "TASK", "confidence": 0.740472674369812}]}, {"text": "Second, tweets contain many kinds of paraphrases not available elsewhere including typos, abbreviations, ungrammatical expressions and slang, which can be particularly valuable for many applications, such as phrase-based text normalization () and correction of writing mistakes (, given the difficulty of acquiring annotated data.", "labels": [], "entities": [{"text": "phrase-based text normalization", "start_pos": 208, "end_pos": 239, "type": "TASK", "confidence": 0.6347289582093557}, {"text": "correction of writing mistakes", "start_pos": 247, "end_pos": 277, "type": "TASK", "confidence": 0.8637479543685913}]}, {"text": "Paraphrase models that are derived from microblog data could be useful to improve other NLP tasks on noisy user-generated text and help users to interpret a large range of up-to-date abbreviations (e.g. dlt \u2192 Doritos Locos Taco) and native expressions (e.g. oh my god \u2192 {oh my goodness | oh my gosh | oh my gawd | oh my jesus}) etc.", "labels": [], "entities": []}, {"text": "This paper presents the first investigation into automatically collecting a large paraphrase corpus of tweets, which can be used for building paraphrase systems adapted to Twitter using techniques from statistical machine translation (SMT).", "labels": [], "entities": [{"text": "statistical machine translation (SMT)", "start_pos": 202, "end_pos": 239, "type": "TASK", "confidence": 0.7808782060941061}]}, {"text": "We show experimental results demonstrating the benefits of an in-domain parallel corpus when paraphrasing tweets.", "labels": [], "entities": []}, {"text": "In addition, our paraphrase models can be applied to the task of normalizing noisy text where we show improvements over the state-of-the-art.", "labels": [], "entities": [{"text": "normalizing noisy text", "start_pos": 65, "end_pos": 87, "type": "TASK", "confidence": 0.8774450421333313}]}, {"text": "Relevant previous work has extracted sentencelevel paraphrases from news corpora).", "labels": [], "entities": []}, {"text": "Paraphrases gathered from noisy usergenerated text on Twitter have unique characteristics which make this comparable corpus a valuable new resource for mining sentence-level paraphrases.", "labels": [], "entities": []}, {"text": "Twitter also has much less context than news articles and much more diverse content, thus posing new challenges to control the noise in mining paraphrases while retaining the desired superficial dissimilarity.", "labels": [], "entities": []}], "datasetContent": [{"text": "We evaluate our system and several baselines at the task of paraphrasing Tweets using previously developed automatic evaluation metrics which have been shown to have high correlation with human judgments ().", "labels": [], "entities": []}, {"text": "In addition, because no previous work has evaluated these metrics in the context of noisy Twitter data, we perform a human evaluation in which annotators are asked to choose which system generates the best paraphrase.", "labels": [], "entities": []}, {"text": "Finally we evaluate our phrase-based normalization system against a state-of-the-art word-based normalizer developed for Twitter.", "labels": [], "entities": [{"text": "phrase-based normalization", "start_pos": 24, "end_pos": 50, "type": "TASK", "confidence": 0.6452534198760986}]}, {"text": "We adopt the normalization dataset of, which was initially annotated for the token-level normalization task, and which we augmented with sentence-level annotations.", "labels": [], "entities": [{"text": "token-level normalization task", "start_pos": 77, "end_pos": 107, "type": "TASK", "confidence": 0.7214617927869161}]}, {"text": "It contains 549 English messages sampled from Twitter API from August to October, 2010.", "labels": [], "entities": []}, {"text": "In addition to automatic evaluation, we also performed a human evaluation in which annotators were asked to pick which system generated the best paraphrase.", "labels": [], "entities": []}, {"text": "We used the same dataset of 200 tweets gathered for the automatic evaluation and generated paraphrases using the 3 systems in with the highest BLEU which achieve a PINC of at least 40.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 143, "end_pos": 147, "type": "METRIC", "confidence": 0.9993064403533936}, {"text": "PINC", "start_pos": 164, "end_pos": 168, "type": "METRIC", "confidence": 0.9979666471481323}]}, {"text": "The annotators were asked to abstain from picking one as the best in cases where there were no changes to the input, or where the resulting paraphrases totally lost the meaning.", "labels": [], "entities": []}, {"text": "displays the number of times each annotator picked each system's output as the best.", "labels": [], "entities": []}, {"text": "Annotator 2 was somewhat more conservative than annotator 1, choosing to abstain more frequently and leading to lower overall frequencies, however in both cases we see a clear advantage from paraphrasing using in-domain models.", "labels": [], "entities": []}, {"text": "As a measure of inter-rater agreement, we computed Cohen's Kappa between the annotators judgment as to whether the Twitter-trained system's output best.", "labels": [], "entities": [{"text": "Cohen's Kappa", "start_pos": 51, "end_pos": 64, "type": "METRIC", "confidence": 0.73912247021993}]}, {"text": "The value of Cohen's Kappa in this case was 0.525.", "labels": [], "entities": []}], "tableCaptions": []}