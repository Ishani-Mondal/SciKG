{"title": [{"text": "Experimental Evaluation of Speech Recognition Technologies for Voice-based Home Automation Control in a Smart Home", "labels": [], "entities": [{"text": "Speech Recognition", "start_pos": 27, "end_pos": 45, "type": "TASK", "confidence": 0.7113467305898666}]}], "abstractContent": [{"text": "This paper presents an audio-based interaction technology that lets the user have full control over her home environment and at detecting distress situations for the elderly and frail population.", "labels": [], "entities": []}, {"text": "We introduce the PATSH framework which performs real-time recognition of voice commands anywhere in the home and detail its architecture and the state-of-the-art processing technologies it employs.", "labels": [], "entities": [{"text": "real-time recognition of voice commands", "start_pos": 48, "end_pos": 87, "type": "TASK", "confidence": 0.7916230082511901}]}, {"text": "This system was evaluated in a realistic Smart Home with three user groups: seniors, visually impaired people and people with no special needs.", "labels": [], "entities": []}, {"text": "Results showed the validity of the PATSH approach and shed light on its usability for people with special needs.", "labels": [], "entities": []}], "introductionContent": [{"text": "Due to the demographic change and ageing in developed countries, the number of older persons is steadily increasing.", "labels": [], "entities": []}, {"text": "In this situation, the society must find solutions to allow these people to live in their home as comfortably and safely as possible by assisting them in their daily life.", "labels": [], "entities": []}, {"text": "This concept, known as Ambient Assisted Living (AAL) aims at anticipating and responding to the special needs of these persons.", "labels": [], "entities": [{"text": "Ambient Assisted Living (AAL)", "start_pos": 23, "end_pos": 52, "type": "TASK", "confidence": 0.6453398168087006}]}, {"text": "In this domain, the development of Smart homes and intelligent companions is seen as a promising way of achieving in-home daily assistance.", "labels": [], "entities": []}, {"text": "However, given the diverse profiles of the senior population (e.g., low/high technical skill, disabilities, etc.), complex interfaces should be avoided.", "labels": [], "entities": []}, {"text": "Nowadays, one of the best interfaces seems to be the speech interface, that makes possible interaction using natural language so that the user does not have to learn complex computing procedures or jargon.", "labels": [], "entities": []}, {"text": "Moreover, it is well adapted to people with reduced mobility and to some emergency situations because the user doesn't need to be close to a switch (\"hands free\" system).", "labels": [], "entities": []}, {"text": "Despite all this, very few Smart Home projects have seriously considered speech recognition in their design.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 73, "end_pos": 91, "type": "TASK", "confidence": 0.7164755761623383}]}, {"text": "Part of this can be attributed to the complexity of setting up this technology in areal environment and to important challenges that still need to be overcome.", "labels": [], "entities": []}, {"text": "In order to make in home voice control a success and a benefit for people with special needs, we argue that a complete framework for audio analysis in Smart Home must be designed.", "labels": [], "entities": []}, {"text": "This framework should be able to provide real-time response, to analyse concurrently several audio channels, to detect audio events, to filter out noise and to perform robust distant speech recognition.", "labels": [], "entities": [{"text": "distant speech recognition", "start_pos": 175, "end_pos": 201, "type": "TASK", "confidence": 0.6073131064573923}]}, {"text": "Furthermore, in contrast with current triggered-bybutton ASR systems commonly found in smartphone, this voice control should be able to work in an \"hand free\" manner in case the person is notable to move.", "labels": [], "entities": []}, {"text": "Another important aspect is the respect for privacy: the system should not disseminate any raw personal data outside the home without the user's consent.", "labels": [], "entities": []}, {"text": "Our approach, called PATSH is a step toward these goals.", "labels": [], "entities": [{"text": "PATSH", "start_pos": 21, "end_pos": 26, "type": "DATASET", "confidence": 0.42677974700927734}]}, {"text": "The originality of the approach is to consider these problems together while they have mostly been studied separately.", "labels": [], "entities": []}, {"text": "To the best of our knowledge, the main trends in audio technology in Smart Homes are related to augmented human machine interaction (e.g., voice command, conversation) and security (mainly fall detection and distress situation recognition).", "labels": [], "entities": [{"text": "fall detection and distress situation recognition", "start_pos": 189, "end_pos": 238, "type": "TASK", "confidence": 0.7047822028398514}]}, {"text": "Regarding security, the main application is the fall detection using the signal of a wearable microphone which is often fused with other modalities (e.g., accelerometer).", "labels": [], "entities": [{"text": "fall detection", "start_pos": 48, "end_pos": 62, "type": "TASK", "confidence": 0.7237487137317657}]}, {"text": "However, the person is constrained to wear these sensors at all times.", "labels": [], "entities": []}, {"text": "To address this constraint, the dialogue system developed by was proposed to replace traditional emergency systems that requires too much change in the lifestyle of the elders.", "labels": [], "entities": []}, {"text": "However, the prototype had a limited vocabulary (yes/no dialogue), was not tested with aged users and there is no mention about how the noise was taken into account.", "labels": [], "entities": []}, {"text": "Most of the speech related research or industrial projects in AAL are actual highly focused on dialogue to build communicative agent (e.g., seethe EU funded Companions or CompanionAble projects or the Semvox system 1 ).", "labels": [], "entities": [{"text": "AAL", "start_pos": 62, "end_pos": 65, "type": "TASK", "confidence": 0.7936768531799316}]}, {"text": "These systems are often composed of ASR, NLU, Dialogue management and TTS parts supplying the user the ability to communicate with the system in an interactive fashion.", "labels": [], "entities": []}, {"text": "However, it is generally the dialogue module (management, modelling, architecture, personalization, etc.) that is the main focus of these projects (e.g., see Companions, OwlSpeak or Jaspis).", "labels": [], "entities": []}, {"text": "Moreover, this setting is different from the Smart Home one as the user must be close to the avatar to speak (i.e., not a distant speech setting).", "labels": [], "entities": []}, {"text": "In, a communicative avatar was designed to interact with a person in a smart office.", "labels": [], "entities": []}, {"text": "In this research, enhanced speech recognition is performed using beamforming and a geometric area of recording.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 27, "end_pos": 45, "type": "TASK", "confidence": 0.7312815338373184}]}, {"text": "But this promising research is still to be tested in a multiroom and multisource realistic home.", "labels": [], "entities": []}, {"text": "Designing and applying speech interfaces in Smart Home to provide security reassurance and natural man-machine interaction is the aim of the SWEET-HOME 2 project.", "labels": [], "entities": []}, {"text": "With respect to this short state-of-the-art, the project addresses the important issues of distant voice command recognition and sound source identification.", "labels": [], "entities": [{"text": "distant voice command recognition", "start_pos": 91, "end_pos": 124, "type": "TASK", "confidence": 0.6230493783950806}, {"text": "sound source identification", "start_pos": 129, "end_pos": 156, "type": "TASK", "confidence": 0.6541761954625448}]}, {"text": "The outcomes of this research are of high importance to improve the robustness of the systems mentioned above.", "labels": [], "entities": []}, {"text": "In this paper, we introduce the PATSH system which perform the real-time identification of the voice command anywhere in the home.", "labels": [], "entities": [{"text": "PATSH", "start_pos": 32, "end_pos": 37, "type": "METRIC", "confidence": 0.838344156742096}, {"text": "real-time identification of the voice command", "start_pos": 63, "end_pos": 108, "type": "TASK", "confidence": 0.7344860186179479}]}, {"text": "Its architecture and the state-of-the-art processing technologies employed are detailed in Section 2.", "labels": [], "entities": []}, {"text": "This system was evaluated in a realistic Smart Home with three user groups: people with no special needs, seniors and, visually impaired people.", "labels": [], "entities": []}, {"text": "These experiments are summarised in Section 3.", "labels": [], "entities": []}, {"text": "PATSH was used on-line (vs. off-line) during the experiment, these results are analysed in Section 4.", "labels": [], "entities": [{"text": "PATSH", "start_pos": 0, "end_pos": 5, "type": "METRIC", "confidence": 0.9358359575271606}]}, {"text": "The paper finishes with a short outlook of future work.", "labels": [], "entities": []}], "datasetContent": [{"text": "Experiments were run in the DOMUS smart home.", "labels": [], "entities": [{"text": "DOMUS smart home", "start_pos": 28, "end_pos": 44, "type": "DATASET", "confidence": 0.9174392223358154}]}, {"text": "shows the details of the flat.", "labels": [], "entities": []}, {"text": "It is a thirty square meters suite flat including a bathroom, a kitchen, a bedroom and a study, all equipped with 150 (konnex) KNX sensors and actuators.", "labels": [], "entities": []}, {"text": "The flat has been equipped with 7 radio microphones set in the ceiling for audio analysis.", "labels": [], "entities": [{"text": "audio analysis", "start_pos": 75, "end_pos": 89, "type": "TASK", "confidence": 0.7132286131381989}]}, {"text": "A specialized communication device, e-lio, from the Technosens company was used to initiate a communication between the user and a relative.", "labels": [], "entities": [{"text": "Technosens company", "start_pos": 52, "end_pos": 70, "type": "DATASET", "confidence": 0.958740770816803}]}, {"text": "To validate the system in realistic conditions, we built scenarios in which every participant was asked to perform the following activities: (1) Sleeping; (2) Resting: listening to the radio; (3) Feeding: preparing and having a meal; and (4) Communicating: having a talk with a remote person thanks to e-lio.", "labels": [], "entities": []}, {"text": "Therefore, this experiment allowed us to process realistic and representative audio events in conditions which are directly linked to usual daily living activities.", "labels": [], "entities": []}, {"text": "Moreover, to evaluate the decision making, some specific situations were planned in the scenarios.", "labels": [], "entities": []}, {"text": "The person is having a meal on the kitchen table.", "labels": [], "entities": []}, {"text": "The most appropriate light is the one above the table.", "labels": [], "entities": []}, {"text": "The person is cleaning up the bedroom.", "labels": [], "entities": []}, {"text": "The most appropriate light is the ceiling one.", "labels": [], "entities": []}, {"text": "The person is cleaning the sink and doing the dishes.", "labels": [], "entities": []}, {"text": "The most appropriate light is the one above the sink.", "labels": [], "entities": []}, {"text": "The person has just finished a nap.", "labels": [], "entities": []}, {"text": "The most appropriate light is the bedside one.", "labels": [], "entities": []}, {"text": "Each participant had to use vocal orders to make the light on or off, open or close blinds, ask about temperature and ask to call his or her relative.", "labels": [], "entities": []}, {"text": "The instruction was given to the participant to repeat the order up to 3 times in case of failure.", "labels": [], "entities": [{"text": "repeat", "start_pos": 48, "end_pos": 54, "type": "METRIC", "confidence": 0.9834632277488708}]}, {"text": "In case of, a wizard of Oz was used in case of persistent problem.", "labels": [], "entities": []}, {"text": "Sixteen participants (including 7 women) without special needs were asked to perform the scenarios without condition on the duration.", "labels": [], "entities": []}, {"text": "A visit, before the experiment, was organized to ensure that the participants will find all the items necessary to perform the scenarios.", "labels": [], "entities": []}, {"text": "It was necessary to explain the right way to utter vocal orders and to use the e-lio system.", "labels": [], "entities": []}, {"text": "Before the experiment, the participant was asked to read a text of 25 short sentences in order to adapt the acoustic models of the ASR for future experiments.", "labels": [], "entities": [{"text": "ASR", "start_pos": 131, "end_pos": 134, "type": "TASK", "confidence": 0.8921217322349548}]}, {"text": "The average age of the participants was 38 years (19-62, min-max) and the experiment lasted between 23min and 48min.", "labels": [], "entities": []}, {"text": "The scenario includes at least 15 vocal orders for each participant but more sentences were uttered because of repetitions.", "labels": [], "entities": []}, {"text": "The method has also been applied in the same context but with aged and visually impaired people.", "labels": [], "entities": []}, {"text": "The aim was both to validate the technology with this specific population and to perform a user study to assess the adequacy of this technology with the targeted users and to compare with the other user studies of the literature.", "labels": [], "entities": []}, {"text": "Between the two experiments, several corrections were applied to PATSH so that the sound/speech discrimination was greatly improved as well as the speech decoding time.", "labels": [], "entities": [{"text": "PATSH", "start_pos": 65, "end_pos": 70, "type": "METRIC", "confidence": 0.46472805738449097}]}, {"text": "The measured decoding time was 1.47 times the sentence duration; as the average duration of a vocal order was 1.048s, the delay between the end of the utterance and the execution of the order was 1.55s.", "labels": [], "entities": []}, {"text": "This is still not a satisfactory delay but this does not prevent usage in real conditions.", "labels": [], "entities": []}, {"text": "In this experiment, eleven participants either aged (6 women) or visually impaired (2 women, 3 men) were recruited.", "labels": [], "entities": []}, {"text": "The average age was 72 years (49-91, min-max).", "labels": [], "entities": []}, {"text": "The aged persons were fully autonomous but were living alone.", "labels": [], "entities": []}, {"text": "The participants were asked to perform 4 scenarios involving daily living activities and distress or risky situations.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Number of audio events (speech and sound).", "labels": [], "entities": []}, {"text": " Table 2: Number of syntactically correct vocal orders", "labels": [], "entities": []}, {"text": " Table 3: Home automation order error rate (DER)", "labels": [], "entities": [{"text": "order error rate (DER)", "start_pos": 26, "end_pos": 48, "type": "METRIC", "confidence": 0.7814284265041351}]}]}