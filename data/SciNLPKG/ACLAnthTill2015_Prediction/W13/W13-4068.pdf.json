{"title": [{"text": "Multi-domain learning and generalization in dialog state tracking", "labels": [], "entities": [{"text": "dialog state tracking", "start_pos": 44, "end_pos": 65, "type": "TASK", "confidence": 0.7207206090291342}]}], "abstractContent": [{"text": "Statistical approaches to dialog state tracking synthesize information across multiple turns in the dialog, overcoming some speech recognition errors.", "labels": [], "entities": [{"text": "dialog state tracking", "start_pos": 26, "end_pos": 47, "type": "TASK", "confidence": 0.8764888246854147}, {"text": "speech recognition", "start_pos": 124, "end_pos": 142, "type": "TASK", "confidence": 0.6833032965660095}]}, {"text": "When training a dialog state tracker, there is typically only a small corpus of well-matched dialog data available.", "labels": [], "entities": [{"text": "dialog state tracker", "start_pos": 16, "end_pos": 36, "type": "TASK", "confidence": 0.7881852984428406}]}, {"text": "However, often there is a large corpus of mis-matched but related data-perhaps pertaining to different semantic concepts, or from a different dialog system.", "labels": [], "entities": []}, {"text": "It would be desirable to use this related dialog data to supplement the small corpus of well-matched dialog data.", "labels": [], "entities": []}, {"text": "This paper addresses this task as multi-domain learning, presenting 3 methods which synthesize data from different slots and different dialog systems.", "labels": [], "entities": []}, {"text": "Since deploying anew dialog state tracker often changes the resulting dialogs in ways that are difficult to predict, we study how well each method generalizes to unseen distributions of dialog data.", "labels": [], "entities": []}, {"text": "Our main result is the finding that a simple method for multi-domain learning substantially improves performance in highly mis-matched conditions.", "labels": [], "entities": []}], "introductionContent": [{"text": "Spoken dialog systems interact with users via natural language to help them achieve a goal.", "labels": [], "entities": []}, {"text": "As the interaction progresses, the dialog manager maintains a representation of the state of the dialog in a process called dialog state tracking.", "labels": [], "entities": [{"text": "dialog state tracking", "start_pos": 124, "end_pos": 145, "type": "TASK", "confidence": 0.6908350984255472}]}, {"text": "For example, in a bus schedule information system, the dialog state might indicate the user's desired bus route, origin, and destination.", "labels": [], "entities": []}, {"text": "Dialog state tracking is difficult because errors in automatic speech recognition (ASR) and spoken language understanding (SLU) are common, and can cause the system to misunderstand the user's needs.", "labels": [], "entities": [{"text": "Dialog state tracking", "start_pos": 0, "end_pos": 21, "type": "TASK", "confidence": 0.9150993426640829}, {"text": "automatic speech recognition (ASR)", "start_pos": 53, "end_pos": 87, "type": "TASK", "confidence": 0.789555013179779}, {"text": "spoken language understanding (SLU)", "start_pos": 92, "end_pos": 127, "type": "TASK", "confidence": 0.7677616278330485}]}, {"text": "At the same time, state tracking is crucial because the system relies on the estimated dialog state to choose actionsfor example, which bus schedule information to present to the user.", "labels": [], "entities": [{"text": "state tracking", "start_pos": 18, "end_pos": 32, "type": "TASK", "confidence": 0.7615885138511658}]}, {"text": "Most commercial systems use hand-crafted rules for state tracking, selecting the SLU result with the highest confidence score observed so far, and discarding alternatives.", "labels": [], "entities": [{"text": "state tracking", "start_pos": 51, "end_pos": 65, "type": "TASK", "confidence": 0.7263068854808807}]}, {"text": "In contrast, statistical approaches compute a posterior distribution over many hypotheses for the dialog state, and in general these have been shown to be superior.", "labels": [], "entities": []}, {"text": "Unfortunately, when training a dialog state tracker, there is rarely a large corpus of matched data available.", "labels": [], "entities": [{"text": "dialog state tracker", "start_pos": 31, "end_pos": 51, "type": "TASK", "confidence": 0.7385759751001993}]}, {"text": "For example, a pilot version of the system maybe fielded in a controlled environment to collect a small initial corpus.", "labels": [], "entities": []}, {"text": "Yet there is often a large quantity of mis-matched dialog data available.", "labels": [], "entities": []}, {"text": "For example, dialog data might be available from another dialog system -such as an earlier version with a different recognizer, dialog controller, and user population -or from a related task -such as searching for restaurants instead of hotels.", "labels": [], "entities": []}, {"text": "In this paper, we tackle the general problem of how to make use of disparate sources of data when training a dialog state tracker.", "labels": [], "entities": [{"text": "dialog state tracker", "start_pos": 109, "end_pos": 129, "type": "TASK", "confidence": 0.7167482773462931}]}, {"text": "For example, should a tracker for each slot be trained on small sets of slot-specific data, or should data from all slots be combined somehow?", "labels": [], "entities": []}, {"text": "Can dialog data from another system be used to build effective tracker fora new system for which no data (yet) exists?", "labels": [], "entities": []}, {"text": "Once data from the new system is available, is the old data still useful?", "labels": [], "entities": []}, {"text": "These inter-related questions can be formalized as multi-domain learning and generalization.", "labels": [], "entities": []}, {"text": "Multi-domain learning (MDL) refers to the task of building a model -here, a state tracker -for a target domain using training data from both the target domain and a different but related domain.", "labels": [], "entities": [{"text": "Multi-domain learning (MDL)", "start_pos": 0, "end_pos": 27, "type": "TASK", "confidence": 0.8272223830223083}]}, {"text": "Generalization refers to the ability of a model to perform well in a domain unlike that seen in any of the training data.", "labels": [], "entities": [{"text": "Generalization", "start_pos": 0, "end_pos": 14, "type": "TASK", "confidence": 0.8478974103927612}]}, {"text": "Both multi-domain learning and generalization are active research topics in the machine learning community, with broad applications.", "labels": [], "entities": []}, {"text": "() provides a comparison of popular methods on several (non-dialog) tasks, including sentiment classification in on-line product reviews.", "labels": [], "entities": [{"text": "sentiment classification in on-line product reviews", "start_pos": 85, "end_pos": 136, "type": "TASK", "confidence": 0.8200859228769938}]}, {"text": "In dialog state tracking, there area variety of properties that could be cast as a \"domain\".", "labels": [], "entities": [{"text": "dialog state tracking", "start_pos": 3, "end_pos": 24, "type": "TASK", "confidence": 0.7909422318140665}]}, {"text": "In this paper, we explore two obvious domains: different dialog systems, and different slots, where slots are informational sub-units of the dialog state, such as the origin, bus route, and departure time in a bus timetables spoken dialog system.", "labels": [], "entities": []}, {"text": "We apply several methods for MDL across varied dialog systems, slots, and combinations of both.", "labels": [], "entities": []}, {"text": "MDL is attractive for dialog state tracking because the distribution across slots and systems is related but not identical.", "labels": [], "entities": [{"text": "dialog state tracking", "start_pos": 22, "end_pos": 43, "type": "TASK", "confidence": 0.8543151418368021}]}, {"text": "For example, the ranges of speech recognition confidence scores for two slots such as bus route and date maybe different, or one system may use confirmations much more often than another.", "labels": [], "entities": [{"text": "speech recognition confidence scores", "start_pos": 27, "end_pos": 63, "type": "TASK", "confidence": 0.6697394847869873}]}, {"text": "Despite these differences, there are useful patterns: regardless of the slot or system, higher confidence scores and responses of \"yes\" to confirmations provide more certainty.", "labels": [], "entities": [{"text": "certainty", "start_pos": 166, "end_pos": 175, "type": "METRIC", "confidence": 0.9872416257858276}]}, {"text": "The hope is that MDL can provide a principled way of using all available data to maximize accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 90, "end_pos": 98, "type": "METRIC", "confidence": 0.9944211840629578}]}, {"text": "An important problem in dialog state tracking is that deploying anew tracker into production will produce anew distribution of dialog data that maybe unlike data observed at training time in ways that are difficult to predict.", "labels": [], "entities": [{"text": "dialog state tracking", "start_pos": 24, "end_pos": 45, "type": "TASK", "confidence": 0.8995827039082845}]}, {"text": "As a result, it is important to test the generalization of dialog state tracking models on data that differs from the training distribution.", "labels": [], "entities": [{"text": "dialog state tracking", "start_pos": 59, "end_pos": 80, "type": "TASK", "confidence": 0.7629616260528564}]}, {"text": "In this paper, we evaluate each of the MDL approaches on multiple held-out datasets, ranging from well-matched to very mis-matched -i.e., dialog data from the same dialog system, a modified version of the dialog system, and a completely different dialog system.", "labels": [], "entities": []}, {"text": "We show that dialog data from multiple existing systems can be used to build good state trackers fora completely new system, and that a simple form of MDL improves generalization substantially.", "labels": [], "entities": []}, {"text": "We also find that, if well-matched data from that new system is available, the effect (positive or negative) of MDL is slight.", "labels": [], "entities": []}, {"text": "Since in practice the level of mis-match can be difficult to predict, this suggests that training with (a particular form of) MDL is the safest approach.", "labels": [], "entities": []}, {"text": "This paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 describes the algorithm used for state tracking and the dialog data employed.", "labels": [], "entities": [{"text": "state tracking", "start_pos": 43, "end_pos": 57, "type": "TASK", "confidence": 0.7917323112487793}]}, {"text": "Section 3 then introduces methods for multi-domain learning.", "labels": [], "entities": []}, {"text": "Section 4 presents results and Section 5 briefly concludes.", "labels": [], "entities": []}], "datasetContent": [{"text": "In the experiments below, we train dialog state trackers that output a scored list of dialog state hypotheses for each slot at each turn in the dialog.", "labels": [], "entities": []}, {"text": "For evaluation, we measure the fraction of output lists where the top dialog state hypothesis is correct.", "labels": [], "entities": []}, {"text": "A dialog state hypothesis is correct if it corresponds to a slot value which has been recognized correctly.", "labels": [], "entities": []}, {"text": "The dialog state tracker may include the meta-hypothesis REST among its hypotheses -this meta-hypothesis is labeled as correct if no correct values have yet been recognized for this slot.", "labels": [], "entities": [{"text": "dialog state tracker", "start_pos": 4, "end_pos": 24, "type": "TASK", "confidence": 0.6577985187371572}, {"text": "REST", "start_pos": 57, "end_pos": 61, "type": "METRIC", "confidence": 0.8996396660804749}]}, {"text": "Since most turns contain no information about most slots, we limit evaluation to turns where new information fora slot appears either in the speech recognition output, or in the system output.", "labels": [], "entities": []}, {"text": "For Synthetic feature vector encoding for data from:: Synthetic features constructed for each multi-domain learning method applied to systems.", "labels": [], "entities": [{"text": "Synthetic feature vector encoding", "start_pos": 4, "end_pos": 37, "type": "TASK", "confidence": 0.7579554915428162}]}, {"text": "Here, the subscript on X indicates the system it originated from.", "labels": [], "entities": []}, {"text": "Asterisk super-scripts indicate system-specific features, which are only included for the group the tracker will be tested on (i.e., the target group).", "labels": [], "entities": []}, {"text": "example, in turn i, if a system confirms a bus route, and a date appears in the speech recognition output, both of these slots in turn i will be included when computing average accuracy.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 80, "end_pos": 98, "type": "TASK", "confidence": 0.6896469593048096}, {"text": "accuracy", "start_pos": 177, "end_pos": 185, "type": "METRIC", "confidence": 0.7557401657104492}]}, {"text": "If the time slot appears in neither the system output nor anywhere in the speech recognition output of turn i, then the time slot in turn i is excluded when computing average accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 175, "end_pos": 183, "type": "METRIC", "confidence": 0.8801167011260986}]}, {"text": "The accuracy computation itself was done by the scoring tool from the Dialog State Tracking Challenge, using the schedule2 accuracy metric for all slots ( ).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.9983507394790649}, {"text": "Dialog State Tracking Challenge", "start_pos": 70, "end_pos": 101, "type": "TASK", "confidence": 0.6968115568161011}, {"text": "accuracy", "start_pos": 123, "end_pos": 131, "type": "METRIC", "confidence": 0.8836638927459717}]}, {"text": "For comparison, we also report performance of a simple rule-based tracker.", "labels": [], "entities": []}, {"text": "For each slot, this tracker scans overall values recognized so far in the dialog, and returns the value which has been recognized with the highest local SLU confidence score.", "labels": [], "entities": [{"text": "SLU confidence score", "start_pos": 153, "end_pos": 173, "type": "METRIC", "confidence": 0.6051113605499268}]}], "tableCaptions": [{"text": " Table 1: Corpora used in this paper. |X| denotes the number of common features, and |X  *  | denotes the  number of system-specific features. The data in systems TEST1 and TEST3 has low mis-match to the  training data because they use very similar dialog managers as in TRAIN2 and TRAIN3, respectively.", "labels": [], "entities": [{"text": "mis-match", "start_pos": 187, "end_pos": 196, "type": "METRIC", "confidence": 0.98861163854599}]}]}