{"title": [{"text": "Learning from errors: Using vector-based compositional semantics for parse reranking", "labels": [], "entities": [{"text": "parse reranking", "start_pos": 69, "end_pos": 84, "type": "TASK", "confidence": 0.8269543349742889}]}], "abstractContent": [{"text": "In this paper, we address the problem of how to use semantics to improve syntactic parsing, by using a hybrid reranking method: a k-best list generated by a symbolic parser is reranked based on parse-correctness scores given by a composi-tional, connectionist classifier.", "labels": [], "entities": [{"text": "syntactic parsing", "start_pos": 73, "end_pos": 90, "type": "TASK", "confidence": 0.7588180601596832}]}, {"text": "This classi-fier uses a recursive neural network to construct vector representations for phrases in a candidate parse tree in order to classify it as syntactically corrector not.", "labels": [], "entities": []}, {"text": "Tested on the WSJ23, our method achieved a statistically significant improvement of 0.20% on F-score (2% error reduction) and 0.95% on exact match, compared with the state-of-the-art Berkeley parser.", "labels": [], "entities": [{"text": "WSJ23", "start_pos": 14, "end_pos": 19, "type": "DATASET", "confidence": 0.9826396703720093}, {"text": "F-score (2% error reduction)", "start_pos": 93, "end_pos": 121, "type": "METRIC", "confidence": 0.7349403670855931}, {"text": "exact match", "start_pos": 135, "end_pos": 146, "type": "METRIC", "confidence": 0.9114421308040619}]}, {"text": "This result shows that vector-based compositional semantics can be usefully applied in syntactic parsing , and demonstrates the benefits of combining the symbolic and connectionist approaches .", "labels": [], "entities": [{"text": "syntactic parsing", "start_pos": 87, "end_pos": 104, "type": "TASK", "confidence": 0.7579293251037598}]}], "introductionContent": [{"text": "Following the idea of compositionality informal semantics, compositionality in vector-based semantics is also based on the principle of compositionality, which says that \"The meaning of a whole is a function of the meanings of the parts and of the way they are syntactically combined\".", "labels": [], "entities": []}, {"text": "According to this principle, composing the meaning of a phrase or sentence requires a syntactic parse tree, which is, inmost current systems, given by a statistical parser.", "labels": [], "entities": [{"text": "composing the meaning of a phrase or sentence", "start_pos": 29, "end_pos": 74, "type": "TASK", "confidence": 0.826837919652462}]}, {"text": "This parser, in turn, is trained on syntactically annotated corpora.", "labels": [], "entities": []}, {"text": "However, there are good reasons to also consider information flowing in the opposite direction: from semantics to syntactic parsing.", "labels": [], "entities": [{"text": "syntactic parsing", "start_pos": 114, "end_pos": 131, "type": "TASK", "confidence": 0.7295881509780884}]}, {"text": "Performance of parsers trained and evaluated on the Penn WSJ treebank has reached a plateau, as many ambiguities cannot be resolved by syntactic information alone.", "labels": [], "entities": [{"text": "Penn WSJ treebank", "start_pos": 52, "end_pos": 69, "type": "DATASET", "confidence": 0.947982907295227}]}, {"text": "Further improvements in parsing may depend on the use of additional sources of information, including semantics.", "labels": [], "entities": [{"text": "parsing", "start_pos": 24, "end_pos": 31, "type": "TASK", "confidence": 0.9704989790916443}]}, {"text": "In this paper, we study the use of semantics for syntactic parsing.", "labels": [], "entities": [{"text": "syntactic parsing", "start_pos": 49, "end_pos": 66, "type": "TASK", "confidence": 0.8414980173110962}]}, {"text": "The currently dominant approach to syntactic parsing is based on extracting symbolic grammars from a treebank and defining appropriate probability distributions over the parse trees that they license).", "labels": [], "entities": [{"text": "syntactic parsing", "start_pos": 35, "end_pos": 52, "type": "TASK", "confidence": 0.8183609545230865}]}, {"text": "An alternative approach, with promising recent developments, is based on using neural networks.", "labels": [], "entities": []}, {"text": "In the present paper, we combine the 'symbolic' and 'connectionist' approaches through reranking: a symbolic parser is used to generate a k-best list which is then reranked based on parse-correctness scores given by a connectionist compositional-semantics-based classifier.", "labels": [], "entities": []}, {"text": "The idea of reranking is motivated by analyses of the results of state-of-the-art symbolic parsers such as the Brown and Berkeley parsers, which have shown that there is still considerable room for improvement: oracle results on 50-best lists display a dramatic improvement inaccuracy (96.08% vs. 90.12% on F-score and 65.56% vs. 37.22% on exact match with the Berkeley parser).", "labels": [], "entities": [{"text": "reranking", "start_pos": 12, "end_pos": 21, "type": "TASK", "confidence": 0.9749892950057983}, {"text": "F-score", "start_pos": 307, "end_pos": 314, "type": "METRIC", "confidence": 0.9387941956520081}]}, {"text": "This suggests that parsers that rely on syntactic corpus-statistics, though not sufficient by themselves, may very well serve as a basis for systems that integrate other sources of information by means of reranking.", "labels": [], "entities": []}, {"text": "One important complementary source of information is the semantic plausibility of the constituents of the syntactically viable parses.", "labels": [], "entities": []}, {"text": "The exploitation of that kind of information is the topic of the research we report here.", "labels": [], "entities": []}, {"text": "In this work, we followup on a proposal by Mark Steedman (1999), who suggested that the realm of semantics lacks the clearcut hierarchical structures that characterise syntax, and that semantic information may therefore be profitably treated by the classificatory mechanisms of neural nets-while the treatment of syntactic structures is best left to symbolic parsers.", "labels": [], "entities": []}, {"text": "We thus developed a hybrid system, which parses its input sentences on the basis of a symbolic probabilistic grammar, and reranks the candidate parses based on scores given by a neural network.", "labels": [], "entities": []}, {"text": "Our work is inspired by the work of Socher and colleagues.", "labels": [], "entities": []}, {"text": "They proposed a parser using a recursive neural network (RNN) for encoding parse trees, representing phrases in a vector space, and scoring them.", "labels": [], "entities": []}, {"text": "Their experimental result (only 1.92% lower than the Stanford parser on unlabelled bracket F-score for sentences up to a length of 15 words) shows that an RNN is expressive enough for syntactic parsing.", "labels": [], "entities": [{"text": "syntactic parsing", "start_pos": 184, "end_pos": 201, "type": "TASK", "confidence": 0.8106814026832581}]}, {"text": "Additionally, their qualitative analysis indicates that the learnt phrase features capture some aspects of phrasal semantics, which could be useful to resolve semantic ambiguity that syntactical information alone cannot.", "labels": [], "entities": []}, {"text": "Our work in this paper differs from their work in that we replace the parsing task by a reranking task, and thus reduce the object space significantly to a set of parses generated by a symbolic parser rather than the space of all parse trees.", "labels": [], "entities": []}, {"text": "As a result, we can apply our method to sentences which are much longer than 15 words.", "labels": [], "entities": []}, {"text": "Reranking a k-best list is not anew idea., have built reranking systems with performances that are state-of-the-art.", "labels": [], "entities": []}, {"text": "In order to achieve such high F-scores, those rerankers rely on a very large number of features selected on the basis of expert knowledge.", "labels": [], "entities": [{"text": "F-scores", "start_pos": 30, "end_pos": 38, "type": "METRIC", "confidence": 0.9932968020439148}]}, {"text": "Unlike them, our feature set is selected automatically, yet the reranker achieved a statistically significant improvement on both F-score and exact match.", "labels": [], "entities": [{"text": "F-score", "start_pos": 130, "end_pos": 137, "type": "METRIC", "confidence": 0.9954600930213928}, {"text": "exact", "start_pos": 142, "end_pos": 147, "type": "METRIC", "confidence": 0.9930419921875}]}, {"text": "Closest to our work is and: both also rely on symbolic parsers to reduce the search space and use RNNs to score candidate parses.", "labels": [], "entities": []}, {"text": "However, our work differs in the way the feature set for reranking is selected.", "labels": [], "entities": []}, {"text": "In their methods, only the score at the tree root is considered whereas in our method the scores at all internal nodes are taken into account.", "labels": [], "entities": []}, {"text": "Selecting the feature set like that gives us a flexible way to deal with errors accumulated from the leaves to the root.", "labels": [], "entities": []}, {"text": "shows a diagram of our method.", "labels": [], "entities": []}, {"text": "First, a parser (in this paper: the Berkeley parser) is used to generate k-best lists of the Wall Street Journal (WSJ) sections 02-21.", "labels": [], "entities": [{"text": "Wall Street Journal (WSJ) sections 02-21", "start_pos": 93, "end_pos": 133, "type": "DATASET", "confidence": 0.9314181730151176}]}, {"text": "Then, all parse trees in these lists and the WSJ02-21 are preprocessed by marking head words, binarising, and performing error-annotation (Section 2).", "labels": [], "entities": [{"text": "WSJ02-21", "start_pos": 45, "end_pos": 53, "type": "DATASET", "confidence": 0.981756329536438}]}, {"text": "After that, we use the annotated trees to train our parse-correctness classifier (Section 3).", "labels": [], "entities": []}, {"text": "Finally, those trees and the classifier are used to train the reranker (Section 4).", "labels": [], "entities": []}], "datasetContent": [{"text": "The experiments presented in this paper have the following setting.", "labels": [], "entities": []}, {"text": "We use the WSJ corpus with the standard splits: sections 2-21 for training, section 22 for development, and section 23 for testing.", "labels": [], "entities": [{"text": "WSJ corpus", "start_pos": 11, "end_pos": 21, "type": "DATASET", "confidence": 0.9721660912036896}]}, {"text": "The latest implementation (version 1.7) of the Berkeley parser 1 () is used for generating 50-best lists.", "labels": [], "entities": []}, {"text": "We mark head words and binarise all trees in the WSJ and the 50-best lists as in Subsection 2.1, and annotate them as in Subsection 2.2 (see).", "labels": [], "entities": [{"text": "WSJ", "start_pos": 49, "end_pos": 52, "type": "DATASET", "confidence": 0.9491503834724426}]}, {"text": "Using the classifier in Section 3, we implemented the reranker in Torch7, trained it on WSJ02-21.", "labels": [], "entities": [{"text": "Torch7", "start_pos": 66, "end_pos": 72, "type": "DATASET", "confidence": 0.9807230830192566}, {"text": "WSJ02-21", "start_pos": 88, "end_pos": 96, "type": "DATASET", "confidence": 0.9830315113067627}]}, {"text": "We used WSJ22 to estimate the parameters \u03b3 y and \u03b3 h by the grid search and found that \u03b3 y = 9 and \u03b3 h = 4 yielded the best F-score.", "labels": [], "entities": [{"text": "WSJ22", "start_pos": 8, "end_pos": 13, "type": "DATASET", "confidence": 0.951426088809967}, {"text": "F-score", "start_pos": 124, "end_pos": 131, "type": "METRIC", "confidence": 0.996969997882843}]}, {"text": "shows the results of our reranker on 50-best WSJ23 given by the Berkeley parser, using the standard evalb.", "labels": [], "entities": [{"text": "WSJ23", "start_pos": 45, "end_pos": 50, "type": "DATASET", "confidence": 0.9599003791809082}]}, {"text": "Our method improves 0.20% on F-score for sentences with all length, and 0.22% for sentences with \u2264 40 words.", "labels": [], "entities": [{"text": "F-score", "start_pos": 29, "end_pos": 36, "type": "METRIC", "confidence": 0.9994753003120422}]}, {"text": "These differences are statistically significant 6 with p-value < 0.003.", "labels": [], "entities": []}, {"text": "Our method also improves exact match (0.95% for all sentences as well as for sentences with \u2264 40 words).: Reranking results on 50-best lists on WSJ23 (LR is labelled recall, LP is labelled precision, LF is labelled F-score, and EX is exact match.) shows the comparison of the three parsers that use the same hybrid reranking approach.", "labels": [], "entities": [{"text": "exact match", "start_pos": 25, "end_pos": 36, "type": "METRIC", "confidence": 0.9291073381900787}, {"text": "WSJ23", "start_pos": 144, "end_pos": 149, "type": "DATASET", "confidence": 0.9792262315750122}, {"text": "recall", "start_pos": 166, "end_pos": 172, "type": "METRIC", "confidence": 0.9894307851791382}, {"text": "precision", "start_pos": 189, "end_pos": 198, "type": "METRIC", "confidence": 0.9744754433631897}, {"text": "exact match.", "start_pos": 234, "end_pos": 246, "type": "METRIC", "confidence": 0.9544856250286102}]}, {"text": "On F-score, our method performed 0.1% lower than, and 1.5% better than.", "labels": [], "entities": [{"text": "F-score", "start_pos": 3, "end_pos": 10, "type": "METRIC", "confidence": 0.9988722205162048}]}, {"text": "However, our method achieved the least improvement on F-score over its corresponding baseline.", "labels": [], "entities": [{"text": "F-score", "start_pos": 54, "end_pos": 61, "type": "METRIC", "confidence": 0.9994387030601501}]}, {"text": "That could be because our baseline parser (i.e., the Berkeley parser) performs much better than the other two baseline parsers; and hence, detecting errors it makes on candidate parse trees is more difficult.: Comparison of parsers using the same hybrid reranking approach.", "labels": [], "entities": []}, {"text": "The numbers in the blankets indicate the improvements on F-score over the corresponding baselines (i.e., the k-best parsers).", "labels": [], "entities": [{"text": "F-score", "start_pos": 57, "end_pos": 64, "type": "METRIC", "confidence": 0.9980631470680237}]}], "tableCaptions": [{"text": " Table 1: Classification results on the WSJ22 and  the k-best lists.", "labels": [], "entities": [{"text": "WSJ22", "start_pos": 40, "end_pos": 45, "type": "DATASET", "confidence": 0.9226582646369934}]}, {"text": " Table 2: Reranking results on 50-best lists on  WSJ23 (LR is labelled recall, LP is labelled pre- cision, LF is labelled F-score, and EX is exact  match.)", "labels": [], "entities": [{"text": "Reranking", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9576981067657471}, {"text": "WSJ23", "start_pos": 49, "end_pos": 54, "type": "DATASET", "confidence": 0.9516453146934509}, {"text": "recall", "start_pos": 71, "end_pos": 77, "type": "METRIC", "confidence": 0.997379720211029}, {"text": "F-score", "start_pos": 122, "end_pos": 129, "type": "METRIC", "confidence": 0.961035966873169}, {"text": "EX", "start_pos": 135, "end_pos": 137, "type": "METRIC", "confidence": 0.9702563881874084}, {"text": "exact  match", "start_pos": 141, "end_pos": 153, "type": "METRIC", "confidence": 0.8994081020355225}]}]}