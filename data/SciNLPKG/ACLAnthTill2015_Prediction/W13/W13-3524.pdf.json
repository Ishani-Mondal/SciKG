{"title": [{"text": "Terminology Extraction Approaches for Product Aspect Detection in Customer Reviews", "labels": [], "entities": [{"text": "Terminology Extraction Approaches", "start_pos": 0, "end_pos": 33, "type": "TASK", "confidence": 0.7085232039292654}, {"text": "Product Aspect Detection in Customer Reviews", "start_pos": 38, "end_pos": 82, "type": "TASK", "confidence": 0.7090474863847097}]}], "abstractContent": [{"text": "In this paper, we address the problem of identifying relevant product aspects in a collection of online customer reviews.", "labels": [], "entities": []}, {"text": "Being able to detect such aspects represents an important subtask of aspect-based review mining systems, which aim at automatically generating structured summaries of customer opinions.", "labels": [], "entities": [{"text": "aspect-based review mining", "start_pos": 69, "end_pos": 95, "type": "TASK", "confidence": 0.6084691683451334}]}, {"text": "We cast the task as a terminology extraction problem and examine the utility of varying term acquisition heuristics, filtering techniques, variant aggregation methods, and relevance measures.", "labels": [], "entities": [{"text": "terminology extraction", "start_pos": 22, "end_pos": 44, "type": "TASK", "confidence": 0.8769212067127228}]}, {"text": "We evaluate the different approaches on two distinct datasets (hotel and camera reviews).", "labels": [], "entities": []}, {"text": "For the best configuration , we find significant improvements over a state-of-the-art baseline method.", "labels": [], "entities": []}], "introductionContent": [{"text": "Identifying significant terms in a text corpus constitutes a core task in natural language processing.", "labels": [], "entities": [{"text": "Identifying significant terms in a text corpus", "start_pos": 0, "end_pos": 46, "type": "TASK", "confidence": 0.8880877154214042}]}, {"text": "Fields of application are for example glossary extraction () or ontology learning (.", "labels": [], "entities": [{"text": "glossary extraction", "start_pos": 38, "end_pos": 57, "type": "TASK", "confidence": 0.6577997952699661}]}, {"text": "In this work, we particularly focus on the application scenario of aspect-based customer review mining (.", "labels": [], "entities": [{"text": "customer review mining", "start_pos": 80, "end_pos": 102, "type": "TASK", "confidence": 0.6882886985937754}]}, {"text": "It is best described as a sentiment analysis task, where the goal is to summarize the opinions expressed in customer reviews.", "labels": [], "entities": [{"text": "sentiment analysis task", "start_pos": 26, "end_pos": 49, "type": "TASK", "confidence": 0.9422481656074524}, {"text": "summarize the opinions expressed in customer reviews", "start_pos": 72, "end_pos": 124, "type": "TASK", "confidence": 0.799450295312064}]}, {"text": "Typically, the problem is decomposed into three subtasks: 1) identify mentions of relevant product aspects, 2) identify sentiment expressions and determine their polarity, and 3) aggregate the sentiments for each aspect.", "labels": [], "entities": []}, {"text": "In this paper, we only consider the first subtask, i.e., finding relevant product aspects in reviews.", "labels": [], "entities": []}, {"text": "More precisely, we define the problem setting as follows: Input is a homogeneous collection of customer reviews, i.e., all reviews refer to a single product type (e.g., digital cameras or hotels).", "labels": [], "entities": [{"text": "Input", "start_pos": 58, "end_pos": 63, "type": "METRIC", "confidence": 0.9465227723121643}]}, {"text": "The goal is to automatically derive a lexicon of the most relevant aspects related to the product type.", "labels": [], "entities": []}, {"text": "For example, given a set of hotel reviews, we want to determine aspects such as \"room size\", \"front desk staff\" \"sleep quality\", and soon.", "labels": [], "entities": []}, {"text": "In general, product aspects may occur as nominal (e.g., \"image stabilization\"), named (e.g., \"SteadyShot feature\"), pronominal (e.g., \"it\"), or implicit mentions (e.g., \"reduction of blurring from camera shake\").", "labels": [], "entities": [{"text": "image stabilization", "start_pos": 57, "end_pos": 76, "type": "TASK", "confidence": 0.7068648338317871}]}, {"text": "We explicitly restrict the task to finding nominal aspect mentions . The contribution of this paper is to explicitly cast the problem setting as a terminology extraction (TE) task and to examine the utility of methods that have been proven beneficial in this context.", "labels": [], "entities": [{"text": "terminology extraction (TE) task", "start_pos": 147, "end_pos": 179, "type": "TASK", "confidence": 0.8541464408238729}]}, {"text": "Most related work does not consider this close relationship and rather presents ad-hoc approaches.", "labels": [], "entities": []}, {"text": "Our main contributions are as follows: -We experiment with varying term acquisition methods, propose a set of new term filtering approaches, and consider variant aggregation techniques typically applied in TE systems.", "labels": [], "entities": [{"text": "term acquisition", "start_pos": 67, "end_pos": 83, "type": "TASK", "confidence": 0.7069704234600067}, {"text": "term filtering", "start_pos": 114, "end_pos": 128, "type": "TASK", "confidence": 0.6911600679159164}]}, {"text": "-We compare the utility of different term relevance measures and experiment with combinations of these measures.", "labels": [], "entities": []}, {"text": "-We propose and assess anew method that filters erroneous modifiers (adjectives) in term candidates.", "labels": [], "entities": []}, {"text": "Our method exploits information obtained from pros/cons summaries of customer reviews.", "labels": [], "entities": []}, {"text": "-Our best configuration improves over a state-ofthe-art baseline by up to 7 percentage points.", "labels": [], "entities": []}, {"text": "The remainder of the paper is organized as follows: In Section 2, we cover related work, setting focus on unsupervised approaches.", "labels": [], "entities": []}, {"text": "Section 3 describes the TE methods we examine in this study.", "labels": [], "entities": [{"text": "TE", "start_pos": 24, "end_pos": 26, "type": "TASK", "confidence": 0.924770176410675}]}, {"text": "Section 4 introduces our evaluation datasets and Section 5 presents experiments and results.", "labels": [], "entities": []}, {"text": "We summarize and conclude in Section 6.: Conceptual overview of related work in product aspect detection.", "labels": [], "entities": [{"text": "product aspect detection", "start_pos": 80, "end_pos": 104, "type": "TASK", "confidence": 0.7180782159169515}]}], "datasetContent": [{"text": "We evaluate our approaches on datasets of hotel and digital camera reviews.", "labels": [], "entities": []}, {"text": "We crawled around 500,000 hotel reviews from Tripadvisor.com and approximately 200,000 digital camera reviews from Amazon.com, Buzzillions.com, and Epinions.com.", "labels": [], "entities": [{"text": "Tripadvisor.com", "start_pos": 45, "end_pos": 60, "type": "DATASET", "confidence": 0.914508581161499}]}, {"text": "From each of the two crawls, we randomly sample 20,000 reviews, which we use as foreground corpora for the terminology extraction task . As a background corpus, we utilize a 100,000 document subset (randomly sampled) of the \"ukWaC corpus\" ().", "labels": [], "entities": [{"text": "terminology extraction", "start_pos": 107, "end_pos": 129, "type": "TASK", "confidence": 0.8672381341457367}, {"text": "ukWaC corpus", "start_pos": 225, "end_pos": 237, "type": "DATASET", "confidence": 0.9748026728630066}]}, {"text": "To evaluate our approaches, we manually annotate a subset of the crawled reviews.", "labels": [], "entities": []}, {"text": "In particular, we randomly sample subsets of 150 hotel and 150 camera reviews that do not overlap with the foreground corpora.", "labels": [], "entities": []}, {"text": "Following prior work on sentiment analysis (), we decompose an opinion into two functional constituents: sentiment expressions and sentiment targets.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 24, "end_pos": 42, "type": "TASK", "confidence": 0.9566185772418976}]}, {"text": "In addition, we consider nominal mentions of product aspects that are not targeted by a sentiment expression.", "labels": [], "entities": []}, {"text": "We annotate a document by marking relevant spans of text with the appropriate annotation type, setting the type's properties (e.g., the polarity of a sentiment expression), and relating the annotations to each other.", "labels": [], "entities": []}, {"text": "summarizes the statistics of the created evaluation corpora (regarding sentiment targets and nominal aspect mentions).", "labels": [], "entities": []}, {"text": "8 Larger corpora did not improve our results.", "labels": [], "entities": []}, {"text": "We conduct intrinsic and extrinsic evaluation of the approaches.", "labels": [], "entities": []}, {"text": "Intrinsic evaluation refers to assessing the quality of the generated product aspect lexicons.", "labels": [], "entities": [{"text": "Intrinsic evaluation", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.732993096113205}]}, {"text": "For this purpose, we manually inspect the extracted lexicons and report results in terms of precision (share of correct entries) or precision@n (the precision of then highest ranked lexicon entries).", "labels": [], "entities": [{"text": "precision", "start_pos": 92, "end_pos": 101, "type": "METRIC", "confidence": 0.9990921020507812}, {"text": "precision", "start_pos": 132, "end_pos": 141, "type": "METRIC", "confidence": 0.9923579096794128}, {"text": "precision", "start_pos": 149, "end_pos": 158, "type": "METRIC", "confidence": 0.8365275859832764}]}, {"text": "For extrinsic evaluation (evaluation in use), we apply the extracted lexicons for the task of aspect detection in customer review documents.", "labels": [], "entities": [{"text": "aspect detection", "start_pos": 94, "end_pos": 110, "type": "TASK", "confidence": 0.831737607717514}]}, {"text": "To match lexicon entries in review texts, we apply the Aho-Corasick algorithm.", "labels": [], "entities": []}, {"text": "If multiple matches overlap, we select the left-most, longest-matching, highestscoring lexicon entry (thus guaranteeing a set of non-overlapping matches).", "labels": [], "entities": []}, {"text": "Only exact matches are counted as true positives.", "labels": [], "entities": []}, {"text": "We further differentiate between two evaluation scenarios: -Scenario A: In this scenario, the task is to extract all product aspects, irrespective of being target of a sentiment expression or not.", "labels": [], "entities": []}, {"text": "We thus define the union of sentiment target and aspect mention annotations as reference (gold standard).", "labels": [], "entities": []}, {"text": "Any extraction that matches either a sentiment target or an aspect mention is considered a true positive.", "labels": [], "entities": []}, {"text": "-Scenario B: This scenario considers the task of detecting sentiment targets.", "labels": [], "entities": [{"text": "detecting sentiment targets", "start_pos": 49, "end_pos": 76, "type": "TASK", "confidence": 0.8770065903663635}]}, {"text": "As it is not our goal to assess the accuracy of sentiment expression detection, we provide the extraction algorithm with perfect (gold standard) knowledge on the presence of sentiment expressions and their relations to sentiment targets (in effect, the algorithm only considers matches that overlap a sentiment target).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 36, "end_pos": 44, "type": "METRIC", "confidence": 0.9968245029449463}, {"text": "sentiment expression detection", "start_pos": 48, "end_pos": 78, "type": "TASK", "confidence": 0.836532731850942}]}], "tableCaptions": [{"text": " Table 1: Basic corpus statistics.", "labels": [], "entities": []}, {"text": " Table 2: Extrinsic evaluation results for the base- line approach.", "labels": [], "entities": []}, {"text": " Table 5: Extrinsic evaluation results with varying  acquisition patterns and heuristics (hotel dataset).", "labels": [], "entities": [{"text": "hotel dataset", "start_pos": 90, "end_pos": 103, "type": "DATASET", "confidence": 0.6645312756299973}]}, {"text": " Table 6: Intrinsic evaluation results with the five  different ranking measures.", "labels": [], "entities": [{"text": "Intrinsic", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9767603278160095}]}, {"text": " Table 7: Extrinsic evaluation results for varying  ranking methods (scenario A).", "labels": [], "entities": []}]}