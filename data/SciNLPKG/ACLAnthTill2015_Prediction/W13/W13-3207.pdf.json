{"title": [{"text": "Applicative structure in vector space models", "labels": [], "entities": [{"text": "Applicative", "start_pos": 0, "end_pos": 11, "type": "METRIC", "confidence": 0.9443170428276062}]}], "abstractContent": [{"text": "We introduce anew 50-dimensional embedding obtained by spectral clustering of a graph describing the conceptual structure of the lexicon.", "labels": [], "entities": []}, {"text": "We use the embedding directly to investigate sets of antonymic pairs, and indirectly to argue that function application in CVSMs requires not just vectors but two transformations (cor-responding to subject and object) as well.", "labels": [], "entities": []}], "introductionContent": [{"text": "Commutativity is a fundamental property of vector space models.", "labels": [], "entities": []}, {"text": "As soon as we encode king by k, queen by q, male by m, and female by f , if we expect k \u00b4 q \" m \u00b4 f , as suggested in, we will, by commutativity, also expect k \u00b4 m \" q \u00b4 f 'ruler, gender unspecified'.", "labels": [], "entities": []}, {"text": "When the meaning decomposition involves function application, commutativity no longer makes sense: consider Victoria as qmEngland and Victor as kmItaly.", "labels": [], "entities": []}, {"text": "If the function application operator m is simply another vector to be added to the representation, the same logic would yield that Italy is the male counterpart of female England.", "labels": [], "entities": []}, {"text": "To make matters worse, performing the same operations on Albert, kmEngland and Elena, qmItaly would yield that Italy is the female counterpart of male England.", "labels": [], "entities": [{"text": "kmEngland", "start_pos": 65, "end_pos": 74, "type": "DATASET", "confidence": 0.8104161620140076}]}, {"text": "Section 2 offers a method to treat antonymy in continuous vector space models (CVSMs).", "labels": [], "entities": []}, {"text": "Section 3 describes anew embedding, 4lang, obtained by spectral clustering from the definitional framework of the Longman Dictionary of Contemporary English, and Section 4 shows how to solve the problem outlined above by treating m and n not as a vectors but as transformations.", "labels": [], "entities": [{"text": "Longman Dictionary of Contemporary English", "start_pos": 114, "end_pos": 156, "type": "DATASET", "confidence": 0.9331601023674011}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 2: Error of approximating real antonymic pairs (Err), mean and standard deviation (m, \u03c3) of error  with 100 random pairings, and the ratio r \" |Err\u00b4m|", "labels": [], "entities": [{"text": "Error", "start_pos": 10, "end_pos": 15, "type": "METRIC", "confidence": 0.9725382328033447}, {"text": "standard deviation (m, \u03c3) of error", "start_pos": 70, "end_pos": 104, "type": "METRIC", "confidence": 0.8375579979684618}, {"text": "Err\u00b4m", "start_pos": 151, "end_pos": 156, "type": "METRIC", "confidence": 0.9185063540935516}]}, {"text": " Table 4: The results on 4lang", "labels": [], "entities": [{"text": "4lang", "start_pos": 25, "end_pos": 30, "type": "DATASET", "confidence": 0.6953843832015991}]}, {"text": " Table 5: Correlations between judgments based on  different embeddings", "labels": [], "entities": []}]}