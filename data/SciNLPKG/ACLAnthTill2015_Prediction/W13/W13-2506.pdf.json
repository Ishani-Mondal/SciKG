{"title": [{"text": "A modular open-source focused crawler for mining monolingual and bilingual corpora from the web", "labels": [], "entities": []}], "abstractContent": [{"text": "This paper discusses a modular and open-source focused crawler (ILSP-FC) for the automatic acquisition of domain-specific monolingual and bilingual corpora from the Web.", "labels": [], "entities": [{"text": "automatic acquisition of domain-specific monolingual and bilingual corpora", "start_pos": 81, "end_pos": 155, "type": "TASK", "confidence": 0.7072893343865871}]}, {"text": "Besides describing the main modules integrated in the crawler (dealing with page fetching, normalization, cleaning , text classification, de-duplication and document pair detection), we evaluate several of the system functionalities in an experiment for the acquisition of pairs of parallel documents in German and Italian for the \"Health & Safety at work\" domain.", "labels": [], "entities": [{"text": "page fetching", "start_pos": 76, "end_pos": 89, "type": "TASK", "confidence": 0.7245128899812698}, {"text": "text classification", "start_pos": 117, "end_pos": 136, "type": "TASK", "confidence": 0.7782778739929199}, {"text": "document pair detection", "start_pos": 157, "end_pos": 180, "type": "TASK", "confidence": 0.6192547182242075}]}], "introductionContent": [], "datasetContent": [{"text": "In order to assess the quality of the resources that ILSP-FC can produce, we evaluated it in a task of acquiring pairs of parallel documents in German and Italian for the \"Health & Safety at work\" (Arbeitsschutz/Sicurezza sul lavoro) domain.", "labels": [], "entities": []}, {"text": "We assume that this task is relatively difficult, i.e. that the number of documents in this domain and pair of languages is relatively small in the web.", "labels": [], "entities": []}, {"text": "Overall, our system delivered 807 document pairs for H&S, containing 1.40 and 1.21 million tokens for IT and DE, respectively.", "labels": [], "entities": []}, {"text": "Numbers refer to tokens in the main content of the acquired web pages, i.e. to tokens in paragraphs without the attribute crawlinfo (see Subsection 3.7).", "labels": [], "entities": []}, {"text": "A sample of the acquired corpora were evaluated against a set of criteria discussed in the following subsections.", "labels": [], "entities": []}, {"text": "We randomly selected 103 document pairs for manual inspection.", "labels": [], "entities": []}, {"text": "The sample size was calculated according to a 95% confidence level and an at most 10% confidence interval.", "labels": [], "entities": []}, {"text": "We use the Java Wikipedia Library () to convert each snapshot into a database that allows structured access to several aspects of categories, articles, sections etc.", "labels": [], "entities": [{"text": "Java Wikipedia Library", "start_pos": 11, "end_pos": 33, "type": "DATASET", "confidence": 0.7167681952317556}]}], "tableCaptions": []}