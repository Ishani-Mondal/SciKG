{"title": [{"text": "Extracting and Aggregating False Information from Microblogs", "labels": [], "entities": [{"text": "Extracting and Aggregating False Information", "start_pos": 0, "end_pos": 44, "type": "TASK", "confidence": 0.8131474852561951}, {"text": "Microblogs", "start_pos": 50, "end_pos": 60, "type": "DATASET", "confidence": 0.6420217156410217}]}], "abstractContent": [{"text": "During the 2011 East Japan Earthquake and Tsunami Disaster, we had found a number of false information spread on Twitter, e.g., \"The Cosmo Oil explosion causes toxic rain.\"", "labels": [], "entities": [{"text": "East Japan Earthquake and Tsunami Disaster", "start_pos": 16, "end_pos": 58, "type": "TASK", "confidence": 0.567485123872757}, {"text": "Cosmo Oil explosion", "start_pos": 133, "end_pos": 152, "type": "DATASET", "confidence": 0.802981972694397}]}, {"text": "This paper extracts pieces of false information exhaustively from all the tweets within one week after the earthquake.", "labels": [], "entities": []}, {"text": "Designing a set of linguistic patterns that correct false information, this paper proposes a method for detecting false information.", "labels": [], "entities": [{"text": "detecting false information", "start_pos": 104, "end_pos": 131, "type": "TASK", "confidence": 0.8318338394165039}]}, {"text": "More specifically, the method extracts text passages that match to the correction patterns, clusters the passages into topics of false information, and selects, for each topic, a passage explaining the false information the most suitably.", "labels": [], "entities": []}, {"text": "In the experiment, we report the performance of the proposed method on the data set extracted manually from Web sites that are specialized in collecting false information .", "labels": [], "entities": []}], "introductionContent": [{"text": "In the aftermath of the Tohoku Earthquake (also known as the Great East Japan Earthquake) in March 2011, social media, such as the Twitter social networking and microblogging service, served as highly active and beneficial sources of information.", "labels": [], "entities": [{"text": "Tohoku Earthquake (also known as the Great East Japan Earthquake", "start_pos": 24, "end_pos": 88, "type": "DATASET", "confidence": 0.6985291838645935}]}, {"text": "Among Internet users, 18.3% referred to social media as information sources, 18.6% referred to Internet newspapers, and 23.1% referred to national and regional government websites (Nomura Research Institute, 2011).", "labels": [], "entities": [{"text": "Nomura Research Institute, 2011)", "start_pos": 181, "end_pos": 213, "type": "DATASET", "confidence": 0.900564710299174}]}, {"text": "This indicates that social media rivaled the other two in influence.", "labels": [], "entities": []}, {"text": "It has also been noted that the Internet and social media has accelerated the dissemination of disinformation and other types of misinformation, e.g., \"Toxic rain will follow the explosion at the Cosmo Oil petrochemical complex\".", "labels": [], "entities": [{"text": "Cosmo Oil petrochemical complex", "start_pos": 196, "end_pos": 227, "type": "DATASET", "confidence": 0.8433246612548828}]}, {"text": "Misinformation such as this regarding safety and danger spread quickly in the aftermath of the Tohoku Earthquake and the related accident at the Fukushima Dai-Ichi Nuclear Power Plant, which threatened the lives and welfare of numerous people.", "labels": [], "entities": [{"text": "Tohoku Earthquake", "start_pos": 95, "end_pos": 112, "type": "DATASET", "confidence": 0.9668596684932709}, {"text": "Fukushima Dai-Ichi Nuclear Power Plant", "start_pos": 145, "end_pos": 183, "type": "DATASET", "confidence": 0.8737392902374268}]}, {"text": "Other themes of the misinformation included the admonition, \"Drink Isodine (povidone iodine) to protect your thyroid from radiation\".", "labels": [], "entities": []}, {"text": "One tweet consolidation site dedicated to collecting/correcting information on the Tohoku Earthquake 1 found that during the month of January 2012, even ten months after the event, more than ten pieces of misinformation related to the earthquake were posted.", "labels": [], "entities": [{"text": "collecting/correcting information", "start_pos": 42, "end_pos": 75, "type": "TASK", "confidence": 0.700346902012825}, {"text": "Tohoku Earthquake 1", "start_pos": 83, "end_pos": 102, "type": "DATASET", "confidence": 0.7905041376749674}]}, {"text": "This indicates a strong need for misinformation alerts in normal times as well as in times of disaster.", "labels": [], "entities": []}, {"text": "In this study, we aim at automatic collection of misinformation disseminated on Twitter.", "labels": [], "entities": [{"text": "automatic collection of misinformation disseminated on Twitter", "start_pos": 25, "end_pos": 87, "type": "TASK", "confidence": 0.73191899061203}]}, {"text": "More concretely, we focus on corrective patterns (CPs), such as It is incorrect that ..., which are commonly used to corrector refute misinformation, and propose a method incorporating such CPs into a system for automatic collection of misinformation.", "labels": [], "entities": [{"text": "corrector refute misinformation", "start_pos": 117, "end_pos": 148, "type": "TASK", "confidence": 0.7653440038363138}, {"text": "automatic collection of misinformation", "start_pos": 212, "end_pos": 250, "type": "TASK", "confidence": 0.6892795562744141}]}, {"text": "We then describe the experimental application of this method to tweets posted during the week following the Tohoku Earthquake.", "labels": [], "entities": [{"text": "Tohoku Earthquake", "start_pos": 108, "end_pos": 125, "type": "DATASET", "confidence": 0.9756126701831818}]}, {"text": "The results of this experiment showed that our method could detect approximately half of the 60 misinformative tweets identified by the existing misinformation consolidation sites, as well as 22 other misinformative tweets that had not been recorded on those sites.", "labels": [], "entities": [{"text": "misinformation consolidation", "start_pos": 145, "end_pos": 173, "type": "TASK", "confidence": 0.6985447406768799}]}], "datasetContent": [{"text": "For misinformation acquisition by the proposed method, it is essential to identify CPs that can effectively represent the misinformation.", "labels": [], "entities": [{"text": "misinformation acquisition", "start_pos": 4, "end_pos": 30, "type": "TASK", "confidence": 0.9052068889141083}]}, {"text": "Our first experiment was to evaluate the performance of our CPs.", "labels": [], "entities": []}, {"text": "We assessed the misinformation extracted by the proposed method by manually examining each instance to determine whether it was equivalent in content to any of the 60 gold instances from the four consolidation websites.", "labels": [], "entities": []}, {"text": "For some of the misinformation extracted by the proposed method, no similar instances were found in the gold set.", "labels": [], "entities": [{"text": "gold set", "start_pos": 104, "end_pos": 112, "type": "DATASET", "confidence": 0.8078358471393585}]}, {"text": "In those cases, we manually investigated the information with Web search engines to determine whether it actually was a case of misinformation.", "labels": [], "entities": []}, {"text": "Additionally, as the objective in the present study is a comprehensive extraction of misinformation, in cases where the content two or more instances of extracted misinformation were deemed to be essentially the same, we counted them as one correct instance of extraction.", "labels": [], "entities": []}, {"text": "Ultimately, the accuracy and recall in this investigation were determined using various values of N, which is the predetermined number of information instances output in order of decreasing score, in the proposed method.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 16, "end_pos": 24, "type": "METRIC", "confidence": 0.9994626641273499}, {"text": "recall", "start_pos": 29, "end_pos": 35, "type": "METRIC", "confidence": 0.9992344379425049}]}, {"text": "shows the results of the evaluation.", "labels": [], "entities": []}, {"text": "With N as 100, approximately 30% of the information instances extracted by the proposed method were found to be present in the gold set.", "labels": [], "entities": []}, {"text": "In addition, approximately 20% of the extracted instances were found to be actual instances of information, and thus correct, even though they were not present in the gold set.", "labels": [], "entities": []}, {"text": "Therefore, it can be said that the proposed method extracted misinformation with a precision of approximately 50%.", "labels": [], "entities": [{"text": "precision", "start_pos": 83, "end_pos": 92, "type": "METRIC", "confidence": 0.9980995059013367}]}, {"text": "Among the incorrect answers, approximately half involved redundant expressions of essentially the same misinformation phrased differently.", "labels": [], "entities": []}, {"text": "In summary, approximately 70% of the misinformation extracted by the proposed method represented a correct answer.", "labels": [], "entities": []}, {"text": "Investigation of the causes of the inaccuracy in output represented by the 48 incorrect answers present among the top 100 extracted misinformation instances showed that they could be classified into six types.", "labels": [], "entities": []}, {"text": "These are listed in, together with the number of incorrect answers attributable to each type.", "labels": [], "entities": []}, {"text": "Types (a) to (d) involve instances that were easily judged as errors, but types (e) and (f) involve instances that would be difficult for humans to characterize as either true information or misinformation.", "labels": [], "entities": []}, {"text": "The six cause types, and potential means of avoiding them, are as follows: (a) Errors in keyword extraction In some instances, unsuitable keywords such as \" (watchamacallit)\", \" (mess)\", and \"\" (a symbol used to mean \"a certain\", as in \"a certain person\") were extracted as misinformation keywords.", "labels": [], "entities": [{"text": "Errors", "start_pos": 79, "end_pos": 85, "type": "METRIC", "confidence": 0.9541064500808716}, {"text": "keyword extraction", "start_pos": 89, "end_pos": 107, "type": "TASK", "confidence": 0.7973374724388123}]}, {"text": "It maybe possible to eliminate this source of error in Step 2 by excluding extraction terms that are written entirely in hiragana (the Japanese cursive syllabary) and/or terms composed in large degree of symbols, such as \"\" above.", "labels": [], "entities": []}, {"text": "(b) Errors in clustering Among the top 100 instances of information extraction, some involved redundancies in the form of different phrases that have essentially the same content, as in the following examples, in which the terms in parentheses were theme terms used in the selection process.", "labels": [], "entities": [{"text": "information extraction", "start_pos": 56, "end_pos": 78, "type": "TASK", "confidence": 0.7766384482383728}]}, {"text": "LPG (Due to the explosion of the Cosmo Oil Chiba Refinery LPG tank in Ichihara City, residents of Chiba Prefecture and its neighboring regions will be subjected to toxic rain.", "labels": [], "entities": [{"text": "Cosmo Oil Chiba Refinery LPG tank", "start_pos": 33, "end_pos": 66, "type": "DATASET", "confidence": 0.7524417042732239}]}, {"text": "(Cosmo Oil Chiba Refinery) Due to the Chiba Prefecture petrochemical complex explosion, the substances adversely affecting human health will mix in the air and fall as acidic rain.", "labels": [], "entities": [{"text": "Chiba Prefecture petrochemical complex explosion", "start_pos": 38, "end_pos": 86, "type": "DATASET", "confidence": 0.7434014558792115}]}, {"text": "(petrochemical complex explosion) Because these two instances of misinformation were not assigned to the same cluster in Step 3, they gave rise to apparent redundancy.", "labels": [], "entities": []}, {"text": "While the current method takes words that co-occur in corrected phrases as their features, it maybe possible to reduce this type of redundancy by adding surface information of the keywords themselves to the feature set.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 3: Causes of failure to extract misinforma- tion  Cause  #  (e) New correction pattern  3  (f) Evidence present in corrective tweet  4  (g) No corrective tweet  3  Total  10", "labels": [], "entities": [{"text": "correction pattern  3", "start_pos": 75, "end_pos": 96, "type": "METRIC", "confidence": 0.9561977982521057}]}, {"text": " Table 4: Accuracy and recall of extracted misin- formation", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9979606866836548}, {"text": "recall", "start_pos": 23, "end_pos": 29, "type": "METRIC", "confidence": 0.99875807762146}]}, {"text": " Table 5: Types of errors that lowered accuracy", "labels": [], "entities": [{"text": "accuracy", "start_pos": 39, "end_pos": 47, "type": "METRIC", "confidence": 0.9984044432640076}]}, {"text": " Table 6: Types of errors that lowered recall  Error type  #  %  (g) Errors in clustering 2  2  10.0  (h) Low ranking  18  90.0  Total  20 100.0", "labels": [], "entities": [{"text": "recall  Error type  #  %", "start_pos": 39, "end_pos": 63, "type": "METRIC", "confidence": 0.8883963346481323}, {"text": "Errors", "start_pos": 69, "end_pos": 75, "type": "METRIC", "confidence": 0.9344634413719177}]}]}