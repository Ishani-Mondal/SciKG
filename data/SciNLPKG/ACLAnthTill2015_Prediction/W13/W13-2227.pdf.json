{"title": [{"text": "The CNGL-DCU-Prompsit Translation Systems for WMT13", "labels": [], "entities": [{"text": "CNGL-DCU-Prompsit Translation", "start_pos": 4, "end_pos": 33, "type": "TASK", "confidence": 0.7495733797550201}, {"text": "WMT13", "start_pos": 46, "end_pos": 51, "type": "TASK", "confidence": 0.6433106064796448}]}], "abstractContent": [{"text": "This paper presents the experiments conducted by the Machine Translation group at DCU and Prompsit Language Engineering for the WMT13 translation task.", "labels": [], "entities": [{"text": "Machine Translation", "start_pos": 53, "end_pos": 72, "type": "TASK", "confidence": 0.8229531347751617}, {"text": "DCU", "start_pos": 82, "end_pos": 85, "type": "DATASET", "confidence": 0.9653583765029907}, {"text": "Prompsit Language Engineering", "start_pos": 90, "end_pos": 119, "type": "DATASET", "confidence": 0.8776196042696635}, {"text": "WMT13 translation task", "start_pos": 128, "end_pos": 150, "type": "TASK", "confidence": 0.9356840252876282}]}, {"text": "Three language pairs are considered: Spanish-English and French-English in both directions and German-English in that direction.", "labels": [], "entities": []}, {"text": "For the Spanish-English pair, the use of linguistic information to select parallel data is investigated.", "labels": [], "entities": []}, {"text": "For the French-English pair, the usefulness of the small in-domain parallel corpus is evaluated, compared to an out-of-domain parallel data sub-sampling method.", "labels": [], "entities": []}, {"text": "Finally, for the German-English system, we describe our work in addressing the long distance reordering problem and a system combination strategy.", "labels": [], "entities": []}], "introductionContent": [{"text": "This paper presents the experiments conducted by the Machine Translation group at DCU 1 and Prompsit Language Engineering 2 for the WMT13 translation task on three language pairs: SpanishEnglish, French-English and German-English.", "labels": [], "entities": [{"text": "Machine Translation", "start_pos": 53, "end_pos": 72, "type": "TASK", "confidence": 0.802232563495636}, {"text": "DCU", "start_pos": 82, "end_pos": 85, "type": "DATASET", "confidence": 0.9352507591247559}, {"text": "WMT13 translation task", "start_pos": 132, "end_pos": 154, "type": "TASK", "confidence": 0.8793232242266337}]}, {"text": "For these language pairs, the language and translation models are built using different approaches and datasets, thus presented in this paper in separate sections.", "labels": [], "entities": []}, {"text": "In Section 2, the systems built for the SpanishEnglish pair in both directions are described.", "labels": [], "entities": [{"text": "SpanishEnglish pair", "start_pos": 40, "end_pos": 59, "type": "DATASET", "confidence": 0.9507977664470673}]}, {"text": "We investigate the use of linguistic information to select parallel data.", "labels": [], "entities": []}, {"text": "In Section 3, we present the systems built for the French-English pair in both di-rections.", "labels": [], "entities": []}, {"text": "The usefulness of the small in-domain parallel corpus is evaluated, compared to an outof-domain parallel data sub-sampling method.", "labels": [], "entities": []}, {"text": "In Section 4, for the German-English system, aiming at exploring the long distance reordering problem, we first describe our efforts in a dependency treeto-string approach, before combining different hierarchical systems with a phrase-based system and show a significant improvement over three baseline systems.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Perplexities in data selection", "labels": [], "entities": [{"text": "data selection", "start_pos": 26, "end_pos": 40, "type": "TASK", "confidence": 0.7146970927715302}]}, {"text": " Table 2: Number of sentences and BLEU scores  obtained on the WMT12 test set for the different  systems on the EN-ES translation task.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 34, "end_pos": 38, "type": "METRIC", "confidence": 0.9984495639801025}, {"text": "WMT12 test set", "start_pos": 63, "end_pos": 77, "type": "DATASET", "confidence": 0.9615624944368998}, {"text": "EN-ES translation task", "start_pos": 112, "end_pos": 134, "type": "TASK", "confidence": 0.8350889484087626}]}, {"text": " Table 3: Number of n-grams (in millions) for the  in-domain and out-of-domain LMs in French and  English.", "labels": [], "entities": []}, {"text": " Table 5: BLEU and TER scores obtained by our  systems. BLEUdev is the score obtained on the  development set given by MERT, while BLEU,  BLEUcased and TER are obtained on the test set  given by the submission website.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9986168146133423}, {"text": "TER", "start_pos": 19, "end_pos": 22, "type": "METRIC", "confidence": 0.9925323128700256}, {"text": "BLEUdev", "start_pos": 56, "end_pos": 63, "type": "METRIC", "confidence": 0.99817955493927}, {"text": "MERT", "start_pos": 119, "end_pos": 123, "type": "DATASET", "confidence": 0.5129445195198059}, {"text": "BLEU", "start_pos": 131, "end_pos": 135, "type": "METRIC", "confidence": 0.9975208640098572}, {"text": "BLEUcased", "start_pos": 138, "end_pos": 147, "type": "METRIC", "confidence": 0.9938517808914185}, {"text": "TER", "start_pos": 152, "end_pos": 155, "type": "METRIC", "confidence": 0.9445382952690125}]}, {"text": " Table 6: BLEU scores obtained by our systems on  the development and test sets for the German to  English translation task.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9991747736930847}, {"text": "German to  English translation task", "start_pos": 88, "end_pos": 123, "type": "TASK", "confidence": 0.6085584282875061}]}]}