{"title": [{"text": "Using Unlabeled Dependency Parsing for Pre-reordering for Chinese-to-Japanese Statistical Machine Translation", "labels": [], "entities": [{"text": "Statistical Machine Translation", "start_pos": 78, "end_pos": 109, "type": "TASK", "confidence": 0.6819836298624674}]}], "abstractContent": [{"text": "Chinese and Japanese have a different sentence structure.", "labels": [], "entities": []}, {"text": "Reordering methods are effective, but need reliable parsers to extract the syntactic structure of the source sentences.", "labels": [], "entities": []}, {"text": "However, Chinese has a loose word order, and Chinese parsers that extract the phrase structure do not perform well.", "labels": [], "entities": []}, {"text": "We propose a framework where only POS tags and unlabeled dependency parse trees are necessary, and linguistic knowledge on structural difference can be encoded in the form of reordering rules.", "labels": [], "entities": []}, {"text": "We show significant improvements in translation quality of sentences from news domain , when compared to state-of-the-art reordering methods.", "labels": [], "entities": [{"text": "translation", "start_pos": 36, "end_pos": 47, "type": "TASK", "confidence": 0.9561805129051208}]}], "introductionContent": [{"text": "Translation between Chinese and Japanese languages gains interest as their economic and political relationship intensifies.", "labels": [], "entities": [{"text": "Translation between Chinese and Japanese languages", "start_pos": 0, "end_pos": 50, "type": "TASK", "confidence": 0.8853773474693298}]}, {"text": "Despite their linguistic influences, these languages have different syntactic structures and phrase-based statistical machine translation (SMT) systems do not perform well.", "labels": [], "entities": [{"text": "phrase-based statistical machine translation (SMT)", "start_pos": 93, "end_pos": 143, "type": "TASK", "confidence": 0.7260200807026455}]}, {"text": "Current word alignment models account for local differences in word order between bilingual sentences, but fail at capturing long distance word alignments.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 8, "end_pos": 22, "type": "TASK", "confidence": 0.7383374273777008}]}, {"text": "One of the main problems in the search of the best word alignment is the combinatorial explosion of word orders, but linguistically-motivated heuristics can help to guide the search.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 51, "end_pos": 65, "type": "TASK", "confidence": 0.7113581597805023}]}, {"text": "This work explores syntax-informed prereordering for Chinese; that is, we obtain syntactic structures of Chinese sentences, reorder the words to resemble the Japanese word order, and then translate the reordered sentences using a phrasebased SMT system.", "labels": [], "entities": []}, {"text": "However, Chinese parsers have difficulties in extracting reliable syntactic information, mainly because Chinese has a loose word order and few syntactic clues such as inflection and function words.", "labels": [], "entities": []}, {"text": "On one hand, parsers implementing head-driven phrase structure grammars infer a detailed constituent structure, and such a rich syntactic structure can be exploited to design well informed reordering methods.", "labels": [], "entities": []}, {"text": "However, inferring abundant syntactic information often implies introducing errors, and reordering methods that heavily rely on detailed information are sensitive to those parsing errors ().", "labels": [], "entities": []}, {"text": "On the other hand, dependency parsers are committed to the simpler task of finding dependency relations and dependency labels, which can also be useful to guide reordering (.", "labels": [], "entities": [{"text": "dependency parsers", "start_pos": 19, "end_pos": 37, "type": "TASK", "confidence": 0.8629891574382782}]}, {"text": "However, reordering methods that rely on those dependency labels will also be prone to errors, specially in the case of Chinese since it has a richer set of dependency labels when compared to other languages.", "labels": [], "entities": []}, {"text": "Since improving parsers for Chinese is challenging, we thus aim at reducing the influence of parsing errors in the reordering procedure.", "labels": [], "entities": []}, {"text": "We present a hybrid approach that boosts the performance of phrase-based SMT systems by pre-reordering the source language using unlabeled parse trees augmented with constituent information derived from Part-of-Speech tags.", "labels": [], "entities": [{"text": "SMT", "start_pos": 73, "end_pos": 76, "type": "TASK", "confidence": 0.8245399594306946}]}, {"text": "Specifically, we propose a framework to prereorder a Subject-Verb-Object (SVO) language, in order to improve its translation to a SubjectObject-Verb (SOV) language, where the only required syntactic information are POS tags and unlabeled dependency parse trees.", "labels": [], "entities": []}, {"text": "We test the performance of our pre-reordering method and compare it to state-of-the-art reordering methods in the news domain for Chinese.", "labels": [], "entities": []}, {"text": "In the next section, we describe similar work on pre-reordering methods for language pairs that in-volve either Chinese or Japanese, and explain how our method builds upon them.", "labels": [], "entities": []}, {"text": "From a linguistic perspective, we describe in section 3 our observations of reordering issues between Chinese and Japanese and detail how our framework solves those issues.", "labels": [], "entities": []}, {"text": "In section 4 we assess to what extent our pre-reordering method succeeds in reordering words in Chinese sentences to resemble the order of Japanese sentences, and measure its impact on translation quality.", "labels": [], "entities": []}, {"text": "The last section is dedicated to discuss our findings and point to future directions.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 3: Evaluation of translation quality of two  test sets when CWMT, News and the combination  of both corpora were used for training.", "labels": [], "entities": [{"text": "translation", "start_pos": 24, "end_pos": 35, "type": "TASK", "confidence": 0.9605568051338196}, {"text": "CWMT", "start_pos": 67, "end_pos": 71, "type": "DATASET", "confidence": 0.897496223449707}]}, {"text": " Table 2: Basic statistics of our corpora. News Devel. and News Test were used to tune and test the  systems trained with both training corpora. Data statistics were collected after tokenizing and filtering  out sentences longer than 64 tokens.", "labels": [], "entities": [{"text": "News Devel.", "start_pos": 43, "end_pos": 54, "type": "DATASET", "confidence": 0.9158884584903717}, {"text": "News Test", "start_pos": 59, "end_pos": 68, "type": "DATASET", "confidence": 0.80347740650177}]}]}