{"title": [{"text": "Subgraph-based Classification of Explicit and Implicit Discourse Relations", "labels": [], "entities": [{"text": "Subgraph-based Classification of Explicit and Implicit Discourse Relations", "start_pos": 0, "end_pos": 74, "type": "TASK", "confidence": 0.7745527625083923}]}], "abstractContent": [{"text": "Current approaches to recognizing discourse relations rely on a combination of shallow, surface-based features (e.g., bigrams, word pairs), and rather specialized hand-crafted features.", "labels": [], "entities": [{"text": "recognizing discourse relations", "start_pos": 22, "end_pos": 53, "type": "TASK", "confidence": 0.839359978834788}]}, {"text": "As away to avoid both the shallowness of word-based representations and the lack of coverage of specialized linguistic features, we use a graph-based representation of discourse segments, which allows fora more abstract (and hence generalizable) notion of syntactic (and partially of semantic) structure.", "labels": [], "entities": []}, {"text": "Empirical evaluation on a hand-annotated corpus of German discourse relations shows that our graph-based approach not only provides a suitable representation for the linguistic factors that are needed in disambiguating discourse relations, but also improves results over a strong state-of-the-art baseline by more accurately identifying Temporal, Comparison and Reporting discourse relations.", "labels": [], "entities": []}], "introductionContent": [{"text": "Discourse relations between textual spans capture essential structural and semantic/pragmatic aspects of text structure.", "labels": [], "entities": []}, {"text": "Besides anaphora and referential structure, discourse relations area key ingredient in understanding a text beyond single clauses or sentences.", "labels": [], "entities": []}, {"text": "The automatic recognition of discourse relations is therefore an important task; approaches to the solution of this problem range from heuristic approaches that use reliable indicators) to modern machine learning approaches such as that apply broad shallow features in cases without such indicators.", "labels": [], "entities": [{"text": "automatic recognition of discourse relations", "start_pos": 4, "end_pos": 48, "type": "TASK", "confidence": 0.737803292274475}]}, {"text": "Especially on implicit discourse relations, where no discourse connective could provide a reliable indication, broad, shallow features such as bigrams or word pairs conceivably lack the precision that would be needed to improve disambiguation results beyond a certain level.", "labels": [], "entities": [{"text": "precision", "start_pos": 186, "end_pos": 195, "type": "METRIC", "confidence": 0.9941754937171936}]}, {"text": "Conversely, hand-crafted linguistic features allow one to encode certain relevant aspects, but they have often limited coverage.", "labels": [], "entities": []}, {"text": "Encoding detailed linguistic information in a structured representation, as in the work presented here, allows us to bridge this divide and potentially find a golden middle between linguistic precision and broad applicability.", "labels": [], "entities": [{"text": "precision", "start_pos": 192, "end_pos": 201, "type": "METRIC", "confidence": 0.9697259068489075}]}, {"text": "We propose a graph-based representation of discourse segments as away to overcome both the shallowness of a word-based representation and the non-specificity or lack of coverage of specialized linguistic features.", "labels": [], "entities": []}, {"text": "In the rest of the paper, section 2 discusses the current state of the art in discourse relation classification.", "labels": [], "entities": [{"text": "discourse relation classification", "start_pos": 78, "end_pos": 111, "type": "TASK", "confidence": 0.7715157071749369}]}, {"text": "Section 3 introduces feature graphs as a general representation and learning mechanism, and section 4 provides an overview of the used corpus, as well as feature-based and graph-based representations for discourse relations.", "labels": [], "entities": []}, {"text": "Section 5 presents empirical evaluation results.", "labels": [], "entities": []}], "datasetContent": [{"text": "For both the 294 explicit nachdem relations and the 803 implicit discourse relations, we use a 10-fold cross-validation scheme where, successively, one tenth of the data is automatically labeled by a model from the remaining nine tenth of the data.", "labels": [], "entities": []}, {"text": "Multiple relation labels are predicted by using binary classifiers (one-vs-all reduction) and using confidence values to choose one or several labels among those that have the most confident positive classification.", "labels": [], "entities": []}, {"text": "In the case of multiple positive classifications (e.g., if Reporting, Temporal and Expansion all receive a positive classification), relations are only considered for the 'second' label if the most-confident label and the potential second label have been seen together in the training data (e.g. Contingency and Temporal can occur together, but Reporting will not be extended by a second relation labels).", "labels": [], "entities": []}, {"text": "Ina second step, the coarse grained relation label (or labels) is extended up to the finest taxonomy level (e.g., an initial coarse-grained Contingency label is extended to Contingency.Causal.Explanation).", "labels": [], "entities": []}, {"text": "In our experiments, we use SVMperf, an SVM implementation that is able to train classifiers optimized for performance on positive instances.", "labels": [], "entities": []}, {"text": "provide evaluation figures for different subsets of the presented features, using aggregate measures over relations both at the coarsest level (for implicit discourse relations, the five categories Contingency, Expansion, Temporal, Comparison, Reporting), and the finest level (which contains twenty-one relations in the case of implicit relations).", "labels": [], "entities": []}, {"text": "For each level of granularity, we can measure the quality of the classifier's predictions in terms of an average over relation tokens, giving partial credit for partially matching labelings (e.g., a system prediction of Narration or Narration+Comparison, instead of gold-standard Narration+Result).", "labels": [], "entities": []}, {"text": "This measure, the dice score, assigns partial credit fora relation token when system and/or gold standard contain multiple labels and both label sets overlap, calculated as 2|G\u2229S| |G|+|S| -an exact match would be scored as 1.0, whereas guessing a sub-or superset (e.g. only Result instead of Result+Narration) would give a contribution of 0.66 for that example, and overlapping predictions (Result+Comparison instead of Result+Narration) would get a partial credit of 0.5.", "labels": [], "entities": []}, {"text": "As an average over relation types, we can also calculate an average of the F-score overall relations, yielding the macro-averaged F-score (MAFS).", "labels": [], "entities": [{"text": "F-score", "start_pos": 75, "end_pos": 82, "type": "METRIC", "confidence": 0.9432876706123352}, {"text": "F-score (MAFS)", "start_pos": 130, "end_pos": 144, "type": "METRIC", "confidence": 0.8761117458343506}]}, {"text": "Shaded rows indicate variants using the graph representation.", "labels": [], "entities": []}, {"text": "Disambiguating nachdem For the disambiguation of the ambiguous temporal connective nachdem, we use a set of linguistic and shallow features to reproduce the results of Versley (2011), similar to that described in section 3, but with very few exceptions.", "labels": [], "entities": []}, {"text": "Looking at the aggregate measures, we see that the graph-based features in isolation already perform quite well, surpassing aversion with linguistic features, but no word pairs or CFG productions.", "labels": [], "entities": []}, {"text": "Adding subgraph features with appropriate feature selection to the complete system (including linguistic and shallow features) yields a further improvement over a relatively strong baseline.", "labels": [], "entities": []}, {"text": "Implicit relations presents both aggregate measures (Dice, macro-averaged F-measure) as well as scores for the most important coarse-grained relations.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 74, "end_pos": 83, "type": "METRIC", "confidence": 0.7599554657936096}]}, {"text": "We provide results for the full graph (grA), aversion with all features except information status (grB), and finally a minimal version that excludes all semantic features and lemmas (grC).", "labels": [], "entities": []}, {"text": "In general, both the linguistic features and the graph features perform much better than the shallow features (with the best single source of information being the complete graph), and also that a combination of linguistic and all shallow features (all-gr) suffers from In the second section of the table, the influence of different information sources is detailed.", "labels": [], "entities": []}, {"text": "We see that, despite the skewed distribution of relations, all information sources outperform the most-frequentsense baseline by themselves.", "labels": [], "entities": []}, {"text": "By providing a higher precision on Expansion relations, and generally better performance on Reporting relations, the graph-based representation performs better than any of the other information sources, and is the only information source to provide enough information for the identification of Comparison relations.", "labels": [], "entities": [{"text": "precision", "start_pos": 22, "end_pos": 31, "type": "METRIC", "confidence": 0.9979032278060913}, {"text": "Reporting relations", "start_pos": 92, "end_pos": 111, "type": "TASK", "confidence": 0.8791151642799377}]}, {"text": "The third group of rows, showing combinations of the linguistic features with the shallow information sources and with the graph representation, shows that, while the addition of specialized features to the shallow ones yields a general improvement, the graph-based representation still works best; for Temporal relations, we see that the noise brought in by the shallow features hinders their identification more than in the case of the graph-based representation.", "labels": [], "entities": [{"text": "Temporal relations", "start_pos": 303, "end_pos": 321, "type": "TASK", "confidence": 0.9665485322475433}]}, {"text": "The last part of table 4 provides evaluation results fora system using the complete set of information sources (all), for systems leaving out one of the shallow information sources (all-bi, all-wp, all-pr), and a system using only linguistic and shallow features but no graph information (all-gr).", "labels": [], "entities": []}, {"text": "We see that, in general, the identification of rare relations such as Temporal, Comparison, and Reporting is helped by the graph representation (the full system obtains the best MAFS scores of 0.438 and 0.208, for coarse-and fine-grained relations, respectively, against 0.388 and 0.145 for the system without graph information).", "labels": [], "entities": []}, {"text": "System variants with graph information also obtain higher coarse-grained dice scores (0.564-0.571) than the version without graph information (0.551 for all-gr).", "labels": [], "entities": []}, {"text": "In the same vein, we see that the parsimonious grC graph gives the best combination result (allC-pr, including linguistic, word pair, unigram/bigram, and graph features) despite the more informative grA giving the best results in isolation.: Implicit discourse relations: specialized linguistic features (ling), word/lemma/pos bigrams (bi), word pairs (wp), CFG productions (pr), and different methods for constructing graphs (grA, grB and grC).", "labels": [], "entities": []}, {"text": "Shaded rows indicate variants using the graph representation.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Frequencies of discourse relations in the corpus of", "labels": [], "entities": []}, {"text": " Table 2: Frequencies of discourse relations in the nachdem data from Simon et al. (2011)", "labels": [], "entities": []}, {"text": " Table 3: Results for disambiguation of nachdem. Rows include the specialized linguistic features of  Versley", "labels": [], "entities": [{"text": "Versley", "start_pos": 102, "end_pos": 109, "type": "DATASET", "confidence": 0.7615429162979126}]}, {"text": " Table 4: Implicit discourse relations: specialized linguistic features (ling), word/lemma/pos bigrams  (bi), word pairs (wp), CFG productions (pr), and different methods for constructing graphs (grA, grB  and grC). Shaded rows indicate variants using the graph representation.", "labels": [], "entities": []}]}