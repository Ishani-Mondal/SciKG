{"title": [{"text": "Exploiting ontology lexica for generating natural language texts from RDF data", "labels": [], "entities": []}], "abstractContent": [{"text": "The increasing amount of machine-readable data available in the context of the Semantic Web creates a need for methods that transform such data into human-comprehensible text.", "labels": [], "entities": []}, {"text": "In this paper we develop and evaluate a Natural Language Generation (NLG) system that converts RDF data into natural language text based on an on-tology and an associated ontology lexicon.", "labels": [], "entities": [{"text": "Natural Language Generation (NLG)", "start_pos": 40, "end_pos": 73, "type": "TASK", "confidence": 0.8017377456029257}]}, {"text": "While it follows a classical NLG pipeline, it diverges from most current NLG systems in that it exploits an ontology lexicon in order to capture context-specific lexicalisations of ontol-ogy concepts, and combines the use of such a lexicon with the choice of lexical items and syntactic structures based on statistical information extracted from a domain-specific corpus.", "labels": [], "entities": []}, {"text": "We apply the developed approach to the cooking domain , providing both an ontology and an ontology lexicon in lemon format.", "labels": [], "entities": []}, {"text": "Finally, we evaluate fluency and adequacy of the generated recipes with respect to two target audiences: cooking novices and advanced cooks.", "labels": [], "entities": []}], "introductionContent": [{"text": "The goal of the Semantic Web is to enrich the current web by a layer of machinereadable and machine-understandable content (Berners-).", "labels": [], "entities": []}, {"text": "In recent years, the growth of data published on the web according to Semantic Web formalisms and data models (e.g. RDF(S) and OWL) has been exponential, leading to more than 30 billion RDF triples 1 available as part of the Linked Open Data cloud, which contains a wide range of factual knowledge that is very interesting to many applications and for many purposes.", "labels": [], "entities": []}, {"text": "However, due to the fact that it is available as RDF, it is not directly accessible to humans.", "labels": [], "entities": []}, {"text": "Thus, natural language generation from RDF data has recently become an important topic for research, leading to the development of various systems generating natural language text from knowledge bases as well as corresponding shared tasks (.", "labels": [], "entities": [{"text": "natural language generation from RDF", "start_pos": 6, "end_pos": 42, "type": "TASK", "confidence": 0.7125320374965668}]}, {"text": "Natural language generation (NLG) from knowledge bases requires knowledge about how the concepts in the underlying ontologyindividuals, classes and relations-are realised linguistically.", "labels": [], "entities": [{"text": "Natural language generation (NLG)", "start_pos": 0, "end_pos": 33, "type": "TASK", "confidence": 0.7815062701702118}]}, {"text": "For this purpose, lemon, a lexicon model for ontologies, has been developed).", "labels": [], "entities": []}, {"text": "One of the use cases of lemon is to support natural language generation systems that take as input a knowledge base structured with respect to a given ontology.", "labels": [], "entities": [{"text": "natural language generation", "start_pos": 44, "end_pos": 71, "type": "TASK", "confidence": 0.7197142044703165}]}, {"text": "In this paper, we present a system that relies on lemon lexica for selecting suitable lexicalisations of a given concept, showing how ontology lexica can be exploited in a standard generation architecture.", "labels": [], "entities": []}, {"text": "We apply our system to the domain of cooking, generating natural language texts for recipes modeled as RDF data based on a cooking ontology.", "labels": [], "entities": []}, {"text": "Our system relies on a large text corpus of cooking recipes that is used to extract frequency information for single terms and n-grams as well as syntactic trees, which are then used in the selection process for lexicalisation and surface realisation.", "labels": [], "entities": [{"text": "surface realisation", "start_pos": 231, "end_pos": 250, "type": "TASK", "confidence": 0.733645036816597}]}, {"text": "Additionally, we provide a manually created lemon lexicon for the underlying ontology that was enriched with inflectional variants derived from Wiktionary.", "labels": [], "entities": []}, {"text": "The lexicon also includes contextual information regarding which lexicalisations to prefer depending on the target group, and thereby allows our system to personalize the output to different groups of users.", "labels": [], "entities": []}, {"text": "We demonstrate the flexibility of our system by showing that it can be easily tuned to generate recipe descriptions both for novices and for advanced cooks and that this adaptation is clearly recognized by users.", "labels": [], "entities": []}, {"text": "The remainder of this paper is structured as follows.", "labels": [], "entities": []}, {"text": "In Section 2 we describe the resources we created and employed, in particular a domain ontology, a corresponding ontology lexicon enriching ontology concepts with lexical information, and a parsed domain corpus.", "labels": [], "entities": []}, {"text": "In Section 3 we describe the architecture of the system, in particular the use of a corpus for selecting appropriate syntactic structures and surface realisations of concepts.", "labels": [], "entities": []}, {"text": "Then we present the results of an extensive user study in Section 4, compare our approach to related work in Section 5 and finally give an outlook on future work in Section 6.", "labels": [], "entities": []}], "datasetContent": [{"text": "The system was evaluated in an online study with 93 participants-mainly students recruited via email or Facebook.", "labels": [], "entities": []}, {"text": "The majority of the participants (70%) were between 18 and 34 years old; the native tongue of almost all participants (95%) was German.", "labels": [], "entities": []}, {"text": "About half of the participants regarded themselves as novices, while the other half regarded themselves as advanced cooks.", "labels": [], "entities": []}, {"text": "For each participant, 20 recipes were randomly selected and split into two groups.", "labels": [], "entities": []}, {"text": "For ten recipes, test subjects were asked to rate the fluency and adequacy of the automatically generated text along the categories very good, good, sufficient and insufficient.", "labels": [], "entities": []}, {"text": "The other ten recipes were used to compare the effect of parameters of the generation system and thus were presented in two different versions, varying the sentence length and complexity as well as the level of proficiency.", "labels": [], "entities": []}, {"text": "Participants were asked to rate texts as being appropriate for novices or for advanced cooks.", "labels": [], "entities": []}, {"text": "The parameters that were varied in our experimental setting are the following: \u2022 \u03bb context : The context of the used terms, in particular novice or advanced.", "labels": [], "entities": []}, {"text": "\u2022 \u03bb pronoun : Amount of proper nouns, where a high value prefers pronouns over proper nouns, while a low value generates only proper nouns.", "labels": [], "entities": []}, {"text": "\u2022 \u03bb variance : Amount of repetitions, where low values lead to always using the same term, whereas high values lead to fewer repetitions.", "labels": [], "entities": [{"text": "\u03bb variance", "start_pos": 2, "end_pos": 12, "type": "METRIC", "confidence": 0.875716358423233}, {"text": "repetitions", "start_pos": 25, "end_pos": 36, "type": "METRIC", "confidence": 0.5904168486595154}]}, {"text": "\u2022 \u03bb length : Length of the created sentences, where a low value creates short sentences, and high values merge short sentences into longer ones.", "labels": [], "entities": [{"text": "Length", "start_pos": 13, "end_pos": 19, "type": "METRIC", "confidence": 0.9818466305732727}]}, {"text": "The values of these parameters that were used in the different configurations are summarized in.", "labels": [], "entities": []}, {"text": "The parameter \u03bb pronoun is not varied but set to a fixed value that yields a satisfactory generation of referring expressions, as texts with smaller or higher values tend to sound artificial or incomprehensible.", "labels": [], "entities": []}, {"text": "Fluency and adequacy of the generated texts Each participant was asked to rate fluency and adequacy often automatically generated texts.", "labels": [], "entities": []}, {"text": "The results are given in.", "labels": [], "entities": []}, {"text": "The fluency of the majority of generated texts (85.8%) were perceived as very good or good, whereas only 1% of the generated texts were rated as insufficient.", "labels": [], "entities": []}, {"text": "Similarly, the adequacy of 92.5% of the generated texts were rated as very good or good, and again only 1% of the generated texts were rated as insufficient.", "labels": [], "entities": [{"text": "adequacy", "start_pos": 15, "end_pos": 23, "type": "METRIC", "confidence": 0.9668234586715698}]}, {"text": "There was no significant difference between judgments of novices and experts; neither did the category of the recipe (main or side dish, dessert, etc.) have any influence.", "labels": [], "entities": []}, {"text": "Overall, these results clearly show that the quality of the texts generated by our system is high.", "labels": [], "entities": []}, {"text": "Error analysis The most frequent errors found in the generated texts can be grouped into the following categories: \u2022 Content (39.4%): Errors in document planning (e.g. due to the ontology missing details about tools, such as for cutting cookies, or the recipe missing information about the amount of ingredients) or aggregation (e.g. sentences with highly related content were not aggregated), as well as sentence repetitions.", "labels": [], "entities": [{"text": "sentence repetitions", "start_pos": 405, "end_pos": 425, "type": "TASK", "confidence": 0.712477833032608}]}, {"text": "\u2022 Language (29.4%): Errors in the referring expression generation or lexicalisation steps (e.g. wrong use of function words like as well) and grammar errors (e.g. wrong use of definite or indefinite determiners).", "labels": [], "entities": [{"text": "Errors", "start_pos": 20, "end_pos": 26, "type": "METRIC", "confidence": 0.9634876251220703}, {"text": "referring expression generation", "start_pos": 34, "end_pos": 65, "type": "TASK", "confidence": 0.6586540341377258}]}, {"text": "\u2022 Other (31.3%): Some users specified that they would prefer another ordering of the involved steps, or that they lack knowledge of particular terms.", "labels": [], "entities": []}, {"text": "Also short sentences with exclamation marks are often perceived as impolite.", "labels": [], "entities": []}, {"text": "Influence of parameter settings We setup the following hypotheses, validating them by means of a \u03c7 2 -test by comparing answers across two conditions corresponding to different parameter settings.", "labels": [], "entities": []}, {"text": "We regarded a p-value of 0.05 as sufficient to reject the corresponding null hypothesis.", "labels": [], "entities": []}, {"text": "H1 Users prefer longer sentences: Rejecting the null hypothesis that users rate texts with longer sentences and texts with shorter sentences in the same way (pvalue: 3 * 10 \u22125 ).", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1. The parameter \u03bb pronoun is  not varied but set to a fixed value that yields  a satisfactory generation of referring expres- sions, as texts with smaller or higher values  tend to sound artificial or incomprehensible.", "labels": [], "entities": []}, {"text": " Table 1: The used parameter sets", "labels": [], "entities": []}]}