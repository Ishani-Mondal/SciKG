{"title": [{"text": "Supervised Morphological Segmentation in a Low-Resource Learning Setting using Conditional Random Fields", "labels": [], "entities": [{"text": "Morphological Segmentation", "start_pos": 11, "end_pos": 37, "type": "TASK", "confidence": 0.806481808423996}]}], "abstractContent": [{"text": "We discuss data-driven morphological segmentation, in which word forms are segmented into morphs, the surface forms of morphemes.", "labels": [], "entities": [{"text": "data-driven morphological segmentation", "start_pos": 11, "end_pos": 49, "type": "TASK", "confidence": 0.7614155610402426}]}, {"text": "Our focus is on a low-resource learning setting, in which only a small amount of annotated word forms are available for model training, while unan-notated word forms are available in abundance.", "labels": [], "entities": []}, {"text": "The current state-of-art methods 1) exploit both the annotated and unan-notated data in a semi-supervised manner , and 2) learn morph lexicons and subsequently uncover segmentations by generating the most likely morph sequences.", "labels": [], "entities": []}, {"text": "In contrast, we discuss 1) employing only the annotated data in a supervised manner , while entirely ignoring the unanno-tated data, and 2) directly learning to predict morph boundaries given their local sub-string contexts instead of learning the morph lexicons.", "labels": [], "entities": []}, {"text": "Specifically, we employ conditional random fields, a popular discriminative log-linear model for seg-mentation.", "labels": [], "entities": []}, {"text": "We present experiments on two data sets comprising five diverse languages.", "labels": [], "entities": []}, {"text": "We show that the fully supervised boundary prediction approach out-performs the state-of-art semi-supervised morph lexicon approaches on all languages when using the same annotated data sets.", "labels": [], "entities": [{"text": "boundary prediction", "start_pos": 34, "end_pos": 53, "type": "TASK", "confidence": 0.756320595741272}]}], "introductionContent": [{"text": "Modern natural language processing (NLP) applications, such as speech recognition, information retrieval and machine translation, perform their tasks using statistical language models.", "labels": [], "entities": [{"text": "natural language processing (NLP)", "start_pos": 7, "end_pos": 40, "type": "TASK", "confidence": 0.8043343722820282}, {"text": "speech recognition", "start_pos": 63, "end_pos": 81, "type": "TASK", "confidence": 0.7461273670196533}, {"text": "information retrieval", "start_pos": 83, "end_pos": 104, "type": "TASK", "confidence": 0.7785070836544037}, {"text": "machine translation", "start_pos": 109, "end_pos": 128, "type": "TASK", "confidence": 0.762484073638916}]}, {"text": "For morphologically rich languages, estimation of the language models is problematic due to the high number of compound words and inflected word forms.", "labels": [], "entities": [{"text": "estimation", "start_pos": 36, "end_pos": 46, "type": "TASK", "confidence": 0.947647750377655}]}, {"text": "A successful means of alleviating this data sparsity problem is to segment words into meaning-bearing sub-word units ().", "labels": [], "entities": []}, {"text": "In linguistics, the smallest meaning-bearing units of a language are called morphemes and their surface forms morphs.", "labels": [], "entities": []}, {"text": "Thus, morphs are natural targets for the segmentation.", "labels": [], "entities": []}, {"text": "For most languages, existing resources contain large amounts of raw unannotated text data, only small amounts of manually prepared annotated training data, and no freely available rule-based morphological analyzers.", "labels": [], "entities": []}, {"text": "The focus of our work is on performing morphological segmentation in this low-resource scenario.", "labels": [], "entities": [{"text": "morphological segmentation", "start_pos": 39, "end_pos": 65, "type": "TASK", "confidence": 0.8237620890140533}]}, {"text": "Given this setting, the current state-of-art methods approach the problem by learning morph lexicons from both annotated and unannotated data using semi-supervised machine learning techniques ().", "labels": [], "entities": []}, {"text": "Subsequent to model training, the methods uncover morph boundaries for new word forms by generating their most likely morph sequences according to the morph lexicons.", "labels": [], "entities": []}, {"text": "In contrast to learning morph lexicons (, we study morphological segmentation by learning to directly predict morph boundaries based on their local substring contexts.", "labels": [], "entities": []}, {"text": "Specifically, we apply the linearchain conditional random field model, a popular discriminative log-linear model for segmentation presented originally by.", "labels": [], "entities": []}, {"text": "Importantly, we learn the segmentation model from solely the small annotated data in a supervised manner, while entirely ignoring the unannotated data.", "labels": [], "entities": [{"text": "segmentation", "start_pos": 26, "end_pos": 38, "type": "TASK", "confidence": 0.974582314491272}]}, {"text": "Despite not using the unannotated data, we show that by discriminatively learning to predict the morph boundaries, we are able to outperform the previous state-of-art.", "labels": [], "entities": []}, {"text": "We present experiments on Arabic and Hebrew using the data set presented originally by, and on English, Finnish and Turkish using the Morpho Challenge 2009/2010 data sets (.", "labels": [], "entities": [{"text": "Morpho Challenge 2009/2010 data sets", "start_pos": 134, "end_pos": 170, "type": "DATASET", "confidence": 0.9326378873416356}]}, {"text": "The results are compared against two stateof-art techniques, namely the log-linear modeling approach presented by and the semi-supervised Morfessor algorithm.", "labels": [], "entities": []}, {"text": "We show that when employing the same small amount of annotated training data, the CRF-based boundary prediction approach outperforms these reference methods on all languages.", "labels": [], "entities": [{"text": "CRF-based boundary prediction", "start_pos": 82, "end_pos": 111, "type": "TASK", "confidence": 0.7041985591252645}]}, {"text": "Additionally, since the CRF model learns from solely the small annotated data set, its training is computationally much less demanding compared to the semi-supervised methods, which utilize both the annotated and the unannotated data sets.", "labels": [], "entities": []}, {"text": "The rest of the paper is organized as follows.", "labels": [], "entities": []}, {"text": "In Section 2, we discuss related work in morphological segmentation and methodology.", "labels": [], "entities": [{"text": "morphological segmentation", "start_pos": 41, "end_pos": 67, "type": "TASK", "confidence": 0.8752910196781158}]}, {"text": "In Section 3, we describe our segmentation method.", "labels": [], "entities": [{"text": "segmentation", "start_pos": 30, "end_pos": 42, "type": "TASK", "confidence": 0.9844248294830322}]}, {"text": "Our experimental setup is described in Section 4, and the obtained results are presented in Section 5.", "labels": [], "entities": []}, {"text": "In Section 6, we discuss the method and the results.", "labels": [], "entities": []}, {"text": "Finally, we present conclusions on the work in Section 7.", "labels": [], "entities": []}], "datasetContent": [{"text": "This section describes the data sets, evaluation metrics, reference methods, and other details concerning the evaluation of the methods.", "labels": [], "entities": []}, {"text": "The word segmentations are evaluated by comparison with linguistic morphs using precision, recall, and F-measure.", "labels": [], "entities": [{"text": "word segmentations", "start_pos": 4, "end_pos": 22, "type": "TASK", "confidence": 0.7104665338993073}, {"text": "precision", "start_pos": 80, "end_pos": 89, "type": "METRIC", "confidence": 0.9995228052139282}, {"text": "recall", "start_pos": 91, "end_pos": 97, "type": "METRIC", "confidence": 0.9987143278121948}, {"text": "F-measure", "start_pos": 103, "end_pos": 112, "type": "METRIC", "confidence": 0.9979087114334106}]}, {"text": "The F-measure equals the geometric mean of precision (the percentage of correctly assigned boundaries with respect to all assigned boundaries) and recall (the percentage of correctly assigned boundaries with respect to the reference boundaries).", "labels": [], "entities": [{"text": "F-measure", "start_pos": 4, "end_pos": 13, "type": "METRIC", "confidence": 0.9973263740539551}, {"text": "precision", "start_pos": 43, "end_pos": 52, "type": "METRIC", "confidence": 0.9992333650588989}, {"text": "recall", "start_pos": 147, "end_pos": 153, "type": "METRIC", "confidence": 0.9996337890625}]}, {"text": "While using F-measure is a standard procedure, the prior work differ at least in three details: (1) whether precision and recall are calculated as micro-average overall segmentation points or as macro-average overall the word forms, (2) whether the evaluation is based on word types or word tokens in a corpus, and (3) if the reference segmentations have alternative correct choices fora single word type, and how to deal with them.", "labels": [], "entities": [{"text": "precision", "start_pos": 108, "end_pos": 117, "type": "METRIC", "confidence": 0.9989818930625916}, {"text": "recall", "start_pos": 122, "end_pos": 128, "type": "METRIC", "confidence": 0.9983336329460144}]}, {"text": "For the experiments with the S&B data sets, we follow and apply tokenbased micro-averages.", "labels": [], "entities": [{"text": "S&B data sets", "start_pos": 29, "end_pos": 42, "type": "DATASET", "confidence": 0.7501567125320434}]}, {"text": "For the experiments with the MC data sets, we follow and use type-based macro-averages.", "labels": [], "entities": [{"text": "MC data sets", "start_pos": 29, "end_pos": 41, "type": "DATASET", "confidence": 0.8572385112444559}]}, {"text": "However, differing from their boundary measure, we take the best match over the alternative reference analyses (separately for precision and recall), since none of the methods considered here provide multiple segmentations per word type.", "labels": [], "entities": [{"text": "precision", "start_pos": 127, "end_pos": 136, "type": "METRIC", "confidence": 0.9992519021034241}, {"text": "recall", "start_pos": 141, "end_pos": 147, "type": "METRIC", "confidence": 0.9984473586082458}]}, {"text": "For the models trained with the full training set, we also report the Fmeasures of the boundary evaluation method by in order to compare to the results reported in the Morpho Challenge website.", "labels": [], "entities": [{"text": "Fmeasures", "start_pos": 70, "end_pos": 79, "type": "METRIC", "confidence": 0.9959949254989624}, {"text": "Morpho Challenge website", "start_pos": 168, "end_pos": 192, "type": "DATASET", "confidence": 0.918947438398997}]}], "tableCaptions": [{"text": " Table 1. Finally, the word forms  in the training set are randomly permuted, and the  first 25%, 50%, 75%, and 100% of them are se- lected as subsets to study the effect of training data  size.", "labels": [], "entities": []}, {"text": " Table 2: The numbers of word types in the MC  data sets (Kurimo et al., 2009; Kurimo et al.,  2010).", "labels": [], "entities": [{"text": "MC  data sets", "start_pos": 43, "end_pos": 56, "type": "DATASET", "confidence": 0.7790911098321279}]}, {"text": " Table 3: Results for Arabic on the S&B data  set", "labels": [], "entities": [{"text": "Arabic", "start_pos": 22, "end_pos": 28, "type": "TASK", "confidence": 0.8663796782493591}, {"text": "S&B data  set", "start_pos": 36, "end_pos": 49, "type": "DATASET", "confidence": 0.739776360988617}]}, {"text": " Table 4: Results for Hebrew on the S&B data  set", "labels": [], "entities": [{"text": "Hebrew", "start_pos": 22, "end_pos": 28, "type": "TASK", "confidence": 0.9387853741645813}, {"text": "S&B data  set", "start_pos": 36, "end_pos": 49, "type": "DATASET", "confidence": 0.752782666683197}]}, {"text": " Table 5: Results for English on the Morpho Chal- lenge 2009/2010 data set (Kurimo et al., 2009; Ku- rimo et al., 2010). The column titled Train. de- notes the number of annotated training instances.  In addition to the annotated data, S-MORFESSOR  utilized an unannotated set of 384,903 word types.", "labels": [], "entities": [{"text": "Morpho Chal- lenge 2009/2010 data set", "start_pos": 37, "end_pos": 74, "type": "DATASET", "confidence": 0.8510454793771108}]}, {"text": " Table 6: Results for Finnish on the Morpho Chal- lenge 2009/2010 data set (Kurimo et al., 2009; Ku- rimo et al., 2010). The column titled Train. de- notes the number of annotated training instances.  In addition to the annotated data, S-MORFESSOR  utilized an unannotated set of 2,206,719 word  types.", "labels": [], "entities": [{"text": "Morpho Chal- lenge 2009/2010 data set", "start_pos": 37, "end_pos": 74, "type": "DATASET", "confidence": 0.8318196270200942}]}, {"text": " Table 7: Results for Turkish on the Morpho Chal- lenge 2009/2010 data set (Kurimo et al., 2009; Ku- rimo et al., 2010). The column titled Train. de- notes the number of annotated training instances.", "labels": [], "entities": [{"text": "Morpho Chal- lenge 2009/2010 data set", "start_pos": 37, "end_pos": 74, "type": "DATASET", "confidence": 0.8908407290776571}]}, {"text": " Table 8: F-measures of the Morpho Chal- lenge boundary evaluation for CRF and S- MORFESSOR using the full annotated training  data set.", "labels": [], "entities": [{"text": "F-measures", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.9925434589385986}, {"text": "MORFESSOR", "start_pos": 82, "end_pos": 91, "type": "METRIC", "confidence": 0.6964045166969299}, {"text": "training  data set", "start_pos": 117, "end_pos": 135, "type": "DATASET", "confidence": 0.7908104658126831}]}]}