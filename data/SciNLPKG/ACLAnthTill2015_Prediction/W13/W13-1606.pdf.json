{"title": [{"text": "Using PU-Learning to Detect Deceptive Opinion Spam", "labels": [], "entities": []}], "abstractContent": [{"text": "Nowadays a large number of opinion reviews are posted on the Web.", "labels": [], "entities": []}, {"text": "Such reviews area very important source of information for customers and companies.", "labels": [], "entities": []}, {"text": "The former rely more than ever on online reviews to make their purchase decisions and the latter to respond promptly to their clients' expectations.", "labels": [], "entities": []}, {"text": "Due to the economic importance of these reviews there is a growing trend to incorporate spam on such sites, and, as a consequence, to develop methods for opinion spam detection.", "labels": [], "entities": [{"text": "opinion spam detection", "start_pos": 154, "end_pos": 176, "type": "TASK", "confidence": 0.7586831450462341}]}, {"text": "In this paper we focus on the detection of deceptive opinion spam, which consists of fictitious opinions that have been deliberately written to sound authentic, in order to deceive the consumers.", "labels": [], "entities": []}, {"text": "In particular we propose a method based on the PU-learning approach which learns only from a few positive examples and a set of un-labeled data.", "labels": [], "entities": []}, {"text": "Evaluation results in a corpus of hotel reviews demonstrate the appropriateness of the proposed method for real applications since it reached a f-measure of 0.84 in the detection of deceptive opinions using only 100 positive examples for training.", "labels": [], "entities": [{"text": "f-measure", "start_pos": 144, "end_pos": 153, "type": "METRIC", "confidence": 0.9801930785179138}]}], "introductionContent": [{"text": "The Web is the greatest repository of digital information and communication platform ever invented.", "labels": [], "entities": []}, {"text": "People around the world widely use it to interact with each other as well as to express opinions and feelings on different issues and topics.", "labels": [], "entities": []}, {"text": "With the increasing availability of online review sites and blogs, costumers rely more than ever on online reviews to make their purchase decisions and businesses to respond promptly to their clients' expectations.", "labels": [], "entities": []}, {"text": "It is not surprising that opinion mining technologies have been witnessed a great interest in recent years (.", "labels": [], "entities": [{"text": "opinion mining", "start_pos": 26, "end_pos": 40, "type": "TASK", "confidence": 0.7794972360134125}]}, {"text": "Research in this field has been mainly oriented to problems such as opinion extraction and polarity classification.", "labels": [], "entities": [{"text": "opinion extraction", "start_pos": 68, "end_pos": 86, "type": "TASK", "confidence": 0.8387079238891602}, {"text": "polarity classification", "start_pos": 91, "end_pos": 114, "type": "TASK", "confidence": 0.922930121421814}]}, {"text": "However, because of the current trend about the growing number of online reviews that are fake or paid by companies to promote their products or damage the reputation of competitors, the automatic detection of opinion spam has emerged as a highly relevant research topic ().", "labels": [], "entities": [{"text": "automatic detection of opinion spam", "start_pos": 187, "end_pos": 222, "type": "TASK", "confidence": 0.7717519402503967}]}, {"text": "Detecting opinion spam is a very challenging problem since opinions expressed in the Web are typically short texts, written by unknown people using different styles and for different purposes.", "labels": [], "entities": [{"text": "Detecting opinion spam", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.9056113560994467}]}, {"text": "Opinion spam has many forms, e.g., fake reviews, fake comments, fake blogs, fake social network postings and deceptive texts.", "labels": [], "entities": []}, {"text": "Opinion spam reviews maybe detected by methods that seek for duplicate reviews, however, this kind of opinion spam only represents a small percentage of the opinions from review sites.", "labels": [], "entities": []}, {"text": "In this paper we focus on a potentially more insidious type of opinion spam, namely, deceptive opinion spam, which consists of fictitious opinions that have been deliberately written to sound authentic, in order to deceive the consumers.", "labels": [], "entities": []}, {"text": "The detection of deceptive opinion spam has been traditionally solved by means of supervised text classification techniques).", "labels": [], "entities": [{"text": "detection of deceptive opinion spam", "start_pos": 4, "end_pos": 39, "type": "TASK", "confidence": 0.7659316539764405}, {"text": "text classification", "start_pos": 93, "end_pos": 112, "type": "TASK", "confidence": 0.758884847164154}]}, {"text": "These techniques have demonstrated to be very robust if they are trained using large sets of labeled instances from both classes, deceptive opinions (positive instances) and truthful opinions (negative examples).", "labels": [], "entities": []}, {"text": "Nevertheless, in real application scenarios it is very difficult to construct such large training sets and, moreover, it is almost impossible to determine the authenticity of the opinions.", "labels": [], "entities": []}, {"text": "In order to meet this restriction we propose a method that learns only from a few positive examples and a set of unlabeled data.", "labels": [], "entities": []}, {"text": "In particular, we propose applying the PU-Learning approach (;) to detect deceptive opinion spam.", "labels": [], "entities": [{"text": "detect deceptive opinion spam", "start_pos": 67, "end_pos": 96, "type": "TASK", "confidence": 0.576738677918911}]}, {"text": "The evaluation of the proposed method was carried out using a corpus of hotel reviews under different training conditions.", "labels": [], "entities": []}, {"text": "The results are encouraging; they show the appropriateness of the proposed method for being used in real opinion spam detection applications.", "labels": [], "entities": [{"text": "real opinion spam detection", "start_pos": 100, "end_pos": 127, "type": "TASK", "confidence": 0.6880574524402618}]}, {"text": "It reached a f-measure of 0.84 in the detection of deceptive opinions using only 100 positive examples, greatly outperforming the effectiveness of the traditional supervised approach and the one-class SVM model.", "labels": [], "entities": [{"text": "f-measure", "start_pos": 13, "end_pos": 22, "type": "METRIC", "confidence": 0.9971160888671875}]}, {"text": "The rest of the paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 presents some related works in the field of opinion spam detection.", "labels": [], "entities": [{"text": "opinion spam detection", "start_pos": 54, "end_pos": 76, "type": "TASK", "confidence": 0.8162802656491598}]}, {"text": "Section 3 describes our adaptation of the PU-Learning approach to the task of opinion spam detection.", "labels": [], "entities": [{"text": "opinion spam detection", "start_pos": 78, "end_pos": 100, "type": "TASK", "confidence": 0.8281193176905314}]}, {"text": "Section 4 presents the experimental results and discusses its advantages and disadvantages.", "labels": [], "entities": []}, {"text": "Finally, Section 5 indicates the contributions of the paper and provides some future work directions.", "labels": [], "entities": []}], "datasetContent": [{"text": "The evaluation of the proposed method was carried out using a dataset of reviews assembled by.", "labels": [], "entities": []}, {"text": "This corpus contains 800 opinions, 400 deceptive and 400 truthful opinions.", "labels": [], "entities": []}, {"text": "These opinions are about the 20 most popular Chicago hotels; deceptive opinions were generated using the Amazon Mechanical Turk (AMT) 3 , whereas -possible-truthful opinions were mined from a total of 6,977 reviews on TripAdvisor . The following paragraphs show two opinions taken from (Ott et al., 2011).", "labels": [], "entities": [{"text": "Amazon Mechanical Turk (AMT) 3", "start_pos": 105, "end_pos": 135, "type": "DATASET", "confidence": 0.8330883298601423}]}, {"text": "These examples are very interesting since they show the great complexity of the automatically -and even manually-detection of deceptive opinions.", "labels": [], "entities": []}, {"text": "Both opinions are very similar and just minor details can help distinguishing one from the other.", "labels": [], "entities": []}, {"text": "For example, in his research found that deceptive reviews used the words \"experience\", \"my husband\", \"I\", \"feel\", \"business\", and \"vacation\" more than genuine ones.", "labels": [], "entities": []}, {"text": "The evaluation of the effectiveness of the proposed method was carried out by means of the f-measure.", "labels": [], "entities": []}, {"text": "This measure is a linear combination of the precision and recall values.", "labels": [], "entities": [{"text": "precision", "start_pos": 44, "end_pos": 53, "type": "METRIC", "confidence": 0.999432384967804}, {"text": "recall", "start_pos": 58, "end_pos": 64, "type": "METRIC", "confidence": 0.9939722418785095}]}, {"text": "We computed this measure for both classes, deceptive and -possibletruthful opinions, nevertheless, the performance on the deceptive opinions is the only measure of real relevance.", "labels": [], "entities": []}, {"text": "The f-measure for each opinion category O i is defined as follows: recall show the results from all the experiments we carried out.", "labels": [], "entities": [{"text": "recall", "start_pos": 67, "end_pos": 73, "type": "METRIC", "confidence": 0.9951748847961426}]}, {"text": "It is important to notice that we used Na\u00a8\u0131veNa\u00a8\u0131ve Bayes and SVM classifiers as learning algorithms in our PU-learning method.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Comparison of the performance of different classifiers when using 20, 40 and 60 examples of deceptive  opinions for training; in this table D refers to deceptive opinions and U to unlabeled opinions.", "labels": [], "entities": []}, {"text": " Table 2: Comparison of the performance of different classifiers when using 80, 100 and 120 examples of deceptive  opinions for training; in this table D refers to deceptive opinions and U to unlabeled opinions.", "labels": [], "entities": []}]}