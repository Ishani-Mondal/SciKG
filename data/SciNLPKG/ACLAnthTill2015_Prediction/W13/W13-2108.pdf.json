{"title": [{"text": "Graphs and Spatial Relations in the Generation of Referring Expressions", "labels": [], "entities": []}], "abstractContent": [{"text": "When they introduced the Graph-Based Algorithm (GBA) for referring expression generation, Krahmer et al.", "labels": [], "entities": [{"text": "referring expression generation", "start_pos": 57, "end_pos": 88, "type": "TASK", "confidence": 0.6885314186414083}]}, {"text": "(2003) flaunted the natural way in which it deals with relations between objects; but this feature has never been tested empirically.", "labels": [], "entities": []}, {"text": "We fill this gap in this paper, exploring referring expression generation from the perspective of the GBA and focusing in particular on generating human-like expressions in visual scenes with spatial relations.", "labels": [], "entities": [{"text": "referring expression generation", "start_pos": 42, "end_pos": 73, "type": "TASK", "confidence": 0.7813727458318075}, {"text": "GBA", "start_pos": 102, "end_pos": 105, "type": "DATASET", "confidence": 0.9669182896614075}]}, {"text": "We compare the original GBA against a variant that we introduce to better reflect human reference, and find that although the original GBA performs reasonably well, our new algorithm offers an even better match to human data (77.91% Dice).", "labels": [], "entities": [{"text": "Dice)", "start_pos": 233, "end_pos": 238, "type": "METRIC", "confidence": 0.9716139733791351}]}, {"text": "Further, it can be extended to capture speaker variation , reaching an 82.83% Dice overlap with human-produced expressions.", "labels": [], "entities": [{"text": "Dice overlap", "start_pos": 78, "end_pos": 90, "type": "METRIC", "confidence": 0.9741891026496887}]}], "introductionContent": [{"text": "Ten years ago,  published the Graph-Based Algorithm (GBA) for referring expression generation (REG).", "labels": [], "entities": [{"text": "referring expression generation (REG)", "start_pos": 62, "end_pos": 99, "type": "TASK", "confidence": 0.8243358333905538}]}, {"text": "REG has since become one of the most researched areas within Natural Language Generation, due in a large part to the central role it plays in communication: referring allows humans and language generation systems alike to invoke the entities that the discourse is about in the mind of a listener or reader.", "labels": [], "entities": [{"text": "REG", "start_pos": 0, "end_pos": 3, "type": "TASK", "confidence": 0.7961688041687012}, {"text": "Natural Language Generation", "start_pos": 61, "end_pos": 88, "type": "TASK", "confidence": 0.6585963070392609}]}, {"text": "Like most REG algorithms, the GBA is focussed on the task of selecting the semantic content fora referring expression, uniquely identifying a target referent among all objects in its visual or linguistic context.", "labels": [], "entities": []}, {"text": "The framework used by the GBA is particularly attractive because it provides fine-grained control for finding the 'best' referring expression, encompassing several previous approaches.", "labels": [], "entities": []}, {"text": "This control is made possible by defining a desired cost function over object properties to guide the construction of the output expression and using a search mechanism that does not stop at the first solution found.", "labels": [], "entities": []}, {"text": "One characteristic of the GBA particularly emphasized by , advancing from research on algorithms such as the Incremental Algorithm and the Greedy Algorithm, was the treatment of relations between entities.", "labels": [], "entities": []}, {"text": "Relations such as on top of or to the left of fallout naturally from the graph-based representation of the domain, a facet missing in earlier algorithms.", "labels": [], "entities": []}, {"text": "We believe that this makes the GBA particularly well-suited for generating language in spatial visual domains.", "labels": [], "entities": [{"text": "GBA", "start_pos": 31, "end_pos": 34, "type": "DATASET", "confidence": 0.7840413451194763}]}, {"text": "In the years since the inception of the GBA, the REG community has become increasingly interested in evaluating algorithms against humanproduced data in visual domains, aiming to mimic human references to objects.", "labels": [], "entities": []}, {"text": "This interest has manifested most prominently in the) based on the TUNA Corpus ).", "labels": [], "entities": [{"text": "TUNA Corpus", "start_pos": 67, "end_pos": 78, "type": "DATASET", "confidence": 0.922258049249649}]}, {"text": "The GBA performed among the best algorithms in all three of these challenges.", "labels": [], "entities": [{"text": "GBA", "start_pos": 4, "end_pos": 7, "type": "METRIC", "confidence": 0.4554312825202942}]}, {"text": "However, in particular its ability to analyze relational information could not be assessed, because the TUNA Corpus does not contain annotated relational descriptions.", "labels": [], "entities": [{"text": "TUNA Corpus", "start_pos": 104, "end_pos": 115, "type": "DATASET", "confidence": 0.9632433652877808}]}, {"text": "We rectify this omission in the current work by testing the GBA on the GRE3D3 Corpus, which was designed to study the use of spatial relations in referring expressions . We compare against a variant of the GBA that we introduce to build longer referring expres-sions, following the observation that humans tend to overspecify (i.e., not be maximally brief) in their referring expressions).", "labels": [], "entities": [{"text": "GBA", "start_pos": 60, "end_pos": 63, "type": "DATASET", "confidence": 0.7736677527427673}, {"text": "GRE3D3 Corpus", "start_pos": 71, "end_pos": 84, "type": "DATASET", "confidence": 0.9825278520584106}]}, {"text": "For both algorithms, we experiment with cost functions defined at different granularities to produce the best match to human data.", "labels": [], "entities": []}, {"text": "We find that we can match human data better than the original GBA with the variant that encourages overspecification.", "labels": [], "entities": [{"text": "GBA", "start_pos": 62, "end_pos": 65, "type": "DATASET", "confidence": 0.8958922028541565}]}, {"text": "With this model, we aim to further advance towards human-like reference by developing a method to capture speaker-specific variation.", "labels": [], "entities": []}, {"text": "Speaker variation cannot easily be modeled by the classic input variables of REG algorithms, but a number of authors have shown that system output can be improved by using speaker identity as an additional feature; this has often been accompanied by the observation that commonalities can be found in the reference behaviour of different speakers), particularly for spatial relations).", "labels": [], "entities": []}, {"text": "In the second experiment reported in this paper, we combine these insights by automatically clustering groups of speakers with similar behaviour and then defining separate cost functions for each group to better guide the algorithms.", "labels": [], "entities": []}, {"text": "Before we assess the ability of the GBA and our variant to produce human-like referring expressions containing relations (Sections 5 and 6), we will give an overview of the relevant background to the treatment of relations in REG, a short history of the GBA, and the relevance of individual variation (Section 2).", "labels": [], "entities": []}, {"text": "We introduce our new variant graph-based algorithm, LongestFirst, in Section 3.", "labels": [], "entities": []}], "datasetContent": [{"text": "In our first experiment, we evaluate how well the GBA produces human-like reference in a corpus that uses spatial relations.", "labels": [], "entities": []}, {"text": "We compare against the LongestFirst variant that encourages overspecification.", "labels": [], "entities": []}, {"text": "We use k-means clustering to group the speakers in the GRE3D3 Corpus based on the number of times they used each attribute and the average length of their descriptions.", "labels": [], "entities": [{"text": "GRE3D3 Corpus", "start_pos": 55, "end_pos": 68, "type": "DATASET", "confidence": 0.9501697719097137}]}, {"text": "We tried values between 2 and 5 fork, but found that any value above 2 resulted in two very large clusters accompanied by a number of extremely small clusters.", "labels": [], "entities": []}, {"text": "As these small clusters would not be suitable for x-fold cross-validation, we proceed with two clusters, one consisting of speakers preferring relatively long descriptions that often contain spatial relations (Cluster CL0, 16 speakers, 160 descriptions), and one consisting of speakers preferring short, non-relational descriptions (Cluster CL1, 47 speakers, 470 descriptions).", "labels": [], "entities": [{"text": "Cluster CL1", "start_pos": 333, "end_pos": 344, "type": "DATASET", "confidence": 0.8899554908275604}]}, {"text": "We train cost functions and POs separately for the two clusters in order to capture the different behaviour patterns they are based on.", "labels": [], "entities": [{"text": "POs", "start_pos": 28, "end_pos": 31, "type": "METRIC", "confidence": 0.9739586114883423}]}, {"text": "We use the FREE-NA\u00a8IVENA\u00a8IVE cost functions for this experiment, which outperformed all others in Experiment 1.", "labels": [], "entities": [{"text": "FREE-NA\u00a8IVENA\u00a8IVE cost", "start_pos": 11, "end_pos": 33, "type": "METRIC", "confidence": 0.9107258319854736}]}, {"text": "We again use 10-fold cross-validation for the evaluation.", "labels": [], "entities": []}, {"text": "In this experiment, we vary the maximum length setting for the LongestFirst algorithm.", "labels": [], "entities": []}, {"text": "In Experiment 1, the maximum length fora referring expression was set to 4 based on previous empirical findings.", "labels": [], "entities": []}, {"text": "Here we additionally test setting it to the rounded average length for each training fold.", "labels": [], "entities": [{"text": "rounded average length", "start_pos": 44, "end_pos": 66, "type": "METRIC", "confidence": 0.7791781624158224}]}, {"text": "On Cluster CL0 this average length is 6 in all folds, on Cluster CL1 it is 3.", "labels": [], "entities": [{"text": "length", "start_pos": 28, "end_pos": 34, "type": "METRIC", "confidence": 0.7708302736282349}]}, {"text": "We now extend our methods to take into account individual variation in the content selection for referring expressions, and evaluate whether we have better success at reproducing participants' relational descriptions.", "labels": [], "entities": []}, {"text": "Rather than using speaker identity as an input parameter to the system (Section 2.3), we automatically find groups of people who behave similarly to each other, but significantly different to speakers in the other groups.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Experiment 1: System performance in %.  We used \ud97b\udf59 2 on Accuracy and paired t-tests on Dice  to check for statistical significance. The best per- formance is highlighted in boldface. It is statisti- cally significantly different from all other systems  (Acc: p < 0.02, Dice: p < 0.0001).", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 65, "end_pos": 73, "type": "METRIC", "confidence": 0.9978260397911072}, {"text": "Acc", "start_pos": 263, "end_pos": 266, "type": "METRIC", "confidence": 0.9824222922325134}]}, {"text": " Table 2: Experiment 2: Performance in % of the  LongestFirst and OriginalGraph algorithms on the  two speaker clusters and overall using the FREE- NA\u00a8IVENA\u00a8IVE (FN) approaches. We used \ud97b\udf59 2 on Accu- racy and paired t-tests on Dice to check for statis- tical significance. The best performance in each  column and those that are statistically not signifi- cantly different are highlighted in boldface.", "labels": [], "entities": [{"text": "FREE- NA\u00a8IVENA\u00a8IVE (FN)", "start_pos": 142, "end_pos": 165, "type": "METRIC", "confidence": 0.9210460245609283}]}]}