{"title": [{"text": "Automatic classification of patterns from the Pattern Dictionary of English Verbs", "labels": [], "entities": []}], "abstractContent": [{"text": "The paper presents a supervised approach to semantic parsing, based on anew semantic resource, the Pattern Dictionary of English Verbs (PDEV).", "labels": [], "entities": [{"text": "semantic parsing", "start_pos": 44, "end_pos": 60, "type": "TASK", "confidence": 0.7965704798698425}, {"text": "Pattern Dictionary of English Verbs (PDEV)", "start_pos": 99, "end_pos": 141, "type": "DATASET", "confidence": 0.6015193723142147}]}, {"text": "PDEV lists the most frequent patterns of English verbs identified in corpus.", "labels": [], "entities": [{"text": "PDEV", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.9443854093551636}]}, {"text": "Each argument in a pattern is semantically categorized with semantic types from the PDEV ontology.", "labels": [], "entities": []}, {"text": "Each pattern is linked to a set of sentences from the British National Corpus.", "labels": [], "entities": [{"text": "British National Corpus", "start_pos": 54, "end_pos": 77, "type": "DATASET", "confidence": 0.9276177287101746}]}, {"text": "The article describes PDEV in details and presents the task of pattern classification.", "labels": [], "entities": [{"text": "pattern classification", "start_pos": 63, "end_pos": 85, "type": "TASK", "confidence": 0.8001760840415955}]}, {"text": "The system described is based on a dis-tributional approach, and achieves 66% in Micro-average F1 across a sample of 25 of the most frequent verbs.", "labels": [], "entities": [{"text": "Micro-average", "start_pos": 81, "end_pos": 94, "type": "METRIC", "confidence": 0.9763714075088501}, {"text": "F1", "start_pos": 95, "end_pos": 97, "type": "METRIC", "confidence": 0.7767791152000427}]}], "introductionContent": [{"text": "This paper reports the results of Natural Language Processing (NLP) experiments in semantic parsing, based on anew semantic resource, the Pattern Dictionary of English Verbs (PDEV).", "labels": [], "entities": [{"text": "semantic parsing", "start_pos": 83, "end_pos": 99, "type": "TASK", "confidence": 0.7707992494106293}]}, {"text": "This resource is the output of Corpus Pattern Analysis (CPA;), a corpus lexicography technique for mapping meaning onto words in text.", "labels": [], "entities": [{"text": "Corpus Pattern Analysis (CPA", "start_pos": 31, "end_pos": 59, "type": "TASK", "confidence": 0.7579542517662048}]}, {"text": "CPA analyses the prototypical syntagmatic patterns with which words in use are associated.", "labels": [], "entities": [{"text": "CPA", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.8310680389404297}]}, {"text": "The patterns emerge from the analysis of corpus concordance lines and careful attention to linguistic context clues is applied to characterize pattern elements and to distinguish between patterns.", "labels": [], "entities": []}, {"text": "Only in a second step is an \"implicature\" (i.e. a meaning) mapped onto a pattern.", "labels": [], "entities": []}, {"text": "In other words, CPA is driven by syntagmatic patterns, not meaning.", "labels": [], "entities": [{"text": "CPA", "start_pos": 16, "end_pos": 19, "type": "TASK", "confidence": 0.9563886523246765}]}, {"text": "Given these two features (pattern-driven and corpus-driven), this resource is unique in its kind, across languages.", "labels": [], "entities": []}, {"text": "However, while CPA has made contributions to lexicography and to linguistics, no experiments have yet been made in NLP to use PDEV in applications such as Information Extraction or Statistical Machine Translation.", "labels": [], "entities": [{"text": "Information Extraction", "start_pos": 155, "end_pos": 177, "type": "TASK", "confidence": 0.8569453954696655}, {"text": "Statistical Machine Translation", "start_pos": 181, "end_pos": 212, "type": "TASK", "confidence": 0.7651176651318868}]}, {"text": "The present paper proposes to make use of PDEV as a resource for the semantic processing of text.", "labels": [], "entities": [{"text": "semantic processing of text", "start_pos": 69, "end_pos": 96, "type": "TASK", "confidence": 0.8018357008695602}]}, {"text": "It describes its structure in detail (section 2) and proposes the task of Pattern classification as a first step in semantic parsing (section 3).", "labels": [], "entities": [{"text": "Pattern classification", "start_pos": 74, "end_pos": 96, "type": "TASK", "confidence": 0.9569841623306274}, {"text": "semantic parsing", "start_pos": 116, "end_pos": 132, "type": "TASK", "confidence": 0.8188366591930389}]}, {"text": "Contributions are summarized in section 4.", "labels": [], "entities": []}], "datasetContent": [{"text": "An important task performed by semantic parsers is Word Sense Disambiguation (WSD), in which systems predict the senses of words in text.", "labels": [], "entities": [{"text": "Word Sense Disambiguation (WSD)", "start_pos": 51, "end_pos": 82, "type": "TASK", "confidence": 0.7706761757532755}]}, {"text": "WSD experiments) have used WordNet as a sense repository but we decided to explore how PDEV patterns could be used in this context.", "labels": [], "entities": [{"text": "WSD", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.7904433608055115}, {"text": "WordNet", "start_pos": 27, "end_pos": 34, "type": "DATASET", "confidence": 0.9506568312644958}]}, {"text": "As each pattern is linked to a set of lines, the present task of pattern classification requires systems to identify the correct pattern for each verb token.", "labels": [], "entities": [{"text": "pattern classification", "start_pos": 65, "end_pos": 87, "type": "TASK", "confidence": 0.8019989430904388}]}, {"text": "Our experiment was carried out on 25 verbs with comparatively high frequency in the BNC, on a range of patterns.", "labels": [], "entities": [{"text": "BNC", "start_pos": 84, "end_pos": 87, "type": "DATASET", "confidence": 0.9473493695259094}]}, {"text": "The dataset contains 20418 verb tokens and was split using the following stratified sampling method: tokens were randomly selected from each verb pattern separately, using a 0.8:0.2 ratio, making sure that in extreme cases, where the set included less than 4 instances, the training set would always contain at least as many examples as in the test set.", "labels": [], "entities": []}, {"text": "Two evaluation metrics were used: Microaverage (Micro-F1) and Macro-average F-score (Macro-F1).", "labels": [], "entities": [{"text": "Microaverage", "start_pos": 34, "end_pos": 46, "type": "METRIC", "confidence": 0.8186689615249634}, {"text": "F-score", "start_pos": 76, "end_pos": 83, "type": "METRIC", "confidence": 0.8654527068138123}]}, {"text": "Micro-F1 can be computed by counting False and True positives and negatives across classes.", "labels": [], "entities": [{"text": "False", "start_pos": 37, "end_pos": 42, "type": "METRIC", "confidence": 0.9811421036720276}]}, {"text": "Micro-F1 can be complemented with Mac-F1 which gives an estimate of the performance of systems in discriminating patterns (by giving equal weight to classes rather than to instances; see equation).", "labels": [], "entities": []}, {"text": "The baseline was generated by applying the majority class (most frequent) found in the training set, to the test set.", "labels": [], "entities": []}, {"text": "Since the dataset is highly biased in terms of label frequency, the baseline Micro-F1 is quite high (0.62 across verbs).", "labels": [], "entities": [{"text": "Micro-F1", "start_pos": 77, "end_pos": 85, "type": "DATASET", "confidence": 0.6032873392105103}]}, {"text": "However, the baseline reaches 0.12 in Macro-F1.", "labels": [], "entities": [{"text": "baseline", "start_pos": 13, "end_pos": 21, "type": "METRIC", "confidence": 0.9828435182571411}, {"text": "Macro-F1", "start_pos": 38, "end_pos": 46, "type": "DATASET", "confidence": 0.8722883462905884}]}], "tableCaptions": [{"text": " Table 1: Results for the pattern classification task", "labels": [], "entities": [{"text": "pattern classification", "start_pos": 26, "end_pos": 48, "type": "TASK", "confidence": 0.9008029103279114}]}]}