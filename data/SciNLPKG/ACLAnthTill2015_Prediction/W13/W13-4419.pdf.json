{"title": [{"text": "NTOU Chinese Spelling Check System in SIGHAN Bake-off 2013", "labels": [], "entities": [{"text": "NTOU Chinese Spelling Check", "start_pos": 0, "end_pos": 27, "type": "TASK", "confidence": 0.6444240361452103}, {"text": "SIGHAN Bake-off 2013", "start_pos": 38, "end_pos": 58, "type": "DATASET", "confidence": 0.7498378356297811}]}], "abstractContent": [{"text": "This paper describes details of NTOU Chinese spelling check system participating in SIGHAN-7 Bakeoff.", "labels": [], "entities": [{"text": "NTOU Chinese spelling check", "start_pos": 32, "end_pos": 59, "type": "TASK", "confidence": 0.7161775529384613}, {"text": "SIGHAN-7 Bakeoff", "start_pos": 84, "end_pos": 100, "type": "TASK", "confidence": 0.5374696850776672}]}, {"text": "The modules in our system include word segmentation, N-gram model probability estimation, similar character replacement, and filtering rules.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 34, "end_pos": 51, "type": "TASK", "confidence": 0.7997770309448242}, {"text": "N-gram model probability estimation", "start_pos": 53, "end_pos": 88, "type": "TASK", "confidence": 0.5619523003697395}, {"text": "similar character replacement", "start_pos": 90, "end_pos": 119, "type": "TASK", "confidence": 0.6656414071718851}]}, {"text": "Three dry runs and three formal runs were submitted, and the best one was created by bigram probability comparison without applying preference and filtering rules.", "labels": [], "entities": []}], "introductionContent": [{"text": "Automatic spell checking is a basic and important technique in building NLP systems.", "labels": [], "entities": [{"text": "Automatic spell checking", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.6272089183330536}]}, {"text": "It has been studied since 1960s as and made the first attempt to solve the spelling error problem in English.", "labels": [], "entities": [{"text": "spelling error problem", "start_pos": 75, "end_pos": 97, "type": "TASK", "confidence": 0.649697502454122}]}, {"text": "Spelling errors in English can be grouped into two classes: non-word spelling errors and real-word spelling errors.", "labels": [], "entities": [{"text": "Spelling errors", "start_pos": 0, "end_pos": 15, "type": "TASK", "confidence": 0.9116830229759216}]}, {"text": "A non-word spelling error occurs when the written string cannot be found in a dictionary, such as in fly *fron Paris.", "labels": [], "entities": [{"text": "fly *fron Paris", "start_pos": 101, "end_pos": 116, "type": "DATASET", "confidence": 0.5898882374167442}]}, {"text": "The typical approach is finding a list of candidates from a large dictionary by edit distance or phonetic similarity.", "labels": [], "entities": []}, {"text": "A real-word spelling error occurs when one word is mistakenly used for another word, such as in fly *form Paris.", "labels": [], "entities": []}, {"text": "Typical approaches include using confusion set (), contextual information, and others.", "labels": [], "entities": []}, {"text": "Spelling error problem in Chinese is quite different.", "labels": [], "entities": [{"text": "Spelling error", "start_pos": 0, "end_pos": 14, "type": "TASK", "confidence": 0.6885489970445633}]}, {"text": "Because there is no word delimiter in a Chinese sentence and almost every Chinese character can be considered as a one-syllable word, most of the errors are real-word errors.", "labels": [], "entities": []}, {"text": "On the other hand, there can be a non-character error where a hand-written character is not legal (thus not collected in a dictionary).", "labels": [], "entities": []}, {"text": "Such an error cannot happen in a digital document because all characters in Chinese character sets such as BIG5 or Unicode are legal.", "labels": [], "entities": [{"text": "BIG5", "start_pos": 107, "end_pos": 111, "type": "DATASET", "confidence": 0.8526056408882141}]}, {"text": "There have been many attempts to solve the spelling error problem in Chinese).", "labels": [], "entities": [{"text": "spelling error problem", "start_pos": 43, "end_pos": 65, "type": "TASK", "confidence": 0.5937920610109965}]}, {"text": "Among them, lists of visually and phonologically similar characters play an important role in Chinese spelling check.", "labels": [], "entities": [{"text": "Chinese spelling check", "start_pos": 94, "end_pos": 116, "type": "TASK", "confidence": 0.729771355787913}]}, {"text": "This bake-off is the first Chinese spell checking evaluation project.", "labels": [], "entities": [{"text": "Chinese spell checking evaluation", "start_pos": 27, "end_pos": 60, "type": "TASK", "confidence": 0.6942096427083015}]}, {"text": "It includes two subtasks: error detection and error correction.", "labels": [], "entities": [{"text": "error detection", "start_pos": 26, "end_pos": 41, "type": "TASK", "confidence": 0.7336136251688004}, {"text": "error correction", "start_pos": 46, "end_pos": 62, "type": "TASK", "confidence": 0.7555906176567078}]}, {"text": "The task is organized based on some research works ().", "labels": [], "entities": []}, {"text": "shows the architecture of our Chinese spelling checking system.", "labels": [], "entities": [{"text": "Chinese spelling checking", "start_pos": 30, "end_pos": 55, "type": "TASK", "confidence": 0.5889107982317606}]}], "datasetContent": [{"text": "We submitted 3 dry runs in this Bake-off.", "labels": [], "entities": [{"text": "Bake-off", "start_pos": 32, "end_pos": 40, "type": "DATASET", "confidence": 0.7860727906227112}]}, {"text": "The first run used only visually similar characters.", "labels": [], "entities": []}, {"text": "The second run used only phonologically similar characters.", "labels": [], "entities": []}, {"text": "And the third run used both kinds of similar characters.", "labels": [], "entities": []}, {"text": "All three runs used bigram probability to detect errors. and 6 illustrate the evaluation results of dry runs in Subtask 1 and Subtask 2.", "labels": [], "entities": []}, {"text": "(Evaluation results of Dryrun3_NTOU in Subtask 2 will be provided in the camera-ready version.)", "labels": [], "entities": []}, {"text": "As we can see, using only phonologically similar characters achieve better F-scores than other strategies.", "labels": [], "entities": [{"text": "F-scores", "start_pos": 75, "end_pos": 83, "type": "METRIC", "confidence": 0.996457040309906}]}, {"text": "We submitted 3 formal runs in this Bake-off.", "labels": [], "entities": [{"text": "Bake-off", "start_pos": 35, "end_pos": 43, "type": "DATASET", "confidence": 0.8423678874969482}]}, {"text": "The first run used unigram probability while the other runs used bigram probability to detect errors.", "labels": [], "entities": []}, {"text": "Besides, preference and filtering rules were applied only on the first run and the third run.", "labels": [], "entities": []}, {"text": "All three runs used all similar characters to do the replacement. and 8 illustrate the evaluation results of formal runs in Subtask 1 and Subtask 2.", "labels": [], "entities": []}, {"text": "As we can see, using bigram probability without preference and filtering rules achieve the best performance.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 5. Dry run performance in Subtask 1", "labels": [], "entities": []}, {"text": " Table 6. Dry run performance in Subtask 2", "labels": [], "entities": []}, {"text": " Table 7. Formal run performance in Subtask 1", "labels": [], "entities": []}]}