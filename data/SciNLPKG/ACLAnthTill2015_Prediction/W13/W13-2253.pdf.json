{"title": [{"text": "A Description of Tunable Machine Translation Evaluation Systems in WMT13 Metrics Task", "labels": [], "entities": [{"text": "Tunable Machine Translation Evaluation", "start_pos": 17, "end_pos": 55, "type": "TASK", "confidence": 0.8577854335308075}, {"text": "WMT13 Metrics", "start_pos": 67, "end_pos": 80, "type": "DATASET", "confidence": 0.8403066694736481}]}], "abstractContent": [{"text": "This paper is to describe our machine translation evaluation systems used for participation in the WMT13 shared Metrics Task.", "labels": [], "entities": [{"text": "machine translation evaluation", "start_pos": 30, "end_pos": 60, "type": "TASK", "confidence": 0.8240603804588318}, {"text": "WMT13 shared Metrics Task", "start_pos": 99, "end_pos": 124, "type": "TASK", "confidence": 0.5093443989753723}]}, {"text": "In the Metrics task, we submitted two automatic MT evaluation systems nLEPOR_baseline and LEPOR_v3.1.", "labels": [], "entities": [{"text": "MT evaluation", "start_pos": 48, "end_pos": 61, "type": "TASK", "confidence": 0.890174388885498}, {"text": "LEPOR", "start_pos": 90, "end_pos": 95, "type": "METRIC", "confidence": 0.9797338843345642}]}, {"text": "nLEPOR_baseline is an n-gram based language independent MT evaluation metric employing the factors of modified sentence length penalty, position difference penalty , n-gram precision and n-gram recall.", "labels": [], "entities": [{"text": "nLEPOR_baseline", "start_pos": 0, "end_pos": 15, "type": "DATASET", "confidence": 0.7393309275309244}, {"text": "MT evaluation", "start_pos": 56, "end_pos": 69, "type": "TASK", "confidence": 0.9152611792087555}, {"text": "position difference penalty", "start_pos": 136, "end_pos": 163, "type": "METRIC", "confidence": 0.7994516491889954}, {"text": "precision", "start_pos": 173, "end_pos": 182, "type": "METRIC", "confidence": 0.9432022571563721}, {"text": "recall", "start_pos": 194, "end_pos": 200, "type": "METRIC", "confidence": 0.991306722164154}]}, {"text": "nLEPOR_baseline measures the similarity of the system output translations and the reference translations only on word sequences.", "labels": [], "entities": []}, {"text": "LEPOR_v3.1 is anew version of LEPOR metric using the mathematical harmonic mean to group the factors and employing some linguistic features, such as the part-of-speech information.", "labels": [], "entities": []}, {"text": "The evaluation results of WMT13 show LEPOR_v3.1 yields the highest average-score 0.86 with human judgments at system-level using Pearson correlation criterion on English-to-other (FR, DE, ES, CS, RU) language pairs.", "labels": [], "entities": [{"text": "WMT13", "start_pos": 26, "end_pos": 31, "type": "DATASET", "confidence": 0.8385927081108093}, {"text": "LEPOR_v3.1", "start_pos": 37, "end_pos": 47, "type": "METRIC", "confidence": 0.9425233602523804}, {"text": "Pearson correlation criterion", "start_pos": 129, "end_pos": 158, "type": "METRIC", "confidence": 0.9308535655339559}]}], "introductionContent": [{"text": "Machine translation has along history since the 1950s and gains a fast development in the recent years because of the higher level of computer technology.", "labels": [], "entities": [{"text": "Machine translation", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.8597173690795898}]}, {"text": "For instances, presents Minimum Error Rate Training (MERT) method for log-linear statistical machine translation models to achieve better translation quality; introduce a syntactically informed phrasal SMT system for English-to-Spanish translation using a phrase translation model, which is based on global reordering and the dependency tree; use the Thematic Role Templates model to improve the translation; develop the phrase-based SMT system for Chinese-Spanish translation using a pivot language.", "labels": [], "entities": [{"text": "Minimum Error Rate Training (MERT)", "start_pos": 24, "end_pos": 58, "type": "METRIC", "confidence": 0.7742631222520556}, {"text": "statistical machine translation", "start_pos": 81, "end_pos": 112, "type": "TASK", "confidence": 0.7251590689023336}, {"text": "SMT", "start_pos": 202, "end_pos": 205, "type": "TASK", "confidence": 0.9210056662559509}, {"text": "phrase translation", "start_pos": 256, "end_pos": 274, "type": "TASK", "confidence": 0.7521328032016754}, {"text": "SMT", "start_pos": 434, "end_pos": 437, "type": "TASK", "confidence": 0.784706175327301}]}, {"text": "With the rapid development of Machine Translation (MT), the evaluation of MT has become a challenge in front of researchers.", "labels": [], "entities": [{"text": "Machine Translation (MT)", "start_pos": 30, "end_pos": 54, "type": "TASK", "confidence": 0.8480855166912079}, {"text": "MT", "start_pos": 74, "end_pos": 76, "type": "TASK", "confidence": 0.9483206272125244}]}, {"text": "However, the MT evaluation is not an easy task due to the fact of the diversity of the languages, especially for the evaluation between distant languages (English, Russia, Japanese, etc.).", "labels": [], "entities": [{"text": "MT evaluation", "start_pos": 13, "end_pos": 26, "type": "TASK", "confidence": 0.928819864988327}]}], "datasetContent": [{"text": "In the MT evaluation task, the Spearman rank correlation coefficient method is usually used by the authoritative ACL WMT to evaluate the correlation of different MT evaluation metrics.", "labels": [], "entities": [{"text": "MT evaluation task", "start_pos": 7, "end_pos": 25, "type": "TASK", "confidence": 0.9131208658218384}, {"text": "Spearman rank correlation coefficient", "start_pos": 31, "end_pos": 68, "type": "METRIC", "confidence": 0.6075384169816971}, {"text": "ACL WMT", "start_pos": 113, "end_pos": 120, "type": "DATASET", "confidence": 0.8855933547019958}, {"text": "MT evaluation", "start_pos": 162, "end_pos": 175, "type": "TASK", "confidence": 0.9071479141712189}]}, {"text": "So we use the Spearman rank correlation coefficient to evaluate the performances of nLEPOR_baseline and LEPOR_v3.1 in system level correlation with human judgments.", "labels": [], "entities": [{"text": "Spearman rank correlation coefficient", "start_pos": 14, "end_pos": 51, "type": "METRIC", "confidence": 0.6945349276065826}, {"text": "LEPOR", "start_pos": 104, "end_pos": 109, "type": "METRIC", "confidence": 0.9883986115455627}]}, {"text": "When there are no ties, is calculated using: The variable is the difference value between the ranks for and is the number of systems.", "labels": [], "entities": []}, {"text": "We also offer the Pearson correlation coefficient information as below.", "labels": [], "entities": [{"text": "Pearson correlation coefficient", "start_pos": 18, "end_pos": 49, "type": "METRIC", "confidence": 0.840889573097229}]}, {"text": "Given a sample of paired data (X, Y) as ( , , the Pearson correlation coefficient is:.", "labels": [], "entities": [{"text": "Pearson correlation coefficient", "start_pos": 50, "end_pos": 81, "type": "METRIC", "confidence": 0.9369538625081381}]}, {"text": "System-level Pearson correlation scores on WMT13 English-to-other language pairs", "labels": [], "entities": [{"text": "Pearson correlation", "start_pos": 13, "end_pos": 32, "type": "METRIC", "confidence": 0.7722806930541992}, {"text": "WMT13 English-to-other language", "start_pos": 43, "end_pos": 74, "type": "DATASET", "confidence": 0.8628228108088175}]}], "tableCaptions": [{"text": " Table 1. The tuned weight values in LEPOR_v3.1 system", "labels": [], "entities": [{"text": "LEPOR", "start_pos": 37, "end_pos": 42, "type": "METRIC", "confidence": 0.9335539937019348}]}, {"text": " Table 2. The performances of nLEPOR_baseline and LEPOR_v3.1 systems on WMT11 corpora", "labels": [], "entities": [{"text": "WMT11 corpora", "start_pos": 72, "end_pos": 85, "type": "DATASET", "confidence": 0.914071649312973}]}, {"text": " Table 3. System-level Pearson correlation scores  on WMT13 English-to-other language pairs", "labels": [], "entities": [{"text": "Pearson correlation scores", "start_pos": 23, "end_pos": 49, "type": "METRIC", "confidence": 0.8702580332756042}, {"text": "WMT13 English-to-other language pairs", "start_pos": 54, "end_pos": 91, "type": "DATASET", "confidence": 0.8710708767175674}]}, {"text": " Table 4. System-level Spearman rank correlation  scores on WMT13 English-to-other language  pairs", "labels": [], "entities": [{"text": "Spearman rank correlation  scores", "start_pos": 23, "end_pos": 56, "type": "METRIC", "confidence": 0.6804752722382545}, {"text": "WMT13 English-to-other language  pairs", "start_pos": 60, "end_pos": 98, "type": "DATASET", "confidence": 0.8978201001882553}]}, {"text": " Table 5. Segment-level Kendall's tau correlation  scores on WMT13 English-to-other language  pairs", "labels": [], "entities": [{"text": "Segment-level Kendall's tau correlation", "start_pos": 10, "end_pos": 49, "type": "METRIC", "confidence": 0.6223704397678376}, {"text": "WMT13 English-to-other language  pairs", "start_pos": 61, "end_pos": 99, "type": "DATASET", "confidence": 0.9094439148902893}]}, {"text": " Table 6. System-level Pearson correlation scores  on WMT13 other-to-English language pairs", "labels": [], "entities": [{"text": "Pearson correlation scores", "start_pos": 23, "end_pos": 49, "type": "METRIC", "confidence": 0.8682848413785299}, {"text": "WMT13 other-to-English language pairs", "start_pos": 54, "end_pos": 91, "type": "DATASET", "confidence": 0.8430577367544174}]}, {"text": " Table 7. System-level Spearman rank correlation  scores on WMT13 other-to-English language  pairs", "labels": [], "entities": [{"text": "Spearman rank correlation  scores", "start_pos": 23, "end_pos": 56, "type": "METRIC", "confidence": 0.6788573712110519}, {"text": "WMT13 other-to-English language  pairs", "start_pos": 60, "end_pos": 98, "type": "DATASET", "confidence": 0.8633363544940948}]}]}