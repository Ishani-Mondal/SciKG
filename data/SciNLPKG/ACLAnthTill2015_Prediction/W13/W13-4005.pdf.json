{"title": [{"text": "Training an Integrated Sentence Planner on User Dialogue", "labels": [], "entities": []}], "abstractContent": [{"text": "An appealing methodology for natural language generation in dialogue systems is to train the system to match a target corpus.", "labels": [], "entities": [{"text": "natural language generation", "start_pos": 29, "end_pos": 56, "type": "TASK", "confidence": 0.6814843416213989}]}, {"text": "We show how users can provide such a corpus as a natural side effect of interacting with a prototype system, when the system uses mixed-initiative interaction and a reversible architecture to cover a domain familiar to users.", "labels": [], "entities": []}, {"text": "We experiment with integrated problems of sentence planning and realization in a referential communication task.", "labels": [], "entities": [{"text": "sentence planning and realization", "start_pos": 42, "end_pos": 75, "type": "TASK", "confidence": 0.732049971818924}]}, {"text": "Our model learns general and context-sensitive patterns to choose descriptive content, vocabulary, syntax and function words, and improves string match with user utterances to 85.8% from a hand-crafted baseline of 54.4%.", "labels": [], "entities": []}], "introductionContent": [{"text": "Natural language generation (NLG) in dialogue involves a complex array of choices.", "labels": [], "entities": [{"text": "Natural language generation (NLG)", "start_pos": 0, "end_pos": 33, "type": "TASK", "confidence": 0.7692426045735677}]}, {"text": "It's appealing to scale up NLG by training systems to make these choices with models derived from empirical data.", "labels": [], "entities": []}, {"text": "Sometimes, these choices have a measurable effect on the flow of the interaction.", "labels": [], "entities": []}, {"text": "Systems can plan such choices with a model of dialogue dynamics that predicts which utterances will fulfill communicative goals successfully and efficiently.", "labels": [], "entities": []}, {"text": "Other times, a wide variety of utterances work well (.", "labels": [], "entities": []}, {"text": "In these cases, systems can instead be designed simply to choose those utterances that most closely resemble specified target behavior.", "labels": [], "entities": []}, {"text": "This paper describes and evaluates anew data-driven methodology for training sentence planning and realization in interactive dialogue systems this way.", "labels": [], "entities": [{"text": "sentence planning and realization", "start_pos": 77, "end_pos": 110, "type": "TASK", "confidence": 0.7657433822751045}]}, {"text": "Our work is particularly inspired by, who train a dialogue sentence planner by annotating its possible outputs for quality; and Jordan and, who train a referring expression generator to match annotated human-human dialogue.", "labels": [], "entities": []}, {"text": "In text generation, researchers have been able to exploit automatic analysis of existing resources on such tasks as ordering words more naturally) and identifying named entities inline with attested mentions).", "labels": [], "entities": [{"text": "text generation", "start_pos": 3, "end_pos": 18, "type": "TASK", "confidence": 0.7969719767570496}]}, {"text": "However, previous work on training dialogue generation has involved the acquisition or annotation of relevant data ad hoc, for example by collecting humanhuman dialogue, running Wizard of Oz experiments, or rating system outputs.", "labels": [], "entities": [{"text": "training dialogue generation", "start_pos": 26, "end_pos": 54, "type": "TASK", "confidence": 0.7325821320215861}]}, {"text": "Our work is different: we use a bootstrapping approach that automatically mines interactions with a running prototype to adapt NLG to match users.", "labels": [], "entities": []}, {"text": "As described in Section 2, our work builds on the COREF system of.", "labels": [], "entities": [{"text": "COREF system", "start_pos": 50, "end_pos": 62, "type": "DATASET", "confidence": 0.8135134875774384}]}, {"text": "COREF and its users chat together to identify simple objects in a visual scene.", "labels": [], "entities": [{"text": "COREF", "start_pos": 0, "end_pos": 5, "type": "DATASET", "confidence": 0.8959498405456543}]}, {"text": "COREF is designed with reversible models of language and dialogue-it tracks users' utterances and its own utterances with the same data structures and represents them as updating the conversational state in parallel ways.", "labels": [], "entities": [{"text": "COREF", "start_pos": 0, "end_pos": 5, "type": "DATASET", "confidence": 0.8124931454658508}]}, {"text": "Because of this symmetry, COREF's understanding of each user utterance determines an input-output pair that the system could take as a target for NLG.", "labels": [], "entities": []}, {"text": "We explain the significance of learning from such data in Section 3.", "labels": [], "entities": []}, {"text": "However, we argue in Sections 4 and 5 that this learning will yield significant results only if system and user do in fact turnout to make similar contributions to dialogue.", "labels": [], "entities": []}, {"text": "Our main experiment therefore uses data collected with anew version of COREF with more flexible strategies for taking initiative, as described in Section 6.", "labels": [], "entities": [{"text": "COREF", "start_pos": 71, "end_pos": 76, "type": "DATASET", "confidence": 0.9043718576431274}]}, {"text": "We use the system's understanding of user utterances in the experiment, along with its productive capacity to generate alterna-tive paraphrases of those utterances, to build an automatically labeled training set of good and bad NLG examples.", "labels": [], "entities": []}, {"text": "We learn a model of the difference and evaluate its use in choosing novel utterances.", "labels": [], "entities": []}, {"text": "As documented in Section 7, the learned model leads to improvements in naturalness over COREF's handcrafted baseline generator; our experiments document these improvements qualitatively and quantitatively.", "labels": [], "entities": []}, {"text": "Our work suggests new ways to design dialogue systems to adhere to formal models with guaranteed behavior while reaping the benefits of data-driven approaches () by improving themselves through ongoing interactions with users.", "labels": [], "entities": []}, {"text": "Our experiments suggest that engaging with user expertise is a key factor in enabling such new design strategies.", "labels": [], "entities": []}, {"text": "Our technique crucially exploits synergies in our domain between the architecture of the dialogue system, the specific dialogue policy that the system implements, and users' abilities to contribute to domain problem solving.", "labels": [], "entities": [{"text": "domain problem solving", "start_pos": 201, "end_pos": 223, "type": "TASK", "confidence": 0.708335280418396}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Comparison of learned model and baseline generator.", "labels": [], "entities": []}, {"text": " Table 2: Comparison of accuracy by item.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 24, "end_pos": 32, "type": "METRIC", "confidence": 0.9938219785690308}]}, {"text": " Table 3: Sample features used to identify user tu- ples and their weights in an overall model.  Syntax Features:  Fits [ S DET N]  2.29  Fits [ S COLOR N]  2.09  Fits [ S DET COLOR N]  1.86  Fits [ S NP IS DET N]  1.12", "labels": [], "entities": [{"text": "NP IS DET N]  1.12", "start_pos": 201, "end_pos": 219, "type": "METRIC", "confidence": 0.5863995403051376}]}]}