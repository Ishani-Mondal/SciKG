{"title": [{"text": "Conditional Random Field-based Parser and Language Model for Traditional Chinese Spelling Checker", "labels": [], "entities": [{"text": "Traditional Chinese Spelling Checker", "start_pos": 61, "end_pos": 97, "type": "TASK", "confidence": 0.5066346749663353}]}], "abstractContent": [{"text": "This paper describes our Chinese spelling check system submitted to SIGHAN Bake-off 2013 evaluation.", "labels": [], "entities": [{"text": "SIGHAN Bake-off 2013 evaluation", "start_pos": 68, "end_pos": 99, "type": "DATASET", "confidence": 0.8313524946570396}]}, {"text": "The main idea is to exchange potential error character with its confusable ones and rescore the modified sentence using a conditional random field (CRF)-based word segmentation/part of speech (POS) tagger and a tri-gram language model (LM) to detect and correct possible spelling errors.", "labels": [], "entities": [{"text": "word segmentation/part of speech (POS) tagger", "start_pos": 159, "end_pos": 204, "type": "TASK", "confidence": 0.8491002678871155}]}, {"text": "Experimental results on the Bakeoff 2013 tasks showed the proposed method achieved 0.50 location detection and 0.24 error location F-scores in sub-task1 and 0.49 location and 0.40 correction accuracies and 0.40 correction precision in sub-task2.", "labels": [], "entities": [{"text": "Bakeoff 2013 tasks", "start_pos": 28, "end_pos": 46, "type": "DATASET", "confidence": 0.8436892032623291}, {"text": "error location F-scores", "start_pos": 116, "end_pos": 139, "type": "METRIC", "confidence": 0.9000434875488281}, {"text": "correction accuracies", "start_pos": 180, "end_pos": 201, "type": "METRIC", "confidence": 0.9530452489852905}, {"text": "correction precision", "start_pos": 211, "end_pos": 231, "type": "METRIC", "confidence": 0.8761274516582489}]}], "introductionContent": [{"text": "Chinese spelling check is a difficult task for two reasons: (1) there are no word delimiters between words, (2) the length of each word is usually only one to three characters long.", "labels": [], "entities": [{"text": "Chinese spelling check", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.6929618318875631}]}, {"text": "So it cannot be done within the word and must be solved within a context.", "labels": [], "entities": []}, {"text": "Therefore, Chinese spell checking is usually divided into two steps: (1) segmentation of text into word sequence and (2) error checking of each word in sentence level.", "labels": [], "entities": [{"text": "Chinese spell checking", "start_pos": 11, "end_pos": 33, "type": "TASK", "confidence": 0.6675583819548289}, {"text": "segmentation of text into word sequence", "start_pos": 73, "end_pos": 112, "type": "TASK", "confidence": 0.8004504243532816}]}, {"text": "Basically, word segmentation can be formulated as a sequential learning problem.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 11, "end_pos": 28, "type": "TASK", "confidence": 0.7761608064174652}]}, {"text": "In the past decade, many statistical methods, such as support vector machine (SVM), conditional random field (CRF)), maximum entropy Markov models (MEMMs), were proposed by NLP researchers to handle this sequential learning task.", "labels": [], "entities": []}, {"text": "Among them, CRF-based approach has been shown to be effective with very low computational complexity.", "labels": [], "entities": []}, {"text": "On the other hand, error checking could be treated as an abnormal word sequence detection problem and is often based on language knowledge, and mainly includes rule-based methods and statistic-based methods.", "labels": [], "entities": [{"text": "error checking", "start_pos": 19, "end_pos": 33, "type": "TASK", "confidence": 0.7758619487285614}, {"text": "word sequence detection", "start_pos": 66, "end_pos": 89, "type": "TASK", "confidence": 0.6647109488646189}]}, {"text": "Rule-based methods use rule sets, which describe some exact dictionary knowledge such as word or character frequency, POS information and some other syntax or morphological features of a language, to detect dubious areas and generate candidate words list.", "labels": [], "entities": []}, {"text": "This kind of methods achieves significant success in some special domains, but it is difficult to deal with open natural language.", "labels": [], "entities": []}, {"text": "On the other hand, statistic-based methods often use a language model that is achieved by using some language knowledge and analyzing a huge of language phenomena on large corpus so more context information is utilized, and this kind of methods is suitable for general domains.", "labels": [], "entities": []}, {"text": "There are many advanced Chinese spelling check methods).", "labels": [], "entities": []}, {"text": "However, from the viewpoint of automatic speech recognition (ASR) research, the word segmentation and LM are the most important modules for ASR studies.", "labels": [], "entities": [{"text": "automatic speech recognition (ASR)", "start_pos": 31, "end_pos": 65, "type": "TASK", "confidence": 0.8177493810653687}, {"text": "word segmentation", "start_pos": 80, "end_pos": 97, "type": "TASK", "confidence": 0.6950053572654724}, {"text": "ASR", "start_pos": 140, "end_pos": 143, "type": "TASK", "confidence": 0.9936873316764832}]}, {"text": "Especially, it is known that a good LM can significantly improve ASR's recognition performance.", "labels": [], "entities": [{"text": "ASR's recognition", "start_pos": 65, "end_pos": 82, "type": "TASK", "confidence": 0.6503733098506927}]}, {"text": "And a sophisticated parser is required for building highly effective LM.", "labels": [], "entities": []}, {"text": "So, in past few years, lots of works were conducted in our laboratory to build a CRF-based word segmentation/POS tagger and a trigram LM to improve the performance of ASR.", "labels": [], "entities": [{"text": "CRF-based word segmentation/POS tagger", "start_pos": 81, "end_pos": 119, "type": "TASK", "confidence": 0.6613763819138209}, {"text": "ASR", "start_pos": 167, "end_pos": 170, "type": "TASK", "confidence": 0.972687304019928}]}, {"text": "Although, we have already applied our parser and LM to ASR and achieved many successes, we would like to take the chance of Bakeoff 2013 evaluation to examine again how generalization and sophistication our parser and LM are.", "labels": [], "entities": [{"text": "ASR", "start_pos": 55, "end_pos": 58, "type": "TASK", "confidence": 0.9292122721672058}, {"text": "Bakeoff 2013 evaluation", "start_pos": 124, "end_pos": 147, "type": "DATASET", "confidence": 0.8404261867205302}]}, {"text": "Therefore, the focus of this paper is on how to integrate our parser and LM originally built for ASR to deal with the Chinese spelling check task.", "labels": [], "entities": [{"text": "ASR", "start_pos": 97, "end_pos": 100, "type": "TASK", "confidence": 0.9567947387695312}, {"text": "Chinese spelling check task", "start_pos": 118, "end_pos": 145, "type": "TASK", "confidence": 0.6395948678255081}]}], "datasetContent": [{"text": "Two configurations of our system (Run1 and Run2) were tested.", "labels": [], "entities": []}, {"text": "Run1 applied only the rulebased frontend.", "labels": [], "entities": [{"text": "Run1", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.8932846784591675}]}, {"text": "Run2 utilized the whole system.", "labels": [], "entities": [{"text": "Run2", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.9602741003036499}]}, {"text": "The performances of the proposed spelling check method are shown in and 4.", "labels": [], "entities": [{"text": "spelling check", "start_pos": 33, "end_pos": 47, "type": "TASK", "confidence": 0.919430285692215}]}, {"text": "From, it can be found that Run1 has very low false alarm and recall rates, but higher accuracy in error detection.", "labels": [], "entities": [{"text": "Run1", "start_pos": 27, "end_pos": 31, "type": "DATASET", "confidence": 0.819629967212677}, {"text": "recall rates", "start_pos": 61, "end_pos": 73, "type": "METRIC", "confidence": 0.9393307864665985}, {"text": "accuracy", "start_pos": 86, "end_pos": 94, "type": "METRIC", "confidence": 0.9994831085205078}, {"text": "error detection", "start_pos": 98, "end_pos": 113, "type": "TASK", "confidence": 0.6423894762992859}]}, {"text": "The reason is that it only modified few errors with high confidence.", "labels": [], "entities": []}, {"text": "Run2 has much higher false alarm and recall rates, but lower accuracy, since it tried to change as much as possible errors and may introduce overkill.", "labels": [], "entities": [{"text": "Run2", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.9274295568466187}, {"text": "recall rates", "start_pos": 37, "end_pos": 49, "type": "METRIC", "confidence": 0.9698760807514191}, {"text": "accuracy", "start_pos": 61, "end_pos": 69, "type": "METRIC", "confidence": 0.9995012283325195}]}, {"text": "However, in general, Run2 has better Fscore than Run1.", "labels": [], "entities": [{"text": "Run2", "start_pos": 21, "end_pos": 25, "type": "DATASET", "confidence": 0.8102219104766846}, {"text": "Fscore", "start_pos": 37, "end_pos": 43, "type": "METRIC", "confidence": 0.999396800994873}]}, {"text": "Furthermore, also shows that Run2 has higher location and correction accuracies (although it has lower correction precision than Run1).", "labels": [], "entities": [{"text": "Run2", "start_pos": 29, "end_pos": 33, "type": "DATASET", "confidence": 0.7933708429336548}, {"text": "correction accuracies", "start_pos": 58, "end_pos": 79, "type": "METRIC", "confidence": 0.8760894536972046}, {"text": "correction precision", "start_pos": 103, "end_pos": 123, "type": "METRIC", "confidence": 0.8832694590091705}]}, {"text": "These results show the benefits of combining CRF-based parser and LM in the second stage of spelling check system.: Evaluation results of the proposed system on Bakeoff 2013 sub-task 2.", "labels": [], "entities": [{"text": "spelling check", "start_pos": 92, "end_pos": 106, "type": "TASK", "confidence": 0.8291460275650024}, {"text": "Bakeoff 2013 sub-task 2", "start_pos": 161, "end_pos": 184, "type": "DATASET", "confidence": 0.9286971241235733}]}, {"text": "There are 1000 test sentences.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 3: Evaluation results of the proposed system on  Bakeoff 2013 sub-task 1: (a) detection error rates, (b)  location error rates on 1000 test sentences.", "labels": [], "entities": [{"text": "Bakeoff 2013", "start_pos": 56, "end_pos": 68, "type": "DATASET", "confidence": 0.8746587336063385}]}, {"text": " Table 4: Evaluation results of the proposed system on  Bakeoff 2013 sub-task 2. There are 1000 test sentenc- es.", "labels": [], "entities": [{"text": "Bakeoff 2013 sub-task", "start_pos": 56, "end_pos": 77, "type": "DATASET", "confidence": 0.9386068185170492}]}]}