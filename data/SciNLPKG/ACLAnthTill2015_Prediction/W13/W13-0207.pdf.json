{"title": [{"text": "Logic Programs vs. First-Order Formulas in Textual Inference", "labels": [], "entities": []}], "abstractContent": [{"text": "In the problem of recognizing textual entailment, the goal is to decide, given a text and a hypothesis expressed in a natural language, whether a human reasoner would call the hypothesis a consequence of the text.", "labels": [], "entities": [{"text": "recognizing textual entailment", "start_pos": 18, "end_pos": 48, "type": "TASK", "confidence": 0.8522817095120748}]}, {"text": "One approach to this problem is to use a first-order reasoning tool to check whether the hypothesis can be derived from the text conjoined with relevant background knowledge, after expressing all of them by first-order formulas.", "labels": [], "entities": []}, {"text": "Another possibility is to express the hypothesis, the text, and the background knowledge in a logic programming language, and use a logic programming system.", "labels": [], "entities": []}, {"text": "We discuss the relation of these methods to each other and to the class of effectively propositional reasoning problems.", "labels": [], "entities": []}, {"text": "This leads us to general conclusions regarding the relationship between classical logic and answer set programming as knowledge representation formalisms.", "labels": [], "entities": []}], "introductionContent": [{"text": "In the problem of recognizing textual entailment, the goal is to decide, given a text T and a hypothesis H expressed in a natural language, whether a human reasoner would call Ha consequence of T . T : The World Bank has also been criticized for its role in financing projects that have been detrimental to human rights and the natural environment.", "labels": [], "entities": [{"text": "recognizing textual entailment", "start_pos": 18, "end_pos": 48, "type": "TASK", "confidence": 0.767120897769928}]}], "datasetContent": [{"text": "Recall that Bos and Markert recognize textual entailment by determining whether implication is logically valid.", "labels": [], "entities": []}, {"text": "In many cases, the negation of formula (1) can be converted to a prenex form with all existential quantifiers in front of the universal quantifiers (\"\u2203\u2200-prenex form\").", "labels": [], "entities": []}, {"text": "Then the sentence F , obtained from this prenex form by Skolemization and then converting the quantifier-free part to conjunctive normal form, is an EPR formula.", "labels": [], "entities": []}, {"text": "It is clear that (1) is logically valid iff F is unsatisfiable.", "labels": [], "entities": []}, {"text": "The possibility of converting to \u2203\u2200-prenex form is essential because it guarantees that no function constants of arity > 0 are introduced in the process of Skolemization.", "labels": [], "entities": [{"text": "Skolemization", "start_pos": 156, "end_pos": 169, "type": "TASK", "confidence": 0.721306562423706}]}, {"text": "It is clear that conjunction (5) can be written in \u2203\u2200-prenex form if every conjunctive term can be written in this form.", "labels": [], "entities": []}, {"text": "How restrictive is this requirement?", "labels": [], "entities": []}, {"text": "The website shown in Footnote 1 gives the first-order formulas corresponding to 799 textual entailment problems from the second PASCAL collection that were produced by Nutcracker.", "labels": [], "entities": [{"text": "Footnote", "start_pos": 21, "end_pos": 29, "type": "DATASET", "confidence": 0.8703718185424805}, {"text": "PASCAL collection", "start_pos": 128, "end_pos": 145, "type": "DATASET", "confidence": 0.8450229465961456}]}, {"text": "In 711 cases (89%), both T and \u00acH can be converted to \u2203\u2200-prenex form.", "labels": [], "entities": []}, {"text": "The conjunctive terms of BK come from two sources: most are automatically extracted from WordNet, the others are hand-coded.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 89, "end_pos": 96, "type": "DATASET", "confidence": 0.9792807698249817}]}, {"text": "All conjunctive terms of the first kind are universal sentences, so that each of them is \u2203\u2200-prenex.", "labels": [], "entities": []}, {"text": "Among the hand-coded parts of BK that Bos and Markert chose to include we found several exceptions, but they are never essential: dropping the \"difficult\" hand-coded part of BK from any of the 711 implications (1) that we have studied never makes a logically valid formula invalid.", "labels": [], "entities": [{"text": "BK", "start_pos": 30, "end_pos": 32, "type": "DATASET", "confidence": 0.931110143661499}]}, {"text": "The model builder PARADOX terminates, in principle, on any EPR formula; it generates a model if the formula is satisfiable, and reports that it is unsatisfiable otherwise.", "labels": [], "entities": [{"text": "PARADOX", "start_pos": 18, "end_pos": 25, "type": "METRIC", "confidence": 0.6215522289276123}]}, {"text": "For this reason, in each of the 711 cases (with the inessential \"difficult\" terms dropped) Bos and Markert would be able to test the formula for satisfiability by running PARADOX alone, without invoking also the theorem prover VAMPIRE.", "labels": [], "entities": [{"text": "PARADOX", "start_pos": 171, "end_pos": 178, "type": "METRIC", "confidence": 0.5061353445053101}, {"text": "VAMPIRE", "start_pos": 227, "end_pos": 234, "type": "METRIC", "confidence": 0.5489988923072815}]}, {"text": "In these 711 cases we could also test the logical validity of by running the answer set solver DLV, as described in the previous section.", "labels": [], "entities": [{"text": "validity", "start_pos": 50, "end_pos": 58, "type": "METRIC", "confidence": 0.9163172841072083}, {"text": "answer set solver DLV", "start_pos": 77, "end_pos": 98, "type": "TASK", "confidence": 0.6231082901358604}]}, {"text": "Interestingly, the runtime of DLV was smaller than the runtime of the model builder PARADOX inmost cases, even though DLV did some redundant work: whenever the program \u03c0(F ) has a model, it computed one of its minimal models.", "labels": [], "entities": []}, {"text": "We should add that all these runtimes are pretty small, usually less than a second.", "labels": [], "entities": []}, {"text": "The main computational difference between model builders, such as PARADOX, and answer set solvers, such as DLV, is that model builders typically start by looking fora finite model with a small universe (say, a singleton); if there is no such model then search is extended to larger universes.", "labels": [], "entities": [{"text": "answer set solvers", "start_pos": 79, "end_pos": 97, "type": "TASK", "confidence": 0.6330054799715678}]}, {"text": "If the input is an EPR formula containing N object constants, then answer set solvers ground the given program with the universe of size N , which means essentially that they only look fora model of cardinality N . Good answer set solvers, such as DLV, perform grounding \"intelligently\" and sometimes introduce auxiliary predicates that make the size of the grounded program smaller.", "labels": [], "entities": []}, {"text": "It is interesting also that among the 711 EPR formulas from Nutcracker experiments that we have investigated, 514 are Horn-all their conjunctive terms (2) are definite (n = m + 1) or negative (n = m).", "labels": [], "entities": []}, {"text": "If F is a Horn EPR formula then the program \u03c0(F ) is nondisjunctive; since there is no negation in this program, it can have at most one stable model.", "labels": [], "entities": []}, {"text": "Note that deciding whether aground nondisjunctive program without negation has a model can be done in linear time.", "labels": [], "entities": []}], "tableCaptions": []}