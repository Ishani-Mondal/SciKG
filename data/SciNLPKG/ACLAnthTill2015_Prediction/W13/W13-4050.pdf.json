{"title": [{"text": "Spoken Dialog Systems for Automated Survey Interviewing", "labels": [], "entities": [{"text": "Spoken Dialog", "start_pos": 0, "end_pos": 13, "type": "TASK", "confidence": 0.8508998453617096}, {"text": "Automated Survey Interviewing", "start_pos": 26, "end_pos": 55, "type": "TASK", "confidence": 0.6180843015511831}]}], "abstractContent": [{"text": "We explore the plausibility of using automated spoken dialog systems (SDS) for administering survey interviews.", "labels": [], "entities": []}, {"text": "Because the goals of a survey dialog system differ from more traditional information-seeking and transactional applications, different measures of task accuracy and success maybe warranted.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 152, "end_pos": 160, "type": "METRIC", "confidence": 0.9723308086395264}]}, {"text": "We report a large-scale experimental evaluation of an SDS that administered survey interviews with questions drawn from government and social scientific surveys.", "labels": [], "entities": []}, {"text": "We compare two dialog confirmation strategies: (1) a traditional strategy of explicit confirmation on low-confidence recognition; and (2) no confirmation.", "labels": [], "entities": [{"text": "dialog confirmation", "start_pos": 15, "end_pos": 34, "type": "TASK", "confidence": 0.765039473772049}, {"text": "low-confidence recognition", "start_pos": 102, "end_pos": 128, "type": "TASK", "confidence": 0.6830822229385376}]}, {"text": "With explicit confirmation, the small percentage of residual errors had little to no impact on survey data measurement.", "labels": [], "entities": []}, {"text": "Even without confirmation, while there are significantly more errors, impact on the substantive conclusions of the survey is still very limited.", "labels": [], "entities": []}], "introductionContent": [{"text": "Survey interviews play a critical role in the operation of government and commerce.", "labels": [], "entities": []}, {"text": "Large-scale social scientific surveys provide key indicators of the successor failure of economic and social policies, driving critical policy and funding decisions.", "labels": [], "entities": []}, {"text": "Market research surveys are key in evaluating products and services for business.", "labels": [], "entities": []}, {"text": "Survey interviews are typically conducted either via telephone or face-to-face by skilled human interviewers.", "labels": [], "entities": []}, {"text": "But ongoing changes in communication technology threaten the viability of these methods.", "labels": [], "entities": []}, {"text": "As people migrate from landline telephony to mobile-only  and Voice-over-IP as primary modes of communication, they undermine the effectiveness of traditional survey sampling techniques that rely on random selection of numbers within a dial code.", "labels": [], "entities": []}, {"text": "Telephone respondents were once reachable at a fixed geographic location in a largely predictable conversational environment.", "labels": [], "entities": []}, {"text": "Now they are increasingly mobile, and more apt to prefer asynchronous communication.", "labels": [], "entities": []}, {"text": "Thus it is imperative to understand how these changing behaviors affect survey results.", "labels": [], "entities": []}, {"text": "The work described here is part of a larger research project (see) that investigates the viability of four different modes for administering a survey interview over a smartphone: automated voice, human voice, automated SMS text, and human SMS text.", "labels": [], "entities": []}, {"text": "Here we focus specifically on the automated voice mode and explore the use of a spoken dialog system for survey administration.", "labels": [], "entities": [{"text": "survey administration", "start_pos": 105, "end_pos": 126, "type": "TASK", "confidence": 0.6569547653198242}]}, {"text": "Spoken dialog systems are widely used in telephony applications such as customer service, information access, and transaction fulfillment.", "labels": [], "entities": [{"text": "information access", "start_pos": 90, "end_pos": 108, "type": "TASK", "confidence": 0.7530811429023743}, {"text": "transaction fulfillment", "start_pos": 114, "end_pos": 137, "type": "TASK", "confidence": 0.7469839453697205}]}, {"text": "They are also now common in virtual assistant applications for smartphones and mobile devices.", "labels": [], "entities": []}, {"text": "But survey designers seeking automation have mostly eschewed spoken dialog in favor of textual web surveys or touchtone DTMF response systems.", "labels": [], "entities": []}, {"text": "A preliminary comparison of spoken dialog and touchtone survey systems is available in, and offer an evaluation of a spoken dialog system for academic course ratings.", "labels": [], "entities": []}, {"text": "The work presented here describes the first large-scale investigation into spoken dialog technology as a viable means of administering the kinds of surveys that produce official statistics and social scientific data.", "labels": [], "entities": []}, {"text": "Survey interview designers should be interested in using spoken dialog systems for several reasons.", "labels": [], "entities": []}, {"text": "The most obvious reason is to curtail the error and bias that human interviewers are known to introduce to survey results data.", "labels": [], "entities": [{"text": "error", "start_pos": 42, "end_pos": 47, "type": "METRIC", "confidence": 0.9793264865875244}]}, {"text": "Decades of research and investment led to \"standardized interviewing techniques\" to reduce this error, and limit a survey interviewer's ability to offer help or clarification in ways that might affect results.", "labels": [], "entities": []}, {"text": "Automated dialog systems can bethought of as the ultimate in standardization, as they can be designed to provide exactly the same interaction possibilities to all respondents.", "labels": [], "entities": [{"text": "standardization", "start_pos": 61, "end_pos": 76, "type": "TASK", "confidence": 0.8866158723831177}]}, {"text": "In effect, everyone can be interviewed by the same \"interviewer.\"", "labels": [], "entities": []}, {"text": "Or, if survey designers want to allow clarification in an interview, an automated spoken dialog system can ensure that the same possibilities are available to all respondents (.", "labels": [], "entities": []}, {"text": "Unlike systems that use human interviewers, there is marginal additional cost per interview after the initial investment of building a system.", "labels": [], "entities": []}, {"text": "This offers significant potential for cost savings in large cross-sectional samples or repeated panel surveys, such as the U.S. Current Population Survey or the American Community Survey.", "labels": [], "entities": [{"text": "U.S. Current Population Survey", "start_pos": 123, "end_pos": 153, "type": "DATASET", "confidence": 0.5932217314839363}, {"text": "American Community Survey", "start_pos": 161, "end_pos": 186, "type": "DATASET", "confidence": 0.9057921369870504}]}, {"text": "Repeated data collection allows refinement and retraining of speech models to improve performance.", "labels": [], "entities": []}, {"text": "Spoken dialog system surveys can be administered on demand at anytime of day, allowing a better fit with respondents' circumstances and schedules.", "labels": [], "entities": []}, {"text": "Compared to asynchronous text-based interviews like web or paperand-pencil surveys, spoken dialog systems can capture richer verbal paradata) or process data like pauses, disfluencies and prosody ( ).", "labels": [], "entities": []}, {"text": "Finally, survey tasks fit nicely within the limitations of current recognition and dialog technology, since they tend to have a purposefully structured and controlled interaction flow and generally require only a limited number of responses to each question.", "labels": [], "entities": []}, {"text": "While spoken dialog systems have the potential to remove data error that is introduced by variation inhuman interviewer behaviors, they also introduce risks to survey data quality due to speech recognition and understanding error.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 187, "end_pos": 205, "type": "TASK", "confidence": 0.7118699252605438}]}, {"text": "Numerous strategies for mitigating error have been explored in research on dialog systems).", "labels": [], "entities": []}, {"text": "One approach is to use either an explicit or implicit confirmation of the user's input.", "labels": [], "entities": []}, {"text": "Following previous research showing that explicit confirmation is less confusing for users (, we adopt an explicit confirmation strategy, which is also more in keeping with standardized interview techniques.", "labels": [], "entities": []}, {"text": "The effects of speech recognition and understanding errors maybe different in a survey dialog system than inmost current spoken dialog applications.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 15, "end_pos": 33, "type": "TASK", "confidence": 0.7551615238189697}]}, {"text": "One consideration is speaker initiative, and the stake of the user in the interaction.", "labels": [], "entities": []}, {"text": "In systems for customer service, information access, or transactions, the user generally initiates contact with the system and seeks to accomplish a task where the system's recognition accuracy will affect success of the user's own goal.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 185, "end_pos": 193, "type": "METRIC", "confidence": 0.7629510164260864}]}, {"text": "But in a survey dialog, the system initiates contact, and most respondents do not have a stake in whether the designers of the survey system succeed at collecting high quality data from them.", "labels": [], "entities": []}, {"text": "This is a key point where a survey interviewing system might differ from traditional SDS: From the survey researchers' perspective, the critical question is not whether individual users achieve some goal, but rather the extent to which individual errors in system recognition and understanding affect the distribution of responses across the population sample, affecting the quality of the estimates produced.", "labels": [], "entities": []}, {"text": "If recognition errors do not affect the substantive conclusions based on the survey data, then survey researchers should be able to tolerate the imprecision of recognition error.", "labels": [], "entities": []}, {"text": "This situation makes survey system evaluation rather different from how one would expect to evaluate the task success of a traditional SDS, like a customer service system.", "labels": [], "entities": []}, {"text": "In Section 2, we characterize the content of the survey items, describe the dialog strategy, and provide examples of interaction.", "labels": [], "entities": []}, {"text": "Section 3 describes the technical architecture of the survey dialog system.", "labels": [], "entities": []}, {"text": "We provide experimental evaluation in Section 4, and conclusions in Section 5.", "labels": [], "entities": []}], "datasetContent": [{"text": "We evaluated the survey dialog system as part of the first phase of a larger experiment comparing different survey interaction modes ().", "labels": [], "entities": []}, {"text": "In this phase, 642 subjects were recruited from Craigslist, Facebook, Google Ads, and Amazon Mechanical Turk.", "labels": [], "entities": []}, {"text": "A web-based screener application verified respondents to be over 21 and collected their zip code.", "labels": [], "entities": []}, {"text": "Of these, 158 respondents were randomly assigned to the automated voice condition.", "labels": [], "entities": []}, {"text": "A $20 iTunes gift card was given as an incentive after completion of a post-interview web questionnaire.", "labels": [], "entities": []}, {"text": "This included multiple-choice questions examining user satisfaction with their experience.", "labels": [], "entities": []}, {"text": "In total there were 8,228 spoken inputs over the 158 respondent dialogs.", "labels": [], "entities": []}, {"text": "These responses were transcribed, coded, and annotated for semantic content.", "labels": [], "entities": []}, {"text": "The questions we sought to answer were: What is the performance of a spoken dialog system on atypical survey task?", "labels": [], "entities": []}, {"text": "What impact does speech recognition and concept error have on overall survey estimates?", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 17, "end_pos": 35, "type": "TASK", "confidence": 0.8029977679252625}]}, {"text": "Does an automated survey system benefit from implementing a traditional confirmation strategy, where responses with low confidence scores are verified with confirmation dialog?", "labels": [], "entities": []}, {"text": "We also examine the impact of dialog length and confirmation prompts on a qualitative measure of user satisfaction.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: User satisfaction regression", "labels": [], "entities": [{"text": "User satisfaction regression", "start_pos": 10, "end_pos": 38, "type": "TASK", "confidence": 0.6506814757982889}]}]}