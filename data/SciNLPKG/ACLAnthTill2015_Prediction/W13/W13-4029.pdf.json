{"title": [{"text": "Exploring the effects of gaze and pauses in situated human-robot interaction", "labels": [], "entities": []}], "abstractContent": [{"text": "In this paper, we present a user study where a robot instructs a human on how to draw a route on a map, similar to a Map Task.", "labels": [], "entities": []}, {"text": "This setup has allowed us to study user reactions to the robot's conversational behaviour in order to get a better understanding of how to generate utterances in incremental dialogue systems.", "labels": [], "entities": []}, {"text": "We have analysed the participants' subjective rating, task completion, verbal responses, gaze behaviour, drawing activity, and cognitive load.", "labels": [], "entities": []}, {"text": "The results show that users utilise the ro-bot's gaze in order to disambiguate referring expressions and manage the flow of the interaction.", "labels": [], "entities": []}, {"text": "Furthermore, we show that the user's behaviour is affected by how pauses are real-ised in the robot's speech.", "labels": [], "entities": []}], "introductionContent": [{"text": "Dialogue systems have traditionally relied on several simplifying assumptions.", "labels": [], "entities": []}, {"text": "When it comes to temporal resolution, the interaction has been assumed to take place with a strict turn-taking protocol, where each speaker takes discrete turns with noticeable gaps in between.", "labels": [], "entities": [{"text": "temporal resolution", "start_pos": 17, "end_pos": 36, "type": "TASK", "confidence": 0.7240264266729355}]}, {"text": "While this assumption simplifies processing, it fails to model many aspects of human-human interaction such as turn-taking with very short gaps or brief overlaps and backchannels in the middle of utterances.", "labels": [], "entities": []}, {"text": "Recently, researchers have turned to more incremental models, where the dialogue is processed in smaller units ().", "labels": [], "entities": []}, {"text": "On the output side, this allows dialogue systems to start speaking before processing is complete, generating and synthesizing the response segment by segment, until the complete response is realised.", "labels": [], "entities": []}, {"text": "If a segment is delayed, there will be a pause in the middle of the system's speech.", "labels": [], "entities": []}, {"text": "While previous studies have clearly shown the potential benefits of incremental speech generation, there are few studies on how users react to pauses in the middle of the system's speech.", "labels": [], "entities": [{"text": "speech generation", "start_pos": 80, "end_pos": 97, "type": "TASK", "confidence": 0.7943196296691895}]}, {"text": "Apart from the real-time nature of spoken interaction, spoken dialog technology has fora longtime also neglected the physical space in which the interaction takes place.", "labels": [], "entities": []}, {"text": "In application scenarios which involve situated interaction, such as human-robot interaction, there might be several users talking to the system at the same time, and there might be physical objects in the surroundings that the user and the system refer to during the interaction ().", "labels": [], "entities": []}, {"text": "In such settings, gaze plays a very important role in the coordination of joint attention and turn-taking.", "labels": [], "entities": []}, {"text": "However, it is not clear to what extent humans are able to utilize the gaze of a robot and respond to these cues.", "labels": [], "entities": []}, {"text": "Here, we present a user study where a robot instructs a human on how to draw a route on a map, similar to a Map Task.", "labels": [], "entities": []}, {"text": "The nature of this setting allows us to study the two phenomena outlined above.", "labels": [], "entities": []}, {"text": "First, we want to understand how a face-to-face setting facilitates coordination of actions between a robot and a user, and how well humans can utilize the robot's gaze to disambiguate referring expressions in situated interaction.", "labels": [], "entities": []}, {"text": "The second purpose of this study is to investigate how the system can either inhibitor encourage different types of user reactions while pausing by using filled pauses, gaze and syntactic completeness.", "labels": [], "entities": []}], "datasetContent": [{"text": "In addition to the utterance-level conditions (concerning completeness) described above, three dialogue-level conditions were implemented: CONSISTENT gaze (FACE): The robot gazes at the landmark that is currently being described during the phases Part I, Pause and Part II.", "labels": [], "entities": [{"text": "CONSISTENT gaze (FACE)", "start_pos": 139, "end_pos": 161, "type": "METRIC", "confidence": 0.8852108240127563}]}, {"text": "In accordance with the findings in for example, the robot looks up at the end of phase Part II, seeking mutual gaze with the user during the Release phase.", "labels": [], "entities": []}, {"text": "RANDOM gaze (FACE): A random gaze behaviour, where the robot randomly shifts between looking at the map (at no particular landmark) and looking at the user, with an interval of 5-10 seconds.", "labels": [], "entities": [{"text": "RANDOM gaze (FACE)", "start_pos": 0, "end_pos": 18, "type": "METRIC", "confidence": 0.8042802929878234}]}], "tableCaptions": []}