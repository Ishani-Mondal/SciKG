{"title": [{"text": "Automatic Metaphor Detection using Large-Scale Lexical Resources and Conventional Metaphor Extraction", "labels": [], "entities": [{"text": "Automatic Metaphor Detection", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.6173425018787384}, {"text": "Conventional Metaphor Extraction", "start_pos": 69, "end_pos": 101, "type": "TASK", "confidence": 0.6511794130007426}]}], "abstractContent": [{"text": "The paper presents an experimental algorithm to detect conventionalized metaphors implicit in the lexical data in a resource like WordNet, where metaphors are coded into the senses and so would never be detected by any algorithm based on the violation of preferences, since there would always be a constraint satisfied by such senses.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 130, "end_pos": 137, "type": "DATASET", "confidence": 0.9491975903511047}]}, {"text": "We report an implementation of this algorithm, which was implemented first the preference constraints in VerbNet.", "labels": [], "entities": [{"text": "VerbNet", "start_pos": 105, "end_pos": 112, "type": "DATASET", "confidence": 0.9550390243530273}]}, {"text": "We then derived in a systematic way afar more extensive set of constraints based on WordNet glosses, and with this data we reimplemented the detection algorithm and got a substantial improvement in recall.", "labels": [], "entities": [{"text": "WordNet glosses", "start_pos": 84, "end_pos": 99, "type": "DATASET", "confidence": 0.9359961152076721}, {"text": "recall", "start_pos": 198, "end_pos": 204, "type": "METRIC", "confidence": 0.998432457447052}]}, {"text": "We suggest that this technique could contribute to improve the performance of existing metaphor detection strategies that do not attempt to detect convention-alized metaphors.", "labels": [], "entities": [{"text": "metaphor detection", "start_pos": 87, "end_pos": 105, "type": "TASK", "confidence": 0.7707159221172333}]}, {"text": "The new WordNet-derived data is of wider significance because it also contains adjective constraints, unlike any existing lexical resource, and can be applied to any language with a semantic parser (and WN) for it.", "labels": [], "entities": [{"text": "WordNet-derived data", "start_pos": 8, "end_pos": 28, "type": "DATASET", "confidence": 0.9503208696842194}]}], "introductionContent": [{"text": "Metaphor is ubiquitous in standard language; it is not a fringe or add-on phenomenon.", "labels": [], "entities": []}, {"text": "The work described concerns detecting and interpreting metaphor on a large scale in corpora.", "labels": [], "entities": [{"text": "detecting and interpreting metaphor", "start_pos": 28, "end_pos": 63, "type": "TASK", "confidence": 0.6736059784889221}]}, {"text": "If metaphor is ubiquitous, then locating and interpreting it must be central to any NLP project that aims to understand general language.", "labels": [], "entities": []}, {"text": "This paper focuses on the initial phase of detection: the identification in text of conceptual combinations that might be deemed metaphoric by a pre-theoretic observer, e.g., \"Brazil has economic muscle\", \"Tom is a brick\", or \"The unions have built a fortress round their pensions\".", "labels": [], "entities": []}, {"text": "There is along cultural tradition of describing and interpreting such phenomena but our goal here is computational: to provide criteria for automatically detecting such cases as candidates for further analysis and interpretation.", "labels": [], "entities": []}, {"text": "The key fact is that metaphors are sometimes new and fresh but can be immediately understood: producing them is often the role of poets, creative journalists and writers of all kinds.", "labels": [], "entities": []}, {"text": "But many are simply part of the history of the language, and are novel only to those who do not happen to know them already: for example \"Tom is a brick\" -taken to mean that he is a reliable man, but which cannot be literally true -is actually encoded as a sense of brick in WordNet (WN) even though it is more familiar to UK than US English speakers.", "labels": [], "entities": [{"text": "WordNet (WN)", "start_pos": 275, "end_pos": 287, "type": "DATASET", "confidence": 0.87031589448452}]}, {"text": "This means that lexical resources already contain conventionalized metaphors.", "labels": [], "entities": []}, {"text": "We propose a simple method for locating and extracting these into the metaphor candidate pool, even when they are not indicated as such in resources like WN (which marks figurative senses very infrequently, unlike some traditional dictionaries).", "labels": [], "entities": []}, {"text": "However, we believe these implicit metaphors in WN -a resource we intend to use as a semantic/lexical database, though transformed as we shall show belowcan be extracted by a simple algorithm, and without any need fora priori distinction of literal versus metaphorical.", "labels": [], "entities": []}, {"text": "That distinction, as we noted, depends to a large degree on the temporal snapshot of a language; e.g., no one now would think \"taking a decision\" was metaphor, even though decisions are not literally taken anywhere.", "labels": [], "entities": []}, {"text": "In this paper, we shall present an algorithm for conventionalized metaphor detection, and show results over a standard corpus of examples that demonstrate a possible useful gain in recall of metaphors, our original aim.", "labels": [], "entities": [{"text": "conventionalized metaphor detection", "start_pos": 49, "end_pos": 84, "type": "TASK", "confidence": 0.840688149134318}]}, {"text": "The algorithm is described in two implementations (or pipelines) corresponding, respectively, to the use of WN and VerbNet ( as semantic knowledge-bases, and to their replacement by our automatically recomputed form of WN, which enables predictions about the preference behavior (see below) of English verbs and adjectives to be better founded than in VerbNet (VN) and on a much larger scale.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": []}