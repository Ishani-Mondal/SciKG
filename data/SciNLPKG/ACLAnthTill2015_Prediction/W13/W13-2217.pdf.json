{"title": [], "abstractContent": [{"text": "We describe the Stanford University NLP Group submission to the 2013 Workshop on Statistical Machine Translation Shared Task.", "labels": [], "entities": [{"text": "Statistical Machine Translation Shared Task", "start_pos": 81, "end_pos": 124, "type": "TASK", "confidence": 0.8576348304748536}]}, {"text": "We demonstrate the effectiveness of anew adaptive, online tuning algorithm that scales to large feature and tuning sets.", "labels": [], "entities": []}, {"text": "For both English-French and English-German, the algorithm produces feature-rich models that improve over a dense baseline and compare favorably to models tuned with established methods.", "labels": [], "entities": []}], "introductionContent": [{"text": "describe an online, adaptive tuning algorithm for feature-rich translation models.", "labels": [], "entities": []}, {"text": "They showed considerable translation quality improvements over MERT and) for two languages in a research setting.", "labels": [], "entities": [{"text": "MERT", "start_pos": 63, "end_pos": 67, "type": "METRIC", "confidence": 0.5036976337432861}]}, {"text": "The purpose of our submission to the 2013 Workshop on Statistical Machine Translation (WMT) Shared Task is to compare the algorithm to more established methods in an evaluation.", "labels": [], "entities": [{"text": "Statistical Machine Translation (WMT) Shared Task", "start_pos": 54, "end_pos": 103, "type": "TASK", "confidence": 0.8024007603526115}]}, {"text": "We submitted English-French (En-Fr) and EnglishGerman (En-De) systems, each with over 100k features tuned on 10k sentences.", "labels": [], "entities": []}, {"text": "This paper describes the systems and also includes new feature sets and practical extensions to the original algorithm.", "labels": [], "entities": []}], "datasetContent": [{"text": "During system development we tuned on newstest2008-2011 (10,570 sentences) and tested #iterations #features tune newstest2012 newstest2013 \u2020   on newstest2012 (3,003 sentences).", "labels": [], "entities": []}, {"text": "We compare the feature-rich model to the \"dense\" baseline.", "labels": [], "entities": []}, {"text": "The En-De system parameters were: 200-best lists, a maximum phrase length of 8, and a distortion limit of 6 with future cost estimation.", "labels": [], "entities": [{"text": "distortion limit", "start_pos": 86, "end_pos": 102, "type": "METRIC", "confidence": 0.9706827700138092}]}, {"text": "The En-Fr system parameters were: 200-best lists, a maximum phrase length of 8, and a distortion limit of 5.", "labels": [], "entities": [{"text": "distortion limit", "start_pos": 86, "end_pos": 102, "type": "METRIC", "confidence": 0.9687662720680237}]}, {"text": "The online tuning algorithm used a default learning rate \u03b7 = 0.03 and a mini-batch size of 20.", "labels": [], "entities": []}, {"text": "We set the regularization strength \u03bb to 10.0 for the discriminative re-ordering model, 0.0 for the dense features, and 0.1 otherwise.", "labels": [], "entities": []}, {"text": "show En-Fr and En-De results, respectively.", "labels": [], "entities": [{"text": "En-Fr", "start_pos": 5, "end_pos": 10, "type": "METRIC", "confidence": 0.9636455774307251}, {"text": "En-De", "start_pos": 15, "end_pos": 20, "type": "METRIC", "confidence": 0.9063745737075806}]}, {"text": "The \"Feature-rich\" model, which contains the full complement of dense and sparse features, offers a meager improvement over the \"Dense\" baseline.", "labels": [], "entities": []}, {"text": "This result contrasts with the results of, who showed significant translation quality improvements over the same dense baseline for Arabic-English and ChineseEnglish.", "labels": [], "entities": []}, {"text": "However, they had multiple target references, whereas the WMT data sets have just one.", "labels": [], "entities": [{"text": "WMT data sets", "start_pos": 58, "end_pos": 71, "type": "DATASET", "confidence": 0.9285906553268433}]}, {"text": "We speculate that this difference is significant.", "labels": [], "entities": []}, {"text": "For example, consider a translation rule that rewrites to a 4-gram in the reference.", "labels": [], "entities": []}, {"text": "This event can increase the sentence-level score, thus encouraging the model to upweight the rule indicator feature.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: En-Fr BLEU-4 [% uncased] results. The tuning set is newstest2008-2011. ( \u2020) newstest2013 is  the cased score computed by the WMT organizers.", "labels": [], "entities": [{"text": "En-Fr", "start_pos": 10, "end_pos": 15, "type": "METRIC", "confidence": 0.8857014775276184}, {"text": "BLEU-4", "start_pos": 16, "end_pos": 22, "type": "METRIC", "confidence": 0.8080697655677795}, {"text": "newstest2008-2011", "start_pos": 62, "end_pos": 79, "type": "DATASET", "confidence": 0.9402448534965515}, {"text": "WMT organizers", "start_pos": 135, "end_pos": 149, "type": "DATASET", "confidence": 0.9423704743385315}]}]}