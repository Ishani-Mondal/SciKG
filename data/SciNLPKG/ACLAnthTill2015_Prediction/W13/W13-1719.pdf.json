{"title": [{"text": "Exploring Syntactic Representations for Native Language Identification", "labels": [], "entities": [{"text": "Exploring Syntactic Representations", "start_pos": 0, "end_pos": 35, "type": "TASK", "confidence": 0.7539691925048828}, {"text": "Native Language Identification", "start_pos": 40, "end_pos": 70, "type": "TASK", "confidence": 0.6927974224090576}]}], "abstractContent": [{"text": "Tree Substitution Grammar rules form a large and expressive class of features capable of representing syntactic and lexical patterns that provide evidence of an author's native language.", "labels": [], "entities": []}, {"text": "However, this class of features can be applied to any general constituent based model of grammar and previous work has done little to explore these options, relying primarily on the common Penn Treebank annotation standard.", "labels": [], "entities": [{"text": "Penn Treebank annotation standard", "start_pos": 189, "end_pos": 222, "type": "DATASET", "confidence": 0.9792385697364807}]}, {"text": "In this work we contrast the performance of syntactic features for Native Language Indentification using five different formalisms.", "labels": [], "entities": [{"text": "Native Language Indentification", "start_pos": 67, "end_pos": 98, "type": "TASK", "confidence": 0.6511459350585938}]}, {"text": "The use of different formalisms captures complementary information from second language data, and can be used in combination to yield classification performance superior to any formalism taken on its own.", "labels": [], "entities": []}], "introductionContent": [{"text": "Native Language Identification, the automatic determination of an author's native language (L1) from their writing in a second language (L2), follows a general trend of supervised classification using features extracted from text.", "labels": [], "entities": [{"text": "Native Language Identification", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.688973089059194}, {"text": "determination of an author's native language (L1) from their writing in a second language (L2)", "start_pos": 46, "end_pos": 140, "type": "TASK", "confidence": 0.6955146163702011}]}, {"text": "These systems can be optimized by both classification algorithm selection and the integration of diverse feature sets, and in this work we focus on the latter.", "labels": [], "entities": [{"text": "classification algorithm selection", "start_pos": 39, "end_pos": 73, "type": "TASK", "confidence": 0.9202650586764017}]}, {"text": "Syntactic features have been shown to provide a strong discriminative signal of an author's native language (), but little work has been done to explore the various options for representation of syntax of learner text.", "labels": [], "entities": []}, {"text": "Many such representations exist, and are routinely employed to improve performance on the widely studied task of parsing the Penn Treebank.", "labels": [], "entities": [{"text": "parsing", "start_pos": 113, "end_pos": 120, "type": "TASK", "confidence": 0.9620050191879272}, {"text": "Penn Treebank", "start_pos": 125, "end_pos": 138, "type": "DATASET", "confidence": 0.9074990451335907}]}, {"text": "Furthermore, most techniques that prove widely successful at this task have publicly available implementations, making them very feasible options for NLI systems.", "labels": [], "entities": []}, {"text": "In this work we investigate the use of Tree Substitution Grammars as features for NLI, focusing on the implication of syntactic paradigm (constituent vs dependency grammar) and the addition of annotations that have proved useful in statistical parsing.", "labels": [], "entities": [{"text": "statistical parsing", "start_pos": 232, "end_pos": 251, "type": "TASK", "confidence": 0.8031584620475769}]}, {"text": "A Tree Substitution Grammar (TSG) is an intuitive extension of the Context Free Grammar (CFG) that allows rewrite rules of arbitrary tree structure.", "labels": [], "entities": [{"text": "Tree Substitution Grammar (TSG)", "start_pos": 2, "end_pos": 33, "type": "TASK", "confidence": 0.6518993675708771}]}, {"text": "Alternatively, a CFG can be seen as a TSG in which the rewrite rules obey the constraint that each is a tree structure of unit depth.", "labels": [], "entities": []}, {"text": "While a collection of parsed data can be potentially generated by a TSG that is exponential in the length of the text, recent techniques allow for the efficient induction of compact grammars.", "labels": [], "entities": []}, {"text": "At a high level, this technique employs the rich-get-richer dynamics of a Dirichlet Process to sample derivations for the trees in the training corpus: the more that a rule is used in other derivations, the more likely it is that we will choose it when sampling a derivation.", "labels": [], "entities": []}, {"text": "We follow previous work in stylometry with TSGs for the NLI in that we parse the entirety of the training data and use it to induce a compact TSG using the method described above.", "labels": [], "entities": []}, {"text": "We then use the TSG rules as binary features for supervised classification such that the feature fora TSG rule is triggered on a document if that rule appears in the parse of some derivation of any of its sentences.", "labels": [], "entities": []}, {"text": "This description purposefully treats the parsing of text as a black box whose input is plain text and whose output is any valid tree structure.", "labels": [], "entities": []}, {"text": "Our work considers five alternatives for this black box, and evaluates the effect of this choice on the NLI Shared Task at the BEA Workshop of NAACL 2013 ).", "labels": [], "entities": [{"text": "BEA Workshop of NAACL 2013", "start_pos": 127, "end_pos": 153, "type": "DATASET", "confidence": 0.87727370262146}]}], "datasetContent": [{"text": "We contrast the syntactic formalisms on the NLI shared task experimental setup for the NAACL 2013 BEA workshop.", "labels": [], "entities": [{"text": "NLI shared task experimental setup for the NAACL 2013 BEA workshop", "start_pos": 44, "end_pos": 110, "type": "DATASET", "confidence": 0.7464752901684154}]}, {"text": "This new data set (  consists of TOEFL essays drawn from speakers of 11 different L1 backgrounds.", "labels": [], "entities": []}, {"text": "9900 Essays were supplied as a training set, with an additional 1100 development set essays and 1100 test essays.", "labels": [], "entities": []}, {"text": "Previous work in NLI has relied heavily on the International Corpus of Learner English, but due to significant topic biases along L1 lines in this data set the explicit use of word tokens was frequently limited to a predetermined set of stopwords.", "labels": [], "entities": [{"text": "International Corpus of Learner English", "start_pos": 47, "end_pos": 86, "type": "DATASET", "confidence": 0.9642121195793152}]}, {"text": "With this in mind, the data set for the shared task was balanced across TOEFL essay prompts and proficiency levels.", "labels": [], "entities": [{"text": "TOEFL essay prompts", "start_pos": 72, "end_pos": 91, "type": "DATASET", "confidence": 0.6828778783480326}]}, {"text": "The result was that the participants in this task were not forced to limit the word tokens explicitly employed, with the hopes that mitigating factors had been minimized.", "labels": [], "entities": []}, {"text": "We prepared the data in the five forms described above and induced TSGs on each version of the parsed training set with the blocked sampling algorithm of.", "labels": [], "entities": [{"text": "TSGs", "start_pos": 67, "end_pos": 71, "type": "METRIC", "confidence": 0.9686023592948914}]}, {"text": "The resulting rules were used as binary feature functions over documents indicating the presence of the rule in some derivation of sentence in that document.", "labels": [], "entities": []}, {"text": "We used the Mallet implementation of a log-linear (MaxEnt) classifier with a zero mean Gaussian prior with variance .1 on the classifier's weights.", "labels": [], "entities": []}, {"text": "Our results on the development set are shown in.", "labels": [], "entities": []}, {"text": "While a range of performance is achieved, when we construct a classifier that simply averages the predictive distributions of all five methods we get better accuracy than any model on its own.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 157, "end_pos": 165, "type": "METRIC", "confidence": 0.9984519481658936}]}, {"text": "We observed further evidence of the orthogonality of these methods by looking at pairs of formalisms and observing how many development set items were predicted correctly by one formalism and incorrectly by another.", "labels": [], "entities": []}, {"text": "This was routinely around 10 percent of the development set in each direction fora given pair, implying that gains of up to at least 20 percent classification accuracy are possible with an expert system that approaches oracle selection of which formalism to use.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 159, "end_pos": 167, "type": "METRIC", "confidence": 0.9272724390029907}]}, {"text": "As our submission to the shared task, we used the Berkeley Parser output in isolation, the average of the five classifiers, and the weighted average of the classifiers using the optimal weights on the development set.", "labels": [], "entities": [{"text": "Berkeley Parser output", "start_pos": 50, "end_pos": 72, "type": "DATASET", "confidence": 0.7639630635579427}]}, {"text": "The former two models use the development set as additional training data, which is one possible explanation of the slightly higher performance of the equally weighted average model.", "labels": [], "entities": []}, {"text": "other explanation of note is that while the weight optimization was carried outwith EM over the likelihood of the development set labels, this did not in correlate positively with classification accuracy; even as we optimized on the development set the accuracy in absolute classification of these items decreased slightly.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 195, "end_pos": 203, "type": "METRIC", "confidence": 0.8568764328956604}, {"text": "accuracy", "start_pos": 253, "end_pos": 261, "type": "METRIC", "confidence": 0.99868243932724}]}, {"text": "The confusion matrix for the evenly averaged model, our best performing system, is shown in.", "labels": [], "entities": []}, {"text": "The most frequently confused L1 pairs were Hindi and Telegu, Japanese and Korean, and Spanish and Italian.", "labels": [], "entities": []}, {"text": "The similarity between Hindi and Telegu is particularly troubling, as they come from two completely different language families and their most obvious similarity is that they are both spoken primarily in India.", "labels": [], "entities": []}, {"text": "This suggests that even though the TOEFL corpus has been balanced by topic that there is a strong geographical signal that is correlated with but not caused by native language.", "labels": [], "entities": [{"text": "TOEFL corpus", "start_pos": 35, "end_pos": 47, "type": "DATASET", "confidence": 0.8418664932250977}]}], "tableCaptions": []}