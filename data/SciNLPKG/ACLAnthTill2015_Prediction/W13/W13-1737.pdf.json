{"title": [{"text": "Evaluating Unsupervised Language Model Adaptation Methods for Speaking Assessment", "labels": [], "entities": [{"text": "Evaluating Unsupervised Language Model Adaptation", "start_pos": 0, "end_pos": 49, "type": "TASK", "confidence": 0.748827314376831}, {"text": "Speaking Assessment", "start_pos": 62, "end_pos": 81, "type": "TASK", "confidence": 0.8733579814434052}]}], "abstractContent": [{"text": "In automated speech assessment, adaptation of language models (LMs) to test questions is important to achieve high recognition accuracy However, for large-scale language tests, the ordinary supervised training, which uses an expensive and time-consuming manual transcription process, is hard to utilize for LM adaptation.", "labels": [], "entities": [{"text": "automated speech assessment", "start_pos": 3, "end_pos": 30, "type": "TASK", "confidence": 0.6372921963532766}, {"text": "accuracy", "start_pos": 127, "end_pos": 135, "type": "METRIC", "confidence": 0.8608106970787048}, {"text": "LM adaptation", "start_pos": 307, "end_pos": 320, "type": "TASK", "confidence": 0.9647867679595947}]}, {"text": "In this paper, several LM adaptation methods that require either no manual transcription processor just a small amount of transcriptions have been evaluated.", "labels": [], "entities": [{"text": "LM adaptation", "start_pos": 23, "end_pos": 36, "type": "TASK", "confidence": 0.9743017256259918}]}, {"text": "Our experiments suggest that these LM adaptation methods can allow us to obtain considerable recognition accuracy gain with no or low human transcription cost.", "labels": [], "entities": [{"text": "LM adaptation", "start_pos": 35, "end_pos": 48, "type": "TASK", "confidence": 0.9381005465984344}, {"text": "accuracy", "start_pos": 105, "end_pos": 113, "type": "METRIC", "confidence": 0.9312110543251038}]}], "introductionContent": [{"text": "Automated speech assessment, a fast-growing area in the speech research field, typically uses an automatic speech recognition (ASR) system to recognize spontaneous speech responses and use the recognition outputs to generate the features for scoring.", "labels": [], "entities": [{"text": "Automated speech assessment", "start_pos": 0, "end_pos": 27, "type": "TASK", "confidence": 0.707407553990682}, {"text": "automatic speech recognition (ASR)", "start_pos": 97, "end_pos": 131, "type": "TASK", "confidence": 0.7410190602143606}]}, {"text": "Since the recognition accuracy directly influences the quality of the speech features, especially for the features related to word entities, such as those measuring grammar accuracy and vocabulary richness, it is important to use ASR systems with high recognition accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 22, "end_pos": 30, "type": "METRIC", "confidence": 0.8216578960418701}, {"text": "accuracy", "start_pos": 173, "end_pos": 181, "type": "METRIC", "confidence": 0.586518406867981}, {"text": "ASR", "start_pos": 230, "end_pos": 233, "type": "TASK", "confidence": 0.9672079682350159}]}, {"text": "Adaptation of language models (LMs) to test responses is an effective method to improve recognition accuracy.", "labels": [], "entities": [{"text": "Adaptation of language models (LMs)", "start_pos": 0, "end_pos": 35, "type": "TASK", "confidence": 0.8646244832447597}, {"text": "accuracy", "start_pos": 100, "end_pos": 108, "type": "METRIC", "confidence": 0.868730366230011}]}, {"text": "However, it is difficult to only use the ordinary supervised training to adapt LMs to test questions.", "labels": [], "entities": []}, {"text": "First, for high-stake tests administered globally, a very large pool of test questions have to be used to strengthen the tests' security and validity.", "labels": [], "entities": [{"text": "validity", "start_pos": 141, "end_pos": 149, "type": "METRIC", "confidence": 0.9620170593261719}]}, {"text": "Since a large number of test questions have many possible answers for each question, a large set of audio files needs to be transcribed to cover response content.", "labels": [], "entities": []}, {"text": "Second, due to time and cost constraints, it may not be practical to have a pre-test to collect enough speech responses for adaptation purposes.", "labels": [], "entities": []}, {"text": "Therefore, it is important to pursue other methods to obtain LM adaptation data in a faster and lower-cost way than the ordinary supervised training.", "labels": [], "entities": [{"text": "LM adaptation", "start_pos": 61, "end_pos": 74, "type": "TASK", "confidence": 0.9464303255081177}]}, {"text": "As we will review in Section 2, some promising technologies, such as unsupervised training, active learning, and LM adaptation based on Web data, have been utilized in broadcast news recognition, dialog system, and soon.", "labels": [], "entities": [{"text": "LM adaptation", "start_pos": 113, "end_pos": 126, "type": "TASK", "confidence": 0.9279726445674896}, {"text": "broadcast news recognition", "start_pos": 168, "end_pos": 194, "type": "TASK", "confidence": 0.7189793586730957}]}, {"text": "In this paper on the LM adaptation task used in automated speech scoring systems, we will report our experiments to obtain LM adaptation data in a faster and more economical way that requires little human involvement.", "labels": [], "entities": [{"text": "LM adaptation task", "start_pos": 21, "end_pos": 39, "type": "TASK", "confidence": 0.9499937891960144}, {"text": "LM adaptation", "start_pos": 123, "end_pos": 136, "type": "TASK", "confidence": 0.7749519050121307}]}, {"text": "To our knowledge, this is the first such work reported in the automated speech assessment area.", "labels": [], "entities": [{"text": "automated speech assessment area", "start_pos": 62, "end_pos": 94, "type": "TASK", "confidence": 0.7388647496700287}]}, {"text": "The rest of the paper is organized as follows: Section 2 reviews the related previous research results; Section 3 describes the English test, the data used in our experiments, and the ASR system used; Section 4 reports the experiments of different methods we tried to obtain LM adaptation data; Section 5 discusses our findings and plans for future research.", "labels": [], "entities": [{"text": "ASR", "start_pos": 184, "end_pos": 187, "type": "TASK", "confidence": 0.6321496367454529}, {"text": "LM adaptation", "start_pos": 275, "end_pos": 288, "type": "TASK", "confidence": 0.9233958423137665}]}], "datasetContent": [{"text": "We collected a set of audio responses from the TOEIC R test, focusing on opinion questions.", "labels": [], "entities": [{"text": "TOEIC R test", "start_pos": 47, "end_pos": 59, "type": "DATASET", "confidence": 0.6217867732048035}]}, {"text": "This data set was randomly selected from different firstlanguage (L1) and English speaking proficiency levels.", "labels": [], "entities": []}, {"text": "Then, these audio files were manually transcribed.", "labels": [], "entities": []}, {"text": "In our experiments, 1470 responses were used for LM adaptation and the remaining 184 responses were used to evaluate speech recognition accuracy.", "labels": [], "entities": [{"text": "LM adaptation", "start_pos": 49, "end_pos": 62, "type": "TASK", "confidence": 0.9843022227287292}, {"text": "speech recognition", "start_pos": 117, "end_pos": 135, "type": "TASK", "confidence": 0.7618508040904999}, {"text": "accuracy", "start_pos": 136, "end_pos": 144, "type": "METRIC", "confidence": 0.7915000319480896}]}, {"text": "When using the seed recognizer without any adaptation, the WER on the evaluation set is 42.8%, which is much higher than the accuracy achieved on the TOEFL R data (33.0%).", "labels": [], "entities": [{"text": "WER", "start_pos": 59, "end_pos": 62, "type": "METRIC", "confidence": 0.9994134902954102}, {"text": "accuracy", "start_pos": 125, "end_pos": 133, "type": "METRIC", "confidence": 0.9988732933998108}, {"text": "TOEFL R data", "start_pos": 150, "end_pos": 162, "type": "DATASET", "confidence": 0.7498235503832499}]}, {"text": "Using the ordinary supervised training, adapting LMs using these 1470 manual transcriptions, the WER is reduced to 34.7%, close to the performance on the in-domain TOEFL R data.", "labels": [], "entities": [{"text": "WER", "start_pos": 97, "end_pos": 100, "type": "METRIC", "confidence": 0.9876201152801514}, {"text": "TOEFL R data", "start_pos": 164, "end_pos": 176, "type": "DATASET", "confidence": 0.7643218239148458}]}, {"text": "Note that a fixed dictionary with a vocabulary size of about 20, 000 words, which in general is much larger than the vocabulary mastered by non-native test takers, was used in our experiment.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: The WER on the evaluation set using different  LM adaptation methods.", "labels": [], "entities": [{"text": "WER", "start_pos": 14, "end_pos": 17, "type": "METRIC", "confidence": 0.9889363646507263}, {"text": "LM adaptation", "start_pos": 57, "end_pos": 70, "type": "TASK", "confidence": 0.8100128471851349}]}]}