{"title": [{"text": "A Cross-Task Flexible Transition Model for Arabic Tokenization, Affix Detection, Affix Labeling, POS Tagging, and Dependency Parsing", "labels": [], "entities": [{"text": "POS Tagging", "start_pos": 97, "end_pos": 108, "type": "TASK", "confidence": 0.7836187481880188}, {"text": "Dependency Parsing", "start_pos": 114, "end_pos": 132, "type": "TASK", "confidence": 0.7235217988491058}]}], "abstractContent": [{"text": "This paper describes cross-task flexible transition models (CTF-TMs) and demonstrates their effectiveness for Arabic natural language processing (NLP).", "labels": [], "entities": [{"text": "Arabic natural language processing (NLP)", "start_pos": 110, "end_pos": 150, "type": "TASK", "confidence": 0.7115345469542912}]}, {"text": "NLP pipelines often suffer from error propagation, as errors committed in lower-level tasks cascade through the remainder of the processing pipeline.", "labels": [], "entities": [{"text": "error propagation", "start_pos": 32, "end_pos": 49, "type": "TASK", "confidence": 0.6884485334157944}]}, {"text": "By allowing a flexible order of operations across and within multiple NLP tasks, a CTF-TM can mitigate both cross-task and within-task error propagation.", "labels": [], "entities": []}, {"text": "Our Arabic CTF-TM models to-kenization, affix detection, affix labeling, part-of-speech tagging, and dependency parsing, achieving state-of-the-art results.", "labels": [], "entities": [{"text": "Arabic CTF-TM", "start_pos": 4, "end_pos": 17, "type": "DATASET", "confidence": 0.796636164188385}, {"text": "affix detection", "start_pos": 40, "end_pos": 55, "type": "TASK", "confidence": 0.6980329900979996}, {"text": "part-of-speech tagging", "start_pos": 73, "end_pos": 95, "type": "TASK", "confidence": 0.710219070315361}, {"text": "dependency parsing", "start_pos": 101, "end_pos": 119, "type": "TASK", "confidence": 0.7429066002368927}]}, {"text": "We present the details of our general framework, our Ara-bic CTF-TM, and the setup and results of our experiments.", "labels": [], "entities": [{"text": "Ara-bic CTF-TM", "start_pos": 53, "end_pos": 67, "type": "DATASET", "confidence": 0.6863909661769867}]}], "introductionContent": [{"text": "Natural Language Processing (NLP) systems often consist of a series of NLP components, each trained to perform a specific task such as parsing.", "labels": [], "entities": []}, {"text": "These pipelines tend to suffer from error propagationerrors introduced by early components cascade through the remainder of the pipeline causing subsequent components to commit additional errors.", "labels": [], "entities": []}, {"text": "Partial solutions from higher-level tasks (e.g., parsing) can aid in resolving the difficult decisions that must be made in solving lower-level tasks, as with partof-speech tagging the classic \"garden path\" sentence example \"The horse raced past the barn fell.\"", "labels": [], "entities": [{"text": "parsing", "start_pos": 49, "end_pos": 56, "type": "TASK", "confidence": 0.954730749130249}, {"text": "partof-speech tagging", "start_pos": 159, "end_pos": 180, "type": "TASK", "confidence": 0.8650301098823547}]}, {"text": "To this end, this paper presents cross-task flexible transition models (CTF-TMs), which model multiple tasks and solve these tasks in a more flexible order than pipeline approaches.", "labels": [], "entities": []}, {"text": "We implement and experiment with a CTF-TM for Arabic 1 language processing and report experimental results for it on Arabic tokenization (i.e., clitic separation), affix detection, affix labeling, part-of-speech tagging, and dependency parsing.", "labels": [], "entities": [{"text": "Arabic 1 language processing", "start_pos": 46, "end_pos": 74, "type": "TASK", "confidence": 0.5415573716163635}, {"text": "clitic separation)", "start_pos": 144, "end_pos": 162, "type": "TASK", "confidence": 0.803038090467453}, {"text": "affix detection", "start_pos": 164, "end_pos": 179, "type": "TASK", "confidence": 0.6991339325904846}, {"text": "affix labeling", "start_pos": 181, "end_pos": 195, "type": "TASK", "confidence": 0.6061321794986725}, {"text": "part-of-speech tagging", "start_pos": 197, "end_pos": 219, "type": "TASK", "confidence": 0.7191153019666672}, {"text": "dependency parsing", "start_pos": 225, "end_pos": 243, "type": "TASK", "confidence": 0.8230531513690948}]}, {"text": "In addition to error propagation between modules within a parsing pipeline, errors may propagate within the parsing process itself due to the fixed order of operations of the parser.", "labels": [], "entities": [{"text": "parsing pipeline", "start_pos": 58, "end_pos": 74, "type": "TASK", "confidence": 0.8239420354366302}]}, {"text": "This is common for standard transition-based dependency parsing models , such as shift-reduce parsers, which incrementally construct a parse by processing the input in a fixed left-to-right or right-to-left fashion.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 45, "end_pos": 63, "type": "TASK", "confidence": 0.7007173895835876}]}, {"text": "However, using a transition model that allows a more flexible order of operations, such as parser, allows difficult decisions to be postponed until later, when more of the solution has been constructed.", "labels": [], "entities": []}, {"text": "CTF-TMs extend this approach by modeling multiple tasks and providing this flexibility across tasks so that no one task needs to be complete before another can be partially solved.", "labels": [], "entities": [{"text": "CTF-TMs", "start_pos": 0, "end_pos": 7, "type": "DATASET", "confidence": 0.8465756177902222}]}, {"text": "As a morphologically rich language, Arabic requires a significant number of processing steps.", "labels": [], "entities": []}, {"text": "Arabic uses a variety of affixes to inflect for case, gender, number (including dual), and mood, has clitics that attach to other words, permits both VSO and SVO constructions, and rarely includes short vowels in written form.", "labels": [], "entities": []}, {"text": "The presence of clitics and the absence of written short vowels are particularly significant sources of ambiguity.", "labels": [], "entities": []}, {"text": "As argues for Modern Hebrew, a Semitic language that shares these characteristics, we contend that mor-phological analysis and parsing should be done in a unified framework, such as a CTF-TM, rather than by separate components.", "labels": [], "entities": [{"text": "mor-phological analysis", "start_pos": 99, "end_pos": 122, "type": "TASK", "confidence": 0.6882016807794571}]}, {"text": "In this paper, we describe CTF-TMs, which can be used fora wide variety of NLP tasks, and present our Arabic CTF-TM for Arabic tokenization, affix detection, affix labeling, part-of-speech tagging, and dependency parsing as well as the results obtained in applying it to our dependency conversion of the Penn Arabic Treebank (ATB) ( ).", "labels": [], "entities": [{"text": "affix detection", "start_pos": 141, "end_pos": 156, "type": "TASK", "confidence": 0.6908150166273117}, {"text": "part-of-speech tagging", "start_pos": 174, "end_pos": 196, "type": "TASK", "confidence": 0.710483506321907}, {"text": "dependency parsing", "start_pos": 202, "end_pos": 220, "type": "TASK", "confidence": 0.8409559428691864}, {"text": "Penn Arabic Treebank (ATB)", "start_pos": 304, "end_pos": 330, "type": "DATASET", "confidence": 0.9739493230978647}]}, {"text": "We find that our Arabic CTF-TM for tokenization, affix detection, affix labeling, POS tagging, and parsing achieves slightly better results than a similar CTF-TM that performs all the tasks except parsing.", "labels": [], "entities": [{"text": "tokenization", "start_pos": 35, "end_pos": 47, "type": "TASK", "confidence": 0.9652283191680908}, {"text": "affix detection", "start_pos": 49, "end_pos": 64, "type": "TASK", "confidence": 0.6862716972827911}, {"text": "POS tagging", "start_pos": 82, "end_pos": 93, "type": "TASK", "confidence": 0.8436450362205505}, {"text": "parsing", "start_pos": 99, "end_pos": 106, "type": "TASK", "confidence": 0.9800413250923157}, {"text": "parsing", "start_pos": 197, "end_pos": 204, "type": "TASK", "confidence": 0.9621129631996155}]}, {"text": "The CTF-TM that supports parsing appears to be more accurate at distinguishing between passive and active verbs as well as between nouns and adjectivescases where the context is crucial for proper interpretation due to Arabic's ambiguities.", "labels": [], "entities": []}, {"text": "Our system achieves tokenization accuracy similar to state-of-the-art system fora standard split of the ATB part 3, and, in our experiments using ATB parts 1-3, our system achieves the highest labeled attachment, unlabeled attachment, and clitic separation figures (including pronomial clitics) for Arabic yet reported (although no other work can be compared directly).", "labels": [], "entities": [{"text": "tokenization", "start_pos": 20, "end_pos": 32, "type": "TASK", "confidence": 0.9562536478042603}, {"text": "accuracy", "start_pos": 33, "end_pos": 41, "type": "METRIC", "confidence": 0.9005919694900513}, {"text": "ATB part 3", "start_pos": 104, "end_pos": 114, "type": "DATASET", "confidence": 0.9418400923411051}]}], "datasetContent": [{"text": "Dependency parsing quality is measured in terms of labeled and unlabeled attachment scores (LAS and UAS), which indicate the percentage of words attached to their correct parent and, in the case of LAS, whose attachment is labeled with the correct dependency.", "labels": [], "entities": [{"text": "Dependency parsing", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.8191908001899719}, {"text": "unlabeled attachment scores (LAS and UAS)", "start_pos": 63, "end_pos": 104, "type": "METRIC", "confidence": 0.6175662279129028}]}, {"text": "Since a given space-delimited token may not be tokenized into words correctly, the dependency arcs are only counted as correct if they occur between the correct words (spans of character indices).", "labels": [], "entities": []}, {"text": "We measure part-of-speech tagging in terms of F-score (F1) and require that the tree token have the correct bounds (was tokenized correctly) and have the correct label.", "labels": [], "entities": [{"text": "part-of-speech tagging", "start_pos": 11, "end_pos": 33, "type": "TASK", "confidence": 0.6970548629760742}, {"text": "F-score (F1)", "start_pos": 46, "end_pos": 58, "type": "METRIC", "confidence": 0.7914429157972336}]}, {"text": "Normally, we would choose LAS on the development set as the measure for determining the version of the model to keep for testing because it measures performance on the highest-level task (labeled dependency parsing).", "labels": [], "entities": [{"text": "LAS", "start_pos": 26, "end_pos": 29, "type": "METRIC", "confidence": 0.9709805846214294}, {"text": "dependency parsing", "start_pos": 196, "end_pos": 214, "type": "TASK", "confidence": 0.7309690415859222}]}, {"text": "However, since one of the CTFTMs does not perform parsing, we instead use POS tagging F1.", "labels": [], "entities": [{"text": "CTFTMs", "start_pos": 26, "end_pos": 32, "type": "DATASET", "confidence": 0.8797569870948792}, {"text": "parsing", "start_pos": 50, "end_pos": 57, "type": "TASK", "confidence": 0.9760427474975586}, {"text": "POS tagging", "start_pos": 74, "end_pos": 85, "type": "TASK", "confidence": 0.6357788592576981}]}, {"text": "In general, we observe that the scores are highly correlated, making the point moot.", "labels": [], "entities": []}, {"text": "For the ATB part 3 experiment, POS tagging F1 peaks on iteration 437.", "labels": [], "entities": [{"text": "ATB part 3 experiment", "start_pos": 8, "end_pos": 29, "type": "DATASET", "confidence": 0.8412640988826752}, {"text": "POS tagging", "start_pos": 31, "end_pos": 42, "type": "TASK", "confidence": 0.6958996504545212}, {"text": "F1", "start_pos": 43, "end_pos": 45, "type": "METRIC", "confidence": 0.7800695300102234}]}, {"text": "For the second experiment, POS tagging F1 peaks at iteration 301 for the CTF-TM with parsing and iteration 278 for the one without.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 27, "end_pos": 38, "type": "TASK", "confidence": 0.7692996263504028}, {"text": "F1", "start_pos": 39, "end_pos": 41, "type": "METRIC", "confidence": 0.7641194462776184}, {"text": "CTF-TM", "start_pos": 73, "end_pos": 79, "type": "DATASET", "confidence": 0.940045952796936}]}, {"text": "For the third experiment, the highest score occurs on iteration 431.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 3: Counts of the number of files, sentences (Sent),  original space-delimited tokens (Tok), ATB tree tokens  (Tree Toks), and affixes in the experimental data.", "labels": [], "entities": []}, {"text": " Table 4: Results for the various experiments (Exp) for both the development and test portions of the data, including per- token clitic separation (tokenization) accuracy, part-of-speech tagging F1, affix boundary detection F1, affix labeling  F1, and both unlabeled and labeled attachment scores.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 162, "end_pos": 170, "type": "METRIC", "confidence": 0.717143714427948}, {"text": "part-of-speech tagging", "start_pos": 172, "end_pos": 194, "type": "TASK", "confidence": 0.6587025076150894}]}, {"text": " Table 5: Top 10 POS mistakes made more often by either  the CTF-TM with parsing or the CTF-TM without on the  ATB part 1, 2, and 3 development set.", "labels": [], "entities": [{"text": "CTF-TM", "start_pos": 61, "end_pos": 67, "type": "DATASET", "confidence": 0.916123628616333}, {"text": "CTF-TM", "start_pos": 88, "end_pos": 94, "type": "DATASET", "confidence": 0.9595333337783813}, {"text": "ATB part 1, 2, and 3 development set", "start_pos": 111, "end_pos": 147, "type": "DATASET", "confidence": 0.7580607801675796}]}, {"text": " Table 6: Counts for the POS tags mentioned in Table 5.", "labels": [], "entities": []}]}