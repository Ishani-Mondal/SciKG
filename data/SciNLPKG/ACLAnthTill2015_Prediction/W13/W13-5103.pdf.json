{"title": [{"text": "De-Identification of Clinical Free Text in Dutch with Limited Training Data: A Case Study", "labels": [], "entities": []}], "abstractContent": [{"text": "In order to analyse the information present in medical records while maintaining patient privacy, there is a basic need for techniques to automatically de-identify the free text information in these records.", "labels": [], "entities": []}, {"text": "This paper presents a machine learning de-identification system for clinical free text in Dutch, relying on best practices from the state of the art in de-identification of English-language texts.", "labels": [], "entities": []}, {"text": "We combine string and pattern matching features with machine learning algorithms and compare performance of three different experimental setups using Support Vector Machines and Random Forests on a limited data set of one hundred manually obfuscated texts provided by Antwerp University Hospital (UZA).", "labels": [], "entities": [{"text": "pattern matching", "start_pos": 22, "end_pos": 38, "type": "TASK", "confidence": 0.7053634971380234}, {"text": "Antwerp University Hospital (UZA)", "start_pos": 268, "end_pos": 301, "type": "DATASET", "confidence": 0.8833893140157064}]}, {"text": "The setup with the best balance in precision and recall during development was tested on an unseen set of raw clinical texts and evaluated manually at the hospital site.", "labels": [], "entities": [{"text": "precision", "start_pos": 35, "end_pos": 44, "type": "METRIC", "confidence": 0.9992176294326782}, {"text": "recall", "start_pos": 49, "end_pos": 55, "type": "METRIC", "confidence": 0.9965230226516724}]}], "introductionContent": [{"text": "In Electronic Health Records (EHRs), medical information about the treatment of patients is stored on a daily basis, both in structured (e.g. lab results, medication, ) and unstructured (e.g. clinical notes) forms.", "labels": [], "entities": []}, {"text": "EHRs are unique sources of information that need be further analyzed to improve diagnosis and treatment of future patients.", "labels": [], "entities": [{"text": "EHRs", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.7324828505516052}]}, {"text": "However, these information sources cannot be freely explored due to privacy regulations.", "labels": [], "entities": []}, {"text": "Automated de-identification is crucial to remove personal health information (PHI), while keeping all medical and contextual information as intact as possible.", "labels": [], "entities": [{"text": "remove personal health information (PHI)", "start_pos": 42, "end_pos": 82, "type": "TASK", "confidence": 0.6263014503887722}]}, {"text": "In the US, this is regulated under the Health Insurance Portability and Accountability Act.", "labels": [], "entities": [{"text": "Health Insurance Portability", "start_pos": 39, "end_pos": 67, "type": "TASK", "confidence": 0.7047921419143677}]}, {"text": "Approaches to de-identification can be categorised into two main types, with rule-based and pattern matching approaches on the one hand and machine learning approaches on the other, as suggested in.", "labels": [], "entities": [{"text": "pattern matching", "start_pos": 92, "end_pos": 108, "type": "TASK", "confidence": 0.6971262097358704}]}, {"text": "Rule-based and pattern-matching approaches often rely on dictionaries and manually constructed regular expressions.", "labels": [], "entities": []}, {"text": "While this type of approach does not require any annotation effort and can easily be customised to increase performance, it offers only limited scalability and is often highly language dependent.", "labels": [], "entities": []}, {"text": "Machine learning approaches in general are better scalable and more robust to noise, but especially supervised learning algorithms require substantial amounts of annotated training data, a very time-consuming and expensive undertaking.", "labels": [], "entities": []}, {"text": "The selection of meaningful features is a crucial aspect in the machine learning approach, especially when only limited data is available.", "labels": [], "entities": []}, {"text": "Hybrid approaches to de-identification such as that presented in have been developed to combine the advantages of the machine learning approach with those of dictionaries and regular expressions.", "labels": [], "entities": []}, {"text": "Below, we highlight a number of interesting studies from the state of the art in automated de-identification.", "labels": [], "entities": []}, {"text": "One of the first systems for de-identification, the Scrub system, was proposed in.", "labels": [], "entities": []}, {"text": "Scrub takes a dictionary rule-based approach and has been shown to be able to effectively model the human approach to locating PHI entities.", "labels": [], "entities": []}, {"text": "This study included well-formatted letters with a header block as well as shorthand notes, but does not provide details on recall and precision.", "labels": [], "entities": [{"text": "recall", "start_pos": 123, "end_pos": 129, "type": "METRIC", "confidence": 0.9989854693412781}, {"text": "precision", "start_pos": 134, "end_pos": 143, "type": "METRIC", "confidence": 0.9964912533760071}]}, {"text": "Stat De-Id () takes a machine learning approach using Support Vector Machines (SVM) as the learning algorithm.", "labels": [], "entities": []}, {"text": "Features cover aspects of the target word as well as of the immediate context of the target.", "labels": [], "entities": []}, {"text": "Conditional Random Fields (CRF) ( are being used increasingly in de-identification research.", "labels": [], "entities": []}, {"text": "Two examples are Health Information DEidentification (HIDE) ( and the Mitre Identification Scrubber Toolkit (MIST) ().", "labels": [], "entities": [{"text": "Health Information DEidentification (HIDE)", "start_pos": 17, "end_pos": 59, "type": "TASK", "confidence": 0.6526512602965037}, {"text": "Mitre Identification Scrubber Toolkit (MIST)", "start_pos": 70, "end_pos": 114, "type": "TASK", "confidence": 0.5107044364724841}]}, {"text": "Several of these de-identification systems (see also and) show excellent results rivaling manual de-identification.", "labels": [], "entities": []}, {"text": "While most de-identification systems score well in terms of recall, they do produce quite a large amount of false positives (see).", "labels": [], "entities": [{"text": "recall", "start_pos": 60, "end_pos": 66, "type": "METRIC", "confidence": 0.9990721940994263}]}, {"text": "This compromises the usability of the de-identified documents, as medically relevant data may have been removed.", "labels": [], "entities": []}, {"text": "In this paper, we present a de-identification case study following best practices from the state of the art.", "labels": [], "entities": []}, {"text": "A machine learning approach is taken, using features based on dictionaries and string and pattern matching techniques.", "labels": [], "entities": []}, {"text": "The objective of this study is to develop a de-identification system for clinical notes in Dutch, a language for which deidentification training data are not available.", "labels": [], "entities": []}, {"text": "We evaluate three machine learning setups on a training set of 100 manually annotated medical notes and test the best performing setup on 100 previously unseen medical notes, the performance of which is manually evaluated at the hospital site.", "labels": [], "entities": []}], "datasetContent": [{"text": "For the development of our de-identification system using the training set described above, we apply the following experimental setup.", "labels": [], "entities": []}, {"text": "First of all, the texts in the dataset are tokenized (i.e. splitting the text in individual words and removing punctuation).", "labels": [], "entities": []}, {"text": "Next, features are derived and calculated.", "labels": [], "entities": []}, {"text": "Ina third step, the resulting set of derived features with associated PHI class per word is used for training.", "labels": [], "entities": []}, {"text": "Ina set of experiments, we (1) assess the performance of the classifiers for the individual PHI classes, (2) evaluate how adding more training data affects performance, and (3) validate the performance on 100 previously unseen documents.", "labels": [], "entities": []}, {"text": "Due to the high cost of manual annotation, our training set is rather small.", "labels": [], "entities": []}, {"text": "As a result, the performance scores can only be interpreted as indicative of performance in a realistic environment.", "labels": [], "entities": []}, {"text": "All results in Experiments 1 and 2 are averaged over fifty independent runs, each selecting different sets of training and test sets from the original training set.", "labels": [], "entities": []}, {"text": "In each run, ten random documents are withheld as test set.", "labels": [], "entities": []}, {"text": "In Experiment 1, the remaining ninety are used for training, while in Experiment 2, a learning curve is constructed, showing the effect of a stepwise (step size=10) increase in training set size.", "labels": [], "entities": []}, {"text": "We present results in terms of precision, recall, and F-score.", "labels": [], "entities": [{"text": "precision", "start_pos": 31, "end_pos": 40, "type": "METRIC", "confidence": 0.9997767806053162}, {"text": "recall", "start_pos": 42, "end_pos": 48, "type": "METRIC", "confidence": 0.9997079968452454}, {"text": "F-score", "start_pos": 54, "end_pos": 61, "type": "METRIC", "confidence": 0.998259961605072}]}, {"text": "We consider recall to be the most important measure for de-identification as it shows the number of PHI-items actually retrieved by the algorithm divided by the number of PHI items present.", "labels": [], "entities": [{"text": "recall", "start_pos": 12, "end_pos": 18, "type": "METRIC", "confidence": 0.9982013702392578}]}, {"text": "Precision indicates how many of the PHI items identified are actually correct.", "labels": [], "entities": [{"text": "Precision", "start_pos": 0, "end_pos": 9, "type": "METRIC", "confidence": 0.9856249690055847}]}, {"text": "F-score is calculated as the harmonic mean between precision and recall.", "labels": [], "entities": [{"text": "F-score", "start_pos": 0, "end_pos": 7, "type": "METRIC", "confidence": 0.9829185009002686}, {"text": "precision", "start_pos": 51, "end_pos": 60, "type": "METRIC", "confidence": 0.9985540509223938}, {"text": "recall", "start_pos": 65, "end_pos": 71, "type": "METRIC", "confidence": 0.9921249747276306}]}, {"text": "Precision and recall are macroaveraged, in away that all classes have an equal weight in the end result.", "labels": [], "entities": [{"text": "Precision", "start_pos": 0, "end_pos": 9, "type": "METRIC", "confidence": 0.9827049374580383}, {"text": "recall", "start_pos": 14, "end_pos": 20, "type": "METRIC", "confidence": 0.999022364616394}]}], "tableCaptions": [{"text": " Table 1: Results per PHI class and classification  setup", "labels": [], "entities": [{"text": "PHI class", "start_pos": 22, "end_pos": 31, "type": "DATASET", "confidence": 0.815835177898407}]}]}