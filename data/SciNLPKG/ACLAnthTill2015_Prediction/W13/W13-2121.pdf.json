{"title": [{"text": "POS-tag based poetry generation with WordNet", "labels": [], "entities": [{"text": "POS-tag based poetry generation", "start_pos": 0, "end_pos": 31, "type": "TASK", "confidence": 0.5597637817263603}, {"text": "WordNet", "start_pos": 37, "end_pos": 44, "type": "DATASET", "confidence": 0.9150089621543884}]}], "abstractContent": [{"text": "In this paper we present the preliminary work of a Basque poetry generation system.", "labels": [], "entities": [{"text": "Basque poetry generation", "start_pos": 51, "end_pos": 75, "type": "TASK", "confidence": 0.7134946783383688}]}, {"text": "Basically, we have extracted the POS-tag sequences from some verse corpora and calculated the probability of each sequence.", "labels": [], "entities": []}, {"text": "For the generation process we have defined 3 different experiments: Based on a strophe from the corpora, we (a) replace each word with other according to its POS-tag and suffixes, (b) replace each noun and adjective with another equally inflected word and (c) replace only nouns with semantically related ones (inflected).", "labels": [], "entities": []}, {"text": "Finally we evaluate those strategies using a Turing Test-like evaluation.", "labels": [], "entities": []}], "introductionContent": [{"text": "Poetry generation is one of the dream tasks of Natural Language Processing (NLP).", "labels": [], "entities": [{"text": "Poetry generation", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.8306738138198853}, {"text": "Natural Language Processing (NLP)", "start_pos": 47, "end_pos": 80, "type": "TASK", "confidence": 0.7393224140008291}]}, {"text": "In this text we point out an approach to generate Basque strophes automatically using some corpora, morphological information and a lexical database.", "labels": [], "entities": []}, {"text": "The presented method is not tied to a specific language, but it is especially suitable for inflected languages, as the POS information used in some tasks with success in noninflected languages is not enough for inflected ones.", "labels": [], "entities": []}, {"text": "We have used the POStags with their inflectional information to learn usual structures in Basque poetry.", "labels": [], "entities": []}, {"text": "This work is part of a more general and complete project, called.", "labels": [], "entities": []}, {"text": "BertsoBOT is a robot capable of creating and singing Basque verses automatically.", "labels": [], "entities": [{"text": "singing Basque verses automatically", "start_pos": 45, "end_pos": 80, "type": "TASK", "confidence": 0.6435183882713318}]}, {"text": "The robot joins together in a single system techniques from robotics, NLP and speech synthesis and recognition.", "labels": [], "entities": [{"text": "speech synthesis", "start_pos": 78, "end_pos": 94, "type": "TASK", "confidence": 0.7132610380649567}]}, {"text": "in this paper comes to improve the generation module of the mentioned system.", "labels": [], "entities": []}, {"text": "Although our intention is to create whole verses, in this paper we present the first steps towards it: the creation of strophes.", "labels": [], "entities": []}, {"text": "Additionally, Basque verses have to rhyme, but in these first experiments we have not considered it.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this work, we have performed a set of experiments to analyze different strategies for the generation of stro-phes in Basque.", "labels": [], "entities": []}, {"text": "In the following lines, we explain the ameliorations we get in each experiment.", "labels": [], "entities": []}, {"text": "The first experiment creates strophes by inserting words that are consistent with each POS-tag and its inflection information.", "labels": [], "entities": []}, {"text": "We first get some of the most common POS-tag sequences and for each POS-tag sequence the application returns two strophes.", "labels": [], "entities": []}, {"text": "The first strophe uses words from the same verse corpus to make substitutions.", "labels": [], "entities": []}, {"text": "The second one uses words from the EPEC corpus ().", "labels": [], "entities": [{"text": "EPEC corpus", "start_pos": 35, "end_pos": 46, "type": "DATASET", "confidence": 0.9779952168464661}]}, {"text": "The second experiment creates clauses, but changing only the nouns and adjectives from original strophes from the corpus.", "labels": [], "entities": []}, {"text": "We mantain the inflection information.", "labels": [], "entities": []}, {"text": "In this experiment we also get two strophes for each pattern sequence, as in the previous attempt (verse corpus and EPEC corpus).", "labels": [], "entities": [{"text": "EPEC corpus", "start_pos": 116, "end_pos": 127, "type": "DATASET", "confidence": 0.8661763668060303}]}, {"text": "With this constraint we avoid the creation of incorrect strophes because of the problem of subcategorization (explained in section 3.2).", "labels": [], "entities": []}, {"text": "The third experiment makes small changes in the original strophes (from the corpus), as it only replaces each noun fora semantically related noun.", "labels": [], "entities": []}, {"text": "The related noun can be: (a) Antonym of the original word or (b) hyponym of the hypernyms of the original word.", "labels": [], "entities": []}, {"text": "In order of preference, first we try to change each name with one of its antonyms.", "labels": [], "entities": []}, {"text": "If there is no antonym, then we try to get the hypernyms of the word to return their hyponims.", "labels": [], "entities": []}, {"text": "Once the new word has been found, we add the needed suffixes (the same ones that had the words from the corpus) in order to fit correctly in the strophe, using the morphological generator.", "labels": [], "entities": []}, {"text": "The change of words with related ones gives us the chance to express semantically similar sentences using different words.", "labels": [], "entities": []}, {"text": "Once the experiments were finished, we made an evaluation in order to analyze the quality of the automatically generated strophes.", "labels": [], "entities": []}, {"text": "The evaluation of computer generated poetry is nowadays fuzzy, so we defined a Turing Test-like evaluation.", "labels": [], "entities": []}, {"text": "We contacted two linguists that had not done any work on this project, so that the evaluation be as objective as possible.", "labels": [], "entities": []}, {"text": "We prepared 135 strophes interleaving some created by the machine with others from the corpus.", "labels": [], "entities": []}, {"text": "We asked the evaluators to guess if the strophe was done by the machine or by a human.", "labels": [], "entities": []}, {"text": "We only draw conclusions using machine-generated strophes, as we want to know how many of them percolate as human-generated ones.", "labels": [], "entities": []}, {"text": "In the next table you can seethe rate of sentences created by the machine and suposed to be done by humans: As you can see, according to Evaluator 1, the first experiment was not very worthy, as the only 3.3% of the machine generated strophes percolated as human generated ones.", "labels": [], "entities": []}, {"text": "The second experiment got better results, and the 26% of the strophes were thought to be human generated ones.", "labels": [], "entities": []}, {"text": "As expected, the strophes of the third experiment are the most trustworthy ones.", "labels": [], "entities": []}, {"text": "The results given by the second evaluator are higher, but the important fact is the increase of the progression over the experiments.", "labels": [], "entities": [{"text": "progression", "start_pos": 100, "end_pos": 111, "type": "METRIC", "confidence": 0.9875608086585999}]}], "tableCaptions": []}