{"title": [], "abstractContent": [{"text": "Reordering is pre-processing stage for Statistical Machine Translation (SMT) system where the words of the source sentence are reordered as per the syntax of the target language.", "labels": [], "entities": [{"text": "Statistical Machine Translation (SMT)", "start_pos": 39, "end_pos": 76, "type": "TASK", "confidence": 0.8456953962643942}]}, {"text": "We are proposing a rich set of rules for better reordering.", "labels": [], "entities": []}, {"text": "The idea is to facilitate the training process by better alignments and parallel phrase extraction fora phrase based SMT system.", "labels": [], "entities": [{"text": "phrase extraction", "start_pos": 81, "end_pos": 98, "type": "TASK", "confidence": 0.7250711023807526}, {"text": "SMT", "start_pos": 117, "end_pos": 120, "type": "TASK", "confidence": 0.9255925416946411}]}, {"text": "Reordering also helps the decoding process and hence improving the machine translation quality.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 67, "end_pos": 86, "type": "TASK", "confidence": 0.7535688281059265}]}, {"text": "We have observed significant improvements in the translation quality by using our approach over the baseline SMT.", "labels": [], "entities": [{"text": "SMT", "start_pos": 109, "end_pos": 112, "type": "TASK", "confidence": 0.9768180847167969}]}, {"text": "We have used BLEU, NIST, multi-reference word error rate, multi-reference position independent error rate for judging the improvements.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 13, "end_pos": 17, "type": "METRIC", "confidence": 0.9985976815223694}, {"text": "NIST", "start_pos": 19, "end_pos": 23, "type": "DATASET", "confidence": 0.698675811290741}, {"text": "multi-reference word error rate", "start_pos": 25, "end_pos": 56, "type": "METRIC", "confidence": 0.6666701957583427}, {"text": "multi-reference position independent error rate", "start_pos": 58, "end_pos": 105, "type": "METRIC", "confidence": 0.6790104866027832}]}, {"text": "We have exploited open source SMT toolkit MOSES to develop the system.", "labels": [], "entities": [{"text": "SMT toolkit MOSES", "start_pos": 30, "end_pos": 47, "type": "TASK", "confidence": 0.6728688677151998}]}], "introductionContent": [{"text": "This paper describes syntactic reordering rules to reorder English sentences as per the Hindi language structure.", "labels": [], "entities": []}, {"text": "Generally in reordering approach, the source sentence is parsed(E) and syntactic reordering rules are applied to form reordered sentence(E`).", "labels": [], "entities": []}, {"text": "The training of SMT system is performed using parallel corpus having source side reordered(E`) and target side.", "labels": [], "entities": [{"text": "SMT", "start_pos": 16, "end_pos": 19, "type": "TASK", "confidence": 0.9945390820503235}, {"text": "source side reordered(E`)", "start_pos": 69, "end_pos": 94, "type": "METRIC", "confidence": 0.7312398155530294}]}, {"text": "The decoding is done by supplying reordered source sentences.", "labels": [], "entities": []}, {"text": "The source sentences prior to decoding are reordered using the same syntactic rules as applied for the training data.", "labels": [], "entities": []}, {"text": "So, this process works as a preprocessing stage for the phrase-based SMT system.", "labels": [], "entities": [{"text": "SMT", "start_pos": 69, "end_pos": 72, "type": "TASK", "confidence": 0.8310509324073792}]}, {"text": "It has been observed that reordering as a pre-processing stage is beneficial for developing English-Hindi phrase based SMT system.", "labels": [], "entities": [{"text": "SMT", "start_pos": 119, "end_pos": 122, "type": "TASK", "confidence": 0.6659470796585083}]}, {"text": "This paper describes a rich set of rules for the structural transformation of English sentence to Hindi language structure using Stanford () parse tree on source side.", "labels": [], "entities": []}, {"text": "These rules are manually extracted based on analysis of source sentence tree and Hindi translation.", "labels": [], "entities": [{"text": "Hindi translation", "start_pos": 81, "end_pos": 98, "type": "TASK", "confidence": 0.6131002604961395}]}, {"text": "For the evaluation purpose we have trained and evaluated three different phrase based SMT systems using MOSES toolkit ( ) and GIZA++).", "labels": [], "entities": [{"text": "SMT", "start_pos": 86, "end_pos": 89, "type": "TASK", "confidence": 0.8664854168891907}]}, {"text": "The first system was non-reordered baseline, second using limited reordering described in and third using improved reordering technique proposed in the paper.", "labels": [], "entities": []}, {"text": "Evaluation has been carried out for end to end English-Hindi translation outputs using BLEU score (), NIST score), multi-reference position-independent word error rate (), multi-reference word error rate ().", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 87, "end_pos": 97, "type": "METRIC", "confidence": 0.9884278476238251}, {"text": "NIST score", "start_pos": 102, "end_pos": 112, "type": "DATASET", "confidence": 0.5751987993717194}, {"text": "multi-reference position-independent word error rate", "start_pos": 115, "end_pos": 167, "type": "METRIC", "confidence": 0.6158168733119964}, {"text": "multi-reference word error rate", "start_pos": 172, "end_pos": 203, "type": "METRIC", "confidence": 0.6158002316951752}]}, {"text": "We have observed improvement in each of these evaluation metrics used.", "labels": [], "entities": []}, {"text": "Next section discusses related work.", "labels": [], "entities": []}, {"text": "Section 3 describes our reordering approach followed by experiments and results in section 4 and conclusion in section 5.", "labels": [], "entities": []}], "datasetContent": [{"text": "The experiments were carried out on the corpus described in   The baseline system was setup by using the phrase-based model (.", "labels": [], "entities": []}, {"text": "For the language model, we carried out experiments and found on comparison that 5-gram model with modified Kneser-Ney smoothing) to be the best performing.", "labels": [], "entities": []}, {"text": "Target Hindi corpus from the training set was used for creating the language model.", "labels": [], "entities": []}, {"text": "The KenLM (Heafield., 2011) toolkit was used for the language modeling experiments.", "labels": [], "entities": [{"text": "KenLM (Heafield., 2011) toolkit", "start_pos": 4, "end_pos": 35, "type": "DATASET", "confidence": 0.859826113496508}, {"text": "language modeling", "start_pos": 53, "end_pos": 70, "type": "TASK", "confidence": 0.7911582291126251}]}, {"text": "The tuning corpus was used to set weights for the language models, distortion model, phrase translation model etc.", "labels": [], "entities": [{"text": "phrase translation", "start_pos": 85, "end_pos": 103, "type": "TASK", "confidence": 0.821872353553772}]}, {"text": "using minimum error rate training.", "labels": [], "entities": [{"text": "error rate", "start_pos": 14, "end_pos": 24, "type": "METRIC", "confidence": 0.8618425130844116}]}, {"text": "Decoding was performed using the MOSES decoder.", "labels": [], "entities": [{"text": "MOSES decoder", "start_pos": 33, "end_pos": 46, "type": "DATASET", "confidence": 0.9650425612926483}]}, {"text": "Stanford constituency parser () was used for parsing.", "labels": [], "entities": [{"text": "Stanford constituency parser", "start_pos": 0, "end_pos": 28, "type": "DATASET", "confidence": 0.8219941655794779}, {"text": "parsing", "start_pos": 45, "end_pos": 52, "type": "TASK", "confidence": 0.9863713383674622}]}, {"text": "above describes with the help of an example how the reordering and hence the translation quality has improved.", "labels": [], "entities": []}, {"text": "From the example it can be seen that the translation by system using our approach is better than the other two systems.", "labels": [], "entities": []}, {"text": "The output translation is structurally more correct in our approach and conveys the same meaning with respect to the reference translation.", "labels": [], "entities": []}, {"text": "The below lists four different evaluations of the systems understudy.", "labels": [], "entities": []}, {"text": "For BLEU and NIST higher score is considered as better and for mWER and mPER lower score is desirable.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 4, "end_pos": 8, "type": "METRIC", "confidence": 0.9928394556045532}, {"text": "NIST", "start_pos": 13, "end_pos": 17, "type": "DATASET", "confidence": 0.9029120206832886}, {"text": "mWER", "start_pos": 63, "end_pos": 67, "type": "DATASET", "confidence": 0.8478578329086304}]}, {"text": "Table 5 shows the results of comparative evaluation of baseline, limited reordering and our approach with improved reordering.", "labels": [], "entities": []}, {"text": "We find that addition of more reordering rules show substantial improvements over the baseline phrase based system and the limited reordering system.", "labels": [], "entities": []}, {"text": "The impact of improved syntactic reordering can be seen as the BLEU and NIST scores have increased whereas mWER and mPER scores have decreased.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 63, "end_pos": 67, "type": "METRIC", "confidence": 0.9990516304969788}]}, {"text": "above shows the count of overall phrases and distinct phrases (distinct on source) for baseline, limited reordering approach and our improved reordering approach.", "labels": [], "entities": []}, {"text": "The table also shows increase over baseline (IOBL) and percentage increase over baseline(%IOBL) for limited reordering and improved reordering.", "labels": [], "entities": [{"text": "baseline (IOBL)", "start_pos": 35, "end_pos": 50, "type": "METRIC", "confidence": 0.7374908477067947}, {"text": "IOBL", "start_pos": 90, "end_pos": 94, "type": "METRIC", "confidence": 0.9507335424423218}]}, {"text": "We have observed that no. of distinct phrases extracted from the training corpus get increased.", "labels": [], "entities": []}, {"text": "The %IOBL for bigger phrases is more compare to shorter phrases.", "labels": [], "entities": [{"text": "IOBL", "start_pos": 5, "end_pos": 9, "type": "METRIC", "confidence": 0.99808669090271}]}, {"text": "This can be attributed to the better alignments resulting in extraction of more phrases (.", "labels": [], "entities": []}], "tableCaptions": []}