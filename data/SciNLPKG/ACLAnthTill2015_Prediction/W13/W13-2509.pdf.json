{"title": [{"text": "Improving MT System Using Extracted Parallel Fragments of Text from Comparable Corpora", "labels": [], "entities": [{"text": "MT", "start_pos": 10, "end_pos": 12, "type": "TASK", "confidence": 0.8361392617225647}]}], "abstractContent": [{"text": "In this article, we present an automated approach of extracting English-Bengali parallel fragments of text from comparable corpora created using Wikipedia documents.", "labels": [], "entities": []}, {"text": "Our approach exploits the multilingualism of Wiki-pedia.", "labels": [], "entities": []}, {"text": "The most important fact is that this approach does not need any domain specific corpus.", "labels": [], "entities": []}, {"text": "We have been able to improve the BLEU score of an existing domain specific English-Bengali machine translation system by 11.14%.", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 33, "end_pos": 43, "type": "METRIC", "confidence": 0.9814248383045197}, {"text": "English-Bengali machine translation", "start_pos": 75, "end_pos": 110, "type": "TASK", "confidence": 0.672799289226532}]}], "introductionContent": [{"text": "Recently comparable corpora have got great attention in the field of NLP.", "labels": [], "entities": []}, {"text": "Extracting parallel fragments of texts, paraphrases or sentences from comparable corpora are particularly useful for any statistical machine translation system (SMT) ( as the size of the parallel corpus plays major role in any SMT performance.", "labels": [], "entities": [{"text": "Extracting parallel fragments of texts, paraphrases or sentences from comparable corpora", "start_pos": 0, "end_pos": 88, "type": "TASK", "confidence": 0.7491288383801779}, {"text": "statistical machine translation system (SMT)", "start_pos": 121, "end_pos": 165, "type": "TASK", "confidence": 0.7183374719960349}, {"text": "SMT", "start_pos": 227, "end_pos": 230, "type": "TASK", "confidence": 0.9942409992218018}]}, {"text": "Extracted parallel phrases from comparable corpora are added with the training corpus as additional data that is expected to facilitate better performance of machine translation systems specifically for those language pairs which have limited parallel resources available.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 158, "end_pos": 177, "type": "TASK", "confidence": 0.7187823802232742}]}, {"text": "In this work, we try to extract English-Bengali parallel fragments of text from comparable corpora.", "labels": [], "entities": []}, {"text": "We have developed an aligned corpus of English-Bengali document pairs using Wikipedia.", "labels": [], "entities": []}, {"text": "Wikipedia is a huge collection of documents in many different languages.", "labels": [], "entities": [{"text": "Wikipedia", "start_pos": 0, "end_pos": 9, "type": "DATASET", "confidence": 0.93825364112854}]}, {"text": "We first collect an English document from Wikipedia and then follow the interlanguage link to find the same document in Bengali (obviously, if such a link exists).", "labels": [], "entities": []}, {"text": "In this way, we create a small corpus.", "labels": [], "entities": []}, {"text": "We assume that such English-Bengali document pairs from Wikipedia are already comparable since they talk about the same entity.", "labels": [], "entities": []}, {"text": "Although each English-Bengali document pair talks about the same entity, most of the times they are not exact translation of each other.", "labels": [], "entities": []}, {"text": "And as a result, parallel fragments of text are rarely found in these document pairs.", "labels": [], "entities": []}, {"text": "The bigger the size of the fragment the less probable it is to find its parallel version in the target side.", "labels": [], "entities": []}, {"text": "Nevertheless, there is always chance of getting parallel phrase, tokens or even sentences in comparable documents.", "labels": [], "entities": []}, {"text": "The challenge is to find those parallel texts which can be useful in increasing machine translation performance.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 80, "end_pos": 99, "type": "TASK", "confidence": 0.8051242530345917}]}, {"text": "In our present work, we have concentrated on finding small fragments of parallel text instead of rigidly looking for parallelism at entire sentential level.", "labels": [], "entities": []}, {"text": "believed that comparable corpora tend to have parallel data at sub-sentential level.", "labels": [], "entities": []}, {"text": "This approach is particularly useful for this type of corpus under consideration, because there is a very little chance of getting exact translation of bigger fragments of text in the target side.", "labels": [], "entities": []}, {"text": "Instead, searching for parallel chunks would be more logical.", "labels": [], "entities": []}, {"text": "If a sentence in the source side has a parallel sentence in the target side, then all of its chunks need to have their parallel translations in the target side as well.", "labels": [], "entities": []}, {"text": "It is to be noted that, although we have document level alignment in our corpus, it is somehow ad-hoc i.e. the documents in the corpus do not belong to any particular domain.", "labels": [], "entities": []}, {"text": "Even with such a corpus we have been able to improve the performance of an existing machine translation system built on tourism domain.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 84, "end_pos": 103, "type": "TASK", "confidence": 0.7447509467601776}]}, {"text": "This also signifies our contribution towards domain adaptation of machine translation systems.", "labels": [], "entities": [{"text": "domain adaptation", "start_pos": 45, "end_pos": 62, "type": "TASK", "confidence": 0.7280154228210449}, {"text": "machine translation", "start_pos": 66, "end_pos": 85, "type": "TASK", "confidence": 0.7100906372070312}]}, {"text": "The rest of the paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 describes the related work.", "labels": [], "entities": []}, {"text": "Section 3 describes the preparation of the comparable corpus.", "labels": [], "entities": []}, {"text": "The system architecture is described in section 4.", "labels": [], "entities": []}, {"text": "Section 5 describes the experiments we conducted and presents the results.", "labels": [], "entities": []}, {"text": "Finally the conclusion is drawn in section 6.", "labels": [], "entities": []}], "datasetContent": [{"text": "We carried out evaluation of the MT quality using two automatic MT evaluation metrics: BLEU () and NIST.", "labels": [], "entities": [{"text": "MT", "start_pos": 33, "end_pos": 35, "type": "TASK", "confidence": 0.9912487268447876}, {"text": "MT", "start_pos": 64, "end_pos": 66, "type": "TASK", "confidence": 0.9767442941665649}, {"text": "BLEU", "start_pos": 87, "end_pos": 91, "type": "METRIC", "confidence": 0.9987095594406128}, {"text": "NIST", "start_pos": 99, "end_pos": 103, "type": "DATASET", "confidence": 0.9249777793884277}]}, {"text": "For the PB-SMT experiments, inclusion of the extracted strict merged parallel fragments from comparable corpora as additional training data presented some improvements over the PB-SMT baseline.", "labels": [], "entities": [{"text": "PB-SMT baseline", "start_pos": 177, "end_pos": 192, "type": "DATASET", "confidence": 0.8746185898780823}]}, {"text": "Window based extracted fragments are added separately with parallel corpus and that also provides some improvements over the PB baseline; however inclusion of window based extracted phrases in baseline system with phrase length 7 improves over both strict and baseline in term of BLEU score and NIST score.", "labels": [], "entities": [{"text": "PB baseline", "start_pos": 125, "end_pos": 136, "type": "DATASET", "confidence": 0.8270671665668488}, {"text": "BLEU score", "start_pos": 280, "end_pos": 290, "type": "METRIC", "confidence": 0.9832502603530884}, {"text": "NIST score", "start_pos": 295, "end_pos": 305, "type": "DATASET", "confidence": 0.5519273281097412}]}, {"text": "shows the performance of the PB-SMT system that shows an improvement over baseline with both strict and window based merging even if, we change their phrase length from 4 to 7.", "labels": [], "entities": []}, {"text": "shows that the best improvement is achieved when we add parallel chunks as window merging with phrase length 7.", "labels": [], "entities": []}, {"text": "It gives 1.19 BLEU point, i.e., 11.14% relative improvement over baseline system.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 14, "end_pos": 18, "type": "METRIC", "confidence": 0.9984884262084961}]}, {"text": "The NIST score could be improved up to 4.12%.", "labels": [], "entities": [{"text": "NIST score", "start_pos": 4, "end_pos": 14, "type": "DATASET", "confidence": 0.6598900258541107}]}, {"text": "Bengali is a morphologically rich language and has relatively free phrase order.", "labels": [], "entities": []}, {"text": "The strict based extraction does not reflect much improvement compared to the window based extraction because strict-merging (Procedure Strict_Merge) cannot cover up all the segments on either side, so very few parallel extractions have been found compared to window based extraction.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1. Statistics of the Comparable Corpus", "labels": [], "entities": []}, {"text": " Table 2. Number of Parallel Chunks found", "labels": [], "entities": [{"text": "Number", "start_pos": 10, "end_pos": 16, "type": "METRIC", "confidence": 0.9688905477523804}]}]}