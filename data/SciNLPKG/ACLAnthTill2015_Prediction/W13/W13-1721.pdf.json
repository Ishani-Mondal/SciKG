{"title": [{"text": "Prompt-based Content Scoring for Automated Spoken Language Assessment", "labels": [], "entities": [{"text": "Prompt-based Content Scoring", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.5972457428773245}, {"text": "Spoken Language Assessment", "start_pos": 43, "end_pos": 69, "type": "TASK", "confidence": 0.7176663080851237}]}], "abstractContent": [{"text": "This paper investigates the use of prompt-based content features for the automated assessment of spontaneous speech in a spoken language proficiency assessment.", "labels": [], "entities": []}, {"text": "The results show that single highest performing prompt-based content feature measures the number of unique lexical types that overlap with the listening materials and are not contained in either the reading materials or a sample response , with a correlation of r = 0.450 with holistic proficiency scores provided by humans.", "labels": [], "entities": []}, {"text": "Furthermore, linear regression scoring models that combine the proposed prompt-based content features with additional spoken language proficiency features are shown to achieve competitive performance with scoring models using content features based on pre-scored responses.", "labels": [], "entities": []}], "introductionContent": [{"text": "A spoken language proficiency assessment should provide information about how well the non-native speaker will be able to perform a wide range of tasks in the target language.", "labels": [], "entities": [{"text": "spoken language proficiency", "start_pos": 2, "end_pos": 29, "type": "TASK", "confidence": 0.6951716542243958}]}, {"text": "Therefore, in order to provide a full evaluation of the non-native speaker's speaking proficiency, the assessment should include some tasks eliciting unscripted, spontaneous speech.", "labels": [], "entities": []}, {"text": "This goal, however, is hard to achieve in the context of a spoken language assessment which employs automated scoring, due to the difficulties in developing accurate automatic speech recognition (ASR) technology for non-native speech and in extracting valid and reliable features.", "labels": [], "entities": [{"text": "accurate automatic speech recognition (ASR)", "start_pos": 157, "end_pos": 200, "type": "TASK", "confidence": 0.7169875970908574}]}, {"text": "Because of this, most spoken language proficiency assessments which use automated scoring have focused on restricted speech, and have included tasks such as reading a word / sentence / paragraph out loud, answering single-word factual questions, etc.", "labels": [], "entities": []}, {"text": "(. In order to address this need, some automated spoken language assessment systems have also included tasks which elicit spontaneous speech.", "labels": [], "entities": []}, {"text": "However, these systems have focused primarily on a nonnative speaker's pronunciation, prosody, and fluency in their scoring models, since these types of features are relatively robust to ASR errors.", "labels": [], "entities": [{"text": "ASR", "start_pos": 187, "end_pos": 190, "type": "TASK", "confidence": 0.987027108669281}]}, {"text": "Some recent studies have investigated the use of features related to a spoken response's content, such as (.", "labels": [], "entities": []}, {"text": "However, the approach to content scoring taken in that study requires a large amount of responses for each prompt to be provided with human scores in order to train the content models.", "labels": [], "entities": [{"text": "content scoring", "start_pos": 25, "end_pos": 40, "type": "TASK", "confidence": 0.7838859260082245}]}, {"text": "This approach is not practical fora large-scale, high-stakes assessment which regularly introduces many new prompts into the assessmentobtaining the required number of scored training responses for each prompt would be quite expensive and could lead to potential security concerns for the assessment.", "labels": [], "entities": []}, {"text": "Therefore, it would be desirable to develop an approach to content scoring which does not require a large amount of actual responses to train the models.", "labels": [], "entities": [{"text": "content scoring", "start_pos": 59, "end_pos": 74, "type": "TASK", "confidence": 0.7695770263671875}]}, {"text": "In this paper, we propose such a method which uses the stimulus materials for each prompt contained in the assessment to evaluate the content in a spoken response.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Correlations of individual content features with  holistic human scores on the training partition", "labels": [], "entities": []}, {"text": " Table 3: Performance of scoring models with the addition  of content features", "labels": [], "entities": []}]}