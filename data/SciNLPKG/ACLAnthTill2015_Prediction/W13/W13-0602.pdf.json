{"title": [{"text": "Can distributional approaches improve on Good Old-Fashioned Lexical Semantics?", "labels": [], "entities": []}], "abstractContent": [{"text": "In this position paper, I discuss some linguistic problems that computational work on lexical semantics has attempted to address in the past and the implications for alternative models which incorporate distributional information.", "labels": [], "entities": []}, {"text": "I concentrate in particular on phenomena involving count/mass distinctions, where older approaches attempted to use lexical semantics in their models of syntax.", "labels": [], "entities": [{"text": "count/mass distinctions", "start_pos": 51, "end_pos": 74, "type": "TASK", "confidence": 0.6115974113345146}]}, {"text": "I outline methods by which the earlier models allowed the transmission of information between lexical items (regular polysemy and inheritance) and address the possibility that similar techniques could usefully be incorporated into distributional models.", "labels": [], "entities": []}], "introductionContent": [{"text": "While there has been much recent discussion of techniques for developing compositional approaches to distributional semantics, especially with respect to particular categories of phrase (e.g., adjective-noun), as far as I am aware, there has been no attempt to discuss systematically all the roles that distributional semantic representations might play in the production of a model of a sentence.", "labels": [], "entities": []}, {"text": "Indeed, from the viewpoint of researchers working on 'traditional' areas of computational linguistics, such as parsing and generation, and those primarily interested in modeling language for its own sake, rather than application-building, the extensive work on distributional semantics has been somewhat disappointing in failing to provide models which are integrated with existing work to help solve long-standing problems.", "labels": [], "entities": [{"text": "parsing and generation", "start_pos": 111, "end_pos": 133, "type": "TASK", "confidence": 0.844015638033549}]}, {"text": "In some respects, most work on distributional semantics lacks ambition compared to earlier research on lexical semantics, in that previous approaches at least attempted to provide accounts that were fully integrated with syntax and full-coverage compositional semantics: i.e., which used lexical semantics as part of the models that assigned syntactic structure or logical form.", "labels": [], "entities": []}, {"text": "There are reasons to think that distributional approaches could well be more appropriate in such contexts, but a demonstration of this will involve looking at abroad range of phenomena.", "labels": [], "entities": []}, {"text": "This paper is intended as a first step in outlining some of the issues that might be considered.", "labels": [], "entities": []}, {"text": "I first want to distinguish the discussion of lexical meaning here from the various approaches to deriving distributional meaning from sentences investigated by,,, and others which in turn relates to previous approaches to combining connectionist and symbolic approaches (e.g.,).", "labels": [], "entities": []}, {"text": "That line of work assumes that a syntactic representation (or perhaps a logical form) is available to guide the process of composition of distributions.", "labels": [], "entities": []}, {"text": "This work is mostly orthogonal to the issue I wish to discuss here, which is whether the lexical phenomena addressed by earlier approaches might be modelled distributionally and whether this has implications for the overall architecture: for instance, in those case where lexical semantics affects syntax, some mechanism is required in the overall architecture to make syntax sensitive to the lexical semantic representation.", "labels": [], "entities": []}, {"text": "This is not to say that there are no points of contact.", "labels": [], "entities": []}, {"text": "For instance, in the notion of cocomposition described in Pustejovsky's Generative Lexicon (GL) work (e.g.,) the composition function is determined both by functor and argument.", "labels": [], "entities": []}, {"text": "This can be perhaps related to some of the more recent work on composition with distributional semantics, where individual words can be associated with different composition functions (as suggested by).", "labels": [], "entities": []}, {"text": "But GL is an exception in treating composition as part of a theory of lexical semantics, and even GL makes rather conventional assumptions about compositional semantics in many respects.", "labels": [], "entities": []}, {"text": "Hence discussion of this is not part of the current paper.", "labels": [], "entities": []}, {"text": "I will concentrate hereon research on modelling the behaviour of individual words rather than work on the traditional relationships between words (or word senses) -hyponymy, synonymy, antonymy and meronymy.", "labels": [], "entities": []}, {"text": "Though this is not the focus of the current discussion, I will briefly touch on the use of hyponymy relationships in modelling the semantics of individual lexemes in \u00a74.", "labels": [], "entities": []}, {"text": "At this point, a nomenclature issue arises, since there is no good collective term for the non-distributional approaches.", "labels": [], "entities": []}, {"text": "'Non-distributional' is clunky.", "labels": [], "entities": []}, {"text": "To talk about 'traditional' or 'classical' lexical semantics seems inappropriate given the the earliest distributional work (e.g., predates, for example, the feature-based approach of (the first computational work on distributions was underway at this point, although the first publication I am aware of is).", "labels": [], "entities": []}, {"text": "The term 'symbolic' is problematic, since distributional semantics is also symbolic.", "labels": [], "entities": []}, {"text": "So, in the absence of a better alternative, I will use 'Good old-fashioned lexical semantics' (GOFLS) by analogy with Haugeland's 'Good old-fashioned AI.", "labels": [], "entities": [{"text": "GOFLS", "start_pos": 95, "end_pos": 100, "type": "METRIC", "confidence": 0.9188108444213867}]}, {"text": "Hence the question that forms the title of this paper: \"Can distributional approaches improve on Good Old-Fashioned Lexical Semantics?\".", "labels": [], "entities": []}, {"text": "Models using hand-crafted GOFLS were integrated into parsing in a range of approaches from the 1970s onwards.", "labels": [], "entities": [{"text": "parsing", "start_pos": 53, "end_pos": 60, "type": "TASK", "confidence": 0.9760202169418335}]}, {"text": "For example, used semantic preferences expressed in terms of semantic primitives specified by for disambiguation with an augmented transition network (ATN) parser.", "labels": [], "entities": []}, {"text": "More complex models were later investigated within feature structure formalisms, perhaps most extensively within Pustejovsky's Generative Lexicon (GL) framework.", "labels": [], "entities": []}, {"text": "Such approaches combine syntax, compositional and lexical semantics within one model and thus lexical semantics can influence and constrain syntax.", "labels": [], "entities": []}, {"text": "This type of approach had some success in the 1980s and early 1990s in limited domains, but failed to scale to broad-coverage NLP.", "labels": [], "entities": []}, {"text": "However, the models were (and are) nevertheless of interest to linguists and to psycholinguists.", "labels": [], "entities": []}, {"text": "Seen from the perspective of using computational modeling to formally investigate language, they have therefore been partially successful.", "labels": [], "entities": []}, {"text": "Nevertheless, I think it is plausible to claim that the failure of GOFLS approaches in a computational setting was not just due to lack of resources to build highly complex lexicons, but to underlying problems with models that do not cope well with the 'messiness' of the actual data.", "labels": [], "entities": []}, {"text": "Verspoor's detailed corpus investigation of some of the 'classic' GL cocomposition phenomena) is a casein point: to allow for the data therewith a GOFLS model would have required fine-grained distinctions to be drawn which were otherwise unmotivated.", "labels": [], "entities": []}, {"text": "Since that was precisely the problem with previous approaches to lexical semantics that had partly motivated the development of GL (see Pustejovsky's discussion and criticism of sense enumeration, for example), there was reason to doubt the classic GL model on theoretical grounds.", "labels": [], "entities": []}, {"text": "Distributional-style approaches have been successfully adopted as models in investigation of some of the 'classic' GL phenomena (e.g.,.", "labels": [], "entities": []}, {"text": "However, these models are partial in that the distributional techniques have been used in isolation, rather than as part of an integrated syntactic-logical-distributional model.", "labels": [], "entities": []}, {"text": "Furthermore, the aim inmost published work is to show the best performance on a particular test set, rather than to build models which demonstrate good performance on abroad range of phenomena, let alone build fully-integrated broad-coverage systems.", "labels": [], "entities": []}, {"text": "It therefore seems worthwhile to revisit some of the roles that GOFLS played in the earlier work, to investigate whether distributional semantics is really a promising alternative and to look at the requirements for distributional models under these assumptions.", "labels": [], "entities": []}, {"text": "The viewpoint here is a theoretical/formal one (rather than practically-oriented NLP): what role can distributional models play in accounts of lexical meaning that aim to be linguistically (and psycholinguistically) plausible?", "labels": [], "entities": []}, {"text": "The current paper is very preliminary -it concentrates on issues relating to the interaction of syntax and lexical semantics with respect to the count/mass distinction, and on the treatment of regular polysemy.", "labels": [], "entities": []}, {"text": "I will draw a distinction between the use of distributional techniques for acquisition of lexical semantic information fora GOFLS approach and models which use distributions directly.", "labels": [], "entities": []}, {"text": "For instance, some approaches to interpreting compound nouns use semantic primitives to represent the relationships between the elements in the compound (such as Levi's classes: BE, HAVE and so on).", "labels": [], "entities": [{"text": "interpreting compound nouns", "start_pos": 33, "end_pos": 60, "type": "TASK", "confidence": 0.8813859224319458}, {"text": "BE", "start_pos": 178, "end_pos": 180, "type": "METRIC", "confidence": 0.9971832633018494}, {"text": "HAVE", "start_pos": 182, "end_pos": 186, "type": "METRIC", "confidence": 0.8091573119163513}]}, {"text": "If these classes form part of the representation for the utterance, or are used in other processing, then even if the classes are determined via distributions, the final model is non-distributional.", "labels": [], "entities": []}, {"text": "In contrast, a genuinely distributional model would represent the relationships themselves as distributions.", "labels": [], "entities": []}, {"text": "Of course, the status of the primitives is not always clear in particular experiments: they maybe seen as a convenient way of categorizing classes of distributions, for instance for evaluation purposes.", "labels": [], "entities": []}, {"text": "Without the integration of models into larger frameworks, such distinctions are naturally a little fuzzy.", "labels": [], "entities": []}, {"text": "One deliberate omission here is any discussion of disambiguation or selectional preferences.", "labels": [], "entities": []}, {"text": "It seems very plausible that distributions might be used to improve a parse-ranking model, and it is surprising there has been so little published work in this area, since it would seem a very useful way of evaluating different distributional techniques.", "labels": [], "entities": []}, {"text": "That is, I would expect a good distributional model to be able to capture the sort of information about semantics that is necessary to resolve some proportion of coordination and PPattachment ambiguities, and to be a much more satisfactory way of doing this than the earlier semantic primitive approaches.", "labels": [], "entities": []}, {"text": "However, disambiguation in principle requires open-ended models of concepts.", "labels": [], "entities": []}, {"text": "That is, in order to disambiguate some utterances, detailed knowledge of the world is required (as has long been recognised e.g.,).", "labels": [], "entities": []}, {"text": "To take a specific example: (1) Follow the path from the bend in the road to the car park.", "labels": [], "entities": []}, {"text": "It is reasonable that distributional semantics might allow partial disambiguation of the PP-attachment (e.g., determining that 'in the road' attaches to 'bend'), but without context (which might only be apparent on the ground rather than in the text) it is not clear how to attach 'to the car park'.", "labels": [], "entities": []}, {"text": "Indeed, examples of this type often cannot be disambiguated by human annotators who lack access to the full context.", "labels": [], "entities": []}, {"text": "For this reason, we cannot use disambiguation examples to test what information needs to be accessible in principle in a particular model, since in the worst case any information could be relevant (i.e., disambiguation is AI-complete).", "labels": [], "entities": []}, {"text": "In this paper, I will use two interrelated phenomena in order to look at how distributional semantics might replace GOFLS and what sort of models might be required.", "labels": [], "entities": [{"text": "GOFLS", "start_pos": 116, "end_pos": 121, "type": "DATASET", "confidence": 0.667290210723877}]}, {"text": "In \u00a72, I will discuss some semantic constraints on grammatical behaviour.", "labels": [], "entities": []}, {"text": "A variety of phenomena related to regular polysemy are then discussed in \u00a73.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": []}