{"title": [{"text": "Word Similarity Using Constructions as Contextual Features 1", "labels": [], "entities": [{"text": "Word Similarity", "start_pos": 0, "end_pos": 15, "type": "TASK", "confidence": 0.6981972903013229}]}], "abstractContent": [{"text": "1 We propose and implement an alternative source of contextual features for word similarity detection based on the notion of lexico-grammatical construction.", "labels": [], "entities": [{"text": "word similarity detection", "start_pos": 76, "end_pos": 101, "type": "TASK", "confidence": 0.7977341214815775}]}, {"text": "On the assumption that selectional restrictions provide indicators of the semantic similarity of words attested in selected positions, we extend the notion of selection beyond that of single selecting heads to multiword constructions exerting se-lectional preferences.", "labels": [], "entities": []}, {"text": "Our model of 92 million cross-indexed hybrid n-grams (serving as our machine-tractable proxy for constructions) extracted from BNC provides the source of contextual features.", "labels": [], "entities": [{"text": "BNC", "start_pos": 127, "end_pos": 130, "type": "DATASET", "confidence": 0.9527579545974731}]}, {"text": "We compare results with those of a grammatical dependency approach (Lin 1998), testing both against WordNet-based similarity rankings (Lin 1998; Resnik 1995).", "labels": [], "entities": []}, {"text": "Averaged over the entire set of target nouns and 10-best candidate similar words, Lin's approach gives overall similarity results closer to WordNet rankings than the con-structional approach does, while the construc-tional approach overtakes Lin's in approximating WordNet similarity for target nouns with a frequency over 3000.", "labels": [], "entities": [{"text": "similarity", "start_pos": 111, "end_pos": 121, "type": "METRIC", "confidence": 0.9420801997184753}, {"text": "WordNet", "start_pos": 140, "end_pos": 147, "type": "DATASET", "confidence": 0.8874018788337708}]}, {"text": "While this suggests feature sparseness for constructions that resolves with higher frequency nouns, constructions as shared contextual features render a much higher yield in similarity performance in approximating WordNet similarity than grammatical relations do.", "labels": [], "entities": []}, {"text": "We examine some cases in detail showing the sorts of similarity detected by a construction-al approach that are undetected by a grammatical relations approach or by WordNet or both and thus overlooked in benchmark evaluations .", "labels": [], "entities": []}], "introductionContent": [{"text": "Distributional approaches to semantics have contributed substantially to computational techniques for detecting or judging the semantic similarity of words fora wide range of applications.", "labels": [], "entities": [{"text": "detecting or judging the semantic similarity of words", "start_pos": 102, "end_pos": 155, "type": "TASK", "confidence": 0.789256252348423}]}, {"text": "Such approaches work from the assumption that the distribution (or the set of contexts) of a word reflect the meaning of that word and, accordingly, that words with similar distributions have similar meanings, inter alia).", "labels": [], "entities": []}, {"text": "Computational work taking such a distributional approach involves two dimensions: (1) some operationalization of the notion 'context' used in determining a word's distribution, and (2) some means of measuring similarity between or among sets of contexts that constitute a word's distribution.", "labels": [], "entities": []}, {"text": "Such work typically involves extracting from a reference corpus the contexts of the candidate words, under some specified definition of context, and rendering these contexts as feature vectors in a vector space that can in turn be compared for (dis)similarity.", "labels": [], "entities": []}, {"text": "In this paper we propose a novel construal of context and contextual features in determining word similarity distributionally and describe and evaluate an implementation of it.", "labels": [], "entities": []}, {"text": "A motivating premise for our approach is that in comparing words by comparing quantitative measures of their distributions, certain details of these distributions and the contexts that constitute them are obscured.", "labels": [], "entities": []}, {"text": "For numerous applications, such as query expansion, document similarity judgment and document classification, this opacity maybe irrelevant.", "labels": [], "entities": [{"text": "query expansion", "start_pos": 35, "end_pos": 50, "type": "TASK", "confidence": 0.8338019549846649}, {"text": "document similarity judgment", "start_pos": 52, "end_pos": 80, "type": "TASK", "confidence": 0.74658731619517}, {"text": "document classification", "start_pos": 85, "end_pos": 108, "type": "TASK", "confidence": 0.7612228691577911}]}, {"text": "There are, however, applications where the loss of some of this obscured detail comes at a cost, that is, where it may become relevant to ask fora pair or set of words not only 'How similar are they?'", "labels": [], "entities": []}, {"text": "but 'How are they similar?'", "labels": [], "entities": []}, {"text": "While current distributional approaches generally focus on the first question, we would like to build on those results to explore ways to further address the second.", "labels": [], "entities": []}], "datasetContent": [{"text": "We first consider here the extent of overlap in the 10-best results produced by the constructional and relational approaches, then compare both constructional and relational approaches as they approximate word similarity scores derived from WordNet, and finally elaborate on specific illustrative cases.", "labels": [], "entities": []}], "tableCaptions": []}