{"title": [{"text": "KUNLP Grammatical Error Correction System For CoNLL-2013 Shared Task", "labels": [], "entities": []}], "abstractContent": [{"text": "This paper describes an English grammatical error correction system for CoNLL-2013 shared task.", "labels": [], "entities": [{"text": "English grammatical error correction", "start_pos": 24, "end_pos": 60, "type": "TASK", "confidence": 0.5390240103006363}, {"text": "CoNLL-2013 shared task", "start_pos": 72, "end_pos": 94, "type": "DATASET", "confidence": 0.7337507804234823}]}, {"text": "Error types covered by our system are article/determiner, preposition , and noun number agreement.", "labels": [], "entities": [{"text": "noun number agreement", "start_pos": 76, "end_pos": 97, "type": "TASK", "confidence": 0.6546392937501272}]}, {"text": "This work is our first attempt on grammatical error correction research.", "labels": [], "entities": [{"text": "grammatical error correction research", "start_pos": 34, "end_pos": 71, "type": "TASK", "confidence": 0.7911599278450012}]}, {"text": "In this work, we only focus on reimplementing the techniques presented before and optimizing the performance.", "labels": [], "entities": []}, {"text": "As a result of the implementation , our system's final F1-score by m2 scorer is 0.1282 in our internal test set.", "labels": [], "entities": [{"text": "F1-score", "start_pos": 55, "end_pos": 63, "type": "METRIC", "confidence": 0.9917697906494141}]}], "introductionContent": [{"text": "As the number of English learners is increasing world widely, the research topic of automated grammar error correction is lively discussed.", "labels": [], "entities": [{"text": "automated grammar error correction", "start_pos": 84, "end_pos": 118, "type": "TASK", "confidence": 0.5703481733798981}]}, {"text": "However, automated grammar error correction is a very difficult field and the result is not satisfactory.", "labels": [], "entities": [{"text": "automated grammar error correction", "start_pos": 9, "end_pos": 43, "type": "TASK", "confidence": 0.6200837045907974}]}, {"text": "Therefore, the shared task about English error correction has been annually held and many researchers are trying to solve this problem.", "labels": [], "entities": [{"text": "English error correction", "start_pos": 33, "end_pos": 57, "type": "TASK", "confidence": 0.6339673896630605}]}, {"text": "Helping Our Own (HOO) 2011 is a pilot shared task for automated correction of errors in nonnative English speakers' papers.", "labels": [], "entities": [{"text": "Helping Our Own (HOO) 2011", "start_pos": 0, "end_pos": 26, "type": "TASK", "confidence": 0.6354433255536216}, {"text": "automated correction of errors in nonnative English speakers' papers", "start_pos": 54, "end_pos": 122, "type": "TASK", "confidence": 0.8298474020428128}]}, {"text": "The shared task evaluates the performance of detection, recognition, correction on thirteen types of English grammatical errors by using F1-score.", "labels": [], "entities": [{"text": "F1-score", "start_pos": 137, "end_pos": 145, "type": "METRIC", "confidence": 0.9967734217643738}]}, {"text": "Because each error type has different characteristics, they have to use different approaches to correct appropriate error types.", "labels": [], "entities": []}, {"text": "In HOO 2012, only two types of errors, preposition and determiner were handled.", "labels": [], "entities": [{"text": "HOO 2012", "start_pos": 3, "end_pos": 11, "type": "DATASET", "confidence": 0.8361734449863434}, {"text": "determiner", "start_pos": 55, "end_pos": 65, "type": "METRIC", "confidence": 0.8696295022964478}]}, {"text": "This shared task also evaluated the performance of detection, recognition, correction by using F1-score.", "labels": [], "entities": [{"text": "F1-score", "start_pos": 95, "end_pos": 103, "type": "METRIC", "confidence": 0.9953043460845947}]}, {"text": "The best result of the preposition error correction is 0.2371 in F1-score and the determiner error correction is 0.3460 in F1-score.", "labels": [], "entities": [{"text": "preposition error correction", "start_pos": 23, "end_pos": 51, "type": "METRIC", "confidence": 0.7668434580167135}, {"text": "F1-score", "start_pos": 65, "end_pos": 73, "type": "METRIC", "confidence": 0.9990336894989014}, {"text": "determiner error correction", "start_pos": 82, "end_pos": 109, "type": "METRIC", "confidence": 0.9714394410451254}, {"text": "F1-score", "start_pos": 123, "end_pos": 131, "type": "METRIC", "confidence": 0.9870948195457458}]}, {"text": "This year CoNLL 2013 shared task covers five types of errors based on the result of HOO 2012.", "labels": [], "entities": [{"text": "CoNLL 2013 shared task", "start_pos": 10, "end_pos": 32, "type": "DATASET", "confidence": 0.8228051066398621}, {"text": "HOO 2012", "start_pos": 84, "end_pos": 92, "type": "DATASET", "confidence": 0.8135313093662262}]}, {"text": "These error types are determiner, preposition, noun number, verb form, and subject-verb agreement.", "labels": [], "entities": []}, {"text": "Because of the limited amount of time and manpower, we only focus on preposition, determiner and noun number.", "labels": [], "entities": []}], "datasetContent": [{"text": "We will try to train the correction model by using large amount of error free corpus in order to overcome the problem of low recall.", "labels": [], "entities": [{"text": "recall", "start_pos": 125, "end_pos": 131, "type": "METRIC", "confidence": 0.9947537183761597}]}, {"text": "To parse large corpus is very time consuming task.", "labels": [], "entities": [{"text": "parse large corpus", "start_pos": 3, "end_pos": 21, "type": "TASK", "confidence": 0.8654586871465048}]}, {"text": "So, in this experiment, we select 9 features which can be extracted without parsing, and test the possibility of using 9 features by training and testing the correction model.", "labels": [], "entities": []}, {"text": "We have performed two different experiments.", "labels": [], "entities": []}, {"text": "In the first experiment, we have used the word itself as a feature.", "labels": [], "entities": []}, {"text": "In the tables 3\u02dc5, \"Raw Word\" represents the case when we use just the word itself.", "labels": [], "entities": []}, {"text": "In the second experiment, we have used the feature name as the postfix of the feature.", "labels": [], "entities": []}, {"text": "In the tables 3\u02dc5, \"With Feature Name\" represents the case when we attach the feature name to the feature and use it as a feature.", "labels": [], "entities": []}, {"text": "For all experiments, we have tried to differentiate the number of features.", "labels": [], "entities": []}, {"text": "20 features are same as Han's work.", "labels": [], "entities": []}, {"text": "18 features are the case when we exclude 2 features(i.e. wd, wd R(20)).", "labels": [], "entities": []}, {"text": "9 features are the case when we use only features which do not require parsing.", "labels": [], "entities": []}, {"text": "We have experimented with Maximum Entropy learning method, and fixed the iteration number to 200.", "labels": [], "entities": []}, {"text": "shows that the precision has highly increased although the recall has decreased when we add the feature name to the set of features used for learning.", "labels": [], "entities": [{"text": "precision", "start_pos": 15, "end_pos": 24, "type": "METRIC", "confidence": 0.9996453523635864}, {"text": "recall", "start_pos": 59, "end_pos": 65, "type": "METRIC", "confidence": 0.9997382760047913}]}, {"text": "When we use 18 features except wd L(3 words preceding s) and wd R(3 words following s), the error correction system achieves the best performance.", "labels": [], "entities": []}, {"text": "According to the experimental result, we can achieve the better result when we use 18 features and the raw word.", "labels": [], "entities": []}, {"text": "But we select final option using 18 features and the word with feature name because of optimization strategies that improve the precision.: The result of noun number error correction shows that the feature name addition does not improve the precision in the case of article correction, and the set of 18 features achieves the best performance for article correction.", "labels": [], "entities": [{"text": "precision.", "start_pos": 128, "end_pos": 138, "type": "METRIC", "confidence": 0.9992316961288452}, {"text": "noun number error correction", "start_pos": 154, "end_pos": 182, "type": "METRIC", "confidence": 0.5394536554813385}, {"text": "precision", "start_pos": 241, "end_pos": 250, "type": "METRIC", "confidence": 0.9980930685997009}, {"text": "article correction", "start_pos": 266, "end_pos": 284, "type": "TASK", "confidence": 0.7649374604225159}, {"text": "article correction", "start_pos": 347, "end_pos": 365, "type": "TASK", "confidence": 0.7905099093914032}]}, {"text": "Therefore, we just use raw words for features and select 18 features for article correction.", "labels": [], "entities": [{"text": "article correction", "start_pos": 73, "end_pos": 91, "type": "TASK", "confidence": 0.7217296063899994}]}, {"text": "In, features of number 1\u02dc5 belong to the basic feature set and features of number 6\u02dc15 belong to the independent feature set and features of number 16\u02dc23 belong to the complex feature set.", "labels": [], "entities": []}, {"text": "The experimental result with various combinations of feature sets shows that the set of basic and complex features achieves the best precision in spite of low recall as shown in.", "labels": [], "entities": [{"text": "precision", "start_pos": 133, "end_pos": 142, "type": "METRIC", "confidence": 0.9988527297973633}, {"text": "recall", "start_pos": 159, "end_pos": 165, "type": "METRIC", "confidence": 0.9986966252326965}]}, {"text": "We use this option and experimentally select the iteration number 700.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Set of features proposed by (Han et al.,  2010)", "labels": [], "entities": []}, {"text": " Table 3: The result of preposition error correction", "labels": [], "entities": [{"text": "preposition error correction", "start_pos": 24, "end_pos": 52, "type": "TASK", "confidence": 0.6139618357022604}]}, {"text": " Table 4: The result of article error correction", "labels": [], "entities": [{"text": "article error correction", "start_pos": 24, "end_pos": 48, "type": "TASK", "confidence": 0.5894656181335449}]}, {"text": " Table 5: The result of noun number error correc- tion", "labels": [], "entities": [{"text": "noun number error correc- tion", "start_pos": 24, "end_pos": 54, "type": "METRIC", "confidence": 0.5519540111223856}]}]}