{"title": [{"text": "Comparison of Bayesian Discriminative and Generative Models for Dialogue State Tracking", "labels": [], "entities": [{"text": "Dialogue State Tracking", "start_pos": 64, "end_pos": 87, "type": "TASK", "confidence": 0.6977313160896301}]}], "abstractContent": [{"text": "In this paper, we describe two dialogue state tracking models competing in the 2012 Dialogue State Tracking Challenge (DSTC).", "labels": [], "entities": [{"text": "dialogue state tracking", "start_pos": 31, "end_pos": 54, "type": "TASK", "confidence": 0.6367397010326385}, {"text": "2012 Dialogue State Tracking Challenge (DSTC)", "start_pos": 79, "end_pos": 124, "type": "TASK", "confidence": 0.7229033336043358}]}, {"text": "First, we detail a novel discrim-inative dialogue state tracker which directly estimates slot-level beliefs using de-terministic state transition probability distribution.", "labels": [], "entities": []}, {"text": "Second, we present a gener-ative model employing a simple dependency structure to achieve fast inference.", "labels": [], "entities": []}, {"text": "The models are evaluated on the DSTC data, and both significantly outperform the baseline DSTC tracker.", "labels": [], "entities": [{"text": "DSTC data", "start_pos": 32, "end_pos": 41, "type": "DATASET", "confidence": 0.9369103014469147}]}], "introductionContent": [{"text": "The core component of virtually any dialogue system is a dialogue state tracker.", "labels": [], "entities": [{"text": "dialogue state tracker", "start_pos": 57, "end_pos": 79, "type": "TASK", "confidence": 0.6464038193225861}]}, {"text": "Its purpose is to monitor dialogue progress and provide compact representation of the past user input and system output in the form of a dialogue state.", "labels": [], "entities": []}, {"text": "In previous works on this topics, used particle filters to perform inference in a complex Bayesian network modelling the dialogue state, presented a generative tracker and showed how to train an observation model from transcribed data, grouped indistinguishable dialogue states into partitions and consequently performed dialogue state tracking on these partitions instead of the individual states, used a dynamic Bayesian network to represent the dialogue model in an approximate form, and used probabilistic ontology trees.", "labels": [], "entities": []}, {"text": "In this paper, we describe two probabilistic dialogue state trackers: (1) a discriminative dialogue state tracker (DT) -a model using a simple deterministic state transition probability, resulting in significant computational savings, and (2), a generative dialogue state tracker (GT) -a model using simple conditional dependency structure with tied and handcrafted model parameters.", "labels": [], "entities": [{"text": "generative dialogue state tracker (GT)", "start_pos": 246, "end_pos": 284, "type": "TASK", "confidence": 0.758163835321154}]}, {"text": "Both trackers were evaluated in the DSTC.", "labels": [], "entities": [{"text": "DSTC", "start_pos": 36, "end_pos": 40, "type": "DATASET", "confidence": 0.8645435571670532}]}, {"text": "The aim of the DSTC was to provide a common testbed for different dialogue state tracking methods and to evaluate these methods in a unified way.", "labels": [], "entities": [{"text": "dialogue state tracking", "start_pos": 66, "end_pos": 89, "type": "TASK", "confidence": 0.6318061848481497}]}, {"text": "Because of limited space, the interested reader is referred to for information about the data and evaluation metrics used in the challenge.", "labels": [], "entities": []}, {"text": "This paper is structured as follows.", "labels": [], "entities": []}, {"text": "The deterministic and generative trackers are detailed in Section 2 and the presented models are evaluated on the DSTC data in Section 3.", "labels": [], "entities": [{"text": "generative trackers", "start_pos": 22, "end_pos": 41, "type": "TASK", "confidence": 0.9235200881958008}, {"text": "DSTC data", "start_pos": 114, "end_pos": 123, "type": "DATASET", "confidence": 0.9623392820358276}]}, {"text": "Section 4 discusses the obtained results, and Section 5 concludes the paper.", "labels": [], "entities": []}], "datasetContent": [{"text": "The discriminative (DT) and generative dialogue (GT) trackers described in Sections 2.1 and 2.2 were evaluated on the DSTC data.", "labels": [], "entities": [{"text": "generative dialogue (GT) trackers", "start_pos": 28, "end_pos": 61, "type": "TASK", "confidence": 0.8788324296474457}, {"text": "DSTC data", "start_pos": 118, "end_pos": 127, "type": "DATASET", "confidence": 0.9661628901958466}]}, {"text": "The input of DT and GT were the SLU n-best lists either with original probabilities or the scores mapped into the probability space.", "labels": [], "entities": []}, {"text": "The trackers were evaluated on both live and batch data.", "labels": [], "entities": []}, {"text": "The metrics were computed with Schedule 1 (see).", "labels": [], "entities": []}, {"text": "In addition, we include into the evaluation the DSTC baseline tracker.", "labels": [], "entities": [{"text": "DSTC baseline tracker", "start_pos": 48, "end_pos": 69, "type": "DATASET", "confidence": 0.8700292110443115}]}, {"text": "The results on the live and batch data are shown in Table 1 in the Appendix.", "labels": [], "entities": [{"text": "Appendix", "start_pos": 67, "end_pos": 75, "type": "METRIC", "confidence": 0.8794624209403992}]}, {"text": "Please note that the results for GT differ from the results submitted for DSTC.", "labels": [], "entities": [{"text": "DSTC", "start_pos": 74, "end_pos": 78, "type": "DATASET", "confidence": 0.890779435634613}]}, {"text": "Only after the submission deadline, did we find that some of the parameters in the transition model were set incorrectly.", "labels": [], "entities": []}, {"text": "After the setting was fixed, the results improved.", "labels": [], "entities": []}, {"text": "The results show that the DT consistently outperforms the baseline tracker and the DT achieves comparable or better results than the GT.", "labels": [], "entities": []}, {"text": "The DT clearly provides better estimates of the dialogue states because of the incorporation of the context and the processing of multiple hypotheses.", "labels": [], "entities": [{"text": "DT", "start_pos": 4, "end_pos": 6, "type": "TASK", "confidence": 0.6721687912940979}]}, {"text": "To assess the statistical significance of the accuracy metric, 95% confidence scores for all measurements were computed.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 46, "end_pos": 54, "type": "METRIC", "confidence": 0.9993999004364014}]}, {"text": "Overall, the confidence intervals were between 0.1% and 0.4% on the individual tests.", "labels": [], "entities": [{"text": "confidence", "start_pos": 13, "end_pos": 23, "type": "METRIC", "confidence": 0.9980579018592834}]}, {"text": "On this basis, all differences larger than 1.0% can be considered statistically significant.", "labels": [], "entities": []}, {"text": "The GT outperforms the baseline tracker on all but the batch data.", "labels": [], "entities": []}, {"text": "Manual inspection of the results revealed that the generative model is very sensitive to the probabilities assigned to the observations.", "labels": [], "entities": [{"text": "generative", "start_pos": 51, "end_pos": 61, "type": "TASK", "confidence": 0.9735661149024963}]}, {"text": "For the batch data, presumably due to the score normalisation, the probabilities of hypotheses in the n-best lists were very similar to each other.", "labels": [], "entities": []}, {"text": "As a result, the generative model had difficulties discriminating between the observed values.", "labels": [], "entities": [{"text": "generative", "start_pos": 17, "end_pos": 27, "type": "TASK", "confidence": 0.9685884118080139}]}, {"text": "In comparison with all trackers submitted for DSTC, the DT achieves second-best accuracy among the submitted trackers and the GT is among the average trackers.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 80, "end_pos": 88, "type": "METRIC", "confidence": 0.9992614388465881}, {"text": "GT", "start_pos": 126, "end_pos": 128, "type": "METRIC", "confidence": 0.9486066102981567}]}, {"text": "For more details see in the Appendix, where the average scores were computed from the accuracy and the Brier score on test sets 1, 2, 3, and 4.", "labels": [], "entities": [{"text": "Appendix", "start_pos": 28, "end_pos": 36, "type": "METRIC", "confidence": 0.9822577834129333}, {"text": "accuracy", "start_pos": 86, "end_pos": 94, "type": "METRIC", "confidence": 0.9996936321258545}, {"text": "Brier", "start_pos": 103, "end_pos": 108, "type": "METRIC", "confidence": 0.8972135782241821}]}, {"text": "Regarding the Brier score, the results show that the DT outperforms the baseline tracker and estimates the belief state as well as the best tracker in the DSTC.", "labels": [], "entities": [{"text": "Brier score", "start_pos": 14, "end_pos": 25, "type": "METRIC", "confidence": 0.5216314196586609}, {"text": "DSTC", "start_pos": 155, "end_pos": 159, "type": "DATASET", "confidence": 0.9684099555015564}]}, {"text": "This can prove especially important when the tracker is used within a complete dialogue system where the policy decisions do not depend on the best dialogue state but on the belief state.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Accuracy of the trackers on the live and  batch test sets, where BT stands for the DSTC  baseline tracker, DT denotes the discriminative  tracker, and GT denotes the generative tracker.  ALL denotes the average scores over the live and  batch test sets.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9984546899795532}, {"text": "BT", "start_pos": 75, "end_pos": 77, "type": "METRIC", "confidence": 0.9871982932090759}, {"text": "DSTC  baseline tracker", "start_pos": 93, "end_pos": 115, "type": "DATASET", "confidence": 0.8518708149592081}, {"text": "ALL", "start_pos": 197, "end_pos": 200, "type": "METRIC", "confidence": 0.9955784678459167}]}, {"text": " Table 2: Accuracy of the trackers submitted for  the DSTC, where BT -C denotes the DSTC base- line tracker without removing the systematically  erroneous SLU hypotheses, BT denotes the DSTC  baseline tracker, DT denotes the discriminative  tracker, GT denotes the generative tracker, and  team* denote the best trackers submitted by other  teams. The scores are averaged scores obtained on  the four DSTC test sets.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9952219128608704}, {"text": "DSTC test sets", "start_pos": 401, "end_pos": 415, "type": "DATASET", "confidence": 0.9535286823908488}]}, {"text": " Table 3: Example of three turns in which the gen- erative system \"forgets\" the observed value. # de- notes the turn number, P denotes the probability  of the observation, SLU hyp. denotes the observed  hypothesis, GS denotes the belief of the generative  system, and DS denotes the belief of the discrimi- native system.", "labels": [], "entities": [{"text": "SLU hyp.", "start_pos": 172, "end_pos": 180, "type": "METRIC", "confidence": 0.9532006978988647}]}]}