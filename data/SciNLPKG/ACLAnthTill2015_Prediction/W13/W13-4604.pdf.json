{"title": [{"text": "Towards High-Reliability Speech Translation in the Medical Domain", "labels": [], "entities": [{"text": "High-Reliability Speech Translation", "start_pos": 8, "end_pos": 43, "type": "TASK", "confidence": 0.694311777750651}]}], "abstractContent": [{"text": "In this paper, we describe the overall design fora speech translation system that aims to reduce the problems caused by language barriers in medical situations.", "labels": [], "entities": [{"text": "speech translation", "start_pos": 51, "end_pos": 69, "type": "TASK", "confidence": 0.7228002995252609}]}, {"text": "As first steps to building a system according to this design, we describe a collection of a medical corpus, and some translation experiments performed on this corpus.", "labels": [], "entities": []}, {"text": "As a result of the experiments, we find that the best of three modern translation systems is able to translate 33%-81% of the sentences in away such that the main content is understandable .", "labels": [], "entities": []}], "introductionContent": [{"text": "One of the most important elements to provision of high-quality medical service is communication between medical practitioners and patients.", "labels": [], "entities": []}, {"text": "However, in situations where practitioners and patients do not share a common language, the language barrier prevents effective communication, making proper diagnosis and treatment much more difficult.", "labels": [], "entities": []}, {"text": "Language barriers occur in medical situations with immigrants who may speak the language of their country of residence to some extent, but not enough to effectively communicate medical symptoms.", "labels": [], "entities": []}, {"text": "There is also the case of medical tourism, where tourists may visit another country to receive high-quality or affordable medical treatment that is not available in their home country.", "labels": [], "entities": []}, {"text": "One potential method for overcoming the communication barrier in medical situations is through the use of automatic speech translation technology.", "labels": [], "entities": [{"text": "automatic speech translation", "start_pos": 106, "end_pos": 134, "type": "TASK", "confidence": 0.711773693561554}]}, {"text": "Automatic translation of speech in medical situations can be expected to be challenging fora number of reasons.", "labels": [], "entities": [{"text": "Automatic translation of speech", "start_pos": 0, "end_pos": 31, "type": "TASK", "confidence": 0.7866537868976593}]}, {"text": "The first reason is that communication of incomplete or incorrect information could lead to a mistaken diagnosis with severe consequences, and thus extremely high levels of accuracy and reliability are required.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 173, "end_pos": 181, "type": "METRIC", "confidence": 0.9989770650863647}, {"text": "reliability", "start_pos": 186, "end_pos": 197, "type": "METRIC", "confidence": 0.9867907166481018}]}, {"text": "The second reason is that conversation in the medical domain has its own unique vocabulary and expressions, and thus it is natural to assume that we must adapt the system appropriately to the medical domain.", "labels": [], "entities": []}, {"text": "There has been some previous work attempting to adapt communication technology to meet these two challenges.", "labels": [], "entities": []}, {"text": "focus on adapting a translation system to medical vocabulary, although the focus on text translation of medical documents instead of speech translation for communication.", "labels": [], "entities": [{"text": "text translation of medical documents", "start_pos": 84, "end_pos": 121, "type": "TASK", "confidence": 0.8349919199943543}, {"text": "speech translation", "start_pos": 133, "end_pos": 151, "type": "TASK", "confidence": 0.7916093170642853}]}, {"text": "propose a system for reliable multilingual communication, but rely on a graphical interface that is something like a powerful bilingual phrasebook adapted to communication at a hospital reception desk.", "labels": [], "entities": []}, {"text": "In this paper, we describe our vision for full speech translation in medical situations, and some first steps to achieve this vision.", "labels": [], "entities": [{"text": "full speech translation", "start_pos": 42, "end_pos": 65, "type": "TASK", "confidence": 0.658280481894811}]}, {"text": "First, in Section 2 we describe our overall design for the speech translation system.", "labels": [], "entities": [{"text": "speech translation", "start_pos": 59, "end_pos": 77, "type": "TASK", "confidence": 0.8337599039077759}]}, {"text": "This system includes the common components of automatic speech recognition (ASR), machine translation (MT), and textto-speech (TTS), augmented to adapt each component to the task at hand.", "labels": [], "entities": [{"text": "automatic speech recognition (ASR)", "start_pos": 46, "end_pos": 80, "type": "TASK", "confidence": 0.8054006497065226}, {"text": "machine translation (MT)", "start_pos": 82, "end_pos": 106, "type": "TASK", "confidence": 0.823351937532425}]}, {"text": "We also consider what is necessary to ensure the reliability of translation results, and consider the use of a system to allow the conversation to be forwarded to human medical interpreters when necessary.", "labels": [], "entities": [{"text": "reliability", "start_pos": 49, "end_pos": 60, "type": "METRIC", "confidence": 0.9527330994606018}]}, {"text": "In the first step towards achieving a translation system for the medical domain we have also collected a medical-domain corpus for JapaneseEnglish and Japanese-Chinese translation, as described in Section 3.", "labels": [], "entities": [{"text": "Japanese-Chinese translation", "start_pos": 151, "end_pos": 179, "type": "TASK", "confidence": 0.6976170837879181}]}, {"text": "We share some insights gained in collecting this corpus, particularly comparing and contrasting text data from a medical domain bilingual phrasebook, and actual conversational data gathered during doctors' visits.", "labels": [], "entities": []}, {"text": "Based on this data, we then build several prototype translation systems for the four language pairs as described in Section 4.", "labels": [], "entities": []}, {"text": "We perform au-: An overview of the use scenario for the medical translation system.", "labels": [], "entities": [{"text": "medical translation", "start_pos": 56, "end_pos": 75, "type": "TASK", "confidence": 0.7310808300971985}]}, {"text": "tomatic and manual evaluation of the results and evaluate how close we are to our goal of creating a system that can provide a first wave of assistance in medical situations.", "labels": [], "entities": []}, {"text": "In particular, we find that overall four (relatively difficult) language pairs, we are on our way towards creating a practical medical machine translation system, with from 33%-81% of sentences over two tasks and four language pairs having all content understandable with some effort.", "labels": [], "entities": [{"text": "medical machine translation", "start_pos": 127, "end_pos": 154, "type": "TASK", "confidence": 0.6293450593948364}]}, {"text": "Finally, in Section 5 we conclude the paper with a discussion of future work.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section we describe a preliminary evaluation of the effectiveness of automatic translation on the medical domain data described in the previous section.", "labels": [], "entities": [{"text": "automatic translation", "start_pos": 77, "end_pos": 98, "type": "TASK", "confidence": 0.6609218120574951}]}, {"text": "In particular, we focus on the MT component, leaving evaluation of ASR, TTS, and the system as a whole for future work.", "labels": [], "entities": [{"text": "MT", "start_pos": 31, "end_pos": 33, "type": "TASK", "confidence": 0.9930970072746277}, {"text": "ASR", "start_pos": 67, "end_pos": 70, "type": "TASK", "confidence": 0.7860410213470459}, {"text": "TTS", "start_pos": 72, "end_pos": 75, "type": "TASK", "confidence": 0.6748458743095398}]}, {"text": "For the tuning and test data for our translation system, we use the data described in the previous section.", "labels": [], "entities": []}, {"text": "For training, 4,000 sentences is not enough to build an accurate MT system, so we add several additional corpora for each language pair.", "labels": [], "entities": [{"text": "MT", "start_pos": 65, "end_pos": 67, "type": "TASK", "confidence": 0.9931679368019104}]}, {"text": "For Japanese-English parallel training data, we add the Eijiro dictionary 1 and its accompanying sample sentences, the BTEC corpus(), and Wikipedia data from the Kyoto Free Translation Task (Neubig, 2011), fora total of 1.33M parallel sentences and 1.97M dictionary entries.", "labels": [], "entities": [{"text": "Eijiro dictionary 1", "start_pos": 56, "end_pos": 75, "type": "DATASET", "confidence": 0.8593009908994039}, {"text": "BTEC corpus", "start_pos": 119, "end_pos": 130, "type": "DATASET", "confidence": 0.9450287520885468}, {"text": "Kyoto Free Translation Task (Neubig, 2011)", "start_pos": 162, "end_pos": 204, "type": "TASK", "confidence": 0.7060259845521715}]}, {"text": "For Japanese-Chinese parallel training data, we add a dictionary extracted from Wikipedia's language links 2 , the BTEC corpus, and TED talks () fora total of 519k sentences and 184k dictionary entries.", "labels": [], "entities": [{"text": "BTEC corpus", "start_pos": 115, "end_pos": 126, "type": "DATASET", "confidence": 0.9698383212089539}]}, {"text": "In addition, we add monolingual from English GigaWord with 22.5M sentences and Chinese Wikipedia with 841k sentences.", "labels": [], "entities": []}, {"text": "We compare three different statistical translation methodologies: phrase-based MT (PBMT, (), hierarchical phrase-based MT), and forest-to-string MT (F2S, ().", "labels": [], "entities": []}, {"text": "The reason why we test these three methodologies is because the former two methodologies do not rely on syntactic analysis, and thus maybe more robust to conversational input that is ill-formed and/or informal.", "labels": [], "entities": []}, {"text": "On the other hand, using syntactic information has been shown to improve translation, particularly between language pairs with different syntactic structures such as those we are handling in our experiments.", "labels": [], "entities": [{"text": "translation", "start_pos": 73, "end_pos": 84, "type": "TASK", "confidence": 0.970470130443573}]}, {"text": "Thus it will be interesting to see which methodology can produce better results, and also if any difference in the effectiveness of the methodologies will be seen between the two corpora.", "labels": [], "entities": []}, {"text": "For training the translation models and decoding, we use the Moses toolkit ( for) toolkit for F2S with the default settings.", "labels": [], "entities": [{"text": "F2S", "start_pos": 94, "end_pos": 97, "type": "DATASET", "confidence": 0.8649190664291382}]}, {"text": "For training language models, we use SRILM), training Kneser-Ney smoothed 5-gram models for each individual language model training corpus, and linearly interpolating these models to maximize likelihood on the tuning corpus.", "labels": [], "entities": [{"text": "SRILM", "start_pos": 37, "end_pos": 42, "type": "METRIC", "confidence": 0.8176630735397339}]}, {"text": "For tokenization we use the Stanford Tokenizer/Segmenter for English and Chinese (), and the KyTea segmenter for Japanese ).", "labels": [], "entities": []}, {"text": "For syntactic parsing in English and Chinese we use a modified version of the Egret parser, and for Japanese we use the Eda parser and the dependency-to-CFG conversion rules in the Travatar toolkit.", "labels": [], "entities": [{"text": "syntactic parsing", "start_pos": 4, "end_pos": 21, "type": "TASK", "confidence": 0.7040219902992249}]}, {"text": "Alignment is performed using the unsupervised aligner GIZA++ for Japanese-Chinese, and the supervised aligner Nile for Japanese-English (, with the alignment models being trained on the alignments distributed with the Kyoto Free Translation Task.", "labels": [], "entities": [{"text": "Alignment", "start_pos": 0, "end_pos": 9, "type": "TASK", "confidence": 0.9685409665107727}, {"text": "Kyoto Free Translation Task", "start_pos": 218, "end_pos": 245, "type": "DATASET", "confidence": 0.8631315529346466}]}, {"text": "To measure translation accuracy, we use the automatic evaluation measures of BLEU () and RIBES () measured overall sentences in the test corpus.", "labels": [], "entities": [{"text": "translation", "start_pos": 11, "end_pos": 22, "type": "TASK", "confidence": 0.9658192992210388}, {"text": "accuracy", "start_pos": 23, "end_pos": 31, "type": "METRIC", "confidence": 0.8213855028152466}, {"text": "BLEU", "start_pos": 77, "end_pos": 81, "type": "METRIC", "confidence": 0.9987295269966125}, {"text": "RIBES", "start_pos": 89, "end_pos": 94, "type": "METRIC", "confidence": 0.9943885207176208}]}, {"text": "We also perform a manual evaluation on 120 sentences from the phrasebook corpus and 80 sentences from the conversation corpus.", "labels": [], "entities": []}, {"text": "These were randomly selected from all sentences of length 1-30, and graded using 1-5 adequacy (Goto et al., 2011) as our evaluation measure.", "labels": [], "entities": []}, {"text": "We also report the percentage of sentences that received a rating of greater than or equal to 2, indicating that the main points of the sentence can be understood, possibly with some difficulty.", "labels": [], "entities": []}, {"text": "The results of the experimental evaluation are shown in.", "labels": [], "entities": []}, {"text": "This graph shows many results, but we first focus on the furthestmost right graph, which shows the percentage of sentences understandable to some extent for each of the systems.", "labels": [], "entities": []}, {"text": "From this graph, we can see that the scores range from 81% understandable sentences for Japanese-Chinese phrasebook sentences, to only 33% understandable sentences on Japanese-English phrasebook sentences.", "labels": [], "entities": []}, {"text": "On the other hand, for conversational sentences, most language pairs hovered at around 55% understandable, with Japanese-English being significantly worse.", "labels": [], "entities": []}, {"text": "An in-depth analysis of the mistaken sentences identified several issues for improvement that were generally shared by all three systems.", "labels": [], "entities": []}, {"text": "Omitted pronouns: Japanese is a pro-drop language, which means that pronouns, usually the subject of the sentence can be omitted and inferred from the context.", "labels": [], "entities": []}, {"text": "This phenomenon is particularly prevalent in the types of dialogue contained in the conversation corpus, with the majority of sentences having their subject omitted.", "labels": [], "entities": []}, {"text": "Given that it is difficult for the translation systems used in the experiments to accurately reproduce these omitted subjects in a non-pro-drop target language such as English, it is likely that replacing these subjects in a preprocessing step would lead to gains inaccuracy ( Dropped words: There were many cases where words central to the sentence were missing from the translation output by the system.", "labels": [], "entities": []}, {"text": "This problem is rooted in a number of problems, such as words being mistakenly unaligned in the training data.", "labels": [], "entities": []}, {"text": "Word segmentation: Both Chinese and Japanese require the segmentation of raw text into words, but occasionally word segmentation errors occurred either due to conversational speech or specialized medical terms.", "labels": [], "entities": [{"text": "Word segmentation", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.7224303781986237}, {"text": "segmentation of raw text into words", "start_pos": 57, "end_pos": 92, "type": "TASK", "confidence": 0.8128446340560913}, {"text": "word segmentation", "start_pos": 111, "end_pos": 128, "type": "TASK", "confidence": 0.702910989522934}]}, {"text": "Thus, using domain adaptation techniques ) to fix the word segmentations in the medical domain could potentially improve down-stream accuracy of translation as well.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 133, "end_pos": 141, "type": "METRIC", "confidence": 0.9942210912704468}]}, {"text": "Medical domain terms: As expected, there were a few medical domain terms not covered by corpora from more general domains, such as \"Benadryl.\"", "labels": [], "entities": []}, {"text": "However, the number was also relatively small, with only 5 untranslatable words occurring in a 200 sentence corpus.", "labels": [], "entities": []}, {"text": "Overall, an interesting shared point between the majority of members of the list is that they are not: Examples of translations generated by each system for Japanese-English.", "labels": [], "entities": []}, {"text": "specific to medical translation, but more related to the style of the text.", "labels": [], "entities": [{"text": "medical translation", "start_pos": 12, "end_pos": 31, "type": "TASK", "confidence": 0.756667822599411}]}, {"text": "Thus while raising the level of medical MT will certainly involve covering medical terminology, it is also equally, if not more, important to overcome obstacles facing the more general speech translation task as well.", "labels": [], "entities": [{"text": "MT", "start_pos": 40, "end_pos": 42, "type": "TASK", "confidence": 0.7175356149673462}, {"text": "speech translation", "start_pos": 185, "end_pos": 203, "type": "TASK", "confidence": 0.7541387379169464}]}, {"text": "Finally, in, we show concrete examples for each of the three translation methods in Japanese-English translation.", "labels": [], "entities": [{"text": "Japanese-English translation", "start_pos": 84, "end_pos": 112, "type": "TASK", "confidence": 0.6480448096990585}]}, {"text": "The first example is from the phrasebook data, uses some medical terms, and has a very typical syntactic structure fora written Japanese sentence.", "labels": [], "entities": []}, {"text": "As a result F2S is able to translate almost perfectly, but PBMT and Hiero have reordering problems garbling the meaning of the sentence.", "labels": [], "entities": [{"text": "PBMT", "start_pos": 59, "end_pos": 63, "type": "DATASET", "confidence": 0.9091660380363464}, {"text": "Hiero", "start_pos": 68, "end_pos": 73, "type": "DATASET", "confidence": 0.8771848082542419}]}, {"text": "The second example literally means \"other eye, please,\" and PBMT is able to generate this very literal translation.", "labels": [], "entities": [{"text": "PBMT", "start_pos": 60, "end_pos": 64, "type": "DATASET", "confidence": 0.8601231575012207}]}, {"text": "Hiero, on the other hand, mistakenly makes the listener the subject of \"check,\" and F2S mistakenly translates \"please\" as \"I'd like,\" which doesn't make sense in this context.", "labels": [], "entities": [{"text": "Hiero", "start_pos": 0, "end_pos": 5, "type": "DATASET", "confidence": 0.9292190074920654}, {"text": "check", "start_pos": 72, "end_pos": 77, "type": "METRIC", "confidence": 0.9623323678970337}]}, {"text": "In the third example, all three systems have trouble translating the colloquial word for \"blink one's eyes,\" with PBMT and Hiero dropping the word altogether, and F2S leaving it untranslated.", "labels": [], "entities": [{"text": "PBMT", "start_pos": 114, "end_pos": 118, "type": "DATASET", "confidence": 0.9042693972587585}, {"text": "Hiero", "start_pos": 123, "end_pos": 128, "type": "DATASET", "confidence": 0.890059769153595}]}], "tableCaptions": [{"text": " Table 1: Size in sentences and words of each lan- guage for each split for the phrasebook and con- versation corpora.", "labels": [], "entities": []}]}