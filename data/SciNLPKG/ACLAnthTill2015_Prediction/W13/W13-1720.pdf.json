{"title": [{"text": "Simple Yet Powerful Native Language Identification on TOEFL11", "labels": [], "entities": [{"text": "Simple Yet Powerful Native Language Identification", "start_pos": 0, "end_pos": 50, "type": "TASK", "confidence": 0.5955634713172913}, {"text": "TOEFL11", "start_pos": 54, "end_pos": 61, "type": "DATASET", "confidence": 0.8401932716369629}]}], "abstractContent": [{"text": "Native language identification (NLI) is the task to determine the native language of the author based on an essay written in a second language.", "labels": [], "entities": [{"text": "Native language identification (NLI)", "start_pos": 0, "end_pos": 36, "type": "TASK", "confidence": 0.8301791846752167}]}, {"text": "NLI is often treated as a classification problem.", "labels": [], "entities": []}, {"text": "In this paper, we use the TOEFL11 data set which consists of more data, in terms of the amount of essays and languages, and less biased across prompts, i.e., topics, of essays.", "labels": [], "entities": [{"text": "TOEFL11 data set", "start_pos": 26, "end_pos": 42, "type": "DATASET", "confidence": 0.9068483312924703}]}, {"text": "We demonstrate that even using word level n-grams as features, and support vector machine (SVM) as a classifier can yield nearly 80% accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 133, "end_pos": 141, "type": "METRIC", "confidence": 0.9967064261436462}]}, {"text": "We observe that the accuracy of a binary-based word level n-gram representation (~80%) is much better than the performance of a frequency-based word level n-gram representation (~20%).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 20, "end_pos": 28, "type": "METRIC", "confidence": 0.9996147155761719}]}, {"text": "Notably, comparable results can be achieved without removing punctuation marks, suggesting a very simple baseline system for NLI.", "labels": [], "entities": []}], "introductionContent": [{"text": "Native language identification (NLI) is an emerging field in the natural language processing community and machine learning community ().", "labels": [], "entities": [{"text": "Native language identification (NLI)", "start_pos": 0, "end_pos": 36, "type": "TASK", "confidence": 0.8355388939380646}]}, {"text": "It is a task to identify the native language (L1) of an author based on his/her texts written in a second language.", "labels": [], "entities": [{"text": "identify the native language (L1)", "start_pos": 16, "end_pos": 49, "type": "TASK", "confidence": 0.6192999482154846}]}, {"text": "The application of NLI can bring many benefits, such as providing a learner adaptive feedback of their writing errors based on the native language for educational purposes (.", "labels": [], "entities": []}, {"text": "NLI can be viewed as a classification problem.", "labels": [], "entities": []}, {"text": "Ina classification problem, a classifier is first trained using a set of training examples.", "labels": [], "entities": []}, {"text": "Each training example is represented as a set of features, along with a class label.", "labels": [], "entities": []}, {"text": "After a classifier is trained, the classifier is evaluated using a testing set.", "labels": [], "entities": []}, {"text": "Good data representation often yields a better classification performance.", "labels": [], "entities": []}, {"text": "Often time, the simpler representations might produce better performance.", "labels": [], "entities": []}, {"text": "In this work, we demonstrate that a binary-based word level ngram representation yields much better performance than a frequency-based word level n-gram representation.", "labels": [], "entities": []}, {"text": "In addition, we observed that removing punctuation marks in an essay does not make too much difference in a classification performance.", "labels": [], "entities": []}, {"text": "The contributions of this paper are to demonstrate the usefulness of a binary-based word level n-gram representation, and a very simple baseline system without the need of removing punctuation marks and stop words.", "labels": [], "entities": []}, {"text": "This paper is organized as the following.", "labels": [], "entities": []}, {"text": "In Section 2, we present related literatures.", "labels": [], "entities": []}, {"text": "TOEFL11 data set is introduced in Section 3.", "labels": [], "entities": [{"text": "TOEFL11 data set", "start_pos": 0, "end_pos": 16, "type": "DATASET", "confidence": 0.985613226890564}]}, {"text": "In Section 4, our features and system design are described.", "labels": [], "entities": []}, {"text": "The results are presented in Section 5, followed by conclusion in Section 6.", "labels": [], "entities": [{"text": "conclusion", "start_pos": 52, "end_pos": 62, "type": "METRIC", "confidence": 0.9652871489524841}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 1 Accuracy of Different Feature Sets, without  Punctuation Marks", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 9, "end_pos": 17, "type": "METRIC", "confidence": 0.9940558671951294}, {"text": "Punctuation", "start_pos": 54, "end_pos": 65, "type": "METRIC", "confidence": 0.9435777068138123}]}, {"text": " Table 2 Accuracy of Different Feature Sets, with  Punctuation Marks", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 9, "end_pos": 17, "type": "METRIC", "confidence": 0.9947037100791931}]}]}