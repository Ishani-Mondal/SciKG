{"title": [{"text": "What metaphor identification systems can tell us about metaphor-in-language", "labels": [], "entities": [{"text": "metaphor identification", "start_pos": 5, "end_pos": 28, "type": "TASK", "confidence": 0.7595646679401398}]}], "abstractContent": [{"text": "This paper evaluates four metaphor identification systems on the 200,000 word VU Amsterdam Metaphor Corpus, comparing results by genre and by sub-class of metaphor.", "labels": [], "entities": [{"text": "metaphor identification", "start_pos": 26, "end_pos": 49, "type": "TASK", "confidence": 0.7353520691394806}, {"text": "VU Amsterdam Metaphor Corpus", "start_pos": 78, "end_pos": 106, "type": "DATASET", "confidence": 0.8933926969766617}]}, {"text": "The paper then compares the rate of agreement between the systems for each genre and sub-class.", "labels": [], "entities": [{"text": "agreement", "start_pos": 36, "end_pos": 45, "type": "METRIC", "confidence": 0.9347826838493347}]}, {"text": "Each of the identification systems is based, explicitly or implicitly, on a theory of metaphor which hypothesizes that certain properties are essential to metaphor-in-language.", "labels": [], "entities": []}, {"text": "The goal of this paper is to see what the successor failure of these systems can tell us about the essential properties of metaphor-in-language.", "labels": [], "entities": []}, {"text": "The success of the identification systems varies significantly across genres and sub-classes of metaphor.", "labels": [], "entities": []}, {"text": "At the same time, the different systems achieve similar success rates on each even though they show low agreement among themselves.", "labels": [], "entities": []}, {"text": "This is taken to be evidence that there are several sub-types of metaphor-in-language and that the ideal metaphor identification system will first define these sub-types and then model the linguistic properties which can distinguish these sub-types from one another and from non-metaphors.", "labels": [], "entities": []}], "introductionContent": [{"text": "The purpose of this paper is to evaluate four systems for identifying metaphor-in-language on the large and representative VU Amsterdam Metaphor Corpus) and then to analyze the correct and incorrect identifications in order to see what they can tell us about the linguistic properties of metaphor-in-language.", "labels": [], "entities": [{"text": "VU Amsterdam Metaphor Corpus", "start_pos": 123, "end_pos": 151, "type": "DATASET", "confidence": 0.9117767065763474}]}, {"text": "The four metaphor identification systems include a word-level semantic similarity measurement method, a word-level abstractness measurement method), a grammatical-relationlevel source-target mapping method, and an utterance-level domain interaction method).", "labels": [], "entities": []}], "datasetContent": [{"text": "The evaluation results discussed in this section consider only the sentences for which each system has the minimum representation; for example, the se-  mantic similarity system had a minimum representation for many fewer sentences than does the abstractness system, but those unrepresented sentences are not held against the system.", "labels": [], "entities": []}, {"text": "Three of the systems use feature vectors: the semantic similarity, word abstractness, and domain interaction systems.", "labels": [], "entities": []}, {"text": "To make the evaluation comparable all three systems are evaluated using Weka's () implementation of the logistic regression algorithm, following), using cross-validation (100 folds) and a ridge estimator value of 0.2.", "labels": [], "entities": []}, {"text": "The evaluation of the source-target system searched for the 903 seed relations in the RASP-parsed test corpus.", "labels": [], "entities": [{"text": "RASP-parsed test corpus", "start_pos": 86, "end_pos": 109, "type": "DATASET", "confidence": 0.901386539141337}]}, {"text": "The sentences used as seeds were removed from the test corpus before searching.", "labels": [], "entities": []}, {"text": "For each evaluation, the reported F-Measure is the weighted average of the F-Measures for metaphors and nonmetaphors.", "labels": [], "entities": [{"text": "F-Measure", "start_pos": 34, "end_pos": 43, "type": "METRIC", "confidence": 0.9789093732833862}]}, {"text": "shows the evaluation results for the four systems on the entire corpus.", "labels": [], "entities": []}, {"text": "The similarity system has the highest number of true positives (5,936), but also the highest number of false positives.", "labels": [], "entities": [{"text": "similarity", "start_pos": 4, "end_pos": 14, "type": "METRIC", "confidence": 0.9144860506057739}]}, {"text": "In fact, the similarity system identifies very few utterances as non-metaphors and this makes the results rather unhelpful.", "labels": [], "entities": []}, {"text": "The abstractness and domain interaction systems have similar F-measures (0.582 and 0.583, respectively); both make a large number of predictions for both metaphor and nonmetaphor, so that they attempt to distinguish between the two, but these predictions are not particularly accurate.", "labels": [], "entities": [{"text": "F-measures", "start_pos": 61, "end_pos": 71, "type": "METRIC", "confidence": 0.9961714148521423}]}, {"text": "The source-target system stands out here, as it does below, with a significantly smaller number of false positives than the other systems (785).", "labels": [], "entities": []}, {"text": "At the same time, it also has a significantly higher number of false negatives (5,496).", "labels": [], "entities": [{"text": "number of false negatives", "start_pos": 53, "end_pos": 78, "type": "METRIC", "confidence": 0.6946801543235779}]}, {"text": "The similarity and source-target systems are on opposite ends of the spectrum in terms of over-identifying and under-identifying metaphor-in-language, and both have similar F-measures (0.444 and 0.440, respectively) which are lower than the abstractness and domain interaction systems.", "labels": [], "entities": [{"text": "F-measures", "start_pos": 173, "end_pos": 183, "type": "METRIC", "confidence": 0.9981628060340881}]}, {"text": "In the same results across all genres and sub-types are presented for implementations without Named Entity Recognition.", "labels": [], "entities": []}, {"text": "The only system which performs significantly differently is the abstractness system, with an F-Measure of 0.482 without vs. 0.582 with NER.", "labels": [], "entities": [{"text": "F-Measure", "start_pos": 93, "end_pos": 102, "type": "METRIC", "confidence": 0.9907015562057495}, {"text": "NER", "start_pos": 135, "end_pos": 138, "type": "DATASET", "confidence": 0.8970310091972351}]}, {"text": "This decline goes hand-inhand with the fact that the system with NER has sufficient representation fora total of 14,454 sentences, while without NER it has sufficient representation for only 10,883 sentences.", "labels": [], "entities": [{"text": "NER", "start_pos": 65, "end_pos": 68, "type": "DATASET", "confidence": 0.9004167318344116}]}, {"text": "starts to break these results down further by genre, in order to find out if the systems perform differently on different sorts of texts.", "labels": [], "entities": []}, {"text": "Every system except for the similarity system (with F-measures of 0.444 and then 0.463) performs more poorly on fiction than on the corpus as a whole.", "labels": [], "entities": [{"text": "F-measures", "start_pos": 52, "end_pos": 62, "type": "METRIC", "confidence": 0.9936889410018921}]}, {"text": "More interestingly, within the fiction genre the similarity and abstractness systems do not predict that any utterances are non-metaphors, which makes their F-measures largely meaningless.", "labels": [], "entities": []}, {"text": "The source-target system continues to make a distinction between metaphor and  non-metaphor within this genre, although the true and false positives (293 and 243, respectively) are much closer to one another than when looking at the corpus as a whole.", "labels": [], "entities": []}, {"text": "looks at the systems' performance within the News genre.", "labels": [], "entities": []}, {"text": "The similarity system, which above made few predictions for non-metaphor continues to predict only metaphors; the abstractness and domain interaction systems join it, predicting only metaphors.", "labels": [], "entities": []}, {"text": "The source-target system, on the other hand, maintains a small number of false positives (61), although continuing to show a large number of false negatives.", "labels": [], "entities": []}, {"text": "In terms of practical applications, the F-measures here do not adequately reflect the fact that three of the four systems essentially fail on this genre.", "labels": [], "entities": []}, {"text": "One of the difficulties is the fact that the News genre contains 1,708 metaphoric sentences and 325 non-metaphoric sentences according to the manual annotations in the VU Amsterdam Metaphor Corpus; that means that 84% of the sentences are annotated as metaphoric.", "labels": [], "entities": [{"text": "VU Amsterdam Metaphor Corpus", "start_pos": 168, "end_pos": 196, "type": "DATASET", "confidence": 0.9101943671703339}]}, {"text": "looks at the results within the Academic genre.", "labels": [], "entities": []}, {"text": "Here all systems make a distinction between metaphor and non-metaphor; this is the first set on which the similarity system has predicted a meaningful number of non-metaphors.", "labels": [], "entities": []}, {"text": "The source-target system misses the most metaphors (1,321) but also makes significantly fewer false positives (146 vs. the next lowest 590 by the similarity system).", "labels": [], "entities": []}, {"text": "The Fmeasures do not adequately reflect the performance of the systems for this genre.", "labels": [], "entities": []}, {"text": "shows the results within the Conversation genre.", "labels": [], "entities": []}, {"text": "This is the reverse of the News genre: three of the four systems make no predictions of metaphors.", "labels": [], "entities": []}, {"text": "This genre contains 1,958 utterances with at least one metaphorically used word and 5,262 without.", "labels": [], "entities": []}, {"text": "Further, this genre contains many more short and/or fragmentary sentences than the others.", "labels": [], "entities": []}, {"text": "Even the source-target system, which is the only system to identify any metaphors, has more than twice as many false positives as true positives, which reverses its performance on the three previous genres.", "labels": [], "entities": []}, {"text": "The initial conclusions we can draw from the genre break-down is that (1) the F-measure does not always reflect meaningful performance and thus that the numbers of true and false positives and negatives should be reported as well; and (2) that the performance on the corpus as a whole disguises a large amount of variation according to genre.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 78, "end_pos": 87, "type": "METRIC", "confidence": 0.9919900298118591}]}, {"text": "shows the results for only the MRW-Met sub-class in the corpus.", "labels": [], "entities": [{"text": "MRW-Met sub-class", "start_pos": 31, "end_pos": 48, "type": "DATASET", "confidence": 0.929007351398468}]}, {"text": "This is the basic metaphor sub-class in the corpus and the most common.", "labels": [], "entities": []}, {"text": "The systems perform better on this sub-class than on any other.", "labels": [], "entities": []}, {"text": "Interestingly, the source-target system makes more false than true positives here (785 vs. 749) and is the only system to make more false than true positives for this sub-class.", "labels": [], "entities": []}, {"text": "It also makes more false negatives than the other systems, although the abstractness, source-target, and domain interaction systems make a comparable number (3,971 and 3,990 and 3,386, respectively).", "labels": [], "entities": []}, {"text": "The domain interaction system  makes the most true positives, although all the Fmeasures are comparable (the lowest is only 0.062 below the highest).", "labels": [], "entities": [{"text": "Fmeasures", "start_pos": 79, "end_pos": 88, "type": "METRIC", "confidence": 0.9293389320373535}]}, {"text": "shows the results for the ambiguous metaphors, under the label WIDLII, and the results are comparable to the results for all other sub-classes except for the MRW-Met sub-class (thus, the other sub-classes will not be discussed individually).", "labels": [], "entities": [{"text": "WIDLII", "start_pos": 63, "end_pos": 69, "type": "DATASET", "confidence": 0.7085075378417969}, {"text": "MRW-Met sub-class", "start_pos": 158, "end_pos": 175, "type": "DATASET", "confidence": 0.9326991438865662}]}, {"text": "The similarity, abstractness, and domain interaction systems do not detect any of these sentences as containing metaphorically used words.", "labels": [], "entities": []}, {"text": "In some ways this failure is acceptable because the original analysts were not convinced that these utterances contained metaphors in the first place.", "labels": [], "entities": []}, {"text": "The source-target system has a very uncharacteristic performance on this sub-class, with 5-times as many false positives as true positives.", "labels": [], "entities": []}, {"text": "This is interesting because it is exactly the opposite of the other systems, which do not predict any sentences to be metaphors at all.", "labels": [], "entities": []}, {"text": "This difference is likely a result of the fact that the other three systems rely on feature vectors that were trained on the WIDLII / Non-Metaphor distinction, while the source-target system uses seed grammatical relations from other sub-classes as well (it shouldn't matter because the relations are hypothesized to represent conceptual metaphors for which the sub-class distinction is not relevant; more seed metaphors were not used because this would have removed them from the evaluation).", "labels": [], "entities": []}, {"text": "In other words, the sub-class comparisons try to distinguish between WIDLII metaphors and non-metaphors in the corpus.", "labels": [], "entities": []}, {"text": "The source-target system was trained on one and only one set of seed metaphors; in other cases this fact increased the system's performance, but in this case it had the opposite effect.", "labels": [], "entities": []}, {"text": "It also shows that non-metaphors are more likely to contain the seed clusters than are ambiguous metaphors.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Number of sentences with sufficient representation in each system.", "labels": [], "entities": []}, {"text": " Table 2: Results for each system across all genres and sub-classes.", "labels": [], "entities": []}, {"text": " Table 3: Results for each system across all genres and sub-classes without Named Entity Recognition.", "labels": [], "entities": [{"text": "Named Entity Recognition", "start_pos": 76, "end_pos": 100, "type": "TASK", "confidence": 0.5757743120193481}]}, {"text": " Table 4: Results for each system in the Fiction genre.", "labels": [], "entities": []}, {"text": " Table 5: Results for each system in the News genre.", "labels": [], "entities": []}, {"text": " Table 6: Results for each system in the Academic genre.", "labels": [], "entities": []}, {"text": " Table 7: Results for each system in the Conversation genre.", "labels": [], "entities": []}, {"text": " Table 10: Agreement among the four metaphor identifi- cation systems using Fleiss' Kappa.", "labels": [], "entities": [{"text": "Fleiss' Kappa", "start_pos": 76, "end_pos": 89, "type": "DATASET", "confidence": 0.7307054400444031}]}, {"text": " Table 8: Results for each system in the MRW-Met Sub-Class.", "labels": [], "entities": [{"text": "MRW-Met Sub-Class", "start_pos": 41, "end_pos": 58, "type": "DATASET", "confidence": 0.9649516940116882}]}, {"text": " Table 9: Results for each system in the WIDLII Sub-Class.", "labels": [], "entities": [{"text": "WIDLII Sub-Class", "start_pos": 41, "end_pos": 57, "type": "DATASET", "confidence": 0.7774023115634918}]}, {"text": " Table 11: Results for meta-systems across all sentences with sufficient representation for all systems.", "labels": [], "entities": []}]}