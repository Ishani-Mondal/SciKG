{"title": [{"text": "Unsupervised Linguistically-Driven Reliable Dependency Parses Detection and Self-Training for Adaptation to the Biomedical Domain", "labels": [], "entities": [{"text": "Unsupervised Linguistically-Driven Reliable Dependency Parses Detection", "start_pos": 0, "end_pos": 71, "type": "TASK", "confidence": 0.5089019040266672}]}], "abstractContent": [{"text": "In this paper, anew self-training method for domain adaptation is illustrated, where the selection of reliable parses is carried out by an unsupervised linguistically-driven algorithm, ULISSE.", "labels": [], "entities": [{"text": "domain adaptation", "start_pos": 45, "end_pos": 62, "type": "TASK", "confidence": 0.8130936920642853}]}, {"text": "The method has been tested on biomedical texts with results showing a significant improvement with respect to considered baselines, which demonstrates its ability to capture both reliability of parses and domain-specificity of linguistic constructions.", "labels": [], "entities": [{"text": "reliability", "start_pos": 179, "end_pos": 190, "type": "METRIC", "confidence": 0.9907498955726624}]}], "introductionContent": [{"text": "As firstly demonstrated by, parsing systems have a drop of accuracy when tested against domain corpora outside of the data from which they were trained.", "labels": [], "entities": [{"text": "parsing", "start_pos": 28, "end_pos": 35, "type": "TASK", "confidence": 0.9784950613975525}, {"text": "accuracy", "start_pos": 59, "end_pos": 67, "type": "METRIC", "confidence": 0.9994198083877563}]}, {"text": "This is areal problem in the biomedical domain where, due to the rapidly expanding body of biomedical literature, the need for increasingly sophisticated and efficient biomedical text mining systems is becoming more and more pressing.", "labels": [], "entities": [{"text": "biomedical text mining", "start_pos": 168, "end_pos": 190, "type": "TASK", "confidence": 0.6657867232958475}]}, {"text": "In particular, the existence of natural language parsers reliably dealing with biomedical texts represents the prerequiste for identifying and extracting knowledge embedded in them.", "labels": [], "entities": []}, {"text": "Over the last years, this problem has been tackled within the biomedical NLP community from different perspectives.", "labels": [], "entities": []}, {"text": "The development of a domain-specific annotated corpus, i.e. the Genia Treebank, played a key role by providing a sound basis for empirical performance evaluation as well as training of parsers.", "labels": [], "entities": [{"text": "Genia Treebank", "start_pos": 64, "end_pos": 78, "type": "DATASET", "confidence": 0.7049286663532257}]}, {"text": "On the other hand, several attempts have been made to adapt general parsers to the biomedical domain.", "labels": [], "entities": []}, {"text": "First experiments in this direction are reported in) who first compared the performance of three different parsers against the Genia treebank and a sample of the Penn Treebank (PTB)) in order to carryout an inter-domain analysis of the typology of errors made by each parser and demonstrated that by integrating the output of the three parsers they achieved statistically significant performance gains.", "labels": [], "entities": [{"text": "Genia treebank", "start_pos": 127, "end_pos": 141, "type": "DATASET", "confidence": 0.9454025030136108}, {"text": "Penn Treebank (PTB))", "start_pos": 162, "end_pos": 182, "type": "DATASET", "confidence": 0.9756162405014038}]}, {"text": "Three different methods of parser adaptation for the biomedical domain have been proposed by) who, starting from the results of unknown word rate experiments carried out on the Genia treebank, adapted a PTB-trained parser by improving the Part-Of-Speech tagging accuracy and by relying on an external domain-specific lexicon.", "labels": [], "entities": [{"text": "parser adaptation", "start_pos": 27, "end_pos": 44, "type": "TASK", "confidence": 0.9557923674583435}, {"text": "Genia treebank", "start_pos": 177, "end_pos": 191, "type": "DATASET", "confidence": 0.9321185946464539}, {"text": "Part-Of-Speech tagging", "start_pos": 239, "end_pos": 261, "type": "TASK", "confidence": 0.6240656822919846}, {"text": "accuracy", "start_pos": 262, "end_pos": 270, "type": "METRIC", "confidence": 0.9002856016159058}]}, {"text": "More recently, and) devised adaptation methods based on domain similarity measures.", "labels": [], "entities": []}, {"text": "In particular, both of them adopted lexical similarity measures to automatically select from an annotated collection of texts those training data which is more relevant, i.e. lexically closer, to adapt the parser to the target domain.", "labels": [], "entities": []}, {"text": "A variety of semi-supervised approaches, where unlabeled data is used in addition to labeled training data, have been recently proposed in the literature in order to adapt parsing systems to new domains.", "labels": [], "entities": []}, {"text": "Among these approaches, the last few years have seen a growing interest in self-training for domain adaptation, i.e. a method for using automatically annotated data from a target domain when training supervised models.", "labels": [], "entities": [{"text": "domain adaptation", "start_pos": 93, "end_pos": 110, "type": "TASK", "confidence": 0.7410183548927307}]}, {"text": "Self-training methods proposed so far mainly differ at the level of the selection of parse trees to be added to the in-domain gold trees as further training data.", "labels": [], "entities": []}, {"text": "Depending on whether or not external supervised classifiers are used to select the parses to be added to the gold-training set, two types of methods are envisaged in the literature.", "labels": [], "entities": []}, {"text": "The first is the case, among others, of:, using a machine learning classifier to predict the reliability of parses on the basis of different feature types; or, selecting identical analyses for the same sentence within the output of different parsing models trained on the same dataset; or), using a discriminative reranker against the output of a n-best generative parser for selecting the best parse for each sentence to be used as further training data.", "labels": [], "entities": []}, {"text": "Yet, due to the fact that several supervised classifiers are resorted to for improving the base supervised parser, this class of methods cannot be seen as a genuine istance of self-training.", "labels": [], "entities": []}, {"text": "The second type of methods is exemplified, among others, by) who use the whole set of automatically analyzed sentences, and by and who add different amounts of automatically parsed data without any selection strategy.", "labels": [], "entities": []}, {"text": "Note that) tested their self-training approach on the Genia Treebank: they self-trained a PTB-trained costituency parser using a random selection of Medline abstracts.", "labels": [], "entities": [{"text": "Genia Treebank", "start_pos": 54, "end_pos": 68, "type": "DATASET", "confidence": 0.7174805849790573}]}, {"text": "In this paper, we address the second scenario with a main novelty: we use an unsupervised approach to select reliable parses from automatically parsed target domain texts to be combined with the gold-training set.", "labels": [], "entities": []}, {"text": "Two unsupervised algorithms have been proposed so far in the literature for selecting reliable parses, namely: PUPA (POSbased Unsupervised Parse Assessment Algorithm) and ULISSE (Unsupervised LInguiStically-driven Selection of dEpendency parses)).", "labels": [], "entities": []}, {"text": "Both algorithms assign a quality score to each parse tree based on statistics collected from a large automatically parsed corpus, with a main difference: whereas PUPA operates on costituency trees and uses statistics about sequences of part-of-speech tags, ULISSE uses statistics about linguistic features checked against dependency-based representations.", "labels": [], "entities": []}, {"text": "The selftraining strategy presented in this paper is based on an augmented version of ULISSE.", "labels": [], "entities": [{"text": "ULISSE", "start_pos": 86, "end_pos": 92, "type": "DATASET", "confidence": 0.9070898294448853}]}, {"text": "The reasons for this choice are twofold: if on the one hand ULISSE appears to outperform PUPA (namely, a dependency-based version of PUPA implemented in), on the other hand the linguistically-driven nature of ULISSE makes our self-training strategy for domain adaptation able to capture reliable parses which are also representative of the syntactic peculiarities of the target domain.", "labels": [], "entities": [{"text": "domain adaptation", "start_pos": 253, "end_pos": 270, "type": "TASK", "confidence": 0.734033539891243}]}, {"text": "After introducing the in-and out-domain corpora used in this study (Section 2), we discuss the results of the multi-level linguistic analysis of these corpora carried out (Section 3) with a view to identifying the main features differentiating the biomedical language from ordinary language.", "labels": [], "entities": []}, {"text": "In Section 4, the algorithm used to select reliable parses from automatically parsed domain-specific texts is described.", "labels": [], "entities": []}, {"text": "In Section 5 the proposed selftraining method is illustrated, followed by a discussion of achieved results (Section 6).", "labels": [], "entities": []}], "datasetContent": [{"text": "In the reported experiments, we used the DeSR parser.", "labels": [], "entities": [{"text": "DeSR", "start_pos": 41, "end_pos": 45, "type": "DATASET", "confidence": 0.8311567306518555}]}, {"text": "Its performance using the proposed domain adaptation strategy was tested against i) the two out-domain datasets distributed for the \"Domain Adaptation Track\" of the CoNLL 2007 Shared Task and ii) the dependency-based version of the Genia Treebank, described in Section 2.", "labels": [], "entities": [{"text": "domain adaptation", "start_pos": 35, "end_pos": 52, "type": "TASK", "confidence": 0.7219815701246262}, {"text": "CoNLL 2007 Shared Task", "start_pos": 165, "end_pos": 187, "type": "DATASET", "confidence": 0.8946405798196793}, {"text": "Genia Treebank", "start_pos": 232, "end_pos": 246, "type": "DATASET", "confidence": 0.7842103540897369}]}, {"text": "For testing purposes, we selected from the dependencybased version of the Genia Treebank sentences with a maximum length of 39 tokens (for a total of 375,912 tokens and 15,623 sentences).", "labels": [], "entities": [{"text": "Genia Treebank sentences", "start_pos": 74, "end_pos": 98, "type": "DATASET", "confidence": 0.917095939318339}]}, {"text": "Results achieved with respect to the CHEM and BIO test sets were evaluated in terms of \"Labelled Attachment Score\" (LAS), whereas for Genia the only possible evaluation was in terms of \"Unlabelled Attachment Score\" (UAS).", "labels": [], "entities": [{"text": "CHEM and BIO test sets", "start_pos": 37, "end_pos": 59, "type": "DATASET", "confidence": 0.7633098661899567}, {"text": "Labelled Attachment Score\" (LAS)", "start_pos": 88, "end_pos": 120, "type": "METRIC", "confidence": 0.8558414322989327}, {"text": "Unlabelled Attachment Score\" (UAS)", "start_pos": 186, "end_pos": 220, "type": "METRIC", "confidence": 0.816826343536377}]}, {"text": "This follows from the fact that, as reported by Illes, this version of Genia is annotated with a Penn Treebankstyle phrase-structure, where a number of functional tags are missing: this influences the type See) fora detailed description of the quality score computation.  of evaluation which can be carried out against the Genia test set.", "labels": [], "entities": [{"text": "Penn Treebankstyle phrase-structure", "start_pos": 97, "end_pos": 132, "type": "DATASET", "confidence": 0.9800697962443033}, {"text": "Genia test set", "start_pos": 323, "end_pos": 337, "type": "DATASET", "confidence": 0.8089550733566284}]}, {"text": "Achieved results were compared with two baselines, represented by: i) the Baseline model (BASE), i.e. the parsing model trained on the PTB training set only; ii) the Random Selection (RS) of parses from automatically parsed out-domain corpora, calculated as the mean of a 10-fold crossvalidation process.", "labels": [], "entities": [{"text": "BASE", "start_pos": 90, "end_pos": 94, "type": "METRIC", "confidence": 0.8817285895347595}, {"text": "PTB training set", "start_pos": 135, "end_pos": 151, "type": "DATASET", "confidence": 0.9136252005894979}, {"text": "Random Selection (RS)", "start_pos": 166, "end_pos": 187, "type": "METRIC", "confidence": 0.9364481329917907}]}, {"text": "As proved by and by for the biomedical domain, the latter represents a strong unsupervised baseline showing a significant accuracy improvement which was obtained by adding incremental amounts of automatically parsed outdomain data to the training dataset without any selection strategy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 122, "end_pos": 130, "type": "METRIC", "confidence": 0.9989930987358093}]}, {"text": "The experiments we carried out to test the effectiveness of our self-training strategy were organised as follows.", "labels": [], "entities": []}, {"text": "ULISSE and the baseline algorithms were used to produce different rankings of parses of the unlabelled target domain corpora.", "labels": [], "entities": [{"text": "ULISSE", "start_pos": 0, "end_pos": 6, "type": "DATASET", "confidence": 0.9404759407043457}]}, {"text": "From the top of these rankings different pools of parses were selected to be used for training.", "labels": [], "entities": []}, {"text": "In particular, two different sets of experiments were carried out, namely: i) using only automatically parsed data as training corpus and ii) combining automatically parsed data with the PTB training set.", "labels": [], "entities": [{"text": "PTB training set", "start_pos": 187, "end_pos": 203, "type": "DATASET", "confidence": 0.941920816898346}]}, {"text": "For each set of experiments, different amounts of unlabelled data were used to create the selftraining models.", "labels": [], "entities": []}, {"text": "reports the results of the BASE model tested on PTB, CHEM, BIO and GENIA.", "labels": [], "entities": [{"text": "BASE", "start_pos": 27, "end_pos": 31, "type": "METRIC", "confidence": 0.9930626749992371}, {"text": "PTB", "start_pos": 48, "end_pos": 51, "type": "DATASET", "confidence": 0.9381710886955261}, {"text": "CHEM", "start_pos": 53, "end_pos": 57, "type": "DATASET", "confidence": 0.7810143232345581}, {"text": "BIO", "start_pos": 59, "end_pos": 62, "type": "METRIC", "confidence": 0.9391145706176758}, {"text": "GENIA", "start_pos": 67, "end_pos": 72, "type": "DATASET", "confidence": 0.9712256193161011}]}, {"text": "When applied without adaptation to the out-domain CHEM, BIO and GENIA test sets, the BASE parsing model has a drop of about 7.5% of LAS in both CHEM and BIO cases.", "labels": [], "entities": [{"text": "BIO", "start_pos": 56, "end_pos": 59, "type": "METRIC", "confidence": 0.9031307697296143}, {"text": "GENIA test sets", "start_pos": 64, "end_pos": 79, "type": "DATASET", "confidence": 0.9285600384076437}, {"text": "BASE", "start_pos": 85, "end_pos": 89, "type": "METRIC", "confidence": 0.9742490649223328}, {"text": "LAS", "start_pos": 132, "end_pos": 135, "type": "METRIC", "confidence": 0.9952515363693237}]}, {"text": "For what concerns UAS, the drop is about 6% for CHEM and about 7% for BIO and GENIA.", "labels": [], "entities": [{"text": "UAS", "start_pos": 18, "end_pos": 21, "type": "DATASET", "confidence": 0.7183964848518372}, {"text": "CHEM", "start_pos": 48, "end_pos": 52, "type": "DATASET", "confidence": 0.480627179145813}, {"text": "BIO", "start_pos": 70, "end_pos": 73, "type": "METRIC", "confidence": 0.5250257849693298}, {"text": "GENIA", "start_pos": 78, "end_pos": 83, "type": "DATASET", "confidence": 0.9231665730476379}]}], "tableCaptions": [{"text": " Table 1: Frequency distribution of the first ten Parts-of-Speech dependency triplets in biomedical and  newspaper corpora.", "labels": [], "entities": []}, {"text": " Table 3: The BASE model tested on PTB, CHEM,  BIO and GENIA.", "labels": [], "entities": [{"text": "BASE", "start_pos": 14, "end_pos": 18, "type": "METRIC", "confidence": 0.9974043965339661}, {"text": "PTB", "start_pos": 35, "end_pos": 38, "type": "DATASET", "confidence": 0.886677622795105}, {"text": "CHEM", "start_pos": 40, "end_pos": 44, "type": "DATASET", "confidence": 0.6424723863601685}, {"text": "BIO", "start_pos": 47, "end_pos": 50, "type": "METRIC", "confidence": 0.9644376039505005}, {"text": "GENIA", "start_pos": 55, "end_pos": 60, "type": "DATASET", "confidence": 0.9593846201896667}]}, {"text": " Table 4: % improvement of ULISSE-Stp+PTB vs  BASE reported in terms of LAS for CHEM and  BIO and of UAS for GENIA.", "labels": [], "entities": [{"text": "ULISSE-Stp+PTB", "start_pos": 27, "end_pos": 41, "type": "METRIC", "confidence": 0.3970345954100291}, {"text": "BASE", "start_pos": 46, "end_pos": 50, "type": "METRIC", "confidence": 0.9968632459640503}, {"text": "LAS", "start_pos": 72, "end_pos": 75, "type": "METRIC", "confidence": 0.9978289008140564}, {"text": "BIO", "start_pos": 90, "end_pos": 93, "type": "METRIC", "confidence": 0.8678958415985107}, {"text": "UAS", "start_pos": 101, "end_pos": 104, "type": "METRIC", "confidence": 0.828731119632721}, {"text": "GENIA", "start_pos": 109, "end_pos": 114, "type": "DATASET", "confidence": 0.8853750228881836}]}, {"text": " Table 5: ULISSE-Stp+PTB on PTB test set with  automatically parsed data.", "labels": [], "entities": [{"text": "ULISSE-Stp+PTB", "start_pos": 10, "end_pos": 24, "type": "METRIC", "confidence": 0.37662582596143085}, {"text": "PTB test set", "start_pos": 28, "end_pos": 40, "type": "DATASET", "confidence": 0.9566563367843628}]}]}