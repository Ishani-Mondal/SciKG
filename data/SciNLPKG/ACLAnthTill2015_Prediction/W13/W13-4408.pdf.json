{"title": [{"text": "Chinese Spelling Checker Based on Statistical Machine Translation", "labels": [], "entities": [{"text": "Chinese Spelling Checker", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.688109556833903}, {"text": "Statistical Machine Translation", "start_pos": 34, "end_pos": 65, "type": "TASK", "confidence": 0.6189329425493876}]}], "abstractContent": [{"text": "Chinese spelling check is an important component for many NLP applications, including word processor and search engines.", "labels": [], "entities": [{"text": "Chinese spelling check", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.5682671666145325}]}, {"text": "However, compared to checkers for alphabetical languages (e.g., English or French), Chinese spelling checkers are more difficult to develop, because there are no word boundaries in Chi-nese writing system, and errors maybe caused by various Chinese input methods.", "labels": [], "entities": [{"text": "Chinese spelling checkers", "start_pos": 84, "end_pos": 109, "type": "TASK", "confidence": 0.6067201097806295}]}, {"text": "In this paper , we proposed a novel method to Chinese spelling checking.", "labels": [], "entities": [{"text": "Chinese spelling checking", "start_pos": 46, "end_pos": 71, "type": "TASK", "confidence": 0.7695374687512716}]}, {"text": "Our approach involves error detection and correction based on the phrasal statistical machine translation framework.", "labels": [], "entities": [{"text": "error detection and correction", "start_pos": 22, "end_pos": 52, "type": "TASK", "confidence": 0.7123155519366264}, {"text": "phrasal statistical machine translation", "start_pos": 66, "end_pos": 105, "type": "TASK", "confidence": 0.6402165591716766}]}, {"text": "The results show that the proposed system achieves significantly better accuracy in error detecting and more satisfactory performance in error correcting.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 72, "end_pos": 80, "type": "METRIC", "confidence": 0.99910968542099}, {"text": "error detecting", "start_pos": 84, "end_pos": 99, "type": "TASK", "confidence": 0.6336350291967392}, {"text": "error correcting", "start_pos": 137, "end_pos": 153, "type": "TASK", "confidence": 0.6788872480392456}]}], "introductionContent": [{"text": "Chinese spelling check is a task involving automatically detecting and correcting typos, roughly corresponding to misspelled words in English.", "labels": [], "entities": [{"text": "Chinese spelling check", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.6304475466410319}]}, {"text": "show that people tend to unintentionally generate typos that sound similar (e.g., \"*\u63aa\u6298 cuo zhe\" and \"\u632b\u6298 cuo zhe\"), or look similar (e.g., \"*\u56fa\u96e3 gu nan\" and \"\u56f0\u96e3 kun nan\").", "labels": [], "entities": []}, {"text": "On the other hand, some typos found on the Web (such as forums or blogs) are used deliberately for the purpose of speed typing or just for fun.", "labels": [], "entities": []}, {"text": "Therefore, spelling check is an important component for many applications such as computer-aided writing and corpus cleanup.", "labels": [], "entities": [{"text": "spelling check", "start_pos": 11, "end_pos": 25, "type": "TASK", "confidence": 0.9203307628631592}, {"text": "corpus cleanup", "start_pos": 109, "end_pos": 123, "type": "TASK", "confidence": 0.7454523146152496}]}, {"text": "The methods of spelling check can be broadly classified into two types: rule-based methods) and statistical methods.", "labels": [], "entities": [{"text": "spelling check", "start_pos": 15, "end_pos": 29, "type": "TASK", "confidence": 0.9658157527446747}]}, {"text": "Rule-based methods use knowledge resources such as a dictionary to identify a word as a typo if the word is not in the dictionary, and provide similar words in the dictionary as suggestions.", "labels": [], "entities": []}, {"text": "However, simple rule-based methods have their limitations.", "labels": [], "entities": []}, {"text": "Consider the sentence \"\u5fc3 \u662f\u5f88\u91cd\u8981\u7684\u3002", "labels": [], "entities": []}, {"text": "xin shi hen zhong yao de\" which is correct.", "labels": [], "entities": []}, {"text": "However, the two single-character words \"\u5fc3 xin\" and \"\u662f shi\" are likely to be regarded as an error by a rule-based model for the longer word \"\u5fc3\u4e8b xin shi\" with identical pronunciation.", "labels": [], "entities": []}, {"text": "Data driven, statistical spelling check approaches appear to be more robust and performs better.", "labels": [], "entities": [{"text": "statistical spelling check", "start_pos": 13, "end_pos": 39, "type": "TASK", "confidence": 0.652280588944753}]}, {"text": "Statistical methods tend to use a large monolingual corpus to create a language model to validate the correction hypotheses.", "labels": [], "entities": []}, {"text": "Considering \"\u5fc3\u662f xin shi\", the two characters \"\u5fc3 xin\" and \"\u662f shi\" area bigram which has high frequency in a monolingual corpus, so we may determine that \"\u5fc3\u662f xin shi\" is not a typo after all.", "labels": [], "entities": []}, {"text": "In this paper, we propose a model, which combines rule-based with statistical approaches to detect errors and generate the most appropriate corrections in Chinese text.", "labels": [], "entities": []}, {"text": "Once, an error is identified by the rule-based detection model, we use statistic machine translation (SMT) model to provide the most appropriate correction.", "labels": [], "entities": [{"text": "statistic machine translation (SMT)", "start_pos": 71, "end_pos": 106, "type": "TASK", "confidence": 0.725868746638298}]}, {"text": "Rule-based models tend to ignore context, so that we use SMT to deal with this problem.", "labels": [], "entities": [{"text": "SMT", "start_pos": 57, "end_pos": 60, "type": "TASK", "confidence": 0.9876713752746582}]}, {"text": "Our model treats spelling correction as a kind of translation, where typos are translated into correctly spelled words according to the translation probability and language model probability.", "labels": [], "entities": [{"text": "spelling correction", "start_pos": 17, "end_pos": 36, "type": "TASK", "confidence": 0.9390898942947388}]}, {"text": "Consider the same case \"\u5fc3\u662f\u5f88\u91cd\u8981\u7684\u3002", "labels": [], "entities": []}, {"text": "xin shi hen zhong yao de\".", "labels": [], "entities": []}, {"text": "The string \"\u5fc3\u662f xin shi\" will not be incorrectly replaced with \"\u5fc3\u4e8b xin shi\" because we would consider \"\u5fc3\u662f xin shi\" is highly probable according to the language model.", "labels": [], "entities": []}, {"text": "The rest of the paper is organized as follows.", "labels": [], "entities": []}, {"text": "We present the related work in the next section.", "labels": [], "entities": []}, {"text": "Then we describe the proposed model for automatically detecting the spelling errors and correcting the found errors in Section 3.", "labels": [], "entities": []}, {"text": "Section 4 and Section 5 present the experimental data and evaluation results.", "labels": [], "entities": []}, {"text": "And we conclude in Section 6.", "labels": [], "entities": []}], "datasetContent": [{"text": "To train our model, we used several corpora including Sinica Chinese Balanced Corpus, TWWaC (Taiwan Web as Corpus), a Chinese dictionary, and a confusion set.", "labels": [], "entities": [{"text": "TWWaC (Taiwan Web as Corpus)", "start_pos": 86, "end_pos": 114, "type": "DATASET", "confidence": 0.8094860485621861}]}, {"text": "We describe the data sets in more detail below.", "labels": [], "entities": []}, {"text": "In Bake-off 2013, the evaluation includes two sub-tasks: error detection and error correction.", "labels": [], "entities": [{"text": "Bake-off 2013", "start_pos": 3, "end_pos": 16, "type": "DATASET", "confidence": 0.8962225615978241}, {"text": "error detection", "start_pos": 57, "end_pos": 72, "type": "TASK", "confidence": 0.7734568417072296}, {"text": "error correction", "start_pos": 77, "end_pos": 93, "type": "TASK", "confidence": 0.7875751554965973}]}, {"text": "For the error detection, sub-task1, there are 1000 sentences with/without spelling errors.", "labels": [], "entities": [{"text": "error detection", "start_pos": 8, "end_pos": 23, "type": "TASK", "confidence": 0.7349726855754852}]}, {"text": "And subtask2 for the error correction, there are also containing 1000 sentences but all with errors.", "labels": [], "entities": [{"text": "error correction", "start_pos": 21, "end_pos": 37, "type": "TASK", "confidence": 0.7886000275611877}]}, {"text": "The evaluation metrics, which computes false-alarm rate, accuracy, precision, recall, and F-Score is provided by SIGHAN 7 Bake-off 2013: Chinese Spelling Check Shared Task.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 57, "end_pos": 65, "type": "METRIC", "confidence": 0.9981531500816345}, {"text": "precision", "start_pos": 67, "end_pos": 76, "type": "METRIC", "confidence": 0.9993906021118164}, {"text": "recall", "start_pos": 78, "end_pos": 84, "type": "METRIC", "confidence": 0.9994115829467773}, {"text": "F-Score", "start_pos": 90, "end_pos": 97, "type": "METRIC", "confidence": 0.9994008541107178}, {"text": "SIGHAN 7 Bake-off 2013", "start_pos": 113, "end_pos": 135, "type": "DATASET", "confidence": 0.8911114633083344}, {"text": "Chinese Spelling Check Shared Task", "start_pos": 137, "end_pos": 171, "type": "TASK", "confidence": 0.4950246810913086}]}, {"text": "In this paper, we describe Run3 system and results.", "labels": [], "entities": []}, {"text": "On sub-task1, evaluation results as follows:.", "labels": [], "entities": []}, {"text": "We obtain higher detection accuracy, error location accuracy, and error location F-Score, which put our system in first place among 13 systems evaluated.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 27, "end_pos": 35, "type": "METRIC", "confidence": 0.8729405999183655}, {"text": "accuracy", "start_pos": 52, "end_pos": 60, "type": "METRIC", "confidence": 0.5373700857162476}, {"text": "error location F-Score", "start_pos": 66, "end_pos": 88, "type": "METRIC", "confidence": 0.8426209092140198}]}, {"text": "On sub-task2, our system obtained location accuracy, correction accuracy, and correction precision of 0.454, 0.443, and 0.6998, respectively.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 43, "end_pos": 51, "type": "METRIC", "confidence": 0.9372064471244812}, {"text": "correction", "start_pos": 53, "end_pos": 63, "type": "METRIC", "confidence": 0.9879031777381897}, {"text": "accuracy", "start_pos": 64, "end_pos": 72, "type": "METRIC", "confidence": 0.8561152219772339}, {"text": "correction", "start_pos": 78, "end_pos": 88, "type": "METRIC", "confidence": 0.9967653751373291}, {"text": "precision", "start_pos": 89, "end_pos": 98, "type": "METRIC", "confidence": 0.5981981158256531}]}], "tableCaptions": [{"text": " Table 2. Translations for \"\u6c23\u4efd qi fen\".", "labels": [], "entities": [{"text": "Translations", "start_pos": 10, "end_pos": 22, "type": "TASK", "confidence": 0.9412721395492554}]}, {"text": " Table 3. Evaluation metrics of Sub-task1.", "labels": [], "entities": []}]}