{"title": [{"text": "Combining Different Features of Idiomaticity for the Automatic Classification of Noun+Verb Expressions in Basque", "labels": [], "entities": [{"text": "Automatic Classification of Noun+Verb Expressions", "start_pos": 53, "end_pos": 102, "type": "TASK", "confidence": 0.7042645982333592}]}], "abstractContent": [{"text": "We present an experimental study of how different features help measuring the idiomatic-ity of noun+verb (NV) expressions in Basque.", "labels": [], "entities": []}, {"text": "After testing several techniques for quantifying the four basic properties of multiword expressions or MWEs (institutionalization, semantic non-compositionality, morphosyntac-tic fixedness and lexical fixedness), we test different combinations of them for classification into idioms and collocations, using Machine Learning (ML) and feature selection.", "labels": [], "entities": []}, {"text": "The results show the major role of distribu-tional similarity, which measures composi-tionality, in the extraction and classification of MWEs, especially, as expected, in the case of idioms.", "labels": [], "entities": [{"text": "extraction and classification of MWEs", "start_pos": 104, "end_pos": 141, "type": "TASK", "confidence": 0.7265218734741211}]}, {"text": "Even though cooccurrence and some aspects of morphosyntactic flexibility contribute to this task in a more limited measure , ML experiments make benefit of these sources of knowledge, allowing to improve the results obtained using exclusively distribu-tional similarity features.", "labels": [], "entities": [{"text": "ML", "start_pos": 125, "end_pos": 127, "type": "TASK", "confidence": 0.9604778289794922}]}], "introductionContent": [{"text": "Idiomaticity is considered the defining feature of the concept of multiword expressions (MWE).", "labels": [], "entities": [{"text": "multiword expressions (MWE)", "start_pos": 66, "end_pos": 93, "type": "TASK", "confidence": 0.6895319938659668}]}, {"text": "It is described as a non-discrete magnitude, whose \"value\" depends on a combination of features like institutionalization, non-compositionality and lexicosyntactic fixedness).", "labels": [], "entities": []}, {"text": "Idiomaticity appears as a continuum rather than as a series of discrete values.", "labels": [], "entities": []}, {"text": "Thus, the classification of MWEs into discrete categories is a difficult task.", "labels": [], "entities": [{"text": "classification of MWEs", "start_pos": 10, "end_pos": 32, "type": "TASK", "confidence": 0.8859766920407613}]}, {"text": "Avery schematic classification that has achieved a fair degree of general acceptance among experts distinguishes two main types of MWEs at phrase-level: idioms and collocations.", "labels": [], "entities": []}, {"text": "This complexity of the concept of idiomaticity has posed a challenge to the development of methods addressing the measurement of the aforementioned four properties.", "labels": [], "entities": []}, {"text": "Recent research has resulted in this issue nowadays being usually addressed through measuring the following phenomena: (i) cooccurrence, for institutionalization; (ii) distributional similarity, for non-compositionality; (iii) deviation from the behavior of free combinations, for morphosyntactic fixedness; and (iv) substitutability, for lexical fixedness.", "labels": [], "entities": []}, {"text": "This is the broad context of our experimental work on the automatic classification of NV expressions in Basque.", "labels": [], "entities": [{"text": "automatic classification of NV expressions in Basque", "start_pos": 58, "end_pos": 110, "type": "TASK", "confidence": 0.7405281237193516}]}], "datasetContent": [{"text": "As an evaluation reference, we use a subset of 1,200 combinations selected randomly from a extracted set of 4,334 bigrams, that is the result of merging the 2,000-best candidates of each AM ranking from thew = \u00b11 and f > 30 extraction set.", "labels": [], "entities": []}, {"text": "The subset has been manually classified by three lexicographers into idioms, collocations and free combinations.", "labels": [], "entities": []}, {"text": "Annotators were provided with an evaluation manual, containing the guidelines for classification and illustrative examples.", "labels": [], "entities": []}, {"text": "The agreement among evaluators was calculated using Fleiss' \u03ba.", "labels": [], "entities": []}, {"text": "We obtained a value of 0.58, which can be considered moderate, close to fair, agreement.", "labels": [], "entities": [{"text": "agreement", "start_pos": 78, "end_pos": 87, "type": "METRIC", "confidence": 0.9330418705940247}]}, {"text": "Although this level of agreement is relatively low when compared to, it is comparable to the one reported by, who attributed his \"relatively low\" value to the fact that \"the notion of collocation is very subjective, domain-specific, and also somewhat vague.\" obtain quite low inter-annotator agreement for annotation of idioms in the ANC (American National Corpus).", "labels": [], "entities": [{"text": "agreement", "start_pos": 23, "end_pos": 32, "type": "METRIC", "confidence": 0.988831639289856}, {"text": "American National Corpus)", "start_pos": 339, "end_pos": 364, "type": "DATASET", "confidence": 0.875524178147316}]}, {"text": "Hence, we consider that the level of agreement we have achieved is acceptable.", "labels": [], "entities": []}, {"text": "For the final classification of the evaluation set, cases where agreement was two or higher were automatically adopted, and the remaining cases were classified after discussion.", "labels": [], "entities": []}, {"text": "We removed 55 combinations that did not belong to the NV category, or that were part of larger MWEs.", "labels": [], "entities": []}, {"text": "The final set included 1,145 items, out of which 80 were idioms 268 collocations, and 797 free combinations.", "labels": [], "entities": []}, {"text": "The results for Kendall's \u03c4 B and AP for MWEs and separate AP values for idioms and collocations are summarized in (only the experiments with the most noteworthy results are included).", "labels": [], "entities": [{"text": "AP", "start_pos": 34, "end_pos": 36, "type": "METRIC", "confidence": 0.9849980473518372}, {"text": "AP", "start_pos": 59, "end_pos": 61, "type": "METRIC", "confidence": 0.9677735567092896}]}, {"text": "The best results are obtained in the Lemur experiments, most notably in the Lemur 2 type, using either Indri or KL-div indexes.", "labels": [], "entities": [{"text": "Indri", "start_pos": 103, "end_pos": 108, "type": "METRIC", "confidence": 0.9806016683578491}]}, {"text": "In the MWE rankings, measures of the R-value type only slightly outperform AMs.", "labels": [], "entities": [{"text": "MWE", "start_pos": 7, "end_pos": 10, "type": "TASK", "confidence": 0.7986648082733154}, {"text": "R-value", "start_pos": 37, "end_pos": 44, "type": "METRIC", "confidence": 0.9564264416694641}]}, {"text": "In the case of idioms, DS measures obtain significantly better ranks than the other measures.", "labels": [], "entities": []}, {"text": "Idioms being the least compositional expressions, his result is expected, and supports the hypothesis that semantic compositionality can better be characterized using measures of DS than using AMs.", "labels": [], "entities": [{"text": "semantic compositionality", "start_pos": 107, "end_pos": 132, "type": "TASK", "confidence": 0.6930712461471558}]}, {"text": "Regarding collocations, no such claim can be made, as the AP values for t-score and f outperform DS values, with a remarkable exception: the best AP is obtained by an Indri index that compares the semantic similarity between the verb in combination with the noun and the verb in contexts without the noun (L2 Indri rankV weight), accordingly with the claim that the semantics of the verb contribute to the semicompositionality of collocations.", "labels": [], "entities": [{"text": "AP", "start_pos": 58, "end_pos": 60, "type": "METRIC", "confidence": 0.9797113537788391}, {"text": "DS", "start_pos": 97, "end_pos": 99, "type": "METRIC", "confidence": 0.9708760380744934}, {"text": "AP", "start_pos": 146, "end_pos": 148, "type": "METRIC", "confidence": 0.9691147804260254}, {"text": "Indri index", "start_pos": 167, "end_pos": 178, "type": "METRIC", "confidence": 0.9162789881229401}]}, {"text": "By contrast, the corresponding measure for the noun (L2 Indri rankN weight) works quite a bit better with idioms than the previous verb measure.", "labels": [], "entities": [{"text": "Indri rankN weight)", "start_pos": 56, "end_pos": 75, "type": "METRIC", "confidence": 0.9316651970148087}]}, {"text": "shows the precision curves for the extraction of MWEs by the best measure of each component of idiomaticity.", "labels": [], "entities": [{"text": "precision", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9934965372085571}, {"text": "extraction of MWEs", "start_pos": 35, "end_pos": 53, "type": "TASK", "confidence": 0.6850703656673431}]}, {"text": "In and 3, we present separately the preci-  Regarding the precision for collocations in, the differences are not obviously significant.", "labels": [], "entities": [{"text": "precision", "start_pos": 58, "end_pos": 67, "type": "METRIC", "confidence": 0.9993416666984558}]}, {"text": "Even though the DS measure has the better performance, precision values for the t-score are not too much lower, and the t-score has a similar performance at the beginning of the ranking (n < 150).", "labels": [], "entities": [{"text": "precision", "start_pos": 55, "end_pos": 64, "type": "METRIC", "confidence": 0.9996364116668701}]}, {"text": "We report only the results of the three methods with the best overall performance: Logistic Regression (LR), SMO and RandomForest (RF).", "labels": [], "entities": []}, {"text": "In, we present the results obtained with datasets containing only DS attributes (the source of knowledge with the best results in single ex- periments); datasets containing all features corresponding to the four properties of idiomaticity; and datasets obtained adding the verb of the bigram as a string-type attribute.", "labels": [], "entities": []}, {"text": "As the figures show, it is difficult to improve the results obtained using only DS.", "labels": [], "entities": [{"text": "DS", "start_pos": 80, "end_pos": 82, "type": "METRIC", "confidence": 0.8778640627861023}]}, {"text": "The results of SMO are better when the features of the four components of idiomaticity are used, and even better when the verb is added, especially for idioms.", "labels": [], "entities": [{"text": "SMO", "start_pos": 15, "end_pos": 18, "type": "TASK", "confidence": 0.9849932193756104}]}, {"text": "The verb causes the performance of RF be slightly worse; in the case of LR, it generates considerable noise.", "labels": [], "entities": []}, {"text": "It can be observed that the figures for LR are more unstable.", "labels": [], "entities": [{"text": "LR", "start_pos": 40, "end_pos": 42, "type": "METRIC", "confidence": 0.6655226945877075}]}, {"text": "Using SMO and RF, convergence does not depend on how many noisy variables are present.", "labels": [], "entities": [{"text": "SMO", "start_pos": 6, "end_pos": 9, "type": "TASK", "confidence": 0.7347150444984436}, {"text": "convergence", "start_pos": 18, "end_pos": 29, "type": "METRIC", "confidence": 0.8601112961769104}]}, {"text": "Thus, feature selection could improve the results when LR is used.", "labels": [], "entities": []}, {"text": "Ina complementary experiment, we observed the impact of removing the attributes of each source of knowledge (without including verbs).", "labels": [], "entities": []}, {"text": "The most evident result was that the exclusion of LFlex features contributes the most to improving F.", "labels": [], "entities": [{"text": "F", "start_pos": 99, "end_pos": 100, "type": "METRIC", "confidence": 0.9757987260818481}]}, {"text": "This was an expected effect, considering the poor results for LFlex measures described in section 4.1.", "labels": [], "entities": []}, {"text": "More interesting is the fact that removing MSFlex features had a higher negative impact on F than not taking AMs as features.", "labels": [], "entities": [{"text": "F", "start_pos": 91, "end_pos": 92, "type": "METRIC", "confidence": 0.6895297169685364}]}, {"text": "shows the results for two datasets generated through two manual selection of attributes: (1) manual 1: the 20 attributes with best AP average results; and (2) manual 2: a manual selection of the attributes from each knowledge source with the best AP MWE, best AP id and best AP col.", "labels": [], "entities": [{"text": "AP average results", "start_pos": 131, "end_pos": 149, "type": "METRIC", "confidence": 0.8981163501739502}]}, {"text": "The third   The results show that, for each method, automatic selection outperforms the two manual selections.", "labels": [], "entities": []}, {"text": "Most of the attributes automatically selected are DS measures, but it is interesting to observe that MSFlex and the verb slot contribute to improving the results.", "labels": [], "entities": [{"text": "DS", "start_pos": 50, "end_pos": 52, "type": "METRIC", "confidence": 0.8705412745475769}, {"text": "MSFlex", "start_pos": 101, "end_pos": 107, "type": "DATASET", "confidence": 0.7461751699447632}]}, {"text": "Using automatic attribute selection and LR, the results are close to the best figure of F W.Av. using SMO and all the features (0.727 vs 0.744).", "labels": [], "entities": [{"text": "LR", "start_pos": 40, "end_pos": 42, "type": "METRIC", "confidence": 0.9899186491966248}, {"text": "F W.Av.", "start_pos": 88, "end_pos": 95, "type": "DATASET", "confidence": 0.6715427339076996}, {"text": "SMO", "start_pos": 102, "end_pos": 105, "type": "METRIC", "confidence": 0.7917506098747253}]}], "tableCaptions": [{"text": " Table 1: Kendall's \u03c4 B rank-correlations relative to an ideal idiomaticity ranking, obtained by different idiomaticity  measures. Non-significant values of \u03c4 B in parentheses (p > 0.05). Average precisions for MWEs in general, and  specific values for idioms and collocations.", "labels": [], "entities": [{"text": "precisions", "start_pos": 196, "end_pos": 206, "type": "METRIC", "confidence": 0.7425487637519836}]}, {"text": " Table 2: Results of Machine Learning experiments combining knowledge sources in three ways: (i) DS: distributional  similarity features; (ii) knowledge related to the four components of idiomaticity (AM+DS+MSFlex+LFlex); (iii)  previous features+verb components of bigrams.", "labels": [], "entities": []}, {"text": " Table 3: F Weighted average and F average results for ex- periments using: (1) the 20 attributes with best AP aver- age results; (2) a manual selection of the 3 best attributes  from each knowledge source; and (3) AttributeSelected- Classifier with automatic attribute selection using Cfs- SubsetEval as evaluator and BestFirst as search method", "labels": [], "entities": [{"text": "F Weighted average", "start_pos": 10, "end_pos": 28, "type": "METRIC", "confidence": 0.909028172492981}, {"text": "F average", "start_pos": 33, "end_pos": 42, "type": "METRIC", "confidence": 0.980654776096344}]}]}