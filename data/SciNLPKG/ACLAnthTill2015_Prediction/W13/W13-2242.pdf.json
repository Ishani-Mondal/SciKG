{"title": [{"text": "Referential Translation Machines for Quality Estimation", "labels": [], "entities": [{"text": "Referential Translation Machines", "start_pos": 0, "end_pos": 32, "type": "TASK", "confidence": 0.957467516263326}]}], "abstractContent": [{"text": "We introduce referential translation machines (RTM) for quality estimation of translation outputs.", "labels": [], "entities": [{"text": "referential translation machines (RTM)", "start_pos": 13, "end_pos": 51, "type": "TASK", "confidence": 0.7290895382563273}]}, {"text": "RTMs area computational model for identifying the translation acts between any two data sets with respect to a reference corpus selected in the same domain, which can be used for estimating the quality of translation outputs, judging the semantic similarity between text, and evaluating the quality of student answers.", "labels": [], "entities": []}, {"text": "RTMs achieve top performance in automatic, accurate, and language independent prediction of sentence-level and word-level statistical machine translation (SMT) quality.", "labels": [], "entities": [{"text": "language independent prediction of sentence-level and word-level statistical machine translation (SMT) quality", "start_pos": 57, "end_pos": 167, "type": "TASK", "confidence": 0.5871658452919551}]}, {"text": "RTMs remove the need to access any SMT system specific information or prior knowledge of the training data or models used when generating the translations.", "labels": [], "entities": [{"text": "RTMs", "start_pos": 0, "end_pos": 4, "type": "TASK", "confidence": 0.8429567217826843}, {"text": "SMT system specific", "start_pos": 35, "end_pos": 54, "type": "TASK", "confidence": 0.8810682694117228}]}, {"text": "We develop novel techniques for solving all subtasks in the WMT13 quality estimation (QE) task (QET 2013) based on individual RTM models.", "labels": [], "entities": [{"text": "WMT13 quality estimation (QE) task (QET 2013)", "start_pos": 60, "end_pos": 105, "type": "TASK", "confidence": 0.7811098423871127}]}, {"text": "Our results achieve improvements over last year's QE task results (QET 2012), as well as our previous results, provide new features and techniques for QE, and rank 1st or 2nd in all of the subtasks.", "labels": [], "entities": [{"text": "QE task results (QET 2012)", "start_pos": 50, "end_pos": 76, "type": "DATASET", "confidence": 0.8473048465592521}, {"text": "QE", "start_pos": 151, "end_pos": 153, "type": "TASK", "confidence": 0.9236046671867371}]}], "introductionContent": [{"text": "Quality Estimation Task (QET) aims to develop quality indicators for translations and predictors without access to the references.", "labels": [], "entities": [{"text": "translations and predictors", "start_pos": 69, "end_pos": 96, "type": "TASK", "confidence": 0.8218737045923868}]}, {"text": "Prediction of translation quality is important because the expected translation performance can help in estimating the effort required for correcting the translations during post-editing by human translators.", "labels": [], "entities": []}, {"text": "RTMs reduce our dependence on any task dependent resource.", "labels": [], "entities": [{"text": "RTMs", "start_pos": 0, "end_pos": 4, "type": "TASK", "confidence": 0.8532902002334595}]}, {"text": "In particular, we do not use the baseline software or the SMT resources provided with the QET 2013 challenge.", "labels": [], "entities": [{"text": "SMT", "start_pos": 58, "end_pos": 61, "type": "TASK", "confidence": 0.9708254933357239}, {"text": "QET 2013 challenge", "start_pos": 90, "end_pos": 108, "type": "DATASET", "confidence": 0.9300418694814047}]}, {"text": "We believe having access to glass-box features such as the phrase table or the n-best lists is not realistic especially for use-cases where translations maybe provided by different MT vendors (not necessarily from SMT products) or by human translators.", "labels": [], "entities": []}, {"text": "Even the prior knowledge of the training corpora used for building the SMT models or any other model used when generating the translations diverges from the goal of independent and unbiased prediction of translation quality.", "labels": [], "entities": [{"text": "SMT", "start_pos": 71, "end_pos": 74, "type": "TASK", "confidence": 0.9831205606460571}]}, {"text": "Our results show that we do not need to use any SMT system dependent information to achieve the top performance when predicting translation output quality.", "labels": [], "entities": [{"text": "SMT system", "start_pos": 48, "end_pos": 58, "type": "TASK", "confidence": 0.8827943503856659}, {"text": "predicting translation output", "start_pos": 117, "end_pos": 146, "type": "TASK", "confidence": 0.7894015113512675}]}], "datasetContent": [{"text": "In this section, we describe the metrics we use to evaluate the learning performance.", "labels": [], "entities": []}, {"text": "Relative absolute error measures the error relative to the error when predicting the actual mean.", "labels": [], "entities": [{"text": "Relative absolute error", "start_pos": 0, "end_pos": 23, "type": "METRIC", "confidence": 0.8986843427022299}]}, {"text": "We use the coefficient of determination, , during optimization where the models are regression based and higher R 2 values are better.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Data statistics for different tasks. The  number of words is listed after tokenization.", "labels": [], "entities": []}, {"text": " Table 2: Statistics of the training data used as in- terpretants in the RTM models in thousands (K) of  sentences or millions (M) of words.", "labels": [], "entities": []}, {"text": " Table 3: Optimal parameters predicted by Equa- tion 1 and Equation 2 and the optimized parame- ter values, \u02c6  C and \u03b3 for SVR and SVRPLS and the  number of dimensions (# dim) for SVRPLS.", "labels": [], "entities": []}, {"text": " Table 4: Task1.1 results on the training set.", "labels": [], "entities": []}, {"text": " Table 5.  Rank lists the overall ranking in the task. RTMs  with SVR PLS learning is able to achieve the top  rank in this task.", "labels": [], "entities": []}, {"text": " Table 5: Task1.1 results on the test set.", "labels": [], "entities": []}, {"text": " Table 6: Task1.2 results on the training set.", "labels": [], "entities": []}, {"text": " Table 7: Task1.2 optimized thresholds and the  corresponding comparisons that were found to be  equal (# same) over all comparisons (# all).", "labels": [], "entities": []}, {"text": " Table 8. We are also able  to achieve the top ranking in this task.", "labels": [], "entities": []}, {"text": " Table 8: Task1.2 results on the test set.", "labels": [], "entities": []}, {"text": " Table 9: Task1.3 results on the training set.", "labels": [], "entities": []}, {"text": " Table 10.  We are able to become the 2nd best system accord- ing to MAE in this task.", "labels": [], "entities": [{"text": "MAE", "start_pos": 69, "end_pos": 72, "type": "DATASET", "confidence": 0.4935413599014282}]}, {"text": " Table 10: Task1.3 results on the test set.", "labels": [], "entities": []}, {"text": " Table 11: Task 2 results on the test set.", "labels": [], "entities": []}]}