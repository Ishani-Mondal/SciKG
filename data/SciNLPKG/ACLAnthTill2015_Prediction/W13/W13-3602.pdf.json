{"title": [], "abstractContent": [{"text": "The CoNLL-2013 shared task focuses on correcting grammatical errors in essays written by non-native learners of English.", "labels": [], "entities": [{"text": "correcting grammatical errors in essays written by non-native learners of English", "start_pos": 38, "end_pos": 119, "type": "TASK", "confidence": 0.8888825449076566}]}, {"text": "In this paper, we describe the University of Illinois system that participated in the shared task.", "labels": [], "entities": []}, {"text": "The system consists of five components and targets five types of common grammatical mistakes made by En-glish as Second Language writers.", "labels": [], "entities": []}, {"text": "We describe our underlying approach, which relates to our previous work, and describe the novel aspects of the system in more detail.", "labels": [], "entities": []}, {"text": "Out of 17 participating teams, our system is ranked first based on both the original annotation and on the revised annotation .", "labels": [], "entities": []}], "introductionContent": [{"text": "The task of correcting grammar and usage mistakes made by English as a Second Language (ESL) writers is difficult for several reasons.", "labels": [], "entities": [{"text": "correcting grammar and usage mistakes made by English as a Second Language (ESL) writers", "start_pos": 12, "end_pos": 100, "type": "TASK", "confidence": 0.8205173127353191}]}, {"text": "First, many of these errors are context-sensitive mistakes that confuse valid English words and thus cannot be detected without considering the context around the word.", "labels": [], "entities": []}, {"text": "Second, the relative frequency of mistakes is quite low: fora given type of mistake, an ESL writer will typically make mistakes in only a small proportion of relevant structures.", "labels": [], "entities": []}, {"text": "For example, determiner mistakes usually occur in 5% to 10% of noun phrases in various annotated ESL corpora.", "labels": [], "entities": []}, {"text": "Third, an ESL writer may make multiple mistakes in a single sentence, which may give misleading local cues for individual classifiers.", "labels": [], "entities": []}, {"text": "In the example shown in, the agreement error on the verb \"tend\" interacts with the noun number error on the word \"equipments\".", "labels": [], "entities": []}, {"text": "Therefore , the *equipments/equipment of biometric identification *tend/tends to be inexpensive . The CoNLL-2013 shared task ( ) focuses on the following five common mistakes made by ESL writers: \u2022 article/determiner \u2022 preposition \u2022 noun number \u2022 subject-verb agreement \u2022 verb form Errors outside this target group are present in the task corpora, but are not evaluated.", "labels": [], "entities": [{"text": "biometric identification", "start_pos": 41, "end_pos": 65, "type": "TASK", "confidence": 0.7955004572868347}]}, {"text": "In this paper, we present a system that combines a set of statistical models, where each model specializes in correcting one of the errors described above.", "labels": [], "entities": []}, {"text": "Because the individual error types have different characteristics, we use several different approaches.", "labels": [], "entities": []}, {"text": "The article system builds on the elements of the system described in).", "labels": [], "entities": []}, {"text": "The preposition classifier uses a combined system, building on work described in (  and).", "labels": [], "entities": []}, {"text": "The remaining three models are all Na\u00a8\u0131veNa\u00a8\u0131ve Bayes classifiers trained on the Google Web 1T 5-gram corpus (henceforth, Google corpus,).", "labels": [], "entities": [{"text": "Google Web 1T 5-gram corpus", "start_pos": 81, "end_pos": 108, "type": "DATASET", "confidence": 0.8241982579231262}, {"text": "Google corpus", "start_pos": 122, "end_pos": 135, "type": "DATASET", "confidence": 0.9394212961196899}]}, {"text": "We first briefly discuss the task (Section 2) and give the overview of our system (Section 3).", "labels": [], "entities": []}, {"text": "We then describe the error-specific components (Sections 3.1, 3.2 and 3.3).", "labels": [], "entities": []}, {"text": "The sections describing individual components quantify their performance on splits of the training data.", "labels": [], "entities": []}, {"text": "In Section 4, we evaluate the complete system on the training data using 5-fold cross-validation (hereafter, \"5-fold CV\") and in Section 5 we show the results we obtained on test.", "labels": [], "entities": []}, {"text": "We close with a discussion focused on error analysis (Section 6) and our conclusions (Section 7).", "labels": [], "entities": [{"text": "error analysis", "start_pos": 38, "end_pos": 52, "type": "TASK", "confidence": 0.8247357308864594}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 2: Statistics on error distribution in train- ing and test data. Percentage denotes the erro- neous instances with respect to the total number of  relevant instances in the data. For example, 10%  of noun phrases in the test data have determiner  errors.", "labels": [], "entities": [{"text": "erro- neous instances", "start_pos": 95, "end_pos": 116, "type": "METRIC", "confidence": 0.9111056625843048}]}, {"text": " Table 4. The results show that AP performs better  than LR. We observed that adding the LM feature  improves precision but results in lower F1, so we  chose the AP classifier without the LM feature for  our final system.", "labels": [], "entities": [{"text": "AP", "start_pos": 32, "end_pos": 34, "type": "METRIC", "confidence": 0.9475464820861816}, {"text": "precision", "start_pos": 110, "end_pos": 119, "type": "METRIC", "confidence": 0.9994580149650574}, {"text": "F1", "start_pos": 141, "end_pos": 143, "type": "METRIC", "confidence": 0.9986013770103455}]}, {"text": " Table 4: Article development results Results on 5-fold", "labels": [], "entities": [{"text": "Article development", "start_pos": 10, "end_pos": 29, "type": "TASK", "confidence": 0.8451490104198456}]}, {"text": " Table 6: Noun, subject-verb agreement and  verb form results. Results on 5-fold CV. The  models are trained on the Google corpus.", "labels": [], "entities": [{"text": "Google corpus", "start_pos": 116, "end_pos": 129, "type": "DATASET", "confidence": 0.8725835382938385}]}, {"text": " Table 7: Results on 5-fold CV on the training  data. The article model is trained on the ESL  data using AP. The other models are trained on the  Google corpus. The last line shows the results,  when all of the five modules are included.", "labels": [], "entities": [{"text": "ESL  data", "start_pos": 90, "end_pos": 99, "type": "DATASET", "confidence": 0.9391919374465942}, {"text": "AP", "start_pos": 106, "end_pos": 108, "type": "METRIC", "confidence": 0.8904706239700317}, {"text": "Google corpus", "start_pos": 147, "end_pos": 160, "type": "DATASET", "confidence": 0.9502456486225128}]}, {"text": " Table 8: Results on Test. The article model is  trained on the ESL data using AP. The other mod- els are trained on the Google corpus. All denotes  the results of the complete model that includes all  of the five modules.", "labels": [], "entities": [{"text": "ESL data", "start_pos": 64, "end_pos": 72, "type": "DATASET", "confidence": 0.9490631520748138}, {"text": "AP", "start_pos": 79, "end_pos": 81, "type": "METRIC", "confidence": 0.8257887959480286}, {"text": "Google corpus", "start_pos": 121, "end_pos": 134, "type": "DATASET", "confidence": 0.9316506683826447}]}]}