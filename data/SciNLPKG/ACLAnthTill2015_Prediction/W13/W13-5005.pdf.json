{"title": [{"text": "Graph-Based Unsupervised Learning of Word Similarities Using Heterogeneous Feature Types", "labels": [], "entities": [{"text": "Graph-Based Unsupervised Learning of Word Similarities", "start_pos": 0, "end_pos": 54, "type": "TASK", "confidence": 0.6010284572839737}]}], "abstractContent": [{"text": "In this work, we propose a graph-based approach to computing similarities between words in an unsupervised manner, and take advantage of heterogeneous feature types in the process.", "labels": [], "entities": []}, {"text": "The approach is based on the creation of two separate graphs, one for words and one for features of different types (alignment-based, orthographic, etc.).", "labels": [], "entities": []}, {"text": "The graphs are connected through edges that link nodes in the feature graph to nodes in the word graph, the edge weights representing the importance of a particular feature fora particular word.", "labels": [], "entities": []}, {"text": "High quality graphs are learned during training, and the proposed method outperforms experimental baselines.", "labels": [], "entities": []}], "introductionContent": [{"text": "Data-driven approaches in natural language processing (NLP) have resulted in a marked improvement in a variety of NLP tasks, from machine translation to part-of-speech tagging.", "labels": [], "entities": [{"text": "natural language processing (NLP)", "start_pos": 26, "end_pos": 59, "type": "TASK", "confidence": 0.823843389749527}, {"text": "machine translation", "start_pos": 130, "end_pos": 149, "type": "TASK", "confidence": 0.7596774101257324}, {"text": "part-of-speech tagging", "start_pos": 153, "end_pos": 175, "type": "TASK", "confidence": 0.7104027569293976}]}, {"text": "Such methods however, are generally only as good as the quality of the data itself.", "labels": [], "entities": []}, {"text": "This issue becomes highlighted when there is a mismatch in domain between training and test data, in that the number of out-of-vocabulary (OOV) words increases, resulting in problems for language modeling, machine translation, and other tasks.", "labels": [], "entities": [{"text": "language modeling", "start_pos": 187, "end_pos": 204, "type": "TASK", "confidence": 0.7238107919692993}, {"text": "machine translation", "start_pos": 206, "end_pos": 225, "type": "TASK", "confidence": 0.8087598085403442}]}, {"text": "An approach that specifically replaces OOV words with their synonyms from a restricted vocabulary (i.e., the words already contained in the training data) could alleviate this OOV word problem.", "labels": [], "entities": []}, {"text": "* This work was done during the first author's internship at the IBM T.J.", "labels": [], "entities": [{"text": "IBM T.J.", "start_pos": 65, "end_pos": 73, "type": "DATASET", "confidence": 0.7165640989939371}]}, {"text": "Watson Research Center, Yorktown Heights, NY in 2012.", "labels": [], "entities": [{"text": "Watson Research Center, Yorktown Heights, NY in 2012", "start_pos": 0, "end_pos": 52, "type": "DATASET", "confidence": 0.883482813835144}]}, {"text": "Vast ontologies that capture semantic similarities between words, also known as WordNets, have been carefully created and compiled by linguists for different languages.", "labels": [], "entities": [{"text": "WordNets", "start_pos": 80, "end_pos": 88, "type": "DATASET", "confidence": 0.9291236996650696}]}, {"text": "A WordNet-based solution could be implemented to fill the gaps when an OOV word is encountered, but this approach is not scalable in that it requires significant human effort fora number of languages in which the WordNet is limited or does not exist.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 213, "end_pos": 220, "type": "DATASET", "confidence": 0.9458498358726501}]}, {"text": "Thus, a practical solution to this problem should ideally require as little human supervision and involvement as possible.", "labels": [], "entities": []}, {"text": "Additionally, words can be similar to each other due to a variety of reasons.", "labels": [], "entities": []}, {"text": "For example, the similarity between the words optimize and optimal can be captured via the high orthographical similarity between the words.", "labels": [], "entities": []}, {"text": "However, relying too much on a single feature type may result in false positives, e.g., suggestions of antonyms instead of synonyms.", "labels": [], "entities": []}, {"text": "Valuable information can be gleaned from a variety of feature types, both monolingual and bilingual.", "labels": [], "entities": []}, {"text": "Thus, any potential solution to an unsupervised or mildly supervised word similarity algorithm should be able to take into account heterogeneous feature types and combine them in a globally effective manner when yielding the final solution.", "labels": [], "entities": [{"text": "word similarity algorithm", "start_pos": 69, "end_pos": 94, "type": "TASK", "confidence": 0.7774496078491211}]}, {"text": "In this work, we present a graph-based approach to impute word similarities in an unsupervised manner and takes into account heterogeneous features.", "labels": [], "entities": []}, {"text": "The key idea is to maintain two graphs, one for words and one for the all the features of different types, and attempt to promote concurrence between the two graphs in an effort to find a final solution.", "labels": [], "entities": []}, {"text": "The similarity graphs learned during training are generally of high quality, and the testing approach proposed outperforms the chosen baselines.", "labels": [], "entities": []}], "datasetContent": [{"text": "In our experiments, we looked at both the quality of the similarity graphs learned from the data, as well as the performance of the link prediction techniques.", "labels": [], "entities": [{"text": "link prediction", "start_pos": 132, "end_pos": 147, "type": "TASK", "confidence": 0.7371849864721298}]}, {"text": "Automatic evaluation of an algorithm that computes similarities between words is tricky.", "labels": [], "entities": []}, {"text": "The judgment on whether two words are synonyms is still done best by a human, requiring significant manual effort.", "labels": [], "entities": []}, {"text": "Therefore, during the experimentation and parameter selection process we developed an intermediate form of evaluation wherein a human annotator assisted in creating a pseudo \"ground truth\".", "labels": [], "entities": [{"text": "parameter selection", "start_pos": 42, "end_pos": 61, "type": "TASK", "confidence": 0.7451771795749664}]}, {"text": "Prior to creating the ground truth, all OOV words in the test set were identified (i.e., no match in our vocabulary), resulting in 978 OOV words.", "labels": [], "entities": []}, {"text": "Named entities were then manually filtered, resulting in a final test set of 312 words for evaluation purposes.", "labels": [], "entities": []}, {"text": "To create the ground truth, we generated for each test OOV word a set of possible synonyms using the alignment and orthographic baselines, as per Section 3.3.", "labels": [], "entities": []}, {"text": "Naturally, many of the words generated were not legitimate synonyms; human evaluators thus removed all words that were not synonyms or near synonyms, ignoring mild grammatical inconsistencies, like singular vs. plural.", "labels": [], "entities": []}, {"text": "Generally, a synonym was considered valid if substituting the word with the synonym preserved meaning in a sentence.", "labels": [], "entities": []}, {"text": "The final evaluation was performed by a human evaluator.", "labels": [], "entities": []}, {"text": "The two baselines and the proposed approach generated the top three synonym candidates fora given OOV test word and both 1-best and 3-best results were evaluated (as in).", "labels": [], "entities": []}, {"text": "Final performance was evaluated using precision and recall.", "labels": [], "entities": [{"text": "precision", "start_pos": 38, "end_pos": 47, "type": "METRIC", "confidence": 0.9996973276138306}, {"text": "recall", "start_pos": 52, "end_pos": 58, "type": "METRIC", "confidence": 0.9988055229187012}]}, {"text": "Recall is defined as the percentage of words for which at least one synonym was generated, and precision evaluates the number of correct synonyms from the ones generated.", "labels": [], "entities": [{"text": "Recall", "start_pos": 0, "end_pos": 6, "type": "METRIC", "confidence": 0.9732555150985718}, {"text": "precision", "start_pos": 95, "end_pos": 104, "type": "METRIC", "confidence": 0.999543309211731}]}], "tableCaptions": [{"text": " Table 1: Corpus statistics for the datasets used in evaluation.", "labels": [], "entities": []}, {"text": " Table 2: Statistics on the number of features extracted based on the number of words, broken down by feature type. Note that the  distributional features are only those with count 5 and above.", "labels": [], "entities": []}, {"text": " Table 4: Legend for the charts in", "labels": [], "entities": []}, {"text": " Table 5: 1-best evaluation results on WMT 2010 OOV words  trained on a 50,000-word vocabulary. Our best approach (\"50k- nhnl\") is bolded", "labels": [], "entities": [{"text": "WMT 2010 OOV words", "start_pos": 39, "end_pos": 57, "type": "DATASET", "confidence": 0.8773199766874313}]}, {"text": " Table 6: 3-best evaluation results on WMT 2010 OOV words  trained on a 50,000-word vocabulary. Our best approach (\"50k- nhnl\") is bolded", "labels": [], "entities": [{"text": "WMT 2010 OOV words", "start_pos": 39, "end_pos": 57, "type": "DATASET", "confidence": 0.8784931153059006}]}]}