{"title": [{"text": "Determining is-a relationships for Textual Entailment", "labels": [], "entities": [{"text": "Textual Entailment", "start_pos": 35, "end_pos": 53, "type": "TASK", "confidence": 0.8169388473033905}]}], "abstractContent": [{"text": "The Textual Entailment task has become influential in NLP and many researchers have become interested in applying it to other tasks.", "labels": [], "entities": [{"text": "Textual Entailment task", "start_pos": 4, "end_pos": 27, "type": "TASK", "confidence": 0.8500210046768188}]}, {"text": "However, the two major issues emerging from this body of work are the fact that NLP applications need systems that (1) attain results which are not corpus dependent and (2) assume that the text for entailment cannot be incorrect or even contradictory.", "labels": [], "entities": []}, {"text": "In this paper we propose a system which decomposes the text into chunks via a shallow text analysis, and determines the entailment relationship by matching the information contained in the is \u2212 a pattern.", "labels": [], "entities": []}, {"text": "The results show that the method is able to cope with the two requirements above.", "labels": [], "entities": []}], "introductionContent": [{"text": "Given a pair of two text fragments, T and H, the textual entailment task consists in deciding whether the information in H is entailed by the information in T ().", "labels": [], "entities": []}, {"text": "Many and diverse systems participated in Recognizing Textual Entailment Challenges (RTE), which helped in pointing out interesting issues with an important impact in other NLP tasks.", "labels": [], "entities": [{"text": "Recognizing Textual Entailment Challenges (RTE)", "start_pos": 41, "end_pos": 88, "type": "TASK", "confidence": 0.7988301217556}]}, {"text": "Under some assumptions, the papers published on this topic have proven that the TE methodology is useful for machine translation, text summarization, information retrieval, question answering, fact checking etc.", "labels": [], "entities": [{"text": "TE", "start_pos": 80, "end_pos": 82, "type": "TASK", "confidence": 0.8840646147727966}, {"text": "machine translation", "start_pos": 109, "end_pos": 128, "type": "TASK", "confidence": 0.8199259042739868}, {"text": "text summarization", "start_pos": 130, "end_pos": 148, "type": "TASK", "confidence": 0.782372921705246}, {"text": "information retrieval", "start_pos": 150, "end_pos": 171, "type": "TASK", "confidence": 0.8179740905761719}, {"text": "question answering", "start_pos": 173, "end_pos": 191, "type": "TASK", "confidence": 0.9077034294605255}, {"text": "fact checking", "start_pos": 193, "end_pos": 206, "type": "TASK", "confidence": 0.9222438037395477}]}, {"text": "The two major issues emerging from this body of work are the fact that NLP applications need systems that (1) attain results which are not corpus dependent and (2) assume that the text for entailment maybe incorrect or even contradictory.", "labels": [], "entities": []}, {"text": "In this paper we propose a system which decomposes the text into chunks via a shallow text analysis, and determines the entailment relationship by matching the information contained in the is \u2212 a pattern.", "labels": [], "entities": []}, {"text": "The results show that the method is able to cope with the two requirements above.", "labels": [], "entities": []}, {"text": "Our system produces stable results on the RTE corpora and is little affected by the presupposed veridical value of the information in T and/or H and, therefore, it is instrumental in addressing the above enumerated issues.", "labels": [], "entities": [{"text": "RTE corpora", "start_pos": 42, "end_pos": 53, "type": "DATASET", "confidence": 0.7536945641040802}]}, {"text": "We focused on the pairs on which H has the form of an is \u2212 a relation between an entity and a property.", "labels": [], "entities": []}, {"text": "The method makes use of shallow text analysis, extracts the information contained in each chunk, and tries to find a match for the entity in Hon the list of entities of T . If the match is successful then the properties of the entities are compared in order to decide on the entailment.", "labels": [], "entities": []}, {"text": "In general, the information allowing the match is not found in a single chunk.", "labels": [], "entities": []}, {"text": "The property of an entity expressed by the is \u2212 a relation found in H maybe not directly expressed in T , the property and the entity being in separated chunks.", "labels": [], "entities": []}, {"text": "The system resolves the coreference between the entities mentioned in each chunk by employing mostly techniques for inter-document coreference (.", "labels": [], "entities": []}, {"text": "To unify the information contained in each chunk we considered a set of heuristics which identifies syntactical fixed forms and expresses them as is \u2212 a relations.", "labels": [], "entities": []}, {"text": "For example, an apposition becomes a copula.", "labels": [], "entities": []}, {"text": "We also recognized relations between entities which are typically expressed as a pattern, for example [[ e1 is known as e2 ]], following the work of).", "labels": [], "entities": []}, {"text": "The basic approach is extended by considering also synonyms/antonyms and negation mismatches.", "labels": [], "entities": [{"text": "negation mismatches", "start_pos": 73, "end_pos": 92, "type": "TASK", "confidence": 0.944894403219223}]}, {"text": "For comparison purposes we considered a set of features which extend the RTE feature set () and syntactic kernels) with SVM.", "labels": [], "entities": [{"text": "RTE feature set", "start_pos": 73, "end_pos": 88, "type": "DATASET", "confidence": 0.7650454839070638}]}, {"text": "The results we obtain support the statement that integration of syntactic and semantic information can yield better results over surface based features.", "labels": [], "entities": []}, {"text": "For a better understanding of the variance of the results according to the corpora, including robustness to noise and dependency of the veridical presupposition on the information in corpus, we used a technique of generating a scrambled corpus similar to the one described in).", "labels": [], "entities": []}, {"text": "The results we obtain confirm that the method is stable and overcome with a large margin other approaches.", "labels": [], "entities": []}, {"text": "Unlike the methods based on logical forms and world knowledge, which many times are less efficient on noisy corpora, the proposed method maintains a shallow syntactic and semantic level while relevant information unification process takes part, a process which is mostly ignored by surface approaches.", "labels": [], "entities": [{"text": "information unification", "start_pos": 201, "end_pos": 224, "type": "TASK", "confidence": 0.7678318023681641}]}, {"text": "The remainder of this paper is organized as follows: in Section 2 we review the relevant literature, in Section 3 we present the details of the methodology we employ and in Section 4 we present and discuss the experiments we carried on the RTE3, 4, and 5 corpora.", "labels": [], "entities": [{"text": "RTE3", "start_pos": 240, "end_pos": 244, "type": "DATASET", "confidence": 0.8137651085853577}]}, {"text": "The paper ends with the conclusions and further work section.", "labels": [], "entities": []}], "datasetContent": [{"text": "We based our experiments on the freely available corpora from the Recognizing Textual Entailment competitions RTE-3, 4 and 5.", "labels": [], "entities": [{"text": "Recognizing Textual Entailment competitions RTE-3", "start_pos": 66, "end_pos": 115, "type": "DATASET", "confidence": 0.5715453326702118}]}, {"text": "All of the entailment pairs were parsed with the BLLIP parser) and subsequently processed with GLARF ().", "labels": [], "entities": [{"text": "BLLIP", "start_pos": 49, "end_pos": 54, "type": "METRIC", "confidence": 0.8349115252494812}, {"text": "GLARF", "start_pos": 95, "end_pos": 100, "type": "METRIC", "confidence": 0.9957899451255798}]}, {"text": "The copula pattern [[ X be \u03b1 ]] was matched in all hypotheses, and only instances where the match was positive were kept, see.", "labels": [], "entities": []}, {"text": "The method presented in the previous section does not require training.", "labels": [], "entities": []}, {"text": "However, in order to have a direct comparison with other methods, we report only the results obtained on the gold corpus.", "labels": [], "entities": [{"text": "gold corpus", "start_pos": 109, "end_pos": 120, "type": "DATASET", "confidence": 0.8966398537158966}]}, {"text": "We employed three progressively complex baselines: \u2022 BL1: Lexical overlap baseline with threshold determined by a linear SVM (Mehdad and Magnini, 2009): RTE corpora, only copula examples", "labels": [], "entities": [{"text": "BL1", "start_pos": 53, "end_pos": 56, "type": "METRIC", "confidence": 0.9797295331954956}]}], "tableCaptions": [{"text": " Table 1: Results on RTE \ud97b\udf59 corpora.", "labels": [], "entities": [{"text": "RTE \ud97b\udf59 corpora", "start_pos": 21, "end_pos": 34, "type": "DATASET", "confidence": 0.7573166092236837}]}, {"text": " Table 2: RTE corpora, only copula examples", "labels": [], "entities": []}, {"text": " Table 3: Results on scrambled corpora", "labels": [], "entities": []}]}