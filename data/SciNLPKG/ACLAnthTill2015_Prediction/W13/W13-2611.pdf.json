{"title": [{"text": "Incremental Grammar Induction from Child-Directed Dialogue Utterances *", "labels": [], "entities": [{"text": "Incremental Grammar Induction from Child-Directed Dialogue Utterances", "start_pos": 0, "end_pos": 69, "type": "TASK", "confidence": 0.8900541067123413}]}], "abstractContent": [{"text": "We describe a method for learning an in-cremental semantic grammar from data in which utterances are paired with logical forms representing their meaning.", "labels": [], "entities": []}, {"text": "Working in an inherently incremental framework , Dynamic Syntax, we show how words can be associated with probabilistic procedures for the incremental projection of meaning, providing a grammar which can be used directly in incremental prob-abilistic parsing and generation.", "labels": [], "entities": [{"text": "prob-abilistic parsing and generation", "start_pos": 236, "end_pos": 273, "type": "TASK", "confidence": 0.6314559280872345}]}, {"text": "We test this on child-directed utterances from the CHILDES corpus, and show that it results in good coverage and semantic accuracy, without requiring annotation at the word level or any independent notion of syntax.", "labels": [], "entities": [{"text": "CHILDES corpus", "start_pos": 51, "end_pos": 65, "type": "DATASET", "confidence": 0.9169255197048187}, {"text": "accuracy", "start_pos": 122, "end_pos": 130, "type": "METRIC", "confidence": 0.9743902087211609}]}], "introductionContent": [{"text": "Human language processing has long been thought to function incrementally, both in parsing and production (.", "labels": [], "entities": []}, {"text": "This incrementality gives rise to many characteristic phenomena in conversational dialogue, including unfinished utterances, interruptions and compound contributions constructed by more than one participant, which pose problems for standard grammar formalisms).", "labels": [], "entities": []}, {"text": "In particular, examples such as (1) suggest that a suitable formalism would be one which defines grammaticality not in terms of licensing strings, but in terms of constraints on the semantic construction process, and which ensures this process is common between parsing and generation.", "labels": [], "entities": []}, {"text": "(1) A: I burnt the toast.", "labels": [], "entities": [{"text": "A", "start_pos": 4, "end_pos": 5, "type": "METRIC", "confidence": 0.9878908395767212}]}, {"text": "* We are grateful to Ruth Kempson for her support and helpful discussions throughout this work.", "labels": [], "entities": []}, {"text": "We also thank the CMCL'2013 anonymous reviewers for their constructive criticism.", "labels": [], "entities": [{"text": "CMCL'2013 anonymous reviewers", "start_pos": 18, "end_pos": 47, "type": "DATASET", "confidence": 0.9273893634478251}]}, {"text": "This work was supported by the EPSRC, RISER project (Ref: EP/J010383/1), and in part by the EU, FP7 project, SpaceBook (Grant agreement no: 270019).", "labels": [], "entities": [{"text": "EPSRC", "start_pos": 31, "end_pos": 36, "type": "DATASET", "confidence": 0.9713414907455444}, {"text": "RISER project (Ref: EP/J010383/1", "start_pos": 38, "end_pos": 70, "type": "DATASET", "confidence": 0.8696408987045288}, {"text": "FP7", "start_pos": 96, "end_pos": 99, "type": "DATASET", "confidence": 0.8624136447906494}]}, {"text": "B: But did you burn . .", "labels": [], "entities": [{"text": "B", "start_pos": 0, "end_pos": 1, "type": "METRIC", "confidence": 0.9386654496192932}]}, {"text": "[where \"did you burn myself?\" if uttered by the same speaker is ungrammatical] One such formalism is Dynamic Syntax (DS) (); it recognises no intermediate layer of syntax, but instead reflects grammatical constraints via constraints on the word-by-word incremental construction of meaning, underpinned by attendant concepts of underspecification and update.", "labels": [], "entities": []}, {"text": "describe a method for inducing a probabilistic DS lexicon from sentences paired with DS semantic trees (see below) representing not only their meaning, but their functionargument structure with fine-grained typing information.", "labels": [], "entities": []}, {"text": "They apply their method only to an artificial corpus generated using a known lexicon.", "labels": [], "entities": []}, {"text": "Here, we build on that work to induce a lexicon from real child-directed utterances paired with less structured Logical Forms in the form of TTR Record Types, thus providing less supervision.", "labels": [], "entities": []}, {"text": "By assuming only the availability of a small set of general compositional semantic operations, reflecting the properties of the lambda calculus and the logic of finite trees, we ensure that the lexical entries learnt include the grammatical constraints and corresponding compositional semantic structure of the language.", "labels": [], "entities": []}, {"text": "Our method exhibits incrementality in two senses: incremental learning, with the grammar being extended and refined as each new sentence becomes available; resulting in an inherently incremental, probabilistic grammar for parsing and production, suitable for use in state-of-the-art incremental dialogue systems) and for modelling humanhuman dialogue.", "labels": [], "entities": []}], "datasetContent": [{"text": "Corpus We tested our approach on a section of the Eve corpus within CHILDES), a series of English child-directed utterances, annotated with LFs by following's syntactic annotation.", "labels": [], "entities": []}, {"text": "We convert these LFs into semantically equivalent RTs; e.g. shows the conversion to a record type for \"He doesn't have a hat\".", "labels": [], "entities": []}, {"text": "Importantly, our representations remove all part-of-speech or syntactic information; e.g. the subject, object and indirect object predicates function as purely semantic role information expressing an event's participants.", "labels": [], "entities": []}, {"text": "This includes e.g. do-aux(e) in, which is taken merely to represent temporal/aspectual information about the event, and could be part of any word hypothesis.", "labels": [], "entities": []}, {"text": "From this corpus we selected 500 short utterance-record type pairs.", "labels": [], "entities": []}, {"text": "The minimum utterance length in this set is 1 word, maximum 7, mean 3.7; it contains 1481 word tokens of 246 types, giving a type:token ratio of 6.0).", "labels": [], "entities": []}, {"text": "We use the first 400 for training and 100 for testing; the test set also has a mean utterance length of 3.7 words, and contains only words seen in training.", "labels": [], "entities": []}, {"text": "Evaluation We evaluate our learner by comparing the record type semantic LFs produced using the induced lexicon against the gold standard LFs, calculating precision, recall and f-score using a method similar to Each field has a potential score in the range.", "labels": [], "entities": [{"text": "precision", "start_pos": 155, "end_pos": 164, "type": "METRIC", "confidence": 0.9996514320373535}, {"text": "recall", "start_pos": 166, "end_pos": 172, "type": "METRIC", "confidence": 0.9994568228721619}, {"text": "f-score", "start_pos": 177, "end_pos": 184, "type": "METRIC", "confidence": 0.9753361940383911}]}, {"text": "The potential maximum for any pair is therefore the number of fields in R 1 (including those in embedded record types).", "labels": [], "entities": []}, {"text": "So, for hypothesis H and goal record type G, with NH and N G fields respectively: shows that the grammar learned achieves both good parsing coverage and semantic accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 162, "end_pos": 170, "type": "METRIC", "confidence": 0.9577717185020447}]}, {"text": "Using the top 3 lexical hypotheses induced from training, 92% of test set utterances receive a parse, and average LF f-score reaches 0.851.", "labels": [], "entities": [{"text": "LF f-score", "start_pos": 114, "end_pos": 124, "type": "METRIC", "confidence": 0.9530680179595947}]}, {"text": "We manually inspected the learned lexicon for instances of ambiguous words to assess the system's ability to disambiguate (e.g. the word ''s' (is) has three different senses in our corpus: (1) auxiliary, e.g. \"the coffee's coming\"; (2) verb predicating NP identity, e.g. \"that's a girl\"; and (3) verb predicating location, e.g. \"where's the pencil\").", "labels": [], "entities": []}, {"text": "From these the first two were in the top 3 hypotheses (probabilities p=0.227 and p=0.068).", "labels": [], "entities": []}, {"text": "For example, the lexical entry learned for (2) is shown in.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Results: parse coverage & accuracy using  the top N hypotheses induced in training.", "labels": [], "entities": [{"text": "parse coverage", "start_pos": 19, "end_pos": 33, "type": "TASK", "confidence": 0.837945431470871}, {"text": "accuracy", "start_pos": 36, "end_pos": 44, "type": "METRIC", "confidence": 0.9993458390235901}]}]}