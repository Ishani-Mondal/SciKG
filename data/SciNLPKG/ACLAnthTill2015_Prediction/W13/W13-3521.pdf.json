{"title": [{"text": "Exploiting multiple hypotheses for Multilingual Spoken Language Understanding", "labels": [], "entities": []}], "abstractContent": [{"text": "In this work, we present an approach for multilingual portability of Spoken Language Understanding systems.", "labels": [], "entities": [{"text": "Spoken Language Understanding", "start_pos": 69, "end_pos": 98, "type": "TASK", "confidence": 0.7787415583928426}]}, {"text": "The goal of this approach is to avoid the effort of acquiring and labeling new corpora to learn models when changing the language.", "labels": [], "entities": []}, {"text": "The work presented in this paper is focused on the learning of a specific translator for the task and the mechanism of transmitting the information among the modules by means of graphs.", "labels": [], "entities": []}, {"text": "These graphs represent a set of hypotheses (a language) that is the input to the statistical semantic decoder that provides the meaning of the sentence.", "labels": [], "entities": []}, {"text": "Some experiments in a Spanish task evaluated with input French utterances and text are presented.", "labels": [], "entities": []}, {"text": "They show the good behavior of the system, mainly when speech input is considered.", "labels": [], "entities": []}], "introductionContent": [{"text": "Spoken Language Understanding (SLU) is one of the key modules in many voice-driven humancomputer interaction systems.", "labels": [], "entities": [{"text": "Spoken Language Understanding (SLU)", "start_pos": 0, "end_pos": 35, "type": "TASK", "confidence": 0.8435896535714468}]}, {"text": "Many successful SLU systems that have been developed in the last few years are based on statistical models automatically learned from semantically labeled corpora.", "labels": [], "entities": []}, {"text": "One of the advantages of statistical models is the capability of representing the variability of lexical realizations of concepts (meanings).", "labels": [], "entities": []}, {"text": "On the other hand, they are usually plain models, that is, they cannot represent a hierarchical semantic dependency, although there are some works in this area.", "labels": [], "entities": []}, {"text": "However, this is not a problem inmost Spoken Dialog Systems since the semantic information to be extracted is not very hierarchically structured.", "labels": [], "entities": []}, {"text": "Another important aspect of these models is that they can be learned from corpora.", "labels": [], "entities": []}, {"text": "The corpora used for training must be large enough to allow an accurate estimation of the probabilities, and it must represent the lexical and syntactic variability that is used in the language to express the semantics as much as possible.", "labels": [], "entities": []}, {"text": "Although there are some approaches based on semi-supervised or unsupervised learning, the most common approaches need to have a segmented and labeled training corpus.", "labels": [], "entities": []}, {"text": "This is the case of discriminative models (like Conditional Random Fields (), and generative models (such as Hidden Markov Models and Stochastic Finite State Automata ().", "labels": [], "entities": []}, {"text": "In the case of supervised learning, it is necessary to define a set of concepts that represent the semantic domain of the task and to associate these concepts to the corresponding sequences of words in the sentences.", "labels": [], "entities": []}, {"text": "This is the case of the French MEDIA corpus (, and the Spanish DIHANA corpus).", "labels": [], "entities": [{"text": "French MEDIA corpus", "start_pos": 24, "end_pos": 43, "type": "DATASET", "confidence": 0.8263728419939677}, {"text": "DIHANA corpus", "start_pos": 63, "end_pos": 76, "type": "DATASET", "confidence": 0.7579732537269592}]}, {"text": "Since the corpus acquisition and labeling require a great manual effort, being able to reuse the corpus generated fora task to easily develop SLU systems for other tasks, or languages, is an important issue.", "labels": [], "entities": [{"text": "corpus acquisition", "start_pos": 10, "end_pos": 28, "type": "TASK", "confidence": 0.7272690534591675}]}, {"text": "This work focuses on the problem of SLU portability between languages ().", "labels": [], "entities": [{"text": "SLU portability between languages", "start_pos": 36, "end_pos": 69, "type": "TASK", "confidence": 0.9241392314434052}]}, {"text": "We propose a semi-supervised approach for adapting the system to tackle sentences that are uttered in anew language.", "labels": [], "entities": []}, {"text": "In order to learn a domain-specific translation model, a parallel corpus is automatically generated from the training set by using web translators.", "labels": [], "entities": []}, {"text": "Due to the fact that the speech recognition and the translation phases can generate many errors, a mechanism to obtain the correct meaning despite these errors is needed.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 25, "end_pos": 43, "type": "TASK", "confidence": 0.7617505788803101}]}, {"text": "This can be performed by supplying many hypotheses between the different stages, either as a set of n sentences or as a graph that represents not only the original sentences but also an adequate generalization of them.", "labels": [], "entities": []}, {"text": "This graph can be obtained from a Grammatical Inference process.", "labels": [], "entities": []}, {"text": "We have also developed a specific algorithm to perform the semantic decoding by taking graphs of words as the input and considering statistical semantic models.", "labels": [], "entities": [{"text": "semantic decoding", "start_pos": 59, "end_pos": 76, "type": "TASK", "confidence": 0.7076232433319092}]}, {"text": "We have applied these techniques for the DIHANA corpus, which is a task to access the information of train timetables and fares in Spanish by phone.", "labels": [], "entities": [{"text": "DIHANA corpus", "start_pos": 41, "end_pos": 54, "type": "DATASET", "confidence": 0.8115061819553375}]}, {"text": "This corpus was originally generated in Spanish, and we have evaluated our system by using input sentences in French.", "labels": [], "entities": []}], "datasetContent": [{"text": "To evaluate this architecture, we performed a set of experiments with the DIHANA corpus.", "labels": [], "entities": [{"text": "DIHANA corpus", "start_pos": 74, "end_pos": 87, "type": "DATASET", "confidence": 0.958033949136734}]}, {"text": "The user turns of the corpus were split into a set of 4889 turns for training and 1227 turns for test.", "labels": [], "entities": []}, {"text": "To train the translation models, the training set was automatically translated from Spanish into French by four freely available web translators (Apertium, Bing, Google, Lucy), which provided us a parallel training corpus.", "labels": [], "entities": []}, {"text": "The semantic model was learned from the segmentation and labeling provided in the DIHANA corpus for the training sentences in Spanish.", "labels": [], "entities": [{"text": "DIHANA corpus", "start_pos": 82, "end_pos": 95, "type": "DATASET", "confidence": 0.8787682056427002}]}, {"text": "All the Language Models in the semantic model were bigram models trained using WittenBell smoothing.", "labels": [], "entities": []}, {"text": "For evaluation purposes, all the test set was manually translated into French, and 500 turns were uttered by four native French speakers.", "labels": [], "entities": []}, {"text": "Thus, we have carried out experiments both considering as the input to our system the correct sentences in French (which is the same than assuming a perfect ASR) and the utterances.", "labels": [], "entities": []}, {"text": "To recognize the utterances the Google ASR was used, which for this test set provides a Word Error Rate of 21.9% considering only the 1-best recognized sentence.", "labels": [], "entities": [{"text": "Google ASR", "start_pos": 32, "end_pos": 42, "type": "DATASET", "confidence": 0.7455329596996307}, {"text": "Word Error Rate", "start_pos": 88, "end_pos": 103, "type": "METRIC", "confidence": 0.7829606930414835}]}, {"text": "For this experimentation we have considered three kinds of ASR outputs, namely, a Perfect ASR (text input), the 1-best output, and finally the nbest hypotheses (with n ranging from 1 to 20).", "labels": [], "entities": [{"text": "ASR outputs", "start_pos": 59, "end_pos": 70, "type": "TASK", "confidence": 0.8977861702442169}, {"text": "Perfect ASR", "start_pos": 82, "end_pos": 93, "type": "METRIC", "confidence": 0.8544390797615051}]}, {"text": "Also, we have configured the system in two different ways: \u2022 Configuration 1: The output of the statistical translation system are the n-best translations for the input.", "labels": [], "entities": []}, {"text": "Note that these n-best could contain repeated translations, which may lead to the reinforcement of some paths in the graphs of words.", "labels": [], "entities": []}, {"text": "\u2022 Configuration 2: The output of the statistical translation system is the set formed by the best n different (unique) translations that it can provide for the given input.", "labels": [], "entities": []}, {"text": "When the output of the ASR are n-best, we have only considered the Configuration 1.", "labels": [], "entities": []}, {"text": "We have evaluated each experiment using two measures: the Concept Error Rate (CER), which corresponds to errors in the output of the SLU module, and the Frame-Slot Error Rate (FSER), which corresponds to errors in the slots of the frames in the final output of the system., and 5 show the results obtained for each of the ASR outputs and configurations considered.", "labels": [], "entities": [{"text": "Concept Error Rate (CER)", "start_pos": 58, "end_pos": 82, "type": "METRIC", "confidence": 0.8232860217491785}, {"text": "Frame-Slot Error Rate (FSER)", "start_pos": 153, "end_pos": 181, "type": "METRIC", "confidence": 0.9015408058961233}]}, {"text": "The horizontal axis represents the number of hypotheses provided by the statistical translator.", "labels": [], "entities": []}, {"text": "As expected, in all the cases the FSER is lower than the CER, as some errors at level of the concept sequence are not relevant for the frame conversion (for example, courtesies).", "labels": [], "entities": [{"text": "FSER", "start_pos": 34, "end_pos": 38, "type": "METRIC", "confidence": 0.9986097812652588}, {"text": "CER", "start_pos": 57, "end_pos": 60, "type": "METRIC", "confidence": 0.9828654527664185}, {"text": "frame conversion", "start_pos": 135, "end_pos": 151, "type": "TASK", "confidence": 0.7912944257259369}]}, {"text": "In the case of text input, the best results are achieved when just one or two hypotheses are provided by the translator.", "labels": [], "entities": []}, {"text": "This is because the translation model has also been learned using correct sentences, which makes the translation system more robust for this kind of input.", "labels": [], "entities": [{"text": "translation", "start_pos": 20, "end_pos": 31, "type": "TASK", "confidence": 0.9669153094291687}]}, {"text": "However, when considering speech as input, the generalization provided by the graphs obtained using a relatively large set of n-best translations leads to a better behavior.", "labels": [], "entities": []}, {"text": "This is due to the fact that the errors introduced by the recognition of the speech input increases the errors in the translation stage.", "labels": [], "entities": []}, {"text": "Thus, working with different alternatives makes it possible to recover some of the errors.", "labels": [], "entities": []}, {"text": "shows the results obtained when optimizing the FSER, and the number of hypotheses n used to build the graphs that provide the best results.", "labels": [], "entities": [{"text": "FSER", "start_pos": 47, "end_pos": 51, "type": "DATASET", "confidence": 0.4231691062450409}]}, {"text": "also show that the parameters that optimize FSER and CER may not be the same.", "labels": [], "entities": [{"text": "FSER", "start_pos": 44, "end_pos": 48, "type": "METRIC", "confidence": 0.5037848949432373}, {"text": "CER", "start_pos": 53, "end_pos": 56, "type": "METRIC", "confidence": 0.8038880228996277}]}, {"text": "This behavior is due to the different nature of both measures.", "labels": [], "entities": []}, {"text": "While CER is defined in terms of the sequence of concepts extracted by the SLU module, FSER only takes into account those segments that have relevant information.", "labels": [], "entities": [{"text": "FSER", "start_pos": 87, "end_pos": 91, "type": "METRIC", "confidence": 0.8588628768920898}]}, {"text": "It can be seen in that, for Configuration 2, when n takes the value 18, both error measures descend.", "labels": [], "entities": [{"text": "Configuration", "start_pos": 28, "end_pos": 41, "type": "TASK", "confidence": 0.9066202640533447}]}, {"text": "However, after this, the errors continue with their ascending tendency.", "labels": [], "entities": []}, {"text": "The reason for this is that with these parameters, the translations provided by the translator generate a graph of words that allows the semantic model to better recover the semantics of the sentence.", "labels": [], "entities": []}, {"text": "However, this effect is spurious, as for higher values of n the error measures present higher values.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Results obtained optimizing the FSER.", "labels": [], "entities": [{"text": "FSER", "start_pos": 42, "end_pos": 46, "type": "METRIC", "confidence": 0.5741460919380188}]}]}