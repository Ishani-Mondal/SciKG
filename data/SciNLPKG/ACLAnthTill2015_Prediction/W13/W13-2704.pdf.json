{"title": [], "abstractContent": [{"text": "Cross-period (diachronic) thesaurus construction aims to enable potential users to search for modern terms and obtain semantically related terms from earlier periods in history.", "labels": [], "entities": [{"text": "Cross-period (diachronic) thesaurus construction", "start_pos": 0, "end_pos": 48, "type": "TASK", "confidence": 0.6400142461061478}]}, {"text": "This is a complex task not previously addressed computationally.", "labels": [], "entities": []}, {"text": "In this paper we introduce a semi-automatic iterative Query Expansion (QE) scheme for supporting cross-period thesaurus construction.", "labels": [], "entities": [{"text": "cross-period thesaurus construction", "start_pos": 97, "end_pos": 132, "type": "TASK", "confidence": 0.7336631417274475}]}, {"text": "We demonstrate the empirical benefit of our scheme fora Jewish cross-period thesaurus and evaluate its impact on recall and on the effectiveness of lexicographer manual effort.", "labels": [], "entities": [{"text": "recall", "start_pos": 113, "end_pos": 119, "type": "METRIC", "confidence": 0.9951844811439514}]}], "introductionContent": [], "datasetContent": [{"text": "We assessed our iterative algorithmic scheme by evaluating its ability to increase the thesaurus coverage, compared to a similar non-iterative cooccurrence-based thesaurus construction method.", "labels": [], "entities": []}, {"text": "In our experiments, we assumed that it is worth spending the lexicographer's time as long as it is productive, thus, all the manual annotations were based on the lexicographer efforts to increase recall until reaching the stopping criterion.", "labels": [], "entities": [{"text": "recall", "start_pos": 196, "end_pos": 202, "type": "METRIC", "confidence": 0.9980745315551758}]}, {"text": "We used algorithmic scheme as our non-iterative baseline (Baseline).", "labels": [], "entities": []}, {"text": "For comparison, we ran our iterative scheme, calculated the average number of judgments per target term (88) and set the baseline stopping criterion to be the same number of judgements per target.", "labels": [], "entities": []}, {"text": "Thus, we ensured that the number of judgements for our iterative algorithm and for the baseline is equal, and thus coverage increase is due to a better use of lexicographer's effort.", "labels": [], "entities": [{"text": "coverage", "start_pos": 115, "end_pos": 123, "type": "METRIC", "confidence": 0.9964526891708374}]}, {"text": "For completeness, we present the results of the non-iterative algorithm with the stopping criterion of the iterative algorithm, when reaching k (k=10 was empirically: Results Comparison selected in our case) sequential irrelevant candidates (First-iteration).", "labels": [], "entities": []}, {"text": "To evaluate our scheme's performance, we used several measures: total number of ancient related terms extracted (RT), relative recall (R) and productivity (Pro).", "labels": [], "entities": [{"text": "total number of ancient related terms extracted (RT)", "start_pos": 64, "end_pos": 116, "type": "METRIC", "confidence": 0.8927617490291595}, {"text": "recall (R)", "start_pos": 127, "end_pos": 137, "type": "METRIC", "confidence": 0.9343433082103729}, {"text": "productivity (Pro)", "start_pos": 142, "end_pos": 160, "type": "METRIC", "confidence": 0.8595340102910995}]}, {"text": "Since we do not have any predefined thesaurus, our micro-averaged relativerecall considered the number of ancient related terms from the output of both methods (baseline and iterative) as the full set of related terms.", "labels": [], "entities": []}, {"text": "Productivity was measured by dividing the total number of ancient related terms extracted (RT) by the total number of the judgments performed for the method (J).", "labels": [], "entities": []}, {"text": "compares the performance of our semiautomatic iterative scheme with that of the baseline over a test set of 30 modern target terms.", "labels": [], "entities": []}, {"text": "Our iterative scheme increases the average number of extracted related terms from 2.1 to 5, i.e., increasing recall by 240%.", "labels": [], "entities": [{"text": "recall", "start_pos": 109, "end_pos": 115, "type": "METRIC", "confidence": 0.9991733431816101}]}, {"text": "The relative recall of the firstiteration (0.31) is included in the relative recall of both the baseline and our iterative method.", "labels": [], "entities": [{"text": "recall", "start_pos": 13, "end_pos": 19, "type": "METRIC", "confidence": 0.9236581325531006}, {"text": "recall", "start_pos": 77, "end_pos": 83, "type": "METRIC", "confidence": 0.9286804795265198}]}, {"text": "Iterating over the first iteration increases recall by 300% (from 50 to 151 terms), while adding more judgements to the non-iterative method increases recall only by 26% (to 63 terms).", "labels": [], "entities": [{"text": "recall", "start_pos": 45, "end_pos": 51, "type": "METRIC", "confidence": 0.9989902377128601}, {"text": "recall", "start_pos": 151, "end_pos": 157, "type": "METRIC", "confidence": 0.9989191293716431}]}, {"text": "The productivity of the iterative process is higher even than the productivity of the first iteration, showing that the iterative process optimizes the lexicographer's manual effort.", "labels": [], "entities": []}, {"text": "shows examples of thesaurus target terms and their ancient related terms, which were added by our iterative scheme 5 . Since the related terms are ancient Halachic terms, we explain them rather than translate them to English.", "labels": [], "entities": []}], "tableCaptions": []}