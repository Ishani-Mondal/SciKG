{"title": [], "abstractContent": [{"text": "Obtaining gold standard data for word sense disambiguation is important but costly.", "labels": [], "entities": [{"text": "word sense disambiguation", "start_pos": 33, "end_pos": 58, "type": "TASK", "confidence": 0.7738661567370096}]}, {"text": "We show how it can be done using a \"Game with a Purpose\" (GWAP) called Wordrobe.", "labels": [], "entities": [{"text": "Wordrobe", "start_pos": 71, "end_pos": 79, "type": "DATASET", "confidence": 0.9533302187919617}]}, {"text": "This game consists of a large set of multiple-choice questions on word senses generated from the Groningen Meaning Bank.", "labels": [], "entities": [{"text": "Groningen Meaning Bank", "start_pos": 97, "end_pos": 119, "type": "DATASET", "confidence": 0.7732452948888143}]}, {"text": "The players need to answer these questions, scoring points depending on the agreement with fellow players.", "labels": [], "entities": []}, {"text": "The working assumption is that the right sense fora word can be determined by the answers given by the players.", "labels": [], "entities": []}, {"text": "To evaluate our method, we gold-standard tagged a portion of the data that was also used in the GWAP.", "labels": [], "entities": [{"text": "GWAP", "start_pos": 96, "end_pos": 100, "type": "DATASET", "confidence": 0.9164792895317078}]}, {"text": "A comparison yielded promising results, ranging from a precision of 0.88 and recall of 0.83 for relative majority agreement, to a precision of 0.98 and recall of 0.35 for questions that were answered unanimously.", "labels": [], "entities": [{"text": "precision", "start_pos": 55, "end_pos": 64, "type": "METRIC", "confidence": 0.999128520488739}, {"text": "recall", "start_pos": 77, "end_pos": 83, "type": "METRIC", "confidence": 0.9995133876800537}, {"text": "precision", "start_pos": 130, "end_pos": 139, "type": "METRIC", "confidence": 0.9985236525535583}, {"text": "recall", "start_pos": 152, "end_pos": 158, "type": "METRIC", "confidence": 0.9992222785949707}]}], "introductionContent": [{"text": "One of the core aspects of semantic annotation is determining the correct sense of each content word from a set of possible senses.", "labels": [], "entities": []}, {"text": "In NLP-related research, many models for disambiguating word senses have been proposed.", "labels": [], "entities": []}, {"text": "Such models have been evaluated through various public evaluation campaigns, most notably SenseEval (now called SemEval), an international word sense disambiguation competition held already six times since its start in 1998).", "labels": [], "entities": [{"text": "word sense disambiguation competition", "start_pos": 139, "end_pos": 176, "type": "TASK", "confidence": 0.7079170271754265}]}, {"text": "All disambiguation models rely on gold standard data from human annotators, but this data is timeconsuming and expensive to obtain.", "labels": [], "entities": []}, {"text": "In the context of constructing the Groningen Meaning Bank (GMB,), a large semantically annotated corpus, we address this problem by making use of crowdsourcing.", "labels": [], "entities": [{"text": "Groningen Meaning Bank (GMB", "start_pos": 35, "end_pos": 62, "type": "DATASET", "confidence": 0.7759225964546204}]}, {"text": "The idea of crowdsourcing is that some tasks that are difficult to solve for computers but easy for humans maybe outsourced to a number of people across the globe.", "labels": [], "entities": []}, {"text": "One of the prime crowdsourcing platforms is Amazon's Mechanical Turk, where workers get paid small amounts to complete small tasks.", "labels": [], "entities": []}, {"text": "Mechanical Turk has already been successfully applied for the purpose of word sense disambiguation and clustering (see, e.g.,).", "labels": [], "entities": [{"text": "word sense disambiguation", "start_pos": 73, "end_pos": 98, "type": "TASK", "confidence": 0.7171331445376078}]}, {"text": "Another crowdsourcing technique, \"Game with a Purpose\" (GWAP), rewards contributors with entertainment rather than money.", "labels": [], "entities": []}, {"text": "GWAPs challenge players to score high on specifically designed tasks, thereby contributing their knowledge.", "labels": [], "entities": []}, {"text": "GWAPs were successfully pioneered in NLP by initiatives such as 'Phrase Detectives' for anaphora resolution) and 'JeuxDeMots' for term relations).", "labels": [], "entities": [{"text": "NLP", "start_pos": 37, "end_pos": 40, "type": "TASK", "confidence": 0.9285038709640503}, {"text": "anaphora resolution", "start_pos": 88, "end_pos": 107, "type": "TASK", "confidence": 0.7674364149570465}]}, {"text": "We have developed an online GWAP platform for semantic annotation, called Wordrobe.", "labels": [], "entities": [{"text": "Wordrobe", "start_pos": 74, "end_pos": 82, "type": "DATASET", "confidence": 0.960336446762085}]}, {"text": "In this paper we present the design and the first results of using Wordrobe for the task of word sense disambiguation.", "labels": [], "entities": [{"text": "Wordrobe", "start_pos": 67, "end_pos": 75, "type": "DATASET", "confidence": 0.9604809284210205}, {"text": "word sense disambiguation", "start_pos": 92, "end_pos": 117, "type": "TASK", "confidence": 0.7640081246693929}]}], "datasetContent": [{"text": "We evaluate the annotations obtained from Wordrobe by comparing the data of the test set (115 questions) to the gold standard.", "labels": [], "entities": [{"text": "Wordrobe", "start_pos": 42, "end_pos": 50, "type": "DATASET", "confidence": 0.9746454954147339}]}, {"text": "We used each of the agreement measures described above to select the answers with a high enough majority, and calculated precision (the number of correct answers with respect to the total number of selected answers), recall (the number of correct answers with respect to the total number of questions), and the corresponding F-score.", "labels": [], "entities": [{"text": "precision", "start_pos": 121, "end_pos": 130, "type": "METRIC", "confidence": 0.9995710253715515}, {"text": "recall", "start_pos": 217, "end_pos": 223, "type": "METRIC", "confidence": 0.9995262622833252}, {"text": "F-score", "start_pos": 325, "end_pos": 332, "type": "METRIC", "confidence": 0.9984651803970337}]}, {"text": "The results are shown in.", "labels": [], "entities": []}, {"text": "As expected, the highest recall is obtained using the relative majority measure since this measure is the least conservative in accepting a majority choice.", "labels": [], "entities": [{"text": "recall", "start_pos": 25, "end_pos": 31, "type": "METRIC", "confidence": 0.9995619654655457}]}, {"text": "As the threshold for accepting a choice is set higher, recall drops and precision rises, up to a very high precision for the unanimity measure, but with a significant loss in recall.", "labels": [], "entities": [{"text": "recall", "start_pos": 55, "end_pos": 61, "type": "METRIC", "confidence": 0.9992616772651672}, {"text": "precision", "start_pos": 72, "end_pos": 81, "type": "METRIC", "confidence": 0.9996973276138306}, {"text": "precision", "start_pos": 107, "end_pos": 116, "type": "METRIC", "confidence": 0.9963976740837097}, {"text": "recall", "start_pos": 175, "end_pos": 181, "type": "METRIC", "confidence": 0.998940646648407}]}, {"text": "The measure based on Pearson's chi-square testis similar in being conservative; having only six answers per question in the test set, only the questions that are very skewed towards one choice give a significant result of the chi-square test.", "labels": [], "entities": []}, {"text": "As described above, each answer is associated with abet between 10% and 100% of the points available fora question, which players can adjust based on how certain they are about their answer.", "labels": [], "entities": []}, {"text": "The distribution of bets overall answers shows two significant peaks for these extremes: in 66% of the cases the maximum bet was chosen, and the default minimum bet was chosen in 12% of the cases.", "labels": [], "entities": []}, {"text": "The main motivation for inserting the betting function was to be able to identify questions that were more difficult for players by looking for low bets.", "labels": [], "entities": []}, {"text": "We tested the correlation between the average bet per question and the relative size of the majority (indicating agreement between players) overall questions using Pearson's product-moment correlation and found a small but significant positive effect (r = 0.150, p < 0.01).", "labels": [], "entities": []}, {"text": "We expect that this effect will increase if more data is available.", "labels": [], "entities": []}, {"text": "In order to test whether questions with high average bets were easier, we repeated the evaluation, including only questions with a high average bet: b \u2265 80% (see).", "labels": [], "entities": []}, {"text": "Recall is reduced strongly, as one would expect, but we do observe an increase in precision for all measures except unanimity.", "labels": [], "entities": [{"text": "Recall", "start_pos": 0, "end_pos": 6, "type": "METRIC", "confidence": 0.9957347512245178}, {"text": "precision", "start_pos": 82, "end_pos": 91, "type": "METRIC", "confidence": 0.9996815919876099}]}, {"text": "This higher precision suggests that indeed the results of the questions for which players on average place a high bet are more similar to the gold standard.", "labels": [], "entities": [{"text": "precision", "start_pos": 12, "end_pos": 21, "type": "METRIC", "confidence": 0.9995375871658325}]}, {"text": "However, we will need more data to confirm this point.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Precision and recall based on different agreement measures", "labels": [], "entities": [{"text": "Precision", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9252988696098328}, {"text": "recall", "start_pos": 24, "end_pos": 30, "type": "METRIC", "confidence": 0.9993957281112671}]}]}