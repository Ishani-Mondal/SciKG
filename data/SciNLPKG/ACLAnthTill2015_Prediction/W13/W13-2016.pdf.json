{"title": [{"text": "UZH in the BioNLP 2013 GENIA Shared Task", "labels": [], "entities": [{"text": "BioNLP 2013 GENIA Shared Task", "start_pos": 11, "end_pos": 40, "type": "DATASET", "confidence": 0.7279639840126038}]}], "abstractContent": [{"text": "We describe a biological event detection method implemented for the Genia Event Extraction task of BioNLP 2013.", "labels": [], "entities": [{"text": "biological event detection", "start_pos": 14, "end_pos": 40, "type": "TASK", "confidence": 0.6656156579653422}, {"text": "Genia Event Extraction task", "start_pos": 68, "end_pos": 95, "type": "TASK", "confidence": 0.8159383237361908}, {"text": "BioNLP 2013", "start_pos": 99, "end_pos": 110, "type": "DATASET", "confidence": 0.7876021564006805}]}, {"text": "The method relies on syntactic dependency relations provided by a general NLP pipeline, supported by statistics derived from Maximum Entropy models for candidate trigger words, for potential arguments , and for argument frames.", "labels": [], "entities": []}], "introductionContent": [{"text": "The OntoGene team at the University of Zurich has developed text mining applications based on a combination of deep-linguistic analysis and machine learning techniques (.", "labels": [], "entities": [{"text": "text mining", "start_pos": 60, "end_pos": 71, "type": "TASK", "confidence": 0.811172366142273}]}, {"text": "Our approaches have proven competitive in several shared task evaluations (.", "labels": [], "entities": []}, {"text": "Additionally, we have developed advanced systems for the curation of the biomedical literature (.", "labels": [], "entities": []}, {"text": "Our participation in the Genia Event Extraction task of) was motivated by the desire of testing our technologies on a more linguistically motivated task.", "labels": [], "entities": [{"text": "Genia Event Extraction task", "start_pos": 25, "end_pos": 52, "type": "TASK", "confidence": 0.8812990188598633}]}, {"text": "In the course of our participation we revised several modules of our document processing pipeline, however we did not have sufficient resources to completely revise the final module which generates the event structures, and we still relied on a module which we had developed for our previous participation to the BioNLP shared task.", "labels": [], "entities": [{"text": "BioNLP shared task", "start_pos": 313, "end_pos": 331, "type": "TASK", "confidence": 0.5480991005897522}]}, {"text": "The final submission was composed by our standard preprocessing module (described briefly in section 2) and novel probability models (section 3), combined within the old event generator (section 4).", "labels": [], "entities": []}], "datasetContent": [{"text": "In our analysis of errors, we noticed that frames with more than one argument are created extremely rarely.", "labels": [], "entities": []}, {"text": "The problem is that frames with several arguments are rarer because the context often does not offer the possibility to attach several arguments.", "labels": [], "entities": []}, {"text": "Therefore, we consistently undergenerated with p args mean as outlined above.: Results on the test data, measured using \"strict equality\".", "labels": [], "entities": []}, {"text": "We have added a number of heuristics to boost multi-argument frames.", "labels": [], "entities": []}, {"text": "Multiplying the probability of a frame by its cubed length (giving twoargument slots 9 times higher probability), and giving Cause-slots 50% higher scores globally led to best results.", "labels": [], "entities": []}, {"text": "We mainly trained and evaluated using the \"strict equality\" evaluation criteria as our reference.", "labels": [], "entities": []}, {"text": "The results on the development data are shown in table 1.", "labels": [], "entities": []}, {"text": "With more relaxed equality definitions, the results were always a few percentage points better.", "labels": [], "entities": []}, {"text": "Our results in the official test run are shown in table 2.", "labels": [], "entities": []}, {"text": "In sum, our submitted system has good performance for simple events, bad performance for Binding events, and a bias towards precision due to a syntactic-based filtering step.", "labels": [], "entities": [{"text": "precision", "start_pos": 124, "end_pos": 133, "type": "METRIC", "confidence": 0.9989408850669861}]}], "tableCaptions": [{"text": " Table 1: Results on the development set, measured using \"strict equality\".", "labels": [], "entities": []}, {"text": " Table 2: Results on the test data, measured using \"strict equality\".", "labels": [], "entities": []}]}