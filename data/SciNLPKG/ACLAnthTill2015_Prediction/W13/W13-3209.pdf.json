{"title": [{"text": "\"Not not bad\" is not \"bad\": A distributional account of negation", "labels": [], "entities": [{"text": "negation", "start_pos": 56, "end_pos": 64, "type": "TASK", "confidence": 0.8934215903282166}]}], "abstractContent": [{"text": "With the increasing empirical success of distributional models of compositional semantics , it is timely to consider the types of textual logic that such models are capable of capturing.", "labels": [], "entities": []}, {"text": "In this paper, we address shortcomings in the ability of current models to capture logical operations such as negation.", "labels": [], "entities": []}, {"text": "As a solution we propose a tripartite formulation fora continuous vector space representation of semantics and subsequently use this representation to develop a formal compositional notion of negation within such models.", "labels": [], "entities": []}], "introductionContent": [{"text": "Distributional models of semantics characterize the meanings of words as a function of the words they co-occur with.", "labels": [], "entities": []}, {"text": "These models, mathematically instantiated as sets of vectors in high dimensional vector spaces, have been applied to tasks such as thesaurus extraction), word-sense discrimination, automated essay marking, and soon.", "labels": [], "entities": [{"text": "thesaurus extraction", "start_pos": 131, "end_pos": 151, "type": "TASK", "confidence": 0.7298812419176102}, {"text": "word-sense discrimination", "start_pos": 154, "end_pos": 179, "type": "TASK", "confidence": 0.8186227381229401}, {"text": "automated essay marking", "start_pos": 181, "end_pos": 204, "type": "TASK", "confidence": 0.6229185064633688}]}, {"text": "During the past few years, research has shifted from using distributional methods for modelling the semantics of words to using them for modelling the semantics of larger linguistic units such as phrases or entire sentences.", "labels": [], "entities": []}, {"text": "This move from word to sentence has yielded models applied to tasks such as paraphrase detection, sentiment analysis (, and semantic relation classification (ibid.).", "labels": [], "entities": [{"text": "paraphrase detection", "start_pos": 76, "end_pos": 96, "type": "TASK", "confidence": 0.9130734801292419}, {"text": "sentiment analysis", "start_pos": 98, "end_pos": 116, "type": "TASK", "confidence": 0.9665148556232452}, {"text": "semantic relation classification", "start_pos": 124, "end_pos": 156, "type": "TASK", "confidence": 0.7173956632614136}]}, {"text": "Most efforts approach the problem of modelling phrase meaning through vector composition using linear algebraic vector operations (, matrix or tensor-based approaches (, or through the use of recursive auto-encoding or neural-networks ().", "labels": [], "entities": []}, {"text": "On the non-compositional front, keep word vectors separate, using syntactic information from sentences to disambiguate words in context; likewise Turney (2012) treats the compositional aspect of phrases and sentences as a matter of similarity measure composition rather than vector composition.", "labels": [], "entities": []}, {"text": "These compositional distributional approaches often portray themselves as attempts to reconcile the empirical aspects of distributional semantics with the structured aspects of formal semantics.", "labels": [], "entities": []}, {"text": "However, they in fact only principally co-opt the syntax-sensitivity of formal semantics, while mostly eschewing the logical aspects.", "labels": [], "entities": []}, {"text": "Expressing the effect of logical operations in high dimensional distributional semantic models is a very different task than in boolean logic.", "labels": [], "entities": []}, {"text": "For example, whereas predicates such as 'red' are seen in predicate calculi as functions mapping elements of some set M red to (and all other domain elements to \u22a5), in compositional distributional models we give the meaning of 'red' a vector-like representation, and devise some combination operation with noun representations to obtain the representation for an adjective-noun pair.", "labels": [], "entities": []}, {"text": "Under the logical view, negation of a predicate therefore yields anew truth-function mapping elements of the complement of M red to (and all other domain elements to \u22a5), but the effect of negation and other logical operations in distributional models is not so sharp: we expect the representation for \"not red\" to remain close to other objects of the same domain of discourse (i.e. other colours) while being sufficiently different from the representation of 'red' in some manner.", "labels": [], "entities": []}, {"text": "Exactly how textual logic would best be represented in a continuous vector space model remains an open problem.", "labels": [], "entities": []}, {"text": "In this paper we propose one possible formulation fora continuous vector space based representation of semantics.", "labels": [], "entities": []}, {"text": "We use this formulation as the basis for providing an account of logical operations for distributional models.", "labels": [], "entities": []}, {"text": "In particular, we focus on the case of negation and how it might work in higher dimensional distributional models.", "labels": [], "entities": [{"text": "negation", "start_pos": 39, "end_pos": 47, "type": "TASK", "confidence": 0.9752514958381653}]}, {"text": "Our formulation separates domain, value and functional representation in such away as to allow negation to be handled naturally.", "labels": [], "entities": []}, {"text": "We explain the linguistic and model-related impacts of this mode of representation and discuss how this approach could be generalised to other semantic functions.", "labels": [], "entities": []}, {"text": "In Section 2, we provide an overview of work relating to that presented in this paper, covering the integration of logical elements in distributional models, and the integration of distributional elements in logical models.", "labels": [], "entities": []}, {"text": "In Section 3, we introduce and argue fora tripartite representation in distributional semantics, and discuss the issues relating to providing a linguistically sensible notion of negation for such representations.", "labels": [], "entities": []}, {"text": "In Section 4, we present matrix-vector models similar to that of as a good candidate for expressing this tripartite representation.", "labels": [], "entities": []}, {"text": "We argue for the elimination of non-linearities from such models, and thus show that negation cannot adequately be captured.", "labels": [], "entities": []}, {"text": "In Section 5, we present a short analysis of the limitation of these matrixvector models with regard to the task of modelling non-boolean logical operations, and present an improved model bypassing these limitations in Section 6.", "labels": [], "entities": []}, {"text": "Finally, in Section 7, we conclude by suggesting future work which will extend and build upon the theoretical foundations presented in this paper.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": []}