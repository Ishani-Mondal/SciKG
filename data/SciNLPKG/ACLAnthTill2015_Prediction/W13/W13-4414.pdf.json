{"title": [{"text": "A Study of Language Modeling for Chinese Spelling Check", "labels": [], "entities": [{"text": "Language Modeling", "start_pos": 11, "end_pos": 28, "type": "TASK", "confidence": 0.7499321103096008}, {"text": "Chinese Spelling", "start_pos": 33, "end_pos": 49, "type": "TASK", "confidence": 0.5824232697486877}]}], "abstractContent": [{"text": "Chinese spelling check (CSC) is still an open problem today.", "labels": [], "entities": [{"text": "Chinese spelling check (CSC)", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.7744529147942861}]}, {"text": "To the best of our knowledge, language modeling is widely used in CSC because of its simplicity and fair predictive power, but most systems only use the conventional n-gram models.", "labels": [], "entities": [{"text": "language modeling", "start_pos": 30, "end_pos": 47, "type": "TASK", "confidence": 0.7330007255077362}]}, {"text": "Our work in this paper continues this general line of research by further exploring different ways to glean extra semantic clues and Web resources to enhance the CSC performance in an unsupervised fashion.", "labels": [], "entities": []}, {"text": "Empirical results demonstrate the utility of our CSC system.", "labels": [], "entities": []}], "introductionContent": [{"text": "Chinese is atonal syllabic and character (symbol) language, in which each character is pronounced as atonal syllable.", "labels": [], "entities": []}, {"text": "A Chinese \"word\" usually comprises two or more characters.", "labels": [], "entities": []}, {"text": "The difficulty of Chinese processing is that many Chinese characters have similar shapes or similar (or same) pronunciations.", "labels": [], "entities": []}, {"text": "Some characters are even similar in both shape and pronunciation).", "labels": [], "entities": []}, {"text": "However, the meanings of these characters (or words composed of the characters) maybe widely divergent.", "labels": [], "entities": []}, {"text": "Due to this reason, all the students in elementary school in Taiwan or the foreign Chinese learners need to practice to identify and correct \"erroneous words\" in a Chinese sentence, which is called the Incorrect Character Correction (ICC) test.", "labels": [], "entities": [{"text": "Incorrect Character Correction (ICC) test", "start_pos": 202, "end_pos": 243, "type": "METRIC", "confidence": 0.6486070709569114}]}, {"text": "In fact, the ICC testis not a simple task even for some adult native speakers in Taiwan.", "labels": [], "entities": [{"text": "ICC testis", "start_pos": 13, "end_pos": 23, "type": "DATASET", "confidence": 0.681549996137619}]}, {"text": "Since most Chinese characters have other characters similar to them in either shape or pronunciation, an intuitive idea for CSC is to construct a confusion set for each character.", "labels": [], "entities": []}, {"text": "Currently, many CSC systems use the confusion sets () to recursively substitute characters and find an optimal result to detect and correct erroneous words.", "labels": [], "entities": []}, {"text": "Moreover, many researches have been focusing on automatically constructing the confusion sets from various knowledge sources, such as the Cangjie code (), psycholinguistic experimental results (), and templates generated from a large corpus . Language modeling can be used to quantify the quality of a given word string, and most previous researches have adopted it as a method to predict which word might be a correct word to replace the possible erroneous word.", "labels": [], "entities": [{"text": "Cangjie code", "start_pos": 138, "end_pos": 150, "type": "DATASET", "confidence": 0.954486072063446}]}, {"text": "Although language modeling has been widely used in CSC, most researches only use the conventional n-gram models.", "labels": [], "entities": [{"text": "language modeling", "start_pos": 9, "end_pos": 26, "type": "TASK", "confidence": 0.7087660878896713}]}, {"text": "To the best of our knowledge, the n-gram language models, aiming at capturing the local contextual information or the lexical regularity of a language, are inevitably faced with two fundamental problems.", "labels": [], "entities": []}, {"text": "On one hand, it is brittle across domains, and the performance of the model is sensitive to changes in the genre or topic of the text on which it is trained.", "labels": [], "entities": []}, {"text": "On the other hand, it fails to capture the information (either semantic or syntactic information) conveyed beyond the n-1 immediately preceding words.", "labels": [], "entities": []}, {"text": "In view of these problems, this paper focuses on exploring the long-span semantic information for language modeling for CSC.", "labels": [], "entities": [{"text": "language modeling", "start_pos": 98, "end_pos": 115, "type": "TASK", "confidence": 0.71980419754982}]}, {"text": "Moreover, we make a step forward to incorporate a search engine to provide extra information from the Web resources to make a more robust system.", "labels": [], "entities": []}, {"text": "The rest of this paper is organized as follows.", "labels": [], "entities": []}, {"text": "In Section 2, we briefly review the n-gram and topic language models.", "labels": [], "entities": []}, {"text": "Section 3 details our proposed CSC system.", "labels": [], "entities": []}, {"text": "A series of experiments are presented in Section 4.", "labels": [], "entities": []}, {"text": "Finally, conclusions and future work are given in Section 5.", "labels": [], "entities": []}], "datasetContent": [{"text": "The experiments include two sub-tasks: error detection and error correction.", "labels": [], "entities": [{"text": "error detection", "start_pos": 39, "end_pos": 54, "type": "TASK", "confidence": 0.7256312966346741}, {"text": "error correction", "start_pos": 59, "end_pos": 75, "type": "TASK", "confidence": 0.7774871289730072}]}, {"text": "All the experimental materials are collected from students' written essays.", "labels": [], "entities": []}, {"text": "The first subtask focuses on the evaluation of error detection.", "labels": [], "entities": [{"text": "evaluation of error detection", "start_pos": 33, "end_pos": 62, "type": "TASK", "confidence": 0.6478877067565918}]}, {"text": "The input word string might consist of no error to evaluate the false-alarm rate of a system.", "labels": [], "entities": []}, {"text": "The evaluation metrics include the detection accuracy, detection F-score, error location F-score, and false-alarm rate.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 45, "end_pos": 53, "type": "METRIC", "confidence": 0.8553653359413147}, {"text": "detection F-score", "start_pos": 55, "end_pos": 72, "type": "METRIC", "confidence": 0.814751923084259}, {"text": "error location F-score", "start_pos": 74, "end_pos": 96, "type": "METRIC", "confidence": 0.90743088722229}]}, {"text": "As can be seen from the left part of, the tri-gram language model (denoted as \"Tri-gram\") can achieve a certain level of performance.", "labels": [], "entities": []}, {"text": "Incorporating the suggestions from a search engine (denoted as \"Tri-gram+Search Engine\") in the CSC system yields significant improvements over Tri-gram in all evaluation metrics.", "labels": [], "entities": []}, {"text": "Further incorporating topic modeling (denoted as \"Tri-gram+Search Engine+PLSA\") can slightly improve the detection Fscore and error location F-score.", "labels": [], "entities": [{"text": "Fscore", "start_pos": 115, "end_pos": 121, "type": "METRIC", "confidence": 0.8347439169883728}, {"text": "error location F-score", "start_pos": 126, "end_pos": 148, "type": "METRIC", "confidence": 0.9004683494567871}]}, {"text": "The results demonstrate that the Web information is an indispensable reference for error detection, and the topic models can further improve the precision and recall rate without increasing the false alarm rate.", "labels": [], "entities": [{"text": "error detection", "start_pos": 83, "end_pos": 98, "type": "TASK", "confidence": 0.7061142474412918}, {"text": "precision", "start_pos": 145, "end_pos": 154, "type": "METRIC", "confidence": 0.9995482563972473}, {"text": "recall rate", "start_pos": 159, "end_pos": 170, "type": "METRIC", "confidence": 0.9846562445163727}]}, {"text": "The second sub-task focuses on the evaluation of error correction.", "labels": [], "entities": [{"text": "evaluation of error correction", "start_pos": 35, "end_pos": 65, "type": "TASK", "confidence": 0.7370139211416245}]}, {"text": "Each sentence includes at least one error.", "labels": [], "entities": []}, {"text": "The evaluation metrics are the location accuracy, correction accuracy, and correction precision.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 40, "end_pos": 48, "type": "METRIC", "confidence": 0.8287266492843628}, {"text": "correction accuracy", "start_pos": 50, "end_pos": 69, "type": "METRIC", "confidence": 0.7676635682582855}, {"text": "correction precision", "start_pos": 75, "end_pos": 95, "type": "METRIC", "confidence": 0.8010903894901276}]}, {"text": "The experimental results are listed in the right part of.", "labels": [], "entities": []}, {"text": "The flowchart of the CSC system.", "labels": [], "entities": []}, {"text": "surprise, Web information and the PLSA topic model cannot complement the conventional tri-gram model to achieve better performance.", "labels": [], "entities": []}, {"text": "The reasons could be twofold.", "labels": [], "entities": []}, {"text": "First, we do not have a sufficient set of development documents to select a reasonable interpolation weight between the tri-gram model and the topic model.", "labels": [], "entities": []}, {"text": "Second, the confusion sets should be further modified by some unsupervised or supervised methods to separate the wheat from the chaff.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2. The flowchart of the CSC system.", "labels": [], "entities": []}]}