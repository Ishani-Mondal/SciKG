{"title": [], "abstractContent": [{"text": "Determining the stance expressed by an author from a post written fora two-sided debate in an online debate forum is a relatively new problem in opinion mining.", "labels": [], "entities": [{"text": "Determining the stance expressed by an author from a post written fora two-sided debate in an online debate forum", "start_pos": 0, "end_pos": 113, "type": "TASK", "confidence": 0.496943988298115}, {"text": "opinion mining", "start_pos": 145, "end_pos": 159, "type": "TASK", "confidence": 0.8148079812526703}]}, {"text": "We extend a state-of-the-art learning-based approach to debate stance classification by (1) inducing lexico-syntactic patterns based on syntactic dependencies and semantic frames that aim to capture the meaning of a sentence and provide a generalized representation of it; and (2) improving the classification of a test post via a novel way of exploiting the information in other test posts with the same stance.", "labels": [], "entities": [{"text": "debate stance classification", "start_pos": 56, "end_pos": 84, "type": "TASK", "confidence": 0.7360362609227499}]}, {"text": "Empirical results on four datasets demonstrate the effectiveness of our extensions.", "labels": [], "entities": []}], "introductionContent": [{"text": "Given a post written fora two-sided topic in an online debate forum (e.g., \"Should abortion be allowed?\"), the task of debate stance classification involves determining which of the two sides (i.e., for or against) its author is taking.", "labels": [], "entities": [{"text": "debate stance classification", "start_pos": 119, "end_pos": 147, "type": "TASK", "confidence": 0.6703343192736307}]}, {"text": "For example, a stance classification system should determine that the author of the following post is anti-abortion.", "labels": [], "entities": [{"text": "stance classification", "start_pos": 15, "end_pos": 36, "type": "TASK", "confidence": 0.929190993309021}]}, {"text": "Post 1: Abortion has been legal for decades and no one seems to have a problem with it.", "labels": [], "entities": [{"text": "Abortion", "start_pos": 8, "end_pos": 16, "type": "TASK", "confidence": 0.9771484136581421}]}, {"text": "There are millions of people in the world who would love to have children but can't.", "labels": [], "entities": []}, {"text": "Previous approaches to debate stance classification have focused on three debate settings, namely congressional floor debates (;), companyinternal discussions, and online social, political, and ideological debates in public forums (.", "labels": [], "entities": [{"text": "debate stance classification", "start_pos": 23, "end_pos": 51, "type": "TASK", "confidence": 0.762521763642629}]}, {"text": "As point out, debates in public forums differ from congressional debates and company-internal discussions in terms of language use.", "labels": [], "entities": []}, {"text": "Specifically, online debaters use colorful and emotional language to express their points, which may involve sarcasm, insults, and questioning another debater's assumptions and evidence.", "labels": [], "entities": []}, {"text": "These properties can potentially make stance classification of online debates more challenging than that of the other two types of debates.", "labels": [], "entities": [{"text": "stance classification", "start_pos": 38, "end_pos": 59, "type": "TASK", "confidence": 0.9028123915195465}]}, {"text": "Our goal in this paper is to improve the state of the art instance classification of online debates, focusing in particular on ideological debates.", "labels": [], "entities": [{"text": "instance classification", "start_pos": 58, "end_pos": 81, "type": "TASK", "confidence": 0.7397260963916779}]}, {"text": "Specifically, we present two extensions, one linguistic and the other extra-linguistic, to the state-of-the-art supervised learning approach to this task proposed by.", "labels": [], "entities": []}, {"text": "In our linguistic extension, we induce patterns from each sentence in the training set using syntactic dependencies and semantic frames that aim to capture the meaning of a sentence and provide a generalized representation of it.", "labels": [], "entities": []}, {"text": "Note that while Anand et al.'s lexico-syntactic approach aims to generalize from a sentence using syntactic dependencies, we aim to generalize using semantic frames.", "labels": [], "entities": []}, {"text": "As we will see in Section 4, not only is there no guarantee that syntactic dependencies can retain or sufficiently capture the meaning of a sentence during the generalization process, it is in fact harder to generalize from syntactic dependencies than from semantic frames.", "labels": [], "entities": []}, {"text": "In our extra-linguistic extension, we improve the classification of a test post via a novel way of exploiting the information in other test posts with the same stance.", "labels": [], "entities": []}, {"text": "We evaluate our approach to stance classification of ideological debates on datasets collected for four domains from online debate forums.: Statistics of the four datasets.", "labels": [], "entities": [{"text": "stance classification of ideological debates", "start_pos": 28, "end_pos": 72, "type": "TASK", "confidence": 0.8637930631637574}]}, {"text": "The rest of the paper is organized as follows.", "labels": [], "entities": []}, {"text": "We first present our datasets in Section 2.", "labels": [], "entities": []}, {"text": "Section 3 describes our two learning-based baseline systems for stance classification.", "labels": [], "entities": [{"text": "stance classification", "start_pos": 64, "end_pos": 85, "type": "TASK", "confidence": 0.9257021844387054}]}, {"text": "Sections 4 and 5 discuss our two extensions.", "labels": [], "entities": []}, {"text": "Finally, we show evaluation results in Section 6 and present conclusions in Section 7.", "labels": [], "entities": []}], "datasetContent": [{"text": "For our experiments, we collect debate posts from four popular domains, Abortion (ABO), Gay Rights (GAY), Obama (OBA), and Marijuana (MAR).", "labels": [], "entities": []}, {"text": "Each post should receive one of two domain labels, for or against, depending on whether the author of the post supports or opposes abortion, gay rights, Obama, or the legalization of marijuana.", "labels": [], "entities": []}, {"text": "To see how we obtain these domain labels, let us first describe the data collection process in more detail.", "labels": [], "entities": []}, {"text": "We collect our debate posts for the four domains from an online debate forum . In each domain, there are several two-sided debates.", "labels": [], "entities": []}, {"text": "Each debate has a subject (e.g., \"Abortion should be banned\") for which a number of posts were written by different authors.", "labels": [], "entities": []}, {"text": "Each post is manually tagged with its author's stance (i.e., yes or no) on the debate subject.", "labels": [], "entities": []}, {"text": "Since the label of each post represents the subject stance but not the domain stance, we need to automatically convert the former to the latter.", "labels": [], "entities": []}, {"text": "For example, for the subject \"Abortion should be banned\", the subject stance yes implies that the author opposes abortion, and hence the domain label for the corresponding label should be against.", "labels": [], "entities": []}, {"text": "We construct one dataset for each domain.", "labels": [], "entities": []}, {"text": "Statistics of these datasets are shown in.", "labels": [], "entities": []}, {"text": "Results are expressed in terms of accuracy obtained via 5-fold cross validation, where accuracy is the percentage of test instances correctly classified.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 34, "end_pos": 42, "type": "METRIC", "confidence": 0.9991542100906372}, {"text": "accuracy", "start_pos": 87, "end_pos": 95, "type": "METRIC", "confidence": 0.9991057515144348}]}, {"text": "Since all experiments require the use of development data for parameter tuning, we use three folds for model training, one fold for development, and one fold for testing in each fold experiment.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Statistics of the four datasets.", "labels": [], "entities": []}, {"text": " Table 3: Development set accuracies.", "labels": [], "entities": []}, {"text": " Table 4: Percentage of posts predicted correctly  by one but not both classifiers on the development  set.", "labels": [], "entities": []}, {"text": " Table 6: 5-fold cross-validation accuracies.", "labels": [], "entities": []}]}