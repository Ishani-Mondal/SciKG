{"title": [{"text": "Generating Natural Language from Linked Data: Unsupervised template extraction", "labels": [], "entities": [{"text": "Unsupervised template extraction", "start_pos": 46, "end_pos": 78, "type": "TASK", "confidence": 0.6334109703699747}]}], "abstractContent": [{"text": "We propose an architecture for generating natural language from Linked Data that automatically learns sentence templates and statistical document planning from parallel RDF datasets and text.", "labels": [], "entities": [{"text": "statistical document planning", "start_pos": 125, "end_pos": 154, "type": "TASK", "confidence": 0.6220952570438385}]}, {"text": "We have built a proof-of-concept system (LOD-DEF) trained on un-annotated text from the Simple English Wikipedia and RDF triples from DBpedia, focusing exclusively on factual, non-temporal information.", "labels": [], "entities": [{"text": "Simple English Wikipedia", "start_pos": 88, "end_pos": 112, "type": "DATASET", "confidence": 0.8576550086339315}, {"text": "DBpedia", "start_pos": 134, "end_pos": 141, "type": "DATASET", "confidence": 0.8636273741722107}]}, {"text": "The goal of the system is to generate short descriptions, equivalent to Wikipedia stubs, of entities found in Linked Datasets.", "labels": [], "entities": []}, {"text": "We have evaluated the LOD-DEF system against a simple generate-from-triples baseline and human-generated output.", "labels": [], "entities": []}, {"text": "In evaluation by humans, LOD-DEF significantly outperforms the baseline on two of three measures: non-redundancy and structure and coherence.", "labels": [], "entities": [{"text": "LOD-DEF", "start_pos": 25, "end_pos": 32, "type": "METRIC", "confidence": 0.903893768787384}]}], "introductionContent": [{"text": "In recent years, work on the Semantic Web has undergone something of a split.", "labels": [], "entities": []}, {"text": "At one end of the continuum, considerable energy has been invested into the construction of detailed domain ontologies expressed in some variant of OWL, 1 with considerable attention paid to maintaining logical consistency.", "labels": [], "entities": [{"text": "OWL, 1", "start_pos": 148, "end_pos": 154, "type": "DATASET", "confidence": 0.8821768760681152}]}, {"text": "At the other end, the so-called Linked Data framework has given rise to the publication of quite large scale datasets, with relatively little concern for ensuring consistency.", "labels": [], "entities": []}, {"text": "Although the language, namely RDF, 2 in which Linked Data is encoded can be regarded as a restricted form of first-order predicate logic, existing Linked Datasets are closer in many ways to large, distributed databases than the kind of carefully constructed knowledge base that is familiar from AI research.", "labels": [], "entities": []}, {"text": "The work that we report here takes as its starting point the following question: can Linked Data be used as the input to a Natural Language Generation (NLG) system?", "labels": [], "entities": [{"text": "Natural Language Generation (NLG)", "start_pos": 123, "end_pos": 156, "type": "TASK", "confidence": 0.7981164952119192}]}, {"text": "There are at least a couple of reasons why a positive answer would be interest.", "labels": [], "entities": []}, {"text": "First, it is still relatively hard for non-experts to browse unfamiliar Linked Data sets, and a natural language representation could potentially ameliorate this problem.", "labels": [], "entities": [{"text": "Linked Data sets", "start_pos": 72, "end_pos": 88, "type": "DATASET", "confidence": 0.766448458035787}]}, {"text": "Second, cultural heritage institutions (e.g., museums, art galleries, and libraries) are increasingly interested in publishing their data in the form of Linked Data.", "labels": [], "entities": []}, {"text": "Such institutions are typically committed to presenting information about their holdings in multiple forms, and consequently generation of natural language that utilises a single Linked Data source would be highly attractive.", "labels": [], "entities": []}, {"text": "Moreover, the very nature of Linked Data should make it easier for an NLG system to supplement institution-specific data with encyclopaedic information drawn from sources such as DBpedia.", "labels": [], "entities": [{"text": "DBpedia", "start_pos": 179, "end_pos": 186, "type": "DATASET", "confidence": 0.9575936794281006}]}, {"text": "In the light of these motivations, we propose an architecture fora trainable NLG system for Linked Data that can automatically learn sentence templates and document planning from parallel RDF data and text, with the communicative goal of describing Wikipedia-style factual descriptions of entities.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Scoring class models", "labels": [], "entities": [{"text": "Scoring", "start_pos": 10, "end_pos": 17, "type": "TASK", "confidence": 0.9703565239906311}]}, {"text": " Table 3: Differences and significance", "labels": [], "entities": [{"text": "Differences", "start_pos": 10, "end_pos": 21, "type": "TASK", "confidence": 0.9697073101997375}]}, {"text": " Table 4: Differences and significance", "labels": [], "entities": [{"text": "Differences", "start_pos": 10, "end_pos": 21, "type": "TASK", "confidence": 0.9716837406158447}]}]}