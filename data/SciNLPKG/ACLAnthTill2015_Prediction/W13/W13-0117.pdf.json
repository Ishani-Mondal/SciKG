{"title": [{"text": "Learning Corpus Patterns Using Finite State Automata", "labels": [], "entities": []}], "abstractContent": [], "introductionContent": [{"text": "Words get their meaning in context and Harris's Distributional Hypothesis has been used in computational linguistics in order to identify the relationship between co-occurring words and their senses.", "labels": [], "entities": []}, {"text": "In general, the local context contains the necessary information for word sense disambiguation.", "labels": [], "entities": [{"text": "word sense disambiguation", "start_pos": 69, "end_pos": 94, "type": "TASK", "confidence": 0.7404924035072327}]}, {"text": "However, the exact extent of the local context varies significantly.", "labels": [], "entities": []}, {"text": "To cope with this problem, previous research has shown that the regularity of word usage in natural language can be exploited).", "labels": [], "entities": []}, {"text": "Many times, words are used in phrases with a patternable structure.", "labels": [], "entities": []}, {"text": "On the basis of corpus evidence, or on the basis of the lexicographer's intuition on the normal usage) a set of patterns can be built which makes the link between context and word senses.", "labels": [], "entities": []}, {"text": "In this paper we focus on patterns centered on verbs.", "labels": [], "entities": []}, {"text": "We show that their structure is learnable and by employing a learning algorithm we are able to build a recognizer able to match such patterns against previously unseen text.", "labels": [], "entities": []}, {"text": "The CPA resource contains a set of patterns fora part of the English verbs and is built through a systematic analysis of the patterns of meaning and use for each verb.", "labels": [], "entities": [{"text": "CPA resource", "start_pos": 4, "end_pos": 16, "type": "DATASET", "confidence": 0.8902638256549835}]}, {"text": "Meaning is associated with prototypical sentences which are extracted from the BNC.", "labels": [], "entities": [{"text": "Meaning", "start_pos": 0, "end_pos": 7, "type": "TASK", "confidence": 0.6298622488975525}, {"text": "BNC", "start_pos": 79, "end_pos": 82, "type": "DATASET", "confidence": 0.9439443945884705}]}, {"text": "The slots of the patterns are specified with semantic types.", "labels": [], "entities": []}, {"text": "For example, the sentences: (ACP) ...", "labels": [], "entities": []}, {"text": "least that intense moment before the body abandons itself to passion.", "labels": [], "entities": []}, {"text": "(CCN) They danced wildly down the street, abandoning themselves to the night and the moon. are instances of the pattern: HUMAN abandon SELF {to ACTIVITY | to ATTITUDE} HUMAN, SELF etc. are semantic types.", "labels": [], "entities": [{"text": "HUMAN abandon SELF", "start_pos": 121, "end_pos": 139, "type": "METRIC", "confidence": 0.7600737611452738}, {"text": "ATTITUDE", "start_pos": 158, "end_pos": 166, "type": "METRIC", "confidence": 0.9238662123680115}, {"text": "SELF", "start_pos": 175, "end_pos": 179, "type": "METRIC", "confidence": 0.9324067234992981}]}, {"text": "The use of {} signals an optional slot of the pattern and | signals a choice.", "labels": [], "entities": []}, {"text": "A semantic type characterizes a whole class of nouns, and as such, the semantic types are organized in a shallow ontology.", "labels": [], "entities": []}, {"text": "The structure of these patterns is regular and we show that we can use the Angluin Algorithm to build a finite state automaton (FSA) which can recognize the patterns.", "labels": [], "entities": []}, {"text": "Going from the set of sentences associated to each pattern to the FSA recognizer is not trivial.", "labels": [], "entities": [{"text": "FSA recognizer", "start_pos": 66, "end_pos": 80, "type": "TASK", "confidence": 0.5939077138900757}]}, {"text": "The CPA does not contain information regarding the syntax of the patterns, or the senses of the words inside a pattern and it does not provide a resource which assigns a list of possible semantic types to the nouns of the English language.", "labels": [], "entities": []}, {"text": "In order to obtain this information, we must rely on parsing and on other two resources, WordNet(Miller) and SUMO.", "labels": [], "entities": [{"text": "parsing", "start_pos": 53, "end_pos": 60, "type": "TASK", "confidence": 0.963735044002533}, {"text": "WordNet", "start_pos": 89, "end_pos": 96, "type": "DATASET", "confidence": 0.9722474217414856}]}, {"text": "WordNet is a sense repository and SUMO is an ontology aligned to WordNet senses.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 0, "end_pos": 7, "type": "DATASET", "confidence": 0.9807702302932739}]}, {"text": "We use SUMO to associate semantic types to the nouns.", "labels": [], "entities": []}, {"text": "In the training phase, which results in the construction of the FSA recognizer, the system learns how to identify a certain pattern in a text where the words are replaced with SUMO semantic types.", "labels": [], "entities": [{"text": "FSA recognizer", "start_pos": 64, "end_pos": 78, "type": "TASK", "confidence": 0.7815990149974823}]}, {"text": "By matching a pattern, we obtain the syntactic structure of the context and the senses of the words in the context due to the SUMO alignment to WordNet.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 144, "end_pos": 151, "type": "DATASET", "confidence": 0.9645225405693054}]}, {"text": "In the experiments we ran, we tested both the accuracy in finding the correct syntactic structure and the accuracy in predicting the correct sense of the words of the matched context.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 46, "end_pos": 54, "type": "METRIC", "confidence": 0.9992271661758423}, {"text": "accuracy", "start_pos": 106, "end_pos": 114, "type": "METRIC", "confidence": 0.9991074204444885}, {"text": "predicting the correct sense of the words of the matched context", "start_pos": 118, "end_pos": 182, "type": "TASK", "confidence": 0.7639992887323553}]}, {"text": "We introduce the task of pattern matching.", "labels": [], "entities": [{"text": "pattern matching", "start_pos": 25, "end_pos": 41, "type": "TASK", "confidence": 0.855719268321991}]}, {"text": "Given an arbitrary sentence for which we know there is a unique pattern that matches it, the task consists in finding the appropriate pattern which matches the right words in the sentence.", "labels": [], "entities": []}, {"text": "We analyzed the performances obtained by a baseline against a SVM approach and against the FSA recognizer.", "labels": [], "entities": [{"text": "FSA recognizer", "start_pos": 91, "end_pos": 105, "type": "TASK", "confidence": 0.7096535861492157}]}, {"text": "The results show that both the SVM and the FSA recognizer are over the baseline by several tens of percentages.", "labels": [], "entities": [{"text": "FSA recognizer", "start_pos": 43, "end_pos": 57, "type": "TASK", "confidence": 0.6912206709384918}]}, {"text": "The FSA recognizer reaches a significantly better accuracy than the SVM approach.", "labels": [], "entities": [{"text": "FSA recognizer", "start_pos": 4, "end_pos": 18, "type": "TASK", "confidence": 0.6836259216070175}, {"text": "accuracy", "start_pos": 50, "end_pos": 58, "type": "METRIC", "confidence": 0.9985750913619995}]}, {"text": "We test the approaches both by across validation technique and by analyzing individually the performances on a list of verbs.", "labels": [], "entities": []}, {"text": "This paper is organized as follow: in the next Section we review the relevant literature on the interaction between meaning, syntax, ontology and patterns.", "labels": [], "entities": []}, {"text": "In Section 3 we describe the form of corpus patterns and the CPA resource.", "labels": [], "entities": [{"text": "CPA resource", "start_pos": 61, "end_pos": 73, "type": "DATASET", "confidence": 0.8158508837223053}]}, {"text": "in Section 4 we present the way in which the Angluin Algorithm for learning regular grammars from examples can be modified to learn to recognize the corpus patterns.", "labels": [], "entities": []}, {"text": "In Section 5 the results of the experiments we carried out are presented and discussed.", "labels": [], "entities": []}, {"text": "In the last section we present the conclusion and further research.", "labels": [], "entities": []}], "datasetContent": [{"text": "We ran several experiments in order to evaluate the performances of pattern recognition via regular grammars.", "labels": [], "entities": [{"text": "pattern recognition", "start_pos": 68, "end_pos": 87, "type": "TASK", "confidence": 0.7647185027599335}]}, {"text": "We started by running a 4 fold cross validation experiment.", "labels": [], "entities": []}, {"text": "Because we wanted to analyze the results in more detail, we look fora set of verbs having a representative number of patterns and of examples for the whole set of verbs and we analyzed specifically the accuracy of various methods individually.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 202, "end_pos": 210, "type": "METRIC", "confidence": 0.9986623525619507}]}, {"text": "The recognizing process using FSA can be made in two scenarios: using a parser or not.", "labels": [], "entities": []}, {"text": "The second scenario, no parsing for the input text, is challenging, because the recognizer acts as syntactico-semantic parser which outputs a dependency path corresponding to the context matched and it also outputs the senses of the words . While the accuracy of pattern recognition is lower in this case, the results are promising.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 251, "end_pos": 259, "type": "METRIC", "confidence": 0.9975090026855469}, {"text": "pattern recognition", "start_pos": 263, "end_pos": 282, "type": "TASK", "confidence": 0.7127254754304886}]}, {"text": "The SUMO features are obtained for the noun phrases heads via a public available API (.", "labels": [], "entities": []}, {"text": "At the test phase all the possible SUMO combinations inside the syntactic slots of a pattern are given to FSA.", "labels": [], "entities": [{"text": "FSA", "start_pos": 106, "end_pos": 109, "type": "DATASET", "confidence": 0.5948238968849182}]}, {"text": "If the FSA is unable to find a derivation, or if it finds more than one, it means that we are unable to match a single pattern against the given sentence and these cases are considered errors.", "labels": [], "entities": [{"text": "FSA", "start_pos": 7, "end_pos": 10, "type": "DATASET", "confidence": 0.7411925196647644}]}, {"text": "The results for the 4 fold cross validation experiment are presented in.", "labels": [], "entities": []}, {"text": "Both the SVM and the FSA reaches a good accuracy.", "labels": [], "entities": [{"text": "SVM", "start_pos": 9, "end_pos": 12, "type": "DATASET", "confidence": 0.6636714935302734}, {"text": "FSA", "start_pos": 21, "end_pos": 24, "type": "METRIC", "confidence": 0.7749544382095337}, {"text": "accuracy", "start_pos": 40, "end_pos": 48, "type": "METRIC", "confidence": 0.9986238479614258}]}, {"text": "However, the results maybe biased by the existence of verbs having just one pattern or of verbs having a dominant pattern.", "labels": [], "entities": []}, {"text": "In such cases, which represents more or less a quart of the total number, there is no ambiguity so we can hardly talk about a recognition process.", "labels": [], "entities": []}, {"text": "For a clearer understanding of the behavior of the systems we chose a set of 12 verbs having a number of patterns between 3 and 9, half of them having exactly 5 patterns (see).", "labels": [], "entities": []}, {"text": "The maximal and the minimal frequencies of a pattern are listed in the third and forth column, respectively.", "labels": [], "entities": []}, {"text": "We are interested in the maximal and minimal frequencies of the pattern, because, usually, there is little training available for those patterns with low frequency.", "labels": [], "entities": []}, {"text": "The risk of not recognizing the minimal frequency is high.", "labels": [], "entities": []}, {"text": "The approach presented here depends to a little extent on the dimension of the training corpus and to a large extent on its quality.", "labels": [], "entities": []}, {"text": "That is why we wanted to analyze the performances for verb pattern max Freq min Freq # train 4% 55: Test Verbs different types of patterns.", "labels": [], "entities": []}, {"text": "The available sentences were divided randomly into training and test sets.", "labels": [], "entities": []}, {"text": "We considered approximately two training sets containing approximately 10% and 30% of all the available sentences, respectively.", "labels": [], "entities": []}, {"text": "With a training ratio of 10%, 8 verbs had between 40 and 50 sentences.", "labels": [], "entities": []}, {"text": "Two verbs, accompany and furnish, have around 20 examples each, and two other verbs have only 5 and, respectively, 9 examples each (see column 5).", "labels": [], "entities": []}, {"text": "The 30% training sets had three times more examples.", "labels": [], "entities": []}, {"text": "The very first run we tried was to use all SUMO features, which led to the acceptance of all the possible combinations.", "labels": [], "entities": []}, {"text": "The result was very low; in more than 90 percent of the cases when the recognition set was not empty, it contained more than a pattern.", "labels": [], "entities": []}, {"text": "This experiment showed the necessity of observing the CCR condition for the CPA patterns.", "labels": [], "entities": []}, {"text": "If the CCR condition is observed, then not all the SUMO attribute combinations are accepted.", "labels": [], "entities": []}, {"text": "All the following experiments are conducted by observing the CCR condition (see section 4).", "labels": [], "entities": [{"text": "CCR condition", "start_pos": 61, "end_pos": 74, "type": "DATASET", "confidence": 0.8065539300441742}]}, {"text": "Using a 10% ratio for training was enough to obtain a very good precision, on average between 80% and 90%.", "labels": [], "entities": [{"text": "precision", "start_pos": 64, "end_pos": 73, "type": "METRIC", "confidence": 0.9995680451393127}]}, {"text": "However, fence expectedly performed poorer than the rest, with a precision of 45%, as it contained only 5 training examples.", "labels": [], "entities": [{"text": "precision", "start_pos": 65, "end_pos": 74, "type": "METRIC", "confidence": 0.9997153878211975}]}, {"text": "Considering the precision for two other verbs with a relatively low number of training examples, namely accompany and furnish, we can see that 20 examples seem to be enough fora precision around 96% (.", "labels": [], "entities": [{"text": "precision", "start_pos": 16, "end_pos": 25, "type": "METRIC", "confidence": 0.9985151886940002}, {"text": "precision", "start_pos": 178, "end_pos": 187, "type": "METRIC", "confidence": 0.9915949702262878}]}, {"text": "The low figure for recall has three main different causes: (1) the errors along the pipe generated at parsing time and at dependency extraction (2) the lack of SUMO features for pronouns and proper names and (3) the rigid condition of recognizing all the elements of a pattern, as requested by the FSA.", "labels": [], "entities": [{"text": "recall", "start_pos": 19, "end_pos": 25, "type": "METRIC", "confidence": 0.9928191304206848}, {"text": "FSA", "start_pos": 298, "end_pos": 301, "type": "DATASET", "confidence": 0.9697049260139465}]}, {"text": "The first two causes are not directly linked to the methodology described here.", "labels": [], "entities": []}, {"text": "These causes could be addressed in an independent manner.", "labels": [], "entities": []}, {"text": "However, the third cause is directly linked to the way the FSA works and we wanted to focus on it.", "labels": [], "entities": [{"text": "FSA", "start_pos": 59, "end_pos": 62, "type": "DATASET", "confidence": 0.8120258450508118}]}, {"text": "When the string corresponding to a test sentence is not complete, the FSA rejects it.", "labels": [], "entities": [{"text": "FSA", "start_pos": 70, "end_pos": 73, "type": "DATASET", "confidence": 0.8293722867965698}]}, {"text": "As many of the patterns may differ due to the direct objector due to the prepositional complement, it suffices to correctly recognize that part of the string in order to correctly categorize the test sentence as belonging to one group or another.", "labels": [], "entities": []}, {"text": "These subparts of the patterns can be automatically generated by comparing the patterns against each other.", "labels": [], "entities": []}, {"text": "We can include them in the training set as well.", "labels": [], "entities": []}, {"text": "Ina second experiment we provided to the AA the automatically generated subparts of the patterns.", "labels": [], "entities": []}, {"text": "We refer to the new automaton as extended FSA in order to distinguish it from the initial FSA trained on complete patterns, which we called BasicFSA.", "labels": [], "entities": [{"text": "FSA", "start_pos": 42, "end_pos": 45, "type": "METRIC", "confidence": 0.42060112953186035}, {"text": "BasicFSA", "start_pos": 140, "end_pos": 148, "type": "DATASET", "confidence": 0.9394811987876892}]}, {"text": "The recall increased significantly by using the extendedFSA.", "labels": [], "entities": [{"text": "recall", "start_pos": 4, "end_pos": 10, "type": "METRIC", "confidence": 0.9989783763885498}, {"text": "extendedFSA", "start_pos": 48, "end_pos": 59, "type": "METRIC", "confidence": 0.5635192394256592}]}, {"text": "For certain verbs the recall was doubled or nearly doubled.", "labels": [], "entities": [{"text": "recall", "start_pos": 22, "end_pos": 28, "type": "METRIC", "confidence": 0.9996108412742615}]}, {"text": "In the results obtained are listed.", "labels": [], "entities": []}, {"text": "We also ran the Extended FSA with a 30% training corpus.", "labels": [], "entities": [{"text": "Extended FSA", "start_pos": 16, "end_pos": 28, "type": "TASK", "confidence": 0.5996513068675995}]}, {"text": "The results are listed in.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: CPA corpus in Figures", "labels": [], "entities": [{"text": "CPA", "start_pos": 10, "end_pos": 13, "type": "TASK", "confidence": 0.4607236385345459}]}, {"text": " Table 3: Dominant Pattern Frequency in Corpus", "labels": [], "entities": [{"text": "Dominant Pattern Frequency", "start_pos": 10, "end_pos": 36, "type": "TASK", "confidence": 0.6574852267901102}]}, {"text": " Table 6: Recall for BasicFSA vs. ExtendedFSA with 10%", "labels": [], "entities": [{"text": "Recall", "start_pos": 10, "end_pos": 16, "type": "METRIC", "confidence": 0.9874758124351501}, {"text": "BasicFSA", "start_pos": 21, "end_pos": 29, "type": "DATASET", "confidence": 0.7688291072845459}]}, {"text": " Table 7: BasicFSA + 10% vs. ExtendedFSA + 30% training set", "labels": [], "entities": [{"text": "BasicFSA", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.49377956986427307}, {"text": "ExtendedFSA", "start_pos": 29, "end_pos": 40, "type": "METRIC", "confidence": 0.6699116230010986}]}, {"text": " Table 8: Cross Validation and 12 Verb F1 results", "labels": [], "entities": [{"text": "Cross Validation", "start_pos": 10, "end_pos": 26, "type": "TASK", "confidence": 0.7979912757873535}, {"text": "Verb F1", "start_pos": 34, "end_pos": 41, "type": "METRIC", "confidence": 0.8176972270011902}]}, {"text": " Table 9: Applying FSA to raw text", "labels": [], "entities": [{"text": "Applying", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9914867877960205}, {"text": "FSA", "start_pos": 19, "end_pos": 22, "type": "METRIC", "confidence": 0.4886529743671417}]}]}