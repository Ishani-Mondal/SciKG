{"title": [{"text": "Multilingual Multi-Document Summarization with POLY 2", "labels": [], "entities": [{"text": "Multilingual Multi-Document Summarization", "start_pos": 0, "end_pos": 41, "type": "TASK", "confidence": 0.5315371453762054}]}], "abstractContent": [{"text": "In this paper we present a linear model for the problem of text summarization, where a summary preserves the information coverage as much as possible in comparison to the original document set.", "labels": [], "entities": [{"text": "text summarization", "start_pos": 59, "end_pos": 77, "type": "TASK", "confidence": 0.7334796488285065}]}, {"text": "We reduce the problem of finding the best summary to the problem of finding the point on a convex polytope closest to the given hy-perplane, and solve it efficiently with the help of fractional linear programming.", "labels": [], "entities": []}, {"text": "We supply here an overview of our system, titled POLY 2 , that participated in the Multi-Ling contest at ACL 2013.", "labels": [], "entities": [{"text": "Multi-Ling contest at ACL 2013", "start_pos": 83, "end_pos": 113, "type": "DATASET", "confidence": 0.507026469707489}]}], "introductionContent": [{"text": "Automated text summarization is an active field of research in various communities like Information Retrieval (IR), Natural Language Processing (NLP), and Text Mining (TM).", "labels": [], "entities": [{"text": "Automated text summarization", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.7740399837493896}, {"text": "Information Retrieval (IR)", "start_pos": 88, "end_pos": 114, "type": "TASK", "confidence": 0.8319765567779541}, {"text": "Text Mining (TM)", "start_pos": 155, "end_pos": 171, "type": "TASK", "confidence": 0.8516294956207275}]}, {"text": "Some authors reduce summarization to the maximum coverage problem) that, despite a great performance, is known as NPhard ().", "labels": [], "entities": [{"text": "summarization", "start_pos": 20, "end_pos": 33, "type": "TASK", "confidence": 0.9845943450927734}, {"text": "coverage", "start_pos": 49, "end_pos": 57, "type": "METRIC", "confidence": 0.8235946297645569}]}, {"text": "Linear Programming helps to find an accurate approximated solution to this problem and became very popular in summarization field in the last years).", "labels": [], "entities": [{"text": "summarization", "start_pos": 110, "end_pos": 123, "type": "TASK", "confidence": 0.985093355178833}]}, {"text": "However, most mentioned works use exponential number of constraints.", "labels": [], "entities": []}, {"text": "Trying to solve a trade-off between summary quality and time complexity, we propose a novel summarization model solving the approximated maximum coverage problem by linear programming in polynomial time.", "labels": [], "entities": [{"text": "summarization", "start_pos": 92, "end_pos": 105, "type": "TASK", "confidence": 0.9732624292373657}]}, {"text": "We measure information coverage by terms 1 and strive to obtain a summary that preserves the optimal value of the cho-1 normalized meaningful words sen objective function as much as possible in comparison to the original document.", "labels": [], "entities": []}, {"text": "Various objective functions combining different parameters like term's position and its frequency are introduced and evaluated.", "labels": [], "entities": []}, {"text": "Our method ranks and extracts significant sentences into a summary and it can be generalized for both single-document and multi-document summarization.", "labels": [], "entities": []}, {"text": "Also, it can be easily adapted to cross-lingual/multilingual summarization.", "labels": [], "entities": []}, {"text": "Formally speaking, in this paper we introduce (1) a novel text representation model expanding a classic Vector Space Model ( to Hyperplane and Half-spaces, (2) re-formulated extractive summarization problem as an optimization task and (3) its solution using linear programming.", "labels": [], "entities": [{"text": "summarization problem", "start_pos": 185, "end_pos": 206, "type": "TASK", "confidence": 0.8038630783557892}]}, {"text": "The main challenge of this paper is anew text representation model making possible to represent an exponential number of extracts without computing them explicitly, and finding the optimal one by simple minimizing a distance function in polynomial time.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": []}