{"title": [{"text": "Experimental Results on the Native Language Identification Shared Task", "labels": [], "entities": [{"text": "Native Language Identification Shared Task", "start_pos": 28, "end_pos": 70, "type": "TASK", "confidence": 0.7594582438468933}]}], "abstractContent": [{"text": "We present a system for automatically identifying the native language of a writer.", "labels": [], "entities": [{"text": "identifying the native language of a writer", "start_pos": 38, "end_pos": 81, "type": "TASK", "confidence": 0.7618827479226249}]}, {"text": "We experiment with a large set of features and train them on a corpus of 9,900 essays written in English by speakers of 11 different languages.", "labels": [], "entities": []}, {"text": "our system achieved an accuracy of 43% on the test data, improved to 63% with improved feature normalization.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 23, "end_pos": 31, "type": "METRIC", "confidence": 0.9997420907020569}]}, {"text": "In this paper, we present the features used in our system, describe our experiments and provide an analysis of our results.", "labels": [], "entities": []}], "introductionContent": [{"text": "The task of Native Language Identification (NLI) is the task of identifying the native language of a writer or a speaker by analyzing their writing in English.", "labels": [], "entities": [{"text": "Native Language Identification (NLI)", "start_pos": 12, "end_pos": 48, "type": "TASK", "confidence": 0.852449874083201}]}, {"text": "Previous work in this area shows that there are several linguistic cues that can be used to do such identification.", "labels": [], "entities": []}, {"text": "Based on their native language, different speakers tend to make different kinds of errors pertaining to spelling, punctuation, and grammar).", "labels": [], "entities": []}, {"text": "We describe the complete set of features we considered in Section 4.", "labels": [], "entities": []}, {"text": "We evaluate different combinations of these features, and different ways of normalizing them in Section 5.", "labels": [], "entities": []}, {"text": "There are many possible applications for an NLI system, as noted by: finding the origins of anonymous text; error correction in various tasks including speech recognition, part-ofspeech tagging, and parsing; and in the field of second language acquisition for identifying learner difficulties.", "labels": [], "entities": [{"text": "finding the origins of anonymous text", "start_pos": 69, "end_pos": 106, "type": "TASK", "confidence": 0.7620256543159485}, {"text": "speech recognition", "start_pos": 152, "end_pos": 170, "type": "TASK", "confidence": 0.7448766976594925}, {"text": "part-ofspeech tagging", "start_pos": 172, "end_pos": 193, "type": "TASK", "confidence": 0.7733654081821442}, {"text": "second language acquisition", "start_pos": 228, "end_pos": 255, "type": "TASK", "confidence": 0.666456957658132}]}, {"text": "We are most interested in statistical approaches to this problem because it may point towards fruitful avenues of research in language and sound transfer, which are how people apply knowledge of their native language, and its phonology and orthography, respectively, to a second language.", "labels": [], "entities": [{"text": "language and sound transfer", "start_pos": 126, "end_pos": 153, "type": "TASK", "confidence": 0.6715608462691307}]}, {"text": "For example, found that character bigrams are quite useful for NLI, which led them to suggest that second language learners' word choice may in part be driven by their native languages.", "labels": [], "entities": []}, {"text": "Analysis of such language and sound translation patterns might be useful in understanding the process of language acquisition in humans.", "labels": [], "entities": [{"text": "language acquisition", "start_pos": 105, "end_pos": 125, "type": "TASK", "confidence": 0.7508613169193268}]}], "datasetContent": [{"text": "The experiments for this paper were performed using the TOEFL11 dataset (  provided as part of the shared task.", "labels": [], "entities": [{"text": "TOEFL11 dataset", "start_pos": 56, "end_pos": 71, "type": "DATASET", "confidence": 0.971531867980957}]}, {"text": "The dataset contains essays written in English from native speakers of 11 languages (Arabic, Chinese, French, German, Hindi, Italian, Japanese, Korean, Spanish, Telugu, and Turkish).", "labels": [], "entities": []}, {"text": "The corpus contains 12,099 essays per language sampled evenly from 8 prompts or topics.", "labels": [], "entities": []}, {"text": "This dataset was designed specifically to support the task of NLI and addresses some of the shortcomings of earlier datasets used for research in this area.", "labels": [], "entities": []}, {"text": "Specifically, the dataset has been carefully selected in order to maintain consistency in topic distributions, character encodings and annotations across the essays from different native languages.", "labels": [], "entities": []}, {"text": "The data was split into three data sets: a training set comprising 9,900 essays, a development set comprising 1,100 essays, and a test set comprising 1,100 essays.", "labels": [], "entities": []}, {"text": "We used weka () and libsvm (Chang and Lin, 2011) to run the experiments.", "labels": [], "entities": []}, {"text": "The classification was done using an SVM classifier.", "labels": [], "entities": [{"text": "classification", "start_pos": 4, "end_pos": 18, "type": "TASK", "confidence": 0.9724063277244568}]}, {"text": "We experimented with different SVM kernels and different values for the cost parameter.", "labels": [], "entities": []}, {"text": "The best performance was achieved with a linear kernel and cost = 0.001.", "labels": [], "entities": []}, {"text": "We trained the model using the combination of the training and the development sets.", "labels": [], "entities": []}, {"text": "We submitted the output of the system to the NLI shared task workshop.", "labels": [], "entities": [{"text": "NLI shared task workshop", "start_pos": 45, "end_pos": 69, "type": "DATASET", "confidence": 0.7586178034543991}]}, {"text": "Our system achieved 43.3% accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 26, "end_pos": 34, "type": "METRIC", "confidence": 0.9997033476829529}]}, {"text": "shows the confusion matrix and the precision, recall, and F-measure for each language.", "labels": [], "entities": [{"text": "precision", "start_pos": 35, "end_pos": 44, "type": "METRIC", "confidence": 0.9996458292007446}, {"text": "recall", "start_pos": 46, "end_pos": 52, "type": "METRIC", "confidence": 0.9977547526359558}, {"text": "F-measure", "start_pos": 58, "end_pos": 67, "type": "METRIC", "confidence": 0.999144434928894}]}, {"text": "After the NLI submission deadline, we noticed that we our system was not handling the normalization of the features properly which resulted in the poor performance.", "labels": [], "entities": []}, {"text": "After fixing the problem, our system achieved 63% accuracy on both test data and 10-fold cross validation on the entire data.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 50, "end_pos": 58, "type": "METRIC", "confidence": 0.9996055960655212}]}], "tableCaptions": [{"text": " Table 1: The results of our original submission to the NLI shared task on the test set. These results reflect the  performance of the system that does not normalize the features properly", "labels": [], "entities": [{"text": "NLI shared task on the test set", "start_pos": 56, "end_pos": 87, "type": "DATASET", "confidence": 0.699852636882237}]}]}