{"title": [{"text": "A Deterministic Dependency Parser with Dynamic Programming for Sanskrit", "labels": [], "entities": []}], "abstractContent": [{"text": "We describe a Deterministic Dependency Parser for Sanskrit.", "labels": [], "entities": []}, {"text": "The parse is developed following a Depth First traversal of a graph whose nodes represent morphological analyses of the words in a sentence.", "labels": [], "entities": []}, {"text": "During the traversal, relations at each node are checked for local compatibility, and finally for each full path, the relations on the path are checked for global compatibility.", "labels": [], "entities": []}, {"text": "Stacking of intermediate results guarantees dynamic programming.", "labels": [], "entities": []}, {"text": "We also describe an interface that displays multiple parses compactly and facilitates users to select the desired parse among various possible solutions with a maximum of n \u2212 1 choices fora sentence with n words.", "labels": [], "entities": []}], "introductionContent": [{"text": "Past decade has witnessed a lot of dynamism and upsurge of activities in the field of Sanskrit Computational Linguistics.", "labels": [], "entities": [{"text": "Sanskrit Computational Linguistics", "start_pos": 86, "end_pos": 120, "type": "TASK", "confidence": 0.6434861024220785}]}, {"text": "Several computational tools became available to the Sanskrit community as a web service through the internet . With the availability of a wide coverage grammar for Sanskrit in the form of As . t . \u00af adhy\u00af ay\u00af \u0131, there was a natural tendency to follow the grammar based approach towards the development of these tools.", "labels": [], "entities": []}, {"text": "Nevertheless, there were also notable efforts to use pure machine learning approaches for building these tools with a small manually tagged corpus as a boot-strap.", "labels": [], "entities": []}, {"text": "At the same time, a combination of the grammar based approach supported by the statistical evidences to push the most likely solution to the top were also followed ().", "labels": [], "entities": []}, {"text": "Sanskrit being influenced by the oral tradition, Sanskrit texts are typically written as a continuous string of characters.", "labels": [], "entities": []}, {"text": "Characters at the juncture of word boundaries undergo euphonic changes thereby merging the word boundaries.", "labels": [], "entities": []}, {"text": "This makes it challenging to split a given string into grammatically acceptable words before taking up the task of parsing.", "labels": [], "entities": []}, {"text": "The task of joining two words is deterministic but splitting a string of characters into well-formed words is non-deterministic.", "labels": [], "entities": []}, {"text": "This non-determinism together with splits at more than one places in a given string leads to exponential possibilities.", "labels": [], "entities": []}, {"text": "Huet proposed a novel way of augmenting the nodes of a Finite State Transducer with appropriate sandhi rules, and achieved the segmentation in linear transitions.", "labels": [], "entities": []}, {"text": "He also developed a shallow parser using the sub-categorisation frames, and the agreement rules.", "labels": [], "entities": []}, {"text": "This parser is useful to rule out the nonsolutions before proceeding for the full fledged parsing.", "labels": [], "entities": []}, {"text": "A purely statistical parser for Sanskrit also exists.", "labels": [], "entities": []}, {"text": "The first full fledged parser for Sanskrit based on P\u00af an . inian Grammar formalism is described in ( . This parser is implemented as a constraint solver.", "labels": [], "entities": []}, {"text": "In this model, a word in a sentence is represented as anode in a graph G, and the relations between the words as directed labelled edges.", "labels": [], "entities": []}, {"text": "The task of parsing a sentence is modelled as finding a sub-graph T of G which is a directed labelled Tree.", "labels": [], "entities": [{"text": "parsing a sentence", "start_pos": 12, "end_pos": 30, "type": "TASK", "confidence": 0.8790412147839864}]}, {"text": "The problem of parsing is divided into three tasks: 1.", "labels": [], "entities": [{"text": "parsing", "start_pos": 15, "end_pos": 22, "type": "TASK", "confidence": 0.9568442106246948}]}, {"text": "The first task is to establish labelled edges between the nodes.", "labels": [], "entities": []}, {"text": "The information of expectancy and agreement is used to establish these labelled edges.", "labels": [], "entities": [{"text": "agreement", "start_pos": 34, "end_pos": 43, "type": "METRIC", "confidence": 0.9197567105293274}]}, {"text": "2. Next a sub-graph T of G is identified, such that T is a directed Tree which satisfies the following constraints.", "labels": [], "entities": []}, {"text": "\u2022 Every node can have at the most one incoming arrow.", "labels": [], "entities": []}, {"text": "\u2022 No two edges emerging from the same node have the same label.", "labels": [], "entities": []}, {"text": "\u2022 There are no loops.", "labels": [], "entities": []}, {"text": "\u2022 The resulting Tree is projective, i.e. if the nodes are arranged linearly according to the word order, then no two links cross each other.", "labels": [], "entities": []}, {"text": "\u2022 It is ensured that certain relations which always occur in pairs e.g. anuyog\u00af \u0131-pratiyog\u00af \u0131 (relata-1 and relata-2), kartr . sam\u00af an\u00af adhikaran . am-kart\u00af a (predicative adjective and subject 2 ), etc.", "labels": [], "entities": []}, {"text": "do have their counter-relatum present in the parse.", "labels": [], "entities": []}, {"text": "3. Finally in case there is more than one possible directed Tree, the solutions are prioritized.", "labels": [], "entities": []}, {"text": "The implementation of the parser is reported in . The graph G is represented as a 5D matrix C with atypical element where R is the relation from them th analysis of the l th word to the j th analysis of the i th word.", "labels": [], "entities": []}, {"text": "In order to prioritize the solutions, every relation is assigned a weight.", "labels": [], "entities": []}, {"text": "A simple Cost function is defined as Cost = w * |j \u2212 i|, where w is the weight of the relation between the nodes i and j.", "labels": [], "entities": [{"text": "Cost", "start_pos": 37, "end_pos": 41, "type": "METRIC", "confidence": 0.9750308990478516}]}, {"text": "The main disadvantage of this approach is the complexity.", "labels": [], "entities": []}, {"text": "The size of the 5D matrix is N * M * K * N * M , where N is the total number of words in a sentence, M is the maximum number of morph analyses fora word in a given sentence and K is the maximum number of distinct possible relations among the words in a given sentence.", "labels": [], "entities": []}, {"text": "Sanskrit words being overloaded with morphological analysis, frequently occurring words tend to have several analyses possible 3 . Similarly though the average length of the sentences 4 is around 10, the sentences from literary texts tend to be longer with more than 20 words.", "labels": [], "entities": []}, {"text": "Sanskrit grammar texts discuss various relations, among words, necessary to interpret the meaning of a sentence.", "labels": [], "entities": [{"text": "interpret the meaning of a sentence", "start_pos": 76, "end_pos": 111, "type": "TASK", "confidence": 0.7936606605847677}]}, {"text": "All these relations were compiled and classified by Ramakrishnamacharyulu (2009) and further they were investigated for their suitability for automatic parsing.", "labels": [], "entities": [{"text": "Ramakrishnamacharyulu (2009)", "start_pos": 52, "end_pos": 80, "type": "DATASET", "confidence": 0.8667246997356415}]}, {"text": "Out of around 90 relations listed there, only those relations which one can predict based on the syntactico-semantic information available in a sentence are considered for automatic tagging (.", "labels": [], "entities": [{"text": "automatic tagging", "start_pos": 172, "end_pos": 189, "type": "TASK", "confidence": 0.5053561180830002}]}, {"text": "There are around 35 of them.", "labels": [], "entities": []}, {"text": "Thus R is one of these 35.", "labels": [], "entities": []}, {"text": "As the number of words in a sentence increases, or if a sentence has even a single word with considerable number of morph analyses, the size of the 5D matrix explodes, and the use of parser in real time applications becomes impractical.", "labels": [], "entities": []}, {"text": "Second disadvantage of the above method is that the constraints are applied globally to the matrix.", "labels": [], "entities": []}, {"text": "However, we notice that some of the constraints are local to anode.", "labels": [], "entities": []}, {"text": "Separating the local constraints from the global, and applying the local constraints at an early stage to rule out nonsolutions should increase the efficiency of the system.", "labels": [], "entities": []}, {"text": "The importance and advantage of Dependency Parser over a constituency parser has been well recognised by the computational linguistic community and we see Dependency parsers for variety of languages such as English, Japanese, Swedish to name a few.", "labels": [], "entities": []}, {"text": "More than half a dozen parsers exist for English alone that produce dependency parse.", "labels": [], "entities": [{"text": "dependency parse", "start_pos": 68, "end_pos": 84, "type": "TASK", "confidence": 0.7543346881866455}]}, {"text": "The existence of P\u00af an . inian grammar for Sanskrit is the strong motivation behind developing a Dependency based parser for Sanskrit.", "labels": [], "entities": []}, {"text": "The current trend towards developing dependency parsers is more towards following the data driven approaches over the grammar based.", "labels": [], "entities": [{"text": "dependency parsers", "start_pos": 37, "end_pos": 55, "type": "TASK", "confidence": 0.7570335268974304}]}, {"text": "However, we follow the grammar based approach.", "labels": [], "entities": []}, {"text": "Some of the factors that motivated the design of the parser and choice of the approach are the following.", "labels": [], "entities": []}, {"text": "\u2022 Sanskrit does not have a tree bank of reasonable size so that we can use data driven approaches for Sanskrit.", "labels": [], "entities": []}, {"text": "\u2022 Sanskrit has a free word order, and hence the traditional POS taggers do not make any sense.", "labels": [], "entities": []}, {"text": "Unlike modern Indian languages which are relatively free word order, and which have a fixed word order for the adjective-substantive sequences, Sanskrit allows even the adjectives and genitives to float around in a sentence.", "labels": [], "entities": []}, {"text": "This makes the usability of POS tagger for Sanskrit doubtful.", "labels": [], "entities": [{"text": "POS tagger", "start_pos": 28, "end_pos": 38, "type": "TASK", "confidence": 0.5568623542785645}]}, {"text": "\u2022 The existence of almost exhaustive grammar for Sanskrit also demands from the users a justification for the analysis in terms of grammar rules.", "labels": [], "entities": []}, {"text": "We describe below a Deterministic Parsing algorithm which applies the local constraints locally, and also uses Dynamic Programming for efficient parsing.", "labels": [], "entities": [{"text": "Deterministic Parsing", "start_pos": 20, "end_pos": 41, "type": "TASK", "confidence": 0.7106071710586548}]}, {"text": "This parser differs from the Deterministic Dependency Parsers for English developed by and Nivre () in three major ways.", "labels": [], "entities": []}, {"text": "These parsers for English use either a bottom-up or a combination of bottom-up and top-down algorithm.", "labels": [], "entities": []}, {"text": "Our parser traverses the sentence from left to right guided by the possible paths among the nodes.", "labels": [], "entities": []}, {"text": "Second major difference is that these parsers use shift-reduce parsing, while we check the relations for compatibility at each node.", "labels": [], "entities": []}, {"text": "The third major difference is that we follow the grammar based approach while the above parsers for English are data driven.", "labels": [], "entities": []}], "datasetContent": [{"text": "Sanskrit Tree bank corpus is developed under Government of India sponsored project 'Development of Sanskrit Computational Toolkit and Sanskrit Hindi Machine Translation system'.", "labels": [], "entities": [{"text": "Sanskrit Tree bank corpus", "start_pos": 0, "end_pos": 25, "type": "DATASET", "confidence": 0.9798957407474518}, {"text": "Sanskrit Hindi Machine Translation", "start_pos": 134, "end_pos": 168, "type": "TASK", "confidence": 0.5556140244007111}]}, {"text": "The corpus consists of around 3000 sentences, a substantial part of it being modern short stories.", "labels": [], "entities": []}, {"text": "A small part of the corpus contains sentences addressing various syntactic phenomena.", "labels": [], "entities": []}, {"text": "The complete tagged corpus is still being cross checked for correctness.", "labels": [], "entities": []}, {"text": "Hence the parser was tested only on 1316 sentences.", "labels": [], "entities": []}, {"text": "We have a hierarchical tagset with 35 tags.", "labels": [], "entities": []}, {"text": "Among these the subclassification of 4 types of location (adhikaran . a) and 3 types of objects (karma) is collapsed into one each resulting into a flat tagset of 30 tags.", "labels": [], "entities": []}, {"text": "Our parser produces all possible parses, ordered on cost.", "labels": [], "entities": []}, {"text": "The one with minimum cost is shown as the first parse.", "labels": [], "entities": []}, {"text": "For evaluation, we consider only the first parse.", "labels": [], "entities": []}, {"text": "The correctness of parses is judged on several well established parameters.", "labels": [], "entities": []}, {"text": "\u2022 Relations with correct label and attachment (LAS) With 35 relations, the labelled attachments were correct in 63.1% cases, while with 30 relations, the score was 67.4%.", "labels": [], "entities": [{"text": "correct label and attachment (LAS)", "start_pos": 17, "end_pos": 51, "type": "METRIC", "confidence": 0.7236585361616952}]}, {"text": "\u2022 Relations with correct attachment (UAS) If only attachments were considered, ignoring the labels, 80.26% attachments matched with the GOLD data.", "labels": [], "entities": [{"text": "correct attachment (UAS)", "start_pos": 17, "end_pos": 41, "type": "METRIC", "confidence": 0.7198717951774597}, {"text": "GOLD data", "start_pos": 136, "end_pos": 145, "type": "DATASET", "confidence": 0.848635345697403}]}, {"text": "\u2022 Sentences with matching dependency trees (MDT) This measure tells us in exactly how many cases the first tree matches the manually tagged tree.", "labels": [], "entities": []}, {"text": "Out of 1316 sentences, the first parse matched exactly in 569 (43.20%) sentences with a tagset of 35 tags, while with 30 tags, the first parse matched in 647 (49.1%) cases.", "labels": [], "entities": []}, {"text": "\u2022 Sentences with correct unlabelled dependency trees (UDT) Instead of complete tree match, now we check only for the attachments, and not the labels.", "labels": [], "entities": []}, {"text": "Among 1316, the unlabelled dependency trees matched in 870 (66.05%) cases.", "labels": [], "entities": []}, {"text": "\u2022 Sentences with one wrong attachment (OWAS) It was found that out of 1316 sentences, 285 (21.6%) sentences had only one wrong labelled attachment.", "labels": [], "entities": [{"text": "Sentences with one wrong attachment (OWAS)", "start_pos": 2, "end_pos": 44, "type": "TASK", "confidence": 0.57320212200284}]}, {"text": "If this is rectified, the performance of the system for correct matches increases drastically.", "labels": [], "entities": []}], "tableCaptions": []}