{"title": [{"text": "GRO Task: Populating the Gene Regulation Ontology with events and relations", "labels": [], "entities": [{"text": "GRO", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.5326617360115051}, {"text": "Gene Regulation Ontology", "start_pos": 25, "end_pos": 49, "type": "TASK", "confidence": 0.7476276059945425}]}], "abstractContent": [{"text": "Semantic querying over the biomedical literature has gained popularity, where a semantic representation of biomedical documents is required.", "labels": [], "entities": [{"text": "Semantic querying", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.8341759741306305}]}, {"text": "Previous BioNLP Shared Tasks exercised semantic event extraction with a small number of pre-defined event concepts.", "labels": [], "entities": [{"text": "semantic event extraction", "start_pos": 39, "end_pos": 64, "type": "TASK", "confidence": 0.6543430387973785}]}, {"text": "The GRO task of the BioNLP'13-ST imposes the challenge of dealing with over 100 GRO concepts.", "labels": [], "entities": []}, {"text": "Its annotated corpus consists of 300 MEDLINE abstracts, and an analysis of inter-annotator agreement on the annotations by two experts shows Kappa values between 43% and 56%.", "labels": [], "entities": [{"text": "Kappa", "start_pos": 141, "end_pos": 146, "type": "METRIC", "confidence": 0.9748406410217285}]}, {"text": "The results from the only participant are promising with F-scores 22% (events) and 63% (relations), and also lead us to open issues such as the need to consider the ontology structure.", "labels": [], "entities": [{"text": "F-scores", "start_pos": 57, "end_pos": 65, "type": "METRIC", "confidence": 0.9930145740509033}]}], "introductionContent": [], "datasetContent": [{"text": "There was one submission for the GRO task of the BioNLP'13-ST, designated as \"TEES-2.1\".", "labels": [], "entities": [{"text": "GRO task", "start_pos": 33, "end_pos": 41, "type": "TASK", "confidence": 0.5466162264347076}, {"text": "BioNLP'13-ST", "start_pos": 49, "end_pos": 61, "type": "DATASET", "confidence": 0.7368195056915283}, {"text": "TEES-2.1", "start_pos": 78, "end_pos": 86, "type": "METRIC", "confidence": 0.978590190410614}]}, {"text": "For comparison purposes, the GRO task organizers produced results with a preliminary system by adapting our existing system, designated as OSEE), for event extraction and developing a simple machine learning model for relation identification.", "labels": [], "entities": [{"text": "event extraction", "start_pos": 150, "end_pos": 166, "type": "TASK", "confidence": 0.7672525942325592}, {"text": "relation identification", "start_pos": 218, "end_pos": 241, "type": "TASK", "confidence": 0.93562251329422}]}, {"text": "We describe these two systems briefly and compare their results with several criteria.", "labels": [], "entities": []}, {"text": "The GRO task follows some of the evaluation criteria of the Genia Event Extraction (GE) task of, including strict and approximate matching, and also introduce new criteria that consider 1) the hierarchical structure of the GRO and 2) parent and/or grandparent of answer concept.", "labels": [], "entities": [{"text": "Genia Event Extraction (GE) task", "start_pos": 60, "end_pos": 92, "type": "TASK", "confidence": 0.8006328088896615}]}, {"text": "We here explain these new criteria in detail.", "labels": [], "entities": []}, {"text": "1) In this scheme of evaluation, the event results of a participant are classified into the GRO concepts at the third level (see for examples), which are ancestors of their labeled classes, and the evaluation results are accumulated for each of those concepts at the third level.", "labels": [], "entities": []}, {"text": "This scheme may give us insights on which categories the participant system shows strength or weakness.", "labels": [], "entities": []}, {"text": "2) This scheme is to deal with such a case that the answer class is \"GeneExpression\", but a participant gives \"IntraCellularProcess\" or \"MolecularProcess\", which are the parent and grandparent of the answer class, thus not entirely wrong nor too generic.", "labels": [], "entities": []}, {"text": "For example, the scheme \"Allowing parents\" allows \"IntraCellularProcess\" to be a correct match to the answer class \"GeneExpression\", as well as the answer class itself.", "labels": [], "entities": []}, {"text": "\"Allowing grandparents\" accepts the grandparents of answer classes as well as the parents.", "labels": [], "entities": [{"text": "answer classes", "start_pos": 52, "end_pos": 66, "type": "TASK", "confidence": 0.8821814656257629}]}, {"text": "shows the evaluation results of the two systems.", "labels": [], "entities": []}, {"text": "Note that all the evaluation results in terms of precision, recall, and F-score in all the tables are percentages.", "labels": [], "entities": [{"text": "precision", "start_pos": 49, "end_pos": 58, "type": "METRIC", "confidence": 0.9996985197067261}, {"text": "recall", "start_pos": 60, "end_pos": 66, "type": "METRIC", "confidence": 0.9995074272155762}, {"text": "F-score", "start_pos": 72, "end_pos": 79, "type": "METRIC", "confidence": 0.9992978572845459}]}, {"text": "The performance of the TEES-2.1 systems, which is clearly better than the OSEE system, is lower than its performance for other tasks of the BioNLP'13-ST, which is understandable, considering 1) the higher number of GRO concepts than those for the other tasks and 2) the low Kappa value of the interannotator agreement.", "labels": [], "entities": [{"text": "BioNLP'13-ST", "start_pos": 140, "end_pos": 152, "type": "DATASET", "confidence": 0.8254367113113403}]}, {"text": "It also shows that the evaluation scheme that allows the parents/grandparents of answer concepts for acceptance does not greatly help increasing the performance, which may mean that the systems are designed to aim individual concepts, not considering the ontology structure.", "labels": [], "entities": []}, {"text": "This issue of considering the structure of the ontology in event extraction can bean interesting future work.", "labels": [], "entities": [{"text": "event extraction", "start_pos": 59, "end_pos": 75, "type": "TASK", "confidence": 0.8212221264839172}]}, {"text": "shows the performance of the systems for the most frequent concepts and also for some selected infrequent concepts.", "labels": [], "entities": []}, {"text": "From the results, we observe that the system performance for an event class does not reflect the number of train-ing data of the class, and that the performance of the syntactic pattern matching system OSEE is high for the event classes, for which the machine learning system TEES-2.1 also performs well.", "labels": [], "entities": []}, {"text": "These observations may indicate that the current approaches to event extraction deal with event types independently, not considering the hierarchical (or semantic) relations between the event types nor relations between entity types.", "labels": [], "entities": [{"text": "event extraction", "start_pos": 63, "end_pos": 79, "type": "TASK", "confidence": 0.788253515958786}]}, {"text": "shows the performance of the systems for the GRO relations.", "labels": [], "entities": [{"text": "GRO", "start_pos": 45, "end_pos": 48, "type": "DATASET", "confidence": 0.5545595288276672}]}, {"text": "These results of TEES in the relation identification of the GRO task (Fscores between 50% and 87%) are much higher than the best results of relation identification (40% F-score) in the Bacteria Biotopes (BB) task, which is to extract relations of localization and part-of.", "labels": [], "entities": [{"text": "TEES", "start_pos": 17, "end_pos": 21, "type": "METRIC", "confidence": 0.9976453185081482}, {"text": "relation identification", "start_pos": 29, "end_pos": 52, "type": "TASK", "confidence": 0.8253800570964813}, {"text": "Fscores", "start_pos": 70, "end_pos": 77, "type": "METRIC", "confidence": 0.997421145439148}, {"text": "relation identification", "start_pos": 140, "end_pos": 163, "type": "TASK", "confidence": 0.8424515724182129}, {"text": "F-score", "start_pos": 169, "end_pos": 176, "type": "METRIC", "confidence": 0.9962922930717468}]}, {"text": "Though the two relation identification tasks of GRO and BB cannot be directly compared due to many differences (e.g. entity types, relation types, corpus sources), it may indicate that the GRO task corpus has been annotated consistently enough to train a model with such high performance and that the low performance of event extraction compared to relation identification maybe due to the big number of event types and would be resolved as the corpus size increases.", "labels": [], "entities": [{"text": "GRO task corpus", "start_pos": 189, "end_pos": 204, "type": "DATASET", "confidence": 0.6043176253636678}, {"text": "event extraction", "start_pos": 320, "end_pos": 336, "type": "TASK", "confidence": 0.7146164029836655}, {"text": "relation identification", "start_pos": 349, "end_pos": 372, "type": "TASK", "confidence": 0.848529577255249}]}], "tableCaptions": [{"text": " Table 1. Inter-annotator agreement re- sults", "labels": [], "entities": [{"text": "Inter-annotator agreement re- sults", "start_pos": 10, "end_pos": 45, "type": "TASK", "confidence": 0.5105769574642182}]}, {"text": " Table 2. Number of annotation elements", "labels": [], "entities": []}, {"text": " Table 3. Number of mentions for frequent  top-level Continuant concepts", "labels": [], "entities": [{"text": "Number", "start_pos": 10, "end_pos": 16, "type": "METRIC", "confidence": 0.9546011090278625}]}, {"text": " Table 4. Number of event instances for  frequent top-level Occurrent concepts", "labels": [], "entities": []}, {"text": " Table 5. Number of relation instances", "labels": [], "entities": []}, {"text": " Table 6. Evaluation results (percentage)", "labels": [], "entities": []}, {"text": " Table 7. Evaluation results grouped into  3rd-level GRO concepts (%)", "labels": [], "entities": [{"text": "GRO", "start_pos": 53, "end_pos": 56, "type": "METRIC", "confidence": 0.7103428840637207}]}, {"text": " Table 8. Evaluation results for frequent  and infrequent individual concepts (%)", "labels": [], "entities": []}, {"text": " Table 9. Evaluation results for relations  (%)", "labels": [], "entities": []}]}