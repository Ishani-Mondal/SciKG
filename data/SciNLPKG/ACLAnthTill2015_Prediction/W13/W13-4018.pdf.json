{"title": [{"text": "Improving Interaction Quality Recognition Using Error Correction", "labels": [], "entities": [{"text": "Improving Interaction Quality Recognition", "start_pos": 0, "end_pos": 41, "type": "TASK", "confidence": 0.877244308590889}]}], "abstractContent": [{"text": "Determining the quality of an ongoing interaction in the field of Spoken Dialogue Systems is a hard task.", "labels": [], "entities": [{"text": "Spoken Dialogue Systems", "start_pos": 66, "end_pos": 89, "type": "TASK", "confidence": 0.8619275490442911}]}, {"text": "While existing methods employing automatic estimation already achieve reasonable results, still there is a lot of room for improvement.", "labels": [], "entities": []}, {"text": "Hence, we aim at tackling the task by estimating the error of the applied statistical classification algorithms in a two-stage approach.", "labels": [], "entities": [{"text": "statistical classification", "start_pos": 74, "end_pos": 100, "type": "TASK", "confidence": 0.7043766975402832}]}, {"text": "Correcting the hypotheses using the estimated model error increases performance by up to 4.1 % relative improvement in Unweighted Average Recall.", "labels": [], "entities": [{"text": "Unweighted Average Recall", "start_pos": 119, "end_pos": 144, "type": "METRIC", "confidence": 0.9346110026041666}]}], "introductionContent": [{"text": "Evaluating the quality of Spoken Dialogue Systems (SDSs) has long since been a challenging task.", "labels": [], "entities": [{"text": "Spoken Dialogue Systems (SDSs)", "start_pos": 26, "end_pos": 56, "type": "TASK", "confidence": 0.7742883463700613}]}, {"text": "While objective metrics like task completion and dialogue duration are not human-centered, subjective measures compensate for this by modeling the user's subjective experience.", "labels": [], "entities": []}, {"text": "This information maybe used to increase the dialogue system's performance (cf. ().", "labels": [], "entities": []}, {"text": "In human-machine dialogues, however, there is no easy way of deriving the user's satisfaction level.", "labels": [], "entities": []}, {"text": "Moreover, asking real users for answering questions about the system performance requires them to spend more time talking to the machine than necessary.", "labels": [], "entities": []}, {"text": "It can be assumed that a regular user does not want to do this as human-machine dialogues usually have no conversational character but are task oriented.", "labels": [], "entities": []}, {"text": "Hence, automatic approaches are the preferred choice.", "labels": [], "entities": []}, {"text": "Famous work on determining the satisfaction level automatically is the PARADISE framework by.", "labels": [], "entities": [{"text": "PARADISE", "start_pos": 71, "end_pos": 79, "type": "METRIC", "confidence": 0.8128281235694885}]}, {"text": "Assuming a linear dependency between objective measures and User Satisfaction (US), a linear regression model is applied to determine US on the dialogue level.", "labels": [], "entities": [{"text": "US", "start_pos": 134, "end_pos": 136, "type": "METRIC", "confidence": 0.9706051349639893}]}, {"text": "This is not only very costly, as dialogues must be performed with real users, but also inadequate if quality on a finer level is of interest, e.g., on the exchange level.", "labels": [], "entities": []}, {"text": "To overcome this issue, work by Schmitt et al.", "labels": [], "entities": []}, {"text": "(2011) introduced anew metric for measuring the performance of an SDS on the exchange level called Interaction Quality (IQ).", "labels": [], "entities": []}, {"text": "They used statistical classification methods to automatically derive the quality based on interaction parameters.", "labels": [], "entities": [{"text": "statistical classification", "start_pos": 10, "end_pos": 36, "type": "TASK", "confidence": 0.6898581683635712}]}, {"text": "Quality labels were applied by expert raters after the dialogue on the exchange level, i.e., for each systemuser-exchange.", "labels": [], "entities": []}, {"text": "Automatically derived parameters were then used as features for creating a statistical classification model using static feature vectors.", "labels": [], "entities": [{"text": "statistical classification", "start_pos": 75, "end_pos": 101, "type": "TASK", "confidence": 0.7444653213024139}]}, {"text": "Based on the same data, put an emphasis on the sequential character of the IQ measure by applying temporal statistical classification using Hidden Markov Models (HMMs) and Continuous Hidden Markov Models (CHMMs).", "labels": [], "entities": [{"text": "IQ", "start_pos": 75, "end_pos": 77, "type": "TASK", "confidence": 0.9289735555648804}]}, {"text": "However, statistical classifiers usually do not achieve perfect performance, i.e., there will always be misclassification.", "labels": [], "entities": []}, {"text": "While most work focuses on applying different statistical models and improving them (Section 2), learning the error to correct the result afterwards represents a different approach.", "labels": [], "entities": []}, {"text": "Therefore, we present our approach on estimating the error of IQ recognition models to correct their hypothesis in order to eventually yield better recognition rates (Section 4).", "labels": [], "entities": [{"text": "IQ recognition", "start_pos": 62, "end_pos": 76, "type": "TASK", "confidence": 0.9503062069416046}]}, {"text": "The definition of IQ and data used for the evaluation of our approach (Section 5) is presented in Section 3.", "labels": [], "entities": [{"text": "IQ", "start_pos": 18, "end_pos": 20, "type": "METRIC", "confidence": 0.8137404918670654}]}, {"text": "Our approach is also compared to a simple hierarchical approach also discussed in Section 5.", "labels": [], "entities": []}], "datasetContent": [{"text": "All experiments are conducted using the LEGO corpus presented in Section 3.", "labels": [], "entities": [{"text": "LEGO corpus", "start_pos": 40, "end_pos": 51, "type": "DATASET", "confidence": 0.8500834703445435}]}, {"text": "By applying 5-fold cross validation, hypotheses for each system-userexchange which is contained in the LEGO corpus are estimated.", "labels": [], "entities": [{"text": "LEGO corpus", "start_pos": 103, "end_pos": 114, "type": "DATASET", "confidence": 0.8874623775482178}]}, {"text": "Please note that some textual interaction parameters are discarded due to their taskdependent nature leaving 45 parameters 1 . For evaluation, we rely on two measures: The unweighted average recall (UAR) and the root mean squared error (RMSE).", "labels": [], "entities": [{"text": "unweighted average recall (UAR)", "start_pos": 172, "end_pos": 203, "type": "METRIC", "confidence": 0.8086259365081787}, {"text": "root mean squared error (RMSE)", "start_pos": 212, "end_pos": 242, "type": "METRIC", "confidence": 0.8841570956366402}]}, {"text": "UAR represents the accuracy corrected by the effects of unbalanced data and is also used by cited literature.", "labels": [], "entities": [{"text": "UAR", "start_pos": 0, "end_pos": 3, "type": "METRIC", "confidence": 0.9477513432502747}, {"text": "accuracy", "start_pos": 19, "end_pos": 27, "type": "METRIC", "confidence": 0.9993025064468384}]}, {"text": "RMSE is used since the error correction method is limited to correcting the results only by one.", "labels": [], "entities": [{"text": "RMSE", "start_pos": 0, "end_pos": 4, "type": "METRIC", "confidence": 0.5371768474578857}]}, {"text": "For bigger errors, the true value cannot be reached.", "labels": [], "entities": []}, {"text": "The performances of two different statistical classification methods are compared, both applied for stage one and stage two: Support Vector Machine (SVM)) using a linear kernel, which is also used by, and Rule Induction (RI) based on Cohen.", "labels": [], "entities": [{"text": "statistical classification", "start_pos": 34, "end_pos": 60, "type": "TASK", "confidence": 0.706385612487793}, {"text": "Rule Induction (RI", "start_pos": 205, "end_pos": 223, "type": "TASK", "confidence": 0.7150803580880165}]}, {"text": "Furthermore, a normalization component is added performing a range normalization of the input parameters in both stages.", "labels": [], "entities": []}, {"text": "This is necessary for using the implementation of the statistical classification algorithms at hand.", "labels": [], "entities": [{"text": "statistical classification", "start_pos": 54, "end_pos": 80, "type": "TASK", "confidence": 0.8390828967094421}]}, {"text": "For error estimation, two variants are explored: using one combined model for all three error classes (\u22121,0,+1) and using two separate models, one for distinguishing between \u22121 and 0 and one for distinguishing between +1 and 0 with combining their results afterwards.", "labels": [], "entities": [{"text": "error estimation", "start_pos": 4, "end_pos": 20, "type": "TASK", "confidence": 0.6374881267547607}]}, {"text": "While using RI for error estimation yields reasonable performance results for the combined model, it is not suitable for error estimation using two separate models as all input vectors are mapped to 0.", "labels": [], "entities": [{"text": "RI", "start_pos": 12, "end_pos": 14, "type": "METRIC", "confidence": 0.8591744303703308}, {"text": "error estimation", "start_pos": 19, "end_pos": 35, "type": "TASK", "confidence": 0.6641897559165955}, {"text": "error estimation", "start_pos": 121, "end_pos": 137, "type": "TASK", "confidence": 0.6565652042627335}]}, {"text": "Hence, for the two model approach, only the SVM is applied . Results for applying error correction (EC) are presented in.", "labels": [], "entities": [{"text": "error correction (EC)", "start_pos": 82, "end_pos": 103, "type": "METRIC", "confidence": 0.9613194108009339}]}, {"text": "Having an SVM at stage one (column SVM), recognition performance is relatively improved by up to 4.6 % using EC.", "labels": [], "entities": [{"text": "recognition", "start_pos": 41, "end_pos": 52, "type": "TASK", "confidence": 0.903430700302124}]}, {"text": "With RI at stage one, performance is only increased by up to 0.5 % which has shown to be not significant using the Wilcoxon test.", "labels": [], "entities": [{"text": "RI", "start_pos": 5, "end_pos": 7, "type": "METRIC", "confidence": 0.9209868311882019}, {"text": "Wilcoxon test", "start_pos": 115, "end_pos": 128, "type": "DATASET", "confidence": 0.8027461171150208}]}, {"text": "The relative improvements in UAR are depicted in.", "labels": [], "entities": [{"text": "UAR", "start_pos": 29, "end_pos": 32, "type": "METRIC", "confidence": 0.5366235375404358}]}, {"text": "Furthermore, these results are compared to a simple hierarchical approach (SH) where the hypothesis h 0 of the stage one classifier is used as an additional feature for the stage two classifier targeting IQ directly.", "labels": [], "entities": []}, {"text": "Here, the performance of the stage two classifier is of most interest since this approach can be viewed as one stage classification with an additional feature.", "labels": [], "entities": []}, {"text": "The results in show that RI does not benefit from additional information (comparison of last row with one stage RI recognition).", "labels": [], "entities": [{"text": "RI", "start_pos": 25, "end_pos": 27, "type": "TASK", "confidence": 0.8604313731193542}, {"text": "RI recognition", "start_pos": 112, "end_pos": 126, "type": "TASK", "confidence": 0.8160155117511749}]}, {"text": "SVM recognition at stage two, though, shows better results.", "labels": [], "entities": [{"text": "SVM recognition", "start_pos": 0, "end_pos": 15, "type": "TASK", "confidence": 0.9329195022583008}]}, {"text": "While its performance is reduced using the SVM hypothesis as additional feature, adding the RI hypothesis improved UAR up to 12.6 % relatively.", "labels": [], "entities": [{"text": "UAR", "start_pos": 115, "end_pos": 118, "type": "METRIC", "confidence": 0.9268839955329895}]}, {"text": "However, there is no reasonable scenario where one would not use the better performing RI in favor of using its results as additional input for SVM recognition.", "labels": [], "entities": [{"text": "SVM recognition", "start_pos": 144, "end_pos": 159, "type": "TASK", "confidence": 0.9502332806587219}]}, {"text": "The question remains why SVM benefits from Error Correction as well as from adding additional input parameters while RI does not.", "labels": [], "entities": []}, {"text": "It remains unclear if this is an effect of the task characteristics combined with the characteristics of the classification method.", "labels": [], "entities": []}, {"text": "It may as well be caused by low classification performance.", "labels": [], "entities": []}, {"text": "A classifier with low performance might be more likely to improve its performance by additional information or EC.", "labels": [], "entities": [{"text": "EC", "start_pos": 111, "end_pos": 113, "type": "METRIC", "confidence": 0.9975090026855469}]}], "tableCaptions": [{"text": " Table 1: Results for IQ recognition: UAR and  RMSE for IQ recognition without stage two, with  error correction at stage two, and with a simple hi- erarchical approach.", "labels": [], "entities": [{"text": "IQ recognition", "start_pos": 22, "end_pos": 36, "type": "TASK", "confidence": 0.9707097411155701}, {"text": "UAR", "start_pos": 38, "end_pos": 41, "type": "METRIC", "confidence": 0.960274875164032}, {"text": "RMSE", "start_pos": 47, "end_pos": 51, "type": "METRIC", "confidence": 0.9390016794204712}, {"text": "IQ recognition", "start_pos": 56, "end_pos": 70, "type": "TASK", "confidence": 0.9409097731113434}, {"text": "error correction", "start_pos": 96, "end_pos": 112, "type": "METRIC", "confidence": 0.9453650116920471}]}]}