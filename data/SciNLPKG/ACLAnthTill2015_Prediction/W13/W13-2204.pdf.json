{"title": [], "abstractContent": [{"text": "This paper describes LIMSI's submissions to the shared WMT'13 translation task.", "labels": [], "entities": [{"text": "WMT'13 translation task", "start_pos": 55, "end_pos": 78, "type": "TASK", "confidence": 0.8223306934038798}]}, {"text": "We report results for French-English, German-English and Spanish-English in both directions.", "labels": [], "entities": []}, {"text": "Our submissions use n-code, an open source system based on bilingual n-grams, and continuous space models in a post-processing step.", "labels": [], "entities": []}, {"text": "The main novelties of this year's participation are the following: our first participation to the Spanish-English task; experiments with source pre-ordering; a tighter integration of continuous space language models using artificial text generation (for Ger-man); and the use of different tuning sets according to the original language of the text to be translated.", "labels": [], "entities": []}], "introductionContent": [{"text": "This paper describes LIMSI's submissions to the shared translation task of the Eighth Workshop on Statistical Machine Translation.", "labels": [], "entities": [{"text": "shared translation task of the Eighth Workshop on Statistical Machine Translation", "start_pos": 48, "end_pos": 129, "type": "TASK", "confidence": 0.6263896199789915}]}, {"text": "LIMSI participated in the French-English, German-English and Spanish-English tasks in both directions.", "labels": [], "entities": [{"text": "LIMSI", "start_pos": 0, "end_pos": 5, "type": "DATASET", "confidence": 0.7620633244514465}]}, {"text": "For this evaluation, we used n-code, an open source inhouse Statistical Machine Translation (SMT) system based on bilingual n-grams 1 , and continuous space models in a post-processing step, both for translation and target language modeling.", "labels": [], "entities": [{"text": "Statistical Machine Translation (SMT)", "start_pos": 60, "end_pos": 97, "type": "TASK", "confidence": 0.8137074112892151}, {"text": "translation and target language modeling", "start_pos": 200, "end_pos": 240, "type": "TASK", "confidence": 0.6092996180057526}]}, {"text": "This paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 contains an overview of the baseline systems built with n-code, including the continuous space models.", "labels": [], "entities": []}, {"text": "As in our previous participations, several steps of data pre-processing, cleaning and filtering are applied, and their improvement took a nonnegligible part of our work.", "labels": [], "entities": []}, {"text": "These steps are summarized in Section 3.", "labels": [], "entities": []}, {"text": "The rest of the paper is devoted to the novelties of the systems submitted this 1 http://ncode.limsi.fr/ year.", "labels": [], "entities": []}, {"text": "Section 4 describes the system developed for our first participation to the Spanish-English translation task in both directions.", "labels": [], "entities": [{"text": "Spanish-English translation task", "start_pos": 76, "end_pos": 108, "type": "TASK", "confidence": 0.7577099402745565}]}, {"text": "To translate from German into English, the impact of source preordering is investigated, and experimental results are reported in Section 5, while for the reverse direction, we explored a text sampling strategy using a 10-gram SOUL model to allow a tighter integration of continuous space models during the translation process (see Section 6).", "labels": [], "entities": []}, {"text": "A final section discusses the main lessons of this study.", "labels": [], "entities": []}], "datasetContent": [{"text": "All reported results are averaged on 3 MERT runs.", "labels": [], "entities": [{"text": "MERT", "start_pos": 39, "end_pos": 43, "type": "METRIC", "confidence": 0.8300502896308899}]}, {"text": "shows the BLEU scores obtained with different corpora setups.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9982643723487854}]}, {"text": "We can observe that using the CommonCrawl corpus improves the performances in both directions, while the impact of the UN data is less important, especially when combined with CommonCrawl.", "labels": [], "entities": [{"text": "CommonCrawl corpus", "start_pos": 30, "end_pos": 48, "type": "DATASET", "confidence": 0.974073737859726}, {"text": "UN data", "start_pos": 119, "end_pos": 126, "type": "DATASET", "confidence": 0.8454426527023315}, {"text": "CommonCrawl", "start_pos": 176, "end_pos": 187, "type": "DATASET", "confidence": 0.9663451313972473}]}, {"text": "The filtering strategy described in Section 4.2 has a slightly positive impact of +0.1 BLEU point for the Spanishto-English direction but yields a 0.2 BLEU point decrease in the opposite direction.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 87, "end_pos": 91, "type": "METRIC", "confidence": 0.9980452060699463}, {"text": "BLEU point decrease", "start_pos": 151, "end_pos": 170, "type": "METRIC", "confidence": 0.9667041103045145}]}, {"text": "For the following experiments, all the available corpora are therefore used: News-Commentary, Europarl, filtered CommonCrawl and UN.", "labels": [], "entities": [{"text": "Europarl", "start_pos": 94, "end_pos": 102, "type": "DATASET", "confidence": 0.9676344394683838}, {"text": "CommonCrawl", "start_pos": 113, "end_pos": 124, "type": "DATASET", "confidence": 0.9265881180763245}, {"text": "UN", "start_pos": 129, "end_pos": 131, "type": "DATASET", "confidence": 0.7707847356796265}]}, {"text": "For each of these corpora, a bilingual n-gram model is estimated and used by n-code as one individual model score.", "labels": [], "entities": []}, {"text": "An additionnal TM is trained on the concatenation all these corpora, resulting in a total of 5 TMs.", "labels": [], "entities": []}, {"text": "Moreover, n-code is able to handle additional \"factored\" bilingual models where the source side words are replaced by the corresponding lemma or even POS tag (.", "labels": [], "entities": []}, {"text": "reports the scores obtained with different settings.", "labels": [], "entities": []}, {"text": "In, big denotes the use of a wider context for n-gram TMs (n = 4, 5, 4 instead of 3, 4, 3 respectively for word-based, POS-based and lemma-based TMs  For English to Spanish, we also experimented with a 5-gram target factored model, using the whole morphosyntactic EAGLES tagset, (pos+ in), to add some syntactic information, but this, in fact, proved harmful.", "labels": [], "entities": []}, {"text": "As several tuning sets were available, experiments were carried outwith the concatenation of nt09 to nt11 as a tuning data set.", "labels": [], "entities": []}, {"text": "This yields an improvement between 0.1 and 0.3 BLEU point when testing on nt12 when translating from Spanish to English.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 47, "end_pos": 51, "type": "METRIC", "confidence": 0.9996225833892822}]}], "tableCaptions": [{"text": " Table 2: BLEU scores for different configuration  of factored translation models. The big prefix de- notes experiments with the larger context for n- gram translation models.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9991679191589355}]}, {"text": " Table 3: BLEU scores for pre-ordering experi- ments with a n-code system and the approach pro- posed by", "labels": [], "entities": [{"text": "BLEU", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9983922839164734}]}, {"text": " Table 4: Impact of the use of sampled texts.", "labels": [], "entities": []}]}