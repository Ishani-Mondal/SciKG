{"title": [{"text": "Towards Joint Morphological Analysis and Dependency Parsing of Turkish", "labels": [], "entities": [{"text": "Morphological Analysis and Dependency Parsing", "start_pos": 14, "end_pos": 59, "type": "TASK", "confidence": 0.7040954411029816}]}], "abstractContent": [{"text": "Turkish is an agglutinative language with rich morphology-syntax interactions.", "labels": [], "entities": []}, {"text": "As an extension of this property, the Turk-ish Treebank is designed to represent sub-lexical dependencies, which brings extra challenges to parsing raw text.", "labels": [], "entities": [{"text": "Turk-ish Treebank", "start_pos": 38, "end_pos": 55, "type": "DATASET", "confidence": 0.9438417851924896}, {"text": "parsing raw text", "start_pos": 140, "end_pos": 156, "type": "TASK", "confidence": 0.8771308859189352}]}, {"text": "In this work, we use a joint POS tagging and parsing approach to parse Turkish raw text, and we show it outperforms a pipeline approach.", "labels": [], "entities": [{"text": "POS tagging and parsing", "start_pos": 29, "end_pos": 52, "type": "TASK", "confidence": 0.7114960104227066}, {"text": "parse Turkish raw text", "start_pos": 65, "end_pos": 87, "type": "TASK", "confidence": 0.8161311000585556}]}, {"text": "Then we experiment with incorporating morphological feature prediction into the joint system.", "labels": [], "entities": [{"text": "morphological feature prediction", "start_pos": 38, "end_pos": 70, "type": "TASK", "confidence": 0.6904072165489197}]}, {"text": "Our results show statistically significant improvements with the joint systems and achieve the state-of-the-art accuracy for Turkish dependency parsing.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 112, "end_pos": 120, "type": "METRIC", "confidence": 0.9995700716972351}, {"text": "Turkish dependency parsing", "start_pos": 125, "end_pos": 151, "type": "TASK", "confidence": 0.5937541325887045}]}], "introductionContent": [{"text": "Turkish is a morphologically rich language (MRL) that has been known to pose interesting research questions to linguists and computational linguists, including architectural issues at the morphologysyntax interface.", "labels": [], "entities": [{"text": "morphologically rich language (MRL)", "start_pos": 13, "end_pos": 48, "type": "TASK", "confidence": 0.7215307553609213}]}, {"text": "Today, good quality tools for morphological analysis are available for analysing Turkish raw text input at the word level, and in work on the Turkish Dependency Treebank (), a representation scheme has been developed that captures the peculiarities at the morphology-syntax interface in a dependency format that is formally compatible with the standard CoNLL dependency format.", "labels": [], "entities": [{"text": "morphological analysis", "start_pos": 30, "end_pos": 52, "type": "TASK", "confidence": 0.7346007227897644}, {"text": "Turkish Dependency Treebank", "start_pos": 142, "end_pos": 169, "type": "DATASET", "confidence": 0.8910480340321859}, {"text": "CoNLL dependency format", "start_pos": 353, "end_pos": 376, "type": "DATASET", "confidence": 0.8421275019645691}]}, {"text": "So, it might seem as if all Turkish-specific challenges have been resolved, and only languageindependent data-driven methods are required from now on (after all, the Turkish Dependency Treebank was included in the, and several researchers working on language-independent methods have reported scores on the available data).", "labels": [], "entities": [{"text": "Turkish Dependency Treebank", "start_pos": 166, "end_pos": 193, "type": "DATASET", "confidence": 0.8942726055781046}]}, {"text": "However, Turkish still causes a considerable architectural challenge for the standard pipeline architecture used in data-driven dependency parsing: the dependency treebank scheme for Turkish is based on segments that are not identical to the words from the raw text input, but are often sublexical units that form parts of morphological derivations.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 128, "end_pos": 146, "type": "TASK", "confidence": 0.7867357134819031}]}, {"text": "While it is straightforward to train data-driven parsers on the gold standard segmentation from the treebank (which is what happened in the shared tasks), any realistic application starting outwith raw text has to involve morphological disambiguation in the preprocessing which means it is not guaranteed that treebank-compatible segment boundaries will be produced.", "labels": [], "entities": []}, {"text": "For instance, when training a dependency parser on predicted POS and morphology features, the treebank is of course used to provide the gold standard dependency arcs, but with an automatic (and hence imperfect) morphological disambiguator, there will be cases where the gold standard assumes two segments fora word, but morphological prediction assumes only one.", "labels": [], "entities": []}, {"text": "So any standard learning algorithm will breakdown because the node sets for the dependency graphs are incompatible.", "labels": [], "entities": []}, {"text": "For many languages, realistic parsing scenarios assume gold tokens and use predicted POS (and morphological features).", "labels": [], "entities": [{"text": "POS", "start_pos": 85, "end_pos": 88, "type": "METRIC", "confidence": 0.9584303498268127}]}, {"text": "For Turkish, keeping the gold segmentation and assigning predicted POS and morphology would converge to using an oracle because gold segmentation would sometimes disambiguate morphology.", "labels": [], "entities": [{"text": "POS", "start_pos": 67, "end_pos": 70, "type": "METRIC", "confidence": 0.9451524615287781}]}, {"text": "Instead, realistic scenarios include segmentation, and a statistical morphological disambiguator picks the most probable analysis among all possibilities a morphological analyser produces.", "labels": [], "entities": [{"text": "segmentation", "start_pos": 37, "end_pos": 49, "type": "TASK", "confidence": 0.972217857837677}]}, {"text": "It is the morphological analysis that determines the lemma, POS, morphological features, and segmentation of a word is based on the number of its word-internal derivations.", "labels": [], "entities": [{"text": "POS", "start_pos": 60, "end_pos": 63, "type": "METRIC", "confidence": 0.9728672504425049}]}, {"text": "For instance, in (1), the middle word bende has four morphological analyses with different lemma and POS combinations, meaning 'at me', 'on the mole', 'to the dam', and 'servant' respectively.", "labels": [], "entities": [{"text": "POS", "start_pos": 101, "end_pos": 104, "type": "METRIC", "confidence": 0.9846300482749939}]}, {"text": "Hence, unlike many other languages, the segmentation, POS tagging, and morphological analysis are tightly connected for Turkish.", "labels": [], "entities": [{"text": "segmentation", "start_pos": 40, "end_pos": 52, "type": "TASK", "confidence": 0.9600650668144226}, {"text": "POS tagging", "start_pos": 54, "end_pos": 65, "type": "TASK", "confidence": 0.8157601356506348}]}, {"text": "Eryi\u02d8 git et al. is the first work that addresses the segmentation problem in parsing predicted text.", "labels": [], "entities": [{"text": "parsing predicted text", "start_pos": 78, "end_pos": 100, "type": "TASK", "confidence": 0.8934735457102457}]}, {"text": "They setup a pipeline architecture of a morphological analyser and disambiguator but leave out handling the multiword expressions.", "labels": [], "entities": []}, {"text": "A recent work from Eryi\u02d8 git (2012) solely focuses on the impact of the morphological analysis and disambiguation of the Turkish treebank.", "labels": [], "entities": [{"text": "Turkish treebank", "start_pos": 121, "end_pos": 137, "type": "DATASET", "confidence": 0.9460447132587433}]}, {"text": "Again, it follows the standard pipeline but this time with a treebank version that represents multiwords as detached segments, which allows avoiding to use a multiword extractor.", "labels": [], "entities": []}, {"text": "The major drawback of a pipeline system is to propagate the disambiguator's mistakes to the parsing step.", "labels": [], "entities": [{"text": "parsing", "start_pos": 92, "end_pos": 99, "type": "TASK", "confidence": 0.96872878074646}]}, {"text": "Moreover, the disambiguator cannot take advantage of syntactic information that could help disambiguate certain morphological analyses.", "labels": [], "entities": []}, {"text": "In (1), the first word kahveleri means 'the coffees (Acc)', 'his/her coffees', 'their (one) coffee', 'their coffees' from (1a) to (1d).", "labels": [], "entities": []}, {"text": "When the first two words come together, they make a sentence meaning 'His/her/their coffees are at my place'.", "labels": [], "entities": []}, {"text": "kahveleri is still ambiguous but its dependency relation is clear; bende, with morphological analysis (1e), behaves as a copular predicate with no overt marker and kahveleri is dependent on bende as a subject.", "labels": [], "entities": []}, {"text": "When the third word i\u00e7elim 'let's drink' follows the former two, the meaning of the sentence changes to 'Let's drink the coffees at my place', which also changes the morphological analysis of kahveleri to (1a).", "labels": [], "entities": []}, {"text": "It now behaves as the object of the main predicate i\u00e7elim.", "labels": [], "entities": []}, {"text": "A pipeline system cannot benefit from such a disambiguation advantage.", "labels": [], "entities": []}, {"text": "An alternative approach to pipeline architectures is making joint decisions on morphological disambiguation and parsing.", "labels": [], "entities": []}, {"text": "It has been shown that such an architecture improves constituency parsing accuracy both for Arabic (Green and Man- ning, 2010) and for Hebrew).", "labels": [], "entities": [{"text": "constituency parsing", "start_pos": 53, "end_pos": 73, "type": "TASK", "confidence": 0.832434743642807}, {"text": "accuracy", "start_pos": 74, "end_pos": 82, "type": "METRIC", "confidence": 0.9096655249595642}]}, {"text": "On the dependency parsing front, introduces a joint morphological disambiguation and dependency parsing architecture which proves to outperform their pipeline architecture for Latin, Ancient Greek, Czech, and Hungarian.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 7, "end_pos": 25, "type": "TASK", "confidence": 0.7957291007041931}, {"text": "dependency parsing", "start_pos": 85, "end_pos": 103, "type": "TASK", "confidence": 0.8030316829681396}]}, {"text": "However it is limited to unlabelled dependency parsing and initial scores are below the state-of-the-art.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 36, "end_pos": 54, "type": "TASK", "confidence": 0.714729368686676}]}, {"text": "On the other hand, parsers that can jointly POS tag become more common in the last years).", "labels": [], "entities": []}, {"text": "propose a joint POS tagger and labelled dependency parser that outperforms the pipeline results and also improves the state-of-the-art accuracy for German, Czech, English, and Chinese.", "labels": [], "entities": [{"text": "POS tagger", "start_pos": 16, "end_pos": 26, "type": "TASK", "confidence": 0.5544008910655975}, {"text": "accuracy", "start_pos": 135, "end_pos": 143, "type": "METRIC", "confidence": 0.9981356859207153}]}, {"text": "Joint POS tagger and dependency parsers are not originally designed for predicting morphological features, but they provide a flexible field (POS) where the parser is not dependent on the morphological disambiguator decisions.", "labels": [], "entities": [{"text": "POS tagger", "start_pos": 6, "end_pos": 16, "type": "TASK", "confidence": 0.6640722453594208}]}, {"text": "So the use of this field can actually be extended to accommodating morphological features instead of or in addition to POS tags, which gives parsers an opportunity to override fixed disambiguator mistakes.", "labels": [], "entities": []}, {"text": "Hence, those parsers approximate to a joint morphological disambiguation and dependency parsing architecture, which provides us with a testbed until genuinely full-fledged joint parsers are developed.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 77, "end_pos": 95, "type": "TASK", "confidence": 0.7393856346607208}]}, {"text": "In this paper we use Bohnet and Nivre's (2012) system to apply their approach to Turkish and later to explore ways to include morphological feature prediction into parsing.", "labels": [], "entities": [{"text": "morphological feature prediction", "start_pos": 126, "end_pos": 158, "type": "TASK", "confidence": 0.6942217151323954}]}, {"text": "Experimental results show that even a partial flexibility in predicting the morphological features helps improve the parsing accuracy statistically significantly.", "labels": [], "entities": [{"text": "parsing", "start_pos": 117, "end_pos": 124, "type": "TASK", "confidence": 0.975411057472229}, {"text": "accuracy", "start_pos": 125, "end_pos": 133, "type": "METRIC", "confidence": 0.9456468224525452}]}, {"text": "The paper is structured as follows: Section 2 gives an overview on how morphological features are used in parsing MRLs.", "labels": [], "entities": [{"text": "parsing MRLs", "start_pos": 106, "end_pos": 118, "type": "TASK", "confidence": 0.9079273641109467}]}, {"text": "Section 3 explains the morphological analysis representation and its relation with segmentation.", "labels": [], "entities": [{"text": "morphological analysis representation", "start_pos": 23, "end_pos": 60, "type": "TASK", "confidence": 0.8309893608093262}]}, {"text": "Section 4 describes the use of morphological features in joint parsing experiments.", "labels": [], "entities": [{"text": "joint parsing", "start_pos": 57, "end_pos": 70, "type": "TASK", "confidence": 0.5921523869037628}]}, {"text": "The setup for experiments are given in Section 5 and results are discussed in Section 6.", "labels": [], "entities": []}, {"text": "We conclude with Section 7.", "labels": [], "entities": []}], "datasetContent": [{"text": "The standard evaluation metrics labelled and unlabelled attachement scores (LAS and UAS)) are not applicable to compare a predicted file to a gold file if the segment sizes are different.", "labels": [], "entities": [{"text": "LAS", "start_pos": 76, "end_pos": 79, "type": "METRIC", "confidence": 0.5088021755218506}, {"text": "UAS", "start_pos": 84, "end_pos": 87, "type": "METRIC", "confidence": 0.5306190252304077}]}, {"text": "We handle this problem by using an evaluation tool based on IGs).", "labels": [], "entities": []}, {"text": "The unlabelled attachement score UAS IG gives the ratio of IGs that are attached to the correct head, and the labelled attachement score LAS IG gives the ratio of IGs attached to the correct head with the correct label.", "labels": [], "entities": [{"text": "UAS IG", "start_pos": 33, "end_pos": 39, "type": "DATASET", "confidence": 0.6070846617221832}, {"text": "labelled attachement score LAS IG", "start_pos": 110, "end_pos": 143, "type": "METRIC", "confidence": 0.6079887270927429}]}, {"text": "In cases where the morphology (segmentation, POS, and morphological features) of the headword is different from the gold one, an attachement is correct only if the dependent is attached to the correct word and the head IG has the gold main POS.", "labels": [], "entities": [{"text": "POS", "start_pos": 45, "end_pos": 48, "type": "METRIC", "confidence": 0.8798795342445374}]}, {"text": "Note that when gold segmentation and POS are used LAS IG and UAS IG are identical to the standard LAS an UAS respectively.", "labels": [], "entities": [{"text": "gold segmentation", "start_pos": 15, "end_pos": 32, "type": "TASK", "confidence": 0.6401744335889816}, {"text": "LAS IG", "start_pos": 50, "end_pos": 56, "type": "METRIC", "confidence": 0.8015005886554718}, {"text": "UAS IG", "start_pos": 61, "end_pos": 67, "type": "METRIC", "confidence": 0.7707410454750061}]}, {"text": "We omit punctuation in evaluation.", "labels": [], "entities": []}, {"text": "We conduct 10-fold cross validation experiments on the training data and report the average scores for pipeline and joint parsers.", "labels": [], "entities": []}, {"text": "Gold settings use gold segmentation, POS, and morphological features, whereas in predicted settings, all this information is predicted (either by the morphological analyser+disambiguator or by the joint parser).", "labels": [], "entities": [{"text": "POS", "start_pos": 37, "end_pos": 40, "type": "METRIC", "confidence": 0.805205225944519}]}, {"text": "For systems we observe improvements on 10-fold cross validation experiments, we also give the test set results.", "labels": [], "entities": []}, {"text": "8  In the first set of experiments, we examine the effect of using morphological features in parsing.", "labels": [], "entities": [{"text": "parsing", "start_pos": 93, "end_pos": 100, "type": "TASK", "confidence": 0.9670198559761047}]}, {"text": "gives the graph-based parser results when both the training and parsing data have morphological information.", "labels": [], "entities": []}, {"text": "The predicted LAS IG is 4.5% lower than the gold one.", "labels": [], "entities": [{"text": "LAS IG", "start_pos": 14, "end_pos": 20, "type": "METRIC", "confidence": 0.873259961605072}]}, {"text": "When the graph-based parser is trained on gold data with morphological features, but the features are not provided during parsing, there are 12.4% and 10.7% LAS IG drops in the gold and predicted settings respectively.", "labels": [], "entities": [{"text": "LAS IG drops", "start_pos": 157, "end_pos": 169, "type": "METRIC", "confidence": 0.9278598427772522}]}, {"text": "A drop in such a scenario is of course expected, but the impact of no morphology in parsing is huge as compared to many other MRLs (e.g., Seeker and Kuhn (2013) report 6.3%, 2.4%, and only 0.4% absolute drops in LAS for Hungarian, Czech, and German respectively).", "labels": [], "entities": [{"text": "parsing", "start_pos": 84, "end_pos": 91, "type": "TASK", "confidence": 0.9730745553970337}, {"text": "LAS", "start_pos": 212, "end_pos": 215, "type": "METRIC", "confidence": 0.9861415028572083}]}, {"text": "When the morphological information is not used in training at all, the parser can cope with the lack of morphological information better during pars-: The effect of using morphological features on the graph-based parser.", "labels": [], "entities": []}, {"text": "Morphological features are used in neither training nor parsing (-T,-P), used in training but not provided in parsing (+T,-P), used both in training and parsing (+T,+P).", "labels": [], "entities": [{"text": "parsing", "start_pos": 56, "end_pos": 63, "type": "TASK", "confidence": 0.9677711129188538}, {"text": "parsing", "start_pos": 153, "end_pos": 160, "type": "TASK", "confidence": 0.9718220829963684}]}, {"text": "Results given are the average 10-fold cross-validation scores on the training data. ing.", "labels": [], "entities": []}, {"text": "Still, the gold and predicted LAS IG scores are absolute 5-6% lower than a setting that uses morphology both in training and parsing.", "labels": [], "entities": [{"text": "LAS IG", "start_pos": 30, "end_pos": 36, "type": "TASK", "confidence": 0.6114613860845566}]}, {"text": "gives the training set 10-fold cross validation average scores for systems we experimented in this paper, as well as for previous work.", "labels": [], "entities": []}, {"text": "It is observed that moving CASE to the POS field helps with a 0.3% absolute increase in the gold pipeline settings.", "labels": [], "entities": [{"text": "CASE", "start_pos": 27, "end_pos": 31, "type": "METRIC", "confidence": 0.5554866790771484}, {"text": "absolute", "start_pos": 67, "end_pos": 75, "type": "METRIC", "confidence": 0.9592181444168091}]}, {"text": "Joint parsing results with gold features, are 1-1.5% absolute lower than the pipeline scores.", "labels": [], "entities": [{"text": "Joint parsing", "start_pos": 0, "end_pos": 13, "type": "TASK", "confidence": 0.47663962841033936}]}, {"text": "This is expected; the gold setting for joint parsing is not exactly gold, as by definition the parser predicts POS tags during parsing instead of gold ones although the segmentation and morphological features are gold.", "labels": [], "entities": [{"text": "joint parsing", "start_pos": 39, "end_pos": 52, "type": "TASK", "confidence": 0.5517221838235855}]}, {"text": "As a result, they cannot beat purely gold settings.", "labels": [], "entities": []}, {"text": "If we have a closer look at the joint systems, we witness that only Joint Case outperforms Joint.", "labels": [], "entities": [{"text": "Joint Case", "start_pos": 68, "end_pos": 78, "type": "DATASET", "confidence": 0.8237735331058502}]}, {"text": "Joint P os+Case increases the tagset to be learned and predicted from 35 to 107 which is probably too fine-grained for the parser.", "labels": [], "entities": [{"text": "Joint P os+Case", "start_pos": 0, "end_pos": 15, "type": "METRIC", "confidence": 0.7323913335800171}]}, {"text": "Agreement markers, which are not directly related to grammatical functions like CASE, have a negative impact in the gold settings when used instead of Verb.", "labels": [], "entities": []}, {"text": "Still, when agreement markers are used only to introduce an extra category, namely VFin, the scores come closer to the baseline of joint parsing with gold information, and even improves over the baseline LAS IG in the predicted setting.", "labels": [], "entities": [{"text": "VFin", "start_pos": 83, "end_pos": 87, "type": "DATASET", "confidence": 0.6643595099449158}, {"text": "LAS IG", "start_pos": 204, "end_pos": 210, "type": "METRIC", "confidence": 0.8965997397899628}]}, {"text": "In the pipeline approach with predicted morphology, using CASE instead of nominal POS im-   proves the labelled accuracy by 0.3% absolute for the training set.", "labels": [], "entities": [{"text": "CASE", "start_pos": 58, "end_pos": 62, "type": "METRIC", "confidence": 0.9155967831611633}, {"text": "POS im-", "start_pos": 82, "end_pos": 89, "type": "METRIC", "confidence": 0.9505488077799479}, {"text": "accuracy", "start_pos": 112, "end_pos": 120, "type": "METRIC", "confidence": 0.8469530344009399}]}, {"text": "Letting the parser predict POS in the joint system adds 0.14 points more.", "labels": [], "entities": [{"text": "POS", "start_pos": 27, "end_pos": 30, "type": "METRIC", "confidence": 0.9659122824668884}]}, {"text": "The best score is achieved with Joint Case which has a 0.3% absolute increase as compared to Joint.", "labels": [], "entities": [{"text": "Joint Case", "start_pos": 32, "end_pos": 42, "type": "METRIC", "confidence": 0.6648348271846771}, {"text": "absolute", "start_pos": 60, "end_pos": 68, "type": "METRIC", "confidence": 0.9635934233665466}, {"text": "Joint", "start_pos": 93, "end_pos": 98, "type": "METRIC", "confidence": 0.966925859451294}]}, {"text": "The difference between pipeline systems and joint systems are statistically significant both for LAS IG and UAS IG , in the gold setting.", "labels": [], "entities": [{"text": "LAS IG", "start_pos": 97, "end_pos": 103, "type": "TASK", "confidence": 0.5889710485935211}, {"text": "UAS IG", "start_pos": 108, "end_pos": 114, "type": "DATASET", "confidence": 0.8687349557876587}]}, {"text": "When predicted data is used, Pipeline Case , Joint, Joint Case LAS IG scores are statistically significantly better than Pipeline (p<0.05, paired t-test).", "labels": [], "entities": [{"text": "Joint Case LAS IG", "start_pos": 52, "end_pos": 69, "type": "METRIC", "confidence": 0.7127518653869629}]}, {"text": "The testset scores are given in.", "labels": [], "entities": []}, {"text": "They follow the training set trend, except for the Joint system to our surprise.", "labels": [], "entities": [{"text": "Joint system", "start_pos": 51, "end_pos": 63, "type": "DATASET", "confidence": 0.8489100933074951}]}, {"text": "This is perhaps due to the different characteristics of test and training data.", "labels": [], "entities": []}, {"text": "When we look at the breakdown of dependencies from 10-fold cross validation results in Section 6.3, we discuss a recall drop in some labels when they are parsed with the Joint parser.", "labels": [], "entities": [{"text": "recall", "start_pos": 113, "end_pos": 119, "type": "METRIC", "confidence": 0.9985694885253906}]}, {"text": "We do not look at the dependency distribution of the test data but if it is different from the training data then a possibly similar drop in the same labels might impact the overall score more.", "labels": [], "entities": []}, {"text": "In parsing the test data with gold features, pipeline systems statistically significantly outperform joint systems.", "labels": [], "entities": []}, {"text": "In the predicted setting, only Joint vs. JointCase UAS IG difference is statistically significant.", "labels": [], "entities": [{"text": "JointCase UAS IG", "start_pos": 41, "end_pos": 57, "type": "TASK", "confidence": 0.6060090661048889}]}, {"text": "Both in, predicted LAS IG scores from Eryi\u02d8 git (2012) are given as an interval.", "labels": [], "entities": [{"text": "LAS IG", "start_pos": 19, "end_pos": 25, "type": "TASK", "confidence": 0.5897852927446365}, {"text": "Eryi\u02d8 git (2012)", "start_pos": 38, "end_pos": 54, "type": "DATASET", "confidence": 0.8342971702416738}]}, {"text": "In her experiments, the parser is trained on the original treebank (that is, no MWE relations are present in the training data) and tested on the detached version.", "labels": [], "entities": []}, {"text": "She reports lower and upper bounds corresponding 0% and 100% accuracy for MWE relations.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 61, "end_pos": 69, "type": "METRIC", "confidence": 0.9635750651359558}, {"text": "MWE relations", "start_pos": 74, "end_pos": 87, "type": "TASK", "confidence": 0.8660201132297516}]}, {"text": "To compare our results to those of Eryi\u02d8 git's, we also calculate the upper bounds with 100% MWE accuracy in our best performing system.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 97, "end_pos": 105, "type": "METRIC", "confidence": 0.7826152443885803}]}, {"text": "When we accept all MWE labels correct 9 we achieve 64.49% LAS IG on the average score of 10-fold cross validation on the training set and 66.46% LAS IG on the testset for the Joint Case system.", "labels": [], "entities": [{"text": "LAS IG", "start_pos": 58, "end_pos": 64, "type": "METRIC", "confidence": 0.8083624839782715}, {"text": "LAS IG", "start_pos": 145, "end_pos": 151, "type": "METRIC", "confidence": 0.9255959093570709}]}, {"text": "For both the predicted and gold systems our parsers outperform previous work.", "labels": [], "entities": []}, {"text": "For comparability with other existing results, we also trained the Pipeline parser on the original version of the treebank which is used in the CoNLL 2007 Shared Task.", "labels": [], "entities": [{"text": "CoNLL 2007 Shared Task", "start_pos": 144, "end_pos": 166, "type": "DATASET", "confidence": 0.907209038734436}]}, {"text": "report 71.6% LAS on the testset (excluding punctuation) for the best system.", "labels": [], "entities": [{"text": "LAS", "start_pos": 13, "end_pos": 16, "type": "METRIC", "confidence": 0.9985563158988953}]}, {"text": "Eryi\u02d8 git (2012) increases the LAS to 71.98% and the Pipeline parser outperform both systems with 72.53% LAS .", "labels": [], "entities": [{"text": "Eryi\u02d8 git (2012)", "start_pos": 0, "end_pos": 16, "type": "DATASET", "confidence": 0.887114942073822}, {"text": "LAS", "start_pos": 31, "end_pos": 34, "type": "METRIC", "confidence": 0.949356734752655}, {"text": "Pipeline parser", "start_pos": 53, "end_pos": 68, "type": "TASK", "confidence": 0.6915670782327652}]}], "tableCaptions": [{"text": " Table 1: The effect of using morphological fea- tures on the graph-based parser. Morphologi- cal features are used in neither training nor pars- ing (-T,-P), used in training but not provided in  parsing (+T,-P), used both in training and pars- ing (+T,+P). Results given are the average 10-fold  cross-validation scores on the training data.", "labels": [], "entities": []}, {"text": " Table 2: Training set 10-fold cross validation av- erage scores. Gold scores Ery11 are taken from  Eryi\u02d8 git et al. (2011) and predicted scores Ery12  are taken from Eryi\u02d8 git (2012). Ery12 (Eryi\u02d8 git,  2012) gives an interval LAS IG corresponding 0%  and 100% accuracy for MWE relations", "labels": [], "entities": [{"text": "Eryi\u02d8 git,  2012)", "start_pos": 192, "end_pos": 209, "type": "DATASET", "confidence": 0.7605216999848684}, {"text": "LAS IG", "start_pos": 228, "end_pos": 234, "type": "METRIC", "confidence": 0.8903293311595917}, {"text": "accuracy", "start_pos": 262, "end_pos": 270, "type": "METRIC", "confidence": 0.996788501739502}, {"text": "MWE", "start_pos": 275, "end_pos": 278, "type": "TASK", "confidence": 0.843363344669342}]}, {"text": " Table 3: Testset scores. Ery11 (Eryi\u02d8 git et al.,  2011) does not provide gold scores for testset.  Ery12 (Eryi\u02d8 git, 2012) gives an interval LAS IG  corresponding 0% and 100% accuracy for MWE  relations.", "labels": [], "entities": [{"text": "Ery11 (Eryi\u02d8 git et al.,  2011)", "start_pos": 26, "end_pos": 57, "type": "DATASET", "confidence": 0.8344056248664856}, {"text": "LAS IG", "start_pos": 143, "end_pos": 149, "type": "METRIC", "confidence": 0.8952680826187134}, {"text": "accuracy", "start_pos": 177, "end_pos": 185, "type": "METRIC", "confidence": 0.9964323043823242}, {"text": "MWE  relations", "start_pos": 190, "end_pos": 204, "type": "TASK", "confidence": 0.8522118628025055}]}, {"text": " Table 4: The dependency breakdown of the 10- fold cross validation scores for Joint Case with pre- dicted morphological information. Precision and  recall are given in percent. Dependencies with less  than 100 occurrences are omitted.", "labels": [], "entities": [{"text": "Precision", "start_pos": 134, "end_pos": 143, "type": "METRIC", "confidence": 0.9967009425163269}, {"text": "recall", "start_pos": 149, "end_pos": 155, "type": "METRIC", "confidence": 0.9991428852081299}]}]}