{"title": [], "abstractContent": [{"text": "The task of Named Entity Recognition (NER) is to identify in text predefined units of information such as person names, organizations and locations.", "labels": [], "entities": [{"text": "Named Entity Recognition (NER)", "start_pos": 12, "end_pos": 42, "type": "TASK", "confidence": 0.8155571768681208}]}, {"text": "In this work, we address the problem of NER in Esto-nian using supervised learning approach.", "labels": [], "entities": [{"text": "NER", "start_pos": 40, "end_pos": 43, "type": "TASK", "confidence": 0.9884070754051208}]}, {"text": "We explore common issues related to building a NER system such as the usage of language-agnostic and language-specific features, the representation of named entity tags, the required corpus size and the need for linguistic tools.", "labels": [], "entities": []}, {"text": "For system training and evaluation purposes, we create a gold standard NER corpus.", "labels": [], "entities": [{"text": "NER corpus", "start_pos": 71, "end_pos": 81, "type": "DATASET", "confidence": 0.8177667856216431}]}, {"text": "On this corpus, our CRF-based system achieves an overall F 1-score of 87%.", "labels": [], "entities": [{"text": "F 1-score", "start_pos": 57, "end_pos": 66, "type": "METRIC", "confidence": 0.9917362332344055}]}], "introductionContent": [{"text": "Named Entity Recognition (NER) is the task of identification of information units in text such as person names, organizations and locations.", "labels": [], "entities": [{"text": "Named Entity Recognition (NER)", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.7895574669043223}, {"text": "identification of information units in text such as person names, organizations and locations", "start_pos": 46, "end_pos": 139, "type": "TASK", "confidence": 0.5976659634283611}]}, {"text": "It is an important subtask in many natural language processing (NLP) applications such as text summarization, information filtering, relation extraction and question answering.", "labels": [], "entities": [{"text": "text summarization", "start_pos": 90, "end_pos": 108, "type": "TASK", "confidence": 0.7652027904987335}, {"text": "information filtering", "start_pos": 110, "end_pos": 131, "type": "TASK", "confidence": 0.8384867012500763}, {"text": "relation extraction", "start_pos": 133, "end_pos": 152, "type": "TASK", "confidence": 0.8913449645042419}, {"text": "question answering", "start_pos": 157, "end_pos": 175, "type": "TASK", "confidence": 0.917625367641449}]}, {"text": "NER has been extensively studied for widely spoken languages such as English with the state-of-the-art systems achieving near-human performance), but no research has yet been done in regards to Estonian.", "labels": [], "entities": [{"text": "NER", "start_pos": 0, "end_pos": 3, "type": "TASK", "confidence": 0.7944000363349915}]}, {"text": "The main difference of Estonian, a Finno-Ugric language, compared to English is high morphological richness.", "labels": [], "entities": []}, {"text": "Estonian is a synthetic language and has relatively high morpheme-per-word ratio.", "labels": [], "entities": []}, {"text": "It has both agglutinative and fusional (inflective) elements: morphemes can express one or more syntactic categories of the word.", "labels": [], "entities": []}, {"text": "Although Estonian is considered a subject-verb-object (SVO) language, all phrase permutations are legal and widely used.", "labels": [], "entities": []}, {"text": "These factors make NLP for Estonian particularly complicated.", "labels": [], "entities": [{"text": "NLP", "start_pos": 19, "end_pos": 22, "type": "TASK", "confidence": 0.9473698735237122}]}, {"text": "In this work, we address the problem of NER in Estonian using supervised learning approach.", "labels": [], "entities": [{"text": "NER", "start_pos": 40, "end_pos": 43, "type": "TASK", "confidence": 0.9795923829078674}]}, {"text": "We explore common issues related to building a NER system such as the usage of language-agnostic and language-specific features, the representation of named entity tags, the required corpus size and the need for linguistic tools.", "labels": [], "entities": []}, {"text": "To train and evaluate our system, we have created a gold standard NER corpus of Estonian news stories, in which we manually annotated occurrences of locations, persons and organizations.", "labels": [], "entities": [{"text": "NER corpus of Estonian news stories", "start_pos": 66, "end_pos": 101, "type": "DATASET", "confidence": 0.8677091598510742}]}, {"text": "Our system, based on Conditional Random Fields, achieves an overall cross-validation F 1 -score of 87%, which is compatible with results reported for similar languages.", "labels": [], "entities": [{"text": "cross-validation F 1 -score", "start_pos": 68, "end_pos": 95, "type": "METRIC", "confidence": 0.7843846559524537}]}, {"text": "The concept of NER originated in the 1990s in the course of the Message Understanding Conferences (, and since then there has been a steady increase in research boosted by evaluation programs such as CoNLL) and ACE).", "labels": [], "entities": [{"text": "NER", "start_pos": 15, "end_pos": 18, "type": "TASK", "confidence": 0.9772111177444458}, {"text": "Message Understanding Conferences", "start_pos": 64, "end_pos": 97, "type": "TASK", "confidence": 0.8233048717180887}, {"text": "CoNLL", "start_pos": 200, "end_pos": 205, "type": "DATASET", "confidence": 0.8662206530570984}, {"text": "ACE", "start_pos": 211, "end_pos": 214, "type": "DATASET", "confidence": 0.8578370809555054}]}, {"text": "The earliest works mainly involved using hand-crafted linguistic rules.", "labels": [], "entities": []}, {"text": "Rule-based systems typically achieve high precision, but suffer low coverage, are laborious to build and and not easily portable to new text domains (.", "labels": [], "entities": [{"text": "precision", "start_pos": 42, "end_pos": 51, "type": "METRIC", "confidence": 0.9954603314399719}, {"text": "coverage", "start_pos": 68, "end_pos": 76, "type": "METRIC", "confidence": 0.975959837436676}]}, {"text": "The current dominant approach for addressing NER problem is supervised machine learning).", "labels": [], "entities": [{"text": "NER problem", "start_pos": 45, "end_pos": 56, "type": "TASK", "confidence": 0.886356770992279}]}, {"text": "Such systems generally read a large annotated corpus and induce disambiguation rules based on discriminative features.", "labels": [], "entities": []}, {"text": "Frequently used techniques include Hidden Markov Models (, Maximum Entropy Models ( and Linear Chain Conditional Random Fields.", "labels": [], "entities": []}, {"text": "The downside of supervised learning is the need fora large, annotated training corpus.", "labels": [], "entities": []}, {"text": "Recently, some research has been done on NER for highly inflective and morphologically rich languages similar to Estonian.", "labels": [], "entities": [{"text": "NER", "start_pos": 41, "end_pos": 44, "type": "TASK", "confidence": 0.9365991353988647}]}, {"text": "report F 1 -score of 95% for Hungarian in business news domain using a Maximum Entropy classifier.", "labels": [], "entities": [{"text": "F 1 -score", "start_pos": 7, "end_pos": 17, "type": "METRIC", "confidence": 0.9616445153951645}]}, {"text": "Notably, authors state that morphological preprocessing only slightly improves the overall performance.", "labels": [], "entities": []}, {"text": "also use Maximum Entropy based approach for NER in Czech achieving 79% F 1 -score.", "labels": [], "entities": [{"text": "NER", "start_pos": 44, "end_pos": 47, "type": "TASK", "confidence": 0.9066411256790161}, {"text": "F 1 -score", "start_pos": 71, "end_pos": 81, "type": "METRIC", "confidence": 0.9840962439775467}]}, {"text": "Pinnis (2012) reports F-score of 60% and 65% for Latvian and Lithuanian languages respectively using CRF classifier with morphological preprocessing and some custom refinements.", "labels": [], "entities": [{"text": "F-score", "start_pos": 22, "end_pos": 29, "type": "METRIC", "confidence": 0.9991135001182556}]}, {"text": "K\u00fc\u00e7K\u00fc\u00e7\u00a8K\u00fc\u00e7\u00fck and others (2009) describe a rule-based NER system for Turkish language which achieves F 1 -score of 79%.", "labels": [], "entities": [{"text": "NER", "start_pos": 53, "end_pos": 56, "type": "TASK", "confidence": 0.9431996941566467}, {"text": "F 1 -score", "start_pos": 100, "end_pos": 110, "type": "METRIC", "confidence": 0.9905905276536942}]}, {"text": "We observe that the reported results are notably inferior compared to well-studied languages such as English.", "labels": [], "entities": []}, {"text": "This can be explained by the language complexity and the lack of required linguistic tools and annotated corpora.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section, we conduct a number of experiments to investigate the system behavior with respect to different factors.", "labels": [], "entities": []}, {"text": "We assess system performance using standard precision, recall and F 1 measure.", "labels": [], "entities": [{"text": "precision", "start_pos": 44, "end_pos": 53, "type": "METRIC", "confidence": 0.9990702271461487}, {"text": "recall", "start_pos": 55, "end_pos": 61, "type": "METRIC", "confidence": 0.9996898174285889}, {"text": "F 1 measure", "start_pos": 66, "end_pos": 77, "type": "METRIC", "confidence": 0.9870044191678365}]}, {"text": "Scores for individual entity types are obtained by averaging results of 10-fold cross-validation on the full dataset.", "labels": [], "entities": []}, {"text": "When splitting the data, document bounds are taken into account so that content of a single document fully falls either into training or test set.", "labels": [], "entities": []}, {"text": "In this way, we minimize terminology transfer between samples used for training and testing.", "labels": [], "entities": [{"text": "terminology transfer", "start_pos": 25, "end_pos": 45, "type": "TASK", "confidence": 0.7709768116474152}]}, {"text": "To summarize the results of an experiment with a single number, we report the weighted average of a corresponding measure overall entity types.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Number of named entities in the corpus.", "labels": [], "entities": []}, {"text": " Table 2: Dictionaries and numbers of entries.", "labels": [], "entities": []}, {"text": " Table 3: End system performance using BIO and  BILOU tag representation schemes. BILOU out- performs BIO (p-value 0.04).", "labels": [], "entities": [{"text": "BILOU", "start_pos": 48, "end_pos": 53, "type": "METRIC", "confidence": 0.9267579317092896}, {"text": "BILOU", "start_pos": 82, "end_pos": 87, "type": "METRIC", "confidence": 0.9821934700012207}, {"text": "BIO", "start_pos": 102, "end_pos": 105, "type": "METRIC", "confidence": 0.9085515141487122}]}, {"text": " Table 4: System performance using different  groups of features.", "labels": [], "entities": []}, {"text": " Table 5. It is worth mentioning, that  we have also attempted to do automatic feature se- lection using \u03c7 2 -test and by discarding infrequent  features. However, both methods resulted in a sig- nificant loss of performance.", "labels": [], "entities": []}]}