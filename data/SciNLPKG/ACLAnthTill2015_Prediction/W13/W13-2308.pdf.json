{"title": [{"text": "Converting Italian Treebanks: Towards an Italian Stanford Dependency Treebank", "labels": [], "entities": [{"text": "Converting", "start_pos": 0, "end_pos": 10, "type": "TASK", "confidence": 0.8839406371116638}, {"text": "Italian Treebanks", "start_pos": 11, "end_pos": 28, "type": "DATASET", "confidence": 0.8018470108509064}, {"text": "Italian Stanford Dependency Treebank", "start_pos": 41, "end_pos": 77, "type": "DATASET", "confidence": 0.7891202569007874}]}], "abstractContent": [{"text": "The paper addresses the challenge of converting MIDT, an existing dependency-based Italian treebank resulting from the harmonization and merging of smaller resources , into the Stanford Dependencies annotation formalism, with the final aim of constructing a standard-compliant resource for the Italian language.", "labels": [], "entities": []}, {"text": "Achieved results include a methodology for converting treebank annotations belonging to the same dependency-based family, the Italian Stanford Dependency Treebank (ISDT), and an Italian localization of the Stanford Dependency scheme.", "labels": [], "entities": [{"text": "Stanford Dependency Treebank (ISDT)", "start_pos": 134, "end_pos": 169, "type": "DATASET", "confidence": 0.8360450565814972}, {"text": "Stanford Dependency scheme", "start_pos": 206, "end_pos": 232, "type": "DATASET", "confidence": 0.9557595252990723}]}], "introductionContent": [{"text": "The limited availability of training resources is a widely acknowledged bottleneck for machine learning approaches for Natural Language Processing (NLP).", "labels": [], "entities": [{"text": "Natural Language Processing (NLP)", "start_pos": 119, "end_pos": 152, "type": "TASK", "confidence": 0.7344208161036173}]}, {"text": "This is also the case of dependency treebanks within statistical dependency parsing.", "labels": [], "entities": [{"text": "statistical dependency parsing", "start_pos": 53, "end_pos": 83, "type": "TASK", "confidence": 0.638923168182373}]}, {"text": "Moreover, the availability of a treebank in a standard format strongly improves its usefulness, increasing the number of tasks for which it can be exploited and allowing the application of a larger variety of tools.", "labels": [], "entities": []}, {"text": "It also has an impact on the reliability of achieved results, and, last but not least, it permits comparability with other resources.", "labels": [], "entities": [{"text": "reliability", "start_pos": 29, "end_pos": 40, "type": "METRIC", "confidence": 0.9781372547149658}]}, {"text": "This motivated a variety of initiatives devoted to the definition of standards for the linguistic annotation of corpora.", "labels": [], "entities": []}, {"text": "Since the early 1990s, different initiatives have been devoted to the definition of standards for the linguistic annotation of corpora with a specific view to re-using and merging existing treebanks.", "labels": [], "entities": []}, {"text": "The starting point is represented by the EAGLES (Expert Advisory Groups on Language Engineering Standards) initiative, which ended up with providing provisional standard guidelines (, operating at the level of both content (i.e. the linguistic categories) and encoding format.", "labels": [], "entities": [{"text": "EAGLES", "start_pos": 41, "end_pos": 47, "type": "METRIC", "confidence": 0.8516821265220642}]}, {"text": "More recent initiatives, e.g. LAF/GrAF ( and SynAF) representing on-going ISO TC37/SC4 standardization activities 1 , rather focused on the definition of a pivot format capable of representing diverse annotation types of varying complexity without providing specifications for the annotation of content categories (i.e., the labels describing the associated linguistic phenomena), for which standardization appeared since the beginning to be a much trickier matter.", "labels": [], "entities": [{"text": "ISO TC37/SC4 standardization", "start_pos": 74, "end_pos": 102, "type": "DATASET", "confidence": 0.728419053554535}, {"text": "standardization", "start_pos": 391, "end_pos": 406, "type": "TASK", "confidence": 0.9613385200500488}]}, {"text": "Recently, other standardization efforts such as ISOCat () tackled this latter issue by providing a set of data categories at various levels of granularity, each accompanied by a precise definition of its linguistic meaning.", "labels": [], "entities": [{"text": "ISOCat", "start_pos": 48, "end_pos": 54, "type": "DATASET", "confidence": 0.935235321521759}]}, {"text": "Unfortunately, the set of dependency categories within ISOCat is still basic and restricted.", "labels": [], "entities": [{"text": "ISOCat", "start_pos": 55, "end_pos": 61, "type": "DATASET", "confidence": 0.9193863868713379}]}, {"text": "We can thus conclude that as far as content categories are concerned de jure standards are not suitable at the moment for being used in the harmonization and merging of real dependency treebanks.", "labels": [], "entities": []}, {"text": "The alternative to de jure standards is represented by de facto standards.", "labels": [], "entities": []}, {"text": "For what concerns dependency-based annotation, which in the recent past has been increasingly exploited fora wide range of NLP-based information extraction tasks, the Stanford Dependency (SD) scheme () is gaining popularity as a de facto standard.", "labels": [], "entities": [{"text": "NLP-based information extraction tasks", "start_pos": 123, "end_pos": 161, "type": "TASK", "confidence": 0.7036901116371155}]}, {"text": "Among the contexts where SD has been applied, we can observe e.g. parsers and corpora exploited in biomedical information extraction, where it has been suggested to be a suitable unifying syntax formalism for several incompatible syntactic annotation schemes (.", "labels": [], "entities": [{"text": "biomedical information extraction", "start_pos": 99, "end_pos": 132, "type": "TASK", "confidence": 0.6236777802308401}]}, {"text": "SD has already been applied to different languages, e.g. Finnish in the Turku treebank, Swedish in the Talbanken treebank 2 , Chinese in the Classical Chinese Literature treebank or Persian in the Uppsala Persian Dependency Treebank (.", "labels": [], "entities": [{"text": "SD", "start_pos": 0, "end_pos": 2, "type": "TASK", "confidence": 0.942798912525177}, {"text": "Turku treebank", "start_pos": 72, "end_pos": 86, "type": "DATASET", "confidence": 0.7883766293525696}, {"text": "Talbanken treebank 2", "start_pos": 103, "end_pos": 123, "type": "DATASET", "confidence": 0.8096762100855509}, {"text": "Classical Chinese Literature treebank", "start_pos": 141, "end_pos": 178, "type": "DATASET", "confidence": 0.748162567615509}, {"text": "Uppsala Persian Dependency Treebank", "start_pos": 197, "end_pos": 232, "type": "DATASET", "confidence": 0.9260921627283096}]}, {"text": "In this paper, we describe the conversion of an existing Italian resource into the SD annotation scheme, with the final aim of developing a standard-compliant treebank, the Italian Stanford Dependency Treebank (ISDT).", "labels": [], "entities": [{"text": "Italian Stanford Dependency Treebank (ISDT)", "start_pos": 173, "end_pos": 216, "type": "DATASET", "confidence": 0.8191965648106166}]}, {"text": "The reference resource, called Merged Italian Dependency Treebank (MIDT), is the result of a previous effort in the direction of improving interoperability of data sets available for Italian by harmonizing and merging two existing dependency-based resources, i.e. TUT and ISST-TANL, adopting incompatible annotation schemes.", "labels": [], "entities": [{"text": "Merged Italian Dependency Treebank (MIDT)", "start_pos": 31, "end_pos": 72, "type": "DATASET", "confidence": 0.6664130049092429}, {"text": "TUT", "start_pos": 264, "end_pos": 267, "type": "DATASET", "confidence": 0.8021931648254395}]}, {"text": "The two conversion steps are visualized in: note that in both of them the focus is on the conversion and merging of the content of linguistic annotation; for what concerns the representation format, all involved treebanks follow the CoNLL tab-separated format) which nowadays represents a de facto standard within the international dependency parsing community.", "labels": [], "entities": [{"text": "CoNLL tab-separated format", "start_pos": 233, "end_pos": 259, "type": "DATASET", "confidence": 0.836829682191213}, {"text": "international dependency parsing", "start_pos": 318, "end_pos": 350, "type": "TASK", "confidence": 0.6066675583521525}]}, {"text": "In this paper, we deal with the second step, focusing on the MIDT to ISDT conversion.", "labels": [], "entities": [{"text": "MIDT to ISDT conversion", "start_pos": 61, "end_pos": 84, "type": "TASK", "confidence": 0.6792105063796043}]}, {"text": "http://medialab.di.unipi.it/wiki/MIDT/.", "labels": [], "entities": [{"text": "MIDT", "start_pos": 33, "end_pos": 37, "type": "METRIC", "confidence": 0.8083182573318481}]}, {"text": "In this conversion process, we had to deal with the peculiarities of the Italian language: the tackled issues range from morphological richness, presence of clitic pronouns to relatively free word order and pro-drop, all properties requiring specific annotation strategies to be dealt with.", "labels": [], "entities": []}, {"text": "Therefore, a byproduct of this conversion process is represented by the specialization of the SD annotation scheme with respect to Italian.", "labels": [], "entities": []}, {"text": "In the following sections, after briefly describing the methodology applied for the development of the MIDT resource (Section 2), we focus on a comparative analysis of the MIDT and SD annotation schemes (Section 3) followed by a description of the implemented conversion process (Section 4).", "labels": [], "entities": [{"text": "MIDT resource", "start_pos": 103, "end_pos": 116, "type": "DATASET", "confidence": 0.7353992760181427}]}, {"text": "Finally, we present the results obtained by training a parsing system on the newly developed resource (Section 5).", "labels": [], "entities": [{"text": "parsing", "start_pos": 55, "end_pos": 62, "type": "TASK", "confidence": 0.9634140729904175}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Parsing results with ISDT resources", "labels": [], "entities": [{"text": "Parsing", "start_pos": 10, "end_pos": 17, "type": "TASK", "confidence": 0.9664507508277893}, {"text": "ISDT", "start_pos": 31, "end_pos": 35, "type": "DATASET", "confidence": 0.6934841275215149}]}]}