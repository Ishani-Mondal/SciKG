{"title": [{"text": "NAIST at 2013 CoNLL Grammatical Error Correction Shared Task", "labels": [], "entities": [{"text": "NAIST at 2013 CoNLL Grammatical Error Correction Shared Task", "start_pos": 0, "end_pos": 60, "type": "DATASET", "confidence": 0.8524315555890402}]}], "abstractContent": [{"text": "This paper describes the Nara Institute of Science and Technology (NAIST) error correction system in the CoNLL 2013 Shared Task.", "labels": [], "entities": [{"text": "Nara Institute of Science and Technology (NAIST) error correction", "start_pos": 25, "end_pos": 90, "type": "TASK", "confidence": 0.9019081375815652}, {"text": "CoNLL 2013 Shared Task", "start_pos": 105, "end_pos": 127, "type": "DATASET", "confidence": 0.8210841119289398}]}, {"text": "We constructed three systems: a system based on the Treelet Language Model for verb form and subject-verb agreement errors; a classifier trained on both learner and native corpora for noun number errors; a statistical machine translation (SMT)-based model for preposition and determiner errors.", "labels": [], "entities": [{"text": "statistical machine translation (SMT)-", "start_pos": 206, "end_pos": 244, "type": "TASK", "confidence": 0.7639194081226984}]}, {"text": "As for subject-verb agreement errors, we show that the Treelet Language Model-based approach can correct errors in which the target verb is distant from its subject.", "labels": [], "entities": []}, {"text": "Our system ranked fourth on the official run.", "labels": [], "entities": []}], "introductionContent": [{"text": "Grammatical error correction is the task of automatically detecting and correcting grammatical errors in text, especially text written by second language learners.", "labels": [], "entities": [{"text": "Grammatical error correction", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.8145314256350199}, {"text": "automatically detecting and correcting grammatical errors in text, especially text written by second language learners", "start_pos": 44, "end_pos": 162, "type": "TASK", "confidence": 0.6934900842607021}]}, {"text": "Its purpose is to assist learners in writing and helps them learn languages.", "labels": [], "entities": []}, {"text": "Last year, HOO 2012 () was held as a shared task on grammatical error correction, focusing on prepositions and determiners.", "labels": [], "entities": [{"text": "HOO 2012", "start_pos": 11, "end_pos": 19, "type": "DATASET", "confidence": 0.5691878795623779}, {"text": "grammatical error correction", "start_pos": 52, "end_pos": 80, "type": "TASK", "confidence": 0.6072131097316742}]}, {"text": "The CoNLL-2013 shared task () includes these areas and also noun number, verb form, and subject-verb agreement errors.", "labels": [], "entities": []}, {"text": "We divide the above 5 error types into three groups: (1) subject-verb agreement (SVA) and verb form (Vform) errors, (2) noun number (Nn) errors, and (3) preposition (Prep) and determiner (ArtOrDet) errors.", "labels": [], "entities": [{"text": "noun number (Nn) errors", "start_pos": 120, "end_pos": 143, "type": "METRIC", "confidence": 0.6502276410659155}]}, {"text": "For the subject-verb agreement and verb form errors, we used a syntactic language model, the Treelet Language Model, because syntactic information is important for verb error correction.", "labels": [], "entities": [{"text": "verb error correction", "start_pos": 164, "end_pos": 185, "type": "TASK", "confidence": 0.6149395108222961}]}, {"text": "For the noun number errors, we used a binary classifier trained on both learner and native corpora.", "labels": [], "entities": []}, {"text": "For the preposition and determiner errors, we adopt a statistical machine translation (SMT)-based approach, aiming at correcting errors in conventional expressions.", "labels": [], "entities": [{"text": "statistical machine translation (SMT)-", "start_pos": 54, "end_pos": 92, "type": "TASK", "confidence": 0.7634669691324234}]}, {"text": "After each subsystem corrects the errors of the corresponding error types, we merge the outputs of all the subsystems.", "labels": [], "entities": []}, {"text": "The result shows our system achieved 21.85 in F-score on the formal run before revision and 28.14 after revision.", "labels": [], "entities": [{"text": "F-score", "start_pos": 46, "end_pos": 53, "type": "METRIC", "confidence": 0.9988969564437866}]}, {"text": "The rest of this paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 presents an overview of related work.", "labels": [], "entities": []}, {"text": "Section 3 describes the system architecture of each of the three subsystems.", "labels": [], "entities": []}, {"text": "Section 4 shows experimental settings and results.", "labels": [], "entities": []}, {"text": "Section 6 concludes this paper.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 4: Results of the submitted system for each type of error and results of additional experiments  with the SMT-based system. The score is evaluated on the m2scorer", "labels": [], "entities": [{"text": "SMT-based", "start_pos": 113, "end_pos": 122, "type": "TASK", "confidence": 0.961451530456543}, {"text": "m2scorer", "start_pos": 161, "end_pos": 169, "type": "DATASET", "confidence": 0.8858944177627563}]}]}