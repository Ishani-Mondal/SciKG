{"title": [{"text": "LIG System for WMT13 QE Task: Investigating the Usefulness of Features in Word Confidence Estimation for MT", "labels": [], "entities": [{"text": "LIG", "start_pos": 0, "end_pos": 3, "type": "METRIC", "confidence": 0.8111572861671448}, {"text": "WMT13 QE", "start_pos": 15, "end_pos": 23, "type": "TASK", "confidence": 0.5760821551084518}, {"text": "Word Confidence Estimation", "start_pos": 74, "end_pos": 100, "type": "TASK", "confidence": 0.7438151041666666}, {"text": "MT", "start_pos": 105, "end_pos": 107, "type": "TASK", "confidence": 0.9516295790672302}]}], "abstractContent": [{"text": "This paper presents the LIG's systems submitted for Task 2 of WMT13 Quality Estimation campaign.", "labels": [], "entities": [{"text": "WMT13 Quality Estimation", "start_pos": 62, "end_pos": 86, "type": "TASK", "confidence": 0.6440184712409973}]}, {"text": "This is a word confidence estimation (WCE) task where each participant was asked to label each word in a translated text as a binary (Keep/Change) or multi-class (Keep/Substitute/Delete) category.", "labels": [], "entities": [{"text": "word confidence estimation (WCE) task", "start_pos": 10, "end_pos": 47, "type": "TASK", "confidence": 0.7597751617431641}]}, {"text": "We integrate a number of features of various types (system-based, lexical, syntactic and semantic) into the conventional feature set, for our baseline classifier training.", "labels": [], "entities": []}, {"text": "After the experiments with all features, we deploy a \"Feature Selection\" strategy to keep only the best performing ones.", "labels": [], "entities": []}, {"text": "Then, a method that combines multiple \"weak\" classifiers to build a strong \"com-posite\" classifier by taking advantage of their complementarity is presented and experimented.", "labels": [], "entities": []}, {"text": "We then select the best systems for submission and present the official results obtained.", "labels": [], "entities": []}], "introductionContent": [{"text": "Recently Statistical Machine Translation (SMT) systems have shown impressive gains with many fruitful results.", "labels": [], "entities": [{"text": "Statistical Machine Translation (SMT)", "start_pos": 9, "end_pos": 46, "type": "TASK", "confidence": 0.8692597448825836}]}, {"text": "While the outputs are more acceptable, the end users still face the need to post edit (or not) an automatic translation.", "labels": [], "entities": []}, {"text": "Then, the issue is to be able to accurately identify the correct parts as well as detecting translation errors.", "labels": [], "entities": [{"text": "detecting translation", "start_pos": 82, "end_pos": 103, "type": "TASK", "confidence": 0.6608222126960754}]}, {"text": "If we focus on errors at the word level, the issue is called Word-level Confidence Estimation (WCE).", "labels": [], "entities": [{"text": "Word-level Confidence Estimation (WCE)", "start_pos": 61, "end_pos": 99, "type": "TASK", "confidence": 0.7250155458847681}]}, {"text": "In WMT 2013, a shared task about quality estimation is proposed.", "labels": [], "entities": [{"text": "WMT 2013", "start_pos": 3, "end_pos": 11, "type": "DATASET", "confidence": 0.7797046303749084}]}, {"text": "This quality estimation task is proposed at two levels: word-level and sentencelevel.", "labels": [], "entities": []}, {"text": "Our work focuses on the word-level quality estimation (named Task 2).", "labels": [], "entities": [{"text": "word-level quality estimation", "start_pos": 24, "end_pos": 53, "type": "TASK", "confidence": 0.633617103099823}]}, {"text": "The objective is to highlight words needing post-edition and to detect parts of the sentence that are not reliable.", "labels": [], "entities": []}, {"text": "For the task 2, participants produce for each token a label according to two sub-tasks: \u2022 a binary classification: good (keep) or bad (change) label \u2022 a multi-class classification: the label refers to the edit action needed for the token (i.e. keep, delete or substitute).", "labels": [], "entities": []}, {"text": "Various approaches have been proposed for WCE: combine several features using neural network and naive Bayes learning algorithms.", "labels": [], "entities": [{"text": "WCE", "start_pos": 42, "end_pos": 45, "type": "TASK", "confidence": 0.9816401600837708}]}, {"text": "One of the most effective feature combinations is the Word Posterior Probability (WPP) as proposed by associated with IBM-model based features ().", "labels": [], "entities": []}, {"text": "propose an approach for phrase-based translation models: a phrase is a sequence of contiguous words and is extracted from word-aligned bilingual training corpus.", "labels": [], "entities": [{"text": "phrase-based translation", "start_pos": 24, "end_pos": 48, "type": "TASK", "confidence": 0.6343659460544586}]}, {"text": "The confidence value of each word is then computed by summing overall phrase pairs in which the target part contains this word.", "labels": [], "entities": []}, {"text": "integrate target word's Part-Of-Speech (POS) and train them by Maximum Entropy Model, allowing significative gains compared to WPP features.", "labels": [], "entities": []}, {"text": "Other approaches are based on external features) allowing to deal with various MT systems (e.g. statistical, rule based etc.).", "labels": [], "entities": [{"text": "MT", "start_pos": 79, "end_pos": 81, "type": "TASK", "confidence": 0.9872857928276062}]}, {"text": "In this paper, we propose to use both internal and external features into a conditionnal random fields (CRF) model to predict the label for each word in the MT hypothesis.", "labels": [], "entities": [{"text": "MT hypothesis", "start_pos": 157, "end_pos": 170, "type": "TASK", "confidence": 0.915511965751648}]}, {"text": "We organize the article as follows: section 2 explains all the used features.", "labels": [], "entities": []}, {"text": "Section 3 presents our experimental settings and the preliminary experiments.", "labels": [], "entities": []}, {"text": "Section 4 explores a feature selection refinement and the section 5 presents work using several classifiers associated with a boosting decision.", "labels": [], "entities": [{"text": "feature selection refinement", "start_pos": 21, "end_pos": 49, "type": "TASK", "confidence": 0.6672419408957163}]}, {"text": "Finally we present our systems submissions and propose some conclusions and perspectives.", "labels": [], "entities": []}], "datasetContent": [{"text": "The WMT13 organizers provide two bilingual data sets, from English to Spanish: the training and the test ones.", "labels": [], "entities": [{"text": "WMT13 organizers", "start_pos": 4, "end_pos": 20, "type": "DATASET", "confidence": 0.8749515116214752}]}, {"text": "The training set consists of 803 MT outputs, in which each token is annotated with one appropriate label.", "labels": [], "entities": []}, {"text": "In the binary variant, the words are classified into \"K\" (Keep) or \"C\" (Change) label, meanwhile in the multiclass variant, they can belong to \"K\" (Keep), \"S\" (Substitution) or \"D\" (Deletion).", "labels": [], "entities": []}, {"text": "The test set contains 284 sentences where all the labels accompanying words are hidden.", "labels": [], "entities": []}, {"text": "For optimizing parameters of the classifier, we extract 50 sentences from the training set to form a development set.", "labels": [], "entities": []}, {"text": "Since a number of repetitive sentences are observed in the original training set, the dev set was carefully chosen to ensure that there is no overlap with the new training set (753 sentences), keeping the tuning process accurate.", "labels": [], "entities": []}, {"text": "Some statistics about each set can be found in.", "labels": [], "entities": []}, {"text": "Motivated by the idea of addressing WCE as a sequence labeling task, we employ the Conditional Random Fields (CRF) model () and the corresponding WAPITI toolkit () to train our classifier.", "labels": [], "entities": []}, {"text": "First, we experiment with the combination of all features.", "labels": [], "entities": []}, {"text": "For the multi-class system, WAPITI's default configuration is applied to determine the label, i.e. label which has the highest score is assigned to word.", "labels": [], "entities": [{"text": "WAPITI", "start_pos": 28, "end_pos": 34, "type": "METRIC", "confidence": 0.6837501525878906}]}, {"text": "In case of the binary system, the classification task is then conducted multiple times, corresponding to a threshold increase from 0.300 to 0.975 (step = 0.025).", "labels": [], "entities": [{"text": "classification task", "start_pos": 34, "end_pos": 53, "type": "TASK", "confidence": 0.8709723353385925}]}, {"text": "When threshold = \u03b1, all words in the test set which the probability of \"K\" class \u03b1 will be labelled as \"K\", and otherwise, \"C\".", "labels": [], "entities": []}, {"text": "The values of Precision (Pr), Recall (Rc) and F-score (F) for K and C label are tracked along this threshold variation, allowing us to select the optimal threshold that yields the highest Results for the all-feature binary system (ALL BIN) at the optimal threshold (0.500) and the multi-class one (ALL MULT) at the default threshold, obtained on our dev set, are shown in.", "labels": [], "entities": [{"text": "Precision (Pr)", "start_pos": 14, "end_pos": 28, "type": "METRIC", "confidence": 0.9548256993293762}, {"text": "Recall (Rc)", "start_pos": 30, "end_pos": 41, "type": "METRIC", "confidence": 0.9501339197158813}, {"text": "F-score (F)", "start_pos": 46, "end_pos": 57, "type": "METRIC", "confidence": 0.9630493521690369}, {"text": "ALL MULT)", "start_pos": 298, "end_pos": 307, "type": "METRIC", "confidence": 0.753504236539205}]}, {"text": "We can notice that with ALL BIN, \"K\" label scores are very promising and \"C' label reaches acceptable performance.", "labels": [], "entities": [{"text": "ALL", "start_pos": 24, "end_pos": 27, "type": "METRIC", "confidence": 0.9508044123649597}, {"text": "BIN", "start_pos": 28, "end_pos": 31, "type": "METRIC", "confidence": 0.8042998909950256}, {"text": "K\" label scores", "start_pos": 34, "end_pos": 49, "type": "METRIC", "confidence": 0.7847103625535965}]}, {"text": "In case of ALL MULT we obtain the almost similar above performance for \"K\" and \"S\", respectively, except the disappointing scores for \"D\" (which can be explained by the fact that very few instances of \"D\" words (4%) are observed in the training corpus).", "labels": [], "entities": [{"text": "ALL MULT", "start_pos": 11, "end_pos": 19, "type": "TASK", "confidence": 0.47748272120952606}]}], "tableCaptions": [{"text": " Table 2. We can notice that with ALL BIN,  \"K\" label scores are very promising and \"C' la- bel reaches acceptable performance. In case of  ALL MULT we obtain the almost similar above  performance for \"K\" and \"S\", respectively, ex- cept the disappointing scores for \"D\" (which can  be explained by the fact that very few instances of  \"D\" words (4%) are observed in the training cor- pus).", "labels": [], "entities": [{"text": "BIN", "start_pos": 38, "end_pos": 41, "type": "METRIC", "confidence": 0.8468385934829712}, {"text": "MULT", "start_pos": 144, "end_pos": 148, "type": "METRIC", "confidence": 0.6776302456855774}]}, {"text": " Table 1: Statistics of training, dev and test sets", "labels": [], "entities": []}, {"text": " Table 2: Average Pr, Rc and F for labels of all- feature binary and multi-class systems, obtained  on dev set.", "labels": [], "entities": [{"text": "F", "start_pos": 29, "end_pos": 30, "type": "METRIC", "confidence": 0.9773139357566833}]}, {"text": " Table 3: The rank of each feature (in term of use- fulness) in the set. The symbol \"*\" indicates our  proposed features.", "labels": [], "entities": []}, {"text": " Table 4: The Pr, Rc and F for labels of binary and  multi-class system built from Top 20 features, at  the optimal threshold value, obtained on dev set", "labels": [], "entities": [{"text": "F", "start_pos": 25, "end_pos": 26, "type": "METRIC", "confidence": 0.9262998700141907}]}, {"text": " Table 5: The Pr, Rc and F for labels of Boosting  binary classifier (BOOST BIN)", "labels": [], "entities": [{"text": "F", "start_pos": 25, "end_pos": 26, "type": "METRIC", "confidence": 0.8877595067024231}, {"text": "BOOST BIN", "start_pos": 70, "end_pos": 79, "type": "METRIC", "confidence": 0.9364804923534393}]}, {"text": " Table 6: Official results of the submitted systems, obtained on test set", "labels": [], "entities": []}]}