{"title": [{"text": "Towards Efficient Large-Scale Feature-Rich Statistical Machine Translation", "labels": [], "entities": [{"text": "Statistical Machine Translation", "start_pos": 43, "end_pos": 74, "type": "TASK", "confidence": 0.6497636238733927}]}], "abstractContent": [{"text": "We present the system we developed to provide efficient large-scale feature-rich discriminative training for machine translation.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 109, "end_pos": 128, "type": "TASK", "confidence": 0.8275820314884186}]}, {"text": "We describe how we integrate with MapReduce using Hadoop streaming to allow arbitrarily scaling the tuning set and utilizing a sparse feature set.", "labels": [], "entities": []}, {"text": "We report our findings on German-English and Russian-English translation, and discuss benefits, as well as obstacles, to tuning on larger development sets drawn from the parallel training data.", "labels": [], "entities": [{"text": "Russian-English translation", "start_pos": 45, "end_pos": 72, "type": "TASK", "confidence": 0.6221106052398682}]}], "introductionContent": [{"text": "The adoption of discriminative learning methods for SMT that scale easily to handle sparse and lexicalized features has been increasing in the last several years).", "labels": [], "entities": [{"text": "SMT", "start_pos": 52, "end_pos": 55, "type": "TASK", "confidence": 0.9944590330123901}]}, {"text": "However, relatively few systems take full advantage of the opportunity.", "labels": [], "entities": []}, {"text": "With some exceptions (), most still rely on tuning a handful of common dense features, along with at most a few thousand others, on a relatively small development set.", "labels": [], "entities": []}, {"text": "While more features tuned on more data usually results in better performance for other NLP tasks, this has not necessarily been the case for SMT.", "labels": [], "entities": [{"text": "SMT", "start_pos": 141, "end_pos": 144, "type": "TASK", "confidence": 0.9935674071311951}]}, {"text": "Thus, our main focus in this paper is to improve understanding into the effective use of sparse features, and understand the benefits and shortcomings of large-scale discriminative training.", "labels": [], "entities": []}, {"text": "To this end, we conducted experiments for the shared translation task of the 2013 Workshop on Statistical Machine Translation for the German-English and Russian-English language pairs.", "labels": [], "entities": [{"text": "shared translation task of the 2013 Workshop on Statistical Machine Translation", "start_pos": 46, "end_pos": 125, "type": "TASK", "confidence": 0.701521635055542}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Corpus statistics in tokens for German.", "labels": [], "entities": []}, {"text": " Table 2: Corpus statistics in tokens for  Russian.", "labels": [], "entities": []}, {"text": " Table 3: Results with the addition of sparse fea- tures for German and Russian.", "labels": [], "entities": []}, {"text": " Table 4: Results with different \u03bb settings for using a per-feature learning rate with sparse features.", "labels": [], "entities": []}, {"text": " Table 5: Comparison of using all features versus  top k selection.", "labels": [], "entities": []}, {"text": " Table 8: Results for German with 2 iterations of  tuning on Dev after tuning on larger set.", "labels": [], "entities": [{"text": "Dev", "start_pos": 61, "end_pos": 64, "type": "DATASET", "confidence": 0.9338645935058594}]}, {"text": " Table 6: German evaluation with large-scale tuning, showing numbers of mappers employed, number of  active features for best model, and test scores on Test and bitext Test2 domains.", "labels": [], "entities": [{"text": "Test and bitext Test2 domains", "start_pos": 152, "end_pos": 181, "type": "DATASET", "confidence": 0.7655937671661377}]}, {"text": " Table 7: Russian evaluation with large-scale tuning, showing numbers of mappers employed, number of  active features for best model, and test scores on Test and bitext Test2 domains.", "labels": [], "entities": [{"text": "Test and bitext Test2 domains", "start_pos": 153, "end_pos": 182, "type": "DATASET", "confidence": 0.7140832304954529}]}]}