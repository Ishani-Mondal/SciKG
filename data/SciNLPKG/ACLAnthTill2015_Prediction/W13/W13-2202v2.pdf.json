{"title": [{"text": "Results of the WMT13 Metrics Shared Task", "labels": [], "entities": [{"text": "WMT13 Metrics Shared Task", "start_pos": 15, "end_pos": 40, "type": "TASK", "confidence": 0.6031415611505508}]}], "abstractContent": [{"text": "This paper presents the results of the WMT13 Metrics Shared Task.", "labels": [], "entities": [{"text": "WMT13 Metrics Shared Task", "start_pos": 39, "end_pos": 64, "type": "TASK", "confidence": 0.6693199723958969}]}, {"text": "We asked participants of this task to score the outputs of the MT systems involved in WMT13 Shared Translation Task.", "labels": [], "entities": [{"text": "MT", "start_pos": 63, "end_pos": 65, "type": "TASK", "confidence": 0.9323503971099854}, {"text": "WMT13 Shared Translation Task", "start_pos": 86, "end_pos": 115, "type": "TASK", "confidence": 0.7094409912824631}]}, {"text": "We collected scores of 16 metrics from 8 research groups.", "labels": [], "entities": []}, {"text": "In addition to that we computed scores of 5 standard metrics such as BLEU, WER, PER as baselines.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 69, "end_pos": 73, "type": "METRIC", "confidence": 0.9991468191146851}, {"text": "WER", "start_pos": 75, "end_pos": 78, "type": "METRIC", "confidence": 0.9961541295051575}, {"text": "PER", "start_pos": 80, "end_pos": 83, "type": "METRIC", "confidence": 0.9947527647018433}]}, {"text": "Collected scores were evaluated in terms of system level correlation (how well each metric's scores correlate with WMT13 official human scores) and in terms of segment level correlation (how often a metric agrees with humans in comparing two translations of a particular sentence).", "labels": [], "entities": [{"text": "WMT13 official human scores", "start_pos": 115, "end_pos": 142, "type": "DATASET", "confidence": 0.8065396249294281}, {"text": "segment level correlation", "start_pos": 160, "end_pos": 185, "type": "METRIC", "confidence": 0.6305674910545349}]}], "introductionContent": [{"text": "Automatic machine translation metrics play a very important role in the development of MT systems and their evaluation.", "labels": [], "entities": [{"text": "machine translation metrics", "start_pos": 10, "end_pos": 37, "type": "TASK", "confidence": 0.7516123255093893}, {"text": "MT", "start_pos": 87, "end_pos": 89, "type": "TASK", "confidence": 0.9973209500312805}]}, {"text": "There are many different metrics of diverse nature and one would like to assess their quality.", "labels": [], "entities": []}, {"text": "For this reason, the Metrics Shared Task is held annually at the Workshop of Statistical Machine Translation.", "labels": [], "entities": [{"text": "Metrics Shared Task", "start_pos": 21, "end_pos": 40, "type": "TASK", "confidence": 0.8785002628962199}, {"text": "Statistical Machine Translation", "start_pos": 77, "end_pos": 108, "type": "TASK", "confidence": 0.851004978020986}]}, {"text": "This year, the Metrics Task was run by different organizers but the only visible change is hopefully that the results of the task are presented in a separate paper instead of the main WMT overview paper.", "labels": [], "entities": [{"text": "WMT overview paper", "start_pos": 184, "end_pos": 202, "type": "DATASET", "confidence": 0.711951732635498}]}, {"text": "In this task, we asked metrics developers to score the outputs of WMT13 Shared Translation Task ().", "labels": [], "entities": [{"text": "WMT13 Shared Translation Task", "start_pos": 66, "end_pos": 95, "type": "TASK", "confidence": 0.7546755373477936}]}, {"text": "We have collected the computed metrics' scores and use them to evaluate quality of the metrics.", "labels": [], "entities": []}, {"text": "The systems' outputs, human judgements and evaluated metrics are described in Section 2.", "labels": [], "entities": []}, {"text": "The quality of the metrics in terms of system level correlation is reported in Section 3.", "labels": [], "entities": []}, {"text": "Segment level correlation is reported in Section 4.", "labels": [], "entities": [{"text": "Segment level correlation", "start_pos": 0, "end_pos": 25, "type": "METRIC", "confidence": 0.8707296252250671}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 4: Segment-level Kendall's \u03c4 correlations of automatic evaluation metrics and the official WMT  human judgements when translating into English.", "labels": [], "entities": [{"text": "Segment-level Kendall's \u03c4 correlations", "start_pos": 10, "end_pos": 48, "type": "METRIC", "confidence": 0.6477833688259125}, {"text": "WMT  human judgements", "start_pos": 98, "end_pos": 119, "type": "TASK", "confidence": 0.5870961745580038}]}, {"text": " Table 5: Segment-level Kendall's \u03c4 correlations of automatic evaluation metrics and the official WMT  human judgements when translating out of English.", "labels": [], "entities": [{"text": "Segment-level Kendall's \u03c4 correlations", "start_pos": 10, "end_pos": 48, "type": "METRIC", "confidence": 0.6429002463817597}, {"text": "WMT  human judgements", "start_pos": 98, "end_pos": 119, "type": "TASK", "confidence": 0.549338161945343}]}]}