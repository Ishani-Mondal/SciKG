{"title": [{"text": "A Pilot Study on Readability Prediction with Reading Time", "labels": [], "entities": [{"text": "Readability Prediction", "start_pos": 17, "end_pos": 39, "type": "TASK", "confidence": 0.6889375150203705}]}], "abstractContent": [{"text": "In this paper we report the results of a pilot study of basing readability prediction on training data annotated with reading time.", "labels": [], "entities": [{"text": "basing readability prediction", "start_pos": 56, "end_pos": 85, "type": "TASK", "confidence": 0.8713353276252747}]}, {"text": "Although reading time is known to be a good metric for predicting readabil-ity, previous work has mainly focused on annotating the training data with subjective readability scores usually on a 1 to 5 scale.", "labels": [], "entities": [{"text": "predicting readabil-ity", "start_pos": 55, "end_pos": 78, "type": "TASK", "confidence": 0.8248748779296875}]}, {"text": "Instead of the subjective assessments of complexity, we use the more objective measure of reading time.", "labels": [], "entities": []}, {"text": "We create and evaluate a predictor using the binary classification problem; the predictor identifies the better of two documents correctly with 68.55% accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 151, "end_pos": 159, "type": "METRIC", "confidence": 0.9962978959083557}]}, {"text": "We also report a comparison of predictors based on reading time and on readability scores.", "labels": [], "entities": []}], "introductionContent": [{"text": "Several recent studies have attempted to predict the readability of documents.", "labels": [], "entities": []}, {"text": "Predicting readability has a very important role in the field of computational linguistics and natural language processing: \u2022 Readability prediction can help users retrieve information from the Internet.", "labels": [], "entities": [{"text": "natural language processing", "start_pos": 95, "end_pos": 122, "type": "TASK", "confidence": 0.6940560340881348}, {"text": "Readability prediction", "start_pos": 126, "end_pos": 148, "type": "TASK", "confidence": 0.8184560239315033}]}, {"text": "If the readability of documents can be predicted, search engines can rank the documents according to readability, allowing users to access the information they need more easily).", "labels": [], "entities": []}, {"text": "\u2022 The predicted readability of a document can be used as an objective function in natural language applications such as machine translation, automatic summarization, and document simplification.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 120, "end_pos": 139, "type": "TASK", "confidence": 0.7929528653621674}, {"text": "summarization", "start_pos": 151, "end_pos": 164, "type": "TASK", "confidence": 0.6498224139213562}, {"text": "document simplification", "start_pos": 170, "end_pos": 193, "type": "TASK", "confidence": 0.7582865953445435}]}, {"text": "Machine translation can use a readability predictor as apart of the objective function to make more fluent translations ( ).", "labels": [], "entities": [{"text": "Machine translation", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.7296390533447266}]}, {"text": "The readability predictor can also be used as apart of a summarizer to generate readable summaries . Document simplification can help readers understand documents more easily by automatically rewriting documents that are not easy to read (.", "labels": [], "entities": [{"text": "Document simplification", "start_pos": 101, "end_pos": 124, "type": "TASK", "confidence": 0.8934620320796967}]}, {"text": "This is possible by paraphrasing the sentences so as to maximize document readability.", "labels": [], "entities": []}, {"text": "\u2022 Readability prediction can be used for educational purposes (.", "labels": [], "entities": [{"text": "Readability prediction", "start_pos": 2, "end_pos": 24, "type": "TASK", "confidence": 0.8758302330970764}]}, {"text": "It can assess human-generated documents automatically.", "labels": [], "entities": []}, {"text": "Most studies build a predictor that outputs a readability score (generally 1-5 scale) or a classifier or ranker that identifies which of two documents has the better readability.", "labels": [], "entities": []}, {"text": "Using textual complexity to rank documents maybe adequate for several applications in the fields of information retrieval, machine translation, document simplification, and the assessment of human-written documents.", "labels": [], "entities": [{"text": "information retrieval", "start_pos": 100, "end_pos": 121, "type": "TASK", "confidence": 0.7313744574785233}, {"text": "machine translation", "start_pos": 123, "end_pos": 142, "type": "TASK", "confidence": 0.7916593551635742}, {"text": "document simplification", "start_pos": 144, "end_pos": 167, "type": "TASK", "confidence": 0.7635740637779236}, {"text": "assessment of human-written documents", "start_pos": 177, "end_pos": 214, "type": "TASK", "confidence": 0.8114343136548996}]}, {"text": "Approaches based on complexity, however, do not well support document summarization.", "labels": [], "entities": [{"text": "document summarization", "start_pos": 61, "end_pos": 83, "type": "TASK", "confidence": 0.5449221283197403}]}, {"text": "In the context of automatic summarization, users want concise summaries to understand the important information present in the documents as rapidly as possible-to create summaries that can be read as quickly as possible, we need a function that can evaluate the quality of the summary in terms of reading time.", "labels": [], "entities": [{"text": "summarization", "start_pos": 28, "end_pos": 41, "type": "TASK", "confidence": 0.8497698307037354}]}, {"text": "To achieve this goal, in this paper, we show the results of our pilot study on predicting the reading time of documents.", "labels": [], "entities": []}, {"text": "Our predictor has two features as follows: 1.", "labels": [], "entities": []}, {"text": "Our predictor is trained by documents directly annotated with reading time.", "labels": [], "entities": [{"text": "predictor", "start_pos": 4, "end_pos": 13, "type": "TASK", "confidence": 0.9235489368438721}]}, {"text": "While previous work employs subjective assessments of complexity, we directly use the reading time to build a predictor.", "labels": [], "entities": []}, {"text": "As a predictor, we adopt Ranking SVM).", "labels": [], "entities": []}, {"text": "2. The predictor predicts the reading time without recourse to features related to document length since our immediate goal is text summarization.", "labels": [], "entities": [{"text": "text summarization", "start_pos": 127, "end_pos": 145, "type": "TASK", "confidence": 0.6748474389314651}]}, {"text": "A preliminary experiment confirms that document length is effective for readability prediction confirming the work by.", "labels": [], "entities": [{"text": "readability prediction", "start_pos": 72, "end_pos": 94, "type": "TASK", "confidence": 0.8075279593467712}]}, {"text": "Summarization demands that the predictor work well regardless of text length.", "labels": [], "entities": []}, {"text": "This is the first report to show that the result of training a predictor with data annotated by reading time is to improve the quality of automatic readability prediction.", "labels": [], "entities": [{"text": "readability prediction", "start_pos": 148, "end_pos": 170, "type": "TASK", "confidence": 0.6894095540046692}]}, {"text": "Furthermore, we report the result of the comparison between our reading time predictor and a conventional complexitybased predictor.", "labels": [], "entities": []}, {"text": "This paper is organized as follows: Section 2 describes related work.", "labels": [], "entities": []}, {"text": "Section 3 describes the data used in the experiments.", "labels": [], "entities": []}, {"text": "Section 4 describes our model.", "labels": [], "entities": []}, {"text": "Section 5 elaborates the features for predicting document readability based on reading time.", "labels": [], "entities": [{"text": "predicting document readability", "start_pos": 38, "end_pos": 69, "type": "TASK", "confidence": 0.8773294885953268}]}, {"text": "Section 6 reports our evaluation experiments.", "labels": [], "entities": []}, {"text": "We conclude this paper and show future directions in Section 7.", "labels": [], "entities": []}], "datasetContent": [{"text": "This section explains the setting of our experiment.", "labels": [], "entities": []}, {"text": "As mentioned above, we adopted Ranking SVM as a predictor.", "labels": [], "entities": []}, {"text": "Since we had 683 tuples (documents, reading time and readability scores), we made 683 C 2 = 232, 903 pairs of documents for Ranking SVM.", "labels": [], "entities": []}, {"text": "Each pair consists of two documents where one has a shorter reading time than the other.", "labels": [], "entities": []}, {"text": "The predictor learned which parameters were better at predicting which document would have the shorter reading time, i.e. higher score.", "labels": [], "entities": []}, {"text": "to prediction accuracy, we adopted a linear kernel.", "labels": [], "entities": [{"text": "prediction", "start_pos": 3, "end_pos": 13, "type": "TASK", "confidence": 0.9609615206718445}, {"text": "accuracy", "start_pos": 14, "end_pos": 22, "type": "METRIC", "confidence": 0.9297884106636047}]}, {"text": "The range of the value of each feature was normalized to lie between -1 and 1.", "labels": [], "entities": []}, {"text": "shows the results yielded by the reading time predictor.", "labels": [], "entities": []}, {"text": "ALL indicates the accuracy achieved by the classifier with all features explained in Section 5.", "labels": [], "entities": [{"text": "ALL", "start_pos": 0, "end_pos": 3, "type": "METRIC", "confidence": 0.9879064559936523}, {"text": "accuracy", "start_pos": 18, "end_pos": 26, "type": "METRIC", "confidence": 0.9994785189628601}]}, {"text": "At the bottom of, Baseline shows the accuracy of random classification.", "labels": [], "entities": [{"text": "Baseline", "start_pos": 18, "end_pos": 26, "type": "METRIC", "confidence": 0.866980791091919}, {"text": "accuracy", "start_pos": 37, "end_pos": 45, "type": "METRIC", "confidence": 0.9997195601463318}]}, {"text": "As shown in, since the height of syntax tree, entity grid and lexical cohesion are good indicators for the prediction, we combined these features.", "labels": [], "entities": []}, {"text": "TH + EG + LC indicates that this combination achieves the best performance.", "labels": [], "entities": [{"text": "TH + EG + LC", "start_pos": 0, "end_pos": 12, "type": "METRIC", "confidence": 0.7755992174148559}]}, {"text": "As to individual features, most of them couldn't distinguish a better document from a worse one.", "labels": [], "entities": []}, {"text": "CT, WF and LL show similar performance to Baseline.", "labels": [], "entities": [{"text": "CT", "start_pos": 0, "end_pos": 2, "type": "DATASET", "confidence": 0.9641592502593994}]}, {"text": "The reason why these features failed to clearer identify the better of the pair could be because the documents are newswire articles.", "labels": [], "entities": []}, {"text": "The ratio between kanji and hiragana, CT, is similar inmost of the articles and hence it couldn't identify the better document.", "labels": [], "entities": [{"text": "CT", "start_pos": 38, "end_pos": 40, "type": "METRIC", "confidence": 0.9966118931770325}]}, {"text": "Similarly, there isn't so much of a difference among the documents in terms of word familiarity, WF.", "labels": [], "entities": []}, {"text": "The language model used, LL, was not effective against the documents tested but it is expected that it would useful if the target documents came from different fields.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Results of proposed reading time predic- tor.", "labels": [], "entities": []}, {"text": " Table 2: A result of classification based on read- ability score.", "labels": [], "entities": [{"text": "read- ability score", "start_pos": 46, "end_pos": 65, "type": "METRIC", "confidence": 0.8759841173887253}]}, {"text": " Table 3: Correlation coefficients of the reading  time and readability score between the subjects.  We calculated the coefficient for each pair of sub- jects and then averaged them.", "labels": [], "entities": []}]}