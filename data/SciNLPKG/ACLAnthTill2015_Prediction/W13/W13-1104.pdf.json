{"title": [{"text": "Really? Well. Apparently Bootstrapping Improves the Performance of Sarcasm and Nastiness Classifiers for Online Dialogue", "labels": [], "entities": [{"text": "Online Dialogue", "start_pos": 105, "end_pos": 120, "type": "TASK", "confidence": 0.7088909149169922}]}], "abstractContent": [{"text": "More and more of the information on the web is dialogic, from Facebook newsfeeds, to forum conversations, to comment threads on news articles.", "labels": [], "entities": []}, {"text": "In contrast to traditional, mono-logic Natural Language Processing resources such as news, highly social dialogue is frequent in social media, making it a challenging context for NLP.", "labels": [], "entities": []}, {"text": "This paper tests a bootstrap-ping method, originally proposed in a mono-logic domain, to train classifiers to identify two different types of subjective language in dialogue: sarcasm and nastiness.", "labels": [], "entities": []}, {"text": "We explore two methods of developing linguistic indicators to be used in a first level classifier aimed at maximizing precision at the expense of recall.", "labels": [], "entities": [{"text": "precision", "start_pos": 118, "end_pos": 127, "type": "METRIC", "confidence": 0.9973729848861694}, {"text": "recall", "start_pos": 146, "end_pos": 152, "type": "METRIC", "confidence": 0.9976663589477539}]}, {"text": "The best performing classifier for the first phase achieves 54% precision and 38% recall for sarcastic utterances.", "labels": [], "entities": [{"text": "precision", "start_pos": 64, "end_pos": 73, "type": "METRIC", "confidence": 0.9996289014816284}, {"text": "recall", "start_pos": 82, "end_pos": 88, "type": "METRIC", "confidence": 0.9996122717857361}]}, {"text": "We then use general syntactic patterns from previous work to create more general sarcasm indicators, improving precision to 62% and recall to 52%.", "labels": [], "entities": [{"text": "precision", "start_pos": 111, "end_pos": 120, "type": "METRIC", "confidence": 0.9996159076690674}, {"text": "recall", "start_pos": 132, "end_pos": 138, "type": "METRIC", "confidence": 0.9995648264884949}]}, {"text": "To further test the generality of the method, we then apply it to bootstrapping a classifier for nastiness dialogic acts.", "labels": [], "entities": [{"text": "nastiness dialogic acts", "start_pos": 97, "end_pos": 120, "type": "TASK", "confidence": 0.8662076989809672}]}, {"text": "Our first phase, using crowdsourced nasty indicators, achieves 58% precision and 49% recall, which increases to 75% precision and 62% recall when we boot-strap over the first level with generalized syntactic patterns.", "labels": [], "entities": [{"text": "precision", "start_pos": 67, "end_pos": 76, "type": "METRIC", "confidence": 0.9996522665023804}, {"text": "recall", "start_pos": 85, "end_pos": 91, "type": "METRIC", "confidence": 0.9996193647384644}, {"text": "precision", "start_pos": 116, "end_pos": 125, "type": "METRIC", "confidence": 0.9991111159324646}, {"text": "recall", "start_pos": 134, "end_pos": 140, "type": "METRIC", "confidence": 0.999237060546875}]}], "introductionContent": [{"text": "More and more of the information on the web is dialogic, from Facebook newsfeeds, to forum conversations, to comment threads on news articles.", "labels": [], "entities": []}, {"text": "In contrast to traditional, monologic Natural Language Processing resources such as news, highly social dialogue is very frequent in social media, as illustrated in the snippets in from the publicly available Internet Argument Corpus (IAC) ( Quote Q, Response R Sarc Nasty Q1: I jsut voted.", "labels": [], "entities": []}, {"text": "sorry if some people actually have, you know, LIVES and don't sit around all day on debate forums to cater to some atheists posts that he thiks they should drop everything for.", "labels": [], "entities": [{"text": "LIVES", "start_pos": 46, "end_pos": 51, "type": "METRIC", "confidence": 0.9774022698402405}]}, {"text": "emoticon-rolleyes emoticon-rolleyes emoticon-rolleyes As to the rest of your post, well, from your attitude I can tell you are not Christian in the least.", "labels": [], "entities": []}, {"text": "Therefore I am content in knowing where people that spew garbage like this will end up in the End.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: How utterances annotated for sarcasm (top) and  nastiness (bottom) in IAC were used. MT = Mechanical  Turk experimental development set. HP train = utter- ances used to test whether combinations of cues could be  used to develop a High precision classifier. HP dev test  = \"Unannotated Text Collection\" in Fig. 2. PE eval =  utterances used to train the Pattern Classifier.", "labels": [], "entities": [{"text": "IAC", "start_pos": 80, "end_pos": 83, "type": "DATASET", "confidence": 0.8118374347686768}]}, {"text": " Table 3: Mechanical Turk (MT) and \u03c7 2 indicators for  Nasty", "labels": [], "entities": [{"text": "Nasty", "start_pos": 55, "end_pos": 60, "type": "TASK", "confidence": 0.7927289009094238}]}, {"text": " Table 4: Sarcasm Train results; P: precision, R: recall, tp:  true positive classifications", "labels": [], "entities": [{"text": "precision", "start_pos": 36, "end_pos": 45, "type": "METRIC", "confidence": 0.9597591757774353}, {"text": "R:", "start_pos": 47, "end_pos": 49, "type": "METRIC", "confidence": 0.8985575735569}, {"text": "recall", "start_pos": 50, "end_pos": 56, "type": "METRIC", "confidence": 0.7701270580291748}, {"text": "true positive classifications", "start_pos": 63, "end_pos": 92, "type": "METRIC", "confidence": 0.8833244244257609}]}, {"text": " Table 5: Nasty Train results; P: precision, R: recall, tp:  true positive classifications", "labels": [], "entities": [{"text": "Nasty", "start_pos": 10, "end_pos": 15, "type": "METRIC", "confidence": 0.9034678936004639}, {"text": "precision", "start_pos": 34, "end_pos": 43, "type": "METRIC", "confidence": 0.9597451090812683}, {"text": "recall", "start_pos": 48, "end_pos": 54, "type": "METRIC", "confidence": 0.82707679271698}, {"text": "true positive classifications", "start_pos": 61, "end_pos": 90, "type": "METRIC", "confidence": 0.8616734743118286}]}, {"text": " Table 6: HP Dev test results; PARAMS: the best pa- rameters for each feature set P: precision, R: recall, F:  f-measure", "labels": [], "entities": [{"text": "HP Dev test", "start_pos": 10, "end_pos": 21, "type": "DATASET", "confidence": 0.8407289783159891}, {"text": "PARAMS", "start_pos": 31, "end_pos": 37, "type": "METRIC", "confidence": 0.9943384528160095}, {"text": "precision", "start_pos": 85, "end_pos": 94, "type": "METRIC", "confidence": 0.9934497475624084}, {"text": "recall", "start_pos": 99, "end_pos": 105, "type": "METRIC", "confidence": 0.9400607943534851}]}, {"text": " Table 8: Pattern Classification Training; P: precision, R:  recall, F: F-measure, tp: true positive classifications", "labels": [], "entities": [{"text": "Pattern Classification", "start_pos": 10, "end_pos": 32, "type": "TASK", "confidence": 0.8490455746650696}, {"text": "precision", "start_pos": 46, "end_pos": 55, "type": "METRIC", "confidence": 0.9894205331802368}, {"text": "recall", "start_pos": 61, "end_pos": 67, "type": "METRIC", "confidence": 0.9494365453720093}, {"text": "F-measure", "start_pos": 72, "end_pos": 81, "type": "METRIC", "confidence": 0.7508803606033325}]}]}