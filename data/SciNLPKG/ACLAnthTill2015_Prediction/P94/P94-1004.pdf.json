{"title": [{"text": "HIDDEN UNDERSTANDING MODELS OF NATURAL LANGUAGE", "labels": [], "entities": [{"text": "HIDDEN", "start_pos": 0, "end_pos": 6, "type": "METRIC", "confidence": 0.601857602596283}, {"text": "UNDERSTANDING MODELS", "start_pos": 7, "end_pos": 27, "type": "METRIC", "confidence": 0.7708399593830109}]}], "abstractContent": [{"text": "We describe and evaluate hidden understanding models, a statistical learning approach to natural language understanding.", "labels": [], "entities": [{"text": "natural language understanding", "start_pos": 89, "end_pos": 119, "type": "TASK", "confidence": 0.6538329025109609}]}, {"text": "Given a string of words, hidden understanding models determine the most likely meaning for the string.", "labels": [], "entities": []}, {"text": "We discuss 1) the problem of representing meaning in this framework, 2) the structure of the statistical model, 3) the process of training the model, and 4) the process of understanding using the model.", "labels": [], "entities": []}, {"text": "Finally, we give experimental results, including results on an ARPA evaluation.", "labels": [], "entities": []}], "introductionContent": [{"text": "Hidden understanding models are an innovative class of statistical mechanisms that, given a string of words, determines the most likely meaning for the string.", "labels": [], "entities": []}, {"text": "The overall approach represents a substantial departure from traditional techniques by replacing hand-crafted grammars and rules with statistical models that are automatically learned from examples.", "labels": [], "entities": []}, {"text": "Hidden understanding models were primarily motivated by techniques that have been extremely successful in speech recognition, especially hidden Markov models.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 106, "end_pos": 124, "type": "TASK", "confidence": 0.7880071997642517}]}, {"text": "Related techniques have previously been applied to the problem of identifying concept sequences within a sentence.", "labels": [], "entities": [{"text": "identifying concept sequences within a sentence", "start_pos": 66, "end_pos": 113, "type": "TASK", "confidence": 0.8229982952276865}]}, {"text": "In addition, the approach contains elements of other natural language processing techniques including semantic grammars, augmented transition networks (ATNs), probabilistic parsing, and automatic grammar induction.", "labels": [], "entities": [{"text": "automatic grammar induction", "start_pos": 186, "end_pos": 213, "type": "TASK", "confidence": 0.6310966710249583}]}, {"text": "Hidden understanding models are capable of learning a variety of meaning representations, ranging from simple domain-specific representations, to ones at a level of detail and sophistication comparable to current natural language systems.", "labels": [], "entities": []}, {"text": "In fact, a hidden understanding model can be used to produce a representation with essentially the same information content as the semantic graph used by the Delphi system, a general purpose NLP system, which utilizes a modified Definite Clause Grammar formalism.", "labels": [], "entities": []}, {"text": "This fact made it possible to interface a hidden understanding system to the discourse processing and database retrieval components of Delphi to produce a complete \"end to end\" system.", "labels": [], "entities": []}, {"text": "This hybrid system participated in the 1993 ATIS natural language evaluation.", "labels": [], "entities": [{"text": "1993 ATIS natural language evaluation", "start_pos": 39, "end_pos": 76, "type": "TASK", "confidence": 0.5375203847885132}]}, {"text": "Although only four months old, the scores achieved by the combined system were quite respectable.", "labels": [], "entities": []}, {"text": "Because of differences between language understanding and speech recognition, significant changes are required in the hidden Markov model methodology.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 58, "end_pos": 76, "type": "TASK", "confidence": 0.7536053657531738}]}, {"text": "Unlike speech, where each phoneme results in a local sequence of spectra, the relation between the meaning of a sentence and the sequence of words is not a simple linear sequential model.", "labels": [], "entities": []}, {"text": "Language is inherently nested, with subgroups of concepts within other concepts.", "labels": [], "entities": []}, {"text": "A statistical system for understanding language must take this and other differences into account in its overall design.", "labels": [], "entities": []}, {"text": "In principle, we have the following requirements fora hidden understanding system: \u2022 A notational system for expressing meanings.", "labels": [], "entities": []}, {"text": "\u2022 A statistical model that is capable of representing meanings and the association between meanings and words.", "labels": [], "entities": []}, {"text": "\u2022 An automatic training program which, given pairs of meanings and word sequences, can estimate the parameters of a statistical model.", "labels": [], "entities": []}, {"text": "\u2022 An understanding program that can search the statistical model to fred the most likely meaning given a word sequence.", "labels": [], "entities": []}, {"text": "Below, we describe solutions for each of these requirements, and describe the relationship of these solutions to other work in stochastic grammars and probabilistic parsing.", "labels": [], "entities": []}, {"text": "Finally, we will report on initial experiments with hidden understanding models.", "labels": [], "entities": []}], "datasetContent": [{"text": "We have implemented a hidden understanding system and performed a variety of experiments.", "labels": [], "entities": []}, {"text": "In addition, we participated in the 1993 ARPA ATIS NL evaluation.", "labels": [], "entities": [{"text": "1993 ARPA ATIS NL evaluation", "start_pos": 36, "end_pos": 64, "type": "DATASET", "confidence": 0.7545925498008728}]}, {"text": "One experiment involved a 1000 sentence ATIS corpus, annotated according to a simple specialized sublanguage model.", "labels": [], "entities": [{"text": "ATIS corpus", "start_pos": 40, "end_pos": 51, "type": "DATASET", "confidence": 0.7073992490768433}]}, {"text": "The annotation effort was split between two annotators, one of whom was a system developer, while the other was not.", "labels": [], "entities": []}, {"text": "To annotate the training data, we used a bootstrapping process in which only the first 100 sentences were annotated strictly by hand.", "labels": [], "entities": []}, {"text": "Thereafter, we worked in cycles of.\"", "labels": [], "entities": []}, {"text": "1. Running the training program using all available annotated data.", "labels": [], "entities": []}, {"text": "2. Running the understanding component to annotate new sentences.", "labels": [], "entities": []}, {"text": "3. Hand correcting the new annotations.", "labels": [], "entities": [{"text": "Hand correcting", "start_pos": 3, "end_pos": 18, "type": "TASK", "confidence": 0.9021959006786346}]}, {"text": "Annotating in this way, we found that a single annotator could produce 200 sentences per day.", "labels": [], "entities": []}, {"text": "We then extracted the first 100 sentences as a test set, and trained the system on the remaining 900 sentences.", "labels": [], "entities": []}, {"text": "The results were as follows: \u2022 61% matched exactly.", "labels": [], "entities": []}, {"text": "\u2022 21% had correct meanings, but did not match exactly.", "labels": [], "entities": []}, {"text": "\u2022 28% had the wrong meaning.", "labels": [], "entities": []}, {"text": "Another experiment involved a 6000 sentence ATIS corpus, annotated according to a more sophisticated meaning model.", "labels": [], "entities": []}, {"text": "In this experiment, the Delphi system automatically produced the annotation by printing out its own internal representation for each sentence, converted into a more readable form.", "labels": [], "entities": []}, {"text": "In order to maintain high quality annotations, we used only sentences for which Delphi produced a complete parse, and for which it also retrieved a correct answer from the database.", "labels": [], "entities": []}, {"text": "We then removed 300 sentences as a test set, and trained the system on the remaining 5700.", "labels": [], "entities": []}, {"text": "The results were as follows: \u2022 85% matched exactly.", "labels": [], "entities": []}, {"text": "\u2022 8% had correct meanings, but did not match exactly.", "labels": [], "entities": []}, {"text": "\u2022 7% had the wrong meaning.", "labels": [], "entities": []}, {"text": "For the ARPA evaluation, we coupled our hidden understanding system to the discourse and backend components of the Delphi.", "labels": [], "entities": []}, {"text": "Using the entire 6000 sentence corpus described above as training data, the system produced a score of 26% simple error on the ATIS NL evaluation.", "labels": [], "entities": [{"text": "simple error", "start_pos": 107, "end_pos": 119, "type": "METRIC", "confidence": 0.9574483036994934}, {"text": "ATIS NL evaluation", "start_pos": 127, "end_pos": 145, "type": "DATASET", "confidence": 0.8733468850453695}]}, {"text": "By examining the errors, we have reached the conclusion that nearly half are due to simple programming issues, especially in the interface between Delphi and the hidden understanding system.", "labels": [], "entities": []}, {"text": "In fact, the interface was still incomplete at the time of the evaluation.", "labels": [], "entities": []}, {"text": "We have just begun a series of experiments using frame based annotations, and are continuing to refme our techniques.", "labels": [], "entities": []}, {"text": "Ina preliminary test involving a small corpus of 588 ATIS sentences, the system correctly aligned the hidden states for over 95% of the sentences in the corpus.", "labels": [], "entities": []}], "tableCaptions": []}