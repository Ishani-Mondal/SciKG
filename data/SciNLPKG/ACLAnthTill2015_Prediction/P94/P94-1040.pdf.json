{"title": [{"text": "RELATING COMPLEXITY TO PRACTICAL PERFORMANCE IN PARSING WITH WIDE-COVERAGE UNIFICATION GRAMMARS", "labels": [], "entities": [{"text": "RELATING COMPLEXITY", "start_pos": 0, "end_pos": 19, "type": "METRIC", "confidence": 0.7358002960681915}, {"text": "PARSING WITH WIDE-COVERAGE UNIFICATION GRAMMARS", "start_pos": 48, "end_pos": 95, "type": "METRIC", "confidence": 0.7651231288909912}]}], "abstractContent": [{"text": "The paper demonstrates that exponential complexities with respect to grammar size and input length have little impact on the performance of three unification-based parsing algorithms, using a wide-coverage grammar.", "labels": [], "entities": [{"text": "unification-based parsing", "start_pos": 146, "end_pos": 171, "type": "TASK", "confidence": 0.555461198091507}]}, {"text": "The results imply that the study and optimisation of unification-based parsing must rely on empirical data until complexity theory can more accurately predict the practical behaviour of such parserQ.", "labels": [], "entities": []}], "introductionContent": [{"text": "General-purpose natural language (NL) analysis systems have recently started to use declarative unification-based sentence grammar formalisms; systems of this type include SRI's CLARE system ) and the A1vey NL Tools (ANLT;.", "labels": [], "entities": [{"text": "A1vey NL Tools (ANLT", "start_pos": 201, "end_pos": 221, "type": "DATASET", "confidence": 0.7978680610656739}]}, {"text": "Using a declarative formalism helps ease the task of developing and maintaining the grammar.", "labels": [], "entities": []}, {"text": "In addition to syntactic processing, the systems incorporate lexical, morphological, and semantic processing, and have been applied successfully to the analysis of naturally-occurring texts (e.g..", "labels": [], "entities": []}, {"text": "Evaluations of the grammars in these particular systems have shown them to have wide coverage 2.", "labels": [], "entities": []}, {"text": "However, although the practical throughput of parsers with such realistic grammars is important, for example when process1This research was supported by SERC/DTI project 4/1/1261 'Extensions to the Alvey Natural Language Tools' and by EC ESPRIT BRA-7315 'ACQUILEX-II'.", "labels": [], "entities": [{"text": "SERC/DTI project 4/1/1261", "start_pos": 153, "end_pos": 178, "type": "DATASET", "confidence": 0.7366104589568244}, {"text": "EC ESPRIT BRA-7315 'ACQUILEX-II", "start_pos": 235, "end_pos": 266, "type": "DATASET", "confidence": 0.5240874886512756}]}, {"text": "I am grateful to Ted Briscoe for comments on an earlier version of this paper, to David Weir for valuable discussions, and to Hiyan Alshawi for assistance with the CLARE system.", "labels": [], "entities": [{"text": "CLARE system", "start_pos": 164, "end_pos": 176, "type": "DATASET", "confidence": 0.680349662899971}]}, {"text": "2For example, Taylor et al. demonstrate that the ANLT grammar is in principle able to analyse 96.8% of a corpus of 10,000 noun phrases taken from a variety of corpora.", "labels": [], "entities": []}, {"text": "ing large amounts of text or in interactive applications, there is little published research that compares the performance of different parsing algorithms using wide-coverage unification-based grammars.", "labels": [], "entities": []}, {"text": "Previous comparisons have either focussed on context-free (CF) or augmented CF parsing, or have used relatively small, limited-coverage unification grammars and lexicons.", "labels": [], "entities": [{"text": "context-free (CF) or augmented CF parsing", "start_pos": 45, "end_pos": 86, "type": "TASK", "confidence": 0.6213088817894459}]}, {"text": "It is not clear that these results scale up to reflect accurately the behaviour of parsers using realistic, complex unification-based grammars: in particular, with grammars admitting less ambiguity parse time will tend to increase more slowly with increasing input length, and also with smaller grammars rule application can be constrained tightly with relatively simple predictive techniques.", "labels": [], "entities": []}, {"text": "Also, since none of these studies relate observed performance to that of other comparable parsing systems, implementational oversights may not be apparent and so be a confounding factor in any general conclusions made.", "labels": [], "entities": []}, {"text": "Other research directed towards improving the throughput of unification-based parsing systems has been concerned with the unification operation itself, which can consume up to 90% of parse time (e.g.) in systems using lexicalist grammar formalisms (e.g. HPSG;.", "labels": [], "entities": [{"text": "unification-based parsing", "start_pos": 60, "end_pos": 85, "type": "TASK", "confidence": 0.7081856429576874}]}, {"text": "However, parsing algorithms assume more importance for grammars having more substantial phrase structure components, such as CLARE (which although employing some HPSGlike analyses still contains several tens of rules) and the ANLT (which uses a formalism derived from GPSG;, sincethe more specific rule set can be used to control which unifications are performed.", "labels": [], "entities": [{"text": "ANLT", "start_pos": 226, "end_pos": 230, "type": "METRIC", "confidence": 0.5695999264717102}]}, {"text": "In NL analysis, the syntactic information associated with lexical items makes top-down parsing less attractive than bottom-up (e.g. CKY;, although the latter is often augmented with top-down predic-tion to improve performance (e.g..", "labels": [], "entities": [{"text": "NL analysis", "start_pos": 3, "end_pos": 14, "type": "TASK", "confidence": 0.9133210182189941}]}, {"text": "Section 2 describes three unification-based parsers which are related to polynomial-complexity bottom-up CF parsing algorithms.", "labels": [], "entities": [{"text": "CF parsing", "start_pos": 105, "end_pos": 115, "type": "TASK", "confidence": 0.6332918405532837}]}, {"text": "Although incorporating unification increases their complexity to exponential on grammar size and input length (section 3), this appears to have little impact on practical performance (section 4).", "labels": [], "entities": []}, {"text": "Sections 5 and 6 discuss these findings and present conclusions.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Parse times (in CPU seconds on a Sun  Sparc ELC workstation) and storage allocated (in  megabytes) while parsing the 129 test sentences  (1-12 words in length).", "labels": [], "entities": [{"text": "Parse", "start_pos": 10, "end_pos": 15, "type": "METRIC", "confidence": 0.9743726253509521}]}, {"text": " Table 2: Mean and standard deviation parse times (in CPU seconds on an HP9000/710 workstation), and  numbers of parses for the 229 test sentences (1-30 words in length) with the BU-LC and LR parsers.", "labels": [], "entities": [{"text": "Mean and standard deviation parse times", "start_pos": 10, "end_pos": 49, "type": "METRIC", "confidence": 0.7910796652237574}, {"text": "BU-LC", "start_pos": 179, "end_pos": 184, "type": "METRIC", "confidence": 0.781417191028595}]}]}