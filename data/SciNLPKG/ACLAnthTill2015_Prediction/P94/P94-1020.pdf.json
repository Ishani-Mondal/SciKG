{"title": [], "abstractContent": [{"text": "Most probabilistic classifiers used for word-sense disam-biguation have either been based on only one contextual feature or have used a model that is simply assumed to characterize the interdependencies among multiple contextual features.", "labels": [], "entities": []}, {"text": "In this paper, a different approach to formulating a probabilistic model is presented along with a case study of the performance of models produced in this manner for the disambiguation of the noun interest.", "labels": [], "entities": []}, {"text": "We describe a method for formulating proba-bilistic models that use multiple contextual features for word-sense disambiguation, without requiring untested assumptions regarding the form of the model.", "labels": [], "entities": [{"text": "word-sense disambiguation", "start_pos": 101, "end_pos": 126, "type": "TASK", "confidence": 0.7304916977882385}]}, {"text": "Using this approach, the joint distribution of all variables is described by only the most systematic variable interactions , thereby limiting the number of parameters to be estimated, supporting computational efficiency, and providing an understanding of the data.", "labels": [], "entities": []}, {"text": "Introduction This paper presents a method for constructing prob-abilistic classifiers for word-sense disambiguation that offers advantages over previous approaches.", "labels": [], "entities": [{"text": "word-sense disambiguation", "start_pos": 90, "end_pos": 115, "type": "TASK", "confidence": 0.7419391870498657}]}, {"text": "Most previous efforts have not attempted to systematically identify the interdependencies among contextual features (such as collocations) that can be used to classify the meaning of an ambiguous word.", "labels": [], "entities": [{"text": "classify the meaning of an ambiguous word", "start_pos": 159, "end_pos": 200, "type": "TASK", "confidence": 0.7518264055252075}]}, {"text": "Many researchers have performed disambiguation on the basis of only a single feature, while others who do consider multiple contex-tual features assume that all contextual features are either conditionally independent given the sense of the word or fully independent.", "labels": [], "entities": []}, {"text": "Of course, all contextual features could be treated as interdependent, but, if there are several features, such a model could have too many parameters to estimate in practice.", "labels": [], "entities": []}, {"text": "We present a method for formulating probabilistic models that describe the relationships among all variables in terms of only the most important interdepen-dencies, that is, models of a certain class that are good approximations to the joint distribution of contextual features and word meanings.", "labels": [], "entities": []}, {"text": "This class is the set of de-composable models: models that can be expressed as a product of marginal distributions, where each marginal", "labels": [], "entities": []}], "introductionContent": [{"text": "This paper presents a method for constructing probabilistic classifiers for word-sense disambiguation that offers advantages over previous approaches.", "labels": [], "entities": [{"text": "word-sense disambiguation", "start_pos": 76, "end_pos": 101, "type": "TASK", "confidence": 0.7509638965129852}]}, {"text": "Most previous efforts have not attempted to systematically identify the interdependencies among contextual features (such as collocations) that can be used to classify the meaning of an ambiguous word.", "labels": [], "entities": [{"text": "classify the meaning of an ambiguous word", "start_pos": 159, "end_pos": 200, "type": "TASK", "confidence": 0.7518264055252075}]}, {"text": "Many researchers have performed disambiguation on the basis of only a single feature, while others who do consider multiple contextual features assume that all contextual features are either conditionally independent given the sense of the word or fully independent.", "labels": [], "entities": []}, {"text": "Of course, all contextual features could be treated as interdependent, but, if there are several features, such a model could have too many parameters to estimate in practice.", "labels": [], "entities": []}, {"text": "We present a method for formulating probabilistic models that describe the relationships among all variables in terms of only the most important interdependencies, that is, models of a certain class that are good approximations to the joint distribution of contextual features and word meanings.", "labels": [], "entities": []}, {"text": "This class is the set of decomposable models: models that can be expressed as a product of marginal distributions, where each marginal is composed of interdependent variables.", "labels": [], "entities": []}, {"text": "The test used to evaluate a model gives preference to those that have the fewest number of interdependencies, thereby selecting models expressing only the most systematic variable interactions.", "labels": [], "entities": []}, {"text": "To summarize the method, one first identifies informative contextual features (where \"informative\" is a well-defined notion, discussed in Section 2).", "labels": [], "entities": []}, {"text": "Then, out of all possible decomposable models characterizing interdependency relationships among the selected variables, those that are found to produce good approximations to the data are identified (using the test mentioned above) and one of those models is used to perform disambiguation.", "labels": [], "entities": []}, {"text": "Thus, we are able to use multiple contextual features without the need for untested assumptions regarding the form of the model.", "labels": [], "entities": []}, {"text": "Further, approximating the joint distribution of all variables with a model identifying only the most important systematic interactions among variables limits the number of parameters to be estimated, supports computational efficiency, and provides an understanding of the data.", "labels": [], "entities": []}, {"text": "The biggest limitation associated with this method is the need for large amounts of sense-tagged data.", "labels": [], "entities": []}, {"text": "Because asymptotic distributions of the test statistics are used, the validity of the results obtained using this approach are compromised when it is applied to sparse data (this point is discussed further in Section 2).", "labels": [], "entities": []}, {"text": "To test the method of model selection presented in this paper, a case study of the disambiguation of the noun interest was performed.", "labels": [], "entities": []}, {"text": "Interest was selected because it has been shown in previous studies to be a difficult word to disambiguate.", "labels": [], "entities": []}, {"text": "We selected as the set of sense tags all non-idiomatic noun senses of interest defined in the electronic version of Longman's Dictionary of Contemporary English (LDOCE) ().", "labels": [], "entities": [{"text": "Longman's Dictionary of Contemporary English (LDOCE)", "start_pos": 116, "end_pos": 168, "type": "DATASET", "confidence": 0.9411674671702914}]}, {"text": "Using the models produced in this study, we are able to assign an LDOCE sense tag to every usage of interest in a heldout test set with 78% accuracy.", "labels": [], "entities": [{"text": "LDOCE sense tag", "start_pos": 66, "end_pos": 81, "type": "METRIC", "confidence": 0.9212920665740967}, {"text": "accuracy", "start_pos": 140, "end_pos": 148, "type": "METRIC", "confidence": 0.9980103373527527}]}, {"text": "Although it is difficult to compare our results to those reported for previous disambiguation experiments, as will be discussed later, we feel these results are encouraging.", "labels": [], "entities": []}, {"text": "The remainder of the paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 provides a more complete definition of the methodology used for formulating decomposable models and Section 3 describes the details of the case study performed to test the approach.", "labels": [], "entities": []}, {"text": "The results of the disambiguation case study are discussed and contrasted with similar efforts in Sections 4 and 5.", "labels": [], "entities": [{"text": "disambiguation", "start_pos": 19, "end_pos": 33, "type": "TASK", "confidence": 0.9760720133781433}]}, {"text": "Section 6 is the conclusion.", "labels": [], "entities": []}], "datasetContent": [{"text": "Unlike several previous approaches to word sense disambiguation (,,,), nothing in this approach limits the selection of sense tags to a particular number or type of meaning distinctions.", "labels": [], "entities": [{"text": "word sense disambiguation", "start_pos": 38, "end_pos": 63, "type": "TASK", "confidence": 0.7576213280359904}]}, {"text": "In this study, our goal was to address a non-trivial case of ambiguity, but one that would allow some comparison of results with previous work.", "labels": [], "entities": []}, {"text": "As a result of these considerations, the word interest was chosen as a test case, and the six non-idiomatic noun senses of interest defined in LDOCE were selected as the tag set.", "labels": [], "entities": []}, {"text": "The only restriction limiting the choice of corpus is the need for large amounts of on-line data.", "labels": [], "entities": []}, {"text": "Due to availability, the Penn Treebank Wall Street Journal corpus was selected.", "labels": [], "entities": [{"text": "Penn Treebank Wall Street Journal corpus", "start_pos": 25, "end_pos": 65, "type": "DATASET", "confidence": 0.9731590151786804}]}, {"text": "In total, 2,476 usages 2 of interest as a noun 3 were automatically extracted from the corpus and manually assigned sense tags corresponding to the LDOCE definitions.", "labels": [], "entities": [{"text": "LDOCE definitions", "start_pos": 148, "end_pos": 165, "type": "DATASET", "confidence": 0.8444532155990601}]}, {"text": "During tagging, 107 usages were removed from the data set due to the authors' inability to classify them in terms of the set of LDOCE senses.", "labels": [], "entities": []}, {"text": "Of the rejected usages, 43 are metonymic, and the rest are hybrid meanings specific to the domain, such as public interest group.", "labels": [], "entities": []}, {"text": "Because our sense distinctions are not merely between two or three clearly defined core senses of a word, the task of hand-tagging the tokens of interest required subtle judgments, a point that has also been observed by other researchers disambiguating with respect to the full set of LDOCE senses (,).", "labels": [], "entities": []}, {"text": "Although this undoubtedly degraded the accuracy of the manually assigned sense tags (and thus the accuracy of the study as well), this problem seems unavoidable when making semantic distinctions beyond clearly defined core senses of a word (,,,).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 39, "end_pos": 47, "type": "METRIC", "confidence": 0.9990907907485962}, {"text": "accuracy", "start_pos": 98, "end_pos": 106, "type": "METRIC", "confidence": 0.9993791580200195}]}, {"text": "Of the 2,369 sentences containing the sense-tagged usages of interest, 600 were randomly selected and set aside to serve as the test set.", "labels": [], "entities": []}, {"text": "The distribution of sense tags in the data set is presented in.", "labels": [], "entities": []}, {"text": "We now turn to the selection of individually informative contextual features.", "labels": [], "entities": []}, {"text": "In our approach to disambiguation, a contextual feature is judged to be informative (i.e., correlated with the sense tag of the ambiguous word) if the model for independence between that feature and the sense tag is judged to have an extremely poor fit using the test described in Section 2.", "labels": [], "entities": []}, {"text": "The worse the fit, the more informative the feature is judged to be (similar to the approach suggested in).", "labels": [], "entities": []}, {"text": "Only features whose values can be automatically determined were considered, and preference was given to features that intuitively are not specific to interest (but seethe discussion of collocational features below).", "labels": [], "entities": []}, {"text": "An additional criterion was that the features not have too many possible values, in order to curtail sparsity in the resulting data matrix.", "labels": [], "entities": []}, {"text": "We considered three different types of contextual features: morphological, collocation-specific, and classbased, with part-of-speech (POS) categories serving as the word classes.", "labels": [], "entities": []}, {"text": "Within these classes, we choose a number of specific features, each of which was judged to be informative as described above.", "labels": [], "entities": []}, {"text": "We used one morphological feature: a dichotomous variable indicating the presence or absence of the plural form.", "labels": [], "entities": []}, {"text": "The values of the class-based variables area set of twenty-five POS tags formed, with one exception, from the first letter of the tags used in the Penn Treebank corpus.", "labels": [], "entities": [{"text": "Penn Treebank corpus", "start_pos": 147, "end_pos": 167, "type": "DATASET", "confidence": 0.9945376714070638}]}, {"text": "Two different sets of class-based variables were selected.", "labels": [], "entities": []}, {"text": "The 2For sentences with more than one usage, the tool used to automatically extract the test data ignored all but one of them.", "labels": [], "entities": []}, {"text": "Thus, some usages were missed.", "labels": [], "entities": []}, {"text": "3The Penn Treebank corpus comes complete with POS tags.", "labels": [], "entities": [{"text": "Penn Treebank corpus", "start_pos": 5, "end_pos": 25, "type": "DATASET", "confidence": 0.9924927552541097}]}, {"text": "first set contained only the POS tags of the word immediately preceding and the word immediately succeeding the ambiguous word, while the second set was extended to include the POS tags of the two immediately preceding and two succeeding words.", "labels": [], "entities": []}, {"text": "A limited number of collocation-specific variables were selected, where the term collocation is used loosely to refer to a specific spelling form occurring in the same sentence as the ambiguous word.", "labels": [], "entities": []}, {"text": "All of our colloeational variables are dichotomous, indicating the presence or absence of the associated spelling form.", "labels": [], "entities": []}, {"text": "While collocation-specific variables are, by definition, specific to the word being disambiguated, the procedure used to select them is general.", "labels": [], "entities": []}, {"text": "The search for collocationspecific variables was limited to the 400 most frequent spelling forms in a data sample composed of sentences containing interest.", "labels": [], "entities": []}, {"text": "Out of these 400, the five spelling forms found to be the most informative using the test described above were selected as the collocational variables.", "labels": [], "entities": []}, {"text": "It is not enough to know that each of the features described above is highly correlated with the meaning of the ambiguous word.", "labels": [], "entities": []}, {"text": "In order to use the features in concert to perform disambiguation, a model describing the interactions among them is needed.", "labels": [], "entities": []}, {"text": "Since we had no reason to prefer, a priori, one form of model over another, all models describing possible interactions among the features were generated, and a model with good fit was selected.", "labels": [], "entities": []}, {"text": "Models were generated and tested as described in Section 2.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: The form and performance on the test data of the model found for each set of variables. Each of the", "labels": [], "entities": []}]}