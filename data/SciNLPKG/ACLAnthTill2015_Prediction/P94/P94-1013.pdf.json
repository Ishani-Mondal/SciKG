{"title": [{"text": "DECISION LISTS FOR LEXICAL AMBIGUITY RESOLUTION: Application to Accent Restoration in Spanish and French", "labels": [], "entities": [{"text": "DECISION LISTS FOR LEXICAL AMBIGUITY RESOLUTION", "start_pos": 0, "end_pos": 47, "type": "METRIC", "confidence": 0.7227528691291809}, {"text": "Accent Restoration", "start_pos": 64, "end_pos": 82, "type": "TASK", "confidence": 0.7669324576854706}]}], "abstractContent": [{"text": "This paper presents a statistical decision procedure for lexical ambiguity resolution.", "labels": [], "entities": [{"text": "lexical ambiguity resolution", "start_pos": 57, "end_pos": 85, "type": "TASK", "confidence": 0.8332394560178121}]}, {"text": "The algorithm exploits both local syntactic patterns and more distant collo-cational evidence, generating an efficient, effective, and highly perspicuous recipe for resolving a given ambiguity.", "labels": [], "entities": []}, {"text": "By identifying and utilizing only the single best dis-ambiguating evidence in a target context, the algorithm avoids the problematic complex modeling of statistical dependencies.", "labels": [], "entities": []}, {"text": "Although directly applicable to a wide class of ambiguities, the algorithm is described and evaluated in a realistic case study, the problem of restoring missing accents in Spanish and French text.", "labels": [], "entities": []}, {"text": "Current accuracy exceeds 99% on the full task, and typically is over 90% for even the most difficult ambiguities.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 8, "end_pos": 16, "type": "METRIC", "confidence": 0.9995957016944885}]}], "introductionContent": [{"text": "This paper presents a general-purpose statistical decision procedure for lexical ambiguity resolution based on decision lists.", "labels": [], "entities": [{"text": "lexical ambiguity resolution", "start_pos": 73, "end_pos": 101, "type": "TASK", "confidence": 0.6600807011127472}]}, {"text": "The algorithm considers multiple types of evidence in the context of an ambiguous word, exploiting differences in collocational distribution as measured by log-likelihoods.", "labels": [], "entities": []}, {"text": "Unlike standard Bayesian approaches, however, it does not combine the log-likelihoods of all available pieces of contextual evidence, but bases its classifications solely on the single most reliable piece of evidence identified in the target context.", "labels": [], "entities": []}, {"text": "Perhaps surprisingly, this strategy appears to yield the same or even slightly better precision than the combination of evidence approach when trained on the same features.", "labels": [], "entities": [{"text": "precision", "start_pos": 86, "end_pos": 95, "type": "METRIC", "confidence": 0.9993652701377869}]}, {"text": "It also brings with it several additional advantages, the greatest of which is the ability to include multiple, highly non-independent sources of evidence without complex modeling of dependencies.", "labels": [], "entities": []}, {"text": "Some other advantages are significant simplicity and ease of implementation, transparent understandability *This research was supported by an NDSEG Fellowship, ARPA grant N00014-90-J-1863 and ARO grant DAAL 03-89-C0031 PRI.", "labels": [], "entities": [{"text": "NDSEG Fellowship", "start_pos": 142, "end_pos": 158, "type": "DATASET", "confidence": 0.8390486836433411}, {"text": "ARPA grant N00014-90-J-1863", "start_pos": 160, "end_pos": 187, "type": "DATASET", "confidence": 0.7589523792266846}, {"text": "ARO grant DAAL 03-89-C0031 PRI", "start_pos": 192, "end_pos": 222, "type": "DATASET", "confidence": 0.8406142473220826}]}, {"text": "The author is also affiliated with the Linguistics Research Department of AT&T Bell Laboratories, and greatly appreciates the use of its resources in support of this work.", "labels": [], "entities": [{"text": "AT&T Bell Laboratories", "start_pos": 74, "end_pos": 96, "type": "DATASET", "confidence": 0.8020300745964051}]}, {"text": "He would like to thank Jason Eisner, Libby Levison, Mark Liberman, Mitch Marcus, Joseph Rosenzweig and Mark Zeren for their valuable feedback. of the resulting decision list, and easy adaptability to new domains.", "labels": [], "entities": []}, {"text": "The particular domain chosen here as a case study is the problem of restoring missing accents 1 to Spanish and French text.", "labels": [], "entities": []}, {"text": "Because it requires the resolution of both semantic and syntactic ambiguity, and offers an objective ground truth for automatic evaluation, it is particularly well suited for demonstrating and testing the capabilities of the given algorithm.", "labels": [], "entities": []}, {"text": "It is also a practical problem with immediate application.", "labels": [], "entities": []}], "datasetContent": [{"text": "Because we have only stripped accents artificially for testing purposes, and the \"correct\" patterns exist online in the original corpus, we can evaluate performance objectively and automatically.", "labels": [], "entities": []}, {"text": "This contrasts with other classification tasks such as word-sense disambiguation and part-of-speech tagging, whereat some point human judgements are required.", "labels": [], "entities": [{"text": "word-sense disambiguation", "start_pos": 55, "end_pos": 80, "type": "TASK", "confidence": 0.7357076108455658}, {"text": "part-of-speech tagging", "start_pos": 85, "end_pos": 107, "type": "TASK", "confidence": 0.6951358616352081}]}, {"text": "Regrettably, however, there are errors in the original corpus, which can be quite substantial depending on the type of accent.", "labels": [], "entities": []}, {"text": "For example, in the Spanish data, accents over the i (1) are frequently omitted; in a sample test 3.7% of the appropriate i accents were missing.", "labels": [], "entities": [{"text": "Spanish data", "start_pos": 20, "end_pos": 32, "type": "DATASET", "confidence": 0.7127900570631027}]}, {"text": "Thus the following results must be interpreted as agreement rates with the corpus accent pattern; the true percent correct maybe several percentage points higher.", "labels": [], "entities": []}, {"text": "The following table gives a breakdown of the different types of Spanish accent ambiguities, their relative frequency in the training corpus, and the algorithm's performance on each: 1\u00b0 As observed before, the prior probabilities in favor of the most common accent pattern are highly skewed, so one does reasonably well at this task by always using the most common pattern.", "labels": [], "entities": []}, {"text": "But the error rate is still 1\u00b0The term prioris a measure of the baseline performance one would expect if the algorithm always chose the most common option.", "labels": [], "entities": [{"text": "error rate", "start_pos": 8, "end_pos": 18, "type": "METRIC", "confidence": 0.9729371070861816}]}, {"text": "roughly 1 per every 75 words, which is unacceptably high.", "labels": [], "entities": []}, {"text": "This algorithm reduces that error rate by over 65%.", "labels": [], "entities": [{"text": "error rate", "start_pos": 28, "end_pos": 38, "type": "METRIC", "confidence": 0.9845454394817352}]}, {"text": "However, to get a better picture of the algorithm's performance, the following table gives a breakdown of results fora random set of the most problematic cases -words exhibiting the largest absolute number of the non-majority accent patterns.", "labels": [], "entities": []}, {"text": "Collectively they constitute the most common potential sources of error.", "labels": [], "entities": []}, {"text": "Evaluation is based on the corpora described in the algorithm's Step 2.", "labels": [], "entities": []}, {"text": "In all experiments, 4/5 of the data was used for training and the remaining 1/5 held out for testing.", "labels": [], "entities": []}, {"text": "More accurate measures of algorithm performance were obtained by repeating each experiment 5 times, using a different 1/5 of the data for each test, and averaging the results.", "labels": [], "entities": []}, {"text": "Note that in every experiment, results were measured on independent test data not seen in the training phase.", "labels": [], "entities": []}], "tableCaptions": []}