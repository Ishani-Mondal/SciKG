{"title": [{"text": "A HYBRID REASONING MODEL FOR INDIRECT ANSWERS", "labels": [], "entities": [{"text": "A HYBRID REASONING MODEL FOR INDIRECT ANSWERS", "start_pos": 0, "end_pos": 45, "type": "METRIC", "confidence": 0.674161033970969}]}], "abstractContent": [{"text": "This paper presents our implemented computational model for interpreting and generating indirect answers to Yes-No questions.", "labels": [], "entities": [{"text": "interpreting and generating indirect answers to Yes-No questions", "start_pos": 60, "end_pos": 124, "type": "TASK", "confidence": 0.8073709532618523}]}, {"text": "Its main features are 1) a discourse-plan-based approach to implicature, 2) a reversible architecture for generation and interpretation, 3) a hybrid reasoning model that employs both plan inference and logical inference, and 4) use of stimulus conditions to model a speaker's motivation for providing appropriate , unrequested information.", "labels": [], "entities": [{"text": "generation and interpretation", "start_pos": 106, "end_pos": 135, "type": "TASK", "confidence": 0.7016095022360483}]}, {"text": "The model handles a wider range of types of indirect answers than previous computational models and has several significant advantages.", "labels": [], "entities": []}], "introductionContent": [{"text": "Imagine a discourse context for (1) in which R's use of just (ld) is intended to convey a No, i.e., that R is not going shopping tonight.", "labels": [], "entities": []}, {"text": "(By convention, square brackets indicate that the enclosed text was not explicitly stated.)", "labels": [], "entities": []}, {"text": "The part of R's response consisting of (ld) -(le) is what we call an According to one study of spoken English, 13 percent of responses to YesNo questions were indirect answers.", "labels": [], "entities": []}, {"text": "Thus, the ability to interpret indirect answers is required for robust dialogue systems.", "labels": [], "entities": [{"text": "interpret indirect answers", "start_pos": 21, "end_pos": 47, "type": "TASK", "confidence": 0.8879439433415731}]}, {"text": "Furthermore, there are good reasons for generating indirect answers instead of just yes, no, or I don't know.", "labels": [], "entities": []}, {"text": "First, they may provide information which is needed to avoid misleading the questioner.", "labels": [], "entities": []}, {"text": "Second, they contribute to an efficient dialogue by anticipating follow-up questions.", "labels": [], "entities": []}, {"text": "Third, they maybe used for social reasons, as in (1).", "labels": [], "entities": []}, {"text": "This paper provides a computational model for the interpretation and generation of indirect answers to Yes-No questions in English.", "labels": [], "entities": [{"text": "interpretation and generation of indirect answers to Yes-No questions", "start_pos": 50, "end_pos": 119, "type": "TASK", "confidence": 0.8015160527494218}]}, {"text": "More precisely, by a Yes-No question we mean one or more utterances used as a request by Q (the questioner) that R (the responder) convey R's evaluation of the truth of a proposition p.", "labels": [], "entities": []}, {"text": "An indirect answer implicitly conveys via one or more utterances R's evaluation of the truth of the questioned proposition p, i.e. that p is true, that p is false, that there is some truth top, that p maybe true, or that p maybe false.", "labels": [], "entities": []}, {"text": "Our model presupposes that Q's question has been understood by R as intended by Q, that Q's request was appropriate, and that Q and R are engaged in a cooperative goal-directed dialogue.", "labels": [], "entities": []}, {"text": "The interpretation and generation components of the model have been implemented in Common Lisp on a Sun SPARCstation.", "labels": [], "entities": []}, {"text": "The model employs an agent's pragmatic knowledge of how language typically is used to answer Yes-No questions in English to constrain the process of generating and interpreting indirect answers.", "labels": [], "entities": []}, {"text": "This knowledge is encoded as a set of domain-independent discourse plan operators and a set of coherence rules, described in section 2.1 shows the architecture of our system.", "labels": [], "entities": []}, {"text": "It is reversible in that the same pragmatic knowledge is used by the interpretation and generation modules.", "labels": [], "entities": []}, {"text": "The interpretation algorithm, described in section 3, is a hybrid approach employing both plan inference and logical inference to infer R's discourse plan.", "labels": [], "entities": []}, {"text": "The generation algorithm, described in section 4, constructs R's discourse plan in two phases.", "labels": [], "entities": []}, {"text": "During the first phase, stimulus conditions are used to trigger goals to include appropriate, extra information in the response plan.", "labels": [], "entities": []}, {"text": "In the second phase, the response plan is pruned to eliminate parts which can be inferred by Q. hOur main sources of data were previous studies, transcripts of naturally occurring two-person dialogue, and constructed examples.", "labels": [], "entities": [{"text": "Q. hOur", "start_pos": 93, "end_pos": 100, "type": "DATASET", "confidence": 0.6553240716457367}]}], "datasetContent": [], "tableCaptions": []}