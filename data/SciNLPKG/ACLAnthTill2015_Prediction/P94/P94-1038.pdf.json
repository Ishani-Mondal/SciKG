{"title": [{"text": "Similarity-Based Estimation of Word Cooccurrence Probabilities", "labels": [], "entities": []}], "abstractContent": [{"text": "In many applications of natural language processing it is necessary to determine the likelihood of a given word combination.", "labels": [], "entities": [{"text": "natural language processing", "start_pos": 24, "end_pos": 51, "type": "TASK", "confidence": 0.689196765422821}]}, {"text": "For example, a speech recognizer may need to determine which of the two word combinations \"eat a peach\" and \"eat a beach\" is more likely.", "labels": [], "entities": [{"text": "speech recognizer", "start_pos": 15, "end_pos": 32, "type": "TASK", "confidence": 0.6898902356624603}]}, {"text": "Statistical NLP methods determine the likelihood of a word combination according to its frequency in a training corpus.", "labels": [], "entities": []}, {"text": "However, the nature of language is such that many word combinations are infrequent and do not occur in a given corpus.", "labels": [], "entities": []}, {"text": "In this work we propose a method for estimating the probability of such previously unseen word combinations using available information on \"most sim-ilar\" words.", "labels": [], "entities": []}, {"text": "We describe a probabilistic word association model based on distributional word similarity, and apply it to improving probability estimates for unseen word bi-grams in a variant of Katz's back-off model.", "labels": [], "entities": []}, {"text": "The similarity-based method yields a 20% perplexity improvement in the prediction of unseen bigrams and statistically significant reductions in speech-recognition error .", "labels": [], "entities": []}], "introductionContent": [{"text": "Data sparseness is an inherent problem in statistical methods for natural language processing.", "labels": [], "entities": []}, {"text": "Such methods use statistics on the relative frequencies of configurations of elements in a training corpus to evaluate alternative analyses or interpretations of new samples of text or speech.", "labels": [], "entities": []}, {"text": "The most likely analysis will betaken to be the one that contains the most frequent configurations.", "labels": [], "entities": []}, {"text": "The problem of data sparseness arises when analyses contain configurations that never occurred in the training corpus.", "labels": [], "entities": []}, {"text": "Then it is not possible to estimate probabilities from observed frequencies, andsome other estimation scheme has to be used.", "labels": [], "entities": []}, {"text": "We focus hereon a particular kind of configuration, word cooccurrence.", "labels": [], "entities": []}, {"text": "Examples of such cooccurrences include relationships between head words in syntactic constructions (verb-object or adjective-noun, for example) and word sequences (n-grams).", "labels": [], "entities": []}, {"text": "In commonly used models, the probability estimate fora previously unseen cooccurrence is a function of the probability esti-", "labels": [], "entities": []}], "datasetContent": [{"text": "2The ARPA WSJ development corpora come in two versions, one with verbalized punctuation and the other without.", "labels": [], "entities": [{"text": "ARPA WSJ development corpora", "start_pos": 5, "end_pos": 33, "type": "DATASET", "confidence": 0.8124015778303146}]}, {"text": "We used the latter in all our experiments.", "labels": [], "entities": []}, {"text": "shows reductions in training and test perplexity, sorted by training reduction, for different choices in the number k of closest neighbors used.", "labels": [], "entities": []}, {"text": "The values of f~, 7 and tare the best ones found for each k.", "labels": [], "entities": [{"text": "tare", "start_pos": 24, "end_pos": 28, "type": "METRIC", "confidence": 0.9906925559043884}]}, {"text": "3 From equation, it is clear that the computational cost of applying the similarity model to an unseen bigram is O(k).", "labels": [], "entities": [{"text": "O", "start_pos": 113, "end_pos": 114, "type": "METRIC", "confidence": 0.9924911856651306}]}, {"text": "Therefore, lower values fork (and also for t) are computationally preferable.", "labels": [], "entities": []}, {"text": "From the table, we can see that reducing k to 30 incurs a penalty of less than 1% in the perplexity improvement, so relatively low values of k appear to be sufficient to achieve most of the benefit of the similarity model.", "labels": [], "entities": []}, {"text": "As the table also shows, the best value of 7 increases ask decreases, that is, for lower k a greater weight is given to the conditioned word's frequency.", "labels": [], "entities": [{"text": "ask", "start_pos": 55, "end_pos": 58, "type": "METRIC", "confidence": 0.9697859883308411}]}, {"text": "This suggests that the predictive power of neighbors beyond the closest 30 or so can be modeled fairly well by the overall frequency of the conditioned word.", "labels": [], "entities": []}, {"text": "The bigram similarity model was also tested as a language model in speech recognition.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 67, "end_pos": 85, "type": "TASK", "confidence": 0.8080699145793915}]}, {"text": "The test data for this experiment were pruned word lattices for 403 WSJ closed-vocabulary test sentences.", "labels": [], "entities": [{"text": "WSJ closed-vocabulary test sentences", "start_pos": 68, "end_pos": 104, "type": "DATASET", "confidence": 0.8242486417293549}]}, {"text": "Arc scores in those lattices are sums of an acoustic score (negative log likelihood) and a language-model score, in this case the negative log probability provided by the baseline bigram model.", "labels": [], "entities": []}, {"text": "From the given lattices, we constructed new lattices in which the arc scores were modified to use the similarity model instead of the baseline model.", "labels": [], "entities": []}, {"text": "We compared the best sentence hypothesis in each original lattice and in the modified one, and counted the word disagreements in which one of the hypotheses is correct.", "labels": [], "entities": []}, {"text": "There were a total of 96 such disagreements.", "labels": [], "entities": []}, {"text": "The similarity model was correct in 64 cases, and the back-off model in 32.", "labels": [], "entities": [{"text": "similarity", "start_pos": 4, "end_pos": 14, "type": "METRIC", "confidence": 0.9760973453521729}]}, {"text": "This advantage for the similarity model is statistically significant at the 0.01 level.", "labels": [], "entities": [{"text": "similarity", "start_pos": 23, "end_pos": 33, "type": "METRIC", "confidence": 0.9354851841926575}]}, {"text": "The overall reduction in error rate is small, from 21.4% to 20.9%, because the number of disagreements is small compared with 3Values of fl and t refer to base 10 logarithms and exponentials in all calculations.", "labels": [], "entities": [{"text": "error rate", "start_pos": 25, "end_pos": 35, "type": "METRIC", "confidence": 0.9897860586643219}]}, {"text": "the overall number of errors in our current recognition setup.", "labels": [], "entities": []}, {"text": "shows some examples of speech recognition disagreements between the two models.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 23, "end_pos": 41, "type": "TASK", "confidence": 0.7937905788421631}]}, {"text": "The hypotheses are labeled 'B' for back-off and 'S' for similarity, and the bold-face words are errors.", "labels": [], "entities": [{"text": "similarity", "start_pos": 56, "end_pos": 66, "type": "METRIC", "confidence": 0.9598234295845032}]}, {"text": "The similarity model seems to be able to model better regularities such as semantic parallelism in lists and avoiding a past tense form after \"to.\"", "labels": [], "entities": []}, {"text": "On the other hand, the similarity model makes several mistakes in which a function word is inserted in a place where punctuation would be found in written text.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Perplexity Reduction on Unseen Bigrams for Different Model Parameters", "labels": [], "entities": [{"text": "Perplexity Reduction", "start_pos": 10, "end_pos": 30, "type": "TASK", "confidence": 0.8177202641963959}]}]}