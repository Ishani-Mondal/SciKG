{"title": [{"text": "Tree Insertion Grammar: A Cubic-Time, Parsable Formalism that Lexicalizes Context-Free Grammar without Changing the Trees Produced", "labels": [], "entities": [{"text": "Tree Insertion Grammar", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.752410501241684}, {"text": "Lexicalizes Context-Free Grammar", "start_pos": 62, "end_pos": 94, "type": "TASK", "confidence": 0.7778374552726746}]}], "abstractContent": [{"text": "Tree insertion grammar (TIG) is a tree-based formalism that makes use of tree substitution and tree adjunction.", "labels": [], "entities": [{"text": "Tree insertion grammar (TIG)", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.8506071120500565}]}, {"text": "TIG is related to tree adjoining grammar.", "labels": [], "entities": [{"text": "TIG", "start_pos": 0, "end_pos": 3, "type": "METRIC", "confidence": 0.5728160738945007}]}, {"text": "However, the adjunction permitted in TIG is sufficiently restricted that TIGs only derive context-free languages and TIGs have the same cubic-time worst-case complexity bounds for recognition and parsing as context-free grammars.", "labels": [], "entities": [{"text": "recognition and parsing", "start_pos": 180, "end_pos": 203, "type": "TASK", "confidence": 0.6279027760028839}]}, {"text": "An efficient Earley-style parser for TIGs is presented.", "labels": [], "entities": []}, {"text": "Any context-free grammar (CFG) can be converted into a lexicalized tree insertion grammar (LTIG) that generates the same trees.", "labels": [], "entities": []}, {"text": "A constructive procedure is presented for converting a CFG into a left anchored (i.e., word initial) LTIG that preserves ambiguity and generates the same trees.", "labels": [], "entities": []}, {"text": "The L,TIG created can be represented compactly by taking advantage of sharing between the elementary trees in it.", "labels": [], "entities": []}, {"text": "Methods of converting CFGs into left anchored CFGs, e.g., the methods of Greibach and Rosenkrantz, do not preserve the trees produced and result in very large output grammars.", "labels": [], "entities": []}, {"text": "For the purpose of experimental evaluation, the LTIG lexicalization procedure was applied to eight different CFGs for subsets of English.", "labels": [], "entities": []}, {"text": "The LTIGs created were smaller than the original CFGs.", "labels": [], "entities": [{"text": "CFGs", "start_pos": 49, "end_pos": 53, "type": "DATASET", "confidence": 0.93719482421875}]}, {"text": "Using an implementation of the Earley-style TIG parser that was specialized for left anchored LTIGs, it was possible to parse more quickly with the LTIGs than with the original CFGs.", "labels": [], "entities": []}], "introductionContent": [{"text": "Most current linguistic theories give lexical accounts of several phenomena that used to be considered purely syntactic.", "labels": [], "entities": []}, {"text": "1 The information put in the lexicon is thereby increased in both amount and complexity.", "labels": [], "entities": [{"text": "complexity", "start_pos": 77, "end_pos": 87, "type": "METRIC", "confidence": 0.9668602347373962}]}, {"text": "In this paper, we study the problem of lexicalizing context-free grammars and show that it enables faster processing.", "labels": [], "entities": []}, {"text": "In previous attempts to take advantage of lexicalization, a variety of lexicalization procedures have been developed that convert context-free grammars (CFGs) into equivalent lexicalized grammars.", "labels": [], "entities": []}, {"text": "However, these procedures typically suffer from one or more of the following problems.", "labels": [], "entities": []}, {"text": "\u2022 Lexicalization procedures such as those developed by * Mitsubishi Electric Research Laboratories, 201 Broadway, Cambridge, MA 02139, USA.", "labels": [], "entities": [{"text": "Mitsubishi Electric Research Laboratories, 201 Broadway, Cambridge, MA 02139", "start_pos": 57, "end_pos": 133, "type": "DATASET", "confidence": 0.9218838761250178}]}, {"text": "E-mail: schabes/waters@merl.com.", "labels": [], "entities": []}, {"text": "1 Some of the linguistic formalisms illustrating the increased use of lexical information are: lexical rules in LFG (, GPSG (, HPSG, Categorial Grammars, some versions of GB theory, and Lexicon-Grammars (.", "labels": [], "entities": []}, {"text": "Like CFG, TIG can be parsed in O(IGInB)-time.", "labels": [], "entities": [{"text": "CFG", "start_pos": 5, "end_pos": 8, "type": "DATASET", "confidence": 0.9190790057182312}, {"text": "O(IGInB)-time", "start_pos": 31, "end_pos": 44, "type": "METRIC", "confidence": 0.8460504412651062}]}, {"text": "Section 4 presents an Earley-style parser for TIG that maintains the valid prefix property.", "labels": [], "entities": [{"text": "TIG", "start_pos": 46, "end_pos": 49, "type": "DATASET", "confidence": 0.8123904466629028}]}, {"text": "Section 5 presents a procedure that converts CFGs into lexicalized tree insertion grammars (LTIGs) generating the same trees.", "labels": [], "entities": [{"text": "CFGs into lexicalized tree insertion grammars (LTIGs", "start_pos": 45, "end_pos": 97, "type": "TASK", "confidence": 0.6986959613859653}]}, {"text": "The procedure produces a left anchored LTIG---one where for each elementary tree, the first element that must be matched against the input is a lexical item.", "labels": [], "entities": []}, {"text": "Section 6 presents a number of experiments evaluating TIG.", "labels": [], "entities": [{"text": "TIG", "start_pos": 54, "end_pos": 57, "type": "TASK", "confidence": 0.8866353034973145}]}, {"text": "Section 6.1 shows that the grammars generated by the LTIG procedure can be represented very compactly.", "labels": [], "entities": []}, {"text": "In the experiments performed, the LTIG grammars are smaller than the CFGs they are generated from.", "labels": [], "entities": []}, {"text": "Section 6.2 investigates the practical value of the grammars created by the LTIG procedure as a vehicle for parsing CFGs.", "labels": [], "entities": [{"text": "parsing CFGs", "start_pos": 108, "end_pos": 120, "type": "TASK", "confidence": 0.8020232915878296}]}, {"text": "It reports a number of experiments comparing a standard Earley-style parser for CFGs with the Earley-style TIG parser of Section 4, adapted to take advantage of the left anchored nature of the grammars created by the LTIG procedure.", "labels": [], "entities": []}, {"text": "In these experiments, parsing using LTIG is typically 5 to 10 times faster.", "labels": [], "entities": [{"text": "parsing", "start_pos": 22, "end_pos": 29, "type": "TASK", "confidence": 0.9800974726676941}]}, {"text": "The original motivation behind the development of TIG was the intuition that the natural-language grammars currently being developed using TAG do not make full use of the capabilities provided by TAG.", "labels": [], "entities": []}, {"text": "This suggests a different use for TIG--as a (partial) substitute for TAG.", "labels": [], "entities": [{"text": "TIG", "start_pos": 34, "end_pos": 37, "type": "METRIC", "confidence": 0.6391807198524475}, {"text": "TAG", "start_pos": 69, "end_pos": 72, "type": "METRIC", "confidence": 0.729181706905365}]}, {"text": "This idea is explored in Section 7.", "labels": [], "entities": []}], "datasetContent": [{"text": "The experiments below use eight grammars for fragments of English as test cases (see).", "labels": [], "entities": []}, {"text": "The first four grammars are the test CFGs used by.", "labels": [], "entities": []}, {"text": "The next three grammars are derived from the Treebank corpus () of hand-parsed sentences from the Wall Street Journal.", "labels": [], "entities": [{"text": "Treebank corpus () of hand-parsed sentences from the Wall Street Journal", "start_pos": 45, "end_pos": 117, "type": "DATASET", "confidence": 0.7379393062808297}]}, {"text": "Each \"Treebank n\" grammar corresponds to then most commonly occurring local rules in the corpus that form a CFG with no useless productions.", "labels": [], "entities": []}, {"text": "8 The eighth grammar is a CFG grammar used in the natural language processing component of a simple interactive computer environment.", "labels": [], "entities": []}, {"text": "It supports conversation with an animated robot called Mike (.", "labels": [], "entities": []}, {"text": "The grammars are all finitely ambiguous and none generates the empty string.", "labels": [], "entities": []}, {"text": "The Tomita III grammar contains an empty rule.", "labels": [], "entities": [{"text": "Tomita III grammar", "start_pos": 4, "end_pos": 22, "type": "DATASET", "confidence": 0.6244167685508728}]}, {"text": "The relative size and complexity of the grammars is indicated at the top of.", "labels": [], "entities": []}, {"text": "The size [G[ is computed as appropriate for an Earley-style CFG parser--i.e., as the number of possible dotted rules, which is the sum, overall the rules, of: one plus the number of elements on the right-hand side of the rule.", "labels": [], "entities": []}, {"text": "The bottom of summarizes the left and right recursive structure of the test grammars.", "labels": [], "entities": []}, {"text": "The grammars have very few sets of mutually left recursive rules involving more than one nonterminal.", "labels": [], "entities": []}, {"text": "In contrast, all but the smallest grammars have many sets of mutually right recursive rules involving significant numbers of different nonterminals.", "labels": [], "entities": []}, {"text": "This reflects the fact that English is primarily right recursive in nature.", "labels": [], "entities": []}, {"text": "Due to the unbalanced recursive nature of the test grammars, left anchored lexicalizations are more compact than right anchored ones.", "labels": [], "entities": []}, {"text": "For languages that are primarily left recursive in nature, the situation would be reversed.", "labels": [], "entities": []}, {"text": "The experiments below are based on parsing a corpus of randomly generated sentences.", "labels": [], "entities": [{"text": "parsing a corpus of randomly generated sentences", "start_pos": 35, "end_pos": 83, "type": "TASK", "confidence": 0.694428060735975}]}, {"text": "For each test grammar, four sentences were generated of each possible length from 1-25.", "labels": [], "entities": []}, {"text": "The top of shows the average number of parses of these sentences versus sentence length.", "labels": [], "entities": []}, {"text": "The ambiguity varies by five orders of magnitude across the test corpus.", "labels": [], "entities": []}, {"text": "The bottom of shows the average number of chart states created when parsing the test sentences using a standard Earley-style CFG parser.", "labels": [], "entities": [{"text": "CFG", "start_pos": 125, "end_pos": 128, "type": "DATASET", "confidence": 0.7089937329292297}]}, {"text": "As is to be expected, the number of chart states rises significantly with the complexity of the grammars, varying by two orders of magnitude.", "labels": [], "entities": []}, {"text": "The number of chart states also grows with the length of the sentences, but not much faster than linearly.", "labels": [], "entities": []}], "tableCaptions": []}