{"title": [{"text": "Modularity and Information Content Classes in Principle-based Parsing", "labels": [], "entities": [{"text": "Parsing", "start_pos": 62, "end_pos": 69, "type": "TASK", "confidence": 0.3838580548763275}]}], "abstractContent": [{"text": "In recent years models of parsing that are isomorphic to a principle-based theory of grammar (most notably Government and Binding (GB) Theory) have been proposed (Berwick et al. 1991).", "labels": [], "entities": [{"text": "Government and Binding (GB) Theory)", "start_pos": 107, "end_pos": 142, "type": "TASK", "confidence": 0.7815881632268429}]}, {"text": "These models are natural and direct implementations of the grammar, but they are not efficient, because GB is not a computationally modular theory.", "labels": [], "entities": []}, {"text": "This paper investigates one problem related to the tension between building linguistically based parsers and building efficient ones.", "labels": [], "entities": []}, {"text": "In particular, the issue of what is a linguistically motivated way of deriving a parser from principle-based theories of grammar is explored.", "labels": [], "entities": []}, {"text": "It is argued that an efficient and faithful parser can be built by taking advantage of the way in which principles are stated.", "labels": [], "entities": []}, {"text": "To support this claim, two features of an implemented parser are discussed.", "labels": [], "entities": []}, {"text": "First, configurations and lexical information are precompiled separately into two tables (an X table and a table of lexical co-occurrence) which gives rise to more compact data structures.", "labels": [], "entities": []}, {"text": "Secondly, precomputation of syntactic features (O-roles, case, etc.) results in efficient computation of chains, because it reduces several problems of chain formation to a local computation, thus avoiding extensive search of the tree for an antecedent or extensive backtracking.", "labels": [], "entities": []}, {"text": "It is also shown that this method of building long-distance dependencies can be computed incrementally.", "labels": [], "entities": []}], "introductionContent": [{"text": "In the development of parsers for syntactic analysis, it is standard practice to posit two working levels: the grammar, on the one hand, and the algorithms, which produce the analysis of the sentence by using the grammar as the source of syntactic knowledge, on the other hand.", "labels": [], "entities": [{"text": "syntactic analysis", "start_pos": 34, "end_pos": 52, "type": "TASK", "confidence": 0.8777362704277039}]}, {"text": "Usually the grammar is derived directly from the work of theoretical linguists.", "labels": [], "entities": []}, {"text": "The interest in building a parser that is grounded in a linguistic theory as closely as possible rests on two sets of reasons: first, theories are developed to account for empirical facts about language in a concise way--they seek general, abstract, language-independent explanations for linguistic phenomena; second, current linguistic theories are supposed to be models of humans' knowledge of language.", "labels": [], "entities": []}, {"text": "Parsers that can use grammars directly are more likely to have wide coverage, and to be valid for many languages; they also constitute the most economical model of the human ability to put knowledge of language to use.", "labels": [], "entities": []}, {"text": "Therefore, postulating a direct correspondence between the parser and theories of grammar is, methodologically, the strongest position, and is usually assumed as a starting point of investigation.", "labels": [], "entities": []}, {"text": "However, experiments with parsers that are tightly related to linguistic principles have often been a disappointment, largely because these parsers are inefficient.", "labels": [], "entities": []}, {"text": "Inefficiency is a problem that cannot simply be cast aside.", "labels": [], "entities": []}, {"text": "Computationally, it renders the use of linguistic theories impractical, and, empirically, it clashes with the (1) the chains are (John, t) and (The children, t).", "labels": [], "entities": []}, {"text": "John seems [ip t to b.", "labels": [], "entities": []}, {"text": "The children are loved t by John.", "labels": [], "entities": []}, {"text": "The advantage of this treatment is that common properties of language, here certain classes of verbs, are expressed by common principles.", "labels": [], "entities": []}, {"text": "This search for generality is not unique to GB theory.", "labels": [], "entities": [{"text": "GB theory", "start_pos": 44, "end_pos": 53, "type": "TASK", "confidence": 0.703869491815567}]}, {"text": "Feature-structure formalisms also use rule schemata to capture similarities among grammar rules.", "labels": [], "entities": []}, {"text": "Moreover, reentrancy as a notational device to express common features seeks the same type of representational economy that is expressed by the use of \"traces\" in GB theory.", "labels": [], "entities": []}, {"text": "It is desirable fora syntactic analyser to make use of linguistic theories to obtain, at least in principle, the same empirical coverage as the theory, and to capture the same generalizations.", "labels": [], "entities": []}, {"text": "Moreover, a parser that makes direct use of a linguistic theory is more explanatory.", "labels": [], "entities": []}, {"text": "A guiding belief for the development of the generative framework is that a theory that can derive its descriptions from the interaction of a small set of general principles is more explanatory than a theory in which descriptive adequacy is obtained by the interaction of a greater number of more particular, specific principles.", "labels": [], "entities": [{"text": "generative framework", "start_pos": 44, "end_pos": 64, "type": "TASK", "confidence": 0.9149170517921448}]}, {"text": "This is because the former theory is smaller.", "labels": [], "entities": []}, {"text": "Thus, each principle can generate a set the encoding of which would require a much larger number of bits than the bits needed to encode the principle itself.", "labels": [], "entities": []}, {"text": "The classic example is the use of natural classes of distinctive features in phonology, in order to compact several rules into one.", "labels": [], "entities": []}, {"text": "A modular theory that encodes universal principles has obtained a greater degree of \u2022 succinctness than a nonmodular theory, and is considered more explanatory.", "labels": [], "entities": []}, {"text": "Since it is desirable for the parser to maintain the level of explanatory power of the theory, it must maintain its modularity.", "labels": [], "entities": []}, {"text": "It has also been argued) that the current shift from rules to a modular system of principles has computational advantages.", "labels": [], "entities": []}, {"text": "Principle-based grammars engender compactness: Given a set of principles, P1, P2,..., Pn, the principles are stored separately and their interaction is computed on-line; the multiplicative interaction of the principles, P1 x P2 x ...", "labels": [], "entities": []}, {"text": "\u00d7 Pn does not need to be stored.", "labels": [], "entities": []}, {"text": "Hence, the size of the grammar is the sum of the sizes of its components: IGI = P~ + P2 + \"'\" 4-Pn.", "labels": [], "entities": [{"text": "IGI", "start_pos": 74, "end_pos": 77, "type": "METRIC", "confidence": 0.985630989074707}]}, {"text": "Consequently, a parser based on such a grammar is compact, and, theoretically, easier to debug, maintain and update.", "labels": [], "entities": []}, {"text": "1 In practice, however, designing and implementing faithful and efficient parsers is not a simple matter.", "labels": [], "entities": []}, {"text": "Defining \"faithfulness\" to a linguistic theory is not a trivial task, as a direct relation between the grammar and the parser is not the only option (see, and references therein).", "labels": [], "entities": []}, {"text": "In general, it is not necessary fora parser to implement the principles of the grammar directly.", "labels": [], "entities": []}, {"text": "Rather, a covering grammar could be used, more suited to the purpose of parsing.", "labels": [], "entities": [{"text": "parsing", "start_pos": 72, "end_pos": 79, "type": "TASK", "confidence": 0.9635909795761108}]}, {"text": "However, it is important that such covering be done in such away that accidental properties of a particular grammar, which would not hold under counterfactual changes, are not used.", "labels": [], "entities": []}, {"text": "Otherwise, the covering grammar would not be sufficiently general.", "labels": [], "entities": []}, {"text": "A faithful implementation is particularly difficult in the GB framework, as GB principles are informally expressed as English statements, and can take a variety of forms.", "labels": [], "entities": []}, {"text": "For example, X theory (a condition on graphs), the Case Filter (an output filter on strings), and the 0 criterion (a bijection relation on predicates and arguments) all fall under the label of principles.", "labels": [], "entities": []}, {"text": "Attempts have been made to formalize GB principles to a set of axioms.", "labels": [], "entities": []}, {"text": "One possible, extreme interpretation of the direct use of principles is an approach where no grammar compilation is allowed.", "labels": [], "entities": []}, {"text": "2 This approach is appealing because it reflects, intuitively, the idea of using the grammar as a set of axioms and reduces parsing to a deduction process.", "labels": [], "entities": []}, {"text": "This is very much in the spirit of the current shift in linguistic theories from construction-dependent rules to general principles, and it separates quite clearly the grammar from the parsing algorithm.", "labels": [], "entities": []}, {"text": "However, it is not obvious that this approach is efficient.", "labels": [], "entities": []}, {"text": "Partial evaluation and variable substitution can increase performance, but, as usual, a space/time trade-off will ensue.", "labels": [], "entities": [{"text": "variable substitution", "start_pos": 23, "end_pos": 44, "type": "TASK", "confidence": 0.7134176939725876}]}, {"text": "Excess of partial evaluation off-line increases the size of the grammar, which might, in turn, slowdown the parse.", "labels": [], "entities": []}, {"text": "Experimentation with different kinds of algorithms suggests that some amount of compilation of the principles might be necessary to alleviate the problem of inefficiency, but that too much compilation slows down the parser again.", "labels": [], "entities": []}, {"text": "shows that the size of a cascade of distinct principles (viewed as machines) is the size of its subparts, while if these same principles are collapsed, the size of the entire system grows mulfiplicatively.", "labels": [], "entities": []}, {"text": "Modularity corresponds to maximal succinctness when all independent principles are stated separately.", "labels": [], "entities": []}, {"text": "Independent principles are, intuitively, principles that can be computed independently of each other, and therefore whose interactions are all possible. and attempt to formalize the concept of independence as separability, assuming that the topology of a principle-based theory like GB can be mapped onto a planar graph.", "labels": [], "entities": []}, {"text": "In fact, if independent modules are separable modules, there is little reason to think that GB is modular, as it corresponds to a highly connected graph.", "labels": [], "entities": []}, {"text": "2 By compilation, here and below, I mean off-line computation of some general property of the grammar, for example the off-line computation of the interaction of principles, using partial evaluation or variable substitution.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1  Comparison of the 3 grammars (compiled into LR tables)", "labels": [], "entities": []}, {"text": " Table 2  Number of actions in the 3 LR tables", "labels": [], "entities": []}, {"text": " Table 4  Comparison of the 3 grammars (compiled into LC tables)", "labels": [], "entities": []}, {"text": " Table 5. As can be seen from", "labels": [], "entities": []}]}