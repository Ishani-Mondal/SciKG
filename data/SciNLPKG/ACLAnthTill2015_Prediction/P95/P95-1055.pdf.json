{"title": [{"text": "Acquisition of a Lexicon from Semantic Representations of Sentences*", "labels": [], "entities": []}], "abstractContent": [{"text": "A system, WOLFIE, that acquires a mapping of words to their semantic representation is presented and a preliminary evaluation is performed.", "labels": [], "entities": []}, {"text": "Tree least general generalizations (TLGGs) of the representations of input sentences are performed to assist in determining the representations of individual words in the sentences.", "labels": [], "entities": []}, {"text": "The best guess fora meaning of a word is the TLGG which overlaps with the highest percentage of sentence representations in which that word appears.", "labels": [], "entities": [{"text": "TLGG", "start_pos": 45, "end_pos": 49, "type": "METRIC", "confidence": 0.9773226976394653}]}, {"text": "Some promising experimental results on a non-artificial data set are presented.", "labels": [], "entities": []}], "introductionContent": [{"text": "Computer language learning is an area of much potential and recent research.", "labels": [], "entities": [{"text": "Computer language learning", "start_pos": 0, "end_pos": 26, "type": "TASK", "confidence": 0.7995369831720988}]}, {"text": "One goal is to learn to map surface sentences to a deeper semantic meaning.", "labels": [], "entities": []}, {"text": "In the long term, we would like to communicate with computers as easily as we do with people.", "labels": [], "entities": []}, {"text": "Learning word meanings is an important step in this direction.", "labels": [], "entities": [{"text": "Learning word meanings", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.7196319103240967}]}, {"text": "Some other approaches to the lexical acquisition problem depend on knowledge of syntax to assist in lexical learning.", "labels": [], "entities": [{"text": "lexical acquisition problem", "start_pos": 29, "end_pos": 56, "type": "TASK", "confidence": 0.8155168493588766}]}, {"text": "Also, most of these have not demonstrated the ability to tie in to the rest of a language learning system.", "labels": [], "entities": []}, {"text": "Finally, unnatural data is sometimes needed.", "labels": [], "entities": []}, {"text": "We present a lexicM acquisition system that learns a mapping of words to their semantic representation, and which overcomes the above problems.", "labels": [], "entities": []}, {"text": "Our system, WOLFIE (WOrd Learning From Interpreted Examples), learns this mapping from training examples consisting of sentences paired with their semantic representation.", "labels": [], "entities": []}, {"text": "The representation used here is based on Conceptual Dependency (CD).", "labels": [], "entities": []}, {"text": "The results of our system can be used to *This research was supported by the National Science Foundation under grant IRI-9310819 assist a larger language acquisition system; in particular, we use the results as part of the input to CHILL.", "labels": [], "entities": []}, {"text": "CHILL learns to parse sentences into case-role representations by anMyzing a sample of sentence/case-role pairings.", "labels": [], "entities": [{"text": "CHILL", "start_pos": 0, "end_pos": 5, "type": "DATASET", "confidence": 0.8470030426979065}]}, {"text": "By extending the representation of each word to a CD representation, the problem faced by CHILL is made more difficult.", "labels": [], "entities": []}, {"text": "Our hypothesis is that the output from WOLFIE can ease the difficulty.", "labels": [], "entities": [{"text": "WOLFIE", "start_pos": 39, "end_pos": 45, "type": "DATASET", "confidence": 0.7737650871276855}]}, {"text": "In the long run, a system such as WOLFIE could be used to help learn to process natural language queries and translate them into a database query language.", "labels": [], "entities": []}, {"text": "Also, WOLFIE could possibly assist in translation from one natural language to another.", "labels": [], "entities": [{"text": "translation from one natural language", "start_pos": 38, "end_pos": 75, "type": "TASK", "confidence": 0.8109556913375855}]}], "datasetContent": [{"text": "Our hypothesis is that useful meaning representations can be learned by WOLFIE.", "labels": [], "entities": [{"text": "WOLFIE", "start_pos": 72, "end_pos": 78, "type": "DATASET", "confidence": 0.8602871894836426}]}, {"text": "One way to test this is by examining the results by hand.", "labels": [], "entities": []}, {"text": "Another way to test this is to use the results to assist a larger learning system.", "labels": [], "entities": []}, {"text": "The corpus used is based on that of.", "labels": [], "entities": []}, {"text": "That corpus is a set of 1475 sentence/case-structure pairs, produced from a set of 19 sentence templates.", "labels": [], "entities": []}, {"text": "We modified only the casestructure portion of these pairs.", "labels": [], "entities": []}, {"text": "There is still the basic case-structure representation, but instead of a single word for each filler, there is a semantic representation, as in the previous section.", "labels": [], "entities": []}, {"text": "The system is implemented in prolog.", "labels": [], "entities": []}, {"text": "We chose a random set of training examples, starting with 50 examples, and incrementing by 100 for each of three trials.", "labels": [], "entities": []}, {"text": "To measure the success of the system, the percentage of correct word meanings obtained was measured.", "labels": [], "entities": []}, {"text": "This climbed to 94% correct after 450 examples, then went down to around 83% thereafter, with training going up to 650 examples.", "labels": [], "entities": [{"text": "correct", "start_pos": 20, "end_pos": 27, "type": "METRIC", "confidence": 0.9990708827972412}]}, {"text": "In one case, in going from 350 to 450 training examples, the number of word-meaning pairs learned went down by ten while the accuracy went up by 31%.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 125, "end_pos": 133, "type": "METRIC", "confidence": 0.9994798302650452}]}, {"text": "This happened, in part, because the incorrect pair (broke,) was hypothesized early in the loop with 350 examples, causing many of the instruments to have an incomplete representation, such as (hatchet, ), instead of the correct (hatchet, ).", "labels": [], "entities": []}, {"text": "This error was not made in cases where a higher percent of the correct word meanings were learned.", "labels": [], "entities": []}, {"text": "It is an area for future research to discover why this error is being made in some cases but not in others.", "labels": [], "entities": []}, {"text": "We have only preliminary results on the task of using WOLFIE to assist CHILL.", "labels": [], "entities": [{"text": "CHILL", "start_pos": 71, "end_pos": 76, "type": "DATASET", "confidence": 0.8211241960525513}]}, {"text": "Those results indicate that CHILL, without WOLFIE's help cannot learn to parse sentences into the deeper semantic representation, but that with 450 examples, assisted by WOLFIE, it can learn parse up to 55% correct on a testing set.", "labels": [], "entities": []}], "tableCaptions": []}