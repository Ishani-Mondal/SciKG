{"title": [{"text": "Statistical Sense Disambiguation with Relatively Small Corpora Using Dictionary Definitions", "labels": [], "entities": [{"text": "Statistical Sense Disambiguation", "start_pos": 0, "end_pos": 32, "type": "TASK", "confidence": 0.8855986396471659}]}], "abstractContent": [{"text": "Corpus-based sense disambiguation methods, like most other statistical NLP approaches, suffer from the problem of data sparseness.", "labels": [], "entities": [{"text": "Corpus-based sense disambiguation", "start_pos": 0, "end_pos": 33, "type": "TASK", "confidence": 0.5552776555220286}]}, {"text": "In this paper, we describe an approach which overcomes this problem using dictionary definitions.", "labels": [], "entities": []}, {"text": "Using the definition-based conceptual co-occurrence data collected from the relatively small Brown corpus, our sense disambiguation system achieves an average accuracy comparable to human performance given the same contextual information.", "labels": [], "entities": [{"text": "Brown corpus", "start_pos": 93, "end_pos": 105, "type": "DATASET", "confidence": 0.8581786453723907}, {"text": "sense disambiguation", "start_pos": 111, "end_pos": 131, "type": "TASK", "confidence": 0.668045237660408}, {"text": "accuracy", "start_pos": 159, "end_pos": 167, "type": "METRIC", "confidence": 0.998458981513977}]}], "introductionContent": [{"text": "Previous corpus-based sense disambiguation methods require substantial amounts of sense-tagged training data ( or aligned bilingual corpora).", "labels": [], "entities": [{"text": "sense disambiguation", "start_pos": 22, "end_pos": 42, "type": "TASK", "confidence": 0.7048971056938171}]}, {"text": "introduces a thesaurus-based approach to statistical sense disambiguation which works on monolingual corpora without the need for sense-tagged training data.", "labels": [], "entities": [{"text": "statistical sense disambiguation", "start_pos": 41, "end_pos": 73, "type": "TASK", "confidence": 0.7212933897972107}]}, {"text": "By collecting statistical data of word occurrences in the context of different thesaurus categories from a relatively large corpus (10 million words), the system can identify salient words for each category.", "labels": [], "entities": []}, {"text": "Using these salient words, the system is able to disambiguate polysemous words with respect to thesaurus categories.", "labels": [], "entities": []}, {"text": "Statistical approaches like these generally suffer from the problem of data sparseness.", "labels": [], "entities": []}, {"text": "To estimate the salience of a word with reasonable accuracy, the system needs the word to have a significant number of occurrences in the corpus.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 51, "end_pos": 59, "type": "METRIC", "confidence": 0.9956910014152527}]}, {"text": "Having large corpora will help but some words are simply too infrequent to make a significant statistical contribution even in a rather large corpus.", "labels": [], "entities": []}, {"text": "Moreover, huge corpora are not generally available in all domains and storage and processing of very huge corpora can be problematic in some cases.Z In this paper, we describe an approach which attacks the problem of. data sparseness in automatic statistical sense disambiguation.", "labels": [], "entities": []}, {"text": "Using definitions from LDOCE (Longman Dictionary of Contemporary English;, cooccurrence data of concepts, rather than words, is collected from a relatively small corpus, the one million word Brown corpus.", "labels": [], "entities": [{"text": "Longman Dictionary of Contemporary English", "start_pos": 30, "end_pos": 72, "type": "DATASET", "confidence": 0.9434659957885743}, {"text": "Brown corpus", "start_pos": 191, "end_pos": 203, "type": "DATASET", "confidence": 0.8148880898952484}]}, {"text": "Since all the definitions in LDOCE are written using words from the 2000 word controlled vocabulary (or in our terminology, defining concepts), even our small corpus is found to be capable of providing statistically significant cooccurrence data at the level of the defining concepts.", "labels": [], "entities": []}, {"text": "This data is then used in a sense disambiguation system.", "labels": [], "entities": []}, {"text": "The system is tested on twelve words previously discussed in the sense disambiguation literature.", "labels": [], "entities": [{"text": "sense disambiguation", "start_pos": 65, "end_pos": 85, "type": "TASK", "confidence": 0.792114794254303}]}, {"text": "The results are found to be comparable to human performance given the same contextual information.", "labels": [], "entities": []}], "datasetContent": [{"text": "Our system is tested on the twelve words discussed in and previous publications on sense disambiguation.", "labels": [], "entities": [{"text": "sense disambiguation", "start_pos": 83, "end_pos": 103, "type": "TASK", "confidence": 0.7558815181255341}]}, {"text": "Our system achieves an average accuracy of 77% on a mean 3-way sense distinction over the twelve words.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 31, "end_pos": 39, "type": "METRIC", "confidence": 0.9993614554405212}]}, {"text": "Numerically, the result is not as good as the 92% as reported in.", "labels": [], "entities": []}, {"text": "However, direct comparison between the numerical results can be misleading since the experiments are carried out on two very different corpora both in size and genre.", "labels": [], "entities": []}, {"text": "Firstly, Yarowsky's system is trained with the 10 million word Grolier's Encyclopedia, which is a magnitude larger than the Brown corpus used by our system.", "labels": [], "entities": [{"text": "Brown corpus", "start_pos": 124, "end_pos": 136, "type": "DATASET", "confidence": 0.7259966135025024}]}, {"text": "Secondly, and more importantly, the two corpora, which are also the test corpora, are very different in genre.", "labels": [], "entities": []}, {"text": "Semantic coherence of text, on which both systems rely, is generally stronger in technical writing than inmost other kinds of text.", "labels": [], "entities": []}, {"text": "Statistical disambiguation systems which rely on semantic coherence will generally perform better on technical writing, which encyclopedia entry can be regarded as one kind of, than on most other kinds of text.", "labels": [], "entities": []}, {"text": "On the other hand, the Brown corpus is a collection of text with all kinds of genre.", "labels": [], "entities": [{"text": "Brown corpus", "start_pos": 23, "end_pos": 35, "type": "DATASET", "confidence": 0.9801287651062012}]}, {"text": "People make use of syntactic, semantic and pragmatic knowledge in sense disambiguation.", "labels": [], "entities": [{"text": "sense disambiguation", "start_pos": 66, "end_pos": 86, "type": "TASK", "confidence": 0.711037203669548}]}, {"text": "It is not very realistic to expect any system which only possesses semantic coherence knowledge (including ours as well as Yarowsky's) to achieve a very high level of accuracy for all words in general text.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 167, "end_pos": 175, "type": "METRIC", "confidence": 0.9951613545417786}]}, {"text": "To provide a better evaluation of our approach, we have conducted an informal experiment aiming at establishing a more reasonable upper bound of the performance of such systems.", "labels": [], "entities": []}, {"text": "In the experiment, a human subject is asked to perform the same disambiguation task as our system, given the same contextual information, 7 Since our system only uses semantic coherence information and has no deeper understanding of the meaning of the text, the human subject is asked to disambiguate the target word, given a list of all the content words in the context (sentence) of the target word in random order.", "labels": [], "entities": []}, {"text": "The words are put in random order because the system does not make use of syntactic information of the sentence either.", "labels": [], "entities": []}, {"text": "The human subject is also allowed access to a copy of LDOCE which the system also uses.", "labels": [], "entities": []}, {"text": "The results are listed in.", "labels": [], "entities": []}, {"text": "The actual upper bound of the performance of statistical methods using semantic coherence information only should be slightly better than the performance of human since the human is disadvantaged by a number of factors, including but not limited to: 1.", "labels": [], "entities": []}, {"text": "it is unnatural for human to disambiguate in the described manner; 2.", "labels": [], "entities": []}, {"text": "the semantic coherence knowledge used by the human is not complete or specific to the current corpusS; 3.", "labels": [], "entities": []}, {"text": "However, the results provide a rough approximation of the upper bound of performance of such systems, The human subject achieves an average accuracy of 71% over the twelve words, which is 6% lower than our system.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 140, "end_pos": 148, "type": "METRIC", "confidence": 0.995542585849762}]}, {"text": "More interestingly, the results of the human subject are found to exhibit a similar pattern to the results of our system -the human subject performs better on words and senses for which our system achieve higher accuracy and less well on words and senses for which our system has a lower accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 212, "end_pos": 220, "type": "METRIC", "confidence": 0.9911536574363708}, {"text": "accuracy", "start_pos": 288, "end_pos": 296, "type": "METRIC", "confidence": 0.9890490770339966}]}], "tableCaptions": [{"text": " Table 1. Results of Experiments", "labels": [], "entities": []}]}