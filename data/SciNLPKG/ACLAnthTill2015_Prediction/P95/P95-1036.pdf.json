{"title": [{"text": "Some Novel Applications of Explanation-Based Learning to Parsing Lexicalized Tree-Adjoining Grammars\"", "labels": [], "entities": []}], "abstractContent": [{"text": "In this paper we present some novel applications of Explanation-Based Learning (EBL) technique to parsing Lexicalized Tree-Adjoining grammars.", "labels": [], "entities": [{"text": "parsing Lexicalized Tree-Adjoining grammars", "start_pos": 98, "end_pos": 141, "type": "TASK", "confidence": 0.8762056976556778}]}, {"text": "The novel aspects are (a) immediate generalization of parses in the training set, (b) generalization over recursive structures and (c) representation of generalized parses as Finite State Transducers.", "labels": [], "entities": []}, {"text": "A highly impoverished parser called a \"stapler\" has also been introduced.", "labels": [], "entities": []}, {"text": "We present experimental results using EBL for different corpora and archi-tectures to show the effectiveness of our approach .", "labels": [], "entities": [{"text": "EBL", "start_pos": 38, "end_pos": 41, "type": "METRIC", "confidence": 0.8367696404457092}]}], "introductionContent": [{"text": "In this paper we present some novel applications of the so-called Explanation-Based Learning technique (EBL) to parsing Lexicalized Tree-Adjoining grammars (LTAG).", "labels": [], "entities": [{"text": "parsing Lexicalized Tree-Adjoining grammars (LTAG)", "start_pos": 112, "end_pos": 162, "type": "TASK", "confidence": 0.8422842621803284}]}, {"text": "EBL techniques were originally introduced in the AI literature by.", "labels": [], "entities": []}, {"text": "The main idea of EBL is to keep track of problems solved in the past and to replay those solutions to solve new but somewhat similar problems in the future.", "labels": [], "entities": []}, {"text": "Although put in these general terms the approach sounds attractive, it is by no means clear that EBL will actually improve the performance of the system using it, an aspect which is of great interest to us here. was the first to investigate this technique in the context of natural language parsing.", "labels": [], "entities": [{"text": "natural language parsing", "start_pos": 274, "end_pos": 298, "type": "TASK", "confidence": 0.6309085488319397}]}, {"text": "Seen as an EBL problem, the parse of a single sentence represents an explanation of why the sentence is apart of the language defined by the grammar.", "labels": [], "entities": []}, {"text": "Parsing new sentences amounts to finding analogous explanations from the training sentences.", "labels": [], "entities": []}, {"text": "As a special case of EBL, Samuelsson and *This work was partiaJly supported by ARC) grant DAAL03-89-0031, ARPA grant N00014-90-J-1863, NSF STC grsmt DIR-8920230, and Ben Franklin Partnership Program (PA) gremt 93S.3078C-6 Rayner (1991) specialize a grammar for the ATIS domain by storing chunks of the parse trees present in a treebank of parsed examples.", "labels": [], "entities": [{"text": "ARPA grant N00014-90-J-1863", "start_pos": 106, "end_pos": 133, "type": "DATASET", "confidence": 0.7670757373174032}, {"text": "Ben Franklin Partnership Program (PA) gremt 93S.3078C-6 Rayner (1991)", "start_pos": 166, "end_pos": 235, "type": "DATASET", "confidence": 0.7634024826379923}]}, {"text": "The idea is to reparse the training examples by letting the parse tree drive the rule expansion process and halting the expansion of a specialized rule if the current node meets a 'tree-cutting' criteria.", "labels": [], "entities": []}, {"text": "However, the problem of specifying an optimal 'tree-cutting' criteria was not addressed in this work.", "labels": [], "entities": []}, {"text": "used the information-theoretic measure of entropy to derive the appropriate sized tree chunks automatically.", "labels": [], "entities": []}, {"text": "also attempts to specialize a grammar given a training corpus of parsed exampies by generalizing the parse for each sentence and storing the generalized phrasal derivations under a suitable index.", "labels": [], "entities": []}, {"text": "Although our work can be considered to be in this general direction, it is distinct in that it exploits some of the key properties of LTAG to achieve an immediate generalization of parses in the training set of sentences, (b) achieve an additional level of generalization of the parses in the training set, thereby dealing with test sentences which are not necessarily of the same length as the training sentences and (c) represent the set of generalized parses as a finite state transducer (FST), which is the first such use of FST in the context of EBL, to the best of our knowledge.", "labels": [], "entities": []}, {"text": "Later in the paper, we will make some additional comments on the relationship between our approach and some of the earlier approaches.", "labels": [], "entities": []}, {"text": "In addition to these special aspects of our work, we will present experimental results evaluating the effectiveness of our approach on more than one kind of corpus.", "labels": [], "entities": []}, {"text": "We also introduce a device called a \"stapler\", a considerably impoverished parser, whose only job is to do term unification and compute alternate attachments for modifiers.", "labels": [], "entities": [{"text": "term unification", "start_pos": 107, "end_pos": 123, "type": "TASK", "confidence": 0.6880883872509003}]}, {"text": "We achieve substantial speed-up by the use of \"stapler\" in combination with the output of the FST.", "labels": [], "entities": [{"text": "speed-up", "start_pos": 23, "end_pos": 31, "type": "METRIC", "confidence": 0.9710319638252258}, {"text": "FST", "start_pos": 94, "end_pos": 97, "type": "DATASET", "confidence": 0.9162667393684387}]}, {"text": "The paper is organized as follows.", "labels": [], "entities": []}, {"text": "In Section 2 we provide a brief introduction to LTAG with the help of an example.", "labels": [], "entities": [{"text": "LTAG", "start_pos": 48, "end_pos": 52, "type": "DATASET", "confidence": 0.5654122233390808}]}, {"text": "In Section 3 we discuss our approach to using EBL and the advantages provided by LTAG.", "labels": [], "entities": [{"text": "LTAG", "start_pos": 81, "end_pos": 85, "type": "DATASET", "confidence": 0.957730233669281}]}, {"text": "The FST representation used for EBL is illustrated in Section 4.", "labels": [], "entities": [{"text": "FST", "start_pos": 4, "end_pos": 7, "type": "METRIC", "confidence": 0.4357771873474121}, {"text": "EBL", "start_pos": 32, "end_pos": 35, "type": "DATASET", "confidence": 0.5480652451515198}]}, {"text": "In Section 5 we present the \"stapler\" in some detail.", "labels": [], "entities": []}, {"text": "The results of some of the experiments based on our approach are presented in Section 6.", "labels": [], "entities": []}, {"text": "In Section 7 we discuss the relevance of our approach to other lexicalized grammars.", "labels": [], "entities": []}, {"text": "In Section 8 we conclude with some directions for future work.", "labels": [], "entities": []}], "datasetContent": [{"text": "We now present experimental results from two different sets of experiments performed to show the effectiveness of our approach.", "labels": [], "entities": []}, {"text": "The first set of experiments, (Experiments l(a) through 1(c)), are intended to measure the coverage of the FST representation of the parses of sentences from a range of corpora (ATIS, IBM-Manual and Alvey).", "labels": [], "entities": [{"text": "FST representation of the parses of sentences", "start_pos": 107, "end_pos": 152, "type": "TASK", "confidence": 0.8749989356313433}, {"text": "ATIS", "start_pos": 178, "end_pos": 182, "type": "DATASET", "confidence": 0.9529301524162292}, {"text": "IBM-Manual", "start_pos": 184, "end_pos": 194, "type": "DATASET", "confidence": 0.8864424824714661}]}, {"text": "The results of these experiments provide a measure of repetitiveness of patterns as described in this paper, at the sentence level, in each of these corpora.", "labels": [], "entities": []}, {"text": "Experiment l(a): The details of the experiment with the ATIS corpus are as follows.", "labels": [], "entities": [{"text": "ATIS corpus", "start_pos": 56, "end_pos": 67, "type": "DATASET", "confidence": 0.9622788727283478}]}, {"text": "A total of 465 sentences, average length of 10 words per sentence, which had been completely parsed by the XTAG system were randomly divided into two sets, a training set of 365 sentences and a test set of 100 sentences, using a random number generator.", "labels": [], "entities": []}, {"text": "For each of the training sentences, the parses were ranked using heuristics 4 (  and the top three derivations were generMized and stored as an FST.", "labels": [], "entities": [{"text": "FST", "start_pos": 144, "end_pos": 147, "type": "METRIC", "confidence": 0.48834171891212463}]}, {"text": "The FST was tested for retrieval of a generalized parse for each of the test sentences that were pretagged with the correct POS sequence (In Experiment 2, we make use of the POS tagger to do the tagging).", "labels": [], "entities": [{"text": "FST", "start_pos": 4, "end_pos": 7, "type": "DATASET", "confidence": 0.5593619346618652}]}, {"text": "When a match is found, the output of the EBL component is a generalized parse that associates with each word the elementary tree that it anchors and the elementary tree into which it adjoins or substitutes into -an almost parse, s 4We axe not using stochastic LTAGs.", "labels": [], "entities": []}, {"text": "For work on Stochastic LTAGs see.", "labels": [], "entities": []}, {"text": "SSee ( for the role of almost parse in supertag disaanbiguation.", "labels": [], "entities": [{"text": "SSee", "start_pos": 0, "end_pos": 4, "type": "METRIC", "confidence": 0.432923287153244}]}, {"text": "Experiment l(b) and 1(c): Similar experiments were conducted using the IBM-manual corpus and a set of noun definitions from the LDOCE dictionary that were used as the Alvey test set.", "labels": [], "entities": [{"text": "IBM-manual corpus", "start_pos": 71, "end_pos": 88, "type": "DATASET", "confidence": 0.9131501615047455}, {"text": "LDOCE dictionary", "start_pos": 128, "end_pos": 144, "type": "DATASET", "confidence": 0.9148930311203003}, {"text": "Alvey test set", "start_pos": 167, "end_pos": 181, "type": "DATASET", "confidence": 0.7517669399579366}]}], "tableCaptions": [{"text": " Table 2: Coverage and Retrieval times for various corpora", "labels": [], "entities": [{"text": "Retrieval", "start_pos": 23, "end_pos": 32, "type": "METRIC", "confidence": 0.8457183837890625}]}, {"text": " Table 3: Performance comparison of XTAG with  and without EBL component", "labels": [], "entities": [{"text": "XTAG", "start_pos": 36, "end_pos": 40, "type": "DATASET", "confidence": 0.7999043464660645}]}]}