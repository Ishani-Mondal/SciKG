{"title": [{"text": "LICENSING AND TREE ADJOINING GRAMMAR IN GOVERNMENT BINDING PARSING", "labels": [], "entities": [{"text": "TREE ADJOINING", "start_pos": 14, "end_pos": 28, "type": "METRIC", "confidence": 0.7656136453151703}, {"text": "GRAMMAR", "start_pos": 29, "end_pos": 36, "type": "METRIC", "confidence": 0.727927565574646}, {"text": "GOVERNMENT BINDING PARSING", "start_pos": 40, "end_pos": 66, "type": "METRIC", "confidence": 0.6414878765741984}]}], "abstractContent": [{"text": "This paper presents an implemented, psychologically plausible parsing model for Government Binding theory grammars.", "labels": [], "entities": [{"text": "Government Binding theory grammars", "start_pos": 80, "end_pos": 114, "type": "TASK", "confidence": 0.8655195832252502}]}, {"text": "I make use of two main ideas: (1) a generalization of the licensing relations of [Abney, 1986] allows for the direct encoding of certain principles of grammar (e.g. Theta Criterion, Case Filter) which drive structure building ; (2) the working space of the parser is constrained to the domain determined by a Tree Adjoining Grammar elementary tree.", "labels": [], "entities": []}, {"text": "All dependencies and constraints are lo-caiized within this bounded structure.", "labels": [], "entities": []}, {"text": "The resultant parser operates in linear time and allows for incremental semantic interpretation and determination of grammaticaiity.", "labels": [], "entities": [{"text": "semantic interpretation", "start_pos": 72, "end_pos": 95, "type": "TASK", "confidence": 0.7535196542739868}]}], "introductionContent": [{"text": "This paper aims to provide a psychologically plausible mechanism for putting the knowledge which a speaker has of the syntax of a language, the competence grammar, to use.", "labels": [], "entities": []}, {"text": "The representation of knowledge of language I assume is that specified by Government Binding (GB) Theory introduced in.", "labels": [], "entities": [{"text": "Government Binding (GB)", "start_pos": 74, "end_pos": 97, "type": "TASK", "confidence": 0.7517126321792602}]}, {"text": "GB, as a competence theory, emphatically does not specify the nature of the language processing mechanism.", "labels": [], "entities": [{"text": "GB", "start_pos": 0, "end_pos": 2, "type": "DATASET", "confidence": 0.5636970400810242}]}, {"text": "In fact, \"proofs\" that transformational grammar is inadequate as a linguistic theory due to various performance measures are fundamentally flawed since they suppose a particular connection between the grammar and parser.", "labels": [], "entities": []}, {"text": "Nonetheless, it seems desirable to maintain a fairly direct connection between the linguistic competence and *I would like to thank the following for their valuable discussion and suggestions: Naoki Fukui, Jarnie Henderson, Aravind Joshi, Tony Kroch, Mitch Marcus, Michael Niv, Yves Schabes, Mark Steedman, Enric Vallduv{.", "labels": [], "entities": []}, {"text": "This work was pa~ially supported by ARO Grants DAAL03-89-C0031 PRI and DAAG29-84-K-0061 and DARPA grant N00014-85-K-0018.", "labels": [], "entities": [{"text": "ARO Grants DAAL03-89-C0031 PRI", "start_pos": 36, "end_pos": 66, "type": "DATASET", "confidence": 0.5772575736045837}, {"text": "DAAG29-84-K-0061", "start_pos": 71, "end_pos": 87, "type": "DATASET", "confidence": 0.9346547722816467}, {"text": "DARPA grant N00014-85-K-0018", "start_pos": 92, "end_pos": 120, "type": "DATASET", "confidence": 0.8095265030860901}]}, {"text": "The author is supported by a Unisys doctoral fellowship.", "labels": [], "entities": []}, {"text": "Otherwise, claims of the psychological reality of this particular conception of competence become essentially vacuous since they cannot be falsified but for the data on which they are founded, i.e. grammaticality judgments.", "labels": [], "entities": []}, {"text": "Thus, in building a model of language processing, I would like to posit as direct a link as is possible between linguistic competence and the operations of the parser while still maintaining certain desirable computational properties.", "labels": [], "entities": [{"text": "language processing", "start_pos": 29, "end_pos": 48, "type": "TASK", "confidence": 0.720925509929657}]}, {"text": "What are the computational properties necessary for psychological plausibility?", "labels": [], "entities": []}, {"text": "Since human syntactic processing is an effortless process, we should expect that it take place efficiently, perhaps in linear time since sentences do not become more difficult to process simply as a function of their length.", "labels": [], "entities": []}, {"text": "Determinism, as proposed by Marcus, seems desirable as well.", "labels": [], "entities": []}, {"text": "In addition, the mechanism should operate in an incremental fashion.", "labels": [], "entities": []}, {"text": "Incrementality is evidenced in the human language processor in two ways.", "labels": [], "entities": []}, {"text": "As we hear a sentence, we buildup semantic representations without waiting until the sentence is complete.", "labels": [], "entities": []}, {"text": "Thus, the semantic processor should have access to syntactic representations prior to an utterance's completion.", "labels": [], "entities": []}, {"text": "Additionally, we are able to perceive ungrammaticality in sentences almost immediately after the ill fonnedness occurs.", "labels": [], "entities": []}, {"text": "Thus, our processing mechanism should mimic this early detection of ungrammatical input.", "labels": [], "entities": []}, {"text": "Unfortunately, a parser with the most transparent relationship to the grammar, a \"parsing as theorem proving\" approach as proposed by and, does not farewell with respect to our computational desiderata.", "labels": [], "entities": []}, {"text": "It suffers from the legacy of the computational properties of first order theorem proving, most notably undecidability, and is thus inadequate for our purposes.", "labels": [], "entities": [{"text": "first order theorem proving", "start_pos": 62, "end_pos": 89, "type": "TASK", "confidence": 0.6551135256886482}]}, {"text": "The question, then, is how much we must repeat from this direct instantiatiou so that we can maintain the requisite properties.", "labels": [], "entities": []}, {"text": "In this paper, I attempt to provide iii an answer.", "labels": [], "entities": []}, {"text": "I propose a parsing model which represents the principles of the grammar in a fairly direct manner, yet preserves efficiency and incrementality.", "labels": [], "entities": []}, {"text": "The model depends upon two key ideas.", "labels": [], "entities": []}, {"text": "First, I utilize the insight of in the use of licensing relations as the foundation for GB parsing.", "labels": [], "entities": [{"text": "GB parsing", "start_pos": 88, "end_pos": 98, "type": "TASK", "confidence": 0.8955178558826447}]}, {"text": "By generalizing Abney's formulation of licensing, I can directly encode and enforce a particular class of the principles of GB theory and in so doing efficiently build phrase structure.", "labels": [], "entities": []}, {"text": "The principles expressible through licensing are not all of those posited by GB.", "labels": [], "entities": [{"text": "GB", "start_pos": 77, "end_pos": 79, "type": "DATASET", "confidence": 0.9504708647727966}]}, {"text": "Thus, the others must be enforced using a different mechanism.", "labels": [], "entities": []}, {"text": "Unfortunately, the unbounded size of the tree created with licensing makes any such mechanism computationally abhorrent.", "labels": [], "entities": []}, {"text": "In order to remedy this, I make use of the Tree Adjoining Grammar (TAG) framework to limit the working space of the parser.", "labels": [], "entities": []}, {"text": "As the parser proceeds, its working slructure is bounded in size.", "labels": [], "entities": []}, {"text": "If this bound is exceeded, we reduce this structure by one of the operations provided by the TAG formalism, either substitution or adjunction.", "labels": [], "entities": [{"text": "TAG formalism", "start_pos": 93, "end_pos": 106, "type": "TASK", "confidence": 0.6028180718421936}]}, {"text": "This results in two structures, each of which form independent elementary trees.", "labels": [], "entities": []}, {"text": "Interestingly, the domain of locality imposed by a TAG elementary tree appears to be sufficient for the expression of the remaining grammatical principles.", "labels": [], "entities": []}, {"text": "Thus, we can check for the satisfaction of the remaining grammatical principles in just the excised piece of structure and then send it off for semantic interpretation.", "labels": [], "entities": [{"text": "semantic interpretation", "start_pos": 144, "end_pos": 167, "type": "TASK", "confidence": 0.7696436643600464}]}, {"text": "Since this domain of constraint checking is bounded in size, this process is done efficiently.", "labels": [], "entities": [{"text": "constraint checking", "start_pos": 21, "end_pos": 40, "type": "TASK", "confidence": 0.7187443226575851}]}, {"text": "This mechanism also works in an incremental fashion.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": []}