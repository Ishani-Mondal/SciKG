{"title": [{"text": "THE COMPUTATIONAL COMPLEXITY OF AVOIDING CONVERSATIONAL IMPLICATURES", "labels": [], "entities": [{"text": "AVOIDING CONVERSATIONAL IMPLICATURES", "start_pos": 32, "end_pos": 68, "type": "METRIC", "confidence": 0.8090655406316122}]}], "abstractContent": [{"text": "Referring expressions and other object descriptions should be maximal under the Local Brevity, No Unnecessary Components, and Lexical Preference preference rules; otherwise, they may lead hearers to infer unwanted conversational implicatures.", "labels": [], "entities": []}, {"text": "These preference rules can be incorporated into a polynomial time generation algorithm, while some alternative formalizations of conversational impficature make the generation task NP-Hard.", "labels": [], "entities": []}], "introductionContent": [{"text": "Natural language generation (NLG) systems should produce referring expressions and other object descriptions that are free of false implicatures, i.e., that do not cause the user of the system to infer incorrect and unwanted conversational implicatures).", "labels": [], "entities": [{"text": "Natural language generation (NLG)", "start_pos": 0, "end_pos": 33, "type": "TASK", "confidence": 0.749578391512235}]}, {"text": "The following utterances illustrate referring expressions that are and are not free of false implicatures: la) \"Sit by the table\" lb) \"Sit by the brown wooden table\" Ina context where only one table was visible, and this table was brown and made of wood, utterances (la) and (lb) would both fulfill the referring goal: a hearer who heard either utterance would have no trouble picking out the object being referred to.", "labels": [], "entities": []}, {"text": "However, a hearer who heard utterance (lb) would probably assume that it was somehow important that the table was brown and made of wood, i.e., that the speaker was trying to do more than just identify the table.", "labels": [], "entities": []}, {"text": "If the speaker did not have this intention, and only wished to tell the hearer whereto sit, then this would bean incorrect conversational implicature, and could lead to problems later in the discourse.", "labels": [], "entities": []}, {"text": "Accordingly, a speaker who only wished to identify the table should use utterance (la) in this situation, f Currently at the Depamnem of Artificial Intelligence, University of Edinburgh, 80 South Bridge, Edinburgh EHI 1HN, and avoid utterance (lb).", "labels": [], "entities": [{"text": "Depamnem of Artificial Intelligence, University of Edinburgh, 80 South Bridge", "start_pos": 125, "end_pos": 202, "type": "DATASET", "confidence": 0.8216776599486669}, {"text": "Edinburgh EHI 1HN", "start_pos": 204, "end_pos": 221, "type": "DATASET", "confidence": 0.8141376773516337}]}, {"text": "Incorrect conversational implicatures may also arise from inappropriate attributive (informational) descriptions.", "labels": [], "entities": []}, {"text": "1 This is illustrated by the following utterances, which might be used by a salesman who wished to inform a customer of the color, material, and sleeve-length of a shirt: 2a) \"I have a red T-shirt\" 2b) \"I have a lightweight red cotton shirt with short sleeves\" Utterances (2a) and (2b) both successfully inform the hearer of the relevant properties of the shirt, assuming the hearer has some domain knowledge about Tshirts.", "labels": [], "entities": []}, {"text": "However, if the hearer has this domain knowledge, the use of utterance (2b) might incorrectly implicate that the object being described was not a T-shirt --because if it was, the hearer would reason, then the speaker would have used utterance (Za).", "labels": [], "entities": []}, {"text": "Therefore, in the above situations the speaker, whether a human or a computer NLG system, should use utterances (la) and (2a), and should avoid utterances (lb) and (2b); utterances (la) and (2a) are free of false implicatures, while the utterances (lb) and (2b) are not.", "labels": [], "entities": []}, {"text": "This paper proposes a computational model for determining when an object description is free of false implicatures.", "labels": [], "entities": []}, {"text": "Briefly, a description is considered free of false implicatures if it is maximal under the Local Brevity, No Unnecessary Components, and Lexical Preference preference rules.", "labels": [], "entities": []}, {"text": "These preference rules were chosen on complexitytheoretic as well as linguistic criteria; descriptions that are maximal under these preference rules can be found in polynomial time, while some alternative formalizations of the free-of-false-implicatures constraint make the generation task NP-Hard.", "labels": [], "entities": []}, {"text": "This paper only addresses the problem of generating free-of-false-implicatures referring expressions, such as utterance (la).", "labels": [], "entities": []}, {"text": "Reiter (1990a,b) uses the same preference rules to formalize the task of generating free-of-false-implicatures attributive descriptions, such as utterance (2a).", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": []}