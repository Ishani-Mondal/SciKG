{"title": [{"text": "Frequency Estimates for Statistical Word Similarity Measures", "labels": [], "entities": [{"text": "Frequency Estimates", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.8066835105419159}, {"text": "Statistical Word Similarity Measures", "start_pos": 24, "end_pos": 60, "type": "TASK", "confidence": 0.7809843495488167}]}], "abstractContent": [{"text": "Statistical measures of word similarity have application in many areas of natural language processing , such as language modeling and information retrieval.", "labels": [], "entities": [{"text": "natural language processing", "start_pos": 74, "end_pos": 101, "type": "TASK", "confidence": 0.6968022386233012}, {"text": "language modeling", "start_pos": 112, "end_pos": 129, "type": "TASK", "confidence": 0.725355789065361}, {"text": "information retrieval", "start_pos": 134, "end_pos": 155, "type": "TASK", "confidence": 0.8160247206687927}]}, {"text": "We report a comparative study of two methods for estimating word co-occurrence frequencies required byword similarity measures.", "labels": [], "entities": []}, {"text": "Our frequency estimates are generated from a terabyte-sized corpus of Web data, and we study the impact of corpus size on the effectiveness of the measures.", "labels": [], "entities": []}, {"text": "We base the evaluation on one TOEFL question set and two practice questions sets, each consisting of a number of multiple choice questions seeking the best synonym fora given target word.", "labels": [], "entities": [{"text": "TOEFL question set", "start_pos": 30, "end_pos": 48, "type": "DATASET", "confidence": 0.7871216932932535}]}, {"text": "For two question sets, a context for the target word is provided, and we examine a number of word similarity measures that exploit this context.", "labels": [], "entities": []}, {"text": "Our best combination of similarity measure and frequency estimation method answers 6-8% more questions than the best results previously reported for the same question sets.", "labels": [], "entities": [{"text": "similarity measure", "start_pos": 24, "end_pos": 42, "type": "METRIC", "confidence": 0.9220153391361237}]}], "introductionContent": [{"text": "Many different statistical tests have been proposed to measure the strength of word similarity or word association in natural language texts).", "labels": [], "entities": []}, {"text": "These tests attempt to measure dependence between words by using statistics taken from a large corpus.", "labels": [], "entities": []}, {"text": "In this context, a key assumption is that similarity between words is a consequence of word co-occurrence, or that the closeness of the words in text is indicative of some kind of relationship between them, such as synonymy or antonymy.", "labels": [], "entities": []}, {"text": "Although word sequences in natural language are unlikely to be independent, these statistical tests provide quantitative information that can be used to compare pairs of co-occurring words.", "labels": [], "entities": []}, {"text": "Also, despite the fact that word co-occurrence is a simple idea, there area variety of ways to estimate word co-occurrence frequencies from text.", "labels": [], "entities": []}, {"text": "Two words can appear close to each other in the same document, passage, paragraph, sentence or fixed-size window.", "labels": [], "entities": []}, {"text": "The boundaries for determining cooccurrence will affect the estimates and as a consequence the word similarity measures.", "labels": [], "entities": []}, {"text": "Statistical word similarity measures play an important role in information retrieval and in many other natural language applications, such as the automatic creation of thesauri and word sense disambiguation.", "labels": [], "entities": [{"text": "information retrieval", "start_pos": 63, "end_pos": 84, "type": "TASK", "confidence": 0.7891996502876282}, {"text": "word sense disambiguation", "start_pos": 181, "end_pos": 206, "type": "TASK", "confidence": 0.684399942557017}]}, {"text": "use word similarity to create groups of related words, in order to discover word senses directly from text.", "labels": [], "entities": []}, {"text": "Recently, provide an analysis on different measures of independence in the context of association rules.", "labels": [], "entities": []}, {"text": "Word similarity is also used in language modeling applications.", "labels": [], "entities": [{"text": "Word similarity", "start_pos": 0, "end_pos": 15, "type": "TASK", "confidence": 0.6476934254169464}, {"text": "language modeling", "start_pos": 32, "end_pos": 49, "type": "TASK", "confidence": 0.730173259973526}]}, {"text": "uses word similarity as a constraint in a maximum entropy model which reduces the perplexity on a test set by 23%.", "labels": [], "entities": []}, {"text": "use a word similarity measure for language modeling in an interpolated model, grouping similar words into classes.", "labels": [], "entities": []}, {"text": "use word similarity to assign probabilities to unseen bigrams by using similar bigrams, which reduces perplexity up to 20% in held out data.", "labels": [], "entities": []}, {"text": "In information retrieval, word similarity can be used to identify terms for pseudo-relevance feedback).", "labels": [], "entities": [{"text": "information retrieval", "start_pos": 3, "end_pos": 24, "type": "TASK", "confidence": 0.8069100975990295}]}, {"text": "expand queries under a pseudo-relevance feedback model by using similar words from documents retrieved and improve effectiveness by more than 20% on an 11-point average precision.", "labels": [], "entities": []}, {"text": "Landauer and Dumais (1997) applied word similarity measures to answer TOEFL (Test Of English as a Foreign Language) synonym questions using Latent Semantic Analysis.", "labels": [], "entities": [{"text": "answer TOEFL (Test Of English as a Foreign Language) synonym", "start_pos": 63, "end_pos": 123, "type": "TASK", "confidence": 0.6223902578155199}]}, {"text": "performed an evaluation of a specific word similarity measure using the same TOEFL questions and compared the results with those obtained", "labels": [], "entities": [{"text": "TOEFL questions", "start_pos": 77, "end_pos": 92, "type": "DATASET", "confidence": 0.7535679042339325}]}], "datasetContent": [{"text": "We evaluate the methods and frequency estimates using 3 test sets.", "labels": [], "entities": []}, {"text": "The first test set is a set of TOEFL questions first used by and also by is given in context (within a sentence).", "labels": [], "entities": []}, {"text": "TS1 has 50 questions and was also used by.", "labels": [], "entities": [{"text": "TS1", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.9213237166404724}]}, {"text": "TS2 has 60 questions extracted from a TOEFL practice guide.", "labels": [], "entities": [{"text": "TS2", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.8480837941169739}, {"text": "TOEFL practice guide", "start_pos": 38, "end_pos": 58, "type": "DATASET", "confidence": 0.8223485151926676}]}, {"text": "For all test sets the answer to each question is known and unique.", "labels": [], "entities": []}, {"text": "For comparison purposes, we also use TS1 and TS2 with no context.", "labels": [], "entities": [{"text": "TS1", "start_pos": 37, "end_pos": 40, "type": "METRIC", "confidence": 0.5286086797714233}]}, {"text": "For the three test sets, TOEFL, TS1 and TS2 without context, we applied the word and document-oriented frequency estimates presented.", "labels": [], "entities": [{"text": "TOEFL", "start_pos": 25, "end_pos": 30, "type": "METRIC", "confidence": 0.7749955654144287}]}, {"text": "We investigated a variety of window sizes, varying the window size from 2 to 256 by powers of 2.", "labels": [], "entities": []}, {"text": "The labels used in figures 3, 5, 6, 8, 9, 10, 12 are composed from a keyword indicating the frequency estimate used (W-window oriented; and DR-document retrieval oriented) and a keyword indicating the word similarity measure.", "labels": [], "entities": []}, {"text": "For no-context measures the keywords are: PMI-Pointwise Mutual Information; CHI-Chi-Squared; MI-Average mutual information; and LL-Log-likelihood.", "labels": [], "entities": [{"text": "PMI-Pointwise", "start_pos": 42, "end_pos": 55, "type": "METRIC", "confidence": 0.9174219369888306}, {"text": "MI-Average mutual information", "start_pos": 93, "end_pos": 122, "type": "METRIC", "confidence": 0.8805705110232035}]}, {"text": "'s are multi-word strings.", "labels": [], "entities": []}, {"text": "For these questions, we assume that the strings maybe treated as collocations and use them \"as is\", adjusting the size of the windows by the collocation size when applicable.", "labels": [], "entities": []}, {"text": "The corpus used for the experiments is a terabyte of Web data crawled from the general web in 2001.", "labels": [], "entities": []}, {"text": "In order to balance the contents of the corpus, a breadth-first order search was used from a initial seed set of URLs representing the homepage of 2392 universities and other educational organizations.", "labels": [], "entities": []}, {"text": "No duplicate pages are included in the collection and the crawler also did not allow a large number of pages from the same site to be downloaded simultaneously.", "labels": [], "entities": []}, {"text": "Overall, the collection contains 53 billion words and 77 million documents.", "labels": [], "entities": []}, {"text": "A key characteristic of this corpus is that it consists of HTML files.", "labels": [], "entities": []}, {"text": "These files have a focus on the presentation, and not necessarily on the style of writing.", "labels": [], "entities": []}, {"text": "Parsing or tagging these files can be a hard process and prone to introduction of error in rates bigger than traditional corpora used in NLP or Information Retrieval.", "labels": [], "entities": [{"text": "Parsing or tagging these files", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.8890684723854065}, {"text": "Information Retrieval", "start_pos": 144, "end_pos": 165, "type": "TASK", "confidence": 0.7342907190322876}]}, {"text": "We also investigate the impact of the collection size on the results, as depicted in figures 4, 11 and 13 for TOEFL, TS1 and TS2 test sets, respectively.", "labels": [], "entities": [{"text": "TOEFL", "start_pos": 110, "end_pos": 115, "type": "DATASET", "confidence": 0.8497108221054077}, {"text": "TS1 and TS2 test sets", "start_pos": 117, "end_pos": 138, "type": "DATASET", "confidence": 0.7247945725917816}]}], "tableCaptions": []}