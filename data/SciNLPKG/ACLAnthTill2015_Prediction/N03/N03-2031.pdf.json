{"title": [{"text": "Auditory-based Acoustic Distinctive Features and Spectral Cues for Robust Automatic Speech Recognition in Low-SNR Car Environments", "labels": [], "entities": [{"text": "Auditory-based Acoustic Distinctive", "start_pos": 0, "end_pos": 35, "type": "TASK", "confidence": 0.6746486822764078}, {"text": "Robust Automatic Speech Recognition", "start_pos": 67, "end_pos": 102, "type": "TASK", "confidence": 0.6001665443181992}]}], "abstractContent": [{"text": "In this paper, a multi-stream paradigm is proposed to improve the performance of automatic speech recognition (ASR) systems in the presence of highly interfering car noise.", "labels": [], "entities": [{"text": "automatic speech recognition (ASR)", "start_pos": 81, "end_pos": 115, "type": "TASK", "confidence": 0.8035626113414764}]}, {"text": "It was found that combining the classical MFCCs with some auditory-based acoustic distinctive cues and the main formant frequencies of a speech signal using a multi-stream paradigm leads to an improvement in the recognition performance in noisy car environments.", "labels": [], "entities": []}], "introductionContent": [{"text": "In general, the performance of existing speech recognition systems, whose designs are predicated on relatively noise-free conditions, degrades rapidly in the presence of a high level of adverse conditions.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 40, "end_pos": 58, "type": "TASK", "confidence": 0.7800295054912567}]}, {"text": "However, a recognizer can provide good performance even in very noisy background conditions if the exact testing condition is used to provide the training material from which the reference patterns of the vocabulary are obtained, which is practically not always the case.", "labels": [], "entities": []}, {"text": "In order to cope with the adverse conditions, different approaches could be used.", "labels": [], "entities": []}, {"text": "The approaches that have been studied for achieving noise robustness can be summarized into two fundamentally different approaches.", "labels": [], "entities": [{"text": "noise robustness", "start_pos": 52, "end_pos": 68, "type": "TASK", "confidence": 0.7214919626712799}]}, {"text": "The first approach attempts to preprocess the corrupted speech input signal prior to the pattern matching in an attempt to enhance the SNR.", "labels": [], "entities": [{"text": "SNR", "start_pos": 135, "end_pos": 138, "type": "TASK", "confidence": 0.9424998760223389}]}, {"text": "The second approach attempts to modify the pattern matching itself in order to account for the effects of noise.", "labels": [], "entities": []}, {"text": "For more details see).", "labels": [], "entities": []}, {"text": "Ina previous work, we introduced an auditory-based multi-stream paradigm for ASR ().", "labels": [], "entities": [{"text": "ASR", "start_pos": 77, "end_pos": 80, "type": "TASK", "confidence": 0.9871044158935547}]}, {"text": "Within this multi-stream paradigm, we merge different sources of information about the speech signal that could be lost when using only the MFCCs to recognize uttered speech.", "labels": [], "entities": []}, {"text": "Our experiments showed that the use of some auditory-based features and formant cues via a multistream paradigm approach leads to an improvement of the recognition performance.", "labels": [], "entities": []}, {"text": "This proves that the MFCCs loose some information relevant to the recognition process despite the popularity of such coefficients in all current ASR systems.", "labels": [], "entities": [{"text": "recognition process", "start_pos": 66, "end_pos": 85, "type": "TASK", "confidence": 0.9092070758342743}, {"text": "ASR", "start_pos": 145, "end_pos": 148, "type": "TASK", "confidence": 0.9815853834152222}]}, {"text": "In our experiments, we used a 3-stream feature vector.", "labels": [], "entities": []}, {"text": "The First stream vector consists of the classical MFCCs and their first derivatives, whereas the second stream vector consists of acoustic cues derived from hearing phenomena studies.", "labels": [], "entities": []}, {"text": "Finally, the magnitudes of the main resonances of the spectrum of the speech signal were used as the elements of the third stream vector.", "labels": [], "entities": []}, {"text": "In this paper, we extend our work presented in () to evaluate the robustness of the proposed features (the acoustic distinctive cues and the spectral cues) using a multi-stream paradigm for ASR in noisy car environments.", "labels": [], "entities": [{"text": "ASR", "start_pos": 190, "end_pos": 193, "type": "TASK", "confidence": 0.9935424327850342}]}, {"text": "As mentioned above, the first stream consists of the MFCCs and their first derivatives, whereas the second stream vector consists of the acoustic cues are computed from an auditory-based analysis applied to the speech signal modeled using the Caelen Model.", "labels": [], "entities": []}, {"text": "Finally, the values of the main peaks of the spectrum of the speech signal were used as the elements of the third stream vector.", "labels": [], "entities": []}, {"text": "The magnitudes of the main peaks were obtained through an LPC analysis.", "labels": [], "entities": [{"text": "LPC", "start_pos": 58, "end_pos": 61, "type": "DATASET", "confidence": 0.8981050252914429}]}, {"text": "The outline of this paper is as follows.", "labels": [], "entities": []}, {"text": "In section 2, an overview on the auditory Caelen Model is given.", "labels": [], "entities": []}, {"text": "Next, we describe briefly in section 3 the statistical framework of the multi-stream paradigm.", "labels": [], "entities": []}, {"text": "Then in section 4, we proceed with the evaluation of the proposed approach for ASR.", "labels": [], "entities": [{"text": "ASR", "start_pos": 79, "end_pos": 82, "type": "TASK", "confidence": 0.9913625121116638}]}, {"text": "Finally, in section 5 we conclude and discuss our results. of current ASR systems is far from the performance achieved by humans.", "labels": [], "entities": [{"text": "ASR", "start_pos": 70, "end_pos": 73, "type": "TASK", "confidence": 0.9920437932014465}]}, {"text": "In an attempt to improve the ASR performance in noisy environments, we evaluate in this work the use of the hearing/perception knowledge for ASR in noisy car environments.", "labels": [], "entities": [{"text": "ASR", "start_pos": 29, "end_pos": 32, "type": "TASK", "confidence": 0.9927265644073486}, {"text": "ASR", "start_pos": 141, "end_pos": 144, "type": "TASK", "confidence": 0.9934918284416199}]}, {"text": "This is accomplished through the use of the auditory-based acoustic distinctive features and the formant frequencies for robust ASR.", "labels": [], "entities": [{"text": "ASR", "start_pos": 128, "end_pos": 131, "type": "TASK", "confidence": 0.9705270528793335}]}], "datasetContent": [{"text": "In the following experiments the TIMIT database was used.", "labels": [], "entities": [{"text": "TIMIT database", "start_pos": 33, "end_pos": 47, "type": "DATASET", "confidence": 0.7955875992774963}]}, {"text": "The TIMIT corpus contains broadband recordings of a total of 6300 sentences, 10 sentences spoken by each of 630 speakers from 8 major dialect regions of the United States, each reading 10 phonetically rich sentences.", "labels": [], "entities": [{"text": "TIMIT corpus", "start_pos": 4, "end_pos": 16, "type": "DATASET", "confidence": 0.9225780665874481}]}, {"text": "To simulate a noisy environment, car noise was added artificially to the clean speech.", "labels": [], "entities": []}, {"text": "Throughout all experiments the HTK-based speech recognition platform system described in (Cambridge University Speech Group, 1997) has been used.", "labels": [], "entities": [{"text": "HTK-based speech recognition platform", "start_pos": 31, "end_pos": 68, "type": "TASK", "confidence": 0.6858141496777534}, {"text": "Cambridge University Speech Group, 1997)", "start_pos": 90, "end_pos": 130, "type": "DATASET", "confidence": 0.9647793429238456}]}, {"text": "The toolkit was designed to support continuous-density HMMs with any numbers of state and mixture components.", "labels": [], "entities": []}, {"text": "In order to evaluate the use of the proposed features for ASR in noisy car environments, we repeated the same experiments performed in our previous study) using the subsets dr1 & dr2 of a noisy version of the TIMIT database at different values of SNR which varies from 16 dB to -4 dB.", "labels": [], "entities": [{"text": "ASR", "start_pos": 58, "end_pos": 61, "type": "TASK", "confidence": 0.9934739470481873}, {"text": "TIMIT database", "start_pos": 209, "end_pos": 223, "type": "DATASET", "confidence": 0.9170794188976288}]}, {"text": "In all our experiments, 12 MFCCs were calculated on a 30-msec Hamming window advanced by 10 msec each frame.", "labels": [], "entities": []}, {"text": "Moreover, the normalized log energy is also found, which is added to the 12 MFCCs to form a 13-dimensional (static) vector.", "labels": [], "entities": []}, {"text": "This static vector is then expanded to produce a 26-dimensional (static+dynamic) vector.", "labels": [], "entities": []}, {"text": "This latter was expanded by adding the seven acoustic distinctive cues that were computed based on the Caelen model analysis.", "labels": [], "entities": []}, {"text": "This was followed by the computation of the main spectral peak magnitudes, which were added to the MFCCs and the acoustic cues to form a 37-dimensional vector    upon which the hidden Markov models (HMMs), that model the speech subword units, were trained.", "labels": [], "entities": [{"text": "MFCCs", "start_pos": 99, "end_pos": 104, "type": "DATASET", "confidence": 0.7975363731384277}]}, {"text": "The main spectral peak magnitudes were computed based on an LPC analysis using 12 poles followed by a peak picking algorithm.", "labels": [], "entities": []}, {"text": "The proposed system used for the recognition task uses tri-phone Gaussian mixture HMM system.", "labels": [], "entities": [{"text": "recognition task", "start_pos": 33, "end_pos": 49, "type": "TASK", "confidence": 0.9234472215175629}]}, {"text": "Three different sets of experiments has been carried out on the noisy version of the TIMIT database.", "labels": [], "entities": [{"text": "TIMIT database", "start_pos": 85, "end_pos": 99, "type": "DATASET", "confidence": 0.9406663775444031}]}, {"text": "In the first set of these experiments, we tested our recognizer using a 30-dimensional feature vector (MFCCEDP), in which we combined the magnitudes of the main spectral peaks to the classical MFCCs and their first derivatives to form two streams that have been used to perform the recognition process.", "labels": [], "entities": []}, {"text": "We found through experiments that the use of these two streams leads to an improvement in the accuracy of the word recognition rate compared to the one obtained when we used the classical MFCCEDA feature vector,.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 94, "end_pos": 102, "type": "METRIC", "confidence": 0.9994282126426697}, {"text": "word recognition", "start_pos": 110, "end_pos": 126, "type": "TASK", "confidence": 0.7974559664726257}]}, {"text": "These tests were repeated using the 2-stream feature vector, in which we combined the acoustic distinctive cues to the classical MFCCs and their first derivatives to form two streams (MFCCEDE).", "labels": [], "entities": []}, {"text": "Again, using these two streams, an improvement in the accuracy of the word recognition rate has been obtained when we tested our recognizer using N mixture Gaussian HMMs using triphone models for different values of SNR,.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 54, "end_pos": 62, "type": "METRIC", "confidence": 0.9993653893470764}, {"text": "word recognition", "start_pos": 70, "end_pos": 86, "type": "TASK", "confidence": 0.8185435831546783}]}, {"text": "We repeated these tests using the proposed features which combines the MFCCs with the acoustic distinctive cues and the formant frequencies to form a three-stream feature vector (MFCCEDEP).", "labels": [], "entities": []}, {"text": "Again, using these combined features, an improvement in the accuracy of the word recognition rate was obtained,.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 60, "end_pos": 68, "type": "METRIC", "confidence": 0.9994522929191589}, {"text": "word recognition", "start_pos": 76, "end_pos": 92, "type": "TASK", "confidence": 0.8476125597953796}]}], "tableCaptions": []}