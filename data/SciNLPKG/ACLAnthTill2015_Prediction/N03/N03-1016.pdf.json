{"title": [{"text": "A* Parsing: Fast Exact Viterbi Parse Selection", "labels": [], "entities": [{"text": "A", "start_pos": 0, "end_pos": 1, "type": "METRIC", "confidence": 0.9097483158111572}]}], "abstractContent": [{"text": "We present an extension of the classic A* search procedure to tabular PCFG parsing.", "labels": [], "entities": [{"text": "tabular PCFG parsing", "start_pos": 62, "end_pos": 82, "type": "TASK", "confidence": 0.6703409751256307}]}, {"text": "The use of A* search can dramatically reduce the time required to find a best parse by conservatively estimating the probabilities of parse completions.", "labels": [], "entities": []}, {"text": "We discuss various estimates and give efficient algorithms for computing them.", "labels": [], "entities": []}, {"text": "On average-length Penn treebank sentences , our most detailed estimate reduces the total number of edges processed to less than 3% of that required by exhaustive parsing, and a simpler estimate, which requires less than a minute of pre-computation, reduces the work to less than 5%.", "labels": [], "entities": [{"text": "Penn treebank sentences", "start_pos": 18, "end_pos": 41, "type": "DATASET", "confidence": 0.7814176579316457}]}, {"text": "Unlike best-first and finite-beam methods for achieving this kind of speed-up, an A* method is guaranteed to find the most likely parse, not just an approximation.", "labels": [], "entities": []}, {"text": "Our parser, which is simpler to implement than an upward-propagating best-first parser, is correct fora wide range of parser control strategies and maintains worst-case cubic time.", "labels": [], "entities": []}], "introductionContent": [{"text": "PCFG parsing algorithms with worst-case cubic-time bounds are well-known.", "labels": [], "entities": [{"text": "PCFG parsing", "start_pos": 0, "end_pos": 12, "type": "TASK", "confidence": 0.7787129580974579}]}, {"text": "However, when dealing with wide-coverage grammars and long sentences, even cubic algorithms can be far too expensive in practice.", "labels": [], "entities": []}, {"text": "Two primary types of methods for accelerating parse selection have been proposed. and Ratnaparkhi (1999) use a beam-search strategy, in which only the best n parses are tracked at any moment.", "labels": [], "entities": [{"text": "parse selection", "start_pos": 46, "end_pos": 61, "type": "TASK", "confidence": 0.918428361415863}]}, {"text": "Parsing time is linear and can be made arbitrarily fast by reducing n.", "labels": [], "entities": [{"text": "Parsing", "start_pos": 0, "end_pos": 7, "type": "TASK", "confidence": 0.8285517692565918}]}, {"text": "This is a greedy strategy, and the actual Viterbi (highest probability) parse can be pruned from the beam because, while it is globally optimal, it may not be locally optimal at every parse stage.,, , and Collins (1999) describe best-first parsing, which is intended fora tabular item-based framework.", "labels": [], "entities": []}, {"text": "In best-first parsing, one builds a figure-of-merit (FOM) over parser items, and uses the FOM to decide the order in which agenda items should be processed.", "labels": [], "entities": [{"text": "figure-of-merit (FOM)", "start_pos": 36, "end_pos": 57, "type": "METRIC", "confidence": 0.6709932833909988}, {"text": "FOM", "start_pos": 90, "end_pos": 93, "type": "METRIC", "confidence": 0.9829356670379639}]}, {"text": "This approach also dramatically reduces the work done during parsing, though it, too, gives no guarantee that the first parse returned is the actual Viterbi parse (nor does it maintain a worst-case cubic time bound).", "labels": [], "entities": [{"text": "parsing", "start_pos": 61, "end_pos": 68, "type": "TASK", "confidence": 0.9614940881729126}]}, {"text": "We discuss best-first parsing further in section 3.3.", "labels": [], "entities": []}, {"text": "Both of these speed-up techniques are based on greedy models of parser actions.", "labels": [], "entities": []}, {"text": "The beam search greedily prunes partial parses at each beam stage, and a best-first FOM greedily orders parse item exploration.", "labels": [], "entities": [{"text": "parse item exploration", "start_pos": 104, "end_pos": 126, "type": "TASK", "confidence": 0.70304936170578}]}, {"text": "If we wish to maintain optimality in a search procedure, the obvious thing to try is A* methods (see for example.", "labels": [], "entities": []}, {"text": "We apply A* search to a tabular itembased parser, ordering the parse items based on a combination of their known internal cost of construction and a conservative estimate of their cost of completion (see).", "labels": [], "entities": []}, {"text": "A* search has been proposed and used for speech applications; however, it has been little used, certainly in the recent statistical parsing literature, apparently because of difficulty in conceptualizing and computing effective admissible estimates.", "labels": [], "entities": [{"text": "statistical parsing", "start_pos": 120, "end_pos": 139, "type": "TASK", "confidence": 0.707871824502945}]}, {"text": "The contribution of this paper is to demonstrate effective ways of doing this, by precomputing grammar statistics which can be used as effective A* estimates.", "labels": [], "entities": [{"text": "A", "start_pos": 145, "end_pos": 146, "type": "METRIC", "confidence": 0.959846556186676}]}, {"text": "The A* formulation provides three benefits.", "labels": [], "entities": []}, {"text": "First, it substantially reduces the work required to parse a sentence, without sacrificing either the optimality of the answer or the worst-case cubic time bounds on the parser.", "labels": [], "entities": [{"text": "parse a sentence", "start_pos": 53, "end_pos": 69, "type": "TASK", "confidence": 0.8661099473635355}]}, {"text": "Second, the resulting parser is structurally simpler than a FOM-driven best-first parser.", "labels": [], "entities": [{"text": "FOM-driven best-first parser", "start_pos": 60, "end_pos": 88, "type": "TASK", "confidence": 0.5138122538725535}]}, {"text": "Finally, it allows us to easily prove the correctness of our algorithm, over abroad range of control strategies and grammar encodings.", "labels": [], "entities": []}, {"text": "In this paper, we describe two methods of constructing A* bounds for PCFGs.", "labels": [], "entities": []}, {"text": "One involves context summarization, which uses estimates of the sort proposed in, but considering richer summaries.", "labels": [], "entities": [{"text": "context summarization", "start_pos": 13, "end_pos": 34, "type": "TASK", "confidence": 0.590956062078476}]}, {"text": "The other involves grammar summarization, which, to our knowledge, is entirely novel.", "labels": [], "entities": [{"text": "grammar summarization", "start_pos": 19, "end_pos": 40, "type": "TASK", "confidence": 0.7627027332782745}]}, {"text": "We present the estimates that we use, along with algorithms to efficiently calculate them, and illustrate their effectiveness in a tabular PCFG parsing algorithm, applied to Penn Treebank sentences.", "labels": [], "entities": [{"text": "PCFG parsing", "start_pos": 139, "end_pos": 151, "type": "TASK", "confidence": 0.7863074839115143}, {"text": "Penn Treebank sentences", "start_pos": 174, "end_pos": 197, "type": "DATASET", "confidence": 0.9684162338574728}]}, {"text": "The cost of an edge X is a combination of the cost to build the edge (the Viterbi inside score \u03b2) and the cost to incorporate it into a root parse (the Viterbi outside score \u03b1).", "labels": [], "entities": [{"text": "Viterbi inside score \u03b2", "start_pos": 74, "end_pos": 96, "type": "METRIC", "confidence": 0.5523050278425217}]}, {"text": "(b) In the corresponding hypergraph, we have exact values for the inside score from the explored hyperedges (solid lines), and use upper bounds on the outside score, which estimate the dashed hyperedges.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": []}