{"title": [{"text": "Supervised and unsupervised PCFG adaptation to novel domains", "labels": [], "entities": [{"text": "PCFG adaptation", "start_pos": 28, "end_pos": 43, "type": "TASK", "confidence": 0.7820752859115601}]}], "abstractContent": [{"text": "This paper investigates adapting a lexicalized probabilistic context-free grammar (PCFG) to a novel domain, using maximum a posteriori (MAP) estimation.", "labels": [], "entities": [{"text": "maximum a posteriori (MAP) estimation", "start_pos": 114, "end_pos": 151, "type": "METRIC", "confidence": 0.8423544594219753}]}, {"text": "The MAP framework is general enough to include some previous model adaptation approaches, such as corpus mixing in Gildea (2001), for example.", "labels": [], "entities": [{"text": "corpus mixing", "start_pos": 98, "end_pos": 111, "type": "TASK", "confidence": 0.7938955128192902}]}, {"text": "Other approaches falling within this framework are more effective.", "labels": [], "entities": []}, {"text": "In contrast to the results in Gildea (2001), we show F-measure parsing accuracy gains of as much as 2.5% for high accuracy lexicalized parsing through the use of out-of-domain treebanks, with the largest gains when the amount of in-domain data is small.", "labels": [], "entities": [{"text": "F-measure parsing", "start_pos": 53, "end_pos": 70, "type": "TASK", "confidence": 0.6457495987415314}, {"text": "accuracy", "start_pos": 71, "end_pos": 79, "type": "METRIC", "confidence": 0.8543768525123596}]}, {"text": "MAP adaptation can also be based on either supervised or unsupervised adaptation data.", "labels": [], "entities": [{"text": "MAP adaptation", "start_pos": 0, "end_pos": 14, "type": "TASK", "confidence": 0.9707713723182678}]}, {"text": "Even when no in-domain treebank is available, unsupervised techniques provide a substantial accuracy gain over unadapted grammars, as much as nearly 5% F-measure improvement.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 92, "end_pos": 100, "type": "METRIC", "confidence": 0.9986563920974731}, {"text": "F-measure", "start_pos": 152, "end_pos": 161, "type": "METRIC", "confidence": 0.9753521680831909}]}], "introductionContent": [{"text": "A fundamental concern for nearly all data-driven approaches to language processing is the sparsity of labeled training data.", "labels": [], "entities": [{"text": "language processing", "start_pos": 63, "end_pos": 82, "type": "TASK", "confidence": 0.7609034776687622}]}, {"text": "The sparsity of syntactically annotated corpora is widely remarked upon, and some recent papers present approaches to improving performance in the absence of large amounts of annotated training data.", "labels": [], "entities": []}, {"text": "looked at adding features to a maximum entropy model for stochastic unification-based grammars (SUBG), from corpora that are not annotated with the SUBG, but rather with simpler treebank annotations for which there are much larger treebanks.", "labels": [], "entities": [{"text": "stochastic unification-based grammars (SUBG)", "start_pos": 57, "end_pos": 101, "type": "TASK", "confidence": 0.6921161909898123}]}, {"text": "demonstrated how active learning techniques can reduce the amount of annotated data required to converge on the best performance, by selecting from among the candidate strings to be annotated in ways which promote more informative examples for earlier annotation. and looked at adapting parsing models trained on large amounts of annotated data from outside of the domain of interest (out-of-domain), through the use of a relatively small amount of in-domain annotated data.", "labels": [], "entities": []}, {"text": "used a variant of the inside-outside algorithm presented in to exploit a partially labeled out-of-domain treebank, and found an advantage to adaptation over direct grammar induction.", "labels": [], "entities": []}, {"text": "simply added the out-of-domain treebank to his in-domain training data, and derived a very small benefit for his high accuracy, lexicalized parser, concluding that even a large amount of out-of-domain data is of little use for lexicalized parsing.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 118, "end_pos": 126, "type": "METRIC", "confidence": 0.9984538555145264}]}, {"text": "Statistical model adaptation based on sparse in-domain data, however, is neither anew problem nor unique to parsing.", "labels": [], "entities": [{"text": "Statistical model adaptation", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.7175911863644918}, {"text": "parsing", "start_pos": 108, "end_pos": 115, "type": "TASK", "confidence": 0.9622470736503601}]}, {"text": "It has been studied extensively by researchers working on acoustic modeling for automatic speech recognition (ASR) ().", "labels": [], "entities": [{"text": "automatic speech recognition (ASR)", "start_pos": 80, "end_pos": 114, "type": "TASK", "confidence": 0.8046930929025015}]}, {"text": "One of the methods that has received much attention in the ASR literature is maximum a posteriori (MAP) estimation (.", "labels": [], "entities": [{"text": "ASR", "start_pos": 59, "end_pos": 62, "type": "TASK", "confidence": 0.9775190353393555}, {"text": "maximum a posteriori (MAP) estimation", "start_pos": 77, "end_pos": 114, "type": "METRIC", "confidence": 0.827069274016789}]}, {"text": "In MAP estimation, the parameters of the model are considered to be random variables themselves with a known distribution (the prior).", "labels": [], "entities": [{"text": "MAP estimation", "start_pos": 3, "end_pos": 17, "type": "TASK", "confidence": 0.9576373994350433}]}, {"text": "The prior distribution and the maximum likelihood distribution based on the in-domain observations then give a posterior distribution over the parameters, from which the mode is selected.", "labels": [], "entities": []}, {"text": "If the amount of indomain (adaptation) data is large, the mode of the posterior distribution is mostly defined by the adaptation sample; if the amount of adaptation data is small, the mode will nearly coincide with the mode of the prior distribution.", "labels": [], "entities": []}, {"text": "The intuition behind MAP estimation is that once there are sufficient observations, the prior model need no longer be relied upon.", "labels": [], "entities": [{"text": "MAP estimation", "start_pos": 21, "end_pos": 35, "type": "TASK", "confidence": 0.9639795422554016}]}, {"text": "investigated MAP adaptation of n-gram language models, in away that is straightforwardly applicable to probabilistic context-free grammars (PCFGs).", "labels": [], "entities": [{"text": "MAP adaptation", "start_pos": 13, "end_pos": 27, "type": "TASK", "confidence": 0.9798633456230164}]}, {"text": "Indeed, this approach can be used for any generative probabilistic model, such as part-of-speech taggers.", "labels": [], "entities": [{"text": "part-of-speech taggers", "start_pos": 82, "end_pos": 104, "type": "TASK", "confidence": 0.7085489183664322}]}, {"text": "In their language modeling approach, in-domain counts are mixed with the out-of-domain model, so that, if the number of observations within the domain is small, the outof-domain model is relied upon, whereas if the number of observations in the domain is high, the model will move toward a Maximum Likelihood (ML) estimate on the indomain data alone.", "labels": [], "entities": [{"text": "Maximum Likelihood (ML) estimate", "start_pos": 290, "end_pos": 322, "type": "METRIC", "confidence": 0.8312616844971975}]}, {"text": "The case of a parsing model trained via relative frequency estimation is identical: in-domain counts can be combined with the out-of-domain model in just such away.", "labels": [], "entities": [{"text": "parsing", "start_pos": 14, "end_pos": 21, "type": "TASK", "confidence": 0.9634571075439453}]}, {"text": "We will show below that weighted count merging is a special case of MAP adaptation; hence the approach of cited above is also a special case of MAP adaptation, with a particular parameterization of the prior.", "labels": [], "entities": [{"text": "weighted count merging", "start_pos": 24, "end_pos": 46, "type": "TASK", "confidence": 0.6039999624093374}, {"text": "MAP adaptation", "start_pos": 68, "end_pos": 82, "type": "TASK", "confidence": 0.9110414683818817}, {"text": "MAP adaptation", "start_pos": 144, "end_pos": 158, "type": "TASK", "confidence": 0.8224876821041107}]}, {"text": "This parameterization is not necessarily the one that optimizes performance.", "labels": [], "entities": []}, {"text": "In the next section, MAP estimation for PCFGs is presented.", "labels": [], "entities": [{"text": "MAP estimation", "start_pos": 21, "end_pos": 35, "type": "TASK", "confidence": 0.8039087057113647}]}, {"text": "This is followed by a brief presentation of the PCFG model that is being learned, and the parser that is used for the empirical trials.", "labels": [], "entities": []}, {"text": "We will present empirical results for multiple MAP adaptation schema, both starting from the Penn Wall St. Journal treebank and adapting to the Brown corpus, and vice versa.", "labels": [], "entities": [{"text": "MAP adaptation", "start_pos": 47, "end_pos": 61, "type": "TASK", "confidence": 0.9295071065425873}, {"text": "Penn Wall St. Journal treebank", "start_pos": 93, "end_pos": 123, "type": "DATASET", "confidence": 0.9846825122833252}, {"text": "Brown corpus", "start_pos": 144, "end_pos": 156, "type": "DATASET", "confidence": 0.9207384586334229}]}, {"text": "We will compare our supervised adaptation performance with the results presented in.", "labels": [], "entities": []}, {"text": "In addition to supervised adaptation, i.e. with a manually annotated treebank, we will present results for unsupervised adaptation, i.e. with an automatically annotated treebank.", "labels": [], "entities": []}, {"text": "We investigate a number of unsupervised approaches, including multiple iterations, increased sample sizes, and self-adaptation.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Conditioning features for the probabilistic CFG  used in the reported empirical trials", "labels": [], "entities": []}, {"text": " Table 3: Parser performance on Brown;E, baselines. Note  that the Gildea results are for sentences \u2264 40 words in  length.", "labels": [], "entities": []}, {"text": " Table 4: Parser performance on WSJ;23, baselines. Note  that the Gildea results are for sentences \u2264 40 words in  length. All others include all sentences.", "labels": [], "entities": [{"text": "WSJ", "start_pos": 32, "end_pos": 35, "type": "DATASET", "confidence": 0.8689565062522888}]}, {"text": " Table 5: Parser performance on Brown;E, supervised adaptation", "labels": [], "entities": []}, {"text": " Table 7: Parser performance on WSJ;23, supervised adaptation. All models use Brown;T,H as the out-of-domain treebank.  Baseline models are built from the fractions of WSJ;2-21, with no out-of-domain treebank.", "labels": [], "entities": [{"text": "WSJ", "start_pos": 32, "end_pos": 35, "type": "DATASET", "confidence": 0.8540955781936646}, {"text": "WSJ", "start_pos": 168, "end_pos": 171, "type": "DATASET", "confidence": 0.9490339756011963}]}, {"text": " Table 8: Parser performance on WSJ;23, unsupervised  adaptation. For all trials, the base training is Brown;T, the  held out is Brown;H plus the parser output for WSJ;24, and", "labels": [], "entities": [{"text": "WSJ", "start_pos": 32, "end_pos": 35, "type": "DATASET", "confidence": 0.8455074429512024}, {"text": "WSJ", "start_pos": 164, "end_pos": 167, "type": "DATASET", "confidence": 0.8768033981323242}]}]}