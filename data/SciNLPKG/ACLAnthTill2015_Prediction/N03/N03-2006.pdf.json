{"title": [{"text": "Adaptation Using Out-of-Domain Corpus within EBMT", "labels": [], "entities": [{"text": "EBMT", "start_pos": 45, "end_pos": 49, "type": "DATASET", "confidence": 0.9024319052696228}]}], "abstractContent": [{"text": "In order to boost the translation quality of EBMT based on a small-sized bilingual corpus , we use an out-of-domain bilingual corpus and, in addition, the language model of an in-domain monolingual corpus.", "labels": [], "entities": []}, {"text": "We conducted experiments with an EBMT system.", "labels": [], "entities": []}, {"text": "The two evaluation measures of the BLEU score and the NIST score demonstrated the effect of using an out-of-domain bilingual corpus and the possibility of using the language model.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 35, "end_pos": 39, "type": "METRIC", "confidence": 0.9982768297195435}, {"text": "NIST score", "start_pos": 54, "end_pos": 64, "type": "DATASET", "confidence": 0.9325496852397919}]}], "introductionContent": [{"text": "Example-Based Machine Translation (EBMT) is adaptable to new domains.", "labels": [], "entities": [{"text": "Example-Based Machine Translation (EBMT)", "start_pos": 0, "end_pos": 40, "type": "TASK", "confidence": 0.832915465037028}]}, {"text": "If you simply prepare a bilingual corpus of anew domain, you'll get a translation system for the domain.", "labels": [], "entities": []}, {"text": "However, if only a small-sized corpus is available, low translation quality is obtained.", "labels": [], "entities": []}, {"text": "We explored methods to boost translation quality based on a small-sized bilingual corpus in the domain.", "labels": [], "entities": [{"text": "translation", "start_pos": 29, "end_pos": 40, "type": "TASK", "confidence": 0.9643344283103943}]}, {"text": "Among these methods, we use an out-of-domain bilingual corpus and, in addition, the language model (LM) of an indomain monolingual corpus.", "labels": [], "entities": []}, {"text": "For accuracy of the LM, a larger training set is better.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.9980607628822327}]}, {"text": "The training set is a target language corpus, which can be more easily prepared than a bilingual corpus.", "labels": [], "entities": []}, {"text": "In prior works, statistical machine translation used not only LM but also translation models.", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 16, "end_pos": 47, "type": "TASK", "confidence": 0.6866817673047384}]}, {"text": "However, making a translation model requires a bilingual corpus.", "labels": [], "entities": [{"text": "translation", "start_pos": 18, "end_pos": 29, "type": "TASK", "confidence": 0.9713587164878845}]}, {"text": "On the other hand, in some studies on multiple-translation selection, the LM of the target language is used to calculate translation scores).", "labels": [], "entities": [{"text": "multiple-translation selection", "start_pos": 38, "end_pos": 68, "type": "TASK", "confidence": 0.7381271421909332}]}, {"text": "For adaptation, we use the LM of an in-domain target language.", "labels": [], "entities": [{"text": "adaptation", "start_pos": 4, "end_pos": 14, "type": "TASK", "confidence": 0.9751051068305969}]}, {"text": "In the following sections, we describe the methods using an out-of-domain bilingual corpus and an indomain monolingual corpus.", "labels": [], "entities": []}, {"text": "Moreover, we report on our experiments.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1. TEL is split into two parts: a test  set of 1,653 sentence pairs and a training set of 9,918.  Perplexities reveal the large difference between the in- domain and out-of-domain corpora.", "labels": [], "entities": []}, {"text": " Table 2. Experimental results of translation by BLEU scores", "labels": [], "entities": [{"text": "translation", "start_pos": 34, "end_pos": 45, "type": "TASK", "confidence": 0.9787724018096924}, {"text": "BLEU", "start_pos": 49, "end_pos": 53, "type": "METRIC", "confidence": 0.9471327662467957}]}]}