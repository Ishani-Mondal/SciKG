{"title": [{"text": "Statistical Sentence Condensation using Ambiguity Packing and Stochastic Disambiguation Methods for Lexical-Functional Grammar", "labels": [], "entities": [{"text": "Statistical Sentence Condensation", "start_pos": 0, "end_pos": 33, "type": "TASK", "confidence": 0.8329172531763712}, {"text": "Lexical-Functional Grammar", "start_pos": 100, "end_pos": 126, "type": "TASK", "confidence": 0.8516384065151215}]}], "abstractContent": [{"text": "We present an application of ambiguity packing and stochastic disambiguation techniques for Lexical-Functional Grammars (LFG) to the domain of sentence condensation.", "labels": [], "entities": [{"text": "Lexical-Functional Grammars (LFG)", "start_pos": 92, "end_pos": 125, "type": "TASK", "confidence": 0.7191985845565796}, {"text": "sentence condensation", "start_pos": 143, "end_pos": 164, "type": "TASK", "confidence": 0.7145564258098602}]}, {"text": "Our system incorporates a linguistic parser/generator for LFG, a transfer component for parse reduction operating on packed parse forests, and a maximum-entropy model for stochastic output selection.", "labels": [], "entities": [{"text": "parse reduction", "start_pos": 88, "end_pos": 103, "type": "TASK", "confidence": 0.9454098641872406}]}, {"text": "Furthermore, we propose the use of standard parser evaluation methods for automatically evaluating the summarization quality of sentence condensation systems.", "labels": [], "entities": [{"text": "summarization", "start_pos": 103, "end_pos": 116, "type": "TASK", "confidence": 0.9615205526351929}]}, {"text": "An experimental evaluation of summarization quality shows a close correlation between the automatic parse-based evaluation and a manual evaluation of generated strings.", "labels": [], "entities": [{"text": "summarization", "start_pos": 30, "end_pos": 43, "type": "TASK", "confidence": 0.9792527556419373}]}, {"text": "Overall sum-marization quality of the proposed system is state-of-the-art, with guaranteed grammatical-ity of the system output due to the use of a constraint-based parser/generator.", "labels": [], "entities": []}], "introductionContent": [{"text": "Recent work in statistical text summarization has put forward systems that do not merely extract and concatenate sentences, but learn how to generate new sentences from Summary, T ext tuples.", "labels": [], "entities": [{"text": "statistical text summarization", "start_pos": 15, "end_pos": 45, "type": "TASK", "confidence": 0.731114904085795}]}, {"text": "Depending on the chosen task, such systems either generate single-sentence \"headlines\" for multi-sentence text), or they provide a sentence condensation module designed for combination with sentence extraction systems).", "labels": [], "entities": [{"text": "sentence extraction", "start_pos": 190, "end_pos": 209, "type": "TASK", "confidence": 0.717426061630249}]}, {"text": "The challenge for such systems is to guarantee the grammaticality and summarization quality of the system output, i.e. the generated sentences need to be syntactically wellformed and need to retain the most salient information of the original document.", "labels": [], "entities": []}, {"text": "For example a sentence extraction system might choose a sentence like: The UNIX operating system, with implementations from Apples to Crays, appears to have the advantage. from a document, which could be condensed as: UNIX appears to have the advantage.", "labels": [], "entities": [{"text": "sentence extraction", "start_pos": 14, "end_pos": 33, "type": "TASK", "confidence": 0.7276756912469864}]}, {"text": "In the approach of, selection and ordering of summary terms is based on bagof-words models and n-grams.", "labels": [], "entities": []}, {"text": "Such models may well produce summaries that are indicative of the original's content; however, n-gram models seem to be insufficient to guarantee grammatical well-formedness of the system output.", "labels": [], "entities": []}, {"text": "To overcome this problem, linguistic parsing and generation systems are used in the sentence condensation approaches of and.", "labels": [], "entities": [{"text": "linguistic parsing", "start_pos": 26, "end_pos": 44, "type": "TASK", "confidence": 0.6921894401311874}]}, {"text": "In these approaches, decisions about which material to include/delete in the sentence summaries do not rely on relative frequency information on words, but rather on probability models of subtree deletions that are learned from a corpus of parses for sentences and their summaries.", "labels": [], "entities": []}, {"text": "A related area where linguistic parsing systems have been applied successfully is sentence simplification.", "labels": [], "entities": [{"text": "linguistic parsing", "start_pos": 21, "end_pos": 39, "type": "TASK", "confidence": 0.7029356360435486}, {"text": "sentence simplification", "start_pos": 82, "end_pos": 105, "type": "TASK", "confidence": 0.8226919174194336}]}, {"text": "presented a sentence reduction method that is based on finite-state technology for linguistic markup and selection, and present a sentence simplification system based on linguistic parsing.", "labels": [], "entities": [{"text": "sentence reduction", "start_pos": 12, "end_pos": 30, "type": "TASK", "confidence": 0.780469685792923}, {"text": "linguistic markup and selection", "start_pos": 83, "end_pos": 114, "type": "TASK", "confidence": 0.616656206548214}, {"text": "linguistic parsing", "start_pos": 170, "end_pos": 188, "type": "TASK", "confidence": 0.7304538190364838}]}, {"text": "However, these approaches do not employ statistical learning techniques to disambiguate simplification decisions, but iteratively apply symbolic reduction rules, producing a single output for each sentence.", "labels": [], "entities": []}, {"text": "The goal of our approach is to apply the fine-grained tools for stochastic Lexical-Functional Grammar (LFG) parsing to the task of sentence condensation.", "labels": [], "entities": [{"text": "stochastic Lexical-Functional Grammar (LFG) parsing", "start_pos": 64, "end_pos": 115, "type": "TASK", "confidence": 0.7782756771360125}, {"text": "sentence condensation", "start_pos": 131, "end_pos": 152, "type": "TASK", "confidence": 0.7138463407754898}]}, {"text": "The system presented in this paper is conceptualized as a tool that can be used as a standalone system for sentence condensation or simplification, or in combination with sentence extraction for text-summarization beyond the sentence-level.", "labels": [], "entities": [{"text": "sentence condensation or simplification", "start_pos": 107, "end_pos": 146, "type": "TASK", "confidence": 0.7564080879092216}, {"text": "sentence extraction", "start_pos": 171, "end_pos": 190, "type": "TASK", "confidence": 0.7141551375389099}]}, {"text": "In our system, to produce a condensed version of a sentence, the sentence is first parsed using a broad-coverage LFG grammar for English.", "labels": [], "entities": []}, {"text": "The parser produces a set of functional (f )-structures for an ambiguous sentence in a packed format.", "labels": [], "entities": []}, {"text": "It presents these to the transfer component in a single packed data structure that represents in one place the substructures shared by several different interpretations.", "labels": [], "entities": []}, {"text": "The transfer component operates on these packed representations and modifies the parser output to produce reduced f -structures.", "labels": [], "entities": []}, {"text": "The reduced f -structures are then filtered by the generator to determine syntactic well-formedness.", "labels": [], "entities": []}, {"text": "A stochastic disambiguator using a maximum entropy model is trained on parsed and manually disambiguated f -structures for pairs of sentences and their condensations.", "labels": [], "entities": []}, {"text": "Using the disambiguator, the string generated from the most probable reduced f -structure produced by the transfer system is chosen.", "labels": [], "entities": []}, {"text": "In contrast to the approaches mentioned above, our system guarantees the grammaticality of generated strings through the use of a constraint-based generator for LFG which uses a slightly tighter version of the grammar than is used by the parser.", "labels": [], "entities": []}, {"text": "As shown in an experimental evaluation, summarization quality of our system is high, due to the combination of linguistically fine-grained analysis tools and expressive stochastic disambiguation models.", "labels": [], "entities": [{"text": "summarization", "start_pos": 40, "end_pos": 53, "type": "TASK", "confidence": 0.954287588596344}]}, {"text": "A second goal of our approach is to apply the standard evaluation methods for parsing to an automatic evaluation of summarization quality for sentence condensation systems.", "labels": [], "entities": [{"text": "summarization", "start_pos": 116, "end_pos": 129, "type": "TASK", "confidence": 0.9683191776275635}]}, {"text": "Instead of deploying costly and non-reusable human evaluation, or using automatic evaluation methods based on word error rate or n-gram match, summarization quality can be evaluated directly and automatically by matching the reduced f -structures that were produced by the system against manually selected f -structures that were produced by parsing a set of manually created condensations.", "labels": [], "entities": [{"text": "summarization", "start_pos": 143, "end_pos": 156, "type": "TASK", "confidence": 0.9681973457336426}]}, {"text": "Such an evaluation only requires human labor for the construction and manual structural disambiguation of a reusable gold standard test set.", "labels": [], "entities": []}, {"text": "Matching against the test set can be done automatically and rapidly, and is repeatable for development purposes and system comparison.", "labels": [], "entities": []}, {"text": "As shown in an experimental evaluation, a close correspondence can be established for rankings produced by the f -structure based automatic evaluation and a manual evaluation of generated strings.", "labels": [], "entities": []}], "datasetContent": [{"text": "Evaluation of quality of sentence condensation systems, and of text summarization and simplification systems in general, has mostly been conducted as intrinsic evaluation by human experts.", "labels": [], "entities": [{"text": "text summarization and simplification", "start_pos": 63, "end_pos": 100, "type": "TASK", "confidence": 0.7868491932749748}]}, {"text": "Recently, proposal for an automatic evaluation of translation systems by measuring n-gram matches of the system output against reference examples has become popular for evaluation of summarization systems.", "labels": [], "entities": [{"text": "summarization", "start_pos": 183, "end_pos": 196, "type": "TASK", "confidence": 0.9597284197807312}]}, {"text": "In addition, an automatic evaluation method based on context-free deletion decisions has been proposed by.", "labels": [], "entities": []}, {"text": "However, for summarization systems that employ a linguistic parser as an integral system component, it is possible to employ the standard evaluation techniques for parsing directly to an evaluation of summarization quality.", "labels": [], "entities": [{"text": "summarization", "start_pos": 13, "end_pos": 26, "type": "TASK", "confidence": 0.9798981547355652}]}, {"text": "A parsingbased evaluation allows us to measure the semantic aspects of summarization quality in terms of grammaticalfunctional information provided by deep parsers.", "labels": [], "entities": [{"text": "summarization", "start_pos": 71, "end_pos": 84, "type": "TASK", "confidence": 0.9678264856338501}]}, {"text": "Furthermore, human expertise was necessary only for the creation of condensed versions of sentences, and for the manual disambiguation of parses assigned to those sentences.", "labels": [], "entities": [{"text": "disambiguation of parses assigned", "start_pos": 120, "end_pos": 153, "type": "TASK", "confidence": 0.7403813451528549}]}, {"text": "Given such a gold standard, summarization quality of a system can be evaluated automatically and repeatedly by matching the structures of the system output against the gold standard structures.", "labels": [], "entities": []}, {"text": "The standard metrics of precision, recall, and F-score from statistical parsing can be used as evaluation metrics for measuring matching quality: Precision measures the number of matching structural items in the parses of the system output and the gold standard, out of all structural items in the system output's parse; recall measures the number of matches, out of all items in the gold standard's parse.", "labels": [], "entities": [{"text": "precision", "start_pos": 24, "end_pos": 33, "type": "METRIC", "confidence": 0.9993959665298462}, {"text": "recall", "start_pos": 35, "end_pos": 41, "type": "METRIC", "confidence": 0.9988172650337219}, {"text": "F-score", "start_pos": 47, "end_pos": 54, "type": "METRIC", "confidence": 0.998325765132904}, {"text": "statistical parsing", "start_pos": 60, "end_pos": 79, "type": "TASK", "confidence": 0.6145884543657303}, {"text": "Precision", "start_pos": 146, "end_pos": 155, "type": "METRIC", "confidence": 0.9684730768203735}, {"text": "recall", "start_pos": 321, "end_pos": 327, "type": "METRIC", "confidence": 0.9990445971488953}]}, {"text": "F-score balances precision and recall as (2 \u00d7 precision \u00d7 recall)/(precision + recall).", "labels": [], "entities": [{"text": "F-score", "start_pos": 0, "end_pos": 7, "type": "METRIC", "confidence": 0.9374637007713318}, {"text": "precision", "start_pos": 17, "end_pos": 26, "type": "METRIC", "confidence": 0.9982089996337891}, {"text": "recall", "start_pos": 31, "end_pos": 37, "type": "METRIC", "confidence": 0.9983397722244263}, {"text": "precision \u00d7 recall)/(precision + recall)", "start_pos": 46, "end_pos": 86, "type": "METRIC", "confidence": 0.7465151101350784}]}, {"text": "For the sentence condensation system presented above, the structural items to be matched consist of relation(predicate, argument) triples.", "labels": [], "entities": []}, {"text": "For example, the goldstandard f -structure of corresponds to 23 dependency relations, the first 14 of which are shared with the reduced f -structure chosen by the stochastic disambiguation system: tense(be:0, pres), mood(be:0, indicative), subj(be:0, prototype:2), xcomp(be:0, ready:1), stmt_type(be:0, declarative), vtype(be:0, copular), subj(ready:1, prototype:2), adegree(ready:1, positive), atype(ready:1, predicative), det(prototype:2, a:7), num(prototype:2, sg), pers(prototype:2, 3), det_form(a:7, a), det_type(a:7, indef), adjunct(be:0, for:12), obj(for: Matching these f -structures against each other corresponds to a precision of 1, recall of .61, and F-score of .76.", "labels": [], "entities": [{"text": "obj", "start_pos": 554, "end_pos": 557, "type": "METRIC", "confidence": 0.9751833081245422}, {"text": "precision", "start_pos": 628, "end_pos": 637, "type": "METRIC", "confidence": 0.994067907333374}, {"text": "recall", "start_pos": 644, "end_pos": 650, "type": "METRIC", "confidence": 0.9996800422668457}, {"text": "F-score", "start_pos": 663, "end_pos": 670, "type": "METRIC", "confidence": 0.999101996421814}]}, {"text": "The fact that our method does not rely on a comparison of the characteristics of surface strings is a clear advantage.", "labels": [], "entities": []}, {"text": "Such comparisons are bad at handling examples which are similar in meaning but differ in word order or vary structurally, such as in passivization or nominalization.", "labels": [], "entities": []}, {"text": "Our method handles such examples straightforwardly.", "labels": [], "entities": []}, {"text": "shows two serialization variants of the condensed sentence of.", "labels": [], "entities": []}, {"text": "The f -structures for these examples are similar to the f -structure assigned to the gold standard condensation shown in (except for the relations ADJUNT-TYPE:parenthetical versus ADV-TYPE:vpadv versus ADV-TYPE:sadv).", "labels": [], "entities": []}, {"text": "An evaluation of summarization quality that is based on matching f -structures will treat these examples equally, whereas an evaluation based on string matching will yield different quality scores for different serializations.", "labels": [], "entities": []}, {"text": "In the next section, we present experimental results of an automatic evaluation of the sentence condensation system described above.", "labels": [], "entities": []}, {"text": "These results show a close correspondence between automatically produced evaluation results and human judgments on the quality of generated condensed strings.", "labels": [], "entities": []}, {"text": "The sentences and condensations we used are taken from data for the experiments of, which were provided to us by Daniel Marcu.", "labels": [], "entities": []}, {"text": "These data consist of pairs of sentences and their condensed versions that have been extracted from computer-news articles and abstracts of the Ziff-Davis corpus.", "labels": [], "entities": []}, {"text": "Out of these data, we parsed and manually disambiguated 500 sentence pairs.", "labels": [], "entities": []}, {"text": "These included a set of 32 sentence pairs that were used for testing purposes in.", "labels": [], "entities": []}, {"text": "In order to control for the small corpus size of this test set, we randomly extracted an additional 32 sentence pairs from the 500 parsed and disambiguated examples as a second test set.", "labels": [], "entities": []}, {"text": "The rest of the 436 randomly selected sentence pairs were used to create training data.", "labels": [], "entities": []}, {"text": "For the purpose of discriminative training, a gold-standard of transferred f -structures was created from the transfer output and the manually selected f -structures for the condensed strings.", "labels": [], "entities": []}, {"text": "This was done automatically by selecting for each example the transferred f -structure that best matched the fstructure annotated for the condensed string.", "labels": [], "entities": []}, {"text": "In the automatic evaluation off -structure match, three different system variants were compared.", "labels": [], "entities": []}, {"text": "Firstly, randomly chosen transferred f -structures were matched against the manually selected f -structures for the manually created condensations.", "labels": [], "entities": []}, {"text": "This evaluation constitutes a lower bound on the F-score against the given gold standard.", "labels": [], "entities": [{"text": "F-score", "start_pos": 49, "end_pos": 56, "type": "METRIC", "confidence": 0.9994505047798157}]}, {"text": "Secondly, matching results for transferred fstructures yielding the maximal F-score against the gold standard were recorded, giving an upper bound for the system.", "labels": [], "entities": [{"text": "F-score", "start_pos": 76, "end_pos": 83, "type": "METRIC", "confidence": 0.9739007949829102}]}, {"text": "Thirdly, the performance of the stochastic model within the range of the lower bound and upper bound was measured by recording the F-score for the f -structure that received highest probability according to the learned distribution on transferred structures.", "labels": [], "entities": [{"text": "F-score", "start_pos": 131, "end_pos": 138, "type": "METRIC", "confidence": 0.9962891340255737}]}, {"text": "In order to make our results comparable to the results of and also to investigate the correspondence between the automatic evaluation and human judgments, a manual evaluation of the strings generated by these system variants was conducted.", "labels": [], "entities": []}, {"text": "Two human judges were presented with the uncondensed surface string and five condensed strings that were displayed in random order for each test example.", "labels": [], "entities": []}, {"text": "The five condensed strings presented to the human judges contained (1) strings generated from three randomly selected fstructures, (2) the strings generated from the f -structures which were selected by the stochastic model, and (3) the manually created gold-standard condensations extracted from the Ziff-Davis abstracts.", "labels": [], "entities": []}, {"text": "The judges were asked to judge summarization quality on a scale of increasing quality from 1 to 5 by assessing how well the generated strings retained the most salient information of the original uncondensed sentences.", "labels": [], "entities": [{"text": "summarization", "start_pos": 31, "end_pos": 44, "type": "TASK", "confidence": 0.9849833846092224}]}, {"text": "Grammaticality of the system output is optimal and not reported separately.", "labels": [], "entities": [{"text": "Grammaticality", "start_pos": 0, "end_pos": 14, "type": "METRIC", "confidence": 0.9774959087371826}]}, {"text": "Results for both evaluations are reported for two test corpora of 32 examples each.", "labels": [], "entities": []}, {"text": "Testset I contains the sentences and condensations used to evaluate the system described in.", "labels": [], "entities": []}, {"text": "Testset II consists of another randomly extracted 32 sentence pairs from the same domain, prepared in the same way.", "labels": [], "entities": []}, {"text": "shows evaluation results fora sentence condensation run that uses manually selected f -structures for the original sentences as input to the transfer component.", "labels": [], "entities": []}, {"text": "These results demonstrate how the condenstation system performs under the optimal circumstances when the parse chosen as input is the best available.", "labels": [], "entities": []}, {"text": "applies the same evaluation data and metrics to a sentence condensation experiment that performs transfer from packed fstructures, i.e. transfer is performed on all parses for an ambiguous sentence instead of on a single manually selected parse.", "labels": [], "entities": []}, {"text": "Alternatively, a single input parse could be selected by stochastic models such as the one described in.", "labels": [], "entities": []}, {"text": "A separate phase of parse disambiguation, and perhaps the effects of any errors that this might introduce, can be avoided by transferring from all parses for an ambiguous sentence.", "labels": [], "entities": [{"text": "parse disambiguation", "start_pos": 20, "end_pos": 40, "type": "TASK", "confidence": 0.8992179930210114}]}, {"text": "This approach is computationally feasible, however, only if condensation can be carried all the way through without unpacking.", "labels": [], "entities": []}, {"text": "Our technology is not yet able to do this (in particular, as mentioned earlier, we have not yet implemented a method for stochastic disambiguation on packed f -structures).", "labels": [], "entities": []}, {"text": "However, we conducted a preliminary assessment of this possibility by unpacking and enumerating the transferred fstructures.", "labels": [], "entities": []}, {"text": "For many sentences this resulted in more candidates than we could operate on in the available time and space, and in those cases we arbitrarily set a cut-off on the number of transferred f -structures we considered.", "labels": [], "entities": []}, {"text": "Since transferred f -structures are produced according to the number of rules applied to transfer them, in this setup the transfer system produces smaller f -structures first, and cuts off less condensed output.", "labels": [], "entities": []}, {"text": "The result of this experiment, shown in, thus provides a conservative estimate on the quality of the condensations we might achieve with a full-packing implementation.", "labels": [], "entities": []}, {"text": "In Figs. 5 and 6, the first row shows F-scores fora random selection, the system selection, and the best possible selection from the transfer output against the gold standard.", "labels": [], "entities": [{"text": "Figs. 5", "start_pos": 3, "end_pos": 10, "type": "DATASET", "confidence": 0.9355053305625916}, {"text": "F-scores", "start_pos": 38, "end_pos": 46, "type": "METRIC", "confidence": 0.9901785850524902}]}, {"text": "The second rows show summarization quality scores for generations from a random selection and the system selection, and for the human-written condensation.", "labels": [], "entities": []}, {"text": "52.7% 65.9% 56.8%: Sentence condensation from manually selected f -structure for original uncondensed sentences.", "labels": [], "entities": [{"text": "Sentence condensation", "start_pos": 19, "end_pos": 40, "type": "TASK", "confidence": 0.9757063090801239}]}, {"text": "be seen from these tables, the ranking of system variants produced by the automatic and manual evaluation confirm a close correlation between the automatic evaluation and human judgments.", "labels": [], "entities": []}, {"text": "A comparison of evaluation results across colums, i.e. across selection variants, shows that a stochastic selection of transferred f -structures is indeed important.", "labels": [], "entities": []}, {"text": "Even if all f -structures are transferred from the same linguistically rich source, and all generated strings are grammatical, a reduction in error rate of around 50% relative to the upper bound can be achieved by stochastic selection.", "labels": [], "entities": [{"text": "error rate", "start_pos": 142, "end_pos": 152, "type": "METRIC", "confidence": 0.9908015727996826}]}, {"text": "In contrast, a comparison between transfer runs with and without perfect disambiguation of the original string shows a decrease of about 5% in F-score, and of only .1 points for summarization quality when transferring from packed parses instead of from the manually selected parse.", "labels": [], "entities": [{"text": "F-score", "start_pos": 143, "end_pos": 150, "type": "METRIC", "confidence": 0.9940179586410522}, {"text": "summarization", "start_pos": 178, "end_pos": 191, "type": "TASK", "confidence": 0.9572155475616455}]}, {"text": "This shows that it is more important to learn what a good transferred f -structure looks like than to have a perfect f -structure to transfer from.", "labels": [], "entities": []}, {"text": "The compression rates associated with the systems that used stochastic selection is around 60%, which is acceptable, but not as aggressive as human-written condensations.", "labels": [], "entities": []}, {"text": "Note that in our current implementation, in some cases the transfer component was unable to operate on the packed representation.", "labels": [], "entities": []}, {"text": "In those cases a parse was chosen at random as a conservative estimate of transfer from all parses.", "labels": [], "entities": []}, {"text": "This fall-back mechanism explains the drop in F-score for the upper bound in comparing Figs. 5 and 6.", "labels": [], "entities": [{"text": "F-score", "start_pos": 46, "end_pos": 53, "type": "METRIC", "confidence": 0.9993082284927368}, {"text": "Figs. 5", "start_pos": 87, "end_pos": 94, "type": "DATASET", "confidence": 0.9138658046722412}]}], "tableCaptions": []}