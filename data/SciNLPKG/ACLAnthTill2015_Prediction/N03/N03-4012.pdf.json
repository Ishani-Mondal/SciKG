{"title": [{"text": "Automatic Extraction of Semantic Networks from Text using Leximancer", "labels": [], "entities": [{"text": "Automatic Extraction of Semantic Networks from Text", "start_pos": 0, "end_pos": 51, "type": "TASK", "confidence": 0.7963078532900129}]}], "abstractContent": [{"text": "Leximancer is a software system for performing conceptual analysis of text data in a largely language independent manner.", "labels": [], "entities": []}, {"text": "The system is modelled on Content Analysis and provides unsupervised and supervised analysis using seeded concept classifiers.", "labels": [], "entities": [{"text": "Content Analysis", "start_pos": 26, "end_pos": 42, "type": "TASK", "confidence": 0.6782170981168747}]}, {"text": "Unsupervised on-tology discovery is a key component.", "labels": [], "entities": [{"text": "Unsupervised on-tology discovery", "start_pos": 0, "end_pos": 32, "type": "TASK", "confidence": 0.6356563369433085}]}, {"text": "1 Method The strategy used for conceptual mapping of text involves abstracting families of words to thesaurus concepts.", "labels": [], "entities": [{"text": "conceptual mapping of text", "start_pos": 31, "end_pos": 57, "type": "TASK", "confidence": 0.7921898066997528}]}, {"text": "These concepts are then used to classify text at a resolution of several sentences.", "labels": [], "entities": []}, {"text": "The resulting concept tags are indexed to provide a document exploration environment for the user.", "labels": [], "entities": []}, {"text": "A smaller number of simple concepts can index many more complex relationships by recording co-occurrences, and complex systems approaches can be applied to these systems of agents.", "labels": [], "entities": []}, {"text": "To achieve this, several novel algorithms were developed: a learning optimiser for automatically selecting , learning, and adapting a concept from the word usage within the text, and an asymmetric scaling process for generating a cluster map of concepts based on co-occurrence in the text.", "labels": [], "entities": []}, {"text": "Extensive evaluation has been performed on real document collections in collaboration with domain experts.", "labels": [], "entities": []}, {"text": "The method adopted has been to perform parallel analyses with these experts and compare the results.", "labels": [], "entities": []}, {"text": "An outline of the algorithms (Smith, 2000) follows: 1.", "labels": [], "entities": []}, {"text": "Text preparation: Standard techniques are employed , including name and term preservation, to-kenisation, and the application of a stop-list.", "labels": [], "entities": [{"text": "Text preparation", "start_pos": 0, "end_pos": 16, "type": "TASK", "confidence": 0.7802998423576355}, {"text": "name and term preservation", "start_pos": 63, "end_pos": 89, "type": "TASK", "confidence": 0.7080058604478836}]}, {"text": "2. Unsupervised and supervised ontology discovery: Concepts can be seeded by a domain expert to suit user requirements, or they can be chosen automatically using a ranking algorithm for finding seed words which reflect the themes present in the data.", "labels": [], "entities": [{"text": "ontology discovery", "start_pos": 31, "end_pos": 49, "type": "TASK", "confidence": 0.680146798491478}]}, {"text": "This process looks for words near the centre of local maxima in the lexical co-occurrence network.", "labels": [], "entities": []}, {"text": "3. Filling the thesaurus: A machine learning algorithm is used to find the relevant thesaurus words from the text data.", "labels": [], "entities": []}, {"text": "This iterative optimiser, derived from a word disambiguation technique (Yarowsky, 1995), finds the nearest local maximum in the lexical co-occurrence network from each concept seed.", "labels": [], "entities": []}, {"text": "Early results show that this lexical network can be reduced to a Scale-free and Small-world network 1. 4. Classification: Text is tagged with multiple concepts using the thesaurus, to a sentence resolution.", "labels": [], "entities": [{"text": "sentence resolution", "start_pos": 186, "end_pos": 205, "type": "TASK", "confidence": 0.7046708911657333}]}, {"text": "5. Mapping: The concepts and their relative co-occurrence frequencies now form a semantic network.", "labels": [], "entities": [{"text": "Mapping", "start_pos": 3, "end_pos": 10, "type": "TASK", "confidence": 0.9759361147880554}]}, {"text": "This is scaled using an asymmetric scaling algorithm, and made into a lattice by ranking concepts by their connectedness, or centrality.", "labels": [], "entities": []}, {"text": "6. User interface: A browser is used for exploring the classification system in depth.", "labels": [], "entities": []}, {"text": "The semantic lattice browser enables semantic characterisation of the data and discovery of indirect association.", "labels": [], "entities": []}, {"text": "Concept co-occurrence spectra and themed text segment browsing are also provided.", "labels": [], "entities": []}], "introductionContent": [], "datasetContent": [], "tableCaptions": []}