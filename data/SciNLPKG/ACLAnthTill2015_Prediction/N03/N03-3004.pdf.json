{"title": [{"text": "Discriminating Among Word Senses Using McQuitty's Similarity Analysis", "labels": [], "entities": []}], "abstractContent": [{"text": "This paper presents an unsupervised method for discriminating among the senses of a given target word based on the context in which it occurs.", "labels": [], "entities": []}, {"text": "Instances of a word that occur in similar contexts are grouped together via McQuitty's Similarity Analysis, an agglomerative clustering algorithm.", "labels": [], "entities": []}, {"text": "The context in which a target word occurs is represented by surface lexical features such as unigrams, bigrams, and second order co-occurrences.", "labels": [], "entities": []}, {"text": "This paper summarizes our approach, and describes the results of a preliminary evaluation we have carried out using data from the SENSEVAL-2 English lexical sample and the line corpus.", "labels": [], "entities": [{"text": "SENSEVAL-2 English lexical sample", "start_pos": 130, "end_pos": 163, "type": "DATASET", "confidence": 0.6145543828606606}]}], "introductionContent": [{"text": "Word sense discrimination is the process of grouping or clustering together instances of written text that include similar usages of a given target word.", "labels": [], "entities": [{"text": "Word sense discrimination", "start_pos": 0, "end_pos": 25, "type": "TASK", "confidence": 0.7207528650760651}]}, {"text": "The instances that form a particular cluster will have used the target word in similar contexts and are therefore presumed to represent a related meaning.", "labels": [], "entities": []}, {"text": "This view follows from the strong contextual hypothesis of, which states that two words are semantically similar to the extent that their contextual representations are similar.", "labels": [], "entities": []}, {"text": "Discrimination is distinct from the more common problem of word sense disambiguation in at least two respects.", "labels": [], "entities": [{"text": "word sense disambiguation", "start_pos": 59, "end_pos": 84, "type": "TASK", "confidence": 0.7243527869383494}]}, {"text": "First, the number of possible senses a target word may have is usually not known in discrimination, while disambiguation is often viewed as a classification problem where a word is assigned to one of several preexisting possible senses.", "labels": [], "entities": [{"text": "disambiguation", "start_pos": 106, "end_pos": 120, "type": "TASK", "confidence": 0.9539014101028442}]}, {"text": "Second, discrimination utilizes features and information that can be easily extracted from raw corpora, whereas disambiguation often relies on supervised learning from sense-tagged training examples.", "labels": [], "entities": []}, {"text": "However, the creation of sense-tagged data is time consuming and results in a knowledge acquisition bottleneck that severely limits the portability and scalability of techniques that employ it.", "labels": [], "entities": []}, {"text": "Discrimination does not suffer from this problem since there is no expensive preprocessing, nor are any external knowledge sources or manually annotated data required.", "labels": [], "entities": []}, {"text": "The objective of this research is to extend previous work in discrimination by, who developed an approach using agglomerative clustering.", "labels": [], "entities": []}, {"text": "Their work relied on McQuitty's Similarity Analysis using localized contextual features.", "labels": [], "entities": [{"text": "Similarity Analysis", "start_pos": 32, "end_pos": 51, "type": "TASK", "confidence": 0.8709118366241455}]}, {"text": "While the approach in this paper also adopts McQuitty's method, it is distinct in that it uses a larger number of features that occur both locally and globally in the instance being discriminated.", "labels": [], "entities": []}, {"text": "It also incorporates several ideas from later work by, including the reliance on a separate \"training\" corpus of raw text from which to identify contextual features, and the use of second order cooccurrences (socs) as feature for discrimination.", "labels": [], "entities": []}, {"text": "Our near term objectives for this research include determining to what extent different types of features impact the accuracy of unsupervised discrimination.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 117, "end_pos": 125, "type": "METRIC", "confidence": 0.9972289204597473}]}, {"text": "We are also interested in assessing how different measures of similarity such as the matching coefficient or the cosine affect overall performance.", "labels": [], "entities": [{"text": "matching coefficient", "start_pos": 85, "end_pos": 105, "type": "METRIC", "confidence": 0.9536535739898682}]}, {"text": "Once we have refined our clustering techniques, we will incorporate them into a method that automatically assigns sense labels to discovered clusters by using information from a machine readable dictionary.", "labels": [], "entities": []}, {"text": "This paper continues with a more detailed discussion of the previous work that forms the foundation for our research.", "labels": [], "entities": []}, {"text": "We then present an overview of the features used to represent the context of a target word, and goon to describe an experimental evaluation using the SENSEVAL-2 lexical sample data.", "labels": [], "entities": [{"text": "SENSEVAL-2 lexical sample data", "start_pos": 150, "end_pos": 180, "type": "DATASET", "confidence": 0.7058971673250198}]}, {"text": "We close with a discussion of our results, a summary of related work, and an outline of our future directions.", "labels": [], "entities": []}], "datasetContent": [{"text": "We evaluate our method using two well known sources of sense-tagged text.", "labels": [], "entities": []}, {"text": "In supervised learning sense-tagged text is used to induce a classifier that is then applied to held out test data.", "labels": [], "entities": []}, {"text": "However, our approach is purely unsupervised and we only use the sense tags to carryout an automatic evaluation of the discovered clusters.", "labels": [], "entities": []}, {"text": "We follow Sch\u00fctze's strategy and use a \"training\" corpus only to extract features and ignore the sense tags.", "labels": [], "entities": []}, {"text": "In particular, we use subsets of the line data ( and the English lexical sample data from the SENSEVAL-2 comparative exercise among word sense disambiguation systems).", "labels": [], "entities": [{"text": "English lexical sample data", "start_pos": 57, "end_pos": 84, "type": "DATASET", "confidence": 0.6429181322455406}, {"text": "word sense disambiguation", "start_pos": 132, "end_pos": 157, "type": "TASK", "confidence": 0.6191126803557078}]}, {"text": "The line data contains 4,146 instances, where each consists of two to three sentences where a single occurrence of line has been manually tagged with one of six possible senses.", "labels": [], "entities": []}, {"text": "We randomly select 100 instances of each sense for test data, and 200 instances of each sense for training.", "labels": [], "entities": []}, {"text": "This gives a total of 600 evaluation instances, and 1200 training instances.", "labels": [], "entities": []}, {"text": "This is done to test the quality of our discrimination method when senses are uniformly distributed and where no particular sense is dominant.", "labels": [], "entities": []}, {"text": "The standard distribution of the SENSEVAL-2 data consists of 8,611 training instances and 4,328 test instances.", "labels": [], "entities": [{"text": "SENSEVAL-2 data", "start_pos": 33, "end_pos": 48, "type": "DATASET", "confidence": 0.7749083936214447}]}, {"text": "Each instance is made up of two to three sentences where a single target word has been manually tagged with a sense (or senses) appropriate for that context.", "labels": [], "entities": []}, {"text": "There are 73 distinct target words found in this data; 29 nouns, 29 verbs, and 15 adjectives.", "labels": [], "entities": []}, {"text": "Most of these words have less than 100 test instances, and approximately twice that number of training examples.", "labels": [], "entities": []}, {"text": "In general these are relatively small samples for an unsupervised approach, but we are developing techniques to increase the amount of training data for this corpus automatically.", "labels": [], "entities": []}, {"text": "We filter the SENSEVAL-2 data in three different ways to prepare it for processing and evaluation.", "labels": [], "entities": [{"text": "SENSEVAL-2 data", "start_pos": 14, "end_pos": 29, "type": "DATASET", "confidence": 0.7719191014766693}]}, {"text": "First, we insure that it only includes instances whose actual sense is among the top five most frequent senses as observed in the training data for that word.", "labels": [], "entities": []}, {"text": "We believe that this is an aggressive number of senses fora discrimination system to attempt, considering that) experimented with 2 and 3 senses, and) made binary distinctions.", "labels": [], "entities": []}, {"text": "Second, instances may have been assigned more than one correct sense by the human annotator.", "labels": [], "entities": []}, {"text": "In order to simplify the evaluation process, we eliminate all but the most frequent of multiple correct answers.", "labels": [], "entities": []}, {"text": "Third, the SENSEVAL-2 data identifies target words that are proper nouns.", "labels": [], "entities": [{"text": "SENSEVAL-2 data", "start_pos": 11, "end_pos": 26, "type": "DATASET", "confidence": 0.7571489214897156}]}, {"text": "We have elected not to use that information and have removed these P tags from the data.", "labels": [], "entities": []}, {"text": "After carrying out these preprocessing steps, the number of training and test instances is 7,476 and 3,733.", "labels": [], "entities": []}, {"text": "We specify an upper limit on the number of senses that McQuitty's algorithm can discover.", "labels": [], "entities": []}, {"text": "In these experiments this value is five for the SENSEVAL-2 data, and six for line.", "labels": [], "entities": [{"text": "SENSEVAL-2 data", "start_pos": 48, "end_pos": 63, "type": "DATASET", "confidence": 0.6704935431480408}]}, {"text": "In future experiments we will specify even higher values, so that the algorithm is forced to create larger number of clusters with very few instances when the actual number of senses is smaller than the given cutoff.", "labels": [], "entities": []}, {"text": "About a third of the words in the SENSEVAL-2 data have fewer than 5 senses, so even now the clustering algorithm is not always told the correct number of clusters it should find.", "labels": [], "entities": [{"text": "SENSEVAL-2 data", "start_pos": 34, "end_pos": 49, "type": "DATASET", "confidence": 0.7686174511909485}]}, {"text": "Once the clusters are formed, we access the actual correct sense of each instance as found in the sense-tagged text.", "labels": [], "entities": []}, {"text": "This information is never utilized prior to evaluation.", "labels": [], "entities": []}, {"text": "We use the sense-tagged text as a gold standard by which we can evaluate the discovered sense clusters.", "labels": [], "entities": []}, {"text": "We assign sense tags to clusters such that the resulting accuracy is maximized.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 57, "end_pos": 65, "type": "METRIC", "confidence": 0.9993094205856323}]}, {"text": "For example, suppose that five clusters (C1 -C5) have been discovered fora word with 100 instances, and that the number of instances in each cluster is 25, 20, 10, 25, and 20.", "labels": [], "entities": []}, {"text": "Suppose that there are five actual senses (S1 -S5), and the number of instances for each sense is, and 20.", "labels": [], "entities": []}, {"text": "shows the resulting confusion matrix if the senses are assigned to clusters in numeric order.", "labels": [], "entities": []}, {"text": "After this assignment is made, the accuracy of the clustering can be determined by finding the sum of the diagonal, and dividing by the total number of instances, which in this case leads to accuracy of 10% (10/100).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 35, "end_pos": 43, "type": "METRIC", "confidence": 0.9993876218795776}, {"text": "accuracy", "start_pos": 191, "end_pos": 199, "type": "METRIC", "confidence": 0.9993124008178711}]}, {"text": "However, clearly there are assignments of senses to clusters that would lead to better results.", "labels": [], "entities": []}, {"text": "Thus, the problem of assigning senses to clusters becomes one of reordering the columns of the confusion such that the diagonal sum is maximized.", "labels": [], "entities": []}, {"text": "This corresponds to several well known problems, among them the Assignment Problem in Operations Research, and determining the maximal matching of a bipartite graph.", "labels": [], "entities": [{"text": "Assignment", "start_pos": 64, "end_pos": 74, "type": "TASK", "confidence": 0.8942509889602661}, {"text": "Operations Research", "start_pos": 86, "end_pos": 105, "type": "TASK", "confidence": 0.8547168970108032}]}, {"text": "shows the maximally accurate assignment of senses to clusters, which leads to accuracy of 70% (70/100).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 78, "end_pos": 86, "type": "METRIC", "confidence": 0.9996227025985718}]}, {"text": "During evaluation we assign one cluster to at most one sense, and vice versa.", "labels": [], "entities": []}, {"text": "When the number of discovered clusters is the same as the number of senses, then there is a 1 to 1 mapping between them.", "labels": [], "entities": []}, {"text": "When the number of clusters is greater than the number of actual senses, then some clusters will be left unassigned.", "labels": [], "entities": []}, {"text": "And when the We determine the precision and recall based on this maximally accurate assignment of sense tags to clusters.", "labels": [], "entities": [{"text": "precision", "start_pos": 30, "end_pos": 39, "type": "METRIC", "confidence": 0.9995985627174377}, {"text": "recall", "start_pos": 44, "end_pos": 50, "type": "METRIC", "confidence": 0.9993409514427185}]}, {"text": "Precision is defined as the number of instances that are clustered correctly divided by the number of instances clustered, while recall is the number of instances clustered correctly over the total number of instances.", "labels": [], "entities": [{"text": "Precision", "start_pos": 0, "end_pos": 9, "type": "METRIC", "confidence": 0.9907446503639221}, {"text": "recall", "start_pos": 129, "end_pos": 135, "type": "METRIC", "confidence": 0.9993728995323181}]}, {"text": "To be clear, we do not believe that word sense discrimination must be carried out relative to a pre-existing set of senses.", "labels": [], "entities": [{"text": "word sense discrimination", "start_pos": 36, "end_pos": 61, "type": "TASK", "confidence": 0.7131097813447317}]}, {"text": "In fact, one of the great advantages of an unsupervised approach is that it need not be relative to any particular set of senses.", "labels": [], "entities": []}, {"text": "We carryout this evaluation technique in order to improve the performance of our clustering algorithm, which we will then apply on text where sense-tagged data is not available.", "labels": [], "entities": []}, {"text": "An alternative means of evaluation is to have a human inspect the discovered clusters and judge them based on the semantic coherence of the instances that populate each cluster, but this is a more time consuming and subjective method of evaluation that we will pursue in future.", "labels": [], "entities": []}, {"text": "For each word in the SENSEVAL-2 data and line, we conducted various experiments, each of which uses a different combination of measure of similarity and features.", "labels": [], "entities": [{"text": "SENSEVAL-2 data and line", "start_pos": 21, "end_pos": 45, "type": "DATASET", "confidence": 0.8727169781923294}]}, {"text": "Features are identified from the training data.", "labels": [], "entities": []}, {"text": "Our features consist of unigrams, bigrams, or second order cooccurrences.", "labels": [], "entities": []}, {"text": "We employ each of these three types of features separately, and we also create a mixed set that is the union of all three sets.", "labels": [], "entities": []}, {"text": "We convert each evaluation instance into a feature vector, and then convert those into a similarity matrix using either the matching coefficient or the cosine.", "labels": [], "entities": []}, {"text": "contains overall precision and recall for the nouns, verbs, and adjectives overall in the SENSEVAL-2 data, and for line.", "labels": [], "entities": [{"text": "precision", "start_pos": 17, "end_pos": 26, "type": "METRIC", "confidence": 0.9995205402374268}, {"text": "recall", "start_pos": 31, "end_pos": 37, "type": "METRIC", "confidence": 0.9991556406021118}, {"text": "SENSEVAL-2 data", "start_pos": 90, "end_pos": 105, "type": "DATASET", "confidence": 0.7132845222949982}]}, {"text": "The SENSEVAL-2 values are derived from 29 nouns, 28 verbs, and 15 adjectives from the SENSEVAL-2 data.", "labels": [], "entities": [{"text": "SENSEVAL-2 data", "start_pos": 86, "end_pos": 101, "type": "DATASET", "confidence": 0.7668681442737579}]}, {"text": "The first column lists the part of speech, the second shows the feature, the third lists the measure of similarity, the fourth and the fifth show precision and recall, the sixth shows the percentage of the majority sense, and the final column shows the number of words in the given part of speech that gave accuracy greater than the percentage of the majority sense.", "labels": [], "entities": [{"text": "precision", "start_pos": 146, "end_pos": 155, "type": "METRIC", "confidence": 0.9994675517082214}, {"text": "recall", "start_pos": 160, "end_pos": 166, "type": "METRIC", "confidence": 0.9988136291503906}, {"text": "accuracy", "start_pos": 307, "end_pos": 315, "type": "METRIC", "confidence": 0.9984525442123413}]}, {"text": "The value of the majority sense is derived from the sensetagged data we use in evaluation, but this is not information that we would presume to have available during actual clustering.", "labels": [], "entities": []}, {"text": "For the SENSEVAL-2 data, on average the precision and recall of the clustering as determined by our evaluation method is less than that of the majority sense, regardless of which features or measure are used.", "labels": [], "entities": [{"text": "SENSEVAL-2 data", "start_pos": 8, "end_pos": 23, "type": "DATASET", "confidence": 0.7957005500793457}, {"text": "precision", "start_pos": 40, "end_pos": 49, "type": "METRIC", "confidence": 0.9995118379592896}, {"text": "recall", "start_pos": 54, "end_pos": 60, "type": "METRIC", "confidence": 0.9989033937454224}]}, {"text": "However, for nouns and verbs, a relatively significant number of individual words have precision and recall values higher than that of the majority sense.", "labels": [], "entities": [{"text": "precision", "start_pos": 87, "end_pos": 96, "type": "METRIC", "confidence": 0.9991545677185059}, {"text": "recall", "start_pos": 101, "end_pos": 107, "type": "METRIC", "confidence": 0.9977957010269165}]}, {"text": "The adjectives are an exception to this, where words are very rarely disambiguated more accurately than the percentage of the majority sense.", "labels": [], "entities": []}, {"text": "However, many of the adjectives have very high frequency majority senses, which makes this a difficult standard for an unsupervised method to reach.", "labels": [], "entities": []}, {"text": "When examining the distribution of instances in clusters, we find that the algorithm tends to seek more balanced distributions, and is unlikely to create a single long cluster that would result in high accuracy fora word whose true distribution of senses is heavily skewed towards a single sense.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 202, "end_pos": 210, "type": "METRIC", "confidence": 0.9883937835693359}]}, {"text": "We also note that the precision and recall of the clustering of the line data is generally better than that of the majority sense regardless of the features or measures employed.", "labels": [], "entities": [{"text": "precision", "start_pos": 22, "end_pos": 31, "type": "METRIC", "confidence": 0.9995878338813782}, {"text": "recall", "start_pos": 36, "end_pos": 42, "type": "METRIC", "confidence": 0.9990915060043335}]}, {"text": "We believe there are two explanations for this.", "labels": [], "entities": []}, {"text": "First, the number of training instances for the line data is significantly higher (1200) than that of the SENSEVAL-2 words, which typically have 100-200 training instances per word.", "labels": [], "entities": []}, {"text": "The number and quality of features identified improves considerably with an increase in the amount of training data.", "labels": [], "entities": []}, {"text": "Thus, the amount of training data available for feature identification is critically important.", "labels": [], "entities": [{"text": "feature identification", "start_pos": 48, "end_pos": 70, "type": "TASK", "confidence": 0.8919638693332672}]}, {"text": "We believe that the SENSEVAL-2 data could be augmented with training data taken from the World Wide Web, and we plan to pursue such approaches and see if our performance on the evaluation data improves as a result.", "labels": [], "entities": [{"text": "SENSEVAL-2 data", "start_pos": 20, "end_pos": 35, "type": "DATASET", "confidence": 0.8285681307315826}]}, {"text": "At this point we do not observe a clear advantage to using the cosine measure or matching coefficient.", "labels": [], "entities": []}, {"text": "This surprises us somewhat, as the number of features employed is generally in the thousands, and the number of non-zero features can be quite large.", "labels": [], "entities": []}, {"text": "It would seem that simply counting the number of matching features would be inferior to the cosine measure, but this is not the case.", "labels": [], "entities": []}, {"text": "This remains an interesting issue that we will continue to explore, with these and other measures of similarity.", "labels": [], "entities": []}, {"text": "Finally, there is not a single feature that does best in all parts of speech.", "labels": [], "entities": []}, {"text": "Second order co-occurrences seem to do well with nouns and adjectives, while bigrams result in accurate clusters for verbs.", "labels": [], "entities": []}, {"text": "We also note that second order co-occurrences do well with the line data.", "labels": [], "entities": []}, {"text": "As yet we have drawn no conclusions from these results, but it is clearly a vital issue to investigate further.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Experimental Results  pos  feat meas prec rec  maj", "labels": [], "entities": []}]}