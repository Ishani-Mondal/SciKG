{"title": [{"text": "SPEECHALATOR: TWO-WAY SPEECH-TO-SPEECH TRANSLATION IN YOUR HAND", "labels": [], "entities": [{"text": "TWO-WAY SPEECH-TO-SPEECH TRANSLATION IN YOUR HAND", "start_pos": 14, "end_pos": 63, "type": "METRIC", "confidence": 0.7319321831067404}]}], "abstractContent": [{"text": "This demonstration involves two-way automatic speech-to-speech translation on a consumer off-the-shelf PDA.", "labels": [], "entities": [{"text": "speech-to-speech translation", "start_pos": 46, "end_pos": 74, "type": "TASK", "confidence": 0.6474638283252716}]}, {"text": "This work was done as part of the DARPA-funded Babylon project, investigating better speech-to-speech translation systems for communication in the field.", "labels": [], "entities": [{"text": "speech-to-speech translation", "start_pos": 85, "end_pos": 113, "type": "TASK", "confidence": 0.7259767055511475}]}, {"text": "The development of the Speecha-lator software-based translation system required addressing a number of hard issues, including anew language for the team (Egyptian Arabic), close integration on a small device, computational efficiency on a limited platform, and scalable coverage for the domain.", "labels": [], "entities": [{"text": "Speecha-lator software-based translation", "start_pos": 23, "end_pos": 63, "type": "TASK", "confidence": 0.623537520567576}]}, {"text": "1. BACKGROUND The Speechalator was developed in part as the next generation of automatic voice translation systems.", "labels": [], "entities": [{"text": "BACKGROUND", "start_pos": 3, "end_pos": 13, "type": "METRIC", "confidence": 0.7003384828567505}, {"text": "automatic voice translation", "start_pos": 79, "end_pos": 106, "type": "TASK", "confidence": 0.7312898834546407}]}, {"text": "The Phrasalator is a one-way device that can recognize a set of pre-defined phrases and play a recorded translation, [1].", "labels": [], "entities": []}, {"text": "This device can be ported easily to new languages, requiring only a hand translation of the phrases and a set of recorded sentences.", "labels": [], "entities": []}, {"text": "However, such a system severely limits communication as the translation is one way, thus reducing one party's responses to simple pointing and perhaps yes and no.", "labels": [], "entities": []}, {"text": "The Babylon project addresses the issues of two-way communication where either party can use the device for conversation.", "labels": [], "entities": []}, {"text": "A number of different groups throughout the US were asked to address specific aspects of the task, such as different languages, translation techniques and platform specifications.", "labels": [], "entities": [{"text": "translation", "start_pos": 128, "end_pos": 139, "type": "TASK", "confidence": 0.9666060209274292}]}, {"text": "The Pittsburgh group was presented with three challenges.", "labels": [], "entities": []}, {"text": "First, we were to work with Arabic, a language with which the group had little experience, to test our capabilities in moving to new languages quickly.", "labels": [], "entities": []}, {"text": "Second, we were instructed to use an interlingua approach to translation , where the source language is translated into an intermediate form that is shared between all languages.", "labels": [], "entities": [{"text": "translation", "start_pos": 61, "end_pos": 72, "type": "TASK", "confidence": 0.9690253138542175}]}, {"text": "This step streamlines expansion to new languages, and CMU has along history in working with interlingua based translation systems.", "labels": [], "entities": []}, {"text": "Third, we were constrained to one portable PDA-class device to host the entire two-way system: two recog-nizers, two translation engines, and two synthesizers.", "labels": [], "entities": []}, {"text": "2. RECOGNITION We used an HMM-based recognizer, developed by Multi-modal Technologies Inc, which has been specifically tuned for PDAs.", "labels": [], "entities": [{"text": "RECOGNITION", "start_pos": 3, "end_pos": 14, "type": "METRIC", "confidence": 0.962243378162384}]}, {"text": "The recognizer allows a grammar to be tightly coupled with the recognizer, which offers important effi-ciencies considering the limited computational power of the device.", "labels": [], "entities": []}, {"text": "With only minor modification we were able to generate our interlingua interchange format (IF) representation directly as output from the recognizer, removing one module from the process.", "labels": [], "entities": []}, {"text": "MTI's recognizer requires under 1M of memory with acoustic models of around 3M per language.", "labels": [], "entities": [{"text": "MTI", "start_pos": 0, "end_pos": 3, "type": "TASK", "confidence": 0.5417740941047668}]}, {"text": "Special optimizations deal with the slow processor and ensure low use of memory during decoding.", "labels": [], "entities": []}, {"text": "The Arabic models were bootstrapped from the GlobalPhone [2] Arabic collections as well as data collected as part of this project.", "labels": [], "entities": [{"text": "GlobalPhone [2] Arabic collections", "start_pos": 45, "end_pos": 79, "type": "DATASET", "confidence": 0.9279383222262064}]}, {"text": "3. TRANSLATION As part of this work we investigated two different techniques for translation, both interlingua based.", "labels": [], "entities": [{"text": "TRANSLATION", "start_pos": 3, "end_pos": 14, "type": "METRIC", "confidence": 0.8714975118637085}, {"text": "translation", "start_pos": 81, "end_pos": 92, "type": "TASK", "confidence": 0.977066695690155}]}, {"text": "The first was purely knowledge-based, following our previous work [3].", "labels": [], "entities": []}, {"text": "The engine developed for this was too large to run on the device, although we were able to run the generation part off-line seamlessly connected by a wireless link from the hand-held device.", "labels": [], "entities": []}, {"text": "The second technique we investigated used a statistical training method to build a model to translate structured interlingua IF to text in the target language.", "labels": [], "entities": []}, {"text": "Because this approach was developed with the handheld in mind, it is efficient enough to run directly on the device, and is used in this demo.", "labels": [], "entities": []}, {"text": "4. SYNTHESIS The synthesis engine is Cepstral's Theta system.", "labels": [], "entities": [{"text": "Theta", "start_pos": 48, "end_pos": 53, "type": "DATASET", "confidence": 0.8687941431999207}]}, {"text": "As the Speechalator runs on very small hardware devices (at least small compared to standard desktops), it was important that the synthesis footprint remained as small as possible.", "labels": [], "entities": []}, {"text": "The speechalator is to be used for people with little exposure to synthetic speech, and the output quality must be Edmonton,", "labels": [], "entities": []}], "introductionContent": [], "datasetContent": [], "tableCaptions": []}