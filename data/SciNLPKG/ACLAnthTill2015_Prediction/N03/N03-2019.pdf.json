{"title": [{"text": "Inferring Temporal Ordering of Events in News", "labels": [], "entities": [{"text": "Inferring Temporal Ordering of Events in News", "start_pos": 0, "end_pos": 45, "type": "TASK", "confidence": 0.8845696789877755}]}], "abstractContent": [{"text": "This paper describes a domain-independent, machine-learning based approach to temporally anchoring and ordering events in news.", "labels": [], "entities": [{"text": "temporally anchoring and ordering events in news", "start_pos": 78, "end_pos": 126, "type": "TASK", "confidence": 0.8419742499079023}]}, {"text": "The approach achieves 84.6% accuracy in temporally anchoring events and 75.4% accuracy in partially ordering them.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 28, "end_pos": 36, "type": "METRIC", "confidence": 0.9991462230682373}, {"text": "temporally anchoring events", "start_pos": 40, "end_pos": 67, "type": "TASK", "confidence": 0.7081485788027445}, {"text": "accuracy", "start_pos": 78, "end_pos": 86, "type": "METRIC", "confidence": 0.999122679233551}]}], "introductionContent": [{"text": "Practical NLP applications such as text summarization and question-answering place increasing demands on the processing of temporal information.", "labels": [], "entities": [{"text": "text summarization", "start_pos": 35, "end_pos": 53, "type": "TASK", "confidence": 0.7884970009326935}]}, {"text": "In multidocument summarization of news, it is important to know the relative order of events so as to correctly merge and present information.", "labels": [], "entities": [{"text": "multidocument summarization of news", "start_pos": 3, "end_pos": 38, "type": "TASK", "confidence": 0.8024443238973618}]}, {"text": "In question-answering, one would like to be able to ask when an event occurs, or what events occurred prior to a particular event.", "labels": [], "entities": []}, {"text": "Such capabilities presuppose an ability to infer the temporal order of events in discourse.", "labels": [], "entities": []}, {"text": "A number of different knowledge sources appear to be involved in inferring event ordering, including tense and aspect (1), temporal adverbials (2), and world knowledge (3).", "labels": [], "entities": []}, {"text": "(1) Max entered the room.", "labels": [], "entities": []}, {"text": "He had drunk/was drinking the wine.", "labels": [], "entities": []}, {"text": "(2) A drunken man died in the central Phillipines when he put a firecracker under his armpit.", "labels": [], "entities": [{"text": "Phillipines", "start_pos": 38, "end_pos": 49, "type": "DATASET", "confidence": 0.7731107473373413}]}, {"text": "N. Secretary-General Boutros Boutros-Ghali Sunday opened a meeting of ....Boutros-Ghali arrived in Nairobi from South Africa, \u2026 As (Bell 1999) has pointed out, the temporal structure of news is dictated by perceived news value rather than chronology.", "labels": [], "entities": []}, {"text": "Thus, the latest news is often presented first, instead of events being described in order of occurrence (the latter ordering is called the narrative convention).", "labels": [], "entities": []}, {"text": "This paper describes a domain-independent approach to temporally anchoring and ordering events in news.", "labels": [], "entities": [{"text": "temporally anchoring and ordering events in news", "start_pos": 54, "end_pos": 102, "type": "TASK", "confidence": 0.8514325448444912}]}, {"text": "The approach is motivated by a pilot experiment with 8 subjects providing news event-ordering judgments which revealed that the narrative convention applied only 47% of the time in ordering the events in successive past-tense clauses.", "labels": [], "entities": []}, {"text": "Our approach involves mixed-initiative corpus annotation, with automatic tagging to identify clause structure, tense, aspect, and temporal adverbials, as well as tagging of reference times and anchoring of events with respect to reference times.", "labels": [], "entities": []}, {"text": "We report on machine learning results from event-time anchoring judgments.", "labels": [], "entities": [{"text": "event-time anchoring judgments", "start_pos": 43, "end_pos": 73, "type": "TASK", "confidence": 0.7848141888777415}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Linguistic Features for each Clause 1,2", "labels": [], "entities": []}, {"text": " Table 3. #Correct-anchor is the number of the anchors  tuples correctly classified and #total is the total number  of anchors tuples classified. Link Recall is the percent- age of human generated links tuples (723 in all) that are  correctly identified by machine learned rules. Link Pre- cision is the percentage of the machine generated links  tuples that are correct.", "labels": [], "entities": [{"text": "Correct-anchor", "start_pos": 11, "end_pos": 25, "type": "METRIC", "confidence": 0.9696506857872009}, {"text": "Link Recall", "start_pos": 146, "end_pos": 157, "type": "METRIC", "confidence": 0.7240050435066223}, {"text": "Link Pre- cision", "start_pos": 280, "end_pos": 296, "type": "METRIC", "confidence": 0.7297596335411072}]}, {"text": " Table 3: Document-Level Accuracy  of Learnt Rules", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 25, "end_pos": 33, "type": "METRIC", "confidence": 0.9410800933837891}]}]}