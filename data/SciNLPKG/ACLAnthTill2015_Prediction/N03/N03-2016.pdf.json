{"title": [{"text": "Cognates Can Improve Statistical Translation Models", "labels": [], "entities": [{"text": "Improve Statistical Translation", "start_pos": 13, "end_pos": 44, "type": "TASK", "confidence": 0.8344634970029196}]}], "abstractContent": [{"text": "We report results of experiments aimed at improving the translation quality by incorporating the cognate information into translation models.", "labels": [], "entities": []}, {"text": "The results confirm that the cognate identification approach can improve the quality of word alignment in bitexts without the need for extra resources.", "labels": [], "entities": [{"text": "cognate identification", "start_pos": 29, "end_pos": 51, "type": "TASK", "confidence": 0.7883930802345276}, {"text": "word alignment", "start_pos": 88, "end_pos": 102, "type": "TASK", "confidence": 0.7068064957857132}]}], "introductionContent": [{"text": "In the context of machine translation, the term cognates denotes words in different languages that are similar in their orthographic or phonetic form and are possible translations of each other.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 18, "end_pos": 37, "type": "TASK", "confidence": 0.7841711938381195}]}, {"text": "The similarity is usually due either to a genetic relationship (e.g. English night and German nacht) or borrowing from one language to another (e.g. English sprint and Japanese supurinto).", "labels": [], "entities": []}, {"text": "Ina broad sense, cognates include not only genetically related words and borrowings but also names, numbers, and punctuation.", "labels": [], "entities": []}, {"text": "Practically all bitexts (bilingual parallel corpora) contain some kind of cognates.", "labels": [], "entities": []}, {"text": "If the languages are represented in different scripts, a phonetic transcription or transliteration of one or both parts of the bitext is a pre-requisite for identifying cognates.", "labels": [], "entities": []}, {"text": "Cognates have been employed fora number of bitextrelated tasks, including sentence alignment (, inducing translation lexicons (), and improving statistical machine translation models).", "labels": [], "entities": [{"text": "sentence alignment", "start_pos": 74, "end_pos": 92, "type": "TASK", "confidence": 0.79212886095047}, {"text": "statistical machine translation", "start_pos": 144, "end_pos": 175, "type": "TASK", "confidence": 0.6162660121917725}]}, {"text": "Cognates are particularly useful when machine-readable bilingual dictionaries are not available.", "labels": [], "entities": []}, {"text": "experimented with using bilingual dictionaries and cognates in the training of Czech-English translation models.", "labels": [], "entities": [{"text": "Czech-English translation", "start_pos": 79, "end_pos": 104, "type": "TASK", "confidence": 0.5745900422334671}]}, {"text": "They found that appending probable cognates to the training bitext significantly lowered the perplexity score on the test bitext (in some cases more than when using a bilingual dictionary), and observed improvement in word alignments of test sentences.", "labels": [], "entities": []}, {"text": "In this paper, we investigate the problem of incorporating the potentially valuable cognate information into the translation models of, which, in their original formulation, consider lexical items in abstraction of their form.", "labels": [], "entities": []}, {"text": "For training of the models, we use the GIZA program.", "labels": [], "entities": [{"text": "GIZA program", "start_pos": 39, "end_pos": 51, "type": "DATASET", "confidence": 0.755917102098465}]}, {"text": "A list of likely cognate pairs is extracted from the training corpus on the basis of orthographic similarity, and appended to the corpus itself.", "labels": [], "entities": []}, {"text": "The objective is to reinforce the coocurrence count between cognates in addition to already existing co-ocurrences.", "labels": [], "entities": []}, {"text": "The results of experiments conducted on a variety of bitexts show that cognate identification can improve word alignments, which leads to better translation models, and, consequently, translations of higher quality.", "labels": [], "entities": [{"text": "cognate identification", "start_pos": 71, "end_pos": 93, "type": "TASK", "confidence": 0.8113112151622772}, {"text": "word alignments", "start_pos": 106, "end_pos": 121, "type": "TASK", "confidence": 0.7512351870536804}]}, {"text": "The improvement is achieved without modifying the statistical training algorithm.", "labels": [], "entities": []}], "datasetContent": [{"text": "We induced translation models using IBM Model 4 () with the GIZA toolkit ().", "labels": [], "entities": []}, {"text": "The maximum sentence length in the training data was set at 30 words.", "labels": [], "entities": []}, {"text": "The actual translations were produced with a greedy decoder ().", "labels": [], "entities": []}, {"text": "For the evaluation of translation quality, we used the BLEU metric (), which measures the n-gram overlap between the translated output and one or more reference translations.", "labels": [], "entities": [{"text": "BLEU metric", "start_pos": 55, "end_pos": 66, "type": "METRIC", "confidence": 0.9783704578876495}]}, {"text": "In our experiments, we used only one reference translation.", "labels": [], "entities": []}, {"text": "In order to confirm that the higher BLEU scores reflect higher translation quality, we performed a manual evaluation of a set of a hundred six-token sentences.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 36, "end_pos": 40, "type": "METRIC", "confidence": 0.9980255365371704}]}, {"text": "The models were induced on a 25,000 sentences portion of Hansards.", "labels": [], "entities": [{"text": "Hansards", "start_pos": 57, "end_pos": 65, "type": "DATASET", "confidence": 0.7420065402984619}]}, {"text": "The training set was augmented with two copies of a cognate list obtained by thresholding LCSR at 0.56.", "labels": [], "entities": [{"text": "LCSR", "start_pos": 90, "end_pos": 94, "type": "METRIC", "confidence": 0.8123199343681335}]}, {"text": "Results ple pairs per sentence are added.", "labels": [], "entities": []}, {"text": "3 Statistical significance was estimated in the following way.", "labels": [], "entities": [{"text": "Statistical significance", "start_pos": 2, "end_pos": 26, "type": "METRIC", "confidence": 0.7780375480651855}]}, {"text": "The variance of the BLEU score was approximated by randomly picking a sample of translated sentences from the test set.", "labels": [], "entities": [{"text": "variance", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.9615861177444458}, {"text": "BLEU score", "start_pos": 20, "end_pos": 30, "type": "METRIC", "confidence": 0.9683341085910797}]}, {"text": "The size of the test sample was equal to the size of the test set (1755 sentences).", "labels": [], "entities": []}, {"text": "The score was computed in this way 200 times for each language.", "labels": [], "entities": []}, {"text": "The mean and the variance of the nine-language average was computed by randomly picking one of the 200 scores for each language and computing the average.", "labels": [], "entities": []}, {"text": "The mean result produced was 0.2025, which is very close to the baseline average score of 0.2027.", "labels": [], "entities": [{"text": "mean", "start_pos": 4, "end_pos": 8, "type": "METRIC", "confidence": 0.9756017327308655}, {"text": "baseline average score", "start_pos": 64, "end_pos": 86, "type": "METRIC", "confidence": 0.7946732441584269}]}, {"text": "The standard deviation of the average was estimated to be 0.0018, which implies that averages above 0.2054 are statistically significant at the 0.95 level.", "labels": [], "entities": []}, {"text": "Baseline: A manual evaluation of the translations generated by the baseline and the cognate-augmented models. of a manual evaluation of the entire set of 100 sentences are shown in.", "labels": [], "entities": []}, {"text": "Although the overall translation quality is low due to the small size of the training corpus and the lack of parameter tuning, the number of completely acceptable translations is higher when cognates are added.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: The number of extracted word pairs as a func- tion of the LCSR threshold, and the corresponding BLEU  scores, averaged over nine Europarl bitexts.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 106, "end_pos": 110, "type": "METRIC", "confidence": 0.9989680051803589}, {"text": "Europarl bitexts", "start_pos": 139, "end_pos": 155, "type": "DATASET", "confidence": 0.7785930931568146}]}, {"text": " Table 2: A manual evaluation of the translations gener- ated by the baseline and the cognate-augmented models.", "labels": [], "entities": []}, {"text": " Table 2. Although the overall translation  quality is low due to the small size of the training corpus  and the lack of parameter tuning, the number of com- pletely acceptable translations is higher when cognates  are added.", "labels": [], "entities": []}]}