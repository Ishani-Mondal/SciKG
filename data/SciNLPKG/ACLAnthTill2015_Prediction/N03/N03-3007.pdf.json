{"title": [{"text": "Word Fragment Identification Using Acoustic-Prosodic Features in Conversational Speech", "labels": [], "entities": [{"text": "Word Fragment Identification", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.7911665638287863}]}], "abstractContent": [{"text": "Word fragments pose serious problems for speech recognizers.", "labels": [], "entities": [{"text": "speech recognizers", "start_pos": 41, "end_pos": 59, "type": "TASK", "confidence": 0.7116444110870361}]}, {"text": "Accurate identification of word fragments will not only improve recognition accuracy, but also be very helpful for dis-fluency detection algorithm because the occurrence of word fragments is a good indicator of speech disfluencies.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 76, "end_pos": 84, "type": "METRIC", "confidence": 0.9768519997596741}, {"text": "dis-fluency detection", "start_pos": 115, "end_pos": 136, "type": "TASK", "confidence": 0.8970037400722504}]}, {"text": "Different from the previous effort of including word fragments in the acoustic model, in this paper, we investigate the problem of word fragment identification from another approach, i.e. building classifiers using acoustic-prosodic features.", "labels": [], "entities": [{"text": "word fragment identification", "start_pos": 131, "end_pos": 159, "type": "TASK", "confidence": 0.6642075876394907}]}, {"text": "Our experiments show that, by combining a few voice quality measures and prosodic features extracted from the forced alignments with the human transcriptions , we obtain a precision rate of 74.3% and a recall rate of 70.1% on the downsampled data of spontaneous speech.", "labels": [], "entities": [{"text": "precision rate", "start_pos": 172, "end_pos": 186, "type": "METRIC", "confidence": 0.9891509413719177}, {"text": "recall rate", "start_pos": 202, "end_pos": 213, "type": "METRIC", "confidence": 0.9848313629627228}]}, {"text": "The overall accuracy is 72.9%, which is significantly better than chance performance of 50%.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 12, "end_pos": 20, "type": "METRIC", "confidence": 0.999800980091095}, {"text": "chance", "start_pos": 66, "end_pos": 72, "type": "METRIC", "confidence": 0.98099285364151}]}], "introductionContent": [{"text": "Word fragments 1 occur frequently in spontaneous speech, and are good indicators for speech disfluencies.", "labels": [], "entities": []}, {"text": "When expressed as a percentage of the disfluencies that contain a word fragment, Levelt found 22% fora pattern description task in Dutch; Lickley reported 36% for casual conversations in British English; Bear et al. found 60% for the ATIS corpus (.", "labels": [], "entities": [{"text": "ATIS corpus", "start_pos": 234, "end_pos": 245, "type": "DATASET", "confidence": 0.9696523547172546}]}, {"text": "We examined 83 conversations of Switchboard corpus and found that about 17% of the disfluencies contain word fragments.", "labels": [], "entities": [{"text": "Switchboard corpus", "start_pos": 32, "end_pos": 50, "type": "DATASET", "confidence": 0.8942955136299133}]}, {"text": "However, accurate identification of word fragments is still an unsolved problem in speech community.", "labels": [], "entities": [{"text": "accurate identification of word fragments", "start_pos": 9, "end_pos": 50, "type": "TASK", "confidence": 0.7205391108989716}]}, {"text": "In most cases, they are simply treated as Out-of-Vocabulary words or are often incorrectly recognized as words in the vocabulary.", "labels": [], "entities": []}, {"text": "This not only affects the neighboring words, causing an increase in word error rate, but also fails to provide the important information that a word fragment is detected thus increasing the probability of a disfluency.", "labels": [], "entities": [{"text": "word error rate", "start_pos": 68, "end_pos": 83, "type": "METRIC", "confidence": 0.7553821802139282}]}, {"text": "The following is an example of the human transcription and the speech recognition output 2 from the Switchboard corpus (): Human transcription: and it's all just you know i've just eating more sort of eat to my apper-appetite", "labels": [], "entities": [{"text": "Switchboard corpus", "start_pos": 100, "end_pos": 118, "type": "DATASET", "confidence": 0.9177915453910828}]}], "datasetContent": [{"text": "Our goal is to investigate whether there are some reliable acoustic-prosodic features for word fragments.", "labels": [], "entities": []}, {"text": "The task of word fragment identification is viewed as a statistical classification problem, i.e. for each word boundary, a classifier determines whether the word before the boundary is a word fragment or not.", "labels": [], "entities": [{"text": "word fragment identification", "start_pos": 12, "end_pos": 40, "type": "TASK", "confidence": 0.6669436991214752}, {"text": "statistical classification", "start_pos": 56, "end_pos": 82, "type": "TASK", "confidence": 0.7101702690124512}]}, {"text": "For such a classification task, we develop an inventory of input features for the statistical classifier.", "labels": [], "entities": []}, {"text": "A CART decision tree classifier is employed to enable easy interpretation of results.", "labels": [], "entities": [{"text": "CART decision tree classifier", "start_pos": 2, "end_pos": 31, "type": "TASK", "confidence": 0.7890849411487579}]}, {"text": "Missing features are allowed in the decision trees.", "labels": [], "entities": []}, {"text": "To avoid globally suboptimal feature combinations in decision trees, we used a feature selection algorithm to search for an optimal subset of input features ().", "labels": [], "entities": []}, {"text": "We used conversational telephone speech Switchboard corpus ( for our experiments.", "labels": [], "entities": [{"text": "Switchboard corpus", "start_pos": 40, "end_pos": 58, "type": "DATASET", "confidence": 0.6310235112905502}]}, {"text": "In the human transcriptions, word fragments are identified (around 0.7% of the words are word fragments).", "labels": [], "entities": []}, {"text": "We use 80% of the data as the training data, and the left 20% for testing.", "labels": [], "entities": []}, {"text": "In order to avoid the bias toward the complete words (which are much more frequent than word fragments), we downsampled the training data so that we have an equal amount number of word fragments and complete words.", "labels": [], "entities": []}, {"text": "Downsampling makes the decision tree model more sensitive to the inherent features of the minority class.", "labels": [], "entities": []}, {"text": "We generated forced alignments using the provided human transcriptions, and derived the prosodic and voice quality features from the resulting phone-level alignments and the speech signal.", "labels": [], "entities": []}, {"text": "The reason that we used human transcriptions is because the current recognition accuracy on such telephone speech is around 70%, which will probably yield inaccurate time marks for the word hypotheses, and thus affect the feature extraction results and also make the evaluation difficult (e.g. determine which word hypothesis should be a word fragment).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 80, "end_pos": 88, "type": "METRIC", "confidence": 0.9082785248756409}, {"text": "feature extraction", "start_pos": 222, "end_pos": 240, "type": "TASK", "confidence": 0.6982738226652145}]}, {"text": "Even if the human transcription and the forced alignment are used to obtain the word and phone level alignments, the alignments could still be error-prone because the recognizer used for obtaining the alignments does not have a model for the word fragments.", "labels": [], "entities": []}, {"text": "Note that we only used transcriptions to get the word and phone level alignments for computing prosodic and voice quality features.", "labels": [], "entities": []}, {"text": "We did not use any word identity information in the features for the classification task.", "labels": [], "entities": [{"text": "classification task", "start_pos": 69, "end_pos": 88, "type": "TASK", "confidence": 0.9231436550617218}]}, {"text": "At each boundary location, we extracted prosodic features and voice quality measures as described in Section 2.", "labels": [], "entities": []}, {"text": "We trained a decision tree classifier from the downsampled training set that contains 1438 samples, and tested it on the downsampled test set with 288 samples (50% of the samples in the training and test set are word fragments).", "labels": [], "entities": []}, {"text": "In the results for word fragments vs. complete words classification are shown.", "labels": [], "entities": [{"text": "complete words classification", "start_pos": 38, "end_pos": 67, "type": "TASK", "confidence": 0.6319019099076589}]}, {"text": "The precision and recall for this fragment detection task are 74.3% and 70.1% respectively.", "labels": [], "entities": [{"text": "precision", "start_pos": 4, "end_pos": 13, "type": "METRIC", "confidence": 0.9998255372047424}, {"text": "recall", "start_pos": 18, "end_pos": 24, "type": "METRIC", "confidence": 0.9998111128807068}, {"text": "fragment detection task", "start_pos": 34, "end_pos": 57, "type": "TASK", "confidence": 0.8738741079966227}]}, {"text": "The overall accuracy for all the test samples is 72.9%, which is significantly better than a chance performance of 50%.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 12, "end_pos": 20, "type": "METRIC", "confidence": 0.9997401833534241}]}, {"text": "These results suggest some acousticprosodic features are indicative for word fragment detection.", "labels": [], "entities": [{"text": "word fragment detection", "start_pos": 72, "end_pos": 95, "type": "TASK", "confidence": 0.8229702711105347}]}, {"text": "shows the pruned decision tree for this task.", "labels": [], "entities": []}, {"text": "An inspection of the decision tree's feature usage in the results can further reveal the potential properties that distinguish word fragments from complete words.", "labels": [], "entities": []}, {"text": "In we report the feature usage as the percentage of decisions that have queried the feature type.", "labels": [], "entities": []}, {"text": "Features that are used higher up in the decision tree have higher usage values.", "labels": [], "entities": []}, {"text": "All these questions imply abnormal voice quality.", "labels": [], "entities": []}, {"text": "We have also conducted the same classification experiments by only using jitter and average OQ two features, and we obtained a classification accuracy of 68.06%.", "labels": [], "entities": [{"text": "jitter", "start_pos": 73, "end_pos": 79, "type": "METRIC", "confidence": 0.8799378871917725}, {"text": "OQ", "start_pos": 92, "end_pos": 94, "type": "METRIC", "confidence": 0.9483036994934082}, {"text": "classification", "start_pos": 127, "end_pos": 141, "type": "TASK", "confidence": 0.8359349370002747}, {"text": "accuracy", "start_pos": 142, "end_pos": 150, "type": "METRIC", "confidence": 0.8806648254394531}]}, {"text": "We also observe from the table that one energy feature and one F0 feature are queried frequently.", "labels": [], "entities": []}, {"text": "However, we may need to be careful of interpreting these prosodic features, because some word fragments are more likely to have a missing (or undefined) value for the stylized F0 or energy features (due to the short duration of the word fragments and the unvoiced frames).", "labels": [], "entities": [{"text": "F0", "start_pos": 176, "end_pos": 178, "type": "METRIC", "confidence": 0.9363299608230591}]}, {"text": "For example, in one leaf of the decision tree, word fragment is hypothesized if the energy slope before the boundary is an undefined value (as shown in, the question is 'EN-ERGY PATTERN BOUNDARY in Xr, Xf?', where 'X' means undefined value).", "labels": [], "entities": [{"text": "EN-ERGY PATTERN BOUNDARY", "start_pos": 170, "end_pos": 194, "type": "METRIC", "confidence": 0.6943457623322805}]}, {"text": "Notice that the usage of the pause feature is very low, although a pause is expected after a sudden closure of the speaker.", "labels": [], "entities": []}, {"text": "One reason for this is that the recognizer is more likely not to generate a pause in the phonetic alignment results when the pause after the mid-word interruption is very short.", "labels": [], "entities": []}, {"text": "For example, around 2/3 of the word fragments in our training and test set are not followed by a pause based on the alignments.", "labels": [], "entities": []}, {"text": "Additionally, there are many other places (e.g. sentence boundaries or filled pauses) that are possible to be followed by a pause, therefore being followed by a pause cannot accurately distinguish between a word fragment and other complete words.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: The word fragment detection results on the  downsampled data of Switchboard corpus.", "labels": [], "entities": [{"text": "word fragment detection", "start_pos": 14, "end_pos": 37, "type": "TASK", "confidence": 0.7978410720825195}, {"text": "Switchboard corpus", "start_pos": 74, "end_pos": 92, "type": "DATASET", "confidence": 0.9211169481277466}]}, {"text": " Table 2: The feature usage for the word fragment detec- tion using the Switchboard data.", "labels": [], "entities": [{"text": "Switchboard data", "start_pos": 72, "end_pos": 88, "type": "DATASET", "confidence": 0.907233715057373}]}]}