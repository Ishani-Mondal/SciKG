{"title": [], "abstractContent": [{"text": "Automatic restoration of punctuation from un-punctuated text has application in improving the fluency and applicability of speech recognition systems.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 123, "end_pos": 141, "type": "TASK", "confidence": 0.7094196826219559}]}, {"text": "We explore the possibility that syntactic information can be used to improve the performance of an HMM-based system for restoring punctuation (specifically, commas) in text.", "labels": [], "entities": []}, {"text": "Our best methods reduce sentence error rate substantially-by some 20%, with an additional 8% reduction possible given improvements in extraction of the requisite syntactic information.", "labels": [], "entities": [{"text": "error rate", "start_pos": 33, "end_pos": 43, "type": "METRIC", "confidence": 0.8765714764595032}]}, {"text": "1 Motivation The move from isolated word to connected speech recognition engendered a qualitative improvement in the naturalness of users' interactions with speech transcription systems, sufficient even to makeup in user satisfaction for some modest increase in error rate.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 54, "end_pos": 72, "type": "TASK", "confidence": 0.7926710546016693}, {"text": "error rate", "start_pos": 262, "end_pos": 272, "type": "METRIC", "confidence": 0.9499685764312744}]}, {"text": "Nonetheless, such systems still retain an important source of unnaturalness in dictation, the requirement to utter all punctuation explicitly.", "labels": [], "entities": []}, {"text": "In order to free the user from this burden, a transcription system would have to reconstruct the punctuation from the word sequence.", "labels": [], "entities": []}, {"text": "For certain applications-for instance, transcription of naturally occurring speech not originally targeted to a speech recognizer (as broadcast audio)-there is no alternative to performing reconstruction of punctuation.", "labels": [], "entities": [{"text": "transcription of naturally occurring speech not originally targeted to a speech recognizer", "start_pos": 39, "end_pos": 129, "type": "TASK", "confidence": 0.7726308703422546}, {"text": "reconstruction of punctuation", "start_pos": 189, "end_pos": 218, "type": "TASK", "confidence": 0.8390592535336813}]}, {"text": "Reconstruction of different punctuation marks is likely to respond to different techniques.", "labels": [], "entities": []}, {"text": "Reconstruction of periods , question marks, and exclamation marks, for instance , is in large part the problem of sentence boundary detection.", "labels": [], "entities": [{"text": "Reconstruction of periods", "start_pos": 0, "end_pos": 25, "type": "TASK", "confidence": 0.8475857575734457}, {"text": "sentence boundary detection", "start_pos": 114, "end_pos": 141, "type": "TASK", "confidence": 0.7372839053471884}]}, {"text": "In this paper, we address the problem of comma restoration.", "labels": [], "entities": [{"text": "comma restoration", "start_pos": 41, "end_pos": 58, "type": "TASK", "confidence": 0.8229069113731384}]}, {"text": "The published literature on intrasen-tence punctuation restoration is quite limited, the state of the art represented by Beeferman, Berger, and Lafferty's CYBERPUNC system, which we review in Section 2, and reimplement as a baseline for our own experiments.", "labels": [], "entities": [{"text": "intrasen-tence punctuation restoration", "start_pos": 28, "end_pos": 66, "type": "TASK", "confidence": 0.7984260519345602}]}, {"text": "(See Section 5 for discussion of related work.)", "labels": [], "entities": []}, {"text": "The CYBERPUNC system uses a simple HMM with tri-gram probabilities to model the comma restoration problem.", "labels": [], "entities": [{"text": "CYBERPUNC", "start_pos": 4, "end_pos": 13, "type": "DATASET", "confidence": 0.8659010529518127}, {"text": "comma restoration", "start_pos": 80, "end_pos": 97, "type": "TASK", "confidence": 0.7902595698833466}]}, {"text": "It is trained on fully punctuated text, and then tested for precision and recall in reconstructing commas in text that has had them removed.", "labels": [], "entities": [{"text": "precision", "start_pos": 60, "end_pos": 69, "type": "METRIC", "confidence": 0.9996174573898315}, {"text": "recall", "start_pos": 74, "end_pos": 80, "type": "METRIC", "confidence": 0.9994531273841858}]}, {"text": "Our replication of the trigram-based method yields a sentence accuracy of 47%.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 62, "end_pos": 70, "type": "METRIC", "confidence": 0.9749325513839722}]}, {"text": "However, the role of the comma in text is closely related to syntactic constituency.", "labels": [], "entities": [{"text": "syntactic constituency", "start_pos": 61, "end_pos": 83, "type": "TASK", "confidence": 0.7898037433624268}]}, {"text": "Nunberg (1990) describes two main classes of comma: the delimiter comma, which is used to mark off a constituent, and the sepa-rator comma, which is inserted between conjoined elements with or without a conjunction.", "labels": [], "entities": []}, {"text": "In both cases, one expects to see commas at the beginning or end of constituents , rather than in the middle.", "labels": [], "entities": []}, {"text": "But this type of correlation is difficult to model with a flat model such as an HMM.", "labels": [], "entities": []}, {"text": "For this reason, we explore here the use of syntactic constituency information for the purpose of comma restoration.", "labels": [], "entities": [{"text": "comma restoration", "start_pos": 98, "end_pos": 115, "type": "TASK", "confidence": 0.8632301688194275}]}, {"text": "We show that even very rarefied amounts of syntactic information can dramatically improve comma restoration performance; our best method accurately restores 58% of sentences.", "labels": [], "entities": [{"text": "comma restoration", "start_pos": 90, "end_pos": 107, "type": "TASK", "confidence": 0.895274817943573}]}, {"text": "Furthermore, even approximate syntactic information provides significant improvement.", "labels": [], "entities": []}, {"text": "There is, of course, great variation inappropriate punctuation of a single word stream.", "labels": [], "entities": []}, {"text": "1 For this reason, independent human annotators consider only about 86% of the sentences in the test set to be correct with respect to comma placement (Beeferman et al., 1998).", "labels": [], "entities": []}, {"text": "Thus, a move from 47% to 58% is a quite substantial improvement , essentially a reduction in sentence error rate of some 30%.", "labels": [], "entities": [{"text": "sentence error rate", "start_pos": 93, "end_pos": 112, "type": "METRIC", "confidence": 0.7148255705833435}]}], "introductionContent": [], "datasetContent": [], "tableCaptions": [{"text": " Table 1.) This is the baseline against which  we evaluate our alternative comma restoration models.", "labels": [], "entities": [{"text": "comma restoration", "start_pos": 75, "end_pos": 92, "type": "TASK", "confidence": 0.711274653673172}]}, {"text": " Table 1: Performance of the various comma restoration models described in this paper.", "labels": [], "entities": [{"text": "comma restoration", "start_pos": 37, "end_pos": 54, "type": "TASK", "confidence": 0.8139408826828003}]}]}