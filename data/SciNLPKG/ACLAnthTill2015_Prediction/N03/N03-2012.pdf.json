{"title": [{"text": "DETECTION OF AGREEMENT vs. DISAGREEMENT IN MEETINGS: TRAINING WITH UNLABELED DATA", "labels": [], "entities": [{"text": "DETECTION", "start_pos": 0, "end_pos": 9, "type": "METRIC", "confidence": 0.8235569596290588}, {"text": "AGREEMENT", "start_pos": 13, "end_pos": 22, "type": "METRIC", "confidence": 0.8163834810256958}, {"text": "DISAGREEMENT IN MEETINGS", "start_pos": 27, "end_pos": 51, "type": "METRIC", "confidence": 0.644352654616038}, {"text": "TRAINING WITH UNLABELED DATA", "start_pos": 53, "end_pos": 81, "type": "METRIC", "confidence": 0.7878695279359818}]}], "abstractContent": [{"text": "To support summarization of automatically transcribed meetings, we introduce a classifier to recognize agreement or disagreement utterances , utilizing both word-based and prosodic cues.", "labels": [], "entities": [{"text": "summarization of automatically transcribed meetings", "start_pos": 11, "end_pos": 62, "type": "TASK", "confidence": 0.8297089457511901}]}, {"text": "We show that hand-labeling efforts can be minimized by using unsupervised training on a large unlabeled data set combined with supervised training on a small amount of data.", "labels": [], "entities": []}, {"text": "For ASR transcripts with over 45% WER, the system recovers nearly 80% of agree/disagree utterances with a confusion rate of only 3%.", "labels": [], "entities": [{"text": "ASR transcripts", "start_pos": 4, "end_pos": 19, "type": "TASK", "confidence": 0.9158457815647125}, {"text": "WER", "start_pos": 34, "end_pos": 37, "type": "METRIC", "confidence": 0.996309220790863}, {"text": "confusion rate", "start_pos": 106, "end_pos": 120, "type": "METRIC", "confidence": 0.9908899068832397}]}], "introductionContent": [{"text": "Meetings are an integral component of life inmost organizations, and records of meetings are important for helping people recall (or learn for the first time) what took place in a meeting.", "labels": [], "entities": []}, {"text": "Audio (or audio-visual) recordings of meetings offer a complete record of the interactions, but listening to the complete recording is impractical.", "labels": [], "entities": []}, {"text": "To facilitate browsing and summarization of meeting recordings, it is useful to automatically annotate topic and participant interaction characteristics.", "labels": [], "entities": [{"text": "summarization of meeting", "start_pos": 27, "end_pos": 51, "type": "TASK", "confidence": 0.8730212052663168}]}, {"text": "Here, we focus on interactions, specifically identifying agreement and disagreement.", "labels": [], "entities": []}, {"text": "These categories are particularly important for identifying decisions in meetings and inferring whether the decisions are controversial, which can be useful for automatic summarization.", "labels": [], "entities": [{"text": "summarization", "start_pos": 171, "end_pos": 184, "type": "TASK", "confidence": 0.8278242349624634}]}, {"text": "In addition, detecting agreement is important for associating action items with meeting participants and for understanding social dynamics.", "labels": [], "entities": [{"text": "detecting agreement", "start_pos": 13, "end_pos": 32, "type": "TASK", "confidence": 0.8572678864002228}]}, {"text": "In this study, we focus on detection using both prosodic and language cues, contrasting results for handtranscribed and automatically transcribed data.", "labels": [], "entities": []}, {"text": "The agreement/disagreement labels can bethought of as a sort of speech act categorization.", "labels": [], "entities": []}, {"text": "Automatic classification of speech acts has been the subject of several studies.", "labels": [], "entities": [{"text": "Automatic classification of speech acts", "start_pos": 0, "end_pos": 39, "type": "TASK", "confidence": 0.8482393741607666}]}, {"text": "Our work builds on (), which showed that prosodic features are useful for classifying speech acts and lead to increased accuracy when combined with word based cues.", "labels": [], "entities": [{"text": "classifying speech acts", "start_pos": 74, "end_pos": 97, "type": "TASK", "confidence": 0.8604291081428528}, {"text": "accuracy", "start_pos": 120, "end_pos": 128, "type": "METRIC", "confidence": 0.9985418319702148}]}, {"text": "Other studies look at prediction of speech acts primarily from word-based cues, using language models or syntactic structure and discourse history (.", "labels": [], "entities": [{"text": "prediction of speech acts", "start_pos": 22, "end_pos": 47, "type": "TASK", "confidence": 0.837902158498764}]}, {"text": "Our work is informed by these studies, but departs significantly by exploring unsupervised training techniques.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Results for detection with different classifiers using word based features.", "labels": [], "entities": []}, {"text": " Table 2: Results for classifiers using prosodic features.", "labels": [], "entities": []}]}