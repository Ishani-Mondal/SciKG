{"title": [{"text": "Adaptive Generation in Dialogue Systems Using Dynamic User Modeling", "labels": [], "entities": [{"text": "Adaptive Generation", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.8989134728908539}]}], "abstractContent": [{"text": "We address the problem of dynamically modeling and adapting to unknown users in resource-scarce domains in the context of interactive spoken dialogue systems.", "labels": [], "entities": []}, {"text": "As an example, we show how a system can learn to choose referring expressions to refer to domain entities for users with different levels of domain expertise, and whose domain knowledge is initially unknown to the system.", "labels": [], "entities": []}, {"text": "We approach this problem using a three-step process: collecting data using a Wizard-of-Oz method, building simulated users, and learning to model and adapt to users using Reinforcement Learning techniques.", "labels": [], "entities": []}, {"text": "We show that by using only a small corpus of non-adaptive dialogues and user knowledge profiles it is possible to learn an adaptive user modeling policy using a sense-predict-adapt approach.", "labels": [], "entities": []}, {"text": "Our evaluation results show that the learned user modeling and adaptation strategies performed better in terms of adaptation than some simple hand-coded baseline policies, with both simulated and real users.", "labels": [], "entities": []}, {"text": "With real users, the learned policy produced around a 20% increase in adaptation in comparison to an adaptive hand-coded baseline.", "labels": [], "entities": [{"text": "adaptation", "start_pos": 70, "end_pos": 80, "type": "METRIC", "confidence": 0.9666686058044434}]}, {"text": "We also show that adaptation to users' domain knowledge results in improving task success (99.47% for the learned policy vs. 84.7% fora hand-coded baseline) and reducing dialogue time of the conversation (11% relative difference).", "labels": [], "entities": []}, {"text": "We also compared the learned policy with a variety of carefully hand-crafted adaptive policies that use the user knowledge profiles to adapt their choices of referring expressions throughout a conversation.", "labels": [], "entities": []}, {"text": "We show that the learned policy generalizes better to unseen user profiles than these hand-coded policies, while having comparable performance on known user profiles.", "labels": [], "entities": []}, {"text": "We discuss the overall advantages of this method and how it can be extended to other levels of adaptation such as content selection and dialogue management, and to other domains where adapting to users' domain knowledge is useful, such as travel and healthcare.", "labels": [], "entities": [{"text": "content selection", "start_pos": 114, "end_pos": 131, "type": "TASK", "confidence": 0.7484729588031769}, {"text": "dialogue management", "start_pos": 136, "end_pos": 155, "type": "TASK", "confidence": 0.7000702172517776}]}], "introductionContent": [{"text": "A user-adaptive spoken dialogue system in a technical support domain should be able to generate instructions that are appropriate to the user's level of domain expertise (using appropriate referring expressions for domain entities, generating instructions with appropriate complexity, etc.).", "labels": [], "entities": []}, {"text": "The domain knowledge of users is often unknown when a conversation starts.", "labels": [], "entities": []}, {"text": "For instance, a caller calling a helpdesk to troubleshoot his laptop cannot be readily identified as a beginner, intermediate, or an expert in the domain.", "labels": [], "entities": []}, {"text": "In natural human-human conversations, dialogue partners learn about each other and adapt their language to suit their domain expertise.", "labels": [], "entities": []}, {"text": "This kind of adaptation is called \"Alignment through Audience Design\".", "labels": [], "entities": [{"text": "Alignment", "start_pos": 35, "end_pos": 44, "type": "TASK", "confidence": 0.9778298735618591}]}, {"text": "Similar to this adaptive human behavior, a spoken dialogue system (SDS) must also be capable of observing the user's dialogue behavior, modeling his/her domain knowledge, and adapting accordingly.", "labels": [], "entities": []}, {"text": "Although there are several levels at which systems can adapt to users' domain knowledge, here we focus on adaptively choosing referring expressions that are used in technical instructions given to users.", "labels": [], "entities": []}, {"text": "We also discuss how our model can later be extended to other levels of adaptation as well such as content selection and dialogue management.", "labels": [], "entities": [{"text": "content selection", "start_pos": 98, "end_pos": 115, "type": "TASK", "confidence": 0.8121564388275146}, {"text": "dialogue management", "start_pos": 120, "end_pos": 139, "type": "TASK", "confidence": 0.8395748734474182}]}, {"text": "Referring expressions are linguistic expressions that are used to refer to domain objects of interest.", "labels": [], "entities": []}, {"text": "Traditionally, the referring expression generation (REG) task includes selecting the type of expression (pronouns, proper nouns, common nouns, etc.), selecting attributes (color, type, size, etc.) and realizing them in the form of a linguistic expression.", "labels": [], "entities": [{"text": "referring expression generation (REG) task includes selecting the type of expression (pronouns, proper nouns, common nouns, etc.), selecting attributes (color, type, size, etc.) and realizing them in the form of a linguistic expression", "start_pos": 19, "end_pos": 254, "type": "Description", "confidence": 0.8495772144068843}]}, {"text": "However, in this work, we focus on the user modeling aspects of referring expression generation.", "labels": [], "entities": [{"text": "referring expression generation", "start_pos": 64, "end_pos": 95, "type": "TASK", "confidence": 0.7735862135887146}]}, {"text": "Our objective is to choose a referring expression (either a technical or a descriptive expression) that the user can understand easily and efficiently.", "labels": [], "entities": []}, {"text": "For this, we build a dynamic user model to represent the user's domain knowledge that is estimated during the conversation.", "labels": [], "entities": []}, {"text": "See for some example utterances that we aim to generate using technical and descriptive expressions or a combination of the two types.", "labels": [], "entities": []}, {"text": "We present an approach to learning user-adaptive behavior by sensing partial information about the user's domain knowledge using unobtrusive information sensing moves, populating the user model, and then predicting the rest of the user's knowledge using reinforcement learning techniques.", "labels": [], "entities": []}, {"text": "We present a three-step process to learning user-adaptive behavior in dialogue systems: data collection, building user simulations, and learning adaptive behavior using reinforcement learning.", "labels": [], "entities": []}, {"text": "We show that the learned behavior performs better than a hand-coded adaptive behavior when evaluated with real users, by adapting to them and thereby enabling them to finish their task faster and more successfully.", "labels": [], "entities": []}, {"text": "Our approach is corpus-driven and the system learns from a small corpus (only 12 dialogues) of non-adaptive human-machine interaction.", "labels": [], "entities": []}, {"text": "In Section 2, we analyze the problem of dynamic user modeling in spoken dialogue systems in detail.", "labels": [], "entities": []}, {"text": "In Section 3, we present a technical support dialogue system that Variants of technical instructions to be generated by the system (with technical and descriptive expressions in italics).", "labels": [], "entities": []}, {"text": "1: Please plug one end of the broadband cable into the broadband filter.", "labels": [], "entities": []}, {"text": "2: Please plug one end of the thin white cable with grey ends into the small white box.", "labels": [], "entities": []}, {"text": "3: Please plug one end of the broadband cable into the small white box.", "labels": [], "entities": []}, {"text": "we use to build and experiment with our adaptive behavior learning model.", "labels": [], "entities": []}, {"text": "We then discuss data collection, building user simulations, and learning adaptive behavior in Sections 4, 5, and 6.", "labels": [], "entities": [{"text": "data collection", "start_pos": 16, "end_pos": 31, "type": "TASK", "confidence": 0.7465618252754211}]}, {"text": "We present the results and analysis of the evaluations in Section 7.", "labels": [], "entities": []}, {"text": "Finally, we present an experiment in simulation comparing the learned policy to a smart hand-coded policy, and discuss future work such as adapting at the level of content selection and dialogue management and adapting to dynamic knowledge profiles in Section 8.", "labels": [], "entities": [{"text": "dialogue management", "start_pos": 186, "end_pos": 205, "type": "TASK", "confidence": 0.7031450271606445}]}], "datasetContent": [{"text": "We measured dialogue divergence (DD) based on the Kullback-Leibler (D KL ) divergence between real and simulated dialogues to show how realistic our user simulation is.", "labels": [], "entities": [{"text": "dialogue divergence (DD)", "start_pos": 12, "end_pos": 36, "type": "TASK", "confidence": 0.6099621713161468}]}, {"text": "Kullback-Leibler (KL) divergence, which is also called relative entropy, is a measure of how similar or different two probability distributions are (.", "labels": [], "entities": []}, {"text": "Several recent studies have used this metric to evaluate how closely their user simulation models replicate real user behavior ().", "labels": [], "entities": []}, {"text": "Because KL divergence is a non-symmetric measure, DD is computed by taking the average of the KL divergence between the simulated responses and the original responses (i.e., D KL (simulated||real)) and vice versa (i.e., D KL (real||simulated)).", "labels": [], "entities": [{"text": "KL divergence", "start_pos": 8, "end_pos": 21, "type": "TASK", "confidence": 0.8325727880001068}]}, {"text": "DD between two models P and Q is defined as follows: The metric measures the divergence between distributions P and Q in N different contexts (i.e., system's dialogue action, entities mentioned, expression type used, and user's knowledge of those expressions) with M responses (i.e., user's dialogue/environment action) per context.", "labels": [], "entities": []}, {"text": "Ideally, the dialogue divergence between two similar distributions is close to zero.", "labels": [], "entities": []}, {"text": "The divergence of our dialogue action model P(A u,t ) and the environment action model P(EA u,t ) with respect to the corpus data were 0.711 and 0.232, respectively.", "labels": [], "entities": []}, {"text": "These results were comparable with other recent work on user simulation).", "labels": [], "entities": []}, {"text": "For a more detailed analysis of our simulation model, see Janarthanam (2011).", "labels": [], "entities": [{"text": "Janarthanam (2011)", "start_pos": 58, "end_pos": 76, "type": "DATASET", "confidence": 0.8691851198673248}]}, {"text": "In this section, we present the details of the evaluation process, the baseline policies, the metrics used, and the results.", "labels": [], "entities": []}, {"text": "We evaluated the learned policy and several handcoded baselines with simulated users and found that the Learned-DS policy produced higher adaptation accuracy than other policies.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 149, "end_pos": 157, "type": "METRIC", "confidence": 0.9708341360092163}]}, {"text": "Another interesting observation is that the evaluation results obtained in simulated environments transfer to evaluations with real users.", "labels": [], "entities": []}, {"text": "We used the adaptation accuracy (see Section 6.1) to measure the level of adaptation to each user.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 23, "end_pos": 31, "type": "METRIC", "confidence": 0.797164261341095}]}, {"text": "In addition, we also measured other interesting parameters from the conversation (normalized learning gain, dialogue duration, and task completion) to investigate how they are affected by adaptation.", "labels": [], "entities": []}, {"text": "Normalized learning gain (LG): We measured the learning effect on the users using normalized learning gain (LG) produced by using unknown jargon expressions.", "labels": [], "entities": [{"text": "Normalized learning gain (LG)", "start_pos": 0, "end_pos": 29, "type": "METRIC", "confidence": 0.7033229619264603}, {"text": "normalized learning gain (LG)", "start_pos": 82, "end_pos": 111, "type": "METRIC", "confidence": 0.7802555362383524}]}, {"text": "This was calculated using the pre-test (PRE) and post-test (POST) scores for the user domain knowledge (DK u ).", "labels": [], "entities": [{"text": "post-test (POST)", "start_pos": 49, "end_pos": 65, "type": "METRIC", "confidence": 0.7742100208997726}]}, {"text": "Please remember that for simulated runs, the domain knowledge of the user is updated during the interaction using the knowledge update rule.", "labels": [], "entities": []}, {"text": "For real users, LG is calculated from their pre-and post-test scores.", "labels": [], "entities": [{"text": "LG", "start_pos": 16, "end_pos": 18, "type": "METRIC", "confidence": 0.9931786060333252}]}, {"text": "Normalized Learning Gain : Dialogue time (DT): This was the time taken for the user to complete the task.", "labels": [], "entities": [{"text": "Dialogue time (DT)", "start_pos": 27, "end_pos": 45, "type": "METRIC", "confidence": 0.8483770012855529}]}, {"text": "For simulated runs, we estimated the time taken (in minutes) to complete the task using a regression model (r 2 = 0.98, p = 0.000) derived from the corpus based on number of words (#(W)), turns (T), and mean user response time (URT).", "labels": [], "entities": [{"text": "mean user response time (URT)", "start_pos": 203, "end_pos": 232, "type": "METRIC", "confidence": 0.7643211356231144}]}, {"text": "Task completion (TC): This was measured by examining the user's broadband set-up after the task was completed (i.e., the percentage of correct connections that they had made in their final set-up).", "labels": [], "entities": [{"text": "Task completion (TC)", "start_pos": 0, "end_pos": 20, "type": "METRIC", "confidence": 0.6774233937263489}]}, {"text": "We used this measure for real users only.", "labels": [], "entities": []}, {"text": "Although our primary objective is to adapt as much as possible to the user, we believe these metrics could be used in future reward functions to achieve goals other than simply adapting to users.", "labels": [], "entities": []}, {"text": "For instance, a tutorial dialogue system would aim to optimize on normalized learning gain and would not care much about dialogue time, adaptation, or perhaps even task completion.", "labels": [], "entities": []}, {"text": "The user modeling module was operated in evaluation mode to produce 200 dialogues per policy distributed equally over the five user groups (Novice, Int1, Int2, Int3, and Expert).", "labels": [], "entities": []}, {"text": "Overall performance of the different policies in terms of Adaptation Accuracy (AA), Dialogue Time (DT), and Learning Gain (LG) are given in. shows how the baseline policies as well as the Learned DS policy perform with each user type.", "labels": [], "entities": [{"text": "Adaptation Accuracy (AA)", "start_pos": 58, "end_pos": 82, "type": "METRIC", "confidence": 0.8647903442382813}, {"text": "Dialogue Time (DT)", "start_pos": 84, "end_pos": 102, "type": "METRIC", "confidence": 0.7933537662029266}, {"text": "Learning Gain (LG)", "start_pos": 108, "end_pos": 126, "type": "METRIC", "confidence": 0.8447794437408447}]}, {"text": "It shows that the Learned DS (LDS) policy generalizes well to unseen user types (i.e., Int1 and Int3) and is more consistent than any baseline policy with the different groups, especially for groups Int1 and Int3, whose profiles were not available to the learning agent.", "labels": [], "entities": []}, {"text": "This shows that a reinforcement learning agent can learn a policy that generalizes well to unseen user types.", "labels": [], "entities": []}, {"text": "In Section 8.2, we further compare the learned policy to additional hand-crafted baseline policies that utilize the user profiles in their adaptation.", "labels": [], "entities": []}, {"text": "A one-way ANOVA was used to test the difference between policies.", "labels": [], "entities": [{"text": "ANOVA", "start_pos": 10, "end_pos": 15, "type": "METRIC", "confidence": 0.6992802023887634}]}, {"text": "We found that the policies differed significantly in the adaptation accuracy (AA) metric (p < 0.0001).", "labels": [], "entities": [{"text": "adaptation accuracy (AA) metric", "start_pos": 57, "end_pos": 88, "type": "METRIC", "confidence": 0.856830875078837}]}, {"text": "We then used two-tailed paired t-tests (pairing user types) to compare the policies further.", "labels": [], "entities": []}, {"text": "We found that the LDS policy was the most accurate (Mean = 79.99, SD = 10.46) in terms of adaptation to each user's initial state of domain knowledge.", "labels": [], "entities": [{"text": "Mean", "start_pos": 52, "end_pos": 56, "type": "METRIC", "confidence": 0.9919278621673584}, {"text": "SD", "start_pos": 66, "end_pos": 68, "type": "METRIC", "confidence": 0.9281898140907288}]}, {"text": "It outperformed all other policies: Switching-adapt (Mean = 62.47, SD = 14.18), Jargon-adapt (Mean = 74.54, SD = 17.9), Stereotype (Mean = 72.46, SD = 20.77), and Descriptive (Mean = 46.15, SD = 33.29).", "labels": [], "entities": []}, {"text": "Accuracy of adaptation of the LDS policy was significantly better than Descriptive policy (p = 0.000, t = 9.11, SE = 37.413), Jargon-adapt policy (p = 0.01, t = 2.58, SE = 20.19), Stereotype policy (p = 0.000, t = 3.95, SE = 23.40), and Switchingadapt policy (p = 0.000, t = 8.09, SE = 22.29).", "labels": [], "entities": [{"text": "SE", "start_pos": 112, "end_pos": 114, "type": "METRIC", "confidence": 0.9880262613296509}, {"text": "SE", "start_pos": 167, "end_pos": 169, "type": "METRIC", "confidence": 0.9808603525161743}, {"text": "SE", "start_pos": 281, "end_pos": 283, "type": "METRIC", "confidence": 0.9737461805343628}]}, {"text": "The LDS policy performed better than the Jargon-adapt policy, because it was able to predict accurately the user's knowledge of referents unseen in the dialogue so far.", "labels": [], "entities": []}, {"text": "It performed better than the Stereotype policy because its adaptive behavior takes into account the uncertainty in the user's dialogue behavior.", "labels": [], "entities": []}, {"text": "For instance, users did not always ask for clarification when they did not know the jargon expression.", "labels": [], "entities": []}, {"text": "They might instead go ahead and do something incorrectly.", "labels": [], "entities": []}, {"text": "Therefore, when there is no verbal feedback (i.e., no clarification request) from the user, the system has no information on which a user profile can be picked.", "labels": [], "entities": []}, {"text": "However, the learned policy represents this uncertainty in its state transistions and is able to select an appropriate adaptive action.", "labels": [], "entities": []}, {"text": "Another point to note is that the LDS policy does not pick a user profile but maps user model states directly to actions, generating either a jargon or descriptive expression for each entity, and so adapts continuously until the end of a dialogue, unlike the stereotype policy, which chooses a profile and sticks with it.", "labels": [], "entities": []}, {"text": "The Jargon-adapt policy performed better than the Switching-adapt and Descriptive policies (p < 0.05) in terms of adaptation accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 125, "end_pos": 133, "type": "METRIC", "confidence": 0.9849066138267517}]}, {"text": "This was because the system can learn more about the user by using more jargon expressions and then using that knowledge to make its later choices more adaptive.", "labels": [], "entities": []}, {"text": "Jargon-adapt performed slightly better than the Stereotype policy but the increase inaccuracy is not statistically significant (p = 0.17).", "labels": [], "entities": []}, {"text": "The Stereotype policy also performed significantly better than the Switchingadapt and the Descriptive policies (p < 0.001).", "labels": [], "entities": []}, {"text": "The Stereotype policy adapted to users globally using their profiles.", "labels": [], "entities": []}, {"text": "However, due to uncertainty in user's responses, it was not always possible to pick the right profile for adaptation.", "labels": [], "entities": []}, {"text": "This was probably why it outperformed the Switching-adapt and the Descriptive policies and performed as well as the Jargon-adapt policy but did not outperform the Learned-DS policy.", "labels": [], "entities": []}, {"text": "The Switchingadapt policy, on the other hand, quickly switched its policy (sometimes erroneously) based on the user's clarification requests but did not adapt appropriately to evidence presented later during the conversation.", "labels": [], "entities": []}, {"text": "Sometimes, this policy switched erroneously because of uncertain user behaviors.", "labels": [], "entities": []}, {"text": "The Descriptive policy performed very well with novice users but not so with other user types.", "labels": [], "entities": []}, {"text": "In terms of dialogue time (DT), the Learned-DS policy was a bit more timeconsuming than the Switching-adapt and Descriptive policies but less so than the Jargon-adapt and Stereotype policies.", "labels": [], "entities": [{"text": "dialogue time (DT)", "start_pos": 12, "end_pos": 30, "type": "METRIC", "confidence": 0.7636109828948975}]}, {"text": "This was because learned policies use sensing moves (giving rise to clarification requests) in order to learn more about the user.", "labels": [], "entities": []}, {"text": "The Descriptive policy was non-adaptive and therefore faster than other policies because it only used descriptive expressions and therefore caused no clarification requests from the users.", "labels": [], "entities": []}, {"text": "Similarly, due to fewer clarification requests, the Switching-adapt policy also took less dialogue time.", "labels": [], "entities": []}, {"text": "Learned policies spent more time in order to learn about the users they interact with before they adapt to them.", "labels": [], "entities": []}, {"text": "When the three highperforming policies (by adaptation accuracy) are compared, the Learned-DS policy had the shortest dialogue duration.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 54, "end_pos": 62, "type": "METRIC", "confidence": 0.8421258330345154}]}, {"text": "This was due to better adaptation.", "labels": [], "entities": []}, {"text": "The difference between the Learned-DS and the Jargon-adapt policy is statistically significant (p < 0.05).", "labels": [], "entities": []}, {"text": "However, the difference between the Learned-DS and the Stereotype policy is not significant.", "labels": [], "entities": []}, {"text": "With respect to normalized learning gain (LG), the Jargon-adapt policy produced the highest gain (LG = 0.97).", "labels": [], "entities": [{"text": "normalized learning gain (LG)", "start_pos": 16, "end_pos": 45, "type": "METRIC", "confidence": 0.762484053770701}, {"text": "LG", "start_pos": 98, "end_pos": 100, "type": "METRIC", "confidence": 0.953552782535553}]}, {"text": "This is because the policy used jargon expressions for all referents at least once.", "labels": [], "entities": []}, {"text": "The difference between Jargon-adapt policy and others were statistically significant at p < 0.0001.", "labels": [], "entities": []}, {"text": "The LDS policy produced a learning gain of 0.63, which is a close second because it did use jargon expressions with novice users until it was ready to adapt to them.", "labels": [], "entities": []}, {"text": "Although the use of jargon expressions with novices and intermediates sacrificed adaptation accuracy, it served to increase normalized learning gain as well as populating the user model.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 92, "end_pos": 100, "type": "METRIC", "confidence": 0.9589977264404297}]}, {"text": "Recall that normalized learning gain is not what we aimed to optimize.", "labels": [], "entities": []}, {"text": "We merely report this metric as we feel it is interesting to see how adaptation affects learning gain and that this could itself be used as a reward function in the future.", "labels": [], "entities": []}, {"text": "We chose the two best performing policies from our evaluation with simulated users for our final evaluation with real users.", "labels": [], "entities": []}, {"text": "Thirty-eight university students from different backgrounds (e.g., Arts, Humanities, Medicine, and Engineering) participated in the evaluation.", "labels": [], "entities": []}, {"text": "Seventeen users were given a system with the Jargon-adapt policy and 19 users interacted with a system with the Learned DS (LDS) policy.", "labels": [], "entities": [{"text": "Learned DS (LDS) policy", "start_pos": 112, "end_pos": 135, "type": "DATASET", "confidence": 0.5934630582729975}]}, {"text": "Data from two other participants were unusable due to logging issues.", "labels": [], "entities": []}, {"text": "Each user was given a pre-task recognition test to record his/her initial domain knowledge.", "labels": [], "entities": []}, {"text": "The mean pre-task recognition score of the two groups were tested with Mann-Whitney U test for two independent samples and found to be not significantly different from each other (Jargon-adapt = 7.33, LDS = 7.45).", "labels": [], "entities": [{"text": "LDS", "start_pos": 201, "end_pos": 204, "type": "METRIC", "confidence": 0.960106372833252}]}, {"text": "Therefore, there was no bias towards any policy.", "labels": [], "entities": []}, {"text": "The experimenter readout a list of technical terms and the user was asked to point out the domain entities laid out in front of them.", "labels": [], "entities": []}, {"text": "They were then given one of the two systems, learned or baseline, to interact with.", "labels": [], "entities": []}, {"text": "Following the system instructions, they then attempted to setup the broadband connection.", "labels": [], "entities": []}, {"text": "When the dialogue had ended, the user was given a post-task test where the recognition test was repeated and their responses were recorded.", "labels": [], "entities": []}, {"text": "The user's broadband connection set-up was manually examined for task completion (i.e., the percentage of correct connections that they had made in their final set-up).", "labels": [], "entities": []}, {"text": "The user was given the task completion results and was then given a user satisfaction questionnaire to evaluate the features of the system based on the conversation.", "labels": [], "entities": []}, {"text": "Example dialogues (reconstructed from logged system and user dialogue acts) between real users and these two policies are given in Appendix A. All users interacted with a wizarded system using one of the two UM policies.", "labels": [], "entities": []}, {"text": "The users' responses were intercepted by a human interpreter (or \"wizard\") and were immediately annotated as dialogue acts, to which the automated dialogue manager responded with a system dialogue action (the dialogue policy was fixed).", "labels": [], "entities": []}, {"text": "The wizards were not aware of the user modeling policy used by the system.", "labels": [], "entities": []}, {"text": "The respective policies chose the referring expressions to generate the system utterance for the given dialogue action.", "labels": [], "entities": []}, {"text": "We compare the performance of the two policies on real users using objective parameters and subjective feedback scores.", "labels": [], "entities": []}, {"text": "Tests for statistical significance were done using the Mann-Whitney U test for two independent samples (due to the non-parametric nature of the data).", "labels": [], "entities": []}, {"text": "Because we measure four metrics, namely, Adaptation Accuracy, Learning Gain, Dialogue Time, and Task Completion Rate, we apply Bonferroni correction and set our \u03b1 to 0.0125 (i.e., 0.05/4).", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 52, "end_pos": 60, "type": "METRIC", "confidence": 0.7034266591072083}, {"text": "Task Completion Rate", "start_pos": 96, "end_pos": 116, "type": "METRIC", "confidence": 0.6298963924249014}]}, {"text": "presents the mean accuracy of adaptation (AA), learning gain (LG), dialogue time (DT), and task completion (TC) produced by the two policies.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 18, "end_pos": 26, "type": "METRIC", "confidence": 0.9991040825843811}, {"text": "adaptation (AA)", "start_pos": 30, "end_pos": 45, "type": "METRIC", "confidence": 0.7174170538783073}, {"text": "learning gain (LG)", "start_pos": 47, "end_pos": 65, "type": "METRIC", "confidence": 0.9228094339370727}, {"text": "dialogue time (DT)", "start_pos": 67, "end_pos": 85, "type": "METRIC", "confidence": 0.8671488046646119}, {"text": "task completion (TC)", "start_pos": 91, "end_pos": 111, "type": "METRIC", "confidence": 0.7253432452678681}]}, {"text": "The LDS policy produced more accurate adaptation than the Jargon-adapt policy (p = 0.000, U = 9.0, r = -0.81).", "labels": [], "entities": [{"text": "U", "start_pos": 90, "end_pos": 91, "type": "METRIC", "confidence": 0.969173789024353}]}, {"text": "The use of the LDS policy resulted in less dialogue time (U = 73.0, p = 0.008, r = -0.46) and higher task completion (U = 47.5, p = 0.0006, r = -0.72) than the Jargon-adapt policy.", "labels": [], "entities": [{"text": "completion", "start_pos": 106, "end_pos": 116, "type": "METRIC", "confidence": 0.9160405993461609}]}, {"text": "However, there was no significant difference in LG.", "labels": [], "entities": [{"text": "LG", "start_pos": 48, "end_pos": 50, "type": "METRIC", "confidence": 0.9707578420639038}]}, {"text": "Another important point to note is that the order of ranking in terms of adaptation accuracy from the simulated user evaluation is preserved in the real user evaluation as well: LDS policy scores better than Jargon-adapt policy in terms of AA both with simulated and real users.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 84, "end_pos": 92, "type": "METRIC", "confidence": 0.8272613286972046}, {"text": "AA", "start_pos": 240, "end_pos": 242, "type": "METRIC", "confidence": 0.9987758994102478}]}, {"text": "We tested for correlation between the above metrics using Spearman's rho  correlation.", "labels": [], "entities": [{"text": "Spearman's rho  correlation", "start_pos": 58, "end_pos": 85, "type": "METRIC", "confidence": 0.5479006171226501}]}, {"text": "We also found that AA correlates positively with task completion rate (TCR) (r = 0.584, p = 0.000) and negatively with DT (r = \u22120.546, p = 0.001).", "labels": [], "entities": [{"text": "AA", "start_pos": 19, "end_pos": 21, "type": "METRIC", "confidence": 0.9994839429855347}, {"text": "completion rate (TCR)", "start_pos": 54, "end_pos": 75, "type": "METRIC", "confidence": 0.9173647880554199}, {"text": "DT", "start_pos": 119, "end_pos": 121, "type": "METRIC", "confidence": 0.9720001220703125}]}, {"text": "These correlations and our results suggest that as a system's adaptation towards its users increases, the task completion rate increases and dialogue duration decreases significantly.", "labels": [], "entities": []}, {"text": "presents how the users subjectively scored different features of the system on an agreement scale of 1 to 4 (with 1 = strongly disagree and 4 = strongly agree), based on their conversations with the two different strategies.", "labels": [], "entities": []}, {"text": "The difference in overall satisfaction score, calculated as the mean of all the questions Q1 to Q8 (with Q2 reversed), was not significant (Jargon = 3.1 \u00b1 0.38, Learned = 3.35 \u00b1 0.32, p = 0.058).", "labels": [], "entities": [{"text": "satisfaction score", "start_pos": 26, "end_pos": 44, "type": "METRIC", "confidence": 0.919743001461029}, {"text": "Jargon = 3.1 \u00b1", "start_pos": 140, "end_pos": 154, "type": "METRIC", "confidence": 0.9422850906848907}]}, {"text": "Although there is statistical difference between the policies in the objective metrics, there is no significant difference between them in any of the user ratings.", "labels": [], "entities": []}, {"text": "Users seemed unable to recognize the nuances in the way the system adapted to them (Q3) and they did not rate the Learned-DS policy any higher than the Jargon-adapt policy regarding whether it was easy to identify objects (Q4).", "labels": [], "entities": []}, {"text": "They could have been satisfied with the fact that both the systems adapted at all.", "labels": [], "entities": []}, {"text": "This adaptation and the fact that the system offered help when the users were confused in interpreting the technical terms could have led the users to score the system well in terms of future use (Q8), dialogue time (Q5), and ease of conversation (Q7); but in common with experiments in dialogue management, it seems that users find it difficult to evaluate these improvements subjectively.", "labels": [], "entities": [{"text": "dialogue time (Q5)", "start_pos": 202, "end_pos": 220, "type": "METRIC", "confidence": 0.8432909488677979}, {"text": "ease", "start_pos": 226, "end_pos": 230, "type": "METRIC", "confidence": 0.9829234480857849}, {"text": "dialogue management", "start_pos": 287, "end_pos": 306, "type": "TASK", "confidence": 0.8122649192810059}]}, {"text": "The users were given only one of the two strategies and therefore were not in a position to compare the two strategies and judge which one was better.", "labels": [], "entities": []}, {"text": "Results in lead us to conclude that perhaps users need to directly compare two or more strategies in order to better judge the differences between strategies, or perhaps the differences are just too subtle for users to notice.", "labels": [], "entities": []}, {"text": "Another point to note is that the participants, although real humans, were performing the task in a laboratory setting and not in areal setting (e.g., at home where they are setting up their own home broadband connection).", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 3  Corpus statistics (grouped on strategy).", "labels": [], "entities": []}, {"text": " Table 8  Stereotypes: n-values and Adaptation Accuracy (where n is number of turns).", "labels": [], "entities": [{"text": "Adaptation", "start_pos": 36, "end_pos": 46, "type": "METRIC", "confidence": 0.9920851588249207}, {"text": "Accuracy", "start_pos": 47, "end_pos": 55, "type": "METRIC", "confidence": 0.6120530366897583}]}, {"text": " Table 9  Evaluation on five simulated user types.", "labels": [], "entities": []}, {"text": " Table 11  Real user feedback.", "labels": [], "entities": []}]}