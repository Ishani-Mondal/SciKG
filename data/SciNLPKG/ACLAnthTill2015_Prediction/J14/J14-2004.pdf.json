{"title": [], "abstractContent": [{"text": "The task of event coreference resolution plays a critical role in many natural language processing applications such as information extraction, question answering, and topic detection and tracking.", "labels": [], "entities": [{"text": "event coreference resolution", "start_pos": 12, "end_pos": 40, "type": "TASK", "confidence": 0.8398026426633199}, {"text": "information extraction", "start_pos": 120, "end_pos": 142, "type": "TASK", "confidence": 0.8414353430271149}, {"text": "question answering", "start_pos": 144, "end_pos": 162, "type": "TASK", "confidence": 0.9265950620174408}, {"text": "topic detection and tracking", "start_pos": 168, "end_pos": 196, "type": "TASK", "confidence": 0.8599889874458313}]}, {"text": "In this article, we describe anew class of unsupervised, nonparametric Bayesian models with the purpose of probabilistically inferring coreference clusters of event mentions from a collection of unlabeled documents.", "labels": [], "entities": []}, {"text": "In order to infer these clusters, we automatically extract various lexical, syntactic, and semantic features for each event mention from the document collection.", "labels": [], "entities": []}, {"text": "Extracting a rich set of features for each event mention allows us to cast event coreference resolution as the task of grouping together the mentions that share the same features (they have the same participating entities, share the same location, happen at the same time, etc.).", "labels": [], "entities": [{"text": "event coreference resolution", "start_pos": 75, "end_pos": 103, "type": "TASK", "confidence": 0.7021273771921793}]}, {"text": "Some of the most important challenges posed by the resolution of event coreference in an unsupervised way stem from (a) the choice of representing event mentions through a rich set of features and (b) the ability of modeling events described both within the same document and across multiple documents.", "labels": [], "entities": [{"text": "resolution of event coreference", "start_pos": 51, "end_pos": 82, "type": "TASK", "confidence": 0.803909957408905}]}, {"text": "Our first unsupervised model that addresses these challenges is a generalization of the hierarchical Dirichlet process.", "labels": [], "entities": []}, {"text": "This new extension presents the hierarchical Dirichlet process's ability to capture the uncertainty regarding the number of clustering components and, additionally, takes into account any finite number of features associated with each event mention.", "labels": [], "entities": []}, {"text": "Furthermore, to overcome some of the limitations of this extension, we devised anew hybrid model, which combines an infinite latent class model with a discrete time series model.", "labels": [], "entities": []}, {"text": "The main advantage of this hybrid model stands in its capability to automatically infer the number of features associated with each event mention from data and, at the same time, to perform an automatic selection of the most informative features for the task of event coreference.", "labels": [], "entities": []}, {"text": "The evaluation performed for solving both within-and cross-document event coref-erence shows significant improvements of these models when compared against two baselines for this task.", "labels": [], "entities": []}], "introductionContent": [{"text": "Event coreference resolution consists of grouping together the text expressions that refer to real-world events (also called event mentions) into a set of clusters such that all the mentions from the same cluster correspond to a unique event.", "labels": [], "entities": [{"text": "Event coreference resolution", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.8218981027603149}]}, {"text": "The problem of event coreference is not new.", "labels": [], "entities": [{"text": "event coreference", "start_pos": 15, "end_pos": 32, "type": "TASK", "confidence": 0.8224921226501465}]}, {"text": "It was originally studied in philosophy, where researchers tried to determine when two events are identical and when they are different.", "labels": [], "entities": []}, {"text": "One relevant theory in this direction was proposed by, who argued that two events are identical if they have the same causes and effects.", "labels": [], "entities": []}, {"text": "Later on, a different theory was proposed by, who considered that each event is associated with a physical object (which is well defined in space and time), and therefore, two events are identical if their corresponding objects have the same spatiotemporal location.", "labels": [], "entities": []}, {"text": "According to, in the same year, Davidson abandoned his suggestion to embrace the Quinean theory on event identity.", "labels": [], "entities": [{"text": "event identity", "start_pos": 99, "end_pos": 113, "type": "TASK", "confidence": 0.6685162335634232}]}, {"text": "Resolving event coreference is an essential requirement for many natural language processing (NLP) applications.", "labels": [], "entities": [{"text": "Resolving event coreference", "start_pos": 0, "end_pos": 27, "type": "TASK", "confidence": 0.9136528372764587}]}, {"text": "For instance, in topic detection and tracking, event coreference resolution is required in order to identify new seminal events in broadcast news that have not been mentioned before ().", "labels": [], "entities": [{"text": "topic detection and tracking", "start_pos": 17, "end_pos": 45, "type": "TASK", "confidence": 0.8005931749939919}, {"text": "event coreference resolution", "start_pos": 47, "end_pos": 75, "type": "TASK", "confidence": 0.7667783399422964}]}, {"text": "In information extraction, event coreference information was used for filling predefined template structures from text documents.", "labels": [], "entities": [{"text": "information extraction", "start_pos": 3, "end_pos": 25, "type": "TASK", "confidence": 0.9016848802566528}, {"text": "event coreference information", "start_pos": 27, "end_pos": 56, "type": "TASK", "confidence": 0.7616270383199056}]}, {"text": "In question answering, a novel method of mapping event structures was used in order to provide answer justification (.", "labels": [], "entities": [{"text": "question answering", "start_pos": 3, "end_pos": 21, "type": "TASK", "confidence": 0.9208291172981262}]}, {"text": "The same idea of mapping event structures was used in a graph-matching approach for enhancing textual entailment.", "labels": [], "entities": [{"text": "textual entailment", "start_pos": 94, "end_pos": 112, "type": "TASK", "confidence": 0.7109437584877014}]}, {"text": "Event coreference information was also used for detecting contradictions in text (.", "labels": [], "entities": []}, {"text": "Previous NLP approaches for solving event coreference relied on supervised learning methods that explore various linguistic properties in order to decide if a pair of event mentions is coreferential or not (Humphreys,.", "labels": [], "entities": [{"text": "solving event coreference", "start_pos": 28, "end_pos": 53, "type": "TASK", "confidence": 0.7282743354638418}]}, {"text": "In spite of being successful fora particular labeled corpus, in general, these pairwise models are dependent on the domain or language that they are trained on.", "labels": [], "entities": []}, {"text": "For instance, in order to adapt a supervised system to run over a collection of documents written in a different language or belonging to a different domain of interest, at least a minimal annotation effort needs to be performed.", "labels": [], "entities": []}, {"text": "Furthermore, because these models are dependent on local pairwise decisions, they are unable to capture a global event distribution at the topic-or document-collection level.", "labels": [], "entities": []}, {"text": "To address these limitations, we departed from the idea of using supervised approaches for event coreference resolution and explored how anew class of unsupervised, nonparametric Bayesian models can be used to probabilistically infer coreference clusters of event mentions from a collection of unlabeled documents.", "labels": [], "entities": [{"text": "event coreference resolution", "start_pos": 91, "end_pos": 119, "type": "TASK", "confidence": 0.7415585120519003}]}, {"text": "In addition, because an event can be mentioned multiple times in a document collection and its mentions may occur both in the same document or across multiple documents, we designed our unsupervised models to solve the two subproblems of within-document and cross-document event coreference resolution.", "labels": [], "entities": [{"text": "cross-document event coreference resolution", "start_pos": 258, "end_pos": 301, "type": "TASK", "confidence": 0.7671483308076859}]}, {"text": "In order to evaluate the unsupervised models for these two subproblems, we annotated anew data set encoding both withinand cross-document event coreference information.", "labels": [], "entities": []}, {"text": "Besides our contribution of using unsupervised methods to solve within-and cross-document event coreference, in this article we present novel Bayesian models that provide a more flexible framework for representing data than current models.", "labels": [], "entities": [{"text": "cross-document event coreference", "start_pos": 75, "end_pos": 107, "type": "TASK", "confidence": 0.605916808048884}]}, {"text": "By starting from the generic problem of clustering observable linguistic objects (i.e., event mentions) encoded into a large collection of text documents where the clusters (i.e., events) can be shared across documents, we devised our unsupervised models such that they provide solutions to the following four desiderata: 1) We prefer the number of clusters (denoted by K) to be probabilistically inferred from data rather than to be assigned to an a priori fixed value.", "labels": [], "entities": []}, {"text": "This desideratum of allowing K to be a free parameter in the Bayesian models devised for our problem constitutes a more realistic approach because, in general, document collections encode an unspecified number of latent linguistic structures.", "labels": [], "entities": []}, {"text": "2) We redefine the task of finding clusters of mentions that refer to the same events as the task of identifying those mentions that share the same event participants and the same event properties.", "labels": [], "entities": []}, {"text": "For example, the same entity must participate in all the event mentions that are coreferential; also, all the coreferential mentions must have the same spatiotemporal location.", "labels": [], "entities": []}, {"text": "These characteristics extracted for each event mention from text are also called linguistic features and, in general, the event mentions corresponding to each of these clusters are characterized by a large set of features.", "labels": [], "entities": []}, {"text": "Because of this, we desire that the generative process associated with each Bayesian model to automatically adapt every time anew feature is added in the feature extraction phase.", "labels": [], "entities": []}, {"text": "3) Although each event mention is represented as a feature-rich linguistic object, there is no guarantee that all the features that describe event mentions have a positive impact for the task of event coreference.", "labels": [], "entities": []}, {"text": "Some of these features maybe redundant or may increase the complexity of the Bayesian models solving this task and, consequently, they may contribute to lowering the overall performance of event coreference.", "labels": [], "entities": []}, {"text": "To address these problems, we wish to incorporate into the Bayesian models a feature selection mechanism that is able to automatically build a set of the most salient features from the initial feature set such that only these salient features will participate in the process of clustering event mentions.", "labels": [], "entities": [{"text": "clustering event mentions", "start_pos": 278, "end_pos": 303, "type": "TASK", "confidence": 0.8517140944798788}]}, {"text": "In this regard, we assume that a feature is salient if it corresponds to a large number of samples in the generative process.", "labels": [], "entities": []}, {"text": "We denote the size of the salient feature set by M. Furthermore, in spite of the fact that the initial feature space describing event mentions can have an unbounded number of features, we want the set of salient features to be finite (i.e., M-finite) at any given point in time during the generative process corresponding to each Bayesian model.", "labels": [], "entities": []}, {"text": "4) Finally, we also want our Bayesian models to capture the structural dependencies of the observable objects.", "labels": [], "entities": []}, {"text": "In this way, the models can take advantage of the sequential order in which the event mentions are generated inside each document.", "labels": [], "entities": []}, {"text": "We believe that these four desiderata constitute a more natural approach for clustering complex linguistic objects from a large collection of documents and relax many of the constraints imposed in the current clustering tasks.", "labels": [], "entities": [{"text": "clustering complex linguistic objects", "start_pos": 77, "end_pos": 114, "type": "TASK", "confidence": 0.8810179531574249}]}, {"text": "It is worth pointing out that the generic problem described here can be instantiated by tasks not only from the area of computational linguistics, but also from other research areas as well.", "labels": [], "entities": []}, {"text": "For instance, in biomedical informatics, clinical researchers can use the new Bayesian models to perform studies over various cohorts of patients.", "labels": [], "entities": []}, {"text": "In this configuration, the observations to be clustered correspond to patients, and the features associated with the patients can be extracted from clinical reports or can be represented by structured clinical information (e.g., white blood cells, temperature, heart rate, respiratory rate, sputum culture).", "labels": [], "entities": []}, {"text": "Another instance of the generic problem described here is from data mining.", "labels": [], "entities": [{"text": "data mining", "start_pos": 63, "end_pos": 74, "type": "TASK", "confidence": 0.733893483877182}]}, {"text": "In this domain, clustering tasks can be performed over structured information stored in large tables (e.g., products, restaurants, hotels).", "labels": [], "entities": []}, {"text": "For this type of problem, each object is associated with a row in", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section, we present the evaluation framework of the Bayesian models for both within-document (WD) and cross-document (CD) coreference resolution.", "labels": [], "entities": [{"text": "cross-document (CD) coreference resolution", "start_pos": 110, "end_pos": 152, "type": "TASK", "confidence": 0.6093576600154241}]}, {"text": "We start by briefly describing the experimental set-up and coreference evaluation measures, and then continue by showing the experimental results on the ACE, OntoNotes, and EventCorefBank data sets.", "labels": [], "entities": [{"text": "ACE", "start_pos": 153, "end_pos": 156, "type": "DATASET", "confidence": 0.9426551461219788}, {"text": "EventCorefBank data sets", "start_pos": 173, "end_pos": 197, "type": "DATASET", "confidence": 0.9105592370033264}]}, {"text": "Finally, we conclude with an analysis of the most common errors made by the Bayesian models.", "labels": [], "entities": []}, {"text": "In the data processing phase, we extracted the linguistic features described in Section 4 for each event mention annotated in the three data sets.", "labels": [], "entities": []}, {"text": "As a result of this phase, in the ACE corpus, we identified 6,553 event mentions grouped into 4,946 events, and in the OntoNotes corpus, we identified 11,433 event mentions grouped into 3,393 events.", "labels": [], "entities": [{"text": "ACE corpus", "start_pos": 34, "end_pos": 44, "type": "DATASET", "confidence": 0.9805026948451996}, {"text": "OntoNotes corpus", "start_pos": 119, "end_pos": 135, "type": "DATASET", "confidence": 0.8964147567749023}]}, {"text": "Likewise, in the new ECB corpus, we distinguished 1,744 event mentions, 1,302 withindocument events, 339 cross-document events, and 43 seminal events (or topics).", "labels": [], "entities": [{"text": "ECB corpus", "start_pos": 21, "end_pos": 31, "type": "DATASET", "confidence": 0.9445315599441528}]}, {"text": "lists additional statistics extracted from these three data sets after performing this phase.", "labels": [], "entities": []}, {"text": "It is also worth mentioning that for processing OntoNotes we devoted additional efforts.", "labels": [], "entities": []}, {"text": "This is because, in spite of the fact that OntoNotes provides coreference annotations for both entity and event mentions, the annotations from this data set do not specify which of the mentions refer to entities and which of them refer to events.", "labels": [], "entities": []}, {"text": "Therefore, in order to identify only the event mentions from OntoNotes, we first ran our event identifier  and then marked as event mentions only those mentions annotated in this data set that overlap with the mentions extracted by the event identifier.", "labels": [], "entities": [{"text": "OntoNotes", "start_pos": 61, "end_pos": 70, "type": "DATASET", "confidence": 0.943789541721344}]}, {"text": "Using this procedure, we marked a number of 4,940 mentions as event mentions from the total number of 67,500 mentions annotated in OntoNotes.", "labels": [], "entities": [{"text": "OntoNotes", "start_pos": 131, "end_pos": 140, "type": "DATASET", "confidence": 0.9303073287010193}]}, {"text": "Ina second step of processing OntoNotes, we extended the number of event mentions to 11,433 by marking all the mentions that share the same cluster with at least one event mention from the set of 4,940 previously identified event mentions.", "labels": [], "entities": []}, {"text": "From the 6,493 event mentions marked in this step, the majority of them correspond to nouns (4,707) and to the it pronoun (767).", "labels": [], "entities": []}, {"text": "Although only a small subset of event mentions was manually annotated with event coreference information in the three data sets (also called the set of true or gold event mentions), during the generative process, we considered all possible event mentions that are expressed in the data sets for every specific event.", "labels": [], "entities": []}, {"text": "We believe this is a more realistic approach, in spite of the fact that we evaluated only the manually annotated events.", "labels": [], "entities": []}, {"text": "For this purpose, we ran the event identifier described in Bejan (2007) on the ACE, OntoNotes, and ECB corpora, and extracted 45,289, 81,938, and 21,175 event mentions, respectively.", "labels": [], "entities": [{"text": "ACE", "start_pos": 79, "end_pos": 82, "type": "DATASET", "confidence": 0.9581844806671143}, {"text": "ECB corpora", "start_pos": 99, "end_pos": 110, "type": "DATASET", "confidence": 0.81076779961586}]}, {"text": "It is also worth mentioning that the set of event mentions obtained from running the event identifier (also called the set of system event mentions) on ACE and ECB includes more than 98% from the set of true event mentions.", "labels": [], "entities": [{"text": "ACE and ECB", "start_pos": 152, "end_pos": 163, "type": "DATASET", "confidence": 0.7821734348932902}]}, {"text": "In terms of feature space dimensionality over the two data sets, we performed experiments with a set of 132 feature types, where each feature type consists, on average, of 6,300 distinct feature values.", "labels": [], "entities": []}, {"text": "In the evaluation phase, we considered only the true mentions from the ACE test data set and from the test sets of a five-fold cross validation scheme on the OntoNotes and ECB data sets.", "labels": [], "entities": [{"text": "ACE test data set", "start_pos": 71, "end_pos": 88, "type": "DATASET", "confidence": 0.9815595000982285}, {"text": "OntoNotes and ECB data sets", "start_pos": 158, "end_pos": 185, "type": "DATASET", "confidence": 0.8234487891197204}]}, {"text": "For evaluating the cross-document coreference annotations from EventCorefBank, we adopted the same approach as described in by merging all the documents from the same topic into a meta-document and then scoring this document as performed for within-document evaluation.", "labels": [], "entities": []}, {"text": "To compute the final results of our experiments, we averaged the results over five runs of the generative models.", "labels": [], "entities": []}, {"text": "In general, the HDP flat model achieved the best performance results on the ACE test data set (the results in), whereas the HDP struct model, which also encounters dependencies between feature types, proved to be more effective on the ECB data set for both within-and cross-document event coreference evaluation (as shown in).", "labels": [], "entities": [{"text": "ACE test data set", "start_pos": 76, "end_pos": 93, "type": "DATASET", "confidence": 0.9780749827623367}, {"text": "ECB data set", "start_pos": 235, "end_pos": 247, "type": "DATASET", "confidence": 0.969313363234202}, {"text": "cross-document event coreference evaluation", "start_pos": 268, "end_pos": 311, "type": "TASK", "confidence": 0.6338948979973793}]}, {"text": "On the OntoNotes data set, as listed in, HDP flat shows better results than HDP struct when considering the B 3 and PW metrics, whereas HDP struct outperforms HDP flat when considering the MUC and CEAF metrics.", "labels": [], "entities": [{"text": "OntoNotes data set", "start_pos": 7, "end_pos": 25, "type": "DATASET", "confidence": 0.9792791207631429}, {"text": "MUC and CEAF metrics", "start_pos": 189, "end_pos": 209, "type": "DATASET", "confidence": 0.7398728430271149}]}, {"text": "Moreover, the results of the HDP flat and HDP struct models show an F-score increase by 4-10 percentage points over the HDP 1f model, and therefore prove that the HDP extensions provide a more flexible representation for clustering objects characterized by rich properties than the original HDP model.", "labels": [], "entities": [{"text": "F-score", "start_pos": 68, "end_pos": 75, "type": "METRIC", "confidence": 0.9991470575332642}]}, {"text": "We also plot the evolution of the generative process associated with an HDP model.", "labels": [], "entities": [{"text": "generative", "start_pos": 34, "end_pos": 44, "type": "TASK", "confidence": 0.9667168259620667}]}, {"text": "For instance, shows that the HDP flat model corresponding to the experiment from row 7 in converges in 350 iteration steps to a posterior distribution over event mentions from the ACE corpus with around 2,000 latent events.", "labels": [], "entities": [{"text": "ACE corpus", "start_pos": 180, "end_pos": 190, "type": "DATASET", "confidence": 0.9704773724079132}]}], "tableCaptions": [{"text": " Table 1  Statistics of the ACE, OntoNotes, and ECB corpora.", "labels": [], "entities": [{"text": "ACE", "start_pos": 28, "end_pos": 31, "type": "DATASET", "confidence": 0.8861873745918274}, {"text": "ECB corpora", "start_pos": 48, "end_pos": 59, "type": "DATASET", "confidence": 0.916405200958252}]}, {"text": " Table 2  Results for WD coreference resolution on the ACE data set.", "labels": [], "entities": [{"text": "WD coreference resolution", "start_pos": 22, "end_pos": 47, "type": "TASK", "confidence": 0.9400568604469299}, {"text": "ACE data set", "start_pos": 55, "end_pos": 67, "type": "DATASET", "confidence": 0.9928743044535319}]}, {"text": " Table 3  Results for WD coreference resolution on the OntoNotes data set.", "labels": [], "entities": [{"text": "WD coreference resolution", "start_pos": 22, "end_pos": 47, "type": "TASK", "confidence": 0.9380190968513489}, {"text": "OntoNotes data set", "start_pos": 55, "end_pos": 73, "type": "DATASET", "confidence": 0.9768984913825989}]}, {"text": " Table 4  Results for WD coreference resolution on the ECB data set.", "labels": [], "entities": [{"text": "WD coreference resolution", "start_pos": 22, "end_pos": 47, "type": "TASK", "confidence": 0.9376140435536703}, {"text": "ECB data set", "start_pos": 55, "end_pos": 67, "type": "DATASET", "confidence": 0.9948714176813761}]}, {"text": " Table 5  Results for CD coreference resolution on the ECB data set.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 25, "end_pos": 47, "type": "TASK", "confidence": 0.8456297516822815}, {"text": "ECB data set", "start_pos": 55, "end_pos": 67, "type": "DATASET", "confidence": 0.9938858350118002}]}, {"text": " Table 6  Feature non-sampling vs. feature sampling in iFHMM-iHMM models.", "labels": [], "entities": []}]}