{"title": [{"text": "Identification of Multiword Expressions by Combining Multiple Linguistic Information Sources", "labels": [], "entities": [{"text": "Identification of Multiword Expressions", "start_pos": 0, "end_pos": 39, "type": "TASK", "confidence": 0.838777095079422}]}], "abstractContent": [{"text": "We propose a framework for using multiple sources of linguistic information in the task of identifying multiword expressions in natural language texts.", "labels": [], "entities": [{"text": "identifying multiword expressions in natural language texts", "start_pos": 91, "end_pos": 150, "type": "TASK", "confidence": 0.6624108723231724}]}, {"text": "We define various linguistically motivated classification features and introduce novel ways for computing them.", "labels": [], "entities": []}, {"text": "We then manually define interrelationships among the features, and express them in a Bayesian network.", "labels": [], "entities": []}, {"text": "The result is a powerful classifier that can identify multiword expressions of various types and multiple syntactic constructions in text corpora.", "labels": [], "entities": []}, {"text": "Our methodology is unsupervised and language-independent; it requires relatively few language resources and is thus suitable fora large number of languages.", "labels": [], "entities": []}, {"text": "We report results on English, French, and Hebrew, and demonstrate a significant improvement in identification accuracy, compared with less sophisticated baselines.", "labels": [], "entities": [{"text": "identification", "start_pos": 95, "end_pos": 109, "type": "TASK", "confidence": 0.8915887475013733}, {"text": "accuracy", "start_pos": 110, "end_pos": 118, "type": "METRIC", "confidence": 0.9819820523262024}]}], "introductionContent": [{"text": "Multiword expressions (MWEs) are lexical items that consist of multiple orthographic words (ad hoc, New York, look up).", "labels": [], "entities": [{"text": "Multiword expressions (MWEs)", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.6949613213539123}]}, {"text": "MWEs constitute a significant portion of the lexicon of any natural language.", "labels": [], "entities": []}, {"text": "They area heterogeneous class of constructions with diverse sets of characteristics, distinguished by their idiosyncratic behavior.", "labels": [], "entities": []}, {"text": "Morphologically, some MWEs allow some of their constituents to freely inflect while restricting (or preventing) the inflection of other constituents.", "labels": [], "entities": []}, {"text": "In some cases MWEs may allow constituents to undergo non-standard morphological inflections that they would not undergo in isolation.", "labels": [], "entities": [{"text": "MWEs", "start_pos": 14, "end_pos": 18, "type": "TASK", "confidence": 0.96401047706604}]}, {"text": "Syntactically, some MWEs behave like words and other are phrases; some occur in one rigid pattern (and a fixed order), and others permit various syntactic transformations.", "labels": [], "entities": []}, {"text": "The most characteristic property of MWEs is their semantic opacity, although the compositionality of MWEs is gradual, and ranges from fully compositional to completely idiomatic).", "labels": [], "entities": []}, {"text": "Because of their prevalence and irregularity, MWEs must be stored in lexicons of natural language processing (NLP) applications.", "labels": [], "entities": []}, {"text": "Awareness of MWEs was proven beneficial fora variety of applications, including information retrieval), building ontologies (Venkatsubramanyan and), text alignment (, and machine translation (.", "labels": [], "entities": [{"text": "information retrieval", "start_pos": 80, "end_pos": 101, "type": "TASK", "confidence": 0.8095749020576477}, {"text": "text alignment", "start_pos": 149, "end_pos": 163, "type": "TASK", "confidence": 0.8468892872333527}, {"text": "machine translation", "start_pos": 171, "end_pos": 190, "type": "TASK", "confidence": 0.7955870926380157}]}, {"text": "We propose a novel architecture for identifying MWEs, of various types and syntactic categories, in monolingual corpora.", "labels": [], "entities": [{"text": "identifying MWEs", "start_pos": 36, "end_pos": 52, "type": "TASK", "confidence": 0.5956910848617554}]}, {"text": "Unlike much existing work, which focuses on a particular syntactic construction, our approach addresses MWEs of various types by zooming in on the general idiosyncratic properties of MWEs rather than on specific properties of each subclass thereof.", "labels": [], "entities": []}, {"text": "Addressing multiple types of MWEs has its limitations: The task is less well-defined, one cannot rely on specific properties of a particular construction, and the type of the MWE is not extracted along with the candidate expression.", "labels": [], "entities": []}, {"text": "Nevertheless, there are clear benefits to such an approach.", "labels": [], "entities": []}, {"text": "Certain applications can benefit from a large, albeit untyped, mixed bag of MWEs; machine translation is an obvious candidate.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 82, "end_pos": 101, "type": "TASK", "confidence": 0.7580934762954712}]}, {"text": "Another use, which motivates our current work, is the construction of computational lexicons.", "labels": [], "entities": []}, {"text": "Clearly, manual supervision is required before MWE candidates are added to a high-precision lexicon, but our approach provides the lexicographer with a large-scale set of potential candidates.", "labels": [], "entities": [{"text": "MWE candidates", "start_pos": 47, "end_pos": 61, "type": "TASK", "confidence": 0.8781355321407318}]}, {"text": "We focus on bigrams only in this work, that is, on MWEs consisting of two consecutive tokens.", "labels": [], "entities": []}, {"text": "Many of the features we design, as well as the general architecture, can in principle be extended to longer MWEs, but we do not address longer (and, in particular, the harder case of non-contiguous) MWEs here.", "labels": [], "entities": []}, {"text": "The architecture uses Bayesian networks to express multiple interdependent linguistically motivated features.", "labels": [], "entities": []}, {"text": "First, we automatically generate a small (training) set of MWE and non-MWE bigrams (positive and negative instances, respectively) from a small parallel corpus.", "labels": [], "entities": []}, {"text": "We then define a set of linguistically motivated features that embody observed characteristics of MWEs.", "labels": [], "entities": []}, {"text": "We augment these by features that reflect collocation measures.", "labels": [], "entities": []}, {"text": "Finally, we define dependencies among these features, expressed in the structure of a Bayesian network model, which we then use for classification.", "labels": [], "entities": []}, {"text": "A Bayesian network (BN) is a directed graph whose nodes express the features used for classification and whose edges define causal relationships among these features.", "labels": [], "entities": []}, {"text": "In this architecture, learning does not result in a black box, expressed solely as feature weights.", "labels": [], "entities": []}, {"text": "Rather, the structure of the BN allows us to study the impact of different MWE features on the classification.", "labels": [], "entities": [{"text": "BN", "start_pos": 29, "end_pos": 31, "type": "DATASET", "confidence": 0.8013284802436829}]}, {"text": "The result is anew method for identifying MWEs of various types in text corpora.", "labels": [], "entities": [{"text": "identifying MWEs", "start_pos": 30, "end_pos": 46, "type": "TASK", "confidence": 0.5498497784137726}]}, {"text": "It combines statistics with an array of linguistically motivated features, organized in an architecture that reflects interdependencies among the features.", "labels": [], "entities": []}, {"text": "The contribution of this work is manifold.", "labels": [], "entities": []}, {"text": "1 First, we use existing approaches to MWE extraction to automatically generate training material.", "labels": [], "entities": [{"text": "MWE extraction", "start_pos": 39, "end_pos": 53, "type": "TASK", "confidence": 0.9950714707374573}]}, {"text": "Specifically, we use our earlier work to extract a set of positive and negative MWE candidates from a small parallel corpus, and use them for training a BN that can then extract anew set of MWEs from a potentially much larger monolingual corpus.", "labels": [], "entities": []}, {"text": "As a result, our method is completely unsupervised (more precisely, it does not require manual annotation; we do need several language resources, see Section 3.2).", "labels": [], "entities": []}, {"text": "Second, we propose several linguistically motivated features that can be computed from data and that are demonstrably productive for improving the accuracy of MWE identification.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 147, "end_pos": 155, "type": "METRIC", "confidence": 0.9979178309440613}, {"text": "MWE identification", "start_pos": 159, "end_pos": 177, "type": "TASK", "confidence": 0.9835092127323151}]}, {"text": "These features focus on the expression of linguistic idiosyncrasies of various types, a phenomenon typical of MWEs.", "labels": [], "entities": []}, {"text": "Some of these features are commonplace, but others are new, or are implemented in novel ways.", "labels": [], "entities": []}, {"text": "In particular, we account for the morphological idiosyncrasy of MWEs using a histogram of the number of inflected forms, in a technique that draws from image processing.", "labels": [], "entities": []}, {"text": "We also use frequency histograms to model the semantic contexts of MWEs.", "labels": [], "entities": []}, {"text": "Finally, the methodology we advocate is not language-specific; given relatively few language resources, it can be easily adapted to new languages.", "labels": [], "entities": []}, {"text": "We demonstrate the generality of our methodology by applying it to three languages: English, French, and Hebrew.", "labels": [], "entities": []}, {"text": "Our evaluation shows that the use of linguistically motivated features results in a reduction of between one quarter and one third of the errors compared with a collocation baseline; organizing the knowledge in a Bayesian network reduces the error rate by an additional 3-9%.", "labels": [], "entities": [{"text": "error rate", "start_pos": 242, "end_pos": 252, "type": "METRIC", "confidence": 0.9601694643497467}]}, {"text": "After discussing related work in the next section (borrowing from Tsvetkov and Wintner), we motivate in Section 3 the methodology we propose, and list the resources needed for implementing it.", "labels": [], "entities": []}, {"text": "Section 4 discusses the linguistically motivated features and their implementation; the organization of the Bayesian network is described in Section 5.", "labels": [], "entities": []}, {"text": "We explain how we generate training materials in Section 6.", "labels": [], "entities": []}, {"text": "Section 7 provides a thorough evaluation of the results.", "labels": [], "entities": []}, {"text": "We conclude with suggestions for future research.", "labels": [], "entities": []}], "datasetContent": [{"text": "We use the training data described in Section 6 for training and evaluation: We perform 10-fold cross validation experiments, reporting accuracy and (balanced) F-score in three set-ups: One (SVM) in which we train an SVM classifier 5 with the features described in Section 4; one (BN-auto) in which we train a Bayesian network with these features, but let Weka determine its structure (using the K2 algorithm); and one (BN) in which we train a Bayesian network whose structure reflects manually crafted linguistically motivated knowledge, as depicted in.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 136, "end_pos": 144, "type": "METRIC", "confidence": 0.9967761635780334}, {"text": "F-score", "start_pos": 160, "end_pos": 167, "type": "METRIC", "confidence": 0.99623703956604}]}, {"text": "The results are listed in; they are compared with a PMI baseline, obtained by defining a Bayesian network with only two nodes, MWE and PMI.", "labels": [], "entities": []}, {"text": "The linguistically motivated features defined in Section 4 are clearly helpful in the classification task: The accuracy of an SVM, informed by these features, is close to 75% for Hebrew, over 78% for French, and as high as 83% for English, reducing the error rate of the PMI baseline by 23% (Hebrew) to 34% (English).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 111, "end_pos": 119, "type": "METRIC", "confidence": 0.9995328187942505}, {"text": "error rate", "start_pos": 253, "end_pos": 263, "type": "METRIC", "confidence": 0.9882376194000244}]}, {"text": "The contribution of the BN is also highly significant, reducing 3-9% more errors (with respect to the errors made by the SVM classifier).", "labels": [], "entities": [{"text": "BN", "start_pos": 24, "end_pos": 26, "type": "METRIC", "confidence": 0.9320333003997803}, {"text": "errors", "start_pos": 74, "end_pos": 80, "type": "METRIC", "confidence": 0.972679078578949}]}, {"text": "In total, the best method, BN, reduces the error rate of the PMIbased classifier by one third.", "labels": [], "entities": [{"text": "BN", "start_pos": 27, "end_pos": 29, "type": "METRIC", "confidence": 0.9850202798843384}, {"text": "error rate", "start_pos": 43, "end_pos": 53, "type": "METRIC", "confidence": 0.9843432605266571}]}, {"text": "Interestingly, a BN whose structure does not reflect prior knowledge, but is rather learned automatically, performs worse than these two methods (but still much better than relying on PMI alone).", "labels": [], "entities": []}, {"text": "It is the combination of linguistically motivated features with feature interdependencies reflecting domain knowledge that contribute to the best performance.", "labels": [], "entities": []}, {"text": "We did not investigate the contribution of each of the features to the classification task.", "labels": [], "entities": [{"text": "classification task", "start_pos": 71, "end_pos": 90, "type": "TASK", "confidence": 0.9112222492694855}]}, {"text": "However, we did analyze the weights assigned by the SVM classifier to specific features.", "labels": [], "entities": []}, {"text": "Unsurprisingly, the most distinctive feature is PMI.", "labels": [], "entities": [{"text": "PMI", "start_pos": 48, "end_pos": 51, "type": "METRIC", "confidence": 0.6335144639015198}]}, {"text": "Among the POS features, the strongest feature is VB NNS, an indication of a negative instance.", "labels": [], "entities": [{"text": "VB NNS", "start_pos": 49, "end_pos": 55, "type": "DATASET", "confidence": 0.5090194046497345}]}, {"text": "Capitalization is also unsurprisingly a very strong feature.", "labels": [], "entities": []}, {"text": "We leave a more systematic analysis of the contribution of each feature to future work.", "labels": [], "entities": []}, {"text": "To further assess the quality of the results, we performed a human evaluation on the English data set.", "labels": [], "entities": [{"text": "English data set", "start_pos": 85, "end_pos": 101, "type": "DATASET", "confidence": 0.9403618971506754}]}, {"text": "We first produced the results in the BN set-up, and then sorted both the (predicted) positive and the (predicted) negative instances by their PMI.", "labels": [], "entities": [{"text": "BN set-up", "start_pos": 37, "end_pos": 46, "type": "DATASET", "confidence": 0.7547767758369446}, {"text": "PMI", "start_pos": 142, "end_pos": 145, "type": "METRIC", "confidence": 0.9627895355224609}]}, {"text": "We randomly picked 100 instances of both lists, at the same positions in the ranked lists, to constitute an evaluation set.", "labels": [], "entities": []}, {"text": "We asked three English-speaking annotators to determine whether the 200 expressions were indeed MWEs.", "labels": [], "entities": []}, {"text": "The annotation guidelines are given in Appendix A. Comparing the three annotators' labels, we found out that they agreed on 141 of the 200 (70.5%).", "labels": [], "entities": []}, {"text": "This should probably betaken as an upper bound for the task.", "labels": [], "entities": []}, {"text": "We then computed the majority label and compared it with our predicted label.", "labels": [], "entities": []}, {"text": "Exactly 142 of the predicted labels were annotated as correct; that's an accuracy of 71%.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 73, "end_pos": 81, "type": "METRIC", "confidence": 0.9993916749954224}]}, {"text": "Of the 141 instances that the three annotators agreed on, our results predict the correct label for 112 instances (79.4%).", "labels": [], "entities": []}, {"text": "We take these figures as a strong indication of the accuracy of the results.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 52, "end_pos": 60, "type": "METRIC", "confidence": 0.9993127584457397}]}, {"text": "As an additional evaluation measure, we use the sets of bigrams in the English WordNet, and the bigram MWEs in the DELA dictionaries of English and French (Section 3.2).", "labels": [], "entities": [{"text": "English WordNet", "start_pos": 71, "end_pos": 86, "type": "DATASET", "confidence": 0.8319225907325745}, {"text": "DELA dictionaries of English and French", "start_pos": 115, "end_pos": 154, "type": "DATASET", "confidence": 0.9122912188371023}]}, {"text": "Because we only have positive instances in these evaluation sets, we can only report recall.", "labels": [], "entities": [{"text": "recall", "start_pos": 85, "end_pos": 91, "type": "METRIC", "confidence": 0.9933342933654785}]}, {"text": "We therefore use the Bayesian network classifier to extract MWEs from the large monolingual corpora discussed in Section 3.2.", "labels": [], "entities": []}, {"text": "For each evaluation set (WordNet, DELA English, and DELA French), we divide the number of bigrams in the set that are classified as MWEs by the size of the intersection of the evaluation set with the monolingual corpus.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 25, "end_pos": 32, "type": "DATASET", "confidence": 0.9361704587936401}, {"text": "DELA French", "start_pos": 52, "end_pos": 63, "type": "DATASET", "confidence": 0.8634665608406067}]}, {"text": "In other words, we exclude from the evaluation those MWEs in the evaluation set that never occur in our corpora.", "labels": [], "entities": []}, {"text": "The results are listed in.", "labels": [], "entities": []}, {"text": "As examples of correctly identified MWEs, consider English advisory board, air cargo, adoption agency, air ticket, crude oil, and soon, and French accord international 'international agreement', acte final 'final act', banque centrale 'central bank', ce soir 'tonight', and so forth, all taken from the DELA dictionaries.", "labels": [], "entities": [{"text": "DELA dictionaries", "start_pos": 303, "end_pos": 320, "type": "DATASET", "confidence": 0.9400657117366791}]}, {"text": "The relatively low recall of our method on these dictionaries is to a large extent due to a very liberal definition of MWEs that the dictionaries use.", "labels": [], "entities": [{"text": "recall", "start_pos": 19, "end_pos": 25, "type": "METRIC", "confidence": 0.9994483590126038}]}, {"text": "Many entries that are listed as MWEs are actually highly compositional, and hence our method fails to identify them.", "labels": [], "entities": []}, {"text": "DELA entries that are not identified by our classifier include examples such as English abnormal behavior, absolute necessity, academic research, and soon.", "labels": [], "entities": [{"text": "soon", "start_pos": 150, "end_pos": 154, "type": "METRIC", "confidence": 0.979714572429657}]}, {"text": "The French DELA dictionary is especially extensive, with examples such as action sociale, action antitumorale, action associative, action caritative, action collective, action commerciale, action communautaire, and many more, all listed as MWEs.", "labels": [], "entities": [{"text": "French DELA dictionary", "start_pos": 4, "end_pos": 26, "type": "DATASET", "confidence": 0.8893582622210184}]}, {"text": "Our system only recognizes the first of these.", "labels": [], "entities": []}, {"text": "The WordNet results are obviously much better.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 4, "end_pos": 11, "type": "DATASET", "confidence": 0.9632998704910278}]}, {"text": "Correctly identified MWEs include ad hoc, outer space, website, inter alia, road map, and so forth.", "labels": [], "entities": []}, {"text": "WordNet MWEs that our system failed to identify include has been, as well, in this, a few, setup, and soon.", "labels": [], "entities": [{"text": "WordNet MWEs", "start_pos": 0, "end_pos": 12, "type": "DATASET", "confidence": 0.9587394893169403}]}, {"text": "A more involved error analysis is required in order to propose potential directions for improvement on this set.", "labels": [], "entities": []}, {"text": "As a further demonstration of the utility of our approach, we evaluate the algorithm on the set NN of Hebrew noun-noun constructions described in Section 3.2.", "labels": [], "entities": []}, {"text": "We train a Bayesian network on the training set described in Section 6 and use it to classify the set NN.", "labels": [], "entities": []}, {"text": "We compare the results of this classifier with a PMI baseline, and also with the classification results reported by; the latter reflects 10-fold cross-validation evaluation using the entire set, so it maybe considered an upper bound for any classifier that uses a general training corpus.", "labels": [], "entities": [{"text": "PMI baseline", "start_pos": 49, "end_pos": 61, "type": "DATASET", "confidence": 0.7203516066074371}]}, {"text": "The results are depicted in.", "labels": [], "entities": []}, {"text": "They clearly demonstrate that the linguistically motivated features we define provide a significant improvement in classification accuracy over the baseline PMI measure.", "labels": [], "entities": [{"text": "classification", "start_pos": 115, "end_pos": 129, "type": "TASK", "confidence": 0.9283488988876343}, {"text": "accuracy", "start_pos": 130, "end_pos": 138, "type": "METRIC", "confidence": 0.9625915288925171}]}, {"text": "Note that our F-score, 0.77, is very close to the best result of 0.79 obtained by as the average of 10-fold cross validation runs, using only high-frequency noun-noun constructions for training.", "labels": [], "entities": [{"text": "F-score", "start_pos": 14, "end_pos": 21, "type": "METRIC", "confidence": 0.9991427659988403}]}, {"text": "We interpret this result as a further proof of the robustness of our architecture.", "labels": [], "entities": []}, {"text": "Finally, we conduct an analysis of the quality of extracted (Hebrew) MWEs.", "labels": [], "entities": []}, {"text": "We used the trained BN to classify the entire set of bigrams present in the (Hebrew side of the) Hebrew-English parallel corpus described in Section 3.2.", "labels": [], "entities": [{"text": "BN", "start_pos": 20, "end_pos": 22, "type": "METRIC", "confidence": 0.8094409108161926}]}, {"text": "Of the more than 140,000 candidates, only 4,000 are classified as MWEs.", "labels": [], "entities": []}, {"text": "We sort this list of potential MWEs by the probability assigned by the BN to the positive value of the variable X mwe . The resulting sorted list is dominated by high-PMI bigrams, especially proper names, all of which are indeed MWEs.", "labels": [], "entities": [{"text": "BN", "start_pos": 71, "end_pos": 73, "type": "METRIC", "confidence": 0.9641209244728088}]}, {"text": "The first non-MWE (false positive) occurs in the 50th place on the list; it is crpt niqwla 'France Nicolas', which is obviously a sub-sequence of the larger MWE, neia crpt niqwla srqwzi 'French president Nicolas Sarkozy'.", "labels": [], "entities": []}, {"text": "Similar sub-sequences are also present, but only five are in the top 100.", "labels": [], "entities": []}, {"text": "Such false positives can be reduced when longer MWEs are extracted, as it can be assumed that a sub-sequence of a longer MWE does not have to be identified.", "labels": [], "entities": []}, {"text": "Other false positives in the top 100 include some highly frequent expressions, but over 85 of the top 100 are clearly MWEs.", "labels": [], "entities": []}, {"text": "Although more careful evaluation is required in order to estimate the rate of true positives in this list, we trust that the vast majority of the positive results are indeed MWEs.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1  Statistics of the monolingual corpora.", "labels": [], "entities": []}, {"text": " Table 2  Statistics of the bilingual corpora.", "labels": [], "entities": []}, {"text": " Table 3  F-score as a function of the value of the prior.", "labels": [], "entities": [{"text": "F-score", "start_pos": 10, "end_pos": 17, "type": "METRIC", "confidence": 0.9978949427604675}]}, {"text": " Table 4  Sizes of the training sets.", "labels": [], "entities": []}, {"text": " Table 7. They clearly demonstrate that the linguistically  motivated features we define provide a significant improvement in classification accu- racy over the baseline PMI measure. Note that our F-score, 0.77, is very close to the", "labels": [], "entities": [{"text": "F-score", "start_pos": 197, "end_pos": 204, "type": "METRIC", "confidence": 0.9984472393989563}]}, {"text": " Table 6  Evaluation results: WordNet and DELA dictionaries.  True positives Evaluation set size Recall (%)", "labels": [], "entities": [{"text": "WordNet", "start_pos": 30, "end_pos": 37, "type": "DATASET", "confidence": 0.9584082365036011}, {"text": "True positives Evaluation set size", "start_pos": 62, "end_pos": 96, "type": "METRIC", "confidence": 0.7876207232475281}, {"text": "Recall", "start_pos": 97, "end_pos": 103, "type": "METRIC", "confidence": 0.7100754380226135}]}, {"text": " Table 7  Evaluation results: noun-noun constructions.", "labels": [], "entities": []}]}