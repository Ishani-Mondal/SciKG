{"title": [{"text": "Applications of Lexicographic Semirings to Problems in Speech and Language Processing", "labels": [], "entities": []}], "abstractContent": [{"text": "This article explores lexicographic semirings and their application to problems in speech and language processing.", "labels": [], "entities": [{"text": "speech and language processing", "start_pos": 83, "end_pos": 113, "type": "TASK", "confidence": 0.6322359591722488}]}, {"text": "Specifically, we present two instantiations of binary lexicographic semirings, one involving a pair of tropical weights, and the other a tropical weight paired with a novel string semiring we term the categorial semiring.", "labels": [], "entities": []}, {"text": "The first of these is used to yield an exact encoding of backoff models with epsilon transitions.", "labels": [], "entities": []}, {"text": "This lexicographic language model semiring allows for off-line optimization of exact models represented as large weighted finite-state transducers in contrast to implicit (on-line) failure transition representations.", "labels": [], "entities": []}, {"text": "We present empirical results demonstrating that, even in simple intersection scenarios amenable to the use of failure transitions, the use of the more powerful lexicographic semiring is competitive in terms of time of intersection.", "labels": [], "entities": []}, {"text": "The second of these lexicographic semirings is applied to the problem of extracting, from a lattice of word sequences tagged for part of speech, only the single best-scoring part of speech tagging for each word sequence.", "labels": [], "entities": []}, {"text": "We do this by incorporating the tags as a categorial weight in the second component of a Tropical, Categorial lexicographic semiring, determinizing the resulting word lattice acceptor in that semiring, and then mapping the tags back as output labels of the word lattice transducer.", "labels": [], "entities": []}, {"text": "We compare our approach to a competing method due to Povey et al.", "labels": [], "entities": []}], "introductionContent": [{"text": "Applications of finite-state methods to problems in speech and language processing have grown significantly over the last decade and a half.", "labels": [], "entities": [{"text": "speech and language processing", "start_pos": 52, "end_pos": 82, "type": "TASK", "confidence": 0.67610302567482}]}, {"text": "From their beginnings in the 1950s and 1960s to implement small hand-built grammars (e.g., through their applications in computational morphology in the 1980s, finite-state models are now routinely applied in areas ranging from parsing, to machine translation (), text normalization, and various areas of speech recognition including pronunciation modeling and language modeling.", "labels": [], "entities": [{"text": "parsing", "start_pos": 228, "end_pos": 235, "type": "TASK", "confidence": 0.9609795808792114}, {"text": "machine translation", "start_pos": 240, "end_pos": 259, "type": "TASK", "confidence": 0.7048272490501404}, {"text": "text normalization", "start_pos": 264, "end_pos": 282, "type": "TASK", "confidence": 0.8161305487155914}, {"text": "speech recognition", "start_pos": 305, "end_pos": 323, "type": "TASK", "confidence": 0.722469761967659}, {"text": "pronunciation modeling", "start_pos": 334, "end_pos": 356, "type": "TASK", "confidence": 0.899821400642395}, {"text": "language modeling", "start_pos": 361, "end_pos": 378, "type": "TASK", "confidence": 0.7712633609771729}]}, {"text": "The development of weighted finite state approaches) has made it possible to implement models that can rank alternative analyses.", "labels": [], "entities": []}, {"text": "A number of weight classes-semirings-can be defined (), though for all practical purposes nearly all actual applications use the tropical semiring, whose most obvious instantiation is as away to combine negative log probabilities of words in a hypothesis in speech recognition systems.", "labels": [], "entities": []}, {"text": "With few exceptions (e.g.,, there has been relatively little work on exploring applications of different semirings, in particular structured semirings consisting of tuples of weights.", "labels": [], "entities": []}, {"text": "In this article we explore the use of what we term lexicographic semirings, which are tuples of weights where the comparison between a pair of tuples starts by comparing the first element of the tuple, then the second, and so forth until unequal values are found-just as lexicographic order is determined between words.", "labels": [], "entities": []}, {"text": "We investigate two such lexicographic semirings, one based on pairs of tropical weights, and the other that uses a tropical weight paired with a novel string weight that we call the categorial semiring.", "labels": [], "entities": []}, {"text": "The latter is based loosely on the operations of categorial grammar.", "labels": [], "entities": []}, {"text": "We use the first semiring to provide an exact encoding of language models as weighted finite-state transducers using epsilon arcs in place of failure arcs.", "labels": [], "entities": []}, {"text": "The second we apply to the problem of selecting only the single-best tagging for each word sequence in a tagged lattice.", "labels": [], "entities": []}, {"text": "In each case we formally justify the application and demonstrate the correctness and efficiency on real domains.", "labels": [], "entities": []}], "datasetContent": [{"text": "For our experiments we used lattices derived from a very large vocabulary continuous speech recognition system, which was built for the 2007 GALE Arabic speech recognition task, and used in the work reported in.", "labels": [], "entities": [{"text": "GALE Arabic speech recognition task", "start_pos": 141, "end_pos": 176, "type": "TASK", "confidence": 0.6858093678951264}]}, {"text": "The lexicographic semiring was evaluated on the development set (2.6 hours of broadcast news and conversations; 18K words).", "labels": [], "entities": []}, {"text": "The 888 word lattices for the development set were generated using a competitive baseline system with acoustic models trained on about 1,000 hours of Arabic broadcast data and a 4-gram language model.", "labels": [], "entities": []}, {"text": "The language model consisting of 122M n-grams was estimated by interpolating 14 components.", "labels": [], "entities": []}, {"text": "The vocabulary is relatively large at 737K, and the associated dictionary has only single pronunciations.", "labels": [], "entities": []}, {"text": "The language model was converted to the automaton topology described earlier, using OpenFst (, and represented in three ways: (1) as an approximation of a failure machine using epsilons instead of failure arcs; (2) as a correct failure machine; and (3) using the lexicographic construction derived in this article.", "labels": [], "entities": []}, {"text": "Note that all of these options are available for representing language models in the OpenGrm library).", "labels": [], "entities": []}, {"text": "The three versions of the LM were evaluated by intersecting them with the 888 lattices of the development set.", "labels": [], "entities": []}, {"text": "The overall error rate for the systems was 24.8%-comparable to the state-of-the-art on this task.", "labels": [], "entities": [{"text": "error rate", "start_pos": 12, "end_pos": 22, "type": "METRIC", "confidence": 0.9880590438842773}]}, {"text": "For the shortest paths, the failure and lexicographic machines always produced identical lattices (as determined by FST equivalence); in contrast, 78.6% of the shortest paths from the epsilon approximation are different, at least in terms of weights, from the shortest paths using the failure LM.", "labels": [], "entities": []}, {"text": "For full lattices 6.1% of the lexicographic outputs differ from the failure LM outputs, due to small floating point rounding issues; 98.9% of the epsilon approximation outputs differ.", "labels": [], "entities": []}, {"text": "In terms of size, the failure LM, with 5.7 million arcs, requires 97 Mb.", "labels": [], "entities": []}, {"text": "The equivalent T , T -lexicographic LM requires 120 Mb, due to the doubling of the size of the weights.", "labels": [], "entities": []}, {"text": "To measure speed, we performed the intersections 1,000 times for each of our 888 lattices on a 2993 MHz Intel Xeon CPU, and took the mean times for each of our methods.", "labels": [], "entities": []}, {"text": "The 888 lattices were processed with a mean of 1.62 seconds in total (1.8 msec per lattice) using the failure LM; using the T , T -lexicographic LM required 1.8 seconds (2.0 msec per lattice), and is thus about 11% slower.", "labels": [], "entities": []}, {"text": "Epsilon approximation, where the failure arcs are approximated with epsilon arcs, took 1.17 seconds (1.3 msec per lattice).", "labels": [], "entities": []}, {"text": "The slightly slower speeds for the exact method using the failure LM, and T , T are due to the overhead of (1) computation of the failure function at runtime for the failure LM, and (2) determinization for the T , T representation.", "labels": [], "entities": []}, {"text": "After intersection (and determinization, if required), there is no size difference in the lattices resulting from any of the three methods.", "labels": [], "entities": []}, {"text": "In this section we have shown that the failure-arc representation of backoff in a finite-state language model topology can be exactly represented using arcs, and weights in the T , T lexicographic semiring.", "labels": [], "entities": []}, {"text": "We turn in the next section to another application of lexicographic semirings, this time involving a novel string semiring as one of the components.", "labels": [], "entities": []}, {"text": "T , C-Lexicographic Semirings 3.4.1 POS-Tagging Problem.", "labels": [], "entities": []}, {"text": "Our solutions were empirically evaluated on 4,664 lattices from the NIST English CTS RT Dev04 test set.", "labels": [], "entities": [{"text": "NIST English CTS RT Dev04 test set", "start_pos": 68, "end_pos": 102, "type": "DATASET", "confidence": 0.9705475739070347}]}, {"text": "The lattices were generated using a state-of-the-art speech recognizer, similar to, trained on about 2,000 hours of data, which performed at a word error rate of about 24%.", "labels": [], "entities": []}, {"text": "The utterances were decoded in three stages using speaker independent models, vocal-tract length normalized models, and speaker-adapted models.", "labels": [], "entities": []}, {"text": "The three sets of models were similar in complexity with 8,000 clustered pentaphone states and 150K Gaussians with diagonal covariances.", "labels": [], "entities": []}, {"text": "The lattices from the recognizer were tagged using a weighted finite state tagger.", "labels": [], "entities": []}, {"text": "The tagger was trained on the Switchboard portion of the Penn Treebank.", "labels": [], "entities": [{"text": "Penn Treebank", "start_pos": 57, "end_pos": 70, "type": "DATASET", "confidence": 0.9172279238700867}]}, {"text": "Further, many of the words in the recognizer vocabulary of 93k words are unobserved in tagger training, and are mapped to an OOV token \"unk\".", "labels": [], "entities": []}, {"text": "Words in the treebank not in the recognizer vocabulary are also mapped to \"unk\", thus providing probability mass for that token in the tagger.", "labels": [], "entities": []}, {"text": "A tokenization transducer T was created to map from recognizer vocabulary to tagger vocabulary.", "labels": [], "entities": []}, {"text": "Two POS-tagging models were trained: a first-order and a third-order hidden Markov model (HMM), estimated and encoded in tagging transducers P.", "labels": [], "entities": []}, {"text": "In the firstorder HMM model, the transition probability is conditioned on the previous word's tag, whereas in the third-order model the transition probability is conditioned on the previous three words' tags.", "labels": [], "entities": []}, {"text": "The transition probabilities are smoothed using Witten-Bell smoothing, and backoff smoothing is achieved using failure transitions.", "labels": [], "entities": []}, {"text": "For each word in the tagger input vocabulary, only POS-tags observed with each word are allowed for that word; that is, emission probability is not smoothed and is zero for unobserved tag/word pairs.", "labels": [], "entities": []}, {"text": "For a given word lattice L, it is first composed with the tokenizer T , then with the POS tagger P to produce a transducer with original lattice word strings on the input side and tag strings on the output side.", "labels": [], "entities": []}, {"text": "These models were validated on a 2,000-sentence held-aside subset of the Switchboard treebank.", "labels": [], "entities": [{"text": "Switchboard treebank", "start_pos": 73, "end_pos": 93, "type": "DATASET", "confidence": 0.9386283457279205}]}, {"text": "The first-order model achieved 91.4% tagging accuracy, and the thirdorder model 93.8% accuracy, which is competitive for this particular task: Eidelman, Huang, and Harper (2010) reported accuracy of 92.4% for an HMM tagger on this task (though fora different validation set).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 45, "end_pos": 53, "type": "METRIC", "confidence": 0.9513291120529175}, {"text": "accuracy", "start_pos": 86, "end_pos": 94, "type": "METRIC", "confidence": 0.9993399977684021}, {"text": "accuracy", "start_pos": 187, "end_pos": 195, "type": "METRIC", "confidence": 0.9989302754402161}, {"text": "HMM tagger", "start_pos": 212, "end_pos": 222, "type": "TASK", "confidence": 0.8143422901630402}]}, {"text": "Both models likely suffer from using a single \"unk\" category, which is relatively coarse and does not capture informative suffix and prefix features that are common in such models for tagging OOVs.", "labels": [], "entities": [{"text": "tagging OOVs", "start_pos": 184, "end_pos": 196, "type": "TASK", "confidence": 0.7808234989643097}]}, {"text": "For the purposes of this article, these models serve to demonstrate the utility of the new lexicographic semiring using realistic models.", "labels": [], "entities": []}, {"text": "A similar WFST topology can be used for discriminatively trained models using richer feature sets, which would potentially achieve higher accuracy on the task.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 138, "end_pos": 146, "type": "METRIC", "confidence": 0.9943753480911255}]}, {"text": "The tagged lattices, obtained from composing the ASR lattice with the POS tagger, were then converted to T , C-lexicographic semiring, determinized in this lexicographic semiring, and then converted back using the mapper transducer as discussed in Section 3.3.1.", "labels": [], "entities": []}, {"text": "Note that the computational cost of this conversion is proportional to the number of arcs in the lattice and hence is significantly lower than the overhead incurred in the conventional approach of extracting all unique paths in the lattice and converting the paths back to a lattice after tagging.", "labels": [], "entities": []}, {"text": "The results of this operation were compared with the method of taking the 1,000 best paths through the original lattice, and removing any path where the path's word sequence had been seen in a lower-cost path.", "labels": [], "entities": []}, {"text": "This generally resulted in a rank-ordered set of paths with n < 1, 000 members.", "labels": [], "entities": []}, {"text": "In all cases the n-best paths produced by the method proposed in this article were identical to the n-best paths produced by the method just described.", "labels": [], "entities": []}, {"text": "The only differences were due to minor floating-point number differences (expected due to weightpushing in determinization), and cases where equivalent weighted paths were output in different orders.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1  For first-order HMM tagger, comparison of the two approaches for extracting the best and  only the best POS for all the word sequences in the test lattice. The approach by Povey et al.  as implemented in Kaldi using a specialized determinization and our re-implementation in  OpenFST with general determinization.", "labels": [], "entities": [{"text": "HMM tagger", "start_pos": 26, "end_pos": 36, "type": "TASK", "confidence": 0.8618227243423462}]}, {"text": " Table 2  For third-order HMM tagger, comparison of the two approaches for extracting the best and only  the best POS for all the word sequences in the test lattice. The approach by Povey et al. as  implemented in Kaldi using a specialized determinization and our re-implementation in  OpenFST with general determinization.", "labels": [], "entities": [{"text": "HMM tagger", "start_pos": 26, "end_pos": 36, "type": "TASK", "confidence": 0.834280252456665}]}]}