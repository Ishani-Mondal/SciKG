{"title": [{"text": "Improved Estimation of Entropy for Evaluation of Word Sense Induction", "labels": [], "entities": [{"text": "Evaluation of Word Sense Induction", "start_pos": 35, "end_pos": 69, "type": "TASK", "confidence": 0.646369731426239}]}], "abstractContent": [{"text": "Information-theoretic measures are among the most standard techniques for evaluation of clustering methods including word sense induction (WSI) systems.", "labels": [], "entities": [{"text": "word sense induction (WSI)", "start_pos": 117, "end_pos": 143, "type": "TASK", "confidence": 0.7647583683331808}]}, {"text": "Such measures rely on sample-based estimates of the entropy.", "labels": [], "entities": []}, {"text": "However, the standard maximum likelihood estimates of the entropy are heavily biased with the bias dependent on, among other things, the number of clusters and the sample size.", "labels": [], "entities": []}, {"text": "This makes the measures unreliable and unfair when the number of clusters produced by different systems vary and the sample size is not exceedingly large.", "labels": [], "entities": []}, {"text": "This corresponds exactly to the setting of WSI evaluation where a ground-truth cluster sense number arguably does not exist and the standard evaluation scenarios use a small number of instances of each word to compute the score.", "labels": [], "entities": [{"text": "WSI evaluation", "start_pos": 43, "end_pos": 57, "type": "TASK", "confidence": 0.8732925951480865}]}, {"text": "We describe more accurate entropy estimators and analyze their performance both in simulations and on evaluation of WSI systems.", "labels": [], "entities": [{"text": "entropy estimators", "start_pos": 26, "end_pos": 44, "type": "TASK", "confidence": 0.6940653324127197}]}], "introductionContent": [{"text": "The task of word sense induction (WSI) has grown in popularity recently.", "labels": [], "entities": [{"text": "word sense induction (WSI)", "start_pos": 12, "end_pos": 38, "type": "TASK", "confidence": 0.8708804051081339}]}, {"text": "WSI has the advantage of not assuming a predefined inventory of senses.", "labels": [], "entities": [{"text": "WSI", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.4985925853252411}]}, {"text": "Rather, senses are induced in an unsupervised fashion on the basis of corpus evidence.", "labels": [], "entities": []}, {"text": "WSI systems can therefore better adapt to different target domains that may require sense inventories of different granularities.", "labels": [], "entities": [{"text": "WSI", "start_pos": 0, "end_pos": 3, "type": "TASK", "confidence": 0.8099106550216675}]}, {"text": "However, the fact that WSI systems do not rely on fixed inventories also makes it notoriously difficult to evaluate and compare their performance.", "labels": [], "entities": [{"text": "WSI", "start_pos": 23, "end_pos": 26, "type": "TASK", "confidence": 0.9372826814651489}]}, {"text": "WSI evaluation is a type of cluster evaluation problem.", "labels": [], "entities": [{"text": "WSI evaluation", "start_pos": 0, "end_pos": 14, "type": "TASK", "confidence": 0.9379830360412598}]}, {"text": "Although cluster evaluation has received much attention (see, e.g.,, it is still not a solved problem.", "labels": [], "entities": [{"text": "cluster evaluation", "start_pos": 9, "end_pos": 27, "type": "TASK", "confidence": 0.9680901765823364}]}, {"text": "Finding a good way to score partially incorrect clusters is particularly difficult.", "labels": [], "entities": []}, {"text": "Several solutions have been proposed but information theoretic measures have been among the most successful and widely used techniques.", "labels": [], "entities": []}, {"text": "One example is the normalized mutual information, also known as V-measure (, which has, for example, been adopted in the).", "labels": [], "entities": []}, {"text": "All information theoretic measures of cluster quality essentially rely on samplebased estimates of entropy.", "labels": [], "entities": []}, {"text": "For instance, the mutual information I(c, k) between a gold standard class c and an output cluster k can be written H(c) + H(k) \u2212 H(k, c), where H(c) and H(k) are the marginal entropies of c and k, respectively, and H(k, c) is their joint entropy.", "labels": [], "entities": []}, {"text": "The most standard estimator is the maximum-likelihood (ML) estimator, which substitutes the probability of each event (cluster, classes, or cluster-class pair occurrence) with its normalized empirical frequency.", "labels": [], "entities": []}, {"text": "Entropy estimators, even though consistent, are biased.", "labels": [], "entities": [{"text": "Entropy estimators", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.7355145812034607}]}, {"text": "This means that the expected estimate of the entropy on a finite sample set is different from the true value.", "labels": [], "entities": []}, {"text": "It is also different from an expected estimate on a larger test set generated from the same distribution, as the bias depends on the size of the sample.", "labels": [], "entities": []}, {"text": "This discrepancy negatively affects entropy-based evaluation measures, such as the V-measure.", "labels": [], "entities": []}, {"text": "This is different from supervised classification evaluation, where the classification accuracy on a finite test set is expected to be equal to the error rate (for the independent and identically distributed, i.i.d.) case, though it can be different due to variance (due to choice of the test set).", "labels": [], "entities": [{"text": "supervised classification evaluation", "start_pos": 23, "end_pos": 59, "type": "TASK", "confidence": 0.7273621062437693}, {"text": "accuracy", "start_pos": 86, "end_pos": 94, "type": "METRIC", "confidence": 0.8311301469802856}, {"text": "error rate", "start_pos": 147, "end_pos": 157, "type": "METRIC", "confidence": 0.9483969211578369}]}, {"text": "As long as the number of samples is large with respect to the number of classes and clusters, the estimate is sufficiently close to the true entropy.", "labels": [], "entities": []}, {"text": "Otherwise, the quality of entropy estimators matters and the bias of the estimator can be large.", "labels": [], "entities": []}, {"text": "This problem is especially prominent for the ML estimator.", "labels": [], "entities": [{"text": "ML estimator", "start_pos": 45, "end_pos": 57, "type": "TASK", "confidence": 0.7451059818267822}]}, {"text": "In WSI, we are faced with exactly those conditions that negatively affect the entropy estimators.", "labels": [], "entities": [{"text": "WSI", "start_pos": 3, "end_pos": 6, "type": "TASK", "confidence": 0.5016651153564453}]}, {"text": "Ina typical setting, the number of examples per word is small-for example, less than 100 on average for the SemEval 2010 WSI task.", "labels": [], "entities": [{"text": "SemEval 2010 WSI task", "start_pos": 108, "end_pos": 129, "type": "TASK", "confidence": 0.7426197081804276}]}, {"text": "The number of clusters, on the other hand, can be fairly high, with some systems outputting more than 10 sense clusters per word on average.", "labels": [], "entities": []}, {"text": "Because the bias of an entropy estimator is dependent on, among other things, the number of clusters, the ranking of different WSI systems is partly affected by the number of clusters they produce.", "labels": [], "entities": []}, {"text": "Even worse, the ranking is also affected by the size of the test set.", "labels": [], "entities": []}, {"text": "The problem is exacerbated when computing the joint entropy between clusters and classes, H(k, c), because this requires estimating the joint probability of cluster-class pairs for which the statistics are even more sparse.", "labels": [], "entities": []}, {"text": "The bias problem of entropy estimators has long been known in the information theory community and many studies have addressed this issue (e.g.,.", "labels": [], "entities": [{"text": "entropy estimators", "start_pos": 20, "end_pos": 38, "type": "TASK", "confidence": 0.8186969757080078}, {"text": "information theory", "start_pos": 66, "end_pos": 84, "type": "TASK", "confidence": 0.8509053885936737}]}, {"text": "In this article, we compare different estimators and their influence on the computed evaluation scores.", "labels": [], "entities": []}, {"text": "We run simulations using a Zipfian distribution where we know the true entropy.", "labels": [], "entities": []}, {"text": "We also compare different estimators against the SemEval 2010 WSI benchmark.", "labels": [], "entities": [{"text": "SemEval 2010 WSI benchmark", "start_pos": 49, "end_pos": 75, "type": "DATASET", "confidence": 0.7118436098098755}]}, {"text": "Our results strongly suggest that there are estimators, namely, the best-upper-bound (BUB) estimator and jackknifed) estimators, which are clearly preferable to the commonly used ML estimators.", "labels": [], "entities": [{"text": "BUB) estimator", "start_pos": 86, "end_pos": 100, "type": "METRIC", "confidence": 0.9306272268295288}]}], "datasetContent": [{"text": "To gauge the effect of the bias problem on WSI evaluation, we computed how the ranking of the SemEval 2010 systems () were affected by different estimators.", "labels": [], "entities": [{"text": "WSI evaluation", "start_pos": 43, "end_pos": 57, "type": "TASK", "confidence": 0.9098321497440338}, {"text": "SemEval 2010 systems", "start_pos": 94, "end_pos": 114, "type": "DATASET", "confidence": 0.7472612659136454}]}, {"text": "The SemEval 2010 organizers supplied a test set containing 8,915 manually annotated examples covering 100 polysemous lemmas.", "labels": [], "entities": []}, {"text": "The average number of gold standard senses per lemma was 3.79.", "labels": [], "entities": [{"text": "gold standard senses", "start_pos": 22, "end_pos": 42, "type": "METRIC", "confidence": 0.8222099343935648}]}, {"text": "Overall, 27 systems participated and were ranked according to their performance on the test set, applying the V-measure evaluation as well as paired F-score and a supervised evaluation scheme.", "labels": [], "entities": [{"text": "F-score", "start_pos": 149, "end_pos": 156, "type": "METRIC", "confidence": 0.9477947354316711}]}, {"text": "The systems were also compared against three baselines.", "labels": [], "entities": []}, {"text": "For the Most Frequent Sense (MFS) baseline all test instances of a given target lemma are grouped into one cluster, that is, there is exactly one cluster per lemma.", "labels": [], "entities": [{"text": "Most Frequent Sense (MFS) baseline", "start_pos": 8, "end_pos": 42, "type": "DATASET", "confidence": 0.5270870583398002}]}, {"text": "The second baseline, Random, assigns each instance randomly to one of four clusters.", "labels": [], "entities": []}, {"text": "The last baseline, proposed in, 1-cluster-per-instance (1ClI), produces as many clusters as there are instances in the test set.", "labels": [], "entities": []}, {"text": "gives an overview of the different systems and the three baselines (shown in italics).", "labels": [], "entities": []}, {"text": "The systems are presented in the order in which they were given in the official", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1  V-measure computed with different estimators. Supervised recall is shown for comparison  (80:20 and 60:40 splits for mapping/evaluation, numbers as provided by Manandhar et al. 2010).  The corresponding ranks are shown in parentheses.", "labels": [], "entities": [{"text": "recall", "start_pos": 67, "end_pos": 73, "type": "METRIC", "confidence": 0.953741192817688}]}]}