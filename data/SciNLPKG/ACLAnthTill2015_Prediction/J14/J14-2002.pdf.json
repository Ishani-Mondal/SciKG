{"title": [{"text": "Arc-Eager Parsing with the Tree Constraint", "labels": [], "entities": [{"text": "Arc-Eager Parsing", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.592947244644165}]}], "abstractContent": [{"text": "The arc-eager system for transition-based dependency parsing is widely used in natural language processing despite the fact that it does not guarantee that the output is a well-formed dependency tree.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 42, "end_pos": 60, "type": "TASK", "confidence": 0.7186573445796967}]}, {"text": "We propose a simple modification to the original system that enforces the tree constraint without requiring any modification to the parser training procedure.", "labels": [], "entities": []}, {"text": "Experiments on multiple languages show that the method on average achieves 72% of the error reduction possible and consistently outperforms the standard heuristic in current use.", "labels": [], "entities": [{"text": "error reduction", "start_pos": 86, "end_pos": 101, "type": "METRIC", "confidence": 0.9471219182014465}]}], "introductionContent": [{"text": "One of the most widely used transition systems for dependency parsing is the arceager system first described in, which has been used as the backbone for greedy deterministic dependency parsers, beam search parsers with structured prediction (, neural network parsers with latent variables, and delexicalized transfer parsers.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 51, "end_pos": 69, "type": "TASK", "confidence": 0.8526830971240997}, {"text": "greedy deterministic dependency parsers", "start_pos": 153, "end_pos": 192, "type": "TASK", "confidence": 0.7139424532651901}, {"text": "beam search parsers", "start_pos": 194, "end_pos": 213, "type": "TASK", "confidence": 0.6558415492375692}]}, {"text": "However, in contrast to most similar transition systems, the arc-eager system does not guarantee that the output is a well-formed dependency tree, which sometimes leads to fragmented parses and lower parsing accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 208, "end_pos": 216, "type": "METRIC", "confidence": 0.8395509123802185}]}, {"text": "Although various heuristics have been proposed to deal with this problem, there has so far been no clean theoretical solution that also gives good parsing accuracy.", "labels": [], "entities": [{"text": "parsing", "start_pos": 147, "end_pos": 154, "type": "TASK", "confidence": 0.9547044634819031}, {"text": "accuracy", "start_pos": 155, "end_pos": 163, "type": "METRIC", "confidence": 0.9090641140937805}]}, {"text": "In this article, we present a modified version of the original arc-eager system, which is provably correct for the class of projective dependency trees, which maintains the linear time complexity of greedy (or beam search) parsers, and which does not require any modifications to the parser training procedure.", "labels": [], "entities": []}, {"text": "Experimental evaluation on the CoNLL-X data sets show that the new system consistently outperforms the standard heuristic in current use, on average achieving 72% of the error reduction possible (compared with 41% for the old heuristic).", "labels": [], "entities": [{"text": "CoNLL-X data sets", "start_pos": 31, "end_pos": 48, "type": "DATASET", "confidence": 0.9700678984324137}, {"text": "error reduction", "start_pos": 170, "end_pos": 185, "type": "METRIC", "confidence": 0.9737855195999146}]}], "datasetContent": [{"text": "In our empirical evaluation we make use of the open-source system MaltParser (Nivre, Hall, and Nilsson 2006), which is a data-driven parser-generator for transition-based dependency parsing supporting the use of different transition systems.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 171, "end_pos": 189, "type": "TASK", "confidence": 0.6542218327522278}]}, {"text": "Besides the original arc-eager system, which is already implemented in MaltParser, we have added an implementation of the new modified system.", "labels": [], "entities": [{"text": "MaltParser", "start_pos": 71, "end_pos": 81, "type": "DATASET", "confidence": 0.9394059777259827}]}, {"text": "The training procedure used in MaltParser derives an oracle transition sequence for each sentence and gold tree in the training corpus and uses every configuration-transition pair in these sequences as a training instance fora multi-class classifier.", "labels": [], "entities": []}, {"text": "Because the oracle sequences in the arceager system always produce a well-formed tree, there will be no training instances corresponding to the extended transition sequences in the new system (i.e., sequences containing one or more non-terminal configurations of the form (\u03c3, [ ], A)).", "labels": [], "entities": []}, {"text": "However, because the Unshift transition is only used in completely deterministic cases, where the classifier is not called upon to rank alternative transitions, we can make use of exactly the same classifier for both the old and the new system.", "labels": [], "entities": []}, {"text": "We compare the original and modified arc-eager systems on all 13 data sets from the CoNLL-X shared task on multilingual dependency parsing), which all assume the existence of a dummy root word prefixed to the sentence.", "labels": [], "entities": [{"text": "CoNLL-X shared task on multilingual dependency parsing", "start_pos": 84, "end_pos": 138, "type": "TASK", "confidence": 0.664531409740448}]}, {"text": "We tune the feature representations separately for each language and projectivize the training data for languages with non-projective dependencies but otherwise use default settings in MaltParser (including the standard heuristic of attaching any unattached tokens to the artificial root node at the end of parsing for the original system).", "labels": [], "entities": []}, {"text": "Because we want to perform a detailed error analysis for fragmented parses, we initially avoid using the dedicated test set for each language and instead report results on a development set created by splitting off 10% of the training data.", "labels": [], "entities": []}, {"text": "(columns 2-3) shows the unlabeled attachment score (including punctuation) achieved with the two systems.", "labels": [], "entities": [{"text": "attachment score", "start_pos": 34, "end_pos": 50, "type": "METRIC", "confidence": 0.8630558252334595}]}, {"text": "We see that the new system improves over the old one by 0.19 percentage points on average, with individual improvements ranging from 0.00 (Japanese) to 0.50 (Slovene).", "labels": [], "entities": []}, {"text": "These differences may seem quantitatively small, but it must be remembered that the unattached tokens left on the stack in fragmented parses constitute a very small fraction of the total number of tokens on which these scores are calculated.", "labels": [], "entities": []}, {"text": "In order to get a more fine-grained picture of the behavior of the two systems, we therefore zoom in specifically on these tokens in the rest of.", "labels": [], "entities": []}, {"text": "Column 4 shows the number of unattached tokens left on the stack when reaching the end of the input (excluding the artificial root node).", "labels": [], "entities": []}, {"text": "Column 5 shows for how many of these tokens the correct head is also on the stack (including the artificial root node).", "labels": [], "entities": []}, {"text": "Both statistics are summed overall sentences in the development set.", "labels": [], "entities": []}, {"text": "We see from these figures that the amount of fragmentation varies greatly between languages, from only four unattached tokens for Japanese to 230 tokens for Slovene.", "labels": [], "entities": []}, {"text": "These tendencies seem to reflect properties of the data sets, with Japanese having the lowest average sentence length of all languages and Slovene having a high percentage of non-projective dependencies and a very small training set.", "labels": [], "entities": []}, {"text": "They also partly explain why these languages show the smallest and largest improvement, respectively, in overall attachment score.", "labels": [], "entities": [{"text": "attachment score", "start_pos": 113, "end_pos": 129, "type": "METRIC", "confidence": 0.923857569694519}]}, {"text": "Experimental results for the old and new arc-eager transition systems (development sets).", "labels": [], "entities": []}, {"text": "UAS = unlabeled attachment score; Stack-Token = number of unattached tokens left in the stack when reaching the end of the input (excluding the artificial root node); Stack-Head = number of unattached tokens for which the head is also left in the stack (including the artificial root node); Correct = number of tokens left in the stack that are correctly attached in the final parser output; Recall = Correct/Stack-Head (%).", "labels": [], "entities": [{"text": "UAS", "start_pos": 0, "end_pos": 3, "type": "METRIC", "confidence": 0.8578324317932129}, {"text": "Recall", "start_pos": 392, "end_pos": 398, "type": "METRIC", "confidence": 0.9914953708648682}]}, {"text": "Columns 6 and 7 show, for the old and the new system, how many of the unattached tokens on the stack are attached to their correct head in the final parser output, as a result of heuristic root attachment for the old system and extended transition sequences for the new system.", "labels": [], "entities": []}, {"text": "Columns 8 and 9 show the same results expressed in terms of recall or error reduction (dividing column 6/7 by column 5).", "labels": [], "entities": [{"text": "recall", "start_pos": 60, "end_pos": 66, "type": "METRIC", "confidence": 0.9994655251502991}, {"text": "error reduction", "start_pos": 70, "end_pos": 85, "type": "METRIC", "confidence": 0.8923150300979614}]}, {"text": "These results clearly demonstrate the superiority of the new system over the old system with heuristic root attachment.", "labels": [], "entities": []}, {"text": "Whereas the old system correctly attaches 40.60% of the tokens for which ahead can be found on the stack, the new system finds correct attachments in 72.12% of the cases.", "labels": [], "entities": []}, {"text": "For some languages, the effect is dramatic, with Arabic improving from just above 10% to over 90% and German from about 15% to almost 70%, but all languages clearly benefit from the new technique for enforcing the tree constraint.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1  Experimental results for the old and new arc-eager transition systems (development sets).  UAS = unlabeled attachment score; Stack-Token = number of unattached tokens left in the stack  when reaching the end of the input (excluding the artificial root node); Stack-Head = number of  unattached tokens for which the head is also left in the stack (including the artificial root node);  Correct = number of tokens left in the stack that are correctly attached in the final parser output;  Recall = Correct/Stack-Head (%).", "labels": [], "entities": [{"text": "UAS", "start_pos": 101, "end_pos": 104, "type": "METRIC", "confidence": 0.9417515993118286}, {"text": "Recall", "start_pos": 497, "end_pos": 503, "type": "METRIC", "confidence": 0.9935740828514099}]}, {"text": " Table 2  Results on final test sets. LAS = labeled attachment score. UAS = unlabeled attachment score.", "labels": [], "entities": [{"text": "LAS = labeled attachment score", "start_pos": 38, "end_pos": 68, "type": "METRIC", "confidence": 0.7676503658294678}, {"text": "UAS = unlabeled attachment score", "start_pos": 70, "end_pos": 102, "type": "METRIC", "confidence": 0.7347801446914672}]}]}