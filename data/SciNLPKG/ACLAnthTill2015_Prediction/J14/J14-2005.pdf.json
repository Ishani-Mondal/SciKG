{"title": [{"text": "Phrase Dependency Machine Translation with Quasi-Synchronous Tree-to-Tree Features", "labels": [], "entities": [{"text": "Phrase Dependency Machine Translation", "start_pos": 0, "end_pos": 37, "type": "TASK", "confidence": 0.7192039489746094}]}], "abstractContent": [{"text": "Recent research has shown clear improvement in translation quality by exploiting linguistic syntax for either the source or target language.", "labels": [], "entities": [{"text": "translation", "start_pos": 47, "end_pos": 58, "type": "TASK", "confidence": 0.9684849381446838}]}, {"text": "However, when using syntax for both languages (\"tree-to-tree\" translation), there is evidence that syntactic divergence can hamper the extraction of useful rules (Ding and Palmer 2005).", "labels": [], "entities": [{"text": "tree-to-tree\" translation", "start_pos": 48, "end_pos": 73, "type": "TASK", "confidence": 0.7463925083478292}]}, {"text": "Smith and Eisner (2006) introduced quasi-synchronous grammar, a formalism that treats non-isomorphic structure softly using features rather than hard constraints.", "labels": [], "entities": []}, {"text": "Although a natural fit for translation modeling, its flexibility has proved challenging for building real-world systems.", "labels": [], "entities": [{"text": "translation modeling", "start_pos": 27, "end_pos": 47, "type": "TASK", "confidence": 0.9855119585990906}]}, {"text": "In this article, we present a tree-to-tree machine translation system inspired by quasi-synchronous grammar.", "labels": [], "entities": [{"text": "tree-to-tree machine translation", "start_pos": 30, "end_pos": 62, "type": "TASK", "confidence": 0.7089586059252421}]}, {"text": "The core of our approach is anew model that combines phrases and dependency syntax, integrating the advantages of phrase-based and syntax-based translation.", "labels": [], "entities": []}, {"text": "We report statistically significant improvements over a phrase-based baseline on five of seven test sets across four language pairs.", "labels": [], "entities": []}, {"text": "We also present encouraging preliminary results on the use of unsupervised dependency parsing for syntax-based machine translation.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 75, "end_pos": 93, "type": "TASK", "confidence": 0.7720107138156891}, {"text": "syntax-based machine translation", "start_pos": 98, "end_pos": 130, "type": "TASK", "confidence": 0.6185417572657267}]}], "introductionContent": [{"text": "Building translation systems for many language pairs requires addressing a wide range of translation divergence phenomena.", "labels": [], "entities": [{"text": "translation divergence", "start_pos": 89, "end_pos": 111, "type": "TASK", "confidence": 0.8767904043197632}]}, {"text": "Several researchers have studied divergence between languages in corpora and found it to be considerable, even for closely related languages.", "labels": [], "entities": []}, {"text": "To address this, many have incorporated linguistic syntax into translation model design.", "labels": [], "entities": [{"text": "translation model design", "start_pos": 63, "end_pos": 87, "type": "TASK", "confidence": 0.9244865576426188}]}, {"text": "The statistical natural language processing (NLP) community has developed automatic parsers that can produce syntactic analyses for sentences in several languages ().", "labels": [], "entities": [{"text": "statistical natural language processing (NLP)", "start_pos": 4, "end_pos": 49, "type": "TASK", "confidence": 0.7373815519469125}]}, {"text": "The availability of these parsers, and gains in their accuracy, triggered research interest in syntax-based statistical machine translation.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 54, "end_pos": 62, "type": "METRIC", "confidence": 0.9986816048622131}, {"text": "statistical machine translation", "start_pos": 108, "end_pos": 139, "type": "TASK", "confidence": 0.5839526156584421}]}, {"text": "Syntax-based translation models are diverse, using different grammatical formalisms and features.", "labels": [], "entities": []}, {"text": "Some use a parse tree for the source sentence (\"tree-to-string\"), others produce a parse when generating the target sentence (\"string-to-tree\"), and others combine both (\"tree-to-tree\").", "labels": [], "entities": []}, {"text": "We focus on the final category in this article.", "labels": [], "entities": []}, {"text": "Tree-to-tree translation has proved to be a difficult modeling problem, as initial attempts at it underperformed systems that used no syntax at all.", "labels": [], "entities": [{"text": "Tree-to-tree translation", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.7107551395893097}]}, {"text": "Subsequent research showed that substantial performance gains can be achieved if hard constraintsspecifically, isomorphism between a source sentence's parse and the parse of its translation-are relaxed (Liu, L \u00a8 u, and.", "labels": [], "entities": []}, {"text": "This suggests that constraints must be handled with care.", "labels": [], "entities": []}, {"text": "Yet the classic approach to tree-to-tree translation imposes hard constraints through the use of synchronous grammars developed for programming language compilation.", "labels": [], "entities": [{"text": "tree-to-tree translation", "start_pos": 28, "end_pos": 52, "type": "TASK", "confidence": 0.7224591672420502}, {"text": "programming language compilation", "start_pos": 132, "end_pos": 164, "type": "TASK", "confidence": 0.6407698094844818}]}, {"text": "A synchronous grammar derives two strings simultaneously: one in the source language and one in the target language.", "labels": [], "entities": []}, {"text": "A single derivation is used for both strings, which limits the divergence phenomena that can be captured.", "labels": [], "entities": []}, {"text": "As a result, researchers have developed synchronous grammars with larger rules that, rule-internally, capture more phenomena, typically at increased computational expense.", "labels": [], "entities": []}, {"text": "We take a different approach.", "labels": [], "entities": []}, {"text": "We take inspiration from a family of formalisms called quasi-synchronous grammar).", "labels": [], "entities": []}, {"text": "Unlike synchronous grammar, QG assumes the entire input sentence and some syntactic parse of it are provided and fixed.", "labels": [], "entities": []}, {"text": "QG then defines a monolingual grammar whose language is a set of translations inspired by the input sentence and tree.", "labels": [], "entities": [{"text": "QG", "start_pos": 0, "end_pos": 2, "type": "DATASET", "confidence": 0.860200822353363}]}, {"text": "The productions in this monolingual grammar generate apiece of the translation's tree and align it to apiece of the fixed input tree.", "labels": [], "entities": []}, {"text": "Therefore, arbitrary non-isomorphic structures are possible between the two trees.", "labels": [], "entities": []}, {"text": "A weighted QG uses feature functions to softly penalize or encourage particular types of syntactic divergence.", "labels": [], "entities": [{"text": "syntactic divergence", "start_pos": 89, "end_pos": 109, "type": "TASK", "confidence": 0.7552730441093445}]}, {"text": "In this article, we present a statistical tree-to-tree machine translation system inspired by quasi-synchronous grammar.", "labels": [], "entities": [{"text": "statistical tree-to-tree machine translation", "start_pos": 30, "end_pos": 74, "type": "TASK", "confidence": 0.5643603578209877}]}, {"text": "We exploit the flexibility of QG to develop anew syntactic translation model that seeks to combine the benefits of both phrase-based and syntax-based translation.", "labels": [], "entities": [{"text": "syntactic translation", "start_pos": 49, "end_pos": 70, "type": "TASK", "confidence": 0.7367624640464783}]}, {"text": "Our model organizes phrases into a tree structure inspired by dependency syntax Tesn\u00ec ere 1959).", "labels": [], "entities": []}, {"text": "Instead of standard dependency trees in which words are vertices, our trees have phrases as vertices.", "labels": [], "entities": []}, {"text": "The result captures phenomena like local reordering and idiomatic translations within phrases, as well as long-distance relationships among the phrases in a sentence.", "labels": [], "entities": []}, {"text": "We use the term phrase dependency tree when referring to this type of dependency tree; phrase dependencies have also been used by for opinion mining and previously for machine translation by.", "labels": [], "entities": [{"text": "opinion mining", "start_pos": 134, "end_pos": 148, "type": "TASK", "confidence": 0.8148068785667419}, {"text": "machine translation", "start_pos": 168, "end_pos": 187, "type": "TASK", "confidence": 0.7506498992443085}]}, {"text": "Because we combine phrase dependencies with features from quasi-synchronous grammar, we refer to our model as a quasi-synchronous phrase dependency (QPD) translation model.", "labels": [], "entities": [{"text": "phrase dependency (QPD) translation", "start_pos": 130, "end_pos": 165, "type": "TASK", "confidence": 0.648314560453097}]}, {"text": "Our tree-to-tree approach requires parsers for both the source and target languages.", "labels": [], "entities": []}, {"text": "For two of the language pairs we consider (Chinese\u2192English and German\u2192English), treebanks of hand-annotated parse trees are available (e.g., the Penn Treebank; Marcus,, allowing the use of highly accurate statistical parsers (.", "labels": [], "entities": [{"text": "Penn Treebank; Marcus", "start_pos": 145, "end_pos": 166, "type": "DATASET", "confidence": 0.9566793441772461}]}, {"text": "We also want to apply our model to languages that do not have tree-banks (e.g., Urdu and Malagasy), and for this we turn to unsupervised parsing.", "labels": [], "entities": []}, {"text": "The NLP community has developed a range of statistical algorithms for building unsupervised parsers).", "labels": [], "entities": []}, {"text": "They require only raw, unannotated text in the language of interest, making them ideal for use in translation.", "labels": [], "entities": []}, {"text": "Unsupervised shallow syntactic analysis has been used successfully for translation modeling by, who showed that unsupervised part-of-speech tags could be used to label the hierarchical translation rules of to match the performance of a system that uses supervised full syntactic parses.", "labels": [], "entities": [{"text": "translation modeling", "start_pos": 71, "end_pos": 91, "type": "TASK", "confidence": 0.9841080904006958}]}, {"text": "We take additional steps in this direction, leveraging state-of-the-art unsupervised models for full syntactic analysis () to obtain improvements in translation quality.", "labels": [], "entities": []}, {"text": "We find that replacing a supervised parser for Chinese with an unsupervised one has no effect on performance, and using an unsupervised English parser only hurts slightly.", "labels": [], "entities": []}, {"text": "We use unsupervised parsing to apply our full model to Urdu\u2192English and English\u2192Malagasy translation, reporting statistically significant improvements over our baselines.", "labels": [], "entities": [{"text": "English\u2192Malagasy translation", "start_pos": 72, "end_pos": 100, "type": "TASK", "confidence": 0.6323654279112816}]}, {"text": "These initial results offer promise for researchers to apply syntactic translation models to the thousands of languages for which we do not have manually annotated corpora, and naturally suggest future research directions.", "labels": [], "entities": [{"text": "syntactic translation", "start_pos": 61, "end_pos": 82, "type": "TASK", "confidence": 0.6942488551139832}]}, {"text": "The rest of this article is laid out as follows.", "labels": [], "entities": []}, {"text": "In Section 2, we discuss quasisynchronous grammar and dependency syntax and motivate our modeling choices.", "labels": [], "entities": []}, {"text": "We present our translation model in Section 3, describe how we extract rules in Section 4, and list our feature functions in Section 5. Decoding algorithms are given in Section 6.", "labels": [], "entities": [{"text": "translation", "start_pos": 15, "end_pos": 26, "type": "TASK", "confidence": 0.9614782333374023}]}, {"text": "We present experiments measuring our system's performance on translation tasks involving four language pairs and several test sets in Section 7.", "labels": [], "entities": [{"text": "translation tasks", "start_pos": 61, "end_pos": 78, "type": "TASK", "confidence": 0.9204984307289124}]}, {"text": "We find statistically significant improvements over a strong phrase-based baseline on five out of seven test sets across four language pairs.", "labels": [], "entities": []}, {"text": "We also perform a human evaluation to study how our system improves translation quality.", "labels": [], "entities": []}, {"text": "This article is a significantly expanded version of , containing additional features, anew decoding algorithm, and a more thorough experimental evaluation.", "labels": [], "entities": []}, {"text": "It presents key material from, to which readers seeking further details are referred.", "labels": [], "entities": []}], "datasetContent": [{"text": "We now present experimental results using our QPD model.", "labels": [], "entities": []}, {"text": "Because our model extends phrase-based translation models with features on source-and target-side syntactic structures, we can conduct experiments that simulate phrase-based, string-to-tree, and tree-to-tree translation, merely by specifying which feature sets to include.", "labels": [], "entities": [{"text": "tree-to-tree translation", "start_pos": 195, "end_pos": 219, "type": "TASK", "confidence": 0.7659360468387604}]}, {"text": "This suggests an additional benefit of using a quasi-synchronous approach for machine translation.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 78, "end_pos": 97, "type": "TASK", "confidence": 0.787045806646347}]}, {"text": "By using features rather than constraints, we can simulate a range of translation systems in a single framework, allowing clean experimental comparisons among modeling strategies and combining strengths of diverse approaches.", "labels": [], "entities": []}, {"text": "We describe our experimental setup in Section 7.1 and present our main results in Section 7.2.", "labels": [], "entities": []}, {"text": "We measure the impact of using unsupervised parsing in Section 7.2.1 and include feature ablation experiments in Section 7.2.2.", "labels": [], "entities": [{"text": "Section 7.2.1", "start_pos": 55, "end_pos": 68, "type": "DATASET", "confidence": 0.8925576210021973}]}, {"text": "We present the results of a manual evaluation in Section 7.3 and give examples.", "labels": [], "entities": []}, {"text": "We conclude in Section 7.4 with a runtime analysis of our decoder and show the impact of decoding constraints on speed and translation quality.", "labels": [], "entities": []}, {"text": "In this section we describe details common to the experiments reported in this section.", "labels": [], "entities": []}, {"text": "Details about decoding and learning were described in Section 6.", "labels": [], "entities": []}, {"text": "Full details about language pairs, data sets, and baseline systems are given in Appendix A and Appendix B. We repeat important details here.", "labels": [], "entities": [{"text": "Appendix A", "start_pos": 80, "end_pos": 90, "type": "METRIC", "confidence": 0.937246173620224}, {"text": "Appendix B.", "start_pos": 95, "end_pos": 106, "type": "METRIC", "confidence": 0.8003015220165253}]}, {"text": "We use case-insensitive IBM BLEU ( for evaluation. To measure significance, we use a paired bootstrap) with 100,000 samples (p \u2264 0.05).", "labels": [], "entities": [{"text": "BLEU", "start_pos": 28, "end_pos": 32, "type": "METRIC", "confidence": 0.8009907603263855}]}, {"text": "We consider German\u2192English (DE\u2192EN), Chinese\u2192English (ZH\u2192EN), Urdu\u2192English (UR\u2192EN), and English\u2192Malagasy (EN\u2192MG) translation.", "labels": [], "entities": []}, {"text": "These four languages exhibit a range of syntactic divergence from English.", "labels": [], "entities": []}, {"text": "They also vary in the availability of resources like parallel data, monolingual target-language data, and treebanks.", "labels": [], "entities": []}, {"text": "It is standard practice to evaluate unsupervised parsers on languages that do actually have treebanks, which are used for evaluation.", "labels": [], "entities": []}, {"text": "We consider this case as well, comparing supervised parsers for English and Chinese to our unsupervised parsers, but we also want to evaluate our ability to exploit unsupervised parsing for languages that have small or nonexistent treebanks, hence our inclusion of Urdu and Malagasy.", "labels": [], "entities": []}, {"text": "We focused on UR\u2192EN and ZH\u2192EN translation for our manual evaluation, as these language pairs showed the largest gains in BLEU when using our QPD model.", "labels": [], "entities": [{"text": "ZH\u2192EN translation", "start_pos": 24, "end_pos": 41, "type": "TASK", "confidence": 0.6736620217561722}, {"text": "BLEU", "start_pos": 121, "end_pos": 125, "type": "METRIC", "confidence": 0.9988254904747009}]}, {"text": "We began by performing a human evaluation using Amazon Mechanical Turk (MTurk) in order to validate the BLEU differences against human preference judgments and to identify translations that were consistently judged better under each model for followup manual evaluation.", "labels": [], "entities": [{"text": "Amazon Mechanical Turk (MTurk)", "start_pos": 48, "end_pos": 78, "type": "DATASET", "confidence": 0.8808826307455698}, {"text": "BLEU", "start_pos": 104, "end_pos": 108, "type": "METRIC", "confidence": 0.9965052604675293}]}], "tableCaptions": [{"text": " Table 11  Feature ablation experiments for UR\u2192EN translation with string-to-tree features, showing the  drop in BLEU when separately removing word (WORD), cluster (CLUST), and configuration  (CFG) feature sets.  *  = significantly worse than TGTTREE. Removing word features causes no  significant difference. Removing cluster features results in a significant difference on both test  sets, and removing configuration features results in a significant difference on test 2 only.", "labels": [], "entities": [{"text": "UR\u2192EN translation", "start_pos": 44, "end_pos": 61, "type": "TASK", "confidence": 0.6479736864566803}, {"text": "BLEU", "start_pos": 113, "end_pos": 117, "type": "METRIC", "confidence": 0.9986217021942139}, {"text": "TGTTREE", "start_pos": 243, "end_pos": 250, "type": "METRIC", "confidence": 0.8957635760307312}]}, {"text": " Table 12  Results of human evaluation performed via Amazon Mechanical Turk. The percentages  represent the portion of sentences for which one system had more preference judgments  than the other system. If a sentence had an equal number of judgments for the two systems,  it was counted in the final row", "labels": [], "entities": [{"text": "Amazon Mechanical Turk", "start_pos": 53, "end_pos": 75, "type": "DATASET", "confidence": 0.9506123264630636}]}]}