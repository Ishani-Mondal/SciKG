{"title": [{"text": "Deriving Transfer Rules from Dominance-Preserving Alignments", "labels": [], "entities": [{"text": "Deriving Transfer", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.8849518001079559}, {"text": "Dominance-Preserving Alignments", "start_pos": 29, "end_pos": 60, "type": "TASK", "confidence": 0.7034076452255249}]}], "abstractContent": [], "introductionContent": [{"text": "Automatic acquisition of translation rules from parallel sentence-aligned text takes a variety of forms.", "labels": [], "entities": [{"text": "Automatic acquisition of translation rules from parallel sentence-aligned text", "start_pos": 0, "end_pos": 78, "type": "TASK", "confidence": 0.7447185748153262}]}, {"text": "Some machine translation (MT) systems treat aligned sentences as unstructured word sequences.", "labels": [], "entities": [{"text": "machine translation (MT)", "start_pos": 5, "end_pos": 29, "type": "TASK", "confidence": 0.851176381111145}]}, {"text": "Other systems, including our own ( and), syntactically analyze sentences (parse) before acquiring transfer rules (cf. (,, and).", "labels": [], "entities": []}, {"text": "This has the advantage of acquiring structural as well as lexical correspondences.", "labels": [], "entities": []}, {"text": "A syntactically analyzed, aligned corpus may serve as an example base fora form of example-based NIT (cf. (,, and ().", "labels": [], "entities": []}, {"text": "This paper 1 describes: (1) an efficient algorithm for aligning a pair of source/target language parse trees; and (9) a procedure for deriving transfer rules from this alignment.", "labels": [], "entities": []}, {"text": "Each transfer rule consists of a pair of tree fragments derived by \"cutting up\" the source and target trees.", "labels": [], "entities": []}, {"text": "A set of transfer rules whose left-hand sides match a source language parse tree is used to generate a target language parse tree from their set of right-hand sides, which is a translation of the source tree.", "labels": [], "entities": []}, {"text": "This technique resembles work on NIT using synchronous Tree-Adjoining Grammars (cf. ().", "labels": [], "entities": []}, {"text": "The Proteus translation system learns transfer rules from pairs of aligned source and target regularized parses, Proteus's representation of predicate argument structure (cf.).", "labels": [], "entities": [{"text": "Proteus translation", "start_pos": 4, "end_pos": 23, "type": "TASK", "confidence": 0.6584920585155487}]}, {"text": "2 Then it uses these transfer rules to map source tan-guage regularized parses generated by our source language parser into target language regularized parses.", "labels": [], "entities": []}, {"text": "Finally a generator converts target regularized parses into target language sentences.", "labels": [], "entities": []}, {"text": "An alignment f is a 1-to-1 partial mapping from source nodes to target nodes.", "labels": [], "entities": []}, {"text": "We consider only alignments which preserve the dominance relationship: If node a dominates node bin the source tree, then f(a) dominates f(b) in the target tree.", "labels": [], "entities": []}, {"text": "In. source nodes .4.", "labels": [], "entities": []}, {"text": "B, C and D map to the corresponding target nodes, marked with a prime, e.g., f(A) = A'.", "labels": [], "entities": []}, {"text": "The alignment maybe represented by the set {(d, A'), (B, B'), (C, C'), (D, D')}.", "labels": [], "entities": []}, {"text": "We can assign a score to each alignment f, based on the (weighted) number of pairs inf; finding the best alignment translates into finding the alignment with the highest score.", "labels": [], "entities": []}, {"text": "Our algorithms are based on and related work.", "labels": [], "entities": []}, {"text": "We needed efficient alignment algorithms because: (1) Corpus-based training requires processing a lot of text; and (2) An exhaustive search of all alignments is too computationally expensive for realistically sized parse trees.", "labels": [], "entities": []}, {"text": "Eliminating dominance violations greatly reduced our search space.", "labels": [], "entities": []}, {"text": "Similar work (e.g.,) considers all possible matches.", "labels": [], "entities": []}, {"text": "our system cannot account for actual dominance violations in a given bitext, there are no such violations in our corpus and many hypothetical cases can be avoided by adopting the appropriate grammar.", "labels": [], "entities": []}, {"text": "Cases of adjuncts aligning with heads and vice versa are not dominance violations if we replace our dependency analysis with one in which internal nodes have category labels and the head constituents are marked by HEAD arcs and we assume the following Categorial Grammar (CG) style analyses.", "labels": [], "entities": []}, {"text": "Suppose that verb (Vi) maps to adverb (A'I) and adverb (A2) maps to verb (V'2), where We seek a better alignment scheme, in which the score S(D, D') could benefit from S(A, A').", "labels": [], "entities": []}, {"text": "We are willing to pay a small penalty to collapse the path from D to E, and align the resulting structure.", "labels": [], "entities": []}, {"text": "This leads to new algorithms where the LeA-preserving restriction is replaced by the weaker, dominance-preserving constraint.", "labels": [], "entities": [{"text": "LeA-preserving", "start_pos": 39, "end_pos": 53, "type": "METRIC", "confidence": 0.8420602679252625}]}, {"text": "The rationale behind allowing an edge, say (v, u) to be collapsed when matching two nodes v and v ~, is that we may find some children of u which correspond well to some children of v', while other children of v correspond well to other children of v'.", "labels": [], "entities": []}, {"text": "(This is not possible if LCA's are preserved.)", "labels": [], "entities": []}, {"text": "The algorithm relies on the assumption that two different children of v will not match well with the same child of v'.", "labels": [], "entities": []}], "datasetContent": [{"text": "Real evaluation of performance of MT systems is time consuming and subjective.", "labels": [], "entities": [{"text": "MT", "start_pos": 34, "end_pos": 36, "type": "TASK", "confidence": 0.9889457821846008}]}, {"text": "Nevertheless, some evaluation system is needed to insure that incremental changes are for the better, or at least, are not detrimental.", "labels": [], "entities": []}, {"text": "We measured the success of our translation by how closely we reproduced Microsoft's English (target language) text.", "labels": [], "entities": [{"text": "Microsoft's English (target language) text", "start_pos": 72, "end_pos": 114, "type": "DATASET", "confidence": 0.8033187687397003}]}, {"text": "Our evaluation procedure computes the ratio between (a) the complement of the intersection set of words in our translation and the actual Microsoft sentence; and (b) the combined lengths of these two sentences.", "labels": [], "entities": []}, {"text": "An exact translation gives a score of 0.", "labels": [], "entities": []}, {"text": "If the system generates the sentence \"A BC D E\" and the actual sentence is \"A BC F\", the score is 3/9 (the length of DE F divided by the combined lengths of AB CD E and AB C F.)", "labels": [], "entities": [{"text": "A BC F", "start_pos": 76, "end_pos": 82, "type": "METRIC", "confidence": 0.774294118086497}]}, {"text": "The dominancepreserving version of the program produced output for 88 out of 91 test sentences.", "labels": [], "entities": []}, {"text": "The average score for these 88 sentences was 0.29:0.21 due to incorrect word matches and 0.08 due to failure to translate because insufficient confidence levels were reached.", "labels": [], "entities": []}, {"text": "The LCA-preserving version produced output for only 83 sentences with an average score of over 0.30: about 0.23 due to incorrect word matches and about 0.08 due to insufficient confidence levels.", "labels": [], "entities": []}, {"text": "This crude scoring technique suggests that the dominance-preserving algorithm improved our results: more sentences were translated with higher quality.", "labels": [], "entities": []}, {"text": "One limitation of this scoring technique is that paraphrases are penalized.", "labels": [], "entities": []}, {"text": "An imperfect score (even .20) may signify an adequate translation.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: (a) A Final Score Matrix; (b) Children-Pairing Matrix", "labels": [], "entities": [{"text": "A Final Score", "start_pos": 14, "end_pos": 27, "type": "METRIC", "confidence": 0.8392481207847595}]}, {"text": " Table 2: Computing Child-Scoring Matrices", "labels": [], "entities": []}]}