{"title": [{"text": "Robust pronoun resolution with limited knowledge", "labels": [], "entities": [{"text": "Robust pronoun resolution", "start_pos": 0, "end_pos": 25, "type": "TASK", "confidence": 0.9296526312828064}]}], "abstractContent": [{"text": "Most traditional approaches to anaphora resolution rely heavily on linguistic and domain knowledge.", "labels": [], "entities": [{"text": "anaphora resolution", "start_pos": 31, "end_pos": 50, "type": "TASK", "confidence": 0.8738952577114105}]}, {"text": "One of the disadvantages of developing a knowledge-based system, however, is that it is a very labour-intensive and time-consuming task.", "labels": [], "entities": []}, {"text": "This paper presents a robust, knowledge-poor approach to resolving pronouns in technical manuals, which operates on texts pre-processed by a part-of-speech tagger.", "labels": [], "entities": []}, {"text": "Input is checked against agreement and fora number of antecedent indicators.", "labels": [], "entities": [{"text": "Input", "start_pos": 0, "end_pos": 5, "type": "METRIC", "confidence": 0.9601722359657288}]}, {"text": "Candidates are assigned scores by each indicator and the candidate with the highest score is returned as the antecedent.", "labels": [], "entities": []}, {"text": "Evaluation reports a success rate of 89.7% which is better than the success rates of the approaches selected for comparison and tested on the same data.", "labels": [], "entities": []}, {"text": "In addition, preliminary experiments show that the approach can be successfully adapted for other languages with minimum modifications.", "labels": [], "entities": []}], "introductionContent": [{"text": "For the most part, anaphora resolution has focused on traditional linguistic methods;.", "labels": [], "entities": [{"text": "anaphora resolution", "start_pos": 19, "end_pos": 38, "type": "TASK", "confidence": 0.9780221879482269}]}, {"text": "However, to represent and manipulate the various types of linguistic and domain knowledge involved requires considerable human input and computational expense.", "labels": [], "entities": []}, {"text": "While various alternatives have been proposed, making use of e.g. neural networks, a situation semantics framework, or the principles of reasoning with uncertainty (e.g., there is still a strong need for the development of robust and effective strategies to meet the demands of practical NLP systems, and to enhance further the automatic processing of growing language resources.", "labels": [], "entities": []}, {"text": "Several proposals have already addressed the anaphora resolution problem by deliberately limiting the extent to which they rely on domain and/or linguistic knowledge).", "labels": [], "entities": [{"text": "anaphora resolution", "start_pos": 45, "end_pos": 64, "type": "TASK", "confidence": 0.7816204130649567}]}, {"text": "Our work is a continuation of these latest trends in the search for inexpensive, fast and reliable procedures for anaphora resolution.", "labels": [], "entities": [{"text": "anaphora resolution", "start_pos": 114, "end_pos": 133, "type": "TASK", "confidence": 0.8616654276847839}]}, {"text": "It is also an example of how anaphors in a specific genre can be resolved quite successfully without any sophisticated linguistic knowledge or even without parsing.", "labels": [], "entities": []}, {"text": "Finally, our evaluation shows that the basic set of antecedent tracking indicators can work well not only for English, but also for other languages (in our case Polish and Arabic).", "labels": [], "entities": []}], "datasetContent": [{"text": "For practical reasons, the approach presented does not incorporate syntactic and semantic information (other than a list of domain terms) and it is not realistic to expect its performance to be as good as an approach which makes use of syntactic and semantic knowledge in terms of constraints and preferences.", "labels": [], "entities": []}, {"text": "The lack of syntactic information, for instance, means giving up c-command constraints and subject preference (or on other occasions object preference, see Mitkov 1995) which could be used in center tracking.", "labels": [], "entities": [{"text": "center tracking", "start_pos": 192, "end_pos": 207, "type": "TASK", "confidence": 0.7175881713628769}]}, {"text": "Syntactic parallelism, useful in discriminating between identical pronouns on the basis of their syntactic function, also has to be forgone.", "labels": [], "entities": [{"text": "Syntactic parallelism", "start_pos": 0, "end_pos": 21, "type": "TASK", "confidence": 0.9252607524394989}]}, {"text": "Lack of semantic knowledge rules out the use of verb semantics and semantic parallelism.", "labels": [], "entities": []}, {"text": "Our evaluation, however, suggests that much less is lost than might be feared.", "labels": [], "entities": []}, {"text": "In fact, our evaluation shows that the results are comparable to syntax-based methods.", "labels": [], "entities": []}, {"text": "We believe that the good success rate is due to the fact that a number of antecedent indicators are taken into account and no factor is given absolute preference.", "labels": [], "entities": []}, {"text": "In particular, this strategy can often override incorrect decisions linked with strong centering preference) or syntactic and semantic parallelism preferences (see below).", "labels": [], "entities": []}, {"text": "Our first evaluation exercise) was based on a random sample text from a technical manual in English.", "labels": [], "entities": []}, {"text": "There were 71 pronouns in the 140 page technical manual; 7 of the pronouns were non-anaphoric and 16 exophoric.", "labels": [], "entities": []}, {"text": "The resolution of anaphors was carried outwith a success rate of 95.8%.", "labels": [], "entities": [{"text": "resolution", "start_pos": 4, "end_pos": 14, "type": "TASK", "confidence": 0.9263443946838379}]}, {"text": "The approach being robust (an attempt is made to resolve each anaphor and a proposed antecedent is returned), this figure represents both \"precision\" and \"recall\" if we use the MUC terminology.", "labels": [], "entities": [{"text": "precision", "start_pos": 139, "end_pos": 148, "type": "METRIC", "confidence": 0.9995648264884949}, {"text": "recall", "start_pos": 155, "end_pos": 161, "type": "METRIC", "confidence": 0.9992579817771912}, {"text": "MUC", "start_pos": 177, "end_pos": 180, "type": "DATASET", "confidence": 0.8106252551078796}]}, {"text": "To avoid any terminological confusion, we shall therefore use the more neutral term \"success rate\" while discussing the evaluation.", "labels": [], "entities": [{"text": "success rate", "start_pos": 85, "end_pos": 97, "type": "METRIC", "confidence": 0.9251629114151001}]}, {"text": "Similarly to the first evaluation, we found that the robust approach was not very successful on sentences with too complicated syntax -a price we have to pay for the \"convenience\" of developing a knowledge-poor system.", "labels": [], "entities": []}, {"text": "The results from experiment 1 and experiment 2 can be summarised in the following (statistically) slightly more representative figures.", "labels": [], "entities": []}, {"text": "We carried out a second evaluation of the approach on a different set of sample texts from the genre of technical manuals (47-page Portable Style-Writer User's Guide.", "labels": [], "entities": []}, {"text": "Out of 223 pronouns in the text, 167 were non-anaphoric (deictic and non-anaphoric \"it\").", "labels": [], "entities": []}, {"text": "The evaluation carried out was manual to ensure that no added error was generated (e.g. due to possible wrong sentence/clause detection or POS tagging).", "labels": [], "entities": [{"text": "wrong sentence/clause detection", "start_pos": 104, "end_pos": 135, "type": "TASK", "confidence": 0.6300031960010528}, {"text": "POS tagging", "start_pos": 139, "end_pos": 150, "type": "TASK", "confidence": 0.7776975035667419}]}, {"text": "Another reason for doing it by hand is to ensure a fair comparison with Breck Baldwin's method, which not being available to us, had to be hand-simulated (see 3.3).", "labels": [], "entities": []}, {"text": "The evaluation indicated 83.6% success rate.", "labels": [], "entities": []}, {"text": "The \"Baseline subject\" model tested on the same data scored 33.9% recall and 67.9% precision, whereas \"Baseline most recent\" scored 66.7%.", "labels": [], "entities": [{"text": "recall", "start_pos": 66, "end_pos": 72, "type": "METRIC", "confidence": 0.9996053576469421}, {"text": "precision", "start_pos": 83, "end_pos": 92, "type": "METRIC", "confidence": 0.9996645450592041}]}, {"text": "Note that \"Baseline subject\" can be assessed both in terms of recall and precision because this \"version\" is not robust: in the event of no subject being available, it is notable to propose an antecedent (the manual guide used as evaluation text contained many imperative zero-subject sentences).", "labels": [], "entities": [{"text": "recall", "start_pos": 62, "end_pos": 68, "type": "METRIC", "confidence": 0.9987037181854248}, {"text": "precision", "start_pos": 73, "end_pos": 82, "type": "METRIC", "confidence": 0.9981794357299805}]}, {"text": "In the second experiment we evaluated the approach from the point of view also of its \"critical success rate\".", "labels": [], "entities": []}, {"text": "This measure (Mitkov 1998b) applies only to anaphors \"ambiguous\" from the point of view of number and gender (i.e. to those \"tough\" anaphors which, after activating the gender and number filters, still have more than one candidate for antecedent) and is indicative of the performance of the antecedent indicators.", "labels": [], "entities": []}, {"text": "Our evaluation established the critical success rate as 82%.", "labels": [], "entities": []}, {"text": "A case where the system failed was when the anaphor and the antecedent were in the same sentence and where preference was given to a candidate in the preceding sentence.", "labels": [], "entities": []}, {"text": "This case and other cases suggest that it might be worthwhile reconsidering/refining the weights for the indicator \"referential distance\".", "labels": [], "entities": []}, {"text": "The lower figure in \"Baseline subject\" corresponds to \"recall\" and the higher figure -to \"precision\".", "labels": [], "entities": [{"text": "recall", "start_pos": 55, "end_pos": 61, "type": "METRIC", "confidence": 0.9946600794792175}, {"text": "precision", "start_pos": 90, "end_pos": 99, "type": "METRIC", "confidence": 0.9973892569541931}]}, {"text": "If we regard as \"discriminative power\" of each antecedent indicator the ratio \"number of successful antecedent identifications when this indicator was applied\"/\"number of applications of this indicator\" (for the non-prepositional noun phrase and definiteness being penalising indicators, this figure is calculated as the ratio \"number of unsuccessful antecedent identifications\"/\"number of applications\"), the immediate reference emerges as the most discriminative indicator (100%), followed by nonprepositional noun phrase (92.2%), collocation (90.9%), section heading (61.9%), lexical reiteration (58.5%), givenness (49.3%), term preference (35.7%) and referential distance (34.4%).", "labels": [], "entities": []}, {"text": "The relatively low figures for the majority of indicators should not be regarded as a surprise: firstly, we should bear in mind that inmost cases a candidate was picked (or rejected) as an antecedent on the basis of applying a number of different indicators and secondly, that most anaphors had a relatively high number of candidates for antecedent.", "labels": [], "entities": []}, {"text": "In terms of frequency of use (\"number of non-zero applications\"/\"number of anaphors\"), the most frequently used indicator proved to be referential distance used in 98.9% of the cases, followed by term preference (97.8%), givenness (83.3%), lexical reiteration (64.4%), definiteness (40%), section heading (37.8%), immediate reference (31.1%) and collocation (11.1%).", "labels": [], "entities": [{"text": "section heading", "start_pos": 289, "end_pos": 304, "type": "TASK", "confidence": 0.7444260716438293}]}, {"text": "As expected, the most frequent indicators were not the most discriminative ones.", "labels": [], "entities": []}, {"text": "We felt appropriate to extend the evaluation of our approach by comparing it to Breck Baldwin's Cog-NIAC (Baldwin 1997) approach which features \"high precision coreference with limited knowledge and linguistics resources\".", "labels": [], "entities": []}, {"text": "The reason is that both our approach and Breck Baldwin's approach share common principles (both are knowledge-poor and use a POS tagger to provide the input) and therefore a comparison would be appropriate.", "labels": [], "entities": []}, {"text": "Given that our approach is robust and returns antecedent for each pronoun, in order to make the comparison as fair as possible, we used CogNIAC's \"resolve all\" version by simulating it manually on the same training data used in evaluation B above.", "labels": [], "entities": []}, {"text": "CogNIAC successfully resolved the pronouns in 75% of the cases.", "labels": [], "entities": [{"text": "CogNIAC", "start_pos": 0, "end_pos": 7, "type": "DATASET", "confidence": 0.8803279399871826}]}, {"text": "This result is comparable with the results described in.", "labels": [], "entities": []}, {"text": "For the training data from the genre of technical manuals, it was rule 5 (see Baldwin 1997) which was most frequently used (39% of the cases, 100% success), followed by rule 8 (33% of the cases, 33% success), rule 7 (11%, 100%), rule I (9%, 100%) and rule 3 (7.4%, 100%).", "labels": [], "entities": []}, {"text": "It would be fair to say that even though the results show superiority of our approach on the training data used (the genre of technical manuals), they cannot be generalised automatically for other genres or unrestricted texts and fora more accurate picture, further extensive tests are necessary.", "labels": [], "entities": []}], "tableCaptions": []}