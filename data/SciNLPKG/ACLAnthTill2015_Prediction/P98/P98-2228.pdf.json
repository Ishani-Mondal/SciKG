{"title": [{"text": "Word Sense Disambiguation using Optimised Combinations of Knowledge Sources", "labels": [], "entities": [{"text": "Word Sense Disambiguation", "start_pos": 0, "end_pos": 25, "type": "TASK", "confidence": 0.6590907375017802}]}], "abstractContent": [{"text": "Word sense disambiguation algorithms, with few exceptions , have made use of only one lexical knowledge source.", "labels": [], "entities": [{"text": "Word sense disambiguation", "start_pos": 0, "end_pos": 25, "type": "TASK", "confidence": 0.6286907891432444}]}, {"text": "We describe a system which performs word sense disambiguation on all content words in free text by combining different knowledge sources: semantic preferences, dictionary definitions and sub-ject/domain codes along with part-of-speech tags, optimised by means of a learning algorithm.", "labels": [], "entities": [{"text": "word sense disambiguation", "start_pos": 36, "end_pos": 61, "type": "TASK", "confidence": 0.7158357004324595}]}, {"text": "We also describe the creation of anew sense tagged corpus by combining existing resources.", "labels": [], "entities": []}, {"text": "Tested accuracy of our approach on this corpus exceeds 92%, demonstrating the viability of all-word disambiguation rather than restricting oneself to a small sample.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 7, "end_pos": 15, "type": "METRIC", "confidence": 0.9996250867843628}]}], "introductionContent": [{"text": "This paper describes a system that integrates a number of partial sources of information to perform word sense disambiguation (WSD) of content words in general text at a high level of accuracy.", "labels": [], "entities": [{"text": "word sense disambiguation (WSD) of content words in general text", "start_pos": 100, "end_pos": 164, "type": "TASK", "confidence": 0.8277013972401619}, {"text": "accuracy", "start_pos": 184, "end_pos": 192, "type": "METRIC", "confidence": 0.9924155473709106}]}, {"text": "The methodology and evaluation of WSD are somewhat different from those of other NLP modules, and one can distinguish three aspects of this difference, all of which comedown to evaluation problems, as does so much in NLP these days.", "labels": [], "entities": [{"text": "WSD", "start_pos": 34, "end_pos": 37, "type": "TASK", "confidence": 0.9332320094108582}]}, {"text": "First, researchers are divided between a general method (that attempts to apply WSD to all the content words of texts, the option taken in this paper) and one that is applied only to a small trial selection of texts words (for example).", "labels": [], "entities": []}, {"text": "These researchers have obtained very high levels of success, in excess of 95%, close to the figures for other \"solved\" NLP modules, the issue being whether these small word sample methods and techniques will transfer to general WSD overall content words.", "labels": [], "entities": [{"text": "WSD overall content words", "start_pos": 228, "end_pos": 253, "type": "TASK", "confidence": 0.7202658653259277}]}, {"text": "Others, (eg. () (Harley and) have pursued the general option on the grounds that it is the real task and should be tackled directly, but with rather lower success rates.", "labels": [], "entities": []}, {"text": "The division between the approaches probably comes down to no more than the availability of gold standard text in sufficient quantities, which is more costly to obtain for WSD than other tasks.", "labels": [], "entities": [{"text": "WSD", "start_pos": 172, "end_pos": 175, "type": "TASK", "confidence": 0.9423966407775879}]}, {"text": "In this paper we describe a method we have used for obtaining more test material by transforming one resource into another, an advance we believe is unique and helpful in this impasse.", "labels": [], "entities": []}, {"text": "However, there have also been deeper problems about evaluation, which has led sceptics like) to question the whole WSD enterprise, for example that it is harder for subjects to assign one and only one sense to a word in context (and hence the produce the test material itself) than to perform other NLP related tasks.", "labels": [], "entities": []}, {"text": "One of the present authors has discussed Kilgarriff's figures elsewhere (Wilks, 1997) and argued that they are not, in fact, as gloomy as he suggests.", "labels": [], "entities": [{"text": "Kilgarriff's figures", "start_pos": 41, "end_pos": 61, "type": "DATASET", "confidence": 0.9185158610343933}]}, {"text": "Again, this is probably an area where there is an \"expertise effect\": some subjects can almost certainly make finer, more intersubjective, sense distinctions than others in a reliable way, just as lexicographers do.", "labels": [], "entities": []}, {"text": "But there is another, quite different, source of unease about the evaluation base: everyone agrees that new senses appear in corpora that cannot be assigned to any existing dictionary sense, and this is an issue of novelty, not just one of the difficulty of discrimination.", "labels": [], "entities": []}, {"text": "If that is the case, it tends to undermine the standard mark-up-model-and-test methodology of most recent NLP, since it will not then be possible to markup sense assignment in advance against a dictionary if new senses are present.", "labels": [], "entities": []}, {"text": "We shall not tackle this difficult issue further here, but press on towards experiment.", "labels": [], "entities": []}], "datasetContent": [{"text": "Rather than expend avast amount of effort on manual tagging we decided to adapt two existing resources to our purposes.", "labels": [], "entities": [{"text": "manual tagging", "start_pos": 45, "end_pos": 59, "type": "TASK", "confidence": 0.662602886557579}]}, {"text": "We took SEMCOR, a 200,000 word corpus with the content words manually tagged as part of the WordNet project.", "labels": [], "entities": [{"text": "WordNet project", "start_pos": 92, "end_pos": 107, "type": "DATASET", "confidence": 0.9117111563682556}]}, {"text": "The semantic tagging was carried out under disciplined conditions using trained lexicographers with tagging inconsistencies between manual annotators controlled.", "labels": [], "entities": [{"text": "semantic tagging", "start_pos": 4, "end_pos": 20, "type": "TASK", "confidence": 0.8042090535163879}]}, {"text": "SENSUS) is a largescale ontology designed for machine-translation and was produced by merging the ontological hierarchies of.", "labels": [], "entities": []}, {"text": "To facilitate this merging it was necessary to derive a mapping between the senses in the two lexical resources.", "labels": [], "entities": []}, {"text": "We used this mapping to translate the WordNet-tagged content words in SEMCOR to LDOCE tags.", "labels": [], "entities": [{"text": "WordNet-tagged content words in SEMCOR", "start_pos": 38, "end_pos": 76, "type": "DATASET", "confidence": 0.8283705711364746}]}, {"text": "The mapping is not one-to-one, and some WordNet senses are mapped onto two or three LDOCE senses when the WordNet sense does not distinguish between them.", "labels": [], "entities": []}, {"text": "The mapping also contained significant gaps (words and senses not in the translation).", "labels": [], "entities": []}, {"text": "SEMCOR contains 91,808 words tagged with WordNet synsets, 6,071 of which are proper names which we ignore, leaving 85,737 words which could potentially be translated.", "labels": [], "entities": [{"text": "SEMCOR", "start_pos": 0, "end_pos": 6, "type": "DATASET", "confidence": 0.8490440845489502}, {"text": "WordNet synsets", "start_pos": 41, "end_pos": 56, "type": "DATASET", "confidence": 0.7950063347816467}]}, {"text": "The translation contains only 36,869 words tagged with LDOCE senses, although this is a reasonable size for an evaluation corpus given this type of task (it is several orders of magnitude larger than those used by)).", "labels": [], "entities": []}, {"text": "This corpus was also constructed without the excessive cost of additional hand-tagging and does not introduce any inconsistencies which may occur with a poorly controlled tagging strategy.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Comparison of tagger with similar systems", "labels": [], "entities": []}, {"text": " Table 2: Results from different knowledge sources", "labels": [], "entities": []}]}