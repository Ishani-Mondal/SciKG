{"title": [{"text": "Feasibility Study for Ellipsis Resolution in Dialogues by Machine-Learning Technique", "labels": [], "entities": [{"text": "Ellipsis Resolution in Dialogues", "start_pos": 22, "end_pos": 54, "type": "TASK", "confidence": 0.8162224590778351}]}], "abstractContent": [{"text": "A method for resolving the ellipses that appear in Japanese dialogues is proposed.", "labels": [], "entities": [{"text": "resolving the ellipses that appear in Japanese dialogues", "start_pos": 13, "end_pos": 69, "type": "TASK", "confidence": 0.6420906111598015}]}, {"text": "This method resolves not only the subject ellipsis, but also those in object and other grammatical cases.", "labels": [], "entities": []}, {"text": "In this approach, a machine-learning algorithm is used to select the attributes necessary fora resolution.", "labels": [], "entities": []}, {"text": "A decision tree is built, and used as the actual ellipsis resolver.", "labels": [], "entities": []}, {"text": "The results of blind tests have shown that the proposed method was able to provide a resolution accuracy of 91.7% for indirect objects, and 78.7% for subjects with a verb predicate.", "labels": [], "entities": [{"text": "resolution", "start_pos": 85, "end_pos": 95, "type": "METRIC", "confidence": 0.9606602191925049}, {"text": "accuracy", "start_pos": 96, "end_pos": 104, "type": "METRIC", "confidence": 0.5233498811721802}]}, {"text": "By investigating the decision tree we found that topic-dependent attributes are necessary to obtain high performance resolution , and that indispensable attributes vary according to the grammatical case.", "labels": [], "entities": []}, {"text": "The problem of data size relative to decision-tree training is also discussed.", "labels": [], "entities": []}], "introductionContent": [{"text": "In machine translation systems, it is necessary to resolve ellipses when the source language doesn't express the subject or other grammatical cases and the target must express it.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 3, "end_pos": 22, "type": "TASK", "confidence": 0.7251932621002197}]}, {"text": "The problem of ellipsis resolution is also troublesome in information extraction and other natural language processing fields.", "labels": [], "entities": [{"text": "ellipsis resolution", "start_pos": 15, "end_pos": 34, "type": "TASK", "confidence": 0.7704921066761017}, {"text": "information extraction", "start_pos": 58, "end_pos": 80, "type": "TASK", "confidence": 0.8751783967018127}]}, {"text": "Several approaches have been proposed to resolve ellipses, which consist of endophoric (intrasentential or anaphoric) ellipses and exophoric (or extrasentential) ellipses.", "labels": [], "entities": []}, {"text": "One of the major approaches for endophoric ellipsis in theoretical basis utilizes the centering theory.", "labels": [], "entities": []}, {"text": "However, its application to complex sentences has not been established because most studies have only investigated its effectiveness with successive simple sentences.", "labels": [], "entities": []}, {"text": "Several studies of this problem have been made using the empirical approach.", "labels": [], "entities": []}, {"text": "Among them, proposed a scoring approach where each constraint is manually scored with an estimation of possibility, and the resolution is conducted by totaling the points each candidate receives.", "labels": [], "entities": []}, {"text": "On the other hand, proposed a resolving algorithm for Japanese exophoric ellipses of written texts, utilizing semantic and pragmatic constraints.", "labels": [], "entities": []}, {"text": "They claimed that 100% of the ellipses with exophoric referents could be resolved, but the experiment was a closed test with only a few samples.", "labels": [], "entities": []}, {"text": "These approaches always require some effort to decide the scoring or the preference of provided constraints.", "labels": [], "entities": []}, {"text": "Aone and Bennett (1995) applied a machinelearning technique to anaphora resolution in written texts.", "labels": [], "entities": [{"text": "anaphora resolution in written texts", "start_pos": 63, "end_pos": 99, "type": "TASK", "confidence": 0.7918989956378937}]}, {"text": "They attempted endophoric ellipsis resolution as apart of anaphora resolution, with approximately 40% recall and 74~ precision at best from 200 test samples.", "labels": [], "entities": [{"text": "endophoric ellipsis resolution", "start_pos": 15, "end_pos": 45, "type": "TASK", "confidence": 0.6224283277988434}, {"text": "recall", "start_pos": 102, "end_pos": 108, "type": "METRIC", "confidence": 0.9996151924133301}, {"text": "74~", "start_pos": 113, "end_pos": 116, "type": "METRIC", "confidence": 0.9502704739570618}, {"text": "precision", "start_pos": 117, "end_pos": 126, "type": "METRIC", "confidence": 0.755571722984314}]}, {"text": "However, they were not concerned with exophoric ellipsis.", "labels": [], "entities": []}, {"text": "In contrast, we applied a machine-learning approach to ellipsis resolution (.", "labels": [], "entities": [{"text": "ellipsis resolution", "start_pos": 55, "end_pos": 74, "type": "TASK", "confidence": 0.7228067964315414}]}, {"text": "In this previous work we resolved the agent case ellipses in dialogue, with a limited topic, and performed with approximately 90% accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 130, "end_pos": 138, "type": "METRIC", "confidence": 0.9984190464019775}]}, {"text": "This does not sufficiently determine the effectiveness of the decision tree, and the feasibility of this technique in resolving ellipses by each surface case is also unclear.", "labels": [], "entities": []}, {"text": "We propose a method to resolve the ellipses that appear in Japanese dialogues.", "labels": [], "entities": []}, {"text": "This method resolves not only the subject ellipsis, but also the object and other grammatical cases.", "labels": [], "entities": []}, {"text": "In this approach, a machine-learning algorithm is used to build a decision tree by selecting the necessary attributes, and the decision tree is used as the actual ellipsis resoh'er.", "labels": [], "entities": []}, {"text": "Another purpose of this paper is to discuss how effective the machine-learning approach is in the problem of ellipsis resolution.", "labels": [], "entities": [{"text": "ellipsis resolution", "start_pos": 109, "end_pos": 128, "type": "TASK", "confidence": 0.738635316491127}]}, {"text": "In the following sections, we discuss topic-dependency in decision trees and compare the resolution effectiveness of each grammatical case.", "labels": [], "entities": []}, {"text": "The problem of data size relative to the decision-tree training is also discussed.", "labels": [], "entities": []}, {"text": "In this paper, we assume that the detection of ellipses is performed by another module, such as a parser.", "labels": [], "entities": []}, {"text": "We only considered ellipses that are commonly and dearly identified.", "labels": [], "entities": []}, {"text": "2 When to Resolve Ellipsis in MT ? As described above, our major application for ellipsis resolution is in machine translation.", "labels": [], "entities": [{"text": "MT", "start_pos": 30, "end_pos": 32, "type": "TASK", "confidence": 0.8937035202980042}, {"text": "ellipsis resolution", "start_pos": 81, "end_pos": 100, "type": "TASK", "confidence": 0.7343356162309647}, {"text": "machine translation", "start_pos": 107, "end_pos": 126, "type": "TASK", "confidence": 0.7837948799133301}]}, {"text": "In an MT process, there can be several approaches about the timing of ellipsis resolution: when analyzing the source language, when generating the target language, or at the same time as translating process.", "labels": [], "entities": [{"text": "MT process", "start_pos": 6, "end_pos": 16, "type": "TASK", "confidence": 0.9266453087329865}, {"text": "ellipsis resolution", "start_pos": 70, "end_pos": 89, "type": "TASK", "confidence": 0.7383688390254974}]}, {"text": "Among these candidates, most of the previous works with Japanese chose the source-language approach.", "labels": [], "entities": []}, {"text": "For instance, attempted to resolve Japanese ellipsis in the source language analysis of J-to-E MT, despite utilizing targetdependent resolution candidates.", "labels": [], "entities": [{"text": "J-to-E MT", "start_pos": 88, "end_pos": 97, "type": "TASK", "confidence": 0.48557956516742706}]}, {"text": "We originally thought that ellipsis resolution in the MT was a generation problem, namely a target-driven problem which utilizes some help, if necessary, of source-language information.", "labels": [], "entities": [{"text": "ellipsis resolution", "start_pos": 27, "end_pos": 46, "type": "TASK", "confidence": 0.7445761263370514}, {"text": "MT", "start_pos": 54, "end_pos": 56, "type": "TASK", "confidence": 0.9432547688484192}]}, {"text": "This is because the problem is outputdependent and it relies on demands from a target language.", "labels": [], "entities": []}, {"text": "In the J-to-Korean or J-toChinese MT, all or most of the ellipses that must be resolved in J-to-E are not necessary to resolve.", "labels": [], "entities": [{"text": "J-toChinese MT", "start_pos": 22, "end_pos": 36, "type": "TASK", "confidence": 0.5271481275558472}]}, {"text": "However, we adopted source-language policy in this paper, with the necessity that we consider a multi-lingual MT system TDMT ( , that deals with both J-to-E and Jto-German MT.", "labels": [], "entities": [{"text": "MT", "start_pos": 110, "end_pos": 112, "type": "TASK", "confidence": 0.963870108127594}]}, {"text": "English and German grammar are not generally believed to be similar.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 2: Number of training attributes", "labels": [], "entities": []}, {"text": " Table 3: Training size and performance", "labels": [], "entities": []}, {"text": " Table 5: Performance of major types in case", "labels": [], "entities": []}, {"text": " Table 6: Depth and maximumwidth of decision  tree", "labels": [], "entities": [{"text": "Depth", "start_pos": 10, "end_pos": 15, "type": "METRIC", "confidence": 0.9836896061897278}]}, {"text": " Table 7: Training Size vs. Coverage", "labels": [], "entities": [{"text": "Training Size vs. Coverage", "start_pos": 10, "end_pos": 36, "type": "TASK", "confidence": 0.672524020075798}]}, {"text": " Table 8: Case vs. Coverage", "labels": [], "entities": []}]}