{"title": [], "abstractContent": [{"text": "In this paper we describe a method for performing word sense disambiguation (WSD).", "labels": [], "entities": [{"text": "word sense disambiguation (WSD)", "start_pos": 50, "end_pos": 81, "type": "TASK", "confidence": 0.8095547705888748}]}, {"text": "The method relies on unsupervised learning and exploits functional relations among words as produced by a shallow parser.", "labels": [], "entities": []}, {"text": "By exploiting an error driven rule learning algorithm (Brill 1997), the system is able to produce rules for WSD, which can be optionally edited by humans in order to increase the performance of the system.", "labels": [], "entities": [{"text": "WSD", "start_pos": 108, "end_pos": 111, "type": "TASK", "confidence": 0.816291868686676}]}], "introductionContent": [{"text": "Although automatic word sense disambiguation (WSD) remains a much more difficult task than part of speech (POS) disambiguation, resources and automatic systems are starting to appear.", "labels": [], "entities": [{"text": "automatic word sense disambiguation (WSD)", "start_pos": 9, "end_pos": 50, "type": "TASK", "confidence": 0.7646024738039289}, {"text": "part of speech (POS) disambiguation", "start_pos": 91, "end_pos": 126, "type": "TASK", "confidence": 0.6059166831629617}]}, {"text": "Some of these systems are even mature enough to be evaluated.", "labels": [], "entities": []}, {"text": "This paper presents an overview of a system for English WSD which will be evaluated ill the context of the SENSEVAL project 1.", "labels": [], "entities": [{"text": "WSD", "start_pos": 56, "end_pos": 59, "type": "TASK", "confidence": 0.725960910320282}]}, {"text": "We report on performing automatic WSD using a specially-adapted version of Brill's error driven unsupervised learning program, originally developed for POS tagging.", "labels": [], "entities": [{"text": "WSD", "start_pos": 34, "end_pos": 37, "type": "TASK", "confidence": 0.9517378807067871}, {"text": "POS tagging", "start_pos": 152, "end_pos": 163, "type": "TASK", "confidence": 0.7436544001102448}]}, {"text": "In our experiment, like ill Resnik (1997), we used both functional and semantic information in order to improve the learning capabilities of the system.", "labels": [], "entities": []}, {"text": "Indeed, by having access to a syntactic and functional sketch of sentences, and by being able to stipulate which relations are important for sentence meaning, we overcame some of the traditional problems found in continuous bigram models, such as the occurrence of interpolated clauses and passive constructions.", "labels": [], "entities": []}, {"text": "Consider, for example, temporal expressions like Tuesday in The stock market Tuesday staged a technical recovery.", "labels": [], "entities": []}, {"text": "Such expressions are quite frequent in newspaper text, often appearing near 1 http://www.itri.bton.ac.uk/events/senseval verbs.", "labels": [], "entities": []}, {"text": "Without any functional information, the semantic rules produced by the algorithm will stipulate a strong semantic relation between the semantic class of words like Tuesday and the semantic class of verbs like stage.", "labels": [], "entities": []}, {"text": "On the contrary, if we use information from a shallow parser, we know that Tuesday is an adverbial expression, probably part of the verb phrase, and that the really important relation to learn is the one between the subject and the verb.", "labels": [], "entities": []}, {"text": "In the following sections we describe (i) the resources we used (Penn Tree Bank, 45 upper level WordNet tags); (ii) the experiment we ran using rule induction techniques on functional relations (functional relation extraction, tag merging, corpus preparation and learning); (iii) the evaluation we performed on the semantically handtagged part of the Brown corpus and, finally, we sketch out the general architecture we are in the process of implementing.", "labels": [], "entities": [{"text": "Penn Tree Bank", "start_pos": 65, "end_pos": 79, "type": "DATASET", "confidence": 0.9945000410079956}, {"text": "functional relation extraction", "start_pos": 195, "end_pos": 225, "type": "TASK", "confidence": 0.7123784025510153}, {"text": "tag merging", "start_pos": 227, "end_pos": 238, "type": "TASK", "confidence": 0.7065368741750717}, {"text": "Brown corpus", "start_pos": 351, "end_pos": 363, "type": "DATASET", "confidence": 0.8360640704631805}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Precision and recall figures", "labels": [], "entities": [{"text": "Precision", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.990969717502594}, {"text": "recall", "start_pos": 24, "end_pos": 30, "type": "METRIC", "confidence": 0.9958178400993347}]}]}