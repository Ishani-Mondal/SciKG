{"title": [{"text": "Predicting Part-of-Speech Information about Unknown Words using Statistical Methods", "labels": [], "entities": [{"text": "Predicting Part-of-Speech Information about Unknown Words", "start_pos": 0, "end_pos": 57, "type": "TASK", "confidence": 0.8962452113628387}]}], "abstractContent": [{"text": "This paper examines the feasibility of using statistical methods to train a part-of-speech pre-dictor for unknown words.", "labels": [], "entities": []}, {"text": "By using statistical methods, without incorporating hand-crafted linguistic information, the predictor could be used with any language for which there is a large tagged training corpus.", "labels": [], "entities": []}, {"text": "Encouraging results have been obtained by testing the predic-tor on unknown words from the Brown corpus.", "labels": [], "entities": [{"text": "Brown corpus", "start_pos": 91, "end_pos": 103, "type": "DATASET", "confidence": 0.9531579315662384}]}, {"text": "The relative value of information sources such as affixes and context is discussed.", "labels": [], "entities": []}, {"text": "This part-of-speech predictor will be used in a part-of-speech tagger to handle out-of-lexicon words.", "labels": [], "entities": []}], "introductionContent": [{"text": "Part-of-speech tagging involves selecting the most likely sequence of syntactic categories for the words in a sentence.", "labels": [], "entities": [{"text": "Part-of-speech tagging", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.7701317965984344}]}, {"text": "These syntactic categories, or tags, generally consist of parts of speech, often with feature information included.", "labels": [], "entities": []}, {"text": "An example set of tags can be found in the Penn Treebank project.", "labels": [], "entities": [{"text": "Penn Treebank project", "start_pos": 43, "end_pos": 64, "type": "DATASET", "confidence": 0.9928993781407675}]}, {"text": "Part-ofspeech tagging is useful for speeding up parsing systems, and allowing the use of partial parsing.", "labels": [], "entities": [{"text": "Part-ofspeech tagging", "start_pos": 0, "end_pos": 21, "type": "TASK", "confidence": 0.7430056035518646}, {"text": "parsing", "start_pos": 48, "end_pos": 55, "type": "TASK", "confidence": 0.9762153625488281}]}, {"text": "Many current systems make use of a Hidden Markov Model (HMM) for part-of-speech tagging.", "labels": [], "entities": [{"text": "part-of-speech tagging", "start_pos": 65, "end_pos": 87, "type": "TASK", "confidence": 0.7494927644729614}]}, {"text": "Other methods include rule-based systems, maximum entropy models, and memory-based models (.", "labels": [], "entities": []}, {"text": "In an HMM tagger the Markov assumption is made so that the current word depends only on the current tag, and the current tag depends only on adjacent tags.", "labels": [], "entities": [{"text": "HMM tagger", "start_pos": 6, "end_pos": 16, "type": "TASK", "confidence": 0.7405565679073334}]}, {"text": "gives a thorough explanation of the equations for an describes an HMM tagging system in detail.", "labels": [], "entities": [{"text": "HMM tagging", "start_pos": 66, "end_pos": 77, "type": "TASK", "confidence": 0.8164628744125366}]}, {"text": "One important area of research in part-ofspeech tagging is how to handle unknown words.", "labels": [], "entities": [{"text": "part-ofspeech tagging", "start_pos": 34, "end_pos": 55, "type": "TASK", "confidence": 0.8367727100849152}]}, {"text": "If a word is not in the lexicon, then the lexical probabilities must be provided from some other source.", "labels": [], "entities": []}, {"text": "One common approach is to use affixation rules to \"learn\" the probabilities for words based on their suffixes or prefixes.", "labels": [], "entities": []}, {"text": "Weischedel's group () examines unknown words in the context of part-of-speech tagging.", "labels": [], "entities": [{"text": "part-of-speech tagging", "start_pos": 63, "end_pos": 85, "type": "TASK", "confidence": 0.7110766917467117}]}, {"text": "Their method creates a probability distribution for an unknown word based on certain features: word endings, hyphenation, and capitalization.", "labels": [], "entities": []}, {"text": "The features to be used are chosen by hand for the system.", "labels": [], "entities": []}, {"text": "Mikheev) uses a general purpose lexicon to learn affix and word ending information to be used in tagging unknown words.", "labels": [], "entities": [{"text": "tagging unknown words", "start_pos": 97, "end_pos": 118, "type": "TASK", "confidence": 0.8825493653615316}]}, {"text": "His work returns a set of possible tags for unknown words, with no probabilities attached, relying on the tagger to disambiguate them.", "labels": [], "entities": []}, {"text": "This work investigates the possibility of automatically creating a probability distribution overall tags for an unknown word, instead of a simple set of tags.", "labels": [], "entities": []}, {"text": "This can be done by creating a probabilistic lexicon from a large tagged corpus (in this case, the Brown corpus), and using that data to estimate distributions for words with a given \"prefix\" or \"suffix\".", "labels": [], "entities": [{"text": "Brown corpus", "start_pos": 99, "end_pos": 111, "type": "DATASET", "confidence": 0.8345600366592407}]}, {"text": "Prefix and suffix indicate substrings that come at the beginning and end of a word respectively, and are not necessarily morphologically meaningful.", "labels": [], "entities": [{"text": "Prefix", "start_pos": 0, "end_pos": 6, "type": "METRIC", "confidence": 0.9873974919319153}]}, {"text": "This predictor will offer a probability distribution of possible tags for an unknown word, based solely on statistical data available in the training corpus.", "labels": [], "entities": []}, {"text": "Mikheev's and Weischedel's systems, along with many others, uses language specific information by using a hand-generated set of English affixes.", "labels": [], "entities": []}, {"text": "This paper investigates what information sources can be automatically constructed, and which are most useful in predicting tags for unknown words.", "labels": [], "entities": [{"text": "predicting tags for unknown words", "start_pos": 112, "end_pos": 145, "type": "TASK", "confidence": 0.8577667355537415}]}], "datasetContent": [{"text": "The experiments were performed using the Brown corpus.", "labels": [], "entities": [{"text": "Brown corpus", "start_pos": 41, "end_pos": 53, "type": "DATASET", "confidence": 0.9582023322582245}]}, {"text": "A 10-fold cross-validation technique was used to generate the data.", "labels": [], "entities": []}, {"text": "The sentences from the corpus were split into ten files, nine of which were used to train the predictor, and one which was the test set.", "labels": [], "entities": [{"text": "predictor", "start_pos": 94, "end_pos": 103, "type": "TASK", "confidence": 0.9349744915962219}]}, {"text": "The lexicon for the test run is created using the data from the training set.", "labels": [], "entities": []}, {"text": "All unknown words in the test set (those that did not occur in the training set) were assigned a tag distribution by the predictor.", "labels": [], "entities": []}, {"text": "Then the results are checked to see if the correct tag is in the n-best tags.", "labels": [], "entities": []}, {"text": "The results from all ten test files were combined to rate the overall performance for the experiment.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Results using Various Methods", "labels": [], "entities": []}]}