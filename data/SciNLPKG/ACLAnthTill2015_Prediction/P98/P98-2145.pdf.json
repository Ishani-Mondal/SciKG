{"title": [{"text": "Text Segmentation with Multiple Surface Linguistic Cues", "labels": [], "entities": [{"text": "Text Segmentation", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.6810314953327179}]}], "abstractContent": [{"text": "In general, a certain range of sentences in a text, is widely assumed to form a coherent unit which is called a discourse segment.", "labels": [], "entities": []}, {"text": "Identifying the segment boundaries is a first step to recognize the structure of a text.", "labels": [], "entities": []}, {"text": "In this paper, we describe a method for identifying segment boundaries of a Japanese text with the aid of multiple surface linguistic cues, though our experiments might be small-scale.", "labels": [], "entities": [{"text": "identifying segment boundaries of a Japanese text", "start_pos": 40, "end_pos": 89, "type": "TASK", "confidence": 0.7414696642330715}]}, {"text": "We also present a method of training the weights for multiple linguistic cues automatically without the overfitting problem.", "labels": [], "entities": []}], "introductionContent": [{"text": "A text consists of multiple sentences that have semantic relations with each other.", "labels": [], "entities": []}, {"text": "They form semantic units which are usually called discourse segments.", "labels": [], "entities": []}, {"text": "The global discourse structure of a text can be constructed by relating the discourse segments with each other.", "labels": [], "entities": []}, {"text": "Therefore, identifying segment boundaries in a text is considered as a first step to construct the discourse structure(.", "labels": [], "entities": []}, {"text": "The use of surface linguistic cues in a text for identification of segment boundaries has been extensively researched, since it is impractical to assume the use of world knowledge for discourse analysis of real texts.", "labels": [], "entities": [{"text": "identification of segment boundaries", "start_pos": 49, "end_pos": 85, "type": "TASK", "confidence": 0.8755487203598022}]}, {"text": "Among a variety of surface cues, lexical cohesion, the surface relationship among words that are semantically similar, has recently received much attention and has been widely used for text segmentation.", "labels": [], "entities": [{"text": "text segmentation", "start_pos": 185, "end_pos": 202, "type": "TASK", "confidence": 0.7922213673591614}]}, {"text": "found that the information of lexical cohesion is not enough and incorporation of other surface information may improve the accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 124, "end_pos": 132, "type": "METRIC", "confidence": 0.9984976053237915}]}, {"text": "In this paper, we describe a method for identifying segment boundaries of a Japanese text with the aid of multiple surface linguistic cues, such as conjunctives, ellipsis, types of sentences, and lexical cohesion.", "labels": [], "entities": []}, {"text": "There area variety of methods for combining multiple knowledge sources (linguistic cues).", "labels": [], "entities": []}, {"text": "Among them, a weighted sum of the scores for all cues that reflects their contribution to identifying the correct segment boundaries is often used as the overall measure to rank the possible segment boundaries.", "labels": [], "entities": []}, {"text": "In the past researches (, the weights for each cue tend to be determined by intuition or trial and error.", "labels": [], "entities": []}, {"text": "Since determining weights by hand is a labor-intensive task and the weights do not always to achieve optimal or even near-optimal performance, we think it is better to determine the weights automatically in order to both avoid the need for expert hand tuning and achieve performance that is at least locally optimal.", "labels": [], "entities": []}, {"text": "We begin by assuming the existence of training texts with the correct segment boundaries and use the method of multiple regression analysis for automatically training the weights.", "labels": [], "entities": []}, {"text": "However, there is a well-known problem in the methods of automatically training the weights, that the weights tend to be overfitted to the training data.", "labels": [], "entities": []}, {"text": "In such a case, the weights cause the degrade of the performance for other texts.", "labels": [], "entities": []}, {"text": "It is considered that the overfitting problem is caused by the relatively large number of the parameters (linguistic cues) compared with the size of the training data.", "labels": [], "entities": []}, {"text": "Furthermore, all of the linguistic cues are not always useful.", "labels": [], "entities": []}, {"text": "Therefore, we optimize the use of cues for training the weights.", "labels": [], "entities": []}, {"text": "We think if only the useful cues are selected from the entire set of cues, better weights can be obtained.", "labels": [], "entities": []}, {"text": "Fortunately, since several methods for parameters selection are already developed in the multiple regression analysis, we use one of these methods called the stepwise method.", "labels": [], "entities": [{"text": "parameters selection", "start_pos": 39, "end_pos": 59, "type": "TASK", "confidence": 0.7321353256702423}, {"text": "multiple regression analysis", "start_pos": 89, "end_pos": 117, "type": "TASK", "confidence": 0.6787650386492411}]}, {"text": "Therefore we think we can obtain the weights only for the useful by the using the multiple regression analysis and the stepwise method.", "labels": [], "entities": []}, {"text": "To give the evidence for the above claims that are summarized below, we carryout some preliminary experiments to show the effectiveness of our approach, even though our experiments might be small-scale.", "labels": [], "entities": []}, {"text": "\u2022 Combining multiple surface cues is effective for text segmentation.", "labels": [], "entities": [{"text": "text segmentation", "start_pos": 51, "end_pos": 68, "type": "TASK", "confidence": 0.8322723805904388}]}, {"text": "\u2022 The multiple regression analysis with the stepwise method is good for selecting the useful cues for text segmentation and weighting these cues automatically.", "labels": [], "entities": [{"text": "text segmentation", "start_pos": 102, "end_pos": 119, "type": "TASK", "confidence": 0.7807269990444183}]}, {"text": "In section two we outline the surface linguistic cues that we use for text segmentation.", "labels": [], "entities": [{"text": "text segmentation", "start_pos": 70, "end_pos": 87, "type": "TASK", "confidence": 0.7789323627948761}]}, {"text": "In section three we describe a method for automatically determining the weights for multiple cues.", "labels": [], "entities": []}, {"text": "In section four we describe a method for automatically selecting cues.", "labels": [], "entities": []}, {"text": "In section five we describe the experiments with our approach.", "labels": [], "entities": []}], "datasetContent": [{"text": "To give the evidence for the claims that are mentioned in the previous sections and are summarized below, we carryout some preliminary experiments to show the effectiveness of our approach.", "labels": [], "entities": []}, {"text": "\u2022 Combining multiple surface cues is effective for text segmentation.", "labels": [], "entities": [{"text": "text segmentation", "start_pos": 51, "end_pos": 68, "type": "TASK", "confidence": 0.8322723805904388}]}, {"text": "\u2022 The multiple regression analysis with the stepwise method is good for selecting the useful cues and weighting these cues automatically.", "labels": [], "entities": []}, {"text": "We pick out 14 texts, which are from the exam questions of the Japanese language that ask us to partition the texts into a given number of segments.", "labels": [], "entities": []}, {"text": "The question is like \"Answer 3 points which partition the following text into semantic units.\"", "labels": [], "entities": []}, {"text": "The system's performance is evaluated by comparing the system's outputs with the model answer attached to the above exam question.", "labels": [], "entities": []}, {"text": "In our 14 texts, the average number of points (boundary candidates) is 20 (the range from 12 to 47).", "labels": [], "entities": []}, {"text": "The average number of correct answers boundaries from the model answer is 3.4 (the range from 2 to 6).", "labels": [], "entities": []}, {"text": "Here we do not take into account the information of paragraph boundaries (such as the indentation) at all due to the following two reasons: Many of the exam question texts have no marks of paragraph boundaries; In case of Japanese texts, it is pointed out that paragraph boundaries and segment boundaries do not always coincide with each other.", "labels": [], "entities": []}, {"text": "In our experiments, the system generates the outputs in the order of the score scr(n,n + 1).", "labels": [], "entities": []}, {"text": "We evaluate the performance in the cases where the system outputs 10%,20%,30%, and 40% of the number of boundary candidates.", "labels": [], "entities": []}, {"text": "We use two measures, Recall and Precision for the evaluation: Recall is the quotient of the number of correctly identified boundaries by the total number of correct boundaries.", "labels": [], "entities": [{"text": "Recall", "start_pos": 21, "end_pos": 27, "type": "METRIC", "confidence": 0.9967353940010071}, {"text": "Precision", "start_pos": 32, "end_pos": 41, "type": "METRIC", "confidence": 0.9987391829490662}, {"text": "Recall", "start_pos": 62, "end_pos": 68, "type": "METRIC", "confidence": 0.9975848197937012}]}, {"text": "Precision is the quotient of the number of correctly identified boundaries by the number of generated boundaries.", "labels": [], "entities": [{"text": "Precision", "start_pos": 0, "end_pos": 9, "type": "METRIC", "confidence": 0.9564979076385498}]}, {"text": "The experiments are made on the following cases: 1.", "labels": [], "entities": []}, {"text": "Use the information of except for lexical cohesion (cues from 1 to 18 and 23).", "labels": [], "entities": []}, {"text": "2. Use the information of lexical cohesion(cues from 19 to 22).", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: The result of the human subjects  [ recall [precision[", "labels": [], "entities": [{"text": "recall", "start_pos": 46, "end_pos": 52, "type": "METRIC", "confidence": 0.9854193925857544}]}]}