{"title": [{"text": "Reference Resolution beyond Coreference: a Conceptual Frame and its Application", "labels": [], "entities": [{"text": "Reference Resolution", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.7991145253181458}, {"text": "Coreference", "start_pos": 28, "end_pos": 39, "type": "TASK", "confidence": 0.8018139004707336}]}], "abstractContent": [{"text": "A model for reference use in communication is proposed, from a rep-resentationist point of view.", "labels": [], "entities": []}, {"text": "Both the sender and the receiver of a message handle representations of their common environment, including mental representations of objects.", "labels": [], "entities": []}, {"text": "Reference resolution by a computer is viewed as the construction of object representations using referring expressions from the discourse, whereas often only coreference links between such expressions are looked for.", "labels": [], "entities": [{"text": "Reference resolution", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.9265100061893463}]}, {"text": "Differences between these two approaches are discussed.", "labels": [], "entities": []}, {"text": "The model has been implemented with elementary rules, and tested on complex narrative texts (hundreds to thousands of referring expressions).", "labels": [], "entities": []}, {"text": "The results support the mental representations paradigm.", "labels": [], "entities": []}], "introductionContent": [{"text": "Most of the natural language understanding methods have been originally developed on domain-specific examples, but more recently several methods have been applied to large corpora, as for instance morphosyntactic tagging or word-sense disambiguation.", "labels": [], "entities": [{"text": "natural language understanding", "start_pos": 12, "end_pos": 42, "type": "TASK", "confidence": 0.6710506478945414}, {"text": "morphosyntactic tagging", "start_pos": 197, "end_pos": 220, "type": "TASK", "confidence": 0.6927527785301208}, {"text": "word-sense disambiguation", "start_pos": 224, "end_pos": 249, "type": "TASK", "confidence": 0.7275204360485077}]}, {"text": "These methods contribute only indirectly to text understanding, being far from building a conceptual representation of the processed discourse.", "labels": [], "entities": [{"text": "text understanding", "start_pos": 44, "end_pos": 62, "type": "TASK", "confidence": 0.8838122487068176}]}, {"text": "Anaphora or pronoun resolution have also reached significant results on unrestricted texts.", "labels": [], "entities": [{"text": "Anaphora or pronoun resolution", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.6465811505913734}]}, {"text": "Coreference resolution is the next step on the way towards discourse understanding.", "labels": [], "entities": [{"text": "Coreference resolution", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.880271852016449}, {"text": "discourse understanding", "start_pos": 59, "end_pos": 82, "type": "TASK", "confidence": 0.7405112683773041}]}, {"text": "The Message Understanding Conferences (MUC) propose since 1995 a coreference task: coreferring expressions are to be linked using appropriate mark-up.", "labels": [], "entities": [{"text": "Message Understanding Conferences (MUC)", "start_pos": 4, "end_pos": 43, "type": "TASK", "confidence": 0.8482294082641602}]}, {"text": "Reference resolution goes further: it has to find out which object is referred to by an expression, thus gradually building a representation of the objects with their features and evolution.", "labels": [], "entities": [{"text": "Reference resolution", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.9269823431968689}]}, {"text": "Coreference resolution is only part of this task, as coreference is only a relation between two expressions that refer to the same object.", "labels": [], "entities": [{"text": "Coreference resolution", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.9413859844207764}]}, {"text": "A framework for reference use inhuman communication is introduced in Section 1, in order to give a coherent and general view of the phenomenon.", "labels": [], "entities": []}, {"text": "Consequences fora resolution mechanism are then examined: data structures, operations, selectional constraints and activation.", "labels": [], "entities": []}, {"text": "This approach is then compared to others in Section 2.", "labels": [], "entities": []}, {"text": "Section 3 describes briefly the implementation of the model, the texts and the scoring methods.", "labels": [], "entities": []}, {"text": "Results are given in Section 4, to corroborate the previous assertions and justify the model.", "labels": [], "entities": []}], "datasetContent": [{"text": "The MRs produced by the reference resolution module (response) are compared to the correct solution (key) using an implementation of the algorithm described by, used also in the MUC evaluations.", "labels": [], "entities": [{"text": "MUC evaluations", "start_pos": 178, "end_pos": 193, "type": "TASK", "confidence": 0.4929391145706177}]}, {"text": "Although this algorithm was designed for coreference evaluation, it builds in fact each coreference chain, and compares the key and the response partition of the RE set in MR subsets --it follows thus the MR paradigm.", "labels": [], "entities": [{"text": "coreference evaluation", "start_pos": 41, "end_pos": 63, "type": "TASK", "confidence": 0.912466287612915}]}, {"text": "The algorithm computes a recall error (number of coreference links missing in the response vs. the key) and a precision error (number of wrong coreference links, i.e. present in the response but absent from the key).", "labels": [], "entities": [{"text": "recall error", "start_pos": 25, "end_pos": 37, "type": "METRIC", "confidence": 0.9872297644615173}, {"text": "precision error", "start_pos": 110, "end_pos": 125, "type": "METRIC", "confidence": 0.9865291714668274}]}, {"text": "The MUC scoring method isn't always meaningful.", "labels": [], "entities": [{"text": "MUC scoring", "start_pos": 4, "end_pos": 15, "type": "METRIC", "confidence": 0.4535945802927017}]}, {"text": "We have shown elsewhere (Popescu-Belis and Robba 1998) that it is too indulgent, and have proposed new algorithms which seem to us more relevant, named here 'core-MR' and 'exclusive-core-MR'.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1. Characteristics of the three texts.", "labels": [], "entities": []}, {"text": " Table 2. Success scores for selection heuristics  (for VA, LPG.eq, LPG)", "labels": [], "entities": [{"text": "VA", "start_pos": 56, "end_pos": 58, "type": "METRIC", "confidence": 0.896493136882782}]}]}