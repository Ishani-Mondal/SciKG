{"title": [{"text": "ADP based Search Algorithm for Statistical Machine Translation", "labels": [], "entities": [{"text": "Statistical Machine Translation", "start_pos": 31, "end_pos": 62, "type": "TASK", "confidence": 0.8183882236480713}]}], "abstractContent": [{"text": "We introduce a novel search algorithm for statistical machine translation based on dynamic programming (DP).", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 42, "end_pos": 73, "type": "TASK", "confidence": 0.7354604204495748}]}, {"text": "During the search process two statistical knowledge sources are combined: a translation model and a bigram language model.", "labels": [], "entities": []}, {"text": "This search algorithm expands hypotheses along the positions of the target string while guaranteeing progressive coverage of the words in the source string.", "labels": [], "entities": []}, {"text": "We present experimental results on the Verbmobil task.", "labels": [], "entities": []}], "introductionContent": [], "datasetContent": [{"text": "The search algorithm suggested in this paper was tested on the Verbmobil Corpus.", "labels": [], "entities": [{"text": "Verbmobil Corpus", "start_pos": 63, "end_pos": 79, "type": "DATASET", "confidence": 0.9823612868785858}]}, {"text": "The results of preliminary tests on a small automatically generated Corpus ( were quite promising and encouraged us to apply our search algorithm to a more realistic task.", "labels": [], "entities": []}, {"text": "The Verbmobil Corpus consists of spontaneously spoken dialogs in the domain of appointment scheduling.", "labels": [], "entities": [{"text": "Verbmobil Corpus", "start_pos": 4, "end_pos": 20, "type": "DATASET", "confidence": 0.8409856557846069}, {"text": "appointment scheduling", "start_pos": 79, "end_pos": 101, "type": "TASK", "confidence": 0.7088128924369812}]}, {"text": "German source sentences are translated into English.", "labels": [], "entities": []}, {"text": "In  formed sample translations (i.e. after labelling) was 13.8.", "labels": [], "entities": []}, {"text": "In preliminary evaluations, optimal values for the thresholds OL and OT had been determined and kept fixed during the experiments.", "labels": [], "entities": [{"text": "OL", "start_pos": 62, "end_pos": 64, "type": "METRIC", "confidence": 0.9657821655273438}, {"text": "OT", "start_pos": 69, "end_pos": 71, "type": "METRIC", "confidence": 0.9418490529060364}]}, {"text": "As an automatic and easy-to-use measure of the translation performance, the Levenshtein distance between the produced translations and the sample translations was calculated.", "labels": [], "entities": [{"text": "Levenshtein distance", "start_pos": 76, "end_pos": 96, "type": "METRIC", "confidence": 0.8161508440971375}]}, {"text": "The translation results are summarized in.", "labels": [], "entities": [{"text": "translation", "start_pos": 4, "end_pos": 15, "type": "TASK", "confidence": 0.9526680707931519}]}, {"text": "Given the vocabulary sizes, it becomes quite obvious that the lexicon probabilities p(f[e) cannot be trained sufficiently on only 16 296 sentence pairs.", "labels": [], "entities": []}, {"text": "The fact that about 40% of the words in the lexicon are seen only once in training illustrates this.", "labels": [], "entities": []}, {"text": "To improve the lexicon probabilities, we interpolated them with lexicon probabilities pM(fle) manually created from a German-English dictionary: where Ne is the number of German words listed as translations of the English word e.", "labels": [], "entities": []}, {"text": "The two lexica were combined by linear interpolation with the interpolation parameter A.", "labels": [], "entities": []}, {"text": "For our first experiments, we set A to 0.5.", "labels": [], "entities": [{"text": "A", "start_pos": 34, "end_pos": 35, "type": "METRIC", "confidence": 0.9978534579277039}]}, {"text": "The test corpus consisted of 150 sentences, for which sample translations exist.", "labels": [], "entities": []}, {"text": "The labels were translated separately: First, the test sentences were preprocessed in order to replace words or groups of words by the correct category label.", "labels": [], "entities": []}, {"text": "Then, our search algorithm translated the transformed sentences.", "labels": [], "entities": []}, {"text": "In the last step, a simple rule-based algorithm replaced the category labels by the translations of the original words.", "labels": [], "entities": []}, {"text": "We used a bigram language model for the English language.", "labels": [], "entities": []}, {"text": "Its perplexity on the corpus of trans-() report a word error rate of 51.8% on similar data.", "labels": [], "entities": [{"text": "word error rate", "start_pos": 50, "end_pos": 65, "type": "METRIC", "confidence": 0.7185768286387125}]}, {"text": "Although the Levenshtein distance has the great advantage to be automatically computable, we have to keep in mind, that it depends fundamentally on the choice of the sample translation.", "labels": [], "entities": []}, {"text": "For example, each of the expressions \"thanks\", \"thank you\" and \"thank you very much\" is a legitimate translation of the German \"danke schSn\", but when calculating the Levenshtein distance to a sample translation, at least two of them will produce word errors.", "labels": [], "entities": []}, {"text": "The more words the vocabulary contains, the more important will be the problem of synonyms.", "labels": [], "entities": []}, {"text": "This is why we also asked five experts to classify independently the produced translations into three categories, being the same as in (): Correct translations are grammatical and convey the same meaning as the input.", "labels": [], "entities": []}, {"text": "Acceptable translations convey the same meaning but with small grammatical mistakes or they convey most but not the entire meaning of the input.", "labels": [], "entities": []}, {"text": "Incorrect translations are ungrammatical or convey little meaningful information or the information is different from the input.", "labels": [], "entities": []}, {"text": "Examples for each category are given in. shows the statistics of the translation performance.", "labels": [], "entities": [{"text": "translation", "start_pos": 69, "end_pos": 80, "type": "TASK", "confidence": 0.9640779495239258}]}, {"text": "When different judgements existed for one sentence, the majority vote was accepted.", "labels": [], "entities": []}, {"text": "For the calculation of the subjective sentence error rate (SSER), translations from the second category counted as \"half-correct\".", "labels": [], "entities": [{"text": "subjective sentence error rate (SSER)", "start_pos": 27, "end_pos": 64, "type": "METRIC", "confidence": 0.7789651794092995}]}, {"text": "When evaluating the performance of a statistical machine translator, we would like to distinguish errors due to the weakness of the underlying models Samstag und Februar sind gut, aber der siebzehnte w~ire besser.", "labels": [], "entities": [{"text": "statistical machine translator", "start_pos": 37, "end_pos": 67, "type": "TASK", "confidence": 0.5955951809883118}]}, {"text": "Saturday and February are quite but better the seventeenth.", "labels": [], "entities": []}, {"text": "Ich kSnnte erst eigentlich jetzt wieder dann November vorschlagen.", "labels": [], "entities": []}, {"text": "I could actually coming back November then.", "labels": [], "entities": []}, {"text": "Suggest beginning the second of November.", "labels": [], "entities": []}, {"text": "Input: Output: Ja, also mit Dienstag und mittwochs und so h/itte ich Zeit, aber Montag kommen wir hier nicht weg aus Kiel.", "labels": [], "entities": [{"text": "Kiel", "start_pos": 117, "end_pos": 121, "type": "DATASET", "confidence": 0.9717290997505188}]}, {"text": "Yes, and including on Tuesday and Wednesday as well, I have time on Monday but we will come to be away from Kiel.", "labels": [], "entities": []}, {"text": "Input: Dann fahren wir da los.", "labels": [], "entities": []}, {"text": "Output: We go out.: Subjective evaluation of the translation performance on Verbmobil: number of sentences evaluated as Correct (C), Acceptable (A) or Incorrect (I).", "labels": [], "entities": [{"text": "Output", "start_pos": 0, "end_pos": 6, "type": "METRIC", "confidence": 0.9221060276031494}, {"text": "Verbmobil", "start_pos": 76, "end_pos": 85, "type": "DATASET", "confidence": 0.8902230262756348}, {"text": "Acceptable", "start_pos": 133, "end_pos": 143, "type": "METRIC", "confidence": 0.9690306782722473}]}, {"text": "For the total percentage of non-correct translations (SSER), the \"acceptable\" translations are counted as half-errors. from search errors, occuring whenever the search algorithm misses a translation hypothesis with a higher score.", "labels": [], "entities": []}, {"text": "Unfortunately, we can never be sure that a search error does not occur, because we do not know whether or not there is another string with an even higher score than the produced output.", "labels": [], "entities": []}, {"text": "Nevertheless, it is quite interesting to compare the score of the algorithm's output and the score of the sample translation in such cases in which the output is not correct (it is classified as \"acceptable\" or \"incorrect\" ).", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 5: Comparison: Score of Reference Transla- tion e and Translator Output e ~ for \"acceptable\"  translations (A) and \"incorrect\" translations (I).  For the total number of non-correct translations  (T), the \"acceptable\" translations are counted as  half-errors.", "labels": [], "entities": []}]}