{"title": [{"text": "A Concept-based Adaptive Approach to Word Sense Disambiguation", "labels": [], "entities": [{"text": "Word Sense Disambiguation", "start_pos": 37, "end_pos": 62, "type": "TASK", "confidence": 0.7197977503140768}]}], "abstractContent": [{"text": "Word sense disambiguation for unrestricted text is one of the most difficult tasks in the fields of computational linguistics.", "labels": [], "entities": [{"text": "Word sense disambiguation", "start_pos": 0, "end_pos": 25, "type": "TASK", "confidence": 0.7189572056134542}]}, {"text": "The crux of the problem is to discover a model that relates the intended sense of a word with its context.", "labels": [], "entities": []}, {"text": "This paper describes a general framework for adaptive conceptual word sense disambiguation.", "labels": [], "entities": [{"text": "adaptive conceptual word sense disambiguation", "start_pos": 45, "end_pos": 90, "type": "TASK", "confidence": 0.6872796297073365}]}, {"text": "Central to this WSD framework is the sense division and semantic relations based on topical analysis of dictionary sense definitions.", "labels": [], "entities": [{"text": "sense division", "start_pos": 37, "end_pos": 51, "type": "TASK", "confidence": 0.7262180894613266}]}, {"text": "The process begins with an initial disambiguation step using an MRD-derived knowledge base.", "labels": [], "entities": [{"text": "MRD-derived knowledge base", "start_pos": 64, "end_pos": 90, "type": "DATASET", "confidence": 0.8117603063583374}]}, {"text": "An adaptation step follows to combine the initial knowledge base with knowledge gleaned from the partial disambiguated text.", "labels": [], "entities": []}, {"text": "Once the knowledge base is adjusted to suit the text at hand, it is then applied to the text again to finalize the disambiguation result.", "labels": [], "entities": []}, {"text": "Definitions and example sentences from LDOCE are employed as training materials for WSD, while passages from the Brown corpus and Wall Street Journal are used for testing.", "labels": [], "entities": [{"text": "WSD", "start_pos": 84, "end_pos": 87, "type": "TASK", "confidence": 0.9704482555389404}, {"text": "Brown corpus", "start_pos": 113, "end_pos": 125, "type": "DATASET", "confidence": 0.9425467252731323}, {"text": "Wall Street Journal", "start_pos": 130, "end_pos": 149, "type": "DATASET", "confidence": 0.84820955991745}]}, {"text": "We report on several experiments illustrating effectiveness of the adaptive approach.", "labels": [], "entities": []}, {"text": "1 Introduction Word sense disambiguation for unrestricted text is one of the most difficult tasks in the fields of computational linguistics.", "labels": [], "entities": [{"text": "Word sense disambiguation", "start_pos": 15, "end_pos": 40, "type": "TASK", "confidence": 0.7662222981452942}]}, {"text": "The crux of the problem is to discover a model that relates the intended sense of a word with its context.", "labels": [], "entities": []}, {"text": "It seems to be very difficult, if not impossible, to statistically acquire enough word-based knowledge about a language necessary to build a robust system capable of automatically disambiguating senses in unrestricted text.", "labels": [], "entities": []}, {"text": "For such a system to be effective, a great deal of balanced materials must be assembled in order to cover many idiosyncratic aspects of the language.", "labels": [], "entities": []}, {"text": "There exist three issues in a lexicalized statistical word sense disambiguation (WSD) model-data sparseness, lack of a level of abstraction, and static learning strategy.", "labels": [], "entities": [{"text": "statistical word sense disambiguation (WSD)", "start_pos": 42, "end_pos": 85, "type": "TASK", "confidence": 0.7396366553647178}]}, {"text": "First, word-based models have a plethora of parameters that are difficult to estimate reliably even with a very large corpus.", "labels": [], "entities": []}, {"text": "Under-trained models lead to low precision.", "labels": [], "entities": [{"text": "precision", "start_pos": 33, "end_pos": 42, "type": "METRIC", "confidence": 0.9990676045417786}]}, {"text": "Second, word-based models lack a degree of abstraction that is crucial fora broad coverage system.", "labels": [], "entities": []}, {"text": "Third, a static WSD model is unlikely to be robust and portable, since it is very difficult to make a single static model relevant to a wide variety of unrestricted texts.", "labels": [], "entities": []}, {"text": "Recent WSD systems have been developed using word-based model for specific limited domain to disambiguate senses appearing in usually easy context (Leacock, Towell, and Voorlees 1996) with a lot of typical salient words.", "labels": [], "entities": [{"text": "WSD", "start_pos": 7, "end_pos": 10, "type": "TASK", "confidence": 0.9470641016960144}]}, {"text": "For unrestricted text, however, the context tends to be very diverse and difficult to capture with a lexicalized model, therefore a corpus-trained system is unlikely to port to new domains and runoff the shelf.", "labels": [], "entities": []}, {"text": "Generality and adaptiveness are therefore key to a robust and portable WSD system.", "labels": [], "entities": []}, {"text": "A concept-based model for WSD requires less parameter and has an element of generality builtin (Liddy and Paik 1993).", "labels": [], "entities": [{"text": "WSD", "start_pos": 26, "end_pos": 29, "type": "TASK", "confidence": 0.9475447535514832}]}, {"text": "Conceptual classes make it possible to generalize from word-specific context in order to disambiguate a word sense appearing in a particularly unfamiliar context in term of word recurrences.", "labels": [], "entities": []}, {"text": "An adaptive system armed with an initial lexical and conceptual knowledge base extracted from machine-readable dictionaries (MRDs), has two strong advantages over static lexicalized models trained using a corpus.", "labels": [], "entities": []}], "introductionContent": [{"text": "Word sense disambiguation for unrestricted text is one of the most difficult tasks in the fields of computational linguistics.", "labels": [], "entities": [{"text": "Word sense disambiguation", "start_pos": 0, "end_pos": 25, "type": "TASK", "confidence": 0.7189573049545288}]}, {"text": "The crux of the problem is to discover a model that relates the intended sense of a word with its context.", "labels": [], "entities": []}, {"text": "It seems to be very difficult, if not impossible, to statistically acquire enough word-based knowledge about a language necessary to build a robust system capable of automatically disambiguating senses in unrestricted text.", "labels": [], "entities": []}, {"text": "For such a system to be effective, a great deal of balanced materials must be assembled in order to cover many idiosyncratic aspects of the language.", "labels": [], "entities": []}, {"text": "There exist three issues in a lexicalized statistical word sense disambiguation (WSD) model -data sparseness, lack of a level of abstraction, and static learning strategy.", "labels": [], "entities": [{"text": "statistical word sense disambiguation (WSD)", "start_pos": 42, "end_pos": 85, "type": "TASK", "confidence": 0.7401623598166874}]}, {"text": "First, word-based models have a plethora of parameters that are difficult to estimate reliably even with a very large corpus.", "labels": [], "entities": []}, {"text": "Under-trained models lead to low precision.", "labels": [], "entities": [{"text": "precision", "start_pos": 33, "end_pos": 42, "type": "METRIC", "confidence": 0.9990676045417786}]}, {"text": "Second, wordbased models lack a degree of abstraction that is crucial fora broad coverage system.", "labels": [], "entities": []}, {"text": "Third, a static WSD model is unlikely to be robust and portable, since it is very difficult to make a single static model relevant to a wide variety of unrestricted texts.", "labels": [], "entities": []}, {"text": "Recent WSD systems have been developed using word-based model for specific limited domain to disambiguate senses appearing in usually easy context) with a lot of typical salient words.", "labels": [], "entities": []}, {"text": "For unrestricted text, however, the context tends to be very diverse and difficult to capture with a lexicalized model, therefore a corpus-trained system is unlikely to port to new domains and runoff the shelf.", "labels": [], "entities": []}, {"text": "Generality and adaptiveness are therefore key to a robust and portable WSD system.", "labels": [], "entities": []}, {"text": "A concept-based model for WSD requires less parameter and has an element of generality builtin (Liddy and Paik 1993).", "labels": [], "entities": [{"text": "WSD", "start_pos": 26, "end_pos": 29, "type": "TASK", "confidence": 0.9475447535514832}]}, {"text": "Conceptual classes make it possible to generalize from wordspecific context in order to disambiguate a word sense appearing in a particularly unfamiliar context in term of word recurrences.", "labels": [], "entities": []}, {"text": "An adaptive system armed with an initial lexical and conceptual knowledge base extracted from machine-readable dictionaries (MRDs), has two strong advantages over static lexicalized models trained using a corpus.", "labels": [], "entities": []}, {"text": "First, the initial knowledge is rich and unbiased such that a substantial portion of text can be disambiguated precisely.", "labels": [], "entities": []}, {"text": "Second, based on the result of initial disambiguated text.", "labels": [], "entities": []}, {"text": "Subsequently, the knowledge base is adjusted to suit the text at hand.", "labels": [], "entities": []}, {"text": "The adjusted knowledge base is then  disambiguation, an adaptation step is taken to make the knowledge base more relevant to the task at hand, leading to broader and more precise WSD.", "labels": [], "entities": [{"text": "WSD", "start_pos": 179, "end_pos": 182, "type": "TASK", "confidence": 0.8661057353019714}]}, {"text": "lays out the general framework for an adaptive conceptual WSD approach, under which this research is being carried out.", "labels": [], "entities": [{"text": "WSD", "start_pos": 58, "end_pos": 61, "type": "TASK", "confidence": 0.8609223365783691}]}, {"text": "The learning process described here begins with a step of knowledge acquisition from MRDs.", "labels": [], "entities": [{"text": "knowledge acquisition from MRDs", "start_pos": 58, "end_pos": 89, "type": "TASK", "confidence": 0.6673168763518333}]}, {"text": "With the acquired knowledge, the system reads the input text and starts the step of initial disambiguation.", "labels": [], "entities": []}, {"text": "Adaptive step follows to combine the initial knowledge base with knowledge gleaned from the partially applied to the text again to finalize the disambiguation result.", "labels": [], "entities": []}, {"text": "For instance, shows the initial contextual representation (CR) extracted from the Longrnan Dictionary of Contemporary English for the GEO-bank sense contained both lexical and conceptual information: {land, river, lake, ...} u {GEO, MOTION ....", "labels": [], "entities": [{"text": "initial contextual representation (CR)", "start_pos": 24, "end_pos": 62, "type": "METRIC", "confidence": 0.5876652052005132}, {"text": "Longrnan Dictionary of Contemporary English", "start_pos": 82, "end_pos": 125, "type": "DATASET", "confidence": 0.9691465258598327}, {"text": "MOTION", "start_pos": 233, "end_pos": 239, "type": "METRIC", "confidence": 0.8719338774681091}]}, {"text": "}. The initial CR is informative enough to disambiguate a passage containing a deer near the riverbank in the input text.", "labels": [], "entities": [{"text": "CR", "start_pos": 15, "end_pos": 17, "type": "METRIC", "confidence": 0.9225296974182129}]}, {"text": "The initial disambiguation step produces sense tagging of deer~ANIMAL and bank~GEOGRAPHY, but certain instances of bank are left untagged for lack of relevant WSD knowledge.", "labels": [], "entities": [{"text": "sense tagging", "start_pos": 41, "end_pos": 54, "type": "TASK", "confidence": 0.6319949328899384}, {"text": "ANIMAL", "start_pos": 63, "end_pos": 69, "type": "METRIC", "confidence": 0.8590914607048035}, {"text": "GEOGRAPHY", "start_pos": 79, "end_pos": 88, "type": "DATASET", "confidence": 0.6641511917114258}, {"text": "WSD", "start_pos": 159, "end_pos": 162, "type": "TASK", "confidence": 0.9376598596572876}]}, {"text": "For instance, the GEO-bank sense in the context of vole is unresolved since there is no information linking ANIMAL context to GEOGRAPHY sense of bank.", "labels": [], "entities": []}, {"text": "The adaptation step adds deer and ANIMAL to the contextual representation for GEO-bank.", "labels": [], "entities": [{"text": "ANIMAL", "start_pos": 34, "end_pos": 40, "type": "METRIC", "confidence": 0.9723867177963257}, {"text": "GEO-bank", "start_pos": 78, "end_pos": 86, "type": "DATASET", "confidence": 0.9412968754768372}]}, {"text": "The enriched CR therefore contains information capable of disambiguating the instance of bank in the context of vole to produce final disambiguation result.", "labels": [], "entities": []}, {"text": "In the following subsections we describe how that is done.", "labels": [], "entities": []}], "datasetContent": [{"text": "In our experiment, we use the materials of text windows of 50 words to the left and 50 words to the right of thirteen polysemous words in the Brown corpus and a sample of Wall Street Journal articles.", "labels": [], "entities": [{"text": "Brown corpus", "start_pos": 142, "end_pos": 154, "type": "DATASET", "confidence": 0.9208458065986633}, {"text": "Wall Street Journal articles", "start_pos": 171, "end_pos": 199, "type": "DATASET", "confidence": 0.9191722422838211}]}, {"text": "All instances of these thirteen words are first disambiguated by two human judges.", "labels": [], "entities": []}, {"text": "For these thirteen words under investigation, only nominal senses are considered.", "labels": [], "entities": []}, {"text": "The experimental results show that the adaptive algorithm disambiguated correctly 71% and 77% of these test cases in the Brown corpus and the WSJ sample.", "labels": [], "entities": [{"text": "Brown corpus", "start_pos": 121, "end_pos": 133, "type": "DATASET", "confidence": 0.9430479407310486}, {"text": "WSJ sample", "start_pos": 142, "end_pos": 152, "type": "DATASET", "confidence": 0.9719932675361633}]}, {"text": "However, there are still room for improvement in the area of precision.", "labels": [], "entities": [{"text": "precision", "start_pos": 61, "end_pos": 70, "type": "METRIC", "confidence": 0.9975494742393494}]}, {"text": "Evidence have shown that by exploiting the constraint of so-called \"one sense per discourse,\" and the strategy of bootstrapping (Yarowsky 1995), it is possible to boost coverage, while maintaining about the same level of precision.", "labels": [], "entities": [{"text": "precision", "start_pos": 221, "end_pos": 230, "type": "METRIC", "confidence": 0.9969336986541748}]}], "tableCaptions": []}