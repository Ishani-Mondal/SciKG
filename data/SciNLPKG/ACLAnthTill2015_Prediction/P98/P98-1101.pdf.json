{"title": [{"text": "Finite-state Approximation of Constraint-based Grammars using Left-corner Grammar Transforms", "labels": [], "entities": []}], "abstractContent": [{"text": "This paper describes how to construct a finite-state machine (FSM) approximating a 'unification-based' grammar using a left-corner grammar transform.", "labels": [], "entities": []}, {"text": "The approximation is presented as a series of grammar transforms, and is exact for left-linear and right-linear CFGs, and for trees up to a user-specified depth of center-embedding.", "labels": [], "entities": []}], "introductionContent": [{"text": "This paper describes a method for approximating grammars with finite-state machines.", "labels": [], "entities": [{"text": "approximating grammars", "start_pos": 34, "end_pos": 56, "type": "TASK", "confidence": 0.9051083922386169}]}, {"text": "Unlike the method derived from the LR(k) parsing algorithm described in, these methods use grammar transformations based on the left-corner grammar transform.", "labels": [], "entities": [{"text": "LR(k) parsing", "start_pos": 35, "end_pos": 48, "type": "TASK", "confidence": 0.49534366726875306}]}, {"text": "One advantage of the left corner methods is that they generalize straightforwardly to complex feature \"unification based\" grammars, unlike the LR(k) based approach.", "labels": [], "entities": []}, {"text": "For example, the implementation described here translates a DCG version of the example grammar given by directly into a FSM without constructing an approximating CFG.", "labels": [], "entities": [{"text": "FSM", "start_pos": 120, "end_pos": 123, "type": "DATASET", "confidence": 0.7632336616516113}, {"text": "CFG", "start_pos": 162, "end_pos": 165, "type": "DATASET", "confidence": 0.9073579907417297}]}, {"text": "Left-corner based techniques are natural for this kind of application because (with the simple optimization described below) they can parse pure leftbranching or pure right-branching structures with a stack depth of one (two if terminals are pushed and popped from the stack).", "labels": [], "entities": []}, {"text": "Higher stack depth occurs with center-embedded structures, which humans find difficult to comprehend.", "labels": [], "entities": []}, {"text": "This suggests that we may get a finite-state approximation to human performance by simply imposing a stack depth bound.", "labels": [], "entities": []}, {"text": "We provide a simple tree-geometric description of the configurations that cause an increase in a left corner parser's stack depth below.", "labels": [], "entities": []}, {"text": "The rest of this paper is structured as follows.", "labels": [], "entities": []}, {"text": "The remainder of this section outlines the \"grammar transform\" approach, summarizes the top-down parsing algorithm and discusses how finite state approximations of top-down parsers can be constructed.", "labels": [], "entities": []}, {"text": "The fact that this approximation is not exact for left linear grammars (which define finite-state languages) motivates a finite-state approximation based on the left-corner parsing algorithm (which is presented as a grammar transform in section 2).", "labels": [], "entities": []}, {"text": "In its standard form the approximation based on the left-corner parsing algorithm suffers from the complementary problem to the top-down approximation: it is not exact for right-linear grammars, but the \"optimized\" variants presented in section 3 overcome this deficiency, resulting in finite-state CFG approximations which are exact for left-linear and right-linear grammars.", "labels": [], "entities": []}, {"text": "Section 4 discusses how these techniques can be combined in an implementation.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": []}