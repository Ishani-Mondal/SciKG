{"title": [{"text": "Term-list Translation using Mono-lingual Word Co-occurrence Vectors*", "labels": [], "entities": [{"text": "Term-list Translation", "start_pos": 0, "end_pos": 21, "type": "TASK", "confidence": 0.7479232847690582}]}], "abstractContent": [{"text": "A term-list is a list of content words that characterize a consistent text or a concept.", "labels": [], "entities": []}, {"text": "This paper presents anew method for translating a term-list by using a corpus in the target language.", "labels": [], "entities": [{"text": "translating a term-list", "start_pos": 36, "end_pos": 59, "type": "TASK", "confidence": 0.8569936354955038}]}, {"text": "The method first retrieves alternative translations for each input word from a bilingual dictionary.", "labels": [], "entities": []}, {"text": "It then determines the most 'coherent' combination of alternative translations , where the coherence of a set of words is defined as the proximity among multi-dimensional vectors produced from the words on the basis of co-occurrence statistics.", "labels": [], "entities": []}, {"text": "The method was applied to term-lists extracted from newspaper articles and achieved 81% translation accuracy for ambiguous words (i.e., words with multiple translations).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 100, "end_pos": 108, "type": "METRIC", "confidence": 0.9272865653038025}]}], "introductionContent": [{"text": "A list of content words, called a term-list, is widely used as a compact representation of documents in information retrieval and other document processing.", "labels": [], "entities": [{"text": "information retrieval", "start_pos": 104, "end_pos": 125, "type": "TASK", "confidence": 0.7019648402929306}]}, {"text": "Automatic translation of term-lists enables this processing to be cross-linguistic.", "labels": [], "entities": []}, {"text": "This paper presents anew method for translating term-lists by using cooccurrence statistics in the target language.", "labels": [], "entities": [{"text": "translating term-lists", "start_pos": 36, "end_pos": 58, "type": "TASK", "confidence": 0.8347687721252441}]}, {"text": "Although there is little study on automatic translation of term-lists, related studies are found in the area of target word selection (for content words) in conventional full-text machine translation (MT).", "labels": [], "entities": [{"text": "automatic translation of term-lists", "start_pos": 34, "end_pos": 69, "type": "TASK", "confidence": 0.7974329739809036}, {"text": "full-text machine translation (MT)", "start_pos": 170, "end_pos": 204, "type": "TASK", "confidence": 0.7833746721347173}]}, {"text": "Approaches for target word selection can be classifted into two types.", "labels": [], "entities": [{"text": "target word selection", "start_pos": 15, "end_pos": 36, "type": "TASK", "confidence": 0.6254702508449554}]}, {"text": "The first type, which has been adopted in many commercial MT systems, is based on hand assembled disambiguation rules, and/or dictionaries.", "labels": [], "entities": [{"text": "MT", "start_pos": 58, "end_pos": 60, "type": "TASK", "confidence": 0.9877575635910034}]}, {"text": "The problem with this approach is that creating these rules requires much cost and that they are usually domain-dependent 1 The second type, called the statistics-based approach, learns disambiguation knowledge from large corpora.", "labels": [], "entities": []}, {"text": "an algorithm that * This research was done when the author was at Center for the Study of Language and Information(CSLI), Stanford University.", "labels": [], "entities": []}, {"text": "1In fact, this is partly shown by the fact that many MT systems have substitutable domain-dependent (or \"user\" ) dictionaries . relies on translation probabilities estimated from large bilingual corpora (). and proposed algorithms for selecting target words by using word co-occurrence statistics in the target language corpora.", "labels": [], "entities": [{"text": "MT", "start_pos": 53, "end_pos": 55, "type": "TASK", "confidence": 0.9757754802703857}]}, {"text": "The latter algorithms using mono-lingual corpora are particularly important because, at present, we cannot always get a sufficient amount of bilingual or parallel corpora.", "labels": [], "entities": []}, {"text": "Our method is closely related to) from the viewpoint that they both rely on mono-lingual corpora only and do not require any syntactic analysis.", "labels": [], "entities": []}, {"text": "The difference is that our method uses \"coherence scores\", which can capture associative relations between two words which do not co-occur in the training corpus.", "labels": [], "entities": []}, {"text": "This paper is organized as follows, Section 2 describes the overall translation process.", "labels": [], "entities": [{"text": "translation", "start_pos": 68, "end_pos": 79, "type": "TASK", "confidence": 0.9804055690765381}]}, {"text": "Section 3 presents a disambiguation algorithm, which is the core part of our translation method.", "labels": [], "entities": []}, {"text": "Section 4 and 5 give experimental results and discussion.", "labels": [], "entities": []}], "datasetContent": [{"text": "We conducted two types of experiments: retranslation experiments and translation experiments.", "labels": [], "entities": [{"text": "translation", "start_pos": 69, "end_pos": 80, "type": "TASK", "confidence": 0.9727043509483337}]}, {"text": "Each experiment includes comparison against the baseline algorithm, which is a unigrambased translation algorithm.", "labels": [], "entities": []}, {"text": "This section presents the two types of experiments, plus the baseline algorithm, followed by experimental results.", "labels": [], "entities": []}, {"text": "In the translation experiment, term-lists in one language, e.g., English, were translated into another language, e.g., in Japanese.", "labels": [], "entities": []}, {"text": "In this experiment, humans judged the correctness of outputs.", "labels": [], "entities": []}, {"text": "Although the translation experiment recreates real applications, it requires human judgment 3.", "labels": [], "entities": [{"text": "translation", "start_pos": 13, "end_pos": 24, "type": "TASK", "confidence": 0.9798627495765686}]}, {"text": "Thus we decided to conduct another type of experiment, called a re-translation experiment.", "labels": [], "entities": []}, {"text": "This experiment translates given term-lists (e.g., in English) into a second language (e.g., Japanese) and maps them back onto the source language (e.g., in this case, English).", "labels": [], "entities": []}, {"text": "Thus the correct translation of a term list, in the most strict sense, is the original term-list itself.", "labels": [], "entities": []}, {"text": "This experiment uses two bilingual dictionaries: a forward dictionary and a backward dictionary.", "labels": [], "entities": []}, {"text": "In this experiment, a word in the given term-list (e.g. in English) is first mapped to another language (e.g., Japanese) by using the forward dictionary.", "labels": [], "entities": []}, {"text": "Each translated word is then mapped back into original language by referring to the backward dictionary.", "labels": [], "entities": []}, {"text": "The union of the translations from the backward dictionary are the translation alternatives to be disambiguated.", "labels": [], "entities": []}, {"text": "The source and the target languages of the translation experiments were English and Japanese respectively.", "labels": [], "entities": []}, {"text": "The re-translation experiments were conducted for English term-lists using Japanese as the second language.", "labels": [], "entities": []}, {"text": "The Japaneseto-English dictionary was EDICT and the English-to-Japanese dictionary was an inversion of the Japanese-to-English dictionary.", "labels": [], "entities": [{"text": "EDICT", "start_pos": 38, "end_pos": 43, "type": "DATASET", "confidence": 0.6654420495033264}]}, {"text": "The co-occurrence statistics were extracted from the 1994 New York Times (420MB) for English and 1990 Nikkei Shinbun (Japanese newspaper) (150MB) for Japanese.", "labels": [], "entities": [{"text": "New York Times", "start_pos": 58, "end_pos": 72, "type": "DATASET", "confidence": 0.8194874922434489}, {"text": "1990 Nikkei Shinbun (Japanese newspaper)", "start_pos": 97, "end_pos": 137, "type": "DATASET", "confidence": 0.7941374480724335}]}, {"text": "The domains of these texts range from business to sports.", "labels": [], "entities": []}, {"text": "Note that 400 articles were randomly separated from the former corpus as the test set.", "labels": [], "entities": []}, {"text": "The initial size of each co-occurrence matrix was 20000-by-1000, where rows and columns correspond to the 20,000 and 1000 most frequent words in the corpus 4.", "labels": [], "entities": []}, {"text": "Each initial matrix was then reduced by using SVD into a matrix of 20000-by-100 using SVD-PACKC(.", "labels": [], "entities": []}, {"text": "Term-lists for the experiments were automatically generated from texts, where a term-list of a document consists of the topmost n words ranked by their tf-idf scores 5.", "labels": [], "entities": []}, {"text": "The relation between the length n of term-list and the disambiguation accuracy was also tested.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 70, "end_pos": 78, "type": "METRIC", "confidence": 0.9771093726158142}]}, {"text": "We prepared two test sets of term-lists: those extracted from the 400 articles from the New York Times mentioned above, and those extracted from articles in Reuters, called Test-NYT, and Test-REU, respectively.", "labels": [], "entities": []}, {"text": "The proposed method was applied to several sets of term-lists of different length.", "labels": [], "entities": []}, {"text": "In this table and the following tables, \"ambiguous\" and \"success\" correspond to the total number of ambiguous words, not term-lists, and the number of words that were successfully translated 6.", "labels": [], "entities": []}, {"text": "The best results were obtained when the length of term-lists was 4 or 6.", "labels": [], "entities": []}, {"text": "In general, the longer a termlist becomes, the more information it has.", "labels": [], "entities": []}, {"text": "However, along term-list tends to be less coherent (i.e., contain different topics).", "labels": [], "entities": []}, {"text": "As far as our experiments are concerned, 4 or 6 was the point of compromise.", "labels": [], "entities": []}, {"text": "Then we compared our method against the baseline algorithm that was trained on the same set of articles used to create the co-occurrence matrix for our algorithm (i.e., New York Times).", "labels": [], "entities": [{"text": "New York Times)", "start_pos": 169, "end_pos": 184, "type": "DATASET", "confidence": 0.8810845166444778}]}, {"text": "Both are applied to term-lists of length 6 made from test-NYT.", "labels": [], "entities": []}, {"text": "The results are shown in.", "labels": [], "entities": []}, {"text": "Although the absolute value of the success rate is not satisfactory, our method significantly outperforms the baseline algorithm.", "labels": [], "entities": []}, {"text": "We, then, applied the same method with the same parameters (i.e., cooccurence and unigram data) to Test-REU.", "labels": [], "entities": []}, {"text": "As shown in, our method did better than the baseline algorithm although the success rate is lower than the previous result.", "labels": [], "entities": []}, {"text": "6If 100 term-lists were processed and each term-list contains 2 ambiguous words, then the \"total\" becomes 200.", "labels": [], "entities": []}, {"text": "The translation experiment from English to Japanese was carried out on Test-NYT.", "labels": [], "entities": [{"text": "translation", "start_pos": 4, "end_pos": 15, "type": "TASK", "confidence": 0.9807695150375366}, {"text": "Test-NYT", "start_pos": 71, "end_pos": 79, "type": "DATASET", "confidence": 0.9925922155380249}]}, {"text": "The training corpus for both proposed and baseline methods was the Nikkei corpus described above.", "labels": [], "entities": [{"text": "Nikkei corpus", "start_pos": 67, "end_pos": 80, "type": "DATASET", "confidence": 0.9731557369232178}]}, {"text": "Outputs were compared against the \"correct data\" which were manually created by removing incorrect alternatives from all possible alternatives.", "labels": [], "entities": []}, {"text": "If all the translation alternatives in the bilingual dictionary were judged to be correct, then we counted this word as unambiguous.", "labels": [], "entities": []}, {"text": "The accuracy of our method and baseline algorithm are shown on Table6.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.9994592070579529}]}, {"text": "The accuracy of our method was 80.8%, about 8 points higher than that of the baseline method.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.9997851252555847}]}, {"text": "This shows our method is effective in improving translation accuracy when syntactic information is not available.", "labels": [], "entities": [{"text": "translation", "start_pos": 48, "end_pos": 59, "type": "TASK", "confidence": 0.9734567999839783}, {"text": "accuracy", "start_pos": 60, "end_pos": 68, "type": "METRIC", "confidence": 0.8099680542945862}]}, {"text": "In this experiment, 57% of input words were unambiguous.", "labels": [], "entities": []}, {"text": "Thus the success rates for entire words were 91.8% (proposed) and 82.6% (baseline).", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: An example of scores", "labels": [], "entities": []}, {"text": " Table 3. In this table and the following tables,  \"ambiguous\" and \"success\" correspond to the total  number of ambiguous words, not term-lists, and the  number of words that were successfully translated 6.  The best results were obtained when the length of  term-lists was 4 or 6. In general, the longer a term- list becomes, the more information it has. However,  a long term-list tends to be less coherent (i.e., con- tain different topics). As far as our experiments are  concerned, 4 or 6 was the point of compromise.", "labels": [], "entities": []}, {"text": " Table 3: Result of Re-translation for Test-NYT  length success/ambiguous (rate)  2  98/141  (69.5%)  4  240/329  (72.9%)  6  410/555  (73.8%)  8  559/777  (71.9%)  10  691/981  (70.4%)  12  813/1165  (69.8%)", "labels": [], "entities": [{"text": "ambiguous (rate)", "start_pos": 64, "end_pos": 80, "type": "METRIC", "confidence": 0.8949375152587891}]}]}