{"title": [{"text": "Characterizing and Recognizing Spoken Corrections in Human-Computer Dialogue", "labels": [], "entities": [{"text": "Characterizing and Recognizing Spoken Corrections in Human-Computer Dialogue", "start_pos": 0, "end_pos": 76, "type": "TASK", "confidence": 0.7868701070547104}]}], "abstractContent": [{"text": "Miscommunication in speech recognition systems is unavoidable, but a detailed characterization of user corrections will enable speech systems to identify when a correction is taking place and to more accurately recognize the content of correction utterances.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 20, "end_pos": 38, "type": "TASK", "confidence": 0.6994318217039108}]}, {"text": "In this paper we investigate the adaptations of users when they encounter recognition errors in interactions with a voice-in/voice-out spoken language system.", "labels": [], "entities": []}, {"text": "In analyzing more than 300 pairs of original and repeat correction utterances, matched on speaker and lexical content, we found overall increases in both utterance and pause duration from original to correction.", "labels": [], "entities": []}, {"text": "Interestingly, corrections of misrecognition errors (CME) exhibited significantly heightened pitch variability, while corrections of rejection errors (CRE) showed only a small but significant decrease in pitch minimum.", "labels": [], "entities": [{"text": "pitch variability", "start_pos": 93, "end_pos": 110, "type": "METRIC", "confidence": 0.9689452648162842}, {"text": "rejection errors (CRE)", "start_pos": 133, "end_pos": 155, "type": "METRIC", "confidence": 0.830938720703125}, {"text": "pitch minimum", "start_pos": 204, "end_pos": 217, "type": "METRIC", "confidence": 0.9678722620010376}]}, {"text": "CME's demonstrated much greater increases in measures of duration and pitch variability than CRE's.", "labels": [], "entities": [{"text": "duration", "start_pos": 57, "end_pos": 65, "type": "METRIC", "confidence": 0.9964438080787659}, {"text": "pitch", "start_pos": 70, "end_pos": 75, "type": "METRIC", "confidence": 0.9379706382751465}]}, {"text": "These contrasts allow the development of decision trees which distinguish CME's from CRE's and from original inputs at 70-75% accuracy based on duration, pitch, and amplitude features.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 126, "end_pos": 134, "type": "METRIC", "confidence": 0.998055100440979}, {"text": "duration", "start_pos": 144, "end_pos": 152, "type": "METRIC", "confidence": 0.9703989624977112}]}], "introductionContent": [{"text": "The frequent recognition errors which plague speech recognition systems present a significant barrier to widespread acceptance of this technology.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 45, "end_pos": 63, "type": "TASK", "confidence": 0.7808409035205841}]}, {"text": "The difficulty of correcting system misrecognitions is directly correlated with user assessments of system quality.", "labels": [], "entities": [{"text": "correcting system misrecognitions", "start_pos": 18, "end_pos": 51, "type": "TASK", "confidence": 0.900614321231842}]}, {"text": "The increased probability of recognition errors immediately after an error compounds this problem.", "labels": [], "entities": []}, {"text": "Thus, it becomes crucially important to characterize the differences between original utterances and user corrections of system recognition failures both in order to recognize when a user attempts a correction, indicating a prior recognition error, and to improve recognition accuracy on these problematic utterances.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 276, "end_pos": 284, "type": "METRIC", "confidence": 0.9459896683692932}]}, {"text": "Analysis of data drawn from afield trial of a telephone-based voice-in/voice-out conversational system demonstrates significant differences between original inputs and corrections in measures of duration, pause, and pitch.", "labels": [], "entities": [{"text": "duration", "start_pos": 195, "end_pos": 203, "type": "METRIC", "confidence": 0.9667642712593079}]}, {"text": "These differences in turn aid in the development of decision trees which distinguish between new input and user corrections.", "labels": [], "entities": []}], "datasetContent": [{"text": "The next step was to develop predictive classitiers of original vs repeat corrections and CME's vs CRE's informed by the descriptive analysis above.", "labels": [], "entities": []}, {"text": "We chose to implement these classifiers with decision trees (using Quinlan's {Quinlan, 1992) C4.5) trained on a subset of the originalrepeat pair data.", "labels": [], "entities": []}, {"text": "Decision trees have two features which make them desirable for this task.", "labels": [], "entities": []}, {"text": "First, since they can ignore irrelevant attributes, they will not be misled by meaningless noise in one or more of the 38 duration, pause, pitch, and amplitude features coded.", "labels": [], "entities": []}, {"text": "Since these features are probably not all important, it is desir-able to use a technique which can identify those which are most relevant.", "labels": [], "entities": []}, {"text": "Second, decision trees are highly intelligible; simple inspection of trees can identify which rules use which attributes to arrive at a classification, unlike more opaque machine learning techniques such as neural nets.", "labels": [], "entities": []}], "tableCaptions": []}