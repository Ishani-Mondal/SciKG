{"title": [{"text": "Automatic extraction of subcorpora based on subcategorization frames from a part-of-speech tagged corpus", "labels": [], "entities": []}], "abstractContent": [{"text": "This paper presents a method for extracting subcorpora documenting different subcate-gorization frames for verbs, nouns, and adjectives in the 100 mio.", "labels": [], "entities": []}, {"text": "The extraction tool consists of a set of batch files for use with the Corpus Query Processor (CQP), which is part of the IMS corpus workbench (cf. Christ 1994a,b).", "labels": [], "entities": [{"text": "IMS corpus workbench", "start_pos": 121, "end_pos": 141, "type": "DATASET", "confidence": 0.8013862768809}]}, {"text": "A macroprocessor has been developed that allows the user to specify in a simple input file which subcorpora are to be created fora given lemma.", "labels": [], "entities": []}, {"text": "The resulting subcorpora can be used (1) to provide evidence for the subcategorization properties of a given lemma, and to facilitate the selection of corpus lines for lexicographic research, and (2) to determine the frequencies of different syntactic contexts of each lemma.", "labels": [], "entities": []}], "introductionContent": [{"text": "A number of resources are available for obtaining subcategorization information, i.e. information on the types of syntactic complements associated with valence-bearing predicators (which include verbs, nouns, and adjectives).", "labels": [], "entities": []}, {"text": "This information, also referred to as valence information is available both in machine-readable form, as in the COMLEX database (, and in humanreadable dictionaries (e.g..", "labels": [], "entities": [{"text": "COMLEX database", "start_pos": 112, "end_pos": 127, "type": "DATASET", "confidence": 0.9538432061672211}]}, {"text": "Increasingly, tools are also becoming available for acquiring subcategorization information from corpora, i.e. for inferring the subcategorization frames of a given lemma (e.g.).", "labels": [], "entities": []}, {"text": "None of these resources provide immediate access to corpus evidence, nor do they provide information on the relative frequency of the patterns that are listed fora given lemma.", "labels": [], "entities": []}, {"text": "There is a need fora tool that can (1) find evidence for subcategorization patterns and (2) determine their frequencies in large corpora: 1.", "labels": [], "entities": []}, {"text": "Statistical approaches to NLP rely on information not just on the range of combinatory possibilities of words, but also the relative frequencies of the expected patterns.", "labels": [], "entities": []}, {"text": "2. Dictionaries that list subcategorization frames often list expected patterns, rather than actual ones.", "labels": [], "entities": []}, {"text": "Lexicographers and lexicologist need access to the evidence for this information.", "labels": [], "entities": []}, {"text": "3. Frequency information has come to be the focus of much psycholinguistic research on sentence processing (see for example.", "labels": [], "entities": [{"text": "sentence processing", "start_pos": 87, "end_pos": 106, "type": "TASK", "confidence": 0.7813690602779388}]}, {"text": "While information on word frequency is readily available (e.g.), there is as yet no easy way of obtaining information from large corpora on the relative frequency of complementation patterns.", "labels": [], "entities": []}, {"text": "None of these points argue against the usefulness of the available resources, but they show that there is a gap in the available information.", "labels": [], "entities": []}, {"text": "To address this need, we have developed a tool for extracting evidence for subcategorization patterns from the 100 mio.", "labels": [], "entities": []}, {"text": "word British National Corpus (BNC).", "labels": [], "entities": [{"text": "British National Corpus (BNC)", "start_pos": 5, "end_pos": 34, "type": "DATASET", "confidence": 0.966068834066391}]}, {"text": "The tool is used as pan of the lexicon-building process in the FrameNet project, an NSF-funded project aimed at creating a lexical database based on the principles of Frame Semantics (Fillmore 1982).", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": []}