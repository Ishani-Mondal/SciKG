{"title": [{"text": "Robust Interaction through Partial Interpretation and Dialogue Management", "labels": [], "entities": [{"text": "Robust Interaction", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.8169646859169006}]}], "abstractContent": [{"text": "In this paper we present results on developing robust natural language interfaces by combining shallow and partial interpretation with dialogue management.", "labels": [], "entities": []}, {"text": "The key issue is to reduce the effort needed to adapt the knowledge sources for parsing and interpretation to a necessary minimum.", "labels": [], "entities": [{"text": "parsing and interpretation", "start_pos": 80, "end_pos": 106, "type": "TASK", "confidence": 0.7449572185675303}]}, {"text": "In the paper we identify different types of information and present corresponding computational models.", "labels": [], "entities": []}, {"text": "The approach utilizes an automatically generated lexicon which is updated with information from a corpus of simulated dialogues.", "labels": [], "entities": []}, {"text": "The grammar is developed manually from the same knowledge sources.", "labels": [], "entities": []}, {"text": "We also present results from evaluations that support the approach.", "labels": [], "entities": []}], "introductionContent": [{"text": "Relying on a traditional deep and complete analysis of the utterances in a natural language interface requires much effort on building grammars and lexicons for each domain.", "labels": [], "entities": []}, {"text": "Analyzing a whole utterance also gives problems with robustness, since the grammars need to cope with all possible variations of an utterance.", "labels": [], "entities": []}, {"text": "In this paper we present results on developing knowledge-based natural language interfaces for information retrieval applications utilizing shallow and partial interpretation.", "labels": [], "entities": [{"text": "information retrieval", "start_pos": 95, "end_pos": 116, "type": "TASK", "confidence": 0.7551917433738708}]}, {"text": "Similar approaches are proposed in, for instance, the work on flexible parsing and in speech systems (cf. ().", "labels": [], "entities": [{"text": "flexible parsing", "start_pos": 62, "end_pos": 78, "type": "TASK", "confidence": 0.6019139885902405}]}, {"text": "The interpretation is driven by the information needed by the background system and guided by expectations from a dialogue manager.", "labels": [], "entities": []}, {"text": "The analysis is done by parsing as small parts of the utterance as possible.", "labels": [], "entities": [{"text": "parsing", "start_pos": 24, "end_pos": 31, "type": "TASK", "confidence": 0.966455340385437}]}, {"text": "The information needed by the interpretation module, i.e. grammar and lexicon, is derived from the database of the background system and information from dialogues collected in Wizard of \" Authors are in alphabetical order Oz-experiments.", "labels": [], "entities": []}, {"text": "We will present what types of information that are needed for the interpretation modules.", "labels": [], "entities": []}, {"text": "We will also report on the sizes of the grammars and lexicon and results from applying the approach to information retrieval systems.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Precision and recall for the grammars", "labels": [], "entities": [{"text": "Precision", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9764372110366821}, {"text": "recall", "start_pos": 24, "end_pos": 30, "type": "METRIC", "confidence": 0.9983235001564026}, {"text": "grammars", "start_pos": 39, "end_pos": 47, "type": "TASK", "confidence": 0.5441989898681641}]}, {"text": " Table 2: Precision and recall when concepts  from the test set were added  Properties", "labels": [], "entities": [{"text": "Precision", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9859858751296997}, {"text": "recall", "start_pos": 24, "end_pos": 30, "type": "METRIC", "confidence": 0.999352753162384}]}]}