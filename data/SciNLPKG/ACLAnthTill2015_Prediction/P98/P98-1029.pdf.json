{"title": [{"text": "Classifier Combination for Improved Lexical Disambiguation", "labels": [], "entities": [{"text": "Improved Lexical Disambiguation", "start_pos": 27, "end_pos": 58, "type": "TASK", "confidence": 0.6576036512851715}]}], "abstractContent": [{"text": "One of the most exciting recent directions in machine learning is the discovery that the combination of multiple classifiers often results in significantly better performance than what can be achieved with a single classifier.", "labels": [], "entities": [{"text": "machine learning", "start_pos": 46, "end_pos": 62, "type": "TASK", "confidence": 0.7620076835155487}]}, {"text": "In this paper, we first show that the errors made from three different state of the art part of speech taggers are strongly complementary.", "labels": [], "entities": [{"text": "speech taggers", "start_pos": 96, "end_pos": 110, "type": "TASK", "confidence": 0.7377793192863464}]}, {"text": "Next, we show how this complementary behavior can be used to our advantage.", "labels": [], "entities": []}, {"text": "By using contextual cues to guide tagger combination, we are able to derive anew tagger that achieves performance significantly greater than any of the individual taggers.", "labels": [], "entities": [{"text": "tagger combination", "start_pos": 34, "end_pos": 52, "type": "TASK", "confidence": 0.9144604206085205}]}], "introductionContent": [{"text": "Part of speech tagging has been a central problem in natural language processing for many years.", "labels": [], "entities": [{"text": "speech tagging", "start_pos": 8, "end_pos": 22, "type": "TASK", "confidence": 0.7242472171783447}, {"text": "natural language processing", "start_pos": 53, "end_pos": 80, "type": "TASK", "confidence": 0.6447867453098297}]}, {"text": "Since the advent of manually tagged corpora such as the Brown Corpus and the Penn Treebank (,), the efficacy of machine learning for training a tagger has been demonstrated using a wide array of techniques, including: Markov models, decision trees, connectionist machines, transformations, nearest-neighbor algorithms, and maximum entropy (,,,,,).", "labels": [], "entities": [{"text": "Brown Corpus", "start_pos": 56, "end_pos": 68, "type": "DATASET", "confidence": 0.916628360748291}, {"text": "Penn Treebank", "start_pos": 77, "end_pos": 90, "type": "DATASET", "confidence": 0.9798707664012909}]}, {"text": "All of these methods seem to achieve roughly comparable accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 56, "end_pos": 64, "type": "METRIC", "confidence": 0.997957706451416}]}, {"text": "The fact that most machine-learningbased taggers achieve comparable results could be attributed to a number of causes.", "labels": [], "entities": [{"text": "machine-learningbased taggers", "start_pos": 19, "end_pos": 48, "type": "TASK", "confidence": 0.6346810460090637}]}, {"text": "It is possible that the 80/20 rule of engineering is applying: a certain number of tagging instances are relatively simple to disambiguate and are therefore being successfully tagged by all approaches, while another percentage is extremely difficult to disambiguate, requiring deep linguistic knowledge, thereby causing all taggers to err.", "labels": [], "entities": []}, {"text": "Another possibility could be that all of the different machine learning techniques are essentially doing the same thing.", "labels": [], "entities": []}, {"text": "We know that the features used by the different algorithms are very similar, typically the words and tags within a small window from the word being tagged.", "labels": [], "entities": []}, {"text": "Therefore it could be possible that they all end up learning the same information, just in different forms.", "labels": [], "entities": []}, {"text": "In the field of machine learning, there have been many recent results demonstrating the efficacy of combining classifiersJ In this paper we explore whether classifier combination can result in an overall improvement in lexical disambiguation accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 242, "end_pos": 250, "type": "METRIC", "confidence": 0.8808601498603821}]}], "datasetContent": [], "tableCaptions": []}