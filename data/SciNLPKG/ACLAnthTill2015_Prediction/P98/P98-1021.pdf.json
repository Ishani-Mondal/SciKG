{"title": [{"text": "Spoken Dialogue Interpretation with the DOP Model", "labels": [], "entities": [{"text": "Spoken Dialogue Interpretation", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.9279390176137289}]}], "abstractContent": [{"text": "We show how the DOP model can be used for fast and robust processing of spoken input in a practical spoken dialogue system called OVIS.", "labels": [], "entities": [{"text": "OVIS", "start_pos": 130, "end_pos": 134, "type": "DATASET", "confidence": 0.8402678966522217}]}, {"text": "OVIS, Openbaar Vervoer Informatie Systeem (\"Public Transport Information System\"), is a Dutch spoken language information system which operates over ordinary telephone lines.", "labels": [], "entities": [{"text": "OVIS", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.8342902064323425}]}, {"text": "The prototype system is the immediate goal of the NWO 1 Priority Programme \"Language and Speech Technology\".", "labels": [], "entities": [{"text": "NWO 1 Priority Programme", "start_pos": 50, "end_pos": 74, "type": "DATASET", "confidence": 0.8371265530586243}]}, {"text": "In this paper, we extend the original DOP model to context-sensitive interpretation of spoken input.", "labels": [], "entities": [{"text": "context-sensitive interpretation of spoken input", "start_pos": 51, "end_pos": 99, "type": "TASK", "confidence": 0.7841683924198151}]}, {"text": "The system we describe uses the OVIS corpus (10,000 trees enriched with compositional semantics) to compute from an input word-graph the best utterance together with its meaning.", "labels": [], "entities": [{"text": "OVIS corpus", "start_pos": 32, "end_pos": 43, "type": "DATASET", "confidence": 0.8881403207778931}]}, {"text": "Dialogue context is taken into account by dividing up the OVIS corpus into context-dependent subcorpora.", "labels": [], "entities": [{"text": "OVIS corpus", "start_pos": 58, "end_pos": 69, "type": "DATASET", "confidence": 0.8311663866043091}]}, {"text": "Each system question triggers a subcorpus by which the user answer is analyzed and interpreted.", "labels": [], "entities": []}, {"text": "Our experiments indicate that the context-sensitive DOP model obtains better accuracy than the original model, allowing for fast and robust processing of spoken input.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 77, "end_pos": 85, "type": "METRIC", "confidence": 0.9989696741104126}]}], "introductionContent": [{"text": "The Data-Oriented Parsing (DOP) model (cf.) is a probabilistic parsing model which does not single out a narrowly predefined set of structures as the statistically significant ones.", "labels": [], "entities": []}, {"text": "It accomplishes this by maintaining a large corpus of analyses of previously occurring utterances.", "labels": [], "entities": []}, {"text": "New utterances are analyzed by combining subtrees from the corpus.", "labels": [], "entities": []}, {"text": "The occurrence-frequencies of the subtrees are used to estimate the most probable analysis of an utterance.", "labels": [], "entities": []}, {"text": "To date, DOP has mainly been applied to corpora of trees labeled with syntactic annotations.", "labels": [], "entities": []}, {"text": "Let us illustrate this with a very simple example.", "labels": [], "entities": []}, {"text": "Suppose that a corpus consists of only two trees: (1) DOP computes the probability of substituting a subtree ton a specific node as the probability of selecting t among all subtrees in the corpus that could be substituted on that node.", "labels": [], "entities": []}, {"text": "This probability is equal to the number of occurrences oft, divided by the total number of occurrences of subtrees t' with the same root label as t.", "labels": [], "entities": []}, {"text": "Let rl(t) return the root label oft then: P(t) = #(t) / ~,t,:rl(t,)=rl(t)#(t').", "labels": [], "entities": []}, {"text": "The probability of a derivation is computed by the product of the probabilities of the subtrees is consists of.", "labels": [], "entities": []}, {"text": "The probability of a parse tree is computed by the sum of the probabilities of all derivations that produce that parse tree.", "labels": [], "entities": []}, {"text": "demonstrated that DOP can be implemented using conventional context-free parsing techniques.", "labels": [], "entities": []}, {"text": "However, the computation of the most probable parse of a sentence is NP-hard.", "labels": [], "entities": []}, {"text": "The most probable parse can be estimated by iterative Monte Carlo sampling, but efficient algorithms exist only for sub-optimal solutions such as the most likely derivation of a sentence or the \"labelled recall parse\" of a sentence.", "labels": [], "entities": [{"text": "labelled recall parse\" of a sentence", "start_pos": 195, "end_pos": 231, "type": "TASK", "confidence": 0.7831249066761562}]}, {"text": "So far, the syntactic DOP model has been tested on the ATIS corpus and the Wall Street Journal corpus, obtaining significantly better test results than other stochastic parsers.", "labels": [], "entities": [{"text": "ATIS corpus", "start_pos": 55, "end_pos": 66, "type": "DATASET", "confidence": 0.9829071760177612}, {"text": "Wall Street Journal corpus", "start_pos": 75, "end_pos": 101, "type": "DATASET", "confidence": 0.9545557647943497}]}, {"text": "For example,  with an accuracy-increase of 6.9%, or an errorreduction of 33%.", "labels": [], "entities": [{"text": "accuracy-increase", "start_pos": 22, "end_pos": 39, "type": "METRIC", "confidence": 0.9995542168617249}, {"text": "errorreduction", "start_pos": 55, "end_pos": 69, "type": "METRIC", "confidence": 0.9734345078468323}]}, {"text": "Goodman also performs a statistical analysis using t-test, showing that the differences are statistically significant beyond the 98th percentile.", "labels": [], "entities": []}, {"text": "In, it was shown how DOP can be generalized to semantic interpretation by using corpora annotated with compositional semantics.", "labels": [], "entities": [{"text": "semantic interpretation", "start_pos": 47, "end_pos": 70, "type": "TASK", "confidence": 0.7407812178134918}]}, {"text": "In the current paper, we extend the DOP model to spoken dialogue understanding, and we show how it can be used as an efficient and robust NLP component in a practical spoken dialogue system called OVIS.", "labels": [], "entities": [{"text": "spoken dialogue understanding", "start_pos": 49, "end_pos": 78, "type": "TASK", "confidence": 0.7412193218866984}]}, {"text": "OVIS, Openbaar Vervoer Informatie Systeem (\"Public Transport Information System\"), is a Dutch spoken language information system which operates over ordinary telephone lines.", "labels": [], "entities": [{"text": "OVIS", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.8342902064323425}]}, {"text": "The prototype system is the immediate goal of the NWO Priority Programme \"Language and Speech Technology\".", "labels": [], "entities": [{"text": "NWO Priority Programme", "start_pos": 50, "end_pos": 72, "type": "DATASET", "confidence": 0.7844484647115072}]}, {"text": "The backbone of any DOP model is an annotated language corpus.", "labels": [], "entities": []}, {"text": "In the following section, we therefore start with a description of the corpus that was developed for the OVIS system, the \"OVIS corpus\".", "labels": [], "entities": [{"text": "OVIS system", "start_pos": 105, "end_pos": 116, "type": "DATASET", "confidence": 0.8732300102710724}, {"text": "OVIS corpus", "start_pos": 123, "end_pos": 134, "type": "DATASET", "confidence": 0.9505737125873566}]}, {"text": "We then show how this corpus can be used by DOP to compute the most likely meaning M of a word string W: argmax g P(M, W).", "labels": [], "entities": [{"text": "argmax", "start_pos": 105, "end_pos": 111, "type": "METRIC", "confidence": 0.9694452881813049}]}, {"text": "Next we demonstrate how the dialogue context C can be integrated so as to compute argmaxg P(M, WI C).", "labels": [], "entities": [{"text": "argmaxg P", "start_pos": 82, "end_pos": 91, "type": "METRIC", "confidence": 0.9636270701885223}]}, {"text": "Finally, we interface DOP with speech and show how the most likely meaning M of an acoustic utterance A given dialogue context C is computed: argmax g P(M, AI C).", "labels": [], "entities": [{"text": "argmax", "start_pos": 142, "end_pos": 148, "type": "METRIC", "confidence": 0.9889765381813049}]}, {"text": "The last section of this paper deals with the experimental evaluation of the model.", "labels": [], "entities": []}], "datasetContent": [{"text": "In our experimental evaluation of DOP we were interested in the following questions: (1) Is DOP fast enough for practical spoken dialogue understanding?", "labels": [], "entities": [{"text": "spoken dialogue understanding", "start_pos": 122, "end_pos": 151, "type": "TASK", "confidence": 0.7283291419347128}]}, {"text": "(2) Can we constrain the OVIS subtrees without loosing accuracy?", "labels": [], "entities": [{"text": "accuracy", "start_pos": 55, "end_pos": 63, "type": "METRIC", "confidence": 0.9984776377677917}]}, {"text": "(3) What is the impact of dialogue context on the accuracy?", "labels": [], "entities": [{"text": "accuracy", "start_pos": 50, "end_pos": 58, "type": "METRIC", "confidence": 0.9925740957260132}]}, {"text": "For all experiments, we used a random split of the 10,000 OVIS trees into a 90% training set and a 10% test set.", "labels": [], "entities": [{"text": "OVIS trees", "start_pos": 58, "end_pos": 68, "type": "DATASET", "confidence": 0.7811318635940552}]}, {"text": "The training set was divided up into the four subcorpora described in section 4, which served to create the corresponding DOP parsers.", "labels": [], "entities": []}, {"text": "The 1000 wordgraphs for the test set utterances were used as input.", "labels": [], "entities": []}, {"text": "For each word-graph, the previous system question was known to determine the particular DOP parser.", "labels": [], "entities": []}, {"text": "while the user utterances were kept apart.", "labels": [], "entities": []}, {"text": "As to the complexity of the word-graphs: the average number of transitions per word is 4.2, and the average number of words per word-graph path is 4.6.", "labels": [], "entities": []}, {"text": "All experiments were run on an SGI Indigo with a MIPS RI0000 processor and 640 Mbyte of core memory, To establish the semantic accuracy of the system, the best meanings produced by the DOP parser were compared with the meanings in the test set.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 127, "end_pos": 135, "type": "METRIC", "confidence": 0.9832413196563721}]}, {"text": "Besides an exact match metric, we also used a more fine-grained evaluation for the semantic accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 92, "end_pos": 100, "type": "METRIC", "confidence": 0.9634914994239807}]}, {"text": "Following the proposals in and van translates as: <denial, destination town, almere> <correction, destination_town, alkmaar> Both the updates in the OVIS test set and the updates produced by the DOP parser were translated into semantic units of the form given above.", "labels": [], "entities": [{"text": "OVIS test set", "start_pos": 149, "end_pos": 162, "type": "DATASET", "confidence": 0.8974176446596781}]}, {"text": "The semantic accuracy was then evaluated in three different ways: (1) match, the percentage of updates which were exactly correct (i.e. which exactly matched the updates in the test set); (2) precision, the number of correct semantic units divided by the number of semantic units which were produced; (3) recall, the number of correct semantic units divided by the number of semantic units in the test set.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 13, "end_pos": 21, "type": "METRIC", "confidence": 0.9565586447715759}, {"text": "match", "start_pos": 70, "end_pos": 75, "type": "METRIC", "confidence": 0.9987878203392029}, {"text": "precision", "start_pos": 192, "end_pos": 201, "type": "METRIC", "confidence": 0.9993116855621338}, {"text": "recall", "start_pos": 305, "end_pos": 311, "type": "METRIC", "confidence": 0.9995996356010437}]}, {"text": "As to question (1), we already suspect that it is not efficient to use all OVIS subtrees.", "labels": [], "entities": []}, {"text": "We therefore performed experiments with versions of DOP where the subtree collection is restricted to subtrees with a certain maximum depth.", "labels": [], "entities": []}, {"text": "The following table shows for four different maximum depths (where the maximum number of frontier words is limited to 3), the number of subtree types in the training set, the semantic accuracy in terms of match, precision and recall (as percentages), and the average CPU time per wordgraph in seconds.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 184, "end_pos": 192, "type": "METRIC", "confidence": 0.9869480133056641}, {"text": "precision", "start_pos": 212, "end_pos": 221, "type": "METRIC", "confidence": 0.9988340735435486}, {"text": "recall", "start_pos": 226, "end_pos": 232, "type": "METRIC", "confidence": 0.9955234527587891}]}, {"text": "The experiments show that at subtree-depth 4 the highest accuracy is achieved, but that only for subtree-depths I and 2 are the processing times fast enough for practical applications.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 57, "end_pos": 65, "type": "METRIC", "confidence": 0.9992353916168213}]}, {"text": "Thus there is a trade-off between efficiency and accuracy: the efficiency deteriorates if the accuracy improves.", "labels": [], "entities": [{"text": "efficiency", "start_pos": 34, "end_pos": 44, "type": "METRIC", "confidence": 0.985363245010376}, {"text": "accuracy", "start_pos": 49, "end_pos": 57, "type": "METRIC", "confidence": 0.9989351630210876}, {"text": "accuracy", "start_pos": 94, "end_pos": 102, "type": "METRIC", "confidence": 0.9994949102401733}]}, {"text": "We believe that a match of 78.5% and a corresponding precision and recall of resp.", "labels": [], "entities": [{"text": "precision", "start_pos": 53, "end_pos": 62, "type": "METRIC", "confidence": 0.9996840953826904}, {"text": "recall", "start_pos": 67, "end_pos": 73, "type": "METRIC", "confidence": 0.9995245933532715}]}, {"text": "83.0% and 84.3% (for the fast processing times at depth 2) is promising enough for further research.", "labels": [], "entities": []}, {"text": "Moreover, by testing DOP directly on the word strings (without the word-graphs), a match of 97.8% was achieved.", "labels": [], "entities": []}, {"text": "This shows that linguistic ambiguities do not play a significant role in this domain.", "labels": [], "entities": []}, {"text": "The actual problem are the ambiguities in the word-graphs (i.e. the multiple paths).", "labels": [], "entities": []}, {"text": "Secondly, we are concerned with the question as to whether we can impose constraints on the subtrees other than their depth, in such away that the accuracy does not deteriorate and perhaps even improves.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 147, "end_pos": 155, "type": "METRIC", "confidence": 0.999437153339386}]}, {"text": "To answer this question, we kept the maximal subtreedepth constant at 3, and employed the following constraints: \u2022 Eliminating once-occurring subtrees: this led to a considerable decrease for all metrics; e.g. match decreased from 79.8% to 75.5%.", "labels": [], "entities": [{"text": "match", "start_pos": 210, "end_pos": 215, "type": "METRIC", "confidence": 0.9971653819084167}]}, {"text": "\u2022 Restricting subtree lexicalization: restricting the maximum number of words in the subtree frontiers to resp.", "labels": [], "entities": []}, {"text": "3, 2 and 1, showed a consistent decrease in semantic accuracy similar to the restriction of the subtree depth in table 1.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 53, "end_pos": 61, "type": "METRIC", "confidence": 0.9743179678916931}]}, {"text": "The match dropped from 79.8% to 76.9% if each subtree was lexicalized with only one word.", "labels": [], "entities": []}, {"text": "\u2022 Eliminating subtrees with only non-head words: this led also to a decrease inaccuracy; the most stringent metric decreased from 79.8% to 77.1%.", "labels": [], "entities": []}, {"text": "Evidently, there can be important relations in OVIS that involve non-head words.", "labels": [], "entities": []}, {"text": "Finally, we are interested in the impact of dialogue context on semantic accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 73, "end_pos": 81, "type": "METRIC", "confidence": 0.6685398817062378}]}, {"text": "To test this, we neglected the previous system questions and created one DOP parser for the whole training set.", "labels": [], "entities": []}, {"text": "The semantic accuracy metric match dropped from 79.8% to 77.4% (for depth 3).", "labels": [], "entities": [{"text": "accuracy metric match", "start_pos": 13, "end_pos": 34, "type": "METRIC", "confidence": 0.9319500724474589}]}, {"text": "Moreover, the CPU time per sentence deteriorated by a factor of 4 (which is mainly due to the fact that larger training sets yield slower DOP parsers).", "labels": [], "entities": []}, {"text": "The following result nicely illustrates how the dialogue context can contribute to better predictions for the correct meaning of an utterance.", "labels": [], "entities": []}, {"text": "In parsing the word-graph corresponding to the acoustic utterance Donderdag acht februari (\"Thursday eight February\"), the DOP model without dialogue context assigned highest probability to a derivation yielding the word string Dordrecht acht februari and its meaning.", "labels": [], "entities": []}, {"text": "The uttered word Donderdag was thus interpreted as the town Dordrecht which was indeed among the other hypothesized words in the word-graph.", "labels": [], "entities": []}, {"text": "If the DOP model took into account the dialogue context, the previous system question When do you want to leave? was known and thus triggered the subtrees from the date-subcorpus only, which now correctly assigned the highest probability to Donderdag acht februari and its meaning, rather than to Dordrecht acht februari.", "labels": [], "entities": [{"text": "Dordrecht acht februari", "start_pos": 297, "end_pos": 320, "type": "DATASET", "confidence": 0.873349924882253}]}], "tableCaptions": [{"text": " Table 1: Experimental results on OVIS word-graphs", "labels": [], "entities": []}]}