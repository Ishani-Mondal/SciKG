{"title": [{"text": "Automatic Construction of Frame Representations for Spontaneous Speech in Unrestricted Domains", "labels": [], "entities": [{"text": "Automatic Construction of Frame Representations", "start_pos": 0, "end_pos": 47, "type": "TASK", "confidence": 0.7387055814266205}]}], "abstractContent": [{"text": "This paper presents a system which automatically generates shallow semantic frame structures for conversational speech in unrestricted domains.", "labels": [], "entities": []}, {"text": "We argue that such shallow semantic representations can indeed be generated with a minimum amount of linguistic knowledge engineering and without having to explicitly construct a semantic knowledge base.", "labels": [], "entities": []}, {"text": "The system is designed to be robust to deal with the problems of speech dysfluencies, ungrammaticalities, and imperfect speech recognition.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 120, "end_pos": 138, "type": "TASK", "confidence": 0.7597200870513916}]}, {"text": "Initial results on speech transcripts are promising in that correct mappings could be identified in 21% of the clauses of a test set (resp.", "labels": [], "entities": []}, {"text": "44% of this test set where ungrammatical or verb-less clauses were removed).", "labels": [], "entities": []}], "introductionContent": [{"text": "In syntactic and semantic analysis of spontaneous speech, little research has been done with regard to dealing with language in unrestricted domains.", "labels": [], "entities": [{"text": "syntactic and semantic analysis of spontaneous speech", "start_pos": 3, "end_pos": 56, "type": "TASK", "confidence": 0.7763762048312596}]}, {"text": "There are several reasons why so far an in-depth analysis of this type of language data has been considered prohibitively hard: \u2022 inherent properties of spontaneous speech, such as dysfiuencies and ungrammaticalities \u2022 word accuracy being far from perfect (e.g., on atypical corpus such as SWITCHBOARD (SWBD) (, current state-of-the-art recognizers have word error rates in the range of 30-40% ()) \u2022 if the domain is unrestricted, manual construction of a semantic knowledge base with reasonable coverage is very labor intensive In this paper we propose to combine methods of partial parsing (\"chunking\") with the mapping of the verb arguments onto subcategorization frames that can be extracted automatically, in this case, from WordNet (.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 224, "end_pos": 232, "type": "METRIC", "confidence": 0.8681578040122986}, {"text": "WordNet", "start_pos": 730, "end_pos": 737, "type": "DATASET", "confidence": 0.9646896123886108}]}, {"text": "As preliminary results indicate, this yields away of generating shallow semantic representations efficiently and with minimal manual effort.", "labels": [], "entities": []}, {"text": "Eventually, these semantic structures can serve as (additional) input to a variety of different tasks in NLP, such as text or dialogue summarization, information gisting, information retrieval, or shallow machine translation.", "labels": [], "entities": [{"text": "text or dialogue summarization", "start_pos": 118, "end_pos": 148, "type": "TASK", "confidence": 0.6012533009052277}, {"text": "information gisting", "start_pos": 150, "end_pos": 169, "type": "TASK", "confidence": 0.763902485370636}, {"text": "information retrieval", "start_pos": 171, "end_pos": 192, "type": "TASK", "confidence": 0.8162092566490173}, {"text": "shallow machine translation", "start_pos": 197, "end_pos": 224, "type": "TASK", "confidence": 0.6290292541186014}]}], "datasetContent": [{"text": "We performed some initial experiments using the SWBD transcripts as input to the system.", "labels": [], "entities": []}, {"text": "These were POS tagged, preprocessed, segmented into short clauses, parsed in chunks using a POS based grammar, and finally, for each short clause, the frame-mapper matched all potential arguments of the verb against all possible subcategorization frames listed in the lemmata file we had precomputed from WordNet (see section 2).", "labels": [], "entities": [{"text": "WordNet", "start_pos": 305, "end_pos": 312, "type": "DATASET", "confidence": 0.9545985460281372}]}, {"text": "In total we had over 600000 short clauses, containing approximately 1.7 million chunks.", "labels": [], "entities": []}, {"text": "Only 18 different chunk patterns accounted for about half of these short clauses.", "labels": [], "entities": []}, {"text": "4 Most of these contain main verbs and hence can be sensibly used in a mapping procedure but some of them (e.g., aff, con j, advp) do not.", "labels": [], "entities": []}, {"text": "These are typically backchannellings, adverbial comments, and colloquial forms (e.g., \"yeah\", \"and...\", \"oh really\").", "labels": [], "entities": []}, {"text": "They can be easily dealt with a preprocessing module that assigns them to one of these categories and does not send them to the mapper.", "labels": [], "entities": []}, {"text": "Another interesting observation we make here is that within these most common chunk patterns, there is only one pattern (np vb np pp) which could lead to a potential PP-attachment ambiguity.", "labels": [], "entities": []}, {"text": "We conjecture that this is most probably due to the nature of conversational speech which, unlike for written (and more formal) language, does not make too frequent use of complex noun phrases that have one or multiple prepositional phrases attached to them.", "labels": [], "entities": []}, {"text": "We selected 98 short clauses randomly from the output to perform a first error analysis.", "labels": [], "entities": []}, {"text": "The results are summarized in.", "labels": [], "entities": []}, {"text": "In over 21% of the clauses, the mapper finds at least one mapping that is correct.", "labels": [], "entities": []}, {"text": "Another 23.5% of the clauses do not contain any chunks that are worth to be mapped in the first place (noises, hesitations), 4 Chunk abbreviations: conj=conjunction, aft=affirmative, np=noun phrase, vb=verbai chunk, vbneg=negated verbal chunk, adjp=adjectival phrase, advp=adverbial phrase, pp=prepositional phrase.", "labels": [], "entities": []}, {"text": "so these could be filtered out and dealt with entirely before the mapping process takes place, as we mentioned earlier.", "labels": [], "entities": []}, {"text": "28.6% of the clauses are in some sense incomplete, mostly they are lacking a main verb which is the crucial element to get the mapping procedure started.", "labels": [], "entities": []}, {"text": "We regard these as \"hard\" residues, including well-known linguistic problems such as ellipsis, in addition to some spoken language ungrammaticalities.", "labels": [], "entities": []}, {"text": "The last two categories (26.6% combined) in the table are due to the incompleteness and inaccuracies of the system components themselves.", "labels": [], "entities": []}, {"text": "To illustrate the process of mapping, we shall present an example here, starting from the POS-tagged utterance up to the semantic frame representation:5 s ( (to/PREP) [theme/an] (you/PRPA))) (again/RB) Since chunks like advp or conj are not part of the WordNet frames, we remove these from the parsed chunk sequence, before a mapping attempt is being made.", "labels": [], "entities": []}, {"text": "7 In our example, WordNet yields 14 frames for 6 senses of the main verb talk.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 18, "end_pos": 25, "type": "DATASET", "confidence": 0.9598385691642761}]}, {"text": "The mapper already finds a \"perfect match \"s for the first, i.e., the most frequent sense 9 of the verb (mapping 4 can be estimated to be more accurate than mapping 3 since also the preposition matches to the input string).", "labels": [], "entities": []}, {"text": "This will be also the default sense to choose, unless there is a word sense disambiguating module available that strongly favors a less frequent sense.", "labels": [], "entities": []}, {"text": "Since WordNet 1.5 does not provide detailed semantic frame information but only general subcategorization with extensions such as \"animate/inanimate\", we plan to extend this information by processing machine-readable dictionaries which provide a richer set of semantic role information of verbal heads, l\u00b0 It is interesting to see that even at this early stage of our project the results of this shallow analysis are quite encouraging.", "labels": [], "entities": []}, {"text": "If we remove those clauses from the test set which either should not or cannot be mapped in the first place (because they are either not containing any structure (\"non-mappable\") or are ungrammatical), the remainder of 47 clauses already has a success-rate of 44.7%.", "labels": [], "entities": []}, {"text": "Improvements of the system components before the mapping stage as well as to the mapper itself will further increase the mapping performance.", "labels": [], "entities": []}, {"text": "7These chunks can be easily added to the mapper's output again, as shown in the example.", "labels": [], "entities": []}, {"text": "Spartial matches, such as mappings I and 2 in this example, are allowed but disfavored to perfect matches.", "labels": [], "entities": []}, {"text": "9In WordNet 1.5, the first sense is also supposed to be the most frequent one.", "labels": [], "entities": [{"text": "9In WordNet 1.5", "start_pos": 0, "end_pos": 15, "type": "DATASET", "confidence": 0.7993427316347758}]}, {"text": "l\u00b0The \"agent\" and \"theme\" assignments are currently just defaults for these types of subcat frames.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: WordNet: verbal lemmata, senses,  and frames", "labels": [], "entities": [{"text": "WordNet", "start_pos": 10, "end_pos": 17, "type": "DATASET", "confidence": 0.9618033170700073}]}, {"text": " Table 2: Most frequent chunk sequences in  short clauses", "labels": [], "entities": []}, {"text": " Table 3. In over  21% of the clauses, the mapper finds at least one  mapping that is correct. Another 23.5% of the  clauses do not contain any chunks that are worth  to be mapped in the first place (noises, hesitations),", "labels": [], "entities": []}]}