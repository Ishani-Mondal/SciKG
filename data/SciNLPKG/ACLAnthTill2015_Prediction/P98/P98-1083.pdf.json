{"title": [{"text": "Using Decision Trees to Construct a Practical Parser", "labels": [], "entities": []}], "abstractContent": [{"text": "This paper describes novel and practical Japanese parsers that uses decision trees.", "labels": [], "entities": []}, {"text": "First, we construct a single decision tree to estimate modification probabilities; how one phrase tends to modify another.", "labels": [], "entities": []}, {"text": "Next, we introduce a boosting algorithm in which several decision trees are constructed and then combined for probability estimation.", "labels": [], "entities": []}, {"text": "The two constructed parsers are evaluated by using the EDR Japanese annotated corpus.", "labels": [], "entities": [{"text": "EDR Japanese annotated corpus", "start_pos": 55, "end_pos": 84, "type": "DATASET", "confidence": 0.9646309912204742}]}, {"text": "The single-tree method outperforms the conventional .Japanese stochastic methods by 4%.", "labels": [], "entities": []}, {"text": "Moreover, the boosting version is shown to have significant advantages; 1) better parsing accuracy than its single-tree counterpart for any amount of training data and 2) no over-fitting to data for various iterations.", "labels": [], "entities": [{"text": "parsing", "start_pos": 82, "end_pos": 89, "type": "TASK", "confidence": 0.9652310609817505}, {"text": "accuracy", "start_pos": 90, "end_pos": 98, "type": "METRIC", "confidence": 0.9573681354522705}]}], "introductionContent": [{"text": "Conventional parsers with practical levels of performance require a number of sophisticated rules that have to be hand-crafted by human linguists.", "labels": [], "entities": []}, {"text": "It is time-consunaing and cumbersome to naaintain these rules for two reasons.", "labels": [], "entities": []}, {"text": "\u2022 The rules are specific to the application domain.", "labels": [], "entities": []}, {"text": "\u2022 Specific rules handling collocational expressions create side effects.", "labels": [], "entities": []}, {"text": "Such rules often deteriorate t, he overall performance of the parser.", "labels": [], "entities": []}, {"text": "The stochastic approach, on the other hand, has the potential to overcome these difficulties.", "labels": [], "entities": []}, {"text": "Because it. induces stochastic rules to maximize overall performance against training data, it not only adapts to any application domain but.", "labels": [], "entities": []}, {"text": "also may avoid overfitting to the data.", "labels": [], "entities": []}, {"text": "In the late 80s and early 90s, the induction and parameter estimation of probabilistic context free grammars (PCFGs) from corpora were intensively studied.", "labels": [], "entities": [{"text": "parameter estimation of probabilistic context free grammars (PCFGs) from corpora", "start_pos": 49, "end_pos": 129, "type": "TASK", "confidence": 0.7695961197217306}]}, {"text": "Because these grammars comprise only nonterminal and part-of-speech tag symbols, their performances were not enough to be used in practical applications.", "labels": [], "entities": []}, {"text": "A broader range of information, in particular lexical information, was found to be essential in disambiguating the syntactic structures of real-world sentences.", "labels": [], "entities": []}, {"text": "SPATTER) augmented the pure PCFG by introducing a number of lexical attributes.", "labels": [], "entities": []}, {"text": "The parser controlled applications of each rule by using the lexical constraints induced by decision tree algorithm.", "labels": [], "entities": []}, {"text": "The SPATTER parser attained 87% accuracy and first made stochastic parsers a practical choice.", "labels": [], "entities": [{"text": "SPATTER parser", "start_pos": 4, "end_pos": 18, "type": "TASK", "confidence": 0.6096681356430054}, {"text": "accuracy", "start_pos": 32, "end_pos": 40, "type": "METRIC", "confidence": 0.9992817044258118}]}, {"text": "The other type of highprecision parser, which is based on dependency analysis was introduced by.", "labels": [], "entities": []}, {"text": "Dependency analysis first segments a sentence into syntactically meaningful sequences of words and then considers the modification of each segment.", "labels": [], "entities": [{"text": "Dependency analysis", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.9180250763893127}]}, {"text": "Collins' parser computes the likelihood that each segment modifies the other (2 term relation) by using large corpora.", "labels": [], "entities": []}, {"text": "These modification probabilities are conditioned by head words of two segments, distance between the two segments and other syntactic features.", "labels": [], "entities": []}, {"text": "Although these two parsers have shown similar performance, the keys of their success are slightly different.", "labels": [], "entities": []}, {"text": "SPATTER parser performance greatly depends on the feature selection ability of the decision tree algorithm rather than its linguistic representation.", "labels": [], "entities": [{"text": "SPATTER parser", "start_pos": 0, "end_pos": 14, "type": "TASK", "confidence": 0.8657984137535095}]}, {"text": "On the other hand, dependency analysis plays an essential role in Collins' parser for efficiently extracting information from corpora.", "labels": [], "entities": [{"text": "dependency analysis", "start_pos": 19, "end_pos": 38, "type": "TASK", "confidence": 0.8885640501976013}]}, {"text": "In this paper, we describe practical Japanese dependency parsers that uses decision trees.", "labels": [], "entities": [{"text": "dependency parsers", "start_pos": 46, "end_pos": 64, "type": "TASK", "confidence": 0.6551669538021088}]}, {"text": "In the Japanese language, dependency analysis has been shown to be powerful because segment (bunsetsu) order in a sentence is relatively free compared to European languages..Japanese dependency parsers generally proceed in three steps.", "labels": [], "entities": [{"text": "dependency analysis", "start_pos": 26, "end_pos": 45, "type": "TASK", "confidence": 0.8718258142471313}, {"text": "Japanese dependency parsers", "start_pos": 174, "end_pos": 201, "type": "TASK", "confidence": 0.6500475207964579}]}, {"text": "1. Segment a sentence into a sequence of bunsetsu.", "labels": [], "entities": []}, {"text": "2. Prepare a modification matrix, each value of which represents how one bunsetsu is likely to modify another.", "labels": [], "entities": []}, {"text": "3. Find optimal modifications in a sentence by a dynamic programming technique.", "labels": [], "entities": []}, {"text": "The most difficult part is the second; how to construct a sophisticated modification matrix.", "labels": [], "entities": []}, {"text": "With conventional Japanese parsers, the linguist nmst classify the bunsetsu and select appropriate features to compute modification values.", "labels": [], "entities": []}, {"text": "The parsers thus suffer from application domain diversity and the side effects of specific rules.", "labels": [], "entities": []}, {"text": "Stochastic dependency parsers like Collins', on the other hand, define a set of attributes for conditioning the modification probabilities.", "labels": [], "entities": []}, {"text": "The parsers consider all of the attributes regardless of bunsetsu type.", "labels": [], "entities": []}, {"text": "These methods can encompass only a small number of features if the probabilities are to be precisely evaluated from finite number of data.", "labels": [], "entities": []}, {"text": "Our decision tree method constructs a more sophisticated modification matrix.", "labels": [], "entities": []}, {"text": "It automatically selects a sufficient number of significant attributes according to bunsetsu type.", "labels": [], "entities": []}, {"text": "We can use arbitrary numbers of the attributes which potentially increase parsing accuracy.", "labels": [], "entities": [{"text": "parsing", "start_pos": 74, "end_pos": 81, "type": "TASK", "confidence": 0.9764615297317505}, {"text": "accuracy", "start_pos": 82, "end_pos": 90, "type": "METRIC", "confidence": 0.9596183896064758}]}, {"text": "Natural languages are full of exceptional and collocational expressions.", "labels": [], "entities": []}, {"text": "It is difficult for machine learning algorithms, as well as human linguists, to judge whether a specific rule is relevant in terms of overall performance.", "labels": [], "entities": []}, {"text": "To tackle this problem, we test the mixture of sequentially generated decision trees.", "labels": [], "entities": []}, {"text": "Specifically, we use the Ada-Boost algorithm) which iteratively performs two procedures: 1.", "labels": [], "entities": []}, {"text": "construct a decision tree based on the current data distribution and 2.", "labels": [], "entities": []}, {"text": "updating the distribution by focusing on data that are not well predicted by the constructed tree.", "labels": [], "entities": []}, {"text": "The final modification probabilities are computed by mixing all the decision trees according to their performance.", "labels": [], "entities": []}, {"text": "The sequential decision trees gradually change from broad coverage to specific exceptional trees that.", "labels": [], "entities": []}, {"text": "cannot be captured by a single general tree.", "labels": [], "entities": []}, {"text": "In other words, the method incorporates not only general expressions but also infrequent specific ones.", "labels": [], "entities": []}, {"text": "The rest of the paper is constructed as follows.", "labels": [], "entities": []}, {"text": "Section 2 summarizes dependency analysis for the Japanese language.", "labels": [], "entities": [{"text": "dependency analysis", "start_pos": 21, "end_pos": 40, "type": "TASK", "confidence": 0.7965914309024811}]}, {"text": "Section 3 explains our decision tree models that compute modification probabilities.", "labels": [], "entities": []}, {"text": "Section 4 then presents experimental results obtained by using EDR Japanese annotated corpora.", "labels": [], "entities": [{"text": "EDR Japanese annotated corpora", "start_pos": 63, "end_pos": 93, "type": "DATASET", "confidence": 0.8894832879304886}]}, {"text": "Finally, section 5 concludes the paper.", "labels": [], "entities": []}], "datasetContent": [{"text": "We evaluated the proposed parser using the EDR Japanese annotated corpus.", "labels": [], "entities": [{"text": "EDR Japanese annotated corpus", "start_pos": 43, "end_pos": 72, "type": "DATASET", "confidence": 0.9701877981424332}]}, {"text": "The experiment consisted of two parts.", "labels": [], "entities": []}, {"text": "One evaluated the single-tree parser and the other tile boosting counterpart.", "labels": [], "entities": []}, {"text": "In tile rest of this section, parsing accuracy refers only to precision; how many of tile system's output are correct in terms of the annotated corpus.", "labels": [], "entities": [{"text": "parsing", "start_pos": 30, "end_pos": 37, "type": "TASK", "confidence": 0.9682464003562927}, {"text": "accuracy", "start_pos": 38, "end_pos": 46, "type": "METRIC", "confidence": 0.9379467964172363}, {"text": "precision", "start_pos": 62, "end_pos": 71, "type": "METRIC", "confidence": 0.9992364645004272}]}, {"text": "We do not show recall because we assume every bunsetsu modifies only one posterior bunsetsu.", "labels": [], "entities": [{"text": "recall", "start_pos": 15, "end_pos": 21, "type": "METRIC", "confidence": 0.999039351940155}]}, {"text": "The features used for learning were non head-word features, (i.e., type 2 to 8 in).", "labels": [], "entities": []}, {"text": "Section 4.1.4 investigates lexical information of head words such as frequent, words and thesaurus categories.", "labels": [], "entities": []}, {"text": "Before going into details of tile experimental results, we sunnnarize here how training and test data were selected.", "labels": [], "entities": []}, {"text": "1. After all sentences in the EDR corpus were word-segmented and part-of-speech tagged (Matsumoto and others, 1996), they were then chunked into a sequence of bunsetsu.   were the 2501th to 3000th sentences of each file.", "labels": [], "entities": [{"text": "EDR corpus", "start_pos": 30, "end_pos": 40, "type": "DATASET", "confidence": 0.9256519973278046}]}, {"text": "In the singletree experiments, we evaluated the following 4 properties of the new dependency parser.", "labels": [], "entities": []}, {"text": "\u2022 Tree pruning and parsing accuracy  This section reports experimental results on the boosting version of our parser.", "labels": [], "entities": [{"text": "parsing", "start_pos": 19, "end_pos": 26, "type": "TASK", "confidence": 0.9789639711380005}, {"text": "accuracy", "start_pos": 27, "end_pos": 35, "type": "METRIC", "confidence": 0.9511945843696594}]}, {"text": "In all experiments, pruning confidence levels were set.", "labels": [], "entities": []}, {"text": "to 55%. and show the parsing accuracy when the number of training examples was increased.", "labels": [], "entities": [{"text": "parsing", "start_pos": 21, "end_pos": 28, "type": "TASK", "confidence": 0.9622340202331543}, {"text": "accuracy", "start_pos": 29, "end_pos": 37, "type": "METRIC", "confidence": 0.9869571924209595}]}, {"text": "Because the number of iterations in each data set changed between 5 and 8, we will show the accuracy by combining the first 5 decision trees.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 92, "end_pos": 100, "type": "METRIC", "confidence": 0.9996032118797302}]}, {"text": "In, the dotted line plots the learning of the singletree case (identical to) for reader's convenience.", "labels": [], "entities": []}, {"text": "The characteristics of the boosting version can be summarized as follows compared to the singletree version.", "labels": [], "entities": []}, {"text": "\u2022 The learning curve rises more rapidly with a small number of examples.", "labels": [], "entities": []}, {"text": "It is surprising that the boosting version with 10000 sentences performs better than the singletree version with 50000 sentences.", "labels": [], "entities": []}, {"text": "\u2022 The boosting version significantly outperforms the singletree counterpart for any number of sentences although they use the same features for learning.", "labels": [], "entities": []}, {"text": "Next, we discuss how the number of iterations influences the parsing accuracy.", "labels": [], "entities": [{"text": "parsing", "start_pos": 61, "end_pos": 68, "type": "TASK", "confidence": 0.9778240919113159}, {"text": "accuracy", "start_pos": 69, "end_pos": 77, "type": "METRIC", "confidence": 0.9532878398895264}]}, {"text": "shows the parsing accuracy for various iteration numbers when 50000 sentences were used as training data.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 18, "end_pos": 26, "type": "METRIC", "confidence": 0.9722124934196472}]}, {"text": "The resuits have two characteristics.", "labels": [], "entities": []}, {"text": "\u2022 Parsing accuracy rose up rapidly at the second iteration.", "labels": [], "entities": [{"text": "Parsing", "start_pos": 2, "end_pos": 9, "type": "TASK", "confidence": 0.6132292747497559}, {"text": "accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9688071012496948}]}, {"text": "* No over-fitting to data was seen although the performance of each generated tree fell around 30% at the final stage of iteration.", "labels": [], "entities": []}, {"text": "o T. i,,i,,gSe,l*e,,co.", "labels": [], "entities": []}, {"text": "I 3OO0 6OOO I'0000 2OOOO 3OO0O 5O0OO I Parsing Accuracy 83.10% 84.03% 84.44% 84.74% 84.91% 85.03%", "labels": [], "entities": [{"text": "Parsing Accuracy 83.10", "start_pos": 39, "end_pos": 61, "type": "METRIC", "confidence": 0.7965197364489237}]}], "tableCaptions": [{"text": " Table 1: Modification Matrix for Sample Sentence", "labels": [], "entities": [{"text": "Sample Sentence", "start_pos": 34, "end_pos": 49, "type": "TASK", "confidence": 0.8622642457485199}]}, {"text": " Table 3: Linguistic Feature Types Used for Learning", "labels": [], "entities": []}, {"text": " Table 4: Values for Each Feature Type", "labels": [], "entities": []}, {"text": " Table 5: Number of Training Sentences v.s. Parsing Accuracy", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 52, "end_pos": 60, "type": "METRIC", "confidence": 0.7637441754341125}]}, {"text": " Table 6: Pruning Confidence Level v.s.Parsing Accuracy", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 47, "end_pos": 55, "type": "METRIC", "confidence": 0.7421398758888245}]}, {"text": " Table 7: Decrease of Parsing Accuracy When Each Attribute Removed", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 30, "end_pos": 38, "type": "METRIC", "confidence": 0.9517337679862976}]}, {"text": " Table 8: Head Word Information v.s. Parsing Accuracy", "labels": [], "entities": []}, {"text": " Table 9: Number of Training Sentences v.s. Parsing Accuracy", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 52, "end_pos": 60, "type": "METRIC", "confidence": 0.7481673955917358}]}, {"text": " Table 10: Number of Iteration v.s. Parsing Accuracy", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 44, "end_pos": 52, "type": "METRIC", "confidence": 0.8808130621910095}]}]}