{"title": [{"text": "Large Scale Collocation Data and Their Application to Japanese Word Processor Technology", "labels": [], "entities": [{"text": "Large Scale Collocation", "start_pos": 0, "end_pos": 23, "type": "TASK", "confidence": 0.6021214226881663}]}], "abstractContent": [{"text": "Word processors or computers used in Japan employ Japanese input method through keyboard stroke combined with Kana (phonetic) character to Kanji (ideographic, Chinese) character conversion technology.", "labels": [], "entities": [{"text": "Kanji (ideographic, Chinese) character conversion", "start_pos": 139, "end_pos": 188, "type": "TASK", "confidence": 0.6297096349298954}]}, {"text": "The key factor of Kana-to-Kanji conversion technology is how to raise the accuracy of the conversion through the homophone processing, since we have so many homophonic Kanjis.", "labels": [], "entities": [{"text": "Kana-to-Kanji conversion", "start_pos": 18, "end_pos": 42, "type": "TASK", "confidence": 0.9137517213821411}, {"text": "accuracy", "start_pos": 74, "end_pos": 82, "type": "METRIC", "confidence": 0.9994496703147888}]}, {"text": "In this paper, we report the results of our Kana-to-Kanji conversion experiments which embody the homo-phone processing based on large scale colloca-tion data.", "labels": [], "entities": [{"text": "Kana-to-Kanji conversion", "start_pos": 44, "end_pos": 68, "type": "TASK", "confidence": 0.8410837054252625}]}, {"text": "It is shown that approximately 135,000 collocations yield 9.1% raise of the conversion accuracy compared with the prototype system which has no collocation data.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 87, "end_pos": 95, "type": "METRIC", "confidence": 0.9710689187049866}]}], "introductionContent": [{"text": "Word processors or computers used in Japan ordinarily employ Japanese input method through keyboard stroke combined ~ with Kana (phonetic) to Kanji (ideographic, Chinese) character conversion technology.", "labels": [], "entities": [{"text": "Kanji (ideographic, Chinese) character conversion", "start_pos": 142, "end_pos": 191, "type": "TASK", "confidence": 0.6502571366727352}]}, {"text": "The Kana-to-Kanji conversion is performed by the morphological analysis on the input Kana siring with no space between words.", "labels": [], "entities": [{"text": "Kana-to-Kanji conversion", "start_pos": 4, "end_pos": 28, "type": "TASK", "confidence": 0.8374044895172119}, {"text": "Kana siring", "start_pos": 85, "end_pos": 96, "type": "TASK", "confidence": 0.6556020379066467}]}, {"text": "Word-or phrase-segmentation is carried out by the analysis to identify the substring of the input which has to be converted from Kana to Kanji.", "labels": [], "entities": []}, {"text": "Kana-Kanji mixed string, which is the ordinary form of Japanese written text, is obtained as the final result.", "labels": [], "entities": []}, {"text": "The major issue of this technology lies in raising the accuracy of the segmentation and the homophone processing to select the correct Kanji among many homophonic candidates.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 55, "end_pos": 63, "type": "METRIC", "confidence": 0.9995591044425964}, {"text": "segmentation", "start_pos": 71, "end_pos": 83, "type": "TASK", "confidence": 0.9549152851104736}]}, {"text": "The conventional methodology for processing homophones have used the function that gives the priority to the word which was used lastly or to the high frequency word.", "labels": [], "entities": []}, {"text": "In fact, however, this method sometimes tends to cause inadequate conversion due to the lack of consideration of the semantic consistency of the word concurrence.", "labels": [], "entities": []}, {"text": "While it is difficult to employ the syntactic or semantic processing in earnest for the word processor from the cost vs. performance viewpoints, for example, the following trials to improve the conversion accuracy have been reported: Employing the case-frame to check the semantic consistency of combination of words.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 205, "end_pos": 213, "type": "METRIC", "confidence": 0.9675323367118835}]}, {"text": "Employing the neural network to describe the consistency of the concurrence of words, Making a concurrence dictionary for the specific topic or field, and giving the priority to the word which is in the dictionary when the topic is identified.", "labels": [], "entities": []}, {"text": "In any of these studies, however, many problems are left unsolved in realizing its practical system.", "labels": [], "entities": []}, {"text": "Besides these semantic or quasi-semantic gadgets, we think it much more practical and effective to use surface level resources, namely, to use extensively the collocation.", "labels": [], "entities": []}, {"text": "But how many collocations contribute to the accuracy of Kana-to-Kanji conversion is not known yet.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 44, "end_pos": 52, "type": "METRIC", "confidence": 0.9990069270133972}, {"text": "Kana-to-Kanji conversion", "start_pos": 56, "end_pos": 80, "type": "TASK", "confidence": 0.8297224342823029}]}, {"text": "In this paper, we present some results of our experiments of Kana-to-Kanji conversion, focusing on the usage of large scale collocation data.", "labels": [], "entities": [{"text": "Kana-to-Kanji conversion", "start_pos": 61, "end_pos": 85, "type": "TASK", "confidence": 0.8533765375614166}]}, {"text": "In chapter 2, descriptions of the collocations used in our system and their classification are given.", "labels": [], "entities": []}, {"text": "In chapter 3, the technological framework of our Kana-to-Kanji conversion systems is outlined.", "labels": [], "entities": [{"text": "Kana-to-Kanji conversion", "start_pos": 49, "end_pos": 73, "type": "TASK", "confidence": 0.8306227922439575}]}, {"text": "In chapter 4, the method and the results of the experiments are given along with some discussions.", "labels": [], "entities": []}, {"text": "In chapter 5, coneluding remarks are given.", "labels": [], "entities": [{"text": "coneluding", "start_pos": 14, "end_pos": 24, "type": "TASK", "confidence": 0.9552487730979919}]}], "datasetContent": [{"text": "Prior to the experiments of Kana-to-Kanji conversion, we prepared a large volume of text data by hand which is formally a set of triples whose first component a is a Kana string (a sentence) with no space, The second component b is the correct segmentation result of a, indicating each boundary between bunsetsus with \"/\" or \".\".", "labels": [], "entities": [{"text": "Kana-to-Kanji conversion", "start_pos": 28, "end_pos": 52, "type": "TASK", "confidence": 0.8819459676742554}]}, {"text": "niwani/baraga/saite, iru c: I~I~.I#~#J~II~I,~T..I,x,'~ } The introduction of the optional boundary assures the flexible evaluation.", "labels": [], "entities": []}, {"text": "For example, each ofl~lA \"C/t,~ saite/iru (be in bloom) and I~I,~'CIA~ saiteiru is accepted as a correct result.", "labels": [], "entities": []}, {"text": "The data fde is divided into two sub-files, fl and 12, depending on the number of bunsetsus in the Kana string a. fl has 10,733 triples, whose a has less than five bunsetsus and t2 has 12,192 triples, whose a has more than four bunsetsus.", "labels": [], "entities": [{"text": "Kana string a. fl", "start_pos": 99, "end_pos": 116, "type": "DATASET", "confidence": 0.9261742681264877}]}, {"text": "Besides, a single word has sometimes more than one Kanji notations, e.g. \"~g hama (beach) and ;~ hama (beach) are both acceptable, and soon.", "labels": [], "entities": []}, {"text": "c'-\u00a2 in the case of TS means that e' coincides with \u00a2 completely or excepting the part which is heteromorphic in the above sense.", "labels": [], "entities": []}, {"text": "For this, each of our conversion system has a dictionary which contains approximately 35,000 fluctuated notations of conceptual words.", "labels": [], "entities": []}, {"text": "Results of the experiments are given in for input file fl and 12, respectively.", "labels": [], "entities": []}, {"text": "Comparing the statistics of system A with D, we can conclude that the introduction of approximately 135,000 collocation data causes 8.1% and 10.5 % raise of CS and TS rate, respectively, in case of relatively short input strings (fl).", "labels": [], "entities": [{"text": "TS rate", "start_pos": 164, "end_pos": 171, "type": "METRIC", "confidence": 0.9519568085670471}]}, {"text": "The raise of SS rate for t\"1 is 2.7%.", "labels": [], "entities": [{"text": "SS rate", "start_pos": 13, "end_pos": 20, "type": "METRIC", "confidence": 0.9807644784450531}]}, {"text": "In case of the longer input strings (t2) whose average number of bunsetsus is approximately 12.6, the raise ofCS, TS and SS rate is 2.4 %, 5.2 % and 5.7 %, respectively.", "labels": [], "entities": [{"text": "raise", "start_pos": 102, "end_pos": 107, "type": "METRIC", "confidence": 0.9815086722373962}, {"text": "TS", "start_pos": 114, "end_pos": 116, "type": "METRIC", "confidence": 0.9922160506248474}, {"text": "SS rate", "start_pos": 121, "end_pos": 128, "type": "METRIC", "confidence": 0.986394613981247}]}, {"text": "As a consequence, the raise ofCS, TS and SS rate is 6.2 %, 9.1% and 3.8 % on the average, respectively.", "labels": [], "entities": [{"text": "TS", "start_pos": 34, "end_pos": 36, "type": "METRIC", "confidence": 0.9872887134552002}, {"text": "SS rate", "start_pos": 41, "end_pos": 48, "type": "METRIC", "confidence": 0.9709428548812866}]}], "tableCaptions": []}