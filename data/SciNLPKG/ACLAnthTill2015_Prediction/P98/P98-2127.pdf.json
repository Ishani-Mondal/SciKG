{"title": [{"text": "Automatic Retrieval and Clustering of Similar Words", "labels": [], "entities": [{"text": "Automatic Retrieval and Clustering of Similar Words", "start_pos": 0, "end_pos": 51, "type": "TASK", "confidence": 0.6785113939217159}]}], "abstractContent": [{"text": "Bootstrapping semantics from text is one of the greatest challenges in natural language learning.", "labels": [], "entities": []}, {"text": "We first define a word similarity measure based on the distributional pattern of words.", "labels": [], "entities": []}, {"text": "The similarity measure allows us to construct a thesaurus using a parsed corpus.", "labels": [], "entities": []}, {"text": "We then present anew evaluation methodology for the automatically constructed thesaurus.", "labels": [], "entities": []}, {"text": "The evaluation results show that the the-saurns is significantly closer to WordNet than Roget Thesaurus is.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 75, "end_pos": 82, "type": "DATASET", "confidence": 0.9683305621147156}]}], "introductionContent": [{"text": "The meaning of an unknown word can often be inferred from its context.", "labels": [], "entities": []}, {"text": "Consider the following (slightly modified) example in): (1) A bottle of tezgiiino is on the table.", "labels": [], "entities": []}, {"text": "We make tezgiiino out of corn.", "labels": [], "entities": []}, {"text": "The contexts in which the word tezgiiino is used suggest that tezgiiino maybe a kind of alcoholic beverage made from corn mash.", "labels": [], "entities": []}, {"text": "Bootstrapping semantics from text is one of the greatest challenges in natural language learning.", "labels": [], "entities": []}, {"text": "It has been argued that similarity plays an important role in word acquisition.", "labels": [], "entities": [{"text": "word acquisition", "start_pos": 62, "end_pos": 78, "type": "TASK", "confidence": 0.80820232629776}]}, {"text": "Identifying similar words is an initial step in learning the definition of a word.", "labels": [], "entities": [{"text": "Identifying similar words", "start_pos": 0, "end_pos": 25, "type": "TASK", "confidence": 0.8982834418614706}]}, {"text": "This paper presents a method for making this first step.", "labels": [], "entities": []}, {"text": "For example, given a corpus that includes the sentences in (1), our goal is to be able to infer that tezgiiino is similar to \"beer\", \"wine\", \"vodka\", etc.", "labels": [], "entities": []}, {"text": "In addition to the long-term goal of bootstrapping semantics from text, automatic identification of similar words has many immediate applications.", "labels": [], "entities": [{"text": "automatic identification of similar words", "start_pos": 72, "end_pos": 113, "type": "TASK", "confidence": 0.7963025331497192}]}, {"text": "The most obvious one is thesaurus construction.", "labels": [], "entities": [{"text": "thesaurus construction", "start_pos": 24, "end_pos": 46, "type": "TASK", "confidence": 0.7320380955934525}]}, {"text": "An automatically created thesaurus offers many advantages over manually constructed thesauri.", "labels": [], "entities": []}, {"text": "Firstly, the terms can be corpus-or genre-specific.", "labels": [], "entities": []}, {"text": "Manually constructed general-purpose dictionaries and thesauri include many usages that are very infrequent in a particular corpus or genre of documents.", "labels": [], "entities": []}, {"text": "For example, one of the 8 senses of \"company\" in WordNet 1.5 is a \"visitor/visitant\", which is a hyponym of \"person\".", "labels": [], "entities": []}, {"text": "This usage of the word is practically never used in newspaper articles.", "labels": [], "entities": []}, {"text": "However, its existance may prevent a co-reference recognizer to rule out the possiblity for personal pronouns to refer to \"company\".", "labels": [], "entities": []}, {"text": "Secondly, certain word usages maybe particular to a period of time, which are unlikely to be captured by manually compiled lexicons.", "labels": [], "entities": []}, {"text": "For example, among 274 occurrences of the word \"westerner\" in a 45 million word San Jose Mercury corpus, 55% of them refer to hostages.", "labels": [], "entities": [{"text": "San Jose Mercury corpus", "start_pos": 80, "end_pos": 103, "type": "DATASET", "confidence": 0.7285551428794861}]}, {"text": "If one needs to search hostage-related articles, \"westemer\" may well be a good search term.", "labels": [], "entities": []}, {"text": "Another application of automatically extracted similar words is to help solve the problem of data sparseness in statistical natural language processing (.", "labels": [], "entities": [{"text": "statistical natural language processing", "start_pos": 112, "end_pos": 151, "type": "TASK", "confidence": 0.6137493476271629}]}, {"text": "When the frequency of a word does not warrant reliable maximum likelihood estimation, its probability can be computed as a weighted sum of the probabilities of words that are similar to it.", "labels": [], "entities": []}, {"text": "It was shown in () that a similarity-based smoothing method achieved much better results than backoff smoothing methods in word sense disambiguation.", "labels": [], "entities": [{"text": "word sense disambiguation", "start_pos": 123, "end_pos": 148, "type": "TASK", "confidence": 0.680070698261261}]}, {"text": "The remainder of the paper is organized as follows.", "labels": [], "entities": []}, {"text": "The next section is concerned with similarities between words based on their distributional patterns.", "labels": [], "entities": []}, {"text": "The similarity measure can then be used to create a thesaurus.", "labels": [], "entities": []}, {"text": "In Section 3, we evaluate the constructed thesauri by computing the similarity between their entries and entries in manually created thesauri.", "labels": [], "entities": []}, {"text": "Section 4 briefly discuss future work in clustering similar words.", "labels": [], "entities": []}, {"text": "Finally, Section 5 reviews related work and summarize our contributions.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section, we present an evaluation of automatically constructed thesauri with two manually compiled thesauri, namely, WordNetl.5 ( ) and Roget Thesaurus.", "labels": [], "entities": [{"text": "WordNetl.5", "start_pos": 125, "end_pos": 135, "type": "DATASET", "confidence": 0.9785236120223999}]}, {"text": "We first define two word similarity measures that are based on the structures of WordNet and Roget.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 81, "end_pos": 88, "type": "DATASET", "confidence": 0.9650958180427551}]}, {"text": "The similarity measure simwN is based on the proposal in).", "labels": [], "entities": []}, {"text": "The similarity measure simRoget treats all the words in Roget as features.", "labels": [], "entities": []}, {"text": "A word w possesses the feature f if f and w belong to a same Roget category.", "labels": [], "entities": []}, {"text": "The similarity between two words is then defined as the cosine coefficient of the two feature vectors.", "labels": [], "entities": []}, {"text": "With simwN and simRoget, we transform WordNet and Roget into the same format as the automatically constructed thesauri in the previous section.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 38, "end_pos": 45, "type": "DATASET", "confidence": 0.9541557431221008}]}, {"text": "We now discuss how to measure the similarity between two thesaurus entries.", "labels": [], "entities": []}, {"text": "Suppose two thesaurus entries for the same word are as follows: 'tO : '//31~ 81~'//12~ 82~...", "labels": [], "entities": []}, {"text": "~I)N~S N Their similarity is defined as:", "labels": [], "entities": [{"text": "similarity", "start_pos": 15, "end_pos": 25, "type": "METRIC", "confidence": 0.9247108697891235}]}], "tableCaptions": [{"text": " Table 2: Distribution of Differences", "labels": [], "entities": [{"text": "Distribution of Differences", "start_pos": 10, "end_pos": 37, "type": "TASK", "confidence": 0.9146657983462015}]}]}