{"title": [{"text": "How Verb Subcategorization Frequencies Are Affected By Corpus Choice", "labels": [], "entities": []}], "abstractContent": [], "introductionContent": [{"text": "The probabilistic relation between verbs and their arguments plays an important role in modern statistical parsers and supertaggers, and in psychological theories of language processing ().", "labels": [], "entities": []}, {"text": "These probabilities are computed in very different ways by the two sets of researchers.", "labels": [], "entities": []}, {"text": "Psychological studies use methods such as sentence completion and sentence production for collecting verb argument structure probabilities.", "labels": [], "entities": [{"text": "sentence completion", "start_pos": 42, "end_pos": 61, "type": "TASK", "confidence": 0.7283191382884979}, {"text": "sentence production", "start_pos": 66, "end_pos": 85, "type": "TASK", "confidence": 0.7126282900571823}, {"text": "collecting verb argument structure probabilities", "start_pos": 90, "end_pos": 138, "type": "TASK", "confidence": 0.8095178008079529}]}, {"text": "In sentence completion, subjects are asked to complete a sentence fragment.", "labels": [], "entities": [{"text": "sentence completion", "start_pos": 3, "end_pos": 22, "type": "TASK", "confidence": 0.7563605010509491}]}, {"text": "used a proper name followed by a verb, such as \"Debbie remembered .\" In sentence subjects are asked to write any sentence containing a given verb.", "labels": [], "entities": []}, {"text": "An example of this type of study is.", "labels": [], "entities": []}, {"text": "An alternative to these psychological methods is to use corpus data.", "labels": [], "entities": []}, {"text": "This can be done automatically with unparsed corpora, from parsed corpora such as Treebank or manually as was done for COMLEX.", "labels": [], "entities": [{"text": "Treebank", "start_pos": 82, "end_pos": 90, "type": "DATASET", "confidence": 0.9726585149765015}, {"text": "COMLEX", "start_pos": 119, "end_pos": 125, "type": "DATASET", "confidence": 0.9221543073654175}]}, {"text": "The advantage of any of these corpus methods is the much greater amount of data that can be used, and the much more natural contexts.", "labels": [], "entities": []}, {"text": "This seems to make it preferable to data generated in psychological studies.", "labels": [], "entities": []}, {"text": "Recent studies) have found differences between corpus frequencies and experimental measures.", "labels": [], "entities": []}, {"text": "This suggests that corpus-based frequencies and experiment-based frequencies may not be interchangeable.", "labels": [], "entities": []}, {"text": "To clarify the nature of the differences between various corpora and to find the causes of these differences, we analyzed psychological sentence production data, written discourse (, and conversational data.", "labels": [], "entities": []}, {"text": "We found that the subcategorization frequencies in each of these sources are different.", "labels": [], "entities": []}, {"text": "We performed three experiments to (1) find the causes of general differences between corpora, (2) measure the size of these differences, and (3) find verb specific differences.", "labels": [], "entities": []}, {"text": "The rest of this paper describes our methodology and the two sources of subcategorization probability differences: discourse influence and semantic influence.", "labels": [], "entities": []}], "datasetContent": [{"text": "Argument preference was also affected by verb semantics.", "labels": [], "entities": [{"text": "Argument preference", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.6987682729959488}]}, {"text": "To examine this effect, we took two sample ambiguous verbs, \"charge\" and \"pass\".", "labels": [], "entities": [{"text": "pass", "start_pos": 74, "end_pos": 78, "type": "METRIC", "confidence": 0.9767175316810608}]}, {"text": "We hand coded them for semantic senses in each of the corpora we used as follows: Examples of 'charge' taken from BC.", "labels": [], "entities": []}, {"text": "accuse: \"His petition charged mental cruelty.\" attack: \"When he charged Mickey was ready.\" money: \"...", "labels": [], "entities": []}, {"text": "20 percent ... was all he charged the traders.\"", "labels": [], "entities": []}, {"text": "Examples of 'pass' taken from BC.", "labels": [], "entities": [{"text": "pass'", "start_pos": 13, "end_pos": 18, "type": "METRIC", "confidence": 0.9857353568077087}, {"text": "BC", "start_pos": 30, "end_pos": 32, "type": "DATASET", "confidence": 0.8555532693862915}]}, {"text": "movement: \"Blue Throat's men spotted him ...", "labels": [], "entities": [{"text": "Blue Throat", "start_pos": 11, "end_pos": 22, "type": "DATASET", "confidence": 0.9131774604320526}]}, {"text": "as he passed.\" law\" 'q'he President noted that Congress last year passed a law providing grants ...\" transfer: \"He asked, when she passed him a glass.\" test: \"Those who T stayed had * to pass tests.\"", "labels": [], "entities": []}, {"text": "We then asked two questions: 1.", "labels": [], "entities": []}, {"text": "Do different verb senses have different argument structure preferences?", "labels": [], "entities": []}, {"text": "2. Do different corpora have different verb sense preferences, and therefore potentially different argument structure preferences?", "labels": [], "entities": []}, {"text": "For both verbs examined (pass and charge) there was a significant effect of verb sense on argument structure probabilities (by X 2 p <.001 for 'charge' and p <.001 for 'pass' This analysis shows that it is possible for shifts in the relative frequency of each of a verbs senses to influence the observed subcat frequencies.", "labels": [], "entities": []}, {"text": "We are currently extending our study to see if verb senses have constant subcategorization frequencies across corpora.", "labels": [], "entities": []}, {"text": "This would be useful for word sense disambiguation and for parsing.", "labels": [], "entities": [{"text": "word sense disambiguation", "start_pos": 25, "end_pos": 50, "type": "TASK", "confidence": 0.7359932859738668}, {"text": "parsing", "start_pos": 59, "end_pos": 66, "type": "TASK", "confidence": 0.9716148972511292}]}, {"text": "If the verb sense is known, then a parser could use this information to help look for likely arguments.", "labels": [], "entities": []}, {"text": "If the subcatagorization is known, then a disambiguator could use this information to find the sense of the verb.", "labels": [], "entities": []}, {"text": "These could be used to bootstrap each other relying on the heuristic that only one sense is used within any discourse).", "labels": [], "entities": []}, {"text": "We had previously hoped to evaluate the accuracy of our treebank induduced subcategorization probabilities by comparing them with the COMLEX hand-coded probabilities (Macleod and Grishman 1994), but we used a different set of subcategorization frames than COMLEX.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 40, "end_pos": 48, "type": "METRIC", "confidence": 0.9992526173591614}]}, {"text": "Instead, we hand checked a random sample of our data for errors.", "labels": [], "entities": [{"text": "errors", "start_pos": 57, "end_pos": 63, "type": "METRIC", "confidence": 0.9630309343338013}]}, {"text": "to find arguments that were located to the left of the verb.", "labels": [], "entities": []}, {"text": "This is because arbitrary amounts of structure can intervene, expecially in the case of traces.", "labels": [], "entities": []}, {"text": "The error rate in our data is between 3% and 7% for all verbs excluding 'say' type verbs such as 'answer', 'ask', 'call', 'read', 'say', and 'write'.", "labels": [], "entities": [{"text": "error rate", "start_pos": 4, "end_pos": 14, "type": "METRIC", "confidence": 0.9869978725910187}]}, {"text": "The error rate is given as a range due to the subjectivity of some types of errors.", "labels": [], "entities": [{"text": "error rate", "start_pos": 4, "end_pos": 14, "type": "METRIC", "confidence": 0.9788682758808136}]}, {"text": "The errors can be divided into two classes; errors which are due to mis-parsed sentences in Treebank ~, and errors which are due to the inadequacy of our search strings in indentifying certain syntactic 9atterns.", "labels": [], "entities": []}, {"text": "Treebank-based errors PP attachment 1% verb+particle vs verb+PP 2% NP/adverbial distinction 2% misc.", "labels": [], "entities": []}, {"text": "miss-parsed sentences 1% Errors based on our search strinl~s missed traces and displaced arguments 1% \"say\" verbs missing quotes 6% Error rate by category In trying to estimate the maximum amount of error in our data, we found cases where it was possible to disagree with the parses/tags given in Treebank.", "labels": [], "entities": [{"text": "Treebank", "start_pos": 297, "end_pos": 305, "type": "DATASET", "confidence": 0.9377655386924744}]}, {"text": "Treebank examples given below include prepositional attachinent (1), the verbparticle/preposition distinction (2), and the NP/adverbial distinction (3).", "labels": [], "entities": []}, {"text": "(Be) Missed traces and displaced argument errors were a result of the difficulty in writing search strings 1 All of our search patterns are based only on the information available in the Treebank 1 coding system, since the Brown Corpus is only available in this scheme.", "labels": [], "entities": [{"text": "Brown Corpus", "start_pos": 223, "end_pos": 235, "type": "DATASET", "confidence": 0.974629282951355}]}, {"text": "The error rate for corpora available in Treebank 2 form would have been lower had we used all available information.", "labels": [], "entities": [{"text": "error rate", "start_pos": 4, "end_pos": 14, "type": "METRIC", "confidence": 0.98748978972435}, {"text": "Treebank 2 form", "start_pos": 40, "end_pos": 55, "type": "DATASET", "confidence": 0.9293025533358256}]}, {"text": "Six percent of the data (overall) was improperly classified due to the failure of our search patterns to identify all of the quote-type arguments which occur in 'say' type verbs.", "labels": [], "entities": []}, {"text": "The identification of these elements is particularly problematic due to the asyntactic nature of these arguments, ranging from a sound (He said 'Argh!')", "labels": [], "entities": [{"text": "Argh", "start_pos": 145, "end_pos": 149, "type": "METRIC", "confidence": 0.9570192694664001}]}, {"text": "The presence or absense of quotation marks was not a completely reliable indicator of these arguments.", "labels": [], "entities": []}, {"text": "This type of error affects only a small subset of the total number of verbs.", "labels": [], "entities": []}, {"text": "27% of the examples of these verbs were mis-classified, always by failing to find a quote-type argument of the verb.", "labels": [], "entities": []}, {"text": "Using separate search strings for these verbs would greatly improve the accuracy of these searches.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 72, "end_pos": 80, "type": "METRIC", "confidence": 0.9991487264633179}]}, {"text": "Our eventual goal is to develop a set of regular expressions that work on fiat tagged corpora instead of TreeBank parsed structures to allow us to gather information from larger corpora than have been done by the TreeBank project (see).", "labels": [], "entities": []}], "tableCaptions": []}