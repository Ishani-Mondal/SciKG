{"title": [{"text": "Tagging Inflective Languages: Prediction of Morphological Categories fora Rich, Structured Tagset", "labels": [], "entities": [{"text": "Tagging Inflective Languages", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.839434007803599}]}], "abstractContent": [{"text": "The major obstacle in morphological (sometimes called morpho-syntactic, or extended POS) tagging of highly inflective languages, such as Czech or Russian, is -given the resources possibly available -the tagset size.", "labels": [], "entities": [{"text": "POS) tagging of highly inflective languages", "start_pos": 84, "end_pos": 127, "type": "TASK", "confidence": 0.7228899896144867}]}, {"text": "Typically, it is in the order of thousands.", "labels": [], "entities": []}, {"text": "Our method uses an exponential probabilistic model based on automatically selected features.", "labels": [], "entities": []}, {"text": "The parameters of the model are computed using simple estimates (which makes training much faster than when one uses Maximum Entropy) to directly minimize the error rate on training data.", "labels": [], "entities": []}, {"text": "The results obtained so far not only show good performance on disambiguation of most of the individual morphological categories, but they also show a significant improvement on the overall prediction of the resulting combined tag over a HMM-based tag n-gram model, using even substantially less training data.", "labels": [], "entities": []}], "introductionContent": [], "datasetContent": [], "tableCaptions": [{"text": " Table 2: Initial Error Rate", "labels": [], "entities": [{"text": "Initial Error Rate", "start_pos": 10, "end_pos": 28, "type": "METRIC", "confidence": 0.9085514744122823}]}, {"text": " Table 3: Resulting Error Rate", "labels": [], "entities": [{"text": "Resulting Error Rate", "start_pos": 10, "end_pos": 30, "type": "METRIC", "confidence": 0.6948430438836416}]}, {"text": " Table 4: Comparing Various Methods", "labels": [], "entities": []}, {"text": " Table 5: Resulting Error Rate in % (newspaper, training size: 160,000, test size: 5000 tokens)", "labels": [], "entities": [{"text": "Resulting Error Rate", "start_pos": 10, "end_pos": 30, "type": "METRIC", "confidence": 0.8290692965189616}]}]}