{"title": [{"text": "Using Chunk Based Partial Parsing of Spontaneous Speech in Unrestricted Domains for Reducing Word Error Rate in Speech Recognition", "labels": [], "entities": [{"text": "Speech Recognition", "start_pos": 112, "end_pos": 130, "type": "TASK", "confidence": 0.6876978874206543}]}], "abstractContent": [{"text": "In this paper, we present a chunk based partial parsing system for spontaneous, conversational speech in unrestricted domains.", "labels": [], "entities": []}, {"text": "We show that the chunk parses produced by this parsing system can be usefully applied to the task of reranking Nbest lists from a speech recognizer, using a combination of chunk-based n-gram model scores and chunk coverage scores.", "labels": [], "entities": []}, {"text": "The input for the system is Nbest lists generated from speech recognizer lattices.", "labels": [], "entities": []}, {"text": "The hypotheses from the Nbest lists are tagged for part of speech, \"cleaned up\" by a preprocessing pipe, parsed by apart of speech based chunk parser, and rescored using a backpropagation neural net trained on the chunk based scores.", "labels": [], "entities": [{"text": "Nbest lists", "start_pos": 24, "end_pos": 35, "type": "DATASET", "confidence": 0.8664398491382599}]}, {"text": "Finally, the reranked Nbest lists are generated.", "labels": [], "entities": []}, {"text": "The results of a system evaluation are promising in that a chunk accuracy of 87.4% is achieved and the best performance on a randomly selected test set is a decrease in word error rate of 0.3 percent (abso-lute), measured on the new first hypotheses in the reranked Nbest lists.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 65, "end_pos": 73, "type": "METRIC", "confidence": 0.9427017569541931}, {"text": "word error rate", "start_pos": 169, "end_pos": 184, "type": "METRIC", "confidence": 0.8193981448809305}, {"text": "abso-lute", "start_pos": 201, "end_pos": 210, "type": "METRIC", "confidence": 0.9669994711875916}, {"text": "Nbest lists", "start_pos": 266, "end_pos": 277, "type": "DATASET", "confidence": 0.8039707541465759}]}], "introductionContent": [{"text": "In the area of parsing spontaneous speech, most work so far has primarily focused on dealing with texts within a narrow, well-defined domain.", "labels": [], "entities": [{"text": "parsing spontaneous speech", "start_pos": 15, "end_pos": 41, "type": "TASK", "confidence": 0.9153475562731425}]}, {"text": "Full scale parsers for spontaneous speech face severe difficulties due to the intrinsic nature of spoken language (e.g., false starts, hesitations, ungrammaticalities), in addition to the well-known complexities of large coverage parsing systems in general).", "labels": [], "entities": []}, {"text": "An even more serious problem is the imperfect word accuracy of speech recognizers, particularly when faced with spontaneous speech over a large vocabulary and over a low bandwidth channel.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 51, "end_pos": 59, "type": "METRIC", "confidence": 0.9681609272956848}, {"text": "speech recognizers", "start_pos": 63, "end_pos": 81, "type": "TASK", "confidence": 0.7198779881000519}]}, {"text": "This is particularly the case for the SWITCHBOARD database () which we mainly used for development, testing, and evaluation of our system.", "labels": [], "entities": [{"text": "SWITCHBOARD database", "start_pos": 38, "end_pos": 58, "type": "DATASET", "confidence": 0.7238097786903381}]}, {"text": "Current state-of-the-art recognizers exhibit word error rates (WER 1) for this corpus of approxIThe word error rate (WEFt in %) is defined as follows: imately 30%-40% (.", "labels": [], "entities": [{"text": "word error rates (WER 1)", "start_pos": 45, "end_pos": 69, "type": "METRIC", "confidence": 0.8127294225352151}, {"text": "approxIThe word error rate (WEFt", "start_pos": 89, "end_pos": 121, "type": "METRIC", "confidence": 0.8526967664559683}]}, {"text": "This means that in fact about every third word in an input utterance will be misrecognized.", "labels": [], "entities": []}, {"text": "Thus, any parser which is too restrictive with respect to the input it accepts will likely fail to find a parse for most of these utterances.", "labels": [], "entities": []}, {"text": "When the domain is restricted, sufficient coverage can be achieved using semantically guided approaches that allow skipping of unparsable words or segments.", "labels": [], "entities": []}, {"text": "Since we cannot build on semantic knowledge for constructing parsers in the way it is done for limited domains when attempting to parse spontaneous speech in unrestricted domains, we argue that more shallow approaches have to be employed to reach a sufficient reliability with a reasonable amount of effort.", "labels": [], "entities": [{"text": "parse spontaneous speech", "start_pos": 130, "end_pos": 154, "type": "TASK", "confidence": 0.8856491446495056}]}, {"text": "In this paper, we present a chunk based partial parser, following ideas from, which is used to to generate shallow syntactic structures from speech recognizer output.", "labels": [], "entities": []}, {"text": "These representations then serve as the basis for scores used in the task of reranking Nbest lists.", "labels": [], "entities": []}, {"text": "The organization of this paper is as follows: In section 2 we introduce the concept of chunk.parsing and how we interpret and use it in our system.", "labels": [], "entities": []}, {"text": "Section 3 deals with the issue of reranking Nbest lists and the question of why we consider it appropriate to use chunk representations for this task.", "labels": [], "entities": []}, {"text": "In section 4, the system architecture is described, and then the results from an evaluation of the system are presented and discussed (sections 5 and 6).", "labels": [], "entities": []}, {"text": "Finally, we give the results of a small study with human subjects on an analogous task (section 7), before pointing out directions for future research (section 8) and summarizing our work (section 9).", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Characteristics of train and test sets", "labels": [], "entities": []}, {"text": " Table 1. While the true  WER corresponds to the WER of the first hypoth- esis (--top ranked), the optimal WER is computed  under the assumption that an oracle would always  pick the hypothesis with the lowest WER in every  Nbest list. The difference between the average true  WER and the optimal WER is 13.1%; this gives  the maximum margin of improvement that rerank- ing can possibly achieve on this data set. Another  interesting figure is the expected WER gain, when  a random process would rerank the Nbest lists and  just pick any hypothesis to be the (new) top one.  For the test set, this expected WER gain is -4.9%  (i.e., the WER would drop by 4.9%).", "labels": [], "entities": []}, {"text": " Table 2: Performance of the chunk parser on  different test sets", "labels": [], "entities": []}, {"text": " Table 4: Recognizer hypotheses from an  example utterance (hypothesis nr. 190  exactly corresponds to the reference)", "labels": [], "entities": []}, {"text": " Table 5: Scores, WER, and", "labels": [], "entities": [{"text": "Scores", "start_pos": 10, "end_pos": 16, "type": "METRIC", "confidence": 0.9958418011665344}, {"text": "WER", "start_pos": 18, "end_pos": 21, "type": "METRIC", "confidence": 0.998540997505188}]}, {"text": " Table 6: Human Performance (WER gain in %)", "labels": [], "entities": [{"text": "WER gain", "start_pos": 29, "end_pos": 37, "type": "METRIC", "confidence": 0.9866930246353149}]}]}