{"title": [{"text": "Trigger-Pair Predictors in Parsing and Tagging", "labels": [], "entities": [{"text": "Tagging", "start_pos": 39, "end_pos": 46, "type": "TASK", "confidence": 0.8490476012229919}]}], "abstractContent": [{"text": "In this article, we apply to natural language parsing and tagging the device of trigger-pair predictors, previously employed exclusively within the field of language modelling for speech recognition.", "labels": [], "entities": [{"text": "natural language parsing", "start_pos": 29, "end_pos": 53, "type": "TASK", "confidence": 0.6318055589993795}, {"text": "speech recognition", "start_pos": 180, "end_pos": 198, "type": "TASK", "confidence": 0.7242270261049271}]}, {"text": "Given the task of predicting the correct rule to associate with a parse-tree node, or the correct tag to associate with a word of text, and assuming a particular class of parsing or tagging model, we quantify the information gain realized by taking account of rule or tag trigger-pair predictors, i.e. pairs consisting of a \"triggering\" rule or tag which has already occurred in the document being processed, together with a specific \"triggered\" rule or tag whose probability of occurrence within the current sentence we wish to estimate.", "labels": [], "entities": [{"text": "parsing or tagging", "start_pos": 171, "end_pos": 189, "type": "TASK", "confidence": 0.8429548144340515}]}, {"text": "This information gain is shown to be substantial.", "labels": [], "entities": []}, {"text": "Further , by utilizing trigger pairs taken from the same general sort of document as is being processed (e.g. same subject matter or same discourse type)-as opposed to pre-dictors derived from a comprehensive general set of English texts-we can significantly increase this information gain.", "labels": [], "entities": []}], "introductionContent": [{"text": "Ifa person or device wished to predict which words or grammatical constructions were about to occur in some document, intuitively one of the most helpful things to know would seem to be which words and constructions occurred within the last half-dozen or dozen sentences of the document.", "labels": [], "entities": []}, {"text": "Other things being equal, a text that has so far been larded with, say, mountaineering terms, is a good bet to continue featuring them.", "labels": [], "entities": []}, {"text": "An author with the habit of ending sentences with adverbial clauses of confirmation, e.g. \"as we all know\", will probably keep up that habit as the discourse progresses.", "labels": [], "entities": []}, {"text": "Within the field of language modelling for speech recognition, maintaining a cache of words that have occurred so far within a document, and using this information to alter probabilities of occurrence of particular choices for the word being predicted, has proved a winning strategy ().", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 43, "end_pos": 61, "type": "TASK", "confidence": 0.74266117811203}]}, {"text": "Models using trigger pairs of words, i.e. pairs consisting of a \"triggering\" word which has already occurred in the document being processed, plus a specific \"triggered\" word whose probability of occurrence as the next word of the document needs to be estimated, have yielded perplexity 1 reductions of 29-38% over the baseline trigram model, fora 5-million-word Wall Street Journal training corpus.", "labels": [], "entities": [{"text": "Wall Street Journal training corpus", "start_pos": 363, "end_pos": 398, "type": "DATASET", "confidence": 0.9427063822746277}]}, {"text": "This paper introduces the idea of using triggerpair techniques to assist in the prediction of rule and tag occurrences, within the context of naturallanguage parsing and tagging.", "labels": [], "entities": [{"text": "prediction of rule and tag occurrences", "start_pos": 80, "end_pos": 118, "type": "TASK", "confidence": 0.7802027463912964}, {"text": "naturallanguage parsing", "start_pos": 142, "end_pos": 165, "type": "TASK", "confidence": 0.674848347902298}]}, {"text": "Given the task of predicting the correct rule to associate with a parsetree node, or the correct tag to associate with a word of text, and assuming a particular class of parsing or tagging model, we quantify the information gain realized by taking account of rule or tag trigger-pair predictors, i.e. pairs consisting of a \"triggering\" rule or tag which has already occurred in the document being processed, plus a specific \"triggered\" rule or tag whose probability of occurrence within the current sentence we wish to estimate.", "labels": [], "entities": []}, {"text": "In what follows, Section 2 provides a basic overview of trigger-pair models.", "labels": [], "entities": []}, {"text": "Section 3 describes the experiments we have performed, which to a large extent parallel successful modelling experiments within the field of language modelling for speech recognition.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 164, "end_pos": 182, "type": "TASK", "confidence": 0.7390212118625641}]}, {"text": "In the first experiment, we investigate the use of trigger pairs to predict both rules and tags over our full corpus of around a million words.", "labels": [], "entities": []}, {"text": "The subsequent experiments investigate the ]See Section 2.", "labels": [], "entities": []}, {"text": "additional information gains accruing from triggerpair modelling when we know what sort of document is being parsed or tagged.", "labels": [], "entities": []}, {"text": "We present our experimental results in Section 4, and discuss them in Section 5.", "labels": [], "entities": []}, {"text": "In Section 6, we present some example trigger pairs; and we conclude, with a glance at projected future research, in Section 7.", "labels": [], "entities": []}], "datasetContent": [{"text": "In order to investigate the utility of using longrange trigger information in tagging and parsing 4i.e. words which trigger words other than themselves 5i.e. words which trigger themselves tasks, we adopt the simple mutual-information approach used in.", "labels": [], "entities": [{"text": "tagging and parsing 4i.e. words which trigger words other than themselves 5i.e. words which trigger themselves tasks", "start_pos": 78, "end_pos": 194, "type": "TASK", "confidence": 0.6480200448456932}]}, {"text": "We carryover into the domain of tags and rules an experiment from Rosenfeld's paper the details of which we outline below.", "labels": [], "entities": []}, {"text": "The idea is to measure the information contributed (in bits, or, equivalently in terms of perplexity reduction) by using the triggers.", "labels": [], "entities": []}, {"text": "Using this technique requires special care to ensure that information \"added\" by the triggers is indeed additional information.", "labels": [], "entities": []}, {"text": "For this reason, in all our experiments we use the unigram model as our base model and we allow only one trigger for each tag (or rule) token.", "labels": [], "entities": []}, {"text": "6 We derive these unigram probabilities from the training corpus and then calculate the total mutual information gained by using the trigger pairs, again with respect to the training corpus.", "labels": [], "entities": []}, {"text": "When using trigger pairs, one usually restricts the trigger to occur within a certain window defined by its distance to the triggered token.", "labels": [], "entities": []}, {"text": "In our experiments, the window starts at the sentence prior to that containing the token and extends back W (the window size) sentences.", "labels": [], "entities": []}, {"text": "The choice to use sentences as the unit of distance is motivated by our intention to incorporate triggers of this form into a probabilistie treebank-based parser and tagger, such as ().", "labels": [], "entities": []}, {"text": "All such parsers and taggers of which we are aware use only intrasentential information in predicting parses or tags, and we wish to remove this information, as far as possible, from our results 7 The window was not allowed to cross a document boundary.", "labels": [], "entities": [{"text": "predicting parses or tags", "start_pos": 91, "end_pos": 116, "type": "TASK", "confidence": 0.850714772939682}]}, {"text": "The perplexity of the task before taking the trigger-pair information into account for tags was 224.0 and for rules was 57.0.", "labels": [], "entities": []}, {"text": "The characteristics of the training corpus we employ are given in.", "labels": [], "entities": []}, {"text": "The corpus, a subset s of the ATR/Lancaster General-English Treebank (), consists of a sequence of sentences which have been tagged and parsed by human experts in terms of the ATR English Grammar; a broad-coverage grammar of English with a high level of analytic detail).", "labels": [], "entities": [{"text": "ATR/Lancaster General-English Treebank", "start_pos": 30, "end_pos": 68, "type": "DATASET", "confidence": 0.9104182600975037}, {"text": "ATR English Grammar", "start_pos": 176, "end_pos": 195, "type": "DATASET", "confidence": 0.9528627196947733}]}, {"text": "For instance, the tagset is both seman\u00a2By rule assignment, we mean the task of assigning a rule-name to anode in a parse tree, given that the constituent boundaries have already been defined.", "labels": [], "entities": [{"text": "rule assignment", "start_pos": 42, "end_pos": 57, "type": "TASK", "confidence": 0.7297634184360504}]}, {"text": "7This is not completely possible, since correlations, even if slight, will exist between intra-and extrasentential information Sspecifically, a roughly-900,000-word subset of the full ATR/Lancaster General-English Treebank (about 1.05 million words), from which all 150,000 words were excluded that were treebanked by the two least accurate ATR/Lancaster treebankers (expected hand-parsing error rate 32%, versus less than 10% overall for the three remaining treebankers) tic and syntactic, and includes around 2000 different tags, which classify nouns, verbs, adjectives and adverbs via over 100 semantic categories.", "labels": [], "entities": [{"text": "ATR/Lancaster General-English Treebank", "start_pos": 184, "end_pos": 222, "type": "DATASET", "confidence": 0.8619110226631165}, {"text": "ATR/Lancaster treebankers", "start_pos": 341, "end_pos": 366, "type": "DATASET", "confidence": 0.830518051981926}]}, {"text": "As examples of the level of syntactic detail, exhaustive syntactic and semantic analysis is performed on all nominal compounds; and the full range of attachment sites is available within the Grammar for sentential and phrasal modifiers, and are used precisely in the Treebank.", "labels": [], "entities": []}, {"text": "The Treebank actually consists of a set of documents, from a variety of sources.", "labels": [], "entities": [{"text": "The Treebank", "start_pos": 0, "end_pos": 12, "type": "DATASET", "confidence": 0.8968933522701263}]}, {"text": "Crucially for our experiments (see below), the idea 9 informing the selection of (the roughly 2000) documents for inclusion in the Treebank was to pack into it the maximum degree of document variation along many different scales--document length, subject area, style, point of view, etc.--but without establishing a single, predetermined classification of the included documents.", "labels": [], "entities": []}, {"text": "In the first experiment, we examine the effectiveness of using trigger pairs over the entire training corpus.", "labels": [], "entities": []}, {"text": "At the same time we investigate the effect of varying the window size.", "labels": [], "entities": []}, {"text": "In additional experiments, we observe the effect of partitioning our training dataset into a few relatively homogeneous subsets, on the hypothesis that this will decrease perplexity.", "labels": [], "entities": []}, {"text": "It seems reasonable that in different text varieties, different sets of trigger pairs will be useful, and that tokens which do not have effective triggers within one text variety may have them in another) \u00b0 To investigate the utility of partitioning the dataset, we construct a separate set of trigger pairs for each class.", "labels": [], "entities": []}, {"text": "These triggers are only active for their respective class and are independent of each other.", "labels": [], "entities": []}, {"text": "Their total mutual information is compared to that derived in exactly the same way from a random partition of our corpus into the same number of classes, each comprised of the same number of documents.", "labels": [], "entities": []}, {"text": "Our training data partitions naturally into four subsets, shown in as Partitioning 1 (\"Source\").", "labels": [], "entities": []}, {"text": "Partitioning 2, \"List Structure\", puts all documents which contain at least some HTMLlike \"List\" markup (e.g. LI (=List Item)) 11 in one 9see () 1\u00b0Related work in topic-specific trigram modelling ( has led to a reduction in perplexity.", "labels": [], "entities": [{"text": "topic-specific trigram modelling", "start_pos": 163, "end_pos": 195, "type": "TASK", "confidence": 0.592481275399526}]}, {"text": "11All documents in our training set are marked up in HTML-like annotation.", "labels": [], "entities": [{"text": "11All documents", "start_pos": 0, "end_pos": 15, "type": "DATASET", "confidence": 0.9079544544219971}]}, {"text": "subset, and all other documents in the other subset.", "labels": [], "entities": []}, {"text": "By merging Partitionings 1 and 2 we obtain Partitioning 3, \"Source Plus List Structure\".", "labels": [], "entities": []}, {"text": "Partitioning 4 is \"Source Plus Document Type\", and contains 9 subsets, e.g. \"Letters; diaries\" (subset 8) and \"Novels; stories; fables\" (subset 7).", "labels": [], "entities": []}, {"text": "With 13 subsets, ~e Partitioning 5, \"Source Plus Domain\" includes e.g.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Training Set Partitions", "labels": [], "entities": [{"text": "Partitions", "start_pos": 23, "end_pos": 33, "type": "TASK", "confidence": 0.5970150232315063}]}, {"text": " Table 3: Perplexity reduction using class-specific triggers to predict tags and rules", "labels": [], "entities": [{"text": "Perplexity reduction", "start_pos": 10, "end_pos": 30, "type": "TASK", "confidence": 0.8472709059715271}]}, {"text": " Table 6: Selected Tag Trigger-Pairs, ATR/Lancaster General-English Treebank: Contrasting Trigger-Pairs  Arising From Partitioned vs. Unpartitioned Training Sets", "labels": [], "entities": [{"text": "ATR/Lancaster General-English Treebank", "start_pos": 38, "end_pos": 76, "type": "DATASET", "confidence": 0.7575902938842773}]}]}