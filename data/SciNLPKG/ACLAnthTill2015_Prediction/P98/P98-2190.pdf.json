{"title": [{"text": "Conditions on Consistency of Probabilistic Tree Adjoining Grammars*", "labels": [], "entities": []}], "abstractContent": [{"text": "Much of the power of probabilistic methods in modelling language comes from their ability to compare several derivations for the same string in the language.", "labels": [], "entities": []}, {"text": "An important starting point for the study of such cross-derivational properties is the notion of consistency.", "labels": [], "entities": []}, {"text": "The probability model defined by a probabilistic grammar is said to be consistent if the probabilities assigned to all the strings in the language sum to one.", "labels": [], "entities": []}, {"text": "From the literature on probabilistic context-free grammars (CFGs), we know precisely the conditions which ensure that consistency is true fora given CFG.", "labels": [], "entities": [{"text": "consistency", "start_pos": 118, "end_pos": 129, "type": "METRIC", "confidence": 0.9769750833511353}, {"text": "CFG", "start_pos": 149, "end_pos": 152, "type": "DATASET", "confidence": 0.9480523467063904}]}, {"text": "This paper derives the conditions under which a given probabilistic Tree Adjoining Grammar (TAG) can be shown to be consistent.", "labels": [], "entities": []}, {"text": "It gives a simple algorithm for checking consistency and gives the formal justification for its correctness.", "labels": [], "entities": []}, {"text": "The conditions derived here can be used to ensure that probability models that use TAGs can be checked for deficiency (i.e. whether any probability mass is assigned to strings that cannot be generated).", "labels": [], "entities": []}], "introductionContent": [{"text": "Much of the power of probabilistic methods in modelling language comes from their ability to compare several derivations for the same string in the language.", "labels": [], "entities": []}, {"text": "This cross-derivational power arises naturally from comparison of various derivational paths, each of which is a product of the probabilities associated with each step in each derivation.", "labels": [], "entities": []}, {"text": "A common approach used to assign structure to language is to use a probabilistic grammar where each elementary rule * This research was partially supported by NSF grant SBR8920230 and ARO grant DAAH0404-94-G-0426.", "labels": [], "entities": [{"text": "ARO grant DAAH0404-94-G-0426", "start_pos": 184, "end_pos": 212, "type": "DATASET", "confidence": 0.6791848540306091}]}, {"text": "The author would like to thank Aravind Joshi, Jeff Reynat, Giorgio Satta, B. Srinivas, Fei Xia and the two anonymous reviewers for their valuable comments. or production is associated with a probability.", "labels": [], "entities": []}, {"text": "Using such a grammar, a probability for each string in the language is computed.", "labels": [], "entities": []}, {"text": "Assuming that the probability of each derivation of a sentence is well-defined, the probability of each string in the language is simply the sum of the probabilities of all derivations of the string.", "labels": [], "entities": []}, {"text": "In general, fora probabilistic grammar G the language of G is denoted by L(G).", "labels": [], "entities": []}, {"text": "Then if a string v is in the language L(G) the probabilistic grammar assigns v some non-zero probability.", "labels": [], "entities": []}, {"text": "There are several cross-derivational properties that can be studied fora given probabilistic grammar formalism.", "labels": [], "entities": []}, {"text": "An important starting point for such studies is the notion of consistency.", "labels": [], "entities": []}, {"text": "The probability model defined by a probabilistic grammar is said to be consistent if the probabilities assigned to all the strings in the language sum to 1.", "labels": [], "entities": []}, {"text": "That is, if Pr defined by a probabilistic grammar, assigns a probability to each string v 6 E*, where Pr(v) = 0 ifv ~ L(G), then", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": []}