{"title": [{"text": "Anaphor resolution in unrestricted texts with partial parsing", "labels": [], "entities": [{"text": "parsing", "start_pos": 54, "end_pos": 61, "type": "TASK", "confidence": 0.540693461894989}]}], "abstractContent": [{"text": "In this paper we deal with several kinds of anaphora in unrestricted texts.", "labels": [], "entities": []}, {"text": "These kinds of anaphora are pronominal references, surface-count anaphora and one-anaphora.", "labels": [], "entities": []}, {"text": "In order to solve these anaphors we work on the output of a part-of-speech tagger, on which we automatically apply a partial parsing from the formalism: Slot Unification Grammar, which has been implemented in Prolog.", "labels": [], "entities": [{"text": "Prolog", "start_pos": 209, "end_pos": 215, "type": "DATASET", "confidence": 0.9057300090789795}]}, {"text": "We only use the following kinds of information: lexical (the lemma of each word), morphologic (person, number, gender) and syntactic.", "labels": [], "entities": []}, {"text": "Finally we show the experimental results, and the restrictions and preferences that we have used for anaphor resolution with partial parsing.", "labels": [], "entities": [{"text": "anaphor resolution", "start_pos": 101, "end_pos": 119, "type": "TASK", "confidence": 0.7485609948635101}]}], "introductionContent": [{"text": "Nowadays there are two different approaches to anaphor resolution: integrated and alternative.", "labels": [], "entities": [{"text": "anaphor resolution", "start_pos": 47, "end_pos": 65, "type": "TASK", "confidence": 0.8017206490039825}]}, {"text": "The former is based on the integration of different kinds of knowledge (e.g. syntactic or semantic information) whereas the latter is based on statistical, neural networks or the principles of reasoning with uncertainty: e.g. and.", "labels": [], "entities": []}, {"text": "Our system can be included into the first approach.", "labels": [], "entities": []}, {"text": "In these integrated approaches the semantic and domain knowledge information is very expensive in relation to computational processing.", "labels": [], "entities": []}, {"text": "As a consequence, current anaphor resolution implementations mainly rely on constraints and preference heuristics which employ information originated from morphosyntactic or shallow semantic analysis, e.g. in.", "labels": [], "entities": [{"text": "anaphor resolution", "start_pos": 26, "end_pos": 44, "type": "TASK", "confidence": 0.782044380903244}]}, {"text": "These approaches, however, perform remarkably well.", "labels": [], "entities": []}, {"text": "In it is described an algorithm for pronominal anaphor resolution with a high rate of correct analyses: 85%.", "labels": [], "entities": [{"text": "pronominal anaphor resolution", "start_pos": 36, "end_pos": 65, "type": "TASK", "confidence": 0.5648035109043121}, {"text": "correct", "start_pos": 86, "end_pos": 93, "type": "METRIC", "confidence": 0.9695125818252563}]}, {"text": "This one operates primarily on syntactic information only.", "labels": [], "entities": []}, {"text": "In it is proposed an algorithm for anaphor resolution which is a modified and extended version of that developed by.", "labels": [], "entities": [{"text": "anaphor resolution", "start_pos": 35, "end_pos": 53, "type": "TASK", "confidence": 0.732108548283577}]}, {"text": "In contrast to that work, this algorithm does not require in-depth, full, syntactic parsing of text.", "labels": [], "entities": []}, {"text": "The modifications enable the resolution process to work from the output of a POS tagger, enriched only with annotations of grammatical function of lexical items in the input text stream.", "labels": [], "entities": []}, {"text": "The advantage of this algorithm is that anaphor resolution can be realized within NLP frameworks which do not -or cannot-employ robust and reliable parsing components.", "labels": [], "entities": [{"text": "anaphor resolution", "start_pos": 40, "end_pos": 58, "type": "TASK", "confidence": 0.7903018593788147}]}, {"text": "Quantitative evaluation shows the anaphor resolution algorithm described hereto run at a rate of 75% accuracy.", "labels": [], "entities": [{"text": "anaphor resolution", "start_pos": 34, "end_pos": 52, "type": "TASK", "confidence": 0.6801421195268631}, {"text": "accuracy", "start_pos": 101, "end_pos": 109, "type": "METRIC", "confidence": 0.9982014894485474}]}, {"text": "Our framework will allow us a similar approach to that of, but we will automatically get syntactic information from partial parsing.", "labels": [], "entities": []}, {"text": "Moreover, our proposal will also be applied to other kinds of anaphors such as surface-count anaphora or one-anaphora.", "labels": [], "entities": []}, {"text": "There are some other approaches that work on the output of a POS tagger, e.g. that of, in which it is proposed another knowledge-poor approach to resolving pronouns in technical manuals in both English and Polish.", "labels": [], "entities": [{"text": "POS tagger", "start_pos": 61, "end_pos": 71, "type": "TASK", "confidence": 0.6799382269382477}]}, {"text": "This approach is a modification of the reported in.", "labels": [], "entities": []}, {"text": "Here, the knowledge is limited to a small noun phrase grammar, a list of terms and This paper has been supported by the CICYT number TIC97-0671-C02-01 / 02 a set of antecedent indicators (definiteness, giveness, term preference, lexical reiteration, ...).", "labels": [], "entities": [{"text": "CICYT number TIC97-0671-C02-01 / 02", "start_pos": 120, "end_pos": 155, "type": "DATASET", "confidence": 0.8048562288284302}]}, {"text": "We will work in a similar way to this approach, since we use some of its antecedent indicators, but we automatically apply a partial parsing that allows us to deal with other kinds of anaphors as well as pronouns.", "labels": [], "entities": []}, {"text": "In this work we are going to apply a partial parsing on the output of a POS tagger in order to solve anaphora problem.", "labels": [], "entities": [{"text": "POS tagger", "start_pos": 72, "end_pos": 82, "type": "TASK", "confidence": 0.5591770708560944}]}, {"text": "We will work over the corpus used within CRATER z.", "labels": [], "entities": []}, {"text": "This corpus contains the International Telecommunications Union CCITT handbook, also known as The Blue Book, in English, French and Spanish versions.", "labels": [], "entities": [{"text": "International Telecommunications Union CCITT handbook", "start_pos": 25, "end_pos": 78, "type": "DATASET", "confidence": 0.9055774450302124}, {"text": "The Blue Book", "start_pos": 94, "end_pos": 107, "type": "DATASET", "confidence": 0.9097564220428467}]}, {"text": "This corpus is the most important collection of telecommunication texts and contains 5M words, automatically tagged by the Spanish version of the Xerox tagger.", "labels": [], "entities": []}, {"text": "We will use the system Slot Unification Grammar (SUG) in order to get a partial parsing on the output of this tagger.", "labels": [], "entities": [{"text": "Slot Unification Grammar (SUG)", "start_pos": 23, "end_pos": 53, "type": "TASK", "confidence": 0.6762219568093618}]}, {"text": "SUG is a logical formalism based on unification, which is an extension of Definite Clause Grammars (DCG).", "labels": [], "entities": []}, {"text": "It is called Slot Unification Grammar due to the slot structures generated by the parser.", "labels": [], "entities": [{"text": "Slot Unification Grammar", "start_pos": 13, "end_pos": 37, "type": "TASK", "confidence": 0.8346552650133768}]}, {"text": "SUG has been developed with the aim of extending DCG in order to facilitate the resolution of several Natural Language Processing (NLP) problems in a modular way.", "labels": [], "entities": []}, {"text": "This system has been firstly proposed in, and it has been previously applied to anaphor resolution in.", "labels": [], "entities": [{"text": "anaphor resolution", "start_pos": 80, "end_pos": 98, "type": "TASK", "confidence": 0.7606030702590942}]}, {"text": "We have used SUG instead of other well known formalisms such as Head Driven Phrase Structure Grammar (HPSG), Lexical Functional Grammar (LFG) or Slot Grammars (SG), because SUG allows a modular and computational treatment of NLP problems, and it facilitates its integration with a POS tagger.", "labels": [], "entities": []}, {"text": "In the following section we will briefly describe SUG formalism in order to facilitate the undertanding of this paper.", "labels": [], "entities": [{"text": "SUG formalism", "start_pos": 50, "end_pos": 63, "type": "TASK", "confidence": 0.8430101871490479}]}, {"text": "In section 2 we will propose a SUG grammar to accomplish the partial parsing of the unrestricted text and the interface to work with the output of the POS tagger.", "labels": [], "entities": []}, {"text": "In section 3 we will explain the algorithm used to anaphor resolution and its constraints and", "labels": [], "entities": [{"text": "anaphor resolution", "start_pos": 51, "end_pos": 69, "type": "TASK", "confidence": 0.7391259372234344}]}], "datasetContent": [{"text": "We have run our system on part of the previously mentioned corpus (9600 words), and we have got the following figures.", "labels": [], "entities": []}, {"text": "Our system has detected 100% of the anaphors described in this paper, and the partial parsing described in, has parsed 81% of words with a very simple grammar 8.", "labels": [], "entities": []}, {"text": "The medium length of the sentences with anaphors is 48 words.", "labels": [], "entities": []}, {"text": "For pronominal references we have a 83% accuracy in detecting the position of the antecedent.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 40, "end_pos": 48, "type": "METRIC", "confidence": 0.9995762705802917}]}, {"text": "For one-anaphora and surface-count anaphora, we have not got significant figures since there were not so many anaphors as we wished (only 5 anaphors with a 80% accuracy).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 160, "end_pos": 168, "type": "METRIC", "confidence": 0.99713134765625}]}, {"text": "The reason why some of the references have failed is mainly due to the lack of semantic information and due to the problem of attachments between different parsed constituents 9.", "labels": [], "entities": []}], "tableCaptions": []}