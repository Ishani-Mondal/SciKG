{"title": [{"text": "Context Management with Topics for Spoken Dialogue Systems", "labels": [], "entities": [{"text": "Context Management", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.9222681820392609}]}], "abstractContent": [{"text": "In this paper we discuss the use of discourse context in spoken dialogue systems and argue that the knowledge of the domain, modelled with the help of dialogue topics is important in maintaining robust-ness of the system and improving recognition accuracy of spoken utterances.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 247, "end_pos": 255, "type": "METRIC", "confidence": 0.9683499336242676}]}, {"text": "We propose a topic model which consists of a domain model, structured into a topic tree, and the Predict-Support algorithm which assigns topics to utterances on the basis of the topic transitions described in the topic tree and the words recognized in the input utterance.", "labels": [], "entities": []}, {"text": "The algorithm uses a probabilistic topic type tree and mutual information between the words and different topic types, and gives recognition accuracy of 78.68% and precision of 74.64%.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 141, "end_pos": 149, "type": "METRIC", "confidence": 0.8775036931037903}, {"text": "precision", "start_pos": 164, "end_pos": 173, "type": "METRIC", "confidence": 0.9996160268783569}]}, {"text": "This makes our topic model highly comparable to discourse models which are based on recognizing dialogue acts.", "labels": [], "entities": []}], "introductionContent": [{"text": "One of the fragile points in integrated spoken language systems is the erroneous analyses of the initial speech input.", "labels": [], "entities": []}, {"text": "1 The output of a speech recognizer has direct influence on the performance of other modules of the system (dealing with dialogue management, translation, database search, response planning, etc.), and the initial inaccuracy usually gets accumulated in the later stages of processing.", "labels": [], "entities": [{"text": "speech recognizer", "start_pos": 18, "end_pos": 35, "type": "TASK", "confidence": 0.7172455936670303}, {"text": "dialogue management", "start_pos": 121, "end_pos": 140, "type": "TASK", "confidence": 0.8212240636348724}, {"text": "translation", "start_pos": 142, "end_pos": 153, "type": "TASK", "confidence": 0.9149317145347595}, {"text": "response planning", "start_pos": 172, "end_pos": 189, "type": "TASK", "confidence": 0.7556160390377045}]}, {"text": "Performance of speech recognizers can be improved by tuning their language model and lexicon, but problems still remain with the erroneous ranking of the best paths: information content of the selected utterances maybe wrong.", "labels": [], "entities": [{"text": "speech recognizers", "start_pos": 15, "end_pos": 33, "type": "TASK", "confidence": 0.7401019334793091}]}, {"text": "It is thus essential to use contextual information to compensate various errors in the output, to provide expectations of what will be said next and to help to determine the appropriate dialogue state.", "labels": [], "entities": []}, {"text": "However, negative effects of an inaccurate context have also been noted: cumulative error in discourse context drags performance of the system below the rates it would achieve were contextual information not used (.", "labels": [], "entities": []}, {"text": "Successful use of context thus presupposes appropriate context management: (1) features that define the context are relevant for the processing task, and (2) construction of the context is accurate.", "labels": [], "entities": []}, {"text": "In this paper we argue in favour of using one type of contextual information, topic information, to maintain robustness of a spoken language system.", "labels": [], "entities": []}, {"text": "Our model deals with the information content of utterances, and defines the context in terms of topic types, related to the current domain knowledge and represented in the form of a topic tree.", "labels": [], "entities": []}, {"text": "To update the context with topics we introduce the Predict-Support algorithm which selects utterance topics on the basis of topic transitions described in the topic tree and words recognized in the current utterance.", "labels": [], "entities": [{"text": "Predict-Support", "start_pos": 51, "end_pos": 66, "type": "METRIC", "confidence": 0.9282784461975098}]}, {"text": "At present, the algorithm is designed as a filter which re-orders the candidates produced by the speech recognizer, but future work encompasses integration of the algorithm into a language model and actual speech recognition process.", "labels": [], "entities": [{"text": "speech recognizer", "start_pos": 97, "end_pos": 114, "type": "TASK", "confidence": 0.7213803827762604}, {"text": "speech recognition", "start_pos": 206, "end_pos": 224, "type": "TASK", "confidence": 0.7118989527225494}]}, {"text": "The paper is organised as follows.", "labels": [], "entities": []}, {"text": "Section 2 reviews the related previous research and sets out our starting point.", "labels": [], "entities": []}, {"text": "Section 3 presents the topic model and the Predict-Support algorithm, and section 4 gives results of the experiments conducted with the model.", "labels": [], "entities": [{"text": "Predict-Support", "start_pos": 43, "end_pos": 58, "type": "METRIC", "confidence": 0.9108893871307373}]}, {"text": "Finally, section 5 summarises the properties of the topic model, and points to future research.", "labels": [], "entities": []}], "datasetContent": [{"text": "We tested the Predict-Support algorithm using cross-validation on our corpus.", "labels": [], "entities": []}, {"text": "The accuracy results of the first predictions are given in.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.9995301961898804}]}, {"text": "PP is the corpus perplexity which represents the average branching factor of the corpus, or the number of alternatives from which to choose the correct label at a given point.", "labels": [], "entities": [{"text": "PP", "start_pos": 0, "end_pos": 2, "type": "METRIC", "confidence": 0.827972412109375}]}, {"text": "For the pruned topic types, we reserved 10 randomly picked dialogues for testing (each test file contained about 400-500 test utterances), and used the other 70 dialogues for training in each test cycle.", "labels": [], "entities": []}, {"text": "The average accuracy rate, 78.68 % is a satisfactory result.", "labels": [], "entities": [{"text": "accuracy rate", "start_pos": 12, "end_pos": 25, "type": "METRIC", "confidence": 0.9750173687934875}]}, {"text": "We also did another set of cross-validation tests using 75 dialogues for training and 5 dialogues for testing, and as expected, a bigger training corpus gives better recognition results when perplexity stays the same.", "labels": [], "entities": []}, {"text": "To compare how much difference a bigger number of topic tags makes to the results, we conducted cross-validation tests with the original 62 topic types.", "labels": [], "entities": []}, {"text": "A finer set of topic tags does worsen  the accuracy, but not as much as we expected: the Support-part of the algorithm effectively remedies prediction inaccuracies.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 43, "end_pos": 51, "type": "METRIC", "confidence": 0.9995212554931641}, {"text": "Support-part", "start_pos": 89, "end_pos": 101, "type": "METRIC", "confidence": 0.9456166625022888}]}, {"text": "Since the same corpus is also tagged with speech acts, we conducted similar cross-validation tests with speech act labels.", "labels": [], "entities": []}, {"text": "The recognition rates are worse than those of the 62 topic types, although perplexity is almost the same.", "labels": [], "entities": []}, {"text": "We believe that this is because speech acts ignore the actual content of the utterance.", "labels": [], "entities": []}, {"text": "Although our speech act labels are surface-oriented, they correlate with only a few fixed phrases (I would like to; please), and are thus less suitable to convey the semantic focus of the utterances, expressed by the content words than topics, which by definition deal with the content.", "labels": [], "entities": []}, {"text": "As the lower-bound experiments we conducted cross-validation tests using the trigram backoffmodel, i.e. relying only on the context which records the history of topic types.", "labels": [], "entities": []}, {"text": "For the first ranked predictions the accuracy rate is about 40%, which is on the same level as the first ranked speech act predictions reported in.", "labels": [], "entities": [{"text": "accuracy rate", "start_pos": 37, "end_pos": 50, "type": "METRIC", "confidence": 0.9761864542961121}]}, {"text": "The average precision of the Predict-Support algorithm is also calculated (  The results of the topic recognition show that the model performs well, and we notice a considerable improvement in the accuracy rates compared to accuracy rates in speech act recognition cited in section 2 (modulo perplexity).", "labels": [], "entities": [{"text": "precision", "start_pos": 12, "end_pos": 21, "type": "METRIC", "confidence": 0.9965941309928894}, {"text": "topic recognition", "start_pos": 96, "end_pos": 113, "type": "TASK", "confidence": 0.8032992780208588}, {"text": "accuracy", "start_pos": 197, "end_pos": 205, "type": "METRIC", "confidence": 0.9987632036209106}, {"text": "accuracy", "start_pos": 224, "end_pos": 232, "type": "METRIC", "confidence": 0.9957222938537598}, {"text": "speech act recognition", "start_pos": 242, "end_pos": 264, "type": "TASK", "confidence": 0.6528098384539286}]}, {"text": "Although the rates are somewhat optimistic as we used transcribed dialogues (= the correct recognizer output), we can still safely conclude that topic information provides a promising starting point in attempts to provide an accurate context for the spoken dialogue systems.", "labels": [], "entities": []}, {"text": "This can be further verified in the perplexity measures for the word recognition: compared to a general language model trained on non-tagged dialogues, perplexity decreases by 20 % fora language model which is trained on topic-dependent dialogues, and by 14 % if we use an open test with unknown words included as well.", "labels": [], "entities": [{"text": "word recognition", "start_pos": 64, "end_pos": 80, "type": "TASK", "confidence": 0.7565825283527374}]}, {"text": "At the end we have to make a remark concerning the relevance of speech acts: our argumentation is not meant to underestimate their use for other purposes in dialogue modelling, but rather, to emphasise the role of topic information in successful context management: in our opinion the topics provide a more reliable and straighforward approximation of the utterance meaning than speech acts, and should not be ignored in the definition of context models for spoken dialogue systems.", "labels": [], "entities": []}], "tableCaptions": []}