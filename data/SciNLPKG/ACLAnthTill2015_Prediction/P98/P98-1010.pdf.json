{"title": [{"text": "A Memory-Based Approach to Learning Shallow Natural Language Patterns", "labels": [], "entities": []}], "abstractContent": [{"text": "Recognizing shallow linguistic patterns, such as basic syntactic relationships between words, is a common task in applied natural language and text processing.", "labels": [], "entities": [{"text": "Recognizing shallow linguistic patterns", "start_pos": 0, "end_pos": 39, "type": "TASK", "confidence": 0.8980494141578674}]}, {"text": "The common practice for approaching this task is by tedious manual definition of possible pattern structures, often in the form of regular expressions or finite automata.", "labels": [], "entities": []}, {"text": "This paper presents a novel memory-based learning method that recognizes shallow patterns in new text based on a bracketed training corpus.", "labels": [], "entities": []}, {"text": "The training data are stored as-is, in efficient suffix-tree data structures.", "labels": [], "entities": []}, {"text": "Generalization is performed on-line at recognition time by comparing subsequences of the new text to positive and negative evidence in the corpus.", "labels": [], "entities": [{"text": "Generalization", "start_pos": 0, "end_pos": 14, "type": "TASK", "confidence": 0.9748655557632446}]}, {"text": "This way, no information in the training is lost, as can happen in other learning systems that construct a single generalized model at the time of training.", "labels": [], "entities": []}, {"text": "The paper presents experimental results for recognizing noun phrase, subject-verb and verb-object patterns in En-glish.", "labels": [], "entities": []}, {"text": "Since the learning approach enables easy port-ing to new domains, we plan to apply it to syntactic patterns in other languages and to sub-language patterns for information extraction.", "labels": [], "entities": [{"text": "information extraction", "start_pos": 160, "end_pos": 182, "type": "TASK", "confidence": 0.8304004967212677}]}], "introductionContent": [{"text": "Identifying local patterns of syntactic sequences and relationships is a fundamental task in natural language processing (NLP).", "labels": [], "entities": [{"text": "Identifying local patterns of syntactic sequences and relationships", "start_pos": 0, "end_pos": 67, "type": "TASK", "confidence": 0.881024606525898}, {"text": "natural language processing (NLP)", "start_pos": 93, "end_pos": 126, "type": "TASK", "confidence": 0.793306976556778}]}, {"text": "Such patterns may correspond to syntactic phrases, like noun phrases, or to pairs of words that participate in a syntactic relationship, like the heads of a verb-object relation.", "labels": [], "entities": []}, {"text": "Such patterns have been found useful in various application areas, including information extraction, text summarization, and bilingual alignment.", "labels": [], "entities": [{"text": "information extraction", "start_pos": 77, "end_pos": 99, "type": "TASK", "confidence": 0.8513582646846771}, {"text": "text summarization", "start_pos": 101, "end_pos": 119, "type": "TASK", "confidence": 0.7755984365940094}, {"text": "bilingual alignment", "start_pos": 125, "end_pos": 144, "type": "TASK", "confidence": 0.7528621852397919}]}, {"text": "Syntactic patterns are useful also for many basic computational linguistic tasks, such as statistical word similarity and various disambiguation problems.", "labels": [], "entities": [{"text": "statistical word similarity", "start_pos": 90, "end_pos": 117, "type": "TASK", "confidence": 0.6845569610595703}]}, {"text": "One approach for detecting syntactic patterns is to obtain a full parse of a sentence and then extract the required patterns.", "labels": [], "entities": []}, {"text": "However, obtaining a complete parse tree fora sentence is difficult in many cases, and may not be necessary at all for identifying most instances of local syntactic patterns.", "labels": [], "entities": []}, {"text": "An alternative approach is to avoid the complexity of full parsing and instead to rely only on local information.", "labels": [], "entities": []}, {"text": "A variety of methods have been developed within this framework, known as shallow parsing, chunking, local parsing etc.", "labels": [], "entities": []}, {"text": "These works have shown that it is possible to identify most instances of local syntactic patterns by rules that examine only the pattern itself and its nearby context.", "labels": [], "entities": []}, {"text": "Often, the rules are applied to sentences that were tagged by partof-speech (POS) and are phrased by some form of regular expressions or finite state automata.", "labels": [], "entities": []}, {"text": "Manual writing of local syntactic rules has become a common practice for many applications.", "labels": [], "entities": []}, {"text": "However, writing rules is often tedious and time consuming.", "labels": [], "entities": []}, {"text": "Furthermore, extending the rules to different languages or sub-language domains can require substantial resources and expertise that are often not available.", "labels": [], "entities": []}, {"text": "As in many areas of NLP, a learning approach is appealing.", "labels": [], "entities": []}, {"text": "Surprisingly, though, rather little work has been devoted to learning local syntactic patterns, mostly noun phrases.", "labels": [], "entities": []}, {"text": "This paper presents a novel general learning approach for recognizing local sequential patterns, that maybe perceived as falling within the memorybased learning paradigm.", "labels": [], "entities": []}, {"text": "The method utilizes a part-of-speech tagged training corpus in which all instances of the target pattern are marked (bracketed).", "labels": [], "entities": []}, {"text": "The training data are stored as-is in suffix-tree data structures, which enable linear time searching for subsequences in the corpus.", "labels": [], "entities": []}, {"text": "The memory-based nature of the presented algorithm stems from its deduction strategy: anew instance of the target pattern is recognized by examining the raw training corpus, searching for positive and negative evidence with respect to the given test sequence.", "labels": [], "entities": []}, {"text": "No model is created for the training corpus, and the raw examples are not converted to any other representation.", "labels": [], "entities": []}, {"text": "Consider the following example 1.", "labels": [], "entities": []}, {"text": "Suppose we 1We use here the POS tags: DT ----determiner, ADJ = adjective, hDV = adverb, C0NJ = conjunction, VB=verb, PP=preposition, NN = singular noun, and NNP ----plural noun.", "labels": [], "entities": [{"text": "DT ----determiner", "start_pos": 38, "end_pos": 55, "type": "METRIC", "confidence": 0.7663328846295675}]}, {"text": "want to decide whether the candidate sequence DT ADJ ADJ NN NNP is a noun phrase (NP) by comparing it to the training corpus.", "labels": [], "entities": []}, {"text": "A good match would be if the entire sequence appears as-is several times in the corpus.", "labels": [], "entities": []}, {"text": "However, due to data sparseness, an exact match cannot always be expected.", "labels": [], "entities": []}, {"text": "A somewhat weaker match maybe obtained if we consider sub-parts of the candidate sequence (called tiles).", "labels": [], "entities": []}, {"text": "For example, suppose the corpus contains noun phrase instances with the following structures: The first structure provides positive evidence that the sequence \"DT ADJ ADJ NN\" is a possible NP prefix while the second structure provides evidence for \"ADJ NN NNP\" being an NP suffix.", "labels": [], "entities": []}, {"text": "Together, these two training instances provide positive evidence that covers the entire candidate.", "labels": [], "entities": []}, {"text": "Considering evidence for sub-parts of the pattern enables us to generalize over the exact structures that are present in the corpus.", "labels": [], "entities": []}, {"text": "Similarly, we also consider the negative evidence for such sub-parts by noting where they occur in the corpus without being a corresponding part of a target instance.", "labels": [], "entities": []}, {"text": "The proposed method, as described in detail in the next section, formalizes this type of reasoning.", "labels": [], "entities": []}, {"text": "It searches specialized data structures for both positive and negative evidence for sub-parts of the candidate structure, and considers additional factors such as context and evidence overlap.", "labels": [], "entities": []}, {"text": "Section 3 presents experimental results for three target syntactic patterns in English, and Section 4 describes related work.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Sizes of training and test data", "labels": [], "entities": [{"text": "Sizes", "start_pos": 10, "end_pos": 15, "type": "TASK", "confidence": 0.9881938695907593}]}, {"text": " Table 2: Distribution of pattern lengths, total num- ber of patterns and average length in the training  data.", "labels": [], "entities": [{"text": "average length", "start_pos": 74, "end_pos": 88, "type": "METRIC", "confidence": 0.8672614991664886}]}, {"text": " Table 3: Results with optimal parameter settings for context size and threshold, and breakeven points. The  last line shows the results of Ramshaw and Marcus (1995) (recognizing NP's) with the same train/test data.  The optimal parameters were obtained by 5-fold cross-validation.", "labels": [], "entities": [{"text": "breakeven", "start_pos": 86, "end_pos": 95, "type": "METRIC", "confidence": 0.9767308235168457}]}]}