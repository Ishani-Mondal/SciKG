{"title": [{"text": "Named Entity Scoring for Speech Input", "labels": [], "entities": []}], "abstractContent": [{"text": "This paper describes anew scoring algorithm that supports comparison of linguistically annotated data from noisy sources.", "labels": [], "entities": []}, {"text": "The new algorithm generalizes the Message Understanding Conference (MUC) Named Entity scoring algorithm, using a comparison based on explicit alignment of the underlying texts, followed by a scoring phase.", "labels": [], "entities": [{"text": "Message Understanding Conference (MUC) Named Entity scoring", "start_pos": 34, "end_pos": 93, "type": "TASK", "confidence": 0.8116072217623392}]}, {"text": "The scoring procedure maps corresponding tagged regions and compares these according to tag type and tag extent, allowing us to reproduce the MUC Named Entity scoring for identical underlying texts.", "labels": [], "entities": [{"text": "MUC Named Entity scoring", "start_pos": 142, "end_pos": 166, "type": "DATASET", "confidence": 0.8203916549682617}]}, {"text": "In addition, the new algorithm scores for content (transcription correctness) of the tagged region, a useful distinction when dealing with noisy data that may differ from a reference transcription (e.g., speech recognizer output).", "labels": [], "entities": []}, {"text": "To illustrate the algorithm, we have prepared a small test data set consisting of a careful transcription of speech data and manual insertion of SGML named entity annotation.", "labels": [], "entities": []}, {"text": "We report results for this small test corpus on a variety of experiments involving automatic speech recognition and named entity tagging.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 93, "end_pos": 111, "type": "TASK", "confidence": 0.6906372755765915}, {"text": "named entity tagging", "start_pos": 116, "end_pos": 136, "type": "TASK", "confidence": 0.6356514692306519}]}], "introductionContent": [], "datasetContent": [], "tableCaptions": []}