{"title": [{"text": "Toward General-Purpose Learning for Information Extraction", "labels": [], "entities": [{"text": "Information Extraction", "start_pos": 36, "end_pos": 58, "type": "TASK", "confidence": 0.7404968440532684}]}], "abstractContent": [{"text": "Two trends are evident in the recent evolution of the field of information extraction: a preference for simple, often corpus-driven techniques over linguistically sophisticated ones; and a broadening of the central problem definition to include many non-traditional text domains.", "labels": [], "entities": [{"text": "information extraction", "start_pos": 63, "end_pos": 85, "type": "TASK", "confidence": 0.7622999250888824}]}, {"text": "This development calls for information extraction systems which are as retctrgetable and general as possible.", "labels": [], "entities": [{"text": "information extraction", "start_pos": 27, "end_pos": 49, "type": "TASK", "confidence": 0.8674075305461884}]}, {"text": "Here, we describe SRV, a learning architecture for information extraction which is designed for maximum generality and flexibility.", "labels": [], "entities": [{"text": "SRV", "start_pos": 18, "end_pos": 21, "type": "TASK", "confidence": 0.8407334685325623}, {"text": "information extraction", "start_pos": 51, "end_pos": 73, "type": "TASK", "confidence": 0.8003378212451935}]}, {"text": "SRV can exploit domain-specific information, including linguistic syntax and lexical information , in the form of features provided to the system explicitly as input for training.", "labels": [], "entities": [{"text": "SRV", "start_pos": 0, "end_pos": 3, "type": "TASK", "confidence": 0.8556382656097412}]}, {"text": "This process is illustrated using a domain created from Reuters corporate acquisitions articles.", "labels": [], "entities": [{"text": "Reuters corporate acquisitions articles", "start_pos": 56, "end_pos": 95, "type": "DATASET", "confidence": 0.812852755188942}]}, {"text": "Features are derived from two general-purpose NLP systems, Sleator and Temperly's link grammar parser and Wordnet.", "labels": [], "entities": [{"text": "Sleator and Temperly's link grammar parser", "start_pos": 59, "end_pos": 101, "type": "TASK", "confidence": 0.5749494092805045}, {"text": "Wordnet", "start_pos": 106, "end_pos": 113, "type": "DATASET", "confidence": 0.959845244884491}]}, {"text": "Experiments compare the learner's performance with and without such linguistic information.", "labels": [], "entities": []}, {"text": "Surprisingly, in many cases, the system performs as well without this information as with it.", "labels": [], "entities": []}], "introductionContent": [{"text": "The field of information extraction (IE) is concerned with using natural language processing (NLP) to extract essential details from text documents automatically.", "labels": [], "entities": [{"text": "information extraction (IE)", "start_pos": 13, "end_pos": 40, "type": "TASK", "confidence": 0.8813556432723999}]}, {"text": "While the problems of retrieval, routing, and filtering have received considerable attention through the years, IE is only now coming into its own as an information management sub-discipline.", "labels": [], "entities": [{"text": "retrieval, routing, and filtering", "start_pos": 22, "end_pos": 55, "type": "TASK", "confidence": 0.5755173414945602}, {"text": "IE", "start_pos": 112, "end_pos": 114, "type": "TASK", "confidence": 0.9893744587898254}]}, {"text": "Progress in the field of IE has been away from general NLP systems, that must be tuned to work ill a particular domain, toward faster systems that perform less linguistic processing of documents and can be more readily targeted at novel domains (e.g.,).", "labels": [], "entities": [{"text": "IE", "start_pos": 25, "end_pos": 27, "type": "TASK", "confidence": 0.9889782071113586}]}, {"text": "A natural part of this development has been the introduction of machine learning techniques to facilitate the domain engineering effort.", "labels": [], "entities": []}, {"text": "Several researchers have reported IE systems which use machine learning at their core).", "labels": [], "entities": [{"text": "IE", "start_pos": 34, "end_pos": 36, "type": "TASK", "confidence": 0.9783161282539368}]}, {"text": "Rather than spend human effort tuning a system for an IE domain, it becomes possible to conceive of training it on a document sample.", "labels": [], "entities": [{"text": "IE domain", "start_pos": 54, "end_pos": 63, "type": "TASK", "confidence": 0.9042490124702454}]}, {"text": "Aside from the obvious savings inhuman development effort, this has significant implications for information extraction as a discipline: Retargetability Moving to a novel domain should no longer be a question of code modification; at most some feature engineering should be required.", "labels": [], "entities": [{"text": "information extraction", "start_pos": 97, "end_pos": 119, "type": "TASK", "confidence": 0.8703088462352753}]}, {"text": "Generality It should be possible to handle a much wider range of domains than previously.", "labels": [], "entities": []}, {"text": "In addition to domains characterized by grammatical prose, we should be able to perform information extraction in domains involving less traditional structure, such as netnews articles and Web pages.", "labels": [], "entities": [{"text": "information extraction", "start_pos": 88, "end_pos": 110, "type": "TASK", "confidence": 0.7808469533920288}]}, {"text": "In this paper we describe a learning algorithm similar in spirit to FOIL, which takes as input a set of tagged documents, and a set of features that control generalization, and produces rules that describe how to extract information from novel documents.", "labels": [], "entities": [{"text": "FOIL", "start_pos": 68, "end_pos": 72, "type": "DATASET", "confidence": 0.5904254913330078}]}, {"text": "For this system, introducing linguistic or any other information particular to a domain is an exercise in feature definition, separate from the central algorithm, which is constant.", "labels": [], "entities": [{"text": "feature definition", "start_pos": 106, "end_pos": 124, "type": "TASK", "confidence": 0.7230035364627838}]}, {"text": "We describe a set of experiments, involving a document collection of newswire articles, in which this learner is compared with simpler learning algorithms.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Accuracy and coverage for all four  learners on the acquisitions fields.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9983988404273987}, {"text": "coverage", "start_pos": 23, "end_pos": 31, "type": "METRIC", "confidence": 0.9925153851509094}]}, {"text": " Table 2: Accuracy from a three-split experiment  at fixed coverage levels.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9958674907684326}]}]}