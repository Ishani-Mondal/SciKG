{"title": [{"text": "Exploiting Syntactic Structure for Language Modeling", "labels": [], "entities": [{"text": "Language Modeling", "start_pos": 35, "end_pos": 52, "type": "TASK", "confidence": 0.7380976378917694}]}], "abstractContent": [{"text": "The paper presents a language model that develops syntactic structure and uses it to extract meaningful information from the word history, thus enabling the use of long distance dependencies.", "labels": [], "entities": []}, {"text": "The model assigns probability to every joint sequence of words-binary-parse-structure with headword annotation and operates in a left-to-right manner-therefore usable for automatic speech recognition.", "labels": [], "entities": [{"text": "automatic speech recognition", "start_pos": 171, "end_pos": 199, "type": "TASK", "confidence": 0.5968291163444519}]}, {"text": "The model, its probabilistic parameterization, and a set of experiments meant to evaluate its predictive power are presented; an improvement over standard trigram modeling is achieved.", "labels": [], "entities": []}], "introductionContent": [{"text": "The main goal of the present work is to develop a language model that uses syntactic structure to model long-distance dependencies.", "labels": [], "entities": []}, {"text": "During the summer96 DoD Workshop a similar attempt was made by the dependency modeling group.", "labels": [], "entities": [{"text": "summer96 DoD Workshop", "start_pos": 11, "end_pos": 32, "type": "DATASET", "confidence": 0.8415191173553467}, {"text": "dependency modeling", "start_pos": 67, "end_pos": 86, "type": "TASK", "confidence": 0.8859911859035492}]}, {"text": "The model we present is closely related to the one investigated in (, however different in a few important aspects: \u2022 our model operates in a left-to-right manner, allowing the decoding of word lattices, as opposed to the one referred to previously, where only whole sentences could be processed, thus reducing its applicability to n-best list re-scoring; the syntactic structure is developed as a model component; \u2022 our model is a factored version of the one in (, thus enabling the calculation of the joint probability of words and parse structure; this was not possible in the previous case due to the huge computational complexity of the model.", "labels": [], "entities": []}, {"text": "Our model develops syntactic structure incrementally while traversing the sentence from left to right.", "labels": [], "entities": []}, {"text": "This is the main difference between our approach and other approaches to statistical natural language parsing.", "labels": [], "entities": [{"text": "statistical natural language parsing", "start_pos": 73, "end_pos": 109, "type": "TASK", "confidence": 0.6905440986156464}]}, {"text": "Our parsing strategy is similar to the incremental syntax ones proposed relatively recently in the linguistic community).", "labels": [], "entities": []}, {"text": "The probabilistic model, its parameterization and a few experiments that are meant to evaluate its potential for speech recognition are presented.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 113, "end_pos": 131, "type": "TASK", "confidence": 0.8745422065258026}]}], "datasetContent": [{"text": "Due to the low speed of the parser --200 wds/min for stack depth 10 and log-probability threshold 6.91 nats (1/1000) --we could carryout the reestimation technique described in section 3.4 on only 1 Mwds of training data.", "labels": [], "entities": []}, {"text": "For convenience we chose to work on the UPenn Treebank corpus.", "labels": [], "entities": [{"text": "UPenn Treebank corpus", "start_pos": 40, "end_pos": 61, "type": "DATASET", "confidence": 0.9921169281005859}]}, {"text": "The vocabulary sizes were: * word vocabulary: 10k, open --all words outside the vocabulary are mapped to the <unk> token; \u2022 POS tag vocabulary: 40, closed; \u2022 non-terminal tag vocabulary: 52, closed; \u2022 parser operation vocabulary: 107, closed; The training data was split into \"development\" set --929,564wds (sections 00-20) --and \"check set\" --73,760wds (sections; the test set size was 82,430wds (sections 23-24).", "labels": [], "entities": []}, {"text": "The \"check\" set has been used for estimating the interpolation weights and tuning the search parameters; the \"development\" set has been used for gathering/estimating counts; the test set has been used strictly for evaluating model performance.", "labels": [], "entities": []}, {"text": "Simple linear interpolation between our model and the trigram model: yielded a further improvement in PPL, as shown in.", "labels": [], "entities": []}, {"text": "The interpolation weight was estimated on check data to be )~ = 0.36.", "labels": [], "entities": []}, {"text": "An overall relative reduction of 11% over the trigram model has been achieved.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1 shows the results of the re-estimation tech- nique presented in section 3.4. We achieved a reduc- tion in test-data perplexity bringing an improvement  over a deleted interpolation trigram model whose  perplexity was 167.14 on the same training-test data;  the reduction is statistically significant according to  a sign test.", "labels": [], "entities": []}, {"text": " Table 2: Interpolation with trigram results", "labels": [], "entities": []}]}