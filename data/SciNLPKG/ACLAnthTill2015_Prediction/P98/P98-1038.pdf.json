{"title": [{"text": "PAT-Trees with the Deletion Function as the Learning Device for Linguistic Patterns", "labels": [], "entities": []}], "abstractContent": [{"text": "In this study, a learning device based on the PAT-tree data structures was developed.", "labels": [], "entities": [{"text": "PAT-tree data structures", "start_pos": 46, "end_pos": 70, "type": "DATASET", "confidence": 0.8572385708491007}]}, {"text": "The original PAT-trees were enhanced with the deletion function to emulate human learning competence.", "labels": [], "entities": []}, {"text": "The learning process worked as follows.", "labels": [], "entities": []}, {"text": "The linguistic patterns from the text corpus are inserted into the PAT-tree one by one.", "labels": [], "entities": []}, {"text": "Since the memory was limited, hopefully, the important and new patterns would be retained in the PAT-tree and the old and unimportant patterns would be released from the tree automatically.", "labels": [], "entities": []}, {"text": "The proposed PAT-trees with the deletion function have the following advantages.", "labels": [], "entities": []}, {"text": "1) They are easy to construct and maintain.", "labels": [], "entities": []}, {"text": "2) Any prefix sub-string and its frequency count through PAT-tree can be searched very quickly.", "labels": [], "entities": []}, {"text": "3) The space requirement fora PAT-tree is linear with respect to the size of the input text.", "labels": [], "entities": []}, {"text": "4) The insertion of anew element can be carried out at anytime without being blocked by the memory constraints because the free space is released through the deletion of unimportant elements.", "labels": [], "entities": []}, {"text": "Experiments on learning high frequency bi-grams were carried out under different memory size constraints.", "labels": [], "entities": []}, {"text": "High recall rates were achieved.", "labels": [], "entities": [{"text": "recall", "start_pos": 5, "end_pos": 11, "type": "METRIC", "confidence": 0.9991990923881531}]}, {"text": "The results show that the proposed PAT-trees can be used as on-line learning devices.", "labels": [], "entities": []}], "introductionContent": [{"text": "Human beings remember useful and important information and gradually forget old and unimportant information in order to accommodate new information.", "labels": [], "entities": []}, {"text": "Under the constraint of memory capacity, it is important to have a learning mechanism that utilizes memory to store and to retrieve information efficiently and flexibly without loss of important information.", "labels": [], "entities": []}, {"text": "We don't know how human memory functions exactly, but the issue of creating computers with similar competence is one of the most important problems being studied.", "labels": [], "entities": []}, {"text": "We are especially interested in computer learning of linguistic patterns without the problem of running out of memory.", "labels": [], "entities": [{"text": "computer learning of linguistic patterns", "start_pos": 32, "end_pos": 72, "type": "TASK", "confidence": 0.7295948147773743}]}, {"text": "To implement such a learning device, a data structure, equipped with the following functions, is needed: a) accept and store the on-line input of character/word patterns, b) efficiently access and retrieve stored patterns, c) accept unlimited amounts of data and at the same time retain the most important as well as the most recent input patterns.", "labels": [], "entities": []}, {"text": "To meet the above needs, the PAT-tree data structure was originally considered a possible candidate to start with.", "labels": [], "entities": [{"text": "PAT-tree data structure", "start_pos": 29, "end_pos": 52, "type": "DATASET", "confidence": 0.8204142451286316}]}, {"text": "The original design of the PAT-tree can be traced back to 1968.", "labels": [], "entities": [{"text": "PAT-tree", "start_pos": 27, "end_pos": 35, "type": "DATASET", "confidence": 0.5993379354476929}]}, {"text": "Morrison proposed a data structure called the \"Practical Algorithm to Retrieve Information Coded in Alphanumeric\"(PATRICIA).", "labels": [], "entities": [{"text": "Retrieve Information Coded in Alphanumeric\"(PATRICIA)", "start_pos": 70, "end_pos": 123, "type": "TASK", "confidence": 0.7529971301555634}]}, {"text": "It is a variation of the binary search tree with binary representation of keys.", "labels": [], "entities": []}, {"text": "In 1987, Gonnet introduced semi-infinite strings and stored them into PATRICIA trees.", "labels": [], "entities": []}, {"text": "A PATRICIA tree constructed overall the possible semi-infinite strings of a text is then called a PAT-tree.", "labels": [], "entities": []}, {"text": "Many kinds of searching functions can be easily performed on a PAT-tree, such as prefix searching, range searching, longest repetition searching and soon.", "labels": [], "entities": [{"text": "prefix searching", "start_pos": 81, "end_pos": 97, "type": "TASK", "confidence": 0.7324278354644775}, {"text": "range searching", "start_pos": 99, "end_pos": 114, "type": "TASK", "confidence": 0.6495167464017868}, {"text": "soon", "start_pos": 149, "end_pos": 153, "type": "METRIC", "confidence": 0.9598259329795837}]}, {"text": "A modification of the PAT-tree was done to fit the needs of Chinese processing in 1996 by Hung, in which the finite strings were used instead of semi-infinite strings.", "labels": [], "entities": []}, {"text": "Since finite strings are not unique in a text as semi-infinite strings are, frequency counts are stored in tree nodes.", "labels": [], "entities": []}, {"text": "In addition to its searching functions, the frequencies of any prefix sub-strings can be accessed very easily in the modified PAT-tree.", "labels": [], "entities": []}, {"text": "Hence, statistical evaluations between sub-strings, such as probabilities, conditional probabilities, and mutual information, can be computed.", "labels": [], "entities": []}, {"text": "It is easy to insert new elements into PATtrees, but memory constrains have made them unable to accept unlimited amounts of information, hence limiting their potential use as learning devices.", "labels": [], "entities": []}, {"text": "In reality, only important or representative data should be retained.", "labels": [], "entities": []}, {"text": "Old and unimportant data can be replaced by new data.", "labels": [], "entities": []}, {"text": "Thus, aside from the original PAT-tree, the deletion mechanism was implemented, which allowed memory to be released for the purpose of storing the most recent inputs when the original memory was exhausted.", "labels": [], "entities": []}, {"text": "With this mechanism, the PAT-tree is now enhanced and has the ability to accept unlimited amounts of information.", "labels": [], "entities": []}, {"text": "Once evaluation functions for data importance are obtained, the PAT-tree will have the potential to bean on-line learning device.", "labels": [], "entities": []}, {"text": "We review the original PAT-tree and its properties in section 2.", "labels": [], "entities": []}, {"text": "In section 3,we describe the PAT-tree with deletion in detail.", "labels": [], "entities": []}, {"text": "In section 4, we give the results obtained after different deletion criteria were tested to see how it performed on learning word bi-gram collocations under different sizes of memory.", "labels": [], "entities": []}, {"text": "Some other possible applications and a simple conclusion are given in the last section.", "labels": [], "entities": []}], "datasetContent": [{"text": "Due to the limited memory capacity of a PAT-tree, old and unimportant elements have to be identified and then deleted from the tree in order to accommodate new elements.", "labels": [], "entities": []}, {"text": "Evaluation is based on the following two criteria: a) the oldness of the elements, and b) the importance of the elements.", "labels": [], "entities": []}, {"text": "Evaluation of an element has to be balanced between these criteria.", "labels": [], "entities": []}, {"text": "The oldness of an element is judged by how long the element has resided in the PAT-tree.", "labels": [], "entities": [{"text": "PAT-tree", "start_pos": 79, "end_pos": 87, "type": "DATASET", "confidence": 0.7811605930328369}]}, {"text": "It seems that anew field in each node of a PAT-tree is needed to store the time when the element was inserted.", "labels": [], "entities": []}, {"text": "When the nth element was inserted, the time was n.", "labels": [], "entities": []}, {"text": "The resident element will become old when new elements are gradually inserted into the tree.", "labels": [], "entities": []}, {"text": "However, old elements might become more and more important if they reoccur in the input text.", "labels": [], "entities": []}, {"text": "The frequency count of an element is a simple criterion for measuring the importance of an element.", "labels": [], "entities": []}, {"text": "Of course, different importance measures can be employed, such as mutual information or conditional probability between a prefix and suffix.", "labels": [], "entities": []}, {"text": "Nonetheless, the frequency count is a very simple and useful measurement.", "labels": [], "entities": []}, {"text": "To simplify the matter, a unified criterion is adopted.", "labels": [], "entities": []}, {"text": "Under this criterion no additional storage is needed to register time.", "labels": [], "entities": []}, {"text": "A time lapse will be delayed in order to revisit and evaluate anode, and hopefully, the frequency counts of important elements will be increased during the time lapse.", "labels": [], "entities": []}, {"text": "It is implemented byway of a circular-like array of tree nodes.", "labels": [], "entities": []}, {"text": "A PAT-tree will be constructed by inserting new elements.", "labels": [], "entities": []}, {"text": "The insertion process takes a free node for each element from the array in the increasing order of their indexes until the array is exhausted.", "labels": [], "entities": []}, {"text": "The deletion process will then be triggered.", "labels": [], "entities": []}, {"text": "The evaluation process will scan the elements according to the array index sequence, which is different from the tree order, to find the least important element in the first k elements to delete.", "labels": [], "entities": []}, {"text": "The freed node will be used to store the newly arriving element.", "labels": [], "entities": []}, {"text": "The next position of the current deleted node will be the starting index of the next k nodes for evaluation.", "labels": [], "entities": []}, {"text": "In this way, it is guaranteed that the minimal time lapse to visit the same node will beat least the size of the PAT-tree divided by k.", "labels": [], "entities": []}, {"text": "In section 4, we describe experiments carried out on the learning of high frequency word bigrams.", "labels": [], "entities": []}, {"text": "The above mentioned time lapse and the frequency measurement for importance were used as the evaluation criteria to determine the learning performance under different memory constraints.", "labels": [], "entities": []}, {"text": "The ideal cases were obtained using a procedure in which the input bi-grams were pre-sorted according to their frequency counts.", "labels": [], "entities": []}, {"text": "The bi-grams were inserted in descending order of their frequencies.", "labels": [], "entities": []}, {"text": "Each bi-gram was inserted n times, where n was its frequency.", "labels": [], "entities": []}, {"text": "According to the deletion criterion, under such an ideal case, the PAT-tree will retain as many high frequency bi-grams as it can.", "labels": [], "entities": []}, {"text": "The deletion process worked as follows.", "labels": [], "entities": []}, {"text": "A fixed number of nodes were checked starting from the last modified node, and the one with the minimal frequency was chosen for deletion.", "labels": [], "entities": []}, {"text": "Since the pointer was moving forward along the index of the array, a time lapse was guaranteed to revisit anode.", "labels": [], "entities": []}, {"text": "Hopefully the high frequency bi-grams would reoccur during the time lapse.", "labels": [], "entities": []}, {"text": "Different forward steps, such as, and 300, were tested, and the results show that deletion of the least important elements within 200 nodes led to the best result.", "labels": [], "entities": []}, {"text": "However the performance results of different steps were not very different..2, it is seen that the recall rates of the important bi-grams under the normal learning process were satisfactory.", "labels": [], "entities": [{"text": "recall", "start_pos": 99, "end_pos": 105, "type": "METRIC", "confidence": 0.9993502497673035}]}, {"text": "Each row denotes the recall rates of a bi-gram greater than the frequency under different sizes of PAT-tree.", "labels": [], "entities": [{"text": "recall rates", "start_pos": 21, "end_pos": 33, "type": "METRIC", "confidence": 0.9852477610111237}]}, {"text": "For instance, the row 10 in.1 shows that the bi-grams which had the frequency greater than 20, were retained as follows: 85.46%, 97.02%, 99.63%, 99.95%, 100%, 100%, 100%, and 100%, when the size of the PAT-tree was 1/64, 2/64 .....", "labels": [], "entities": []}, {"text": "8/64 of the total number of the different bi-grams, respectively.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 4.1 Finding the minimum of the next 200 nodes.", "labels": [], "entities": []}, {"text": " Table 4.2 Input bi-grams in descending order of their  aencies.", "labels": [], "entities": [{"text": "aencies", "start_pos": 56, "end_pos": 63, "type": "METRIC", "confidence": 0.9948452711105347}]}]}