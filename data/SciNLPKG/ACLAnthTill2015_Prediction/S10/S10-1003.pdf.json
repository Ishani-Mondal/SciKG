{"title": [{"text": "SemEval-2010 Task 3: Cross-Lingual Word Sense Disambiguation", "labels": [], "entities": [{"text": "SemEval-2010 Task", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.8571266531944275}, {"text": "Cross-Lingual Word Sense Disambiguation", "start_pos": 21, "end_pos": 60, "type": "TASK", "confidence": 0.7265269532799721}]}], "abstractContent": [{"text": "The goal of this task is to evaluate the feasibility of multilingual WSD on a newly developed multilingual lexical sample data set.", "labels": [], "entities": [{"text": "WSD", "start_pos": 69, "end_pos": 72, "type": "TASK", "confidence": 0.7884202003479004}, {"text": "multilingual lexical sample data set", "start_pos": 94, "end_pos": 130, "type": "DATASET", "confidence": 0.7402644634246827}]}, {"text": "Participants were asked to automatically determine the contextually appropriate translation of a given English noun in five languages, viz.", "labels": [], "entities": []}, {"text": "Dutch, German, Italian, Spanish and French.", "labels": [], "entities": []}, {"text": "This paper reports on the sixteen submissions from the five different participating teams.", "labels": [], "entities": []}], "introductionContent": [{"text": "Word Sense Disambiguation, the task of selecting the correct sense of an ambiguous word in a given context, is a well-researched NLP problem (see for example and), largely boosted by the various Senseval and SemEval editions.", "labels": [], "entities": [{"text": "Word Sense Disambiguation, the task of selecting the correct sense of an ambiguous word in a given context", "start_pos": 0, "end_pos": 106, "type": "Description", "confidence": 0.7003260317601656}]}, {"text": "The SemEval-2010 Cross-lingual Word Sense Disambiguation task focuses on two bottlenecks in current WSD research, namely the scarcity of sense inventories and sense-tagged corpora (especially for languages other than English) and the growing tendency to evaluate the performance of WSD systems in areal application such as machine translation and cross-language information retrieval (see for example).", "labels": [], "entities": [{"text": "SemEval-2010 Cross-lingual Word Sense Disambiguation task", "start_pos": 4, "end_pos": 61, "type": "TASK", "confidence": 0.7437800566355387}, {"text": "WSD", "start_pos": 100, "end_pos": 103, "type": "TASK", "confidence": 0.956561267375946}, {"text": "machine translation", "start_pos": 323, "end_pos": 342, "type": "TASK", "confidence": 0.7985472977161407}, {"text": "cross-language information retrieval", "start_pos": 347, "end_pos": 383, "type": "TASK", "confidence": 0.643672376871109}]}, {"text": "The Cross-lingual WSD task aims at the development of a multilingual data set to test the feasibility of multilingual WSD.", "labels": [], "entities": [{"text": "Cross-lingual WSD task", "start_pos": 4, "end_pos": 26, "type": "TASK", "confidence": 0.6905085643132528}]}, {"text": "Many studies have already shown the validity of this crosslingual evidence idea (, but until now no benchmark data sets have been available.", "labels": [], "entities": []}, {"text": "For the SemEval-2010 competition we developed (i) a sense inventory in which the sense distinctions were extracted from the multilingual corpus Europarl 1 and (ii) a data set in which the ambiguous words were annotated with the senses from the multilingual sense inventory.", "labels": [], "entities": [{"text": "Europarl 1", "start_pos": 144, "end_pos": 154, "type": "DATASET", "confidence": 0.8562014102935791}]}, {"text": "The Cross-Lingual WSD task is a lexical sample task for English nouns, in which the word senses are made up of the translations in five languages, viz.", "labels": [], "entities": [{"text": "Cross-Lingual WSD task", "start_pos": 4, "end_pos": 26, "type": "TASK", "confidence": 0.6470244725545248}]}, {"text": "Dutch, French, Italian, Spanish and German.", "labels": [], "entities": []}, {"text": "Both the sense inventory and the annotated data set were constructed fora sample of 25 nouns.", "labels": [], "entities": []}, {"text": "The data set was divided into atrial set of 5 ambiguous nouns and a test set of 20 nouns.", "labels": [], "entities": []}, {"text": "The participants had to automatically determine the contextually appropriate translation fora given English noun in each or a subset of the five target languages.", "labels": [], "entities": []}, {"text": "Only translations present in Europarl were considered as valid translations.", "labels": [], "entities": [{"text": "Europarl", "start_pos": 29, "end_pos": 37, "type": "DATASET", "confidence": 0.9857444167137146}]}, {"text": "The remainder of this article is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 focuses on the task description and gives a short overview of the construction of the sense inventory and the annotation of the benchmark data set with the senses from the multilingual sense inventory.", "labels": [], "entities": []}, {"text": "Section 3 clarifies the scoring metrics and presents two frequency-based baselines.", "labels": [], "entities": []}, {"text": "The participating systems are presented in Section 4, while the results of the task are discussed in Section 5.", "labels": [], "entities": []}, {"text": "Section 6 concludes this paper.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 3: Best System Results", "labels": [], "entities": []}, {"text": " Table 4: Out-of-five System Results", "labels": [], "entities": []}]}