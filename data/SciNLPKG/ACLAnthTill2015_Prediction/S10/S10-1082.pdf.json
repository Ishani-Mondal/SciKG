{"title": [{"text": "KSU KDD: Word Sense Induction by Clustering in Topic Space", "labels": [], "entities": [{"text": "KSU KDD", "start_pos": 0, "end_pos": 7, "type": "DATASET", "confidence": 0.7085979282855988}, {"text": "Word Sense Induction", "start_pos": 9, "end_pos": 29, "type": "TASK", "confidence": 0.672104686498642}]}], "abstractContent": [{"text": "We describe our language-independent un-supervised word sense induction system.", "labels": [], "entities": [{"text": "language-independent un-supervised word sense induction", "start_pos": 16, "end_pos": 71, "type": "TASK", "confidence": 0.6333184897899627}]}, {"text": "This system only uses topic features to cluster different word senses in their global context topic space.", "labels": [], "entities": []}, {"text": "Using unlabeled data, this system trains a latent Dirichlet allocation (LDA) topic model then uses it to infer the topics distribution of the test instances.", "labels": [], "entities": []}, {"text": "By clustering these topics distributions in their topic space we cluster them into different senses.", "labels": [], "entities": []}, {"text": "Our hypothesis is that closeness in topic space reflects similarity between different word senses.", "labels": [], "entities": []}, {"text": "This system participated in SemEval-2 word sense induction and disambiguation task and achieved the second highest V-measure score among all other systems.", "labels": [], "entities": [{"text": "SemEval-2 word sense induction", "start_pos": 28, "end_pos": 58, "type": "TASK", "confidence": 0.857817992568016}]}], "introductionContent": [{"text": "Ambiguity of meaning is inherent in natural language because the deliverer of words tries to minimize the size of the vocabulary set he uses.", "labels": [], "entities": []}, {"text": "Therefore, a sizable portion of this vocabulary is polysemous and the intended meaning of such words can be encoded in their context.", "labels": [], "entities": []}, {"text": "Due to the knowledge acquisition bottleneck problem and scarcity in training data, unsupervised corpus based approaches could be favored over supervised ones in word sense disambiguation (WSD) tasks.", "labels": [], "entities": [{"text": "knowledge acquisition", "start_pos": 11, "end_pos": 32, "type": "TASK", "confidence": 0.7457078397274017}, {"text": "word sense disambiguation (WSD) tasks", "start_pos": 161, "end_pos": 198, "type": "TASK", "confidence": 0.8079878560134343}]}, {"text": "Similar efforts in this area include work by) in which they use latent Dirichlet allocation (LDA) topic models to extract the global context topic and use it as a feature along other baseline features.", "labels": [], "entities": []}, {"text": "Another technique uses clustering based approach with WordNet as an external resource for disambiguation without relying on training data.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 54, "end_pos": 61, "type": "DATASET", "confidence": 0.9519564509391785}]}, {"text": "To disambiguate a polysemous word in a text document, we use the document topic distribution to represent its context.", "labels": [], "entities": []}, {"text": "A document topic distribution is the probabilistic distribution of a document over a set of topics.", "labels": [], "entities": []}, {"text": "The assumption is that: given two word senses and the topic distribution of their context, the closeness between these two topic distributions in their topic space is an indication of the similarity between those two senses.", "labels": [], "entities": []}, {"text": "Our motivation behind building this system was the observation that the context of a polysemous word helps determining its sense to some degree.", "labels": [], "entities": []}, {"text": "In our word sense induction (WSI) system, we use LDA to create a topic model for the given corpus and use it to infer the topic distribution of the documents containing the ambiguous words.", "labels": [], "entities": [{"text": "word sense induction (WSI)", "start_pos": 7, "end_pos": 33, "type": "TASK", "confidence": 0.7750600427389145}]}, {"text": "This paper describes our WSI system which participated in SemEval-2 word sense induction and disambiguation task).", "labels": [], "entities": [{"text": "SemEval-2 word sense induction", "start_pos": 58, "end_pos": 88, "type": "TASK", "confidence": 0.8658051788806915}]}], "datasetContent": [{"text": "We use the same unsupervised evaluation measures used in SemEval-2).", "labels": [], "entities": []}, {"text": "These measures do not require descriptive The V-measure is used for unsupervised evaluation.", "labels": [], "entities": []}, {"text": "It is the harmonic mean of the homogeneity and completeness.", "labels": [], "entities": []}, {"text": "Homogeneity is a measure of the degree that each formed cluster consists of data points that belong to a single gold standard (GS) class as defined below.", "labels": [], "entities": []}, {"text": "1 http://mallet.cs.umass.edu Where H() is an entropy function, C and GS refer to cluster and class sizes, respectively.", "labels": [], "entities": []}, {"text": "N is the number of data points, a ij are data points of class GS i that belong to cluster C j . On the other hand, completeness measures the degree that each class consists of data points that belong to a single cluster.", "labels": [], "entities": []}, {"text": "It is defined as follows.", "labels": [], "entities": []}, {"text": "Homogeneity and completeness can be seen as entropy based measures of precision and recall, respectively.", "labels": [], "entities": [{"text": "precision", "start_pos": 70, "end_pos": 79, "type": "METRIC", "confidence": 0.9992903470993042}, {"text": "recall", "start_pos": 84, "end_pos": 90, "type": "METRIC", "confidence": 0.9986159801483154}]}, {"text": "The V-measure has a range of 0 (worst performance) to 1, inclusive.", "labels": [], "entities": []}, {"text": "The other evaluation measure is the F-score, which is the harmonic mean of precision and recall.", "labels": [], "entities": [{"text": "F-score", "start_pos": 36, "end_pos": 43, "type": "METRIC", "confidence": 0.9986364245414734}, {"text": "precision", "start_pos": 75, "end_pos": 84, "type": "METRIC", "confidence": 0.9989816546440125}, {"text": "recall", "start_pos": 89, "end_pos": 95, "type": "METRIC", "confidence": 0.9938587546348572}]}, {"text": "It has a range of 0 to 1 (best performance), inclusive.", "labels": [], "entities": []}, {"text": "The WSI system described earlier was tested on SemEval-1 WSI task (task 2) data (65 verbs, 35 nouns), and participated in the same task in SemEval-2 (task 14) (50 verbs, 50 nouns).", "labels": [], "entities": [{"text": "SemEval-1 WSI task (task 2) data", "start_pos": 47, "end_pos": 79, "type": "DATASET", "confidence": 0.573668759316206}]}, {"text": "The sense induction process was the same in both cases.", "labels": [], "entities": [{"text": "sense induction", "start_pos": 4, "end_pos": 19, "type": "TASK", "confidence": 0.8403221964836121}]}, {"text": "Before running our main experiments, we wanted to see how the number of topics K used in the topic model could affect the performance of our system.", "labels": [], "entities": []}, {"text": "We tested our WSI system on SemEval-1 data using different K values as shown in.", "labels": [], "entities": [{"text": "SemEval-1 data", "start_pos": 28, "end_pos": 42, "type": "DATASET", "confidence": 0.7588099241256714}]}, {"text": "We found that the V-measure and F-score values increase with increasing K, as more dimensions are added to the topic space, the different senses in this K-dimensional space unfold.", "labels": [], "entities": [{"text": "F-score", "start_pos": 32, "end_pos": 39, "type": "METRIC", "confidence": 0.9915270209312439}]}, {"text": "This trend stops at a value of K = 400 in a sign to the limited vocabulary of the training data.", "labels": [], "entities": [{"text": "K", "start_pos": 31, "end_pos": 32, "type": "METRIC", "confidence": 0.9421952962875366}]}, {"text": "This K value is used in all other experiments.", "labels": [], "entities": [{"text": "K", "start_pos": 5, "end_pos": 6, "type": "METRIC", "confidence": 0.9633523225784302}]}, {"text": "Next, we evaluated the performance of our system on SemEval-1 WSI task data.", "labels": [], "entities": [{"text": "SemEval-1 WSI task data", "start_pos": 52, "end_pos": 75, "type": "DATASET", "confidence": 0.6398079693317413}]}, {"text": "Since no training data was provided for this task, we used an unannotated version of the test instances to create the LDA topic model.", "labels": [], "entities": []}, {"text": "For each target word (verb or noun), we trained the topic model on its given test  instances.", "labels": [], "entities": []}, {"text": "Then we used the generated model's inferencer to find the topics distribution of each one of them.", "labels": [], "entities": []}, {"text": "These distributions are then clustered in the topic space using the K-means algorithm and the cosine similarity measure was used to evaluate the distances between these distributions.", "labels": [], "entities": [{"text": "cosine similarity measure", "start_pos": 94, "end_pos": 119, "type": "METRIC", "confidence": 0.737536092599233}]}, {"text": "The results of this experiment are shown in.", "labels": [], "entities": []}, {"text": "Our WSI system took part in the main SemEval-2 WSI task (task 14).", "labels": [], "entities": [{"text": "SemEval-2 WSI task", "start_pos": 37, "end_pos": 55, "type": "TASK", "confidence": 0.7386869192123413}]}, {"text": "In the unsupervised evaluation, our system had the second highest V-measure value of 15.7 for all words 2 . A breakdown of the obtained V-measure and F-scores is shown in.", "labels": [], "entities": [{"text": "F-scores", "start_pos": 150, "end_pos": 158, "type": "METRIC", "confidence": 0.978281557559967}]}, {"text": "To analyze the performance of the system, we examined the clustering of the target noun word \"promotion\" to different senses by our system.", "labels": [], "entities": [{"text": "clustering of the target noun word \"promotion\"", "start_pos": 58, "end_pos": 104, "type": "TASK", "confidence": 0.688554177681605}]}, {"text": "We compared it to the GS classes of this word in the answer key provided by the task organizers.", "labels": [], "entities": []}, {"text": "For a more objective comparison, we ran the K-means clustering algorithm with K equal to the number of GS classes.", "labels": [], "entities": []}, {"text": "Even though the number of formed clusters affects the performance of the system, we assume that the number of senses is known in this analysis.", "labels": [], "entities": []}, {"text": "We focus on the ability of the algorithm to cluster similar senses together.", "labels": [], "entities": []}, {"text": "A graphical comparison is given in.", "labels": [], "entities": []}, {"text": "The target noun word \"promotion\" has 27 instances and four senses.", "labels": [], "entities": []}, {"text": "The lower four rectangles in represent the four different GS classes, and the upper four rectangles represent the four clusters created by our system.", "labels": [], "entities": []}, {"text": "Three of the four instances representing a job \"promotion\" () were clustered together, but the fourth one was clustered in a different class due to terms like \"driving,\" \"troops,\" and \"hostile\" in its context.", "labels": [], "entities": []}, {"text": "The offer sense of \"promotion\" () was mainly split between two clusters, cluster 2 which most of its instances has mentions of numbers and monetary units, and cluster 4 which describes business and labor from an employee's eye.", "labels": [], "entities": []}, {"text": "The 13 instances of the third class which carry the sense encourage of the word promotion () are distributed among the four different clusters de-  pending on other topic words that classified them as either belonging to cluster 4 (encouragement in business), cluster 3 (encouragement in conflict or war context), cluster 2 (numbers and money context), or cluster 1 (otherwise).", "labels": [], "entities": []}, {"text": "We can see that the topic model is unable to detect and extract topic words for the \"encourage\" sense of the word.", "labels": [], "entities": []}, {"text": "Finally, due to the lack of enough training instances of the sense of a promotional issue of a newspaper (), the topic model inferencer clustered it in the numbers and monetary cluster because it was rich in numbers.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Effect of varying the number of topics K  on performance", "labels": [], "entities": []}, {"text": " Table 2: V-measure and F-score on SemEval-1  All Verbs Nouns  V-measure 8.4  8.0  8.7  F-score  63.9  56.8  69.0", "labels": [], "entities": [{"text": "F-score", "start_pos": 24, "end_pos": 31, "type": "METRIC", "confidence": 0.9922683835029602}]}, {"text": " Table 3: V-measure and F-score on SemEval-2  All Verbs Nouns  V-measure 15.7  12.4  18.0  F-score  36.9  54.7  24.6", "labels": [], "entities": [{"text": "F-score", "start_pos": 24, "end_pos": 31, "type": "METRIC", "confidence": 0.9946553707122803}, {"text": "F-score", "start_pos": 91, "end_pos": 98, "type": "METRIC", "confidence": 0.7051980495452881}]}]}