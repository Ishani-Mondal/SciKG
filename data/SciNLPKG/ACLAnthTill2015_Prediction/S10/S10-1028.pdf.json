{"title": [{"text": "OWNS: Cross-lingual Word Sense Disambiguation Using Weighted Overlap Counts and Wordnet Based Similarity Measures", "labels": [], "entities": [{"text": "OWNS", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.7879204750061035}, {"text": "Cross-lingual Word Sense Disambiguation", "start_pos": 6, "end_pos": 45, "type": "TASK", "confidence": 0.703568197786808}, {"text": "Wordnet Based Similarity Measures", "start_pos": 80, "end_pos": 113, "type": "TASK", "confidence": 0.4896857216954231}]}], "abstractContent": [{"text": "We report here our work on English French Cross-lingual Word Sense Disam-biguation where the task is to find the best French translation fora target English word depending on the context in which it is used.", "labels": [], "entities": [{"text": "Cross-lingual Word Sense Disam-biguation", "start_pos": 42, "end_pos": 82, "type": "TASK", "confidence": 0.6860325932502747}]}, {"text": "Our approach relies on identifying the nearest neighbors of the test sentence from the training data using a pairwise similarity measure.", "labels": [], "entities": []}, {"text": "The proposed measure finds the affinity between two sentences by calculating a weighted sum of the word overlap and the semantic overlap between them.", "labels": [], "entities": []}, {"text": "The semantic overlap is calculated using standard Wordnet Similarity measures.", "labels": [], "entities": []}, {"text": "Once the nearest neighbors have been identified, the best translation is found by taking a majority vote over the French translations of the nearest neighbors.", "labels": [], "entities": []}], "introductionContent": [{"text": "Cross Language Word Sense Disambiguation (CL-WSD) is the problem of finding the correct target language translation of a word given the context in which it appears in the source language.", "labels": [], "entities": [{"text": "Cross Language Word Sense Disambiguation (CL-WSD)", "start_pos": 0, "end_pos": 49, "type": "TASK", "confidence": 0.7275609560310841}]}, {"text": "In many cases a full disambiguation may not be necessary as it is common for different meanings of a word to have the same translation.", "labels": [], "entities": []}, {"text": "This is especially true in cases where the sense distinction is very fine and two or more senses of a word are closely related.", "labels": [], "entities": []}, {"text": "For example, the two senses of the word letter, namely, \"formal document' and \"written/printed message\" have the same French translation \"lettre\".", "labels": [], "entities": []}, {"text": "The problem is thus reduced to distinguishing between the coarser senses of a word and ignoring the finer sense distinctions which is known to be a common cause of errors in conventional WSD.", "labels": [], "entities": [{"text": "WSD", "start_pos": 187, "end_pos": 190, "type": "TASK", "confidence": 0.9253050088882446}]}, {"text": "CL-WSD can thus be seen as a slightly relaxed version of the conventional WSD problem.", "labels": [], "entities": [{"text": "WSD", "start_pos": 74, "end_pos": 77, "type": "TASK", "confidence": 0.887843132019043}]}, {"text": "However, CL-WSD has its own set of challenges as described below.", "labels": [], "entities": [{"text": "CL-WSD", "start_pos": 9, "end_pos": 15, "type": "DATASET", "confidence": 0.879647433757782}]}, {"text": "The translations learnt from a parallel corpus may contain a lot of errors.", "labels": [], "entities": []}, {"text": "Such errors are hard to avoid due to the inherent noise associated with statistical alignment models.", "labels": [], "entities": []}, {"text": "This problem can be overcome if good bilingual dictionaries are available between the source and target language.", "labels": [], "entities": []}, {"text": "EuroWordNet 1 can be used to construct such a bilingual dictionary between English and French but it is not freely available.", "labels": [], "entities": [{"text": "EuroWordNet 1", "start_pos": 0, "end_pos": 13, "type": "DATASET", "confidence": 0.9714145064353943}]}, {"text": "Instead, in this work, we use a noisy statistical dictionary learnt from the Europarl parallel corpus) which is freely downloadable.", "labels": [], "entities": [{"text": "Europarl parallel corpus", "start_pos": 77, "end_pos": 101, "type": "DATASET", "confidence": 0.9573687513669332}]}, {"text": "Another challenge arises in the form of matching the lexical choice of a native speaker.", "labels": [], "entities": []}, {"text": "For example, the word coach (as in, vehicle) may get translated differently as autocar, autobus or bus even when it appears in very similar contexts.", "labels": [], "entities": []}, {"text": "Such decisions depend on the native speaker's intuition and are very difficult fora machine to replicate due to their inconsistent usage in a parallel training corpus.", "labels": [], "entities": []}, {"text": "The above challenges are indeed hard to overcome, especially in an unsupervised setting, as evidenced by the lower accuracies reported by all systems participating in the SEMEVAL Shared Task on Cross-lingual Word Sense Disambiguation (.", "labels": [], "entities": [{"text": "accuracies", "start_pos": 115, "end_pos": 125, "type": "METRIC", "confidence": 0.9885455965995789}, {"text": "SEMEVAL Shared Task on Cross-lingual Word Sense Disambiguation", "start_pos": 171, "end_pos": 233, "type": "TASK", "confidence": 0.5795555859804153}]}, {"text": "Our system ranked second in the English French task (in the out-of-five evaluation).", "labels": [], "entities": [{"text": "English French task", "start_pos": 32, "end_pos": 51, "type": "DATASET", "confidence": 0.7777044773101807}]}, {"text": "Even though its average performance was lower than the baseline by 3% it performed better than the baseline for 12 out of the 20 target nouns.", "labels": [], "entities": []}, {"text": "Our approach identifies the top-five translations of a word by taking a majority vote over the translations appearing in the nearest neighbors of the test sentence as found in the training data.", "labels": [], "entities": []}, {"text": "We use a pairwise similarity measure which finds the affinity between two sentences by calculating a weighted sum of the word overlap and the semantic overlap between them.", "labels": [], "entities": []}, {"text": "The semantic overlap is calculated using standard Wordnet Similarity measures.", "labels": [], "entities": []}, {"text": "The remainder of this paper is organized as follows.", "labels": [], "entities": []}, {"text": "In section 2 we describe related work on WSD.", "labels": [], "entities": [{"text": "WSD", "start_pos": 41, "end_pos": 44, "type": "TASK", "confidence": 0.964004397392273}]}, {"text": "In section 3 we describe our approach.", "labels": [], "entities": []}, {"text": "In Section 4 we present the results followed by conclusion in section 5.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Performance of our system in best evalu- ation", "labels": [], "entities": []}, {"text": " Table 2: Performance of our system in oof evalua- tion", "labels": [], "entities": []}]}