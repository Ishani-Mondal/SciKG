{"title": [{"text": "SemEval-2010 Task 9: The Interpretation of Noun Compounds Using Paraphrasing Verbs and Prepositions", "labels": [], "entities": []}], "abstractContent": [{"text": "Previous research has shown that the meaning of many noun-noun compounds N 1 N 2 can be approximated reasonably well by paraphrasing clauses of the form 'N 2 that.", "labels": [], "entities": []}, {"text": ".. N 1 ', where '..", "labels": [], "entities": []}, {"text": "' stands fora verb with or without a preposition.", "labels": [], "entities": []}, {"text": "For example , malaria mosquito is a 'mosquito that carries malaria'.", "labels": [], "entities": []}, {"text": "Evaluating the quality of such paraphrases is the theme of Task 9 at SemEval-2010.", "labels": [], "entities": []}, {"text": "This paper describes some background, the task definition, the process of data collection and the task results.", "labels": [], "entities": []}, {"text": "We also venture a few general conclusions before the participating teams present their systems at the SemEval-2010 workshop.", "labels": [], "entities": []}, {"text": "There were 5 teams who submitted 7 systems .", "labels": [], "entities": []}], "introductionContent": [{"text": "Noun compounds (NCs) are sequences of two or more nouns that act as a single noun, 1 e.g., stem cell, stem cell research, stem cell research organization, etc.", "labels": [], "entities": []}, {"text": "observe that NCs pose syntactic and semantic challenges for three basic reasons: (1) the compounding process is extremely productive in English; (2) the semantic relation between the head and the modifier is implicit; (3) the interpretation can be influenced by contextual and pragmatic factors.", "labels": [], "entities": []}, {"text": "Corpus studies have shown that while NCs are very common in English, their frequency distribution follows a Zipfian or power-law distribution and the majority of NCs encountered will be rare types.", "labels": [], "entities": []}, {"text": "As a consequence, Natural Language Processing (NLP) We follow the definition in applications cannot afford either to ignore NCs or to assume that they can be handled by relying on a dictionary or other static resource.", "labels": [], "entities": []}, {"text": "Trouble with lexical resources for NCs notwithstanding, NC semantics plays a central role in complex knowledge discovery and applications, including but not limited to Question Answering (QA), Machine Translation (MT), and Information Retrieval (IR).", "labels": [], "entities": [{"text": "knowledge discovery", "start_pos": 101, "end_pos": 120, "type": "TASK", "confidence": 0.779395341873169}, {"text": "Question Answering (QA)", "start_pos": 168, "end_pos": 191, "type": "TASK", "confidence": 0.8550403475761413}, {"text": "Machine Translation (MT)", "start_pos": 193, "end_pos": 217, "type": "TASK", "confidence": 0.8612903714179992}, {"text": "Information Retrieval (IR)", "start_pos": 223, "end_pos": 249, "type": "TASK", "confidence": 0.8494763016700745}]}, {"text": "For example, knowing the (implicit) semantic relation between the NC components can help rank and refine queries in QA and IR, or select promising translation pairs in MT).", "labels": [], "entities": []}, {"text": "Thus, robust semantic interpretation of NCs should be of much help in broad-coverage semantic processing.", "labels": [], "entities": [{"text": "semantic interpretation of NCs", "start_pos": 13, "end_pos": 43, "type": "TASK", "confidence": 0.7785181999206543}, {"text": "broad-coverage semantic processing", "start_pos": 70, "end_pos": 104, "type": "TASK", "confidence": 0.7563358942667643}]}, {"text": "Proposed approaches to modelling NC semantics have used semantic similarity) and paraphrasing.", "labels": [], "entities": []}, {"text": "The former body of work seeks to measure the similarity between known and unseen NCs by considering various features, usually context-related.", "labels": [], "entities": []}, {"text": "In contrast, the latter group uses verb semantics to interpret NCs directly, e.g., olive oil as 'oil that is extracted from olive(s)', drug death as 'death that is caused by drug(s)', flu shot as a 'shot that prevents flu'.", "labels": [], "entities": []}, {"text": "The growing popularity -and expected direct utility -of paraphrase-based NC semantics has encouraged us to propose an evaluation exercise for the 2010 edition of SemEval.", "labels": [], "entities": []}, {"text": "This paper gives a bird's-eye view of the task.", "labels": [], "entities": []}, {"text": "Section 2 presents its objective, data, data collection, and evaluation method.", "labels": [], "entities": [{"text": "data collection", "start_pos": 40, "end_pos": 55, "type": "TASK", "confidence": 0.7633479535579681}]}, {"text": "Section 3 lists the participating teams.", "labels": [], "entities": []}, {"text": "Section 4 shows the results and our analysis.", "labels": [], "entities": []}, {"text": "In Section 5, we sum up our experience so far.", "labels": [], "entities": []}], "datasetContent": [{"text": "Following Nakov (2008b), we took advantage of the Amazon Mechanical Turk 2 (MTurk) to acquire paraphrasing verbs from human annotators.", "labels": [], "entities": [{"text": "Amazon Mechanical Turk 2 (MTurk)", "start_pos": 50, "end_pos": 82, "type": "DATASET", "confidence": 0.9189584170069013}]}, {"text": "The service offers inexpensive access to subjects for tasks which require human intelligence.", "labels": [], "entities": []}, {"text": "Its API allows a computer program to run tasks easily and collate the subjects' responses.", "labels": [], "entities": []}, {"text": "MTurk is becoming a popular means of eliciting and collecting linguistic intuitions for NLP research; see for an overview and a further discussion.", "labels": [], "entities": [{"text": "MTurk", "start_pos": 0, "end_pos": 5, "type": "DATASET", "confidence": 0.8050841093063354}]}, {"text": "Even though we recruited human subjects, whom we required to take a qualification test, 3 data collection was time-consuming since many annotators did not follow the instructions.", "labels": [], "entities": [{"text": "3 data collection", "start_pos": 88, "end_pos": 105, "type": "TASK", "confidence": 0.7668560942014059}]}, {"text": "We had to monitor their progress and to send them timely messages, pointing out mistakes.", "labels": [], "entities": []}, {"text": "Although the MTurk service allows task owners to accept or reject individual submissions, rejection was the last resort since it has the triply unpleasant effect of (1) denying the worker her fee, (2) negatively affecting her rating, and (3) lowering our rating as a requester.", "labels": [], "entities": []}, {"text": "We thus chose to try and educate our workers \"on the fly\".", "labels": [], "entities": []}, {"text": "Even so, we ended up with many examples which we had to correct manually by labor-intensive post-processing.", "labels": [], "entities": []}, {"text": "The flaws were not different from those already described by.", "labels": [], "entities": []}, {"text": "Post-editing was also necessary to lemmatize the paraphrasing verbs systematically.", "labels": [], "entities": []}, {"text": "The test file has a similar format, except that the frequency is not included and the paraphrases for each noun compound appear in random order: ...", "labels": [], "entities": []}, {"text": "chest pain originate chest pain start in chest pain descend in chest pain be in ...", "labels": [], "entities": []}, {"text": "All evaluation was performed by computing an appropriate measure of similarity/correlation between system predictions and the compiled judgements of the human annotators.", "labels": [], "entities": [{"text": "similarity", "start_pos": 68, "end_pos": 78, "type": "METRIC", "confidence": 0.9684887528419495}]}, {"text": "We did it on a compound-bycompound basis and averaged overall compounds in the test dataset.", "labels": [], "entities": []}, {"text": "Section 4 shows results for three measures: Spearman rank correlation, Pearson correlation, and cosine similarity.", "labels": [], "entities": [{"text": "Spearman rank correlation", "start_pos": 44, "end_pos": 69, "type": "METRIC", "confidence": 0.626177042722702}, {"text": "Pearson correlation", "start_pos": 71, "end_pos": 90, "type": "METRIC", "confidence": 0.9370712339878082}]}, {"text": "Spearman Rank Correlation (\u03c1) was adopted as the official evaluation measure for the competition.", "labels": [], "entities": [{"text": "Spearman Rank Correlation (\u03c1)", "start_pos": 0, "end_pos": 29, "type": "METRIC", "confidence": 0.8265525450309118}]}, {"text": "As a rank correlation statistic, it does not use the numerical values of the predictions or human judgements, only their relative ordering encoded as integer ranks.", "labels": [], "entities": []}, {"text": "For a sample of n items ranked by two methods x and y, the rank correlation \u03c1 is calculated as follows: where xi , y i are the ranks given by x and y to the ith item, respectively.", "labels": [], "entities": [{"text": "rank correlation \u03c1", "start_pos": 59, "end_pos": 77, "type": "METRIC", "confidence": 0.8811079859733582}]}, {"text": "The value of \u03c1 ranges be- For non-negative data, the cosine similarity takes values between 0.0 and 1.0.", "labels": [], "entities": [{"text": "cosine similarity", "start_pos": 53, "end_pos": 70, "type": "METRIC", "confidence": 0.7493017613887787}]}, {"text": "Pearson's r can be viewed as aversion of the cosine similarity which performs centering on x and y.", "labels": [], "entities": []}, {"text": "Baseline: To help interpret these evaluation mea-  summing the frequencies for all compounds in the training dataset, and the paraphrases for the test examples were scored according to this distribution.", "labels": [], "entities": []}, {"text": "Note that this baseline entirely ignores the identity of the nouns in the compound.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Statistics about the the training/test datasets. Shown are the total number of verbs proposed as  well as the minimum, maximum and average number of paraphrasing verb types/tokens per compound.", "labels": [], "entities": []}, {"text": " Table 3: Evaluation results for SemEval-2010 Task 9 (* denotes a late submission).", "labels": [], "entities": [{"text": "SemEval-2010 Task 9", "start_pos": 33, "end_pos": 52, "type": "TASK", "confidence": 0.8866846164067587}]}]}