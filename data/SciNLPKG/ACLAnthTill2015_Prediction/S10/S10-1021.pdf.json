{"title": [{"text": "BART: A Multilingual Anaphora Resolution System", "labels": [], "entities": [{"text": "BART", "start_pos": 0, "end_pos": 4, "type": "TASK", "confidence": 0.9228519797325134}, {"text": "Multilingual Anaphora Resolution", "start_pos": 8, "end_pos": 40, "type": "TASK", "confidence": 0.669921338558197}]}], "abstractContent": [{"text": "BART (Versley et al., 2008) is a highly modular toolkit for coreference resolution that supports state-of-the-art statistical approaches and enables efficient feature engineering.", "labels": [], "entities": [{"text": "BART", "start_pos": 0, "end_pos": 4, "type": "METRIC", "confidence": 0.6969805955886841}, {"text": "coreference resolution", "start_pos": 60, "end_pos": 82, "type": "TASK", "confidence": 0.9561003148555756}]}, {"text": "For the SemEval task 1 on Coreference Resolution , BART runs have been submitted for Ger-man, English, and Italian.", "labels": [], "entities": [{"text": "SemEval task", "start_pos": 8, "end_pos": 20, "type": "TASK", "confidence": 0.917312353849411}, {"text": "Coreference Resolution", "start_pos": 26, "end_pos": 48, "type": "TASK", "confidence": 0.8836564719676971}, {"text": "BART", "start_pos": 51, "end_pos": 55, "type": "METRIC", "confidence": 0.8565487861633301}]}, {"text": "BART relies on a maximum entropy-based classifier for pairs of mentions.", "labels": [], "entities": [{"text": "BART", "start_pos": 0, "end_pos": 4, "type": "TASK", "confidence": 0.756726086139679}]}, {"text": "A novel entity-mention approach based on Semantic Trees is at the moment only supported for English.", "labels": [], "entities": []}], "introductionContent": [{"text": "This paper presents a multilingual coreference resolution system based on BART (.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 35, "end_pos": 57, "type": "TASK", "confidence": 0.7646546959877014}, {"text": "BART", "start_pos": 74, "end_pos": 78, "type": "DATASET", "confidence": 0.5269386172294617}]}, {"text": "BART is a modular toolkit for coreference resolution that supports state-of-the-art statistical approaches to the task and enables efficient feature engineering.", "labels": [], "entities": [{"text": "BART", "start_pos": 0, "end_pos": 4, "type": "METRIC", "confidence": 0.48875126242637634}, {"text": "coreference resolution", "start_pos": 30, "end_pos": 52, "type": "TASK", "confidence": 0.9586798846721649}]}, {"text": "BART has originally been created and tested for English, but its flexible modular architecture ensures its portability to other languages and domains.", "labels": [], "entities": [{"text": "BART", "start_pos": 0, "end_pos": 4, "type": "TASK", "confidence": 0.6310300230979919}]}, {"text": "In SemEval-2010 task 1 on Coreference Resolution, BART has shown reliable performance for English, German and Italian.", "labels": [], "entities": [{"text": "Coreference Resolution", "start_pos": 26, "end_pos": 48, "type": "TASK", "confidence": 0.917599231004715}, {"text": "BART", "start_pos": 50, "end_pos": 54, "type": "METRIC", "confidence": 0.7098904848098755}]}, {"text": "In our SemEval experiments, we mainly focus on extending BART to cover multiple languages.", "labels": [], "entities": [{"text": "BART", "start_pos": 57, "end_pos": 61, "type": "TASK", "confidence": 0.9434905052185059}]}, {"text": "Given a corpus in anew language, one can re-train BART to obtain baseline results.", "labels": [], "entities": [{"text": "BART", "start_pos": 50, "end_pos": 54, "type": "TASK", "confidence": 0.7439935207366943}]}, {"text": "Such a language-agnostic system, however, is only used as a starting point: substantial improvements can be achieved by incorporating language-specific information with the help of the Language Plugin.", "labels": [], "entities": []}, {"text": "This design provides effective separation between linguistic and machine learning aspects of the problem.", "labels": [], "entities": []}], "datasetContent": [{"text": "The system was evaluated on the SemEval task 1 corpus by using the SemEval scorer.", "labels": [], "entities": [{"text": "SemEval task 1 corpus", "start_pos": 32, "end_pos": 53, "type": "DATASET", "confidence": 0.7097817659378052}]}, {"text": "First, we have evaluated our mention detection modules: the system's ability to recognize both the mention extensions and the heads in the regular setting.", "labels": [], "entities": [{"text": "mention detection", "start_pos": 29, "end_pos": 46, "type": "TASK", "confidence": 0.7482431828975677}]}, {"text": "BART has achieved the best score for mention detection in German and has shown reliable figures for English.", "labels": [], "entities": [{"text": "BART", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.8507058620452881}, {"text": "mention detection", "start_pos": 37, "end_pos": 54, "type": "TASK", "confidence": 0.7075519263744354}]}, {"text": "For Italian, the moderate performance level is due to the different algorithms for identifying the heads: the MaltParser (trained on TUT: http://www.di.unito.it/ \u02dc tutreeb) produces a more semantic representation, while the SemEval scorer seems to adopt a more syntactic approach.", "labels": [], "entities": [{"text": "TUT", "start_pos": 133, "end_pos": 136, "type": "DATASET", "confidence": 0.6601757407188416}]}, {"text": "Second, we have evaluated the quality of our coreference resolution modules.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 45, "end_pos": 67, "type": "TASK", "confidence": 0.8753642141819}]}, {"text": "For German, BART has shown better performance than all the other systems on the regular track.", "labels": [], "entities": [{"text": "BART", "start_pos": 12, "end_pos": 16, "type": "METRIC", "confidence": 0.494843989610672}]}, {"text": "For English, the only language targeted by all systems, BART shows good performance overall metrics in the regular setting, usually only outperformed by systems that were tuned to a particular metric.", "labels": [], "entities": [{"text": "BART", "start_pos": 56, "end_pos": 60, "type": "METRIC", "confidence": 0.7088066339492798}]}, {"text": "Finally, the Italian version of BART shows reliable figures for coreference resolution, given the mention alignment problem discussed above.", "labels": [], "entities": [{"text": "BART", "start_pos": 32, "end_pos": 36, "type": "METRIC", "confidence": 0.3478875458240509}, {"text": "coreference resolution", "start_pos": 64, "end_pos": 86, "type": "TASK", "confidence": 0.9723511040210724}]}], "tableCaptions": []}