{"title": [{"text": "WINGNUS: Keyphrase Extraction Utilizing Document Logical Structure", "labels": [], "entities": [{"text": "Keyphrase Extraction Utilizing Document Logical", "start_pos": 9, "end_pos": 56, "type": "TASK", "confidence": 0.8376436173915863}]}], "abstractContent": [{"text": "We present a system description of the WINGNUS teamwork 1 for the SemEval-2010 task #5 Automatic Keyphrase Extraction from Scientific Articles.", "labels": [], "entities": [{"text": "SemEval-2010 task #5 Automatic Keyphrase Extraction", "start_pos": 66, "end_pos": 117, "type": "TASK", "confidence": 0.7648560915674482}]}, {"text": "A key feature of our system is that it utilizes an inferred document logical structure in our candidate identification process, to limit the number of phrases in the candidate list, while maintaining its coverage of important phrases.", "labels": [], "entities": [{"text": "candidate identification process", "start_pos": 94, "end_pos": 126, "type": "TASK", "confidence": 0.8391585747400919}]}, {"text": "Our top performing system achieves an F 1 of 25.22% for the combined keyphrases (author and reader assigned) in the final test data.", "labels": [], "entities": [{"text": "F 1", "start_pos": 38, "end_pos": 41, "type": "METRIC", "confidence": 0.9917068481445312}]}, {"text": "We note that the method we report here is novel and orthogonal from other systems, so it can be combined with other techniques to potentially achieve higher performance.", "labels": [], "entities": []}], "introductionContent": [{"text": "Keyphrases are noun phrases (NPs) that capture the primary topics of a document.", "labels": [], "entities": []}, {"text": "While beneficial for applications such as summarization, clustering and indexing, only a minority of documents have manually-assigned keyphrases, as it is a timeconsuming process.", "labels": [], "entities": [{"text": "summarization", "start_pos": 42, "end_pos": 55, "type": "TASK", "confidence": 0.9918102622032166}, {"text": "clustering", "start_pos": 57, "end_pos": 67, "type": "TASK", "confidence": 0.882806122303009}]}, {"text": "Automatic keyphrase generation is thus a focus for many researchers.", "labels": [], "entities": [{"text": "keyphrase generation", "start_pos": 10, "end_pos": 30, "type": "TASK", "confidence": 0.7427716851234436}]}, {"text": "Most existing keyphrase extraction systems view this task as a supervised classification task in two stages: generating a list of candidates -candidate identification; and using answer keyphrases to distinguish true keyphrases -candidate selection.", "labels": [], "entities": [{"text": "keyphrase extraction", "start_pos": 14, "end_pos": 34, "type": "TASK", "confidence": 0.7222731858491898}, {"text": "generating a list of candidates -candidate identification", "start_pos": 109, "end_pos": 166, "type": "TASK", "confidence": 0.6749011650681496}]}, {"text": "The selection model uses a set of features that capture the saliency of a phrase as a keyphrase.", "labels": [], "entities": []}, {"text": "A major challenge of the keyphrase extraction task lies in the candidate identification process.", "labels": [], "entities": [{"text": "keyphrase extraction task", "start_pos": 25, "end_pos": 50, "type": "TASK", "confidence": 0.8673022389411926}, {"text": "candidate identification process", "start_pos": 63, "end_pos": 95, "type": "TASK", "confidence": 0.8296692967414856}]}, {"text": "A narrow candidate list will overlook some true keyphrases (favoring precision), whereas abroad list will produce more errors and require more processing in latter selection stage (favoring recall).", "labels": [], "entities": [{"text": "precision", "start_pos": 69, "end_pos": 78, "type": "METRIC", "confidence": 0.9983737468719482}, {"text": "recall", "start_pos": 190, "end_pos": 196, "type": "METRIC", "confidence": 0.9984657764434814}]}, {"text": "In our previous system, we made use of the document logical structure in the proposed features.", "labels": [], "entities": []}, {"text": "The premise of this earlier work was that keyphrases are distributed non-uniformly in different logical sections of a paper, favoring sections such as introduction, and related work.", "labels": [], "entities": []}, {"text": "We introduced features indicating which sections a candidate occurrs in.", "labels": [], "entities": []}, {"text": "For our fielded system in this task (, we further leverage the document logical structure for both candidate identification and selection stages.", "labels": [], "entities": [{"text": "candidate identification", "start_pos": 99, "end_pos": 123, "type": "TASK", "confidence": 0.7429872751235962}]}, {"text": "Our contributions are as follows: 1) We suggest the use of Google Scholar-based crawler to automatically find PDF files to enhance logical structure extraction; 2) We provide a keyphrase distribution study with respect to different logical structures; and 3) From the study result, we propose a candidate identification approach that uses logical structures to effectively limit the number of candidates considered while ensuring good coverage.", "labels": [], "entities": [{"text": "logical structure extraction", "start_pos": 131, "end_pos": 159, "type": "TASK", "confidence": 0.7512116432189941}, {"text": "candidate identification", "start_pos": 295, "end_pos": 319, "type": "TASK", "confidence": 0.8045966625213623}]}], "datasetContent": [{"text": "For this task (, we are given two datasets: train (144 docs) and test (100 docs) with detailed answers for train.", "labels": [], "entities": []}, {"text": "To tune our system, we split the train dataset into train and validation subsets: train t (104 docs) and train v (40 docs).", "labels": [], "entities": []}, {"text": "Once the best setting is derived from train t -train v , we obtain the final model trained on the full data, and apply it to the test set for the final results.", "labels": [], "entities": []}, {"text": "Our evaluation process is accomplished in two stages: we first experiment different feature combinations by using the input types fulltext and full 1 . We then fix the best feature set, and vary our different abridged inputs to find the optimal one.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Keyphrase distribution over different log- ical structures computed from the 144 training  documents. The type counts of author-assigned  (ath), reader-assigned (rder) and combined (comb)  keyphrases are shown. Sent indicates the number  of sentences in each LS. The Den column gives the  density of keyphrases for each LS.", "labels": [], "entities": []}, {"text": " Table 2: Different levels of abridged inputs com- puted on the training data. Cand shows the  number of candidate keyphrases extracted for  each input type; Com gives the number of cor- rect keyphrases appear as candidates; Recall is  computed with respect to the total number of  keyphrases in the original texts (2059).", "labels": [], "entities": [{"text": "Cand", "start_pos": 79, "end_pos": 83, "type": "METRIC", "confidence": 0.9436619281768799}, {"text": "Com", "start_pos": 158, "end_pos": 161, "type": "METRIC", "confidence": 0.976321280002594}, {"text": "Recall", "start_pos": 225, "end_pos": 231, "type": "METRIC", "confidence": 0.9993575215339661}]}, {"text": " Table 3: Performance of individual features (on  fulltext) added separately to the base set F 1,4 .", "labels": [], "entities": []}, {"text": " Table 4: Performance (F 1 ) over difference feature  combinations for fulltext and full 1 inputs.", "labels": [], "entities": [{"text": "F 1 )", "start_pos": 23, "end_pos": 28, "type": "METRIC", "confidence": 0.9030867020289103}]}, {"text": " Table 5: Performance over different abridged in- puts using the best feature set F 1,3,4,6 . \"@N\" indi- cates the number of top N keyphrase matches.", "labels": [], "entities": []}, {"text": " Table 6: Final results on the test data.", "labels": [], "entities": []}]}