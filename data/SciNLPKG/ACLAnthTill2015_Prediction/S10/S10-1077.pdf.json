{"title": [{"text": "JU_CSE_TEMP: A First Step towards Evaluating Events, Time Ex- pressions and Temporal Relations", "labels": [], "entities": [{"text": "JU_CSE_TEMP", "start_pos": 0, "end_pos": 11, "type": "DATASET", "confidence": 0.8011349558830261}, {"text": "Evaluating Events", "start_pos": 34, "end_pos": 51, "type": "TASK", "confidence": 0.8950599730014801}, {"text": "Temporal Relations", "start_pos": 76, "end_pos": 94, "type": "TASK", "confidence": 0.7215831577777863}]}], "abstractContent": [{"text": "Temporal information extraction is a popular and interesting research field in the area of Natural Language Processing (NLP).", "labels": [], "entities": [{"text": "Temporal information extraction", "start_pos": 0, "end_pos": 31, "type": "TASK", "confidence": 0.8869595328966776}, {"text": "Natural Language Processing (NLP)", "start_pos": 91, "end_pos": 124, "type": "TASK", "confidence": 0.7537758648395538}]}, {"text": "In this paper, we report our works on TempEval-2 shared task.", "labels": [], "entities": []}, {"text": "This is our first participation and we participated in all the tasks, i.e., A, B, C, D, E and F.", "labels": [], "entities": []}, {"text": "We develop rule-based systems for Tasks A and B, whereas the remaining tasks are based on a machine learning approach, namely Conditional Random Field (CRF).", "labels": [], "entities": []}, {"text": "All our systems are still in their development stages, and we report the very initial results.", "labels": [], "entities": []}, {"text": "Evaluation results on the shared task English datasets yield the precision, recall and F-measure values of 55%, 17% and 26%, respectively for Task A and 48%, 56% and 52%, respectively for Task B (event recognition).", "labels": [], "entities": [{"text": "precision", "start_pos": 65, "end_pos": 74, "type": "METRIC", "confidence": 0.9997647404670715}, {"text": "recall", "start_pos": 76, "end_pos": 82, "type": "METRIC", "confidence": 0.9966705441474915}, {"text": "F-measure", "start_pos": 87, "end_pos": 96, "type": "METRIC", "confidence": 0.9953486323356628}, {"text": "event recognition)", "start_pos": 196, "end_pos": 214, "type": "TASK", "confidence": 0.8189224203427633}]}, {"text": "The rest of tasks, namely C, D, E and F were evaluated with a relatively simpler metric: the number of correct answers divided by the number of answers.", "labels": [], "entities": []}, {"text": "Experiments on the English datasets yield the accuracies of 63%, 80%, 56% and 56% for tasks C, D, E and F, respectively.", "labels": [], "entities": [{"text": "English datasets", "start_pos": 19, "end_pos": 35, "type": "DATASET", "confidence": 0.9236065745353699}, {"text": "accuracies", "start_pos": 46, "end_pos": 56, "type": "METRIC", "confidence": 0.9977903366088867}]}], "introductionContent": [{"text": "Temporal information extraction is, nowadays, a popular and interesting research area of Natural Language Processing (NLP).", "labels": [], "entities": [{"text": "Temporal information extraction", "start_pos": 0, "end_pos": 31, "type": "TASK", "confidence": 0.8817300001780192}, {"text": "Natural Language Processing (NLP)", "start_pos": 89, "end_pos": 122, "type": "TASK", "confidence": 0.7592570583025614}]}, {"text": "Generally, events are described in different newspaper texts, stories and other important documents where events happen in time and the temporal location and ordering of these events are specified.", "labels": [], "entities": []}, {"text": "One of the important tasks of text analysis clearly requires identifying events described in a text and locating these in time.", "labels": [], "entities": [{"text": "text analysis", "start_pos": 30, "end_pos": 43, "type": "TASK", "confidence": 0.7872457504272461}]}, {"text": "This is also important in a wide range of NLP applications that include temporal question answering, machine translation and document summarization.", "labels": [], "entities": [{"text": "temporal question answering", "start_pos": 72, "end_pos": 99, "type": "TASK", "confidence": 0.6135810911655426}, {"text": "machine translation", "start_pos": 101, "end_pos": 120, "type": "TASK", "confidence": 0.8070438504219055}, {"text": "document summarization", "start_pos": 125, "end_pos": 147, "type": "TASK", "confidence": 0.7168544232845306}]}, {"text": "In the literature, temporal relation identification based on machine learning approaches can be found in,, and some of the TempEval 2007 participants ).", "labels": [], "entities": [{"text": "temporal relation identification", "start_pos": 19, "end_pos": 51, "type": "TASK", "confidence": 0.7556545933087667}, {"text": "TempEval 2007 participants", "start_pos": 123, "end_pos": 149, "type": "DATASET", "confidence": 0.8981840411822001}]}, {"text": "Most of these works tried to improve classification accuracies through feature engineering.", "labels": [], "entities": [{"text": "classification accuracies", "start_pos": 37, "end_pos": 62, "type": "TASK", "confidence": 0.8106609880924225}, {"text": "feature engineering", "start_pos": 71, "end_pos": 90, "type": "TASK", "confidence": 0.8116637468338013}]}, {"text": "The performance of any machine learning based system is often limited by the amount of available training data.", "labels": [], "entities": []}, {"text": "introduced a temporal reasoning component that greatly expands the available training data.", "labels": [], "entities": []}, {"text": "The training set was increased by a factor of 10 by computing the closure of the various temporal relations that exist in the training data.", "labels": [], "entities": []}, {"text": "They reported significant improvement of the classification accuracies on event-event and event-time relations.", "labels": [], "entities": []}, {"text": "Their experimental result showed the accuracies of 62.5%-94.95% and 73.68%-90.16% for event-event and event-time relations, respectively.", "labels": [], "entities": [{"text": "accuracies", "start_pos": 37, "end_pos": 47, "type": "METRIC", "confidence": 0.9931175708770752}]}, {"text": "However, this has two shortcomings, namely feature vector duplication caused by the data normalization process and the unrealistic evaluation scheme.", "labels": [], "entities": [{"text": "feature vector duplication", "start_pos": 43, "end_pos": 69, "type": "TASK", "confidence": 0.6340645352999369}]}, {"text": "The solutions to these issues are briefly described in.", "labels": [], "entities": []}, {"text": "In TempEval 2007 task, a common standard dataset was introduced that involves three temporal relations.", "labels": [], "entities": [{"text": "TempEval 2007 task", "start_pos": 3, "end_pos": 21, "type": "DATASET", "confidence": 0.8039992054303488}]}, {"text": "The participants reported F-measure scores for event-event relations ranging from 42% to 55% and for event-time relations from 73% to 80%.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 26, "end_pos": 35, "type": "METRIC", "confidence": 0.9983900785446167}]}, {"text": "Unlike (), event-event temporal relations were not discourse-wide (i.e., any pair of events can be temporally linked) in.", "labels": [], "entities": []}, {"text": "Here, the event-event relations were restricted to events within two consecutive sentences.", "labels": [], "entities": []}, {"text": "Thus, these two frameworks produced highly dissimilar re-sults for solving the problem of temporal relation classification.", "labels": [], "entities": [{"text": "temporal relation classification", "start_pos": 90, "end_pos": 122, "type": "TASK", "confidence": 0.6571083863576254}]}, {"text": "In order to apply various machine learning algorithms, most of the authors formulated temporal relation as an event paired with a time or another event and translated these into a set of feature values.", "labels": [], "entities": []}, {"text": "Some of the popularly used machine learning techniques were Naive-Bayes, Decision Tree (C5.0), Maximum Entropy (ME) and Support Vector Machine (SVM).", "labels": [], "entities": []}, {"text": "Machine learning techniques alone cannot always yield good accuracies.", "labels": [], "entities": []}, {"text": "To achieve reasonable accuracy, some researchers () used hybrid approach.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 22, "end_pos": 30, "type": "METRIC", "confidence": 0.998566210269928}]}, {"text": "The basic principle of hybrid approach is to combine the rule-based component with machine learning.", "labels": [], "entities": []}, {"text": "It has been shown in () that classifiers make most mistakes near the decision plane in feature space.", "labels": [], "entities": []}, {"text": "The authors carried out a series of experiments for each of the three tasks on four models, namely naive-Bayes, decision tree (C5.0), maximum entropy and support vector machine.", "labels": [], "entities": []}, {"text": "The system was designed in such away that they can take the advantage of rule-based as well as machine learning during final decision making.", "labels": [], "entities": []}, {"text": "But, they did not explain exactly in what situations machine learning or rule based system should be used given a particular instance.", "labels": [], "entities": []}, {"text": "They had the option to call either component on the fly in different situations so that they can take advantage of the two empirical approaches in an integrated way.", "labels": [], "entities": []}, {"text": "The rest of the paper is structured as follows.", "labels": [], "entities": []}, {"text": "We present very brief descriptions of the different tasks in Section 2.", "labels": [], "entities": []}, {"text": "Section 3 describes our approach in details with rule-based techniques for tasks A and B in Subsection 3.1, CRF based techniques in Subsection 3.2 for tasks C, D, E and F, and features in Subsection 3.3.", "labels": [], "entities": []}, {"text": "Detailed evaluation results are reported in Section 4.", "labels": [], "entities": []}, {"text": "Finally, Section 5 concludes the paper with a direction to future works.", "labels": [], "entities": []}], "datasetContent": [{"text": "Each of the tasks is evaluated with the TempEval-2 shared task datasets.", "labels": [], "entities": [{"text": "TempEval-2 shared task datasets", "start_pos": 40, "end_pos": 71, "type": "DATASET", "confidence": 0.7781635075807571}]}, {"text": "For the extents of events and time expressions (tasks A and B), precision, recall and the Fmeasure are used as evaluation metrics, using the following formulas: Precision (P) = tp/ (tp + fp) Recall (R) = tp/ (tp + fn) F-measure = 2 *(P * R)/ (P + R) Where, tp is the number of tokens that are part of an extent in both keys and response, fp is the number of tokens that are part of an extent in the response but not in the key, and fn is the number of tokens that are part of an extent in the key but not in the response.", "labels": [], "entities": [{"text": "precision", "start_pos": 64, "end_pos": 73, "type": "METRIC", "confidence": 0.999462902545929}, {"text": "recall", "start_pos": 75, "end_pos": 81, "type": "METRIC", "confidence": 0.9994105100631714}, {"text": "Fmeasure", "start_pos": 90, "end_pos": 98, "type": "METRIC", "confidence": 0.992892861366272}, {"text": "Precision", "start_pos": 161, "end_pos": 170, "type": "METRIC", "confidence": 0.9753243923187256}, {"text": "Recall", "start_pos": 191, "end_pos": 197, "type": "METRIC", "confidence": 0.9774245023727417}]}, {"text": "An even simpler evaluation metric similar to the definition of 'accuracy' is used to evaluate the attributes of events and time expressions (the second part of tasks, A and B) and for relation types (tasks C through F).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 64, "end_pos": 72, "type": "METRIC", "confidence": 0.9972373247146606}]}, {"text": "The metric, henceforth referred to as 'accuracy', is defined as below: Number of correct answers/ Number of answers present in the test data", "labels": [], "entities": [{"text": "accuracy", "start_pos": 39, "end_pos": 47, "type": "METRIC", "confidence": 0.9983432292938232}]}], "tableCaptions": [{"text": " Table 1. Experimental results on tasks A and B", "labels": [], "entities": []}, {"text": " Table 2. Ex- periments show the accuracies of 63%, 80%,  56% and 56% for tasks C, D, E and F, respec- tively. Results show that our system performs  best for task D, i.e., relationships between event  and document creation time. The system  achieves an accuracy of 63% for task C that finds  the temporal relation between an event and a time  expression in the same sentence. The system per- forms quite similarly for tasks E and F. It is to be  noted that there is still the room for performance  improvement. In the present work, we did not  carry out sufficient experiments to identify the  most suitable feature templates for each of the  tasks. In future, we would experiment after se- lecting a development set for each task; and find  out appropriate feature template depending upon  the performance on the development set.", "labels": [], "entities": [{"text": "accuracies", "start_pos": 33, "end_pos": 43, "type": "METRIC", "confidence": 0.9903556108474731}, {"text": "accuracy", "start_pos": 254, "end_pos": 262, "type": "METRIC", "confidence": 0.9971876740455627}]}]}