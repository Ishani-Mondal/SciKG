{"title": [{"text": "CFILT: Resource Conscious Approaches for All-Words Domain Specific WSD", "labels": [], "entities": [{"text": "CFILT", "start_pos": 0, "end_pos": 5, "type": "DATASET", "confidence": 0.9353581666946411}, {"text": "WSD", "start_pos": 67, "end_pos": 70, "type": "TASK", "confidence": 0.4763345718383789}]}], "abstractContent": [{"text": "We describe two approaches for All-words Word Sense Disambiguation on a Specific Domain.", "labels": [], "entities": [{"text": "All-words Word Sense Disambiguation", "start_pos": 31, "end_pos": 66, "type": "TASK", "confidence": 0.6579436361789703}]}, {"text": "The first approach is a knowledge based approach which extracts domain-specific largest connected components from the Wordnet graph by exploiting the semantic relations between all candidate synsets appearing in a domain-specific untagged corpus.", "labels": [], "entities": [{"text": "Wordnet graph", "start_pos": 118, "end_pos": 131, "type": "DATASET", "confidence": 0.9606876075267792}]}, {"text": "Given a test word, disambiguation is performed by considering only those candidate synsets that belong to the top-k largest connected components.", "labels": [], "entities": [{"text": "disambiguation", "start_pos": 19, "end_pos": 33, "type": "TASK", "confidence": 0.9612966179847717}]}, {"text": "The second approach is a weakly supervised approach which relies on the \"One Sense Per Domain\" heuristic and uses a few hand labeled examples for the most frequently appearing words in the target domain.", "labels": [], "entities": []}, {"text": "Once the most frequent words have been disambiguated they can provide strong clues for disambiguating other words in the sentence using an iterative disambiguation algorithm.", "labels": [], "entities": []}, {"text": "Our weakly supervised system gave the best performance across all systems that participated in the task even when it used as few as 100 hand labeled examples from the target domain .", "labels": [], "entities": []}], "introductionContent": [{"text": "Domain specific WSD exhibits high level of accuracy even for the all-words scenario () -provided training and testing are on the same domain.", "labels": [], "entities": [{"text": "WSD", "start_pos": 16, "end_pos": 19, "type": "TASK", "confidence": 0.7444362640380859}, {"text": "accuracy", "start_pos": 43, "end_pos": 51, "type": "METRIC", "confidence": 0.9989748001098633}]}, {"text": "However, the effort of creating the training corpus -annotated sense marked corpora -for every domain of interest has always been a matter of concern.", "labels": [], "entities": []}, {"text": "Therefore, attempts have been made to develop unsupervised () and knowledge based techniques () for WSD which do not need sense marked corpora.", "labels": [], "entities": [{"text": "WSD", "start_pos": 100, "end_pos": 103, "type": "TASK", "confidence": 0.9843711256980896}]}, {"text": "However, such approaches have not proved effective, since they typically do not perform better than the Wordnet first sense baseline accuracy in the all-words scenario.", "labels": [], "entities": [{"text": "Wordnet first sense baseline accuracy", "start_pos": 104, "end_pos": 141, "type": "METRIC", "confidence": 0.7527418255805969}]}, {"text": "Motivated by the desire to develop annotationlean all-words domain specific techniques for WSD we propose two resource conscious approaches.", "labels": [], "entities": [{"text": "WSD", "start_pos": 91, "end_pos": 94, "type": "TASK", "confidence": 0.9769493937492371}]}, {"text": "The first approach is a knowledge based approach which focuses on retaining only domain specific synsets in the Wordnet using a two step pruning process.", "labels": [], "entities": [{"text": "Wordnet", "start_pos": 112, "end_pos": 119, "type": "DATASET", "confidence": 0.9692853093147278}]}, {"text": "In the first step, the Wordnet graph is restricted to only those synsets which contain words appearing in an untagged domainspecific corpus.", "labels": [], "entities": [{"text": "Wordnet graph", "start_pos": 23, "end_pos": 36, "type": "DATASET", "confidence": 0.9226438999176025}]}, {"text": "In the second step, the graph is pruned further by retaining only the largest connected components of the pruned graph.", "labels": [], "entities": []}, {"text": "Each target word in a given sentence is then disambiguated using an iterative disambiguation process by considering only those candidate synsets which appear in the top-k largest connected components.", "labels": [], "entities": []}, {"text": "Our knowledge based approach performed better than current state of the art knowledge based approach (.", "labels": [], "entities": []}, {"text": "Also, the precision was better than the Wordnet first sense baseline even though the F-score was slightly lower than the baseline.", "labels": [], "entities": [{"text": "precision", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9997652173042297}, {"text": "Wordnet first sense baseline", "start_pos": 40, "end_pos": 68, "type": "DATASET", "confidence": 0.8364146649837494}, {"text": "F-score", "start_pos": 85, "end_pos": 92, "type": "METRIC", "confidence": 0.9990113973617554}]}, {"text": "The second approach is a weakly supervised approach which uses a few hand labeled examples for the most frequent words in the target domain in addition to the publicly available mixed-domain SemCor ( corpus.", "labels": [], "entities": []}, {"text": "The underlying assumption is that words exhibit \"One Sense Per Domain\" phenomenon and hence even as few as 5 training examples per word would be sufficient to identify the predominant sense of the most frequent words in the target domain.", "labels": [], "entities": []}, {"text": "Further, once the most frequent words have been disambiguated using the predominant sense, they can provide strong clues for disambiguating other words in the sentence.", "labels": [], "entities": []}, {"text": "Our weakly supervised system gave the best performance across all systems that participated in the task even when it used as few as 100 hand labeled examples from the target domain.", "labels": [], "entities": []}, {"text": "The remainder of this paper is organized as follows.", "labels": [], "entities": []}, {"text": "In section 2 we describe related work on domain-specific WSD.", "labels": [], "entities": [{"text": "WSD", "start_pos": 57, "end_pos": 60, "type": "TASK", "confidence": 0.7989523410797119}]}, {"text": "In section 3 we discuss an Iterative Word Sense Disambiguation algorithm which lies at the heart of both our approaches.", "labels": [], "entities": [{"text": "Iterative Word Sense Disambiguation", "start_pos": 27, "end_pos": 62, "type": "TASK", "confidence": 0.5677430927753448}]}, {"text": "In section 4 we describe our knowledge based approach.", "labels": [], "entities": []}, {"text": "In section 5 we describe our weakly supervised approach.", "labels": [], "entities": []}, {"text": "In section 6 we present results and discussions followed by conclusion in section 7.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 2: The performance of our systems in the  shared task", "labels": [], "entities": []}]}