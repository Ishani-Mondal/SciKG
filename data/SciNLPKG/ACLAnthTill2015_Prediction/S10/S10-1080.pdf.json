{"title": [{"text": "HERMIT: Flexible Clustering for the SemEval-2 WSI Task", "labels": [], "entities": [{"text": "HERMIT", "start_pos": 0, "end_pos": 6, "type": "METRIC", "confidence": 0.9385455250740051}, {"text": "SemEval-2 WSI", "start_pos": 36, "end_pos": 49, "type": "TASK", "confidence": 0.656985729932785}]}], "abstractContent": [{"text": "A single word may have multiple un-specified meanings in a corpus.", "labels": [], "entities": []}, {"text": "Word sense induction aims to discover these different meanings through word use, and knowledge-lean algorithms attempt this without using external lexical resources.", "labels": [], "entities": [{"text": "Word sense induction", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.7288915117581686}]}, {"text": "We propose anew method for identifying the different senses that uses a flexible clustering strategy to automatically determine the number of senses, rather than predefining it.", "labels": [], "entities": []}, {"text": "We demonstrate the effectiveness using the SemEval-2 WSI task, achieving competitive scores on both the V-Measure and Recall metrics, depending on the parameter configuration.", "labels": [], "entities": [{"text": "SemEval-2 WSI task", "start_pos": 43, "end_pos": 61, "type": "TASK", "confidence": 0.7364985148111979}, {"text": "Recall", "start_pos": 118, "end_pos": 124, "type": "METRIC", "confidence": 0.9390718936920166}]}], "introductionContent": [{"text": "The Word Sense Induction task of SemEval 2010 compares several sense induction and discrimination systems that are trained over a common corpus.", "labels": [], "entities": [{"text": "Word Sense Induction task of SemEval 2010", "start_pos": 4, "end_pos": 45, "type": "TASK", "confidence": 0.7787067719868251}]}, {"text": "Systems are provided with an unlabeled training corpus consisting of 879,807 contexts for 100 polysemous words, with 50 nouns and 50 verbs.", "labels": [], "entities": []}, {"text": "Each context consists of several sentences that use a single sense of a target word, whereat least one sentence contains the word.", "labels": [], "entities": []}, {"text": "Systems must use the training corpus to induce sense representations for the many word senses and then use those representations to produce sense labels for the same 100 words in unseen contexts from a testing corpus.", "labels": [], "entities": []}, {"text": "We perform this task by utilizing a distributional word space formed using dimensionality reduction and a hybrid clustering method.", "labels": [], "entities": []}, {"text": "Our model is highly scalable; the dimensionality of the word space is reduced immediately through a process based on random projections.", "labels": [], "entities": []}, {"text": "In addition, an online part of our clustering algorithm maintains only a centroid that describes an induced word sense, instead of all observed contexts, which lets the model scale to much larger corpora than those used in the SemEval-2 WSI task.", "labels": [], "entities": [{"text": "SemEval-2 WSI task", "start_pos": 227, "end_pos": 245, "type": "TASK", "confidence": 0.7786093354225159}]}], "datasetContent": [{"text": "The WSI task evaluated the submitted solutions with two methods of experimentation: an unsupervised method and a supervised method.", "labels": [], "entities": [{"text": "WSI task", "start_pos": 4, "end_pos": 12, "type": "TASK", "confidence": 0.638573408126831}]}, {"text": "The unsupervised method is measured according to the VMeasure and the F-Score.", "labels": [], "entities": [{"text": "VMeasure", "start_pos": 53, "end_pos": 61, "type": "DATASET", "confidence": 0.5233190655708313}, {"text": "F-Score", "start_pos": 70, "end_pos": 77, "type": "METRIC", "confidence": 0.9893712997436523}]}, {"text": "The supervised method is measured using recall.", "labels": [], "entities": [{"text": "recall", "start_pos": 40, "end_pos": 46, "type": "METRIC", "confidence": 0.9985766410827637}]}, {"text": "When configured for the F-Score, HERMIT-F performs well; this configuration would have ranked third for the F-Score if it had been submitted.", "labels": [], "entities": [{"text": "F-Score", "start_pos": 24, "end_pos": 31, "type": "DATASET", "confidence": 0.5196922421455383}, {"text": "HERMIT-F", "start_pos": 33, "end_pos": 41, "type": "METRIC", "confidence": 0.9675995111465454}, {"text": "F-Score", "start_pos": 108, "end_pos": 115, "type": "DATASET", "confidence": 0.6326358914375305}]}, {"text": "However, its performance is also due to the relatively few senses per word it generates, 1.54.", "labels": [], "entities": []}, {"text": "The inverse performance of both optimized configurations is reflective of the contrasting nature of the two performance measures.", "labels": [], "entities": []}, {"text": "The supervised evaluation simulates a supervised Word Sense Disambiguation (WSD) task.", "labels": [], "entities": [{"text": "Word Sense Disambiguation (WSD) task", "start_pos": 49, "end_pos": 85, "type": "TASK", "confidence": 0.7725006427083697}]}, {"text": "The induced sense labels for the test corpus are split such that the first set is used for mapping induced senses to golden senses and the remaining sense labels are treated as sense labels provided by a WSD system, which allows for evaluation.", "labels": [], "entities": []}, {"text": "Five splits are done at random to avoid any biases created due to the separation of the mapping corpus and the evaluation corpus; the resulting score for this task is the average recall over the five divisions.", "labels": [], "entities": [{"text": "recall", "start_pos": 179, "end_pos": 185, "type": "METRIC", "confidence": 0.9982932209968567}]}, {"text": "Two sets of splits were used for evaluation: one with 80% of the senses as the mapping portion and 20% as the evaluation portion and one with 60% as the mapping portion corpus and 40% for evaluation.", "labels": [], "entities": []}, {"text": "The results for the 80/20 split and 60/40 split are displayed in tables 3 and 4, respectively.", "labels": [], "entities": []}, {"text": "In both supervised evaluations, our submitted system does moderately well.", "labels": [], "entities": []}, {"text": "In both cases it outperforms the Random baseline and does almost as well as the MFS baseline.", "labels": [], "entities": [{"text": "MFS baseline", "start_pos": 80, "end_pos": 92, "type": "DATASET", "confidence": 0.8593546748161316}]}, {"text": "The submitted system outperforms the Random baseline and approaches the MFS baseline for the 80/20 split.", "labels": [], "entities": [{"text": "MFS baseline", "start_pos": 72, "end_pos": 84, "type": "DATASET", "confidence": 0.863739937543869}]}, {"text": "The HERMIT-S version, which is optimized for this task, provides similar results.", "labels": [], "entities": [{"text": "HERMIT-S", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.91241455078125}]}], "tableCaptions": [{"text": " Table 1: V-Measure for the unsupervised evalua- tion", "labels": [], "entities": []}, {"text": " Table 2: F-Scores for the unsupervised evaluation", "labels": [], "entities": [{"text": "F-Scores", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9978016018867493}]}, {"text": " Table 3: Supervised recall for the 80/20 split", "labels": [], "entities": [{"text": "recall", "start_pos": 21, "end_pos": 27, "type": "METRIC", "confidence": 0.9934693574905396}, {"text": "80/20", "start_pos": 36, "end_pos": 41, "type": "DATASET", "confidence": 0.8964364926020304}]}, {"text": " Table 4: Supervised recall for the 60/40 split", "labels": [], "entities": [{"text": "recall", "start_pos": 21, "end_pos": 27, "type": "METRIC", "confidence": 0.9922423362731934}]}]}