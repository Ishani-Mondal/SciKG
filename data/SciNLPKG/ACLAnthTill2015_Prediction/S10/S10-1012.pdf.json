{"title": [], "abstractContent": [{"text": "An overview of the SemEval-2 Japanese WSD task is presented.", "labels": [], "entities": [{"text": "SemEval-2 Japanese WSD task", "start_pos": 19, "end_pos": 46, "type": "TASK", "confidence": 0.8095967471599579}]}, {"text": "It is a lexical sample task, and word senses are defined according to a Japanese dictionary, the Iwanami Kokugo Jiten.", "labels": [], "entities": [{"text": "Iwanami Kokugo Jiten", "start_pos": 97, "end_pos": 117, "type": "DATASET", "confidence": 0.9072290261586508}]}, {"text": "This dictionary and a training corpus were distributed to participants.", "labels": [], "entities": []}, {"text": "The number of target words was 50, with 22 nouns, 23 verbs, and 5 adjectives.", "labels": [], "entities": []}, {"text": "Fifty instances of each target word were provided, consisting of a total of 2,500 instances for the evaluation.", "labels": [], "entities": []}, {"text": "Nine systems from four organizations participated in the task.", "labels": [], "entities": []}], "introductionContent": [{"text": "This paper reports an overview of the SemEval-2 Japanese Word Sense Disambiguation (WSD) task.", "labels": [], "entities": [{"text": "SemEval-2 Japanese Word Sense Disambiguation (WSD) task", "start_pos": 38, "end_pos": 93, "type": "TASK", "confidence": 0.8840441571341621}]}, {"text": "It can be considered an extension of the SENSEVAL-2 Japanese monolingual dictionarybased task, so it is a lexical sample task.", "labels": [], "entities": [{"text": "SENSEVAL-2 Japanese monolingual dictionarybased task", "start_pos": 41, "end_pos": 93, "type": "TASK", "confidence": 0.5429242730140686}]}, {"text": "Word senses are defined according to the Iwanami Kokugo Jiten (, a Japanese dictionary published by Iwanami Shoten.", "labels": [], "entities": [{"text": "Iwanami", "start_pos": 41, "end_pos": 48, "type": "DATASET", "confidence": 0.9224486947059631}]}, {"text": "It was distributed to participants as a sense inventory.", "labels": [], "entities": []}, {"text": "Our task has the following two new characteristics: 1.", "labels": [], "entities": []}, {"text": "All previous Japanese sense-tagged corpora were from newspaper articles, while sensetagged corpora were constructed in English on balanced corpora, such as Brown corpus and BNC corpus.", "labels": [], "entities": [{"text": "Brown corpus", "start_pos": 156, "end_pos": 168, "type": "DATASET", "confidence": 0.9572309255599976}, {"text": "BNC corpus", "start_pos": 173, "end_pos": 183, "type": "DATASET", "confidence": 0.8353336155414581}]}, {"text": "The first balanced corpus of contemporary written Japanese (BCCWJ corpus) is now being constructed as part of a national project in Japan, and we are now constructing a sense-tagged corpus based on it.", "labels": [], "entities": [{"text": "BCCWJ corpus)", "start_pos": 60, "end_pos": 73, "type": "DATASET", "confidence": 0.8867307106653849}]}, {"text": "Therefore, the task will use the first balanced Japanese sense-tagged corpus.", "labels": [], "entities": []}, {"text": "Because a balanced corpus consists of documents from multiple genres, the corpus can be divided into multiple sub-corpora of a genre.", "labels": [], "entities": []}, {"text": "In supervised learning approaches on word sense disambiguation, because word sense distribution might vary across different sub-corpora, we need to take into account the genres of training and test corpora.", "labels": [], "entities": [{"text": "word sense disambiguation", "start_pos": 37, "end_pos": 62, "type": "TASK", "confidence": 0.721411128838857}]}, {"text": "Therefore, word sense disambiguation on a balanced corpus requires tackling a kind of domain (genre) adaptation problem (; Agirre and de Lacalle, 2008).", "labels": [], "entities": [{"text": "word sense disambiguation", "start_pos": 11, "end_pos": 36, "type": "TASK", "confidence": 0.7844122449556986}]}, {"text": "2. In previous WSD tasks, systems have been required to select a sense from a given set of senses in a dictionary fora word in one context (an instance).", "labels": [], "entities": [{"text": "WSD tasks", "start_pos": 15, "end_pos": 24, "type": "TASK", "confidence": 0.9252599775791168}]}, {"text": "However, the set of senses in the dictionary is not always complete.", "labels": [], "entities": []}, {"text": "New word senses sometimes appear after the dictionary has been compiled.", "labels": [], "entities": []}, {"text": "Therefore, some instances might have a sense that cannot be found in the dictionary's set.", "labels": [], "entities": []}, {"text": "The task will take into account not only the instances that have a sense in the given set but also the instances that have a sense that cannot be found in the set.", "labels": [], "entities": []}, {"text": "In the latter case, systems should output that the instances have a sense that is not in the set.", "labels": [], "entities": []}, {"text": "Training data, a corpus that consists of three genres (books, newspaper articles, and white papers) and is manually annotated with sense IDs, was also distributed to participants.", "labels": [], "entities": []}, {"text": "For the evaluation, we distributed a corpus that consists of four genres (books, newspaper articles, white papers, and documents from a Q&A site on the WWW) with marked target words as test data.", "labels": [], "entities": [{"text": "WWW", "start_pos": 152, "end_pos": 155, "type": "DATASET", "confidence": 0.5758242607116699}]}, {"text": "Participants were requested to assign one or more sense IDs to each target word, optionally with associated probabilities.", "labels": [], "entities": []}, {"text": "The number of target words was 50, with 22 nouns, 23 verbs, and 5 adjectives.", "labels": [], "entities": []}, {"text": "Fifty instances of each target word were provided, con-sisting of a total of 2,500 instances for the evaluation.", "labels": [], "entities": []}, {"text": "In what follows, section two describes the details of the data used in the Japanese WSD task.", "labels": [], "entities": [{"text": "Japanese WSD task", "start_pos": 75, "end_pos": 92, "type": "TASK", "confidence": 0.5951959490776062}]}, {"text": "Section three describes the process to construct the sense tagged data, including the analysis of an inter-annotator agreement.", "labels": [], "entities": []}, {"text": "Section four briefly introduces participating systems and section five describes their results.", "labels": [], "entities": []}, {"text": "Finally, section six concludes the paper.", "labels": [], "entities": []}], "datasetContent": [{"text": "The evaluation was returned in the following two ways: 1.", "labels": [], "entities": []}, {"text": "The outputted sense IDs were evaluated, assuming the 'new sense' as another sense ID.", "labels": [], "entities": []}, {"text": "The outputted sense IDs were compared to the given gold standard word senses, and the usual precision measure for supervised word sense disambiguation systems was computed using the scorer.", "labels": [], "entities": [{"text": "precision", "start_pos": 92, "end_pos": 101, "type": "METRIC", "confidence": 0.9991981387138367}, {"text": "word sense disambiguation", "start_pos": 125, "end_pos": 150, "type": "TASK", "confidence": 0.582088569800059}]}, {"text": "The Iwanami Kokugo Jiten has three levels for sense IDs, and we used the middle-level sense in the task.", "labels": [], "entities": [{"text": "Iwanami Kokugo Jiten", "start_pos": 4, "end_pos": 24, "type": "DATASET", "confidence": 0.9065025846163431}, {"text": "sense IDs", "start_pos": 46, "end_pos": 55, "type": "TASK", "confidence": 0.6554867625236511}]}, {"text": "Therefore, the scoring in the task was 'middle-grained scoring.'", "labels": [], "entities": []}, {"text": "2. The ability of finding the instances of new senses was evaluated, assuming the task as classifying each instance into a 'known sense' or 'new sense' class.", "labels": [], "entities": []}, {"text": "The outputted sense IDs (same as in 1.) were compared to the given gold standard word senses, and the usual accuracy for binary classification was computed, assuming all sense IDs in the dictionary were in the 'known sense' class.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 108, "end_pos": 116, "type": "METRIC", "confidence": 0.9993977546691895}]}], "tableCaptions": [{"text": " Table 1: Results: Word sense disambiguation  Precision  Baseline  0.7528  HIT-1  0.6612  JAIST-1  0.6864  JAIST-2  0.7476  JAIST-3  0.7208  MSS-1  0.6404  MSS-2  0.6384  MSS-3  0.6604  RALI-1  0.7592  RALI-2  0.7636", "labels": [], "entities": [{"text": "Word sense disambiguation", "start_pos": 19, "end_pos": 44, "type": "TASK", "confidence": 0.6172514259815216}, {"text": "Precision  Baseline  0.7528  HIT-1  0.6612", "start_pos": 46, "end_pos": 88, "type": "METRIC", "confidence": 0.617641144990921}, {"text": "JAIST-1  0.6864  JAIST-2  0.7476  JAIST-3  0.7208  MSS-1  0.6404  MSS-2  0.6384  MSS-3  0.6604  RALI-1  0.7592  RALI-2  0.7636", "start_pos": 90, "end_pos": 216, "type": "DATASET", "confidence": 0.8207693379372358}]}, {"text": " Table 2: Results: New sense detection  Accuracy Precision Recall  Baseline  0.9844  - 0  HIT-1  0.9132  0.0297 0.0769  JAIST-1  0.9512  0.0337 0.0769  JAIST-2  0.9872  1 0.1795  JAIST-3  0.9532  0.0851 0.2051  MSS-1  0.9416  0.1409 0.5385  MSS-2  0.9384  0.1338 0.5385  MSS-3  0.9652  0.2333 0.5385  RALI-1  0.9864  0.7778 0.1795  RALI-2  0.9872  0.8182 0.2308", "labels": [], "entities": [{"text": "New sense detection", "start_pos": 19, "end_pos": 38, "type": "TASK", "confidence": 0.5809883773326874}, {"text": "Accuracy Precision Recall  Baseline  0.9844  - 0  HIT-1", "start_pos": 40, "end_pos": 95, "type": "METRIC", "confidence": 0.8510811179876328}]}, {"text": " Table 3: Results for each POS (Precision): Word  sense disambiguation  Noun  Verb Adjective  Baseline 0.8255 0.6878  0.732  HIT-1  0.7436 0.5739  0.7  JAIST-1 0.7645 0.5957  0.76  JAIST-2  0.84 0.6626  0.732  JAIST-3 0.8236 0.6217  0.724  MSS-1  0.7 0.5504  0.792  MSS-2  0.6991 0.5470  0.792  MSS-3  0.7218 0.5713  0.8  RALI-1 0.8236 0.6965  0.764  RALI-2 0.8127 0.7191  0.752", "labels": [], "entities": [{"text": "Word  sense disambiguation  Noun  Verb Adjective  Baseline", "start_pos": 44, "end_pos": 102, "type": "TASK", "confidence": 0.7210296222141811}, {"text": "HIT-1", "start_pos": 125, "end_pos": 130, "type": "METRIC", "confidence": 0.7718236446380615}]}, {"text": " Table 4: Results for each POS (Accuracy): New  sense detection  Noun  Verb Adjective  Baseline  0.97 0.9948  1  HIT-1  0.8881 0.9304  0.944  JAIST-1 0.9518 0.9470  0.968  JAIST-2 0.9764 0.9948  1  JAIST-3 0.9564 0.9470  0.968  MSS-1  0.9355 0.9409  0.972  MSS-2  0.9336 0.9357  0.972  MSS-3  0.96 0.9670  0.98  RALI-1 0.9745 0.9948  1  RALI-2 0.9764 0.9948  1", "labels": [], "entities": [{"text": "HIT-1", "start_pos": 113, "end_pos": 118, "type": "METRIC", "confidence": 0.8819212913513184}]}, {"text": " Table 5: Results for entropy classes (Precision):  Word sense disambiguation  D easy  D mid D dif f", "labels": [], "entities": [{"text": "Word sense disambiguation  D", "start_pos": 52, "end_pos": 80, "type": "TASK", "confidence": 0.6016685664653778}]}, {"text": " Table 6: Results for Entropy classes (Accuracy):  New sense detection  D easy  D mid D dif f", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 39, "end_pos": 47, "type": "METRIC", "confidence": 0.9983689188957214}]}]}