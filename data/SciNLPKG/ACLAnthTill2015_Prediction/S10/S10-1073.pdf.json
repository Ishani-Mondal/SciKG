{"title": [{"text": "UC3M system: Determining the Extent, Type and Value of Time Expressions in TempEval-2", "labels": [], "entities": [{"text": "UC3M", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.8794691562652588}, {"text": "Extent", "start_pos": 29, "end_pos": 35, "type": "METRIC", "confidence": 0.9894796013832092}]}], "abstractContent": [{"text": "This paper describes the participation of Universidad Carlos III de Madrid in Task A of the TempEval-2 evaluation.", "labels": [], "entities": [{"text": "TempEval-2 evaluation", "start_pos": 92, "end_pos": 113, "type": "TASK", "confidence": 0.7222457230091095}]}, {"text": "The UC3M system was originally developed for the temporal expressions recognition and normalization (TERN task) in Spanish texts, according to the TIDES standard.", "labels": [], "entities": [{"text": "temporal expressions recognition and normalization (TERN task) in Spanish texts", "start_pos": 49, "end_pos": 128, "type": "TASK", "confidence": 0.7774052818616232}]}, {"text": "Current version supposes an almost-total refactoring of the earliest system.", "labels": [], "entities": []}, {"text": "Additionally, it has been adapted to the TimeML annotation schema and a considerable effort has been done with the aim of increasing its coverage.", "labels": [], "entities": [{"text": "TimeML annotation schema", "start_pos": 41, "end_pos": 65, "type": "DATASET", "confidence": 0.8990766604741415}]}, {"text": "It takes a rule-based design both in the identification and the resolution phases.", "labels": [], "entities": [{"text": "identification and the resolution", "start_pos": 41, "end_pos": 74, "type": "TASK", "confidence": 0.5954449400305748}]}, {"text": "It adopts an inductive approach based on the empirical study of frequency of temporal expressions in Spanish corpora.", "labels": [], "entities": []}, {"text": "Detecting the extent of the temporal expressions the system achieved a Precision/Recall of 0.90/0.87 whereas, in determining the TYPE and VALUE of those expressions, system results were 0.91 and 0.83, respectively.", "labels": [], "entities": [{"text": "Precision/Recall", "start_pos": 71, "end_pos": 87, "type": "METRIC", "confidence": 0.8825391928354899}, {"text": "TYPE", "start_pos": 129, "end_pos": 133, "type": "METRIC", "confidence": 0.9991620779037476}, {"text": "VALUE", "start_pos": 138, "end_pos": 143, "type": "METRIC", "confidence": 0.9845883250236511}]}], "introductionContent": [{"text": "The study of temporality in NLP is not anew task.", "labels": [], "entities": []}, {"text": "However, in the last years it has witnessed a huge interest.", "labels": [], "entities": []}, {"text": "Initiatives like TempEval task or the Automatic Context Extraction 1 (ACE) TERN competitions have boosted research on the field and have promoted the development of new resources to the scientific community.", "labels": [], "entities": [{"text": "Automatic Context Extraction 1 (ACE) TERN", "start_pos": 38, "end_pos": 79, "type": "TASK", "confidence": 0.7475154735147953}]}, {"text": "There are two main advantages in participating in these evaluations.", "labels": [], "entities": []}, {"text": "On the one hand it is possible to measure the systems' performance under standardized metrics, sharing datasets and other resources.", "labels": [], "entities": []}, {"text": "On the other hand, it is possible to make comparative evaluations among distinct participants looking forward the same objectives but using different approaches.", "labels": [], "entities": []}, {"text": "Until recently, most of temporally annotated corpora, as well as temporal taggers, were available in English.", "labels": [], "entities": []}, {"text": "Since languages as Spanish start to become prominent in the field it seems interesting the development of specific resources.", "labels": [], "entities": []}, {"text": "Tempeval-2 has contributed to this target in a significant way thanks to the release of annotated corpora and the publication of specific guidelines (,.", "labels": [], "entities": []}, {"text": "This paper resumes the participation of the UC3M system in the task of determining the extent and resolving the value of time expressions in texts (Task A).", "labels": [], "entities": []}, {"text": "This system was originally developed for the Spanish TERN task proposed in ACE 2007 evaluation, achieving encouraging results although it was in a early stage of development.", "labels": [], "entities": [{"text": "Spanish TERN task proposed in ACE 2007 evaluation", "start_pos": 45, "end_pos": 94, "type": "DATASET", "confidence": 0.7061300091445446}]}, {"text": "The system follows a ruled-based approach whose knowledge base has been inducted from the study of annotated temporal corpora (Vicente-.", "labels": [], "entities": []}, {"text": "A machine learning approach was initially discarded due to the limitation of annotated Spanish corpora.", "labels": [], "entities": []}, {"text": "The aims of this work were to improve the coverage of the original system and test its performance against new available datasets with a view to its integration in future domains of application.", "labels": [], "entities": []}, {"text": "Main challenges were to move to anew temporal model where interval is considered as the basic time unit as well as the isolation of the internal representation of temporal information from the annotation schema.", "labels": [], "entities": []}, {"text": "This paper is organized as follows: Section 2 describes the system operation; Section 3 presents experimentation and results; conclusions and future work are discussed in Section 4.", "labels": [], "entities": []}], "datasetContent": [{"text": "Precision and recall and f-measure are used as evaluation metrics according to the evaluation methodology ( ).", "labels": [], "entities": [{"text": "Precision", "start_pos": 0, "end_pos": 9, "type": "METRIC", "confidence": 0.9896301627159119}, {"text": "recall", "start_pos": 14, "end_pos": 20, "type": "METRIC", "confidence": 0.9969791173934937}]}, {"text": "To determine the quality of annotation, results are completed with figures concerning to the resolution of TYPE and VAL attributes.", "labels": [], "entities": [{"text": "resolution", "start_pos": 93, "end_pos": 103, "type": "METRIC", "confidence": 0.9084887504577637}, {"text": "TYPE", "start_pos": 107, "end_pos": 111, "type": "METRIC", "confidence": 0.5602643489837646}, {"text": "VAL", "start_pos": 116, "end_pos": 119, "type": "METRIC", "confidence": 0.818996787071228}]}, {"text": "Before evaluation, the system was tested on the training corpus and, once the test datasets were released, it was tested on the corpus for relations detection (tasks C-F) since it contained both files \"timex-extents.tab\" and \"timexattributes.tab\".", "labels": [], "entities": [{"text": "relations detection", "start_pos": 139, "end_pos": 158, "type": "TASK", "confidence": 0.7953275740146637}]}, {"text": "The results are shown in.", "labels": [], "entities": []}, {"text": "In results of final evaluation are presented and compared with the other participants' figures for the same task and language.", "labels": [], "entities": []}, {"text": "Since the test corpora were not aligned, further comparisons for different languages have not been proposed.", "labels": [], "entities": []}, {"text": "Our system achieved a precision rate of 90% and a recall of 87%, being the f-measure of 88%.", "labels": [], "entities": [{"text": "precision rate", "start_pos": 22, "end_pos": 36, "type": "METRIC", "confidence": 0.9736878871917725}, {"text": "recall", "start_pos": 50, "end_pos": 56, "type": "METRIC", "confidence": 0.9933937191963196}, {"text": "f-measure", "start_pos": 75, "end_pos": 84, "type": "METRIC", "confidence": 0.9734558463096619}]}, {"text": "Thus, it supposes a significant improvement over our earlier work.", "labels": [], "entities": []}, {"text": "In more, determining the value of TIMEX3 attributes the system raises good figures, obtaining the best VAL score, what means that normalization is working well.", "labels": [], "entities": [{"text": "TIMEX3", "start_pos": 34, "end_pos": 40, "type": "METRIC", "confidence": 0.728085458278656}, {"text": "VAL score", "start_pos": 103, "end_pos": 112, "type": "METRIC", "confidence": 0.97918301820755}, {"text": "normalization", "start_pos": 130, "end_pos": 143, "type": "TASK", "confidence": 0.9646551012992859}]}, {"text": "Analyzing the experimental errors several facts can be highlighted: The percentage of expressions completely and correctly recognized and normalized is good but there are some missing expressions, mainly due to their complexity (or fuzziness) and to the absence of a rule to manage them, i.e.: \"durante un largo periodo\" (during along period).", "labels": [], "entities": []}, {"text": "Errors in determining the extent of the temporal expressions were mainly due to the inclusion of prepositions or articles that precede to the kernel of the expression, i.e.: \"a corto plazo\" vs. \"corto plazo\" (in short term).", "labels": [], "entities": []}, {"text": "A number of false positives were due to some inconsistencies in the annotation of the corpus.", "labels": [], "entities": []}, {"text": "An example has been observed in fuzzy time expressions that denotes a future reference: \"el pr\u00f3ximo t\u00e9cnico\" (the next trainer) (not annotated) vs. \"el pr\u00f3ximo preparador\" (the next coach) (FUTURE_REF) Although normalization figures are good, some annotations are incorrect if their resolution implies context-aware mechanisms.", "labels": [], "entities": [{"text": "FUTURE_REF", "start_pos": 190, "end_pos": 200, "type": "METRIC", "confidence": 0.8513174255688986}]}], "tableCaptions": [{"text": " Table 3 Annotation patterns for dates", "labels": [], "entities": []}, {"text": " Table 6 Annotation patterns for times", "labels": [], "entities": []}, {"text": " Table 7 Results on training corpus", "labels": [], "entities": []}, {"text": " Table 8 Results on test corpus", "labels": [], "entities": []}]}