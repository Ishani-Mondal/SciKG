{"title": [{"text": "TANL-1: Coreference Resolution by Parse Analysis and Similarity Clustering", "labels": [], "entities": [{"text": "Coreference Resolution", "start_pos": 8, "end_pos": 30, "type": "TASK", "confidence": 0.9797629117965698}, {"text": "Parse Analysis", "start_pos": 34, "end_pos": 48, "type": "TASK", "confidence": 0.7173868715763092}]}], "abstractContent": [{"text": "Our submission to the Semeval 2010 task on coreference resolution in multiple languages is based on parse analysis and similarity clustering.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 43, "end_pos": 65, "type": "TASK", "confidence": 0.9430252015590668}, {"text": "parse analysis", "start_pos": 100, "end_pos": 114, "type": "TASK", "confidence": 0.9550281167030334}]}, {"text": "The system uses a binary classifier, based on Maximum En-tropy, to decide whether or not there is a relationship between each pair of mentions extracted from a textual document.", "labels": [], "entities": []}, {"text": "Mention detection is based on the analysis of the dependency parse tree.", "labels": [], "entities": [{"text": "Mention detection", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.8605161309242249}]}], "introductionContent": [], "datasetContent": [], "tableCaptions": [{"text": " Table 1. Gold task, Accuracy scores.", "labels": [], "entities": [{"text": "Gold task", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9467914402484894}, {"text": "Accuracy scores", "start_pos": 21, "end_pos": 36, "type": "METRIC", "confidence": 0.9711939692497253}]}, {"text": " Table 2. Regular task. Accuracy scores.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 24, "end_pos": 32, "type": "METRIC", "confidence": 0.9989006519317627}]}, {"text": " Table 3. Example of different conventions for NE and  COREF in the English corpus.", "labels": [], "entities": [{"text": "COREF", "start_pos": 55, "end_pos": 60, "type": "METRIC", "confidence": 0.9222031831741333}]}]}