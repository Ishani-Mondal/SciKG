{"title": [{"text": "COLEUR and COLSLM: A WSD approach to Multilingual Lexical Substitution, Tasks 2 and 3 SemEval 2010", "labels": [], "entities": [{"text": "COLEUR", "start_pos": 0, "end_pos": 6, "type": "METRIC", "confidence": 0.4530208110809326}, {"text": "WSD", "start_pos": 21, "end_pos": 24, "type": "TASK", "confidence": 0.9443935751914978}]}], "abstractContent": [{"text": "In this paper, we present a word sense disambiguation (WSD) based system for multilingual lexical substitution.", "labels": [], "entities": [{"text": "word sense disambiguation (WSD)", "start_pos": 28, "end_pos": 59, "type": "TASK", "confidence": 0.7484670927127203}, {"text": "multilingual lexical substitution", "start_pos": 77, "end_pos": 110, "type": "TASK", "confidence": 0.6686095396677653}]}, {"text": "Our method depends on having a WSD system for English and an automatic word alignment method.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 71, "end_pos": 85, "type": "TASK", "confidence": 0.7007525861263275}]}, {"text": "Crucially the approach relies on having parallel corpora.", "labels": [], "entities": []}, {"text": "For Task 2 (Sinha et al., 2009) we apply a supervised WSD system to derive the English word senses.", "labels": [], "entities": [{"text": "WSD", "start_pos": 54, "end_pos": 57, "type": "TASK", "confidence": 0.8917483687400818}]}, {"text": "For Task 3 (Lefever & Hoste, 2009), we apply an unsupervised approach to the training and test data.", "labels": [], "entities": []}, {"text": "Both of our systems that participated in Task 2 achieve a decent ranking among the participating systems.", "labels": [], "entities": []}, {"text": "For Task 3 we achieve the highest ranking on several of the language pairs: French, German and Italian.", "labels": [], "entities": []}], "introductionContent": [{"text": "In this paper, we present our system that was applied to the cross lingual substitution for two tasks in SEMEVAL 2010, Tasks 2 and 3.", "labels": [], "entities": [{"text": "cross lingual substitution", "start_pos": 61, "end_pos": 87, "type": "TASK", "confidence": 0.6252330442269644}, {"text": "SEMEVAL 2010", "start_pos": 105, "end_pos": 117, "type": "TASK", "confidence": 0.5650225281715393}]}, {"text": "We adopt the same approach for both tasks with some differences in the basic set-up.", "labels": [], "entities": []}, {"text": "Our basic approach relies on applying a word sense disambiguation (WSD) system to the English data that comes from a parallel corpus for English and a language of relevance to the task, language 2 (l2).", "labels": [], "entities": [{"text": "word sense disambiguation (WSD)", "start_pos": 40, "end_pos": 71, "type": "TASK", "confidence": 0.7373300840457281}]}, {"text": "Then we automatically induce the English word sense correspondences to l2.", "labels": [], "entities": []}, {"text": "Accordingly, fora given test target word, we return its equivalent l2 words assuming that we are able to disambiguate the target word in context.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Precision and Recall results per corpus on  Task 2 test set", "labels": [], "entities": [{"text": "Precision", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9912207722663879}, {"text": "Recall", "start_pos": 24, "end_pos": 30, "type": "METRIC", "confidence": 0.9874441027641296}]}, {"text": " Table 2: Results of T3-COLEUR per language on Task 3 Test set", "labels": [], "entities": []}]}