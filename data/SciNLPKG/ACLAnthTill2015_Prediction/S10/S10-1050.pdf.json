{"title": [{"text": "ECNU: Effective Semantic Relations Classification without Complicated Features or Multiple External Corpora", "labels": [], "entities": [{"text": "Semantic Relations Classification", "start_pos": 16, "end_pos": 49, "type": "TASK", "confidence": 0.6115641196568807}]}], "abstractContent": [{"text": "This paper describes our approach to the automatic identification of semantic relations between nominals in English sentences.", "labels": [], "entities": [{"text": "automatic identification of semantic relations between nominals in English sentences", "start_pos": 41, "end_pos": 125, "type": "TASK", "confidence": 0.8316863507032395}]}, {"text": "The basic idea of our strategy is to develop machine-learning classifiers which: (1) make use of class-independent features and classifier; (2) make use of a simple and effective feature set without high computational cost; (3) make no use of external annotated or unannotated corpus at all.", "labels": [], "entities": []}, {"text": "At SemEval 2010 Task 8 our system achieved an F-measure of 75.43% and a accuracy of 70.22%.", "labels": [], "entities": [{"text": "SemEval 2010 Task 8", "start_pos": 3, "end_pos": 22, "type": "TASK", "confidence": 0.573025070130825}, {"text": "F-measure", "start_pos": 46, "end_pos": 55, "type": "METRIC", "confidence": 0.9996176958084106}, {"text": "accuracy", "start_pos": 72, "end_pos": 80, "type": "METRIC", "confidence": 0.9995854496955872}]}], "introductionContent": [{"text": "Knowledge extraction of semantic relations between pairs of nominals from English text is one important application both as an end in itself and as an intermediate step in various downstream NLP applications, such as information extraction, summarization, machine translation, QA etc.", "labels": [], "entities": [{"text": "Knowledge extraction of semantic relations between pairs of nominals from English text", "start_pos": 0, "end_pos": 86, "type": "TASK", "confidence": 0.892297754685084}, {"text": "information extraction", "start_pos": 217, "end_pos": 239, "type": "TASK", "confidence": 0.8513500988483429}, {"text": "summarization", "start_pos": 241, "end_pos": 254, "type": "TASK", "confidence": 0.9888958930969238}, {"text": "machine translation", "start_pos": 256, "end_pos": 275, "type": "TASK", "confidence": 0.7829311788082123}, {"text": "QA", "start_pos": 277, "end_pos": 279, "type": "TASK", "confidence": 0.8885120749473572}]}, {"text": "It is also useful for many auxiliary tasks such as word sense disambiguation, language modeling, paraphrasing and discourse relation processing.", "labels": [], "entities": [{"text": "word sense disambiguation", "start_pos": 51, "end_pos": 76, "type": "TASK", "confidence": 0.6975108583768209}, {"text": "language modeling", "start_pos": 78, "end_pos": 95, "type": "TASK", "confidence": 0.7726186215877533}, {"text": "discourse relation processing", "start_pos": 114, "end_pos": 143, "type": "TASK", "confidence": 0.7221543987592062}]}, {"text": "In the past decade, semantic relation classification has attracted a lot of interest from researchers and a wide variety of relation classification schemes exist in the literature.", "labels": [], "entities": [{"text": "semantic relation classification", "start_pos": 20, "end_pos": 52, "type": "TASK", "confidence": 0.8420352339744568}, {"text": "relation classification", "start_pos": 124, "end_pos": 147, "type": "TASK", "confidence": 0.8084200322628021}]}, {"text": "However, most research work is quite different in definition of relations and granularities of various applications.", "labels": [], "entities": []}, {"text": "That is, there is little agreement on relation inventories.) provides anew standard benchmark for semantic relation classification to a wider community, where it defines 9 relations including CAUSE-EFFECT, COMPONENT-WHOLE, CONTENT-CONTAINER, ENTITY-DESTINATION, ENTITY-ORIGIN, INSTRUMENT-AGENCY, MEMBER-COLLECTION, MESSAGE-TOPIC, PRODUCT-PRODUCER, and a tenth pseudorelation OTHER (where relation is not one of the 9 annotated relations).", "labels": [], "entities": [{"text": "semantic relation classification", "start_pos": 98, "end_pos": 130, "type": "TASK", "confidence": 0.7300978104273478}, {"text": "OTHER", "start_pos": 375, "end_pos": 380, "type": "METRIC", "confidence": 0.9383029937744141}]}, {"text": "Unlike the previous semantic relation task in SemEval 2007 Task 4, the current evaluation provides neither query pattern for each sentence nor manually annotated word sense (in WordNet semantic) for each nominals.", "labels": [], "entities": [{"text": "SemEval 2007 Task 4", "start_pos": 46, "end_pos": 65, "type": "TASK", "confidence": 0.726430743932724}]}, {"text": "Since its initiative is to provide a more realistic real-world application design that is practical, any classification system must be usable without too much effort.", "labels": [], "entities": []}, {"text": "It needs to be easily computable.", "labels": [], "entities": []}, {"text": "So we need to take into account the following special considerations.", "labels": [], "entities": []}, {"text": "1. The extracted features for relation are expected to be easily computable.", "labels": [], "entities": []}, {"text": "That is, the steps in the feature extraction process are to be simple and direct for the purpose of reducing errors possibly introduced by many NLP tools.", "labels": [], "entities": [{"text": "feature extraction process", "start_pos": 26, "end_pos": 52, "type": "TASK", "confidence": 0.8088818987210592}]}, {"text": "Furthermore, a unified (global) feature set is setup for all relations rather than for each relation.", "labels": [], "entities": []}, {"text": "2. Most previous work at SemEval 2007 Task 4 leveraged on external theauri or corpora (whether unannotated or annotated),, and) that make the task adaption to different domains and languages more difficult, since they would not have such manually classified or annotated corpus available.", "labels": [], "entities": [{"text": "SemEval 2007 Task 4", "start_pos": 25, "end_pos": 44, "type": "TASK", "confidence": 0.7605680078268051}]}, {"text": "From a practical point of view, our system would make use of less resources.", "labels": [], "entities": []}, {"text": "Based on the above considerations, the idea of our system is to make use of external resources as less as possible.", "labels": [], "entities": []}, {"text": "The purpose of this work is twofold.", "labels": [], "entities": []}, {"text": "First, it provides an overview of our simple and effective process for this task.", "labels": [], "entities": []}, {"text": "Second, it compares different features and classification strategies for semantic relation.", "labels": [], "entities": [{"text": "semantic relation", "start_pos": 73, "end_pos": 90, "type": "TASK", "confidence": 0.851307600736618}]}, {"text": "Section 2 presents the system description.", "labels": [], "entities": []}, {"text": "Section 3 describes the results and discussions.", "labels": [], "entities": []}, {"text": "Section 4 concludes this work.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Summary of 7 system configurations and performance on the test data. Precision, Recall, F1  are macro-averaged for system's performance on 9 non-Other relations and evaluated with directionality  taken into account.", "labels": [], "entities": [{"text": "Precision", "start_pos": 79, "end_pos": 88, "type": "METRIC", "confidence": 0.9974512457847595}, {"text": "Recall", "start_pos": 90, "end_pos": 96, "type": "METRIC", "confidence": 0.9963619112968445}, {"text": "F1", "start_pos": 98, "end_pos": 100, "type": "METRIC", "confidence": 0.9904983639717102}]}, {"text": " Table 2: Performance obtained per relation on SR5 system. Precision, Recall, F1 are macro-averaged for  system's performance on 9 non-Other relations and evaluated with directionality taken into account.", "labels": [], "entities": [{"text": "Precision", "start_pos": 59, "end_pos": 68, "type": "METRIC", "confidence": 0.9984708428382874}, {"text": "Recall", "start_pos": 70, "end_pos": 76, "type": "METRIC", "confidence": 0.996645987033844}, {"text": "F1", "start_pos": 78, "end_pos": 80, "type": "METRIC", "confidence": 0.9918111562728882}]}, {"text": " Table 3: Performance of these 7 systems on the test data as a function of training set size. The four  training subsets, TD1, TD2, TD3 and TD4, have 1000, 2000, 4000 and 8000 (complete) training samples  respectively. F1 is macro-averaged for system's performance on 9 non-Other relations and evaluated  with directionality taken into account.", "labels": [], "entities": [{"text": "F1", "start_pos": 219, "end_pos": 221, "type": "METRIC", "confidence": 0.9952109456062317}]}]}