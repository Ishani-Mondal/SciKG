{"title": [], "abstractContent": [{"text": "We describe the Edinburgh information extraction system which we are currently adapting for analysis of newspaper text as part of the SYNC3 project.", "labels": [], "entities": [{"text": "Edinburgh information extraction", "start_pos": 16, "end_pos": 48, "type": "TASK", "confidence": 0.7651383777459463}, {"text": "analysis of newspaper text", "start_pos": 92, "end_pos": 118, "type": "TASK", "confidence": 0.6531275063753128}]}, {"text": "Our most recent focus is geospatial and temporal grounding of entities and it has been useful to participate in TempEval-2 to measure the performance of our system and to guide further development.", "labels": [], "entities": []}, {"text": "We took part in Tasks A and B for English.", "labels": [], "entities": []}, {"text": "1 Background The Language Technology Group (LTG) at Edin-burgh has been active in the field of information extraction (IE) fora number of years.", "labels": [], "entities": [{"text": "Edin-burgh", "start_pos": 52, "end_pos": 62, "type": "DATASET", "confidence": 0.9230906963348389}, {"text": "information extraction (IE)", "start_pos": 95, "end_pos": 122, "type": "TASK", "confidence": 0.8870463371276855}]}, {"text": "Up until recently our main focus has been in biomedical IE (Alex et al., 2008) but we have also been pursuing projects in other domains, e.g. digitised historical documents (Grover et al., 2010) and we are currently participants in the EU-funded SYNC3 project where our role is to analyse news articles and establish spatio-temporal and other relations between news events.", "labels": [], "entities": [{"text": "biomedical IE", "start_pos": 45, "end_pos": 58, "type": "TASK", "confidence": 0.5114722400903702}]}, {"text": "As a step towards this goal, we have been extending and adapting our IE pipeline to ground spatial and temporal entities.", "labels": [], "entities": [{"text": "IE", "start_pos": 69, "end_pos": 71, "type": "TASK", "confidence": 0.9644348621368408}]}, {"text": "We have developed the Edinburgh Geop-arser for georeferencing documents and have evaluated our system against the SpatialML corpus, as reported in Tobin et al.", "labels": [], "entities": [{"text": "Edinburgh Geop-arser", "start_pos": 22, "end_pos": 42, "type": "DATASET", "confidence": 0.9089151620864868}, {"text": "SpatialML corpus", "start_pos": 114, "end_pos": 130, "type": "DATASET", "confidence": 0.8232641220092773}]}, {"text": "We are currently in the process of developing a rule-based date and time grounding component and it is this component that we used for Task A, which requires systems to identify the extents of temporal named entities and provide their interpretation.", "labels": [], "entities": []}, {"text": "The TempEval-2 data also contains event entities and we have adapted the output of our in-house chunker (Grover and Tobin, 2006) to identify events for Task B, which requires systems to identify event denoting words and to compute a range of attributes for them.", "labels": [], "entities": [{"text": "TempEval-2 data", "start_pos": 4, "end_pos": 19, "type": "DATASET", "confidence": 0.8578096628189087}]}, {"text": "In future work we will adapt our machine-learning-based relation extraction component (Haddow, 2008) to recognise relations between spatial and temporal entities and event entities along the lines of the linking tasks.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 56, "end_pos": 75, "type": "TASK", "confidence": 0.7216040790081024}]}, {"text": "2 The Edinburgh IE System Our IE system is a modular pipeline system built around the LT-XML2 1 and LT-TTT2 2 toolsets.", "labels": [], "entities": [{"text": "Edinburgh IE System", "start_pos": 6, "end_pos": 25, "type": "DATASET", "confidence": 0.946770191192627}, {"text": "LT-TTT2 2 toolsets", "start_pos": 100, "end_pos": 118, "type": "DATASET", "confidence": 0.8459609746932983}]}, {"text": "Documents are converted into our internal document format and are then passed through a sequence of linguistic components which each add XML markup.", "labels": [], "entities": []}, {"text": "Early stages identify paragraphs, sentences and tokens.", "labels": [], "entities": []}, {"text": "Part-of-speech (POS) tagging is done using the C&C tagger (Curran and Clark, 2003a) and lemmatisation is done using morpha (Minnen et al., 2000).", "labels": [], "entities": [{"text": "Part-of-speech (POS) tagging", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.5608653128147125}]}, {"text": "We use both rule-based and machine-learning named entity recognition (NER) components, the former implemented using LT-TTT2 and the latter using the C&C maximum entropy NER tagger (Curran and Clark, 2003b).", "labels": [], "entities": [{"text": "machine-learning named entity recognition (NER)", "start_pos": 27, "end_pos": 74, "type": "TASK", "confidence": 0.7454627709729331}]}, {"text": "We are experimenting to find the best combination of the two different NER views but this is not an issue in the case of date and time entities since we have taken the decision to use the rule-based output for these.", "labels": [], "entities": []}, {"text": "The main motivation for this decision arises from the need to ground (provide temporal values for) these entities and the rules for the grounding are most naturally implemented as an elaboration of the rules for recognition.", "labels": [], "entities": []}, {"text": "Our IE pipeline also uses the LT-TTT2 chun-ker to provide a very shallow syntactic analysis.", "labels": [], "entities": []}, {"text": "Figure 1 shows an example of the results of processing at the point where the rule-based NER and chunker have both applied.", "labels": [], "entities": []}, {"text": "As can be seen from Figure 1, a positive feature for TempEval-2 is that the verb group analysis provides information about tense, aspect, voice, modality and polarity which translate relatively straightforwardly into the Task B attributes.", "labels": [], "entities": []}, {"text": "The noun group analysis provides verbal stem information (e.g. 1 www.ltg.ed.ac.uk/software/ltxml2 2 www.ltg.ed.ac.uk/software/lt-ttt2 333", "labels": [], "entities": []}], "introductionContent": [], "datasetContent": [{"text": "The recognition results for both timex and event extents are shown in.", "labels": [], "entities": []}, {"text": "For Task A (timex) we achieved a close balance between precision and recall, while for Task B (events) we erred towards recall at some cost to precision.", "labels": [], "entities": [{"text": "precision", "start_pos": 55, "end_pos": 64, "type": "METRIC", "confidence": 0.9993897676467896}, {"text": "recall", "start_pos": 69, "end_pos": 75, "type": "METRIC", "confidence": 0.9976093769073486}, {"text": "recall", "start_pos": 120, "end_pos": 126, "type": "METRIC", "confidence": 0.9978163242340088}, {"text": "precision", "start_pos": 143, "end_pos": 152, "type": "METRIC", "confidence": 0.9978809952735901}]}], "tableCaptions": [{"text": " Table 1. For Task A (timex)  we achieved a close balance between precision and  recall, while for Task B (events) we erred towards  recall at some cost to precision.", "labels": [], "entities": [{"text": "precision", "start_pos": 66, "end_pos": 75, "type": "METRIC", "confidence": 0.9994251728057861}, {"text": "recall", "start_pos": 81, "end_pos": 87, "type": "METRIC", "confidence": 0.9976096153259277}, {"text": "recall", "start_pos": 133, "end_pos": 139, "type": "METRIC", "confidence": 0.9980066418647766}, {"text": "precision", "start_pos": 156, "end_pos": 165, "type": "METRIC", "confidence": 0.9979590177536011}]}]}