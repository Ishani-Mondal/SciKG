{"title": [{"text": "UTDMet: Combining WordNet and Corpus Data for Argument Coercion Detection", "labels": [], "entities": [{"text": "UTDMet", "start_pos": 0, "end_pos": 6, "type": "DATASET", "confidence": 0.8313440084457397}, {"text": "Argument Coercion Detection", "start_pos": 46, "end_pos": 73, "type": "TASK", "confidence": 0.6187386016050974}]}], "abstractContent": [{"text": "This paper describes our system for the classification of argument coercion for SemEval-2010 Task 7.", "labels": [], "entities": [{"text": "classification of argument coercion", "start_pos": 40, "end_pos": 75, "type": "TASK", "confidence": 0.8338453024625778}, {"text": "SemEval-2010 Task 7", "start_pos": 80, "end_pos": 99, "type": "TASK", "confidence": 0.8614246646563212}]}, {"text": "We present two approaches to classifying an argument's semantic class, which is then compared to the predicate's expected semantic class to detect coercions.", "labels": [], "entities": [{"text": "classifying an argument's semantic class", "start_pos": 29, "end_pos": 69, "type": "TASK", "confidence": 0.8054816822210947}]}, {"text": "The first approach is based on learning the members of an arbitrary semantic class using WordNet's hy-pernymy structure.", "labels": [], "entities": []}, {"text": "The second approach leverages automatically extracted semantic parse information from a large corpus to identify similar arguments by the predicates that select them.", "labels": [], "entities": []}, {"text": "We show the results these approaches obtain on the task as well as how they can improve a traditional feature-based approach.", "labels": [], "entities": []}], "introductionContent": [{"text": "Argument coercion (a type of metonymy) occurs when the expected semantic class (relative to the a predicate) is substituted for an object of a different semantic class.", "labels": [], "entities": []}, {"text": "Metonymy is a pervasive phenomenon in language and the interpretation of metonymic expressions can impact tasks from semantic parsing () to question answering (.", "labels": [], "entities": [{"text": "semantic parsing", "start_pos": 117, "end_pos": 133, "type": "TASK", "confidence": 0.7456648051738739}, {"text": "question answering", "start_pos": 140, "end_pos": 158, "type": "TASK", "confidence": 0.8054612576961517}]}, {"text": "A seminal example in metonymy from) is: (1) The ham sandwich is waiting for his check.", "labels": [], "entities": []}, {"text": "The ARG1 for the predicate wait is typically an animate, but the \"ham sandwich\" is clearly not an animate.", "labels": [], "entities": [{"text": "ARG1", "start_pos": 4, "end_pos": 8, "type": "METRIC", "confidence": 0.7775816917419434}]}, {"text": "Rather, the argument is coerced to fulfill the predicate's typing requirement.", "labels": [], "entities": []}, {"text": "This coercion is allowed because an object that would normally fulfill the typing requirement (the customer) can be uniquely identified by an attribute (the ham sandwich he ordered).", "labels": [], "entities": []}, {"text": "SemEval-2010 Task 7 (\"Argument Selection and Coercion\") () was designed to evaluate systems that detect such coercions and provide a \"compositional history\" of argument selection relative to the predicate.", "labels": [], "entities": []}, {"text": "In order to accomplish this, an argument is annotated with both the semantic class to which it belongs (the \"source\" type) as well as the class expected by the predicate (the \"target\" type).", "labels": [], "entities": []}, {"text": "However, in the data provided, the target type was unambiguous given the lemmatized predicate, so the remainder of this paper discusses source type classification.", "labels": [], "entities": [{"text": "source type classification", "start_pos": 136, "end_pos": 162, "type": "TASK", "confidence": 0.6664574444293976}]}, {"text": "The detection of coercion is then simply performed by checking if the classified source type and target type are different.", "labels": [], "entities": []}, {"text": "In our system, we explore two approaches with separate underlying assumptions about how arbitrary semantic classes can be learned.", "labels": [], "entities": []}, {"text": "In our first approach, we assume a semantic class can be defined a priori from a set of seed terms and that WordNet is capable of defining the membership of that semantic class.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 108, "end_pos": 115, "type": "DATASET", "confidence": 0.9528695344924927}]}, {"text": "We apply the PageRank algorithm in order to weight WordNet synsets given a set of seed concepts.", "labels": [], "entities": []}, {"text": "In our second approach, we assume that arguments in the same semantic class will be selected by similar verbs.", "labels": [], "entities": []}, {"text": "We apply a statistical test to determine the most representative predicates for an argument.", "labels": [], "entities": []}, {"text": "This approach benefits from a large corpus from which we automatically extracted 200 million predicate-argument pairs.", "labels": [], "entities": []}, {"text": "The remainder of this paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 discusses our WordNet-based approach.", "labels": [], "entities": []}, {"text": "Section 3 describes our corpus approach.", "labels": [], "entities": []}, {"text": "Section 4 discusses our experiments and results.", "labels": [], "entities": []}, {"text": "Section 5 provides a conclusion and direction for future work.", "labels": [], "entities": []}, {"text": "Due to space limitations, previous work is discussed when relevant.", "labels": [], "entities": []}], "datasetContent": [{"text": "We have conducted several experiments to test the performance of the approaches outlined in Sections 2 and 3 along with additional features commonly found in information extraction literature.", "labels": [], "entities": [{"text": "information extraction", "start_pos": 158, "end_pos": 180, "type": "TASK", "confidence": 0.8165462017059326}]}, {"text": "All experiments were conducted using the SVM multiclass support vector machine library 4 .", "labels": [], "entities": [{"text": "SVM multiclass support vector machine", "start_pos": 41, "end_pos": 78, "type": "TASK", "confidence": 0.6010154128074646}]}], "tableCaptions": [{"text": " Table 1: Some of the concepts (and scores) learned  from applying PageRank to WordNet hypernyms.", "labels": [], "entities": []}, {"text": " Table 3: Ablation test of feature sets showing  micro-precision scores.", "labels": [], "entities": [{"text": "Ablation", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9917961359024048}]}, {"text": " Table 4: Results for UTDMET on SemEval-2010  Task 7.", "labels": [], "entities": [{"text": "UTDMET", "start_pos": 22, "end_pos": 28, "type": "TASK", "confidence": 0.7961679697036743}, {"text": "SemEval-2010  Task 7", "start_pos": 32, "end_pos": 52, "type": "TASK", "confidence": 0.7437249223391215}]}]}