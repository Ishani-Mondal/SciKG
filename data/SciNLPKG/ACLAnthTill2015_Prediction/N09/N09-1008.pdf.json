{"title": [{"text": "Improved Reconstruction of Protolanguage Word Forms", "labels": [], "entities": [{"text": "Improved Reconstruction of Protolanguage Word Forms", "start_pos": 0, "end_pos": 51, "type": "TASK", "confidence": 0.8569910625616709}]}], "abstractContent": [{"text": "We present an unsupervised approach to reconstructing ancient word forms.", "labels": [], "entities": [{"text": "reconstructing ancient word forms", "start_pos": 39, "end_pos": 72, "type": "TASK", "confidence": 0.8420319706201553}]}, {"text": "The present work addresses three limitations of previous work.", "labels": [], "entities": []}, {"text": "First, previous work focused on faith-fulness features, which model changes between successive languages.", "labels": [], "entities": []}, {"text": "We add marked-ness features, which model well-formedness within each language.", "labels": [], "entities": []}, {"text": "Second, we introduce universal features, which support generalizations across languages.", "labels": [], "entities": []}, {"text": "Finally, we increase the number of languages to which these methods can be applied by an order of magnitude by using improved inference methods.", "labels": [], "entities": []}, {"text": "Experiments on the reconstruction of Proto-Oceanic, Proto-Malayo-Javanic, and Classical Latin show substantial reductions in error rate, giving the best results to date.", "labels": [], "entities": [{"text": "error rate", "start_pos": 125, "end_pos": 135, "type": "METRIC", "confidence": 0.9833073616027832}]}], "introductionContent": [{"text": "A central problem in diachronic linguistics is the reconstruction of ancient languages from their modern descendants.", "labels": [], "entities": [{"text": "diachronic linguistics", "start_pos": 21, "end_pos": 43, "type": "TASK", "confidence": 0.7898932993412018}, {"text": "reconstruction of ancient languages from their modern descendants", "start_pos": 51, "end_pos": 116, "type": "TASK", "confidence": 0.8276131749153137}]}, {"text": "Here, we consider the problem of reconstructing phonological forms, given a known linguistic phylogeny and known cognate groups.", "labels": [], "entities": []}, {"text": "For example, (a) shows a collection of word forms in several Oceanic languages, all meaning to cry.", "labels": [], "entities": []}, {"text": "The ancestral form in this case has been presumed to be /taNis/ in.", "labels": [], "entities": []}, {"text": "We are interested in models which take as input many such word tuples, each representing a cognate group, along with a language tree, and induce word forms for hidden ancestral languages.", "labels": [], "entities": []}, {"text": "The traditional approach to this problem has been the comparative method, in which reconstructions are done manually using assumptions about the relative probability of different kinds of sound change.", "labels": [], "entities": []}, {"text": "There has been work attempting to automate part) or all of the process.", "labels": [], "entities": []}, {"text": "However, previous automated methods have been unable to leverage three important ideas a linguist would employ.", "labels": [], "entities": []}, {"text": "We address these omissions here, resulting in a more powerful method for automatically reconstructing ancient protolanguages.", "labels": [], "entities": []}, {"text": "First, linguists triangulate reconstructions from many languages, while past work has been limited to small numbers of languages.", "labels": [], "entities": [{"text": "linguists triangulate reconstructions", "start_pos": 7, "end_pos": 44, "type": "TASK", "confidence": 0.5923137168089548}]}, {"text": "For example, used four languages to reconstruct Proto-Malayo-Javanic (PMJ) and used two languages to reconstruct Classical Latin (La).", "labels": [], "entities": []}, {"text": "We revisit these small datasets and show that our method significantly outperforms these previous systems.", "labels": [], "entities": []}, {"text": "However, we also show that our method can be applied to a much larger data set (, reconstructing ProtoOceanic (POc) from 64 modern languages.", "labels": [], "entities": []}, {"text": "In addition, performance improves with more languages, which was not the case for previous methods.", "labels": [], "entities": []}, {"text": "Second, linguists exploit knowledge of phonological universals.", "labels": [], "entities": []}, {"text": "For example, small changes in vowel height or consonant place are more likely than large changes, and much more likely than change to arbitrarily different phonemes.", "labels": [], "entities": []}, {"text": "Ina statistical system, one could imagine either manually encoding or automatically inferring such preferences.", "labels": [], "entities": []}, {"text": "We show that both strategies are effective.", "labels": [], "entities": []}, {"text": "Finally, linguists consider not only how languages change, but also how they are internally consistent.", "labels": [], "entities": []}, {"text": "Past models described how sounds do (or, more often, do not) change between nodes in the tree.", "labels": [], "entities": []}, {"text": "To borrow broad terminology from the Optimality Theory literature), such models incorporated faithfulness features, capturing the ways in which successive forms remained similar to one another.", "labels": [], "entities": [{"text": "Optimality Theory", "start_pos": 37, "end_pos": 54, "type": "TASK", "confidence": 0.8260121643543243}]}, {"text": "However, each language has certain regular phonotactic patterns which con-strain these changes.", "labels": [], "entities": []}, {"text": "We encode such patterns using markedness features, characterizing the internal phonotactic structure of each language.", "labels": [], "entities": []}, {"text": "Faithfulness and markedness play roles analogous to the channel and language models of a noisy-channel system.", "labels": [], "entities": []}, {"text": "We show that markedness features improve reconstruction, and can be used efficiently.", "labels": [], "entities": [{"text": "reconstruction", "start_pos": 41, "end_pos": 55, "type": "TASK", "confidence": 0.9047842025756836}]}], "datasetContent": [{"text": "We performed a comprehensive set of experiments to test the new method for reconstruction outlined above.", "labels": [], "entities": []}, {"text": "In Section 5.1, we analyze in isolation the effects of varying the set of features, the number of observed languages, the topology, and the number of iterations of EM.", "labels": [], "entities": []}, {"text": "In Section 5.2 we compare performance to an oracle and to three other systems.", "labels": [], "entities": []}, {"text": "Evaluation of all methods was done by computing the Levenshtein distance between the reconstruction produced by each method and the reconstruction produced by linguists.", "labels": [], "entities": [{"text": "Levenshtein distance", "start_pos": 52, "end_pos": 72, "type": "METRIC", "confidence": 0.7295051515102386}]}, {"text": "We averaged this distance across reconstructed words to report a single number for each method.", "labels": [], "entities": []}, {"text": "We show in the average word length in each corpus; note that the Latin average is much larger, giving an explanation to the higher errors in the Romance dataset.", "labels": [], "entities": [{"text": "Romance dataset", "start_pos": 145, "end_pos": 160, "type": "DATASET", "confidence": 0.7517126202583313}]}, {"text": "The statistical significance of all performance differences are assessed using a paired t-test with significance level of 0.05.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Effects of ablation of various aspects of our  unsupervised system on mean edit distance to proto  Oceanic. -Sharing corresponds to the subset of the fea- tures in OPERATION, FAITHFULNESS and MARKEDNESS  that condition on the current language, -Topology corre- sponds to using a flat topology where the only edges in  the tree connect modern languages to proto Oceanic. The  semi-supervised system is described in the text. All dif- ferences (compared to the unsupervised full system) are  statistically significant.", "labels": [], "entities": [{"text": "OPERATION", "start_pos": 174, "end_pos": 183, "type": "METRIC", "confidence": 0.9172565937042236}, {"text": "FAITHFULNESS", "start_pos": 185, "end_pos": 197, "type": "METRIC", "confidence": 0.9972482323646545}, {"text": "MARKEDNESS", "start_pos": 202, "end_pos": 212, "type": "METRIC", "confidence": 0.9520948529243469}]}, {"text": " Table 1. In the  example shown, the reconstruction is as good as the  oracle, though off by one character (the final /s/ is  not present in any of the 32 inputs and therefore  is not reconstructed). The diagrams show, for both  the global and the local features, the expectations  of each substitution superimposed on an IPA sound  chart, as well as a list of the top changes. Darker  lines indicate higher counts. This run did not use  natural class constraints, but it can be seen that lin- guistically plausible substitutions are learned. The  global features prefer a range of voicing changes,  manner changes, adjacent vowel motion, and so on,  including mutations like /s/ to /h/ which are common  but poorly represented in a naive attribute-based nat- ural class scheme. On the other hand, the features lo- cal to the language Kwara'ae (Kw.) pick out the sub- set of these changes which are active in that branch,  such as /s/\u2192/t/ fortition.", "labels": [], "entities": []}, {"text": " Table 2: Experimental setup: number of held-out proto- word from (absolute and relative), of modern languages,  cognate sets and total observed words. The split for  BCLKG is the same as in", "labels": [], "entities": [{"text": "BCLKG", "start_pos": 167, "end_pos": 172, "type": "DATASET", "confidence": 0.6542654633522034}]}]}