{"title": [{"text": "A Local Tree Alignment-based Soft Pattern Matching Approach for Information Extraction", "labels": [], "entities": [{"text": "Local Tree Alignment-based Soft Pattern Matching Approach", "start_pos": 2, "end_pos": 59, "type": "TASK", "confidence": 0.7863566023962838}, {"text": "Information Extraction", "start_pos": 64, "end_pos": 86, "type": "TASK", "confidence": 0.7563404142856598}]}], "abstractContent": [{"text": "This paper presents anew soft pattern matching method which aims to improve the recall with minimized precision loss in information extraction tasks.", "labels": [], "entities": [{"text": "soft pattern matching", "start_pos": 25, "end_pos": 46, "type": "TASK", "confidence": 0.634920746088028}, {"text": "recall", "start_pos": 80, "end_pos": 86, "type": "METRIC", "confidence": 0.9992623925209045}, {"text": "precision loss", "start_pos": 102, "end_pos": 116, "type": "METRIC", "confidence": 0.9785267412662506}, {"text": "information extraction", "start_pos": 120, "end_pos": 142, "type": "TASK", "confidence": 0.7623414099216461}]}, {"text": "Our approach is based on a local tree alignment algorithm, and an effective strategy for controlling flexibility of the pattern matching will be presented.", "labels": [], "entities": []}, {"text": "The experimental results show that the method can significantly improve the information extraction performance.", "labels": [], "entities": [{"text": "information extraction", "start_pos": 76, "end_pos": 98, "type": "TASK", "confidence": 0.8805829286575317}]}], "introductionContent": [{"text": "The goal of information extraction (IE) is to extract structured information from unstructured natural language documents.", "labels": [], "entities": [{"text": "information extraction (IE)", "start_pos": 12, "end_pos": 39, "type": "TASK", "confidence": 0.8742835640907287}]}, {"text": "Pattern induction to generate extraction patterns from a number of training instances is one of the most widely applied approaches for IE.", "labels": [], "entities": [{"text": "Pattern induction", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.8926580250263214}, {"text": "IE", "start_pos": 135, "end_pos": 137, "type": "TASK", "confidence": 0.994117021560669}]}, {"text": "A number of pattern induction approaches have recently been researched based on the dependency analysis (Yangarber, 2003) () () (.", "labels": [], "entities": [{"text": "pattern induction", "start_pos": 12, "end_pos": 29, "type": "TASK", "confidence": 0.7586152255535126}]}, {"text": "The natural language texts in training instances are parsed by dependency analyzer and converted into dependency trees.", "labels": [], "entities": []}, {"text": "Each subtree of a dependency tree is considered as a candidate of extraction patterns.", "labels": [], "entities": []}, {"text": "An extraction pattern is generated by selecting the subtree which indicates the dependency relationships of each labeled slot value in the training instance and agrees on the selection criteria defined by each pattern representation model.", "labels": [], "entities": []}, {"text": "A number of dependency tree-based pattern representation models have been proposed.", "labels": [], "entities": [{"text": "dependency tree-based pattern representation", "start_pos": 12, "end_pos": 56, "type": "TASK", "confidence": 0.6132508888840675}]}, {"text": "The predicate-argument (SVO) model allows subtrees containing only a verb and its direct subject and object as extraction pattern candidates).", "labels": [], "entities": []}, {"text": "The chain model represents extraction patterns as a chain-shaped path from each target slot value to the root node of the dependency tree (.", "labels": [], "entities": []}, {"text": "A couple of chain model patterns sharing the same verb are linked to each other and construct a linked-chain model pattern ().", "labels": [], "entities": []}, {"text": "The subtree model considers all subtrees as pattern candidates (.", "labels": [], "entities": []}, {"text": "Regardless of the applied pattern representation model, the methods have concentrated on extracting only exactly equivalent subtrees of test instances to the extraction patterns, which we call hard pattern matching.", "labels": [], "entities": [{"text": "hard pattern matching", "start_pos": 193, "end_pos": 214, "type": "TASK", "confidence": 0.7313873767852783}]}, {"text": "While the hard pattern matching policy is helpful to improve the precision of the extracted results, it can cause the low recall problem.", "labels": [], "entities": [{"text": "hard pattern matching", "start_pos": 10, "end_pos": 31, "type": "TASK", "confidence": 0.6453551252683004}, {"text": "precision", "start_pos": 65, "end_pos": 74, "type": "METRIC", "confidence": 0.9981372356414795}, {"text": "recall", "start_pos": 122, "end_pos": 128, "type": "METRIC", "confidence": 0.9993808269500732}]}, {"text": "In order to tackle this problem, a number of soft pattern matching approaches which aim to improve recall with minimized precision loss have been applied to the linear vector pattern models by introducing a probabilistic model () or a sequence alignment algorithm (.", "labels": [], "entities": [{"text": "soft pattern matching", "start_pos": 45, "end_pos": 66, "type": "TASK", "confidence": 0.7158507506052653}, {"text": "recall", "start_pos": 99, "end_pos": 105, "type": "METRIC", "confidence": 0.9974473714828491}, {"text": "precision loss", "start_pos": 121, "end_pos": 135, "type": "METRIC", "confidence": 0.9872747957706451}, {"text": "sequence alignment", "start_pos": 235, "end_pos": 253, "type": "TASK", "confidence": 0.6659324020147324}]}, {"text": "In this paper, we propose an alternative soft pattern matching method for IE based on a local tree alignment algorithm.", "labels": [], "entities": [{"text": "soft pattern matching", "start_pos": 41, "end_pos": 62, "type": "TASK", "confidence": 0.69817586739858}, {"text": "IE", "start_pos": 74, "end_pos": 76, "type": "TASK", "confidence": 0.9920416474342346}]}, {"text": "While other soft pattern matching approaches have been able to handle the matching among linear vector instances with features from tree structures only, our method aims to directly solve the low recall problem of tree-to-tree pattern matching by introducing the local tree alignment algorithm which is widely used in bioinformatics to analyze RNA secondary structures.", "labels": [], "entities": [{"text": "soft pattern matching", "start_pos": 12, "end_pos": 33, "type": "TASK", "confidence": 0.6967872579892477}, {"text": "recall", "start_pos": 196, "end_pos": 202, "type": "METRIC", "confidence": 0.9869084358215332}]}], "datasetContent": [{"text": "In order to evaluate the effectiveness of our method, we performed an experiment for the scenario template extraction task on the management succession domain in MUC-6.", "labels": [], "entities": [{"text": "scenario template extraction", "start_pos": 89, "end_pos": 117, "type": "TASK", "confidence": 0.7505930066108704}, {"text": "MUC-6", "start_pos": 162, "end_pos": 167, "type": "DATASET", "confidence": 0.9580517411231995}]}, {"text": "The task aims to extract scenario template instances which consist of person-in, person-out, position, organization slot values from news articles about management succession events.", "labels": [], "entities": []}, {"text": "We used a modified version of the MUC-6 corpus including 599 training documents and 100 test documents described by.", "labels": [], "entities": [{"text": "MUC-6 corpus", "start_pos": 34, "end_pos": 46, "type": "DATASET", "confidence": 0.9717527627944946}]}, {"text": "While the scenario templates on the original MUC-6 corpus are labeled on each document, this version has scenario templates for each sentence.", "labels": [], "entities": [{"text": "MUC-6 corpus", "start_pos": 45, "end_pos": 57, "type": "DATASET", "confidence": 0.941211462020874}]}, {"text": "All the sentences in both training and test documents were converted into dependency trees From the dependency trees and scenario templates on the training data, we constructed pattern candidate sets for four types of pattern representation models which are SVO, chain, linked-chain, and subtree models.", "labels": [], "entities": []}, {"text": "For each pattern candidate, corresponding confidence score and optimal threshold value were computed.", "labels": [], "entities": [{"text": "confidence score", "start_pos": 42, "end_pos": 58, "type": "METRIC", "confidence": 0.9366632103919983}]}, {"text": "The pattern candidates for each pattern representation model were arranged in descending order of confidence score.", "labels": [], "entities": []}, {"text": "According to the arranged order, each pattern was matched with test documents and the extracted results were accumulated.", "labels": [], "entities": []}, {"text": "Extracted templates for test documents are evaluated by comparing with the answer templates on the test corpus.", "labels": [], "entities": []}, {"text": "The curves in show the relative performance of the pattern matching strategies for each pattern representation model.", "labels": [], "entities": [{"text": "pattern matching", "start_pos": 51, "end_pos": 67, "type": "TASK", "confidence": 0.7111465632915497}]}, {"text": "The results suggest that soft pattern matching strategy with optimal threshold values requires less number of patterns for the performance saturation than the hard pattern matching strategy for all pattern models except the SVO model.", "labels": [], "entities": [{"text": "soft pattern matching", "start_pos": 25, "end_pos": 46, "type": "TASK", "confidence": 0.6065697570641836}]}, {"text": "For the SVO model, the result of soft pattern matching strategy is equivalent to that of hard pattern matching strategy.", "labels": [], "entities": []}, {"text": "It is because most of patterns represented in SVO model are relatively shorter than those represented in other models.", "labels": [], "entities": []}, {"text": "In order to evaluate the flexibility controlling strategy, we compared the result of optimally determined threshold values with the cases of using represents the final results for all pattern representation models and threshold values.", "labels": [], "entities": []}, {"text": "For the SVO model, all the results are equivalent regardless of the threshold strategy because of extremely short length of the patterns.", "labels": [], "entities": []}, {"text": "For the other pattern models, precisions are increased and recalls are decreased by increasing the threshold.", "labels": [], "entities": [{"text": "precisions", "start_pos": 30, "end_pos": 40, "type": "METRIC", "confidence": 0.9996880292892456}, {"text": "recalls", "start_pos": 59, "end_pos": 66, "type": "METRIC", "confidence": 0.9996639490127563}]}, {"text": "The maximum performances in F-score are achieved by our optimal threshold determining strategy for all pattern representation models.", "labels": [], "entities": [{"text": "F-score", "start_pos": 28, "end_pos": 35, "type": "METRIC", "confidence": 0.9775028824806213}]}, {"text": "The experimental results of our method show the better recall than the cases of hard pattern matching and controlled precision than the cases of extremely soft pattern matching.", "labels": [], "entities": [{"text": "recall", "start_pos": 55, "end_pos": 61, "type": "METRIC", "confidence": 0.9993595480918884}, {"text": "precision", "start_pos": 117, "end_pos": 126, "type": "METRIC", "confidence": 0.9960944056510925}]}], "tableCaptions": []}