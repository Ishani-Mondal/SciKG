{"title": [{"text": "Syntactic Tree-based Relation Extraction Using a Generalization of Collins and Duffy Convolution Tree Kernel", "labels": [], "entities": [{"text": "Syntactic Tree-based Relation Extraction", "start_pos": 0, "end_pos": 40, "type": "TASK", "confidence": 0.8034266978502274}, {"text": "Collins and Duffy Convolution Tree Kernel", "start_pos": 67, "end_pos": 108, "type": "DATASET", "confidence": 0.8571097354094187}]}], "abstractContent": [{"text": "Relation extraction is a challenging task in natural language processing.", "labels": [], "entities": [{"text": "Relation extraction", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.9729732275009155}, {"text": "natural language processing", "start_pos": 45, "end_pos": 72, "type": "TASK", "confidence": 0.6357135673364004}]}, {"text": "Syntactic features are recently shown to be quite effective for relation extraction.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 64, "end_pos": 83, "type": "TASK", "confidence": 0.9611571729183197}]}, {"text": "In this paper, we generalize the state of the art syntactic convolution tree kernel introduced by Collins and Duffy.", "labels": [], "entities": []}, {"text": "The proposed generalized kernel is more flexible and customizable, and can be conveniently utilized for systematic generation of more effective application specific syntactic sub-kernels.", "labels": [], "entities": []}, {"text": "Using the generalized kernel, we will also propose a number of novel syntactic sub-kernels for relation extraction.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 95, "end_pos": 114, "type": "TASK", "confidence": 0.8838228583335876}]}, {"text": "These kernels show a remarkable performance improvement over the original Collins and Duffy kernel in the extraction of ACE-2005 relation types.", "labels": [], "entities": [{"text": "extraction of ACE-2005 relation types", "start_pos": 106, "end_pos": 143, "type": "TASK", "confidence": 0.6407172322273255}]}], "introductionContent": [{"text": "One of the contemporary demanding NLP tasks is information extraction, which is the procedure of extracting structured information such as entities, relations, and events from free text documents.", "labels": [], "entities": [{"text": "information extraction", "start_pos": 47, "end_pos": 69, "type": "TASK", "confidence": 0.7722682952880859}, {"text": "extracting structured information such as entities, relations, and events from free text documents", "start_pos": 97, "end_pos": 195, "type": "TASK", "confidence": 0.75283203125}]}, {"text": "As an information extraction sub-task, semantic relation extraction is the procedure of finding predefined semantic relations between textual entity mentions.", "labels": [], "entities": [{"text": "information extraction", "start_pos": 6, "end_pos": 28, "type": "TASK", "confidence": 0.7737107872962952}, {"text": "semantic relation extraction", "start_pos": 39, "end_pos": 67, "type": "TASK", "confidence": 0.7055820027987162}, {"text": "finding predefined semantic relations between textual entity mentions", "start_pos": 88, "end_pos": 157, "type": "TASK", "confidence": 0.6564353257417679}]}, {"text": "For instance, assuming a semantic relation with type Physical and subtype Located between an entity of type Person and another entity of type Location, the sentence \"Police arrested Mark at the airport last week.\" conveys two mentions of this relation between \"Mark\" and \"airport\" and also between \"police\" and \"airport\" that can be shown in the following format.", "labels": [], "entities": []}, {"text": "Phys.Located(Mark, airport) Phys.Located(police, airport) Relation extraction is a key step towards question answering systems by which vital structured data is acquired from underlying free text resources.", "labels": [], "entities": [{"text": "Relation extraction", "start_pos": 58, "end_pos": 77, "type": "TASK", "confidence": 0.9283365607261658}, {"text": "question answering", "start_pos": 100, "end_pos": 118, "type": "TASK", "confidence": 0.8523759841918945}]}, {"text": "Detection of protein interactions in biomedical corpora () is another valuable application of relation extraction.", "labels": [], "entities": [{"text": "Detection of protein interactions", "start_pos": 0, "end_pos": 33, "type": "TASK", "confidence": 0.8899081945419312}, {"text": "relation extraction", "start_pos": 94, "end_pos": 113, "type": "TASK", "confidence": 0.8643666505813599}]}, {"text": "Relation extraction can be approached by a standard classification learning method.", "labels": [], "entities": [{"text": "Relation extraction", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.9741058647632599}]}, {"text": "We particularly use SVM and kernel functions as our classification method.", "labels": [], "entities": []}, {"text": "A kernel is a function that calculates the inner product of two transformed vectors of a high dimensional feature space using the original feature vectors as shown in eq.", "labels": [], "entities": []}, {"text": "1. Kernel functions can implicitly capture a large amount of features efficiently; thus, they have been widely used in various NLP tasks.", "labels": [], "entities": []}, {"text": "Various types of features have been exploited so far for relation extraction.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 57, "end_pos": 76, "type": "TASK", "confidence": 0.9533470869064331}]}, {"text": "In () sequence of words features are utilized using a sub-sequence kernel.", "labels": [], "entities": []}, {"text": "In () dependency graph features are exploited, and in () syntactic features are employed for relation extraction.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 93, "end_pos": 112, "type": "TASK", "confidence": 0.8912816047668457}]}, {"text": "Although in order to achieve the best performance, it is necessary to use a proper combination of these features (, in this paper, we will concentrate on how to better capture the syntactic features for relation extraction.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 203, "end_pos": 222, "type": "TASK", "confidence": 0.900150865316391}]}, {"text": "In CD'01) a convolution syntactic tree kernel is proposed that generally measures the syntactic similarity between parse trees.", "labels": [], "entities": []}, {"text": "In this paper, a generalized version of CD'01 convolution tree kernel is proposed by associating generic weights to the nodes and sub-trees of the parse tree.", "labels": [], "entities": []}, {"text": "These weights can be used to incorporate domain knowledge into the kernel and make it more flexible and customizable.", "labels": [], "entities": []}, {"text": "The generalized kernel can be conveniently used to generate a variety of syntactic sub-kernels (including the original CD'01 kernel), by adopting appropriate weighting mechanisms.", "labels": [], "entities": []}, {"text": "As a result, in this paper, novel syntactic subkernels are generated from the generalized kernel for the task of relation extraction.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 113, "end_pos": 132, "type": "TASK", "confidence": 0.8611811697483063}]}, {"text": "Evaluations demonstrate that these kernels outperform the original CD'01 kernel in the extraction of ACE-2005 main relation types The remainder of this paper is structured as follows.", "labels": [], "entities": []}, {"text": "In section 2, the most related works are briefly reviewed.", "labels": [], "entities": []}, {"text": "In section 3, CD'01 tree kernel is described.", "labels": [], "entities": [{"text": "CD'01 tree kernel", "start_pos": 14, "end_pos": 31, "type": "DATASET", "confidence": 0.9025610685348511}]}, {"text": "The proposed generalized convolution tree kernel is explained in section 4 and its produced sub-kernels for relation extraction are illustrated in section 5.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 108, "end_pos": 127, "type": "TASK", "confidence": 0.8337866365909576}]}, {"text": "The experimental results are discussed in section 6.", "labels": [], "entities": []}, {"text": "Our work is concluded in section 7 and some possible future works are presented in section 8.", "labels": [], "entities": []}], "datasetContent": [{"text": "The proposed kernels are evaluated on ACE-2005 multilingual corpus ().", "labels": [], "entities": [{"text": "ACE-2005 multilingual corpus", "start_pos": 38, "end_pos": 66, "type": "DATASET", "confidence": 0.9023834466934204}]}, {"text": "In order to avoid parsing problems, the more formal parts of the corpus in \"news wire\" and \"broadcast news\" sections are used for evaluation as in ().", "labels": [], "entities": [{"text": "parsing", "start_pos": 18, "end_pos": 25, "type": "TASK", "confidence": 0.9784525036811829}]}, {"text": "We have used LIBSVM (Chang and Lin 2001) java source for the SVM classification and Stanford NLP package 1 for tokenization, sentence segmentation and parsing.", "labels": [], "entities": [{"text": "SVM classification", "start_pos": 61, "end_pos": 79, "type": "TASK", "confidence": 0.8106318116188049}, {"text": "Stanford NLP package 1", "start_pos": 84, "end_pos": 106, "type": "DATASET", "confidence": 0.9002334475517273}, {"text": "tokenization", "start_pos": 111, "end_pos": 123, "type": "TASK", "confidence": 0.9665766954421997}, {"text": "sentence segmentation", "start_pos": 125, "end_pos": 146, "type": "TASK", "confidence": 0.72956383228302}]}, {"text": "Following, every pair of entities within a sentence is regarded as a negative relation instance unless it is annotated as a positive relation in the corpus.", "labels": [], "entities": []}, {"text": "The total number of negative training instances, constructed in this way, is about 20 times more than the number of annotated positive instances.", "labels": [], "entities": []}, {"text": "Thus, we also imposed the restriction of maximum argument distance of 10 words.", "labels": [], "entities": []}, {"text": "This constraint eliminates half of the negative constructed instances while slightly decreases positive instances.", "labels": [], "entities": []}, {"text": "Nevertheless, since the resulted training set is still unbalanced, we used LIBSVM weighting mechanism.", "labels": [], "entities": [{"text": "LIBSVM", "start_pos": 75, "end_pos": 81, "type": "METRIC", "confidence": 0.6257017254829407}]}, {"text": "Precisely, if there are P positive and N negative instances in the training set, a weight value of P N / is used for positive instances while the default weight value of 1 is used for negative ones.", "labels": [], "entities": []}, {"text": "A binary SVM is trained for every relation type separately, and type compatible annotated and constructed relation instances are used to train it.", "labels": [], "entities": []}, {"text": "For each relation type, only type compatible relation instances are exploited for training.", "labels": [], "entities": []}, {"text": "For example to learn an ORG-AFF relation (which applies to (PER, ORG) or (ORG, ORG) argument types) it is meaningless to use a relation instance between two entities of type PERSON.", "labels": [], "entities": []}, {"text": "Moreover, the total number of training instances used for training every relation type is restricted to 5000 instances to shorten the duration of the evaluation process.", "labels": [], "entities": []}, {"text": "The reported results are achieved using a 5-fold cross validation method.", "labels": [], "entities": []}, {"text": "The kernels AAP, AAPD and TSAAPD-0 (TSAAPD with threshold = 0) and TSAAPD-1 (TSAAPD with threshold = 1) are compared with CD'01 convolution tree kernel.", "labels": [], "entities": [{"text": "AAP", "start_pos": 12, "end_pos": 15, "type": "METRIC", "confidence": 0.8584853410720825}, {"text": "AAPD", "start_pos": 17, "end_pos": 21, "type": "METRIC", "confidence": 0.7796311378479004}, {"text": "TSAAPD-0", "start_pos": 26, "end_pos": 34, "type": "METRIC", "confidence": 0.7578091025352478}, {"text": "TSAAPD-1", "start_pos": 67, "end_pos": 75, "type": "METRIC", "confidence": 0.5657323002815247}]}, {"text": "All the kernels 1 http://nlp.stanford.edu/software/index.shtml except for AAP are computed on the PT portion described in section 2.", "labels": [], "entities": [{"text": "AAP", "start_pos": 74, "end_pos": 77, "type": "METRIC", "confidence": 0.5585138201713562}, {"text": "PT portion", "start_pos": 98, "end_pos": 108, "type": "DATASET", "confidence": 0.7318121194839478}]}, {"text": "AAP is computed over the MCT tree portion which is also proposed by) and is the sub-tree rooted at the first common ancestor of relation arguments.", "labels": [], "entities": [{"text": "AAP", "start_pos": 0, "end_pos": 3, "type": "METRIC", "confidence": 0.8284215927124023}, {"text": "MCT tree", "start_pos": 25, "end_pos": 33, "type": "DATASET", "confidence": 0.8502770960330963}]}, {"text": "For the proposed kernels \u03b1 is set to 0.44 which is tuned on a development set that contained 5000 instances of type PHYS.", "labels": [], "entities": []}, {"text": "The \u03bb parameter of CD'01 kernel is set to 0.4 according to).", "labels": [], "entities": []}, {"text": "The C parameter of SVM classification is set to 2.4 for all the kernels after tuning it individually for each kernel on the mentioned development set.", "labels": [], "entities": [{"text": "SVM classification", "start_pos": 19, "end_pos": 37, "type": "TASK", "confidence": 0.9093645513057709}]}, {"text": "The results of the experiments are shown in.", "labels": [], "entities": []}, {"text": "The proposed kernels outperform the original CD'01 kernel in four of the six relation types.", "labels": [], "entities": []}, {"text": "The performance of TSAAPD-1 is especially remarkable because it is the best kernel in ORG-AFF and PER-SOC relations.", "labels": [], "entities": [{"text": "TSAAPD-1", "start_pos": 19, "end_pos": 27, "type": "DATASET", "confidence": 0.47946086525917053}, {"text": "ORG-AFF", "start_pos": 86, "end_pos": 93, "type": "METRIC", "confidence": 0.9537994265556335}]}, {"text": "It particularly performs very well in the extraction of PER-SOC relation with an F 1 -measure of 0.73.", "labels": [], "entities": [{"text": "PER-SOC", "start_pos": 56, "end_pos": 63, "type": "METRIC", "confidence": 0.832732081413269}, {"text": "F 1 -measure", "start_pos": 81, "end_pos": 93, "type": "METRIC", "confidence": 0.9289165139198303}]}, {"text": "It should be noted that the general low performance of all the kernels on the GEN-AFF type is because of its extremely small number of annotated instances in the training set (40 in 5000).", "labels": [], "entities": [{"text": "GEN-AFF type", "start_pos": 78, "end_pos": 90, "type": "DATASET", "confidence": 0.8929489254951477}]}, {"text": "The AAPD kernel has the best performance with a remarkable improvement over the Collins kernel in GEN-AFF relation type.", "labels": [], "entities": [{"text": "AAPD kernel", "start_pos": 4, "end_pos": 15, "type": "DATASET", "confidence": 0.8765802085399628}, {"text": "Collins kernel", "start_pos": 80, "end_pos": 94, "type": "DATASET", "confidence": 0.948870062828064}, {"text": "GEN-AFF relation type", "start_pos": 98, "end_pos": 119, "type": "TASK", "confidence": 0.6943135062853495}]}, {"text": "The results clearly demonstrate that the nodes closer to the ancestor path of relation arguments contain the most useful syntactic features for relation extraction", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 144, "end_pos": 163, "type": "TASK", "confidence": 0.904361367225647}]}], "tableCaptions": [{"text": " Table 1: The F 1 -Measure value is shown for every kernel on each ACE-2005 main relation type. For every relation  type the best result is shown in bold font.", "labels": [], "entities": [{"text": "F 1 -Measure value", "start_pos": 14, "end_pos": 32, "type": "METRIC", "confidence": 0.9593523502349853}, {"text": "ACE-2005 main relation type", "start_pos": 67, "end_pos": 94, "type": "DATASET", "confidence": 0.8770462721586227}]}]}