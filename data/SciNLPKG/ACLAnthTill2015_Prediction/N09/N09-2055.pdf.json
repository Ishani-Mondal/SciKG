{"title": [{"text": "Statistical Post-Editing of a Rule-Based Machine Translation System *", "labels": [], "entities": [{"text": "Rule-Based Machine Translation", "start_pos": 30, "end_pos": 60, "type": "TASK", "confidence": 0.615726480881373}]}], "abstractContent": [{"text": "Automatic post-editing (APE) systems aim at correcting the output of machine translation systems to produce better quality translations, i.e. produce translations can be manually post-edited with an increase in productivity.", "labels": [], "entities": [{"text": "Automatic post-editing (APE)", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.6097790241241455}]}, {"text": "In this work, we present an APE system that uses statistical models to enhance a commercial rule-based machine translation (RBMT) system.", "labels": [], "entities": [{"text": "APE", "start_pos": 28, "end_pos": 31, "type": "TASK", "confidence": 0.8866232633590698}, {"text": "rule-based machine translation (RBMT)", "start_pos": 92, "end_pos": 129, "type": "TASK", "confidence": 0.8181362350781759}]}, {"text": "In addition, a procedure for effortless human evaluation has been established.", "labels": [], "entities": [{"text": "human evaluation", "start_pos": 40, "end_pos": 56, "type": "TASK", "confidence": 0.5424828380346298}]}, {"text": "We have tested the APE system with two corpora of different complexity.", "labels": [], "entities": [{"text": "APE", "start_pos": 19, "end_pos": 22, "type": "TASK", "confidence": 0.4888969361782074}]}, {"text": "For the Parliament corpus, we show that the APE system significantly complements and improves the RBMT system.", "labels": [], "entities": [{"text": "Parliament corpus", "start_pos": 8, "end_pos": 25, "type": "DATASET", "confidence": 0.9222161173820496}, {"text": "RBMT system", "start_pos": 98, "end_pos": 109, "type": "DATASET", "confidence": 0.7810556590557098}]}, {"text": "Results for the Protocols corpus, although less conclusive, are promising as well.", "labels": [], "entities": [{"text": "Protocols corpus", "start_pos": 16, "end_pos": 32, "type": "DATASET", "confidence": 0.7819125354290009}]}, {"text": "Finally, several possible sources of errors have been identified which will help develop future system enhancements.", "labels": [], "entities": []}], "introductionContent": [{"text": "Current machine translation systems are far from perfect.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 8, "end_pos": 27, "type": "TASK", "confidence": 0.740829586982727}]}, {"text": "To achieve high-quality output, the raw translations they generate often need to be corrected, or post-edited by human translators.", "labels": [], "entities": []}, {"text": "One way of increasing the productivity of the whole process is the development of automatic post-editing (APE) systems ().", "labels": [], "entities": []}, {"text": "Many of these works propose a combination of rule-based machine translation (RBMT) and statistical machine translation (SMT) systems, in order to take advantage of the particular capabilities of each system.", "labels": [], "entities": [{"text": "rule-based machine translation (RBMT)", "start_pos": 45, "end_pos": 82, "type": "TASK", "confidence": 0.7952616711457571}, {"text": "statistical machine translation (SMT)", "start_pos": 87, "end_pos": 124, "type": "TASK", "confidence": 0.7846355388561884}]}, {"text": "A possible combination is to automatically postedit the output of a RBMT system employing a SMT system.", "labels": [], "entities": [{"text": "SMT", "start_pos": 92, "end_pos": 95, "type": "TASK", "confidence": 0.9577028155326843}]}, {"text": "In this work, we will apply this technique into two different corpora: Parliament and Protocols.", "labels": [], "entities": []}, {"text": "In addition, we will propose anew human evaluation measure that will deal with the impact of the automatic post-editing.", "labels": [], "entities": []}, {"text": "This paper is structured as follows: after a brief introduction of the RBMT, SMT, and APE systems in Section 2, Section 3 details the carried out experimentation, discussing its results.", "labels": [], "entities": [{"text": "RBMT", "start_pos": 71, "end_pos": 75, "type": "DATASET", "confidence": 0.5427483916282654}, {"text": "SMT", "start_pos": 77, "end_pos": 80, "type": "TASK", "confidence": 0.723611056804657}]}, {"text": "Finally, some conclusions and future work are presented in Section 4.", "labels": [], "entities": []}], "datasetContent": [{"text": "We present some experiments carried out using the introduced APE system, and comparing its performance with that of the RBMT and SMT systems.", "labels": [], "entities": [{"text": "APE", "start_pos": 61, "end_pos": 64, "type": "METRIC", "confidence": 0.5426003336906433}, {"text": "RBMT", "start_pos": 120, "end_pos": 124, "type": "DATASET", "confidence": 0.7116129994392395}, {"text": "SMT", "start_pos": 129, "end_pos": 132, "type": "TASK", "confidence": 0.7566667199134827}]}, {"text": "In the experimentation, two different English-toSpanish corpora have been chosen, Parliament and Protocols, both of them provided by a professional translation agency.", "labels": [], "entities": []}, {"text": "The Parliament corpus consists of a series of documents from proceedings of parliamentary sessions, provided by a client of the translation agency involved in this work.", "labels": [], "entities": [{"text": "Parliament corpus", "start_pos": 4, "end_pos": 21, "type": "DATASET", "confidence": 0.8572446703910828}]}, {"text": "Most of the sentences are transcriptions of parliamentary speeches, and thus, with the peculiarities of the oral language.", "labels": [], "entities": []}, {"text": "Despite of the multi-topic nature of the speeches, differences in training and test perplexities indicate that the topics in test are well represented in the training set (corpus statistics in).", "labels": [], "entities": []}, {"text": "On the other hand, the Protocols corpus is a collection of medical protocols.", "labels": [], "entities": [{"text": "Protocols corpus", "start_pos": 23, "end_pos": 39, "type": "DATASET", "confidence": 0.7151831388473511}]}, {"text": "This is a more difficult task, as its statistics reflect in.", "labels": [], "entities": []}, {"text": "There are many factors that explain this complexity, such as the different companies involved in training and test sets, out-of-domain test data (see perplexity and out-of-vocabulary words), non-native authors, etc.", "labels": [], "entities": []}, {"text": "In order to assess the proposed systems, a series of measures have been considered.", "labels": [], "entities": []}, {"text": "In first place, some state-of-the-art automatic metrics have been chosen to give a first idea of the quality of the translations.", "labels": [], "entities": []}, {"text": "These translations have been also evaluated by professional translators to assess the increase of productivity when using each system.", "labels": [], "entities": []}, {"text": "The automatic assessment of the translation quality has been carried out using the BiLingual Evaluation Understudy (BLEU) (), and the Translation Error Rate (TER) ().", "labels": [], "entities": [{"text": "translation", "start_pos": 32, "end_pos": 43, "type": "TASK", "confidence": 0.9512984752655029}, {"text": "BiLingual Evaluation Understudy (BLEU)", "start_pos": 83, "end_pos": 121, "type": "METRIC", "confidence": 0.7909220407406489}, {"text": "Translation Error Rate (TER)", "start_pos": 134, "end_pos": 162, "type": "METRIC", "confidence": 0.8140256305535635}]}, {"text": "The latter takes into account the number of edits required to convert the system output into the reference.", "labels": [], "entities": []}, {"text": "Hence, this measure roughly estimates the post-edition process.", "labels": [], "entities": []}, {"text": "A new human evaluation measure has been proposed to roughly estimate the productivity increase when using each of the systems in areal scenario, grounded on previous works for human evaluation of qualitative factors . One of the desired qualities for this measure was that it should pose little effort to the human evaluator.", "labels": [], "entities": []}, {"text": "Thus, a binary measure was chosen, the suitability, where the translations are identified as suitable or not suitable.", "labels": [], "entities": []}, {"text": "A given translation is considered to be suitable if it can be manually post-edited with effort savings, i.e., the evaluator thinks that a manual post-editing will increase his productivity.", "labels": [], "entities": []}, {"text": "On the contrary, if the evaluator prefers to ignore the proposed translation and start it over, the sentence is deemed not suitable.", "labels": [], "entities": []}, {"text": "Significance of the results has been assessed by the paired bootstrap resampling method, described in.", "labels": [], "entities": []}, {"text": "It estimates how confidently the conclusion that a system outperforms another one can be drawn from a test result.", "labels": [], "entities": []}, {"text": "Rule-based translation was performed by means of a commercial RBMT system.", "labels": [], "entities": [{"text": "Rule-based translation", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.6831130385398865}]}, {"text": "On the other hand, statistical training and translation in both SMT and APE systems were carried out using the Moses toolkit ( . It should be noted that APE system was trained taking the RBMT output as source, instead of the original text.", "labels": [], "entities": [{"text": "translation", "start_pos": 44, "end_pos": 55, "type": "TASK", "confidence": 0.977207601070404}, {"text": "SMT", "start_pos": 64, "end_pos": 67, "type": "TASK", "confidence": 0.9717517495155334}, {"text": "RBMT output", "start_pos": 187, "end_pos": 198, "type": "DATASET", "confidence": 0.7651415169239044}]}, {"text": "In this way, it is able to post-edit the RBMT translations.", "labels": [], "entities": [{"text": "RBMT translations", "start_pos": 41, "end_pos": 58, "type": "DATASET", "confidence": 0.7252612709999084}]}, {"text": "Finally, the texts employed for the human evaluation were composed by 350 sentences randomly drawn from each one of the two test corpora described in this paper.", "labels": [], "entities": []}, {"text": "Two professional translators carried out the human evaluation.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Corpus statistics for Parliament and Protocols.  OOV stands for out-of-vocabulary words.", "labels": [], "entities": [{"text": "OOV", "start_pos": 59, "end_pos": 62, "type": "METRIC", "confidence": 0.9723033308982849}]}, {"text": " Table 2: Automatic evaluation for Parliament and Proto- cols tests.", "labels": [], "entities": [{"text": "Automatic", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9435229897499084}, {"text": "Parliament", "start_pos": 35, "end_pos": 45, "type": "DATASET", "confidence": 0.8590106964111328}, {"text": "Proto- cols tests", "start_pos": 50, "end_pos": 67, "type": "DATASET", "confidence": 0.8420783877372742}]}, {"text": " Table 3: Human evaluation for Parliament and Protocols  corpora. Percentage of suitable translated sentences for  each system.", "labels": [], "entities": []}]}