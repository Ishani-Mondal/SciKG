{"title": [{"text": "Using Language Modeling to Select Useful Annotation Data", "labels": [], "entities": []}], "abstractContent": [], "introductionContent": [{"text": "A data set is imbalanced when the distribution of classes in it is dominated by a single class.", "labels": [], "entities": []}, {"text": "In Word Sense Disambiguation (WSD), the classes are word senses.", "labels": [], "entities": [{"text": "Word Sense Disambiguation (WSD)", "start_pos": 3, "end_pos": 34, "type": "TASK", "confidence": 0.7638233304023743}]}, {"text": "The problem of imbalanced data is painfully familiar to WSD researchers: word senses are particularly well known for their skewed distributions that are also highly domain and corpus dependent.", "labels": [], "entities": [{"text": "WSD", "start_pos": 56, "end_pos": 59, "type": "TASK", "confidence": 0.9273142218589783}]}, {"text": "Most polysemous words have a sense that occurs in a disproportionately high number of cases and another sense that is seen very infrequently.", "labels": [], "entities": []}, {"text": "For example, the OntoNotes () sense inventory defines two senses for the verb to add.", "labels": [], "entities": []}, {"text": "Of all the instances of this verb in the OntoNotes sense-tagged corpus, 93% are the instances of the predominant sense (not the arithmetic sense!).", "labels": [], "entities": [{"text": "OntoNotes sense-tagged corpus", "start_pos": 41, "end_pos": 70, "type": "DATASET", "confidence": 0.817473848660787}]}, {"text": "Another fact: there are 4,554 total senses in the OntoNotes sense inventory for 1,713 recently released verbs.", "labels": [], "entities": []}, {"text": "Only 3,498 of them are present in the actual annotated data.", "labels": [], "entities": []}, {"text": "More than 1,000 senses (23%) are so rare that they are missing from the corpus altogether.", "labels": [], "entities": []}, {"text": "More than a third of the released verbs are missing representative instances of at least one sense.", "labels": [], "entities": []}, {"text": "In fact many of the verbs are pseudo-monosemous: even though the sense inventory defines multiple senses, only the most frequent sense is present in the actual annotated data.", "labels": [], "entities": []}, {"text": "For example, only 1 out of 8 senses of to rip is present in the data.", "labels": [], "entities": [{"text": "to rip", "start_pos": 39, "end_pos": 45, "type": "TASK", "confidence": 0.6590706259012222}]}, {"text": "The skewed nature of sense distributions is a fact of life.", "labels": [], "entities": []}, {"text": "At the same time, a large-scale annotation project like OntoNotes, whose goal is the creation of a comprehensive linguistic resource, cannot simply ignore it.", "labels": [], "entities": []}, {"text": "That a sense is rare in a corpus does not mean that it is less important to annotate a sufficient number of instances of that sense: in a different domain it can be more common and not having enough annotated instances of that sense could jeopardize the success of an automatic crossdomain WSD system.", "labels": [], "entities": []}, {"text": "For example, sense 8 of to rip (\"to import an audio file directly from CD\") is extremely popular on the web but it does not exist at all in the OntoNotes data.", "labels": [], "entities": [{"text": "OntoNotes data", "start_pos": 144, "end_pos": 158, "type": "DATASET", "confidence": 0.9640020430088043}]}, {"text": "Only the traditional sense of to swap exists in the data but not the computer science sense (\"to move apiece of program into memory\"), while the latter can conceivably be significantly more popular in technical domains.", "labels": [], "entities": []}, {"text": "In general, class imbalance complicates supervised learning.", "labels": [], "entities": []}, {"text": "This contention certainly holds for WSD.", "labels": [], "entities": [{"text": "WSD", "start_pos": 36, "end_pos": 39, "type": "TASK", "confidence": 0.8010573983192444}]}, {"text": "As an illustration, consider the verb to call, for which the OntoNotes sense inventory defines 11 senses.", "labels": [], "entities": [{"text": "OntoNotes sense inventory", "start_pos": 61, "end_pos": 86, "type": "DATASET", "confidence": 0.7900375525156657}]}, {"text": "Senses 3 and 5 are the most frequent: together they constitute 84% of the data.", "labels": [], "entities": []}, {"text": "To investigate which classes are problematic fora classifi-er, we conducted 50 supervised learning experiments.", "labels": [], "entities": []}, {"text": "In each experiment one instance of this verb was selected at random and used for testing while the rest was used for training a maximum entropy model.", "labels": [], "entities": []}, {"text": "The resulting confusion matrix shows that the model correctly classified most of the instances of the two predominant senses while misclassifying the other classes.", "labels": [], "entities": []}, {"text": "The vast majority of the errors came from confusing other senses with sense 5 which is the most frequent sense of to call.", "labels": [], "entities": []}, {"text": "Clearly, the data imbalance problem has a significant negative effect on performance.", "labels": [], "entities": []}, {"text": "Let us now envision the following realistic scenario: An annotation project receives funds to sense-tag a set of verbs in a corpus.", "labels": [], "entities": []}, {"text": "It maybe the case that some annotated data is already available for these verbs and the goal is to improve sense coverage, or no annotated data is available at all.", "labels": [], "entities": []}, {"text": "But it turns out there are only enough funds to annotate a portion (e.g. half) of the total instances.", "labels": [], "entities": []}, {"text": "The question arises how to pre-select the instances from the corpus in away that would ensure that all the senses are as well represented as possible.", "labels": [], "entities": []}, {"text": "Because some senses of these verbs are very rare, the pool of instances pre-selected for the annotation should include as many as possible instances of the rare senses.", "labels": [], "entities": []}, {"text": "Random sampling -the simplest approach -will clearly not work: the pre-selected data will contain roughly the same proportion of the rare sense instances as the original set.", "labels": [], "entities": [{"text": "Random sampling", "start_pos": 0, "end_pos": 15, "type": "TASK", "confidence": 0.7429758012294769}]}, {"text": "If random sampling is not the answer, the data must be selected in some non-uniform way, i.e. using selective sampling.", "labels": [], "entities": []}, {"text": "Active learning (e.g.) is one approach to this problem.", "labels": [], "entities": []}, {"text": "Some evidence is available () that active learning outperforms random sampling in finding the instances of rare senses.", "labels": [], "entities": []}, {"text": "However, active learning has several shortcomings: (1) it requires some annotated data to start the process; (2) it is problematic when the initial training set only contains the data fora single class (e.g. the pseudomonosemous verbs); (3) it is not always efficient in practice: In the OntoNotes project, the data is annotated by two human taggers and the disagreements are adjudicated by the third.", "labels": [], "entities": []}, {"text": "In classic active learning a single instance is labeled on each iteration This means the human taggers would have to wait on each other to tag the instance, on the adjudicator for the resolution of a possible disagreement, and finally on the system which still needs to be-retrained to select the next instance to be labeled, a time sink much greater than tagging additional instances; (4) finally, active learning may not bean option if the data selected needs to be manually pre-processed (e.g. sentence segmented, tokenized, and treebanked -as was the case with some of the OntoNotes data).", "labels": [], "entities": [{"text": "OntoNotes data", "start_pos": 577, "end_pos": 591, "type": "DATASET", "confidence": 0.9029140770435333}]}, {"text": "In this setting, on each iteration of the algorithm, the taggers have to also wait for the selected instance to be manually pre-processed before they can label it.", "labels": [], "entities": []}, {"text": "Thus, it would be significantly more convenient if all the data to be annotated could be pre-selected in advance.", "labels": [], "entities": []}, {"text": "In this paper we turn to two unsupervised methods which have the potential to achieve that goal.", "labels": [], "entities": []}, {"text": "We propose a simple language modelingbased sampling method (abbreviated as LMS) that increases the likelihood of seeing rare senses in the pre-selected data.", "labels": [], "entities": []}, {"text": "The basic approach is as follow: using language modeling we can rank the instances of the ambiguous verb according to their probability of occurrence in the corpus.", "labels": [], "entities": []}, {"text": "Because the instances of the rare senses are less frequent than the instances of the predominant sense, we can expect that there will be a higher than usual concentration of the rare sense instances among the instances that have low probabilities.", "labels": [], "entities": []}, {"text": "The method is completely unsupervised and the only resource that it requires is a Language Modeling toolkit such as SRILM), which we used in our experiments.", "labels": [], "entities": [{"text": "SRILM", "start_pos": 116, "end_pos": 121, "type": "DATASET", "confidence": 0.7145426273345947}]}, {"text": "We compare this method with a random sampling baseline and semi-supervised clustering, which can serve the same purpose.", "labels": [], "entities": []}, {"text": "We show that our method outperforms both of the competing approaches.", "labels": [], "entities": []}, {"text": "We review the relevant literature in section 2, explain the details of LMS in section 3, evaluate LMS in section 4, discuss the results in section 5, and describe our plans for future work in section 6.", "labels": [], "entities": []}], "datasetContent": [{"text": "For the evaluation, we selected two-sense verbs from the OntoNotes data that have at least 100 instances and where the share of the rare sense is less than 20%.", "labels": [], "entities": [{"text": "OntoNotes data", "start_pos": 57, "end_pos": 71, "type": "DATASET", "confidence": 0.9482346773147583}]}, {"text": "There were 11 such verbs (2,230 instances total) with the average share of the rare sense 11%.", "labels": [], "entities": []}, {"text": "Our task consists of clustering the instances of a verb into two clusters, one of which is expected to have a higher concentration of the rare senses than the other.", "labels": [], "entities": []}, {"text": "Since the rare sense cluster is of primary interest to us, we report two metrics: (1) precision: the ratio of the number of instances of the rare sense in the cluster and the total number of instances in the cluster; (2) recall: the ratio of the number of instances of the rare sense in the cluster and the total number of the rare sense instances in both clusters.", "labels": [], "entities": [{"text": "precision", "start_pos": 86, "end_pos": 95, "type": "METRIC", "confidence": 0.9993841648101807}, {"text": "recall", "start_pos": 221, "end_pos": 227, "type": "METRIC", "confidence": 0.999579131603241}]}, {"text": "Note that precision is not of primary importance for this task because the goal is not to reliably identify the instances of the rare sense but rather to group them into a cluster where the rare senses will have a higher concentration than in the original set of the candidate instances.", "labels": [], "entities": [{"text": "precision", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9990957975387573}]}, {"text": "At the same time achieving high recall is important since we want to ensure that most, if not all, of the rare senses that were present among the candidate instances are captured in the rare sense cluster.", "labels": [], "entities": [{"text": "recall", "start_pos": 32, "end_pos": 38, "type": "METRIC", "confidence": 0.9981610178947449}]}], "tableCaptions": [{"text": " Table 3. The fourth column shows the  relative size of the K-means cluster that was  seeded with the rare sense. Therefore it also de-", "labels": [], "entities": []}, {"text": " Table 3. LMS vs. K-means", "labels": [], "entities": []}]}