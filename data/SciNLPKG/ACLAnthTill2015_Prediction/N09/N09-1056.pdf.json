{"title": [{"text": "For a few dollars less: Identifying review pages sans human labels", "labels": [], "entities": [{"text": "Identifying review pages sans human labels", "start_pos": 24, "end_pos": 66, "type": "TASK", "confidence": 0.7953201333681742}]}], "abstractContent": [{"text": "We address the problem of large-scale automatic detection of online reviews without using any human labels.", "labels": [], "entities": [{"text": "large-scale automatic detection of online reviews", "start_pos": 26, "end_pos": 75, "type": "TASK", "confidence": 0.7812839448451996}]}, {"text": "We propose an efficient method that combines two basic ideas: Building a classifier from a large number of noisy examples and using the structure of the web-site to enhance the performance of this classi-fier.", "labels": [], "entities": []}, {"text": "Experiments suggest that our method is competitive against supervised learning methods that mandate expensive human effort.", "labels": [], "entities": []}], "introductionContent": [{"text": "Shoppers are migrating to the web and online reviews are playing a critical role in affecting their shopping decisions, online and offline.", "labels": [], "entities": []}, {"text": "According to two surveys published by comScore and, 81% of web users have done online research on a product at least once.", "labels": [], "entities": [{"text": "comScore", "start_pos": 38, "end_pos": 46, "type": "DATASET", "confidence": 0.9537932872772217}]}, {"text": "Among readers of online reviews, more than 70% reported that the reviews had a significant influence on their purchases.", "labels": [], "entities": []}, {"text": "Realizing this economic potential, search engines have been scrambling to cater to such user needs in innovative ways.", "labels": [], "entities": []}, {"text": "For example, in response to a product-related query, a search engine might want to surface only review pages, perhaps via a \"filter by\" option, to the user.", "labels": [], "entities": []}, {"text": "More ambitiously, they might want to dissect the reviews, segregate them into novice and expert judgments, distill sentiments, and present an aggregated \"wisdom of the crowds\" opinion to the user.", "labels": [], "entities": []}, {"text": "Identifying review pages is the indispensable enabler to fulfill any such ambition; nonetheless, this problem does not seem to have been addressed at web scale before.", "labels": [], "entities": []}, {"text": "Detecting review webpages in a few, review-only websites is an easy, manually-doable task.", "labels": [], "entities": [{"text": "Detecting review webpages", "start_pos": 0, "end_pos": 25, "type": "TASK", "confidence": 0.8923935890197754}]}, {"text": "A large fraction of the interesting review content, however, is present on pages outside such websites.", "labels": [], "entities": []}, {"text": "This is where the task becomes challenging.", "labels": [], "entities": []}, {"text": "Review pages might constitute a minority and can be buried in a multitude of ways among non-review pagesfor instance, the movie review pages in nytimes.", "labels": [], "entities": []}, {"text": "com, which are scattered among all news articles, or the product review pages in amazon.com, which are accessible from the product description page.", "labels": [], "entities": []}, {"text": "An automatic and scalable method to identify reviews is thus a practical necessity for the next-generation search engines.", "labels": [], "entities": []}, {"text": "The problem is actually more general than detecting reviews: it applies to detecting any \"horizontal\" category such as buying guides, forums, discussion boards, FAQs, etc.", "labels": [], "entities": []}, {"text": "Given the nature of these problems, it is tempting to use supervised classification.", "labels": [], "entities": [{"text": "supervised classification", "start_pos": 58, "end_pos": 83, "type": "TASK", "confidence": 0.7229551076889038}]}, {"text": "A formidable barrier is the labeling task itself since human labels need time and money.", "labels": [], "entities": [{"text": "labeling task", "start_pos": 28, "end_pos": 41, "type": "TASK", "confidence": 0.8935998380184174}]}, {"text": "On the other hand, it is easier to generate an enormous number of lowquality labeled examples through purely automatic methods.", "labels": [], "entities": []}, {"text": "This prompts the question: Can we do review detection by focusing just on the textual content of a large number of automatically obtained but low-quality labeled examples, perhaps also utilizing the site structure specific to each website?", "labels": [], "entities": [{"text": "review detection", "start_pos": 37, "end_pos": 53, "type": "TASK", "confidence": 0.7089165598154068}]}, {"text": "And how will it compare to the best supervised classification method?", "labels": [], "entities": []}, {"text": "We address these questions in this paper.", "labels": [], "entities": []}, {"text": "We propose the first end-toend method that can operate at web scale to efficiently detect review pages.", "labels": [], "entities": []}, {"text": "Our method is based on using simple URL-based clues to automatically partition a large collection of webpages into two noisy classes: One that consists mostly of review webpages and another that consists of a mixture of some review but predominantly non-review webpages (more details in Section.", "labels": [], "entities": []}, {"text": "We analyze the use of a naive Bayes classifier in this noisy setting and present a simple algorithm for review page classification.", "labels": [], "entities": [{"text": "review page classification", "start_pos": 104, "end_pos": 130, "type": "TASK", "confidence": 0.5620969235897064}]}, {"text": "We further enhance the performance of this classifier by incorporating information about the structure of the website that is manifested through the URLs of the webpages.", "labels": [], "entities": []}, {"text": "We do this by partitioning the website into clusters of webpages, where the clustering delicately balances the information in the site-unaware labels provided by the classifier in the previous step and the site structure encoded in the URL tokens; a decision tree is used to accomplish this.", "labels": [], "entities": []}, {"text": "Our classification method for noisily-labeled examples and the use of sitespecific cues to improve upon a site-independent classifier are general techniques that maybe applicable in other large-scale web analyses.", "labels": [], "entities": []}, {"text": "Experiments on 2000 hand-labeled webpages from 40 websites of varying sizes show that besides being computationally efficient, our human-labelfree method not only outperforms those based on off-the-shelf subjectivity detection but also remains competitive against the state-of-the-art supervised text classification that relies on editorial labels.", "labels": [], "entities": [{"text": "supervised text classification", "start_pos": 285, "end_pos": 315, "type": "TASK", "confidence": 0.6554255882898966}]}], "datasetContent": [{"text": "As discussed in Section 3.1, our goal is to obtain a large noisy set of positive and negative labeled examples.", "labels": [], "entities": []}, {"text": "We obtained these labels for the webpages in the training sites, S rest , which is essentially S all \\ S 40 . First, the URLs in S rest were tokenized using a unigram model based on an English dictionary; this is so that strings such as reviewoftheday are properly interpreted.", "labels": [], "entities": []}, {"text": "C + : To be labeled +1, the path-component of the URL of the webpage has to contain the token review.", "labels": [], "entities": []}, {"text": "Our assumption is that such pages are highly likely to be review pages.", "labels": [], "entities": []}, {"text": "On a uniform sample of 100 such pages in S all , 90% were found to be genuine reviews.", "labels": [], "entities": []}, {"text": "Thus, we obtained a collection of webpages with slightly noisy positive labels.", "labels": [], "entities": []}, {"text": "C \u2212 : The rest of the pages in S rest were labeled \u22121.", "labels": [], "entities": []}, {"text": "Clearly this is a noisy negative set since not all pages containing reviews have review as part of their URLs (recall the example from zagat.com); thus many pages in C \u2212 can still be reviews.", "labels": [], "entities": []}, {"text": "While the negative labels in S rest are more noisy than the positive labels, we believe most of the nonreview pages are in C \u2212 , and as most websites contain a significant number of non-review pages, the percentage of reviews in C \u2212 is smaller than that in C + (the assumption \u03b1 \u03b2 in Section 3.1).", "labels": [], "entities": []}, {"text": "We collected all the paragraphs (as defined earlier) from both C + and C \u2212 separately.", "labels": [], "entities": []}, {"text": "We eliminated duplicate paragraphs (this further mitigates the templates issue, especially for sites generated by content-management software), and trained a unigram language model as in Section 3.1.", "labels": [], "entities": []}, {"text": "The evaluations were conducted on the 1515 labeled (non-empty) pages in S 40 described in Section 4.1.", "labels": [], "entities": []}, {"text": "We report the accuracy (acc.) as well as precision (prec.), recall (rec.), and f-measure (fmeas.) for C + . Trivial baselines.", "labels": [], "entities": [{"text": "accuracy (acc.)", "start_pos": 14, "end_pos": 29, "type": "METRIC", "confidence": 0.8539669662714005}, {"text": "precision", "start_pos": 41, "end_pos": 50, "type": "METRIC", "confidence": 0.9995754361152649}, {"text": "recall (rec.)", "start_pos": 60, "end_pos": 73, "type": "METRIC", "confidence": 0.9181117564439774}]}, {"text": "Out of the 1515 labeled pages, 565 were labeled +1 and 950 were labeled \u22121.", "labels": [], "entities": []}, {"text": "Table 1 summarizes the performance of baselines that always predict one of the classes and a baseline that randomly select a class according to the class distribution S 40 . As we can see, the best accuracy is .63, the best f-measure is .54, and they cannot be achieved by the same baseline.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 198, "end_pos": 206, "type": "METRIC", "confidence": 0.9987677335739136}]}, {"text": "Before present- ing the main results of our methods, we introduce a much stronger baseline that utilizes a knowledgerich subjectivity detection package.", "labels": [], "entities": [{"text": "knowledgerich subjectivity detection", "start_pos": 107, "end_pos": 143, "type": "TASK", "confidence": 0.5524766445159912}]}], "tableCaptions": [{"text": " Table 1: Trivial baseline performances.", "labels": [], "entities": []}, {"text": " Table 2: Best performances of opf and lwd methods.", "labels": [], "entities": []}, {"text": " Table 3: Performance of our methods.", "labels": [], "entities": []}]}