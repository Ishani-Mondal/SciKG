{"title": [{"text": "Tree Linearization in English: Improving Language Model Based Approaches", "labels": [], "entities": [{"text": "Improving Language Model Based Approaches", "start_pos": 31, "end_pos": 72, "type": "TASK", "confidence": 0.7413433730602265}]}], "abstractContent": [{"text": "We compare two approaches to dependency tree linearization, a task which arises in many NLP applications.", "labels": [], "entities": [{"text": "dependency tree linearization", "start_pos": 29, "end_pos": 58, "type": "TASK", "confidence": 0.8079003294308981}]}, {"text": "The first one is the widely used 'overgenerate and rank' approach which relies exclusively on a trigram language model (LM); the second one combines language modeling with a maximum entropy classifier trained on a range of linguistic features.", "labels": [], "entities": []}, {"text": "The results provide strong support for the combined method and show that trigram LMs are appropriate for phrase linearization while on the clause level a richer representation is necessary to achieve comparable performance.", "labels": [], "entities": [{"text": "phrase linearization", "start_pos": 105, "end_pos": 125, "type": "TASK", "confidence": 0.818064421415329}]}], "introductionContent": [{"text": "To date, many natural language processing applications rely on syntactic representations and also modify them by compressing, fusing, or translating into a different language.", "labels": [], "entities": []}, {"text": "A syntactic tree emerging as a result of such operations has to be linearized to a string of words before it can be output to the end-user.", "labels": [], "entities": []}, {"text": "The simple and most widely used trigram LM has become a standard tool for tree linearization in English).", "labels": [], "entities": []}, {"text": "For languages with less rigid word order, LM-based approaches have been shown to perform poorly (e.g., for Dutch), and methods relying on a range of linguistic features have been successfully applied instead (see and, for Japanese and German resp.).", "labels": [], "entities": []}, {"text": "To our knowledge, none of the linearization studies have compared a LM-based method with an alternative.", "labels": [], "entities": []}, {"text": "Thus, it would be of interest to draw such a comparison, especially on English data, where LMs are usually expected to work well.", "labels": [], "entities": []}, {"text": "As an improvement to the LM-based approach, we propose a combined method which distinguishes between the phrase and the clause levels: \u2022 it relies on a trigram LM to order words within phrases; \u2022 it finds the order of clause constituents (i.e., constituents dependent on a finite verb) with a maximum entropy classifier trained on a range of linguistic features.", "labels": [], "entities": []}, {"text": "We show that such a differentiated approach is beneficial and that the proposed combination outperforms the method which relies solely on a LM.", "labels": [], "entities": []}, {"text": "Hence, our results challenge the widespread attitude that trigram LMs provide an appropriate way to linearize syntactic trees in English but also indicate that they perform well in linearizing subtrees corresponding to phrases.", "labels": [], "entities": []}], "datasetContent": [{"text": "The goal of our experiments is to check the following hypotheses: 1.", "labels": [], "entities": []}, {"text": "That trigram LMs are well-suited for phrase linearization.", "labels": [], "entities": [{"text": "phrase linearization", "start_pos": 37, "end_pos": 57, "type": "TASK", "confidence": 0.8169833123683929}]}, {"text": "2. That there is a considerable drop in performance when one uses them for linearization on the clause level.", "labels": [], "entities": []}, {"text": "3. That an approach which uses a richer representation on the clause level is more appropriate.", "labels": [], "entities": []}, {"text": "To test the trigram-based approach, we generate all possible permutations of clause constituents, place the verb right after the subject and then rank the resulting strings with the LM taking the information on sentence boundaries into account.", "labels": [], "entities": []}, {"text": "To test the combined approach, we find the best candidate for the first position in the clause, then put the remaining constituents in a random order, and finally sort them by consulting the second classifier.", "labels": [], "entities": []}, {"text": "The purpose of the evaluation is to assess how good a method is at reproducing the input from its dependency tree.", "labels": [], "entities": []}, {"text": "We separately evaluate the performance on the phrase and the clause levels.", "labels": [], "entities": []}, {"text": "When comparing the two methods on the clause level, we take the clause constituents as they are presented in the input sentence.", "labels": [], "entities": []}, {"text": "Although English allows for some minor variation in word order and it might happen that the generated order is not necessarily wrong if different from the original one, we do not expect this to happen often and evaluate the performance rigorously: only the original order counts as the correct one.", "labels": [], "entities": []}, {"text": "The default evaluation metric is perphrase/per-clause accuracy: Other metrics we use to measure how different a generated order of N elements is from the correct one are: where t is the minimum number of interchanges of consecutive elements to achieve the right order).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 54, "end_pos": 62, "type": "METRIC", "confidence": 0.974926769733429}]}, {"text": "2. Edit distance related di, di = 1 \u2212 m N where m is the minimum number of deletions combined with insertions to get to the right order ().", "labels": [], "entities": [{"text": "Edit distance", "start_pos": 3, "end_pos": 16, "type": "METRIC", "confidence": 0.9486963748931885}]}, {"text": "E.g., on the phrase level, the incorrectly generated phrase the all brothers of my neighbor ('1-0-2-3-4-5') gets \u03c4 = 0.87, di = 0.83.", "labels": [], "entities": []}, {"text": "Likewise, given the input sentence from (1a), the incorrectly generated order of the four clause constituents in (1c) -'1-0-2-3' -gets \u03c4 of 0.67 and di of 0.75.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Results of the trigram method on the phrase level", "labels": [], "entities": []}, {"text": " Table 2: Results of the two methods on the clause level", "labels": [], "entities": []}]}