{"title": [{"text": "Web and Corpus Methods for Malay Count Classifier Prediction", "labels": [], "entities": [{"text": "Malay Count Classifier Prediction", "start_pos": 27, "end_pos": 60, "type": "TASK", "confidence": 0.7354153469204903}]}], "abstractContent": [{"text": "We examine the capacity of Web and corpus frequency methods to predict preferred count classifiers for nouns in Malay.", "labels": [], "entities": []}, {"text": "The observed F-score for the Web model of 0.671 considerably outperformed corpus-based frequency and machine learning models.", "labels": [], "entities": [{"text": "F-score", "start_pos": 13, "end_pos": 20, "type": "METRIC", "confidence": 0.9970280528068542}]}, {"text": "We expect that this is a fruitful extension for Web-as-corpus approaches to lexicons in languages other than English, but further research is required in other SouthEast and East Asian languages.", "labels": [], "entities": [{"text": "SouthEast and East Asian languages", "start_pos": 160, "end_pos": 194, "type": "DATASET", "confidence": 0.8418610453605652}]}], "introductionContent": [{"text": "The objective of this paper is to extend a Malay lexicon with count classifier information for nominal types.", "labels": [], "entities": []}, {"text": "This is done under the umbrella of deep lexical acquisition: the process of automatically or semi-automatically learning linguistic structures for use in linguistically rich language resources such as precision grammars or wordnets.", "labels": [], "entities": [{"text": "deep lexical acquisition", "start_pos": 35, "end_pos": 59, "type": "TASK", "confidence": 0.6893074115117391}]}, {"text": "One might call Malaya \"medium-density\" language: some NLP resources exist, but substantially fewer than those for English, and they tend to be of low complexity.", "labels": [], "entities": []}, {"text": "Resources like the Web seem promising for bootstrapping further resources, aided in part by simple syntax and a Romanised orthographic system.", "labels": [], "entities": []}, {"text": "The vast size of the Web has been demonstrated to combat the data sparseness problem, for example, in.", "labels": [], "entities": []}, {"text": "We examine using a similar \"first gloss\" strategy to Lapata and Keller (akin to \"first sense\" in WSD, in this case, identifying the most basic surface form that a speaker would use to disambiguate between possible classes), where the Web is used a corpus to query a set of candidate surface forms, and the frequencies are used to disambiguate the lexical property.", "labels": [], "entities": []}, {"text": "Due to the heterogeneity of the Web, we expect to observe a significant amount of blocking from Indonesian, a language with which Malay is somewhat mutually intelligible).", "labels": [], "entities": []}, {"text": "Hence, we contrast this approach with observing the cues directly from a corpus strictly of Malay, as well as a corpus-based supervised machine learning approach which does not rely on a presupplied gloss.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Performance of the five systems.", "labels": [], "entities": []}, {"text": " Table 2: Performance of corpus frequency assignment  (Corpus in Table 1), backed-off to the other systems.", "labels": [], "entities": [{"text": "corpus frequency assignment", "start_pos": 25, "end_pos": 52, "type": "TASK", "confidence": 0.6352063020070394}]}, {"text": " Table 1. The best  F-score is observed for the Web frequency system,  which also had the highest recall. The best precision  was observed for the corpus frequency system, but  with very low recall -about 85% of the wordforms  could not be assigned to a class (the corresponding  figure for the Web system was about 9%). Conse- quently, we attempted a number of back-off strate- gies so as to improve the recall of this system.  The results for backing off the corpus frequency  system to the Web model, the two maximum entropy  models, and two baselines (the majority class, and  the semantically empty classifier) are shown in Ta- ble 2. Using a Web back-off was nearly identical to  the basic Web system: most of the correct assign- ments being made by the corpus frequency system  were also being captured through Web frequencies,  which indicates that these are the easier, high fre- quency entries. Backing off to the machine learn- ing models performed the same or slightly better  than using the machine learning model by itself. It  therefore seems that the most balanced corpus-based", "labels": [], "entities": [{"text": "F-score", "start_pos": 20, "end_pos": 27, "type": "METRIC", "confidence": 0.996000349521637}, {"text": "recall", "start_pos": 98, "end_pos": 104, "type": "METRIC", "confidence": 0.9953540563583374}, {"text": "precision", "start_pos": 115, "end_pos": 124, "type": "METRIC", "confidence": 0.9958974123001099}, {"text": "recall", "start_pos": 191, "end_pos": 197, "type": "METRIC", "confidence": 0.9945985078811646}, {"text": "recall", "start_pos": 405, "end_pos": 411, "type": "METRIC", "confidence": 0.9952935576438904}]}]}