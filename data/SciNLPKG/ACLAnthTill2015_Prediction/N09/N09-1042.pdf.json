{"title": [{"text": "Global Models of Document Structure Using Latent Permutations", "labels": [], "entities": [{"text": "Global Models of Document Structure", "start_pos": 0, "end_pos": 35, "type": "TASK", "confidence": 0.613138610124588}]}], "abstractContent": [{"text": "We present a novel Bayesian topic model for learning discourse-level document structure.", "labels": [], "entities": [{"text": "learning discourse-level document structure", "start_pos": 44, "end_pos": 87, "type": "TASK", "confidence": 0.6110395714640617}]}, {"text": "Our model leverages insights from discourse theory to constrain latent topic assignments in away that reflects the underlying organization of document topics.", "labels": [], "entities": []}, {"text": "We propose a global model in which both topic selection and ordering are biased to be similar across a collection of related documents.", "labels": [], "entities": [{"text": "topic selection", "start_pos": 40, "end_pos": 55, "type": "TASK", "confidence": 0.7576478123664856}]}, {"text": "We show that this space of orderings can be elegantly represented using a distribution over permutations called the generalized Mallows model.", "labels": [], "entities": []}, {"text": "Our structure-aware approach substantially outperforms alternative approaches for cross-document comparison and single-document segmentation.", "labels": [], "entities": [{"text": "cross-document comparison", "start_pos": 82, "end_pos": 107, "type": "TASK", "confidence": 0.7669287025928497}, {"text": "single-document segmentation", "start_pos": 112, "end_pos": 140, "type": "TASK", "confidence": 0.7329687178134918}]}], "introductionContent": [{"text": "In this paper, we introduce a novel latent topic model for the unsupervised learning of document structure.", "labels": [], "entities": []}, {"text": "Traditional topic models assume that topics are randomly spread throughout a document, or that the succession of topics in a document is Markovian.", "labels": [], "entities": []}, {"text": "In contrast, our approach takes advantage of two important discourse-level properties of text in determining topic assignments: first, that each document follows a progression of nonrecurring coherent topics; and second, that documents from the same domain tend to present similar topics, in similar orders.", "labels": [], "entities": []}, {"text": "We show that a topic model incorporating these long-range dependencies outperforms al- Code, data, and annotations used in this work are available at http://groups.csail.mit.edu/rbg/code/mallows/ ternative approaches for segmentation and crossdocument comparison.", "labels": [], "entities": [{"text": "crossdocument comparison", "start_pos": 238, "end_pos": 262, "type": "TASK", "confidence": 0.7424871623516083}]}, {"text": "For example, consider a collection of encyclopedia articles about cities.", "labels": [], "entities": []}, {"text": "The first constraint captures the notion that a single topic, such as Architecture, is expressed in a contiguous block within the document, rather than spread over disconnected sections.", "labels": [], "entities": []}, {"text": "The second constraint reflects our intuition that all of these related articles will generally mention some major topics associated with cities, such as History and Culture, and will often exhibit similar topic orderings, such as placing History before Culture.", "labels": [], "entities": []}, {"text": "We present a Bayesian latent topic model over related documents that encodes these discourse constraints by positing a single distribution over a document's entire topic structure.", "labels": [], "entities": []}, {"text": "This global view on ordering is able to elegantly encode discourse-level properties that would be difficult to represent using local dependencies, such as those induced by hidden Markov models.", "labels": [], "entities": []}, {"text": "Our model enforces that the same topic does not appear in disconnected portions of the topic sequence.", "labels": [], "entities": []}, {"text": "Furthermore, our approach biases toward selecting sequences with similar topic ordering, by modeling a distribution over the space of topic permutations.", "labels": [], "entities": []}, {"text": "Learning this ordering distribution is a key technical challenge in our proposed approach.", "labels": [], "entities": []}, {"text": "For this purpose, we employ the generalized Mallows model, a permutation distribution that concentrates probability mass on a small set of similar permutations.", "labels": [], "entities": []}, {"text": "It directly captures the intuition of the second constraint, and uses a small parameter set to control how likely individual topics are to be reordered.", "labels": [], "entities": []}, {"text": "We evaluate our model on two challenging document-level tasks.", "labels": [], "entities": []}, {"text": "In the alignment task, we aim to discover paragraphs across different documents that share the same topic.", "labels": [], "entities": []}, {"text": "We also consider the segmentation task, where the goal is to partition each document into a sequence of topically coherent segments.", "labels": [], "entities": [{"text": "segmentation task", "start_pos": 21, "end_pos": 38, "type": "TASK", "confidence": 0.9045229256153107}]}, {"text": "We find that our structure modeling approach substantially outperforms state-of-the-art baselines for both tasks.", "labels": [], "entities": [{"text": "structure modeling", "start_pos": 17, "end_pos": 35, "type": "TASK", "confidence": 0.7401734590530396}]}, {"text": "Furthermore, we demonstrate the importance of explicitly modeling a distribution over topic permutations; our model yields significantly better results than variants that either use a fixed ordering, or are order-agnostic.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Comparison of the alignments produced by our model and a series of baselines and model variations, for both  10 and 20 topics, evaluated against clean and noisy sets of section headings. Higher scores are better. Within the same  K, the methods which our model significantly outperforms are indicated with  *  for p < 0.001 and for p < 0.01.", "labels": [], "entities": []}, {"text": " Table 2: Comparison of the segmentations produced by our model and a series of baselines and model variations, for  both 10 and 20 topics, evaluated against clean and noisy sets of section headings. Lower scores are better.  \u2020BayesSeg  is given the true number of segments, so its segments count reflects the reference structure's segmentation.", "labels": [], "entities": []}]}