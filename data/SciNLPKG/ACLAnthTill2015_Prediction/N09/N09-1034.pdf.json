{"title": [{"text": "Unsupervised Constraint Driven Learning For Transliteration Discovery", "labels": [], "entities": []}], "abstractContent": [{"text": "This paper introduces a novel unsupervised constraint-driven learning algorithm for identifying named-entity (NE) transliterations in bilingual corpora.", "labels": [], "entities": [{"text": "identifying named-entity (NE) transliterations in bilingual corpora", "start_pos": 84, "end_pos": 151, "type": "TASK", "confidence": 0.7301218741469913}]}, {"text": "The proposed method does not require any annotated data or aligned corpora.", "labels": [], "entities": []}, {"text": "Instead, it is bootstrapped using a simple resource-a romanization table.", "labels": [], "entities": []}, {"text": "We show that this resource, when used in conjunction with constraints, can efficiently identify translitera-tion pairs.", "labels": [], "entities": []}, {"text": "We evaluate the proposed method on transliterating English NEs to three different languages-Chinese, Russian and Hebrew.", "labels": [], "entities": [{"text": "transliterating English NEs", "start_pos": 35, "end_pos": 62, "type": "TASK", "confidence": 0.8727547327677408}]}, {"text": "Our experiments show that constraint driven learning can significantly outperform existing unsupervised models and achieve competitive results to existing supervised models.", "labels": [], "entities": []}], "introductionContent": [{"text": "Named entity (NE) transliteration is the process of transcribing a NE from a source language to some target language while preserving its pronunciation in the original language.", "labels": [], "entities": [{"text": "Named entity (NE) transliteration", "start_pos": 0, "end_pos": 33, "type": "TASK", "confidence": 0.599423552552859}]}, {"text": "Automatic NE transliteration is an important component in many cross-language applications, such as Cross-Lingual Information Retrieval (CLIR) and Machine Translation(MT).", "labels": [], "entities": [{"text": "Automatic NE transliteration", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.6670359373092651}, {"text": "Cross-Lingual Information Retrieval (CLIR)", "start_pos": 100, "end_pos": 142, "type": "TASK", "confidence": 0.7702136238416036}, {"text": "Machine Translation(MT)", "start_pos": 147, "end_pos": 170, "type": "TASK", "confidence": 0.8540651798248291}]}, {"text": "It might initially seem that transliteration is an easy task, requiring only finding a phonetic mapping between character sets.", "labels": [], "entities": []}, {"text": "However simply matching every source language character to its target language counterpart is not likely to work well as in practice this mapping depends on the context the characters appear in and on transliteration conventions which may change across domains.", "labels": [], "entities": []}, {"text": "As a result, current approaches employ machine learning methods which, given enough labeled training data learn how to determine whether a pair of words constitute a transliteration pair.", "labels": [], "entities": []}, {"text": "These methods typically require training data and language-specific expertise which may not exist for many languages.", "labels": [], "entities": []}, {"text": "In this paper we try to overcome these difficulties and show that when the problem is modeled correctly, a simple character level mapping is a sufficient resource.", "labels": [], "entities": []}, {"text": "In our experiments, English was used as the source language, allowing us to use romanization tables, a resource commonly-available for many languages . These tables contain an incomplete mapping between character sets, mapping every character to its most common counterpart.", "labels": [], "entities": []}, {"text": "Our transliteration model takes a discriminative approach.", "labels": [], "entities": []}, {"text": "Given a word pair, the model determines if one word is a transliteration of the other.", "labels": [], "entities": []}, {"text": "The features used by this model are character n-gram matches across the two strings.", "labels": [], "entities": []}, {"text": "We enhance the initial model with constraints, by framing the feature extraction process as a structured prediction problem -given a word pair, the set of possible active features is defined as a set of latent binary variables.", "labels": [], "entities": [{"text": "feature extraction", "start_pos": 62, "end_pos": 80, "type": "TASK", "confidence": 0.7712129354476929}]}, {"text": "The contextual dependency be- tween features is encoded as a set of constraints over these variables.", "labels": [], "entities": []}, {"text": "Features are extracted by finding an assignment that maximizes the similarity score between the two strings and conforms to the constraints.", "labels": [], "entities": []}, {"text": "The model is bootstrapped using a romanization table and uses a discriminatively self-trained classifier as away to improve over several training iterations.", "labels": [], "entities": []}, {"text": "Furthermore, when specific knowledge about the source and target languages exists, it can be directly injected into the model as constraints.", "labels": [], "entities": []}, {"text": "We tested our approach on three very different languages -Russian, a Slavic language, Hebrew a Semitic language, and Chinese, a SinoTibetan language.", "labels": [], "entities": []}, {"text": "In all languages, using this simple resource in conjunction with constraints provided us with a robust transliteration system which significantly outperforms existing unsupervised approaches and achieves comparable performance to supervised methods.", "labels": [], "entities": []}, {"text": "The rest of the paper is organized as follows.", "labels": [], "entities": []}, {"text": "2 briefly examines more related work.", "labels": [], "entities": []}, {"text": "3 explains our model and Sec.", "labels": [], "entities": []}, {"text": "4 provide a linguistic intuition for it.", "labels": [], "entities": []}, {"text": "5 describes our experiments and evaluates our results followed by sec.", "labels": [], "entities": []}, {"text": "6 which concludes our paper.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section, we demonstrate the effectiveness of constraint driven learning empirically.", "labels": [], "entities": []}, {"text": "We start by describing the datasets and experimental settings and then proceed to describe the results.", "labels": [], "entities": []}, {"text": "We evaluated our method on three very different target lan-).", "labels": [], "entities": []}, {"text": "Note that one of the models proposed in () takes advantage of the temporal information.", "labels": [], "entities": []}, {"text": "Our best model, the unsupervised learning with all constraints, outperforms both models in (), even though we do not use any temporal information.", "labels": [], "entities": []}, {"text": "guages: Russian, Chinese, and Hebrew, and compared our results to previously published results.", "labels": [], "entities": []}, {"text": "In our experiments the system is evaluated on its ability to correctly identify the gold transliteration for each source word.", "labels": [], "entities": []}, {"text": "We evaluated the system's performance using two measures adopted in many transliteration works.", "labels": [], "entities": []}, {"text": "The first one is Mean Reciprocal Rank (MRR), used in ( ), which is the average of the multiplicative inverse of the rank of the correct answer.", "labels": [], "entities": [{"text": "Mean Reciprocal Rank (MRR)", "start_pos": 17, "end_pos": 43, "type": "METRIC", "confidence": 0.9636634588241577}]}, {"text": "Formally, Let n be the number of source NEs.", "labels": [], "entities": []}, {"text": "Let GoldRank(i) be the rank the algorithm assigns to the correct transliteration.", "labels": [], "entities": [{"text": "GoldRank", "start_pos": 4, "end_pos": 12, "type": "DATASET", "confidence": 0.7210355401039124}]}, {"text": "Then, MRR is defined by: Another measure is Accuracy (ACC) used in, which is the percentage of the top rank candidates being the gold transliteration.", "labels": [], "entities": [{"text": "MRR", "start_pos": 6, "end_pos": 9, "type": "METRIC", "confidence": 0.7838227152824402}, {"text": "Accuracy (ACC)", "start_pos": 44, "end_pos": 58, "type": "METRIC", "confidence": 0.9767521917819977}]}, {"text": "In our implementation we used the support vector machine (SVM) learning algorithm with linear kernel as our underlying learning algorithm (mentioned in part 2.5 of Algorithm 1) . We used the package LIB-LINEAR () in our experiments.", "labels": [], "entities": []}, {"text": "Through all of our experiments, we used the 2-norm hinge loss as our loss function and fixed the regularization parameter C to be 0.5.", "labels": [], "entities": []}, {"text": "We experimented using three different target languages Russian, Chinese, and Hebrew.", "labels": [], "entities": []}, {"text": "We used English as the source language in all these experiments.", "labels": [], "entities": []}, {"text": "The Russian data set 2 , originally introduced in (), is comprised of temporally aligned news articles.", "labels": [], "entities": [{"text": "Russian data set 2", "start_pos": 4, "end_pos": 22, "type": "DATASET", "confidence": 0.8973880261182785}]}, {"text": "The dataset contains 727 single word English NEs with a corresponding set of 50,648 potential Russian candidate words which include not only name entities, but also other words appearing in the news articles.", "labels": [], "entities": []}, {"text": "The Chinese dataset is taken directly from an English-Chinese transliteration dictionary, derived from LDC Gigaword corpus 3 . The entire dictionary consists of 74,396 pairs of English-Chinese NEs, where Chinese NEs are written in Pinyin, a romanized spelling system of Chinese.", "labels": [], "entities": [{"text": "LDC Gigaword corpus 3", "start_pos": 103, "end_pos": 124, "type": "DATASET", "confidence": 0.8567677289247513}]}, {"text": "In ( ) a dataset which contains about 600 English NEs and 700 Chinese candidates is used.", "labels": [], "entities": []}, {"text": "Since the dataset is not publicly available, we created a dataset in a similar way.", "labels": [], "entities": []}, {"text": "We randomly selected approximately 600 NE pairs and then added about 100 candidates which do not correspond to any of the English NE  is our method, KR'06 is described in () and GR'08 in.", "labels": [], "entities": [{"text": "GR'08", "start_pos": 178, "end_pos": 183, "type": "METRIC", "confidence": 0.9199079871177673}]}, {"text": "Note that our results for Hebrew are comparable with a supervised system.", "labels": [], "entities": []}, {"text": "The Hebrew dataset, originally introduced in (), consists of 300 English-Hebrew pairs extracted from Wikipedia.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Comparison to previously published results. UCDL", "labels": [], "entities": [{"text": "UCDL", "start_pos": 54, "end_pos": 58, "type": "DATASET", "confidence": 0.9733389616012573}]}]}