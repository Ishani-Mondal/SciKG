{"title": [{"text": "Preference Grammars: Softening Syntactic Constraints to Improve Statistical Machine Translation", "labels": [], "entities": [{"text": "Preference Grammars", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.9173809289932251}, {"text": "Statistical Machine Translation", "start_pos": 64, "end_pos": 95, "type": "TASK", "confidence": 0.7516659498214722}]}], "abstractContent": [{"text": "We propose a novel probabilistic syn-choronous context-free grammar formalism for statistical machine translation, in which syntactic nonterminal labels are represented as \"soft\" preferences rather than as \"hard\" matching constraints.", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 82, "end_pos": 113, "type": "TASK", "confidence": 0.7342444658279419}]}, {"text": "This formalism allows us to efficiently score unlabeled synchronous derivations without forgoing traditional syntactic constraints.", "labels": [], "entities": []}, {"text": "Using this score as a feature in a log-linear model, we are able to approximate the selection of the most likely unlabeled derivation.", "labels": [], "entities": []}, {"text": "This helps reduce fragmentation of probability across differently labeled derivations of the same translation.", "labels": [], "entities": []}, {"text": "It also allows the importance of syntactic preferences to be learned alongside other features (e.g., the language model) and for particular labeling procedures.", "labels": [], "entities": []}, {"text": "We show improvements in translation quality on small and medium sized Chinese-to-English translation tasks.", "labels": [], "entities": [{"text": "translation", "start_pos": 24, "end_pos": 35, "type": "TASK", "confidence": 0.9703072309494019}, {"text": "Chinese-to-English translation tasks", "start_pos": 70, "end_pos": 106, "type": "TASK", "confidence": 0.7609908580780029}]}], "introductionContent": [{"text": "Probabilistic synchronous context-free grammars (PSCFGs) define weighted production rules that are automatically learned from parallel training data.", "labels": [], "entities": []}, {"text": "As in classical CFGs, these rules make use of nonterminal symbols to generalize beyond lexical modeling of sentences.", "labels": [], "entities": []}, {"text": "In MT, this permits translation and reordering to be conditioned on more abstract notions of context.", "labels": [], "entities": [{"text": "MT", "start_pos": 3, "end_pos": 5, "type": "TASK", "confidence": 0.9793897271156311}, {"text": "translation", "start_pos": 20, "end_pos": 31, "type": "TASK", "confidence": 0.972192108631134}]}, {"text": "For example, VP \u2192 ne VB 1 pas # do not VB 1 represents the discontiguous translation of the French words \"ne\" and \"pas\" to \"do not\", in the context of the labeled nonterminal symbol \"VB\" (representing syntactic category \"verb\").", "labels": [], "entities": []}, {"text": "Translation with PSCFGs is typically expressed as the problem of finding the maximum-weighted derivation consistent with the source sentence, where the scores are defined (at least in part) by R-valued weights associated with the rules.", "labels": [], "entities": [{"text": "Translation", "start_pos": 0, "end_pos": 11, "type": "TASK", "confidence": 0.9567539095878601}]}, {"text": "A PSCFG derivation is asynchronous parse tree.", "labels": [], "entities": []}, {"text": "Defining the translation function as finding the best derivation has the unfortunate side effect of forcing differently-derived versions of the same target sentence to compete with each other.", "labels": [], "entities": []}, {"text": "In other words, the true score of each translation is \"fragmented\" across many derivations, so that each translation's most probable derivation is the only one that matters.", "labels": [], "entities": []}, {"text": "The more Bayesian approach of finding the most probable translation (integrating out the derivations) instantiates an NP-hard inference problem even for simple word-based models; for grammar-based translation it is known as the consensus problem (Casacuberta and de la).", "labels": [], "entities": []}, {"text": "With weights interpreted as probabilities, the maximum-weighted derivation is the maximum a posteriori (MAP) derivation: where f is the source sentence, e ranges over target sentences, and d ranges over PSCFG derivations (synchronous trees).", "labels": [], "entities": [{"text": "maximum a posteriori (MAP)", "start_pos": 82, "end_pos": 108, "type": "METRIC", "confidence": 0.7274642437696457}]}, {"text": "This is often described as an approximation to the most probable translation, argmax ed p(e, d | f ).", "labels": [], "entities": [{"text": "argmax ed p", "start_pos": 78, "end_pos": 89, "type": "METRIC", "confidence": 0.9564571380615234}]}, {"text": "In this paper, we will describe a technique that aims to find the most probable equivalence class of unlabeled derivations, rather than a single labeled derivation, reducing the fragmentation problem.", "labels": [], "entities": []}, {"text": "Solving this problem exactly is still an NP-hard consensus problem, but we provide approximations that build on well-known PSCFG decoding methods.", "labels": [], "entities": []}, {"text": "Our model falls somewhere between PSCFGs that extract nonterminal symbols from parse trees and treat them as part of the derivation () and unlabeled hierarchical structures; we treat nonterminal labels as random variables chosen at each node, with each (unlabeled) rule expressing \"preferences\" for particular nonterminal labels, learned from data.", "labels": [], "entities": []}, {"text": "The paper is organized as follows.", "labels": [], "entities": []}, {"text": "In Section 2, we summarize the use of PSCFG grammars for translation.", "labels": [], "entities": [{"text": "translation", "start_pos": 57, "end_pos": 68, "type": "TASK", "confidence": 0.9736595749855042}]}, {"text": "We describe our model (Section 3).", "labels": [], "entities": []}, {"text": "Section 4 explains the preference-related calculations, and Section 5 addresses decoding.", "labels": [], "entities": []}, {"text": "Experimental results using preference grammars in a loglinear translation model are presented for two standard Chinese-to-English tasks in Section 6.", "labels": [], "entities": []}, {"text": "We review related work (Section 7) and conclude.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Training data configurations used to evaluate preference grammars. The number of words in the target text  and the number of singleton 1-n-grams represented in the complete model are the defining statistics that characterize  the scale of each task. For each LM we also indicate the order of the n-gram model.", "labels": [], "entities": []}, {"text": " Table 2: Translation quality metrics on the IWSLT translation task, with IWSLT 2006 as the development corpora, and  IWSLT 2007 and 2008 as test corpora. Each metric is annotated with an \u2191 if increases in the metric value correspond  to increase in translation quality and a \u2193 if the opposite is true. We also list length penalties for the BLEU metric to  show that improvements are not due to length optimizations alone.", "labels": [], "entities": [{"text": "IWSLT translation task", "start_pos": 45, "end_pos": 67, "type": "TASK", "confidence": 0.7406277457873026}, {"text": "BLEU", "start_pos": 341, "end_pos": 345, "type": "METRIC", "confidence": 0.9858388304710388}]}, {"text": " Table 3: Translation quality and test set translation time  (using 50 machines with 2 tasks per machine) measured  by the BLEU metric for the NIST task. NIST 2006 is  used as the development (Dev.) corpus and NIST 2007 is  used as the unseen evaluation corpus (Test). Dev. scores  are reported for systems that have been separately MERT  trained, Pref. systems share parameters from a single  MERT training. Systems are described in the text.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 123, "end_pos": 127, "type": "METRIC", "confidence": 0.9987333416938782}, {"text": "NIST", "start_pos": 143, "end_pos": 147, "type": "DATASET", "confidence": 0.8680810928344727}, {"text": "NIST 2006", "start_pos": 154, "end_pos": 163, "type": "DATASET", "confidence": 0.9346178472042084}]}]}