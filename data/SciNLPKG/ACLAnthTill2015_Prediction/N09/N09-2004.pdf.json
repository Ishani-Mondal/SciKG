{"title": [{"text": "Semantic Roles for SMT: A Hybrid Two-Pass Model Human Language Technology Center HKUST", "labels": [], "entities": [{"text": "SMT", "start_pos": 19, "end_pos": 22, "type": "TASK", "confidence": 0.9915294647216797}, {"text": "HKUST", "start_pos": 81, "end_pos": 86, "type": "DATASET", "confidence": 0.795089602470398}]}], "abstractContent": [{"text": "We present results on a novel hybrid semantic SMT model that incorporates the strengths of both semantic role labeling and phrase-based statistical machine translation.", "labels": [], "entities": [{"text": "SMT", "start_pos": 46, "end_pos": 49, "type": "TASK", "confidence": 0.6974778175354004}, {"text": "semantic role labeling", "start_pos": 96, "end_pos": 118, "type": "TASK", "confidence": 0.6436960597832998}, {"text": "phrase-based statistical machine translation", "start_pos": 123, "end_pos": 167, "type": "TASK", "confidence": 0.6514034867286682}]}, {"text": "The approach avoids major complexity limitations via a two-pass architecture.", "labels": [], "entities": []}, {"text": "The first pass is performed using a conventional phrase-based SMT model.", "labels": [], "entities": [{"text": "SMT", "start_pos": 62, "end_pos": 65, "type": "TASK", "confidence": 0.8925515413284302}]}, {"text": "The second pass is performed by a reordering strategy guided by shallow semantic parsers that produce both semantic frame and role labels.", "labels": [], "entities": []}, {"text": "Evaluation on a Wall Street Journal newswire genre test set showed the hybrid model to yield an improvement of roughly half a point in BLEU score over a strong pure phrase-based SMT baseline-to our knowledge, the first successful application of semantic role labeling to SMT.", "labels": [], "entities": [{"text": "Wall Street Journal newswire genre test set", "start_pos": 16, "end_pos": 59, "type": "DATASET", "confidence": 0.947781469140734}, {"text": "BLEU score", "start_pos": 135, "end_pos": 145, "type": "METRIC", "confidence": 0.9842616617679596}, {"text": "SMT", "start_pos": 178, "end_pos": 181, "type": "TASK", "confidence": 0.8401649594306946}, {"text": "semantic role labeling", "start_pos": 245, "end_pos": 267, "type": "TASK", "confidence": 0.654780517021815}, {"text": "SMT", "start_pos": 271, "end_pos": 274, "type": "TASK", "confidence": 0.8839327096939087}]}], "introductionContent": [{"text": "Many of the most glaring errors made by today's statistical machine translation systems are those resulting from confusion of semantic roles.", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 48, "end_pos": 79, "type": "TASK", "confidence": 0.6161390443642935}]}, {"text": "Translation errors of this type frequently result in critical misunderstandings of the essential meaning of the original input language sentences -who did what to whom, for whom or what, how, where, when, and why.", "labels": [], "entities": []}, {"text": "Semantic role confusions are errors of adequacy rather than fluency.", "labels": [], "entities": [{"text": "Semantic role confusions", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.7610683441162109}]}, {"text": "It has often been noted that the dominance of lexically-oriented, precisionbased metrics such as BLEU ( tend to reward fluency more than adequacy.", "labels": [], "entities": [{"text": "precisionbased", "start_pos": 66, "end_pos": 80, "type": "METRIC", "confidence": 0.9700597524642944}, {"text": "BLEU", "start_pos": 97, "end_pos": 101, "type": "METRIC", "confidence": 0.9974526762962341}]}, {"text": "The length penalty in the BLEU metric, in particular, is only an indirect and weak indicator of adequacy.", "labels": [], "entities": [{"text": "length penalty", "start_pos": 4, "end_pos": 18, "type": "METRIC", "confidence": 0.9857001304626465}, {"text": "BLEU", "start_pos": 26, "end_pos": 30, "type": "METRIC", "confidence": 0.980803370475769}]}, {"text": "As a result, SMT work has been driven to optimize systems such that they often produce translations that contain significant role confusion errors despite reading fluently.", "labels": [], "entities": [{"text": "SMT", "start_pos": 13, "end_pos": 16, "type": "TASK", "confidence": 0.9942458271980286}]}, {"text": "The present work is inspired by the question of whether we can improve translation utility via a strategy of favoring semantic adequacy slightly more -possibly at the expense of slight degradations in lexical fluency.", "labels": [], "entities": []}, {"text": "Shallow semantic parsing models have attained increasing levels of accuracy in recent years (.", "labels": [], "entities": [{"text": "semantic parsing", "start_pos": 8, "end_pos": 24, "type": "TASK", "confidence": 0.7036713510751724}, {"text": "accuracy", "start_pos": 67, "end_pos": 75, "type": "METRIC", "confidence": 0.9988263249397278}]}, {"text": "Such models, which identify semantic frames within input sentences by marking its predicates, and labeling their arguments with the semantic roles that they fill.", "labels": [], "entities": []}, {"text": "Evidence has begun to accumulate that semantic frames -predicates and semantic roles -tend to preserve consistency across translations better than syntactic roles do.", "labels": [], "entities": []}, {"text": "This is, of course, by design; it follows from the definition of semantic roles, which are less language-dependent than syntactic roles.", "labels": [], "entities": []}, {"text": "Across Chinese and English, for example, it has been reported that approximately 84% of semantic roles are preserved consistently).", "labels": [], "entities": []}, {"text": "Of these, roughly 15% do not preserve syntactic roles consistently.", "labels": [], "entities": []}, {"text": "Since this directly targets the task of determining semantic correctness, we believe that the adequacy of MT output could be improved by leveraging the predictions of semantic parsers.", "labels": [], "entities": [{"text": "determining semantic correctness", "start_pos": 40, "end_pos": 72, "type": "TASK", "confidence": 0.6077785591284434}, {"text": "MT", "start_pos": 106, "end_pos": 108, "type": "TASK", "confidence": 0.9852812886238098}]}, {"text": "We would like to exploit automatic semantic parsers to identify inconsistent semantic frame and role mappings between the input source sentences and their output translations.", "labels": [], "entities": []}, {"text": "However, we take note of the difficult experience in making syntactic and semantic models con-tribute to improving SMT accuracy.", "labels": [], "entities": [{"text": "SMT", "start_pos": 115, "end_pos": 118, "type": "TASK", "confidence": 0.9957001209259033}, {"text": "accuracy", "start_pos": 119, "end_pos": 127, "type": "METRIC", "confidence": 0.7991976737976074}]}, {"text": "On the one hand, there is reason to be optimistic.", "labels": [], "entities": []}, {"text": "Over the past decade, we have seen an accumulation of evidence that SMT accuracy can be improved via tree-structured and syntactic models (e.g.,, and more recently, work from lexical semantics has also at long last been successfully applied to increasing SMT accuracy, in the form of techniques adapted from word sense disambiguation models.", "labels": [], "entities": [{"text": "SMT", "start_pos": 68, "end_pos": 71, "type": "TASK", "confidence": 0.9951462149620056}, {"text": "accuracy", "start_pos": 72, "end_pos": 80, "type": "METRIC", "confidence": 0.8896966576576233}, {"text": "SMT", "start_pos": 255, "end_pos": 258, "type": "TASK", "confidence": 0.9949852228164673}, {"text": "accuracy", "start_pos": 259, "end_pos": 267, "type": "METRIC", "confidence": 0.7011944651603699}, {"text": "word sense disambiguation", "start_pos": 308, "end_pos": 333, "type": "TASK", "confidence": 0.6187112232049307}]}, {"text": "On the other hand, both directions saw unexpected disappointments along the way (e.g.,.", "labels": [], "entities": []}, {"text": "We are therefore forewarned that it is likely to beat least as difficult to successfully adapt the even more complex types of lexical semantics modeling from semantic parsing and role labeling to the translation task.", "labels": [], "entities": [{"text": "semantic parsing", "start_pos": 158, "end_pos": 174, "type": "TASK", "confidence": 0.7100655138492584}, {"text": "role labeling", "start_pos": 179, "end_pos": 192, "type": "TASK", "confidence": 0.7342279255390167}, {"text": "translation task", "start_pos": 200, "end_pos": 216, "type": "TASK", "confidence": 0.8992317914962769}]}, {"text": "In this paper, we present a novel hybrid model that, for the first time to our knowledge, successfully applies semantic parsing technology to the challenge of improving the quality of ChineseEnglish statistical machine translation.", "labels": [], "entities": [{"text": "semantic parsing", "start_pos": 111, "end_pos": 127, "type": "TASK", "confidence": 0.7536176145076752}, {"text": "ChineseEnglish statistical machine translation", "start_pos": 184, "end_pos": 230, "type": "TASK", "confidence": 0.8135833442211151}]}, {"text": "The model makes use of atypical representative SMT system based on Moses, plus shallow semantic parsers for both English and Chinese.", "labels": [], "entities": [{"text": "SMT", "start_pos": 47, "end_pos": 50, "type": "TASK", "confidence": 0.9821324348449707}]}], "datasetContent": [{"text": "A Chinese-English experiment was conducted on the two-pass hybrid model.", "labels": [], "entities": []}, {"text": "A phrase-based SMT baseline model was built by augmenting the open source statistical machine translation decoder Moses () with additional preprocessors.", "labels": [], "entities": [{"text": "SMT", "start_pos": 15, "end_pos": 18, "type": "TASK", "confidence": 0.9176136255264282}, {"text": "statistical machine translation decoder Moses", "start_pos": 74, "end_pos": 119, "type": "TASK", "confidence": 0.7429897069931031}]}, {"text": "English and Chinese shallow semantic parsers followed those discussed in Section 1.", "labels": [], "entities": [{"text": "Chinese shallow semantic parsers", "start_pos": 12, "end_pos": 44, "type": "TASK", "confidence": 0.6091047823429108}]}, {"text": "The model was trained on LDC newswire parallel text consisting of 3.42 million sentence pairs, containing 64.1 million English words and 56.9 million Chinese words.", "labels": [], "entities": [{"text": "LDC newswire parallel text", "start_pos": 25, "end_pos": 51, "type": "DATASET", "confidence": 0.90883569419384}]}, {"text": "The English was tokenized and case-normalized; the Chinese was tokenized via a maximum-entropy model ().", "labels": [], "entities": []}, {"text": "Phrase translations were extracted via the growdiag-final heuristic.", "labels": [], "entities": []}, {"text": "The language model is a 6-gram model trained with Kneser-Ney smoothing using the SRI language modeling toolkit.", "labels": [], "entities": [{"text": "SRI language modeling", "start_pos": 81, "end_pos": 102, "type": "TASK", "confidence": 0.6560085018475851}]}, {"text": "The test set of Wall Street Journal newswire sentences was randomly extracted from the Chinese-English Bilingual Propbank.", "labels": [], "entities": [{"text": "Wall Street Journal newswire sentences", "start_pos": 16, "end_pos": 54, "type": "DATASET", "confidence": 0.9536267399787903}, {"text": "Chinese-English Bilingual Propbank", "start_pos": 87, "end_pos": 121, "type": "DATASET", "confidence": 0.7530312736829122}]}, {"text": "Although we did not make use of the Propbank annotations, this would potentially allow other types of analyses in the future.", "labels": [], "entities": [{"text": "Propbank annotations", "start_pos": 36, "end_pos": 56, "type": "DATASET", "confidence": 0.9248320460319519}]}, {"text": "The phrase-based SMT model used for the first pass achieves a BLEU score of 42.99, establishing a fairly strong baseline to begin with.", "labels": [], "entities": [{"text": "SMT", "start_pos": 17, "end_pos": 20, "type": "TASK", "confidence": 0.9602147340774536}, {"text": "BLEU score", "start_pos": 62, "end_pos": 72, "type": "METRIC", "confidence": 0.9891380071640015}]}, {"text": "In comparison, the automatically errorcorrected translations that are output by the second pass achieve a BLEU score of 43.51.", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 106, "end_pos": 116, "type": "METRIC", "confidence": 0.9812703132629395}]}, {"text": "This represents approximately half a point improvement over the strong baseline.", "labels": [], "entities": []}, {"text": "An example is seen in.", "labels": [], "entities": []}, {"text": "The SMT first pass translation has an ARG0 National Development Bank of Japan in the capital market which is badly mismatched to both the input sentence's ARG0 \ud97b\udf59\ud97b\udf59 \u5f00\u53d1 \u94f6\ud97b\udf59 and ARGM-LOC \ud97b\udf59 \ud97b\udf59\ud97b\udf59 \u8d44\ud97b\udf59 \ud97b\udf59\u573a.", "labels": [], "entities": [{"text": "SMT first pass translation", "start_pos": 4, "end_pos": 30, "type": "TASK", "confidence": 0.8481764495372772}, {"text": "ARG0 National Development Bank", "start_pos": 38, "end_pos": 68, "type": "DATASET", "confidence": 0.8545217365026474}]}, {"text": "The second pass ends up re-ordering the constituent phrase corresponding to the mismatched ARGM-LOC, of Japan in the capital market, to follow the PRED issued, where the new English semantic parse now assigns most of its words the correctly matched ARGM-LOC semantic role label.", "labels": [], "entities": [{"text": "PRED issued", "start_pos": 147, "end_pos": 158, "type": "DATASET", "confidence": 0.7649604380130768}, {"text": "English semantic parse", "start_pos": 174, "end_pos": 196, "type": "TASK", "confidence": 0.6286521355311075}]}, {"text": "Similarly, samurai bonds 30 billion yen is re-ordered to 30 billion yen samurai bonds.", "labels": [], "entities": []}], "tableCaptions": []}