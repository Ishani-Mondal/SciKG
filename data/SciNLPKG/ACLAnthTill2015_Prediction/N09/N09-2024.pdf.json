{"title": [{"text": "A Simple Sentence-Level Extraction Algorithm for Comparable Data", "labels": [], "entities": []}], "abstractContent": [{"text": "The paper presents a novel sentence pair extraction algorithm for comparable data, where a large set of candidate sentence pairs is scored directly at the sentence-level.", "labels": [], "entities": [{"text": "sentence pair extraction", "start_pos": 27, "end_pos": 51, "type": "TASK", "confidence": 0.6878375113010406}]}, {"text": "The sentence-level extraction relies on a very efficient implementation of a simple symmetric scoring function: a computation speed-up by a factor of 30 is reported.", "labels": [], "entities": [{"text": "sentence-level extraction", "start_pos": 4, "end_pos": 29, "type": "TASK", "confidence": 0.7857151925563812}]}, {"text": "On Spanish-English data, the extraction algorithm finds the highest scoring sentence pairs from close to 1 trillion candidate pairs without search errors.", "labels": [], "entities": []}, {"text": "Significant improvements in BLEU are reported by including the extracted sentence pairs into the training of a phrase-based SMT (Statistical Machine Translation) system.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 28, "end_pos": 32, "type": "METRIC", "confidence": 0.975862979888916}, {"text": "phrase-based SMT (Statistical Machine Translation)", "start_pos": 111, "end_pos": 161, "type": "TASK", "confidence": 0.732237879719053}]}], "introductionContent": [{"text": "The paper presents a simple sentence-level translation pair extraction algorithm from comparable monolingual news data.", "labels": [], "entities": [{"text": "sentence-level translation pair extraction", "start_pos": 28, "end_pos": 70, "type": "TASK", "confidence": 0.7746382802724838}]}, {"text": "It differs from similar algorithms that select translation correspondences explicitly at the document level.", "labels": [], "entities": []}, {"text": "In these publications, the authors use Information-Retrieval (IR) techniques to match document pairs that are likely translations of each other.", "labels": [], "entities": []}, {"text": "More complex sentence-level models are then used to extract parallel sentence pairs (or fragments).", "labels": [], "entities": []}, {"text": "From a computational perspective, the document-level filtering steps are needed to reduce the number of candidate sentence pairs.", "labels": [], "entities": [{"text": "document-level filtering", "start_pos": 38, "end_pos": 62, "type": "TASK", "confidence": 0.7044423371553421}]}, {"text": "While IR techniques might be useful to improve the selection accuracy, the current paper demonstrates that they are not necessary to obtain parallel sentence pairs.", "labels": [], "entities": [{"text": "IR", "start_pos": 6, "end_pos": 8, "type": "TASK", "confidence": 0.9736165404319763}, {"text": "accuracy", "start_pos": 61, "end_pos": 69, "type": "METRIC", "confidence": 0.9846318960189819}]}, {"text": "For some data, e.g. the Portuguese-English Reuters data used in the experiments in Section 3, document-level information may not even be available.", "labels": [], "entities": [{"text": "Portuguese-English Reuters data", "start_pos": 24, "end_pos": 55, "type": "DATASET", "confidence": 0.7814396818478903}]}, {"text": "In this paper, sentence pairs are extracted by a simple model that is based on the so-called IBM).", "labels": [], "entities": [{"text": "IBM", "start_pos": 93, "end_pos": 96, "type": "DATASET", "confidence": 0.8561533689498901}]}, {"text": "The Model-1 is trained on some parallel data available fora language pair, i.e. the data used to train the baseline systems in Section 3.", "labels": [], "entities": []}, {"text": "The scoring function used in this paper is inspired by phrase-based SMT.", "labels": [], "entities": [{"text": "phrase-based SMT", "start_pos": 55, "end_pos": 71, "type": "TASK", "confidence": 0.5706634223461151}]}, {"text": "Typically, a phrase-based SMT system includes a feature that scores phrase pairs using lexical weights () which are computed for two directions: source to target and target to source.", "labels": [], "entities": [{"text": "SMT", "start_pos": 26, "end_pos": 29, "type": "TASK", "confidence": 0.8267328143119812}]}, {"text": "Here, a sentence pair is scored as a phrase pair that covers all the source and target words.", "labels": [], "entities": []}, {"text": "The scoring function \u033a(S, T ) is defined as follows: Here, S = s J 1 is the source sentence of length J and T = t I 1 is the target sentence of length I. p(s|T ) is the Model-1 probability assigned to the source word s given the target sentence T , p(t|S) is defined accordingly.", "labels": [], "entities": []}, {"text": "p(s|t) and p(t|s) are word translation probabilities obtained by two parallel Model-1 training stepson the same data, but swapping the role of source and target language.", "labels": [], "entities": [{"text": "word translation probabilities", "start_pos": 22, "end_pos": 52, "type": "TASK", "confidence": 0.7903591195742289}]}, {"text": "They are smoothed to avoid 0.0 entries; there is no special NULL-word model and stop words are kept.", "labels": [], "entities": []}, {"text": "The log(\u00b7) is applied to turn the sentence-level probabilities into scores.", "labels": [], "entities": []}, {"text": "These log-probabilities are normalized with respect to the source and target sentence length: this way the score \u033a(S, T ) can be used across all sentence pairs considered, and a single manually set threshold \u03b8 is used to select all those sentence pairs whose score is above it.", "labels": [], "entities": []}, {"text": "For computational reasons, the sum \u033a(S, T ) is computed over the following terms: \u03c4 (t i , S) where 1 \u2264 i \u2264 I and \u03c3(s j , T ), where 1\u2264 j \u2264 J.", "labels": [], "entities": []}, {"text": "The \u03c4 's and \u03c3's represent partial score contributions fora given source or target position.", "labels": [], "entities": []}, {"text": "Note that \u033a(S, T ) \u2264 0 since the terms \u03c4 (\u00b7, S) \u2264 0 and \u03c3(\u00b7, T ) \u2264 0.", "labels": [], "entities": []}, {"text": "Section 2 presents an efficient implementation of the scoring function in Eq.", "labels": [], "entities": [{"text": "Eq", "start_pos": 74, "end_pos": 76, "type": "DATASET", "confidence": 0.9063169956207275}]}, {"text": "1. Its effectiveness is demonstrated in Section 3.", "labels": [], "entities": []}, {"text": "Finally, Section 4 discusses future work and extensions of the current algorithm.", "labels": [], "entities": []}], "datasetContent": [{"text": "The parallel sentence extraction algorithm presented in this paper is tested in detail on the largescale Spanish-English Gigaword data.", "labels": [], "entities": [{"text": "parallel sentence extraction", "start_pos": 4, "end_pos": 32, "type": "TASK", "confidence": 0.6295910974343618}, {"text": "Spanish-English Gigaword data", "start_pos": 105, "end_pos": 134, "type": "DATASET", "confidence": 0.6773403783639272}]}, {"text": "The Spanish data comes from 3 news feeds: Agence France-Presse (AFP), Associated Press Worldstream (APW), and Xinhua News).", "labels": [], "entities": [{"text": "Spanish data", "start_pos": 4, "end_pos": 16, "type": "DATASET", "confidence": 0.7375869601964951}, {"text": "Associated Press Worldstream (APW)", "start_pos": 70, "end_pos": 104, "type": "DATASET", "confidence": 0.828154077132543}]}, {"text": "Caching the target word probabilities results in the biggest reduction.", "labels": [], "entities": []}, {"text": "The results are representative: finding the highest scoring target sentence T fora given source sentence S takes about 1 second on average.", "labels": [], "entities": []}, {"text": "Since 20 million source sentences are processed, and the workload is distributed over roughly 120 processors, overall processing time sums to less than 3 days.", "labels": [], "entities": []}, {"text": "Here, the total number of translation pairs considered is close to 1 trillion.", "labels": [], "entities": []}, {"text": "The effect of including additional sentence pairs along with selection statistics is presented in Table 3.", "labels": [], "entities": []}, {"text": "Translation results are presented fora standard phrase-based SMT system.", "labels": [], "entities": [{"text": "Translation", "start_pos": 0, "end_pos": 11, "type": "TASK", "confidence": 0.9349109530448914}, {"text": "SMT", "start_pos": 61, "end_pos": 64, "type": "TASK", "confidence": 0.8835977911949158}]}, {"text": "Here, both languages use a test set with a single reference.", "labels": [], "entities": []}, {"text": "Including about 1.4 million sentence pairs extracted from the Gigaword data, we obtain a statistically significant improvement from 42.3 to 45.6 in BLEU ().", "labels": [], "entities": [{"text": "Gigaword data", "start_pos": 62, "end_pos": 75, "type": "DATASET", "confidence": 0.9601940810680389}, {"text": "BLEU", "start_pos": 148, "end_pos": 152, "type": "METRIC", "confidence": 0.9938940405845642}]}, {"text": "The baseline system has been trained on about 1.8 million sentence pairs from Europarl and FBIS parallel data.", "labels": [], "entities": [{"text": "Europarl", "start_pos": 78, "end_pos": 86, "type": "DATASET", "confidence": 0.9909694790840149}, {"text": "FBIS parallel data", "start_pos": 91, "end_pos": 109, "type": "DATASET", "confidence": 0.7699247598648071}]}, {"text": "We also present results fora Portuguese-English system: the baseline has been trained on Europarl and JRC data.", "labels": [], "entities": [{"text": "Europarl", "start_pos": 89, "end_pos": 97, "type": "DATASET", "confidence": 0.9898567199707031}, {"text": "JRC data", "start_pos": 102, "end_pos": 110, "type": "DATASET", "confidence": 0.8936079144477844}]}, {"text": "Parallel sentence pairs are extracted from comparable Reuters news data published in 2006.", "labels": [], "entities": [{"text": "Reuters news data published in 2006", "start_pos": 54, "end_pos": 89, "type": "DATASET", "confidence": 0.9411043922106425}]}, {"text": "The corpus statistics for the Portuguese-English data are given in.", "labels": [], "entities": [{"text": "Portuguese-English data", "start_pos": 30, "end_pos": 53, "type": "DATASET", "confidence": 0.805924654006958}]}, {"text": "The selection threshold \u03b8 is determined with the help of bilingual annotators (it typically takes a few hours).", "labels": [], "entities": []}, {"text": "Sentence pairs are selected with a conservative threshold \u03b8 \u2032 first.", "labels": [], "entities": []}, {"text": "Then, all the sentence pairs are sorted by descending score.", "labels": [], "entities": []}, {"text": "The annotator descends this list to determine a score threshold cut-off.", "labels": [], "entities": []}, {"text": "Here, translation pairs are considered to be parallel if 75 % of source and target words have a corresponding translation in the other sentence.", "labels": [], "entities": []}, {"text": "Using a threshold \u03b8 = \u22124.1 for the Spanish-English data, results in a selection precision of around 80 % (most of the misqualified pairs are partial translations with less than 75 % coverage or short sequences of high frequency words).", "labels": [], "entities": [{"text": "Spanish-English data", "start_pos": 35, "end_pos": 55, "type": "DATASET", "confidence": 0.7098452001810074}, {"text": "precision", "start_pos": 80, "end_pos": 89, "type": "METRIC", "confidence": 0.5613239407539368}]}, {"text": "This simple selection criterion proved sufficient to obtain the results presented in this paper.", "labels": [], "entities": []}, {"text": "As can be seen from, the optimal threshold is language specific.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Effect of the implementation techniques on a  full search that computes \u033a(S, T ) exhaustively for all sen- tence pairs (S, T ) for a given S.", "labels": [], "entities": []}, {"text": " Table 2: Corpus statistics for comparable data. Any  document-level information is ignored.", "labels": [], "entities": []}, {"text": " Table 3: Spanish-English and Portuguese-English extrac- tion results.", "labels": [], "entities": [{"text": "extrac- tion", "start_pos": 49, "end_pos": 61, "type": "METRIC", "confidence": 0.9086400469144186}]}]}