{"title": [{"text": "Assessing and Improving the Performance of Speech Recognition for Incremental Systems", "labels": [], "entities": [{"text": "Speech Recognition", "start_pos": 43, "end_pos": 61, "type": "TASK", "confidence": 0.6603318303823471}]}], "abstractContent": [{"text": "In incremental spoken dialogue systems, partial hypotheses about what was said are required even while the utterance is still ongoing.", "labels": [], "entities": []}, {"text": "We define measures for evaluating the quality of incremental ASR components with respect to the relative correctness of the partial hypotheses compared to hypotheses that can optimize over the complete input, the timing of hypothesis formation relative to the portion of the input they are about, and hypothesis stability, defined as the number of times they are revised.", "labels": [], "entities": [{"text": "ASR", "start_pos": 61, "end_pos": 64, "type": "TASK", "confidence": 0.9813753366470337}]}, {"text": "We show that simple incremen-tal post-processing can improve stability dramatically , at the cost of timeliness (from 90 % of edits of hypotheses being spurious down to 10 % at a lag of 320 ms).", "labels": [], "entities": [{"text": "timeliness", "start_pos": 101, "end_pos": 111, "type": "METRIC", "confidence": 0.987851083278656}]}, {"text": "The measures are not independent, and we show how system designers can find a desired operating point for their ASR.", "labels": [], "entities": [{"text": "ASR", "start_pos": 112, "end_pos": 115, "type": "TASK", "confidence": 0.9488486647605896}]}, {"text": "To our knowledge, we are the first to suggest and examine a variety of measures for assessing incremental ASR and improve performance on this basis.", "labels": [], "entities": [{"text": "ASR", "start_pos": 106, "end_pos": 109, "type": "TASK", "confidence": 0.930857241153717}]}], "introductionContent": [{"text": "Incrementality, that is, the property of beginning to process input before it is complete, is often seen as a desirable property of dialogue systems (e.g.,), as it allows the system to (a) fold processing time (of modules such as parsers, or dialogue managers) into the time taken by the utterance, and (b) react to partial results, for example by generating back-channel utterances or speculatively initiating potentially relevant database queries.", "labels": [], "entities": []}, {"text": "Input to a spoken dialogue system normally passes an automatic speech recognizer (ASR) as a first processing module, thus the module's incrementality determines the level of incrementality that can be reached by the system as a whole.", "labels": [], "entities": [{"text": "speech recognizer (ASR)", "start_pos": 63, "end_pos": 86, "type": "TASK", "confidence": 0.7792291402816772}]}, {"text": "Using an ASR system incrementally poses interesting challenges, however.", "labels": [], "entities": [{"text": "ASR", "start_pos": 9, "end_pos": 12, "type": "TASK", "confidence": 0.9608192443847656}]}, {"text": "Typically, ASRs use dynamic programming and the maximum likelihood hypothesis to find the word sequence with the lowest expected likelihood of the sequence containing errors (sentence error).", "labels": [], "entities": [{"text": "ASRs", "start_pos": 11, "end_pos": 15, "type": "TASK", "confidence": 0.9831539988517761}]}, {"text": "Due to the dynamic programming approach, what is considered the best hypothesis about a given stretch of the input signal can change during the recognition process, as more right context which can be used as evidence becomes available.", "labels": [], "entities": []}, {"text": "In this paper, we argue that normally used metrics for ASR evaluation such as word error rate must be complemented with metrics specifically designed for measuring incremental performance, and offer some such metrics.", "labels": [], "entities": [{"text": "ASR evaluation", "start_pos": 55, "end_pos": 69, "type": "TASK", "confidence": 0.9729787409305573}, {"text": "word error rate", "start_pos": 78, "end_pos": 93, "type": "METRIC", "confidence": 0.5774106780687968}]}, {"text": "We show that there are various subproperties that are not independent of each other, and that trade-offs are involved if either of those is to be optimized.", "labels": [], "entities": []}, {"text": "Finally, we propose ways to improve incremental performance (as measured by our metrics) through the use of smoothing techniques.", "labels": [], "entities": []}, {"text": "To our knowledge, incremental evaluation metrics of ASR for incremental have not yet been covered in the literature.", "labels": [], "entities": [{"text": "ASR", "start_pos": 52, "end_pos": 55, "type": "TASK", "confidence": 0.9789390563964844}]}, {"text": "Most closely related, show results for an ASR which fixes its results after a given time \u2206 and report the corresponding word error rate (WER).", "labels": [], "entities": [{"text": "ASR", "start_pos": 42, "end_pos": 45, "type": "TASK", "confidence": 0.9482763409614563}, {"text": "word error rate (WER)", "start_pos": 120, "end_pos": 141, "type": "METRIC", "confidence": 0.9045725762844086}]}, {"text": "This unfortunately confounds the incremental and nonincremental properties of their ASR's performance.", "labels": [], "entities": [{"text": "ASR", "start_pos": 84, "end_pos": 87, "type": "TASK", "confidence": 0.9848685264587402}]}, {"text": "The remainder of this paper is structured as follows: In section 2, we give an overview of incremenality with respect to ASR, and develop our evalua-tion metrics.", "labels": [], "entities": [{"text": "ASR", "start_pos": 121, "end_pos": 124, "type": "TASK", "confidence": 0.873865008354187}]}, {"text": "Section 3 describes the setup and data that we used in our experiments, and reports and discusses some basic measures for different variants of the setup.", "labels": [], "entities": []}, {"text": "In section 4 we propose and discuss two orthogonal methods that improve incremental performance: using right context and using message smoothing, which show different properties with regard to our measures.", "labels": [], "entities": [{"text": "message smoothing", "start_pos": 127, "end_pos": 144, "type": "TASK", "confidence": 0.7549774050712585}]}, {"text": "Finally, in section 5 we sum up and point to future directions.", "labels": [], "entities": []}], "datasetContent": [{"text": "Ina modular system, an incremental module is one that generates (partial) responses while input is still ongoing and makes these available to other modules.", "labels": [], "entities": []}, {"text": "ASR modules that use token passing ( can easily be adapted to output anew, live hypothesis after processing of every input frame (often that is every 10 ms).", "labels": [], "entities": [{"text": "token passing", "start_pos": 21, "end_pos": 34, "type": "TASK", "confidence": 0.7466188371181488}]}, {"text": "In an incremental system we are able to get partial results from these hypotheses as soon as they become available -or rather as soon as they can be trusted.", "labels": [], "entities": []}, {"text": "As mentioned above, hypotheses are only tentative, and maybe revised when more right context becomes available.", "labels": [], "entities": []}, {"text": "Modules consuming the output of an incremental ASR hence must be able to deal with such revisions.", "labels": [], "entities": [{"text": "ASR", "start_pos": 47, "end_pos": 50, "type": "TASK", "confidence": 0.9137110114097595}]}, {"text": "There is a first trade-off here: Depending on how costly revision is for later modules (which after all may need to revise any hypotheses which they themselves based on the nowrevised input), it maybe better to reduce the incrementality a bit -in the sense that partial information is produced less often, and hence new words for example are recognised later -if that buys stability (fewer revisions).", "labels": [], "entities": []}, {"text": "Also, ignoring some incremental results that are likely to be wrong may increase system performance.", "labels": [], "entities": []}, {"text": "Defining these notions more precisely is the aim of this section.", "labels": [], "entities": []}], "tableCaptions": []}