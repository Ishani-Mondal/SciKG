{"title": [{"text": "Using a maximum entropy model to build segmentation lattices for MT", "labels": [], "entities": [{"text": "MT", "start_pos": 65, "end_pos": 67, "type": "TASK", "confidence": 0.9487468600273132}]}], "abstractContent": [{"text": "Recent work has shown that translating seg-mentation lattices (lattices that encode alternative ways of breaking the input to an MT system into words), rather than text in any particular segmentation, improves translation quality of languages whose orthography does not mark morpheme boundaries.", "labels": [], "entities": []}, {"text": "However, much of this work has relied on multiple segmenters that perform differently on the same input to generate sufficiently diverse source segmen-tation lattices.", "labels": [], "entities": []}, {"text": "In this work, we describe a maximum entropy model of compound word splitting that relies on a few general features that can be used to generate segmentation lattices for most languages with productive compounding.", "labels": [], "entities": [{"text": "compound word splitting", "start_pos": 53, "end_pos": 76, "type": "TASK", "confidence": 0.6332792143026987}]}, {"text": "Using a model optimized for Ger-man translation, we present results showing significant improvements in translation quality in German-English, Hungarian-English, and Turkish-English translation over state-of-the-art baselines.", "labels": [], "entities": [{"text": "Ger-man translation", "start_pos": 28, "end_pos": 47, "type": "TASK", "confidence": 0.6243286579847336}]}], "introductionContent": [{"text": "Compound words pose significant challenges to the lexicalized models that are currently common in statistical machine translation.", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 98, "end_pos": 129, "type": "TASK", "confidence": 0.6928903758525848}]}, {"text": "This problem has been widely acknowledged, and the conventional solution, which has been shown to work well for many language pairs, is to segment compounds into their constituent morphemes using either morphological analyzers or empirical methods and then to translate from or to this segmented variant (.", "labels": [], "entities": []}, {"text": "But into what units should a compound word be segmented?", "labels": [], "entities": []}, {"text": "Taken as a stand-alone task, the goal of a compound splitter is to produce a segmentation for some input that matches the linguistic intuitions of a native speaker of the language.", "labels": [], "entities": [{"text": "compound splitter", "start_pos": 43, "end_pos": 60, "type": "TASK", "confidence": 0.7544138133525848}]}, {"text": "However, there are often advantages to using elements larger than single morphemes as the minimal lexical unit for MT, since they may correspond more closely to the units of translation.", "labels": [], "entities": [{"text": "MT", "start_pos": 115, "end_pos": 117, "type": "TASK", "confidence": 0.9779049158096313}]}, {"text": "Unfortunately, determining the optimal segmentation is challenging, typically requiring extensive experimentation (.", "labels": [], "entities": [{"text": "segmentation", "start_pos": 39, "end_pos": 51, "type": "TASK", "confidence": 0.9629687666893005}]}, {"text": "Recent work has shown that by combining a variety of segmentations of the input into a segmentation lattice and effectively marginalizing over many different segmentations, translations superior to those resulting from any single single segmentation of the input can be obtained (.", "labels": [], "entities": []}, {"text": "Unfortunately, this approach is difficult to utilize because it requires multiple segmenters that behave differently on the same input.", "labels": [], "entities": []}, {"text": "In this paper, we describe a maximum entropy word segmentation model that is trained to assign high probability to possibly several segmentations of an input word.", "labels": [], "entities": [{"text": "maximum entropy word segmentation", "start_pos": 29, "end_pos": 62, "type": "TASK", "confidence": 0.6632884293794632}]}, {"text": "This model enables generation of diverse, accurate segmentation lattices from a single model that are appropriate for use in decoders that accept word lattices as input, such as Moses ().", "labels": [], "entities": []}, {"text": "Since our model relies a small number of dense features, its parameters can be tuned using very small amounts of manually created reference lattices.", "labels": [], "entities": []}, {"text": "Furthermore, since these parameters were chosen to have valid interpretation across a variety of languages, we find that the weights estimated for one apply quite well to another.", "labels": [], "entities": []}, {"text": "We show that these lattices significantly improve translation quality when translating into English from three languages exhibiting productive compounding: German, Turkish, and Hungarian.", "labels": [], "entities": []}, {"text": "The paper is structured as follows.", "labels": [], "entities": []}, {"text": "In the next sec-tion, we describe translation from segmentation lattices and give a motivating example, Section 3 describes our segmentation model and its tuning and how it is used to generate segmentation lattices, Section 5 presents experimental results, Section 6 reviews relevant related work, and in Section 7 we conclude and discuss future work.", "labels": [], "entities": []}], "datasetContent": [{"text": "We now review experiments using segmentation lattices produced by the segmentation model we just introduced in German-English, Hungarian-English, and Turkish-English translation tasks and then show results elucidating the effect of the lattice density parameter.", "labels": [], "entities": [{"text": "Turkish-English translation tasks", "start_pos": 150, "end_pos": 183, "type": "TASK", "confidence": 0.7672126690546671}]}, {"text": "We begin with a description of our MT system.", "labels": [], "entities": [{"text": "MT", "start_pos": 35, "end_pos": 37, "type": "TASK", "confidence": 0.9854385852813721}]}], "tableCaptions": [{"text": " Table 2: Features and weights learned by maximum like- lihood training, sorted by weight magnitude.", "labels": [], "entities": []}, {"text": " Table 4: Translation results for German (DE)-English,  Hungarian (HU)-English, and Turkish (TR)-English.  Scores were computed using a single reference and are  case insensitive.", "labels": [], "entities": [{"text": "Translation", "start_pos": 10, "end_pos": 21, "type": "TASK", "confidence": 0.8717142343521118}]}]}