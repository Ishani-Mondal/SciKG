{"title": [{"text": "Large-scale Computation of Distributional Similarities for Queries", "labels": [], "entities": []}], "abstractContent": [{"text": "We present a large-scale, data-driven approach to computing distributional similarity scores for queries.", "labels": [], "entities": []}, {"text": "We contrast this to recent web-based techniques which either require the off-line computation of complete phrase vectors, or an expensive on-line interaction with a search engine interface.", "labels": [], "entities": []}, {"text": "Independent of the computational advantages of our approach, we show empirically that our technique is more effective at ranking query alternatives that the computationally more expensive technique of using the results from a web search engine.", "labels": [], "entities": []}], "introductionContent": [{"text": "Measuring the semantic similarity between queries or, more generally, between pairs of very short texts, is increasingly receiving attention due to its many applications.", "labels": [], "entities": []}, {"text": "An accurate metric of query similarities is useful for query expansion, to improve recall in Information Retrieval systems; for query suggestion, to propose to the user related queries that might help reach the desired information more quickly; and for sponsored search, where advertisers bid for keywords that maybe different but semantically equivalent to user queries.", "labels": [], "entities": [{"text": "query expansion", "start_pos": 55, "end_pos": 70, "type": "TASK", "confidence": 0.853120744228363}, {"text": "recall", "start_pos": 83, "end_pos": 89, "type": "METRIC", "confidence": 0.9974291920661926}, {"text": "Information Retrieval", "start_pos": 93, "end_pos": 114, "type": "TASK", "confidence": 0.7458659410476685}, {"text": "query suggestion", "start_pos": 128, "end_pos": 144, "type": "TASK", "confidence": 0.8163284361362457}]}, {"text": "In this paper, we study the problem of measuring similarity between queries using corpus-based unsupervised methods.", "labels": [], "entities": []}, {"text": "Given a query q, we would like to rank all other queries according to their similarity to q.", "labels": [], "entities": []}, {"text": "The proposed approach compares favorably to a state-of-the-art unsupervised system.", "labels": [], "entities": []}], "datasetContent": [{"text": "As an evolution of the distributional similarities approach, we also implemented a second version where the queries are chunked into phrases.", "labels": [], "entities": []}, {"text": "The motivation for the second version is that, in some queries, like [new york cheap hotel], it makes sense to handle new york as a single phrase with a single associated context vector collected from the web corpus.", "labels": [], "entities": []}, {"text": "The list of valid n-grams is collected by combining several metrics, e.g. whether Wikipedia contains an entry with that name, or whether they appear quoted in query logs.", "labels": [], "entities": []}, {"text": "The queries are then chunked greedily always preferring the longer ngram from our list.", "labels": [], "entities": []}, {"text": "shows the results of trying both systems on the same set of queries.", "labels": [], "entities": []}, {"text": "The original system is the one called Unigrams, and the one that chunks the queries is the one called N-grams.", "labels": [], "entities": []}, {"text": "The distributional similarity approaches outperform the webbased kernel on all the metrics, and chunking queries shows a good improvement over using unigrams.", "labels": [], "entities": []}, {"text": "To collect the contextual features for words and phrases, we have used a corpus of hundreds of millions of documents crawled from the Web in August 2008.", "labels": [], "entities": []}, {"text": "An HTML parser is used to extract text and non-English documents are discarded.", "labels": [], "entities": []}, {"text": "After process, the remaining corpus contains hundreds of billions of words.", "labels": [], "entities": []}, {"text": "As a source of keywords, we have used the top  one and a half million English queries sent to the Google search engine after being fully anonymized.", "labels": [], "entities": []}, {"text": "We have calculated the pairwise similarity between all queries, which would potentially return 2.25 trillion similarity scores, but in practice returns a much smaller number as many pairs have non-overlapping contexts.", "labels": [], "entities": []}, {"text": "As a baseline, we have used anew implementation of the Web Kernel similarity).", "labels": [], "entities": []}, {"text": "The parameters are set the same as reported in the paper with the exception of the snippet size; in their study, the size was limited to 1,000 characters and in our system, the normal snippet returned by Google is used (around 160 characters).", "labels": [], "entities": []}, {"text": "In order to evaluate our system, we prepared a goldstandard set of query similarities.", "labels": [], "entities": []}, {"text": "We have randomly sampled 65 queries from our full dataset, and obtained the top 20 suggestions from both the Sahami system and the distributional similarities system.", "labels": [], "entities": [{"text": "Sahami system", "start_pos": 109, "end_pos": 122, "type": "DATASET", "confidence": 0.9050501585006714}]}, {"text": "Two human raters have rated the original query and the union of the sets of suggestions, using the same 5-point Likert scale that Sahami used.", "labels": [], "entities": [{"text": "Likert scale", "start_pos": 112, "end_pos": 124, "type": "METRIC", "confidence": 0.9575023651123047}]}, {"text": "shows the confusion matrix of scores between the two raters.", "labels": [], "entities": [{"text": "confusion", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9880081415176392}]}, {"text": "Most of the disagreements are between the scores 0 and 1, which means that probably it was not clear enough whether the queries were unrelated or only slightly related.", "labels": [], "entities": []}, {"text": "It is also noteworthy that in this case, very few rewritten queries were classified as being better than the original, which also suggests to us that probably we could remove the topmost score from the classifications scale.", "labels": [], "entities": []}, {"text": "We have evaluated inter-judge agreement in the following two ways: first, using the weighted Kappa score, which has a value of 0.7111.", "labels": [], "entities": []}, {"text": "Second, by grouping the pairs judged as irrelevant or slightly relevant (scores 0 and 1) as a class containing negative examples, and the pairs judged as very relevant, equal or better (scores 2 through 4) as a class containing positive examples.", "labels": [], "entities": []}, {"text": "Using this two-class clas-  sification, Cohen's Kappa score becomes 0.6171.", "labels": [], "entities": [{"text": "Kappa score", "start_pos": 48, "end_pos": 59, "type": "METRIC", "confidence": 0.8977076709270477}]}, {"text": "Both scores indicates substantial agreement amongst the raters.", "labels": [], "entities": []}, {"text": "The data set thus collected is a ranked list of suggestions for each query 1 , and can be used to evaluate any other suggestion-ranking system.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Example of context words for the query [acid fast bacteria].", "labels": [], "entities": []}, {"text": " Table 2: Confusion matrix for the pairs in the goldstandard. Rows", "labels": [], "entities": [{"text": "Confusion", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9682443737983704}, {"text": "goldstandard", "start_pos": 48, "end_pos": 60, "type": "DATASET", "confidence": 0.9159173965454102}, {"text": "Rows", "start_pos": 62, "end_pos": 66, "type": "METRIC", "confidence": 0.9722276926040649}]}, {"text": " Table 3: Results. mAP is mean average precision, and AUC is the", "labels": [], "entities": [{"text": "mean average precision", "start_pos": 26, "end_pos": 48, "type": "METRIC", "confidence": 0.8301887512207031}, {"text": "AUC", "start_pos": 54, "end_pos": 57, "type": "METRIC", "confidence": 0.9986967444419861}]}]}