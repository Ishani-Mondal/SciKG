{"title": [{"text": "Improving nonparameteric Bayesian inference: experiments on unsupervised word segmentation with adaptor grammars", "labels": [], "entities": [{"text": "Improving nonparameteric Bayesian inference", "start_pos": 0, "end_pos": 43, "type": "TASK", "confidence": 0.8815566748380661}, {"text": "word segmentation", "start_pos": 73, "end_pos": 90, "type": "TASK", "confidence": 0.7548059225082397}]}], "abstractContent": [{"text": "One of the reasons nonparametric Bayesian inference is attracting attention in computational linguistics is because it provides a prin-cipled way of learning the units of generalization together with their probabilities.", "labels": [], "entities": []}, {"text": "Adaptor grammars area framework for defining a variety of hierarchical nonparametric Bayesian models.", "labels": [], "entities": []}, {"text": "This paper investigates some of the choices that arise in formulating adaptor grammars and associated inference procedures , and shows that they can have a dramatic impact on performance in an unsuper-vised word segmentation task.", "labels": [], "entities": [{"text": "word segmentation task", "start_pos": 207, "end_pos": 229, "type": "TASK", "confidence": 0.8129512866338094}]}, {"text": "With appropriate adaptor grammars and inference procedures we achieve an 87% word token f-score on the standard Brent version of the Bernstein-Ratner corpus, which is an error reduction of over 35% over the best previously reported results for this corpus.", "labels": [], "entities": [{"text": "word token f-score", "start_pos": 77, "end_pos": 95, "type": "METRIC", "confidence": 0.6651747822761536}, {"text": "error reduction", "start_pos": 170, "end_pos": 185, "type": "METRIC", "confidence": 0.9743336141109467}]}], "introductionContent": [{"text": "Most machine learning algorithms used in computational linguistics are parametric, i.e., they learn a numerical weight (e.g., a probability) associated with each feature, where the set of features is fixed before learning begins.", "labels": [], "entities": []}, {"text": "Such procedures can be used to learn features or structural units by embedding them in a \"propose-and-prune\" algorithm: a feature proposal component proposes potentially useful features (e.g., combinations of the currently most useful features), which are then fed to a parametric learner that estimates their weights.", "labels": [], "entities": []}, {"text": "After estimating feature weights and pruning \"useless\" low-weight features, the cycle repeats.", "labels": [], "entities": []}, {"text": "While such algorithms can achieve impressive results, their effectiveness depends on how well the feature proposal step relates to the overall learning objective, and it can take considerable insight and experimentation to devise good feature proposals.", "labels": [], "entities": []}, {"text": "One of the main reasons for the recent interest in nonparametric Bayesian inference is that it offers a systematic framework for structural inference, i.e., inferring the features relevant to a particular problem as well as their weights.", "labels": [], "entities": []}, {"text": "(Here \"nonparametric\" means that the models do not have a fixed set of parameters; our nonparametric models do have parameters, but the particular parameters in a model are learned along with their values).", "labels": [], "entities": []}, {"text": "Dirichlet Processes and their associated predictive distributions, Chinese Restaurant Processes, are one kind of nonparametric Bayesian model that has received considerable attention recently, in part because they can be composed in hierarchical fashion to form Hierarchical Dirichlet Processes (HDP) ().", "labels": [], "entities": []}, {"text": "Lexical acquisition is an ideal test-bed for exploring methods for inferring structure, where the features learned are the words of the language.", "labels": [], "entities": [{"text": "Lexical acquisition", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.8712736666202545}]}, {"text": "(Even the most hard-core nativists agree that the words of a language must be learned).", "labels": [], "entities": []}, {"text": "We use the unsupervised word segmentation problem as a test case for evaluating structural inference in this paper.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 24, "end_pos": 41, "type": "TASK", "confidence": 0.7260093241930008}]}, {"text": "Nonparametric Bayesian methods produce state-of-the-art performance on this task (.", "labels": [], "entities": []}, {"text": "Ina computational linguistics setting it is natural to try to align the HDP hierarchy with the hierarchy defined by a grammar.", "labels": [], "entities": []}, {"text": "Adaptor grammars, which are one way of doing this, make it easy to explore a wide variety of HDP grammar-based models.", "labels": [], "entities": []}, {"text": "Given an appropriate adaptor grammar, the fea-tures learned by adaptor grammars can correspond to linguistic units such as words, syllables and collocations.", "labels": [], "entities": []}, {"text": "Different adaptor grammars encode different assumptions about the structure of these units and how they relate to each other.", "labels": [], "entities": []}, {"text": "A generic adaptor grammar inference program infers these units from training data, making it easy to investigate how these assumptions affect learning.", "labels": [], "entities": []}, {"text": "However, there area number of choices in the design of adaptor grammars and the associated inference procedure.", "labels": [], "entities": []}, {"text": "While this paper studies the impact of these on the word segmentation task, these choices arise in other nonparametric Bayesian inference problems as well, so our results should be useful more generally.", "labels": [], "entities": [{"text": "word segmentation task", "start_pos": 52, "end_pos": 74, "type": "TASK", "confidence": 0.8149699171384176}]}, {"text": "The rest of this paper is organized as follows.", "labels": [], "entities": []}, {"text": "The next section reviews adaptor grammars and presents three different adaptor grammars for word segmentation that serve as running examples in this paper.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 92, "end_pos": 109, "type": "TASK", "confidence": 0.7491292953491211}]}, {"text": "Adaptor grammars contain a large number of adjustable parameters, and Section 3 discusses how these can be estimated using Bayesian techniques.", "labels": [], "entities": [{"text": "Adaptor grammars", "start_pos": 0, "end_pos": 16, "type": "TASK", "confidence": 0.8452572524547577}]}, {"text": "Section 4 examines several implementation options within the adaptor grammar inference algorithm and shows that they can make a significant impact on performance.", "labels": [], "entities": []}, {"text": "Cumulatively these changes make a significant difference in word segmentation accuracy: our final adaptor grammar performs unsupervised word segmentation with an 87% token f-score on the standard Brent version of the Bernstein-Ratner corpus, which is an error reduction of over 35% compared to the best previously reported results on this corpus.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 60, "end_pos": 77, "type": "TASK", "confidence": 0.7727361917495728}, {"text": "accuracy", "start_pos": 78, "end_pos": 86, "type": "METRIC", "confidence": 0.947462260723114}, {"text": "word segmentation", "start_pos": 136, "end_pos": 153, "type": "TASK", "confidence": 0.7151552885770798}, {"text": "error reduction", "start_pos": 254, "end_pos": 269, "type": "METRIC", "confidence": 0.9729337692260742}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Word segmentation accuracy measured by word token f-scores on Brent's version of the Bernstein-Ratner  corpus as a function of adaptor grammar, adaptor and estimation procedure. Pitman-Yor Process adaptors were used  when a X was sampled, otherwise Chinese Restaurant Process adaptors were used. In runs where \u03b8 was not integrated  out it was set uniformly, and all \u03b1 X = b X were set to 100 they were not sampled.", "labels": [], "entities": [{"text": "Word segmentation", "start_pos": 10, "end_pos": 27, "type": "TASK", "confidence": 0.7473704218864441}, {"text": "accuracy", "start_pos": 28, "end_pos": 36, "type": "METRIC", "confidence": 0.9066911935806274}, {"text": "Brent's version of the Bernstein-Ratner  corpus", "start_pos": 72, "end_pos": 119, "type": "DATASET", "confidence": 0.7248667478561401}]}]}