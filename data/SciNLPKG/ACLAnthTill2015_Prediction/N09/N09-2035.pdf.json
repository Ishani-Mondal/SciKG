{"title": [{"text": "Taking into Account the Differences between Actively and Passively Acquired Data: The Case of Active Learning with Support Vector Machines for Imbalanced Datasets", "labels": [], "entities": []}], "abstractContent": [{"text": "Actively sampled data can have very different characteristics than passively sampled data.", "labels": [], "entities": []}, {"text": "Therefore, it's promising to investigate using different inference procedures during AL than are used during passive learning (PL).", "labels": [], "entities": []}, {"text": "This general idea is explored in detail for the fo-cused case of AL with cost-weighted SVMs for imbalanced data, a situation that arises for many HLT tasks.", "labels": [], "entities": []}, {"text": "The key idea behind the proposed InitPA method for addressing imbalance is to base cost models during AL on an estimate of overall corpus imbalance computed via a small unbiased sample rather than the imbalance in the labeled training data, which is the leading method used during PL.", "labels": [], "entities": [{"text": "PL", "start_pos": 281, "end_pos": 283, "type": "TASK", "confidence": 0.9857978224754333}]}], "introductionContent": [{"text": "Recently there has been considerable interest in using active learning (AL) to reduce HLT annotation burdens.", "labels": [], "entities": [{"text": "HLT annotation", "start_pos": 86, "end_pos": 100, "type": "TASK", "confidence": 0.8631100654602051}]}, {"text": "Actively sampled data can have different characteristics than passively sampled data and therefore, this paper proposes modifying algorithms used to infer models during AL.", "labels": [], "entities": []}, {"text": "Since most AL research assumes the same learning algorithms will be used during AL as during passive learning 1 (PL), this paper opens up anew thread of AL research that accounts for the differences between passively and actively sampled data.", "labels": [], "entities": []}, {"text": "The specific case focused on in this paper is that of AL with SVMs (AL-SVM) for imbalanced * This research was conducted while the first author was a PhD student at the University of Delaware.", "labels": [], "entities": []}, {"text": "Passive learning refers to the typical supervised learning setup where the learner does not actively select its training data.", "labels": [], "entities": [{"text": "Passive learning", "start_pos": 0, "end_pos": 16, "type": "TASK", "confidence": 0.688987597823143}]}, {"text": "datasets 2 . Collectively, the factors: interest in AL, widespread class imbalance for many HLT tasks, interest in using SVMs, and PL research showing that SVM performance can be improved substantially by addressing imbalance, indicate the importance of the case of AL with SVMs with imbalanced data.", "labels": [], "entities": []}, {"text": "Extensive PL research has shown that learning algorithms' performance degrades for imbalanced datasets and techniques have been developed that prevent this degradation.", "labels": [], "entities": []}, {"text": "However, to date, relatively little work has addressed imbalance during AL (see Section 2).", "labels": [], "entities": [{"text": "AL", "start_pos": 72, "end_pos": 74, "type": "TASK", "confidence": 0.7949841022491455}]}, {"text": "In contrast to previous work, this paper advocates that the AL scenario brings out the need to modify PL approaches to dealing with imbalance.", "labels": [], "entities": []}, {"text": "In particular, anew method is developed for cost-weighted SVMs that estimates a cost model based on overall corpus imbalance rather than the imbalance in the so far labeled training data.", "labels": [], "entities": []}, {"text": "Section 2 discusses related work, Section 3 discusses the experimental setup, Section 4 presents the new method called InitPA, Section 5 evaluates InitPA, and Section 6 concludes.", "labels": [], "entities": []}], "datasetContent": [{"text": "We use relation extraction (RE) and text classification (TC) datasets and SVM light (Joachims, 1999) for training the SVMs.", "labels": [], "entities": [{"text": "relation extraction (RE)", "start_pos": 7, "end_pos": 31, "type": "TASK", "confidence": 0.8351034641265869}, {"text": "text classification (TC)", "start_pos": 36, "end_pos": 60, "type": "TASK", "confidence": 0.8240858793258667}]}, {"text": "For RE, we use AImed, previously used to train protein interaction extraction systems).", "labels": [], "entities": [{"text": "RE", "start_pos": 4, "end_pos": 6, "type": "TASK", "confidence": 0.946246862411499}, {"text": "protein interaction extraction", "start_pos": 47, "end_pos": 77, "type": "TASK", "confidence": 0.6370967229207357}]}, {"text": "As in previous work, we cast RE as a binary classification task (14.94% of the examples in AImed are positive).", "labels": [], "entities": []}, {"text": "We use the K GC kernel from (), one of the highest-performing systems on AImed to date and perform 10-fold cross validation.", "labels": [], "entities": [{"text": "K GC kernel", "start_pos": 11, "end_pos": 22, "type": "DATASET", "confidence": 0.8078557650248209}]}, {"text": "For TC, we use the Reuters-21578 ModApte split.", "labels": [], "entities": [{"text": "TC", "start_pos": 4, "end_pos": 6, "type": "TASK", "confidence": 0.7450166940689087}, {"text": "Reuters-21578 ModApte split", "start_pos": 19, "end_pos": 46, "type": "DATASET", "confidence": 0.9235498905181885}]}, {"text": "Since a document may belong to more than one category, each category is treated as a separate binary classification problem, as in.", "labels": [], "entities": []}, {"text": "As in, we use the ten largest categories, which have imbalances ranging from 1.88% to 29.96%.", "labels": [], "entities": []}, {"text": "In addition to InitPA and CurrentPA, we also implemented the methods from ().", "labels": [], "entities": [{"text": "CurrentPA", "start_pos": 26, "end_pos": 35, "type": "DATASET", "confidence": 0.9580093622207642}]}, {"text": "We implemented oversampling by duplicating points and by BootOS (.", "labels": [], "entities": [{"text": "BootOS", "start_pos": 57, "end_pos": 63, "type": "DATASET", "confidence": 0.7846380472183228}]}, {"text": "To avoid cluttering the graphs, we only show the highest-performing oversampling variant, which was by duplicating points.", "labels": [], "entities": []}, {"text": "Learning curves are presented in Figures 4 and 5.", "labels": [], "entities": []}, {"text": "Note InitPA is the highest-performing method for all datasets, especially in the practically important area of where the learning curves begin to plateau.", "labels": [], "entities": []}, {"text": "This area is important because this is around where we would want to stop AL.", "labels": [], "entities": []}, {"text": "Observe that the gains of InitPA over CurrentPA are smaller for Reuters.", "labels": [], "entities": [{"text": "InitPA", "start_pos": 26, "end_pos": 32, "type": "DATASET", "confidence": 0.7975573539733887}, {"text": "CurrentPA", "start_pos": 38, "end_pos": 47, "type": "DATASET", "confidence": 0.9259742498397827}, {"text": "Reuters", "start_pos": 64, "end_pos": 71, "type": "DATASET", "confidence": 0.9298216104507446}]}, {"text": "For some Reuters categories, InitPA and CurrentPA have nearly identical performance.", "labels": [], "entities": [{"text": "CurrentPA", "start_pos": 40, "end_pos": 49, "type": "DATASET", "confidence": 0.9561787843704224}]}, {"text": "Applying the models learned by CurrentPA at each round of AL on the data used to train the model reveals that the recall on the training data is nearly 100% for those categories where InitPA/CurrentPA perform similarly.", "labels": [], "entities": [{"text": "CurrentPA", "start_pos": 31, "end_pos": 40, "type": "DATASET", "confidence": 0.9160670042037964}, {"text": "recall", "start_pos": 114, "end_pos": 120, "type": "METRIC", "confidence": 0.9990673661231995}, {"text": "CurrentPA", "start_pos": 191, "end_pos": 200, "type": "DATASET", "confidence": 0.9178789854049683}]}, {"text": "Increasing the relative penalty for slack error on positive training points will not have much impact if (nearly) all of the pos train points are already classified correctly.", "labels": [], "entities": [{"text": "slack error", "start_pos": 36, "end_pos": 47, "type": "METRIC", "confidence": 0.7426393926143646}]}, {"text": "Thus, in situations where models are already achieving nearly 100% recall on their train data, InitPA is not expected to outperform CurrentPA.", "labels": [], "entities": [{"text": "recall", "start_pos": 67, "end_pos": 73, "type": "METRIC", "confidence": 0.9977685213088989}, {"text": "InitPA", "start_pos": 95, "end_pos": 101, "type": "METRIC", "confidence": 0.7848415970802307}, {"text": "CurrentPA", "start_pos": 132, "end_pos": 141, "type": "DATASET", "confidence": 0.9679580330848694}]}, {"text": "The hyperplanes learned during AL-SVM serve two purposes: sampling -they govern which unlabeled points will be selected for human annotation, and predicting -when AL stops, the most recently learned hyperplane is used for classifying test data.", "labels": [], "entities": [{"text": "predicting", "start_pos": 146, "end_pos": 156, "type": "TASK", "confidence": 0.936650276184082}]}, {"text": "Although all AL-SVM approaches we're aware of use the same hyperplane at each round of AL for both of these purposes, this is not required.", "labels": [], "entities": []}, {"text": "We compared InitPA with hybrid approaches where hyperplanes trained using an InitPA cost model are used for sampling and hyperplanes trained using a CurrentPA cost model are used for predicting, and viceversa, and found that InitPA performed better than both of these hybrid approaches.", "labels": [], "entities": [{"text": "CurrentPA", "start_pos": 149, "end_pos": 158, "type": "DATASET", "confidence": 0.954215407371521}, {"text": "predicting", "start_pos": 183, "end_pos": 193, "type": "TASK", "confidence": 0.9649932384490967}]}, {"text": "This indicates that the InitPA cost model yields hyperplanes that are better for both sampling and predicting.", "labels": [], "entities": [{"text": "predicting", "start_pos": 99, "end_pos": 109, "type": "TASK", "confidence": 0.8932019472122192}]}], "tableCaptions": []}