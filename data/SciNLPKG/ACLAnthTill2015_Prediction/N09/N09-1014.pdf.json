{"title": [{"text": "Graph-based Learning for Statistical Machine Translation", "labels": [], "entities": [{"text": "Statistical Machine Translation", "start_pos": 25, "end_pos": 56, "type": "TASK", "confidence": 0.8123653928438822}]}], "abstractContent": [{"text": "Current phrase-based statistical machine translation systems process each test sentence in isolation and do not enforce global consistency constraints, even though the test data is often internally consistent with respect to topic or style.", "labels": [], "entities": [{"text": "phrase-based statistical machine translation", "start_pos": 8, "end_pos": 52, "type": "TASK", "confidence": 0.5902738943696022}]}, {"text": "We propose anew consistency model for machine translation in the form of a graph-based semi-supervised learning algorithm that exploits similarities between training and test data and also similarities between different test sentences.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 38, "end_pos": 57, "type": "TASK", "confidence": 0.7908051908016205}]}, {"text": "The algorithm learns a regression function jointly over training and test data and uses the resulting scores to rerank translation hypotheses.", "labels": [], "entities": []}, {"text": "Evaluation on two travel expression translation tasks demonstrates improvements of up to 2.6 BLEU points absolute and 2.8% in PER.", "labels": [], "entities": [{"text": "travel expression translation", "start_pos": 18, "end_pos": 47, "type": "TASK", "confidence": 0.6238394578297933}, {"text": "BLEU", "start_pos": 93, "end_pos": 97, "type": "METRIC", "confidence": 0.9996349811553955}, {"text": "PER", "start_pos": 126, "end_pos": 129, "type": "METRIC", "confidence": 0.9953881502151489}]}], "introductionContent": [{"text": "Current phrase-based statistical machine translation (SMT) systems commonly operate at the sentence level-each sentence is translated in isolation, even when the test data consists of internally coherent paragraphs or stories, such as news articles.", "labels": [], "entities": [{"text": "phrase-based statistical machine translation (SMT)", "start_pos": 8, "end_pos": 58, "type": "TASK", "confidence": 0.7352764989648547}]}, {"text": "For each sentence, SMT systems choose the translation hypothesis that maximizes a combined log-linear model score, which is computed independently of all other sentences, using globally optimized combination weights.", "labels": [], "entities": [{"text": "SMT", "start_pos": 19, "end_pos": 22, "type": "TASK", "confidence": 0.9917032122612}]}, {"text": "Thus, similar input strings maybe translated in very different ways, depending on which component model happens to dominate the combined score for that sentence.", "labels": [], "entities": []}, {"text": "This is illustrated by the following example (from the IWSLT 2007 Arabic-English translation task): Source 1: Asf lA ymknk *lk hnAk klfp HwAly vmAnyn dwlAr lAlsAEp AlwAHdp Ref: sorry you can't there is a cost the charge is eighty dollars per hour 1-best: i'm sorry you can't therein the cost about eighty dollars fora one o'clock Source 2: E*rA lA ymknk t$gyl AltlfAz HtY tqlE AlTA}rp Ref: sorry you cannot turn the tv on until the plane has taken off 1-best: excuse me i you turn tv until the plane departs The phrase lA ymknk (you may not/you cannot) is translated differently (and wrongly in the second case) due to different segmentations and phrase translations chosen by the decoder.", "labels": [], "entities": [{"text": "IWSLT 2007 Arabic-English translation task", "start_pos": 55, "end_pos": 97, "type": "TASK", "confidence": 0.7736700415611267}]}, {"text": "Though different choices maybe sometimes appropriate, the lack of constraints enforcing translation consistency often leads to suboptimal translation performance.", "labels": [], "entities": []}, {"text": "It would be desirable to counter this effect by encouraging similar outputs for similar inputs (under a suitably defined notion of similarity, which may include e.g. a context specification for the phrase/sentence).", "labels": [], "entities": []}, {"text": "In machine learning, the idea of forcing the outputs of a statistical learner to vary smoothly with the underlying structure of the inputs has been formalized in the graph-based learning (GBL) framework.", "labels": [], "entities": []}, {"text": "In GBL, both labeled (train) and unlabeled (test) data samples are jointly represented as vertices in a graph whose edges encode pairwise similarities between samples.", "labels": [], "entities": []}, {"text": "Various learning algorithms can be applied to assign labels to the test samples while ensuring that the classification output varies smoothly along the manifold defined by the graph.", "labels": [], "entities": []}, {"text": "GBL has been successfully applied to a range of problems in computer vision, computational biology, and natural language processing.", "labels": [], "entities": [{"text": "GBL", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.711909830570221}, {"text": "natural language processing", "start_pos": 104, "end_pos": 131, "type": "TASK", "confidence": 0.6527503728866577}]}, {"text": "However, inmost cases, the learning tasks consisted of unstructured classification, where the input was represented by fixedlength feature vectors and the output was one of a finite set of discrete labels.", "labels": [], "entities": []}, {"text": "In machine translation, by contrast, both inputs and outputs consist of word strings of variable length, and the number of possible outputs is not fixed and practically unlimited.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 3, "end_pos": 22, "type": "TASK", "confidence": 0.7681683003902435}]}, {"text": "In this paper we propose anew graph-based learning algorithm with structured inputs and outputs to improve consistency in phrase-based statistical machine translation.", "labels": [], "entities": [{"text": "phrase-based statistical machine translation", "start_pos": 122, "end_pos": 166, "type": "TASK", "confidence": 0.5868524312973022}]}, {"text": "We define a joint similarity graph over training and test data and use an iterative label propagation procedure to regress a scoring function over the graph.", "labels": [], "entities": []}, {"text": "The resulting scores for unlabeled samples (translation hypotheses) are then combined with standard model scores in a log-linear translation model for the purpose of reranking.", "labels": [], "entities": []}, {"text": "First, from a machine translation perspective, we design and evaluate a global consistency model enforcing that similar inputs receive similar translations.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 14, "end_pos": 33, "type": "TASK", "confidence": 0.7671917676925659}]}, {"text": "Second, from a machine learning perspective, we apply graph-based learning to a task with structured inputs and outputs, which is a novel contribution in itself since previous applications of GBL have focused on predicting categorical labels.", "labels": [], "entities": [{"text": "predicting categorical labels", "start_pos": 212, "end_pos": 241, "type": "TASK", "confidence": 0.8567891120910645}]}, {"text": "We evaluate our approach on two machine translation tasks, the IWSLT 2007 Italianto-English and Arabic-to-English tasks, and demonstrate significant improvements over the baseline.", "labels": [], "entities": [{"text": "machine translation tasks", "start_pos": 32, "end_pos": 57, "type": "TASK", "confidence": 0.7569836378097534}, {"text": "IWSLT 2007 Italianto-English", "start_pos": 63, "end_pos": 91, "type": "DATASET", "confidence": 0.8931927879651388}]}], "datasetContent": [{"text": "We started with the IE system and initially investigated the effect of only including edges between labeled and unlabeled samples in the graph.", "labels": [], "entities": []}, {"text": "This is equivalent to using a weighted k-nearest neighbor reranker that, for each hypothesis, computes average similarity with its neighborhood of labeled points, and uses the resulting score for reranking.", "labels": [], "entities": []}, {"text": "Starting with the IE task and the BLEU-based similarity metric, we ran optimization experiments that varied the similarity threshold and compared sum vs. product combination of source and target similarity scores, settling for \u03b8 = 0.7 and product combination.", "labels": [], "entities": [{"text": "IE task", "start_pos": 18, "end_pos": 25, "type": "TASK", "confidence": 0.7458450198173523}, {"text": "BLEU-based similarity metric", "start_pos": 34, "end_pos": 62, "type": "METRIC", "confidence": 0.9444528023401896}]}, {"text": "We experimented with three different ways of weighting the contributions from labeled-unlabeled vs. unlabeled-unlabeled edges: (a) no weighting, (b) labeled-to-unlabeled edges were weighted 4 times stronger than unlabeledunlabeled ones; and (c) labeled-to-unlabeled edges were weighted 2 times stronger.", "labels": [], "entities": []}, {"text": "The weighting schemes do not lead to significantly different results.", "labels": [], "entities": []}, {"text": "The best result obtained shows again of 1.2 BLEU points on the dev set and 1 point on the eval set, reflecting PER gains of 2% and 1.2%, respectively.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 44, "end_pos": 48, "type": "METRIC", "confidence": 0.9990555644035339}, {"text": "PER", "start_pos": 111, "end_pos": 114, "type": "METRIC", "confidence": 0.998434841632843}]}, {"text": "We next tested the string kernel based similarity measure.", "labels": [], "entities": []}, {"text": "The parameter values were 0.5 for the gap penalty, a maximum substring length of k = 4, and weights of 0, 0.1, 0.2, 0.7.", "labels": [], "entities": []}, {"text": "These values were chosen heuristically and were not tuned extensively due to time constraints.", "labels": [], "entities": []}, {"text": "Results show significant improvements in PER and BLEU.", "labels": [], "entities": [{"text": "PER", "start_pos": 41, "end_pos": 44, "type": "METRIC", "confidence": 0.998491644859314}, {"text": "BLEU", "start_pos": 49, "end_pos": 53, "type": "METRIC", "confidence": 0.9984756112098694}]}, {"text": "In the context of the BTEC challenge task it is interesting to compare this approach to adding the development set directly to the training set.", "labels": [], "entities": [{"text": "BTEC challenge task", "start_pos": 22, "end_pos": 41, "type": "TASK", "confidence": 0.6716089844703674}]}, {"text": "Part of the improvements maybe due to utilizing kNN information from a data set that is matched to the test System dev-2 eval  set in terms of style.", "labels": [], "entities": []}, {"text": "If this data were also used for training the initial phrase table, the improvements might disappear.", "labels": [], "entities": []}, {"text": "We first optimized the log-linear model combination weights on the entire dev07 set (dev-1 and dev-2 in) before retraining the phrase table using the combined train and dev07 data.", "labels": [], "entities": []}, {"text": "The new baseline performance (shown in Table 4) is much better than before, due to the improved training data.", "labels": [], "entities": []}, {"text": "We then added GBL to this system by keeping the model combination weights trained for the previous system, using the N-best lists generated by the new system, and using the combined train+dev07 set as a train set for selecting similar sentences.", "labels": [], "entities": [{"text": "GBL", "start_pos": 14, "end_pos": 17, "type": "METRIC", "confidence": 0.9644672274589539}]}, {"text": "We used the GBL parameters that yielded the best performance in the experiments described above.", "labels": [], "entities": [{"text": "GBL", "start_pos": 12, "end_pos": 15, "type": "METRIC", "confidence": 0.6604707837104797}]}, {"text": "As can be seen from: Effect of GBL on IE system trained with matched data (eval set).", "labels": [], "entities": [{"text": "GBL", "start_pos": 31, "end_pos": 34, "type": "METRIC", "confidence": 0.55042564868927}]}, {"text": "For the AE task we used \u03b8 = 0.5; however, this threshold was not tuned extensively.", "labels": [], "entities": [{"text": "AE", "start_pos": 8, "end_pos": 10, "type": "METRIC", "confidence": 0.8820093274116516}, {"text": "\u03b8", "start_pos": 24, "end_pos": 25, "type": "METRIC", "confidence": 0.9486171007156372}]}, {"text": "Results using BLEU similarity are shown in.", "labels": [], "entities": [{"text": "BLEU similarity", "start_pos": 14, "end_pos": 29, "type": "METRIC", "confidence": 0.9314374029636383}]}, {"text": "The best result on the eval set yields an improvement of 1.2 BLEU points though only 0.2% reduction in PER.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 61, "end_pos": 65, "type": "METRIC", "confidence": 0.9994651675224304}, {"text": "PER", "start_pos": 103, "end_pos": 106, "type": "METRIC", "confidence": 0.9978985786437988}]}, {"text": "Overall, results seem to vary with parameter settings and nature of the test set (e.g. on dev5, used as a test set, not for optimization, a surprisingly larger improvement in BLEU of 2.7 points is obtained!).", "labels": [], "entities": [{"text": "BLEU", "start_pos": 175, "end_pos": 179, "type": "METRIC", "confidence": 0.9993707537651062}]}, {"text": "Overall, sentence similarities were observed to be lower for this task.", "labels": [], "entities": []}, {"text": "One reason maybe that the AE system includes statistical tokenization of the source side, which is itself error-prone in that it can split the same word in different ways depending on the con-  text.", "labels": [], "entities": []}, {"text": "Since our similarity measure is word-based, this may cause similar sentences to fall below the threshold.", "labels": [], "entities": []}, {"text": "The string kernel does not yield any improvement over the BLEU-based similarity measure on this task.", "labels": [], "entities": [{"text": "BLEU-based similarity measure", "start_pos": 58, "end_pos": 87, "type": "METRIC", "confidence": 0.9501902858416239}]}, {"text": "One possible improvement would be to use an extended string kernel that can take morphological similarity into account.", "labels": [], "entities": []}, {"text": "Example Below we give an actual example of a translation improvement, showing the source sentence, the 1-best hypotheses of the baseline system and GBL system, respectively, the references, and the translations of similar sentences in the graph neighborhood of the current sentence.", "labels": [], "entities": [{"text": "GBL system", "start_pos": 148, "end_pos": 158, "type": "DATASET", "confidence": 0.7560359835624695}]}], "tableCaptions": [{"text": " Table 1: Data set sizes and reference translations count.", "labels": [], "entities": []}, {"text": " Table 2: GBL results (%BLEU/PER) on IE task  for different weightings of labeled-labeled vs. labeled- unlabeled graph edges (BLEU-based similarity measure).", "labels": [], "entities": [{"text": "GBL", "start_pos": 10, "end_pos": 13, "type": "METRIC", "confidence": 0.8942309617996216}, {"text": "BLEU", "start_pos": 24, "end_pos": 28, "type": "METRIC", "confidence": 0.9985698461532593}, {"text": "PER", "start_pos": 29, "end_pos": 32, "type": "METRIC", "confidence": 0.5925574898719788}, {"text": "BLEU-based similarity measure", "start_pos": 126, "end_pos": 155, "type": "METRIC", "confidence": 0.9486047625541687}]}, {"text": " Table 3: GBL results (%BLEU/PER) on IE tasks with  string-kernel based similarity measure.", "labels": [], "entities": [{"text": "GBL", "start_pos": 10, "end_pos": 13, "type": "METRIC", "confidence": 0.8728951811790466}, {"text": "BLEU/PER)", "start_pos": 24, "end_pos": 33, "type": "METRIC", "confidence": 0.8078005835413933}, {"text": "IE tasks", "start_pos": 37, "end_pos": 45, "type": "TASK", "confidence": 0.8243466019630432}]}, {"text": " Table 4: Effect of GBL on IE system trained with  matched data (eval set).", "labels": [], "entities": []}, {"text": " Table 5: AE results (%BLEU/PER, \u03b8 = 0.5)", "labels": [], "entities": [{"text": "AE", "start_pos": 10, "end_pos": 12, "type": "METRIC", "confidence": 0.9990724325180054}, {"text": "BLEU", "start_pos": 23, "end_pos": 27, "type": "METRIC", "confidence": 0.9993822574615479}, {"text": "PER", "start_pos": 28, "end_pos": 31, "type": "METRIC", "confidence": 0.7074378728866577}]}]}