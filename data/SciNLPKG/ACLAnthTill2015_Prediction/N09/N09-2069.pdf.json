{"title": [{"text": "Automatic Chinese Abbreviation Generation Using Conditional Random Field", "labels": [], "entities": [{"text": "Chinese Abbreviation Generation", "start_pos": 10, "end_pos": 41, "type": "TASK", "confidence": 0.5792573392391205}]}], "abstractContent": [{"text": "This paper presents anew method for automatically generating abbreviations for Chi-nese organization names.", "labels": [], "entities": []}, {"text": "Abbreviations are commonly used in spoken Chinese, especially for organization names.", "labels": [], "entities": []}, {"text": "The generation of Chinese abbreviation is much more complex than English abbreviations, most of which are acronyms and truncations.", "labels": [], "entities": []}, {"text": "The abbreviation generation process is formulated as a character tagging problem and the conditional random field (CRF) is used as the tagging model.", "labels": [], "entities": [{"text": "abbreviation generation", "start_pos": 4, "end_pos": 27, "type": "TASK", "confidence": 0.8058660328388214}, {"text": "character tagging", "start_pos": 55, "end_pos": 72, "type": "TASK", "confidence": 0.7562958002090454}]}, {"text": "A carefully selected group of features is used in the CRF model.", "labels": [], "entities": []}, {"text": "After generating a list of abbreviation candidates using the CRF, a length model is incorporated to re-rank the candidates.", "labels": [], "entities": [{"text": "CRF", "start_pos": 61, "end_pos": 64, "type": "DATASET", "confidence": 0.8831217288970947}]}, {"text": "Finally the full-name and abbreviation co-occurrence information from a web search engine is utilized to further improve the performance.", "labels": [], "entities": []}, {"text": "We achieved top-10 coverage of 88.3% by the proposed method.", "labels": [], "entities": [{"text": "coverage", "start_pos": 19, "end_pos": 27, "type": "METRIC", "confidence": 0.9795978665351868}]}], "introductionContent": [{"text": "Long named entities are frequently abbreviated in oral Chinese language for efficiency and simplicity.", "labels": [], "entities": []}, {"text": "Therefore, abbreviation modeling is an important building component for many systems that accept spoken input, such as directory assistance and voice search systems.", "labels": [], "entities": [{"text": "abbreviation modeling", "start_pos": 11, "end_pos": 32, "type": "TASK", "confidence": 0.9650457203388214}]}, {"text": "While English abbreviations are usually formed as acronyms, Chinese abbreviations are much more complex, as shown in.", "labels": [], "entities": []}, {"text": "Most of the Chinese abbreviations are formed by selecting several characters from full-names, which are not necessarily the first character of each word.", "labels": [], "entities": []}, {"text": "Usually the original character order in the full-name is preserved in Figure 1: Chinese abbreviation examples the abbreviation.", "labels": [], "entities": []}, {"text": "However, re-ordering of characters as shown in the third example in where characters \"\" and \"\" are swapped in the abbreviation, also happens.", "labels": [], "entities": []}, {"text": "There has been a considerable amount of research on extracting full-name and abbreviation pairs in the same document for obtaining abbreviations).", "labels": [], "entities": []}, {"text": "However, generation of abbreviations given a full-name is still a non-trivial problem.) have proposed using a hidden Markov model to generate abbreviations from full-names.", "labels": [], "entities": []}, {"text": "However, their method assumes that there is no word-to-null mapping, which means that every word in the full-name has to contribute at least one character to the abbreviation.", "labels": [], "entities": []}, {"text": "This assumption does not hold for organizations' names which have many word skips in the abbreviation generation.", "labels": [], "entities": []}, {"text": "The CRF was first introduced to natural language processing (NLP) by) and has been widely used in word segmentation, part-ofspeech (POS) tagging, and some other NLP tasks.", "labels": [], "entities": [{"text": "natural language processing (NLP)", "start_pos": 32, "end_pos": 65, "type": "TASK", "confidence": 0.792784720659256}, {"text": "word segmentation", "start_pos": 98, "end_pos": 115, "type": "TASK", "confidence": 0.7739233672618866}, {"text": "part-ofspeech (POS) tagging", "start_pos": 117, "end_pos": 144, "type": "TASK", "confidence": 0.5860383689403534}]}, {"text": "In this paper, we convert the Chinese abbreviation generation process to a CRF tagging problem.", "labels": [], "entities": [{"text": "Chinese abbreviation generation", "start_pos": 30, "end_pos": 61, "type": "TASK", "confidence": 0.586404949426651}, {"text": "CRF tagging", "start_pos": 75, "end_pos": 86, "type": "TASK", "confidence": 0.8280909955501556}]}, {"text": "The key problem here is how to find a group of discrim-inant and robust features.", "labels": [], "entities": []}, {"text": "After using the CRF, we get a list of abbreviation candidates with associate probability scores.", "labels": [], "entities": [{"text": "CRF", "start_pos": 16, "end_pos": 19, "type": "DATASET", "confidence": 0.8720919489860535}]}, {"text": "We also use the prior conditional probability of the length of the abbreviations given the length of the full-names to complement the CRF probability scores.", "labels": [], "entities": []}, {"text": "Such global information is hard to include in the CRF model.", "labels": [], "entities": []}, {"text": "In addition, we apply the full-name and abbreviation candidate cooccurrence statistics obtained on the web to increase the correctness of the abbreviation candidates.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Length statistics on the training set", "labels": [], "entities": [{"text": "Length", "start_pos": 10, "end_pos": 16, "type": "METRIC", "confidence": 0.9536536931991577}]}]}