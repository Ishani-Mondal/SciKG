{"title": [{"text": "Dynamic Programming-based Search Algorithms in NLP", "labels": [], "entities": []}], "abstractContent": [{"text": "Dynamic Programming (DP) is an important class of algorithms widely used in many areas of speech and language processing.", "labels": [], "entities": [{"text": "Dynamic Programming (DP)", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.8104526042938233}, {"text": "speech and language processing", "start_pos": 90, "end_pos": 120, "type": "TASK", "confidence": 0.6328325420618057}]}, {"text": "It provides efficient solutions to seemingly intractable inference over exponentially-large spaces by sharing overlapping subproblems.", "labels": [], "entities": []}, {"text": "Well-known examples of DP in our field include Viterbi and Forward-Backward Algorithms for finite-state models, CKY and Earley Algorithms for context-free parsing, and A* Algorithm for both.", "labels": [], "entities": [{"text": "CKY", "start_pos": 112, "end_pos": 115, "type": "DATASET", "confidence": 0.9242910742759705}]}, {"text": "These algorithms are widely used to solve problems ranging from sequence labeling to word alignment to machine translation decoding.", "labels": [], "entities": [{"text": "sequence labeling", "start_pos": 64, "end_pos": 81, "type": "TASK", "confidence": 0.6769101172685623}, {"text": "word alignment", "start_pos": 85, "end_pos": 99, "type": "TASK", "confidence": 0.7945947349071503}, {"text": "machine translation decoding", "start_pos": 103, "end_pos": 131, "type": "TASK", "confidence": 0.8209495941797892}]}, {"text": "With this overwhelming popularity, this tutorial aims to provide a better understanding of DP from both theoretical and practical perspectives.", "labels": [], "entities": [{"text": "DP", "start_pos": 91, "end_pos": 93, "type": "TASK", "confidence": 0.8972465395927429}]}, {"text": "In the theory part, we try to unify various DP algorithms under a generic algebraic framework, where the above mentioned examples are merely special cases, and we can easily analyze their correctness and complexities.", "labels": [], "entities": []}, {"text": "However, exact DP algorithms are often infeasible in practice due to time and space constraints.", "labels": [], "entities": []}, {"text": "So in the practice part, we will survey several widely used tricks to reduce the size of the search space, including beam search, histogram pruning, coarse-to-fine search, and cube pruning.", "labels": [], "entities": [{"text": "beam search", "start_pos": 117, "end_pos": 128, "type": "TASK", "confidence": 0.8518166244029999}]}, {"text": "We will discuss these methods within the context of state-of-the-art large-scale NLP systems.", "labels": [], "entities": []}], "introductionContent": [], "datasetContent": [], "tableCaptions": []}