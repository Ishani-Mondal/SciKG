{"title": [{"text": "Topic Identification Using Wikipedia Graph Centrality", "labels": [], "entities": [{"text": "Topic Identification", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.8909215033054352}]}], "abstractContent": [{"text": "This paper presents a method for automatic topic identification using a graph-centrality algorithm applied to an encyclopedic graph derived from Wikipedia.", "labels": [], "entities": [{"text": "topic identification", "start_pos": 43, "end_pos": 63, "type": "TASK", "confidence": 0.804463654756546}]}, {"text": "When tested on a data set with manually assigned topics, the system is found to significantly improve over a simpler baseline that does not make use of the external encyclopedic knowledge.", "labels": [], "entities": []}], "introductionContent": [{"text": "Document topics have been used fora longtime by librarians to improve the retrieval of a document, and to provide background or associated information for browsing by users.", "labels": [], "entities": []}, {"text": "They can also assist search, background information gathering and contextualization tasks, and enhanced relevancy measures.", "labels": [], "entities": [{"text": "background information gathering", "start_pos": 29, "end_pos": 61, "type": "TASK", "confidence": 0.7507215539614359}]}, {"text": "The goal of the work described in this paper is to automatically find topics that are relevant to an input document.", "labels": [], "entities": []}, {"text": "We refer to this task as \"topic identification\".", "labels": [], "entities": [{"text": "topic identification", "start_pos": 26, "end_pos": 46, "type": "TASK", "confidence": 0.8822237551212311}]}, {"text": "For instance, starting with a document on \"United States in the Cold War,\" we want to identify relevant topics, such as \"history,\" \"Global Conflicts,\" \"Soviet Union,\" and so forth.", "labels": [], "entities": []}, {"text": "We propose an unsupervised method for topic identification, based on a biased graph centrality algorithm applied to a large knowledge graph built from Wikipedia.", "labels": [], "entities": [{"text": "topic identification", "start_pos": 38, "end_pos": 58, "type": "TASK", "confidence": 0.9454299509525299}]}, {"text": "The task of topic identification goes beyond keyword extraction, since relevant topics may not be necessarily mentioned in the document, and instead have to be obtained from some repositories of external knowledge.", "labels": [], "entities": [{"text": "topic identification", "start_pos": 12, "end_pos": 32, "type": "TASK", "confidence": 0.8341883420944214}, {"text": "keyword extraction", "start_pos": 45, "end_pos": 63, "type": "TASK", "confidence": 0.7897335588932037}]}, {"text": "The task is also different from text classification, since the topics are either not known in advance or are provided in the form of a controlled vocabulary with thousands of entries, and thus no classification can be performed.", "labels": [], "entities": [{"text": "text classification", "start_pos": 32, "end_pos": 51, "type": "TASK", "confidence": 0.8341836929321289}]}, {"text": "Instead, with topic identification, we aim to find topics (or categories 1 ) that are relevant to the document at hand, which can be used to enrich the content of the document with relevant external knowledge.", "labels": [], "entities": [{"text": "topic identification", "start_pos": 14, "end_pos": 34, "type": "TASK", "confidence": 0.7222273796796799}]}], "datasetContent": [{"text": "We run two experiments, aimed at measuring the relevancy of the automatically identified topics with respect to a manually annotated gold standard data set.", "labels": [], "entities": [{"text": "gold standard data set", "start_pos": 133, "end_pos": 155, "type": "DATASET", "confidence": 0.7363686338067055}]}, {"text": "In the first experiment, the identification of the important concepts in the input text (used to bias the topic ranking process) is performed manually, by the Wikipedia users.", "labels": [], "entities": [{"text": "topic ranking", "start_pos": 106, "end_pos": 119, "type": "TASK", "confidence": 0.6909050792455673}]}, {"text": "In the second experiment, the identification of these important concepts is done automatically with the Wikify!", "labels": [], "entities": [{"text": "Wikify!", "start_pos": 104, "end_pos": 111, "type": "DATASET", "confidence": 0.8840629160404205}]}, {"text": "In both experiments, the ranking of the concepts from the encyclopedic graph is performed using the dynamic ranking process described in Section 2.", "labels": [], "entities": []}, {"text": "We use a data set consisting of 150 articles from Wikipedia, which have been explicitly removed from the encyclopedic graph.", "labels": [], "entities": []}, {"text": "All the articles in this data set include manual annotations of the relevant categories, as assigned by the Wikipedia users, against which we can measure the quality of the automatic topic assignments.", "labels": [], "entities": []}, {"text": "The 150 articles have been randomly selected while following the constraint that they each contain at least three article links and at least three category links.", "labels": [], "entities": []}, {"text": "Our task is to rediscover the relevant categories for each page.", "labels": [], "entities": []}, {"text": "Note that the task is non-trivial, since there are more than 350,000 categories to choose from.", "labels": [], "entities": []}, {"text": "We evaluate the quality of our system through the standard measures of precision and recall.", "labels": [], "entities": [{"text": "precision", "start_pos": 71, "end_pos": 80, "type": "METRIC", "confidence": 0.9997420907020569}, {"text": "recall", "start_pos": 85, "end_pos": 91, "type": "METRIC", "confidence": 0.9988102912902832}]}], "tableCaptions": []}