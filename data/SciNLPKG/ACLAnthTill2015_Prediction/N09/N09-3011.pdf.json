{"title": [{"text": "Loss-Sensitive Discriminative Training of Machine Transliteration Models", "labels": [], "entities": []}], "abstractContent": [{"text": "In machine transliteration we transcribe a name across languages while maintaining its phonetic information.", "labels": [], "entities": [{"text": "machine transliteration", "start_pos": 3, "end_pos": 26, "type": "TASK", "confidence": 0.740669846534729}]}, {"text": "In this paper, we present a novel sequence transduction algorithm for the problem of machine transliter-ation.", "labels": [], "entities": []}, {"text": "Our model is discriminatively trained by the MIRA algorithm, which improves the traditional Perceptron training in three ways: (1) It allows us to consider k-best translitera-tions instead of the best one.", "labels": [], "entities": [{"text": "MIRA", "start_pos": 45, "end_pos": 49, "type": "METRIC", "confidence": 0.9081821441650391}]}, {"text": "(2) It is trained based on the ranking of these transliterations according to user-specified loss function (Lev-enshtein edit distance).", "labels": [], "entities": [{"text": "Lev-enshtein edit distance)", "start_pos": 108, "end_pos": 135, "type": "METRIC", "confidence": 0.7991658449172974}]}, {"text": "(3) It enables the user to tune a built-in parameter to cope with noisy non-separable data during training.", "labels": [], "entities": []}, {"text": "On an Arabic-English name transliteration task, our model achieves a relative error reduction of 2.2% over a perceptron-based model with similar features, and an error reduction of 7.2% over a statistical machine translation model with more complex features.", "labels": [], "entities": [{"text": "relative error reduction", "start_pos": 69, "end_pos": 93, "type": "METRIC", "confidence": 0.7540680766105652}, {"text": "error reduction", "start_pos": 162, "end_pos": 177, "type": "METRIC", "confidence": 0.9746561050415039}, {"text": "statistical machine translation", "start_pos": 193, "end_pos": 224, "type": "TASK", "confidence": 0.6689574321111044}]}], "introductionContent": [], "datasetContent": [{"text": "We apply our model to the real-world ArabicEnglish name transliteration task on a data set of 10,084 Arabic names from the LDC.", "labels": [], "entities": [{"text": "ArabicEnglish name transliteration task", "start_pos": 37, "end_pos": 76, "type": "TASK", "confidence": 0.7216788232326508}]}, {"text": "The data set consists of Arabic names in an ASCII-based alphabet and its English rendering.", "labels": [], "entities": []}, {"text": "shows a few examples of Arabic-English pairs in our data set.", "labels": [], "entities": []}, {"text": "We use the same training/development/testing (8084/1000/1000) set as the one used in a previous benchmark study.", "labels": [], "entities": []}, {"text": "The development and testing data were obtained by randomly removing entries from the training data.", "labels": [], "entities": []}, {"text": "The absence of short vowels (e.g. \"a\" in NB\"I, nab'i), doubled consonants (e.g. \"ww\" in FWAL, fawwal) and other diacritics in Arabic make the transliteration a hard problem.", "labels": [], "entities": [{"text": "FWAL", "start_pos": 88, "end_pos": 92, "type": "DATASET", "confidence": 0.8625234365463257}]}, {"text": "Therefore, it is hard to achieve perfect accuracy on this data set.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 41, "end_pos": 49, "type": "METRIC", "confidence": 0.9993233680725098}]}, {"text": "For training, we set K = 20 best hypotheses and 1.", "labels": [], "entities": []}, {"text": "a = arg max\u00e2max\u02c6max\u00e2 w \u03c4 \u00b7 \u03a6(\u02c6 a, e, f ) (Find best scoring alignment between e and f using dynamic programming) 2.", "labels": [], "entities": []}, {"text": "Generate a list of K-best target hypotheses {e \u2032 1 , e \u2032 2 , . .", "labels": [], "entities": []}, {"text": ", e \u2032 K } given the current parameters w \u03c4 . Let the corresponding alignments for the targets be . Set w \u03c4 +1 to be the solution of :  C = 1.0 and run the algorithm for T = 10 epochs.", "labels": [], "entities": []}, {"text": "To evaluate our algorithm, we generate 1-best (or 5-best) hypotheses using the beam search procedure and measure accuracy as the percentage of instances in which the target sequence e is one of the 1-best (or 5-best) targets.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 113, "end_pos": 121, "type": "METRIC", "confidence": 0.9992895126342773}]}, {"text": "The input features are based on character m-grams form = 1, 2, 3.", "labels": [], "entities": []}, {"text": "Unlike previ-ous generative transliteration models, no additional language model feature is used.", "labels": [], "entities": [{"text": "previ-ous generative transliteration", "start_pos": 7, "end_pos": 43, "type": "TASK", "confidence": 0.6874613960584005}]}, {"text": "We compare our model against a state-of-the-art statistical machine translation (SMT) system) and an averaged perceptron edit model (PTEM) with identical features).", "labels": [], "entities": [{"text": "statistical machine translation (SMT)", "start_pos": 48, "end_pos": 85, "type": "TASK", "confidence": 0.828918973604838}]}, {"text": "The SMT system directly models the posterior probability P r(e|f ) using a log-linear combination of several sub-models: a characterbased phrase translation model, a character-based lexicon model, a character penalty and a phrase penalty.", "labels": [], "entities": [{"text": "SMT", "start_pos": 4, "end_pos": 7, "type": "TASK", "confidence": 0.9910879731178284}, {"text": "phrase translation", "start_pos": 138, "end_pos": 156, "type": "TASK", "confidence": 0.6747623383998871}]}, {"text": "In the PTEM model, the update rule only considers the best target sequence and modifies the parameters Model (train+dev) 1-best 5-best SMT 0.528 0.824 PTEM 0.552 0.803 MIRA 0.562 0.841: The 1-best and 5-best accuracy of different models on the Arabic-English transliteration task.", "labels": [], "entities": [{"text": "MIRA", "start_pos": 168, "end_pos": 172, "type": "METRIC", "confidence": 0.8064701557159424}, {"text": "accuracy", "start_pos": 208, "end_pos": 216, "type": "METRIC", "confidence": 0.9860419631004333}]}, {"text": "At 95% confidence level, MIRA/PTEM outperform the SMT model in 1-best accuracy and MIRA outperforms PTEM/SMT in 5-best accuracy.", "labels": [], "entities": [{"text": "MIRA", "start_pos": 25, "end_pos": 29, "type": "METRIC", "confidence": 0.8717947602272034}, {"text": "PTEM", "start_pos": 30, "end_pos": 34, "type": "METRIC", "confidence": 0.6596951484680176}, {"text": "SMT", "start_pos": 50, "end_pos": 53, "type": "TASK", "confidence": 0.9769195318222046}, {"text": "accuracy", "start_pos": 70, "end_pos": 78, "type": "METRIC", "confidence": 0.9296187162399292}, {"text": "MIRA", "start_pos": 83, "end_pos": 87, "type": "METRIC", "confidence": 0.9633564352989197}, {"text": "SMT", "start_pos": 105, "end_pos": 108, "type": "TASK", "confidence": 0.6444174647331238}, {"text": "accuracy", "start_pos": 119, "end_pos": 127, "type": "METRIC", "confidence": 0.9391623139381409}]}, {"text": "shows the 1-best and 5-best accuracy of each model trained on the combined train+dev data set.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 28, "end_pos": 36, "type": "METRIC", "confidence": 0.9931938052177429}, {"text": "train+dev data set", "start_pos": 75, "end_pos": 93, "type": "DATASET", "confidence": 0.8447324872016907}]}, {"text": "All the models are evaluated on the same test set.", "labels": [], "entities": []}, {"text": "Both MIRA and PTEM algorithms outperform the SMT model in terms of 1-best accuracy.", "labels": [], "entities": [{"text": "MIRA", "start_pos": 5, "end_pos": 9, "type": "METRIC", "confidence": 0.9266437292098999}, {"text": "PTEM", "start_pos": 14, "end_pos": 18, "type": "METRIC", "confidence": 0.9237560033798218}, {"text": "SMT", "start_pos": 45, "end_pos": 48, "type": "TASK", "confidence": 0.9914183616638184}, {"text": "accuracy", "start_pos": 74, "end_pos": 82, "type": "METRIC", "confidence": 0.8803144693374634}]}, {"text": "The differences inaccuracy are significant at 95% confidence level, using the bootstrapping method for hypothesis testing.", "labels": [], "entities": []}, {"text": "The difference in 1-best performance of MIRA and PTEM is not significant.", "labels": [], "entities": [{"text": "1-best", "start_pos": 18, "end_pos": 24, "type": "METRIC", "confidence": 0.9632919430732727}, {"text": "MIRA", "start_pos": 40, "end_pos": 44, "type": "METRIC", "confidence": 0.7360237836837769}, {"text": "PTEM", "start_pos": 49, "end_pos": 53, "type": "METRIC", "confidence": 0.7840277552604675}]}, {"text": "At 5-best, the MIRA model outperforms both SMT and PTEM model.", "labels": [], "entities": [{"text": "MIRA", "start_pos": 15, "end_pos": 19, "type": "METRIC", "confidence": 0.9313206076622009}, {"text": "SMT", "start_pos": 43, "end_pos": 46, "type": "TASK", "confidence": 0.8618519306182861}, {"text": "PTEM", "start_pos": 51, "end_pos": 55, "type": "METRIC", "confidence": 0.826252281665802}]}, {"text": "We conjecture that using the problem-specific Levenshtein loss function helps filter bad target sequences from the K-best outputs during training.", "labels": [], "entities": [{"text": "Levenshtein loss function", "start_pos": 46, "end_pos": 71, "type": "METRIC", "confidence": 0.7510813275973002}]}, {"text": "Ina second experiment we studied the effect of changing C on the performance of the algorithm.", "labels": [], "entities": []}, {"text": "We ran the algorithm with the above settings, except varying the value of the complexity parameter to one of 7 values in the range C = 0.00001, 0.0001, . .", "labels": [], "entities": []}, {"text": ", 0.1, 1.0, training only using the train set, and evaluating the resulting model on  the test set.", "labels": [], "entities": []}, {"text": "The results are summarized in.", "labels": [], "entities": []}, {"text": "The entry marked with a star * indicates the model that achieved the best performance on the dev set fora particular choice of evaluation measure (1-best or 5-best).", "labels": [], "entities": []}, {"text": "We find that changing C does have an effect on model performance.", "labels": [], "entities": []}, {"text": "As the value of C decreases, the performance at lower ranks improves: C = 0.01 is good for 5-best accuracy and C = 0.001 for 20-best accuracy (not in table).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 98, "end_pos": 106, "type": "METRIC", "confidence": 0.9789365530014038}, {"text": "accuracy", "start_pos": 133, "end_pos": 141, "type": "METRIC", "confidence": 0.9665782451629639}]}, {"text": "As C is further reduced, a greater number of iterations are needed to converge.", "labels": [], "entities": []}, {"text": "In our model, where the alignments are not observed but inferred during training, we find that making small incremental updates makes our algorithm more robust.", "labels": [], "entities": []}, {"text": "Indeed, setting C = 0.01 and training on the train+dev set improves 5-best performance of our model from 0.841 to 0.861.", "labels": [], "entities": [{"text": "C", "start_pos": 16, "end_pos": 17, "type": "METRIC", "confidence": 0.9637312889099121}]}, {"text": "Hence, the choice of C is important.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 3: The effect of varying model parameter C on 1,5- best accuracy on the test set. All the models are trained  with Levenshtein loss and 20-best targets. The super- script  *  indicates the models that achieved the greatest  performance on the dev set for a particular column.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 63, "end_pos": 71, "type": "METRIC", "confidence": 0.9582290053367615}, {"text": "Levenshtein loss", "start_pos": 122, "end_pos": 138, "type": "METRIC", "confidence": 0.9600836336612701}]}]}