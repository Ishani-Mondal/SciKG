{"title": [{"text": "A Finite-State Turn-Taking Model for Spoken Dialog Systems", "labels": [], "entities": [{"text": "Spoken Dialog", "start_pos": 37, "end_pos": 50, "type": "TASK", "confidence": 0.8509097397327423}]}], "abstractContent": [{"text": "This paper introduces the Finite-State Turn-Taking Machine (FSTTM), anew model to control the turn-taking behavior of conversational agents.", "labels": [], "entities": []}, {"text": "Based on a non-deterministic finite-state machine, the FSTTM uses a cost matrix and decision theoretic principles to select a turn-taking action at anytime.", "labels": [], "entities": [{"text": "FSTTM", "start_pos": 55, "end_pos": 60, "type": "DATASET", "confidence": 0.7824647426605225}]}, {"text": "We show how the model can be applied to the problem of end-of-turn detection.", "labels": [], "entities": [{"text": "end-of-turn detection", "start_pos": 55, "end_pos": 76, "type": "TASK", "confidence": 0.6744592934846878}]}, {"text": "Evaluation results on a deployed spoken dialog system show that the FSTTM provides significantly higher responsiveness than previous approaches.", "labels": [], "entities": [{"text": "FSTTM", "start_pos": 68, "end_pos": 73, "type": "DATASET", "confidence": 0.7284297943115234}]}], "introductionContent": [{"text": "Turn-taking, the process by which participants in a conversation alternate speech and silence, is an essential component of spoken interaction.", "labels": [], "entities": []}, {"text": "In order to lead productive conversations, people need not only know what to say but also when to say it.", "labels": [], "entities": []}, {"text": "Decades of research on Conversation Analysis and psycholinguistics) have shown that human turn-taking behavior relies on a wide range of rules and signals at many different levels of language, from prosody to syntax, semantics, and discourse structure.", "labels": [], "entities": [{"text": "Conversation Analysis", "start_pos": 23, "end_pos": 44, "type": "TASK", "confidence": 0.9422491192817688}]}, {"text": "In contrast, turn-taking in spoken dialog systems is often reduced toad hoc rules only based on very low level features.", "labels": [], "entities": []}, {"text": "This simplistic approach leads to inefficient, unnatural, and possibly confusing behavior ().", "labels": [], "entities": []}, {"text": "Recently, more complex models of turn-taking have been proposed).", "labels": [], "entities": []}, {"text": "Yet, these models still rely extensively on hand-coded expert knowledge and do not lend themselves to data-driven optimization.", "labels": [], "entities": []}, {"text": "Furthermore, to our knowledge, no such model has been deployed in a widely used system outside of the laboratory.", "labels": [], "entities": []}, {"text": "In this paper, we propose a flexible, practical model of turn-taking behavior that builds upon previous work on finite-state models of the conversational floor.", "labels": [], "entities": []}, {"text": "Because of its simplicity and generality, this model can be applied to many turn-taking phenomena.", "labels": [], "entities": []}, {"text": "At the same time, being grounded in decision theory, it lends itself well to data-driven optimization.", "labels": [], "entities": [{"text": "decision theory", "start_pos": 36, "end_pos": 51, "type": "TASK", "confidence": 0.9012176990509033}, {"text": "data-driven optimization", "start_pos": 77, "end_pos": 101, "type": "TASK", "confidence": 0.7125771343708038}]}, {"text": "We illustrate our approach by applying the model to a specific turn-taking task: end-of-turn detection.", "labels": [], "entities": [{"text": "end-of-turn detection", "start_pos": 81, "end_pos": 102, "type": "TASK", "confidence": 0.6739960312843323}]}, {"text": "2 Conversational Floor as a Finite-State Machine 2.1 6-state finite state models of turn-taking In the 1960's and early 1970's, several researchers proposed models to explain the rhythmic turn-taking patterns inhuman conversation.", "labels": [], "entities": []}, {"text": "In particular, Jaffe and Feldstein (1970) studied the mean duration of pauses, switching pauses (when a different speaker takes the floor), simultaneous speech, and (singlespeaker) vocalizations in recorded dyadic conversations.", "labels": [], "entities": []}, {"text": "Based on their observation that these durations follow exponential distributions, they proposed first-order Markov models to capture the alternation of speech and silence in dialog.", "labels": [], "entities": []}, {"text": "Their initial model had four states: only participant A is speak-: Our six-state model of turn-taking, inspired by and.", "labels": [], "entities": []}, {"text": "See section 3.1 fora description of the states.", "labels": [], "entities": []}, {"text": "ing; only participant B is speaking; both participants are speaking; and neither participant is speaking.", "labels": [], "entities": []}, {"text": "However, such a model fails to distinguish switching pauses from A to B from switching pauses from B to A.", "labels": [], "entities": []}, {"text": "Based on this observation, they extend their model to a six-state model which they found to better fit their data than the four-state model.", "labels": [], "entities": []}, {"text": "Around the same time, Brady (1969) developed a very similar six-state model.", "labels": [], "entities": []}, {"text": "He trained the parameters on a recorded conversation and compared the generated conversations to the original real one along several dimensions (pause and speech segment durations, overlaps, etc), finding that his model generally produced a good fit of the data.", "labels": [], "entities": []}], "datasetContent": [{"text": "We performed two batch evaluations of the FSTTM.", "labels": [], "entities": [{"text": "FSTTM", "start_pos": 42, "end_pos": 47, "type": "DATASET", "confidence": 0.885784924030304}]}, {"text": "The first one aims at comparing in-pause-FSTTM with a fixed-threshold baseline as well as previous data-driven endpointing methods proposed in (reimplemented by us) and.", "labels": [], "entities": []}, {"text": "This evaluation was done on the corpus used in (the \"2007 corpus\").", "labels": [], "entities": [{"text": "2007 corpus\")", "start_pos": 53, "end_pos": 66, "type": "DATASET", "confidence": 0.9267608126004537}]}, {"text": "As seen in, the FSTTM outperforms all other approaches (albeit only slightly compared to, improving over the fixed threshold baseline by up to 29.5%.", "labels": [], "entities": [{"text": "FSTTM", "start_pos": 16, "end_pos": 21, "type": "DATASET", "confidence": 0.46509966254234314}]}, {"text": "Second, we compared the anytime-FSTTM with in-pause-FSTTM and a fixed-threshold baseline (for reference) on the more recent 2008 corpus (since the 2007 corpus did not contain all necessary features for anytime-FSTTM).", "labels": [], "entities": []}, {"text": "We set C p G = 1 and set C s G to either 0, leading to an endpointer that never endpoints during speech (in-pause-FSTTM), or 1000 (anytime-FSTTM).", "labels": [], "entities": []}, {"text": "In both cases, we vary C U to compute the latency / cut-in rate trade-off curve.", "labels": [], "entities": [{"text": "latency / cut-in rate trade-off curve", "start_pos": 42, "end_pos": 79, "type": "METRIC", "confidence": 0.8496109346548716}]}, {"text": "The results are shown in (b).", "labels": [], "entities": []}, {"text": "Anytime-FSTTM endpointing is consistently better than inpause-FSTTM.", "labels": [], "entities": []}, {"text": "For example, at a cut-in rate of 5%, anytime-FSTTM yields latencies that are on average 17% shorter than in-pause-FSTTM, and 40% shorter than the baseline.", "labels": [], "entities": []}, {"text": "Additionally, we found that, in anytime-FSTTM, 30 to 40% of the turns are endpointed before the pause is detected by the VAD.", "labels": [], "entities": [{"text": "VAD", "start_pos": 121, "end_pos": 124, "type": "METRIC", "confidence": 0.8787319660186768}]}, {"text": "To confirm the results of the batch evaluation, we implemented our FSTTM model in the deployed system a let it run for ten days using either FSTTM or a fixed threshold for endpointing, resulting in a corpus of 171 FSTTM and 148 control dialogs.", "labels": [], "entities": [{"text": "FSTTM", "start_pos": 141, "end_pos": 146, "type": "METRIC", "confidence": 0.8066135048866272}, {"text": "FSTTM", "start_pos": 214, "end_pos": 219, "type": "DATASET", "confidence": 0.7630846500396729}]}, {"text": "For FSTTM, we set C p G = 1, C s G = 500, and C U = 5000.", "labels": [], "entities": [{"text": "FSTTM", "start_pos": 4, "end_pos": 9, "type": "DATASET", "confidence": 0.551038384437561}]}, {"text": "In the batch evaluation, these values correspond to a cut-in rate of 6.3% and an average latency of 320 ms.", "labels": [], "entities": [{"text": "latency", "start_pos": 89, "end_pos": 96, "type": "METRIC", "confidence": 0.9839552044868469}]}, {"text": "For the control condition, we set the fixed endpointing threshold to 555 ms, which also corresponded to about 6.3% cut-ins.", "labels": [], "entities": []}, {"text": "shows the average latency and cut-in rate for both conditions.", "labels": [], "entities": [{"text": "latency", "start_pos": 18, "end_pos": 25, "type": "METRIC", "confidence": 0.9955750703811646}, {"text": "cut-in rate", "start_pos": 30, "end_pos": 41, "type": "METRIC", "confidence": 0.9151550233364105}]}, {"text": "The FSTTM improves over the baseline on all metrics, reducing average latency by 193 ms (p < 0.05), cut-in rate by 1.5% (although this result is not statistically significant).", "labels": [], "entities": [{"text": "FSTTM", "start_pos": 4, "end_pos": 9, "type": "METRIC", "confidence": 0.5353522896766663}, {"text": "latency", "start_pos": 70, "end_pos": 77, "type": "METRIC", "confidence": 0.5091424584388733}, {"text": "cut-in rate", "start_pos": 100, "end_pos": 111, "type": "METRIC", "confidence": 0.886351078748703}]}], "tableCaptions": []}