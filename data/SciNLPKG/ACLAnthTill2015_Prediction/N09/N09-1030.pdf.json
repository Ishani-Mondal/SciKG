{"title": [{"text": "May All Your Wishes Come True: A Study of Wishes and How to Recognize Them", "labels": [], "entities": []}], "abstractContent": [{"text": "A wish is \"a desire or hope for something to happen.\"", "labels": [], "entities": []}, {"text": "In December 2007, people from around the world offered up their wishes to be printed on confetti and dropped from the sky during the famous New Year's Eve \"ball drop\" in New York City's Times Square.", "labels": [], "entities": [{"text": "New Year's Eve \"ball drop\" in New York City's Times Square", "start_pos": 140, "end_pos": 198, "type": "TASK", "confidence": 0.609159376223882}]}, {"text": "We present an in-depth analysis of this collection of wishes.", "labels": [], "entities": []}, {"text": "We then leverage this unique resource to conduct the first study on building general \"wish detectors\" for natural language text.", "labels": [], "entities": []}, {"text": "Wish detection complements traditional sentiment analysis and is valuable for collecting business intelligence and insights into the world's wants and desires.", "labels": [], "entities": [{"text": "Wish detection", "start_pos": 0, "end_pos": 14, "type": "TASK", "confidence": 0.8365800976753235}, {"text": "sentiment analysis", "start_pos": 39, "end_pos": 57, "type": "TASK", "confidence": 0.912411093711853}]}, {"text": "We demonstrate the wish detectors' effectiveness on domains as diverse as consumer product reviews and online political discussions.", "labels": [], "entities": []}], "introductionContent": [{"text": "Each year, New York City rings in the New Year with the famous \"ball drop\" in Times Square.", "labels": [], "entities": []}, {"text": "In December 2007, the Times Square Alliance, coproducer of the Times Square New Year's Eve Celebration, launched a Web site called the Virtual Wishing Wall 1 that allowed people around the world to submit their New Year's wishes.", "labels": [], "entities": [{"text": "Times Square Alliance", "start_pos": 22, "end_pos": 43, "type": "DATASET", "confidence": 0.9543967247009277}, {"text": "Times Square New Year's Eve Celebration", "start_pos": 63, "end_pos": 102, "type": "DATASET", "confidence": 0.9363512907709394}]}, {"text": "These wishes were then printed on confetti and dropped from the sky at midnight on December in sync with the ball drop.", "labels": [], "entities": [{"text": "December", "start_pos": 83, "end_pos": 91, "type": "DATASET", "confidence": 0.9759994745254517}]}, {"text": "We obtained access to this set of nearly 100,000 New Year's wishes, which we call the \"WISH corpus.\" shows a selected sample of the WISH 1 http://www.timessquarenyc.org/nye/nye interactive.html corpus.", "labels": [], "entities": [{"text": "WISH corpus.", "start_pos": 87, "end_pos": 99, "type": "DATASET", "confidence": 0.9526817202568054}, {"text": "WISH 1", "start_pos": 132, "end_pos": 138, "type": "DATASET", "confidence": 0.8956565260887146}]}, {"text": "Some are far-reaching fantasies and aspirations, while others deal with everyday concerns like economic and medical distress.", "labels": [], "entities": []}, {"text": "We analyze this first-of-its-kind corpus in Section 2.", "labels": [], "entities": []}, {"text": "The New Oxford American Dictionary defines \"wish\" as \"a desire or hope for something to happen.\"", "labels": [], "entities": []}, {"text": "How wishes are expressed, and how such wishful expressions can be automatically recognized, are open questions in natural language processing.", "labels": [], "entities": []}, {"text": "Leveraging the WISH corpus, we conduct the first study on building general \"wish detectors\" for natural language text, and demonstrate their effectiveness on domains as diverse as consumer product reviews and online political discussions.", "labels": [], "entities": [{"text": "WISH corpus", "start_pos": 15, "end_pos": 26, "type": "DATASET", "confidence": 0.9174549579620361}]}, {"text": "Such wish detectors have tremendous value in collecting business intelligence and public opinions.", "labels": [], "entities": []}, {"text": "We discuss the wish detectors in Section 3, and experimental results in Section 4.", "labels": [], "entities": []}], "datasetContent": [{"text": "We experimented with two domains, manually labeled at the sentence-level as wishes or non-wishes.", "labels": [], "entities": []}, {"text": "Example wishes are listed in.", "labels": [], "entities": []}, {"text": "Consumer product reviews: 1,235 sentences selected from a collection of amazon.com and cnet.com reviews ().", "labels": [], "entities": []}, {"text": "12% of the sentences are labeled as wishes.", "labels": [], "entities": []}, {"text": "Political discussion board postings: 6,379 sentences selected from politics.com).", "labels": [], "entities": []}, {"text": "34% are labeled as wishes.", "labels": [], "entities": []}, {"text": "We automatically split the corpora into sentences using MxTerminator).", "labels": [], "entities": [{"text": "MxTerminator", "start_pos": 56, "end_pos": 68, "type": "DATASET", "confidence": 0.7195733785629272}]}, {"text": "As preprocessing before learning, we tokenized the text in the Penn TreeBank style, down- cased, and removed all punctuation.", "labels": [], "entities": [{"text": "Penn TreeBank style", "start_pos": 63, "end_pos": 82, "type": "DATASET", "confidence": 0.9765686591466268}]}, {"text": "For all four wish detectors, we performed 10-fold cross validation.", "labels": [], "entities": []}, {"text": "We used the default parameter in SVM light for all trials.", "labels": [], "entities": []}, {"text": "As the data sets are skewed, we compare the detectors using precision-recall curves and the area under the curve (AUC).", "labels": [], "entities": [{"text": "precision-recall", "start_pos": 60, "end_pos": 76, "type": "METRIC", "confidence": 0.9945259690284729}, {"text": "AUC)", "start_pos": 114, "end_pos": 118, "type": "METRIC", "confidence": 0.951806902885437}]}, {"text": "For the manual baseline, we produce the curve by varying the number of templates applied (in rank order), which gradually predicts more sentences as wishes (increasing recall at the expense of precision).", "labels": [], "entities": [{"text": "recall", "start_pos": 168, "end_pos": 174, "type": "METRIC", "confidence": 0.9977464079856873}, {"text": "precision", "start_pos": 193, "end_pos": 202, "type": "METRIC", "confidence": 0.9988566637039185}]}, {"text": "A final point is added at recall 1.0, corresponding to applying an empty template that matches all sentences.", "labels": [], "entities": []}, {"text": "For the SVM-based methods, we vary the threshold applied to the real-valued margin prediction to produce the curves.", "labels": [], "entities": []}, {"text": "All curves are interpolated, and AUC measures are computed, using the techniques of ().", "labels": [], "entities": [{"text": "AUC", "start_pos": 33, "end_pos": 36, "type": "METRIC", "confidence": 0.9458609223365784}]}, {"text": "shows the precision-recall curves for the Politics corpus.", "labels": [], "entities": [{"text": "precision-recall", "start_pos": 10, "end_pos": 26, "type": "METRIC", "confidence": 0.9989983439445496}, {"text": "Politics corpus", "start_pos": 42, "end_pos": 57, "type": "DATASET", "confidence": 0.8665609359741211}]}, {"text": "All curves are averages over 10 folds (i.e., for each of 100 evenly spaced, interpolated recall points, the 10 precision values are averaged).", "labels": [], "entities": [{"text": "recall", "start_pos": 89, "end_pos": 95, "type": "METRIC", "confidence": 0.9292482137680054}, {"text": "precision", "start_pos": 111, "end_pos": 120, "type": "METRIC", "confidence": 0.9914472103118896}]}, {"text": "As expected, can be very precise with low recall-only the very top few templates achieve high precision and pick out a small number of wishes with \"i wish\" and \"i hope.\"", "labels": [], "entities": [{"text": "recall-only", "start_pos": 42, "end_pos": 53, "type": "METRIC", "confidence": 0.9990190267562866}, {"text": "precision", "start_pos": 94, "end_pos": 103, "type": "METRIC", "confidence": 0.9939554333686829}]}, {"text": "As we introduce more templates to cover more true wishes, precision drops off quickly. is similar, Corpus [Words] [Words + Templates] Politics 0.67 \u00b1 0.03 0.77 \u00b1 0.03 0.73 \u00b1 0.03 0.80 \u00b1 0.03", "labels": [], "entities": [{"text": "precision", "start_pos": 58, "end_pos": 67, "type": "METRIC", "confidence": 0.9995735287666321}]}], "tableCaptions": [{"text": " Table 1: Example wishes and their frequencies in the  WISH corpus.", "labels": [], "entities": [{"text": "WISH corpus", "start_pos": 55, "end_pos": 66, "type": "DATASET", "confidence": 0.932820200920105}]}, {"text": " Table 2: Wish topics learned from Latent Dirichlet Allocation. Words are sorted by p(word|topic).", "labels": [], "entities": []}, {"text": " Table 3. The underscore  matches any string. These templates can be turned  into a simple rule-based classifier: If part of a sen- tence matches one of the templates, the sentence is", "labels": [], "entities": []}]}