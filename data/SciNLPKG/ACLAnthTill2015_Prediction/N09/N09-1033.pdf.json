{"title": [], "abstractContent": [{"text": "State of the art set expansion algorithms produce varying quality expansions for different entity types.", "labels": [], "entities": []}, {"text": "Even for the highest quality expansions , errors still occur and manual refinements are necessary for most practical uses.", "labels": [], "entities": []}, {"text": "In this paper, we propose algorithms to aide this refinement process, greatly reducing the amount of manual labor required.", "labels": [], "entities": []}, {"text": "The methods rely on the fact that most expansion errors are systematic, often stemming from the fact that some seed elements are ambiguous.", "labels": [], "entities": []}, {"text": "Using our methods, empirical evidence shows that average R-precision over random entity sets improves by 26% to 51% when given from 5 to 10 manually tagged errors.", "labels": [], "entities": [{"text": "R-precision", "start_pos": 57, "end_pos": 68, "type": "METRIC", "confidence": 0.9229592084884644}]}, {"text": "Both proposed refinement models have linear time complexity in set size allowing for practical online use in set expansion systems.", "labels": [], "entities": []}], "introductionContent": [{"text": "Sets of named entities are extremely useful in a variety of natural language and information retrieval tasks.", "labels": [], "entities": [{"text": "information retrieval", "start_pos": 81, "end_pos": 102, "type": "TASK", "confidence": 0.7280024290084839}]}, {"text": "For example, companies such as Yahoo! and Google maintain sets of named entities such as cities, products and celebrities to improve search engine relevance.", "labels": [], "entities": []}, {"text": "Manually creating and maintaining large sets of named entities is expensive and laborious.", "labels": [], "entities": []}, {"text": "In response, many automatic and semi-automatic methods of creating sets of named entities have been proposed, some are supervised (), unsupervised (Pantel and Lin 2002,), and others semi-supervised ().", "labels": [], "entities": []}, {"text": "Semi-supervised approaches are often used in practice since they allow for targeting specific entity classes such as European Cities and French Impressionist Painters.", "labels": [], "entities": []}, {"text": "Methods differ in complexity from simple ones using lexicosyntactic patterns) to more complicated techniques based on distributional similarity.", "labels": [], "entities": []}, {"text": "Even for state of the art methods, expansion errors inevitably occur and manual refinements are necessary for most practical uses requiring high precision (such as for query interpretation at commercial search engines).", "labels": [], "entities": [{"text": "precision", "start_pos": 145, "end_pos": 154, "type": "METRIC", "confidence": 0.9882537126541138}, {"text": "query interpretation at commercial search engines", "start_pos": 168, "end_pos": 217, "type": "TASK", "confidence": 0.7946218550205231}]}, {"text": "Looking at expansions from state of the art systems such as GoogleSets 1 , we found systematic errors such as those resulting from ambiguous seed instances.", "labels": [], "entities": []}, {"text": "For example, consider the following seed instances for the target set Roman Gods:", "labels": [], "entities": []}], "datasetContent": [{"text": "We evaluate our algorithms against manually scraped gold standard sets, which were extracted from Wikipedia to represent a random collection of concepts.", "labels": [], "entities": []}, {"text": "Section 4.1 discusses the gold standard sets and the criteria behind their selection.", "labels": [], "entities": [{"text": "gold standard sets", "start_pos": 26, "end_pos": 44, "type": "DATASET", "confidence": 0.8829849163691202}]}, {"text": "To present a statistically significant view of our results we generated a set of trials from gold standard sets to use as seeds for our seed set expansion algorithm.", "labels": [], "entities": []}, {"text": "Also, in section 4.2 we discuss how we can simulate editorial feedback using our gold standard sets.", "labels": [], "entities": []}, {"text": "To provide a statistically significant view of the performance of our algorithm, we created more than 1000 trials as follows.", "labels": [], "entities": []}, {"text": "For each of the gold standard seed sets, we created 30 random sortings.", "labels": [], "entities": []}, {"text": "These 30 random sortings were then used to generate trial seed sets with a maximum size of 20 seeds.", "labels": [], "entities": []}, {"text": "Wikipedia 5 served as the source corpus for our algorithms described in Sections 3.1 and 3.2.", "labels": [], "entities": [{"text": "Wikipedia 5", "start_pos": 0, "end_pos": 11, "type": "DATASET", "confidence": 0.9548603594303131}]}, {"text": "All articles were POS-tagged using and later chunked using a variant of (Abney 1991).", "labels": [], "entities": []}, {"text": "Corpus statistics from this processed text were collected to build the similarity matrix for the SIM method (Section 3.1) and to extract the features required for the FMM method (Section 3.2).", "labels": [], "entities": []}, {"text": "In both cases corpus statistics were extracted over the semi-syntactic contexts (chunks) to approximate term meanings.", "labels": [], "entities": []}, {"text": "The minimum similarity thresholds were experimentally set to 0.15 and 0.11 for the SIM and FMM algorithms respectively.", "labels": [], "entities": [{"text": "similarity", "start_pos": 12, "end_pos": 22, "type": "METRIC", "confidence": 0.8325244784355164}]}, {"text": "Each experimental trial described in Section 4.2, which consists of a set of seed instances of one of our 50 random semantic classes, was expanded using a variant of the distributional set expansion algorithm from.", "labels": [], "entities": []}, {"text": "The expansions were judged against the gold standard and each candidate expansion was marked as either corrector incorrect.", "labels": [], "entities": []}, {"text": "This set of expanded and judged candidate files were used as inputs to the algorithms described in Sections 3.1 and 3.2.", "labels": [], "entities": []}, {"text": "Choosing the first candidate expansion that was judged as incorrect simulated our user feedback.", "labels": [], "entities": []}, {"text": "This process was repeated for each iteration of the algorithm and results are reported for 10 iterations.", "labels": [], "entities": []}, {"text": "The outputs of our algorithms were again judged against the gold standard lists and the performance was measured in terms of precision gains over the baseline at various ranks.", "labels": [], "entities": [{"text": "precision", "start_pos": 125, "end_pos": 134, "type": "METRIC", "confidence": 0.9976862668991089}]}, {"text": "Precision gain for an algorithm over a baseline is the percentage increase in precision for the same values of parameters of the algorithm over the baseline.", "labels": [], "entities": [{"text": "Precision gain", "start_pos": 0, "end_pos": 14, "type": "METRIC", "confidence": 0.9878810942173004}, {"text": "precision", "start_pos": 78, "end_pos": 87, "type": "METRIC", "confidence": 0.9986777901649475}]}, {"text": "Also, as the size of our gold standard lists vary, we report another commonly used statistic, R-precision.", "labels": [], "entities": [{"text": "R-precision", "start_pos": 94, "end_pos": 105, "type": "METRIC", "confidence": 0.9024307131767273}]}, {"text": "Rprecision for any set is the precision at the size of the gold standard set.", "labels": [], "entities": [{"text": "Rprecision", "start_pos": 0, "end_pos": 10, "type": "METRIC", "confidence": 0.9841626882553101}, {"text": "precision", "start_pos": 30, "end_pos": 39, "type": "METRIC", "confidence": 0.9993522763252258}, {"text": "gold standard set", "start_pos": 59, "end_pos": 76, "type": "DATASET", "confidence": 0.8240790963172913}]}, {"text": "For example, if a gold standard set contains 20 elements, then R-precision for any set expansion is measured as the precision at rank 20.", "labels": [], "entities": [{"text": "precision", "start_pos": 116, "end_pos": 125, "type": "METRIC", "confidence": 0.9976303577423096}]}, {"text": "The average R-precision over each set is then reported.", "labels": [], "entities": [{"text": "R-precision", "start_pos": 12, "end_pos": 23, "type": "METRIC", "confidence": 0.9425140619277954}]}, {"text": "lists the performance of our baseline algorithm (Section 4.3) and our proposed methods SIM and FMM (Sections 3.1 and 3.2) in terms of their R-precision with 95% confidence bounds over 10 iterations of each algorithm.", "labels": [], "entities": [{"text": "FMM", "start_pos": 95, "end_pos": 98, "type": "DATASET", "confidence": 0.7513274550437927}]}], "tableCaptions": [{"text": " Table 1. R-precision of the three methods with 95% confi- dence bounds.", "labels": [], "entities": [{"text": "R-precision", "start_pos": 10, "end_pos": 21, "type": "METRIC", "confidence": 0.9866806864738464}]}]}