{"title": [{"text": "Evaluating the Syntactic Transformations in Gold Standard Corpora for Statistical Sentence Compression", "labels": [], "entities": [{"text": "Syntactic Transformations", "start_pos": 15, "end_pos": 40, "type": "TASK", "confidence": 0.806089848279953}, {"text": "Gold Standard Corpora", "start_pos": 44, "end_pos": 65, "type": "DATASET", "confidence": 0.9103900988896688}, {"text": "Statistical Sentence Compression", "start_pos": 70, "end_pos": 102, "type": "TASK", "confidence": 0.764720618724823}]}], "abstractContent": [{"text": "We present a policy-based error analysis approach that demonstrates a limitation to the current commonly adopted paradigm for sentence compression.", "labels": [], "entities": [{"text": "sentence compression", "start_pos": 126, "end_pos": 146, "type": "TASK", "confidence": 0.7816824316978455}]}, {"text": "We demonstrate that these limitations arise from the strong assumption of locality of the decision making process in the search for an acceptable derivation in this paradigm.", "labels": [], "entities": []}], "introductionContent": [{"text": "In this paper we present a policy-based error analysis approach that demonstrates a limitation to the current commonly adopted paradigm for sentence compression).", "labels": [], "entities": [{"text": "policy-based error analysis", "start_pos": 27, "end_pos": 54, "type": "TASK", "confidence": 0.6357874075571696}, {"text": "sentence compression", "start_pos": 140, "end_pos": 160, "type": "TASK", "confidence": 0.7637613713741302}]}, {"text": "Specifically, in typical statistical compression approaches, a simplifying assumption is made that compression is accomplished strictly by means of word deletion.", "labels": [], "entities": [{"text": "statistical compression", "start_pos": 25, "end_pos": 48, "type": "TASK", "confidence": 0.7699759900569916}]}, {"text": "Furthermore, each sequence of contiguous words that are dropped from a source sentence is considered independently of other sequences of words dropped from other portions of the sentence, so that the features that predict whether deleting a sequence of words is preferred or not is based solely on local considerations.", "labels": [], "entities": []}, {"text": "This simplistic approach allows all possible derivations to be modeled and decoded efficiently within the search space, using a dynamic programming algorithm.", "labels": [], "entities": []}, {"text": "In theory, it should be possible to learn how to generate effective compressions using a corpus of source-target sentence pairs, given enough examples and sufficiently expressive features.", "labels": [], "entities": []}, {"text": "However, our analysis casts doubt that this framework with its strong assumptions of locality is sufficiently powerful to learn the types of example compressions frequently found in corpora of human generated gold standard compressions regardless of how expressive the features are.", "labels": [], "entities": []}, {"text": "Work in sentence compression has been somewhat hampered by the tremendous cost involved in producing a gold standard corpus.", "labels": [], "entities": [{"text": "sentence compression", "start_pos": 8, "end_pos": 28, "type": "TASK", "confidence": 0.8338971138000488}]}, {"text": "Because of this tremendous cost, the same gold standard corpora are used in many different published studies almost as a black box.", "labels": [], "entities": []}, {"text": "This is done with little scrutiny of the limitations on the learnability of the desired target systems.", "labels": [], "entities": []}, {"text": "These limitations result from inconsistencies due to the subtleties in the process by which humans generate the gold standard compressions from the source sentences, and from the strong locality assumptions inherent in the frameworks.", "labels": [], "entities": []}, {"text": "Typically, the humans who have participated in the construction of these corpora have been instructed to preserve grammaticality and to produce compressions by deletion.", "labels": [], "entities": []}, {"text": "Human ratings of the gold standard compressions by separate judges confirm that the human developers have literally followed the instructions, and have produced compressions that are themselves largely grammatical.", "labels": [], "entities": []}, {"text": "Nevertheless, what we demonstrate with our error analysis is that they have used meaning preserving transformation that didn't consistently preserve the grammatical relations from the source sentence while transforming source sentences into target sentences.", "labels": [], "entities": []}, {"text": "This places limitations on how well the preferred patterns of compression can be learned using the current paradigm and existing corpora.", "labels": [], "entities": []}, {"text": "In the remainder of the paper, we discuss relevant work in sentence compression.", "labels": [], "entities": [{"text": "sentence compression", "start_pos": 59, "end_pos": 79, "type": "TASK", "confidence": 0.8253986537456512}]}, {"text": "We then introduce our policy-based error analysis technique.", "labels": [], "entities": [{"text": "policy-based error analysis", "start_pos": 22, "end_pos": 49, "type": "TASK", "confidence": 0.592828502257665}]}, {"text": "Next we discuss the error analysis itself and the conclusions we draw from it.", "labels": [], "entities": []}, {"text": "Finally, we conclude with future directions for broader application of this error analysis technique.", "labels": [], "entities": [{"text": "error analysis", "start_pos": 76, "end_pos": 90, "type": "TASK", "confidence": 0.671563133597374}]}], "datasetContent": [{"text": "In this section we discuss the results from evaluating the 8 grammar policies discussed in Section 3 over the ZD and CL corpora, as discussed above.", "labels": [], "entities": []}, {"text": "The policies were evaluated with respect to whether they applied in a sentence, i.e., whether the premise of the \"if \u2026 then\" rule is true in the sentence, and whether the policy was broken when applied, i.e., if the premise is true but the consequent is false.", "labels": [], "entities": []}, {"text": "The striking finding is that for everyone of the policies discussed in the previous section, they are violated for at least 10% of the sentences where they applied, and sometimes as much as 72%.", "labels": [], "entities": []}, {"text": "For most policies, the proportion of sentences where the policy is violated when applied is a minority of cases.", "labels": [], "entities": []}, {"text": "Thus, based on this, we can expect that grammar oriented features motivated by these policies and derived from a syntactic analysis of the source and/or target sentences in the gold standard could be used to improve the performance of compression systems that don't make use of syntactic information to that extent.", "labels": [], "entities": []}, {"text": "However, the noticeable proportion of violations with respect to some of the policies indicate that there is a limited extent to which these types of features can contribute towards improved performance.", "labels": [], "entities": []}, {"text": "One observation we make from is that while the proportion of sentences where the policies (Columns 2 and 4) apply as well as the proportion of sentences where the policies are broken when applied (Columns 3 and 5) are highly correlated between the two corpora.", "labels": [], "entities": []}, {"text": "Nevertheless, the distributions are not identical.", "labels": [], "entities": []}, {"text": "Thus, again, while we predict that using this style of dependency syntax features might improve performance of compression systems within a single corpus, we would not expect trained models that rely on these syntactic dependency features to generalize in an ideal way between corpora.", "labels": [], "entities": []}, {"text": "Beyond the above evaluation illustrating the extent to which grammar inspired policies are violated inhuman generated gold standard corpora, interesting insights into challenges that must be addressed in order to improve performance can be obtained by taking a close look at typical examples from the CL corpus where the policies are broken in the gold standard corpora (bold represents dropped words).", "labels": [], "entities": [{"text": "CL corpus", "start_pos": 301, "end_pos": 310, "type": "DATASET", "confidence": 0.8487841486930847}]}, {"text": "1. The attempt to put flesh and blood on the skeleton structure of a possible united Europe emerged.", "labels": [], "entities": []}, {"text": "2. Annely has used the gallery 's three floors to divide the exhibits into three distinct groups.", "labels": [], "entities": []}, {"text": "3. Labor has said it will scrap the system.", "labels": [], "entities": []}, {"text": "4. Montenegro 's sudden rehabilitation of Nicholas 's memory is a popular move.", "labels": [], "entities": [{"text": "rehabilitation of Nicholas 's memory", "start_pos": 24, "end_pos": 60, "type": "TASK", "confidence": 0.5752395838499069}]}, {"text": "In Sentence 1, retaining the dependent Noun structure of the dropped Preposition on in the PP violates Policy 7.", "labels": [], "entities": [{"text": "Sentence 1", "start_pos": 3, "end_pos": 13, "type": "TASK", "confidence": 0.9175296127796173}]}, {"text": "Such a NP to Infinitive Phrase transformation changes the syntactic structure of the sentence.", "labels": [], "entities": []}, {"text": "Sentence 2 also breaks several policies, namely Policies 1, 4 and 7.", "labels": [], "entities": [{"text": "Sentence 2", "start_pos": 0, "end_pos": 10, "type": "TASK", "confidence": 0.9086774587631226}]}, {"text": "The syntactic root has is dropped.", "labels": [], "entities": []}, {"text": "Also the main verb has used is dropped while retaining the Subject Annely.", "labels": [], "entities": []}, {"text": "In Sentence 3, breaking Policies 1, 2 and 4, the human annotators replaced the pronoun it with the noun Labor, the subject of a dropped verb 'has said'.", "labels": [], "entities": [{"text": "Sentence 3", "start_pos": 3, "end_pos": 13, "type": "TASK", "confidence": 0.9315658509731293}]}, {"text": "Such anaphora resolution cannot be done without relevant context, which is not available in strictly local paradigms of sentence compression.", "labels": [], "entities": [{"text": "anaphora resolution", "start_pos": 5, "end_pos": 24, "type": "TASK", "confidence": 0.7286565154790878}, {"text": "sentence compression", "start_pos": 120, "end_pos": 140, "type": "TASK", "confidence": 0.7176832556724548}]}, {"text": "In Sentence 4, policies 3. 5 and 8 are violated.", "labels": [], "entities": [{"text": "Sentence 4", "start_pos": 3, "end_pos": 13, "type": "TASK", "confidence": 0.9057942032814026}]}, {"text": "Transformations like substituting Nicholas's memory by the metonym Nicholas and popular move by popular need to be identified and analyzed.", "labels": [], "entities": [{"text": "substituting Nicholas's memory", "start_pos": 21, "end_pos": 51, "type": "TASK", "confidence": 0.7548628896474838}]}, {"text": "Such varied transformations, made in the syntactic structure of the sentences by human annotators, are counter-intuitive, making them hard to be captured in the linear models learned in association with the syntactic features in current compression systems.", "labels": [], "entities": []}], "tableCaptions": []}