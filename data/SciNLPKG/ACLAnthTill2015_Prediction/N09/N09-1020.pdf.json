{"title": [{"text": "Hierarchical Dirichlet Trees for Information Retrieval", "labels": [], "entities": [{"text": "Information Retrieval", "start_pos": 33, "end_pos": 54, "type": "TASK", "confidence": 0.7430754005908966}]}], "abstractContent": [{"text": "We propose a principled probabilisitc framework which uses trees over the vocabulary to capture similarities among terms in an information retrieval setting.", "labels": [], "entities": []}, {"text": "This allows the retrieval of documents based not just on occurrences of specific query terms, but also on similarities between terms (an effect similar to query expansion).", "labels": [], "entities": [{"text": "query expansion", "start_pos": 155, "end_pos": 170, "type": "TASK", "confidence": 0.7162096053361893}]}, {"text": "Additionally our principled generative model exhibits an effect similar to inverse document frequency.", "labels": [], "entities": []}, {"text": "We give encouraging experimental evidence of the superiority of the hierarchical Dirichlet tree compared to standard baselines.", "labels": [], "entities": []}], "introductionContent": [{"text": "Information retrieval (IR) is the task of retrieving, given a query, the documents relevant to the user from a large quantity of documents.", "labels": [], "entities": [{"text": "Information retrieval (IR) is the task of retrieving, given a query, the documents relevant to the user from a large quantity of documents", "start_pos": 0, "end_pos": 138, "type": "Description", "confidence": 0.7998825388926046}]}, {"text": "IR has become very important in recent years, with the proliferation of large quantities of documents on the worldwide web.", "labels": [], "entities": [{"text": "IR", "start_pos": 0, "end_pos": 2, "type": "TASK", "confidence": 0.9764562845230103}]}, {"text": "Many IR systems are based on some relevance score function R(j, q) which returns the relevance of document j to query q.", "labels": [], "entities": [{"text": "IR", "start_pos": 5, "end_pos": 7, "type": "TASK", "confidence": 0.9802548289299011}, {"text": "relevance score function R", "start_pos": 34, "end_pos": 60, "type": "METRIC", "confidence": 0.7715228796005249}]}, {"text": "Examples of such relevance score functions include term frequency-inverse document frequency (tf-idf) and Okapi BM25 (.", "labels": [], "entities": [{"text": "term frequency-inverse document frequency (tf-idf)", "start_pos": 51, "end_pos": 101, "type": "METRIC", "confidence": 0.8714324321065631}, {"text": "Okapi BM25", "start_pos": 106, "end_pos": 116, "type": "DATASET", "confidence": 0.5643163025379181}]}, {"text": "Besides the effect that documents containing more query terms should be more relevant (term frequency), the main effect that many relevance scores try to capture is that of inverse document frequency: the importance of a term is inversely related to the number of documents that it appears in, i.e. the popularity of the term.", "labels": [], "entities": []}, {"text": "This is because popular terms, e.g. common and stop words, are often uninformative, while rare terms are often very informative.", "labels": [], "entities": []}, {"text": "Another important effect is that related or co-occurring terms are often useful in determining the relevance of documents.", "labels": [], "entities": []}, {"text": "Because most relevance scores do not capture this effect, IR systems resort to techniques like query expansion which includes synonyms and other morphological forms of the original query terms in order to improve retrieval results; e.g. (. In this paper we explore a probabilistic model for IR that simultaneously handles both effects in a principled manner.", "labels": [], "entities": [{"text": "IR", "start_pos": 58, "end_pos": 60, "type": "TASK", "confidence": 0.970332145690918}, {"text": "query expansion", "start_pos": 95, "end_pos": 110, "type": "TASK", "confidence": 0.7188143730163574}, {"text": "IR", "start_pos": 291, "end_pos": 293, "type": "TASK", "confidence": 0.9757813811302185}]}, {"text": "It builds upon the work of) who proposed a hierarchical Dirichlet document model.", "labels": [], "entities": []}, {"text": "In this model, each document is modeled using a multinomial distribution (making the bag-of-words assumption) whose parameters are given Dirichlet priors.", "labels": [], "entities": []}, {"text": "The common mean of the Dirichlet priors is itself assumed random and given a Dirichlet hyperprior.", "labels": [], "entities": []}, {"text": "showed that the shared mean parameter induces sharing of information across documents in the corpus, and leads to an inverse document frequency effect.", "labels": [], "entities": []}, {"text": "We generalize the model of) by replacing the Dirichlet distributions with Dirichlet tree distributions, thus we call our model the hierarchical Dirichlet tree.", "labels": [], "entities": []}, {"text": "Related terms are placed close by in the vocabulary tree, allowing the model to take this knowledge into account when determining document relevance.", "labels": [], "entities": []}, {"text": "This makes it unnecessary to use ad-hoc query expansion methods, as related words such as synonyms will betaken into account by the retrieval rule.", "labels": [], "entities": []}, {"text": "The structure of the tree is learned from data in an unsupervised fashion, us-ing a variety of agglomerative clustering techniques.", "labels": [], "entities": []}, {"text": "We review the hierarchical Dirichlet document (HDD) model in section 2, and present our proposed hierarchical Dirichlet tree (HDT) document model in section 3.", "labels": [], "entities": []}, {"text": "We describe three algorithms for constructing the vocabulary tree in section 4, and give encouraging experimental evidence of the superiority of the hierarchical Dirichlet tree compared to standard baselines in section 5.", "labels": [], "entities": []}, {"text": "We conclude the paper in section 6.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section we present experimental results on two IR datasets: Cranfield and Medline 4 . The Cranfield dataset consists of 1,400 documents and 225 queries; its vocabulary size after stemming and removing stop words is 4,227.", "labels": [], "entities": [{"text": "Cranfield", "start_pos": 68, "end_pos": 77, "type": "DATASET", "confidence": 0.8833947777748108}, {"text": "Medline", "start_pos": 82, "end_pos": 89, "type": "DATASET", "confidence": 0.7647848725318909}, {"text": "Cranfield dataset", "start_pos": 98, "end_pos": 115, "type": "DATASET", "confidence": 0.806812971830368}]}, {"text": "The Medline dataset contains 1,033 documents and 30 queries with the vocabulary size of 8,800 after stemming and removing stop words.", "labels": [], "entities": [{"text": "Medline dataset", "start_pos": 4, "end_pos": 19, "type": "DATASET", "confidence": 0.9657959640026093}]}, {"text": "We compare HDT with the flat HDD model and Okapi BM25 (.", "labels": [], "entities": [{"text": "Okapi BM25", "start_pos": 43, "end_pos": 53, "type": "DATASET", "confidence": 0.9316402971744537}]}, {"text": "Since one of our motivations has been to: Average precision and Top-10 precision scores of HDT with different trees versus flat model and BM25.", "labels": [], "entities": [{"text": "Average", "start_pos": 42, "end_pos": 49, "type": "METRIC", "confidence": 0.935027003288269}, {"text": "precision", "start_pos": 50, "end_pos": 59, "type": "METRIC", "confidence": 0.8959179520606995}, {"text": "precision", "start_pos": 71, "end_pos": 80, "type": "METRIC", "confidence": 0.9135040640830994}, {"text": "BM25", "start_pos": 138, "end_pos": 142, "type": "METRIC", "confidence": 0.8377174735069275}]}, {"text": "The statistics for each tree shows its average/maximum depth of its leaf nodes as well as the number of its total internal nodes.", "labels": [], "entities": []}, {"text": "The bold numbers highlight the best results in the corresponding columns.", "labels": [], "entities": []}, {"text": "getaway from query expansion, we also compare against Okapi BM25 with query expansion.", "labels": [], "entities": []}, {"text": "The new terms to expand each query are chosen based on Robertson-Sparck Jones weights) from the pseudo relevant documents.", "labels": [], "entities": []}, {"text": "The comparison criteria are (i) top-10 precision, and (ii) average precision.", "labels": [], "entities": [{"text": "precision", "start_pos": 39, "end_pos": 48, "type": "METRIC", "confidence": 0.9895394444465637}, {"text": "average", "start_pos": 59, "end_pos": 66, "type": "METRIC", "confidence": 0.9579806327819824}, {"text": "precision", "start_pos": 67, "end_pos": 76, "type": "METRIC", "confidence": 0.8081948757171631}]}], "tableCaptions": [{"text": " Table 1: Average precision and Top-10 precision scores of HDT with different trees versus flat model and BM25. The  statistics for each tree shows its average/maximum depth of its leaf nodes as well as the number of its total internal  nodes. The bold numbers highlight the best results in the corresponding columns.", "labels": [], "entities": [{"text": "precision", "start_pos": 18, "end_pos": 27, "type": "METRIC", "confidence": 0.9553800821304321}, {"text": "precision", "start_pos": 39, "end_pos": 48, "type": "METRIC", "confidence": 0.9097878336906433}, {"text": "BM25", "start_pos": 106, "end_pos": 110, "type": "METRIC", "confidence": 0.5104996562004089}]}]}