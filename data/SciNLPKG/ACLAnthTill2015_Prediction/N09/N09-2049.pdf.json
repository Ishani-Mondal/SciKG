{"title": [{"text": "Analysing Recognition Errors in Unlimited-Vocabulary Speech Recognition", "labels": [], "entities": [{"text": "Analysing Recognition", "start_pos": 0, "end_pos": 21, "type": "TASK", "confidence": 0.8766026794910431}, {"text": "Unlimited-Vocabulary Speech Recognition", "start_pos": 32, "end_pos": 71, "type": "TASK", "confidence": 0.598925938208898}]}], "abstractContent": [{"text": "We analyze the recognition errors made by a morph-based continuous speech recognition system, which practically allows an unlimited vocabulary.", "labels": [], "entities": [{"text": "morph-based continuous speech recognition", "start_pos": 44, "end_pos": 85, "type": "TASK", "confidence": 0.6942790001630783}]}, {"text": "Examining the role of the acoustic and language models in erroneous regions shows how speaker adaptive training (SAT) and discriminative training with minimum phone frame error (MPFE) criterion decrease errors in different error classes.", "labels": [], "entities": [{"text": "minimum phone frame error (MPFE) criterion", "start_pos": 151, "end_pos": 193, "type": "METRIC", "confidence": 0.7574485838413239}]}, {"text": "Analyzing the errors with respect to word frequencies and manually classified error types reveals the most potential areas for improving the system.", "labels": [], "entities": []}], "introductionContent": [{"text": "Large vocabulary speech recognizers have become very complex.", "labels": [], "entities": [{"text": "speech recognizers", "start_pos": 17, "end_pos": 35, "type": "TASK", "confidence": 0.7447469234466553}]}, {"text": "Understanding how the parts of the system affect the results separately or together is far from trivial.", "labels": [], "entities": []}, {"text": "Still, analyzing the recognition errors may suggest how to reduce the errors further.", "labels": [], "entities": []}, {"text": "There exist previous work on analyzing recognition errors.", "labels": [], "entities": [{"text": "analyzing recognition errors", "start_pos": 29, "end_pos": 57, "type": "TASK", "confidence": 0.6783882975578308}]}, {"text": "developed error region analysis (ERA), which reveals whether the errors are due to acoustic or language models.", "labels": [], "entities": [{"text": "error region analysis (ERA)", "start_pos": 10, "end_pos": 37, "type": "TASK", "confidence": 0.6781911551952362}]}, {"text": "analyzed errors made by eight recognition systems on the Switchboard corpus.", "labels": [], "entities": [{"text": "Switchboard corpus", "start_pos": 57, "end_pos": 75, "type": "DATASET", "confidence": 0.9315929412841797}]}, {"text": "The errors correlated with the phone misclassification and speech rate, and conclusion was that the acoustic front ends should be improved further.", "labels": [], "entities": []}, {"text": "analyzed the main errors made by the 2004 BBN speech recognition system.", "labels": [], "entities": [{"text": "BBN speech recognition", "start_pos": 42, "end_pos": 64, "type": "TASK", "confidence": 0.7573217153549194}]}, {"text": "They showed that errors typically occur in clusters and differ between broadcast news (BN) and conversational telephone speech (CTS) domains.", "labels": [], "entities": []}, {"text": "Named entities were a common cause for errors in the BN domain, and hesitation, repeats and partially spoken words in the CTS domain.", "labels": [], "entities": [{"text": "BN domain", "start_pos": 53, "end_pos": 62, "type": "DATASET", "confidence": 0.7854001522064209}, {"text": "repeats", "start_pos": 80, "end_pos": 87, "type": "METRIC", "confidence": 0.9597110748291016}, {"text": "CTS domain", "start_pos": 122, "end_pos": 132, "type": "DATASET", "confidence": 0.8264470994472504}]}, {"text": "This paper analyzes the errors made by a Finnish morph-based continuous recognition system.", "labels": [], "entities": [{"text": "Finnish morph-based continuous recognition", "start_pos": 41, "end_pos": 83, "type": "TASK", "confidence": 0.4677311033010483}]}, {"text": "In addition to partitioning the errors using ERA, we compare the number of letter errors in different regions and analyze what kind of errors are corrected when speaker adaptive training and discriminative training are taken in use.", "labels": [], "entities": [{"text": "ERA", "start_pos": 45, "end_pos": 48, "type": "METRIC", "confidence": 0.9524397253990173}]}, {"text": "The most potential error sources are also studied by partitioning the errors according to manual error classes and word frequencies.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: SpeechDat: Letter errors for different training  methods and error regions. The reference transcript con- tains 40355 letters in total.", "labels": [], "entities": []}, {"text": " Table 2: Manual error classes and the number of letter errors for the ML+SAT+MPFE system.", "labels": [], "entities": [{"text": "ML+SAT+MPFE system", "start_pos": 71, "end_pos": 89, "type": "DATASET", "confidence": 0.7310025890668234}]}]}