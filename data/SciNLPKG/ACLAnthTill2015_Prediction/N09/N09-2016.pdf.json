{"title": [{"text": "Learning Bayesian Networks for Semantic Frame Composition in a Spoken Dialog System", "labels": [], "entities": [{"text": "Semantic Frame Composition", "start_pos": 31, "end_pos": 57, "type": "TASK", "confidence": 0.6419031719366709}]}], "abstractContent": [{"text": "A stochastic approach based on Dynamic Bayesian Networks (DBNs) is introduced for spoken language understanding.", "labels": [], "entities": [{"text": "spoken language understanding", "start_pos": 82, "end_pos": 111, "type": "TASK", "confidence": 0.6522244811058044}]}, {"text": "DBN-based models allow to infer and then to compose semantic frame-based tree structures from speech transcriptions.", "labels": [], "entities": []}, {"text": "Experimental results on the French MEDIA dialog corpus show the appropriateness of the technique which both lead to good tree identification results and can provide the dialog system with n-best lists of scored hypotheses.", "labels": [], "entities": [{"text": "French MEDIA dialog corpus", "start_pos": 28, "end_pos": 54, "type": "DATASET", "confidence": 0.8892709761857986}, {"text": "tree identification", "start_pos": 121, "end_pos": 140, "type": "TASK", "confidence": 0.7038204371929169}]}], "introductionContent": [{"text": "Recent developments in Spoken Dialog Systems (SDSs) have renewed the interest for the extraction of rich and high-level semantics from users' utterances.", "labels": [], "entities": [{"text": "Spoken Dialog Systems (SDSs)", "start_pos": 23, "end_pos": 51, "type": "TASK", "confidence": 0.8472715218861898}]}, {"text": "Shifting every SDS component from hand-crafted to stochastic is foreseen as a good option to improve their overall performance by an increased robustness to speech variabilities.", "labels": [], "entities": []}, {"text": "For instance stochastic methods are now efficient alternatives to rule-based techniques for Spoken Language Understanding (SLU).", "labels": [], "entities": [{"text": "Spoken Language Understanding (SLU)", "start_pos": 92, "end_pos": 127, "type": "TASK", "confidence": 0.7810018757979075}]}, {"text": "The SLU module links up the automatic speech recognition (ASR) module and the dialog manager.", "labels": [], "entities": [{"text": "automatic speech recognition (ASR)", "start_pos": 28, "end_pos": 62, "type": "TASK", "confidence": 0.7891313433647156}]}, {"text": "From the user's utterance analysis, it derives a representation of its semantic content upon which the dialog manager can decide the next best action to perform, taking into account the current dialog context.", "labels": [], "entities": []}, {"text": "In this work, the overall objective is to increase the relevancy of the semantic information used by the system.", "labels": [], "entities": []}, {"text": "Generally the internal meaning representation is based on flat concept sets obtained by either keyword spotting or conceptual decoding.", "labels": [], "entities": [{"text": "keyword spotting", "start_pos": 95, "end_pos": 111, "type": "TASK", "confidence": 0.7634190022945404}]}, {"text": "In some cases a dialog act can be added on top of the concept set.", "labels": [], "entities": []}, {"text": "Here we intend to consider an additional semantic composition step which will capture the abstract semantic structures conveyed by the basic concept representation.", "labels": [], "entities": []}, {"text": "A frame formalism is applied to specify these nested structures.", "labels": [], "entities": []}, {"text": "As such structures do not rely on sequential constraints, pure left-right branching semantic parser (such as) will not apply in this case.", "labels": [], "entities": []}, {"text": "To derive automatically such frame meaning representations we propose a system based on a two decoding step process using dynamic Bayesian networks (DBNs) (): first basic concepts are derived from the user's utterance transcriptions, then inferences are made on sequential semantic frame structures, considering all the available previous annotation levels (words and concepts).", "labels": [], "entities": []}, {"text": "The inference process extracts all possible sub-trees (branches) according to lower level information (generation) and composes the hypothesized branches into a single utterance-span tree (composition).", "labels": [], "entities": []}, {"text": "A hand-craft rule-based approach is used to derive the seed annotated training data.", "labels": [], "entities": []}, {"text": "So both approaches are not competing and the stochastic approach is justified as only the DBN system is able to provide n-best lists of tree hypotheses with confidence scores to a stochastic dialog manager (such as the very promising POMDP-based approaches).", "labels": [], "entities": []}, {"text": "The paper is organized as follows.", "labels": [], "entities": []}, {"text": "The next section presents the semantic frame annotation on the MEDIA corpus.", "labels": [], "entities": [{"text": "MEDIA corpus", "start_pos": 63, "end_pos": 75, "type": "DATASET", "confidence": 0.8867695927619934}]}, {"text": "Then Section 3 introduces the DBNbased models for semantic composition and finally Section 4 reports on the experiments.", "labels": [], "entities": [{"text": "semantic composition", "start_pos": 50, "end_pos": 70, "type": "TASK", "confidence": 0.7492563426494598}]}, {"text": "2 Semantic Frames on the MEDIA corpus MEDIA is a French corpus of negotiation dialogs among users and a tourist information phone server ().", "labels": [], "entities": [{"text": "MEDIA corpus MEDIA", "start_pos": 25, "end_pos": 43, "type": "DATASET", "confidence": 0.8251912196477255}]}, {"text": "The corpus contains 1,257 dialogs recorded using a Wizard of Oz system.", "labels": [], "entities": []}, {"text": "The semantic corpus is annotated with concept-value pairs corresponding to word segments with the addition of specifier tags representing some relations between concepts.", "labels": [], "entities": []}, {"text": "The annotation utilizes 83 basic concepts and 19 specifiers.", "labels": [], "entities": []}, {"text": "Amongst the available semantic representations, the semantic frames () are probably the most suited to the task, mostly because of their ability to represent negotiation dialogs.", "labels": [], "entities": []}, {"text": "Semantic frames are computational models describing common or abstract situations involving roles, the frame elements (FEs).", "labels": [], "entities": []}, {"text": "The FrameNet project () provides a large frame database for English.", "labels": [], "entities": []}, {"text": "As no such resource exists for French, we elaborated a frame ontology to describe the semantic knowledge of the MEDIA domain.", "labels": [], "entities": [{"text": "MEDIA domain", "start_pos": 112, "end_pos": 124, "type": "DATASET", "confidence": 0.7680642008781433}]}, {"text": "The MEDIA ontology is composed of 21 frames and 86 FEs.", "labels": [], "entities": [{"text": "FEs", "start_pos": 51, "end_pos": 54, "type": "METRIC", "confidence": 0.9889140725135803}]}, {"text": "All are described by a set of manually defined patterns made of lexical units and conceptual units (frame and FE evoking words and concepts).", "labels": [], "entities": [{"text": "FE", "start_pos": 110, "end_pos": 112, "type": "METRIC", "confidence": 0.9675163626670837}]}, {"text": "gives the annotation of word sequence \"staying in a hotel near the Festival de Cannes\".", "labels": [], "entities": [{"text": "Festival de Cannes", "start_pos": 67, "end_pos": 85, "type": "DATASET", "confidence": 0.9175140062967936}]}, {"text": "The training data are automatically annotated by a rule-based process.", "labels": [], "entities": []}, {"text": "Pattern matching triggers the instantiation of frames and FEs which are composed using a set of logical rules.", "labels": [], "entities": [{"text": "Pattern matching", "start_pos": 0, "end_pos": 16, "type": "TASK", "confidence": 0.8297158777713776}]}, {"text": "Composition may involve creation, modification or deletion of frame and FE instances.", "labels": [], "entities": []}, {"text": "About 70 rules are currently used.", "labels": [], "entities": []}, {"text": "This process is task-oriented and is progressively enriched with new rules to improve its accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 90, "end_pos": 98, "type": "METRIC", "confidence": 0.9969353675842285}]}, {"text": "A reference frame annotation for the training corpus is established in this way and used for learning the parameters of the stochastic models introduced in the next section.", "labels": [], "entities": []}], "datasetContent": [{"text": "The DBN-based composition systems were evaluated on a test set of 225 speakers' turns manually annotated in terms of frames and FEs.", "labels": [], "entities": [{"text": "FEs", "start_pos": 128, "end_pos": 131, "type": "METRIC", "confidence": 0.9627742767333984}]}, {"text": "The rulebased system was used to perform a frame annotation of the MEDIA data.", "labels": [], "entities": [{"text": "MEDIA data", "start_pos": 67, "end_pos": 77, "type": "DATASET", "confidence": 0.8798255324363708}]}, {"text": "On the test set, an average F-measure of 0.95 for frame identification confirms the good reliability of the process.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 28, "end_pos": 37, "type": "METRIC", "confidence": 0.9992282390594482}, {"text": "frame identification", "start_pos": 50, "end_pos": 70, "type": "TASK", "confidence": 0.797169953584671}]}, {"text": "The DBN model parameters were trained on the training data using jointly the manual transcriptions, the manual concept annotations and the rule-based frame annotations.", "labels": [], "entities": []}, {"text": "Experiments were carried out on the test set under three conditions varying the input noise level: \u2022 REF (reference): speaker turns manually transcribed and annotated; \u2022 SLU: concepts decoded from manual transcriptions using a DBN-based SLU model comparable to   generated by an ASR system and concepts decoded using them (14.8% word error rate, 24.3% concept error rate).", "labels": [], "entities": [{"text": "REF", "start_pos": 101, "end_pos": 104, "type": "METRIC", "confidence": 0.9921384453773499}, {"text": "word error rate", "start_pos": 329, "end_pos": 344, "type": "METRIC", "confidence": 0.7451277772585551}, {"text": "concept error rate", "start_pos": 352, "end_pos": 370, "type": "METRIC", "confidence": 0.8005499243736267}]}, {"text": "All the experiments reported in the paper were performed using GMTK (), a general purpose graphical model toolkit and SRILM), a language modeling toolkit. is populated with the results on the test set for the DBN-based frame composition systems in terms of precision, recall and F-measure.", "labels": [], "entities": [{"text": "GMTK", "start_pos": 63, "end_pos": 67, "type": "DATASET", "confidence": 0.7394943237304688}, {"text": "SRILM", "start_pos": 118, "end_pos": 123, "type": "METRIC", "confidence": 0.752683699131012}, {"text": "precision", "start_pos": 257, "end_pos": 266, "type": "METRIC", "confidence": 0.9994623064994812}, {"text": "recall", "start_pos": 268, "end_pos": 274, "type": "METRIC", "confidence": 0.9992721676826477}, {"text": "F-measure", "start_pos": 279, "end_pos": 288, "type": "METRIC", "confidence": 0.9967989921569824}]}, {"text": "For the FE figures, only the reference FEs corresponding to correctly identified frames are considered.", "labels": [], "entities": [{"text": "FE", "start_pos": 8, "end_pos": 10, "type": "METRIC", "confidence": 0.6553247570991516}, {"text": "FEs", "start_pos": 39, "end_pos": 42, "type": "METRIC", "confidence": 0.9451546669006348}]}, {"text": "Only the frame and FE names are considered, neither their constituents nor their order matter.", "labels": [], "entities": [{"text": "FE", "start_pos": 19, "end_pos": 21, "type": "METRIC", "confidence": 0.9536582827568054}]}, {"text": "Finally, results are given for the sub-frame links between frames and FEs.", "labels": [], "entities": [{"text": "FEs", "start_pos": 70, "end_pos": 73, "type": "METRIC", "confidence": 0.963908314704895}]}, {"text": "shows that the performances of the 3 DBN-based systems are quite comparable.", "labels": [], "entities": []}, {"text": "Anyhow the 2-level system can be considered the best as besides its good F-measure results, it is also the most efficient model in terms of decoding complexity.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 73, "end_pos": 82, "type": "METRIC", "confidence": 0.94355309009552}]}, {"text": "The good results obtained for the sub-frame links confirm that the DBN models combined with a small rule set can be used to generate consistent hierarchical structures.", "labels": [], "entities": []}, {"text": "Moreover, as they can provide hypotheses with confidence scores they can be used in a multiple input/output context (lattices and n-best lists) or in a validation process (evaluating and ranking hypotheses from other systems).", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Precision (\u00af p), Recall (\u00af r) and F-measure ( \u00af  F-m) on the MEDIA test set for the DBN-based frame composition  systems.", "labels": [], "entities": [{"text": "Precision (\u00af p)", "start_pos": 10, "end_pos": 25, "type": "METRIC", "confidence": 0.9347552806138992}, {"text": "Recall (\u00af r)", "start_pos": 27, "end_pos": 39, "type": "METRIC", "confidence": 0.9607978314161301}, {"text": "F-measure ( \u00af  F-m)", "start_pos": 44, "end_pos": 63, "type": "METRIC", "confidence": 0.8613417863845825}, {"text": "MEDIA test set", "start_pos": 71, "end_pos": 85, "type": "DATASET", "confidence": 0.8956208825111389}]}]}