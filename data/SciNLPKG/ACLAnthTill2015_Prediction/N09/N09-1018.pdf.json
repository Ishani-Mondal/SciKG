{"title": [{"text": "Jointly Identifying Predicates, Arguments and Senses using Markov Logic", "labels": [], "entities": []}], "abstractContent": [{"text": "In this paper we present a Markov Logic Network for Semantic Role Labelling that jointly performs predicate identification, frame dis-ambiguation, argument identification and argument classification for all predicates in a sentence.", "labels": [], "entities": [{"text": "Semantic Role Labelling", "start_pos": 52, "end_pos": 75, "type": "TASK", "confidence": 0.6772480209668478}, {"text": "predicate identification", "start_pos": 98, "end_pos": 122, "type": "TASK", "confidence": 0.9052634239196777}, {"text": "argument identification", "start_pos": 147, "end_pos": 170, "type": "TASK", "confidence": 0.728766068816185}, {"text": "argument classification", "start_pos": 175, "end_pos": 198, "type": "TASK", "confidence": 0.7548123896121979}]}, {"text": "Empirically we find that our approach is competitive: our best model would appear on par with the best entry in the CoNLL 2008 shared task open track, and at the 4th place of the closed track-right behind the systems that use significantly better parsers to generate their input features.", "labels": [], "entities": [{"text": "CoNLL 2008 shared task open track", "start_pos": 116, "end_pos": 149, "type": "DATASET", "confidence": 0.7492246826489767}]}, {"text": "Moreover , we observe that by fully capturing the complete SRL pipeline in a single probabilis-tic model we can achieve significant improvements over more isolated systems, in particular for out-of-domain data.", "labels": [], "entities": [{"text": "SRL pipeline", "start_pos": 59, "end_pos": 71, "type": "TASK", "confidence": 0.881332129240036}]}, {"text": "Finally, we show that despite the joint approach, our system is still efficient.", "labels": [], "entities": []}], "introductionContent": [{"text": "Semantic Role Labelling (SRL,) is generally understood as the task of identifying and classifying the semantic arguments and modifiers of the predicates mentioned in a sentence.", "labels": [], "entities": [{"text": "Semantic Role Labelling (SRL", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.7954881310462951}, {"text": "classifying the semantic arguments and modifiers of the predicates mentioned in a sentence", "start_pos": 86, "end_pos": 176, "type": "TASK", "confidence": 0.6053800032689021}]}, {"text": "For example, in the case of the following sentence: we are to find out that for the predicate token \"plays\" with sense \"play a role\" (play.02) the phrase headed by the token \"Haag\" is referring to the player (A0) of the play event, and the phrase headed by the token \"Elianti\" is referring to the role (A1) being played.", "labels": [], "entities": []}, {"text": "SRL is considered as a key task for applications that require to answer \"Who\", \"What\", \"Where\", etc.", "labels": [], "entities": [{"text": "SRL", "start_pos": 0, "end_pos": 3, "type": "TASK", "confidence": 0.8683567047119141}]}, {"text": "questions, such as Information Extraction, Question Answering and Summarization.", "labels": [], "entities": [{"text": "Information Extraction", "start_pos": 19, "end_pos": 41, "type": "TASK", "confidence": 0.7978648245334625}, {"text": "Question Answering", "start_pos": 43, "end_pos": 61, "type": "TASK", "confidence": 0.8684171736240387}, {"text": "Summarization", "start_pos": 66, "end_pos": 79, "type": "TASK", "confidence": 0.9380427598953247}]}, {"text": "Any real-world SRL system needs to make several decisions, either explicitly or implicitly: which are the predicate tokens of a sentence (predicate identification), which are the tokens that have semantic roles with respect to these predicates (argument identification), which are the roles these tokens play (argument classification), and which is the sense of the predicate (sense disambiguation).", "labels": [], "entities": [{"text": "SRL", "start_pos": 15, "end_pos": 18, "type": "TASK", "confidence": 0.9669130444526672}]}, {"text": "In this paper we use Markov Logic (ML), a Statistical Relational Learning framework that combines First Order Logic and Markov Networks, to develop a joint probabilistic model overall decisions mentioned above.", "labels": [], "entities": []}, {"text": "The following paragraphs will motivate this choice.", "labels": [], "entities": []}, {"text": "First, it allows us to readily capture global correlations between decisions, such as the constraint that a predicate can only have one agent.", "labels": [], "entities": []}, {"text": "This type of correlations has been successfully exploited in several previous SRL approaches ().", "labels": [], "entities": [{"text": "SRL", "start_pos": 78, "end_pos": 81, "type": "TASK", "confidence": 0.9811035394668579}]}, {"text": "Second, we can use the joint model to evaluate the benefit of incorporating decisions into the joint model that either have not received much attention within the SRL community (predicate identification and sense disambiguation), or been largely made in isolation (argument identification and classification for all predicates of a sentence).", "labels": [], "entities": [{"text": "SRL", "start_pos": 163, "end_pos": 166, "type": "TASK", "confidence": 0.950128436088562}, {"text": "predicate identification and sense disambiguation", "start_pos": 178, "end_pos": 227, "type": "TASK", "confidence": 0.6350612998008728}, {"text": "argument identification", "start_pos": 265, "end_pos": 288, "type": "TASK", "confidence": 0.7307746410369873}]}, {"text": "Third, our ML model is essentially a template that describes a class of Markov Networks.", "labels": [], "entities": []}, {"text": "Algorithms can perform inference in terms of this template with-out ever having to fully instantiate the complete Markov Network (.", "labels": [], "entities": []}, {"text": "This can dramatically improve the efficiency of an SRL system when compared to a propositional approach such as Integer Linear Programming (ILP).", "labels": [], "entities": [{"text": "SRL", "start_pos": 51, "end_pos": 54, "type": "TASK", "confidence": 0.981478214263916}]}, {"text": "Finally, when it comes to actually building an SRL system with ML there are \"only\" four things to do: preparing input data files, converting output data files, and triggering learning and inference.", "labels": [], "entities": [{"text": "SRL", "start_pos": 47, "end_pos": 50, "type": "TASK", "confidence": 0.955394983291626}]}, {"text": "The remaining work can be done by an off-theshelf Markov Logic interpreter.", "labels": [], "entities": []}, {"text": "This is to be contrasted with pipeline systems where several components need to be trained and connected, or Integer Linear Programming approaches for which we need to write additional wrapper code to generate ILPs.", "labels": [], "entities": []}, {"text": "Empirically we find that our system is competitive-our best model would appear on par with the best entry in the shared task open track, and at the 4th place of the closed track-right behind systems that use significantly better parsers 1 to generate their input features.", "labels": [], "entities": []}, {"text": "We also observe that by integrating frame disambiguation into the joint SRL model, and by extracting all arguments for all predicates in a sentence simultaneously, significant improvements compared to more isolated systems can be achieved.", "labels": [], "entities": [{"text": "frame disambiguation", "start_pos": 36, "end_pos": 56, "type": "TASK", "confidence": 0.712728887796402}]}, {"text": "These improvements are particularly large in the case of out-of-domain data, suggesting that a joint approach helps to increase the robustness of SRL.", "labels": [], "entities": [{"text": "SRL", "start_pos": 146, "end_pos": 149, "type": "TASK", "confidence": 0.9688647985458374}]}, {"text": "Finally, we show that despite the joint approach, our system is still efficient.", "labels": [], "entities": []}, {"text": "Our paper is organised as follows: we first introduce ML (section 2), then we present our model in terms of ML (section 3) and illustrate how to perform learning and inference with it (section 4).", "labels": [], "entities": []}, {"text": "How this model will be evaluated is explained in section 5 with the corresponding evaluation presented in section 6.", "labels": [], "entities": []}, {"text": "We conclude in section 7.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 3: Semantic F 1 scores for our systems and three  CoNLL 2008 shared task participants. The Bottom-up  results are statistically significantly different to all others  (i.e., \u03c1 \u2264 0.05 according to the sign test).", "labels": [], "entities": [{"text": "F 1", "start_pos": 19, "end_pos": 22, "type": "METRIC", "confidence": 0.9180091023445129}, {"text": "CoNLL 2008 shared task", "start_pos": 57, "end_pos": 79, "type": "DATASET", "confidence": 0.9319638609886169}]}, {"text": " Table 4: F 1 scores for M predicates; Pipe. refers to the  Pipeline system, Fu. to the full system.", "labels": [], "entities": [{"text": "F 1 scores", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.9619324803352356}, {"text": "Pipeline system", "start_pos": 60, "end_pos": 75, "type": "DATASET", "confidence": 0.8940105140209198}]}, {"text": " Table 5: F 1 scores for ML predicates; w/o refers to  a Bottom-up system without isArgument predicate, w/  refers to a Bottom-up system with isArgument predicate.", "labels": [], "entities": [{"text": "F 1", "start_pos": 10, "end_pos": 13, "type": "METRIC", "confidence": 0.9773183763027191}, {"text": "ML predicates", "start_pos": 25, "end_pos": 38, "type": "TASK", "confidence": 0.9675134420394897}]}]}