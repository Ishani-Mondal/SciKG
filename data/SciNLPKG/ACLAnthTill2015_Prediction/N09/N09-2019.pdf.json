{"title": [{"text": "Minimum Bayes Risk Combination of Translation Hypotheses from Alternative Morphological Decompositions", "labels": [], "entities": []}], "abstractContent": [{"text": "We describe a simple strategy to achieve translation performance improvements by combining output from identical statistical machine translation systems trained on alternative morphological decompositions of the source language.", "labels": [], "entities": []}, {"text": "Combination is done by means of Minimum Bayes Risk decoding over a shared N-best list.", "labels": [], "entities": [{"text": "Minimum Bayes Risk decoding", "start_pos": 32, "end_pos": 59, "type": "TASK", "confidence": 0.4716786667704582}]}, {"text": "When translating into English from two highly inflected languages such as Ara-bic and Finnish we obtain significant improvements over simply selecting the best morphological decomposition.", "labels": [], "entities": []}], "introductionContent": [{"text": "Morphologically rich languages pose significant challenges for natural language processing.", "labels": [], "entities": [{"text": "natural language processing", "start_pos": 63, "end_pos": 90, "type": "TASK", "confidence": 0.6714096566041311}]}, {"text": "The extensive use of inflection, derivation, and composition leads to a huge vocabulary, and sparsity in models estimated from data.", "labels": [], "entities": []}, {"text": "Statistical machine translation (SMT) systems estimated from parallel text are affected by this.", "labels": [], "entities": [{"text": "Statistical machine translation (SMT)", "start_pos": 0, "end_pos": 37, "type": "TASK", "confidence": 0.7741055687268575}]}, {"text": "This is particularly acute when either the source or the target language, or both, are morphologically complex.", "labels": [], "entities": []}, {"text": "Owing to these difficulties and to the natural interest researchers take in complex linguistic phenomena, many approaches to morphological analysis have been developed and evaluated.", "labels": [], "entities": [{"text": "morphological analysis", "start_pos": 125, "end_pos": 147, "type": "TASK", "confidence": 0.813100278377533}]}, {"text": "We focus on applications to SMT in Section 1.1, but we note the recent general survey and the Morpho Challenge competitive evaluations . Prior evaluations of morphological analyzers have focused on determining which analyzer was See http://www.cis.hut.fi/morphochallenge2009/ and links best suited for some particular task.", "labels": [], "entities": [{"text": "SMT", "start_pos": 28, "end_pos": 31, "type": "TASK", "confidence": 0.9953742623329163}]}, {"text": "For translation, we take a different approach and investigate whether competing analyzers might have complementary information.", "labels": [], "entities": [{"text": "translation", "start_pos": 4, "end_pos": 15, "type": "TASK", "confidence": 0.9878042936325073}]}, {"text": "We train two identical SMT systems with two versions of the same parallel corpus, each with a different morphological decomposition of the source language.", "labels": [], "entities": [{"text": "SMT", "start_pos": 23, "end_pos": 26, "type": "TASK", "confidence": 0.9876437187194824}]}, {"text": "We combine their translation hypotheses performing Minimum Bayes Risk decoding over merged Nbest lists.", "labels": [], "entities": [{"text": "Minimum Bayes Risk decoding", "start_pos": 51, "end_pos": 78, "type": "TASK", "confidence": 0.6249520853161812}]}, {"text": "Results are reported in the NIST 2008 Arabic-to-English MT task and an European Parliament Finnish-to-English task, with significant gains over each individual system.", "labels": [], "entities": [{"text": "NIST 2008 Arabic-to-English MT task", "start_pos": 28, "end_pos": 63, "type": "TASK", "confidence": 0.7703794121742249}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 2: Arabic-to-English translation results. Lower- cased IBM BLEU reported.", "labels": [], "entities": [{"text": "IBM", "start_pos": 62, "end_pos": 65, "type": "DATASET", "confidence": 0.5846203565597534}, {"text": "BLEU", "start_pos": 66, "end_pos": 70, "type": "METRIC", "confidence": 0.9276320338249207}]}, {"text": " Table 3: Finnish-to-English translation results. Lower- cased IBM BLEU reported.", "labels": [], "entities": [{"text": "Finnish-to-English translation", "start_pos": 10, "end_pos": 40, "type": "TASK", "confidence": 0.6087420284748077}, {"text": "IBM", "start_pos": 63, "end_pos": 66, "type": "DATASET", "confidence": 0.5767621397972107}, {"text": "BLEU", "start_pos": 67, "end_pos": 71, "type": "METRIC", "confidence": 0.9238027930259705}]}]}