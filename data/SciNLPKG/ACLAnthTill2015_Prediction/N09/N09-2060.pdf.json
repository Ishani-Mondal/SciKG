{"title": [], "abstractContent": [{"text": "This paper presents methods for performing graph-based semantic classification using kernel functions defined on the WordNet lexical hierarchy.", "labels": [], "entities": [{"text": "graph-based semantic classification", "start_pos": 43, "end_pos": 78, "type": "TASK", "confidence": 0.7086683909098307}, {"text": "WordNet lexical hierarchy", "start_pos": 117, "end_pos": 142, "type": "DATASET", "confidence": 0.9411538044611613}]}, {"text": "These functions are evaluated on the SemEval Task 4 relation classification dataset and their performance is shown to be competitive with that of more complex systems.", "labels": [], "entities": [{"text": "SemEval Task 4 relation classification", "start_pos": 37, "end_pos": 75, "type": "TASK", "confidence": 0.8071732640266418}]}, {"text": "A number of possible future developments are suggested to illustrate the flexibility of the approach.", "labels": [], "entities": []}], "introductionContent": [{"text": "The estimation of semantic similarity between words is one of the longest-established tasks in Natural Language Processing and many approaches to the problem have been proposed.", "labels": [], "entities": [{"text": "estimation of semantic similarity between words", "start_pos": 4, "end_pos": 51, "type": "TASK", "confidence": 0.8856844703356425}]}, {"text": "The two dominant lexical similarity paradigms are distributional similarity, which compares words on the basis of their observed co-occurrence behaviour in corpora, and semantic network similarity, which compares words based on their position in a graph such as the WordNet hierarchy.", "labels": [], "entities": []}, {"text": "In this paper we consider measures of network similarity for the purpose of supervised classification with kernel methods.", "labels": [], "entities": []}, {"text": "The utility of kernel functions related to popular distributional similarity measures has recently been demonstrated by\u00b4Oby\u00b4 by\u00b4O; we show here that kernel analogues of WordNet similarity can likewise give good performance on a semantic classification task.", "labels": [], "entities": [{"text": "semantic classification task", "start_pos": 228, "end_pos": 256, "type": "TASK", "confidence": 0.7974583804607391}]}], "datasetContent": [{"text": "For all kernels and relation datasets, the kernel matrix for each argument position was precomputed and normalised so that every diagonal entry equalled 1.", "labels": [], "entities": []}, {"text": "A small number of candidate arguments are not annotated with a WordNet sense or are assigned a non-noun sense; these arguments were assumed to have self-similarity equal to 1 and zero similarity to all other arguments.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 63, "end_pos": 70, "type": "DATASET", "confidence": 0.9217516183853149}]}, {"text": "This does not affect the positive semi-definiteness of the kernel matrices.", "labels": [], "entities": []}, {"text": "The per-argument kernel matrices were summed to give the kernel matrix for each relation subtask.", "labels": [], "entities": []}, {"text": "The ker- All experiments were run using the LIBSVM support vector machine library).", "labels": [], "entities": [{"text": "LIBSVM support vector machine library", "start_pos": 44, "end_pos": 81, "type": "DATASET", "confidence": 0.8624584197998046}]}, {"text": "For each relation the SVM cost parameter was optimised in the range (2 \u22126 , 2 \u22124 , . .", "labels": [], "entities": []}, {"text": ", 2 12 ) through cross-validation on the training set.", "labels": [], "entities": []}, {"text": "The diffusion kernel parameter twas optimised in the same way, in the range (10 \u22123 , 10 \u22122 , . .", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Results on SemEval Task 4", "labels": [], "entities": [{"text": "SemEval Task", "start_pos": 21, "end_pos": 33, "type": "TASK", "confidence": 0.9180050194263458}]}]}