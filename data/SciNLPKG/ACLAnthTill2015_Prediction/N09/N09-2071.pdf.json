{"title": [{"text": "Tightly coupling Speech Recognition and Search", "labels": [], "entities": [{"text": "Speech Recognition", "start_pos": 17, "end_pos": 35, "type": "TASK", "confidence": 0.7326039671897888}, {"text": "Search", "start_pos": 40, "end_pos": 46, "type": "TASK", "confidence": 0.6551851034164429}]}], "abstractContent": [{"text": "In this paper, we discuss the benefits of tightly coupling speech recognition and search components in the context of a speech-driven search application.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 59, "end_pos": 77, "type": "TASK", "confidence": 0.7206809222698212}]}, {"text": "We demonstrate that by incorporating constraints from the information repository that is being searched not only improves the speech recognition accuracy but also results in higher search accuracy.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 126, "end_pos": 144, "type": "TASK", "confidence": 0.7830207943916321}, {"text": "accuracy", "start_pos": 145, "end_pos": 153, "type": "METRIC", "confidence": 0.9087819457054138}, {"text": "accuracy", "start_pos": 188, "end_pos": 196, "type": "METRIC", "confidence": 0.9669808149337769}]}], "introductionContent": [{"text": "With the exponential growth in the use of mobile devices in recent years, the need for speech-driven interfaces is becoming apparent.", "labels": [], "entities": []}, {"text": "The limited screen space and soft keyboards of mobile devices make it cumbersome to type in text input.", "labels": [], "entities": []}, {"text": "Furthermore, by the mobile nature of these devices, users often would like to use them in hands-busy environments, ruling out the possibility of typing text.", "labels": [], "entities": []}, {"text": "In this paper, we focus on the problem of speechdriven search to access information repositories using mobile devices.", "labels": [], "entities": []}, {"text": "Such an application typically uses a speech recognizer (ASR) for transforming the user's speech input to text and a search component that uses the resulting text as a query to retrieve the relevant documents from the information repository.", "labels": [], "entities": []}, {"text": "For the purposes of this paper, we use the business listings containing the name, address and phone number of businesses as the information repository.", "labels": [], "entities": []}, {"text": "Most of the literature on speech-driven search applications that are available in the consumer market () have quite rightly emphasized the importance of the robustness of the ASR language model and the data needed to build such a robust language model.", "labels": [], "entities": [{"text": "ASR language", "start_pos": 175, "end_pos": 187, "type": "TASK", "confidence": 0.8794399499893188}]}, {"text": "We acknowledge that this is a significant issue for building such systems, and we provide our approach to creating a language model.", "labels": [], "entities": []}, {"text": "However, in contrast to most of these systems that treat speech-driven search to be largely an ASR problem followed by a Search problem, in this paper, we show the benefits of tightly coupling ASR and Search tasks and illustrate techniques to improve the accuracy of both components by exploiting the co-constraints between the two components.", "labels": [], "entities": [{"text": "ASR problem", "start_pos": 95, "end_pos": 106, "type": "TASK", "confidence": 0.9004684090614319}, {"text": "accuracy", "start_pos": 255, "end_pos": 263, "type": "METRIC", "confidence": 0.9969078898429871}]}, {"text": "The outline of the paper is as follows.", "labels": [], "entities": []}, {"text": "In Section 2, we discuss the setup of our speech-driven application.", "labels": [], "entities": []}, {"text": "In Section 3, we discuss our method to integrating the speech and search components.", "labels": [], "entities": []}, {"text": "We present the results of the experiments in Section 4 and conclude in Section 5.", "labels": [], "entities": []}], "datasetContent": [{"text": "We took 852 speech queries collected from users using a mobile device based speech search application.", "labels": [], "entities": []}, {"text": "We ran the speech recognizer on these queries using the language model described in Section 2 and created word-confusion networks such as those illustrated in.", "labels": [], "entities": [{"text": "speech recognizer", "start_pos": 11, "end_pos": 28, "type": "TASK", "confidence": 0.700483500957489}]}, {"text": "These 852 utterances were divided into 300 utterances for the development set and 552 for the test set.", "labels": [], "entities": []}, {"text": "We transform the scores into costs and search for minimum cost paths.", "labels": [], "entities": []}, {"text": "The baseline ASR word and sentence (complete string) accuracies on the development set are 63.1% and 57.0% while those on the test set are 65.1% and 55.3% respectively.", "labels": [], "entities": [{"text": "ASR word and sentence (complete string) accuracies", "start_pos": 13, "end_pos": 63, "type": "METRIC", "confidence": 0.635100394487381}]}, {"text": "In, we summarize the improvements obtained by rescoring the ASR WCNs based on the different metrics used for computing the word scores according to the search criteria.", "labels": [], "entities": [{"text": "ASR WCNs", "start_pos": 60, "end_pos": 68, "type": "TASK", "confidence": 0.49346737563610077}]}, {"text": "The largest improvement in word and sentence accuracies is obtained by using the rescoring metric:  To analyze the Search accuracy of the baseline ASR output in comparison to the ASR output, reranked using the |dfw| \u00d7 idf reranking metric, we used each of the two sets of ASR outputs (i.e., baseline and reranked) as queries to our search engine, SearchFST (described in Section 3).", "labels": [], "entities": [{"text": "Search accuracy", "start_pos": 115, "end_pos": 130, "type": "METRIC", "confidence": 0.7192456424236298}]}, {"text": "For the search results produced by each set of queries, we computed the precision, recall, and F-score values of the listings retrieved with respect to the listings retrieved by the set of human transcribed queries (Reference).", "labels": [], "entities": [{"text": "precision", "start_pos": 72, "end_pos": 81, "type": "METRIC", "confidence": 0.9995594620704651}, {"text": "recall", "start_pos": 83, "end_pos": 89, "type": "METRIC", "confidence": 0.9964851140975952}, {"text": "F-score", "start_pos": 95, "end_pos": 102, "type": "METRIC", "confidence": 0.9992623925209045}]}, {"text": "The precision, recall, and F-scores for the baseline ASR output and the reranked ASR output, averaged across each set, is presented in.", "labels": [], "entities": [{"text": "precision", "start_pos": 4, "end_pos": 13, "type": "METRIC", "confidence": 0.9994908571243286}, {"text": "recall", "start_pos": 15, "end_pos": 21, "type": "METRIC", "confidence": 0.9963020086288452}, {"text": "F-scores", "start_pos": 27, "end_pos": 35, "type": "METRIC", "confidence": 0.9990099668502808}, {"text": "ASR", "start_pos": 53, "end_pos": 56, "type": "TASK", "confidence": 0.704360842704773}]}, {"text": "For the purposes of this experiment, we assume that the set returned by our SearchFST for the human transcribed set of queries is the reference search set.", "labels": [], "entities": []}, {"text": "This is however an approximation fora human annotated search set.", "labels": [], "entities": []}, {"text": "In, by comparing the search accuracy scores corresponding to the baseline ASR output to those corresponding to the reranked ASR output, we see that reranking the ASR output using the information repository produces a substantial improvement in the accuracy of the search results.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 28, "end_pos": 36, "type": "METRIC", "confidence": 0.8232380747795105}, {"text": "accuracy", "start_pos": 248, "end_pos": 256, "type": "METRIC", "confidence": 0.9969269633293152}]}, {"text": "It is interesting to note that even though the reranking of the ASR as shown in is of the order of 1%, the improvement in Search accuracy is substantially higher.", "labels": [], "entities": [{"text": "reranking", "start_pos": 47, "end_pos": 56, "type": "METRIC", "confidence": 0.9950690269470215}, {"text": "ASR", "start_pos": 64, "end_pos": 67, "type": "TASK", "confidence": 0.6338402032852173}, {"text": "accuracy", "start_pos": 129, "end_pos": 137, "type": "METRIC", "confidence": 0.9264991879463196}]}, {"text": "This indicates to the fact that exploiting constraints from both components results in improving the recognition accuracy of that subset of words that are more relevant for Search.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 113, "end_pos": 121, "type": "METRIC", "confidence": 0.9644085764884949}]}], "tableCaptions": [{"text": " Table 2: Performance of the metrics used for rescoring  the WCNs output by ASR. (AD refers to arc density.)", "labels": [], "entities": [{"text": "AD", "start_pos": 82, "end_pos": 84, "type": "METRIC", "confidence": 0.9521603584289551}]}, {"text": " Table 3: Table showing the relevancy of the search results  obtained by the baseline ASR output compared to those  obtained by the reranked ASR output.", "labels": [], "entities": []}]}