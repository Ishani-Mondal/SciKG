{"title": [{"text": "Improving A Simple Bigram HMM Part-of-Speech Tagger by Latent Annotation and Self-Training", "labels": [], "entities": [{"text": "HMM Part-of-Speech Tagger", "start_pos": 26, "end_pos": 51, "type": "TASK", "confidence": 0.7097981770833334}]}], "abstractContent": [{"text": "In this paper, we describe and evaluate a bi-gram part-of-speech (POS) tagger that uses latent annotations and then investigate using additional genre-matched unlabeled data for self-training the tagger.", "labels": [], "entities": []}, {"text": "The use of latent annotations substantially improves the performance of a baseline HMM bigram tag-ger, outperforming a trigram HMM tagger with sophisticated smoothing.", "labels": [], "entities": []}, {"text": "The performance of the latent tagger is further enhanced by self-training with a large set of unlabeled data, even in situations where standard bigram or trigram taggers do not benefit from self-training when trained on greater amounts of labeled training data.", "labels": [], "entities": []}, {"text": "Our best model obtains a state-of-the-art Chinese tagging accuracy of 94.78% when evaluated on a representative test set of the Penn Chinese Treebank 6.0.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 58, "end_pos": 66, "type": "METRIC", "confidence": 0.9354587197303772}, {"text": "Penn Chinese Treebank 6.0", "start_pos": 128, "end_pos": 153, "type": "DATASET", "confidence": 0.9867161959409714}]}], "introductionContent": [{"text": "Part-of-speech (POS) tagging, the process of assigning every word in a sentence with a POS tag (e.g., NN (normal noun) or JJ (adjective)), is prerequisite for many advanced natural language processing tasks.", "labels": [], "entities": [{"text": "Part-of-speech (POS) tagging", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.6057805478572845}]}, {"text": "Building upon the large body of research to improve tagging performance for various languages using various models (e.g.,) and the recent work on PCFG grammars with latent annotations (), we will investigate the use of fine-grained latent annotations for Chinese POS tagging.", "labels": [], "entities": [{"text": "tagging", "start_pos": 52, "end_pos": 59, "type": "TASK", "confidence": 0.9654436111450195}, {"text": "POS tagging", "start_pos": 263, "end_pos": 274, "type": "TASK", "confidence": 0.6288240551948547}]}, {"text": "While state-of-the-art tagging systems have achieved accuracies above 97% in English, Chinese POS tagging () has proven to be more challenging, and it is the focus of this study.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 94, "end_pos": 105, "type": "TASK", "confidence": 0.7788176834583282}]}, {"text": "The value of the latent variable approach for tagging is that it can learn more fine grained tags to better model the training data.", "labels": [], "entities": [{"text": "tagging", "start_pos": 46, "end_pos": 53, "type": "TASK", "confidence": 0.9808696508407593}]}, {"text": "analyzed the errors of unsupervised learning using EM and found that both estimation and optimization errors decrease as the amount of unlabeled data increases.", "labels": [], "entities": []}, {"text": "In our case, the learning of latent annotations through EM may also benefit from a large set of automatically labeled data to improve tagging performance.", "labels": [], "entities": []}, {"text": "Semi-supervised, self-labeled data has been effectively used to train acoustic models for speech recognition; however, early investigations of self-training on POS tagging have mixed outcomes.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 90, "end_pos": 108, "type": "TASK", "confidence": 0.8480321168899536}, {"text": "POS tagging", "start_pos": 160, "end_pos": 171, "type": "TASK", "confidence": 0.8723323345184326}]}, {"text": "reported positive results with little labeled training data but negative results when the amount of labeled training data increases.", "labels": [], "entities": []}, {"text": "reported that self-training improves a trigram tagger's accuracy, but this tagger was trained with only a small amount of in-domain labeled data.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 56, "end_pos": 64, "type": "METRIC", "confidence": 0.9979932308197021}]}, {"text": "In this paper, we will investigate whether the performance of a simple bigram HMM tagger can be improved by introducing latent annotations and whether self-training can further improve its performance.", "labels": [], "entities": [{"text": "HMM tagger", "start_pos": 78, "end_pos": 88, "type": "TASK", "confidence": 0.5630827695131302}]}, {"text": "To the best of our knowledge, this is the first attempt to use latent annotations with self-training to enhance the performance of a POS tagger.", "labels": [], "entities": [{"text": "POS tagger", "start_pos": 133, "end_pos": 143, "type": "TASK", "confidence": 0.7397660315036774}]}], "datasetContent": [{"text": "The Penn Chinese Treebank 6.0 (CTB6) () is used as the labeled data in our study.", "labels": [], "entities": [{"text": "Penn Chinese Treebank 6.0 (CTB6)", "start_pos": 4, "end_pos": 36, "type": "DATASET", "confidence": 0.970464961869376}]}, {"text": "CTB6 contains news articles, which are used as the primary source of labeled data in our experiments, as well as broadcast news transcriptions.", "labels": [], "entities": [{"text": "CTB6", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.9661526679992676}]}, {"text": "Since the news articles were collected during different time periods from different sources with a diversity of topics, in order to obtain a representative split of train-testdevelopment sets, we divide them into blocks of 10 files in sorted order and for each block use the first file for development, the second for test, and the remaining for training.", "labels": [], "entities": []}, {"text": "The broadcast news data exhibits many of the characteristics of newswire text (it contains many nonverbal expressions, e.g., numbers and symbols, and is fully punctuated) and so is also included in the training data set.", "labels": [], "entities": [{"text": "training data set", "start_pos": 202, "end_pos": 219, "type": "DATASET", "confidence": 0.7954630454381307}]}, {"text": "We also utilize a greater number of unlabeled sentences in the self-training experiments.", "labels": [], "entities": []}, {"text": "They are selected from similar sources to the newswire articles, and are normalized ( and word segmented (.", "labels": [], "entities": []}, {"text": "See fora summary of the data used.", "labels": [], "entities": []}, {"text": "plots the learning curves of two bigram taggers with latent annotations (Bigram+LA:2 has the special handling of rare words as described in Section 2 while Bigram+LA:1 does not) and compares its performance with a state-of-the-art trigram HMM tagger ( ) that uses trigram transition and emission models together with bidirectional decoding.", "labels": [], "entities": []}, {"text": "Both bigram taggers initially have much lower tagging accuracy than the trigram tagger, due to its strong but invalid independence assumption.", "labels": [], "entities": [{"text": "bigram taggers", "start_pos": 5, "end_pos": 19, "type": "TASK", "confidence": 0.6795659512281418}, {"text": "accuracy", "start_pos": 54, "end_pos": 62, "type": "METRIC", "confidence": 0.9812110662460327}]}, {"text": "As the number of latent annotations increases, the bigram taggers are able to learn more from the context based on the latent annotations, and their performance improves significantly, outperforming the trigram tagger.", "labels": [], "entities": []}, {"text": "The performance gap between the two bigram taggers suggests that over-fitting occurs in the word emission model when more latent annotations are available for optimization; sharing the statistics among rare words alleviates some of the sparseness while supporting the modeling of deeper dependencies among more frequent events.", "labels": [], "entities": []}, {"text": "In the later experiments, we use Bigram+LA to denote the Bigram+LA:2 tagger.", "labels": [], "entities": [{"text": "Bigram+LA:2 tagger", "start_pos": 57, "end_pos": 75, "type": "DATASET", "confidence": 0.8244860370953878}]}, {"text": "compares the self-training capability of three models (the bigram tagger w/ or w/o latent annotations, and the aforementioned trigram tagger) using different sizes of labeled training data and the full set of unlabeled data.", "labels": [], "entities": []}, {"text": "For each model, a tagger is first trained on the allocated labeled training data and is then used to tag the unlabeled data.", "labels": [], "entities": []}, {"text": "A new tagger is then trained on the combination 4 of the allocated labeled training data and the newly automatically labeled data.", "labels": [], "entities": []}, {"text": "There are two interesting observations that distinguish the bigram tagger with latent annotations from the other two taggers.", "labels": [], "entities": []}, {"text": "First, although all of the taggers improve as more labeled training data is available, the performance gap between the bigram tagger with latent annotations and the other two taggers also increases.", "labels": [], "entities": []}, {"text": "This is because more latent annotations can be used to take advantage of the additional training data to learn deeper dependencies.", "labels": [], "entities": []}, {"text": "Second, the bigram tagger with latent annotations benefits much more from self-training, although it already has the highest performance among the three taggers before self-training.", "labels": [], "entities": [{"text": "bigram tagger", "start_pos": 12, "end_pos": 25, "type": "TASK", "confidence": 0.5932218730449677}]}, {"text": "The bigram tagger without latent annotations benefits little from selftraining.", "labels": [], "entities": [{"text": "bigram tagger", "start_pos": 4, "end_pos": 17, "type": "TASK", "confidence": 0.6472633928060532}]}, {"text": "Except fora slight improvement when there is a small amount of labeled training, selftraining slightly hurts tagging performance as the amount of labeled data increases.", "labels": [], "entities": []}, {"text": "The trigram tagger benefits from self-training initially but eventually has a similar pattern to the bigram tagger when trained on the full labeled set.", "labels": [], "entities": [{"text": "trigram tagger", "start_pos": 4, "end_pos": 18, "type": "TASK", "confidence": 0.7051158547401428}]}, {"text": "The performance of the latent bigram tagger improves consistently with self-training.", "labels": [], "entities": [{"text": "bigram tagger", "start_pos": 30, "end_pos": 43, "type": "TASK", "confidence": 0.6373027414083481}]}, {"text": "Although the gain decreases for models trained on larger training sets, since stronger models are harder to improve, self-training still contributes significantly to model accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 172, "end_pos": 180, "type": "METRIC", "confidence": 0.990474283695221}]}, {"text": "The final tagging performance on the test set is reported in.", "labels": [], "entities": []}, {"text": "All of the improvements are statistically significant (p < 0.005).", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: The number of sentences and words in the data.", "labels": [], "entities": []}, {"text": " Table 2. All of the improvements are  statistically significant (p < 0.005).", "labels": [], "entities": []}, {"text": " Table 2: The performance of the taggers on the test set.", "labels": [], "entities": []}]}