{"title": [{"text": "A Simplex Armijo Downhill Algorithm for Optimizing Statistical Machine Translation Decoding Parameters", "labels": [], "entities": [{"text": "Statistical Machine Translation Decoding Parameters", "start_pos": 51, "end_pos": 102, "type": "TASK", "confidence": 0.7768633246421814}]}], "abstractContent": [{"text": "We propose a variation of simplex-downhill algorithm specifically customized for optimizing parameters in statistical machine translation (SMT) de-coder for better end-user automatic evaluation metric scores for translations, such as versions of BLEU, TER and mixtures of them.", "labels": [], "entities": [{"text": "statistical machine translation (SMT)", "start_pos": 106, "end_pos": 143, "type": "TASK", "confidence": 0.7707805881897608}, {"text": "BLEU", "start_pos": 246, "end_pos": 250, "type": "METRIC", "confidence": 0.991862416267395}, {"text": "TER", "start_pos": 252, "end_pos": 255, "type": "METRIC", "confidence": 0.8858649730682373}]}, {"text": "Traditional simplex-downhill has the advantage of derivative-free computations of objective functions, yet still gives satisfactory searching directions inmost scenarios.", "labels": [], "entities": []}, {"text": "This is suitable for optimizing translation metrics as they are not differentiable in nature.", "labels": [], "entities": []}, {"text": "On the other hand, Armijo algorithm usually performs line search efficiently given a searching direction.", "labels": [], "entities": []}, {"text": "It is a deep hidden fact that an efficient line search method will change the iterations of simplex, and hence the searching trajectories.", "labels": [], "entities": []}, {"text": "We propose to embed the Armijo inexact line search within the simplex-downhill algorithm.", "labels": [], "entities": []}, {"text": "We show, in our experiments, the proposed algorithm improves over the widely-applied Minimum Error Rate training algorithm for optimizing machine translation parameters.", "labels": [], "entities": []}], "introductionContent": [{"text": "A simple log-linear form is used in SMT systems to combine feature functions designed for identifying good translations, with proper weights.", "labels": [], "entities": [{"text": "SMT", "start_pos": 36, "end_pos": 39, "type": "TASK", "confidence": 0.9962485432624817}]}, {"text": "However, we often observe that tuning the weight associated with each feature function is indeed not easy.", "labels": [], "entities": []}, {"text": "Starting from a N-Best list generated from a translation decoder, an optimizer, such as Minimum Error Rate (MER) training, proposes directions to search fora better weight-vector \u03bb to combine feature functions.", "labels": [], "entities": [{"text": "Minimum Error Rate (MER", "start_pos": 88, "end_pos": 111, "type": "METRIC", "confidence": 0.8230468511581421}]}, {"text": "With a given \u03bb, the N-Best list is re-ranked, and newly selected top-1 hypothesis will be used to compute the final MT evaluation metric score.", "labels": [], "entities": [{"text": "MT evaluation", "start_pos": 116, "end_pos": 129, "type": "TASK", "confidence": 0.855606198310852}]}, {"text": "Due to limited variations in the N-Best list, the nature of ranking, and more importantly, the non-differentiable objective functions used for MT (such as BLEU ()), one often found only local optimal solutions to \u03bb, with no clue to walkout of the riddles.", "labels": [], "entities": [{"text": "MT", "start_pos": 143, "end_pos": 145, "type": "TASK", "confidence": 0.986289918422699}, {"text": "BLEU", "start_pos": 155, "end_pos": 159, "type": "METRIC", "confidence": 0.9978320002555847}]}, {"text": "Automatic evaluation metrics of translations known so far are designed to simulate human judgments of translation qualities especially in the aspects of fluency and adequacy; they are not differentiable in nature.", "labels": [], "entities": []}, {"text": "Simplexdownhill algorithm does not require the objective function to be differentiable, and this is well-suited for optimizing such automatic metrics.", "labels": [], "entities": []}, {"text": "MER searches each dimension independently in a greedy fashion, while simplex algorithms consider the movement of all the dimensions at the same time via three basic operations: reflection, expansion and contraction, to shrink the simplex iteratively to some local optimal.", "labels": [], "entities": []}, {"text": "Practically, as also shown in our experiments, we observe simplex-downhill usually gives better solutions over MER with random restarts for both, and reaches the solutions much faster inmost of the cases.", "labels": [], "entities": [{"text": "MER", "start_pos": 111, "end_pos": 114, "type": "METRIC", "confidence": 0.9451174139976501}]}, {"text": "However, simplex-downhill algorithm is an unconstrained algorithm, which does not leverage any domain knowledge in machine translation.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 115, "end_pos": 134, "type": "TASK", "confidence": 0.7129675000905991}]}, {"text": "Indeed, the objective function used in SMT is shown to be a piece-wise linear problem in (, and this motivated us to embed an inexact line search with Armijo rules within a simplex to guide the directions for iterative expansion, reflection and contraction operations.", "labels": [], "entities": [{"text": "SMT", "start_pos": 39, "end_pos": 42, "type": "TASK", "confidence": 0.993722140789032}]}, {"text": "Our proposed modification to the simplex algorithm is an embedded backtracking line search, and the algorithm's convergence) still holds, though it is configured specially here for optimizing automatic machine translation evaluation metrics.", "labels": [], "entities": [{"text": "convergence", "start_pos": 112, "end_pos": 123, "type": "METRIC", "confidence": 0.9448282718658447}, {"text": "machine translation evaluation", "start_pos": 202, "end_pos": 232, "type": "TASK", "confidence": 0.7715636193752289}]}, {"text": "The remainder of the paper is structured as follow: we briefly introduce the optimization problem in section 2; in section 3, our proposed simplex Armijo downhill algorithm is explained in details; experiments comparing relevant algorithms are in section 4; the conclusions and discussions are given in section 5.", "labels": [], "entities": []}], "datasetContent": [{"text": "Our experiments were carried out on Chinese-English using our syntax-based decoder (), a chart-based decoder with tree-to-string 3 grammar, in GALE P3/P3.5 evaluations.", "labels": [], "entities": []}, {"text": "There were 10 feature functions computed for each hypothesis, and N-best list size is up to 2,000 per sentence.", "labels": [], "entities": []}, {"text": "Given a weight-vector \u00af \u03bb 0 , our decoder outputs N-Best unique hypotheses for each input source sentence; the event space is then built, and the optimizer is called with a number of random restarts.", "labels": [], "entities": []}, {"text": "We used 164 seeds 4 with a small perturbation of three random dimensions in \u00af \u03bb 0 . The best \u00af \u03bb 1 is selected under a given optimizing metric, and is fed back to the decoder to re-generate anew N-Best list.", "labels": [], "entities": []}, {"text": "Event space is enriched by merging the newly generated N-Best list, and the optimization runs again.", "labels": [], "entities": []}, {"text": "This process is iteratively carried out until there are no more improvements observed on a development data set.", "labels": [], "entities": []}, {"text": "We select three different metrics: NIST BLEU, IBM BLEU, TER, and a combination of (TER-NISTBLEU)/2 as our optimization goal.", "labels": [], "entities": [{"text": "NIST", "start_pos": 35, "end_pos": 39, "type": "DATASET", "confidence": 0.6059029698371887}, {"text": "BLEU", "start_pos": 40, "end_pos": 44, "type": "METRIC", "confidence": 0.8692950010299683}, {"text": "IBM", "start_pos": 46, "end_pos": 49, "type": "METRIC", "confidence": 0.8198170065879822}, {"text": "BLEU", "start_pos": 50, "end_pos": 54, "type": "METRIC", "confidence": 0.5631517767906189}, {"text": "TER", "start_pos": 56, "end_pos": 59, "type": "METRIC", "confidence": 0.9922558069229126}]}, {"text": "On the devset with four references using MT06-NIST text part data, we carried out the optimizations as shown in.", "labels": [], "entities": [{"text": "MT06-NIST text part data", "start_pos": 41, "end_pos": 65, "type": "DATASET", "confidence": 0.8913794904947281}]}, {"text": "Over these 164 random restarts in each of the optimizers over the four configurations shown in, we found most of the time simplex algorithms perform better than MER in these configurations.", "labels": [], "entities": [{"text": "MER", "start_pos": 161, "end_pos": 164, "type": "METRIC", "confidence": 0.8080887794494629}]}, {"text": "Simplex algorithm considers to move all the dimensions at the same time, instead of fixing other dimensions and carrying out a greedy search for one dimension as in MER.", "labels": [], "entities": [{"text": "MER", "start_pos": 165, "end_pos": 168, "type": "DATASET", "confidence": 0.7610843777656555}]}, {"text": "With Armijo line search embedded in the simplex-downhill algorithm, the algorithm has a better chance to walkout of the local optimal, via changing the shrinking trajectory of the simplex using a line search to identify the best steps to move.", "labels": [], "entities": []}, {"text": "Shown in, the solutions from simplex Armijo downhill outperformed the other two under four different optimization metrics for most of the time.", "labels": [], "entities": []}, {"text": "Empirically, we found optimizing toward (TER-NISTBLEU)/2 gives marginally better results on final TER and IBM BLEU.", "labels": [], "entities": [{"text": "TER-NISTBLEU", "start_pos": 41, "end_pos": 53, "type": "METRIC", "confidence": 0.8691728711128235}, {"text": "IBM", "start_pos": 106, "end_pos": 109, "type": "DATASET", "confidence": 0.6009431481361389}, {"text": "BLEU", "start_pos": 110, "end_pos": 114, "type": "METRIC", "confidence": 0.923687756061554}]}, {"text": "On our devset, we also observed that whenever optimizing toward TER (or mixture of TER & BLEU), MER does not seem to move much, as shown in-(a) and.", "labels": [], "entities": [{"text": "TER", "start_pos": 64, "end_pos": 67, "type": "METRIC", "confidence": 0.9908285140991211}, {"text": "BLEU", "start_pos": 89, "end_pos": 93, "type": "METRIC", "confidence": 0.7893512845039368}, {"text": "MER", "start_pos": 96, "end_pos": 99, "type": "METRIC", "confidence": 0.9427885413169861}]}, {"text": "However, on BLEU (NIST or IBM version), MER does move reasonably with random restarts.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 12, "end_pos": 16, "type": "METRIC", "confidence": 0.9416561126708984}, {"text": "NIST", "start_pos": 18, "end_pos": 22, "type": "DATASET", "confidence": 0.9221773147583008}, {"text": "MER", "start_pos": 40, "end_pos": 43, "type": "METRIC", "confidence": 0.5923933386802673}]}, {"text": "Comparing TER with BLEU, we think the \"shift\" counter in TER is a confusing factor to the optimizer, and cannot be computed accurately in the current TER implementations.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 19, "end_pos": 23, "type": "METRIC", "confidence": 0.9985950589179993}]}, {"text": "Also, our random perturbations to the seeds used in restarts might be relatively weaker for MER comparing to our simplex algorithms, though they use exactly the same random seeds.", "labels": [], "entities": [{"text": "MER", "start_pos": 92, "end_pos": 95, "type": "TASK", "confidence": 0.4930768609046936}]}, {"text": "Another fact we found is optimizing toward corpus-level (TER-NISTBLEU)/2 seems to give better performances on most of our unseen datasets, and we choose this as optimization goal to illustrate the algorithms' performances on our unseen testset.", "labels": [], "entities": [{"text": "TER-NISTBLEU)/2", "start_pos": 57, "end_pos": 72, "type": "METRIC", "confidence": 0.9391487240791321}]}, {"text": "Our test set is the held-out speech part data . We optimize toward corpus-level (TER-NISTBLEU)/2 using devset, and apply the weight-vector on testset to evaluate TER, IBMBLEUr4n4, and a simple combination of (TER-IBMBLEU)/2.0 to compare different algorithms' strengths 6 . Shown in, simplex Armijo downhill performs the best (though not statistically significant), and the improvements are consistent in multiple runs in our observations.", "labels": [], "entities": [{"text": "TER", "start_pos": 162, "end_pos": 165, "type": "METRIC", "confidence": 0.9926854372024536}, {"text": "IBMBLEUr4n4", "start_pos": 167, "end_pos": 178, "type": "METRIC", "confidence": 0.802744448184967}]}, {"text": "Also, given limited resources, such as number of machines and fixed time schedule, both simplex algorithms can run with more random restarts than MER, and can potentially reach better solutions.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Comparing different optimization algorithms on the held-out speech data, measured on document-average TER, IBMBLEU  and (TER-IBMBLEU)/2.0, which were used in GALE P3/3.5 Chinese-English evaluations in Rosetta consortium.", "labels": [], "entities": [{"text": "TER", "start_pos": 112, "end_pos": 115, "type": "METRIC", "confidence": 0.7718014717102051}, {"text": "IBMBLEU", "start_pos": 117, "end_pos": 124, "type": "METRIC", "confidence": 0.819612979888916}, {"text": "GALE P3/3.5 Chinese-English evaluations in Rosetta consortium", "start_pos": 168, "end_pos": 229, "type": "DATASET", "confidence": 0.7515519857406616}]}]}