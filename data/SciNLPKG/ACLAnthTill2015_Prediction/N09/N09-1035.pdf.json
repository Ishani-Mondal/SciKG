{"title": [], "abstractContent": [{"text": "Syllables play an important role in speech synthesis and recognition.", "labels": [], "entities": [{"text": "speech synthesis", "start_pos": 36, "end_pos": 52, "type": "TASK", "confidence": 0.790818452835083}]}, {"text": "We present several different approaches to the syllabifica-tion of phonemes.", "labels": [], "entities": []}, {"text": "We investigate approaches based on linguistic theories of syllabification, as well as a discriminative learning technique that combines Support Vector Machine and Hidden Markov Model technologies.", "labels": [], "entities": []}, {"text": "Our experiments on English, Dutch and German demonstrate that our transparent implementation of the sonority sequencing principle is more accurate than previous implementations , and that our language-independent SVM-based approach advances the current state-of-the-art, achieving word accuracy of over 98% in English and 99% in German and Dutch.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 286, "end_pos": 294, "type": "METRIC", "confidence": 0.8388618230819702}]}], "introductionContent": [{"text": "Syllabification is the process of dividing a word into its constituent syllables.", "labels": [], "entities": []}, {"text": "Although some work has been done on syllabifying orthographic forms (, syllables are, technically speaking, phonological entities that can only be composed of strings of phonemes.", "labels": [], "entities": []}, {"text": "Most linguists view syllables as an important unit of prosody because many phonological rules and constraints apply within syllables or at syllable boundaries.", "labels": [], "entities": []}, {"text": "Apart from their purely linguistic significance, syllables play an important role in speech synthesis and recognition).", "labels": [], "entities": [{"text": "speech synthesis", "start_pos": 85, "end_pos": 101, "type": "TASK", "confidence": 0.7312324345111847}]}, {"text": "The pronunciation of a given phoneme tends to vary depending on its location within a syllable.", "labels": [], "entities": []}, {"text": "While actual implementations vary, text-tospeech (TTS) systems must have, at minimum, three components): a letter-to-phoneme (L2P) module, a prosody module, and a synthesis module.", "labels": [], "entities": []}, {"text": "Syllabification can play a role in all three modules.", "labels": [], "entities": []}, {"text": "Because of the productive nature of language, a dictionary look-up process for syllabification is inadequate.", "labels": [], "entities": []}, {"text": "No dictionary can ever contain all possible words in a language.", "labels": [], "entities": []}, {"text": "For this reason, it is necessary to develop systems that can automatically syllabify out-of-dictionary words.", "labels": [], "entities": []}, {"text": "In this paper, we advance the state-of-the-art in both categorical (non-statistical) and supervised syllabification.", "labels": [], "entities": []}, {"text": "We outline three categorical approaches based on common linguistic theories of syllabification.", "labels": [], "entities": []}, {"text": "We demonstrate that when implemented carefully, such approaches can be very effective, approaching supervised performance.", "labels": [], "entities": []}, {"text": "We also present a data-driven, discriminative solution: a Support Vector Machine Hidden Markov Model (SVM-HMM), which tags each phoneme with its syllabic role.", "labels": [], "entities": []}, {"text": "Given enough data, the SVM-HMM achieves impressive accuracy thanks to its ability to capture context-dependent generalizations, while also memorizing inevitable exceptions.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 51, "end_pos": 59, "type": "METRIC", "confidence": 0.9989219903945923}]}, {"text": "Our experiments on English, Dutch and German demonstrate that our SVM-HMM approach substantially outperforms the existing state-of-the-art learning approaches.", "labels": [], "entities": []}, {"text": "Although direct comparisons are difficult, our system achieves over 99% word accuracy on German and Dutch, and the highest reported accuracy on English.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 77, "end_pos": 85, "type": "METRIC", "confidence": 0.9289065003395081}, {"text": "accuracy", "start_pos": 132, "end_pos": 140, "type": "METRIC", "confidence": 0.9725885391235352}]}, {"text": "The paper is organized as follows.", "labels": [], "entities": []}, {"text": "We outline common linguistic theories of syllabification in Section 2, and we survey previous computational sys-tems in Section 3.", "labels": [], "entities": []}, {"text": "Our linguistically-motivated approaches are described in Section 4.", "labels": [], "entities": []}, {"text": "In Section 5, we describe our system based on the SVM-HMM.", "labels": [], "entities": [{"text": "SVM-HMM", "start_pos": 50, "end_pos": 57, "type": "DATASET", "confidence": 0.9222794771194458}]}, {"text": "The experimental results are presented in Section 6.", "labels": [], "entities": []}], "datasetContent": [{"text": "We developed our approach using the English portion of the CELEX lexical database (.", "labels": [], "entities": [{"text": "CELEX lexical database", "start_pos": 59, "end_pos": 81, "type": "DATASET", "confidence": 0.964272658030192}]}, {"text": "CELEX provides the phonemes of a word and its correct syllabification.", "labels": [], "entities": [{"text": "CELEX", "start_pos": 0, "end_pos": 5, "type": "DATASET", "confidence": 0.9660685658454895}]}, {"text": "It does not designate the phonemes as onsets, nuclei, or codas, which is the labeling we want to predict.", "labels": [], "entities": []}, {"text": "Fortunately, extracting the labels from a syllabified word is straightforward.", "labels": [], "entities": []}, {"text": "All vowel phones are assigned to be nuclei; consonants preceding the nucleus in a syllable are assigned to be onsets, while consonants following the nucleus in a syllable are assigned to be codas.", "labels": [], "entities": []}, {"text": "The results in were obtained on a test set of 5K randomly selected words.", "labels": [], "entities": []}, {"text": "For training the SVM-HMM, we randomly selected 30K words not appearing in the test set, while 6K training examples were held out for development testing.", "labels": [], "entities": []}, {"text": "We report the performance in terms of word accuracy (entire words syllabified correctly).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 43, "end_pos": 51, "type": "METRIC", "confidence": 0.8514631390571594}]}, {"text": "Among the categorical approaches, SONORITY clearly outperforms not only LEGALITY, but also tsylb, an implementation of the complex algorithm of, which makes use of lists of legal English onsets.", "labels": [], "entities": []}, {"text": "Overall, our SVM-based approach is a clear winner.", "labels": [], "entities": []}, {"text": "The results of our discriminative method compares favorably with the results of competing approaches on English CELEX.", "labels": [], "entities": [{"text": "English CELEX", "start_pos": 104, "end_pos": 117, "type": "DATASET", "confidence": 0.8669643700122833}]}, {"text": "Since there are no standard train-test splits for syllabification, the comparison is necessarily indirect, but note that our training set is substantially smaller.", "labels": [], "entities": []}, {"text": "For her language-independent PCFG-based approach, M\u00fcller (2006) reports 92.64% word accuracy on the set of 64K examples from CELEX using 10-fold cross-validation.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 84, "end_pos": 92, "type": "METRIC", "confidence": 0.8969276547431946}, {"text": "CELEX", "start_pos": 125, "end_pos": 130, "type": "DATASET", "confidence": 0.9054430723190308}]}, {"text": "The Learned EBG approach of van den Bosch (1997) achieves 97.78% word accuracy when training on approximately 60K examples.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 70, "end_pos": 78, "type": "METRIC", "confidence": 0.9355344176292419}]}, {"text": "Therefore, our results represent a nearly 50% reduction of the error rate.", "labels": [], "entities": [{"text": "error rate", "start_pos": 63, "end_pos": 73, "type": "METRIC", "confidence": 0.9848105013370514}]}, {"text": "Though the SVM-HMM's training data requirements are lower than previous supervised syllabification approaches, they are still substantial.", "labels": [], "entities": []}, {"text": "shows a learning curve over varying amounts of training data.", "labels": [], "entities": []}, {"text": "Performance does not reach acceptable levels until 5K training examples are provided.", "labels": [], "entities": []}, {"text": "Marchand et al. report a disappointing word accuracy of 54.14% for their legality-based implementation, which does not accord with the results of our categorical approaches on English CELEX.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 44, "end_pos": 52, "type": "METRIC", "confidence": 0.8763103485107422}, {"text": "English CELEX", "start_pos": 176, "end_pos": 189, "type": "DATASET", "confidence": 0.8135048747062683}]}, {"text": "Consequently, we also apply our methods to the dataset they used for their experiments: the NETtalk dictionary.", "labels": [], "entities": [{"text": "NETtalk dictionary", "start_pos": 92, "end_pos": 110, "type": "DATASET", "confidence": 0.8180060088634491}]}, {"text": "NETtalk contains 20K English words; in the experiments reported here, we use 13K training examples and 7K test words.", "labels": [], "entities": [{"text": "NETtalk", "start_pos": 0, "end_pos": 7, "type": "DATASET", "confidence": 0.8630428314208984}]}, {"text": "As is apparent from, our performance degrades significantly when switching to NETtalk.", "labels": [], "entities": []}, {"text": "The steep decline found in the categorical methods is particularly notable, and indicates significant divergence between the syllabifications employed in the two datasets.", "labels": [], "entities": []}, {"text": "Phonologists do not always agree on the correct syllable breaks fora word, but the NETtalk syllabifications are often at odds with linguistic intuitions.", "labels": [], "entities": []}, {"text": "We randomly selected 50 words and compared their syllabifications against those found in Merriam-Webster Online.", "labels": [], "entities": [{"text": "Merriam-Webster Online", "start_pos": 89, "end_pos": 111, "type": "DATASET", "confidence": 0.9608764946460724}]}, {"text": "We found that CELEX syllabifications agree with MerriamWebster in 84% of cases, while NETtalk only agrees 52% of the time.", "labels": [], "entities": [{"text": "MerriamWebster", "start_pos": 48, "end_pos": 62, "type": "DATASET", "confidence": 0.9072487354278564}]}, {"text": "shows several words from the NETtalk  and CELEX datasets.", "labels": [], "entities": [{"text": "NETtalk", "start_pos": 29, "end_pos": 36, "type": "DATASET", "confidence": 0.9209118485450745}, {"text": "CELEX datasets", "start_pos": 42, "end_pos": 56, "type": "DATASET", "confidence": 0.9235585629940033}]}, {"text": "We see that CELEX follows the maximal onset principle consistently, while NETtalk does in some instances but not others.", "labels": [], "entities": [{"text": "CELEX", "start_pos": 12, "end_pos": 17, "type": "DATASET", "confidence": 0.8261114358901978}, {"text": "maximal onset", "start_pos": 30, "end_pos": 43, "type": "METRIC", "confidence": 0.8034232258796692}]}, {"text": "We also note that there area number of NETtalk syllabifications that are clearly wrong, such as the last two examples in.", "labels": [], "entities": []}, {"text": "The variability of NETtalk is much more difficult to capture with any kind of principled approach.", "labels": [], "entities": []}, {"text": "Thus, we argue that low performance on NETtalk indicate inconsistent syllabifications within that dataset, rather than any actual deficiency of the methods.", "labels": [], "entities": []}, {"text": "NETtalk's variable syllabification practices notwithstanding, the SVM-HMM approach still outperforms the previous benchmark on the dataset.", "labels": [], "entities": [{"text": "NETtalk", "start_pos": 0, "end_pos": 7, "type": "DATASET", "confidence": 0.9054614901542664}]}, {"text": "report 88.53% word accuracy for their SbA technique using leave-one-out testing on the entire NETtalk set (20K words).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 19, "end_pos": 27, "type": "METRIC", "confidence": 0.9520323276519775}, {"text": "NETtalk set", "start_pos": 94, "end_pos": 105, "type": "DATASET", "confidence": 0.9124472737312317}]}, {"text": "With fewer training examples, we reduce the error rate by almost 40%.", "labels": [], "entities": [{"text": "error rate", "start_pos": 44, "end_pos": 54, "type": "METRIC", "confidence": 0.9919048547744751}]}], "tableCaptions": [{"text": " Table 1: Word accuracy on the CELEX dataset.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 15, "end_pos": 23, "type": "METRIC", "confidence": 0.9627470970153809}, {"text": "CELEX dataset", "start_pos": 31, "end_pos": 44, "type": "DATASET", "confidence": 0.9881970882415771}]}, {"text": " Table 2: Word accuracy on the NETtalk dataset.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 15, "end_pos": 23, "type": "METRIC", "confidence": 0.9537620544433594}, {"text": "NETtalk dataset", "start_pos": 31, "end_pos": 46, "type": "DATASET", "confidence": 0.9664756059646606}]}, {"text": " Table 3: Word accuracy on the CELEX dataset.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 15, "end_pos": 23, "type": "METRIC", "confidence": 0.9622753262519836}, {"text": "CELEX dataset", "start_pos": 31, "end_pos": 44, "type": "DATASET", "confidence": 0.988463431596756}]}, {"text": " Table 4: Word accuracy on the datasets of Goldwater and  Johnson (2005).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 15, "end_pos": 23, "type": "METRIC", "confidence": 0.9512855410575867}]}]}