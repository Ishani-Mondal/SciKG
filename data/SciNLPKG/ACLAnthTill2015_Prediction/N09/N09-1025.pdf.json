{"title": [], "abstractContent": [{"text": "We use the Margin Infused Relaxed Algorithm of Crammer et al. to add a large number of new features to two machine translation systems: the Hiero hierarchical phrase-based translation system and our syntax-based translation system.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 107, "end_pos": 126, "type": "TASK", "confidence": 0.7379105091094971}, {"text": "Hiero hierarchical phrase-based translation", "start_pos": 140, "end_pos": 183, "type": "TASK", "confidence": 0.5805264040827751}]}, {"text": "On a large-scale Chinese-English translation task, we obtain statistically significant improvements of +1.5 B\uf76c\uf765\uf775 and +1.1 B\uf76c\uf765\uf775, respectively.", "labels": [], "entities": [{"text": "Chinese-English translation task", "start_pos": 17, "end_pos": 49, "type": "TASK", "confidence": 0.6783996323744456}, {"text": "B", "start_pos": 108, "end_pos": 109, "type": "METRIC", "confidence": 0.9865525364875793}, {"text": "B", "start_pos": 122, "end_pos": 123, "type": "METRIC", "confidence": 0.8848444223403931}]}, {"text": "We analyze the impact of the new features and the performance of the learning algorithm.", "labels": [], "entities": []}], "introductionContent": [{"text": "What linguistic features can improve statistical machine translation (MT)?", "labels": [], "entities": [{"text": "statistical machine translation (MT)", "start_pos": 37, "end_pos": 73, "type": "TASK", "confidence": 0.8146330018838247}]}, {"text": "This is a fundamental question for the discipline, particularly as it pertains to improving the best systems we have.", "labels": [], "entities": []}, {"text": "Further: \u2022 Do syntax-based translation systems have unique and effective levers to pull when designing new features?", "labels": [], "entities": []}, {"text": "\u2022 Can large numbers of feature weights be learned efficiently and stably on modest amounts of data?", "labels": [], "entities": []}, {"text": "In this paper, we address these questions by experimenting with a large number of new features.", "labels": [], "entities": []}, {"text": "We add more than 250 features to improve a syntaxbased MT system-already the highest-scoring single system in the NIST 2008 Chinese-English common-data track-by +1.1 B\uf76c\uf765\uf775.", "labels": [], "entities": [{"text": "MT", "start_pos": 55, "end_pos": 57, "type": "TASK", "confidence": 0.9092294573783875}, {"text": "NIST 2008 Chinese-English common-data track-by +1.1", "start_pos": 114, "end_pos": 165, "type": "DATASET", "confidence": 0.9322956715311322}, {"text": "B", "start_pos": 166, "end_pos": 167, "type": "METRIC", "confidence": 0.6071242690086365}]}, {"text": "We also add more than 10,000 features to Hiero and obtain a +1.5 B\uf76c\uf765\uf775 improvement.", "labels": [], "entities": [{"text": "Hiero", "start_pos": 41, "end_pos": 46, "type": "DATASET", "confidence": 0.9114840030670166}, {"text": "B", "start_pos": 65, "end_pos": 66, "type": "METRIC", "confidence": 0.9736371040344238}]}, {"text": "* This research was supported in part by DARPA contract HR0011-06-C-0022 under subcontract to BBN Technologies.", "labels": [], "entities": [{"text": "DARPA contract HR0011-06-C-0022", "start_pos": 41, "end_pos": 72, "type": "DATASET", "confidence": 0.6395649711290995}, {"text": "BBN Technologies", "start_pos": 94, "end_pos": 110, "type": "DATASET", "confidence": 0.9554433524608612}]}, {"text": "Many of the new features use syntactic information, and in particular depend on information that is available only inside a syntax-based translation model.", "labels": [], "entities": []}, {"text": "Thus they widen the advantage that syntaxbased models have over other types of models.", "labels": [], "entities": []}, {"text": "The models are trained using the Margin Infused Relaxed Algorithm or MIRA () instead of the standard minimum-error-rate training or MERT algorithm.", "labels": [], "entities": [{"text": "Margin Infused Relaxed Algorithm", "start_pos": 33, "end_pos": 65, "type": "METRIC", "confidence": 0.6184474155306816}, {"text": "MIRA", "start_pos": 69, "end_pos": 73, "type": "METRIC", "confidence": 0.9168867468833923}]}, {"text": "Our results add to a growing body of evidence () that MIRA is preferable to MERT across languages and systems, even for very large-scale tasks.", "labels": [], "entities": [{"text": "MIRA", "start_pos": 54, "end_pos": 58, "type": "TASK", "confidence": 0.5900763273239136}, {"text": "MERT", "start_pos": 76, "end_pos": 80, "type": "TASK", "confidence": 0.9225348234176636}]}], "datasetContent": [{"text": "For our experiments, we used a 260 million word Chinese/English bitext.", "labels": [], "entities": []}, {"text": "We ran GIZA++ on the entire bitext to produce IBM Model 4 word alignments, and then the link deletion algorithm  the syntax-based system, we ran a reimplementation of the Collins parser (Collins, 1997) on the English half of the bitext to produce parse trees, then restructured and relabeled them as described in Section 3.2.", "labels": [], "entities": [{"text": "IBM Model 4 word alignments", "start_pos": 46, "end_pos": 73, "type": "TASK", "confidence": 0.6703096628189087}, {"text": "Collins parser (Collins, 1997)", "start_pos": 171, "end_pos": 201, "type": "DATASET", "confidence": 0.8839714697429112}]}, {"text": "Syntax-based rule extraction was performed on a 65 million word subset of the training data.", "labels": [], "entities": [{"text": "rule extraction", "start_pos": 13, "end_pos": 28, "type": "TASK", "confidence": 0.7135883718729019}]}, {"text": "For Hiero, rules with up to two nonterminals were extracted from a 38 million word subset and phrasal rules were extracted from the remainder of the training data.", "labels": [], "entities": [{"text": "Hiero", "start_pos": 4, "end_pos": 9, "type": "TASK", "confidence": 0.7444702386856079}]}, {"text": "We trained three 5-gram language models: one on the English half of the bitext, used by both systems, one on one billion words of English, used by the syntax-based system, and one on two billion words of English, used by Hiero.", "labels": [], "entities": [{"text": "Hiero", "start_pos": 221, "end_pos": 226, "type": "DATASET", "confidence": 0.8885297179222107}]}, {"text": "Modified Kneser-Ney smoothing) was applied to all language models.", "labels": [], "entities": []}, {"text": "The language models are represented using randomized data structures similar to those of.", "labels": [], "entities": []}, {"text": "Our tuning set (2010 sentences) and test set (1994 sentences) were drawn from newswire data from the NIST 2004 and 2005 evaluations and the GALE program (with no overlap at either the segment or document level).", "labels": [], "entities": [{"text": "NIST 2004 and 2005 evaluations", "start_pos": 101, "end_pos": 131, "type": "DATASET", "confidence": 0.8820899486541748}, {"text": "GALE program", "start_pos": 140, "end_pos": 152, "type": "DATASET", "confidence": 0.8223444223403931}]}, {"text": "For the source-side syntax features, we used the Berkeley parser () to parse the Chinese side of both sets.", "labels": [], "entities": []}, {"text": "We implemented the source-side context features for Hiero and the target-side syntax features for the syntax-based system, and the discount features for both.", "labels": [], "entities": [{"text": "Hiero", "start_pos": 52, "end_pos": 57, "type": "DATASET", "confidence": 0.9431148767471313}]}, {"text": "We then ran MIRA on the tuning set with 20 parallel learners for Hiero and 73 parallel learners for the syntax-based system.", "labels": [], "entities": [{"text": "MIRA", "start_pos": 12, "end_pos": 16, "type": "METRIC", "confidence": 0.6756398677825928}, {"text": "Hiero", "start_pos": 65, "end_pos": 70, "type": "DATASET", "confidence": 0.9310654997825623}]}, {"text": "We chose a stopping iteration based on the B\uf76c\uf765\uf775 score on the tuning set, and used the averaged feature weights from all iter-  ations of all learners to decode the test set.", "labels": [], "entities": [{"text": "B\uf76c\uf765\uf775 score", "start_pos": 43, "end_pos": 53, "type": "METRIC", "confidence": 0.9613649050394694}]}, {"text": "The results show significant improvements in both systems (p < 0.01) over already very strong MERT baselines.", "labels": [], "entities": [{"text": "MERT", "start_pos": 94, "end_pos": 98, "type": "TASK", "confidence": 0.773193895816803}]}, {"text": "Adding the source-side and discount features to Hiero yields a +1.5 B\uf76c\uf765\uf775 improvement, and adding the target-side syntax and discount features to the syntax-based system yields a +1.1 B\uf76c\uf765\uf775 improvement.", "labels": [], "entities": [{"text": "Hiero", "start_pos": 48, "end_pos": 53, "type": "DATASET", "confidence": 0.9110313653945923}, {"text": "B", "start_pos": 68, "end_pos": 69, "type": "METRIC", "confidence": 0.9914074540138245}, {"text": "B", "start_pos": 183, "end_pos": 184, "type": "METRIC", "confidence": 0.9934375882148743}]}, {"text": "The results also show that for Hiero, the various classes of features contributed roughly equally; for the syntax-based system, we see that two of the feature classes make small contributions but time constraints unfortunately did not permit isolated testing of all feature classes.", "labels": [], "entities": [{"text": "Hiero", "start_pos": 31, "end_pos": 36, "type": "DATASET", "confidence": 0.7381791472434998}]}], "tableCaptions": [{"text": " Table 1: Adding new features with MIRA significantly improves translation accuracy. Scores are case-insensitive IBM  B\uf76c\uf765\uf775 scores.  *  or  *  *  = significantly better than MERT baseline (p < 0.05 or 0.01, respectively).", "labels": [], "entities": [{"text": "MIRA", "start_pos": 35, "end_pos": 39, "type": "METRIC", "confidence": 0.4296897053718567}, {"text": "translation", "start_pos": 63, "end_pos": 74, "type": "TASK", "confidence": 0.95420241355896}, {"text": "accuracy", "start_pos": 75, "end_pos": 83, "type": "METRIC", "confidence": 0.8035168051719666}, {"text": "IBM  B\uf76c\uf765\uf775 scores", "start_pos": 113, "end_pos": 129, "type": "METRIC", "confidence": 0.8338987678289413}, {"text": "MERT baseline", "start_pos": 173, "end_pos": 186, "type": "METRIC", "confidence": 0.8385553658008575}]}, {"text": " Table 2: Weights learned for discount features. Nega- tive weights indicate bonuses; positive weights indicate  penalties.", "labels": [], "entities": [{"text": "Nega- tive weights", "start_pos": 49, "end_pos": 67, "type": "METRIC", "confidence": 0.9239316135644913}]}]}