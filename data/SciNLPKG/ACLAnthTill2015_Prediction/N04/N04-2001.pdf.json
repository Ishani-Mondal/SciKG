{"title": [{"text": "Multilingual Speech Recognition for Information Retrieval in Indian context", "labels": [], "entities": [{"text": "Multilingual Speech Recognition", "start_pos": 0, "end_pos": 31, "type": "TASK", "confidence": 0.7305376529693604}, {"text": "Information Retrieval", "start_pos": 36, "end_pos": 57, "type": "TASK", "confidence": 0.7172844409942627}]}], "abstractContent": [{"text": "This paper analyzes various issues in building a HMM based multilingual speech recognizer for Indian languages.", "labels": [], "entities": [{"text": "multilingual speech recognizer", "start_pos": 59, "end_pos": 89, "type": "TASK", "confidence": 0.6473155617713928}]}, {"text": "The system is originally designed for Hindi and Tamil languages and adapted to incorporate Indian accented Eng-lish.", "labels": [], "entities": []}, {"text": "Language-specific characteristics in speech recognition framework are highlighted.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 37, "end_pos": 55, "type": "TASK", "confidence": 0.7651689052581787}]}, {"text": "The recognizer is embedded in information retrieval applications and hence several issues like handling spontaneous telephony speech in real-time, integrated language identification for interactive response and automatic graph-eme to phoneme conversion to handle Out Of Vocabulary words are addressed.", "labels": [], "entities": [{"text": "information retrieval", "start_pos": 30, "end_pos": 51, "type": "TASK", "confidence": 0.7305018901824951}, {"text": "language identification", "start_pos": 158, "end_pos": 181, "type": "TASK", "confidence": 0.7322008907794952}]}, {"text": "Experiments to study relative effectiveness of different algorithms have been performed and the results are investigated.", "labels": [], "entities": []}], "introductionContent": [{"text": "Human preference for speech communication has led to the growth of spoken language systems for information exchange.", "labels": [], "entities": [{"text": "information exchange", "start_pos": 95, "end_pos": 115, "type": "TASK", "confidence": 0.7850245237350464}]}, {"text": "Such systems need a robust and versatile speech recognizer at its front-end, capable of decoding the speech utterances.", "labels": [], "entities": []}, {"text": "A recognizer developed for spoken language information retrieval in Indian languages should have the following features: \ud97b\udf59\ud97b\udf59 It must be insensitive to spontaneous speech effects and telephone channel noise.", "labels": [], "entities": [{"text": "spoken language information retrieval", "start_pos": 27, "end_pos": 64, "type": "TASK", "confidence": 0.6599206030368805}]}, {"text": "\ud97b\udf59\ud97b\udf59 Language Switching is common in India where there is a general familiarity of more than one language.", "labels": [], "entities": [{"text": "\ud97b\udf59\ud97b\udf59 Language Switching", "start_pos": 0, "end_pos": 21, "type": "TASK", "confidence": 0.5278143783410391}]}, {"text": "This demands fora multilingual speech recognition system to decode sentences with words from several languages.", "labels": [], "entities": []}, {"text": "\ud97b\udf59\ud97b\udf59 Integrated language identification should be possible which helps later stages like speech synthesis to interact in user's native language.", "labels": [], "entities": [{"text": "language identification", "start_pos": 14, "end_pos": 37, "type": "TASK", "confidence": 0.739604115486145}, {"text": "speech synthesis", "start_pos": 87, "end_pos": 103, "type": "TASK", "confidence": 0.7230526655912399}]}, {"text": "This paper reports our work in building a multilingual speech recognizer for Tamil, Hindi and accented English.", "labels": [], "entities": [{"text": "multilingual speech recognizer", "start_pos": 42, "end_pos": 72, "type": "TASK", "confidence": 0.6445362468560537}]}, {"text": "To handle sparseness in speech data and linguistic knowledge for Indian languages, we have addressed techniques like cross-lingual bootstrapping, automatic grapheme to phoneme conversion and adaptation of phonetic decision trees.", "labels": [], "entities": [{"text": "phoneme conversion", "start_pos": 168, "end_pos": 186, "type": "TASK", "confidence": 0.7241871654987335}]}, {"text": "In the area of Indian language speech recognition, various issues in building Hindi LVCSR systems have been dealt in.", "labels": [], "entities": [{"text": "Indian language speech recognition", "start_pos": 15, "end_pos": 49, "type": "TASK", "confidence": 0.7541027218103409}]}, {"text": "For Tamil language) attempts to develop a speaker independent recognition system for restricted vocabulary tasks.", "labels": [], "entities": []}, {"text": "Speech recognizer for railway enquiry task in Hindi is developed by.", "labels": [], "entities": [{"text": "Speech recognizer", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.6826429218053818}, {"text": "railway enquiry task", "start_pos": 22, "end_pos": 42, "type": "TASK", "confidence": 0.848674496014913}]}, {"text": "The paper is organized as follows.", "labels": [], "entities": []}, {"text": "In sections 2, 3 and 4 we discuss the steps involved in building a multilingual recognizer for Hindi and Tamil.", "labels": [], "entities": []}, {"text": "In section 5 automatic generation of phonetic baseforms from orthography is explained.", "labels": [], "entities": []}, {"text": "Section 6 presents the results of adapting the system for accented English.", "labels": [], "entities": []}, {"text": "Techniques to incorporate Language Identification are described in Section 7.", "labels": [], "entities": [{"text": "Language Identification", "start_pos": 26, "end_pos": 49, "type": "TASK", "confidence": 0.7294806838035583}]}, {"text": "Finally we conclude with a note on future work in section 8.", "labels": [], "entities": []}], "datasetContent": [{"text": "The baseline system is trained on N_ENG corpus and is used to recognize NN_TAE utterances.", "labels": [], "entities": [{"text": "N_ENG corpus", "start_pos": 34, "end_pos": 46, "type": "DATASET", "confidence": 0.6250973418354988}, {"text": "recognize NN_TAE utterances", "start_pos": 62, "end_pos": 89, "type": "TASK", "confidence": 0.5294069290161133}]}, {"text": "It is a wellknown fact that accented speech is influenced by native language of the speaker.", "labels": [], "entities": []}, {"text": "Hence we tried decoding NN_TAE data using Tamil recognizer.", "labels": [], "entities": [{"text": "NN_TAE data", "start_pos": 24, "end_pos": 35, "type": "DATASET", "confidence": 0.5254182070493698}]}, {"text": "The lexicon is generated using grapheme to phoneme rules.", "labels": [], "entities": []}, {"text": "The accuracy dropped below the baseline, which means that there is no direct relationship between N_TAM and NN_TAE speech.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.9996837377548218}]}, {"text": "The result is already confirmed by (Laura.M..", "labels": [], "entities": [{"text": "Laura.M..", "start_pos": 36, "end_pos": 45, "type": "DATASET", "confidence": 0.9773975610733032}]}, {"text": "Careful analysis of the accented speech shows that perception of the target phone is close to acoustically related phone in speaker's native language.", "labels": [], "entities": []}, {"text": "As speaker gains proficiency, his pronunciation is tuned towards the target phone and hence the influence of interfering phone is less pronounced.", "labels": [], "entities": []}, {"text": "This clearly suggests that any acoustic modeling technique should start with native language models and suitably modify them to handle accented English.", "labels": [], "entities": []}, {"text": "Hence attempts to retrain or adapt N_ENG models using N_TAM data have degraded the accuracy.", "labels": [], "entities": [{"text": "N_TAM data", "start_pos": 54, "end_pos": 64, "type": "DATASET", "confidence": 0.6402788907289505}, {"text": "accuracy", "start_pos": 83, "end_pos": 91, "type": "METRIC", "confidence": 0.9990524649620056}]}, {"text": "First set of experiments is carried out using N_ENG models.", "labels": [], "entities": []}, {"text": "MLLR adaptation and retraining with NN_TAE data increased the accuracy.", "labels": [], "entities": [{"text": "MLLR adaptation", "start_pos": 0, "end_pos": 15, "type": "TASK", "confidence": 0.7340662479400635}, {"text": "NN_TAE data", "start_pos": 36, "end_pos": 47, "type": "DATASET", "confidence": 0.725969523191452}, {"text": "accuracy", "start_pos": 62, "end_pos": 70, "type": "METRIC", "confidence": 0.9990039467811584}]}, {"text": "In the second set of experiments English models are bootstrapped using N_TAM models by heuristic IPA mapping.", "labels": [], "entities": []}, {"text": "They are then trained by pooling N_ENG and NN_TAE data.", "labels": [], "entities": [{"text": "ENG", "start_pos": 35, "end_pos": 38, "type": "METRIC", "confidence": 0.4699496626853943}, {"text": "NN_TAE data", "start_pos": 43, "end_pos": 54, "type": "DATASET", "confidence": 0.5308980122208595}]}, {"text": "This method showed better performance than other approaches.", "labels": [], "entities": []}, {"text": "The comparative results are shown in1.", "labels": [], "entities": []}], "tableCaptions": []}