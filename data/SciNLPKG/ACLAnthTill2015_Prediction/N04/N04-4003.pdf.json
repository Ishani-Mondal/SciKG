{"title": [{"text": "Example-based Rescoring of Statistical Machine Translation Output", "labels": [], "entities": [{"text": "Rescoring of Statistical Machine Translation Output", "start_pos": 14, "end_pos": 65, "type": "TASK", "confidence": 0.8084152738253275}]}], "abstractContent": [{"text": "Conventional statistical machine translation (SMT) approaches might not be able to find a good translation due to problems in its statistical models (due to data sparseness during the estimation of the model parameters) as well as search errors during the decoding process.", "labels": [], "entities": [{"text": "statistical machine translation (SMT)", "start_pos": 13, "end_pos": 50, "type": "TASK", "confidence": 0.8020930141210556}]}, {"text": "This paper 1 presents an example-based rescoring method that validates SMT translation candidates and judges whether the selected decoder output is good or not.", "labels": [], "entities": [{"text": "SMT translation", "start_pos": 71, "end_pos": 86, "type": "TASK", "confidence": 0.9760904610157013}]}, {"text": "Given such a validation filter, defective translations can be rejected.", "labels": [], "entities": []}, {"text": "The experiments show a drastic improvement in the overall system performance compared to translation selection methods based on statistical scores only.", "labels": [], "entities": [{"text": "translation selection", "start_pos": 89, "end_pos": 110, "type": "TASK", "confidence": 0.933599203824997}]}], "introductionContent": [{"text": "The statistical machine translation framework (SMT) formulates the problem of translating a sentence from a source language S into a target language T as the maximization problem of the conditional probability: where p(S|T ) is called a translation model (T M ), representing the generation probability from T into S, p(T ) is called a language model (LM ) and represents the likelihood of the target language ().", "labels": [], "entities": [{"text": "statistical machine translation framework (SMT", "start_pos": 4, "end_pos": 50, "type": "TASK", "confidence": 0.7434351295232773}]}, {"text": "The TM and LM probabilities are trained automatically from a parallel text corpus (parameter estimation).", "labels": [], "entities": []}, {"text": "They represent the general translation knowledge used to map a sequence of words from the source language into the target language.", "labels": [], "entities": []}, {"text": "During the translation process (decoding) a statistical score based on the probabilities of the translation and the language models is assigned to each translation candidate and the one with the highest TM\u00b7LM score is selected as the translation output.", "labels": [], "entities": [{"text": "TM\u00b7LM score", "start_pos": 203, "end_pos": 214, "type": "METRIC", "confidence": 0.9457247853279114}]}, {"text": "However, the system might not be able to find a good translation due to parameter estimation problems of the statistical models (due to data sparseness during the estimation of the model probabilities) and search errors during the translation process.", "labels": [], "entities": []}, {"text": "Moreover, conventional SMT approaches use words as the translation unit.", "labels": [], "entities": [{"text": "SMT", "start_pos": 23, "end_pos": 26, "type": "TASK", "confidence": 0.993463397026062}]}, {"text": "Therefore, the optimization is carried out locally generating the translation word-by-word.", "labels": [], "entities": []}, {"text": "In the framework of example-based machine translation (EBMT), however, a parallel text corpus is used directly to obtain the translation.", "labels": [], "entities": [{"text": "example-based machine translation (EBMT)", "start_pos": 20, "end_pos": 60, "type": "TASK", "confidence": 0.8085455298423767}]}, {"text": "Given an input sentence, translation examples from the corpus that are best matched to the input are retrieved and adjusted to obtain the translation.", "labels": [], "entities": []}, {"text": "Thus the translation unit used in EBMT approaches is a complete sentence, providing a larger context for the generation of an appropriate translation.", "labels": [], "entities": []}, {"text": "However, this approach requires appropriate translation examples to achieve an accurate translation.", "labels": [], "entities": []}, {"text": "A combination of statistical and example-based MT approaches shows some promising perspectives for overcoming the shortcomes of each approach.", "labels": [], "entities": [{"text": "MT", "start_pos": 47, "end_pos": 49, "type": "TASK", "confidence": 0.9543032646179199}]}, {"text": "In this paper, we propose an example-based rescoring method (EBRS) for selecting translation candidates generated by a statistical decoder, as illustrated in.", "labels": [], "entities": []}, {"text": "It retrieves translation examples that are similar to the input from a parallel text corpus (cf. Section 2).", "labels": [], "entities": []}, {"text": "The target parts of these examples (seed) paired with the input form the input of a statistical decoder (cf. Section 3).", "labels": [], "entities": []}, {"text": "The statistical scores of each generated translation candidate are rescored using information about how much the seed sentence is modified during decoding.", "labels": [], "entities": []}, {"text": "It measures the distance between the word sequences of the decoder output and its seed sentence based on the costs of edit distance operations (cf. Section 4).", "labels": [], "entities": []}, {"text": "We combine the distance measure with the statistical scores of the SMT engine, resulting in a reliability measure to identify modeling problems in statistically optimized translation candidates and to reject inappropriate solutions (cf. Section 5).", "labels": [], "entities": [{"text": "SMT", "start_pos": 67, "end_pos": 70, "type": "TASK", "confidence": 0.9933453798294067}]}, {"text": "Translation examples consist of pairs of pre-translated sentences, either by humans (high quality) or automatically using MT systems (reduced quality).", "labels": [], "entities": []}, {"text": "A collection of translation examples can be used directly to obtain a translation of a given input sentence.", "labels": [], "entities": []}, {"text": "The similarity of the input to the source part of the translation examples enables us to identify translation candidates that might be close to the actual translation.", "labels": [], "entities": []}, {"text": "A common approach to measure the distance between sequences of words is the edit distance criteria.", "labels": [], "entities": []}, {"text": "The distance is defined as the sum of the costs of insertion (INS), deletion (DEL), and substitution (SUB) operations required to map one word sequence into the other.", "labels": [], "entities": [{"text": "insertion (INS), deletion (DEL)", "start_pos": 51, "end_pos": 82, "type": "METRIC", "confidence": 0.8107149733437432}]}, {"text": "The edit distance can be calculated by a standard dynamic programming technique.", "labels": [], "entities": []}, {"text": "An extension of the edit-distance-based retrieval method is presented in (.", "labels": [], "entities": []}, {"text": "It incorporates the tf\u00b7idf criteria as seen in the information retrieval framework by treating each translation example as a document.", "labels": [], "entities": []}, {"text": "For each word of the input, its term frequency tf i,j is combined with its document frequency df i into a single weight w i,j , which is used to select the most relevant ones out of N documents (= example targets).", "labels": [], "entities": []}, {"text": "Another possibility for obtaining translation examples is simply to utilize available (off-the-shelf) MT systems by pairing the input sentence with the obtained MT output.", "labels": [], "entities": []}, {"text": "However, the quality of those translation examples might be much lower than manually created translations.) presents a greedy approach to search for the translation that is most likely according to previously learned statitistical models.", "labels": [], "entities": []}, {"text": "An extension of this approach that can take advantage of translation examples provided fora given input sentence is proposed in (.", "labels": [], "entities": []}, {"text": "Instead of decoding and generating an output string word-by-word as is done in the basic concept, this greedy approach slightly modifies the target part of the translation examples so that the pair becomes the actual translation.", "labels": [], "entities": []}], "datasetContent": [{"text": "The evaluation of our approach is carried out using a collection of Japanese sentences and their English translations that are commonly found in phrasebooks for tourists going abroad ().", "labels": [], "entities": []}, {"text": "The Basic Travel Expression Corpus (BTEC) contains 157K sentence pairs and the average lengths in words of Japanese and English sentences are 7.7 and 5.5, respectively.", "labels": [], "entities": [{"text": "Basic Travel Expression Corpus (BTEC)", "start_pos": 4, "end_pos": 41, "type": "DATASET", "confidence": 0.7128852605819702}]}, {"text": "The corpus was split randomly into three parts for training (155K), parameter tuning (10K), and evaluation (10K) purposes.", "labels": [], "entities": []}, {"text": "The experiments described below were carried out on 510 sentences selected randomly as the test set.", "labels": [], "entities": []}, {"text": "For the evaluation, we used the following automatic scoring measures and human assessment.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Downgrading Effects During Decoding", "labels": [], "entities": []}, {"text": " Table 2: MT System Performance", "labels": [], "entities": [{"text": "MT", "start_pos": 10, "end_pos": 12, "type": "TASK", "confidence": 0.9685606360435486}]}, {"text": " Table 3. The baseline system TM\u00b7LM seems to work  best when used in combination with the tf\u00b7idf-based re- trieval method, achieving around 80% translation accu- racy. Moderate improvements of around 2% can be seen  when the proposed rescoring functions are used together  with the seed sentences obtained for the baseline system.", "labels": [], "entities": []}, {"text": " Table 4: Change in Translation Accuracy", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 32, "end_pos": 40, "type": "METRIC", "confidence": 0.9163895845413208}]}]}