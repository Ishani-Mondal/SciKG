{"title": [{"text": "Automatic Tagging of Arabic Text: From Raw Text to Base Phrase Chunks", "labels": [], "entities": [{"text": "Automatic Tagging of Arabic Text", "start_pos": 0, "end_pos": 32, "type": "TASK", "confidence": 0.8093323767185211}]}], "abstractContent": [{"text": "To date, there are no fully automated systems addressing the community's need for fundamental language processing tools for Arabic text.", "labels": [], "entities": []}, {"text": "In this paper, we present a Support Vector Machine (SVM) based approach to automatically tokenize (segmenting off clitics), part-of-speech (POS) tag and annotate base phrases (BPs) in Arabic text.", "labels": [], "entities": []}, {"text": "We adapt highly accurate tools that have been developed for En-glish text and apply them to Arabic text.", "labels": [], "entities": []}, {"text": "Using standard evaluation metrics, we report that the SVM-TOK tokenizer achieves an \u00a1 \u00a3 \u00a2 \u00a5 \u00a4 \u00a3 \u00a6 score of 99.12, the SVM-POS tagger achieves an accuracy of 95.49%, and the SVM-BP chunker yields an \u00a1 \u00a2 \u00a7 \u00a4 \u00a3 \u00a6 score of 92.08.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 145, "end_pos": 153, "type": "METRIC", "confidence": 0.9991683959960938}]}], "introductionContent": [{"text": "Arabic is garnering attention in the NLP community due to its socio-political importance and its linguistic differences from Indo-European languages.", "labels": [], "entities": []}, {"text": "These linguistic characteristics, especially dialect differences and complex morphology present interesting challenges for NLP researchers.", "labels": [], "entities": []}, {"text": "But like most non-European languages, Arabic is lacking in annotated resources and tools.", "labels": [], "entities": []}, {"text": "Fully automated fundamental NLP tools such as Tokenizers, Part Of Speech (POS) Taggers and Base Phrase (BP) Chunkers are still not available for Arabic.", "labels": [], "entities": []}, {"text": "Meanwhile, these tools are readily available and have achieved remarkable accuracy and sophistication for the processing of many European languages.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 74, "end_pos": 82, "type": "METRIC", "confidence": 0.9985380172729492}]}, {"text": "With the release of the Arabic Penn TreeBank 1 (v2.0), 1 the story is about to change.", "labels": [], "entities": [{"text": "Arabic Penn TreeBank 1 (v2.0), 1", "start_pos": 24, "end_pos": 56, "type": "DATASET", "confidence": 0.9445777402983772}]}, {"text": "In this paper, we propose solutions to the problems of Tokenization, POS Tagging and BP Chunking of Arabic text.", "labels": [], "entities": [{"text": "Tokenization", "start_pos": 55, "end_pos": 67, "type": "TASK", "confidence": 0.6717840433120728}, {"text": "POS Tagging", "start_pos": 69, "end_pos": 80, "type": "TASK", "confidence": 0.7524663209915161}, {"text": "BP Chunking of Arabic text", "start_pos": 85, "end_pos": 111, "type": "TASK", "confidence": 0.6967330753803254}]}, {"text": "By Tokenization we mean the process of segmenting clitics from stems, since in Arabic, prepositions, conjunctions, and some pronouns are cliticized (orthographically\u00a8This orthographically\u00a8 orthographically\u00a8This work was partially supported by the National Science Foundation via a KDD Supplement to NSF CISE/IRI/Interactive Systems Award IIS-9978025.", "labels": [], "entities": [{"text": "KDD Supplement to NSF CISE/IRI/Interactive Systems Award IIS-9978025", "start_pos": 281, "end_pos": 349, "type": "TASK", "confidence": 0.5264894366264343}]}, {"text": "1 http://www.ldc.upenn.edu/ and phonological fused) onto stems.", "labels": [], "entities": []}, {"text": "Separating conjunctions from the following noun, for example, is a key first step in parsing.", "labels": [], "entities": [{"text": "Separating conjunctions from the following noun", "start_pos": 0, "end_pos": 47, "type": "TASK", "confidence": 0.8837726016839346}, {"text": "parsing", "start_pos": 85, "end_pos": 92, "type": "TASK", "confidence": 0.9723770022392273}]}, {"text": "By POS Tagging, we mean the standard problem of annotating these segmented words with parts of speech drawn from the 'collapsed' Arabic Penn TreeBank POS tagset.", "labels": [], "entities": [{"text": "POS Tagging", "start_pos": 3, "end_pos": 14, "type": "TASK", "confidence": 0.5780292004346848}, {"text": "Arabic Penn TreeBank POS tagset", "start_pos": 129, "end_pos": 160, "type": "DATASET", "confidence": 0.8440055608749389}]}, {"text": "Base Phrase (BP) Chunking is the process of creating non-recursive base phrases such as noun phrases, adjectival phrases, verb phrases, preposition phrases, etc.", "labels": [], "entities": [{"text": "Base Phrase (BP) Chunking", "start_pos": 0, "end_pos": 25, "type": "TASK", "confidence": 0.7415511012077332}]}, {"text": "For each of these tasks, we adopt a supervised machine learning perspective using Support Vector Machines (SVMs) trained on the Arabic TreeBank, leveraging off of already existing algorithms for English.", "labels": [], "entities": [{"text": "Arabic TreeBank", "start_pos": 128, "end_pos": 143, "type": "DATASET", "confidence": 0.9139909744262695}]}, {"text": "The results are comparable to state-of-the-art results on English text when trained on similar sized data.", "labels": [], "entities": []}], "datasetContent": [{"text": "The Arabic TreeBank consists of 4519 sentences.", "labels": [], "entities": [{"text": "Arabic TreeBank", "start_pos": 4, "end_pos": 19, "type": "DATASET", "confidence": 0.9200882613658905}]}, {"text": "The development set, training set and test set are the same for all the experiments.", "labels": [], "entities": []}, {"text": "The sentences are randomly distributed with 119 sentences in the development set, 400 sentences in the test set and 4000 sentences in the training set.", "labels": [], "entities": []}, {"text": "The data is transliterated in the Arabic TreeBank into Latin based ASCII characters using the Buckwalter transliteration scheme.", "labels": [], "entities": [{"text": "Arabic TreeBank", "start_pos": 34, "end_pos": 49, "type": "DATASET", "confidence": 0.7593475580215454}, {"text": "Buckwalter", "start_pos": 94, "end_pos": 104, "type": "DATASET", "confidence": 0.9548214673995972}]}, {"text": "We used the non vocalized version of the treebank for all the experiments.", "labels": [], "entities": []}, {"text": "All the data is derived from the parsed trees in the treebank.", "labels": [], "entities": []}, {"text": "We use a standard SVM with a polynomial kernel, of degree 2 and C=1.", "labels": [], "entities": []}, {"text": "Standard metrics of Accuracy (Acc), Precision (Prec), Recall (Rec), and the F-measure, , on the test set are utilized.", "labels": [], "entities": [{"text": "Accuracy (Acc)", "start_pos": 20, "end_pos": 34, "type": "METRIC", "confidence": 0.9193451404571533}, {"text": "Precision (Prec)", "start_pos": 36, "end_pos": 52, "type": "METRIC", "confidence": 0.944661945104599}, {"text": "Recall (Rec)", "start_pos": 54, "end_pos": 66, "type": "METRIC", "confidence": 0.9549240469932556}, {"text": "F-measure", "start_pos": 76, "end_pos": 85, "type": "METRIC", "confidence": 0.9767306447029114}]}], "tableCaptions": [{"text": " Table 1: Sample SVM-TOK tagging", "labels": [], "entities": [{"text": "Sample SVM-TOK tagging", "start_pos": 10, "end_pos": 32, "type": "TASK", "confidence": 0.7779954175154368}]}, {"text": " Table 2: Results of SVM-TOK compared against RULE  and RULE+DICT on Arabic tokenization", "labels": [], "entities": [{"text": "RULE", "start_pos": 46, "end_pos": 50, "type": "METRIC", "confidence": 0.9402879476547241}, {"text": "tokenization", "start_pos": 76, "end_pos": 88, "type": "TASK", "confidence": 0.6854822635650635}]}, {"text": " Table 3: Results of SVM-POS compared against  BASELINE on the task of POS tagging of Arabic text", "labels": [], "entities": [{"text": "BASELINE", "start_pos": 47, "end_pos": 55, "type": "METRIC", "confidence": 0.9787375926971436}, {"text": "POS tagging of Arabic text", "start_pos": 71, "end_pos": 97, "type": "TASK", "confidence": 0.8442681074142456}]}, {"text": " Table 4: Results of SVM-BP on base phrase chunking of  Arabic text", "labels": [], "entities": [{"text": "base phrase chunking of  Arabic text", "start_pos": 31, "end_pos": 67, "type": "TASK", "confidence": 0.8080639143784841}]}]}