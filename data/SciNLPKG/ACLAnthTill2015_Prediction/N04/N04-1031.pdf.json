{"title": [{"text": "Paraphrasing Predicates from Written Language to Spoken Language Using the Web", "labels": [], "entities": [{"text": "Paraphrasing Predicates from Written Language", "start_pos": 0, "end_pos": 45, "type": "TASK", "confidence": 0.9080496430397034}]}], "abstractContent": [{"text": "There area lot of differences between expressions used in written language and spoken language.", "labels": [], "entities": []}, {"text": "It is one of the reasons why speech synthesis applications are prone to produce unnatural speech.", "labels": [], "entities": [{"text": "speech synthesis", "start_pos": 29, "end_pos": 45, "type": "TASK", "confidence": 0.754722386598587}]}, {"text": "This paper represents a method of paraphrasing unsuitable expressions for spoken language into suitable ones.", "labels": [], "entities": []}, {"text": "Those two expressions can be distinguished based on the occurrence probability in written and spoken language corpora which are automatically collected from the Web.", "labels": [], "entities": []}, {"text": "Experimental results indicated the effectiveness of our method.", "labels": [], "entities": []}, {"text": "The precision of the collected corpora was 94%, and the accuracy of learning paraphrases was 76 %.", "labels": [], "entities": [{"text": "precision", "start_pos": 4, "end_pos": 13, "type": "METRIC", "confidence": 0.9995657801628113}, {"text": "accuracy", "start_pos": 56, "end_pos": 64, "type": "METRIC", "confidence": 0.9997197985649109}]}], "introductionContent": [{"text": "Information can be provided in various forms, and one of them is speech form.", "labels": [], "entities": []}, {"text": "Speech form is familiar to humans, and can convey information effectively ().", "labels": [], "entities": []}, {"text": "However, little electronic information is provided in speech form so far.", "labels": [], "entities": []}, {"text": "On the other hand, there is a lot of information in text form, and it can be transformed into speech by a speech synthesis.", "labels": [], "entities": []}, {"text": "Therefore, a lot of attention has been given to applications which uses speech synthesis, for example ().", "labels": [], "entities": [{"text": "speech synthesis", "start_pos": 72, "end_pos": 88, "type": "TASK", "confidence": 0.7200493216514587}]}, {"text": "In order to enhance such applications, two problems need to be resolved.", "labels": [], "entities": []}, {"text": "The first is that current speech synthesis technology is still insufficient and many applications often produce speech with unnatural accents and intonations.", "labels": [], "entities": [{"text": "speech synthesis", "start_pos": 26, "end_pos": 42, "type": "TASK", "confidence": 0.747176468372345}]}, {"text": "The second one is that there area lot of differences between expressions used in written language and spoken language.", "labels": [], "entities": []}, {"text": "For example, Ohishi indicated that difficult words and compound nouns are more often used in written language than in spoken language.", "labels": [], "entities": []}, {"text": "Therefore, the applications are prone to produce unnatural speech, if their input is in written language.", "labels": [], "entities": []}, {"text": "Although the first problem is well-known, little attention has been given to the second one.", "labels": [], "entities": []}, {"text": "The reason why the second problem arises is that the input text contains Unsuitable Expressions for Spoken language (UES).", "labels": [], "entities": []}, {"text": "Therefore, the problem can be resolved by paraphrasing UES into Suitable Expression for Spoken language (SES).", "labels": [], "entities": []}, {"text": "This is anew application of paraphrasing.", "labels": [], "entities": []}, {"text": "There are no similar attempts, although a variety of applications have been discussed so far, for example question-answering ( or text-simplification.", "labels": [], "entities": []}, {"text": "In order to paraphrase UES into SES, this paper proposes a method of learning paraphrase pairs in the form of 'UES \ud97b\udf59 SES'.", "labels": [], "entities": [{"text": "UES \ud97b\udf59 SES", "start_pos": 111, "end_pos": 120, "type": "TASK", "confidence": 0.5886205534140269}]}, {"text": "The key notion of the method is to distinguish UES and SES based on the occurrence probability in written and spoken language corpora which are automatically collected from the Web.", "labels": [], "entities": [{"text": "SES", "start_pos": 55, "end_pos": 58, "type": "METRIC", "confidence": 0.784568190574646}]}, {"text": "The procedure of the method is as follows: 1 (step 1) Paraphrase pairs of predicates 2 are learned from a dictionary using a method proposed by).", "labels": [], "entities": []}, {"text": "(step 2) Written and spoken language corpora are automatically collected from the Web.", "labels": [], "entities": []}, {"text": "(step 3) From the paraphrase pairs learned in step 1, those in the form of 'UES \ud97b\udf59SES'areselectedusing the corpora.", "labels": [], "entities": [{"text": "UES \ud97b\udf59SES'areselectedusing", "start_pos": 76, "end_pos": 101, "type": "METRIC", "confidence": 0.7451018889745077}]}, {"text": "This paper deals with only paraphrase pairs of predicates, although UES includes not only predicates but also other categories such as nouns.", "labels": [], "entities": []}, {"text": "This paper is organized as follows.", "labels": [], "entities": []}, {"text": "In Section 2 related works are illustrated.", "labels": [], "entities": []}, {"text": "Section 3 summarizes the method of Kaji et al.", "labels": [], "entities": []}, {"text": "In Section 4, we describe the method of collecting corpora form the Web and report the experimental result.", "labels": [], "entities": []}, {"text": "In Section 5, we describe the method of selecting suitable paraphrases pairs and the experimental result.", "labels": [], "entities": []}, {"text": "Our future work is described in Section 6, and we conclude in Section 7.", "labels": [], "entities": []}], "datasetContent": [{"text": "The two judges built a data set, and 20-hold cross validation was used.", "labels": [], "entities": []}, {"text": "Data set 267 paraphrase pairs were extracted at random form the 5,836 paraphrase pairs learned in section 3.", "labels": [], "entities": []}, {"text": "Two judges independently tagged each of the 267 paraphrase pairs as positive or negative.", "labels": [], "entities": []}, {"text": "Then, only such paraphrase pairs that were agreed upon by both of them were used as data set.", "labels": [], "entities": []}, {"text": "The data set consists of 200 paraphrase pairs (70 positive pairs and 130 negative pairs).", "labels": [], "entities": []}, {"text": "Experimental result We implemented the system using Tiny SVM package 7 .The Kernel function explored was the polynomial function of degree 2.", "labels": [], "entities": []}, {"text": "Using 20-hold cross validation, two types of feature sets (F-set1 and F-set2) were evaluated.", "labels": [], "entities": []}, {"text": "F-set1 is a feature set of all the four features, and F-set2 is that of only two features: OP of source in the spoken language corpus, and OP of target in the spoken language corpus.", "labels": [], "entities": [{"text": "OP", "start_pos": 91, "end_pos": 93, "type": "METRIC", "confidence": 0.9801602959632874}, {"text": "OP", "start_pos": 139, "end_pos": 141, "type": "METRIC", "confidence": 0.9733850359916687}]}, {"text": "The results were evaluated through three measures: accuracy of the classification (positive or negative), precision of positive paraphrase pairs, and recall of positive paraphrase pairs.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 51, "end_pos": 59, "type": "METRIC", "confidence": 0.9995446801185608}, {"text": "precision", "start_pos": 106, "end_pos": 115, "type": "METRIC", "confidence": 0.9991773962974548}, {"text": "recall", "start_pos": 150, "end_pos": 156, "type": "METRIC", "confidence": 0.9985822439193726}]}, {"text": "The accuracy, precision and recall of F-set1 were 76 %, 70 % and 73 % respectively.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.9998774528503418}, {"text": "precision", "start_pos": 14, "end_pos": 23, "type": "METRIC", "confidence": 0.9998509883880615}, {"text": "recall", "start_pos": 28, "end_pos": 34, "type": "METRIC", "confidence": 0.9998639822006226}, {"text": "F-set1", "start_pos": 38, "end_pos": 44, "type": "DATASET", "confidence": 0.5763817429542542}]}, {"text": "Those of F-set2 were 75 %, 67 %, and 69 %.", "labels": [], "entities": [{"text": "F-set2", "start_pos": 9, "end_pos": 15, "type": "METRIC", "confidence": 0.5194872617721558}]}, {"text": "The paraphrase pair (1) is positive example and the paraphrase pair (2) is negative, and both of them were successfully classified.", "labels": [], "entities": []}, {"text": "The source of (1) appears only 10 times in the spoken language corpus, on the other hand, the source of (2) does 67 times.", "labels": [], "entities": []}, {"text": "Discussion It is challenging to detect the connotational difference between lexical paraphrases, and all the features were not explicitly given but estimated using the corpora which were prepared in the unsupervised manner.", "labels": [], "entities": []}, {"text": "Therefore, we think that the accuracy of 76 % is very high.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 29, "end_pos": 37, "type": "METRIC", "confidence": 0.9998034834861755}]}, {"text": "The result of F-set1 exceeds that of F-set2.", "labels": [], "entities": []}, {"text": "This indicates that comparing \u00c7\u00c8\u00b4\ud97b\udf59\u00b5 in the written and spoken language corpus is effective.", "labels": [], "entities": [{"text": "\u00c7\u00c8\u00b4\ud97b\udf59\u00b5", "start_pos": 30, "end_pos": 35, "type": "METRIC", "confidence": 0.8722720940907797}]}, {"text": "Calculated \u00c7\u00c8\u00b4\ud97b\udf59\u00b5 was occasionally quite far from our intuition.", "labels": [], "entities": [{"text": "\u00c7\u00c8\u00b4\ud97b\udf59\u00b5", "start_pos": 11, "end_pos": 16, "type": "METRIC", "confidence": 0.9364387392997742}]}, {"text": "One example is that of 'kangekisuru', which is a very difficult verb that means 'to watch a drama'.", "labels": [], "entities": []}, {"text": "Although the verb is rarely used in real spoken language, its occurrence probability in the spoken language corpus was very high: the verb appeared 9 times in the written language corpus and 69 times in the spoken language corpus.", "labels": [], "entities": [{"text": "occurrence probability", "start_pos": 62, "end_pos": 84, "type": "METRIC", "confidence": 0.9595615565776825}]}, {"text": "We examined those corpora, and found that the spoken language corpus happens to contain a lot of texts about dramas.", "labels": [], "entities": []}, {"text": "Such problems caused by biased topics will be resolved by collecting corpora form larger Web corpus.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: The size of the corpora  # of pages # of words  The Web corpus  660,062  733M  Written language corpus  80,685  77M  Spoken language corpus  73,977  113M", "labels": [], "entities": [{"text": "Web corpus  660,062  733M  Written language corpus  80,685  77M  Spoken language corpus  73,977  113M", "start_pos": 62, "end_pos": 163, "type": "DATASET", "confidence": 0.9123077456440244}]}, {"text": " Table 3. The judge 1 identified  228 pages as properly classified ones; the judge 2 iden- tified 221 pages as properly classified ones. The average  precision of the total was 94% (=228+221/240+240) and  we can say that our corpora have sufficient quality.", "labels": [], "entities": [{"text": "precision", "start_pos": 150, "end_pos": 159, "type": "METRIC", "confidence": 0.9978231191635132}]}, {"text": " Table 3: # of pages properly collected  Judge 1 Judge 2  Written language corpus 119/125 110/125  Spoken language corpus 109/115 111/115  Total  228/240 221/240", "labels": [], "entities": []}, {"text": " Table 4: Occurrence probability of 'jikaisuru'", "labels": [], "entities": [{"text": "Occurrence probability", "start_pos": 10, "end_pos": 32, "type": "METRIC", "confidence": 0.9612319767475128}]}, {"text": " Table 6: Accuracy, precision and recall", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9994157552719116}, {"text": "precision", "start_pos": 20, "end_pos": 29, "type": "METRIC", "confidence": 0.9996898174285889}, {"text": "recall", "start_pos": 34, "end_pos": 40, "type": "METRIC", "confidence": 0.9991256594657898}]}]}