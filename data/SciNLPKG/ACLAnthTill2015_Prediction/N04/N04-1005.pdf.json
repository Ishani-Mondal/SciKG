{"title": [{"text": "Balancing Data-driven and Rule-based Approaches in the Context of a Multimodal Conversational System", "labels": [], "entities": []}], "abstractContent": [{"text": "Moderate-sized rule-based spoken language models for recognition and understanding are easy to develop and provide the ability to rapidly prototype conversational applications.", "labels": [], "entities": [{"text": "recognition and understanding", "start_pos": 53, "end_pos": 82, "type": "TASK", "confidence": 0.8608186443646749}]}, {"text": "However, scalability of such systems is a bottleneck due to the heavy cost of authoring and maintenance of rule sets and inevitable brittle-ness due to lack of coverage in the rule sets.", "labels": [], "entities": []}, {"text": "In contrast, data-driven approaches are robust and the procedure for model building is usually simple.", "labels": [], "entities": [{"text": "model building", "start_pos": 69, "end_pos": 83, "type": "TASK", "confidence": 0.7357429563999176}]}, {"text": "However, the lack of data in a particular application domain limits the ability to build data-driven models.", "labels": [], "entities": []}, {"text": "In this paper, we address the issue of combining data-driven and grammar-based models for rapid prototyping of robust speech recognition and understanding models fora multimodal conversational system.", "labels": [], "entities": [{"text": "speech recognition and understanding", "start_pos": 118, "end_pos": 154, "type": "TASK", "confidence": 0.7433686554431915}]}, {"text": "We also present methods that reuse data from different domains and investigate the limits of such models in the context of a particular application domain.", "labels": [], "entities": []}], "introductionContent": [{"text": "In the past four decades of speech and natural language processing, both data-driven approaches and rule-based approaches have been prominent at different periods in time.", "labels": [], "entities": [{"text": "speech and natural language processing", "start_pos": 28, "end_pos": 66, "type": "TASK", "confidence": 0.6811738073825836}]}, {"text": "In the recent past, rule-based approaches have fallen into disfavor due to their brittleness and the significant cost of authoring and maintaining complex rule sets.", "labels": [], "entities": []}, {"text": "Data-driven approaches are robust and provide a simple process of developing applications given the data from the application domain.", "labels": [], "entities": []}, {"text": "However, the reliance on domain-specific data is also one of the significant bottlenecks of data-driven approaches.", "labels": [], "entities": []}, {"text": "Development of a conversational system using data-driven approaches cannot proceed until data pertaining to the application domain is available.", "labels": [], "entities": []}, {"text": "The collection and annotation of such data is extremely time-consuming and tedious, which is aggravated by the presence of multiple modalities in the user's input, as in our case.", "labels": [], "entities": []}, {"text": "Also, extending an existing application to support an additional feature requires adding additional data sets with that feature.", "labels": [], "entities": []}, {"text": "In this paper, we explore various methods for combining rule-based and in-domain data for rapid prototyping of speech recognition and understanding models that are robust to ill-formed or unexpected input in the context of a multimodal conversational system.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 111, "end_pos": 129, "type": "TASK", "confidence": 0.7015202194452286}]}, {"text": "We also investigate approaches to reuse out-of-domain data and compare their performance against the performance of in-domain data-driven models.", "labels": [], "entities": []}, {"text": "We investigate these issues in the context of a multimodal application designed to provide an interactive city guide: MATCH.", "labels": [], "entities": [{"text": "MATCH", "start_pos": 118, "end_pos": 123, "type": "DATASET", "confidence": 0.8095859885215759}]}, {"text": "In Section 2, we present the MATCH application, the architecture of the system and the apparatus for multimodal understanding.", "labels": [], "entities": [{"text": "MATCH", "start_pos": 29, "end_pos": 34, "type": "TASK", "confidence": 0.6328490972518921}, {"text": "multimodal understanding", "start_pos": 101, "end_pos": 125, "type": "TASK", "confidence": 0.7390020191669464}]}, {"text": "In Section 3, we discuss various approaches to rapid prototyping of the language model for the speech recognizer and in Section 4 we present two approaches to robust multimodal understanding.", "labels": [], "entities": [{"text": "speech recognizer", "start_pos": 95, "end_pos": 112, "type": "TASK", "confidence": 0.7063591182231903}]}, {"text": "Section 5 presents the results for speech recognition and multimodal understanding using the different approaches we consider.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 35, "end_pos": 53, "type": "TASK", "confidence": 0.8806936144828796}, {"text": "multimodal understanding", "start_pos": 58, "end_pos": 82, "type": "TASK", "confidence": 0.7462590634822845}]}], "datasetContent": [{"text": "We describe a set of experiments to evaluate the performance of the speech recognizer and the concept accuracy of speech only and speech and gesture exchanges in our MATCH multimodal system.", "labels": [], "entities": [{"text": "speech recognizer", "start_pos": 68, "end_pos": 85, "type": "TASK", "confidence": 0.7118339538574219}, {"text": "accuracy", "start_pos": 102, "end_pos": 110, "type": "METRIC", "confidence": 0.9881934523582458}]}, {"text": "We use word accuracy and string accuracy for evaluating ASR output.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 12, "end_pos": 20, "type": "METRIC", "confidence": 0.850419819355011}, {"text": "accuracy", "start_pos": 32, "end_pos": 40, "type": "METRIC", "confidence": 0.6634067893028259}, {"text": "ASR", "start_pos": 56, "end_pos": 59, "type": "TASK", "confidence": 0.9691675305366516}]}, {"text": "All results presented in this section are based on 10-fold crossvalidation experiments run on the 709 spoken and multimodal exchanges collected from the pilot study described in Section 3.1.", "labels": [], "entities": []}, {"text": "presents the performance results for ASR word and sentence accuracy using language models trained on collected in-domain corpus as well as on corpora derived using the different methods discussed in Section 3.", "labels": [], "entities": [{"text": "ASR word and sentence accuracy", "start_pos": 37, "end_pos": 67, "type": "TASK", "confidence": 0.8839563846588134}]}, {"text": "For the class-based models mentioned in the table, we defined different classes based on areas of interest (eg. riverside park, turtle pond), points of interest (eg. Ellis Island, United Nations Building), type of cuisine (eg.: Performance results for ASR Word and Sentence accuracy using models trained on data derived from different methods of bootstrapping domain-specific data.", "labels": [], "entities": [{"text": "Ellis Island, United Nations Building", "start_pos": 166, "end_pos": 203, "type": "DATASET", "confidence": 0.7953924039999644}, {"text": "ASR Word and Sentence accuracy", "start_pos": 252, "end_pos": 282, "type": "TASK", "confidence": 0.7859962701797485}]}], "tableCaptions": [{"text": " Table 2: Performance results for ASR Word and Sentence accuracy using models trained on data derived from different  methods of bootstrapping domain-specific data.", "labels": [], "entities": [{"text": "ASR Word and Sentence accuracy", "start_pos": 34, "end_pos": 64, "type": "TASK", "confidence": 0.8433285593986511}]}, {"text": " Table 3: Performance results of robust multimodal understanding", "labels": [], "entities": []}]}