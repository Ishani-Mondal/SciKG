{"title": [{"text": "Feature Selection for Trainable Multilingual Broadcast News Segmentation", "labels": [], "entities": [{"text": "Multilingual Broadcast News Segmentation", "start_pos": 32, "end_pos": 72, "type": "TASK", "confidence": 0.6305890530347824}]}], "abstractContent": [{"text": "Indexing and retrieving broadcast news stories within a large collection requires automatic detection of story boundaries.", "labels": [], "entities": [{"text": "Indexing and retrieving broadcast news stories", "start_pos": 0, "end_pos": 46, "type": "TASK", "confidence": 0.7679973890384039}]}, {"text": "This video news story segmentation can use a wide range of audio , language, video, and image features.", "labels": [], "entities": [{"text": "video news story segmentation", "start_pos": 5, "end_pos": 34, "type": "TASK", "confidence": 0.6868274509906769}]}, {"text": "In this paper, we investigate the correlation between automatically-derived multimodal features and story boundaries in seven different broadcast news sources in three languages.", "labels": [], "entities": []}, {"text": "We identify several features that are important for all seven sources analyzed, and we discuss the contributions of other features that are important fora subset of the seven sources.", "labels": [], "entities": []}], "introductionContent": [{"text": "Indexing and retrieving stories within a large collection of video requires automatic detection of story boundaries, and video story segmentation is an essential step toward providing the means for finding, linking, summarizing, and visualizing related parts of multimedia collections.", "labels": [], "entities": [{"text": "Indexing and retrieving stories within a large collection of video", "start_pos": 0, "end_pos": 66, "type": "TASK", "confidence": 0.7894365131855011}, {"text": "video story segmentation", "start_pos": 121, "end_pos": 145, "type": "TASK", "confidence": 0.7253510355949402}, {"text": "summarizing, and visualizing related parts of multimedia collections", "start_pos": 216, "end_pos": 284, "type": "TASK", "confidence": 0.6587741606765323}]}, {"text": "In many cases, previous story segmentation research has focused on single stream analysis techniques, utilizing only one of the information sources present in news broadcasts: natural language, audio, image, and video (see, for example,,),(),).", "labels": [], "entities": [{"text": "story segmentation", "start_pos": 24, "end_pos": 42, "type": "TASK", "confidence": 0.7359686493873596}, {"text": "single stream analysis", "start_pos": 67, "end_pos": 89, "type": "TASK", "confidence": 0.7255225578943888}]}, {"text": "Some segmentation research has included multimodal approaches that were capable of combining features from multiple information sources),( . While this work was a significant improvement over single-stream approaches, they were rarely applied to non-English sources without closed captioning.", "labels": [], "entities": []}, {"text": "Previous work on story segmentation has identified many features useful for finding story boundaries, but feature selection is often model-dependent and does not account for the differences between broadcast sources.", "labels": [], "entities": [{"text": "story segmentation", "start_pos": 17, "end_pos": 35, "type": "TASK", "confidence": 0.7734759449958801}]}, {"text": "Specific features useful for video story segmentation vary widely from one source to the next, and the degree to which each feature is useful also varies across sources and even from one broadcast to the next within a single source.", "labels": [], "entities": [{"text": "video story segmentation", "start_pos": 29, "end_pos": 53, "type": "TASK", "confidence": 0.7613666852315267}]}, {"text": "This variety suggests the need for trainable techniques in which salient source-specific features can be automatically learned from a set of training data.", "labels": [], "entities": []}, {"text": "This data-driven approach is especially important in multilingual video processing, where native speakers may not be available to develop segmentation models for every language.", "labels": [], "entities": [{"text": "multilingual video processing", "start_pos": 53, "end_pos": 82, "type": "TASK", "confidence": 0.6396555801232656}]}, {"text": "The goal of this paper is to provide a modelindependent investigation of the correlation between a wide range of multimedia features and news story boundaries, in order to aid the development of improved segmentation algorithms.", "labels": [], "entities": []}, {"text": "Our work seeks to complement recent work in model-dependent feature selection, such as (, without making assumptions about the dependencies between features.", "labels": [], "entities": []}, {"text": "The feature analysis we describe in this paper consisted of several steps.", "labels": [], "entities": []}, {"text": "First, we created a data set for our experiments by capturing and digitally encoding a set of news broadcasts from seven video news sources in three languages.", "labels": [], "entities": []}, {"text": "A native speaker manually labelled the story and commercial boundaries in each broadcast; we describe the data in Section 2.", "labels": [], "entities": []}, {"text": "We ran several state-of-theart audio and video analysis software packages on each recorded broadcasts to extract time-stamped multimedia metadata, and we defined a set of possible segmentation features based on the metadata values produced by the analysis software; we describe the software analysis and feature extraction in Section 3.", "labels": [], "entities": [{"text": "feature extraction", "start_pos": 304, "end_pos": 322, "type": "TASK", "confidence": 0.7535865008831024}]}, {"text": "Finally, we analyzed the patterns of occurrence of the features with respect to story and commercial boundaries in all the news broadcasts; the results of our analysis are described in Section 4.", "labels": [], "entities": []}, {"text": "The data for our segmentation research consists of a set of news broadcasts recorded directly from a satellite dish between September 2002 and February 2003.", "labels": [], "entities": [{"text": "segmentation", "start_pos": 17, "end_pos": 29, "type": "TASK", "confidence": 0.9731643795967102}]}, {"text": "The data set contains roughly equal amounts (8-12 hours) of news broadcasts from seven sources in three languages: Aljazeera (Arabic), BBC America (UK English), China Central TV (Mandarin Chinese), CNN Headline News (US English), CNN International (US/UK English), Fox News (US English), and Newsworld International (US/UK English).", "labels": [], "entities": [{"text": "CNN Headline News (US English)", "start_pos": 198, "end_pos": 228, "type": "DATASET", "confidence": 0.8893248864582607}]}, {"text": "Each broadcast was manually segmented with the labels \"story\" and \"commercial\" by one annotator and verified by a second, at least one of whom was a native speaker of the broadcast language.", "labels": [], "entities": []}, {"text": "We found that a very good segmentation is possible by a non-native speaker based solely on video and acoustic cues, but a native speaker is required to verify story boundaries that require language knowledge, such as a single-shot video sequence of several stories read by a news anchor without pausing.", "labels": [], "entities": []}, {"text": "The definition of \"story\" in our experiments corresponds with the Topic Detection and Tracking definition: a segment of a news broadcast with a coherent news focus, containing at least two independent, declarative clauses (LDC, 1999).", "labels": [], "entities": [{"text": "Topic Detection and Tracking", "start_pos": 66, "end_pos": 94, "type": "TASK", "confidence": 0.8767476826906204}, {"text": "LDC, 1999)", "start_pos": 223, "end_pos": 233, "type": "DATASET", "confidence": 0.8712604492902756}]}, {"text": "The segments within broadcasts briefly summarizing several stories were not assigned a \"story\" label, nor were anchor introductions, signoffs, banter, and teasers for upcoming stories.", "labels": [], "entities": []}, {"text": "Each individual story within blocks of contiguous stories was labeled \"story.\"", "labels": [], "entities": []}, {"text": "A sequence of contiguous commercials was annotated with a single \"commercial\" label with a single pair of boundaries for the entire block.", "labels": [], "entities": []}, {"text": "shows the details of our experimental data set.", "labels": [], "entities": []}, {"text": "The first two columns show the broadcast source and the language.", "labels": [], "entities": []}, {"text": "The next two columns show the total number of hours and the number of hours labeled \"story\" for each source.", "labels": [], "entities": []}, {"text": "It is interesting to note that the percentage of broadcast time devoted to news stories varies widely by source, from 62% for CNN Headline News to 90% for CNN International.", "labels": [], "entities": [{"text": "CNN Headline News", "start_pos": 126, "end_pos": 143, "type": "DATASET", "confidence": 0.9225826660792033}, {"text": "CNN International", "start_pos": 155, "end_pos": 172, "type": "DATASET", "confidence": 0.8876902163028717}]}, {"text": "Similarly, the average story length varies widely, as shown in the final column of, from 52 seconds per story for CNN Headline News to 171 seconds per story for Fox News.", "labels": [], "entities": [{"text": "CNN Headline News", "start_pos": 114, "end_pos": 131, "type": "DATASET", "confidence": 0.8996928731600443}]}, {"text": "These large differences are extremely important when modeling the distributions of stories (and commercials) within news broadcasts from various sources.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Data sources (Broadcast source, language, total  hours, hours of stories, number of stories, average story  length).", "labels": [], "entities": []}]}