{"title": [{"text": "Converting Text into Agent Animations: Assigning Gestures to Text", "labels": [], "entities": [{"text": "Converting Text into Agent Animations", "start_pos": 0, "end_pos": 37, "type": "TASK", "confidence": 0.7463489294052124}]}], "abstractContent": [{"text": "This paper proposes a method for assigning gestures to text based on lexical and syntactic information.", "labels": [], "entities": []}, {"text": "First, our empirical study identified lexical and syntactic information strongly correlated with gesture occurrence and suggested that syntactic structure is more useful for judging gesture occurrence than local syntactic cues.", "labels": [], "entities": []}, {"text": "Based on the empirical results, we have implemented a system that converts text into an animated agent that gestures and speaks synchronously.", "labels": [], "entities": []}], "introductionContent": [{"text": "The significant advances in computer graphics over the last decade have improved the expressiveness of animated characters and have promoted research on interface agents, which serve as mediators of humancomputer interactions.", "labels": [], "entities": []}, {"text": "As an interface agent has an embodied figure, it can use its face and body to display nonverbal behaviors while speaking.", "labels": [], "entities": []}, {"text": "Previous studies inhuman communication suggest that gestures in particular contribute to better understanding of speech.", "labels": [], "entities": []}, {"text": "About 90% of all gestures by speakers occur when the speaker is actually uttering something.", "labels": [], "entities": []}, {"text": "Experimental studies have shown that spoken sentences are heard twice as accurately when they are presented along with a gesture.", "labels": [], "entities": []}, {"text": "Comprehension of a description accompanied by gestures is better than that accompanied by only the speaker's face and lip movements.", "labels": [], "entities": []}, {"text": "These previous studies suggest that generating appropriate gestures synchronized with speech is a promising approach to improving the performance of interface agents.", "labels": [], "entities": []}, {"text": "In previous studies of multimodal generation, gestures were determined according to the instruction content (Andre,), the task situation in a learning environment, or the agent's communicative goal in conversation).", "labels": [], "entities": [{"text": "multimodal generation", "start_pos": 23, "end_pos": 44, "type": "TASK", "confidence": 0.7558436989784241}]}, {"text": "These approaches, however, require the contents developer (e.g., a schoolteacher designing teaching materials) to be skilled at describing semantic and pragmatic relations in logical form.", "labels": [], "entities": []}, {"text": "A different approach,) proposes a toolkit that takes plain text as input and automatically suggests a sequence of agent behaviors synchronized with the synthesized speech.", "labels": [], "entities": []}, {"text": "However, there has been little work in computational linguistics on how to identify and extract linguistic information in text in order to generate gestures.", "labels": [], "entities": []}, {"text": "Our study has addressed these issues by considering two questions.", "labels": [], "entities": []}, {"text": "(1) Is the lexical and syntactic information in text useful for generating meaningful gestures?", "labels": [], "entities": []}, {"text": "(2) If so, how can the information be extracted from the text and exploited in a gesture decision mechanism in an interface agent?", "labels": [], "entities": []}, {"text": "Our goal is to develop a media conversion technique that generates agent animations synchronized with speech from plain text.", "labels": [], "entities": []}, {"text": "This paper is organized as follows.", "labels": [], "entities": []}, {"text": "The next section reviews theoretical issues about the relationships between gestures and syntactic information.", "labels": [], "entities": []}, {"text": "The empirical study we conducted based on these issues is described in Sec.", "labels": [], "entities": []}, {"text": "4 we describe the implementation of our presentation agent system, and in the last section we discuss future directions.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": []}