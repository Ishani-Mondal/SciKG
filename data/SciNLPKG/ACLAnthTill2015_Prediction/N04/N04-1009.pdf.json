{"title": [{"text": "A Probabilistic Rasch Analysis of Question Answering Evaluations", "labels": [], "entities": [{"text": "Rasch Analysis of Question Answering Evaluations", "start_pos": 16, "end_pos": 64, "type": "TASK", "confidence": 0.8644941647847494}]}], "abstractContent": [{"text": "The field of Psychometrics routinely grapples with the question of what it means to measure the inherent ability of an organism to perform a given task, and for the last forty years, the field has increasingly relied on probabilistic methods such as the Rasch model for test construction and the analysis of test results.", "labels": [], "entities": [{"text": "test construction", "start_pos": 270, "end_pos": 287, "type": "TASK", "confidence": 0.7360414564609528}]}, {"text": "Because the underlying issues of measuring ability apply to human language technologies as well, such probabilistic methods can be advantageously applied to the evaluation of those technologies.", "labels": [], "entities": []}, {"text": "To test this claim, Rasch measurement was applied to the results of 67 systems participating in the Question Answering track of the 2002 Text REtrieval Conference (TREC) competition.", "labels": [], "entities": [{"text": "Rasch measurement", "start_pos": 20, "end_pos": 37, "type": "METRIC", "confidence": 0.6903976798057556}, {"text": "Question Answering track of the 2002 Text REtrieval Conference (TREC) competition", "start_pos": 100, "end_pos": 181, "type": "TASK", "confidence": 0.8238376149764428}]}, {"text": "Satisfactory model fit was obtained, and the paper illustrates the theoretical and practical strengths of Rasch scaling for evaluating systems as well as questions.", "labels": [], "entities": []}, {"text": "Most important, simulations indicate that a test invariant metric can be defined by carrying forward 20 to 50 equating questions, thus placing the yearly results on a common scale.", "labels": [], "entities": []}], "introductionContent": [{"text": "For a number of years, objective evaluation of state-ofthe-art computational systems on realistic language processing tasks has been a driving force in the advance of Human Language Technology (HLT).", "labels": [], "entities": [{"text": "Human Language Technology (HLT)", "start_pos": 167, "end_pos": 198, "type": "TASK", "confidence": 0.6910293102264404}]}, {"text": "Often, such evaluations are based on the use of simple sum-scores (i.e., the number of correct answers) and derivatives thereof (e.g., percentages), or on ad-hoc ways to rank or order system responses according to their correctness.", "labels": [], "entities": []}, {"text": "Unfortunately, research in other areas indicates that such approaches rarely yield a cumulative body of knowledge, thereby complicating theory formation and practical decision making alike.", "labels": [], "entities": [{"text": "theory formation", "start_pos": 136, "end_pos": 152, "type": "TASK", "confidence": 0.7983259558677673}, {"text": "decision making", "start_pos": 167, "end_pos": 182, "type": "TASK", "confidence": 0.7028561532497406}]}, {"text": "In fact, although it is often taken for granted that sums or percentages adequately reflect systems' performance, this assumption does not agree with many models currently used in educational testing (cf.,).", "labels": [], "entities": []}, {"text": "To address this situation, we present the use of) measurement to the HLT research community, in general, and to the Question Answering (QA) research community, in particular.", "labels": [], "entities": [{"text": "Question Answering (QA)", "start_pos": 116, "end_pos": 139, "type": "TASK", "confidence": 0.8194274961948395}]}, {"text": "Rasch measurement has evolved over the last forty years to rigorously quantify performance aspects in such diverse areas as educational testing, cognitive development, moral judgment, eating disorders (see e.g.,), as well as olfactory screening for Alzheimer's disease () and model glider competitions.", "labels": [], "entities": [{"text": "Rasch measurement", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.8828597366809845}]}, {"text": "In each case, the major contribution of Rasch measurement is to decompose performance into two additive sources: the difficulty of the task and the ability of the person or system performing this task.", "labels": [], "entities": []}, {"text": "While Rasch measurement is new to the evaluation of the performance of HLT systems, we intend to demonstrate that this approach applies here as well, and that it potentially provides significant advantages over traditional evaluation approaches.", "labels": [], "entities": [{"text": "Rasch measurement", "start_pos": 6, "end_pos": 23, "type": "TASK", "confidence": 0.7901428639888763}]}, {"text": "Our principal theoretical argument in favor of Rasch modeling is that the decomposition of performance into task difficulty and system ability creates the potential for formulating detailed and testable hypotheses in other areas of language technology.", "labels": [], "entities": [{"text": "Rasch modeling", "start_pos": 47, "end_pos": 61, "type": "TASK", "confidence": 0.964550256729126}]}, {"text": "For QA, the existence of a well-defined, precise, mathematical formulation of question difficulty and system ability can provide the basis for the study of the dimensions inherent in the answering task, the formal characterization of questions, and the methodical analysis of the strengths and weaknesses of competing algorithmic approaches.", "labels": [], "entities": [{"text": "QA", "start_pos": 4, "end_pos": 6, "type": "TASK", "confidence": 0.9367778897285461}]}, {"text": "As 3) explain: \"The goal is to create abstractions that transcend the raw data, just as in the physical sciences, so that inferences can be made about constructs rather than mere descriptions about raw data.\"", "labels": [], "entities": []}, {"text": "Researchers are then in a position to formulate initial theories, validate the consequences of theories on real data, refine theories in light of empirical data, and followup with revised experimentation in a dialectic process that forms the essence of scientific discovery.", "labels": [], "entities": []}, {"text": "Rasch modeling offers a number of direct practical advantages as well.", "labels": [], "entities": [{"text": "Rasch modeling", "start_pos": 0, "end_pos": 14, "type": "TASK", "confidence": 0.9741165339946747}]}, {"text": "Among these are: \u2022 Quantification of question difficulty and system ability on a single scale with a common metric.", "labels": [], "entities": []}, {"text": "\u2022 Support for the creation of tailor-made questions and the compilation of questions that suit welldefined evaluation objectives.", "labels": [], "entities": []}, {"text": "\u2022 Equating (calibration) of distinct question corpora so that systems participating in distinct evaluation cycles can be directly compared.", "labels": [], "entities": []}, {"text": "\u2022 Assessment of the degree to which independent evaluations assess the same system abilities.", "labels": [], "entities": []}, {"text": "\u2022 Availability of rigorous statistical techniques for the following: -analysis of fit of the data produced from systems' performance to the Rasch modeling assumptions; -identification of individual systems whose performance behavior does not conform to the performance patterns of the population as a whole; -identification of individual test questions that appear to be testing facets distinct from those evaluated by the test as a whole; -assessment of the reliability of the test -that is, the degree to which we can expect estimates of systems' abilities to be replicated if these systems are given another test of equivalent questions; -identification of unmodeled sources of variation in the data through a variety of methods, including bias tests and analysis of residual terms.", "labels": [], "entities": []}, {"text": "The remainder of the paper is organized as follows.", "labels": [], "entities": []}, {"text": "First, we present in section 2 the basic concepts of Rasch modeling.", "labels": [], "entities": [{"text": "Rasch modeling", "start_pos": 53, "end_pos": 67, "type": "TASK", "confidence": 0.9754302501678467}]}, {"text": "We continue in section 3 with an application of Rasch modeling to the data resulting from the QA track of the 2002 Text REtrieval Conference (TREC) competition.", "labels": [], "entities": [{"text": "Rasch modeling", "start_pos": 48, "end_pos": 62, "type": "TASK", "confidence": 0.8721183836460114}, {"text": "Text REtrieval Conference (TREC) competition", "start_pos": 115, "end_pos": 159, "type": "TASK", "confidence": 0.6427984578268868}]}, {"text": "We fit the model to the data, analyze the resulting fit, and demonstrate some of the benefits that can be derived from this approach.", "labels": [], "entities": []}, {"text": "In section 4 we present simulation results on test equating.", "labels": [], "entities": []}, {"text": "Finally, we conclude with a summary of our findings and present ideas for continuing research into the application of Rasch models to technology development and scientific theory formation in the various fields of human language processing.", "labels": [], "entities": [{"text": "scientific theory formation", "start_pos": 161, "end_pos": 188, "type": "TASK", "confidence": 0.7231982350349426}, {"text": "human language processing", "start_pos": 214, "end_pos": 239, "type": "TASK", "confidence": 0.6891314188639323}]}], "datasetContent": [{"text": "We used the results from the Question Answering track of the 2002 TREC competition to test the feasibility of applying Rasch modeling to QA evaluation.", "labels": [], "entities": [{"text": "Question Answering track of the 2002 TREC competition", "start_pos": 29, "end_pos": 82, "type": "TASK", "confidence": 0.5702435821294785}, {"text": "QA evaluation", "start_pos": 137, "end_pos": 150, "type": "TASK", "confidence": 0.8057683110237122}]}, {"text": "Sixty-seven systems participated, and answered 500 questions by returning a single precise response extracted from a 3-gigabyte corpus of texts.", "labels": [], "entities": []}, {"text": "While the NIST judges assessed each answer as correct, incorrect, non-exact, or unsupported, we created binary responses by treating each of these last three assessments as incorrect.", "labels": [], "entities": [{"text": "NIST", "start_pos": 10, "end_pos": 14, "type": "DATASET", "confidence": 0.9062495827674866}]}, {"text": "Ten questions were excluded from all analyses, as these were not answered correctly by any system.", "labels": [], "entities": []}, {"text": "The final When all respondents answer some question q correctly (or data set thus consisted of 67 systems' responses to 490 questions.", "labels": [], "entities": []}, {"text": "The size of the dots is proportional to SE s 2.", "labels": [], "entities": [{"text": "SE", "start_pos": 40, "end_pos": 42, "type": "METRIC", "confidence": 0.9963255524635315}]}, {"text": "The circled dot is displaced to fit the graph.", "labels": [], "entities": []}, {"text": "Systems by S s , Outfit s, and SE s", "labels": [], "entities": [{"text": "Outfit", "start_pos": 17, "end_pos": 23, "type": "DATASET", "confidence": 0.8927226662635803}]}], "tableCaptions": [{"text": " Table 1. Misfit Diagnosis of Best Performing Sys- tem", "labels": [], "entities": [{"text": "Misfit Diagnosis", "start_pos": 10, "end_pos": 26, "type": "TASK", "confidence": 0.9305330216884613}, {"text": "Sys- tem", "start_pos": 46, "end_pos": 54, "type": "TASK", "confidence": 0.7516398628552755}]}, {"text": " Table 2. Results of the Simulation Study", "labels": [], "entities": [{"text": "Simulation", "start_pos": 25, "end_pos": 35, "type": "TASK", "confidence": 0.9886634945869446}]}]}