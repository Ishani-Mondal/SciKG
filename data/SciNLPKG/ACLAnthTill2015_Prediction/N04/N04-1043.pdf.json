{"title": [{"text": "Name Tagging with Word Clusters and Discriminative Training", "labels": [], "entities": [{"text": "Name Tagging", "start_pos": 0, "end_pos": 12, "type": "TASK", "confidence": 0.8368324041366577}]}], "abstractContent": [{"text": "We present a technique for augmenting annotated training data with hierarchical word clusters that are automatically derived from a large unannotated corpus.", "labels": [], "entities": []}, {"text": "Cluster membership is encoded in features that are incorporated in a discriminatively trained tagging model.", "labels": [], "entities": [{"text": "Cluster membership", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.7457703053951263}]}, {"text": "Active learning is used to select training examples.", "labels": [], "entities": []}, {"text": "We evaluate the technique for named-entity tagging.", "labels": [], "entities": [{"text": "named-entity tagging", "start_pos": 30, "end_pos": 50, "type": "TASK", "confidence": 0.696239173412323}]}, {"text": "Compared with a state-of-the-art HMM-based name finder, the presented technique requires only 13% as much annotated data to achieve the same level of performance.", "labels": [], "entities": [{"text": "HMM-based name finder", "start_pos": 33, "end_pos": 54, "type": "TASK", "confidence": 0.7920963764190674}]}, {"text": "Given a large annotated training set of 1,000,000 words, the technique achieves a 25% reduction in error over the state-of-the-art HMM trained on the same material.", "labels": [], "entities": [{"text": "error", "start_pos": 99, "end_pos": 104, "type": "METRIC", "confidence": 0.9885580539703369}]}], "introductionContent": [{"text": "At a recent meeting, we presented name-tagging technology to a potential user.", "labels": [], "entities": []}, {"text": "The technology had performed well informal evaluations, had been applied successfully by several research groups, and required only annotated training examples to configure for new name classes.", "labels": [], "entities": []}, {"text": "Nevertheless, it did not meet the user's needs.", "labels": [], "entities": []}, {"text": "To achieve reasonable performance, the HMM-based technology we presented required roughly 150,000 words of annotated examples, and over a million words to achieve peak accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 168, "end_pos": 176, "type": "METRIC", "confidence": 0.9948209524154663}]}, {"text": "Given atypical annotation rate of 5,000 words per hour, we estimated that setting up a name finder fora new problem would take four person days of annotation work -a period we considered reasonable.", "labels": [], "entities": [{"text": "name finder", "start_pos": 87, "end_pos": 98, "type": "TASK", "confidence": 0.737194687128067}]}, {"text": "However, this user's problems were too dynamic for that much setup time.", "labels": [], "entities": []}, {"text": "To be useful, the system would have to be trainable in minutes or hours, not days or weeks.", "labels": [], "entities": []}, {"text": "We left the meeting thinking about ways to reduce training requirements to no more than a few hours.", "labels": [], "entities": []}, {"text": "It seemed that three existing ideas could be combined in away that might reduce training requirements sufficiently to achieve the objective.", "labels": [], "entities": []}, {"text": "First were techniques for producing word clusters from large unannotated corpora ().", "labels": [], "entities": []}, {"text": "The resulting clusters appeared to contain a great deal of implicit semantic information.", "labels": [], "entities": []}, {"text": "This implicit information, we believed, could serve to augment a small amount of annotated data.", "labels": [], "entities": []}, {"text": "Particularly promising were techniques for producing hierarchical clusters at various scales, from small and highly specific to large and more general.", "labels": [], "entities": []}, {"text": "To benefit from such information, however, we would need an automatic learning mechanism that could effectively exploit it.", "labels": [], "entities": []}, {"text": "Fortunately, a second line of recent research provided a potential solution.", "labels": [], "entities": []}, {"text": "Recent work in discriminative methods () suggested a framework for exploiting large numbers of arbitrary input features.", "labels": [], "entities": []}, {"text": "These methods seemed to have exactly the right ch a r ac t er i st i c sf or in co r p or at in gt he statistically-correlated hierarchical word clusters we wished to exploit.", "labels": [], "entities": []}, {"text": "Combining these two methods, we suspected, would be sufficient to drastically reduce the number of annotated examples required.", "labels": [], "entities": []}, {"text": "However, we also hoped that a third technique, active learning (, would be particularly effective when used in conjunction with hierarchical word clusters.", "labels": [], "entities": []}, {"text": "Specifically, active learning attempts to select examples for annotation by estimating the system's certainty about the answer, requesting a human judgment only for those cases where it is most uncertain.", "labels": [], "entities": []}, {"text": "Unfortunately, the issue often comes down to whether a specific word has previously been observed in training: if the system has seen the word, it is certain, if not, it is uncertain.", "labels": [], "entities": []}, {"text": "Word clusters at various scales, we hoped, would permit more subtle distinctions to influence the system's certainty, increasing the method's effectiveness earlier in the process when fewer training examples have been annotated.", "labels": [], "entities": [{"text": "certainty", "start_pos": 107, "end_pos": 116, "type": "METRIC", "confidence": 0.9727267622947693}]}], "datasetContent": [{"text": "We performed our experiments using the seven MUC-6 name categories: person, organization, location, date, time, percent, and monetary amount.", "labels": [], "entities": [{"text": "MUC-6", "start_pos": 45, "end_pos": 50, "type": "DATASET", "confidence": 0.685669481754303}]}, {"text": "For annotated data, we used text from Sections 02-23 of the Wall Street Journal Treebank corpus that had previously been annotated with the MUC name classes.", "labels": [], "entities": [{"text": "Wall Street Journal Treebank corpus", "start_pos": 60, "end_pos": 95, "type": "DATASET", "confidence": 0.9719141602516175}, {"text": "MUC name classes", "start_pos": 140, "end_pos": 156, "type": "DATASET", "confidence": 0.9068363308906555}]}, {"text": "Sections 02-21 were used as training material, and Section 23 was used as test (note that the syntactic trees were not used in any way).", "labels": [], "entities": []}, {"text": "Scoring was performed using the MUC scorer.", "labels": [], "entities": [{"text": "Scoring", "start_pos": 0, "end_pos": 7, "type": "TASK", "confidence": 0.801876425743103}, {"text": "MUC scorer", "start_pos": 32, "end_pos": 42, "type": "DATASET", "confidence": 0.967043399810791}]}, {"text": "For unsupervised clustering data, we used the Wall Street Journal subset of the Continuous Speech Recognition (CSR-III) collection (LDC catalog # LDC95T6).", "labels": [], "entities": [{"text": "Wall Street Journal subset of the Continuous Speech Recognition (CSR-III) collection (LDC catalog # LDC95T6)", "start_pos": 46, "end_pos": 154, "type": "DATASET", "confidence": 0.8291381785744115}]}, {"text": "This portion of the collection contains approximately 100 million words.", "labels": [], "entities": []}, {"text": "Active learning experiments were performed by permitting the system to choose examples from among the pool of annotated data, rather than presenting the examples in their natural chronological order.", "labels": [], "entities": []}, {"text": "This approach, previously used in, permits simulation of human-in-the-loop experiments that are inexpensive to run and repeatable because they don't actually involve a human annotator.", "labels": [], "entities": []}, {"text": "However, because the pool of pre-annotated examples is limited, the results are most meaningful for small training sets.", "labels": [], "entities": []}, {"text": "Once the system has selected the most useful examples from the pool, it is forced to choose among the remainder that it previously rejected as less useful.", "labels": [], "entities": []}, {"text": "At the extreme where all available examples are used, our experimental framework prevents active learning from exhibiting any benefit whatsoever since the system is left no choice in selecting examples.", "labels": [], "entities": []}, {"text": "Before considering the impact of word clustering on system performance, we first evaluate the discriminative tagger relative to the baseline HMM.", "labels": [], "entities": [{"text": "word clustering", "start_pos": 33, "end_pos": 48, "type": "TASK", "confidence": 0.7303013503551483}]}, {"text": "For this experiment, we used all of the features described in Section 3 except word cluster features.", "labels": [], "entities": []}, {"text": "The remaining features encode essentially the same information used in the HMM, although in a slightly different form.", "labels": [], "entities": []}, {"text": "For very small and very large training sets, the systems perform about the same.", "labels": [], "entities": []}, {"text": "Between these extremes, the discriminative tagger exhibits somewhat, though not distressingly, worse performance.", "labels": [], "entities": []}, {"text": "We conjecture that lack of smoothing in the discriminative tagger may account for the difference.", "labels": [], "entities": []}, {"text": "Second, we consider the impact of word clusters.", "labels": [], "entities": []}, {"text": "compares performance of the discriminative tagger, now with cluster features included, to the baseline HMM.", "labels": [], "entities": []}, {"text": "Immediately, with only 5,000 words of training, the discriminative model significantly outperforms the HMM.", "labels": [], "entities": []}, {"text": "With 50,000 words of training, performance for the discriminative model exceeds 90F, a level not reached by the HMM until it has observed 150,000 words of training.", "labels": [], "entities": []}, {"text": "Somewhat surprisingly, the clusters continue to provide some benefit even with 1,000,000 words of training.", "labels": [], "entities": []}, {"text": "At this operating point, the discriminative tagger achieves an F-score of 96.08 compared to 94.72 for the HMM, a 25% reduction in error.", "labels": [], "entities": [{"text": "F-score", "start_pos": 63, "end_pos": 70, "type": "METRIC", "confidence": 0.9997432827949524}, {"text": "error", "start_pos": 130, "end_pos": 135, "type": "METRIC", "confidence": 0.9779319167137146}]}, {"text": "Third, we consider the impact of active learning.", "labels": [], "entities": []}, {"text": "shows (a) discriminative tagger performance without cluster features, (b) the same tagger using active learning, (c) the discriminative tagger with cluster features, and (d) the discriminative tagger with cluster features using active learning.", "labels": [], "entities": []}, {"text": "Both with and without clusters, active learning exhibits a noticeable increase in learning rates.", "labels": [], "entities": []}, {"text": "However, the increase in learning rate is significantly more pronounced when cluster features are introduced.", "labels": [], "entities": [{"text": "learning rate", "start_pos": 25, "end_pos": 38, "type": "METRIC", "confidence": 0.8843415081501007}]}, {"text": "We attribute this increase to better confidence measures provided byword clusters -the system is no longer restricted to whether or not it knows a word; it now can know something about the clusters to which a word belongs, even if it does not know the word.", "labels": [], "entities": []}, {"text": "Finally, shows the impact of consolidating the gains from both cluster features and active learning compared to the baseline HMM.", "labels": [], "entities": []}, {"text": "This final combination achieves an F-score of 90 with less than 20,000 words of training -a quantity that can be annotated in about 4 person hours -compared to 150,000 words for the HMM -a quantity requiring nearly 4 person days to annotate.", "labels": [], "entities": [{"text": "F-score", "start_pos": 35, "end_pos": 42, "type": "METRIC", "confidence": 0.9994633793830872}]}, {"text": "At 1,000,000 word of training, the final combination continues to exhibit a 25% reduction in error over the baseline system (because of limitations in the experimental framework discussed earlier, active learning can provide no additional gain at this operating point).", "labels": [], "entities": [{"text": "error", "start_pos": 93, "end_pos": 98, "type": "METRIC", "confidence": 0.9763566255569458}]}], "tableCaptions": [{"text": " Table 1: Sample bit strings", "labels": [], "entities": []}]}