{"title": [{"text": "Direct Maximization of Average Precision by Hill-Climbing, with a Comparison to a Maximum Entropy Approach", "labels": [], "entities": [{"text": "Maximum Entropy Approach", "start_pos": 82, "end_pos": 106, "type": "METRIC", "confidence": 0.5536530613899231}]}], "abstractContent": [{"text": "We describe an algorithm for choosing term weights to maximize average precision.", "labels": [], "entities": [{"text": "precision", "start_pos": 71, "end_pos": 80, "type": "METRIC", "confidence": 0.9355348348617554}]}, {"text": "The algorithm performs successive exhaustive searches through single directions in weight space.", "labels": [], "entities": []}, {"text": "It makes use of a novel technique for considering all possible values of average precision that arise in searching fora maximum in a given direction.", "labels": [], "entities": [{"text": "precision", "start_pos": 81, "end_pos": 90, "type": "METRIC", "confidence": 0.8014349937438965}]}, {"text": "We apply the algorithm and compare this algorithm to a maximum entropy approach.", "labels": [], "entities": []}], "introductionContent": [{"text": "This paper presents an algorithm for searching term weight space by directly hill-climbing on average precision.", "labels": [], "entities": [{"text": "precision", "start_pos": 102, "end_pos": 111, "type": "METRIC", "confidence": 0.9349938631057739}]}, {"text": "Given a query and a topic-that is, given a set of terms, and a set of documents, some of which are marked \"relevant\"-the algorithm chooses weights that maximize the average precision of the document set when sorted by the sum of the weighted terms.", "labels": [], "entities": [{"text": "precision", "start_pos": 173, "end_pos": 182, "type": "METRIC", "confidence": 0.9825939536094666}]}, {"text": "We show that this algorithm, when used in the larger context of finding \"optimal\" queries, performs similar to a maximum entropy approach, which does not climb directly on average precision.", "labels": [], "entities": [{"text": "precision", "start_pos": 180, "end_pos": 189, "type": "METRIC", "confidence": 0.9675101637840271}]}, {"text": "This work is part of a larger research program on the study of optimal queries.", "labels": [], "entities": []}, {"text": "Optimal queries, for our purposes, are queries that best distinguish relevant from nonrelevant documents fora corpus drawn from some larger (theoretical) population of documents.", "labels": [], "entities": []}, {"text": "Although both performance on the training data and generalization ability are components of optimal queries, in this paper we focus only on the former.", "labels": [], "entities": []}], "datasetContent": [{"text": "In order to compare the results of the weight search algorithm to those of the maximum entropy model, we employed the same experiment setup.", "labels": [], "entities": []}, {"text": "We ran on 15 topics, which were manually selected from the TREC 6, 7, and 8 collections), with the objective of creating a representative subset.", "labels": [], "entities": [{"text": "TREC 6", "start_pos": 59, "end_pos": 65, "type": "DATASET", "confidence": 0.8675079345703125}]}, {"text": "The document sets were divided into randomly selected training, validation and test \"splits\", comprising 25%, 25%, and 50%, respectively, of the complete set.", "labels": [], "entities": []}, {"text": "For each query, a set of candidate terms was selected based on mutual information between (binary) term occurrence and document relevance.", "labels": [], "entities": []}, {"text": "From this set, terms were chosen individually to be included in the query, and coefficients for all terms were calculated using L-BFGS, a quasi-Newton unconstrained optimization algorithm ().", "labels": [], "entities": []}, {"text": "For experimenting with the weight search algorithm, we investigated queries of length 1 through 20 for each topic, so each topic involved 20 experiments.", "labels": [], "entities": [{"text": "weight search", "start_pos": 27, "end_pos": 40, "type": "TASK", "confidence": 0.7046422362327576}]}, {"text": "The first term weight was fixed at 1.0.", "labels": [], "entities": []}, {"text": "The single-term queries did not require a weight search, as the weight of a single term does not affect the average precision score.", "labels": [], "entities": [{"text": "precision score", "start_pos": 116, "end_pos": 131, "type": "METRIC", "confidence": 0.9674991369247437}]}, {"text": "For the remaining 19 experiments for each topic, the direction vectors \u03c9 were chosen such that the algorithm searched a single term weight at a time.", "labels": [], "entities": []}, {"text": "For example, a query with  i terms used the i \u2212 1 directions . The two-term query fora topic started the search from the point \u03c0 2,0 = \ud97b\udf591 0\ud97b\udf59, and each successive experiment for that topic was initialized with the starting point \u03c0 0 equal to the final point in the previous iteration, concatenated with a 0.", "labels": [], "entities": []}, {"text": "The \"value vectors\" \u03c5 j used in all experiments were Okapi tf scores.", "labels": [], "entities": []}], "tableCaptions": []}