{"title": [{"text": "Acquiring Hyponymy Relations from Web Documents", "labels": [], "entities": [{"text": "Acquiring Hyponymy Relations from Web Documents", "start_pos": 0, "end_pos": 47, "type": "TASK", "confidence": 0.7621388336022695}]}], "abstractContent": [{"text": "This paper describes an automatic method for acquiring hyponymy relations from HTML documents on the WWW.", "labels": [], "entities": [{"text": "acquiring hyponymy relations from HTML documents on the WWW", "start_pos": 45, "end_pos": 104, "type": "TASK", "confidence": 0.6081550386216905}]}, {"text": "Hyponymy relations can play a crucial role in various natural language processing systems.", "labels": [], "entities": []}, {"text": "Most existing acquisition methods for hyponymy relations rely on particular linguistic patterns, such as \"NP such as NP\".", "labels": [], "entities": []}, {"text": "Our method, however, does not use such linguistic patterns, and we expect that our procedure can be applied to a wide range of expressions for which existing methods cannot be used.", "labels": [], "entities": []}, {"text": "Our acquisition algorithm uses clues such as itemization or listing in HTML documents and statistical measures such as document frequencies and verb-noun co-occurrences.", "labels": [], "entities": []}], "introductionContent": [{"text": "The goal of this work is to become able to automatically acquire hyponymy relations fora wide range of words or phrases from HTML documents on the WWW.", "labels": [], "entities": [{"text": "WWW", "start_pos": 147, "end_pos": 150, "type": "DATASET", "confidence": 0.6616262197494507}]}, {"text": "We do not use particular lexicosyntactic patterns, as previous attempts have).", "labels": [], "entities": []}, {"text": "The frequencies of use for such lexicosyntactic patterns are relatively low, and there can be many words or phrases that do not appear in such patterns even if we look at a large number of texts.", "labels": [], "entities": []}, {"text": "The effort of searching for other clues indicating hyponymy relations is thus significant.", "labels": [], "entities": []}, {"text": "We try to acquire hyponymy relations by combining three different types of clue obtainable from a wide range of words or phrases.", "labels": [], "entities": []}, {"text": "The first type of clue is inclusion in itemizations or lists found in typical HTML documents on the WWW.", "labels": [], "entities": [{"text": "inclusion", "start_pos": 26, "end_pos": 35, "type": "METRIC", "confidence": 0.8818951845169067}]}, {"text": "The second consists of statistical measures such as the document frequency (df) and the inverse document frequency (idf), which are Assumption B Given a set of hyponyms that have a common hypernym, the hypernym appears in many documents that include the hyponyms.", "labels": [], "entities": [{"text": "document frequency (df)", "start_pos": 56, "end_pos": 79, "type": "METRIC", "confidence": 0.8104382693767548}, {"text": "inverse document frequency (idf)", "start_pos": 88, "end_pos": 120, "type": "METRIC", "confidence": 0.8079850524663925}, {"text": "Assumption", "start_pos": 132, "end_pos": 142, "type": "METRIC", "confidence": 0.9793654680252075}]}, {"text": "Assumption C Hyponyms and their hypernyms are semantically similar.", "labels": [], "entities": []}, {"text": "Our acquisition process computes a common hypernym for expressions in the same itemizations.", "labels": [], "entities": []}, {"text": "First, we download a large number of HTML documents from the WWW and extract a set of natural language expressions that are listed in the same itemized region of documents.", "labels": [], "entities": [{"text": "HTML documents from the WWW", "start_pos": 37, "end_pos": 64, "type": "DATASET", "confidence": 0.5854272365570068}]}, {"text": "We extract the set of expressions, {Toyota, Honda, Nissan} from it.", "labels": [], "entities": []}, {"text": "From Assumption A, we can treat these expressions as candidates of hyponyms that have a common hypernym such as \"company\".", "labels": [], "entities": []}, {"text": "We call such expressions in the same itemization hyponym candidates.", "labels": [], "entities": []}, {"text": "Particularly, a set of the hyponym candidates extracted from a single itemization or list is called a hyponym candidate set (HCS).", "labels": [], "entities": []}, {"text": "For the example document, we would treat Toyota, Honda, and Nissan as hyponym candidates, and regard them as members of the same HCS.", "labels": [], "entities": [{"text": "HCS", "start_pos": 129, "end_pos": 132, "type": "DATASET", "confidence": 0.8756566047668457}]}, {"text": "We then download documents that include at least one hyponym candidate by using an existing search engine, and pickup a noun that appears in the documents and that has the largest score.", "labels": [], "entities": []}, {"text": "The score was designed so that words appearing in many downloaded documents are highly ranked, according to Assumption B. We call the selected noun a hypernym candidate for the given hyponym candidates.", "labels": [], "entities": [{"text": "Assumption B.", "start_pos": 108, "end_pos": 121, "type": "METRIC", "confidence": 0.9644680023193359}]}, {"text": "Note that if we download documents including \"Toyota\" or \"Honda\", many will include the word \"company\", which is a true hypernym of Toyota.", "labels": [], "entities": []}, {"text": "However, words which are not hypernyms, but which are closely associated with Toyota or Honda (e.g., \"price\") will also be included in many of the downloaded documents.", "labels": [], "entities": []}, {"text": "The next step of our procedure is designed to exclude such nonhypernyms according to Assumption C. We compute the similarity between hypernym candidates and hyponym candidates in an HCS, and eliminate the HCS and its hypernym candidate from the output if they are not semantically similar.", "labels": [], "entities": [{"text": "Assumption", "start_pos": 85, "end_pos": 95, "type": "METRIC", "confidence": 0.9807091951370239}]}, {"text": "For instance, if the previous step of our procedure produces \"price\" as a hypernym candidate for Toyota and Honda, then the hypernym candidate and the hyponym candidates are removed from the output.", "labels": [], "entities": []}, {"text": "We empirically show that this helps to improve overall precision.", "labels": [], "entities": [{"text": "precision", "start_pos": 55, "end_pos": 64, "type": "METRIC", "confidence": 0.9986047148704529}]}, {"text": "Finally, we further elaborate computed hypernym candidates by using additional heuristic rules.", "labels": [], "entities": []}, {"text": "Though we admit that these rules are rather ad hoc, they worked well in our experiments.", "labels": [], "entities": []}, {"text": "We have tested the effectiveness of our methods through a series of experiments in which we used HTML documents downloaded from actual web sites.", "labels": [], "entities": []}, {"text": "We observed that our method can find a significant number of hypernyms that (at least some of) alternative hypernym acquisition procedures cannot acquire, at least, when only a rather small amount of texts are available.", "labels": [], "entities": []}, {"text": "In this paper, Section 2 describes our acquisition algorithm.", "labels": [], "entities": []}, {"text": "Section 3 gives our experimental results which we obtained using Japanese HTML documents, and Section 4 discusses the benefit obtained through our method based on a comparison with alternative methods.", "labels": [], "entities": []}], "datasetContent": [{"text": "We downloaded about 8.71 \u00d7 10 5 HTML documents (10.4 GB with HTML tags), and extracted 9.02 \u00d7 10 4 HCSs through the method described in Section 2.1.", "labels": [], "entities": []}, {"text": "We Figure 4: Contribution of each step and rule randomly picked 2,000 HCSs from among the extracted HCS as our test set.", "labels": [], "entities": []}, {"text": "The test set contained 13,790 hyponym candidates.", "labels": [], "entities": []}, {"text": "(Besides these HCSs, we used a development set consisting of about 4,000 HCSs to develop our algorithm.)", "labels": [], "entities": []}, {"text": "For each single hyponym candidate, we downloaded the top 100 documents in the ranking produced by a search engine 5 as a local document set if the engine found more than 100 documents.", "labels": [], "entities": []}, {"text": "Otherwise, all the documents were downloaded.", "labels": [], "entities": []}, {"text": "(Note that a local document set for an HCS may contain more than 100 documents.)", "labels": [], "entities": []}, {"text": "As a global document set, we used the downloaded 1.00 \u00d7 10 6 HTML documents (1.26 GB without HTML tags).", "labels": [], "entities": []}, {"text": "shows the accuracy of hypernyms obtained after Steps 2, 3, and 4.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9996436834335327}]}, {"text": "We assumed each step produced the sorted pairs of an HCS and a hypernym, which are denoted by {{h(C 1 ), The sorting was done by the score sim(h after Steps 3 and 4, as described before, while the output of Step 2 was sorted by the df \u00b7 idf score.", "labels": [], "entities": []}, {"text": "In addition, we assumed The search engine \"goo\".", "labels": [], "entities": []}, {"text": "Step 4 is the final output, this means that we also assumed that only the top 200 pairs of a hypernym and an HCS would be produced as final output with our procedure.", "labels": [], "entities": [{"text": "HCS", "start_pos": 109, "end_pos": 112, "type": "DATASET", "confidence": 0.884357750415802}]}, {"text": "In other words, the remaining 1,800 (=2,000-200) pairs were discarded.", "labels": [], "entities": []}, {"text": ") The resulting hypernyms were checked by the authors according to the definition of the hypernym given in, i.e., we checked if the expression \"a hyponym candidate is a kind of a hypernym candidate.\" is acceptable.", "labels": [], "entities": []}, {"text": "Then, we computed the precision, which is the ratio of the correct hypernym-hyponym pairs against all the pairs obtained from the top n pairs of an HCS and its hypernym candidate.", "labels": [], "entities": [{"text": "precision", "start_pos": 22, "end_pos": 31, "type": "METRIC", "confidence": 0.9995269775390625}]}, {"text": "The x-axis of the graph indicates the number of hypernym-hyponym pairs obtained from the top n pairs of an HCS and its hypernym candidate, while the y-axis indicates the precision.", "labels": [], "entities": [{"text": "precision", "start_pos": 170, "end_pos": 179, "type": "METRIC", "confidence": 0.99904865026474}]}, {"text": "More precisely, the curve for Step i plots the following points, where 1 \u2264 j \u2264 200.", "labels": [], "entities": []}, {"text": "indicates the number of hyponym candidates in C k that are true hyponyms of h(C k ).", "labels": [], "entities": []}, {"text": "Note that after Step 4, the precision reached about 75% for 701 hyponym candidates, which was slightly more than 5% of all the given hyponym candidates.", "labels": [], "entities": [{"text": "precision", "start_pos": 28, "end_pos": 37, "type": "METRIC", "confidence": 0.9995113611221313}]}, {"text": "For 1398 hyponym candidates (about 10% of all the candidates), the precision was about 61%.", "labels": [], "entities": [{"text": "precision", "start_pos": 67, "end_pos": 76, "type": "METRIC", "confidence": 0.9979385733604431}]}, {"text": "Another important point is that \"Step 2 (tf)\" in the graph refers to an alternative to our Step 2 procedure; i.e., the Step 2 procedure in which df (h(C), LD(C)) was replaced by tf (h(C), LD(C)).", "labels": [], "entities": []}, {"text": "One can seethe Step 2 procedure with df works better than that with tf . shows some examples of the acquired HCSs and their common hypernyms.", "labels": [], "entities": []}, {"text": "Recall that a common suffix of an HCS is a good candidate to be a hypernym.", "labels": [], "entities": []}, {"text": "The examples were taken from cases where a common suffix hypernymhyponym,hyponym .* .* hypernym, hyponym .* (| )?", "labels": [], "entities": []}, {"text": "hypernym, hyponym .* .* hypernym, hyponym .* .* hypernym, hyponym .* ( | ) .* hypernym, hyponym .* .* hypernym, hyponym .* ( | ) .* hypernym The hypernym and hyponym maybe bracketed byor \"\".: lexicosyntactic patterns of an HCS was not produced as a hypernym.", "labels": [], "entities": []}, {"text": "This list is actually the output of Step 3, and shows which HCSs and their hypernym candidates were eliminated/modified from the output in Step 4 and which rule was fired to eliminate/modify them.", "labels": [], "entities": []}, {"text": "Next, we eliminated some steps from the whole procedure.", "labels": [], "entities": []}, {"text": "shows the accuracy when one of the steps was eliminated from the procedure.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9997153878211975}]}, {"text": "\"-Step X\" or \"-Rule X\" refers to the accuracies obtained through the procedure from which step X or rule X were eliminated.", "labels": [], "entities": []}, {"text": "Note that both graphs indicate that every step and rule contributed to the improvement of the precision.", "labels": [], "entities": [{"text": "precision", "start_pos": 94, "end_pos": 103, "type": "METRIC", "confidence": 0.9989099502563477}]}, {"text": "compares our method and an alternative method, which was the algorithm that re-ranks the top j hypernym candidates fora given HCS by using the score where h is a hypernym candidate, in Step 3.", "labels": [], "entities": [{"text": "HCS", "start_pos": 126, "end_pos": 129, "type": "DATASET", "confidence": 0.8844195604324341}]}, {"text": "(Recall that our algorithm uses the score only for sorting pairs of HCSs and their hypernym.", "labels": [], "entities": []}, {"text": "In other words, we do not re-rank the hypernym candidates fora single HCS.)", "labels": [], "entities": [{"text": "HCS", "start_pos": 70, "end_pos": 73, "type": "DATASET", "confidence": 0.831317663192749}]}, {"text": "We found no significant improvement when the alternative was used.", "labels": [], "entities": []}], "tableCaptions": []}