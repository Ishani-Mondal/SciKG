{"title": [{"text": "Lattice-Based Search for Spoken Utterance Retrieval", "labels": [], "entities": [{"text": "Spoken Utterance Retrieval", "start_pos": 25, "end_pos": 51, "type": "TASK", "confidence": 0.8293988903363546}]}], "abstractContent": [{"text": "Recent work on spoken document retrieval has suggested that it is adequate to take the single-best output of ASR, and perform text retrieval on this output.", "labels": [], "entities": [{"text": "spoken document retrieval", "start_pos": 15, "end_pos": 40, "type": "TASK", "confidence": 0.6270798643430074}, {"text": "ASR", "start_pos": 109, "end_pos": 112, "type": "TASK", "confidence": 0.9486498236656189}, {"text": "text retrieval", "start_pos": 126, "end_pos": 140, "type": "TASK", "confidence": 0.767851322889328}]}, {"text": "This is reasonable enough for the task of retrieving broadcast news stories, where word error rates are relatively low, and the stories are long enough to contain much redundancy.", "labels": [], "entities": [{"text": "retrieving broadcast news stories", "start_pos": 42, "end_pos": 75, "type": "TASK", "confidence": 0.900691956281662}, {"text": "word error rates", "start_pos": 83, "end_pos": 99, "type": "METRIC", "confidence": 0.7929065624872843}]}, {"text": "But it is patently not reasonable if one's task is to retrieve a short snippet of speech in a domain where WER's can be as high as 50%; such would be the situation with teleconference speech, where one's task is to find if and when a participant uttered a certain phrase.", "labels": [], "entities": [{"text": "WER's", "start_pos": 107, "end_pos": 112, "type": "METRIC", "confidence": 0.9616700112819672}]}, {"text": "In this paper we propose an indexing procedure for spoken utterance retrieval that works on lattices rather than just single-best text.", "labels": [], "entities": [{"text": "spoken utterance retrieval", "start_pos": 51, "end_pos": 77, "type": "TASK", "confidence": 0.7711348533630371}]}, {"text": "We demonstrate that this procedure can improve F scores by over five points compared to single-best retrieval on tasks with poor WER and low redundancy.", "labels": [], "entities": [{"text": "F scores", "start_pos": 47, "end_pos": 55, "type": "METRIC", "confidence": 0.9878624379634857}, {"text": "WER", "start_pos": 129, "end_pos": 132, "type": "METRIC", "confidence": 0.9912959337234497}]}, {"text": "The representation is flexible so that we can represent both word lattices, as well as phone lattices, the latter being important for improving performance when searching for phrases containing OOV words.", "labels": [], "entities": []}], "introductionContent": [{"text": "Automatic systems for indexing, archiving, searching and browsing of large amounts of spoken communications have become a reality in the last decade.", "labels": [], "entities": [{"text": "archiving, searching and browsing of large amounts of spoken communications", "start_pos": 32, "end_pos": 107, "type": "TASK", "confidence": 0.5813307437029752}]}, {"text": "Most such systems use an automatic speech recognition (ASR) component to convert speech to text which is then used as an input to a standard text based information retrieval (IR) component.", "labels": [], "entities": [{"text": "automatic speech recognition (ASR)", "start_pos": 25, "end_pos": 59, "type": "TASK", "confidence": 0.8198452393213908}, {"text": "text based information retrieval (IR)", "start_pos": 141, "end_pos": 178, "type": "TASK", "confidence": 0.7640676072665623}]}, {"text": "This strategy works reasonably well when speech recognition output is mostly corrector the documents are long enough so that some occurrences of the query terms are recognized correctly.", "labels": [], "entities": []}, {"text": "Most of the research has concentrated on retrieval of Broadcast News type of spoken documents where speech is relatively clean and the documents are relatively long.", "labels": [], "entities": [{"text": "Broadcast News type of spoken documents", "start_pos": 54, "end_pos": 93, "type": "DATASET", "confidence": 0.8272326787312826}]}, {"text": "In addition it is possible to find large amounts of text with similar content in order to build better language models and enhance retrieval through use of similar documents.", "labels": [], "entities": []}, {"text": "We are interested in extending this to telephone conversations and teleconferences.", "labels": [], "entities": []}, {"text": "Our task is locating occurrences of a query in spoken communications to aid browsing.", "labels": [], "entities": [{"text": "locating occurrences of a query in spoken communications", "start_pos": 12, "end_pos": 68, "type": "TASK", "confidence": 0.7476576268672943}]}, {"text": "This is not exactly spoken document retrieval.", "labels": [], "entities": [{"text": "spoken document retrieval", "start_pos": 20, "end_pos": 45, "type": "TASK", "confidence": 0.643086830774943}]}, {"text": "In fact, it is more similar to word spotting.", "labels": [], "entities": [{"text": "word spotting", "start_pos": 31, "end_pos": 44, "type": "TASK", "confidence": 0.7718996703624725}]}, {"text": "Each document is a short segment of audio.", "labels": [], "entities": []}, {"text": "Although reasonable retrieval performance can be obtained using the best ASR hypothesis for tasks with moderate (\u223c 20%) word error rates, tasks with higher (40 \u2212 50%) word error rates require use of multiple ASR hypotheses.", "labels": [], "entities": [{"text": "ASR", "start_pos": 73, "end_pos": 76, "type": "TASK", "confidence": 0.899280309677124}]}, {"text": "Use of ASR lattices makes the system more robust to recognition errors.", "labels": [], "entities": []}, {"text": "Almost all ASR systems have a closed vocabulary.", "labels": [], "entities": [{"text": "ASR", "start_pos": 11, "end_pos": 14, "type": "TASK", "confidence": 0.9776071310043335}]}, {"text": "This restriction comes from run-time requirements as well as the finite amount of data used for training the language models of the ASR systems.", "labels": [], "entities": [{"text": "ASR", "start_pos": 132, "end_pos": 135, "type": "TASK", "confidence": 0.9608473777770996}]}, {"text": "Typically the recognition vocabulary is taken to be the words appearing in the language model training corpus.", "labels": [], "entities": []}, {"text": "Sometimes the vocabulary is further reduced to only include the most frequent words in the corpus.", "labels": [], "entities": []}, {"text": "The words that are not in this closed vocabulary -the out of vocabulary (OOV) words -will not be recognized by the ASR system, contributing to recognition errors.", "labels": [], "entities": [{"text": "ASR", "start_pos": 115, "end_pos": 118, "type": "TASK", "confidence": 0.9496946334838867}]}, {"text": "The effects of OOV words in spoken document retrieval are discussed by.", "labels": [], "entities": [{"text": "spoken document retrieval", "start_pos": 28, "end_pos": 53, "type": "TASK", "confidence": 0.6455098390579224}]}, {"text": "Using phonetic search helps retrieve OOV words.", "labels": [], "entities": []}, {"text": "This paper is organized as follows.", "labels": [], "entities": []}, {"text": "In Section 2 we give an overview of related work, focusing on methods dealing with speech recognition errors and OOV queries.", "labels": [], "entities": [{"text": "speech recognition errors", "start_pos": 83, "end_pos": 108, "type": "TASK", "confidence": 0.8025720516840616}]}, {"text": "We present the methods used in this study in Section 3.", "labels": [], "entities": []}, {"text": "Experimental setup and results are given in Section 4.", "labels": [], "entities": []}, {"text": "Finally, our conclusions are presented in Section 5.", "labels": [], "entities": []}], "datasetContent": [{"text": "For evaluating ASR performance we use the standard word error rate (WER) as our metric.", "labels": [], "entities": [{"text": "ASR", "start_pos": 15, "end_pos": 18, "type": "TASK", "confidence": 0.9965601563453674}, {"text": "standard word error rate (WER)", "start_pos": 42, "end_pos": 72, "type": "METRIC", "confidence": 0.8418827482632228}]}, {"text": "Since we are interested in retrieval we use OOV rate by type to measure the OOV word characteristics.", "labels": [], "entities": [{"text": "OOV rate", "start_pos": 44, "end_pos": 52, "type": "METRIC", "confidence": 0.8286782205104828}]}, {"text": "For evaluating retrieval performance we use precision and recall with respect to manual transcriptions.", "labels": [], "entities": [{"text": "precision", "start_pos": 44, "end_pos": 53, "type": "METRIC", "confidence": 0.9995884299278259}, {"text": "recall", "start_pos": 58, "end_pos": 64, "type": "METRIC", "confidence": 0.9992480874061584}]}, {"text": "Let Correct(q) be the number of times the query q is found correctly, Answer(q) be the number of answers to the query q, and Reference(q) be the number of times q is found in the reference.", "labels": [], "entities": [{"text": "Correct(q)", "start_pos": 4, "end_pos": 14, "type": "METRIC", "confidence": 0.934136226773262}, {"text": "Answer(q)", "start_pos": 70, "end_pos": 79, "type": "METRIC", "confidence": 0.94906285405159}, {"text": "Reference(q)", "start_pos": 125, "end_pos": 137, "type": "METRIC", "confidence": 0.9285311102867126}]}, {"text": "We compute precision and recall rates for each query and report the average overall queries.", "labels": [], "entities": [{"text": "precision", "start_pos": 11, "end_pos": 20, "type": "METRIC", "confidence": 0.9992989301681519}, {"text": "recall", "start_pos": 25, "end_pos": 31, "type": "METRIC", "confidence": 0.9979196190834045}]}, {"text": "The set of queries Q consists of all the words seen in the reference except fora stoplist of 100 most common words.", "labels": [], "entities": []}, {"text": "The measurement is not weighted by frequency -i.e. each query q \u2208 Q is presented to the system only once, independent of the number of occurences of q in the transcriptions.", "labels": [], "entities": []}, {"text": "For lattice based retrieval methods, different operating points can be obtained by changing the threshold.", "labels": [], "entities": []}, {"text": "The precision and recall at these operating points can be plotted as a curve.", "labels": [], "entities": [{"text": "precision", "start_pos": 4, "end_pos": 13, "type": "METRIC", "confidence": 0.9995478987693787}, {"text": "recall", "start_pos": 18, "end_pos": 24, "type": "METRIC", "confidence": 0.9994230270385742}]}, {"text": "In addition to individual precision-recall values we also compute the F-measure defined as F = 2 \u00d7 Precision \u00d7 Recall Precision + Recall and report the maximum F-measure (maxF) to summarize the information in a precision-recall curve.", "labels": [], "entities": [{"text": "precision-recall", "start_pos": 26, "end_pos": 42, "type": "METRIC", "confidence": 0.9738403558731079}, {"text": "F-measure", "start_pos": 70, "end_pos": 79, "type": "METRIC", "confidence": 0.9845691323280334}, {"text": "F = 2 \u00d7 Precision \u00d7 Recall Precision + Recall", "start_pos": 91, "end_pos": 136, "type": "METRIC", "confidence": 0.6633350640535355}, {"text": "F-measure (maxF)", "start_pos": 160, "end_pos": 176, "type": "METRIC", "confidence": 0.9328661561012268}]}], "tableCaptions": [{"text": " Table 1: Word Error Rate (WER) and OOV Rate (by  type) of various LVCSR tasks", "labels": [], "entities": [{"text": "Word Error Rate (WER)", "start_pos": 10, "end_pos": 31, "type": "METRIC", "confidence": 0.842838317155838}, {"text": "OOV Rate", "start_pos": 36, "end_pos": 44, "type": "METRIC", "confidence": 0.9862411022186279}]}, {"text": " Table 2: Precision Recall for ASR 1-best", "labels": [], "entities": [{"text": "Precision Recall", "start_pos": 10, "end_pos": 26, "type": "METRIC", "confidence": 0.7991848289966583}, {"text": "ASR 1-best", "start_pos": 31, "end_pos": 41, "type": "METRIC", "confidence": 0.6262768059968948}]}, {"text": " Table 3: Comparison of index sizes", "labels": [], "entities": []}, {"text": " Table 4: Comparison of different sources for the phone  index on the Teleconferences corpus", "labels": [], "entities": [{"text": "Teleconferences", "start_pos": 70, "end_pos": 85, "type": "DATASET", "confidence": 0.9471315741539001}]}, {"text": " Table 6: Results for word pair queries on Switchboard", "labels": [], "entities": [{"text": "word pair queries", "start_pos": 22, "end_pos": 39, "type": "TASK", "confidence": 0.7659962972005209}, {"text": "Switchboard", "start_pos": 43, "end_pos": 54, "type": "TASK", "confidence": 0.41051754355430603}]}, {"text": " Table 7: Maximum F-measure for various systems and  tasks", "labels": [], "entities": [{"text": "F-measure", "start_pos": 18, "end_pos": 27, "type": "METRIC", "confidence": 0.9553630352020264}]}]}