{"title": [{"text": "Improvements in Phrase-Based Statistical Machine Translation", "labels": [], "entities": [{"text": "Phrase-Based Statistical Machine Translation", "start_pos": 16, "end_pos": 60, "type": "TASK", "confidence": 0.8312182277441025}]}], "abstractContent": [{"text": "In statistical machine translation, the currently best performing systems are based in someway on phrases or word groups.", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 3, "end_pos": 34, "type": "TASK", "confidence": 0.6680394212404887}]}, {"text": "We describe the baseline phrase-based translation system and various refinements.", "labels": [], "entities": [{"text": "phrase-based translation", "start_pos": 25, "end_pos": 49, "type": "TASK", "confidence": 0.6304284483194351}]}, {"text": "We describe a highly efficient monotone search algorithm with a complexity linear in the input sentence length.", "labels": [], "entities": []}, {"text": "We present translation results for three tasks: Verb-mobil, Xerox and the Canadian Hansards.", "labels": [], "entities": [{"text": "Verb-mobil", "start_pos": 48, "end_pos": 58, "type": "DATASET", "confidence": 0.9427518844604492}, {"text": "Xerox", "start_pos": 60, "end_pos": 65, "type": "DATASET", "confidence": 0.8518163561820984}, {"text": "Canadian Hansards", "start_pos": 74, "end_pos": 91, "type": "DATASET", "confidence": 0.8157623112201691}]}, {"text": "For the Xerox task, it takes less than 7 seconds to translate the whole test set consisting of more than 10K words.", "labels": [], "entities": []}, {"text": "The translation results for the Xerox and Canadian Hansards task are very promising.", "labels": [], "entities": [{"text": "translation", "start_pos": 4, "end_pos": 15, "type": "TASK", "confidence": 0.9735941886901855}, {"text": "Canadian Hansards task", "start_pos": 42, "end_pos": 64, "type": "DATASET", "confidence": 0.8569755951563517}]}, {"text": "The system even outperforms the alignment template system.", "labels": [], "entities": [{"text": "alignment template", "start_pos": 32, "end_pos": 50, "type": "TASK", "confidence": 0.8908812403678894}]}], "introductionContent": [{"text": "In statistical machine translation, we are given a source language ('French') sentence f J 1 = f 1 . .", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 3, "end_pos": 34, "type": "TASK", "confidence": 0.6925295988718668}]}, {"text": "f J , which is to be translated into a target language ('English') sentence e I 1 = e 1 . .", "labels": [], "entities": []}, {"text": "e I . Among all possible target language sentences, we will choose the sentence with the highest probability: = argmax The decomposition into two knowledge sources in Equation 2 is known as the source-channel approach to statistical machine translation (.", "labels": [], "entities": [{"text": "argmax", "start_pos": 112, "end_pos": 118, "type": "METRIC", "confidence": 0.959933876991272}, {"text": "statistical machine translation", "start_pos": 221, "end_pos": 252, "type": "TASK", "confidence": 0.6522917846838633}]}, {"text": "It allows an independent modeling of target language model P r(e I 1 ) and translation model P r(f J 1 |e I 1 ) 1 . The target language The notational convention will be as follows: we use the symbol P r(\u00b7) to denote general probability distributions with (nearly) no specific assumptions.", "labels": [], "entities": []}, {"text": "In contrast, for model-based probability distributions, we use the generic symbol p(\u00b7).", "labels": [], "entities": []}, {"text": "model describes the well-formedness of the target language sentence.", "labels": [], "entities": []}, {"text": "The translation model links the source language sentence to the target language sentence.", "labels": [], "entities": []}, {"text": "It can be further decomposed into alignment and lexicon model.", "labels": [], "entities": []}, {"text": "The argmax operation denotes the search problem, i.e. the generation of the output sentence in the target language.", "labels": [], "entities": []}, {"text": "We have to maximize overall possible target language sentences.", "labels": [], "entities": []}, {"text": "An alternative to the classical source-channel approach is the direct modeling of the posterior probability P r(e I 1 |f J 1 ).", "labels": [], "entities": [{"text": "posterior probability P r", "start_pos": 86, "end_pos": 111, "type": "METRIC", "confidence": 0.8888882249593735}]}, {"text": "Using a log-linear model ), we obtain: Here, Z(f J 1 ) denotes the appropriate normalization constant.", "labels": [], "entities": []}, {"text": "As a decision rule, we obtain: This approach is a generalization of the source-channel approach.", "labels": [], "entities": []}, {"text": "It has the advantage that additional models or feature functions can be easily integrated into the overall system.", "labels": [], "entities": []}, {"text": "The model scaling factors \u03bb M 1 are trained according to the maximum entropy principle, e.g. using the GIS algorithm.", "labels": [], "entities": []}, {"text": "Alternatively, one can train them with respect to the final translation quality measured by some error criterion.", "labels": [], "entities": []}, {"text": "The remaining part of this work is structured as follows: in the next section, we will describe the baseline phrase-based translation model and the extraction of bilingual phrases.", "labels": [], "entities": [{"text": "phrase-based translation", "start_pos": 109, "end_pos": 133, "type": "TASK", "confidence": 0.598996564745903}]}, {"text": "Then, we will describe refinements of the baseline model.", "labels": [], "entities": []}, {"text": "In Section 4, we will describe a monotone search algorithm.", "labels": [], "entities": []}, {"text": "Its complexity is linear in the sentence length.", "labels": [], "entities": []}, {"text": "The next section contains the statistics of the corpora that were used.", "labels": [], "entities": []}, {"text": "Then, we will investigate the degree of monotonicity and present the translation results for three tasks: Verbmobil, Xerox and Canadian Hansards.", "labels": [], "entities": [{"text": "Verbmobil", "start_pos": 106, "end_pos": 115, "type": "DATASET", "confidence": 0.9110069870948792}, {"text": "Canadian Hansards", "start_pos": 127, "end_pos": 144, "type": "DATASET", "confidence": 0.8764891624450684}]}], "datasetContent": [{"text": "So far, in machine translation research a single generally accepted criterion for the evaluation of the experimental results does not exist.", "labels": [], "entities": [{"text": "machine translation research", "start_pos": 11, "end_pos": 39, "type": "TASK", "confidence": 0.8611829082171122}]}, {"text": "Therefore, we use a variety of different criteria.", "labels": [], "entities": []}, {"text": "\u2022 WER (word error rate): The WER is computed as the minimum number of substitution, insertion and deletion operations that have to be performed to convert the generated sentence into the reference sentence.", "labels": [], "entities": [{"text": "WER (word error rate)", "start_pos": 2, "end_pos": 23, "type": "METRIC", "confidence": 0.8476704061031342}, {"text": "WER", "start_pos": 29, "end_pos": 32, "type": "METRIC", "confidence": 0.9945435523986816}]}, {"text": "\u2022 PER (position-independent word error rate): A shortcoming of the WER is that it requires a perfect word order.", "labels": [], "entities": [{"text": "PER", "start_pos": 2, "end_pos": 5, "type": "METRIC", "confidence": 0.9972148537635803}, {"text": "position-independent word error rate)", "start_pos": 7, "end_pos": 44, "type": "METRIC", "confidence": 0.7197307765483856}, {"text": "WER", "start_pos": 67, "end_pos": 70, "type": "METRIC", "confidence": 0.7456610202789307}]}, {"text": "The word order of an acceptable sentence can be different from that of the target sentence, so that the WER measure alone could be misleading.", "labels": [], "entities": [{"text": "WER measure", "start_pos": 104, "end_pos": 115, "type": "METRIC", "confidence": 0.9848631024360657}]}, {"text": "The PER compares the words in the two sentences ignoring the word order.", "labels": [], "entities": [{"text": "PER", "start_pos": 4, "end_pos": 7, "type": "METRIC", "confidence": 0.9520605206489563}]}, {"text": "\u2022 BLEU score: This score measures the precision of unigrams, bigrams, trigrams and fourgrams with respect to a reference translation with a penalty for too short sentences ().", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 2, "end_pos": 12, "type": "METRIC", "confidence": 0.9864911735057831}, {"text": "precision", "start_pos": 38, "end_pos": 47, "type": "METRIC", "confidence": 0.9988828301429749}]}, {"text": "BLEU measures accuracy, i.e. large BLEU scores are better.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 0, "end_pos": 4, "type": "METRIC", "confidence": 0.9884402751922607}, {"text": "accuracy", "start_pos": 14, "end_pos": 22, "type": "METRIC", "confidence": 0.9994174242019653}, {"text": "BLEU", "start_pos": 35, "end_pos": 39, "type": "METRIC", "confidence": 0.9987710118293762}]}, {"text": "\u2022 NIST score: This score is similar to BLEU.", "labels": [], "entities": [{"text": "NIST score", "start_pos": 2, "end_pos": 12, "type": "METRIC", "confidence": 0.8348874449729919}, {"text": "BLEU", "start_pos": 39, "end_pos": 43, "type": "METRIC", "confidence": 0.9900132417678833}]}, {"text": "It is a weighted ngram precision in combination with a penalty for too short sentences).", "labels": [], "entities": [{"text": "weighted ngram precision", "start_pos": 8, "end_pos": 32, "type": "METRIC", "confidence": 0.5655646622180939}]}, {"text": "NIST measures accuracy, i.e. large NIST scores are better.", "labels": [], "entities": [{"text": "NIST", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.8189612627029419}, {"text": "accuracy", "start_pos": 14, "end_pos": 22, "type": "METRIC", "confidence": 0.9991021156311035}]}, {"text": "For the Verbmobil task, we have multiple references available.", "labels": [], "entities": []}, {"text": "Therefore on this task, we compute all the preceding criteria with respect to multiple references.", "labels": [], "entities": []}, {"text": "To indicate this, we will precede the acronyms with an m (multiple) if multiple references are used.", "labels": [], "entities": []}, {"text": "For the other two tasks, only single references are used.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Statistics of training and test corpus for the Verb- mobil task (PP=perplexity).", "labels": [], "entities": []}, {"text": " Table 2: Statistics of training and test corpus for the Xe- rox task (PP=perplexity).  Spanish English  Train Sentences  55 761  Words  752 606 665 399  Vocabulary  11 050  7 956  Dev  Sentences  1012  Words  15 957  14 278  Trigram PP  - 28.1  Test  Sentences  1125  Words  10 106  8 370  Trigram PP  - 48.3", "labels": [], "entities": []}, {"text": " Table 3: Statistics of training and test corpus for the  Canadian Hansards task (PP=perplexity).  French English  Train Sentences  1.5M  Words  24M  22M  Vocabulary 100 269  78 332  Dev  Sentences  500  Words  9 043  8 195  Trigram PP  - 57.7  Test  Sentences  5432  Words  97 646  88 773  Trigram PP  - 56.7", "labels": [], "entities": [{"text": "Canadian Hansards task", "start_pos": 58, "end_pos": 80, "type": "DATASET", "confidence": 0.8812670111656189}, {"text": "French English  Train Sentences  1.5M  Words  24M  22M  Vocabulary 100", "start_pos": 99, "end_pos": 169, "type": "DATASET", "confidence": 0.8853824436664581}]}, {"text": " Table 4: Degree of monotonicity in the training corpora  for all three tasks (numbers in percent).  Verbmobil Xerox Hansards  nonmonotone  76.3  75.1  59.7  monotone  55.4  65.3  51.5  deg. of mon.  72.6  87.0  86.3", "labels": [], "entities": [{"text": "Verbmobil Xerox Hansards", "start_pos": 101, "end_pos": 125, "type": "DATASET", "confidence": 0.9156651695569357}]}, {"text": " Table 5: Effect of lexicon smoothing on the translation  performance [%] for the German-English Verbmobil task.  system  mWER mPER BLEU NIST  unsmoothed  37.3  21.1  46.6  7.96  uniform  37.0  20.7  47.0  7.99  unigram  38.2  22.3  45.5  7.79", "labels": [], "entities": [{"text": "BLEU", "start_pos": 132, "end_pos": 136, "type": "METRIC", "confidence": 0.9784470200538635}]}, {"text": " Table 6. Obviously, the monotone phrase-based  system outperforms the monotone single-word based sys- tem. The result of the phrase-based system is comparable  to the nonmonotone single-word based search with the  IBM constraints. With respect to the mPER, the PB sys- tem clearly outperforms all single-word based systems.", "labels": [], "entities": []}, {"text": " Table 6: Translation performance [%] for the German- English Verbmobil task (251 sentences).", "labels": [], "entities": [{"text": "Translation", "start_pos": 10, "end_pos": 21, "type": "TASK", "confidence": 0.96610027551651}, {"text": "German- English Verbmobil task", "start_pos": 46, "end_pos": 76, "type": "DATASET", "confidence": 0.6270778775215149}]}, {"text": " Table 7: Translation performance [%] for the Spanish- English Xerox task (1125 sentences).", "labels": [], "entities": [{"text": "Translation", "start_pos": 10, "end_pos": 21, "type": "TASK", "confidence": 0.9618768692016602}, {"text": "Spanish- English Xerox task", "start_pos": 46, "end_pos": 73, "type": "TASK", "confidence": 0.45741853713989256}]}, {"text": " Table 8: Translation performance [%] for the French- English Canadian Hansards task (5432 sentences).", "labels": [], "entities": [{"text": "Translation", "start_pos": 10, "end_pos": 21, "type": "TASK", "confidence": 0.9663648009300232}, {"text": "French- English Canadian Hansards task", "start_pos": 46, "end_pos": 84, "type": "DATASET", "confidence": 0.6967684278885523}]}, {"text": " Table 9: Translation Speed for all tasks on a AMD Athlon  2.2GHz.", "labels": [], "entities": [{"text": "Translation", "start_pos": 10, "end_pos": 21, "type": "TASK", "confidence": 0.9366699457168579}, {"text": "AMD Athlon  2.2GHz", "start_pos": 47, "end_pos": 65, "type": "DATASET", "confidence": 0.8430315852165222}]}]}