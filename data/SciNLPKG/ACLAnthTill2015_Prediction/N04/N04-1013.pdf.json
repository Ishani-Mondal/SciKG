{"title": [{"text": "Speed and Accuracy in Shallow and Deep Stochastic Parsing", "labels": [], "entities": [{"text": "Speed", "start_pos": 0, "end_pos": 5, "type": "METRIC", "confidence": 0.9598215222358704}, {"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9837735891342163}]}], "abstractContent": [{"text": "This paper reports some experiments that compare the accuracy and performance of two stochastic parsing systems.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 53, "end_pos": 61, "type": "METRIC", "confidence": 0.9981884360313416}]}, {"text": "The currently popular Collins parser is a shallow parser whose output contains more detailed semantically-relevant information than other such parsers.", "labels": [], "entities": [{"text": "Collins", "start_pos": 22, "end_pos": 29, "type": "DATASET", "confidence": 0.9372610449790955}]}, {"text": "The XLE parser is a deep-parsing system that couples a Lexical Functional Grammar to a log-linear disambiguation component and provides much richer representations theory.", "labels": [], "entities": []}, {"text": "We measured the accuracy of both systems against a gold standard of the PARC 700 dependency bank, and also measured their processing times.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 16, "end_pos": 24, "type": "METRIC", "confidence": 0.9996166229248047}, {"text": "PARC 700 dependency bank", "start_pos": 72, "end_pos": 96, "type": "DATASET", "confidence": 0.948648676276207}]}, {"text": "We found the deep-parsing system to be more accurate than the Collins parser with only a slight reduction in parsing speed.", "labels": [], "entities": [{"text": "parsing", "start_pos": 109, "end_pos": 116, "type": "TASK", "confidence": 0.9608349800109863}]}], "introductionContent": [{"text": "In applications that are sensitive to the meanings expressed by natural language sentences, it has become common in recent years simply to incorporate publicly available statistical parsers.", "labels": [], "entities": []}, {"text": "A state-of-the-art statistical parsing system that enjoys great popularity in research systems is the parser described in Collins (1999) (henceforth \"the Collins parser\").", "labels": [], "entities": [{"text": "statistical parsing", "start_pos": 19, "end_pos": 38, "type": "TASK", "confidence": 0.6928602159023285}, {"text": "Collins (1999)", "start_pos": 122, "end_pos": 136, "type": "DATASET", "confidence": 0.9300888180732727}]}, {"text": "This system not only is frequently used for off-line data preprocessing, but also is included as a black-box component for applications such as document summarization), information extraction (), machine translation, and question answering ().", "labels": [], "entities": [{"text": "document summarization", "start_pos": 144, "end_pos": 166, "type": "TASK", "confidence": 0.7258013188838959}, {"text": "information extraction", "start_pos": 169, "end_pos": 191, "type": "TASK", "confidence": 0.8366959095001221}, {"text": "machine translation", "start_pos": 196, "end_pos": 215, "type": "TASK", "confidence": 0.8308236300945282}, {"text": "question answering", "start_pos": 221, "end_pos": 239, "type": "TASK", "confidence": 0.9047890603542328}]}, {"text": "This is be-cause the Collins parser shares the property of robustness with other statistical parsers, but more than other such parsers, the categories of its parse-trees make grammatical distinctions that presumably are useful for meaningsensitive applications.", "labels": [], "entities": []}, {"text": "For example, the categories of the Model 3 Collins parser distinguish between heads, arguments, and adjuncts and they mark some longdistance dependency paths; these distinctions can guide application-specific postprocessors in extracting important semantic relations.", "labels": [], "entities": []}, {"text": "In contrast, state-of-the-art parsing systems based on deep grammars mark explicitly and in much more detail a wider variety of syntactic and semantic dependencies and should therefore provide even better support for meaning-sensitive applications.", "labels": [], "entities": []}, {"text": "But common wisdom has it that parsing systems based on deep linguistic grammars are too difficult to produce, lack coverage and robustness, and also have poor run-time performance.", "labels": [], "entities": [{"text": "coverage", "start_pos": 115, "end_pos": 123, "type": "METRIC", "confidence": 0.9780703186988831}]}, {"text": "The Collins parser is thought to be accurate and fast and thus to represent a reasonable trade-off between \"good-enough\" output, speed, and robustness.", "labels": [], "entities": [{"text": "Collins", "start_pos": 4, "end_pos": 11, "type": "DATASET", "confidence": 0.8922836184501648}, {"text": "accurate", "start_pos": 36, "end_pos": 44, "type": "METRIC", "confidence": 0.9594259262084961}, {"text": "speed", "start_pos": 129, "end_pos": 134, "type": "METRIC", "confidence": 0.9697878956794739}]}, {"text": "This paper reports on some experiments that put this conventional wisdom to an empirical test.", "labels": [], "entities": []}, {"text": "We investigated the accuracy of recovering semantically-relevant grammatical dependencies from the tree-structures produced by the Collins parser, comparing these dependencies to gold-standard dependencies which are available fora subset of 700 sentences randomly drawn from section 23 of the Wall Street Journal (see).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 20, "end_pos": 28, "type": "METRIC", "confidence": 0.9953096508979797}, {"text": "Wall Street Journal", "start_pos": 293, "end_pos": 312, "type": "DATASET", "confidence": 0.9488013386726379}]}, {"text": "We compared the output of the XLE system, a deep-grammar-based parsing system using the English Lexical-Functional Grammar previously constructed as part of the Pargram project (), to the same gold standard.", "labels": [], "entities": []}, {"text": "This system incorporates sophisticated ambiguity-management technology so that all possible syntactic analyses of a sentence are computed in an efficient, packed representation ().", "labels": [], "entities": []}, {"text": "In accordance with LFG theory, the output includes not only standard context-free phrase-structure trees but also attribute-value matrices (LFG's f(unctional) structures) that explicitly encode predicate-argument relations and other meaningful properties.", "labels": [], "entities": []}, {"text": "XLE selects the most probable analysis from the potentially large candidate set by means of a stochastic disambiguation component based on a log-linear (a.k.a. maximum-entropy) probability model ().", "labels": [], "entities": []}, {"text": "The stochastic component is also \"ambiguity-enabled\" in the sense that the computations for statistical estimation and selection of the most probable analyses are done efficiently by dynamic programming, avoiding the need to unpack the parse forests and enumerate individual analyses.", "labels": [], "entities": [{"text": "statistical estimation", "start_pos": 92, "end_pos": 114, "type": "TASK", "confidence": 0.7701397836208344}]}, {"text": "The underlying parsing system also has built-in robustness mechanisms that allow it to parse strings that are outside the scope of the grammar as a shortest sequence of wellformed \"fragments\".", "labels": [], "entities": []}, {"text": "Furthermore, performance parameters that bound parsing and disambiguation work can be tuned for efficient but accurate operation.", "labels": [], "entities": [{"text": "parsing", "start_pos": 47, "end_pos": 54, "type": "TASK", "confidence": 0.9688085317611694}]}, {"text": "As part of our assessment, we also measured the parsing speed of the two systems, taking into account all stages of processing that each system requires to produce its output.", "labels": [], "entities": [{"text": "parsing", "start_pos": 48, "end_pos": 55, "type": "TASK", "confidence": 0.9605478048324585}]}, {"text": "For example, since the Collins parser depends on a prior part-of-speech tagger, we included the time for POS tagging in our Collins measurements.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 105, "end_pos": 116, "type": "TASK", "confidence": 0.8140442967414856}]}, {"text": "XLE incorporates a sophisticated finite-state morphology and dictionary lookup component, and its time is part of the measure of XLE performance.", "labels": [], "entities": []}, {"text": "Performance parameters of both the Collins parser and the XLE system were adjusted on a heldout set consisting of a random selection of 1/5 of the PARC 700 dependency bank; experimental results were then based on the other 560 sentences.", "labels": [], "entities": [{"text": "Collins", "start_pos": 35, "end_pos": 42, "type": "DATASET", "confidence": 0.951524019241333}, {"text": "PARC 700 dependency bank", "start_pos": 147, "end_pos": 171, "type": "DATASET", "confidence": 0.9142877906560898}]}, {"text": "For Model 3 of the Collins parser, abeam size of 1000, and not the recommended beam size of 10000, was found to optimize parsing speed at little loss inaccuracy.", "labels": [], "entities": [{"text": "Collins parser", "start_pos": 19, "end_pos": 33, "type": "TASK", "confidence": 0.6977952420711517}, {"text": "parsing", "start_pos": 121, "end_pos": 128, "type": "TASK", "confidence": 0.9617162942886353}]}, {"text": "On the same heldout set, parameters of the stochastic disambiguation system and parameters for parsing performance were adjusted fora Core and a Complete version of the XLE system, differing in the size of the constraint-set of the underlying grammar.", "labels": [], "entities": []}, {"text": "For both XLE and the Collins parser we wrote conversion programs to transform the normal (tree or fstructure) output into the corresponding relations of the dependency bank.", "labels": [], "entities": []}, {"text": "This conversion was relatively straightforward for LFG structures (.", "labels": [], "entities": []}, {"text": "However, a certain amount of skill and intuition was required to provide a fair conversion of the Collins trees: we did not want to penalize configurations in the Collins trees that encoded alternative but equally legitimate representations of the same linguistic properties (e.g. whether auxiliaries are encoded as main verbs or aspect features), but we also did not want to build into the conversion program transformations that compensate for information that Collins cannot provide without appealing to additional linguistic resources (such as identifying the subjects of infinitival complements).", "labels": [], "entities": [{"text": "Collins trees", "start_pos": 98, "end_pos": 111, "type": "DATASET", "confidence": 0.9038875997066498}]}, {"text": "We did not include the time for dependency conversion in our measures of performance.", "labels": [], "entities": [{"text": "dependency conversion", "start_pos": 32, "end_pos": 53, "type": "TASK", "confidence": 0.8540845513343811}]}, {"text": "The experimental results show that stochastic parsing with the Core LFG grammar achieves a better F-score than the Collins parser at a roughly comparable parsing speed.", "labels": [], "entities": [{"text": "Core LFG grammar", "start_pos": 63, "end_pos": 79, "type": "DATASET", "confidence": 0.7070947289466858}, {"text": "F-score", "start_pos": 98, "end_pos": 105, "type": "METRIC", "confidence": 0.9989863038063049}]}, {"text": "The XLE system achieves 12% reduction in error rate over the Collins parser, that is 77.6% F-score for the XLE system versus 74.6% for the Collins parser, at a cost in parsing time of a factor of 1.49.", "labels": [], "entities": [{"text": "error rate", "start_pos": 41, "end_pos": 51, "type": "METRIC", "confidence": 0.9175634980201721}, {"text": "F-score", "start_pos": 91, "end_pos": 98, "type": "METRIC", "confidence": 0.9996116757392883}, {"text": "parsing", "start_pos": 168, "end_pos": 175, "type": "TASK", "confidence": 0.9525594115257263}]}], "datasetContent": [{"text": "We conducted our experiments by preparing versions of the test sentences in the form appropriate to each system.", "labels": [], "entities": []}, {"text": "We used a configuration of the XLE parser that expects sentences conforming to ordinary text conventions to appear in a file separated by double line-feeds.", "labels": [], "entities": []}, {"text": "Since the PARC 700 treats proper names as multiword expressions, we then augmented the input strings with XML markup of the named entities.", "labels": [], "entities": [{"text": "PARC 700", "start_pos": 10, "end_pos": 18, "type": "DATASET", "confidence": 0.8821592032909393}]}, {"text": "These are parsed by the grammar as described in section 2.", "labels": [], "entities": []}, {"text": "We used manual named entity markup for this experiment because our intent is to measure parsing technology independent of either the time or errors of an automatic named-entity extractor.", "labels": [], "entities": [{"text": "parsing", "start_pos": 88, "end_pos": 95, "type": "TASK", "confidence": 0.8784939646720886}]}, {"text": "However, in other experiments with an automatic finite-state extractor, we have found that the time for named-entity recognition is negligible (on the order of seconds across the entire corpus) and makes relatively few errors, so that the results reported here are good approximations of what might be expected in more realistic situations.", "labels": [], "entities": [{"text": "named-entity recognition", "start_pos": 104, "end_pos": 128, "type": "TASK", "confidence": 0.7391515076160431}]}, {"text": "As input to the Collins parser, we used the part-ofspeech tagged version of section 23 that was provided with the parser.", "labels": [], "entities": [{"text": "Collins", "start_pos": 16, "end_pos": 23, "type": "DATASET", "confidence": 0.9616500735282898}]}, {"text": "From this we extracted the 700 sentences in the PARC 700.", "labels": [], "entities": [{"text": "PARC 700", "start_pos": 48, "end_pos": 56, "type": "DATASET", "confidence": 0.9187383651733398}]}, {"text": "We then modified them to produce named entity input so that the parses would match the PARC 700.", "labels": [], "entities": [{"text": "PARC 700", "start_pos": 87, "end_pos": 95, "type": "DATASET", "confidence": 0.9641508758068085}]}, {"text": "This was done by putting underscores between the parts of the named entity and changing the final part of speech tag to the appropriate one (usually NNP) if necessary.", "labels": [], "entities": []}, {"text": "(The number of words indicated at the beginning of the input string was also reduced accordingly.)", "labels": [], "entities": []}, {"text": "An example is shown in (1).", "labels": [], "entities": []}, {"text": "After parsing, the underscores were converted to spaces to match the PARC 700 predicates.", "labels": [], "entities": [{"text": "parsing", "start_pos": 6, "end_pos": 13, "type": "TASK", "confidence": 0.973202109336853}, {"text": "PARC 700 predicates", "start_pos": 69, "end_pos": 88, "type": "DATASET", "confidence": 0.9471976359685262}]}, {"text": "Before the final evaluation, 1/5 of the PARC 700 dependency bank was randomly extracted as a heldout set.", "labels": [], "entities": [{"text": "PARC 700 dependency bank", "start_pos": 40, "end_pos": 64, "type": "DATASET", "confidence": 0.9420321136713028}]}, {"text": "This set was used to adjust the performance parameters of the XLE system and the Collins parser so as to optimize parsing speed without losing accuracy.", "labels": [], "entities": [{"text": "Collins", "start_pos": 81, "end_pos": 88, "type": "DATASET", "confidence": 0.9647388458251953}, {"text": "accuracy", "start_pos": 143, "end_pos": 151, "type": "METRIC", "confidence": 0.996086597442627}]}, {"text": "For example, the limit on the length of medial phrases was set to 20 words for the XLE system (see Sec.", "labels": [], "entities": []}, {"text": "2), and a regularizer penalty of 10 was found optimal for the 1 prior used in stochastic disambiguation.", "labels": [], "entities": []}, {"text": "For the Collins parser, abeam size of 1000 was found to improve speed considerably at little cost inaccuracy.", "labels": [], "entities": [{"text": "Collins parser", "start_pos": 8, "end_pos": 22, "type": "DATASET", "confidence": 0.9013399183750153}, {"text": "speed", "start_pos": 64, "end_pos": 69, "type": "METRIC", "confidence": 0.9910280108451843}]}, {"text": "Furthermore, the np-bracketing flag (npbflag) was set to 0 to produce an extended set of NP levels for improved argument/adjunct distinction 6 . The final evaluation was done on the remaining 560 examples.", "labels": [], "entities": []}, {"text": "Timing results are reported in seconds of CPU time . POS tagging of the input to the Collins parser took 6 seconds and this was added to the timing result of the Collins parser.", "labels": [], "entities": [{"text": "Timing", "start_pos": 0, "end_pos": 6, "type": "METRIC", "confidence": 0.9462027549743652}, {"text": "POS tagging", "start_pos": 53, "end_pos": 64, "type": "TASK", "confidence": 0.8156358599662781}, {"text": "Collins", "start_pos": 85, "end_pos": 92, "type": "DATASET", "confidence": 0.9278296232223511}, {"text": "timing", "start_pos": 141, "end_pos": 147, "type": "METRIC", "confidence": 0.9882510304450989}, {"text": "Collins parser", "start_pos": 162, "end_pos": 176, "type": "DATASET", "confidence": 0.9098342955112457}]}, {"text": "Time spent for finite-state morphology and dictionary lookup for XLE is part of the measure of its timing performance.", "labels": [], "entities": []}, {"text": "We did not include the time for dependency extraction or stemming the Collins output.", "labels": [], "entities": [{"text": "dependency extraction", "start_pos": 32, "end_pos": 53, "type": "TASK", "confidence": 0.9152690172195435}, {"text": "Collins output", "start_pos": 70, "end_pos": 84, "type": "DATASET", "confidence": 0.8187119364738464}]}, {"text": "shows timing and accuracy results for the Reduced dependency set.", "labels": [], "entities": [{"text": "timing", "start_pos": 6, "end_pos": 12, "type": "METRIC", "confidence": 0.9960153698921204}, {"text": "accuracy", "start_pos": 17, "end_pos": 25, "type": "METRIC", "confidence": 0.9926316738128662}]}, {"text": "The parser settings compared are Model 3 of the Collins parser adjusted to beam size 1000, and the Core and Complete versions of the XLE system, differing in the size of the grammar's constraintset.", "labels": [], "entities": [{"text": "Collins", "start_pos": 48, "end_pos": 55, "type": "DATASET", "confidence": 0.9599646329879761}]}, {"text": "Clearly, both versions of the XLE system achieve a significant reduction in error rate over the Collins parser (12% for the core XLE system and 20% for the complete system) at an increase in parsing time of a factor of only 1.49 for the core XLE system.", "labels": [], "entities": [{"text": "error rate", "start_pos": 76, "end_pos": 86, "type": "METRIC", "confidence": 0.9847517311573029}]}, {"text": "The complete version gives an overall improvement in F-score of 5% over the Collins parser at a cost of a factor of 5 in parsing time.", "labels": [], "entities": [{"text": "F-score", "start_pos": 53, "end_pos": 60, "type": "METRIC", "confidence": 0.9996058344841003}, {"text": "Collins parser", "start_pos": 76, "end_pos": 90, "type": "DATASET", "confidence": 0.8887735307216644}]}], "tableCaptions": [{"text": " Table 1: Timing and accuracy results for Collins parser  and Complete and Core versions of XLE system on Re- duced version of PARC 700 dependency bank.", "labels": [], "entities": [{"text": "Timing", "start_pos": 10, "end_pos": 16, "type": "METRIC", "confidence": 0.8908919095993042}, {"text": "accuracy", "start_pos": 21, "end_pos": 29, "type": "METRIC", "confidence": 0.997225284576416}, {"text": "Collins", "start_pos": 42, "end_pos": 49, "type": "DATASET", "confidence": 0.9711685180664062}, {"text": "PARC 700 dependency bank", "start_pos": 127, "end_pos": 151, "type": "DATASET", "confidence": 0.9384384602308273}]}]}