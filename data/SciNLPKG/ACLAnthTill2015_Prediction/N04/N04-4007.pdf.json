{"title": [{"text": "Advances in Children's Speech Recognition within an Interactive Literacy Tutor", "labels": [], "entities": [{"text": "Children's Speech Recognition", "start_pos": 12, "end_pos": 41, "type": "TASK", "confidence": 0.6000918075442314}]}], "abstractContent": [{"text": "1 In this paper we present recent advances in acoustic and language modeling that improve recognition performance when children readout loud within digital books.", "labels": [], "entities": []}, {"text": "First we extend previous work by incorporating cross-utterance word history information and dynamic n-gram language modeling.", "labels": [], "entities": []}, {"text": "By additionally incorporating Vocal Tract Length Normalization (VTLN), Speaker-Adaptive Training (SAT) and iterative unsupervised structural maximum a posteriori linear regression (SMAPLR) adaptation we demonstrate a 54% reduction in word error rate.", "labels": [], "entities": [{"text": "Vocal Tract Length Normalization (VTLN", "start_pos": 30, "end_pos": 68, "type": "TASK", "confidence": 0.6574925283590952}, {"text": "Speaker-Adaptive Training (SAT)", "start_pos": 71, "end_pos": 102, "type": "METRIC", "confidence": 0.603528869152069}, {"text": "word error rate", "start_pos": 234, "end_pos": 249, "type": "METRIC", "confidence": 0.6505023042360941}]}, {"text": "Next, we show how data from children's read-aloud sessions can be utilized to improve accuracy in a spontaneous story summarization task.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 86, "end_pos": 94, "type": "METRIC", "confidence": 0.9979732632637024}, {"text": "spontaneous story summarization task", "start_pos": 100, "end_pos": 136, "type": "TASK", "confidence": 0.7245931625366211}]}, {"text": "An error reduction of 15% over previous published results is shown.", "labels": [], "entities": [{"text": "error", "start_pos": 3, "end_pos": 8, "type": "METRIC", "confidence": 0.9929060935974121}]}, {"text": "Finally we describe a novel real-time implementation of our research system that incorporates time-adaptive acoustic and language modeling.", "labels": [], "entities": []}], "introductionContent": [{"text": "Pioneering research by MIT and CMU as well as more recent work by the IBM Watch-me-Read Project have demonstrated that speech recognition can play an effective role in systems designed to improve children's reading abilities (.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 119, "end_pos": 137, "type": "TASK", "confidence": 0.7222208380699158}]}, {"text": "In CMU's Project LISTEN, for example, the tutor operates by prompting children to read individual sentences out loud.", "labels": [], "entities": [{"text": "CMU's Project LISTEN", "start_pos": 3, "end_pos": 23, "type": "DATASET", "confidence": 0.8745466619729996}]}, {"text": "The tutor listens to the child using speech recognition and extracts features that can be used to detect oral reading miscues ().", "labels": [], "entities": []}, {"text": "Upon detecting reading miscues, the tutor provides appropriate feedback to the child.", "labels": [], "entities": []}, {"text": "Recent re- sults show that such automated reading tutors can improve student achievement ( ).", "labels": [], "entities": []}, {"text": "Providing real time feedback by highlighting words as the are readout loud is the basis of at least one commercial product today (http://www.soliloquy.com).  and) describe anew scientifically-based literacy program, Foundations to Fluency, in which a virtual tutor-a lifelike 3D computer model-interacts with children in multimodal learning tasks to teach them to read.", "labels": [], "entities": []}, {"text": "A key component of this program is the Interactive Book, which combines real-time speech recognition, facial animation, and natural language understanding capabilities to teach children to read and comprehend text.", "labels": [], "entities": []}, {"text": "Interactive Books are designed to improve student achievement by helping students to learn to read fluently, to acquire new knowledge through deep understanding of what they read, to make connections to other knowledge, and to express their ideas concisely through spoken or written summaries.", "labels": [], "entities": []}, {"text": "Transcribed spoken summaries can be graded automatically to provide feedback to the student about their comprehension.", "labels": [], "entities": [{"text": "Transcribed spoken summaries", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.6773697932561239}]}, {"text": "During reading out loud activities in Interactive Books, the goal is to design a computer interface and speech recognizer that combine to teach the student to read fluently and naturally.", "labels": [], "entities": [{"text": "speech recognizer", "start_pos": 104, "end_pos": 121, "type": "TASK", "confidence": 0.7190321683883667}]}, {"text": "Here, speech recognition is used to track a child's position within the text during read-aloud sessions in addition to providing timing and confidence information which can be used for reading assessment.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 6, "end_pos": 24, "type": "TASK", "confidence": 0.7195972800254822}, {"text": "timing", "start_pos": 129, "end_pos": 135, "type": "METRIC", "confidence": 0.9934850335121155}]}, {"text": "The speech recognizer must follow the students verbal behaviors accurately and quickly, so the cursor (or highlighted word) appears at the right place and right time when the student is reading fluently, and pauses when the student hesitates to sound out a word.", "labels": [], "entities": [{"text": "speech recognizer", "start_pos": 4, "end_pos": 21, "type": "TASK", "confidence": 0.70185986161232}]}, {"text": "The recognizer must also score mispronounced words accurately so that the student can revisit these words and receive feedback about their pronunciation after completing a paragraph or page (since highlighting hypothesized mispronounced words when reading out loud may disrupt fluent reading behavior).", "labels": [], "entities": []}, {"text": "In this paper we focus on the problem of speech recognition to track and provide feedback during reading out loud and to transcribe spoken summaries of text.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 41, "end_pos": 59, "type": "TASK", "confidence": 0.7200409024953842}, {"text": "transcribe spoken summaries of text", "start_pos": 121, "end_pos": 156, "type": "TASK", "confidence": 0.8435204863548279}]}, {"text": "Specifically, we describe several new methods for incorporating language modeling knowledge into the read aloud task.", "labels": [], "entities": [{"text": "language modeling knowledge", "start_pos": 64, "end_pos": 91, "type": "TASK", "confidence": 0.7847701112429301}]}, {"text": "In addition, through use of speaker adaptation, we also demonstrate the potential for significant gains in recognition accuracy.", "labels": [], "entities": [{"text": "speaker adaptation", "start_pos": 28, "end_pos": 46, "type": "TASK", "confidence": 0.7487261593341827}, {"text": "accuracy", "start_pos": 119, "end_pos": 127, "type": "METRIC", "confidence": 0.9347085356712341}]}, {"text": "Finally, we leverage improvements in speech recognition for read aloud tracking to improve performance for spoken story summarization.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 37, "end_pos": 55, "type": "TASK", "confidence": 0.7091533243656158}, {"text": "read aloud tracking", "start_pos": 60, "end_pos": 79, "type": "TASK", "confidence": 0.6591337124506632}, {"text": "spoken story summarization", "start_pos": 107, "end_pos": 133, "type": "TASK", "confidence": 0.7013532121976217}]}, {"text": "Work reported here extends previous work in several important ways: by integrating the research advances into areal time system, and by including timeadaptive language modeling and time-adaptive acoustic modeling of the child's voice into the system.", "labels": [], "entities": []}, {"text": "The paper is organized as follows.", "labels": [], "entities": []}, {"text": "2 describes our baseline speech recognition system and reading tracking method.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 25, "end_pos": 43, "type": "TASK", "confidence": 0.7005615234375}, {"text": "reading tracking", "start_pos": 55, "end_pos": 71, "type": "TASK", "confidence": 0.8091892302036285}]}, {"text": "3 presents our rationale for using word-error-rate as a measure of performance.", "labels": [], "entities": []}, {"text": "4 describes the read aloud and story summarization corpora used in this work.", "labels": [], "entities": []}, {"text": "5 describes and evaluates proposed improvements in a read aloud speech recognition task.", "labels": [], "entities": [{"text": "read aloud speech recognition task", "start_pos": 53, "end_pos": 87, "type": "TASK", "confidence": 0.6824181497097015}]}, {"text": "6 describes how these improvements translate to improved recognition of story summaries produced by a child.", "labels": [], "entities": [{"text": "recognition of story summaries produced", "start_pos": 57, "end_pos": 96, "type": "TASK", "confidence": 0.9107629537582398}]}, {"text": "7 details our real-time system implementation.", "labels": [], "entities": []}], "datasetContent": [{"text": "There are many different ways in which speech recognition can be used to serve children.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 39, "end_pos": 57, "type": "TASK", "confidence": 0.7904150187969208}]}, {"text": "In computer-based literacy tutors, speech recognition can be used to measure children's ability to read fluently and pronounce words while reading out loud, to engage in spoken dialogues with an animated agent to assess and train comprehension, or to transcribe spoken summaries of stories that can be graded automatically.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 35, "end_pos": 53, "type": "TASK", "confidence": 0.7421261668205261}, {"text": "transcribe spoken summaries of stories", "start_pos": 251, "end_pos": 289, "type": "TASK", "confidence": 0.7921227931976318}]}, {"text": "Because of the variety of ways of using speech recognition systems, it is critically important to establish common metrics that are used by the research community so that progress can be measured both within and across systems.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 40, "end_pos": 58, "type": "TASK", "confidence": 0.7023670971393585}]}, {"text": "For this reason, we argue that word error rate calculations using the widely accepted NIST scoring software provides the most widely accepted, easy to use and highly valid metric.", "labels": [], "entities": [{"text": "word error rate", "start_pos": 31, "end_pos": 46, "type": "METRIC", "confidence": 0.5735066135724386}, {"text": "NIST scoring software", "start_pos": 86, "end_pos": 107, "type": "DATASET", "confidence": 0.8506211638450623}]}, {"text": "In this scoring procedure, word error rate is computed strictly by comparing the speech recognizer output against a known human transcription (or the text in a book).", "labels": [], "entities": [{"text": "word error rate", "start_pos": 27, "end_pos": 42, "type": "METRIC", "confidence": 0.6425977349281311}]}, {"text": "Of course, authors are free to define and report other measures, such as detection/false alarm curves for useful events such as reading miscues.", "labels": [], "entities": [{"text": "detection/false alarm curves", "start_pos": 73, "end_pos": 101, "type": "METRIC", "confidence": 0.6220057427883148}]}, {"text": "However, such analyses should always supplement reports of word error rates using a single standardized measure.", "labels": [], "entities": [{"text": "word error rates", "start_pos": 59, "end_pos": 75, "type": "METRIC", "confidence": 0.6550115545590719}]}, {"text": "Adopting this strategy enables fair and balanced comparisons within and across systems for any speech data given a known word-level transcription.", "labels": [], "entities": []}, {"text": "For all experiments in this paper we use speech data and associated transcriptions from 106 children (grade 3: 17 speakers, grade 4: 28 speakers, and grade 5: 61 speakers) who were asked to read one often stories and to provide a spoken story summary.", "labels": [], "entities": []}, {"text": "The 16 kHz audio data contains an average of 1054 words (min 532 words; max 1926 words) with an average of 413 unique words per story.", "labels": [], "entities": []}, {"text": "The resulting summaries spoken by children contain an average of 168 words.", "labels": [], "entities": []}, {"text": "The resulting text is used to estimate a back-off trigram language model.", "labels": [], "entities": []}, {"text": "We stress that only the story text is used to construct the language model.", "labels": [], "entities": []}, {"text": "Details on the story texts are provided in.", "labels": [], "entities": []}, {"text": "Note that the sentence markers (<s> and </s>) are used to represent positions of expected speaker pause.", "labels": [], "entities": []}, {"text": "This baseline system is shown in(A) to produce a 17.4% word error rate.", "labels": [], "entities": [{"text": "word error rate", "start_pos": 55, "end_pos": 70, "type": "METRIC", "confidence": 0.7596550981203715}]}], "tableCaptions": [{"text": " Table 1: Recognition of children's read out-loud data.", "labels": [], "entities": [{"text": "Recognition of children's read out-loud", "start_pos": 10, "end_pos": 49, "type": "TASK", "confidence": 0.8648623128732046}]}, {"text": " Table 2: Recognition of spontaneous story summaries", "labels": [], "entities": [{"text": "Recognition of spontaneous story summaries", "start_pos": 10, "end_pos": 52, "type": "TASK", "confidence": 0.8597835421562194}]}]}