{"title": [{"text": "A Smorgasbord of Features for Statistical Machine Translation", "labels": [], "entities": [{"text": "Statistical Machine Translation", "start_pos": 30, "end_pos": 61, "type": "TASK", "confidence": 0.8883474270502726}]}], "abstractContent": [{"text": "We describe a methodology for rapid experimentation in statistical machine translation which we use to add a large number of features to a baseline system exploiting features from a wide range of levels of syntactic representation.", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 55, "end_pos": 86, "type": "TASK", "confidence": 0.6992378532886505}]}, {"text": "Feature values were combined in a log-linear model to select the highest scoring candidate translation from an n-best list.", "labels": [], "entities": []}, {"text": "Feature weights were optimized directly against the BLEU evaluation metric on held-out data.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 52, "end_pos": 56, "type": "METRIC", "confidence": 0.9917786717414856}]}, {"text": "We present results fora small selection of features at each level of syntactic representation.", "labels": [], "entities": []}], "introductionContent": [{"text": "Despite the enormous progress in machine translation (MT) due to the use of statistical techniques in recent years, state-of-the-art statistical systems often produce translations with obvious errors.", "labels": [], "entities": [{"text": "machine translation (MT)", "start_pos": 33, "end_pos": 57, "type": "TASK", "confidence": 0.8575513482093811}]}, {"text": "Grammatical errors include lack of a main verb, wrong word order, and wrong choice of function words.", "labels": [], "entities": []}, {"text": "Frequent problems of a less grammatical nature include missing content words and incorrect punctuation.", "labels": [], "entities": []}, {"text": "In this paper, we attempt to address these problems by exploring a variety of new features for scoring candidate translations.", "labels": [], "entities": [{"text": "scoring candidate translations", "start_pos": 95, "end_pos": 125, "type": "TASK", "confidence": 0.5515771706899008}]}, {"text": "A high-quality statistical translation system is our baseline, and we add new features to the existing set, which are then combined in a log-linear model.", "labels": [], "entities": [{"text": "statistical translation", "start_pos": 15, "end_pos": 38, "type": "TASK", "confidence": 0.696511447429657}]}, {"text": "To allow an easy integration of new features, the baseline system provides an n-best list of candidate translations which is then reranked using the new features.", "labels": [], "entities": []}, {"text": "This framework allows us to incorporate different types of features, including features based on syntactic analyses of the source and target sentences, which we hope will address the grammaticality of the translations, as well as lower-level features.", "labels": [], "entities": []}, {"text": "As we work on n-best lists, we can easily use global sentence-level features.", "labels": [], "entities": []}, {"text": "We begin by describing our baseline system and the n-best rescoring framework within which we conducted our experiments.", "labels": [], "entities": []}, {"text": "We then present a selection of new features, progressing from word-level features to those based to part-of-speech tags and syntactic chunks, and then to features based on Treebank-based syntactic parses of the source and target sentences.", "labels": [], "entities": []}], "datasetContent": [{"text": "We worked with the Chinese-English data from the recent evaluations, as both large amounts of sentence-aligned training corpora and multiple gold standard reference translations are available.", "labels": [], "entities": []}, {"text": "This is a standard data set, making it possible to compare results with other systems.", "labels": [], "entities": []}, {"text": "In addition, working on Chinese allows us to use the existing Chinese syntactic treebank and parsers based on it.", "labels": [], "entities": []}, {"text": "For the baseline MT system, we distinguish the following three different sentence-or chunk-aligned parallel training corpora: \u2022 training corpus (train): This is the basic training corpus used to train the alignment template translation model (word lexicon and phrase lexicon).", "labels": [], "entities": [{"text": "MT", "start_pos": 17, "end_pos": 19, "type": "TASK", "confidence": 0.9839248657226562}]}, {"text": "This corpus consists of about 170M English words.", "labels": [], "entities": []}, {"text": "Large parts of this corpus are aligned on a sub-sentence level to avoid the existence of very long sentences which would be filtered out in the training process to allow a manageable word alignment training.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 183, "end_pos": 197, "type": "TASK", "confidence": 0.7104769647121429}]}, {"text": "\u2022 development corpus (dev): This is the training corpus used in discriminative training of the modelparameters of the log-linear translation model.", "labels": [], "entities": []}, {"text": "In most experiments described in this report this corpus consists of 993 sentences (about 25K words) in both languages.", "labels": [], "entities": []}, {"text": "\u2022 test corpus (test): This is the test corpus used to assess the quality of the newly developed feature functions.", "labels": [], "entities": []}, {"text": "It consists of 878 sentences (about 25K words).", "labels": [], "entities": []}, {"text": "For development and test data, we have four English (reference) translations for each Chinese sentence.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Oracle BLEU scores for different sizes of the  n-best list. The avBLEUr3 scores are computed with  respect to three reference translations averaged over the  four different choices of holding out one reference.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 17, "end_pos": 21, "type": "METRIC", "confidence": 0.9902547001838684}]}, {"text": " Table 2: Results for the baseline features, each new fea- ture added to the baseline features on its own, and a com- bination of new features.", "labels": [], "entities": []}]}