{"title": [{"text": "Cross-Document Coreference on a Large Scale Corpus", "labels": [], "entities": [{"text": "Cross-Document Coreference", "start_pos": 0, "end_pos": 26, "type": "TASK", "confidence": 0.7040603160858154}]}], "abstractContent": [{"text": "In this paper, we will compare and evaluate the effectiveness of different statistical methods in the task of cross-document coreference resolution.", "labels": [], "entities": [{"text": "cross-document coreference resolution", "start_pos": 110, "end_pos": 147, "type": "TASK", "confidence": 0.8178099592526754}]}, {"text": "We created entity models for different test sets and compare the following disambiguation and clustering techniques to cluster the entity models in order to create coreference chains: Incremental Vector Space KL-Divergence Agglomerative Vector Space", "labels": [], "entities": []}], "introductionContent": [{"text": "Coreference analysis refers to the process of determining whether or not two mentions of entities refer to the same person).", "labels": [], "entities": [{"text": "Coreference analysis", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.9152216613292694}]}, {"text": "For example, consider the following short passage of text: John Smith was appointed chair of the committee.", "labels": [], "entities": [{"text": "John Smith", "start_pos": 59, "end_pos": 69, "type": "DATASET", "confidence": 0.8919797539710999}]}, {"text": "Because of his past experience, Mr. Smith seemed the perfect choice.", "labels": [], "entities": []}, {"text": "His good friend John, however, was not considered.", "labels": [], "entities": []}, {"text": "Coreference analysis attempts to decide whether John Smith and Mr. Smith refer to the same person, and whether John is also the same person.", "labels": [], "entities": [{"text": "Coreference analysis", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.911157101392746}]}, {"text": "The task is often extended to include references such as his or even his good friend, though we do not explore that extension in this study.", "labels": [], "entities": []}, {"text": "Addressing this problem is important to support systems such as those that search for, extract, and process mentions of \"people of interest\" in news or transcripts, or for other information organization tasks that might benefit from precise knowledge of how names occur, such as Topic Detection and Tracking.", "labels": [], "entities": [{"text": "Topic Detection and Tracking", "start_pos": 279, "end_pos": 307, "type": "TASK", "confidence": 0.7683288529515266}]}, {"text": "Cross-document coreference analysis pushes the task into considering whether mentions of a name in different documents are the same.", "labels": [], "entities": [{"text": "Cross-document coreference analysis", "start_pos": 0, "end_pos": 35, "type": "TASK", "confidence": 0.6710546414057413}]}, {"text": "The problem becomes more complex because documents might come from different sources, will probably have different authors and different writing conventions and styles(, and may even be in different languages.", "labels": [], "entities": []}, {"text": "There has been little published work on crossdocument coreference analysis and that has generally been evaluated on a small corpus of documents.", "labels": [], "entities": [{"text": "crossdocument coreference analysis", "start_pos": 40, "end_pos": 74, "type": "TASK", "confidence": 0.8549758593241373}]}, {"text": "A major contribution of this work is to develop a substantially larger (more than two orders of magnitude) corpus for evaluation.", "labels": [], "entities": []}, {"text": "We show that the previous approach is effective but that a variation on it, agglomerative vector space, provides improved and much more stable results.", "labels": [], "entities": []}, {"text": "We begin in Section 2 by describing how crossdocument coreference analysis is evaluated.", "labels": [], "entities": [{"text": "crossdocument coreference analysis", "start_pos": 40, "end_pos": 74, "type": "TASK", "confidence": 0.8693288763364156}]}, {"text": "We sketch prior work in Section 3 and describe our two evaluation corpora in Section 4.", "labels": [], "entities": []}, {"text": "Section 5 discusses the three algorithms that we explore for this task and then Section 6 describes our experimental results on both corpora.", "labels": [], "entities": []}, {"text": "In Section 7 we provide some additional analysis that attempts to explain some surprising results.", "labels": [], "entities": []}, {"text": "We conclude in Section 8 with a description of our plans for future work.", "labels": [], "entities": []}], "datasetContent": [{"text": "Given a collection of named entities from documents, the coreferencing task is to put them into equivalence classes, where every mention in the same class refers to the same entity (person, location, organization, and so on).", "labels": [], "entities": []}, {"text": "The classes are referred to as \"coreference chains\" because the entities are chained together.", "labels": [], "entities": []}, {"text": "To evaluate the coreference chains emitted by a system, we need truth data: the chains of entities that are actually referring to the same person.", "labels": [], "entities": []}, {"text": "Evaluation then proceeds by comparing the true chains to the system's hypothesized chains.", "labels": [], "entities": []}, {"text": "We use the B-CUBED scoring algorithm (Bagga and Baldwin 1998) because it is the one used in the published research.", "labels": [], "entities": [{"text": "B-CUBED scoring algorithm", "start_pos": 11, "end_pos": 36, "type": "METRIC", "confidence": 0.9293995300928751}]}, {"text": "The algorithm works as follows.", "labels": [], "entities": []}, {"text": "For each entity mention e in the evaluation set, we first locate the truth chain TC that contains that mention (it can be in only one truth chain) and the system's hypothesized chain HC that contains it (again, there can be only one hypothesis chain).", "labels": [], "entities": []}, {"text": "We then compute a precision and recall score for those two chains.", "labels": [], "entities": [{"text": "precision", "start_pos": 18, "end_pos": 27, "type": "METRIC", "confidence": 0.9996839761734009}, {"text": "recall score", "start_pos": 32, "end_pos": 44, "type": "METRIC", "confidence": 0.9794776737689972}]}, {"text": "Precision is the proportion of mentions in HC that are also in TC and recall is the proportion of mentions in TC that are also in HC.", "labels": [], "entities": [{"text": "Precision", "start_pos": 0, "end_pos": 9, "type": "METRIC", "confidence": 0.9919712543487549}, {"text": "recall", "start_pos": 70, "end_pos": 76, "type": "METRIC", "confidence": 0.9994245767593384}]}, {"text": "If the chains match perfectly, recall and precision will both be one.", "labels": [], "entities": [{"text": "recall", "start_pos": 31, "end_pos": 37, "type": "METRIC", "confidence": 0.9996720552444458}, {"text": "precision", "start_pos": 42, "end_pos": 51, "type": "METRIC", "confidence": 0.9995046854019165}]}, {"text": "If the hypothesis chain contains only the single mention e, then its precision will be one, and its recall will be 1/|TC|, the inverse of the size of the truth chain.", "labels": [], "entities": [{"text": "precision", "start_pos": 69, "end_pos": 78, "type": "METRIC", "confidence": 0.9995902180671692}, {"text": "recall", "start_pos": 100, "end_pos": 106, "type": "METRIC", "confidence": 0.9996293783187866}, {"text": "TC", "start_pos": 118, "end_pos": 120, "type": "METRIC", "confidence": 0.9543344974517822}]}, {"text": "Note that it is not possible to have a precision or recall of zero since entity e is always in common between the two chains.", "labels": [], "entities": [{"text": "precision", "start_pos": 39, "end_pos": 48, "type": "METRIC", "confidence": 0.9991078972816467}, {"text": "recall", "start_pos": 52, "end_pos": 58, "type": "METRIC", "confidence": 0.9936315417289734}]}, {"text": "Our implementation of the B-CUBED algorithm is used specifically to evaluate an existing set of coreference chains and does not utilize any smoothing to handle system output which contains no entities.", "labels": [], "entities": []}, {"text": "Overall precision and recall values are determined by averaging the individual values overall mentions in the evaluation set.", "labels": [], "entities": [{"text": "precision", "start_pos": 8, "end_pos": 17, "type": "METRIC", "confidence": 0.9994439482688904}, {"text": "recall", "start_pos": 22, "end_pos": 28, "type": "METRIC", "confidence": 0.9992319345474243}]}, {"text": "These are the primary evaluation measures for cross-document coreference analysis.", "labels": [], "entities": [{"text": "cross-document coreference analysis", "start_pos": 46, "end_pos": 81, "type": "TASK", "confidence": 0.8338201642036438}]}, {"text": "To evaluate our various techniques for the task of cross-document coreferencing, we used the two test corpora mentioned in Section 4 and the three coreference approaches described in Section 5.", "labels": [], "entities": []}, {"text": "The coreference chains are then evaluated using the B-CUBED algorithm to measure precision and recall as described in Section 2.", "labels": [], "entities": [{"text": "B-CUBED", "start_pos": 52, "end_pos": 59, "type": "METRIC", "confidence": 0.9749603867530823}, {"text": "precision", "start_pos": 81, "end_pos": 90, "type": "METRIC", "confidence": 0.9991284012794495}, {"text": "recall", "start_pos": 95, "end_pos": 101, "type": "METRIC", "confidence": 0.998873770236969}]}, {"text": "We present the results by corpus.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Breakdown of distribution by number of  occurrences within the Person X corpus.", "labels": [], "entities": [{"text": "Breakdown of distribution", "start_pos": 10, "end_pos": 35, "type": "TASK", "confidence": 0.7816442449887594}, {"text": "Person X corpus", "start_pos": 73, "end_pos": 88, "type": "DATASET", "confidence": 0.6221460998058319}]}, {"text": " Table 2: Breakdown of document and entity  distribution in the domain subject specific clusters.", "labels": [], "entities": [{"text": "Breakdown of document and entity  distribution", "start_pos": 10, "end_pos": 56, "type": "TASK", "confidence": 0.5389382094144821}]}]}