{"title": [{"text": "The Tao of CHI: Towards Effective Human-Computer Interaction", "labels": [], "entities": []}], "abstractContent": [{"text": "End-to-end evaluations of conversational dialogue systems with naive users are currently uncovering severe usability problems that result in low task completion rates.", "labels": [], "entities": []}, {"text": "Preliminary analyses suggest that these problems are related to the system's dialogue management and turn-taking behavior.", "labels": [], "entities": [{"text": "dialogue management", "start_pos": 77, "end_pos": 96, "type": "TASK", "confidence": 0.7498014569282532}]}, {"text": "We present the results of experiments designed to take a detailed look at the effects of that behavior.", "labels": [], "entities": []}, {"text": "Based on the resulting findings, we spell out a set of criteria which lie orthogonal to dialogue quality, but nevertheless constitute an integral part of a more comprehensive view on dialogue felicity as a function of dialogue quality and efficiency.", "labels": [], "entities": []}], "introductionContent": [{"text": "Research on dialogue systems in the past has focused on engineering the various processing stages involved in dialogical human-computer interaction (HCI) -e. g., robust automatic speech recognition, intention recognition, natural language generation or speech synthesis (cf., or).", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 179, "end_pos": 197, "type": "TASK", "confidence": 0.7669135332107544}, {"text": "intention recognition", "start_pos": 199, "end_pos": 220, "type": "TASK", "confidence": 0.6957215815782547}, {"text": "natural language generation", "start_pos": 222, "end_pos": 249, "type": "TASK", "confidence": 0.6770578424135844}, {"text": "speech synthesis", "start_pos": 253, "end_pos": 269, "type": "TASK", "confidence": 0.6933378726243973}]}, {"text": "Alongside these efforts the characteristics of computer-directed language have also been examined as a general phenomenon (cf., or).", "labels": [], "entities": []}, {"text": "The flip side, i. e., computer-human interaction (CHI), has received very little attention as a research question by itself.", "labels": [], "entities": [{"text": "computer-human interaction (CHI)", "start_pos": 22, "end_pos": 54, "type": "TASK", "confidence": 0.6313884615898132}]}, {"text": "That is not to say that natural language generation and synthesis have not made vast improvements, but rather that the nature and design of the computer as an interlocutor itself, i. e., the effects of human-directed language, have not been scrutinized as such.", "labels": [], "entities": [{"text": "natural language generation", "start_pos": 24, "end_pos": 51, "type": "TASK", "confidence": 0.7025387684504191}]}, {"text": "Looking at broad levels of distinctions for dialogue systems, e. g., that of between controlled and conversational dialogue systems, we note the singular employment of human-based differentiae, i. e., the degree of the restriction of the human interactions.", "labels": [], "entities": []}, {"text": "Differentiae stemming from the other communication partner, i. e., the computer, are not taken into accountneither on a practical nor on a theoretical level.", "labels": [], "entities": []}, {"text": "In the past controlled and restricted interactions between the user and the system increased recognition and understanding accuracies to a level that systems became reliable enough for deployment in various real world applications, e. g., transportation or cinema information systems).", "labels": [], "entities": []}, {"text": "Today's more conversational dialogue systems, e. g., SMARTKOM () or MATCH (), are able to cope with much less predictable user utterances.", "labels": [], "entities": [{"text": "SMARTKOM", "start_pos": 53, "end_pos": 61, "type": "DATASET", "confidence": 0.6283347606658936}]}, {"text": "Despite the fact that in these systems recognition and processing have become extremely difficult, the reliability thereof has been pushed towards acceptable degrees by employing an array of highly sophisticated technological advances -such as dynamic lexica for multi-domain speech recognition and flexible pronunciation models (), robust understanding and discourse modeling techniques) combined with ontological reasoning capabilities (.", "labels": [], "entities": [{"text": "recognition and processing", "start_pos": 39, "end_pos": 65, "type": "TASK", "confidence": 0.7297579844792684}, {"text": "multi-domain speech recognition", "start_pos": 263, "end_pos": 294, "type": "TASK", "confidence": 0.6457717617352804}]}, {"text": "However, the usability of such conversational dialogue systems is still unsatisfactory, as shown in usability experiments with real users) that employed the PROMISE evaluation framework described in, which offers some multimodal extentions over the PARADISE framework described in . The work described herein constitutes a starting point fora scientific examination of the whys and wherefores of the challenging results stemming from such end-to-end evaluations of conversational dialogue systems.", "labels": [], "entities": []}, {"text": "Following a brief description of the state of the art in examinations of computer-directed language, we describe anew experimental paradigm, the first two studies using the paradigm and their corresponding results.", "labels": [], "entities": []}, {"text": "Concluding, we discuss the ensuing implications for the design of successful and felicitous conversational dialogue systems.", "labels": [], "entities": []}], "datasetContent": [{"text": "For conducting the experiments we developed anew paradigm for collecting telephone-based dialogue data, called Wizard and Operator Test (WOT), which contains elements of both Wizard-of-Oz (WoZ) experiments) as well as Hidden Operator Tests ().", "labels": [], "entities": [{"text": "Wizard and Operator Test (WOT)", "start_pos": 111, "end_pos": 141, "type": "METRIC", "confidence": 0.5941004795687539}]}, {"text": "This procedure also represents a simplification of classical end-to-end experiments, as it is -much like WoZ experiments -conductible without the technically very complex use of areal conversational system.", "labels": [], "entities": []}, {"text": "As post-experimental interviews showed, this did not limit the feeling of authenticity regarding the simulated conversational system by the human subjects ( ).", "labels": [], "entities": []}, {"text": "The WOT setup consists of two major phases that begin after subjects have been given a set of tasks to be solved with the telephone-based dialogue system: in Phase 1 the human assistant (\u00a1 ) is acting as a wizard who is simulating the dialogue system, much like in WoZ experiments, by operating a speech synthesis interface, in Phase 2, which starts immediately after a system breakdown has been simulated by means of beeping noises transmitted via the telephone, the human assistant is acting as a human operator asking the subject to continue with the tasks.", "labels": [], "entities": [{"text": "WOT", "start_pos": 4, "end_pos": 7, "type": "TASK", "confidence": 0.8139873147010803}]}, {"text": "This setup enables to control for various factors.", "labels": [], "entities": []}, {"text": "Most importantly the technical performance (e. g., latency times), the pragmatic performance (e. g., understanding vs. non-understanding of the user utterances) and the communicative behavior of the simulated systems can be adjusted to resemble that of state of the art dialogue systems.", "labels": [], "entities": []}, {"text": "These factors can, of course, also be adjusted to simulate potential future capabilites of dialogue systems and test their effects.", "labels": [], "entities": []}, {"text": "The main point of the experimental setup, however, is to enable precise analyses of the differences in the communicative behaviors of the various interlocutors, i. e., human-human, human-computer and computer-human interaction.", "labels": [], "entities": []}, {"text": "The experiments were conducted with an English setup, subjects and assistants in the United States of America and with a German setup, subjects and assistants in Germany.", "labels": [], "entities": []}, {"text": "Both experiments were otherwise identical and in each 22 sessions were recorded.", "labels": [], "entities": []}, {"text": "At the beginning of the WOT, the test manager told the subjects that they were testing a novel telephone-based dialogue system that supplies touristic information on the city of Heidelberg.", "labels": [], "entities": [{"text": "WOT", "start_pos": 24, "end_pos": 27, "type": "TASK", "confidence": 0.5966008901596069}, {"text": "Heidelberg", "start_pos": 178, "end_pos": 188, "type": "DATASET", "confidence": 0.9342663288116455}]}, {"text": "In order to avoid the usual paraphrases of tasks worded too specifically, the manager gave the subjects an overall list of 20 very general touristic activities, such as visit museum or eat out, from which each subject had to pick six tasks which had to be solved in the experiment.", "labels": [], "entities": []}, {"text": "The manager then removed the original list, dialed the system's number on the phone and exited from the room after handing over the telephone receiver.", "labels": [], "entities": []}, {"text": "The subject was always greeted by the system's standard opening ply: Welcome to the Heidelberger tourist information system.", "labels": [], "entities": [{"text": "Heidelberger tourist information system", "start_pos": 84, "end_pos": 123, "type": "DATASET", "confidence": 0.9453421235084534}]}, {"text": "How I can help you?", "labels": [], "entities": []}, {"text": "After three tasks were finished (some successful some not) the assistant simulated the system's breakdown and entered the line by saying Excuse me, something seems to have happened with our system, may I assist you from hereon and finishing the remaining three tasks with the subjects.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Average length and turns in Phase 1 and 2", "labels": [], "entities": [{"text": "Average length", "start_pos": 10, "end_pos": 24, "type": "METRIC", "confidence": 0.8426484763622284}]}, {"text": " Table 2: Overall dialogue efficiencies with pauses +p and  without pauses -p.", "labels": [], "entities": []}, {"text": " Table 5: Overlaps in Phase 1 versus Phase 2", "labels": [], "entities": []}]}