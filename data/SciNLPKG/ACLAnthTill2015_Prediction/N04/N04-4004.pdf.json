{"title": [{"text": "An Empirical Study on Multiple LVCSR Model Combination by Machine Learning", "labels": [], "entities": []}], "abstractContent": [{"text": "This paper proposes to apply machine learning techniques to the task of combining outputs of multiple LVCSR models.", "labels": [], "entities": []}, {"text": "The proposed technique has advantages over that by voting schemes such as ROVER, especially when the majority of participating models are not reliable.", "labels": [], "entities": [{"text": "ROVER", "start_pos": 74, "end_pos": 79, "type": "METRIC", "confidence": 0.833987295627594}]}, {"text": "In this machine learning framework, as features of machine learning, information such as the model IDs which output the hypothesized word are useful for improving the word recognition rate.", "labels": [], "entities": [{"text": "word recognition", "start_pos": 167, "end_pos": 183, "type": "TASK", "confidence": 0.7880888283252716}]}, {"text": "Experimental results show that the combination results achieve a relative word error reduction of up to 39 % against the best performing single model and that of up to 23 % against ROVER.", "labels": [], "entities": [{"text": "word error reduction", "start_pos": 74, "end_pos": 94, "type": "METRIC", "confidence": 0.7536480824152628}]}, {"text": "We further empirically show that it performs better when LVCSR models to be combined are chosen so as to cover as many correctly recognized words as possible, rather than choosing models in descending order of their word correct rates.", "labels": [], "entities": [{"text": "word correct rates", "start_pos": 216, "end_pos": 234, "type": "METRIC", "confidence": 0.70806884765625}]}], "introductionContent": [{"text": "Since current speech recognizers' outputs are far from perfect and always include a certain amount of recognition errors, it is quite desirable to have an estimate of confidence for each hypothesized word.", "labels": [], "entities": [{"text": "speech recognizers'", "start_pos": 14, "end_pos": 33, "type": "TASK", "confidence": 0.7164790034294128}]}, {"text": "This is especially true for many practical applications of speech recognition systems such as automatic weighting of additional, non-speech knowledge sources, keyword based speech understanding, and recognition error rejection -confirmation in spoken dialogue systems.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 59, "end_pos": 77, "type": "TASK", "confidence": 0.7388902306556702}, {"text": "keyword based speech understanding", "start_pos": 159, "end_pos": 193, "type": "TASK", "confidence": 0.5800560191273689}, {"text": "recognition error rejection -confirmation", "start_pos": 199, "end_pos": 240, "type": "TASK", "confidence": 0.7291119813919067}]}, {"text": "Most of previous works on confidence measures (e.g., ) are based on features available in a single LVCSR model.", "labels": [], "entities": []}, {"text": "However, it is well known that a voting scheme such as ROVER (Recognizer output voting error reduction) for combining multiple speech recognizers' outputs can achieve word error reduction.", "labels": [], "entities": [{"text": "ROVER", "start_pos": 55, "end_pos": 60, "type": "METRIC", "confidence": 0.9929867386817932}, {"text": "Recognizer output voting error reduction)", "start_pos": 62, "end_pos": 103, "type": "TASK", "confidence": 0.5519724041223526}, {"text": "word error reduction", "start_pos": 167, "end_pos": 187, "type": "TASK", "confidence": 0.6455743511517843}]}, {"text": "Considering the success of a simple voting scheme such as ROVER, it also seems quite possible to improve reliability of previously studied features for confidence measures by simply exploiting more than one speech recognizers' outputs.", "labels": [], "entities": [{"text": "ROVER", "start_pos": 58, "end_pos": 63, "type": "METRIC", "confidence": 0.6622764468193054}, {"text": "reliability", "start_pos": 105, "end_pos": 116, "type": "METRIC", "confidence": 0.9753934741020203}]}, {"text": "From this observation, we experimentally evaluated the agreement among the outputs of multiple Japanese LVCSR models, with respect to whether it is effective as an estimate of confidence for each hypothesized word.", "labels": [], "entities": []}, {"text": "Our previous study reported that the agreement between the outputs with two different acoustic models can achieve quite reliable confidence, and also showed that the proposed measure of confidence outperforms previously studied features for confidence measures such as the acoustic stability and the hypothesis density).", "labels": [], "entities": [{"text": "confidence", "start_pos": 129, "end_pos": 139, "type": "METRIC", "confidence": 0.9695759415626526}]}, {"text": "We also reported evaluation results with 26 distinct acoustic models and identified the features of acoustic models most effective in achieving high confidence ().", "labels": [], "entities": []}, {"text": "The most remarkable results are as follows: for the newspaper sentence utterances, nearly 99% precision is achieved by decreasing 94% word correct rate of the best performing single model by only 7%.", "labels": [], "entities": [{"text": "newspaper sentence utterances", "start_pos": 52, "end_pos": 81, "type": "TASK", "confidence": 0.6794189612070719}, {"text": "precision", "start_pos": 94, "end_pos": 103, "type": "METRIC", "confidence": 0.9995476603507996}, {"text": "word correct rate", "start_pos": 134, "end_pos": 151, "type": "METRIC", "confidence": 0.6847330927848816}]}, {"text": "For the broadcast news speech, nearly 95% precision is achieved by decreasing 72% word correct rate of the best performing single model by only 8%.", "labels": [], "entities": [{"text": "precision", "start_pos": 42, "end_pos": 51, "type": "METRIC", "confidence": 0.9996439218521118}, {"text": "word correct rate", "start_pos": 82, "end_pos": 99, "type": "METRIC", "confidence": 0.7586681048075358}]}, {"text": "Based on those results of our previous studies, this paper proposes to apply machine learning techniques to the task of combining outputs of multiple LVCSR models.", "labels": [], "entities": []}, {"text": "As a machine learning technique, the Support Vector Machine (SVM) learning technique is employed.", "labels": [], "entities": []}, {"text": "A Support Vector Machine is trained for choosing the most confident one among several hypothesized words, where, as features of SVM learning, information such as the model IDs which output the hypothesized word, its part-of-speech, and the number of syllables are useful for improving the word recognition rate.", "labels": [], "entities": [{"text": "word recognition", "start_pos": 289, "end_pos": 305, "type": "TASK", "confidence": 0.7467384338378906}]}, {"text": "Model combination by high performance machine learning techniques such as SVM learning has advantages over that by voting schemes such as ROVER and others), especially when the majority of participating models are not reliable.", "labels": [], "entities": [{"text": "SVM learning", "start_pos": 74, "end_pos": 86, "type": "TASK", "confidence": 0.86287921667099}]}, {"text": "In the model combination techniques based on voting schemes, outputs of multiple LVCSR models are combined according to simple majority vote or weighted majority vote based on confidence of each hypothesized word such as its likelihood.", "labels": [], "entities": []}, {"text": "The results of model combination by those voting techniques can be harmed when the majority of participating models have quite low performance and output word recognition errors with high confidence.", "labels": [], "entities": []}, {"text": "On the other hand, in the model combination by high performance machine learning techniques such as SVM learning, among those participating models, reliable ones and unreliable ones are easily discriminated through the training process of machine learning framework.", "labels": [], "entities": [{"text": "SVM learning", "start_pos": 100, "end_pos": 112, "type": "TASK", "confidence": 0.744326263666153}]}, {"text": "Furthermore, depending on the features of hypothesized words such as its part-of-speech and the number of syllables, outputs of multiple models are combined in an optimal fashion so as to minimize word recognition errors in the combination results.", "labels": [], "entities": [{"text": "word recognition", "start_pos": 197, "end_pos": 213, "type": "TASK", "confidence": 0.670508861541748}]}, {"text": "Experimental results show that model combination by SVM achieves the followings: i.e., for the newspaper sentence utterances, a relative word error reduction of 39 % against the best performing single model and that of 23 % against ROVER; for the broadcast news speech, a relative word error reduction of 13 % against the best performing single model and that of 8 % against ROVER.", "labels": [], "entities": [{"text": "word error reduction", "start_pos": 137, "end_pos": 157, "type": "METRIC", "confidence": 0.756648580233256}]}, {"text": "We further empirically show that it performs better when LVCSR models to be combined are chosen so as to cover as many correctly recognized words as possible, rather than choosing models in descending order of their word correct rates 1 .", "labels": [], "entities": []}], "datasetContent": [{"text": "The evaluation data sets consist of newspaper sentence utterances, which are relatively easier for speech recognizers, and rather harder broadcast news speech: 1) 100 newspaper sentence utterances from 10 male speakers consisting of 1,565 words, selected by IPA Japanese dictation free software project () from the JNAS (Japanese Newspaper Article Sentences) speech data (Itou and others, 1998), 2) 175 Japanese NHK broadcast news (June 1st, 1996) speech sentences consisting of 6,813 words, uttered by 14 male speakers (six announcers and eight reporters).", "labels": [], "entities": [{"text": "speech recognizers", "start_pos": 99, "end_pos": 117, "type": "TASK", "confidence": 0.7370777428150177}, {"text": "JNAS (Japanese Newspaper Article Sentences) speech", "start_pos": 315, "end_pos": 365, "type": "TASK", "confidence": 0.6428702138364315}, {"text": "NHK broadcast news (June 1st, 1996) speech sentences", "start_pos": 412, "end_pos": 464, "type": "DATASET", "confidence": 0.8327989903363314}]}], "tableCaptions": []}