{"title": [{"text": "Corpus-Based Induction of Syntactic Structure: Models of Dependency and Constituency", "labels": [], "entities": [{"text": "Corpus-Based Induction of Syntactic Structure", "start_pos": 0, "end_pos": 45, "type": "TASK", "confidence": 0.7326694667339325}]}], "abstractContent": [{"text": "We present a generative model for the unsupervised learning of dependency structures.", "labels": [], "entities": []}, {"text": "We also describe the multiplicative combination of this dependency model with a model of linear constituency.", "labels": [], "entities": []}, {"text": "The product model outperforms both components on their respective evaluation metrics, giving the best published figures for un-supervised dependency parsing and unsupervised constituency parsing.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 138, "end_pos": 156, "type": "TASK", "confidence": 0.6878413558006287}, {"text": "constituency parsing", "start_pos": 174, "end_pos": 194, "type": "TASK", "confidence": 0.7553841471672058}]}, {"text": "We also demonstrate that the combined model works and is robust cross-linguistically, being able to exploit either attachment or distributional regularities that are salient in the data.", "labels": [], "entities": []}], "introductionContent": [{"text": "The task of statistically inducing hierarchical syntactic structure over unannotated sentences of natural language has received a great deal of attention (.", "labels": [], "entities": [{"text": "statistically inducing hierarchical syntactic structure", "start_pos": 12, "end_pos": 67, "type": "TASK", "confidence": 0.5767302572727203}]}, {"text": "Researchers have explored this problem fora variety of reasons: to argue empirically against the poverty of the stimulus, to use induction systems as a first stage in constructing large treebanks), to build better language models, and to examine cognitive issues in language learning ().", "labels": [], "entities": []}, {"text": "An important distinction should be drawn between work primarily interested in the weak generative capacity of models, where modeling hierarchical structure is only useful insofar as it leads to improved models over observed structures, and work interested in the strong generative capacity of models, where the unobserved structure itself is evaluated).", "labels": [], "entities": []}, {"text": "This paper falls into the latter category; we will be inducing models of linguistic constituency and dependency with the goal of recovering linguistically plausible structures.", "labels": [], "entities": []}, {"text": "We make no claims as to the cognitive plausibility of the induction mechanisms we present here; however, the ability of these systems to recover substantial linguistic patterns from surface yields alone does speak to the strength of support for these patterns in the data, and hence undermines arguments based on \"the poverty of the stimulus\").", "labels": [], "entities": []}], "datasetContent": [{"text": "An example dependency representation of a short sentence is shown in, where, following the traditional dependency grammar notation, the regent or head of a dependency is marked with the tail of the dependency arrow, and the dependent is marked with the arrowhead).", "labels": [], "entities": []}, {"text": "It will be important in what follows to see that such a representation is isomorphic (in terms of strong generative capacity) to a restricted form of phrase structure grammar, where the set of terminals and nonterminals is identical, and every rule is of the form X \u2192 X Y or X \u2192 Y X, giving the isomorphic representation of figure 1(a) shown in figure 1(b).", "labels": [], "entities": [{"text": "phrase structure grammar", "start_pos": 150, "end_pos": 174, "type": "TASK", "confidence": 0.8245742917060852}]}, {"text": "1 Depending on the model, part-of- speech categories maybe included in the dependency representation, as shown here, or dependencies maybe directly between words.", "labels": [], "entities": []}, {"text": "Below, we will assume an additonal reserved nonterminal ROOT, whose sole dependent is the head of the sentence.", "labels": [], "entities": [{"text": "ROOT", "start_pos": 56, "end_pos": 60, "type": "METRIC", "confidence": 0.9603371024131775}]}, {"text": "This simplifies the notation, math, and the evaluation metric.", "labels": [], "entities": []}, {"text": "A dependency analysis will always consist of exactly as many dependencies as there are words in the sentence.", "labels": [], "entities": [{"text": "dependency analysis", "start_pos": 2, "end_pos": 21, "type": "TASK", "confidence": 0.8361979722976685}]}, {"text": "For example, in the dependency structure of figure 1(b), the dependencies are {(ROOT, fell), (fell, payrolls), (fell, in), (in, September), (payrolls, Factory)}.", "labels": [], "entities": [{"text": "ROOT", "start_pos": 80, "end_pos": 84, "type": "METRIC", "confidence": 0.9915493726730347}]}, {"text": "The quality of a hypothesized dependency structure can hence be evaluated by accuracy as compared to a gold-standard dependency structure, by reporting the percentage of dependencies shared between the two analyses.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 77, "end_pos": 85, "type": "METRIC", "confidence": 0.9993276596069336}]}, {"text": "In the next section, we discuss several models of dependency structure, and throughout this paper we report the accuracy of various methods at recovering gold-standard dependency parses from various corpora, detailed here.", "labels": [], "entities": [{"text": "dependency structure", "start_pos": 50, "end_pos": 70, "type": "TASK", "confidence": 0.8354207575321198}, {"text": "accuracy", "start_pos": 112, "end_pos": 120, "type": "METRIC", "confidence": 0.9987305998802185}, {"text": "recovering gold-standard dependency parses", "start_pos": 143, "end_pos": 185, "type": "TASK", "confidence": 0.6880094930529594}]}, {"text": "WSJ is the entire Penn English Treebank WSJ portion.", "labels": [], "entities": [{"text": "WSJ", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.9230485558509827}, {"text": "Penn English Treebank WSJ portion", "start_pos": 18, "end_pos": 51, "type": "DATASET", "confidence": 0.9725612998008728}]}, {"text": "WSJ10 is the subset of sentences which contained 10 words or less after the removal of punctuation.", "labels": [], "entities": [{"text": "WSJ10", "start_pos": 0, "end_pos": 5, "type": "DATASET", "confidence": 0.8983643054962158}]}, {"text": "CTB10 is the sentences of the same length from the Penn Chinese treebank (v3).", "labels": [], "entities": [{"text": "CTB10", "start_pos": 0, "end_pos": 5, "type": "DATASET", "confidence": 0.9477222561836243}, {"text": "Penn Chinese treebank", "start_pos": 51, "end_pos": 72, "type": "DATASET", "confidence": 0.9879079659779867}]}, {"text": "NEGRA10 is the same, for the German NE-GRA corpus, based on the supplied conversion of the NEGRA corpus into Penn treebank format.", "labels": [], "entities": [{"text": "NEGRA10", "start_pos": 0, "end_pos": 7, "type": "DATASET", "confidence": 0.9577766060829163}, {"text": "German NE-GRA corpus", "start_pos": 29, "end_pos": 49, "type": "DATASET", "confidence": 0.8061235149701437}, {"text": "NEGRA corpus", "start_pos": 91, "end_pos": 103, "type": "DATASET", "confidence": 0.9159593284130096}, {"text": "Penn treebank format", "start_pos": 109, "end_pos": 129, "type": "DATASET", "confidence": 0.8747087319691976}]}, {"text": "In most of the present experiments, the provided partsof-speech were used as the input alphabet, though we also present limited experimentation with synthetic parts-of-speech.", "labels": [], "entities": []}, {"text": "It is important to note that the Penn treebanks do not include dependency annotations; however, the automatic dependency rules from are sufficiently accurate to be a good benchmark for unsupervised systems for the time being (though see below for specific issues).", "labels": [], "entities": [{"text": "Penn treebanks", "start_pos": 33, "end_pos": 47, "type": "DATASET", "confidence": 0.9889691472053528}]}, {"text": "Similar head-finding rules were used for Chinese experiments.", "labels": [], "entities": []}, {"text": "The NE-GRA corpus, however, does supply hand-annotated dependency structures.", "labels": [], "entities": [{"text": "NE-GRA corpus", "start_pos": 4, "end_pos": 17, "type": "DATASET", "confidence": 0.8076595962047577}]}, {"text": "structures which specify orders of attachment among multiple dependents which share a common head.", "labels": [], "entities": []}, {"text": "Where possible, we report an accuracy figure for both directed and undirected dependencies.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 29, "end_pos": 37, "type": "METRIC", "confidence": 0.9996633529663086}]}, {"text": "Reporting undirected numbers has two advantages: first, it facilitates comparison with earlier work, and, more importantly, it allows one to partially obscure the effects of alternate analyses, such as the systematic choice between a modal and a main verb for the head of a sentence (in either case, the two verbs would be linked, but the direction would vary).", "labels": [], "entities": [{"text": "Reporting undirected numbers", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.8758184711138407}]}], "tableCaptions": []}