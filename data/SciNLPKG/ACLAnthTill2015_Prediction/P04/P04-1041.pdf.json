{"title": [{"text": "Long-Distance Dependency Resolution in Automatically Acquired Wide-Coverage PCFG-Based LFG Approximations", "labels": [], "entities": [{"text": "Long-Distance Dependency Resolution", "start_pos": 0, "end_pos": 35, "type": "TASK", "confidence": 0.7021440168221792}, {"text": "PCFG-Based LFG Approximations", "start_pos": 76, "end_pos": 105, "type": "METRIC", "confidence": 0.5824514428774515}]}], "abstractContent": [{"text": "This paper shows how finite approximations of long distance dependency (LDD) resolution can be obtained automatically for wide-coverage, robust, probabilistic Lexical-Functional Grammar (LFG) resources acquired from treebanks.", "labels": [], "entities": [{"text": "long distance dependency (LDD) resolution", "start_pos": 46, "end_pos": 87, "type": "TASK", "confidence": 0.6713294727461678}]}, {"text": "We extract LFG subcategorisation frames and paths linking LDD reentrancies from f-structures generated automatically for the Penn-II treebank trees and use them in an LDD resolution algorithm to parse new text.", "labels": [], "entities": [{"text": "Penn-II treebank trees", "start_pos": 125, "end_pos": 147, "type": "DATASET", "confidence": 0.9817175467809042}]}, {"text": "Unlike (Collins, 1999; Johnson, 2002), in our approach resolution of LDDs is done at f-structure (attribute-value structure representations of basic predicate-argument or dependency structure) without empty productions, traces and coindexation in CFG parse trees.", "labels": [], "entities": []}, {"text": "Currently our best automatically induced grammars achieve 80.97% f-score for f-structures parsing section 23 of the WSJ part of the Penn-II treebank and evaluating against the DCU 105 1 and 80.24% against the PARC 700 Dependency Bank (King et al., 2003), performing at the same or a slightly better level than state-of-the-art hand-crafted grammars (Kaplan et al., 2004).", "labels": [], "entities": [{"text": "f-score", "start_pos": 65, "end_pos": 72, "type": "METRIC", "confidence": 0.9792371988296509}, {"text": "f-structures parsing", "start_pos": 77, "end_pos": 97, "type": "TASK", "confidence": 0.6954672634601593}, {"text": "WSJ part", "start_pos": 116, "end_pos": 124, "type": "DATASET", "confidence": 0.962835043668747}, {"text": "Penn-II treebank", "start_pos": 132, "end_pos": 148, "type": "DATASET", "confidence": 0.8347281217575073}, {"text": "DCU 105 1", "start_pos": 176, "end_pos": 185, "type": "DATASET", "confidence": 0.9295167326927185}, {"text": "PARC 700 Dependency Bank", "start_pos": 209, "end_pos": 233, "type": "DATASET", "confidence": 0.9671071469783783}]}], "introductionContent": [{"text": "The determination of syntactic structure is an important step in natural language processing as syntactic structure strongly determines semantic interpretation in the form of predicate-argument structure, dependency relations or logical form.", "labels": [], "entities": []}, {"text": "For a substantial number of linguistic phenomena such as topicalisation, wh-movement in relative clauses and interrogative sentences, however, there is an important difference between the location of the (surface) realisation of linguistic material and the location where this material should be interpreted semantically.", "labels": [], "entities": []}, {"text": "Resolution of such long-distance dependencies (LDDs) is therefore crucial in the determination of accurate predicate-argument struc-ture, deep dependency relations and the construction of proper meaning representations such as logical forms.", "labels": [], "entities": [{"text": "Resolution of such long-distance dependencies (LDDs)", "start_pos": 0, "end_pos": 52, "type": "TASK", "confidence": 0.646967176347971}]}, {"text": "Modern unification/constraint-based grammars such as LFG or HPSG capture deep linguistic information including LDDs, predicate-argument structure, or logical form.", "labels": [], "entities": []}, {"text": "Manually scaling rich unification grammars to naturally occurring free text, however, is extremely time-consuming, expensive and requires considerable linguistic and computational expertise.", "labels": [], "entities": []}, {"text": "Few hand-crafted, deep unification grammars have in fact achieved the coverage and robustness required to parse a corpus of say the size and complexity of the Penn treebank: ( show how a deep, carefully hand-crafted LFG is successfully scaled to parse the Penn-II treebank) with discriminative (loglinear) parameter estimation techniques.", "labels": [], "entities": [{"text": "coverage", "start_pos": 70, "end_pos": 78, "type": "METRIC", "confidence": 0.9706943035125732}, {"text": "Penn treebank", "start_pos": 159, "end_pos": 172, "type": "DATASET", "confidence": 0.9912702441215515}, {"text": "Penn-II treebank", "start_pos": 256, "end_pos": 272, "type": "DATASET", "confidence": 0.9830357134342194}]}, {"text": "The last 20 years have seen continuously increasing efforts in the construction of parse-annotated corpora.", "labels": [], "entities": []}, {"text": "Substantial treebanks 2 are now available for many languages (including English, Japanese, Chinese, German, French, Czech, Turkish), others are currently under construction (Arabic, Bulgarian) or near completion.", "labels": [], "entities": []}, {"text": "Treebanks have been enormously influential in the development of robust, state-of-the-art parsing technology: grammars (or grammatical information) automatically extracted from treebank resources provide the backbone of many state-of-the-art probabilistic parsing approaches.", "labels": [], "entities": []}, {"text": "Such approaches are attractive as they achieve robustness, coverage and performance while incurring very low grammar development cost.", "labels": [], "entities": [{"text": "coverage", "start_pos": 59, "end_pos": 67, "type": "METRIC", "confidence": 0.9004315733909607}]}, {"text": "However, with few notable exceptions (e.g. Collins', ), treebank-based probabilistic parsers return fairly simple \"surfacey\" CFG trees, without deep syntactic or semantic information.", "labels": [], "entities": [{"text": "Collins'", "start_pos": 43, "end_pos": 51, "type": "DATASET", "confidence": 0.9533248245716095}]}, {"text": "The grammars used by such systems are sometimes re-ferred to as \"half\" (or \"shallow\") grammars), i.e. they do not resolve LDDs but interpret linguistic material purely locally where it occurs in the tree.", "labels": [], "entities": []}, {"text": "Recently) showed how wide-coverage, probabilistic unification grammar resources can be acquired automatically from fstructure-annotated treebanks.", "labels": [], "entities": []}, {"text": "Many second generation treebanks provide a certain amount of deep syntactic or dependency information (e.g. in the form of Penn-II functional tags and traces) supporting the computation of representations of deep linguistic information.", "labels": [], "entities": [{"text": "Penn-II", "start_pos": 123, "end_pos": 130, "type": "DATASET", "confidence": 0.9467374682426453}]}, {"text": "Exploiting this information () implement an automatic LFG f-structure annotation algorithm that associates nodes in treebank trees with fstructure annotations in the form of attribute-value structure equations representing abstract predicateargument structure/dependency relations.", "labels": [], "entities": []}, {"text": "From the f-structure annotated treebank they automatically extract wide-coverage, robust, PCFG-based LFG approximations that parse new text into trees and f-structure representations.", "labels": [], "entities": []}, {"text": "The LFG approximations of), however, are only \"half\" grammars, i.e. like most of their probabilistic CFG cousins) they do not resolve LDDs but interpret linguistic material purely locally where it occurs in the tree.", "labels": [], "entities": []}, {"text": "In this paper we show how finite approximations of long distance dependency resolution can be obtained automatically for wide-coverage, robust, probabilistic LFG resources automatically acquired from treebanks.", "labels": [], "entities": [{"text": "long distance dependency resolution", "start_pos": 51, "end_pos": 86, "type": "TASK", "confidence": 0.6397113427519798}]}, {"text": "We extract LFG subcategorisation frames and paths linking LDD reentrancies from f-structures generated automatically for the Penn-II treebank trees and use them in an LDD resolution algorithm to parse new text.", "labels": [], "entities": [{"text": "Penn-II treebank trees", "start_pos": 125, "end_pos": 147, "type": "DATASET", "confidence": 0.9817175467809042}]}, {"text": "Unlike), in our approach LDDs are resolved on the level of f-structure representation, rather than in terms of empty productions and coindexation on parse trees.", "labels": [], "entities": []}, {"text": "Currently we achieve fstructure/dependency f-scores of 80.24 and 80.97 for parsing section 23 of the WSJ part of the Penn-II treebank, evaluating against the PARC 700 and DCU 105 respectively.", "labels": [], "entities": [{"text": "fstructure/dependency f-scores", "start_pos": 21, "end_pos": 51, "type": "METRIC", "confidence": 0.7037974745035172}, {"text": "parsing", "start_pos": 75, "end_pos": 82, "type": "TASK", "confidence": 0.9616542458534241}, {"text": "WSJ part", "start_pos": 101, "end_pos": 109, "type": "DATASET", "confidence": 0.9470029473304749}, {"text": "Penn-II treebank", "start_pos": 117, "end_pos": 133, "type": "DATASET", "confidence": 0.9280261993408203}, {"text": "PARC 700", "start_pos": 158, "end_pos": 166, "type": "DATASET", "confidence": 0.9273678064346313}, {"text": "DCU 105", "start_pos": 171, "end_pos": 178, "type": "DATASET", "confidence": 0.8297818303108215}]}, {"text": "The paper is structured as follows: we give a brief introduction to LFG.", "labels": [], "entities": [{"text": "LFG", "start_pos": 68, "end_pos": 71, "type": "DATASET", "confidence": 0.8831747770309448}]}, {"text": "We outline the automatic f-structure annotation algorithm, PCFG-based LFG grammar approximations and parsing architectures of ().", "labels": [], "entities": [{"text": "PCFG-based LFG grammar", "start_pos": 59, "end_pos": 81, "type": "DATASET", "confidence": 0.7580118179321289}]}, {"text": "We present our subcategorisation frame extraction and introduce the treebankbased acquisition of finite approximations of LFG functional uncertainty equations in terms of LDD paths.", "labels": [], "entities": [{"text": "subcategorisation frame extraction", "start_pos": 15, "end_pos": 49, "type": "TASK", "confidence": 0.6723145445187887}]}, {"text": "We present the f-structure LDD resolution algorithm, provide results and extensive evaluation.", "labels": [], "entities": [{"text": "LDD resolution", "start_pos": 27, "end_pos": 41, "type": "TASK", "confidence": 0.6951323300600052}]}, {"text": "We compare our method with previous work.", "labels": [], "entities": []}, {"text": "Finally, we conclude.) minimally involves two levels of syntactic representation: 3 c-structure and f-structure.", "labels": [], "entities": []}, {"text": "C(onstituent)-structure represents the grouping of words and phrases into larger constituents and is realised in terms of a CF-PSG grammar.", "labels": [], "entities": []}, {"text": "F(unctional)-structure represents abstract syntactic functions such as SUBJ(ect), OBJ(ect), OBL(ique), closed and open clausal COMP/XCOMP(lement), ADJ(unct), APP(osition) etc. and is implemented in terms of recursive feature structures (attribute-value matrices).", "labels": [], "entities": []}, {"text": "C-structure captures surface grammatical configurations, fstructure encodes abstract syntactic information approximating to predicate-argument/dependency structure or simple logical form.", "labels": [], "entities": []}, {"text": "C-and f-structures are related in terms of functional annotations (constraints, attribute-value equations) on c-structure rules (cf.  Uparrows point to the f-structure associated with the mother node, downarrows to that of the local node.", "labels": [], "entities": []}, {"text": "The equations are collected with arrows instantiated to unique tree node identifiers, and a constraint solver generates an f-structure.", "labels": [], "entities": []}], "datasetContent": [{"text": "We ran experiments with grammars in both the pipeline and the integrated parsing architectures.", "labels": [], "entities": []}, {"text": "The first grammar is a basic PCFG, while A-PCFG includes the f-structure annotations.", "labels": [], "entities": []}, {"text": "We apply a parent transformation to each grammar) to give P-PCFG and PA-PCFG.", "labels": [], "entities": []}, {"text": "We train on sections 02-21 (grammar, lexical extraction and LDD paths) of the Penn-II Treebank and test on section 23.", "labels": [], "entities": [{"text": "lexical extraction", "start_pos": 37, "end_pos": 55, "type": "TASK", "confidence": 0.7258972823619843}, {"text": "Penn-II Treebank", "start_pos": 78, "end_pos": 94, "type": "DATASET", "confidence": 0.9934797286987305}]}, {"text": "The only pre-processing of the trees that we do is to remove empty nodes, and remove all Penn-II functional tags in the integrated model.", "labels": [], "entities": [{"text": "Penn-II", "start_pos": 89, "end_pos": 96, "type": "DATASET", "confidence": 0.947666585445404}]}, {"text": "We evaluate the parse trees using evalb.", "labels": [], "entities": []}, {"text": "Following (), we convert f-structures into dependency triple format.", "labels": [], "entities": []}, {"text": "Using their software we evaluate the f-structure parser output against: 1.", "labels": [], "entities": []}, {"text": "The full 2,416 f-structures automatically generated by the f-structure annotation algorithm for the original Penn-II trees, in a CCG-style   The results are given in.", "labels": [], "entities": [{"text": "Penn-II trees", "start_pos": 109, "end_pos": 122, "type": "DATASET", "confidence": 0.9757268726825714}]}, {"text": "The parenttransformed grammars perform best in both architectures.", "labels": [], "entities": []}, {"text": "In all cases, there is a marked improvement (2.07-6.36%) in the f-structures after LDD resolution.", "labels": [], "entities": [{"text": "LDD resolution", "start_pos": 83, "end_pos": 97, "type": "TASK", "confidence": 0.7276762425899506}]}, {"text": "We achieve between 73.78% and 80.97% preds-only and 83.79% to 87.04% all GFs f-score, depending on gold-standard.", "labels": [], "entities": [{"text": "preds-only", "start_pos": 37, "end_pos": 47, "type": "METRIC", "confidence": 0.9963079690933228}, {"text": "GFs f-score", "start_pos": 73, "end_pos": 84, "type": "METRIC", "confidence": 0.8678390681743622}]}, {"text": "We achieve between 77.68% and 80.24% against the PARC 700 following the experiments in ().", "labels": [], "entities": [{"text": "PARC 700", "start_pos": 49, "end_pos": 57, "type": "DATASET", "confidence": 0.8601844608783722}]}, {"text": "For details on how we map the f-structures produced by our parsers to a format similar to that of the PARC 700 Dependency Bank, see ).", "labels": [], "entities": [{"text": "PARC 700 Dependency Bank", "start_pos": 102, "end_pos": 126, "type": "DATASET", "confidence": 0.9717181771993637}]}, {"text": "shows the evaluation result broken down by individual GF (preds-only) for the integrated model PA-PCFG against the DCU 105.", "labels": [], "entities": [{"text": "GF", "start_pos": 54, "end_pos": 56, "type": "METRIC", "confidence": 0.9824920892715454}, {"text": "DCU 105", "start_pos": 115, "end_pos": 122, "type": "DATASET", "confidence": 0.957695722579956}]}, {"text": "In order to measure how many of the LDD reentrancies in the gold-standard f-structures are captured correctly by our parsers, we developed evaluation software for f-structure LDD reentrancies (similar to Johnson's (2002) evaluation to capture traces and their antecedents in trees).", "labels": [], "entities": []}, {"text": "shows the results with the integrated model achieving more than 76% correct LDD reentrancies.", "labels": [], "entities": [{"text": "correct LDD reentrancies", "start_pos": 68, "end_pos": 92, "type": "METRIC", "confidence": 0.832827647527059}]}, {"text": "antecedents to parse trees, while we present an approach to LDD resolution on the level of f-structure.", "labels": [], "entities": [{"text": "LDD resolution", "start_pos": 60, "end_pos": 74, "type": "TASK", "confidence": 0.8734771907329559}]}, {"text": "It seems that the f-structure-based approach is more abstract (99 LDD path types against approximately 9,000 tree-fragment types in) and fine-grained in its use of lexical information (subcat frames).", "labels": [], "entities": []}, {"text": "In contrast to Johnson's approach, our LDD resolution algorithm is not biased.", "labels": [], "entities": [{"text": "LDD resolution", "start_pos": 39, "end_pos": 53, "type": "TASK", "confidence": 0.7747146785259247}]}, {"text": "It computes all possible complete resolutions and orderranks them using LDD path and subcat frame probabilities.", "labels": [], "entities": []}, {"text": "It is difficult to provide a satisfactory comparison between the two methods, but we have carried out an experiment that compares them at the f-structure level.", "labels": [], "entities": []}, {"text": "We take the output of Charniak's   parser) and, using the pipeline f-structure annotation model, evaluate against the DCU 105, both before and after LDD resolution.", "labels": [], "entities": [{"text": "DCU 105", "start_pos": 118, "end_pos": 125, "type": "DATASET", "confidence": 0.9251514673233032}]}, {"text": "Using the software described in) we add empty nodes to the output of Charniak's parser, pass these trees to our automatic annotation algorithm and evaluate against the DCU 105.", "labels": [], "entities": [{"text": "DCU 105", "start_pos": 168, "end_pos": 175, "type": "DATASET", "confidence": 0.925653874874115}]}, {"text": "The results are given in.", "labels": [], "entities": []}, {"text": "Our method of resolving LDDs at f-structure level results in a preds-only f-score of 80.97%.", "labels": [], "entities": [{"text": "preds-only f-score", "start_pos": 63, "end_pos": 81, "type": "METRIC", "confidence": 0.8457942008972168}]}, {"text": "Using)'s method of adding empty nodes to the parse-trees results in an f-score of 79.75%.", "labels": [], "entities": [{"text": "f-score", "start_pos": 71, "end_pos": 78, "type": "METRIC", "confidence": 0.9625393152236938}]}, {"text": "provides CCG-based models of LDDs.", "labels": [], "entities": []}, {"text": "Some of these involve extensive cleanup of the underlying Penn-II treebank resource prior to grammar extraction.", "labels": [], "entities": [{"text": "Penn-II treebank resource", "start_pos": 58, "end_pos": 83, "type": "DATASET", "confidence": 0.9858366449673971}, {"text": "grammar extraction", "start_pos": 93, "end_pos": 111, "type": "TASK", "confidence": 0.7282204478979111}]}, {"text": "In contrast, in our approach we leave the treebank as is and only add (but never correct) annotations.", "labels": [], "entities": []}, {"text": "Earlier HPSG work () is based on independently constructed hand-crafted XTAG resources.", "labels": [], "entities": []}, {"text": "In contrast, we acquire our resources from treebanks and achieve substantially wider coverage.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: F-structure annotation results for DCU 105", "labels": [], "entities": [{"text": "DCU", "start_pos": 45, "end_pos": 48, "type": "DATASET", "confidence": 0.8984018564224243}]}, {"text": " Table 3: Semantic forms for the verb accept.", "labels": [], "entities": []}, {"text": " Table 5: Most frequent wh-less TOPIC-REL paths", "labels": [], "entities": [{"text": "TOPIC-REL", "start_pos": 32, "end_pos": 41, "type": "METRIC", "confidence": 0.6247992515563965}]}, {"text": " Table 6: Number of path types extracted", "labels": [], "entities": []}, {"text": " Table 7. The parent- transformed grammars perform best in both archi- tectures. In all cases, there is a marked improve- ment (2.07-6.36%) in the f-structures after LDD res- olution. We achieve between 73.78% and 80.97%  preds-only and 83.79% to 87.04% all GFs f-score,  depending on gold-standard. We achieve between  77.68% and 80.24% against the PARC 700 follow- ing the experiments in (", "labels": [], "entities": [{"text": "improve- ment", "start_pos": 113, "end_pos": 126, "type": "METRIC", "confidence": 0.8228168884913126}, {"text": "preds-only", "start_pos": 222, "end_pos": 232, "type": "METRIC", "confidence": 0.9926639795303345}, {"text": "PARC 700 follow- ing", "start_pos": 350, "end_pos": 370, "type": "DATASET", "confidence": 0.9507300734519959}]}, {"text": " Table 9: LDD Evaluation on the DCU 105", "labels": [], "entities": [{"text": "DCU", "start_pos": 32, "end_pos": 35, "type": "DATASET", "confidence": 0.9360056519508362}]}, {"text": " Table 10: Comparison at f-structure level of LDD  resolution to (Johnson, 2002) on the DCU 105", "labels": [], "entities": [{"text": "DCU 105", "start_pos": 88, "end_pos": 95, "type": "DATASET", "confidence": 0.9829791188240051}]}]}