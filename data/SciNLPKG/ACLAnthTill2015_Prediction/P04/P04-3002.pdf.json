{"title": [{"text": "Improving Domain-Specific Word Alignment for Computer Assisted Translation", "labels": [], "entities": [{"text": "Improving Domain-Specific Word Alignment", "start_pos": 0, "end_pos": 40, "type": "TASK", "confidence": 0.897482767701149}, {"text": "Computer Assisted Translation", "start_pos": 45, "end_pos": 74, "type": "TASK", "confidence": 0.7512621084849039}]}], "abstractContent": [{"text": "This paper proposes an approach to improve word alignment in a specific domain, in which only a small-scale domain-specific corpus is available, by adapting the word alignment information in the general domain to the specific domain.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 43, "end_pos": 57, "type": "TASK", "confidence": 0.8182783424854279}]}, {"text": "This approach first trains two statistical word alignment models with the large-scale corpus in the general domain and the small-scale corpus in the specific domain respectively, and then improves the domain-specific word alignment with these two models.", "labels": [], "entities": [{"text": "statistical word alignment", "start_pos": 31, "end_pos": 57, "type": "TASK", "confidence": 0.6516378919283549}, {"text": "domain-specific word alignment", "start_pos": 201, "end_pos": 231, "type": "TASK", "confidence": 0.6737233102321625}]}, {"text": "Experimental results show a significant improvement in terms of both alignment precision and recall.", "labels": [], "entities": [{"text": "alignment", "start_pos": 69, "end_pos": 78, "type": "TASK", "confidence": 0.8831579089164734}, {"text": "precision", "start_pos": 79, "end_pos": 88, "type": "METRIC", "confidence": 0.9607902765274048}, {"text": "recall", "start_pos": 93, "end_pos": 99, "type": "METRIC", "confidence": 0.9991459846496582}]}, {"text": "And the alignment results are applied in a computer assisted translation system to improve human translation efficiency.", "labels": [], "entities": [{"text": "human translation", "start_pos": 91, "end_pos": 108, "type": "TASK", "confidence": 0.6164606809616089}]}], "introductionContent": [{"text": "Bilingual word alignment is first introduced as an intermediate result in statistical machine translation (SMT) (.", "labels": [], "entities": [{"text": "Bilingual word alignment", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.7733428875605265}, {"text": "statistical machine translation (SMT)", "start_pos": 74, "end_pos": 111, "type": "TASK", "confidence": 0.7949310690164566}]}, {"text": "In previous alignment methods, some researchers modeled the alignments with different statistical models (.", "labels": [], "entities": []}, {"text": "Some researchers use similarity and association measures to build alignment links ().", "labels": [], "entities": [{"text": "similarity", "start_pos": 21, "end_pos": 31, "type": "METRIC", "confidence": 0.9603409767150879}]}, {"text": "However, All of these methods require a large-scale bilingual corpus for training.", "labels": [], "entities": []}, {"text": "When the large-scale bilingual corpus is not available, some researchers use existing dictionaries to improve word alignment.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 110, "end_pos": 124, "type": "TASK", "confidence": 0.7640053331851959}]}, {"text": "However, few works address the problem of domain-specific word alignment when neither the large-scale domain-specific bilingual corpus nor the domain-specific translation dictionary is available.", "labels": [], "entities": [{"text": "domain-specific word alignment", "start_pos": 42, "end_pos": 72, "type": "TASK", "confidence": 0.6308439671993256}]}, {"text": "This paper addresses the problem of word alignment in a specific domain, where only a small domain-specific corpus is available.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 36, "end_pos": 50, "type": "TASK", "confidence": 0.8002453744411469}]}, {"text": "In the domain-specific corpus, there are two kinds of words.", "labels": [], "entities": []}, {"text": "Some are general words, which are also frequently used in the general domain.", "labels": [], "entities": []}, {"text": "Others are domain-specific words, which only occur in the specific domain.", "labels": [], "entities": []}, {"text": "In general, it is not quite hard to obtain a large-scale general bilingual corpus while the available domain-specific bilingual corpus is usually quite small.", "labels": [], "entities": []}, {"text": "Thus, we use the bilingual corpus in the general domain to improve word alignments for general words and the corpus in the specific domain for domain-specific words.", "labels": [], "entities": [{"text": "word alignments", "start_pos": 67, "end_pos": 82, "type": "TASK", "confidence": 0.704674556851387}]}, {"text": "In other words, we will adapt the word alignment information in the general domain to the specific domain.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 34, "end_pos": 48, "type": "TASK", "confidence": 0.7088148146867752}]}, {"text": "In this paper, we perform word alignment adaptation from the general domain to a specific domain (in this study, a user manual fora medical system) with four steps.", "labels": [], "entities": [{"text": "word alignment adaptation", "start_pos": 26, "end_pos": 51, "type": "TASK", "confidence": 0.8842212160428365}]}, {"text": "(1) We train a word alignment model using the large-scale bilingual corpus in the general domain; (2) We train another word alignment model using the small-scale bilingual corpus in the specific domain; (3) We build two translation dictionaries according to the alignment results in (1) and (2) respectively; (4) For each sentence pair in the specific domain, we use the two models to get different word alignment results and improve the results according to the translation dictionaries.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 15, "end_pos": 29, "type": "TASK", "confidence": 0.7281671613454819}]}, {"text": "Experimental results show that our method improves domain-specific word alignment in terms of both precision and recall, achieving a 21.96% relative error rate reduction.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 67, "end_pos": 81, "type": "TASK", "confidence": 0.6844098418951035}, {"text": "precision", "start_pos": 99, "end_pos": 108, "type": "METRIC", "confidence": 0.9992510676383972}, {"text": "recall", "start_pos": 113, "end_pos": 119, "type": "METRIC", "confidence": 0.9985523819923401}, {"text": "relative error rate", "start_pos": 140, "end_pos": 159, "type": "METRIC", "confidence": 0.7519926925500234}]}, {"text": "The acquired alignment results are used in a generalized translation memory system (GTMS, a kind of computer assisted translation systems)).", "labels": [], "entities": []}, {"text": "This kind of system facilitates the re-use of existing translation pairs to translate documents.", "labels": [], "entities": []}, {"text": "When translating anew sentence, the system tries to provide the pre-translated examples matched with the input and recommends a translation to the human translator, and then the translator edits the suggestion to get a final translation.", "labels": [], "entities": []}, {"text": "The conventional TMS can only recommend translation examples on the sentential level while GTMS can work on both sentential and sub-sentential levels by using word alignment results.", "labels": [], "entities": [{"text": "GTMS", "start_pos": 91, "end_pos": 95, "type": "DATASET", "confidence": 0.8768569231033325}, {"text": "word alignment", "start_pos": 159, "end_pos": 173, "type": "TASK", "confidence": 0.6857515424489975}]}, {"text": "These GTMS are usually employed to translate various documents such as user manuals, computer operation guides, and mechanical operation manuals.", "labels": [], "entities": []}, {"text": "In statistical translation models (, only one-to-one and more-to-one word alignment links can be found.", "labels": [], "entities": [{"text": "statistical translation", "start_pos": 3, "end_pos": 26, "type": "TASK", "confidence": 0.5225462466478348}]}, {"text": "Thus, some multi-word units cannot be correctly aligned.", "labels": [], "entities": []}, {"text": "In order to deal with this problem, we perform translation in two directions (English to Chinese, and Chinese to English) as described in).", "labels": [], "entities": []}, {"text": "The GIZA++ toolkit 1 is used to perform statistical word alignment.", "labels": [], "entities": [{"text": "GIZA++ toolkit 1", "start_pos": 4, "end_pos": 20, "type": "DATASET", "confidence": 0.8645645529031754}, {"text": "statistical word alignment", "start_pos": 40, "end_pos": 66, "type": "TASK", "confidence": 0.733969529469808}]}, {"text": "For the general domain, we use and to represent the alignment sets obtained with English as the source language and Chinese as the target language or vice versa.", "labels": [], "entities": []}, {"text": "For alignment links in both sets, we use i for English words and j for Chinese words. is the position of the source word aligned to the target word in position k.", "labels": [], "entities": []}, {"text": "The set indicates the words aligned to the same source word k.", "labels": [], "entities": []}, {"text": "For example, if a Chinese word in position j is connect to an English word in position i, then . And if a Chinese word in position j is connect to English words in position i and k, then . Based on the above two alignment sets, we obtain their intersection set, union set 2 and subtraction set.", "labels": [], "entities": []}, {"text": "Intersection: For the specific domain, we use and to represent the word alignment sets in the two directions.", "labels": [], "entities": []}, {"text": "The symbols , 1 SF 2 SF SF PF and MF represents the intersection set, union set and the subtraction set, respectively.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1. Word Alignment Adaptation Results", "labels": [], "entities": [{"text": "Word Alignment Adaptation", "start_pos": 10, "end_pos": 35, "type": "TASK", "confidence": 0.8170465330282847}]}]}