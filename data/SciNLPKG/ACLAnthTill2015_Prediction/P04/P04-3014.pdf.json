{"title": [{"text": "Improving Bitext Word Alignments via Syntax-based Reordering of English", "labels": [], "entities": [{"text": "Improving Bitext Word Alignments", "start_pos": 0, "end_pos": 32, "type": "TASK", "confidence": 0.8296765089035034}, {"text": "Syntax-based Reordering of English", "start_pos": 37, "end_pos": 71, "type": "TASK", "confidence": 0.7088160067796707}]}], "abstractContent": [{"text": "We present an improved method for automated word alignment of parallel texts which takes advantage of knowledge of syntactic divergences, while avoiding the need for syntactic analysis of the less resource rich language, and retaining the robustness of syntactically agnostic approaches such as the IBM word alignment models.", "labels": [], "entities": [{"text": "word alignment of parallel texts", "start_pos": 44, "end_pos": 76, "type": "TASK", "confidence": 0.8313992857933045}, {"text": "syntactic analysis", "start_pos": 166, "end_pos": 184, "type": "TASK", "confidence": 0.7042869180440903}, {"text": "IBM word alignment", "start_pos": 299, "end_pos": 317, "type": "TASK", "confidence": 0.6061795552571615}]}, {"text": "We achieve this by using simple, easily-elicited knowledge to produce syntax-based heuristics which transform the target language (e.g. English) into a form more closely resembling the source language, and then by using standard alignment methods to align the transformed bitext.", "labels": [], "entities": []}, {"text": "We present experimental results under variable resource conditions.", "labels": [], "entities": []}, {"text": "The method improves word alignment performance for language pairs such as English-Korean and English-Hindi, which exhibit longer-distance syntactic divergences.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 20, "end_pos": 34, "type": "TASK", "confidence": 0.7840714156627655}]}], "introductionContent": [{"text": "Word-level alignment is a key infrastructural technology for multilingual processing.", "labels": [], "entities": [{"text": "Word-level alignment", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.6855766922235489}]}, {"text": "It is crucial for the development of translation models and translation lexica, as well as for translingual projection (;).", "labels": [], "entities": [{"text": "translation models", "start_pos": 37, "end_pos": 55, "type": "TASK", "confidence": 0.9234972596168518}, {"text": "translingual projection", "start_pos": 95, "end_pos": 118, "type": "TASK", "confidence": 0.840933620929718}]}, {"text": "It has increasingly attracted attention as a task worthy of study in its own right).", "labels": [], "entities": []}, {"text": "Syntax-light alignment models such as the five IBM models ( and their relatives have proved to be very successful and robust at producing word-level alignments, especially for closely related languages with similar word order and mostly local reorderings, which can be captured via simple models of relative word distortion.", "labels": [], "entities": [{"text": "word-level alignments", "start_pos": 138, "end_pos": 159, "type": "TASK", "confidence": 0.7226094901561737}]}, {"text": "However, these models have been less successful at modeling syntactic distortions with longer distance movement.", "labels": [], "entities": []}, {"text": "In contrast, more syntactically informed approaches have been constrained by the often weak syntactic correspondences typical of real-world parallel texts, and by the difficulty of finding or inducing syntactic parsers for any but a few of the world's most studied languages.", "labels": [], "entities": []}, {"text": "Our approach uses simple, easily-elicited knowledge of divergences to produce heuristic syntaxbased transformations from English to a form (English ) more closely resembling the source lan-", "labels": [], "entities": []}], "datasetContent": [{"text": "For each language we treated, we assembled sentence-aligned, tokenized training and test corpora, with hand-annotated gold-standard word alignments for the latter 1 . We did not apply any sort of morphological analysis beyond basic word tokenization.", "labels": [], "entities": []}, {"text": "We measured system performance with wa eval align.pl, provided by Rada Mihalcea and Ted Pedersen.", "labels": [], "entities": []}, {"text": "Each training set provides the aligner with information about lexical affinities and reordering patterns.", "labels": [], "entities": []}, {"text": "For Hindi, Korean and Chinese, we also tested our system under the more difficult situation of having only a bilingual word list but no bitext available.", "labels": [], "entities": []}, {"text": "This is a plausible low-resource language scenario    and a test of the ability of the system to take sole responsibility for knowledge of reordering.", "labels": [], "entities": []}, {"text": "describes the test sets and shows the correlation in gold standard aligned word pairs between the position of the English word in the English sentence and the position of the source-language word in the source-language sentence (normalizing the positions to fall between 0 and 1).", "labels": [], "entities": []}, {"text": "The baseline (direct) correlations give quantitative evidence of differing degrees of syntactic divergence with English, and the English correlations demonstrate that our heuristics do have the effect of better fitting source language word order.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Performance in Precision, Recall, and F- measure (per cent) of all systems.", "labels": [], "entities": [{"text": "Precision", "start_pos": 25, "end_pos": 34, "type": "METRIC", "confidence": 0.9966059923171997}, {"text": "Recall", "start_pos": 36, "end_pos": 42, "type": "METRIC", "confidence": 0.9887170791625977}, {"text": "F- measure", "start_pos": 48, "end_pos": 58, "type": "METRIC", "confidence": 0.9922348459561666}]}, {"text": " Table 3: Test set characteristics, including number  of sentence pairs, mean length of English sentences,  and correlation r 2 between English and source- language normalized word positions in gold-standard  data, for direct and English situations.", "labels": [], "entities": []}]}