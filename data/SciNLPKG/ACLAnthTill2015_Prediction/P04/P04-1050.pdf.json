{"title": [{"text": "Evaluating Centering-based metrics of coherence for text structuring using a reliably annotated corpus", "labels": [], "entities": [{"text": "text structuring", "start_pos": 52, "end_pos": 68, "type": "TASK", "confidence": 0.7181901931762695}]}], "abstractContent": [{"text": "We use a reliably annotated corpus to compare metrics of coherence based on Centering Theory with respect to their potential usefulness for text structuring in natural language generation.", "labels": [], "entities": [{"text": "text structuring", "start_pos": 140, "end_pos": 156, "type": "TASK", "confidence": 0.7250174283981323}, {"text": "natural language generation", "start_pos": 160, "end_pos": 187, "type": "TASK", "confidence": 0.6215874056021372}]}, {"text": "Previous corpus-based evaluations of the coherence of text according to Centering did not compare the coherence of the chosen text structure with that of the possible alternatives.", "labels": [], "entities": []}, {"text": "A corpus-based methodology is presented which distinguishes between Centering-based metrics taking these alternatives into account, and represents therefore a more appropriate way to evaluate Centering from a text structuring perspective.", "labels": [], "entities": []}], "introductionContent": [], "datasetContent": [], "tableCaptions": [{"text": " Table 3: Comparing M.NOCB with M.CHEAP, M.KP and M.BFP in gnome", "labels": [], "entities": []}, {"text": " Table 4: Comparing M.NOCB with M.CHEAP, M.KP and M.BFP using the novel methodology  in MPIRO", "labels": [], "entities": [{"text": "MPIRO", "start_pos": 88, "end_pos": 93, "type": "DATASET", "confidence": 0.7814611792564392}]}]}