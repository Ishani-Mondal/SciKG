{"title": [{"text": "Statistical Machine Translation with Word-and Sentence-Aligned Parallel Corpora", "labels": [], "entities": [{"text": "Statistical Machine Translation", "start_pos": 0, "end_pos": 31, "type": "TASK", "confidence": 0.7732534209887186}]}], "abstractContent": [{"text": "The parameters of statistical translation models are typically estimated from sentence-aligned parallel corpora.", "labels": [], "entities": [{"text": "statistical translation", "start_pos": 18, "end_pos": 41, "type": "TASK", "confidence": 0.6659795343875885}]}, {"text": "We show that significant improvements in the alignment and translation quality of such models can be achieved by additionally including word-aligned data during training.", "labels": [], "entities": []}, {"text": "Incorporating word-level alignments into the parameter estimation of the IBM models reduces alignment error rate and increases the Bleu score when compared to training the same models only on sentence-aligned data.", "labels": [], "entities": [{"text": "alignment error rate", "start_pos": 92, "end_pos": 112, "type": "METRIC", "confidence": 0.6774922311306}, {"text": "Bleu score", "start_pos": 131, "end_pos": 141, "type": "METRIC", "confidence": 0.9912871420383453}]}, {"text": "On the Verbmobil data set, we attain a 38% reduction in the alignment error rate and a higher Bleu score with half as many training examples.", "labels": [], "entities": [{"text": "Verbmobil data set", "start_pos": 7, "end_pos": 25, "type": "DATASET", "confidence": 0.9694013992945353}, {"text": "alignment error rate", "start_pos": 60, "end_pos": 80, "type": "METRIC", "confidence": 0.7949756383895874}, {"text": "Bleu score", "start_pos": 94, "end_pos": 104, "type": "METRIC", "confidence": 0.9861290454864502}]}, {"text": "We discuss how varying the ratio of word-aligned to sentence-aligned data affects the expected performance gain.", "labels": [], "entities": []}], "introductionContent": [{"text": "Machine translation systems based on probabilistic translation models ( are generally trained using sentence-aligned parallel corpora.", "labels": [], "entities": [{"text": "Machine translation", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.7577446401119232}]}, {"text": "For many language pairs these exist in abundant quantities.", "labels": [], "entities": []}, {"text": "However for new domains or uncommon language pairs extensive parallel corpora are often hard to come by.", "labels": [], "entities": []}, {"text": "Two factors could increase the performance of statistical machine translation for new language pairs and domains: a reduction in the cost of creating new training data, and the development of more efficient methods for exploiting existing training data.", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 46, "end_pos": 77, "type": "TASK", "confidence": 0.6937005321184794}]}, {"text": "Approaches such as harvesting parallel corpora from the web address the creation of data.", "labels": [], "entities": []}, {"text": "We take the second, complementary approach.", "labels": [], "entities": []}, {"text": "We address the problem of efficiently exploiting existing parallel corpora by adding explicit word-level alignments between a number of the sentence pairs in the training corpus.", "labels": [], "entities": []}, {"text": "We modify the standard parameter estimation procedure for IBM Models and HMM variants so that they can exploit these additional wordlevel alignments.", "labels": [], "entities": [{"text": "IBM Models and HMM", "start_pos": 58, "end_pos": 76, "type": "DATASET", "confidence": 0.8457117229700089}]}, {"text": "Our approach uses both word-and sentence-level alignments for training material.", "labels": [], "entities": []}, {"text": "In this paper we: 1.", "labels": [], "entities": []}, {"text": "Describe how the parameter estimation framework of can be adapted to incorporate word-level alignments; 2.", "labels": [], "entities": []}, {"text": "Report significant improvements in alignment error rate and translation quality when training on data with word-level alignments; 3.", "labels": [], "entities": [{"text": "error rate", "start_pos": 45, "end_pos": 55, "type": "METRIC", "confidence": 0.8166483640670776}]}, {"text": "Demonstrate that the inclusion of word-level alignments is more effective than using a bilingual dictionary; 4.", "labels": [], "entities": []}, {"text": "Show the importance of amplifying the contribution of word-aligned data during parameter estimation.", "labels": [], "entities": []}, {"text": "This paper shows that word-level alignments improve the parameter estimates for translation models, which in turn results in improved statistical translation for languages that do not have large sentence-aligned parallel corpora.", "labels": [], "entities": [{"text": "statistical translation", "start_pos": 134, "end_pos": 157, "type": "TASK", "confidence": 0.6711248904466629}]}], "datasetContent": [{"text": "To perform our experiments with word-level alignements we modified GIZA++, an existing and freely available implementation of the IBM models and HMM variants.", "labels": [], "entities": []}, {"text": "Our modifications involved circumventing the E-step for sentences which had word-level alignments and incorporating these observed alignment statistics in the M-step.", "labels": [], "entities": []}, {"text": "The observed and expected statistics were weighted accordingly by \u03bb and (1 \u2212 \u03bb) respectively as were their contributions to the mixed log likelihood.", "labels": [], "entities": []}, {"text": "In order to measure the accuracy of the predictions that the statistical translation models make under our various experimental settings, we choose the alignment error rate (AER) metric, which is defined in.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 24, "end_pos": 32, "type": "METRIC", "confidence": 0.9985400438308716}, {"text": "alignment error rate (AER) metric", "start_pos": 152, "end_pos": 185, "type": "METRIC", "confidence": 0.9475875071116856}]}, {"text": "We also investigated whether improved AER leads to improved translation quality.", "labels": [], "entities": [{"text": "AER", "start_pos": 38, "end_pos": 41, "type": "METRIC", "confidence": 0.9984117746353149}]}, {"text": "We used the alignments created during our AER experiments as the input to a phrase-based decoder.", "labels": [], "entities": []}, {"text": "We translated a test set of 350 sentences, and used the Bleu metric () to automatically evaluate machine translation quality.", "labels": [], "entities": [{"text": "Bleu metric", "start_pos": 56, "end_pos": 67, "type": "METRIC", "confidence": 0.8839975297451019}, {"text": "machine translation", "start_pos": 97, "end_pos": 116, "type": "TASK", "confidence": 0.6366312652826309}]}, {"text": "We used the Verbmobil German-English parallel corpus as a source of training data because it has been used extensively in evaluating statistical translation and alignment accuracy.", "labels": [], "entities": [{"text": "Verbmobil German-English parallel corpus", "start_pos": 12, "end_pos": 52, "type": "DATASET", "confidence": 0.9034834206104279}, {"text": "statistical translation", "start_pos": 133, "end_pos": 156, "type": "TASK", "confidence": 0.6209661364555359}, {"text": "alignment", "start_pos": 161, "end_pos": 170, "type": "TASK", "confidence": 0.7882503867149353}, {"text": "accuracy", "start_pos": 171, "end_pos": 179, "type": "METRIC", "confidence": 0.6640812158584595}]}, {"text": "This data set comes with a manually word-aligned set of 350 sentences which we used as our test set.", "labels": [], "entities": []}, {"text": "Our experiments additionally required a very large set of word-aligned sentence pairs to be incorporated in the training set.", "labels": [], "entities": []}, {"text": "Since previous work has shown that when training on the complete set of 34,000 sentence pairs an alignment error rate as low as 6% can be achieved for the Verbmobil data, we automatically generated a set of alignments for the entire training data set using the unmodified version of GIZA++.", "labels": [], "entities": [{"text": "alignment error rate", "start_pos": 97, "end_pos": 117, "type": "METRIC", "confidence": 0.8881057898203532}, {"text": "Verbmobil data", "start_pos": 155, "end_pos": 169, "type": "DATASET", "confidence": 0.949073076248169}]}, {"text": "We wanted to use automatic alignments in lieu of actual hand alignments so that we would be able to perform experiments using large data sets.", "labels": [], "entities": []}, {"text": "We ran a pilot experiment to test whether our automatic would produce similar results to manual alignments.", "labels": [], "entities": []}, {"text": "We divided our manual word alignments into training and test sets and compared the performance of models trained on human aligned data against models trained on automatically aligned data.", "labels": [], "entities": [{"text": "word alignments", "start_pos": 22, "end_pos": 37, "type": "TASK", "confidence": 0.7288367301225662}]}, {"text": "100-fold cross validation showed that manual and automatic alignments produced AER results that were similar to each other to within 0.1%.", "labels": [], "entities": [{"text": "AER", "start_pos": 79, "end_pos": 82, "type": "METRIC", "confidence": 0.9987044334411621}]}, {"text": "Having satisfied ourselves that automatic alignment were a sufficient stand-in for manual alignments, we performed our main experiments which fell into the following categories: 1.", "labels": [], "entities": [{"text": "automatic alignment", "start_pos": 32, "end_pos": 51, "type": "TASK", "confidence": 0.594084769487381}]}, {"text": "Verifying that the use of word-aligned data has an impact on the quality of alignments predicted by the IBM Models, and comparing the quality increase to that gained by using a bilingual dictionary in the estimation stage.", "labels": [], "entities": [{"text": "IBM Models", "start_pos": 104, "end_pos": 114, "type": "DATASET", "confidence": 0.9423075318336487}]}, {"text": "2. Evaluating whether improved parameter estimates of alignment quality lead to improved translation quality.", "labels": [], "entities": [{"text": "translation", "start_pos": 89, "end_pos": 100, "type": "TASK", "confidence": 0.955565869808197}]}, {"text": "3. Experimenting with how increasing the ratio of word-aligned to sentence-aligned data affected the performance.", "labels": [], "entities": []}, {"text": "4. Experimenting with our \u03bb parameter which allows us to weight the relative contributions of the word-aligned and sentence-aligned data, and relating it to the ratio experiments.", "labels": [], "entities": []}, {"text": "5. Showing that improvements to AER and translation quality held for another corpus.", "labels": [], "entities": [{"text": "AER", "start_pos": 32, "end_pos": 35, "type": "METRIC", "confidence": 0.9087647199630737}, {"text": "translation", "start_pos": 40, "end_pos": 51, "type": "TASK", "confidence": 0.9316684007644653}]}, {"text": "We additionally tested whether incorporating wordlevel alignments into the estimation improved results fora larger corpus.", "labels": [], "entities": []}, {"text": "We repeated our experiments using the Canadian Hansards French-English parallel corpus.", "labels": [], "entities": [{"text": "Canadian Hansards French-English parallel corpus", "start_pos": 38, "end_pos": 86, "type": "DATASET", "confidence": 0.8844516754150391}]}, {"text": "gives a summary of the improvements in AER and Bleu score for that corpus, when testing on a held outset of 484 hand aligned sentences.", "labels": [], "entities": [{"text": "AER", "start_pos": 39, "end_pos": 42, "type": "METRIC", "confidence": 0.999240517616272}, {"text": "Bleu score", "start_pos": 47, "end_pos": 57, "type": "METRIC", "confidence": 0.9768815338611603}]}, {"text": "On the whole, alignment error rates are higher and Bleu scores are considerably lower for the Hansards corpus.", "labels": [], "entities": [{"text": "alignment error", "start_pos": 14, "end_pos": 29, "type": "METRIC", "confidence": 0.6740205585956573}, {"text": "Bleu scores", "start_pos": 51, "end_pos": 62, "type": "METRIC", "confidence": 0.9792877733707428}, {"text": "Hansards corpus", "start_pos": 94, "end_pos": 109, "type": "DATASET", "confidence": 0.9826695919036865}]}, {"text": "This is probably due to the differences in the corpora.", "labels": [], "entities": []}, {"text": "Whereas the Verbmobil corpus has a small vocabulary (<10,000 per lan-", "labels": [], "entities": [{"text": "Verbmobil corpus", "start_pos": 12, "end_pos": 28, "type": "DATASET", "confidence": 0.94666787981987}]}], "tableCaptions": [{"text": " Table 1: Alignment error rates for the various IBM  Models trained with sentence-aligned data", "labels": [], "entities": [{"text": "Alignment error rates", "start_pos": 10, "end_pos": 31, "type": "METRIC", "confidence": 0.7326717873414358}]}, {"text": " Table 2: Alignment error rates for the various IBM  Models trained with word-aligned data", "labels": [], "entities": [{"text": "Alignment error rates", "start_pos": 10, "end_pos": 31, "type": "METRIC", "confidence": 0.7262450059254965}]}, {"text": " Table 3: The improved alignment error rates when  using a dictionary instead of word-aligned data to  constrain word translations", "labels": [], "entities": [{"text": "word translations", "start_pos": 113, "end_pos": 130, "type": "TASK", "confidence": 0.7111170142889023}]}, {"text": " Table 4: Improved AER leads to improved transla- tion quality", "labels": [], "entities": [{"text": "Improved", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9887435436248779}, {"text": "AER", "start_pos": 19, "end_pos": 22, "type": "METRIC", "confidence": 0.9194771647453308}]}]}