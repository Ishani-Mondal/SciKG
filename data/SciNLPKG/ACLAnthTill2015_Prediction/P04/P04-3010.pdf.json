{"title": [{"text": "Part-of-Speech Tagging Considering Surface Form for an Agglutinative Language", "labels": [], "entities": [{"text": "Part-of-Speech Tagging", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.8124478757381439}]}], "abstractContent": [{"text": "The previous probabilistic part-of-speech tagging models for agglutinative languages have considered only lexical forms of morphemes, not surface forms of words.", "labels": [], "entities": [{"text": "part-of-speech tagging", "start_pos": 27, "end_pos": 49, "type": "TASK", "confidence": 0.6954471915960312}]}, {"text": "This causes an inaccurate calculation of the probability.", "labels": [], "entities": []}, {"text": "The proposed model is based on the observation that when there exist words (surface forms) that share the same lexical forms, the probabilities to appear are different from each other.", "labels": [], "entities": []}, {"text": "Also, it is designed to consider lexical form of word.", "labels": [], "entities": []}, {"text": "By experiments, we show that the proposed model outperforms the bigram Hidden Markov model (HMM)-based tagging model.", "labels": [], "entities": []}], "introductionContent": [{"text": "Part-of-speech (POS) tagging is a job to assign a proper POS tag to each linguistic unit such as word fora given sentence.", "labels": [], "entities": [{"text": "Part-of-speech (POS) tagging", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.5909167408943177}]}, {"text": "In English POS tagging, word is used as a linguistic unit.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 11, "end_pos": 22, "type": "TASK", "confidence": 0.9026508927345276}]}, {"text": "However, the number of possible words in agglutinative languages such as Korean is almost infinite because words can be freely formed by gluing morphemes together.", "labels": [], "entities": []}, {"text": "Therefore, morpheme-unit tagging is preferred and more suitable in such languages than word-unit tagging.", "labels": [], "entities": [{"text": "morpheme-unit tagging", "start_pos": 11, "end_pos": 32, "type": "TASK", "confidence": 0.6294153183698654}, {"text": "word-unit tagging", "start_pos": 87, "end_pos": 104, "type": "TASK", "confidence": 0.7018111199140549}]}, {"text": "shows an example of morpheme structure of a sentence, where the bold lines indicate the most likely morpheme-POS sequence.", "labels": [], "entities": []}, {"text": "A solid line represents a transition between two morphemes across a word boundary and a dotted line represents a transition between two morphemes in a word.", "labels": [], "entities": []}, {"text": "The previous probabilistic POS models for agglutinative languages have considered only lexical forms of morphemes, not surface forms of words.", "labels": [], "entities": []}, {"text": "This causes an inaccurate calculation of the probability.", "labels": [], "entities": []}, {"text": "The proposed model is based on the observation that when there exist words (surface forms) that share the same lexical forms, the probabilities to appear are different from each other.", "labels": [], "entities": []}, {"text": "Also, it is designed to consider lexical form of word.", "labels": [], "entities": []}, {"text": "By experiments, we show that the proposed model outperforms the bigram Hidden Markov model (HMM)-based tagging model.", "labels": [], "entities": []}], "datasetContent": [{"text": "For evaluation, two data sets are used: ETRI POS tagged corpus and KAIST POS tagged corpus.", "labels": [], "entities": [{"text": "ETRI POS tagged corpus", "start_pos": 40, "end_pos": 62, "type": "DATASET", "confidence": 0.688932791352272}, {"text": "KAIST POS tagged corpus", "start_pos": 67, "end_pos": 90, "type": "DATASET", "confidence": 0.7749634981155396}]}, {"text": "We divided the test data into ten parts.", "labels": [], "entities": []}, {"text": "The performances of the model are measured by averaging over the ten test sets in the 10-fold cross-validation experiment.", "labels": [], "entities": []}, {"text": "shows the summary of the corpora.", "labels": [], "entities": []}, {"text": "Generally, POS tagging goes through the following steps: First, run a morphological analyzer, where it generates all the possible interpretations fora given input text.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 11, "end_pos": 22, "type": "TASK", "confidence": 0.9091596603393555}]}, {"text": "Then, a POS tagger takes the results as input and chooses the most likely one among them.", "labels": [], "entities": []}, {"text": "Therefore, the performance of the tagger depends on that of the preceding morphological analyzer.", "labels": [], "entities": []}, {"text": "If the morphological analyzer does not generate the exact result, the tagger has no chance to select the correct one, thus an answer inclusion rate of the morphological analyzer becomes the upper bound of the tagger.", "labels": [], "entities": []}, {"text": "The previous works preprocessed the dictionary to include all the exact answers in the morphological analyzer's results.", "labels": [], "entities": []}, {"text": "However, this evaluation method is inappropriate to the real application in the strict sense.", "labels": [], "entities": []}, {"text": "In this experiment, we present the accuracy of the morphological analyzer instead of preprocessing the dictionary.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 35, "end_pos": 43, "type": "METRIC", "confidence": 0.9996079802513123}]}, {"text": "ProKOMA's results with the test data are listed in.", "labels": [], "entities": [{"text": "ProKOMA", "start_pos": 0, "end_pos": 7, "type": "DATASET", "confidence": 0.9466820955276489}]}, {"text": "In the table, 1-best accuracy is defined as the number of words whose result with the highest probability is matched to the gold standard over the entire words in the test data.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 21, "end_pos": 29, "type": "METRIC", "confidence": 0.702117919921875}]}, {"text": "This can also be a tagging model that does not consider any outer context.", "labels": [], "entities": []}, {"text": "To compare the proposed model with the standard model, the results of the two models are given in.", "labels": [], "entities": []}, {"text": "As can be seen, our model outperforms the HMM model.", "labels": [], "entities": []}, {"text": "Moreover, the HMM model is even worse than the ProKOMA's 1-best accuracy.", "labels": [], "entities": [{"text": "ProKOMA", "start_pos": 47, "end_pos": 54, "type": "DATASET", "confidence": 0.9491694569587708}, {"text": "accuracy", "start_pos": 64, "end_pos": 72, "type": "METRIC", "confidence": 0.8090627789497375}]}, {"text": "This tells that the standard HMM by itself is not a good model for agglutinative languages.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Summary of the data  Corpus  ETRI KAIST  Total # of words  288,291 175,468  Total # of sentences  27,855  16,193  # of tags  27  54", "labels": [], "entities": [{"text": "ETRI KAIST  Total #", "start_pos": 39, "end_pos": 58, "type": "METRIC", "confidence": 0.637786328792572}]}, {"text": " Table 2: Morphological analyzer's results with the  test data  Corpus  ETRI KAIST  Answer inclusion rate (%)  95.82 95.95  Average # of results per word 2.16  1.81  1-best accuracy (%)  88.31 90.12", "labels": [], "entities": [{"text": "Morphological analyzer", "start_pos": 10, "end_pos": 32, "type": "TASK", "confidence": 0.7350977957248688}, {"text": "ETRI KAIST  Answer inclusion rate (%)  95.82 95.95  Average # of results per word 2.16  1.81  1-best accuracy", "start_pos": 72, "end_pos": 181, "type": "METRIC", "confidence": 0.7815071741739908}]}]}