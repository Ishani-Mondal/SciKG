{"title": [{"text": "Using Conditional Random Fields to Predict Pitch Accents in Conversational Speech", "labels": [], "entities": []}], "abstractContent": [{"text": "The detection of prosodic characteristics is an important aspect of both speech synthesis and speech recognition.", "labels": [], "entities": [{"text": "speech synthesis", "start_pos": 73, "end_pos": 89, "type": "TASK", "confidence": 0.7872150242328644}, {"text": "speech recognition", "start_pos": 94, "end_pos": 112, "type": "TASK", "confidence": 0.8051165640354156}]}, {"text": "Correct placement of pitch accents aids in more natural sounding speech, while automatic detection of accents can contribute to better word-level recognition and better textual understanding.", "labels": [], "entities": [{"text": "word-level recognition", "start_pos": 135, "end_pos": 157, "type": "TASK", "confidence": 0.6846757978200912}]}, {"text": "In this paper we investigate probabilistic, contex-tual, and phonological factors that influence pitch accent placement in natural, conversational speech in a sequence labeling setting.", "labels": [], "entities": [{"text": "pitch accent placement", "start_pos": 97, "end_pos": 119, "type": "TASK", "confidence": 0.5881194969018301}]}, {"text": "We introduce Conditional Random Fields (CRFs) to pitch accent prediction task in order to incorporate these factors efficiently in a sequence model.", "labels": [], "entities": [{"text": "pitch accent prediction task", "start_pos": 49, "end_pos": 77, "type": "TASK", "confidence": 0.7306101694703102}]}, {"text": "We demonstrate the usefulness and the incremental effect of these factors in a sequence model by performing experiments on hand labeled data from the Switchboard Corpus.", "labels": [], "entities": [{"text": "Switchboard Corpus", "start_pos": 150, "end_pos": 168, "type": "DATASET", "confidence": 0.8689752519130707}]}, {"text": "Our model outperforms the baseline and previous models of pitch accent prediction on the Switchboard Corpus.", "labels": [], "entities": [{"text": "pitch accent prediction", "start_pos": 58, "end_pos": 81, "type": "TASK", "confidence": 0.6347502966721853}, {"text": "Switchboard Corpus", "start_pos": 89, "end_pos": 107, "type": "DATASET", "confidence": 0.9583054184913635}]}], "introductionContent": [{"text": "The suprasegmental features of speech relay critical information in conversation.", "labels": [], "entities": []}, {"text": "Yet, one of the major roadblocks to natural sounding speech synthesis has been the identification and implementation of prosodic characteristics.", "labels": [], "entities": [{"text": "natural sounding speech synthesis", "start_pos": 36, "end_pos": 69, "type": "TASK", "confidence": 0.6514407694339752}]}, {"text": "The difficulty with this task lies in the fact that prosodic cues are never absolute; they are relative to individual speakers, gender, dialect, discourse context, local context, phonological environment, and many other factors.", "labels": [], "entities": []}, {"text": "This is especially true of pitch accent, the acoustic cues that make one word more prominent than others in an utterance.", "labels": [], "entities": []}, {"text": "For example, a word with a fundamental frequency (f0) of 120 Hz would likely be quite prominent in a male speaker, but not fora typical female speaker.", "labels": [], "entities": [{"text": "fundamental frequency (f0)", "start_pos": 27, "end_pos": 53, "type": "METRIC", "confidence": 0.7821079850196838}]}, {"text": "Likewise, the accent on the utterance \"Jon's leaving.\" is critical in determining whether it is the answer to the question \"Who is leaving?\"", "labels": [], "entities": []}, {"text": "(\"JON's leaving.\") or \"What is Jon doing?\"", "labels": [], "entities": []}, {"text": "(\"Jon's LEAVING.\").", "labels": [], "entities": [{"text": "LEAVING.", "start_pos": 8, "end_pos": 16, "type": "METRIC", "confidence": 0.600360095500946}]}, {"text": "Accurate pitch accent prediction lies in the successful combination of as many of the contextual variables as possible.", "labels": [], "entities": [{"text": "pitch accent prediction", "start_pos": 9, "end_pos": 32, "type": "TASK", "confidence": 0.7122483253479004}]}, {"text": "Syntactic information such as part of speech has proven to be a successful predictor of accentuation).", "labels": [], "entities": []}, {"text": "In general, function words are not accented, while content words are.", "labels": [], "entities": []}, {"text": "Various measures of a word's informativeness, such as the information content (IC) of a word) and its collocational strength in a given context) have also proven to be useful models of pitch accent.", "labels": [], "entities": []}, {"text": "However, in open topic conversational speech, accent is very unpredictable.", "labels": [], "entities": [{"text": "accent", "start_pos": 46, "end_pos": 52, "type": "METRIC", "confidence": 0.9704456329345703}]}, {"text": "Part of speech and the informativeness of a word do not capture all aspects of accentuation, as we see in this example taken from Switchboard, where a function word gets accented (accented words are in uppercase): I, I have STRONG OBJECTIONS to THAT.", "labels": [], "entities": [{"text": "STRONG", "start_pos": 224, "end_pos": 230, "type": "METRIC", "confidence": 0.9666079878807068}, {"text": "OBJECTIONS", "start_pos": 231, "end_pos": 241, "type": "METRIC", "confidence": 0.5518853068351746}, {"text": "THAT", "start_pos": 245, "end_pos": 249, "type": "METRIC", "confidence": 0.6988853216171265}]}, {"text": "Accent is also influenced by aspects of rhythm and timing.", "labels": [], "entities": [{"text": "Accent", "start_pos": 0, "end_pos": 6, "type": "METRIC", "confidence": 0.9466312527656555}]}, {"text": "The length of words, in both number of phones and normalized duration, affect its likelihood of being accented.", "labels": [], "entities": []}, {"text": "Additionally, whether the immediately surrounding words bear pitch accent also affect the likelihood of accentuation.", "labels": [], "entities": []}, {"text": "In other words, a word that might typically be accented maybe unaccented because the surrounding words also bear pitch accent.", "labels": [], "entities": []}, {"text": "Phrase boundaries seem to play a role in accentuation as well.", "labels": [], "entities": []}, {"text": "The first word of intonational phrases (IP) is less likely to be accented while the last word of an IP tends be accented.", "labels": [], "entities": []}, {"text": "In short, accented words within the same IP are not independent of each other.", "labels": [], "entities": []}, {"text": "Previous work on pitch accent prediction, however, neglected the dependency between labels.", "labels": [], "entities": [{"text": "pitch accent prediction", "start_pos": 17, "end_pos": 40, "type": "TASK", "confidence": 0.689330130815506}]}, {"text": "Different machine learning techniques, such as decision trees, rule induction systems), bagging), boosting) have been used in a scenario where the accent of each word is predicted independently.", "labels": [], "entities": []}, {"text": "One exception to this line of research is the use of Hidden Markov Models (HMM) for pitch accent prediction).", "labels": [], "entities": [{"text": "pitch accent prediction", "start_pos": 84, "end_pos": 107, "type": "TASK", "confidence": 0.6397441724936167}]}, {"text": "demonstrate the effectiveness of a sequence model over a rule induction system, RIP-PER, that treats each label independently by showing that HMMs outperform RIPPER when the same variables are used.", "labels": [], "entities": []}, {"text": "Until recently, HMMs were the predominant formalism to model label sequences.", "labels": [], "entities": []}, {"text": "However, they have two major shortcomings.", "labels": [], "entities": []}, {"text": "They are trained non-discriminatively using maximum likelihood estimation to model the joint probability of the observation and label sequences.", "labels": [], "entities": []}, {"text": "Also, they require questionable independence assumptions to achieve efficient inference and learning.", "labels": [], "entities": []}, {"text": "Therefore, variables used in Hidden Markov models of pitch accent prediction have been very limited, e.g. part of speech and frequency).", "labels": [], "entities": [{"text": "pitch accent prediction", "start_pos": 53, "end_pos": 76, "type": "TASK", "confidence": 0.691359798113505}]}, {"text": "Discriminative learning methods, such as Maximum Entropy Markov Models (), Projection Based Markov Models), Conditional Random Fields (), Sequence AdaBoost (), Sequence Perceptron), Hidden Markov Support Vector Machines () and Maximum-Margin Markov Networks (), overcome the limitations of HMMs.", "labels": [], "entities": []}, {"text": "Among these methods, CRFs is the most common technique used in NLP and has been successfully applied to Part-of-Speech Tagging (), Named-Entity Recognition) and shallow parsing.", "labels": [], "entities": [{"text": "Part-of-Speech Tagging", "start_pos": 104, "end_pos": 126, "type": "TASK", "confidence": 0.7674312591552734}, {"text": "Named-Entity Recognition", "start_pos": 131, "end_pos": 155, "type": "TASK", "confidence": 0.6847137659788132}, {"text": "shallow parsing", "start_pos": 161, "end_pos": 176, "type": "TASK", "confidence": 0.8020100891590118}]}, {"text": "The goal of this study is to better identify which words in a string of text will bear pitch accent.", "labels": [], "entities": []}, {"text": "Our contribution is two-fold: employing new predictors and utilizing a discriminative model.", "labels": [], "entities": []}, {"text": "We combine the advantages of probabilistic, syntactic, and phonological predictors with the advantages of modeling pitch accent in a sequence labeling setting using CRFs ().", "labels": [], "entities": []}, {"text": "The rest of the paper is organized as follows: In Section 2, we introduce CRFs.", "labels": [], "entities": []}, {"text": "Then, we describe our corpus and the variables in Section 3 and Section 4.", "labels": [], "entities": []}, {"text": "We present the experimental setup and report results in Section 5.", "labels": [], "entities": []}, {"text": "Finally, we discuss our results (Section 6) and conclude (Section 7).", "labels": [], "entities": []}], "datasetContent": [{"text": "All experiments were run using 10 fold crossvalidation.", "labels": [], "entities": []}, {"text": "We used Viterbi decoding to find the most likely sequence and report the performance in terms of label accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 103, "end_pos": 111, "type": "METRIC", "confidence": 0.8697179555892944}]}, {"text": "We ran all experiments with varying window sizes (w \u2208 {1, 3, 5}).", "labels": [], "entities": []}, {"text": "The baseline which simply assigns the most common label, unaccented, achieves 60.53 \u00b1 1.50%.", "labels": [], "entities": []}, {"text": "Previous research has demonstrated that part of speech and frequency, or a combination of these two, are very reliable predictors of pitch accent.", "labels": [], "entities": []}, {"text": "Thus, to test the worthiness of using a CRF model, the first experiment we ran was a comparison of an HMM to a CRF using just the combination of part of speech and unigram.", "labels": [], "entities": []}, {"text": "The HMM score (referred as HMM:POS, Unigram in) was 68.62 \u00b1 1.78, while the CRF model (referred as CRF:POS, Unigram in) performed significantly better at 72.56 \u00b1 1.86.", "labels": [], "entities": []}, {"text": "Note that Pan and McKeown (1999) reported 74% accuracy with their HMM model.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 46, "end_pos": 54, "type": "METRIC", "confidence": 0.9995835423469543}]}, {"text": "The difference is due to the different corpora used in each case.", "labels": [], "entities": []}, {"text": "While they also used spontaneous speech, it was a limited domain in the sense that it was speech from discharge orders from doctors atone medical facility.", "labels": [], "entities": []}, {"text": "The SWDB corpus is open domain conversational speech.", "labels": [], "entities": [{"text": "SWDB corpus", "start_pos": 4, "end_pos": 15, "type": "DATASET", "confidence": 0.7479744553565979}]}, {"text": "In order to capture some aspects of the IC and collocational strength of a word, in the second experiment we ran part of speech plus all of the probabilistic variables (referred as CRF:POS, Prob in).", "labels": [], "entities": [{"text": "IC", "start_pos": 40, "end_pos": 42, "type": "TASK", "confidence": 0.9036290645599365}]}, {"text": "The model accuracy was 73.94%, thus improved over the model using POS and unigram values by 1.38%.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9989069700241089}]}, {"text": "In the third experiment we wanted to know if TTS applications that made use of purely textual input could be aided by the addition of timing and rhythm variables that can be gleaned from a text string.", "labels": [], "entities": [{"text": "TTS", "start_pos": 45, "end_pos": 48, "type": "TASK", "confidence": 0.9395708441734314}, {"text": "timing", "start_pos": 134, "end_pos": 140, "type": "METRIC", "confidence": 0.954729437828064}]}, {"text": "Thus, we included the textual features described in Section 4.3 in addition to the probabilistic and syntactic features (referred as CRF:POS, Prob, Txt in).", "labels": [], "entities": []}, {"text": "The accuracy was improved by 1.73%.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.999624490737915}]}, {"text": "For the final experiment, we added the acoustic variable, resulting in the use of all the variables described in Section 4 (referred as CRF:All in).", "labels": [], "entities": []}, {"text": "We get about 0.5% increase inaccuracy, 76.1% with a window of size w = 1.", "labels": [], "entities": [{"text": "inaccuracy", "start_pos": 27, "end_pos": 37, "type": "METRIC", "confidence": 0.984666109085083}]}, {"text": "Using larger windows resulted in minor increases in the performance of the model, as summarized in.", "labels": [], "entities": []}, {"text": "Our best accuracy was 76.36% using all features in aw = 5 window size.: Test accuracy of pitch accent prediction on SWDB using various variables and window sizes.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 9, "end_pos": 17, "type": "METRIC", "confidence": 0.9992870688438416}, {"text": "accuracy", "start_pos": 77, "end_pos": 85, "type": "METRIC", "confidence": 0.9976133108139038}, {"text": "pitch accent prediction", "start_pos": 89, "end_pos": 112, "type": "TASK", "confidence": 0.6287762820720673}]}], "tableCaptions": [{"text": " Table 1: Percentage of accented and unaccented  items by POS.", "labels": [], "entities": [{"text": "POS", "start_pos": 58, "end_pos": 61, "type": "DATASET", "confidence": 0.7154013514518738}]}, {"text": " Table 5: Test accuracy of pitch accent prediction on  SWDB using various variables and window sizes.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 15, "end_pos": 23, "type": "METRIC", "confidence": 0.9992606043815613}, {"text": "pitch accent prediction", "start_pos": 27, "end_pos": 50, "type": "TASK", "confidence": 0.6428294082482656}]}]}