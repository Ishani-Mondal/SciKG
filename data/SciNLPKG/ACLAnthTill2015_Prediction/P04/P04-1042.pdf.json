{"title": [{"text": "Deep dependencies from context-free statistical parsers: correcting the surface dependency approximation", "labels": [], "entities": []}], "abstractContent": [{"text": "We present a linguistically-motivated algorithm for reconstructing nonlocal dependency in broad-coverage context-free parse trees derived from treebanks.", "labels": [], "entities": []}, {"text": "We use an algorithm based on loglinear classifiers to augment and reshape context-free trees so as to reintroduce underlying nonlocal dependencies lost in the context-free approximation.", "labels": [], "entities": []}, {"text": "We find that our algorithm compares favorably with prior work on English using an existing evaluation metric, and also introduce and argue fora new dependency-based evaluation metric.", "labels": [], "entities": []}, {"text": "By this new evaluation metric our algorithm achieves 60% error reduction on gold-standard input trees and 5% error reduction on state-of-the-art machine-parsed input trees, when compared with the best previous work.", "labels": [], "entities": []}, {"text": "We also present the first results on non-local dependency reconstruction fora language other than En-glish, comparing performance on English and German.", "labels": [], "entities": []}, {"text": "Our new evaluation metric quantitatively corroborates the intuition that in a language with freer word order, the surface dependencies in context-free parse trees area poorer approximation to underlying dependency structure.", "labels": [], "entities": []}], "introductionContent": [{"text": "While parsers are been used for other purposes, the primary motivation for syntactic parsing is as an aid to semantic interpretation, in pursuit of broader goals of natural language understanding.", "labels": [], "entities": [{"text": "syntactic parsing", "start_pos": 75, "end_pos": 92, "type": "TASK", "confidence": 0.7486916184425354}, {"text": "semantic interpretation", "start_pos": 109, "end_pos": 132, "type": "TASK", "confidence": 0.7227441370487213}, {"text": "natural language understanding", "start_pos": 165, "end_pos": 195, "type": "TASK", "confidence": 0.6719032227993011}]}, {"text": "Proponents of traditional 'deep' or 'precise' approaches to syntax, such as GB, CCG, HPSG, LFG, or TAG, have argued that sophisticated grammatical formalisms are essential to resolving various hidden relationships such as the source phrase of moved whphrases in questions and relativizations, or the controller of clauses without an overt subject.", "labels": [], "entities": []}, {"text": "Knowledge of these hidden relationships is in turn essential to semantic interpretation of the kind practiced in the semantic parsing () and QA) literatures.", "labels": [], "entities": [{"text": "semantic interpretation", "start_pos": 64, "end_pos": 87, "type": "TASK", "confidence": 0.8708278834819794}, {"text": "semantic parsing", "start_pos": 117, "end_pos": 133, "type": "TASK", "confidence": 0.7450173199176788}]}, {"text": "However, work in statistical parsing has for the most part put these needs aside, being content to recover surface context-free (CF) phrase structure trees.", "labels": [], "entities": [{"text": "statistical parsing", "start_pos": 17, "end_pos": 36, "type": "TASK", "confidence": 0.8411853611469269}]}, {"text": "This perhaps reflects the fact that context-free phrase structure grammar (CFG) is in some sense at the the heart of the majority of both formal and computational syntactic research.", "labels": [], "entities": [{"text": "context-free phrase structure grammar (CFG)", "start_pos": 36, "end_pos": 79, "type": "TASK", "confidence": 0.7911979896681649}]}, {"text": "Although, upon introducing it, rejected CFG as an adequate framework for natural language description, the majority of work in the last half century has used context-free structural descriptions and related methodologies in one form or another as an important component of syntactic analysis.", "labels": [], "entities": [{"text": "natural language description", "start_pos": 73, "end_pos": 101, "type": "TASK", "confidence": 0.6757746835549673}, {"text": "syntactic analysis", "start_pos": 273, "end_pos": 291, "type": "TASK", "confidence": 0.8325746655464172}]}, {"text": "CFGs seem adequate to weakly generate almost all common natural language structures, and also facilitate a transparent predicate-argument and/or semantic interpretation for the more basic ones (.", "labels": [], "entities": [{"text": "CFGs", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.7448148131370544}]}, {"text": "Nevertheless, despite their success in providing surface phrase structure analyses, if statistical parsers and the representations they produce do not provide a useful steppingstone to recovering the hidden relationships, they will ultimately come to be seen as a dead end, and work will necessarily return to using richer formalisms.", "labels": [], "entities": [{"text": "surface phrase structure analyses", "start_pos": 49, "end_pos": 82, "type": "TASK", "confidence": 0.7009453177452087}]}, {"text": "In this paper we attempt to establish to what degree current statistical parsers area useful step in analysis by examining the performance of further statistical classifiers on non-local dependency recovery from CF parse trees.", "labels": [], "entities": []}, {"text": "The natural isomorphism from CF trees to dependency trees induces only local dependencies, derived from the headsister relation in a CF local tree.", "labels": [], "entities": []}, {"text": "However, if the output of a context-free parser can be algorithmically augmented to accurately identify and incorporate nonlocal dependencies, then we can say that the context-free parsing model is a safe approximation to the true task of dependency reconstruction.", "labels": [], "entities": [{"text": "dependency reconstruction", "start_pos": 239, "end_pos": 264, "type": "TASK", "confidence": 0.787100076675415}]}, {"text": "We investigate the safeness of this approximation, devising an algorithm to reconstruct non-local dependencies from context-free parse trees using loglinear classifiers, tested on treebanks of not only English but also German, a language with much freer word order and correspondingly more discontinuity than English.", "labels": [], "entities": []}, {"text": "This algorithm can be used as an intermediate step between the surface output trees of modern statistical parsers and semantic interpretation systems fora variety of tasks.", "labels": [], "entities": []}, {"text": "1: Example of empty and nonlocal annotations from the Penn Treebank of English, including null complementizers (0), relativization (*T*-1), rightextraposition (*ICH*-2), and syntactic control (*-3).", "labels": [], "entities": [{"text": "Penn Treebank of English", "start_pos": 54, "end_pos": 78, "type": "DATASET", "confidence": 0.9844755232334137}]}], "datasetContent": [{"text": "The datasets used for this study consist of the Wall Street Journal section of the Penn Treebank of English (WSJ) and the context-free version of the NEGRA (version 2) corpus of German ().", "labels": [], "entities": [{"text": "Wall Street Journal section of the Penn Treebank of English (WSJ)", "start_pos": 48, "end_pos": 113, "type": "DATASET", "confidence": 0.9449866643318763}, {"text": "NEGRA (version 2) corpus of German", "start_pos": 150, "end_pos": 184, "type": "DATASET", "confidence": 0.7700932249426842}]}, {"text": "Full-size experiments on WSJ described in Section 4 used the standard sections 2-21 for training, 24 for development, and trees whose yield is under 100 words from section 23 for testing.", "labels": [], "entities": [{"text": "WSJ", "start_pos": 25, "end_pos": 28, "type": "DATASET", "confidence": 0.7701991200447083}]}, {"text": "Experiments described in Section 4.3 used the same development and test sets but files 200-959 of WSJ as a smaller training set; for NEGRA we followed in using the first 18,602 sentences for training, the last 1,000 for development, and the previous 1,000 for testing.", "labels": [], "entities": [{"text": "WSJ", "start_pos": 98, "end_pos": 101, "type": "DATASET", "confidence": 0.9773923754692078}, {"text": "NEGRA", "start_pos": 133, "end_pos": 138, "type": "DATASET", "confidence": 0.8728447556495667}]}, {"text": "Consistent with prior work and with common practice in statistical parsing, we stripped categories of all functional tags prior to training and testing (though in several cases this seems to have been a limiting move; see Section 5).", "labels": [], "entities": [{"text": "statistical parsing", "start_pos": 55, "end_pos": 74, "type": "TASK", "confidence": 0.8077856004238129}]}, {"text": "Nonlocal dependency annotation in Penn Treebanks can be divided into three major types: unindexed empty elements, dislocations, and control.", "labels": [], "entities": [{"text": "Penn Treebanks", "start_pos": 34, "end_pos": 48, "type": "DATASET", "confidence": 0.9860389828681946}]}, {"text": "The first type consists primarily of null complementizers, as exemplified in by the null relative pronoun 0 (c.f. aspects that it sees), and do not participate in (though they may mediate) nonlocal dependency.", "labels": [], "entities": []}, {"text": "The second type consists of a dislocated element coindexed with an origin site of semantic interpretation, as in the association in is fun.)", "labels": [], "entities": []}, {"text": "Controllers are to be interpreted as syntactic (and possibly semantic) arguments both in their overt position and in the position of loci they control.", "labels": [], "entities": []}, {"text": "This type encompasses raising, control, passivization, and unexpressed subjects of to-infinitive and gerund verbs, among other constructions.", "labels": [], "entities": []}, {"text": "NEGRA's original annotation is as dependency trees with phrasal nodes, crossing branches, and no empty elements.", "labels": [], "entities": [{"text": "NEGRA", "start_pos": 0, "end_pos": 5, "type": "DATASET", "confidence": 0.8992170691490173}]}, {"text": "However, the distribution includes a context-free version produced algorithmically by recursively remapping discontinuous parts of nodes upward into higher phrases and marking their sites of origin.", "labels": [], "entities": []}, {"text": "The resulting \"traces\" correspond roughly to a subclass of the second class of Penn Treebank empties discussed above, and include wh-movement, topicalization, right extrapositions from NP, expletives, and scrambling of sub-2 Four of the annotation errors in WSJ lead to uninterpretable dislocation and sharing patterns, including failure to annotate dislocations corresponding to marked origin sites, and mislabelings of control loci as origin sites of dislocation that lead to cyclic dislocations (which are explicitly prohibited in WSJ annotation guidelines).", "labels": [], "entities": [{"text": "Penn Treebank empties", "start_pos": 79, "end_pos": 100, "type": "DATASET", "confidence": 0.9911083579063416}, {"text": "WSJ", "start_pos": 258, "end_pos": 261, "type": "DATASET", "confidence": 0.9610537886619568}]}, {"text": "We corrected these errors manually before model testing and training.", "labels": [], "entities": []}, {"text": "3 For a detailed description of the algorithm for creating the context-free version of NEGRA, see  jects after other complements.", "labels": [], "entities": []}, {"text": "The positioning of NEGRA's \"traces\" inside the mother node is completely algorithmic; a dislocated constituent C has its trace at the edge of the original mother closest to C's overt position.", "labels": [], "entities": []}, {"text": "Given a context-free NEGRA tree shorn of its trace/antecedent notation, however, it is far from trivial to determine which nodes are dislocated, and where they come from.", "labels": [], "entities": []}, {"text": "shows an annotated sentence from the NEGRA corpus with discontinuities due to right extraposition (*T1*) and topicalization (*T2*), before and after transformation into context-free form with traces.", "labels": [], "entities": [{"text": "NEGRA corpus", "start_pos": 37, "end_pos": 49, "type": "DATASET", "confidence": 0.951928049325943}]}], "tableCaptions": [{"text": " Table 1: Shared feature templates. See text for template  descriptions. # Special is the number of special templates  used for the classifier. \u2297 denotes that all subsets of the  template conjunction were included.", "labels": [], "entities": []}, {"text": " Table 2: Comparison with previous work using John- son's PARSEVAL metric. Jn is Johnson (2002); DD is  Dienes and Dubey (2003b); Pres is the present work.", "labels": [], "entities": [{"text": "John- son's", "start_pos": 46, "end_pos": 57, "type": "DATASET", "confidence": 0.9188618659973145}, {"text": "PARSEVAL metric", "start_pos": 58, "end_pos": 73, "type": "METRIC", "confidence": 0.5383537113666534}, {"text": "Pres", "start_pos": 130, "end_pos": 134, "type": "METRIC", "confidence": 0.9972295165061951}]}, {"text": " Table 3: Typed dependency F1 performance when com- posed with statistical parser. P CF is parser output eval- uated by context-free (shallow) dependencies; all oth- ers are evaluated on deep dependencies. P is parser, G  is string-to-context-free-gold-tree mapping, A is present  remapping algorithm, J is Johnson 2002, D is the COM- BINED model of Dienes 2003.", "labels": [], "entities": [{"text": "BINED", "start_pos": 335, "end_pos": 340, "type": "METRIC", "confidence": 0.6138899326324463}]}, {"text": " Table 4: Cross-linguistic comparison of dislocated node identification and remapping. ID is correct identification  of nodes as +/-dislocated; Rel is relocation of node to correct mother given gold-standard data on which nodes are  dislocated (only applicable for gold trees); Combo is both correct identification and remapping.", "labels": [], "entities": [{"text": "dislocated node identification", "start_pos": 41, "end_pos": 71, "type": "TASK", "confidence": 0.720738152662913}, {"text": "Rel", "start_pos": 144, "end_pos": 147, "type": "METRIC", "confidence": 0.98163902759552}]}, {"text": " Table 5: Typed dependency F1 performance when com- posed with statistical parser. Remapped dependencies  involve only non-relativization dislocations and exclude  control loci.", "labels": [], "entities": [{"text": "F1", "start_pos": 27, "end_pos": 29, "type": "METRIC", "confidence": 0.680427610874176}]}]}