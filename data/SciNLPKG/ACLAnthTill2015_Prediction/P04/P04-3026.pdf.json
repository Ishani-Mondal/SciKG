{"title": [{"text": "A Practical Solution to the Problem of Automatic Word Sense Induction", "labels": [], "entities": [{"text": "Automatic Word Sense Induction", "start_pos": 39, "end_pos": 69, "type": "TASK", "confidence": 0.6749951764941216}]}], "abstractContent": [{"text": "Recent studies in word sense induction are based on clustering global co-occurrence vectors , i.e. vectors that reflect the overall behavior of a word in a corpus.", "labels": [], "entities": [{"text": "word sense induction", "start_pos": 18, "end_pos": 38, "type": "TASK", "confidence": 0.8258747458457947}]}, {"text": "If a word is semantically ambiguous, this means that these vectors are mixtures of all its senses.", "labels": [], "entities": []}, {"text": "Inducing a word's senses therefore involves the difficult problem of recovering the sense vectors from the mixtures.", "labels": [], "entities": []}, {"text": "In this paper we argue that the demixing problem can be avoided since the contextual behavior of the senses is directly observable in the form of the local contexts of a word.", "labels": [], "entities": []}, {"text": "From human disambiguation performance we know that the context of a word is usually sufficient to determine its sense.", "labels": [], "entities": []}, {"text": "Based on this observation we describe an algorithm that discovers the different senses of an ambiguous word by clustering its contexts.", "labels": [], "entities": []}, {"text": "The main difficulty with this approach, namely the problem of data sparseness, could be minimized by looking at only the three main dimensions of the context matrices.", "labels": [], "entities": []}], "introductionContent": [{"text": "The topic of this paper is word sense induction, that is the automatic discovery of the possible senses of a word.", "labels": [], "entities": [{"text": "word sense induction", "start_pos": 27, "end_pos": 47, "type": "TASK", "confidence": 0.7910867730776469}]}, {"text": "A related problem is word sense disambiguation: Here the senses are assumed to be known and the task is to choose the correct one when given an ambiguous word in context.", "labels": [], "entities": [{"text": "word sense disambiguation", "start_pos": 21, "end_pos": 46, "type": "TASK", "confidence": 0.7899365822474161}]}, {"text": "Whereas until recently the focus of research had been on sense disambiguation, papers like,, and give evidence that sense induction now also attracts attention.", "labels": [], "entities": [{"text": "sense disambiguation", "start_pos": 57, "end_pos": 77, "type": "TASK", "confidence": 0.7625809907913208}, {"text": "sense induction", "start_pos": 116, "end_pos": 131, "type": "TASK", "confidence": 0.7935459911823273}]}, {"text": "In the approach by, all words occurring in a parsed corpus are clustered on the basis of the distances of their co-occurrence vectors.", "labels": [], "entities": []}, {"text": "This is called global clustering.", "labels": [], "entities": [{"text": "global clustering", "start_pos": 15, "end_pos": 32, "type": "TASK", "confidence": 0.7158192098140717}]}, {"text": "Since (by looking at differential vectors) their algorithm allows a word to belong to more than one cluster, each cluster a word is assigned to can be considered as one of its senses.", "labels": [], "entities": []}, {"text": "A problem that we see with this approach is that it allows only as many senses as clusters, thereby limiting the granularity of the meaning space.", "labels": [], "entities": []}, {"text": "This problem is avoided by who uses local instead of global clustering.", "labels": [], "entities": []}, {"text": "This means, to find the senses of a given word only its close associations are clustered, that is for each word new clusters will be found.", "labels": [], "entities": []}, {"text": "Despite many differences, to our knowledge almost all approaches to sense induction that have been published so far have a common limitation: They rely on global co-occurrence vectors, i.e. on vectors that have been derived from an entire corpus.", "labels": [], "entities": [{"text": "sense induction", "start_pos": 68, "end_pos": 83, "type": "TASK", "confidence": 0.806703120470047}]}, {"text": "Since most words are semantically ambiguous, this means that these vectors reflect the sum of the contextual behavior of a word's underlying senses, i.e. they are mixtures of all senses occurring in the corpus.", "labels": [], "entities": []}, {"text": "However, since reconstructing the sense vectors from the mixtures is difficult, the question is if we really need to base our work on mixtures or if there is someway to directly observe the contextual behavior of the senses thereby avoiding the mixing beforehand.", "labels": [], "entities": []}, {"text": "In this paper we suggest to look at local instead of global co-occurrence vectors.", "labels": [], "entities": []}, {"text": "As can be seen from human performance, in almost all cases the local context of an ambiguous word is sufficient to disambiguate its sense.", "labels": [], "entities": []}, {"text": "This means that the local context of a word usually carries no ambiguities.", "labels": [], "entities": []}, {"text": "The aim of this paper is to show how this observation whose application tends to severely suffer from the sparse-data problem can be successfully exploited for word sense induction.", "labels": [], "entities": [{"text": "word sense induction", "start_pos": 160, "end_pos": 180, "type": "TASK", "confidence": 0.8435624241828918}]}], "datasetContent": [], "tableCaptions": []}