{"title": [{"text": "Combining Lexical, Syntactic, and Semantic Features with Maximum Entropy Models for Extracting Relations", "labels": [], "entities": []}], "abstractContent": [{"text": "Extracting semantic relationships between entities is challenging because of a paucity of annotated data and the errors induced by entity detection modules.", "labels": [], "entities": [{"text": "Extracting semantic relationships between entities", "start_pos": 0, "end_pos": 50, "type": "TASK", "confidence": 0.9066095590591431}]}, {"text": "We employ Maximum Entropy models to combine diverse lexical, syntactic and semantic features derived from the text.", "labels": [], "entities": []}, {"text": "Our system obtained competitive results in the Automatic Content Extraction (ACE) evaluation.", "labels": [], "entities": [{"text": "Automatic Content Extraction (ACE)", "start_pos": 47, "end_pos": 81, "type": "TASK", "confidence": 0.7100965529680252}]}, {"text": "Here we present our general approach and describe our ACE results.", "labels": [], "entities": []}], "introductionContent": [{"text": "Extraction of semantic relationships between entities can be very useful for applications such as biography extraction and question answering, e.g. to answer queries such as \"Where is the Taj Mahal?\".", "labels": [], "entities": [{"text": "Extraction of semantic relationships between entities", "start_pos": 0, "end_pos": 53, "type": "TASK", "confidence": 0.8472950756549835}, {"text": "biography extraction", "start_pos": 98, "end_pos": 118, "type": "TASK", "confidence": 0.8304058313369751}, {"text": "question answering", "start_pos": 123, "end_pos": 141, "type": "TASK", "confidence": 0.8931201100349426}]}, {"text": "Several prior approaches to relation extraction have focused on using syntactic parse trees.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 28, "end_pos": 47, "type": "TASK", "confidence": 0.9742961823940277}]}, {"text": "For the Template Relations task of MUC-7, BBN researchers () augmented syntactic parse trees with semantic information corresponding to entities and relations and built generative models for the augmented trees.", "labels": [], "entities": [{"text": "Template Relations task", "start_pos": 8, "end_pos": 31, "type": "TASK", "confidence": 0.9450823664665222}]}, {"text": "More recently, () have proposed extracting relations by computing kernel functions between parse trees and () have extended this work to estimate kernel functions between augmented dependency trees.", "labels": [], "entities": []}, {"text": "We build Maximum Entropy models for extracting relations that combine diverse lexical, syntactic and semantic features.", "labels": [], "entities": []}, {"text": "Our results indicate that using a variety of information sources can result in improved recall and overall F measure.", "labels": [], "entities": [{"text": "recall", "start_pos": 88, "end_pos": 94, "type": "METRIC", "confidence": 0.999647855758667}, {"text": "F measure", "start_pos": 107, "end_pos": 116, "type": "METRIC", "confidence": 0.9585525393486023}]}, {"text": "Our approach can easily scale to include more features from a multitude of sources-e.g. WordNet, gazatteers, output of other semantic taggers etc.-that can be brought to bear on this task.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 88, "end_pos": 95, "type": "DATASET", "confidence": 0.9401697516441345}]}, {"text": "In this paper, we present our general approach, describe the features we currently use and show the results of our participation in the ACE evaluation.", "labels": [], "entities": []}, {"text": "Automatic Content Extraction) is an evaluation conducted by NIST to measure Entity Detection and Tracking (EDT) and relation detection and characterization (RDC).", "labels": [], "entities": [{"text": "Automatic Content Extraction)", "start_pos": 0, "end_pos": 29, "type": "TASK", "confidence": 0.6569031774997711}, {"text": "NIST", "start_pos": 60, "end_pos": 64, "type": "DATASET", "confidence": 0.8846935629844666}, {"text": "Entity Detection and Tracking (EDT)", "start_pos": 76, "end_pos": 111, "type": "TASK", "confidence": 0.7749919635908944}, {"text": "relation detection and characterization (RDC)", "start_pos": 116, "end_pos": 161, "type": "TASK", "confidence": 0.8618411336626325}]}, {"text": "The EDT task entails the detection of mentions of entities and chaining them together by identifying their coreference.", "labels": [], "entities": []}, {"text": "In ACE vocabulary, entities are objects, mentions are references to them, and relations are explicitly or implicitly stated relationships among entities.", "labels": [], "entities": []}, {"text": "Entities can be of five types: persons, organizations, locations, facilities, and geo-political entities (geographically defined regions that define apolitical boundary, e.g. countries, cities, etc.).", "labels": [], "entities": []}, {"text": "Mentions have levels: they can be names, nominal expressions or pronouns.", "labels": [], "entities": []}, {"text": "The RDC task detects implicit and explicit relations 1 between entities identified by the EDT task.", "labels": [], "entities": []}, {"text": "Here is an example: The American Medical Association voted yesterday to install the heir apparent as its president-elect, rejecting a strong, upstart challenge by a District doctor who argued that the nation's largest physicians' group needs stronger ethics and new leadership.", "labels": [], "entities": [{"text": "American Medical Association", "start_pos": 24, "end_pos": 52, "type": "DATASET", "confidence": 0.8569180766741434}]}, {"text": "In electing Thomas R. Reardon, an Oregon general practitioner who had been the chairman of its board, ...", "labels": [], "entities": []}, {"text": "In this fragment, all the underlined phrases are mentions referring to the American Medical Association, or to Thomas R. Reardon or the board (an organization) of the American Medical Association.", "labels": [], "entities": [{"text": "American Medical Association", "start_pos": 75, "end_pos": 103, "type": "DATASET", "confidence": 0.9696728587150574}, {"text": "American Medical Association", "start_pos": 167, "end_pos": 195, "type": "DATASET", "confidence": 0.8990749915440878}]}, {"text": "Moreover, there is an explicit management relation between chairman and board, which are references to Thomas R. Reardon and the board of the American Medical Association respectively.", "labels": [], "entities": [{"text": "American Medical Association", "start_pos": 142, "end_pos": 170, "type": "DATASET", "confidence": 0.9578697880109152}]}, {"text": "Relation extraction is hard, since successful extraction implies correctly detecting both the argument mentions, correctly chaining these mentions to their re- spective entities, and correctly determining the type of relation that holds between them.", "labels": [], "entities": [{"text": "Relation extraction", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.8530722558498383}]}, {"text": "This paper focuses on the relation extraction component of our ACE system.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 26, "end_pos": 45, "type": "TASK", "confidence": 0.8563289940357208}]}, {"text": "The reader is referred to) for more details of our mention detection and mention chaining modules.", "labels": [], "entities": [{"text": "mention detection", "start_pos": 51, "end_pos": 68, "type": "TASK", "confidence": 0.7351575642824173}, {"text": "mention chaining", "start_pos": 73, "end_pos": 89, "type": "TASK", "confidence": 0.6665705740451813}]}, {"text": "In the next section, we describe our extraction system.", "labels": [], "entities": []}, {"text": "We present results in section 3, and we conclude after making some general observations in section 4.", "labels": [], "entities": []}], "datasetContent": [{"text": "We divided the ACE training data provided by LDC into separate training and development sets.", "labels": [], "entities": [{"text": "ACE training data", "start_pos": 15, "end_pos": 32, "type": "DATASET", "confidence": 0.7043007214864095}, {"text": "LDC", "start_pos": 45, "end_pos": 48, "type": "DATASET", "confidence": 0.516516923904419}]}, {"text": "The training set contained around 300K words, and 9752 instances of relations and the development set contained around 46K words, and 1679 instances of relations.: The Precision, Recall, F-measure and the ACE Value on the development set with true mentions and entities.", "labels": [], "entities": [{"text": "Precision", "start_pos": 168, "end_pos": 177, "type": "METRIC", "confidence": 0.9869691133499146}, {"text": "Recall", "start_pos": 179, "end_pos": 185, "type": "METRIC", "confidence": 0.9654840230941772}, {"text": "F-measure", "start_pos": 187, "end_pos": 196, "type": "METRIC", "confidence": 0.9861990213394165}, {"text": "ACE Value", "start_pos": 205, "end_pos": 214, "type": "METRIC", "confidence": 0.8377093076705933}]}], "tableCaptions": [{"text": " Table 2: The Precision, Recall, F-measure and the  ACE Value on the development set with true men- tions and entities.", "labels": [], "entities": [{"text": "Precision", "start_pos": 14, "end_pos": 23, "type": "METRIC", "confidence": 0.9977161884307861}, {"text": "Recall", "start_pos": 25, "end_pos": 31, "type": "METRIC", "confidence": 0.9945354461669922}, {"text": "F-measure", "start_pos": 33, "end_pos": 42, "type": "METRIC", "confidence": 0.9969416260719299}, {"text": "ACE Value", "start_pos": 52, "end_pos": 61, "type": "METRIC", "confidence": 0.956131637096405}]}, {"text": " Table 3: The Precision, Recall, F-measure, and  ACE Value on the development set with system out- put mentions and entities.", "labels": [], "entities": [{"text": "Precision", "start_pos": 14, "end_pos": 23, "type": "METRIC", "confidence": 0.9983578324317932}, {"text": "Recall", "start_pos": 25, "end_pos": 31, "type": "METRIC", "confidence": 0.9824008345603943}, {"text": "F-measure", "start_pos": 33, "end_pos": 42, "type": "METRIC", "confidence": 0.9921848177909851}, {"text": "ACE Value", "start_pos": 49, "end_pos": 58, "type": "METRIC", "confidence": 0.9752843379974365}]}, {"text": " Table 4: The F-measure and ACE Value for the test  sets with true (T) and system output (S) mentions  and entities.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 14, "end_pos": 23, "type": "METRIC", "confidence": 0.991596519947052}, {"text": "ACE Value", "start_pos": 28, "end_pos": 37, "type": "METRIC", "confidence": 0.9771736860275269}]}]}