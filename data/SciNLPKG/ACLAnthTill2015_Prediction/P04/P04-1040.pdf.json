{"title": [{"text": "Enriching the Output of a Parser Using Memory-Based Learning", "labels": [], "entities": []}], "abstractContent": [{"text": "We describe a method for enriching the output of a parser with information available in a corpus.", "labels": [], "entities": []}, {"text": "The method is based on graph rewriting using memory-based learning, applied to dependency structures.", "labels": [], "entities": []}, {"text": "This general framework allows us to accurately recover both grammatical and semantic information as well as non-local dependencies.", "labels": [], "entities": []}, {"text": "It also facilitates dependency-based evaluation of phrase structure parsers.", "labels": [], "entities": [{"text": "dependency-based evaluation of phrase structure parsers", "start_pos": 20, "end_pos": 75, "type": "TASK", "confidence": 0.633952741821607}]}, {"text": "Our method is largely independent of the choice of parser and corpus, and shows state of the art performance.", "labels": [], "entities": []}], "introductionContent": [{"text": "We describe a method to automatically enrich the output of parsers with information that is present in existing treebanks but usually not produced by the parsers themselves.", "labels": [], "entities": []}, {"text": "First and most important, for applications requiring information extraction or semantic interpretation of text, it is desirable to have parsers produce grammatically and semantically rich output.", "labels": [], "entities": [{"text": "information extraction", "start_pos": 53, "end_pos": 75, "type": "TASK", "confidence": 0.7535925507545471}]}, {"text": "Second, to facilitate dependency-based comparison and evaluation of different parsers, their outputs may need to be transformed into specific rich dependency formalisms.", "labels": [], "entities": []}, {"text": "The method allows us to automatically transform the output of a parser into structures as they are annotated in a dependency treebank.", "labels": [], "entities": []}, {"text": "For a phrase structure parser, we first convert the produced phrase structures into dependency graphs in a straightforward way, and then apply a sequence of graph transformations: changing dependency labels, adding new nodes, and adding new dependencies.", "labels": [], "entities": [{"text": "phrase structure parser", "start_pos": 6, "end_pos": 29, "type": "TASK", "confidence": 0.7146251797676086}]}, {"text": "A memory-based learner trained on a dependency corpus is used to detect which modifications should be performed.", "labels": [], "entities": []}, {"text": "For a dependency corpus derived from the Penn Treebank and the parsers we considered, these transformations correspond to adding Penn functional tags (e.g., -SBJ, -TMP, -LOC), empty nodes (e.g., NP PRO) and non-local dependencies (controlled traces, WHextraction, etc.).", "labels": [], "entities": [{"text": "Penn Treebank", "start_pos": 41, "end_pos": 54, "type": "DATASET", "confidence": 0.9916045367717743}]}, {"text": "For these specific sub-tasks our method achieves state of the art performance.", "labels": [], "entities": []}, {"text": "The evaluation of the transformed output of the parsers of and gives 90% unlabelled and 84% labelled accuracy with respect to dependencies, when measured against a dependency corpus derived from the Penn Treebank.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 101, "end_pos": 109, "type": "METRIC", "confidence": 0.9456893801689148}, {"text": "Penn Treebank", "start_pos": 199, "end_pos": 212, "type": "DATASET", "confidence": 0.9942048788070679}]}, {"text": "The paper is organized as follows.", "labels": [], "entities": []}, {"text": "After providing some background and motivation in Section 2, we give the general overview of our method in Section 3.", "labels": [], "entities": []}, {"text": "In Sections 4 through 8, we describe all stages of the transformation process, providing evaluation results and comparing our methods to earlier work.", "labels": [], "entities": []}, {"text": "We discuss the results in Section 9.", "labels": [], "entities": []}], "datasetContent": [{"text": "After the original WSJ structures and the parsers' outputs have been converted to dependency structures, we evaluate the performance of the parsers against the dependency corpus.", "labels": [], "entities": []}, {"text": "We use the standard precision/recall measures over sets of dependencies Notice that since neither Collins' nor Charniak's parser outputs WSJ functional labels, all dependencies with functional labels in the gold parse will be judged incorrect in the third setting.", "labels": [], "entities": [{"text": "precision", "start_pos": 20, "end_pos": 29, "type": "METRIC", "confidence": 0.9984922409057617}, {"text": "recall", "start_pos": 30, "end_pos": 36, "type": "METRIC", "confidence": 0.9492891430854797}]}, {"text": "The evaluation results are shown in, in the row \"step 0\".", "labels": [], "entities": []}, {"text": "As explained above, the low numbers for the dependency evaluation with functional tags are expected, because the two parsers were not intended to produce functional labels.", "labels": [], "entities": []}, {"text": "Interestingly, the ranking of the two parsers is different for the dependency-based evaluation than for PARSEVAL: To summarize the evaluation scores at this stage, both parsers perform with f-score around 87% on unlabelled dependencies.", "labels": [], "entities": []}, {"text": "When evaluating on bare dependency labels (i.e., disregarding functional tags) the performance drops to 83%.", "labels": [], "entities": []}, {"text": "The new errors that appear when taking labels into account come from different sources: incorrect POS tags (NN vs. VBG), different degrees of flatness of analyses in gold and test parses (JJ vs. ADJP, or CD vs. QP) and inconsistencies in the Penn annotation (VP vs. RRC).", "labels": [], "entities": [{"text": "Penn annotation (VP vs. RRC", "start_pos": 242, "end_pos": 269, "type": "DATASET", "confidence": 0.8290298183759054}]}, {"text": "Finally, the performance goes down to around 66% when taking into account functional tags, which are not produced by the parsers at all.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Dependency-based evaluation of the parsers after different transformation steps", "labels": [], "entities": []}]}