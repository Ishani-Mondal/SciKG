{"title": [{"text": "FSA: An Efficient and Flexible C++ Toolkit for Finite State Automata Using On-Demand Computation", "labels": [], "entities": [{"text": "FSA", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.6857255697250366}]}], "abstractContent": [{"text": "In this paper we present the RWTH FSA toolkit-an efficient implementation of algorithms for creating and manipulating weighted finite-state automata.", "labels": [], "entities": [{"text": "RWTH FSA toolkit-an", "start_pos": 29, "end_pos": 48, "type": "DATASET", "confidence": 0.6088392933209738}]}, {"text": "The toolkit has been designed using the principle of on-demand computation and offers a large range of widely used algorithms.", "labels": [], "entities": []}, {"text": "To prove the superior efficiency of the toolkit, we compare the implementation to that of other publically available toolkits.", "labels": [], "entities": []}, {"text": "We also show that on-demand computations help to reduce memory requirements significantly without any loss in speed.", "labels": [], "entities": []}, {"text": "To increase its flexibility, the RWTH FSA toolkit supports high-level interfaces to the programming language Python as well as a command-line tool for interactive manipulation of FSAs.", "labels": [], "entities": [{"text": "RWTH FSA toolkit", "start_pos": 33, "end_pos": 49, "type": "DATASET", "confidence": 0.7950484951337179}]}, {"text": "Furthermore, we show how to utilize the toolkit to rapidly build a fast and accurate statistical machine translation system.", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 85, "end_pos": 116, "type": "TASK", "confidence": 0.6202553510665894}]}, {"text": "Future extensibility of the toolkit is ensured as it will be publically available as open source software.", "labels": [], "entities": []}], "introductionContent": [{"text": "Finite-state automata (FSA) methods proved to elegantly solve many difficult problems in the field of natural language processing.", "labels": [], "entities": [{"text": "natural language processing", "start_pos": 102, "end_pos": 129, "type": "TASK", "confidence": 0.6337897876898447}]}, {"text": "Among the most recent ones are full and lazy compilation of the search network for speech recognition), integrated speech translation), speech summarization (, language modelling (  and parameter estimation through EM) to mention only a few.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 83, "end_pos": 101, "type": "TASK", "confidence": 0.7495802640914917}, {"text": "speech translation", "start_pos": 115, "end_pos": 133, "type": "TASK", "confidence": 0.7160569876432419}, {"text": "speech summarization", "start_pos": 136, "end_pos": 156, "type": "TASK", "confidence": 0.7911155521869659}, {"text": "language modelling", "start_pos": 160, "end_pos": 178, "type": "TASK", "confidence": 0.7592761218547821}]}, {"text": "From this list of different applications it is clear that there is a high demand for generic tools to create and manipulate FSAs.", "labels": [], "entities": []}, {"text": "In the past, a number of toolkits have been published, all with different design principles.", "labels": [], "entities": []}, {"text": "Here, we give a short overview of toolkits that offer an almost complete set of algorithms: \u2022 The FSM Library TM from AT&T () is judged the most efficient implementation, offers various semirings, ondemand computation and many algorithms, but is available only in binary form with a proprietary, noncommercial license.", "labels": [], "entities": [{"text": "FSM Library TM from AT&T", "start_pos": 98, "end_pos": 122, "type": "DATASET", "confidence": 0.9273808939116341}]}, {"text": "\u2022 FSA6.1 from) is implemented in Prolog.", "labels": [], "entities": [{"text": "FSA6.1", "start_pos": 2, "end_pos": 8, "type": "DATASET", "confidence": 0.5353926420211792}, {"text": "Prolog", "start_pos": 33, "end_pos": 39, "type": "DATASET", "confidence": 0.9748185276985168}]}, {"text": "It is licensed under the terms of the.", "labels": [], "entities": []}, {"text": "\u2022 The WFST toolkit from) is built on top of the Automaton Standard Template Library ( and uses C++ template mechanisms for efficiency and flexibility, but lacks on-demand computation.", "labels": [], "entities": []}, {"text": "Also licensed under the terms of the.", "labels": [], "entities": []}, {"text": "This paper describes a highly efficient new implementation of a finite-state automata toolkit that uses on-demand computation.", "labels": [], "entities": []}, {"text": "Currently, it is being used at the Lehrstuhl f\u00fcr Informatik VI, RWTH Aachen in different speech recognition and translation research applications.", "labels": [], "entities": [{"text": "RWTH Aachen", "start_pos": 64, "end_pos": 75, "type": "DATASET", "confidence": 0.8222113251686096}, {"text": "speech recognition and translation research", "start_pos": 89, "end_pos": 132, "type": "TASK", "confidence": 0.7443246960639953}]}, {"text": "The toolkit will be available under an open source license and can be obtained from our website http://www-i6.informatik.rwth-aachen.de.", "labels": [], "entities": []}, {"text": "The remaining part of the paper is organized as follows: Section 2 will give a short introduction to the theory of finite-state automata to recall part of the terminology and notation.", "labels": [], "entities": []}, {"text": "We will also give a short explanation of composition which we use as an exemplary object of study in the following sections.", "labels": [], "entities": []}, {"text": "In Section 2.3 we will discuss the locality of algorithms defined on finite-state automata.", "labels": [], "entities": []}, {"text": "This forms the basis for implementations using on-demand computations.", "labels": [], "entities": []}, {"text": "Then the RWTH FSA toolkit implementation is detailed in Section 3.", "labels": [], "entities": [{"text": "RWTH FSA toolkit", "start_pos": 9, "end_pos": 25, "type": "DATASET", "confidence": 0.730664849281311}]}, {"text": "In Section 4.1 we will compare the efficiency of different toolkits.", "labels": [], "entities": []}, {"text": "As a showcase for the flexibility we show how to use the toolkit to build a statistical machine translation system in Section 4.2.", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 76, "end_pos": 107, "type": "TASK", "confidence": 0.6408554414908091}]}, {"text": "We conclude the paper with a short summary in Section 5 and discuss some possible future extensions in Section 6.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Tasks used for measuring the efficiency of  the toolkits. Sizes are given for the resulting trans- ducers (VM = Verbmobil).", "labels": [], "entities": [{"text": "VM = Verbmobil", "start_pos": 117, "end_pos": 131, "type": "METRIC", "confidence": 0.6928968032201132}]}, {"text": " Table 2: Comparison of peak memory usage in MB  (  *  aborted due to exceeded memory limits).  Exp. FSA FSM AT&T  WFST  1  360 1700  1500 > 1850  *   2  59  310  69 > 1850  *   3  48  230  176  550", "labels": [], "entities": [{"text": "FSA FSM AT&T  WFST  1  360 1700  1500", "start_pos": 101, "end_pos": 138, "type": "DATASET", "confidence": 0.8701562494039535}]}, {"text": " Table 3: Comparison of CPU time in seconds in- cluding I/O using a 1.2GHz AMD Athlon proces- sor (  *  exceeded memory limits: given time indicates  point of abortion).  Exp. FSA FSM AT&T WFST  1  105  203  515 > 40  *   2  6.5  182 11760 > 64  *   3  6.6  21  28  3840", "labels": [], "entities": [{"text": "FSA FSM AT&T WFST  1  105  203  515", "start_pos": 176, "end_pos": 211, "type": "DATASET", "confidence": 0.8993935942649841}]}, {"text": " Table 4: Translation results for different tasks compared to similar systems using the alignment template  (AT) approach (Tests were performed on a 1.2GHz AMD Athlon).  Task  System  Translation  WER PER 100-BLEU Memory Time/Sentence  [%]  [%]  [MB]  [ms]  Eutrans  FSA  Spanish \u2192 English 8.12 7.64  10.7  6-8  20  AT  8.25  - - - - FUB  FSA  Italian \u2192 English  27.0 21.5  37.7  3-5  22  AT  23.7 18.1  36.0  - - Verbmobil  FSA  German \u2192 English 48.3 41.6  69.8  65-90  460  AT  40.5 30.1  62.2  - - PF-Star  FSA  Italian \u2192 English  39.8 34.1  58.4  12-15  35  AT  36.8 29.1  54.3  - -", "labels": [], "entities": [{"text": "Translation", "start_pos": 10, "end_pos": 21, "type": "TASK", "confidence": 0.9626420140266418}, {"text": "WER PER 100-BLEU Memory Time/Sentence", "start_pos": 197, "end_pos": 234, "type": "METRIC", "confidence": 0.8635203157152448}, {"text": "FUB  FSA  Italian", "start_pos": 334, "end_pos": 351, "type": "DATASET", "confidence": 0.8548726042111715}]}]}