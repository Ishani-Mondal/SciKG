{"title": [{"text": "A Kernel PCA Method for Superior Word Sense Disambiguation", "labels": [], "entities": [{"text": "Superior Word Sense Disambiguation", "start_pos": 24, "end_pos": 58, "type": "TASK", "confidence": 0.7064791470766068}]}], "abstractContent": [{"text": "We introduce anew method for disambiguating word senses that exploits a nonlinear Kernel Principal Component Analysis (KPCA) technique to achieve accuracy superior to the best published individual models.", "labels": [], "entities": [{"text": "Kernel Principal Component Analysis (KPCA)", "start_pos": 82, "end_pos": 124, "type": "TASK", "confidence": 0.6708278145108905}, {"text": "accuracy", "start_pos": 146, "end_pos": 154, "type": "METRIC", "confidence": 0.9990546107292175}]}, {"text": "We present empirical results demonstrating significantly better accuracy compared to the state-of-the-art achieved by either na\u00a8\u0131vena\u00a8\u0131ve Bayes or maximum entropy models, on Senseval-2 data.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 64, "end_pos": 72, "type": "METRIC", "confidence": 0.9991563558578491}, {"text": "Senseval-2 data", "start_pos": 174, "end_pos": 189, "type": "DATASET", "confidence": 0.944701224565506}]}, {"text": "We also contrast against another type of kernel method, the support vector machine (SVM) model, and show that our KPCA-based model outperforms the SVM-based model.", "labels": [], "entities": []}, {"text": "It is hoped that these highly encouraging first results on KPCA for natural language processing tasks will inspire further development of these directions.", "labels": [], "entities": []}], "introductionContent": [{"text": "Achieving higher precision in supervised word sense disambiguation (WSD) tasks without resorting toad hoc voting or similar ensemble techniques has become somewhat daunting in recent years, given the challenging benchmarks set by na\u00a8\u0131vena\u00a8\u0131ve Bayes models (e.g.,,,,) as well as maximum entropy models (e.g.,,).", "labels": [], "entities": [{"text": "precision", "start_pos": 17, "end_pos": 26, "type": "METRIC", "confidence": 0.9945384860038757}, {"text": "word sense disambiguation (WSD) tasks", "start_pos": 41, "end_pos": 78, "type": "TASK", "confidence": 0.7866345260824475}]}, {"text": "A good foundation for comparative studies has been established by the Senseval data and evaluations; of particular relevance here are the lexical sample tasks from Senseval-1 () and Senseval-2.", "labels": [], "entities": [{"text": "Senseval data", "start_pos": 70, "end_pos": 83, "type": "DATASET", "confidence": 0.8417117297649384}]}, {"text": "We therefore chose this problem to introduce an efficient and accurate new word sense disambiguation approach that exploits a nonlinear Kernel PCA technique to make predictions implicitly based on generalizations over feature combinations.", "labels": [], "entities": [{"text": "word sense disambiguation", "start_pos": 75, "end_pos": 100, "type": "TASK", "confidence": 0.689371774593989}]}, {"text": "The The author would like to thank the Hong Kong Research Grants Council (RGC) for supporting this research in part through grants RGC6083/99E, RGC6256/00E, and DAG03/04.", "labels": [], "entities": [{"text": "Hong Kong Research Grants Council (RGC)", "start_pos": 39, "end_pos": 78, "type": "DATASET", "confidence": 0.927685908973217}, {"text": "DAG03", "start_pos": 161, "end_pos": 166, "type": "METRIC", "confidence": 0.8680068850517273}]}, {"text": "technique is applicable whenever vector representations of a disambiguation task can be generated; thus many properties of our technique can be expected to be highly attractive from the standpoint of natural language processing in general.", "labels": [], "entities": []}, {"text": "In the following sections, we first analyze the potential of nonlinear principal components with respect to the task of disambiguating word senses.", "labels": [], "entities": []}, {"text": "Based on this, we describe a full model for WSD built on KPCA.", "labels": [], "entities": [{"text": "WSD", "start_pos": 44, "end_pos": 47, "type": "TASK", "confidence": 0.9247452020645142}, {"text": "KPCA", "start_pos": 57, "end_pos": 61, "type": "DATASET", "confidence": 0.9403660893440247}]}, {"text": "We then discuss experimental results confirming that this model outperforms stateof-the-art published models for Senseval-related lexical sample tasks as represented by na\u00a8\u0131vena\u00a8\u0131ve Bayes models, as well as (2) maximum entropy models.", "labels": [], "entities": []}, {"text": "We then consider whether other kernel methods-in particular, the popular SVM modelare equally competitive, and discover experimentally that KPCA achieves higher accuracy than the SVM model.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 161, "end_pos": 169, "type": "METRIC", "confidence": 0.9983892440795898}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 3: The original observed training vectors (showing only the first three dimensions) and their first three  principal components as transformed via PCA and KPCA.", "labels": [], "entities": []}, {"text": " Table 4: Testing vector (showing only the first three dimensions) and its first three principal components  as transformed via the trained PCA and KPCA parameters. The PCA-based and KPCA-based sense class  predictions disagree.", "labels": [], "entities": []}, {"text": " Table 7: Comparison of training and testing times for the different WSD model implementations.", "labels": [], "entities": []}]}