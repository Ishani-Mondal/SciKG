{"title": [{"text": "Robust VPE detection using Automatically Parsed Text", "labels": [], "entities": [{"text": "Robust VPE detection", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.823773721853892}]}], "abstractContent": [{"text": "This paper describes a Verb Phrase El-lipsis (VPE) detection system, built for robustness, accuracy and domain independence.", "labels": [], "entities": [{"text": "Verb Phrase El-lipsis (VPE) detection", "start_pos": 23, "end_pos": 60, "type": "TASK", "confidence": 0.495805025100708}, {"text": "accuracy", "start_pos": 91, "end_pos": 99, "type": "METRIC", "confidence": 0.9983046054840088}]}, {"text": "The system is corpus-based, and uses machine learning techniques on free text that has been automatically parsed.", "labels": [], "entities": []}, {"text": "Tested on a mixed corpus comprising a range of genres, the system achieves a 70% F1-score.", "labels": [], "entities": [{"text": "F1-score", "start_pos": 81, "end_pos": 89, "type": "METRIC", "confidence": 0.9992577433586121}]}, {"text": "This system is designed as the first stage of a complete VPE resolution system that is input free text, detects VPEs, and proceeds to find the antecedents and resolve them.", "labels": [], "entities": [{"text": "VPE resolution", "start_pos": 57, "end_pos": 71, "type": "TASK", "confidence": 0.9371268153190613}]}], "introductionContent": [{"text": "Ellipsis is a linguistic phenomenon that has received considerable attention, mostly focusing on its interpretation.", "labels": [], "entities": []}, {"text": "Most work on ellipsis () is aimed at discerning the procedures and the level of language processing at which ellipsis resolution takes place, or ambiguous and difficult cases.", "labels": [], "entities": [{"text": "ellipsis resolution", "start_pos": 109, "end_pos": 128, "type": "TASK", "confidence": 0.7825880646705627}]}, {"text": "The detection of elliptical sentences or the identification of the antecedent and elided clauses within them are usually not dealt with, but taken as given.", "labels": [], "entities": [{"text": "detection of elliptical sentences", "start_pos": 4, "end_pos": 37, "type": "TASK", "confidence": 0.8107592165470123}]}, {"text": "Noisy or missing input, which is unavoidable in NLP applications, is not dealt with, and neither is focusing on specific domains or applications.", "labels": [], "entities": []}, {"text": "It therefore becomes clear that a robust, trainable approach is needed.", "labels": [], "entities": []}, {"text": "An example of Verb Phrase Ellipsis (VPE), which is detected by the presence of an auxiliary verb without a verb phrase, is seen in example 1.", "labels": [], "entities": [{"text": "Verb Phrase Ellipsis (VPE)", "start_pos": 14, "end_pos": 40, "type": "TASK", "confidence": 0.8022578209638596}]}, {"text": "VPE can also occur with semi-auxiliaries, as in example 2.", "labels": [], "entities": [{"text": "VPE", "start_pos": 0, "end_pos": 3, "type": "TASK", "confidence": 0.810359001159668}]}, {"text": "(1) John 3 {loves his 3 wife} 2 . Bill 3 does 1 too.", "labels": [], "entities": []}, {"text": "(2) But although he was terse, he didn't {rage at me} 2 the way I expected him to 1 . Several steps of work need to be done for ellipsis resolution : 1.", "labels": [], "entities": [{"text": "ellipsis resolution", "start_pos": 128, "end_pos": 147, "type": "TASK", "confidence": 0.8210577666759491}]}, {"text": "First, elided verbs need to be found.", "labels": [], "entities": []}, {"text": "For most cases of ellipsis, copying of the antecedent clause is enough for resolution).", "labels": [], "entities": [{"text": "resolution", "start_pos": 75, "end_pos": 85, "type": "TASK", "confidence": 0.9676170349121094}]}, {"text": "For cases where ambiguity exists, a method for generating the full list of possible solutions, and suggesting the most likely one is needed.", "labels": [], "entities": []}, {"text": "This paper describes the work done on the first stage, the detection of elliptical verbs.", "labels": [], "entities": [{"text": "detection of elliptical verbs", "start_pos": 59, "end_pos": 88, "type": "TASK", "confidence": 0.7772351503372192}]}, {"text": "First, previous work done on tagged corpora will be summarised.", "labels": [], "entities": []}, {"text": "Then, new work on parsed corpora will be presented, showing the gains possible through sentence-level features.", "labels": [], "entities": []}, {"text": "Finally, experiments using unannotated data that is parsed using an automatic parser are presented, as our aim is to produce a stand-alone system.", "labels": [], "entities": []}, {"text": "We have chosen to concentrate on VP ellipsis due to the fact that it is far more common than other forms of ellipsis, but pseudo-gapping, an example of which is seen in example 3, has also been included due to the similarity of its resolution to VPE.", "labels": [], "entities": []}, {"text": "Do so/it/that and so doing anaphora are not handled, as their resolution is different from that of VPE ().", "labels": [], "entities": [{"text": "resolution", "start_pos": 62, "end_pos": 72, "type": "METRIC", "confidence": 0.9710127115249634}]}, {"text": "(3) John writes plays, and Bill does novels.", "labels": [], "entities": []}], "datasetContent": [{"text": "To experiment with what gains are possible through the use of more complex data such as parse trees, the Penn Treebank is used for the second round of experiments.", "labels": [], "entities": [{"text": "Penn Treebank", "start_pos": 105, "end_pos": 118, "type": "DATASET", "confidence": 0.9961948096752167}]}, {"text": "The results are presented as new features are added in a cumulative fashion, so each experiment also contains the data contained in those before it.", "labels": [], "entities": []}, {"text": "The next set of experiments use the BNC and Treebank, but strip POS and parse information, and parse them automatically using two different parsers.", "labels": [], "entities": [{"text": "BNC", "start_pos": 36, "end_pos": 39, "type": "DATASET", "confidence": 0.7078768014907837}, {"text": "parse information", "start_pos": 72, "end_pos": 89, "type": "TASK", "confidence": 0.8959102630615234}]}, {"text": "This enables us to test what kind of performance is possible for real-world applications.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Comparison of algorithms", "labels": [], "entities": []}, {"text": " Table 2: Initial results with the Treebank", "labels": [], "entities": [{"text": "Treebank", "start_pos": 35, "end_pos": 43, "type": "DATASET", "confidence": 0.926792562007904}]}, {"text": " Table 3: Effects of using the close-to-punctuation  feature", "labels": [], "entities": []}, {"text": " Table 4: Effects of using the heuristic feature", "labels": [], "entities": []}, {"text": " Table 5: Effects of using the surrounding cate- gories", "labels": [], "entities": []}, {"text": " Table 6: Effects of using the Auxiliary-final VP  feature", "labels": [], "entities": []}, {"text": " Table 7: Effects of using the improved Empty VP  feature", "labels": [], "entities": []}, {"text": " Table 8: Effects of using the empty categories", "labels": [], "entities": []}, {"text": " Table 10: Performance of features on re-parsed  Treebank data", "labels": [], "entities": [{"text": "Treebank data", "start_pos": 49, "end_pos": 62, "type": "DATASET", "confidence": 0.8341211080551147}]}, {"text": " Table 12: Performance of features on parsed BNC  data", "labels": [], "entities": [{"text": "BNC  data", "start_pos": 45, "end_pos": 54, "type": "DATASET", "confidence": 0.8289168179035187}]}, {"text": " Table 9: Results on re-parsed data from the Treebank", "labels": [], "entities": [{"text": "Treebank", "start_pos": 45, "end_pos": 53, "type": "DATASET", "confidence": 0.7743282318115234}]}, {"text": " Table 11: Results on parsed data from the BNC", "labels": [], "entities": [{"text": "BNC", "start_pos": 43, "end_pos": 46, "type": "DATASET", "confidence": 0.8535370230674744}]}, {"text": " Table 13: Results on parsed data using the combined dataset", "labels": [], "entities": []}]}