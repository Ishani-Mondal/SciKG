{"title": [{"text": "Annealing Techniques for Unsupervised Statistical Language Learning", "labels": [], "entities": [{"text": "Statistical Language Learning", "start_pos": 38, "end_pos": 67, "type": "TASK", "confidence": 0.8138211568196615}]}], "abstractContent": [{"text": "Exploiting unannotated natural language data is hard largely because unsupervised parameter estimation is hard.", "labels": [], "entities": []}, {"text": "We describe deterministic annealing (Rose et al., 1990) as an appealing alternative to the Expectation-Maximization algorithm (Dempster et al., 1977).", "labels": [], "entities": []}, {"text": "Seeking to avoid search error, DA begins by globally maximizing an easy concave function and maintains a local maximum as it gradually morphs the function into the desired non-concave likelihood function.", "labels": [], "entities": []}, {"text": "Applying DA to parsing and tagging models is shown to be straightforward ; significant improvements over EM are shown on a part-of-speech tagging task.", "labels": [], "entities": [{"text": "parsing and tagging", "start_pos": 15, "end_pos": 34, "type": "TASK", "confidence": 0.7207353115081787}, {"text": "part-of-speech tagging task", "start_pos": 123, "end_pos": 150, "type": "TASK", "confidence": 0.7473945816357931}]}, {"text": "We describe a variant , skewed DA, which can incorporate a good initializer when it is available, and show significant improvements over EM on a grammar induction task.", "labels": [], "entities": []}], "introductionContent": [{"text": "Unlabeled data remains a tantalizing potential resource for NLP researchers.", "labels": [], "entities": []}, {"text": "Some tasks can thrive on a nearly pure diet of unlabeled data.", "labels": [], "entities": []}, {"text": "But for other tasks, such as machine translation, the chief merit of unlabeled data is simply that nothing else is available; unsupervised parameter estimation is notorious for achieving mediocre results.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 29, "end_pos": 48, "type": "TASK", "confidence": 0.8253322839736938}]}, {"text": "The standard starting point is the ExpectationMaximization (EM) algorithm.", "labels": [], "entities": []}, {"text": "EM iteratively adjusts a model's parameters from an initial guess until it converges to a local maximum.", "labels": [], "entities": []}, {"text": "Unfortunately, likelihood functions in practice are riddled with suboptimal local maxima (e.g.,.", "labels": [], "entities": []}, {"text": "Moreover, maximizing likelihood is not equivalent to maximizing task-defined accuracy (e.g.,.", "labels": [], "entities": [{"text": "likelihood", "start_pos": 21, "end_pos": 31, "type": "METRIC", "confidence": 0.5370416045188904}, {"text": "accuracy", "start_pos": 77, "end_pos": 85, "type": "METRIC", "confidence": 0.986156165599823}]}, {"text": "Here we focus on the search error problem.", "labels": [], "entities": []}, {"text": "Assume that one has a model for which improving likelihood really will improve accuracy (e.g., at predicting hidden part-of-speech (POS) tags or parse trees).", "labels": [], "entities": [{"text": "likelihood", "start_pos": 48, "end_pos": 58, "type": "METRIC", "confidence": 0.9420516490936279}, {"text": "accuracy", "start_pos": 79, "end_pos": 87, "type": "METRIC", "confidence": 0.998374342918396}, {"text": "predicting hidden part-of-speech (POS) tags", "start_pos": 98, "end_pos": 141, "type": "TASK", "confidence": 0.8086209041731698}]}, {"text": "Hence, we seek methods that tend to locate mountaintops rather than hilltops of the likelihood function.", "labels": [], "entities": []}, {"text": "Alternatively, we might want methods that find hilltops with other desirable properties.", "labels": [], "entities": []}, {"text": "1 suggest that one should seek a highIn \u00a72 we review deterministic annealing (DA) and show how it generalizes the EM algorithm.", "labels": [], "entities": []}, {"text": "\u00a73 shows how DA can be used for parameter estimation for models of language structure that use dynamic programming to compute posteriors over hidden structure, such as hidden Markov models (HMMs) and stochastic context-free grammars (SCFGs).", "labels": [], "entities": []}, {"text": "In \u00a74 we apply DA to the problem of learning a trigram POS tagger without labeled data.", "labels": [], "entities": []}, {"text": "We then describe how one of the received strengths of DAits robustness to the initializing model parameterscan be a shortcoming in situations where the initial parameters carry a helpful bias.", "labels": [], "entities": []}, {"text": "We present a solution to this problem in the form of anew algorithm, skewed deterministic annealing (SDA; \u00a75).", "labels": [], "entities": []}, {"text": "Finally we apply SDA to a grammar induction model and demonstrate significantly improved performance over EM ( \u00a76).", "labels": [], "entities": []}, {"text": "\u00a77 highlights future directions for this work.", "labels": [], "entities": []}], "datasetContent": [{"text": "We ran experiments using both CCM models on the tag sequences of length tenor less in the Wall Street Journal Penn Treebank corpus, after extracting punctuation.", "labels": [], "entities": [{"text": "Wall Street Journal Penn Treebank corpus", "start_pos": 90, "end_pos": 130, "type": "DATASET", "confidence": 0.965567390124003}]}, {"text": "This corpus consists of 7,519 sentences (52,837 tag tokens, 38 types).", "labels": [], "entities": []}, {"text": "We report PARSEVAL scores averaged by constituent (rather than by sentence), and do not give the learner credit forgetting full sentences or single tags as constituents.", "labels": [], "entities": [{"text": "PARSEVAL", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.8661568760871887}]}, {"text": "Because the E step for this model is computationally intensive, we set the DA parameters at \u03b2 min = 0.01, \u03b1 = 1.5 so that fewer E steps would be necessary.", "labels": [], "entities": [{"text": "E", "start_pos": 12, "end_pos": 13, "type": "METRIC", "confidence": 0.9408271908760071}, {"text": "DA", "start_pos": 75, "end_pos": 77, "type": "METRIC", "confidence": 0.7945720553398132}]}, {"text": "The convergence criterion was relative improvement < 10 \u22129 in the objective.", "labels": [], "entities": [{"text": "convergence", "start_pos": 4, "end_pos": 15, "type": "METRIC", "confidence": 0.9896413683891296}]}, {"text": "The results are shown in.", "labels": [], "entities": []}, {"text": "The first point to notice is that a uniform initializer is a bad idea, as Klein and Manning predicted.", "labels": [], "entities": []}, {"text": "All conditions but We refer readers to or Cover and Thomas (1991, p.", "labels": [], "entities": []}, {"text": "72) for details; computing expected counts fora sentence is a closed form operation.", "labels": [], "entities": []}, {"text": "Klein and Manning's argument for this initialization step is that it is less biased toward balanced trees than the uniform model used during learning; we also found that it works far better in practice.", "labels": [], "entities": []}, {"text": "12 This is why the CCM 1 performance reported here differs from Klein and Manning's; our implementation of the EM condition gave virtually identical results under either evaluation scheme  The two CCM models, trained with two unsupervised algorithms, each with two initializers.", "labels": [], "entities": []}, {"text": "Note that DA is equivalent to SDA initialized with a uniform distribution.", "labels": [], "entities": []}, {"text": "The third line corresponds to the setup reported by.", "labels": [], "entities": []}, {"text": "UR is unlabeled recall, UP is unlabeled precision, F is their harmonic mean, and CB is the average number of crossing brackets per sentence.", "labels": [], "entities": [{"text": "UR", "start_pos": 0, "end_pos": 2, "type": "METRIC", "confidence": 0.975884199142456}, {"text": "recall", "start_pos": 16, "end_pos": 22, "type": "METRIC", "confidence": 0.9831799268722534}, {"text": "UP", "start_pos": 24, "end_pos": 26, "type": "METRIC", "confidence": 0.9946303367614746}, {"text": "precision", "start_pos": 40, "end_pos": 49, "type": "METRIC", "confidence": 0.9696016907691956}, {"text": "CB", "start_pos": 81, "end_pos": 83, "type": "METRIC", "confidence": 0.9812303781509399}]}, {"text": "All evaluation is on the same data used for unsupervised learning (i.e., there is no training/test split).", "labels": [], "entities": []}, {"text": "The high cross-entropy values arise from the deficiency of models 1 and 2, and are not comparable across models.", "labels": [], "entities": []}, {"text": "one find better structure when initialized with Klein and Manning's random-split model.", "labels": [], "entities": []}, {"text": "(The exception is SDA on model 1; possibly the high deficiency of model 1 interacts poorly with SDA's search in some way.)", "labels": [], "entities": []}, {"text": "Next we note that with the random-split initializer, our model 2 is a bit better than model 1 on PARSEVAL measures and converges more quickly.", "labels": [], "entities": [{"text": "PARSEVAL", "start_pos": 97, "end_pos": 105, "type": "METRIC", "confidence": 0.5798410773277283}]}, {"text": "Every instance of DA or SDA achieved higher log-likelihood than the corresponding EM condition.", "labels": [], "entities": []}, {"text": "This is what we hoped to gain from annealing: better local maxima.", "labels": [], "entities": []}, {"text": "In the case of model 2 with the random-split initializer, SDA significantly outperformed EM (comparing both matches and crossing brackets per sentence under a binomial sign test, p < 10 \u22126 ); we see a > 5% reduction in average crossing brackets per sentence.", "labels": [], "entities": []}, {"text": "Thus, our strategy of using DA but modifying it to accept an initializer worked as desired in this case, yielding our best overall performance.", "labels": [], "entities": []}, {"text": "The systematic results we describe next suggest that these patterns persist across different training sets in this domain.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: EM vs. DA on unsupervised trigram POS tagging, using a tag dictionary. Each of the accuracy results is significant when  accuracy is compared at either the word-level or sentence-level. (Significance at p < 10 \u22126 under a binomial sign test in each  case. E.g., on the test set, the DA model correctly tagged 1,652 words that EM's model missed while EM correctly tagged 726  words that DA missed. Similarly, the DA model had higher accuracy on 850 sentences, while EM had higher accuracy on only 287.  These differences are extremely unlikely to occur due to chance.) The differences in cross-entropy, compared by sentence, were  significant in the training set but not the test set (p < 0.01 under a binomial sign test). Recall that lower cross entropy means higher  likelihood.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 93, "end_pos": 101, "type": "METRIC", "confidence": 0.9982625842094421}, {"text": "accuracy", "start_pos": 131, "end_pos": 139, "type": "METRIC", "confidence": 0.9976992011070251}, {"text": "accuracy", "start_pos": 441, "end_pos": 449, "type": "METRIC", "confidence": 0.9828739762306213}, {"text": "accuracy", "start_pos": 488, "end_pos": 496, "type": "METRIC", "confidence": 0.9718238711357117}]}]}