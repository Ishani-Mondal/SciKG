{"title": [{"text": "Discovering Relations among Named Entities from Large Corpora", "labels": [], "entities": []}], "abstractContent": [{"text": "Discovering the significant relations embedded in documents would be very useful not only for information retrieval but also for question answering and summarization.", "labels": [], "entities": [{"text": "Discovering the significant relations embedded in documents", "start_pos": 0, "end_pos": 59, "type": "TASK", "confidence": 0.7687703711645943}, {"text": "information retrieval", "start_pos": 94, "end_pos": 115, "type": "TASK", "confidence": 0.733686625957489}, {"text": "question answering", "start_pos": 129, "end_pos": 147, "type": "TASK", "confidence": 0.9164650142192841}, {"text": "summarization", "start_pos": 152, "end_pos": 165, "type": "TASK", "confidence": 0.9843866229057312}]}, {"text": "Prior methods for relation discovery , however, needed large annotated corpora which cost a great deal of time and effort.", "labels": [], "entities": [{"text": "relation discovery", "start_pos": 18, "end_pos": 36, "type": "TASK", "confidence": 0.9772752821445465}]}, {"text": "We propose an unsupervised method for relation discovery from large corpora.", "labels": [], "entities": [{"text": "relation discovery from large corpora", "start_pos": 38, "end_pos": 75, "type": "TASK", "confidence": 0.8985373497009277}]}, {"text": "The key idea is clustering pairs of named entities according to the similarity of context words intervening between the named entities.", "labels": [], "entities": [{"text": "clustering pairs of named entities", "start_pos": 16, "end_pos": 50, "type": "TASK", "confidence": 0.8133885741233826}]}, {"text": "Our experiments using one year of newspapers reveals not only that the relations among named entities could be detected with high recall and precision, but also that appropriate labels could be automatically provided for the relations.", "labels": [], "entities": [{"text": "recall", "start_pos": 130, "end_pos": 136, "type": "METRIC", "confidence": 0.9992879033088684}, {"text": "precision", "start_pos": 141, "end_pos": 150, "type": "METRIC", "confidence": 0.9952221512794495}]}], "introductionContent": [{"text": "Although Internet search engines enable us to access a great deal of information, they cannot easily give us answers to complicated queries, such as \"a list of recent mergers and acquisitions of companies\" or \"current leaders of nations from allover the world\".", "labels": [], "entities": []}, {"text": "In order to find answers to these types of queries, we have to analyze relevant documents to collect the necessary information.", "labels": [], "entities": []}, {"text": "If many relations such as \"Company A merged with Company B\" embedded in those documents could be gathered and structured automatically, it would be very useful not only for information retrieval but also for question answering and summarization.", "labels": [], "entities": [{"text": "information retrieval", "start_pos": 173, "end_pos": 194, "type": "TASK", "confidence": 0.7538990676403046}, {"text": "question answering", "start_pos": 208, "end_pos": 226, "type": "TASK", "confidence": 0.9299102425575256}, {"text": "summarization", "start_pos": 231, "end_pos": 244, "type": "TASK", "confidence": 0.9769008159637451}]}, {"text": "Information Extraction provides methods for extracting information such as particular events and relations between entities from text.", "labels": [], "entities": [{"text": "Information Extraction", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.7681346535682678}]}, {"text": "However, it is domain dependent and it could not give answers to those types of queries from Web documents which include widely various domains.", "labels": [], "entities": []}, {"text": "Our goal is automatically discovering useful relations among arbitrary entities embedded in large \u00a3 This work is supported by Nippon Telegraph and Telephone (NTT) Corporation's one-year visiting program at New York University.", "labels": [], "entities": [{"text": "Nippon Telegraph and Telephone (NTT) Corporation", "start_pos": 126, "end_pos": 174, "type": "DATASET", "confidence": 0.7811107039451599}]}, {"text": "We defined a relation broadly as an affiliation, role, location, part-whole, social relationship and soon between a pair of entities.", "labels": [], "entities": []}, {"text": "For example, if the sentence, \"George Bush was inaugurated as the president of the United States.\" exists in documents, the relation, \"George Bush\"(PERSON) is the \"President of\" the \"United States\" (GPE 1 ), should be extracted.", "labels": [], "entities": []}, {"text": "In this paper, we propose an unsupervised method of discovering relations among various entities from large text corpora.", "labels": [], "entities": []}, {"text": "Our method does not need the richly annotated corpora required for supervised learning -corpora which take great time and effort to prepare.", "labels": [], "entities": []}, {"text": "It also does not need any instances of relations as initial seeds for weakly supervised learning.", "labels": [], "entities": []}, {"text": "This is an advantage of our approach, since we cannot know in advance all the relations embedded in text.", "labels": [], "entities": []}, {"text": "Instead, we only need a named entity (NE) tagger to focus on the named entities which should be the arguments of relations.", "labels": [], "entities": []}, {"text": "Recently developed named entity taggers work quite well and are able to extract named entities from text at a practically useful level.", "labels": [], "entities": [{"text": "named entity taggers", "start_pos": 19, "end_pos": 39, "type": "TASK", "confidence": 0.7155890464782715}]}, {"text": "The rest of this paper is organized as follows.", "labels": [], "entities": []}, {"text": "We discuss prior work and their limitations in section 2.", "labels": [], "entities": []}, {"text": "We propose anew method of relation discovery in section 3.", "labels": [], "entities": [{"text": "relation discovery", "start_pos": 26, "end_pos": 44, "type": "TASK", "confidence": 0.9454552233219147}]}, {"text": "Then we describe experiments and evaluations in section 4 and 5, and discuss the approach in section 6.", "labels": [], "entities": []}, {"text": "Finally, we conclude with future work.", "labels": [], "entities": []}], "datasetContent": [{"text": "We experimented with one year of The New York Times (1995) as our corpus to verify our proposed method.", "labels": [], "entities": [{"text": "The New York Times (1995)", "start_pos": 33, "end_pos": 58, "type": "DATASET", "confidence": 0.8930486440658569}]}, {"text": "We determined three parameters for thresholds and identified the patterns for parallel expressions and expressions peculiar to The New York Times as ignorable context.", "labels": [], "entities": [{"text": "The New York Times", "start_pos": 127, "end_pos": 145, "type": "DATASET", "confidence": 0.9362948834896088}]}, {"text": "We set the maximum context word length to 5 words and set the frequency threshold of co-occurring NE pairs to 30 empirically.", "labels": [], "entities": []}, {"text": "We also used the patterns, \",.*,\", \"and\" and \"or\" for parallel expressions, and the pattern \") --\" (used in datelines at the beginning of articles) as peculiar to The New York Times.", "labels": [], "entities": [{"text": "The New York Times", "start_pos": 163, "end_pos": 181, "type": "DATASET", "confidence": 0.7667446881532669}]}, {"text": "In our experiment, the norm threshold was set to 10.", "labels": [], "entities": []}, {"text": "We also used stop words when context vectors are made.", "labels": [], "entities": []}, {"text": "The stop words include symbols and words which occurred under 3 times as infrequent words and those which occurred over 100,000 times as highly frequent words.", "labels": [], "entities": []}, {"text": "We applied our proposed method to The New York Times 1995, identified the NE pairs satisfying our criteria, and extracted the NE pairs along with their intervening words as our data set.", "labels": [], "entities": [{"text": "The New York Times 1995", "start_pos": 34, "end_pos": 57, "type": "DATASET", "confidence": 0.9513335704803467}]}, {"text": "In order to evaluate the relations detected automatically, we analyzed the data set manually and identified the relations for two different domains.", "labels": [], "entities": []}, {"text": "One was the PERSON-GPE (PER-GPE) domain.", "labels": [], "entities": [{"text": "PERSON-GPE (PER-GPE) domain", "start_pos": 12, "end_pos": 39, "type": "DATASET", "confidence": 0.7101800680160523}]}, {"text": "We obtained 177 distinct NE pairs and classified them into 38 classes (relations) manually.", "labels": [], "entities": []}, {"text": "The other was the COMPANY-COMPANY (COM-COM) domain.", "labels": [], "entities": [{"text": "COMPANY-COMPANY (COM-COM) domain", "start_pos": 18, "end_pos": 50, "type": "DATASET", "confidence": 0.7384053826332092}]}, {"text": "We got 65 distinct NE pairs and classified them into 10 classes manually.", "labels": [], "entities": []}, {"text": "However, the types of both arguments of a relation are the same in the COM-COM domain.", "labels": [], "entities": []}, {"text": "So the COM-COM domain includes symmetrical relations as well as asymmetrical relations.", "labels": [], "entities": []}, {"text": "For the latter, we have to distinguish the different orders of arguments.", "labels": [], "entities": []}, {"text": "We show the types of classes and the number in each class in.", "labels": [], "entities": []}, {"text": "The errors in NE tagging were eliminated to evaluate our method correctly.", "labels": [], "entities": [{"text": "NE tagging", "start_pos": 14, "end_pos": 24, "type": "TASK", "confidence": 0.9145848155021667}]}, {"text": "We evaluated separately the placement of the NE pairs into clusters and the assignment of labels to these clusters.", "labels": [], "entities": []}, {"text": "In the first step, we evaluated clusters consisting of two or more pairs.", "labels": [], "entities": []}, {"text": "For each cluster, we determined the relation (R) of the cluster as the most frequently represented relation; we call this the major relation of the cluster.", "labels": [], "entities": []}, {"text": "NE pairs with relation R in a cluster whose major relation was R were counted as correct; the correct pair count, These values vary depending on the threshold of cosine similarity.", "labels": [], "entities": []}, {"text": "As the threshold is decreased, the clusters gradually merge, finally forming one big cluster.", "labels": [], "entities": []}, {"text": "We show the results of complete linkage clustering for the PERSON-GPE (PER-GPE) domain in and for the COMPANY-COMPANY (COM-COM) domain in.", "labels": [], "entities": []}, {"text": "With these metrics, precision fell as the threshold of cosine similarity was lowered.", "labels": [], "entities": [{"text": "precision", "start_pos": 20, "end_pos": 29, "type": "METRIC", "confidence": 0.9994575381278992}]}, {"text": "Recall increased until the threshold was almost 0, at which point it fell because the total number of correct pairs in the remaining few big clusters decreased.", "labels": [], "entities": [{"text": "Recall", "start_pos": 0, "end_pos": 6, "type": "METRIC", "confidence": 0.9876225590705872}]}, {"text": "The best F-measure was 82 in the PER-GPE domain, 77 in the COM-COM domain.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 9, "end_pos": 18, "type": "METRIC", "confidence": 0.9987566471099854}, {"text": "PER-GPE domain", "start_pos": 33, "end_pos": 47, "type": "DATASET", "confidence": 0.7354330122470856}, {"text": "COM-COM domain", "start_pos": 59, "end_pos": 73, "type": "DATASET", "confidence": 0.8351708650588989}]}, {"text": "In both domains, the best F-measure was found near 0 cosine similarity.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 26, "end_pos": 35, "type": "METRIC", "confidence": 0.9975304007530212}, {"text": "0 cosine similarity", "start_pos": 51, "end_pos": 70, "type": "METRIC", "confidence": 0.5607411563396454}]}, {"text": "Generally, it is difficult to determine the threshold of similarity in advance.", "labels": [], "entities": [{"text": "similarity", "start_pos": 57, "end_pos": 67, "type": "METRIC", "confidence": 0.8443713188171387}]}, {"text": "Since the best threshold of cosine similarity was almost same in the two domains, we fixed the cosine threshold at a single value just above zero for both domains for simplicity.", "labels": [], "entities": []}, {"text": "We also investigated each cluster with the threshold of cosine similarity just above 0.", "labels": [], "entities": []}, {"text": "We got 34: Major relations in clusters and the most frequent common words in each cluster PER-GPE clusters and 15 COM-COM clusters.", "labels": [], "entities": []}, {"text": "We show the F-measure, recall and precision at this cosine threshold in both domains in.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 12, "end_pos": 21, "type": "METRIC", "confidence": 0.99919193983078}, {"text": "recall", "start_pos": 23, "end_pos": 29, "type": "METRIC", "confidence": 0.9995611310005188}, {"text": "precision", "start_pos": 34, "end_pos": 43, "type": "METRIC", "confidence": 0.9996342658996582}]}, {"text": "We got 80 F-measure in the PER-GPE domain and 75 Fmeasure in the COM-COM domain.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9971861243247986}, {"text": "PER-GPE", "start_pos": 27, "end_pos": 34, "type": "METRIC", "confidence": 0.8183653354644775}, {"text": "Fmeasure", "start_pos": 49, "end_pos": 57, "type": "METRIC", "confidence": 0.9900131225585938}]}, {"text": "These values were very close to the best F-measure.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 41, "end_pos": 50, "type": "METRIC", "confidence": 0.9824032783508301}]}, {"text": "Then, we evaluated the labeling of clusters of NE pairs.", "labels": [], "entities": []}, {"text": "We show the larger clusters for each domain, along with the ratio of the number of pairs bearing the major relation to the total number of pairs in each cluster, on the left in.", "labels": [], "entities": []}, {"text": "(As noted above, the major relation is the most frequently represented relation in the cluster.)", "labels": [], "entities": []}, {"text": "We also show the most frequent common words and their relative frequency in each cluster on the right in.", "labels": [], "entities": []}, {"text": "If two NE pairs in a cluster share a particular context word, we consider these pairs to be linked (with respect to this word).", "labels": [], "entities": []}, {"text": "The relative frequency fora word is the number of such links, relative to the maximal possible number of links  , the word is shared by all NE pairs.", "labels": [], "entities": []}, {"text": "Although we obtained some meaningful relations in small clusters, we have omitted the small clusters because the common words in such small clusters might be unreliable.", "labels": [], "entities": []}, {"text": "We found that all large clusters had appropriate relations and that the common words which occurred frequently in those clusters accurately represented the relations.", "labels": [], "entities": []}, {"text": "In other words, the frequent common words could be regarded as suitable labels for the relations.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Manually classified relations which are extracted from Newspapers", "labels": [], "entities": [{"text": "Newspapers", "start_pos": 65, "end_pos": 75, "type": "DATASET", "confidence": 0.7876375913619995}]}]}