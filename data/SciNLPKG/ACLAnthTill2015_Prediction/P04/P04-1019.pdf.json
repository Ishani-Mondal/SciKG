{"title": [], "abstractContent": [{"text": "We use machine learning techniques to find the best combination of local focus and lexical distance features for identifying the anchor of mereological bridging references.", "labels": [], "entities": []}, {"text": "We find that using first mention , utterance distance, and lexical distance computed using either Google or WordNet results in an accuracy significantly higher than obtained in previous experiments.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 108, "end_pos": 115, "type": "DATASET", "confidence": 0.9292795062065125}, {"text": "accuracy", "start_pos": 130, "end_pos": 138, "type": "METRIC", "confidence": 0.9992085099220276}]}], "introductionContent": [{"text": "BRIDGING REFERENCES (BR)anaphoric expressions that cannot be resolved purely on the basis of string matching and thus require the reader to 'bridge' the gap using commonsense inferences-are arguably the most interesting and, at the same time, the most challenging problem in anaphora resolution.", "labels": [], "entities": [{"text": "BRIDGING REFERENCES (BR", "start_pos": 0, "end_pos": 23, "type": "METRIC", "confidence": 0.8463872820138931}, {"text": "anaphora resolution", "start_pos": 275, "end_pos": 294, "type": "TASK", "confidence": 0.8079661726951599}]}, {"text": "Work such as ( provided an experimental confirmation of the hypothesis first put forward by that BRIDG-ING DESCRIPTIONS (BD) 1 are more similar to pronouns than to other types of definite descriptions, in that they are sensitive to the local rather than the global focus (.", "labels": [], "entities": [{"text": "BRIDG-ING DESCRIPTIONS (BD) 1", "start_pos": 97, "end_pos": 126, "type": "METRIC", "confidence": 0.886435737212499}]}, {"text": "This previuous work also suggested that simply choosing the entity whose description is lexically closest to that of the bridging description among those in the current focus space gives poor results; in fact, better results are obtained by always choosing as ANCHOR of the bridging reference 2 the first-mentioned entity of the previous sentence.", "labels": [], "entities": [{"text": "ANCHOR", "start_pos": 260, "end_pos": 266, "type": "METRIC", "confidence": 0.9952303767204285}]}, {"text": "But neither source of information in isolation resulted in an accuracy over 40%.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 62, "end_pos": 70, "type": "METRIC", "confidence": 0.9995197057723999}]}, {"text": "In short, this earlier work suggested that a combination of salience and lexical / commonsense information is needed to choose the most likely anchor; the problem remained of how to combine this information.", "labels": [], "entities": []}, {"text": "In the work described in this paper, we used machine learning techniques to find the best combination of local focus features and lexical distance features, focusing on MEREOLOGICAL bridging references: 3 references referring to parts of an object already introduced (the cabinet), such as the panels or the top (underlined) in the following example from the GNOME corpus ( ).", "labels": [], "entities": [{"text": "MEREOLOGICAL", "start_pos": 169, "end_pos": 181, "type": "METRIC", "confidence": 0.8309488296508789}, {"text": "GNOME corpus", "start_pos": 359, "end_pos": 371, "type": "DATASET", "confidence": 0.9029655754566193}]}, {"text": "(1) The combination of rare and expensive materials used on [this cabinet]i indicates that it was a particularly expensive commission.", "labels": [], "entities": []}, {"text": "The four Japanese lacquer panels date from the mid-to late 1600s and were created with a technique known as kijimaki-e.", "labels": [], "entities": []}, {"text": "For this type of lacquer, artisans sanded plain wood to heighten its strong grain and used it as the background of each panel.", "labels": [], "entities": []}, {"text": "They then added the scenic elements of landscape, plants, and animals in raised lacquer.", "labels": [], "entities": []}, {"text": "Although this technique was common in Japan, such large panels were rarely incorporated into French eighteenth-century furniture.", "labels": [], "entities": []}, {"text": "Heavy Ionic pilasters, whose copper-filled flutes give an added rich color and contrast to the giltbronze mounts, flank the panels.", "labels": [], "entities": []}, {"text": "Yellow jasper, a semiprecious stone, rather than the usual marble, forms the top.", "labels": [], "entities": []}], "datasetContent": [{"text": "In the first series of experiments only mereological Bridging Descriptions were considered (i.e., only bridging references realized by the-NPs).", "labels": [], "entities": []}, {"text": "Ina second series of experiments we considered all 153 mereological BRs, including ones realized with indefinites.", "labels": [], "entities": []}, {"text": "Finally, we tested a classifier trained on balanced data (1:1 and 1:3) to find the anchors of BDs among all possible anchors.", "labels": [], "entities": []}, {"text": "The GNOME corpus contains 58 mereological BDs.", "labels": [], "entities": [{"text": "GNOME corpus", "start_pos": 4, "end_pos": 16, "type": "DATASET", "confidence": 0.9166045784950256}]}, {"text": "The five sentences preceding these 58 BDs contain a total of 1511 distinct entities for which ahead could be recovered, possibly by examining their antecedents.", "labels": [], "entities": []}, {"text": "This means an average of 26 distinct potential antecedents per BD, and 5.2 entities per sentence.", "labels": [], "entities": [{"text": "BD", "start_pos": 63, "end_pos": 65, "type": "METRIC", "confidence": 0.5955567359924316}]}, {"text": "The simplest baselines for the task of finding the anchor are therefore 4% (by randomly choosing one antecedent among those in the previous five sentences) and 19.2% (by randomly choosing one antecedent among those in the previous sentence only).", "labels": [], "entities": [{"text": "finding the anchor", "start_pos": 39, "end_pos": 57, "type": "TASK", "confidence": 0.7619491020838419}]}, {"text": "As 4.6 entities on average were realized in first mention position in the five sentences preceding a BD (269/58), choosing randomly among the first-mentioned entities gives a slighly higher accuracy of 21.3%.", "labels": [], "entities": [{"text": "BD", "start_pos": 101, "end_pos": 103, "type": "METRIC", "confidence": 0.9472729563713074}, {"text": "accuracy", "start_pos": 190, "end_pos": 198, "type": "METRIC", "confidence": 0.9983501434326172}]}, {"text": "A few further baselines can be established by examining each feature separately.", "labels": [], "entities": []}, {"text": "Google didn't return any hits for 1089 out of 1511 distinct PAs, and no hit for 24/58 anchors; in 8/58 of cases (13.8%) the entity with the minimum Google distance is the correct anchor.", "labels": [], "entities": []}, {"text": "We saw before that the method for computing WordNet distance used in didn't find a path for any of the mereological BDs; however, not trying to follow mereological links worked much better, achieving the same accuracy as Google distance (8/58, 13.8%) and finding connections for much higher percentages of concepts: no path could be found for only 10/58 of actual anchors, and for 503/1511 potential antecedents.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 209, "end_pos": 217, "type": "METRIC", "confidence": 0.9988436698913574}]}, {"text": "Pairwise combinations of these features were also considered.", "labels": [], "entities": []}, {"text": "The best such combination, choosing the first mentioned entity in the previous sentence, achieves an accuracy of 18/58, 31%.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 101, "end_pos": 109, "type": "METRIC", "confidence": 0.9996229410171509}]}, {"text": "These baseline results are summarized in the following table.", "labels": [], "entities": []}, {"text": "Notice how even the best baselines achieve pretty low accuracy, and how even simple 'salience' measures work better than lexical distance measures.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 54, "end_pos": 62, "type": "METRIC", "confidence": 0.9983106851577759}]}, {"text": "The features utterance distance, local first mention, and global f.m. were used in all machine learning experiments.", "labels": [], "entities": []}, {"text": "But since one of our goals was to compare different lexical resources, only one lexical distance feature was used in the first two experiment.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: BD resolution results using only lexical distance with WordNet, HAL-style vectorial lexicon,  and construction-based lexicon.", "labels": [], "entities": [{"text": "BD resolution", "start_pos": 10, "end_pos": 23, "type": "TASK", "confidence": 0.7345751821994781}, {"text": "WordNet", "start_pos": 65, "end_pos": 72, "type": "DATASET", "confidence": 0.9692847728729248}]}, {"text": " Table 2: Baselines for the BD task", "labels": [], "entities": [{"text": "BD", "start_pos": 28, "end_pos": 30, "type": "DATASET", "confidence": 0.4233342707157135}]}, {"text": " Table 4: Precision and recall for positive instances", "labels": [], "entities": [{"text": "Precision", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9951279163360596}, {"text": "recall", "start_pos": 24, "end_pos": 30, "type": "METRIC", "confidence": 0.9991550445556641}]}]}