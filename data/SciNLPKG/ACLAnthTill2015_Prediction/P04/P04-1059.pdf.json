{"title": [], "abstractContent": [{"text": "This paper presents a Chinese word segmen-tation system which can adapt to different domains and standards.", "labels": [], "entities": []}, {"text": "We first present a statistical framework where domain-specific words are identified in a unified approach to word segmentation based on linear models.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 109, "end_pos": 126, "type": "TASK", "confidence": 0.7322063148021698}]}, {"text": "We explore several features and describe how to create training data by sampling.", "labels": [], "entities": []}, {"text": "We then describe a transformation-based learning method used to adapt our system to different word segmentation standards.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 94, "end_pos": 111, "type": "TASK", "confidence": 0.7294293642044067}]}, {"text": "Evaluation of the proposed system on five test sets with different standards shows that the system achieves state-of-the-art performance on all of them.", "labels": [], "entities": []}, {"text": "1 Introduction Chinese word segmentation has been a long-standing research topic in Chinese language processing.", "labels": [], "entities": [{"text": "Chinese word segmentation", "start_pos": 15, "end_pos": 40, "type": "TASK", "confidence": 0.6336016853650411}, {"text": "Chinese language processing", "start_pos": 84, "end_pos": 111, "type": "TASK", "confidence": 0.6451187531153361}]}, {"text": "Recent development in this field shows that, in addition to ambiguity resolution and unknown word detection, the usefulness of a Chinese word segmenter also depends crucially on its ability to adapt to different domains of texts and different segmentation standards.", "labels": [], "entities": [{"text": "ambiguity resolution", "start_pos": 60, "end_pos": 80, "type": "TASK", "confidence": 0.6975248008966446}, {"text": "unknown word detection", "start_pos": 85, "end_pos": 107, "type": "TASK", "confidence": 0.6674023369948069}, {"text": "Chinese word segmenter", "start_pos": 129, "end_pos": 151, "type": "TASK", "confidence": 0.662448654572169}]}, {"text": "The need of adaptation involves two research issues that we will address in this paper.", "labels": [], "entities": []}, {"text": "The first is new word detection.", "labels": [], "entities": [{"text": "word detection", "start_pos": 17, "end_pos": 31, "type": "TASK", "confidence": 0.8483105301856995}]}, {"text": "Different domains/applications may have different vocabularies which contain new words/terms that are not available in a general dictionary.", "labels": [], "entities": []}, {"text": "In this paper, new words refer to OOV words other than named entities, factoids and morphologically derived words.", "labels": [], "entities": []}, {"text": "These words are mostly domain specific terms (e.g. \u8702\u7a9d\u5f0f 'cellular') and time-sensitive political, social or cultural terms (e.g. \u4e09\u901a'Three Links', \u975e\u5178 'SARS').", "labels": [], "entities": []}, {"text": "The second issue concerns the customizable display of word segmentation.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 54, "end_pos": 71, "type": "TASK", "confidence": 0.7271803170442581}]}, {"text": "Different Chinese NLP-enabled applications may have different requirements that call for different granularities of word segmentation.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 116, "end_pos": 133, "type": "TASK", "confidence": 0.7136996537446976}]}, {"text": "For example, speech recognition systems prefer \"longer words\" to achieve higher accuracy whereas information retrieval systems prefer \"shorter words\" to obtain higher recall rates, etc.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 13, "end_pos": 31, "type": "TASK", "confidence": 0.7844556868076324}, {"text": "accuracy", "start_pos": 80, "end_pos": 88, "type": "METRIC", "confidence": 0.9956023693084717}, {"text": "recall rates", "start_pos": 167, "end_pos": 179, "type": "METRIC", "confidence": 0.9830535054206848}]}, {"text": "(Wu, 2003).", "labels": [], "entities": []}, {"text": "Given a word seg-mentation specification (or standard) and/or some application data used as training data, a segmenter with customizable display should be able to provide alternative segmentation units according to the specification which is either pre-defined or implied in the data.", "labels": [], "entities": []}, {"text": "In this paper, we first present a statistical framework for Chinese word segmentation, where various problems of word segmentation are solved simultaneously in a unified approach.", "labels": [], "entities": [{"text": "Chinese word segmentation", "start_pos": 60, "end_pos": 85, "type": "TASK", "confidence": 0.5887986520926157}, {"text": "word segmentation", "start_pos": 113, "end_pos": 130, "type": "TASK", "confidence": 0.7203624546527863}]}, {"text": "Our approach is based on linear models where component models are inspired by the source-channel models of Chinese sentence generation.", "labels": [], "entities": [{"text": "Chinese sentence generation", "start_pos": 107, "end_pos": 134, "type": "TASK", "confidence": 0.6737274825572968}]}, {"text": "We then describe in detail how the new word identification (NWI) problem is handled in this framework.", "labels": [], "entities": [{"text": "word identification (NWI)", "start_pos": 39, "end_pos": 64, "type": "TASK", "confidence": 0.8457144558429718}]}, {"text": "We explore several features and describe how to create training data by sampling.", "labels": [], "entities": []}, {"text": "We evaluate the performance of our segmentation system using an annotated test set, where new words are simulated by sampling.", "labels": [], "entities": []}, {"text": "We then describe a transformation-based learning (TBL, Brill, 1995) method that is used to adapt our system to different segmentation standards.", "labels": [], "entities": []}, {"text": "We compare the adaptive system to other state-of-the-art systems using four test sets in the SIGHAN's First International Chinese Word Segmentation Bakeoff, each of which is constructed according to a different seg-mentation standard.", "labels": [], "entities": [{"text": "SIGHAN's First International Chinese Word Segmentation Bakeoff", "start_pos": 93, "end_pos": 155, "type": "TASK", "confidence": 0.6855660751461983}]}, {"text": "The performance of our system is comparable to the best systems reported on all four test sets.", "labels": [], "entities": []}, {"text": "It demonstrates the possibility of having a single adaptive Chinese word segmenter that is capable of supporting multiple user applications .", "labels": [], "entities": [{"text": "Chinese word segmenter", "start_pos": 60, "end_pos": 82, "type": "TASK", "confidence": 0.6981220642725626}]}], "introductionContent": [{"text": "Chinese word segmentation has been a longstanding research topic in Chinese language processing.", "labels": [], "entities": [{"text": "Chinese word segmentation", "start_pos": 0, "end_pos": 25, "type": "TASK", "confidence": 0.58929842710495}, {"text": "Chinese language processing", "start_pos": 68, "end_pos": 95, "type": "TASK", "confidence": 0.6395642161369324}]}, {"text": "Recent development in this field shows that, in addition to ambiguity resolution and unknown word detection, the usefulness of a Chinese word segmenter also depends crucially on its ability to adapt to different domains of texts and different segmentation standards.", "labels": [], "entities": [{"text": "ambiguity resolution", "start_pos": 60, "end_pos": 80, "type": "TASK", "confidence": 0.6975248008966446}, {"text": "unknown word detection", "start_pos": 85, "end_pos": 107, "type": "TASK", "confidence": 0.6674023369948069}, {"text": "Chinese word segmenter", "start_pos": 129, "end_pos": 151, "type": "TASK", "confidence": 0.662448654572169}]}, {"text": "The need of adaptation involves two research issues that we will address in this paper.", "labels": [], "entities": []}, {"text": "The first is new word detection.", "labels": [], "entities": [{"text": "word detection", "start_pos": 17, "end_pos": 31, "type": "TASK", "confidence": 0.8483105301856995}]}, {"text": "Different domains/applications may have different vocabularies which contain new words/terms that are not available in a general dictionary.", "labels": [], "entities": []}, {"text": "In this paper, new words refer to OOV words other than named entities, factoids and morphologically derived words.", "labels": [], "entities": []}, {"text": "These words are mostly domain specific terms (e.g. \u8702\u7a9d\u5f0f 'cellular') and time-sensitive political, social or cultural terms (e.g. \u4e09\u901a'Three Links', \u975e\u5178 'SARS').", "labels": [], "entities": []}, {"text": "The second issue concerns the customizable display of word segmentation.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 54, "end_pos": 71, "type": "TASK", "confidence": 0.7271803170442581}]}, {"text": "Different Chinese NLP-enabled applications may have different requirements that call for different granularities of word segmentation.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 116, "end_pos": 133, "type": "TASK", "confidence": 0.7136996537446976}]}, {"text": "For example, speech recognition systems prefer \"longer words\" to achieve higher accuracy whereas information retrieval systems prefer \"shorter words\" to obtain higher recall rates, etc.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 13, "end_pos": 31, "type": "TASK", "confidence": 0.7844556868076324}, {"text": "accuracy", "start_pos": 80, "end_pos": 88, "type": "METRIC", "confidence": 0.9956023693084717}, {"text": "recall rates", "start_pos": 167, "end_pos": 179, "type": "METRIC", "confidence": 0.9830535054206848}]}, {"text": "(. Given a word segmentation specification (or standard) and/or some application data used as training data, a segmenter with customizable display should be able to provide alternative segmentation units according to the specification which is either pre-defined or implied in the data.", "labels": [], "entities": [{"text": "word segmentation specification", "start_pos": 11, "end_pos": 42, "type": "TASK", "confidence": 0.7635753552118937}]}, {"text": "In this paper, we first present a statistical framework for Chinese word segmentation, where various problems of word segmentation are solved simultaneously in a unified approach.", "labels": [], "entities": [{"text": "Chinese word segmentation", "start_pos": 60, "end_pos": 85, "type": "TASK", "confidence": 0.5887986520926157}, {"text": "word segmentation", "start_pos": 113, "end_pos": 130, "type": "TASK", "confidence": 0.7203624546527863}]}, {"text": "Our approach is based on linear models where component models are inspired by the source-channel models of Chinese sentence generation.", "labels": [], "entities": [{"text": "Chinese sentence generation", "start_pos": 107, "end_pos": 134, "type": "TASK", "confidence": 0.6737274825572968}]}, {"text": "We then describe in detail how the new word identification (NWI) problem is handled in this framework.", "labels": [], "entities": [{"text": "word identification (NWI)", "start_pos": 39, "end_pos": 64, "type": "TASK", "confidence": 0.8457144558429718}]}, {"text": "We explore several features and describe how to create training data by sampling.", "labels": [], "entities": []}, {"text": "We evaluate the performance of our segmentation system using an annotated test set, where new words are simulated by sampling.", "labels": [], "entities": []}, {"text": "We then describe a transformation-based learning method that is used to adapt our system to different segmentation standards.", "labels": [], "entities": []}, {"text": "We compare the adaptive system to other state-of-the-art systems using four test sets in the SIGHAN's First International Chinese Word Segmentation Bakeoff, each of which is constructed according to a different segmentation standard.", "labels": [], "entities": [{"text": "SIGHAN's First International Chinese Word Segmentation Bakeoff", "start_pos": 93, "end_pos": 155, "type": "TASK", "confidence": 0.6953701302409172}]}, {"text": "The performance of our system is comparable to the best systems reported on all four test sets.", "labels": [], "entities": []}, {"text": "It demonstrates the possibility of having a single adaptive Chinese word segmenter that is capable of supporting multiple user applications.", "labels": [], "entities": [{"text": "Chinese word segmenter", "start_pos": 60, "end_pos": 82, "type": "TASK", "confidence": 0.6981220642725626}]}], "datasetContent": [{"text": "We evaluated the proposed adaptive word segmentation system (henceforth AWS) using five different standards.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 35, "end_pos": 52, "type": "TASK", "confidence": 0.7205391675233841}]}, {"text": "The training and test corpora of these standards are detailed in  MSR is used as the general standard in our experiments, on the basis of which the generic segmenter has been developed.", "labels": [], "entities": []}, {"text": "The training and test corpora were annotated manually, where there is only one allowable word segmentation for each sentence.", "labels": [], "entities": []}, {"text": "The training corpus contains approximately 35 million Chinese characters from various domains of text such as newspapers, novels, magazines etc.", "labels": [], "entities": []}, {"text": "90% of the training corpus are used for context model training, and 10% are held-out data for model parameter training as shown in.", "labels": [], "entities": []}, {"text": "The NE class models, as shown in, were trained on the corresponding NE lists that were collected separately.", "labels": [], "entities": []}, {"text": "The test set contains a total of 225,734 tokens, including 205,162 lexicon/morph-lexicon words, 3,703 PNs, 5,287 LNs, 3,822 ONs, and 4,152 factoids.", "labels": [], "entities": []}, {"text": "In Section 5.1, we will describe some simulated test sets that are derived from the MSR test set by sampling NWs from a 98,686-entry dictionary.", "labels": [], "entities": [{"text": "MSR test set", "start_pos": 84, "end_pos": 96, "type": "DATASET", "confidence": 0.8605669736862183}]}, {"text": "The four Bakeoff standards are used as 'specific' standards into which we wish to adapt the general standard.", "labels": [], "entities": [{"text": "Bakeoff standards", "start_pos": 9, "end_pos": 26, "type": "DATASET", "confidence": 0.8765552639961243}]}, {"text": "We notice in that the sizes of adaptation data sets (i.e. training corpora of the four Bakeoff standards) are much smaller than that of the MSR training set.", "labels": [], "entities": [{"text": "MSR training set", "start_pos": 140, "end_pos": 156, "type": "DATASET", "confidence": 0.7187062303225199}]}, {"text": "The experimental setting turns out to be a good simulation of the adaptation paradigm described in Section 4.", "labels": [], "entities": []}, {"text": "The performance of word segmentation is measured through test precision (P), test recall (R), F score (which is defined as 2PR/(P+R)), the OOV rate for the test corpus (on Bakeoff corpora, OOV is defined as the set of words in the test corpus not occurring in the training corpus.), the recall on OOV words (Roov), and the recall on in-vocabulary (Riv) words.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 19, "end_pos": 36, "type": "TASK", "confidence": 0.728930652141571}, {"text": "test precision (P)", "start_pos": 57, "end_pos": 75, "type": "METRIC", "confidence": 0.7871649980545044}, {"text": "recall (R)", "start_pos": 82, "end_pos": 92, "type": "METRIC", "confidence": 0.9189595729112625}, {"text": "F score", "start_pos": 94, "end_pos": 101, "type": "METRIC", "confidence": 0.9925885796546936}, {"text": "OOV rate", "start_pos": 139, "end_pos": 147, "type": "METRIC", "confidence": 0.9611916840076447}, {"text": "recall on OOV words (Roov)", "start_pos": 287, "end_pos": 313, "type": "METRIC", "confidence": 0.582273930311203}, {"text": "recall", "start_pos": 323, "end_pos": 329, "type": "METRIC", "confidence": 0.996940016746521}]}, {"text": "We also tested the statistical significance of results, using the criterion proposed by, and all results reported in this section are significantly different from each other.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: NWI results on MSR test set, NWI as post-processor versus unified approach", "labels": [], "entities": [{"text": "MSR test set", "start_pos": 25, "end_pos": 37, "type": "DATASET", "confidence": 0.8201567331949869}]}, {"text": " Table 3: Comparison scores for PK open and CTB open.", "labels": [], "entities": []}, {"text": " Table 4: Comparison scores for HK open and AS open.", "labels": [], "entities": []}]}