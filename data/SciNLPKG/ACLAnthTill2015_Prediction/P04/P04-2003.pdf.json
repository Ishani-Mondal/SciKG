{"title": [{"text": "Searching for Topics in a Large Collection of Texts", "labels": [], "entities": []}], "abstractContent": [{"text": "We describe an original method that automatically finds specific topics in a large collection of texts.", "labels": [], "entities": []}, {"text": "Each topic is first identified as a specific cluster of texts and then represented as a virtual concept, which is a weighted mixture of words.", "labels": [], "entities": []}, {"text": "Our intention is to employ these virtual concepts in document indexing.", "labels": [], "entities": [{"text": "document indexing", "start_pos": 53, "end_pos": 70, "type": "TASK", "confidence": 0.7120935022830963}]}, {"text": "In this paper we show some preliminary experimental results and discuss directions of future work.", "labels": [], "entities": []}], "introductionContent": [{"text": "In the field of information retrieval (for a detailed survey see e.g. (), document indexing and representing documents as vectors belongs among the most successful techniques.", "labels": [], "entities": [{"text": "information retrieval", "start_pos": 16, "end_pos": 37, "type": "TASK", "confidence": 0.7573213875293732}, {"text": "document indexing", "start_pos": 74, "end_pos": 91, "type": "TASK", "confidence": 0.7323360443115234}]}, {"text": "Within the framework of the well known vector model, the indexed elements are usually individual words, which leads to high dimensional vectors.", "labels": [], "entities": []}, {"text": "However, there are several approaches that try to reduce the high dimensionality of the vectors in order to improve the effectivity of retrieving.", "labels": [], "entities": []}, {"text": "The most famous is probably the method called Latent Semantic Indexing (LSI), introduced by, which employs a specific linear transformation of original word-based vectors using a system of \"latent semantic concepts\".", "labels": [], "entities": [{"text": "Latent Semantic Indexing (LSI)", "start_pos": 46, "end_pos": 76, "type": "TASK", "confidence": 0.7589203417301178}]}, {"text": "Other two approaches which inspired us, namely and, are similar to LSI but different in the way how they project the vectors of documents into a space of a lower dimension.", "labels": [], "entities": []}, {"text": "Our idea is to establish a system of \"virtual concepts\", which are linear functions represented by vectors, extracted from automatically discovered \"concept-formative clusters\" of documents.", "labels": [], "entities": []}, {"text": "Shortly speaking, concept-formative clusters are semantically coherent and specific sets of documents, which represent specific topics.", "labels": [], "entities": []}, {"text": "This idea was originally proposed by, who hypothesizes that concept-oriented vector models of documents based on indexing virtual concepts could improve the effectiveness of both automatic comparison of documents and their matching with queries.", "labels": [], "entities": []}, {"text": "The paper is organized as follows.", "labels": [], "entities": []}, {"text": "In section 2 we formalize the notion of concept-formative clusters and give a heuristic method of finding them.", "labels": [], "entities": []}, {"text": "Section 3 first introduces virtual concepts in a formal way and shows an algorithm to construct them.", "labels": [], "entities": []}, {"text": "Then, some experiments are shown.", "labels": [], "entities": []}, {"text": "In sections 4 we compare our model with another approach and give a brief survey of some open questions.", "labels": [], "entities": []}, {"text": "Finally, a short summary is given in section 5.", "labels": [], "entities": []}, {"text": "where the three lambdas are parameters whose purpose is balancing the three factors.", "labels": [], "entities": []}, {"text": "To be concept-formative, a cut (i) must have a sufficiently high quality and (ii) must be locally optimal.", "labels": [], "entities": []}, {"text": "which results from the original # as its local modification.", "labels": [], "entities": []}, {"text": "First we need the following definition:", "labels": [], "entities": []}], "datasetContent": [{"text": "The experiments reported here were done on a small experimental collection of Czech documents.", "labels": [], "entities": [{"text": "Czech documents", "start_pos": 78, "end_pos": 93, "type": "DATASET", "confidence": 0.8279836177825928}]}, {"text": "The texts were articles from two different newspapers and one journal.", "labels": [], "entities": []}, {"text": "Each document was morphologically analyzed and lemmatized) and then indexed and represented as a vector.", "labels": [], "entities": []}, {"text": "We indexed only lemmas of nouns, adjectives, verbs, adverbs and numerals whose document frequency was greater than edges in the graph of the collection.", "labels": [], "entities": []}, {"text": "We had computed a set of concept-formative clusters and then approximated the corresponding membership functions by virtual concepts.", "labels": [], "entities": []}, {"text": "The first thing we have observed was that the quadratic residual error systematically and progresivelly decreases in each GRA iteration.", "labels": [], "entities": [{"text": "quadratic residual error", "start_pos": 46, "end_pos": 70, "type": "METRIC", "confidence": 0.8726392984390259}]}, {"text": "Moreover, the words in virtual concepts are obviously intelligible for humans and strongly suggest the topic.", "labels": [], "entities": []}, {"text": "An example is given in  Another example is cluster #19 focused on \"pension funds\", which was approximated (The signs after the words indicate their positive or negative weights in the concept.) shows the approximation of this cluster by virtual concept.", "labels": [], "entities": []}], "tableCaptions": []}