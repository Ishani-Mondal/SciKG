{"title": [{"text": "Co-training for Predicting Emotions with Spoken Dialogue Data", "labels": [], "entities": [{"text": "Predicting Emotions", "start_pos": 16, "end_pos": 35, "type": "TASK", "confidence": 0.9085860848426819}]}], "abstractContent": [{"text": "Natural Language Processing applications often require large amounts of annotated training data, which are expensive to obtain.", "labels": [], "entities": []}, {"text": "In this paper we investigate the applicability of Co-training to train classifiers that predict emotions in spoken dialogues.", "labels": [], "entities": []}, {"text": "In order to do so, we have first applied the wrapper approach with Forward Selection and Na\u00efve Bayes, to reduce the dimensionality of our feature set.", "labels": [], "entities": []}, {"text": "Our results show that Co-training can be highly effective when a good set of features are chosen.", "labels": [], "entities": []}], "introductionContent": [{"text": "In this paper we investigate the automatic labeling of spoken dialogue data, in order to train a classifier that predicts students' emotional states in a human-human speech-based tutoring corpus.", "labels": [], "entities": [{"text": "automatic labeling of spoken dialogue", "start_pos": 33, "end_pos": 70, "type": "TASK", "confidence": 0.7080509781837463}]}, {"text": "Supervised training of classifiers requires annotated data, which demands costly efforts from human annotators.", "labels": [], "entities": []}, {"text": "One approach to minimize this effort is to use), a semi-supervised algorithm in which two learners are iteratively combining their outputs to increase the training set used to re-train each other and generate more labeled data automatically.", "labels": [], "entities": []}, {"text": "The main focus of this paper is to explore how Cotraining can be applied to annotate spoken dialogues.", "labels": [], "entities": []}, {"text": "A major challenge to address is in reducing the dimensionality of the many features available to the learners.", "labels": [], "entities": []}, {"text": "The motivation for our research arises from the need to annotate a human-human speech corpus for the ITSPOKE (Intelligent Tutoring SPOKEn dialogue System) project ().", "labels": [], "entities": [{"text": "ITSPOKE (Intelligent Tutoring SPOKEn dialogue System) project", "start_pos": 101, "end_pos": 162, "type": "DATASET", "confidence": 0.5562688310941061}]}, {"text": "Ongoing research in ITSPOKE aims to recognize emotional states of students in order to build a spoken dialogue tutoring system that automatically predicts and adapts to the student's emotions.", "labels": [], "entities": []}, {"text": "ITSPOKE uses supervised learning to predict emotions with spoken dialogue data.", "labels": [], "entities": [{"text": "ITSPOKE", "start_pos": 0, "end_pos": 7, "type": "DATASET", "confidence": 0.8787742853164673}]}, {"text": "Although a large set of dialogues have been collected, only 8% of them have been annotated (10 dialogues with a total of 350 utterances), due to the laborious annotation process.", "labels": [], "entities": []}, {"text": "We believe that increasing the size of the training set with more annotated examples will increase the accuracy of the system's predictions.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 103, "end_pos": 111, "type": "METRIC", "confidence": 0.999234676361084}]}, {"text": "Therefore, we are looking fora less labour-intensive approach to data annotation.", "labels": [], "entities": [{"text": "data annotation", "start_pos": 65, "end_pos": 80, "type": "TASK", "confidence": 0.6795369982719421}]}], "datasetContent": [{"text": "The two learners are initialized with only 6 labeled examples in the training set.", "labels": [], "entities": []}, {"text": "The Cotraining system added examples from the 140 \"pseudo-labeled\" examples 1 in the Prediction Set.", "labels": [], "entities": []}, {"text": "The size of the training set increased in each iteration by adding the 2 best examples (those with the highest confidence scores) labeled by the two learners.", "labels": [], "entities": []}, {"text": "The Emotional learner and the NonEmotional learner were set to work with the set of features selected by the wrapper approach to optimize the precision (PPV and NPV) as described in section 4.1.", "labels": [], "entities": [{"text": "precision", "start_pos": 142, "end_pos": 151, "type": "METRIC", "confidence": 0.9978976249694824}]}, {"text": "We have applied Weka's) AdaBoost's version of j48 decision trees (as used in Forbes- ) to the 140 unseen examples of the test set for generating the learning curve shown in. illustrates the learning curve of the accuracy on the test set, taking the union of the set of features selected to label the examples.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 212, "end_pos": 220, "type": "METRIC", "confidence": 0.9919508695602417}]}, {"text": "We used the 3 best features for PPV for the Emotional Learner and the best feature for NPV for the NonEmotional Learner (see Section 4.1).", "labels": [], "entities": [{"text": "NPV", "start_pos": 87, "end_pos": 90, "type": "DATASET", "confidence": 0.920708179473877}]}, {"text": "The x-axis shows the number of training examples added; the y-axis shows the accuracy of the classifier on test instances.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 77, "end_pos": 85, "type": "METRIC", "confidence": 0.9991992115974426}]}, {"text": "We compare the learning curve from Co-training with a baseline of majority class and an upper-bound, in which the classifiers are trained on human-annotated data.", "labels": [], "entities": []}, {"text": "Post-hoc analyses reveal that four incorrectly labeled examples were added to the training set: example numbers 21, 22, 45, and 51 (see the x-axis).", "labels": [], "entities": []}, {"text": "Shortly after the inclusion of example 21, the Co-training learning curve diverges from the upper-bound.", "labels": [], "entities": []}, {"text": "All of them correspond to Non-Emotional examples that were labeled as Emotional by the Emotional learner with the highest confidence.", "labels": [], "entities": []}, {"text": "The Co-training system stopped after adding 58 examples to the initial 6 in the training set because the remaining data cannot be labeled by the learners with high precision.", "labels": [], "entities": [{"text": "precision", "start_pos": 164, "end_pos": 173, "type": "METRIC", "confidence": 0.9891893863677979}]}, {"text": "However, as we can see, the training set generated by the Co-training technique can perform almost as well as the upperbound, even if incorrectly labeled examples are included in the training set..", "labels": [], "entities": []}, {"text": "Learning Curve of Accuracy using best features for Precision of Emotional/Non-Emotional", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 18, "end_pos": 26, "type": "METRIC", "confidence": 0.96702641248703}]}], "tableCaptions": []}