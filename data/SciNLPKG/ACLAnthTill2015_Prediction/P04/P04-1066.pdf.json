{"title": [], "abstractContent": [{"text": "We investigate a number of simple methods for improving the word-alignment accuracy of IBM Model 1.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 75, "end_pos": 83, "type": "METRIC", "confidence": 0.9821577072143555}, {"text": "IBM Model 1", "start_pos": 87, "end_pos": 98, "type": "DATASET", "confidence": 0.8982252677281698}]}, {"text": "We demonstrate reduction in alignment error rate of approximately 30% resulting from (1) giving extra weight to the probability of alignment to the null word, (2) smoothing probability estimates for rare words, and (3) using a simple heuris-tic estimation method to initialize, or replace, EM training of model parameters.", "labels": [], "entities": [{"text": "alignment error rate", "start_pos": 28, "end_pos": 48, "type": "METRIC", "confidence": 0.7427017490069071}]}], "introductionContent": [{"text": "IBM Model 1 () is a wordalignment model that is widely used in working with parallel bilingual corpora.", "labels": [], "entities": [{"text": "IBM Model 1", "start_pos": 0, "end_pos": 11, "type": "DATASET", "confidence": 0.9065565665562948}]}, {"text": "It was originally developed to provide reasonable initial parameter estimates for more complex word-alignment models, but it has subsequently found a host of additional uses.", "labels": [], "entities": []}, {"text": "Among the applications of Model 1 are segmenting long sentences into subsentental units for improved word alignment (, extracting parallel sentences from comparable corpora (), bilingual sentence alignment), aligning syntactictree fragments (, and estimating phrase translation probabilities (.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 101, "end_pos": 115, "type": "TASK", "confidence": 0.7358333319425583}, {"text": "bilingual sentence alignment", "start_pos": 177, "end_pos": 205, "type": "TASK", "confidence": 0.6159748335679373}, {"text": "estimating phrase translation probabilities", "start_pos": 248, "end_pos": 291, "type": "TASK", "confidence": 0.7596156969666481}]}, {"text": "Furthermore, at the 2003 Johns Hopkins summer workshop on statistical machine translation, a large number of features were tested to discover which ones could improve a state-of-the-art translation system, and the only feature that produced a \"truly significant improvement\" was the Model 1 score ().", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 58, "end_pos": 89, "type": "TASK", "confidence": 0.5812816222508749}]}, {"text": "Despite the fact that IBM Model 1 is so widely used, essentially no attention seems to have been paid to whether it is possible to improve on the standard Expectation-Maximization (EM) procedure for estimating its parameters.", "labels": [], "entities": [{"text": "IBM Model 1", "start_pos": 22, "end_pos": 33, "type": "DATASET", "confidence": 0.8491657773653666}]}, {"text": "This maybe due in part to the fact that proved that the log-likelihood objective function for Model 1 is a strictly concave function of the model parameters, so that it has a unique local maximum.", "labels": [], "entities": []}, {"text": "This, in turn, means that EM training will converge to that maximum from any starting point in which none of the initial parameter values is zero.", "labels": [], "entities": []}, {"text": "If one equates optimum parameter estimation with finding the global maximum for the likelihood of the training data, then this result would seem to show no improvement is possible.", "labels": [], "entities": []}, {"text": "However, in virtually every application of statistical techniques in natural-language processing, maximizing the likelihood of the training data causes overfitting, resulting in lower task performance than some other estimates for the model parameters.", "labels": [], "entities": []}, {"text": "This is implicitly recognized in the widespread adoption of early stopping in estimating the parameters of Model 1.", "labels": [], "entities": []}, {"text": "stopped after only one iteration of EM in using Model 1 to initialize their stop after five iterations in using Model 1 to initialize the HMM word-alignment model.", "labels": [], "entities": []}, {"text": "Both of these are far short of convergence to the maximum likelihood estimates for the model parameters.", "labels": [], "entities": []}, {"text": "We have identified at least two ways in which the standard EM training method for Model 1 leads to suboptimal performance in terms of wordalignment accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 148, "end_pos": 156, "type": "METRIC", "confidence": 0.8615301847457886}]}, {"text": "In this paper we show that by addressing these issues, substantial improvements in word-alignment accuracy can be achieved.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 98, "end_pos": 106, "type": "METRIC", "confidence": 0.9580485820770264}]}], "datasetContent": [{"text": "We trained and evaluated our various modifications to Model 1 on data from the bilingual word alignment workshop held at HLT-NAACL 2003.", "labels": [], "entities": [{"text": "bilingual word alignment workshop held at HLT-NAACL 2003", "start_pos": 79, "end_pos": 135, "type": "TASK", "confidence": 0.694483321160078}]}, {"text": "We used a subset of the Canadian Hansards bilingual corpus supplied for the workshop, comprising 500,000 English-French sentences pairs, including 37 sentence pairs designated as \"trial\" data, and 447 sentence pairs designated as test data.", "labels": [], "entities": [{"text": "Canadian Hansards bilingual corpus", "start_pos": 24, "end_pos": 58, "type": "DATASET", "confidence": 0.8665570020675659}]}, {"text": "The trial and test data had been manually aligned at the word level, noting particular pairs of words either as \"sure\" or \"possible\" alignments, as described by.", "labels": [], "entities": []}, {"text": "To limit the number of translation probabilities that we had to store, we first computed LLR association scores for all bilingual word pairs with a positive association (p(t, s) > p(t)\u00b7p(s)), and discarded from further consideration those with an LLR score of less that 0.9, which was chosen to be just low enough to retain all the \"sure\" word alignments in the trial data.", "labels": [], "entities": []}, {"text": "This resulted in 13,285,942 possible word-to-word translation pairs (plus 66,406 possible null-word-to-word pairs).", "labels": [], "entities": []}, {"text": "For most models, the word translation parameters are set automatically by EM.", "labels": [], "entities": [{"text": "word translation", "start_pos": 21, "end_pos": 37, "type": "TASK", "confidence": 0.7343213260173798}]}, {"text": "We trained each variation of each model for 20 iterations, which was enough in almost all cases to discern a clear minimum error on the 37 sentence pairs of trial data, and we chose as the preferred iteration the one with the lowest alignment error rate on the trial data.", "labels": [], "entities": []}, {"text": "The other parameters of the various versions of Model 1 described in Sections 4-6 were optimized with respect to alignment error rate on the trial data using simple hill climbing.", "labels": [], "entities": [{"text": "alignment error rate", "start_pos": 113, "end_pos": 133, "type": "METRIC", "confidence": 0.8109398086865743}]}, {"text": "All the results we report for the 447 sentence pairs of test data use the parameter values set to their optimal values for the trial data.", "labels": [], "entities": []}, {"text": "We report results for four principal versions of Model 1, trained using English as the source language and French as the target language: \u2022 The standard model is initialized using uniform distributions, and trained without smoothing using EM, fora number of iterations optimized on the trial data.", "labels": [], "entities": []}, {"text": "\u2022 The smoothed model is like the standard model, but with optimized values of the nullword weight and add-n parameter.", "labels": [], "entities": []}, {"text": "\u2022 The heuristic model simply uses the initial heuristic estimates of the translation parameter values, with an optimized LLR exponent and null-word weight, but no EM re-estimation.", "labels": [], "entities": []}, {"text": "\u2022 The combined model initializes the translation parameter values with the heuristic estimates, using the LLR exponent and null-word weight from the optimal heuristic model, and applies EM using optimized values of the null-word weight and add-n parameters.", "labels": [], "entities": [{"text": "EM", "start_pos": 186, "end_pos": 188, "type": "METRIC", "confidence": 0.9703798890113831}]}, {"text": "The null-word weight used during EM is optimized separately from the null-word weight used in the initial heuristic parameter estimates.", "labels": [], "entities": [{"text": "EM", "start_pos": 33, "end_pos": 35, "type": "TASK", "confidence": 0.9130420684814453}]}, {"text": "We also performed ablation experiments in which we ommitted each applicable modification in turn from each principal version of Model 1, to observe the effect on alignment error.", "labels": [], "entities": [{"text": "alignment error", "start_pos": 162, "end_pos": 177, "type": "METRIC", "confidence": 0.7487377226352692}]}, {"text": "All non-EM-trained parameters were re-optimized on the trial data for each version of Model 1 tested, with the exception  that the value of the LLR exponent and initial nullword weight in the combined model were carried over from the heuristic model.", "labels": [], "entities": []}], "tableCaptions": []}