{"title": [{"text": "Classifying Semantic Relations in Bioscience Texts", "labels": [], "entities": [{"text": "Classifying Semantic Relations", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.8654658993085226}]}], "abstractContent": [{"text": "A crucial step toward the goal of automatic extraction of propositional information from natural language text is the identification of semantic relations between constituents in sentences.", "labels": [], "entities": [{"text": "automatic extraction of propositional information from natural language text", "start_pos": 34, "end_pos": 110, "type": "TASK", "confidence": 0.8708928889698453}, {"text": "identification of semantic relations between constituents in sentences", "start_pos": 118, "end_pos": 188, "type": "TASK", "confidence": 0.7537062615156174}]}, {"text": "We examine the problem of distinguishing among seven relation types that can occur between the entities \"treatment\" and \"disease\" in bioscience text, and the problem of identifying such entities.", "labels": [], "entities": []}, {"text": "We compare five generative graphical models and a neural network, using lexical, syntactic, and semantic features, finding that the latter help achieve high classification accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 172, "end_pos": 180, "type": "METRIC", "confidence": 0.9290688037872314}]}], "introductionContent": [{"text": "The biosciences literature is rich, complex and continually growing.", "labels": [], "entities": []}, {"text": "The National Library of Medicine's MEDLINE database 1 contains bibliographic citations and abstracts from more than 4,600 biomedical journals, and an estimated half a million new articles are added every year.", "labels": [], "entities": [{"text": "National Library of Medicine's MEDLINE database 1", "start_pos": 4, "end_pos": 53, "type": "DATASET", "confidence": 0.8615526556968689}]}, {"text": "Much of the important, late-breaking bioscience information is found only in textual form, and so methods are needed to automatically extract semantic entities and the relations between them from this text.", "labels": [], "entities": []}, {"text": "For example, in the following sentences, hepatitis and its variants, which are DISEASES, are found in different semantic relationships with various TREATMENTs: 1 http://www.nlm.nih.gov/pubs/factsheets/medline.html (1) Effect of interferon on hepatitis B (2) A two-dose combined hepatitis A and B vaccine would facilitate immunization programs (3) These results suggest that con A-induced hepatitis was ameliorated by pretreatment with TJ-135.", "labels": [], "entities": [{"text": "TREATMENTs", "start_pos": 148, "end_pos": 158, "type": "METRIC", "confidence": 0.9742686748504639}]}, {"text": "In there is an unspecified effect of the treatment interferon on hepatitis B.", "labels": [], "entities": []}, {"text": "In (2) the vaccine prevents hepatitis A and B while in (3) hepatitis is cured by the treatment TJ-135.", "labels": [], "entities": [{"text": "TJ-135", "start_pos": 95, "end_pos": 101, "type": "DATASET", "confidence": 0.7645848393440247}]}, {"text": "We refer to this problem as Relation Classification.", "labels": [], "entities": [{"text": "Relation Classification", "start_pos": 28, "end_pos": 51, "type": "TASK", "confidence": 0.9531004130840302}]}, {"text": "A related task is Role Extraction (also called, in the literature, \"information extraction\" or \"named entity recognition\"), defined as: given a sentence such as \"The fluoroquinolones for urinary tract infections: a review\", extract all and only the strings of text that correspond to the roles TREATMENT (fluoroquinolones) and DISEASE (urinary tract infections).", "labels": [], "entities": [{"text": "Role Extraction", "start_pos": 18, "end_pos": 33, "type": "TASK", "confidence": 0.8164592981338501}, {"text": "information extraction\" or \"named entity recognition", "start_pos": 68, "end_pos": 120, "type": "TASK", "confidence": 0.669508058577776}, {"text": "TREATMENT", "start_pos": 294, "end_pos": 303, "type": "METRIC", "confidence": 0.9873613119125366}]}, {"text": "To make inferences about the facts in the text we need a system that accomplishes both these tasks: the extraction of the semantic roles and the recognition of the relationship that holds between them.", "labels": [], "entities": []}, {"text": "In this paper we compare five generative graphical models and a discriminative model (a multilayer neural network) on these tasks.", "labels": [], "entities": []}, {"text": "Recognizing subtle differences among relations is a difficult task; nevertheless the results achieved by our models are quite promising: when the roles are not given, the neural network achieves 79.6% accuracy and the best graphical model achieves 74.9%.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 201, "end_pos": 209, "type": "METRIC", "confidence": 0.9981873631477356}]}, {"text": "When the roles are given, the neural net reaches 96.9% accuracy while the best graphical model gets 91.6% accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 55, "end_pos": 63, "type": "METRIC", "confidence": 0.9971856474876404}, {"text": "accuracy", "start_pos": 106, "end_pos": 114, "type": "METRIC", "confidence": 0.9972858428955078}]}, {"text": "Part of the reason for the", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 2: F-measures for the models of", "labels": [], "entities": [{"text": "F-measures", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.9938235282897949}]}, {"text": " Table 4: Confusion matrix for the dynamic model D2 for \"rel + irrel.\", \"only features\". In column \"Num.  Sent.\" the numbers of sentences used for training and testing and in the last column the classification  accuracies for each relation. The total accuracy for this case is 74.9%.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 251, "end_pos": 259, "type": "METRIC", "confidence": 0.9996402263641357}]}]}