{"title": [{"text": "Data-Driven Strategies for an Automated Dialogue System", "labels": [], "entities": []}], "abstractContent": [{"text": "We present a prototype natural-language problem-solving application fora financial services call center, developed as part of the Amiti\u00e9s multilingual human-computer dialogue project.", "labels": [], "entities": [{"text": "Amiti\u00e9s multilingual human-computer dialogue", "start_pos": 130, "end_pos": 174, "type": "TASK", "confidence": 0.8157588541507721}]}, {"text": "Our automated dialogue system, based on empirical evidence from real call-center conversations, features a data-driven approach that allows for mixed system/customer initiative and spontaneous conversation.", "labels": [], "entities": []}, {"text": "Preliminary evaluation results indicate efficient dialogues and high user satisfaction, with performance comparable to or better than that of current conversational travel information systems.", "labels": [], "entities": []}], "introductionContent": [{"text": "Recently there has been a great deal of interest in improving natural-language human-computer conversation.", "labels": [], "entities": []}, {"text": "Automatic speech recognition continues to improve, and dialogue management techniques have progressed beyond menu-driven prompts and restricted customer responses.", "labels": [], "entities": [{"text": "Automatic speech recognition", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.6347955167293549}, {"text": "dialogue management", "start_pos": 55, "end_pos": 74, "type": "TASK", "confidence": 0.8308274745941162}]}, {"text": "Yet few researchers have made use of a large body of human-human telephone calls, on which to form the basis of a data-driven automated system.", "labels": [], "entities": []}, {"text": "The Amiti\u00e9s project seeks to develop novel technologies for building empirically induced dialogue processors to support multilingual human-computer interaction, and to integrate these technologies into systems for accessing information and services (http://www.dcs.shef.ac. uk/nlp/amities).", "labels": [], "entities": [{"text": "Amiti\u00e9s", "start_pos": 4, "end_pos": 11, "type": "TASK", "confidence": 0.9647925496101379}]}, {"text": "Sponsored jointly by the European Commission and the US Defense Advanced Research Projects Agency, the Amiti\u00e9s Consortium includes partners in both the EU and the US, as well as financial call centers in the UK and France.", "labels": [], "entities": [{"text": "Amiti\u00e9s Consortium", "start_pos": 103, "end_pos": 121, "type": "TASK", "confidence": 0.8256665170192719}]}, {"text": "A large corpus of recorded, transcribed telephone conversations between real agents and customers gives us a unique opportunity to analyze and incorporate features of human-human dialogues into our automated system.", "labels": [], "entities": []}, {"text": "(Generic names and numbers were substituted for all personal details in the transcriptions.)", "labels": [], "entities": []}, {"text": "This corpus spans two different application areas: software support and (a much smaller size) customer banking.", "labels": [], "entities": []}, {"text": "The banking corpus of several hundred calls has been collected first and it forms the basis of our initial multilingual triaging application, implemented for English,; as well as our prototype automatic financial services system, presented in this paper, which completes a variety of tasks in English.", "labels": [], "entities": []}, {"text": "The much larger software support corpus (10,000 calls in English and French) is still being collected and processed and will be used to develop the next Amiti\u00e9s prototype.", "labels": [], "entities": [{"text": "Amiti\u00e9s", "start_pos": 153, "end_pos": 160, "type": "TASK", "confidence": 0.9680961966514587}]}, {"text": "We observe that for interactions with structured data -whether these data consist of flight information, spare parts, or customer account information -domain knowledge need not be built ahead of time.", "labels": [], "entities": []}, {"text": "Rather, methods for handling the data can arise from the way the data are organized.", "labels": [], "entities": []}, {"text": "Once we know the basic data structures, the transactions, and the protocol to be followed (e.g., establish caller's identity before exchanging sensitive information); we need only build dialogue models for handling various conversational situations, in order to implement a dialogue system.", "labels": [], "entities": []}, {"text": "For our corpus, we have used a modified DAMSL tag set to capture the functional layer of the dialogues, and a frame-based semantic scheme to record the semantic layer ().", "labels": [], "entities": []}, {"text": "The \"frames\" or transactions in our domain are common customer-service tasks: VerifyId, ChangeAddress, InquireBalance, Lost/StolenCard and Make Payment.", "labels": [], "entities": []}, {"text": "(In this context \"task\" and \"transaction\" are synonymous.)", "labels": [], "entities": []}, {"text": "Each frame is associated with attributes or slots that must be filled with values in no particular order during the course of the dialogue; for example, account number, name, payment amount, etc.", "labels": [], "entities": []}], "datasetContent": [{"text": "Ten native speakers of English, 6 female and 4 male, were asked to participate in a preliminary inlab system evaluation (half in the UK and half in the US).", "labels": [], "entities": []}, {"text": "The Amiti\u00e9s system developers were not among these volunteers.", "labels": [], "entities": [{"text": "Amiti\u00e9s", "start_pos": 4, "end_pos": 11, "type": "TASK", "confidence": 0.8792023062705994}]}, {"text": "Each made 9 phone calls to the system from behind a closed door, according to scenarios designed to test various customer identities as well as single or multiple tasks.", "labels": [], "entities": []}, {"text": "After each call, participants filled out a questionnaire to register their degree of satisfaction with aspects of the interaction.", "labels": [], "entities": []}, {"text": "Overall call success was 70%, with 98% successful completions for the VerifyId and 96% for the CheckBalance subtasks ().", "labels": [], "entities": [{"text": "completions", "start_pos": 50, "end_pos": 61, "type": "METRIC", "confidence": 0.9527314305305481}, {"text": "VerifyId", "start_pos": 70, "end_pos": 78, "type": "DATASET", "confidence": 0.918628454208374}, {"text": "CheckBalance subtasks", "start_pos": 95, "end_pos": 116, "type": "DATASET", "confidence": 0.933824360370636}]}, {"text": "\"Failures\" were not system crashes but simulated transfers to a human agent.", "labels": [], "entities": []}, {"text": "There were 5 user terminations.", "labels": [], "entities": []}, {"text": "Average word error rates were 17% for calls that were successfully completed, and 22% for failed calls.", "labels": [], "entities": [{"text": "word error rates", "start_pos": 8, "end_pos": 24, "type": "METRIC", "confidence": 0.7173635959625244}]}, {"text": "Word error rate by user ranged from 11% to 26%.", "labels": [], "entities": [{"text": "Word error rate", "start_pos": 0, "end_pos": 15, "type": "METRIC", "confidence": 0.8202424645423889}]}, {"text": "Call duration was found to reflect the complexity of each scenario, where complexity is defined as the number of \"concepts\" needed to complete each task.", "labels": [], "entities": []}, {"text": "The following items are judged to be concepts: task identification; values such as first name, last name, house number, street and phone number; and positive or negative responses such as whether anew card is desired.", "labels": [], "entities": [{"text": "task identification", "start_pos": 47, "end_pos": 66, "type": "TASK", "confidence": 0.6829143762588501}]}, {"text": "illustrate the relationship between length of call and task complexity.", "labels": [], "entities": []}, {"text": "It should be noted that customer verification, a task performed in every dialogue, requires a minimum of 3 personal details to be verified against a database record, but may require more in the case of recognition errors.", "labels": [], "entities": [{"text": "customer verification", "start_pos": 24, "end_pos": 45, "type": "TASK", "confidence": 0.7709431946277618}]}, {"text": "The overall average number of turns per dialogue was 18.28.", "labels": [], "entities": []}, {"text": "The user spoke an average of 6.89 words per turn and the system 11.42.", "labels": [], "entities": []}, {"text": "User satisfaction for each call was assessed byway of a questionnaire containing five statements.", "labels": [], "entities": [{"text": "satisfaction", "start_pos": 5, "end_pos": 17, "type": "METRIC", "confidence": 0.9177437424659729}]}, {"text": "These covered the clarity of the instructions, ease of doing the task, how well the system understands the caller, how well the system works, and the caller's enjoyment of the system.", "labels": [], "entities": [{"text": "clarity", "start_pos": 18, "end_pos": 25, "type": "METRIC", "confidence": 0.9896643757820129}]}, {"text": "Participants rated each on a five-point Likert scale.", "labels": [], "entities": []}, {"text": "Summed results showed an average score of 20.45 overall users (range 5-25; higher = stronger agreement).", "labels": [], "entities": [{"text": "agreement", "start_pos": 93, "end_pos": 102, "type": "METRIC", "confidence": 0.9681255221366882}]}, {"text": "Although user satisfaction was high, we were more interested in identifying the major problems for the callers.", "labels": [], "entities": []}, {"text": "Users were often frustrated by recognition failures and/or unsuccessful attempts to capture values such as anew street address, county, or phone number.", "labels": [], "entities": []}, {"text": "Sometimes the system failed to determine that the user was finished.", "labels": [], "entities": []}, {"text": "Because the system is designed to be nonrestrictive in accepting users' input, misidentifications were common.", "labels": [], "entities": []}, {"text": "One user spoke for many by saying, \"There were times when the system would ask me to repeat information I had not yet given to it.\"", "labels": [], "entities": []}, {"text": "We plan to revise our strategy so that we area little more cautious in our reprompts.", "labels": [], "entities": []}, {"text": "Occasionally, the system misidentified the user's desired task and had difficulty backing off gracefully and starting the correct task.", "labels": [], "entities": []}, {"text": "We are working on improving our recovery strategies for these cases.", "labels": [], "entities": []}, {"text": "The following transcription of an interaction with our system illustrates the efficiency made possible when the data supplied by the caller drives the conversation: AMITI\u00c9S USER: bye", "labels": [], "entities": [{"text": "AMITI\u00c9S", "start_pos": 165, "end_pos": 172, "type": "METRIC", "confidence": 0.9854604601860046}, {"text": "USER", "start_pos": 173, "end_pos": 177, "type": "METRIC", "confidence": 0.8495503664016724}]}], "tableCaptions": []}