{"title": [{"text": "Relieving The Data Acquisition Bottleneck In Word Sense Disambiguation", "labels": [], "entities": [{"text": "Relieving The Data Acquisition Bottleneck In Word Sense Disambiguation", "start_pos": 0, "end_pos": 70, "type": "TASK", "confidence": 0.7208591865168678}]}], "abstractContent": [{"text": "Supervised learning methods for WSD yield better performance than unsupervised methods.", "labels": [], "entities": [{"text": "WSD", "start_pos": 32, "end_pos": 35, "type": "TASK", "confidence": 0.9722172021865845}]}, {"text": "Yet the availability of clean training data for the former is still a severe challenge.", "labels": [], "entities": []}, {"text": "In this paper, we present an unsupervised bootstrapping approach for WSD which exploits huge amounts of automatically generated noisy data for training within a supervised learning framework.", "labels": [], "entities": [{"text": "WSD", "start_pos": 69, "end_pos": 72, "type": "TASK", "confidence": 0.9651066064834595}]}, {"text": "The method is evaluated using the 29 nouns in the English Lexical Sample task of SENSEVAL2.", "labels": [], "entities": []}, {"text": "Our algorithm does as well as supervised algorithms on 31% of this test set, which is an improvement of 11% (absolute) over state-of-the-art bootstrapping WSD algorithms.", "labels": [], "entities": []}, {"text": "We identify seven different factors that impact the performance of our system.", "labels": [], "entities": []}], "introductionContent": [{"text": "Supervised Word Sense Disambiguation (WSD) systems perform better than unsupervised systems.", "labels": [], "entities": [{"text": "Word Sense Disambiguation (WSD)", "start_pos": 11, "end_pos": 42, "type": "TASK", "confidence": 0.7300483683745066}]}, {"text": "But lack of training data is a severe bottleneck for supervised systems due to the extensive labor and cost involved.", "labels": [], "entities": []}, {"text": "Indeed, one of the main goals of the SENSEVAL exercises is to create large amounts of sense-annotated data for supervised systems).", "labels": [], "entities": [{"text": "SENSEVAL", "start_pos": 37, "end_pos": 45, "type": "TASK", "confidence": 0.9377822875976562}]}, {"text": "The problem is even more challenging for languages which possess scarce computer readable knowledge resources.", "labels": [], "entities": []}, {"text": "In this paper, we investigate the role of large amounts of noisily sense annotated data obtained using an unsupervised approach in relieving the data acquisition bottleneck for the WSD task.", "labels": [], "entities": [{"text": "WSD task", "start_pos": 181, "end_pos": 189, "type": "TASK", "confidence": 0.9429904520511627}]}, {"text": "We bootstrap a supervised learning WSD system with an unsupervised seed set.", "labels": [], "entities": [{"text": "WSD", "start_pos": 35, "end_pos": 38, "type": "TASK", "confidence": 0.9017941951751709}]}, {"text": "We use the sense annotated data produced by Diab's unsupervised system SALAAM.", "labels": [], "entities": []}, {"text": "SALAAM is a WSD system that exploits parallel corpora for sense disambiguation of words in running text.", "labels": [], "entities": [{"text": "WSD", "start_pos": 12, "end_pos": 15, "type": "TASK", "confidence": 0.9449451565742493}, {"text": "sense disambiguation of words in running text", "start_pos": 58, "end_pos": 103, "type": "TASK", "confidence": 0.8579894474574498}]}, {"text": "To date, SALAAM yields the best scores for an unsupervised system on the SENSEVAL2 English All-Words task.", "labels": [], "entities": [{"text": "SALAAM", "start_pos": 9, "end_pos": 15, "type": "METRIC", "confidence": 0.9937312006950378}, {"text": "SENSEVAL2 English All-Words task", "start_pos": 73, "end_pos": 105, "type": "TASK", "confidence": 0.6645955294370651}]}, {"text": "SALAAM is an appealing approach as it provides automatically sense annotated data in two languages simultaneously, thereby providing a multilingual framework for solving the data acquisition problem.", "labels": [], "entities": [{"text": "data acquisition", "start_pos": 174, "end_pos": 190, "type": "TASK", "confidence": 0.7583977580070496}]}, {"text": "For instance, SALAAM has been used to bootstrap the WSD process for Arabic as illustrated in.", "labels": [], "entities": [{"text": "SALAAM", "start_pos": 14, "end_pos": 20, "type": "METRIC", "confidence": 0.8548771142959595}]}, {"text": "Ina supervised learning setting, WSD is cast as a classification problem, where a predefined set of sense tags constitutes the classes.", "labels": [], "entities": [{"text": "WSD", "start_pos": 33, "end_pos": 36, "type": "TASK", "confidence": 0.9509978890419006}]}, {"text": "The ambiguous words in text are assigned one or more of these classes by a machine learning algorithm based on some extracted features.", "labels": [], "entities": []}, {"text": "This algorithm learns parameters from explicit associations between the class and the features, or combination of features, that characterize it.", "labels": [], "entities": []}, {"text": "Therefore, such systems are very sensitive to the training data, and those data are, generally, assumed to be as clean as possible.", "labels": [], "entities": []}, {"text": "In this paper, we question that assumption.", "labels": [], "entities": []}, {"text": "Can large amounts of noisily annotated data used in training be useful within such a learning paradigm for WSD?", "labels": [], "entities": [{"text": "WSD", "start_pos": 107, "end_pos": 110, "type": "TASK", "confidence": 0.9839801788330078}]}, {"text": "What is the nature of the quality-quantity trade-off in addressing this problem?", "labels": [], "entities": []}], "datasetContent": [{"text": "In this evaluation, system trained with SALAAM-tagged data and\u00a8\u00a1 is always trained with SV2LS TR as part of the training set in order to guarantee genre congruence between the training and test sets.The scores are calculated using scorer2.", "labels": [], "entities": [{"text": "SALAAM-tagged data", "start_pos": 40, "end_pos": 58, "type": "DATASET", "confidence": 0.7098619639873505}, {"text": "\u00a8\u00a1", "start_pos": 62, "end_pos": 64, "type": "METRIC", "confidence": 0.9668756127357483}, {"text": "TR", "start_pos": 94, "end_pos": 96, "type": "METRIC", "confidence": 0.4779774844646454}]}, {"text": "The average precision score overall the items for\u00a8\u00a1 is 65.3% at 100% Coverage.", "labels": [], "entities": [{"text": "precision score", "start_pos": 12, "end_pos": 27, "type": "METRIC", "confidence": 0.9756665229797363}, {"text": "\u00a8\u00a1", "start_pos": 49, "end_pos": 51, "type": "METRIC", "confidence": 0.9838314056396484}]}], "tableCaptions": [{"text": " Table 2: The number of senses per item, in  column #Ss,", "labels": [], "entities": []}]}