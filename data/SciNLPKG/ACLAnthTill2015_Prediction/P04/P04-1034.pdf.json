{"title": [{"text": "The Sentimental Factor: Improving Review Classification via Human-Provided Information", "labels": [], "entities": [{"text": "Sentimental", "start_pos": 4, "end_pos": 15, "type": "TASK", "confidence": 0.9830249547958374}, {"text": "Improving Review Classification", "start_pos": 24, "end_pos": 55, "type": "TASK", "confidence": 0.8099118868509928}]}], "abstractContent": [{"text": "Sentiment classification is the task of labeling a review document according to the polarity of its prevailing opinion (favorable or unfavorable).", "labels": [], "entities": [{"text": "Sentiment classification", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.9677311778068542}]}, {"text": "In approaching this problem, a model builder often has three sources of information available: a small collection of labeled documents, a large collection of unlabeled documents, and human understanding of language.", "labels": [], "entities": []}, {"text": "Ideally, a learning method will utilize all three sources.", "labels": [], "entities": []}, {"text": "To accomplish this goal, we generalize an existing procedure that uses the latter two.", "labels": [], "entities": []}, {"text": "We extend this procedure by re-interpreting it as a Naive Bayes model for document sentiment.", "labels": [], "entities": [{"text": "document sentiment", "start_pos": 74, "end_pos": 92, "type": "TASK", "confidence": 0.7273770868778229}]}, {"text": "Viewed as such, it can also be seen to extract a pair of derived features that are linearly combined to predict sentiment.", "labels": [], "entities": []}, {"text": "This perspective allows us to improve upon previous methods, primarily through two strategies: incorporating additional derived features into the model and, where possible, using labeled data to estimate their relative influence.", "labels": [], "entities": []}], "introductionContent": [{"text": "Text documents are available in ever-increasing numbers, making automated techniques for information extraction increasingly useful.", "labels": [], "entities": [{"text": "information extraction", "start_pos": 89, "end_pos": 111, "type": "TASK", "confidence": 0.8450627028942108}]}, {"text": "Traditionally, most research effort has been directed towards \"objective\" information, such as classification according to topic; however, interest is growing in producing information about the opinions that a document contains; for instance,.", "labels": [], "entities": []}, {"text": "In March, 2004, the American Association for Artificial Intelligence held a symposium in this area, entitled \"Exploring Affect and Attitude in Text.\"", "labels": [], "entities": [{"text": "Exploring Affect and Attitude in Text", "start_pos": 110, "end_pos": 147, "type": "TASK", "confidence": 0.8054810961087545}]}, {"text": "One task in opinion extraction is to label a review document d according to its prevailing sentiment s \u2208 {\u22121, 1} (unfavorable or favorable).", "labels": [], "entities": [{"text": "opinion extraction", "start_pos": 12, "end_pos": 30, "type": "TASK", "confidence": 0.7775267064571381}]}, {"text": "Several previous papers have addressed this problem by building models that rely exclusively upon labeled documents, e.g.,.", "labels": [], "entities": []}, {"text": "By learning models from labeled data, one can apply familiar, powerful techniques directly; however, in practice it maybe difficult to obtain enough labeled reviews to learn model parameters accurately.", "labels": [], "entities": []}, {"text": "A contrasting approach) relies only upon documents whose labels are unknown.", "labels": [], "entities": []}, {"text": "This makes it possible to use a large underlying corpusin this case, the entire Internet as seen through the AltaVista search engine.", "labels": [], "entities": []}, {"text": "As a result, estimates for model parameters are subject to a relatively small amount of random variation.", "labels": [], "entities": []}, {"text": "The corresponding drawback to such an approach is that its predictions are not validated on actual documents.", "labels": [], "entities": []}, {"text": "In machine learning, it has often been effective to use labeled and unlabeled examples in tandem, e.g..", "labels": [], "entities": []}, {"text": "Turney's model introduces the further consideration of incorporating human-provided knowledge about language.", "labels": [], "entities": []}, {"text": "In this paper we build models that utilize all three sources: labeled documents, unlabeled documents, and human-provided information.", "labels": [], "entities": []}, {"text": "The basic concept behind Turney's model is quite simple.", "labels": [], "entities": []}, {"text": "The \"sentiment orientation\") of a pair of words is taken to be known.", "labels": [], "entities": []}, {"text": "These words serve as \"anchors\" for positive and negative sentiment.", "labels": [], "entities": []}, {"text": "Words that co-occur more frequently with one anchor than the other are themselves taken to be predictive of sentiment.", "labels": [], "entities": []}, {"text": "As a result, information about a pair of words is generalized to many words, and then to documents.", "labels": [], "entities": []}, {"text": "In the following section, we relate this model with Naive Bayes classification, showing that Turney's classifier is a \"pseudo-supervised\" approach: it effectively generates anew corpus of labeled documents, upon which it fits a Naive Bayes classifier.", "labels": [], "entities": [{"text": "Naive Bayes classification", "start_pos": 52, "end_pos": 78, "type": "TASK", "confidence": 0.7206602891286215}]}, {"text": "This insight allows the procedure to be represented as a probability model that is linear on the logistic scale, which in turn suggests generalizations that are developed in subsequent sections.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": []}