{"title": [{"text": "A TAG-based noisy channel model of speech repairs", "labels": [], "entities": []}], "abstractContent": [{"text": "This paper describes a noisy channel model of speech repairs, which can identify and correct repairs in speech transcripts.", "labels": [], "entities": [{"text": "speech repairs", "start_pos": 46, "end_pos": 60, "type": "TASK", "confidence": 0.7449436187744141}]}, {"text": "A syntactic parser is used as the source model, and a novel type of TAG-based transducer is the channel model.", "labels": [], "entities": []}, {"text": "The use of TAG is motivated by the intuition that the reparandum is a \"rough copy\" of the repair.", "labels": [], "entities": [{"text": "TAG", "start_pos": 11, "end_pos": 14, "type": "METRIC", "confidence": 0.571291983127594}]}, {"text": "The model is trained and tested on the Switchboard disfluency-annotated corpus.", "labels": [], "entities": [{"text": "Switchboard disfluency-annotated corpus", "start_pos": 39, "end_pos": 78, "type": "DATASET", "confidence": 0.8374907771746317}]}], "introductionContent": [{"text": "Most spontaneous speech contains disfluencies such as partial words, filled pauses (e.g., \"uh\", \"um\", \"huh\"), explicit editing terms (e.g., \"I mean\"), parenthetical asides and repairs.", "labels": [], "entities": []}, {"text": "Of these repairs pose particularly difficult problems for parsing and related NLP tasks.", "labels": [], "entities": [{"text": "parsing", "start_pos": 58, "end_pos": 65, "type": "TASK", "confidence": 0.9828333854675293}]}, {"text": "This paper presents an explicit generative model of speech repairs and shows how it can eliminate this kind of disfluency.", "labels": [], "entities": [{"text": "speech repairs", "start_pos": 52, "end_pos": 66, "type": "TASK", "confidence": 0.737933799624443}]}, {"text": "While speech repairs have been studied by psycholinguists for sometime, as far as we know this is the first time a probabilistic model of speech repairs based on a model of syntactic structure has been described in the literature.", "labels": [], "entities": [{"text": "speech repairs", "start_pos": 6, "end_pos": 20, "type": "TASK", "confidence": 0.7138781547546387}, {"text": "speech repairs", "start_pos": 138, "end_pos": 152, "type": "TASK", "confidence": 0.7441195249557495}]}, {"text": "Probabilistic models have the advantage over other kinds of models that they can in principle be integrated with other probabilistic models to produce a combined model that uses all available evidence to select the globally optimal analysis.", "labels": [], "entities": []}, {"text": "studied the location and distribution of repairs in the Switchboard corpus, but did not propose an actual model of repairs.", "labels": [], "entities": [{"text": "Switchboard corpus", "start_pos": 56, "end_pos": 74, "type": "DATASET", "confidence": 0.916353166103363}]}, {"text": "Heeman and Allen (1999) describe a noisy channel model of speech repairs, but leave \"extending the model to incorporate higher level syntactic . .", "labels": [], "entities": [{"text": "speech repairs", "start_pos": 58, "end_pos": 72, "type": "TASK", "confidence": 0.7077584862709045}]}, {"text": "processing\" to future work.", "labels": [], "entities": []}, {"text": "The previous work most closely related to the current work is, who used a boosted decision stub classifier to classify words as edited or not on a word byword basis, but do not identify or assign a probability to a repair as a whole.", "labels": [], "entities": []}, {"text": "There are two innovations in this paper.", "labels": [], "entities": []}, {"text": "First, we demonstrate that using a syntactic parser-based language model instead of bi/trigram language models significantly improves the accuracy of repair detection and correction.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 138, "end_pos": 146, "type": "METRIC", "confidence": 0.9991329312324524}, {"text": "repair detection and correction", "start_pos": 150, "end_pos": 181, "type": "TASK", "confidence": 0.8272847980260849}]}, {"text": "Second, we show how Tree Adjoining Grammars (TAGs) can be used to provide a precise formal description and probabilistic model of the crossed dependencies occurring in speech repairs.", "labels": [], "entities": []}, {"text": "The rest of this paper is structured as follows.", "labels": [], "entities": []}, {"text": "The next section describes the noisy channel model of speech repairs and the section after that explains how it can be applied to detect and repair speech repairs.", "labels": [], "entities": [{"text": "speech repairs", "start_pos": 54, "end_pos": 68, "type": "TASK", "confidence": 0.7664408087730408}, {"text": "detect and repair speech repairs", "start_pos": 130, "end_pos": 162, "type": "TASK", "confidence": 0.6432713627815246}]}, {"text": "Section 4 evaluates this model on the Penn 3 disfluency-tagged Switchboard corpus, and section 5 concludes and discusses future work.", "labels": [], "entities": [{"text": "Penn 3 disfluency-tagged Switchboard corpus", "start_pos": 38, "end_pos": 81, "type": "DATASET", "confidence": 0.9362793207168579}]}], "datasetContent": [{"text": "This section describes how we evaluate our noisy model.", "labels": [], "entities": []}, {"text": "As mentioned earlier, following our test data consisted of all Penn III Switchboard tree-bank sw4[0-1]*.mrg files.", "labels": [], "entities": [{"text": "Penn III Switchboard tree-bank sw4[0-1]*.mrg files", "start_pos": 63, "end_pos": 113, "type": "DATASET", "confidence": 0.9449957013130188}]}, {"text": "However, our test data differs from theirs in that in this test we deleted all partial words and punctuation from the data, as this results in a more realistic test situation.", "labels": [], "entities": []}, {"text": "Since the immediate goal of this work is to produce a program that identifies the words of a sentence that belong to the reparandum of a repair construction (to a first approximation these words can be ignored in later processing), our evaluation focuses on the model's performance in recovering the words in a reparandum.", "labels": [], "entities": []}, {"text": "That is, the model is used to classify each word in the sentence as belonging to a reparandum or not, and all other additional structure produced by the model is ignored.", "labels": [], "entities": []}, {"text": "We measure model performance using standard precision p, recall rand f-score f , measures.", "labels": [], "entities": [{"text": "recall rand f-score f", "start_pos": 57, "end_pos": 78, "type": "METRIC", "confidence": 0.9158941507339478}]}, {"text": "If n c is the number of reparandum words the model correctly classified, n t is the number of true reparandum words given by the manual annotations and n m is the number of words the model predicts to be reparandum words, then the precision is n c /n m , recall is n c /n t , and f is 2pr/(p + r).", "labels": [], "entities": [{"text": "precision", "start_pos": 231, "end_pos": 240, "type": "METRIC", "confidence": 0.9983810186386108}, {"text": "recall", "start_pos": 255, "end_pos": 261, "type": "METRIC", "confidence": 0.9992471933364868}]}, {"text": "For comparison we include the results of running the word-by-word classifier described in, but where partial words and punctuation have been removed from the training and test data.", "labels": [], "entities": []}, {"text": "We also provide results for our noisy channel model using a bigram language model and a second trigram model where the twenty most likely analyses are rescored.", "labels": [], "entities": []}, {"text": "Finally we show the results using the parser language model.", "labels": [], "entities": []}, {"text": "The noisy channel model using a bigram language model does a slightly worse job at identifying reparandum and interregnum words than the classifier proposed in.", "labels": [], "entities": []}, {"text": "Replacing the bigram language model with a trigram model helps slightly, and parserbased language model results in a significant performance improvement overall of the others.", "labels": [], "entities": []}], "tableCaptions": []}