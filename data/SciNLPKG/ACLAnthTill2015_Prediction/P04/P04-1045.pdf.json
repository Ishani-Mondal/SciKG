{"title": [{"text": "Predicting Student Emotions in Computer-Human Tutoring Dialogues", "labels": [], "entities": [{"text": "Predicting Student Emotions in Computer-Human Tutoring Dialogues", "start_pos": 0, "end_pos": 64, "type": "TASK", "confidence": 0.7894305714539119}]}], "abstractContent": [{"text": "We examine the utility of speech and lexical features for predicting student emotions in computer-human spoken tutoring dialogues.", "labels": [], "entities": [{"text": "predicting student emotions in computer-human spoken tutoring dialogues", "start_pos": 58, "end_pos": 129, "type": "TASK", "confidence": 0.6782000884413719}]}, {"text": "We first annotate student turns for negative, neutral, positive and mixed emotions.", "labels": [], "entities": []}, {"text": "We then extract acoustic-prosodic features from the speech signal, and lexical items from the transcribed or recognized speech.", "labels": [], "entities": []}, {"text": "We compare the results of machine learning experiments using these features alone or in combination to predict various categorizations of the annotated student emotions.", "labels": [], "entities": []}, {"text": "Our best results yield a 19-36% relative improvement in error reduction over a baseline.", "labels": [], "entities": [{"text": "error reduction", "start_pos": 56, "end_pos": 71, "type": "METRIC", "confidence": 0.914627730846405}]}, {"text": "Finally , we compare our results with emotion prediction in human-human tutoring dialogues.", "labels": [], "entities": [{"text": "emotion prediction", "start_pos": 38, "end_pos": 56, "type": "TASK", "confidence": 0.7992919683456421}]}], "introductionContent": [{"text": "This paper explores the feasibility of automatically predicting student emotional states in a corpus of computer-human spoken tutoring dialogues.", "labels": [], "entities": [{"text": "predicting student emotional states", "start_pos": 53, "end_pos": 88, "type": "TASK", "confidence": 0.7478496879339218}]}, {"text": "Intelligent tutoring dialogue systems have become more prevalent in recent years, as one method of improving the performance gap between computer and human tutors; recent experiments with such systems (e.g.,) are starting to yield promising empirical results.", "labels": [], "entities": []}, {"text": "Another method for closing this performance gap has been to incorporate affective reasoning into computer tutoring systems, independently of whether or not the tutor is dialogue-based ().", "labels": [], "entities": []}, {"text": "For example,) have shown that adding human-provided emotional scaffolding to an automated reading tutor increases student persistence.", "labels": [], "entities": []}, {"text": "Our long-term goal is to merge these lines of dialogue and affective tutoring research, by enhancing our intelligent tutoring spoken dialogue system to automatically predict and adapt to student emotions, and to investigate whether this improves learning and other measures of performance.", "labels": [], "entities": []}, {"text": "Previous spoken dialogue research has shown that predictive models of emotion distinctions (e.g., emotional vs. non-emotional, negative vs. nonnegative) can be developed using features typically available to a spoken dialogue system in real-time (e.g, acoustic-prosodic, lexical, dialogue, and/or contextual) (;.", "labels": [], "entities": []}, {"text": "In prior work we built on and generalized such research, by defining a three-way distinction between negative, neutral, and positive student emotional states that could be reliably annotated and accurately predicted in human-human spoken tutoring dialogues (Forbes- ).", "labels": [], "entities": []}, {"text": "Like the non-tutoring studies, our results showed that combining feature types yielded the highest predictive accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 110, "end_pos": 118, "type": "METRIC", "confidence": 0.9171570539474487}]}, {"text": "In this paper we investigate the application of our approach to a comparable corpus of computerhuman tutoring dialogues, which displays many different characteristics, such as shorter utterances, little student initiative, and non-overlapping speech.", "labels": [], "entities": []}, {"text": "We investigate whether we can annotate and predict student emotions as accurately and whether the relative utility of speech and lexical features as predictors is the same, especially when the output of the speech recognizer is used (rather than a human transcription of the student speech).", "labels": [], "entities": []}, {"text": "Our best models for predicting three different types of emotion classifications achieve accuracies of 66-73%, representing relative improvements of 19-36% over majority class baseline errors.", "labels": [], "entities": [{"text": "accuracies", "start_pos": 88, "end_pos": 98, "type": "METRIC", "confidence": 0.9977624416351318}]}, {"text": "Our computer-human results also show interesting differences compared with comparable analyses of human-human data.", "labels": [], "entities": []}, {"text": "Our results provide an empirical basis for enhancing our spoken dialogue tutoring system to automatically predict and adapt to a student model that includes emotional states.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: NnN Analysis Confusion Matrix", "labels": [], "entities": []}, {"text": " Table 2: EnE Analysis Confusion Matrix", "labels": [], "entities": [{"text": "EnE Analysis Confusion", "start_pos": 10, "end_pos": 32, "type": "TASK", "confidence": 0.753938247760137}]}, {"text": " Table 3: NPN Analysis Confusion Matrix", "labels": [], "entities": []}, {"text": " Table 4: %Correct, NnN Agreed, MAJ (non- negative) = 65.65%", "labels": [], "entities": [{"text": "Correct", "start_pos": 11, "end_pos": 18, "type": "METRIC", "confidence": 0.9727339744567871}, {"text": "Agreed", "start_pos": 24, "end_pos": 30, "type": "METRIC", "confidence": 0.9164066910743713}, {"text": "MAJ", "start_pos": 32, "end_pos": 35, "type": "METRIC", "confidence": 0.9682247042655945}]}, {"text": " Table 5: %Correct, EnE Agreed, MAJ (emotional)  = 58.64%", "labels": [], "entities": [{"text": "Correct", "start_pos": 11, "end_pos": 18, "type": "METRIC", "confidence": 0.990215539932251}, {"text": "EnE", "start_pos": 20, "end_pos": 23, "type": "METRIC", "confidence": 0.9811034202575684}, {"text": "Agreed", "start_pos": 24, "end_pos": 30, "type": "METRIC", "confidence": 0.5208628177642822}, {"text": "MAJ", "start_pos": 32, "end_pos": 35, "type": "METRIC", "confidence": 0.938783586025238}]}, {"text": " Table 6: %Correct, NPN Agreed, MAJ (neutral) =  46.52%", "labels": [], "entities": [{"text": "Correct", "start_pos": 11, "end_pos": 18, "type": "METRIC", "confidence": 0.9775214195251465}, {"text": "NPN", "start_pos": 20, "end_pos": 23, "type": "DATASET", "confidence": 0.4924568235874176}, {"text": "Agreed", "start_pos": 24, "end_pos": 30, "type": "METRIC", "confidence": 0.887448251247406}, {"text": "MAJ", "start_pos": 32, "end_pos": 35, "type": "METRIC", "confidence": 0.9104523062705994}]}, {"text": " Table 7: %Corr., NnN Consensus, MAJ=62.47%", "labels": [], "entities": [{"text": "Corr.", "start_pos": 11, "end_pos": 16, "type": "METRIC", "confidence": 0.995292067527771}, {"text": "MAJ", "start_pos": 33, "end_pos": 36, "type": "METRIC", "confidence": 0.9809176921844482}]}, {"text": " Table 8: %Corr., EnE Consensus, MAJ=55.86%", "labels": [], "entities": [{"text": "Corr.", "start_pos": 11, "end_pos": 16, "type": "METRIC", "confidence": 0.988965630531311}, {"text": "EnE Consensus", "start_pos": 18, "end_pos": 31, "type": "METRIC", "confidence": 0.9347026348114014}, {"text": "MAJ", "start_pos": 33, "end_pos": 36, "type": "METRIC", "confidence": 0.9323839545249939}]}, {"text": " Table 9: %Corr., NPN Consensus, MAJ=48.35%", "labels": [], "entities": [{"text": "Corr.", "start_pos": 11, "end_pos": 16, "type": "METRIC", "confidence": 0.9916197061538696}, {"text": "NPN Consensus", "start_pos": 18, "end_pos": 31, "type": "METRIC", "confidence": 0.5400300621986389}, {"text": "MAJ", "start_pos": 33, "end_pos": 36, "type": "METRIC", "confidence": 0.9756124019622803}]}, {"text": " Table 10: Human-Human %Correct, NnN MAJ=72.21%; EnE MAJ=50.86%; NPN MAJ=53.24%", "labels": [], "entities": [{"text": "EnE MAJ", "start_pos": 49, "end_pos": 56, "type": "METRIC", "confidence": 0.9189345240592957}]}]}