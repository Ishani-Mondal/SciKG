{"title": [{"text": "A Machine Learning Approach to German Pronoun Resolution", "labels": [], "entities": [{"text": "Machine Learning Approach to German Pronoun Resolution", "start_pos": 2, "end_pos": 56, "type": "TASK", "confidence": 0.5706714051110404}]}], "abstractContent": [{"text": "This paper presents a novel ensemble learning approach to resolving German pronouns.", "labels": [], "entities": [{"text": "resolving German pronouns", "start_pos": 58, "end_pos": 83, "type": "TASK", "confidence": 0.8011005918184916}]}, {"text": "Boosting, the method in question, combines the moderately accurate hypotheses of several classifiers to form a highly accurate one.", "labels": [], "entities": []}, {"text": "Experiments show that this approach is superior to a single decision-tree classi-fier.", "labels": [], "entities": []}, {"text": "Furthermore, we present a stan-dalone system that resolves pronouns in unannotated text by using a fully automatic sequence of preprocessing modules that mimics the manual annotation process.", "labels": [], "entities": []}, {"text": "Although the system performs well within a limited textual domain, further research is needed to make it effective for open-domain question answering and text summarisation.", "labels": [], "entities": [{"text": "question answering", "start_pos": 131, "end_pos": 149, "type": "TASK", "confidence": 0.7933695912361145}, {"text": "text summarisation", "start_pos": 154, "end_pos": 172, "type": "TASK", "confidence": 0.728660374879837}]}], "introductionContent": [{"text": "Automatic coreference resolution, pronominal and otherwise, has been a popular research area in Natural Language Processing for more than two decades, with extensive documentation of both the rule-based and the machine learning approach.", "labels": [], "entities": [{"text": "Automatic coreference resolution", "start_pos": 0, "end_pos": 32, "type": "TASK", "confidence": 0.7150791883468628}]}, {"text": "For the latter, good results have been achieved with large feature sets (including syntactic, semantic, grammatical and morphological information) derived from handannotated corpora.", "labels": [], "entities": []}, {"text": "However, for applications that work with plain text (e.g. question answering, text summarisation), this approach is not practical.", "labels": [], "entities": [{"text": "question answering", "start_pos": 58, "end_pos": 76, "type": "TASK", "confidence": 0.8356935679912567}, {"text": "text summarisation)", "start_pos": 78, "end_pos": 97, "type": "TASK", "confidence": 0.8015246788660685}]}, {"text": "The system presented in this paper resolves German pronouns in free text by imitating the manual annotation process with off-the-shelf language sofware.", "labels": [], "entities": [{"text": "resolves German pronouns in free text", "start_pos": 35, "end_pos": 72, "type": "TASK", "confidence": 0.8179888327916464}]}, {"text": "As the avalability and reliability of such software is limited, the system can use only a small number of features.", "labels": [], "entities": [{"text": "avalability", "start_pos": 7, "end_pos": 18, "type": "METRIC", "confidence": 0.9678285121917725}]}, {"text": "The fact that most German pronouns are morphologically ambiguous proves an additional challenge.", "labels": [], "entities": []}, {"text": "The choice of boosting as the underlying machine learning algorithm is motivated both by its theoretical concept as well as its performance for other NLP tasks.", "labels": [], "entities": []}, {"text": "The fact that boosting uses the method of ensemble learning, i.e. combining the decisions of several classifiers, suggests that the combined hypothesis will be more accurate than one learned by a single classifier.", "labels": [], "entities": []}, {"text": "On the practical side, boosting has distinguished itself by achieving good results with small feature sets.", "labels": [], "entities": [{"text": "boosting", "start_pos": 23, "end_pos": 31, "type": "TASK", "confidence": 0.9810147285461426}]}], "datasetContent": [{"text": "Before evaluating the actual system, we compared the performance of boosting to that of C4.5, as reported in).", "labels": [], "entities": []}, {"text": "Trained on the same corpus and evaluated with the 10-fold crossvalidation method, boosting significantly outperforms C4.5 on both personal and possessive pronouns (see).", "labels": [], "entities": []}, {"text": "These results support the intuition that ensemble methods are superior to single classifiers.", "labels": [], "entities": []}, {"text": "To put the performance of our system into perspective, we established a baseline and an upper bound for the task.", "labels": [], "entities": []}, {"text": "The baseline chooses as the antecedent the closest non-pronominal markable that agrees in number and gender with the pronoun.", "labels": [], "entities": []}, {"text": "The upper bound is the system's performance on the manually annotated (gold standard) data without the semantic features.", "labels": [], "entities": []}, {"text": "For the baseline, accuracy is significantly higher for the gold standard data than for the two test sets (see).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 18, "end_pos": 26, "type": "METRIC", "confidence": 0.9996823072433472}, {"text": "gold standard data", "start_pos": 59, "end_pos": 77, "type": "DATASET", "confidence": 0.7110878825187683}]}, {"text": "This shows that agreement is the most important feature, which, if annotated correctly, resolves almost half of the pronouns.", "labels": [], "entities": [{"text": "agreement", "start_pos": 16, "end_pos": 25, "type": "METRIC", "confidence": 0.8483766913414001}]}, {"text": "The classification results of the gold standard data, which are much lower than the ones in also PPER PPOS) 82.8 84.9 our system 87.4 86.9 demonstrate the importance of the semantic features.", "labels": [], "entities": [{"text": "gold standard data", "start_pos": 34, "end_pos": 52, "type": "DATASET", "confidence": 0.8416653275489807}, {"text": "PPER PPOS", "start_pos": 97, "end_pos": 106, "type": "DATASET", "confidence": 0.8039554357528687}]}, {"text": "As for the test sets, while the classifier significantly outperformed the baseline for the HTC set, it did nothing for the Spiegel set.", "labels": [], "entities": [{"text": "HTC set", "start_pos": 91, "end_pos": 98, "type": "DATASET", "confidence": 0.9012262523174286}]}, {"text": "This shows the limitations of an algorithm trained on overly restricted data.", "labels": [], "entities": []}, {"text": "Among the selection heuristics, the approach of resolving pronominal antecedents proved consistently more effective than ignoring them, while the results for the closest-first and best-first strategies were mixed.", "labels": [], "entities": []}, {"text": "They imply, however, that the bestfirst approach should be chosen if the classifier performed above a certain threshold; otherwise the closest-first approach is safer.", "labels": [], "entities": []}, {"text": "Overall, the fact that 67.2 of the pronouns were correctly resolved in the automatically annotated HTC test set, while the upper bound is 82.0, validates the approach taken for this system.", "labels": [], "entities": [{"text": "HTC test set", "start_pos": 99, "end_pos": 111, "type": "DATASET", "confidence": 0.9262474973996481}]}], "tableCaptions": [{"text": " Table 3: Accuracy of the different selection heuristics compared with baseline accuracy and classification  F-score. HTC-Gold and HTC-Test stand for manually and automatically annotated test sets, respectively.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9959678649902344}, {"text": "accuracy", "start_pos": 80, "end_pos": 88, "type": "METRIC", "confidence": 0.9461344480514526}, {"text": "F-score", "start_pos": 109, "end_pos": 116, "type": "METRIC", "confidence": 0.6468828320503235}, {"text": "HTC-Gold", "start_pos": 118, "end_pos": 126, "type": "DATASET", "confidence": 0.7615100145339966}, {"text": "HTC-Test", "start_pos": 131, "end_pos": 139, "type": "DATASET", "confidence": 0.8291866183280945}]}]}