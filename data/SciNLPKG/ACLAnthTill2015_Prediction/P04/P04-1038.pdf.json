{"title": [{"text": "Chinese Verb Sense Discrimination Using an EM Clustering Model with Rich Linguistic Features", "labels": [], "entities": [{"text": "Chinese Verb Sense Discrimination", "start_pos": 0, "end_pos": 33, "type": "TASK", "confidence": 0.6305319741368294}]}], "abstractContent": [{"text": "This paper discusses the application of the Expectation-Maximization (EM) clustering algorithm to the task of Chinese verb sense discrimination.", "labels": [], "entities": [{"text": "Chinese verb sense discrimination", "start_pos": 110, "end_pos": 143, "type": "TASK", "confidence": 0.7090597450733185}]}, {"text": "The model utilized rich linguistic features that capture predicate-argument structure information of the target verbs.", "labels": [], "entities": []}, {"text": "A semantic taxonomy for Chinese nouns, which was built semi-automatically based on two electronic Chinese semantic dictionaries, was used to provide semantic features for the model.", "labels": [], "entities": []}, {"text": "Purity and normalized mutual information were used to evaluate the clustering performance on 12 Chinese verbs.", "labels": [], "entities": []}, {"text": "The experimental results show that the EM clustering model can learn sense or sense group distinctions for most of the verbs successfully.", "labels": [], "entities": [{"text": "EM clustering", "start_pos": 39, "end_pos": 52, "type": "TASK", "confidence": 0.8767892420291901}]}, {"text": "We further enhanced the model with certain fine-grained semantic categories called lexical sets.", "labels": [], "entities": []}, {"text": "Our results indicate that these lexical sets improve the model's performance for the three most challenging verbs chosen from the first set of experiments.", "labels": [], "entities": []}], "introductionContent": [{"text": "Highly ambiguous words may lead to irrelevant document retrieval and inaccurate lexical choice in machine translation (), which suggests that word sense disambiguation (WSD) is beneficial and sometimes even necessary in such NLP tasks.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 98, "end_pos": 117, "type": "TASK", "confidence": 0.7226456552743912}, {"text": "word sense disambiguation (WSD)", "start_pos": 142, "end_pos": 173, "type": "TASK", "confidence": 0.7250203291575114}]}, {"text": "This paper addresses WSD in Chinese through developing an Expectation-Maximization (EM) clustering model to learn Chinese verb sense distinctions.", "labels": [], "entities": [{"text": "WSD", "start_pos": 21, "end_pos": 24, "type": "TASK", "confidence": 0.9942281246185303}, {"text": "learn Chinese verb sense distinctions", "start_pos": 108, "end_pos": 145, "type": "TASK", "confidence": 0.6155106842517852}]}, {"text": "The major goal is to do sense discrimination rather than sense labeling, similar to.", "labels": [], "entities": [{"text": "sense discrimination", "start_pos": 24, "end_pos": 44, "type": "TASK", "confidence": 0.7202585935592651}, {"text": "sense labeling", "start_pos": 57, "end_pos": 71, "type": "TASK", "confidence": 0.6830359399318695}]}, {"text": "The basic idea is to divide instances of a word into several clusters that have no sense labels.", "labels": [], "entities": []}, {"text": "The instances in the same cluster are regarded as having the same meaning.", "labels": [], "entities": []}, {"text": "Word sense discrimination can be applied to document retrieval and similar tasks in information access, and to facilitating the building of large annotated corpora.", "labels": [], "entities": [{"text": "Word sense discrimination", "start_pos": 0, "end_pos": 25, "type": "TASK", "confidence": 0.6521655321121216}, {"text": "document retrieval", "start_pos": 44, "end_pos": 62, "type": "TASK", "confidence": 0.7244469374418259}]}, {"text": "In addition, since the clustering model can be trained on large unannotated corpora and evaluated on a relatively small sense-tagged corpus, it can be used to find indicative features for sense distinctions through exploring huge amount of available unannotated text data.", "labels": [], "entities": []}, {"text": "The EM clustering algorithm () used here is an unsupervised machine learning algorithm that has been applied in many NLP tasks, such as inducing a semantically labeled lexicon and determining lexical choice in machine translation (, automatic acquisition of verb semantic classes) and automatic semantic labeling ().", "labels": [], "entities": [{"text": "EM clustering", "start_pos": 4, "end_pos": 17, "type": "TASK", "confidence": 0.8230048716068268}, {"text": "machine translation", "start_pos": 210, "end_pos": 229, "type": "TASK", "confidence": 0.7190898060798645}, {"text": "automatic acquisition of verb semantic classes", "start_pos": 233, "end_pos": 279, "type": "TASK", "confidence": 0.702486495176951}, {"text": "automatic semantic labeling", "start_pos": 285, "end_pos": 312, "type": "TASK", "confidence": 0.5667476952075958}]}, {"text": "In our task, we equipped the EM clustering model with rich linguistic features that capture the predicate-argument structure information of verbs and restricted the feature set for each verb using knowledge from dictionaries.", "labels": [], "entities": [{"text": "EM clustering", "start_pos": 29, "end_pos": 42, "type": "TASK", "confidence": 0.8643984496593475}]}, {"text": "We also semiautomatically built a semantic taxonomy for Chinese nouns based on two Chinese electronic semantic dictionaries, the Hownet dictionary 1 and the Rocling dictionary.", "labels": [], "entities": [{"text": "Hownet dictionary 1", "start_pos": 129, "end_pos": 148, "type": "DATASET", "confidence": 0.966742992401123}, {"text": "Rocling dictionary", "start_pos": 157, "end_pos": 175, "type": "DATASET", "confidence": 0.8584547936916351}]}, {"text": "The 7 top-level categories of this taxonomy were used as semantic features for the model.", "labels": [], "entities": []}, {"text": "Since external knowledge is used to obtain the semantic features and guide feature selection, the model is not completely unsupervised from this perspective; however, it does not make use of any annotated training data.", "labels": [], "entities": []}, {"text": "Two external quality measures, purity and normalized mutual information (NMI), were used to evaluate the model's performance on 12 Chinese verbs.", "labels": [], "entities": [{"text": "purity", "start_pos": 31, "end_pos": 37, "type": "METRIC", "confidence": 0.9962217807769775}, {"text": "normalized mutual information (NMI)", "start_pos": 42, "end_pos": 77, "type": "METRIC", "confidence": 0.8263812710841497}]}, {"text": "The experimental results show that rich linguistic features and the semantic taxonomy are both very useful in sense discrimination.", "labels": [], "entities": [{"text": "sense discrimination", "start_pos": 110, "end_pos": 130, "type": "TASK", "confidence": 0.8030368089675903}]}, {"text": "The model generally performs well in learning sense group distinctions for difficult, highly polysemous verbs and sense distinctions for other verbs.", "labels": [], "entities": [{"text": "learning sense group distinctions", "start_pos": 37, "end_pos": 70, "type": "TASK", "confidence": 0.5651671141386032}]}, {"text": "Enhanced by certain fine-grained semantic categories called lexical sets is under the threshold 0.001.", "labels": [], "entities": []}, {"text": "When doing classification, for each verb instance, the model calculates the same conditional probability as in equation and assigns the instance to the cluster with the maximal ) ,..., , | (", "labels": [], "entities": []}], "datasetContent": [{"text": "Since we need labeled data to evaluate the clustering performance but have limited sensetagged corpora, we applied the clustering model to 12 Chinese verbs in our experiments.", "labels": [], "entities": []}, {"text": "The verbs are chosen from 28 annotated verbs in Penn Chinese Treebank so that they have at least two verb meanings in the corpus and for each of them, the number of instances fora single verb sense does not exceed 90% of the total number of instances.", "labels": [], "entities": [{"text": "Penn Chinese Treebank", "start_pos": 48, "end_pos": 69, "type": "DATASET", "confidence": 0.990306556224823}]}, {"text": "In our task, we generally do not include senses for other parts of speech of the selected words, such as noun, preposition, conjunction and particle etc., since the parser we used has a very high accuracy in distinguishing different parts of speech of these words (>98% for most of them).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 196, "end_pos": 204, "type": "METRIC", "confidence": 0.9972056746482849}]}, {"text": "However, we do include senses for conjunctional and/or prepositional usage of two words, \"\u5230|dao4\" and \"\u4e3a|wei4\", since our parser cannot distinguish the verb usage from the conjunctional or prepositional usage for the two words very well.", "labels": [], "entities": []}, {"text": "Five verbs, the first five listed in, are both highly polysemous and difficult fora supervised word sense classifier ().", "labels": [], "entities": []}, {"text": "In our experiments, we manually grouped the verb senses for the five verbs.", "labels": [], "entities": []}, {"text": "The criteria for the grouping are similar to Palmer et al.'s (to appear) work on English verbs, which considers both sense coherence and predicate-argument structure distinctions.", "labels": [], "entities": []}, {"text": "gives an example of In the supervised task, their accuracies are lower than 85%, and four of them are even lower than the baselines.", "labels": [], "entities": [{"text": "accuracies", "start_pos": 50, "end_pos": 60, "type": "METRIC", "confidence": 0.9948861002922058}]}, {"text": "The model was trained on an unannotated corpus, People's Daily News (PDN), and tested on the manually sense-tagged Chinese Treebank (with some additional sense-tagged PDN data).", "labels": [], "entities": [{"text": "People's Daily News (PDN)", "start_pos": 48, "end_pos": 73, "type": "DATASET", "confidence": 0.9391038162367684}, {"text": "Chinese Treebank", "start_pos": 115, "end_pos": 131, "type": "DATASET", "confidence": 0.9645080864429474}]}, {"text": "We parsed the training and test data using a Maximum Entropy parser and extracted the features from the parsed data automatically.", "labels": [], "entities": []}, {"text": "The number of clusters used by the model is set to the number of the defined senses or sense groups of each target verb.", "labels": [], "entities": []}, {"text": "For each verb, we ran the EM clustering algorithm ten times.", "labels": [], "entities": [{"text": "EM clustering", "start_pos": 26, "end_pos": 39, "type": "TASK", "confidence": 0.7964887320995331}]}, {"text": "shows the average performance and the standard deviation for each verb.", "labels": [], "entities": []}, {"text": "summarizes the data used in the experiments, where we also give the normalized sense perplexity of each verb in the test data.", "labels": [], "entities": []}, {"text": "We use two external quality measures, purity and normalized mutual information (NMI) to evaluate the clustering performance.", "labels": [], "entities": [{"text": "purity", "start_pos": 38, "end_pos": 44, "type": "METRIC", "confidence": 0.9950293898582458}, {"text": "normalized mutual information (NMI)", "start_pos": 49, "end_pos": 84, "type": "METRIC", "confidence": 0.8544168174266815}]}, {"text": "Assuming a verb has l senses, the clustering model assigns n instances of the verb into k clusters, in is the size of the ith cluster, j n is the number of instances hand-tagged with the jth sense, and j in is the number of instances with the jth sense in the ith cluster, purity is defined in equation The sense-tagged PDN data we used here are the same as in ().", "labels": [], "entities": [{"text": "purity", "start_pos": 273, "end_pos": 279, "type": "METRIC", "confidence": 0.9612298011779785}]}, {"text": "11 It is calculated as the entropy of the sense distribution of a verb in the test data divided by the largest possible entropy, i.e., log 2 (the number of senses of the verb in the test data).", "labels": [], "entities": []}, {"text": "It can be interpreted as classification accuracy when for each cluster we treat the majority of instances that have the same sense as correctly classified.", "labels": [], "entities": [{"text": "classification", "start_pos": 25, "end_pos": 39, "type": "TASK", "confidence": 0.9506620764732361}, {"text": "accuracy", "start_pos": 40, "end_pos": 48, "type": "METRIC", "confidence": 0.9254090189933777}]}, {"text": "The baseline purity is calculated by treating all instances fora target verb in a single cluster.", "labels": [], "entities": []}, {"text": "The purity measure is very intuitive.", "labels": [], "entities": [{"text": "purity measure", "start_pos": 4, "end_pos": 18, "type": "METRIC", "confidence": 0.9669815301895142}]}, {"text": "In our case, since the number of clusters is preset to the number of senses, purity for verbs with two senses is equal to classification accuracy defined in supervised WSD.", "labels": [], "entities": [{"text": "purity", "start_pos": 77, "end_pos": 83, "type": "METRIC", "confidence": 0.9925318360328674}, {"text": "accuracy", "start_pos": 137, "end_pos": 145, "type": "METRIC", "confidence": 0.971218466758728}]}, {"text": "However, for verbs with more than 2 senses, purity is less informative in that a clustering model could achieve high purity by making the instances of 2 or 3 dominant senses the majority instances of all the clusters.", "labels": [], "entities": [{"text": "purity", "start_pos": 44, "end_pos": 50, "type": "METRIC", "confidence": 0.9879041314125061}]}, {"text": "Mutual information (MI) is more theoretically well-founded than purity.", "labels": [], "entities": [{"text": "Mutual information (MI)", "start_pos": 0, "end_pos": 23, "type": "TASK", "confidence": 0.8988166570663452}, {"text": "purity", "start_pos": 64, "end_pos": 70, "type": "METRIC", "confidence": 0.9305282831192017}]}, {"text": "Treating the verb sense and the cluster as random variables Sand C, the MI between them is defined in equation MI(S,C) characterizes the reduction in uncertainty of one random variable S (or C) due to knowing the other variable C (or S).", "labels": [], "entities": []}, {"text": "A single cluster with all instances fora target verb has a zero MI.", "labels": [], "entities": [{"text": "MI", "start_pos": 64, "end_pos": 66, "type": "METRIC", "confidence": 0.9975411891937256}]}, {"text": "Random clustering also has a zero MI in the limit.", "labels": [], "entities": [{"text": "Random clustering", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.7528733313083649}, {"text": "MI", "start_pos": 34, "end_pos": 36, "type": "METRIC", "confidence": 0.9987528324127197}]}, {"text": "In our experiments, we used [0,1]-normalized mutual information (NMI).", "labels": [], "entities": []}, {"text": "A shortcoming of this measure, however, is that the best possible clustering (upper bound) evaluates to less than 1, unless classes are balanced.", "labels": [], "entities": []}, {"text": "Unfortunately, unbalanced sense distribution is the usual casein WSD tasks, which makes NMI itself hard to interpret.", "labels": [], "entities": [{"text": "WSD tasks", "start_pos": 65, "end_pos": 74, "type": "TASK", "confidence": 0.8345635533332825}]}, {"text": "Therefore, in addition to NMI, we also give its upper bound (upper-NMI) and the ratio of NMI and its upper bound (NMI-ratio) for each verb, as shown in columns 6 to 8 in.", "labels": [], "entities": []}, {"text": "Senses for \"\u5230|dao4\" Sense groups for \"\u5230|dao4\" summarizes the experimental results for the 12 Chinese verbs.", "labels": [], "entities": []}, {"text": "As we see, the EM clustering model performs well on most of them, except the verb \"\u8981|yao4\".", "labels": [], "entities": [{"text": "EM clustering", "start_pos": 15, "end_pos": 28, "type": "TASK", "confidence": 0.8086295425891876}]}, {"text": "The NMI measure NMI-ratio turns out to be more stringent than purity.", "labels": [], "entities": [{"text": "NMI measure NMI-ratio", "start_pos": 4, "end_pos": 25, "type": "METRIC", "confidence": 0.6673412521680196}, {"text": "purity", "start_pos": 62, "end_pos": 68, "type": "METRIC", "confidence": 0.980641782283783}]}, {"text": "A high purity does not necessarily mean a high NMI-ratio.", "labels": [], "entities": [{"text": "NMI-ratio", "start_pos": 47, "end_pos": 56, "type": "METRIC", "confidence": 0.9393901228904724}]}, {"text": "Although intuitively, NMI-ratio should be related to sense perplexity and purity, it is hard to formalize the relationships between them from the results.", "labels": [], "entities": [{"text": "purity", "start_pos": 74, "end_pos": 80, "type": "METRIC", "confidence": 0.987815260887146}]}, {"text": "In fact, the NMI-ratio fora particular verb is eventually determined by its concrete sense distribution in the test data and the model's clustering behavior for that verb.", "labels": [], "entities": []}, {"text": "For example, the verbs \"\u51fa|chu1\" and \"\u89c1|jian4\" have the same sense perplexity and \"\u89c1|jian4\" has a higher purity than \"\u51fa|chu1\" (72.20% vs. 63.31%), but the NMIratio for \"\u89c1|jian4\" is much lower than \"\u51fa|chu1\").", "labels": [], "entities": [{"text": "purity", "start_pos": 104, "end_pos": 110, "type": "METRIC", "confidence": 0.9743192195892334}, {"text": "NMIratio", "start_pos": 154, "end_pos": 162, "type": "METRIC", "confidence": 0.5399079918861389}]}, {"text": "An analysis of the classification results for \"\u89c1|jian4\" shows that the clustering model made the instances of the verb's most dominant sense the majority instances of three clusters (of total 5 clusters), which is penalized heavily by the NMI measure.", "labels": [], "entities": [{"text": "NMI measure", "start_pos": 239, "end_pos": 250, "type": "DATASET", "confidence": 0.7824482321739197}]}, {"text": "Rich linguistic features turnout to be very effective in learning Chinese verb sense distinctions.", "labels": [], "entities": [{"text": "learning Chinese verb sense distinctions", "start_pos": 57, "end_pos": 97, "type": "TASK", "confidence": 0.7397390365600586}]}, {"text": "Except for the two verbs, \"\u53d1\u73b0|fa1xian4\" and \"\u8868\u793a|biao3shi4\", the sense distinctions of which can usually be made only by syntactic alternations, 13 features such as semantic features or combinations of semantic features and syntactic alternations are very beneficial and sometimes even necessary for learning sense distinctions of other verbs.", "labels": [], "entities": []}, {"text": "For example, the verb \"\u89c1|jian4\" has one sense see, in which the verb typically takes a Human subject and a sentential complement, while in another sense show, the verb typically takes an Entity subject and a State object.", "labels": [], "entities": []}, {"text": "An inspection of the classification results shows.", "labels": [], "entities": []}, {"text": "A summary of the training and test data used in the experiments.", "labels": [], "entities": []}, {"text": "The performance of the EM clustering model on 12 Chinese verbs measured by purity and normalized mutual information (NMI) that the EM clustering model has indeed learned such combinatory patterns from the training data.", "labels": [], "entities": [{"text": "EM clustering", "start_pos": 23, "end_pos": 36, "type": "TASK", "confidence": 0.7866085171699524}, {"text": "purity", "start_pos": 75, "end_pos": 81, "type": "METRIC", "confidence": 0.9928096532821655}, {"text": "normalized mutual information (NMI)", "start_pos": 86, "end_pos": 121, "type": "METRIC", "confidence": 0.8378509432077408}, {"text": "EM clustering", "start_pos": 131, "end_pos": 144, "type": "TASK", "confidence": 0.7341188192367554}]}, {"text": "The experimental results also indicate that the semantic taxonomy we built is beneficial for the task.", "labels": [], "entities": []}, {"text": "For example, the verb \"\u6295\u5165|tou1ru4\" has two senses, input and plunge into.", "labels": [], "entities": []}, {"text": "It typically takes an Event object for the second sense but not for the first one.", "labels": [], "entities": []}, {"text": "A single feature obtained from our semantic taxonomy, which tests whether the verb takes an Event object, captures this property neatly (achieves purity 95.65% and NMI-ratio 78.38% when using 2 clusters).", "labels": [], "entities": [{"text": "NMI-ratio", "start_pos": 164, "end_pos": 173, "type": "METRIC", "confidence": 0.9310775995254517}]}, {"text": "Without the taxonomy, the top-level category Event is split into many finegrained Hownet or Rocling categories, which makes it very difficult for the EM clustering model to learn sense distinctions for this verb.", "labels": [], "entities": [{"text": "Hownet", "start_pos": 82, "end_pos": 88, "type": "DATASET", "confidence": 0.9065614342689514}]}, {"text": "In fact, in a preliminary experiment only using the Hownet and Rocling categories, the model had the same purity as the baseline (52.17%) and a low NMI-ratio (4.22%) when using 2 clusters.", "labels": [], "entities": [{"text": "Hownet", "start_pos": 52, "end_pos": 58, "type": "DATASET", "confidence": 0.9875999689102173}, {"text": "purity", "start_pos": 106, "end_pos": 112, "type": "METRIC", "confidence": 0.9698230028152466}, {"text": "NMI-ratio", "start_pos": 148, "end_pos": 157, "type": "METRIC", "confidence": 0.9840818643569946}]}, {"text": "The purity improved when using more clusters (70.43% with 4 clusters and 76.09% with 6), but it was still much lower than the purity achieved by using the semantic taxonomy and the NMI-ratio dropped further (1.19% and 1.20% for the two cases).", "labels": [], "entities": []}, {"text": "By looking at the classification results, we identified three major types of errors.", "labels": [], "entities": []}, {"text": "First, preprocessing errors create noisy data for the model.", "labels": [], "entities": []}, {"text": "Second, certain sense distinctions depend heavily on global contextual information (crosssentence information) that is not captured by our model.", "labels": [], "entities": []}, {"text": "This problem is especially serious for the verb \"\u8981|yao4\".", "labels": [], "entities": []}, {"text": "For example, without global contextual information, the verb can have at least three meanings want, need or should in the same clause, as shown in Third, a target verb sometimes has specific types of NP arguments or co-occurs with specific types of verbs in verb compounds in certain senses.", "labels": [], "entities": []}, {"text": "Such information is crucial for distinguishing these senses from others, but is not captured by the general semantic taxonomy used here.", "labels": [], "entities": []}, {"text": "We did further experiments to investigate how much improvement the model could gain by capturing such information, as discussed in Section 5.3.", "labels": [], "entities": []}, {"text": "As discussed by Patrick, certain senses of a verb are often distinguished by very narrowly defined semantic classes (called lexical sets) that are specific to the meaning of that verb sense.", "labels": [], "entities": []}, {"text": "For example, in our case, the verb \"\u6062\u590d|hui1fu4\" has a sense recover in which its direct object should be something that can be recovered naturally.", "labels": [], "entities": []}, {"text": "A typical set of object NPs of the verb for this particular sense is partially listed in Most words in this lexical set belong to the Hownet category attribute and the top-level category State in our taxonomy.", "labels": [], "entities": [{"text": "Hownet category attribute", "start_pos": 134, "end_pos": 159, "type": "DATASET", "confidence": 0.9030935565630595}]}, {"text": "However, even the lower-level category attribute still contains many other words irrelevant to the lexical set, some of which are even typical objects of the verb for two other senses, resume and regain, such as \"\u90a6\u4ea4/diplomatic relations\" in \"\u6062\u590d/resume \u90a6\u4ea4/diplomatic relations\" and \"\u540d\u8a89/reputation\" in \"\u6062\u590d/regain\u540d\u8a89/reputation\".", "labels": [], "entities": []}, {"text": "Therefore, a lexical set like (4) is necessary for distinguishing the recover sense from other senses of the verb.", "labels": [], "entities": []}, {"text": "It has been argued that the extensional definition of lexical sets can only be done using corpus evidence and it cannot be done fully automatically.", "labels": [], "entities": [{"text": "extensional definition of lexical sets", "start_pos": 28, "end_pos": 66, "type": "TASK", "confidence": 0.8984259843826294}]}, {"text": "In our experiments, we use a bootstrapping approach to obtain five lexical sets semi-automatically for three verbs \"\u51fa|chu1\", \"\u89c1|jian4\" and \"\u6062\u590d|hui1fu4\" that have both low purity and low NMI-ratio in the first set of experiments.", "labels": [], "entities": []}, {"text": "We first extracted candidates for the lexical sets from the training data.", "labels": [], "entities": []}, {"text": "For example, we extracted all the direct objects of the verb \"\u6062\u590d|hui1fu4\" and all the verbs that combined with the verb \"\u51fa|chu1\" to form verb compounds from the automatically parsed training data.", "labels": [], "entities": []}, {"text": "From the candidates, we manually selected words to form five initial seed sets, each of which contains no more than ten words.", "labels": [], "entities": []}, {"text": "A simple algorithm was used to search for all the words that have the same detailed Hownet semantic definitions (semantic category plus certain supplementary information) as the seed words.", "labels": [], "entities": [{"text": "Hownet", "start_pos": 84, "end_pos": 90, "type": "DATASET", "confidence": 0.9545139074325562}]}, {"text": "We did not use Rocling because its semantic definitions are so general that a seed word tends to extend to a huge set of irrelevant words.", "labels": [], "entities": []}, {"text": "Highly relevant words were manually selected from all the words found by the searching algorithm and added to the initial seed sets.", "labels": [], "entities": []}, {"text": "The enlarged sets were used as lexical sets.", "labels": [], "entities": []}, {"text": "The enhanced model first uses the lexical sets to obtain the semantic category of the NP arguments of the three verbs.", "labels": [], "entities": []}, {"text": "Only when the search fails does the model resort to the general semantic taxonomy.", "labels": [], "entities": []}, {"text": "The model also uses the lexical sets to determine the types of the compound verbs that contain the target verb \"\u51fa|chu1\" and uses them as new features.", "labels": [], "entities": []}, {"text": "shows the model's performance on the three verbs with or without using lexical sets.", "labels": [], "entities": []}, {"text": "As we see, lexical sets improves the model's performance on all of them, especially on the verb \"\u51fa|chu1\".", "labels": [], "entities": []}, {"text": "Although the results are still preliminary, they nevertheless provide us hints of how much a WSD model for Chinese verbs could gain from lexical sets.", "labels": [], "entities": [{"text": "WSD", "start_pos": 93, "end_pos": 96, "type": "TASK", "confidence": 0.7967830896377563}]}], "tableCaptions": [{"text": " Table 1. A summary of the training and test data used in the experiments", "labels": [], "entities": []}, {"text": " Table 2. The performance of the EM clustering model on 12 Chinese verbs measured  by purity and normalized mutual information (NMI)", "labels": [], "entities": [{"text": "EM clustering", "start_pos": 33, "end_pos": 46, "type": "TASK", "confidence": 0.9216382205486298}, {"text": "purity", "start_pos": 86, "end_pos": 92, "type": "METRIC", "confidence": 0.992340087890625}, {"text": "normalized mutual information (NMI)", "start_pos": 97, "end_pos": 132, "type": "METRIC", "confidence": 0.7474867105484009}]}]}