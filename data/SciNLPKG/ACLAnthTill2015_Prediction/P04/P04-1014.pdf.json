{"title": [{"text": "Parsing the WSJ using CCG and Log-Linear Models", "labels": [], "entities": [{"text": "WSJ", "start_pos": 12, "end_pos": 15, "type": "DATASET", "confidence": 0.9088526368141174}]}], "abstractContent": [{"text": "This paper describes and evaluates log-linear parsing models for Combinatory Categorial Grammar (CCG).", "labels": [], "entities": [{"text": "Combinatory Categorial Grammar (CCG)", "start_pos": 65, "end_pos": 101, "type": "TASK", "confidence": 0.8223159313201904}]}, {"text": "A parallel implementation of the L-BFGS optimisation algorithm is described, which runs on a Beowulf cluster allowing the complete Penn Treebank to be used for estimation.", "labels": [], "entities": [{"text": "Beowulf cluster", "start_pos": 93, "end_pos": 108, "type": "DATASET", "confidence": 0.9627321064472198}, {"text": "Penn Treebank", "start_pos": 131, "end_pos": 144, "type": "DATASET", "confidence": 0.9954618811607361}, {"text": "estimation", "start_pos": 160, "end_pos": 170, "type": "TASK", "confidence": 0.9637511968612671}]}, {"text": "We also develop anew efficient parsing algorithm for CCG which maximises expected recall of dependencies.", "labels": [], "entities": [{"text": "recall", "start_pos": 82, "end_pos": 88, "type": "METRIC", "confidence": 0.9839729070663452}]}, {"text": "We compare models which use all CCG derivations, including non-standard derivations, with normal-form models.", "labels": [], "entities": []}, {"text": "The performances of the two models are comparable and the results are competitive with existing wide-coverage CCG parsers.", "labels": [], "entities": []}], "introductionContent": [{"text": "A number of statistical parsing models have recently been developed for Combinatory Categorial Grammar) and used in parsers applied to the WSJ Penn Treebank (.", "labels": [], "entities": [{"text": "statistical parsing", "start_pos": 12, "end_pos": 31, "type": "TASK", "confidence": 0.5708757489919662}, {"text": "Combinatory Categorial Grammar", "start_pos": 72, "end_pos": 102, "type": "TASK", "confidence": 0.6282598872979482}, {"text": "WSJ Penn Treebank", "start_pos": 139, "end_pos": 156, "type": "DATASET", "confidence": 0.9163989226023356}]}, {"text": "In Clark and Curran we argued for the use of log-linear parsing models for CCG.", "labels": [], "entities": [{"text": "Clark and Curran", "start_pos": 3, "end_pos": 19, "type": "DATASET", "confidence": 0.826478918393453}]}, {"text": "However, estimating a log-linear model fora widecoverage CCG grammar is very computationally expensive.", "labels": [], "entities": []}, {"text": "Following, we showed how the estimation can be performed efficiently by applying the inside-outside algorithm to a packed chart.", "labels": [], "entities": [{"text": "estimation", "start_pos": 29, "end_pos": 39, "type": "TASK", "confidence": 0.9676708579063416}]}, {"text": "We also showed how the complete WSJ Penn Treebank can be used for training by developing a parallel version of Generalised Iterative Scaling (GIS) to perform the estimation.", "labels": [], "entities": [{"text": "WSJ Penn Treebank", "start_pos": 32, "end_pos": 49, "type": "DATASET", "confidence": 0.9084758758544922}, {"text": "Generalised Iterative Scaling (GIS)", "start_pos": 111, "end_pos": 146, "type": "TASK", "confidence": 0.6937280893325806}]}, {"text": "This paper significantly extends our earlier work in a number of ways.", "labels": [], "entities": []}, {"text": "First, we evaluate a number of log-linear models, obtaining results which are competitive with the state-of-the-art for CCG parsing.", "labels": [], "entities": [{"text": "CCG parsing", "start_pos": 120, "end_pos": 131, "type": "TASK", "confidence": 0.7006243765354156}]}, {"text": "We also compare log-linear models which use all CCG derivations, including non-standard derivations, with normal-form models.", "labels": [], "entities": []}, {"text": "Second, we find that GIS is unsuitable for estimating a model of the size being considered, and develop a parallel version of the L-BFGS algorithm).", "labels": [], "entities": []}, {"text": "And finally, we show that the parsing algorithm described in  is extremely slow in some cases, and suggest an efficient alternative based on.", "labels": [], "entities": [{"text": "parsing", "start_pos": 30, "end_pos": 37, "type": "TASK", "confidence": 0.9752800464630127}]}, {"text": "The development of parsing and estimation algorithms for models which use all derivations extends existing CCG parsing techniques, and allows us to test whether there is useful information in the additional derivations.", "labels": [], "entities": [{"text": "parsing and estimation", "start_pos": 19, "end_pos": 41, "type": "TASK", "confidence": 0.7985360225041708}, {"text": "CCG parsing", "start_pos": 107, "end_pos": 118, "type": "TASK", "confidence": 0.6285239458084106}]}, {"text": "However, we find that the performance of the normal-form model is at least as good as the all-derivations model, in our experiments todate.", "labels": [], "entities": []}, {"text": "The normal-form approach allows the use of additional constraints on rule applications, leading to a smaller model, reducing the computational resources required for estimation, and resulting in an extremely efficient parser.", "labels": [], "entities": []}, {"text": "This paper assumes a basic understanding of CCG; see for an introduction, and and for an introduction to statistical parsing with CCG.", "labels": [], "entities": [{"text": "statistical parsing", "start_pos": 105, "end_pos": 124, "type": "TASK", "confidence": 0.7839469015598297}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Results on development set; labelled and unla-", "labels": [], "entities": []}, {"text": " Table 2: Results on development set for the normal- form models", "labels": [], "entities": []}, {"text": " Table 3: Results on the test set", "labels": [], "entities": []}]}