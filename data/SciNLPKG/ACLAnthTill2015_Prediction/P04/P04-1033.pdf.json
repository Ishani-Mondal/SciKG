{"title": [{"text": "Learning with Unlabeled Data for Text Categorization Using Bootstrapping and Feature Projection Techniques", "labels": [], "entities": [{"text": "Text Categorization", "start_pos": 33, "end_pos": 52, "type": "TASK", "confidence": 0.7627122104167938}]}], "abstractContent": [{"text": "A wide range of supervised learning algorithms has been applied to Text Categorization.", "labels": [], "entities": [{"text": "Text Categorization", "start_pos": 67, "end_pos": 86, "type": "TASK", "confidence": 0.7599101960659027}]}, {"text": "However, the supervised learning approaches have some problems.", "labels": [], "entities": []}, {"text": "One of them is that they require a large, often prohibitive, number of labeled training documents for accurate learning.", "labels": [], "entities": []}, {"text": "Generally, acquiring class labels for training data is costly, while gathering a large quantity of unlabeled data is cheap.", "labels": [], "entities": []}, {"text": "We here propose anew automatic text categorization method for learning from only unlabeled data using a bootstrapping framework and a feature projection technique.", "labels": [], "entities": []}, {"text": "From results of our experiments, our method showed reasonably comparable performance compared with a supervised method.", "labels": [], "entities": []}, {"text": "If our method is used in a text categorization task, building text categorization systems will become significantly faster and less expensive.", "labels": [], "entities": [{"text": "text categorization task", "start_pos": 27, "end_pos": 51, "type": "TASK", "confidence": 0.8085018197695414}]}], "introductionContent": [{"text": "Text categorization is the task of classifying documents into a certain number of pre-defined categories.", "labels": [], "entities": [{"text": "Text categorization", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.7694660723209381}]}, {"text": "Many supervised learning algorithms have been applied to this area.", "labels": [], "entities": []}, {"text": "These algorithms today are reasonably successful when provided with enough labeled or annotated training examples.", "labels": [], "entities": []}, {"text": "For example, there are Naive Bayes ), Rocchio (, Nearest Neighbor (kNN) (), TCFP (), and Support Vector Machine (SVM).", "labels": [], "entities": []}, {"text": "However, the supervised learning approach has some difficulties.", "labels": [], "entities": []}, {"text": "One key difficulty is that it requires a large, often prohibitive, number of labeled training data for accurate learning.", "labels": [], "entities": []}, {"text": "Since a labeling task must be done manually, it is a painfully time-consuming process.", "labels": [], "entities": [{"text": "labeling task", "start_pos": 8, "end_pos": 21, "type": "TASK", "confidence": 0.9269630312919617}]}, {"text": "Furthermore, since the application area of text categorization has diversified from newswire articles and web pages to E-mails and newsgroup postings, it is also a difficult task to create training data for each application area . In this light, we consider learning algorithms that do not require such a large amount of labeled data.", "labels": [], "entities": [{"text": "text categorization", "start_pos": 43, "end_pos": 62, "type": "TASK", "confidence": 0.6972658038139343}]}, {"text": "While labeled data are difficult to obtain, unlabeled data are readily available and plentiful.", "labels": [], "entities": []}, {"text": "Therefore, this paper advocates using a bootstrapping framework and a feature projection technique with just unlabeled data for text categorization.", "labels": [], "entities": []}, {"text": "The input to the bootstrapping process is a large amount of unlabeled data and a small amount of seed information to tell the learner about the specific task.", "labels": [], "entities": []}, {"text": "In this paper, we consider seed information in the form of title words associated with categories.", "labels": [], "entities": []}, {"text": "In general, since unlabeled data are much less expensive and easier to collect than labeled data, our method is useful for text categorization tasks including online data sources such as web pages, E-mails, and newsgroup postings.", "labels": [], "entities": []}, {"text": "To automatically buildup a text classifier with unlabeled data, we must solve two problems; how we can automatically generate labeled training documents (machine-labeled data) from only title words and how we can handle incorrectly labeled documents in the machine-labeled data.", "labels": [], "entities": []}, {"text": "This paper provides solutions for these problems.", "labels": [], "entities": []}, {"text": "For the first problem, we employ the bootstrapping framework.", "labels": [], "entities": []}, {"text": "For the second, we use the TCFP classifier with robustness from noisy data (.", "labels": [], "entities": []}, {"text": "How can labeled training data be automatically created from unlabeled data and title words?", "labels": [], "entities": []}, {"text": "Maybe unlabeled data don't have any information for building a text classifier because they do not contain the most important information, their category.", "labels": [], "entities": []}, {"text": "Thus we must assign the class to each document in order to use supervised learning approaches.", "labels": [], "entities": []}, {"text": "Since text categorization is a task based on pre-defined categories, we know the categories for classifying documents.", "labels": [], "entities": [{"text": "text categorization", "start_pos": 6, "end_pos": 25, "type": "TASK", "confidence": 0.7287977039813995}]}, {"text": "Knowing the categories means that we can choose at least a representative title word of each category.", "labels": [], "entities": []}, {"text": "This is the starting point of our proposed method.", "labels": [], "entities": []}, {"text": "As we carryout a bootstrapping task from these title words, we can finally get labeled training data.", "labels": [], "entities": []}, {"text": "Suppose, for example, that we are interested in classifying newsgroup postings about specially 'Autos' category.", "labels": [], "entities": [{"text": "classifying newsgroup postings", "start_pos": 48, "end_pos": 78, "type": "TASK", "confidence": 0.8437017798423767}]}, {"text": "Above all, we can select 'automobile' as a title word, and automatically extract keywords ('car', 'gear', 'transmission', 'sedan', and so on) using co-occurrence information.", "labels": [], "entities": []}, {"text": "In our method, we use context (a sequence of 60 words) as a unit of meaning for bootstrapping from title words; it is generally constructed as a middle size of a sentence and a document.", "labels": [], "entities": []}, {"text": "We then extract core contexts that include at least one of the title words and the keywords.", "labels": [], "entities": []}, {"text": "We call them centroid-contexts because they are regarded as contexts with the core meaning of each category.", "labels": [], "entities": []}, {"text": "From the centroidcontexts, we can gain many words contextually cooccurred with the title words and keywords: 'driver', 'clutch', 'trunk', and soon.", "labels": [], "entities": []}, {"text": "They are words in first-order co-occurrence with the title words and the keywords.", "labels": [], "entities": []}, {"text": "To gather more vocabulary, we extract contexts that are similar to centroid-contexts by a similarity measure; they contain words in second-order co-occurrence with the title words and the keywords.", "labels": [], "entities": []}, {"text": "We finally construct context-cluster of each category as the combination of centroid-contexts and contexts selected by the similarity measure.", "labels": [], "entities": []}, {"text": "Using the context-clusters as labeled training data, a Naive Bayes classifier can be built.", "labels": [], "entities": []}, {"text": "Since the Naive Bayes classifier can label all unlabeled documents for their category, we can finally obtain labeled training data (machine-labeled data).", "labels": [], "entities": []}, {"text": "When the machine-labeled data is used to learn a text classifier, there is another difficult in that they have more incorrectly labeled documents than manually labeled data.", "labels": [], "entities": []}, {"text": "Thus we develop and employ the TCFP classifiers with robustness from noisy data.", "labels": [], "entities": [{"text": "TCFP classifiers", "start_pos": 31, "end_pos": 47, "type": "TASK", "confidence": 0.6560419201850891}]}, {"text": "The rest of this paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 reviews previous works.", "labels": [], "entities": []}, {"text": "In section 3 and 4, we explain the proposed method in detail.", "labels": [], "entities": []}, {"text": "Section 5 is devoted to the analysis of the empirical results.", "labels": [], "entities": []}, {"text": "The final section describes conclusions and future works.", "labels": [], "entities": []}], "datasetContent": [{"text": "To test our method, we used three different kinds of data sets: UseNet newsgroups (20 Newsgroups), web pages (WebKB), and newswire articles (Reuters 21578).", "labels": [], "entities": [{"text": "Reuters 21578)", "start_pos": 141, "end_pos": 155, "type": "DATASET", "confidence": 0.9332510034243265}]}, {"text": "For fair evaluation in Newsgroups and WebKB, we employed the fivefold cross-validation method.", "labels": [], "entities": [{"text": "WebKB", "start_pos": 38, "end_pos": 43, "type": "DATASET", "confidence": 0.8263466358184814}]}, {"text": "The Newsgroups data set, collected by Ken Lang, contains about 20,000 articles evenly divided among 20 UseNet discussion groups . In this paper, we used only 16 categories after removing 4 categories: three miscellaneous categories (talk.politics.misc, talk.religion.misc, and comp.os.ms-windows.misc) and one duplicate meaning category (comp.sys. ibm.pc.hardware).", "labels": [], "entities": [{"text": "Newsgroups data set", "start_pos": 4, "end_pos": 23, "type": "DATASET", "confidence": 0.923746645450592}]}, {"text": "The second data set comes from the WebKB project at CMU ().", "labels": [], "entities": [{"text": "WebKB project at CMU", "start_pos": 35, "end_pos": 55, "type": "DATASET", "confidence": 0.8332932591438293}]}, {"text": "This data set contains web pages gathered from university computer science departments.", "labels": [], "entities": []}, {"text": "The Reuters 21578 Distribution 1.0 data set consists of 12,902 articles and 90 topic categories from the Reuters newswire.", "labels": [], "entities": [{"text": "Reuters 21578 Distribution 1.0 data set", "start_pos": 4, "end_pos": 43, "type": "DATASET", "confidence": 0.9820658465226492}, {"text": "Reuters newswire", "start_pos": 105, "end_pos": 121, "type": "DATASET", "confidence": 0.9797304570674896}]}, {"text": "Like other study in, we used the ten most populous categories to identify the news topic.", "labels": [], "entities": []}, {"text": "About 25% documents from training data of each data set are selected fora validation set.", "labels": [], "entities": []}, {"text": "We applied a statistical feature selection method (\u03c7 2 statistics) to a preprocessing stage for each classifier.", "labels": [], "entities": []}, {"text": "As performance measures, we followed the standard definition of recall, precision, and F 1 measure.", "labels": [], "entities": [{"text": "recall", "start_pos": 64, "end_pos": 70, "type": "METRIC", "confidence": 0.9996458292007446}, {"text": "precision", "start_pos": 72, "end_pos": 81, "type": "METRIC", "confidence": 0.999294638633728}, {"text": "F 1 measure", "start_pos": 87, "end_pos": 98, "type": "METRIC", "confidence": 0.9936903119087219}]}, {"text": "For evaluation performance average across categories, we used the micro-averaging method ().", "labels": [], "entities": []}, {"text": "Results on Reuters are reported as precision-recall breakeven points, which is a standard information retrieval measure for binary classification Title words in our experiment are selected according to category names of each data set (see as an example).", "labels": [], "entities": [{"text": "Reuters", "start_pos": 11, "end_pos": 18, "type": "DATASET", "confidence": 0.9626487493515015}, {"text": "precision-recall breakeven points", "start_pos": 35, "end_pos": 68, "type": "METRIC", "confidence": 0.945383886496226}]}], "tableCaptions": [{"text": " Table 2. The top micro-avg F1 scores and precision-recall breakeven points of each method.", "labels": [], "entities": [{"text": "F1", "start_pos": 28, "end_pos": 30, "type": "METRIC", "confidence": 0.7316716313362122}, {"text": "precision-recall breakeven", "start_pos": 42, "end_pos": 68, "type": "METRIC", "confidence": 0.9034993648529053}]}, {"text": " Table 3. The comparison of our method and the  supervised NB classifier", "labels": [], "entities": []}, {"text": " Table 4. The comparison of our method and enhancing  method", "labels": [], "entities": []}, {"text": " Table 5. The comparison of our method and sIB", "labels": [], "entities": []}]}