{"title": [], "abstractContent": [{"text": "In this paper we describe a biography summarization system using sentence classification and ideas from information retrieval.", "labels": [], "entities": [{"text": "biography summarization", "start_pos": 28, "end_pos": 51, "type": "TASK", "confidence": 0.7570879757404327}, {"text": "sentence classification", "start_pos": 65, "end_pos": 88, "type": "TASK", "confidence": 0.7235981374979019}]}, {"text": "Although the individual techniques are not new, assembling and applying them to generate multi-document biographies is new.", "labels": [], "entities": []}, {"text": "Our system was evaluated in DUC2004.", "labels": [], "entities": [{"text": "DUC2004", "start_pos": 28, "end_pos": 35, "type": "DATASET", "confidence": 0.961908221244812}]}, {"text": "It is among the top performers in task 5-short summaries focused by person questions.", "labels": [], "entities": [{"text": "summaries focused by person questions", "start_pos": 47, "end_pos": 84, "type": "TASK", "confidence": 0.8129418015480041}]}], "introductionContent": [{"text": "Automatic text summarization is one form of information management.", "labels": [], "entities": [{"text": "Automatic text summarization", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.6716688474019369}, {"text": "information management", "start_pos": 44, "end_pos": 66, "type": "TASK", "confidence": 0.8169113993644714}]}, {"text": "It is described as selecting a subset of sentences from a document that is in size a small percentage of the original and yet is just as informative.", "labels": [], "entities": []}, {"text": "Summaries can serve as surrogates of the full texts in the context of Information Retrieval (IR).", "labels": [], "entities": [{"text": "Information Retrieval (IR)", "start_pos": 70, "end_pos": 96, "type": "TASK", "confidence": 0.8585000157356262}]}, {"text": "Summaries are created from two types of text sources, a single document or a set of documents.", "labels": [], "entities": [{"text": "Summaries", "start_pos": 0, "end_pos": 9, "type": "TASK", "confidence": 0.9664520025253296}]}, {"text": "Multi-document summarization (MDS) is a natural and more elaborative extension of single-document summarization, and poses additional difficulties on algorithm design.", "labels": [], "entities": [{"text": "Multi-document summarization (MDS)", "start_pos": 0, "end_pos": 34, "type": "TASK", "confidence": 0.8690529942512513}]}, {"text": "Various kinds of summaries fall into two broad categories: generic summaries are the direct derivatives of the source texts; specialinterest summaries are generated in response to queries or topic-oriented questions.", "labels": [], "entities": [{"text": "summaries", "start_pos": 17, "end_pos": 26, "type": "TASK", "confidence": 0.9623775482177734}]}, {"text": "One important application of special-interest MDS systems is creating biographies to answer questions like \"who is Kofi Annan?\".", "labels": [], "entities": []}, {"text": "This task would be tedious for humans to perform in situations where the information related to the person is deeply and sparsely buried in large quantity of news texts that are not obviously related.", "labels": [], "entities": []}, {"text": "This paper describes a MDS biography system that responds to the \"who is\" questions by identifying information about the person-inquestion using IR and classification techniques, and creates multi-document biographical summaries.", "labels": [], "entities": []}, {"text": "The overall system design is shown in.", "labels": [], "entities": []}, {"text": "To determine what and how sentences are selected and ranked, a simple IR method and experimental classification methods both contributed.", "labels": [], "entities": []}, {"text": "The set of top-scoring sentences, after redundancy removal, is the resulting biography.", "labels": [], "entities": []}, {"text": "As yet, the system contains no inter-sentence 'smoothing' stage.", "labels": [], "entities": []}, {"text": "In this paper, work in related areas is discussed in Section 2; a description of our biography corpus used for training and testing the classification component is in Section 3; Section 4 explains the need and the process of classifying sentences according to their biographical state; the application of the classification method in biography extraction/summarization is described in Section 5; an accompanying evaluation on the quality of the biography summaries is shown in Section 6; and future work is outlined in Section 7.", "labels": [], "entities": [{"text": "biography extraction/summarization", "start_pos": 334, "end_pos": 368, "type": "TASK", "confidence": 0.7826206833124161}]}], "datasetContent": [{"text": "An intrinsic evaluation of biography summary was recently conducted under the guidance of Document Understanding Conference (DUC2004) using the automatic summarization evaluation tool ROUGE (Recall-Oriented Understudy for Gisting Evaluation) by.", "labels": [], "entities": [{"text": "Document Understanding Conference (DUC2004)", "start_pos": 90, "end_pos": 133, "type": "DATASET", "confidence": 0.6593210349480311}, {"text": "ROUGE", "start_pos": 184, "end_pos": 189, "type": "METRIC", "confidence": 0.9236583709716797}]}, {"text": "50 TREC English document clusters, each containing on average 10 news articles, were the input to the system.", "labels": [], "entities": []}, {"text": "Summary length was restricted to 665 bytes.", "labels": [], "entities": [{"text": "Summary length", "start_pos": 0, "end_pos": 14, "type": "METRIC", "confidence": 0.8828057646751404}]}, {"text": "Brute force truncation was applied on longer summaries.", "labels": [], "entities": [{"text": "Brute", "start_pos": 0, "end_pos": 5, "type": "METRIC", "confidence": 0.9617488384246826}]}, {"text": "The ROUGE-L metric is based on Longest Common Subsequence (LCS) overlap).", "labels": [], "entities": [{"text": "ROUGE-L", "start_pos": 4, "end_pos": 11, "type": "METRIC", "confidence": 0.9752072691917419}, {"text": "Longest Common Subsequence (LCS) overlap", "start_pos": 31, "end_pos": 71, "type": "METRIC", "confidence": 0.7692793778010777}]}, {"text": "shows that our system (86) performs at an equivalent level with the best systems 9 and 10, that is, they both lie within our system's 95% upper confidence interval.", "labels": [], "entities": []}, {"text": "The 2-class classification module was used in generating the answers.", "labels": [], "entities": [{"text": "2-class classification", "start_pos": 4, "end_pos": 26, "type": "TASK", "confidence": 0.6522198617458344}]}, {"text": "The figure also shows the performance data evaluated with lower and higher confidences set at 95%.", "labels": [], "entities": []}, {"text": "The performance data are from official DUC results.", "labels": [], "entities": [{"text": "DUC", "start_pos": 39, "end_pos": 42, "type": "DATASET", "confidence": 0.8039000034332275}]}, {"text": "shows the performance results of our system 86, using 10-class sentence classification, comparing to other systems from DUC by replicating the official evaluating process.", "labels": [], "entities": [{"text": "10-class sentence classification", "start_pos": 54, "end_pos": 86, "type": "TASK", "confidence": 0.6659907102584839}, {"text": "DUC", "start_pos": 120, "end_pos": 123, "type": "DATASET", "confidence": 0.952572762966156}]}, {"text": "Only system 9 performs slightly better with its score being higher than our system's 95% upper confidence interval.", "labels": [], "entities": []}, {"text": "A baseline system (5) that takes the first 665 bytes of the most recent text from the set as the resulting biography was also evaluated amongst the peer systems.", "labels": [], "entities": []}, {"text": "Clearly, humans still perform at a level much superior to any system.", "labels": [], "entities": []}, {"text": "Measuring fluency and coherence is also important in reflecting the true quality of machinegenerated summaries.", "labels": [], "entities": []}, {"text": "There is no automated tool for this purpose currently.", "labels": [], "entities": []}, {"text": "We plan to incorporate one for the future development of this work.", "labels": [], "entities": []}], "tableCaptions": []}