{"title": [{"text": "Explorations in Disambiguation Using XML Text Representation", "labels": [], "entities": [{"text": "Disambiguation", "start_pos": 16, "end_pos": 30, "type": "TASK", "confidence": 0.9676920771598816}, {"text": "XML Text Representation", "start_pos": 37, "end_pos": 60, "type": "TASK", "confidence": 0.5789168377717336}]}], "abstractContent": [{"text": "In SENSEVAL-3, CL Research participated in four tasks: English all-words, English lexical sample, disambiguation of WordNet glosses, and automatic labeling of semantic roles.", "labels": [], "entities": [{"text": "disambiguation of WordNet glosses", "start_pos": 98, "end_pos": 131, "type": "TASK", "confidence": 0.7139932960271835}, {"text": "automatic labeling of semantic roles", "start_pos": 137, "end_pos": 173, "type": "TASK", "confidence": 0.6673686265945434}]}, {"text": "This participation was performed within the development of CL Research's Knowledge Management System, which massively tags texts with syntactic, semantic, and discourse characterizations and attributes.", "labels": [], "entities": [{"text": "CL Research", "start_pos": 59, "end_pos": 70, "type": "DATASET", "confidence": 0.8171685039997101}]}, {"text": "This System is fully integrated with CL Research's DIMAP dictionary maintenance software, which provides access to one or more dictionaries for disambiguation and representation.", "labels": [], "entities": [{"text": "CL Research's DIMAP dictionary maintenance", "start_pos": 37, "end_pos": 79, "type": "DATASET", "confidence": 0.8756443758805593}, {"text": "disambiguation and representation", "start_pos": 144, "end_pos": 177, "type": "TASK", "confidence": 0.6598998606204987}]}, {"text": "Our core disambiguation functionality, unchanged since SENSEVAL-2, performed at a level comparable to our previous performance.", "labels": [], "entities": []}, {"text": "Our participation in the SENSEVAL-3 tasks was concerned primarily with text processing and representation issues and did not advance our disambiguation capabilities.", "labels": [], "entities": [{"text": "SENSEVAL-3 tasks", "start_pos": 25, "end_pos": 41, "type": "TASK", "confidence": 0.8779594600200653}, {"text": "text processing and representation", "start_pos": 71, "end_pos": 105, "type": "TASK", "confidence": 0.7265177816152573}]}], "introductionContent": [{"text": "CL Research participated in four SENSEVAL-3 tasks: English all-words, English lexical sample, disambiguation of WordNet glosses, and automatic labeling of semantic roles.", "labels": [], "entities": [{"text": "CL Research", "start_pos": 0, "end_pos": 11, "type": "DATASET", "confidence": 0.9061242640018463}, {"text": "SENSEVAL-3", "start_pos": 33, "end_pos": 43, "type": "TASK", "confidence": 0.9302762746810913}, {"text": "disambiguation of WordNet glosses", "start_pos": 94, "end_pos": 127, "type": "TASK", "confidence": 0.6604629307985306}, {"text": "automatic labeling of semantic roles", "start_pos": 133, "end_pos": 169, "type": "TASK", "confidence": 0.6737080216407776}]}, {"text": "We also ran the latter two tasks, but since their test sets were generated blindly, our results did not involve use of any prior information.", "labels": [], "entities": []}, {"text": "Our participation in these tasks is a continuation and extension of our efforts to perform NLP tasks within an integrated text processing system known as the Knowledge Management System (KMS).", "labels": [], "entities": []}, {"text": "KMS parses and processes text into an XML representation tagged with syntactic, semantic, and discourse properties.", "labels": [], "entities": [{"text": "KMS parses", "start_pos": 0, "end_pos": 10, "type": "TASK", "confidence": 0.6104598492383957}]}, {"text": "This representation is then used for such tasks as question answering and text summarization).", "labels": [], "entities": [{"text": "question answering", "start_pos": 51, "end_pos": 69, "type": "TASK", "confidence": 0.9074380099773407}, {"text": "text summarization", "start_pos": 74, "end_pos": 92, "type": "TASK", "confidence": 0.7264323532581329}]}, {"text": "The SENSEVAL-3 tasks were performed as part of CL Research's efforts to extend and improve the semantic characterizations in the KMS XML representations.", "labels": [], "entities": []}, {"text": "For each SENSEVAL-3 task, the corresponding texts in the test sets were processed using the general KMS functionality.", "labels": [], "entities": [{"text": "SENSEVAL-3 task", "start_pos": 9, "end_pos": 24, "type": "TASK", "confidence": 0.8469639420509338}]}, {"text": "However, since the texts involved in the SENSEVAL tasks were quite small, the amount of processing was quite minimal.", "labels": [], "entities": [{"text": "SENSEVAL tasks", "start_pos": 41, "end_pos": 55, "type": "TASK", "confidence": 0.9320048689842224}]}, {"text": "The descriptions below focus on the integration of disambiguation technology in a larger system and do not present any advancements in this technology.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1. All-Words Results  Run  Items  Precision  Nouns  895  0.523  Verbs  731  0.361  Adjectives  346  0.413  Adverbs  13  0.077  Hyphenated/U  56  0.179  Total  2041  0.434", "labels": [], "entities": []}, {"text": " Table 2. Lexical Sample Recall (Training)  Run  Items  Fine  Coarse  Adjectives  314  0.382  0.516  Nouns  3593  0.490  0.561  Verbs  3961  0.409  0.525  Total  7868  0.445  0.541", "labels": [], "entities": []}, {"text": " Table 3. Lexical Sample Recall (Test)  Run  Items  Fine  Coarse  Adjectives  159  0.409  0.503  Nouns  1806  0.488  0.576  Verbs  1977  0.419  0.540  Total  3942  0.450  0.555", "labels": [], "entities": []}, {"text": " Table  4. Among 10 participating runs, our precision was  the second lowest and our recall was the third lowest.  We were only able to identify 76.8 percent of the test  items with our current implementation. However, in  comparing our results with our performance in the  all-words and lexical sample tasks, the results here  are not significantly different. Moreover, these results  suggest a minimum that might be obtained with a  disambiguation system that relies only on picking the  first sense.", "labels": [], "entities": [{"text": "precision", "start_pos": 44, "end_pos": 53, "type": "METRIC", "confidence": 0.9994718432426453}, {"text": "recall", "start_pos": 85, "end_pos": 91, "type": "METRIC", "confidence": 0.9995467066764832}]}, {"text": " Table 4. Disambiguation of WordNet Glosses  Items Precision  Recall  \"Gold\" words  15179  0.449  0.345", "labels": [], "entities": [{"text": "WordNet Glosses  Items Precision  Recall  \"Gold\" words  15179  0.449  0.345", "start_pos": 28, "end_pos": 103, "type": "DATASET", "confidence": 0.5893970280885696}]}, {"text": " Table 5.  Precision and recall reflect standard measures of how  well we were able to identify frame elements. The  low recall is a reflection of the small percentage of  items attempted. The overlap indicates how well we  were able to identify the beginning and ending  positions of the constituents we identified.", "labels": [], "entities": [{"text": "Precision", "start_pos": 11, "end_pos": 20, "type": "METRIC", "confidence": 0.9921188354492188}, {"text": "recall", "start_pos": 25, "end_pos": 31, "type": "METRIC", "confidence": 0.9991869330406189}, {"text": "recall", "start_pos": 121, "end_pos": 127, "type": "METRIC", "confidence": 0.9958441853523254}]}, {"text": " Table 5. Automatic Labeling of Semantic Roles  Items Precision Overlap Recall Attempted  16279  0.583 0.480 0.111  19.0", "labels": [], "entities": [{"text": "Automatic Labeling of Semantic Roles  Items Precision Overlap Recall Attempted  16279", "start_pos": 10, "end_pos": 95, "type": "TASK", "confidence": 0.7725684426047585}]}]}