{"title": [{"text": "Combining Prosodic and Text Features for Segmentation of Mandarin Broadcast News", "labels": [], "entities": [{"text": "Segmentation", "start_pos": 41, "end_pos": 53, "type": "TASK", "confidence": 0.9682708978652954}, {"text": "Mandarin Broadcast News", "start_pos": 57, "end_pos": 80, "type": "DATASET", "confidence": 0.6824940244356791}]}], "abstractContent": [{"text": "Automatic topic segmentation, separation of a discourse stream into its constituent stories or topics, is a necessary preprocessing step for applications such as information retrieval, anaphora resolution, and summarization.", "labels": [], "entities": [{"text": "topic segmentation", "start_pos": 10, "end_pos": 28, "type": "TASK", "confidence": 0.6925535649061203}, {"text": "information retrieval", "start_pos": 162, "end_pos": 183, "type": "TASK", "confidence": 0.8069972693920135}, {"text": "anaphora resolution", "start_pos": 185, "end_pos": 204, "type": "TASK", "confidence": 0.7577024102210999}, {"text": "summarization", "start_pos": 210, "end_pos": 223, "type": "TASK", "confidence": 0.9928600192070007}]}, {"text": "While significant progress has been made in this area for text sources and for En-glish audio sources, little work has been done in automatic, acoustic feature-based segmentation of other languages.", "labels": [], "entities": []}, {"text": "In this paper, we consider exploiting both prosodic and text-based features for topic segmentation of Mandarin Chinese.", "labels": [], "entities": [{"text": "topic segmentation of Mandarin Chinese", "start_pos": 80, "end_pos": 118, "type": "TASK", "confidence": 0.7952007055282593}]}, {"text": "As atone language , Mandarin presents special challenges for applicability of intonation-based techniques, since the pitch contour is also used to establish lexical identity.", "labels": [], "entities": []}, {"text": "We demonstrate that intonational cues such as reduction in pitch and intensity at topic boundaries and increase in duration and pause still provide significant contrasts in Mandarin Chinese.", "labels": [], "entities": [{"text": "duration", "start_pos": 115, "end_pos": 123, "type": "METRIC", "confidence": 0.9294829964637756}]}, {"text": "We build a decision tree classifier that, based only on word and local context prosodic information without reference to term similarity, cue phrase, or sentence-level information, achieves boundary classification accuracy of 84.6-95.6% on a balanced test set.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 214, "end_pos": 222, "type": "METRIC", "confidence": 0.9553380012512207}]}, {"text": "We contrast these results with classification using text-based features, exploiting both text similarity and n-gram cues, to achieve accuracies between 77-95.6%, if silence features are used.", "labels": [], "entities": [{"text": "accuracies", "start_pos": 133, "end_pos": 143, "type": "METRIC", "confidence": 0.9891662001609802}]}, {"text": "Finally we integrate prosody, text, and silence features using a voting strategy to combine decision tree classifiers for each feature subset individually and all subsets jointly.", "labels": [], "entities": []}, {"text": "This voted decision tree classifier yields an overall classification accuracy of 96.85%, with 2.8% miss and 3.15% false alarm rates on a representative corpus sample, demonstrating synergistic combination of prosodic and text features for topic segmentation.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 69, "end_pos": 77, "type": "METRIC", "confidence": 0.9647490978240967}, {"text": "miss", "start_pos": 99, "end_pos": 103, "type": "METRIC", "confidence": 0.9955106973648071}, {"text": "false alarm", "start_pos": 114, "end_pos": 125, "type": "METRIC", "confidence": 0.9173052906990051}, {"text": "topic segmentation", "start_pos": 239, "end_pos": 257, "type": "TASK", "confidence": 0.7429986298084259}]}], "introductionContent": [{"text": "Natural spoken discourse is composed of a sequence of utterances, not independently generated or randomly strung together, but rather organized according to basic structural principles.", "labels": [], "entities": []}, {"text": "This structure in turn guides the interpretation of individual utterances and the discourse as a whole.", "labels": [], "entities": [{"text": "interpretation of individual utterances", "start_pos": 34, "end_pos": 73, "type": "TASK", "confidence": 0.7615830451250076}]}, {"text": "Formal written discourse signals a hierarchical, tree-based discourse structure explicitly by the division of the text into chapters, sections, paragraphs, and sentences.", "labels": [], "entities": []}, {"text": "This structure, in turn, identifies domains for interpretation; many systems for anaphora resolution rely on some notion of locality (.", "labels": [], "entities": [{"text": "anaphora resolution", "start_pos": 81, "end_pos": 100, "type": "TASK", "confidence": 0.7306296676397324}]}, {"text": "Similarly, this structure represents topical organization, and thus would be useful in information retrieval to select documents where the primary sections are on-topic, and, for summarization, to select information covering the different aspects of the topic.", "labels": [], "entities": [{"text": "information retrieval", "start_pos": 87, "end_pos": 108, "type": "TASK", "confidence": 0.7224542498588562}, {"text": "summarization", "start_pos": 179, "end_pos": 192, "type": "TASK", "confidence": 0.9918336868286133}]}, {"text": "Unfortunately, spoken discourse does not include the orthographic conventions that signal structural organization in written discourse.", "labels": [], "entities": []}, {"text": "Instead, one must infer the hierarchical structure of spoken discourse from other cues.", "labels": [], "entities": []}, {"text": "Prior research ( has shown that human labelers can more sharply, consistently, and confidently identify discourse structure in a word-level transcription when an original audio recording is available than they canon the basis of the transcribed text alone.", "labels": [], "entities": []}, {"text": "This finding indicates that substantial additional information about the structure of the discourse is encoded in the acoustic-prosodic features of the utterance.", "labels": [], "entities": []}, {"text": "Given the often errorful transcriptions available for large speech corpora, we choose to focus hereon fully exploiting the prosodic cues to discourse structure present in the original speech.", "labels": [], "entities": []}, {"text": "We then compare the effectiveness of a pure prosodic classification to text-based and mixed text and prosodic based classification.", "labels": [], "entities": []}, {"text": "In the current set of experiments, we concentrate on sequential segmentation of news broadcasts into individual stories.", "labels": [], "entities": [{"text": "sequential segmentation of news broadcasts into individual stories", "start_pos": 53, "end_pos": 119, "type": "TASK", "confidence": 0.8371484130620956}]}, {"text": "While a richer hierarchical segmentation is ultimately desirable, sequential story segmentation provides a natural starting point.", "labels": [], "entities": [{"text": "sequential story segmentation", "start_pos": 66, "end_pos": 95, "type": "TASK", "confidence": 0.6440296173095703}]}, {"text": "This level of segmentation can also be most reliably performed by human labelers and thus can be considered most robust, and segmented data sets are publicly available.", "labels": [], "entities": []}, {"text": "Furthermore, we apply prosodic-based segmentation to Mandarin Chinese, in addition to textual features.", "labels": [], "entities": []}, {"text": "Not only is the use of prosodic cues to topic segmentation much less well-studied in general than is the use of text cues, but the use of prosodic cues has been largely limited to English and other European languages.", "labels": [], "entities": [{"text": "topic segmentation", "start_pos": 40, "end_pos": 58, "type": "TASK", "confidence": 0.8046277463436127}]}], "datasetContent": [{"text": "The resulting classifier achieved 95.6% accuracy, with 2% missed boundaries and 7% false alarms.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 40, "end_pos": 48, "type": "METRIC", "confidence": 0.9989511966705322}]}, {"text": "This effectiveness is a substantial improvement over the sample baseline of 50%.", "labels": [], "entities": []}, {"text": "A portion of the decision tree is reproduced in.", "labels": [], "entities": []}, {"text": "Inspection of the tree indicates the key role of silence as well as the use of both contextual and purely local features of pitch, intensity, and duration.", "labels": [], "entities": [{"text": "duration", "start_pos": 146, "end_pos": 154, "type": "METRIC", "confidence": 0.9689716100692749}]}, {"text": "The classifier relies on the theoretically and empirically grounded features of pitch, intensity, duration, and silence, where it has been suggested that higher pitch and wider range are associated with topic initiation and lower pitch or narrower range is associated with topic finality.", "labels": [], "entities": [{"text": "duration", "start_pos": 98, "end_pos": 106, "type": "METRIC", "confidence": 0.9721284508705139}, {"text": "topic initiation", "start_pos": 203, "end_pos": 219, "type": "TASK", "confidence": 0.7972672879695892}, {"text": "topic finality", "start_pos": 273, "end_pos": 287, "type": "TASK", "confidence": 0.7431312203407288}]}, {"text": "We performed a set of contrastive experiments to explore the impact of different lexical tones on classification accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 113, "end_pos": 121, "type": "METRIC", "confidence": 0.8177207708358765}]}, {"text": "We grouped words based on the lexical tone of the initial syllable into high, rising, low, and falling.", "labels": [], "entities": []}, {"text": "We found no tone-based differences in classification with all groups achieving 94-96% accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 86, "end_pos": 94, "type": "METRIC", "confidence": 0.9938881993293762}]}, {"text": "Since the magnitude of the difference in pitch based on discourse position is comparable to that based on lexical tone identity, and the overlap between pitch values in non-final and final positions is relatively small, we obtain consistent results.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Reduction in classification accuracy with removal of features. Each row is labeled with the feature  that is newly removed from the set of available features.", "labels": [], "entities": [{"text": "classification", "start_pos": 23, "end_pos": 37, "type": "TASK", "confidence": 0.942512571811676}, {"text": "accuracy", "start_pos": 38, "end_pos": 46, "type": "METRIC", "confidence": 0.9592664837837219}]}]}