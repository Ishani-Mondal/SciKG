{"title": [{"text": "A Statistical Constraint Dependency Grammar (CDG) Parser", "labels": [], "entities": [{"text": "Statistical Constraint Dependency Grammar (CDG", "start_pos": 2, "end_pos": 48, "type": "TASK", "confidence": 0.7540450294812521}, {"text": "Parser", "start_pos": 50, "end_pos": 56, "type": "DATASET", "confidence": 0.2708079516887665}]}], "abstractContent": [{"text": "CDG represents a sentence's grammatical structure as assignments of dependency relations to functional variables associated with each word in the sentence.", "labels": [], "entities": []}, {"text": "In this paper, we describe a statistical CDG (SCDG) parser that performs parsing incre-mentally and evaluate it on the Wall Street Journal Penn Treebank.", "labels": [], "entities": [{"text": "Wall Street Journal Penn Treebank", "start_pos": 119, "end_pos": 152, "type": "DATASET", "confidence": 0.9711578607559204}]}, {"text": "Using a tight integration of multiple knowledge sources, together with distance modeling and synergistic dependencies, this parser achieves a parsing accuracy comparable to several state-of-the-art context-free grammar (CFG) based statistical parsers using a dependency-based evaluation metric.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 150, "end_pos": 158, "type": "METRIC", "confidence": 0.8353196382522583}]}, {"text": "Factors contributing to the SCDG parser's performance are analyzed.", "labels": [], "entities": [{"text": "SCDG parser", "start_pos": 28, "end_pos": 39, "type": "TASK", "confidence": 0.7494246363639832}]}], "introductionContent": [{"text": "Statistical parsing has been an important focus of recent research).", "labels": [], "entities": [{"text": "Statistical parsing", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.8809830248355865}]}, {"text": "Several of these parsers generate constituents by conditioning probabilities on non-terminal labels, part-of-speech (POS) tags, and some headword information).", "labels": [], "entities": []}, {"text": "They utilize non-terminals that go beyond the level of a single word and do not explicitly use lexical features.", "labels": [], "entities": []}, {"text": "Collins' Model 2 parser (1999) learns the distinction between complements and adjuncts by using heuristics during training, distinguishes complement and adjunct non-terminals, and includes a probabilistic choice of left and right subcategorization frames, while his Model 3 parser uses gap features to model wh-movement.", "labels": [], "entities": []}, {"text": "Charniak) developed a state-of-the-art statistical CFG parser and then built an effective language model based on it).", "labels": [], "entities": [{"text": "CFG parser", "start_pos": 51, "end_pos": 61, "type": "TASK", "confidence": 0.6075024753808975}]}, {"text": "But his parser and language model were originally designed to analyze complete sentences.", "labels": [], "entities": []}, {"text": "Among the statistical dependency grammar parsers, best probabilistic dependency model used unlabeled links between words and their heads, as well as between words and their complements and adjuncts.", "labels": [], "entities": []}, {"text": "However, the parser does not distinguish between complements and adjuncts or model whmovement.", "labels": [], "entities": []}, {"text": "Collins' bilexical dependency grammar parser (1999) used head-modifier relations between pairs of words much as in a dependency grammar, but they are limited to relationships between words in reduced sentences with base NPs.", "labels": [], "entities": []}, {"text": "Our research interest focuses on building a high quality statistical parser for language modeling.", "labels": [], "entities": [{"text": "language modeling", "start_pos": 80, "end_pos": 97, "type": "TASK", "confidence": 0.7367809116840363}]}, {"text": "We chose CDG as the underlying grammar for several reasons.", "labels": [], "entities": []}, {"text": "Since CDGs can be lexicalized at the wordlevel, a CDG parser-based language model is an important alternative to CFG parser-based models, which must model both non-terminals and terminals.", "labels": [], "entities": []}, {"text": "Furthermore, the lexicalization of CDG parse rules is able to include not only lexical category information, but also a rich set of lexical features to model subcategorization and wh-movement.", "labels": [], "entities": []}, {"text": "By using CDG, our statistical model is able to distinguish between adjuncts and complements.", "labels": [], "entities": []}, {"text": "Additionally, CDG is more powerful than CFG and is able to model languages with crossing dependencies and free word ordering.", "labels": [], "entities": [{"text": "CFG", "start_pos": 40, "end_pos": 43, "type": "DATASET", "confidence": 0.8695381283760071}]}, {"text": "In this paper, we describe and evaluate a statistical CDG parser for which the probabilities of parse prefix hypotheses are incrementally updated when the next input word is available, i.e., it parses incrementally.", "labels": [], "entities": [{"text": "statistical CDG parser", "start_pos": 42, "end_pos": 64, "type": "TASK", "confidence": 0.5674848357836405}]}, {"text": "Section 2 describes how CDG represents a sentence's parse and then defines a Super-ARV, which is a lexicalization of CDG parse rules used in our parsing model.", "labels": [], "entities": []}, {"text": "Section 3 presents the parsing model, while Section 4 motivates the evaluation metric used to evaluate our parser.", "labels": [], "entities": [{"text": "parsing", "start_pos": 23, "end_pos": 30, "type": "TASK", "confidence": 0.9733291268348694}]}, {"text": "Section 5 presents and discusses the experimental results.", "labels": [], "entities": []}], "datasetContent": [{"text": "Since our parser is trained using a CFG-to-CDG transformer, which maps a CFG parse tree to a unique CDG parse, it is sensible to evaluate our parser's accuracy using gold standard CDG parse relations.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 151, "end_pos": 159, "type": "METRIC", "confidence": 0.9987473487854004}]}, {"text": "Furthermore, in the 1998 Johns Hopkins Summer workshop final report), Collins et al. pointed out that in general the mapping from dependencies to tree structures is one-to-many: there are many possible trees that can be generated fora given dependency structure since, although generally trees in the Penn Treebank corpus are quite flat, they are not consistently \"flat.\"", "labels": [], "entities": [{"text": "Johns Hopkins Summer workshop final report", "start_pos": 25, "end_pos": 67, "type": "DATASET", "confidence": 0.8211338023344675}, {"text": "Penn Treebank corpus", "start_pos": 301, "end_pos": 321, "type": "DATASET", "confidence": 0.9890379110972086}]}, {"text": "This variability adds a non-deterministic aspect to the mapping from CDG dependencies to CFG parse trees that could cause spurious PARSEVAL scoring errors.", "labels": [], "entities": []}, {"text": "Additionally, when there are crossing dependencies, then no tree can be generated for that set of dependencies.", "labels": [], "entities": []}, {"text": "Consequently, we have opted to use a transformer to convert CFG trees to CDG parses and define anew dependency-based metric adapted from.", "labels": [], "entities": []}, {"text": "This differs from Eisner's (1996) precision and recall metrics which use no label information and score only parent (governor) assignments, as in traditional dependency grammars.", "labels": [], "entities": [{"text": "precision", "start_pos": 34, "end_pos": 43, "type": "METRIC", "confidence": 0.9976320266723633}, {"text": "recall", "start_pos": 48, "end_pos": 54, "type": "METRIC", "confidence": 0.9600668549537659}]}, {"text": "We will evaluate role value labeled precision and recall on all roles of the parse, as well as the governoronly portion of a parse.", "labels": [], "entities": [{"text": "precision", "start_pos": 36, "end_pos": 45, "type": "METRIC", "confidence": 0.9721017479896545}, {"text": "recall", "start_pos": 50, "end_pos": 56, "type": "METRIC", "confidence": 0.9993084669113159}]}, {"text": "Eisner and Lin argued that dependency link evaluation metrics are valuable for comparing parsers since they are less sensitive than PARSEVAL to single misattachment errors that may cause significant error propagation to other constituents.", "labels": [], "entities": []}, {"text": "This, together with the fact that we must train our parser using CDG parses generated in a lossy manner from a CFG treebank, we chose to use RLP and RLR to compare our parsing accuracy with several state-ofthe-art parsers.", "labels": [], "entities": [{"text": "CFG treebank", "start_pos": 111, "end_pos": 123, "type": "DATASET", "confidence": 0.9350487291812897}, {"text": "RLP", "start_pos": 141, "end_pos": 144, "type": "METRIC", "confidence": 0.9268215298652649}, {"text": "RLR", "start_pos": 149, "end_pos": 152, "type": "METRIC", "confidence": 0.8746969699859619}, {"text": "accuracy", "start_pos": 176, "end_pos": 184, "type": "METRIC", "confidence": 0.8581605553627014}]}, {"text": "All of the evaluations were performed on the Wall Street Journal Penn Treebank task.", "labels": [], "entities": [{"text": "Wall Street Journal Penn Treebank task", "start_pos": 45, "end_pos": 83, "type": "DATASET", "confidence": 0.9669113357861837}]}, {"text": "Following the traditional data setup, sections 02-21 are used for training our parser, section 23 is used for testing, and section 24 is used as the development set for parameter tuning and debugging.", "labels": [], "entities": []}, {"text": "As in, we evaluate on all sentences with length \u2264 40 words (2,245 sentences) and length \u2264 100 words (2,416 sentences).", "labels": [], "entities": [{"text": "length", "start_pos": 81, "end_pos": 87, "type": "METRIC", "confidence": 0.965336263179779}]}, {"text": "For training our probabilistic CDG parser on this task, the CFG bracketing of the training set is trans-BASIC PARSING ALGORITHM 1.", "labels": [], "entities": [{"text": "PARSING ALGORITHM 1", "start_pos": 110, "end_pos": 129, "type": "METRIC", "confidence": 0.8558392326037089}]}, {"text": "Using SuperARV tagging on word sequence w1, . .", "labels": [], "entities": [{"text": "SuperARV tagging", "start_pos": 6, "end_pos": 22, "type": "TASK", "confidence": 0.6607102006673813}]}, {"text": ", wn, obtain a set of N-best SuperARV sequences with each element consisting of n (word, SuperARV) tuples, denoted \ud97b\udf59w1, s1\ud97b\udf59, . .", "labels": [], "entities": []}, {"text": ", \ud97b\udf59wn, sn\ud97b\udf59, which we will call an assignment.", "labels": [], "entities": []}, {"text": "2. For each SuperARV assignment, initialize the stack of parse prefixes with this assignment: / * From left-to-right, process each \ud97b\udf59word, tag\ud97b\udf59 of the assignment and generate parse prefixes * / fork : = 1, n do Sort the parse prefixes in the stack according to logP r(T ) and apply pruning using the thresholds.", "labels": [], "entities": []}, {"text": "3. After processing w1, . .", "labels": [], "entities": []}, {"text": ", wn, pick the parse with the highest logP r(T ) in the stack as the parse for that sentence.", "labels": [], "entities": []}, {"text": "formed into CDG annotations using a CFG-to-CDG transformer.", "labels": [], "entities": []}, {"text": "Note that the soundness of the CFG-to-CDG transformer was evaluated by examining the CDG parses generated from the transformer on the Penn Treebank development set to ensure that they were correct given our grammar definition.", "labels": [], "entities": [{"text": "CFG-to-CDG transformer", "start_pos": 31, "end_pos": 53, "type": "DATASET", "confidence": 0.8998820781707764}, {"text": "Penn Treebank development set", "start_pos": 134, "end_pos": 163, "type": "DATASET", "confidence": 0.9954159408807755}]}], "tableCaptions": [{"text": " Table 2: Results on Section 23 of the WSJ Penn Tree-", "labels": [], "entities": [{"text": "Section 23 of the WSJ Penn Tree-", "start_pos": 21, "end_pos": 53, "type": "DATASET", "confidence": 0.731065958738327}]}, {"text": " Table 3: Results on Section 23 of the WSJ Penn Tree-", "labels": [], "entities": [{"text": "Section 23 of the WSJ Penn Tree-", "start_pos": 21, "end_pos": 53, "type": "DATASET", "confidence": 0.721310131251812}]}, {"text": " Table 4: Evaluation of five models on Section 23 sentences with and without traces: L denotes the best loosely", "labels": [], "entities": []}]}