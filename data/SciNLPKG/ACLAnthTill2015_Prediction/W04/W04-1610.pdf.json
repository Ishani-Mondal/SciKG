{"title": [{"text": "Automatic Arabic Document Categorization Based on the Na\u00efve Bayes Algorithm", "labels": [], "entities": [{"text": "Automatic Arabic Document Categorization", "start_pos": 0, "end_pos": 40, "type": "TASK", "confidence": 0.5595969706773758}, {"text": "Na\u00efve Bayes Algorithm", "start_pos": 54, "end_pos": 75, "type": "DATASET", "confidence": 0.8787239789962769}]}], "abstractContent": [{"text": "This paper deals with automatic classification of Arabic web documents.", "labels": [], "entities": [{"text": "automatic classification of Arabic web documents", "start_pos": 22, "end_pos": 70, "type": "TASK", "confidence": 0.8166673878828684}]}, {"text": "Such a classification is very useful for affording directory search functionality, which has been used by many web portals and search engines to cope with an ever-increasing number of documents on the web.", "labels": [], "entities": []}, {"text": "In this paper, Naive Bayes (NB) which is a statistical machine learning algorithm, is used to classify non-vocalized Arabic web documents (after their words have been transformed to the corresponding canonical form, i.e., roots) to one of five pre-defined categories.", "labels": [], "entities": []}, {"text": "Cross validation experiments are used to evaluate the NB categorizer.", "labels": [], "entities": [{"text": "NB", "start_pos": 54, "end_pos": 56, "type": "DATASET", "confidence": 0.756309449672699}]}, {"text": "The data set used during these experiments consists of 300 web documents per category.", "labels": [], "entities": []}, {"text": "The results of cross validation in the leave-one-out experiment show that, using 2,000 terms/roots, the categorization accuracy varies from one category to another with an average accuracy overall categories of 68.78 %.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 119, "end_pos": 127, "type": "METRIC", "confidence": 0.9611265659332275}, {"text": "accuracy", "start_pos": 180, "end_pos": 188, "type": "METRIC", "confidence": 0.9950934648513794}]}, {"text": "Furthermore, the best categorization performance by category during cross validation experiments goes up to 92.8%.", "labels": [], "entities": []}, {"text": "Further tests carried out on a manually collected evaluation set which consists of 10 documents from each of the 5 categories, show that the overall classification accuracy achieved overall categories is 62%, and that the best result by category reaches 90%.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 164, "end_pos": 172, "type": "METRIC", "confidence": 0.9731727242469788}]}], "introductionContent": [{"text": "With the explosive growth of text documents on the web, relevant information retrieval has become a crucial task to satisfy the needs of different end users.", "labels": [], "entities": [{"text": "relevant information retrieval", "start_pos": 56, "end_pos": 86, "type": "TASK", "confidence": 0.6597291628519694}]}, {"text": "To this end, automatic text categorization has emerged as away to cope with such a problem.", "labels": [], "entities": [{"text": "automatic text categorization", "start_pos": 13, "end_pos": 42, "type": "TASK", "confidence": 0.5683613121509552}]}, {"text": "Automatic text (or document) categorization attempts to replace and save human effort required in performing manual categorization.", "labels": [], "entities": [{"text": "Automatic text (or document) categorization", "start_pos": 0, "end_pos": 43, "type": "TASK", "confidence": 0.5855315157345363}]}, {"text": "It consists of assigning and labeling documents using a set of predefined categories based on document contents.", "labels": [], "entities": []}, {"text": "As such, one of the primary objectives of automatic text categorization has been the enhancement and the support of information retrieval tasks to tackle problems, such as information filtering and routing, clustering of related documents, and the classification of documents into pre-specified subject themes.", "labels": [], "entities": [{"text": "automatic text categorization", "start_pos": 42, "end_pos": 71, "type": "TASK", "confidence": 0.6022026240825653}, {"text": "information retrieval", "start_pos": 116, "end_pos": 137, "type": "TASK", "confidence": 0.7270660102367401}, {"text": "information filtering and routing", "start_pos": 172, "end_pos": 205, "type": "TASK", "confidence": 0.7658767998218536}, {"text": "clustering of related documents", "start_pos": 207, "end_pos": 238, "type": "TASK", "confidence": 0.8697185218334198}, {"text": "classification of documents into pre-specified subject themes", "start_pos": 248, "end_pos": 309, "type": "TASK", "confidence": 0.7796804394040789}]}, {"text": "Automatic text categorization has been used in search engines, digital library systems, and document management systems.", "labels": [], "entities": [{"text": "Automatic text categorization", "start_pos": 0, "end_pos": 29, "type": "TASK", "confidence": 0.5991680522759756}]}, {"text": "Such applications have included electronic email filtering, newsgroups classification, and survey data grouping.", "labels": [], "entities": [{"text": "electronic email filtering", "start_pos": 32, "end_pos": 58, "type": "TASK", "confidence": 0.6304820676644644}, {"text": "newsgroups classification", "start_pos": 60, "end_pos": 85, "type": "TASK", "confidence": 0.6765977442264557}, {"text": "survey data grouping", "start_pos": 91, "end_pos": 111, "type": "TASK", "confidence": 0.625182718038559}]}, {"text": "Barq for instance uses automatic categorization to provide similar documents feature (.", "labels": [], "entities": [{"text": "Barq", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.8800945281982422}]}, {"text": "In this paper, NB which is a statistical machine learning algorithm is used to learn to classify non-vocalized 1 Arabic web text documents.", "labels": [], "entities": [{"text": "classify non-vocalized 1 Arabic web text documents", "start_pos": 88, "end_pos": 138, "type": "TASK", "confidence": 0.7831514307430812}]}, {"text": "This paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2, briefly describe related works in the area of automatic text categorization.", "labels": [], "entities": [{"text": "automatic text categorization", "start_pos": 57, "end_pos": 86, "type": "TASK", "confidence": 0.6558296183745066}]}, {"text": "Section 3 describes the preprocessing undergone by documents for the purpose of categorization; it describes in particular the preprocessing specific to the Arabic language.", "labels": [], "entities": []}, {"text": "In section 4 Na\u00efve Bayes (NB), the learning algorithm used in this paper for document categorization is presented.", "labels": [], "entities": [{"text": "Na\u00efve Bayes (NB)", "start_pos": 13, "end_pos": 29, "type": "DATASET", "confidence": 0.746704351902008}, {"text": "document categorization", "start_pos": 77, "end_pos": 100, "type": "TASK", "confidence": 0.7637945711612701}]}, {"text": "Section 5 outlines the experimental setting, as well as the experiments carried out to evaluate the performance of the NB classifier.", "labels": [], "entities": [{"text": "NB classifier", "start_pos": 119, "end_pos": 132, "type": "DATASET", "confidence": 0.7724043428897858}]}, {"text": "It also gives the numerical results with their analysis and interpretation.", "labels": [], "entities": []}, {"text": "Section 6 summarizes the work and suggests some ideas for future works.", "labels": [], "entities": []}], "datasetContent": [{"text": "For classification problems, it is customary to measure a classifier's performance in terms of classification error rate.", "labels": [], "entities": [{"text": "classification problems", "start_pos": 4, "end_pos": 27, "type": "TASK", "confidence": 0.9426538646221161}, {"text": "classification error rate", "start_pos": 95, "end_pos": 120, "type": "METRIC", "confidence": 0.7285537123680115}]}, {"text": "A data set of documents is used with known category/class label L(D k ) for each document D k . The set is split into two subsets: a training set and a testing set.", "labels": [], "entities": []}, {"text": "The trained classifier is used to assign a class AC(D k ) using Equation (3) to each document (D k ) in the test set, as if its true class label were not known.", "labels": [], "entities": [{"text": "Equation (3)", "start_pos": 64, "end_pos": 76, "type": "METRIC", "confidence": 0.9340704381465912}]}, {"text": "If AC(D k ) matches L(D k ), the classification is considered correct; otherwise, it is counted as an error: For a given class, the error rate is computed as the ratio of the number of errors made on the whole test set of unlabeled documents (X u ) to the cardinality |X u | of this set.", "labels": [], "entities": [{"text": "error rate", "start_pos": 132, "end_pos": 142, "type": "METRIC", "confidence": 0.9635326564311981}]}, {"text": "For a given class Ci , the error rate is computed as: In order to measure the performance of the NB algorithm on Arabic document classification, we conducted several experiments: we performed cross validation using the original space (using all the words in the documents), cross validation experiments based on feature selection (using a subset of terms/roots only), and experiments based on an independently constructed evaluation set.", "labels": [], "entities": [{"text": "Arabic document classification", "start_pos": 113, "end_pos": 143, "type": "TASK", "confidence": 0.5632921159267426}]}, {"text": "The following paragraphs describe the data set used, and the experiments.", "labels": [], "entities": []}, {"text": "In these experiments, each document in data set X is represented by all word roots in the document.", "labels": [], "entities": []}, {"text": "The cross validation experiments described in, is conducted.", "labels": [], "entities": []}, {"text": "reports the error rates obtained overall categories during the cross validation experiments.", "labels": [], "entities": []}, {"text": "The smallest error rate is obtained in the leave-one-out experiment (as illustrated in)., and represent, respectively, the confusion matrices of the cross validation experiments.", "labels": [], "entities": [{"text": "error rate", "start_pos": 13, "end_pos": 23, "type": "METRIC", "confidence": 0.9268609881401062}]}, {"text": "The percentages reported in an entry of a confusion matrix correspond to the percentage of documents that are known to actually belong to the category given by the row header of the matrix, but that are assigned by NB to the category given by the column header.", "labels": [], "entities": []}, {"text": "Cross validation has been used to determine the average performance of NB for Arabic text categorization, and to design training sets that produce the best performance.", "labels": [], "entities": [{"text": "Cross validation", "start_pos": 0, "end_pos": 16, "type": "TASK", "confidence": 0.6708518862724304}, {"text": "Arabic text categorization", "start_pos": 78, "end_pos": 104, "type": "TASK", "confidence": 0.5476248065630595}]}, {"text": "This experiment, based on a separately and independently constructed evaluation set, is designed to evaluate the performance of NB on a set of documents that have never been submitted to the classifier.", "labels": [], "entities": []}, {"text": "For this purpose, we further carefully collected manually 10 documents from Aljazeera.net for each of the 5 predefined categories.", "labels": [], "entities": [{"text": "Aljazeera.net", "start_pos": 76, "end_pos": 89, "type": "DATASET", "confidence": 0.9264397621154785}]}, {"text": "For each category, we have selected documents that best represent the variability in the category.", "labels": [], "entities": []}, {"text": "We refer to this collection of documents as the evaluation set.", "labels": [], "entities": []}, {"text": "This set is presented to the classifier for categorization.", "labels": [], "entities": []}, {"text": "For testing on the evaluation set, trained NB classifiers are used.", "labels": [], "entities": []}, {"text": "For each category, we use the NB classifier that has been trained using the training set that produced the best category classification accuracy in cross validation experiments.", "labels": [], "entities": [{"text": "category classification", "start_pos": 112, "end_pos": 135, "type": "TASK", "confidence": 0.6759195923805237}, {"text": "accuracy", "start_pos": 136, "end_pos": 144, "type": "METRIC", "confidence": 0.8116614818572998}]}, {"text": "In our case, we have used the whole set as a training set (1,500) represented by 2,000 terms since the best cross validation accuracy was obtained in leaveone-out experiment with 2,000 terms.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 125, "end_pos": 133, "type": "METRIC", "confidence": 0.8903283476829529}]}, {"text": "summarizes NB's performance results when tested using the evaluation set.", "labels": [], "entities": []}, {"text": "The results obtained have shown higher performance for the Sports and the Business categories with a classification accuracy that is higher than 70%.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 116, "end_pos": 124, "type": "METRIC", "confidence": 0.7974910140037537}]}, {"text": "The performance of other categories ranges from 40% to 60%.", "labels": [], "entities": []}, {"text": "The average accuracy overall categories is 62%.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 12, "end_pos": 20, "type": "METRIC", "confidence": 0.9995784163475037}]}, {"text": "The results obtained in the evaluation set experiment are very consistent with the performance obtained in cross validation experiments.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1. The error rates of NB over all categories in", "labels": [], "entities": [{"text": "error rates", "start_pos": 14, "end_pos": 25, "type": "METRIC", "confidence": 0.981490820646286}]}, {"text": " Table 2. Confusion Matrix results for cross  validation, with no feature extraction (1/3-2/3).", "labels": [], "entities": [{"text": "cross  validation", "start_pos": 39, "end_pos": 56, "type": "TASK", "confidence": 0.6746949851512909}]}, {"text": " Table 3. Confusion Matrix results for cross  validation, with no feature extraction (1/2-1/2).", "labels": [], "entities": [{"text": "cross  validation", "start_pos": 39, "end_pos": 56, "type": "TASK", "confidence": 0.6752320528030396}]}, {"text": " Table 4. Confusion Matrix results for cross  validation, with no feature extraction (2/3-1/3).", "labels": [], "entities": [{"text": "cross  validation", "start_pos": 39, "end_pos": 56, "type": "TASK", "confidence": 0.6747120320796967}]}, {"text": " Table 5. Confusion Matrix results for cross validation,  with no feature extraction (Leave-one-out)", "labels": [], "entities": [{"text": "cross validation", "start_pos": 39, "end_pos": 55, "type": "TASK", "confidence": 0.76165372133255}, {"text": "feature extraction", "start_pos": 66, "end_pos": 84, "type": "TASK", "confidence": 0.6606516540050507}]}, {"text": " Table 6. The performance  levels obtained are comparable to those obtained  without feature selection.", "labels": [], "entities": []}, {"text": " Table 7. Classification accuracy on the evaluation set  using Leave-one-out and TF-IDF with 2,000 roots/terms", "labels": [], "entities": [{"text": "Classification", "start_pos": 10, "end_pos": 24, "type": "TASK", "confidence": 0.8073461055755615}, {"text": "accuracy", "start_pos": 25, "end_pos": 33, "type": "METRIC", "confidence": 0.9741462469100952}, {"text": "TF-IDF", "start_pos": 81, "end_pos": 87, "type": "METRIC", "confidence": 0.676772952079773}]}]}