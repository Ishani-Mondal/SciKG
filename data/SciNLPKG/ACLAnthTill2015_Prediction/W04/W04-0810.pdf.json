{"title": [{"text": "A First Evaluation of Logic Form Identification Systems", "labels": [], "entities": [{"text": "Logic Form Identification", "start_pos": 22, "end_pos": 47, "type": "TASK", "confidence": 0.7138972282409668}]}], "abstractContent": [{"text": "This paper presents a first experience with evaluating sytems that address the issue of Logic Form Identification (LFi).", "labels": [], "entities": [{"text": "Logic Form Identification (LFi)", "start_pos": 88, "end_pos": 119, "type": "TASK", "confidence": 0.7768085698286692}]}, {"text": "A Gold Standard approach was used in which experts provide solutions to test data.", "labels": [], "entities": []}, {"text": "The expert solutions, the gold standard, are then compared against outputs from participanting systems and different metrics observed.", "labels": [], "entities": []}, {"text": "We proposed a few novel metrics, including precision and recall, that are further used to provide comparative results.", "labels": [], "entities": [{"text": "precision", "start_pos": 43, "end_pos": 52, "type": "METRIC", "confidence": 0.9995156526565552}, {"text": "recall", "start_pos": 57, "end_pos": 63, "type": "METRIC", "confidence": 0.998268723487854}]}, {"text": "The test data included 4155 arguments and 2398 predicates grouped in 300 sentences.", "labels": [], "entities": []}], "introductionContent": [{"text": "The goal of a Logic Form Identification (LFi) task is to evaluate the performance of different methods addressing the issue of LFi.", "labels": [], "entities": [{"text": "Logic Form Identification (LFi) task", "start_pos": 14, "end_pos": 50, "type": "TASK", "confidence": 0.8034683806555611}]}, {"text": "The Logic Form (LF) that we use is a flat, scope-free first order logic representation that embeds lexical and syntactic information.", "labels": [], "entities": []}, {"text": "Given a set of English sentences, participating systems were supposed to return the sentences in Logic Form as in the example below.", "labels": [], "entities": []}, {"text": "Input: The Earth provides the food we eat everyday.", "labels": [], "entities": []}, {"text": "Output: Earth:n (x1) provide:v (e1, x1, x2) food:n (x2) we(x3) eat:v (e2, x3, x2; x4) day:n (x4) The general approach adopted for evaluation was a gold standard approach in which the test data is first correctly mapped onto its corresponding LF by a team of experts and then this correct LF is automatically compared against outputs provided by participating sytems.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 2: Comparative view of valid submissions.", "labels": [], "entities": []}]}