{"title": [{"text": "On the use of confidence for statistical decision in dialogue strategies", "labels": [], "entities": []}], "abstractContent": [{"text": "This paper describes an interpretation and decision strategy that minimizes interpretation errors and perform dialogue actions which may not depend on the hypothesized concepts only, but also on confidence of what has been recognized.", "labels": [], "entities": []}, {"text": "The concepts introduced here are applied in a system which integrates language and interpretation models into Stochastic Finite State Transducers (SFST).", "labels": [], "entities": []}, {"text": "Furthermore, acoustic , linguistic and semantic confidence measures on the hypothesized word sequences are made available to the dialogue strategy.", "labels": [], "entities": []}, {"text": "By evaluating predicates related to these confidence measures, a decision tree automatically learn a decision strategy for rescoring a n-best list of candidates representing a user's utterance.", "labels": [], "entities": []}, {"text": "The different actions that can be then performed are chosen according to the confidence scores given by the tree.", "labels": [], "entities": []}], "introductionContent": [{"text": "There is a wide consensus in the scientific community that human-computer dialogue systems based on spoken natural language make mistakes because the Automatic Speech Recognition (ASR) component may not hypothesize some of the pronounced words and the various levels of knowledge used for recognizing and reasoning about conceptual entities are imprecise and incomplete.", "labels": [], "entities": [{"text": "Automatic Speech Recognition (ASR)", "start_pos": 150, "end_pos": 184, "type": "TASK", "confidence": 0.7510565121968588}, {"text": "recognizing and reasoning about conceptual entities", "start_pos": 289, "end_pos": 340, "type": "TASK", "confidence": 0.685727039972941}]}, {"text": "In spite of these problems, it is possible to make useful applications with dialogue systems using spoken input if suitable interpretation and decision strategies are conceived that minimize interpretation errors and perform dialogue actions which may not depend on the hypothesized concepts only, but also on confidence of what has been recognized.", "labels": [], "entities": []}, {"text": "This paper introduces some concepts developed for telephone applications in the framework of stochastic models for interpretation and dialogue strategies, a good overview of which can be found in).", "labels": [], "entities": [{"text": "interpretation and dialogue strategies", "start_pos": 115, "end_pos": 153, "type": "TASK", "confidence": 0.7421981617808342}]}, {"text": "The concepts introduced here are applied in a system which integrates language and interpretation models into Stochastic Finite State Transducers (SFST).", "labels": [], "entities": []}, {"text": "Furthermore, acoustic, linguistic and semantic confidence measures on the hypothesized word sequences are made available to the dialogue strategy.", "labels": [], "entities": []}, {"text": "A new way of using them in the dialogue decision process is proposed in this paper.", "labels": [], "entities": [{"text": "dialogue decision process", "start_pos": 31, "end_pos": 56, "type": "TASK", "confidence": 0.7948734164237976}]}, {"text": "Most of the Spoken language Understanding Systems (SLU) use semantic grammars with semantic tags as nonterminals) with rules for rewriting them into strings of words.", "labels": [], "entities": [{"text": "Spoken language Understanding Systems (SLU)", "start_pos": 12, "end_pos": 55, "type": "TASK", "confidence": 0.7669273444584438}]}, {"text": "The SFSTs of the system used for the experiments described here, represent knowledge for the basic building blocks of a frame-based semantic grammar.", "labels": [], "entities": []}, {"text": "Each block represents a property/value relation.", "labels": [], "entities": []}, {"text": "Different SFSTs may share words in the same sentence.", "labels": [], "entities": [{"text": "SFSTs", "start_pos": 10, "end_pos": 15, "type": "TASK", "confidence": 0.8729649186134338}]}, {"text": "Property/value hypotheses are generated with an approach described in (  and are combined into a sentence interpretation hypothesis in which the same word may contribute to more than one property/value pair.", "labels": [], "entities": []}, {"text": "The dialogue strategy has to evaluate the probability that each component of each pair has been correctly hypothesized in order to decide to perform an action that minimizes the risk of user dissatisfaction.", "labels": [], "entities": []}], "datasetContent": [{"text": "Experiments were carried out on a dialogue corpus provided by France Telecom R&D.", "labels": [], "entities": [{"text": "France Telecom R&D", "start_pos": 62, "end_pos": 80, "type": "DATASET", "confidence": 0.9743794798851013}]}, {"text": "The task has a vocabulary of 2200 words.", "labels": [], "entities": []}, {"text": "The language model used is made of 44K words.", "labels": [], "entities": []}, {"text": "For this study we selected utterances corresponding to answers to a prompt asking for the kind of restaurant the users were looking for.", "labels": [], "entities": []}, {"text": "This corpus has been cut in two: a development corpus containing 511 utterances and a test corpus containing 419 utterances.", "labels": [], "entities": []}, {"text": "This development corpus has been used to train the decision tree presented in section 5.2.", "labels": [], "entities": []}, {"text": "The Word Error Rate on the test corpus is 22.7%.", "labels": [], "entities": [{"text": "Word Error Rate", "start_pos": 4, "end_pos": 19, "type": "METRIC", "confidence": 0.783641537030538}]}, {"text": "shows the results obtained with a rescoring strategy that selects, from the structured n-best list, the hypothesis with the highest P (\u0393 | M ).", "labels": [], "entities": []}, {"text": "The baseline results are obtained with a standard maximum-likelihood approach choosing the hypothesis maximizing the probability P (\u0393 | Y ) of equation 1.", "labels": [], "entities": []}, {"text": "No rejection is performed in this experiment.", "labels": [], "entities": []}, {"text": "The size of the n-best lists was set to 12 items: the first 4 candidates of the first 3 interpretations in the structured n-best list.", "labels": [], "entities": []}, {"text": "shows the curve UER vs. utterance rejection on the development and test corpora.", "labels": [], "entities": [{"text": "UER", "start_pos": 16, "end_pos": 19, "type": "METRIC", "confidence": 0.9946212768554688}]}, {"text": "As we can see very significant improvements can be achieved with very little utterance rejection.", "labels": [], "entities": [{"text": "utterance rejection", "start_pos": 77, "end_pos": 96, "type": "TASK", "confidence": 0.7972038090229034}]}, {"text": "For example, at a 5% utterance rejection operating point, the UER on the development corpus drops from 15.0% to 8.6% (42.6% relative improvement) and from 17.7% to 11.4% (35.6% relative improvement).", "labels": [], "entities": [{"text": "utterance rejection", "start_pos": 21, "end_pos": 40, "type": "TASK", "confidence": 0.738463282585144}, {"text": "UER", "start_pos": 62, "end_pos": 65, "type": "METRIC", "confidence": 0.9876366257667542}]}, {"text": "By using equation 5 for finding the operating point minimizing the risk fonction (with a cost \u03c1 fa = 1.5 \u00d7 \u03c1 fr ) on the development corpus we obtain: \u2022 on the development corpus: UER=6.5 utterance rejection=13.1 \u2022 on the test corpus: UER=9.6 utterance rejection=15.9", "labels": [], "entities": [{"text": "UER", "start_pos": 180, "end_pos": 183, "type": "METRIC", "confidence": 0.9925646781921387}, {"text": "UER", "start_pos": 235, "end_pos": 238, "type": "METRIC", "confidence": 0.9968841671943665}]}], "tableCaptions": [{"text": " Table 1: Understanding Error Rate results with and with- out rescoring on structured n-best lists (n=12) (no rejec- tion)", "labels": [], "entities": [{"text": "Error Rate", "start_pos": 24, "end_pos": 34, "type": "METRIC", "confidence": 0.8799717426300049}]}]}