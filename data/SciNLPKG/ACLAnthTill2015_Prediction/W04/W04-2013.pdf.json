{"title": [], "abstractContent": [{"text": "Text document clustering can greatly simplify browsing large collections of documents by reorganizing them into a smaller number of manageable clusters.", "labels": [], "entities": [{"text": "Text document clustering", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.6656293372313181}]}, {"text": "Algorithms to solve this task exist; however, the algorithms are only as good as the data they work on.", "labels": [], "entities": []}, {"text": "Problems include ambiguity and synonymy, the former allowing for erroneous groupings and the latter causing similarities between documents to go unnoticed.", "labels": [], "entities": []}, {"text": "In this research, na\u00a8\u0131vena\u00a8\u0131ve, syntax-based disambigua-tion is attempted by assigning each word a part-of-speech tag and by enriching the 'bag-of-words' data representation often used for document clustering with synonyms and hypernyms from WordNet.", "labels": [], "entities": []}], "introductionContent": [{"text": "Text document clustering is the grouping of text documents into semantically related groups, or as Hayes puts it, \"they are grouped because they are likely to be wanted together\".", "labels": [], "entities": [{"text": "Text document clustering", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.6663135091463724}, {"text": "grouping of text documents into semantically related", "start_pos": 32, "end_pos": 84, "type": "TASK", "confidence": 0.7673547267913818}]}, {"text": "Initially, document clustering was developed to improve precision and recall of information retrieval systems.", "labels": [], "entities": [{"text": "document clustering", "start_pos": 11, "end_pos": 30, "type": "TASK", "confidence": 0.7455973923206329}, {"text": "precision", "start_pos": 56, "end_pos": 65, "type": "METRIC", "confidence": 0.9978095889091492}, {"text": "recall", "start_pos": 70, "end_pos": 76, "type": "METRIC", "confidence": 0.9950281977653503}]}, {"text": "More recently, however, driven by the ever increasing amount of text documents available incorporate document repositories and on the Internet, the focus has shifted towards providing ways to efficiently browse large collections of documents and to reorganise search results for display in a structured, often hierarchical manner.", "labels": [], "entities": []}, {"text": "The clustering of Internet search results has attracted particular attention.", "labels": [], "entities": [{"text": "clustering of Internet search results", "start_pos": 4, "end_pos": 41, "type": "TASK", "confidence": 0.8506067156791687}]}, {"text": "Some recent studies explored the feasibility of clustering 'in real-time' and the problem of adequately labeling clusters.", "labels": [], "entities": []}, {"text": "have created a clustering interface for the metasearch engine present their work on a system called SHOC.", "labels": [], "entities": [{"text": "SHOC", "start_pos": 100, "end_pos": 104, "type": "DATASET", "confidence": 0.8078433275222778}]}, {"text": "The reader is also referred to Vivisimo, 1 a commercial clustering interface based on results from a number of searchengines.", "labels": [], "entities": []}, {"text": "Ways to increase clustering speed are explored in many research papers, and the recent trend towards web-based clustering, requiring real-time performance, does not seem to change this.", "labels": [], "entities": [{"text": "clustering", "start_pos": 17, "end_pos": 27, "type": "TASK", "confidence": 0.9665838479995728}]}, {"text": "However, van Rijsbergen points out, \"it seems tome a little early in the day to insist on efficiency even before we know much about the behaviour of clustered files in terms of the effectiveness of retrieval\".", "labels": [], "entities": [{"text": "efficiency", "start_pos": 90, "end_pos": 100, "type": "METRIC", "confidence": 0.9811123609542847}]}, {"text": "Indeed, it maybe worth exploring which factors influence the quality (or effectiveness) of document clustering.", "labels": [], "entities": [{"text": "document clustering", "start_pos": 91, "end_pos": 110, "type": "TASK", "confidence": 0.6351940631866455}]}, {"text": "Clustering can be broken down into two stages.", "labels": [], "entities": []}, {"text": "The first one is to preprocess the documents, i.e. transforming the documents into a suitable and useful data representation.", "labels": [], "entities": []}, {"text": "The second stage is to analyse the prepared data and divide it into clusters, i.e. the clustering algorithm.", "labels": [], "entities": []}, {"text": "compare the suitability of a number of algorithms for text clustering and conclude that bisecting k-means, a partitional algorithm, is the current state-of-the-art.", "labels": [], "entities": [{"text": "text clustering", "start_pos": 54, "end_pos": 69, "type": "TASK", "confidence": 0.7971799075603485}]}, {"text": "Its processing time increases linearly with the number of documents and its quality is similar to that of hierarchical algorithms.", "labels": [], "entities": []}, {"text": "Preprocessing the documents is probably at least as important as the choice of an algorithm, since an algorithm can only be as good as the data it works on.", "labels": [], "entities": []}, {"text": "While there area number of preprocessing steps, that are almost standard now, the effects of adding background knowledge are still not very extensively researched.", "labels": [], "entities": []}, {"text": "This work explores if and how the two following methods can improve the effectiveness of clustering.", "labels": [], "entities": []}, {"text": "observe that part-of-speech tagging (PoS) solves semantic ambiguity to some extent (40% in one of their tests).", "labels": [], "entities": [{"text": "part-of-speech tagging (PoS", "start_pos": 13, "end_pos": 40, "type": "TASK", "confidence": 0.8165613561868668}]}, {"text": "Based on this observation, we study whether na\u00a8\u0131vena\u00a8\u0131ve word sense disambiguation by PoS tagging can help to improve clustering results.", "labels": [], "entities": [{"text": "word sense disambiguation", "start_pos": 57, "end_pos": 82, "type": "TASK", "confidence": 0.624057819445928}, {"text": "PoS tagging", "start_pos": 86, "end_pos": 97, "type": "TASK", "confidence": 0.6781335771083832}]}, {"text": "Synonymy and hypernymy can reveal hidden similarities, potentially leading to better clusters.", "labels": [], "entities": []}, {"text": "WordNet, 2 an ontology which models these two relations (among many others) (, is used to include synonyms and hypernyms in the data representation and the effects on clustering quality are observed and analysed.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 0, "end_pos": 7, "type": "DATASET", "confidence": 0.9640860557556152}]}, {"text": "The overall aim of the approach outlined above is to cluster documents by meaning, hence it is relevant to language understanding.", "labels": [], "entities": [{"text": "language understanding", "start_pos": 107, "end_pos": 129, "type": "TASK", "confidence": 0.7060726135969162}]}, {"text": "The approach has some of the characteristics expected from a robust language understanding system.", "labels": [], "entities": []}, {"text": "Firstly, learning only relies on unannoted text data, which is abundant and does not contain the individual bias of an annotator.", "labels": [], "entities": []}, {"text": "Secondly, the approach is based on general-purpose resources (Brill's PoS Tagger, WordNet), and the performance is studied under pessimistic (hence more realistic) assumptions, e.g., that the tagger is trained on a standard dataset with potentially different properties from the documents to be clustered.", "labels": [], "entities": [{"text": "Brill's PoS Tagger", "start_pos": 62, "end_pos": 80, "type": "DATASET", "confidence": 0.7512042373418808}, {"text": "WordNet", "start_pos": 82, "end_pos": 89, "type": "DATASET", "confidence": 0.9218083620071411}]}, {"text": "Similarly, the approach studies the potential benefits of using all possible senses (and hypernyms) from WordNet, in an attempt to postpone (or avoid altogether) the need for Word Sense Disambiguation (WSD), and the related pitfalls of a WSD tool which maybe biased towards a specific domain or language style.", "labels": [], "entities": [{"text": "Word Sense Disambiguation (WSD)", "start_pos": 175, "end_pos": 206, "type": "TASK", "confidence": 0.733860582113266}]}, {"text": "The remainder of the document is structured as follows.", "labels": [], "entities": []}, {"text": "Section 2 describes related work and the techniques used to preprocess the data, as well as cluster it and evaluate the results achieved.", "labels": [], "entities": []}, {"text": "Section 3 provides some background on the selected corpus, the Reuters-21578 test collection, and presents the subcorpora that are extracted for use in the experiments.", "labels": [], "entities": [{"text": "Reuters-21578 test collection", "start_pos": 63, "end_pos": 92, "type": "DATASET", "confidence": 0.9835776686668396}]}, {"text": "Section 4 describes the experimental framework, while Section 5 presents the results and their evaluation.", "labels": [], "entities": []}, {"text": "Finally, conclusions are drawn and further work discussed in Section 6. 2 available at http://www.cogsci.princeton.edu/\u223cwn", "labels": [], "entities": []}], "datasetContent": [{"text": "The results are presented in the format of one graph per corpus, showing the entropy, purity and overall similarity values for each of the configurations shown in.", "labels": [], "entities": [{"text": "purity", "start_pos": 86, "end_pos": 92, "type": "METRIC", "confidence": 0.9587476849555969}]}, {"text": "On the X-axis, the different configuration settings are listed.", "labels": [], "entities": []}, {"text": "On the right-hand side, hype refers to the hypernym depth, syn refers to whether synonyms were included or not, pos refers to the presence or absence of PoS tags and clusters refers to the number of clusters created.", "labels": [], "entities": []}, {"text": "For improved readability, lines are drawn, splitting the graphs into three sections, one for each number of clusters.", "labels": [], "entities": []}, {"text": "For experiments on the corpora 'reut-max20' and 'reut-max50', the values in the graphs are the average of three test runs, whereas for the corpora 'reut-min15-max20' and 'reut-max100', the values are those obtained from a single test run.", "labels": [], "entities": []}, {"text": "The Y-axis indicates the numerical values for each of the measures.", "labels": [], "entities": []}, {"text": "Note that the values for purity and similarity are percentages, and thus limited to the range between 0 and 1.", "labels": [], "entities": [{"text": "purity", "start_pos": 25, "end_pos": 31, "type": "METRIC", "confidence": 0.9985033273696899}, {"text": "similarity", "start_pos": 36, "end_pos": 46, "type": "METRIC", "confidence": 0.9938561320304871}]}, {"text": "For those two measures, higher values indicate better quality.", "labels": [], "entities": []}, {"text": "High entropy values, on the other hand, indicate lower quality.", "labels": [], "entities": []}, {"text": "Entropy values are always greater than 0 and for the particular experiments carried out, they never exceed 1.3.", "labels": [], "entities": [{"text": "Entropy", "start_pos": 0, "end_pos": 7, "type": "METRIC", "confidence": 0.9875364899635315}]}, {"text": "In analysing the test results, the main focus is on the data of corpora 'reut-max20' and 'reutmax50', shown in and, respectively.", "labels": [], "entities": []}, {"text": "This data is more reliable, because it is the average of repeated test runs.", "labels": [], "entities": []}, {"text": "show the test data obtained from clustering the corpora 'reut-min15-max20' and 'reutmax100', respectively.", "labels": [], "entities": []}, {"text": "The fact that the purity and similarity values are far from 100 percent is not unusual.", "labels": [], "entities": [{"text": "purity", "start_pos": 18, "end_pos": 24, "type": "METRIC", "confidence": 0.9986357092857361}, {"text": "similarity", "start_pos": 29, "end_pos": 39, "type": "METRIC", "confidence": 0.9776812791824341}]}, {"text": "In many cases, not even human annotators agree on how to categorise a particular document ().", "labels": [], "entities": []}, {"text": "More importantly, the number of categories are not adjusted to the number of labels present in a corpus, which makes complete agreement impossible.", "labels": [], "entities": []}, {"text": "All three measures indicate that the quality increases with the number of clusters.", "labels": [], "entities": []}, {"text": "The graph in illustrates this for the entropy in 'reut-max50'.", "labels": [], "entities": []}, {"text": "For any given configuration, it appears that the decrease in entropy is almost constant when the number of clusters increases.", "labels": [], "entities": []}, {"text": "This is easily explained by the average cluster sizes, which decrease with an increasing number of clusters; when clusters are smaller, the probability of having a high percentage of documents with the same label in a cluster increases.", "labels": [], "entities": []}, {"text": "This   becomes obvious when very small clusters are looked at.", "labels": [], "entities": []}, {"text": "For instance, the minimum purity value fora cluster containing three documents is 33 percent, for two documents it is 50 percent, and, in the extreme case of a single document per cluster, purity is always 100 percent.", "labels": [], "entities": [{"text": "purity", "start_pos": 26, "end_pos": 32, "type": "METRIC", "confidence": 0.8401167988777161}, {"text": "purity", "start_pos": 189, "end_pos": 195, "type": "METRIC", "confidence": 0.9970858693122864}]}, {"text": "The PoS Only experiment results in performance, which is very similar to the Baseline, and is sometimes a little better, sometimes a little worse.", "labels": [], "entities": [{"text": "PoS Only", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.7457336187362671}]}, {"text": "This is expected, and the experiment is included to allow fora more accurate interpretation of the subsequent experiments using synonyms and hypernyms.", "labels": [], "entities": []}, {"text": "A more interesting observation is that purity and entropy values indicate better clusters for Baseline than for any of the configurations using background knowledge from WordNet (i.e. Syns, Hyper 5 and Hyper All).", "labels": [], "entities": [{"text": "purity", "start_pos": 39, "end_pos": 45, "type": "METRIC", "confidence": 0.9918632507324219}, {"text": "WordNet", "start_pos": 170, "end_pos": 177, "type": "DATASET", "confidence": 0.9537512063980103}]}, {"text": "One possible conclusion is that adding background knowledge is not helpful at all.", "labels": [], "entities": []}, {"text": "However, the reasons for the relatively poor performance could also be due to the way the experiments are setup.", "labels": [], "entities": []}, {"text": "Therefore, a possible explanation for these results could be that the benefit of extra overlap between documents, which the added synonyms and hypernyms should provide, is outweighed by the additional noise they create.", "labels": [], "entities": []}, {"text": "WordNet does often provide five or more senses fora word, which means that for one correct sense a number of incorrect senses are added, even if the PoS tags eliminate some of them.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 0, "end_pos": 7, "type": "DATASET", "confidence": 0.9673780202865601}]}, {"text": "The overall similarity measure gives a different indication.", "labels": [], "entities": [{"text": "similarity", "start_pos": 12, "end_pos": 22, "type": "METRIC", "confidence": 0.990474283695221}]}, {"text": "Its values appear to increase for the cases where background knowledge is included, especially when hypernyms are added.", "labels": [], "entities": []}, {"text": "Overall similarity is the weighted average of the intra-cluster similarities of all clusters.", "labels": [], "entities": [{"text": "similarity", "start_pos": 8, "end_pos": 18, "type": "METRIC", "confidence": 0.9727697372436523}]}, {"text": "So the intra-cluster similarity actually increases with     added information.", "labels": [], "entities": []}, {"text": "As similarity increases with additional overlap, the overall similarity measure shows that additional overlap is achieved.", "labels": [], "entities": [{"text": "similarity", "start_pos": 3, "end_pos": 13, "type": "METRIC", "confidence": 0.9618937373161316}, {"text": "similarity", "start_pos": 61, "end_pos": 71, "type": "METRIC", "confidence": 0.978496789932251}]}, {"text": "The main problem with the approach of adding all synonyms and all hypernyms into the document vectors seems to be the added noise.", "labels": [], "entities": []}, {"text": "The expectation that tf idf weighting would take care of these quasi-random new concepts is not met, but the results also indicate possible improvements to this approach.", "labels": [], "entities": []}, {"text": "If word-by-word disambiguation would be   used, the correct sense of a word could be chosen and only the hypernyms for the correct sense of the word could betaken into account.", "labels": [], "entities": []}, {"text": "This should drastically reduce noise.", "labels": [], "entities": []}, {"text": "The benefit of the added 'correct' concepts would then probably improve cluster quality.", "labels": [], "entities": []}, {"text": "experimented successfully with simple disambiguation strategies, e.g., they used only the first sense provided by WordNet.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 114, "end_pos": 121, "type": "DATASET", "confidence": 0.9725842475891113}]}, {"text": "As an alternative to word-by-word disambiguation, a strategy to disambiguate based on document vectors could be devised; after adding all alternative senses of the terms, the least frequent ones could be removed.", "labels": [], "entities": []}, {"text": "This is similar to pruning but would be done on a document by document basis, rather than globally on the whole corpus.", "labels": [], "entities": []}, {"text": "The basis for this idea is that only concepts that appear repeatedly in a document contribute (significantly) to the meaning of the document.", "labels": [], "entities": []}, {"text": "It is important that this is done before hypernyms are added, especially when all levels of hypernyms are added, because the most general terms are bound to appear more often than the more specific ones.", "labels": [], "entities": []}, {"text": "This would lead to lots of very similar, but meaningless bags of words or bags of concepts.", "labels": [], "entities": []}, {"text": "Comparing Syns, Hyper 5 and Hyper All with each other, in many cases Hyper 5 gives the best results.", "labels": [], "entities": [{"text": "Hyper 5", "start_pos": 16, "end_pos": 23, "type": "METRIC", "confidence": 0.9071353077888489}]}, {"text": "A possible explanation could again be the equilibrium between valuable information and noise that are added to the vector representations.", "labels": [], "entities": []}, {"text": "From these results it seems that there is a point where the amount of information added reaches its maximum benefit; adding more knowledge afterwards results in decreased cluster quality again.", "labels": [], "entities": []}, {"text": "It should be noted that a fixed threshold for the levels of hypernyms used is unlikely to be optimal for all words.", "labels": [], "entities": []}, {"text": "Instead, a more refined approach could set this threshold as a function of the semantic distance between the word and its hypernyms.", "labels": [], "entities": []}, {"text": "The maximised benefit is most evident in the 'reut-max100' corpus (.", "labels": [], "entities": []}, {"text": "However, it needs to be kept in mind that for the last two data points, Hyper 5 and Hyper All, the pruning threshold is 200.", "labels": [], "entities": [{"text": "pruning threshold", "start_pos": 99, "end_pos": 116, "type": "METRIC", "confidence": 0.9594815373420715}]}, {"text": "Therefore, the comparison with Syns needs to be done with care.", "labels": [], "entities": []}, {"text": "This is not much of a problem, because the other graphs consistently show that the performance for Syns is worse than for Hyper 5.", "labels": [], "entities": []}, {"text": "The difference between Hyper 5 and Hyper All in 'reut-max100', can be directly compared though, because the pruning threshold of 200 is used for both configurations.", "labels": [], "entities": []}, {"text": "Surprisingly, there is a sharp drop in the overall similarity from Hyper 5 to Hyper All, much more evident than in the other three corpora.", "labels": [], "entities": []}, {"text": "One possible explanation could be the different structure of the corpus.", "labels": [], "entities": []}, {"text": "It seems more probable, however, that the high pruning threshold is the cause again.", "labels": [], "entities": [{"text": "pruning threshold", "start_pos": 47, "end_pos": 64, "type": "METRIC", "confidence": 0.8927730619907379}]}, {"text": "Assuming that Hyper 5 seldom includes the most general concepts, whereas Hyper All always includes them, their frequency in Hyper All becomes so high that the frequencies of all the other terms are very low in comparison.", "labels": [], "entities": []}, {"text": "The document vectors in case of Hyper All end up containing mostly meaningless concepts, because most of the others are pruned.", "labels": [], "entities": []}, {"text": "This leads to decreased cluster quality because the general concepts have little discriminating power.", "labels": [], "entities": []}, {"text": "In the corresponding experiments on other corpora, more of the specific concepts are retained.", "labels": [], "entities": []}, {"text": "Therefore, a better balance between general and specific concepts is maintained, keeping the cluster quality higher than in the case of corpus 'reut-max100'.", "labels": [], "entities": []}, {"text": "PoS Only performs similar to Baseline, although usually a slight decrease in quality can be observed.", "labels": [], "entities": []}, {"text": "Despite the assumption that the disambiguation achieved by the PoS tags should improve clustering results, this is clearly not the case.", "labels": [], "entities": [{"text": "PoS tags", "start_pos": 63, "end_pos": 71, "type": "DATASET", "confidence": 0.7721186578273773}]}, {"text": "PoS tags only disambiguate the cases where different word classes are represented by the same stem, e.g., the noun 'run' and the verb 'run'.", "labels": [], "entities": []}, {"text": "Clearly the meanings of these pairs are inmost cases related.", "labels": [], "entities": []}, {"text": "Therefore, distinguishing between them reduces the weight of their common concept by splitting it between two concepts.", "labels": [], "entities": []}, {"text": "In the worst case, they are pruned if treated separately, instead of contributing significantly to the document vector as a joint concept.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Corpus Statistics  Category Size  Name  Size  \u00f8  stdev  reut-min15-max20  713  20  0.7  reut-max20  881  13  7.7  reut-max50  1690  24  19.9  reut-max100  2244  34  35.2  reut-base  9446 143  553.2", "labels": [], "entities": []}]}