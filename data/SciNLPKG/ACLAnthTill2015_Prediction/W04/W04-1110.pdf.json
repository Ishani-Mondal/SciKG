{"title": [{"text": "Automated Alignment and Extraction of Bilingual Domain Ontology for Medical Domain Web Search", "labels": [], "entities": [{"text": "Automated Alignment and Extraction of Bilingual Domain Ontology", "start_pos": 0, "end_pos": 63, "type": "TASK", "confidence": 0.8313086181879044}, {"text": "Medical Domain Web Search", "start_pos": 68, "end_pos": 93, "type": "TASK", "confidence": 0.5576854944229126}]}], "abstractContent": [{"text": "This paper proposes an approach to automated ontology alignment and domain ontology extraction from two knowledge bases.", "labels": [], "entities": [{"text": "ontology alignment", "start_pos": 45, "end_pos": 63, "type": "TASK", "confidence": 0.8484964370727539}, {"text": "domain ontology extraction", "start_pos": 68, "end_pos": 94, "type": "TASK", "confidence": 0.7797035475571951}]}, {"text": "First, WordNet and HowNet knowledge bases are aligned to construct a bilingual universal ontology based on the co-occurrence of the words in a parallel corpus.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 7, "end_pos": 14, "type": "DATASET", "confidence": 0.9426107406616211}, {"text": "HowNet knowledge bases", "start_pos": 19, "end_pos": 41, "type": "DATASET", "confidence": 0.9184887806574503}]}, {"text": "The bilingual universal ontology has the merit that it contains more structural and semantic information coverage from two complementary knowledge bases, WordNet and HowNet.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 154, "end_pos": 161, "type": "DATASET", "confidence": 0.9480606913566589}, {"text": "HowNet", "start_pos": 166, "end_pos": 172, "type": "DATASET", "confidence": 0.915105938911438}]}, {"text": "For domain-specific applications, a medical domain ontology is further extracted from the universal ontology using the island-driven algorithm and a medical domain corpus.", "labels": [], "entities": []}, {"text": "Finally, the domain-dependent terms and some axioms between medical terms based on a medical encyclopaedia are added into the ontology.", "labels": [], "entities": []}, {"text": "For ontology evaluation, experiments on web search were conducted using the constructed ontology.", "labels": [], "entities": [{"text": "ontology evaluation", "start_pos": 4, "end_pos": 23, "type": "TASK", "confidence": 0.9568336009979248}]}, {"text": "The experimental results show that the proposed approach can automatically align and extract the domain-specific ontology.", "labels": [], "entities": []}, {"text": "In addition, the extracted ontology also shows its promising ability for medical web search.", "labels": [], "entities": [{"text": "medical web search", "start_pos": 73, "end_pos": 91, "type": "TASK", "confidence": 0.6189994017283121}]}], "introductionContent": [{"text": "In intelligent mining, in order to obviate the unnecessary keyword expansion, some knowledge base should be involved in the intelligent information system.", "labels": [], "entities": [{"text": "intelligent mining", "start_pos": 3, "end_pos": 21, "type": "TASK", "confidence": 0.726582333445549}]}, {"text": "In recent years, considerable progress has been invested in developing the conceptual bases for building technology that allows knowledge reuse and sharing.", "labels": [], "entities": []}, {"text": "As information exchangeability and communication becomes increasingly global, multiple-language lexical resources that can provide transnational services are becoming increasingly important.", "labels": [], "entities": []}, {"text": "Over the last few years, significant effort has been made to construct the ontology manually according to the domain expert's knowledge.", "labels": [], "entities": []}, {"text": "Manual ontology merging using conventional editing tools without intelligent support is difficult, labor intensive and error prone.", "labels": [], "entities": [{"text": "ontology merging", "start_pos": 7, "end_pos": 23, "type": "TASK", "confidence": 0.7895620763301849}]}, {"text": "Therefore, several systems and frameworks for supporting the knowledge engineer in the ontology merging task have recently been proposed.", "labels": [], "entities": [{"text": "ontology merging task", "start_pos": 87, "end_pos": 108, "type": "TASK", "confidence": 0.8840038180351257}]}, {"text": "To avoid the reiteration in ontology construction, the algorithm of ontology merge (UMLS http://umlsks.nlm.nih.gov/) ( and ontology alignment (Vossen and Peters 1997))) were invested.", "labels": [], "entities": [{"text": "ontology construction", "start_pos": 28, "end_pos": 49, "type": "TASK", "confidence": 0.8621137738227844}, {"text": "UMLS", "start_pos": 84, "end_pos": 88, "type": "DATASET", "confidence": 0.9353540539741516}, {"text": "ontology alignment", "start_pos": 123, "end_pos": 141, "type": "TASK", "confidence": 0.7779010236263275}]}, {"text": "The final ontology is a merged version of the original ontologies.", "labels": [], "entities": []}, {"text": "The two original ontologies persist, with links established between them in alignment.", "labels": [], "entities": []}, {"text": "Alignment usually is performed when the ontologies cover domains that are complementary to each other.", "labels": [], "entities": [{"text": "Alignment", "start_pos": 0, "end_pos": 9, "type": "TASK", "confidence": 0.9669913053512573}]}, {"text": "In the past, domain ontology was usually constructed manually according to the knowledge or experience of the experts or ontology engineers.", "labels": [], "entities": []}, {"text": "Recently, automatic and semi-automatic methods have been developed.", "labels": [], "entities": []}, {"text": "OntoExtract ( provided an ontology engineering chain to construct the domain ontology from WordNet and SemCor.", "labels": [], "entities": [{"text": "OntoExtract", "start_pos": 0, "end_pos": 11, "type": "DATASET", "confidence": 0.9213894605636597}, {"text": "WordNet", "start_pos": 91, "end_pos": 98, "type": "DATASET", "confidence": 0.9417510628700256}]}, {"text": "On the other hand, multi-lingual ontology is very important for natural language processing, such as machine translation (MT), web mining and cross language information retrieval (CLIR).", "labels": [], "entities": [{"text": "machine translation (MT)", "start_pos": 101, "end_pos": 125, "type": "TASK", "confidence": 0.8636521697044373}, {"text": "web mining", "start_pos": 127, "end_pos": 137, "type": "TASK", "confidence": 0.713503897190094}, {"text": "cross language information retrieval (CLIR)", "start_pos": 142, "end_pos": 185, "type": "TASK", "confidence": 0.7174807148320335}]}, {"text": "Generally, a multi-lingual ontology maps the keyword set of one language to another language, or compute the co-occurrence of the words among languages.", "labels": [], "entities": []}, {"text": "In addition, a key merit for multilingual ontology is that it can increase the relation and structural information coverage by aligning two or more language-dependent ontologies with different semantic features.", "labels": [], "entities": []}, {"text": "Nowadays large collections of information in various styles are available on the Internet.", "labels": [], "entities": []}, {"text": "And finding desired information on the World Wide Web is becoming a critical issue.", "labels": [], "entities": [{"text": "finding desired information on the World Wide Web", "start_pos": 4, "end_pos": 53, "type": "TASK", "confidence": 0.6142301559448242}]}, {"text": "Some generalpurpose search engine like Google (http://www.google.com) and Altavista (http://www.altavista.com/) provide the facility to mine the web.", "labels": [], "entities": []}, {"text": "There are three major research areas about web mining: web content mining, web structure mining and web usage mining.", "labels": [], "entities": [{"text": "web content mining", "start_pos": 55, "end_pos": 73, "type": "TASK", "confidence": 0.6349859337011973}, {"text": "web structure mining", "start_pos": 75, "end_pos": 95, "type": "TASK", "confidence": 0.6256757974624634}, {"text": "web usage mining", "start_pos": 100, "end_pos": 116, "type": "TASK", "confidence": 0.6199449797471365}]}, {"text": "This paper proposes a novel method to web content mining with unstructured web pages.", "labels": [], "entities": [{"text": "web content mining", "start_pos": 38, "end_pos": 56, "type": "TASK", "confidence": 0.6596148312091827}]}, {"text": "There are many approaches in the view of natural language processing.", "labels": [], "entities": [{"text": "natural language processing", "start_pos": 41, "end_pos": 68, "type": "TASK", "confidence": 0.6488733688990275}]}, {"text": "According to the representation of web pages, there are three kinds of the content: bag of words (with order or not) ()), phrases)(), relational terms) and concept categories.", "labels": [], "entities": []}, {"text": "We proposed an ontologybased web search approach.", "labels": [], "entities": []}, {"text": "Unfortunately, there are some irrelevant pages obtained and these pages result in low precision rate and recall rate due to the problem of polysemy.", "labels": [], "entities": [{"text": "precision rate", "start_pos": 86, "end_pos": 100, "type": "METRIC", "confidence": 0.9875096678733826}, {"text": "recall rate", "start_pos": 105, "end_pos": 116, "type": "METRIC", "confidence": 0.982787013053894}]}, {"text": "To solve this problem, domain knowledge becomes necessary.", "labels": [], "entities": []}, {"text": "The domain-specific web miners like SPIRAL, Cora, and) are employed as the special search engine for the interesting topic.", "labels": [], "entities": [{"text": "SPIRAL", "start_pos": 36, "end_pos": 42, "type": "DATASET", "confidence": 0.6520507335662842}, {"text": "Cora", "start_pos": 44, "end_pos": 48, "type": "DATASET", "confidence": 0.7200816869735718}]}, {"text": "These ones dedicated to recipes are less likely to return irrelevant web pages when the query is entered.", "labels": [], "entities": []}, {"text": "In this paper, WordNet and HowNet knowledge bases are aligned to construct a bilingual universal ontology based on the co-occurrence of the words in a parallel corpus.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 15, "end_pos": 22, "type": "DATASET", "confidence": 0.945584774017334}, {"text": "HowNet knowledge bases", "start_pos": 27, "end_pos": 49, "type": "DATASET", "confidence": 0.918484648068746}]}, {"text": "For domain-specific applications, a medical domain ontology is further extracted from the universal ontology using the island-driven algorithm () and a medical domain corpus.", "labels": [], "entities": []}, {"text": "Finally, the axioms between medical terms are derived based on semantic relations.", "labels": [], "entities": []}, {"text": "A web search system for medical domain based on the extracted domain ontology is realized to demonstrate the feasibility of the methods proposed in this paper.", "labels": [], "entities": []}, {"text": "The rest of the paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 describes ontology construction process and the web searching system framework.", "labels": [], "entities": [{"text": "ontology construction", "start_pos": 20, "end_pos": 41, "type": "TASK", "confidence": 0.9157335758209229}]}, {"text": "Section 3 presents the experimental results for the evaluation of our approach.", "labels": [], "entities": []}, {"text": "Section 4 gives some concluding remarks.", "labels": [], "entities": []}, {"text": "shows the block diagram for ontology construction and the framework of the domainspecific web search system.", "labels": [], "entities": [{"text": "ontology construction", "start_pos": 28, "end_pos": 49, "type": "TASK", "confidence": 0.9427805840969086}]}, {"text": "There are four major processes in the proposed system: bilingual ontology alignment, domain ontology extraction, knowledge representation and domain-specific web search.", "labels": [], "entities": [{"text": "bilingual ontology alignment", "start_pos": 55, "end_pos": 83, "type": "TASK", "confidence": 0.6656152804692587}, {"text": "domain ontology extraction", "start_pos": 85, "end_pos": 111, "type": "TASK", "confidence": 0.7712541619936625}, {"text": "knowledge representation", "start_pos": 113, "end_pos": 137, "type": "TASK", "confidence": 0.7630606889724731}]}], "datasetContent": [{"text": "To evaluate the proposed approach, a medical web search system was constructed.", "labels": [], "entities": []}, {"text": "The web pages were collected from several Websites and totally 2322 web pages for medical domain and 8133 web pages for contrastive domain were collected.", "labels": [], "entities": []}, {"text": "On the other hand, the training and test queries for training and evaluating the system performance were also collected.", "labels": [], "entities": []}, {"text": "Forty users, who do not take part in the system development, were asked to provide a set of queries given the collected web pages.", "labels": [], "entities": []}, {"text": "After post-processing, the duplicate queries and the queries out of the medical domain are removed.", "labels": [], "entities": []}, {"text": "Finally, 3207 test queries mixed Chinese with English words using natural language were obtained.", "labels": [], "entities": []}, {"text": "In the following experiments, web pages were separately evaluated by focusing on one inference module based on the domain-specific ontology at a time.", "labels": [], "entities": []}, {"text": "That is, the mixture weight is set to 1 for one inference module and the other is set to 0 in each evaluation.", "labels": [], "entities": []}, {"text": "For comparison, the keyword-based VSM approach and the ontology-based system are also evaluated and shown in.", "labels": [], "entities": []}, {"text": "The precision and recall rates are used as the evaluation measures.", "labels": [], "entities": [{"text": "precision", "start_pos": 4, "end_pos": 13, "type": "METRIC", "confidence": 0.9996647834777832}, {"text": "recall rates", "start_pos": 18, "end_pos": 30, "type": "METRIC", "confidence": 0.98415607213974}]}, {"text": "And the ontology based approach means the combination of concept inference and axiom inference described in the section 3.2.", "labels": [], "entities": []}, {"text": "The precision rates and recall rates of the proposed method and the baseline system", "labels": [], "entities": [{"text": "precision", "start_pos": 4, "end_pos": 13, "type": "METRIC", "confidence": 0.9994926452636719}, {"text": "recall", "start_pos": 24, "end_pos": 30, "type": "METRIC", "confidence": 0.9982767105102539}]}], "tableCaptions": []}