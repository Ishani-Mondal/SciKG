{"title": [{"text": "Augmenting Ensemble Classification for Word Sense Disambiguation with a Kernel PCA Model", "labels": [], "entities": [{"text": "Augmenting Ensemble Classification", "start_pos": 0, "end_pos": 34, "type": "TASK", "confidence": 0.904930055141449}, {"text": "Word Sense Disambiguation", "start_pos": 39, "end_pos": 64, "type": "TASK", "confidence": 0.7985607782999674}]}], "abstractContent": [{"text": "The HKUST word sense disambiguation systems benefit from anew nonlinear Kernel Principal Component Analysis (KPCA) based disambigua-tion technique.", "labels": [], "entities": [{"text": "HKUST word sense disambiguation", "start_pos": 4, "end_pos": 35, "type": "TASK", "confidence": 0.7792491763830185}]}, {"text": "We discuss and analyze results from the Senseval-3 English, Chinese, and Multilingual Lexical Sample data sets.", "labels": [], "entities": [{"text": "Senseval-3 English, Chinese, and Multilingual Lexical Sample data sets", "start_pos": 40, "end_pos": 110, "type": "DATASET", "confidence": 0.6072147705338218}]}, {"text": "Among an ensemble of four different kinds of voted models, the KPCA-based model, along with the maximum en-tropy model, outperforms the boosting model and na\u00a8\u0131vena\u00a8\u0131ve Bayes model.", "labels": [], "entities": []}, {"text": "Interestingly, while the KPCA-based model typically achieves close or better accuracy than the maximum entropy model, nevertheless a comparison of predicted classifications shows that it has a significantly different bias.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 77, "end_pos": 85, "type": "METRIC", "confidence": 0.9974864721298218}]}, {"text": "This characteristic makes it an excellent voter, as confirmed by results showing that removing the KPCA-based model from the ensemble generally degrades performance .", "labels": [], "entities": []}], "introductionContent": [{"text": "Classifier combination has become a standard architecture for shared task evaluations in word sense disambiguation (WSD), named entity recognition, and similar problems that can naturally be cast as classification problems.", "labels": [], "entities": [{"text": "word sense disambiguation (WSD)", "start_pos": 89, "end_pos": 120, "type": "TASK", "confidence": 0.7841705232858658}, {"text": "named entity recognition", "start_pos": 122, "end_pos": 146, "type": "TASK", "confidence": 0.6128728687763214}]}, {"text": "Voting is the most common method of combination, having proven to be remarkably effective yet simple.", "labels": [], "entities": [{"text": "Voting", "start_pos": 0, "end_pos": 6, "type": "TASK", "confidence": 0.8064684271812439}, {"text": "combination", "start_pos": 36, "end_pos": 47, "type": "TASK", "confidence": 0.9682835340499878}]}, {"text": "A key problem in improving the accuracy of such ensemble classification systems is to find new voting models that (1) exhibit significantly different prediction biases from the models already voting, and yet (2) attain stand-alone classification accuracies that are as good or better.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 31, "end_pos": 39, "type": "METRIC", "confidence": 0.9966576099395752}]}, {"text": "When either of these conditions is not met, adding the new voting model typically degrades the accuracy of the ensemble instead of helping it.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 95, "end_pos": 103, "type": "METRIC", "confidence": 0.9992701411247253}]}, {"text": "In this work, we investigate the potential of one promising new disambiguation model with respect The author would like to thank the Hong Kong Research Grants Council (RGC) for supporting this research in part through research grants RGC6083/99E, RGC6256/00E, and DAG03/04.EG09.", "labels": [], "entities": [{"text": "Hong Kong Research Grants Council (RGC)", "start_pos": 133, "end_pos": 172, "type": "DATASET", "confidence": 0.899071641266346}]}, {"text": "to augmenting our existing ensemble combining a maximum entropy model, a boosting model, and a na\u00a8\u0131vena\u00a8\u0131ve Bayes model-a combination representing some of the best stand-alone WSD models currently known.", "labels": [], "entities": []}, {"text": "The new WSD model, proposed by , is a method for disambiguating word senses that exploits a nonlinear Kernel Principal Component Analysis (KPCA) technique.", "labels": [], "entities": [{"text": "WSD", "start_pos": 8, "end_pos": 11, "type": "TASK", "confidence": 0.9401021003723145}, {"text": "Kernel Principal Component Analysis (KPCA)", "start_pos": 102, "end_pos": 144, "type": "TASK", "confidence": 0.7248896445546832}]}, {"text": "That the KPCA-based model could potentially be a good candidate fora new voting model is suggested bys empirical results showing that it yielded higher accuracies on Senseval-2 data sets than other models that included maximum entropy, na\u00a8\u0131vena\u00a8\u0131ve Bayes, and SVM based models.", "labels": [], "entities": [{"text": "accuracies", "start_pos": 152, "end_pos": 162, "type": "METRIC", "confidence": 0.9622554183006287}, {"text": "Senseval-2 data sets", "start_pos": 166, "end_pos": 186, "type": "DATASET", "confidence": 0.9281909068425497}]}, {"text": "In the following sections, we begin with a description of the experimental setup, which utilizes a number of individual classifiers in a voting ensemble.", "labels": [], "entities": []}, {"text": "We then describe the KPCA-based model to be added to the baseline ensemble.", "labels": [], "entities": []}, {"text": "The accuracy results of the three submitted models are examined, and also the individual voting models are compared.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.9994615912437439}]}, {"text": "Subsequently, we analyze the degree of difference in voting bias of the KPCA-based model from the others, and finally show that this does indeed usually lead to accuracy gains in the voting ensemble.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 161, "end_pos": 169, "type": "METRIC", "confidence": 0.9983428716659546}]}, {"text": "senses are defined using the HowNet knowledge base.", "labels": [], "entities": [{"text": "HowNet knowledge base", "start_pos": 29, "end_pos": 50, "type": "DATASET", "confidence": 0.9770849347114563}]}, {"text": "There are an average of 3.95 senses per target word type, ranging from 2 to 8.", "labels": [], "entities": []}, {"text": "Only about 37 training instances per target word are available.", "labels": [], "entities": []}, {"text": "The Multilingual (t) task is defined similarly to the English lexical sample task, except that the word senses are the translations into Hindi, rather than WordNet senses.", "labels": [], "entities": []}, {"text": "The Multilingual (t) task requires finding the Hindi sense for 31 English target word types.", "labels": [], "entities": []}, {"text": "There are an average of 7.54 senses per target word type, ranging from 3 to 16.", "labels": [], "entities": []}, {"text": "A relatively large training set is provided (more than 260 training instances per word on average).", "labels": [], "entities": []}, {"text": "The Multilingual (ts) task uses a different data set of 10 target words and provides the correct English sense of the target word for both training and testing.", "labels": [], "entities": []}, {"text": "There are an average of 6.2 senses per target word type, ranging from 3 to 11.", "labels": [], "entities": []}, {"text": "The training set for this subtask was smaller, with about 150 training instances per target word.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Comparison of accuracy results for various HKUST ensemble and individual models on Senseval- 3 Lexical Sample tasks, confirming the high accuracy of the KPCA-based model. All test instances were  attempted. (Bold model names were the systems entered.)", "labels": [], "entities": [{"text": "accuracy", "start_pos": 24, "end_pos": 32, "type": "METRIC", "confidence": 0.9959824085235596}, {"text": "HKUST", "start_pos": 53, "end_pos": 58, "type": "DATASET", "confidence": 0.8792089223861694}, {"text": "accuracy", "start_pos": 147, "end_pos": 155, "type": "METRIC", "confidence": 0.9983497858047485}]}, {"text": " Table 2: Confusion matrices showing that the KPCA-based model votes very differently from the other  models on the Senseval-3 Lexical Sample tasks. Percentages representing disagreement between KPCA and  other voting models are shown in bold.", "labels": [], "entities": []}, {"text": " Table 3: Comparison of the accuracies for the voting ensembles with and without the KPCA voter, confirm- ing that adding the KPCA-based model to the voting ensemble always helps on Senseval-3 Lexical Sample  tasks.", "labels": [], "entities": [{"text": "confirm", "start_pos": 97, "end_pos": 104, "type": "METRIC", "confidence": 0.9717150330543518}]}]}