{"title": [{"text": "Chinese Term Extraction from Web Pages Based on Compound word Productivity", "labels": [], "entities": [{"text": "Chinese Term Extraction from Web Pages", "start_pos": 0, "end_pos": 38, "type": "TASK", "confidence": 0.7441444993019104}]}], "abstractContent": [{"text": "In this paper, we propose an automatic term recognition system for Chinese.", "labels": [], "entities": [{"text": "term recognition", "start_pos": 39, "end_pos": 55, "type": "TASK", "confidence": 0.7038446664810181}]}, {"text": "Our idea is based on the relation between a compound word and its constituents that are simple words or individual Chinese character.", "labels": [], "entities": []}, {"text": "More precisely, we basically focus on how many words/characters adjoin the word/character in question to form compound words.", "labels": [], "entities": []}, {"text": "We also take into account the frequency of term.", "labels": [], "entities": [{"text": "frequency", "start_pos": 30, "end_pos": 39, "type": "METRIC", "confidence": 0.9755564332008362}]}, {"text": "We evaluated word based method and character based method with several Chinese Web pages, resulting in precision of 75% for top ten candidate terms.", "labels": [], "entities": [{"text": "precision", "start_pos": 103, "end_pos": 112, "type": "METRIC", "confidence": 0.9991828799247742}]}], "introductionContent": [{"text": "Automatic term recognition, ATR in short, aims at extracting domain specific terms from a corpus or Web pages.", "labels": [], "entities": [{"text": "Automatic term recognition", "start_pos": 0, "end_pos": 26, "type": "TASK", "confidence": 0.6608193318049113}, {"text": "extracting domain specific terms from a corpus or Web pages", "start_pos": 50, "end_pos": 109, "type": "TASK", "confidence": 0.7781704127788543}]}, {"text": "Domain specific terms are terms that express the concept specifically defined in the given domain.", "labels": [], "entities": []}, {"text": "They are required to have a unique meaning in order for efficient communication about the topic of the domain.", "labels": [], "entities": []}, {"text": "It is, however, difficult to decide automatically whether they are unique.", "labels": [], "entities": []}, {"text": "So we put this issue aside.", "labels": [], "entities": []}, {"text": "In terms of feasibility, their grammatical status is important, for instance part of speeches.", "labels": [], "entities": []}, {"text": "Although they are not necessarily confined to simple words where \"simple word\" means a word which could not be further divided into shorter and more basic words, the majority of them are actually compound words,.", "labels": [], "entities": []}, {"text": "Thus, we here focus on both of simple and compound words.", "labels": [], "entities": []}, {"text": "In terms of text length, even one Web page which is not long gives us a number of domain specific vocabulary like \"national library\", \"library policy\" if the Web page is about libraries.", "labels": [], "entities": []}, {"text": "If we expand domain specific terms to this extent, the big portion of domain specific terms are compound words.", "labels": [], "entities": []}, {"text": "Obviously, the majority of compound words consist of relatively small number of distinct simple words.", "labels": [], "entities": []}, {"text": "In this situation, it is natural to pay attention to the relation among compound words and their constituent simple words.", "labels": [], "entities": []}, {"text": "( proposed an important feature of domain specific terms called termhood which refers to the degree that a linguistic unit is related to a domain-specific concept.", "labels": [], "entities": []}, {"text": "Presumably, it is necessary to develop an ATR method that calculates termhood of each term candidate extracted from a domain corpus that usually consists of a number of documents.", "labels": [], "entities": [{"text": "ATR", "start_pos": 42, "end_pos": 45, "type": "METRIC", "confidence": 0.7565125226974487}]}, {"text": "Many works of ATR use statistics of term candidate distribution in a corpus such as term frequency to calculate the termhood of every term candidate.", "labels": [], "entities": []}, {"text": "This frequency based methods, however, heavily depend on the size of corpus.", "labels": [], "entities": []}, {"text": "Thus we do not expect a good result if we extract domain specific terms from one or a few Web pages.", "labels": [], "entities": []}, {"text": "If we shift our focus from a corpus based statistics like frequency to term space that consists of all term candidates, we expect better result of extracted terms even from one Web page because of the following reason: A set of term candidates has its own structure like relations between compound words and their constituent simple words as stated before.", "labels": [], "entities": []}, {"text": "The statistical information about these relations comes from more microscopic structure than term frequency.", "labels": [], "entities": []}, {"text": "Thus, if we utilize more information from term space, it is reasonable to expect better performance in extracting from a small text like one Web page.", "labels": [], "entities": []}, {"text": "Without this kind of information, we will be suffering from the shortage of information for ATR.", "labels": [], "entities": [{"text": "ATR", "start_pos": 92, "end_pos": 95, "type": "DATASET", "confidence": 0.7174286246299744}]}, {"text": "Now look at frequency based information and information inherent with term space more closely.", "labels": [], "entities": []}, {"text": "Even though several kinds of statistics about actual use in a corpus such as term frequency give a good approximation of termhood.", "labels": [], "entities": []}, {"text": "They are not necessarily meanings in a writer's mind.", "labels": [], "entities": []}, {"text": "On the contrary, the statistics of term space can reflect the meaning in a writer's mind because it is up to a writer's decision how to make a compound word term to express a complicated concept using simple word terms as its components.", "labels": [], "entities": []}, {"text": "More precisely, if a certain simple word, say N, expresses the basic concept of a domain that the document treats, the writer of the document, we expect, uses N not only many times but in various ways.", "labels": [], "entities": []}, {"text": "One of typical way of this kind is that he/she composes quite a few compound words using N and uses these compound words in documents he/she writes.", "labels": [], "entities": []}, {"text": "For this reason, we have to focus on the relation among simple words and compound words when pursuing new ATR methods.", "labels": [], "entities": [{"text": "ATR", "start_pos": 106, "end_pos": 109, "type": "TASK", "confidence": 0.9260659217834473}]}, {"text": "One of the attempts to make use of this relation has been done by.", "labels": [], "entities": []}, {"text": "Their method is based on the number of distinct simple words that come left or right of a simple word term to makeup compound word terms.", "labels": [], "entities": []}, {"text": "In this paper, we apply their method to deal with Web pages written in Chinese.", "labels": [], "entities": []}, {"text": "In this paper, section 2 gives the background of ATR methods.", "labels": [], "entities": [{"text": "ATR", "start_pos": 49, "end_pos": 52, "type": "TASK", "confidence": 0.9622126221656799}]}, {"text": "In section 3 we introduce ATR method developed by.", "labels": [], "entities": [{"text": "ATR", "start_pos": 26, "end_pos": 29, "type": "METRIC", "confidence": 0.8563400506973267}]}, {"text": "Section 4, 5 and 6 are for how to apply their method to Chinese language and evaluation of two proposed method: 1) Word based method using Chinese morphological analyzer ICTCLAS(Zhang, Yu, Xiong and Liu. 2003), 2) Stop character based method.", "labels": [], "entities": [{"text": "Chinese morphological analyzer ICTCLAS", "start_pos": 139, "end_pos": 177, "type": "TASK", "confidence": 0.49732573330402374}]}], "datasetContent": [], "tableCaptions": []}