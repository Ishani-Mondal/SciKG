{"title": [{"text": "An Integrated Method for Chinese Unknown Word Extraction 1", "labels": [], "entities": [{"text": "Chinese Unknown Word Extraction", "start_pos": 25, "end_pos": 56, "type": "TASK", "confidence": 0.5883544832468033}]}], "abstractContent": [{"text": "Unknown word recognition is an important problem in Chinese word segmentation systems.", "labels": [], "entities": [{"text": "Unknown word recognition", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.6875394781430563}, {"text": "Chinese word segmentation", "start_pos": 52, "end_pos": 77, "type": "TASK", "confidence": 0.6027972400188446}]}, {"text": "In this paper, we propose an integrated method for Chinese unknown word extraction for off-line corpus processing, in which both context-entropy (on each side) and frequency ratio against background corpus are introduced to evaluate the candidate words.", "labels": [], "entities": [{"text": "Chinese unknown word extraction", "start_pos": 51, "end_pos": 82, "type": "TASK", "confidence": 0.6090073511004448}, {"text": "off-line corpus processing", "start_pos": 87, "end_pos": 113, "type": "TASK", "confidence": 0.6456422905127207}]}, {"text": "Both of the measures are computed efficiently on Suffix array with much less space overhead.", "labels": [], "entities": []}, {"text": "Our method can also be reinforced when combined with a basic Segmentor by boundary-verification and arbitrary n-gram words can be extracted by our method.", "labels": [], "entities": []}, {"text": "We test our method on Chinese novel Xiao Ao Jiang Hu, and obtain satisfactory achievements compared to traditional criteria such as Likelihood Ratio.", "labels": [], "entities": [{"text": "Chinese novel Xiao Ao Jiang Hu", "start_pos": 22, "end_pos": 52, "type": "DATASET", "confidence": 0.8155141174793243}]}], "introductionContent": [{"text": "The unique feature of Chinese writing system is that it is character-based, not word-based.", "labels": [], "entities": []}, {"text": "The fact that there are no delimiters between words poses the well-known problem of word segmentation.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 84, "end_pos": 101, "type": "TASK", "confidence": 0.7248505204916}]}, {"text": "Any Chinese Information Processing (CIP) systems beyond character level, such as information retrieval, automatic proofreading, text classification, text-tospeech conversion, syntactic parser, information extraction and machine translation, etc.", "labels": [], "entities": [{"text": "information retrieval", "start_pos": 81, "end_pos": 102, "type": "TASK", "confidence": 0.7840710878372192}, {"text": "text classification", "start_pos": 128, "end_pos": 147, "type": "TASK", "confidence": 0.7701695561408997}, {"text": "text-tospeech conversion", "start_pos": 149, "end_pos": 173, "type": "TASK", "confidence": 0.7188491672277451}, {"text": "syntactic parser", "start_pos": 175, "end_pos": 191, "type": "TASK", "confidence": 0.7110613882541656}, {"text": "information extraction", "start_pos": 193, "end_pos": 215, "type": "TASK", "confidence": 0.8149918019771576}, {"text": "machine translation", "start_pos": 220, "end_pos": 239, "type": "TASK", "confidence": 0.7707363665103912}]}, {"text": "should have a built-in word segmentation block.", "labels": [], "entities": [{"text": "word segmentation block", "start_pos": 23, "end_pos": 46, "type": "TASK", "confidence": 0.774350494146347}]}, {"text": "Currently, dictionary-based method is the basic and efficient one for word segmentation.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 70, "end_pos": 87, "type": "TASK", "confidence": 0.7618261575698853}]}, {"text": "A fixed Chinese electronic dictionary is required for most CIP systems.", "labels": [], "entities": []}, {"text": "Yet there are many unknown words (out of the fixed dictionary) coming into being all the time.", "labels": [], "entities": []}, {"text": "The unknown words are diverse, including proper nouns (person names, place names, organization names, etc.), domain-specific terminological nouns and abbreviations, even author-coined terms, etc. and they appear frequently in real text.", "labels": [], "entities": []}, {"text": "This may cause ambiguity in Chinese word segmentation and lead to errors in the applications.", "labels": [], "entities": [{"text": "Chinese word segmentation", "start_pos": 28, "end_pos": 53, "type": "TASK", "confidence": 0.6100382407506307}]}, {"text": "Presently, many systems (),,, ) focus on online recognition of proper nouns, and have achieved inspiring results in newscorpus but will be deteriorated in special text, such as spoken corpus, novels.", "labels": [], "entities": []}, {"text": "As to the rests of unknown words types, it is still the obstacle of application systems, although they are really important for specific collections of texts.", "labels": [], "entities": []}, {"text": "For instance, according to our count on Chinese novel Xiao Ao Jiang Hu (\u300a\u7b11\u50b2\u6c5f\u6e56\u300b) (JIN Yong (\u91d1\u5eb8), 1967), there are almost 515 unknown word types (out of our 243,539-item general dictionary) of total 39,404 occurrences and total 112,654 characters, and there are 983,134 characters overall in this novel (that is, about 11.46% characters of the whole novel are occupied by unknown words.).", "labels": [], "entities": [{"text": "JIN Yong (\u91d1\u5eb8), 1967)", "start_pos": 81, "end_pos": 101, "type": "DATASET", "confidence": 0.6684232552846273}]}, {"text": "And most of them, such as \"\u4e1c\u65b9\u4e0d\u8d25\"(person name), \"\u8f9f\u90aa \u5251 \u8c31 \"(normal noun), \" \u65e5 \u6708 \u795e \u6559 \"(organization name), etc.", "labels": [], "entities": []}, {"text": "can't be recognized by most current CIP systems.", "labels": [], "entities": []}, {"text": "It is important to note that without efficient unknown word extraction method, most CIP systems can't obtain satisfactory results.", "labels": [], "entities": [{"text": "word extraction", "start_pos": 55, "end_pos": 70, "type": "TASK", "confidence": 0.7133783251047134}]}], "datasetContent": [{"text": "We use novel Xiao Ao Jiang Hu as foreground corpus compared with the rest of novels of Mr. JIN Yong as background corpus.", "labels": [], "entities": []}, {"text": "The total characters of foreground and background corpus are 983,134 and 7,551,555 respectively.", "labels": [], "entities": []}, {"text": "We read through the novel Xiao Ao Jiang Hu and 5 graduates manually selected 515 new terms (out of our lexicon) with exact meaning in the novel as follows for the final test: (a) Proper nouns, such as person names: \"\u4ee4\u72d0\u51b2\", \"\u4e1c\u65b9\u4e0d\u8d25\", \"\u4ee4\u72d0\u5927\u54e5\", place names: \"\u9ed1\u6728 \u5d16 \", \" \u601d \u8fc7 \u5d16 \", \" \u6052 \u5c71 \u522b \u9662 \", organization names: \"\u65e5\u6708\u795e\u6559\", \"\u4e94\u5cb3\u5251\u6d3e\" etc.", "labels": [], "entities": []}, {"text": "(b) Normal nouns, such as \"\u8f9f\u90aa\u5251\u8c31\", \"\u5438\u661f\u5927 \u6cd5\", etc.", "labels": [], "entities": []}, {"text": "(c) Others, such as \"\u5267\u6597\", \"\u60ca\u6016\", etc.", "labels": [], "entities": []}, {"text": "By our method, we extract 117,807 candidates in this novel.", "labels": [], "entities": []}, {"text": "shows the result after filtering with Context-entropy on both sides and boundaryverification on different total extracted numbers; We also compared our integrated method to traditional measure LR.", "labels": [], "entities": []}, {"text": "On lower total number levels, LR will overrun our method in unknown-word recall, and in turn overrun by us on higher levels.", "labels": [], "entities": [{"text": "LR", "start_pos": 30, "end_pos": 32, "type": "METRIC", "confidence": 0.9568902254104614}, {"text": "recall", "start_pos": 73, "end_pos": 79, "type": "METRIC", "confidence": 0.7216194272041321}]}, {"text": "As to precision, our method always keeps ahead.", "labels": [], "entities": [{"text": "precision", "start_pos": 6, "end_pos": 15, "type": "METRIC", "confidence": 0.9966424703598022}]}, {"text": "We also notice that both of the methods have much low precision in extraction.", "labels": [], "entities": [{"text": "precision", "start_pos": 54, "end_pos": 63, "type": "METRIC", "confidence": 0.9992764592170715}]}, {"text": "To retrieve terms with much certain, we rank the entire final list on RFR values in final phase.", "labels": [], "entities": [{"text": "RFR", "start_pos": 70, "end_pos": 73, "type": "METRIC", "confidence": 0.4850810170173645}]}, {"text": "Most significant terms will comes in the front of ranked list.", "labels": [], "entities": []}, {"text": "shows that our method shows the top 12 of final list, and shows the performance of our method on different top levels when ranks the final list on RFR values.", "labels": [], "entities": [{"text": "RFR", "start_pos": 147, "end_pos": 150, "type": "METRIC", "confidence": 0.5797945857048035}]}], "tableCaptions": [{"text": " Table 1: Examples of candidates order by TC", "labels": [], "entities": [{"text": "TC", "start_pos": 42, "end_pos": 44, "type": "TASK", "confidence": 0.6225400567054749}]}, {"text": " Table 3: Result of our method compared to LR", "labels": [], "entities": [{"text": "LR", "start_pos": 43, "end_pos": 45, "type": "DATASET", "confidence": 0.507771909236908}]}]}