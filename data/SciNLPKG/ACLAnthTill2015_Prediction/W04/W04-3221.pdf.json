{"title": [{"text": "Attribute-Based and Value-Based Clustering: An Evaluation", "labels": [], "entities": []}], "abstractContent": [{"text": "In most research on concept acquisition from corpora, concepts are modeled as vectors of relations extracted from syntactic structures.", "labels": [], "entities": [{"text": "concept acquisition from corpora", "start_pos": 20, "end_pos": 52, "type": "TASK", "confidence": 0.8151917159557343}]}, {"text": "In the case of modifiers, these relations often specify values of attributes, as in (attr red); this is unlike what typically proposed in theories of knowledge representation, where concepts are typically defined in terms of their attributes (e.g., color).", "labels": [], "entities": [{"text": "knowledge representation", "start_pos": 150, "end_pos": 174, "type": "TASK", "confidence": 0.7658828496932983}]}, {"text": "We compared models of concepts based on values with models based on attributes, using lexical clustering as the basis for comparison.", "labels": [], "entities": []}, {"text": "We find that attribute-based models work better than value-based ones, and result in shorter descriptions; but that mixed models including both the best attributes and the best values work best of all.", "labels": [], "entities": []}], "introductionContent": [{"text": "In most recent research on concept acquisition from corpora (e.g., for lexicon construction), concepts are viewed as vectors of relations, or properties, extracted from syntactic structures, and many others).", "labels": [], "entities": [{"text": "concept acquisition from corpora", "start_pos": 27, "end_pos": 59, "type": "TASK", "confidence": 0.8109003603458405}]}, {"text": "These properties often specify values of attributes such as color, shape, or size: for example, the vector used by for the concept dog includes the property (dog adj-mod brown).", "labels": [], "entities": []}, {"text": "(We will use the term values hereto refer to any modifier.)", "labels": [], "entities": []}, {"text": "To our knowledge, however, no attempt has been made by computational linguists to use the attributes themselves in such vectors: i.e., to learn that the description of the concept dog includes elements such as (dog color) or (dog size).", "labels": [], "entities": []}, {"text": "This is surprising when considering that most models of concepts in the AI literature are based on such attributes.", "labels": [], "entities": []}, {"text": "Two problems need to be addressed when trying to identify concept attributes.", "labels": [], "entities": []}, {"text": "The first problem is that values are easier to extract.", "labels": [], "entities": []}, {"text": "We found, however, that patterns like the X of the dog, already used in) to find part-of relations (using techniques derived from those used in) to find hyponymy relations) are quite effective at finding attributes.", "labels": [], "entities": []}, {"text": "A second problem might be that instances of such patterns are less frequent than those used to extract values, even in large corpora such as the British National Corpus (BNC).", "labels": [], "entities": [{"text": "British National Corpus (BNC)", "start_pos": 145, "end_pos": 174, "type": "DATASET", "confidence": 0.971680482228597}]}, {"text": "But this problem, as well, is less serious when using the Web as a corpus.", "labels": [], "entities": []}, {"text": "We report on two experiments whose goal was to test whether identifying attributes leads to better lexical descriptions of concepts.", "labels": [], "entities": []}, {"text": "We do this by comparing the results obtained by using attributes or more general modifiers -that we will simply call values -as elements of concept vectors used to identify concept similarities via clustering.", "labels": [], "entities": []}, {"text": "In Section 2, we discuss how Web data were used to build attribute-and value-based concept vectors, and our clustering and evaluation methods.", "labels": [], "entities": []}, {"text": "In Section 3, we discuss a first experiment using the set of concepts used in.", "labels": [], "entities": []}, {"text": "In Section 4, we discuss a second experiment using 214 concepts from WordNet.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 69, "end_pos": 76, "type": "DATASET", "confidence": 0.9710363149642944}]}, {"text": "In Section 5 we return to the notion of attribute.", "labels": [], "entities": []}], "datasetContent": [{"text": "We used two types of measures to evaluate the clusters produced by CLUTO using the concept descriptions discussed above, both of which compare the clusters produced by the system to model clusters.", "labels": [], "entities": []}, {"text": "Accuracy is computed by dividing the number of correctly clustered concepts by the total number of concepts.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 0, "end_pos": 8, "type": "METRIC", "confidence": 0.9889193177223206}]}, {"text": "The number of correctly clustered concepts is determined by examining each system cluster, finding the class of each concept in the model clusters, and determining the majority class.", "labels": [], "entities": []}, {"text": "The cluster is then labeled with this class; the concepts belonging to it are taken to be correctly clustered, whereas the remaining concepts are judged to be incorrectly clustered.", "labels": [], "entities": []}, {"text": "In the contingency table evaluation, the clusters are converted into two lists (one for the system clusters and one for the model clusters) of yes-no answers to the question \"Does the pair of concepts occur in the same cluster?\" for each pair of concepts.", "labels": [], "entities": []}, {"text": "A contingency table is then built, from which recall (R), precision (P), fallout, and F measures can be computed.", "labels": [], "entities": [{"text": "recall (R)", "start_pos": 46, "end_pos": 56, "type": "METRIC", "confidence": 0.93142369389534}, {"text": "precision (P)", "start_pos": 58, "end_pos": 71, "type": "METRIC", "confidence": 0.9534001648426056}, {"text": "F", "start_pos": 86, "end_pos": 87, "type": "METRIC", "confidence": 0.9966073036193848}]}, {"text": "For example, if the model clusters are: (A, B, C) and (D), and the system clusters are: (A, B) and (C, D), the yes-no lists are as in, and the contingency table is as in.", "labels": [], "entities": []}, {"text": "One limitation of using Google is that even with an increased daily limit of 20,000, it wouldn't really be feasible to attempt to cluster, say, all of WordNet 100,000 noun concepts.", "labels": [], "entities": []}, {"text": "For this reason, we used much smaller sets of concepts in our two experiments.", "labels": [], "entities": []}, {"text": "The first set allowed us to compare our results with those obtained by; the second set consisted of a larger number of concepts from WordNet.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 133, "end_pos": 140, "type": "DATASET", "confidence": 0.9728707075119019}]}, {"text": "used a set of 34 concepts belonging to 3 different classes (animals, body parts, and geographical locations) to evaluate their method for acquiring lexical representations, HAL (Hyperspace Analogue to Language).", "labels": [], "entities": [{"text": "HAL", "start_pos": 173, "end_pos": 176, "type": "METRIC", "confidence": 0.7406162023544312}]}, {"text": "Lund and Burgess were able to correctly cluster all of the concepts except for one body part, tooth, which was incorrectly clustered with animals.", "labels": [], "entities": []}, {"text": "In this first experiment, we used the 34 Lund and Burgess concepts plus Italy, horse, and tongue (37 in total) to compare value-based and attribute-based description when used for clustering, using concept descriptions collected using the methods described above.", "labels": [], "entities": []}, {"text": "The input to clustering is a frequency table with concepts as rows and values, attributes, or both attributes and values as columns.", "labels": [], "entities": []}, {"text": "Each cell in the table contains the frequency of co-occurrence between the concept and corresponding value or attribute.", "labels": [], "entities": []}, {"text": "Before clustering, the frequencies are transformed into weighted values using the t test).", "labels": [], "entities": []}, {"text": "(The t test was found by to be the best weighting method.)", "labels": [], "entities": []}, {"text": "The t test formula we used for attributes is shown below: where N is the total number of relations, and C is a count function.", "labels": [], "entities": []}, {"text": "The values formula is similar.", "labels": [], "entities": []}, {"text": "We use the CLUTO vcluster command for clustering, with parameters: similarity function = Extended Jaccard Coefficient, clustering method = Graph Partitioning, no. of clusters = 3.", "labels": [], "entities": []}, {"text": "shows the accuracy of the produced clusters when using values, attributes, and the combination with different vector sizes.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9993650317192078}]}, {"text": "The results show that with concept descriptions of length 500, attributes (97.30%) are much more accurate than values (64.86%).", "labels": [], "entities": []}, {"text": "With vectors of size 1522, the accuracy with attributes remains the same, while the accuracy with values improves, but is still lower than the accuracy with attributes (94.59%).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 31, "end_pos": 39, "type": "METRIC", "confidence": 0.9994213581085205}, {"text": "accuracy", "start_pos": 84, "end_pos": 92, "type": "METRIC", "confidence": 0.9994565844535828}, {"text": "accuracy", "start_pos": 143, "end_pos": 151, "type": "METRIC", "confidence": 0.9982070922851562}]}, {"text": "This indicates that attributes have more discriminatory power than values: an attribute vector of size 500 is sufficient to produce a more accurate result than using a value vector of three times the size.", "labels": [], "entities": []}, {"text": "But perhaps the most interesting result is that even though further increasing the size of pure attribute-and value-descriptions (to 4753 and 4969, respectively) does not improve accuracy, perfect accuracy can be obtained by using vectors of length 3044, including the 1522 best attributes and the 1522 best values.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 179, "end_pos": 187, "type": "METRIC", "confidence": 0.9980751276016235}, {"text": "accuracy", "start_pos": 197, "end_pos": 205, "type": "METRIC", "confidence": 0.9983905553817749}]}, {"text": "This suggests that while attributes area good way of generalizing across properties, not all properties of concepts can be viewed as attribute/value pairs (section 5; also (Poesio and Almuhareb, submitted)).", "labels": [], "entities": []}, {"text": "In order to get a more realistic evaluation and a better comparison with work such as), we also ran a second experiment using a larger set of concepts from the WordNet noun hierarchy  The frequencies for attributes and values were again collected as in the first experiment.", "labels": [], "entities": [{"text": "WordNet noun hierarchy", "start_pos": 160, "end_pos": 182, "type": "DATASET", "confidence": 0.8938530882199606}]}, {"text": "However, these data were used in a different way.", "labels": [], "entities": []}, {"text": "In determining the weight, we performed the t test on boolean values instead of the original frequencies 6 , treating all positive frequencies as 1 and everything else as 0.", "labels": [], "entities": []}, {"text": "This eliminates the effect of variations in frequencies in the original data, the intuition being that frequencies do not add to the semantics of concepts: what we are interested in is the fact that a concept has a given attribute/value, regardless of how many times we have encountered this fact.", "labels": [], "entities": []}, {"text": "This approach is similar to the approach adopted in; see also) fora comparison of methods dealing with concept vectors based on raw frequencies or boolean values.", "labels": [], "entities": []}, {"text": "The transformed table is a binary table that contains only zeros and ones in its cells.", "labels": [], "entities": []}, {"text": "shows the contingency table for clusters produced based on boolean and frequency for the combined data of attributes and values; it shows that boolean data is more accurate in the four cases.", "labels": [], "entities": []}, {"text": "For clustering, as well, we used CLUTO in a different way.", "labels": [], "entities": [{"text": "clustering", "start_pos": 4, "end_pos": 14, "type": "TASK", "confidence": 0.9783887267112732}]}, {"text": "Instead of asking CLUTO to compute the similarities between the concepts, we computed them ourselves, using the version of the extended Jaccard similarity function used by Curran and Moens, as this version produces better results than the one used in CLUTO.", "labels": [], "entities": []}, {"text": "The two versions of the extended Jaccard function are shown below: where t m,i and t n,i are the weighted co-occurrence values between concept m and concept n with attribute/value i, and computed as in equation  We compute the similarity between each pair of concepts, produce a similarity matrix and send it to CLUTO for clustering.", "labels": [], "entities": []}, {"text": "We then call the scluster 6 In equation (1), this will effect only C(concept i , attribute j ), other counts will not be effected.", "labels": [], "entities": []}, {"text": "7 Here, we use full size vectors that contain all the features.", "labels": [], "entities": []}, {"text": "command of CLUTO with the following parameters: clustering method = Graph Partitioning, no. of clusters = 13.", "labels": [], "entities": []}, {"text": "The results of the evaluation are shown in.", "labels": [], "entities": []}, {"text": "Value-based concept descriptions resulted in better clusters than attribute-based when measured using Accuracy (71.96% vs. 64.02%), but the other measures all indicate that attributes work slightly better than values: e.g., F=55.55% for values, 56.64% for attributes.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 102, "end_pos": 110, "type": "METRIC", "confidence": 0.9989081621170044}, {"text": "F", "start_pos": 224, "end_pos": 225, "type": "METRIC", "confidence": 0.9978978633880615}]}, {"text": "The reason for this difference is that the Accuracy measure simply evaluates if each concept is assigned to its correct cluster, while the remaining measures concern about the relation between each pair of concepts (i.e., if they were assigned to the same cluster or not).", "labels": [], "entities": [{"text": "Accuracy measure", "start_pos": 43, "end_pos": 59, "type": "METRIC", "confidence": 0.9725355207920074}]}, {"text": "But, just as in Experiment 1, the best results by any measure are again obtained when using concept descriptions containing the best 'attributes' and the best 'values'; this time, however, the difference is much more significant: Accuracy is 85.51%, F is 74.41%.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 230, "end_pos": 238, "type": "METRIC", "confidence": 0.9994413256645203}, {"text": "F", "start_pos": 250, "end_pos": 251, "type": "METRIC", "confidence": 0.9969547986984253}]}, {"text": "shows the confusion matrix for the clusters produced using both attributes and values.", "labels": [], "entities": []}, {"text": "A close inspection of these clusters reveals that 'furniture' concepts were the less homogeneous because they were scattered among four different clusters.", "labels": [], "entities": []}, {"text": "There are 14 'furniture' concepts; six of them (bookcase, cabinet, couch, cradle, desk and wardrobe) were grouped in a separate cluster which also contains two more concepts (pickup and greenhouse).", "labels": [], "entities": []}, {"text": "Four of the concepts (bed, lamp, seat, and table) were clustered with 'body part' concepts.", "labels": [], "entities": []}, {"text": "Two of the concepts (dresser and sofa) were clustered with 'cloth' concepts, and the remaining two concepts (chair and lounge) were clustered with 'building' concepts.", "labels": [], "entities": []}, {"text": "Two points should be noted about the furniture concepts.", "labels": [], "entities": []}, {"text": "First, at least two concepts (seat and lounge) have more than one sense in WordNet.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 75, "end_pos": 82, "type": "DATASET", "confidence": 0.974398672580719}]}, {"text": "Seat was clustered with body part concepts, which is acceptable if we think of seat as \"the fleshy part of the human body that you sit on\" (WordNet, sense 2).", "labels": [], "entities": [{"text": "WordNet", "start_pos": 140, "end_pos": 147, "type": "DATASET", "confidence": 0.9694241881370544}]}, {"text": "The same for lounge, which was clustered with buildings, which is consistent with its second sense in WordNet: \"a public room (as in a hotel or airport) with seating where people can wait\".", "labels": [], "entities": [{"text": "WordNet", "start_pos": 102, "end_pos": 109, "type": "DATASET", "confidence": 0.9400049448013306}]}, {"text": "This indicates that techniques for differentiating between different senses are needed -e.g., using a soft clustering technique as in () instead of a hard clustering technique.", "labels": [], "entities": []}, {"text": "Second, furniture concepts may not have a common prototype that is shared by all of the member concepts.", "labels": [], "entities": []}, {"text": "This is a well known problem in the prototype theory of concepts).", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Model and the system answers for the  co-occurrence question", "labels": [], "entities": []}, {"text": " Table 3: The contingency table", "labels": [], "entities": []}, {"text": " Table 4: Clustering accuracy with values,  attributes, and their combination, using different  vector sizes", "labels": [], "entities": [{"text": "accuracy", "start_pos": 21, "end_pos": 29, "type": "METRIC", "confidence": 0.9943532943725586}]}, {"text": " Table 5: The contingency table based on boolean  and frequency for the combined attributes and  values", "labels": [], "entities": []}, {"text": " Table 6: Clustering evaluation based on values,  attributes, and the combination", "labels": [], "entities": []}, {"text": " Table 7: The confusion matrix for the clusters  produced using both attributes and values", "labels": [], "entities": []}]}