{"title": [{"text": "Virtual Modality: a Framework for Testing and Building Multimodal Applications", "labels": [], "entities": [{"text": "Virtual Modality", "start_pos": 0, "end_pos": 16, "type": "TASK", "confidence": 0.7615065574645996}]}], "abstractContent": [{"text": "This paper introduces a method that generates simulated multimodal input to be used in testing multimodal system implementations, as well as to build statistically motivated multimodal integration modules.", "labels": [], "entities": []}, {"text": "The generation of such data is inspired by the fact that true multimodal data, recorded from real usage scenarios, is difficult and costly to obtain in large amounts.", "labels": [], "entities": []}, {"text": "On the other hand, thanks to operational speech-only dialogue system applications, a wide selection of speech/text data (in the form of transcriptions, recognizer outputs, parse results, etc.) is available.", "labels": [], "entities": []}, {"text": "Taking the textual transcriptions and converting them into multimodal inputs in order to assist multimodal system development is the underlying idea of the paper.", "labels": [], "entities": []}, {"text": "A conceptual framework is established which utilizes two input channels: the original speech channel and an additional channel called Virtual Modality.", "labels": [], "entities": []}, {"text": "This additional channel provides a certain level of abstraction to represent non-speech user inputs (e.g., gestures or sketches).", "labels": [], "entities": []}, {"text": "From the transcriptions of the speech modality, pre-defined semantic items (e.g., nominal location references) are identified, removed, and replaced with deictic references (e.g., here, there).", "labels": [], "entities": []}, {"text": "The deleted semantic items are then placed into the Virtual Modality channel and, according to external parameters (such as a pre-defined user population with various deviations), temporal shifts relative to the instant of each corresponding deictic reference are issued.", "labels": [], "entities": []}, {"text": "The paper explains the procedure followed to create Virtual Modality data, the details of the speech-only database, and results based on a multimodal city information and navigation application.", "labels": [], "entities": []}], "introductionContent": [{"text": "Multimodal systems have recently drawn significant attention from researchers, and the reasons for such an interest are many.", "labels": [], "entities": []}, {"text": "First, speech recognition based applications and systems have become mature enough for larger-scale deployment.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 7, "end_pos": 25, "type": "TASK", "confidence": 0.8017464280128479}]}, {"text": "The underlying technologies are gradually exhibiting increased robustness and performance, and from the usability point of view, users can see some clear benefits from speech-driven applications.", "labels": [], "entities": []}, {"text": "The next evolutionary step is the extension of the \"one dimensional\" (i.e., speech-only) interface capabilities to include other modalities, such as gesture, sketch, gaze, and text.", "labels": [], "entities": []}, {"text": "This will lead to a better and more comprehensive user experience.", "labels": [], "entities": []}, {"text": "A second reason is the widely accepted, and expected, mobility and pervasiveness of computers.", "labels": [], "entities": []}, {"text": "Devices are getting more and more powerful and versatile; they can be connected anywhere and anytime to networks, as well as to each other.", "labels": [], "entities": []}, {"text": "This poses new demands for the user interface.", "labels": [], "entities": []}, {"text": "It is no longer sufficient to support only a single input modality.", "labels": [], "entities": []}, {"text": "Depending on the specific application, the given usage scenario, and the context, for example, users should be offered a variety of options by which to interact with the system in an appropriate and efficient way.", "labels": [], "entities": []}, {"text": "Third, as the output capabilities of devices provide ever-increasing multimedia experiences, it is natural that the input mechanism must also deal with various modalities in an intuitive and comprehensive manner.", "labels": [], "entities": []}, {"text": "If a map is displayed to the user, it is natural to expect that the user may want to relate to this physical entity, for instance, via gestures, pointing, gazing or by other, not necessarily speech-based, communicative means.", "labels": [], "entities": []}, {"text": "Multimodal interfaces give the user alternatives and flexibility in terms of the interaction; they are enabling rather than restricting.", "labels": [], "entities": []}, {"text": "The primary goal is to fully understand the user's intention, and this can only be realized if all intentional user inputs, as well as any available contextual information (e.g., location, pragmatics, sensory data, user preferences, current and previous interaction histories) are taken into account.", "labels": [], "entities": []}, {"text": "This paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 introduces the concept of Virtual Modality and how the multimodal data are generated.", "labels": [], "entities": []}, {"text": "Section 3 explains the underlying Galaxy environment and briefly summarizes the operation of the Context Resolution module responsible for, among other tasks, resolving deictic references.", "labels": [], "entities": [{"text": "Context Resolution", "start_pos": 97, "end_pos": 115, "type": "TASK", "confidence": 0.8147341907024384}]}, {"text": "The data generation as well as statistics is covered in Section 4.", "labels": [], "entities": [{"text": "data generation", "start_pos": 4, "end_pos": 19, "type": "TASK", "confidence": 0.7462206184864044}]}, {"text": "The experimental methodology is described in Section 5.", "labels": [], "entities": []}, {"text": "Finally, the results are summarized and directions for future work are outlined.", "labels": [], "entities": []}], "datasetContent": [{"text": "The experimental setup is depicted in.", "labels": [], "entities": []}, {"text": "The core of the system is the Galaxy Communicator architecture extended with the Batchmode server (as explained in Section 3 and shown in more details in).", "labels": [], "entities": [{"text": "Batchmode server", "start_pos": 81, "end_pos": 97, "type": "DATASET", "confidence": 0.9256724417209625}]}, {"text": "It must be noted that although the sentences are taken from dialogues, each sentence is processed independently so the focus of attention is the new aspect introduced by the Virtual Modality.", "labels": [], "entities": []}, {"text": "There are two runs for each experiment.", "labels": [], "entities": []}, {"text": "First, the original sentences are input to the Batchmode server and then passed to the Voyager application via the Galaxy architecture.", "labels": [], "entities": []}, {"text": "The outcomes are the corresponding frames from the Language Understanding server (the Context Resolution server is not invoked due to the absence of context in this case).", "labels": [], "entities": [{"text": "Context Resolution", "start_pos": 86, "end_pos": 104, "type": "TASK", "confidence": 0.7475873827934265}]}, {"text": "The second run takes the Virtual Modality data, namely the new sentences with the deictic references and the accompanying data for the Virtual Modality channel (semantic value, begin-end markers).", "labels": [], "entities": []}, {"text": "The output frames are produced by the Language Understanding module and further processed by the Context Resolution server to resolve deictic references.", "labels": [], "entities": [{"text": "Context Resolution", "start_pos": 97, "end_pos": 115, "type": "TASK", "confidence": 0.8047249019145966}]}, {"text": "The last step of the execution is the comparison of the frame pairs: one frame for the original sentence and the other for the Virtual Modality data.", "labels": [], "entities": []}, {"text": "The results presented below are from the very initial tests; clearly more work is needed to justify the concept of Virtual Modality, as well as to fully investigate the utilization of the generated data in testing.", "labels": [], "entities": []}, {"text": "The initial experiments were run on 436 sentences, which represent a small portion of the entire database.", "labels": [], "entities": []}, {"text": "The results indicate that if only one deictic reference per sentence is used with zero deviation, the generated output frames are identical to the original sentence output frames in 82.03% of the cases.", "labels": [], "entities": []}, {"text": "The erroneous results occurred when the preposition and a chosen deictic form together formed an ungrammatical expression (e.g. \"how about on over there?\").", "labels": [], "entities": []}, {"text": "The data generation process requires further refinements to decide whether a preposition can be used with a randomly selected deictic expression.", "labels": [], "entities": []}, {"text": "In sentences with two deictic references only 78.26% agreement was achieved.", "labels": [], "entities": [{"text": "agreement", "start_pos": 53, "end_pos": 62, "type": "METRIC", "confidence": 0.9875404238700867}]}, {"text": "The major reason for this is the incorrect replacement of highways and highway numbers with deictic references by the data generation process.", "labels": [], "entities": []}, {"text": "Also, awkward combinations of deictic references result in incorrect resolution.", "labels": [], "entities": []}, {"text": "All these problems will be addressed in future work.", "labels": [], "entities": []}, {"text": "Additionally, since the current version of the Context Resolution server has no built-in time limits for resolving deictic references, future work will aim to incorporate some kind of temporal considerations and adaptivity.", "labels": [], "entities": [{"text": "Context Resolution server", "start_pos": 47, "end_pos": 72, "type": "TASK", "confidence": 0.8960399031639099}]}, {"text": "The Virtual Modality data creation process supports the generation of a large amount of timeshifted versions of the original data, which can be used for further testing of the system's temporal robustness.", "labels": [], "entities": [{"text": "Virtual Modality data creation", "start_pos": 4, "end_pos": 34, "type": "TASK", "confidence": 0.6272153556346893}]}], "tableCaptions": [{"text": " Table 2. Overview of the original Voyager  data (turn = sentence).", "labels": [], "entities": [{"text": "Voyager  data", "start_pos": 35, "end_pos": 48, "type": "DATASET", "confidence": 0.8553435802459717}]}]}