{"title": [{"text": "Verb Sense and Subcategorization: Using Joint Inference to Improve Performance on Complementary Tasks", "labels": [], "entities": [{"text": "Verb Sense", "start_pos": 0, "end_pos": 10, "type": "TASK", "confidence": 0.6705115735530853}]}], "abstractContent": [{"text": "We propose a general model for joint inference in correlated natural language processing tasks when fully annotated training data is not available, and apply this model to the dual tasks of word sense disambiguation and verb subcategorization frame determination.", "labels": [], "entities": [{"text": "word sense disambiguation", "start_pos": 190, "end_pos": 215, "type": "TASK", "confidence": 0.6626189748446146}, {"text": "verb subcategorization frame determination", "start_pos": 220, "end_pos": 262, "type": "TASK", "confidence": 0.7084917351603508}]}, {"text": "The model uses the EM algorithm to simultaneously complete partially annotated training sets and learn a generative probabilis-tic model over multiple annotations.", "labels": [], "entities": []}, {"text": "When applied to the word sense and verb subcategorization frame determination tasks, the model learns sharp joint probability distributions which correspond to linguistic intuitions about the correlations of the variables.", "labels": [], "entities": [{"text": "word sense and verb subcategorization frame determination", "start_pos": 20, "end_pos": 77, "type": "TASK", "confidence": 0.6538959230695452}]}, {"text": "Use of the joint model leads to error reductions over competitive independent models on these tasks.", "labels": [], "entities": [{"text": "error", "start_pos": 32, "end_pos": 37, "type": "METRIC", "confidence": 0.9624786972999573}]}], "introductionContent": [{"text": "Natural language processing research has traditionally been divided into a number of separate tasks, each of which is believed to bean important subtask of the larger language comprehension or generation problem.", "labels": [], "entities": [{"text": "Natural language processing research", "start_pos": 0, "end_pos": 36, "type": "TASK", "confidence": 0.7622547447681427}]}, {"text": "These tasks are usually addressed separately, with systems designed to solve a single problem.", "labels": [], "entities": []}, {"text": "However, many of these tasks are not truly independent; if solutions to one were known they would facilitate finding solutions to the others.", "labels": [], "entities": []}, {"text": "For some sets of these problems, one would like to be able to do joint inference, where information of one kind can influence decisions about information of another kind and vice versa.", "labels": [], "entities": []}, {"text": "For instance, information about named entities can usefully inform the decisions of a part-of-speech tagger, but equally, part-of-speech information can help a named entity recognizer.", "labels": [], "entities": []}, {"text": "If one had a large corpus annotated with all the information types of interest, one could estimate a joint distribution overall of the variables simply by counting.", "labels": [], "entities": []}, {"text": "However, it is more often the case that one lacks any jointly annotated corpus, or at least one that is sufficiently large, given that the joint distribution is necessarily sparser than the marginal distributions.", "labels": [], "entities": []}, {"text": "It would therefore be useful to be able to build a model for this joint inference task using only partially supervised data.", "labels": [], "entities": []}, {"text": "In this System Name Accuracy kunlp 57.6 jhu-english-JHU-final 56.6 SMUls 56.3 LIA-Sinequa-Lexsample 53.5 manning-cs224n 52.3 paper we examine these problems in the context of joint inference over verb senses and their subcategorization frames (SCFs).", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 2: The learned joint distribution over the senses  and subcategorizations of the verb begin (in percent  probability). Low probability senses and subcategoriza- tions have been omitted.", "labels": [], "entities": []}, {"text": " Table 3. Note that the sense and SCF  variables are highly correlated for this verb. Sense  2:30:00 occurs almost entirely with verb phrase ar- guments, sense 2:30:01 occurs almost entirely as a  transitive verb, and sense 2:42:04 occurs as an in- transitive verb (no arguments following the verb).  It should be evident that the strong correlation be-tween these two variables can be exploited to in- crease performance in the tasks of predicting their  values in either direction, even when the evidence is  weak or uncertain.", "labels": [], "entities": []}, {"text": " Table 4: Comparison of the performance of the indepen- dent and joint inference models on the verb sense and  SCF tasks,evaluated on the Senseval-2 test set, for each  of the 29 verbs in the study. These results were obtained  with no per-verb parameter optimization. Note the great  variation in problem difficulty and joint model perfor- mance across verbs.", "labels": [], "entities": [{"text": "Senseval-2 test set", "start_pos": 138, "end_pos": 157, "type": "DATASET", "confidence": 0.7791733940442404}]}]}