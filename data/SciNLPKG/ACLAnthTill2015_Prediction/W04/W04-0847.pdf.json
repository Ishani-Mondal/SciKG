{"title": [{"text": "Optimizing Feature Set for Chinese Word Sense Disambiguation", "labels": [], "entities": [{"text": "Chinese Word Sense Disambiguation", "start_pos": 27, "end_pos": 60, "type": "TASK", "confidence": 0.6826417446136475}]}], "abstractContent": [{"text": "This article describes the implementation of I 2 R word sense disambiguation system (I 2 R \u2212 W SD) that participated in one senseval3 task: Chinese lexical sample task.", "labels": [], "entities": [{"text": "I 2 R word sense disambiguation", "start_pos": 45, "end_pos": 76, "type": "TASK", "confidence": 0.5463687678178152}]}, {"text": "Our core algorithm is a supervised Naive Bayes classifier.", "labels": [], "entities": []}, {"text": "This classifier utilizes an optimal feature set, which is determined by maximizing the cross validated accuracy of NB classifier on training data.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 103, "end_pos": 111, "type": "METRIC", "confidence": 0.9167668223381042}]}, {"text": "The optimal feature set includes part-of-speech with position information in local context , and bag of words in topical context.", "labels": [], "entities": []}], "introductionContent": [{"text": "Word sense disambiguation (WSD) is to assign appropriate meaning to a given ambiguous word in a text.", "labels": [], "entities": [{"text": "Word sense disambiguation (WSD)", "start_pos": 0, "end_pos": 31, "type": "TASK", "confidence": 0.8199164172013601}]}, {"text": "Corpus based method is one of the successful lines of research on WSD.", "labels": [], "entities": [{"text": "WSD", "start_pos": 66, "end_pos": 69, "type": "TASK", "confidence": 0.9635178446769714}]}, {"text": "Many supervised learning algorithms have been applied for WSD, ex.", "labels": [], "entities": [{"text": "WSD", "start_pos": 58, "end_pos": 61, "type": "TASK", "confidence": 0.9786631464958191}]}, {"text": "Bayesian learning (), exemplar based learning, decision list), neural network (, maximum entropy method (), etc..", "labels": [], "entities": []}, {"text": "In this paper, we employ Naive Bayes classifier to perform WSD.", "labels": [], "entities": [{"text": "WSD", "start_pos": 59, "end_pos": 62, "type": "TASK", "confidence": 0.7660467624664307}]}, {"text": "Resolving the ambiguity of words usually relies on the contexts of their occurrences.", "labels": [], "entities": [{"text": "Resolving the ambiguity of words", "start_pos": 0, "end_pos": 32, "type": "TASK", "confidence": 0.8914446949958801}]}, {"text": "The feature set used for context representation consists of local and topical features.", "labels": [], "entities": [{"text": "context representation", "start_pos": 25, "end_pos": 47, "type": "TASK", "confidence": 0.7275035381317139}]}, {"text": "Local features include part of speech tags of words within local context, morphological information of target word, local collocations, and syntactic relations between contextual words and target word, etc..", "labels": [], "entities": []}, {"text": "Topical features are bag of words occurred within topical context.", "labels": [], "entities": []}, {"text": "Contextual features play an important role in providing discrimination information for classifiers in WSD.", "labels": [], "entities": [{"text": "WSD", "start_pos": 102, "end_pos": 105, "type": "TASK", "confidence": 0.904137372970581}]}, {"text": "In other words, an informative feature set will help classifiers to accurately disambiguate word senses, but an uninformative feature set will deteriorate the performance of classifiers.", "labels": [], "entities": []}, {"text": "In this paper, we optimize feature set by maximizing the cross validated accuracy of Naive Bayes classifier on sense tagged training data.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 73, "end_pos": 81, "type": "METRIC", "confidence": 0.9463565945625305}]}], "datasetContent": [{"text": "In this paper, five fold cross validation method was employed to estimate the accuracy of our classifier, which was the criterion for evaluation of feature sets.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 78, "end_pos": 86, "type": "METRIC", "confidence": 0.9991735816001892}]}, {"text": "All of the sense tagged examples of some target word in senseval3 training data were shuffled and divided into five equal folds.", "labels": [], "entities": [{"text": "senseval3 training data", "start_pos": 56, "end_pos": 79, "type": "DATASET", "confidence": 0.7440894246101379}]}, {"text": "We used four folds as training set and the remaining fold as test set.", "labels": [], "entities": []}, {"text": "This procedure was repeated five times under different division between training set and test set.", "labels": [], "entities": []}, {"text": "The average accuracy over five runs is defined as the accuracy of our classifier.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 12, "end_pos": 20, "type": "METRIC", "confidence": 0.9243316054344177}, {"text": "accuracy", "start_pos": 54, "end_pos": 62, "type": "METRIC", "confidence": 0.9992495179176331}]}, {"text": "For each word, the optimal value of topical context window siz\u00ea n twas determined by selecting a minimal value of n t which maximized the cross validated accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 154, "end_pos": 162, "type": "METRIC", "confidence": 0.9165223240852356}]}, {"text": "summarizes the results of Naive Bayes classifier using four feature sets evaluated on senseval3 Chinese training data.", "labels": [], "entities": [{"text": "Naive Bayes classifier", "start_pos": 26, "end_pos": 48, "type": "TASK", "confidence": 0.6909875671068827}, {"text": "senseval3 Chinese training data", "start_pos": 86, "end_pos": 117, "type": "DATASET", "confidence": 0.9473719298839569}]}, {"text": "shows the accuracy of Naive Bayes classifier as a function of topical context window size on four nouns and three verbs.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9990658164024353}, {"text": "Naive Bayes classifier", "start_pos": 22, "end_pos": 44, "type": "TASK", "confidence": 0.6415403286616007}]}, {"text": "Several results should be noted specifically: If overall accuracy over 20 Chinese characters is used as evaluation criterion for feature set, the four feature sets can be sorted as follows: F EAT U REA1 > F EAT U REA2 \u2248 F EAT U REB1 > F EAT U REB2.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 57, "end_pos": 65, "type": "METRIC", "confidence": 0.9943384528160095}, {"text": "F EAT U REA1", "start_pos": 190, "end_pos": 202, "type": "METRIC", "confidence": 0.797745406627655}, {"text": "F EAT U REB2", "start_pos": 235, "end_pos": 247, "type": "DATASET", "confidence": 0.5776499882340431}]}, {"text": "This indicated that simply increasing local window size or enriching feature set by incorporating bigram templates, local word with position information, and local words with POS tags did not improve the performance of sense disambiguation.", "labels": [], "entities": [{"text": "sense disambiguation", "start_pos": 219, "end_pos": 239, "type": "TASK", "confidence": 0.7136280089616776}]}, {"text": "In, it showed that with FEATUREA1, the optimal topical context window size was less than 10 words for 13 out of 20 target words.", "labels": [], "entities": [{"text": "FEATUREA1", "start_pos": 24, "end_pos": 33, "type": "METRIC", "confidence": 0.9921042919158936}]}, {"text": "showed that for most of nouns and verbs, Naive Bayes classifier achieved best disambiguation accuracy with small topical context window size (<10 words).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 93, "end_pos": 101, "type": "METRIC", "confidence": 0.9881651401519775}]}, {"text": "This gives the evidence that for most of Chinese words, including nouns and verbs, the near distance context is more important than the long distance context for sense disambiguation.", "labels": [], "entities": [{"text": "sense disambiguation", "start_pos": 162, "end_pos": 182, "type": "TASK", "confidence": 0.7439851760864258}]}, {"text": "The empirical study in section 6 showed that FEA-TUREA1 performed best among all the feature sets.", "labels": [], "entities": [{"text": "FEA-TUREA1", "start_pos": 45, "end_pos": 55, "type": "METRIC", "confidence": 0.9872380495071411}]}, {"text": "A Naive Bayes classifier with FEATUREA1 as feature set was learned from all the senseval3 Chinese training data for each target word.", "labels": [], "entities": [{"text": "FEATUREA1", "start_pos": 30, "end_pos": 39, "type": "METRIC", "confidence": 0.997337281703949}, {"text": "senseval3 Chinese training data", "start_pos": 80, "end_pos": 111, "type": "DATASET", "confidence": 0.8552134335041046}]}, {"text": "Then we used this classifier to determine the senses of occurrences of target words in test data.", "labels": [], "entities": []}, {"text": "The official result of I 2 R \u2212 W SD system in Chinese lexical sample task is listed below: Precision: 60.40% (229.00 correct of 379.00 attempted).", "labels": [], "entities": [{"text": "Precision", "start_pos": 91, "end_pos": 100, "type": "METRIC", "confidence": 0.9984443783760071}]}, {"text": "Recall: 60.40% (229.00 correct of 379.00 in total).", "labels": [], "entities": [{"text": "Recall", "start_pos": 0, "end_pos": 6, "type": "METRIC", "confidence": 0.9852022528648376}, {"text": "correct", "start_pos": 23, "end_pos": 30, "type": "METRIC", "confidence": 0.9369484186172485}]}, {"text": "Attempted: 100.00% (379.00 attempted of 379.00 in total).", "labels": [], "entities": [{"text": "Attempted", "start_pos": 0, "end_pos": 9, "type": "METRIC", "confidence": 0.9915018081665039}]}], "tableCaptions": []}