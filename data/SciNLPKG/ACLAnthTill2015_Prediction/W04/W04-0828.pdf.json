{"title": [{"text": "TALP System for the English Lexical Sample Task", "labels": [], "entities": [{"text": "TALP", "start_pos": 0, "end_pos": 4, "type": "METRIC", "confidence": 0.6978541612625122}, {"text": "English Lexical Sample", "start_pos": 20, "end_pos": 42, "type": "TASK", "confidence": 0.5101131101449331}]}], "abstractContent": [], "introductionContent": [{"text": "This paper describes the TALP system on the English Lexical Sample task of the Senseval-3 1 event.", "labels": [], "entities": [{"text": "TALP", "start_pos": 25, "end_pos": 29, "type": "METRIC", "confidence": 0.8903582096099854}]}, {"text": "The system is fully supervised and relies on a particular Machine Learning algorithm, namely Support Vector Machines.", "labels": [], "entities": []}, {"text": "It does not use extra examples than those provided by Senseval-3 organisers, though it uses external tools and ontologies to extract part of the representation features.", "labels": [], "entities": []}, {"text": "Three main characteristics have to be pointed out from the system architecture.", "labels": [], "entities": []}, {"text": "The first thing is the way in which the multiclass classification problem posed by WSD is addressed using the binary SVM classifiers.", "labels": [], "entities": [{"text": "multiclass classification", "start_pos": 40, "end_pos": 65, "type": "TASK", "confidence": 0.757110595703125}]}, {"text": "Two different approaches for binarizing multiclass problems have been tested: one-vs-all and constraint classification.", "labels": [], "entities": [{"text": "constraint classification", "start_pos": 93, "end_pos": 118, "type": "TASK", "confidence": 0.6874513179063797}]}, {"text": "Ina cross-validation experimental setting the best strategy has been selected at word level.", "labels": [], "entities": []}, {"text": "Section 2 is devoted to explain this issue in detail.", "labels": [], "entities": []}, {"text": "The second characteristic is the rich set of features used to represent training and test examples.", "labels": [], "entities": []}, {"text": "Topical and local context features are used as usual, but also syntactic relations and semantic features indicating the predominant semantic classes in the example context are taken into account.", "labels": [], "entities": []}, {"text": "A detailed description of the features is presented in section 3.", "labels": [], "entities": []}, {"text": "And finally, since each word represents a learning problem with different characteristics, a per-word feature selection has been applied.", "labels": [], "entities": []}, {"text": "This tuning process is explained in detail in section 4.", "labels": [], "entities": []}, {"text": "The last two sections discuss the experimental results (section 5) and present the main conclusions of the work performed (section 6).", "labels": [], "entities": []}], "datasetContent": [{"text": "For each binarization approach, we performed a feature selection process consisting of two consecutive steps: \u2022 POS feature selection: Using the Senseval-2 corpus, an exhaustive selection of the best set of features for each particular Part-of-Speech was performed.", "labels": [], "entities": [{"text": "POS feature selection", "start_pos": 112, "end_pos": 133, "type": "TASK", "confidence": 0.649861087401708}, {"text": "Senseval-2 corpus", "start_pos": 145, "end_pos": 162, "type": "DATASET", "confidence": 0.8823578059673309}]}, {"text": "These feature sets were taken as the initial sets in the feature selection process of Senseval-3.", "labels": [], "entities": []}, {"text": "\u2022 Word feature selection: We applied a forward(selection)-backward(deletion) twostep procedure to obtain the best feature selection per word.", "labels": [], "entities": [{"text": "Word feature selection", "start_pos": 2, "end_pos": 24, "type": "TASK", "confidence": 0.6434198319911957}]}, {"text": "For each word, the process starts with the best feature set obtained in the previous step according to its Part-of-Speech.", "labels": [], "entities": []}, {"text": "Now, during selection, we consider those features not selected during POS feature selection, adding all features which produce some improvement.", "labels": [], "entities": []}, {"text": "During deletion, we consider only those features selected during POS feature selection, removing all features which produces some improvement.", "labels": [], "entities": [{"text": "POS feature selection", "start_pos": 65, "end_pos": 86, "type": "TASK", "confidence": 0.680912176767985}]}, {"text": "Although this addition-deletion procedure could be iterated until no further improvement is achieved, we only performed a unique iteration because of the computational overhead.", "labels": [], "entities": []}, {"text": "One brief experiment (not reported here) for one-vs-all achieves an increase of 2.63% inaccuracy for the first iteration and 0.52% fora second one.", "labels": [], "entities": []}, {"text": "First iteration improves the accuracy of 53 words and the second improves only 15.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 29, "end_pos": 37, "type": "METRIC", "confidence": 0.9993001222610474}]}, {"text": "Comparing the evolution of these 15 words, the increase inaccuracy is of 2.06% for the first iteration and 1.68% for the second one.", "labels": [], "entities": [{"text": "inaccuracy", "start_pos": 56, "end_pos": 66, "type": "METRIC", "confidence": 0.9135338664054871}]}, {"text": "These results may suggest that accuracy could be increased by this iteration procedure.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 31, "end_pos": 39, "type": "METRIC", "confidence": 0.9993153810501099}]}, {"text": "The result of this process is the selection of the best binarization approach and the best feature set for each individual word.", "labels": [], "entities": []}, {"text": "Considering feature selection, we have inspected the selected attributes for all the words and we observed that among these attributes there are features of all four types.", "labels": [], "entities": []}, {"text": "The most selected features are the local ones, and among them those of 'first noun/adjective on the left/right'; from topical features the most selected ones are the 'comb' and in a less measure the 'topic'; from the knowledge-based the most selected feature are those of 'sumo' and 'domains labels'; and from syntactical ones, those of 'Yarowsky's patterns'.", "labels": [], "entities": []}, {"text": "All the features previously mentioned where selected at least for 50 of the 57 Senseval-3 words.", "labels": [], "entities": []}, {"text": "Even so, it is useful the use of all features when a selection procedure is applied.", "labels": [], "entities": []}, {"text": "These general features do notwork fine for all words.", "labels": [], "entities": []}, {"text": "Some words make use of the less selected features; that is, every word is a different problem.", "labels": [], "entities": []}, {"text": "Regarding the implementation details of the system, we used SVM light), a very robust and complete implementation of Support Vector Machines learning algorithms, which is freely available for research purposes . A simple lineal kernel with a regularization C value of 0.1 was applied.", "labels": [], "entities": []}, {"text": "This parameter was empirically decided on the basis of our previous experiments on the Senseval-2 corpus.", "labels": [], "entities": [{"text": "Senseval-2 corpus", "start_pos": 87, "end_pos": 104, "type": "DATASET", "confidence": 0.9166163206100464}]}, {"text": "Additionally, previous tests using non-linear kernels did not provide better results.", "labels": [], "entities": []}, {"text": "The selection of the best feature set and the binarization scheme per word described above, have been performed using a 5-fold cross validation procedure on the Senseval-3 training set.", "labels": [], "entities": [{"text": "Senseval-3 training set", "start_pos": 161, "end_pos": 184, "type": "DATASET", "confidence": 0.8848037521044413}]}, {"text": "The five partitions of the training set were obtained maintaining, as much as possible, the initial distribution of examples per sense.", "labels": [], "entities": []}, {"text": "After several experiments considering the 'U' label as an additional regular class, we found that we obtained better results by simply ignoring it.", "labels": [], "entities": []}, {"text": "Then, if a training example was tagged only with this label, it was removed from the training set.", "labels": [], "entities": []}, {"text": "If the example was tagged with this label and others, the 'U' label was also removed from the learning example.", "labels": [], "entities": []}, {"text": "In that way, the TALP system do not assigns 'U' labels to the test examples.", "labels": [], "entities": []}, {"text": "Due to lack of time, the TALP system presented at the competition time did not include a complete model selection for the constraint classification binarization setting.", "labels": [], "entities": []}, {"text": "More precisely, 14 words were processed within the complete model selection framework, and 43 were adjusted with a fixed onevs-all approach but a complete feature selection.", "labels": [], "entities": []}, {"text": "After the competition was closed, we implemented the constraint classification setting more efficiently and we reprocessed again the data.", "labels": [], "entities": []}, {"text": "Section 5 shows the results of both variants.", "labels": [], "entities": []}, {"text": "A rough estimation of the complete model selection time for both approaches is the following.", "labels": [], "entities": []}, {"text": "The training spent about 12 hours (OVA setting) and 5 days (CC setting) to complete 6 , suggesting that the main drawback of these approaches is the computational overhead.", "labels": [], "entities": []}, {"text": "Fortunately, the process time can be easily reduced: the CC layer could be ported from Perl to C++ and the model selection could be easily parallelized (since the treatment of each word is independent).", "labels": [], "entities": []}, {"text": "shows the accuracy obtained on the training set and table 3 the results of our system (SE3, TALP), together with the most frequent sense baseline (mfs), the recall result of the best system in the task (best), and the recall median between all participant systems (avg).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9994714856147766}, {"text": "TALP", "start_pos": 92, "end_pos": 96, "type": "METRIC", "confidence": 0.9797998070716858}, {"text": "sense baseline (mfs)", "start_pos": 131, "end_pos": 151, "type": "METRIC", "confidence": 0.7549624741077423}, {"text": "recall", "start_pos": 157, "end_pos": 163, "type": "METRIC", "confidence": 0.9977582693099976}, {"text": "recall median", "start_pos": 218, "end_pos": 231, "type": "METRIC", "confidence": 0.9843979775905609}]}, {"text": "These last three figures were provided provided by the organizers of the task.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Overall results of all system variants on the  training set", "labels": [], "entities": []}, {"text": " Table 3: Overall results on the Senseval-3 test set", "labels": [], "entities": [{"text": "Senseval-3 test", "start_pos": 33, "end_pos": 48, "type": "DATASET", "confidence": 0.7403604388237}]}]}