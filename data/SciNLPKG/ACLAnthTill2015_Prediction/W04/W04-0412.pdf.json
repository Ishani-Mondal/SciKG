{"title": [{"text": "Non-Contiguous Word Sequences for Information Retrieval", "labels": [], "entities": [{"text": "Non-Contiguous Word Sequences", "start_pos": 0, "end_pos": 29, "type": "TASK", "confidence": 0.5813495715459188}, {"text": "Information Retrieval", "start_pos": 34, "end_pos": 55, "type": "TASK", "confidence": 0.7147492319345474}]}], "abstractContent": [{"text": "The growing amount of textual information available electronically has increased the need for high performance retrieval.", "labels": [], "entities": []}, {"text": "The use of phrases was long seen as a natural way to improve retrieval performance over the common document models that ignore the sequential aspect of word occurrences in documents, considering them as \"bags of words\".", "labels": [], "entities": []}, {"text": "However, both statistical and syntactical phrases showed disappointing results for large document collections.", "labels": [], "entities": []}, {"text": "In this paper we present a recent type of multi-word expressions in the form of Maximal Frequent Sequences (Ahonen-Myka, 1999).", "labels": [], "entities": [{"text": "Maximal Frequent Sequences (Ahonen-Myka, 1999)", "start_pos": 80, "end_pos": 126, "type": "TASK", "confidence": 0.587227676063776}]}, {"text": "Mined phrases rather than statistical or syntac-tical phrases, their main strengths are to form a very compact index and to account for the sequentiality and adjacency of meaningful word co-occurrences, by allowing fora gap between words.", "labels": [], "entities": []}, {"text": "We introduce a method for using these phrases in information retrieval and present our experiments.", "labels": [], "entities": [{"text": "information retrieval", "start_pos": 49, "end_pos": 70, "type": "TASK", "confidence": 0.8229335248470306}]}, {"text": "They show a clear improvement over the well-known technique of extracting frequent word pairs.", "labels": [], "entities": [{"text": "extracting frequent word pairs", "start_pos": 63, "end_pos": 93, "type": "TASK", "confidence": 0.8474685847759247}]}], "introductionContent": [{"text": "The constantly growing number of electronic documents increases the need for high performance retrieval, the precision of a system being the percentage of relevant documents among the total number of hits returned to a query.", "labels": [], "entities": [{"text": "precision", "start_pos": 109, "end_pos": 118, "type": "METRIC", "confidence": 0.9991673231124878}]}, {"text": "Most information retrieval systems do not account for word order in a document.", "labels": [], "entities": [{"text": "information retrieval", "start_pos": 5, "end_pos": 26, "type": "TASK", "confidence": 0.7167126536369324}]}, {"text": "However, we can assume that there must exist away to account for word order, which permits to improve retrieval performance.", "labels": [], "entities": []}, {"text": "mention many problems due the use of single word terms only.", "labels": [], "entities": []}, {"text": "They observe that some word associations have a totally different meaning of the \"sum\" of the meanings of the words that compose them (e.g., \"hot dog\" is usually not used to refer to a warm dog !).", "labels": [], "entities": []}, {"text": "Other lexical units pose similar problems (e.g., \"kick the bucket\").", "labels": [], "entities": []}, {"text": "Work on the use of phrases in IR has been carried out for more than 25 years.", "labels": [], "entities": [{"text": "IR", "start_pos": 30, "end_pos": 32, "type": "TASK", "confidence": 0.8846776485443115}]}, {"text": "Early results were very promising.", "labels": [], "entities": []}, {"text": "However, unexpectedly, the constant growth of test collections caused a drastic fall in the quality of the results.", "labels": [], "entities": []}, {"text": "In 1975, show an improvement in average precision over 10 recall points between reiterated the exact same experiments with a 10 Mb collection and obtained improvements from 11% to 20%.", "labels": [], "entities": [{"text": "precision", "start_pos": 40, "end_pos": 49, "type": "METRIC", "confidence": 0.922741711139679}, {"text": "recall", "start_pos": 58, "end_pos": 64, "type": "METRIC", "confidence": 0.9976242184638977}]}, {"text": "This negative impact of the collection size was lately confirmed by over a 655 Mb collection, improving the average precison by only one percent ! Turpin and Moffat (1999) revisited and extended this work to obtain improvements between 4% and 6%.", "labels": [], "entities": [{"text": "precison", "start_pos": 116, "end_pos": 124, "type": "METRIC", "confidence": 0.7834159731864929}]}, {"text": "A conclusion of this related work is that phrases improve results in low levels of recall, but are globally inefficient for then first ranked documents.", "labels": [], "entities": [{"text": "recall", "start_pos": 83, "end_pos": 89, "type": "METRIC", "confidence": 0.9981786012649536}]}, {"text": "According to, this low benefit from phrases to the best answers is explained by the fact that phrases promote documents that deal with only one aspect of possibly multi-faceted queries.", "labels": [], "entities": []}, {"text": "For example, a topic of TREC-4 is about \"problems associated with pension plans, such as fraud, skimming, tapping or raiding\".", "labels": [], "entities": [{"text": "skimming, tapping or raiding", "start_pos": 96, "end_pos": 124, "type": "TASK", "confidence": 0.7257689893245697}]}, {"text": "Several top-ranked documents discuss pension plans, but no related problem.", "labels": [], "entities": []}, {"text": "term this problem as one of inadequate query coverage.", "labels": [], "entities": []}, {"text": "In our opinion, this does not contradict the idea that adding document descriptors accounting for word order must permit to improve the performance of IR systems.", "labels": [], "entities": [{"text": "IR", "start_pos": 151, "end_pos": 153, "type": "TASK", "confidence": 0.9748636484146118}]}, {"text": "But related work shows the need for another way to combine phrase and word term descriptors and even more the fact that the phrases currently used to model documents are not well suited for that.", "labels": [], "entities": []}, {"text": "In the next section, we will briefly describe the vector space model (sometimes quoted as \"bag of words\", for it simply ignores words' positions).", "labels": [], "entities": []}, {"text": "We will then describe the different types of phrases used in related work (section 3).", "labels": [], "entities": []}, {"text": "In section 4, we define our own phrases (maximal frequent sequences) and explain how they will be better document descriptors than those found in the state of the art.", "labels": [], "entities": []}, {"text": "In section 5, we present a technique to incorporate maximal frequent sequences into document indexing and query processing, so as to properly take advantage of this extra information in an information retrieval framework.", "labels": [], "entities": [{"text": "document indexing", "start_pos": 84, "end_pos": 101, "type": "TASK", "confidence": 0.6412075161933899}]}, {"text": "In section 6, we present our experiments and results, before we conclude the paper in section 7.", "labels": [], "entities": []}], "datasetContent": [{"text": "We based our experiments on the 494Mb INEX document collection (Initiative for the Evaluation of XML retrieval 1 ).", "labels": [], "entities": [{"text": "INEX document collection", "start_pos": 38, "end_pos": 62, "type": "DATASET", "confidence": 0.7887778977553049}]}, {"text": "INEX was created in 2002 to compensate the lack of an evaluation forum for the XML information retrieval.", "labels": [], "entities": [{"text": "INEX", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.7822856903076172}, {"text": "XML information retrieval", "start_pos": 79, "end_pos": 104, "type": "TASK", "confidence": 0.5938519438107809}]}, {"text": "This collection consists of 12,107 scientific articles written in English from IEEE journals, combined to a set of queries and corresponding manual assessments.", "labels": [], "entities": []}, {"text": "However, in the present experiments, we ignore this structure and only exploit plain text to return full articles as our candidate retrieval answers.", "labels": [], "entities": []}, {"text": "The manual assessments indeed tell us which candidate answers are relevant and which ones are not.", "labels": [], "entities": []}, {"text": "We use these relevance values to compute precision and recall measures, which permit scoring each set of candidate answers, and equivalently the means by which each set was obtained.", "labels": [], "entities": [{"text": "precision", "start_pos": 41, "end_pos": 50, "type": "METRIC", "confidence": 0.9991770386695862}, {"text": "recall", "start_pos": 55, "end_pos": 61, "type": "METRIC", "confidence": 0.9984744191169739}]}, {"text": "In our experiments, we used average precision over then first hits as our main reference.", "labels": [], "entities": [{"text": "precision", "start_pos": 36, "end_pos": 45, "type": "METRIC", "confidence": 0.5067928433418274}]}, {"text": "This evaluation measure was first introduced by and was used as the official evaluation measure in the INEX 2002 campaign.", "labels": [], "entities": [{"text": "INEX 2002 campaign", "start_pos": 103, "end_pos": 121, "type": "DATASET", "confidence": 0.8180468082427979}]}, {"text": "As a baseline, we computed and evaluated a run using only single word terms, as detailed in section 2.", "labels": [], "entities": []}, {"text": "Our goal was to compare our new technique to the state of the art.", "labels": [], "entities": []}, {"text": "Thus we computed one run using our technique (aggregating the MFS RSVs and the single word term RSVs topic-wise, with the weighting scheme mentioned hereabove), and one run by calculating all statistical phrases following the definition of.", "labels": [], "entities": [{"text": "MFS RSVs", "start_pos": 62, "end_pos": 70, "type": "DATASET", "confidence": 0.9189172983169556}]}, {"text": "The only difference is that we did not set a minimal document frequency threshold.", "labels": [], "entities": []}, {"text": "We made this choice from the standpoint that our aim was not to measure efficiency, but the quality of the results.", "labels": [], "entities": []}, {"text": "The corresponding number of features is given in table 2.", "labels": [], "entities": []}, {"text": "We extracted 328,289 MFS of different sizes.", "labels": [], "entities": []}, {"text": "Their splitting forms no more than 674,257 pairs (this number is probably lower because the same pair can be extracted from numerous MFS).", "labels": [], "entities": []}, {"text": "For those representations, the average precision for then first retrieved documents are presented in table 3.", "labels": [], "entities": [{"text": "precision", "start_pos": 39, "end_pos": 48, "type": "METRIC", "confidence": 0.9984342455863953}]}, {"text": "We learn two things from those results.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Quantity of relevance stemming from various indexing phrases w.r.t. a keyphrase query  ABCD", "labels": [], "entities": [{"text": "Quantity of relevance stemming", "start_pos": 10, "end_pos": 40, "type": "TASK", "confidence": 0.8268750309944153}]}, {"text": " Table 2: Number of feature terms", "labels": [], "entities": [{"text": "Number", "start_pos": 10, "end_pos": 16, "type": "METRIC", "confidence": 0.9468671679496765}]}, {"text": " Table 4: Average Precision@100 for various lin- ear combinations", "labels": [], "entities": [{"text": "Average", "start_pos": 10, "end_pos": 17, "type": "METRIC", "confidence": 0.9484313726425171}, {"text": "Precision", "start_pos": 18, "end_pos": 27, "type": "METRIC", "confidence": 0.8383192420005798}]}]}