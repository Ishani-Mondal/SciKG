{"title": [{"text": "Event Clustering on Streaming News Using Co-Reference Chains and Event Words", "labels": [], "entities": []}], "abstractContent": [{"text": "Event clustering on streaming news aims to group documents by events automatically.", "labels": [], "entities": [{"text": "Event clustering", "start_pos": 0, "end_pos": 16, "type": "TASK", "confidence": 0.7028302401304245}]}, {"text": "This paper employs co-reference chains to extract the most representative sentences, and then uses them to select the most informative features for clustering.", "labels": [], "entities": []}, {"text": "Due to the long span of events, a fixed threshold approach prohibits the latter documents to be clustered and thus decreases the performance.", "labels": [], "entities": []}, {"text": "A dynamic threshold using time decay function and spanning window is proposed.", "labels": [], "entities": []}, {"text": "Besides the noun phrases in co-reference chains, event words in each sentence are also introduced to improve the related performance.", "labels": [], "entities": []}, {"text": "The experimental results show that both event words and co-reference chains are useful on event clustering.", "labels": [], "entities": [{"text": "event clustering", "start_pos": 90, "end_pos": 106, "type": "TASK", "confidence": 0.7895877659320831}]}], "introductionContent": [{"text": "News, which is an important information source, is reported anytime and anywhere, and is disseminated across geographic barriers through Internet.", "labels": [], "entities": []}, {"text": "Detecting the occurrences of new events and tracking the processes of the events) are useful for decision-making in this fast-changing network era.", "labels": [], "entities": [{"text": "Detecting the occurrences of new events", "start_pos": 0, "end_pos": 39, "type": "TASK", "confidence": 0.8880149722099304}]}, {"text": "Event clustering automatically groups documents by events that are specified in the documents in a temporal order.", "labels": [], "entities": [{"text": "Event clustering", "start_pos": 0, "end_pos": 16, "type": "TASK", "confidence": 0.7528338432312012}]}, {"text": "The research issues behind event clustering include: how many features can be used to determine event clusters, which cue patterns can be employed to relate news stories in the same event, how the clustering strategies affect the clustering performance using retrospective data or on-line data, how the time factor affects clustering performance, and how multilingual data is clustered.", "labels": [], "entities": [{"text": "event clustering", "start_pos": 27, "end_pos": 43, "type": "TASK", "confidence": 0.7129049599170685}]}, {"text": "Chen and considered named entities, other nouns and verbs as cue patterns to relate news stories describing the same event.", "labels": [], "entities": []}, {"text": "A centroid-based approach with a two-threshold scheme determines relevance (irrelevance) between a news story and a topic cluster.", "labels": [], "entities": []}, {"text": "A leastrecently-used removal strategy models the time factor in such away that older and unimportant terms will have no effect on clustering.", "labels": [], "entities": []}, {"text": "Chen, touched on event clustering in multilingual multi-document summarization.", "labels": [], "entities": [{"text": "event clustering", "start_pos": 17, "end_pos": 33, "type": "TASK", "confidence": 0.7482327222824097}]}, {"text": "They showed that translation after clustering is better than translation before clustering, and translation deferred to sentence clustering, which reduces the propagation of translation errors, is most promising.", "labels": [], "entities": [{"text": "sentence clustering", "start_pos": 120, "end_pos": 139, "type": "TASK", "confidence": 0.6907998472452164}]}, {"text": "proposed concepts of topic words and event words for event tracking.", "labels": [], "entities": [{"text": "event tracking", "start_pos": 53, "end_pos": 67, "type": "TASK", "confidence": 0.774823009967804}]}, {"text": "They introduced more semantic approach for feature selection than the approach of parts of speech.", "labels": [], "entities": [{"text": "feature selection", "start_pos": 43, "end_pos": 60, "type": "TASK", "confidence": 0.6989161968231201}]}, {"text": "Wong, employed these concepts to select informative words for headline generation, and to rank the extracted sentences in multi-document summarization.", "labels": [], "entities": [{"text": "headline generation", "start_pos": 62, "end_pos": 81, "type": "TASK", "confidence": 0.9149689376354218}]}, {"text": "proposed entitybased cross-document co-referencing which uses co-reference chains of each document to generate its summary and then use the summary rather than the whole article to select informative words to be the features of the document.", "labels": [], "entities": []}, {"text": "proposed a primitive model for text summarization using co-reference chains as well.", "labels": [], "entities": [{"text": "text summarization", "start_pos": 31, "end_pos": 49, "type": "TASK", "confidence": 0.7957013547420502}]}, {"text": "proposed a text summarization model using lexical chains and showed that proper nouns and anaphora resolution is indispensable.", "labels": [], "entities": [{"text": "text summarization", "start_pos": 11, "end_pos": 29, "type": "TASK", "confidence": 0.6793741434812546}, {"text": "proper nouns and anaphora resolution", "start_pos": 73, "end_pos": 109, "type": "TASK", "confidence": 0.7373907446861268}]}, {"text": "The two semantics-based feature selection approaches, i.e., co-reference chains and event words, are complementary in some sense.", "labels": [], "entities": []}, {"text": "The former denotes equivalence classes of noun phrases, and the latter considers both nominal and verbal features, which appear across paragraphs.", "labels": [], "entities": []}, {"text": "This paper will employ both co-reference chains and event words for temporal event clustering.", "labels": [], "entities": [{"text": "temporal event clustering", "start_pos": 68, "end_pos": 93, "type": "TASK", "confidence": 0.7098264296849569}]}, {"text": "An event clustering system using co-reference chains is described in Section 2.", "labels": [], "entities": [{"text": "event clustering", "start_pos": 3, "end_pos": 19, "type": "TASK", "confidence": 0.7492072582244873}]}, {"text": "The evaluation method and the related experimental results are described in Section 3.", "labels": [], "entities": []}, {"text": "The event words are introduced and discussed in Section 4.", "labels": [], "entities": []}, {"text": "Section 5 proposes a summation model and a two-level model, respectively for event clustering using both coreference chains and event words.", "labels": [], "entities": [{"text": "summation", "start_pos": 21, "end_pos": 30, "type": "TASK", "confidence": 0.9577009677886963}, {"text": "event clustering", "start_pos": 77, "end_pos": 93, "type": "TASK", "confidence": 0.7720098793506622}]}, {"text": "Section 6 concludes the remarks.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table  2. The best result is 0.012990 when the threshold  is set to 0.05.", "labels": [], "entities": []}, {"text": " Table 2: Detection Costs Using Centroid Approach", "labels": [], "entities": [{"text": "Detection Costs", "start_pos": 10, "end_pos": 25, "type": "TASK", "confidence": 0.9790893197059631}]}, {"text": " Table 3. Detection Costs Using Co-Reference  Chains", "labels": [], "entities": [{"text": "Detection Costs", "start_pos": 10, "end_pos": 25, "type": "TASK", "confidence": 0.9677958786487579}]}, {"text": " Table 4. Detection Costs with Various Dynamic  Threshold Functions (Initial Threshold = 0.05)", "labels": [], "entities": [{"text": "Detection Costs", "start_pos": 10, "end_pos": 25, "type": "TASK", "confidence": 0.9276835024356842}, {"text": "Initial Threshold", "start_pos": 69, "end_pos": 86, "type": "METRIC", "confidence": 0.906314492225647}]}, {"text": " Table 5. Detection Costs with Various Window  Sizes Using Formula (3) (Initial Threshold = 0.05)", "labels": [], "entities": [{"text": "Detection Costs", "start_pos": 10, "end_pos": 25, "type": "TASK", "confidence": 0.950061559677124}, {"text": "Initial", "start_pos": 72, "end_pos": 79, "type": "METRIC", "confidence": 0.990391731262207}, {"text": "Threshold", "start_pos": 80, "end_pos": 89, "type": "METRIC", "confidence": 0.5138804316520691}]}, {"text": " Table 6. Detection Costs with Event Words and  Various Window Sizes", "labels": [], "entities": [{"text": "Detection Costs", "start_pos": 10, "end_pos": 25, "type": "TASK", "confidence": 0.9571208357810974}]}, {"text": " Table 7. Detection Costs Using Summation Model", "labels": [], "entities": [{"text": "Detection Costs", "start_pos": 10, "end_pos": 25, "type": "TASK", "confidence": 0.9662423133850098}]}, {"text": " Table 8. Detection Costs Using Two level Models", "labels": [], "entities": [{"text": "Detection Costs", "start_pos": 10, "end_pos": 25, "type": "TASK", "confidence": 0.9878809154033661}]}]}