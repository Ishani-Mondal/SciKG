{"title": [{"text": "Word Sense Disambiguation by Web Mining for Word Co-occurrence Probabilities", "labels": [], "entities": [{"text": "Word Sense Disambiguation", "start_pos": 0, "end_pos": 25, "type": "TASK", "confidence": 0.6938401460647583}]}], "abstractContent": [{"text": "This paper describes the National Research Council (NRC) Word Sense Disambiguation (WSD) system , as applied to the English Lexical Sample (ELS) task in Senseval-3.", "labels": [], "entities": [{"text": "National Research Council (NRC) Word Sense Disambiguation (WSD)", "start_pos": 25, "end_pos": 88, "type": "TASK", "confidence": 0.8121858239173889}, {"text": "English Lexical Sample (ELS) task", "start_pos": 116, "end_pos": 149, "type": "TASK", "confidence": 0.6762877915586744}]}, {"text": "The NRC system approaches WSD as a classical supervised machine learning problem, using familiar tools such as the Weka machine learning software and Brill's rule-based part-of-speech tagger.", "labels": [], "entities": [{"text": "NRC", "start_pos": 4, "end_pos": 7, "type": "DATASET", "confidence": 0.8509080410003662}, {"text": "WSD", "start_pos": 26, "end_pos": 29, "type": "TASK", "confidence": 0.961628794670105}]}, {"text": "Head words are represented as feature vectors with several hundred features.", "labels": [], "entities": []}, {"text": "Approximately half of the features are syntactic and the other half are semantic.", "labels": [], "entities": []}, {"text": "The main novelty in the system is the method for generating the semantic features, based on word co-occurrence probabilities.", "labels": [], "entities": []}, {"text": "The probabilities are estimated using the Waterloo MultiText System with a corpus of about one ter-abyte of unlabeled text, collected by a web crawler.", "labels": [], "entities": [{"text": "Waterloo MultiText System", "start_pos": 42, "end_pos": 67, "type": "DATASET", "confidence": 0.9289769132932028}]}], "introductionContent": [{"text": "The Senseval-3 English Lexical Sample (ELS) task requires disambiguating 57 words, with an average of roughly 140 training examples and 70 testing examples of each word.", "labels": [], "entities": [{"text": "Senseval-3 English Lexical Sample (ELS) task", "start_pos": 4, "end_pos": 48, "type": "TASK", "confidence": 0.7368095703423023}]}, {"text": "Each example is about a paragraph of text, in which the word that is to be disambiguated is marked as the headword.", "labels": [], "entities": []}, {"text": "The average headword has around six senses.", "labels": [], "entities": []}, {"text": "The training examples are manually classified according to the intended sense of the headword, inferred from the surrounding context.", "labels": [], "entities": []}, {"text": "The task is to use the training data and any other relevant information to automatically assign classes to the testing examples.", "labels": [], "entities": []}, {"text": "This paper presents the National Research Council (NRC) Word Sense Disambiguation (WSD) system, which generated our four entries for the Senseval-3 ELS task (NRC-Fine, NRC-Fine2, NRC-Coarse, and NRC-Coarse2).", "labels": [], "entities": [{"text": "National Research Council (NRC) Word Sense Disambiguation (WSD)", "start_pos": 24, "end_pos": 87, "type": "TASK", "confidence": 0.7074170807997385}, {"text": "NRC-Coarse2", "start_pos": 195, "end_pos": 206, "type": "DATASET", "confidence": 0.942979097366333}]}, {"text": "Our approach to the ELS task is to treat it as a classical supervised machine learning problem.", "labels": [], "entities": [{"text": "ELS task", "start_pos": 20, "end_pos": 28, "type": "TASK", "confidence": 0.9346507787704468}]}, {"text": "Each example is represented as a feature vector with several hundred features.", "labels": [], "entities": []}, {"text": "Each of the 57 ambiguous words is represented with a different set of features.", "labels": [], "entities": []}, {"text": "Typically, around half of the features are syntactic and the other half are semantic.", "labels": [], "entities": []}, {"text": "After the raw examples are converted to feature vectors, the Weka machine learning software is used to induce a model of the training data and predict the classes of the testing examples).", "labels": [], "entities": [{"text": "Weka", "start_pos": 61, "end_pos": 65, "type": "DATASET", "confidence": 0.9080826640129089}]}, {"text": "The syntactic features are based on part-ofspeech tags, assigned by a rule-based tagger.", "labels": [], "entities": []}, {"text": "The main innovation of the NRC WSD system is the method for generating the semantic features, which are derived from word co-occurrence probabilities.", "labels": [], "entities": [{"text": "NRC WSD system", "start_pos": 27, "end_pos": 41, "type": "DATASET", "confidence": 0.740641713142395}]}, {"text": "We estimated these probabilities using the Waterloo MultiText System with a corpus of about one terabyte of unlabeled text, collected by a web crawler (.", "labels": [], "entities": [{"text": "Waterloo MultiText System", "start_pos": 43, "end_pos": 68, "type": "DATASET", "confidence": 0.9288611809412638}]}, {"text": "In Section 2, we describe the NRC WSD system.", "labels": [], "entities": [{"text": "NRC WSD system", "start_pos": 30, "end_pos": 44, "type": "DATASET", "confidence": 0.8315678040186564}]}, {"text": "Our experimental results are presented in Section 3 and we conclude in Section 4.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 2: Comparison of NRC-Fine with other Senseval-3 ELS systems.", "labels": [], "entities": [{"text": "NRC-Fine", "start_pos": 24, "end_pos": 32, "type": "DATASET", "confidence": 0.9214049577713013}]}]}