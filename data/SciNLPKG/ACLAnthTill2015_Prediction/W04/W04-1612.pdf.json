{"title": [{"text": "Automatic diacritization of Arabic for Acoustic Modeling in Speech Recognition", "labels": [], "entities": [{"text": "Acoustic Modeling in Speech Recognition", "start_pos": 39, "end_pos": 78, "type": "TASK", "confidence": 0.6788396894931793}]}], "abstractContent": [{"text": "Automatic recognition of Arabic dialectal speech is a challenging task because Arabic dialects are essentially spoken varieties.", "labels": [], "entities": [{"text": "Automatic recognition of Arabic dialectal speech", "start_pos": 0, "end_pos": 48, "type": "TASK", "confidence": 0.7769426753123602}]}, {"text": "Only few dialectal resources are available to date; moreover, most available acoustic data collections are transcribed without diacritics.", "labels": [], "entities": []}, {"text": "Such a transcription omits essential pronunciation information about a word, such as short vowels.", "labels": [], "entities": []}, {"text": "In this paper we investigate various procedures that enable us to use such training data by automatically inserting the missing dia-critics into the transcription.", "labels": [], "entities": []}, {"text": "These procedures use acoustic information in combination with different levels of morphological and contextual constraints.", "labels": [], "entities": []}, {"text": "We evaluate their performance against manually dia-critized transcriptions.", "labels": [], "entities": []}, {"text": "In addition, we demonstrate the effect of their accuracy on the recognition performance of acoustic models trained on automatically diacritized training data.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 48, "end_pos": 56, "type": "METRIC", "confidence": 0.9977760910987854}]}], "introductionContent": [{"text": "Large-vocabulary automatic speech recognition (ASR) for conversational Arabic poses several challenges for the speech research community.", "labels": [], "entities": [{"text": "Large-vocabulary automatic speech recognition (ASR)", "start_pos": 0, "end_pos": 51, "type": "TASK", "confidence": 0.7143364420958928}]}, {"text": "The most difficult problems in developing highly accurate speech recognition systems for Arabic are the predominance of non-diacritized text material, the enormous dialectal variety, and the morphological complexity.", "labels": [], "entities": []}, {"text": "Most available acoustic training material for Arabic ASR is transcribed in the Arabic script form, which does not include short vowels and other diacritics that reflect differences in pronunciation, such as the shadda, tanween, etc.", "labels": [], "entities": [{"text": "ASR", "start_pos": 53, "end_pos": 56, "type": "TASK", "confidence": 0.7391331195831299}]}, {"text": "In particular, almost all additional text data that can easily be obtained (e.g. broadcast news corpora) is represented in standard script form.", "labels": [], "entities": []}, {"text": "To our knowledge, the only available corpus that does include detailed phonetic information is the CallHome (CH) Egyptian Colloquial Arabic (ECA) corpus distributed by the Linguistic Data Consortium (LDC).", "labels": [], "entities": [{"text": "CallHome (CH) Egyptian Colloquial Arabic (ECA) corpus distributed", "start_pos": 99, "end_pos": 164, "type": "DATASET", "confidence": 0.905715694030126}]}, {"text": "This corpus has been transcribed in both the script form and a so-called romanized form, which is an ASCII representation that includes short vowels and other diacritic information and thus has complete pronunciation information.", "labels": [], "entities": []}, {"text": "It is quite challenging to create such a transcription: native speakers of Arabic are not used to writing their language in a \"romanized\" form, or even in fully diacritized script form.", "labels": [], "entities": []}, {"text": "Consequently, this task is considered almost as difficult as phonetic transcription.", "labels": [], "entities": [{"text": "phonetic transcription", "start_pos": 61, "end_pos": 83, "type": "TASK", "confidence": 0.7673417627811432}]}, {"text": "Transcribing a sufficiently large amount of training data in this way is therefore labor-intensive and costly since it involves (re)-training native speakers for this purpose.", "labels": [], "entities": []}, {"text": "The constraint of having mostly nondiacritized texts as recognizer training material leads to problems for both acoustic and language modeling.", "labels": [], "entities": [{"text": "language modeling", "start_pos": 125, "end_pos": 142, "type": "TASK", "confidence": 0.7211705893278122}]}, {"text": "First, it is difficult to train accurate acoustic models for short vowels if their identity and location in the signal is not known.", "labels": [], "entities": []}, {"text": "Second, the absence of diacritics leads to a larger set of linguistic contexts fora given word form; language models trained on nondiacritized material may therefore be less predictive than those trained on diacritized texts.", "labels": [], "entities": []}, {"text": "Both of these factors may lead to a loss in recognition accuracy.", "labels": [], "entities": [{"text": "recognition", "start_pos": 44, "end_pos": 55, "type": "TASK", "confidence": 0.9302589297294617}, {"text": "accuracy", "start_pos": 56, "end_pos": 64, "type": "METRIC", "confidence": 0.9388349652290344}]}, {"text": "Previous work ( has shown that ignoring available vowel information does indeed lead to a significant increase in both language model perplexity and word error rate.", "labels": [], "entities": [{"text": "word error rate", "start_pos": 149, "end_pos": 164, "type": "METRIC", "confidence": 0.6370007594426473}]}, {"text": "Therefore, we are interested in automatically deriving a diacritized transcription from the Arabic script representation when a manual diacritization is not available.", "labels": [], "entities": []}, {"text": "Some software companies (Sakhr, Apptek, RDI) have developed commercial products for the automatic diacritization of Arabic.", "labels": [], "entities": [{"text": "automatic diacritization of Arabic", "start_pos": 88, "end_pos": 122, "type": "TASK", "confidence": 0.76862832903862}]}, {"text": "However, these products use only textbased information, such as the syntactic context and possible morphological analyses of words, to predict diacritics.", "labels": [], "entities": []}, {"text": "In the context of diacritization for speech recognition, by contrast, acoustic data is available that can be used as an additional knowledge source.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 37, "end_pos": 55, "type": "TASK", "confidence": 0.8298478722572327}]}, {"text": "Moreover, commercial products concentrate exclusively on Modern Standard Arabic (MSA), whereas a common objective of Arabic ASR is conversational speech recognition, which is usually dialectal.", "labels": [], "entities": [{"text": "conversational speech recognition", "start_pos": 131, "end_pos": 164, "type": "TASK", "confidence": 0.7022335926691691}]}, {"text": "For this reason, a more flexible set of tools is required in order to diacritize dialectal Arabic prior to speech recognizer training.", "labels": [], "entities": [{"text": "speech recognizer", "start_pos": 107, "end_pos": 124, "type": "TASK", "confidence": 0.7333589792251587}]}, {"text": "In this work we investigate the relative benefits of a variety of knowledge sources (acoustic, morphological, and contextual) to automatically diacritize MSA transcriptions.", "labels": [], "entities": [{"text": "MSA transcriptions", "start_pos": 154, "end_pos": 172, "type": "TASK", "confidence": 0.8147172629833221}]}, {"text": "We evaluate the different approaches in two different ways: (a) by comparing the automatic output against a manual reference diacritization and computing the diacritization error rate, and (b) by using automatically diacritized training data in a cross-dialectal speech recognition application.", "labels": [], "entities": [{"text": "cross-dialectal speech recognition", "start_pos": 247, "end_pos": 281, "type": "TASK", "confidence": 0.6515484054883321}]}, {"text": "The remainder of this paper is structured as follows: Section 2 gives a detailed description of the motivation as well as prior work.", "labels": [], "entities": []}, {"text": "Section 3 describes the corpora used for the experiments reported in this paper.", "labels": [], "entities": []}, {"text": "The automatic diacritization procedures and results are explained in Section 4.", "labels": [], "entities": []}, {"text": "The speech recognition experiments and results are reported in Section 5.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 4, "end_pos": 22, "type": "TASK", "confidence": 0.8246245384216309}, {"text": "Section 5", "start_pos": 63, "end_pos": 72, "type": "DATASET", "confidence": 0.8761372566223145}]}, {"text": "Section 6 presents our conclusions.", "labels": [], "entities": []}], "datasetContent": [{"text": "Our overall goal is to use large amounts of MSA acoustic data to enrich training material fora speech recognizer for conversational Egyptian Arabic.", "labels": [], "entities": [{"text": "speech recognizer", "start_pos": 95, "end_pos": 112, "type": "TASK", "confidence": 0.7181580811738968}]}, {"text": "The ECA recognizer was trained on the romanized transcription of the CallHome corpus described above and uses short vowel models.", "labels": [], "entities": [{"text": "ECA recognizer", "start_pos": 4, "end_pos": 18, "type": "TASK", "confidence": 0.6891874969005585}, {"text": "CallHome corpus", "start_pos": 69, "end_pos": 84, "type": "DATASET", "confidence": 0.9667657911777496}]}, {"text": "In order to be able to use the phonetically deficient MSA transcriptions, we first need to convert them to a diacritized form.", "labels": [], "entities": []}, {"text": "In addition to measuring autodiacritization error rates, as above, we would like to evaluate the different diacritization procedures by investigating how acoustic models trained on the different outputs affect ASR performance.", "labels": [], "entities": [{"text": "ASR", "start_pos": 210, "end_pos": 213, "type": "TASK", "confidence": 0.9935224652290344}]}, {"text": "One motivation for using cross-dialectal data is the assumption that infrequent triphones in the CallHome corpus might have more training samples in the larger MSA corpus.", "labels": [], "entities": [{"text": "CallHome corpus", "start_pos": 97, "end_pos": 112, "type": "DATASET", "confidence": 0.9703973531723022}, {"text": "MSA corpus", "start_pos": 160, "end_pos": 170, "type": "DATASET", "confidence": 0.7437228858470917}]}, {"text": "In) we demonstrated that it is possible to get a small improvement in this task by combining the scores of models trained strictly on CallHome (CH) with models trained on the combined FBIS+CH data, where the FBIS data was diacritized using the method described in Section 4.1.", "labels": [], "entities": [{"text": "FBIS+CH data", "start_pos": 184, "end_pos": 196, "type": "DATASET", "confidence": 0.5740213841199875}, {"text": "FBIS data", "start_pos": 208, "end_pos": 217, "type": "DATASET", "confidence": 0.8305828869342804}]}, {"text": "Here we compare that experiment with the experiments where the methods described in Sections 4.2 and 4.3 were used for diacritizing the FBIS corpus.", "labels": [], "entities": [{"text": "FBIS corpus", "start_pos": 136, "end_pos": 147, "type": "DATASET", "confidence": 0.7468225657939911}]}], "tableCaptions": [{"text": " Table 2: Automatic diacritization error rates  (%).", "labels": [], "entities": [{"text": "Automatic diacritization error rates", "start_pos": 10, "end_pos": 46, "type": "METRIC", "confidence": 0.7935023903846741}]}, {"text": " Table 4: Word error rates (%) obtained after the final recognition pass and with ROVER combina- tion with the baseline system. FBIS1, FBIS2 and FBIS3 correspond to the diacritization procedures  described in Sections 4.1, 4.2 and 4.3 respectively. For the first approach we report results using  the tagger probabilities with weights 1 and 5.", "labels": [], "entities": [{"text": "Word error rates", "start_pos": 10, "end_pos": 26, "type": "METRIC", "confidence": 0.80476842323939}, {"text": "ROVER combina- tion", "start_pos": 82, "end_pos": 101, "type": "METRIC", "confidence": 0.951681837439537}]}]}