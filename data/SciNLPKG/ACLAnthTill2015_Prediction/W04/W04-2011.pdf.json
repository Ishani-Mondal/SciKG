{"title": [{"text": "Knowledge Extraction Using Dynamical Updating of Representation", "labels": [], "entities": [{"text": "Knowledge Extraction", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.6822257936000824}]}], "abstractContent": [{"text": "We present a system that extracts knowledge from the textual content of documents.", "labels": [], "entities": []}, {"text": "The acquired knowledge is represented through an associative network, that is dynamically updated by the integration of a contextualized structure representing the content of the new analysed document.", "labels": [], "entities": []}, {"text": "Grounded on the basis of \"long term working memory\" theory by W. Kintsch and K.A. Ericsson, our system makes use of a scale free graph model to update the final knowledge representation.", "labels": [], "entities": []}, {"text": "This knowledge acquisition system has been validated by first experimental results.", "labels": [], "entities": [{"text": "knowledge acquisition", "start_pos": 5, "end_pos": 26, "type": "TASK", "confidence": 0.8509541749954224}]}], "introductionContent": [{"text": "From an historical perspective, four types of knowledge representation schemas are worth to be considered (W. .", "labels": [], "entities": []}, {"text": "\"Feature systems\" (J.J. have been developed in philosophy and linguistics and became very popular especially in psychology.", "labels": [], "entities": []}, {"text": "This representation aimed at finding a limited set of basic semantic characteristics that, combined by means of particular composition rules, could express complex concepts.", "labels": [], "entities": []}, {"text": "It was a very simple representation system but conceptual relations were not considered.", "labels": [], "entities": []}, {"text": "Furthermore the defined features did not change with the context and the goals that had to be achieved.", "labels": [], "entities": []}, {"text": "\"Associative networks\" consider also semantic relations between concepts.", "labels": [], "entities": []}, {"text": "Knowledge is represented by a network of concepts bounded by more or less strong associations.", "labels": [], "entities": []}, {"text": "This formalism is bolstered by a lot of experimental data, for example byword priming experiments ( D.E. Meyer, R.W..", "labels": [], "entities": []}, {"text": "But networks whose links are not labelled are not very expressive.", "labels": [], "entities": []}, {"text": "\"Semantic networks\" ( A.M. Collins, M.R. are an evolution of associative networks.", "labels": [], "entities": []}, {"text": "Concepts continue to be symbolized by nodes, but these are linked by labeled arcs (IS-A, PART-OF etc.).", "labels": [], "entities": [{"text": "PART-OF", "start_pos": 89, "end_pos": 96, "type": "METRIC", "confidence": 0.9015716910362244}]}, {"text": "In this way well ordered concept hierarchies can be defined and the hereditariness of properties is allowed.", "labels": [], "entities": []}, {"text": "\"Schemas\", \"frames\" and \"scripts\" are structures for coordinating concepts that belong to the same event or superstructure.", "labels": [], "entities": []}, {"text": "Classical examples of these formalisms are the \"room frame\" of Minsky (M. and the restaurant script of Schank and Abelson (R.C. Schank, R.P..", "labels": [], "entities": []}, {"text": "The problem with these representation forms is that they are static.", "labels": [], "entities": []}, {"text": "In fact human mind generates contextualized structures, that are adapted to the particular context of use.", "labels": [], "entities": []}, {"text": "\"Networks of propositions\" (or \"knowledge nets\", W. ) are an alternative formalism that combines and extends the advantages of the representation forms that have been introduced so far.", "labels": [], "entities": []}, {"text": "The predicate-argument schema can be considered as the fundamental linguistic unit especially in the representation of textual content.", "labels": [], "entities": []}, {"text": "Atomic propositions consist of a relational term (the predicate) and one or more arguments.", "labels": [], "entities": []}, {"text": "Networks of propositions link these atomic propositions through weighted and not labeled arcs.", "labels": [], "entities": []}, {"text": "According to this formalism the meaning of anode is given by its position in the net.", "labels": [], "entities": []}, {"text": "From a psychologic point of view only the nodes that are active (i.e. that are maintained int he working memory) contribute to specify the sense of anode.", "labels": [], "entities": []}, {"text": "Hence the meaning of a concept is not permanent and fixed but is built every time in the working memory by the activation of a certain subset of propositions in the neighbour of the node that represents the concept.", "labels": [], "entities": []}, {"text": "The context of use (objectives, accumulated experiences, emotional and situational state etc.) determines which nodes have to be activated.", "labels": [], "entities": []}, {"text": "For the definition of retrieval modalities Ericsson and Kintsch has introduced the concept of long term working memory (LTWM) (W.Kintsch, V.L.).", "labels": [], "entities": []}, {"text": "They noticed that some cognitive tasks, as textual comprehension, cannot be explained only using the concept of working memory.", "labels": [], "entities": []}, {"text": "Given the strict limits of capacity of the short term memory (STM) and of the working memory (WM), tasks that require an enormous employment of resources cannot be carried out.", "labels": [], "entities": []}, {"text": "The theory of long term working memory specifies under which conditions the capacity of WM can be extended.", "labels": [], "entities": []}, {"text": "The LTWM is involved only in the execution of well known tasks and actions, that belong to a particular cognitive domain that has been well experienced.", "labels": [], "entities": []}, {"text": "In these cases the working memory can be subdivided in a short term part (STWM) that has a limited capacity and a LTWM that is apart of the long term memory represented by the network of propositions.", "labels": [], "entities": [{"text": "LTWM", "start_pos": 114, "end_pos": 118, "type": "METRIC", "confidence": 0.8988593220710754}]}, {"text": "The content of STWM automatically generates the LTWM.", "labels": [], "entities": [{"text": "LTWM", "start_pos": 48, "end_pos": 52, "type": "DATASET", "confidence": 0.7937322854995728}]}, {"text": "In particular objects present in the STWM are linked to other objects in the LTM by fixed and stable memory structures (retrieval cues).", "labels": [], "entities": []}], "datasetContent": [{"text": "The degree distribution of a graph with directed links is reported below.", "labels": [], "entities": []}, {"text": "In order to evaluate the learning capabilities of the system, we applied it on a medical article.", "labels": [], "entities": []}, {"text": "The sections of the paper have been presented separately as independent texts regarding the same topic.", "labels": [], "entities": []}, {"text": "This choice has been imposed by the necessity to enable also the retrieval of information from LTM.", "labels": [], "entities": []}, {"text": "As expected, the resulting LTM network was atypical scale-free graph (tab.", "labels": [], "entities": []}, {"text": "2  The analysis has been repeated 30 times examining the coherence rate of each resulting LTM representation.", "labels": [], "entities": []}, {"text": "The coherence measure is based on a kind of transitivity assumption, i.e. if two concepts have similar relationships with other concepts, then the two concepts should be similar.", "labels": [], "entities": []}, {"text": "The coherence rate is obtained by correlating the LTM ratings given for each item in a pair with all of the other concepts . Its value can be correctly computed only producing symmetric versions of the LTM data.", "labels": [], "entities": [{"text": "LTM data", "start_pos": 202, "end_pos": 210, "type": "DATASET", "confidence": 0.7683222591876984}]}, {"text": "The average coherence rate was 0.45, indicating that the system has conceptualized the t erms according to a precise inner schema.", "labels": [], "entities": []}, {"text": "To evaluate the correctness of this schema we are going to compare the obtained LTM representations with experimental data obtained from a group of human subjects.", "labels": [], "entities": []}, {"text": "The subjects will be asked to read the same medical article examined by the system, assigning a rate of similarity to each pair of words that has been considered by the system.", "labels": [], "entities": []}, {"text": "A Pathfinder analysis (R.W. Schvaneveldt, F.T.) will be performed on the relatedness matrices provided by human subjects and the LTM matrices in order to extract the so called \"latent semantic\", i.e. other implicit relations between words.", "labels": [], "entities": []}, {"text": "The obtained matrices will be compared using a similarity rate determined by the correspondence of links in the two types of networks.", "labels": [], "entities": [{"text": "similarity rate", "start_pos": 47, "end_pos": 62, "type": "METRIC", "confidence": 0.9752483367919922}]}], "tableCaptions": [{"text": " Table 1: General characteristics of some  semantic networks.", "labels": [], "entities": []}, {"text": " Table 2: LTM with 40 nodes", "labels": [], "entities": []}]}