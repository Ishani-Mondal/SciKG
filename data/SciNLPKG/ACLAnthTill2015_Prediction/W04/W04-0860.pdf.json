{"title": [{"text": "The R2D2 Team at SENSEVAL-3 *", "labels": [], "entities": [{"text": "SENSEVAL-3", "start_pos": 17, "end_pos": 27, "type": "TASK", "confidence": 0.5314531326293945}]}], "abstractContent": [{"text": "The R2D2 systems for the English All-Words and Lexical Sample tasks at SENSEVAL-3 are based on several supervised and unsupervised methods combined by means of a voting procedure.", "labels": [], "entities": [{"text": "English All-Words and Lexical Sample tasks", "start_pos": 25, "end_pos": 67, "type": "TASK", "confidence": 0.5372636715571085}]}, {"text": "Main goal was to take advantage of training data when available , and getting maximum coverage with the help of methods that not need such learning examples.", "labels": [], "entities": [{"text": "coverage", "start_pos": 86, "end_pos": 94, "type": "METRIC", "confidence": 0.9846383929252625}]}, {"text": "The results reported in this paper show that supervised and unsupervised methods working in parallel , and a simple sequence of preferences when comparing the answers of such methods, is a feasible method..", "labels": [], "entities": []}, {"text": "The whole system is, in fact, a cascade of decisions of what label to assign to a concrete instance based on the agreement of pairs of systems, when it is possible, or selecting the available answer from one of them.", "labels": [], "entities": []}, {"text": "In this way, supervised are preferred to unsupervised methods, but these last ones are able to tag such words that not have available training data.", "labels": [], "entities": []}], "introductionContent": [{"text": "Designing a system for Natural Language Processing (NLP) requires a large knowledge on language structure, morphology, syntax, semantics and pragmatic nuances.", "labels": [], "entities": [{"text": "Natural Language Processing (NLP)", "start_pos": 23, "end_pos": 56, "type": "TASK", "confidence": 0.6988809208075205}]}, {"text": "All of these different linguistic knowledge forms, however, have a common associated problem, their many ambiguities, which are difficult to resolve.", "labels": [], "entities": []}, {"text": "In this paper we concentrate on the resolution of the lexical ambiguity that appears when a given word in a context has several different meanings.", "labels": [], "entities": []}, {"text": "* This paper has been partially supported by the Spanish Government (CICyT) under project number TIC-2003-7180 and the Valencia Government (OCyT) under project number This specific task is commonly referred as Word Sense Disambiguation (WSD).", "labels": [], "entities": [{"text": "Valencia Government (OCyT", "start_pos": 119, "end_pos": 144, "type": "DATASET", "confidence": 0.872728243470192}, {"text": "Word Sense Disambiguation (WSD)", "start_pos": 210, "end_pos": 241, "type": "TASK", "confidence": 0.7435342421134313}]}, {"text": "This is a difficult problem that is receiving a great deal of attention from the research community because its resolution can help other NLP applications as Machine Translation (MT), Information Retrieval (IR), Text Processing, Grammatical Analysis, Information Extraction (IE), hypertext navigation and soon.", "labels": [], "entities": [{"text": "Machine Translation (MT)", "start_pos": 158, "end_pos": 182, "type": "TASK", "confidence": 0.8557575106620788}, {"text": "Information Retrieval (IR)", "start_pos": 184, "end_pos": 210, "type": "TASK", "confidence": 0.832135808467865}, {"text": "Text Processing", "start_pos": 212, "end_pos": 227, "type": "TASK", "confidence": 0.8089913129806519}, {"text": "Grammatical Analysis", "start_pos": 229, "end_pos": 249, "type": "TASK", "confidence": 0.8145367503166199}, {"text": "Information Extraction (IE)", "start_pos": 251, "end_pos": 278, "type": "TASK", "confidence": 0.7904146075248718}, {"text": "hypertext navigation", "start_pos": 280, "end_pos": 300, "type": "TASK", "confidence": 0.8345288336277008}]}, {"text": "The R2D2 Team has participated in two tasks: English all-words and lexical sample.", "labels": [], "entities": []}, {"text": "We use several different systems both supervised and unsupervised.", "labels": [], "entities": []}, {"text": "The supervised methods are based on Maximum Entropy (ME) (, neural network using the Learning Vector Quantization algorithm and Specialized Hidden Markov Models).", "labels": [], "entities": [{"text": "Maximum Entropy (ME)", "start_pos": 36, "end_pos": 56, "type": "METRIC", "confidence": 0.7833079099655151}]}, {"text": "The unsupervised methods are Relevant Domains (RD) () and the CIAOSENSO WSD system which is based on Conceptual Density (Agirre and, frequency of WordNet () senses and WordNet Domains).", "labels": [], "entities": [{"text": "CIAOSENSO WSD", "start_pos": 62, "end_pos": 75, "type": "DATASET", "confidence": 0.7145772576332092}, {"text": "Agirre", "start_pos": 121, "end_pos": 127, "type": "METRIC", "confidence": 0.9744857549667358}]}, {"text": "In the following section we will show a more complete description of the systems.", "labels": [], "entities": []}, {"text": "Next, how such methods were combined in two voting systems, and the results obtained in SENSEVAL-3.", "labels": [], "entities": [{"text": "SENSEVAL-3", "start_pos": 88, "end_pos": 98, "type": "DATASET", "confidence": 0.48972412943840027}]}, {"text": "Finally, some conclusions will be presented.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": []}