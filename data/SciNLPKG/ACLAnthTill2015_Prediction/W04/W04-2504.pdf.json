{"title": [{"text": "Discourse Structure for Context Question Answering", "labels": [], "entities": [{"text": "Context Question Answering", "start_pos": 24, "end_pos": 50, "type": "TASK", "confidence": 0.7288520733515421}]}], "abstractContent": [{"text": "Ina real-world setting, questions are not asked in isolation, but rather in a cohesive manner that involves a sequence of related questions to meet user's information needs.", "labels": [], "entities": []}, {"text": "The capability to interpret and answer questions based on context is important.", "labels": [], "entities": [{"text": "interpret and answer questions", "start_pos": 18, "end_pos": 48, "type": "TASK", "confidence": 0.8189877718687057}]}, {"text": "In this paper, we discuss the role of discourse modeling in context question answering.", "labels": [], "entities": [{"text": "context question answering", "start_pos": 60, "end_pos": 86, "type": "TASK", "confidence": 0.6128617624441782}]}, {"text": "In particular, we motivate a semantic-rich discourse representation and discuss the impact of refined discourse structure on question answering.", "labels": [], "entities": [{"text": "question answering", "start_pos": 125, "end_pos": 143, "type": "TASK", "confidence": 0.8419579863548279}]}], "introductionContent": [{"text": "Ina real-world setting, questions are not asked in isolation, but rather in a cohesive manner that involves a sequence of related questions to meet user's information needs.", "labels": [], "entities": []}, {"text": "The capability to interpret and answer questions based on context is important.", "labels": [], "entities": [{"text": "interpret and answer questions", "start_pos": 18, "end_pos": 48, "type": "TASK", "confidence": 0.8189877718687057}]}, {"text": "For example, shows an example of a series of context questions.", "labels": [], "entities": []}, {"text": "In this example, the interpretation of Q2 and Q4 depends on the resolution of \"it\" and \"this\" from the context respectively.", "labels": [], "entities": []}, {"text": "Although neither Q3 nor Q6 requires any anaphora resolution, the interpretation of Q3 depends on Q2 while the interpretation of Q6 depends solely on itself.", "labels": [], "entities": [{"text": "anaphora resolution", "start_pos": 40, "end_pos": 59, "type": "TASK", "confidence": 0.7197236716747284}]}, {"text": "Furthermore, in Q5, there are no explicit references.", "labels": [], "entities": [{"text": "Q5", "start_pos": 16, "end_pos": 18, "type": "DATASET", "confidence": 0.8890836238861084}]}, {"text": "Its interpretation depends on a preceding question (e.g.,Q4), however, in a different manner.", "labels": [], "entities": []}, {"text": "This example indicates that interpreting each of these questions and extracting answers needs to be situated in a particular context as the QA session proceeds.", "labels": [], "entities": [{"text": "interpreting each of these questions", "start_pos": 28, "end_pos": 64, "type": "TASK", "confidence": 0.8218495011329651}]}, {"text": "There are situations where a question is \"complete\" enough and its interpretation does not depend on the previous questions (Q6).", "labels": [], "entities": []}, {"text": "There are also situations where the interpretation of a question depends on preceding questions no matter whether it requires anaphora or ellipsis resolution.", "labels": [], "entities": [{"text": "ellipsis resolution", "start_pos": 138, "end_pos": 157, "type": "TASK", "confidence": 0.7424091398715973}]}, {"text": "Based on these observations, a natural question to ask is what makes the use of discourse differently in different situations?", "labels": [], "entities": []}, {"text": "What is the role of discourse in context question answering?", "labels": [], "entities": [{"text": "context question answering", "start_pos": 33, "end_pos": 59, "type": "TASK", "confidence": 0.6646605432033539}]}, {"text": "To address these questions, a key issue, in our mind, is that every question and its answer have a discourse status with respect to an entire QA session.", "labels": [], "entities": []}, {"text": "This discourse status includes two aspects.", "labels": [], "entities": []}, {"text": "The first aspect relates to discourse roles of entities in a question and the corresponding answer.", "labels": [], "entities": []}, {"text": "Entities (such as noun phrase, verb phrase, preposition phrase, etc) in a question carry distinctive roles that indicate what is the topic or focus of a question in terms of the overall information seeking discourse.", "labels": [], "entities": [{"text": "Entities (such as noun phrase, verb phrase, preposition phrase, etc) in a question carry distinctive roles that indicate what is the topic or focus of a question", "start_pos": 0, "end_pos": 161, "type": "Description", "confidence": 0.8128158515319228}]}, {"text": "Topic relates to the \"aboutness\" of a question and focus relates to a specific perspective of the topic.", "labels": [], "entities": []}, {"text": "The second aspect of discourse status relates to discourse transitions that indicate how discourse roles are changed from one question to another as the interaction proceeds and how such changes reflect the progress of user information needs.", "labels": [], "entities": []}, {"text": "Both discourse roles and discourse transitions determine whether the context is useful, and if so, how to use the context to interpret a question.", "labels": [], "entities": []}, {"text": "This paper takes an initial attempt to investigate the discourse status for context question answering.", "labels": [], "entities": [{"text": "context question answering", "start_pos": 76, "end_pos": 102, "type": "TASK", "confidence": 0.6504555940628052}]}, {"text": "In particular, it motivates a semantic-rich discourse representation that captures both discourse roles of a question and discourse transitions between questions.", "labels": [], "entities": []}, {"text": "Through examples, this paper further discusses the potential impact of this refined discourse structure on context question answering.", "labels": [], "entities": [{"text": "context question answering", "start_pos": 107, "end_pos": 133, "type": "TASK", "confidence": 0.6929147640864054}]}], "datasetContent": [], "tableCaptions": []}