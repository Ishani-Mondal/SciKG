{"title": [{"text": "Unsupervised WSD based on automatically retrieved examples: The importance of bias", "labels": [], "entities": [{"text": "WSD", "start_pos": 13, "end_pos": 16, "type": "TASK", "confidence": 0.8890603184700012}]}], "abstractContent": [{"text": "This paper explores the large-scale acquisition of sense-tagged examples for Word Sense Disam-biguation (WSD).", "labels": [], "entities": [{"text": "Word Sense Disam-biguation (WSD)", "start_pos": 77, "end_pos": 109, "type": "TASK", "confidence": 0.6536573568979899}]}, {"text": "We have applied the \"WordNet monosemous relatives\" method to construct automatically a web corpus that we have used to train disambiguation systems.", "labels": [], "entities": []}, {"text": "The corpus-building process has highlighted important factors, such as the distribution of senses (bias).", "labels": [], "entities": []}, {"text": "The corpus has been used to train WSD algorithms that include supervised methods (combining automatic and manually-tagged examples), minimally supervised (requiring sense bias information from hand-tagged corpora), and fully unsupervised.", "labels": [], "entities": [{"text": "WSD", "start_pos": 34, "end_pos": 37, "type": "TASK", "confidence": 0.9739863276481628}]}, {"text": "These methods were tested on the Senseval-2 lexical sample test set, and compared successfully to other systems with minimum or no supervision.", "labels": [], "entities": [{"text": "Senseval-2 lexical sample test set", "start_pos": 33, "end_pos": 67, "type": "DATASET", "confidence": 0.9329741835594177}]}], "introductionContent": [{"text": "The results of recent WSD exercises, e.g. Senseval-2 1 show clearly that WSD methods based on hand-tagged examples are the ones performing best.", "labels": [], "entities": [{"text": "WSD", "start_pos": 22, "end_pos": 25, "type": "TASK", "confidence": 0.9765498638153076}, {"text": "WSD", "start_pos": 73, "end_pos": 76, "type": "TASK", "confidence": 0.9494946002960205}]}, {"text": "However, the main drawback for supervised WSD is the knowledge acquisition bottleneck: the systems need large amounts of costly hand-tagged data.", "labels": [], "entities": [{"text": "WSD", "start_pos": 42, "end_pos": 45, "type": "TASK", "confidence": 0.9122626185417175}, {"text": "knowledge acquisition", "start_pos": 53, "end_pos": 74, "type": "TASK", "confidence": 0.8438303768634796}]}, {"text": "The situation is more dramatic for lesser studied languages.", "labels": [], "entities": []}, {"text": "In order to overcome this problem, different research lines have been explored: automatic acquisition of training examples), bootstrapping techniques, or active learning.", "labels": [], "entities": []}, {"text": "In this work, we have focused on the automatic acquisition of examples.", "labels": [], "entities": [{"text": "automatic acquisition of examples", "start_pos": 37, "end_pos": 70, "type": "TASK", "confidence": 0.7770292535424232}]}, {"text": "When supervised systems have no specific training examples fora target word, they need to rely on publicly available all-words sense-tagged corpora like Semcor (, which is tagged with WordNet word senses.", "labels": [], "entities": []}, {"text": "The systems performing best in the English all-words task in Senseval-2 were basically supervised systems trained on Semcor.", "labels": [], "entities": []}, {"text": "Unfortunately, for most of the words, this cor-1 http://www.senseval.org.", "labels": [], "entities": []}, {"text": "pus only provides a handful of tagged examples.", "labels": [], "entities": [{"text": "pus", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.9316534996032715}]}, {"text": "In fact, only a few systems could overcome the Most Frequent Sense (MFS) baseline, which would tag each word with the sense occurring most frequently in Semcor.", "labels": [], "entities": []}, {"text": "In our approach, we will also rely on Semcor as the basic resource, both for training examples and as an indicator of the distribution of the senses of the target word.", "labels": [], "entities": []}, {"text": "The goal of our experiment is to evaluate up to which point we can automatically acquire examples for word senses and train accurate supervised WSD systems on them.", "labels": [], "entities": [{"text": "WSD", "start_pos": 144, "end_pos": 147, "type": "TASK", "confidence": 0.9577896595001221}]}, {"text": "This is a very promising line of research, but one which remains relatively understudied (cf. Section 2).", "labels": [], "entities": []}, {"text": "The method we applied is based on the monosemous relatives of the target words (), and we studied some parameters that affect the quality of the acquired corpus, such as the distribution of the number of training instances per each word sense (bias), and the type of features used for disambiguation (local vs. topical).", "labels": [], "entities": []}, {"text": "Basically, we built three systems, one fully supervised (using examples from both Semcor and automatically acquired examples), one minimally supervised (using the distribution of senses in Semcor and automatically acquired examples) and another fully unsupervised (using an automatically acquired sense rank) and automatically acquired examples).", "labels": [], "entities": []}, {"text": "This paper is structured as follows.", "labels": [], "entities": []}, {"text": "First, Section 2 describes previous work on the field.", "labels": [], "entities": []}, {"text": "Section 3 introduces the experimental setting for evaluating the acquired corpus.", "labels": [], "entities": []}, {"text": "Section 4 is devoted to the process of building the corpus, which is evaluated in Section 5.", "labels": [], "entities": []}, {"text": "Finally, the conclusions are given in Section 6.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section we will present the Decision List method, the features used to represent the context, the two hand-tagged corpora used in the experiment and the word-set used for evaluation.", "labels": [], "entities": []}, {"text": "In all experiments, the recall of the systems is presented as evaluation measure.", "labels": [], "entities": [{"text": "recall", "start_pos": 24, "end_pos": 30, "type": "METRIC", "confidence": 0.998791515827179}]}, {"text": "There is total coverage (because of the high overlap of topical features) and the recall and precision are the same . In order to evaluate the acquired corpus, our first task was to analyze the impact of bias.", "labels": [], "entities": [{"text": "recall", "start_pos": 82, "end_pos": 88, "type": "METRIC", "confidence": 0.9996167421340942}, {"text": "precision", "start_pos": 93, "end_pos": 102, "type": "METRIC", "confidence": 0.998770534992218}]}, {"text": "The results are shown in.", "labels": [], "entities": []}, {"text": "There are 2 figures for each distribution: (1) simply assign the first ranked sense, and (2) use the monosemous corpus following the predetermined bias.", "labels": [], "entities": []}, {"text": "As we described in Section 3, the testing part of the Senseval-2 lexical sample data was used for evaluation.", "labels": [], "entities": [{"text": "Senseval-2 lexical sample data", "start_pos": 54, "end_pos": 84, "type": "DATASET", "confidence": 0.9175415933132172}]}, {"text": "We also include the results using Senseval2 bias, which is taken from the training part.", "labels": [], "entities": []}, {"text": "The recall per word for some distributions can be seen in.", "labels": [], "entities": [{"text": "recall", "start_pos": 4, "end_pos": 10, "type": "METRIC", "confidence": 0.9992473125457764}]}, {"text": "The results show clearly that when bias information from a hand-tagged corpora is used the recall improves significantly, even when the bias comes from a corpus -Semcor-different from the target corpus -Senseval-.", "labels": [], "entities": [{"text": "recall", "start_pos": 91, "end_pos": 97, "type": "METRIC", "confidence": 0.9995883107185364}]}, {"text": "The bias is useful by itself, and we see that the higher the performance of the 1st ranked sense heuristic, the lower the gain using the monosemous corpus.", "labels": [], "entities": []}, {"text": "We want to note that in fully unsupervised mode we attain a recall of 43.2% with the automatic ranking.", "labels": [], "entities": [{"text": "recall", "start_pos": 60, "end_pos": 66, "type": "METRIC", "confidence": 0.9995635151863098}]}, {"text": "Using the minimally supervised information of bias, we get 49.8% if we have the bias from an external corpus (Semcor) and: Recall for all the nouns using the monosemous corpus with Senseval-2 training bias (MR, and substitution), Semcor bias, and Automatic bias.", "labels": [], "entities": [{"text": "MR", "start_pos": 207, "end_pos": 209, "type": "METRIC", "confidence": 0.910493016242981}, {"text": "Automatic bias", "start_pos": 247, "end_pos": 261, "type": "METRIC", "confidence": 0.97257861495018}]}, {"text": "The Senseval-2 results are given by feature type.", "labels": [], "entities": []}, {"text": "57.5% if we have access to the bias of the target corpus (Senseval 7 ).", "labels": [], "entities": []}, {"text": "This results show clearly that the acquired corpus has useful information about the word senses, and that bias is extremely important.", "labels": [], "entities": []}, {"text": "We will present two further experiments performed with the monosemous corpus resource.", "labels": [], "entities": []}, {"text": "The goal of the first will be to measure the WSD performance that we achieve using Semcor as the only supervised data source.", "labels": [], "entities": [{"text": "WSD", "start_pos": 45, "end_pos": 48, "type": "TASK", "confidence": 0.9584323167800903}]}, {"text": "In our second experiment, we will compare the performance of our totally unsupervised approach (monosemous corpus and automatic bias) with other unsupervised approaches in the Senseval-2 English lexical task.", "labels": [], "entities": [{"text": "Senseval-2 English lexical task", "start_pos": 176, "end_pos": 207, "type": "TASK", "confidence": 0.46860281378030777}]}], "tableCaptions": [{"text": " Table 1: Examples per type (0,1,...) that are ac- quired from the web for the three senses of church  following the Semcor bias, and total examples in  Semcor.", "labels": [], "entities": []}, {"text": " Table 2: Distribution of examples for the senses of authority in different corpora. Pr (proportional) and MR  (minimum ratio) columns correspond to different ways to apply Semcor bias.", "labels": [], "entities": [{"text": "Pr", "start_pos": 85, "end_pos": 87, "type": "METRIC", "confidence": 0.9764560461044312}, {"text": "MR  (minimum ratio)", "start_pos": 107, "end_pos": 126, "type": "METRIC", "confidence": 0.949855101108551}]}, {"text": " Table 3: Number of examples following different  sense distributions. Minimum-ratio is applied for  the Semcor and automatic bias.", "labels": [], "entities": [{"text": "Minimum-ratio", "start_pos": 71, "end_pos": 84, "type": "METRIC", "confidence": 0.9959391355514526}, {"text": "Semcor", "start_pos": 105, "end_pos": 111, "type": "DATASET", "confidence": 0.9023874998092651}]}, {"text": " Table 4: Recall for all the nouns using the monose- mous corpus with Senseval-2 training bias (MR, and  substitution), Semcor bias, and Automatic bias. The  Senseval-2 results are given by feature type.", "labels": [], "entities": [{"text": "MR", "start_pos": 96, "end_pos": 98, "type": "METRIC", "confidence": 0.9455243349075317}, {"text": "Automatic bias", "start_pos": 137, "end_pos": 151, "type": "METRIC", "confidence": 0.9808989763259888}]}, {"text": " Table 5: Performance (recall) on Senseval-2 lexical- sample, using different bias to create the corpus.  The type column shows the kind of system.", "labels": [], "entities": [{"text": "recall", "start_pos": 23, "end_pos": 29, "type": "METRIC", "confidence": 0.993854820728302}, {"text": "Senseval-2 lexical- sample", "start_pos": 34, "end_pos": 60, "type": "DATASET", "confidence": 0.8133828639984131}]}, {"text": " Table 6: Recall training in Semcor, the acquired  web corpus (Semcor bias), and a combination of  both, compared to that of the Semcor MFS.", "labels": [], "entities": []}, {"text": " Table 7: Our minimally supervised and fully unsu- pervised systems compared to the unsupervised sys- tems (marked in bold) in the 29 noun subset of the  Senseval-2 Lexical Sample.", "labels": [], "entities": [{"text": "Senseval-2 Lexical Sample", "start_pos": 154, "end_pos": 179, "type": "DATASET", "confidence": 0.81494140625}]}]}