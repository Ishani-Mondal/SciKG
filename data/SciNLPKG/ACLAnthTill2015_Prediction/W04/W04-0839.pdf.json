{"title": [{"text": "Complementarity of Lexical and Simple Syntactic Features: The SyntaLex Approach to SENSEVAL-3", "labels": [], "entities": [{"text": "SENSEVAL-3", "start_pos": 83, "end_pos": 93, "type": "TASK", "confidence": 0.8593027591705322}]}], "abstractContent": [{"text": "This paper describes the SyntaLex entries in the English Lexical Sample Task of SENSEVAL-3.", "labels": [], "entities": []}, {"text": "There are four entries in all, where each of the different entries corresponds to use of word bigrams or Part of Speech tags as features.", "labels": [], "entities": []}, {"text": "The systems rely on bagged decision trees, and focus on using pairs of lexical and syntactic features individually and in combination.", "labels": [], "entities": []}, {"text": "They are descendants of the Duluth systems that participated in SENSEVAL-2.", "labels": [], "entities": [{"text": "SENSEVAL-2", "start_pos": 64, "end_pos": 74, "type": "TASK", "confidence": 0.7442019581794739}]}], "introductionContent": [{"text": "The SyntaLex systems are supervised learners that identify the intended sense of a word (target word) given its context.", "labels": [], "entities": [{"text": "identify the intended sense of a word (target word)", "start_pos": 50, "end_pos": 101, "type": "TASK", "confidence": 0.6820064810189334}]}, {"text": "They are derived from the Duluth systems that participated in SENSEVAL-2, and which are more fully described in.", "labels": [], "entities": [{"text": "SENSEVAL-2", "start_pos": 62, "end_pos": 72, "type": "TASK", "confidence": 0.7048981785774231}]}, {"text": "The context of a word is a rich source of discrete features which lend themselves nicely to decision tree learning.", "labels": [], "entities": [{"text": "decision tree learning", "start_pos": 92, "end_pos": 114, "type": "TASK", "confidence": 0.7403887112935384}]}, {"text": "Prior research (e.g.,,,,) suggests that use of both syntactic and lexical features will improve disambiguation accuracies.", "labels": [], "entities": [{"text": "disambiguation accuracies", "start_pos": 96, "end_pos": 121, "type": "TASK", "confidence": 0.8382563889026642}]}, {"text": "There has also been considerable work on word sense disambiguation using various supervised learning algorithms.", "labels": [], "entities": [{"text": "word sense disambiguation", "start_pos": 41, "end_pos": 66, "type": "TASK", "confidence": 0.8113758563995361}]}, {"text": "However, both and ( show that different learning algorithms produce similar results and that the use of appropriate features may dramatically improve results.", "labels": [], "entities": []}, {"text": "Thus, our focus is not on the learning algorithm but on the features used and their dynamics.", "labels": [], "entities": []}, {"text": "Our systems use bigrams and Part of Speech features individually, in a simple ensemble and as part of single classifier using both kinds of features.", "labels": [], "entities": []}, {"text": "We also show that state of the art results (72.1%, coarse grained accuracy) can be achieved using just these simple sets of features.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 66, "end_pos": 74, "type": "METRIC", "confidence": 0.8004435300827026}]}], "datasetContent": [{"text": "The SyntaLex systems are used to perform a series of word sense disambiguation experiments using lexical and syntactic features both individually and in combination.", "labels": [], "entities": [{"text": "word sense disambiguation", "start_pos": 53, "end_pos": 78, "type": "TASK", "confidence": 0.6537074645360311}]}, {"text": "The C4.5 algorithm, as implemented by the J48 program in the Waikato Environment for Knowledge Analysis http://www.d.umn.edu/ tpederse/pos.html 2000) is used to learn bagged decision trees for each word to be disambiguated.", "labels": [], "entities": []}, {"text": "Ten decision trees are learned for each task based on ten different samples of training instances.", "labels": [], "entities": []}, {"text": "Each sample is created by drawing N instances, with replacement, from a training set consisting of N total instances.", "labels": [], "entities": []}, {"text": "Given a test instance, weighted scores for each sense provided by each of the ten decision trees are summed.", "labels": [], "entities": []}, {"text": "The sense with the highest score is chosen as the intended sense.", "labels": [], "entities": []}, {"text": "A majority classifier which always chooses the most frequent sense of a word in the training data, achieves an accuracy of 56.5%.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 111, "end_pos": 119, "type": "METRIC", "confidence": 0.9996403455734253}]}, {"text": "This result acts as a baseline to which our results maybe compared.", "labels": [], "entities": []}, {"text": "The decision trees learned by our system fallback on the most frequent sense in case the identified features are unable to disambiguate the target word.", "labels": [], "entities": []}, {"text": "Thus, the classification of all test instances is attempted and we therefore report our results () in terms of accuracies.", "labels": [], "entities": []}, {"text": "The breakdown of the coarse and fine grained accuracies for nouns, verbs and adjectives is also depicted.", "labels": [], "entities": []}, {"text": "Consider a sentence where the target word line is used in the plural form, has a personal pronoun preceding it and is not followed by a preposition.", "labels": [], "entities": []}, {"text": "A decision tree based on such Part of Speech features as described above is likely to capture the intuitive notion that in such cases line is used in the line of text sense, as in, the actor forgot his lines or they read their lines slowly.", "labels": [], "entities": []}, {"text": "Similarly, if the word following line is a preposition, the tree is likely to predict the product sense, as in, the line of clothes.", "labels": [], "entities": []}], "tableCaptions": []}