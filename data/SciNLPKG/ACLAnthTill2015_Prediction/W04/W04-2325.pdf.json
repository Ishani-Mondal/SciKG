{"title": [{"text": "Causes and Strategies for Requesting Clarification in Dialogue", "labels": [], "entities": [{"text": "Requesting Clarification in Dialogue", "start_pos": 26, "end_pos": 62, "type": "TASK", "confidence": 0.9344405829906464}]}], "abstractContent": [{"text": "We do two things in this paper.", "labels": [], "entities": []}, {"text": "First, we present a model of possible causes for requesting clarifications in dialogue, i.e., we classify types of non-understandings that lead to clarifications.", "labels": [], "entities": []}, {"text": "For this we make more precise the models of communication of (Clark, 1996) and (Allwood, 1995), relating them to an independently motivated theory of discourse semantics , SDRT (Asher and Lascarides, 2003).", "labels": [], "entities": []}, {"text": "As we show, the lack of such a model is a problem for extant analyses of clarification moves.", "labels": [], "entities": []}, {"text": "Second, we combine this model with an extended notion of \"confidence score\" that combines speech recognition confidence with different kinds of semantic and pragmatic confidence , and argue that the resulting processing model can produce a more natural clarification and confirmation behaviour than that of current dialogue systems.", "labels": [], "entities": []}, {"text": "We close with a description of an experimental implementation of the model.", "labels": [], "entities": []}], "introductionContent": [{"text": "It is widely accepted that it would be desirable for dialogue systems to be able to produce and understand the whole range of Clarification Requests (CRs) that can be found in human-human dialogue, as exemplified in the following: A precondition for fulfilling this desideratum is a detailed analysis of the communication problems that lead to the need for clarification.", "labels": [], "entities": [{"text": "Clarification Requests (CRs)", "start_pos": 126, "end_pos": 154, "type": "TASK", "confidence": 0.6640555620193481}]}, {"text": "As we show in this paper, extant approaches to CR do not satisfy this precondition.", "labels": [], "entities": [{"text": "CR", "start_pos": 47, "end_pos": 49, "type": "TASK", "confidence": 0.9805193543434143}]}, {"text": "We propose that a good starting-point for developing a more general analysis is a multi-levelled model of communication along the lines of and, distinguishing (among other things) between acoustic understanding and semantic understanding.", "labels": [], "entities": []}, {"text": "We explore such a model from the perspective of generating and interpreting CRs, making the central concepts of the model precise by relating it to an independently motivated model of discourse semantics called SDRT.", "labels": [], "entities": []}, {"text": "Deciding on whether to produce CRs is part of the Confirmation Strategy (CS) of a dialogue system (cf.), inter alia).", "labels": [], "entities": []}, {"text": "An explicit confirmation of an understanding can besought via a CR, whereas implicit confirmation can besought by displaying the system's understanding: (2) a.", "labels": [], "entities": []}, {"text": "Explicit confirmation: \"Did you say you want to leave from Potsdam?\" b. Implicit confirmation: \"From Potsdam.", "labels": [], "entities": []}, {"text": "Current dialogue systems base their decision on the CS to follow only on their confidence in the speech recognition results.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 97, "end_pos": 115, "type": "TASK", "confidence": 0.7570123076438904}]}, {"text": "It would be desirable, however, if they could clarify or confirm other hypotheses as well, for example about reference resolution, depending on their confidence in that resolution: Moreover, confidences on different levels of processing should be allowed to interact.", "labels": [], "entities": [{"text": "reference resolution", "start_pos": 109, "end_pos": 129, "type": "TASK", "confidence": 0.7861237823963165}]}, {"text": "Ina situation where the speech recogniser cannot decide between the hypotheses \"Sandy\" and \"Andy\" fora certain input, but where the former proper name can be resolved to a more salient discourse referent than the latter, a dialogue system should ideally prefer the former hypothesis and choose implicit confirmation (variant A below), rather than explicitly clarifying which alternative to choose (variant B): (4) User: Send the file to {Sandy | Andy}.", "labels": [], "entities": []}, {"text": "Sys a: To Sandy, OK.", "labels": [], "entities": [{"text": "Sys a: To Sandy, OK", "start_pos": 0, "end_pos": 19, "type": "DATASET", "confidence": 0.7314998592649188}]}, {"text": "Sys b: Did you say Sandy or Andy?", "labels": [], "entities": [{"text": "Andy", "start_pos": 28, "end_pos": 32, "type": "METRIC", "confidence": 0.9537444710731506}]}, {"text": "The remainder of the paper is organised as follows.", "labels": [], "entities": []}, {"text": "After presenting an initial classification of CRs and discussing extant approaches in the next section, we propose in Section 3 a model of causes for requesting clarification.", "labels": [], "entities": [{"text": "classification of CRs", "start_pos": 28, "end_pos": 49, "type": "TASK", "confidence": 0.6656412482261658}]}, {"text": "Building on this theoretical model we turn in Section 4 to extending the concept of confidence in a hypothesis in order to produce the CS behaviour sketched above.", "labels": [], "entities": []}, {"text": "We also discuss initial findings from an experimental implementation of this idea.", "labels": [], "entities": []}], "datasetContent": [{"text": "So far we have said very little about how the theory of discourse semantics alluded to in Section 3.2 tackles its various tasks.", "labels": [], "entities": []}, {"text": "Ina nutshell, the theory SDRT can be seen as a combination of dynamic semantics (e.g., DRT, (Kamp and Reyle, 1993)) plus (AI-based) pragmatics.", "labels": [], "entities": [{"text": "SDRT", "start_pos": 25, "end_pos": 29, "type": "TASK", "confidence": 0.9542102217674255}]}, {"text": "In contrast to traditional dynamic semantics, SDRT attempts to represent the pragmatically preferred interpretation of a discourse.", "labels": [], "entities": [{"text": "SDRT", "start_pos": 46, "end_pos": 50, "type": "TASK", "confidence": 0.95900559425354}]}, {"text": "The central notion of Discourse Update is for-mulated in SDRT within a precise nonmonotonic logic, in which one computes the rhetorical relation (or equivalently, the speech act type) which connects the new information to some antecedent utterance.", "labels": [], "entities": []}, {"text": "This speech act places constraints on content and the speech act related goals or SARGs; these in turn serve to resolve semantic underspecification.", "labels": [], "entities": [{"text": "SARGs", "start_pos": 82, "end_pos": 87, "type": "METRIC", "confidence": 0.8825728893280029}]}, {"text": "Note that those SARGs are goals that are either conventionally associated with a particular type of utterance or are recoverable by the interpreter from the discourse context; this distinguishes the goals that interact with linguistic knowledge from goals in general.", "labels": [], "entities": []}, {"text": "The implementation of the theory which we extended for this paper, RUDI (, works in the domain of appointment scheduling (we will refer to the extended version as RUDI clar ).", "labels": [], "entities": [{"text": "RUDI", "start_pos": 67, "end_pos": 71, "type": "METRIC", "confidence": 0.7845656871795654}, {"text": "appointment scheduling", "start_pos": 98, "end_pos": 120, "type": "TASK", "confidence": 0.7683340609073639}]}, {"text": "It focuses on resolving one particular kind of underspecification, namely that arising from the need to \"bridge\" definites to their context.", "labels": [], "entities": []}, {"text": "To give an example, for (15) the system computes that the \"Wednesday afternoon\" is 'bridged' via the relation 'next' to the time of utterance: A: What is a good time for you in the next couple of weeks?", "labels": [], "entities": []}, {"text": "B: Wednesday afternoon would be good.", "labels": [], "entities": [{"text": "B", "start_pos": 0, "end_pos": 1, "type": "METRIC", "confidence": 0.9634529948234558}]}, {"text": "It does this by non-monotonically inferring the rhetorical relation connecting the second to the first utterance (Question-Answer Pair), and using constraints on this relation (roughly, times mentioned in the answer must overlap with that from the question) to resolve underspecification.", "labels": [], "entities": []}, {"text": "Before we further describe how the algorithm works, however, we give a couple of examples illustrating the clarification behaviour of the system.", "labels": [], "entities": []}, {"text": "Example shows an input where the SR component offers two hypotheses that both have to be considered.", "labels": [], "entities": []}, {"text": "Let's assume that there is no salient Monday the 13th given the dialogue context.", "labels": [], "entities": [{"text": "Monday the 13th", "start_pos": 38, "end_pos": 53, "type": "DATASET", "confidence": 0.8018795450528463}]}, {"text": "In such a situation we want the system to dramatically lower its confidence in the Monday hypothesis, leading to a situation where only the Sunday hypothesis will have to be confirmed, and only implicitly, rather than having to clarify both hypotheses.", "labels": [], "entities": []}, {"text": "Here it is not the case that one hypothesis is ruled out completely; the difference between the hypotheses here is that one is 'costlier' to maintain.", "labels": [], "entities": []}, {"text": "In our approach the dialogue \"Let's meet next weekend.", "labels": [], "entities": []}, {"text": "-How about Monday?\" is just about coherent, under a reading where the second utterance indirectly corrects the plan (a more explicit version of this would be \"How about Monday instead?\").", "labels": [], "entities": []}, {"text": "This speech act (Plan-Correction), however, is inferred in RUDI clar with a much lower confidence than the more direct speech act Plan-Elaboration that is computed for the Sunday-variant of B's utterance.", "labels": [], "entities": [{"text": "RUDI clar", "start_pos": 59, "end_pos": 68, "type": "METRIC", "confidence": 0.9564584493637085}]}, {"text": "Hence, the system prefers that latter variant and proceeds accordingly.", "labels": [], "entities": []}, {"text": "The previous examples combined an ambiguity introduced by the SR module with confidence scores from further levels.", "labels": [], "entities": [{"text": "SR module", "start_pos": 62, "end_pos": 71, "type": "DATASET", "confidence": 0.6976674944162369}]}, {"text": "However, new ambiguity can also arise during these latter processing stages.", "labels": [], "entities": []}, {"text": "In (18) the temporal expression in B's utterance cannot be uniquely resolved (and in this sense the utterance is actually slightly incoherent, since it violates the uniqueness presupposition of definites), and so the system has to clarify the intended reference.", "labels": [], "entities": []}, {"text": "A: Let's meet this weekend.", "labels": [], "entities": []}, {"text": "B: How about at 3pm?", "labels": [], "entities": [{"text": "B", "start_pos": 0, "end_pos": 1, "type": "METRIC", "confidence": 0.9192724823951721}]}, {"text": "RUDI: 3pm on Saturday or 3pm on Sunday?", "labels": [], "entities": [{"text": "RUDI", "start_pos": 0, "end_pos": 4, "type": "METRIC", "confidence": 0.9651436805725098}]}, {"text": "The last example, (19), shows another source for quantified hypotheses: resolving any temporal expression other than \"tomorrow\" to the next day is dispreferred in the system, and so its confidence in this resolution is lowered and it has to be clarified.", "labels": [], "entities": []}, {"text": "We now sketch how the system works.", "labels": [], "entities": []}, {"text": "Reflecting the modularity of the underlying theory, RUDI( clar ) divides the update process into several stages (shown schematically in).", "labels": [], "entities": [{"text": "RUDI", "start_pos": 52, "end_pos": 56, "type": "METRIC", "confidence": 0.8389339447021484}]}, {"text": "The initial module mrs2di postprocesses the semantic representation provided by the grammar, for example by including underspecified bridging relations for definites.", "labels": [], "entities": []}, {"text": "RUDI clar allows logical forms to be annotated with confidence values (following an approach similar to that of (, associating the confidence values with labels in an underspecified LF), and it allows alternative hypotheses as input (only two at present).", "labels": [], "entities": [{"text": "RUDI", "start_pos": 0, "end_pos": 4, "type": "METRIC", "confidence": 0.7156457304954529}]}, {"text": "In this way we can represent in the system a situation where the speech recogniser cannot make a decision, as in or above.", "labels": [], "entities": []}, {"text": "At the next stage, an utterance in the context is chosen to which the current one can be attached via a rhetorical relation, and this in turn determines which antecedents for bridging are available.", "labels": [], "entities": []}, {"text": "(Should this choice turnout to lead to failure in successive modules, the system can backtrack and choose another attachment site.)", "labels": [], "entities": []}, {"text": "The speech act(s) of the current utterance is (are) then inferred non-monotonically (if there is more than one hypothesis coming from the previous step, this is done for each of them) from information about the antecedent and the current utterance and axioms for each relation.", "labels": [], "entities": []}, {"text": "The next module, sa cnstr, tests whether certain constraints on the meaning of the speech acts are satisfied by the utterances that are being connected.", "labels": [], "entities": []}, {"text": "After this, the SARGs are computed and any remaining underspecification is resolved.", "labels": [], "entities": [{"text": "SARGs", "start_pos": 16, "end_pos": 21, "type": "METRIC", "confidence": 0.8886709809303284}]}, {"text": "Finally, anew module clarify compares (if there is more than one) and scores the hypotheses, assigning scores for the bridging decisions and for the speech-act inferences.", "labels": [], "entities": []}, {"text": "Some of the rules used here are shown in.", "labels": [], "entities": []}, {"text": "A weighted average is computed, and, based on the resulting score, the module decides on whether to launch into a clarification sub-dialogue, and if so, which clarification strategy to follow.", "labels": [], "entities": []}, {"text": "(We set the thresholds for this and the weights for the average manually to achieve the behaviour described here; see discussion below.)", "labels": [], "entities": []}, {"text": "The level at which RUDI clar targets the clarification is always the lowest one where there was a problem; i.e., where alternative hypotheses were introduced, or where no result could be computed.", "labels": [], "entities": [{"text": "RUDI clar targets the clarification", "start_pos": 19, "end_pos": 54, "type": "TASK", "confidence": 0.7459312200546264}]}, {"text": "For instance, in (17) this would be the SR level rather than the speech act level.", "labels": [], "entities": [{"text": "SR level", "start_pos": 40, "end_pos": 48, "type": "METRIC", "confidence": 0.9706476926803589}]}, {"text": "This system is capable of producing flexible CRs that adapt to the dialogue context, and this shows the value of the idea of modelling in a fine-grained way sources of CRs and of extending the concept of confidence scores.", "labels": [], "entities": []}, {"text": "However, the system is only a first proof-of-concept, and we discuss possible improvements in the next section.", "labels": [], "entities": []}], "tableCaptions": []}