{"title": [{"text": "A New Approach for English-Chinese Named Entity Alignment", "labels": [], "entities": [{"text": "English-Chinese Named Entity Alignment", "start_pos": 19, "end_pos": 57, "type": "TASK", "confidence": 0.5904846787452698}]}], "abstractContent": [{"text": "* Traditional word alignment approaches cannot come up with satisfactory results for Named Entities.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 14, "end_pos": 28, "type": "TASK", "confidence": 0.7505039870738983}]}, {"text": "In this paper, we propose a novel approach using a maximum entropy model for named entity alignment.", "labels": [], "entities": [{"text": "named entity alignment", "start_pos": 77, "end_pos": 99, "type": "TASK", "confidence": 0.6442379355430603}]}, {"text": "To ease the training of the maximum entropy model, bootstrapping is used to help supervised learning.", "labels": [], "entities": []}, {"text": "Unlike previous work reported in the literature, our work conducts bilingual Named Entity alignment without word segmentation for Chinese and its performance is much better than that with word segmentation.", "labels": [], "entities": [{"text": "bilingual Named Entity alignment", "start_pos": 67, "end_pos": 99, "type": "TASK", "confidence": 0.614035464823246}, {"text": "word segmentation", "start_pos": 188, "end_pos": 205, "type": "TASK", "confidence": 0.7097550481557846}]}, {"text": "When compared with IBM and HMM alignment models, experimental results show that our approach outperforms IBM Model 4 and HMM significantly.", "labels": [], "entities": [{"text": "HMM alignment", "start_pos": 27, "end_pos": 40, "type": "TASK", "confidence": 0.6423793882131577}]}], "introductionContent": [{"text": "This paper addresses the Named Entity (NE) alignment of a bilingual corpus, which means building an alignment between each source NE and its translation NE in the target language.", "labels": [], "entities": []}, {"text": "Research has shown that Named Entities (NE) carry essential information inhuman language.", "labels": [], "entities": []}, {"text": "Aligning bilingual Named Entities is an effective way to extract an NE translation list and translation templates.", "labels": [], "entities": [{"text": "Aligning bilingual Named Entities", "start_pos": 0, "end_pos": 33, "type": "TASK", "confidence": 0.8343668729066849}]}, {"text": "For example, in the following sentence pair, aligning the NEs, and can produce a translation template correctly.", "labels": [], "entities": []}, {"text": "A Named Entity alignment, however, is not easy to obtain.", "labels": [], "entities": []}, {"text": "It requires both Named Entity Recognition (NER) and alignment be handled correctly.", "labels": [], "entities": [{"text": "Named Entity Recognition (NER)", "start_pos": 17, "end_pos": 47, "type": "TASK", "confidence": 0.7318723797798157}, {"text": "alignment", "start_pos": 52, "end_pos": 61, "type": "METRIC", "confidence": 0.7667255997657776}]}, {"text": "NEs may not be well recognized, or only * The work was done while the first author was visiting Microsoft Research Asia.", "labels": [], "entities": [{"text": "NEs", "start_pos": 0, "end_pos": 3, "type": "TASK", "confidence": 0.8991919755935669}, {"text": "Microsoft Research Asia", "start_pos": 96, "end_pos": 119, "type": "DATASET", "confidence": 0.796000341574351}]}, {"text": "parts of them maybe recognized during NER.", "labels": [], "entities": [{"text": "NER", "start_pos": 38, "end_pos": 41, "type": "TASK", "confidence": 0.9194405674934387}]}, {"text": "When aligning bilingual NEs in different languages, we need to handle many-to-many alignments.", "labels": [], "entities": []}, {"text": "And the inconsistency of NE translation and NER in different languages is also a big problem.", "labels": [], "entities": [{"text": "NE translation", "start_pos": 25, "end_pos": 39, "type": "TASK", "confidence": 0.9520554840564728}]}, {"text": "Specifically, in Chinese NE processing, since Chinese is not a tokenized language, previous work ( normally conducts word segmentation and identifies Named Entities in turn.", "labels": [], "entities": [{"text": "Chinese NE processing", "start_pos": 17, "end_pos": 38, "type": "TASK", "confidence": 0.6475374897321066}, {"text": "word segmentation", "start_pos": 117, "end_pos": 134, "type": "TASK", "confidence": 0.7132083773612976}]}, {"text": "This involves several problems for Chinese NEs, such as word segmentation error, the identification of Chinese NE boundaries, and the mis-tagging of Chinese NEs.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 56, "end_pos": 73, "type": "TASK", "confidence": 0.7064123302698135}, {"text": "identification of Chinese NE boundaries", "start_pos": 85, "end_pos": 124, "type": "TASK", "confidence": 0.858877980709076}]}, {"text": "For example, \"\u56fd\u9632\u90e8\u957f\" in Chinese is really one unit and should not be segmented as/\u957f.", "labels": [], "entities": []}, {"text": "The errors from word segmentation and NER will propagate into NE alignment.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 16, "end_pos": 33, "type": "TASK", "confidence": 0.7003946751356125}]}, {"text": "In this paper, we propose a novel approach using a maximum entropy model to carryout EnglishChinese Named Entity 1 alignment.", "labels": [], "entities": [{"text": "EnglishChinese Named Entity 1 alignment", "start_pos": 85, "end_pos": 124, "type": "DATASET", "confidence": 0.9297897338867187}]}, {"text": "NEs in English are first recognized by NER tools.", "labels": [], "entities": [{"text": "NEs", "start_pos": 0, "end_pos": 3, "type": "TASK", "confidence": 0.9348729848861694}]}, {"text": "We then investigate NE translation features to identify NEs in Chinese and determine the most probable alignment.", "labels": [], "entities": [{"text": "NE translation", "start_pos": 20, "end_pos": 34, "type": "TASK", "confidence": 0.8477977514266968}]}, {"text": "To ease the training of the maximum entropy model, bootstrapping is used to help supervised learning.", "labels": [], "entities": []}, {"text": "On the other hand, to avoid error propagations from word segmentation and NER, we directly extract Chinese NEs and make the alignment from plain text without word segmentation.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 52, "end_pos": 69, "type": "TASK", "confidence": 0.6948022544384003}]}, {"text": "It is unlike previous work reported in the literature.", "labels": [], "entities": []}, {"text": "Although this makes the task more difficult, it greatly reduces the chance of errors introduced by previous steps and therefore produces much better performance on our task.", "labels": [], "entities": []}, {"text": "To justify our approach, we adopt traditional alignment approaches, in particular IBM Model 4 () and HMM (, to carryout NE alignment as our baseline systems.", "labels": [], "entities": [{"text": "NE alignment", "start_pos": 120, "end_pos": 132, "type": "TASK", "confidence": 0.9391164183616638}]}, {"text": "Experimental results show that in this task our approach outperforms IBM Model 4 and HMM significantly.", "labels": [], "entities": [{"text": "IBM Model 4", "start_pos": 69, "end_pos": 80, "type": "DATASET", "confidence": 0.8899834553400675}]}, {"text": "Furthermore, the performance without word segmentation is much better than that with word segmentation.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 37, "end_pos": 54, "type": "TASK", "confidence": 0.710370197892189}, {"text": "word segmentation", "start_pos": 85, "end_pos": 102, "type": "TASK", "confidence": 0.6954658478498459}]}, {"text": "The rest of this paper is organized as follows: In section 2, we discuss related work on NE alignment.", "labels": [], "entities": [{"text": "NE alignment", "start_pos": 89, "end_pos": 101, "type": "TASK", "confidence": 0.9411464333534241}]}, {"text": "Section 3 gives the overall framework of NE alignment with our maximum entropy model.", "labels": [], "entities": [{"text": "NE alignment", "start_pos": 41, "end_pos": 53, "type": "TASK", "confidence": 0.9611075222492218}]}, {"text": "Feature functions and bootstrapping procedures are also explained in this section.", "labels": [], "entities": []}, {"text": "We show experimental results and compare them with baseline systems in Section 4.", "labels": [], "entities": []}, {"text": "Section 5 concludes the paper and discusses ongoing future work.", "labels": [], "entities": []}], "datasetContent": [{"text": "We perform experiments to investigate the performance of the above framework.", "labels": [], "entities": []}, {"text": "We take the LDC Xinhua News with aligned English-Chinese sentence pairs as our corpus.", "labels": [], "entities": [{"text": "LDC Xinhua News", "start_pos": 12, "end_pos": 27, "type": "DATASET", "confidence": 0.9165546894073486}]}, {"text": "The incremental testing strategy is to investigate the system's performance as more and more data are added into the data set.", "labels": [], "entities": []}, {"text": "Initially, we take 300 2 http://www.isi.edu/~och/YASMET.html sentences as the standard testing set, and we repeatedly add 5k more sentences into the data set and process the new data.", "labels": [], "entities": [{"text": "YASMET.html", "start_pos": 49, "end_pos": 60, "type": "METRIC", "confidence": 0.7678252458572388}]}, {"text": "After iterative re-ranking, the performance of alignment models over the 300 sentence pairs is calculated.", "labels": [], "entities": []}, {"text": "The learning curves are drawn from 5k through 30k sentences with the step as 5k every time.", "labels": [], "entities": []}], "tableCaptions": []}