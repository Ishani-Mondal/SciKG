{"title": [{"text": "Hybrid Statistical and Structural Semantic Modeling for Thai Multi- Stage Spoken Language Understanding", "labels": [], "entities": [{"text": "Thai Multi- Stage Spoken Language Understanding", "start_pos": 56, "end_pos": 103, "type": "TASK", "confidence": 0.586202187197549}]}], "abstractContent": [{"text": "This article proposes a hybrid statistical and structural semantic model for multi-stage spoken language understanding (SLU).", "labels": [], "entities": [{"text": "multi-stage spoken language understanding (SLU)", "start_pos": 77, "end_pos": 124, "type": "TASK", "confidence": 0.7470128663948604}]}, {"text": "The first stage of this SLU utilizes a weighted finite state transducer (WFST)-based parser, which encodes the regular grammar of concepts to be extracted.", "labels": [], "entities": []}, {"text": "The proposed method improves the regular grammar model by incorporating a well-known n-gram semantic tagger.", "labels": [], "entities": []}, {"text": "This hybrid model thus enhances the syntax of n-gram outputs while providing robustness against speech-recognition errors.", "labels": [], "entities": []}, {"text": "With applications to a Thai hotel reservation domain, it is shown to outperform both individual models at every stage of the SLU system.", "labels": [], "entities": [{"text": "Thai hotel reservation domain", "start_pos": 23, "end_pos": 52, "type": "TASK", "confidence": 0.6231152042746544}]}, {"text": "Under the probabilistic WFST framework, the use of N-best hypotheses from the speech recognizer instead of the 1-best can further improve performance requiring only a small additional processing time.", "labels": [], "entities": []}], "introductionContent": [{"text": "Automatic speech recognition (ASR) for Thai language is still in the first stage, where Thai researchers in related fields have worked towards creating fundamental tools for language processing such as phonological and morphological analyzers.", "labels": [], "entities": [{"text": "Automatic speech recognition (ASR)", "start_pos": 0, "end_pos": 34, "type": "TASK", "confidence": 0.7931670149167379}]}, {"text": "Although Thai writing is an alphabetic system, a problem of writing without sentence markers or spaces between words has obstructed initiation of development of ASR.", "labels": [], "entities": [{"text": "ASR", "start_pos": 161, "end_pos": 164, "type": "TASK", "confidence": 0.9813971519470215}]}, {"text": "Pioneering a Thai spoken dialogue system has therefore become a challenging task, where several unique components need to be developed specifically fora Thai system.", "labels": [], "entities": [{"text": "Thai spoken dialogue system", "start_pos": 13, "end_pos": 40, "type": "TASK", "confidence": 0.6841525509953499}]}, {"text": "Our prototype dialogue system, namely Thai Interactive Hotel Reservation Agent (TIRA), was created mainly by handcrafted rules.", "labels": [], "entities": [{"text": "Thai Interactive Hotel Reservation Agent (TIRA)", "start_pos": 38, "end_pos": 85, "type": "TASK", "confidence": 0.7023349031805992}]}, {"text": "The first user evaluation showed that the spoken language understanding (SLU) part of the system proved the most problematic as it could not cover the variety of contents supplied by the users, especially when they talked in a mixed-initiative style.", "labels": [], "entities": [{"text": "spoken language understanding (SLU)", "start_pos": 42, "end_pos": 77, "type": "TASK", "confidence": 0.7796984016895294}]}, {"text": "To rapidly improve performance, a trainable SLU model is preferable and it needs to be able to learn from a partially annotated corpus, where only essential keywords are given.", "labels": [], "entities": []}, {"text": "This is particularly important for Thai where no large corpus is available.", "labels": [], "entities": []}, {"text": "Recently, a novel multi-stage SLU model has been developed, which combines two different practices used for SLU-related tasks, robust semantic parsing and topic classification.", "labels": [], "entities": [{"text": "semantic parsing", "start_pos": 134, "end_pos": 150, "type": "TASK", "confidence": 0.7161140739917755}, {"text": "topic classification", "start_pos": 155, "end_pos": 175, "type": "TASK", "confidence": 0.784597784280777}]}, {"text": "The former paradigm was implemented in the concept extraction and concept-value recognition component, whereas the latter was applied for the goal identification component.", "labels": [], "entities": [{"text": "concept extraction", "start_pos": 43, "end_pos": 61, "type": "TASK", "confidence": 0.7267980426549911}, {"text": "concept-value recognition", "start_pos": 66, "end_pos": 91, "type": "TASK", "confidence": 0.7061618864536285}, {"text": "goal identification", "start_pos": 142, "end_pos": 161, "type": "TASK", "confidence": 0.7708026766777039}]}, {"text": "The concept extraction utilizes a set of weighted finite-state transducers (WFST) to encode possible word-syntax (or regular grammar) expressed for each concept.", "labels": [], "entities": [{"text": "concept extraction", "start_pos": 4, "end_pos": 22, "type": "TASK", "confidence": 0.745059460401535}]}, {"text": "The concept WFST not only determines the existence of a concept in an input utterance, but also labels keywords used to construct its value in the concept-value recognition component.", "labels": [], "entities": []}, {"text": "Given the extracted concepts, the goal of the utterance can be identified in the goal identification component using a generalized pattern classifier.", "labels": [], "entities": []}, {"text": "This article reports an improvement of the concept extraction and concept-value recognition parts by conducting a well-known statistical n-gram parser to compensate for the concept expressions, which cannot be recognized by the ordinary concept WFST.", "labels": [], "entities": [{"text": "concept extraction", "start_pos": 43, "end_pos": 61, "type": "TASK", "confidence": 0.7178197652101517}, {"text": "concept-value recognition", "start_pos": 66, "end_pos": 91, "type": "TASK", "confidence": 0.72794409096241}, {"text": "WFST", "start_pos": 245, "end_pos": 249, "type": "DATASET", "confidence": 0.9072383642196655}]}, {"text": "The ngram modeling alone lacks structural information as it captures only up to n-word dependencies.", "labels": [], "entities": []}, {"text": "Combining the statistical and structural model for SLU hence becomes a better alternative.", "labels": [], "entities": [{"text": "SLU", "start_pos": 51, "end_pos": 54, "type": "TASK", "confidence": 0.7454442381858826}]}, {"text": "Motivated by, we propose a strategic way called logical ngram modeling, which combines the statistical n-gram with the existing regular grammar.", "labels": [], "entities": [{"text": "logical ngram modeling", "start_pos": 48, "end_pos": 70, "type": "TASK", "confidence": 0.6097769637902578}]}, {"text": "In contrast to the regular-grammar approach, the probabilistic model allows the SLU to deal with ASR N-best hypotheses, resulting in an increment of the overall performance.", "labels": [], "entities": []}, {"text": "Some related works are reviewed in the next section, followed by a description of our multi-stage SLU model.", "labels": [], "entities": []}, {"text": "Section 4 explains the proposed hybrid model.", "labels": [], "entities": []}, {"text": "Section 5 shows the evaluation results with a conclusion in section 6.", "labels": [], "entities": []}], "datasetContent": [{"text": "Four measures were used for evaluation: 1.", "labels": [], "entities": []}, {"text": "Word accuracy (WAcc) -the standard measure for evaluating the ASR, 2.", "labels": [], "entities": [{"text": "accuracy (WAcc)", "start_pos": 5, "end_pos": 20, "type": "METRIC", "confidence": 0.9061200022697449}, {"text": "ASR", "start_pos": 62, "end_pos": 65, "type": "TASK", "confidence": 0.9124521613121033}]}, {"text": "Concept F-measure (ConF) -the F-measure of detected concepts, 3.", "labels": [], "entities": []}, {"text": "Goal accuracy (GAcc) -the number of utterances with correctly identified goals, divided by the total number of test utterances, 4.", "labels": [], "entities": [{"text": "accuracy (GAcc)", "start_pos": 5, "end_pos": 20, "type": "METRIC", "confidence": 0.9229094684123993}]}, {"text": "Concept-value accuracy (CAcc) -the number of concepts, whose values are correctly matched to their references, divided by the total number of concepts that contain values.", "labels": [], "entities": [{"text": "accuracy (CAcc)", "start_pos": 14, "end_pos": 29, "type": "METRIC", "confidence": 0.9240143001079559}]}], "tableCaptions": [{"text": " Table 3. Characteristics of data sets", "labels": [], "entities": []}, {"text": " Table 4. Evaluation results for the ES set using the  Reg, Ngram, and LNgram models.", "labels": [], "entities": [{"text": "ES set", "start_pos": 37, "end_pos": 43, "type": "DATASET", "confidence": 0.7510391473770142}]}]}