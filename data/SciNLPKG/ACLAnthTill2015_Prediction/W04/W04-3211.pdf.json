{"title": [{"text": "Mixing Weak Learners in Semantic Parsing", "labels": [], "entities": []}], "abstractContent": [{"text": "We apply a novel variant of Random Forests (Breiman, 2001) to the shallow semantic parsing problem and show extremely promising results.", "labels": [], "entities": [{"text": "shallow semantic parsing", "start_pos": 66, "end_pos": 90, "type": "TASK", "confidence": 0.6075824399789175}]}, {"text": "The final system has a semantic role classification accuracy of 88.3% using PropBank gold-standard parses.", "labels": [], "entities": [{"text": "semantic role classification", "start_pos": 23, "end_pos": 51, "type": "TASK", "confidence": 0.5756663183371226}, {"text": "accuracy", "start_pos": 52, "end_pos": 60, "type": "METRIC", "confidence": 0.9326699376106262}, {"text": "PropBank gold-standard parses", "start_pos": 76, "end_pos": 105, "type": "DATASET", "confidence": 0.9613479971885681}]}, {"text": "These results are better than all others published except those of the Support Vector Machine (SVM) approach implemented by Pradhan et al.", "labels": [], "entities": []}, {"text": "(2003) and Random Forests have numerous advantages over SVMs including simplicity, faster training and classification, easier multi-class classification , and easier problem-specific customization.", "labels": [], "entities": [{"text": "multi-class classification", "start_pos": 126, "end_pos": 152, "type": "TASK", "confidence": 0.7178124338388443}]}, {"text": "We also present new features which result in a 1.1% gain in classification accuracy and describe a technique that results in a 97% reduction in the feature space with no significant degradation inaccuracy.", "labels": [], "entities": [{"text": "classification", "start_pos": 60, "end_pos": 74, "type": "TASK", "confidence": 0.950401782989502}, {"text": "accuracy", "start_pos": 75, "end_pos": 83, "type": "METRIC", "confidence": 0.9637009501457214}]}], "introductionContent": [{"text": "Shallow semantic parsing is the process of finding sentence constituents that play a semantic role relative to a target predicate and then labeling those constituents according to their respective roles.", "labels": [], "entities": [{"text": "Shallow semantic parsing", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.6889212628205618}]}, {"text": "Specifying an event's agent, patient, location, time of occurrence, etc, can be useful for NLP tasks such as information extraction (c.f.,, dialog understanding, question answering, text summarization, and machine translation.", "labels": [], "entities": [{"text": "information extraction", "start_pos": 109, "end_pos": 131, "type": "TASK", "confidence": 0.7716159820556641}, {"text": "dialog understanding", "start_pos": 140, "end_pos": 160, "type": "TASK", "confidence": 0.840207040309906}, {"text": "question answering", "start_pos": 162, "end_pos": 180, "type": "TASK", "confidence": 0.8736920654773712}, {"text": "text summarization", "start_pos": 182, "end_pos": 200, "type": "TASK", "confidence": 0.7471864521503448}, {"text": "machine translation", "start_pos": 206, "end_pos": 225, "type": "TASK", "confidence": 0.8186200559139252}]}, {"text": "Example 1 depicts a semantic parse.", "labels": [], "entities": []}, {"text": "We expand on previous semantic parsing work () by presenting a novel algorithm worthy of further exploration, describing a technique to drastically reduce feature space size, and presenting statistically significant new features.", "labels": [], "entities": [{"text": "semantic parsing", "start_pos": 22, "end_pos": 38, "type": "TASK", "confidence": 0.7425723671913147}]}, {"text": "The accuracy of the final system is 88.3% on the classification task using the) corpus.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.999667763710022}]}, {"text": "This is just 0.6% off the best accuracy reported in the literature.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 31, "end_pos": 39, "type": "METRIC", "confidence": 0.9991611242294312}]}, {"text": "The classification algorithm used here is a variant of Random Forests (RFs)).", "labels": [], "entities": []}, {"text": "This was motivated by Breiman's empirical studies of numerous datasets showing that RFs often have lower generalize error than AdaBoost, are less sensitive to noise in the training data, and learn well from weak inputs, while taking much less time to train.", "labels": [], "entities": [{"text": "AdaBoost", "start_pos": 127, "end_pos": 135, "type": "DATASET", "confidence": 0.9243291616439819}]}, {"text": "RFs are also simpler to understand and implement than SVMs, leading to, among other things, easier interpretation of feature importance and interactions (c.f.,), easier multi-class classification (requiring only a single training session versus one for each class), and easier problem-specific customization (e.g., by introducing prior knowledge).", "labels": [], "entities": [{"text": "interpretation of feature importance and interactions", "start_pos": 99, "end_pos": 152, "type": "TASK", "confidence": 0.8461006085077921}, {"text": "multi-class classification", "start_pos": 169, "end_pos": 195, "type": "TASK", "confidence": 0.696494072675705}]}, {"text": "The algorithm described here is considerably different from those in.", "labels": [], "entities": []}, {"text": "It was significantly revised to better handle high dimensional categorical inputs and as a result provides much better accuracy on the shallow semantic parsing problem.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 119, "end_pos": 127, "type": "METRIC", "confidence": 0.9988364577293396}, {"text": "shallow semantic parsing", "start_pos": 135, "end_pos": 159, "type": "TASK", "confidence": 0.5918023685614268}]}, {"text": "The experiments reported here focus on the classification task -given a parsed constituent known to play a semantic role relative to a given predicate, decide which role is the appropriate one to assign to that constituent.", "labels": [], "entities": []}, {"text": "Gold-standard sentence parses for test and training are taken from the PropBank dataset.", "labels": [], "entities": [{"text": "PropBank dataset", "start_pos": 71, "end_pos": 87, "type": "DATASET", "confidence": 0.9885217845439911}]}, {"text": "We report results on two feature sets from the literature and anew feature set described here.", "labels": [], "entities": []}, {"text": "In section 2, we describe the data used in the experiments.", "labels": [], "entities": []}, {"text": "Section 3 details the classification algorithm.", "labels": [], "entities": [{"text": "classification", "start_pos": 22, "end_pos": 36, "type": "TASK", "confidence": 0.9850554466247559}]}, {"text": "Section 4 presents the experimental results and describes each experiment's feature set.", "labels": [], "entities": []}, {"text": "Section 5 provides a discussion and thoughts on future work.", "labels": [], "entities": []}], "datasetContent": [{"text": "Four experiments are reported: the first uses the baseline features of; the second is composed of features proposed by and; the third experiment evaluates anew feature set; and the final experiment addresses a method of reducing the feature space.", "labels": [], "entities": []}, {"text": "The experiments all focus strictly on the classification task -given a syntactic constituent known to bean argument of a given predicate, decide which argument role is the appropriate one to assign to the constituent.", "labels": [], "entities": []}, {"text": "The first experiment compares the random forest classifier to three other classifiers, a statistical Bayesian approach with backoff (), a decision tree classifier (, and a Support Vector Machine (SVM) ().", "labels": [], "entities": []}, {"text": "The baseline feature set utilized in this experiment is described in (see () for details).", "labels": [], "entities": []}, {"text": "Surdeanu et al. omit the SU B-CA T E G OR I Z A T I ON feature, but add a binary-valued feature that indicates the governing category of noun-phrase argument constituents.", "labels": [], "entities": [{"text": "SU B-CA T E G OR I Z A T I ON feature", "start_pos": 25, "end_pos": 62, "type": "METRIC", "confidence": 0.8720681002506843}]}, {"text": "This feature takes on the value S or VP depending on which constituent type (sentence or verb phase respectively) eventually dominates the argument in the parse tree.", "labels": [], "entities": []}, {"text": "This generally indicates grammatical subjects versus objects, respectively.", "labels": [], "entities": []}, {"text": "They also used the predicate with its case and morphology intact, in addition to using its lemma.", "labels": [], "entities": []}, {"text": "Surdeanu et al. indicate that, due to memory limitations on Classifier Accuracy Bayesian ( 82.8 Decision Tree ( 78.8 SVM ( 87.1 First Tree 78.3 Random Forest 84.6: Results of baseline feature set experiment their hardware, they trained on only 75 KB of the PropBank argument constituents -about 60% of the annotated data.", "labels": [], "entities": [{"text": "82.8 Decision Tree ( 78.8 SVM ( 87.1 First Tree 78.3 Random Forest 84.6", "start_pos": 91, "end_pos": 162, "type": "DATASET", "confidence": 0.614098710673196}]}, {"text": "shows the results of experiment 1, comparing the classifier accuracies as trained on the baseline feature set.", "labels": [], "entities": []}, {"text": "Using a difference of two proportions test as described in, the accuracy differences are all statistically significant at p=0.01.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 64, "end_pos": 72, "type": "METRIC", "confidence": 0.9992879033088684}]}, {"text": "The Random Forest approach outperforms the Bayesian method and the Decision Tree method.", "labels": [], "entities": []}, {"text": "However, it does not perform as well as the SVM classifier.", "labels": [], "entities": []}, {"text": "Interestingly, the classification accuracy of the first tree in the Random Forest, given in row four, is almost as high as that of the C5 decision trees) of Surdeanu et al.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 34, "end_pos": 42, "type": "METRIC", "confidence": 0.9765177965164185}, {"text": "Random Forest", "start_pos": 68, "end_pos": 81, "type": "DATASET", "confidence": 0.8999115526676178}]}, {"text": "The second experiment compares the random forest classifier to the boosted decision tree and the SVM using all of the features reported by Pradhan et al.", "labels": [], "entities": []}, {"text": "The additional features used in this experiment are listed in (see sources for further details).", "labels": [], "entities": []}, {"text": "In addition to the extra features noted in the previous experiment, Surdeanu et al. report on four more features, not included here (content word part of speech (CW PoS) 1 , CW named entity class, and two phrasal verb collocation features).", "labels": [], "entities": []}, {"text": "shows the results of experiment 2, comparing the classifier accuracies using the full feature sets reported in each source.", "labels": [], "entities": []}, {"text": "Surdeanu et al. also applied boosting in this experiment and chose the outcome of the boosting iteration that performed best.", "labels": [], "entities": []}, {"text": "Using the difference of two proportions test, the accuracy differences are all statistically significant at p=0.01.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 50, "end_pos": 58, "type": "METRIC", "confidence": 0.9994351267814636}]}, {"text": "The Random Forest approach outperforms the Boosted Decision Tree method by 3.5%, but trails the SVM classifier by 2.3%.", "labels": [], "entities": []}, {"text": "In analyzing the performance on individual argument classes using McNemar's test, Random Forest performs significantly better on AR G0 (p=0.001) then the SVM, and the SVM has significantly better results on AR G1 (p=0.001).", "labels": [], "entities": []}, {"text": "We evaluated several new features and report on the most significant here, as described in.", "labels": [], "entities": []}, {"text": "The results are reported in table 4.", "labels": [], "entities": []}, {"text": "The accuracy improvements relative to the results from experiment 2 are all statistically significant at p=0.001 (McNemar's testis used for all significance tests in this section).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.9992727637290955}]}, {"text": "Comparing the SVM results in experiment 2 to the best results here shows statistical significance 2 Due to space, we cannot report all experiments; contact the first author for more information.", "labels": [], "entities": []}, {"text": "The other features we evaluated involved: the phrase type of the parent constituent, the list of phrase types encompassing the sentence fragment between the target predicate and constituent, the prefix and suffix of the cw and hw, animacy, high frequency words preceding and following the predicate, and the morphological form of the predicate.", "labels": [], "entities": []}, {"text": "All of these improved accuracy on the development set (some with statistical significance at p=0.01), but we suspect the development baseline was at a low point, since these features largely did not improve performance when combined with CW Base and GP.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 22, "end_pos": 30, "type": "METRIC", "confidence": 0.9993888139724731}, {"text": "GP", "start_pos": 250, "end_pos": 252, "type": "METRIC", "confidence": 0.9540917277336121}]}, {"text": "In analyzing the effect on individual argument classes, seven have high \u03c7 2 values (AR G2-4, AR GM-DI S (discourse), AR GM-LO C (locative), AR GM-MN R (manner), and AR GM-TM P (temporal)), but given the large number of degrees of freedom, only AR GM-TM P is significant (p=0.05).", "labels": [], "entities": []}, {"text": "Example section-00 sentence fragments including the target predicate (P) and AR G2 role whose classification was corrected by the GP feature include \"[ P banned] to [everyday visitors]\", \"[ P considered] as [an additional risk for the investor]\", and \"[ P made] of [gallium arsenide]\".", "labels": [], "entities": []}, {"text": "Comparing the SVM results to the best results here, the Random Forest performs significantly better on Arg0 (p=0.001), and the SVM is significantly better on Arg1 (p=0.001).", "labels": [], "entities": [{"text": "Arg0", "start_pos": 103, "end_pos": 107, "type": "METRIC", "confidence": 0.6214570999145508}, {"text": "Arg1", "start_pos": 158, "end_pos": 162, "type": "DATASET", "confidence": 0.7442398071289062}]}, {"text": "Again the degrees of freedom prevent significance at p=0.1, but the Random Forest outperforms the SVM with a fairly high \u03c7 2 value on AR G4, AR GM-DI S, AR GM-LO C, and AR GM-TM P.", "labels": [], "entities": [{"text": "AR G4", "start_pos": 134, "end_pos": 139, "type": "DATASET", "confidence": 0.9545257091522217}, {"text": "AR GM-LO C", "start_pos": 153, "end_pos": 163, "type": "DATASET", "confidence": 0.8790532350540161}, {"text": "AR GM-TM P", "start_pos": 169, "end_pos": 179, "type": "DATASET", "confidence": 0.9149744113286337}]}, {"text": "We originally assumed we would be using binaryvalued features with sparse matrices, much like in the SVM approach.", "labels": [], "entities": []}, {"text": "Since many of the features have a very large number of values (e.g., the PA T H feature has over 540k values), we sought ways to reduce the number of equivalent binary-valued features.", "labels": [], "entities": []}, {"text": "This section reports on one of these methods, which should be of interest to others in resource constrained environments.", "labels": [], "entities": []}, {"text": "In this experiment, we preprocess the baseline inputs described in to reduce their number of category values.", "labels": [], "entities": []}, {"text": "Specifically, for each original category value, vi \u2208 V , we determine whether it occurs in observations associated with one or more than one semantic role label, R. If it is associated with more than one R, vi is left as is.", "labels": [], "entities": []}, {"text": "When vi maps to only a single R j , we replace vi with an arbitrary value, v k / \u2208 V , which is the same for all such v occurring strictly in association with R j . The PA T H input starts with 540732 original feature values and has only 1904 values after this process, while HE AD WO RD is reduced from 33977 values to 13208 and PH R A SE TY PE is reduced from 62 to 44 values.", "labels": [], "entities": [{"text": "HE AD WO RD", "start_pos": 276, "end_pos": 287, "type": "METRIC", "confidence": 0.8465579897165298}, {"text": "PH R A SE TY PE", "start_pos": 330, "end_pos": 345, "type": "METRIC", "confidence": 0.9281334777673086}]}, {"text": "The process has no effect on the other baseline input features.", "labels": [], "entities": []}, {"text": "The total reduction in equivalent binaryvalued features is 97%.", "labels": [], "entities": []}, {"text": "We also test the effect of disregarding feature values during training if they only occur once in the training data.", "labels": [], "entities": []}, {"text": "This has a more modest effect, reducing PA T H to 156788 values and HE AD WO RD to 29482 values, with no other reductions.", "labels": [], "entities": [{"text": "PA T H", "start_pos": 40, "end_pos": 46, "type": "METRIC", "confidence": 0.8521248896916708}, {"text": "HE AD WO RD", "start_pos": 68, "end_pos": 79, "type": "METRIC", "confidence": 0.889913022518158}]}, {"text": "The total reduction in equivalent binaryvalued features is 67%.", "labels": [], "entities": []}, {"text": "Training on the baseline feature set, the net effect of these two procedures was less than a 0.3% loss of accuracy on the development set.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 106, "end_pos": 114, "type": "METRIC", "confidence": 0.9993122816085815}]}, {"text": "The McNemar test indicates this is not significant at p=0.1.", "labels": [], "entities": []}, {"text": "In the end, our implementation used categorical features, rather than binary-valued features (e.g., rather than use 577710 binary-valued features to represent the baseline inputs, we use 7 features which might take on a large number of values -PA T H has 540732 values).", "labels": [], "entities": [{"text": "PA T H", "start_pos": 244, "end_pos": 250, "type": "DATASET", "confidence": 0.8405467867851257}]}, {"text": "In this case, the method does not result in as significant a reduction in the memory requirements.", "labels": [], "entities": []}, {"text": "While we did not use this feature reduction in any of the experiments reported previously, we see it as being very beneficial to others whose implementation maybe more resource constrained, particularly those using a binary-valued feature representation.", "labels": [], "entities": []}, {"text": "The method also reduced training time by 17% and should lead to much larger reductions for implementations using binary-valued features.", "labels": [], "entities": []}, {"text": "For example, the worst case training time for SVMs is quadratic in the number of features and this method reduced the dimensionality to 3% of its original size.", "labels": [], "entities": []}, {"text": "Therefore, the method has the theoretical potential to reduce training time by up to 100(1-0.03 2 ) = 99.91%.", "labels": [], "entities": [{"text": "training time", "start_pos": 62, "end_pos": 75, "type": "METRIC", "confidence": 0.741312563419342}]}, {"text": "While it is unlikely to approach this in practice, it should provide significant savings.", "labels": [], "entities": []}, {"text": "This maybe especially helpful during model selection or feature evaluation, after which, one could revert to the full dimensionality for final training to improve classification accuracy.", "labels": [], "entities": [{"text": "model selection", "start_pos": 37, "end_pos": 52, "type": "TASK", "confidence": 0.7816289067268372}, {"text": "feature evaluation", "start_pos": 56, "end_pos": 74, "type": "TASK", "confidence": 0.6106115877628326}, {"text": "classification", "start_pos": 163, "end_pos": 177, "type": "TASK", "confidence": 0.9427273869514465}, {"text": "accuracy", "start_pos": 178, "end_pos": 186, "type": "METRIC", "confidence": 0.8201792240142822}]}, {"text": "The slight decrement inaccuracy may also be overcome by the ability to handle larger datasets.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Number of sentences, words, marked pred- icates, and labeled arguments in thousands", "labels": [], "entities": []}, {"text": " Table 2: Results of baseline feature set experiment", "labels": [], "entities": []}, {"text": " Table 3: Results of experiment 2", "labels": [], "entities": []}, {"text": " Table 4: Results of experiment 2", "labels": [], "entities": []}]}