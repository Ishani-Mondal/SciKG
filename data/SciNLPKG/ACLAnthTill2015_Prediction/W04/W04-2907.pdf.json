{"title": [{"text": "General Indexation of Weighted Automata - Application to Spoken Utterance Retrieval", "labels": [], "entities": [{"text": "Spoken Utterance Retrieval", "start_pos": 57, "end_pos": 83, "type": "TASK", "confidence": 0.8021331230799357}]}], "abstractContent": [{"text": "Much of the massive quantities of digitized data widely available, e.g., text, speech, handwritten sequences, are either given directly, or, as a result of some prior processing, as weighted automata.", "labels": [], "entities": []}, {"text": "These are compact representations of a large number of alternative sequences and their weights reflecting the uncertainty or variability of the data.", "labels": [], "entities": []}, {"text": "Thus, the indexation of such data requires indexing weighted automata.", "labels": [], "entities": []}, {"text": "We present a general algorithm for the index-ation of weighted automata.", "labels": [], "entities": []}, {"text": "The resulting index is represented by a deterministic weighted transducer that is optimal for search: the search for an input string takes time linear in the sum of the size of that string and the number of indices of the weighted automata where it appears.", "labels": [], "entities": []}, {"text": "We also introduce a general framework based on weighted transducers that generalizes this indexation to enable the search for more complex patterns including syntactic information or for different types of sequences, e.g., word sequences instead of phonemic sequences.", "labels": [], "entities": []}, {"text": "The use of this framework is illustrated with several examples.", "labels": [], "entities": []}, {"text": "We applied our general indexation algorithm and framework to the problem of indexation of speech utterances and report the results of our experiments in several tasks demonstrating that our techniques yield comparable results to previous methods, while providing greater generality , including the possibility of searching for arbitrary patterns represented by weighted au-tomata.", "labels": [], "entities": [{"text": "indexation of speech utterances", "start_pos": 76, "end_pos": 107, "type": "TASK", "confidence": 0.740218997001648}]}, {"text": "1 Motivation Much of the massive quantities of digitized data widely available is highly variable or uncertain.", "labels": [], "entities": []}, {"text": "This uncertainty affects the interpretation of the data and its computational processing at various levels, e.g., natural language texts are abundantly ambiguous, speech and handwritten sequences are highly variable and hard to recognize in presence of noise, biological sequences maybe altered or incomplete.", "labels": [], "entities": []}, {"text": "Searching or indexing such data requires dealing with a large number of ranked or weighted alternatives.", "labels": [], "entities": []}, {"text": "These maybe for example the different parses of an input text, the various responses to a search engine or information extraction query, or the best hypotheses of a speech or handwritten recognition system.", "labels": [], "entities": [{"text": "information extraction query", "start_pos": 107, "end_pos": 135, "type": "TASK", "confidence": 0.7304006814956665}]}, {"text": "In most cases, alternative sequences can be compactly represented by weighted automata.", "labels": [], "entities": []}, {"text": "The weights maybe probabilities or some other weights used to rank different hypotheses.", "labels": [], "entities": []}, {"text": "This motivates our study of the general problem of indexation of weighted automata.", "labels": [], "entities": []}, {"text": "This is more general than the classical indexation problems since, typically, there are many distinct hypotheses or alternatives associated with the same index, e.g., a specific input speech or handwritten sequence may have a large number of different transcriptions according to the system and models used.", "labels": [], "entities": []}, {"text": "Moreover, the problem requires taking into consideration the weight of each alternative, which does not have a counterpart in classical indexation problems.", "labels": [], "entities": []}, {"text": "We describe a general indexation algorithm for weighted automata.", "labels": [], "entities": []}, {"text": "The resulting index is represented by a deterministic weighted transducer that is optimal for search: the search for an input string takes time linear in the sum of the size of that string and the number of indices of the weighted automata where it appears.", "labels": [], "entities": []}, {"text": "In some cases, one may wish to search using sequences in some level, e.g. word sequences, different from the level of the sequences of the index, e.g. phonemic sequences.", "labels": [], "entities": []}, {"text": "One may also wish to search for complex sequences including both words and parts-of-speech, or re", "labels": [], "entities": []}], "introductionContent": [], "datasetContent": [{"text": "Our task is retrieving the utterances (or short audio segments) that a given query appears in.", "labels": [], "entities": [{"text": "retrieving the utterances (or short audio segments)", "start_pos": 12, "end_pos": 63, "type": "TASK", "confidence": 0.580058044857449}]}, {"text": "The experimental setup is identical to that of.", "labels": [], "entities": []}, {"text": "Since, we take the system described there as our baseline, we give a brief review of the basic indexation algorithm used there.", "labels": [], "entities": []}, {"text": "The algorithm uses the same preprocessing step.", "labels": [], "entities": []}, {"text": "For each label in \u03a3, an index file is constructed.", "labels": [], "entities": []}, {"text": "For each arc a that appears in the preprocessed weighted automaton Bi , the following information is stored:).", "labels": [], "entities": []}, {"text": "Since the preprocessing ensures that f [q] = 0 for all q in Bi , it is possible to compute \u2212 log(E Pi [C x ]) as in Equation 4 using the information stored in the index.", "labels": [], "entities": []}, {"text": "For evaluating retrieval performance we use precision and recall with respect to manual transcriptions.", "labels": [], "entities": [{"text": "precision", "start_pos": 44, "end_pos": 53, "type": "METRIC", "confidence": 0.9995884299278259}, {"text": "recall", "start_pos": 58, "end_pos": 64, "type": "METRIC", "confidence": 0.9992480874061584}]}, {"text": "Let Correct(q) be the number of times the query q is found correctly, Answer(q) be the number of answers to the query q, and Reference(q) be the number of times q is found in the reference.", "labels": [], "entities": [{"text": "Correct(q)", "start_pos": 4, "end_pos": 14, "type": "METRIC", "confidence": 0.934136226773262}, {"text": "Answer(q)", "start_pos": 70, "end_pos": 79, "type": "METRIC", "confidence": 0.9490625262260437}, {"text": "Reference(q)", "start_pos": 125, "end_pos": 137, "type": "METRIC", "confidence": 0.9285311102867126}]}, {"text": "We compute precision and recall rates for each query and report the average overall queries.", "labels": [], "entities": [{"text": "precision", "start_pos": 11, "end_pos": 20, "type": "METRIC", "confidence": 0.9992989301681519}, {"text": "recall", "start_pos": 25, "end_pos": 31, "type": "METRIC", "confidence": 0.9979196190834045}]}, {"text": "The set of queries Q includes all the words seen in the reference except fora stoplist of 100 most common words.", "labels": [], "entities": []}, {"text": "For lattice based retrieval methods, different operating points can be obtained by changing the threshold.", "labels": [], "entities": []}, {"text": "The precision and recall at these operating points can be plotted as a curve.", "labels": [], "entities": [{"text": "precision", "start_pos": 4, "end_pos": 13, "type": "METRIC", "confidence": 0.9995478987693787}, {"text": "recall", "start_pos": 18, "end_pos": 24, "type": "METRIC", "confidence": 0.9994230270385742}]}, {"text": "In addition to individual precision-recall values we also compute the F-measure defined as and report the maximum F-measure (maxF) to summarize the information in a precision-recall curve.", "labels": [], "entities": [{"text": "precision-recall", "start_pos": 26, "end_pos": 42, "type": "METRIC", "confidence": 0.9806473255157471}, {"text": "F-measure", "start_pos": 70, "end_pos": 79, "type": "METRIC", "confidence": 0.9924236536026001}, {"text": "F-measure (maxF)", "start_pos": 114, "end_pos": 130, "type": "METRIC", "confidence": 0.9518970996141434}]}], "tableCaptions": [{"text": " Table 1: Comparison of Index Sizes in MegaBytes.", "labels": [], "entities": []}]}