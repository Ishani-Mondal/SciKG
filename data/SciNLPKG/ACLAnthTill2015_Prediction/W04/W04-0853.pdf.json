{"title": [], "abstractContent": [{"text": "The task of word sense disambiguation is to assign a sense label to a word in a passage.", "labels": [], "entities": [{"text": "word sense disambiguation", "start_pos": 12, "end_pos": 37, "type": "TASK", "confidence": 0.7150551676750183}]}, {"text": "We report our algorithms and experiments for the two tasks that we participated in viz.", "labels": [], "entities": []}, {"text": "the task of WSD of Word-Net glosses and the task of WSD of English lexical sample.", "labels": [], "entities": [{"text": "WSD", "start_pos": 52, "end_pos": 55, "type": "METRIC", "confidence": 0.6183664798736572}]}, {"text": "For both the tasks, we explore a method of sense disambiguation through a process of \"compar-ing\" the current context fora word against a repository of contextual clues or glosses for each sense of each word.", "labels": [], "entities": [{"text": "sense disambiguation", "start_pos": 43, "end_pos": 63, "type": "TASK", "confidence": 0.7450029253959656}]}, {"text": "We compile these glosses in two different ways for the two tasks.", "labels": [], "entities": []}, {"text": "For the first task, these glosses are all compiled using WordNet and are of various types viz.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 57, "end_pos": 64, "type": "DATASET", "confidence": 0.9728114008903503}]}, {"text": "hypernymy glosses, holonymy mixture, descriptive glosses and some hybrid mixtures of these glosses.", "labels": [], "entities": []}, {"text": "The \"comparison\" could be done in a variety of ways that could include/exclude stemming, expansion of one gloss type with another gloss type, etc.", "labels": [], "entities": []}, {"text": "The results show that the system does best when stemming is used and glosses are expanded.", "labels": [], "entities": []}, {"text": "However, it appears that the evidence for word-senses ,accumulated through WordNet, in the form of glosses, are quite sparse.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 75, "end_pos": 82, "type": "DATASET", "confidence": 0.9680249691009521}]}, {"text": "Generating dense glosses for all WordNet senses requires a massive sense tagged corpus-which is currently unavailable.", "labels": [], "entities": []}, {"text": "Hence, as part of the English lexical sample task, we try the same approach on densely populated glosses accumulated from the training data for this task.", "labels": [], "entities": []}], "introductionContent": [{"text": "The main idea behind our approach for both the WSD tasks is to use the context of a word along with the gloss or description of each of its senses to find its correct sense.", "labels": [], "entities": [{"text": "WSD tasks", "start_pos": 47, "end_pos": 56, "type": "TASK", "confidence": 0.9191873073577881}]}, {"text": "The similarity between the context and each sense of the word is measured and the word-sense with the highest similarity measure is picked as most appropriate, that with second highest similarity is ranked second and soon.", "labels": [], "entities": []}, {"text": "Glosses have been used by authors in the past for WSD.", "labels": [], "entities": [{"text": "Glosses", "start_pos": 0, "end_pos": 7, "type": "METRIC", "confidence": 0.9780724048614502}, {"text": "WSD", "start_pos": 50, "end_pos": 53, "type": "TASK", "confidence": 0.9793784022331238}]}, {"text": "The novelty in our approach, for the task of disambiguation of extended WordNet is in the way we generate our descriptions or glosses.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 72, "end_pos": 79, "type": "DATASET", "confidence": 0.7958711981773376}]}, {"text": "Also, an additional novelty in the second task, is in our use of textual proximity between words in the neighborhood of the word to be disambiguated and the words in the glosses of each of its senses.", "labels": [], "entities": []}], "datasetContent": [{"text": "The algorithms were evaluated against Semcor and was also used in Senseval-3 competition.", "labels": [], "entities": []}, {"text": "We present results in this section.", "labels": [], "entities": []}, {"text": "For this task, the gloss fora word-sense is generated by concatenating the contexts of all training instances for that word-sense.", "labels": [], "entities": []}, {"text": "An inverted index is generated for the glosses.", "labels": [], "entities": []}, {"text": "The context fora test instance is fired as a query and the senses for the word are ranked using the tf-igf based cosine similarity metric described in section 3.1.", "labels": [], "entities": []}, {"text": "The top sense is picked.", "labels": [], "entities": []}, {"text": "The baseline precision obtained for this task was 53.5% The precision obtained using fine-grained scoring was 66.1% and the recall was 65.7%.", "labels": [], "entities": [{"text": "precision", "start_pos": 13, "end_pos": 22, "type": "METRIC", "confidence": 0.9171519875526428}, {"text": "precision", "start_pos": 60, "end_pos": 69, "type": "METRIC", "confidence": 0.9991625547409058}, {"text": "recall", "start_pos": 124, "end_pos": 130, "type": "METRIC", "confidence": 0.9996832609176636}]}, {"text": "The precision obtained using coarse-grained scoring was 74.3% and the recall was 73.9%.: Report of Senseval-3 Extended WordNet task with modified parameters", "labels": [], "entities": [{"text": "precision", "start_pos": 4, "end_pos": 13, "type": "METRIC", "confidence": 0.9993873834609985}, {"text": "recall", "start_pos": 70, "end_pos": 76, "type": "METRIC", "confidence": 0.9996589422225952}]}], "tableCaptions": [{"text": " Table 1: List of acronyms used", "labels": [], "entities": []}, {"text": " Table 2: Results for Hypernymy glosses", "labels": [], "entities": []}, {"text": " Table 3: Results for Hyper-Desc(\u00a9 ) glosses", "labels": [], "entities": []}, {"text": " Table 4: Results for Hyper-Desc(\u00a8 ) glosses", "labels": [], "entities": []}, {"text": " Table 5: Results for Holo-Desc(\u00a8 ) glosses", "labels": [], "entities": []}, {"text": " Table 7: Report of Senseval-3 Extended WordNet  task with modified parameters", "labels": [], "entities": []}]}