{"title": [{"text": "Automatic Paragraph Identification: A Study across Languages and Domains", "labels": [], "entities": [{"text": "Automatic Paragraph Identification", "start_pos": 0, "end_pos": 34, "type": "TASK", "confidence": 0.7031425833702087}]}], "abstractContent": [{"text": "In this paper we investigate whether paragraphs can be identified automatically in different languages and domains.", "labels": [], "entities": []}, {"text": "We propose a machine learning approach which exploits textual and discourse cues and we assess how well humans perform on this task.", "labels": [], "entities": []}, {"text": "Our best models achieve an accuracy that is significantly higher than the best baseline and, for most data sets, comes to within 6% of human performance .", "labels": [], "entities": [{"text": "accuracy", "start_pos": 27, "end_pos": 35, "type": "METRIC", "confidence": 0.9996254444122314}]}], "introductionContent": [{"text": "Written texts are usually broken up into sentences and paragraphs.", "labels": [], "entities": []}, {"text": "Sentence splitting is a necessary pre-processing step fora number of Natural Language Processing (NLP) tasks including part-ofspeech tagging and parsing.", "labels": [], "entities": [{"text": "Sentence splitting", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.941514402627945}, {"text": "part-ofspeech tagging", "start_pos": 119, "end_pos": 140, "type": "TASK", "confidence": 0.6338370144367218}]}, {"text": "Since sentence-final punctuation can be ambiguous (e.g., a period can also be used in an abbreviation as well as to mark the end of a sentence), the task is not trivial and has consequently attracted a lot of attention (e.g.,).", "labels": [], "entities": []}, {"text": "In contrast, there has been virtually no previous research on inferring paragraph boundaries automatically.", "labels": [], "entities": []}, {"text": "One reason for this is that paragraph boundaries are usually marked unambiguously by anew line and extra white space.", "labels": [], "entities": []}, {"text": "However, a number of applications could benefit from a paragraph detection mechanism.", "labels": [], "entities": [{"text": "paragraph detection", "start_pos": 55, "end_pos": 74, "type": "TASK", "confidence": 0.9417242407798767}]}, {"text": "Textto-text generation applications such as single-and multidocument summarisation as well as text simplification usually take naturally occurring texts as input and transform them into new texts satisfying specific constraints (e.g., length, style, language).", "labels": [], "entities": [{"text": "Textto-text generation", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.7900241315364838}, {"text": "single-and multidocument summarisation", "start_pos": 44, "end_pos": 82, "type": "TASK", "confidence": 0.5885351101557413}, {"text": "text simplification", "start_pos": 94, "end_pos": 113, "type": "TASK", "confidence": 0.7530973255634308}]}, {"text": "The output texts do not always preserve the structure and editing conventions of the original text.", "labels": [], "entities": []}, {"text": "In summarisation, for example, sentences are typically extracted verbatim and concatenated to form a summary.", "labels": [], "entities": [{"text": "summarisation", "start_pos": 3, "end_pos": 16, "type": "TASK", "confidence": 0.9673963189125061}]}, {"text": "Insertion of paragraph breaks could improve the readability of the summaries by indicating topic shifts and providing visual targets to the reader.", "labels": [], "entities": []}, {"text": "Machine translation is another application for which automatic paragraph detection is relevant.", "labels": [], "entities": [{"text": "Machine translation", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.8424174189567566}, {"text": "paragraph detection", "start_pos": 63, "end_pos": 82, "type": "TASK", "confidence": 0.9052865207195282}]}, {"text": "Current systems deal with paragraph boundary insertion in the target language simply by preserving the boundaries from the source language.", "labels": [], "entities": [{"text": "paragraph boundary insertion", "start_pos": 26, "end_pos": 54, "type": "TASK", "confidence": 0.7114764849344889}]}, {"text": "However, there is evidence for cross-linguistic variation in paragraph formation and placement, particularly for languages that are not closely related such as English and Chinese).", "labels": [], "entities": [{"text": "paragraph formation and placement", "start_pos": 61, "end_pos": 94, "type": "TASK", "confidence": 0.8120853006839752}]}, {"text": "So, a paragraph insertion mechanism that is specific to the target language, instead of one that relies solely on the source language, may yield more readable texts.", "labels": [], "entities": [{"text": "paragraph insertion", "start_pos": 6, "end_pos": 25, "type": "TASK", "confidence": 0.8350354433059692}]}, {"text": "Paragraph boundary detection is also relevant for speech-to-text applications.", "labels": [], "entities": [{"text": "Paragraph boundary detection", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.9224220712979635}]}, {"text": "The output of automatic speech recognition systems is usually raw text without any punctuation or paragraph breaks.", "labels": [], "entities": [{"text": "automatic speech recognition", "start_pos": 14, "end_pos": 42, "type": "TASK", "confidence": 0.6662931640942892}]}, {"text": "This naturally makes the text very hard to read, which can cause processing difficulties, especially if speech recognition is used to provide deaf students with real-time transcripts of lectures.", "labels": [], "entities": []}, {"text": "Furthermore, sometimes the output of a speech recogniser needs to be processed automatically by applications such as information extraction or summarisation.", "labels": [], "entities": [{"text": "speech recogniser", "start_pos": 39, "end_pos": 56, "type": "TASK", "confidence": 0.6938325762748718}, {"text": "information extraction", "start_pos": 117, "end_pos": 139, "type": "TASK", "confidence": 0.8692462742328644}, {"text": "summarisation", "start_pos": 143, "end_pos": 156, "type": "TASK", "confidence": 0.9205268025398254}]}, {"text": "Most of these applications (e.g.,) port techniques developed for written texts to spoken texts and therefore require input that is punctuated and broken into paragraphs.", "labels": [], "entities": []}, {"text": "While there has been some research on finding sentence boundaries in spoken text), there has been little research on determining paragraph boundaries.", "labels": [], "entities": []}, {"text": "If paragraph boundaries were mainly an aesthetic device for visually breaking up long texts into smaller chunks, as has previously been suggested (see), paragraph boundaries could be easily inserted by splitting a text into several equal-size segments.", "labels": [], "entities": []}, {"text": "Psycho-linguistic research, however, indicates that paragraph boundaries are not purely aesthetic.", "labels": [], "entities": []}, {"text": "For example, asked her subjects to reinstate paragraph boundaries into fiction texts from which all boundaries had been removed and found that humans are able to do so with an accuracy that is higher than would be expected by chance.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 176, "end_pos": 184, "type": "METRIC", "confidence": 0.9985873699188232}]}, {"text": "Crucially, she also found that (a) individual subjects did not make all their paragraphs the same length and (b) paragraphs in the original text whose length deviated significantly from the average paragraph length were still identified correctly by a large proportion of subjects.", "labels": [], "entities": []}, {"text": "These results show that people are often able to identify paragraphs correctly even if they are exceptionally short or long without defaulting to a simple template of average paragraph length.", "labels": [], "entities": []}, {"text": "Human agreement on the task suggests that the text itself provides cues for paragraph insertion, even though there is some disagreement over which specific cues are used by humans (see).", "labels": [], "entities": [{"text": "paragraph insertion", "start_pos": 76, "end_pos": 95, "type": "TASK", "confidence": 0.884274035692215}]}, {"text": "Possible cues include repeated content words, pronoun coreference, paragraph length, and local semantic connectedness.", "labels": [], "entities": [{"text": "pronoun coreference", "start_pos": 46, "end_pos": 65, "type": "TASK", "confidence": 0.6844736635684967}]}, {"text": "In this paper, we investigate whether it is possible to exploit some of these textual cues together with syntactic and discourse related information to determine paragraph boundaries automatically.", "labels": [], "entities": []}, {"text": "We treat paragraph boundary identification as a classification task and examine whether the difficulty of the task and the utility of individual textual cues varies across languages and across domains.", "labels": [], "entities": [{"text": "paragraph boundary identification", "start_pos": 9, "end_pos": 42, "type": "TASK", "confidence": 0.838869571685791}]}, {"text": "We also assess human performance on the same task and whether it differs across domains.", "labels": [], "entities": []}], "datasetContent": [{"text": "BoosTexter is parametrised with respect to the number of training iterations.", "labels": [], "entities": [{"text": "BoosTexter", "start_pos": 0, "end_pos": 10, "type": "DATASET", "confidence": 0.8415449857711792}]}, {"text": "In all our experiments, this parameter was optimised on the development set; BoosTexter was initially trained for 500 iterations, and then re-trained with the number of iterations that led to the lowest error rate on the development set.", "labels": [], "entities": []}, {"text": "Throughout this paper all results are reported on the unseen test set and were obtained using models optimised on the development set.", "labels": [], "entities": []}, {"text": "We report the models' accuracy at predicting the right label (i.e., paragraph starting or not) for each sentence.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 22, "end_pos": 30, "type": "METRIC", "confidence": 0.9993539452552795}]}, {"text": "We established an upper bound against which our automatic methods could be compared by conducting an experiment that assessed how well humans agree on identifying paragraph boundaries.", "labels": [], "entities": []}, {"text": "Five participants were given three English texts (one from each domain), selected randomly from the test corpus.", "labels": [], "entities": []}, {"text": "Each text consisted of approximately a tenth of the original test set (i.e., 200-400 sentences).", "labels": [], "entities": []}, {"text": "The participants were asked to insert paragraph breaks wherever it seemed appropriate to them.", "labels": [], "entities": []}, {"text": "No other instructions were given, as we wanted to see whether they could independently perform the task without any specific knowledge regarding the domains and their paragraphing conventions.", "labels": [], "entities": []}, {"text": "We measured the agreement of the judges using the Kappa coefficient but also report percentage agreement to facilitate comparison with our models.", "labels": [], "entities": [{"text": "agreement", "start_pos": 16, "end_pos": 25, "type": "METRIC", "confidence": 0.9862058758735657}]}, {"text": "In all cases, we compute pairwise agreements and report the mean.", "labels": [], "entities": []}, {"text": "Our results are shown in.", "labels": [], "entities": []}, {"text": "As can be seen, participants tend to agree with each other on the task.", "labels": [], "entities": []}, {"text": "The least agreement is observed for the news domain.", "labels": [], "entities": [{"text": "agreement", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.964346170425415}]}, {"text": "This is somewhat expected as the Wall Street Journal texts are rather difficult to process for non-experts.", "labels": [], "entities": [{"text": "Wall Street Journal texts", "start_pos": 33, "end_pos": 58, "type": "DATASET", "confidence": 0.9732091426849365}]}, {"text": "Also remember, that our subjects were given no instructions or training.", "labels": [], "entities": []}, {"text": "In all cases our models yield an accuracy lower than the human agreement.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 33, "end_pos": 41, "type": "METRIC", "confidence": 0.999535322189331}]}, {"text": "For the fiction domain the best model is 5.67% lower than the upper bound, for the news domain it is 5.62% and for the parliament domain it is 5.42% (see).", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Accuracy of non-syntactic and language modelling features on test set", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9951651096343994}]}, {"text": " Table 3: Syntactic features on English test data", "labels": [], "entities": [{"text": "English test data", "start_pos": 32, "end_pos": 49, "type": "DATASET", "confidence": 0.774538258711497}]}]}