{"title": [{"text": "Word Sense Disambiguation based on Term to Term Similarity in a Context Space", "labels": [], "entities": [{"text": "Word Sense Disambiguation", "start_pos": 0, "end_pos": 25, "type": "TASK", "confidence": 0.6080435911814371}]}], "abstractContent": [{"text": "This paper describes the exemplar based approach presented by UNED at Senseval-3.", "labels": [], "entities": [{"text": "UNED at Senseval-3", "start_pos": 62, "end_pos": 80, "type": "DATASET", "confidence": 0.7380388577779134}]}, {"text": "Instead of representing contexts as bags of terms and defining a similarity measure between contexts , we propose to represent terms as bags of contexts and define a similarity measure between terms.", "labels": [], "entities": []}, {"text": "Thus, words, lemmas and senses are represented in the same space (the context space), and similarity measures can be defined between them.", "labels": [], "entities": []}, {"text": "New contexts are transformed into this representation in order to calculate their similarity to the candidate senses.", "labels": [], "entities": []}, {"text": "We show how standard similarity measures obtain better results in this framework.", "labels": [], "entities": []}, {"text": "A new similarity measure in the context space is proposed for selecting the senses and performing disambigua-tion.", "labels": [], "entities": []}, {"text": "Results of this approach at Senseval-3 are here reported.", "labels": [], "entities": [{"text": "Senseval-3", "start_pos": 28, "end_pos": 38, "type": "DATASET", "confidence": 0.8749148845672607}]}], "introductionContent": [{"text": "Word Sense Disambiguation (WSD) is the task of deciding the appropriate sense fora particular use of a polysemous word, given its textual or discursive context.", "labels": [], "entities": [{"text": "Word Sense Disambiguation (WSD)", "start_pos": 0, "end_pos": 31, "type": "TASK", "confidence": 0.783660406867663}]}, {"text": "A previous nontrivial step is to determine the inventory of meanings potentially attributable to that word.", "labels": [], "entities": []}, {"text": "For this reason, WSD in Senseval is reformulated as a classification problem where a dictionary becomes the class inventory.", "labels": [], "entities": [{"text": "WSD", "start_pos": 17, "end_pos": 20, "type": "TASK", "confidence": 0.9377651214599609}]}, {"text": "The disambiguation process, then, consists in assigning one or more of these classes to the ambiguous word in the given context.", "labels": [], "entities": []}, {"text": "The Senseval evaluation forum provides a controlled framework where different WSD systems can be tested and compared.", "labels": [], "entities": [{"text": "WSD", "start_pos": 78, "end_pos": 81, "type": "TASK", "confidence": 0.9356653094291687}]}, {"text": "Corpus-based methods have offered encouraging results in the last years.", "labels": [], "entities": []}, {"text": "This kind of methods profits from statistics on a training corpus, and Machine Learning (ML) algorithms to produce a classifier.", "labels": [], "entities": []}, {"text": "Learning algorithms can be divided in two main categories: Supervised (where the correct answer for each piece of training is provided) and Unsupervised (where the training data is given without any answer indication).", "labels": [], "entities": []}, {"text": "Tests at Senseval-3 are made in various languages for which two main tasks are proposed: an all-words task and a lexical sample task.", "labels": [], "entities": []}, {"text": "Participants have available a training corpus, a set of test examples and a sense inventory in each language.", "labels": [], "entities": []}, {"text": "The training corpora are available in a labelled and a unlabelled format; the former is mainly for supervised systems and the latter mainly for the unsupervised ones.", "labels": [], "entities": []}, {"text": "Several supervised ML algorithms have been applied to WSD,): Decision Lists, Neural Networks, Bayesian classifiers, Boosting, Exemplarbased learning, etc.", "labels": [], "entities": [{"text": "WSD", "start_pos": 54, "end_pos": 57, "type": "TASK", "confidence": 0.9199829697608948}]}, {"text": "We report here the exemplar-based approach developed by UNED and tested at the Senseval-3 competition in the lexical sample tasks for English, Spanish, Catalan and Italian.", "labels": [], "entities": []}, {"text": "After this brief introduction, Sections 2 and 3 are devoted, respectively, to the training data and the processing performed over these data.", "labels": [], "entities": []}, {"text": "Section 4 characterizes the UNED WSD system.", "labels": [], "entities": [{"text": "UNED WSD system", "start_pos": 28, "end_pos": 43, "type": "DATASET", "confidence": 0.6740854581197103}]}, {"text": "First, we describe the general approach based on the representation of words, lemmas and senses in a Context Space.", "labels": [], "entities": []}, {"text": "Then, we show how results are improved by applying standard similarity measures as cosine in this Context Space.", "labels": [], "entities": []}, {"text": "Once the representation framework is established, we define the criteria underlying the final similarity measure used at Senseval-3, and we compare it with the previous similarity measures.", "labels": [], "entities": []}, {"text": "Section 5 reports the official results obtained at the Senseval-3 Lexical Sample tasks for English, Spanish, Italian and Catalan.", "labels": [], "entities": [{"text": "Senseval-3 Lexical Sample tasks", "start_pos": 55, "end_pos": 86, "type": "DATASET", "confidence": 0.856736958026886}]}, {"text": "Finally, we conclude and point out some future work.", "labels": [], "entities": []}, {"text": "surrounding context, where the average context window varies from language to language.", "labels": [], "entities": []}, {"text": "Each training example gives one or more semantic labels for the ambiguous word corresponding to the correct sense in that context.", "labels": [], "entities": []}, {"text": "Senseval-3 provided the training data and the test data in XML format.", "labels": [], "entities": [{"text": "Senseval-3", "start_pos": 0, "end_pos": 10, "type": "DATASET", "confidence": 0.8631142973899841}]}, {"text": "The XML tagging conventions provides an excellent ground for the corpora processing, allowing a simple way for the data browsing and transformation.", "labels": [], "entities": [{"text": "XML tagging", "start_pos": 4, "end_pos": 15, "type": "TASK", "confidence": 0.648856446146965}, {"text": "corpora processing", "start_pos": 65, "end_pos": 83, "type": "TASK", "confidence": 0.7346402108669281}]}, {"text": "However, some of the XML well-formedness constraints are not completely satisfied.", "labels": [], "entities": []}, {"text": "For example, there is no XML declaration and no root element in the English Lexical Sample documents.", "labels": [], "entities": [{"text": "English Lexical Sample documents", "start_pos": 68, "end_pos": 100, "type": "DATASET", "confidence": 0.8414007425308228}]}, {"text": "Once these shortcomings are fixed any XML parser can normally read and process the data.", "labels": [], "entities": []}, {"text": "Despite the similarity in the structure of the different corpora at the lexical sample task in different languages, we had found a heterogeneous vocabulary both in the XML tags and the attributes, forcing to develop 'ad hoc' parsers for each language.", "labels": [], "entities": []}, {"text": "We missed a common and public document type definition for all the tasks.", "labels": [], "entities": []}, {"text": "Sense codification is another field where different solutions had been taken.", "labels": [], "entities": []}, {"text": "In the English corpus nouns and adjectives are annotated using the WordNet 1.7.1.", "labels": [], "entities": [{"text": "WordNet 1.7.1", "start_pos": 67, "end_pos": 80, "type": "DATASET", "confidence": 0.9434901475906372}]}, {"text": "classification 1, while the verbs are based on Wordsmyth 2 (Scott, 1997).", "labels": [], "entities": [{"text": "Wordsmyth 2 (Scott, 1997)", "start_pos": 47, "end_pos": 72, "type": "DATASET", "confidence": 0.9240636655262539}]}, {"text": "In the Catalan and Spanish tasks the sense inventory gives a more coarse-grained classification than WordNet.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 101, "end_pos": 108, "type": "DATASET", "confidence": 0.9470081925392151}]}, {"text": "Both tasks have provided a dictionary with additional information as examples, typical collocations and the equivalent synsets at WordNet 1.5.", "labels": [], "entities": [{"text": "WordNet 1.5", "start_pos": 130, "end_pos": 141, "type": "DATASET", "confidence": 0.9082808494567871}]}, {"text": "Finally, the Italian sense inventory is based on the MultiWordnet dictionary).", "labels": [], "entities": [{"text": "MultiWordnet dictionary", "start_pos": 53, "end_pos": 76, "type": "DATASET", "confidence": 0.9145960807800293}]}, {"text": "Unlike the other mentioned languages , the Italian task doesn't provide a separate file with the dictionary.", "labels": [], "entities": []}, {"text": "Besides the training data provided by Senseval, we have used the SemCor () collection in which every word is already tagged in its part of speech, sense and synset of WordNet.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 167, "end_pos": 174, "type": "DATASET", "confidence": 0.9667701125144958}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Bag of words versus bag of contexts, precision-recall", "labels": [], "entities": [{"text": "Bag of words", "start_pos": 10, "end_pos": 22, "type": "TASK", "confidence": 0.8771747350692749}, {"text": "precision-recall", "start_pos": 47, "end_pos": 63, "type": "METRIC", "confidence": 0.9967155456542969}]}, {"text": " Table 2: Example of inconsistencies in human annotation", "labels": [], "entities": []}, {"text": " Table 3: Precision-recall for the new similarity measure", "labels": [], "entities": [{"text": "Precision-recall", "start_pos": 10, "end_pos": 26, "type": "METRIC", "confidence": 0.9799491763114929}]}, {"text": " Table 4: Incidence of Criterium 2, precision- recall", "labels": [], "entities": [{"text": "Incidence", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9182631969451904}, {"text": "precision- recall", "start_pos": 36, "end_pos": 53, "type": "METRIC", "confidence": 0.860025147596995}]}, {"text": " Table 5: Official results at Senseval-3, precision- recall", "labels": [], "entities": [{"text": "precision- recall", "start_pos": 42, "end_pos": 59, "type": "METRIC", "confidence": 0.876188337802887}]}]}