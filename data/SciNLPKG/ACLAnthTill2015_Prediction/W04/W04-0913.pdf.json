{"title": [{"text": "Text Understanding with GETARUNS for Q/A and Summarization", "labels": [], "entities": [{"text": "Text Understanding", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.7177748829126358}, {"text": "GETARUNS", "start_pos": 24, "end_pos": 32, "type": "METRIC", "confidence": 0.909906804561615}, {"text": "Summarization", "start_pos": 45, "end_pos": 58, "type": "TASK", "confidence": 0.9042820930480957}]}], "abstractContent": [{"text": "Summarization and Question Answering need precise linguistic information with a much higher coverage than what is being offered by currently available statistically based systems.", "labels": [], "entities": [{"text": "Summarization", "start_pos": 0, "end_pos": 13, "type": "TASK", "confidence": 0.9894819259643555}, {"text": "Question Answering", "start_pos": 18, "end_pos": 36, "type": "TASK", "confidence": 0.8389967381954193}, {"text": "coverage", "start_pos": 92, "end_pos": 100, "type": "METRIC", "confidence": 0.9812530875205994}]}, {"text": "We assume that the starting point of any interesting application in these fields must necessarily be a good syntactic-semantic parser.", "labels": [], "entities": []}, {"text": "In this paper we present the system for text understanding called GETARUNS, General Text and Reference Understanding System (Delmonte, 2003a).", "labels": [], "entities": [{"text": "text understanding", "start_pos": 40, "end_pos": 58, "type": "TASK", "confidence": 0.7889713644981384}, {"text": "GETARUNS", "start_pos": 66, "end_pos": 74, "type": "METRIC", "confidence": 0.8367646932601929}, {"text": "General Text and Reference Understanding System (Delmonte, 2003a)", "start_pos": 76, "end_pos": 141, "type": "DATASET", "confidence": 0.6381936154582284}]}, {"text": "The heart of the system is a rule-based top-down DCG-style parser, which uses an LFG oriented grammar organization.", "labels": [], "entities": []}, {"text": "The parser produces an f-structure as a DAG which is then used to create a Logical Form, the basis for all further semantic representation.", "labels": [], "entities": []}, {"text": "GETARUNS, has a highly sophisticated linguistically based semantic module which is used to buildup the Discourse Model.", "labels": [], "entities": [{"text": "GETARUNS", "start_pos": 0, "end_pos": 8, "type": "DATASET", "confidence": 0.8069236278533936}]}, {"text": "Semantic processing is strongly modularized and distributed amongst a number of different submodules which take care of Spatio-Temporal Reasoning, Discourse Level Anaphora Resolution.", "labels": [], "entities": [{"text": "Spatio-Temporal Reasoning", "start_pos": 120, "end_pos": 145, "type": "TASK", "confidence": 0.7054027616977692}, {"text": "Discourse Level Anaphora Resolution", "start_pos": 147, "end_pos": 182, "type": "TASK", "confidence": 0.5698733925819397}]}], "introductionContent": [{"text": "GETARUNS, the system for text understanding developed at the University of Venice, is equipped with three main modules: a lower module for parsing where sentence strategies are implemented; a middle module for semantic interpretation and discourse model construction which is cast into Situation Semantics; and a higher module where reasoning and generation takes place) . The system is based on LFG theoretical framework) and has a highly interconnected modular structure.", "labels": [], "entities": [{"text": "GETARUNS", "start_pos": 0, "end_pos": 8, "type": "DATASET", "confidence": 0.8702958226203918}, {"text": "text understanding", "start_pos": 25, "end_pos": 43, "type": "TASK", "confidence": 0.7981345057487488}, {"text": "semantic interpretation", "start_pos": 210, "end_pos": 233, "type": "TASK", "confidence": 0.7314830422401428}, {"text": "discourse model construction", "start_pos": 238, "end_pos": 266, "type": "TASK", "confidence": 0.6821350455284119}, {"text": "LFG theoretical framework", "start_pos": 396, "end_pos": 421, "type": "DATASET", "confidence": 0.9353180527687073}]}, {"text": "It is a top-down depth-first DCG-based parser written in Prolog which uses a strong deterministic policy by means of a lookahead mechanism with a WFST to help recovery when failure is unavoidable due to strong attachment ambiguity.", "labels": [], "entities": [{"text": "Prolog", "start_pos": 57, "end_pos": 63, "type": "DATASET", "confidence": 0.9633435606956482}, {"text": "WFST", "start_pos": 146, "end_pos": 150, "type": "DATASET", "confidence": 0.7337007522583008}]}, {"text": "It is divided up into a pipeline of sequential but independent modules which realize the subdivision of a parsing scheme as proposed in LFG theory where a c-structure is built before the f-structure can be projected by unification into a DAG.", "labels": [], "entities": []}, {"text": "In this sense we try to apply in a given sequence phrasestructure rules as they are ordered in the grammar: whenever a syntactic constituent is successfully built, it is checked for semantic consistency, both internally for head-spec agreement, and externally, in case of a non-substantial head like a preposition dominating the lower NP constituent.", "labels": [], "entities": []}, {"text": "Other important local semantic consistency checks are performed with modifiers like attributive and predicative adjuncts.", "labels": [], "entities": []}, {"text": "In case the governing predicate expects obligatory arguments to be lexically realized they will be searched and checked for uniqueness and coherence as LFG grammaticality principles require).", "labels": [], "entities": []}, {"text": "In other words, syntactic and semantic information is accessed and used as soon as possible: in particular, both categorial and subcategorization information attached to predicates in the lexicon is extracted as soon as the main predicate is processed, be it adjective, noun or verb, and is used to subsequently restrict the number of possible structures to be built.", "labels": [], "entities": []}, {"text": "Adjuncts are computed by semantic cross compatibility tests on the basis of selectional restrictions of main predicates and adjuncts heads.", "labels": [], "entities": []}, {"text": "As far as parsing is concerned, we purport the view that the implementation of sound parsing algorithm must go hand in hand with sound grammar construction.", "labels": [], "entities": [{"text": "parsing", "start_pos": 10, "end_pos": 17, "type": "TASK", "confidence": 0.9769411683082581}, {"text": "sound parsing algorithm", "start_pos": 79, "end_pos": 102, "type": "TASK", "confidence": 0.7914182543754578}, {"text": "sound grammar construction", "start_pos": 129, "end_pos": 155, "type": "TASK", "confidence": 0.652363121509552}]}, {"text": "Extragrammaticalities can be better coped with within a solid linguistic framework rather than without it.", "labels": [], "entities": []}, {"text": "Our parser is a rule-based deterministic parser in the sense that it uses a lookahead and a Well-Formed Substring Table to reduce backtracking.", "labels": [], "entities": []}, {"text": "It also implements Finite State Automata in the task of tag disambiguation, and produces multiwords whenever lexical information allows it.", "labels": [], "entities": [{"text": "tag disambiguation", "start_pos": 56, "end_pos": 74, "type": "TASK", "confidence": 0.7776099145412445}]}, {"text": "In our parser we use a number of parsing strategies and graceful recovery procedures which follow a strictly parameterized approach to their definition and implementation.", "labels": [], "entities": []}, {"text": "Recovery procedures are also used to cope with elliptical structures and uncommon orthographic and punctuation patterns.", "labels": [], "entities": []}, {"text": "A shallow or partial parser, in the sense of, is also implemented and always activated before the complete parse takes place, in order to produce the default baseline output to be used by further computation in case of total failure.", "labels": [], "entities": []}, {"text": "In that case partial semantic mapping will take place where no Logical Form is being built and only referring expressions are asserted in the Discourse Modelbut see below.", "labels": [], "entities": []}], "datasetContent": [{"text": "We downloaded the only freely available corpus annotated with anaphoric relations, i.e. Wolverhampton's Manual Corpus made available by Prof. Ruslan Mitkov on his website.", "labels": [], "entities": [{"text": "Wolverhampton's Manual Corpus", "start_pos": 88, "end_pos": 117, "type": "DATASET", "confidence": 0.9709788262844086}]}, {"text": "The corpus contains text from Manuals at the following address, http://clg.wlv.ac.uk/resources/corpus.html To compare our results with the SGML documents we created a Perl script that extracted all referring expressions and wrote the output into a separate file.", "labels": [], "entities": []}, {"text": "The new representation of the SGML files looked now like a list of records each one denoted by an index a dash and the text of the referring expression.", "labels": [], "entities": []}, {"text": "In case of complex referring expressions we had more than one index available and so we translated the complex referring expression into a couple or a triple of records each one denoted by its index.", "labels": [], "entities": []}, {"text": "The final results were 75% F-measure -complete results are published in.", "labels": [], "entities": [{"text": "F-measure -complete", "start_pos": 27, "end_pos": 46, "type": "METRIC", "confidence": 0.9541891018549601}]}], "tableCaptions": []}