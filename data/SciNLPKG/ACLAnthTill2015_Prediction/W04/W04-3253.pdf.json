{"title": [{"text": "Sentiment analysis using support vector machines with diverse information sources", "labels": [], "entities": [{"text": "Sentiment analysis", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.9758441746234894}]}], "abstractContent": [{"text": "This paper introduces an approach to sentiment analysis which uses support vector machines (SVMs) to bring together diverse sources of potentially pertinent information, including several fa-vorability measures for phrases and adjectives and, where available, knowledge of the topic of the text.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 37, "end_pos": 55, "type": "TASK", "confidence": 0.9646024405956268}]}, {"text": "Models using the features introduced are further combined with unigram models which have been shown to be effective in the past (Pang et al., 2002) and lemmatized versions of the unigram models.", "labels": [], "entities": []}, {"text": "Experiments on movie review data from Epinions.com demonstrate that hybrid SVMs which combine unigram-style feature-based SVMs with those based on real-valued favorability measures obtain superior performance, producing the best results yet published using this data.", "labels": [], "entities": [{"text": "movie review data from Epinions.com", "start_pos": 15, "end_pos": 50, "type": "DATASET", "confidence": 0.6714562892913818}]}, {"text": "Further experiments using a feature set enriched with topic information on a smaller dataset of music reviews hand-annotated for topic are also reported, the results of which suggest that incorporating topic information into such models may also yield improvement.", "labels": [], "entities": []}], "introductionContent": [{"text": "Recently an increasing amount of research has been devoted to investigating methods of recognizing favorable and unfavorable sentiments towards specific subjects within natural language texts.", "labels": [], "entities": [{"text": "recognizing favorable and unfavorable sentiments towards specific subjects within natural language texts", "start_pos": 87, "end_pos": 191, "type": "TASK", "confidence": 0.6375690251588821}]}, {"text": "Areas of application for such analysis are numerous and varied, ranging from newsgroup flame filtering and informative augmentation of search engine responses to analysis of public opinion trends and customer feedback.", "labels": [], "entities": [{"text": "newsgroup flame filtering", "start_pos": 77, "end_pos": 102, "type": "TASK", "confidence": 0.6323131322860718}]}, {"text": "For many of these tasks, classifying the tone of the communication as generally positive or negative is an important step.", "labels": [], "entities": []}, {"text": "There area number of challenging aspects of this task.", "labels": [], "entities": []}, {"text": "Opinions in natural language are very often expressed in subtle and complex ways, presenting challenges which may not be easily addressed by simple text categorization approaches such as n-gram or keyword identification approaches.", "labels": [], "entities": [{"text": "keyword identification", "start_pos": 197, "end_pos": 219, "type": "TASK", "confidence": 0.7100815922021866}]}, {"text": "Although such approaches have been employed effectively (), there appears to remain considerable room for improvement.", "labels": [], "entities": []}, {"text": "Moving beyond these approaches can involve addressing the task at several levels.", "labels": [], "entities": []}, {"text": "Recognizing the semantic impact of words or phrases is a challenging task in itself, but in many cases the overarching sentiment of a text is not the same as that of decontextualized snippets.", "labels": [], "entities": [{"text": "Recognizing the semantic impact of words or phrases", "start_pos": 0, "end_pos": 51, "type": "TASK", "confidence": 0.9110693112015724}]}, {"text": "Negative reviews may contain many apparently positive phrases even while maintaining a strongly negative tone, and the opposite is also common.", "labels": [], "entities": []}, {"text": "This paper introduces an approach to classifying texts as positive or negative using Support Vector Machines (SVMs), a well-known and powerful tool for classification of vectors of real-valued features.", "labels": [], "entities": []}, {"text": "The present approach emphasizes the use of a variety of diverse information sources, and SVMs provide the ideal tool to bring these sources together.", "labels": [], "entities": []}, {"text": "We describe the methods used to assign values to selected words and phrases, and we introduce a method of bringing them together to create a model for the classification of texts.", "labels": [], "entities": [{"text": "classification of texts", "start_pos": 155, "end_pos": 178, "type": "TASK", "confidence": 0.8785985112190247}]}, {"text": "In addition, several classes of features based upon the proximity of the topic with phrases which have been assigned favorability values are described in order to take further advantage of situations in which the topic of the text maybe explicitly identified.", "labels": [], "entities": []}, {"text": "The results of a variety of experiments are presented, using both data which is not topic annotated and data which has been hand annotated for topic.", "labels": [], "entities": []}, {"text": "In the case of the former, the present approach is shown to yield better performance than previous models on the same data.", "labels": [], "entities": []}, {"text": "In the case of the latter, results indicate that our approach may allow for further improvements to be gained given knowledge of the topic of the text.", "labels": [], "entities": []}], "datasetContent": [{"text": "First, value phrases were extracted and their values were derived using the method described in section 3.1.", "labels": [], "entities": []}, {"text": "After this, supervised learning was performed using these values as features.", "labels": [], "entities": []}, {"text": "In training data, reviews corresponding to a below average rating were classed as negative and those with an above average rating were classed as positive.", "labels": [], "entities": []}, {"text": "The first dataset consisted of a total of 1380 Epinions.com movie reviews, approximately half positive and half negative.", "labels": [], "entities": []}, {"text": "This is the same dataset as was presented in.", "labels": [], "entities": []}, {"text": "In order to compare results as directly as possible, we report results of 3-fold cross validation, following.", "labels": [], "entities": []}, {"text": "Likewise, we include punctuation as tokens and normalize the feature values for text length.", "labels": [], "entities": []}, {"text": "To lend further support to the conclusions we also report results for 10-fold cross validation experiments.", "labels": [], "entities": []}, {"text": "On this dataset the feature sets investigated include various combinations of the Turney value, the three text-wide Osgood values, and word token unigrams or lemmatized unigrams.", "labels": [], "entities": [{"text": "Turney value", "start_pos": 82, "end_pos": 94, "type": "DATASET", "confidence": 0.9149804413318634}]}, {"text": "The second dataset consists of 100 record reviews from the Pitchfork Media online record review publication, 3 topic-annotated by hand.", "labels": [], "entities": [{"text": "Pitchfork Media online record review publication", "start_pos": 59, "end_pos": 107, "type": "DATASET", "confidence": 0.8829179505507151}]}, {"text": "In addition to the features employed with the first dataset, this dataset allows the use those features described in 3.3 which make use of topic information, namely the broader PMI derived SO values and the topicsentence Osgood values.", "labels": [], "entities": []}, {"text": "Due to the relatively small size of this dataset, test suites were created using 100, 20, 10, and 5-fold cross validation, to maximize the amount of data available for training and the accuracy of the results.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 185, "end_pos": 193, "type": "METRIC", "confidence": 0.9988240599632263}]}, {"text": "Text length normalization appeared to harm performance on this dataset, and so the models reported here for this dataset were not normalized for length.", "labels": [], "entities": [{"text": "Text length normalization", "start_pos": 0, "end_pos": 25, "type": "TASK", "confidence": 0.602596233288447}]}, {"text": "SVMs were built using Kudo's TinySVM soft-  ware implementation.", "labels": [], "entities": [{"text": "TinySVM soft-  ware implementation", "start_pos": 29, "end_pos": 63, "type": "DATASET", "confidence": 0.8718720078468323}]}, {"text": "Several kernel types, kernel parameters, and optimization parameters were investigated, but no appreciable and consistent benefits were gained by deviating from the the default linear kernel with all parameter values set to their default, so only these results are reported here, with the exception of the Turney Values-only model on the Pitchfork dataset.", "labels": [], "entities": [{"text": "Pitchfork dataset", "start_pos": 338, "end_pos": 355, "type": "DATASET", "confidence": 0.9086441099643707}]}, {"text": "This single-featured model caused segmentation faults on some partitions with the linear kernel, and so the results for this model only, seen in, were obtained using a polynomial kernel with parameter set to 2 (default is 1) and the constraints violation penalty set at 2 (default is 1).", "labels": [], "entities": []}, {"text": "Several hybrid SVM models were further tested using the results from the previously described models as features.", "labels": [], "entities": []}, {"text": "In these models, the feature values for each event represent the distance from the dividing hyperplane for each constituent model.", "labels": [], "entities": []}], "tableCaptions": []}