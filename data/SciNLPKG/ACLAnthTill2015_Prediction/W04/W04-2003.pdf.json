{"title": [{"text": "A Robust and Hybrid Deep-Linguistic Theory Applied to Large-Scale Parsing", "labels": [], "entities": []}], "abstractContent": [{"text": "Modern statistical parsers are robust and quite fast, but their output is relatively shallow when compared to formal grammar parsers.", "labels": [], "entities": []}, {"text": "We suggest to extend statistical approaches to a more deep-linguistic analysis while at the same timekeeping the speed and low complexity of a statistical parser.", "labels": [], "entities": [{"text": "speed", "start_pos": 113, "end_pos": 118, "type": "METRIC", "confidence": 0.9905800223350525}]}, {"text": "The resulting parsing architecture suggested, implemented and evaluated here is highly robust and hybrid on a number of levels, combining statistical and rule-based approaches , constituency and dependency grammar , shallow and deep processing, full and near-full parsing.", "labels": [], "entities": [{"text": "parsing", "start_pos": 14, "end_pos": 21, "type": "TASK", "confidence": 0.9637752175331116}]}, {"text": "With its parsing speed of about 300,000 words per hour and state-of-the-art performance the parser is reliable fora number of large-scale applications discussed in the article.", "labels": [], "entities": [{"text": "parsing", "start_pos": 9, "end_pos": 16, "type": "TASK", "confidence": 0.9645891189575195}]}], "introductionContent": [{"text": "Robustness in Computational Linguistics has been recently recognized as a central issue for the design of reliable, large-scale Natural Language Processing (NLP) systems.", "labels": [], "entities": []}, {"text": "While the highest possible linguistic coverage is desirable, speed and robustness are equally important in practical applications.", "labels": [], "entities": [{"text": "speed", "start_pos": 61, "end_pos": 66, "type": "METRIC", "confidence": 0.9885721206665039}]}, {"text": "Formal Grammar Parser have carefully crafted grammars written by professional linguists.", "labels": [], "entities": [{"text": "Formal Grammar Parser", "start_pos": 0, "end_pos": 21, "type": "TASK", "confidence": 0.6893183489640554}]}, {"text": "In addition to expressing local relations, i.e. relations between a mother and a direct daughter node, a number of non-local relations, i.e. relations involving more than two generations, are also modeled.", "labels": [], "entities": []}, {"text": "An example of a nonlocal relation is the subject control relation in the sentence John wants to leave, where John is not only the explicit subject of want, but equally the implicit subject of leave.", "labels": [], "entities": []}, {"text": "A parser that fails to recognize control subjects misses important information, quantitatively about 3 % of all subjects.", "labels": [], "entities": []}, {"text": "But unrestricted real-world texts still pose a problem to NLP systems that are based on Formal Grammars.", "labels": [], "entities": []}, {"text": "Few hand-crafted, deep linguistic grammars achieve the coverage and robustness needed to parse large corpora (see () for an exception, and () for approaches extracting formal grammars from the Treebank), and speed remains a serious challenge.", "labels": [], "entities": [{"text": "coverage", "start_pos": 55, "end_pos": 63, "type": "METRIC", "confidence": 0.9816095232963562}, {"text": "speed", "start_pos": 208, "end_pos": 213, "type": "METRIC", "confidence": 0.9858773946762085}]}, {"text": "The typical problems can be grouped as follows.", "labels": [], "entities": []}, {"text": "Grammar complexity Fully comprehensive grammars are difficult to maintain and considerably increase parsing complexity.", "labels": [], "entities": []}, {"text": "Note that statistical parsers can equally suffer from this problem, see e.g. ().", "labels": [], "entities": []}, {"text": "Parsing complexity Typical formal grammar parser complexity is much higher than the O(n 3 ) for CFG.", "labels": [], "entities": [{"text": "formal grammar parser", "start_pos": 27, "end_pos": 48, "type": "TASK", "confidence": 0.6480790972709656}, {"text": "O", "start_pos": 84, "end_pos": 85, "type": "METRIC", "confidence": 0.9880453944206238}, {"text": "CFG", "start_pos": 96, "end_pos": 99, "type": "DATASET", "confidence": 0.9260291457176208}]}, {"text": "The complexity of some formal grammars is still unknown.", "labels": [], "entities": []}, {"text": "For Tree-Adjoining Grammars (TAG) it is O(n 7 ) or O(n 8 ) depending on the implementation.", "labels": [], "entities": []}, {"text": "() state that the theoretical bound of worst time complexity for Head-Driven Phrase Structure Grammar (HPSG) parsing is exponential.", "labels": [], "entities": [{"text": "Head-Driven Phrase Structure Grammar (HPSG) parsing", "start_pos": 65, "end_pos": 116, "type": "TASK", "confidence": 0.7326956950128078}]}, {"text": "Parsing algorithms able to treat completely unrestricted long-distance dependencies are NPcomplete).", "labels": [], "entities": []}, {"text": "Ranking Returning all syntactically possible analyses fora sentence is not really what is expected of a syntactic analyzer if it should be of practical use, since fora human there is usually only one \"correct\" interpretation.", "labels": [], "entities": []}, {"text": "A clear indication of preference, by means of ranking the analyses in a preference order is needed.", "labels": [], "entities": []}, {"text": "Pruning In order to keep search spaces manageable it is in fact necessary to discard unconvincing alternatives already during the parsing process.", "labels": [], "entities": [{"text": "parsing process", "start_pos": 130, "end_pos": 145, "type": "TASK", "confidence": 0.8904560804367065}]}, {"text": "Ina statistical parser, the ranking of intermediate structures occurs naturally, while a rule-based system has to rely on ad hoc heuristics.", "labels": [], "entities": []}, {"text": "With abeam search in a parse-time pruning system, which means that the total number of alternatives kept is constant from a certain search complexity onwards, real-world parsing time can be reduced to near-linear.", "labels": [], "entities": []}, {"text": "If one were to assume a constantly full beam, or uses an oracle) it is linear in practice.", "labels": [], "entities": []}, {"text": "A number of robust statistical parsers that offer solutions to these problems have now become available), but they typically produce CFG constituency data as output, trees that do not express long-distance dependencies.", "labels": [], "entities": [{"text": "CFG constituency data", "start_pos": 133, "end_pos": 154, "type": "DATASET", "confidence": 0.7812467614809672}]}, {"text": "Although grammatical function and empty nodes annotation expressing long-distance dependencies are provided in Treebanks such as the Penn Treebank (), most statistical Treebank trained parsers fully or largely ignore them 1 , which entails two problems: first, the training cannot profit from valuable annotation data.", "labels": [], "entities": [{"text": "Penn Treebank", "start_pos": 133, "end_pos": 146, "type": "DATASET", "confidence": 0.9948996007442474}]}, {"text": "Second, the extraction of long-distance dependencies (LDD) and the mapping to shallow semantic representations is not always possible from the output of these parsers.", "labels": [], "entities": []}, {"text": "This limitation is aggravated by alack of co-indexation information and parsing errors across an LDD.", "labels": [], "entities": []}, {"text": "In fact, some syntactic relations cannot be recovered on configurational grounds only.", "labels": [], "entities": []}, {"text": "For these reasons,) provocatively refers to them as \"halfgrammars\".", "labels": [], "entities": []}, {"text": "The paper is organized as follows.", "labels": [], "entities": []}, {"text": "We first explore a deep-linguistic grammar theory for English that is inherently designed to be robust by extending the low processing complexity and the robustness of statistical approaches to a more deep-linguistic level, by making careful use of underspecification, grammar compression techniques and using a grammar that directly delivers simple predicate-argument structures.", "labels": [], "entities": []}, {"text": "This allow us to use a context-free grammar at parse-time while successfully treating longdistance dependencies using low-complexity approaches before and after parsing.", "labels": [], "entities": []}, {"text": "Our approach is to use finite-state approximations of long-distance dependencies, as they are described in) for Dependency Grammar (DG) and ) for Lexical Functional Grammar (LFG).", "labels": [], "entities": [{"text": "Lexical Functional Grammar (LFG)", "start_pos": 146, "end_pos": 178, "type": "TASK", "confidence": 0.77739617228508}]}, {"text": "show that finite-state preprocessing modules can successfully deal with LDDs.", "labels": [], "entities": []}, {"text": "Our approach is similar in also amounting to a preprocessing recognition of LDDs.", "labels": [], "entities": []}, {"text": "Then we show that the implementation (Pro3Gres) profits from hybridness and is fast 1 (Collins, 1999) Model 2 uses some of the functional labels, and Model 3 some long-distance dependencies and robust enough to do large-scale parsing of totally unrestricted texts and give an overview of its applications.", "labels": [], "entities": []}, {"text": "To conclude, two evaluations are given.", "labels": [], "entities": []}], "datasetContent": [{"text": "Pro3Gres is currently being applied in a Question Answering system specifically targeted at).", "labels": [], "entities": [{"text": "Pro3Gres", "start_pos": 0, "end_pos": 8, "type": "DATASET", "confidence": 0.9373360276222229}, {"text": "Question Answering", "start_pos": 41, "end_pos": 59, "type": "TASK", "confidence": 0.7044712007045746}]}, {"text": "One of the main advantages of a dependency-based parser such as Pro3Gres over other parsing approaches is that a mapping from the syntactic layer to a semantic layer (meaning representation) is partly simplified ().", "labels": [], "entities": []}, {"text": "The original version of the QA system used the Link Grammar (LG) parser, which however had a number of significant shortcomings.", "labels": [], "entities": [{"text": "Link Grammar (LG) parser", "start_pos": 47, "end_pos": 71, "type": "TASK", "confidence": 0.48046713570753735}]}, {"text": "In particular the set of the dependency relations used in LG is very idiosyncratic, which makes any syntacticsemantic mapping created for LG necessarily unportable and difficult to extend and maintain.", "labels": [], "entities": []}, {"text": "A recent line of research concerns applications for the Semantic Web.", "labels": [], "entities": []}, {"text": "The documents available in the World Wide Web are mostly written in natural language.", "labels": [], "entities": []}, {"text": "As such, they are understandable only to humans.", "labels": [], "entities": []}, {"text": "One of the directions of Semantic Web research is about adding a layer to the documents that somehow formalizes their content, making it understandable also to software agents.", "labels": [], "entities": []}, {"text": "Such Semantic Web annotations can be seen as away to mark explicitly the meaning of certain parts of the documents.", "labels": [], "entities": []}, {"text": "The dependency relations provided by a parser such as Pro3Gres, combined with domain specific axioms, allow the creation of (some of) the semantic annotations, as described in ().", "labels": [], "entities": [{"text": "Pro3Gres", "start_pos": 54, "end_pos": 62, "type": "DATASET", "confidence": 0.9409011602401733}]}, {"text": "The modified QA system (using Pro3Gres) is being exploited in the area of 'Life Sciences', for applications concerning Knowledge Discovery over Medline abstracts ().", "labels": [], "entities": [{"text": "Knowledge Discovery", "start_pos": 119, "end_pos": 138, "type": "TASK", "confidence": 0.6510901153087616}]}, {"text": "We illustrate some of the differences between general-purpose parsing and the parsing of highly technical texts like Medline and give two evaluations.", "labels": [], "entities": [{"text": "general-purpose parsing", "start_pos": 46, "end_pos": 69, "type": "TASK", "confidence": 0.7656192481517792}, {"text": "Medline", "start_pos": 117, "end_pos": 124, "type": "DATASET", "confidence": 0.7799779772758484}]}], "tableCaptions": [{"text": " Table 2: Results of evaluating the parser output on Carroll's test suite on subject, object, PP- attachment and clause subordination relations, and a selective evaluation of 5 relations involving  long-distance dependencies (LDD)", "labels": [], "entities": [{"text": "PP- attachment and clause subordination relations", "start_pos": 94, "end_pos": 143, "type": "TASK", "confidence": 0.6371766371386391}]}, {"text": " Table 3: Results of evaluating 100 random sentences from the terminology-annotated GENIA  corpus, on subject, object, PP-attachment and clause subordination relations", "labels": [], "entities": [{"text": "GENIA  corpus", "start_pos": 84, "end_pos": 97, "type": "DATASET", "confidence": 0.9122421741485596}]}]}