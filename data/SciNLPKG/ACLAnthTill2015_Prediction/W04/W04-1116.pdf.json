{"title": [{"text": "Automatic Semantic Role Assignment fora Tree Structure", "labels": [], "entities": []}], "abstractContent": [{"text": "We present an automatic semantic roles labeling system for structured trees of Chinese sentences.", "labels": [], "entities": [{"text": "semantic roles labeling", "start_pos": 24, "end_pos": 47, "type": "TASK", "confidence": 0.6902487476666769}]}, {"text": "It adopts dependency decision making and example-based approaches.", "labels": [], "entities": [{"text": "dependency decision making", "start_pos": 10, "end_pos": 36, "type": "TASK", "confidence": 0.7422244151433309}]}, {"text": "The training data and extracted examples are from the Sinica Treebank, which is a Chinese Treebank with semantic role assigned for each constituent.", "labels": [], "entities": [{"text": "Sinica Treebank", "start_pos": 54, "end_pos": 69, "type": "DATASET", "confidence": 0.8200953304767609}, {"text": "Chinese Treebank", "start_pos": 82, "end_pos": 98, "type": "DATASET", "confidence": 0.9024663865566254}]}, {"text": "It used 74 abstract semantic roles including thematic roles, such as 'agent'; 'theme', 'instrument', and secondary roles of 'location', 'time', 'manner' and roles for nominal modifiers.", "labels": [], "entities": []}, {"text": "The design of role assignment algorithm is based on the different decision features, such as head-argument/modifier, case makers, sentence structures etc.", "labels": [], "entities": [{"text": "role assignment algorithm", "start_pos": 14, "end_pos": 39, "type": "TASK", "confidence": 0.8737782835960388}, {"text": "case makers", "start_pos": 117, "end_pos": 128, "type": "TASK", "confidence": 0.7077936381101608}]}, {"text": "It labels semantic roles of parsed sentences.", "labels": [], "entities": []}, {"text": "Therefore the practical performance of the system depends on a good parser which labels the right structures of sentences.", "labels": [], "entities": []}, {"text": "The system achieves 92.71% accuracy in labeling the semantic roles for pre-structure-bracketed texts which is considerably higher than the simple method using probabilistic model of head-modifier relations.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 27, "end_pos": 35, "type": "METRIC", "confidence": 0.9994400143623352}]}], "introductionContent": [{"text": "For natural language understanding, the process of fine-grain semantic role assignment is one of the prominent steps, which provides semantic relations between constituents.", "labels": [], "entities": [{"text": "natural language understanding", "start_pos": 4, "end_pos": 34, "type": "TASK", "confidence": 0.6444135010242462}, {"text": "fine-grain semantic role assignment", "start_pos": 51, "end_pos": 86, "type": "TASK", "confidence": 0.6102069765329361}]}, {"text": "The sense and sense relations between constituents are core meaning of a sentence.", "labels": [], "entities": []}, {"text": "Conventionally there are two kinds of methods for role assignments, one is using only statistical information () and the other is combining with grammar rules (.", "labels": [], "entities": [{"text": "role assignments", "start_pos": 50, "end_pos": 66, "type": "TASK", "confidence": 0.8457175493240356}]}, {"text": "However using only grammar rules to assign semantic roles could lead to low coverage.", "labels": [], "entities": [{"text": "coverage", "start_pos": 76, "end_pos": 84, "type": "METRIC", "confidence": 0.9618957042694092}]}, {"text": "On the other hand, performance of statistical methods relies on significant dependent features.", "labels": [], "entities": []}, {"text": "Data driven is a suitable strategy for semantic roles assignments of general texts.", "labels": [], "entities": [{"text": "semantic roles assignments of general texts", "start_pos": 39, "end_pos": 82, "type": "TASK", "confidence": 0.8073102434476217}]}, {"text": "We use the Sinica Treebank as information resource because of its various domains texts including politics, society, literature\u2026etc and it is a Chinese Treebank with semantic role assigned for each constituent.", "labels": [], "entities": [{"text": "Sinica Treebank", "start_pos": 11, "end_pos": 26, "type": "DATASET", "confidence": 0.7972762882709503}, {"text": "Chinese Treebank", "start_pos": 144, "end_pos": 160, "type": "DATASET", "confidence": 0.9322372078895569}]}, {"text": "It used 74 abstract semantic roles including thematic roles, such as 'agent'; 'theme', 'instrument', and secondary roles of 'location', 'time', 'manner' and modifiers of nouns, such as 'quantifier', 'predication', 'possessor', etc.", "labels": [], "entities": []}, {"text": "The design of role assignment algorithm is based on the different decision features, such as head-argument/modifier, case makers, sentence structures etc.", "labels": [], "entities": [{"text": "role assignment algorithm", "start_pos": 14, "end_pos": 39, "type": "TASK", "confidence": 0.8737782835960388}, {"text": "case makers", "start_pos": 117, "end_pos": 128, "type": "TASK", "confidence": 0.7077932208776474}]}, {"text": "It labels semantic roles of parsed sentences by example-based probabilistic models.", "labels": [], "entities": []}], "datasetContent": [{"text": "We adopt the Sinica Treebank as both training and testing data.", "labels": [], "entities": [{"text": "Sinica Treebank", "start_pos": 13, "end_pos": 28, "type": "DATASET", "confidence": 0.8214719891548157}]}, {"text": "It contains about 40,000 parsed sentences.", "labels": [], "entities": []}, {"text": "We use 35,000 sentences as training data and the rest 5,000 as testing data shows the coverage of each classifier, their accuracies, and performance of each individual classifier without back off process.", "labels": [], "entities": []}, {"text": "The table 3 shows combined performance of the four classifiers after back off processes in sequence.", "labels": [], "entities": []}, {"text": "The baseline algorithm is the simple unigram approach to assign the most common role for the target word.", "labels": [], "entities": []}, {"text": "Because the accuracy of the four classifiers is considerably high, instead of using linear probability combinations we will rather use the most reliable classifier for each different features combination.: The accuracy of our backoff method and the baseline (the most common semantic roles)  The experiments were carried out for the refined back off model with the same set of training data and testing data as in the previous experiments.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 12, "end_pos": 20, "type": "METRIC", "confidence": 0.9975280165672302}, {"text": "accuracy", "start_pos": 210, "end_pos": 218, "type": "METRIC", "confidence": 0.9996412992477417}]}, {"text": "shows that the refined back off model gains 2.4 % accuracy rate than the original back off model.", "labels": [], "entities": [{"text": "accuracy rate", "start_pos": 50, "end_pos": 63, "type": "METRIC", "confidence": 0.9888639450073242}]}, {"text": "However most of the improvement is due to the refinements of features extractions and canonical representation for certain classes of words.", "labels": [], "entities": []}, {"text": "A few improvements were contributed to the decision making on the cases of structure dependency.", "labels": [], "entities": [{"text": "decision making", "start_pos": 43, "end_pos": 58, "type": "TASK", "confidence": 0.8906394839286804}]}], "tableCaptions": []}