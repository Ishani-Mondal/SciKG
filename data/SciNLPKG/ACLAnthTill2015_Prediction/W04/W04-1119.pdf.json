{"title": [{"text": "A Semi-Supervised Approach to Build Annotated Corpus for Chinese Named Entity Recognition", "labels": [], "entities": [{"text": "Chinese Named Entity Recognition", "start_pos": 57, "end_pos": 89, "type": "TASK", "confidence": 0.6052292063832283}]}], "abstractContent": [{"text": "1 This paper presents a semi-supervised approach to reduce human effort in building an annotated Chinese corpus.", "labels": [], "entities": []}, {"text": "One of the disadvantages of many statistical Chinese named entity recognition systems is that training data maybe in short supply, and manually building annotated corpus is expensive.", "labels": [], "entities": [{"text": "statistical Chinese named entity recognition", "start_pos": 33, "end_pos": 77, "type": "TASK", "confidence": 0.5834305107593536}]}, {"text": "In the proposed approach, we construct an 80M hand-annotated corpus in three steps: (1) Automatically annotate training corpus; (2) Manually refine small subsets of the automatically annotated corpus; (3) Combine small subsets and whole corpus in a bootstrapping process.", "labels": [], "entities": []}, {"text": "Our approach is tested on a state-of-the-art Chinese word segmentation system (Gao et al., 2003, 2004).", "labels": [], "entities": [{"text": "Chinese word segmentation", "start_pos": 45, "end_pos": 70, "type": "TASK", "confidence": 0.6643733183542887}]}, {"text": "Experiments show that only a small subset of hand-annotated corpus is sufficient to achieve a satisfying performance of the named entity component in this system.", "labels": [], "entities": []}], "introductionContent": [{"text": "The success of applying statistical methods to natural language processing tasks depends to a large degree upon the quality and amount of available training data.", "labels": [], "entities": [{"text": "natural language processing tasks", "start_pos": 47, "end_pos": 80, "type": "TASK", "confidence": 0.7016899511218071}]}, {"text": "This paper presents our method of creating training data for the statistical Chinese word segmenter proposed in.", "labels": [], "entities": [{"text": "statistical Chinese word segmenter", "start_pos": 65, "end_pos": 99, "type": "TASK", "confidence": 0.5981213003396988}]}, {"text": "The segmenter is based on improved source-channel models, which are trained on a large amount of annotated training data.", "labels": [], "entities": []}, {"text": "Whereas the hand-annotation is a very expensive task, creating the training data automatically remains an open research problem.", "labels": [], "entities": []}, {"text": "Our approach falls somewhere between the two extremes of the spectrum.", "labels": [], "entities": []}, {"text": "We try to minimize the human effort while keeping the quality of the annotation reasonably good for model estimation.", "labels": [], "entities": [{"text": "model estimation", "start_pos": 100, "end_pos": 116, "type": "TASK", "confidence": 0.6629598587751389}]}, {"text": "The method to be presented has been discussed briefly in.", "labels": [], "entities": []}, {"text": "This paper presents an extended description with more details and experimental results.", "labels": [], "entities": []}, {"text": "The training data refer to a set of Chinese sentences where word boundaries and types have been annotated.", "labels": [], "entities": []}, {"text": "Our basic solution is the bootstrapping approach described in.", "labels": [], "entities": []}, {"text": "It consists of three steps: (1) Initially, we use a greedy word segmenter to annotate the corpus, and obtain initial models based on the initial annotated corpus; (2) We re-annotate the corpus using the obtained models; (3) Re-train the models using the re-annotated corpus.", "labels": [], "entities": []}, {"text": "Steps 2 and 3 are iterated until the performance of the system converges.", "labels": [], "entities": []}, {"text": "In this approach, the quality of the resulting models depends to a large degree upon the quality of the initial annotated corpus.", "labels": [], "entities": []}, {"text": "Because there are many named entities that are not stored in a dictionary, traditional dictionary-based forward maximum matching (FMM) algorithm is not sufficient to create a good initial corpus.", "labels": [], "entities": [{"text": "dictionary-based forward maximum matching (FMM)", "start_pos": 87, "end_pos": 134, "type": "TASK", "confidence": 0.5905223318508693}]}, {"text": "We thus manually annotate named entities on a small subset (call seed set) of the training data.", "labels": [], "entities": []}, {"text": "Then, we obtain a model on the seed set (called seed model).", "labels": [], "entities": []}, {"text": "We thus improve the initial model which is trained on the initial annotated training corpus by interpolating it with the seed model.", "labels": [], "entities": []}, {"text": "Our experiments show that a relatively small seed set (e.g., 10 million characters, which takes approximately three weeks for 4 persons to annotate the NE tags) is enough to get a good improved model for initialization.", "labels": [], "entities": [{"text": "initialization", "start_pos": 204, "end_pos": 218, "type": "TASK", "confidence": 0.978144109249115}]}, {"text": "The remainder of this paper is organized as follows: Section 2 summarizes the related work.", "labels": [], "entities": []}, {"text": "Section 3 deals with our approach to improve model estimation for Chinese word segmentation.", "labels": [], "entities": [{"text": "model estimation", "start_pos": 45, "end_pos": 61, "type": "TASK", "confidence": 0.6538735628128052}, {"text": "Chinese word segmentation", "start_pos": 66, "end_pos": 91, "type": "TASK", "confidence": 0.5889121194680532}]}, {"text": "The experiments are presented at Section 4.", "labels": [], "entities": []}, {"text": "Finally we conclude in Section 5.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section, we first present our experiments on the generation and evaluation of hand-annotated corpus to answer the first two questions.", "labels": [], "entities": []}, {"text": "Then, the answer to the third question is given in subsection 4.2.", "labels": [], "entities": []}, {"text": "To evaluate the quality of our annotated corpus, we trained a context model using the method described in Section 3, with the first-obtained 10-million-character seed set.", "labels": [], "entities": []}, {"text": "We then compare the performance of the resulting segmenter with those of other state-of-the-art segmenters and the FMM segmenter.", "labels": [], "entities": [{"text": "FMM segmenter", "start_pos": 115, "end_pos": 128, "type": "TASK", "confidence": 0.6517847776412964}]}, {"text": "We conduct evaluations in terms of precision (P) and recall (R).", "labels": [], "entities": [{"text": "precision (P)", "start_pos": 35, "end_pos": 48, "type": "METRIC", "confidence": 0.9456597715616226}, {"text": "recall (R)", "start_pos": 53, "end_pos": 63, "type": "METRIC", "confidence": 0.9410346746444702}]}], "tableCaptions": [{"text": " Table 1: Results on different Chinese word seg- menters", "labels": [], "entities": []}]}