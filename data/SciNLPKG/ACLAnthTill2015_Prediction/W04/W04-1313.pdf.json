{"title": [{"text": "Combining Utterance-Boundary and Predictability Approaches to Speech Segmentation", "labels": [], "entities": [{"text": "Speech Segmentation", "start_pos": 62, "end_pos": 81, "type": "TASK", "confidence": 0.7263258993625641}]}], "abstractContent": [{"text": "This paper investigates two approaches to speech segmentation based on different heuris-tics: the utterance-boundary strategy, and the predictability strategy.", "labels": [], "entities": [{"text": "speech segmentation", "start_pos": 42, "end_pos": 61, "type": "TASK", "confidence": 0.7363232970237732}]}, {"text": "On the basis of former empirical results as well as theoretical considerations , it is suggested that the utterance-boundary approach could be used as a prepro-cessing step in order to lighten the task of the predictability approach, without damaging the resulting segmentation.", "labels": [], "entities": []}, {"text": "This intuition leads to the formulation of an explicit model, which is empirically evaluated fora task of word segmen-tation on a child-oriented phonemically transcribed French corpus.", "labels": [], "entities": []}, {"text": "The results show that the hybrid algorithm outperforms its component parts while reducing the total memory load involved.", "labels": [], "entities": []}], "introductionContent": [{"text": "The design of speech segmentation 1 methods has been much studied ever since Harris' seminal propositions.", "labels": [], "entities": [{"text": "speech segmentation 1", "start_pos": 14, "end_pos": 35, "type": "TASK", "confidence": 0.8213464816411337}]}, {"text": "Research conducted since the mid 1990's by cognitive scientists has established it as a paradigm of its own in the field of computational models of language acquisition.", "labels": [], "entities": [{"text": "language acquisition", "start_pos": 148, "end_pos": 168, "type": "TASK", "confidence": 0.657624363899231}]}, {"text": "In this paper, we investigate two boundarybased approaches to speech segmentation.", "labels": [], "entities": [{"text": "speech segmentation", "start_pos": 62, "end_pos": 81, "type": "TASK", "confidence": 0.7165724486112595}]}, {"text": "Such methods \"attempt to identify individual wordboundaries in the input, without reference to words per se\".", "labels": [], "entities": []}, {"text": "The first approach we discuss relies on the utterance-boundary strategy, which consists in reusing the information provided by the occurrence of specific phoneme sequences at utterance beginnings or endings in order to hypoth-esize boundaries inside utterances ().", "labels": [], "entities": []}, {"text": "The second approach is based on the predictability strategy, which assumes that speech should be segmented at locations where some measure of the uncertainty about the next symbol (phoneme or syllable for instance) is high.", "labels": [], "entities": []}, {"text": "Our implementation of the utteranceboundary strategy is based on n-grams statistics.", "labels": [], "entities": []}, {"text": "It was previously found to perform a \"safe\" word segmentation, that is with a rather high precision, but also too conservative as witnessed by a not so high recall.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 44, "end_pos": 61, "type": "TASK", "confidence": 0.7082785665988922}, {"text": "precision", "start_pos": 90, "end_pos": 99, "type": "METRIC", "confidence": 0.9972617626190186}, {"text": "recall", "start_pos": 157, "end_pos": 163, "type": "METRIC", "confidence": 0.9960934519767761}]}, {"text": "As regards the predictability strategy, we have implemented an incremental interpretation of the classical successor count.", "labels": [], "entities": [{"text": "predictability", "start_pos": 15, "end_pos": 29, "type": "TASK", "confidence": 0.9681688547134399}]}, {"text": "This approach also relies on the observation of phoneme sequences, the length of which is however not restricted to a fixed value.", "labels": [], "entities": []}, {"text": "Consequently, the memory load involved by the successor count algorithm is expected to be higher than for the utterance-boundary approach, and its performance substantially better.", "labels": [], "entities": []}, {"text": "The experiments presented in this paper were inspired by the intuition that both algorithms could be combined in order to make the most of their respective strengths.", "labels": [], "entities": []}, {"text": "The utteranceboundary typicality could be used as a computationally inexpensive preprocessing step, finding some true boundaries without inducing too many false alarms; then, the heavier machinery of the successor count would be used to accurately detect more boundaries, its burden being lessened as it would process the chunks produced by the first algorithm rather than whole utterances.", "labels": [], "entities": []}, {"text": "We will show the results obtained fora word segmentation task on a phonetically transcribed and child-oriented French corpus, focusing on the effect of the preprocessing step on precision and recall, as well as its impact on memory load and processing time.", "labels": [], "entities": [{"text": "word segmentation task", "start_pos": 39, "end_pos": 61, "type": "TASK", "confidence": 0.7795194784800211}, {"text": "precision", "start_pos": 178, "end_pos": 187, "type": "METRIC", "confidence": 0.9971404075622559}, {"text": "recall", "start_pos": 192, "end_pos": 198, "type": "METRIC", "confidence": 0.9906178116798401}]}, {"text": "The next section is devoted to the formal definition of both algorithms.", "labels": [], "entities": []}, {"text": "Section 3 discusses some issues related to the space and time complexity they involve.", "labels": [], "entities": []}, {"text": "The experimental setup as well as the results of the simulations are described in section 4, and in conclusion we will summarize our findings and suggest directions for further research.", "labels": [], "entities": []}, {"text": "2 Description of the algorithms 2.1 Segmentation by thresholding Many distributional segmentation algorithms described in the literature can be seen as instances of the following abstract procedure).", "labels": [], "entities": []}, {"text": "Let S be the set of phonemes (or segments) in a given language.", "labels": [], "entities": []}, {"text": "In the most general case, the input of the algorithm is an utterance of length l, that is a sequence of l phonemes u := s 1 . .", "labels": [], "entities": []}, {"text": "s l (where s i denotes the i-th phoneme of u).", "labels": [], "entities": []}, {"text": "Then, for 1 where the values of the decision variable D(u, i) and of the threshold T (u, i) may depend on both the whole sequence and the actual position examined . The output of such algorithms can be evaluated in reference to the segmentation performed by a human expert, using traditional measures from the signal detection framework.", "labels": [], "entities": [{"text": "signal detection", "start_pos": 310, "end_pos": 326, "type": "TASK", "confidence": 0.7762799859046936}]}, {"text": "It is usual to give evaluations both for word and boundary detection).", "labels": [], "entities": [{"text": "word and boundary detection", "start_pos": 41, "end_pos": 68, "type": "TASK", "confidence": 0.6933832913637161}]}, {"text": "The word precision is the probability fora word isolated by the segmentation procedure to be present in the reference segmentation, and the word recall is the probability fora word occurring in the true segmentation to be correctly isolated.", "labels": [], "entities": [{"text": "precision", "start_pos": 9, "end_pos": 18, "type": "METRIC", "confidence": 0.7073301672935486}, {"text": "recall", "start_pos": 145, "end_pos": 151, "type": "METRIC", "confidence": 0.9440686702728271}]}, {"text": "Similarly, the segmentation precision is the probability that an inferred boundary actually occurs in the true segmentation, and the segmentation recall is the probability fora true boundary to be detected.", "labels": [], "entities": [{"text": "precision", "start_pos": 28, "end_pos": 37, "type": "METRIC", "confidence": 0.6757757663726807}, {"text": "recall", "start_pos": 146, "end_pos": 152, "type": "METRIC", "confidence": 0.9439495801925659}]}, {"text": "In the remaining of this section, we will use this framework to show how the two algorithms we investigate rely on different definitions of D(u, i) and T (u, i).", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": []}