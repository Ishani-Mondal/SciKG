{"title": [{"text": "Analysis of Semantic Classes in Medical Text for Question Answering", "labels": [], "entities": [{"text": "Question Answering", "start_pos": 49, "end_pos": 67, "type": "TASK", "confidence": 0.7748217880725861}]}], "abstractContent": [{"text": "To answer questions from clinical-evidence texts, we identify occurrences of the semantic classes-disease, medication, patient outcome-that are candidate elements of the answer, and the relations among them.", "labels": [], "entities": []}, {"text": "Additionally, we determine whether an outcome is positive or negative.", "labels": [], "entities": []}], "introductionContent": [], "datasetContent": [{"text": "We evaluated the cue word method of detecting the outcome on the remaining one-third of the sections of CE.", "labels": [], "entities": []}, {"text": "(The test set is rather small because of the difficulty in obtaining the annotations.)", "labels": [], "entities": []}, {"text": "The outcome detection task was broken into two sub-tasks, each evaluated separately: to identify the outcome itself and to determine its textual boundary.", "labels": [], "entities": [{"text": "outcome detection task", "start_pos": 4, "end_pos": 26, "type": "TASK", "confidence": 0.872353732585907}]}, {"text": "The result of identification is shown in.", "labels": [], "entities": [{"text": "identification", "start_pos": 14, "end_pos": 28, "type": "TASK", "confidence": 0.9737156629562378}]}, {"text": "Eighty-one sentences in the test set contain either an outcome or result, which is 52% of all the test sentences.", "labels": [], "entities": []}, {"text": "This was taken as the baseline of the evaluation: taking all sentences in the test set as positive (i.e., containing an outcome or result).", "labels": [], "entities": []}, {"text": "By contrast, the accuracy of the combination approach is 83%.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 17, "end_pos": 25, "type": "METRIC", "confidence": 0.9998158812522888}]}, {"text": "There are two main reasons why some outcomes were not identified.", "labels": [], "entities": []}, {"text": "One is that some outcomes do not have any cue word:  The classification used four different sets of features.", "labels": [], "entities": []}, {"text": "The first feature set includes every unigram that appears at least three times in the whole training set.", "labels": [], "entities": []}, {"text": "To improve the performance by attenuating the sparse data problem, in the second feature set, all names of diseases were replaced by the same tag disease.", "labels": [], "entities": []}, {"text": "This was done by pre-processing the text using MetaMap to identify all diseases in both the training and the test examples.", "labels": [], "entities": []}, {"text": "Then the identified diseases were replaced by the disease tag automatically.", "labels": [], "entities": []}, {"text": "As medications often are not mentioned in outcomes, they were not generalized in this manner.", "labels": [], "entities": []}, {"text": "The third feature set represents changes described in outcomes.", "labels": [], "entities": []}, {"text": "Our observation is that outcomes often involve the change in a clinical value.", "labels": [], "entities": []}, {"text": "For example, after a medication was applied to a disease, something was increased (enhanced, more, . .", "labels": [], "entities": []}, {"text": ") or decreased (reduced, less, . .", "labels": [], "entities": []}, {"text": "). Thus the polarity of an outcome is often determined by how change happens: if a bad thing (e.g., mortality) is reduced then it is a positive outcome; if the bad thing is increased, then the outcome is negative.", "labels": [], "entities": []}, {"text": "We try to capture this observation by adding context features to the feature set.", "labels": [], "entities": []}, {"text": "The way they were added is similar to incorporating the negation effect described by.", "labels": [], "entities": []}, {"text": "But instead of just finding a \"negation word\" (not, isn't, didn't, etc.), we need to find two groups of words: those indicating more and those indicating less.", "labels": [], "entities": []}, {"text": "In the training text, we found 9 words in the first group and 7 words in the second group.", "labels": [], "entities": []}, {"text": "When pre-processing text for classification, following the method of Pang et al., we attached the tag MORE to all words between the more-words and the following punctuation mark, and the tag LESS to the words after the less-words.", "labels": [], "entities": [{"text": "MORE", "start_pos": 102, "end_pos": 106, "type": "METRIC", "confidence": 0.9863854050636292}, {"text": "LESS", "start_pos": 191, "end_pos": 195, "type": "METRIC", "confidence": 0.9770740866661072}]}, {"text": "The fourth feature set is the combination of the effects of feature set two and three.", "labels": [], "entities": []}, {"text": "In representing each sentence by a feature vector, we tested both presence (feature appears or not) and frequency (count the number of occurrences of the feature in the sentence).", "labels": [], "entities": [{"text": "frequency", "start_pos": 104, "end_pos": 113, "type": "METRIC", "confidence": 0.9848321080207825}]}, {"text": "The accuracy of the classification is shown in Table 5.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.999686598777771}, {"text": "classification", "start_pos": 20, "end_pos": 34, "type": "TASK", "confidence": 0.9714486598968506}]}, {"text": "The baseline is to assign a random class (here we use negative, as they are more frequent in the test set) to all test samples.", "labels": [], "entities": []}, {"text": "The presence of features performs better than frequency of features in general.", "labels": [], "entities": []}, {"text": "Using a more general category instead of specific diseases has a positive effect on the presence-based classification.", "labels": [], "entities": [{"text": "presence-based classification", "start_pos": 88, "end_pos": 117, "type": "TASK", "confidence": 0.5554206520318985}]}, {"text": "We speculate that the effect of this generalization will be bigger if a larger test set were used.", "labels": [], "entities": []}, {"text": "did not compare the result of using and not using the negation context effect, so it is not clear how much it improved their result.", "labels": [], "entities": []}, {"text": "In our task, it is clear that the MORE/ LESS feature has a significant effect on the performance, especially for the frequency features.", "labels": [], "entities": [{"text": "MORE", "start_pos": 34, "end_pos": 38, "type": "METRIC", "confidence": 0.9888837337493896}, {"text": "LESS", "start_pos": 40, "end_pos": 44, "type": "METRIC", "confidence": 0.5888325572013855}]}], "tableCaptions": [{"text": " Table 1: Results of identifying outcomes in CE", "labels": [], "entities": [{"text": "CE", "start_pos": 45, "end_pos": 47, "type": "TASK", "confidence": 0.7956094145774841}]}, {"text": " Table 2: Results of boundary detection of correctly  identified outcomes in CE. A: Identified fragments;  B: true boundary.", "labels": [], "entities": []}, {"text": " Table 4: Results of relation analysis", "labels": [], "entities": [{"text": "relation analysis", "start_pos": 21, "end_pos": 38, "type": "TASK", "confidence": 0.9639535844326019}]}, {"text": " Table 4.  Most errors are because of the weak indicators  with and and. As in the outcome identification task,  both the training and test sets are rather small, as no  standard annotated text is available.", "labels": [], "entities": [{"text": "outcome identification task", "start_pos": 83, "end_pos": 110, "type": "TASK", "confidence": 0.8587476015090942}]}, {"text": " Table 5: Results of outcome polarity classification", "labels": [], "entities": [{"text": "outcome polarity classification", "start_pos": 21, "end_pos": 52, "type": "TASK", "confidence": 0.8182972272237142}]}]}