{"title": [], "abstractContent": [{"text": "This paper presents the Swarthmore College word-sense disambiguation system which was designed for the 2004 SENSEVAL3 competition.", "labels": [], "entities": [{"text": "Swarthmore College word-sense disambiguation", "start_pos": 24, "end_pos": 68, "type": "TASK", "confidence": 0.6606861352920532}, {"text": "SENSEVAL3 competition", "start_pos": 108, "end_pos": 129, "type": "TASK", "confidence": 0.7080941200256348}]}, {"text": "Our system participated in five tasks: the lexical sample tasks in Basque, Catalan, Italian, Romanian, and Spanish.", "labels": [], "entities": []}, {"text": "For each task, a suite of supervised algorithms were combined using voting to form the final system.", "labels": [], "entities": []}], "introductionContent": [{"text": "The Swarthmore College system consisted of three supervised classifiers which were used to perform lexical ambiguity resolution in five languages.", "labels": [], "entities": [{"text": "lexical ambiguity resolution", "start_pos": 99, "end_pos": 127, "type": "TASK", "confidence": 0.6963016192118326}]}, {"text": "A nearest-neighbor clustering classifier, a na\u00a8\u0131vena\u00a8\u0131ve Bayes classifier, and a decision list classifier were each trained on several permutations of the extracted feature set, then the answers were joined using voting.", "labels": [], "entities": []}, {"text": "The training data was limited to the labeled data provided by the organizers; no outside or unlabeled data was used.", "labels": [], "entities": []}, {"text": "The systems presented in this paper were developed by undergraduates as part of a class project at Swarthmore College.", "labels": [], "entities": []}], "datasetContent": [{"text": "As previously discussed, we used a combination of three supervised classifiers, each run on a different subset of the features.", "labels": [], "entities": []}, {"text": "Here we report the performance of each of the individual classifiers, as well as the features we found to be most indicative of the correct sense.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Final results, officially and unofficially,  from making a bug-fix before notification of results,  but after the submission deadline.", "labels": [], "entities": []}, {"text": " Table 2: Using simple tie-breakers in voting. The  second column also includes the bug fix described  in  \u00a74.1.1. Note that the tie-breaking error was found  after notification of our final results.", "labels": [], "entities": []}, {"text": " Table 3: Precision on likely collocational senses.", "labels": [], "entities": [{"text": "Precision", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9720739126205444}]}, {"text": " Table 4: Overall impact of using bagging.", "labels": [], "entities": []}, {"text": " Table 5: Accuracy of the decision list system using  each of the available features individually. All of  the above features, except 'docsrc' were used in the  final system. The features are ordered from least to  most informative across the four languages.", "labels": [], "entities": []}, {"text": " Table 6: Accuracies for each of the classifiers: Most  Frequent Sense, Na\u00a8\u0131veNa\u00a8\u0131ve Bayes, Nearest-Neighbor  Clustering, and Decision Lists.", "labels": [], "entities": [{"text": "Accuracies", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.9947625994682312}, {"text": "Most  Frequent Sense", "start_pos": 50, "end_pos": 70, "type": "METRIC", "confidence": 0.6705211699008942}]}]}