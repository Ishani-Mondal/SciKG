{"title": [{"text": "Annotating Student Emotional States in Spoken Tutoring Dialogues", "labels": [], "entities": [{"text": "Spoken Tutoring Dialogues", "start_pos": 39, "end_pos": 64, "type": "TASK", "confidence": 0.8379846811294556}]}], "abstractContent": [{"text": "We present an annotation scheme for student emotions in tutoring dialogues.", "labels": [], "entities": []}, {"text": "Analyses of our scheme with respect to interannota-tor agreement and predictive accuracy indicate that our scheme is reliable in our domain, and that our emotion labels can be predicted with a high degree of accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 80, "end_pos": 88, "type": "METRIC", "confidence": 0.9651235938072205}, {"text": "accuracy", "start_pos": 208, "end_pos": 216, "type": "METRIC", "confidence": 0.9951085448265076}]}, {"text": "We discuss issues concerning the implementation of emotion prediction and adaptation in the computer tutoring dialogue system we are developing.", "labels": [], "entities": [{"text": "emotion prediction", "start_pos": 51, "end_pos": 69, "type": "TASK", "confidence": 0.8350005745887756}]}], "introductionContent": [{"text": "This paper describes a coding scheme for annotating student emotional states in spoken dialogue tutoring corpora, and analyzes the scheme not only for its reliability, but also for its utility in developing a spoken dialogue tutoring system that can model and respond to student emotions.", "labels": [], "entities": []}, {"text": "Motivation for this work comes from the performance discrepancy between human tutors and current machine tutors: typically, students tutored by human tutors achieve higher learning gains than students tutored by computer tutors.", "labels": [], "entities": []}, {"text": "The development of computational tutorial dialogue systems) represents one method of closing this performance gap, e.g. it is hypothesized that dialogue-based tutors allow greater adaptivity to students' beliefs and misconceptions.", "labels": [], "entities": []}, {"text": "Another method for closing this performance gap involves incorporating emotion prediction and adaptation into computer tutors ().", "labels": [], "entities": [{"text": "emotion prediction", "start_pos": 71, "end_pos": 89, "type": "TASK", "confidence": 0.7327263355255127}]}, {"text": "For example) have shown that adding human-provided emotional scaffolding to an automated reading tutor increases student persistence.", "labels": [], "entities": []}, {"text": "This suggests that the success of computer dialogue tutors could be increased by responding to both what a student says and how s/he says it, e.g. with confidence or uncertainty.", "labels": [], "entities": []}, {"text": "To assess the impact of adding emotion modeling to dialogue tutoring systems, we are building ITSPOKE (Intelligent Tutoring SPOKEn dialogue system), a spoken dialogue system that uses the Why2-Atlas conceptual physics tutoring system () as its \"back-end.\"", "labels": [], "entities": []}, {"text": "1 Our first step towards incorporating emotion processing into ITSPOKE is to develop a reliable annotation scheme for student emotions.", "labels": [], "entities": [{"text": "ITSPOKE", "start_pos": 63, "end_pos": 70, "type": "DATASET", "confidence": 0.8108766078948975}]}, {"text": "Our next step will be to use the data that has been annotated according to this scheme to enhance ITSPOKE to dynamically predict and adapt to student emotions.", "labels": [], "entities": [{"text": "ITSPOKE", "start_pos": 98, "end_pos": 105, "type": "DATASET", "confidence": 0.5848208069801331}]}, {"text": "This adds additional constraints on our annotation scheme besides good reliability, namely that our annotations are predictable by ITSPOKE with a high degree of accuracy (automatically and in real-time), and that they are expressive enough to support the range of desired system adaptations.", "labels": [], "entities": [{"text": "reliability", "start_pos": 71, "end_pos": 82, "type": "METRIC", "confidence": 0.9684625864028931}, {"text": "ITSPOKE", "start_pos": 131, "end_pos": 138, "type": "DATASET", "confidence": 0.5686438083648682}, {"text": "accuracy", "start_pos": 161, "end_pos": 169, "type": "METRIC", "confidence": 0.9974249601364136}]}, {"text": "In Section 2 we review previous work in emotion annotation for spoken dialogue systems.", "labels": [], "entities": [{"text": "emotion annotation", "start_pos": 40, "end_pos": 58, "type": "TASK", "confidence": 0.7369048595428467}]}, {"text": "In Section 3 we discuss our tutoring research project and corpora.", "labels": [], "entities": []}, {"text": "In Section 4 we present an emotion annotation scheme for this domain.", "labels": [], "entities": []}, {"text": "In Section 5 we analyze our scheme with respect to interannotator agreement and predictive accuracy, using a corpus of human tutoring dialogues.", "labels": [], "entities": [{"text": "predictive", "start_pos": 80, "end_pos": 90, "type": "TASK", "confidence": 0.932051420211792}, {"text": "accuracy", "start_pos": 91, "end_pos": 99, "type": "METRIC", "confidence": 0.8968812227249146}]}, {"text": "Our agreement indicates that our scheme is reliable, while machine learning experiments on annotated data indicate that our emotion labels can be predicted with a high degree of accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 178, "end_pos": 186, "type": "METRIC", "confidence": 0.9948287606239319}]}, {"text": "In Section 6 we analyze more expressive versions of our scheme, and discuss differences between annotating human and computer spoken tutoring dialogues.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Confusion Matrix 1: Minor", "labels": [], "entities": []}, {"text": " Table 3: Confusion Matrix 3: Pos/Neu", "labels": [], "entities": []}, {"text": " Table 4: Conf. Matrix 4: (Weak) Pos/Neu", "labels": [], "entities": []}, {"text": " Table 7: Summary: Annotation and Learning Results", "labels": [], "entities": [{"text": "Summary", "start_pos": 10, "end_pos": 17, "type": "TASK", "confidence": 0.8410742282867432}]}, {"text": " Table 8. The row and column labels are as above, e.g.  the NPN row represents turns consensus-labeled as nega- tive/neutral/positive, first when all three minor classes are  conflated with neutral, and second where the weak minor  classes are conflated with their main counterparts.", "labels": [], "entities": []}, {"text": " Table 8: Consensus Labeling over Analyses", "labels": [], "entities": [{"text": "Consensus Labeling over Analyses", "start_pos": 10, "end_pos": 42, "type": "TASK", "confidence": 0.8405640870332718}]}, {"text": " Table 9: Predicting Consensus Labels", "labels": [], "entities": [{"text": "Predicting Consensus Labels", "start_pos": 10, "end_pos": 37, "type": "TASK", "confidence": 0.854467511177063}]}, {"text": " Table 10: Confusion Matrix: All 6 Emotion Classes", "labels": [], "entities": []}]}