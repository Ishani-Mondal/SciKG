{"title": [], "abstractContent": [{"text": "This article focuses on the development of Natural Language Processing (NLP) tools for Computer Assisted Language Learning (CALL).", "labels": [], "entities": [{"text": "Computer Assisted Language Learning (CALL)", "start_pos": 87, "end_pos": 129, "type": "TASK", "confidence": 0.7445225375039237}]}, {"text": "After identifying the inherent limitations of NLP-free tools, we describe the general framework of Mirto, an NLP-based authoring platform under construction in our laboratory, and organized into four distinct layers: functions, scripts, activities and scenarios.", "labels": [], "entities": []}, {"text": "Through several examples, we explain how Mirto's architecture allows to implement state-of-the-art NLP functions, integrate them into easily handled scripts in order to create, without computing skills, didactic activities that could be recorded in more complex sequences or scenarios.", "labels": [], "entities": []}], "introductionContent": [], "datasetContent": [{"text": "The learner production, in the framework of an activity, may have very various forms: clicks on checkbox, words, sentences or even texts.", "labels": [], "entities": []}, {"text": "The evaluation of sentences and texts is a tough problem: NLP techniques cannot really give reliable information about features that require a human interpretation (meaning, style, etc.).", "labels": [], "entities": []}, {"text": "Even for the simplest task of error detection, the existing models are both silent and noisy at the same time: some errors are not detected, and correct expressions are wrongly pointed out as errors.", "labels": [], "entities": [{"text": "error detection", "start_pos": 30, "end_pos": 45, "type": "TASK", "confidence": 0.7067977786064148}]}, {"text": "On the opposite, the evaluation of a multiple choice questionnaire is a trivial problem that does not need the expensive implementation of NLP tools.", "labels": [], "entities": []}, {"text": "For now, we think that the most realistic and promising application concerns the evaluation of simple lexical productions.", "labels": [], "entities": []}, {"text": "We are currently studying a three levels protocol for the evaluation of a given answer with respect to the expected correct answer.", "labels": [], "entities": []}, {"text": "If the given answer is different, three cases are considered: 1-Spelling error: if the entered chain does not exist in an inflected form dictionary, one can assume that it bears a spelling error.", "labels": [], "entities": []}, {"text": "If the chain is very close to the correct answer, a message can be displayed, warning about the spelling error.", "labels": [], "entities": [{"text": "spelling", "start_pos": 96, "end_pos": 104, "type": "METRIC", "confidence": 0.8810162544250488}]}, {"text": "Else, a list of resembling existing words can be proposed to the learner, asking him to make a choice.", "labels": [], "entities": []}, {"text": "2-Morphosyntactic level: at this stage, the answer is integrated in the linguistic context of the activity (for instance, the sentence where the gap was done, in a gap-filling exercise), in order to compute a morphosyntactic analysis with tagging and lemmatization.", "labels": [], "entities": []}, {"text": "If the lemma is the same than the lemma of the correct answer, a warning can be displayed about the difference in the morphosyntactic features (e.g. \"wrong tense\", \"wrong number\", etc.).", "labels": [], "entities": []}, {"text": "3-Semantic level: in the case of a different lemma, a semantic wordnet is searched in order to check whether a close semantic link (synonymy, hyperonymy, hyponymy, meronymy, antonymy) can be found between the given answer and the expected one.", "labels": [], "entities": []}, {"text": "Then, a warning can be displayed such as \"be more precise\", \"not exactly\", etc.", "labels": [], "entities": []}, {"text": "In the global architecture, such a script could be useful for the evaluation of various activities: gapfilling, lexical questions, etc.", "labels": [], "entities": []}, {"text": "According to the specific context and aim of a given activity, the feed-back to the learner maybe very different.", "labels": [], "entities": []}, {"text": "For instance, if a gap-filling exercise is designed to test the ability to conjugate verbs in a given tense, the fact that the lemma of the learner's answer is different is not very important, provided that the verbal flexion is correct.", "labels": [], "entities": []}, {"text": "Therefore, in the design of such an evaluation script, it is important to separate the comparison and the feed-back.", "labels": [], "entities": []}, {"text": "We plan to implement too scripts: -the comparison script that takes as an input: the linguistic context, the expected answer, the given answer; and returns a difference code such as: 0: no difference -the feed-back script that takes as an input the difference code, and returns a message, such as : \"yes, but the spelling is wrong\", \"be more precise\".", "labels": [], "entities": [{"text": "precise", "start_pos": 342, "end_pos": 349, "type": "METRIC", "confidence": 0.9728989601135254}]}, {"text": "Even if one can propose standard messages for each difference code, the teacher should obviously be able to edit an adapted message set depending on the didactic context of a given activity.", "labels": [], "entities": []}], "tableCaptions": []}