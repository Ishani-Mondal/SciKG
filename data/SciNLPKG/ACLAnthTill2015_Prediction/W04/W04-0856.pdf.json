{"title": [{"text": "Pattern Abstraction and Term Similarity for Word Sense Disambiguation: IRST at Senseval-3", "labels": [], "entities": [{"text": "Word Sense Disambiguation", "start_pos": 44, "end_pos": 69, "type": "TASK", "confidence": 0.6491477290789286}, {"text": "IRST", "start_pos": 71, "end_pos": 75, "type": "METRIC", "confidence": 0.57471764087677}, {"text": "Senseval-3", "start_pos": 79, "end_pos": 89, "type": "DATASET", "confidence": 0.49546530842781067}]}], "abstractContent": [{"text": "This paper summarizes IRST's participation in Senseval-3.", "labels": [], "entities": [{"text": "IRST", "start_pos": 22, "end_pos": 26, "type": "DATASET", "confidence": 0.5721201300621033}]}, {"text": "We participated both in the English all-words task and in some lexical sample tasks (En-glish, Basque, Catalan, Italian, Spanish).", "labels": [], "entities": []}, {"text": "On one hand, for the all-words task, we tried to refine the Domain Driven Disambiguation that we presented at Senseval-2.", "labels": [], "entities": []}, {"text": "The refinements consist of both exploiting anew technique (Domain Relevance Estimation) for domain detection in texts, and experimenting with the use of Latent Semantic Analysis to avoid reliance on manually annotated domain resources (e.g. WORD-NET DOMAINS).", "labels": [], "entities": [{"text": "Domain Relevance Estimation)", "start_pos": 59, "end_pos": 87, "type": "TASK", "confidence": 0.7171092107892036}, {"text": "domain detection in texts", "start_pos": 92, "end_pos": 117, "type": "TASK", "confidence": 0.8284426331520081}]}, {"text": "On the other hand, for the lexical sample tasks, we explored the direction of pattern abstraction and we demonstrated the feasibility of leveraging external knowledge using kernel methods .", "labels": [], "entities": [{"text": "pattern abstraction", "start_pos": 78, "end_pos": 97, "type": "TASK", "confidence": 0.7238976657390594}]}], "introductionContent": [{"text": "The starting point for our research in the Word Sense Disambiguation (WSD) area was to explore the use of semantic domains in order to solve lexical ambiguity.", "labels": [], "entities": [{"text": "Word Sense Disambiguation (WSD)", "start_pos": 43, "end_pos": 74, "type": "TASK", "confidence": 0.7877296855052313}]}, {"text": "At the Senseval-2 competition we proposed anew approach to WSD, namely Domain Driven Disambiguation (DDD).", "labels": [], "entities": [{"text": "WSD", "start_pos": 59, "end_pos": 62, "type": "TASK", "confidence": 0.9452982544898987}, {"text": "Domain Driven Disambiguation (DDD)", "start_pos": 71, "end_pos": 105, "type": "TASK", "confidence": 0.7469450334707896}]}, {"text": "This approach consists of comparing the estimated domain of the context of the word to be disambiguated with the domains of its senses, exploiting the property of domains to be features of both texts and words.", "labels": [], "entities": []}, {"text": "The domains of the word senses can be either inferred from the learning data or derived from the information in WORDNET DOMAINS.", "labels": [], "entities": [{"text": "WORDNET DOMAINS", "start_pos": 112, "end_pos": 127, "type": "DATASET", "confidence": 0.7781780064105988}]}, {"text": "For Senseval-3, we refined the DDD methodology with a fully unsupervised technique -Domain Relevance Estimation (DRE) -for domain detection in texts.", "labels": [], "entities": [{"text": "domain detection in texts", "start_pos": 123, "end_pos": 148, "type": "TASK", "confidence": 0.8220374286174774}]}, {"text": "DRE is performed by an expectation maximization algorithm for the gaussian mixture model, which is exploited to differentiate relevant domain information in texts from noise.", "labels": [], "entities": [{"text": "DRE", "start_pos": 0, "end_pos": 3, "type": "METRIC", "confidence": 0.5867374539375305}]}, {"text": "This refined DDD system was presented in the English all-words task.", "labels": [], "entities": []}, {"text": "Originally DDD was developed to assess the usefulness of domain information for WSD.", "labels": [], "entities": [{"text": "WSD", "start_pos": 80, "end_pos": 83, "type": "TASK", "confidence": 0.9459202289581299}]}, {"text": "Thus it did not exploit other knowledge sources commonly used for disambiguation (e.g. syntactic patterns or collocations).", "labels": [], "entities": []}, {"text": "As a consequence the performance of the DDD system is quite good for precision (it disambiguates well the \"domain\" words), but as far as recall is concerned it is not competitive compared with other state of the art techniques.", "labels": [], "entities": [{"text": "precision", "start_pos": 69, "end_pos": 78, "type": "METRIC", "confidence": 0.9975335597991943}, {"text": "recall", "start_pos": 137, "end_pos": 143, "type": "METRIC", "confidence": 0.9917908906936646}]}, {"text": "On the other hand DDD outperforms the state of the art for unsupervised systems, demonstrating the usefulness of domain information for WSD.", "labels": [], "entities": [{"text": "WSD", "start_pos": 136, "end_pos": 139, "type": "TASK", "confidence": 0.8937432765960693}]}, {"text": "In addition, the DDD approach requires domain annotations for word senses (for the experiments we used WORDNET DOMAINS, a lexical resource developed at IRST).", "labels": [], "entities": [{"text": "IRST", "start_pos": 152, "end_pos": 156, "type": "DATASET", "confidence": 0.9245398640632629}]}, {"text": "Like all manual annotations, such an operation is costly (more than two man years have been spent for labeling the whole WORDNET DOMAINS structure) and affected by subjectivity.", "labels": [], "entities": [{"text": "WORDNET DOMAINS structure", "start_pos": 121, "end_pos": 146, "type": "DATASET", "confidence": 0.7664234240849813}]}, {"text": "Thus, one drawback of the DDD methodology was alack of portability among languages and among different sense repositories (unless we have synsetaligned WordNets).", "labels": [], "entities": []}, {"text": "Besides the improved DDD, our other proposals for Senseval-3 constitute an attempt to overcome these previous issues.", "labels": [], "entities": [{"text": "DDD", "start_pos": 21, "end_pos": 24, "type": "DATASET", "confidence": 0.7514752149581909}]}, {"text": "To deal with the problem of having a domainannotated WORDNET, we experimented with a novel methodology to automatically acquire domain information from corpora.", "labels": [], "entities": []}, {"text": "For this aim we estimated term similarity from a large scale corpus, exploiting the assumption that semantic domains are sets of very closely related terms.", "labels": [], "entities": []}, {"text": "In particular we implemented a variation of Latent Semantic Analysis (LSA) in order to obtain a vector representation for words, texts and synsets.", "labels": [], "entities": [{"text": "Latent Semantic Analysis (LSA)", "start_pos": 44, "end_pos": 74, "type": "TASK", "confidence": 0.7239970962206522}]}, {"text": "LSA performs a dimensionality reduction in the feature space describing both texts and words, capturing implicitly the notion of semantic domains required by DDD.", "labels": [], "entities": []}, {"text": "In order to perform disambiguation, LSA vectors have been estimated for the synsets in WORDNET.", "labels": [], "entities": [{"text": "WORDNET", "start_pos": 87, "end_pos": 94, "type": "DATASET", "confidence": 0.9585647583007812}]}, {"text": "We participated in the English all-words task also with a first prototype (DDD-LSA) that exploits LSA instead of WORDNET DOMAINS.", "labels": [], "entities": [{"text": "LSA", "start_pos": 98, "end_pos": 101, "type": "METRIC", "confidence": 0.8865085244178772}]}, {"text": "Kernels-WSD Catalan Lex-Sample Kernels-WSD Spanish Lex-Sample Kernels-WSD: IRST participation at Senseval-3 As far as lexical sample tasks are concerned, we participated in the English, Italian, Spanish, Catalan, and Basque tasks.", "labels": [], "entities": [{"text": "Kernels-WSD Catalan Lex-Sample Kernels-WSD Spanish Lex-Sample Kernels-WSD", "start_pos": 0, "end_pos": 73, "type": "TASK", "confidence": 0.7624750307628086}, {"text": "IRST participation at Senseval-3", "start_pos": 75, "end_pos": 107, "type": "DATASET", "confidence": 0.5259743481874466}]}, {"text": "For these tasks, we explored the direction of pattern abstraction for WSD.", "labels": [], "entities": [{"text": "pattern abstraction", "start_pos": 46, "end_pos": 65, "type": "TASK", "confidence": 0.7141365706920624}, {"text": "WSD", "start_pos": 70, "end_pos": 73, "type": "TASK", "confidence": 0.9214386343955994}]}, {"text": "Pattern abstraction is an effective methodology for WSD).", "labels": [], "entities": [{"text": "Pattern abstraction", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.8834215402603149}, {"text": "WSD", "start_pos": 52, "end_pos": 55, "type": "TASK", "confidence": 0.9863482713699341}]}, {"text": "Our preliminary experiments have been performed using TIES, a generalized Information Extraction environment developed at IRST that implements the boosted wrapper induction algorithm).", "labels": [], "entities": [{"text": "TIES", "start_pos": 54, "end_pos": 58, "type": "METRIC", "confidence": 0.8070942759513855}, {"text": "IRST", "start_pos": 122, "end_pos": 126, "type": "DATASET", "confidence": 0.9327356219291687}]}, {"text": "The main limitation of such an approach is, once more, the integration of different knowledge sources.", "labels": [], "entities": []}, {"text": "In particular, paradigmatic information seems hard to be represented in the TIES framework, motivating our decision to exploit kernel methods for WSD.", "labels": [], "entities": [{"text": "TIES framework", "start_pos": 76, "end_pos": 90, "type": "DATASET", "confidence": 0.8969260156154633}]}, {"text": "Kernel methods is an area of recent interest in Machine Learning.", "labels": [], "entities": [{"text": "Machine Learning", "start_pos": 48, "end_pos": 64, "type": "TASK", "confidence": 0.8059767484664917}]}, {"text": "Kernels are similarity functions between instances that allows to integrate different knowledge sources and to model explicitly linguistic insights inside the powerful framework of support vector machine classification.", "labels": [], "entities": [{"text": "support vector machine classification", "start_pos": 181, "end_pos": 218, "type": "TASK", "confidence": 0.6233185529708862}]}, {"text": "For Senseval-3 we implemented the Kernels-WSD system, which exploits kernel methods to perform the following operations: (i) pattern abstraction; (ii) combination of different knowledge sources, in particular domain information and syntagmatic information; (iii) integration of unsupervised term proximity estimation in the supervised framework.", "labels": [], "entities": []}, {"text": "The paper is structured as follows.", "labels": [], "entities": []}, {"text": "Section 2 introduces LSA and its relations with semantic domains.", "labels": [], "entities": []}, {"text": "Section 3 presents the systems for the English all-words task (i.e. DDD and DDD-LSA).", "labels": [], "entities": []}, {"text": "In section 4 our supervised approaches are reported.", "labels": [], "entities": []}, {"text": "In particular the TIES system is described in section 4.1, while the approach based on kernel methods is discussed in section 4.2.", "labels": [], "entities": [{"text": "TIES", "start_pos": 18, "end_pos": 22, "type": "DATASET", "confidence": 0.7299000024795532}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 2: DDD on the English all-words task.", "labels": [], "entities": [{"text": "DDD", "start_pos": 10, "end_pos": 13, "type": "TASK", "confidence": 0.7532709240913391}]}, {"text": " Table 3: DDD-LSA on the English all-words task.", "labels": [], "entities": []}, {"text": " Table 4: Performance of the TIES system", "labels": [], "entities": [{"text": "TIES", "start_pos": 29, "end_pos": 33, "type": "DATASET", "confidence": 0.6664147973060608}]}, {"text": " Table 5: Performance of the Kernels-WSD system", "labels": [], "entities": []}]}