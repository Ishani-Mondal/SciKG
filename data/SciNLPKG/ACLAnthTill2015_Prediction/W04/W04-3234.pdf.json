{"title": [{"text": "Trained Named Entity Recognition Using Distributional Clusters", "labels": [], "entities": [{"text": "Named Entity Recognition", "start_pos": 8, "end_pos": 32, "type": "TASK", "confidence": 0.6969297130902609}]}], "abstractContent": [{"text": "This work applies boosted wrapper induction (BWI), a machine learning algorithm for information extraction from semi-structured documents, to the problem of named entity recognition.", "labels": [], "entities": [{"text": "boosted wrapper induction (BWI)", "start_pos": 18, "end_pos": 49, "type": "TASK", "confidence": 0.5729163885116577}, {"text": "information extraction from semi-structured documents", "start_pos": 84, "end_pos": 137, "type": "TASK", "confidence": 0.8498035669326782}, {"text": "named entity recognition", "start_pos": 157, "end_pos": 181, "type": "TASK", "confidence": 0.6548492908477783}]}, {"text": "The default feature set of BWI is augmented with features based on distributional term clusters induced from a large unlabeled text corpus.", "labels": [], "entities": [{"text": "BWI", "start_pos": 27, "end_pos": 30, "type": "DATASET", "confidence": 0.6706836223602295}]}, {"text": "Using no traditional linguistic resources, such as syntactic tags or special-purpose gazetteers, this approach yields results near the state of the art in the MUC 6 named entity domain.", "labels": [], "entities": [{"text": "MUC 6 named entity domain", "start_pos": 159, "end_pos": 184, "type": "DATASET", "confidence": 0.8016484260559082}]}, {"text": "Supervised learning using features derived through unsupervised corpus analysis maybe regarded as an alternative to bootstrapping methods.", "labels": [], "entities": []}], "introductionContent": [{"text": "The problem of named entity recognition (NER) has recently received increasing attention.", "labels": [], "entities": [{"text": "named entity recognition (NER)", "start_pos": 15, "end_pos": 45, "type": "TASK", "confidence": 0.8052313178777695}]}, {"text": "Identification of generic semantic categories in text-such as mentions of people, organizations, locations, and temporal and numeric expressions-is a necessary first step in many applications of information extraction, information retrieval, and question answering.", "labels": [], "entities": [{"text": "Identification of generic semantic categories in text-such as mentions of people, organizations, locations", "start_pos": 0, "end_pos": 106, "type": "TASK", "confidence": 0.8786689003308614}, {"text": "information extraction", "start_pos": 195, "end_pos": 217, "type": "TASK", "confidence": 0.7527205348014832}, {"text": "information retrieval", "start_pos": 219, "end_pos": 240, "type": "TASK", "confidence": 0.812353253364563}, {"text": "question answering", "start_pos": 246, "end_pos": 264, "type": "TASK", "confidence": 0.9047724604606628}]}, {"text": "To a large extent, knowledge-poor methods suffice to yield good recognition performance.", "labels": [], "entities": []}, {"text": "In particular, supervised learning can be used to produce a system with performance at or near the state of the art ().", "labels": [], "entities": []}, {"text": "In the supervised learning framework, a corpus of (typically) a few hundred documents is annotated by hand to identify the entities of interest.", "labels": [], "entities": []}, {"text": "Features of local context are then used to train a system to distinguish instances from non-instances in novel texts.", "labels": [], "entities": []}, {"text": "Such features may include literal word tests, patterns of orthography, parts of speech, semantic categories, or membership in special-purpose gazetteers.", "labels": [], "entities": []}, {"text": "While supervised training greatly facilitates the development of a robust NER system, the requirement of a substantial training corpus remains an impediment to the rapid deployment of NER in new domains or new languages.", "labels": [], "entities": []}, {"text": "A number bush peters reagan noriega ...", "labels": [], "entities": []}, {"text": "japan california london chicago ...: Sample members of four clusters from the Wall Street Journal corpus. of researchers have therefore sought to exploit the availability of unlabeled documents, typically by bootstrapping a classifier using automatic labellings ().", "labels": [], "entities": [{"text": "Wall Street Journal corpus.", "start_pos": 78, "end_pos": 105, "type": "DATASET", "confidence": 0.955185130238533}]}, {"text": "Here, we investigate a different approach.", "labels": [], "entities": []}, {"text": "Using a distributional clustering technique called coclustering, we produce clusters which, intuitively, should be useful for NER.", "labels": [], "entities": [{"text": "NER", "start_pos": 126, "end_pos": 129, "type": "TASK", "confidence": 0.968501627445221}]}, {"text": "shows example terms from several sample clusters induced using a collection of documents from the Wall Street Journal (WSJ).", "labels": [], "entities": [{"text": "Wall Street Journal (WSJ)", "start_pos": 98, "end_pos": 123, "type": "DATASET", "confidence": 0.9341743290424347}]}, {"text": "Several papers have shown that distributional clustering yields categories that have high agreement with part of speech).", "labels": [], "entities": [{"text": "distributional clustering", "start_pos": 31, "end_pos": 56, "type": "TASK", "confidence": 0.6898639500141144}]}, {"text": "As the table illustrates, these clusters also tend to have a useful semantic dimension.", "labels": [], "entities": []}, {"text": "Clustering on the WSJ portion of the North American News corpus yields two clusters that clearly correspond to personal names, one for first names and one for last names.", "labels": [], "entities": [{"text": "WSJ portion of the North American News corpus", "start_pos": 18, "end_pos": 63, "type": "DATASET", "confidence": 0.9670504033565521}]}, {"text": "As an experiment, we scanned the MUC6 NER data set for token sequences consisting of zero or more members of the first name cluster (or an initial followed by a period), followed by one or more members of the last name cluster.", "labels": [], "entities": [{"text": "MUC6 NER data set", "start_pos": 33, "end_pos": 50, "type": "DATASET", "confidence": 0.9156193733215332}]}, {"text": "This simple procedure identified 64% of personal names with 77% precision.", "labels": [], "entities": [{"text": "precision", "start_pos": 64, "end_pos": 73, "type": "METRIC", "confidence": 0.9986202716827393}]}, {"text": "In this paper, we attempt to improve on this result by converting the clusters into features to be exploited by a general-purpose machine learning algorithm for information extraction.", "labels": [], "entities": [{"text": "information extraction", "start_pos": 161, "end_pos": 183, "type": "TASK", "confidence": 0.8382163047790527}]}, {"text": "In Section 2, we provide a brief description of Boosted Wrapper Induction (BWI), a pattern learner that has yielded promising results on semi-structured information extraction problems).", "labels": [], "entities": [{"text": "Boosted Wrapper Induction (BWI)", "start_pos": 48, "end_pos": 79, "type": "TASK", "confidence": 0.6175583799680074}, {"text": "information extraction", "start_pos": 153, "end_pos": 175, "type": "TASK", "confidence": 0.7151702493429184}]}, {"text": "In Section 3, we describe our clustering approach and its particular application.", "labels": [], "entities": []}, {"text": "Section 4 presents the results of our experiments.", "labels": [], "entities": []}, {"text": "Finally, in Section 5, we assess the significance of our contribution and attempt to identify promising future directions.", "labels": [], "entities": []}], "datasetContent": [{"text": "We experimented with the MUC 6 named entity data set, which consists of a training set of 318 documents, a validation set of 30 documents, and a test set of 30 documents.", "labels": [], "entities": [{"text": "MUC 6 named entity data set", "start_pos": 25, "end_pos": 52, "type": "DATASET", "confidence": 0.8880481521288554}]}, {"text": "All documents are annotated to identify three types of name (PERSON, ORGANIZATION, [germany][]: Sample boundary detectors for the seven MUC 6 fields produced by BWI using the baseline feature set.", "labels": [], "entities": [{"text": "PERSON", "start_pos": 61, "end_pos": 67, "type": "METRIC", "confidence": 0.99327552318573}, {"text": "ORGANIZATION", "start_pos": 69, "end_pos": 81, "type": "METRIC", "confidence": 0.9935418367385864}, {"text": "BWI", "start_pos": 161, "end_pos": 164, "type": "DATASET", "confidence": 0.618229866027832}]}, {"text": "An initial and terminal detector is shown for each field.", "labels": [], "entities": []}, {"text": "LOCATION), two types of temporal expression (DATE, TIME), and two types of numeric expression (MONEY, PERCENT).", "labels": [], "entities": [{"text": "LOCATION", "start_pos": 0, "end_pos": 8, "type": "METRIC", "confidence": 0.9198129773139954}, {"text": "DATE", "start_pos": 45, "end_pos": 49, "type": "METRIC", "confidence": 0.8876487016677856}, {"text": "TIME", "start_pos": 51, "end_pos": 55, "type": "METRIC", "confidence": 0.9371433258056641}, {"text": "MONEY", "start_pos": 95, "end_pos": 100, "type": "METRIC", "confidence": 0.7792245149612427}, {"text": "PERCENT", "start_pos": 102, "end_pos": 109, "type": "METRIC", "confidence": 0.9652096629142761}]}, {"text": "It is common to report performance in terms of precision, recall, and their harmonic mean (F1), a convention to which we adhere.", "labels": [], "entities": [{"text": "precision", "start_pos": 47, "end_pos": 56, "type": "METRIC", "confidence": 0.9995643496513367}, {"text": "recall", "start_pos": 58, "end_pos": 64, "type": "METRIC", "confidence": 0.9993870258331299}, {"text": "harmonic mean (F1)", "start_pos": 76, "end_pos": 94, "type": "METRIC", "confidence": 0.8344136953353882}]}, {"text": "For comparison with numbers reported in the literature, we used the learned extractors to produce mark-up and evaluated the result using the MUC 6 scorer.", "labels": [], "entities": [{"text": "MUC 6 scorer", "start_pos": 141, "end_pos": 153, "type": "DATASET", "confidence": 0.7913200259208679}]}, {"text": "The MUC 6 evaluation framework differs from ours in two key ways.", "labels": [], "entities": [{"text": "MUC 6 evaluation framework", "start_pos": 4, "end_pos": 30, "type": "DATASET", "confidence": 0.7277811020612717}]}, {"text": "Most importantly, all entity types are to be processed simultaneously.", "labels": [], "entities": []}, {"text": "We benefit from this framework, since spurious predictions for one entity type maybe superseded by correct predictions fora related type.", "labels": [], "entities": []}, {"text": "The opportunity is greatest for the three name types; in inspecting the false positives, we observed a number of confu-: Performance on the markup task, as scored by the MUC 6 scorer.", "labels": [], "entities": [{"text": "MUC 6 scorer", "start_pos": 170, "end_pos": 182, "type": "DATASET", "confidence": 0.8128952185312907}]}, {"text": "The MUC scorer is also more lenient than ours, awarding points for extraction of alternative strings and forgiving the inclusion of certain functional tokens in the extracted text.", "labels": [], "entities": [{"text": "MUC scorer", "start_pos": 4, "end_pos": 14, "type": "DATASET", "confidence": 0.8039945065975189}]}, {"text": "In moving to the multi-entity extraction setting, the obvious approach is to collect predictions from all extractors simultaneously.", "labels": [], "entities": [{"text": "multi-entity extraction", "start_pos": 17, "end_pos": 40, "type": "TASK", "confidence": 0.7169233113527298}]}, {"text": "However, this requires a strategy for dealing with overlapping predictions (e.g., a single text fragment labeled as both a person and organization).", "labels": [], "entities": []}, {"text": "We resolve such conflicts by preferring in each case the extraction with the highest confidence.", "labels": [], "entities": []}, {"text": "In order to render confidence scores more comparable, we normalized the weights of detectors making up each boundary classifier so they sum to one.", "labels": [], "entities": []}, {"text": "A comparison of with suggests the extent to which BWI benefits from the multifield mark-up setting.", "labels": [], "entities": [{"text": "BWI", "start_pos": 50, "end_pos": 53, "type": "METRIC", "confidence": 0.46375852823257446}]}, {"text": "Note that, here, we used only the \"formal\" test set for evaluation, in contrast with the numbers in, which combine the two test sets.", "labels": [], "entities": []}, {"text": "The lift we observe from cluster features is also in evidence here, and is most evident as an increase in recall, particularly of PERSON and ORGANI-ZATION.", "labels": [], "entities": [{"text": "recall", "start_pos": 106, "end_pos": 112, "type": "METRIC", "confidence": 0.9994625449180603}, {"text": "PERSON", "start_pos": 130, "end_pos": 136, "type": "METRIC", "confidence": 0.9371431469917297}, {"text": "ORGANI-ZATION", "start_pos": 141, "end_pos": 154, "type": "METRIC", "confidence": 0.9391393661499023}]}, {"text": "There is now also an increase in global precision, attributable in large part to the benefit of extracting multiple fields simultaneously.", "labels": [], "entities": [{"text": "precision", "start_pos": 40, "end_pos": 49, "type": "METRIC", "confidence": 0.9882200956344604}]}, {"text": "The F1 score produced by BWI is comparable to the best machine-learning-based results re-ported elsewhere., reports summary F1 of 0.93 on the same test set, but using a model trained on 450,000 words.", "labels": [], "entities": [{"text": "F1 score", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.9748754799365997}, {"text": "BWI", "start_pos": 25, "end_pos": 28, "type": "DATASET", "confidence": 0.8600742816925049}, {"text": "F1", "start_pos": 124, "end_pos": 126, "type": "METRIC", "confidence": 0.6771814823150635}]}, {"text": "We count approximately 130,000 words in the experiments reported here.", "labels": [], "entities": []}, {"text": "The numbers reported by, for PERSON, ORGANIZATION, and LOCATION (F1 of 0.947, 0.815, and 0.925, respectively), are slightly better than the numbers BWI reaches on the same fields.", "labels": [], "entities": [{"text": "PERSON", "start_pos": 29, "end_pos": 35, "type": "METRIC", "confidence": 0.7225473523139954}, {"text": "ORGANIZATION", "start_pos": 37, "end_pos": 49, "type": "METRIC", "confidence": 0.9971522092819214}, {"text": "LOCATION", "start_pos": 55, "end_pos": 63, "type": "METRIC", "confidence": 0.9975800514221191}, {"text": "F1", "start_pos": 65, "end_pos": 67, "type": "METRIC", "confidence": 0.9957906603813171}, {"text": "BWI", "start_pos": 148, "end_pos": 151, "type": "METRIC", "confidence": 0.5610588788986206}]}, {"text": "Note, however, that the features provided to their learner include syntactic labels and carefully engineered semantic categories, whereas we eschew knowledge-and labor-intensive resources.", "labels": [], "entities": []}, {"text": "This has important implications for the portability of the approaches to new domains and languages.", "labels": [], "entities": []}, {"text": "By taking a few post-processing steps, it is possible to realize further improvements.", "labels": [], "entities": []}, {"text": "For example, the learner occasionally identifies terms and phrases which some simple rules can reliably reject.", "labels": [], "entities": []}, {"text": "By suppressing any prediction that consists entirely of a stopword, we increase the precision of both ORGA-NIZATION and LOCATION to 0.86 (from 0.84 and 0.80) and overall F1 to 0.88.", "labels": [], "entities": [{"text": "precision", "start_pos": 84, "end_pos": 93, "type": "METRIC", "confidence": 0.9996734857559204}, {"text": "ORGA-NIZATION", "start_pos": 102, "end_pos": 115, "type": "METRIC", "confidence": 0.9976590871810913}, {"text": "LOCATION", "start_pos": 120, "end_pos": 128, "type": "METRIC", "confidence": 0.9754675030708313}, {"text": "F1", "start_pos": 170, "end_pos": 172, "type": "METRIC", "confidence": 0.9997760653495789}]}, {"text": "We can also exploit what Cucerzan and Yarowsky (1999) call the one sense per discourse phenomenon, the tendency of terms to have a fixed meaning within a single document.", "labels": [], "entities": []}, {"text": "By marking up unmarked strings that match extracted entity instances in the same document, we can improve the recall of some fields.", "labels": [], "entities": [{"text": "recall", "start_pos": 110, "end_pos": 116, "type": "METRIC", "confidence": 0.9983015060424805}]}, {"text": "We added this postprocessing step for the PERSON and ORGANI-ZATION fields.", "labels": [], "entities": [{"text": "PERSON", "start_pos": 42, "end_pos": 48, "type": "METRIC", "confidence": 0.69830322265625}, {"text": "ORGANI-ZATION", "start_pos": 53, "end_pos": 66, "type": "METRIC", "confidence": 0.9600902199745178}]}, {"text": "This increased recall of PERSON from 0.95 to 0.98 and of ORGANIZATION from 0.74 to 0.79 with minimal changes to precision and a slight improvement in summary F1.", "labels": [], "entities": [{"text": "recall", "start_pos": 15, "end_pos": 21, "type": "METRIC", "confidence": 0.9997333884239197}, {"text": "PERSON", "start_pos": 25, "end_pos": 31, "type": "METRIC", "confidence": 0.9426911473274231}, {"text": "ORGANIZATION", "start_pos": 57, "end_pos": 69, "type": "METRIC", "confidence": 0.9982473850250244}, {"text": "precision", "start_pos": 112, "end_pos": 121, "type": "METRIC", "confidence": 0.9993972778320312}, {"text": "summary", "start_pos": 150, "end_pos": 157, "type": "METRIC", "confidence": 0.9339374303817749}, {"text": "F1", "start_pos": 158, "end_pos": 160, "type": "METRIC", "confidence": 0.7815394401550293}]}], "tableCaptions": [{"text": " Table 4: Sample boundary detectors for the seven  MUC 6 fields produced by BWI using the expanded  feature set.", "labels": [], "entities": [{"text": "MUC 6 fields", "start_pos": 51, "end_pos": 63, "type": "DATASET", "confidence": 0.6681338349978129}, {"text": "BWI", "start_pos": 76, "end_pos": 79, "type": "DATASET", "confidence": 0.48897096514701843}]}, {"text": " Table 5: Most frequent members of clusters refer- enced by detectors in", "labels": [], "entities": []}, {"text": " Table 7: Performance on the markup task, as scored  by the MUC 6 scorer.", "labels": [], "entities": [{"text": "MUC 6 scorer", "start_pos": 60, "end_pos": 72, "type": "DATASET", "confidence": 0.8960775335629781}]}]}