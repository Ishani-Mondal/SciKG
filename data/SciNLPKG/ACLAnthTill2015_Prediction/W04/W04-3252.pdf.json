{"title": [{"text": "TextRank: Bringing Order into Texts", "labels": [], "entities": [{"text": "Bringing Order into Texts", "start_pos": 10, "end_pos": 35, "type": "TASK", "confidence": 0.8388154953718185}]}], "abstractContent": [{"text": "In this paper, we introduce TextRank-a graph-based ranking model for text processing, and show how this model can be successfully used in natural language applications.", "labels": [], "entities": []}, {"text": "In particular, we propose two innovative unsupervised methods for keyword and sentence extraction, and show that the results obtained compare favorably with previously published results on established benchmarks.", "labels": [], "entities": [{"text": "keyword and sentence extraction", "start_pos": 66, "end_pos": 97, "type": "TASK", "confidence": 0.597196415066719}]}], "introductionContent": [{"text": "Graph-based ranking algorithms like Kleinberg's HITS algorithm) or Google's PageRank () have been successfully used in citation analysis, social networks, and the analysis of the link-structure of the World Wide Web.", "labels": [], "entities": [{"text": "citation analysis", "start_pos": 119, "end_pos": 136, "type": "TASK", "confidence": 0.9516662359237671}]}, {"text": "Arguably, these algorithms can be singled out as key elements of the paradigm-shift triggered in the field of Web search technology, by providing a Web page ranking mechanism that relies on the collective knowledge of Web architects rather than individual content analysis of Web pages.", "labels": [], "entities": []}, {"text": "In short, a graph-based ranking algorithm is away of deciding on the importance of a vertex within a graph, by taking into account global information recursively computed from the entire graph, rather than relying only on local vertex-specific information.", "labels": [], "entities": []}, {"text": "Applying a similar line of thinking to lexical or semantic graphs extracted from natural language documents, results in a graph-based ranking model that can be applied to a variety of natural language processing applications, where knowledge drawn from an entire text is used in making local ranking/selection decisions.", "labels": [], "entities": []}, {"text": "Such text-oriented ranking methods can be applied to tasks ranging from automated extraction of keyphrases, to extractive summarization and word sense disambiguation (.", "labels": [], "entities": [{"text": "extractive summarization", "start_pos": 111, "end_pos": 135, "type": "TASK", "confidence": 0.6363528668880463}, {"text": "word sense disambiguation", "start_pos": 140, "end_pos": 165, "type": "TASK", "confidence": 0.6647159655888876}]}, {"text": "In this paper, we introduce the TextRank graphbased ranking model for graphs extracted from natural language texts.", "labels": [], "entities": []}, {"text": "We investigate and evaluate the application of TextRank to two language processing tasks consisting of unsupervised keyword and sentence extraction, and show that the results obtained with TextRank are competitive with state-of-the-art systems developed in these areas.", "labels": [], "entities": [{"text": "sentence extraction", "start_pos": 128, "end_pos": 147, "type": "TASK", "confidence": 0.7341537475585938}]}], "datasetContent": [{"text": "We evaluate the TextRank sentence extraction algorithm on a single-document summarization task, using 567 news articles provided during the Document Understanding Evaluations 2002).", "labels": [], "entities": [{"text": "TextRank sentence extraction", "start_pos": 16, "end_pos": 44, "type": "TASK", "confidence": 0.5894324680169424}]}, {"text": "For each article, TextRank generates an 100-words summary -the task undertaken by other systems participating in this single document summarization task.", "labels": [], "entities": []}, {"text": "For evaluation, we are using the ROUGE evaluation toolkit, which is a method based on Ngram statistics, found to be highly correlated with human evaluations (.", "labels": [], "entities": []}, {"text": "Two manually produced reference summaries are provided, and used in the evaluation process 5 . Weights are listed to the right or above the edge they correspond to.", "labels": [], "entities": []}, {"text": "Similar weights are computed for each edge in the graph, but are not displayed due to space restrictions.", "labels": [], "entities": []}, {"text": "ROUGE is available at http://www.isi.edu/\u02dccyl/ROUGE/.", "labels": [], "entities": [{"text": "ROUGE", "start_pos": 0, "end_pos": 5, "type": "METRIC", "confidence": 0.5668337941169739}, {"text": "ROUGE", "start_pos": 46, "end_pos": 51, "type": "METRIC", "confidence": 0.9043890237808228}]}, {"text": "Fifteen different systems participated in this task, and we compare the performance of TextRank with the top five performing systems, as well as with the baseline proposed by the DUC evaluators -consisting of a 100-word summary constructed by taking the first sentences in each article.", "labels": [], "entities": [{"text": "TextRank", "start_pos": 87, "end_pos": 95, "type": "DATASET", "confidence": 0.8899356126785278}, {"text": "DUC evaluators", "start_pos": 179, "end_pos": 193, "type": "DATASET", "confidence": 0.9350955784320831}]}, {"text": "shows the results obtained on this data set of 567 news articles, including the results for TextRank (shown in bold), the baseline, and the results of the top five performing systems in the DUC 2002 single document summarization task  Discussion.", "labels": [], "entities": [{"text": "TextRank", "start_pos": 92, "end_pos": 100, "type": "DATASET", "confidence": 0.9350581765174866}, {"text": "DUC 2002 single document summarization task  Discussion", "start_pos": 190, "end_pos": 245, "type": "TASK", "confidence": 0.7064102292060852}]}, {"text": "TextRank succeeds in identifying the most important sentences in a text based on information exclusively drawn from the text itself.", "labels": [], "entities": [{"text": "TextRank", "start_pos": 0, "end_pos": 8, "type": "DATASET", "confidence": 0.8508594632148743}]}, {"text": "Unlike other supervised systems, which attempt to learn what makes a good summary by training on collections of summaries built for other articles, TextRank is fully unsupervised, and relies only on the given text to derive an extractive summary, which represents a summarization model closer to what humans are doing when producing an abstract fora given document.", "labels": [], "entities": []}, {"text": "Notice that TextRank goes beyond the sentence \"connectivity\" in a text.", "labels": [], "entities": []}, {"text": "For instance, sentence 15 in the example provided in would not be identified as \"important\" based on the number of connections it has with other vertices in the graph, but it is identified as \"important\" by TextRank (and by humans -see the reference summaries displayed in the same.", "labels": [], "entities": [{"text": "TextRank", "start_pos": 207, "end_pos": 215, "type": "DATASET", "confidence": 0.9474143981933594}]}, {"text": "Another important aspect of TextRank is that it gives a ranking overall sentences in a text -which means that it can be easily adapted to extracting very short summaries (headlines consisting of one sentence), or longer more explicative summaries, consisting of more than 100 words.", "labels": [], "entities": []}, {"text": "We are also investigating combinations of keyphrase and sentence extraction techniques as a method for building short/long summaries.", "labels": [], "entities": [{"text": "sentence extraction", "start_pos": 56, "end_pos": 75, "type": "TASK", "confidence": 0.7071548253297806}]}, {"text": "Finally, another advantage of TextRank over previously proposed methods for building extractive summaries is the fact that it does not require training corpora, which makes it easily adaptable to other languages or domains.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Results for automatic keyword extraction using TextRank or supervised learning", "labels": [], "entities": [{"text": "automatic keyword extraction", "start_pos": 22, "end_pos": 50, "type": "TASK", "confidence": 0.6057751874128977}, {"text": "TextRank", "start_pos": 57, "end_pos": 65, "type": "DATASET", "confidence": 0.926439642906189}]}, {"text": " Table 2: Results for single document summarization:  TextRank, top 5 (out of 15) DUC 2002 systems, and  baseline. Evaluation takes into account (a) all words;  (b) stemmed words; (c) stemmed words, and no stop- words.", "labels": [], "entities": [{"text": "TextRank", "start_pos": 54, "end_pos": 62, "type": "DATASET", "confidence": 0.9012444019317627}, {"text": "DUC 2002", "start_pos": 82, "end_pos": 90, "type": "DATASET", "confidence": 0.9233182072639465}]}]}