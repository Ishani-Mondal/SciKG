{"title": [{"text": "The Italian Lexical Sample Task at SENSEVAL-3", "labels": [], "entities": [{"text": "Italian Lexical Sample", "start_pos": 4, "end_pos": 26, "type": "DATASET", "confidence": 0.7919427355130514}, {"text": "SENSEVAL-3", "start_pos": 35, "end_pos": 45, "type": "TASK", "confidence": 0.33824029564857483}]}], "abstractContent": [{"text": "The Italian lexical sample task at SENSEVAL-3 provided a framework to evaluate supervised and semi-supervised WSD systems.", "labels": [], "entities": [{"text": "WSD systems", "start_pos": 110, "end_pos": 121, "type": "TASK", "confidence": 0.8976902961730957}]}, {"text": "This paper reports on the task preparation-which offered the opportunity to review and refine the Italian MultiWordNet-and on the results of the six participants, focussing on both the manual and automatic tagging procedures.", "labels": [], "entities": []}], "introductionContent": [{"text": "The task consisted in automatically determining the correct meaning of a word within a given context (i.e. a short text snippet).", "labels": [], "entities": [{"text": "determining the correct meaning of a word within a given context", "start_pos": 36, "end_pos": 100, "type": "TASK", "confidence": 0.7104757373983209}]}, {"text": "Systems' results were compared on the one hand to those achieved by human annotators (upper bound), and on the other hand to those returned by a basic algorithm (baseline).", "labels": [], "entities": []}, {"text": "In the second section of this paper an overview of the task preparation is given and in the following one the main features of the participating systems are briefly outlined and the results of the evaluation exercise are presented.", "labels": [], "entities": []}, {"text": "In the conclusions we give an overall judgement of the outcome of the task, suggesting possible improvements for the next campaign.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1. Manual Annotation Results", "labels": [], "entities": []}, {"text": " Table 2. Automatic Annotation Results (fine-grained score)", "labels": [], "entities": [{"text": "Automatic Annotation", "start_pos": 10, "end_pos": 30, "type": "METRIC", "confidence": 0.7987706065177917}]}]}