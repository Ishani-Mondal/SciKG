{"title": [{"text": "Annotating Discourse Connectives And Their Arguments", "labels": [], "entities": []}], "abstractContent": [{"text": "This paper describes anew, large scale discourse-level annotation project-the Penn Discourse TreeBank (PDTB).", "labels": [], "entities": [{"text": "Penn Discourse TreeBank (PDTB)", "start_pos": 78, "end_pos": 108, "type": "DATASET", "confidence": 0.9489087661107382}]}, {"text": "We present an approach to annotating a level of discourse structure that is based on identifying discourse connectives and their arguments.", "labels": [], "entities": []}, {"text": "The PDTB is being built directly on top of the Penn Tree-Bank and Propbank, thus supporting the extraction of useful syntactic and semantic features and providing a richer substrate for the development and evaluation of practical algorithms.", "labels": [], "entities": [{"text": "Penn Tree-Bank", "start_pos": 47, "end_pos": 61, "type": "DATASET", "confidence": 0.994409590959549}]}, {"text": "We provide a detailed preliminary analysis of inter-annotator agreement-both the level of agreement and the types of inter-annotator variation .", "labels": [], "entities": []}], "introductionContent": [{"text": "Large scale annotated corpora have played a critical role in speech and natural language research.", "labels": [], "entities": []}, {"text": "The Penn TreeBank (PTB) is an example of such a resource with worldwide impact on natural language processing.", "labels": [], "entities": [{"text": "Penn TreeBank (PTB)", "start_pos": 4, "end_pos": 23, "type": "DATASET", "confidence": 0.9738907814025879}]}, {"text": "However, the PTB deals with text only at the sentence level: with the demand for more powerful NLP applications comes a need for greater richness in annotation.", "labels": [], "entities": []}, {"text": "At the sentence level, Penn Propbank is adding predicate-argument annotation to sentences in PTB ().", "labels": [], "entities": [{"text": "Penn Propbank", "start_pos": 23, "end_pos": 36, "type": "DATASET", "confidence": 0.9811297655105591}, {"text": "PTB", "start_pos": 93, "end_pos": 96, "type": "DATASET", "confidence": 0.9037963151931763}]}, {"text": "At the discourselevel are efforts to produce corpora annotated with rhetorical relations.", "labels": [], "entities": []}, {"text": "This paper describes a more basic discourse-level annotation project -the Penn Discourse TreeBank (PDTB) -that aims to produce a large-scale corpus in which discourse connectives are annotated, along with their arguments.", "labels": [], "entities": [{"text": "Penn Discourse TreeBank (PDTB)", "start_pos": 74, "end_pos": 104, "type": "DATASET", "confidence": 0.942191998163859}]}, {"text": "There have been several approaches to describing discourse in terms of discourse relations.", "labels": [], "entities": []}, {"text": "In these approaches, the additional meaning the discourse contributes beyond the sentence derives from discourse relations.", "labels": [], "entities": []}, {"text": "Specification of the discourse relations fora discourse thus constitutes a description of a certain level of discourse structure.", "labels": [], "entities": []}, {"text": "Rather than starting from (abstract) discourse relations, we describe an approach to annotating a largescale corpus in terms of a more basic characterisation of discourse structure in terms of discourse connectives and their arguments.", "labels": [], "entities": []}, {"text": "The motivation for such an approach stems from work by,, which integrates sentence level structures with discourse level structure (using tree-adjoining grammars for both cases, LTAG and DLTAG, respectively).", "labels": [], "entities": []}, {"text": "This allows structural composition and its associated semantic composition at the sentence level to be smoothly carried over to the discourse level, a goal also shared by, and, among others.", "labels": [], "entities": []}, {"text": "Discourse connectives and their arguments can be successfully annotated with high reliability (cf. Section 4).", "labels": [], "entities": [{"text": "reliability", "start_pos": 82, "end_pos": 93, "type": "METRIC", "confidence": 0.982459306716919}]}, {"text": "This is not surprising, given that the task resembles that of annotating verbs and their arguments at the sentence level).", "labels": [], "entities": []}, {"text": "In fact, we use a fine-grained, lexically grounded annotation in which argument labels are specific to the dis- In the PDTB annotations, we have deliberately adopted a policy to make the annotations independent of the DLTAG framework for two reasons: (1) to make the annotated corpus widely useful to researchers working in different frameworks and (2) to make the annotators' task easier, thereby increasing interannotator reliability.", "labels": [], "entities": []}, {"text": "However, the approaches in Gardent (1997),, and Polanyi and van den are different in two ways: a) the process by which discourse derives compositional aspects of meaning is considered entirely separate from how clauses do so, and b) only two mechanisms are used for deriving discourse semantics -compositional semantics and inference.", "labels": [], "entities": []}, {"text": "course connectives involved, in much the same way as in.", "labels": [], "entities": []}, {"text": "In contrast, a recent attempt () at using RST-type relations for annotating a much smaller corpus has already revealed difficulties involved in reliably annotating more abstract discourse relations.", "labels": [], "entities": []}, {"text": "Moreover, this type of annotation does not contain any record of the basis on which a relation was assigned.", "labels": [], "entities": []}, {"text": "The paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 provides a brief overview of the fundamental ideas that provide the basis for the design of the PDTB annotation.", "labels": [], "entities": []}, {"text": "Section 3 gives a detailed description of the annotation project, including information about the size of the corpus, completed annotations as well as annotation instructions as formulated in the guidelines.", "labels": [], "entities": []}, {"text": "Section 4 presents data analysis based on current annotations as well as results from inter-annotator agreement.", "labels": [], "entities": []}, {"text": "Section 5 wraps up with a summary of the work.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Distribution of Agreement by Connective, with  ARG1 and ARG2 Annotations Counted Independently", "labels": [], "entities": [{"text": "Distribution of Agreement", "start_pos": 10, "end_pos": 35, "type": "TASK", "confidence": 0.8670356671015421}, {"text": "ARG1", "start_pos": 57, "end_pos": 61, "type": "DATASET", "confidence": 0.9471721053123474}]}, {"text": " Table 2: Distribution of Agreement by Connective, with  ARG1 and ARG2 Annotations Counted Together", "labels": [], "entities": [{"text": "Distribution of Agreement", "start_pos": 10, "end_pos": 35, "type": "TASK", "confidence": 0.869939923286438}, {"text": "ARG1", "start_pos": 57, "end_pos": 61, "type": "DATASET", "confidence": 0.9356637001037598}]}, {"text": " Table 4. Note that here again, the number of disagree- ments reduces to half using the partial match measure for  the parenthetical and dependent clause classes, giving us  92.6% agreement overall.", "labels": [], "entities": [{"text": "agreement", "start_pos": 180, "end_pos": 189, "type": "METRIC", "confidence": 0.9749554991722107}]}, {"text": " Table 4: Disagreement Classification for Implicit Con- nective ARG Annotations", "labels": [], "entities": [{"text": "Disagreement Classification", "start_pos": 10, "end_pos": 37, "type": "TASK", "confidence": 0.8844811320304871}, {"text": "Implicit Con- nective ARG Annotations", "start_pos": 42, "end_pos": 79, "type": "TASK", "confidence": 0.5632404188315073}]}]}