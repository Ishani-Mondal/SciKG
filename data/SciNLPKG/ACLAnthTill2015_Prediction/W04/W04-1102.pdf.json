{"title": [{"text": "A Preliminary Study on Probabilistic Models for Chinese Abbreviations", "labels": [], "entities": []}], "abstractContent": [{"text": "Chinese abbreviations are widely used in the modern Chinese texts.", "labels": [], "entities": []}, {"text": "They area special form of unknown words, including many named entities.", "labels": [], "entities": []}, {"text": "This results in difficulty for correct Chinese processing.", "labels": [], "entities": [{"text": "correct Chinese processing", "start_pos": 31, "end_pos": 57, "type": "TASK", "confidence": 0.6095681488513947}]}, {"text": "In this study, the Chinese abbreviation problem is regarded as an error recovery problem in which the suspect root words are the \"errors\" to be recovered from a set of candidates.", "labels": [], "entities": [{"text": "error recovery", "start_pos": 66, "end_pos": 80, "type": "TASK", "confidence": 0.6481844037771225}]}, {"text": "Such a problem is mapped to an HMM-based generation model for both abbreviation identification and root word recovery, and is integrated as part of a unified word segmentation model when the input extends to a complete sentence.", "labels": [], "entities": [{"text": "abbreviation identification", "start_pos": 67, "end_pos": 94, "type": "TASK", "confidence": 0.8912835419178009}, {"text": "root word recovery", "start_pos": 99, "end_pos": 117, "type": "TASK", "confidence": 0.6428285539150238}, {"text": "word segmentation", "start_pos": 158, "end_pos": 175, "type": "TASK", "confidence": 0.7692552506923676}]}, {"text": "Two major experiments are conducted to test the abbreviation models.", "labels": [], "entities": []}, {"text": "In the first experiment, an attempt is made to guess the abbreviations of the root words.", "labels": [], "entities": []}, {"text": "An accuracy rate of 72% is observed.", "labels": [], "entities": [{"text": "accuracy rate", "start_pos": 3, "end_pos": 16, "type": "METRIC", "confidence": 0.9818437397480011}]}, {"text": "In contrast, a second experiment is conducted to guess the root words from abbreviations.", "labels": [], "entities": []}, {"text": "Some submodels could achieve as high as 51% accuracy with the simple HMM-based model.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 44, "end_pos": 52, "type": "METRIC", "confidence": 0.9993715882301331}]}, {"text": "Some quantitative observations against heuristic abbreviation knowledge about Chinese are also observed.", "labels": [], "entities": []}], "introductionContent": [{"text": "The modern Chinese language is a highly abbreviated one due to the mixed uses of ancient single character words as well as modern multi-character words and compound words.", "labels": [], "entities": []}, {"text": "The abbreviated form and root form are used interchangeably everywhere in the current Chinese articles.", "labels": [], "entities": []}, {"text": "Some news articles may contain about 20% of sentences that have suspect abbreviated words in them.", "labels": [], "entities": []}, {"text": "Since abbreviations cannot be enumerated in a dictionary, it forms a special class of unknown words, many of which originate from named entities.", "labels": [], "entities": []}, {"text": "Many other open class words are also abbreviatable.", "labels": [], "entities": []}, {"text": "This particular class thus introduces complication for Chinese language processing, including the fundamental word segmentation process (Chiang 1992,) and many word-based applications.", "labels": [], "entities": [{"text": "Chinese language processing", "start_pos": 55, "end_pos": 82, "type": "TASK", "confidence": 0.6650813420613607}, {"text": "word segmentation", "start_pos": 110, "end_pos": 127, "type": "TASK", "confidence": 0.7072969973087311}]}, {"text": "For instance, a keyword-based information retrieval system may requires the two forms, such as \" \ud97b\udf59 \ud97b\udf59 \" and \" \ud97b\udf59 \ud97b\udf59 \ud97b\udf59 \ud97b\udf59 \" (\"legislators\"), in order not to miss any relevant documents.", "labels": [], "entities": [{"text": "keyword-based information retrieval", "start_pos": 16, "end_pos": 51, "type": "TASK", "confidence": 0.6390706400076548}]}, {"text": "The Chinese word segmentation process is also significantly degraded by the existence of unknown words, including unknown abbreviations.", "labels": [], "entities": [{"text": "Chinese word segmentation", "start_pos": 4, "end_pos": 29, "type": "TASK", "confidence": 0.5746502975622813}]}, {"text": "There are many heuristics for Chinese abbreviations.", "labels": [], "entities": []}, {"text": "Such heuristics, however, can easily break.", "labels": [], "entities": []}, {"text": "Currently, only some quantitative approaches (Huang 1994a, 94b) are available in predicting the presentation of an abbreviation.", "labels": [], "entities": [{"text": "predicting the presentation of an abbreviation", "start_pos": 81, "end_pos": 127, "type": "TASK", "confidence": 0.7892618576685587}]}, {"text": "Since such formulations regard the word segmentation process and abbreviation identification as two independent processes, they probably cannot optimize the identification process jointly with the word segmentation process, and thus may lose the useful contextual information.", "labels": [], "entities": [{"text": "word segmentation process", "start_pos": 35, "end_pos": 60, "type": "TASK", "confidence": 0.7675903042157491}, {"text": "abbreviation identification", "start_pos": 65, "end_pos": 92, "type": "TASK", "confidence": 0.8408041596412659}, {"text": "word segmentation", "start_pos": 197, "end_pos": 214, "type": "TASK", "confidence": 0.6999628841876984}]}, {"text": "Some class-based segmentation models well integrate the identification of some regular non-lexicalized units (such as named entities).", "labels": [], "entities": []}, {"text": "However, the abbreviation process can be applied to almost all word forms (or classes of words).", "labels": [], "entities": []}, {"text": "Therefore, this particular word formation process may have to be handled as a separate layer in the segmentation process.", "labels": [], "entities": [{"text": "word formation process", "start_pos": 27, "end_pos": 49, "type": "TASK", "confidence": 0.8114928007125854}]}, {"text": "To resolve the Chinese abbreviation problems and integrate its identification into the word segmentation process, this study proposes to regard the abbreviation problem in the word segmentation process as an \"error recovery\" problem in which the suspect root words are the \"errors\" to be recovered from a set of candidates according to some generation probability criteria.", "labels": [], "entities": [{"text": "word segmentation process", "start_pos": 87, "end_pos": 112, "type": "TASK", "confidence": 0.7810606360435486}, {"text": "word segmentation process", "start_pos": 176, "end_pos": 201, "type": "TASK", "confidence": 0.7957274814446768}]}, {"text": "This idea implies that an HMM-based model for identifying Chinese abbreviations could be effective in either identifying the existence of an abbreviation or the recovery of the root words from an abbreviation.", "labels": [], "entities": []}, {"text": "We therefore start with a unified word segmentation model so that both processes can be handled at the same time, and when the input is reduced to a single abbreviated word, the model can be equally useful for recovering its root.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 34, "end_pos": 51, "type": "TASK", "confidence": 0.7708940804004669}]}, {"text": "As aside effect of using HMM-based formulation, we expect that a large abbreviation dictionary could be derived from a large corpus or from web documents through the training process of the unified word segmentation model automatically.", "labels": [], "entities": []}, {"text": "Section 2 will show our HMM models and the three abbreviation problems correspond to the three basic HMM problems.", "labels": [], "entities": []}, {"text": "Section 3 will show the experiment setup.", "labels": [], "entities": []}, {"text": "Section 4 will examine the experiments to guess abbreviations from root or vice versa.", "labels": [], "entities": []}], "datasetContent": [{"text": "The unified model can be applied to a whole sentence which contains abbreviations during word segmentation.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 89, "end_pos": 106, "type": "TASK", "confidence": 0.7129958271980286}]}, {"text": "When the input is reduced to a single abbreviated word (or compound), it can also be applied to recover the underlying root constituent words (without consulting contextual words).", "labels": [], "entities": []}, {"text": "In this paper, we will only focus on the abbreviation word recovery problems.", "labels": [], "entities": [{"text": "abbreviation word recovery", "start_pos": 41, "end_pos": 67, "type": "TASK", "confidence": 0.6724326908588409}]}, {"text": "Two major experiments are conducted.", "labels": [], "entities": []}, {"text": "The first experiment is to guess the most likely abbreviation form fora word using various feature combinations; the second is to guess the root word from an abbreviation.", "labels": [], "entities": []}, {"text": "The following sections will give more details.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 3. Test Set Performance for  Abbreviation Generation with Combined  Features.", "labels": [], "entities": [{"text": "Abbreviation Generation", "start_pos": 36, "end_pos": 59, "type": "TASK", "confidence": 0.7923852205276489}]}, {"text": " Table 4. Abbreviation Recovery Performance.", "labels": [], "entities": [{"text": "Abbreviation Recovery", "start_pos": 10, "end_pos": 31, "type": "TASK", "confidence": 0.6570923924446106}]}]}