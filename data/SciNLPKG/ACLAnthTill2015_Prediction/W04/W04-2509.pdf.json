{"title": [{"text": "Handling Information Access Dialogue through QA Technologies -A novel challenge for open-domain question answering", "labels": [], "entities": [{"text": "Handling Information Access Dialogue", "start_pos": 0, "end_pos": 36, "type": "TASK", "confidence": 0.7273756563663483}, {"text": "question answering", "start_pos": 96, "end_pos": 114, "type": "TASK", "confidence": 0.7424208372831345}]}], "abstractContent": [{"text": "A novel challenge for evaluating open-domain question answering technologies is proposed.", "labels": [], "entities": [{"text": "question answering", "start_pos": 45, "end_pos": 63, "type": "TASK", "confidence": 0.7118503600358963}]}, {"text": "In this challenge, question answering systems are supposed to be used interactively to answer a series of related questions, whereas in the conventional setting, systems answer isolated questions one by one.", "labels": [], "entities": [{"text": "question answering", "start_pos": 19, "end_pos": 37, "type": "TASK", "confidence": 0.848284512758255}]}, {"text": "Such an interaction occurs in the case of gathering information fora report on a specific topic, or when browsing information of interest to the user.", "labels": [], "entities": []}, {"text": "In this paper, first, we explain the design of the challenge.", "labels": [], "entities": []}, {"text": "We then discuss its reality and show how the capabilities measured by the challenge are useful and important in practical situations, and that the difficulty of the challenge is proper for evaluating the current state of open-domain question answering technologies.", "labels": [], "entities": [{"text": "question answering", "start_pos": 233, "end_pos": 251, "type": "TASK", "confidence": 0.6731716096401215}]}], "introductionContent": [{"text": "Open-domain question answering technologies allow users to ask a question in natural language and obtain the answer itself rather than a list of documents that contain the answer.", "labels": [], "entities": [{"text": "question answering", "start_pos": 12, "end_pos": 30, "type": "TASK", "confidence": 0.7305446714162827}]}, {"text": "These technologies make it possible to retrieve information itself rather than merely documents, and will lead to new styles of information access).", "labels": [], "entities": []}, {"text": "The recent research on open-domain question answering concentrates on answering factoid questions one by one in isolation from each other.", "labels": [], "entities": [{"text": "question answering", "start_pos": 35, "end_pos": 53, "type": "TASK", "confidence": 0.713776245713234}]}, {"text": "Such systems that answer isolated factoid questions are the most basic level of question answering technologies, and will lead to more sophisticated technologies that can be used by professional reporters and information analysts.", "labels": [], "entities": [{"text": "question answering", "start_pos": 80, "end_pos": 98, "type": "TASK", "confidence": 0.8064116537570953}]}, {"text": "On some stage of that sophistication, a cub reporter writing an article on a specific topic will be able to translate the main issue addressed by his report into a set of simpler questions and then pose those questions to the question answering system ().", "labels": [], "entities": [{"text": "question answering", "start_pos": 226, "end_pos": 244, "type": "TASK", "confidence": 0.704218253493309}]}, {"text": "In addition, there is a relation between multi-document summarization and question answering.", "labels": [], "entities": [{"text": "multi-document summarization", "start_pos": 41, "end_pos": 69, "type": "TASK", "confidence": 0.62599977850914}, {"text": "question answering", "start_pos": 74, "end_pos": 92, "type": "TASK", "confidence": 0.87452432513237}]}, {"text": "In his lecture, Eduard Hovy mentioned that multi-document summarization maybe able to be reduced into a series of question answering).", "labels": [], "entities": [{"text": "question answering", "start_pos": 114, "end_pos": 132, "type": "TASK", "confidence": 0.7444457709789276}]}, {"text": "In SUMMAC, an intrinsic evaluation was conducted which measures the extent to which a summary provides answers to a set of obligatory questions on a given topic ().", "labels": [], "entities": [{"text": "SUMMAC", "start_pos": 3, "end_pos": 9, "type": "TASK", "confidence": 0.8275405168533325}]}, {"text": "Those suggest such question answering systems that can answer a series of related questions would surely be a useful aid to summarization work by human and by machine.", "labels": [], "entities": [{"text": "question answering", "start_pos": 19, "end_pos": 37, "type": "TASK", "confidence": 0.7625783383846283}, {"text": "summarization", "start_pos": 124, "end_pos": 137, "type": "TASK", "confidence": 0.9908084273338318}]}, {"text": "Against this background, question answering systems need to be able to answer a series of questions, which have a common topic and/or share a local context.", "labels": [], "entities": [{"text": "question answering", "start_pos": 25, "end_pos": 43, "type": "TASK", "confidence": 0.9040907919406891}]}, {"text": "In this paper, we propose a challenge to measure objectively and quantitatively such an ability of question answering systems.", "labels": [], "entities": [{"text": "question answering", "start_pos": 99, "end_pos": 117, "type": "TASK", "confidence": 0.8074801564216614}]}, {"text": "We call this challenge QACIAD (Question Answering Challenge for Information Access Dialogue).", "labels": [], "entities": [{"text": "Question Answering Challenge for Information Access Dialogue)", "start_pos": 31, "end_pos": 92, "type": "TASK", "confidence": 0.6906787678599358}]}, {"text": "In this challenge, question answering systems are used interactively to participate in dialogues for accessing information.", "labels": [], "entities": [{"text": "question answering", "start_pos": 19, "end_pos": 37, "type": "TASK", "confidence": 0.8777777552604675}]}, {"text": "Such information access dialogue occurs such as when gathering information fora report on a specific topic, or when browsing information of interest to the user.", "labels": [], "entities": []}, {"text": "Actually, in QACIAD, the interaction is only simulated and systems answer a series of questions in a batch mode.", "labels": [], "entities": []}, {"text": "Although such a simulation may neglect the inherent dynamics of dialogue, it is a practical compromise for objective evaluation and, as a result, the test sets of the challenge are reusable.", "labels": [], "entities": []}, {"text": "Question answering systems need a wide range of abilities in order to participate in information access dialogues ().", "labels": [], "entities": [{"text": "Question answering", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.9013957679271698}]}, {"text": "First, the systems must respond in real time to make interaction possible.", "labels": [], "entities": []}, {"text": "They must also properly interpret a given question within the context of a specific dialogue, and also be cooperative by adding appropriate information not mentioned explicitly by the user.", "labels": [], "entities": []}, {"text": "Moreover, the systems should be able to pose a question for clarification to resolve ambiguity concerning the user's goal and intentions, and to participate in mixed initiative dialogue by making suggestions and leading the user toward solving the problem.", "labels": [], "entities": []}, {"text": "Among these various capabilities, QACIAD focuses on the most fundamental aspect of dialogue, that is, interpreting a given question within the context of a specific dialogue.", "labels": [], "entities": [{"text": "interpreting a given question within the context of a specific dialogue", "start_pos": 102, "end_pos": 173, "type": "TASK", "confidence": 0.7896684841676191}]}, {"text": "It measures context processing abilities of systems such as anaphora resolution and ellipses handling.", "labels": [], "entities": [{"text": "anaphora resolution", "start_pos": 60, "end_pos": 79, "type": "TASK", "confidence": 0.7486188411712646}, {"text": "ellipses handling", "start_pos": 84, "end_pos": 101, "type": "TASK", "confidence": 0.7326342761516571}]}, {"text": "This paper is organized as follows.", "labels": [], "entities": []}, {"text": "The next chapter explains the design of QACIAD.", "labels": [], "entities": [{"text": "QACIAD", "start_pos": 40, "end_pos": 46, "type": "DATASET", "confidence": 0.6634392738342285}]}, {"text": "The following three chapters discuss the reality of the challenge.", "labels": [], "entities": []}, {"text": "First, we explain the process of constructing the test set of the challenge and introduce the results of a study conducted during this process which show the validity of QACIAD.", "labels": [], "entities": [{"text": "validity", "start_pos": 158, "end_pos": 166, "type": "METRIC", "confidence": 0.976982593536377}, {"text": "QACIAD", "start_pos": 170, "end_pos": 176, "type": "DATASET", "confidence": 0.5182761549949646}]}, {"text": "That is, QACIAD measures valid abilities needed for participating in information access dialogues.", "labels": [], "entities": [{"text": "QACIAD", "start_pos": 9, "end_pos": 15, "type": "METRIC", "confidence": 0.6879208087921143}]}, {"text": "In other words, the ability measured by the challenge is crucial to the systems for realizing information access dialogues for writing reports and summaries.", "labels": [], "entities": []}, {"text": "Second, we show the statistics of pragmatic phenomena in the constructed test set, and demonstrate that the challenge covers a wide variety of pragmatic phenomena observed in real dialogues.", "labels": [], "entities": []}, {"text": "Third, based on a preliminary analysis of the QACIAD run, we show that the challenge has a proper difficulty for evaluating the current state of open-domain question answering technologies.", "labels": [], "entities": [{"text": "QACIAD run", "start_pos": 46, "end_pos": 56, "type": "DATASET", "confidence": 0.847036212682724}, {"text": "question answering", "start_pos": 157, "end_pos": 175, "type": "TASK", "confidence": 0.7702367305755615}]}, {"text": "In the last two chapters, we discuss problems identified while constructing the test set and conducting the run, and draw some conclusions.", "labels": [], "entities": []}], "datasetContent": [{"text": "In QACIAD, as the systems are requested to return one list consisting all and only correct answers and the number of correct answers differs for each question 1 , modified F measure is used for the evaluation, which takes account of both precision and recall.", "labels": [], "entities": [{"text": "QACIAD", "start_pos": 3, "end_pos": 9, "type": "DATASET", "confidence": 0.6687664985656738}, {"text": "F measure", "start_pos": 172, "end_pos": 181, "type": "METRIC", "confidence": 0.9844409823417664}, {"text": "precision", "start_pos": 238, "end_pos": 247, "type": "METRIC", "confidence": 0.9994906187057495}, {"text": "recall", "start_pos": 252, "end_pos": 258, "type": "METRIC", "confidence": 0.9979422688484192}]}, {"text": "The first is for the case where an answer list returned by a system contains the same answer more than once or answers in different expressions denoting the same item.", "labels": [], "entities": []}, {"text": "In that case, only one answer is regarded as the correct one, and so the precision of such answer list decreases.", "labels": [], "entities": [{"text": "precision", "start_pos": 73, "end_pos": 82, "type": "METRIC", "confidence": 0.9994915723800659}]}, {"text": "Cases regarded as different expressions denoting the same item include a person's name with and without the position name, variations of foreign name notation, differences of monetary units used, differences of timezone referred to, and soon.", "labels": [], "entities": []}, {"text": "The second modification is for questions with no answer.", "labels": [], "entities": []}, {"text": "For those questions, modified F measure is 1.0 if a system returns an empty list as the answer, and is 0.0 otherwise.", "labels": [], "entities": [{"text": "F measure", "start_pos": 30, "end_pos": 39, "type": "METRIC", "confidence": 0.9938022494316101}]}, {"text": "It is a special case that the number of answers is just one for all questions shown in.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Categorization of questions by subject", "labels": [], "entities": []}, {"text": " Table 2: Categorization of questions by answer type", "labels": [], "entities": []}]}