{"title": [], "abstractContent": [{"text": "In this paper we present a novel approach to map textual entities such as words, phrases, sentences, paragraphs or arbitrary text fragments onto artificial structures which we call \"Text Sense Representation Trees\" (TSR trees).", "labels": [], "entities": [{"text": "map textual entities such as words, phrases, sentences, paragraphs or arbitrary text fragments", "start_pos": 45, "end_pos": 139, "type": "TASK", "confidence": 0.5869386773556471}]}, {"text": "These TSR trees represent an abstract notion of the meaning of the respective text, subjective to an abstract \"common\" understanding within the World Wide Web.", "labels": [], "entities": []}, {"text": "TSR Trees can be used to support text and language processing systems such as text categorizers, classifiers, automatic summarizers and applications of the Semantic Web.", "labels": [], "entities": []}, {"text": "We will explain how to construct the TSR tree structures and how to use them properly; furthermore we describe some preliminary evaluation results.", "labels": [], "entities": []}], "introductionContent": [{"text": "Many important tasks in the field of Natural Language Processing (NLP) such as text categorization, text summarization, (semi-) automatic translation and such require a certain amount of world knowledge and knowledge about text meaning and sense.", "labels": [], "entities": [{"text": "text categorization", "start_pos": 79, "end_pos": 98, "type": "TASK", "confidence": 0.7614105045795441}, {"text": "text summarization", "start_pos": 100, "end_pos": 118, "type": "TASK", "confidence": 0.7718111872673035}, {"text": "automatic translation", "start_pos": 128, "end_pos": 149, "type": "TASK", "confidence": 0.7517041563987732}]}, {"text": "Handling the amount of textual data in the World Wide Web also increasingly requires advanced automatic text and language processing techniques: successful search engines like Google) already employ text retrieval and information extraction methods based on shallow semantic information.", "labels": [], "entities": [{"text": "text retrieval", "start_pos": 199, "end_pos": 213, "type": "TASK", "confidence": 0.7199372351169586}, {"text": "information extraction", "start_pos": 218, "end_pos": 240, "type": "TASK", "confidence": 0.729498565196991}]}, {"text": "There are many methodologies to generate word sense representations, but efficiency and effectivity of fully automated techniques tends to below (Diana Zaiu Inkpen and Graeme.", "labels": [], "entities": []}, {"text": "Furthermore, formalisation and quantification of evaluation methods is difficult because in general word sense related techniques are only verifyable through theoretical examination, application on language or human judges), i.e. there is no inherent validation because there is no direct connection to the world as perceived by humans.", "labels": [], "entities": []}, {"text": "In the case of frequency based word sense representations corpus related difficulties arise (number of tagged entities, corpus quality, etc.).", "labels": [], "entities": []}, {"text": "In order to overcome these limitations, we developed a methodology to generate and use explicit computer-usable representations of text senses.", "labels": [], "entities": []}, {"text": "A common understanding of the \"sense\" of words is defined by the ways the word is used in context, i.e. the interpretation of the word that is consistent with the text meaning 1 -as summarized by S. G. Pulman in (R., Section 3.5).", "labels": [], "entities": []}, {"text": "Extending this definition onto full texts, we introduce our notion of \"Text Sense Representation\" (TSR) as \"the set of possible computer usable interpretations of a text without respect to a particular linguistic context\" 2 . TSR Trees provide detailed answers to questions like \"how close are these n words topically related to each other?\", \"are these m sentences really about the same topic?\" or \"how much does paragraph x contribute to topic y?\".", "labels": [], "entities": [{"text": "Text Sense Representation\" (TSR)", "start_pos": 71, "end_pos": 103, "type": "TASK", "confidence": 0.8021969326904842}]}, {"text": "They cannot tell e.g. a telephone is a physical artifact, it's purpose is to enable distant communication, etc.", "labels": [], "entities": []}, {"text": "TSR Trees are not meant to substitute meaning acquired through conceptual or linguistic analysis but are rather aimed at: \u2022 augmenting deeper (linguistic or conceptual) methodologies by providing additional analysis clues \u2022 standalone usage in generic shallow methods (e.g. in shallow text categorization) and specific applications (e.g. anti-spam functionality)", "labels": [], "entities": []}], "datasetContent": [{"text": "For testing, we setup some preliminary experiments :We built a prototype system based on a Tomcat application server 6 that was able to generate TSR trees for lists of input terms and store these trees along with their width, weight and depth features in an SQL database.", "labels": [], "entities": [{"text": "Tomcat application server 6", "start_pos": 91, "end_pos": 118, "type": "DATASET", "confidence": 0.8852349072694778}]}, {"text": "From this database we extracted the data used in the evaluation process.", "labels": [], "entities": []}, {"text": "We applied each feature explained in Section 4 on a set of words taken from 4 corpora.", "labels": [], "entities": []}, {"text": "These corpora were constructed as follows: The Basic corpus: The 100 first terms from a dictionary of \"basic english words\" like account, brother, crush, building, cry, etc.", "labels": [], "entities": []}, {"text": "The Med corpus: The 100 first terms from a specialized medical dictionary.", "labels": [], "entities": [{"text": "Med corpus", "start_pos": 4, "end_pos": 14, "type": "DATASET", "confidence": 0.7476633191108704}]}, {"text": "The Comp corpus: The 100 first terms from a specialized dictionary of computer science.", "labels": [], "entities": [{"text": "Comp corpus", "start_pos": 4, "end_pos": 15, "type": "DATASET", "confidence": 0.7570703327655792}]}, {"text": "The Top' corpus: The 100 terms that were ranked as \"top 100\" by the Wortschatz engine).", "labels": [], "entities": []}, {"text": "We expected terms of the Basic and Top corpora to show high weight and breadth and low depth values.", "labels": [], "entities": [{"text": "Basic and Top corpora", "start_pos": 25, "end_pos": 46, "type": "DATASET", "confidence": 0.8064540475606918}, {"text": "breadth", "start_pos": 71, "end_pos": 78, "type": "METRIC", "confidence": 0.9954385161399841}]}, {"text": "We also expected terms from the Med and Comp corpora to be of high depth but differing in weight and breadth.", "labels": [], "entities": [{"text": "Med and Comp corpora", "start_pos": 32, "end_pos": 52, "type": "DATASET", "confidence": 0.8834047764539719}, {"text": "breadth", "start_pos": 101, "end_pos": 108, "type": "METRIC", "confidence": 0.9927049279212952}]}, {"text": "These Expectations were supported by our results from generating and comparing the respective corpus TSR trees (see below).", "labels": [], "entities": [{"text": "Expectations", "start_pos": 6, "end_pos": 18, "type": "METRIC", "confidence": 0.9727024435997009}]}, {"text": "For brevity, we will only present a summary of our findings here.", "labels": [], "entities": []}, {"text": "Single Tree Features Comparing the outcome of applying single TSR tree features onto the four corpora showed some interesting results: 1.", "labels": [], "entities": []}, {"text": "Terms from the Med corpus are often not represented within the web directory which means that a TSR tree cannot be built for these terms.", "labels": [], "entities": [{"text": "Med corpus", "start_pos": 15, "end_pos": 25, "type": "DATASET", "confidence": 0.9276911616325378}]}, {"text": "In general, terms from the Med corpus have a very low tree weight value (in most cases < 10).", "labels": [], "entities": [{"text": "Med corpus", "start_pos": 27, "end_pos": 37, "type": "DATASET", "confidence": 0.9325730204582214}]}, {"text": "Strangely, some words such as \"by\", \"and\", \"because\" etc. from the Top corpus also have low ratings.", "labels": [], "entities": [{"text": "Top corpus", "start_pos": 67, "end_pos": 77, "type": "DATASET", "confidence": 0.9151908159255981}]}, {"text": "Examining the actual web directory pages exhibits that these terms seldom contributed to a web pages semantic context and thusly were seldom represented in the web directory.", "labels": [], "entities": []}, {"text": "It appears that all input terms were interpreted by the ODP search engine as being semantically relevant, e.g. the word \"about\" only generated hits in categories about movie titles, e.g. etc.", "labels": [], "entities": []}, {"text": "This strongly indicates that the input to the algorithm should be a noun or a common noun phrase.", "labels": [], "entities": []}, {"text": "Terms from the Basic corpus and the Comp corpus are rated comparably high, e.g. some common words from the Basic corpus such as \"air\", \"animal\", etc. were assigned very high weight values (weight > 100).", "labels": [], "entities": [{"text": "Basic corpus", "start_pos": 15, "end_pos": 27, "type": "DATASET", "confidence": 0.9783784449100494}, {"text": "Comp corpus", "start_pos": 36, "end_pos": 47, "type": "DATASET", "confidence": 0.8834170401096344}, {"text": "Basic corpus", "start_pos": 107, "end_pos": 119, "type": "DATASET", "confidence": 0.9013302624225616}]}, {"text": "The generality values listing exhibits that indeed mostly general terms are identified by this feature.", "labels": [], "entities": []}, {"text": "Surprisingly, some terms such as \"software\" and \"design\" were also attributed high generality.", "labels": [], "entities": []}, {"text": "Further investigation shows that \"generality\" is a context dependent feature, e.g. the term \"software\" is very general for the computer domain.", "labels": [], "entities": []}, {"text": "Only at the first tree level, a domain independent generality factor can be attributed to this feature.", "labels": [], "entities": []}, {"text": "We also found that pruning has its greatest effect on this feature; this leads to the conclusion that the generality feature should be applied on TSR trees that are not pruned according to some threshold.", "labels": [], "entities": []}, {"text": "Except a very few cases, all top rated terms are in the Comp or in the Med corpus i.e. the two specialized corpora.", "labels": [], "entities": [{"text": "Comp", "start_pos": 56, "end_pos": 60, "type": "DATASET", "confidence": 0.8883973956108093}, {"text": "Med corpus", "start_pos": 71, "end_pos": 81, "type": "DATASET", "confidence": 0.9367991089820862}]}, {"text": "These terms are apparently more specific in context than the lower rating terms.", "labels": [], "entities": []}, {"text": "Advanced Tree Features Even though we tested the Multi Tree features on only a few test cases (about 30), we are confident that future evaluation will confirm our preliminary results.", "labels": [], "entities": []}, {"text": "Computing the difference of two or three single TSR trees turned out to be less informative than the distance value between these trees but a small number of experiments lead us to the conclusion that TSR trees of large text fragments can be compared by difference features with a conclusive outcome.", "labels": [], "entities": []}, {"text": "Using node labels and weights for comparison in any case resulted in a 100% distance.", "labels": [], "entities": []}, {"text": "This effect derived from the fact that even though some trees were similar in structure, their respective weights differed in every case.", "labels": [], "entities": []}, {"text": "The distance feature therefore is applicable to node labels only or has to introduce arithmetical means for adjusting weights.", "labels": [], "entities": []}, {"text": "After correcting the distance algorithm, it worked as expected on trees with about the same node number (High distance between e.g. \"blood\" and \"air\", low distance between \"account\" and \"credit\").", "labels": [], "entities": []}, {"text": "We also achieved reasonable results on trees differing in node number when applying a methodology of filtering homonymous aspects of the respective larger TSR tree (i.e. by using the node number of the smaller tree as upper bound and filtering first level tree nodes).", "labels": [], "entities": []}, {"text": "Nonetheless we did not yet manage to find an absolute numerical expression that describes the distance feature appropriately.", "labels": [], "entities": []}], "tableCaptions": []}