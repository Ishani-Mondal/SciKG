{"title": [{"text": "Multiword Expression Filtering for Building Knowledge Maps", "labels": [], "entities": [{"text": "Multiword Expression Filtering", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.7687756220499674}, {"text": "Building Knowledge Maps", "start_pos": 35, "end_pos": 58, "type": "TASK", "confidence": 0.6202392478783926}]}], "abstractContent": [{"text": "This paper describes an algorithm that can be used to improve the quality of multiword expressions extracted from documents.", "labels": [], "entities": []}, {"text": "We measure multiword expression quality by the \"usefulness\" of a multiword expression in helping ontolo-gists build knowledge maps that allow users to search a large document corpus.", "labels": [], "entities": []}, {"text": "Our stopword based algorithm takes n-grams extracted from documents, and cleans them up to make them more suitable for building knowledge maps.", "labels": [], "entities": []}, {"text": "Running our algorithm on large corpora of documents has shown that it helps to increase the percentage of useful terms from 40% to 70%-with an eight-fold improvement observed in some cases.", "labels": [], "entities": []}], "introductionContent": [{"text": "Many real world applications require extraction of word sequences or multiword expressions from text.", "labels": [], "entities": [{"text": "extraction of word sequences or multiword expressions from text", "start_pos": 37, "end_pos": 100, "type": "TASK", "confidence": 0.7053173647986518}]}, {"text": "Examples of such applications include, among others, creation of search engine indexes, knowledge discovery, data mining, machine translation, summarization and term suggestion for either knowledge engineering or query refinement by end users of a search system.", "labels": [], "entities": [{"text": "knowledge discovery", "start_pos": 88, "end_pos": 107, "type": "TASK", "confidence": 0.7799834907054901}, {"text": "data mining", "start_pos": 109, "end_pos": 120, "type": "TASK", "confidence": 0.7894748151302338}, {"text": "machine translation", "start_pos": 122, "end_pos": 141, "type": "TASK", "confidence": 0.804462194442749}, {"text": "summarization", "start_pos": 143, "end_pos": 156, "type": "TASK", "confidence": 0.9781904220581055}]}, {"text": "The application of interest to the authors of this paper was that of building knowledge maps that help bridge the gap between searchers and documents.", "labels": [], "entities": []}, {"text": "A knowledge map fora particular domain is a collection of concepts, relationships between these concepts as well as evidence associated to each concept.", "labels": [], "entities": []}, {"text": "A domain concept represents an abstraction that can be generalized from instances in the domain.", "labels": [], "entities": []}, {"text": "It can be a person, a thing, or an event.", "labels": [], "entities": []}, {"text": "An example of a concept in the operating system domain is 'installation guidelines'.", "labels": [], "entities": []}, {"text": "Relationships between concepts can be either generalization or specialization (such as \"is a\") as well as different types of association (such as \"part-of\").", "labels": [], "entities": []}, {"text": "The evidence associated to a concept is a set of single or multiword terms such that if any of those terms are found in a document, then it is likely that the document refers to that concept.", "labels": [], "entities": []}, {"text": "The task we were trying to support was to identify multiword expressions in a corpus of documents belonging to a domain that can help ontologists identify the important concepts in the domain as well as their evidence.", "labels": [], "entities": []}, {"text": "Our research was focused on domains where the corpus of documents representing the domain contains a high degree of technical content.", "labels": [], "entities": []}, {"text": "The reason for this is that such documents are served on many company web sites to help provide technical support for both employees and customers.", "labels": [], "entities": []}, {"text": "Our research assumes that a term 1 is \"useful\" when it meets all of the following conditions -(1) it makes sense in context of the domain, (2) it represents an action, some tangible or intangible object, name of a product, or a troubleshooting phrase, and (3) it would be chosen by an ontologist to be incorporated to their knowledge map.", "labels": [], "entities": []}, {"text": "Some examples of multiword expressions that maybe considered useful for building knowledge maps about technical content are \"how to uninstall the program\", \"Simple Mail Transfer Protocol\", and \"cannot reboot the computer\".", "labels": [], "entities": [{"text": "Simple Mail Transfer Protocol", "start_pos": 157, "end_pos": 186, "type": "TASK", "confidence": 0.5860293284058571}]}, {"text": "Some expressions may not seem useful at first glance but may make sense to an ontologist familiar with that domain.", "labels": [], "entities": []}, {"text": "For instance, the occurrence of the number \"error 37582\" maybe an error code, and hence evidence of a particular kind of problem.", "labels": [], "entities": []}, {"text": "Similarly, expressions such as \"after rebooting the system\" may not seem useful but maybe good evidence of concepts related to problem identification.", "labels": [], "entities": [{"text": "problem identification", "start_pos": 127, "end_pos": 149, "type": "TASK", "confidence": 0.7883232831954956}]}, {"text": "Examples of expressions that maybe acceptable for some purposes, but not for building knowledge maps are \"this software was implemented by\" and \"and reboot the system to\".", "labels": [], "entities": []}, {"text": "These expressions however can become useful after undergoing some processing or manipulation by humans.", "labels": [], "entities": []}, {"text": "We extracted n-grams from documents using an algorithm proposed by, and cleaned them up iteratively using a stopwordbased algorithm in order to make them more useful for building knowledge maps.", "labels": [], "entities": []}, {"text": "Tseng's algorithm is based on the assumption that documents concentrating on a topic tend to mention a set of words in a specific sequence repeatedly.", "labels": [], "entities": []}, {"text": "In other words, repeated multiword expressions are extracted since they will make good evidence candidates.", "labels": [], "entities": []}, {"text": "Our experience with Tseng's algorithm was that it extracts many useful multiword expressions.", "labels": [], "entities": []}, {"text": "But, it also extracts multiword expressions that are repeated frequently in the documents but are not useful when viewed independently of the sentences from where they originated.", "labels": [], "entities": []}, {"text": "This may not matter for some applications, but puts a lot of burden on librarians or ontologists who want to use those multiword expressions to build knowledge maps.", "labels": [], "entities": []}, {"text": "Examples of such expressions are \"software was\", \"computer crashed after\", \"installed in order to\", and soon.", "labels": [], "entities": []}, {"text": "Such expressions have to undergo further manipulation or processing by ontologists in order for them to be useful.", "labels": [], "entities": []}, {"text": "A good weighting algorithm may eliminate some of these expressions in some cases.", "labels": [], "entities": []}, {"text": "However, our experience has shown that in a sufficiently large and homogenous set of documents, occurrence of all of these variations is so high that many of them meet the threshold requirements to qualify as eligible multiword expressions.", "labels": [], "entities": [{"text": "occurrence", "start_pos": 96, "end_pos": 106, "type": "METRIC", "confidence": 0.9855425357818604}]}, {"text": "Setting higher frequency thresholds maybe a solution to this problem, but that may result in elimination of other useful multiword expressions.", "labels": [], "entities": []}, {"text": "One of the steps usually undertaken is to eliminate not so useful single word terms extracted from documents.", "labels": [], "entities": []}, {"text": "For instance, the word \"the\" is not considered to be useful for most purposes.", "labels": [], "entities": []}, {"text": "If a user were to submit a query such as \"the cat\", returning documents that contain \"cat\" would be more useful than looking for documents that contain both \"the\" and \"cat.\"", "labels": [], "entities": []}, {"text": "Terms such as \"a\", \"an\", \"the\" and soon are referred to as \"stopwords\" or \"noise words\" or \"skipwords\", and these are usually ignored by search engines when they occur by themselves when building indexes.", "labels": [], "entities": []}, {"text": "There are many common stopword lists useful in various contexts.", "labels": [], "entities": []}, {"text": "Statistical and quantitative techniques using frequency or mutual information scores for multiword expressions as well as syntactic techniques using phrase trees have been used to extract multiword expressions from text.", "labels": [], "entities": []}, {"text": "According to, many multiword units identified using statistical methods cannot be considered as terms although it maybe useful to identify them.", "labels": [], "entities": []}, {"text": "Examples cited by the authors include terms such as \"be notified\" and \"valid for\".", "labels": [], "entities": []}, {"text": "Less commonly found in literature is work done to \"clean\" or \"filter\" the extracted multiword expressions to make them suitable for certain purposes.", "labels": [], "entities": []}, {"text": "An example of implementation of a filter is found in work done by Merkel et al. in their FRASSE system where they defined words that should be stripped at the beginning and at the end of multiword expressions as well as requirements on what kinds of characters should be regarded as pairs (quotation marks, parentheses, etc).", "labels": [], "entities": [{"text": "FRASSE system", "start_pos": 89, "end_pos": 102, "type": "DATASET", "confidence": 0.8307853639125824}]}, {"text": "The reason for identifying characters that should be regarded in pairs is to make sure that multiword expressions that are retained after filtering do not have only one parenthesis character or quotation mark.", "labels": [], "entities": []}, {"text": "Their filter was implemented with the use of entropy thresholds and stopwords for the Swedish language.", "labels": [], "entities": []}, {"text": "Another example of a proposed filter is found in work by Dias et. al. in which the authors suggest using a filter that removed stopwords where they occurred either at the beginning or at the end of multiword expressions.", "labels": [], "entities": []}, {"text": "Our work uses a standard stopword list used by systems that suggest terms to ontologists and end users, and part of speech information to achieve the same goal.", "labels": [], "entities": []}, {"text": "The part of speech information ensures that we treat beginning and end of multilword expressions differently.", "labels": [], "entities": []}, {"text": "Our contribution has been to extend Tseng's algorithm using stopwords and apart of speech based algorithm to reduce the occurrence of expressions that need further processing by ontologists.", "labels": [], "entities": []}, {"text": "Our goal was to increase the proportion of expressions extracted that don't have to undergo anymore manual processing by ontologists to make them useful.", "labels": [], "entities": []}, {"text": "This is very useful in situations such as term suggestion where users can be saved the time and effort involved in going through long lists of terms many of which may not be useful, or may have to be manipulated in someway to make them useful.", "labels": [], "entities": []}, {"text": "Running our algorithm on large corpora of documents has shown that it helps to increase the percentage of useful terms from 40% (+-10) to 70% (+-10).", "labels": [], "entities": []}, {"text": "In other words, the improvement is at least 20% and could be high as 160%.", "labels": [], "entities": []}, {"text": "The rest of this paper is organized as followsSection 2 describes our algorithm for extraction of frequently occurring n-grams, and converting them to useful multiword expressions.", "labels": [], "entities": []}, {"text": "Sections 3 and 4 describe the results of evaluating our algorithm on large corpora of documents and conclude the paper.", "labels": [], "entities": []}], "datasetContent": [{"text": "We implemented this algorithm using Java, and ran it on more than 20 corpora of documents dealing with technology topics.", "labels": [], "entities": []}, {"text": "The size of the corpora ranged from 4000 documents to 500,000 documents.", "labels": [], "entities": []}, {"text": "The average size of the corpora was around 5-6 MB.", "labels": [], "entities": []}, {"text": "The topics discussed include, among others, computer networking, instructions on how to install and use application software, troubleshooting software problems, and soon.", "labels": [], "entities": [{"text": "computer networking", "start_pos": 44, "end_pos": 63, "type": "TASK", "confidence": 0.7324261963367462}]}, {"text": "Program inputs include documents, and a stopwords list.", "labels": [], "entities": []}, {"text": "Benefits of applying our algorithm to filter expressions include: Term list size reduction -The result of applying our algorithm to filter expressions extracted from documents is a reduction in number of terms by at least 30%-40%.", "labels": [], "entities": [{"text": "Term list size reduction", "start_pos": 66, "end_pos": 90, "type": "TASK", "confidence": 0.6327398419380188}]}, {"text": "This translated to an order-of-magnitude reduction in time and effort on the part of ontologists and other users.", "labels": [], "entities": []}, {"text": "Without the algorithm, ontologists may have had to study the list manually to eliminate meaningless expressions and manipulate other terms to turn them into useful expressions.", "labels": [], "entities": []}, {"text": "Examples of such reduction include: Expressions such as \"Windows 98 operating system\", \"Windows 98 operating system was\", \"the Windows 98 operating system\", and \"Windows 98 operating system is\" are reduced to \"Windows 98 operating system\".", "labels": [], "entities": []}, {"text": "Expressions such as \"the screen flickers\", and \"screen flickers and\" would be reduced to just \"screen flickers\".", "labels": [], "entities": []}, {"text": "Expressions such as \"and is a\" and \"is not\" and \"and etc.\" are eliminated from the list.", "labels": [], "entities": []}, {"text": "The individual words in these expressions are in the stop words list, but ordinarily a multiword expression such as \"is not\" would make it past the stop words filter since it contains more than one word in it.", "labels": [], "entities": []}, {"text": "The reduction in the number of terms translated to a reduction in the number of person-weeks required to create a knowledge map using the terms.", "labels": [], "entities": []}, {"text": "We noticed a savings in the number of person-weeks that ranged from 50% to close to 90%.", "labels": [], "entities": []}, {"text": "In one particular instance, using our algorithm reduced the time required to create a knowledge map based on extracted n-grams from 4 person-weeks to about 0.5 person /weeks Higher precision -There is a greater probability that the terms that remain after filtering are useful terms.", "labels": [], "entities": [{"text": "precision", "start_pos": 181, "end_pos": 190, "type": "METRIC", "confidence": 0.9981836676597595}]}, {"text": "In other words, the remaining terms are more likely to be considered useful by users.", "labels": [], "entities": []}, {"text": "Our experience has shown that the percentage of useful terms prior to filtering ranged from 30% to 50%.", "labels": [], "entities": []}, {"text": "Post filtering, the percentage of useful terms ranged from 60% to 80%.", "labels": [], "entities": []}, {"text": "In other words, running our algorithm on large corpora of documents has shown that it helps to increase the percentage of useful terms from 40% (\u00b110%) to 70% (\u00b110%) -with an eight-fold improvement observed in some cases.", "labels": [], "entities": []}, {"text": "Domain independence -Pattern extraction from documents involves extracting both domain specific and domain independent terms.", "labels": [], "entities": [{"text": "Domain independence", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.6958277970552444}, {"text": "Pattern extraction from documents", "start_pos": 21, "end_pos": 54, "type": "TASK", "confidence": 0.864744707942009}]}, {"text": "Domain specific terms are those that represent the core knowledge in the domain.", "labels": [], "entities": []}, {"text": "For example, terms such as \"dynamic host control protocol\" and \"TCP/IP\" can be considered to be domain specific terms in the computer networking domain.", "labels": [], "entities": []}, {"text": "On the other hand, terms such as \"document author\" are not domain specific.", "labels": [], "entities": []}, {"text": "The technique described in this paper aids in filtering both domain specific and domain independent terms extracted from documents.", "labels": [], "entities": []}, {"text": "The tests conducted have been primarily with documents containing technology topics.", "labels": [], "entities": []}, {"text": "However, this algorithm worked well with documents related to electronic commerce as well.", "labels": [], "entities": []}, {"text": "The algorithm is, of course, not foolproof, and there are instances where expressions that ought to be modified are not, and expressions are modified more than necessary.", "labels": [], "entities": []}, {"text": "For instance, the expression \"software was\" will be correctly reduced to \"software\" since \"was\" is an auxiliary verb.", "labels": [], "entities": []}, {"text": "The multiword expression \"computer crashed after\" will be reduced to \"computer crashed\" since \"after\" is a prepositon, but \"installed in order to\" will be reduced to \"installed in order\".", "labels": [], "entities": []}, {"text": "\"Installed in order\" is not a useful expression, but it is one of the expressions that are not processed correctly by our algorithm.", "labels": [], "entities": []}, {"text": "On the whole, however, our finding is that applying this algorithm results in a significant savings of time and effort to extract useful multiword expressions from documents.", "labels": [], "entities": []}], "tableCaptions": []}