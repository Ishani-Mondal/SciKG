{"title": [{"text": "Character-Sense Association and Compounding Template Similarity: Automatic Semantic Classification of Chinese Compounds", "labels": [], "entities": [{"text": "Compounding Template Similarity", "start_pos": 32, "end_pos": 63, "type": "TASK", "confidence": 0.6878503362337748}, {"text": "Automatic Semantic Classification of Chinese Compounds", "start_pos": 65, "end_pos": 119, "type": "TASK", "confidence": 0.725991502404213}]}], "abstractContent": [{"text": "This paper presents a character-based model of automatic sense determination for Chinese compounds.", "labels": [], "entities": [{"text": "automatic sense determination", "start_pos": 47, "end_pos": 76, "type": "TASK", "confidence": 0.6229464113712311}]}, {"text": "The model adopts a sense approximation approach using synonymous compounds retrieved by measuring similarity of semantic template in compounding.", "labels": [], "entities": [{"text": "sense approximation", "start_pos": 19, "end_pos": 38, "type": "TASK", "confidence": 0.6955716013908386}]}, {"text": "The similarity measure is derived from an association network among characters and senses, which is built from a formatted MRD.", "labels": [], "entities": []}, {"text": "Adopting the taxonomy of CILIN, a system of deep semantic classification (at least to the small classes) for V-V compounds is implemented and evaluated to test the model.", "labels": [], "entities": []}, {"text": "The experiment reports a high precision rate (about 38% in outside test and 61% in inside test) against the baseline one (about 18%).", "labels": [], "entities": [{"text": "precision rate", "start_pos": 30, "end_pos": 44, "type": "METRIC", "confidence": 0.9889563322067261}]}], "introductionContent": [{"text": "Sense tagging is an important task in NLP.", "labels": [], "entities": [{"text": "Sense tagging", "start_pos": 0, "end_pos": 13, "type": "TASK", "confidence": 0.8445256352424622}]}, {"text": "It is supposed to provide semantic information useful to the application tasks like IR and MT.", "labels": [], "entities": [{"text": "IR", "start_pos": 84, "end_pos": 86, "type": "TASK", "confidence": 0.8917657136917114}, {"text": "MT", "start_pos": 91, "end_pos": 93, "type": "TASK", "confidence": 0.8916507959365845}]}, {"text": "As generally acknowledged, sense tagging is to assign a certain sense to a word in a certain context by using a semantic lexicon.", "labels": [], "entities": [{"text": "sense tagging", "start_pos": 27, "end_pos": 40, "type": "TASK", "confidence": 0.7188239097595215}]}, {"text": "In addition to word sense disambiguation (WSD) for known words, sense determination for words unknown to the lexicon poses another challenge in sense tagging.", "labels": [], "entities": [{"text": "word sense disambiguation (WSD)", "start_pos": 15, "end_pos": 46, "type": "TASK", "confidence": 0.7882027477025986}, {"text": "sense determination", "start_pos": 64, "end_pos": 83, "type": "TASK", "confidence": 0.6669183969497681}, {"text": "sense tagging", "start_pos": 144, "end_pos": 157, "type": "TASK", "confidence": 0.7124989777803421}]}, {"text": "This is especially the casein NLP of Chinese, a language rich in compound words.", "labels": [], "entities": []}, {"text": "According to the data in), about 5.51% of unknown words is encountered in their sense-tagging task of Chinese corpus.", "labels": [], "entities": [{"text": "Chinese corpus", "start_pos": 102, "end_pos": 116, "type": "DATASET", "confidence": 0.8595027029514313}]}, {"text": "Instead of proper names, the cross-linguistically most common type of unknown words, compound words constitute the majority of unknown words in Chinese text.", "labels": [], "entities": []}, {"text": "According to , the three most dominant types of Chinese unknown words are: compound nouns (about 51%), compound verbs (about 34%), and proper names (about 15%).", "labels": [], "entities": []}, {"text": "While the identification and classification of proper names is an issue already well discussed in Chinese NLP researches, the sense determination of unknown compounds remains a subject relatively less tackled.", "labels": [], "entities": [{"text": "identification and classification of proper names", "start_pos": 10, "end_pos": 59, "type": "TASK", "confidence": 0.8395842562119166}, {"text": "sense determination of unknown compounds", "start_pos": 126, "end_pos": 166, "type": "TASK", "confidence": 0.8483451724052429}]}], "datasetContent": [{"text": "For evaluating the performance of the system, 500 V-V compounds are randomly picked out from CILIN to form the test set.", "labels": [], "entities": [{"text": "CILIN", "start_pos": 93, "end_pos": 98, "type": "DATASET", "confidence": 0.9001480937004089}]}, {"text": "Two modes of evaluation experiments are carried out: both modes adopt dico2 (CILIN) in Module-B (dicox=dioc2) to determine semantic classes, while the inside-test mode uses dico2 (CILIN) in Module-A and the outside-test mode uses dico1 (HowNet) in Module-A, to obtain association network and retrieve the T-similar words.", "labels": [], "entities": []}, {"text": "To make the test compounds unknown to the model, the semantic classes of the test compounds have to be invisible to CILIN, while the invisibility should not undermine the training of the association network in Module-A. The effect is done by dynamically withdrawing a word from dico2 in Module-B each time when it is in test.", "labels": [], "entities": []}, {"text": "Two ways of evaluation can be made: by verifying the answer to the level of small class (level-3) and to the level of subclasses (level-4).", "labels": [], "entities": []}, {"text": "The accuracy is calculated by verifying if the correct answer or one of the correct answers (if V-V is polysemous) according to CILIN can be found in the first n ranked semantic classes predicted by the system.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.9995087385177612}, {"text": "CILIN", "start_pos": 128, "end_pos": 133, "type": "DATASET", "confidence": 0.8212213516235352}]}, {"text": "The performance of a random head-picking model is offered as the baseline.", "labels": [], "entities": []}, {"text": "In this baseline model, one of the semantic classes of X and Y is randomly chosen as the semantic class of the compound X-Y.", "labels": [], "entities": []}, {"text": "Level-3(Small Class) Level-4(Subclass ) n outside inside Baseline outside inside Baseline 1 39.80% 61.60% 18.83% 36.60% 60.40% 17.34% 2 56.80% 76.00% 31.40% 52.80% 74.40% 29.12% 3 64.40% 83.80% 40.21% 59.80% 80.80% 37.54%.", "labels": [], "entities": []}, {"text": "Performance for 500 V-V compounds The results in show that the system achieves a precision rate of 60.40% for inside test and 36.60% for outside test in level-4 classification against the baseline one of 17.34%.", "labels": [], "entities": [{"text": "precision rate", "start_pos": 81, "end_pos": 95, "type": "METRIC", "confidence": 0.991385281085968}]}, {"text": "Not to our surprise, the performance of classification to level-3, a slightly shallower level, is slightly better: 61.60% for inside test and 39.80% for outside test.", "labels": [], "entities": []}, {"text": "also shows that the system can achieve a correction rate of 59.8% (outside) and 80.80% (inside) for including the correct answer in the first 3 ranked candidate classes in level-4, 64.40% (outside) and 83.80% (inside) in level-3, all much better than the baseline ones, 37.54% and 40.21%.", "labels": [], "entities": [{"text": "correction rate", "start_pos": 41, "end_pos": 56, "type": "METRIC", "confidence": 0.9880355298519135}]}], "tableCaptions": [{"text": " Table 2. Level-3 performance for [+/-Head] V-V", "labels": [], "entities": []}, {"text": " Table 3. Level-3 performance for V-V of category VC", "labels": [], "entities": []}]}