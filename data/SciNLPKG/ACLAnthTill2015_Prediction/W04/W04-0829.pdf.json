{"title": [{"text": "WSD Based on Mutual Information and Syntactic Patterns", "labels": [], "entities": [{"text": "WSD", "start_pos": 0, "end_pos": 3, "type": "TASK", "confidence": 0.7556830048561096}]}], "abstractContent": [{"text": "This paper describes a hybrid system for WSD, presented to the English all-words and lexical-sample tasks, that relies on two different unsupervised approaches.", "labels": [], "entities": [{"text": "WSD", "start_pos": 41, "end_pos": 44, "type": "TASK", "confidence": 0.9820160269737244}]}, {"text": "The first one selects the senses according to mutual information proximity between a context word a variant of the sense.", "labels": [], "entities": []}, {"text": "The second heuristic analyzes the examples of use in the glosses of the senses so that simple syntactic patterns are inferred.", "labels": [], "entities": []}, {"text": "This patterns are matched against the disambigua-tion contexts.", "labels": [], "entities": []}, {"text": "We show that the first heuristic obtains a precision and recall of .58 and .35 respectively in the all words task while the second obtains .80 and .25.", "labels": [], "entities": [{"text": "precision", "start_pos": 43, "end_pos": 52, "type": "METRIC", "confidence": 0.9996916055679321}, {"text": "recall", "start_pos": 57, "end_pos": 63, "type": "METRIC", "confidence": 0.9988964796066284}]}, {"text": "The high precision obtained recommends deeper research of the techniques.", "labels": [], "entities": [{"text": "precision", "start_pos": 9, "end_pos": 18, "type": "METRIC", "confidence": 0.9926055669784546}]}, {"text": "Results for the lexical sample task are also provided.", "labels": [], "entities": []}], "introductionContent": [{"text": "We will describe in this paper the system that we presented to the SENSEVAL-3 competition in the English all-words and lexical-sample tasks.", "labels": [], "entities": [{"text": "SENSEVAL-3 competition", "start_pos": 67, "end_pos": 89, "type": "TASK", "confidence": 0.6691488921642303}]}, {"text": "It is an unsupervised system that relies only on dictionary information and raw coocurrence data that we collected from a large untagged corpus.", "labels": [], "entities": []}, {"text": "There is also a supervised extension of the system for the lexical sample task that takes into account the training data provided for the lexical sample task.", "labels": [], "entities": []}, {"text": "We will describe two heuristics; the first one selects the sense of the words' synset with a synonym with the highest Mutual Information (MI) with a context word.", "labels": [], "entities": [{"text": "Mutual Information (MI", "start_pos": 118, "end_pos": 140, "type": "METRIC", "confidence": 0.8120039254426956}]}, {"text": "This heuristic will be covered in section 2.", "labels": [], "entities": []}, {"text": "The second heuristic relies on a set of syntactic structure rules that support particular senses.", "labels": [], "entities": []}, {"text": "This rules have been extracted from the examples in WordNet sense glosses.", "labels": [], "entities": [{"text": "WordNet sense glosses", "start_pos": 52, "end_pos": 73, "type": "DATASET", "confidence": 0.9280852476755778}]}, {"text": "Section 3 will be devoted to this technique.", "labels": [], "entities": []}, {"text": "In section 4 we will explain the combination of both heuristics to finish in section 5 with our conclusions and some considerations for future work.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Closest variant heuristic results", "labels": [], "entities": []}, {"text": " Table 2: Syntactic pattern heuristic results", "labels": [], "entities": [{"text": "Syntactic pattern heuristic", "start_pos": 10, "end_pos": 37, "type": "TASK", "confidence": 0.9173889756202698}]}]}