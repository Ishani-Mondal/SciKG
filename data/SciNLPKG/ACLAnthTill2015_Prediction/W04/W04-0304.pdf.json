{"title": [], "abstractContent": [{"text": "We present a general architecture for incremen-tal interaction between modules in a speech-to-intention continuous understanding dialogue system.", "labels": [], "entities": []}, {"text": "This architecture is then instantiated in the form of an incremental parser which receives suit-ability feedback on NP constituents from a reference resolution module.", "labels": [], "entities": []}, {"text": "Oracle results indicate that perfect NP suitability judgments can provide a labelled-bracket error reduction of as much as 42% and an efficiency improvement of 30%.", "labels": [], "entities": [{"text": "labelled-bracket error reduction", "start_pos": 76, "end_pos": 108, "type": "METRIC", "confidence": 0.7825097044308981}]}, {"text": "Preliminary experiments in which the parser incorporates feedback judgments based on the set of referents found in the discourse context achieve a maximum error reduction of 9.3% and efficiency gain of 4.6%.", "labels": [], "entities": [{"text": "error reduction", "start_pos": 155, "end_pos": 170, "type": "METRIC", "confidence": 0.9654815793037415}]}, {"text": "The parser is also able to incrementally instantiate the semantics of underspecified pronouns based on matches from the discourse context.", "labels": [], "entities": []}, {"text": "These results suggest that the architecture holds promise as a platform for incremental parsing supporting continuous understanding.", "labels": [], "entities": []}], "introductionContent": [{"text": "Humans process language incrementally, as has been shown by classic psycholinguistic discussions surrounding the garden-path phenomenon and parsing preferences (.", "labels": [], "entities": []}, {"text": "Moreover, a variety of eye-tracking experiments) suggest that complex semantic and referential constraints are incorporated on an incremental basis inhuman parsing decisions.", "labels": [], "entities": []}, {"text": "Computational parsers, however, still tend to operate an entire sentence at a time, despite the advent of speech-to-intention dialogue systems such as Verbmobil (;), Gemini () and TRIPS).", "labels": [], "entities": []}, {"text": "Naturalness, robustness, and interactivity are goals of such systems, but control flow is typically the sequential execution of modules, each operating on the output of its predecessor; only after the entire sentence has been parsed do higher-level modules such as intention recognition and reference resolution get involved.", "labels": [], "entities": [{"text": "intention recognition", "start_pos": 265, "end_pos": 286, "type": "TASK", "confidence": 0.6976428925991058}, {"text": "reference resolution", "start_pos": 291, "end_pos": 311, "type": "TASK", "confidence": 0.8055059611797333}]}, {"text": "In contrast to this sequential model is the continuous understanding approach, in which all levels of language analysis occur simultaneously, from speech recognition to intention recognition.", "labels": [], "entities": [{"text": "speech recognition to intention recognition", "start_pos": 147, "end_pos": 190, "type": "TASK", "confidence": 0.6497330725193023}]}, {"text": "As well as being psycholinguistically motivated, continuous understanding models offer potential computational advantages, including accuracy and efficiency improvements for real-time spoken language understanding and better support for the spontaneities of natural human speech.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 133, "end_pos": 141, "type": "METRIC", "confidence": 0.9981493949890137}, {"text": "real-time spoken language understanding", "start_pos": 174, "end_pos": 213, "type": "TASK", "confidence": 0.6919889003038406}]}, {"text": "Continuous understanding is necessary if the system is to respond before the entire utterance is analyzed, a prerequisite for incremental confirmation and clarification.", "labels": [], "entities": []}, {"text": "The major computational advantage of continuous understanding models is that high-level expectations and feedback should be able to influence the search of lowerlevel processes, thus leading to a focused search through hypotheses that are plausible at all levels of processing.", "labels": [], "entities": []}, {"text": "One of the major current applications of parsers that operate incrementally is for language modelling in speech recognition ().", "labels": [], "entities": [{"text": "language modelling", "start_pos": 83, "end_pos": 101, "type": "TASK", "confidence": 0.7236750572919846}, {"text": "speech recognition", "start_pos": 105, "end_pos": 123, "type": "TASK", "confidence": 0.7485257983207703}]}, {"text": "This work is important not only for its ability to improve performance on the speech recognition task; it also models the interactions between speech recognition and parsing in a continuous understanding system.", "labels": [], "entities": [{"text": "speech recognition task", "start_pos": 78, "end_pos": 101, "type": "TASK", "confidence": 0.8581085205078125}, {"text": "speech recognition", "start_pos": 143, "end_pos": 161, "type": "TASK", "confidence": 0.7049894034862518}]}, {"text": "Our research attempts to further the quest for continuous understanding by moving one step up the hierarchy, building an incremental parser which is the advisee rather than the advisor.", "labels": [], "entities": []}, {"text": "We begin by presenting a general architecture for incremental interaction between the parser and higher-level modules, and then discuss a specific instantiation of this general architecture in which a reference resolution module provides feedback to the parser on the suitability of noun phrases.", "labels": [], "entities": []}, {"text": "Experiments with incremental feedback from a refer- ence resolution module and an NP suitability oracle are reported, and the ability of the implementation to incrementally instantiate semantically underspecified pronouns is outlined.", "labels": [], "entities": [{"text": "refer- ence resolution", "start_pos": 45, "end_pos": 67, "type": "TASK", "confidence": 0.6171933189034462}]}, {"text": "We believe this research provides an important start towards developing endto-end continuous understanding models.", "labels": [], "entities": []}], "datasetContent": [{"text": "The Monroe domain) is a series of task-oriented dialogues between human participants set in a simulated rescue operation domain, where participants collaboratively plan responses to emergency calls.", "labels": [], "entities": [{"text": "Monroe domain", "start_pos": 4, "end_pos": 17, "type": "DATASET", "confidence": 0.8727470934391022}]}, {"text": "Dialogues were recorded, broken up into utterances, and then transcribed by hand, removing speech repairs from the parser input.", "labels": [], "entities": []}, {"text": "These transcriptions served as input for all experiments reported below.", "labels": [], "entities": []}, {"text": "A probabilistic grammar was trained from supervised data, assigning PCFG probabilities for the rule expansions in the CFG backbone of the handcrafted, semantically constrained grammar.", "labels": [], "entities": [{"text": "CFG backbone", "start_pos": 118, "end_pos": 130, "type": "DATASET", "confidence": 0.9457143545150757}]}, {"text": "The parser was run using this grammar, but without any incremental interaction whatsoever, in order to establish baseline accuracy and efficiency numbers.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 122, "end_pos": 130, "type": "METRIC", "confidence": 0.9743400812149048}]}, {"text": "The corpus consists of six task-oriented dialogues; four were used for the PCFG training, one was held out to establish appropriate parameter values, and one was selected for testing.", "labels": [], "entities": []}, {"text": "The held-out and test dialogues contain hand-checked gold standard parses.", "labels": [], "entities": []}, {"text": "Under normal operation of the sequential dialogue system, the parser is run in best-first mode, providing only a single analysis to higher-level modules, and has a constituent construction limit in an attempt to simulate the demands of a real-time system.", "labels": [], "entities": []}, {"text": "When the parser reaches the constituent limit, appropriate partial analyses are collected and forwarded to higher-level modules.", "labels": [], "entities": []}, {"text": "These constraints were kept in place during our experiments, because they would be necessary under normal operation of the system.", "labels": [], "entities": []}, {"text": "Thus, the inability to parse a sentence does not necessarily indicate alack of coverage of the grammar, but rather alack of efficiency in the parsing process.", "labels": [], "entities": []}, {"text": "As can be seen in, the parser achieves a 94.6% labelled bracket precision, and a 71.1% labelled bracket recall.", "labels": [], "entities": [{"text": "labelled bracket precision", "start_pos": 47, "end_pos": 73, "type": "METRIC", "confidence": 0.7081061402956644}, {"text": "recall", "start_pos": 104, "end_pos": 110, "type": "METRIC", "confidence": 0.895261287689209}]}, {"text": "Note that only constituents of complete parses were checked against the gold standard, to avoid any bias introduced by the partial parse evaluation metric.", "labels": [], "entities": []}, {"text": "Of the 290 gold standard utterances in the test data, 270 could be parsed, and 224 were parsed perfectly.", "labels": [], "entities": []}, {"text": "We began with a feasibility study to determine how significant the effects of incremental advice on noun phrases could be in principle.", "labels": [], "entities": []}, {"text": "The feedback from the reference module is designed to determine whether particular NPs are good or bad from a reference standpoint.", "labels": [], "entities": []}, {"text": "We constructed a simple feedback oracle from supervised data which determined, for each NP, whether or not the final parse of the sentence contained an NP constituent which spanned the same input.", "labels": [], "entities": []}, {"text": "Those NPs marked \"good\", which did appear in the parse, were added to the chart as new constituents.", "labels": [], "entities": []}, {"text": "NPs marked \"bad\" were added to the chart with a probability of zero 1 . A second or-acle evaluation performed this same task, but only providing feedback on definite singular NPs.", "labels": [], "entities": []}, {"text": "The results of both oracles are shown in.", "labels": [], "entities": []}, {"text": "The first five rows give the precision, recall, fstatistic, the raw f-statistic improvement, and the fstatistic error reduction percentage, all determined in terms of labelled bracket accuracy.", "labels": [], "entities": [{"text": "precision", "start_pos": 29, "end_pos": 38, "type": "METRIC", "confidence": 0.9997513890266418}, {"text": "recall", "start_pos": 40, "end_pos": 46, "type": "METRIC", "confidence": 0.9994294047355652}, {"text": "fstatistic", "start_pos": 48, "end_pos": 58, "type": "METRIC", "confidence": 0.9336007237434387}, {"text": "fstatistic error reduction percentage", "start_pos": 101, "end_pos": 138, "type": "METRIC", "confidence": 0.9152124226093292}, {"text": "accuracy", "start_pos": 184, "end_pos": 192, "type": "METRIC", "confidence": 0.6188150644302368}]}, {"text": "There is a marked increase in both precision and recall, with an overall error reduction of 42.4% with the full oracle and 27.2% with the definite singular oracle.", "labels": [], "entities": [{"text": "precision", "start_pos": 35, "end_pos": 44, "type": "METRIC", "confidence": 0.9996095299720764}, {"text": "recall", "start_pos": 49, "end_pos": 55, "type": "METRIC", "confidence": 0.9993131160736084}, {"text": "error reduction", "start_pos": 73, "end_pos": 88, "type": "METRIC", "confidence": 0.9756471514701843}]}, {"text": "Thus, in this domain over a quarter of all incorrectly labelled constituents are attributable to syntactically incorrect definite singular NPs.", "labels": [], "entities": []}, {"text": "The number of constituents built during the parse is used as a measure of efficiency, and the work reduction is reported in the sixth row of the table, showing an efficiency improvement of 30.3% or 18.7%, depending on the oracle.", "labels": [], "entities": []}, {"text": "The final two lines of the table show that both the number of sentences which can be parsed and the number of sentences which are perfectly parsed increase under both models.", "labels": [], "entities": []}, {"text": "The nature of the oracle experiment ensures some reduction in error and complexity, but the magnitude of the improvement is surprising, and certainly encouraging for the prospects of incremental reference.", "labels": [], "entities": [{"text": "error", "start_pos": 62, "end_pos": 67, "type": "METRIC", "confidence": 0.9865096211433411}]}, {"text": "Definite singular NPs typically have a unique referent, providing a locus for effective feedback, and we believe that incremental interaction with an accurate reference module might approach the oracle performance.", "labels": [], "entities": []}, {"text": "For these experiments the parser interacted with the actual reference module, incorporating feedback according to the model discussed in Section 3.3.", "labels": [], "entities": []}, {"text": "The first data column of repeats the baseline results of the parser without reference feedback.", "labels": [], "entities": []}, {"text": "The next two columns show statistics fora run of the parser with incremental feedback from reference, using a probability model based on a classification scheme which distinguished only whether or not the set of referent matches was empty.", "labels": [], "entities": []}, {"text": "The second data column shows the results for the estimated interpolation parameter value of \u03bb = 0.2, while the third data column shows results for the empirically determined optimal \u03bb value of 0.1.", "labels": [], "entities": []}, {"text": "The results are encouraging, with an error reduction of 8.2% or 9.3% on the test dialogue, although the amount of work the parser performed was reduced by only 4.0% and 3.6%.", "labels": [], "entities": [{"text": "error reduction", "start_pos": 37, "end_pos": 52, "type": "METRIC", "confidence": 0.9855014681816101}]}, {"text": "A further encouraging sign is that for every exploratory \u03bb value we whether it is \"good\" or \"bad\".", "labels": [], "entities": []}, {"text": "In this degenerate case of allor-nothing feedback, chart subversion and heuristic subversion are equivalent.", "labels": [], "entities": []}, {"text": "tried in either the held-out or the test data, both the accuracy and efficiency improved.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 56, "end_pos": 64, "type": "METRIC", "confidence": 0.9996482133865356}]}, {"text": "Reference information also helped increase both the number of sentences that could be parsed and the number of sentences that were parsed perfectly, although the improvements were small.", "labels": [], "entities": []}, {"text": "The estimated value of \u03bb = 0.2 produced an error reduction that was approximately 20% of the oracular, which is a very good start, especially considering that this experiment used only the information of whether there was a referent match or not.", "labels": [], "entities": [{"text": "error reduction", "start_pos": 43, "end_pos": 58, "type": "METRIC", "confidence": 0.9833375811576843}]}, {"text": "The efficiency gains were more modest at just above 10% of the oracular results, although one would expect less radical efficiency improvements from this experiment, since under the linear interpolation of the experiment, even extremely dispreferred analyses maybe expanded, whereas the oracle simply drops all dispreferred NPs off the beam immediately.", "labels": [], "entities": []}, {"text": "We performed a second experiment that made more complete use of the reference data, breaking down referent sets according to when and how often they were mentioned, whether they matched the focus, and whether they were in the set of relevant place names.", "labels": [], "entities": []}, {"text": "We expected that this information would provide considerably better results than the simple match/no-match classification above.", "labels": [], "entities": []}, {"text": "For example, consider a definite singular NP: if it matches a single referent, one would expect it to be in the parse with high probability, but multiple matches would indicate that the referent was not unique, and that the base noun probably requires additional discriminating information (e.g. a prepositional phrase or restrictive relative clause).", "labels": [], "entities": []}, {"text": "Unfortunately, as the final column of shows, the additional information did not provide much of an advantage.", "labels": [], "entities": []}, {"text": "The amount of work done was reduced by 4.6%, the largest of any efficiency improvement, but error reduction was only 5.8%, and the number of sentences parsed perfectly actually decreased by one.", "labels": [], "entities": [{"text": "error reduction", "start_pos": 92, "end_pos": 107, "type": "METRIC", "confidence": 0.9123607873916626}]}, {"text": "We conjecture that co-reference chains maybe a significant source of confusion in the reference data.", "labels": [], "entities": []}, {"text": "Ideally, if several entities in the discourse context all refer to the same real-world entity, they should be counted as a single match.", "labels": [], "entities": []}, {"text": "The current reference module does construct co-referential chains, but a single error in co-reference identification will cause all future NPs to match both the chain and the misidentified item, instead of producing the single match desired.", "labels": [], "entities": []}, {"text": "The reference module has to rely on the parser to provide the correct context, so there is something of a bootstrapping problem at work, which indicates both a drawback and a potential of this type of incremental interaction.", "labels": [], "entities": []}, {"text": "The positive feedback loop bodes well for the potential benefits of the incremental system, because as the incremental reference information begins to improve the performance of the parser, the context provided to the reference resolution module improves, which provides even more accurate reference information.", "labels": [], "entities": [{"text": "reference resolution", "start_pos": 218, "end_pos": 238, "type": "TASK", "confidence": 0.6971092373132706}]}, {"text": "Of course, in the early stages of such a system, this works against us; many of the reference resolution errors could be a result of the poor quality of the discourse context.", "labels": [], "entities": [{"text": "reference resolution", "start_pos": 84, "end_pos": 104, "type": "TASK", "confidence": 0.7322835773229599}]}, {"text": "Our current efforts aim to identify and correct these and other reference resolution issues.", "labels": [], "entities": [{"text": "reference resolution", "start_pos": 64, "end_pos": 84, "type": "TASK", "confidence": 0.8228424787521362}]}, {"text": "Not only will this improve the performance of the Reference Advisor from an incremental parsing standpoint, but it should also further our understanding of reference resolution itself.", "labels": [], "entities": [{"text": "reference resolution", "start_pos": 156, "end_pos": 176, "type": "TASK", "confidence": 0.8530676662921906}]}, {"text": "We have shown efficiency improvements in terms of the overall number of constituents constructed by the parser; however, one might ask whether this improvement in parsing speed comes at a large cost to the overall efficiency of the system.", "labels": [], "entities": [{"text": "parsing", "start_pos": 163, "end_pos": 170, "type": "TASK", "confidence": 0.9581130146980286}]}, {"text": "We suggest that this is in some sense the wrong question to ask, because fora real-time interactive system the primary concern is to keep up with the human interlocutor, and the incremental approach offers afar greater opportunity for parallelism between modules.", "labels": [], "entities": []}, {"text": "In terms of time elapsed from speech to analysis, the system as a whole should benefit from the incremental architecture.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Results for (a) The baseline parser without  reference feedback, (b) An Oracle Advisor correctly  determining status of all NPs, (c) An Oracle Advi- sor correctly determining status of definite singular  NPs.", "labels": [], "entities": []}, {"text": " Table 2: Results for Discourse Experiment with  Simple (SC) and Complex (CC) Classifiers", "labels": [], "entities": []}]}