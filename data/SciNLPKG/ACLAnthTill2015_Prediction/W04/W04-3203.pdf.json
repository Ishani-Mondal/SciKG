{"title": [{"text": "Induction of Greedy Controllers for Deterministic Treebank Parsers", "labels": [], "entities": [{"text": "Induction", "start_pos": 0, "end_pos": 9, "type": "TASK", "confidence": 0.9721312522888184}]}], "abstractContent": [{"text": "Most statistical parsers have used the grammar induction approach, in which a stochastic grammar is induced from a treebank.", "labels": [], "entities": [{"text": "grammar induction", "start_pos": 39, "end_pos": 56, "type": "TASK", "confidence": 0.7018349468708038}]}, {"text": "An alternative approach is to induce a controller fora given parsing automaton.", "labels": [], "entities": []}, {"text": "Such controllers maybe stochastic; here, we focus on greedy controllers , which result in deterministic parsers.", "labels": [], "entities": []}, {"text": "We use decision trees to learn the controllers.", "labels": [], "entities": []}, {"text": "The resulting parsers are surprisingly accurate and robust, considering their speed and simplicity.", "labels": [], "entities": []}, {"text": "They are almost as fast as current part-of-speech taggers, and considerably more accurate than a basic unlexicalized PCFG parser.", "labels": [], "entities": [{"text": "part-of-speech taggers", "start_pos": 35, "end_pos": 57, "type": "TASK", "confidence": 0.713528648018837}]}, {"text": "We also describe Markov parsing models, a general framework for parser modeling and control, of which the parsers reported here area special case.", "labels": [], "entities": [{"text": "parser modeling", "start_pos": 64, "end_pos": 79, "type": "TASK", "confidence": 0.9205364882946014}]}], "introductionContent": [{"text": "A fundamental result of formal language theory is that the languages defined by context-free grammars are the same as those accepted by push-down automata.", "labels": [], "entities": [{"text": "formal language theory", "start_pos": 24, "end_pos": 46, "type": "TASK", "confidence": 0.6406451165676117}]}, {"text": "This result was recently extended to the stochastic case).", "labels": [], "entities": []}, {"text": "There are thus two main approaches to training a statistical parser: inducing stochastic grammars and inducing stochastic automata.", "labels": [], "entities": []}, {"text": "Most recent work has employed grammar induction).", "labels": [], "entities": [{"text": "grammar induction", "start_pos": 30, "end_pos": 47, "type": "TASK", "confidence": 0.8005402982234955}]}, {"text": "Examples of the automaton-induction approach are, which described a deterministic parser, and, which described a stochastic parser.", "labels": [], "entities": []}, {"text": "The deterministic parsers reported in this paper are greedy versions of stochastic parsers based on Markov parsing models, described in section 3.3.", "labels": [], "entities": []}, {"text": "A greedy parser takes the single most probable action at every choice point.", "labels": [], "entities": []}, {"text": "It thus does the minimum amount of search possible.", "labels": [], "entities": []}, {"text": "There will always be a tradeoff between speed on the one hand and accuracy and robustness on the other.", "labels": [], "entities": [{"text": "speed", "start_pos": 40, "end_pos": 45, "type": "METRIC", "confidence": 0.9971053004264832}, {"text": "accuracy", "start_pos": 66, "end_pos": 74, "type": "METRIC", "confidence": 0.9994732737541199}]}, {"text": "Our aim, in studying greedy parsers, is to find out what levels of coverage and accuracy can be attained at the high-speed extreme of this tradeoff.", "labels": [], "entities": [{"text": "coverage", "start_pos": 67, "end_pos": 75, "type": "METRIC", "confidence": 0.9836206436157227}, {"text": "accuracy", "start_pos": 80, "end_pos": 88, "type": "METRIC", "confidence": 0.9928332567214966}]}, {"text": "There is no guarantee that a greedy parser will find the best parse, or indeed any complete parse.", "labels": [], "entities": []}, {"text": "So the accuracy and coverage of greedy parsers are both interesting empirical questions.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 7, "end_pos": 15, "type": "METRIC", "confidence": 0.9988027811050415}, {"text": "coverage", "start_pos": 20, "end_pos": 28, "type": "METRIC", "confidence": 0.9682669639587402}]}, {"text": "We find that they are almost as fast as current part-of-speech taggers, and they outperform basic unlexicalized PCFG parsers.", "labels": [], "entities": [{"text": "part-of-speech taggers", "start_pos": 48, "end_pos": 70, "type": "TASK", "confidence": 0.7228817939758301}]}, {"text": "While coverage is a concern, it is quite high (over 99%) for some of our parsers.", "labels": [], "entities": [{"text": "coverage", "start_pos": 6, "end_pos": 14, "type": "METRIC", "confidence": 0.995731770992279}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Parser performance on section 23 of the Penn Treebank. Coverage, recall, and precision  are given as percentages.", "labels": [], "entities": [{"text": "section 23 of the Penn Treebank", "start_pos": 32, "end_pos": 63, "type": "DATASET", "confidence": 0.7469715674718221}, {"text": "Coverage", "start_pos": 65, "end_pos": 73, "type": "METRIC", "confidence": 0.9984606504440308}, {"text": "recall", "start_pos": 75, "end_pos": 81, "type": "METRIC", "confidence": 0.9995343685150146}, {"text": "precision", "start_pos": 87, "end_pos": 96, "type": "METRIC", "confidence": 0.999815046787262}]}]}