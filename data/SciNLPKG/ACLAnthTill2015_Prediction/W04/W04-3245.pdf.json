{"title": [{"text": "From Machine Translation to Computer Assisted Translation using Finite-State Models", "labels": [], "entities": [{"text": "Machine Translation", "start_pos": 5, "end_pos": 24, "type": "TASK", "confidence": 0.8067571222782135}, {"text": "Computer Assisted Translation", "start_pos": 28, "end_pos": 57, "type": "TASK", "confidence": 0.7143949568271637}]}], "abstractContent": [{"text": "State-of-the-art machine translation techniques are still far from producing high quality translations.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 17, "end_pos": 36, "type": "TASK", "confidence": 0.7325046360492706}]}, {"text": "This drawback leads us to introduce an alternative approach to the translation problem that brings human expertise into the machine translation scenario.", "labels": [], "entities": [{"text": "translation problem", "start_pos": 67, "end_pos": 86, "type": "TASK", "confidence": 0.935442179441452}, {"text": "machine translation", "start_pos": 124, "end_pos": 143, "type": "TASK", "confidence": 0.7726962268352509}]}, {"text": "In this framework, namely Computer Assisted Translation (CAT), human translators interact with a translation system, as an assistance tool, that dinamically offers, a list of translations that best completes the part of the sentence already translated.", "labels": [], "entities": [{"text": "Computer Assisted Translation (CAT)", "start_pos": 26, "end_pos": 61, "type": "TASK", "confidence": 0.8175776700178782}]}, {"text": "In this paper, finite state transducers are presented as a candidate technology in the CAT paradigm.", "labels": [], "entities": [{"text": "CAT", "start_pos": 87, "end_pos": 90, "type": "TASK", "confidence": 0.9882892370223999}]}, {"text": "The appropriateness of this technique is evaluated on a printer manual corpus and results from preliminary experiments confirm that human translators would reduce to less than 25% the amount of work to be done for the same task.", "labels": [], "entities": [{"text": "printer manual corpus", "start_pos": 56, "end_pos": 77, "type": "DATASET", "confidence": 0.7092556854089102}]}], "introductionContent": [{"text": "State-of-the-art machine translation techniques are still far from producing high quality translations.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 17, "end_pos": 36, "type": "TASK", "confidence": 0.7325046360492706}]}, {"text": "This drawback leads us to introduce an alternative approach to the translation problem that brings human expertise into the machine translation scenario.", "labels": [], "entities": [{"text": "translation problem", "start_pos": 67, "end_pos": 86, "type": "TASK", "confidence": 0.935442179441452}, {"text": "machine translation", "start_pos": 124, "end_pos": 143, "type": "TASK", "confidence": 0.7726962268352509}]}, {"text": "() proposed this idea that can be illustrated as follows.", "labels": [], "entities": []}, {"text": "Initially, the human translator is provided with a possible translation for the sentence to be translated.", "labels": [], "entities": []}, {"text": "Unfortunately inmost of the cases, this translation is not perfect, so the translator amends it and asks fora translation of the part of the sentence still to be translated (completion).", "labels": [], "entities": []}, {"text": "This latter interaction is repeated as many times as needed until the final translation is achieved.", "labels": [], "entities": []}, {"text": "The scenario described in the previous paragraph, can be seen as an iterative refinement of the translations offered by the translation system, that without possessing the desired quality, help the translator to increase his/her productivity.", "labels": [], "entities": []}, {"text": "Nowadays, this lack of translation excellence is a common characteristic in all machine translation systems.", "labels": [], "entities": [{"text": "translation", "start_pos": 23, "end_pos": 34, "type": "TASK", "confidence": 0.9674041271209717}, {"text": "machine translation", "start_pos": 80, "end_pos": 99, "type": "TASK", "confidence": 0.7114038467407227}]}, {"text": "Therefore, the human-machine synergy represented by the CAT paradigm seems to be more promising than fully-automatic translation in the near future.", "labels": [], "entities": [{"text": "CAT", "start_pos": 56, "end_pos": 59, "type": "TASK", "confidence": 0.9736143946647644}]}, {"text": "The CAT paradigm has two important aspects: the models need to provide adequate completions and they have to do so efficiently to perform under usability constrains.", "labels": [], "entities": [{"text": "CAT", "start_pos": 4, "end_pos": 7, "type": "TASK", "confidence": 0.982693076133728}]}, {"text": "To fulfill these two requirements, Stochastic Finite State Transducers (SFST) have been selected since they have proved in the past to be able to provide adequate translations).", "labels": [], "entities": []}, {"text": "In addition, efficient parsing algorithms can be easily adapted in order to provide completions.", "labels": [], "entities": []}, {"text": "The rest of the paper is structured as follows.", "labels": [], "entities": []}, {"text": "The following section introduces the general setting for machine translation and finite state models.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 57, "end_pos": 76, "type": "TASK", "confidence": 0.8060860335826874}]}, {"text": "In section 3, the search procedure for an interactive translation is presented.", "labels": [], "entities": []}, {"text": "Experimental results are presented in section 4.", "labels": [], "entities": []}, {"text": "Finally, some conclusions and future work are explained in section 5.", "labels": [], "entities": []}], "datasetContent": [{"text": "The assessment of the techniques presented in section 3 has been carried out using three measures: 1.", "labels": [], "entities": []}, {"text": "Translation Word Error Rate (TWER): It is defined as the minimum number of word substitution, deletion and insertion operations to convert the target sentence provided by the transducer into the reference translation.", "labels": [], "entities": [{"text": "Word Error Rate (TWER)", "start_pos": 12, "end_pos": 34, "type": "METRIC", "confidence": 0.8069991966088613}]}, {"text": "Also known as edit distance.", "labels": [], "entities": [{"text": "edit distance", "start_pos": 14, "end_pos": 27, "type": "METRIC", "confidence": 0.904506266117096}]}, {"text": "2. Character Error Rate (CER): Edit distance in terms of characters between the target sentence provided by the transducer and the reference translation.", "labels": [], "entities": [{"text": "Character Error Rate (CER)", "start_pos": 3, "end_pos": 29, "type": "METRIC", "confidence": 0.8709287146727244}, {"text": "Edit distance", "start_pos": 31, "end_pos": 44, "type": "METRIC", "confidence": 0.9759269654750824}]}, {"text": "3. Key-Stroke Ratio (KSR): Number of keystrokes that are necessary to achieve the reference translation plus the acceptance keystroke divided by the number of running characters.", "labels": [], "entities": [{"text": "Key-Stroke Ratio (KSR)", "start_pos": 3, "end_pos": 25, "type": "METRIC", "confidence": 0.9093476176261902}, {"text": "reference translation", "start_pos": 82, "end_pos": 103, "type": "TASK", "confidence": 0.6254526674747467}]}, {"text": "4. BiLingual Evaluation Understudy (BLEU) (): Basically is a function of the k-substrings that appear in the hypothesized target sentence and in the reference target sentence.", "labels": [], "entities": [{"text": "BiLingual Evaluation Understudy (BLEU)", "start_pos": 3, "end_pos": 41, "type": "METRIC", "confidence": 0.8196558207273483}]}, {"text": "These experiments were perfomed with 3-gram transducers based on the GIATI technique.", "labels": [], "entities": [{"text": "GIATI", "start_pos": 69, "end_pos": 74, "type": "METRIC", "confidence": 0.7449492812156677}]}, {"text": "On the leftmost column appears the language pair employed for each experiment, English (En), Spanish (Es), French (Fr) and German (De).", "labels": [], "entities": []}, {"text": "The main two central columns compare the results obtained with 1-best translation to 5-best translations.", "labels": [], "entities": []}, {"text": "When using 5-best translations, that target sentence out of these five, that minimizes most the correspondent error measure is selected.", "labels": [], "entities": [{"text": "correspondent error measure", "start_pos": 96, "end_pos": 123, "type": "METRIC", "confidence": 0.8266671895980835}]}, {"text": "The results are shown in Table 2.", "labels": [], "entities": []}, {"text": "The best results were obtained between English and Spanish language pairs, in which the human translator would need to type less than 25% of the total reference sentences.", "labels": [], "entities": []}, {"text": "In other words, this would result in a theoretically factor of 4 increase in the productivity of human translators.", "labels": [], "entities": []}, {"text": "In fact, preliminary subjective evaluations have received positive feedback from professional translators when testing the prototype.", "labels": [], "entities": []}, {"text": "Furthermore, in all cases there is a clear and significant improvement in error measures when moving from 1 to 5-best translations.", "labels": [], "entities": [{"text": "error", "start_pos": 74, "end_pos": 79, "type": "METRIC", "confidence": 0.9861176609992981}]}, {"text": "This gain in translation quality dimishes in a log-wise fashion as the number of best translations increases.", "labels": [], "entities": []}, {"text": "However, the number of hypotheses should be limited to the user capability to skim through the candidate translations and decide on which one to select.", "labels": [], "entities": []}, {"text": "Pair of languages as English and French presents somewhat higher error rates, as is also the case between English and German, reflecting the complexity of the task faced in these experiments.", "labels": [], "entities": [{"text": "error rates", "start_pos": 65, "end_pos": 76, "type": "METRIC", "confidence": 0.9780395030975342}]}], "tableCaptions": [{"text": " Table 1: Features of Xerox Corpus: training, vocabulary and test sizes measured in thousands of words.  SIM: Currently used \"reversible\" preprocessing.  RAW: Original corpus without preprocess.  PERPLEXITY: Measure how well a language model describes the test set.", "labels": [], "entities": [{"text": "Xerox Corpus", "start_pos": 22, "end_pos": 34, "type": "DATASET", "confidence": 0.9617751836776733}, {"text": "SIM", "start_pos": 105, "end_pos": 108, "type": "METRIC", "confidence": 0.9043454527854919}, {"text": "RAW", "start_pos": 154, "end_pos": 157, "type": "METRIC", "confidence": 0.7228733897209167}, {"text": "PERPLEXITY", "start_pos": 196, "end_pos": 206, "type": "METRIC", "confidence": 0.9857848286628723}]}, {"text": " Table 2: Results for the Xerox Corpus comparing  1-best to 5-best translations", "labels": [], "entities": [{"text": "Xerox Corpus", "start_pos": 26, "end_pos": 38, "type": "DATASET", "confidence": 0.9120230674743652}]}, {"text": " Table 3: Results for the Xerox Corpus comparing  1-best to 5-best translations", "labels": [], "entities": [{"text": "Xerox Corpus", "start_pos": 26, "end_pos": 38, "type": "DATASET", "confidence": 0.9114924669265747}]}]}