{"title": [{"text": "Adaptation of Maximum Entropy Capitalizer: Little Data Can Help a Lot", "labels": [], "entities": []}], "abstractContent": [{"text": "A novel technique for maximum \"a posteriori\" (MAP) adaptation of maximum entropy (MaxEnt) and maximum entropy Markov models (MEMM) is presented.", "labels": [], "entities": []}, {"text": "The technique is applied to the problem of recovering the correct capitalization of uniformly cased text: a \"background\" capitalizer trained on 20Mwds of Wall Street Journal (WSJ) text from 1987 is adapted to two Broadcast News (BN) test sets-one containing ABC Primetime Live text and the other NPR Morning News/CNN Morning Edition text-from 1996.", "labels": [], "entities": [{"text": "Wall Street Journal (WSJ) text", "start_pos": 154, "end_pos": 184, "type": "DATASET", "confidence": 0.8091986094202314}, {"text": "Broadcast News (BN) test sets-one containing ABC Primetime Live text", "start_pos": 213, "end_pos": 281, "type": "DATASET", "confidence": 0.7216897408167521}, {"text": "NPR Morning News/CNN Morning Edition text-from 1996", "start_pos": 296, "end_pos": 347, "type": "DATASET", "confidence": 0.7988087998496162}]}, {"text": "The \"in-domain\" performance of the WSJ capi-talizer is 45% better than that of the 1-gram base-line, when evaluated on a test set drawn from WSJ 1994.", "labels": [], "entities": [{"text": "WSJ", "start_pos": 35, "end_pos": 38, "type": "DATASET", "confidence": 0.9268730282783508}, {"text": "WSJ 1994", "start_pos": 141, "end_pos": 149, "type": "DATASET", "confidence": 0.9543956816196442}]}, {"text": "When evaluating on the mismatched \"out-of-domain\" test data, the 1-gram baseline is outper-formed by 60%; the improvement brought by the adaptation technique using a very small amount of matched BN data-25-70kwds-is about 20-25% relative.", "labels": [], "entities": [{"text": "BN data-25-70kwds-is", "start_pos": 195, "end_pos": 215, "type": "DATASET", "confidence": 0.7612048089504242}]}, {"text": "Overall, automatic capitalization error rate of 1.4% is achieved on BN data.", "labels": [], "entities": [{"text": "automatic capitalization error rate", "start_pos": 9, "end_pos": 44, "type": "METRIC", "confidence": 0.8273154348134995}, {"text": "BN data", "start_pos": 68, "end_pos": 75, "type": "DATASET", "confidence": 0.881725013256073}]}], "introductionContent": [{"text": "Automatic capitalization is a practically relevant problem: speech recognition output needs to be capitalized; also, modern word processors perform capitalization among other text proofing algorithms such as spelling correction and grammar checking.", "labels": [], "entities": [{"text": "Automatic capitalization", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.6932652592658997}, {"text": "spelling correction", "start_pos": 208, "end_pos": 227, "type": "TASK", "confidence": 0.8324149549007416}, {"text": "grammar checking", "start_pos": 232, "end_pos": 248, "type": "TASK", "confidence": 0.6856376677751541}]}, {"text": "Capitalization can be also used as a preprocessing step in named entity extraction or machine translation.", "labels": [], "entities": [{"text": "named entity extraction", "start_pos": 59, "end_pos": 82, "type": "TASK", "confidence": 0.633204996585846}, {"text": "machine translation", "start_pos": 86, "end_pos": 105, "type": "TASK", "confidence": 0.7349546253681183}]}, {"text": "We study the impact of using increasing amounts of training data as well as using a small amount of adaptation data on this simple problem that is well suited to data-driven approaches since vast amounts of \"training\" data are easily obtainable by simply wiping the case information in text.", "labels": [], "entities": []}, {"text": "As in previous approaches, the problem is framed as an instance of the class of sequence labeling problems.", "labels": [], "entities": [{"text": "sequence labeling", "start_pos": 80, "end_pos": 97, "type": "TASK", "confidence": 0.5953560322523117}]}, {"text": "A case frequently encountered in practice is that of using mismatched -out-of-domain, in this particular case we used Broadcast Newstest data.", "labels": [], "entities": [{"text": "Broadcast Newstest data", "start_pos": 118, "end_pos": 141, "type": "DATASET", "confidence": 0.966699481010437}]}, {"text": "For example, one may wish to use a capitalization engine developed on newswire text for email or office documents.", "labels": [], "entities": []}, {"text": "This typically affects negatively the performance of a given model, and more sophisticated models tend to be more brittle.", "labels": [], "entities": []}, {"text": "In the capitalization case we have studied, the relative performance improvement of the MEMM capitalizer over the 1-gram baseline drops from in-domain -WSJ -performance of 45% to 35-40% when used on the slightly mismatched BN data.", "labels": [], "entities": [{"text": "BN data", "start_pos": 223, "end_pos": 230, "type": "DATASET", "confidence": 0.8810650408267975}]}, {"text": "In order to take advantage of the adaptation data in our scenario, a maximum a-posteriori (MAP) adaptation technique for maximum entropy (MaxEnt) models is developed.", "labels": [], "entities": []}, {"text": "The adaptation procedure proves to be quite effective in further reducing the capitalization error of the WSJ MEMM capitalizer on BN test data.", "labels": [], "entities": [{"text": "WSJ MEMM capitalizer", "start_pos": 106, "end_pos": 126, "type": "DATASET", "confidence": 0.7663588921229044}, {"text": "BN test data", "start_pos": 130, "end_pos": 142, "type": "DATASET", "confidence": 0.8546809752782186}]}, {"text": "It is also quite general and could improve performance of MaxEnt models in any scenario where model adaptation is desirable.", "labels": [], "entities": []}, {"text": "A further relative improvement of about 20% is obtained by adapting the WSJ model to Broadcast News (BN) text.", "labels": [], "entities": [{"text": "WSJ model", "start_pos": 72, "end_pos": 81, "type": "DATASET", "confidence": 0.8565539717674255}, {"text": "Broadcast News (BN) text", "start_pos": 85, "end_pos": 109, "type": "DATASET", "confidence": 0.8715993265310923}]}, {"text": "Overall, the MEMM capitalizer adapted to BN data achieves 60% relative improvement inaccuracy over the 1-gram baseline.", "labels": [], "entities": [{"text": "BN data", "start_pos": 41, "end_pos": 48, "type": "DATASET", "confidence": 0.8721825182437897}]}, {"text": "The paper is organized as follows: the next section frames automatic capitalization as a sequence labeling problem, presents previous approaches as well as the widespread and highly sub-optimal 1-gram capitalization technique that is used as a baseline inmost experiments in this work and others.", "labels": [], "entities": [{"text": "sequence labeling", "start_pos": 89, "end_pos": 106, "type": "TASK", "confidence": 0.6449637711048126}]}, {"text": "The MEMM sequence labeling technique is briefly reviewed in Section 3.", "labels": [], "entities": [{"text": "MEMM sequence labeling", "start_pos": 4, "end_pos": 26, "type": "TASK", "confidence": 0.7474750081698099}]}, {"text": "Section 4 describes the MAP adaptation technique used for the capitalization of out-of-domain text.", "labels": [], "entities": [{"text": "MAP adaptation", "start_pos": 24, "end_pos": 38, "type": "TASK", "confidence": 0.9789873361587524}, {"text": "capitalization of out-of-domain text", "start_pos": 62, "end_pos": 98, "type": "TASK", "confidence": 0.8892209231853485}]}, {"text": "The detailed mathematical derivation is presented in Appendix A. The experimental results are presented in Section 5, followed by conclusions and suggestions for future work.", "labels": [], "entities": [{"text": "Appendix", "start_pos": 53, "end_pos": 61, "type": "METRIC", "confidence": 0.7784255743026733}]}], "datasetContent": [{"text": "The baseline 1-gram and the background MEMM capitalizer were trained on various amounts of WSJ () data from 1987 -files WS87_{001-126}.", "labels": [], "entities": [{"text": "WSJ () data from 1987 -files WS87_{001-126", "start_pos": 91, "end_pos": 133, "type": "DATASET", "confidence": 0.9021494090557098}]}, {"text": "The in-domain test data used was file WS94_000 (8.7kwds).", "labels": [], "entities": [{"text": "WS94_000", "start_pos": 38, "end_pos": 46, "type": "DATASET", "confidence": 0.867313027381897}]}, {"text": "As for the adaptation experiments, two different sets of BN data were used, whose sizes are summarized in 1.", "labels": [], "entities": [{"text": "BN data", "start_pos": 57, "end_pos": 64, "type": "DATASET", "confidence": 0.7349669933319092}]}, {"text": "BN CNN/NPR data.", "labels": [], "entities": [{"text": "BN CNN/NPR data", "start_pos": 0, "end_pos": 15, "type": "DATASET", "confidence": 0.9286930799484253}]}, {"text": "The training/development/test partition consisted of a 3-way random split of file BN624BTS.", "labels": [], "entities": [{"text": "BN624BTS", "start_pos": 82, "end_pos": 90, "type": "DATASET", "confidence": 0.913907527923584}]}, {"text": "The resulting sets are denoted CNN-trn/dev/tst, respectively 2.", "labels": [], "entities": [{"text": "CNN-trn", "start_pos": 31, "end_pos": 38, "type": "DATASET", "confidence": 0.8895935416221619}]}, {"text": "The training set consisted of file BN623ATS whereas the development/test set consisted of a 2-way random split of file BN624ATS  We have proceeded building both 1-gram and MEMM capitalizers using various amounts of background training data.", "labels": [], "entities": []}, {"text": "The model sizes for the 1-gram and MEMM capitalizer are presented in Table 2.", "labels": [], "entities": []}, {"text": "Count cut-off feature selection has been used Thanks to one of the anonymous reviewers for pointing out this possible connection.: Background models performance on indomain (WSJ-test) and out-of-domain (BN-dev) data for various amounts of training data than the 1-gram one when trained and evaluated on Wall Street Journal text.", "labels": [], "entities": [{"text": "Wall Street Journal text", "start_pos": 303, "end_pos": 327, "type": "DATASET", "confidence": 0.9782642126083374}]}, {"text": "The relative performance improvement of the MEMM capitalizer over the 1-gram baseline drops to 35-40% when using out-ofdomain Broadcast News data.", "labels": [], "entities": [{"text": "out-ofdomain Broadcast News data", "start_pos": 113, "end_pos": 145, "type": "DATASET", "confidence": 0.7200280427932739}]}, {"text": "Both models benefit from using more training data.", "labels": [], "entities": []}, {"text": "We have then adapted the best MEMM model built on 20Mwds on the two BN data sets (CNN/ABC) and compared performance against the 1-gram and the unadapted MEMM models.", "labels": [], "entities": [{"text": "BN data sets", "start_pos": 68, "end_pos": 80, "type": "DATASET", "confidence": 0.9578308264414469}]}, {"text": "There area number of parameters to be tuned on development data.", "labels": [], "entities": []}, {"text": "presents the variation in model size with different count cut-off values for the feature selection procedure on the adaptation data.", "labels": [], "entities": []}, {"text": "As can be seen, very few features are added to the background model.", "labels": [], "entities": []}, {"text": "presents the variation in log-likelihood and capitalization accuracy on the CNN adaptation training and development data, respectively.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 60, "end_pos": 68, "type": "METRIC", "confidence": 0.7426325678825378}]}, {"text": "The adaptation procedure was found Cut-off 0 5 10 6 No. features 243,262 237,745 237,586: Adapted model size as a function of count cut-off threshold used for feature selection on CNNtrn adaptation data; the entry corresponding to the cut-off threshold of 10 6 represents the number of features in the background model to be insensitive to the number of reestimation iterations, and, more surprisingly, to the number of features added to the background model from the adaptation data, as shown in 5.", "labels": [], "entities": [{"text": "CNNtrn adaptation data", "start_pos": 180, "end_pos": 202, "type": "DATASET", "confidence": 0.9468150734901428}]}, {"text": "The most sensitive parameter is the prior variance \u03c3 2 , as shown in; its value is chosen to maximize classification accuracy on development data.", "labels": [], "entities": [{"text": "prior variance \u03c3 2", "start_pos": 36, "end_pos": 54, "type": "METRIC", "confidence": 0.8789314180612564}, {"text": "classification", "start_pos": 102, "end_pos": 116, "type": "TASK", "confidence": 0.9438222050666809}, {"text": "accuracy", "start_pos": 117, "end_pos": 125, "type": "METRIC", "confidence": 0.8870813250541687}]}, {"text": "As expected, low values of \u03c3 2 result in no adaptation at all, whereas high values of \u03c3 2 fit the training data very well, and result in a dramatic increase of training data loglikelihood and accuracies approaching 100%.", "labels": [], "entities": [{"text": "accuracies", "start_pos": 192, "end_pos": 202, "type": "METRIC", "confidence": 0.9938837885856628}]}, {"text": "Finally, presents the results on test data for 1-gram, background and adapted MEMM.", "labels": [], "entities": [{"text": "MEMM", "start_pos": 78, "end_pos": 82, "type": "DATASET", "confidence": 0.725979208946228}]}, {"text": "As can be seen, the background MEMM outperforms the 1-gram model on both BN test sets by about 35-40% relative.", "labels": [], "entities": [{"text": "MEMM", "start_pos": 31, "end_pos": 35, "type": "METRIC", "confidence": 0.6275259256362915}, {"text": "BN test sets", "start_pos": 73, "end_pos": 85, "type": "DATASET", "confidence": 0.8875119884808859}]}, {"text": "Adaptation improves performance even further by another 20-25% relative.", "labels": [], "entities": [{"text": "Adaptation", "start_pos": 0, "end_pos": 10, "type": "TASK", "confidence": 0.8826847076416016}]}, {"text": "Overall, the adapted models achieve 60% relative reduction in capitalization error over the 1-gram baseline on both BN test sets.", "labels": [], "entities": [{"text": "capitalization error", "start_pos": 62, "end_pos": 82, "type": "METRIC", "confidence": 0.8113624155521393}, {"text": "BN test sets", "start_pos": 116, "end_pos": 128, "type": "DATASET", "confidence": 0.8849301735560099}]}, {"text": "An intuitively satisfying result is the fact that the cross-test set performance (CNN", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Background and adaptation training, devel- opment, and test data partition sizes", "labels": [], "entities": [{"text": "devel- opment", "start_pos": 46, "end_pos": 59, "type": "TASK", "confidence": 0.6645426253477732}]}, {"text": " Table 3: Background models performance on in- domain (WSJ-test) and out-of-domain (BN-dev)  data for various amounts of training data", "labels": [], "entities": []}, {"text": " Table 5: Adapted model performance for various  count cut-off and \u03c3 2 variance values; log-likelihood  and accuracy on adaptation data CNN-trn as well  as accuracy on held-out data CNN-dev; the back- ground model results (no new features added) are  the entries corresponding to the cut-off threshold of  10 6", "labels": [], "entities": [{"text": "accuracy", "start_pos": 108, "end_pos": 116, "type": "METRIC", "confidence": 0.9992918968200684}, {"text": "accuracy", "start_pos": 156, "end_pos": 164, "type": "METRIC", "confidence": 0.999085545539856}, {"text": "CNN-dev", "start_pos": 182, "end_pos": 189, "type": "DATASET", "confidence": 0.9208003282546997}]}, {"text": " Table 6: Background and adapted models perfor- mance on BN test data; two adaptation/test sets are  used: ABC and CNN", "labels": [], "entities": [{"text": "BN test data", "start_pos": 57, "end_pos": 69, "type": "DATASET", "confidence": 0.9251062472661337}, {"text": "CNN", "start_pos": 115, "end_pos": 118, "type": "DATASET", "confidence": 0.7383920550346375}]}]}