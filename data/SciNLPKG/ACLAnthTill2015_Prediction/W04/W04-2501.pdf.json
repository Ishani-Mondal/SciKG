{"title": [], "abstractContent": [{"text": "Progress in Question Answering can be achieved by (1) combining multiple strategies that optimally resolve different question classes of various degrees of complexity; (2) enhancing the precision of question interpretation and answer extraction; and (3) question decomposition and answer fusion.", "labels": [], "entities": [{"text": "Question Answering", "start_pos": 12, "end_pos": 30, "type": "TASK", "confidence": 0.8094469308853149}, {"text": "precision", "start_pos": 186, "end_pos": 195, "type": "METRIC", "confidence": 0.9987478256225586}, {"text": "question interpretation", "start_pos": 199, "end_pos": 222, "type": "TASK", "confidence": 0.7210155427455902}, {"text": "answer extraction", "start_pos": 227, "end_pos": 244, "type": "TASK", "confidence": 0.7168390899896622}, {"text": "question decomposition", "start_pos": 254, "end_pos": 276, "type": "TASK", "confidence": 0.8431641459465027}, {"text": "answer fusion", "start_pos": 281, "end_pos": 294, "type": "TASK", "confidence": 0.7777049541473389}]}, {"text": "In this paper we also present the impact of modeling the user background on Q/A and discuss the pragmatics pf processing negation in Q/A.", "labels": [], "entities": []}], "introductionContent": [{"text": "Our fundamental premise is that progress in Q/A cannot be achieved only by enhancing the processing components, but it also requires generating the best strategies for processing each individual question.", "labels": [], "entities": []}, {"text": "Thus we believe that Q/A systems capable of successfully processing complex questions should employ multiple strategies instead of the current pipeline approach, consisting of (1) question processing, (2) passage retrieval and (3) answer selection.", "labels": [], "entities": [{"text": "question processing", "start_pos": 180, "end_pos": 199, "type": "TASK", "confidence": 0.7754409313201904}, {"text": "passage retrieval", "start_pos": 205, "end_pos": 222, "type": "TASK", "confidence": 0.8238186836242676}, {"text": "answer selection", "start_pos": 231, "end_pos": 247, "type": "TASK", "confidence": 0.8505899906158447}]}, {"text": "The pipeline architecture was reported in ().", "labels": [], "entities": []}, {"text": "Recently, a novel approach based on combinations of multiple independent agents implementing different answer finding strategies (multistrategy) and multiple search spaces (multiple-source) was developed by the IBM QA group (.", "labels": [], "entities": [{"text": "answer finding", "start_pos": 103, "end_pos": 117, "type": "TASK", "confidence": 0.8595066070556641}]}, {"text": "In () another form of combining strategies for advanced QA is proposed: (1) a knowledge-based Q/A implementation based on syntactic/semantic processing is combined using a maximum-entropy framework with (2) a statistical noisy-channel algorithm for Q/A and (3) a pattern-based approach that learn from Web data.", "labels": [], "entities": []}, {"text": "In this project we propose a different form of finding optimal strategies of advanced QA which is based on (a) Question Decomposition, (b) Answer Fusion and feedback from (c) Interactive Q&A and (d) User Background Recognition.", "labels": [], "entities": [{"text": "Question Decomposition", "start_pos": 111, "end_pos": 133, "type": "TASK", "confidence": 0.6312731802463531}, {"text": "Answer Fusion", "start_pos": 139, "end_pos": 152, "type": "TASK", "confidence": 0.8917669951915741}, {"text": "User Background Recognition", "start_pos": 199, "end_pos": 226, "type": "TASK", "confidence": 0.6247687538464864}]}, {"text": "We argue that all this new architectures operate under the assumption that there is a concept-based or pattern-based method for identifying the correct answer for any question that will be processed.", "labels": [], "entities": []}, {"text": "However, we believe that there are complex questions that need first to be decomposed into simple questions, for which concept-based or pattern-based resolving techniques either exists or maybe developed.", "labels": [], "entities": []}, {"text": "For instance, when asking Q 1 : \"How have thefts impacted on the safety of Russia's nuclear navy, and has the theft problem been increased or decreased over time?\" we may have series of simpler questions that decompose the question focus.", "labels": [], "entities": []}, {"text": "One such example of simple question is Q 1 a : \"What specific instances of theft do we know about?\"", "labels": [], "entities": []}, {"text": "-which is a listquestion similar to those evaluated in the recent TREC tracks (.", "labels": [], "entities": [{"text": "TREC tracks", "start_pos": 66, "end_pos": 77, "type": "DATASET", "confidence": 0.8159267008304596}]}, {"text": "Related, simpler question is Q 1 b : \"What sort of items have been stolen?\".", "labels": [], "entities": []}, {"text": "Question Q 1 a asks about instantiations of the theft events, whereas question Q 1 b inquires about the objects of the events.", "labels": [], "entities": []}, {"text": "The decompositions may follow other arguments of the event predicates, e.g. -the agents in Q 1 c : \"Who are the perpetrators of these thefts?\" as well as specializations of the events, e.g. \"economical impact\" specializing one of the possible impacts of the thefts in the question Q 1 d : \"Do thefts have an economical impact on the naval bases?\".", "labels": [], "entities": []}, {"text": "Furthermore, the concepts from the complex question need to be clearly understood, and often definition questions will be considered as decompositions that enable the processing of complex questions.", "labels": [], "entities": []}, {"text": "The definition may involve entities from the complex question, e.g. Q 1 e : \"What is meant by nuclear navy?\" or events from the complex question, e.g. Q 1 f : \"What does 'impact' mean?\"", "labels": [], "entities": []}, {"text": "There are several criteria that guide question decomposition, which also determine the answer resolution strategies.", "labels": [], "entities": [{"text": "question decomposition", "start_pos": 38, "end_pos": 60, "type": "TASK", "confidence": 0.8187769651412964}, {"text": "answer resolution", "start_pos": 87, "end_pos": 104, "type": "TASK", "confidence": 0.7815522849559784}]}, {"text": "The criteria are: When a complex question is processed, and is decomposed into a set of simpler questions which are analyzed independently.", "labels": [], "entities": []}, {"text": "Each decomposed question may belong to a different class, for which certain strategies maybe optimal.", "labels": [], "entities": []}, {"text": "Such strategies implement the pragmatic processes that interact with the syntactic and semantic information that results from the derivation of: (1) expected answer types or structures, (2) name entities which are recognized, as well as (3) syntactic and semantic dependencies derived from the parsing of the question into predicate-argument structures.", "labels": [], "entities": []}, {"text": "To be able to process the question precisely we are developing techniques that leverage a database of one million questions that have answers in a controlled corpus.", "labels": [], "entities": []}, {"text": "This large database provides wide coverage of answer types and answer instances.", "labels": [], "entities": []}, {"text": "It also enhances the retrieval, navigation and fusion of partial answers.", "labels": [], "entities": [{"text": "navigation", "start_pos": 32, "end_pos": 42, "type": "TASK", "confidence": 0.9146234393119812}]}, {"text": "The challenge of creating a set of approximately one million question and answer pairs are twofold.", "labels": [], "entities": []}, {"text": "First, the pairs need to be diverse in terms of difficulty, where difficulty can be defined in terms of answer type complexity (common, uncommon, requiring decomposition), answer granularity (concentrated within a small fragment or spread across several passages and documents), ease of matching (requiring both surface-text and deep semantic understanding).", "labels": [], "entities": []}, {"text": "Second, the pairs should be reliable, i.e. each question must be associated with a correct answer.", "labels": [], "entities": []}, {"text": "Our solution is a combination of collection and generation from semi-structured resources, followed by expansion and validation.", "labels": [], "entities": []}, {"text": "We will generate the collection of QA pairs from Frequently Asked Questions (FAQ) files on various topics.", "labels": [], "entities": []}, {"text": "We will develop a dedicated harvesting algorithm to identify FAQ's on the Web and extract the QA pairs.", "labels": [], "entities": []}, {"text": "The large database of questions also allows us to create a benchmark that will support the development of statistical techniques for Q/A.", "labels": [], "entities": []}, {"text": "The architecture of the benchmark system is illustrated in.", "labels": [], "entities": []}, {"text": "Our system selects answers based on (1) question processing strategies; (2) passage retrieval strategies made possible by (3) question decomposition and (4) answer fusion.", "labels": [], "entities": [{"text": "question processing", "start_pos": 40, "end_pos": 59, "type": "TASK", "confidence": 0.6931133419275284}, {"text": "passage retrieval", "start_pos": 76, "end_pos": 93, "type": "TASK", "confidence": 0.7877326607704163}, {"text": "question decomposition", "start_pos": 126, "end_pos": 148, "type": "TASK", "confidence": 0.730828121304512}, {"text": "answer fusion", "start_pos": 157, "end_pos": 170, "type": "TASK", "confidence": 0.7659015357494354}]}, {"text": "When a question is posed to the system, it is either decomposed on a set of simpler questions or it is processed in parallel with similar questions provided by the Interactive Question Answering component.", "labels": [], "entities": [{"text": "Interactive Question Answering", "start_pos": 164, "end_pos": 194, "type": "TASK", "confidence": 0.5253638525803884}]}, {"text": "Based on the user background, a set of similar questions maybe selected and analyzed in parallel.", "labels": [], "entities": []}, {"text": "Multiple strategies are available for retrieving relevant passages.", "labels": [], "entities": []}, {"text": "The possible selections are once again dictated by feedback from interactions with the user.", "labels": [], "entities": []}, {"text": "The relevant passages may also be combined on the basis of the same interactive and background information.", "labels": [], "entities": []}, {"text": "We propose to study and develop several kernel methods that can operate in Support Vector Machines for determining the optimal strategies and compare the results with the Maximum Entropy combinations reported in).", "labels": [], "entities": []}, {"text": "The answer is produced by an answer fusion module that uses fusion operators.", "labels": [], "entities": []}, {"text": "Since such operators are template-like, pattern acquisition methods maybe employed for acquiring them.", "labels": [], "entities": [{"text": "pattern acquisition", "start_pos": 40, "end_pos": 59, "type": "TASK", "confidence": 0.7232732176780701}]}, {"text": "The rest of the paper is organized as follows.", "labels": [], "entities": []}, {"text": "The answer fusion strategies are presented in Section 2.", "labels": [], "entities": [{"text": "answer fusion", "start_pos": 4, "end_pos": 17, "type": "TASK", "confidence": 0.8715770840644836}]}, {"text": "Section 3details the methods for bootstrapping Question Answering.", "labels": [], "entities": [{"text": "bootstrapping Question Answering", "start_pos": 33, "end_pos": 65, "type": "TASK", "confidence": 0.8562827905019125}]}, {"text": "Section 4 describes the impact of the user background on the pragmatics of Q/A.", "labels": [], "entities": []}, {"text": "Section 5 presents the problems engendered by processing negations in Question Answering.", "labels": [], "entities": [{"text": "Question Answering", "start_pos": 70, "end_pos": 88, "type": "TASK", "confidence": 0.6873678117990494}]}, {"text": "Section 6 summarizes the conclusions.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": []}