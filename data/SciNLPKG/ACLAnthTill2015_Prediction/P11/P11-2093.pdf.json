{"title": [{"text": "Pointwise Prediction for Robust, Adaptable Japanese Morphological Analysis", "labels": [], "entities": [{"text": "Adaptable Japanese Morphological Analysis", "start_pos": 33, "end_pos": 74, "type": "TASK", "confidence": 0.5379894748330116}]}], "abstractContent": [{"text": "We present a pointwise approach to Japanese morphological analysis (MA) that ignores structure information during learning and tagging.", "labels": [], "entities": [{"text": "Japanese morphological analysis (MA)", "start_pos": 35, "end_pos": 71, "type": "TASK", "confidence": 0.805103729168574}]}, {"text": "Despite the lack of structure, it is able to outperform the current state-of-the-art struc-tured approach for Japanese MA, and achieves accuracy similar to that of structured predic-tors using the same feature set.", "labels": [], "entities": [{"text": "Japanese MA", "start_pos": 110, "end_pos": 121, "type": "TASK", "confidence": 0.4384854584932327}, {"text": "accuracy", "start_pos": 136, "end_pos": 144, "type": "METRIC", "confidence": 0.9982313513755798}]}, {"text": "We also find that the method is both robust to out-of-domain data, and can be easily adapted through the use of a combination of partial annotation and active learning.", "labels": [], "entities": []}], "introductionContent": [{"text": "Japanese morphological analysis (MA) takes an unsegmented string of Japanese text as input, and outputs a string of morphemes annotated with parts of speech (POSs).", "labels": [], "entities": [{"text": "Japanese morphological analysis (MA)", "start_pos": 0, "end_pos": 36, "type": "TASK", "confidence": 0.8365534643332163}]}, {"text": "As MA is the first step in Japanese NLP, its accuracy directly affects the accuracy of NLP systems as a whole.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 45, "end_pos": 53, "type": "METRIC", "confidence": 0.9991263747215271}, {"text": "accuracy", "start_pos": 75, "end_pos": 83, "type": "METRIC", "confidence": 0.9990389347076416}]}, {"text": "In addition, with the proliferation of text in various domains, there is increasing need for methods that are both robust and adaptable to out-of-domain data ().", "labels": [], "entities": []}, {"text": "Previous approaches have used structured predictors such as hidden Markov models (HMMs) or conditional random fields (CRFs), which consider the interactions between neighboring words and parts of speech).", "labels": [], "entities": []}, {"text": "However, while structure does provide valuable information, have shown that gains provided by structured prediction can be largely recovered by using a richer feature set.", "labels": [], "entities": []}, {"text": "This approach has also been called \"pointwise\" prediction, as it makes a single independent decision at each point (.", "labels": [], "entities": [{"text": "pointwise\" prediction", "start_pos": 36, "end_pos": 57, "type": "TASK", "confidence": 0.6842744549115499}]}, {"text": "While focus on the speed benefits of pointwise prediction, we demonstrate that it also allows for more robust and adaptable MA.", "labels": [], "entities": [{"text": "pointwise prediction", "start_pos": 37, "end_pos": 57, "type": "TASK", "confidence": 0.5790443122386932}]}, {"text": "We find experimental evidence that pointwise MA can exceed the accuracy of a state-of-the-art structured approach () on in-domain data, and is significantly more robust to out-of-domain data.", "labels": [], "entities": [{"text": "MA", "start_pos": 45, "end_pos": 47, "type": "TASK", "confidence": 0.5926684737205505}, {"text": "accuracy", "start_pos": 63, "end_pos": 71, "type": "METRIC", "confidence": 0.9994420409202576}]}, {"text": "We also show that pointwise MA can be adapted to new domains with minimal effort through the combination of active learning and partial annotation (, where only informative parts of a particular sentence are annotated.", "labels": [], "entities": [{"text": "MA", "start_pos": 28, "end_pos": 30, "type": "TASK", "confidence": 0.7895457148551941}]}, {"text": "Ina realistic domain adaptation scenario, we find that a combination of pointwise prediction, partial annotation, and active learning allows for easy adaptation.", "labels": [], "entities": []}], "datasetContent": [{"text": "In order to test the effectiveness of pointwise MA, we did an experiment measuring accuracy both on in-domain data, and in a domain-adaptation situation.", "labels": [], "entities": [{"text": "MA", "start_pos": 48, "end_pos": 50, "type": "TASK", "confidence": 0.8155571222305298}, {"text": "accuracy", "start_pos": 83, "end_pos": 91, "type": "METRIC", "confidence": 0.9992757439613342}]}, {"text": "We used the Balanced Corpus of Contemporary Written Japanese (BCCWJ), specifying the whitepaper, news, and books sections as our general domain corpus, and the web text section as our target domain corpus.", "labels": [], "entities": [{"text": "Balanced Corpus of Contemporary Written Japanese (BCCWJ)", "start_pos": 12, "end_pos": 68, "type": "DATASET", "confidence": 0.642522394657135}]}, {"text": "As a representative of joint sequence-based MA described in 2.1, we used MeCab (), an open source implementation of's CRF-based method (we will call this JOINT).", "labels": [], "entities": []}, {"text": "For the pointwise two-step method, we trained logistic regression models with the LIBLINEAR toolkit) using the features described in Section 2.2 (2-LR).", "labels": [], "entities": [{"text": "LIBLINEAR", "start_pos": 82, "end_pos": 91, "type": "METRIC", "confidence": 0.947072446346283}]}, {"text": "In addition, we trained a CRF-based model with the CRFSuite toolkit using the same features and set-up (for both word  segmentation and POS tagging) to examine the contribution of context information (2-CRF).", "labels": [], "entities": [{"text": "word  segmentation", "start_pos": 113, "end_pos": 131, "type": "TASK", "confidence": 0.7258982360363007}, {"text": "POS tagging", "start_pos": 136, "end_pos": 147, "type": "TASK", "confidence": 0.7377127110958099}]}, {"text": "To create the dictionary, we added all of the words in the corpus, but left out a small portion of singletons to prevent overfitting on the training data . As an evaluation measure, we follow and and use Word/POS tag pair Fmeasure, so that both word boundaries and POS tags must be correct fora word to be considered correct.", "labels": [], "entities": [{"text": "Fmeasure", "start_pos": 222, "end_pos": 230, "type": "METRIC", "confidence": 0.6228011846542358}]}], "tableCaptions": [{"text": " Table 4: Word/POS F-measure for each method when  trained and tested on general (GEN) or target (TAR) do- main corpora.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 19, "end_pos": 28, "type": "METRIC", "confidence": 0.5201400518417358}]}]}