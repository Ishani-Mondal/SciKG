{"title": [{"text": "Good Seed Makes a Good Crop: Accelerating Active Learning Using Language Modeling", "labels": [], "entities": []}], "abstractContent": [{"text": "Active Learning (AL) is typically initialized with a small seed of examples selected randomly.", "labels": [], "entities": [{"text": "Active Learning (AL)", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.7094685733318329}]}, {"text": "However, when the distribution of classes in the data is skewed, some classes maybe missed, resulting in a slow learning progress.", "labels": [], "entities": []}, {"text": "Our contribution is twofold: (1) we show that an unsupervised language modeling based technique is effective in selecting rare class examples, and (2) we use this technique for seeding AL and demonstrate that it leads to a higher learning rate.", "labels": [], "entities": [{"text": "seeding AL", "start_pos": 177, "end_pos": 187, "type": "TASK", "confidence": 0.8970506489276886}]}, {"text": "The evaluation is conducted in the context of word sense disam-biguation.", "labels": [], "entities": []}], "introductionContent": [{"text": "Active learning (AL) has become a popular research field due to its potential benefits: it can lead to drastic reductions in the amount of annotation that is necessary for training a highly accurate statistical classifier.", "labels": [], "entities": [{"text": "Active learning (AL)", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.8442186832427978}]}, {"text": "Unlike in a random sampling approach, where unlabeled data is selected for annotation randomly, AL delegates the selection of unlabeled data to the classifier.", "labels": [], "entities": []}, {"text": "Ina typical AL setup, a classifier is trained on a small sample of the data (usually selected randomly), known as the seed examples.", "labels": [], "entities": []}, {"text": "The classifier is subsequently applied to a pool of unlabeled data with the purpose of selecting additional examples that the classifier views as informative.", "labels": [], "entities": []}, {"text": "The selected data is annotated and the cycle is repeated, allowing the learner to quickly refine the decision boundary between the classes.", "labels": [], "entities": []}, {"text": "Unfortunately, AL is susceptible to a shortcoming known as the missed cluster effect) and its special case called the missed class effect ().", "labels": [], "entities": [{"text": "missed cluster effect", "start_pos": 63, "end_pos": 84, "type": "METRIC", "confidence": 0.8211015661557516}]}, {"text": "The missed cluster effect is a consequence of the fact that seed examples influence the direction the learner takes in its exploration of the instance space.", "labels": [], "entities": []}, {"text": "Whenever the seed does not contain the examples of a certain cluster that is representative of a group of examples in the data, the learner may become overconfident about the class membership of this cluster (particularly if it lies far from the decision boundary).", "labels": [], "entities": []}, {"text": "As a result, the learner spends a lot of time exploring one region of the instance space at the expense of missing another.", "labels": [], "entities": []}, {"text": "This problem can become especially severe, when the class distribution in the data is skewed: a randomly selected seed may not adequately represent all the classes or even miss certain classes altogether.", "labels": [], "entities": []}, {"text": "Consider a binary classification task where rare class examples constitute 5% of the data (a frequent scenario in e.g. word sense disambiguation).", "labels": [], "entities": [{"text": "binary classification task", "start_pos": 11, "end_pos": 37, "type": "TASK", "confidence": 0.7471219102541605}, {"text": "word sense disambiguation", "start_pos": 119, "end_pos": 144, "type": "TASK", "confidence": 0.6381568610668182}]}, {"text": "If 10 examples are chosen randomly for seeding AL, the probability that none of the rare class examples will make it to the seed is 60% 1 . Thus, there is a high probability that AL would stall, selecting only the examples of the predominant class over the course of many iterations.", "labels": [], "entities": []}, {"text": "At the same time, if we had away to ensure that examples of the rare class were present in the seed, AL would be able to select the examples of both classes, efficiently clarifying the decision boundary and ultimately producing an accurate classifier.", "labels": [], "entities": []}, {"text": "simulated these scenarios using manually constructed seed sets.", "labels": [], "entities": []}, {"text": "They demonstrated that seeding AL with a data set that is artificially enriched with rare class examples indeed leads to a higher learning rate comparing to randomly sampled and predominant class enriched seeds.", "labels": [], "entities": []}, {"text": "In this paper, we propose a simple automatic approach for selecting the seeds that are rich in the examples of the rare class.", "labels": [], "entities": []}, {"text": "We then demonstrate that this approach to seed selection accelerates AL.", "labels": [], "entities": [{"text": "seed selection", "start_pos": 42, "end_pos": 56, "type": "TASK", "confidence": 0.7475366294384003}, {"text": "AL", "start_pos": 69, "end_pos": 71, "type": "METRIC", "confidence": 0.7223973870277405}]}, {"text": "Finally, we analyze the mechanism of this acceleration.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": []}