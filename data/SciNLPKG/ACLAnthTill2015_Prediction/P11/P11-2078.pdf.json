{"title": [{"text": "On-line Language Model Biasing for Statistical Machine Translation", "labels": [], "entities": [{"text": "On-line Language Model Biasing", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.591937817633152}, {"text": "Statistical Machine Translation", "start_pos": 35, "end_pos": 66, "type": "TASK", "confidence": 0.8455619215965271}]}], "abstractContent": [{"text": "The language model (LM) is a critical component inmost statistical machine translation (SMT) systems, serving to establish a probability distribution over the hypothesis space.", "labels": [], "entities": [{"text": "statistical machine translation (SMT)", "start_pos": 55, "end_pos": 92, "type": "TASK", "confidence": 0.8031914929548899}]}, {"text": "Most SMT systems use a static LM, independent of the source language input.", "labels": [], "entities": [{"text": "SMT", "start_pos": 5, "end_pos": 8, "type": "TASK", "confidence": 0.9910515546798706}]}, {"text": "While previous work has shown that adapting LMs based on the input improves SMT performance , none of the techniques has thus far been shown to be feasible for on-line systems.", "labels": [], "entities": [{"text": "SMT", "start_pos": 76, "end_pos": 79, "type": "TASK", "confidence": 0.9970280528068542}]}, {"text": "In this paper, we develop a novel measure of cross-lingual similarity for biasing the LM based on the test input.", "labels": [], "entities": []}, {"text": "We also illustrate an efficient on-line implementation that supports integration with on-line SMT systems by transferring much of the computational load off-line.", "labels": [], "entities": [{"text": "SMT", "start_pos": 94, "end_pos": 97, "type": "TASK", "confidence": 0.9689261317253113}]}, {"text": "Our approach yields significant reductions in target perplexity compared to the static LM, as well as consistent improvements in SMT performance across language pairs (English-Dari and English-Pashto).", "labels": [], "entities": [{"text": "SMT", "start_pos": 129, "end_pos": 132, "type": "TASK", "confidence": 0.9943432807922363}]}], "introductionContent": [{"text": "While much of the focus in developing a statistical machine translation (SMT) system revolves around the translation model (TM), most systems do not emphasize the role of the language model (LM).", "labels": [], "entities": [{"text": "statistical machine translation (SMT)", "start_pos": 40, "end_pos": 77, "type": "TASK", "confidence": 0.7857979585727056}]}, {"text": "The latter generally follows a n-gram structure and is estimated from a large, monolingual corpus of target sentences.", "labels": [], "entities": []}, {"text": "In most systems, the LM is independent of the test input, i.e. fixed n-gram probabilities determine the likelihood of all translation hypotheses, regardless of the source input.", "labels": [], "entities": []}, {"text": "The views expressed are those of the author and do not reflect the official policy or position of the Department of Defense or the U.S. Government.", "labels": [], "entities": []}, {"text": "Some previous work exists in LM adaptation for SMT.", "labels": [], "entities": [{"text": "LM adaptation", "start_pos": 29, "end_pos": 42, "type": "TASK", "confidence": 0.922758013010025}, {"text": "SMT", "start_pos": 47, "end_pos": 50, "type": "TASK", "confidence": 0.9720730185508728}]}, {"text": "used a cross-lingual information retrieval (CLIR) system to select a subset of target documents \"comparable\" to the source document; bias LMs estimated from these subsets were interpolated with a static background LM.", "labels": [], "entities": [{"text": "cross-lingual information retrieval (CLIR)", "start_pos": 7, "end_pos": 49, "type": "TASK", "confidence": 0.7632492035627365}]}, {"text": "converted initial SMT hypotheses to queries and retrieved similar sentences from a large monolingual collection.", "labels": [], "entities": [{"text": "SMT hypotheses", "start_pos": 18, "end_pos": 32, "type": "TASK", "confidence": 0.9163609445095062}]}, {"text": "The latter were used to build source-specific LMs that were then interpolated with a background model.", "labels": [], "entities": []}, {"text": "A similar approach was proposed by.", "labels": [], "entities": []}, {"text": "While feasible in offline evaluations where the test set is relatively static, the above techniques are computationally expensive and therefore not suitable for low-latency, interactive applications of SMT.", "labels": [], "entities": [{"text": "SMT", "start_pos": 202, "end_pos": 205, "type": "TASK", "confidence": 0.9918681979179382}]}, {"text": "Examples include speechto-speech and web-based interactive translation systems, where test inputs are user-generated and preclude off-line LM adaptation.", "labels": [], "entities": [{"text": "LM adaptation", "start_pos": 139, "end_pos": 152, "type": "TASK", "confidence": 0.868831604719162}]}, {"text": "In this paper, we present a novel technique for weighting a LM corpus at the sentence level based on the source language input.", "labels": [], "entities": []}, {"text": "The weighting scheme relies on a measure of cross-lingual similarity evaluated by projecting sparse vector representations of the target sentences into the space of source sentences using a transformation matrix computed from the bilingual parallel data.", "labels": [], "entities": []}, {"text": "The LM estimated from this weighted corpus boosts the probability of relevant target n-grams, while attenuating unrelated target segments.", "labels": [], "entities": []}, {"text": "Our formulation, based on simple ideas in linear algebra, alleviates run-time complexity by pre-computing the majority of intermediate products off-line.", "labels": [], "entities": []}, {"text": "Distribution Statement \"A\" (Approved for Public Release, Distribution Unlimited)", "labels": [], "entities": [{"text": "Distribution Statement \"A\"", "start_pos": 0, "end_pos": 26, "type": "METRIC", "confidence": 0.569796109199524}, {"text": "Approved", "start_pos": 28, "end_pos": 36, "type": "METRIC", "confidence": 0.984525740146637}]}], "datasetContent": [{"text": "We measure the utility of the proposed LM biasing technique in two ways: (a) given a parallel test corpus, by comparing source-conditional target perplexity with biased LMs to target perplexity with the static LM, and (b) by comparing SMT performance with static and biased LMs.", "labels": [], "entities": [{"text": "LM biasing", "start_pos": 39, "end_pos": 49, "type": "TASK", "confidence": 0.9239720702171326}, {"text": "SMT", "start_pos": 235, "end_pos": 238, "type": "TASK", "confidence": 0.9937468767166138}]}, {"text": "We conduct experiments on two resource-poor language pairs commissioned under the DARPA Transtac speech-to-speech translation initiative, viz.", "labels": [], "entities": [{"text": "DARPA Transtac speech-to-speech translation", "start_pos": 82, "end_pos": 125, "type": "TASK", "confidence": 0.6771328449249268}]}, {"text": "English-Dari (E2D) and English-Pashto (E2P), on test sets with single as well as multiple references.", "labels": [], "entities": []}, {"text": "Having determined that target sentences of a parallel test corpus better fit biased LMs estimated from the corresponding source-weighted training corpus, we proceeded to conduct SMT experiments on both language pairs to demonstrate the utility of biased LMs in improving translation performance.", "labels": [], "entities": [{"text": "SMT", "start_pos": 178, "end_pos": 181, "type": "TASK", "confidence": 0.9918864369392395}]}, {"text": "We used an internally developed phrase-based SMT system, similar to Moses (, as a test-bed for our translation experiments.", "labels": [], "entities": [{"text": "SMT", "start_pos": 45, "end_pos": 48, "type": "TASK", "confidence": 0.8506631851196289}]}, {"text": "We used GIZA++ to induce automatic word alignments from the parallel training corpus.", "labels": [], "entities": [{"text": "word alignments", "start_pos": 35, "end_pos": 50, "type": "TASK", "confidence": 0.7177132964134216}]}, {"text": "Phrase translation rules (up to a maximum source span of 5 words) were extracted from a combination of forward and backward word alignments ().", "labels": [], "entities": [{"text": "Phrase translation", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.8814909160137177}]}, {"text": "The SMT decoder uses a log-linear model that combines numerous features, including but not limited to phrase translation probability, LM probability, and distortion penalty, to estimate the posterior probability of target hypotheses.", "labels": [], "entities": [{"text": "SMT", "start_pos": 4, "end_pos": 7, "type": "TASK", "confidence": 0.9865403771400452}, {"text": "phrase translation", "start_pos": 102, "end_pos": 120, "type": "TASK", "confidence": 0.7117714434862137}, {"text": "LM probability", "start_pos": 134, "end_pos": 148, "type": "METRIC", "confidence": 0.8796228170394897}, {"text": "distortion penalty", "start_pos": 154, "end_pos": 172, "type": "METRIC", "confidence": 0.9779728949069977}]}, {"text": "We used minimum error rate training (MERT) to tune the feature weights for maximum BLEU () on the development set.", "labels": [], "entities": [{"text": "minimum error rate training (MERT)", "start_pos": 8, "end_pos": 42, "type": "METRIC", "confidence": 0.846448472567967}, {"text": "BLEU", "start_pos": 83, "end_pos": 87, "type": "METRIC", "confidence": 0.9990161657333374}]}, {"text": "Finally, we evaluated SMT performance on the test set in terms of BLEU and TER ().", "labels": [], "entities": [{"text": "SMT", "start_pos": 22, "end_pos": 25, "type": "TASK", "confidence": 0.9910654425621033}, {"text": "BLEU", "start_pos": 66, "end_pos": 70, "type": "METRIC", "confidence": 0.99956876039505}, {"text": "TER", "start_pos": 75, "end_pos": 78, "type": "METRIC", "confidence": 0.9985431432723999}]}, {"text": "The baseline SMT system used the static trigram LM with cutoff frequencies optimized for minimum perplexity on the development set.", "labels": [], "entities": [{"text": "SMT", "start_pos": 13, "end_pos": 16, "type": "TASK", "confidence": 0.9904188513755798}]}, {"text": "Biased LMs (with n-gram cutoffs tuned as above) were estimated for all source sentences in the development and test  sets, and were used to decode the corresponding inputs.", "labels": [], "entities": []}, {"text": "summarizes the consistent improvement in BLEU/TER across multiple test sets and language pairs.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 41, "end_pos": 45, "type": "METRIC", "confidence": 0.9972457885742188}, {"text": "TER", "start_pos": 46, "end_pos": 49, "type": "METRIC", "confidence": 0.5232095122337341}]}], "tableCaptions": [{"text": " Table 2: Reduction in perplexity using biased LMs.", "labels": [], "entities": []}, {"text": " Table 3: SMT performance with static and biased LMs.", "labels": [], "entities": [{"text": "SMT", "start_pos": 10, "end_pos": 13, "type": "TASK", "confidence": 0.9937783479690552}]}]}