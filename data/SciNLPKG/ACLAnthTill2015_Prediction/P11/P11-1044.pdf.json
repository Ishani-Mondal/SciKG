{"title": [{"text": "An Algorithm for Unsupervised Transliteration Mining with an Application to Word Alignment", "labels": [], "entities": [{"text": "Unsupervised Transliteration Mining", "start_pos": 17, "end_pos": 52, "type": "TASK", "confidence": 0.6400825579961141}, {"text": "Word Alignment", "start_pos": 76, "end_pos": 90, "type": "TASK", "confidence": 0.6741428673267365}]}], "abstractContent": [{"text": "We propose a language-independent method for the automatic extraction of transliteration pairs from parallel corpora.", "labels": [], "entities": [{"text": "automatic extraction of transliteration pairs from parallel corpora", "start_pos": 49, "end_pos": 116, "type": "TASK", "confidence": 0.8266857117414474}]}, {"text": "In contrast to previous work, our method uses no form of supervision, and does not require linguistically informed preprocessing.", "labels": [], "entities": []}, {"text": "We conduct experiments on data sets from the NEWS 2010 shared task on transliteration mining and achieve an F-measure of up to 92%, out-performing most of the semi-supervised systems that were submitted.", "labels": [], "entities": [{"text": "NEWS 2010 shared task", "start_pos": 45, "end_pos": 66, "type": "DATASET", "confidence": 0.918152928352356}, {"text": "transliteration mining", "start_pos": 70, "end_pos": 92, "type": "TASK", "confidence": 0.745123952627182}, {"text": "F-measure", "start_pos": 108, "end_pos": 117, "type": "METRIC", "confidence": 0.9995328187942505}]}, {"text": "We also apply our method to English/Hindi and English/Arabic parallel corpora and compare the results with manually built gold standards which mark transliterated word pairs.", "labels": [], "entities": []}, {"text": "Finally, we integrate the transliteration module into the GIZA++ word aligner and evaluate it on two word alignment tasks achieving improvements in both precision and recall measured against gold standard word alignments.", "labels": [], "entities": [{"text": "GIZA++ word aligner", "start_pos": 58, "end_pos": 77, "type": "DATASET", "confidence": 0.8496679812669754}, {"text": "precision", "start_pos": 153, "end_pos": 162, "type": "METRIC", "confidence": 0.9991223216056824}, {"text": "recall", "start_pos": 167, "end_pos": 173, "type": "METRIC", "confidence": 0.9969437718391418}]}], "introductionContent": [{"text": "Most previous methods for building transliteration systems were supervised, requiring either handcrafted rules or a clean list of transliteration pairs, both of which are expensive to create.", "labels": [], "entities": []}, {"text": "Such resources are also not applicable to other language pairs.", "labels": [], "entities": []}, {"text": "In this paper, we show that it is possible to extract transliteration pairs from a parallel corpus using an unsupervised method.", "labels": [], "entities": []}, {"text": "We first align a bilingual corpus at the word level using GIZA++ and create a list of word pairs containing a mix of nontransliterations and transliterations.", "labels": [], "entities": []}, {"text": "We train a statistical transliterator on the list of word pairs.", "labels": [], "entities": []}, {"text": "We then filter out a few word pairs (those which have the lowest transliteration probabilities according to the trained transliteration system) which are likely to be non-transliterations.", "labels": [], "entities": []}, {"text": "We retrain the transliterator on the filtered data set.", "labels": [], "entities": []}, {"text": "This process is iterated, filtering out more and more non-transliteration pairs until a nearly clean list of transliteration word pairs is left.", "labels": [], "entities": []}, {"text": "The optimal number of iterations is automatically determined by a novel stopping criterion.", "labels": [], "entities": []}, {"text": "We compare our unsupervised transliteration mining method with the semi-supervised systems presented at the NEWS 2010 shared task on transliteration mining () using four language pairs.", "labels": [], "entities": [{"text": "transliteration mining", "start_pos": 28, "end_pos": 50, "type": "TASK", "confidence": 0.8568671345710754}, {"text": "NEWS 2010 shared task", "start_pos": 108, "end_pos": 129, "type": "TASK", "confidence": 0.7615765035152435}, {"text": "transliteration mining", "start_pos": 133, "end_pos": 155, "type": "TASK", "confidence": 0.6799089014530182}]}, {"text": "We refer to this task as NEWS10.", "labels": [], "entities": [{"text": "NEWS10", "start_pos": 25, "end_pos": 31, "type": "DATASET", "confidence": 0.886395275592804}]}, {"text": "These systems used a manually labelled set of data for initial supervised training, which means that they are semi-supervised systems.", "labels": [], "entities": []}, {"text": "In contrast, our system is fully unsupervised.", "labels": [], "entities": []}, {"text": "We achieve an Fmeasure of up to 92% outperforming most of the semi-supervised systems.", "labels": [], "entities": [{"text": "Fmeasure", "start_pos": 14, "end_pos": 22, "type": "METRIC", "confidence": 0.9975590705871582}]}, {"text": "The NEWS10 data sets are extracted Wikipedia InterLanguage Links (WIL) which consist of parallel phrases, whereas a parallel corpus consists of parallel sentences.", "labels": [], "entities": [{"text": "NEWS10 data sets", "start_pos": 4, "end_pos": 20, "type": "DATASET", "confidence": 0.9758299986521403}]}, {"text": "Transliteration mining on the WIL data sets is easier due to a higher percentage of transliterations than in parallel corpora.", "labels": [], "entities": [{"text": "Transliteration mining", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.9202907979488373}, {"text": "WIL data sets", "start_pos": 30, "end_pos": 43, "type": "DATASET", "confidence": 0.9558855493863424}]}, {"text": "We also do experiments on parallel corpora for two language pairs.", "labels": [], "entities": []}, {"text": "To this end, we created gold standards in which sampled word pairs are annotated as either transliterations or non-transliterations.", "labels": [], "entities": []}, {"text": "These gold standards have been submitted with the paper as supplementary material as they are available to the research community.", "labels": [], "entities": []}, {"text": "430 Finally we integrate a transliteration module into the GIZA++ word aligner and show that it improves word alignment quality.", "labels": [], "entities": [{"text": "GIZA++ word aligner", "start_pos": 59, "end_pos": 78, "type": "DATASET", "confidence": 0.8493946641683578}, {"text": "word alignment", "start_pos": 105, "end_pos": 119, "type": "TASK", "confidence": 0.7699373066425323}]}, {"text": "The transliteration module is trained on the transliteration pairs which our mining method extracts from the parallel corpora.", "labels": [], "entities": []}, {"text": "We evaluate our word alignment system on two language pairs using gold standard word alignments and achieve improvements of 10% and 13.5% in precision and 3.5% and 13.5% in recall.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 16, "end_pos": 30, "type": "TASK", "confidence": 0.7658427357673645}, {"text": "precision", "start_pos": 141, "end_pos": 150, "type": "METRIC", "confidence": 0.9995743632316589}, {"text": "recall", "start_pos": 173, "end_pos": 179, "type": "METRIC", "confidence": 0.9983211159706116}]}, {"text": "The rest of the paper is organized as follows.", "labels": [], "entities": []}, {"text": "In section 2, we describe the filtering model and the transliteration model.", "labels": [], "entities": []}, {"text": "In section 3, we present our iterative transliteration mining algorithm and an algorithm which computes a stopping criterion for the mining algorithm.", "labels": [], "entities": [{"text": "transliteration mining", "start_pos": 39, "end_pos": 61, "type": "TASK", "confidence": 0.717628002166748}]}, {"text": "Section 4 describes the evaluation of our mining method through both gold standard evaluation and through using it to improve word alignment quality.", "labels": [], "entities": [{"text": "word alignment quality", "start_pos": 126, "end_pos": 148, "type": "TASK", "confidence": 0.7890890836715698}]}, {"text": "In section 5, we present previous work and we conclude in section 6.", "labels": [], "entities": []}], "datasetContent": [{"text": "We evaluate our transliteration mining algorithm on three tasks: transliteration mining from Wikipedia InterLanguage Links, transliteration mining from parallel corpora, and word alignment using a word aligner with a transliteration component.", "labels": [], "entities": [{"text": "transliteration mining", "start_pos": 16, "end_pos": 38, "type": "TASK", "confidence": 0.8469250500202179}, {"text": "transliteration mining", "start_pos": 65, "end_pos": 87, "type": "TASK", "confidence": 0.8033390939235687}, {"text": "transliteration mining from parallel corpora", "start_pos": 124, "end_pos": 168, "type": "TASK", "confidence": 0.8575318813323974}, {"text": "word alignment", "start_pos": 174, "end_pos": 188, "type": "TASK", "confidence": 0.7886881232261658}]}, {"text": "On the WIL data sets, we compare our fully unsupervised system with the semi-supervised systems presented at the NEWS10 ().", "labels": [], "entities": [{"text": "WIL data sets", "start_pos": 7, "end_pos": 20, "type": "DATASET", "confidence": 0.9547096093495687}, {"text": "NEWS10", "start_pos": 113, "end_pos": 119, "type": "DATASET", "confidence": 0.9698230624198914}]}, {"text": "In the evaluation on parallel corpora, we compare our mining results with a manually built gold standard in which each word pair is either marked as a transliteration or as a non-transliteration.", "labels": [], "entities": []}, {"text": "In the word alignment experiment, we integrate a transliteration module which is trained on the transliterations pairs extracted by our method into a word aligner and show a significant improvement.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 7, "end_pos": 21, "type": "TASK", "confidence": 0.8410135209560394}]}, {"text": "The following sections describe the experiments in detail.", "labels": [], "entities": []}, {"text": "We: Summary of results on NEWS10 data sets where \"EA\" is English/Arabic, \"ET\" is English/Tamil and \"EH\" is English/Hindi.", "labels": [], "entities": [{"text": "NEWS10 data sets", "start_pos": 26, "end_pos": 42, "type": "DATASET", "confidence": 0.9810333053270975}, {"text": "EA", "start_pos": 50, "end_pos": 52, "type": "METRIC", "confidence": 0.9883962869644165}, {"text": "EH", "start_pos": 100, "end_pos": 102, "type": "METRIC", "confidence": 0.9604372978210449}]}, {"text": "\"Our\" shows the F-measure of our filtered data against the gold standard using the supplied evaluation tool, \"Systems\" is the total number of participants in the subtask, and \"Rank\" is the rank we would have obtained if our system had participated.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 16, "end_pos": 25, "type": "METRIC", "confidence": 0.9972900152206421}, {"text": "Rank", "start_pos": 176, "end_pos": 180, "type": "METRIC", "confidence": 0.9318509697914124}]}, {"text": "contain training data, seed data and reference data.", "labels": [], "entities": []}, {"text": "We make no use of the seed data since our system is fully unsupervised.", "labels": [], "entities": []}, {"text": "We calculate the F-measure of our filtered transliteration pairs against the supplied gold standard using the supplied evaluation tool.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 17, "end_pos": 26, "type": "METRIC", "confidence": 0.9986839890480042}]}, {"text": "For English/Arabic, English/Hindi and English/Tamil, our system is better than most of the semi-supervised systems presented at the NEWS 2010 shared task for transliteration mining.", "labels": [], "entities": [{"text": "NEWS 2010 shared task", "start_pos": 132, "end_pos": 153, "type": "DATASET", "confidence": 0.7863022685050964}, {"text": "transliteration mining", "start_pos": 158, "end_pos": 180, "type": "TASK", "confidence": 0.7159459590911865}]}, {"text": "summarizes the F-scores on these data sets.", "labels": [], "entities": [{"text": "F-scores", "start_pos": 15, "end_pos": 23, "type": "METRIC", "confidence": 0.9926562905311584}]}, {"text": "On the English/Russian data set, our system achieves 76% F-measure which is not good compared with the systems that participated in the shared task.", "labels": [], "entities": [{"text": "English/Russian data set", "start_pos": 7, "end_pos": 31, "type": "DATASET", "confidence": 0.6817897379398346}, {"text": "F-measure", "start_pos": 57, "end_pos": 66, "type": "METRIC", "confidence": 0.999617338180542}]}, {"text": "The English/Russian corpus contains many cognates which -according to the NEWS10 definition -are not transliterations of each other.", "labels": [], "entities": [{"text": "English/Russian corpus", "start_pos": 4, "end_pos": 26, "type": "DATASET", "confidence": 0.6203149408102036}, {"text": "NEWS10 definition", "start_pos": 74, "end_pos": 91, "type": "DATASET", "confidence": 0.9459404349327087}]}, {"text": "Our system learns the cognates in the training data and extracts them as transliterations (see).", "labels": [], "entities": []}, {"text": "The two best teams on the English/Russian task presented various extraction methods.", "labels": [], "entities": []}, {"text": "Their systems behave differently on English/Russian than on other language pairs.", "labels": [], "entities": []}, {"text": "Their best systems for English/Russian are only trained on the seed data and the use of unlabelled data does not help the performance.", "labels": [], "entities": []}, {"text": "Since our system is fully unsupervised, and the unlabelled data is not useful, we perform badly.", "labels": [], "entities": []}, {"text": "The Wikipedia InterLanguage Links shared task data contains a much larger proportion of transliterations than a parallel corpus.", "labels": [], "entities": [{"text": "Wikipedia InterLanguage Links shared task data", "start_pos": 4, "end_pos": 50, "type": "DATASET", "confidence": 0.7952891091505686}]}, {"text": "In order to examine how well our method performs on parallel corpora, we apply it to parallel corpora of English/Hindi and English/Arabic, and compare the transliteration mining results with a gold standard.", "labels": [], "entities": []}, {"text": "We use the English/Hindi corpus from the shared task on word alignment, organized as part of the ACL 2005 Workshop on Building and Using Parallel Texts (WA05) ().", "labels": [], "entities": [{"text": "word alignment", "start_pos": 56, "end_pos": 70, "type": "TASK", "confidence": 0.7439461648464203}, {"text": "ACL 2005 Workshop on Building and Using Parallel Texts (WA05)", "start_pos": 97, "end_pos": 158, "type": "TASK", "confidence": 0.5721643244226774}]}, {"text": "For English/Arabic, we use a freely available parallel corpus from the United Nations (UN).", "labels": [], "entities": []}, {"text": "We randomly take 200,000 parallel sentences from the UN corpus of the year 2000.", "labels": [], "entities": [{"text": "UN corpus of the year 2000", "start_pos": 53, "end_pos": 79, "type": "DATASET", "confidence": 0.9280484120051066}]}, {"text": "We create gold standards for both language pairs by randomly selecting a few thousand word pairs from the lists of word pairs extracted from the two corpora.", "labels": [], "entities": []}, {"text": "We manually tag them as either transliterations or non-transliterations.", "labels": [], "entities": []}, {"text": "The English/Hindi gold standard contains 180 transliteration pairs and 2084 non-transliteration pairs and the English/Arabic gold standard contains 288 transliteration pairs and 6639 non-transliteration pairs.", "labels": [], "entities": [{"text": "English/Hindi gold standard", "start_pos": 4, "end_pos": 31, "type": "DATASET", "confidence": 0.7426231741905213}, {"text": "English/Arabic gold standard", "start_pos": 110, "end_pos": 138, "type": "DATASET", "confidence": 0.7321908831596374}]}, {"text": "We have submitted these gold standards with the paper.", "labels": [], "entities": []}, {"text": "They are available to the research community.", "labels": [], "entities": []}, {"text": "In the following sections, we describe the median9 heuristic and the splitting method of Algorithm 2.", "labels": [], "entities": []}, {"text": "The splitting method is used to avoid early peaks in the held-out statistics, and the median9 heuristic smooths the held-out statistics in order to obtain a single peak.", "labels": [], "entities": []}, {"text": "The English/Hindi corpus available from WA05 consists of training, development and test data.", "labels": [], "entities": [{"text": "English/Hindi corpus available from WA05", "start_pos": 4, "end_pos": 44, "type": "DATASET", "confidence": 0.6980009547301701}]}, {"text": "As development and test data for English/Arabic, we use manually created gold standard word alignments for 155 sentences extracted from the Hansards corpus released by LDC.", "labels": [], "entities": [{"text": "Hansards corpus released by LDC", "start_pos": 140, "end_pos": 171, "type": "DATASET", "confidence": 0.9516257762908935}]}, {"text": "We use 50 sentences for development and 105 sentences for test.", "labels": [], "entities": []}, {"text": "Baseline: We align the data sets using GIZA++ and refine the alignments using the grow-diag-final-and heuristic (.", "labels": [], "entities": []}, {"text": "We obtain the baseline F-measure by comparing the alignments of the test corpus with the gold standard alignments.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 23, "end_pos": 32, "type": "METRIC", "confidence": 0.9616448879241943}]}, {"text": "Experiments We use GIZA++ with 5 iterations of Model1, 4 iterations of HMM and 4 iterations of Model4.", "labels": [], "entities": [{"text": "Model1", "start_pos": 47, "end_pos": 53, "type": "DATASET", "confidence": 0.9186789393424988}]}, {"text": "We interpolate translation and transliteration probabilities at different iterations (and different combinations of iterations) of the three models and always observe an improvement in alignment quality.", "labels": [], "entities": []}, {"text": "For the final experiments, we interpolate at every iteration of the IBM models and the HMM model except the last iteration of every model where we could not interpolate for technical reasons.", "labels": [], "entities": [{"text": "IBM models", "start_pos": 68, "end_pos": 78, "type": "DATASET", "confidence": 0.9569962322711945}, {"text": "HMM model", "start_pos": 87, "end_pos": 96, "type": "DATASET", "confidence": 0.9105225503444672}]}, {"text": "5 Algo- We had problems in resuming MGIZA++ training when training was supposed to continue from a different model, such as if we stopped after the 5th iteration of Model1 and then tried to resume MGIZA++ from the first iteration of the HMM model.", "labels": [], "entities": []}, {"text": "In this case, we ran the 5th iteration of Model1, then the first iteration of the HMM and only then stopped for interpolarithm 4 shows the interpolation of the transliteration probabilities with IBM Model4.", "labels": [], "entities": [{"text": "Model1", "start_pos": 42, "end_pos": 48, "type": "DATASET", "confidence": 0.9589852094650269}, {"text": "IBM Model4", "start_pos": 195, "end_pos": 205, "type": "DATASET", "confidence": 0.9442950487136841}]}, {"text": "We used the same procedure with IBM Model1 and the HMM model.", "labels": [], "entities": [{"text": "IBM Model1", "start_pos": 32, "end_pos": 42, "type": "DATASET", "confidence": 0.8990333676338196}]}, {"text": "The parameter \u03bb is optimized on development data for every language pair.", "labels": [], "entities": []}, {"text": "The word alignment system is not very sensitive to \u03bb.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 4, "end_pos": 18, "type": "TASK", "confidence": 0.731879249215126}]}, {"text": "Any \u03bb in the range between 50 and 100 works fine for all language pairs.", "labels": [], "entities": []}, {"text": "The optimization helps to maximize the improvement in word alignment quality.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 54, "end_pos": 68, "type": "TASK", "confidence": 0.7965087890625}]}, {"text": "For our experiments, we use \u03bb = 80.", "labels": [], "entities": []}, {"text": "On test data, we achieve an improvement of approximately 10% and 13.5% in precision and 3.5% and 13.5% in recall on English/Hindi and English/Arabic word alignment, respectively.", "labels": [], "entities": [{"text": "precision", "start_pos": 74, "end_pos": 83, "type": "METRIC", "confidence": 0.9996167421340942}, {"text": "recall", "start_pos": 106, "end_pos": 112, "type": "METRIC", "confidence": 0.999460756778717}, {"text": "English/Arabic word alignment", "start_pos": 134, "end_pos": 163, "type": "TASK", "confidence": 0.5612237215042114}]}, {"text": "shows the scores of the baseline and our word alignment model.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 41, "end_pos": 55, "type": "TASK", "confidence": 0.7133641242980957}]}, {"text": "We compared our word alignment results with the systems presented at WA05.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 16, "end_pos": 30, "type": "TASK", "confidence": 0.7395726442337036}, {"text": "WA05", "start_pos": 69, "end_pos": 73, "type": "DATASET", "confidence": 0.933739185333252}]}, {"text": "Three systems, one limited and two un-limited, participated in the English/Hindi task.", "labels": [], "entities": []}, {"text": "We outperform the limited system and one un-limited system.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Summary of results on NEWS10 data sets where  \"EA\" is English/Arabic, \"ET\" is English/Tamil and \"EH\"  is English/Hindi. \"Our\" shows the F-measure of our fil- tered data against the gold standard using the supplied  evaluation tool, \"Systems\" is the total number of partic- ipants in the subtask, and \"Rank\" is the rank we would  have obtained if our system had participated.", "labels": [], "entities": [{"text": "NEWS10 data sets", "start_pos": 32, "end_pos": 48, "type": "DATASET", "confidence": 0.9784021178881327}, {"text": "EA", "start_pos": 57, "end_pos": 59, "type": "METRIC", "confidence": 0.9623289704322815}, {"text": "EH", "start_pos": 107, "end_pos": 109, "type": "METRIC", "confidence": 0.9672601222991943}, {"text": "F-measure", "start_pos": 146, "end_pos": 155, "type": "METRIC", "confidence": 0.9963114857673645}, {"text": "Rank", "start_pos": 311, "end_pos": 315, "type": "METRIC", "confidence": 0.9412333965301514}]}, {"text": " Table 3: Transliteration mining results using the parallel  corpus of English/Hindi (EH) and English/Arabic (EA)  against the gold standard", "labels": [], "entities": [{"text": "Transliteration mining", "start_pos": 10, "end_pos": 32, "type": "TASK", "confidence": 0.9672047793865204}]}, {"text": " Table 4: Word alignment results on the test data of En- glish/Hindi (EH) and English/Arabic (EA) where P b is  the precision of baseline GIZA++ and P ti is the precision  of our word alignment system", "labels": [], "entities": [{"text": "Word alignment", "start_pos": 10, "end_pos": 24, "type": "TASK", "confidence": 0.7733615338802338}, {"text": "precision", "start_pos": 116, "end_pos": 125, "type": "METRIC", "confidence": 0.9970787763595581}, {"text": "precision", "start_pos": 161, "end_pos": 170, "type": "METRIC", "confidence": 0.9984431862831116}]}]}