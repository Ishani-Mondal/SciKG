{"title": [], "abstractContent": [{"text": "In this paper we propose anew method for evaluating systems that extract temporal information from text.", "labels": [], "entities": []}, {"text": "It uses temporal closure 1 to reward relations that are equivalent but distinct.", "labels": [], "entities": []}, {"text": "Our metric measures the overall performance of systems with a single score, making comparison between different systems straightforward.", "labels": [], "entities": []}, {"text": "Our approach is easy to implement, intuitive, accurate, scalable and computationally inexpensive.", "labels": [], "entities": []}], "introductionContent": [{"text": "The recent emergence of language processing applications like question answering, information extraction, and document summarization has motivated the need for temporally-aware systems.", "labels": [], "entities": [{"text": "question answering", "start_pos": 62, "end_pos": 80, "type": "TASK", "confidence": 0.8832738995552063}, {"text": "information extraction", "start_pos": 82, "end_pos": 104, "type": "TASK", "confidence": 0.8475565612316132}, {"text": "document summarization", "start_pos": 110, "end_pos": 132, "type": "TASK", "confidence": 0.6723159104585648}]}, {"text": "This, along with the availability of the temporal annotation scheme TimeML ( , a temporally annotated corpus, TimeBank ( ) and the temporal evaluation challenges and, has led to an explosion of research on temporal information processing (TIP).", "labels": [], "entities": [{"text": "TimeML", "start_pos": 68, "end_pos": 74, "type": "DATASET", "confidence": 0.9282914996147156}, {"text": "temporal information processing (TIP)", "start_pos": 206, "end_pos": 243, "type": "TASK", "confidence": 0.7997429470221201}]}, {"text": "Prior evaluation methods (TempEval-1, 2) for different TIP subtasks have borrowed precision and recall measures from the information retrieval community.", "labels": [], "entities": [{"text": "precision", "start_pos": 82, "end_pos": 91, "type": "METRIC", "confidence": 0.998835027217865}, {"text": "recall", "start_pos": 96, "end_pos": 102, "type": "METRIC", "confidence": 0.9979088306427002}]}, {"text": "This has two problems: First, systems express temporal relations in different, yet equivalent, ways.", "labels": [], "entities": []}, {"text": "Consider a scenario where the Temporal closure is a reasoning mechanism that derives new implied temporal relations, i.e. makes implicit temporal relations explicit.", "labels": [], "entities": [{"text": "Temporal closure", "start_pos": 30, "end_pos": 46, "type": "TASK", "confidence": 0.831447958946228}]}, {"text": "For example, if we know A before B, B before C, then using temporal closure we can derive A before C. demonstrates the closure table for 13 Allen interval relations.", "labels": [], "entities": []}, {"text": "reference annotation contains e 1 <e 2 and e 2 <e 3 and the system identifies the relation e 1 <e . The traditional evaluation metric will fail to identify e 1 <e 3 as a correct relation, which is a logical consequence of the reference annotation.", "labels": [], "entities": []}, {"text": "Second, traditional evaluations tell us how well a system performs in a particular task, but not the overall performance.", "labels": [], "entities": []}, {"text": "For example, in TempEval-2 there were 6 subtasks (event extraction, temporal expression extraction and 4 subtasks on identifying temporal relations).", "labels": [], "entities": [{"text": "event extraction", "start_pos": 50, "end_pos": 66, "type": "TASK", "confidence": 0.6871077865362167}, {"text": "temporal expression extraction", "start_pos": 68, "end_pos": 98, "type": "TASK", "confidence": 0.576788862546285}]}, {"text": "Thus, different systems perform best is different subtasks, but we can't compare overall performance of systems.", "labels": [], "entities": []}, {"text": "We use temporal closure to identify equivalent temporal relations and produce a single score that measures the temporal awareness of each system.", "labels": [], "entities": []}, {"text": "We use Timegraph) for computing temporal closure, which makes our system scalable and computationally inexpensive.", "labels": [], "entities": [{"text": "temporal closure", "start_pos": 32, "end_pos": 48, "type": "TASK", "confidence": 0.6817308962345123}]}], "datasetContent": [{"text": "We also use temporal closure to reward equivalent but distinct relations.", "labels": [], "entities": []}, {"text": "However, we do not compare against the temporal closure of reference annotation and system output, like Setzer et al., but 2 For relation R A, B between A and B, derivations are R A, C , R B, C , R A, D , R B, D . If the intersection of all these derived relations equals R A, B , it means that R A, B is not a core relation, since it can be obtained by composing some other relations.", "labels": [], "entities": []}, {"text": "Otherwise, the relation is a core, since removing it tends to loss of information.", "labels": [], "entities": []}, {"text": "we use the temporal closure to verify if a temporal relation can be derived or not.", "labels": [], "entities": []}, {"text": "Our precision and recall is defined as: Precision = (# of system temporal relations that can be verified from reference annotation temporal closure graph / # of temporal relations in system output) Recall = (# of reference annotation temporal relations that can be verified from system output's temporal closure graph / # of temporal relations in reference annotation) The harmonic mean of precision and recall, i.e. fscore, will give an evaluation of the temporal awareness of the system.", "labels": [], "entities": [{"text": "precision", "start_pos": 4, "end_pos": 13, "type": "METRIC", "confidence": 0.9989314675331116}, {"text": "recall", "start_pos": 18, "end_pos": 24, "type": "METRIC", "confidence": 0.9947195053100586}, {"text": "Precision", "start_pos": 40, "end_pos": 49, "type": "METRIC", "confidence": 0.9984859824180603}, {"text": "Recall", "start_pos": 198, "end_pos": 204, "type": "METRIC", "confidence": 0.9955477714538574}, {"text": "precision", "start_pos": 390, "end_pos": 399, "type": "METRIC", "confidence": 0.9984838366508484}, {"text": "recall", "start_pos": 404, "end_pos": 410, "type": "METRIC", "confidence": 0.9771332740783691}]}, {"text": "As an example, consider again the examples in, with K as reference annotation.", "labels": [], "entities": []}, {"text": "S 1 and S 3 clearly have 100% precision, and S 2 also gets 100% precision, since the B<D edge can be verified through the temporal closure graph of K.", "labels": [], "entities": [{"text": "precision", "start_pos": 30, "end_pos": 39, "type": "METRIC", "confidence": 0.9989321827888489}, {"text": "precision", "start_pos": 64, "end_pos": 73, "type": "METRIC", "confidence": 0.9990211725234985}]}, {"text": "Note, our recall measure doesn't reward the B<D edge of S 2 , but it is counted for precision.", "labels": [], "entities": [{"text": "recall", "start_pos": 10, "end_pos": 16, "type": "METRIC", "confidence": 0.9988216757774353}, {"text": "B<D edge", "start_pos": 44, "end_pos": 52, "type": "METRIC", "confidence": 0.8755431324243546}, {"text": "precision", "start_pos": 84, "end_pos": 93, "type": "METRIC", "confidence": 0.9990289211273193}]}, {"text": "S 1 and S 3 both get a recall of 2/3, since 2 edges can be verified in the reference temporal closure graph.", "labels": [], "entities": [{"text": "recall", "start_pos": 23, "end_pos": 29, "type": "METRIC", "confidence": 0.9992154836654663}]}, {"text": "This scheme is similar to the MUC-6 scoring for coreference (.", "labels": [], "entities": [{"text": "MUC-6 scoring", "start_pos": 30, "end_pos": 43, "type": "DATASET", "confidence": 0.684331089258194}, {"text": "coreference", "start_pos": 48, "end_pos": 59, "type": "TASK", "confidence": 0.9218822121620178}]}, {"text": "Their scoring estimated the minimal number of missing links necessary to complete co-reference chain in order to make it match the human annotation.", "labels": [], "entities": []}, {"text": "Here in both S 1 and S 3 , we are missing one edge to match with the reference annotation; hence 2/3 is the appropriate score.", "labels": [], "entities": []}, {"text": "Precision, recall and fscore for all these system output are shown in: Precision, recall and fscore for systems in according to our evaluation metric  Our proposed evaluation metric has some very good properties, which makes it very suitable as a standard metric.", "labels": [], "entities": [{"text": "Precision", "start_pos": 0, "end_pos": 9, "type": "METRIC", "confidence": 0.9894422292709351}, {"text": "recall", "start_pos": 11, "end_pos": 17, "type": "METRIC", "confidence": 0.997348427772522}, {"text": "fscore", "start_pos": 22, "end_pos": 28, "type": "METRIC", "confidence": 0.9922458529472351}, {"text": "Precision", "start_pos": 71, "end_pos": 80, "type": "METRIC", "confidence": 0.9473505020141602}, {"text": "recall", "start_pos": 82, "end_pos": 88, "type": "METRIC", "confidence": 0.9979871511459351}, {"text": "fscore", "start_pos": 93, "end_pos": 99, "type": "METRIC", "confidence": 0.9937644004821777}]}, {"text": "This section presents a few empirical tests to show the usefulness of our metric.", "labels": [], "entities": []}, {"text": "Our precision and recall goes with the same spirit with traditional precision and recall, as a result, performance decreases with the decrease of information.", "labels": [], "entities": [{"text": "precision", "start_pos": 4, "end_pos": 13, "type": "METRIC", "confidence": 0.9991734623908997}, {"text": "recall", "start_pos": 18, "end_pos": 24, "type": "METRIC", "confidence": 0.996863842010498}, {"text": "precision", "start_pos": 68, "end_pos": 77, "type": "METRIC", "confidence": 0.997797966003418}, {"text": "recall", "start_pos": 82, "end_pos": 88, "type": "METRIC", "confidence": 0.9928067922592163}]}, {"text": "Specifically, i. if we remove relations from the reference annotation and then compare that against the full reference annotation, then recall decreases linearly.", "labels": [], "entities": [{"text": "recall", "start_pos": 136, "end_pos": 142, "type": "METRIC", "confidence": 0.9991112351417542}]}, {"text": "Shown in. ii. if we introduce noise by adding new relations, then precision decreases linearly). iii.", "labels": [], "entities": [{"text": "precision", "start_pos": 66, "end_pos": 75, "type": "METRIC", "confidence": 0.9994889497756958}]}, {"text": "if we introduce noise by changing existing relations then fscore decreases linearly). iv. if we remove temporal entities (such as events or temporal expressions), performance decreases more for entities that are temporally related to more entities.", "labels": [], "entities": [{"text": "fscore", "start_pos": 58, "end_pos": 64, "type": "METRIC", "confidence": 0.965416669845581}]}, {"text": "This means, if the system fails to extract important temporal entities then the performance will decrease more ().", "labels": [], "entities": []}, {"text": "Temporal entities related with a maximum number of entities are removed first.", "labels": [], "entities": []}, {"text": "It is evident from the graph that performance decreased more for removing important entities (first few entities).", "labels": [], "entities": []}, {"text": "These properties explain that our final fscore captures how well a system extracts events, temporal expressions and temporal relations.", "labels": [], "entities": []}, {"text": "Therefore this single score captures all the scores of six subtasks in TempEval-2, making it very convenient and straightforward to compare different systems.", "labels": [], "entities": []}, {"text": "Our implementation using Timegraph is also scalable.", "labels": [], "entities": [{"text": "Timegraph", "start_pos": 25, "end_pos": 34, "type": "DATASET", "confidence": 0.9120888710021973}]}, {"text": "We ran our Timegraph construction algorithm on the complete TimeBank corpus and found that Timegraph construction time increases linearly with the increase of number of nodes and edges (= # of cross-chain links and # of chains) ().", "labels": [], "entities": [{"text": "Timegraph construction", "start_pos": 11, "end_pos": 33, "type": "TASK", "confidence": 0.7500281631946564}, {"text": "TimeBank corpus", "start_pos": 60, "end_pos": 75, "type": "DATASET", "confidence": 0.9725393950939178}]}, {"text": "The largest document, with 235 temporal relations (around 900 nodes+edges in Timegraph) only takes 0.22 seconds in a laptop computer with 4GB RAM and 2.26 GHz Core 2 Duo processor.", "labels": [], "entities": []}, {"text": "We also confirmed that the number of nodes + edges in Timegraph also increases linearly with number of temporal relations in TimeBank documents.", "labels": [], "entities": [{"text": "Timegraph", "start_pos": 54, "end_pos": 63, "type": "DATASET", "confidence": 0.9475204348564148}, {"text": "TimeBank documents", "start_pos": 125, "end_pos": 143, "type": "DATASET", "confidence": 0.9356525242328644}]}, {"text": ", i.e. our Timegraph construction time correlates with the # of relations in TimeBank documents).", "labels": [], "entities": [{"text": "TimeBank documents", "start_pos": 77, "end_pos": 95, "type": "DATASET", "confidence": 0.9662587642669678}]}, {"text": "Searching in Timegraph, which we need for temporal evaluation, also depends on number of nodes and edges, hence number of TimeBank relations.", "labels": [], "entities": []}, {"text": "We ran a temporal evaluation on TimeBank corpus using the same document as system output.", "labels": [], "entities": [{"text": "TimeBank corpus", "start_pos": 32, "end_pos": 47, "type": "DATASET", "confidence": 0.9745117425918579}]}, {"text": "The operation included creating two Timegraphs and searching in the Timegraph.", "labels": [], "entities": [{"text": "Timegraph", "start_pos": 68, "end_pos": 77, "type": "DATASET", "confidence": 0.9751386642456055}]}, {"text": "As expected, the searching time also increases linearly against the number of relations and is computationally inexpensive).", "labels": [], "entities": []}, {"text": "for all documents of TimeBank corpus.", "labels": [], "entities": [{"text": "TimeBank corpus", "start_pos": 21, "end_pos": 36, "type": "DATASET", "confidence": 0.9815360307693481}]}], "tableCaptions": [{"text": " Table 1: Precision, recall and fscore for systems in", "labels": [], "entities": [{"text": "Precision", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9952095150947571}, {"text": "recall", "start_pos": 21, "end_pos": 27, "type": "METRIC", "confidence": 0.9989546537399292}, {"text": "fscore", "start_pos": 32, "end_pos": 38, "type": "METRIC", "confidence": 0.9850695729255676}]}]}