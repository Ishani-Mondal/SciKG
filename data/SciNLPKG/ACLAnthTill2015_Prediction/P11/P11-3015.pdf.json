{"title": [{"text": "Sentiment Analysis of Citations using Sentence Structure-Based Features", "labels": [], "entities": [{"text": "Sentiment Analysis of Citations", "start_pos": 0, "end_pos": 31, "type": "TASK", "confidence": 0.9324436485767365}]}], "abstractContent": [{"text": "Sentiment analysis of citations in scientific papers and articles is anew and interesting problem due to the many linguistic differences between scientific texts and other genres.", "labels": [], "entities": [{"text": "Sentiment analysis of citations in scientific papers and articles", "start_pos": 0, "end_pos": 65, "type": "TASK", "confidence": 0.9330056375927396}]}, {"text": "In this paper, we focus on the problem of automatic identification of positive and negative sentiment polarity in citations to scientific papers.", "labels": [], "entities": [{"text": "automatic identification of positive and negative sentiment polarity in citations to scientific papers", "start_pos": 42, "end_pos": 144, "type": "TASK", "confidence": 0.7511428411190326}]}, {"text": "Using a newly constructed annotated citation sentiment corpus, we explore the effectiveness of existing and novel features, including n-grams, specialised science-specific lexical features, dependency relations, sentence splitting and negation features.", "labels": [], "entities": [{"text": "sentence splitting", "start_pos": 212, "end_pos": 230, "type": "TASK", "confidence": 0.7463187873363495}]}, {"text": "Our results show that 3-grams and dependencies perform best in this task; they outperform the sentence splitting, science lexicon and negation based features.", "labels": [], "entities": [{"text": "sentence splitting", "start_pos": 94, "end_pos": 112, "type": "TASK", "confidence": 0.7228540629148483}]}], "introductionContent": [{"text": "Sentiment analysis is the task of identifying positive and negative opinions, sentiments, emotions and attitudes expressed in text.", "labels": [], "entities": [{"text": "Sentiment analysis", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.9501400291919708}, {"text": "identifying positive and negative opinions, sentiments, emotions and attitudes expressed in text", "start_pos": 34, "end_pos": 130, "type": "TASK", "confidence": 0.540367528796196}]}, {"text": "Although there has been in the past few years a growing interest in this field for different text genres such as newspaper text, reviews and narrative text, relatively less emphasis has been placed on extraction of opinions from scientific literature, more specifically, citations.", "labels": [], "entities": [{"text": "extraction of opinions from scientific literature", "start_pos": 201, "end_pos": 250, "type": "TASK", "confidence": 0.8067618012428284}]}, {"text": "Analysis of citation sentiment would open up many exciting new applications in bibliographic search and in bibliometrics, i.e., the automatic evaluation the influence and impact of individuals and journals via citations.", "labels": [], "entities": [{"text": "Analysis of citation sentiment", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.7861416786909103}]}, {"text": "Existing bibliometric measures like H-Index () and adapted graph ranking algorithms like PageRank () treat all citations as equal.", "labels": [], "entities": []}, {"text": "However, argued that if a cited work is criticised, it should consequently carry lower or even negative weight for bibliometric measures.", "labels": [], "entities": []}, {"text": "Automatic citation sentiment detection is a prerequisite for such a treatment.", "labels": [], "entities": [{"text": "citation sentiment detection", "start_pos": 10, "end_pos": 38, "type": "TASK", "confidence": 0.9380243817965189}]}, {"text": "Moreover, citation sentiment detection can also help researchers during search, by detecting problems with a particular approach.", "labels": [], "entities": [{"text": "citation sentiment detection", "start_pos": 10, "end_pos": 38, "type": "TASK", "confidence": 0.9570462703704834}]}, {"text": "It can be used as a first step to scientific summarisation, enable users to recognise unaddressed issues and possible gaps in the current research, and thus help them set their research directions.", "labels": [], "entities": [{"text": "scientific summarisation", "start_pos": 34, "end_pos": 58, "type": "TASK", "confidence": 0.5829349756240845}]}, {"text": "For other genres a rich literature on sentiment detection exists and researchers have used a number of features such as n-grams, presence of adjectives, adverbs and other parts-of-speech (POS), negation, grammatical and dependency relations as well as specialised lexicons in order to detect sentiments from phrases, words, sentences and documents.", "labels": [], "entities": [{"text": "sentiment detection", "start_pos": 38, "end_pos": 57, "type": "TASK", "confidence": 0.9127214252948761}]}, {"text": "State-of-the-art systems report around 85-90% accuracy for different genres of text ().", "labels": [], "entities": [{"text": "accuracy", "start_pos": 46, "end_pos": 54, "type": "METRIC", "confidence": 0.999245285987854}]}, {"text": "Given such good results, one might think that a sentence-based sentiment detection system trained on a different genre could be used equally well to classify citations.", "labels": [], "entities": [{"text": "sentence-based sentiment detection", "start_pos": 48, "end_pos": 82, "type": "TASK", "confidence": 0.6610005299250284}, {"text": "classify citations", "start_pos": 149, "end_pos": 167, "type": "TASK", "confidence": 0.8406239151954651}]}, {"text": "We argue that this might not be the case; our citation sentiment recogniser uses specialised training data and tests the performance of specialised features against current state-of-the-art features.", "labels": [], "entities": [{"text": "citation sentiment recogniser", "start_pos": 46, "end_pos": 75, "type": "TASK", "confidence": 0.695165197054545}]}, {"text": "The reasons for this are based on the following observations: \u2022 Sentiment in citations is often hidden.", "labels": [], "entities": [{"text": "Sentiment in citations", "start_pos": 64, "end_pos": 86, "type": "TASK", "confidence": 0.8757083614667257}]}, {"text": "This might be because of the general strategy to avoid overt criticism due to the sociological aspect of citing (.", "labels": [], "entities": []}, {"text": "states that many works are cited out of \"politeness, policy or piety\".", "labels": [], "entities": []}, {"text": "Negative sentiment, while still present and detectable for humans, is expressed in subtle ways and might be hedged, especially when it cannot be quantitatively justified.", "labels": [], "entities": [{"text": "Negative sentiment", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.9148127138614655}]}, {"text": "While SCL has been successfully applied to POS tagging and Sentiment Analysis (), its effectiveness for parsing was rather unexplored.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 43, "end_pos": 54, "type": "TASK", "confidence": 0.7835793793201447}, {"text": "Sentiment Analysis", "start_pos": 59, "end_pos": 77, "type": "TASK", "confidence": 0.7768522202968597}, {"text": "parsing", "start_pos": 104, "end_pos": 111, "type": "TASK", "confidence": 0.9796579480171204}]}, {"text": "\u2022 Citation sentences are often neutral with respect to sentiment, either because they describe an algorithm, approach or methodology objectively, or because they are used to support a factor statement.", "labels": [], "entities": []}, {"text": "There are five different IBM translation models).", "labels": [], "entities": [{"text": "IBM translation", "start_pos": 25, "end_pos": 40, "type": "TASK", "confidence": 0.5632397830486298}]}, {"text": "This gives rise to afar higher proportion of objective sentences than in other genres.", "labels": [], "entities": []}, {"text": "\u2022 Negative polarity is often expressed in contrastive terms, e.g. in evaluation sections.", "labels": [], "entities": []}, {"text": "Although the sentiment is indirect in these cases, its negativity is implied by the fact that the authors' own work is clearly evaluated positively in comparison.", "labels": [], "entities": []}, {"text": "This method was shown to outperform the class based model proposed in) . .", "labels": [], "entities": []}, {"text": "\u2022 There is also much variation between scientific texts and other genres concerning the lexical items chosen to convey sentiment.", "labels": [], "entities": []}, {"text": "Sentiment carrying science-specific terms exist and are relatively frequent, which motivates the use of a sentiment lexicon specialised to science.", "labels": [], "entities": [{"text": "Sentiment carrying science-specific", "start_pos": 0, "end_pos": 35, "type": "TASK", "confidence": 0.862214982509613}]}, {"text": "Similarity-based smoothing (Dagan, Lee, and Pereira 1999) provides an intuitively appealing approach to language modeling.", "labels": [], "entities": [{"text": "language modeling", "start_pos": 104, "end_pos": 121, "type": "TASK", "confidence": 0.7343120574951172}]}, {"text": "\u2022 Technical terms play a large role overall in scientific text.", "labels": [], "entities": []}, {"text": "Some of these carry sentiment as well.", "labels": [], "entities": []}, {"text": "Current state of the art machine translation systems use phrasal (n-gram) features . .", "labels": [], "entities": [{"text": "machine translation", "start_pos": 25, "end_pos": 44, "type": "TASK", "confidence": 0.7308474183082581}]}, {"text": "For this reason, using higher order n-grams might prove to be useful in sentiment detection.", "labels": [], "entities": [{"text": "sentiment detection", "start_pos": 72, "end_pos": 91, "type": "TASK", "confidence": 0.9768357574939728}]}, {"text": "\u2022 The scope of influence of citations varies widely from a single clause (as in the example below) to several paragraphs: As reported in, small increases in METEOR (), BLEU () and NIST scores) suggest that . .", "labels": [], "entities": [{"text": "METEOR", "start_pos": 157, "end_pos": 163, "type": "METRIC", "confidence": 0.9957972764968872}, {"text": "BLEU", "start_pos": 168, "end_pos": 172, "type": "METRIC", "confidence": 0.9938342571258545}, {"text": "NIST scores", "start_pos": 180, "end_pos": 191, "type": "METRIC", "confidence": 0.591208815574646}]}, {"text": "This affects lexical features directly since there could be \"sentiment overlap\" associated with neighbouring citations.", "labels": [], "entities": []}, {"text": "showed that assuming larger citation scopes has a positive effect in retrieval.", "labels": [], "entities": []}, {"text": "We will test the opposite direction here, i.e., we assume short scopes and use a parser to split sentences, so that the features associated with the clauses not directly connected to the citation are disregarded.", "labels": [], "entities": []}, {"text": "We created anew sentiment-annotated corpus of scientific text in the form of a sentence-based collection of over 8700 citations.", "labels": [], "entities": []}, {"text": "Our experiments use a supervised classifier with the state-of-the-art features from the literature, as well as new features based on the observations above.", "labels": [], "entities": []}, {"text": "Our results show that the most successful feature combination includes dependency features and n-grams longer than for other genres (n = 3), but the assumption of a smaller scope (sentence splitting) decreased results.", "labels": [], "entities": [{"text": "sentence splitting", "start_pos": 180, "end_pos": 198, "type": "TASK", "confidence": 0.7140083760023117}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Results using science lexicon (scilex), contex- tual polarity (cpol), dependencies (dep), negation (neg),  sentence splitting (split) and word-level (wlev) features.", "labels": [], "entities": [{"text": "sentence splitting", "start_pos": 117, "end_pos": 135, "type": "TASK", "confidence": 0.6920269578695297}]}]}