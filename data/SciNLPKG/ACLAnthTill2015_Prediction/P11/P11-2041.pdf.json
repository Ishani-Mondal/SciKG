{"title": [{"text": "Semi-Supervised Modeling for Prenominal Modifier Ordering", "labels": [], "entities": [{"text": "Prenominal Modifier Ordering", "start_pos": 29, "end_pos": 57, "type": "TASK", "confidence": 0.5429486334323883}]}], "abstractContent": [{"text": "In this paper, we argue that ordering prenom-inal modifiers-typically pursued as a supervised modeling task-is particularly well-suited to semi-supervised approaches.", "labels": [], "entities": []}, {"text": "By relying on automatic parses to extract noun phrases, we can scale up the training data by orders of magnitude.", "labels": [], "entities": []}, {"text": "This minimizes the predominant issue of data sparsity that has informed most previous approaches.", "labels": [], "entities": []}, {"text": "We compare several recent approaches, and find improvements from additional training data across the board; however, none outperform a simple n-gram model.", "labels": [], "entities": []}], "introductionContent": [{"text": "In any given noun phrase (NP), an arbitrary number of nominal modifiers maybe used.", "labels": [], "entities": []}, {"text": "The order of these modifiers affects how natural or fluent a phrase sounds.", "labels": [], "entities": []}, {"text": "Determining a natural ordering is a key task in the surface realization stage of a natural language generation (NLG) system, where the adjectives and other modifiers chosen to identify a referent must be ordered before a final string is produced.", "labels": [], "entities": [{"text": "Determining a natural ordering", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.8656661808490753}, {"text": "natural language generation (NLG)", "start_pos": 83, "end_pos": 116, "type": "TASK", "confidence": 0.8336379726727804}]}, {"text": "For example, consider the alternation between the phrases \"big red ball\" and \"red big ball\".", "labels": [], "entities": []}, {"text": "The phrase \"big red ball\" provides a basic ordering of the words big and red.", "labels": [], "entities": []}, {"text": "The reverse ordering, in \"red big ball\", sounds strange, a phrase that would only occur in marked situations.", "labels": [], "entities": []}, {"text": "There is no consensus on the exact qualities that affect a modifier's position, but it is clear that some modifier orderings sound more natural than others, even if all are strictly speaking grammatical.", "labels": [], "entities": []}, {"text": "Determining methods for ordering modifiers prenominally and investigating the factors underlying modifier ordering have been areas of considerable research, including work in natural language processing, linguistics, and psychology.", "labels": [], "entities": []}, {"text": "A central issue in work on modifier ordering is how to order modifiers that are unobserved during system development.", "labels": [], "entities": [{"text": "modifier ordering", "start_pos": 27, "end_pos": 44, "type": "TASK", "confidence": 0.8276824057102203}]}, {"text": "English has upwards of 200,000 words, with over 50,000 words in the vocabulary of an educated adult.", "labels": [], "entities": []}, {"text": "Up to a quarter of these words maybe adjectives, which poses a significant problem for any system that attempts to categorize English adjectives in ways that are useful for an ordering task.", "labels": [], "entities": []}, {"text": "Extensive in-context observation of adjectives and other modifiers is required to adequately characterize their behavior.", "labels": [], "entities": []}, {"text": "Developers of automatic modifier ordering systems have thus spent considerable effort attempting to make reliable predictions despite sparse data, and have largely limited their systems to order modifier pairs instead of full modifier strings.", "labels": [], "entities": []}, {"text": "Conventional wisdom has been that direct evidence methods such as simple n-gram modeling are insufficient for capturing such a complex and productive process.", "labels": [], "entities": []}, {"text": "Recent approaches have therefore utilized increasingly sophisticated data-driven approaches.", "labels": [], "entities": []}, {"text": "Most recently, used both discriminative and generative methods for estimating class-based language models with multiplesequence alignments (MSA).", "labels": [], "entities": []}, {"text": "Training on manually curated syntactic corpora, they showed excellent indomain performance relative to prior systems, and decent cross-domain generalization.", "labels": [], "entities": []}, {"text": "However, following a purely supervised training approach for this task is unduly limiting and leads to conventional assumptions that are not borne out in practice, such as the inapplicability of simple n-236 gram models.", "labels": [], "entities": []}, {"text": "NP segmentation is one of the most reliable annotations that automatic parsers can now produce, and maybe applied to essentially arbitrary amounts of unlabeled data.", "labels": [], "entities": [{"text": "NP segmentation", "start_pos": 0, "end_pos": 15, "type": "TASK", "confidence": 0.7327100336551666}]}, {"text": "This yields orders-ofmagnitude larger training sets, so that methods that are sensitive to sparse data and/or are domain specific can be trained on sufficient data.", "labels": [], "entities": []}, {"text": "In this paper, we compare an n-gram language model and a hidden Markov model (HMM) constructed using expectation maximization (EM) with several recent ordering approaches, and demonstrate superior performance of the n-gram model across different domains, particularly as the training data size is scaled up.", "labels": [], "entities": []}, {"text": "This paper presents two important results: 1) N-gram modeling performs better than previously believed for this task, and in fact surpasses current class-based systems.", "labels": [], "entities": []}, {"text": "1 2) Automatic parsers can effectively provide essentially unlimited training data for learning modifier ordering preferences.", "labels": [], "entities": []}, {"text": "Our results point the way to larger scale datadriven approaches to this and related tasks.", "labels": [], "entities": []}], "datasetContent": [{"text": "Below, we evaluate these most recent systems, scaling up the training data by several orders of magnitude.", "labels": [], "entities": []}, {"text": "Our results indicate that an n-gram model outperforms previous systems, and generalizes quite well across different domains.", "labels": [], "entities": []}, {"text": "With respect to cross-domain applicability, we see that, as with the WSJ evaluation, the MSA and ngram approaches are roughly commensurate on the Brown corpus; but the n-gram model shows a greater advantage on the Switchboard test set when trained on the NYT data.", "labels": [], "entities": [{"text": "WSJ evaluation", "start_pos": 69, "end_pos": 83, "type": "DATASET", "confidence": 0.8144120573997498}, {"text": "ngram", "start_pos": 97, "end_pos": 102, "type": "METRIC", "confidence": 0.8859269022941589}, {"text": "Brown corpus", "start_pos": 146, "end_pos": 158, "type": "DATASET", "confidence": 0.8567483723163605}, {"text": "Switchboard test set", "start_pos": 214, "end_pos": 234, "type": "DATASET", "confidence": 0.8462713758150736}, {"text": "NYT data", "start_pos": 255, "end_pos": 263, "type": "DATASET", "confidence": 0.9536731243133545}]}, {"text": "Perhaps this is due to higher reliance on conventionalized collocations in the spoken language of Switchboard.", "labels": [], "entities": []}, {"text": "Finally, it is clear that the addition of the WSJ data to the NYT data yields improvements only for the specific newswire domain -none of the results change much for these two new domains when the WSJ data is included (last row of the table).", "labels": [], "entities": [{"text": "WSJ data", "start_pos": 46, "end_pos": 54, "type": "DATASET", "confidence": 0.8821240365505219}, {"text": "NYT data", "start_pos": 62, "end_pos": 70, "type": "DATASET", "confidence": 0.9423782229423523}, {"text": "WSJ data", "start_pos": 197, "end_pos": 205, "type": "DATASET", "confidence": 0.9108967483043671}]}, {"text": "We note that the improvements observed when scaling the training corpus with in-domain data persist when applied to very diverse domains.", "labels": [], "entities": []}, {"text": "Interestingly, n-gram models, which may have been considered unlikely to generalize well to other domains, maintain their superior performance in each trial.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Multi-modifier noun phrases in training data", "labels": [], "entities": []}, {"text": " Table 2: Multi-modifier noun phrases in testing data", "labels": [], "entities": []}, {"text": " Table 4: Results on WSJ sections 22-24, Switchboard test set, and Brown test set for n-gram model (Ngr), Mitchell's  single-class system (1-cl), HMM and MSA systems, under various training conditions.", "labels": [], "entities": [{"text": "WSJ sections 22-24", "start_pos": 21, "end_pos": 39, "type": "DATASET", "confidence": 0.7846478422482809}, {"text": "Switchboard test set", "start_pos": 41, "end_pos": 61, "type": "DATASET", "confidence": 0.791810005903244}]}]}