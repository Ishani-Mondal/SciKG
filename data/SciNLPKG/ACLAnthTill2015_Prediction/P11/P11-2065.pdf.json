{"title": [{"text": "Detection of Agreement and Disagreement in Broadcast Conversations", "labels": [], "entities": [{"text": "Detection of Agreement and Disagreement in Broadcast Conversations", "start_pos": 0, "end_pos": 66, "type": "TASK", "confidence": 0.8845269680023193}]}], "abstractContent": [{"text": "We present Conditional Random Fields based approaches for detecting agree-ment/disagreement between speakers in English broadcast conversation shows.", "labels": [], "entities": [{"text": "detecting agree-ment/disagreement between speakers in English broadcast conversation shows", "start_pos": 58, "end_pos": 148, "type": "TASK", "confidence": 0.7606287923726168}]}, {"text": "We develop annotation approaches fora variety of linguistic phenomena.", "labels": [], "entities": []}, {"text": "Various lexical, structural, durational, and prosodic features are explored.", "labels": [], "entities": []}, {"text": "We compare the performance when using features extracted from automatically generated annotations against that when using human annotations.", "labels": [], "entities": []}, {"text": "We investigate the efficacy of adding prosodic features on top of lexical, structural, and durational features.", "labels": [], "entities": [{"text": "durational", "start_pos": 91, "end_pos": 101, "type": "METRIC", "confidence": 0.9355962872505188}]}, {"text": "Since the training data is highly imbalanced, we explore two sampling approaches, random downsampling and ensemble downsampling.", "labels": [], "entities": []}, {"text": "Overall, our approach achieves 79.2% (precision), 50.5% (recall), 61.7% (F1) for agreement detection and 69.2% (precision), 46.9% (recall), and 55.9% (F1) for disagreement detection, on the English broadcast conversation data.", "labels": [], "entities": [{"text": "precision", "start_pos": 38, "end_pos": 47, "type": "METRIC", "confidence": 0.9992903470993042}, {"text": "recall", "start_pos": 57, "end_pos": 63, "type": "METRIC", "confidence": 0.9977802634239197}, {"text": "F1", "start_pos": 73, "end_pos": 75, "type": "METRIC", "confidence": 0.9978400468826294}, {"text": "agreement detection", "start_pos": 81, "end_pos": 100, "type": "TASK", "confidence": 0.756237655878067}, {"text": "precision", "start_pos": 112, "end_pos": 121, "type": "METRIC", "confidence": 0.9980738162994385}, {"text": "recall", "start_pos": 131, "end_pos": 137, "type": "METRIC", "confidence": 0.9945794343948364}, {"text": "F1", "start_pos": 151, "end_pos": 153, "type": "METRIC", "confidence": 0.9974743723869324}, {"text": "disagreement detection", "start_pos": 159, "end_pos": 181, "type": "TASK", "confidence": 0.7077637612819672}, {"text": "English broadcast conversation data", "start_pos": 190, "end_pos": 225, "type": "DATASET", "confidence": 0.9266318827867508}]}], "introductionContent": [{"text": "In this work, we present models for detecting agreement/disagreement (denoted (dis)agreement) between speakers in English broadcast conversation shows.", "labels": [], "entities": [{"text": "detecting agreement/disagreement (denoted (dis)agreement) between speakers in English broadcast conversation shows", "start_pos": 36, "end_pos": 150, "type": "TASK", "confidence": 0.6957242819998}]}, {"text": "The Broadcast Conversation (BC) genre differs from the Broadcast News (BN) genre in that it is more interactive and spontaneous, referring to free speech in news-style TV and radio programs and consisting of talk shows, interviews, call-in programs, live reports, and round-tables.", "labels": [], "entities": [{"text": "Broadcast Conversation (BC) genre", "start_pos": 4, "end_pos": 37, "type": "TASK", "confidence": 0.6808232416709264}]}, {"text": "Previous \ud97b\udf59 y This work was performed while the author was at ICSI.", "labels": [], "entities": [{"text": "ICSI", "start_pos": 61, "end_pos": 65, "type": "DATASET", "confidence": 0.9570232033729553}]}, {"text": "work on detecting (dis)agreements has been focused on meeting data.", "labels": [], "entities": [{"text": "detecting (dis)agreements", "start_pos": 8, "end_pos": 33, "type": "TASK", "confidence": 0.835737657546997}]}, {"text": "(,),) used spurt-level agreement annotations from the ICSI meeting corpus (.", "labels": [], "entities": [{"text": "ICSI meeting corpus", "start_pos": 54, "end_pos": 73, "type": "DATASET", "confidence": 0.9649932980537415}]}, {"text": "() explored unsupervised machine learning approaches and on manual transcripts, they achieved an overall 3-way agreement/disagreement classification accuracy as 82% with keyword features.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 149, "end_pos": 157, "type": "METRIC", "confidence": 0.8476919531822205}]}, {"text": "() explored Bayesian Networks for the detection of (dis)agreements.", "labels": [], "entities": [{"text": "detection of (dis)agreements", "start_pos": 38, "end_pos": 66, "type": "TASK", "confidence": 0.7990925510724386}]}, {"text": "They used adjacency pair information to determine the structure of their conditional Markov model and outperformed the results of () by improving the 3-way classification accuracy into 86.9%.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 171, "end_pos": 179, "type": "METRIC", "confidence": 0.9380501508712769}]}, {"text": "() explored semi-supervised learning algorithms and reached a competitive performance of 86.7% 3-way classification accuracy on manual transcriptions with only lexical features.) investigated supervised machine learning techniques and yields competitive results on the annotated data from the AMI meeting corpus).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 116, "end_pos": 124, "type": "METRIC", "confidence": 0.8878200054168701}, {"text": "AMI meeting corpus", "start_pos": 293, "end_pos": 311, "type": "DATASET", "confidence": 0.9640105962753296}]}, {"text": "Our work differs from these previous studies in two major categories.", "labels": [], "entities": []}, {"text": "One is that a different definition of (dis)agreement was used.", "labels": [], "entities": []}, {"text": "In the current work, a (dis)agreement occurs when a responding speaker agrees with, accepts, or disagrees with or rejects, a statement or proposition by a first speaker.", "labels": [], "entities": [{"text": "a (dis)agreement occurs when a responding speaker agrees with, accepts, or disagrees with or rejects, a statement or proposition by a first speaker", "start_pos": 21, "end_pos": 168, "type": "Description", "confidence": 0.7585535501611644}]}, {"text": "Second, we explored (dis)agreement detection in broadcast conversation.", "labels": [], "entities": [{"text": "agreement detection", "start_pos": 25, "end_pos": 44, "type": "TASK", "confidence": 0.6975131779909134}]}, {"text": "Due to the difference in publicity and intimacy/collegiality between speakers in broadcast conversations vs. meetings, (dis)agreement may have different character-374 istics.", "labels": [], "entities": []}, {"text": "Different from the unsupervised approaches in ( and semi-supervised approaches in), we conducted supervised training.", "labels": [], "entities": []}, {"text": "Also, different from ( and (), our classification was carried out on the utterance level, instead of on the spurt-level.s work by adding features from previous spurts and features from the general dialog context to infer the class of the current spurt, on top of features from the current spurt (local features) used by Hillard et al. used adjacency pairs to describe the interaction between speakers and the relations between consecutive spurts.", "labels": [], "entities": []}, {"text": "In this preliminary study on broadcast conversation, we directly modeled (dis)agreement detection without using adjacency pairs.", "labels": [], "entities": [{"text": "dis)agreement detection", "start_pos": 74, "end_pos": 97, "type": "TASK", "confidence": 0.6311521902680397}]}, {"text": "Still, within the conditional random fields (CRF) framework, we explored features from preceding and following utterances to consider context in the discourse structure.", "labels": [], "entities": []}, {"text": "We explored a wide variety of features, including lexical, structural, durational, and prosodic features.", "labels": [], "entities": []}, {"text": "To our knowledge, this is the first work to systematically investigate detection of agreement/disagreement for broadcast conversation data.", "labels": [], "entities": [{"text": "detection of agreement/disagreement", "start_pos": 71, "end_pos": 106, "type": "TASK", "confidence": 0.8093209147453309}]}, {"text": "The remainder of the paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 presents our data and automatic annotation modules.", "labels": [], "entities": []}, {"text": "Section 3 describes various features and the CRF model we explored.", "labels": [], "entities": []}, {"text": "Experimental results and discussion appear in Section 4, as well as conclusions and future directions.", "labels": [], "entities": []}], "datasetContent": [{"text": "All (dis)agreement detection results are based on nfold cross-validation.", "labels": [], "entities": [{"text": "agreement detection", "start_pos": 9, "end_pos": 28, "type": "TASK", "confidence": 0.6644091755151749}]}, {"text": "In this procedure, we held out one show as the test set, randomly held out another show as the dev set, trained models on the rest of the data, and tested the model on the heldout show.", "labels": [], "entities": []}, {"text": "We iterated through all shows and computed the overall accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 55, "end_pos": 63, "type": "METRIC", "confidence": 0.9992513060569763}]}, {"text": "shows the results of (dis)agreement detection using all features except prosodic features.", "labels": [], "entities": [{"text": "dis)agreement detection", "start_pos": 22, "end_pos": 45, "type": "TASK", "confidence": 0.6146306172013283}]}, {"text": "We compared two conditions: (1) features extracted completely from the automatic LUC annotations and automatically detected speaker roles, and (2) features from manual speaker role labels and manual LUC annotations when manual annotations are available.", "labels": [], "entities": []}, {"text": "showed that running a fully automatic system to generate automatic annotations and automatic speaker roles pro-376 duced comparable performance to the system using features from manual annotations whenever available.: Precision (%), recall (%), and F1 (%) of (dis)agreement detection using features extracted from manual speaker role labels and manual LUC annotations when available, denoted Manual Annotation, and automatic LUC annotations and automatically detected speaker roles, denoted Automatic Annotation.", "labels": [], "entities": [{"text": "Precision", "start_pos": 218, "end_pos": 227, "type": "METRIC", "confidence": 0.9970965385437012}, {"text": "recall", "start_pos": 233, "end_pos": 239, "type": "METRIC", "confidence": 0.9990449547767639}, {"text": "F1", "start_pos": 249, "end_pos": 251, "type": "METRIC", "confidence": 0.9986730813980103}, {"text": "agreement detection", "start_pos": 264, "end_pos": 283, "type": "TASK", "confidence": 0.6743067651987076}]}, {"text": "We then focused on the condition of using features from manual annotations when available and added prosodic features as described in Section 3.", "labels": [], "entities": []}, {"text": "The results are shown in.", "labels": [], "entities": []}, {"text": "Adding prosodic features produced a 0.7% absolute gain on F1 on agreement detection, and 1.5% absolute gain on F1 on disagreement detection.: Precision (%), recall (%), and F1 (%) of (dis)agreement detection using manual annotations without and with prosodic features.", "labels": [], "entities": [{"text": "F1", "start_pos": 58, "end_pos": 60, "type": "METRIC", "confidence": 0.9988195300102234}, {"text": "agreement detection", "start_pos": 64, "end_pos": 83, "type": "TASK", "confidence": 0.7452674508094788}, {"text": "F1", "start_pos": 111, "end_pos": 113, "type": "METRIC", "confidence": 0.9952398538589478}, {"text": "disagreement detection.", "start_pos": 117, "end_pos": 140, "type": "TASK", "confidence": 0.7164807468652725}, {"text": "Precision", "start_pos": 142, "end_pos": 151, "type": "METRIC", "confidence": 0.9876055717468262}, {"text": "recall", "start_pos": 157, "end_pos": 163, "type": "METRIC", "confidence": 0.9990541338920593}, {"text": "F1", "start_pos": 173, "end_pos": 175, "type": "METRIC", "confidence": 0.9995641112327576}, {"text": "agreement detection", "start_pos": 188, "end_pos": 207, "type": "TASK", "confidence": 0.6769896596670151}]}, {"text": "Note that only about 10% utterances among all data are involved in (dis)agreement.", "labels": [], "entities": []}, {"text": "This indicates a highly imbalanced data set as one class is more heavily represented than the other/others.", "labels": [], "entities": []}, {"text": "We suspected that this high imbalance has played a major role in the high precision and low recall results we obtained so far.", "labels": [], "entities": [{"text": "precision", "start_pos": 74, "end_pos": 83, "type": "METRIC", "confidence": 0.9956023693084717}, {"text": "recall", "start_pos": 92, "end_pos": 98, "type": "METRIC", "confidence": 0.9973002076148987}]}, {"text": "Various approaches have been studied to handle imbalanced data for classifications, trying to balance the class distribution in the training set by either oversampling the minority class or downsampling the majority class.", "labels": [], "entities": []}, {"text": "In this preliminary study of sampling approaches for handling imbalanced data for CRF training, we investigated two approaches, random downsampling and ensemble downsampling.", "labels": [], "entities": [{"text": "CRF training", "start_pos": 82, "end_pos": 94, "type": "TASK", "confidence": 0.9467747807502747}]}, {"text": "Random downsampling randomly downsamples the majority class to equate the number of minority and majority class samples.", "labels": [], "entities": []}, {"text": "Ensemble downsampling is a refinement of random downsampling which doesn't discard any majority class samples.", "labels": [], "entities": []}, {"text": "Instead, we partitioned the majority class samples into N subspaces with each subspace containing the same number of samples as the minority class.", "labels": [], "entities": []}, {"text": "Then we train N CRF models, each based on the minority class samples and one disjoint partition from the N subspaces.", "labels": [], "entities": []}, {"text": "During testing, the posterior probability for one utterance is averaged over the N CRF models.", "labels": [], "entities": []}, {"text": "The results from these two sampling approaches as well as the baseline are shown in.", "labels": [], "entities": []}, {"text": "Both sampling approaches achieved significant improvement over the baseline, i.e., training on the original data set, and ensemble downsampling produced better performance than downsampling.", "labels": [], "entities": []}, {"text": "We noticed that both sampling approaches degraded slightly in precision but improved significantly in recall, resulting in 4.5% absolute gain on F1 for agreement detection and 4.7% absolute gain on F1 for disagreement detection.", "labels": [], "entities": [{"text": "precision", "start_pos": 62, "end_pos": 71, "type": "METRIC", "confidence": 0.9994221925735474}, {"text": "recall", "start_pos": 102, "end_pos": 108, "type": "METRIC", "confidence": 0.9992697834968567}, {"text": "F1", "start_pos": 145, "end_pos": 147, "type": "METRIC", "confidence": 0.998136043548584}, {"text": "agreement detection", "start_pos": 152, "end_pos": 171, "type": "TASK", "confidence": 0.7537484467029572}, {"text": "F1", "start_pos": 198, "end_pos": 200, "type": "METRIC", "confidence": 0.9943795800209045}, {"text": "disagreement detection", "start_pos": 205, "end_pos": 227, "type": "TASK", "confidence": 0.6940024197101593}]}, {"text": "In conclusion, this paper presents our work on detection of agreements and disagreements in En-377 glish broadcast conversation data.", "labels": [], "entities": [{"text": "En-377 glish broadcast conversation data", "start_pos": 92, "end_pos": 132, "type": "DATASET", "confidence": 0.6249507427215576}]}, {"text": "We explored a variety of features, including lexical, structural, durational, and prosodic features.", "labels": [], "entities": []}, {"text": "We experimented these features using a linear-chain conditional random fields model and conducted supervised training.", "labels": [], "entities": []}, {"text": "We observed significant improvement from adding prosodic features and employing two sampling approaches, random downsampling and ensemble downsampling.", "labels": [], "entities": []}, {"text": "Overall, we achieved 79.2% (precision), 50.5% (recall), 61.7% (F1) for agreement detection and 69.2% (precision), 46.9% (recall), and 55.9% (F1) for disagreement detection, on English broadcast conversation data.", "labels": [], "entities": [{"text": "precision", "start_pos": 28, "end_pos": 37, "type": "METRIC", "confidence": 0.999190628528595}, {"text": "recall", "start_pos": 47, "end_pos": 53, "type": "METRIC", "confidence": 0.9978000521659851}, {"text": "F1", "start_pos": 63, "end_pos": 65, "type": "METRIC", "confidence": 0.9979750514030457}, {"text": "agreement detection", "start_pos": 71, "end_pos": 90, "type": "TASK", "confidence": 0.7772313356399536}, {"text": "precision", "start_pos": 102, "end_pos": 111, "type": "METRIC", "confidence": 0.9980741739273071}, {"text": "recall", "start_pos": 121, "end_pos": 127, "type": "METRIC", "confidence": 0.9942464232444763}, {"text": "F1", "start_pos": 141, "end_pos": 143, "type": "METRIC", "confidence": 0.9972273707389832}, {"text": "disagreement detection", "start_pos": 149, "end_pos": 171, "type": "TASK", "confidence": 0.7065924257040024}, {"text": "English broadcast conversation data", "start_pos": 176, "end_pos": 211, "type": "DATASET", "confidence": 0.8474978059530258}]}, {"text": "In future work, we plan to continue adding and refining features, explore dependencies between features and contextual cues with respect to agreements and disagreements, and investigate the efficacy of other machine learning approaches such as Bayesian networks and Support Vector Machines.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Precision (%), recall (%), and F1 (%) of  (dis)agreement detection using features extracted from  manual speaker role labels and manual LUC annota- tions when available, denoted Manual Annotation, and  automatic LUC annotations and automatically detected  speaker roles, denoted Automatic Annotation.", "labels": [], "entities": [{"text": "Precision", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9977226853370667}, {"text": "recall", "start_pos": 25, "end_pos": 31, "type": "METRIC", "confidence": 0.9991821646690369}, {"text": "F1", "start_pos": 41, "end_pos": 43, "type": "METRIC", "confidence": 0.999583899974823}, {"text": "agreement detection", "start_pos": 57, "end_pos": 76, "type": "TASK", "confidence": 0.6855732798576355}]}, {"text": " Table 2: Precision (%), recall (%), and F1 (%) of  (dis)agreement detection using manual annotations with- out and with prosodic features.", "labels": [], "entities": [{"text": "Precision", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9982221722602844}, {"text": "recall", "start_pos": 25, "end_pos": 31, "type": "METRIC", "confidence": 0.9995861649513245}, {"text": "F1", "start_pos": 41, "end_pos": 43, "type": "METRIC", "confidence": 0.9997273087501526}, {"text": "agreement detection", "start_pos": 57, "end_pos": 76, "type": "TASK", "confidence": 0.6257935613393784}]}, {"text": " Table 3: Precision (%), recall (%), and F1 (%) of  (dis)agreement detection without sampling, with random  downsampling and ensemble downsampling. Manual an- notations and prosodic features are used.", "labels": [], "entities": [{"text": "Precision", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9979068040847778}, {"text": "recall", "start_pos": 25, "end_pos": 31, "type": "METRIC", "confidence": 0.999447762966156}, {"text": "F1", "start_pos": 41, "end_pos": 43, "type": "METRIC", "confidence": 0.9995478987693787}, {"text": "agreement detection", "start_pos": 57, "end_pos": 76, "type": "TASK", "confidence": 0.6483994275331497}]}]}