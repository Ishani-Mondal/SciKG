{"title": [{"text": "Question Detection in Spoken Conversations Using Textual Conversations", "labels": [], "entities": [{"text": "Question Detection in Spoken Conversations", "start_pos": 0, "end_pos": 42, "type": "TASK", "confidence": 0.8062278985977173}]}], "abstractContent": [{"text": "We investigate the use of textual Internet conversations for detecting questions in spoken conversations.", "labels": [], "entities": [{"text": "detecting questions in spoken conversations", "start_pos": 61, "end_pos": 104, "type": "TASK", "confidence": 0.8237220168113708}]}, {"text": "We compare the text-trained model with models trained on manually-labeled, domain-matched spoken utterances with and without prosodic features.", "labels": [], "entities": []}, {"text": "Overall , the text-trained model achieves over 90% of the performance (measured in Area Under the Curve) of the domain-matched model including prosodic features, but does especially poorly on declarative questions.", "labels": [], "entities": []}, {"text": "We describe efforts to utilize unlabeled spoken utterances and prosodic features via domain adaptation.", "labels": [], "entities": []}], "introductionContent": [{"text": "Automatic speech recognition systems, which transcribe words, are often augmented by subsequent processing for inserting punctuation or labeling speech acts.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 10, "end_pos": 28, "type": "TASK", "confidence": 0.7185448259115219}, {"text": "labeling speech acts", "start_pos": 136, "end_pos": 156, "type": "TASK", "confidence": 0.7876336574554443}]}, {"text": "Both prosodic features (extracted from the acoustic signal) and lexical features (extracted from the word sequence) have been shown to be useful for these tasks).", "labels": [], "entities": []}, {"text": "However, access to labeled speech training data is generally required in order to use prosodic features.", "labels": [], "entities": []}, {"text": "On the other hand, the Internet contains large quantities of textual data that is already labeled with punctuation, and which can be used to train a system using lexical features.", "labels": [], "entities": []}, {"text": "In this work, we focus on question detection in the Meeting Recorder Dialog Act corpus (MRDA) ( ), using text sentences with question marks in Wikipedia \"talk\" pages.", "labels": [], "entities": [{"text": "question detection", "start_pos": 26, "end_pos": 44, "type": "TASK", "confidence": 0.8621684014797211}, {"text": "Meeting Recorder Dialog Act corpus (MRDA)", "start_pos": 52, "end_pos": 93, "type": "DATASET", "confidence": 0.8023423030972481}]}, {"text": "We compare the performance of a question detector trained on the text domain using lexical features with one trained on MRDA using lexical features and/or prosodic features.", "labels": [], "entities": []}, {"text": "In addition, we experiment with two unsupervised domain adaptation methods to incorporate unlabeled MRDA utterances into the text-based question detector.", "labels": [], "entities": []}, {"text": "The goal is to use the unlabeled domain-matched data to bridge stylistic differences as well as to incorporate the prosodic features, which are unavailable in the labeled text data.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 2: Question detection rates (%) by question type for  each system (L=lexical features, P=prosodic features.)  Detection rates are given at a false positive rate of 16.7%  (starred points in", "labels": [], "entities": [{"text": "Question detection", "start_pos": 10, "end_pos": 28, "type": "TASK", "confidence": 0.8093354403972626}]}, {"text": " Table 3: Adaptation performance by question type, at  false positive rate of 16.7% (starred points in", "labels": [], "entities": []}]}