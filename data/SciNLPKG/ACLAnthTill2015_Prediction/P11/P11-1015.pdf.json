{"title": [{"text": "Learning Word Vectors for Sentiment Analysis", "labels": [], "entities": [{"text": "Sentiment Analysis", "start_pos": 26, "end_pos": 44, "type": "TASK", "confidence": 0.972612202167511}]}], "abstractContent": [{"text": "Unsupervised vector-based approaches to semantics can model rich lexical meanings, but they largely fail to capture sentiment information that is central to many word meanings and important fora wide range of NLP tasks.", "labels": [], "entities": []}, {"text": "We present a model that uses a mix of unsuper-vised and supervised techniques to learn word vectors capturing semantic term-document information as well as rich sentiment content.", "labels": [], "entities": []}, {"text": "The proposed model can leverage both continuous and multi-dimensional sentiment information as well as non-sentiment annotations.", "labels": [], "entities": []}, {"text": "We instantiate the model to utilize the document-level sentiment polarity annotations present in many online documents (e.g. star ratings).", "labels": [], "entities": []}, {"text": "We evaluate the model using small, widely used sentiment and subjectivity corpora and find it out-performs several previously introduced methods for sentiment classification.", "labels": [], "entities": [{"text": "sentiment classification", "start_pos": 149, "end_pos": 173, "type": "TASK", "confidence": 0.9043182730674744}]}, {"text": "We also introduce a large dataset of movie reviews to serve as a more robust benchmark for work in this area.", "labels": [], "entities": []}], "introductionContent": [{"text": "Word representations area critical component of many natural language processing systems.", "labels": [], "entities": [{"text": "Word representations", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.6725480854511261}]}, {"text": "It is common to represent words as indices in a vocabulary, but this fails to capture the rich relational structure of the lexicon.", "labels": [], "entities": []}, {"text": "Vector-based models do much better in this regard.", "labels": [], "entities": []}, {"text": "They encode continuous similarities between words as distance or angle between word vectors in a high-dimensional space.", "labels": [], "entities": []}, {"text": "The general approach has proven useful in tasks such as word sense disambiguation, named entity recognition, part of speech tagging, and document retrieval.", "labels": [], "entities": [{"text": "word sense disambiguation", "start_pos": 56, "end_pos": 81, "type": "TASK", "confidence": 0.7360045313835144}, {"text": "named entity recognition", "start_pos": 83, "end_pos": 107, "type": "TASK", "confidence": 0.6386526226997375}, {"text": "part of speech tagging", "start_pos": 109, "end_pos": 131, "type": "TASK", "confidence": 0.7063411772251129}, {"text": "document retrieval", "start_pos": 137, "end_pos": 155, "type": "TASK", "confidence": 0.7902060747146606}]}, {"text": "In this paper, we present a model to capture both semantic and sentiment similarities among words.", "labels": [], "entities": []}, {"text": "The semantic component of our model learns word vectors via an unsupervised probabilistic model of documents.", "labels": [], "entities": []}, {"text": "However, in keeping with linguistic and cognitive research arguing that expressive content and descriptive semantic content are distinct, we find that this basic model misses crucial sentiment information.", "labels": [], "entities": []}, {"text": "For example, while it learns that wonderful and amazing are semantically close, it doesn't capture the fact that these are both very strong positive sentiment words, at the opposite end of the spectrum from terrible and awful.", "labels": [], "entities": []}, {"text": "Thus, we extend the model with a supervised sentiment component that is capable of embracing many social and attitudinal aspects of meaning.", "labels": [], "entities": []}, {"text": "This component of the model uses the vector representation of words to predict the sentiment annotations on contexts in which the words appear.", "labels": [], "entities": []}, {"text": "This causes words expressing similar sentiment to have similar vector representations.", "labels": [], "entities": []}, {"text": "The full objective function of the model thus learns semantic vectors that are imbued with nuanced sentiment information.", "labels": [], "entities": []}, {"text": "In our experiments, we show how the model can leverage document-level sentiment annotations of a sort that are abundant online in the form of consumer reviews for movies, products, etc.", "labels": [], "entities": []}, {"text": "The technique is sufficiently general to work also with continuous and multi-dimensional notions of sentiment as well as non-sentiment annotations (e.g., political affiliation, speaker commitment).", "labels": [], "entities": []}, {"text": "After presenting the model in detail, we provide illustrative examples of the vectors it learns, and then we systematically evaluate the approach on document-level and sentence-level classification tasks.", "labels": [], "entities": [{"text": "sentence-level classification", "start_pos": 168, "end_pos": 197, "type": "TASK", "confidence": 0.6509507894515991}]}, {"text": "Our experiments involve the small, widely used sentiment and subjectivity corpora of, which permits us to make comparisons with a number of related approaches and published results.", "labels": [], "entities": []}, {"text": "We also show that this dataset contains many correlations between examples in the training and testing sets.", "labels": [], "entities": []}, {"text": "This leads us to evaluate on, and make publicly available, a large dataset of informal movie reviews from the Internet Movie Database (IMDB).", "labels": [], "entities": [{"text": "Internet Movie Database (IMDB)", "start_pos": 110, "end_pos": 140, "type": "DATASET", "confidence": 0.8232812484105428}]}], "datasetContent": [{"text": "We evaluate our model with document-level and sentence-level categorization tasks in the domain of online movie reviews.", "labels": [], "entities": []}, {"text": "For document categorization, we compare our method to previously published results on a standard dataset, and introduce anew dataset for the task.", "labels": [], "entities": [{"text": "document categorization", "start_pos": 4, "end_pos": 27, "type": "TASK", "confidence": 0.6997018903493881}]}, {"text": "In both tasks we compare our model's word representations with several bag of words weighting methods, and alternative approaches to word vector induction.", "labels": [], "entities": [{"text": "word vector induction", "start_pos": 133, "end_pos": 154, "type": "TASK", "confidence": 0.706867496172587}]}, {"text": "The polarity dataset version 2.0 introduced by Pang and Lee (2004) 1 consists of 2,000 movie reviews, where each is associated with a binary sentiment polarity label.", "labels": [], "entities": []}, {"text": "We report 10-fold cross validation results using the authors' published folds to make our results comparable with others in the literature.", "labels": [], "entities": []}, {"text": "We use a linear support vector machine (SVM) classifier trained with LIBLINEAR, and set the SVM regularization parameter to the same value used by. shows the classification performance of our method, other VSMs we implemented, and previously reported results from the literature.", "labels": [], "entities": [{"text": "LIBLINEAR", "start_pos": 69, "end_pos": 78, "type": "METRIC", "confidence": 0.9836663007736206}]}, {"text": "Bag of words vectors are denoted by their weighting notation.", "labels": [], "entities": []}, {"text": "Features from word vector learner are denoted by the learner name.", "labels": [], "entities": []}, {"text": "As a control, we trained versions of our model with only the unsupervised semantic component, and the full model (semantic and sentiment).", "labels": [], "entities": []}, {"text": "We also include results fora version of our full model trained with 50,000 additional unlabeled examples.", "labels": [], "entities": []}, {"text": "Finally, to test whether our models' representations complement a standard bag of words, we evaluate performance of the two feature representations concatenated.", "labels": [], "entities": []}, {"text": "1 http://www.cs.cornell.edu/people/pabo/movie-review-data Our method's features clearly outperform those of other VSMs, and perform best when combined with the original bag of words representation.", "labels": [], "entities": []}, {"text": "The variant of our model trained with additional unlabeled data performed best, suggesting the model can effectively utilize large amounts of unlabeled data along with labeled examples.", "labels": [], "entities": []}, {"text": "Our method performs competitively with previously reported results in spite of our restriction to a vocabulary of only 5,000 words.", "labels": [], "entities": []}, {"text": "We extracted the movie title associated with each review and found that 1,299 of the 2,000 reviews in the dataset have at least one other review of the same movie in the dataset.", "labels": [], "entities": []}, {"text": "Of 406 movies with multiple reviews, 249 have the same polarity label for all of their reviews.", "labels": [], "entities": []}, {"text": "Overall, these facts suggest that, relative to the size of the dataset, there are highly correlated examples with correlated labels.", "labels": [], "entities": []}, {"text": "This is a natural and expected property of this kind of document collection, but it can have a substantial impact on performance in datasets of this scale.", "labels": [], "entities": []}, {"text": "In the random folds distributed by the authors, approximately 50% of reviews in each validation fold's test set have a review of the same movie with the same label in the training set.", "labels": [], "entities": []}, {"text": "Because the dataset is small, a learner may perform well by memorizing the association between label and words unique to a particular movie (e.g., character names or plot terms).", "labels": [], "entities": []}, {"text": "We introduce a substantially larger dataset, which 148 uses disjoint sets of movies for training and testing.", "labels": [], "entities": []}, {"text": "These steps minimize the ability of a learner to rely on idiosyncratic word-class associations, thereby focusing attention on genuine sentiment features.", "labels": [], "entities": []}, {"text": "We constructed a collection of 50,000 reviews from IMDB, allowing no more than 30 reviews per movie.", "labels": [], "entities": [{"text": "IMDB", "start_pos": 51, "end_pos": 55, "type": "DATASET", "confidence": 0.8919424414634705}]}, {"text": "The constructed dataset contains an even number of positive and negative reviews, so randomly guessing yields 50% accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 114, "end_pos": 122, "type": "METRIC", "confidence": 0.9987553358078003}]}, {"text": "Following previous work on polarity classification, we consider only highly polarized reviews.", "labels": [], "entities": [{"text": "polarity classification", "start_pos": 27, "end_pos": 50, "type": "TASK", "confidence": 0.9789460599422455}]}, {"text": "A negative review has a score \u2264 4 out of 10, and a positive review has a score \u2265 7 out of 10.", "labels": [], "entities": []}, {"text": "Neutral reviews are not included in the dataset.", "labels": [], "entities": []}, {"text": "In the interest of providing a benchmark for future work in this area, we release this dataset to the public.", "labels": [], "entities": []}, {"text": "We evenly divided the dataset into training and test sets.", "labels": [], "entities": []}, {"text": "The training set is the same 25,000 labeled reviews used to induce word vectors with our model.", "labels": [], "entities": []}, {"text": "We evaluate classifier performance after cross-validating classifier parameters on the training set, again using a linear SVM in all cases.", "labels": [], "entities": []}, {"text": "shows classification performance on our subset of IMDB reviews.", "labels": [], "entities": [{"text": "IMDB reviews", "start_pos": 50, "end_pos": 62, "type": "DATASET", "confidence": 0.8546430766582489}]}, {"text": "Our model showed superior performance to other approaches, and performed best when concatenated with bag of words representation.", "labels": [], "entities": []}, {"text": "Again the variant of our model which utilized extra unlabeled data during training performed best.", "labels": [], "entities": []}, {"text": "Differences inaccuracy are small, but, because our test set contains 25,000 examples, the variance of the performance estimate is quite low.", "labels": [], "entities": []}, {"text": "For example, an accuracy increase of 0.1% corresponds to correctly classifying an additional 25 reviews.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 16, "end_pos": 24, "type": "METRIC", "confidence": 0.999474823474884}, {"text": "correctly", "start_pos": 57, "end_pos": 66, "type": "METRIC", "confidence": 0.9608421921730042}]}], "tableCaptions": [{"text": " Table 2: Classification accuracy on three tasks. From left to right the datasets are: A collection of 2,000 movie reviews  often used as a benchmark of sentiment classification (Pang", "labels": [], "entities": [{"text": "Classification", "start_pos": 10, "end_pos": 24, "type": "TASK", "confidence": 0.9588719606399536}, {"text": "accuracy", "start_pos": 25, "end_pos": 33, "type": "METRIC", "confidence": 0.9777088761329651}, {"text": "sentiment classification", "start_pos": 153, "end_pos": 177, "type": "TASK", "confidence": 0.9462728798389435}, {"text": "Pang", "start_pos": 179, "end_pos": 183, "type": "DATASET", "confidence": 0.8288472294807434}]}]}