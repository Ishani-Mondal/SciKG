{"title": [], "abstractContent": [{"text": "We present a probabilistic topic model for jointly identifying properties and attributes of social media review snippets.", "labels": [], "entities": []}, {"text": "Our model simultaneously learns a set of properties of a product and captures aggregate user sentiments towards these properties.", "labels": [], "entities": []}, {"text": "This approach directly enables discovery of highly rated or inconsistent properties of a product.", "labels": [], "entities": []}, {"text": "Our model admits an efficient variational mean-field inference algorithm which can be paral-lelized and run on large snippet collections.", "labels": [], "entities": []}, {"text": "We evaluate our model on a large corpus of snippets from Yelp reviews to assess property and attribute prediction.", "labels": [], "entities": [{"text": "Yelp reviews", "start_pos": 57, "end_pos": 69, "type": "DATASET", "confidence": 0.9007828533649445}, {"text": "attribute prediction", "start_pos": 93, "end_pos": 113, "type": "TASK", "confidence": 0.7209321558475494}]}, {"text": "We demonstrate that it outperforms applicable baselines by a considerable margin.", "labels": [], "entities": []}], "introductionContent": [{"text": "Online product reviews have become an increasingly valuable and influential source of information for consumers.", "labels": [], "entities": []}, {"text": "Different reviewers may choose to comment on different properties or aspects of a product; therefore their reviews focus on different qualities of the product.", "labels": [], "entities": []}, {"text": "Even when they discuss the same properties, their experiences and, subsequently, evaluations of the product can differ dramatically.", "labels": [], "entities": []}, {"text": "Thus, information in any single review may not provide a complete and balanced view representative of the product as a whole.", "labels": [], "entities": []}, {"text": "To address this need, online retailers often use simple aggregation mechanisms to represent the spectrum of user sentiment.", "labels": [], "entities": []}, {"text": "For instance, product pages on Amazon prominently display the distribution of numerical scores across reCoherent property cluster", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section, we describe in detail our data set and present three experiments and their results.", "labels": [], "entities": []}, {"text": "Data Set Our data set consists of snippets from Yelp reviews generated by the system described in.", "labels": [], "entities": []}, {"text": "This system is trained to extract snippets containing short descriptions of user sentiment towards some aspect of a restaurant.", "labels": [], "entities": []}, {"text": "select only the snippets labeled by that system as referencing food, and we ignore restaurants with fewer than 20 snippets.", "labels": [], "entities": []}, {"text": "There are 13,879 snippets in total, taken from 328 restaurants in and around the Boston/Cambridge area.", "labels": [], "entities": [{"text": "Boston/Cambridge area", "start_pos": 81, "end_pos": 102, "type": "DATASET", "confidence": 0.8761522024869919}]}, {"text": "The average snippet length is 7.8 words, and there are an average of 42.1 snippets per restaurant, although there is high variance in number of snippets for each restaurant.", "labels": [], "entities": []}, {"text": "For sentiment attribute seed words, we use 42 and 33 words for the positive and negative distributions respectively.", "labels": [], "entities": []}, {"text": "These are hand-selected based on the restaurant review domain; therefore, they include domain-specific words such as delicious and gross.", "labels": [], "entities": []}, {"text": "Tasks We perform three experiments to evaluate our model's effectiveness.", "labels": [], "entities": []}, {"text": "First, a cluster prediction task is designed to test the quality of the learned property clusters.", "labels": [], "entities": [{"text": "cluster prediction task", "start_pos": 9, "end_pos": 32, "type": "TASK", "confidence": 0.785995235045751}]}, {"text": "Second, an attribute analysis task will evaluate the sentiment analysis portion of the model.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 53, "end_pos": 71, "type": "TASK", "confidence": 0.9383623898029327}]}, {"text": "Third, we present a task designed to test whether the system can correctly identify properties which have conflicting attributes, which tests both clustering and sentiment analysis.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 162, "end_pos": 180, "type": "TASK", "confidence": 0.899715393781662}]}], "tableCaptions": [{"text": " Table 2: Results using the MUC metric on the cluster  prediction task. Note that while the precision of the base- line is higher, the recall and overall F1 of our model out- weighs that. While MUC has a deficiency in that putting  everything into a single cluster will artificially inflate the  score, parameters on our model are set so that the model  uses the same number of clusters as the baseline system.", "labels": [], "entities": [{"text": "cluster  prediction task", "start_pos": 46, "end_pos": 70, "type": "TASK", "confidence": 0.8365488648414612}, {"text": "precision", "start_pos": 92, "end_pos": 101, "type": "METRIC", "confidence": 0.9994028806686401}, {"text": "recall", "start_pos": 135, "end_pos": 141, "type": "METRIC", "confidence": 0.9997479319572449}, {"text": "F1", "start_pos": 154, "end_pos": 156, "type": "METRIC", "confidence": 0.9958305954933167}, {"text": "MUC", "start_pos": 194, "end_pos": 197, "type": "DATASET", "confidence": 0.6546675562858582}]}, {"text": " Table 7: Results of conflict analysis by correctness of  property label (P) and attribute conflict (A). Examples  of each type of correctness pair are show in in", "labels": [], "entities": [{"text": "attribute conflict (A)", "start_pos": 81, "end_pos": 103, "type": "METRIC", "confidence": 0.6526569724082947}]}, {"text": " Table 6.  50% of the clusters are correct in both labels, and there  are approximately the same number of errors toward both  property and attribute.", "labels": [], "entities": []}]}