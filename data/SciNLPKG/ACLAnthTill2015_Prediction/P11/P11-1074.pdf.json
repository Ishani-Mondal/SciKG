{"title": [{"text": "N-Best Rescoring Based on Pitch-accent Patterns", "labels": [], "entities": []}], "abstractContent": [{"text": "In this paper, we adopt an n-best rescoring scheme using pitch-accent patterns to improve automatic speech recognition (ASR) performance.", "labels": [], "entities": [{"text": "automatic speech recognition (ASR)", "start_pos": 90, "end_pos": 124, "type": "TASK", "confidence": 0.7720207025607427}]}, {"text": "The pitch-accent model is decoupled from the main ASR system, thus allowing us to develop it independently.", "labels": [], "entities": [{"text": "ASR", "start_pos": 50, "end_pos": 53, "type": "TASK", "confidence": 0.8042613863945007}]}, {"text": "N-best hypotheses from recognizers are rescored by additional scores that measure the correlation of the pitch-accent patterns between the acoustic signal and lexical cues.", "labels": [], "entities": []}, {"text": "To test the robustness of our algorithm, we use two different data sets and recognition setups: the first one is En-glish radio news data that has pitch accent labels , but the recognizer is trained from a small amount of data and has high error rate; the second one is English broadcast news data using a state-of-the-art SRI recognizer.", "labels": [], "entities": [{"text": "error rate", "start_pos": 240, "end_pos": 250, "type": "METRIC", "confidence": 0.9527933299541473}]}, {"text": "Our experimental results demonstrate that our approach is able to reduce word error rate relatively by about 3%.", "labels": [], "entities": [{"text": "word error rate", "start_pos": 73, "end_pos": 88, "type": "METRIC", "confidence": 0.6281155943870544}]}, {"text": "This gain is consistent across the two different tests, showing promising future directions of incorporating prosodic information to improve speech recognition.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 141, "end_pos": 159, "type": "TASK", "confidence": 0.8266166746616364}]}], "introductionContent": [{"text": "Prosody refers to the suprasegmental features of natural speech, such as rhythm and intonation, since it normally extends over more than one phoneme segment.", "labels": [], "entities": []}, {"text": "Speakers use prosody to convey paralinguistic information such as emphasis, intention, attitude, and emotion.", "labels": [], "entities": []}, {"text": "Humans listening to speech with natural prosody are able to understand the content with low cognitive load and high accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 116, "end_pos": 124, "type": "METRIC", "confidence": 0.9970705509185791}]}, {"text": "However, most modern ASR systems only use an acoustic model and a language model.", "labels": [], "entities": [{"text": "ASR", "start_pos": 21, "end_pos": 24, "type": "TASK", "confidence": 0.9899808764457703}]}, {"text": "Acoustic information in ASR is represented by spectral features that are usually extracted over a window length of a few tens of milliseconds.", "labels": [], "entities": [{"text": "ASR", "start_pos": 24, "end_pos": 27, "type": "TASK", "confidence": 0.9827661514282227}]}, {"text": "They miss useful information contained in the prosody of the speech that may help recognition.", "labels": [], "entities": [{"text": "recognition", "start_pos": 82, "end_pos": 93, "type": "TASK", "confidence": 0.9737051129341125}]}, {"text": "Recently a lot of research has been done in automatic annotation of prosodic events.", "labels": [], "entities": []}, {"text": "They used acoustic and lexical-syntactic cues to annotate prosodic events with a variety of machine learning approaches and achieved good performance.", "labels": [], "entities": []}, {"text": "There are also many studies using prosodic information for various spoken language understanding tasks.", "labels": [], "entities": [{"text": "spoken language understanding", "start_pos": 67, "end_pos": 96, "type": "TASK", "confidence": 0.7825135588645935}]}, {"text": "However, research using prosodic knowledge for speech recognition is still quite limited.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 47, "end_pos": 65, "type": "TASK", "confidence": 0.9155037999153137}]}, {"text": "In this study, we investigate leveraging prosodic information for recognition in an n-best rescoring framework.", "labels": [], "entities": []}, {"text": "Previous studies showed that prosodic events, such as pitch-accent, are closely related with acoustic prosodic cues and lexical structure of utterance.", "labels": [], "entities": []}, {"text": "The pitch-accent pattern given acoustic signal is strongly correlated with lexical items, such as syllable identity and canonical stress pattern.", "labels": [], "entities": []}, {"text": "Therefore as a first study, we focus on pitch-accent in this paper.", "labels": [], "entities": []}, {"text": "We develop two separate pitch-accent detection models, using acoustic (observation model) and lexical information (expectation model) respectively, and propose a scoring method for the correlation of pitch-accent patterns between the two models for recognition hypotheses.", "labels": [], "entities": [{"text": "pitch-accent detection", "start_pos": 24, "end_pos": 46, "type": "TASK", "confidence": 0.7225582003593445}]}, {"text": "The n-best list is rescored using the pitch-accent matching scores combined with the other scores from the ASR system (acoustic and language model scores).", "labels": [], "entities": []}, {"text": "We show that our method yields a word error rate (WER) reduction of about 3.64% and 2.07% relatively on two baseline ASR systems, one being a state-of-the-art recognizer for the broadcast news domain.", "labels": [], "entities": [{"text": "word error rate (WER) reduction", "start_pos": 33, "end_pos": 64, "type": "METRIC", "confidence": 0.9125425304685321}, {"text": "ASR", "start_pos": 117, "end_pos": 120, "type": "TASK", "confidence": 0.9560151100158691}]}, {"text": "The fact that it holds across different baseline systems suggests the possibility that prosody can be used to help improve speech recognition performance.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 123, "end_pos": 141, "type": "TASK", "confidence": 0.8321130275726318}]}, {"text": "The remainder of this paper is organized as follows.", "labels": [], "entities": []}, {"text": "In the next section, we review previous work briefly.", "labels": [], "entities": []}, {"text": "Section 3 explains the models and features for pitch-accent detection.", "labels": [], "entities": [{"text": "pitch-accent detection", "start_pos": 47, "end_pos": 69, "type": "TASK", "confidence": 0.673741340637207}]}, {"text": "We provide details of our n-best rescoring approach in Section 4.", "labels": [], "entities": []}, {"text": "Section 5 describes our corpus and baseline ASR setup.", "labels": [], "entities": [{"text": "ASR", "start_pos": 44, "end_pos": 47, "type": "TASK", "confidence": 0.984919548034668}]}, {"text": "Section 6 presents our experiments and results.", "labels": [], "entities": []}, {"text": "The last section gives a brief summary along with future directions.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Pitch accent detection results: performance of  individual acoustic and lexical models, and the agreement  between the two models (i.e., prosody score for a syllable,  Equation 3) for positive and negative classes. Also shown  is the reference result for pitch accent detection from Jeon  and Liu (2009).", "labels": [], "entities": [{"text": "Pitch accent detection", "start_pos": 10, "end_pos": 32, "type": "TASK", "confidence": 0.7865286469459534}, {"text": "pitch accent detection", "start_pos": 265, "end_pos": 287, "type": "TASK", "confidence": 0.7584405144055685}]}, {"text": " Table 4: Examples of rescoring results. Binary expressions inside the parenthesis below a word represent pitch-accent  markers for the syllables in the word.", "labels": [], "entities": []}]}