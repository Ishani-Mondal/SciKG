{"title": [{"text": "Beam-Width Prediction for Efficient Context-Free Parsing", "labels": [], "entities": [{"text": "Beam-Width Prediction", "start_pos": 0, "end_pos": 21, "type": "TASK", "confidence": 0.7680934965610504}]}], "abstractContent": [{"text": "Efficient decoding for syntactic parsing has become a necessary research area as statistical grammars grow inaccuracy and size and as more NLP applications leverage syntactic analyses.", "labels": [], "entities": [{"text": "syntactic parsing", "start_pos": 23, "end_pos": 40, "type": "TASK", "confidence": 0.8144194483757019}]}, {"text": "We review prior methods for pruning and then present anew framework that unifies their strengths into a single approach.", "labels": [], "entities": []}, {"text": "Using a log linear model, we learn the optimal beam-search pruning parameters for each CYK chart cell, effectively predicting the most promising areas of the model space to explore.", "labels": [], "entities": []}, {"text": "We demonstrate that our method is faster than coarse-to-fine pruning, exemplified in both the Charniak and Berkeley parsers, by empirically comparing our parser to the Berkeley parser using the same grammar and under identical operating conditions.", "labels": [], "entities": []}], "introductionContent": [{"text": "Statistical constituent parsers have gradually increased inaccuracy over the past ten years.", "labels": [], "entities": [{"text": "Statistical constituent parsers", "start_pos": 0, "end_pos": 31, "type": "TASK", "confidence": 0.607740730047226}]}, {"text": "This accuracy increase has opened the door to automatically derived syntactic information within a number of NLP tasks.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 5, "end_pos": 13, "type": "METRIC", "confidence": 0.9990836381912231}]}, {"text": "Prior work incorporating parse structure into machine translation and Semantic Role Labeling ( indicate that such hierarchical structure can have great benefit over shallow labeling techniques like chunking and part-of-speech tagging.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 46, "end_pos": 65, "type": "TASK", "confidence": 0.8046735525131226}, {"text": "Semantic Role Labeling", "start_pos": 70, "end_pos": 92, "type": "TASK", "confidence": 0.7874137759208679}, {"text": "part-of-speech tagging", "start_pos": 211, "end_pos": 233, "type": "TASK", "confidence": 0.7061294317245483}]}, {"text": "Although syntax is becoming increasingly important for large-scale NLP applications, constituent parsing is slow -too slow to scale to the size of many potential consumer applications.", "labels": [], "entities": [{"text": "constituent parsing", "start_pos": 85, "end_pos": 104, "type": "TASK", "confidence": 0.7829164862632751}]}, {"text": "The exhaustive CYK algorithm has computational complexity O(n 3 |G|) where n is the length of the sentence and |G| is the number of grammar productions, a nonnegligible constant.", "labels": [], "entities": [{"text": "O", "start_pos": 58, "end_pos": 59, "type": "METRIC", "confidence": 0.7122483253479004}]}, {"text": "Increases inaccuracy have primarily been accomplished through an increase in the size of the grammar, allowing individual grammar rules to be more sensitive to their surrounding context, at a considerable cost in efficiency.", "labels": [], "entities": []}, {"text": "Grammar transformation techniques such as linguistically inspired non-terminal annotations) and latent variable grammars () have increased the grammar size |G| from a few thousand rules to several million in an explicitly enumerable grammar, or even more in an implicit grammar.", "labels": [], "entities": [{"text": "Grammar transformation", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.6809938997030258}]}, {"text": "Exhaustive search for the maximum likelihood parse tree with a state-of-the-art grammar can require over a minute of processing fora single sentence of 25 words, an unacceptable amount of time for real-time applications or when processing millions of sentences.", "labels": [], "entities": []}, {"text": "Deterministic algorithms for dependency parsing exist that can extract syntactic dependency structure very quickly, but this approach is often undesirable as constituent parsers are more accurate and more adaptable to new domains (.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 29, "end_pos": 47, "type": "TASK", "confidence": 0.8170305490493774}]}, {"text": "The most accurate constituent parsers, e.g.,,, make use of approximate inference, limiting their search to a fraction of the total search space and achieving speeds of between one and four newspaper sentences per second.", "labels": [], "entities": []}, {"text": "The paradigm for building stateof-the-art parsing models is to first design a model structure that can achieve high accuracy and then, after the model has been built, design effective approximate inference methods around that particular model; e.g., coarse-to-fine non-terminal hierarchies fora given model, or agenda-based methods 440 that are empirically tuned to achieve acceptable efficiency/accuracy operating points.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 116, "end_pos": 124, "type": "METRIC", "confidence": 0.9927998781204224}, {"text": "accuracy", "start_pos": 396, "end_pos": 404, "type": "METRIC", "confidence": 0.9691813588142395}]}, {"text": "While both of the above mentioned papers use the CYK dynamic programming algorithm to search through possible solutions, their particular methods of approximate inference are quite distinct.", "labels": [], "entities": []}, {"text": "In this paper, we examine a general approach to approximate inference in constituent parsing that learns cell-specific thresholds for arbitrary grammars.", "labels": [], "entities": [{"text": "approximate inference in constituent parsing", "start_pos": 48, "end_pos": 92, "type": "TASK", "confidence": 0.6752543985843659}]}, {"text": "For each cell in the CYK chart, we sort all potential constituents in a local agenda, ordered by an estimate of their posterior probability.", "labels": [], "entities": [{"text": "CYK chart", "start_pos": 21, "end_pos": 30, "type": "DATASET", "confidence": 0.9491358995437622}]}, {"text": "Given features extracted from the chart cell context -e.g., span width; POS-tags and words surrounding the boundary of the cell -we train a log linear model to predict how many constituents should be popped from the local agenda and added to the chart.", "labels": [], "entities": []}, {"text": "As a special case of this approach, we simply predict whether the number to add should be zero or greater than zero, in which case the method can be seen as a cell-by-cell generalization of tagger-derived Chart Constraints.", "labels": [], "entities": []}, {"text": "More generally, instead of a binary classification decision, we can also use this method to predict the desired cell population directly and get cell closure for free when the classifier predicts a beam-width of zero.", "labels": [], "entities": []}, {"text": "In addition, we use a nonsymmetric loss function during optimization to account for the imbalance between over-predicting or under-predicting the beam-width.", "labels": [], "entities": []}, {"text": "A key feature of our approach is that it does not rely upon reference syntactic annotations when learning to search.", "labels": [], "entities": []}, {"text": "Rather, the beam-width prediction model is trained to learn the rank of constituents in the maximum likelihood trees.", "labels": [], "entities": [{"text": "beam-width prediction", "start_pos": 12, "end_pos": 33, "type": "TASK", "confidence": 0.7869604527950287}]}, {"text": "We will illustrate this by presenting results using a latent-variable grammar, for which there is no \"true\" reference latent variable parse.", "labels": [], "entities": []}, {"text": "We simply parse sections 2-21 of the WSJ treebank and train our search models from the output of these trees, with no prior knowledge of the non-terminal set or other grammar characteristics to guide the process.", "labels": [], "entities": [{"text": "WSJ treebank", "start_pos": 37, "end_pos": 49, "type": "DATASET", "confidence": 0.9798164069652557}]}, {"text": "Hence, this ap- proach is broadly applicable to a wide range of scenarios, including tuning the search to new domains where domain mismatch may yield very different efficiency/accuracy operating points.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 176, "end_pos": 184, "type": "METRIC", "confidence": 0.99409419298172}]}, {"text": "In the next section, we present prior work on approximate inference in parsing, and discuss how our method to learn optimal beam-search parameters unite many of their strengths into a single framework.", "labels": [], "entities": [{"text": "parsing", "start_pos": 71, "end_pos": 78, "type": "TASK", "confidence": 0.9144327044487}]}, {"text": "We then explore using our approach to open or close cells in the chart as an alternative to.", "labels": [], "entities": []}, {"text": "Finally, we present results which combine cell closure and adaptive beam-width prediction to achieve the most efficient parser.", "labels": [], "entities": [{"text": "cell closure", "start_pos": 42, "end_pos": 54, "type": "TASK", "confidence": 0.7005122601985931}, {"text": "beam-width prediction", "start_pos": 68, "end_pos": 89, "type": "TASK", "confidence": 0.6798242330551147}]}], "datasetContent": [{"text": "We run all experiments on the WSJ treebank) using the standard splits: section 2-21 for training, section 22 for development, and section 23 for testing.", "labels": [], "entities": [{"text": "WSJ treebank", "start_pos": 30, "end_pos": 42, "type": "DATASET", "confidence": 0.9832360446453094}]}, {"text": "We preprocess the treebank by removing empty nodes, temporal labels, and spurious unary productions (X\u2192X), as is standard in published works on syntactic parsing.", "labels": [], "entities": [{"text": "syntactic parsing", "start_pos": 144, "end_pos": 161, "type": "TASK", "confidence": 0.7900095880031586}]}, {"text": "The pruning methods we present in this paper can be used to parse with any grammar.", "labels": [], "entities": []}, {"text": "To achieve stateof-the-art accuracy levels, we parse with the Berkeley SM6 latent-variable grammar) where the original treebank non-terminals are automatically split into subclasses to optimize parsing accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 27, "end_pos": 35, "type": "METRIC", "confidence": 0.9957910776138306}, {"text": "accuracy", "start_pos": 202, "end_pos": 210, "type": "METRIC", "confidence": 0.7579569816589355}]}, {"text": "This is an explicit grammar consisting of 4.3 million productions, 2.4 million of which are lexical productions.", "labels": [], "entities": []}, {"text": "Exhaustive CYK parsing with the grammar takes more than a minute per sentence.", "labels": [], "entities": [{"text": "CYK parsing", "start_pos": 11, "end_pos": 22, "type": "TASK", "confidence": 0.7219544649124146}]}, {"text": "Accuracy is computed from the 1-best Viterbi (max) tree extracted from the chart.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 0, "end_pos": 8, "type": "METRIC", "confidence": 0.987781286239624}]}, {"text": "Alternative decoding methods, such as marginalizing over the latent variables in the grammar or MaxRule decoding (Petrov and Klein, 2007a) are certainly possible in our framework, but it is unknown how effective these methods will be given the heavily pruned nature of the chart.", "labels": [], "entities": []}, {"text": "We leave investigation of this to future work.", "labels": [], "entities": [{"text": "investigation", "start_pos": 9, "end_pos": 22, "type": "TASK", "confidence": 0.9622376561164856}]}, {"text": "We compute the precision and recall of constituents from the 1-best Viterbi trees using the standard EVALB script (?), which ignores punctuation and the root symbol.", "labels": [], "entities": [{"text": "precision", "start_pos": 15, "end_pos": 24, "type": "METRIC", "confidence": 0.9993144273757935}, {"text": "recall", "start_pos": 29, "end_pos": 35, "type": "METRIC", "confidence": 0.9974314570426941}]}, {"text": "Accuracy results are reported as F-measure (F 1 ), the harmonic mean between precision and recall.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 0, "end_pos": 8, "type": "METRIC", "confidence": 0.9820079803466797}, {"text": "F-measure (F 1 )", "start_pos": 33, "end_pos": 49, "type": "METRIC", "confidence": 0.8609495162963867}, {"text": "precision", "start_pos": 77, "end_pos": 86, "type": "METRIC", "confidence": 0.9957299828529358}, {"text": "recall", "start_pos": 91, "end_pos": 97, "type": "METRIC", "confidence": 0.9798539280891418}]}, {"text": "We ran all timing tests on an Intel 3.00GHz processor with 6MB of cache and 16GB of memory.", "labels": [], "entities": []}, {"text": "Our parser is written in Java and publicly available at http://nlp.csee.ogi.edu.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Section 22 development set results for CYK and", "labels": [], "entities": [{"text": "CYK", "start_pos": 49, "end_pos": 52, "type": "DATASET", "confidence": 0.9270176887512207}]}, {"text": " Table 2: Section 23 test set results for multiple parsers using", "labels": [], "entities": [{"text": "Section 23 test set", "start_pos": 10, "end_pos": 29, "type": "DATASET", "confidence": 0.881782591342926}]}]}