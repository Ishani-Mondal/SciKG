{"title": [{"text": "Exploiting Syntactico-Semantic Structures for Relation Extraction", "labels": [], "entities": [{"text": "Relation Extraction", "start_pos": 46, "end_pos": 65, "type": "TASK", "confidence": 0.953051894903183}]}], "abstractContent": [{"text": "In this paper, we observe that there exists a second dimension to the relation extraction (RE) problem that is orthogonal to the relation type dimension.", "labels": [], "entities": [{"text": "relation extraction (RE) problem", "start_pos": 70, "end_pos": 102, "type": "TASK", "confidence": 0.8479660799105962}]}, {"text": "We show that most of these second dimensional structures are relatively constrained and not difficult to identify.", "labels": [], "entities": []}, {"text": "We propose a novel algorithmic approach to RE that starts by first identifying these structures and then, within these, identifying the semantic type of the relation.", "labels": [], "entities": [{"text": "RE", "start_pos": 43, "end_pos": 45, "type": "TASK", "confidence": 0.9909063577651978}]}, {"text": "In the real RE problem where relation arguments need to be identified , exploiting these structures also allows reducing pipelined propagated errors.", "labels": [], "entities": []}, {"text": "We show that this RE framework provides significant improvement in RE performance.", "labels": [], "entities": [{"text": "RE", "start_pos": 67, "end_pos": 69, "type": "TASK", "confidence": 0.848452627658844}]}], "introductionContent": [{"text": "Relation extraction (RE) has been defined as the task of identifying a given set of semantic binary relations in text.", "labels": [], "entities": [{"text": "Relation extraction (RE)", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.9409198522567749}]}, {"text": "For instance, given the span of text \".", "labels": [], "entities": []}, {"text": "\", one would like to extract the relation that \"the Seattle zoo\" is located-at \"Seattle\".", "labels": [], "entities": []}, {"text": "RE has been frequently studied over the last few years as a supervised learning task, learning from spans of text that are annotated with a set of semantic relations of interest.", "labels": [], "entities": [{"text": "RE", "start_pos": 0, "end_pos": 2, "type": "TASK", "confidence": 0.9485984444618225}]}, {"text": "However, most approaches to RE have assumed that the relations' arguments are given as input (), and therefore offer only a partial solution to the problem.", "labels": [], "entities": [{"text": "RE", "start_pos": 28, "end_pos": 30, "type": "TASK", "confidence": 0.9918668866157532}]}, {"text": "Conceptually, this is a rather simple approach as all spans of texts are treated uniformly and are being mapped to one of several relation types of interest.", "labels": [], "entities": []}, {"text": "However, these approaches to RE require a large amount of manually annotated training data to achieve good performance, making it difficult to expand the set of target relations.", "labels": [], "entities": [{"text": "RE", "start_pos": 29, "end_pos": 31, "type": "TASK", "confidence": 0.995819091796875}]}, {"text": "Moreover, as we show, these approaches become brittle when the relations' arguments are not given but rather need to be identified in the data too.", "labels": [], "entities": []}, {"text": "In this paper we build on the observation that there exists a second dimension to the relation extraction problem that is orthogonal to the relation type dimension: all relation types are expressed in one of several constrained syntactico-semantic structures.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 86, "end_pos": 105, "type": "TASK", "confidence": 0.792232871055603}]}, {"text": "As we show, identifying where the text span is on the syntactico-semantic structure dimension first, can be leveraged in the RE process to yield improved performance.", "labels": [], "entities": [{"text": "RE", "start_pos": 125, "end_pos": 127, "type": "TASK", "confidence": 0.9407639503479004}]}, {"text": "Moreover, working in the second dimension provides robustness to the real RE problem, that of identifying arguments along with the relations between them.", "labels": [], "entities": []}, {"text": "For example, in \"the Seattle zoo\", the entity mention \"Seattle\" modifies the noun \"zoo\".", "labels": [], "entities": []}, {"text": "Thus, the two mentions \"Seattle\" and \"the Seattle zoo\", are involved in what we later calla premodifier relation, one of several syntactico-semantic structures we identify in Section 3.", "labels": [], "entities": []}, {"text": "We highlight that all relation types can be expressed in one of several syntactico-semantic structures -Premodifiers, Possessive, Preposition, Formulaic and Verbal.", "labels": [], "entities": []}, {"text": "As it turns out, most of these structures are relatively constrained and are not difficult to identify.", "labels": [], "entities": []}, {"text": "This suggests a novel algorithmic approach to RE that starts by first identifying these structures and then, within these, identifying the semantic type of the relation.", "labels": [], "entities": [{"text": "RE", "start_pos": 46, "end_pos": 48, "type": "TASK", "confidence": 0.992316722869873}]}, {"text": "Not only does this approach provide significantly improved RE perfor-mance, it carries with it two additional advantages.", "labels": [], "entities": [{"text": "RE", "start_pos": 59, "end_pos": 61, "type": "METRIC", "confidence": 0.876211404800415}]}, {"text": "First, leveraging the syntactico-semantic structure is especially beneficial in the presence of small amounts of data.", "labels": [], "entities": []}, {"text": "Second, and more important, is the fact that exploiting the syntactico-semantic dimension provides several new options for dealing with the full RE problem -incorporating the argument identification into the problem.", "labels": [], "entities": [{"text": "RE problem", "start_pos": 145, "end_pos": 155, "type": "TASK", "confidence": 0.9288508296012878}]}, {"text": "We explore one of these possibilities, making use of the constrained structures as away to aid in the identification of the relations' arguments.", "labels": [], "entities": []}, {"text": "We show that this already provides significant gain, and discuss other possibilities that can be explored.", "labels": [], "entities": []}, {"text": "The contributions of this paper are summarized below: \u2022 We highlight that all relation types are expressed as one of several syntactico-semantic structures and show that most of these are relatively constrained and not difficult to identify.", "labels": [], "entities": []}, {"text": "Consequently, working first in this structural dimension can be leveraged in the RE process to improve performance.", "labels": [], "entities": [{"text": "RE", "start_pos": 81, "end_pos": 83, "type": "TASK", "confidence": 0.9303444623947144}]}, {"text": "\u2022 We show that when one does not have a large number of training examples, exploiting the syntactico-semantic structures is crucial for RE performance.", "labels": [], "entities": [{"text": "RE", "start_pos": 136, "end_pos": 138, "type": "TASK", "confidence": 0.9762243628501892}]}, {"text": "\u2022 We show how to leverage these constrained structures to improve RE when the relations' arguments are not given.", "labels": [], "entities": [{"text": "RE", "start_pos": 66, "end_pos": 68, "type": "TASK", "confidence": 0.793759822845459}]}, {"text": "The constrained structures allow us to jointly entertain argument candidates and relations built with them as arguments.", "labels": [], "entities": []}, {"text": "Specifically, we show that considering argument candidates which otherwise would have been discarded (provided they exist in syntactico-semantic structures), we reduce error propagation along a standard pipeline RE architecture, and that this joint inference process leads to improved RE performance.", "labels": [], "entities": [{"text": "RE", "start_pos": 285, "end_pos": 287, "type": "TASK", "confidence": 0.8766623735427856}]}, {"text": "In the next section, we describe our relation extraction framework that leverages the syntacticosemantic structures.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 37, "end_pos": 56, "type": "TASK", "confidence": 0.8751273453235626}]}, {"text": "We then present these structures in Section 3.", "labels": [], "entities": []}, {"text": "We describe our mention entity typing system in Section 4 and features for the RE system in Section 5.", "labels": [], "entities": [{"text": "RE", "start_pos": 79, "end_pos": 81, "type": "TASK", "confidence": 0.5263317227363586}]}, {"text": "We present our RE experiments in Section 6 and perform analysis in Section 7, before concluding in Section 8.", "labels": [], "entities": [{"text": "RE", "start_pos": 15, "end_pos": 17, "type": "TASK", "confidence": 0.9087257385253906}]}, {"text": "Output: RE base and RE s", "labels": [], "entities": [{"text": "Output", "start_pos": 0, "end_pos": 6, "type": "METRIC", "confidence": 0.9660689830780029}, {"text": "RE base", "start_pos": 8, "end_pos": 15, "type": "METRIC", "confidence": 0.9742890298366547}, {"text": "RE", "start_pos": 20, "end_pos": 22, "type": "METRIC", "confidence": 0.9885523319244385}]}], "datasetContent": [{"text": "We use the ACE-2004 dataset (catalog LDC2005T09 from the Linguistic Data Consortium) to conduct our experiments.", "labels": [], "entities": [{"text": "ACE-2004 dataset (catalog LDC2005T09 from the Linguistic Data Consortium", "start_pos": 11, "end_pos": 83, "type": "DATASET", "confidence": 0.8898701369762421}]}, {"text": "Following prior work, we use the news wire (nwire) and broadcast news (bnews) corpora of ACE-2004 for our experiments, which consists of 345 documents.", "labels": [], "entities": [{"text": "ACE-2004", "start_pos": 89, "end_pos": 97, "type": "DATASET", "confidence": 0.7220046520233154}]}, {"text": "To build our RE system, we use the LIBLINEAR () package, with its default settings of L2-loss SVM (dual) as the solver, and we use an epsilon of 0.1.", "labels": [], "entities": [{"text": "RE", "start_pos": 13, "end_pos": 15, "type": "TASK", "confidence": 0.7613414525985718}, {"text": "LIBLINEAR", "start_pos": 35, "end_pos": 44, "type": "METRIC", "confidence": 0.958324670791626}, {"text": "solver", "start_pos": 112, "end_pos": 118, "type": "TASK", "confidence": 0.9314484596252441}]}, {"text": "To ensure that this baseline RE system based on the features in Section 5 is competitive, we compare against the state-of-the-art featurebased RE systems of and.", "labels": [], "entities": []}, {"text": "In these works, the authors reported performance on undirected coarsegrained RE.", "labels": [], "entities": []}, {"text": "Performing 5-fold cross validation on the nwire and bnews corpora, and reported F-measures of 71.5 and 71.2, respectively.", "labels": [], "entities": [{"text": "F-measures", "start_pos": 80, "end_pos": 90, "type": "METRIC", "confidence": 0.9992688298225403}]}, {"text": "Using the same evaluation setting, our baseline RE system achieves a competitive 71.4 F-measure.", "labels": [], "entities": [{"text": "RE", "start_pos": 48, "end_pos": 50, "type": "TASK", "confidence": 0.5849296450614929}, {"text": "F-measure", "start_pos": 86, "end_pos": 95, "type": "METRIC", "confidence": 0.8644668459892273}]}, {"text": "We build three RE classifiers: binary, coarse, fine.", "labels": [], "entities": [{"text": "RE classifiers", "start_pos": 15, "end_pos": 29, "type": "TASK", "confidence": 0.7543514966964722}]}, {"text": "Lumping all the predefined target relations into a single label, we build a binary classifier to predict whether any of the predefined relations exists between a given mention pair.", "labels": [], "entities": []}, {"text": "In this work, we model the argument order of the mentions when performing RE, since relations are usually asymmetric in nature.", "labels": [], "entities": [{"text": "RE", "start_pos": 74, "end_pos": 76, "type": "TASK", "confidence": 0.8428844809532166}]}, {"text": "For instance, we consider mi :EMP-ORG:m j and m j :EMP-ORG:m i to be distinct relation types.", "labels": [], "entities": []}, {"text": "In our experiments, we extracted a total of 55,520 examples or mention pairs.", "labels": [], "entities": []}, {"text": "Out of these, 4,011 are positive relation examples annotated with 6 coarse-grained relation types and 22 fine-grained relation types . We build a coarse-grained classifier to disambiguate between 13 relation labels (two asymmetric labels for each of the 6 coarse-grained relation types and a null label).", "labels": [], "entities": []}, {"text": "We similarly build a fine-grained classifier to disambiguate between 45 relation labels.", "labels": [], "entities": []}, {"text": "For our experiments, we adopt the experimental setting in our prior work of ensuring that all examples from a single document are either all used for training, or all used for evaluation.", "labels": [], "entities": []}, {"text": "In that work, we also highlight that ACE annotators rarely duplicate a relation link for coreferent mentions.", "labels": [], "entities": []}, {"text": "For instance, assume mentions mi , m j , and m k are in the same sentence, mentions mi and m j are coreferent, and the annotators tag the mention pair m j , m k with a particular relation r.", "labels": [], "entities": []}, {"text": "The annotators will rarely duplicate the same (implicit)    relation r between mi and m k , thus leaving the gold relation label as null.", "labels": [], "entities": []}, {"text": "Whether this is corrector not is debatable.", "labels": [], "entities": []}, {"text": "However, to avoid being penalized when our RE system actually correctly predicts the label of an implicit relation, we take the following approach.", "labels": [], "entities": []}, {"text": "During evaluation, if our system correctly predicts an implicit label, we simply switch its prediction to the null label.", "labels": [], "entities": []}, {"text": "Since the RE recall scores only take into account non-null relation labels, this scoring method does not change the recall, but could marginally increase the precision scores by decreasing the count of RE predictions.", "labels": [], "entities": [{"text": "RE recall", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.6017092168331146}, {"text": "recall", "start_pos": 116, "end_pos": 122, "type": "METRIC", "confidence": 0.9990808963775635}, {"text": "precision", "start_pos": 158, "end_pos": 167, "type": "METRIC", "confidence": 0.9987799525260925}]}, {"text": "In our experiments, we observe that both the usual and our scoring method give very similar RE results and the experimental trends remain the same.", "labels": [], "entities": [{"text": "RE", "start_pos": 92, "end_pos": 94, "type": "METRIC", "confidence": 0.9775271415710449}]}, {"text": "Of course, using this scoring method requires coreference information, which is available in the ACE data.", "labels": [], "entities": [{"text": "ACE data", "start_pos": 97, "end_pos": 105, "type": "DATASET", "confidence": 0.9801248013973236}]}, {"text": "To perform our experiments, we split the 345 documents into 5 equal sets.", "labels": [], "entities": []}, {"text": "In each of the 5 folds, 4 sets (276 documents) are reserved for drawing training examples, while the remaining set (69 documents) is used as evaluation data.", "labels": [], "entities": []}, {"text": "In the experiments described in this section, we use the gold mentions available in the data.", "labels": [], "entities": []}, {"text": "When one only has a small amount of training data, it is crucial to take advantage of external knowledge such as the syntactico-semantic structures.", "labels": [], "entities": []}, {"text": "To simulate this setting, in each fold, we randomly selected 10 documents from the fold's available training documents (about 3% of the total 345 documents) as training data.", "labels": [], "entities": []}, {"text": "We built one binary, one coarse-grained, and one fine-grained classifier for each fold.", "labels": [], "entities": []}, {"text": "In Section 2, we described how we trained a baseline RE classifier (RE base ) and a RE classifier using the syntactico-semantic patterns (RE s ).", "labels": [], "entities": []}, {"text": "We first apply RE base on each test example mention pair (m i ,m j ) to obtain the RE baseline results, showing these in under the column \"10 documents\", and in the rows \"Binary\", \"Coarse\", and \"Fine\".", "labels": [], "entities": [{"text": "RE base", "start_pos": 15, "end_pos": 22, "type": "METRIC", "confidence": 0.9553612470626831}, {"text": "RE", "start_pos": 83, "end_pos": 85, "type": "METRIC", "confidence": 0.9226648807525635}]}, {"text": "We then applied RE son the test examples as described in Section 2, showing the results in the rows \"Binary+Patterns\", \"Coarse+Patterns\", and \"Fine+Patterns\".", "labels": [], "entities": [{"text": "RE", "start_pos": 16, "end_pos": 18, "type": "METRIC", "confidence": 0.9841498732566833}]}, {"text": "The results show that by using syntactico-semantic structures, we obtain significant F-measure improvements of 8.3, 7.2, and 5.5 for binary, coarse-grained, and fine-grained relation predictions respectively.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 85, "end_pos": 94, "type": "METRIC", "confidence": 0.9538602828979492}]}, {"text": "Next, we perform our experiments using predicted mentions.", "labels": [], "entities": []}, {"text": "ACE-2004 defines 7 coarse-grained entity types, each of which are then refined into 43 fine- grained entity types.", "labels": [], "entities": [{"text": "ACE-2004", "start_pos": 0, "end_pos": 8, "type": "DATASET", "confidence": 0.9441084265708923}]}, {"text": "Using the ACE data annotated with mentions and predefined entity types, we build a fine-grained mention entity typing (MET) classifier to disambiguate between 44 labels (43 finegrained and a null label to indicate not a mention).", "labels": [], "entities": [{"text": "ACE data annotated", "start_pos": 10, "end_pos": 28, "type": "DATASET", "confidence": 0.937715490659078}]}, {"text": "To obtain the coarse-grained entity type predictions from the classifier, we simply check which coarsegrained type the fine-grained prediction belongs to.", "labels": [], "entities": []}, {"text": "We use the LIBLINEAR package with the same settings as earlier specified for the RE system.", "labels": [], "entities": [{"text": "LIBLINEAR", "start_pos": 11, "end_pos": 20, "type": "METRIC", "confidence": 0.9706986546516418}]}, {"text": "In each fold, we build a MET classifier using all the (276) training documents in that fold.", "labels": [], "entities": [{"text": "MET classifier", "start_pos": 25, "end_pos": 39, "type": "TASK", "confidence": 0.7814780175685883}]}, {"text": "We apply RE base on all mention pairs (m i ,m j ) where both mi and m j have non null entity type predictions.", "labels": [], "entities": [{"text": "RE base", "start_pos": 9, "end_pos": 16, "type": "METRIC", "confidence": 0.9789933264255524}]}, {"text": "We show these baseline results in the Rows \"Binary\", \"Coarse\", and \"Fine\" of.", "labels": [], "entities": [{"text": "Rows", "start_pos": 38, "end_pos": 42, "type": "METRIC", "confidence": 0.9889863729476929}]}, {"text": "In Section 2, we described our algorithmic approach () that takes advantage of the structures with predicted mentions.", "labels": [], "entities": []}, {"text": "We show the results of this approach in the Rows \"Binary+Patterns\", \"Coarse+Patterns\", and \"Fine+Patterns\" of.", "labels": [], "entities": [{"text": "Rows", "start_pos": 44, "end_pos": 48, "type": "METRIC", "confidence": 0.9578770995140076}]}, {"text": "The results show that by leveraging syntacticosemantic structures, we obtain significant F-measure improvements of 8.2, 4.6, and 3.6 for binary, coarsegrained, and fine-grained relation predictions respectively.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 89, "end_pos": 98, "type": "METRIC", "confidence": 0.9625813961029053}]}], "tableCaptions": [{"text": " Table 4: Micro-averaged (across the 5 folds) RE results using gold mentions.", "labels": [], "entities": [{"text": "RE", "start_pos": 46, "end_pos": 48, "type": "METRIC", "confidence": 0.5465667247772217}]}, {"text": " Table 5: Micro-averaged (across the 5 folds) RE results using predicted mentions.", "labels": [], "entities": [{"text": "RE", "start_pos": 46, "end_pos": 48, "type": "TASK", "confidence": 0.49408966302871704}]}, {"text": " Table 6: Recall and precision of the patterns.", "labels": [], "entities": [{"text": "Recall", "start_pos": 10, "end_pos": 16, "type": "METRIC", "confidence": 0.9917003512382507}, {"text": "precision", "start_pos": 21, "end_pos": 30, "type": "METRIC", "confidence": 0.9994115829467773}]}]}