{"title": [{"text": "Learning Sub-Word Units for Open Vocabulary Speech Recognition", "labels": [], "entities": [{"text": "Open Vocabulary Speech Recognition", "start_pos": 28, "end_pos": 62, "type": "TASK", "confidence": 0.5717780962586403}]}], "abstractContent": [{"text": "Large vocabulary speech recognition systems fail to recognize words beyond their vocabulary , many of which are information rich terms, like named entities or foreign words.", "labels": [], "entities": []}, {"text": "Hybrid word/sub-word systems solve this problem by adding sub-word units to large vocabulary word based systems; new words can then be represented by combinations of sub-word units.", "labels": [], "entities": []}, {"text": "Previous work heuristically created the sub-word lexicon from phonetic representations of text using simple statistics to select common phone sequences.", "labels": [], "entities": []}, {"text": "We propose a probabilistic model to learn the sub-word lexicon optimized fora given task.", "labels": [], "entities": []}, {"text": "We consider the task of out of vocabulary (OOV) word detection, which relies on output from a hybrid model.", "labels": [], "entities": [{"text": "out of vocabulary (OOV) word detection", "start_pos": 24, "end_pos": 62, "type": "TASK", "confidence": 0.638301782310009}]}, {"text": "A hybrid model with our learned sub-word lexicon reduces error by 6.3% and 7.6% (absolute) at a 5% false alarm rate on an English Broadcast News and MIT Lectures task respectively.", "labels": [], "entities": [{"text": "error", "start_pos": 57, "end_pos": 62, "type": "METRIC", "confidence": 0.9943110942840576}, {"text": "English Broadcast News and MIT Lectures task", "start_pos": 122, "end_pos": 166, "type": "DATASET", "confidence": 0.8675472140312195}]}], "introductionContent": [{"text": "Most automatic speech recognition systems operate with a large but limited vocabulary, finding the most likely words in the vocabulary for the given acoustic signal.", "labels": [], "entities": [{"text": "automatic speech recognition", "start_pos": 5, "end_pos": 33, "type": "TASK", "confidence": 0.6679084996382395}]}, {"text": "While large vocabulary continuous speech recognition (LVCSR) systems produce high quality transcripts, they fail to recognize out of vocabulary (OOV) words.", "labels": [], "entities": [{"text": "large vocabulary continuous speech recognition (LVCSR)", "start_pos": 6, "end_pos": 60, "type": "TASK", "confidence": 0.8009180277585983}]}, {"text": "Unfortunately, OOVs are often information rich nouns, such as named entities and foreign words, and mis-recognizing them can have a disproportionate impact on transcript coherence.", "labels": [], "entities": []}, {"text": "Hybrid word/sub-word recognizers can produce a sequence of sub-word units in place of OOV words.", "labels": [], "entities": []}, {"text": "Ideally, the recognizer outputs a complete word for in-vocabulary (IV) utterances, and sub-word units for OOVs.", "labels": [], "entities": []}, {"text": "Consider the word \"Slobodan\", the given name of the former president of Serbia.", "labels": [], "entities": []}, {"text": "As an uncommon English word, it is unlikely to be in the vocabulary of an English recognizer.", "labels": [], "entities": []}, {"text": "While a LVCSR system would output the closest known words (e.x.", "labels": [], "entities": []}, {"text": "\"slow it dawn\"), a hybrid system could output a sequence of multi-phoneme units: s low, b ax, d ae n.", "labels": [], "entities": []}, {"text": "The latter is more useful for automatically recovering the word's orthographic form, identifying that an OOV was spoken, or improving performance of a spoken term detection system with OOV queries.", "labels": [], "entities": [{"text": "automatically recovering the word's orthographic form", "start_pos": 30, "end_pos": 83, "type": "TASK", "confidence": 0.7212774668421064}]}, {"text": "In fact, hybrid systems have improved OOV spoken term detection (, achieved better phone error rates, especially in OOV regions (, and obtained state-of-the-art performance for OOV detection ().", "labels": [], "entities": [{"text": "OOV spoken term detection", "start_pos": 38, "end_pos": 63, "type": "TASK", "confidence": 0.8653932511806488}, {"text": "OOV detection", "start_pos": 177, "end_pos": 190, "type": "TASK", "confidence": 0.931527316570282}]}, {"text": "Hybrid recognizers vary in a number of ways: sub-word unit type: variable-length phoneme units ( or joint letter sound sub-words (); unit creation: data-driven or linguistically motivated; and how they are incorporated in LVCSR systems: hierarchical) or flat models).", "labels": [], "entities": []}, {"text": "In this work, we consider how to optimally create sub-word units fora hybrid system.", "labels": [], "entities": []}, {"text": "These units are variable-length phoneme sequences, although in principle our work can be use for other unit types.", "labels": [], "entities": []}, {"text": "Previous methods for creating the sub-word lexicon have relied on simple statistics computed from the phonetic representation of text ().", "labels": [], "entities": []}, {"text": "These units typically represent the most frequent phoneme sequences in English words.", "labels": [], "entities": []}, {"text": "However, it isn't clear why these units would produce the best hybrid output.", "labels": [], "entities": []}, {"text": "Instead, we introduce a probabilistic model for learning the optimal units fora given task.", "labels": [], "entities": []}, {"text": "Our model learns a segmentation of a text corpus given some side information: a mapping between the vocabulary and a label set; learned units are predictive of class labels.", "labels": [], "entities": []}, {"text": "In this paper, we learn sub-word units optimized for OOV detection.", "labels": [], "entities": [{"text": "OOV detection", "start_pos": 53, "end_pos": 66, "type": "TASK", "confidence": 0.9082596004009247}]}, {"text": "OOV detection aims to identify regions in the LVCSR output where OOVs were uttered.", "labels": [], "entities": [{"text": "OOV detection", "start_pos": 0, "end_pos": 13, "type": "TASK", "confidence": 0.8747551441192627}]}, {"text": "Towards this goal, we are interested in selecting units such that the recognizer outputs them only for OOV regions while prefering to output a complete word for in-vocabulary regions.", "labels": [], "entities": []}, {"text": "Our approach yields improvements over state-of-the-art results.", "labels": [], "entities": []}, {"text": "We begin by presenting our log-linear model for learning sub-word units with a simple but effective inference procedure.", "labels": [], "entities": []}, {"text": "After reviewing existing OOV detection approaches, we detail how the learned units are integrated into a hybrid speech recognition system.", "labels": [], "entities": [{"text": "OOV detection", "start_pos": 25, "end_pos": 38, "type": "TASK", "confidence": 0.9160297811031342}, {"text": "speech recognition", "start_pos": 112, "end_pos": 130, "type": "TASK", "confidence": 0.715674877166748}]}, {"text": "We show improvements in OOV detection, and evaluate impact on phone error rates.", "labels": [], "entities": [{"text": "OOV detection", "start_pos": 24, "end_pos": 37, "type": "TASK", "confidence": 0.8064872622489929}]}], "datasetContent": [{"text": "We used the data set constructed by to obtain a transcript of the audio.", "labels": [], "entities": []}, {"text": "Acoustic models were trained on 300 hours of HUB4 data ( and utterances containing OOV words as marked in OOVCORP were excluded.", "labels": [], "entities": [{"text": "HUB4 data", "start_pos": 45, "end_pos": 54, "type": "DATASET", "confidence": 0.7903155088424683}]}, {"text": "The language model was trained on 400M words from various text sources The IBM system used speaker adaptive training based on maximum likelihood with no discriminative training. with a 83K word vocabulary.", "labels": [], "entities": []}, {"text": "The LVCSR system's WER on the standard RT04 BN test set was 19.4%.", "labels": [], "entities": [{"text": "WER", "start_pos": 19, "end_pos": 22, "type": "METRIC", "confidence": 0.9996234178543091}, {"text": "RT04 BN test set", "start_pos": 39, "end_pos": 55, "type": "DATASET", "confidence": 0.947645977139473}]}, {"text": "Excluded utterances amount to 100hrs.", "labels": [], "entities": []}, {"text": "These were divided into 5 hours of training for the OOV detector and 95 hours of test.", "labels": [], "entities": [{"text": "OOV detector", "start_pos": 52, "end_pos": 64, "type": "TASK", "confidence": 0.7518633306026459}]}, {"text": "Note that the OOV detector training set is different from the LVCSR training set.", "labels": [], "entities": [{"text": "OOV detector", "start_pos": 14, "end_pos": 26, "type": "TASK", "confidence": 0.5534858405590057}, {"text": "LVCSR training set", "start_pos": 62, "end_pos": 80, "type": "DATASET", "confidence": 0.9260882139205933}]}, {"text": "We also use a hybrid LVCSR system, combining word and sub-word units obtained from either our approach or a state-of-the-art baseline approach () ( \u00a75.2).", "labels": [], "entities": []}, {"text": "Our hybrid system's lexicon has 83K words and 5K or 10K sub-words.", "labels": [], "entities": []}, {"text": "Note that the word vocabulary is common to both systems and only the sub-words are selected using either approach.", "labels": [], "entities": []}, {"text": "The word vocabulary used is close to most modern LVCSR system vocabularies for English Broadcast News; the resulting OOVs are more challenging but more realistic (i.e. mostly named entities and technical terms).", "labels": [], "entities": [{"text": "LVCSR system vocabularies for English Broadcast News", "start_pos": 49, "end_pos": 101, "type": "DATASET", "confidence": 0.710889492716108}]}, {"text": "The 1290 words are OOVs to both the word and hybrid systems.", "labels": [], "entities": [{"text": "OOVs", "start_pos": 19, "end_pos": 23, "type": "METRIC", "confidence": 0.7628118395805359}]}, {"text": "In addition we report OOV detection results on a MIT lectures data set () consisting of 3 Hrs from two speakers with a 1.5% OOV rate.", "labels": [], "entities": [{"text": "OOV detection", "start_pos": 22, "end_pos": 35, "type": "TASK", "confidence": 0.8654945492744446}, {"text": "MIT lectures data set", "start_pos": 49, "end_pos": 70, "type": "DATASET", "confidence": 0.9460740089416504}, {"text": "OOV rate", "start_pos": 124, "end_pos": 132, "type": "METRIC", "confidence": 0.9817199110984802}]}, {"text": "These were divided into 1 Hr for training the OOV detector and 2 Hrs for testing.", "labels": [], "entities": [{"text": "OOV detector", "start_pos": 46, "end_pos": 58, "type": "TASK", "confidence": 0.5092816650867462}]}, {"text": "Note that the LVCSR system is trained on Broadcast News data.", "labels": [], "entities": [{"text": "LVCSR", "start_pos": 14, "end_pos": 19, "type": "DATASET", "confidence": 0.8795862793922424}, {"text": "Broadcast News data", "start_pos": 41, "end_pos": 60, "type": "DATASET", "confidence": 0.9577347040176392}]}, {"text": "This outof-domain test-set help us evaluate the cross-domain performance of the proposed and baseline hybrid systems.", "labels": [], "entities": []}, {"text": "OOVs in this data set correspond mainly to technical terms in computer science and math.", "labels": [], "entities": [{"text": "OOVs in this data set", "start_pos": 0, "end_pos": 21, "type": "DATASET", "confidence": 0.7794387817382813}]}, {"text": "e.g. ALGORITHM, DEBUG, COMPILER, LISP.", "labels": [], "entities": [{"text": "ALGORITHM", "start_pos": 5, "end_pos": 14, "type": "METRIC", "confidence": 0.9657484889030457}, {"text": "DEBUG", "start_pos": 16, "end_pos": 21, "type": "METRIC", "confidence": 0.872570276260376}, {"text": "COMPILER", "start_pos": 23, "end_pos": 31, "type": "METRIC", "confidence": 0.7788594365119934}, {"text": "LISP", "start_pos": 33, "end_pos": 37, "type": "METRIC", "confidence": 0.9730585217475891}]}, {"text": "We obtain confusion networks from both the word and hybrid LVCSR systems.", "labels": [], "entities": []}, {"text": "We align the LVCSR transcripts with the reference transcripts and tag each confusion region as either IV or OOV.", "labels": [], "entities": [{"text": "IV", "start_pos": 102, "end_pos": 104, "type": "METRIC", "confidence": 0.9547380208969116}, {"text": "OOV", "start_pos": 108, "end_pos": 111, "type": "METRIC", "confidence": 0.6548073291778564}]}, {"text": "The OOV detector classifies each region in the confusion network as IV/OOV.", "labels": [], "entities": [{"text": "OOV", "start_pos": 4, "end_pos": 7, "type": "METRIC", "confidence": 0.8506117463111877}]}, {"text": "We report OOV detection accuracy using standard detection error tradeoff (DET) curves ().", "labels": [], "entities": [{"text": "OOV detection", "start_pos": 10, "end_pos": 23, "type": "TASK", "confidence": 0.8413816392421722}, {"text": "accuracy", "start_pos": 24, "end_pos": 32, "type": "METRIC", "confidence": 0.9384313821792603}, {"text": "standard detection error tradeoff (DET)", "start_pos": 39, "end_pos": 78, "type": "METRIC", "confidence": 0.8039551036698478}]}, {"text": "DET curves measure tradeoffs between false alarms (x-axis) and misses (y-axis), and are useful for determining the optimal operating point for an application; lower curves are better.", "labels": [], "entities": []}, {"text": "Following we separately evaluate unobserved OOVs.", "labels": [], "entities": []}, {"text": "8 In this work we ignore pronunciation variability and simply consider the most likely pronunciation for each word.", "labels": [], "entities": []}, {"text": "It is straightforward to extend to multiple pronunciations by first sampling a pronunciation for each word and then sampling a segmentation for that pronunciation.", "labels": [], "entities": []}, {"text": "8 Once an OOV word has been observed in the OOV detector training data, even if it was not in the LVCSR training data, it is no longer truly OOV.", "labels": [], "entities": [{"text": "OOV detector training data", "start_pos": 44, "end_pos": 70, "type": "DATASET", "confidence": 0.6818628311157227}, {"text": "LVCSR training data", "start_pos": 98, "end_pos": 117, "type": "DATASET", "confidence": 0.931723395983378}]}], "tableCaptions": [{"text": " Table 1: Coverage of OOV regions by baseline and pro- posed sub-words in OOVCORP.", "labels": [], "entities": [{"text": "OOVCORP", "start_pos": 74, "end_pos": 81, "type": "DATASET", "confidence": 0.8454818725585938}]}, {"text": " Table 2: Phone Error Rate for OOVCORP.", "labels": [], "entities": [{"text": "Phone Error Rate", "start_pos": 10, "end_pos": 26, "type": "METRIC", "confidence": 0.7022361358006796}]}]}