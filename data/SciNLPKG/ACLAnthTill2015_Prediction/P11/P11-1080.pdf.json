{"title": [{"text": "Large-Scale Cross-Document Coreference Using Distributed Inference and Hierarchical Models", "labels": [], "entities": []}], "abstractContent": [{"text": "Cross-document coreference, the task of grouping all the mentions of each entity in a document collection, arises in information extraction and automated knowledge base construction.", "labels": [], "entities": [{"text": "Cross-document coreference", "start_pos": 0, "end_pos": 26, "type": "TASK", "confidence": 0.7789088487625122}, {"text": "information extraction", "start_pos": 117, "end_pos": 139, "type": "TASK", "confidence": 0.7839540243148804}, {"text": "knowledge base construction", "start_pos": 154, "end_pos": 181, "type": "TASK", "confidence": 0.6639927327632904}]}, {"text": "For large collections, it is clearly impractical to consider all possible groupings of mentions into distinct entities.", "labels": [], "entities": []}, {"text": "To solve the problem we propose two ideas: (a) a distributed inference technique that uses paral-lelism to enable large scale processing, and (b) a hierarchical model of coreference that represents uncertainty over multiple granular-ities of entities to facilitate more effective approximate inference.", "labels": [], "entities": []}, {"text": "To evaluate these ideas, we constructed a labeled corpus of 1.5 million disambiguated mentions in Web pages by selecting link anchors referring to Wikipedia entities.", "labels": [], "entities": []}, {"text": "We show that the combination of the hierarchical model with distributed inference quickly obtains high accuracy (with error reduction of 38%) on this large dataset, demonstrating the scalability of our approach.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 103, "end_pos": 111, "type": "METRIC", "confidence": 0.999242901802063}, {"text": "error reduction", "start_pos": 118, "end_pos": 133, "type": "METRIC", "confidence": 0.9755561351776123}]}], "introductionContent": [{"text": "Given a collection of mentions of entities extracted from a body of text, coreference or entity resolution consists of clustering the mentions such that two mentions belong to the same cluster if and only if they refer to the same entity.", "labels": [], "entities": [{"text": "entity resolution", "start_pos": 89, "end_pos": 106, "type": "TASK", "confidence": 0.6875404119491577}]}, {"text": "Solutions to this problem are important in semantic analysis and knowledge discovery tasks.", "labels": [], "entities": [{"text": "semantic analysis", "start_pos": 43, "end_pos": 60, "type": "TASK", "confidence": 0.9522631764411926}, {"text": "knowledge discovery tasks", "start_pos": 65, "end_pos": 90, "type": "TASK", "confidence": 0.8515239159266154}]}, {"text": "While significant progress has been made in within-document coreference, the larger problem of cross-document coreference has not received as much attention.", "labels": [], "entities": [{"text": "cross-document coreference", "start_pos": 95, "end_pos": 121, "type": "TASK", "confidence": 0.7406753599643707}]}, {"text": "Unlike inference in other language processing tasks that scales linearly in the size of the corpus, the hypothesis space for coreference grows superexponentially with the number of mentions.", "labels": [], "entities": []}, {"text": "Consequently, most of the current approaches are developed on small datasets containing a few thousand mentions.", "labels": [], "entities": []}, {"text": "We believe that cross-document coreference resolution is most useful when applied to a very large set of documents, such as all the news articles published during the last 20 years.", "labels": [], "entities": [{"text": "cross-document coreference resolution", "start_pos": 16, "end_pos": 53, "type": "TASK", "confidence": 0.7869577209154764}]}, {"text": "Such a corpus would have billions of mentions.", "labels": [], "entities": []}, {"text": "In this paper we propose a model and inference algorithms that can scale the cross-document coreference problem to corpora of that size.", "labels": [], "entities": [{"text": "cross-document coreference problem", "start_pos": 77, "end_pos": 111, "type": "TASK", "confidence": 0.7755867838859558}]}, {"text": "Much of the previous work in cross-document coreference () groups mentions into entities with some form of greedy clustering using a pairwise mention similarity or distance function based on mention text, context, and document-level statistics.", "labels": [], "entities": []}, {"text": "Such methods have not been shown to scale up, and they cannot exploit cluster features that cannot be expressed in terms of mention pairs.", "labels": [], "entities": []}, {"text": "We provide a detailed survey of related work in Section 6.", "labels": [], "entities": []}, {"text": "Other previous work attempts to address some of the above concerns by mapping coreference to inference on an undirected graphical model ().", "labels": [], "entities": []}, {"text": "These models contain pairwise factors between all pairs of mentions capturing similarity between them.", "labels": [], "entities": []}, {"text": "Many of these models also enforce transitivity and enable features over entities by including set-valued variables.", "labels": [], "entities": []}, {"text": "Exact inference in these models is intractable and a number of approximate inference schemes) maybe used.", "labels": [], "entities": []}, {"text": "In particular, Markov chain Monte Carlo (MCMC) based inference has been found to work well in practice.", "labels": [], "entities": []}, {"text": "However as the number of mentions grows to Web scale, as in our problem of crossdocument coreference, even these inference techniques become infeasible, motivating the need fora scalable, parallelizable solution.", "labels": [], "entities": []}, {"text": "In this work we first distribute MCMC-based inference for the graphical model representation of coreference.", "labels": [], "entities": []}, {"text": "Entities are distributed across the machines such that the parallel MCMC chains on the different machines use only local proposal distributions.", "labels": [], "entities": []}, {"text": "After a fixed number of samples on each machine, we redistribute the entities among machines to enable proposals across entities that were previously on different machines.", "labels": [], "entities": []}, {"text": "In comparison to the greedy approaches used in related work, our MCMC-based inference provides better robustness properties.", "labels": [], "entities": []}, {"text": "As the number of mentions becomes large, highquality samples for MCMC become scarce.", "labels": [], "entities": []}, {"text": "To facilitate better proposals, we present a hierarchical model.", "labels": [], "entities": []}, {"text": "We add sub-entity variables that represent clusters of similar mentions that are likely to be coreferent; these are used to propose composite jumps that move multiple mentions together.", "labels": [], "entities": []}, {"text": "We also introduce super-entity variables that represent clusters of similar entities; these are used to distribute entities among the machines such that similar entities are assigned to the same machine.", "labels": [], "entities": []}, {"text": "These additional levels of hierarchy dramatically increase the probability of beneficial proposals even with a large number of entities and mentions.", "labels": [], "entities": []}, {"text": "To create a large corpus for evaluation, we identify pages that have hyperlinks to Wikipedia, and extract the anchor text and the context around the link.", "labels": [], "entities": []}, {"text": "We treat the anchor text as the mention, the context as the document, and the title of the Wikipedia page as the entity label.", "labels": [], "entities": []}, {"text": "Using this approach, 1.5 million mentions were annotated with 43k entity labels.", "labels": [], "entities": []}, {"text": "On this dataset, our proposed model yields a B 3 (Bagga and Baldwin, 1998) F1 score of 73.7%, improving over the baseline by 16% absolute (corresponding to 38% error reduction).", "labels": [], "entities": [{"text": "B 3 (Bagga and Baldwin, 1998) F1 score", "start_pos": 45, "end_pos": 83, "type": "METRIC", "confidence": 0.7427288022908297}, {"text": "error reduction", "start_pos": 160, "end_pos": 175, "type": "METRIC", "confidence": 0.9736975133419037}]}, {"text": "Our experimental results also show that our proposed hierarchical model converges much faster even though it contains many more variables.", "labels": [], "entities": []}], "datasetContent": [{"text": "We evaluate our models and algorithms on a number of datasets.", "labels": [], "entities": []}, {"text": "First, we compare performance on the small, publicly-available \"John Smith\" dataset.", "labels": [], "entities": [{"text": "John Smith\" dataset", "start_pos": 64, "end_pos": 83, "type": "DATASET", "confidence": 0.9680299013853073}]}, {"text": "Second, we run the automated Person-X evaluation to obtain thousands of mentions that we use to demonstrate accuracy and scalability improvements.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 108, "end_pos": 116, "type": "METRIC", "confidence": 0.998660683631897}]}, {"text": "Most importantly, we create a large labeled corpus using links to Wikipedia to explore the performance in the large-scale setting.", "labels": [], "entities": []}, {"text": "There is a severe lack of labeled corpora for crossdocument coreference due to the effort required to evaluate the coreference decisions.", "labels": [], "entities": []}, {"text": "Related approaches have used automated Person-X evaluation (), in which unique person-name strings are treated as the true entity labels for the mentions.", "labels": [], "entities": []}, {"text": "Every mention string is replaced with an \"X\" for the coreference system.", "labels": [], "entities": []}, {"text": "We use this evaluation methodology on 25k personname mentions from the New York Times corpus each with one of 50 unique strings.", "labels": [], "entities": [{"text": "New York Times corpus", "start_pos": 71, "end_pos": 92, "type": "DATASET", "confidence": 0.7210060060024261}]}, {"text": "As before, we set the bias b to achieve the same number of entities.", "labels": [], "entities": []}, {"text": "We use 1 million samples in each round of inference, followed by random redistribution in the flat model, and super-entities in the hierarchical model.", "labels": [], "entities": []}, {"text": "Results are averaged over five runs.: Wikipedia Link Corpus Statistics.", "labels": [], "entities": [{"text": "Wikipedia Link Corpus Statistics", "start_pos": 38, "end_pos": 70, "type": "DATASET", "confidence": 0.9676425158977509}]}, {"text": "Size of an entity is the number of mentions of that entity.", "labels": [], "entities": []}, {"text": "shows accuracy compared to relative wallclock running time for distributed inference on the flat, pairwise model.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 6, "end_pos": 14, "type": "METRIC", "confidence": 0.9996871948242188}]}, {"text": "Speed and accuracy improve as additional machines are added, but larger number of machines lead to diminishing returns for this small dataset.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9994014501571655}]}, {"text": "Distributed inference on our hierarchical model is evaluated in against inference on the pairwise model from.", "labels": [], "entities": []}, {"text": "We see that the individual hierarchical models perform much better than the pairwise model; they achieve the same accuracy as the pairwise model in approximately 10% of the time.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 114, "end_pos": 122, "type": "METRIC", "confidence": 0.9991140961647034}]}, {"text": "Moreover, distributed inference on the combined hierarchical model is both faster and more accurate than the individual hierarchical models.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: F1 Scores on the Wikipedia Link Data.  The results are significant at the 0.0001 level over  Subsquare according to the difference of proportions  significance test.", "labels": [], "entities": [{"text": "F1 Scores", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9811939597129822}, {"text": "Wikipedia Link Data", "start_pos": 27, "end_pos": 46, "type": "DATASET", "confidence": 0.9592898686726888}, {"text": "Subsquare", "start_pos": 103, "end_pos": 112, "type": "DATASET", "confidence": 0.9275748133659363}, {"text": "difference of proportions  significance test", "start_pos": 130, "end_pos": 174, "type": "METRIC", "confidence": 0.7669109582901001}]}]}