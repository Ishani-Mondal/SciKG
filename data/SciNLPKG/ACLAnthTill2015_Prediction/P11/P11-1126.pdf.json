{"title": [{"text": "Hypothesis Mixture Decoding for Statistical Machine Translation", "labels": [], "entities": [{"text": "Hypothesis Mixture Decoding", "start_pos": 0, "end_pos": 27, "type": "TASK", "confidence": 0.817948579788208}, {"text": "Statistical Machine Translation", "start_pos": 32, "end_pos": 63, "type": "TASK", "confidence": 0.8488050500551859}]}], "abstractContent": [{"text": "This paper presents hypothesis mixture decoding (HM decoding), anew decoding scheme that performs translation reconstruction using hypotheses generated by multiple translation systems.", "labels": [], "entities": [{"text": "hypothesis mixture decoding (HM decoding)", "start_pos": 20, "end_pos": 61, "type": "TASK", "confidence": 0.720928532736642}, {"text": "translation reconstruction", "start_pos": 98, "end_pos": 124, "type": "TASK", "confidence": 0.9685936868190765}]}, {"text": "HM decoding involves two decoding stages: first, each component system decodes independently , with the explored search space kept for use in the next step; second, anew search space is constructed by composing existing hypotheses produced by all component systems using a set of rules provided by the HM decoder itself, and anew set of model independent features are used to seek the final best translation from this new search space.", "labels": [], "entities": []}, {"text": "Few assumptions are made by our approach about the underlying component systems, enabling us to leverage SMT models based on arbitrary paradigms.", "labels": [], "entities": [{"text": "SMT", "start_pos": 105, "end_pos": 108, "type": "TASK", "confidence": 0.9947618842124939}]}, {"text": "We compare our approach with several related techniques, and demonstrate significant BLEU improvements in large-scale Chinese-to-English translation tasks.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 85, "end_pos": 89, "type": "METRIC", "confidence": 0.9980506896972656}, {"text": "Chinese-to-English translation tasks", "start_pos": 118, "end_pos": 154, "type": "TASK", "confidence": 0.7424336075782776}]}], "introductionContent": [{"text": "Besides tremendous efforts on constructing more complicated and accurate models for statistical machine translation (SMT) (), many researchers have concentrated on the approaches that improve translation quality using information between hypotheses from one or more SMT systems as well.", "labels": [], "entities": [{"text": "statistical machine translation (SMT)", "start_pos": 84, "end_pos": 121, "type": "TASK", "confidence": 0.8056070854266485}, {"text": "SMT", "start_pos": 266, "end_pos": 269, "type": "TASK", "confidence": 0.94687819480896}]}, {"text": "System combination is built on top of the N-best outputs generated by multiple component systems () which aligns multiple hypotheses to build confusion networks as new search spaces, and outputs the highest scoring paths as the final translations.", "labels": [], "entities": []}, {"text": "Consensus decoding, on the other hand, can be based on either single or multiple systems: single system based methods () re-rank translations produced by a single SMT model using either n-gram posteriors or expected n-gram counts.", "labels": [], "entities": [{"text": "SMT", "start_pos": 163, "end_pos": 166, "type": "TASK", "confidence": 0.9645527005195618}]}, {"text": "Because hypotheses generated by a single model are highly correlated, improvements obtained are usually small; recently, dedicated efforts have been made to extend it from single system to multiple systems (.", "labels": [], "entities": []}, {"text": "Such methods select translations by optimizing consensus models over the combined hypotheses using all component systems' posterior distributions.", "labels": [], "entities": []}, {"text": "Although these two types of approaches have shown consistent improvements over the standard Maximum a Posteriori (MAP) decoding scheme, most of them are implemented as post-processing procedures over translations generated by MAP decoders.", "labels": [], "entities": []}, {"text": "In this sense, the work of is different in that both partial and full hypotheses are re-ranked during the decoding phase directly using consensus between translations from different SMT systems.", "labels": [], "entities": [{"text": "SMT", "start_pos": 182, "end_pos": 185, "type": "TASK", "confidence": 0.9770167469978333}]}, {"text": "However, their method does not change component systems' search spaces.", "labels": [], "entities": []}, {"text": "This paper presents hypothesis mixture decoding (HM decoding), anew decoding scheme that performs translation reconstruction using hypotheses generated by multiple component systems.", "labels": [], "entities": [{"text": "hypothesis mixture decoding (HM decoding)", "start_pos": 20, "end_pos": 61, "type": "TASK", "confidence": 0.739426463842392}, {"text": "translation reconstruction", "start_pos": 98, "end_pos": 124, "type": "TASK", "confidence": 0.9740269780158997}]}, {"text": "HM decoding involves two decoding stages: first, each component system decodes the source sentence independently, with the explored search space kept for use in the next step; second, anew search space is constructed by composing existing hypo-theses produced by all component systems using a set of rules provided by the HM decoder itself, and anew set of component model independent features are used to seek the final best translation from this new constructed search space.", "labels": [], "entities": []}, {"text": "We evaluate by combining two SMT models with state-of-the-art performances on the NIST Chinese-to-English translation tasks.", "labels": [], "entities": [{"text": "SMT", "start_pos": 29, "end_pos": 32, "type": "TASK", "confidence": 0.9894785284996033}, {"text": "NIST Chinese-to-English translation tasks", "start_pos": 82, "end_pos": 123, "type": "TASK", "confidence": 0.7462115287780762}]}, {"text": "Experimental results show that our approach outperforms the best component SMT system by up to 2.11 BLEU points.", "labels": [], "entities": [{"text": "SMT", "start_pos": 75, "end_pos": 78, "type": "TASK", "confidence": 0.9909492135047913}, {"text": "BLEU", "start_pos": 100, "end_pos": 104, "type": "METRIC", "confidence": 0.9990574717521667}]}, {"text": "Consistent improvements can be observed over several related decoding techniques as well, including word-level system combination, collaborative decoding and model combination.", "labels": [], "entities": [{"text": "word-level system combination", "start_pos": 100, "end_pos": 129, "type": "TASK", "confidence": 0.6312558452288309}]}], "datasetContent": [{"text": "In the last part, we evaluate the quality of oracle translations on the n-best lists generated by HM decoding and all decoding approaches discussed in this paper.", "labels": [], "entities": []}, {"text": "Oracle performances are obtained using the metric of sentence-level BLEU score proposed by, and each decoding approach outputs its 1000-best hypotheses, which are used to extract oracle translations.: Oracle performances of different methods (+: significantly better than the best multiple-system based decoding method (CD-Comb) with < 0.05) Results are shown in: compared to each single component system, decoding methods based on multiple SMT systems can provide significant improvements on oracle translations; word-level system combination, collaborative decoding and model combination show similar performances, in which CD-Comb performs best; BTG-HMD, SCFG-HMD and SC BTG+SCFG can obtain significant improvements than all the other approaches, and SC BTG+SCFG performs best on all evaluation sets.", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 68, "end_pos": 78, "type": "METRIC", "confidence": 0.9566834568977356}]}], "tableCaptions": [{"text": " Table 1: Statistics on dev and test data sets", "labels": [], "entities": []}, {"text": " Table 2: HM decoding vs. single component system  decoding (*: significantly better than each component  system with < 0.01)", "labels": [], "entities": []}, {"text": " Table 3: HM decoding vs. system combination (+: sig- nificantly better than SC with < 0.05)", "labels": [], "entities": []}, {"text": " Table 4: HM decoding vs. consensus decoding (+: sig- nificantly better than the best result of consensus decod- ing methods with < 0.05)", "labels": [], "entities": []}, {"text": " Table 5: System combination based on the outputs of  BTG-HMD and SCFG-HMD (+: significantly better  than the best HM decoding algorithm (SCFG-HMD)  with < 0.05)", "labels": [], "entities": [{"text": "BTG-HMD", "start_pos": 54, "end_pos": 61, "type": "DATASET", "confidence": 0.927818238735199}]}, {"text": " Table 6: Oracle performances of different methods (+:  significantly better than the best multiple-system based  decoding method (CD-Comb) with < 0.05)", "labels": [], "entities": []}, {"text": " Table 6: compared to each  single component system, decoding methods based  on multiple SMT systems can provide significant  improvements on oracle translations; word-level  system combination, collaborative decoding and  model combination show similar performances, in  which CD-Comb performs best; BTG-HMD,  SCFG-HMD and SC BTG+SCFG can obtain significant  improvements than all the other approaches, and  SC BTG+SCFG performs best on all evaluation sets.", "labels": [], "entities": [{"text": "SMT", "start_pos": 89, "end_pos": 92, "type": "TASK", "confidence": 0.9584512710571289}]}]}