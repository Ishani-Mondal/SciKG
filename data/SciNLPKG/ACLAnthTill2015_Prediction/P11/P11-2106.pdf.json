{"title": [{"text": "Semantic Information and Derivation Rules for Robust Dialogue Act Detection in a Spoken Dialogue System", "labels": [], "entities": [{"text": "Robust Dialogue Act Detection", "start_pos": 46, "end_pos": 75, "type": "TASK", "confidence": 0.7967112734913826}]}], "abstractContent": [{"text": "In this study, a novel approach to robust dialogue act detection for error-prone speech recognition in a spoken dialogue system is proposed.", "labels": [], "entities": [{"text": "dialogue act detection", "start_pos": 42, "end_pos": 64, "type": "TASK", "confidence": 0.6624403993288676}, {"text": "error-prone speech recognition", "start_pos": 69, "end_pos": 99, "type": "TASK", "confidence": 0.6865438421567281}]}, {"text": "First, partial sentence trees are proposed to represent a speech recognition output sentence.", "labels": [], "entities": [{"text": "speech recognition output sentence", "start_pos": 58, "end_pos": 92, "type": "TASK", "confidence": 0.7672489583492279}]}, {"text": "Semantic information and the derivation rules of the partial sentence trees are extracted and used to model the relationship between the dialogue acts and the derivation rules.", "labels": [], "entities": []}, {"text": "The constructed model is then used to generate a semantic score for dialogue act detection given an input speech utterance.", "labels": [], "entities": [{"text": "dialogue act detection", "start_pos": 68, "end_pos": 90, "type": "TASK", "confidence": 0.7927615245183309}]}, {"text": "The proposed approach is implemented and evaluated in a Mandarin spoken dialogue system for tour-guiding service.", "labels": [], "entities": []}, {"text": "Combined with scores derived from the ASR recognition probability and the dialogue history, the proposed approach achieves 84.3% detection accuracy, an absolute improvement of 34.7% over the base-line of the semantic slot-based method with 49.6% detection accuracy.", "labels": [], "entities": [{"text": "ASR recognition", "start_pos": 38, "end_pos": 53, "type": "TASK", "confidence": 0.9671854674816132}, {"text": "accuracy", "start_pos": 139, "end_pos": 147, "type": "METRIC", "confidence": 0.96849524974823}, {"text": "accuracy", "start_pos": 256, "end_pos": 264, "type": "METRIC", "confidence": 0.6659535765647888}]}], "introductionContent": [{"text": "An intuitive framework for spoken dialogue system (SDS) can be regarded as a chain process.", "labels": [], "entities": [{"text": "spoken dialogue system (SDS)", "start_pos": 27, "end_pos": 55, "type": "TASK", "confidence": 0.7412573496500651}]}, {"text": "Specifically, the automatic speech recognition (ASR) module accepts the user's utterance Ut and returns a string of words W t The spoken language understanding (SLU) module converts W t to an abstract representation of the user's dialogue act (DA).", "labels": [], "entities": [{"text": "automatic speech recognition (ASR)", "start_pos": 18, "end_pos": 52, "type": "TASK", "confidence": 0.8079151014486948}]}, {"text": "The dialogue management (DM) module determines the user's dialogue act A * t and accordingly decides the current act of the system.", "labels": [], "entities": [{"text": "dialogue management (DM)", "start_pos": 4, "end_pos": 28, "type": "TASK", "confidence": 0.8235515594482422}, {"text": "A", "start_pos": 71, "end_pos": 72, "type": "METRIC", "confidence": 0.8453893065452576}]}, {"text": "The system DA is converted to a surface representation by natural lan- guage generation in the textual form, which is passed to a text-to-speech synthesizer for speech waveform generation.", "labels": [], "entities": [{"text": "speech waveform generation", "start_pos": 161, "end_pos": 187, "type": "TASK", "confidence": 0.6380816002686819}]}, {"text": "The cycle repeats when the user responds with anew utterance.", "labels": [], "entities": []}, {"text": "Clearly, one can see that the inference of the user's overall intention via DA detection is an important task in SDS.", "labels": [], "entities": [{"text": "DA detection", "start_pos": 76, "end_pos": 88, "type": "TASK", "confidence": 0.8787481486797333}, {"text": "SDS", "start_pos": 113, "end_pos": 116, "type": "TASK", "confidence": 0.9715486168861389}]}, {"text": "depicts the training and test phases of the SLU module and the DM module in our system.", "labels": [], "entities": []}, {"text": "The dataflow for training and testing are indicated by blue arrows and red arrows, respectively.", "labels": [], "entities": []}, {"text": "The input word sequences are converted to partial sentence trees (PST) () in the PST Construction block.", "labels": [], "entities": []}, {"text": "The derivation rule (DR) Generation block extracts derivation rules from the training text.", "labels": [], "entities": []}, {"text": "The DR-DA matrix is created after clustering the sentences into different dialogue acts (DAs), counting the occurrences the DRs in DA, and introducing an entropy-based weighting scheme).", "labels": [], "entities": []}, {"text": "This matrix is pivotal in the computation of the lexical score.", "labels": [], "entities": []}, {"text": "Finally, the lexical, the history, and the ASR scores are combined to decide the 603 optimal dialogue act, and a proper action by the system is taken.", "labels": [], "entities": [{"text": "ASR", "start_pos": 43, "end_pos": 46, "type": "METRIC", "confidence": 0.977495551109314}]}, {"text": "In our system, not only the clean text data but also the noisy ASR output data are used in order to take the error-proneness of ASR output into account.", "labels": [], "entities": []}, {"text": "Furthermore, a predefined keyword list is used and the keyword tokens are replaced by the corresponding named entity classes (NEC) in order to obtain a compact feature set.", "labels": [], "entities": []}], "datasetContent": [{"text": "To evaluate the proposed method of dialogue act detection for robust spoken dialogue system, we adopt the commonly-used Wizard-of-Oz approach to harvest the Tainan-city tourguiding dialogue corpus in a lab environment and experiment with simulated noisy ASR results.", "labels": [], "entities": [{"text": "dialogue act detection", "start_pos": 35, "end_pos": 57, "type": "TASK", "confidence": 0.7047752539316813}, {"text": "Tainan-city tourguiding dialogue corpus", "start_pos": 157, "end_pos": 196, "type": "DATASET", "confidence": 0.802223414182663}, {"text": "ASR", "start_pos": 254, "end_pos": 257, "type": "TASK", "confidence": 0.8936938047409058}]}, {"text": "The details are given in this section.", "labels": [], "entities": []}, {"text": "Two types of data from different sources are collected for this work.", "labels": [], "entities": []}, {"text": "The first type of data, called A-data, is a travel information data set harvested from the databases available on the web, e.g., Wikipedia and Google Map.", "labels": [], "entities": []}, {"text": "A-data consists of 1, 603 sentences with 317 word types.", "labels": [], "entities": []}, {"text": "The second type of data, called Q-data, is the edited transcription of a speech data set simulating human-computer dialogues in a lab environment.", "labels": [], "entities": []}, {"text": "Qdata is intended for the system to learn to handle the various situations, e.g., misunderstanding the user's intention.", "labels": [], "entities": []}, {"text": "It consists of 144 dialogues with 1, 586 utterances.", "labels": [], "entities": []}, {"text": "From the Q-data, 28 named entity classes and 796 derivation rules were obtained from the Sparser.", "labels": [], "entities": [{"text": "Sparser", "start_pos": 89, "end_pos": 96, "type": "DATASET", "confidence": 0.9357181787490845}]}, {"text": "gives some examples of the selected NECs and semantic classes.", "labels": [], "entities": []}, {"text": "A Mandarin speech recognition engine was realized using the HTK (), which is commonly used in research and development.", "labels": [], "entities": [{"text": "Mandarin speech recognition", "start_pos": 2, "end_pos": 29, "type": "TASK", "confidence": 0.6396335959434509}, {"text": "HTK", "start_pos": 60, "end_pos": 63, "type": "DATASET", "confidence": 0.8714571595191956}]}, {"text": "For speech features, 39 dimensions were used, including 12 dimensions of mel-frequency cepstral coefficients (MFCCs), one dimension of log energy, and their delta and acceleration features.", "labels": [], "entities": [{"text": "mel-frequency cepstral coefficients (MFCCs)", "start_pos": 73, "end_pos": 116, "type": "METRIC", "confidence": 0.7909103035926819}]}, {"text": "In total, the acoustic models are composed of 153 subsyllable and 37 particle models (e.g.  on Hidden Markov Model (HMM) with 32 Gaussian mixture components per state.", "labels": [], "entities": []}, {"text": "For the language model, SRILM toolkit) was employed to estimate a bi-gram model with the Qdata.", "labels": [], "entities": []}, {"text": "The average word accuracy of the ASR module is 86.1% with a lexicon of 297 words.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 17, "end_pos": 25, "type": "METRIC", "confidence": 0.9528892636299133}, {"text": "ASR", "start_pos": 33, "end_pos": 36, "type": "TASK", "confidence": 0.9727135896682739}]}, {"text": "Note that the vocabulary size is small due to a limited domain.", "labels": [], "entities": []}, {"text": "5-fold cross validation method was utilized for system evaluation.", "labels": [], "entities": []}, {"text": "As shown in, one can see that 38 DA types achieve the best performance for the proposed detection model.", "labels": [], "entities": []}, {"text": "Therefore, we use 38 DA types (q = 38) in our system.", "labels": [], "entities": []}, {"text": "Note that some exemplar DAs are shown in.", "labels": [], "entities": []}, {"text": "We incrementally add techniques in our SDS until the complete proposed overall system is implemented, to observe the effect of these techniques.", "labels": [], "entities": []}, {"text": "The detection accuracies are shown in.", "labels": [], "entities": []}, {"text": "In this table, the third column (ASR) represents the results of the experiment using the ASR transcripts directly.", "labels": [], "entities": [{"text": "ASR)", "start_pos": 33, "end_pos": 37, "type": "METRIC", "confidence": 0.8084929287433624}]}, {"text": "The fourth column (REF) uses the reference transcripts, so it represents the case with perfect ASR.", "labels": [], "entities": [{"text": "REF", "start_pos": 19, "end_pos": 22, "type": "METRIC", "confidence": 0.9294312596321106}]}, {"text": "The first (40%-sim) and second (60%-sim) column represents the simulation where 40% and 60% of the words in the reference transcripts are retained, respectively.", "labels": [], "entities": []}, {"text": "There are five sets of experiments summarized in this table.", "labels": [], "entities": []}, {"text": "For the baseline, each keyword corresponds to a coordinate in the vector representation fora sentence.", "labels": [], "entities": []}, {"text": "The results are shown in the first row (baseline).", "labels": [], "entities": []}, {"text": "In the second set of experiments (NEC), the keywords are replaced by their NEC.", "labels": [], "entities": [{"text": "NEC", "start_pos": 75, "end_pos": 78, "type": "DATASET", "confidence": 0.8702850341796875}]}, {"text": "In the third set of experiments (PST), the PST representation fora sentence is used.", "labels": [], "entities": []}, {"text": "In the fourth set of experiments (DR), the derivation rule representation of a sentence is used.", "labels": [], "entities": []}, {"text": "Finally, the entropy-normalized DR-DA matrix is used to represent sentences, and the results are shown in the last row (DR-DA).", "labels": [], "entities": []}, {"text": "There are strong improvements when NEC (from 49.6% to 56.8%) and PST (from 56.8% to 76.2%) representations are introduced.", "labels": [], "entities": [{"text": "NEC", "start_pos": 35, "end_pos": 38, "type": "TASK", "confidence": 0.4354035258293152}, {"text": "PST", "start_pos": 65, "end_pos": 68, "type": "DATASET", "confidence": 0.6511508226394653}]}, {"text": "Moreover,: Evaluation on different weighted product fusion the DR and DR-DA representations also lead to significant improvements, achieving 81.6% to 82.9%, respectively.", "labels": [], "entities": []}, {"text": "For the other conditions of 40%-sim, 60%-sim, and REF, similar improvements of using NEC and PST are observed.", "labels": [], "entities": [{"text": "REF", "start_pos": 50, "end_pos": 53, "type": "METRIC", "confidence": 0.9939135909080505}, {"text": "NEC", "start_pos": 85, "end_pos": 88, "type": "DATASET", "confidence": 0.6859921813011169}]}, {"text": "Using DR-DA, however, suffers from performance degradation when the keywords are randomly discarded.", "labels": [], "entities": []}, {"text": "We examine the effect of different weighted product fusion and rewrite the formulation in (5) as where \u03bb A is the weight for the ASR score and the lexical score, \u03bb L is the weight of the history score, and \u03bb A + \u03bb L = 1.", "labels": [], "entities": [{"text": "ASR score", "start_pos": 129, "end_pos": 138, "type": "METRIC", "confidence": 0.6890788078308105}]}, {"text": "shows the results that history information will effect on the DA detection, because it was estimated by the dialogue turns that captured the user behaviors.", "labels": [], "entities": [{"text": "DA detection", "start_pos": 62, "end_pos": 74, "type": "TASK", "confidence": 0.9755938351154327}]}], "tableCaptions": [{"text": " Table 2: Detection accuracies with varying numbers of  DA types.", "labels": [], "entities": [{"text": "Detection accuracies", "start_pos": 10, "end_pos": 30, "type": "TASK", "confidence": 0.6061516553163528}]}, {"text": " Table 3: Detection accuracies of cascading components  for the lexical score.", "labels": [], "entities": [{"text": "Detection accuracies", "start_pos": 10, "end_pos": 30, "type": "METRIC", "confidence": 0.7493795454502106}]}, {"text": " Table 4: Evaluation on different weighted product fusion", "labels": [], "entities": []}]}