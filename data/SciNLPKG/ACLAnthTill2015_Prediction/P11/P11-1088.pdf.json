{"title": [{"text": "Using Deep Morphology to Improve Automatic Error Detection in Arabic Handwriting Recognition", "labels": [], "entities": [{"text": "Improve Automatic Error Detection", "start_pos": 25, "end_pos": 58, "type": "TASK", "confidence": 0.5467318221926689}, {"text": "Handwriting Recognition", "start_pos": 69, "end_pos": 92, "type": "TASK", "confidence": 0.748828113079071}]}], "abstractContent": [{"text": "Arabic handwriting recognition (HR) is a challenging problem due to Arabic's connected letter forms, consonantal diacritics and rich morphology.", "labels": [], "entities": [{"text": "Arabic handwriting recognition (HR)", "start_pos": 0, "end_pos": 35, "type": "TASK", "confidence": 0.770994633436203}]}, {"text": "In this paper we isolate the task of identification of erroneous words in HR from the task of producing corrections for these words.", "labels": [], "entities": [{"text": "identification of erroneous words in HR", "start_pos": 37, "end_pos": 76, "type": "TASK", "confidence": 0.7523581087589264}]}, {"text": "We consider a variety of linguistic (morphological and syntactic) and non-linguistic features to automatically identify these errors.", "labels": [], "entities": []}, {"text": "Our best approach achieves a roughly \u223c15% absolute increase in F-score over a simple but reasonable baseline.", "labels": [], "entities": [{"text": "F-score", "start_pos": 63, "end_pos": 70, "type": "METRIC", "confidence": 0.9919667840003967}]}, {"text": "A detailed error analysis shows that linguistic features , such as lemma (i.e., citation form) models , help improve HR-error detection precisely where we expect them to: semantically incoherent error words.", "labels": [], "entities": [{"text": "HR-error detection", "start_pos": 117, "end_pos": 135, "type": "TASK", "confidence": 0.9649906754493713}]}], "introductionContent": [{"text": "After years of development, optical character recognition (OCR) for Latin-character languages, such as English, has been refined greatly.", "labels": [], "entities": [{"text": "optical character recognition (OCR)", "start_pos": 28, "end_pos": 63, "type": "TASK", "confidence": 0.7435684353113174}]}, {"text": "Arabic, however, possesses a complex orthography and morphology that makes OCR more difficult).", "labels": [], "entities": [{"text": "OCR", "start_pos": 75, "end_pos": 78, "type": "TASK", "confidence": 0.853730320930481}]}, {"text": "Because of this, only a few systems for Arabic OCR of printed text have been developed, and these have not been thoroughly evaluated.", "labels": [], "entities": [{"text": "OCR of printed text", "start_pos": 47, "end_pos": 66, "type": "TASK", "confidence": 0.834380641579628}]}, {"text": "OCR of Arabic handwritten text (handwriting recognition, or HR), whether online or offline, is even more challenging compared to printed Arabic OCR, where the uniformity of letter shapes and other factors allow for easier recognition ().", "labels": [], "entities": [{"text": "OCR of Arabic handwritten text", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.849972414970398}, {"text": "handwriting recognition, or HR)", "start_pos": 32, "end_pos": 63, "type": "TASK", "confidence": 0.6317063868045807}]}, {"text": "OCR and HR systems are often improved by performing post-processing; these are attempts to evaluate whether each word, phrase or sentence in the OCR/HR output is legal and/or probable.", "labels": [], "entities": []}, {"text": "When an illegal word or phrase is discovered (error detection), these systems usually attempt to generate a legal alternative (error correction).", "labels": [], "entities": [{"text": "error detection)", "start_pos": 46, "end_pos": 62, "type": "TASK", "confidence": 0.8047550320625305}]}, {"text": "In this paper, we present a HR error detection system that uses deep lexical and morphological feature models to locate possible \"problem zones\" -words or phrases that are likely incorrect -in Arabic HR output.", "labels": [], "entities": [{"text": "HR error detection", "start_pos": 28, "end_pos": 46, "type": "TASK", "confidence": 0.9043749570846558}]}, {"text": "We use an off-the-shelf HR system ( to generate an N-best list of hypotheses for each of several scanned segments of Arabic handwriting.", "labels": [], "entities": []}, {"text": "Our problem zone detection (PZD) system then tags the potentially erroneous (problem) words.", "labels": [], "entities": [{"text": "problem zone detection (PZD)", "start_pos": 4, "end_pos": 32, "type": "TASK", "confidence": 0.7454186975955963}]}, {"text": "A subsequent HR post-processing system can then focus its effort on these words when generating additional alternative hypotheses.", "labels": [], "entities": []}, {"text": "We only discuss the PZD system and not the task of new hypothesis generation; the evaluation is on error/problem identification.", "labels": [], "entities": [{"text": "new hypothesis generation", "start_pos": 51, "end_pos": 76, "type": "TASK", "confidence": 0.7917970021565756}, {"text": "error/problem identification", "start_pos": 99, "end_pos": 127, "type": "TASK", "confidence": 0.6788002550601959}]}, {"text": "PZD can also be useful in highlighting erroneous text for human post-editors.", "labels": [], "entities": [{"text": "PZD", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.6342772841453552}]}, {"text": "This paper is structured as follows: Section 2 provides background on the difficulties of the Arabic HR task.", "labels": [], "entities": [{"text": "Arabic HR task", "start_pos": 94, "end_pos": 108, "type": "TASK", "confidence": 0.6428228418032328}]}, {"text": "Section 3 presents an analysis of HR errors and defines what is considered a problem zone to be tagged.", "labels": [], "entities": [{"text": "HR", "start_pos": 34, "end_pos": 36, "type": "TASK", "confidence": 0.9288561940193176}]}, {"text": "The experimental features, data and other variables are outlined in Section 4.", "labels": [], "entities": []}, {"text": "The experiments are presented and discussed in Section 5.", "labels": [], "entities": []}, {"text": "We discuss and compare to some related work in detail in Section 6.", "labels": [], "entities": [{"text": "Section 6", "start_pos": 57, "end_pos": 66, "type": "DATASET", "confidence": 0.8693850040435791}]}, {"text": "Conclusions and suggested avenues of for future progress are presented in Section 7.", "labels": [], "entities": []}], "datasetContent": [{"text": "The data used in this paper is derived from image scans provided by the Linguistic Data Consortium (LDC).", "labels": [], "entities": [{"text": "Linguistic Data Consortium (LDC)", "start_pos": 72, "end_pos": 104, "type": "DATASET", "confidence": 0.8483787178993225}]}, {"text": "This data consists of high-resolution (600 dpi) handwriting scans of Arabic text taken from newswire articles, web logs and newsgroups, along with ground truth annotations and word bounding box information.", "labels": [], "entities": [{"text": "word bounding box", "start_pos": 176, "end_pos": 193, "type": "TASK", "confidence": 0.7456788520018259}]}, {"text": "The scans include variations inscribe demographic background, writing instrument, paper and writing speed.", "labels": [], "entities": []}, {"text": "The BBN Byblos HR system () is then used to process these scanned images into sequences of segments (sentence fragments).", "labels": [], "entities": [{"text": "BBN Byblos HR", "start_pos": 4, "end_pos": 17, "type": "DATASET", "confidence": 0.9157958229382833}]}, {"text": "The system generates a ranked N-best list of hypotheses for each segment, where N could be as high as 300.", "labels": [], "entities": []}, {"text": "On average, a segment has 6.87 words (including punctuation).", "labels": [], "entities": []}, {"text": "We divide the N-best list data into training, development (dev) and test sets.", "labels": [], "entities": []}, {"text": "For training, we consider two sets of size 2000 and 4000 segments (S) with the 10 top-ranked hypotheses (H) for each segment to provide additional variations.", "labels": [], "entities": []}, {"text": "The references are also included in the training sets to provide examples of perfect text.", "labels": [], "entities": []}, {"text": "The dev and test sets use 500 segments with one top-ranked hypothesis each {H=1}.", "labels": [], "entities": []}, {"text": "We can construct a trivial PZD baseline by assuming all the input words are PROBs; this results in baseline % Precision/Recall/F-scores of 25.8/100/41.1 and 26.0/100/41.2 for the dev and test sets, respectively.", "labels": [], "entities": [{"text": "Precision/Recall/F-scores", "start_pos": 110, "end_pos": 135, "type": "METRIC", "confidence": 0.776585602760315}]}, {"text": "Note that in this paper we eschew these baselines in favor of comparison to a non-trivial baseline generated by a simple PZD model.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 3: PZD F-scores for simple feature combinations.  The training set used was {S=2000, H=10} and the mod- els were evaluated on the dev set. The improvement over  the word baseline case is also indicated. %Imp is the rel- ative improvement over the first row.", "labels": [], "entities": [{"text": "PZD", "start_pos": 10, "end_pos": 13, "type": "DATASET", "confidence": 0.3492564558982849}, {"text": "F-scores", "start_pos": 14, "end_pos": 22, "type": "METRIC", "confidence": 0.5219630002975464}, {"text": "Imp", "start_pos": 211, "end_pos": 214, "type": "METRIC", "confidence": 0.9841193556785583}]}, {"text": " Table 4: PZD F-scores for models that include Binned  features. The training set used was {S=2000, H=10} and  the models were evaluated on the dev set. The improve- ment over the word baseline case is also indicated. The  label \"N-grams\" following a Binned feature refers to us- ing 1, 2 and 3-grams of that feature. Indentation marks  accumulative features in model. The best performing row  (with bolded score) is word+nw N-grams+lem.", "labels": [], "entities": [{"text": "PZD", "start_pos": 10, "end_pos": 13, "type": "DATASET", "confidence": 0.33318832516670227}, {"text": "F-scores", "start_pos": 14, "end_pos": 22, "type": "METRIC", "confidence": 0.64473557472229}]}, {"text": " Table 5: PZD F-scores for models when word confi- dence is added to the feature set. The training set used  was {S=2000, H=10} and the models were evaluated on  the dev set. The improvement generated by including  word confidence is indicated. The label \"N-grams\" fol- lowing a Binned feature refers to using 1, 2 and 3-grams  of that feature. Indentation marks accumulative features  in model. %Imp is the relative improvement gained by  adding the conf feature.", "labels": [], "entities": [{"text": "PZD", "start_pos": 10, "end_pos": 13, "type": "DATASET", "confidence": 0.3384653627872467}, {"text": "F-scores", "start_pos": 14, "end_pos": 22, "type": "METRIC", "confidence": 0.7286181449890137}, {"text": "Imp", "start_pos": 397, "end_pos": 400, "type": "METRIC", "confidence": 0.9950482249259949}]}, {"text": " Table 6: PZD F-scores for selected models when the  number of training segments (S) is doubled. The training  set used was {S=2000, H=10} and {S=4000, H=10},  and the models were evaluated on the dev set. The label  \"N-grams\" following a Binned feature refers to using 1, 2  and 3-grams of that feature. Indentation marks accumu- lative features in model.", "labels": [], "entities": [{"text": "PZD", "start_pos": 10, "end_pos": 13, "type": "DATASET", "confidence": 0.32101285457611084}, {"text": "F-scores", "start_pos": 14, "end_pos": 22, "type": "METRIC", "confidence": 0.6384732127189636}]}, {"text": " Table 7: Error analysis results comparing the perfor- mance of multiple systems over different metrics (a) and  word/error types (b). %Prob shows the distribution of  problem words into different word types (word, punctua- tion and digit) and error types. INS, DEL and SUB stand  for insertion, deletion and substitution error types, re- spectively. Ortho stands for orthographic variant. Lemma  stands for 'shared lemma'. The columns to the right  of the %Prob column show recall percentage for each  word/error type.", "labels": [], "entities": [{"text": "INS", "start_pos": 257, "end_pos": 260, "type": "METRIC", "confidence": 0.9710781574249268}, {"text": "DEL", "start_pos": 262, "end_pos": 265, "type": "METRIC", "confidence": 0.8887231349945068}, {"text": "recall", "start_pos": 475, "end_pos": 481, "type": "METRIC", "confidence": 0.9989103078842163}]}, {"text": " Table 8: Results on test set of 500 segments with one hy- pothesis each. The models were trained on the {S=4000,  H=10} training set.", "labels": [], "entities": []}]}