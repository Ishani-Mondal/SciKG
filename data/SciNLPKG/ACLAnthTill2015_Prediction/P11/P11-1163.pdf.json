{"title": [], "abstractContent": [{"text": "Nested event structures area common occurrence in both open domain and domain specific extraction tasks, e.g., a \"crime\" event can cause a \"investigation\" event, which can lead to an \"arrest\" event.", "labels": [], "entities": []}, {"text": "However, most current approaches address event extraction with highly local models that extract each event and argument independently.", "labels": [], "entities": [{"text": "event extraction", "start_pos": 41, "end_pos": 57, "type": "TASK", "confidence": 0.7260289937257767}]}, {"text": "We propose a simple approach for the extraction of such structures by taking the tree of event-argument relations and using it directly as the representation in a reranking dependency parser.", "labels": [], "entities": []}, {"text": "This provides a simple framework that captures global properties of both nested and flat event structures.", "labels": [], "entities": []}, {"text": "We explore a rich feature space that models both the events to be parsed and context from the original supporting text.", "labels": [], "entities": []}, {"text": "Our approach obtains competitive results in the extraction of biomedical events from the BioNLP'09 shared task with a F1 score of 53.5% in development and 48.6% in testing.", "labels": [], "entities": [{"text": "BioNLP'09 shared task", "start_pos": 89, "end_pos": 110, "type": "DATASET", "confidence": 0.7354290088017782}, {"text": "F1 score", "start_pos": 118, "end_pos": 126, "type": "METRIC", "confidence": 0.9879268407821655}]}], "introductionContent": [{"text": "Event structures in open domain texts are frequently highly complex and nested: a \"crime\" event can cause an \"investigation\" event, which can lead to an \"arrest\" event (.", "labels": [], "entities": []}, {"text": "The same observation holds in specific domains.", "labels": [], "entities": []}, {"text": "For example, the BioNLP'09 shared task () focuses on the extraction of nested biomolecular events, where, e.g., a REGULATION event causes a TRANSCRIPTION event (see fora detailed example).", "labels": [], "entities": []}, {"text": "Despite this observation, many stateof-the-art supervised event extraction models still extract events and event arguments independently, ignoring their underlying structure.", "labels": [], "entities": [{"text": "stateof-the-art supervised event extraction", "start_pos": 31, "end_pos": 74, "type": "TASK", "confidence": 0.6910137087106705}]}, {"text": "In this paper, we propose anew approach for supervised event extraction where we take the tree of relations and their arguments and use it directly as the representation in a dependency parser (rather than conventional syntactic relations).", "labels": [], "entities": [{"text": "supervised event extraction", "start_pos": 44, "end_pos": 71, "type": "TASK", "confidence": 0.6283500492572784}]}, {"text": "Our approach is conceptually simple: we first convert the original representation of events and their arguments to dependency trees by creating dependency arcs between event anchors (phrases that anchor events in the supporting text) and their corresponding arguments.", "labels": [], "entities": []}, {"text": "Note that after conversion, only event anchors and entities remain.", "labels": [], "entities": [{"text": "event anchors and entities", "start_pos": 33, "end_pos": 59, "type": "TASK", "confidence": 0.7599701657891273}]}, {"text": "shows a sentence and its converted form from the biomedical domain with four events: two POSITIVE REGULATION events, anchored by the phrase \"acts as a costimulatory signal,\" and two TRANSCRIPTION events, both anchored on \"gene transcription.\"", "labels": [], "entities": [{"text": "POSITIVE REGULATION events", "start_pos": 89, "end_pos": 115, "type": "METRIC", "confidence": 0.8562313516934713}, {"text": "TRANSCRIPTION", "start_pos": 182, "end_pos": 195, "type": "METRIC", "confidence": 0.9479522705078125}]}, {"text": "All events take either protein entity mentions (PROT) or other events as arguments.", "labels": [], "entities": []}, {"text": "The latter is what allows for nested event structures.", "labels": [], "entities": []}, {"text": "Existing dependency parsing models can be adapted to produce these semantic structures instead of syntactic dependencies.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 9, "end_pos": 27, "type": "TASK", "confidence": 0.7250348627567291}]}, {"text": "We built a global reranking parser model using multiple decoders from MSTParser ().", "labels": [], "entities": [{"text": "MSTParser", "start_pos": 70, "end_pos": 79, "type": "DATASET", "confidence": 0.9637971520423889}]}, {"text": "The main contributions of this paper are the following: 1.", "labels": [], "entities": []}, {"text": "We demonstrate that parsing is an attractive approach for extracting events, both nested and otherwise.", "labels": [], "entities": [{"text": "parsing", "start_pos": 20, "end_pos": 27, "type": "TASK", "confidence": 0.9835715293884277}]}, {"text": "(a) Original sentence with nested events (b) After conversion to event dependencies Figure 1: Nested events in the text fragment: \".", "labels": [], "entities": []}, {"text": "the HTLV-1 transactivator protein, tax, acts as a costimulatory signal for GM-CSF and IL-2 gene transcription . .", "labels": [], "entities": []}, {"text": "\" Throughout this paper, bold text indicates instances of event anchors and italicized text denotes entities (PROTEINs in the BioNLP'09 domain).", "labels": [], "entities": [{"text": "BioNLP'09 domain", "start_pos": 126, "end_pos": 142, "type": "DATASET", "confidence": 0.9108569622039795}]}, {"text": "Note that in (a) there are two copies of each type of event, which are merged to single nodes in the dependency tree (Section 3.1).", "labels": [], "entities": []}, {"text": "2. We propose a wide range of features for event extraction.", "labels": [], "entities": [{"text": "event extraction", "start_pos": 43, "end_pos": 59, "type": "TASK", "confidence": 0.8317539393901825}]}, {"text": "Our analysis indicates that features which model the global event structure yield considerable performance improvements, which proves that modeling event structure jointly is beneficial.", "labels": [], "entities": []}, {"text": "3. We evaluate on the biomolecular event corpus from the the BioNLP'09 shared task and show that our approach obtains competitive results.", "labels": [], "entities": [{"text": "BioNLP'09 shared task", "start_pos": 61, "end_pos": 82, "type": "DATASET", "confidence": 0.8237605690956116}]}], "datasetContent": [{"text": "Our experiments use the BioNLP'09 shared task corpus () which includes 800 biomedical abstracts (7,449 sentences, 8,597 events) for training and 150 abstracts (1,450 sentences, 1,809 events) for development.", "labels": [], "entities": [{"text": "BioNLP'09 shared task corpus", "start_pos": 24, "end_pos": 52, "type": "DATASET", "confidence": 0.8036560565233231}]}, {"text": "The test set includes 260 abstracts, 2,447 sentences, and 3,182 events.", "labels": [], "entities": []}, {"text": "Throughout our experiments, we report BioNLP F1 scores with approximate span and recursive event matching (as described in the shared task definition).", "labels": [], "entities": [{"text": "BioNLP F1 scores", "start_pos": 38, "end_pos": 54, "type": "METRIC", "confidence": 0.8755556146303812}]}, {"text": "For preprocessing, we parsed all documents using the self-trained biomedical McClosky-CharniakJohnson reranking parser.", "labels": [], "entities": []}, {"text": "We bias the anchor detector to favor recall, allowing the parser and reranker to determine which event anchors will ultimately be used.", "labels": [], "entities": [{"text": "recall", "start_pos": 37, "end_pos": 43, "type": "METRIC", "confidence": 0.9987269043922424}]}, {"text": "When performing nbest parsing, n = 50.", "labels": [], "entities": [{"text": "nbest parsing", "start_pos": 16, "end_pos": 29, "type": "TASK", "confidence": 0.5249361246824265}]}, {"text": "For parser feature pruning, \u03b1 = 0.001.", "labels": [], "entities": []}, {"text": "shows the performance of each of the decoders when using gold event anchors.", "labels": [], "entities": []}, {"text": "In both cases where n-best decoding is available, the reranker improves performance over the 1-best parsers.", "labels": [], "entities": []}, {"text": "We also present the results from a reranker trained from multiple decoders which is our highest scoring model.", "labels": [], "entities": []}, {"text": "In, we present the output for the predicted anchor scenario.", "labels": [], "entities": []}, {"text": "In the case of the 2P decoder, the reranker does not improve performance, though the drop is minimal.", "labels": [], "entities": []}, {"text": "This is because the reranker chose an unfortunate regularization constant during crossvalidation, most likely due to the small size of the training data.", "labels": [], "entities": []}, {"text": "In later experiments where more data is available, the reranker consistently improves accuracy).", "labels": [], "entities": [{"text": "reranker", "start_pos": 55, "end_pos": 63, "type": "METRIC", "confidence": 0.9384427070617676}, {"text": "accuracy", "start_pos": 86, "end_pos": 94, "type": "METRIC", "confidence": 0.9994675517082214}]}, {"text": "As before, the reranker trained from multiple decoders outperforms unreranked models and reranked single decoders.", "labels": [], "entities": []}, {"text": "All in all, our best model in scores 1 F1 point higher than the best system at the BioNLP'09 shared task, and the best model in performs similarly to the best shared task system, which also scores 53.5% on development.", "labels": [], "entities": [{"text": "F1", "start_pos": 39, "end_pos": 41, "type": "METRIC", "confidence": 0.9980276226997375}, {"text": "BioNLP'09 shared task", "start_pos": 83, "end_pos": 104, "type": "DATASET", "confidence": 0.6838423212369283}]}, {"text": "We show the effects of each system component in.", "labels": [], "entities": []}, {"text": "Note how our upper limit is 87.1% due to our conversion process, which enforces the tree constraint, drops events spanning sentences, and performs approximate reconstruction of BINDING events.", "labels": [], "entities": []}, {"text": "Given that state-of-the-art systems on this task currently perform in the 50-60% range, we are not troubled by this number as it still allows for plenty of potential.", "labels": [], "entities": []}, {"text": "12 list 94.7% as the upper limit for their system.", "labels": [], "entities": []}, {"text": "Considering this relatively large difference, we find the results in the previous table very encouraging.", "labels": [], "entities": []}, {"text": "As in other BioNLP'09 systems, our performance drops when switching from gold to predicted anchor information.", "labels": [], "entities": []}, {"text": "Our decrease is similar to the one seen in.", "labels": [], "entities": []}, {"text": "To show the potential of reranking, we provide oracle reranker scores in.", "labels": [], "entities": []}, {"text": "An oracle reranker picks the highest scoring parse from the available parses.", "labels": [], "entities": []}, {"text": "We limit the n-best lists to the top k parses where k \u2208 {1, 2, 10, All}.", "labels": [], "entities": []}, {"text": "For single decoders, \"All\" uses the entire 50-best list.", "labels": [], "entities": []}, {"text": "For multiple decoders, the n-best lists are concatenated together.", "labels": [], "entities": []}, {"text": "The oracle score with multiple decoders and gold anchors is only 0.4% lower than our upper limit (see).", "labels": [], "entities": []}, {"text": "This indicates that parses which could have achieved that limit were nearly always present.", "labels": [], "entities": []}, {"text": "Improving the features in the reranker as well as the original parsers will help us move closer to the limit.", "labels": [], "entities": []}, {"text": "With predicated anchors, the oracle score is about 13% lower but still shows significant potential.", "labels": [], "entities": []}, {"text": "Our final results on the test set, broken down by class, are shown in.", "labels": [], "entities": []}, {"text": "As with other systems, complex events (e.g., REGULATION) prove harder than simple events.", "labels": [], "entities": [{"text": "REGULATION", "start_pos": 45, "end_pos": 55, "type": "METRIC", "confidence": 0.8645496964454651}]}, {"text": "To get a complex event correct, one must correctly detect and parse all events in Additionally, improvements such as document-level parsing and DAG parsing would eliminate the need for much of the approximate and lossy portions of the conversion process.: Oracle reranker BioNLP F1 scores for our n-best decoders and their combinations before reranking on the development corpus.", "labels": [], "entities": [{"text": "document-level parsing", "start_pos": 117, "end_pos": 139, "type": "TASK", "confidence": 0.639197364449501}, {"text": "DAG parsing", "start_pos": 144, "end_pos": 155, "type": "TASK", "confidence": 0.6429011821746826}, {"text": "BioNLP F1 scores", "start_pos": 272, "end_pos": 288, "type": "METRIC", "confidence": 0.7515444358189901}]}, {"text": "the event subtree allowing small errors to have large effects.", "labels": [], "entities": []}, {"text": "Top systems on this task obtain F1 scores of 52.0% at the shared task evaluation) and 56.3% post evaluation ().", "labels": [], "entities": [{"text": "F1", "start_pos": 32, "end_pos": 34, "type": "METRIC", "confidence": 0.9997908473014832}]}, {"text": "However, both systems are tailored to the biomedical domain (the latter uses multiple syntactic parsers), whereas our system has a design that is virtually domain independent.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: BioNLP recall, precision, and F1 scores of individual decoders and the best decoder combination  on development data with the impact of event anchor detection and reranking. Decoder names include the  features order (1 or 2) followed by the projectivity (P = projective, N = non-projective).", "labels": [], "entities": [{"text": "BioNLP", "start_pos": 10, "end_pos": 16, "type": "METRIC", "confidence": 0.9917707443237305}, {"text": "recall", "start_pos": 17, "end_pos": 23, "type": "METRIC", "confidence": 0.9346413612365723}, {"text": "precision", "start_pos": 25, "end_pos": 34, "type": "METRIC", "confidence": 0.9995500445365906}, {"text": "F1", "start_pos": 40, "end_pos": 42, "type": "METRIC", "confidence": 0.9997609257698059}, {"text": "event anchor detection", "start_pos": 146, "end_pos": 168, "type": "TASK", "confidence": 0.6437360147635142}]}, {"text": " Table 2: Effect of each major component to the over- all performance in the development corpus. Compo- nents shown: AD -event anchor detection; Parse  -best individual parsing model; RR -reranking  multiple parsers; Conv -conversion between the  event and dependency representations. 'G' indicates  that gold data was used; '' indicates that the actual  component was used.", "labels": [], "entities": [{"text": "event anchor detection", "start_pos": 121, "end_pos": 143, "type": "TASK", "confidence": 0.7385796705881754}, {"text": "Parse", "start_pos": 145, "end_pos": 150, "type": "METRIC", "confidence": 0.9907745718955994}, {"text": "RR", "start_pos": 184, "end_pos": 186, "type": "METRIC", "confidence": 0.9564072489738464}]}, {"text": " Table 3: Oracle reranker BioNLP F1 scores for  our n-best decoders and their combinations before  reranking on the development corpus.", "labels": [], "entities": [{"text": "BioNLP F1 scores", "start_pos": 26, "end_pos": 42, "type": "METRIC", "confidence": 0.8196878234545389}]}, {"text": " Table 4: Results in the test set broken by event class;  scores generated with the main official metric of ap- proximate span and recursive event matching.", "labels": [], "entities": [{"text": "ap- proximate span", "start_pos": 108, "end_pos": 126, "type": "METRIC", "confidence": 0.9021060466766357}]}]}