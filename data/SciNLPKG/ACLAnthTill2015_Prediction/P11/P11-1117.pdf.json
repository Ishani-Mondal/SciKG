{"title": [{"text": "A Pronoun Anaphora Resolution System based on Factorial Hidden Markov Models", "labels": [], "entities": [{"text": "Pronoun Anaphora Resolution", "start_pos": 2, "end_pos": 29, "type": "TASK", "confidence": 0.8342859943707784}]}], "abstractContent": [{"text": "This paper presents a supervised pronoun anaphora resolution system based on factorial hidden Markov models (FHMMs).", "labels": [], "entities": [{"text": "pronoun anaphora resolution", "start_pos": 33, "end_pos": 60, "type": "TASK", "confidence": 0.6564940909544627}]}, {"text": "The basic idea is that the hidden states of FHMMs are an explicit short-term memory with an antecedent buffer containing recently described referents.", "labels": [], "entities": [{"text": "FHMMs", "start_pos": 44, "end_pos": 49, "type": "DATASET", "confidence": 0.8394569754600525}]}, {"text": "Thus an observed pronoun can find its antecedent from the hidden buffer, or in terms of a generative model, the entries in the hidden buffer generate the corresponding pronouns.", "labels": [], "entities": []}, {"text": "A system implementing this model is evaluated on the ACE corpus with promising performance.", "labels": [], "entities": [{"text": "ACE corpus", "start_pos": 53, "end_pos": 63, "type": "DATASET", "confidence": 0.9835362434387207}]}], "introductionContent": [{"text": "Pronoun anaphora resolution is the task of finding the correct antecedent fora given pronominal anaphor in a document.", "labels": [], "entities": [{"text": "Pronoun anaphora resolution", "start_pos": 0, "end_pos": 27, "type": "TASK", "confidence": 0.7778597275416056}]}, {"text": "It is a subtask of coreference resolution, which is the process of determining whether two or more linguistic expressions in a document refer to the same entity.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 19, "end_pos": 41, "type": "TASK", "confidence": 0.9529867768287659}]}, {"text": "Adopting terminology used in the Automatic Context Extraction (ACE) program, these expressions are called mentions.", "labels": [], "entities": [{"text": "Automatic Context Extraction (ACE)", "start_pos": 33, "end_pos": 67, "type": "TASK", "confidence": 0.7868135720491409}]}, {"text": "Each mention is a reference to some entity in the domain of discourse.", "labels": [], "entities": []}, {"text": "Mentions usually fall into three categories -proper mentions (proper names), nominal mentions (descriptions), and pronominal mentions (pronouns).", "labels": [], "entities": []}, {"text": "There is a great deal of related work on this subject, so the descriptions of other systems below are those which are most related or which the current model has drawn insight from.", "labels": [], "entities": []}, {"text": "Pairwise models () and graph-partitioning methods) decompose the task into a collection of pairwise or mention set coreference decisions.", "labels": [], "entities": []}, {"text": "Decisions for each pair or each group of mentions are based on probabilities of features extracted by discriminative learning models.", "labels": [], "entities": []}, {"text": "The aforementioned approaches have proven to be fruitful; however, there are some notable problems.", "labels": [], "entities": []}, {"text": "Pairwise modeling may fail to produce coherent partitions.", "labels": [], "entities": []}, {"text": "That is, if we link results of pairwise decisions to each other, there maybe conflicting coreferences.", "labels": [], "entities": []}, {"text": "Graph-partitioning methods attempt to reconcile pairwise scores into a final coherent clustering, but they are combinatorially harder to work within discriminative approaches.", "labels": [], "entities": []}, {"text": "One line of research aiming at overcoming the limitation of pairwise models is to learn a mentionranking model to rank preceding mentions fora given anaphor) This approach results in more coherent coreference chains.", "labels": [], "entities": []}, {"text": "Recent years have also seen the revival of interest in generative models in both machine learning and natural language processing., proposed an unsupervised nonparametric Bayesian model for coreference resolution.", "labels": [], "entities": [{"text": "generative", "start_pos": 55, "end_pos": 65, "type": "TASK", "confidence": 0.9660387635231018}, {"text": "coreference resolution", "start_pos": 190, "end_pos": 212, "type": "TASK", "confidence": 0.9645477831363678}]}, {"text": "In contrast to pairwise models, this fully generative model produces each mention from a combination of global entity properties and local attentional state.", "labels": [], "entities": []}, {"text": "did similar work using the same unsupervised generative model, but relaxed head generation as head-index generation, enforced agreement constraints at the global level, and assigned salience only to pronouns.", "labels": [], "entities": [{"text": "head-index generation", "start_pos": 94, "end_pos": 115, "type": "TASK", "confidence": 0.6767001152038574}]}, {"text": "Another unsupervised generative model was recently presented to tackle only pronoun anaphora resolution).", "labels": [], "entities": [{"text": "pronoun anaphora resolution", "start_pos": 76, "end_pos": 103, "type": "TASK", "confidence": 0.6295414467652639}]}, {"text": "The expectation-maximization algorithm (EM) was applied to learn parameters automatically from the parsed version of the North American News Corpus (.", "labels": [], "entities": [{"text": "North American News Corpus", "start_pos": 121, "end_pos": 147, "type": "DATASET", "confidence": 0.8285589069128036}]}, {"text": "This model generates a pronoun's person, number and gender features along with the governor of the pronoun and the syntactic relation between the pronoun and the governor.", "labels": [], "entities": []}, {"text": "This inference process allows the system to keep track of multiple hypotheses through time, including multiple different possible histories of the discourse.", "labels": [], "entities": []}, {"text": "Haghighi and Klein (2010) improved their nonparametric model by sharing lexical statistics at the level of abstract entity types.", "labels": [], "entities": []}, {"text": "Consequently, their model substantially reduces semantic compatibility errors.", "labels": [], "entities": []}, {"text": "They report the best results to date on the complete end-to-end coreference task.", "labels": [], "entities": [{"text": "coreference task", "start_pos": 64, "end_pos": 80, "type": "TASK", "confidence": 0.8936221897602081}]}, {"text": "Further, this model functions in an online setting at mention level.", "labels": [], "entities": []}, {"text": "Namely, the system identifies mentions from a parse tree and resolves resolution with a left-to-right sequential beam search.", "labels": [], "entities": [{"text": "resolves resolution", "start_pos": 61, "end_pos": 80, "type": "TASK", "confidence": 0.6291855871677399}]}, {"text": "This is similar to where a Bell tree is used to score and store the searching path.", "labels": [], "entities": []}, {"text": "In this paper, we present a supervised pronoun resolution system based on Factorial Hidden Markov Models (FHMMs).", "labels": [], "entities": [{"text": "pronoun resolution", "start_pos": 39, "end_pos": 57, "type": "TASK", "confidence": 0.7626838386058807}]}, {"text": "This system is motivated by human processing concerns, by operating incrementally and maintaining a limited short term memory for holding recently mentioned referents.", "labels": [], "entities": []}, {"text": "According to, anaphoric definite NPs are much faster retrieved if the antecedent of a pronoun is in immediately previous sentence.", "labels": [], "entities": []}, {"text": "Therefore, a limited short term memory should be good enough for resolving the majority of pronouns.", "labels": [], "entities": [{"text": "memory", "start_pos": 32, "end_pos": 38, "type": "METRIC", "confidence": 0.8220305442810059}]}, {"text": "In order to construct an operable model, we also measured the average distance between pronouns and their antecedents as discussed in next sections and used distances as important salience features in the model., the current system essentially uses prior information as a discourse model with a time-series manner, using a dynamic programming inference algorithm.", "labels": [], "entities": []}, {"text": "Third, the FHMM described here is an integrated system, in contrast with (.", "labels": [], "entities": [{"text": "FHMM", "start_pos": 11, "end_pos": 15, "type": "DATASET", "confidence": 0.9421436786651611}]}, {"text": "The model generates part of speech tags as simple structural information, as well as related semantic information at each time step or word-by-word step.", "labels": [], "entities": []}, {"text": "While the framework described here can be extended to deeper structural information, POS tags alone are valuable as they can be used to incorporate the binding features (described below).", "labels": [], "entities": []}, {"text": "Although the system described here is evaluated for pronoun resolution, the framework we describe can be extended to more general coreference resolution in a fairly straightforward manner.", "labels": [], "entities": [{"text": "pronoun resolution", "start_pos": 52, "end_pos": 70, "type": "TASK", "confidence": 0.7801811695098877}, {"text": "coreference resolution", "start_pos": 130, "end_pos": 152, "type": "TASK", "confidence": 0.9411976039409637}]}, {"text": "Further, as in other HMM-based systems, the system can be either supervised or unsupervised.", "labels": [], "entities": []}, {"text": "But extensions to unsupervised learning are left for future work.", "labels": [], "entities": []}, {"text": "The final results are compared with a few supervised systems as the mention-ranking model and systems compared in their paper, and Charniak and Elsner's (2009) unsupervised system, emPronouns.", "labels": [], "entities": [{"text": "emPronouns", "start_pos": 181, "end_pos": 191, "type": "DATASET", "confidence": 0.9430184364318848}]}, {"text": "The FHMM-based pronoun resolution system does a better job than the global ranking technique and other approaches.", "labels": [], "entities": [{"text": "FHMM-based pronoun resolution", "start_pos": 4, "end_pos": 33, "type": "TASK", "confidence": 0.6805513501167297}]}, {"text": "This is a promising start for this novel FHMM-based pronoun resolution system.", "labels": [], "entities": [{"text": "FHMM-based pronoun resolution", "start_pos": 41, "end_pos": 70, "type": "TASK", "confidence": 0.706336518128713}]}], "datasetContent": [{"text": "In this research, we used the ACE corpus (Phase 2) 1 for evaluation.", "labels": [], "entities": [{"text": "ACE corpus (Phase 2) 1", "start_pos": 30, "end_pos": 52, "type": "DATASET", "confidence": 0.8914089032581874}]}, {"text": "The development of this corpus involved two stages.", "labels": [], "entities": []}, {"text": "The first stage is called EDT (entity detection and tracking) while the second stage is called RDC (relation detection and characterization).", "labels": [], "entities": [{"text": "EDT", "start_pos": 26, "end_pos": 29, "type": "METRIC", "confidence": 0.9174239635467529}, {"text": "entity detection and tracking", "start_pos": 31, "end_pos": 60, "type": "TASK", "confidence": 0.813201293349266}, {"text": "RDC", "start_pos": 95, "end_pos": 98, "type": "METRIC", "confidence": 0.8698865175247192}, {"text": "relation detection and characterization", "start_pos": 100, "end_pos": 139, "type": "TASK", "confidence": 0.8187870234251022}]}, {"text": "All markables have named entity types such as FACILITY, GPE (geopolitical entity), PERSON, LOCATION, ORGANIZATION, PERSON, VEHI-CLE and WEAPONS, which were annotated in the first stage.", "labels": [], "entities": [{"text": "FACILITY", "start_pos": 46, "end_pos": 54, "type": "METRIC", "confidence": 0.9011573791503906}, {"text": "GPE", "start_pos": 56, "end_pos": 59, "type": "METRIC", "confidence": 0.9073129296302795}, {"text": "PERSON", "start_pos": 83, "end_pos": 89, "type": "METRIC", "confidence": 0.9013254642486572}, {"text": "LOCATION", "start_pos": 91, "end_pos": 99, "type": "METRIC", "confidence": 0.904920220375061}, {"text": "ORGANIZATION", "start_pos": 101, "end_pos": 113, "type": "METRIC", "confidence": 0.9751031994819641}, {"text": "PERSON", "start_pos": 115, "end_pos": 121, "type": "METRIC", "confidence": 0.9153397083282471}, {"text": "VEHI-CLE", "start_pos": 123, "end_pos": 131, "type": "METRIC", "confidence": 0.8964591026306152}, {"text": "WEAPONS", "start_pos": 136, "end_pos": 143, "type": "METRIC", "confidence": 0.8253887295722961}]}, {"text": "In the second stage, relations between named entities were annotated.", "labels": [], "entities": []}, {"text": "This corpus include three parts, composed of different genres: newspaper texts (NPAPER), newswire texts (NWIRE) and broadcasted news (BNEWS).", "labels": [], "entities": []}, {"text": "Each of these is split into a train part and a devtest part.", "labels": [], "entities": []}, {"text": "For the train part, there are 76, 130 and 217 articles in NPA-PER, NWIRE and BNEWS respectively while for the test part, there are 17, 29 and 51 articles respectively.", "labels": [], "entities": [{"text": "NPA-PER", "start_pos": 58, "end_pos": 65, "type": "DATASET", "confidence": 0.929894208908081}, {"text": "NWIRE", "start_pos": 67, "end_pos": 72, "type": "METRIC", "confidence": 0.5377656817436218}, {"text": "BNEWS", "start_pos": 77, "end_pos": 82, "type": "METRIC", "confidence": 0.9708836078643799}]}, {"text": "Though the number of articles are quite different for three genres, the total number of words are almost the same.", "labels": [], "entities": []}, {"text": "Namely, the length of NPAPER is much longer than BNEWS (about 1200 words, 800 word and 500 words respectively for three genres).", "labels": [], "entities": [{"text": "NPAPER", "start_pos": 22, "end_pos": 28, "type": "DATASET", "confidence": 0.7271848917007446}, {"text": "BNEWS", "start_pos": 49, "end_pos": 54, "type": "METRIC", "confidence": 0.5372902750968933}]}, {"text": "The longer articles involve longer coreference chains.", "labels": [], "entities": []}, {"text": "Following the common practice, we used the devtest material only for testing.", "labels": [], "entities": []}, {"text": "Progress during the development phase was estimated only by using cross-validation on the training set for the BNEWS section.", "labels": [], "entities": [{"text": "BNEWS section", "start_pos": 111, "end_pos": 124, "type": "DATASET", "confidence": 0.9165383279323578}]}, {"text": "In order to make comparisons with publications which used the same corpus, we make efforts to setup identical conditions for our experiments.", "labels": [], "entities": []}, {"text": "The main point of comparison is, which was similar in that it described anew type of coreference resolver using simple features.", "labels": [], "entities": [{"text": "coreference resolver", "start_pos": 85, "end_pos": 105, "type": "TASK", "confidence": 0.8957796692848206}]}, {"text": "Therefore, similar to their practice, we use all forms of personal and possessive pronouns that were annotated as ACE \"markables\".", "labels": [], "entities": []}, {"text": "Namely, pronouns associated with named entity types could be used in this system.", "labels": [], "entities": []}, {"text": "In experiments, we also used true ACE mentions as they did.", "labels": [], "entities": []}, {"text": "This means that pleonastics and references to eventualities or to non-ACE entities are not included in our experiments either.", "labels": [], "entities": []}, {"text": "In all, 7263 referential pronouns in training data set and 1866 in testing data set are found in all three genres.", "labels": [], "entities": [{"text": "training data set", "start_pos": 37, "end_pos": 54, "type": "DATASET", "confidence": 0.7870066861311594}, {"text": "testing data set", "start_pos": 67, "end_pos": 83, "type": "DATASET", "confidence": 0.8190353910128275}]}, {"text": "They have results of three different systems: SCC (single candidate classifier), TCC (twin candidate classifier) and RK (ranking).", "labels": [], "entities": [{"text": "TCC", "start_pos": 81, "end_pos": 84, "type": "METRIC", "confidence": 0.8851172924041748}, {"text": "RK", "start_pos": 117, "end_pos": 119, "type": "METRIC", "confidence": 0.9665210247039795}]}, {"text": "Besides the three and our own system, we also report results of emPronouns, which is an unsupervised system based on a recently published paper.", "labels": [], "entities": [{"text": "emPronouns", "start_pos": 64, "end_pos": 74, "type": "DATASET", "confidence": 0.8387796878814697}]}, {"text": "We select this unsupervised system for two reasons.", "labels": [], "entities": []}, {"text": "Firstly, emPronouns is a publicly available system with high accuracy in pronoun resolution.", "labels": [], "entities": [{"text": "emPronouns", "start_pos": 9, "end_pos": 19, "type": "DATASET", "confidence": 0.9467082023620605}, {"text": "accuracy", "start_pos": 61, "end_pos": 69, "type": "METRIC", "confidence": 0.9981489181518555}]}, {"text": "Secondly, it is necessary for us to demonstrate our system has strong empirical superiority over unsupervised ones.", "labels": [], "entities": []}, {"text": "In testing, we also used the OPNLP Named Entity Recognizer to tag the test corpus.", "labels": [], "entities": [{"text": "OPNLP Named Entity Recognizer", "start_pos": 29, "end_pos": 58, "type": "DATASET", "confidence": 0.680857926607132}]}, {"text": "During training, besides coreference annotation itself, the part of speech, dependencies between words and named entities, gender, number and index are extracted using relative frequency estimation to train models for the coreference resolution system.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 222, "end_pos": 244, "type": "TASK", "confidence": 0.9327823221683502}]}, {"text": "Inputs for testing are the plain text and the trained model files.", "labels": [], "entities": []}, {"text": "The entity buffer used in these experiments kept track of only the six most recent mentions.", "labels": [], "entities": []}, {"text": "The result of this process is an annotation of the headword of every noun phrase denoting it as a mention.", "labels": [], "entities": []}, {"text": "In addition, this system does not do anaphoricity detection, so the antecedent operation for non-anaphora pronoun it is set to be none.", "labels": [], "entities": [{"text": "anaphoricity detection", "start_pos": 37, "end_pos": 59, "type": "TASK", "confidence": 0.7013600021600723}]}, {"text": "Finally, the system does not yet model cataphora, about 10 cataphoric pronouns in the testing data which are all counted as wrong.", "labels": [], "entities": []}], "tableCaptions": []}