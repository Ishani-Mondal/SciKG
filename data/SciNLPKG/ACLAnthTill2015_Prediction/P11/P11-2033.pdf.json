{"title": [{"text": "Transition-based Dependency Parsing with Rich Non-local Features", "labels": [], "entities": [{"text": "Dependency Parsing", "start_pos": 17, "end_pos": 35, "type": "TASK", "confidence": 0.7707270979881287}]}], "abstractContent": [{"text": "Transition-based dependency parsers generally use heuristic decoding algorithms but can accommodate arbitrarily rich feature representations.", "labels": [], "entities": [{"text": "Transition-based dependency parsers", "start_pos": 0, "end_pos": 35, "type": "TASK", "confidence": 0.661231925090154}]}, {"text": "In this paper, we show that we can improve the accuracy of such parsers by considering even richer feature sets than those employed in previous systems.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 47, "end_pos": 55, "type": "METRIC", "confidence": 0.9987866282463074}]}, {"text": "In the standard Penn Treebank setup, our novel features improve attachment score form 91.4% to 92.9%, giving the best results so far for transition-based parsing and rivaling the best results overall.", "labels": [], "entities": [{"text": "Penn Treebank", "start_pos": 16, "end_pos": 29, "type": "DATASET", "confidence": 0.9895031452178955}, {"text": "attachment score", "start_pos": 64, "end_pos": 80, "type": "METRIC", "confidence": 0.9612257182598114}, {"text": "transition-based parsing", "start_pos": 137, "end_pos": 161, "type": "TASK", "confidence": 0.678388237953186}]}, {"text": "For the Chinese Treebank, they give a signficant improvement of the state of the art.", "labels": [], "entities": [{"text": "Chinese Treebank", "start_pos": 8, "end_pos": 24, "type": "DATASET", "confidence": 0.9833855330944061}]}, {"text": "An open source release of our parser is freely available.", "labels": [], "entities": []}], "introductionContent": [{"text": "Transition-based dependency parsing) utilize a deterministic shift-reduce process for making structural predictions.", "labels": [], "entities": [{"text": "Transition-based dependency parsing", "start_pos": 0, "end_pos": 35, "type": "TASK", "confidence": 0.61811230580012}]}, {"text": "Compared to graph-based dependency parsing, it typically offers linear time complexity and the comparative freedom to define non-local features, as exemplified by the comparison between MaltParser and MSTParser (.", "labels": [], "entities": [{"text": "graph-based dependency parsing", "start_pos": 12, "end_pos": 42, "type": "TASK", "confidence": 0.7309881846110026}, {"text": "MSTParser", "start_pos": 201, "end_pos": 210, "type": "DATASET", "confidence": 0.8802435398101807}]}, {"text": "Recent research has addressed two potential disadvantages of systems like MaltParser.", "labels": [], "entities": [{"text": "MaltParser", "start_pos": 74, "end_pos": 84, "type": "DATASET", "confidence": 0.9392613768577576}]}, {"text": "In the aspect of decoding, beam-search () and partial dynamic-programming) have been applied to improve upon greedy one-best search, and positive results were reported.", "labels": [], "entities": []}, {"text": "In the aspect of training, global structural learning has been used to replace local learning on each decision (, although the effect of global learning has not been separated out and studied alone.", "labels": [], "entities": []}, {"text": "In this short paper, we study a third aspect in a statistical system: feature definition.", "labels": [], "entities": [{"text": "feature definition", "start_pos": 70, "end_pos": 88, "type": "TASK", "confidence": 0.7035849392414093}]}, {"text": "Representing the type of information a statistical system uses to make predictions, feature templates can be one of the most important factors determining parsing accuracy.", "labels": [], "entities": [{"text": "parsing", "start_pos": 155, "end_pos": 162, "type": "TASK", "confidence": 0.9673308730125427}, {"text": "accuracy", "start_pos": 163, "end_pos": 171, "type": "METRIC", "confidence": 0.8613705635070801}]}, {"text": "Various recent attempts have been made to include non-local features into graph-based dependency parsing.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 86, "end_pos": 104, "type": "TASK", "confidence": 0.6647537052631378}]}, {"text": "Transitionbased parsing, by contrast, can easily accommodate arbitrarily complex representations involving nonlocal features.", "labels": [], "entities": []}, {"text": "Complex non-local features, such as bracket matching and rhythmic patterns, are used in transition-based constituency parsing), and most transitionbased dependency parsers incorporate some nonlocal features, but current practice is nevertheless to use a rather restricted set of features, as exemplified by the default feature models in MaltParser ().", "labels": [], "entities": [{"text": "bracket matching", "start_pos": 36, "end_pos": 52, "type": "TASK", "confidence": 0.7380647957324982}, {"text": "transition-based constituency parsing", "start_pos": 88, "end_pos": 125, "type": "TASK", "confidence": 0.5994734962781271}]}, {"text": "We explore considerably richer feature representations and show that they improve parsing accuracy significantly.", "labels": [], "entities": [{"text": "parsing", "start_pos": 82, "end_pos": 89, "type": "TASK", "confidence": 0.9817319512367249}, {"text": "accuracy", "start_pos": 90, "end_pos": 98, "type": "METRIC", "confidence": 0.9486740827560425}]}, {"text": "In standard experiments using the Penn Treebank, our parser gets an unlabeled attachment score of 92.9%, which is the best result achieved with a transition-based parser and comparable to the state of the art.", "labels": [], "entities": [{"text": "Penn Treebank", "start_pos": 34, "end_pos": 47, "type": "DATASET", "confidence": 0.9942857027053833}, {"text": "unlabeled attachment score", "start_pos": 68, "end_pos": 94, "type": "METRIC", "confidence": 0.7058183352152506}]}, {"text": "For the Chinese Treebank, our parser gets a score of 86.0%, the best reported result so far.", "labels": [], "entities": [{"text": "Chinese Treebank", "start_pos": 8, "end_pos": 24, "type": "DATASET", "confidence": 0.9881977438926697}]}], "datasetContent": [{"text": "Our experiments were performed using the Penn Treebank (PTB) and Chinese Treebank (CTB) data.", "labels": [], "entities": [{"text": "Penn Treebank (PTB)", "start_pos": 41, "end_pos": 60, "type": "DATASET", "confidence": 0.9640387177467347}, {"text": "Chinese Treebank (CTB) data", "start_pos": 65, "end_pos": 92, "type": "DATASET", "confidence": 0.9522480467955271}]}, {"text": "We follow the standard approach to split PTB3, using sections 2 -21 for training, section 22 for development and 23 for final testing.", "labels": [], "entities": [{"text": "split", "start_pos": 35, "end_pos": 40, "type": "TASK", "confidence": 0.9482321739196777}, {"text": "PTB3", "start_pos": 41, "end_pos": 45, "type": "DATASET", "confidence": 0.6878695487976074}]}, {"text": "Bracketed sentences from PTB were transformed into dependency formats using the Penn2Malt tool.", "labels": [], "entities": [{"text": "Penn2Malt", "start_pos": 80, "end_pos": 89, "type": "DATASET", "confidence": 0.9726256132125854}]}, {"text": "Following, we assign POS-tags to the training data using ten-way jackknifing.", "labels": [], "entities": []}, {"text": "We used our implementation of the Collins (2002) tagger (with 97.3% accuracy on a standard Penn Treebank test) to perform POS-tagging.", "labels": [], "entities": [{"text": "Collins (2002) tagger", "start_pos": 34, "end_pos": 55, "type": "DATASET", "confidence": 0.8324830055236816}, {"text": "accuracy", "start_pos": 68, "end_pos": 76, "type": "METRIC", "confidence": 0.9956510663032532}, {"text": "Penn Treebank test", "start_pos": 91, "end_pos": 109, "type": "DATASET", "confidence": 0.9898280700047811}]}, {"text": "For all experiments, we set the beam size to 64 for the parser, and report unlabeled and labeled attachment scores (UAS, LAS) and unlabeled exact match (UEM) for evaluation.: Final test accuracies for English.", "labels": [], "entities": [{"text": "attachment scores (UAS, LAS)", "start_pos": 97, "end_pos": 125, "type": "METRIC", "confidence": 0.8217388561793736}, {"text": "exact match (UEM)", "start_pos": 140, "end_pos": 157, "type": "METRIC", "confidence": 0.9563429713249206}, {"text": "Final test accuracies", "start_pos": 175, "end_pos": 196, "type": "METRIC", "confidence": 0.7315996885299683}]}, {"text": "UAS = unlabeled attachment score; UEM = unlabeled exact match; LAS = labeled attachment score.", "labels": [], "entities": [{"text": "UAS = unlabeled attachment score", "start_pos": 0, "end_pos": 32, "type": "METRIC", "confidence": 0.6772177755832672}, {"text": "UEM", "start_pos": 34, "end_pos": 37, "type": "METRIC", "confidence": 0.9577224850654602}, {"text": "exact match", "start_pos": 50, "end_pos": 61, "type": "METRIC", "confidence": 0.8817690014839172}, {"text": "LAS = labeled attachment score", "start_pos": 63, "end_pos": 93, "type": "METRIC", "confidence": 0.7683550000190735}]}, {"text": "shows the effect of new features on the development test data for English.", "labels": [], "entities": []}, {"text": "We start with the baseline features in, and incrementally add the distance, valency, unigram, third-order and label set feature templates in.", "labels": [], "entities": []}, {"text": "Each group of new feature templates improved the accuracies over the previous system, and the final accuracy with all new features was 93.14% in unlabeled attachment score.", "labels": [], "entities": [{"text": "accuracies", "start_pos": 49, "end_pos": 59, "type": "METRIC", "confidence": 0.9686030745506287}, {"text": "accuracy", "start_pos": 100, "end_pos": 108, "type": "METRIC", "confidence": 0.9986248016357422}]}, {"text": "shows the final test results of our parser for English.", "labels": [], "entities": []}, {"text": "We include in the table results from the pure transition-based parser of (row 'Z&C08 transition'), the dynamic-programming arc-standard parser of Huang and Sagae (2010) (row 'H&S10'), and graphbased models including MSTParser), the baseline feature parser of (row 'K08 baeline'), and the two models of.", "labels": [], "entities": []}, {"text": "Our extended parser significantly outperformed the baseline parser, achiev-", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 3: The effect of new features on the development  set for English. UAS = unlabeled attachment score; UEM  = unlabeled exact match.", "labels": [], "entities": [{"text": "UAS = unlabeled attachment score", "start_pos": 74, "end_pos": 106, "type": "METRIC", "confidence": 0.7315228104591369}, {"text": "UEM", "start_pos": 108, "end_pos": 111, "type": "METRIC", "confidence": 0.9539986848831177}, {"text": "exact match", "start_pos": 125, "end_pos": 136, "type": "METRIC", "confidence": 0.9307511746883392}]}, {"text": " Table 4: Final test accuracies for English. UAS = unla- beled attachment score; UEM = unlabeled exact match;  LAS = labeled attachment score.", "labels": [], "entities": [{"text": "Final test accuracies", "start_pos": 10, "end_pos": 31, "type": "METRIC", "confidence": 0.7836248675982157}, {"text": "UAS", "start_pos": 45, "end_pos": 48, "type": "METRIC", "confidence": 0.9926738142967224}, {"text": "unla- beled attachment score", "start_pos": 51, "end_pos": 79, "type": "METRIC", "confidence": 0.7809066772460938}, {"text": "UEM = unlabeled exact match", "start_pos": 81, "end_pos": 108, "type": "METRIC", "confidence": 0.7624545216560363}, {"text": "LAS = labeled attachment score", "start_pos": 111, "end_pos": 141, "type": "METRIC", "confidence": 0.7490285396575928}]}]}