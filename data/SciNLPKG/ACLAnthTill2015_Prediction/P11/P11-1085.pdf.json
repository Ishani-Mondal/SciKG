{"title": [{"text": "Learning to Transform and Select Elementary Trees for Improved Syntax-based Machine Translations", "labels": [], "entities": [{"text": "Syntax-based Machine Translations", "start_pos": 63, "end_pos": 96, "type": "TASK", "confidence": 0.5923130611578623}]}], "abstractContent": [{"text": "We propose a novel technique of learning how to transform the source parse trees to improve the translation qualities of syntax-based translation models using synchronous context-free grammars.", "labels": [], "entities": []}, {"text": "We transform the source tree phrasal structure into a set of simpler structures, expose such decisions to the decoding process, and find the least expensive transformation operation to better model word reordering.", "labels": [], "entities": []}, {"text": "In particular, we integrate synchronous bi-narizations, verb regrouping, removal of redundant parse nodes, and incorporate a few important features such as translation boundaries.", "labels": [], "entities": []}, {"text": "We learn the structural preferences from the data in a generative framework.", "labels": [], "entities": []}, {"text": "The syntax-based translation system integrating the proposed techniques outperforms the best Arabic-English unconstrained system in NIST-08 evaluations by 1.3 absolute BLEU, which is statistically significant.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 168, "end_pos": 172, "type": "METRIC", "confidence": 0.9960177540779114}]}], "introductionContent": [{"text": "Most syntax-based machine translation models with synchronous context free grammar (SCFG) have been relying on the off-the-shelf monolingual parse structures to learn the translation equivalences for string-to-tree, tree-to-string or tree-to-tree grammars.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 18, "end_pos": 37, "type": "TASK", "confidence": 0.6896984279155731}]}, {"text": "However, stateof-the-art monolingual parsers are not necessarily well suited for machine translation in terms of both labels and chunks/brackets.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 81, "end_pos": 100, "type": "TASK", "confidence": 0.7099888771772385}]}, {"text": "For instance, in Arabic-to-English translation, we find only 45.5% of Arabic NP-SBJ structures are mapped to the English NP-SBJ with machine alignment and parse trees, and only 60.1% of NP-SBJs are mapped with human alignment and parse trees as in \u00a7 2.", "labels": [], "entities": []}, {"text": "The chunking is of more concern; at best only 57.4% source chunking decisions are translated contiguously on the target side.", "labels": [], "entities": [{"text": "chunking", "start_pos": 4, "end_pos": 12, "type": "TASK", "confidence": 0.9714033603668213}]}, {"text": "To translate the rest of the chunks one has to frequently break the original structures.", "labels": [], "entities": []}, {"text": "The main issue lies in the strong assumption behind SCFG-style nonterminals -each nonterminal (or variable) assumes a source chunk should be rewritten into a contiguous chunk in the target.", "labels": [], "entities": []}, {"text": "Without integrating techniques to modify the parse structures, the SCFGs are not to be effective even for translating NP-SBJ in linguistically distant language-pairs such as Arabic-English.", "labels": [], "entities": []}, {"text": "Such problems have been noted in previous literature. and used broken syntactic fragments to augment their grammars to increase the rule coverage; while we learn optimal tree fragments transformed from the original ones via a generative framework, they enumerate the fragments available from the original trees without learning process.", "labels": [], "entities": []}, {"text": "introduced parse forests to blur the chunking decisions to a certain degree, to expand search space and reduce parsing errors from 1-best trees ( ; others tried to use the parse trees as soft constraints on top of unlabeled grammar such as) without sufficiently leveraging rich tree context.", "labels": [], "entities": []}, {"text": "Recent works tried more complex approaches to integrate both parsing and decoding in one single search space as in (, at the cost of huge search space.", "labels": [], "entities": []}, {"text": "In (), combinations of tree forest and tree-sequence () based approaches were carried out by adding pseudo nodes and hyper edges into the forest.", "labels": [], "entities": []}, {"text": "Overall, the forest-based translation can reduce the risks from upstream parsing errors and expand the search space, but it cannot sufficiently address the syntactic divergences between various language-pairs.", "labels": [], "entities": []}, {"text": "The tree sequence approach adds pseudo nodes and hyper edges to the forest, which makes the forest even denser and harder for navigation and search.", "labels": [], "entities": []}, {"text": "As trees thrive in the search space, especially with the pseudo nodes and edges being added to the already dense forest, it is becoming harder to wade through the deep forest for the best derivation path out.", "labels": [], "entities": []}, {"text": "We propose to simplify suitable subtrees to a reasonable level, at which the correct reordering can be easily identified.", "labels": [], "entities": []}, {"text": "The transformed structure should be frequent enough to have rich statistics for learning a model.", "labels": [], "entities": []}, {"text": "Instead of creating pseudo nodes and edges and make the forest dense, we transform a tree with a few simple operators; only meaningful frontier nodes, context nodes and edges are kept to induce the correct reordering; such operations also enable the model to share the statistics among all similar subtrees.", "labels": [], "entities": []}, {"text": "On the basis of our study on investigating the language divergence between Arabic-English with human aligned and parsed data, we integrate several simple statistical operations, to transform parse trees adaptively to serve the translation purpose better.", "labels": [], "entities": []}, {"text": "For each source span in the given sentence, a subgraph, corresponding to an elementary tree (in Eqn.", "labels": [], "entities": []}, {"text": "1), is proposed for PSCFG translation; we apply a few operators to transform the subgraph into some frequent subgraphs seen in the whole training data, and thus introduce alternative similar translational equivalences to explain the same source span with enriched statistics and features.", "labels": [], "entities": [{"text": "PSCFG translation", "start_pos": 20, "end_pos": 37, "type": "TASK", "confidence": 0.9521556496620178}]}, {"text": "For instance, if we regroup two adjacent nodes IV and NP-SBJ in the tree, we can obtain the correct reordering pattern for verb-subject order, which is not easily available otherwise.", "labels": [], "entities": []}, {"text": "By finding a set of similar elementary trees derived from the original elementary trees, statistics can be shared for robust learning.", "labels": [], "entities": []}, {"text": "We also investigate the features using the context beyond the phrasal subtree.", "labels": [], "entities": []}, {"text": "This is to further disambiguate the transformed subgraphs so that informative neighboring nodes and edges can influence the reordering preferences for each of the transformed trees.", "labels": [], "entities": []}, {"text": "For instance, at the beginning and end of a sentence, we do not expect dramatic long distance reordering to happen; or under SBAR context, the clause may prefer monotonic reordering for verb and subject.", "labels": [], "entities": []}, {"text": "Such boundary features were treated as hard constraints in previous literature in terms of re-labeling () or re-structuring (.", "labels": [], "entities": []}, {"text": "The boundary cases were not addressed in the previous literature for trees, and here we include them in our feature sets for learning a MaxEnt model to predict the transformations.", "labels": [], "entities": []}, {"text": "We integrate the neighboring context of the subgraph in our transformation preference predictions, and this improve translation qualities further.", "labels": [], "entities": []}, {"text": "The rest of the paper is organized as follows: in section 2, we analyze the projectable structures using human aligned and parsed data, to identify the problems for SCFG in general; in section 3, our proposed approach is explained in detail, including the statistical operators using a MaxEnt model; in section 4, we illustrate the integration of the proposed approach in our decoder; in section 5, we present experimental results; in section 6, we conclude with discussions and future work.", "labels": [], "entities": []}], "datasetContent": [{"text": "In our experiments, we built our system using most of the parallel training data available to us: 250M Arabic running tokens, corresponding to the \"unconstrained\" condition in NIST-MT08.", "labels": [], "entities": [{"text": "NIST-MT08", "start_pos": 176, "end_pos": 185, "type": "DATASET", "confidence": 0.9490893483161926}]}, {"text": "We chose the testsets of newswire and weblog genres from MT08 and DEV10 1 . In particular, we choose MT08 to enable the comparison of our results to the reported results in NIST evaluations.", "labels": [], "entities": [{"text": "MT08", "start_pos": 57, "end_pos": 61, "type": "DATASET", "confidence": 0.9692779183387756}, {"text": "DEV10 1", "start_pos": 66, "end_pos": 73, "type": "DATASET", "confidence": 0.8606674671173096}, {"text": "MT08", "start_pos": 101, "end_pos": 105, "type": "DATASET", "confidence": 0.9574609994888306}, {"text": "NIST", "start_pos": 173, "end_pos": 177, "type": "DATASET", "confidence": 0.8850340247154236}]}, {"text": "Our training and test data is summarized in.", "labels": [], "entities": []}, {"text": "For testings, we have 129,908 tokens in our testsets.", "labels": [], "entities": []}, {"text": "For language models (LM), we used 6-gram LM trained with 10.3 billion English tokens, and also a shrinkage-based LM (Chen, 2009) -\"ModelM\") with 150 word-clusters learnt from 2.1 million tokens.", "labels": [], "entities": []}, {"text": "From the parallel data, we extract phrase pairs(blocks) and elementary trees to string grammar in various configurations: basic tree-to-string rules (Tr2str), elementary tree-to-string rules with boundaries \u00af t(elm2str+ \u00af m), and with both \u00af t and \u00af m (elm2str+ \u00af t + \u00af m).", "labels": [], "entities": [{"text": "Tr2str", "start_pos": 150, "end_pos": 156, "type": "METRIC", "confidence": 0.8761282563209534}]}, {"text": "This is to evaluate the operators' effects at different levels for decoding.", "labels": [], "entities": []}, {"text": "To learn our MaxEnt models defined in \u00a7 3.3, we collect the events during extracting elm2str grammar in training time, and learn the model using improved iterative scaling.", "labels": [], "entities": []}, {"text": "We use the same training data as that used in training our Arabic parser.", "labels": [], "entities": []}, {"text": "There are 16 thousand human parse trees with human alignment; additional 1 thousand human parse and aligned sent-pairs are used as unseen test set to verify our MaxEnt models and parsers.", "labels": [], "entities": []}, {"text": "For our Arabic parser, we have a labeled F-measure of 78.4%, and POS tag accuracy 94.9%.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 41, "end_pos": 50, "type": "METRIC", "confidence": 0.9064038395881653}, {"text": "POS tag accuracy", "start_pos": 65, "end_pos": 81, "type": "METRIC", "confidence": 0.7975406448046366}]}, {"text": "In particular, we'll evaluate model p c ( \u00af t|\u03b3, \u00af m) in Eqn.", "labels": [], "entities": []}, {"text": "3 for predicting the translation boundaries in \u00a7 3.5.3 for projectable spans as detailed in \u00a7 5.1.", "labels": [], "entities": []}, {"text": "Our decoder (Zhao and Al-Onaizan, 2008) supports grammars including monotone, ITG, Hiero, tree-tostring, string-to-tree, and several mixtures of them (.", "labels": [], "entities": []}, {"text": "We used 19 feature functions, mainly from those used in phrase-based decoder like Moses (, including two language models (one fora 6-gram LM, one for ModelM, one brevity penalty, IBM Model-1 () style alignment probabilities in both directions, relative frequency in both directions, word/rule counts, content/function word mismatch, together with features on tr2str rule probabilities.", "labels": [], "entities": []}, {"text": "We use BLEU () and TER () to evaluate translation qualities.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 7, "end_pos": 11, "type": "METRIC", "confidence": 0.9991118311882019}, {"text": "TER", "start_pos": 19, "end_pos": 22, "type": "METRIC", "confidence": 0.9988810420036316}]}, {"text": "Our baseline used basic elementary tree to string grammar without any manipulations and boundary markers in the model,  and we achieved a BLEUr4n4 55.01 for MT08-NW, or a cased BLEU of 53.31, which is close to the best officially reported result 53.85 for unconstrained systems.", "labels": [], "entities": [{"text": "BLEUr4n4", "start_pos": 138, "end_pos": 146, "type": "METRIC", "confidence": 0.9991238713264465}, {"text": "MT08-NW", "start_pos": 157, "end_pos": 164, "type": "DATASET", "confidence": 0.7888801097869873}, {"text": "BLEU", "start_pos": 177, "end_pos": 181, "type": "METRIC", "confidence": 0.9982465505599976}]}, {"text": "We expose the statistical decisions in Eqn.", "labels": [], "entities": [{"text": "Eqn.", "start_pos": 39, "end_pos": 43, "type": "DATASET", "confidence": 0.9557237029075623}]}, {"text": "3 as the rule probability as one of the 19 dimensions, and use Simplex Downhill algorithm with Armijo line search () to optimize the weight vector for decoding.", "labels": [], "entities": []}, {"text": "The algorithm moves all dimensions at the same time, and empirically achieved more stable results than MER) in many of our experiments.", "labels": [], "entities": [{"text": "MER", "start_pos": 103, "end_pos": 106, "type": "METRIC", "confidence": 0.9453508853912354}]}], "tableCaptions": [{"text": " Table 1: The labeled and unlabeled F-measures for projecting  the source nodes onto the target side via alignments and parse  trees; unlabeled F-measures show the bracketing accuracies for  translating a source span contiguously. H: human, M: machine.", "labels": [], "entities": []}, {"text": " Table 7: Training and test data; using all training parallel training data for 4 test sets", "labels": [], "entities": []}, {"text": " Table 8. It showed our Max- Ent model is very accurate using human trees: 94.5% of  accuracy, and about 84.7% of accuracy for using the ma- chine parsed trees. Our accuracies are higher compared  with the 71+% accuracies reported in (Xiong et al., 2010)  for their phrasal decoder.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 85, "end_pos": 93, "type": "METRIC", "confidence": 0.9994475245475769}, {"text": "accuracy", "start_pos": 114, "end_pos": 122, "type": "METRIC", "confidence": 0.9992431402206421}, {"text": "accuracies", "start_pos": 165, "end_pos": 175, "type": "METRIC", "confidence": 0.9984032511711121}]}, {"text": " Table 8: Accuracies of predicting projectable structures", "labels": [], "entities": [{"text": "Accuracies", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.9943965673446655}, {"text": "predicting projectable", "start_pos": 24, "end_pos": 46, "type": "TASK", "confidence": 0.8985778391361237}]}, {"text": " Table 9: The predicted projectable structures in MT08-NW", "labels": [], "entities": [{"text": "MT08-NW", "start_pos": 50, "end_pos": 57, "type": "TASK", "confidence": 0.5642678141593933}]}, {"text": " Table 10: TER and BLEU for MT08-NW, using only \u00af  t(\u03b3)", "labels": [], "entities": [{"text": "TER", "start_pos": 11, "end_pos": 14, "type": "METRIC", "confidence": 0.9991693496704102}, {"text": "BLEU", "start_pos": 19, "end_pos": 23, "type": "METRIC", "confidence": 0.9991501569747925}, {"text": "MT08-NW", "start_pos": 28, "end_pos": 35, "type": "DATASET", "confidence": 0.5566888451576233}]}, {"text": " Table 11: TER and BLEU for MT08-NW, using \u00af  t(\u03b3, \u00af  m).", "labels": [], "entities": [{"text": "TER", "start_pos": 11, "end_pos": 14, "type": "METRIC", "confidence": 0.9991557598114014}, {"text": "BLEU", "start_pos": 19, "end_pos": 23, "type": "METRIC", "confidence": 0.9991877675056458}, {"text": "MT08-NW", "start_pos": 28, "end_pos": 35, "type": "DATASET", "confidence": 0.6213415265083313}]}, {"text": " Table 12: BLEU scores on various test sets; comparing elementary tree-to-string grammar (tr2str), transformation of the trees  (elm2str+ \u00af  t), using the neighboring function for boundaries ( elm2str+ \u00af  m), and combination of all together ( elm2str+ \u00af  t(\u03b3, \u00af  m)).  MT08-NW and MT08-WB have four references; Dev10-WB has three references, and Dev10-NW has one reference. BLEUn4  were reported.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 11, "end_pos": 15, "type": "METRIC", "confidence": 0.9958966970443726}, {"text": "MT08-NW", "start_pos": 269, "end_pos": 276, "type": "DATASET", "confidence": 0.9281476736068726}, {"text": "MT08-WB", "start_pos": 281, "end_pos": 288, "type": "DATASET", "confidence": 0.9060682058334351}, {"text": "Dev10-NW", "start_pos": 346, "end_pos": 354, "type": "DATASET", "confidence": 0.9454650282859802}, {"text": "BLEUn4", "start_pos": 374, "end_pos": 380, "type": "METRIC", "confidence": 0.9929920434951782}]}]}