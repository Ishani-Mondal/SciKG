{"title": [{"text": "Optimal and Syntactically-Informed Decoding for Monolingual Phrase-Based Alignment", "labels": [], "entities": [{"text": "Monolingual Phrase-Based Alignment", "start_pos": 48, "end_pos": 82, "type": "TASK", "confidence": 0.5858555237452189}]}], "abstractContent": [{"text": "The task of aligning corresponding phrases across two related sentences is an important component of approaches for natural language problems such as textual inference, paraphrase detection and text-to-text generation.", "labels": [], "entities": [{"text": "paraphrase detection", "start_pos": 169, "end_pos": 189, "type": "TASK", "confidence": 0.9095049202442169}, {"text": "text-to-text generation", "start_pos": 194, "end_pos": 217, "type": "TASK", "confidence": 0.724625751376152}]}, {"text": "In this work, we examine a state-of-the-art struc-tured prediction model for the alignment task which uses a phrase-based representation and is forced to decode alignments using an approximate search approach.", "labels": [], "entities": []}, {"text": "We propose instead a straightforward exact decoding technique based on integer linear programming that yields order-of-magnitude improvements in decoding speed.", "labels": [], "entities": []}, {"text": "This ILP-based decoding strategy permits us to consider syntactically-informed constraints on alignments which significantly increase the precision of the model.", "labels": [], "entities": [{"text": "precision", "start_pos": 138, "end_pos": 147, "type": "METRIC", "confidence": 0.9989350438117981}]}], "introductionContent": [{"text": "Natural language processing problems frequently involve scenarios in which a pair or group of related sentences need to be aligned to each other, establishing links between their common words or phrases.", "labels": [], "entities": [{"text": "Natural language processing", "start_pos": 0, "end_pos": 27, "type": "TASK", "confidence": 0.689924438794454}]}, {"text": "For instance, most approaches for natural language inference (NLI) rely on alignment techniques to establish the overlap between the given premise and a hypothesis before determining if the former entails the latter.", "labels": [], "entities": [{"text": "natural language inference (NLI)", "start_pos": 34, "end_pos": 66, "type": "TASK", "confidence": 0.8247889876365662}]}, {"text": "Such monolingual alignment techniques are also frequently employed in systems for paraphrase generation, multi-document summarization, sentence fusion and question answering.", "labels": [], "entities": [{"text": "paraphrase generation", "start_pos": 82, "end_pos": 103, "type": "TASK", "confidence": 0.8926936388015747}, {"text": "multi-document summarization", "start_pos": 105, "end_pos": 133, "type": "TASK", "confidence": 0.661272794008255}, {"text": "sentence fusion", "start_pos": 135, "end_pos": 150, "type": "TASK", "confidence": 0.7731470763683319}, {"text": "question answering", "start_pos": 155, "end_pos": 173, "type": "TASK", "confidence": 0.9008655846118927}]}, {"text": "Previous work has presented a phrase-based monolingual aligner for NLI (MANLI) that has been shown to significantly outperform a token-based NLI aligner () as well as popular alignment techniques borrowed from machine translation).", "labels": [], "entities": [{"text": "machine translation", "start_pos": 210, "end_pos": 229, "type": "TASK", "confidence": 0.7152927368879318}]}, {"text": "However, MANLI's use of a phrase-based alignment representation appears to pose a challenge to the decoding task, i.e. the task of recovering the highest-scoring alignment under some parameters.", "labels": [], "entities": [{"text": "MANLI", "start_pos": 9, "end_pos": 14, "type": "DATASET", "confidence": 0.8358243107795715}]}, {"text": "Consequently, employ a stochastic search algorithm to decode alignments approximately while remaining consistent with regard to phrase segmentation.", "labels": [], "entities": [{"text": "phrase segmentation", "start_pos": 128, "end_pos": 147, "type": "TASK", "confidence": 0.7565540671348572}]}, {"text": "In this paper, we propose an exact decoding technique for MANLI that retrieves the globally optimal alignment fora sentence pair given some parameters.", "labels": [], "entities": [{"text": "MANLI", "start_pos": 58, "end_pos": 63, "type": "DATASET", "confidence": 0.7868463397026062}]}, {"text": "Our approach is based on integer linear programming (ILP) and can leverage optimized general-purpose LP solvers to recover exact solutions.", "labels": [], "entities": []}, {"text": "This strategy boosts decoding speed by an order of magnitude over stochastic search in our experiments.", "labels": [], "entities": []}, {"text": "Additionally, we introduce hard syntactic constraints on alignments produced by the model, yielding better precision and a large increase in the number of perfect alignments produced over our evaluation corpus.", "labels": [], "entities": [{"text": "precision", "start_pos": 107, "end_pos": 116, "type": "METRIC", "confidence": 0.9994722008705139}]}], "datasetContent": [{"text": "MANLI was trained and evaluated on a corpus of human-generated alignment annotations produced by Microsoft Research for inference problems from the second Recognizing Textual Entailment (RTE2) challenge ().", "labels": [], "entities": [{"text": "MANLI", "start_pos": 0, "end_pos": 5, "type": "DATASET", "confidence": 0.7829995155334473}, {"text": "Recognizing Textual Entailment (RTE2) challenge", "start_pos": 155, "end_pos": 202, "type": "TASK", "confidence": 0.7020240724086761}]}, {"text": "The corpus consists of a development set and test set that both feature 800 inference problems, each of which consists of a premise, a hypothesis and three independently-annotated human alignments.", "labels": [], "entities": []}, {"text": "In our experiments, we merge the annotations using majority rule in the same manner as.", "labels": [], "entities": []}, {"text": "A TAG-based probabilistic dependency parser) is used to formulate the above constraints in our experiments.", "labels": [], "entities": [{"text": "TAG-based probabilistic dependency parser", "start_pos": 2, "end_pos": 43, "type": "TASK", "confidence": 0.5275932401418686}]}, {"text": "The results are shown in and indicate a notable increase in alignment precision, which is to be expected as the constraints specifically seek to exclude poor edits.", "labels": [], "entities": [{"text": "precision", "start_pos": 70, "end_pos": 79, "type": "METRIC", "confidence": 0.9096133708953857}]}, {"text": "Despite the simple and overly general restrictions being applied, recall is almost unaffected.", "labels": [], "entities": [{"text": "recall", "start_pos": 66, "end_pos": 72, "type": "METRIC", "confidence": 0.9975515007972717}]}, {"text": "Most compellingly, the number of perfect alignments produced by the system increases significantly when compared to the unconstrained models from (a relative increase of 35% on the test corpus).", "labels": [], "entities": []}, {"text": "The short hypotheses featured in the RTE2 corpus (averaging 11 words) dampen the effect of the quadratic growth in number of edits with sentence length.", "labels": [], "entities": [{"text": "RTE2 corpus", "start_pos": 37, "end_pos": 48, "type": "DATASET", "confidence": 0.9602740108966827}]}, {"text": "For this reason, we also run the aligners on a corpus of 297 related sentence pairs which don't have a particular disparity in sentence lengths).", "labels": [], "entities": []}, {"text": "The large difference in decoding time illustrates the scaling limitations of the searchbased decoder.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Performance of aligners in terms of precision, re- call, F-measure and number of perfect alignments (E%).", "labels": [], "entities": [{"text": "precision", "start_pos": 46, "end_pos": 55, "type": "METRIC", "confidence": 0.9995965361595154}, {"text": "re- call", "start_pos": 57, "end_pos": 65, "type": "METRIC", "confidence": 0.964247981707255}, {"text": "F-measure", "start_pos": 67, "end_pos": 76, "type": "METRIC", "confidence": 0.9985675811767578}, {"text": "number of perfect alignments", "start_pos": 81, "end_pos": 109, "type": "METRIC", "confidence": 0.705422431230545}, {"text": "E", "start_pos": 111, "end_pos": 112, "type": "METRIC", "confidence": 0.8137982487678528}]}, {"text": " Table 3: Performance of MANLI-Exact featuring addi- tional modifier (M) and lineage (L) constraints. Figures  in boldface are statistically significant over the uncon- strained MANLI reimplementation (p \u2264 0.05).", "labels": [], "entities": [{"text": "lineage (L)", "start_pos": 77, "end_pos": 88, "type": "METRIC", "confidence": 0.897251769900322}]}]}