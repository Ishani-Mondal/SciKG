{"title": [{"text": "A Corpus of Scope-disambiguated English Text", "labels": [], "entities": []}], "abstractContent": [{"text": "Previous work on quantifier scope annotation focuses on scoping sentences with only two quantified noun phrases (NPs), where the quan-tifiers are restricted to a predefined list.", "labels": [], "entities": [{"text": "quantifier scope annotation", "start_pos": 17, "end_pos": 44, "type": "TASK", "confidence": 0.7730793754259745}]}, {"text": "It also ignores negation, modal/logical operators, and other sentential adverbials.", "labels": [], "entities": []}, {"text": "We present a comprehensive scope annotation scheme.", "labels": [], "entities": []}, {"text": "We annotate the scope interaction between all scopal terms in the sentence from quantifiers to scopal adverbials, without putting any restriction on the number of scopal terms in a sentence.", "labels": [], "entities": []}, {"text": "In addition , all NPs, explicitly quantified or not, with no restriction on the type of quantification, are investigated for possible scope interactions.", "labels": [], "entities": []}], "introductionContent": [{"text": "Since the early days of natural language understanding (NLU), quantifier scope disambiguation has been an extremely hard task.", "labels": [], "entities": [{"text": "natural language understanding (NLU)", "start_pos": 24, "end_pos": 60, "type": "TASK", "confidence": 0.8033273120721182}, {"text": "quantifier scope disambiguation", "start_pos": 62, "end_pos": 93, "type": "TASK", "confidence": 0.8226780692736307}]}, {"text": "Therefore, early NLU systems either devised some mechanism for leaving the semantic representation underspecified, or tried to assign scoping to sentences based on heuristics.", "labels": [], "entities": []}, {"text": "There has been a lot of work since then on developing frameworks for scope-underspecified semantic representations).", "labels": [], "entities": []}, {"text": "The motivation of most recent formalisms is to develop a constraint-based framework where you can incrementally add constraints to filter out unwanted scopings.", "labels": [], "entities": []}, {"text": "However, almost all of these formalisms are based on hard constraints, which have to be satisfied in every reading of the sentence.", "labels": [], "entities": []}, {"text": "It seems that the story is different in practice.", "labels": [], "entities": []}, {"text": "Most of the constraints one can hope for (imposed by discourse, pragmatics, word knowledge, etc.) are soft constraints, that is they define a preference over the possible readings of a sentence.", "labels": [], "entities": []}, {"text": "As a result, statistical methods seem to be well suited for scope disambiguation.", "labels": [], "entities": [{"text": "scope disambiguation", "start_pos": 60, "end_pos": 80, "type": "TASK", "confidence": 0.8635848462581635}]}, {"text": "Surprisingly enough, after two decades of extensive work on statistical techniques in natural language processing, there has not been much work on scope disambiguation (see section 6 fora review).", "labels": [], "entities": [{"text": "scope disambiguation", "start_pos": 147, "end_pos": 167, "type": "TASK", "confidence": 0.7977642118930817}]}, {"text": "In addition, as discussed later, this work is very restricted.", "labels": [], "entities": []}, {"text": "It considers sentences with only two quantifiers, where the quantifiers are picked from a predefined list.", "labels": [], "entities": []}, {"text": "For example, it ignores definites, bare singulars/plurals, and proper nouns, as well as negations and other scopal operators.", "labels": [], "entities": []}, {"text": "A major reason for the lack of work on statistical scope disambiguation is the lack of a comprehensive scope-disambiguated corpus.", "labels": [], "entities": [{"text": "statistical scope disambiguation", "start_pos": 39, "end_pos": 71, "type": "TASK", "confidence": 0.6817213694254557}]}, {"text": "In fact, there is not even a standard test set for evaluation purposes.", "labels": [], "entities": []}, {"text": "The reason behind this latter fact is simple.", "labels": [], "entities": []}, {"text": "Scope disambiguation is very hard even for humans.", "labels": [], "entities": [{"text": "Scope disambiguation", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.9823097288608551}]}, {"text": "In fact, our own early effort to annotate part of the Penn Treebank with full scope information soon proved to be too ambitious.", "labels": [], "entities": [{"text": "Penn Treebank", "start_pos": 54, "end_pos": 67, "type": "DATASET", "confidence": 0.8847499489784241}]}, {"text": "Instead, we have picked a domain that covers many challenging phenomena in scope disambiguation, while keeping the scope disambiguation fairly intuitive.", "labels": [], "entities": [{"text": "scope disambiguation", "start_pos": 75, "end_pos": 95, "type": "TASK", "confidence": 0.762283593416214}]}, {"text": "This helps us to build the first moderately sized corpus of natural language text with full scope information.", "labels": [], "entities": []}, {"text": "By fully scoping a sentence, we mean to label the scope interaction between every two scopal elements in that sen-tence.", "labels": [], "entities": []}, {"text": "We scope all scope-bearing NPs (quantified or not), negations, logical/modal operators, and other sentential adverbials.", "labels": [], "entities": []}, {"text": "We also annotate plurals with their distributive vs. collective readings.", "labels": [], "entities": []}, {"text": "In addition, we label sentences with coreference relations because they affect the scope interaction between NPs.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": []}