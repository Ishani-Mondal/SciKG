{"title": [{"text": "Semantic Representation of Negation Using Focus Detection", "labels": [], "entities": [{"text": "Semantic Representation of Negation", "start_pos": 0, "end_pos": 35, "type": "TASK", "confidence": 0.8592611998319626}, {"text": "Focus Detection", "start_pos": 42, "end_pos": 57, "type": "TASK", "confidence": 0.708353191614151}]}], "abstractContent": [{"text": "Negation is present in all human languages and it is used to reverse the polarity of part of statements that are otherwise affirmative by default.", "labels": [], "entities": []}, {"text": "A negated statement often carries positive implicit meaning, but to pinpoint the positive part from the negative part is rather difficult.", "labels": [], "entities": []}, {"text": "This paper aims at thoroughly representing the semantics of negation by revealing implicit positive meaning.", "labels": [], "entities": []}, {"text": "The proposed representation relies on focus of negation detection.", "labels": [], "entities": [{"text": "negation detection", "start_pos": 47, "end_pos": 65, "type": "TASK", "confidence": 0.9755552411079407}]}, {"text": "For this, new annotation over PropBank and a learning algorithm are proposed.", "labels": [], "entities": [{"text": "PropBank", "start_pos": 30, "end_pos": 38, "type": "DATASET", "confidence": 0.9534478783607483}]}], "introductionContent": [{"text": "Understanding the meaning of text is along term goal in the natural language processing community.", "labels": [], "entities": [{"text": "Understanding the meaning of text", "start_pos": 0, "end_pos": 33, "type": "TASK", "confidence": 0.80842365026474}]}, {"text": "Whereas philosophers and linguists have proposed several theories, along with models to represent the meaning of text, the field of computational linguistics is still far from doing this automatically.", "labels": [], "entities": []}, {"text": "The ambiguity of language, the need to detect implicit knowledge, and the demand for commonsense knowledge and reasoning area few of the difficulties to overcome.", "labels": [], "entities": []}, {"text": "Substantial progress has been made, though, especially on detection of semantic relations, ontologies and reasoning methods.", "labels": [], "entities": []}, {"text": "Negation is present in all languages and it is always the case that statements are affirmative by default.", "labels": [], "entities": []}, {"text": "Negation is marked and it typically signals something unusual or an exception.", "labels": [], "entities": [{"text": "Negation", "start_pos": 0, "end_pos": 8, "type": "TASK", "confidence": 0.9053427577018738}]}, {"text": "It maybe present in all units of language, e.g., words (incredible), clauses (He doesn't have friends).", "labels": [], "entities": []}, {"text": "Negation and its correlates (truth values, lying, irony, false or contradictory statements) are exclusive characteristics of humans).", "labels": [], "entities": []}, {"text": "Negation is fairly well-understood in grammars; the valid ways to express a negation are documented.", "labels": [], "entities": []}, {"text": "However, there has not been extensive research on detecting it, and more importantly, on representing the semantics of negation.", "labels": [], "entities": []}, {"text": "Negation has been largely ignored within the area of semantic relations.", "labels": [], "entities": [{"text": "Negation", "start_pos": 0, "end_pos": 8, "type": "TASK", "confidence": 0.9521024227142334}]}, {"text": "At first glance, one would think that interpreting negation could be reduced to finding negative keywords, detect their scope using syntactic analysis and reverse its polarity.", "labels": [], "entities": [{"text": "interpreting negation", "start_pos": 38, "end_pos": 59, "type": "TASK", "confidence": 0.9120062589645386}]}, {"text": "Actually, it is more complex.", "labels": [], "entities": []}, {"text": "Negation plays a remarkable role in text understanding and it poses considerable challenges.", "labels": [], "entities": [{"text": "text understanding", "start_pos": 36, "end_pos": 54, "type": "TASK", "confidence": 0.9055310189723969}]}, {"text": "Detecting the scope of negation in itself is challenging: All vegetarians do not eat meat means that vegetarians do not eat meat and yet All that glitters is not gold means that it is not the case that all that glitters is gold (so out of all things that glitter, some are gold and some are not).", "labels": [], "entities": [{"text": "negation", "start_pos": 23, "end_pos": 31, "type": "TASK", "confidence": 0.944502055644989}]}, {"text": "In the former example, the universal quantifier all has scope over the negation; in the latter, the negation has scope overall.", "labels": [], "entities": []}, {"text": "In logic, two negatives always cancel each other out.", "labels": [], "entities": []}, {"text": "On the other hand, in language this is only theoretically the case: she is not unhappy does not mean that she is happy; it means that she is not fully unhappy, but she is not happy either.", "labels": [], "entities": []}, {"text": "Some negated statements carry a positive implicit meaning.", "labels": [], "entities": []}, {"text": "For example, cows do not eat meat implies that cows eat something other than meat.", "labels": [], "entities": []}, {"text": "Otherwise, the speaker would have stated cows do not eat.", "labels": [], "entities": []}, {"text": "A clearer example is the correct and yet puzzling statement tables do not eat meat.", "labels": [], "entities": []}, {"text": "This sentence sounds unnatural because of the underlying positive statement (i.e., tables eat something other than meat).", "labels": [], "entities": []}, {"text": "Negation can express less than or in between when used in a scalar context.", "labels": [], "entities": []}, {"text": "For example, John does not have three children probably means that he has either one or two children.", "labels": [], "entities": []}, {"text": "Contrasts may use negation to disagree about a statement and not to negate it, e.g., That place is not big, it is massive defines the place as massive, and therefore, big.", "labels": [], "entities": []}], "datasetContent": [{"text": "As a learning algorithm, we use bagging with C4.5 decision trees.", "labels": [], "entities": []}, {"text": "This combination is fast to train and test, and typically provides good performance.", "labels": [], "entities": []}, {"text": "More features than the ones depicted were tried, but we only report the final set.", "labels": [], "entities": []}, {"text": "For example, the parent node for all roles was considered and discarded.", "labels": [], "entities": []}, {"text": "We name the model considering all features and trained using bagging with C4.5 trees FOC-DET.", "labels": [], "entities": [{"text": "FOC-DET", "start_pos": 85, "end_pos": 92, "type": "METRIC", "confidence": 0.8877626061439514}]}, {"text": "Results over the test split are depicted in  rithm exclusively the label corresponding to the last role and flags indicating the presence of roles yields 61.38 accuracy (BASIC baseline).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 160, "end_pos": 168, "type": "METRIC", "confidence": 0.9878139495849609}, {"text": "BASIC baseline", "start_pos": 170, "end_pos": 184, "type": "METRIC", "confidence": 0.9444326758384705}]}, {"text": "Having an agreement of 0.72, there is still room for improvement.", "labels": [], "entities": []}, {"text": "The full set of features yields 65.50 accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 38, "end_pos": 46, "type": "METRIC", "confidence": 0.968525767326355}]}, {"text": "The difference inaccuracy between BASIC and FOC-DET (4.12) is statistically significant (Z-value = 1.71).", "labels": [], "entities": [{"text": "FOC-DET", "start_pos": 44, "end_pos": 51, "type": "DATASET", "confidence": 0.8815174102783203}]}, {"text": "We test the significance of the difference in performance between two systems i and j on a set of ins instances with the Z-score test, where z = abs(err i ,err j ) \u03c3 d , err k is the error made using set k", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 4: Roles, total instantiations and counts corre- sponding to focus over training and held-out instances.", "labels": [], "entities": []}, {"text": " Table 6.  Simply choosing A1 as the focus yields an accuracy  of 42.11. A better baseline is to always pick the last  role (58.39 accuracy). Feeding the learning algo-", "labels": [], "entities": [{"text": "A1", "start_pos": 27, "end_pos": 29, "type": "METRIC", "confidence": 0.9876173138618469}, {"text": "accuracy", "start_pos": 53, "end_pos": 61, "type": "METRIC", "confidence": 0.9995989203453064}, {"text": "accuracy", "start_pos": 131, "end_pos": 139, "type": "METRIC", "confidence": 0.9871551990509033}]}]}