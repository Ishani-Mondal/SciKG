{"title": [{"text": "A Word-Class Approach to Labeling PSCFG Rules for Machine Translation", "labels": [], "entities": [{"text": "Labeling PSCFG", "start_pos": 25, "end_pos": 39, "type": "TASK", "confidence": 0.7541345953941345}, {"text": "Machine Translation", "start_pos": 50, "end_pos": 69, "type": "TASK", "confidence": 0.7440710365772247}]}], "abstractContent": [{"text": "In this work we propose methods to label probabilistic synchronous context-free grammar (PSCFG) rules using only word tags, generated by either part-of-speech analysis or unsupervised word class induction.", "labels": [], "entities": [{"text": "label probabilistic synchronous context-free grammar (PSCFG)", "start_pos": 35, "end_pos": 95, "type": "TASK", "confidence": 0.7852153927087784}]}, {"text": "The proposals range from simple tag-combination schemes to a phrase clustering model that can incorporate an arbitrary number of features.", "labels": [], "entities": [{"text": "phrase clustering", "start_pos": 61, "end_pos": 78, "type": "TASK", "confidence": 0.7862483561038971}]}, {"text": "Our models improve translation quality over the single generic label approach of Chiang (2005) and perform on par with the syntactically motivated approach from Zollmann and Venugopal (2006) on the NIST large Chinese-to-English translation task.", "labels": [], "entities": [{"text": "translation", "start_pos": 19, "end_pos": 30, "type": "TASK", "confidence": 0.9667474627494812}, {"text": "NIST large Chinese-to-English translation task", "start_pos": 198, "end_pos": 244, "type": "TASK", "confidence": 0.707405173778534}]}, {"text": "These results persist when using automatically learned word tags, suggesting broad applicability of our technique across diverse language pairs for which syntactic resources are not available.", "labels": [], "entities": []}], "introductionContent": [{"text": "The Probabilistic Synchronous Context Free Grammar (PSCFG) formalism suggests an intuitive approach to model the long-distance and lexically sensitive reordering phenomena that often occur across language pairs considered for statistical machine translation.", "labels": [], "entities": [{"text": "Probabilistic Synchronous Context Free Grammar (PSCFG) formalism", "start_pos": 4, "end_pos": 68, "type": "TASK", "confidence": 0.7013458576467302}, {"text": "statistical machine translation", "start_pos": 226, "end_pos": 257, "type": "TASK", "confidence": 0.6722013056278229}]}, {"text": "As in monolingual parsing, nonterminal symbols in translation rules are used to generalize beyond purely lexical operations.", "labels": [], "entities": []}, {"text": "Labels on these nonterminal symbols are often used to enforce syntactic constraints in the generation of bilingual sentences and imply conditional independence assumptions in the translation model.", "labels": [], "entities": []}, {"text": "Several techniques have been recently proposed to automatically identify and estimate parameters for PSCFGs (or related synchronous grammars) from parallel corpora (;).", "labels": [], "entities": []}, {"text": "While all of these techniques rely on wordalignments to suggest lexical relationships, they differ in the way in which they assign labels to nonterminal symbols of PSCFG rules.", "labels": [], "entities": []}, {"text": "describes a procedure to extract PSCFG rules from word-aligned () corpora, where all nonterminals share the same generic label X.", "labels": [], "entities": []}, {"text": "In and, target language parse trees are used to identify rules and label their nonterminal symbols, while use source language parse trees instead.", "labels": [], "entities": []}, {"text": "directly extend the rule extraction procedure from to heuristically label any phrase pair based on target language parse trees.", "labels": [], "entities": [{"text": "rule extraction", "start_pos": 20, "end_pos": 35, "type": "TASK", "confidence": 0.7177131325006485}]}, {"text": "Label-based approaches have resulted in improvements in translation quality over the single X label approach (; however, all the works cited here rely on stochastic parsers that have been trained on manually created syntactic treebanks.", "labels": [], "entities": []}, {"text": "These treebanks are difficult and expensive to produce and exist fora limited set of languages only.", "labels": [], "entities": []}, {"text": "In this work, we propose a labeling approach that is based merely on part-of-speech analysis of the source or target language (or even both).", "labels": [], "entities": []}, {"text": "Towards the ultimate goal of building end-to-end machine translation systems without any human annotations, we also experiment with automatically inferred word classes using distributional clustering.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 49, "end_pos": 68, "type": "TASK", "confidence": 0.7326884567737579}]}, {"text": "Since the number of classes is a parameter of the clustering method and the resulting nonterminal size of our grammar is a function of the number of word classes, the PSCFG grammar complexity can be adjusted to the specific translation task at hand.", "labels": [], "entities": []}, {"text": "Finally, we introduce a more flexible labeling approach based on K-means clustering, which allows 1 the incorporation of an arbitrary number of wordclass based features, including phrasal contexts, can make use of multiple tagging schemes, and also allows non-class features such as phrase sizes.", "labels": [], "entities": []}], "datasetContent": [{"text": "We evaluate our approach by comparing translation quality, as evaluated by the IBM-BLEU () metric on the NIST Chinese-to-English translation task using MT04 as development set to train the model parameters \u03bb, and MT05, MT06 and MT08 as test sets.", "labels": [], "entities": [{"text": "NIST Chinese-to-English translation task", "start_pos": 105, "end_pos": 145, "type": "TASK", "confidence": 0.8015892505645752}, {"text": "MT04", "start_pos": 152, "end_pos": 156, "type": "DATASET", "confidence": 0.8381030559539795}, {"text": "MT05", "start_pos": 213, "end_pos": 217, "type": "DATASET", "confidence": 0.8851515054702759}, {"text": "MT06", "start_pos": 219, "end_pos": 223, "type": "DATASET", "confidence": 0.8844577670097351}, {"text": "MT08", "start_pos": 228, "end_pos": 232, "type": "DATASET", "confidence": 0.9108216166496277}]}, {"text": "Even though a key advantage of our method is its applicability to resource-poor languages, we used a language pair for which linguistic resources are available in order to determine how close translation performance can get to a fully syntax-based system.", "labels": [], "entities": []}, {"text": "Accordingly, we use Chiang's hierarchical phrase based translation model as abase line, and the syntax-augmented MT model () as a 'target line', a model that would not be applicable for language pairs without linguistic resources.", "labels": [], "entities": []}, {"text": "We perform PSCFG rule extraction and decoding using the open-source \"SAMT\" system (Venugopal and, using the provided implementations for the hierarchical and syntax-augmented grammars.", "labels": [], "entities": [{"text": "PSCFG rule extraction", "start_pos": 11, "end_pos": 32, "type": "TASK", "confidence": 0.8359777331352234}, {"text": "Venugopal", "start_pos": 83, "end_pos": 92, "type": "DATASET", "confidence": 0.8660344481468201}]}, {"text": "Apart from the language model, the lexical, phrasal, and (for the syntax grammar) labelconditioned features, and the rule, target word, and glue operation counters, Venugopal and Zollmann (2009) also provide both the hierarchical and syntax-augmented grammars with a rareness penalty 1/ cnt(r), where cnt(r) is the occurrence count of ruler in the training corpus, allowing the system to learn penalization of low-frequency rules, as well as three indicator features firing if the rule has one, two unswapped, and two swapped nonterminal pairs, respectively.", "labels": [], "entities": []}, {"text": "Further, to mitigate badly estimated PSCFG derivations based on low-frequency rules of the much sparser syntax model, the syntax grammar also contains the hierarchical grammar as a backbone (cf. for details and empirical analysis).", "labels": [], "entities": []}, {"text": "We implemented our rule labeling approach within the SAMT rule extraction pipeline, resulting in comparable features across all systems.", "labels": [], "entities": [{"text": "rule labeling", "start_pos": 19, "end_pos": 32, "type": "TASK", "confidence": 0.8001999855041504}, {"text": "SAMT rule extraction pipeline", "start_pos": 53, "end_pos": 82, "type": "TASK", "confidence": 0.8840169161558151}]}, {"text": "For all systems, we use the bottom-up chart parsing decoder implemented in the SAMT toolkit with a reordering limit of 15 source words, and correspondingly extract rules from initial phrase pairs of maximum source length 15.", "labels": [], "entities": [{"text": "bottom-up chart parsing decoder", "start_pos": 28, "end_pos": 59, "type": "TASK", "confidence": 0.7373168766498566}, {"text": "SAMT toolkit", "start_pos": 79, "end_pos": 91, "type": "DATASET", "confidence": 0.8920387029647827}]}, {"text": "All rules have at most two nonterminal symbols, which must be non-consecutive on the source side, and rules must contain at least one source-side terminal symbol.", "labels": [], "entities": []}, {"text": "The beam settings for the hierarchical system are 600 items per 'X' (generic rule) cell, and 600 per 'S' (glue) cell.", "labels": [], "entities": []}, {"text": "Due to memory limitations, the multi-nonterminal grammars have to be pruned more harshly: We al-low 100 'S' items, and a total of 500 non-'S' items, but maximally 40 items per nonterminal.", "labels": [], "entities": []}, {"text": "For all systems, we further discard non-initial rules occurring only once.", "labels": [], "entities": []}, {"text": "For the multi-nonterminal systems, we generally further discard all non-generic non-initial rules occurring less than 6 times, but we additionally give results fora 'slow' version of the Syntax targetline system and our best word class based systems, where only single-occurrences were removed.", "labels": [], "entities": []}, {"text": "For parameter tuning, we use the L 0 -regularized minimum-error-rate training tool provided by the SAMT toolkit.", "labels": [], "entities": [{"text": "parameter tuning", "start_pos": 4, "end_pos": 20, "type": "TASK", "confidence": 0.731421485543251}, {"text": "SAMT toolkit", "start_pos": 99, "end_pos": 111, "type": "DATASET", "confidence": 0.9154096841812134}]}, {"text": "Each system is trained separately to adapt the parameters to its specific properties (size of nonterminal set, grammar complexity, features sparseness, reliance on the language model, etc.).", "labels": [], "entities": []}, {"text": "The parallel training data comprises of 9.6M sentence pairs (206M Chinese and 228M English words).", "labels": [], "entities": []}, {"text": "The source and target language parses for the syntax-augmented grammar, as well as the POS tags for our POS-based grammars were generated by the Stanford parser (.", "labels": [], "entities": []}, {"text": "The results are given in.", "labels": [], "entities": []}, {"text": "Results for the Syntax system are consistent with previous results (, indicating improvements over the hierarchical system.", "labels": [], "entities": []}, {"text": "Our approach, using target POS tags ('POS-tgt (no phr.", "labels": [], "entities": []}, {"text": "s.)'), outperforms the hierarchical system on all three tests sets, and gains further improvements when accounting for phrase size ('POS-tgt').", "labels": [], "entities": []}, {"text": "The latter approach is roughly on par with the corresponding Syntax system, slightly outperforming it on average, but not consistently across all test sets.", "labels": [], "entities": []}, {"text": "The same is true for the 'slow' version ('POS-tgt-slow').", "labels": [], "entities": [{"text": "POS-tgt-slow", "start_pos": 42, "end_pos": 54, "type": "DATASET", "confidence": 0.732759952545166}]}, {"text": "The model based on bilingually tagged training instances ('POS-src&tgt') does not gain further improvements over the merely target-based one, but actually performs worse.", "labels": [], "entities": []}, {"text": "We assume this is due to the huge number of nonterminals of 'POS-src&tgt' ((2 * 33 2 + 33)(2 * 36 2 + 36) = 5.8M in principle) compared to 'POS-tgt' (2 * 36 2 + 36 = 2628), increasing the sparseness of the grammar and thus leading to less reliable statistical estimates.", "labels": [], "entities": []}, {"text": "We also experimented with a source-tag based model ('POS-src').", "labels": [], "entities": []}, {"text": "In line with previous findings for syntax-augmented grammars (, the source-side-based grammar does not reach the translation quality of its target-based counterpart; however, the model still outperforms the hi-erarchical system on all test sets.", "labels": [], "entities": []}, {"text": "Further, decoding is much faster than for 'POS-ext-tgt' and even slightly faster than 'Hierarchical'.", "labels": [], "entities": []}, {"text": "This is due to the fact that for the source-tag based approach, a given chart cell in the CYK decoder, represented by a start and end position in the source sentence, almost uniquely determines the nonterminal any hypothesis in this cell can have: Disregarding partof-speech tag ambiguity and phrase size accounting, that nonterminal will be the composition of the tags of the start and end source words spanned by that cell.", "labels": [], "entities": [{"text": "CYK decoder", "start_pos": 90, "end_pos": 101, "type": "DATASET", "confidence": 0.9527954757213593}, {"text": "phrase size accounting", "start_pos": 293, "end_pos": 315, "type": "TASK", "confidence": 0.7226298848787943}]}, {"text": "At the same time, this demonstrates that there is hence less of a role for the nonterminal labels to resolve translational ambiguity in the source based model than in the target based model.", "labels": [], "entities": []}, {"text": "Performance of the word-clustering based models To empirically validate the unsupervised clustering approaches, we first need to decide how to determine the number of word classes, N . A straightforward approach is to run experiments and report test set results for many different N . While this would allow us to reliably conclude the optimal number N , a comparison of that best-performing clustering method to the hierarchical, syntax, and POS systems would be tainted by the fact that N was effectively tuned on the test sets.", "labels": [], "entities": []}, {"text": "We therefore choose N merely based on development set performance.", "labels": [], "entities": []}, {"text": "Unfortunately, variance in development set BLEU scores tends to be higher than test set scores, despite of SAMT MERT's inbuilt algorithms to overcome local optima, such as random restarts and zeroing-out.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 43, "end_pos": 47, "type": "METRIC", "confidence": 0.9724252820014954}, {"text": "MERT", "start_pos": 112, "end_pos": 116, "type": "METRIC", "confidence": 0.4777657985687256}]}, {"text": "We have noticed that using an L 0 -penalized BLEU score 5 as MERT's objective on the merged n-best lists overall iterations is more stable and will therefore use this score to determine N . (left) shows the performance of the distributional clustering model ('Clust') and its morphology-sensitive extension ('Clust-morph') according to this score for varying values of N = 1, . .", "labels": [], "entities": [{"text": "BLEU", "start_pos": 45, "end_pos": 49, "type": "METRIC", "confidence": 0.7710639238357544}]}, {"text": ", 36 (the number Penn treebank POS tags, used for the 'POS' models, is 36).", "labels": [], "entities": [{"text": "Penn treebank POS tags", "start_pos": 17, "end_pos": 39, "type": "DATASET", "confidence": 0.9526675790548325}]}, {"text": "For 'Clust', we see a comfortably wide plateau of nearly-identical scores from N = 7, . .", "labels": [], "entities": []}, {"text": "Scores for 'Clust-morph' are lower throughout, and peak at N = 7.", "labels": [], "entities": [{"text": "Clust-morph", "start_pos": 12, "end_pos": 23, "type": "METRIC", "confidence": 0.7908530235290527}]}, {"text": "Looking back at, we now compare the clustering models chosen by the procedure above-: Translation quality in % case-insensitive IBM-BLEU (i.e., brevity penalty based on closest reference length) for Chinese-English NIST-large translation tasks, comparing baseline Hierarchical and Syntax systems with POS and clustering based approaches proposed in this work.", "labels": [], "entities": [{"text": "Translation", "start_pos": 86, "end_pos": 97, "type": "TASK", "confidence": 0.9380164742469788}, {"text": "NIST-large translation tasks", "start_pos": 215, "end_pos": 243, "type": "TASK", "confidence": 0.8268961906433105}]}, {"text": "'TestAvg' shows the average score over the three test sets.", "labels": [], "entities": [{"text": "TestAvg'", "start_pos": 1, "end_pos": 9, "type": "DATASET", "confidence": 0.7985007464885712}]}, {"text": "'Time' is the average decoding time per sentence in seconds on one CPU.", "labels": [], "entities": [{"text": "Time", "start_pos": 1, "end_pos": 5, "type": "METRIC", "confidence": 0.9881816506385803}]}, {"text": "resulting in N = 7 for the morphology-unaware model ('Clust-7-tgt') as well as the morphologyaware model ('Clust-7-morph-tgt')-to the other systems.", "labels": [], "entities": []}, {"text": "'Clust-7-tgt' improves over the hierarchical baseline on all three test sets and is on par with the corresponding Syntax and POS target lines.", "labels": [], "entities": [{"text": "Clust-7-tgt", "start_pos": 1, "end_pos": 12, "type": "METRIC", "confidence": 0.9269154667854309}]}, {"text": "The same holds for the 'Clust-7-tgt-slow' version.", "labels": [], "entities": []}, {"text": "We also experimented with a model variant based on seven source and seven target language clusters ('Clust-7-src&tgt') and a source-only labeled model ('Clust-7-src')-both performing worse.", "labels": [], "entities": []}, {"text": "Surprisingly, the morphology-sensitive clustering model ('Clust-7-morph-tgt'), while still improving over the hierarchical system, performs worse than the morphology-unaware model.", "labels": [], "entities": []}, {"text": "An inspection of the trained word clusters showed that the model, while far superior to the morphologyunaware model in e.g. mapping all numbers to the same class, is overzealous in discovering morphological regularities (such as the '-ed' suffix) to partition functionally only slightly dissimilar words (such present-tense and past-tense verbs) into different classes.", "labels": [], "entities": []}, {"text": "While these subtle distinctions make for good partitionings when the number of clusters is large, they appear to lead to inferior results for our task that relies on coarse-grained partitionings of the vocabulary.", "labels": [], "entities": []}, {"text": "Note that there are no 'src' or 'src&tgt' systems for 'Clust-morph', as Chinese, being a monosyllabic writing system, does not lend itself to morphology-sensitive clustering.", "labels": [], "entities": []}, {"text": "K-means clustering based models To establish suitable values for the \u03b1 parameters and investigate the impact of the number of clusters, we looked at the development performance over various parameter combinations fora K-means model based on source and/or target part-of-speech tags.", "labels": [], "entities": []}, {"text": "As can be seen from (right), our method reaches its peak performance at around 50 clusters and then levels off slightly.", "labels": [], "entities": []}, {"text": "Encouragingly, in contrast to the hard labeling procedure, K-means actually improves when adding source-side information.", "labels": [], "entities": []}, {"text": "The optimal ratio of weighting source and target classes is 0.5:1, corresponding to \u03b1 src = .5.", "labels": [], "entities": []}, {"text": "Incorporating context information also helps, and does best for \u03b1 cntxt = 0.25, i.e. when giving contexts 1/4 the influence of the phrase boundary words.", "labels": [], "entities": []}, {"text": "Entry 'kmeans-POS-src&tgt' in shows the test set results for the development-set best Kmeans configuration (i.e., \u03b1 src = .5, \u03b1 cntxt = 0.25, and using 500 clusters).", "labels": [], "entities": []}, {"text": "While beating the hierarchical baseline, it is only minimally better than the much simpler target-based hard labeling method 'POS-tgt'.", "labels": [], "entities": []}, {"text": "We also tried K-means variants in which the Euclidean distance metric is replaced by the city block distance L 1 and the cosine dissimilarity, respectively, with slightly worse outcomes.", "labels": [], "entities": []}, {"text": "Configuration 'kmeans-POS-src&tgt (\u03b1 ins = .5)' investigates the incorporation of non-boundary word tags inside the phrase.", "labels": [], "entities": []}, {"text": "Unfortunately, these features appear to deteriorate performance, presumably because given a fixed number of clusters, accounting for contents inside the phrase comes at the cost of neglect of boundary words, which are more relevant to producing correctly reordered translations.", "labels": [], "entities": []}, {"text": "The two completely unsupervised systems 'kmeans-Clust-7-src&tgt' (based on 7-class MKCLS distributional word clustering) and 'kmeans-Clust-7..36-src&tgt' (using six different word clustering models simultaneously: all the MKCLS models from (left) except for the two-, three-and five-class models) have the best results, outperforming the other K-means models as well as 'Syntax' and 'POS-tgt' on average, but not on all test sets.", "labels": [], "entities": [{"text": "MKCLS distributional word clustering", "start_pos": 83, "end_pos": 119, "type": "TASK", "confidence": 0.6149895712733269}]}, {"text": "Lastly, we give results for 'slow' K-means configurations ('kmeans-POS-src&tgt-slow' and 'kmeansClust-7..36-s&t-slow').", "labels": [], "entities": []}, {"text": "Unfortunately (or fortunately, from a pragmatic viewpoint), the models are outperformed by the much simpler 'POS-tgt-slow' and 'Clust-7-tgt-slow' models.", "labels": [], "entities": [{"text": "POS-tgt-slow", "start_pos": 109, "end_pos": 121, "type": "DATASET", "confidence": 0.7834129333496094}]}, {"text": "improve the statistical phrasebased MT model by injecting supertags, lexical information such as the POS tag of the word and its subcategorization information, into the phrase table, resulting in generalized phrases with placeholders in them.", "labels": [], "entities": [{"text": "MT", "start_pos": 36, "end_pos": 38, "type": "TASK", "confidence": 0.7834408283233643}]}, {"text": "The supertags are also injected into the language model.", "labels": [], "entities": []}, {"text": "Our approach also generates phrase labels and placeholders based on word tags (albeit in a different manner and without the use of subcategorization information), but produces PSCFG rules for use in a parsing-based decoding system.", "labels": [], "entities": []}], "tableCaptions": []}