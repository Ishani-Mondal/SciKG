{"title": [{"text": "Domain Adaptation by Constraining Inter-Domain Variability of Latent Feature Representation", "labels": [], "entities": [{"text": "Domain Adaptation", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.6843378841876984}]}], "abstractContent": [{"text": "We consider a semi-supervised setting for domain adaptation where only unlabeled data is available for the target domain.", "labels": [], "entities": [{"text": "domain adaptation", "start_pos": 42, "end_pos": 59, "type": "TASK", "confidence": 0.7565160095691681}]}, {"text": "One way to tackle this problem is to train a generative model with latent variables on the mixture of data from the source and target domains.", "labels": [], "entities": []}, {"text": "Such a model would cluster features in both domains and ensure that at least some of the latent variables are predictive of the label on the source domain.", "labels": [], "entities": []}, {"text": "The danger is that these pre-dictive clusters will consist of features specific to the source domain only and, consequently, a classifier relying on such clusters would perform badly on the target domain.", "labels": [], "entities": []}, {"text": "We introduce a constraint enforcing that marginal distributions of each cluster (i.e., each latent variable) do not vary significantly across domains.", "labels": [], "entities": []}, {"text": "We show that this constraint is effective on the sentiment classification task (Pang et al., 2002), resulting in scores similar to the ones obtained by the structural correspondence methods (Blitzer et al., 2007) without the need to engineer auxiliary tasks.", "labels": [], "entities": [{"text": "sentiment classification task", "start_pos": 49, "end_pos": 78, "type": "TASK", "confidence": 0.931024432182312}]}], "introductionContent": [{"text": "Supervised learning methods have become a standard tool in natural language processing, and large training sets have been annotated fora wide variety of tasks.", "labels": [], "entities": [{"text": "natural language processing", "start_pos": 59, "end_pos": 86, "type": "TASK", "confidence": 0.6305556197961172}]}, {"text": "However, most learning algorithms operate under assumption that the learning data originates from the same distribution as the test data, though in practice this assumption is often violated.", "labels": [], "entities": []}, {"text": "This difference in the data distributions normally results in a significant drop inaccuracy.", "labels": [], "entities": []}, {"text": "To address this problem a number of domain-adaptation methods has recently been proposed (see e.g.,).", "labels": [], "entities": []}, {"text": "In addition to the labeled data from the source domain, they also exploit small amounts of labeled data and/or unlabeled data from the target domain to estimate a more predictive model for the target domain.", "labels": [], "entities": []}, {"text": "In this paper we focus on a more challenging and arguably more realistic version of the domainadaptation problem where only unlabeled data is available for the target domain.", "labels": [], "entities": []}, {"text": "One of the most promising research directions on domain adaptation for this setting is based on the idea of inducing a shared feature representation), that is mapping from the initial feature representation to anew representation such that (1) examples from both domains 'look similar' and (2) an accurate classifier can be trained in this new representation.", "labels": [], "entities": [{"text": "domain adaptation", "start_pos": 49, "end_pos": 66, "type": "TASK", "confidence": 0.721954271197319}]}, {"text": "use auxiliary tasks based on unlabeled data for both domains (called pivot features) and a dimensionality reduction technique to induce such shared representation.", "labels": [], "entities": []}, {"text": "The success of their domain-adaptation method (Structural Correspondence Learning, SCL) crucially depends on the choice of the auxiliary tasks, and defining them can be a non-trivial engineering problem for many NLP tasks.", "labels": [], "entities": []}, {"text": "In this paper, we investigate methods which do not use auxiliary tasks to induce a shared feature representation.", "labels": [], "entities": []}, {"text": "We use generative latent variable models (LVMs) learned on all the available data: unlabeled data for both domains and on the labeled data for the source domain.", "labels": [], "entities": []}, {"text": "Our LVMs use vectors of latent features to represent examples.", "labels": [], "entities": []}, {"text": "The latent variables encode regularities observed on unlabeled data from both domains, and they are learned to be predictive of the labels on the source domain.", "labels": [], "entities": []}, {"text": "Such LVMs can be regarded as composed of two parts: a mapping from initial (normally, word-based) representation to anew shared distributed representation, and also a classifier in this representation.", "labels": [], "entities": []}, {"text": "The danger of this semi-supervised approach in the domain-adaptation setting is that some of the latent variables will correspond to clusters of features specific only to the source domain, and consequently, the classifier relying on this latent variable will be badly affected when tested on the target domain.", "labels": [], "entities": []}, {"text": "Intuitively, one would want the model to induce only those features which generalize between domains.", "labels": [], "entities": []}, {"text": "We encode this intuition by introducing a term in the learning objective which regularizes inter-domain difference in marginal distributions of each latent variable.", "labels": [], "entities": []}, {"text": "Another, though conceptually similar, argument for our method is coming from theoretical results which postulate that the drop inaccuracy of an adapted classifier is dependent on the discrepancy distance between the source and target domains (.", "labels": [], "entities": []}, {"text": "Roughly, the discrepancy distance is small when linear classifiers cannot distinguish between examples from different domains.", "labels": [], "entities": []}, {"text": "A necessary condition for this is that the feature expectations do not vary significantly across domains.", "labels": [], "entities": []}, {"text": "Therefore, our approach can be regarded as minimizing a coarse approximation of the discrepancy distance.", "labels": [], "entities": []}, {"text": "The introduced term regularizes model expectations and it can be viewed as a form of a generalized expectation (GE) criterion.", "labels": [], "entities": []}, {"text": "Unlike the standard GE criterion, where a model designer defines the prior fora model expectation, our criterion postulates that the model expectations should be similar across domains.", "labels": [], "entities": []}, {"text": "In our experiments, we use a form of Harmonium Model) with a single layer of binary latent variables.", "labels": [], "entities": []}, {"text": "Though exact inference with this class of models is infeasible we use an efficient approximation, which can be regarded either as a mean-field approximation to the reconstruction error or a deterministic version of the Contrastive Divergence sampling method.", "labels": [], "entities": []}, {"text": "Though such an estimator is biased, in practice, it yields accurate models.", "labels": [], "entities": []}, {"text": "We explain how the introduced regularizer can be integrated into the stochastic gradient descent learning algorithm for our model.", "labels": [], "entities": []}, {"text": "We evaluate our approach on adapting sentiment classifiers on 4 domains: books, DVDs, electronics and kitchen appliances).", "labels": [], "entities": [{"text": "adapting sentiment classifiers", "start_pos": 28, "end_pos": 58, "type": "TASK", "confidence": 0.8698580861091614}]}, {"text": "The loss due to transfer to anew domain is very significant for this task: in our experiments it was approaching 9%, in average, for the non-adapted model.", "labels": [], "entities": []}, {"text": "Our regularized model achieves 35% average relative error reduction with respect to the nonadapted classifier, whereas the non-regularized version demonstrates a considerably smaller reduction of 26%.", "labels": [], "entities": [{"text": "relative error reduction", "start_pos": 43, "end_pos": 67, "type": "METRIC", "confidence": 0.7540487845738729}]}, {"text": "Both the achieved error reduction and the absolute score match the results reported in) for the best version 1 of the SCL method (SCL-MI, 36%), suggesting that our approach is a viable alternative to SCL.", "labels": [], "entities": [{"text": "error reduction", "start_pos": 18, "end_pos": 33, "type": "METRIC", "confidence": 0.9793877005577087}, {"text": "absolute score", "start_pos": 42, "end_pos": 56, "type": "METRIC", "confidence": 0.9596268534660339}]}, {"text": "The rest of the paper is structured as follows.", "labels": [], "entities": []}, {"text": "In Section 2 we introduce a model which uses vectors of latent variables to model statistical dependencies between the elementary features.", "labels": [], "entities": []}, {"text": "In Section 3 we discuss its applicability in the domain-adaptation setting, and introduce constraints on inter-domain variability as away to address the discovered limitations.", "labels": [], "entities": []}, {"text": "Section 4 describes approximate learning and inference algorithms used in our experiments.", "labels": [], "entities": []}, {"text": "In Section 5 we provide an empirical evaluation of the proposed method.", "labels": [], "entities": []}, {"text": "We conclude in Section 6 with further examination of the related work.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section we empirically evaluate our approach on the sentiment classification task.", "labels": [], "entities": [{"text": "sentiment classification task", "start_pos": 60, "end_pos": 89, "type": "TASK", "confidence": 0.9358872969945272}]}, {"text": "We start with the description of the experimental set-up and the baselines, then we present the results and discuss the utility of the constraint on inter-domain variability.", "labels": [], "entities": []}, {"text": "To evaluate our approach, we consider the same dataset as the one used to evaluate the SCL method ().", "labels": [], "entities": []}, {"text": "The dataset is composed of labeled and unlabeled reviews of four different product types: books, DVDs, electronics and kitchen appliances.", "labels": [], "entities": []}, {"text": "For each domain, the dataset contains 1,000 labeled positive reviews and 1,000 labeled negative reviews, as well as several thousands of unlabeled examples (4,919 reviews per domain in average: ranging from 3,685 for DVDs to 5,945 for kitchen appliances).", "labels": [], "entities": []}, {"text": "As in, we randomly split each labelled portion into 1,600 examples for training and 400 examples for testing.", "labels": [], "entities": []}, {"text": "We evaluate the performance of our domainadaptation approach on every ordered pair of domains.", "labels": [], "entities": []}, {"text": "For every pair, the semi-supervised methods use labeled data from the source domain and unlabeled data from both domains.", "labels": [], "entities": []}, {"text": "We compare them with two supervised methods: a supervised model (Base) which is trained on the source domain data only, and another supervised model (Indomain) which is learned on the labeled data from the target domain.", "labels": [], "entities": []}, {"text": "The Base model can be regarded as a natural baseline model, whereas the In-domain model is essentially an upper-bound for any domainadaptation method.", "labels": [], "entities": []}, {"text": "All the methods, supervised and semi-supervised, are based on the model described in Section 2.", "labels": [], "entities": []}, {"text": "Instead of using the full set of bigram and unigram counts as features, we use a frequency cut-off of 30 to remove infrequent ngrams.", "labels": [], "entities": []}, {"text": "This does not seem to have an adverse effect on the accuracy but makes learning very efficient: the average training time for the semi-supervised methods was about 20 minutes on a standard PC.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 52, "end_pos": 60, "type": "METRIC", "confidence": 0.9994578957557678}]}, {"text": "We coarsely tuned the parameters of the learning methods using a form of cross-validation.", "labels": [], "entities": []}, {"text": "Both the parameter of the multi-conditional objective \u03b1 (see Section 2) and the weighting for the constraint \u03b2 (see Section 3.2) were set to 5.", "labels": [], "entities": []}, {"text": "We used 25 iterations of stochastic gradient descent.", "labels": [], "entities": []}, {"text": "The initial learning rate and the weight decay (the inverse squared variance of the Gaussian prior) were set to 0.01, and both parameters were reduced by the factor of 2 every iteration the objective function estimate went down.", "labels": [], "entities": [{"text": "weight decay", "start_pos": 34, "end_pos": 46, "type": "METRIC", "confidence": 0.9342095851898193}, {"text": "inverse squared variance", "start_pos": 52, "end_pos": 76, "type": "METRIC", "confidence": 0.8053288261095682}]}, {"text": "The size of the latent representation was equal to 10.", "labels": [], "entities": []}, {"text": "The stochastic weight updates were amortized with the momentum (\u03b3) of 0.99.", "labels": [], "entities": [{"text": "momentum (\u03b3)", "start_pos": 54, "end_pos": 66, "type": "METRIC", "confidence": 0.9382911175489426}]}, {"text": "We trained the model both without regularization of the domain variability (NoReg, \u03b2 = 0), and with the regularizing term (Reg).", "labels": [], "entities": []}, {"text": "For the SCL method to produce an accurate classifier for the target domain it is necessary to train a classifier using both the induced shared representation and the initial nontransformed representation.", "labels": [], "entities": []}, {"text": "In our case, due to joint learning and non-convexity of the learning problem, this approach would be problematic.", "labels": [], "entities": []}, {"text": "Instead, we combine predictions of the semi-supervised models Reg and NoReg with the baseline out-of-domain model (Base) using the product-of-experts combination, the corresponding methods are called In all our models, we augmented the vector z with an additional component set to 0 for examples in the source domain and to 1 for the target domain examples.", "labels": [], "entities": []}, {"text": "In this way, we essentially subtracted a unigram domain-specific model from our latent variable model in the hope that this will further reduce the domain dependence of the rest of the model parameters.", "labels": [], "entities": []}, {"text": "In preliminary experiments, this modification was beneficial for all the models including the non-constrained one (NoReg).", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Drop in the accuracy score due to the transfer  for the 4 domains: (B)ooks, (D)VD, (E)electronics and  (K)itchen appliances, and in average over the domains.", "labels": [], "entities": [{"text": "accuracy score", "start_pos": 22, "end_pos": 36, "type": "METRIC", "confidence": 0.9764390885829926}]}]}