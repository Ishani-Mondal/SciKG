{"title": [{"text": "A New Dataset and Method for Automatically Grading ESOL Texts", "labels": [], "entities": [{"text": "Automatically Grading ESOL Texts", "start_pos": 29, "end_pos": 61, "type": "TASK", "confidence": 0.6855422258377075}]}], "abstractContent": [{"text": "We demonstrate how supervised discrimina-tive machine learning techniques can be used to automate the assessment of 'English as a Second or Other Language' (ESOL) examination scripts.", "labels": [], "entities": [{"text": "assessment of 'English as a Second or Other Language' (ESOL) examination scripts", "start_pos": 102, "end_pos": 182, "type": "TASK", "confidence": 0.7321520913392305}]}, {"text": "In particular, we use rank preference learning to explicitly model the grade relationships between scripts.", "labels": [], "entities": []}, {"text": "A number of different features are extracted and ablation tests are used to investigate their contribution to overall performance.", "labels": [], "entities": []}, {"text": "A comparison between regression and rank preference models further supports our method.", "labels": [], "entities": []}, {"text": "Experimental results on the first publically available dataset show that our system can achieve levels of performance close to the upper bound for the task, as defined by the agreement between human examiners on the same corpus.", "labels": [], "entities": []}, {"text": "Finally, using a set of 'outlier' texts, we test the validity of our model and identify cases where the model's scores diverge from that of a human examiner.", "labels": [], "entities": []}], "introductionContent": [{"text": "The task of automated assessment of free text focuses on automatically analysing and assessing the quality of writing competence.", "labels": [], "entities": []}, {"text": "Automated assessment systems exploit textual features in order to measure the overall quality and assign a score to a text.", "labels": [], "entities": []}, {"text": "The earliest systems used superficial features, such as word and sentence length, as proxies for understanding the text.", "labels": [], "entities": []}, {"text": "More recent systems have used more sophisticated automated text processing techniques to measure grammaticality, textual coherence, prespecified errors, and so forth.", "labels": [], "entities": []}, {"text": "Deployment of automated assessment systems gives a number of advantages, such as the reduced workload in marking texts, especially when applied to large-scale assessments.", "labels": [], "entities": []}, {"text": "Additionally, automated systems guarantee the application of the same marking criteria, thus reducing inconsistency, which may arise when more than one human examiner is employed.", "labels": [], "entities": [{"text": "inconsistency", "start_pos": 102, "end_pos": 115, "type": "METRIC", "confidence": 0.9794942140579224}]}, {"text": "Often, implementations include feedback with respect to the writers' writing abilities, thus facilitating self-assessment and self-tutoring.", "labels": [], "entities": []}, {"text": "Implicitly or explicitly, previous work has mostly treated automated assessment as a supervised text classification task, where training texts are labelled with a grade and unlabelled test texts are fitted to the same grade point scale via a regression step applied to the classifier output (see Section 6 for more.", "labels": [], "entities": [{"text": "text classification", "start_pos": 96, "end_pos": 115, "type": "TASK", "confidence": 0.7580273449420929}]}, {"text": "Different techniques have been used, including cosine similarity of vectors representing text in various ways), often combined with dimensionality reduction techniques such as Latent Semantic Analysis (LSA) (, generative machine learning models), domain-specific feature extraction (), and/or modified syntactic parsers.", "labels": [], "entities": [{"text": "Latent Semantic Analysis (LSA)", "start_pos": 176, "end_pos": 206, "type": "TASK", "confidence": 0.7333705027898153}, {"text": "generative machine learning", "start_pos": 210, "end_pos": 237, "type": "TASK", "confidence": 0.8407355745633444}, {"text": "domain-specific feature extraction", "start_pos": 247, "end_pos": 281, "type": "TASK", "confidence": 0.6354617973168691}]}, {"text": "A recent review identifies twelve different automated free-text scoring systems.", "labels": [], "entities": []}, {"text": "Examples include e-Rater (), Intelligent Essay Assessor (IEA) (, IntelliMetric) and Project Essay Grade (PEG).", "labels": [], "entities": []}, {"text": "Several of these are now deployed in highstakes assessment of examination scripts.", "labels": [], "entities": [{"text": "highstakes assessment of examination scripts", "start_pos": 37, "end_pos": 81, "type": "TASK", "confidence": 0.7682802557945252}]}, {"text": "Although there are many published analyses of the perfor-mance of individual systems, as yet there is no publically available shared dataset for training and testing such systems and comparing their performance.", "labels": [], "entities": []}, {"text": "As it is likely that the deployment of such systems will increase, standardised and independent evaluation methods are important.", "labels": [], "entities": []}, {"text": "We make such a dataset of ESOL examination scripts available 1 (see Section 2 for more details), describe our novel approach to the task, and provide results for our system on this dataset.", "labels": [], "entities": []}, {"text": "We address automated assessment as a supervised discriminative machine learning problem and particularly as a rank preference problem).", "labels": [], "entities": []}, {"text": "Our reasons are twofold: Discriminative classification techniques often outperform non-discriminative ones in the context of text classification.", "labels": [], "entities": [{"text": "Discriminative classification", "start_pos": 25, "end_pos": 54, "type": "TASK", "confidence": 0.7794401347637177}, {"text": "text classification", "start_pos": 125, "end_pos": 144, "type": "TASK", "confidence": 0.7668757140636444}]}, {"text": "Additionally, rank preference techniques) allow us to explicitly learn an optimal ranking model of text quality.", "labels": [], "entities": []}, {"text": "Learning a ranking directly, rather than fitting a classifier score to a grade point scale after training, is both a more generic approach to the task and one which exploits the labelling information in the training data efficiently and directly.", "labels": [], "entities": []}, {"text": "Techniques such as LSA measure, in addition to writing competence, the semantic relevance of a text written in response to a given prompt.", "labels": [], "entities": []}, {"text": "However, although our corpus of manually-marked texts was produced by learners of English in response to prompts eliciting free-text answers, the marking criteria are primarily based on the accurate use of a range of different linguistic constructions.", "labels": [], "entities": []}, {"text": "For this reason, we believe that an approach which directly measures linguistic competence will be better suited to ESOL text assessment, and will have the additional advantage that it may not require retraining for new prompts or tasks.", "labels": [], "entities": [{"text": "ESOL text assessment", "start_pos": 116, "end_pos": 136, "type": "TASK", "confidence": 0.82823246717453}]}, {"text": "As far as we know, this is the first application of a rank preference model to automated assessment (hereafter AA).", "labels": [], "entities": [{"text": "AA", "start_pos": 111, "end_pos": 113, "type": "METRIC", "confidence": 0.9846003651618958}]}, {"text": "In this paper, we report experiments on rank preference Support Vector Machines (SVMs) trained on a relatively small amount of data, on identification of appropriate feature types derived automatically from generic text processing tools, on comparison with a regression SVM model, and on the robustness of the best model to 'outlier' texts.", "labels": [], "entities": []}, {"text": "1 http://www.ilexir.com/ We report a consistent, comparable and replicable set of results based entirely on the new dataset and on public-domain tools and data, whilst also experimentally motivating some novel feature types for the AA task, thus extending the work described in.", "labels": [], "entities": [{"text": "AA task", "start_pos": 232, "end_pos": 239, "type": "TASK", "confidence": 0.931736946105957}]}, {"text": "In the following sections we describe in more detail the dataset used for training and testing, the system developed, the evaluation methodology, as well as ablation experiments aimed at studying the contribution of different feature types to the AA task.", "labels": [], "entities": [{"text": "AA task", "start_pos": 247, "end_pos": 254, "type": "TASK", "confidence": 0.9173077642917633}]}, {"text": "We show experimentally that discriminative models with appropriate feature types can achieve performance close to the upper bound, as defined by the agreement between human examiners on the same test corpus.", "labels": [], "entities": []}], "datasetContent": [{"text": "In order to evaluate our AA system, we use two correlation measures, Pearson's product-moment correlation coefficient and Spearman's rank correlation coefficient (hereafter Pearson's and Spearman's correlation respectively).", "labels": [], "entities": [{"text": "Pearson's product-moment correlation coefficient", "start_pos": 69, "end_pos": 117, "type": "METRIC", "confidence": 0.9310181975364685}, {"text": "Spearman's rank correlation coefficient", "start_pos": 122, "end_pos": 161, "type": "METRIC", "confidence": 0.6635628819465638}]}, {"text": "Pearson's correlation determines the degree to which two linearly dependent variables are related.", "labels": [], "entities": [{"text": "Pearson's correlation", "start_pos": 0, "end_pos": 21, "type": "METRIC", "confidence": 0.520957738161087}]}, {"text": "As Pearson's correlation is sensitive to the distribution of data and, due to outliers, its value can be misleading, we also report Spearman's correlation.", "labels": [], "entities": [{"text": "Pearson's correlation", "start_pos": 3, "end_pos": 24, "type": "METRIC", "confidence": 0.7302435835202535}, {"text": "Spearman's correlation", "start_pos": 132, "end_pos": 154, "type": "METRIC", "confidence": 0.6251944204171499}]}, {"text": "The latter is a nonparametric robust measure of association which is  Pearson's and Spearman's correlation by 0.006 and 0.015 respectively.", "labels": [], "entities": [{"text": "Pearson's and Spearman's correlation", "start_pos": 70, "end_pos": 106, "type": "METRIC", "confidence": 0.6889206568400065}]}, {"text": "The addition of the error-rate obtained from the manually annotated CLC error tags on top of all the features further improves performance by 0.01 and 0.016.", "labels": [], "entities": [{"text": "error-rate", "start_pos": 20, "end_pos": 30, "type": "METRIC", "confidence": 0.977453887462616}]}, {"text": "An evaluation of our best error detection method shows a Pearson correlation of 0.611 between the estimated and the true CLC error counts.", "labels": [], "entities": [{"text": "error detection", "start_pos": 26, "end_pos": 41, "type": "TASK", "confidence": 0.6598735451698303}, {"text": "Pearson correlation", "start_pos": 57, "end_pos": 76, "type": "METRIC", "confidence": 0.9770914316177368}]}, {"text": "This suggests that there is room for improvement in the language models we developed to estimate the error-rate.", "labels": [], "entities": []}, {"text": "In the experiments reported hereafter, we use the ukWaC+CLC LM to calculate the error-rate.", "labels": [], "entities": [{"text": "ukWaC+CLC LM", "start_pos": 50, "end_pos": 62, "type": "DATASET", "confidence": 0.7745146006345749}]}, {"text": "In order to assess the independent as opposed to the order-dependent additive contribution of each feature type to the overall performance of the system, we run a number of ablation tests.", "labels": [], "entities": []}, {"text": "An ablation test consists of removing one feature of the system at a time and re-evaluating the model on the test set.", "labels": [], "entities": []}, {"text": "presents Pearson's and Spearman's correlation between the CLC and our system, when removing one feature at a time.", "labels": [], "entities": []}, {"text": "All features have a positive effect on performance, while the error-rate has a big impact, as its absence is responsible fora 0.061 decrease of Spearman's correlation.", "labels": [], "entities": [{"text": "error-rate", "start_pos": 62, "end_pos": 72, "type": "METRIC", "confidence": 0.9911620616912842}, {"text": "Spearman's correlation", "start_pos": 144, "end_pos": 166, "type": "METRIC", "confidence": 0.7606688936551412}]}, {"text": "In addition, the  removal of either the word ngrams, the PS rules, or the error-rate estimate contributes to a large decrease in Pearson's correlation.", "labels": [], "entities": [{"text": "error-rate estimate", "start_pos": 74, "end_pos": 93, "type": "METRIC", "confidence": 0.952104389667511}, {"text": "Pearson's correlation", "start_pos": 129, "end_pos": 150, "type": "METRIC", "confidence": 0.8986017902692159}]}, {"text": "In order to test the significance of the improved correlations, we ran one-tailed t-tests with a = 0.05 for the difference between dependent correlations.", "labels": [], "entities": []}, {"text": "The results showed that PoS ngrams, PS rules, the complexity measures, and the estimated error-rate contribute significantly to the improvement of Spearman's correlation, while PS rules also contribute significantly to the improvement of Pearson's correlation.", "labels": [], "entities": [{"text": "PoS ngrams", "start_pos": 24, "end_pos": 34, "type": "METRIC", "confidence": 0.7456494569778442}, {"text": "error-rate", "start_pos": 89, "end_pos": 99, "type": "METRIC", "confidence": 0.868872880935669}, {"text": "Spearman's correlation", "start_pos": 147, "end_pos": 169, "type": "METRIC", "confidence": 0.5757529735565186}, {"text": "Pearson's correlation", "start_pos": 238, "end_pos": 259, "type": "METRIC", "confidence": 0.5841489334901174}]}, {"text": "One of the main approaches adopted by previous systems involves the identification of features that measure writing skill, and then the application of linear or stepwise regression to find optimal feature weights so that the correlation with manually assigned scores is maximised.", "labels": [], "entities": []}, {"text": "We trained a SVM regression model with our full set of feature types and compared it to the SVM rank preference model.", "labels": [], "entities": []}, {"text": "The results are given in.", "labels": [], "entities": []}, {"text": "The rank preference model improves Pearson's and Spearman's correlation by 0.044 and 0.067 respectively, and these differences are significant, suggesting that rank preference is a more appropriate model for the AA task.", "labels": [], "entities": [{"text": "Pearson's and Spearman's correlation", "start_pos": 35, "end_pos": 71, "type": "METRIC", "confidence": 0.7371309647957484}, {"text": "AA task", "start_pos": 212, "end_pos": 219, "type": "TASK", "confidence": 0.9013916850090027}]}, {"text": "Four senior and experienced ESOL examiners remarked the 97 FCE test scripts drawn from 2001 exams, using the marking scheme from that year (see Section 2).", "labels": [], "entities": [{"text": "ESOL examiners", "start_pos": 28, "end_pos": 42, "type": "DATASET", "confidence": 0.7664999067783356}, {"text": "FCE test scripts drawn from 2001 exams", "start_pos": 59, "end_pos": 97, "type": "DATASET", "confidence": 0.9342879823275975}]}, {"text": "In order to obtain a ceiling for the performance of our system, we calculate the average correlation between the CLC and the examiners' scores, and find an upper bound of 0.796 and 0.792 Pearson's and Spearman's correlation respectively.", "labels": [], "entities": [{"text": "Pearson's and Spearman's correlation", "start_pos": 187, "end_pos": 223, "type": "METRIC", "confidence": 0.8141011049350103}]}, {"text": "In order to evaluate the overall performance of our system, we calculate its correlation with the four senior examiners in addition to the RASCH-adjusted CLC scores.", "labels": [], "entities": [{"text": "RASCH-adjusted CLC scores", "start_pos": 139, "end_pos": 164, "type": "METRIC", "confidence": 0.8066076636314392}]}, {"text": "The average correlation of the AA system with the CLC and the examiner scores shows that it is close    to the upper bound for the task.", "labels": [], "entities": [{"text": "AA", "start_pos": 31, "end_pos": 33, "type": "METRIC", "confidence": 0.9980803728103638}]}, {"text": "Human-machine agreement is comparable to that of human-human agreement, with the exception of Pearson's correlation with examiner E4 and Spearman's correlation with examiners E1 and E4, where the discrepancies are higher.", "labels": [], "entities": [{"text": "Pearson", "start_pos": 94, "end_pos": 101, "type": "METRIC", "confidence": 0.8467405438423157}]}, {"text": "It is likely that a larger training set and/or more consistent grading of the existing training data would help to close this gap.", "labels": [], "entities": []}, {"text": "However, our system is not measuring some properties of the scripts, such as discourse cohesion or relevance to the prompt eliciting the text, that examiners will take into account.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Correlation between the CLC scores and the AA  system predicted values.", "labels": [], "entities": [{"text": "AA", "start_pos": 53, "end_pos": 55, "type": "METRIC", "confidence": 0.9915396571159363}]}, {"text": " Table 2: Ablation tests showing the correlation between  the CLC and the AA system.", "labels": [], "entities": [{"text": "Ablation", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9966238737106323}, {"text": "AA", "start_pos": 74, "end_pos": 76, "type": "METRIC", "confidence": 0.9520446062088013}]}, {"text": " Table 3: Comparison between regression and rank pref- erence model.", "labels": [], "entities": [{"text": "rank pref- erence", "start_pos": 44, "end_pos": 61, "type": "METRIC", "confidence": 0.7121569737792015}]}, {"text": " Table 4: Pearson's correlation of the AA system predicted  values with the CLC and the examiners' scores, where E1  refers to the first examiner, E2 to the second etc.", "labels": [], "entities": [{"text": "AA", "start_pos": 39, "end_pos": 41, "type": "METRIC", "confidence": 0.9705497622489929}]}, {"text": " Table 5: Spearman's correlation of the AA system pre- dicted values with the CLC and the examiners' scores,  where E1 refers to the first examiner, E2 to the second  etc.", "labels": [], "entities": [{"text": "AA system pre- dicted", "start_pos": 40, "end_pos": 61, "type": "METRIC", "confidence": 0.8773877501487732}]}, {"text": " Table 6: Correlation between the predicted values and the  examiner's scores on 'outlier' texts.", "labels": [], "entities": [{"text": "Correlation", "start_pos": 10, "end_pos": 21, "type": "METRIC", "confidence": 0.956976592540741}]}]}