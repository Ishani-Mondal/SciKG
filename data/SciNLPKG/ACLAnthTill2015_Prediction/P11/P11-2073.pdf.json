{"title": [{"text": "Improving Decoding Generalization for Tree-to-String Translation", "labels": [], "entities": [{"text": "Improving Decoding Generalization", "start_pos": 0, "end_pos": 33, "type": "TASK", "confidence": 0.8964937726656595}, {"text": "Tree-to-String Translation", "start_pos": 38, "end_pos": 64, "type": "TASK", "confidence": 0.7695356607437134}]}], "abstractContent": [{"text": "To address the parse error issue for tree-to-string translation, this paper proposes a similarity-based decoding generation (SDG) solution by reconstructing similar source parse trees for decoding at the decoding time instead of taking multiple source parse trees as input for decoding.", "labels": [], "entities": [{"text": "tree-to-string translation", "start_pos": 37, "end_pos": 63, "type": "TASK", "confidence": 0.7635339796543121}, {"text": "similarity-based decoding generation (SDG)", "start_pos": 87, "end_pos": 129, "type": "TASK", "confidence": 0.8038835028807322}]}, {"text": "Experiments on Chinese-English translation demonstrated that our approach can achieve a significant improvement over the standard method, and has little impact on decoding speed in practice.", "labels": [], "entities": [{"text": "Chinese-English translation", "start_pos": 15, "end_pos": 42, "type": "TASK", "confidence": 0.6628735214471817}]}, {"text": "Our approach is very easy to implement , and can be applied to other paradigms such as tree-to-tree models.", "labels": [], "entities": []}], "introductionContent": [{"text": "Among linguistically syntax-based statistical machine translation (SMT) approaches, the tree-tostring model;) is the simplest and fastest, in which parse trees on source side are used for grammar extraction and decoding.", "labels": [], "entities": [{"text": "linguistically syntax-based statistical machine translation (SMT)", "start_pos": 6, "end_pos": 71, "type": "TASK", "confidence": 0.738077525049448}, {"text": "grammar extraction", "start_pos": 188, "end_pos": 206, "type": "TASK", "confidence": 0.7570075392723083}]}, {"text": "Formally, given a source (e.g., Chinese) string c and its auto-parsed tree T 1-best , the goal of typical tree-to-string SMT is to find a target (e.g., English) string e* by the following equation as ) , | Pr( max arg where Pr(e|c,T 1-best ) is the probability that e is the translation of the given source string c and its T 1-best . A typical tree-to-string decoder aims to search for the best derivation among all consistent derivations that convert source tree into a target-language string.", "labels": [], "entities": [{"text": "SMT", "start_pos": 121, "end_pos": 124, "type": "TASK", "confidence": 0.9341942071914673}]}, {"text": "We call this set of consistent derivations the tree-to-string search space.", "labels": [], "entities": []}, {"text": "Each derivation in the search space respects the source parse tree.", "labels": [], "entities": []}, {"text": "Parsing errors on source parse trees would cause negative effects on tree-to-string translation due to decoding on incorrect source parse trees.", "labels": [], "entities": []}, {"text": "To address the parse error issue in tree-to-string translation, a natural solution is to use n-best parse trees instead of 1-best parse tree as input for decoding, which can be expressed by where <T n-best > denotes a set of n-best parse trees of c produced by a state-of-the-art syntactic parser.", "labels": [], "entities": []}, {"text": "A simple alternative) to generate <T n-best > is to utilize multiple parsers, which can improve the diversity among source parse trees in <T n-best >.", "labels": [], "entities": []}, {"text": "In this solution, the most representative work is the forest-based translation method) in which a packed forest (forest for short) structure is used to effectively represent <T n-best > for decoding.", "labels": [], "entities": []}, {"text": "Forest-based approaches can increase the treeto-string search space for decoding, but face a nontrivial problem of high decoding time complexity in practice.", "labels": [], "entities": []}, {"text": "In this paper, we propose anew solution by reconstructing new similar source parse trees for decoding, referred to as similarity-based decoding generation (SDG), which is expressed as where <T sim > denotes a set of similar parse trees of T 1-best that are dynamically reconstructed at the de-coding time.", "labels": [], "entities": [{"text": "similarity-based decoding generation (SDG)", "start_pos": 118, "end_pos": 160, "type": "TASK", "confidence": 0.7956776320934296}]}, {"text": "Roughly speaking, <T n-best > is a subset of {T 1-best , <T sim >}.", "labels": [], "entities": []}, {"text": "Along this line of thinking, Equation (2) can be considered as a special case of Equation (3).", "labels": [], "entities": [{"text": "Equation", "start_pos": 29, "end_pos": 37, "type": "METRIC", "confidence": 0.8193715810775757}]}, {"text": "In our SDG solution, given a source parse tree T 1-best , the key is how to generate its <T sim > at the decoding time.", "labels": [], "entities": []}, {"text": "In practice, it is almost intractable to directly reconstructing <T sim > in advance as input for decoding due to too high computation complexity.", "labels": [], "entities": []}, {"text": "To address this crucial challenge, this paper presents a simple and effective technique based on similarity-based matching constraints to construct new similar source parse trees for decoding at the decoding time.", "labels": [], "entities": []}, {"text": "Our SDG approach can explicitly increase the tree-to-string search space for decoding without changing any grammar extraction and pruning settings, and has little impact on decoding speed in practice.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1. BLEU4 (%) scores of various methods on Dev  set (MT03) and two test sets (MT04 and MT05). Each  small test set (<=20) was built by removing the sen- tences with more than 20 words from the full set (ALL).  + and * indicate significantly better on performance  comparison at p < .05 and p < .01, respectively.", "labels": [], "entities": [{"text": "BLEU4", "start_pos": 10, "end_pos": 15, "type": "METRIC", "confidence": 0.9989718198776245}, {"text": "MT03", "start_pos": 59, "end_pos": 63, "type": "DATASET", "confidence": 0.47738420963287354}, {"text": "MT04", "start_pos": 84, "end_pos": 88, "type": "DATASET", "confidence": 0.9567016959190369}, {"text": "MT05", "start_pos": 93, "end_pos": 97, "type": "DATASET", "confidence": 0.8700874447822571}]}]}