{"title": [{"text": "Ordering Prenominal Modifiers with a Reranking Approach", "labels": [], "entities": [{"text": "Reranking Approach", "start_pos": 37, "end_pos": 55, "type": "METRIC", "confidence": 0.5986493527889252}]}], "abstractContent": [{"text": "In this work, we present a novel approach to the generation task of ordering prenomi-nal modifiers.", "labels": [], "entities": []}, {"text": "We take a maximum entropy reranking approach to the problem which admits arbitrary features on a permutation of modifiers, exploiting hundreds of thousands of features in total.", "labels": [], "entities": []}, {"text": "We compare our error rates to the state-of-the-art and to a strong Google n-gram count baseline.", "labels": [], "entities": [{"text": "error", "start_pos": 15, "end_pos": 20, "type": "METRIC", "confidence": 0.948482871055603}]}, {"text": "We attain a maximum error reduction of 69.8% and average error reduction across all test sets of 59.1% compared to the state-of-the-art and a maximum error reduction of 68.4% and average error reduction across all test sets of 41.8% compared to our Google n-gram count baseline.", "labels": [], "entities": [{"text": "error reduction", "start_pos": 20, "end_pos": 35, "type": "METRIC", "confidence": 0.904612272977829}, {"text": "error reduction", "start_pos": 57, "end_pos": 72, "type": "METRIC", "confidence": 0.872736394405365}, {"text": "error reduction", "start_pos": 150, "end_pos": 165, "type": "METRIC", "confidence": 0.8714026808738708}, {"text": "error reduction", "start_pos": 187, "end_pos": 202, "type": "METRIC", "confidence": 0.9225420951843262}, {"text": "Google n-gram count baseline", "start_pos": 249, "end_pos": 277, "type": "DATASET", "confidence": 0.8063100725412369}]}], "introductionContent": [{"text": "Speakers rarely have difficulty correctly ordering modifiers such as adjectives, adverbs, or gerunds when describing some noun.", "labels": [], "entities": []}, {"text": "The phrase \"beautiful blue Macedonian vase\" sounds very natural, whereas changing the modifier ordering to \"blue Macedonian beautiful vase\" is awkward (see for more examples).", "labels": [], "entities": []}, {"text": "In this work, we consider the task of ordering an unordered set of prenominal modifiers so that they sound fluent to native language speakers.", "labels": [], "entities": []}, {"text": "This is an important task for natural language generation systems.", "labels": [], "entities": [{"text": "natural language generation", "start_pos": 30, "end_pos": 57, "type": "TASK", "confidence": 0.6472289264202118}]}, {"text": "Much linguistic research has investigated the semantic constraints behind prenominal modifier orderings.", "labels": [], "entities": []}, {"text": "One common line of research suggests that modifiers can be organized by the underlying semantic property they describe and that there is.", "labels": [], "entities": []}, {"text": "The most natural sounding ordering is in bold, followed by other possibilities that may only be appropriate in certain situations.", "labels": [], "entities": []}, {"text": "an ordering on semantic properties which in turn restricts modifier orderings.", "labels": [], "entities": []}, {"text": "For instance, contend that the size property precedes the color property and thus \"small black cat\" sounds more fluent than \"black small cat\".", "labels": [], "entities": []}, {"text": "Using > to denote precedence of semantic groups, some commonly proposed orderings are: quality > size > shape > color > provenance (, age > color > participle > provenance > noun > denominal (, and value > dimension > physical property > speed > human propensity > age > color.", "labels": [], "entities": []}, {"text": "However, correctly classifying modifiers into these groups can be difficult and maybe domain dependent or constrained by the context in which the modifier is being used.", "labels": [], "entities": []}, {"text": "In addition, these methods do not specify how to order modifiers within the same class or modifiers that do not fit into any of the specified groups.", "labels": [], "entities": []}, {"text": "There have also been a variety of corpus-based, computational approaches.", "labels": [], "entities": []}, {"text": "Mitchell (2009) uses a class-based approach in which modifiers are grouped into classes based on which positions they prefer in the training corpus, with a predefined ordering imposed on these classes.", "labels": [], "entities": []}, {"text": "Shaw and Hatzivassiloglou (1999) developed three different approaches to the problem that use counting methods and clustering algorithms, and Malouf (2000) expands upon Shaw and Hatzivassiloglou's work.", "labels": [], "entities": []}, {"text": "This paper describes a computational solution to the problem that uses relevant features to model the modifier ordering process.", "labels": [], "entities": []}, {"text": "By mapping a set of features across the training data and using a maximum entropy reranking model, we can learn optimal weights for these features and then order each set of modifiers in the test data according to our features and the learned weights.", "labels": [], "entities": []}, {"text": "This approach has not been used before to solve the prenominal modifier ordering problem, and as we demonstrate, vastly outperforms the state-of-the-art, especially for sequences of longer lengths.", "labels": [], "entities": [{"text": "prenominal modifier ordering problem", "start_pos": 52, "end_pos": 88, "type": "TASK", "confidence": 0.7073944881558418}]}, {"text": "Section 2 of this paper describes previous computational approaches.", "labels": [], "entities": []}, {"text": "In Section 3 we present the details of our maximum entropy reranking approach.", "labels": [], "entities": []}, {"text": "Section 4 covers the evaluation methods we used, and Section 5 presents our results.", "labels": [], "entities": []}, {"text": "In Section 6 we compare our approach to previous methods, and in Section 7 we discuss future work and improvements that could be made to our system.", "labels": [], "entities": []}], "datasetContent": [{"text": "To evaluate our system (MAXENT) and our baselines, we partitioned the corpora into training and testing data.", "labels": [], "entities": [{"text": "MAXENT", "start_pos": 24, "end_pos": 30, "type": "METRIC", "confidence": 0.8537537455558777}]}, {"text": "For each NP in the test data, we generated a set of modifiers and looked at the predicted orderings of the MAXENT, CLASS BASED, and GOOGLE N-GRAM methods.", "labels": [], "entities": [{"text": "MAXENT", "start_pos": 107, "end_pos": 113, "type": "METRIC", "confidence": 0.8031032681465149}, {"text": "CLASS", "start_pos": 115, "end_pos": 120, "type": "METRIC", "confidence": 0.8132926821708679}, {"text": "BASED", "start_pos": 121, "end_pos": 126, "type": "METRIC", "confidence": 0.5828968286514282}, {"text": "GOOGLE", "start_pos": 132, "end_pos": 138, "type": "DATASET", "confidence": 0.5129745006561279}]}, {"text": "We considered a predicted sequence ordering to be correct if it matches the original ordering of the modifiers in the corpus.", "labels": [], "entities": []}, {"text": "We ran four trials, the first holding out the Brown corpus and using it as the test set, the second holding out the WSJ corpus, the third holding out the Switchboard corpus, and the fourth holding out a randomly selected tenth of the NANC.", "labels": [], "entities": [{"text": "Brown corpus", "start_pos": 46, "end_pos": 58, "type": "DATASET", "confidence": 0.976220041513443}, {"text": "WSJ corpus", "start_pos": 116, "end_pos": 126, "type": "DATASET", "confidence": 0.9516876041889191}, {"text": "Switchboard corpus", "start_pos": 154, "end_pos": 172, "type": "DATASET", "confidence": 0.9004587531089783}, {"text": "NANC", "start_pos": 234, "end_pos": 238, "type": "DATASET", "confidence": 0.9747945070266724}]}, {"text": "For each trial we used the rest of the data as our training set.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 3: Number of NPs extracted from our data for NP sequences with 1 to 5 modifiers.", "labels": [], "entities": []}, {"text": " Table 4: Token and type prediction accuracies for the GOOGLE N-GRAM, MAXENT, and CLASS BASED approaches  for modifier sequences of lengths 2-5. Our data consisted of four corpuses: Brown, Switchboard, WSJ, and NANC.  The test data was held out and each approach was trained on the rest of the data. Winning scores are in bold. The  number of features used during training for the MAXENT approach for each test corpus is also listed.", "labels": [], "entities": [{"text": "type prediction", "start_pos": 20, "end_pos": 35, "type": "TASK", "confidence": 0.6324007660150528}, {"text": "GOOGLE", "start_pos": 55, "end_pos": 61, "type": "METRIC", "confidence": 0.4956510066986084}, {"text": "BASED", "start_pos": 88, "end_pos": 93, "type": "METRIC", "confidence": 0.6928001642227173}]}]}