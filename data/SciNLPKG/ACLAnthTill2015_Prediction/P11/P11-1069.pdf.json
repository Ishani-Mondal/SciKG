{"title": [], "abstractContent": [{"text": "CCGs are directly compatible with binary-branching bottom-up parsing algorithms, in particular CKY and shift-reduce algorithms.", "labels": [], "entities": []}, {"text": "While the chart-based approach has been the dominant approach for CCG, the shift-reduce method has been little explored.", "labels": [], "entities": [{"text": "CCG", "start_pos": 66, "end_pos": 69, "type": "TASK", "confidence": 0.9293198585510254}]}, {"text": "In this paper, we develop a shift-reduce CCG parser using a discriminative model and beam search, and compare its strengths and weaknesses with the chart-based C&C parser.", "labels": [], "entities": []}, {"text": "We study different errors made by the two parsers, and show that the shift-reduce parser gives competitive accuracies compared to C&C.", "labels": [], "entities": []}, {"text": "Considering our use of a small beam, and given the high ambiguity levels in an automatically-extracted grammar and the amount of information in the CCG lexical categories which form the shift actions, this is a surprising result.", "labels": [], "entities": []}], "introductionContent": [{"text": "Combinatory Categorial Grammar) is a lexicalised theory of grammar which has been successfully applied to a range of problems in NLP, including treebank creation, syntactic parsing, logical form construction () and surface realization.", "labels": [], "entities": [{"text": "Combinatory Categorial Grammar)", "start_pos": 0, "end_pos": 31, "type": "TASK", "confidence": 0.7198080644011497}, {"text": "treebank creation", "start_pos": 144, "end_pos": 161, "type": "TASK", "confidence": 0.7532387673854828}, {"text": "syntactic parsing", "start_pos": 163, "end_pos": 180, "type": "TASK", "confidence": 0.7166282385587692}, {"text": "logical form construction", "start_pos": 182, "end_pos": 207, "type": "TASK", "confidence": 0.6448293626308441}, {"text": "surface realization", "start_pos": 215, "end_pos": 234, "type": "TASK", "confidence": 0.7264918684959412}]}, {"text": "From a parsing perspective, the C&C parser has been shown to be competitive with state-of-theart statistical parsers on a variety of test suites, including those consisting of grammatical relations, Penn Treebank phrasestructure trees, and unbounded dependencies (.", "labels": [], "entities": [{"text": "Penn Treebank phrasestructure trees", "start_pos": 199, "end_pos": 234, "type": "DATASET", "confidence": 0.9679971784353256}]}, {"text": "The binary branching nature of CCG means that it is naturally compatible with bottom-up parsing algorithms such as shift-reduce and CKY).", "labels": [], "entities": []}, {"text": "However, the parsing work by, and also and, has only considered chart-parsing.", "labels": [], "entities": [{"text": "parsing", "start_pos": 13, "end_pos": 20, "type": "TASK", "confidence": 0.9781907796859741}]}, {"text": "In this paper we fill a gap in the CCG literature by developing a shiftreduce parser for CCG.", "labels": [], "entities": []}, {"text": "Shift-reduce parsers have become popular for dependency parsing, building on the initial work of Yamada and and.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 45, "end_pos": 63, "type": "TASK", "confidence": 0.8878260552883148}]}, {"text": "One advantage of shift-reduce parsers is that the scoring model can be defined over actions, allowing highly efficient parsing by using a greedy algorithm in which the highest scoring action (or a small number of possible actions) is taken at each step.", "labels": [], "entities": []}, {"text": "In addition, high accuracy can be maintained by using a model which utilises a rich set of features for making each local decision ().", "labels": [], "entities": [{"text": "accuracy", "start_pos": 18, "end_pos": 26, "type": "METRIC", "confidence": 0.9994096755981445}]}, {"text": "Following recent work applying global discriminative models to large-scale structured prediction problems (, we build our shift-reduce parser using a global linear model, and compare it with the chartbased C&C parser.", "labels": [], "entities": []}, {"text": "Using standard development and test sets from CCGbank, our shift-reduce parser gives a labeled F-measure of 85.53%, which is competitive with the 85.45% F-measure of the C&C parser on recovery of predicate-argument dependencies from CCGbank.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 95, "end_pos": 104, "type": "METRIC", "confidence": 0.976360559463501}, {"text": "F-measure", "start_pos": 153, "end_pos": 162, "type": "METRIC", "confidence": 0.9905558228492737}]}, {"text": "Hence our work shows that 683 transition-based parsing can be successfully applied to CCG, improving on earlier attempts such as.", "labels": [], "entities": [{"text": "683 transition-based parsing", "start_pos": 26, "end_pos": 54, "type": "TASK", "confidence": 0.4999645749727885}]}, {"text": "Detailed analysis shows that our shift-reduce parser yields a higher precision, lower recall and higher F-score on most of the common CCG dependency types compared to C&C.", "labels": [], "entities": [{"text": "precision", "start_pos": 69, "end_pos": 78, "type": "METRIC", "confidence": 0.9993752837181091}, {"text": "recall", "start_pos": 86, "end_pos": 92, "type": "METRIC", "confidence": 0.9995506405830383}, {"text": "F-score", "start_pos": 104, "end_pos": 111, "type": "METRIC", "confidence": 0.9993748068809509}]}, {"text": "One advantage of the shift-reduce parser is that it easily handles sentences for which it is difficult to find a spanning analysis, which can happen with CCG because the lexical categories at the leaves of a derivation place strong contraints on the set of possible derivations, and the supertagger which provides the lexical categories sometimes makes mistakes.", "labels": [], "entities": []}, {"text": "Unlike the C&C parser, the shift-reduce parser naturally produces fragmentary analyses when appropriate (), and can produce sensible local structures even when a full spanning analysis cannot be found.", "labels": [], "entities": []}, {"text": "Finally, considering this work in the wider parsing context, it provides an interesting comparison between heuristic beam search using a rich set of features, and optimal dynamic programming search where the feature range is restricted.", "labels": [], "entities": [{"text": "heuristic beam search", "start_pos": 107, "end_pos": 128, "type": "TASK", "confidence": 0.604255477587382}]}, {"text": "We are able to perform this comparison because the use of the CCG supertagger means that the C&C parser is able to build the complete chart, from which it can find the optimal derivation, with no pruning whatsoever at the parsing stage.", "labels": [], "entities": []}, {"text": "In contrast, the shift-reduce parser uses a simple beam search with a relatively small beam.", "labels": [], "entities": []}, {"text": "Perhaps surprisingly, given the ambiguity levels in an automatically-extracted grammar, and the amount of information in the CCG lexical categories which form the shift actions, the shift-reduce parser using heuristic beam search is able to outperform the chart-based parser.", "labels": [], "entities": []}], "datasetContent": [{"text": "Our experiments were performed using CCGBank, which was split into three subsets for training (Sections 02-21), development testing (Section 00) and the final test (Section 23).", "labels": [], "entities": [{"text": "CCGBank", "start_pos": 37, "end_pos": 44, "type": "DATASET", "confidence": 0.9389267563819885}]}, {"text": "Extracted from the training data, the CCG grammar used by our parser consists of 3070 binary rule instances and 191 unary rule instances.", "labels": [], "entities": []}, {"text": "We compute F-scores over labeled CCG dependencies and also lexical category accuracy.", "labels": [], "entities": [{"text": "F-scores", "start_pos": 11, "end_pos": 19, "type": "METRIC", "confidence": 0.9203023314476013}, {"text": "accuracy", "start_pos": 76, "end_pos": 84, "type": "METRIC", "confidence": 0.9485791325569153}]}, {"text": "CCG dependencies are defined in terms of lexical categories, by numbering each argument slot in a complex category.", "labels": [], "entities": []}, {"text": "For example, the first NP in a transitive verb category is a CCG dependency relation, corresponding to the subject of the verb.", "labels": [], "entities": []}, {"text": "gives a more precise definition.", "labels": [], "entities": []}, {"text": "We use the generate script from the C&C tools 3 to transform derivations into CCG dependencies.", "labels": [], "entities": []}, {"text": "There is a mismatch between the grammar that generate uses, which is the same grammar as the C&C parser, and the grammar we extract from CCGbank, which contains more rule instances.", "labels": [], "entities": [{"text": "CCGbank", "start_pos": 137, "end_pos": 144, "type": "DATASET", "confidence": 0.9464303851127625}]}, {"text": "Hence generate is unable to produce dependencies for some of the derivations our shift-reduce parser produces.", "labels": [], "entities": []}, {"text": "In order to allow generate to process all derivations from the shift-reduce parser, we repeatedly removed rules that the generate script cannot handle from our grammar, until all derivations in the development data could be dealt with.", "labels": [], "entities": []}, {"text": "In fact, this procedure potentially reduces the accuracy of the shift-reduce parser, but the effect is comparatively small because only about 4% of the development and test sentences contain rules that are not handled by the generate script.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 48, "end_pos": 56, "type": "METRIC", "confidence": 0.9994668364524841}]}, {"text": "All experiments were performed using automati-cally assigned POS-tags, with 10-fold cross validation used to assign POS-tags and lexical categories to the training data.", "labels": [], "entities": []}, {"text": "At the supertagging stage, multiple lexical categories are assigned to each word in the input.", "labels": [], "entities": []}, {"text": "For each word, the supertagger assigns all lexical categories whose forward-backward probability is above \u03b2 \u00b7 max, where max is the highest lexical category probability for the word, and \u03b2 is a threshold parameter.", "labels": [], "entities": []}, {"text": "To give the parser a reasonable freedom in lexical category disambiguation, we used a small \u03b2 value of 0.0001, which results in 3.6 lexical categories being assigned to each word on average in the training data.", "labels": [], "entities": [{"text": "lexical category disambiguation", "start_pos": 43, "end_pos": 74, "type": "TASK", "confidence": 0.6632121006647745}]}, {"text": "For training, but not testing, we also added the correct lexical category to the list of lexical categories fora word in cases when it was not provided by the supertagger.", "labels": [], "entities": []}, {"text": "Increasing the size of the beam in the parser beam search leads to higher accuracies but slower running time.", "labels": [], "entities": [{"text": "accuracies", "start_pos": 74, "end_pos": 84, "type": "METRIC", "confidence": 0.9808381199836731}]}, {"text": "In our development experiments, the accuracy improvement became small when the beam size reached 16, and so we set the size of the beam to 16 for the remainder of the experiments.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 36, "end_pos": 44, "type": "METRIC", "confidence": 0.9995817542076111}]}, {"text": "shows the labeled precision (lp), recall (lr), F-score (lf), sentence-level accuracy (lsent) and lexical category accuracy (cats) of our parser and the C&C parser on the development data.", "labels": [], "entities": [{"text": "labeled precision (lp)", "start_pos": 10, "end_pos": 32, "type": "METRIC", "confidence": 0.7983708024024964}, {"text": "recall (lr)", "start_pos": 34, "end_pos": 45, "type": "METRIC", "confidence": 0.9589201956987381}, {"text": "F-score (lf)", "start_pos": 47, "end_pos": 59, "type": "METRIC", "confidence": 0.9632298052310944}, {"text": "sentence-level accuracy (lsent)", "start_pos": 61, "end_pos": 92, "type": "METRIC", "confidence": 0.7840827941894531}, {"text": "lexical category accuracy (cats)", "start_pos": 97, "end_pos": 129, "type": "METRIC", "confidence": 0.7259691407283148}]}, {"text": "We ran the C&C parser using the normal-form model (we reproduced the numbers reported in), and copied the results of the hybrid model from, since the hybrid model is not part of the public release.", "labels": [], "entities": [{"text": "C&C parser", "start_pos": 11, "end_pos": 21, "type": "DATASET", "confidence": 0.8330828845500946}]}], "tableCaptions": [{"text": " Table 2: Accuracies on the development test data.", "labels": [], "entities": [{"text": "Accuracies", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.9976535439491272}]}, {"text": " Table 3: Accuracy comparison on the most common CCG dependency types. (o) -our parser; (C) -C&C (hybrid)", "labels": [], "entities": []}, {"text": " Table 4: Comparison with C&C; final test. * -not directly comparable.", "labels": [], "entities": []}]}