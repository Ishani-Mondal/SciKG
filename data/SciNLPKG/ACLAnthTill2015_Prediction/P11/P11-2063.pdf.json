{"title": [{"text": "NULEX: An Open-License Broad Coverage Lexicon", "labels": [], "entities": []}], "abstractContent": [{"text": "Broad coverage lexicons for the English language have traditionally been handmade.", "labels": [], "entities": []}, {"text": "This approach, while accurate, requires too much human labor.", "labels": [], "entities": []}, {"text": "Furthermore, resources contain gaps in coverage, contain specific types of information, or are incompatible with other resources.", "labels": [], "entities": []}, {"text": "We believe that the state of open-license technology is such that a comprehensive syntactic lexicon can be automatically compiled.", "labels": [], "entities": []}, {"text": "This paper describes the creation of such a lexicon, NU-LEX, an open-license feature-based lexicon for general purpose parsing that combines WordNet, VerbNet, and Wiktionary and contains over 100,000 words.", "labels": [], "entities": [{"text": "NU-LEX", "start_pos": 53, "end_pos": 59, "type": "DATASET", "confidence": 0.8932583332061768}, {"text": "general purpose parsing", "start_pos": 103, "end_pos": 126, "type": "TASK", "confidence": 0.6180087824662527}, {"text": "WordNet", "start_pos": 141, "end_pos": 148, "type": "DATASET", "confidence": 0.9522132277488708}]}, {"text": "NU-LEX was integrated into a bottom up chart parser.", "labels": [], "entities": [{"text": "NU-LEX", "start_pos": 0, "end_pos": 6, "type": "DATASET", "confidence": 0.9489810466766357}, {"text": "bottom up chart parser", "start_pos": 29, "end_pos": 51, "type": "TASK", "confidence": 0.6475258469581604}]}, {"text": "We ran the parser through three sets of sentences, 50 sentences total, from the Simple English Wikipedia and compared its performance to the same parser using Comlex.", "labels": [], "entities": [{"text": "Simple English Wikipedia", "start_pos": 80, "end_pos": 104, "type": "DATASET", "confidence": 0.8448341886202494}]}, {"text": "Both parsers performed almost equally with NU-LEX finding all lex-items for 50% of the sentences and Comlex succeeding for 52%.", "labels": [], "entities": []}, {"text": "Furthermore, NULEX's shortcomings primarily fell into two categories, suggesting future research directions.", "labels": [], "entities": []}], "introductionContent": [{"text": "While there are many types of parsers available, all of them rely on a lexicon of words, whether syntactic like Comlex, enriched with semantics like WordNet, or derived from tagged corpora like the Penn).", "labels": [], "entities": [{"text": "WordNet", "start_pos": 149, "end_pos": 156, "type": "DATASET", "confidence": 0.9491395354270935}, {"text": "Penn", "start_pos": 198, "end_pos": 202, "type": "DATASET", "confidence": 0.954863965511322}]}, {"text": "However, many of these resources have gaps that the others can fill in.", "labels": [], "entities": []}, {"text": "WordNet, for example, only contains open-class words, and it lacks the extensive subcategorization frame and agreement information present in.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 0, "end_pos": 7, "type": "DATASET", "confidence": 0.9763675332069397}]}, {"text": "Comlex, while syntactically deep, doesn't have tagged usage data or semantic groupings.", "labels": [], "entities": [{"text": "Comlex", "start_pos": 0, "end_pos": 6, "type": "DATASET", "confidence": 0.9067018628120422}]}, {"text": "Furthermore, many of these resources do not map to one another or have restricted licenses.", "labels": [], "entities": []}, {"text": "The goal of our research was to create a syntactic lexicon, like.", "labels": [], "entities": []}, {"text": "Each entry is represented by Cyc assertions and contains syntactic information as a set of features consistent with previous feature systems).", "labels": [], "entities": []}], "datasetContent": [{"text": "The sample sentences consisted of 50 samples from the Simple English Wikipedia 2 articles on the heart, lungs, and George Washington.", "labels": [], "entities": [{"text": "Simple English Wikipedia", "start_pos": 54, "end_pos": 78, "type": "DATASET", "confidence": 0.7805840571721395}, {"text": "George Washington", "start_pos": 115, "end_pos": 132, "type": "DATASET", "confidence": 0.8377445936203003}]}, {"text": "The heart set consisted of the first 25 sentences of the article, not counting parentheticals.", "labels": [], "entities": []}, {"text": "The lungs set consisted of the first 13 sentences of the article.", "labels": [], "entities": []}, {"text": "The George Washington set consisted of the first 12 sentences of that article.", "labels": [], "entities": [{"text": "George Washington set", "start_pos": 4, "end_pos": 25, "type": "DATASET", "confidence": 0.8774718244870504}]}, {"text": "These sets corresponded to the first section or first two sections of each article.", "labels": [], "entities": []}, {"text": "There were 239 unique words in the whole set out of 599 words total.", "labels": [], "entities": []}, {"text": "Each set was parsed by the EANLU parser.", "labels": [], "entities": [{"text": "EANLU parser", "start_pos": 27, "end_pos": 39, "type": "DATASET", "confidence": 0.9173291921615601}]}, {"text": "EANLU is a bottom-up chart parser that uses compositional semantics to translate natural language into Cyc predicate calculus representations.", "labels": [], "entities": [{"text": "EANLU", "start_pos": 0, "end_pos": 5, "type": "DATASET", "confidence": 0.8411583304405212}]}, {"text": "It is based on a Allen's (1995) parser.", "labels": [], "entities": [{"text": "Allen's (1995) parser", "start_pos": 17, "end_pos": 38, "type": "DATASET", "confidence": 0.7959658702214559}]}, {"text": "It runs on top of the FIRE reasoning engine which it uses to query the Cyc KB.", "labels": [], "entities": [{"text": "FIRE reasoning", "start_pos": 22, "end_pos": 36, "type": "TASK", "confidence": 0.541023313999176}, {"text": "Cyc KB", "start_pos": 71, "end_pos": 77, "type": "DATASET", "confidence": 0.9200742244720459}]}, {"text": "Each sentence was evaluated as correct based on whether or not it returned the proper word forms.", "labels": [], "entities": []}, {"text": "Since we are not evaluating EANLU's grammar, we did not formally evaluate the parser's ability to generate a complete parse from the lex-items, but we note informally that parse completeness was generally the same.", "labels": [], "entities": []}, {"text": "Failure occurred if any lex-item was not retrieved or if the parser was unable to parse the sentence due to system memory constraints.", "labels": [], "entities": []}], "tableCaptions": []}