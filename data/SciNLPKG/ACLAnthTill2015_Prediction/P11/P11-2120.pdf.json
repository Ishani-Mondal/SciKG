{"title": [{"text": "Data point selection for cross-language adaptation of dependency parsers", "labels": [], "entities": [{"text": "cross-language adaptation of dependency parsers", "start_pos": 25, "end_pos": 72, "type": "TASK", "confidence": 0.7859692573547363}]}], "abstractContent": [{"text": "We consider a very simple, yet effective, approach to cross language adaptation of dependency parsers.", "labels": [], "entities": [{"text": "cross language adaptation of dependency parsers", "start_pos": 54, "end_pos": 101, "type": "TASK", "confidence": 0.7278121262788773}]}, {"text": "We first remove lexical items from the treebanks and map part-of-speech tags into a common tagset.", "labels": [], "entities": []}, {"text": "We then train a language model on tag sequences in otherwise unlabeled target data and rank labeled source data by perplexity per word of tag sequences from less similar to most similar to the target.", "labels": [], "entities": []}, {"text": "We then train our target language parser on the most similar data points in the source labeled data.", "labels": [], "entities": []}, {"text": "The strategy achieves much better results than a non-adapted baseline and state-of-the-art unsupervised dependency parsing, and results are comparable to more complex projection-based cross language adaptation algorithms .", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 104, "end_pos": 122, "type": "TASK", "confidence": 0.7211371064186096}, {"text": "cross language adaptation", "start_pos": 184, "end_pos": 209, "type": "TASK", "confidence": 0.600041131178538}]}], "introductionContent": [{"text": "While unsupervised dependency parsing has seen rapid progress in recent years, results are still far from the results that can be achieved with supervised parsers and not yet good enough to solve real-world problems.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 19, "end_pos": 37, "type": "TASK", "confidence": 0.7026835083961487}]}, {"text": "In this paper, we will be interested in an alternative strategy, namely cross-language adaptation of dependency parsers.", "labels": [], "entities": [{"text": "cross-language adaptation of dependency parsers", "start_pos": 72, "end_pos": 119, "type": "TASK", "confidence": 0.716834020614624}]}, {"text": "The idea is, briefly put, to learn how to parse Arabic, for example, from, say, a Danish treebank, comparing unlabeled data from both languages.", "labels": [], "entities": [{"text": "Danish treebank", "start_pos": 82, "end_pos": 97, "type": "DATASET", "confidence": 0.8925737738609314}]}, {"text": "This is similar to, but more difficult than most domain adaptation or transfer learning scenarios, where differences between source and target distributions are smaller.", "labels": [], "entities": [{"text": "domain adaptation", "start_pos": 49, "end_pos": 66, "type": "TASK", "confidence": 0.7402346730232239}]}, {"text": "Most previous work in cross-language adaptation has used parallel corpora to project dependency structures across translations using word alignments), but in this paper we show that similar results can be achieved by much simpler means.", "labels": [], "entities": [{"text": "cross-language adaptation", "start_pos": 22, "end_pos": 47, "type": "TASK", "confidence": 0.847901314496994}]}, {"text": "Specifically, we build on the cross-language adaptation algorithm for closely related languages developed by and extend it to much less related languages.", "labels": [], "entities": [{"text": "cross-language adaptation", "start_pos": 30, "end_pos": 55, "type": "TASK", "confidence": 0.7863452434539795}]}], "datasetContent": [], "tableCaptions": []}