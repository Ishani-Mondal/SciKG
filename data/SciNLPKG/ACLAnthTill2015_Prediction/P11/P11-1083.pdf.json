{"title": [{"text": "How to train your multi bottom-up tree transducer", "labels": [], "entities": []}], "abstractContent": [{"text": "The local multi bottom-up tree transducer is introduced and related to the (non-contiguous) synchronous tree sequence substitution grammar.", "labels": [], "entities": []}, {"text": "It is then shown how to obtain a weighted local multi bottom-up tree transducer from a bilingual and biparsed corpus.", "labels": [], "entities": []}, {"text": "Finally, the problem of non-preservation of regularity is addressed.", "labels": [], "entities": []}, {"text": "Three properties that ensure preservation are introduced, and it is discussed how to adjust the rule extraction process such that they are automatically fulfilled.", "labels": [], "entities": [{"text": "rule extraction", "start_pos": 96, "end_pos": 111, "type": "TASK", "confidence": 0.7169080674648285}]}], "introductionContent": [{"text": "A (formal) translation model is at the core of every machine translation system.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 53, "end_pos": 72, "type": "TASK", "confidence": 0.6940166801214218}]}, {"text": "Predominantly, statistical processes are used to instantiate the formal model and derive a specific translation device.", "labels": [], "entities": []}, {"text": "discuss automatically trainable translation models in their seminal paper.", "labels": [], "entities": []}, {"text": "However, the IBM models of are stringbased in the sense that they base the translation decision on the words and their surrounding context.", "labels": [], "entities": []}, {"text": "Contrary, in the field of syntax-based machine translation, the translation models have full access to the syntax of the sentences and can base their decision on it.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 39, "end_pos": 58, "type": "TASK", "confidence": 0.7501974701881409}]}, {"text": "A good exposition to both fields is presented in.", "labels": [], "entities": []}, {"text": "In this paper, we deal exclusively with syntaxbased translation models such as synchronous tree substitution grammars (STSG), multi bottom-up tree transducers (MBOT), and synchronous tree-sequence substitution grammars (STSSG).", "labels": [], "entities": []}, {"text": "gives a good introduction to STSG, which originate from the syntax-directed translation schemes of Aho and Ullman.", "labels": [], "entities": [{"text": "STSG", "start_pos": 29, "end_pos": 33, "type": "TASK", "confidence": 0.878945529460907}]}, {"text": "Roughly speaking, an STSG has rules in which two linked nonterminals are replaced (at the same time) by two corresponding trees containing terminal and nonterminal symbols.", "labels": [], "entities": []}, {"text": "In addition, the nonterminals in the two replacement trees are linked, which creates new linked nonterminals to which further rules can be applied.", "labels": [], "entities": []}, {"text": "Henceforth, we refer to these two trees as input and output tree.", "labels": [], "entities": []}, {"text": "MBOT have been introduced in and are slightly more expressive than STSG.", "labels": [], "entities": [{"text": "MBOT", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.6293300986289978}]}, {"text": "Roughly speaking, they allow one replacement input tree and several output trees in a single rule.", "labels": [], "entities": []}, {"text": "This change and the presence of states yields many algorithmically advantageous properties such as closure under composition, efficient binarization, and efficient input and output restriction [see (].", "labels": [], "entities": []}, {"text": "Finally, STSSG, which have been derived from rational tree relations), have been discussed by,, and.", "labels": [], "entities": [{"text": "STSSG", "start_pos": 9, "end_pos": 14, "type": "TASK", "confidence": 0.6583021879196167}]}, {"text": "They are even more expressive than the local variant of the multi bottom-up tree transducer (LMBOT) that we introduce here and can have several input and output trees in a single rule.", "labels": [], "entities": []}, {"text": "In this contribution, we restrict MBOT to a form that is particularly relevant in machine translation.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 82, "end_pos": 101, "type": "TASK", "confidence": 0.8056426346302032}]}, {"text": "We drop the general state behavior of MBOT and replace it by the common locality tests that are also present in STSG, STSSG, and STAG.", "labels": [], "entities": [{"text": "MBOT", "start_pos": 38, "end_pos": 42, "type": "DATASET", "confidence": 0.7758752703666687}]}, {"text": "The obtained device is the local MBOT (LMBOT).", "labels": [], "entities": [{"text": "MBOT (LMBOT)", "start_pos": 33, "end_pos": 45, "type": "DATASET", "confidence": 0.7403412908315659}]}, {"text": "argued the algorithmical advantages of MBOT over STSG and proposed MBOT as an implementation alternative for STSG.", "labels": [], "entities": [{"text": "MBOT", "start_pos": 39, "end_pos": 43, "type": "DATASET", "confidence": 0.6571712493896484}]}, {"text": "In particular, the training procedure would train STSG; i.e., it would not utilize the additional expressive power of MBOT.", "labels": [], "entities": [{"text": "MBOT", "start_pos": 118, "end_pos": 122, "type": "DATASET", "confidence": 0.9372998476028442}]}, {"text": "However, and demonstrate that the additional expressivity gained from non-contiguous rules greatly improves the translation quality.", "labels": [], "entities": []}, {"text": "In this contribution we address this separation and investigate a training procedure for LMBOT that allows non-contiguous fragments while preserving the algorithmic advantages of MBOT.", "labels": [], "entities": [{"text": "MBOT", "start_pos": 179, "end_pos": 183, "type": "DATASET", "confidence": 0.8762719035148621}]}, {"text": "To this end, we introduce a rule extraction and weight training method for LMBOT that is based on the corresponding procedures for STSG and STSSG.", "labels": [], "entities": [{"text": "rule extraction", "start_pos": 28, "end_pos": 43, "type": "TASK", "confidence": 0.6919810026884079}, {"text": "STSSG", "start_pos": 140, "end_pos": 145, "type": "DATASET", "confidence": 0.8290631771087646}]}, {"text": "However, general LMBOT can be too expressive in the sense that they allow translations that do not preserve regularity.", "labels": [], "entities": []}, {"text": "Preservation of regularity is an important property for efficient representations and efficient algorithms [see (].", "labels": [], "entities": []}, {"text": "Consequently, we present 3 properties that ensure that an LMBOT preserves regularity.", "labels": [], "entities": []}, {"text": "In addition, we shortly discuss how these properties could be enforced in the rule extraction procedure.", "labels": [], "entities": [{"text": "rule extraction", "start_pos": 78, "end_pos": 93, "type": "TASK", "confidence": 0.8439972996711731}]}], "datasetContent": [], "tableCaptions": []}