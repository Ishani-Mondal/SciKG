{"title": [{"text": "Models and Training for Unsupervised Preposition Sense Disambiguation", "labels": [], "entities": [{"text": "Preposition Sense Disambiguation", "start_pos": 37, "end_pos": 69, "type": "TASK", "confidence": 0.8079975843429565}]}], "abstractContent": [{"text": "We present a preliminary study on unsu-pervised preposition sense disambiguation (PSD), comparing different models and training techniques (EM, MAP-EM with L 0 norm, Bayesian inference using Gibbs sampling).", "labels": [], "entities": [{"text": "preposition sense disambiguation (PSD)", "start_pos": 48, "end_pos": 86, "type": "TASK", "confidence": 0.7739795744419098}]}, {"text": "To our knowledge, this is the first attempt at un-supervised preposition sense disambiguation.", "labels": [], "entities": [{"text": "preposition sense disambiguation", "start_pos": 61, "end_pos": 93, "type": "TASK", "confidence": 0.6689648826917013}]}, {"text": "Our best accuracy reaches 56%, a significant improvement (at p <.001) of 16% over the most-frequent-sense baseline.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 9, "end_pos": 17, "type": "METRIC", "confidence": 0.9995751976966858}]}], "introductionContent": [{"text": "Reliable disambiguation of words plays an important role in many NLP applications.", "labels": [], "entities": []}, {"text": "Prepositions are ubiquitous-they account for more than 10% of the 1.16m words in the Brown corpus-and highly ambiguous.", "labels": [], "entities": [{"text": "Brown corpus-and", "start_pos": 85, "end_pos": 101, "type": "DATASET", "confidence": 0.9574520587921143}]}, {"text": "The Preposition Project ( lists an average of 9.76 senses for each of the 34 most frequent English prepositions, while nouns usually have around two (WordNet nouns average about 1.2 senses, 2.7 if monosemous nouns are excluded).", "labels": [], "entities": []}, {"text": "Disambiguating prepositions is thus a challenging and interesting task in itself (as exemplified by the SemEval 2007 task, (), and holds promise for NLP applications such as Information Extraction or Machine Translation.", "labels": [], "entities": [{"text": "Information Extraction", "start_pos": 174, "end_pos": 196, "type": "TASK", "confidence": 0.8355414271354675}, {"text": "Machine Translation", "start_pos": 200, "end_pos": 219, "type": "TASK", "confidence": 0.7964884042739868}]}, {"text": "Given a sentence such as the following: In the morning, he shopped in Rome we ultimately want to be able to annotate it as 1 See () for how using WSD can help MT.", "labels": [], "entities": [{"text": "MT", "start_pos": 159, "end_pos": 161, "type": "TASK", "confidence": 0.9950599074363708}]}, {"text": "Here, the preposition in has two distinct meanings, namely a temporal and a locative one.", "labels": [], "entities": []}, {"text": "Ultimately, we want to disambiguate prepositions not by and for themselves, but in the context of sequential semantic labeling.", "labels": [], "entities": [{"text": "sequential semantic labeling", "start_pos": 98, "end_pos": 126, "type": "TASK", "confidence": 0.6403837402661642}]}, {"text": "This should also improve disambiguation of the words linked by the prepositions (here, morning, shopped, and Rome).", "labels": [], "entities": []}, {"text": "We propose using unsupervised methods in order to leverage unlabeled data, since, to our knowledge, there are no annotated data sets that include both preposition and argument senses.", "labels": [], "entities": []}, {"text": "In this paper, we present our unsupervised framework and show results for preposition disambiguation.", "labels": [], "entities": [{"text": "preposition disambiguation", "start_pos": 74, "end_pos": 100, "type": "TASK", "confidence": 0.8430196344852448}]}, {"text": "We hope to present results for the joint disambiguation of preposition and arguments in a future paper.", "labels": [], "entities": []}, {"text": "The results from this work can be incorporated into a number of NLP problems, such as semantic tagging, which tries to assign not only syntactic, but also semantic categories to unlabeled text.", "labels": [], "entities": [{"text": "semantic tagging", "start_pos": 86, "end_pos": 102, "type": "TASK", "confidence": 0.7129526436328888}]}, {"text": "Knowledge about semantic constraints of prepositional constructions would not only provide better label accuracy, but also aid in resolving prepositional attachment problems.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 104, "end_pos": 112, "type": "METRIC", "confidence": 0.9424120783805847}, {"text": "resolving prepositional attachment", "start_pos": 130, "end_pos": 164, "type": "TASK", "confidence": 0.630352516969045}]}, {"text": "Learning by Reading approaches) also crucially depend on unsupervised techniques as the ones described here for textual enrichment.", "labels": [], "entities": [{"text": "textual enrichment", "start_pos": 112, "end_pos": 130, "type": "TASK", "confidence": 0.7592273056507111}]}, {"text": "Our contributions are: \u2022 we present the first unsupervised preposition sense disambiguation (PSD) system \u2022 we compare the effectiveness of various models and unsupervised training methods \u2022 we present ways to extend this work to prepositional arguments", "labels": [], "entities": [{"text": "preposition sense disambiguation (PSD)", "start_pos": 59, "end_pos": 97, "type": "TASK", "confidence": 0.7989036440849304}]}], "datasetContent": [], "tableCaptions": []}