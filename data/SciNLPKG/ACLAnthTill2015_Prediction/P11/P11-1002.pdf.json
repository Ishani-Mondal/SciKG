{"title": [], "abstractContent": [{"text": "In this work, we tackle the task of machine translation (MT) without parallel training data.", "labels": [], "entities": [{"text": "machine translation (MT)", "start_pos": 36, "end_pos": 60, "type": "TASK", "confidence": 0.8850724101066589}]}, {"text": "We frame the MT problem as a de-cipherment task, treating the foreign text as a cipher for English and present novel methods for training translation models from non-parallel text.", "labels": [], "entities": [{"text": "MT problem", "start_pos": 13, "end_pos": 23, "type": "TASK", "confidence": 0.9261487424373627}]}], "introductionContent": [{"text": "Bilingual corpora area staple of statistical machine translation (SMT) research.", "labels": [], "entities": [{"text": "statistical machine translation (SMT) research", "start_pos": 33, "end_pos": 79, "type": "TASK", "confidence": 0.8479333519935608}]}, {"text": "From these corpora, we estimate translation model parameters: wordto-word translation tables, fertilities, distortion parameters, phrase tables, syntactic transformations, etc.", "labels": [], "entities": [{"text": "wordto-word translation", "start_pos": 62, "end_pos": 85, "type": "TASK", "confidence": 0.6331411451101303}]}, {"text": "Starting with the classic IBM work, training has been viewed as a maximization problem involving hidden word alignments (a) that are assumed to underlie observed sentence pairs (e, f ): arg max Brown et al. give various formulas that boil P \u03b8 (f, a|e) down to the specific parameters to be estimated.", "labels": [], "entities": []}, {"text": "Of course, for many language pairs and domains, parallel data is not available.", "labels": [], "entities": []}, {"text": "In this paper, we address the problem of learning a full translation model from non-parallel data, and we use the learned model to translate new foreign strings.", "labels": [], "entities": []}, {"text": "As successful work develops along this line, we expect more domains and language pairs to be conquered by SMT.", "labels": [], "entities": [{"text": "SMT", "start_pos": 106, "end_pos": 109, "type": "TASK", "confidence": 0.9790059924125671}]}, {"text": "How can we learn a translation model from nonparallel data?", "labels": [], "entities": []}, {"text": "Intuitively, we try to construct translation model tables which, when applied to observed foreign text, consistently yield sensible English.", "labels": [], "entities": []}, {"text": "This is essentially the same approach taken by cryptanalysts and epigraphers when they deal with source texts.", "labels": [], "entities": []}, {"text": "In our case, we observe a large number of foreign strings f , and we apply maximum likelihood training: Following Weaver (1955), we imagine that this corpus of foreign strings \"is really written in English, but has been coded in some strange symbols,\" thus: The variable e ranges overall possible English strings, and P (e) is a language model built from large amounts of English text that is unrelated to the foreign strings.", "labels": [], "entities": []}, {"text": "Re-writing for hidden alignments, we get: Note that this formula has the same free P \u03b8 (f, a|e) parameters as expression.", "labels": [], "entities": []}, {"text": "We seek to manipulate these parameters in order to learn the same full translation model.", "labels": [], "entities": []}, {"text": "We note that for each f , not only is the alignment a still hidden, but now the English translation e is hidden as well.", "labels": [], "entities": []}, {"text": "A language model P (e) is typically used in SMT decoding, but here P (e) actually plays a central role in training translation model parameters.", "labels": [], "entities": [{"text": "SMT decoding", "start_pos": 44, "end_pos": 56, "type": "TASK", "confidence": 0.9490177631378174}]}, {"text": "To distinguish the two, we refer to (5) as decipherment, rather than decoding.", "labels": [], "entities": []}, {"text": "We can now draw on previous decipherment work for solving simpler substitution/transposition ciphers).", "labels": [], "entities": []}, {"text": "We must keep in mind, however, that foreign language is a much more demanding code, involving highly nondeterministic mappings and very large substitution tables.", "labels": [], "entities": []}, {"text": "The contributions of this paper are therefore: \u2022 We give first results for training a full translation model from non-parallel text, and we apply the model to translate previously-unseen text.", "labels": [], "entities": []}, {"text": "This work is thus distinguished from prior work on extracting or augmenting partial lexicons using non-parallel corpora.", "labels": [], "entities": []}, {"text": "It also contrasts with self-training (), which requires a parallel seed and often does not engage in iterative maximization.", "labels": [], "entities": []}, {"text": "\u2022 We develop novel methods to deal with largescale vocabularies inherent in MT problems.", "labels": [], "entities": [{"text": "MT", "start_pos": 76, "end_pos": 78, "type": "TASK", "confidence": 0.9937937259674072}]}], "datasetContent": [{"text": "Data: For the word substitution experiments, we use two corpora: \u2022 Temporal expression corpus containing short English temporal expressions such as \"THE NEXT MONTH\", \"THE LAST THREE YEARS\", etc.", "labels": [], "entities": [{"text": "word substitution", "start_pos": 14, "end_pos": 31, "type": "TASK", "confidence": 0.7708180546760559}, {"text": "THE NEXT MONTH", "start_pos": 149, "end_pos": 163, "type": "METRIC", "confidence": 0.7954336802164713}, {"text": "THE LAST THREE YEARS", "start_pos": 167, "end_pos": 187, "type": "METRIC", "confidence": 0.41559427231550217}]}, {"text": "The cipher data contains 5000 expressions (9619 tokens, 153 word types).", "labels": [], "entities": []}, {"text": "We also have access to a separate English corpus (which is not parallel to the ciphertext) containing 125k temporal expressions (242k word tokens, 201 word types) for LM training.", "labels": [], "entities": [{"text": "LM training", "start_pos": 167, "end_pos": 178, "type": "TASK", "confidence": 0.9132807552814484}]}, {"text": "\u2022 build an English word n-gram LM, which is used in the decipherment process.", "labels": [], "entities": []}, {"text": "Evaluation: We compute the accuracy of a particular decipherment as the percentage of cipher tokens that were correctly deciphered from the whole corpus.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 27, "end_pos": 35, "type": "METRIC", "confidence": 0.999204695224762}]}, {"text": "We run the two methods (Iterative EM 4 and Bayesian) and then compare them in terms of word substitution decipherment accuracies.", "labels": [], "entities": []}, {"text": "Results: compares the word substitution results from Iterative EM and Bayesian decipherment.", "labels": [], "entities": [{"text": "word substitution", "start_pos": 22, "end_pos": 39, "type": "TASK", "confidence": 0.6845202296972275}]}, {"text": "Both methods achieve high accuracies, decoding 70-90% of the two word substitution ciphers.", "labels": [], "entities": [{"text": "accuracies", "start_pos": 26, "end_pos": 36, "type": "METRIC", "confidence": 0.981664776802063}]}, {"text": "Overall, Bayesian decipherment (with sparse priors) performs better than Iterative EM and achieves the best results on this task.", "labels": [], "entities": []}, {"text": "We also observe that both methods benefit from better LMs and more (cipher) training data.", "labels": [], "entities": []}, {"text": "shows sample outputs from Bayesian decipherment.", "labels": [], "entities": []}, {"text": "Data: We work with the Spanish/English language pair and use the following corpora in our MT experiments: \u2022 Time corpus: We mined English newswire text on the Web and collected 295k temporal expressions such as \"LAST YEAR\", \"THE FOURTH QUARTER\", \"IN JAN 1968\", etc.", "labels": [], "entities": [{"text": "MT", "start_pos": 90, "end_pos": 92, "type": "TASK", "confidence": 0.9566212892532349}, {"text": "THE FOURTH QUARTER", "start_pos": 225, "end_pos": 243, "type": "METRIC", "confidence": 0.7360027233759562}, {"text": "IN JAN", "start_pos": 247, "end_pos": 253, "type": "METRIC", "confidence": 0.6490003168582916}]}, {"text": "We first process the data and normalize numbers and names of months/weekdays-for example, \"1968\" is replaced with \"NNNN\", \"JANUARY\" with \"\", and soon.", "labels": [], "entities": []}, {"text": "We then translate the English temporal phrases into Spanish using an automatic translation software (Google Translate) followed by manual annotation to correct mistakes made by the software.", "labels": [], "entities": []}, {"text": "We create the following splits out of the resulting parallel corpus:  TEST (Spanish): 13181 sentences (1127 unique), 39k word tokens, 562 word types.", "labels": [], "entities": [{"text": "TEST", "start_pos": 70, "end_pos": 74, "type": "METRIC", "confidence": 0.8497816920280457}]}, {"text": "Both Spanish/English sides of TRAIN are used for parallel MT training, whereas decipherment uses only monolingual English data for training LMs.", "labels": [], "entities": [{"text": "TRAIN", "start_pos": 30, "end_pos": 35, "type": "METRIC", "confidence": 0.7284335494041443}, {"text": "MT training", "start_pos": 58, "end_pos": 69, "type": "TASK", "confidence": 0.9167772829532623}]}, {"text": "MT Systems: We build and compare different MT systems under two training scenarios: 1.", "labels": [], "entities": [{"text": "MT", "start_pos": 0, "end_pos": 2, "type": "TASK", "confidence": 0.8908894658088684}, {"text": "MT", "start_pos": 43, "end_pos": 45, "type": "TASK", "confidence": 0.967535674571991}]}, {"text": "Parallel training using: (a) MOSES, a phrase translation system ( widely used in MT literature, and (b) a simpler version of IBM Model 3 (without distortion parameters) which can be trained tractably using the strategy of Knight and Al-Onaizan (1998).", "labels": [], "entities": [{"text": "phrase translation", "start_pos": 38, "end_pos": 56, "type": "TASK", "confidence": 0.8031283020973206}, {"text": "MT", "start_pos": 81, "end_pos": 83, "type": "TASK", "confidence": 0.9615944623947144}]}, {"text": "2. Decipherment without parallel data using: (a) EM method (from Section 3.1), and (b) Bayesian method (from Section 3.2).", "labels": [], "entities": []}, {"text": "Evaluation: All the MT systems are run on the Spanish test data and the quality of the resulting English translations are evaluated using two different measures-(1) Normalized edit distance score), and (2) BLEU (Papineni et When computing edit distance, we account for substitutions, insertions, deletions as well as local-swap edit operations required to convert a given English string into the (gold) reference translation.", "labels": [], "entities": [{"text": "MT", "start_pos": 20, "end_pos": 22, "type": "TASK", "confidence": 0.9777023792266846}, {"text": "Spanish test data", "start_pos": 46, "end_pos": 63, "type": "DATASET", "confidence": 0.7828739881515503}, {"text": "Normalized edit distance score", "start_pos": 165, "end_pos": 195, "type": "METRIC", "confidence": 0.7803808003664017}, {"text": "BLEU", "start_pos": 206, "end_pos": 210, "type": "METRIC", "confidence": 0.9995101690292358}]}, {"text": "al., 2002), a standard MT evaluation measure.", "labels": [], "entities": [{"text": "MT evaluation", "start_pos": 23, "end_pos": 36, "type": "TASK", "confidence": 0.8851771950721741}]}, {"text": "Results: compares the results of various MT systems (using parallel versus decipherment training) on the two test corpora in terms of edit distance scores (a lower score indicates closer match to the gold translation).", "labels": [], "entities": [{"text": "MT", "start_pos": 41, "end_pos": 43, "type": "TASK", "confidence": 0.9842191338539124}, {"text": "edit distance scores", "start_pos": 134, "end_pos": 154, "type": "METRIC", "confidence": 0.8941719929377238}]}, {"text": "The figure also shows the corresponding BLEU scores in parentheses for comparison (higher scores indicate better MT output).", "labels": [], "entities": [{"text": "BLEU", "start_pos": 40, "end_pos": 44, "type": "METRIC", "confidence": 0.9995297193527222}, {"text": "MT output", "start_pos": 113, "end_pos": 122, "type": "METRIC", "confidence": 0.7220762073993683}]}, {"text": "We observe that even without parallel training data, our decipherment strategies achieve MT accuracies comparable to parallel-trained systems.", "labels": [], "entities": [{"text": "MT", "start_pos": 89, "end_pos": 91, "type": "TASK", "confidence": 0.9716141819953918}]}, {"text": "On the Time corpus, the best decipherment (Method 2a in the achieves an edit distance score of 28.7 (versus 4.7 for MOSES).", "labels": [], "entities": [{"text": "Time corpus", "start_pos": 7, "end_pos": 18, "type": "DATASET", "confidence": 0.9627006947994232}, {"text": "edit distance score", "start_pos": 72, "end_pos": 91, "type": "METRIC", "confidence": 0.9514274199803671}]}, {"text": "Better LMs yield better MT results for both parallel and decipherment training-for example, using a segment-based English LM instead of a 2-gram LM yields a 24% reduction in edit distance and a 9% improvement in BLEU score for EM decipherment.", "labels": [], "entities": [{"text": "MT", "start_pos": 24, "end_pos": 26, "type": "TASK", "confidence": 0.987250566482544}, {"text": "BLEU score", "start_pos": 212, "end_pos": 222, "type": "METRIC", "confidence": 0.9843964874744415}, {"text": "EM decipherment", "start_pos": 227, "end_pos": 242, "type": "TASK", "confidence": 0.8520530760288239}]}, {"text": "We also investigate how the performance of different MT systems vary with the size of the training data.", "labels": [], "entities": [{"text": "MT", "start_pos": 53, "end_pos": 55, "type": "TASK", "confidence": 0.9877772927284241}]}, {"text": "plots the BLEU scores versus training sizes for different MT systems on the Time corpus.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9993601441383362}, {"text": "MT", "start_pos": 58, "end_pos": 60, "type": "TASK", "confidence": 0.9707748293876648}, {"text": "Time corpus", "start_pos": 76, "end_pos": 87, "type": "DATASET", "confidence": 0.9842184484004974}]}, {"text": "Clearly, using more training data yields better performance for all systems.", "labels": [], "entities": []}, {"text": "However, higher improvements are observed when using parallel data in comparison to decipherment training which only uses monolingual data.", "labels": [], "entities": []}, {"text": "We also notice that the scores do not improve much when going beyond 10,000 train- ing instances for this domain.", "labels": [], "entities": []}, {"text": "It is interesting to quantify the value of parallel versus non-parallel data for any given MT task.", "labels": [], "entities": [{"text": "MT task", "start_pos": 91, "end_pos": 98, "type": "TASK", "confidence": 0.92311230301857}]}, {"text": "In other words, \"how much non-parallel data is worth how much parallel data in order to achieve the same MT accuracy?\" provides a reasonable answer to this question for the Spanish/English MT task described here.", "labels": [], "entities": [{"text": "MT", "start_pos": 105, "end_pos": 107, "type": "TASK", "confidence": 0.963811457157135}, {"text": "accuracy", "start_pos": 108, "end_pos": 116, "type": "METRIC", "confidence": 0.863345742225647}, {"text": "Spanish/English MT task", "start_pos": 173, "end_pos": 196, "type": "TASK", "confidence": 0.5113491296768189}]}, {"text": "We see that deciphering with 10k monolingual Spanish sentences yields the same performance as training with around 200-500 parallel English/Spanish sentence pairs.", "labels": [], "entities": []}, {"text": "This is the first attempt at such a quantitative comparison for MT and our results are encouraging.", "labels": [], "entities": [{"text": "MT", "start_pos": 64, "end_pos": 66, "type": "TASK", "confidence": 0.9869131445884705}]}, {"text": "We envision that further developments in unsupervised methods will help reduce this gap further.", "labels": [], "entities": []}], "tableCaptions": []}