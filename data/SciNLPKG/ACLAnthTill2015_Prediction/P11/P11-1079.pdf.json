{"title": [{"text": "Bootstrapping Coreference Resolution Using Word Associations", "labels": [], "entities": [{"text": "Coreference Resolution", "start_pos": 14, "end_pos": 36, "type": "TASK", "confidence": 0.8153169751167297}]}], "abstractContent": [{"text": "In this paper, we present an unsupervised framework that bootstraps a complete corefer-ence resolution (CoRe) system from word associations mined from a large unlabeled corpus.", "labels": [], "entities": []}, {"text": "We show that word associations are useful for CoRe-e.g., the strong association between Obama and President is an indicator of likely coreference.", "labels": [], "entities": []}, {"text": "Association information has so far not been used in CoRe because it is sparse and difficult to learn from small labeled corpora.", "labels": [], "entities": []}, {"text": "Since unlabeled text is readily available , our unsupervised approach addresses the sparseness problem.", "labels": [], "entities": []}, {"text": "Ina self-training framework , we train a decision tree on a corpus that is automatically labeled using word associations.", "labels": [], "entities": []}, {"text": "We show that this unsupervised system has better CoRe performance than other learning approaches that do not use manually labeled data.", "labels": [], "entities": []}], "introductionContent": [{"text": "Coreference resolution (CoRe) is the process of finding markables (noun phrases) referring to the same real world entity or concept.", "labels": [], "entities": [{"text": "Coreference resolution (CoRe)", "start_pos": 0, "end_pos": 29, "type": "TASK", "confidence": 0.8709203243255615}]}, {"text": "Until recently, most approaches tried to solve the problem by binary classification, where the probability of a pair of markables being coreferent is estimated from labeled data.", "labels": [], "entities": [{"text": "binary classification", "start_pos": 62, "end_pos": 83, "type": "TASK", "confidence": 0.7142562568187714}]}, {"text": "Alternatively, a model that determines whether a markable is coreferent with a preceding cluster can be used.", "labels": [], "entities": []}, {"text": "For both pair-based and cluster-based models, a well established feature model plays an important role.", "labels": [], "entities": []}, {"text": "Typical systems use a rich feature space based on lexical, syntactic and semantic knowledge.", "labels": [], "entities": []}, {"text": "Most commonly used features are described by.", "labels": [], "entities": []}, {"text": "Most existing systems are supervised systems, trained on human-labeled benchmark data sets for English.", "labels": [], "entities": []}, {"text": "These systems use linguistic features based on number, gender, person etc.", "labels": [], "entities": []}, {"text": "It is a challenge to adapt these systems to new domains, genres and languages because a significant human labeling effort is usually necessary to get good performance.", "labels": [], "entities": []}, {"text": "To address this challenge, we pursue an unsupervised self-training approach.", "labels": [], "entities": []}, {"text": "We train a classifier on a corpus that is automatically labeled using association information.", "labels": [], "entities": []}, {"text": "Self-training approaches usually include the use of some manually labeled data.", "labels": [], "entities": []}, {"text": "In contrast, our self-trained system is not trained on any manually labeled data and is therefore a completely unsupervised system.", "labels": [], "entities": []}, {"text": "Although training on automatically labeled data can be viewed as a form of supervision, we reserve the term supervised system for systems that are trained on manually labeled data.", "labels": [], "entities": []}, {"text": "The key novelty of our approach is that we bootstrap a competitive CoRe system from association information that is mined from an unlabeled corpus in a completely unsupervised fashion.", "labels": [], "entities": []}, {"text": "While this method is shallow, it provides valuable information for CoRe because it considers the actual identity of the words in question.", "labels": [], "entities": []}, {"text": "Consider the pair of markables (Obama, President).", "labels": [], "entities": []}, {"text": "It is a likely coreference pair, but this information is not accessible to standard CoRe systems because they only use string-based features (often called lexical features), named entity features and semantic word class features (e.g., from WordNet) that do not distinguish, 783 say, Obama from Hawking.", "labels": [], "entities": []}, {"text": "In our approach, word association information is used for clustering markables in unsupervised learning.", "labels": [], "entities": []}, {"text": "Association information is calculated as association scores between heads of markables as described below.", "labels": [], "entities": [{"text": "Association", "start_pos": 0, "end_pos": 11, "type": "METRIC", "confidence": 0.8907573819160461}]}, {"text": "We view association information as an example of a shallow feature space which contrasts with the rich feature space that is generally used in CoRe.", "labels": [], "entities": []}, {"text": "Our experiments are conducted using the MCORE system (\"Modular COreference REsolution\").", "labels": [], "entities": []}, {"text": "1 MCORE can operate in three different settings: unsupervised (subsystem A-INF), supervised), and self-trained (subsystem UNSEL).", "labels": [], "entities": [{"text": "UNSEL", "start_pos": 122, "end_pos": 127, "type": "DATASET", "confidence": 0.8181139230728149}]}, {"text": "The unsupervised subsystem A-INF (\"Association INFormation\") uses the association scores between heads as the distance measure when clustering markables.", "labels": [], "entities": [{"text": "A-INF", "start_pos": 27, "end_pos": 32, "type": "METRIC", "confidence": 0.9580788612365723}]}, {"text": "SUCRE (\"SUpervised Coreference REsolution\") is trained on a labeled corpus (manually or automatically labeled) similar to standard CoRe systems.", "labels": [], "entities": []}, {"text": "Finally, the unsupervised self-trained subsystem UNSEL (\"UNsupervised SELf-trained\") uses the unsupervised subsystem A-INF to automatically label an unlabeled corpus that is then used as a training set for SUCRE.", "labels": [], "entities": [{"text": "SUCRE", "start_pos": 206, "end_pos": 211, "type": "TASK", "confidence": 0.9550256133079529}]}, {"text": "Our main contributions in this paper are as follows: 1.", "labels": [], "entities": []}, {"text": "We demonstrate that word association information can be used to develop an unsupervised model for shallow coreference resolution (subsystem A-INF).", "labels": [], "entities": [{"text": "shallow coreference resolution", "start_pos": 98, "end_pos": 128, "type": "TASK", "confidence": 0.7044532299041748}]}, {"text": "2. We introduce an unsupervised self-trained method (UNSEL) that takes a two-learner twofeature-space approach.", "labels": [], "entities": [{"text": "UNSEL", "start_pos": 53, "end_pos": 58, "type": "DATASET", "confidence": 0.7422544360160828}]}, {"text": "The two learners are A-INF and SUCRE.", "labels": [], "entities": [{"text": "A-INF", "start_pos": 21, "end_pos": 26, "type": "METRIC", "confidence": 0.995187520980835}, {"text": "SUCRE", "start_pos": 31, "end_pos": 36, "type": "METRIC", "confidence": 0.8023197054862976}]}, {"text": "The feature spaces are the shallow and rich feature spaces.", "labels": [], "entities": []}, {"text": "3. We show that the performance of UNSEL is better than the performance of other unsupervised systems when it is self-trained on the automatically labeled corpus and uses the leveraging effect of a rich feature space.", "labels": [], "entities": [{"text": "UNSEL", "start_pos": 35, "end_pos": 40, "type": "DATASET", "confidence": 0.7220854759216309}]}, {"text": "4. MCORE is a flexible and modular framework that is able to learn from data with different quality and domain.", "labels": [], "entities": [{"text": "MCORE", "start_pos": 3, "end_pos": 8, "type": "DATASET", "confidence": 0.8211818933486938}]}, {"text": "Not only is it able to deal with shallow information spaces (A-INF), but it can also deliver competitive results for rich feature spaces (SUCRE and UNSEL).", "labels": [], "entities": [{"text": "A-INF", "start_pos": 61, "end_pos": 66, "type": "METRIC", "confidence": 0.911321222782135}, {"text": "UNSEL", "start_pos": 148, "end_pos": 153, "type": "DATASET", "confidence": 0.5803634524345398}]}, {"text": "This paper is organized as follows.", "labels": [], "entities": []}, {"text": "Related work is discussed in Section 2.", "labels": [], "entities": []}, {"text": "In Section 3, we present our system architecture.", "labels": [], "entities": []}, {"text": "Section 4 describes the experiments and Section 5 presents and discusses our results.", "labels": [], "entities": []}, {"text": "The final section presents our conclusions.", "labels": [], "entities": []}], "datasetContent": [{"text": "We report recall, precision, and F 1 for MUC (, B 3 (Bagga and Baldwin, 1998), and CEAF ().", "labels": [], "entities": [{"text": "recall", "start_pos": 10, "end_pos": 16, "type": "METRIC", "confidence": 0.9996117949485779}, {"text": "precision", "start_pos": 18, "end_pos": 27, "type": "METRIC", "confidence": 0.9996974468231201}, {"text": "F 1", "start_pos": 33, "end_pos": 36, "type": "METRIC", "confidence": 0.9893112182617188}, {"text": "MUC", "start_pos": 41, "end_pos": 44, "type": "TASK", "confidence": 0.4847419559955597}, {"text": "CEAF", "start_pos": 83, "end_pos": 87, "type": "DATASET", "confidence": 0.9159550666809082}]}, {"text": "We selected these three metrics because a single metric is often misleading and because we need to use metrics that were used in previous unsupervised work.", "labels": [], "entities": []}, {"text": "It is well known that MUC by itself is insufficient because it gives misleadingly high scores to the \"single-chain\" system that puts all markables into one chain ().", "labels": [], "entities": [{"text": "MUC", "start_pos": 22, "end_pos": 25, "type": "DATASET", "confidence": 0.47218722105026245}]}, {"text": "However, B 3 and CEAF have a different bias: they give high scores to the \"all-singletons\" system that puts each markable in a separate chain.", "labels": [], "entities": [{"text": "B 3", "start_pos": 9, "end_pos": 12, "type": "METRIC", "confidence": 0.8142825067043304}, {"text": "CEAF", "start_pos": 17, "end_pos": 21, "type": "DATASET", "confidence": 0.7050325274467468}]}, {"text": "On OntoNotes test, we get B 3 = 83.2 and CEAF = 71.2 for all-singletons, which incorrectly suggests that performance is good; but MUC F 1 is 0 in this case, demonstrating that all-singletons performs poorly.", "labels": [], "entities": [{"text": "OntoNotes test", "start_pos": 3, "end_pos": 17, "type": "DATASET", "confidence": 0.7796836793422699}, {"text": "B 3", "start_pos": 26, "end_pos": 29, "type": "METRIC", "confidence": 0.9808278977870941}, {"text": "CEAF", "start_pos": 41, "end_pos": 45, "type": "METRIC", "confidence": 0.9951760768890381}, {"text": "MUC F 1", "start_pos": 130, "end_pos": 137, "type": "METRIC", "confidence": 0.8796978990236918}]}, {"text": "With the goal of performing a complete evaluation, one that punishes all-singletons as well as single-chain, we use one of the following two combinations: (i) MUC and B 3 or (ii) MUC and CEAF.", "labels": [], "entities": [{"text": "CEAF", "start_pos": 187, "end_pos": 191, "type": "DATASET", "confidence": 0.6751267910003662}]}, {"text": "showed that B 3 and CEAF are highly correlated (Pearson's r = 0.91).", "labels": [], "entities": [{"text": "B 3", "start_pos": 12, "end_pos": 15, "type": "METRIC", "confidence": 0.9809169471263885}, {"text": "CEAF", "start_pos": 20, "end_pos": 24, "type": "METRIC", "confidence": 0.9443580508232117}, {"text": "Pearson's r", "start_pos": 48, "end_pos": 59, "type": "METRIC", "confidence": 0.8889673352241516}]}, {"text": "Therefore, either combination (i) or combination (ii) fairly characterizes CoRe performance.) on ACE2003.", "labels": [], "entities": [{"text": "ACE2003", "start_pos": 97, "end_pos": 104, "type": "DATASET", "confidence": 0.9713209271430969}]}, {"text": "To our knowledge, these three papers are the best and most recent evaluation results for unsupervised learning and they all report results on ACE-2 and ACE-2003.", "labels": [], "entities": [{"text": "ACE-2", "start_pos": 142, "end_pos": 147, "type": "DATASET", "confidence": 0.9580917954444885}, {"text": "ACE-2003", "start_pos": 152, "end_pos": 160, "type": "DATASET", "confidence": 0.9308489561080933}]}, {"text": "Results on SUCRE will be discussed later in this section.", "labels": [], "entities": [{"text": "SUCRE", "start_pos": 11, "end_pos": 16, "type": "TASK", "confidence": 0.8025386333465576}]}, {"text": "A-INF scores are below some of the earlier unsupervised work reported in the literature (lines 2, 6, 10) although they are close to competitive on two of the datasets (lines 15 and 20: MUC scores are equal or better, CEAF scores are worse).", "labels": [], "entities": [{"text": "A-INF", "start_pos": 0, "end_pos": 5, "type": "METRIC", "confidence": 0.9856869578361511}, {"text": "CEAF", "start_pos": 217, "end_pos": 221, "type": "METRIC", "confidence": 0.9346145987510681}]}, {"text": "Given the simplicity of A-INF, which uses nothing but asso- We report numbers for the better performing Pronoun-only Salience variant of H&K proposed by ciations mined from a large unannotated corpus, its performance is surprisingly good.", "labels": [], "entities": [{"text": "A-INF", "start_pos": 24, "end_pos": 29, "type": "METRIC", "confidence": 0.865849494934082}]}], "tableCaptions": [{"text": " Table 1: Scores for MCORE (A-INF, SUCRE and UNSEL) and three comparable systems on ACE-2 and ACE2003.", "labels": [], "entities": [{"text": "MCORE", "start_pos": 21, "end_pos": 26, "type": "DATASET", "confidence": 0.7240716218948364}, {"text": "A-INF", "start_pos": 28, "end_pos": 33, "type": "METRIC", "confidence": 0.8587160110473633}, {"text": "UNSEL", "start_pos": 45, "end_pos": 50, "type": "METRIC", "confidence": 0.752440869808197}, {"text": "ACE-2", "start_pos": 84, "end_pos": 89, "type": "DATASET", "confidence": 0.9577592611312866}, {"text": "ACE2003", "start_pos": 94, "end_pos": 101, "type": "DATASET", "confidence": 0.7541390657424927}]}, {"text": " Table 2: F 1 scores for MCORE (SUCRE and UNSEL)  and the best comparable systems in SemEval-2010. MD:  Markable Detection F 1 (Recasens et al., 2010).", "labels": [], "entities": [{"text": "F 1 scores", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.9795205990473429}, {"text": "MCORE", "start_pos": 25, "end_pos": 30, "type": "DATASET", "confidence": 0.7429673671722412}, {"text": "UNSEL", "start_pos": 42, "end_pos": 47, "type": "DATASET", "confidence": 0.86476731300354}, {"text": "Markable Detection F 1", "start_pos": 104, "end_pos": 126, "type": "METRIC", "confidence": 0.7382384017109871}]}]}