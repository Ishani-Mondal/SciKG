{"title": [{"text": "Phrase-Based Translation Model for Question Retrieval in Community Question Answer Archives", "labels": [], "entities": [{"text": "Phrase-Based Translation", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.8573678135871887}, {"text": "Question Retrieval in Community Question Answer", "start_pos": 35, "end_pos": 82, "type": "TASK", "confidence": 0.7192174394925436}]}], "abstractContent": [{"text": "Community-based question answer (Q&A) has become an important issue due to the popularity of Q&A archives on the web.", "labels": [], "entities": [{"text": "Community-based question answer (Q&A)", "start_pos": 0, "end_pos": 37, "type": "TASK", "confidence": 0.8043612688779831}]}, {"text": "This paper is concerned with the problem of question retrieval.", "labels": [], "entities": [{"text": "question retrieval", "start_pos": 44, "end_pos": 62, "type": "TASK", "confidence": 0.816416323184967}]}, {"text": "Question retrieval in Q&A archives aims to find historical questions that are semantically equivalent or relevant to the queried questions.", "labels": [], "entities": [{"text": "Question retrieval in Q&A archives", "start_pos": 0, "end_pos": 34, "type": "TASK", "confidence": 0.7309148950236184}]}, {"text": "In this paper, we propose a novel phrase-based translation model for question retrieval.", "labels": [], "entities": [{"text": "phrase-based translation", "start_pos": 34, "end_pos": 58, "type": "TASK", "confidence": 0.6515882015228271}, {"text": "question retrieval", "start_pos": 69, "end_pos": 87, "type": "TASK", "confidence": 0.8316998481750488}]}, {"text": "Compared to the traditional word-based translation models, the phrase-based translation model is more effective because it captures contextual information in modeling the translation of phrases as a whole, rather than translating single words in isolation.", "labels": [], "entities": [{"text": "word-based translation", "start_pos": 28, "end_pos": 50, "type": "TASK", "confidence": 0.6520683914422989}, {"text": "phrase-based translation", "start_pos": 63, "end_pos": 87, "type": "TASK", "confidence": 0.7279356122016907}]}, {"text": "Experiments conducted on real Q&A data demonstrate that our proposed phrase-based translation model significantly outper-forms the state-of-the-art word-based translation model.", "labels": [], "entities": [{"text": "phrase-based translation", "start_pos": 69, "end_pos": 93, "type": "TASK", "confidence": 0.727487176656723}, {"text": "word-based translation", "start_pos": 148, "end_pos": 170, "type": "TASK", "confidence": 0.6780036389827728}]}], "introductionContent": [{"text": "Over the past few years, large scale question and answer (Q&A) archives have become an important information resource on the Web.", "labels": [], "entities": [{"text": "question and answer (Q&A) archives", "start_pos": 37, "end_pos": 71, "type": "TASK", "confidence": 0.8135520484712389}]}, {"text": "These include the traditional Frequently Asked Questions (FAQ) archives and the emerging community-based Q&A services, such as Yahoo!", "labels": [], "entities": []}, {"text": "Answers 1 , Live QnA 2 , and Baidu Zhidao 3 . Community-based Q&A services can directly return answers to the queried questions instead of a list of relevant documents, thus provide an effective alternative to the traditional adhoc information retrieval.", "labels": [], "entities": []}, {"text": "To make full use of the large scale archives of question-answer pairs, it is critical to have functionality helping users to retrieve historical answers (.", "labels": [], "entities": []}, {"text": "Therefore, it is a meaningful task to retrieve the questions that are semantically equivalent or relevant to the queried questions.", "labels": [], "entities": []}, {"text": "For example in, given question Q 1 , Q 2 can be returned and their answers will then be used to answer Q 1 because the answer of Q 2 is expected to partially satisfy the queried question Q . This is what we called question retrieval in this paper.", "labels": [], "entities": [{"text": "question retrieval", "start_pos": 214, "end_pos": 232, "type": "TASK", "confidence": 0.7963690459728241}]}, {"text": "The major challenge for Q&A retrieval, as for Query: Q1: How to get rid of stuffy nose?", "labels": [], "entities": [{"text": "Q&A retrieval", "start_pos": 24, "end_pos": 37, "type": "TASK", "confidence": 0.820687398314476}]}, {"text": "Expected: Q2: What is the best way to prevent a cold?", "labels": [], "entities": []}, {"text": "Not Expected: Q3: How do I air out my stuffy room?", "labels": [], "entities": []}, {"text": "Q4: How do you make a nosebleed stop quicker?: An example on question retrieval most information retrieval models, such as vector space model (VSM) (), Okapi model (, language model (LM), is the lexical gap (or lexical chasm) between the queried questions and the historical questions in the archives ().", "labels": [], "entities": [{"text": "question retrieval", "start_pos": 61, "end_pos": 79, "type": "TASK", "confidence": 0.731346607208252}]}, {"text": "For example in, Q 1 and Q 2 are two semantically similar questions, but they have very few words in common.", "labels": [], "entities": []}, {"text": "This prob-lem is more serious for Q&A retrieval, since the question-answer pairs are usually short and there is little chance of finding the same content expressed using different wording (.", "labels": [], "entities": [{"text": "Q&A retrieval", "start_pos": 34, "end_pos": 47, "type": "TASK", "confidence": 0.79005566239357}]}, {"text": "To solve the lexical gap problem, most researchers regarded the question retrieval task as a statistical machine translation problem by using IBM model 1 () to learn the word-to-word translation probabilities.", "labels": [], "entities": [{"text": "question retrieval task", "start_pos": 64, "end_pos": 87, "type": "TASK", "confidence": 0.8459639350573221}, {"text": "statistical machine translation", "start_pos": 93, "end_pos": 124, "type": "TASK", "confidence": 0.6372383832931519}]}, {"text": "Experiments consistently reported that the word-based translation models could yield better performance than the traditional methods (e.g., VSM. Okapi and LM).", "labels": [], "entities": [{"text": "word-based translation", "start_pos": 43, "end_pos": 65, "type": "TASK", "confidence": 0.6641667783260345}, {"text": "VSM. Okapi", "start_pos": 140, "end_pos": 150, "type": "DATASET", "confidence": 0.8529852330684662}]}, {"text": "However, all these existing approaches are considered to be context independent in that they do not take into account any contextual information in modeling word translation probabilities.", "labels": [], "entities": [{"text": "word translation probabilities", "start_pos": 157, "end_pos": 187, "type": "TASK", "confidence": 0.8095703125}]}, {"text": "For example in, although neither of the individual word pair (e.g., \"stuffy\"/\"cold\" and \"nose\"/\"cold\") might have a high translation probability, the sequence of words \"stuffy nose\" can be easily translated from a single word \"cold\" in Q 2 with a relative high translation probability.", "labels": [], "entities": []}, {"text": "In this paper, we argue that it is beneficial to capture contextual information for question retrieval.", "labels": [], "entities": [{"text": "question retrieval", "start_pos": 84, "end_pos": 102, "type": "TASK", "confidence": 0.8188295960426331}]}, {"text": "To this end, inspired by the phrase-based statistical machine translation (SMT) systems (), we propose a phrasebased translation model (P-Trans) for question retrieval, and we assume that question retrieval should be performed at the phrase level.", "labels": [], "entities": [{"text": "phrase-based statistical machine translation (SMT)", "start_pos": 29, "end_pos": 79, "type": "TASK", "confidence": 0.728579682963235}, {"text": "phrasebased translation", "start_pos": 105, "end_pos": 128, "type": "TASK", "confidence": 0.6847849190235138}, {"text": "question retrieval", "start_pos": 149, "end_pos": 167, "type": "TASK", "confidence": 0.7585784196853638}, {"text": "question retrieval", "start_pos": 188, "end_pos": 206, "type": "TASK", "confidence": 0.7058410197496414}]}, {"text": "This model learns the probability of translating one sequence of words (e.g., phrase) into another sequence of words, e.g., translating a phrase in a historical question into another phrase in a queried question.", "labels": [], "entities": []}, {"text": "Compared to the traditional word-based translation models that account for translating single words in isolation, the phrase-based translation model is potentially more effective because it captures some contextual information in modeling the translation of phrases as a whole.", "labels": [], "entities": [{"text": "word-based translation", "start_pos": 28, "end_pos": 50, "type": "TASK", "confidence": 0.6647577881813049}, {"text": "phrase-based translation", "start_pos": 118, "end_pos": 142, "type": "TASK", "confidence": 0.6858864426612854}]}, {"text": "More precise translation can be determined for phrases than for words.", "labels": [], "entities": []}, {"text": "It is thus reasonable to expect that using such phrase translation probabilities as ranking features is likely to improve the question retrieval performance, as we will show in our experiments.", "labels": [], "entities": [{"text": "phrase translation", "start_pos": 48, "end_pos": 66, "type": "TASK", "confidence": 0.7335560619831085}, {"text": "question retrieval", "start_pos": 126, "end_pos": 144, "type": "TASK", "confidence": 0.7377792596817017}]}, {"text": "Unlike the general natural language translation, the parallel sentences between questions and answers in community-based Q&A have very different lengths, leaving many words in answers unaligned to any word in queried questions.), we restrict our attention to those phrase translations consistent with a good wordlevel alignment.", "labels": [], "entities": []}, {"text": "Specifically, we make the following contributions: \u2022 we formulate the question retrieval task as a phrase-based translation problem by modeling the contextual information (in Section 3.1).", "labels": [], "entities": [{"text": "question retrieval task", "start_pos": 70, "end_pos": 93, "type": "TASK", "confidence": 0.8193239768346151}, {"text": "phrase-based translation", "start_pos": 99, "end_pos": 123, "type": "TASK", "confidence": 0.7114288806915283}]}, {"text": "\u2022 we linearly combine the phrase-based translation model for the question part and answer part (in Section 3.2).", "labels": [], "entities": [{"text": "phrase-based translation", "start_pos": 26, "end_pos": 50, "type": "TASK", "confidence": 0.6651302427053452}]}, {"text": "\u2022 we propose a linear ranking model framework for question retrieval in which different models are incorporated as features because the phrasebased translation model cannot be interpolated with a unigram language model (in Section 3.3).", "labels": [], "entities": [{"text": "question retrieval", "start_pos": 50, "end_pos": 68, "type": "TASK", "confidence": 0.8264696896076202}]}, {"text": "\u2022 finally, we conduct the experiments on community-based Q&A data for question retrieval.", "labels": [], "entities": [{"text": "question retrieval", "start_pos": 70, "end_pos": 88, "type": "TASK", "confidence": 0.8309065699577332}]}, {"text": "The results show that our proposed approach significantly outperforms the baseline methods (in Section 4).", "labels": [], "entities": []}, {"text": "The remainder of this paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 introduces the existing state-of-theart methods.", "labels": [], "entities": []}, {"text": "Section 3 describes our phrase-based translation model for question retrieval.", "labels": [], "entities": [{"text": "phrase-based translation", "start_pos": 24, "end_pos": 48, "type": "TASK", "confidence": 0.6725474745035172}, {"text": "question retrieval", "start_pos": 59, "end_pos": 77, "type": "TASK", "confidence": 0.8270204663276672}]}, {"text": "Section 4 presents the experimental results.", "labels": [], "entities": []}, {"text": "In Section 5, we conclude with ideas for future research.", "labels": [], "entities": []}], "datasetContent": [{"text": "We collect the questions from Yahoo!", "labels": [], "entities": []}, {"text": "Answers and use the getByCategory function provided in Yahoo!", "labels": [], "entities": []}, {"text": "Answers API 5 to obtain Q&A threads from the Yahoo!", "labels": [], "entities": []}, {"text": "More specifically, we utilize the resolved questions under the top-level category at Yahoo!", "labels": [], "entities": []}, {"text": "Answers, namely \"Computers & Internet\".", "labels": [], "entities": []}, {"text": "The resulting question repository that we use for question retrieval contains 518,492 questions.", "labels": [], "entities": [{"text": "question retrieval", "start_pos": 50, "end_pos": 68, "type": "TASK", "confidence": 0.7561147809028625}]}, {"text": "To learn the translation probabilities, we use about one million question-answer pairs from another data set.", "labels": [], "entities": []}, {"text": "In order to create the test set, we randomly select 300 questions for this category, denoted as \"CI TST\".", "labels": [], "entities": []}, {"text": "To obtain the ground-truth of question retrieval, we employ the Vector Space Model (VSM) ( to retrieve the top 20 results and obtain manual judgements.", "labels": [], "entities": [{"text": "question retrieval", "start_pos": 30, "end_pos": 48, "type": "TASK", "confidence": 0.7946611940860748}]}, {"text": "The top 20 results don't include the queried question itself.", "labels": [], "entities": []}, {"text": "Given a returned result by VSM, an annotator is asked to label it with \"relevant\" or \"irrelevant\".", "labels": [], "entities": [{"text": "VSM", "start_pos": 27, "end_pos": 30, "type": "DATASET", "confidence": 0.8406133055686951}]}, {"text": "If a returned result is considered semantically equivalent to the queried question, the annotator will label it as \"relevant\"; otherwise, the annotator will label it as \"irrelevant\".", "labels": [], "entities": []}, {"text": "Two annotators are involved in the annotation process.", "labels": [], "entities": []}, {"text": "If a conflict happens, a third person will make judgement for the final result.", "labels": [], "entities": []}, {"text": "In the process of manually judging questions, the annotators are presented only the questions.", "labels": [], "entities": []}, {"text": "We evaluate the performance of our approach using Mean Average Precision (MAP).", "labels": [], "entities": [{"text": "Mean Average Precision (MAP)", "start_pos": 50, "end_pos": 78, "type": "METRIC", "confidence": 0.9690710405508677}]}, {"text": "We perform a significant test, i.e., a t-test with a default significant level of 0.05.", "labels": [], "entities": []}, {"text": "Following the literature, we set the parameters \u03bb = 0.) in equations (1), (3) and (5), and \u03b1 = 0.8 () in equation (6).", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 3: Statistics on the Test Data", "labels": [], "entities": [{"text": "Test Data", "start_pos": 28, "end_pos": 37, "type": "DATASET", "confidence": 0.8316399157047272}]}, {"text": " Table 4: Comparison with different methods for question  retrieval.", "labels": [], "entities": [{"text": "question  retrieval", "start_pos": 48, "end_pos": 67, "type": "TASK", "confidence": 0.8204306662082672}]}, {"text": " Table 5: The impact of the phrase length on retrieval per- formance.", "labels": [], "entities": []}, {"text": " Table 6: Effectiveness of parallel corpus preprocessing.", "labels": [], "entities": []}, {"text": " Table 7: The impact of pooling strategy for question re- trieval.", "labels": [], "entities": [{"text": "question re- trieval", "start_pos": 45, "end_pos": 65, "type": "TASK", "confidence": 0.8810355067253113}]}]}