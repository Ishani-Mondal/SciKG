{"title": [{"text": "Model-Based Aligner Combination Using Dual Decomposition", "labels": [], "entities": []}], "abstractContent": [{"text": "Unsupervised word alignment is most often modeled as a Markov process that generates a sentence f conditioned on its translation e.", "labels": [], "entities": [{"text": "Unsupervised word alignment", "start_pos": 0, "end_pos": 27, "type": "TASK", "confidence": 0.6127402087052664}]}, {"text": "A similar model generating e from f will make different alignment predictions.", "labels": [], "entities": []}, {"text": "Statistical machine translation systems combine the predictions of two directional models, typically using heuristic combination procedures like grow-diag-final.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 12, "end_pos": 31, "type": "TASK", "confidence": 0.7486610114574432}]}, {"text": "This paper presents a graph-ical model that embeds two directional align-ers into a single model.", "labels": [], "entities": []}, {"text": "Inference can be performed via dual decomposition, which reuses the efficient inference algorithms of the directional models.", "labels": [], "entities": []}, {"text": "Our bidirectional model enforces a one-to-one phrase constraint while accounting for the uncertainty in the underlying directional models.", "labels": [], "entities": []}, {"text": "The resulting alignments improve upon baseline combination heuristics in word-level and phrase-level evaluations.", "labels": [], "entities": []}], "introductionContent": [{"text": "Word alignment is the task of identifying corresponding words in sentence pairs.", "labels": [], "entities": [{"text": "Word alignment", "start_pos": 0, "end_pos": 14, "type": "TASK", "confidence": 0.7062029093503952}]}, {"text": "The standard approach to word alignment employs directional Markov models that align the words of a sentence f to those of its translation e, such as IBM Model 4 ( or the HMM-based alignment model (.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 25, "end_pos": 39, "type": "TASK", "confidence": 0.7998503744602203}]}, {"text": "Machine translation systems typically combine the predictions of two directional models, one which aligns f toe and the other e to f ().", "labels": [], "entities": [{"text": "Machine translation", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.7531327605247498}]}, {"text": "Combination can reduce errors and relax the one-to-many structural restriction of directional models.", "labels": [], "entities": []}, {"text": "Common combination methods include the union or intersection of directional alignments, as well as heuristic interpolations between the union and intersection like grow-diag-final (.", "labels": [], "entities": []}, {"text": "This paper presents a model-based alternative to aligner combination.", "labels": [], "entities": []}, {"text": "Inference in a probabilistic model resolves the conflicting predictions of two directional models, while taking into account each model's uncertainty over its output.", "labels": [], "entities": []}, {"text": "This result is achieved by embedding two directional HMM-based alignment models into a larger bidirectional graphical model.", "labels": [], "entities": [{"text": "HMM-based alignment", "start_pos": 53, "end_pos": 72, "type": "TASK", "confidence": 0.7713089883327484}]}, {"text": "The full model structure and potentials allow the two embedded directional models to disagree to some extent, but reward agreement.", "labels": [], "entities": []}, {"text": "Moreover, the bidirectional model enforces a one-to-one phrase alignment structure, similar to the output of phrase alignment models (, unsupervised inversion transduction grammar (ITG) models, and supervised ITG models (.", "labels": [], "entities": [{"text": "phrase alignment", "start_pos": 109, "end_pos": 125, "type": "TASK", "confidence": 0.707791805267334}]}, {"text": "Inference in our combined model is not tractable because of numerous edge cycles in the model graph.", "labels": [], "entities": []}, {"text": "However, we can employ dual decomposition as an approximate inference technique . In this approach, we iteratively apply the same efficient sequence algorithms for the underlying directional models, and thereby optimize a dual bound on the model objective.", "labels": [], "entities": [{"text": "dual decomposition", "start_pos": 23, "end_pos": 41, "type": "TASK", "confidence": 0.8227531015872955}]}, {"text": "In cases where our algorithm converges, we have a certificate of optimality under the full model.", "labels": [], "entities": []}, {"text": "Early stopping before convergence still yields useful outputs.", "labels": [], "entities": []}, {"text": "Our model-based approach to aligner combination yields improvements in alignment quality and phrase extraction quality in Chinese-English experiments, relative to typical heuristic combinations methods applied to the predictions of independent directional models.", "labels": [], "entities": [{"text": "aligner combination", "start_pos": 28, "end_pos": 47, "type": "TASK", "confidence": 0.8078921735286713}, {"text": "phrase extraction", "start_pos": 93, "end_pos": 110, "type": "TASK", "confidence": 0.7815898358821869}]}], "datasetContent": [{"text": "We evaluated our bidirectional model by comparing its output to the annotations of a hand-aligned corpus.", "labels": [], "entities": []}, {"text": "In this way, we can show that the bidirectional model improves alignment quality and enables the extraction of more correct phrase pairs.", "labels": [], "entities": []}, {"text": "To evaluate alignment error of the baseline directional aligners, we must apply a combination procedure such as union or intersection to A a and A b . Likewise, in order to evaluate alignment error for our combined model in cases where the inference algorithm does not converge, we must apply combination to c (a) and c . In cases where the algorithm does converge, c (a) = c (b) and so no further combination is necessary.", "labels": [], "entities": []}, {"text": "We evaluate alignments relative to hand-aligned data using two metrics.", "labels": [], "entities": []}, {"text": "First, we measure alignment error rate (AER), which compares the proposed alignment set A to the sure set Sand possible set P in the annotation, where S \u2286 P.", "labels": [], "entities": [{"text": "alignment error rate (AER)", "start_pos": 18, "end_pos": 44, "type": "METRIC", "confidence": 0.9379510879516602}]}], "tableCaptions": [{"text": " Table 2: Alignment error rate results for the bidirectional  model versus the baseline directional models. \"grow- diag\" denotes the grow-diag-final heuristic.", "labels": [], "entities": [{"text": "Alignment error rate", "start_pos": 10, "end_pos": 30, "type": "METRIC", "confidence": 0.7431901892026266}]}, {"text": " Table 3: Phrase pair extraction accuracy for phrase pairs  up to length 5. \"grow-diag\" denotes the grow-diag-final  heuristic.", "labels": [], "entities": [{"text": "Phrase pair extraction", "start_pos": 10, "end_pos": 32, "type": "TASK", "confidence": 0.8589478731155396}, {"text": "accuracy", "start_pos": 33, "end_pos": 41, "type": "METRIC", "confidence": 0.9782310128211975}]}]}