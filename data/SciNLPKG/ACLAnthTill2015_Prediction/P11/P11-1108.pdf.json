{"title": [{"text": "Simple Unsupervised Grammar Induction from Raw Text with Cascaded Finite State Models", "labels": [], "entities": []}], "abstractContent": [{"text": "We consider anew subproblem of unsuper-vised parsing from raw text, unsupervised partial parsing-the unsupervised version of text chunking.", "labels": [], "entities": []}, {"text": "We show that addressing this task directly, using probabilistic finite-state methods , produces better results than relying on the local predictions of a current best unsu-pervised parser, Seginer's (2007) CCL.", "labels": [], "entities": [{"text": "Seginer's (2007) CCL", "start_pos": 189, "end_pos": 209, "type": "DATASET", "confidence": 0.6233097066481909}]}, {"text": "These finite-state models are combined in a cascade to produce more general (full-sentence) constituent structures; doing so outperforms CCL by a wide margin in unlabeled PARSEVAL scores for English, German and Chinese.", "labels": [], "entities": []}, {"text": "Finally , we address the use of phrasal punctuation as a heuristic indicator of phrasal boundaries , both in our system and in CCL.", "labels": [], "entities": []}], "introductionContent": [{"text": "Unsupervised grammar induction has been an active area of research in computational linguistics for over twenty years (.", "labels": [], "entities": [{"text": "Unsupervised grammar induction", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.7310276627540588}]}, {"text": "Recent work) has largely built on the dependency model with valence of, and is characterized by its reliance on gold-standard part-of-speech (POS) annotations: the models are trained on and evaluated using sequences of POS tags rather than raw tokens.", "labels": [], "entities": []}, {"text": "This is also true for models which are not successors of).", "labels": [], "entities": []}, {"text": "An exception which learns from raw text and makes no use of POS tags is the common cover links parser.", "labels": [], "entities": []}, {"text": "CCL established stateof-the-art results for unsupervised constituency parsing from raw text, and it is also incremental and extremely fast for both learning and parsing.", "labels": [], "entities": [{"text": "CCL", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.9670872688293457}, {"text": "constituency parsing from raw text", "start_pos": 57, "end_pos": 91, "type": "TASK", "confidence": 0.7264634251594544}]}, {"text": "Unfortunately, CCL is a non-probabilistic algorithm based on a complex set of inter-relating heuristics and a non-standard (though interesting) representation of constituent trees.", "labels": [], "entities": []}, {"text": "This makes it hard to extend.", "labels": [], "entities": []}, {"text": "Note that although improve on Seginer's results, they do so by selecting training sets to best match the particular test sentences-CCL itself is used without modification.", "labels": [], "entities": []}, {"text": "explore an alternative strategy of unsupervised partial parsing: directly predicting low-level constituents based solely on word co-occurrence frequencies.", "labels": [], "entities": [{"text": "unsupervised partial parsing", "start_pos": 35, "end_pos": 63, "type": "TASK", "confidence": 0.6871331334114075}]}, {"text": "Essentially, this means segmenting raw text into multiword constituents.", "labels": [], "entities": []}, {"text": "In that paper, we show-somewhat surprisingly-that CCL's performance is mostly dependent on its effectiveness at identifying low-level constituents.", "labels": [], "entities": []}, {"text": "In fact, simply extracting non-hierarchical multiword constituents from CCL's output and putting a rightbranching structure over them actually works better than CCL's own higher level predictions.", "labels": [], "entities": []}, {"text": "This result suggests that improvements to low-level constituent prediction will ultimately lead to further gains in overall constituent parsing.", "labels": [], "entities": [{"text": "constituent prediction", "start_pos": 52, "end_pos": 74, "type": "TASK", "confidence": 0.7187463343143463}, {"text": "constituent parsing", "start_pos": 124, "end_pos": 143, "type": "TASK", "confidence": 0.6897260844707489}]}, {"text": "Here, we present such an improvement by using probabilistic finite-state models for phrasal segmentation from raw text.", "labels": [], "entities": [{"text": "phrasal segmentation", "start_pos": 84, "end_pos": 104, "type": "TASK", "confidence": 0.7287509739398956}]}, {"text": "The task for these models is chunking, so we evaluate performance on identification of multiword chunks of all constituent types as well as only noun phrases.", "labels": [], "entities": []}, {"text": "Our unsupervised chunkers extend straightforwardly to a cascade that predicts higher levels of constituent structure, similar to the supervised approach of.", "labels": [], "entities": []}, {"text": "This forms an overall unsupervised parsing system that outperforms CCL by a wide margin.", "labels": [], "entities": [{"text": "parsing", "start_pos": 35, "end_pos": 42, "type": "TASK", "confidence": 0.9372531771659851}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Constituent chunks and base NPs in the datasets.", "labels": [], "entities": []}, {"text": " Table 2: Percentage of gold standard constituents and  words under constituent chunks and base NPs.", "labels": [], "entities": []}, {"text": " Table 3: Unsupervised chunking results for local constituent structure identification and NP chunking on held-out test  sets. CCL refers to the lowest constituents extracted from CCL output.", "labels": [], "entities": [{"text": "local constituent structure identification", "start_pos": 44, "end_pos": 86, "type": "TASK", "confidence": 0.7182510942220688}, {"text": "NP chunking", "start_pos": 91, "end_pos": 102, "type": "TASK", "confidence": 0.7972767949104309}]}, {"text": " Table 4: Recall of CCL on the chunking tasks.", "labels": [], "entities": [{"text": "Recall", "start_pos": 10, "end_pos": 16, "type": "METRIC", "confidence": 0.9743859171867371}]}, {"text": " Table 7: NP and PP recall at cascade levels 1 and 2. The  level 1 NP numbers differ from the NP chunking numbers  from Table 3 since they include root-level constituents  which are often NPs.", "labels": [], "entities": [{"text": "recall", "start_pos": 20, "end_pos": 26, "type": "METRIC", "confidence": 0.8481329083442688}]}, {"text": " Table 6: Unlabeled PARSEVAL scores for cascaded models.", "labels": [], "entities": [{"text": "PARSEVAL", "start_pos": 20, "end_pos": 28, "type": "METRIC", "confidence": 0.8430363535881042}]}, {"text": " Table 9: Effects of dropping phrasal punctuation in un- supervised chunking and parsing evaluations relative to", "labels": [], "entities": [{"text": "parsing evaluations", "start_pos": 81, "end_pos": 100, "type": "TASK", "confidence": 0.7798773348331451}]}]}