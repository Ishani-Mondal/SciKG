{"title": [], "abstractContent": [{"text": "Tree-to-string translation is syntax-aware and efficient but sensitive to parsing errors.", "labels": [], "entities": [{"text": "Tree-to-string translation", "start_pos": 0, "end_pos": 26, "type": "TASK", "confidence": 0.6475509852170944}]}, {"text": "Forest-to-string translation approaches mitigate the risk of propagating parser errors into translation errors by considering a forest of alternative trees, as generated by a source language parser.", "labels": [], "entities": []}, {"text": "We propose an alternative approach to generating forests that is based on combining sub-trees within the first best parse through binarization.", "labels": [], "entities": []}, {"text": "Provably, our binarization forest can cover any non-consitituent phrases in a sentence but maintains the desirable property that for each span there is at most one nonterminal so that the grammar constant for decoding is relatively small.", "labels": [], "entities": []}, {"text": "For the purpose of reducing search errors, we apply the synchronous binarization technique to forest-to-string decoding.", "labels": [], "entities": []}, {"text": "Combining the two techniques , we show that using a fast shift-reduce parser we can achieve significant quality gains in NIST 2008 English-to-Chinese track (1.3 BLEU points over a phrase-based system, 0.8 BLEU points over a hierarchical phrase-based system).", "labels": [], "entities": [{"text": "NIST 2008 English-to-Chinese track", "start_pos": 121, "end_pos": 155, "type": "DATASET", "confidence": 0.9547064304351807}, {"text": "BLEU", "start_pos": 161, "end_pos": 165, "type": "METRIC", "confidence": 0.9975739121437073}, {"text": "BLEU", "start_pos": 205, "end_pos": 209, "type": "METRIC", "confidence": 0.9966381788253784}]}, {"text": "Consistent and significant gains are also shown in WMT 2010 in the English to German, French, Spanish and Czech tracks.", "labels": [], "entities": [{"text": "WMT 2010", "start_pos": 51, "end_pos": 59, "type": "DATASET", "confidence": 0.8960621356964111}]}], "introductionContent": [{"text": "In recent years, researchers have explored a wide spectrum of approaches to incorporate syntax and structure into machine translation models.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 114, "end_pos": 133, "type": "TASK", "confidence": 0.715618908405304}]}, {"text": "The unifying framework for these models is synchronous grammars or tree transducers ().", "labels": [], "entities": []}, {"text": "Depending on whether or not monolingual parsing is carried out on the source side or the target side for inference, there are four general categories within the framework: \u2022 string-to-string) \u2022 string-to-tree ( \u2022 tree-to-string; \u2022 tree-to-tree In terms of search, the string-to-x models explore all possible source parses and map them to the target side, while the tree-to-x models search over the subspace of structures of the source side constrained by an input tree or trees.", "labels": [], "entities": []}, {"text": "Hence, tree-to-x models are more constrained but more efficient.", "labels": [], "entities": []}, {"text": "Models such as  can match multilevel tree fragments on the source side which means larger contexts are taken into account for translation), which is a modeling advantage.", "labels": [], "entities": []}, {"text": "To balance efficiency and accuracy, forest-tostring models (  use a compact representation of exponentially many trees to improve tree-to-string models.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 26, "end_pos": 34, "type": "METRIC", "confidence": 0.9988135099411011}]}, {"text": "Traditionally, such forests are obtained through hyper-edge pruning in the k-best search space of a monolingual parser.", "labels": [], "entities": []}, {"text": "The pruning parameters that control the size of forests are normally handtuned.", "labels": [], "entities": []}, {"text": "Such forests encode both syntactic variants and structural variants.", "labels": [], "entities": []}, {"text": "By syntactic variants, we refer to the fact that a parser can parse a substring into either a noun phrase or verb phrase in certain cases.", "labels": [], "entities": []}, {"text": "835 We believe that structural variants which allow more source spans to be explored during translation are more important, while syntactic variants might improve word sense disambiguation but also introduce more spurious ambiguities () during decoding.", "labels": [], "entities": [{"text": "word sense disambiguation", "start_pos": 163, "end_pos": 188, "type": "TASK", "confidence": 0.6782131393750509}]}, {"text": "To focus on structural variants, we propose a family of binarization algorithms to expand one single constituent tree into a packed forest of binary trees containing combinations of adjacent tree nodes.", "labels": [], "entities": []}, {"text": "We control the freedom of tree node binary combination by restricting the distance to the lowest common ancestor of two tree nodes.", "labels": [], "entities": []}, {"text": "We show that the best results are achieved when the distance is two, i.e., when combining tree nodes sharing a common grand-parent.", "labels": [], "entities": []}, {"text": "In contrast to conventional parser-produced-forestto-string models, in our model: \u2022 Forests are not generated by a parser but by combining sub-structures using a tree binarizer.", "labels": [], "entities": []}, {"text": "\u2022 Instead of using arbitary pruning parameters, we control forest size by an integer number that defines the degree of tree structure violation.", "labels": [], "entities": []}, {"text": "\u2022 There is at most one nonterminal per span so that the grammar constant is small.", "labels": [], "entities": []}, {"text": "Since GHKM rules () can cover multi-level tree fragments, asynchronous grammar extracted using the GHKM algorithm can have synchronous translation rules with more than two nonterminals regardless of the branching factor of the source trees.", "labels": [], "entities": []}, {"text": "For the first time, we show that similar to string-to-tree decoding, synchronous binarization significantly reduces search errors and improves translation quality for forest-to-string decoding.", "labels": [], "entities": []}, {"text": "To summarize, the whole pipeline is as follows.", "labels": [], "entities": []}, {"text": "First, a parser produces the highest-scored tree for an input sentence.", "labels": [], "entities": []}, {"text": "Second, the parse tree is restructured using our binarization algorithm, resulting in a binary packed forest.", "labels": [], "entities": []}, {"text": "Third, we apply the forest-based variant of the GHKM algorithm ) on the new forest for rule extraction.", "labels": [], "entities": [{"text": "rule extraction", "start_pos": 87, "end_pos": 102, "type": "TASK", "confidence": 0.8104504346847534}]}, {"text": "Fourth, on the translation forest generated by all applicable translation rules, which is not necessarily binary, we apply the synchronous binarization algorithm () to generate a binary translation forest.", "labels": [], "entities": []}, {"text": "Finally, we use a bottom-up decoding algorithm with intergrated LM intersection using the cube pruning technique.", "labels": [], "entities": []}, {"text": "The rest of the paper is organized as follows.", "labels": [], "entities": []}, {"text": "In Section 2, we give an overview of the forest-tostring models.", "labels": [], "entities": []}, {"text": "In Section 2.1, we introduce a more efficient and flexible algorithm for extracting composed GHKM rules based on the same principle as cube pruning.", "labels": [], "entities": []}, {"text": "In Section 3, we introduce our source tree binarization algorithm for producing binarized forests.", "labels": [], "entities": []}, {"text": "In Section 4, we explain how to do synchronous rule factorization in a forest-to-string decoder.", "labels": [], "entities": []}, {"text": "Experimental results are in Section 5.", "labels": [], "entities": []}], "datasetContent": [{"text": "We ran experiments on public data sets for English to Chinese, Czech, French, German, and SpanishAlgorithm 1 The CYK-n Binarization Algorithm 1: function CYKBINARIZER(T, n) 2: for each tree node \u2208 T in bottom-up topological order do 3: Make a copy of node in the forest output F 4: Ancestors[node] = the nearest n ancestors of node 5: Label translation to evaluate our methods.", "labels": [], "entities": [{"text": "Label translation", "start_pos": 335, "end_pos": 352, "type": "TASK", "confidence": 0.8128188252449036}]}], "tableCaptions": [{"text": " Table 3: Comparing different source tree binarization  schemes for English-Chinese translation, showing both  BLEU scores and model sizes. The rule counts include  normal phrases which are used at the leaf level during  decoding.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 111, "end_pos": 115, "type": "METRIC", "confidence": 0.9992051720619202}]}, {"text": " Table 4: Binarized forests versus parser-generated forests  for forest-to-string English-German translation.", "labels": [], "entities": []}, {"text": " Table 5: The effect of synchronous binarization for tree- to-string and forest-to-string systems, on the English- Chinese task.", "labels": [], "entities": []}]}