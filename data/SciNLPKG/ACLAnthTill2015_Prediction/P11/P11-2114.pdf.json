{"title": [{"text": "Comparative News Summarization Using Linear Programming", "labels": [], "entities": [{"text": "Comparative News Summarization", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.7745938698450724}]}], "abstractContent": [{"text": "Comparative News Summarization aims to highlight the commonalities and differences between two comparable news topics.", "labels": [], "entities": [{"text": "Comparative News Summarization", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.7280856966972351}]}, {"text": "In this study, we propose a novel approach to generating comparative news summaries.", "labels": [], "entities": [{"text": "generating comparative news summaries", "start_pos": 46, "end_pos": 83, "type": "TASK", "confidence": 0.7336712926626205}]}, {"text": "We formulate the task as an optimization problem of selecting proper sentences to maximize the comparativeness within the summary and the representativeness to both news topics.", "labels": [], "entities": []}, {"text": "We consider semantic-related cross-topic concept pairs as comparative evidences, and consider topic-related concepts as representative evidences.", "labels": [], "entities": []}, {"text": "The optimization problem is addressed by using a linear programming model.", "labels": [], "entities": []}, {"text": "The experimental results demonstrate the effectiveness of our proposed model.", "labels": [], "entities": []}], "introductionContent": [{"text": "Comparative News Summarization aims to highlight the commonalities and differences between two comparable news topics.", "labels": [], "entities": [{"text": "Comparative News Summarization", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.7280856966972351}]}, {"text": "It can help users to analyze trends, draw lessons from the past, and gain insights about similar situations.", "labels": [], "entities": []}, {"text": "For example, by comparing the information about mining accidents in Chile and China, we can discover what leads to the different endings and how to avoid those tragedies.", "labels": [], "entities": []}, {"text": "Comparative text mining has drawn much attention in recent years.", "labels": [], "entities": [{"text": "Comparative text mining", "start_pos": 0, "end_pos": 23, "type": "TASK", "confidence": 0.809643546740214}]}, {"text": "The proposed works differ in the domain of corpus, the source of comparison and the representing form of results.", "labels": [], "entities": []}, {"text": "So far, most researches focus on comparing review opinions of products (; Jindal and Liu, 2006a; * Corresponding author.", "labels": [], "entities": []}, {"text": "A reason is that the aspects in reviews are easy to be extracted and the comparisons have simple patterns, e.g. positive vs. negative.", "labels": [], "entities": []}, {"text": "A few other works have also tried to compare facts and views in news article () and Blogs ().", "labels": [], "entities": [{"text": "Blogs", "start_pos": 84, "end_pos": 89, "type": "DATASET", "confidence": 0.8935942649841309}]}, {"text": "The comparative information can be extracted from explicit comparative sentences (), or mined implicitly by matching up features of objects in the same aspects).", "labels": [], "entities": []}, {"text": "The comparisons can be represented by charts (), word clusters (, key phrases(), and summaries which consist of pairs of sentences or text sections).", "labels": [], "entities": []}, {"text": "Among these forms, the comparative summary conveys rich information with good readability, so it keeps attracting interest in the research community.", "labels": [], "entities": []}, {"text": "In general, document summarization can be performed by extraction or abstraction).", "labels": [], "entities": [{"text": "document summarization", "start_pos": 12, "end_pos": 34, "type": "TASK", "confidence": 0.6364962458610535}]}, {"text": "Due to the difficulty of natural sentence generation, most automatic summarization systems are extraction-based.", "labels": [], "entities": [{"text": "sentence generation", "start_pos": 33, "end_pos": 52, "type": "TASK", "confidence": 0.7963089048862457}]}, {"text": "They select salient sentences to maximize the objective functions of generated summaries).", "labels": [], "entities": []}, {"text": "The major difference between the traditional summarization task and the comparative summarization task is that traditional summarization task places equal emphasis on all kinds of information in the source, while comparative summarization task only focuses on the comparisons between objects.", "labels": [], "entities": [{"text": "summarization task", "start_pos": 45, "end_pos": 63, "type": "TASK", "confidence": 0.9150122702121735}, {"text": "summarization task", "start_pos": 123, "end_pos": 141, "type": "TASK", "confidence": 0.8709952235221863}]}, {"text": "News is one of the most important channels for acquiring information.", "labels": [], "entities": []}, {"text": "However, it is more difficult to extract comparisons in news articles than in reviews.", "labels": [], "entities": []}, {"text": "The aspects are much diverse in news.", "labels": [], "entities": []}, {"text": "They can be the time of the events, the person involved, the attitudes of participants, etc.", "labels": [], "entities": []}, {"text": "These aspects can be expressed explicitly or implicitly in many ways.", "labels": [], "entities": []}, {"text": "For example, \"storm\" and \"rain\" both talk about \"weather\", and thus they can form a potential comparison.", "labels": [], "entities": []}, {"text": "All these issues raise great challenges to comparative summarization in the news domain.", "labels": [], "entities": [{"text": "comparative summarization", "start_pos": 43, "end_pos": 68, "type": "TASK", "confidence": 0.851007342338562}]}, {"text": "In this study, we propose a novel approach for comparative news summarization.", "labels": [], "entities": [{"text": "comparative news summarization", "start_pos": 47, "end_pos": 77, "type": "TASK", "confidence": 0.9279255270957947}]}, {"text": "We consider comparativeness and representativeness as well as redundancy in an objective function, and solve the optimization problem by using linear programming to extract proper comparable sentences.", "labels": [], "entities": []}, {"text": "More specifically, we consider a pair of sentences comparative if they share comparative concepts; we also consider a sentence representative if it contains important concepts about the topic.", "labels": [], "entities": []}, {"text": "Thus a good comparative summary contains important comparative pairs, as well as important concepts about individual topics.", "labels": [], "entities": []}, {"text": "Experimental results demonstrate the effectiveness of our model, which outperforms the baseline systems in quality of comparison identification and summarization.", "labels": [], "entities": [{"text": "comparison identification", "start_pos": 118, "end_pos": 143, "type": "TASK", "confidence": 0.7906760275363922}, {"text": "summarization", "start_pos": 148, "end_pos": 161, "type": "TASK", "confidence": 0.9707741737365723}]}], "datasetContent": [{"text": "Because of the novelty of the comparative news summarization task, there is no existing data set for evaluating.", "labels": [], "entities": [{"text": "comparative news summarization task", "start_pos": 30, "end_pos": 65, "type": "TASK", "confidence": 0.8712385296821594}]}, {"text": "We thus create our own.", "labels": [], "entities": []}, {"text": "We first choose five pairs of comparable topics, then retrieve ten related news articles for each topic using the Google News 2 search engine.", "labels": [], "entities": [{"text": "Google News 2 search engine", "start_pos": 114, "end_pos": 141, "type": "DATASET", "confidence": 0.8514352440834045}]}, {"text": "Finally we write the comparative summary for each topic pair manually.", "labels": [], "entities": []}, {"text": "The topics are showed in table 1.", "labels": [], "entities": []}, {"text": "We evaluate the models with following measures: Comparison Precision / Recall / F-measure: let a a and am be the numbers of all aspects We use IBM ILOG CPLEX optimizer to solve the problem.", "labels": [], "entities": [{"text": "Comparison", "start_pos": 48, "end_pos": 58, "type": "METRIC", "confidence": 0.9211989641189575}, {"text": "Precision", "start_pos": 59, "end_pos": 68, "type": "METRIC", "confidence": 0.6496785879135132}, {"text": "Recall", "start_pos": 71, "end_pos": 77, "type": "METRIC", "confidence": 0.6309959292411804}, {"text": "F-measure", "start_pos": 80, "end_pos": 89, "type": "METRIC", "confidence": 0.8902238011360168}, {"text": "IBM ILOG CPLEX", "start_pos": 143, "end_pos": 157, "type": "DATASET", "confidence": 0.6045311192671458}]}, {"text": "involved in the automatically generated summary and manually written summary respectively; ca be the number of human agreed comparative aspects in the automatically generated summary.", "labels": [], "entities": []}, {"text": "The comparison precision (CP ), comparison recall (CR) and comparison F-measure (CF ) are defined as follows: the ROUGE is a widely used metric in summarization evaluation.", "labels": [], "entities": [{"text": "comparison precision (CP )", "start_pos": 4, "end_pos": 30, "type": "METRIC", "confidence": 0.8201314449310303}, {"text": "recall (CR)", "start_pos": 43, "end_pos": 54, "type": "METRIC", "confidence": 0.9409919530153275}, {"text": "comparison F-measure (CF )", "start_pos": 59, "end_pos": 85, "type": "METRIC", "confidence": 0.847062063217163}, {"text": "ROUGE", "start_pos": 114, "end_pos": 119, "type": "METRIC", "confidence": 0.992276132106781}, {"text": "summarization evaluation", "start_pos": 147, "end_pos": 171, "type": "TASK", "confidence": 0.9403804242610931}]}, {"text": "It measures summary quality by counting overlapping units between the candidate summary and the reference summary (.", "labels": [], "entities": []}, {"text": "In the experiment, we report the f-measure values of ROUGE-1, ROUGE-2 and ROUGE-SU4, which count overlapping unigrams, bigrams and skip-4-grams respectively.", "labels": [], "entities": [{"text": "ROUGE-1", "start_pos": 53, "end_pos": 60, "type": "METRIC", "confidence": 0.9249880313873291}, {"text": "ROUGE-2", "start_pos": 62, "end_pos": 69, "type": "METRIC", "confidence": 0.8825139999389648}, {"text": "ROUGE-SU4", "start_pos": 74, "end_pos": 83, "type": "METRIC", "confidence": 0.8593477606773376}]}, {"text": "To evaluate whether the summary is related to both topics, we also split each comparative summary into two topic-related parts, evaluate them respectively, and report the mean of the two ROUGE values (denoted as MROUGE).", "labels": [], "entities": [{"text": "ROUGE", "start_pos": 187, "end_pos": 192, "type": "METRIC", "confidence": 0.9943221807479858}, {"text": "MROUGE", "start_pos": 212, "end_pos": 218, "type": "METRIC", "confidence": 0.9913703203201294}]}, {"text": "We apply all the systems to generate comparative summaries with a length limit of 200 words.", "labels": [], "entities": []}, {"text": "The evaluation results are shown in table 2.", "labels": [], "entities": []}, {"text": "Compared with baseline models, our linear programming based comparative model (denoted as LPCM) achieves best scores overall metrics.", "labels": [], "entities": []}, {"text": "It is expected to find that the NCM model does not perform well in this task because it does not focus on the comparisons.", "labels": [], "entities": []}, {"text": "The CRM model utilizes the similarity between two topics to enhance the score of comparison related sentences.", "labels": [], "entities": []}, {"text": "However, it does not guarantee to choose pairwise sentences to form comparisons.", "labels": [], "entities": []}, {"text": "The LPCM model focus on both comparativeness and representativeness at the same time, and thus it achieves good performance on both comparison extraction and summarization.", "labels": [], "entities": [{"text": "comparison extraction", "start_pos": 132, "end_pos": 153, "type": "TASK", "confidence": 0.8435044884681702}, {"text": "summarization", "start_pos": 158, "end_pos": 171, "type": "TASK", "confidence": 0.9547532200813293}]}], "tableCaptions": [{"text": " Table 1: Comparable topic pairs in the dataset.", "labels": [], "entities": []}, {"text": " Table 2: Evaluation results of systems", "labels": [], "entities": []}]}