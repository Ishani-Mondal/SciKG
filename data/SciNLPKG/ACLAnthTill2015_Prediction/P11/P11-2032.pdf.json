{"title": [{"text": "Bayesian Word Alignment for Statistical Machine Translation", "labels": [], "entities": [{"text": "Bayesian Word Alignment", "start_pos": 0, "end_pos": 23, "type": "TASK", "confidence": 0.5375699698925018}, {"text": "Statistical Machine Translation", "start_pos": 28, "end_pos": 59, "type": "TASK", "confidence": 0.8234955271085104}]}], "abstractContent": [{"text": "In this work, we compare the translation performance of word alignments obtained via Bayesian inference to those obtained via expectation-maximization (EM).", "labels": [], "entities": []}, {"text": "We propose a Gibbs sampler for fully Bayesian inference in IBM Model 1, integrating overall possible parameter values in finding the alignment distribution.", "labels": [], "entities": [{"text": "IBM Model 1", "start_pos": 59, "end_pos": 70, "type": "DATASET", "confidence": 0.9630708893140157}]}, {"text": "We show that Bayesian inference outperforms EM in all of the tested language pairs, domains and data set sizes, by up to 2.99 BLEU points.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 126, "end_pos": 130, "type": "METRIC", "confidence": 0.9983198046684265}]}, {"text": "We also show that the proposed method effectively addresses the well-known rare word problem in EM-estimated models; and at the same time induces a much smaller dictionary of bilingual word-pairs.", "labels": [], "entities": []}], "introductionContent": [{"text": "Word alignment is a crucial early step in the training of most statistical machine translation (SMT) systems, in which the estimated alignments are used for constraining the set of candidates in phrase/grammar extraction ().", "labels": [], "entities": [{"text": "Word alignment", "start_pos": 0, "end_pos": 14, "type": "TASK", "confidence": 0.7089507579803467}, {"text": "statistical machine translation (SMT)", "start_pos": 63, "end_pos": 100, "type": "TASK", "confidence": 0.8032053112983704}, {"text": "phrase/grammar extraction", "start_pos": 195, "end_pos": 220, "type": "TASK", "confidence": 0.6434605047106743}]}, {"text": "State-of-the-art word alignment models, such as IBM Models (), HMM (, and the jointly-trained symmetric HMM (), contain a large number of parameters (e.g., word translation probabilities) that need to be estimated in addition to the desired hidden alignment variables.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 17, "end_pos": 31, "type": "TASK", "confidence": 0.7685525715351105}, {"text": "IBM Models", "start_pos": 48, "end_pos": 58, "type": "DATASET", "confidence": 0.9288302659988403}, {"text": "word translation", "start_pos": 156, "end_pos": 172, "type": "TASK", "confidence": 0.7049812972545624}]}, {"text": "The most common method of inference in such models is expectation-maximization (EM) or an approximation to EM when exact EM is intractable.", "labels": [], "entities": []}, {"text": "However, being a maximization (e.g., maximum likelihood (ML) or maximum a posteriori (MAP)) technique, EM is generally prone to local optima and overfitting.", "labels": [], "entities": [{"text": "maximum likelihood (ML) or maximum a posteriori (MAP))", "start_pos": 37, "end_pos": 91, "type": "METRIC", "confidence": 0.7950189212958018}, {"text": "EM", "start_pos": 103, "end_pos": 105, "type": "TASK", "confidence": 0.9384836554527283}]}, {"text": "In essence, the alignment distribution obtained via EM takes into account only the most likely point in the parameter space, but does not consider contributions from other points.", "labels": [], "entities": []}, {"text": "Problems with the standard EM estimation of IBM Model 1 was pointed out by and a number of heuristic changes to the estimation procedure, such as smoothing the parameter estimates, were shown to reduce the alignment error rate, but the effects on translation performance was not reported.", "labels": [], "entities": [{"text": "EM estimation", "start_pos": 27, "end_pos": 40, "type": "TASK", "confidence": 0.814597874879837}, {"text": "IBM Model 1", "start_pos": 44, "end_pos": 55, "type": "DATASET", "confidence": 0.8271377086639404}, {"text": "alignment error rate", "start_pos": 206, "end_pos": 226, "type": "METRIC", "confidence": 0.694431314865748}, {"text": "translation", "start_pos": 247, "end_pos": 258, "type": "TASK", "confidence": 0.9590343236923218}]}, {"text": "note that the parameter estimation (for which they use variational EM) suffers from data sparsity and use symmetric Dirichlet priors, but they find the MAP solution.", "labels": [], "entities": [{"text": "parameter estimation", "start_pos": 14, "end_pos": 34, "type": "TASK", "confidence": 0.6675588190555573}]}, {"text": "Bayesian inference, the approach in this paper, have recently been applied to several unsupervised learning problems in NLP as well as to other tasks in SMT such as synchronous grammar induction) and learning phrase alignments directly.", "labels": [], "entities": [{"text": "SMT", "start_pos": 153, "end_pos": 156, "type": "TASK", "confidence": 0.9920964241027832}, {"text": "synchronous grammar induction", "start_pos": 165, "end_pos": 194, "type": "TASK", "confidence": 0.5793706774711609}, {"text": "learning phrase alignments", "start_pos": 200, "end_pos": 226, "type": "TASK", "confidence": 0.6681157847245535}]}, {"text": "Word alignment learning problem was addressed jointly with segmentation learning in,, and.", "labels": [], "entities": [{"text": "Word alignment learning", "start_pos": 0, "end_pos": 23, "type": "TASK", "confidence": 0.8120417396227518}]}, {"text": "The former two works place nonparametric priors (also known as cache models) on the parameters and utilize Gibbs sampling.", "labels": [], "entities": []}, {"text": "However, alignment inference in neither of these works is exactly Bayesian since the alignments are updated by running GIZA++ ( or by local maximization ().", "labels": [], "entities": [{"text": "alignment inference", "start_pos": 9, "end_pos": 28, "type": "TASK", "confidence": 0.9467212855815887}]}, {"text": "On the other hand, apply a sparse Dirichlet prior on the multinomial parameters to prevent overfitting.", "labels": [], "entities": []}, {"text": "They use variational Bayes for inference, but they do not investigate the effect of Bayesian inference to word alignment in isolation.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 106, "end_pos": 120, "type": "TASK", "confidence": 0.7514753341674805}]}, {"text": "Recently, proposed fertility extensions to IBM Model 1 and HMM, but they do not place any prior on the parameters and their inference method is actually stochastic EM (also known as Monte Carlo EM), a ML technique in which sampling is used to approximate the expected counts in the E-step.", "labels": [], "entities": [{"text": "IBM Model 1", "start_pos": 43, "end_pos": 54, "type": "DATASET", "confidence": 0.8713480631510416}]}, {"text": "Even though they report substantial reductions in alignment error rate, the translation BLEU scores do not improve.", "labels": [], "entities": [{"text": "alignment error rate", "start_pos": 50, "end_pos": 70, "type": "METRIC", "confidence": 0.768756628036499}, {"text": "BLEU", "start_pos": 88, "end_pos": 92, "type": "METRIC", "confidence": 0.8358302712440491}]}, {"text": "Our approach in this paper is fully Bayesian in which the alignment probabilities are inferred by integrating overall possible parameter values assuming an intuitive, sparse prior.", "labels": [], "entities": []}, {"text": "We develop a Gibbs sampler for alignments under IBM Model 1, which is relevant for the state-of-the-art SMT systems since: (1) Model 1 is used in bootstrapping the parameter settings for EM training of higherorder alignment models, and (2) many state-of-theart SMT systems use Model 1 translation probabilities as features in their log-linear model.", "labels": [], "entities": [{"text": "IBM Model 1", "start_pos": 48, "end_pos": 59, "type": "DATASET", "confidence": 0.9321458339691162}, {"text": "SMT", "start_pos": 104, "end_pos": 107, "type": "TASK", "confidence": 0.98822021484375}, {"text": "SMT", "start_pos": 261, "end_pos": 264, "type": "TASK", "confidence": 0.9191440939903259}]}, {"text": "We evaluate the inferred alignments in terms of the end-toend translation performance, where we show the results with a variety of input data to illustrate the general applicability of the proposed technique.", "labels": [], "entities": []}, {"text": "To our knowledge, this is the first work to directly investigate the effects of Bayesian alignment inference on translation performance.", "labels": [], "entities": [{"text": "Bayesian alignment inference", "start_pos": 80, "end_pos": 108, "type": "TASK", "confidence": 0.7284682095050812}]}], "datasetContent": [{"text": "For Turkish\u2194English experiments, we used the 20K-sentence travel domain BTEC dataset () from the yearly IWSLT evaluations 6 for training, the CSTAR 2003 test set for development, and the IWSLT 2004 test set for testing . For Czech\u2194English, we used the 95K-sentence news commentary parallel corpus from the WMT shared task 8 for training, news2008 set for development, news2009 set for testing, and the 438M-word English and 81.7M-word Czech monolingual news corpora for additional language model (LM) training.", "labels": [], "entities": [{"text": "BTEC dataset", "start_pos": 72, "end_pos": 84, "type": "DATASET", "confidence": 0.9250964820384979}, {"text": "CSTAR 2003 test set", "start_pos": 142, "end_pos": 161, "type": "DATASET", "confidence": 0.9433177411556244}, {"text": "IWSLT 2004 test set", "start_pos": 187, "end_pos": 206, "type": "DATASET", "confidence": 0.9488572627305984}, {"text": "WMT shared task 8", "start_pos": 306, "end_pos": 323, "type": "DATASET", "confidence": 0.7842100262641907}]}, {"text": "For Arabic\u2194English, we used the 65K-sentence LDC2004T18 (news from) for training, the AFP portion of LDC2004T17 (news from 1998, single reference) for development and testing (about 875 sentences each), and the 298M-word English and 215M-word Arabic AFP and Xinhua subsets of the respective Gigaword corpora (LDC2007T07 and LDC2007T40) for additional LM training.", "labels": [], "entities": []}, {"text": "All language models are 4-gram in the travel domain experiments and 5-gram in the news domain experiments.", "labels": [], "entities": []}, {"text": "For each language pair, we trained standard phrase-based SMT systems in both directions (including alignment symmetrization and log-linear model tuning) using Moses (, SRILM, and ZMERT (Zaidan, 2009) tools and evaluated using BLEU (  GIZA++ (Och and Ney, 2003) for EM.", "labels": [], "entities": [{"text": "SMT", "start_pos": 57, "end_pos": 60, "type": "TASK", "confidence": 0.870810329914093}, {"text": "BLEU", "start_pos": 226, "end_pos": 230, "type": "METRIC", "confidence": 0.9964473843574524}]}, {"text": "For each translation task, we report two EM estimates, obtained after 5 and 80 iterations (EM-5 and EM-80), respectively; and three Gibbs sampling estimates, two of which were initialized with those two EM Viterbi alignments (GS-5 and GS-80) and a third was initialized naively 9 (GS-N).", "labels": [], "entities": [{"text": "translation task", "start_pos": 9, "end_pos": 25, "type": "TASK", "confidence": 0.9010339081287384}, {"text": "GS-N", "start_pos": 281, "end_pos": 285, "type": "DATASET", "confidence": 0.7538211345672607}]}, {"text": "Sampling settings were B = 400 for T\u2194E, 4000 for C\u2194E and 8000 for A\u2194E; M = 100, and L = 10.", "labels": [], "entities": []}, {"text": "For reference, we also report the results with IBM Model 4 alignments (M4) trained in the standard bootstrapping regimen of 1 5 H 5 3 3 4 3 . compares the BLEU scores of Bayesian inference and EM estimation.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 155, "end_pos": 159, "type": "METRIC", "confidence": 0.9992634654045105}, {"text": "EM estimation", "start_pos": 193, "end_pos": 206, "type": "TASK", "confidence": 0.6268895268440247}]}, {"text": "In all translation tasks, Bayesian inference outperforms EM.", "labels": [], "entities": [{"text": "translation tasks", "start_pos": 7, "end_pos": 24, "type": "TASK", "confidence": 0.9253039360046387}]}, {"text": "The improvement range is from 2.59 (in Turkish-to-English) up to 2.99 (in English-to-Turkish) BLEU points in travel domain and from 0.16 (in English-to-Czech) up to 0.85 (in English-to-Arabic) BLEU points in news domain.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 94, "end_pos": 98, "type": "METRIC", "confidence": 0.9978862404823303}, {"text": "BLEU", "start_pos": 193, "end_pos": 197, "type": "METRIC", "confidence": 0.9987016916275024}]}, {"text": "Compared to the state-of-the-art IBM Model 4, the Bayesian Model 1 is better in all travel domain tasks and is comparable or better in the news domain.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: BLEU scores in translation experiments. E: En- glish, T: Turkish, C: Czech, A: Arabic.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9990547299385071}]}, {"text": " Table 3: Distribution of inferred alignment fertilities. The  four blocks of rows from top to bottom correspond to (in  order) the total number of source tokens, source tokens  with fertilities in the range 4-7, source tokens with fertil- ities higher than 7, and the maximum observed fertility.  The first language listed is the source in alignment (Sec- tion 2).", "labels": [], "entities": []}, {"text": " Table 4: Sizes of bilingual dictionaries induced by differ- ent alignment methods.", "labels": [], "entities": []}]}