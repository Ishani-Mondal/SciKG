{"title": [{"text": "Confidence-Weighted Learning of Factored Discriminative Language Models", "labels": [], "entities": []}], "abstractContent": [{"text": "Language models based on word surface forms only are unable to benefit from available linguistic knowledge, and tend to suffer from poor estimates for rare features.", "labels": [], "entities": []}, {"text": "We propose an approach to overcome these two limitations.", "labels": [], "entities": []}, {"text": "We use factored features that can flexibly capture linguistic regularities, and we adopt confidence-weighted learning, a form of discriminative online learning that can better take advantage of a heavy tail of rare features.", "labels": [], "entities": []}, {"text": "Finally, we extend the confidence-weighted learning to deal with label noise in training data, a common case with discriminative language modeling.", "labels": [], "entities": []}], "introductionContent": [{"text": "Language Models (LMs) are key components inmost statistical machine translation systems, where they play a crucial role in promoting output fluency.", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 48, "end_pos": 79, "type": "TASK", "confidence": 0.628483513991038}]}, {"text": "Standard n-gram generative language models have been extended in several ways.", "labels": [], "entities": []}, {"text": "Generative factored language models represent each token by multiple factorssuch as part-of-speech, lemma and surface formand capture linguistic patterns in the target language at the appropriate level of abstraction.", "labels": [], "entities": []}, {"text": "Instead of estimating likelihood, discriminative language models ( directly model fluency by casting the task as a binary classification or a ranking problem.", "labels": [], "entities": []}, {"text": "The method we propose combines advantages of both directions mentioned above.", "labels": [], "entities": []}, {"text": "We use factored features to capture linguistic patterns and discriminative learning for directly modeling fluency.", "labels": [], "entities": []}, {"text": "We define highly overlapping and correlated factored features, and extend a robust learning algorithm to handle them and cope with a high rate of label noise.", "labels": [], "entities": []}, {"text": "For discriminatively learning language models, we use confidence-weighted learning (, an extension of the perceptron-based online learning used in previous work on discriminative language models.", "labels": [], "entities": []}, {"text": "Furthermore, we extend confidence-weighted learning with soft margin to handle the case where training data labels are noisy, as is typically the casein discriminative language modeling.", "labels": [], "entities": []}, {"text": "The rest of this paper is organized as follows.", "labels": [], "entities": []}, {"text": "In Section 2, we introduce factored features for discriminative language models.", "labels": [], "entities": []}, {"text": "Section 3 presents confidence-weighted learning.", "labels": [], "entities": []}, {"text": "Section 4 describes its extension for the case where training data are noisy.", "labels": [], "entities": []}, {"text": "We present empirical results in Section 5 and differentiate our approach from previous ones in Section 6.", "labels": [], "entities": []}, {"text": "Finally, Section 7 presents some concluding remarks.", "labels": [], "entities": []}], "datasetContent": [{"text": "We empirically validated our approach in two ways.", "labels": [], "entities": []}, {"text": "We first measured the effectiveness of the algorithms in deciding, given a pair of candidate translations fora same source sentence, whether the first candidate is more fluent than the second.", "labels": [], "entities": []}, {"text": "Ina second experiment we used the score provided by the trained DLM as an additional feature in an n-best list reranking task and compared algorithms in terms of impact on NIST and BLEU.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 181, "end_pos": 185, "type": "METRIC", "confidence": 0.9865869879722595}]}, {"text": "The dataset we use in our study is the SpanishEnglish one from the shared task of the WMT-2007 workshop 2 . Matrax, a phrase-based statistical machine translation system), including a trigram generative language model with Kneser-Ney smoothing.", "labels": [], "entities": [{"text": "SpanishEnglish", "start_pos": 39, "end_pos": 53, "type": "DATASET", "confidence": 0.9318215250968933}, {"text": "WMT-2007 workshop 2", "start_pos": 86, "end_pos": 105, "type": "DATASET", "confidence": 0.841905931631724}, {"text": "phrase-based statistical machine translation", "start_pos": 118, "end_pos": 162, "type": "TASK", "confidence": 0.5798774883151054}]}, {"text": "We then obtain training data for the discriminative language model as follows.", "labels": [], "entities": []}, {"text": "We take a random subset of the parallel training set containing 50,000 sentence pairs.", "labels": [], "entities": []}, {"text": "We use Matrax to generate an n-best list for each source sentence.", "labels": [], "entities": []}, {"text": "We define (P i , Ni ), i = 1 . .", "labels": [], "entities": []}, {"text": "50, 000 as:  where NIST * i is the highest sentence-level NIST score achieved in nbest i . The size of n-best lists was set to 10.", "labels": [], "entities": []}, {"text": "Using this dataset, we trained discriminative language models by standard perceptron, confidence-weighted learning and confidenceweighted learning with soft margin.", "labels": [], "entities": []}, {"text": "We then trained the weights of a re-ranker using eight features (seven from the baseline Matrax plus one from the DLM) using a simple structured perceptron algorithm on the development set.", "labels": [], "entities": []}, {"text": "For testing, we used the same trained Matrax model to generate n-best lists of size 1,000 each for each source sentence.", "labels": [], "entities": []}, {"text": "Then, we used the trained discriminative language model to compute a score for each translation in the n-best list.", "labels": [], "entities": []}, {"text": "The score is used with seven standard Matrax features for re-ranking.", "labels": [], "entities": []}, {"text": "Finally, we measure the quality of the translations re-ranked to the top.", "labels": [], "entities": []}, {"text": "In order to obtain the required factors for the target-side tokens, we ran the morphological analyzer and POS-tagger integrated in the Xerox Incremental Parser) on the target side of the training corpus used for creating the phrase-table, and extended the phrase-table format so as to record, for each token, all its factors.", "labels": [], "entities": [{"text": "POS-tagger", "start_pos": 106, "end_pos": 116, "type": "METRIC", "confidence": 0.9210305213928223}]}], "tableCaptions": [{"text": " Table 2: Error rates for fluency ranking. See article body  for an explanation of the experiments.", "labels": [], "entities": [{"text": "Error", "start_pos": 10, "end_pos": 15, "type": "METRIC", "confidence": 0.9916098713874817}, {"text": "fluency ranking", "start_pos": 26, "end_pos": 41, "type": "TASK", "confidence": 0.8149900436401367}]}, {"text": " Table 3: NIST and BLEU scores upon n-best list re- ranking with the proposed discriminative language mod- els.", "labels": [], "entities": [{"text": "NIST", "start_pos": 10, "end_pos": 14, "type": "DATASET", "confidence": 0.8878067135810852}, {"text": "BLEU", "start_pos": 19, "end_pos": 23, "type": "METRIC", "confidence": 0.9933245778083801}]}]}