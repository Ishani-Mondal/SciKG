{"title": [{"text": "Monolingual Alignment by Edit Rate Computation on Sentential Paraphrase Pairs", "labels": [], "entities": [{"text": "Monolingual Alignment", "start_pos": 0, "end_pos": 21, "type": "TASK", "confidence": 0.8966904878616333}]}], "abstractContent": [{"text": "In this paper, we present a novel way of tackling the monolingual alignment problem on pairs of sentential paraphrases by means of edit rate computation.", "labels": [], "entities": []}, {"text": "In order to inform the edit rate, information in the form of subsenten-tial paraphrases is provided by a range of techniques built for different purposes.", "labels": [], "entities": []}, {"text": "We show that the tunable TER-PLUS metric from Machine Translation evaluation can achieve good performance on this task and that it can effectively exploit information coming from complementary sources.", "labels": [], "entities": [{"text": "TER-PLUS", "start_pos": 25, "end_pos": 33, "type": "METRIC", "confidence": 0.9415004253387451}, {"text": "Machine Translation evaluation", "start_pos": 46, "end_pos": 76, "type": "TASK", "confidence": 0.8948850631713867}]}], "introductionContent": [{"text": "The acquisition of subsentential paraphrases has attracted a lot of attention recently . Techniques are usually developed for extracting paraphrase candidates from specific types of corpora, including monolingual parallel corpora), monolingual comparable corpora, bilingual parallel corpora (), and edit histories of multi-authored text).", "labels": [], "entities": []}, {"text": "These approaches face two main issues, which correspond to the typical measures of precision, or how appropriate the extracted paraphrases are, and of recall, or how many of the paraphrases present in a given corpus can be found effectively.", "labels": [], "entities": [{"text": "precision", "start_pos": 83, "end_pos": 92, "type": "METRIC", "confidence": 0.9986299276351929}, {"text": "recall", "start_pos": 151, "end_pos": 157, "type": "METRIC", "confidence": 0.9985135197639465}]}, {"text": "To start with, both measures are often hard to compute in practice, as 1) the definition of what makes an acceptable paraphrase pair is still a research question, and 2) it is often impractical to extract a complete set of acceptable paraphrases from most resources.", "labels": [], "entities": []}, {"text": "Second, as regards the precision of paraphrase acquisition techniques in particular, it is notable that most works on paraphrase acquisition are not based on direct observation of larger paraphrase pairs.", "labels": [], "entities": [{"text": "precision", "start_pos": 23, "end_pos": 32, "type": "METRIC", "confidence": 0.9943028688430786}, {"text": "paraphrase acquisition", "start_pos": 36, "end_pos": 58, "type": "TASK", "confidence": 0.9466713964939117}, {"text": "paraphrase acquisition", "start_pos": 118, "end_pos": 140, "type": "TASK", "confidence": 0.8998343646526337}]}, {"text": "Even monolingual corpora obtained by pairing very closely related texts such as news headlines on the same topic and from the same time frame) often contain unrelated segments that should not be aligned to form a subsentential paraphrase pair.", "labels": [], "entities": []}, {"text": "Using bilingual corpora to acquire paraphrases indirectly by pivoting through other languages is faced, in particular, with the issue of phrase polysemy, both in the source and in the pivot languages.", "labels": [], "entities": []}, {"text": "It has previously been noted that highly parallel monolingual corpora, typically obtained via multiple translation into the same language, constitute the most appropriate type of corpus for extracting high quality paraphrases, in spite of their rareness (.", "labels": [], "entities": []}, {"text": "We build on this claim hereto propose an original approach for the task of subsentential alignment based on the computation of a minimum edit rate between two sentential paraphrases.", "labels": [], "entities": [{"text": "subsentential alignment", "start_pos": 75, "end_pos": 98, "type": "TASK", "confidence": 0.8207777142524719}]}, {"text": "More precisely, we concentrate on the alignment of atomic paraphrase pairs ( , where the words from both paraphrases are aligned as a whole to the words of the other paraphrase, as opposed to composite paraphrase pairs obtained by joining together adjacent paraphrase pairs or possibly adding unaligned words.", "labels": [], "entities": []}, {"text": "provides examples of atomic paraphrase pairs derived from a word alignment between two English sentential paraphrases.: Reference alignments fora pair of English sentential paraphrases and their associated list of atomic paraphrase pairs extracted from them.", "labels": [], "entities": []}, {"text": "Note that identity pairs (e.g. China \u2194 China) will never be considered in this work and will not betaken into account for evaluation.", "labels": [], "entities": []}, {"text": "The remainder of this paper is organized as follows.", "labels": [], "entities": []}, {"text": "We first briefly describe in section 2 how we apply edit rate computation to the task of atomic paraphrase alignment, and we explain in section 3 how we can inform such a technique with paraphrase candidates extracted by additional techniques.", "labels": [], "entities": [{"text": "paraphrase alignment", "start_pos": 96, "end_pos": 116, "type": "TASK", "confidence": 0.7294215261936188}]}, {"text": "We present our experiments and discuss their results in section 4 and conclude in section 5. 2 Edit rate for paraphrase alignment TER-PLUS (Translation Edit Rate Plus)) is a score designed for evaluation of Machine Translation (MT) output.", "labels": [], "entities": [{"text": "Edit rate", "start_pos": 95, "end_pos": 104, "type": "METRIC", "confidence": 0.9859150052070618}, {"text": "paraphrase alignment", "start_pos": 109, "end_pos": 129, "type": "TASK", "confidence": 0.8313117027282715}, {"text": "TER-PLUS (Translation Edit Rate Plus))", "start_pos": 130, "end_pos": 168, "type": "METRIC", "confidence": 0.8589683515684945}, {"text": "Machine Translation (MT) output", "start_pos": 207, "end_pos": 238, "type": "TASK", "confidence": 0.8475899795691172}]}, {"text": "Its typical use takes a system hypothesis to compute an optimal set of word edits that can transform it into some existing reference translation.", "labels": [], "entities": []}, {"text": "Edit types include exact word matching, word insertion and deletion, block movement of contiguous words (computed as an approximation), as well as variants substitution through stemming, synonym or paraphrase matching.", "labels": [], "entities": [{"text": "exact word matching", "start_pos": 19, "end_pos": 38, "type": "TASK", "confidence": 0.5518377919991811}, {"text": "word insertion and deletion", "start_pos": 40, "end_pos": 67, "type": "TASK", "confidence": 0.8122607171535492}, {"text": "paraphrase matching", "start_pos": 198, "end_pos": 217, "type": "TASK", "confidence": 0.6722323596477509}]}, {"text": "Each edit type is parameterized by at least one weight which can be optimized using e.g. hill climbing.", "labels": [], "entities": []}, {"text": "TER-PLUS is therefore a tunable metric.", "labels": [], "entities": [{"text": "TER-PLUS", "start_pos": 0, "end_pos": 8, "type": "METRIC", "confidence": 0.9503450393676758}]}, {"text": "We will henceforth design as TER MT the TER metric (basically, without variants matching) optimized for correlation with human judgment of accuracy in MT evaluation, which is to date one of the most used metrics for this task.", "labels": [], "entities": [{"text": "TER", "start_pos": 29, "end_pos": 32, "type": "METRIC", "confidence": 0.7180612087249756}, {"text": "MT", "start_pos": 33, "end_pos": 35, "type": "TASK", "confidence": 0.48518237471580505}, {"text": "TER metric", "start_pos": 40, "end_pos": 50, "type": "METRIC", "confidence": 0.9547843635082245}, {"text": "accuracy", "start_pos": 139, "end_pos": 147, "type": "METRIC", "confidence": 0.9670661091804504}, {"text": "MT evaluation", "start_pos": 151, "end_pos": 164, "type": "TASK", "confidence": 0.9698271155357361}]}, {"text": "While this metric was not designed explicitely for the acquisition of word alignments, it produces as a by-product of its approximate search a list of alignments involving either individual words or phrases, potentially fitting with the previous definition of atomic paraphrase pairs.", "labels": [], "entities": [{"text": "acquisition of word alignments", "start_pos": 55, "end_pos": 85, "type": "TASK", "confidence": 0.6880753338336945}]}, {"text": "When applying it on a MT system hypothesis and a reference translation, it computes how much effort would be needed to obtain the reference from the hypothesis, possibly independently of the appropriateness of the alignments produced.", "labels": [], "entities": [{"text": "MT system", "start_pos": 22, "end_pos": 31, "type": "TASK", "confidence": 0.8849073052406311}]}, {"text": "However, if we consider instead a pair of sentential paraphrases, it can be used to reveal what subsentential units can be aligned.", "labels": [], "entities": []}, {"text": "Of course, this relies on information that will often go beyond simple exact word matching.", "labels": [], "entities": [{"text": "word matching", "start_pos": 77, "end_pos": 90, "type": "TASK", "confidence": 0.676596000790596}]}, {"text": "This is where the capability of exploiting paraphrase matching can come into play: TER-PLUS can exploit a table of paraphrase pairs, and defines the cost of a phrase substitution as \"a function of the probability of the paraphrase and the number of edits needed to align the two phrases without the use of phrase substitutions\".", "labels": [], "entities": [{"text": "paraphrase matching", "start_pos": 43, "end_pos": 62, "type": "TASK", "confidence": 0.8012551069259644}]}, {"text": "Intuitively, the more parallel two sentential paraphrases are, the more atomic paraphrase pairs will be reliably found, and the easier it will be for TER-PLUS to correctly identify the remaining pairs.", "labels": [], "entities": []}, {"text": "But in the general case, and considering less apparently parallel sentence pairs, its work can be facilitated by the incorporation of candidate paraphrase pairs in its paraphrase table.", "labels": [], "entities": []}, {"text": "We consider this possible type of hybridation in the next section.", "labels": [], "entities": []}, {"text": "Statistical Word Alignment The GIZA++ tool () computes statistical word alignment models of increasing complexity from parallel corpora.", "labels": [], "entities": [{"text": "Statistical Word Alignment", "start_pos": 0, "end_pos": 26, "type": "TASK", "confidence": 0.64260267217954}, {"text": "statistical word alignment", "start_pos": 55, "end_pos": 81, "type": "TASK", "confidence": 0.6296810209751129}]}, {"text": "While originally developped in the bilingual context of Machine Translation, nothing prevents building such models on monolingual corpora.", "labels": [], "entities": [{"text": "Machine Translation", "start_pos": 56, "end_pos": 75, "type": "TASK", "confidence": 0.7491387128829956}]}, {"text": "However, in order to build reliable models it is necessary to use enough training material including minimal redundancy of words.", "labels": [], "entities": []}, {"text": "To this end, we will be using monolingual corpora made up of multiply-translated sentences, allowing us to provide GIZA++ with all possible sentence pairs to improve the quality of its word alignments (note that following common practice we used symetrized alignments from the alignments in both directions).", "labels": [], "entities": []}, {"text": "This constitutes an advantage for this technique that the following techniques working on each sentence pair independently do not have.", "labels": [], "entities": []}], "datasetContent": [{"text": "We used the methodology described by  for constructing evaluation corpora and assessing the performance of various techniques on the task of paraphrase acquisition.", "labels": [], "entities": [{"text": "paraphrase acquisition", "start_pos": 141, "end_pos": 163, "type": "TASK", "confidence": 0.894586592912674}]}, {"text": "Ina nutshell, pairs of sentential paraphrases are hand-aligned and define a set of reference atomic paraphrase pairs at the level of words or blocks or words, denoted as R atom , and also a set of reference composite paraphrase pairs obtained by joining adjacent atomic paraphrase pairs (up to a given length), denoted as R.", "labels": [], "entities": []}, {"text": "Techniques output word alignments from which atomic candidate paraphrase pairs, denoted as H atom , as well as composite paraphrase pairs, denoted as H, can be extracted.", "labels": [], "entities": []}, {"text": "The usual measures of precision, recall and f-measure can then be defined in the following way: To evaluate our individual techniques and their use by the tunable TER-PLUS technique (henceforth TERP), we measured results on two different corpora in French and English.", "labels": [], "entities": [{"text": "precision", "start_pos": 22, "end_pos": 31, "type": "METRIC", "confidence": 0.9995023012161255}, {"text": "recall", "start_pos": 33, "end_pos": 39, "type": "METRIC", "confidence": 0.9991104006767273}, {"text": "f-measure", "start_pos": 44, "end_pos": 53, "type": "METRIC", "confidence": 0.9669586420059204}, {"text": "TER-PLUS", "start_pos": 163, "end_pos": 171, "type": "METRIC", "confidence": 0.9112854599952698}]}, {"text": "In each case, a heldout development corpus of 150 paraphrase pairs was used for tuning the TERP hybrid systems towards precision (\u2192 p), recall (\u2192 r), or F-measure (\u2192 f 1 ).", "labels": [], "entities": [{"text": "precision", "start_pos": 119, "end_pos": 128, "type": "METRIC", "confidence": 0.9989246726036072}, {"text": "recall", "start_pos": 136, "end_pos": 142, "type": "METRIC", "confidence": 0.9980339407920837}, {"text": "F-measure", "start_pos": 153, "end_pos": 162, "type": "METRIC", "confidence": 0.9895104169845581}]}, {"text": "1 All techniques were evaluated on the same test set consisting of 375 paraphrase pairs.", "labels": [], "entities": []}, {"text": "For English, we used the MTC corpus described in ( , which consists of multiply-translated Chinese sentences into English, with an average lexical overlap 2 of 65.91% (all tokens) and 63.95% (content words only).", "labels": [], "entities": [{"text": "MTC corpus", "start_pos": 25, "end_pos": 35, "type": "DATASET", "confidence": 0.8991562724113464}]}, {"text": "We used as our reference set both the alignments marked as \"Sure\" and \"Possible\".", "labels": [], "entities": []}, {"text": "For French, we used the CESTA corpus of news articles 3 obtained by translating into French from various languages with an average lexical overlap of 79.63% (all tokens) and 78.19% (content words only).", "labels": [], "entities": [{"text": "CESTA corpus of news articles", "start_pos": 24, "end_pos": 53, "type": "DATASET", "confidence": 0.9623401284217834}]}, {"text": "These Hill climbing was used for tuning as in (, with uniform weights and 100 random restarts.", "labels": [], "entities": []}, {"text": "We compute the percentage of lexical overlap between the vocabularies of two sentences S1 and S2 as : |S1 \u2229 S2|/min(|S1|, |S2|) 3 http://www.elda.org/article125.html", "labels": [], "entities": []}], "tableCaptions": []}