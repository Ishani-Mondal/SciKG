{"title": [{"text": "Clustering Comparable Corpora For Bilingual Lexicon Extraction", "labels": [], "entities": [{"text": "Bilingual Lexicon Extraction", "start_pos": 34, "end_pos": 62, "type": "TASK", "confidence": 0.6036049326260885}]}], "abstractContent": [{"text": "We study in this paper the problem of enhancing the comparability of bilingual corpora in order to improve the quality of bilingual lexicons extracted from comparable corpora.", "labels": [], "entities": []}, {"text": "We introduce a clustering-based approach for enhancing corpus comparability which exploits the homogeneity feature of the corpus, and finally preserves most of the vocabulary of the original corpus.", "labels": [], "entities": []}, {"text": "Our experiments illustrate the well-foundedness of this method and show that the bilingual lexicons obtained from the homogeneous corpus are of better quality than the lexicons obtained with previous approaches .", "labels": [], "entities": []}], "introductionContent": [{"text": "Bilingual lexicons are an important resource in multilingual natural language processing tasks such as statistical machine translation and cross-language information retrieval.", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 103, "end_pos": 134, "type": "TASK", "confidence": 0.7329180836677551}, {"text": "cross-language information retrieval", "start_pos": 139, "end_pos": 175, "type": "TASK", "confidence": 0.7370195190111796}]}, {"text": "Because it is expensive to manually build bilingual lexicons adapted to different domains, researchers have tried to automatically extract bilingual lexicons from various corpora.", "labels": [], "entities": []}, {"text": "Compared with parallel corpora, it is much easier to build high-volume comparable corpora, i.e. corpora consisting of documents in different languages covering overlapping information.", "labels": [], "entities": []}, {"text": "Several studies have focused on the extraction of bilingual lexicons from comparable corpora.", "labels": [], "entities": []}, {"text": "The basic assumption behind most studies on lexicon extraction from comparable corpora is a distributional hypothesis, stating that words which are translation of each other are likely to appear in similar context across languages.", "labels": [], "entities": [{"text": "lexicon extraction from comparable corpora", "start_pos": 44, "end_pos": 86, "type": "TASK", "confidence": 0.848627233505249}]}, {"text": "On top of this hypothesis, researchers have investigated the use of better representations for word contexts, as well as the use of different methods for matching words across languages.", "labels": [], "entities": []}, {"text": "These approaches seem to have reached a plateau in terms of performance.", "labels": [], "entities": []}, {"text": "More recently, and departing from such traditional approaches, we have proposed in an approach based on improving the comparability of the corpus under consideration, prior to extracting bilingual lexicons.", "labels": [], "entities": []}, {"text": "This approach is interesting since there is no point in trying to extract lexicons from a corpus with a low degree of comparability, as the probability of finding translations of any given word is low in such cases.", "labels": [], "entities": []}, {"text": "We follow here the same general idea and aim, in a first step, at improving the comparability of a given corpus while preserving most of its vocabulary.", "labels": [], "entities": []}, {"text": "However, unlike the previous work, we show here that it is possible to guarantee a certain degree of homogeneity for the improved corpus, and that this homogeneity translates into a significant improvement of both the quality of the resulting corpora and the bilingual lexicons extracted.", "labels": [], "entities": []}], "datasetContent": [{"text": "The experiments we have designed in this paper aim at assessing (a) whether the clustering-based algorithm we have introduced yields corpora of higher quality in terms of comparability scores, and (b) whether the bilingual lexicons extracted from such corpora are of higher quality.", "labels": [], "entities": []}, {"text": "Several corpora were used in our experiments: the TREC 1 Associated Press corpus (AP, English) and the corpora used in the CLEF 2 campaign including the Los Angeles Times (LAT94, English), the Glasgow Herald (GH95, English), Le Monde (MON94, French), SDA French 94 (SDA94, French) and SDA French 95 (SDA95, French).", "labels": [], "entities": [{"text": "TREC 1 Associated Press corpus", "start_pos": 50, "end_pos": 80, "type": "DATASET", "confidence": 0.8785987854003906}, {"text": "CLEF 2 campaign including the Los Angeles Times (LAT94", "start_pos": 123, "end_pos": 177, "type": "DATASET", "confidence": 0.7231122583150864}, {"text": "Glasgow Herald (GH95", "start_pos": 193, "end_pos": 213, "type": "DATASET", "confidence": 0.939370796084404}, {"text": "Le Monde (MON94", "start_pos": 225, "end_pos": 240, "type": "DATASET", "confidence": 0.8828489929437637}]}, {"text": "In addition, two monolingual corpora Wiki-En and Wiki-Fr were built by respectively retrieving all the articles below the category Society and Soci\u00e9t\u00e9 from the Wikipedia dump files 3 . The bilingual dictionary used in the experiments is constructed from an online dictionary.", "labels": [], "entities": []}, {"text": "It consists of 33k distinct English words and 28k distinct French words, constituting 76k translation pairs.", "labels": [], "entities": []}, {"text": "In our experiments, we use the method described in this paper, as well as the one in ( which is the only alternative method to enhance corpus comparability.", "labels": [], "entities": []}, {"text": "To extract bilingual lexicons from comparable corpora, we directly use here the method proposed by which has been referred to as the standard approach in more recent studies.", "labels": [], "entities": []}, {"text": "In this approach, each word w is represented as a context vector consisting of the words co-occurring with win a certain window in the corpus.", "labels": [], "entities": []}, {"text": "The context vectors in different languages are then bridged with an existing bilingual dictionary.", "labels": [], "entities": []}, {"text": "Finally, a similarity score is given to any word pair based on the cosine of their respective context vectors.", "labels": [], "entities": [{"text": "similarity score", "start_pos": 11, "end_pos": 27, "type": "METRIC", "confidence": 0.9606362581253052}]}, {"text": "In order to measure the performance of the lexicons extracted, we follow the common practice by dividing the bilingual dictionary into 2 parts: 10% of the English words (3,338 words) together with their translations are randomly chosen and used as the evaluation set, the remaining words being used to compute the similarity of context vectors.", "labels": [], "entities": []}, {"text": "English words not present in P e or with no translation in P fare excluded from the evaluation set.", "labels": [], "entities": []}, {"text": "For each English word in the evaluation set, all the French words in P fare then ranked according to their similarity with the English word.", "labels": [], "entities": []}, {"text": "Precision and recall are then computed on the first N translation candidate lists.", "labels": [], "entities": [{"text": "Precision", "start_pos": 0, "end_pos": 9, "type": "METRIC", "confidence": 0.9881768822669983}, {"text": "recall", "start_pos": 14, "end_pos": 20, "type": "METRIC", "confidence": 0.9988555908203125}]}, {"text": "The precision amounts in this case to the proportion of lists containing the correct translation (in case of multiple translations, a list is deemed to contain the correct translation as soon as one of the possible translations is present).", "labels": [], "entities": [{"text": "precision", "start_pos": 4, "end_pos": 13, "type": "METRIC", "confidence": 0.9992609620094299}]}, {"text": "The recall is the proportion of correct translations found in the lists to all the translations in the corpus.", "labels": [], "entities": [{"text": "recall", "start_pos": 4, "end_pos": 10, "type": "METRIC", "confidence": 0.9994710087776184}]}, {"text": "This evaluation procedure has been used in previous studies and is now standard.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Performance of the bilingual lexicon extraction from different corpora (best results in bold)", "labels": [], "entities": []}]}