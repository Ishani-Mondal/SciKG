{"title": [{"text": "Unsupervised Part-of-Speech Tagging with Bilingual Graph-Based Projections", "labels": [], "entities": [{"text": "Part-of-Speech Tagging", "start_pos": 13, "end_pos": 35, "type": "TASK", "confidence": 0.6736863255500793}]}], "abstractContent": [{"text": "We describe a novel approach for inducing unsupervised part-of-speech taggers for languages that have no labeled training data, but have translated text in a resource-rich language.", "labels": [], "entities": []}, {"text": "Our method does not assume any knowledge about the target language (in particular no tagging dictionary is assumed), making it applicable to a wide array of resource-poor languages.", "labels": [], "entities": []}, {"text": "We use graph-based label propagation for cross-lingual knowledge transfer and use the projected labels as features in an unsupervised model (Berg-Kirkpatrick et al., 2010).", "labels": [], "entities": [{"text": "label propagation", "start_pos": 19, "end_pos": 36, "type": "TASK", "confidence": 0.7778038680553436}, {"text": "cross-lingual knowledge transfer", "start_pos": 41, "end_pos": 73, "type": "TASK", "confidence": 0.6476472218831381}]}, {"text": "Across eight Eu-ropean languages, our approach results in an average absolute improvement of 10.4% over a state-of-the-art baseline, and 16.7% over vanilla hidden Markov models induced with the Expectation Maximization algorithm.", "labels": [], "entities": [{"text": "Expectation Maximization", "start_pos": 194, "end_pos": 218, "type": "TASK", "confidence": 0.8012879490852356}]}], "introductionContent": [{"text": "Supervised learning approaches have advanced the state-of-the-art on a variety of tasks in natural language processing, resulting in highly accurate systems.", "labels": [], "entities": []}, {"text": "Supervised part-of-speech (POS) taggers, for example, approach the level of inter-annotator agreement.3% accuracy for English).", "labels": [], "entities": [{"text": "part-of-speech (POS) taggers", "start_pos": 11, "end_pos": 39, "type": "TASK", "confidence": 0.6478299379348755}, {"text": "accuracy", "start_pos": 105, "end_pos": 113, "type": "METRIC", "confidence": 0.9953925609588623}]}, {"text": "However, supervised methods rely on labeled training data, which is time-consuming and expensive to generate.", "labels": [], "entities": []}, {"text": "Unsupervised learning approaches appear to be a natural solution to this problem, as they require only unannotated text for train- * This research was carried out during an internship at Google Research.", "labels": [], "entities": []}, {"text": "Unfortunately, the best completely unsupervised English POS tagger (that does not make use of a tagging dictionary) reaches only 76.1% accuracy (, making its practical usability questionable at best.", "labels": [], "entities": [{"text": "POS tagger", "start_pos": 56, "end_pos": 66, "type": "TASK", "confidence": 0.552106574177742}, {"text": "accuracy", "start_pos": 135, "end_pos": 143, "type": "METRIC", "confidence": 0.998618483543396}]}, {"text": "To bridge this gap, we consider a practically motivated scenario, in which we want to leverage existing resources from a resource-rich language (like English) when building tools for resource-poor foreign languages.", "labels": [], "entities": []}, {"text": "We assume that absolutely no labeled training data is available for the foreign language of interest, but that we have access to parallel data with a resource-rich language.", "labels": [], "entities": []}, {"text": "This scenario is applicable to a large set of languages and has been considered by a number of authors in the past.  and  study related but different multilingual grammar and tagger induction tasks, where it is assumed that no labeled data at all is available.", "labels": [], "entities": [{"text": "tagger induction", "start_pos": 175, "end_pos": 191, "type": "TASK", "confidence": 0.8936554491519928}]}, {"text": "Our work is closest to that of, but differs in two important ways.", "labels": [], "entities": []}, {"text": "First, we use a novel graph-based framework for projecting syntactic information across language boundaries.", "labels": [], "entities": []}, {"text": "To this end, we construct a bilingual graph over word types to establish a connection between the two languages ( \u00a73), and then use graph label propagation to project syntactic information from English to the foreign language ( \u00a74).", "labels": [], "entities": []}, {"text": "Second, we treat the projected labels as features in an unsuper-vised model ( \u00a75), rather than using them directly for supervised training.", "labels": [], "entities": []}, {"text": "To make the projection practical, we rely on the twelve universal part-of-speech tags of.", "labels": [], "entities": []}, {"text": "Syntactic universals area well studied concept in linguistics, and were recently used in similar form by for multilingual grammar induction.", "labels": [], "entities": [{"text": "multilingual grammar induction", "start_pos": 109, "end_pos": 139, "type": "TASK", "confidence": 0.7598024606704712}]}, {"text": "Because there might be some controversy about the exact definitions of such universals, this set of coarse-grained POS categories is defined operationally, by collapsing language (or treebank) specific distinctions to a set of categories that exists across all languages.", "labels": [], "entities": []}, {"text": "These universal POS categories not only facilitate the transfer of POS information from one language to another, but also relieve us from using controversial evaluation metrics, 2 by establishing a direct correspondence between the induced hidden states in the foreign language and the observed English labels.", "labels": [], "entities": []}, {"text": "We evaluate our approach on eight European languages ( \u00a76), and show that both our contributions provide consistent and statistically significant improvements.", "labels": [], "entities": []}, {"text": "Our final average POS tagging accuracy of 83.4% compares very favorably to the average accuracy of Berg-Kirkpatrick et al.'s monolingual unsupervised state-of-the-art model (73.0%), and considerably bridges the gap to fully supervised POS tagging performance (96.6%).", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 18, "end_pos": 29, "type": "TASK", "confidence": 0.782703697681427}, {"text": "accuracy", "start_pos": 30, "end_pos": 38, "type": "METRIC", "confidence": 0.8979746699333191}, {"text": "accuracy", "start_pos": 87, "end_pos": 95, "type": "METRIC", "confidence": 0.9964144229888916}, {"text": "POS tagging", "start_pos": 235, "end_pos": 246, "type": "TASK", "confidence": 0.8202634453773499}]}], "datasetContent": [{"text": "Before presenting our results, we describe the datasets that we used, as well as two baselines.", "labels": [], "entities": []}, {"text": "We utilized two kinds of datasets in our experiments: (i) monolingual treebanks 9 and (ii) large amounts of parallel text with English on one side.", "labels": [], "entities": []}, {"text": "The availability of these resources guided our selection of foreign languages.", "labels": [], "entities": []}, {"text": "For monolingual treebank data we relied on the CoNLL-X and CoNLL-2007 shared tasks on dependency parsing ().", "labels": [], "entities": [{"text": "CoNLL-X", "start_pos": 47, "end_pos": 54, "type": "DATASET", "confidence": 0.9637928605079651}, {"text": "dependency parsing", "start_pos": 86, "end_pos": 104, "type": "TASK", "confidence": 0.6955780982971191}]}, {"text": "The parallel data came from the Europarl corpus () and the ODS United Nations dataset).", "labels": [], "entities": [{"text": "Europarl corpus", "start_pos": 32, "end_pos": 47, "type": "DATASET", "confidence": 0.9949815571308136}, {"text": "ODS United Nations dataset", "start_pos": 59, "end_pos": 85, "type": "DATASET", "confidence": 0.9541622847318649}]}, {"text": "Taking the intersection of languages in these resources, and selecting languages with large amounts of parallel data, yields the following set of eight Indo-European languages: Danish, Dutch, German, Greek, Italian, Portuguese, Spanish and Swedish.", "labels": [], "entities": []}, {"text": "Of course, we are primarily interested in applying our techniques to languages for which no labeled resources are available.", "labels": [], "entities": []}, {"text": "However, we needed to restrict ourselves to these languages in order to be able to evaluate the performance of our approach.", "labels": [], "entities": []}, {"text": "We paid particular attention to minimize the number of free parameters, and used the same hyperparameters for all language pairs, rather than attempting language-specific tuning.", "labels": [], "entities": []}, {"text": "We hope that this will allow practitioners to apply our approach directly to languages for which no resources are available.", "labels": [], "entities": []}, {"text": "While we tried to minimize the number of free parameters in our model, there area few hyperparameters that need to beset.", "labels": [], "entities": []}, {"text": "Fortunately, performance was stable across various values, and we were able to use the same hyperparameters for all languages.", "labels": [], "entities": []}, {"text": "We used C = 1.0 as the L 2 regularization constant in (Eq.", "labels": [], "entities": []}, {"text": "10) and trained both EM and L-BFGS for 1000 iterations.", "labels": [], "entities": [{"text": "EM", "start_pos": 21, "end_pos": 23, "type": "DATASET", "confidence": 0.7935090065002441}]}, {"text": "When extracting the vector: Part-of-speech tagging accuracies for various baselines and oracles, as well as our approach.", "labels": [], "entities": [{"text": "Part-of-speech tagging", "start_pos": 28, "end_pos": 50, "type": "TASK", "confidence": 0.6424702852964401}]}, {"text": "\"Avg\" denotes macro-average across the eight languages.", "labels": [], "entities": [{"text": "Avg", "start_pos": 1, "end_pos": 4, "type": "METRIC", "confidence": 0.9622750878334045}]}, {"text": "t x used to compute the constraint feature from the graph, we tried three threshold values for \u03c4 (see Eq. 7).", "labels": [], "entities": []}, {"text": "Because we don't have a separate development set, we used the training set to select among them and found 0.2 to work slightly better than 0.1 and 0.3.", "labels": [], "entities": []}, {"text": "For seven out of eight languages a threshold of 0.2 gave the best results for our final model, which indicates that for languages without any validation set, \u03c4 = 0.2 can be used.", "labels": [], "entities": []}, {"text": "For graph propagation, the hyperparameter \u03bd was set to 2 \u00d7 10 \u22126 and was not tuned.", "labels": [], "entities": [{"text": "graph propagation", "start_pos": 4, "end_pos": 21, "type": "TASK", "confidence": 0.7298185378313065}]}, {"text": "The graph was constructed using 2 million trigrams; we chose these by truncating the parallel datasets up to the number of sentence pairs that contained 2 million trigrams.", "labels": [], "entities": []}, {"text": "shows our complete set of results.", "labels": [], "entities": []}, {"text": "As expected, the vanilla HMM trained with EM performs the worst.", "labels": [], "entities": []}, {"text": "The feature-HMM model works better for all languages, generalizing the results achieved for English by.", "labels": [], "entities": []}, {"text": "Our \"Projection\" baseline is able to benefit from the bilingual information and greatly improves upon the monolingual baselines, but falls short of the \"No LP\" model by 2.5% on an average.", "labels": [], "entities": []}, {"text": "The \"No LP\" model does not outperform direct projection for German and Greek, but performs better for six out of eight languages.", "labels": [], "entities": []}, {"text": "Overall, it gives improvements ranging from 1.1% for German to 14.7% for Italian, for an average improvement of 8.3% over the unsupervised feature-HMM model.", "labels": [], "entities": []}, {"text": "For comparison, the completely unsupervised feature-HMM baseline accuracy on the universal POS tags for English is 79.4%, and goes up to 88.7% with a treebank dictionary.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 65, "end_pos": 73, "type": "METRIC", "confidence": 0.8438330292701721}]}, {"text": "Our full model (\"With LP\") outperforms the unsupervised baselines and the \"No LP\" setting for all languages.", "labels": [], "entities": []}, {"text": "It falls short of the \"Projection\" baseline for German, but is statistically indistinguishable in terms of accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 107, "end_pos": 115, "type": "METRIC", "confidence": 0.9980485439300537}]}, {"text": "As indicated by bolding, for seven out of eight languages the improvements of the \"With LP\" setting are statistically significant with respect to the other models, including the \"No LP\" setting.", "labels": [], "entities": []}, {"text": "11 Overall, it performs 10.4% better than the hitherto state-of-the-art feature-HMM baseline, and 4.6% better than direct projection, when we macro-average the accuracy overall languages.", "labels": [], "entities": [{"text": "direct projection", "start_pos": 115, "end_pos": 132, "type": "TASK", "confidence": 0.6897425800561905}, {"text": "accuracy", "start_pos": 160, "end_pos": 168, "type": "METRIC", "confidence": 0.9988552331924438}]}], "tableCaptions": [{"text": " Table 2: Part-of-speech tagging accuracies for various baselines and oracles, as well as our approach. \"Avg\" denotes  macro-average across the eight languages.", "labels": [], "entities": [{"text": "Part-of-speech tagging", "start_pos": 10, "end_pos": 32, "type": "TASK", "confidence": 0.728994756937027}, {"text": "Avg", "start_pos": 105, "end_pos": 108, "type": "METRIC", "confidence": 0.9487795829772949}]}, {"text": " Table 3: Size of the vocabularies for the \"No LP\" and  \"With LP\" models for which we can impose constraints.", "labels": [], "entities": []}]}