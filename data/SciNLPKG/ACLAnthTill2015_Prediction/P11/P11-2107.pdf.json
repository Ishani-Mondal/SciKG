{"title": [{"text": "Predicting Relative Prominence in Noun-Noun Compounds", "labels": [], "entities": [{"text": "Predicting Relative Prominence", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.9179372588793436}]}], "abstractContent": [{"text": "There are several theories regarding what influences prominence assignment in English noun-noun compounds.", "labels": [], "entities": [{"text": "prominence assignment", "start_pos": 53, "end_pos": 74, "type": "TASK", "confidence": 0.7170456796884537}]}, {"text": "We have developed corpus-driven models for automatically predicting prominence assignment in noun-noun compounds using feature sets based on two such theories: the informativeness theory and the semantic composition theory.", "labels": [], "entities": [{"text": "predicting prominence assignment", "start_pos": 57, "end_pos": 89, "type": "TASK", "confidence": 0.7790377537409464}]}, {"text": "The evaluation of the prediction models indicate that though both of these theories are relevant, they account for different types of variability in prominence assignment.", "labels": [], "entities": [{"text": "prominence assignment", "start_pos": 149, "end_pos": 170, "type": "TASK", "confidence": 0.7219726890325546}]}], "introductionContent": [{"text": "Text-to-speech synthesis (TTS) systems stand to gain in improved intelligibility and naturalness if we have good control of the prosody.", "labels": [], "entities": [{"text": "Text-to-speech synthesis (TTS)", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.8024321973323822}]}, {"text": "Typically, prosodic labels are predicted through text analysis and are used to control the acoustic parameters fora TTS system.", "labels": [], "entities": [{"text": "TTS", "start_pos": 116, "end_pos": 119, "type": "TASK", "confidence": 0.8777377605438232}]}, {"text": "An important aspect of prosody prediction is predicting which words should be prosodically prominent, i.e., produced with greater energy, higher pitch, and/or longer duration than the neighboring words, in order to indicate the former's greater communicative salience.", "labels": [], "entities": [{"text": "prosody prediction", "start_pos": 23, "end_pos": 41, "type": "TASK", "confidence": 0.9319864809513092}]}, {"text": "Appropriate prominence assignment is crucial for listeners' understanding of the intended message.", "labels": [], "entities": []}, {"text": "However, the immense prosodic variability found in spoken language makes prominence prediction a challenging problem.", "labels": [], "entities": [{"text": "prominence prediction", "start_pos": 73, "end_pos": 94, "type": "TASK", "confidence": 0.9322639405727386}]}, {"text": "A particular sub-problem of prominence prediction that still defies a complete solution is prediction of relative prominence in noun-noun compounds.", "labels": [], "entities": [{"text": "prominence prediction", "start_pos": 28, "end_pos": 49, "type": "TASK", "confidence": 0.7023930698633194}, {"text": "prediction of relative prominence in noun-noun compounds", "start_pos": 91, "end_pos": 147, "type": "TASK", "confidence": 0.7663516317095075}]}, {"text": "Noun-noun compounds such as White House, cherry pie, parking lot, Madison Avenue, Wall Street, nail polish, french fries, computer programmer, dogcatcher, silk tie, and self reliance, occur quite frequently in the English language.", "labels": [], "entities": []}, {"text": "Ina discourse neutral context, such constructions usually have leftmost prominence, i.e., speakers produce the left-hand noun with greater prominence than the right-hand noun.", "labels": [], "entities": []}, {"text": "However, a significant portionabout 25% -of them are assigned rightmost prominence (such as cherry pie, Madison Avenue, silk tie, computer programmer, and self reliance from the list above).", "labels": [], "entities": []}, {"text": "What factors influence speakers' decision to assign left or right prominence is still an open question.", "labels": [], "entities": []}, {"text": "There are several different theories about relative prominence assignment in noun-noun (henceforth, NN) compounds, such as the structural theory, the analogical theory), the semantic theory and the informativeness theory.", "labels": [], "entities": [{"text": "relative prominence assignment in noun-noun (henceforth, NN) compounds", "start_pos": 43, "end_pos": 113, "type": "TASK", "confidence": 0.7551865794441917}]}, {"text": "However, inmost studies, the different theories are examined and applied in isolation, thus making it difficult to compare them directly.", "labels": [], "entities": []}, {"text": "It would be informative and illuminating to apply these theories to the same task and the same dataset.", "labels": [], "entities": []}, {"text": "For this paper, we focus on two particular theories, the informativeness theory and the semantic composition theory.", "labels": [], "entities": []}, {"text": "The informativeness theory posits that the relatively more informative and unexpected noun is given greater prominence in the NN compound than the less informative and more predictable noun.", "labels": [], "entities": []}, {"text": "The semantic composition theory posits that relative prominence assignment in NN compounds is decided according to the semantic relationship between the two nouns.", "labels": [], "entities": [{"text": "relative prominence assignment", "start_pos": 44, "end_pos": 74, "type": "TASK", "confidence": 0.6139690975348154}]}, {"text": "We apply these two theories to the task of predicting relative prominence in NN compounds via statistical corpus-driven methods, within the larger context of building a system that can predict appropriate prominence patterns for text-to-speech synthesis.", "labels": [], "entities": [{"text": "predicting relative prominence", "start_pos": 43, "end_pos": 73, "type": "TASK", "confidence": 0.7771550019582113}, {"text": "text-to-speech synthesis", "start_pos": 229, "end_pos": 253, "type": "TASK", "confidence": 0.7042568027973175}]}, {"text": "Here we are only focusing on predicting relative prominence of NN compounds in a neutral context, where there are no pragmatic reasons (such as contrastiveness or given/new distinction) for shifting prominence.", "labels": [], "entities": []}], "datasetContent": [{"text": "For our evaluation, we used a hand-labeled corpus of 7831 NN compounds randomly selected from the 1990 Associated Press newswire, and hand-tagged for leftmost or rightmost prominence.", "labels": [], "entities": [{"text": "1990 Associated Press newswire", "start_pos": 98, "end_pos": 128, "type": "DATASET", "confidence": 0.8010885119438171}]}, {"text": "This corpus contains 64 pairs of NN compounds that differ in terms of capitalization but not in terms of relative prominence assignment.", "labels": [], "entities": []}, {"text": "It only contains four pairs of NN compounds that differ in terms of capitalization and in terms of relative prominence assignment.", "labels": [], "entities": []}, {"text": "Since there is not enough data in this corpus to consider capitalization as a feature, we removed the case information (by lowercasing the entire corpora), and removed any duplicates.", "labels": [], "entities": []}, {"text": "Of the four pairs that differed in terms of capitalization, we only retained the lower-cased NN compounds.", "labels": [], "entities": []}, {"text": "By normalizing Sproat's hand-labeled corpus in this way, we created a slightly smaller corpus 7767 utterances that was used for the evaluation.", "labels": [], "entities": [{"text": "Sproat's hand-labeled corpus", "start_pos": 15, "end_pos": 43, "type": "DATASET", "confidence": 0.8375320285558701}]}, {"text": "For each of the NN compounds in this corpus, we computed the three aforementioned feature sets.", "labels": [], "entities": []}, {"text": "To compute the informativeness features, we used the LDC English Gigaword corpus.", "labels": [], "entities": [{"text": "LDC English Gigaword corpus", "start_pos": 53, "end_pos": 80, "type": "DATASET", "confidence": 0.9534328579902649}]}, {"text": "The semantic category vectors and the semantic informativeness features were obtained from Wordnet.", "labels": [], "entities": [{"text": "Wordnet", "start_pos": 91, "end_pos": 98, "type": "DATASET", "confidence": 0.9797850251197815}]}, {"text": "Using each of the three feature sets individually as well as combined together, we built automatic relative prominence prediction models using Boostexter, a discriminative classification model based on the boosting family of algorithms, which was first proposed in.", "labels": [], "entities": [{"text": "relative prominence prediction", "start_pos": 99, "end_pos": 129, "type": "TASK", "confidence": 0.6538717051347097}, {"text": "Boostexter", "start_pos": 143, "end_pos": 153, "type": "DATASET", "confidence": 0.7807154059410095}]}, {"text": "Following an experimental methodology similar to, we used 88% (6835 samples) of the corpus as training data and the remaining 12% (932 samples) as test data.", "labels": [], "entities": []}, {"text": "For each test case, the output of the prediction models was either a 0 (indicating that the leftmost noun receive higher prominence) or a 1 (indicating that the rightmost noun receive higher prominence).", "labels": [], "entities": []}, {"text": "We estimated the model error of the different prediction models by computing the relative error reduction from the baseline error.", "labels": [], "entities": []}, {"text": "The baseline error was obtained by assigning the majority class to all test cases.", "labels": [], "entities": [{"text": "baseline error", "start_pos": 4, "end_pos": 18, "type": "METRIC", "confidence": 0.8964536488056183}]}, {"text": "We avoided overfitting by using 5-fold cross validation.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Results of prediction models", "labels": [], "entities": []}, {"text": " Table 2: Results of lexically-enhanced prediction models", "labels": [], "entities": []}]}