{"title": [{"text": "From Bilingual Dictionaries to Interlingual Document Representations", "labels": [], "entities": [{"text": "Interlingual Document Representations", "start_pos": 31, "end_pos": 68, "type": "TASK", "confidence": 0.7773660024007162}]}], "abstractContent": [{"text": "Mapping documents into an interlingual representation can help bridge the language barrier of a cross-lingual corpus.", "labels": [], "entities": []}, {"text": "Previous approaches use aligned documents as training data to learn an interlingual representation, making them sensitive to the domain of the training data.", "labels": [], "entities": []}, {"text": "In this paper, we learn an in-terlingual representation in an unsupervised manner using only a bilingual dictionary.", "labels": [], "entities": []}, {"text": "We first use the bilingual dictionary to find candidate document alignments and then use them to find an interlingual representation.", "labels": [], "entities": []}, {"text": "Since the candidate alignments are noisy, we develop a robust learning algorithm to learn the interlingual representation.", "labels": [], "entities": []}, {"text": "We show that bilingual dictionaries generalize to different domains better: our approach gives better performance than either a word byword translation method or Canonical Correlation Analysis (CCA) trained on a different domain.", "labels": [], "entities": [{"text": "bilingual dictionaries generalize", "start_pos": 13, "end_pos": 46, "type": "TASK", "confidence": 0.6801679531733195}, {"text": "word byword translation", "start_pos": 128, "end_pos": 151, "type": "TASK", "confidence": 0.6754647890726725}]}], "introductionContent": [{"text": "The growth of text corpora in different languages poses an inherent problem of aligning documents across languages.", "labels": [], "entities": []}, {"text": "Obtaining an explicit alignment, or a different way of bridging the language barrier, is an important step in many natural language processing (NLP) applications such as: document retrieval (), Transliteration Mining ( and Multilingual Web Search (.", "labels": [], "entities": [{"text": "document retrieval", "start_pos": 171, "end_pos": 189, "type": "TASK", "confidence": 0.783326268196106}, {"text": "Transliteration Mining", "start_pos": 194, "end_pos": 216, "type": "TASK", "confidence": 0.9093672931194305}]}, {"text": "Aligning documents from different languages arises in all the above mentioned problems.", "labels": [], "entities": []}, {"text": "In this paper, we address this problem by mapping documents into a common subspace (interlingual representation) . This common subspace generalizes the notion of vector space model for cross-lingual applications.", "labels": [], "entities": []}, {"text": "There are two major approaches for solving the document alignment problem, depending on the available resources.", "labels": [], "entities": [{"text": "document alignment problem", "start_pos": 47, "end_pos": 73, "type": "TASK", "confidence": 0.8336588939030966}]}, {"text": "The first approach, which is widely used in the Cross-lingual Information Retrieval (CLIR) literature, uses bilingual dictionaries to translate documents from one language (source) into another (target) language ().", "labels": [], "entities": [{"text": "Cross-lingual Information Retrieval (CLIR)", "start_pos": 48, "end_pos": 90, "type": "TASK", "confidence": 0.7484513769547144}]}, {"text": "Then standard measures such as cosine similarity are used to identify target language documents that are close to the translated document.", "labels": [], "entities": [{"text": "cosine similarity", "start_pos": 31, "end_pos": 48, "type": "METRIC", "confidence": 0.6330564320087433}]}, {"text": "The second approach is to use training data of aligned document pairs to find a common subspace such that the aligned document pairs are maximally correlated . Both kinds of approaches have their own strengths and weaknesses.", "labels": [], "entities": []}, {"text": "Dictionary based approaches treat source documents independently, i.e., each source language document is translated independently of other documents.", "labels": [], "entities": []}, {"text": "Moreover, after translation, the relationship of a given source document with the rest of the source documents is ignored.", "labels": [], "entities": []}, {"text": "On the other hand, supervised approaches use all the source and target language documents to infer an interlingual representation, but their strong dependency on the training data prevents them from generalizing well to test documents from a different domain.", "labels": [], "entities": []}, {"text": "In this paper, we propose a technique that combines the advantages of both these approaches.", "labels": [], "entities": []}, {"text": "At abroad level, our approach uses bilingual dictionaries to identify initial noisy document alignments (Sec.", "labels": [], "entities": [{"text": "identify initial noisy document alignments", "start_pos": 61, "end_pos": 103, "type": "TASK", "confidence": 0.6025624752044678}]}, {"text": "2.1) and then uses these noisy alignments as training data to learn a common subspace.", "labels": [], "entities": []}, {"text": "Since the alignments are noisy, we need a learning algorithm that is robust to the errors in the training data.", "labels": [], "entities": []}, {"text": "It is known that techniques like CCA overfit the training data).", "labels": [], "entities": []}, {"text": "So, we start with an unsupervised approach such as Kernelized Sorting () and develop a supervised variant of it (Sec. 2.2).", "labels": [], "entities": []}, {"text": "Our supervised variant learns to modify the within language document similarities according to the given alignments.", "labels": [], "entities": []}, {"text": "Since the original algorithm is unsupervised, we hope that its supervised variant is tolerant to errors in the candidate alignments.", "labels": [], "entities": []}, {"text": "The primary advantage of our method is that, it does not use any training data and thus generalizes to test documents from different domains.", "labels": [], "entities": []}, {"text": "And unlike the dictionary based approaches, we use all the documents in computing the common subspace and thus achieve better accuracies compared to the approaches which translate documents in isolation.", "labels": [], "entities": [{"text": "accuracies", "start_pos": 126, "end_pos": 136, "type": "METRIC", "confidence": 0.9698362350463867}]}, {"text": "There are two main contributions of this work.", "labels": [], "entities": []}, {"text": "First, we propose a discriminative technique to learn an interlingual representation using only a bilingual dictionary.", "labels": [], "entities": []}, {"text": "Second, we develop a supervised variant of Kernelized Sorting algorithm () which learns to modify within language document similarities according to a given alignment.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Accuracy of different approaches on the  Wikipedia documents in English-Spanish and English- German language pairs. For CCA, we regularize the  within language covariance matrices as (1\u2212\u03bb)XX T +\u03bbI  and the regularization parameter \u03bb value is also shown.", "labels": [], "entities": []}]}