{"title": [{"text": "Better Hypothesis Testing for Statistical Machine Translation: Controlling for Optimizer Instability", "labels": [], "entities": [{"text": "Statistical Machine Translation", "start_pos": 30, "end_pos": 61, "type": "TASK", "confidence": 0.8040031989415487}]}], "abstractContent": [{"text": "In statistical machine translation, a researcher seeks to determine whether some innovation (e.g., anew feature, model, or inference algorithm) improves translation quality in comparison to a baseline system.", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 3, "end_pos": 34, "type": "TASK", "confidence": 0.6627804239590963}]}, {"text": "To answer this question, he runs an experiment to evaluate the behavior of the two systems on held-out data.", "labels": [], "entities": []}, {"text": "In this paper, we consider how to make such experiments more statistically reliable.", "labels": [], "entities": []}, {"text": "We provide a systematic analysis of the effects of optimizer instability-an extraneous variable that is seldom controlled for-on experimental outcomes, and make recommendations for reporting results more accurately.", "labels": [], "entities": []}], "introductionContent": [{"text": "The need for statistical hypothesis testing for machine translation (MT) has been acknowledged since at least.", "labels": [], "entities": [{"text": "machine translation (MT)", "start_pos": 48, "end_pos": 72, "type": "TASK", "confidence": 0.8258367061614991}]}, {"text": "In that work, the proposed method was based on bootstrap resampling and was designed to improve the statistical reliability of results by controlling for randomness across test sets.", "labels": [], "entities": []}, {"text": "However, there is no consistently used strategy that controls for the effects of unstable estimates of model parameters.", "labels": [], "entities": []}, {"text": "While the existence of optimizer instability is an acknowledged problem, it is only infrequently discussed in relation to the reliability of experimental results, and, to our knowledge, there has yet to be a systematic study of its effects on hypothesis testing.", "labels": [], "entities": []}, {"text": "In this paper, we present a series of experiments demonstrating that optimizer instability can account for substantial amount of variation in translation quality, 2 which, if not controlled for, could lead to incorrect conclusions.", "labels": [], "entities": []}, {"text": "We then show that it is possible to control for this variable with a high degree of confidence with only a few replications of the experiment and conclude by suggesting new best practices for significance testing for machine translation.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 217, "end_pos": 236, "type": "TASK", "confidence": 0.8139666318893433}]}], "datasetContent": [{"text": "In our experiments, we ran the MERT optimizer to optimize BLEU on a held-out development set many times to obtain a set of optimizer samples on two different pairs of systems (4 configurations total).", "labels": [], "entities": [{"text": "BLEU", "start_pos": 58, "end_pos": 62, "type": "METRIC", "confidence": 0.9927379488945007}]}, {"text": "Each pair consists of a baseline system (System A) and an \"experimental\" system (System B), which previous research has suggested will perform better.", "labels": [], "entities": []}, {"text": "The first system pair contrasts a baseline phrasebased system (Moses) and experimental hierarchical phrase-based system (Hiero), which were constructed from the Chinese-English BTEC corpus (0.7M words), the later of which was decoded with the cdec decoder ().", "labels": [], "entities": [{"text": "BTEC corpus", "start_pos": 177, "end_pos": 188, "type": "DATASET", "confidence": 0.7794200778007507}]}, {"text": "The second system pair contrasts two German-English Hiero/cdec systems constructed from the WMT11 parallel training data (98M words).", "labels": [], "entities": [{"text": "WMT11 parallel training data", "start_pos": 92, "end_pos": 120, "type": "DATASET", "confidence": 0.8485977202653885}]}, {"text": "The baseline system was trained on unsegmented words, and the experimental system was constructed using the most probable segmentation of the German text according to the CRF word segmentation model of.", "labels": [], "entities": [{"text": "CRF word segmentation", "start_pos": 171, "end_pos": 192, "type": "TASK", "confidence": 0.7055476705233256}]}, {"text": "The ChineseEnglish systems were optimized 300 times, and the German-English systems were optimized 50 times.", "labels": [], "entities": []}, {"text": "Our experiments used the default implementation of MERT that accompanies each of the two decoders.", "labels": [], "entities": [{"text": "MERT", "start_pos": 51, "end_pos": 55, "type": "METRIC", "confidence": 0.6057583689689636}]}, {"text": "The Moses MERT implementation uses 20 random restart points per iteration, drawn uniformly from the default ranges for each feature, and, at each iteration, 200-best lists were extracted with the current weight vector ().", "labels": [], "entities": []}, {"text": "The cdec MERT implementation performs inference over the decoder search space which is structured as a hypergraph ().", "labels": [], "entities": []}, {"text": "Rather than using restart points, in addition to optimizing each feature independently, it optimizes in 5 random directions per iteration by constructing a search vector by uniformly sampling each element of the vector from (\u22121, 1) and then renormalizing so it has length 1.", "labels": [], "entities": []}, {"text": "For all systems, the initial weight vector was manually initialized so as to yield reasonable translations.", "labels": [], "entities": []}, {"text": "Results are reported using BLEU (), METEOR 5 (Banerjee and, and TER ().", "labels": [], "entities": [{"text": "BLEU", "start_pos": 27, "end_pos": 31, "type": "METRIC", "confidence": 0.9990247488021851}, {"text": "METEOR 5", "start_pos": 36, "end_pos": 44, "type": "METRIC", "confidence": 0.9605898261070251}, {"text": "TER", "start_pos": 64, "end_pos": 67, "type": "METRIC", "confidence": 0.9973486661911011}]}], "tableCaptions": [{"text": " Table 1: Measured standard deviations of different au- tomatic metrics due to test-set and optimizer variability.  s dev is reported only for the tuning objective function  BLEU.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 174, "end_pos": 178, "type": "METRIC", "confidence": 0.9459938406944275}]}, {"text": " Table 2: Two-system analysis: AR p-values for three  different \"single sample\" scenarios that illustrate differ- ent pathological scenarios that can result when the sam- pled weight vectors are \"low\" or \"high.\" For \"random,\"  we simulate an experiments with n optimization replica- tions by drawing n optimized system outputs from our  pool and performing AR; this simulation was repeated  250 times and the 95% CI of the AR p-values is reported.", "labels": [], "entities": [{"text": "CI", "start_pos": 413, "end_pos": 415, "type": "METRIC", "confidence": 0.9898388385772705}]}]}