{"title": [{"text": "HITS-based Seed Selection and Stop List Construction for Bootstrapping", "labels": [], "entities": [{"text": "HITS-based Seed Selection", "start_pos": 0, "end_pos": 25, "type": "TASK", "confidence": 0.7120566566785177}, {"text": "Stop List Construction", "start_pos": 30, "end_pos": 52, "type": "TASK", "confidence": 0.5890904466311137}, {"text": "Bootstrapping", "start_pos": 57, "end_pos": 70, "type": "TASK", "confidence": 0.36487388610839844}]}], "abstractContent": [{"text": "In bootstrapping (seed set expansion), selecting good seeds and creating stop lists are two effective ways to reduce semantic drift, but these methods generally need human supervision.", "labels": [], "entities": [{"text": "seed set expansion)", "start_pos": 18, "end_pos": 37, "type": "TASK", "confidence": 0.8161820620298386}]}, {"text": "In this paper, we propose a graph-based approach to helping editors choose effective seeds and stop list instances, applicable to Pantel and Pennacchiotti's Espresso bootstrapping algorithm.", "labels": [], "entities": []}, {"text": "The idea is to select seeds and create a stop list using the rankings of instances and patterns computed by Klein-berg's HITS algorithm.", "labels": [], "entities": []}, {"text": "Experimental results on a variation of the lexical sample task show the effectiveness of our method.", "labels": [], "entities": []}], "introductionContent": [{"text": "Bootstrapping) is a technique frequently used in natural language processing to expand limited resources with minimal supervision.", "labels": [], "entities": []}, {"text": "Given a small amount of sample data (seeds) representing a particular semantic class of interest, bootstrapping first trains a classifier (which often is a weighted list of surface patterns characterizing the seeds) using the seeds, and then apply it on the remaining data to select instances most likely to be of the same class as the seeds.", "labels": [], "entities": []}, {"text": "These selected instances are added to the seed set, and the process is iterated until sufficient labeled data are acquired.", "labels": [], "entities": []}, {"text": "Many bootstrapping algorithms have been proposed fora variety of tasks: word sense disambiguation), information extraction), named entity recognition, part-of-speech tagging ( , and statistical parsing ().", "labels": [], "entities": [{"text": "word sense disambiguation", "start_pos": 72, "end_pos": 97, "type": "TASK", "confidence": 0.6505014896392822}, {"text": "information extraction", "start_pos": 100, "end_pos": 122, "type": "TASK", "confidence": 0.834674209356308}, {"text": "named entity recognition", "start_pos": 125, "end_pos": 149, "type": "TASK", "confidence": 0.6581366757551829}, {"text": "part-of-speech tagging", "start_pos": 151, "end_pos": 173, "type": "TASK", "confidence": 0.7329447865486145}, {"text": "statistical parsing", "start_pos": 182, "end_pos": 201, "type": "TASK", "confidence": 0.8531819581985474}]}, {"text": "Bootstrapping algorithms, however, are known to suffer from the problem called semantic drift: as the iteration proceeds, the algorithms tend to select instances increasingly irrelevant to the seed instances (.", "labels": [], "entities": []}, {"text": "For example, suppose we want to collect the names of common tourist sites from a web corpus.", "labels": [], "entities": []}, {"text": "Given seed instances {New York City, Maldives Islands}, bootstrapping might learn, atone point of the iteration, patterns like \"pictures of X\" and \"photos of X,\" which also co-occur with many irrelevant instances.", "labels": [], "entities": []}, {"text": "In this case, a later iteration would likely acquire frequent words co-occurring with these generic patterns, such as Michael Jackson.", "labels": [], "entities": []}, {"text": "Previous work has tried to reduce the effect of semantic drift by making the stop list of instances that must not be extracted.", "labels": [], "entities": [{"text": "semantic drift", "start_pos": 48, "end_pos": 62, "type": "TASK", "confidence": 0.7443062365055084}]}, {"text": "Drift can also be reduced with carefully selected seeds.", "labels": [], "entities": []}, {"text": "However, both of these approaches require expert knowledge.", "labels": [], "entities": []}, {"text": "In this paper, we propose a graph-based approach to seed selection and stop list creation for the stateof-the-art bootstrapping algorithm Espresso ().", "labels": [], "entities": [{"text": "seed selection", "start_pos": 52, "end_pos": 66, "type": "TASK", "confidence": 0.7856879532337189}, {"text": "stop list creation", "start_pos": 71, "end_pos": 89, "type": "TASK", "confidence": 0.6546346445878347}]}, {"text": "An advantage of this approach is that it requires zero or minimal supervision.", "labels": [], "entities": []}, {"text": "The idea is to use the hubness score of instances and patterns computed from the pointwise mutual information matrix with the HITS algorithm.", "labels": [], "entities": []}, {"text": "pointed out that semantic drift in Espresso has the same root as topic drift) observed with HITS, noting the algorithmic similarity between them.", "labels": [], "entities": [{"text": "HITS", "start_pos": 92, "end_pos": 96, "type": "DATASET", "confidence": 0.8406972289085388}]}, {"text": "While Komachi et al. proposed to use algorithms different from Espresso to 30 avoid semantic drift, in this paper we take advantage of this similarity to make better use of Espresso.", "labels": [], "entities": []}, {"text": "We demonstrate the effectiveness of our approach on a word sense disambiguation task.", "labels": [], "entities": [{"text": "word sense disambiguation task", "start_pos": 54, "end_pos": 84, "type": "TASK", "confidence": 0.7991032525897026}]}], "datasetContent": [{"text": "We evaluate our methods on a variant of the lexical sample word sense disambiguation task.", "labels": [], "entities": [{"text": "lexical sample word sense disambiguation", "start_pos": 44, "end_pos": 84, "type": "TASK", "confidence": 0.674304461479187}]}, {"text": "In the lexical sample task, a small pre-selected set of a target word is given, along with an inventory of senses for each word.", "labels": [], "entities": []}, {"text": "Each word comes with a number of instances (context sentences) in which the target word occur, and some of these sentences are manually labeled with the correct sense of the target word in each context.", "labels": [], "entities": []}, {"text": "The goal of the task is to classify unlabeled context sentences by the sense of the target word in each context, using the set of labeled sentences.", "labels": [], "entities": []}, {"text": "To apply Espresso for this task, we reformulate the task to be that of seed set expansion, and not classification.", "labels": [], "entities": []}, {"text": "That is, the hand-labeled sentences having the same sense label are used as the seed set, and it is expanded overall the remaining (unlabeled) sentences.", "labels": [], "entities": []}, {"text": "The reason we use the lexical sample task is that every sentence (instance) belongs to one of the predefined senses (classes), and we can expect the most frequent sense in the corpus to form the highest HITS ranking instances.", "labels": [], "entities": []}, {"text": "This allows us to completely automate our experiments, without the need to manually check the HITS ranking in Step 2 of Section 3.2.", "labels": [], "entities": [{"text": "HITS ranking", "start_pos": 94, "end_pos": 106, "type": "METRIC", "confidence": 0.8689447045326233}]}, {"text": "That is, for the most frequent sense (majority sense), we take Step 3a and use the highest ranked instances as seeds; for the rest of the senses (minority senses), we take Step 3b and use them as the stop list.", "labels": [], "entities": []}, {"text": "We used the seven most frequent polysemous nouns (arm, bank, degree, difference, paper, party and shelter) in the SENSEVAL-3 dataset, and line (: Comparison of seed selection for Espresso (\u03c4 = 5, n seed = 7).", "labels": [], "entities": [{"text": "SENSEVAL-3 dataset", "start_pos": 114, "end_pos": 132, "type": "DATASET", "confidence": 0.8209230303764343}, {"text": "Espresso", "start_pos": 179, "end_pos": 187, "type": "DATASET", "confidence": 0.8475668430328369}]}, {"text": "For Random, results are reported as (mean \u00b1 standard deviation).", "labels": [], "entities": [{"text": "mean \u00b1 standard deviation", "start_pos": 37, "end_pos": 62, "type": "METRIC", "confidence": 0.8596895933151245}]}, {"text": "All figures are expressed in percentage terms.", "labels": [], "entities": []}, {"text": "The row labeled \"Avg.\" lists the values macroaveraged over the nine tasks.", "labels": [], "entities": [{"text": "Avg.", "start_pos": 17, "end_pos": 21, "type": "METRIC", "confidence": 0.9389981031417847}]}, {"text": "1994) datasets 1 for our experiments.", "labels": [], "entities": []}, {"text": "We lowercased words in the sentence and pre-processed them with the Porter stemmer to get the stems of words.", "labels": [], "entities": []}, {"text": "Following ( , we used two types of features extracted from neighboring contexts: collocational features and bag-of-words features.", "labels": [], "entities": []}, {"text": "For collocational features, we set a window of three words to the right and left of the target word.", "labels": [], "entities": []}, {"text": "We run Espresso on the above datasets using different seed selection methods (for majority sense of target words), and with or without stop lists created by our method (for minority senses of target words).", "labels": [], "entities": []}, {"text": "We evaluate the performance of the systems according to the following evaluation metrics: mean average precision (MAP), area under the ROC curve (AUC), R-precision, and precision@n (P@n).", "labels": [], "entities": [{"text": "mean average precision (MAP)", "start_pos": 90, "end_pos": 118, "type": "METRIC", "confidence": 0.9357645014921824}, {"text": "ROC curve (AUC)", "start_pos": 135, "end_pos": 150, "type": "METRIC", "confidence": 0.9551997423171997}, {"text": "R-precision", "start_pos": 152, "end_pos": 163, "type": "METRIC", "confidence": 0.9405016899108887}, {"text": "precision", "start_pos": 169, "end_pos": 178, "type": "METRIC", "confidence": 0.9976536631584167}]}, {"text": "The output of Espresso may contain seed instances input to the system, but seeds are excluded from the evaluation.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Comparison of seed selection for Espresso (\u03c4 = 5, n seed = 7). For Random, results are reported as (mean \u00b1  standard deviation). All figures are expressed in percentage terms. The row labeled \"Avg.\" lists the values macro- averaged over the nine tasks.", "labels": [], "entities": [{"text": "Avg.", "start_pos": 203, "end_pos": 207, "type": "METRIC", "confidence": 0.9929973483085632}]}]}