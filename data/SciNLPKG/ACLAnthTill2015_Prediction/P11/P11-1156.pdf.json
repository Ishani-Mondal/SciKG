{"title": [{"text": "Exploiting Web-Derived Selectional Preference to Improve Statistical Dependency Parsing", "labels": [], "entities": [{"text": "Selectional Preference", "start_pos": 23, "end_pos": 45, "type": "TASK", "confidence": 0.7694047689437866}, {"text": "Improve Statistical Dependency Parsing", "start_pos": 49, "end_pos": 87, "type": "TASK", "confidence": 0.748703308403492}]}], "abstractContent": [{"text": "In this paper, we present a novel approach which incorporates the web-derived selec-tional preferences to improve statistical dependency parsing.", "labels": [], "entities": [{"text": "statistical dependency parsing", "start_pos": 114, "end_pos": 144, "type": "TASK", "confidence": 0.6963644127051035}]}, {"text": "Conventional selectional preference learning methods have usually fo-cused on word-to-class relations, e.g., a verb selects as its subject a given nominal class.", "labels": [], "entities": []}, {"text": "This paper extends previous work to word-to-word selectional preferences by using web-scale data.", "labels": [], "entities": [{"text": "word-to-word selectional preferences", "start_pos": 36, "end_pos": 72, "type": "TASK", "confidence": 0.7263482213020325}]}, {"text": "Experiments show that web-scale data improves statistical dependency parsing , particularly for long dependency relationships.", "labels": [], "entities": [{"text": "statistical dependency parsing", "start_pos": 46, "end_pos": 76, "type": "TASK", "confidence": 0.7081586817900339}]}, {"text": "There is no data like more data, performance improves log-linearly with the number of parameters (unique N-grams).", "labels": [], "entities": []}, {"text": "More importantly , when operating on new domains, we show that using web-derived selectional preferences is essential for achieving robust performance .", "labels": [], "entities": []}], "introductionContent": [{"text": "Dependency parsing is the task of building dependency links between words in a sentence, which has recently gained a wide interest in the natural language processing community.", "labels": [], "entities": [{"text": "Dependency parsing", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.8654201924800873}]}, {"text": "With the availability of large-scale annotated corpora such as Penn Treebank (, it is easy to train a high-performance dependency parser using supervised learning methods.", "labels": [], "entities": [{"text": "Penn Treebank", "start_pos": 63, "end_pos": 76, "type": "DATASET", "confidence": 0.994229793548584}]}, {"text": "However, current state-of-the-art statistical dependency parsers) tend to have * Correspondence author: jzhao@nlpr.ia.ac.cn lower accuracies for longer dependencies.", "labels": [], "entities": []}, {"text": "The length of a dependency from word w i to word w j is simply equal to |i \u2212 j|.", "labels": [], "entities": []}, {"text": "Longer dependencies typically represent the modifier of the root or the main verb, internal dependencies of longer NPs or PP-attachment in a sentence.", "labels": [], "entities": []}, {"text": "shows the F 1 score 1 relative to the dependency length on the development set by using the graph-based dependency parsers).", "labels": [], "entities": [{"text": "F 1 score 1", "start_pos": 10, "end_pos": 21, "type": "METRIC", "confidence": 0.9734087288379669}]}, {"text": "We note that the parsers provide very good results for adjacent dependencies (96.89% for dependency length =1), while the dependency length increases, the accuracies degrade sharply.", "labels": [], "entities": []}, {"text": "These longer dependencies are therefore a major opportunity to improve the overall performance of dependency parsing.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 98, "end_pos": 116, "type": "TASK", "confidence": 0.8360236883163452}]}, {"text": "Usually, these longer dependencies can be parsed dependent on the specific words involved due to the limited range of features (e.g., a verb and its modifiers).", "labels": [], "entities": []}, {"text": "Lexical statistics are therefore needed for resolving ambiguous relationships, yet the lexicalized statistics are sparse and difficult to estimate directly.", "labels": [], "entities": []}, {"text": "To solve this problem, some information with different granularity has been investigated.", "labels": [], "entities": []}, {"text": "proposed a semi-supervised dependency parsing by introducing lexical intermediaries at a coarser level than words themselves via a cluster method.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 27, "end_pos": 45, "type": "TASK", "confidence": 0.7014285922050476}]}, {"text": "This approach, however, ignores the selectional preference for word-to-word interactions, such as head-modifier relationship.", "labels": [], "entities": []}, {"text": "Extra resources beyond the annotated corpora are needed to capture the bi-lexical relationship at the word-to-word level.", "labels": [], "entities": []}, {"text": "Our purpose in this paper is to exploit webderived selectional preferences to improve the supervised statistical dependency parsing.", "labels": [], "entities": [{"text": "statistical dependency parsing", "start_pos": 101, "end_pos": 131, "type": "TASK", "confidence": 0.5777106483777364}]}, {"text": "All of our lexical statistics are derived from two kinds of webscale corpus: one is the web, which is the largest data set that is available for NLP.", "labels": [], "entities": []}, {"text": "Another is a web-scale N-gram corpus, which is a N-gram corpus with N-grams of length 1-5 (), we call it Google V1 in this paper.", "labels": [], "entities": []}, {"text": "The idea is very simple: web-scale data have large coverage for word pair acquisition.", "labels": [], "entities": [{"text": "word pair acquisition", "start_pos": 64, "end_pos": 85, "type": "TASK", "confidence": 0.7851577202479044}]}, {"text": "By leveraging some assistant data, the dependency parsing model can directly utilize the additional information to capture the word-to-word level relationships.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 39, "end_pos": 57, "type": "TASK", "confidence": 0.7770423293113708}]}, {"text": "We address two natural and related questions which some previous studies leave open: Question I: Is there a benefit in incorporating web-derived selectional preference features for statistical dependency parsing, especially for longer dependencies?", "labels": [], "entities": [{"text": "statistical dependency parsing", "start_pos": 181, "end_pos": 211, "type": "TASK", "confidence": 0.6789452036221822}]}, {"text": "Question II: How well do web-derived selectional preferences perform on new domains?", "labels": [], "entities": []}, {"text": "For Question I, we systematically assess the value of using web-scale data in state-of-the-art supervised dependency parsers.", "labels": [], "entities": []}, {"text": "We compare dependency parsers that include or exclude selectional preference features obtained from web-scale corpus.", "labels": [], "entities": []}, {"text": "To the best of our knowledge, none of the existing studies directly address long dependencies of dependency parsing by using web-scale data.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 97, "end_pos": 115, "type": "TASK", "confidence": 0.737598717212677}]}, {"text": "Most statistical parsers are highly domain dependent.", "labels": [], "entities": []}, {"text": "For example, the parsers trained on WSJ text perform poorly on Brown corpus.", "labels": [], "entities": [{"text": "WSJ text", "start_pos": 36, "end_pos": 44, "type": "DATASET", "confidence": 0.8060864508152008}, {"text": "Brown corpus", "start_pos": 63, "end_pos": 75, "type": "DATASET", "confidence": 0.9792710840702057}]}, {"text": "Some studies have investigated domain adaptation for parsers).", "labels": [], "entities": [{"text": "domain adaptation", "start_pos": 31, "end_pos": 48, "type": "TASK", "confidence": 0.736685037612915}]}, {"text": "These approaches assume that the parsers know which domain it is used, and that it has access to representative data in that domain.", "labels": [], "entities": []}, {"text": "However, in practice, these assumptions are unrealistic in many real applications, such as when processing the heterogeneous genre of web texts.", "labels": [], "entities": []}, {"text": "In this paper we incorporate the web-derived selectional preference features to design our parsers for robust opendomain testing.", "labels": [], "entities": []}, {"text": "We conduct the experiments on the English Penn Treebank (PTB)).", "labels": [], "entities": [{"text": "English Penn Treebank (PTB))", "start_pos": 34, "end_pos": 62, "type": "DATASET", "confidence": 0.9602838059266409}]}, {"text": "The results show that web-derived selectional preference can improve the statistical dependency parsing, particularly for long dependency relationships.", "labels": [], "entities": [{"text": "statistical dependency parsing", "start_pos": 73, "end_pos": 103, "type": "TASK", "confidence": 0.6363752583662668}]}, {"text": "More importantly, when operating on new domains, the webderived selectional preference features show great potential for achieving robust performance (Section 4.3).", "labels": [], "entities": []}, {"text": "The remainder of this paper is divided as follows.", "labels": [], "entities": []}, {"text": "Section 2 gives a brief introduction of dependency parsing.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 40, "end_pos": 58, "type": "TASK", "confidence": 0.9156285226345062}]}, {"text": "Section 3 describes the web-derived selectional preference features.", "labels": [], "entities": []}, {"text": "Experimental evaluation and results are reported in Section 4.", "labels": [], "entities": []}, {"text": "Finally, we discuss related work and draw conclusion in Section 5 and Section 6, respectively.", "labels": [], "entities": []}], "datasetContent": [{"text": "In order to evaluate the effectiveness of our proposed approach, we conducted dependency parsing experiments in English.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 78, "end_pos": 96, "type": "TASK", "confidence": 0.839253306388855}]}, {"text": "The experiments were performed on the Penn Treebank (PTB) (, using a standard set of head-selection rules to convert the phrase structure syntax of the Treebank into a dependency tree representation, dependency labels were obtained via the \"Malt\" hard-coded setting.", "labels": [], "entities": [{"text": "Penn Treebank (PTB)", "start_pos": 38, "end_pos": 57, "type": "DATASET", "confidence": 0.9782022953033447}]}, {"text": "We split the Treebank into a training set (Sections 2-21), a development set (Section 22), and several test sets (Sections 0, 9 1, 23, and 24).", "labels": [], "entities": []}, {"text": "The part-of-speech tags for the development and test set were automatically assigned by the MXPOST tagger 10 , where the tagger was trained on the entire training corpus.", "labels": [], "entities": [{"text": "MXPOST tagger 10", "start_pos": 92, "end_pos": 108, "type": "DATASET", "confidence": 0.8029275139172872}]}, {"text": "Web page hits for word pairs and trigrams are obtained using a simple heuristic query to the search engine Google.", "labels": [], "entities": []}, {"text": "11 Inflected queries are performed by expanding a bigram or trigram into all its morphological forms.", "labels": [], "entities": []}, {"text": "These forms are then submitted as literal queries, and the resulting hits are summed up.", "labels": [], "entities": []}, {"text": "John Carroll's suite of morphological tools 12 is used to generate inflected forms of verbs and nouns.", "labels": [], "entities": []}, {"text": "All the search terms are performed as exact matches by using quotation marks and submitted to the search engines in lowercase.", "labels": [], "entities": []}, {"text": "We measured the performance of the parsers using the following metrics: unlabeled attachment score (UAS), labeled attachment score (LAS) and complete match (CM), which were defined by.", "labels": [], "entities": [{"text": "unlabeled attachment score (UAS)", "start_pos": 72, "end_pos": 104, "type": "METRIC", "confidence": 0.8319467455148697}, {"text": "labeled attachment score (LAS)", "start_pos": 106, "end_pos": 136, "type": "METRIC", "confidence": 0.8415192464987437}, {"text": "complete match (CM)", "start_pos": 141, "end_pos": 160, "type": "METRIC", "confidence": 0.9247645020484925}]}, {"text": "All the metrics are calculated as mean scores per word, and punctuation tokens are consistently excluded.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 3: Unlabeled accuracies (UAS) and labeled accuracies (LAS) on Section 0, 1, 23, 24. Abbreviation:  dep1/dep2=first-order parser and second-order parser with the baseline features; +hits=N-gram features derived from  the Google hits; +V1=N-gram features derived from the Google V1; suffix-L=labeled parser. Unlabeled parsers are  scored using unlabeled parent predictions, and labeled parsers are scored using labeled parent predictions.", "labels": [], "entities": [{"text": "labeled accuracies (LAS)", "start_pos": 41, "end_pos": 65, "type": "METRIC", "confidence": 0.7614962458610535}, {"text": "Section 0", "start_pos": 69, "end_pos": 78, "type": "DATASET", "confidence": 0.9321063160896301}, {"text": "Abbreviation", "start_pos": 91, "end_pos": 103, "type": "METRIC", "confidence": 0.9791864156723022}]}, {"text": " Table 4: Comparison of our final results with other best- performing systems on the whole Section 23. Type  D, C and S denote discriminative, combined and semi- supervised systems, respectively.  \u2020 These papers were  not directly reported the results on this data set, we im- plemented the experiments in this paper.", "labels": [], "entities": []}, {"text": " Table 5: N-gram data, with total number of words in the  original corpus (in billions, B). Following (Brants and  Franz, 2006; Pitler et al., 2010), we set the frequency  threshold to filter the data \u03b8, and total number of unique  N-gram (types) remaining in the data.", "labels": [], "entities": []}]}