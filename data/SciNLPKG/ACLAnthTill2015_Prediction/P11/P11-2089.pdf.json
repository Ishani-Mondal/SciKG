{"title": [{"text": "They Can Help: Using Crowdsourcing to Improve the Evaluation of Grammatical Error Detection Systems", "labels": [], "entities": [{"text": "Evaluation of Grammatical Error Detection", "start_pos": 50, "end_pos": 91, "type": "TASK", "confidence": 0.6732972383499145}]}], "abstractContent": [{"text": "Despite the rising interest in developing grammatical error detection systems for non-native speakers of English, progress in the field has been hampered by alack of informative met-rics and an inability to directly compare the performance of systems developed by different researchers.", "labels": [], "entities": [{"text": "grammatical error detection", "start_pos": 42, "end_pos": 69, "type": "TASK", "confidence": 0.6488604843616486}]}, {"text": "In this paper we address these problems by presenting two evaluation methodologies, both based on a novel use of crowdsourcing.", "labels": [], "entities": []}], "introductionContent": [], "datasetContent": [{"text": "In this section, we provide details on how crowdsourcing can help revamp the evaluation of error detection systems: (a) by providing more informative measures for the intrinsic evaluation of a single system ( \u00a7 4.1), and (b) by easily enabling system comparison ( \u00a7 4.2).", "labels": [], "entities": [{"text": "evaluation of error detection", "start_pos": 77, "end_pos": 106, "type": "TASK", "confidence": 0.6327114775776863}]}, {"text": "When evaluating the performance of grammatical error detection systems against human judgments, the judgments for each instance are generally reduced to the single most frequent category: Error or OK.", "labels": [], "entities": [{"text": "grammatical error detection", "start_pos": 35, "end_pos": 62, "type": "TASK", "confidence": 0.6888924638430277}, {"text": "Error", "start_pos": 188, "end_pos": 193, "type": "METRIC", "confidence": 0.9756220579147339}, {"text": "OK", "start_pos": 197, "end_pos": 199, "type": "METRIC", "confidence": 0.7824212312698364}]}, {"text": "This reduction is not an accurate reflection of a complex phenomenon.", "labels": [], "entities": []}, {"text": "It discards valuable information about the acceptability of usage because it treats all \"bad\" uses as equal (and all good ones as equal), when they are not.", "labels": [], "entities": []}, {"text": "Arguably, it would be fairer to use a continuous scale, such as the proportion of raters who judge an instance as corrector We found 2 duplicate sentences and removed them. incorrect.", "labels": [], "entities": []}, {"text": "For example, if 90% of raters agree on a rating of Error for an instance of preposition usage, then that is stronger evidence that the usage is an error than if 56% of Turkers classified it as Error and 44% classified it as OK (the sentence \"In addition classmates play with some game and enjoy\" is an example).", "labels": [], "entities": [{"text": "Error", "start_pos": 51, "end_pos": 56, "type": "METRIC", "confidence": 0.9795348048210144}]}, {"text": "The regular measures of precision and recall would be fairer if they reflected this reality.", "labels": [], "entities": [{"text": "precision", "start_pos": 24, "end_pos": 33, "type": "METRIC", "confidence": 0.9996660947799683}, {"text": "recall", "start_pos": 38, "end_pos": 44, "type": "METRIC", "confidence": 0.9994402527809143}]}, {"text": "Besides fairness, another reason to use a continuous scale is that of stability, particularly with a small number of instances in the evaluation set (quite common in the field).", "labels": [], "entities": []}, {"text": "By relying on majority judgments, precision and recall measures tend to be unstable (see below).", "labels": [], "entities": [{"text": "precision", "start_pos": 34, "end_pos": 43, "type": "METRIC", "confidence": 0.9994019269943237}, {"text": "recall", "start_pos": 48, "end_pos": 54, "type": "METRIC", "confidence": 0.9990004897117615}]}, {"text": "We modify the measures of precision and recall to incorporate distributions of correctness, obtained via crowdsourcing, in order to make them fairer and more stable indicators of system performance.", "labels": [], "entities": [{"text": "precision", "start_pos": 26, "end_pos": 35, "type": "METRIC", "confidence": 0.9994718432426453}, {"text": "recall", "start_pos": 40, "end_pos": 46, "type": "METRIC", "confidence": 0.9987295269966125}]}, {"text": "Given an error detection system that classifies a sentence containing a specific preposition as Error (class 1) if the preposition is extraneous and OK (class 0) otherwise, we propose the following weighted versions of hits (H w ), misses (M w ) and false positives (FP w ): In the above equations, N is the total number of instances, c i sys is the class (1 or 0) , and pi crowd indicates the proportion of the crowd that classified instance i as Error.", "labels": [], "entities": [{"text": "misses (M w ) and false positives (FP w )", "start_pos": 232, "end_pos": 273, "type": "METRIC", "confidence": 0.7222599138816198}]}, {"text": "Note that if we were to revert to the majority crowd judgment as the sole judgment for each instance, instead of proportions, pi crowd would always be either 1 or 0 and the above formulae would simply compute the normal hits, misses and false positives.", "labels": [], "entities": []}, {"text": "Given these definitions, weighted precision can be defined as Precision w = H w /(H w + FP w ) and weighted recall as Recall w = H w /(H w + M w ).", "labels": [], "entities": [{"text": "precision", "start_pos": 34, "end_pos": 43, "type": "METRIC", "confidence": 0.9713197946548462}, {"text": "Precision", "start_pos": 62, "end_pos": 71, "type": "METRIC", "confidence": 0.9865476489067078}, {"text": "FP", "start_pos": 88, "end_pos": 90, "type": "METRIC", "confidence": 0.945494532585144}, {"text": "recall", "start_pos": 108, "end_pos": 114, "type": "METRIC", "confidence": 0.9935591816902161}, {"text": "Recall", "start_pos": 118, "end_pos": 124, "type": "METRIC", "confidence": 0.9715319275856018}]}, {"text": "To illustrate the utility of these weighted measures, we evaluated the LM and PERC systems on the dataset containing 923 preposition instances, against all 20 Turker judgments.", "labels": [], "entities": [{"text": "PERC", "start_pos": 78, "end_pos": 82, "type": "METRIC", "confidence": 0.909517765045166}]}, {"text": "shows a histogram of the Turker agreement for the majority rating over the set.", "labels": [], "entities": [{"text": "Turker agreement", "start_pos": 25, "end_pos": 41, "type": "DATASET", "confidence": 0.8063324689865112}]}, {"text": "shows both the unweighted (discrete majority judgment) and weighted (continuous Turker proportion) versions of precision and recall for this system.", "labels": [], "entities": [{"text": "precision", "start_pos": 111, "end_pos": 120, "type": "METRIC", "confidence": 0.9995967745780945}, {"text": "recall", "start_pos": 125, "end_pos": 131, "type": "METRIC", "confidence": 0.9991239905357361}]}, {"text": "The numbers clearly show that in the unweighted case, the performance of the system is overestimated simply because the system is getting as much credit for each contentious case (low agreement) as for each clear one (high agreement).", "labels": [], "entities": []}, {"text": "In the weighted measure we propose, the contentious cases are weighted lower and therefore their contribution to the overall performance is reduced.", "labels": [], "entities": []}, {"text": "This is a fairer representation since the system should not be expected to perform as well on the less reliable instances as it does on the clear-cut instances.", "labels": [], "entities": []}, {"text": "Essentially, if humans cannot consistently decide whether  a case is an error then a system's output cannot be considered entirely right or entirely wrong.", "labels": [], "entities": []}, {"text": "As an added advantage, the weighted measures are more stable.", "labels": [], "entities": []}, {"text": "Consider a contentious instance in a small dataset where 7 out of 15 Turkers (a minority) classified it as Error.", "labels": [], "entities": [{"text": "Error", "start_pos": 107, "end_pos": 112, "type": "METRIC", "confidence": 0.9913580417633057}]}, {"text": "However, it might easily have happened that 8 Turkers (a majority) classified it as Error instead of 7.", "labels": [], "entities": [{"text": "Error", "start_pos": 84, "end_pos": 89, "type": "METRIC", "confidence": 0.997328519821167}]}, {"text": "In that case, the change in unweighted precision would have been much larger than is warranted by such a small change in the data.", "labels": [], "entities": [{"text": "precision", "start_pos": 39, "end_pos": 48, "type": "METRIC", "confidence": 0.9594843983650208}]}, {"text": "However, weighted precision is guaranteed to be more stable.", "labels": [], "entities": [{"text": "precision", "start_pos": 18, "end_pos": 27, "type": "METRIC", "confidence": 0.9759138226509094}]}, {"text": "Note that the instability decreases as the size of the dataset increases but still remains a problem.", "labels": [], "entities": [{"text": "instability", "start_pos": 14, "end_pos": 25, "type": "METRIC", "confidence": 0.959494411945343}]}], "tableCaptions": [{"text": " Table 1: Comparing commonly used (unweighted) and  proposed (weighted) precision/recall measures for LM.", "labels": [], "entities": [{"text": "precision", "start_pos": 72, "end_pos": 81, "type": "METRIC", "confidence": 0.9950998425483704}, {"text": "recall", "start_pos": 82, "end_pos": 88, "type": "METRIC", "confidence": 0.9254505634307861}, {"text": "LM", "start_pos": 102, "end_pos": 104, "type": "TASK", "confidence": 0.9629583954811096}]}]}