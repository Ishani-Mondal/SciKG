{"title": [{"text": "An Unsupervised Model for Joint Phrase Alignment and Extraction", "labels": [], "entities": [{"text": "Joint Phrase Alignment and Extraction", "start_pos": 26, "end_pos": 63, "type": "TASK", "confidence": 0.733882212638855}]}], "abstractContent": [{"text": "We present an unsupervised model for joint phrase alignment and extraction using non-parametric Bayesian methods and inversion transduction grammars (ITGs).", "labels": [], "entities": [{"text": "joint phrase alignment and extraction", "start_pos": 37, "end_pos": 74, "type": "TASK", "confidence": 0.6826116681098938}]}, {"text": "The key contribution is that phrases of many granulari-ties are included directly in the model through the use of a novel formulation that memorizes phrases generated not only by terminal, but also non-terminal symbols.", "labels": [], "entities": []}, {"text": "This allows fora completely probabilistic model that is able to create a phrase table that achieves competitive accuracy on phrase-based machine translation tasks directly from unaligned sentence pairs.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 112, "end_pos": 120, "type": "METRIC", "confidence": 0.9741262197494507}, {"text": "phrase-based machine translation tasks", "start_pos": 124, "end_pos": 162, "type": "TASK", "confidence": 0.7002039179205894}]}, {"text": "Experiments on several language pairs demonstrate that the proposed model matches the accuracy of traditional two-step word alignment/phrase extraction approach while reducing the phrase table to a fraction of the original size.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 86, "end_pos": 94, "type": "METRIC", "confidence": 0.9989967942237854}, {"text": "word alignment/phrase extraction", "start_pos": 119, "end_pos": 151, "type": "TASK", "confidence": 0.6820622622966767}]}], "introductionContent": [{"text": "The training of translation models for phrasebased statistical machine translation (SMT) systems () takes unaligned bilingual training data as input, and outputs a scored table of phrase pairs.", "labels": [], "entities": [{"text": "phrasebased statistical machine translation (SMT)", "start_pos": 39, "end_pos": 88, "type": "TASK", "confidence": 0.7558988034725189}]}, {"text": "This phrase table is traditionally generated by going through a pipeline of two steps, first generating word (or minimal phrase) alignments, then extracting a phrase table that is consistent with these alignments.", "labels": [], "entities": []}, {"text": "However, as note, this two step approach results in word alignments that are not optimal for the final task of generating phrase tables that are used in translation.", "labels": [], "entities": [{"text": "word alignments", "start_pos": 52, "end_pos": 67, "type": "TASK", "confidence": 0.7146090418100357}]}, {"text": "As a solution to this, they proposed a supervised discriminative model that performs joint word alignment and phrase extraction, and found that joint estimation of word alignments and extraction sets improves both word alignment accuracy and translation results.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 91, "end_pos": 105, "type": "TASK", "confidence": 0.7197428941726685}, {"text": "phrase extraction", "start_pos": 110, "end_pos": 127, "type": "TASK", "confidence": 0.7626413106918335}, {"text": "word alignment", "start_pos": 214, "end_pos": 228, "type": "TASK", "confidence": 0.7539505362510681}, {"text": "accuracy", "start_pos": 229, "end_pos": 237, "type": "METRIC", "confidence": 0.8441940546035767}]}, {"text": "In this paper, we propose the first unsupervised approach to joint alignment and extraction of phrases at multiple granularities.", "labels": [], "entities": [{"text": "joint alignment and extraction of phrases", "start_pos": 61, "end_pos": 102, "type": "TASK", "confidence": 0.7552357614040375}]}, {"text": "This is achieved by constructing a generative model that includes phrases at many levels of granularity, from minimal phrases all the way up to full sentences.", "labels": [], "entities": []}, {"text": "The model is similar to previously proposed phrase alignment models based on inversion transduction grammars (ITGs), with one important change: ITG symbols and phrase pairs are generated in the opposite order.", "labels": [], "entities": [{"text": "phrase alignment", "start_pos": 44, "end_pos": 60, "type": "TASK", "confidence": 0.8151867389678955}]}, {"text": "In traditional ITG models, the branches of a biparse tree are generated from a nonterminal distribution, and each leaf is generated by a word or phrase pair distribution.", "labels": [], "entities": []}, {"text": "As a result, only minimal phrases are directly included in the model, while larger phrases must be generated by heuristic extraction methods.", "labels": [], "entities": []}, {"text": "In the proposed model, at each branch in the tree, we first attempt to generate a phrase pair from the phrase pair distribution, falling back to ITG-based divide and conquer strategy to generate phrase pairs that do not exist (or are given low probability) in the phrase distribution.", "labels": [], "entities": []}, {"text": "We combine this model with the Bayesian nonparametric Pitman-Yor process), realizing ITG-based divide and conquer through a novel formulation where the Pitman-Yor process uses two copies of itself as abase measure.", "labels": [], "entities": []}, {"text": "As a result of this modeling strategy, phrases of multiple granularities are generated, and thus memorized, by the Pitman-Yor process.", "labels": [], "entities": []}, {"text": "This makes it possible to directly use probabilities of the phrase model as a replacement for the phrase table generated by heuristic extraction techniques.", "labels": [], "entities": []}, {"text": "Using this model, we perform machine translation experiments over four language pairs.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 29, "end_pos": 48, "type": "TASK", "confidence": 0.7299320995807648}]}, {"text": "We observe that the proposed joint phrase alignment and extraction approach is able to meet or exceed results attained by a combination of GIZA++ and heuristic phrase extraction with significantly smaller phrase table size.", "labels": [], "entities": [{"text": "phrase alignment and extraction", "start_pos": 35, "end_pos": 66, "type": "TASK", "confidence": 0.7083182856440544}, {"text": "phrase extraction", "start_pos": 160, "end_pos": 177, "type": "TASK", "confidence": 0.7214638888835907}]}, {"text": "We also find that it achieves superior BLEU scores over previously proposed ITG-based phrase alignment approaches.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 39, "end_pos": 43, "type": "METRIC", "confidence": 0.9991740584373474}, {"text": "ITG-based phrase alignment", "start_pos": 76, "end_pos": 102, "type": "TASK", "confidence": 0.5862300097942352}]}], "datasetContent": [{"text": "We evaluate the proposed method on translation tasks from four languages, French, German, Spanish, and Japanese, into English.", "labels": [], "entities": [{"text": "translation tasks", "start_pos": 35, "end_pos": 52, "type": "TASK", "confidence": 0.8986418545246124}]}, {"text": "de-en es-en fr-en ja-en TM (en) 1  The data for French, German, and Spanish are from the 2010 Workshop on Statistical Machine Translation.", "labels": [], "entities": [{"text": "Statistical Machine Translation", "start_pos": 106, "end_pos": 137, "type": "TASK", "confidence": 0.7518794337908427}]}, {"text": "We use the news commentary corpus for training the TM, and the news commentary and Europarl corpora for training the LM.", "labels": [], "entities": [{"text": "Europarl corpora", "start_pos": 83, "end_pos": 99, "type": "DATASET", "confidence": 0.9405217170715332}]}, {"text": "For Japanese, we use data from the NTCIR patent translation task (.", "labels": [], "entities": [{"text": "NTCIR patent translation task", "start_pos": 35, "end_pos": 64, "type": "TASK", "confidence": 0.8451096266508102}]}, {"text": "We use the first 100k sentences of the parallel corpus for the TM, and the whole parallel corpus for the LM.", "labels": [], "entities": []}, {"text": "Details of both corpora can be found in.", "labels": [], "entities": []}, {"text": "Corpora are tokenized, lower-cased, and sentences of over 40 words on either side are removed for TM training.", "labels": [], "entities": [{"text": "TM training", "start_pos": 98, "end_pos": 109, "type": "TASK", "confidence": 0.9059305489063263}]}, {"text": "For both tasks, we perform weight tuning and testing on specified development and test sets.", "labels": [], "entities": [{"text": "weight tuning", "start_pos": 27, "end_pos": 40, "type": "TASK", "confidence": 0.7850735485553741}]}, {"text": "We compare the accuracy of our proposed method of joint phrase alignment and extraction using the FLAT, HIER and HLEN models, with a baseline of using word alignments from GIZA++ and heuristic phrase extraction.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 15, "end_pos": 23, "type": "METRIC", "confidence": 0.9994730353355408}, {"text": "phrase alignment and extraction", "start_pos": 56, "end_pos": 87, "type": "TASK", "confidence": 0.7539607360959053}, {"text": "FLAT", "start_pos": 98, "end_pos": 102, "type": "METRIC", "confidence": 0.9583386778831482}, {"text": "HIER", "start_pos": 104, "end_pos": 108, "type": "METRIC", "confidence": 0.7000909447669983}, {"text": "HLEN", "start_pos": 113, "end_pos": 117, "type": "METRIC", "confidence": 0.9522089958190918}, {"text": "phrase extraction", "start_pos": 193, "end_pos": 210, "type": "TASK", "confidence": 0.6904914975166321}]}, {"text": "Decoding is performed using Moses () using the phrase tables learned by each method under consideration, as well as standard bidirectional lexical reordering probabilities ( . Maximum phrase length is limited to 7 in all models, and for the LM we use an interpolated Kneser-Ney 5-gram model.", "labels": [], "entities": []}, {"text": "For GIZA++, we use the standard training regimen up to Model 4, and combine alignments with grow-diag-final-and.", "labels": [], "entities": []}, {"text": "For the proposed models, we train for 100 iterations, and use the final sample acquired at the end of the training process for our experiments using a single sample   we also try averaging the phrase tables from the last ten samples as described in Section 5.3.", "labels": [], "entities": []}, {"text": "The results for these experiments can be found in Table 2.", "labels": [], "entities": []}, {"text": "From these results we can see that when using a single sample, the combination of using HIER and model probabilities achieves results approximately equal to GIZA++ and heuristic phrase extraction.", "labels": [], "entities": [{"text": "GIZA", "start_pos": 157, "end_pos": 161, "type": "METRIC", "confidence": 0.9453078508377075}, {"text": "phrase extraction", "start_pos": 178, "end_pos": 195, "type": "TASK", "confidence": 0.7225170880556107}]}, {"text": "This is the first reported result in which an unsupervised phrase alignment model has built a phrase This indicates potential gains to be provided by length-based parameter tuning were outweighed by losses due to the increased complexity of the model.", "labels": [], "entities": []}, {"text": "In particular, we believe the necessity to combine probabilities from multiple P t,l models into a single phrase table may have resulted in a distortion of the phrase probabilities.", "labels": [], "entities": []}, {"text": "In addition, the assumption that phrase lengths are generated from a uniform distribution is likely too strong, and further gains provided by P base . As iterations took 1.3 hours on a single processor, good translation results can be achieved in approximately 13 hours, which could further reduced using distributed sampling  It can also be seen that combining phrase tables from multiple samples improved the BLEU score for HLEN, but not for HIER.", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 411, "end_pos": 421, "type": "METRIC", "confidence": 0.9833864569664001}, {"text": "HLEN", "start_pos": 426, "end_pos": 430, "type": "METRIC", "confidence": 0.4479885995388031}]}, {"text": "This suggests that for HIER, most of the useful phrase pairs discovered by the model are included in every iteration, and the increased recall obtained by combining multiple samples does not consistently outweigh the increased confusion caused by the larger phrase table.", "labels": [], "entities": [{"text": "recall", "start_pos": 136, "end_pos": 142, "type": "METRIC", "confidence": 0.9986662864685059}]}, {"text": "We also evaluated the effectiveness of modelbased phrase extraction compared to heuristic phrase extraction.", "labels": [], "entities": [{"text": "phrase extraction", "start_pos": 50, "end_pos": 67, "type": "TASK", "confidence": 0.7208429574966431}, {"text": "phrase extraction", "start_pos": 90, "end_pos": 107, "type": "TASK", "confidence": 0.6933364421129227}]}, {"text": "Using the alignments from HIER, we created phrase tables using model probabilities (MOD), and heuristic extraction on words (HEUR-W), blocks (HEUR-B), and minimal phrases (HEUR-P) as described in Section 5.", "labels": [], "entities": []}, {"text": "The results of these experiments are shown in.", "labels": [], "entities": []}, {"text": "It can be seen that model-based phrase extraction using HIER outperforms or insignificantly underperforms heuristic phrase extraction overall experimental settings, while keeping the phrase table to a fraction of the size of most heuristic extraction methods.", "labels": [], "entities": [{"text": "phrase extraction", "start_pos": 32, "end_pos": 49, "type": "TASK", "confidence": 0.7886016368865967}, {"text": "heuristic phrase extraction", "start_pos": 106, "end_pos": 133, "type": "TASK", "confidence": 0.6400276819864908}]}, {"text": "Finally, we varied the size of the parallel corpus for the Japanese-English task from 50k to 400k sen- tences and measured the effect of corpus size on translation accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 164, "end_pos": 172, "type": "METRIC", "confidence": 0.8546580672264099}]}, {"text": "From the results in (a), it can be seen that at all corpus sizes, the results from all three methods are comparable, with insignificant differences between GIZA++ and HIER at all levels, and HLEN lagging slightly behind HIER.", "labels": [], "entities": []}, {"text": "(b) shows the size of the phrase table induced by each method over the various corpus sizes.", "labels": [], "entities": []}, {"text": "It can be seen that the tables created by GIZA++ are significantly larger at all corpus sizes, with the difference being particularly pronounced at larger corpus sizes.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: BLEU score and phrase table size by alignment method, extraction method, and samples combined. Bold  numbers are not significantly different from the best result according to the sign test (p < 0.05) (Collins et al., 2005).", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.9685038924217224}]}, {"text": " Table 3: Translation results and phrase table size for var- ious phrase extraction techniques (French-English).", "labels": [], "entities": [{"text": "Translation", "start_pos": 10, "end_pos": 21, "type": "TASK", "confidence": 0.9672591090202332}, {"text": "var- ious phrase extraction", "start_pos": 56, "end_pos": 83, "type": "TASK", "confidence": 0.6199805557727813}]}, {"text": " Table 3. It can be seen  that model-based phrase extraction using HIER out- performs or insignificantly underperforms heuris- tic phrase extraction over all experimental settings,  while keeping the phrase table to a fraction of the  size of most heuristic extraction methods.", "labels": [], "entities": [{"text": "phrase extraction", "start_pos": 43, "end_pos": 60, "type": "TASK", "confidence": 0.7408393025398254}, {"text": "heuris- tic phrase extraction", "start_pos": 119, "end_pos": 148, "type": "TASK", "confidence": 0.6887482106685638}]}]}