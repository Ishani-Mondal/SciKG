{"title": [{"text": "Subjectivity and Sentiment Analysis of Modern Standard Arabic", "labels": [], "entities": [{"text": "Sentiment Analysis", "start_pos": 17, "end_pos": 35, "type": "TASK", "confidence": 0.8975576460361481}, {"text": "Modern Standard Arabic", "start_pos": 39, "end_pos": 61, "type": "DATASET", "confidence": 0.6094662348429362}]}], "abstractContent": [{"text": "Although Subjectivity and Sentiment Analysis (SSA) has been witnessing a flurry of novel research , there are few attempts to build SSA systems for Morphologically-Rich Languages (MRL).", "labels": [], "entities": [{"text": "Subjectivity and Sentiment Analysis (SSA)", "start_pos": 9, "end_pos": 50, "type": "TASK", "confidence": 0.7871478114809308}]}, {"text": "In the current study, we report efforts to partially fill this gap.", "labels": [], "entities": []}, {"text": "We present a newly developed manually annotated corpus of Modern Standard Arabic (MSA) together with anew polarity lexicon.The corpus is a collection of newswire documents annotated on the sentence level.", "labels": [], "entities": [{"text": "Modern Standard Arabic (MSA)", "start_pos": 58, "end_pos": 86, "type": "DATASET", "confidence": 0.7715139389038086}]}, {"text": "We also describe an automatic SSA tagging system that exploits the annotated data.", "labels": [], "entities": [{"text": "SSA tagging", "start_pos": 30, "end_pos": 41, "type": "TASK", "confidence": 0.9811447858810425}]}, {"text": "We investigate the impact of different levels of preprocessing settings on the SSA classification task.", "labels": [], "entities": [{"text": "SSA classification task", "start_pos": 79, "end_pos": 102, "type": "TASK", "confidence": 0.9656588435173035}]}, {"text": "We show that by explicitly accounting for the rich morphology the system is able to achieve significantly higher levels of performance.", "labels": [], "entities": []}], "introductionContent": [{"text": "Subjectivity and Sentiment Analysis (SSA) is an area that has been witnessing a flurry of novel research.", "labels": [], "entities": [{"text": "Subjectivity and Sentiment Analysis (SSA)", "start_pos": 0, "end_pos": 41, "type": "TASK", "confidence": 0.863569336278098}]}, {"text": "In natural language, subjectivity refers to expression of opinions, evaluations, feelings, and speculations and thus incorporates sentiment.", "labels": [], "entities": []}, {"text": "The process of subjectivity classification refers to the task of classifying texts into either objective (e.g., Mubarak stepped down) or subjective (e.g., Mubarak, the hateful dictator, stepped down).", "labels": [], "entities": [{"text": "subjectivity classification", "start_pos": 15, "end_pos": 42, "type": "TASK", "confidence": 0.7245079576969147}]}, {"text": "Subjective text is further classified with sentiment or polarity.", "labels": [], "entities": []}, {"text": "For sentiment classification, the task refers to identifying whether the subjective text is positive (e.g., What an excellent camera!), negative (e.g., I hate this camera!), neutral (e.g., I believe there will be a meeting.), or, sometimes, mixed (e.g., It is good, but I hate it!) texts.", "labels": [], "entities": [{"text": "sentiment classification", "start_pos": 4, "end_pos": 28, "type": "TASK", "confidence": 0.9746898412704468}]}, {"text": "Most of the SSA literature has focused on English and other Indio-European languages.", "labels": [], "entities": [{"text": "SSA", "start_pos": 12, "end_pos": 15, "type": "TASK", "confidence": 0.9694185256958008}]}, {"text": "Very few studies have addressed the problem for morphologically rich languages (MRL) such as Arabic, Hebrew, Turkish, Czech, etc.", "labels": [], "entities": [{"text": "morphologically rich languages (MRL)", "start_pos": 48, "end_pos": 84, "type": "TASK", "confidence": 0.7405209441979727}]}, {"text": "(. MRL pose significant challenges to NLP systems in general, and the SSA task is expected to be no exception.", "labels": [], "entities": [{"text": "SSA task", "start_pos": 70, "end_pos": 78, "type": "TASK", "confidence": 0.8623899817466736}]}, {"text": "The problem is even more pronounced in some MRL due to the lack in annotated resources for SSA such as labeled corpora, and polarity lexica.", "labels": [], "entities": [{"text": "MRL", "start_pos": 44, "end_pos": 47, "type": "TASK", "confidence": 0.959805965423584}]}, {"text": "In the current paper, we investigate the task of sentence-level SSA on Modern Standard Arabic (MSA) texts from the newswire genre.", "labels": [], "entities": [{"text": "SSA", "start_pos": 64, "end_pos": 67, "type": "TASK", "confidence": 0.7103273868560791}, {"text": "Modern Standard Arabic (MSA) texts from the newswire genre", "start_pos": 71, "end_pos": 129, "type": "DATASET", "confidence": 0.7502268688245253}]}, {"text": "We run experiments on three different pre-processing settings based on tokenized text from the Penn Arabic Treebank (PATB) () and employ both language-independent and Arabicspecific, morphology-based features.", "labels": [], "entities": [{"text": "Penn Arabic Treebank (PATB)", "start_pos": 95, "end_pos": 122, "type": "DATASET", "confidence": 0.9720205167929331}]}, {"text": "Our work shows that explicitly using morphology-based features in our models improves the system's performance.", "labels": [], "entities": []}, {"text": "We also measure the impact of using a wide coverage polarity lexicon and show that using a tailored resource results in significant improvement in classification performance.", "labels": [], "entities": []}], "datasetContent": [{"text": "We divide our data into 80% for 5-fold crossvalidation and 20% for test.", "labels": [], "entities": []}, {"text": "For experiments on the test data, the 80% are used as training data.", "labels": [], "entities": []}, {"text": "We have two settings, a development setting (DEV) and a test setting (TEST).", "labels": [], "entities": [{"text": "TEST)", "start_pos": 70, "end_pos": 75, "type": "METRIC", "confidence": 0.8923534750938416}]}, {"text": "In the development setting, we run the typical 5 fold cross validation where we train on 4 folds and test on the 5th and then average the results.", "labels": [], "entities": []}, {"text": "In the test setting, we only ran with the best configurations yielded from the DEV conditions.", "labels": [], "entities": [{"text": "DEV", "start_pos": 79, "end_pos": 82, "type": "DATASET", "confidence": 0.9035635590553284}]}, {"text": "In TEST mode, we still train with 4 folds but we test on the test data exclusively, averaging across the different training rounds.", "labels": [], "entities": []}, {"text": "It is worth noting that the test data is larger than any given dev data (20% of the overall data set for test, vs. 16% for any DEV fold).", "labels": [], "entities": []}, {"text": "We report results using F-measure (F).", "labels": [], "entities": [{"text": "F-measure (F)", "start_pos": 24, "end_pos": 37, "type": "METRIC", "confidence": 0.9310726672410965}]}, {"text": "Moreover, for TEST we report only experiments on the Stem+Morph setting and Stem+Morph+ADJ, Stem+Morph+DOMAIN, and Stem+Morph+UNIQUE.", "labels": [], "entities": [{"text": "TEST", "start_pos": 14, "end_pos": 18, "type": "DATASET", "confidence": 0.49377575516700745}]}, {"text": "Below, we only report the best-performing results across the N-GRAM features and their combinations.", "labels": [], "entities": []}, {"text": "In each case, our baseline is the majority class in the training set.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Subjectivity results on Stem+Morph+language independent features", "labels": [], "entities": []}, {"text": " Table 3: Sentiment results on Stem+Morph+language independent features", "labels": [], "entities": [{"text": "Sentiment", "start_pos": 10, "end_pos": 19, "type": "TASK", "confidence": 0.9817765355110168}]}]}