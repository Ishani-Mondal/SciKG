{"title": [{"text": "Two Easy Improvements to Lexical Weighting", "labels": [], "entities": [{"text": "Lexical Weighting", "start_pos": 25, "end_pos": 42, "type": "TASK", "confidence": 0.887856662273407}]}], "abstractContent": [{"text": "We introduce two simple improvements to the lexical weighting features of Koehn, Och, and Marcu (2003) for machine translation: one which smooths the probability of translating word f to word e by simplifying English morphology , and one which conditions it on the kind of training data that f and e co-occurred in.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 107, "end_pos": 126, "type": "TASK", "confidence": 0.7611599564552307}]}, {"text": "These new variations lead to improvements of up to +0.8 BLEU, with an average improvement of +0.6 BLEU across two language pairs, two genres, and two translation systems.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 56, "end_pos": 60, "type": "METRIC", "confidence": 0.998497724533081}, {"text": "BLEU", "start_pos": 98, "end_pos": 102, "type": "METRIC", "confidence": 0.9951903820037842}]}], "introductionContent": [{"text": "Lexical weighting features () estimate the probability of a phrase pair or translation rule word-by-word.", "labels": [], "entities": [{"text": "Lexical weighting", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.8205425441265106}]}, {"text": "In this paper, we introduce two simple improvements to these features: one which smooths the probability of translating word f to word e using English morphology, and one which conditions it on the kind of training data that f and e co-occurred in.", "labels": [], "entities": []}, {"text": "These new variations lead to improvements of up to +0.8 BLEU, with an average improvement of +0.6 BLEU across two language pairs, two genres, and two translation systems.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 56, "end_pos": 60, "type": "METRIC", "confidence": 0.998497724533081}, {"text": "BLEU", "start_pos": 98, "end_pos": 102, "type": "METRIC", "confidence": 0.9951903820037842}]}], "datasetContent": [{"text": "Setup We tested these features on two machine translation systems: a hierarchical phrasebased (string-to-string) system (Chiang, 2005) and a syntax-based (string-to-tree) system ().", "labels": [], "entities": []}, {"text": "For Arabic-English translation, both systems were trained on 190+220 million words of parallel data; for Chinese-English, the string-to-string system was trained on 240+260 million words of parallel data, and the string-to-tree system, 58+65 million words.", "labels": [], "entities": []}, {"text": "Both used two language models, one trained on the combined English sides of the Arabic-English and Chinese-English data, and one trained on 4 billion words of English data.", "labels": [], "entities": []}, {"text": "The baseline string-to-string system already incorporates some simple provenance features: for each s-feature s, there is a feature P(s | rule).", "labels": [], "entities": []}, {"text": "Both baseline also include a variety of other features.", "labels": [], "entities": []}, {"text": "Both systems were trained using MIRA) on a held-out set, then tested on two more sets (Dev and Test) disjoint from the data used for rule extraction and for MIRA training.", "labels": [], "entities": [{"text": "MIRA", "start_pos": 32, "end_pos": 36, "type": "DATASET", "confidence": 0.49729809165000916}, {"text": "rule extraction", "start_pos": 133, "end_pos": 148, "type": "TASK", "confidence": 0.889868289232254}, {"text": "MIRA", "start_pos": 157, "end_pos": 161, "type": "TASK", "confidence": 0.8768742680549622}]}, {"text": "These datasets have roughly 1000-3000 sentences (30,000-70,000 words) and are drawn from test sets from the NIST MT evaluation and development sets from the GALE program.", "labels": [], "entities": [{"text": "NIST MT evaluation", "start_pos": 108, "end_pos": 126, "type": "DATASET", "confidence": 0.8599504828453064}, {"text": "GALE program", "start_pos": 157, "end_pos": 169, "type": "DATASET", "confidence": 0.7748184502124786}]}, {"text": "Individual tests We first tested morphological smoothing using the string-to-string system on Chinese-English translation.", "labels": [], "entities": [{"text": "morphological smoothing", "start_pos": 33, "end_pos": 56, "type": "TASK", "confidence": 0.6959751546382904}]}, {"text": "The morphologically smoothed system generated the improved translation 29.4 The translations (12) and (13) come from the Arabic-English baseline and provenance systems.", "labels": [], "entities": []}, {"text": "For Arabic-English, we also compared against lexical weighting features that use sentence weights kindly provided to us by Matsoukas et al.", "labels": [], "entities": []}, {"text": "Our features performed better, although it should be noted that those sentence weights had been optimized fora different translation model.", "labels": [], "entities": []}, {"text": "Combined tests Finally, we tested the features across a wider range of tasks.", "labels": [], "entities": []}, {"text": "For Chinese-English translation, we combined the morphologicallysmoothed and provenance-conditioned lexical weighting features; for Arabic-English, we continued to use only the provenance-conditioned features.", "labels": [], "entities": []}, {"text": "We tested using both systems, and on both newswire and web genres.", "labels": [], "entities": []}, {"text": "The results are shown in.", "labels": [], "entities": []}, {"text": "The features produce statistically significant improvements across all 16 conditions.", "labels": [], "entities": []}, {"text": "shows the feature weights obtained for the provenance-conditioned features t s ( f | e) in the string-to-string Chinese-English system, trained on newswire and web data.", "labels": [], "entities": []}, {"text": "On the diagonal are corpora that were equally useful in either genre.", "labels": [], "entities": []}, {"text": "Surprisingly, the UN data received strong positive weights, indicating usefulness in both genres.", "labels": [], "entities": [{"text": "UN data", "start_pos": 18, "end_pos": 25, "type": "DATASET", "confidence": 0.9026414155960083}]}, {"text": "Two lists of named entities received large weights: the LDC list (LDC2005T34) in the positive direction and the NewsExplorer list in the negative direction, suggesting that there are noisy entries in the latter.", "labels": [], "entities": [{"text": "NewsExplorer list", "start_pos": 112, "end_pos": 129, "type": "DATASET", "confidence": 0.953775942325592}]}, {"text": "The corpus LDC2007E08, which contains parallel data mined from comparable corpora (), received strong negative weights.", "labels": [], "entities": [{"text": "LDC2007E08", "start_pos": 11, "end_pos": 21, "type": "DATASET", "confidence": 0.8456670641899109}]}, {"text": "Off the diagonal are corpora favored in only one genre or the other: above, we see that the wl (weblog) and ng (newsgroup) genres are more helpful for web translation, as expected (although web oddly seems less helpful), as well as LDC2006G05 (LDC/FBIS/NVTC Parallel Text V2.0).", "labels": [], "entities": [{"text": "web translation", "start_pos": 151, "end_pos": 166, "type": "TASK", "confidence": 0.7213829457759857}, {"text": "LDC/FBIS/NVTC Parallel Text V2.0", "start_pos": 244, "end_pos": 276, "type": "DATASET", "confidence": 0.8242254257202148}]}, {"text": "Below are corpora more helpful for newswire translation, like LDC2005T06 (Chinese News Translation Text Part 1).", "labels": [], "entities": [{"text": "newswire translation", "start_pos": 35, "end_pos": 55, "type": "TASK", "confidence": 0.5911947041749954}, {"text": "Chinese News Translation Text Part 1)", "start_pos": 74, "end_pos": 111, "type": "DATASET", "confidence": 0.8229225533349174}]}], "tableCaptions": [{"text": " Table 2: The morphologically-smoothed lexical weight- ing features weaken the preference for singular or plural  translations, with the exception of t(friends | \u670b\u53cb).", "labels": [], "entities": []}, {"text": " Table 3. But some  genres favor perhaps more or less strongly. Thus,  both translations (12) and (13) are good, but the lat- ter uses a slightly more informal register appropriate  to the genre.  Following Matsoukas et al. (2009), we assign each  training sentence pair a set of binary features which  we call s-features:", "labels": [], "entities": []}, {"text": " Table 4: Our variations on lexical weighting improve translation quality significantly across 16 different test conditions.  All improvements are significant at the p < 0.01 level, except where marked with an asterisk (  *  ), indicating p < 0.05.", "labels": [], "entities": []}]}