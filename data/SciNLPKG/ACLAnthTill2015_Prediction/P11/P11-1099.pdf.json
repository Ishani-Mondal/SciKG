{"title": [], "abstractContent": [{"text": "Argumentation schemes are structures or templates for various kinds of arguments.", "labels": [], "entities": []}, {"text": "Given the text of an argument with premises and conclusion identified, we classify it as an instance of one of five common schemes, using features specific to each scheme.", "labels": [], "entities": []}, {"text": "We achieve accuracies of 63-91% in one-against-others classification and 80-94% in pairwise classification (baseline = 50% in both cases).", "labels": [], "entities": [{"text": "accuracies", "start_pos": 11, "end_pos": 21, "type": "METRIC", "confidence": 0.9987034797668457}]}], "introductionContent": [{"text": "We investigate anew task in the computational analysis of arguments: the classification of arguments by the argumentation schemes that they use.", "labels": [], "entities": [{"text": "computational analysis of arguments", "start_pos": 32, "end_pos": 67, "type": "TASK", "confidence": 0.773645706474781}]}, {"text": "An argumentation scheme, informally, is a framework or structure fora (possibly defeasible) argument; we will give a more-formal definition and examples in Section 3.", "labels": [], "entities": []}, {"text": "Our work is motivated by the need to determine the unstated (or implicitly stated) premises that arguments written in natural language normally draw on.", "labels": [], "entities": []}, {"text": "Such premises are called enthymemes.", "labels": [], "entities": []}, {"text": "For instance, the argument in Example 1 consists of one explicit premise (the first sentence) and a conclusion (the second sentence): Example 1 [Premise:] The survival of the entire world is at stake.", "labels": [], "entities": []}, {"text": "[Conclusion:] The treaties and covenants aiming fora world free of nuclear arsenals and other conventional and biological weapons of mass destruction should be adhered to scrupulously by all nations.", "labels": [], "entities": []}, {"text": "Another premise is left implicit -\"Adhering to those treaties and covenants is a means of realizing survival of the entire world\".", "labels": [], "entities": []}, {"text": "This proposition is an enthymeme of this argument.", "labels": [], "entities": []}, {"text": "Our ultimate goal is to reconstruct the enthymemes in an argument, because determining these unstated assumptions is an integral part of understanding, supporting, or attacking an entire argument.", "labels": [], "entities": []}, {"text": "Hence reconstructing enthymemes is an important problem in argument understanding.", "labels": [], "entities": [{"text": "argument understanding", "start_pos": 59, "end_pos": 81, "type": "TASK", "confidence": 0.9142346084117889}]}, {"text": "We believe that first identifying the particular argumentation scheme that an argument is using will help to bridge the gap between stated and unstated propositions in the argument, because each argumentation scheme is a relatively fixed \"template\" for arguing.", "labels": [], "entities": []}, {"text": "That is, given an argument, we first classify its argumentation scheme; then we fit the stated propositions into the corresponding template; and from this we infer the enthymemes.", "labels": [], "entities": []}, {"text": "In this paper, we present an argument scheme classification system as a stage following argument detection and proposition classification.", "labels": [], "entities": [{"text": "argument scheme classification", "start_pos": 29, "end_pos": 59, "type": "TASK", "confidence": 0.6493523518244425}, {"text": "argument detection", "start_pos": 88, "end_pos": 106, "type": "TASK", "confidence": 0.7238442748785019}, {"text": "proposition classification", "start_pos": 111, "end_pos": 137, "type": "TASK", "confidence": 0.7793614864349365}]}, {"text": "First in Section 2 and Section 3, we introduce the background to our work, including related work in this field, the two core concepts of argumentation schemes and scheme-sets, and the Araucaria dataset.", "labels": [], "entities": [{"text": "Araucaria dataset", "start_pos": 185, "end_pos": 202, "type": "DATASET", "confidence": 0.8507936000823975}]}, {"text": "In Section 4 and Section 5 we present our classification system, including the overall framework, data preprocessing, feature selection, and the experimental setups.", "labels": [], "entities": [{"text": "feature selection", "start_pos": 118, "end_pos": 135, "type": "TASK", "confidence": 0.733912393450737}]}, {"text": "In the remaining section, we present the essential approaches to solve the leftover problems of this paper which we will study in our future work, and discuss the experimental results, and potential directions for future work.", "labels": [], "entities": []}], "datasetContent": [{"text": "One of the challenges for automatic argumentation analysis is that suitable annotated corpora are still very rare, in spite of work by many researchers.", "labels": [], "entities": [{"text": "automatic argumentation analysis", "start_pos": 26, "end_pos": 58, "type": "TASK", "confidence": 0.7152264912923177}]}, {"text": "In the work described here, we use the Araucaria database 1 , an online repository of arguments, as our experimental dataset.", "labels": [], "entities": [{"text": "Araucaria database 1", "start_pos": 39, "end_pos": 59, "type": "DATASET", "confidence": 0.8858305017153422}]}, {"text": "Araucaria includes approximately 660 manually annotated arguments from various sources, such as newspapers and court cases, and keeps growing.", "labels": [], "entities": [{"text": "Araucaria", "start_pos": 0, "end_pos": 9, "type": "DATASET", "confidence": 0.7611618638038635}]}, {"text": "Although Araucaria has several limitations, such as rather small size and low agreement among annotators 2 , it is nonetheless one of the best argumentative corpora available to date.", "labels": [], "entities": [{"text": "agreement", "start_pos": 78, "end_pos": 87, "type": "METRIC", "confidence": 0.9638818502426147}]}, {"text": "We experiment with different combinations of general features and scheme-specific features (discussed in Section 4.3).", "labels": [], "entities": []}, {"text": "To evaluate each experiment, we use the average accuracy over 10 pools of randomly sampled data (each with baseline at 50% 6 ) with 10-fold cross-validation.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 48, "end_pos": 56, "type": "METRIC", "confidence": 0.9965426325798035}]}], "tableCaptions": [{"text": " Table 5: Best average accuracies (BAAs) (%) of pairwise  classification.", "labels": [], "entities": [{"text": "average accuracies (BAAs)", "start_pos": 15, "end_pos": 40, "type": "METRIC", "confidence": 0.8336729049682617}, {"text": "pairwise  classification", "start_pos": 48, "end_pos": 72, "type": "TASK", "confidence": 0.7422367036342621}]}, {"text": " Table 6: Accuracy (%) with and without type in one-against-others classification. BAA-t is best average accuracy with  type, and BAA-no t is best average accuracy without type. max diff, min diff, and avg diff are maximal, minimal, and  average differences between each experimental setup with type and without type while the remaining conditions are  the same.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.998424768447876}, {"text": "BAA-t", "start_pos": 83, "end_pos": 88, "type": "METRIC", "confidence": 0.9987659454345703}, {"text": "accuracy", "start_pos": 105, "end_pos": 113, "type": "METRIC", "confidence": 0.8916597962379456}, {"text": "BAA-no", "start_pos": 130, "end_pos": 136, "type": "METRIC", "confidence": 0.9977691173553467}, {"text": "accuracy", "start_pos": 155, "end_pos": 163, "type": "METRIC", "confidence": 0.9116822481155396}]}, {"text": " Table 7: Accuracy (%) with and without type in pairwise classification. Column headings have the same meanings as  in", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9988203644752502}, {"text": "pairwise classification", "start_pos": 48, "end_pos": 71, "type": "TASK", "confidence": 0.6375619769096375}]}]}