{"title": [{"text": "Contrasting Multi-Lingual Prosodic Cues to Predict Verbal Feedback for Rapport", "labels": [], "entities": []}], "abstractContent": [{"text": "Verbal feedback is an important information source in establishing interactional rapport.", "labels": [], "entities": []}, {"text": "However, predicting verbal feedback across languages is challenging due to language-specific differences, inter-speaker variation, and the relative sparseness and optionality of verbal feedback.", "labels": [], "entities": [{"text": "predicting verbal feedback", "start_pos": 9, "end_pos": 35, "type": "TASK", "confidence": 0.8936498761177063}]}, {"text": "In this paper, we employ an approach combining classifier weighting and SMOTE algorithm oversampling to improve verbal feedback prediction in Arabic, English, and Spanish dyadic conversations.", "labels": [], "entities": [{"text": "SMOTE", "start_pos": 72, "end_pos": 77, "type": "METRIC", "confidence": 0.6924932599067688}, {"text": "verbal feedback prediction", "start_pos": 112, "end_pos": 138, "type": "TASK", "confidence": 0.6444884637991587}]}, {"text": "This approach improves the prediction of verbal feedback , up to 6-fold, while maintaining a high overall accuracy.", "labels": [], "entities": [{"text": "prediction of verbal feedback", "start_pos": 27, "end_pos": 56, "type": "TASK", "confidence": 0.858539804816246}, {"text": "accuracy", "start_pos": 106, "end_pos": 114, "type": "METRIC", "confidence": 0.9978381991386414}]}, {"text": "Analyzing highly weighted features highlights widespread use of pitch, with more varied use of intensity and duration.", "labels": [], "entities": [{"text": "pitch", "start_pos": 64, "end_pos": 69, "type": "METRIC", "confidence": 0.9521917104721069}, {"text": "duration", "start_pos": 109, "end_pos": 117, "type": "METRIC", "confidence": 0.9454306960105896}]}], "introductionContent": [{"text": "Culture-specific aspects of speech and nonverbal behavior enable creation and maintenance of a sense of rapport.", "labels": [], "entities": []}, {"text": "Rapport is important because it is known to enhance goal-directed interactions and also to promote learning.", "labels": [], "entities": [{"text": "Rapport", "start_pos": 0, "end_pos": 7, "type": "METRIC", "confidence": 0.8484026789665222}]}, {"text": "Previous work has identified crosscultural differences in a variety of behaviors, for example, nodding, facial expression (), gaze, cues to vocal back-channel;, nonverbal back-channel), and coverbal gesturing).", "labels": [], "entities": [{"text": "coverbal gesturing", "start_pos": 190, "end_pos": 208, "type": "TASK", "confidence": 0.6637912094593048}]}, {"text": "Here we focus on the automatic prediction of listener verbal feedback in dyadic unrehearsed storytelling to elucidate the similarities and differences in three language/cultural groups: Iraqi Arabic-, Mexican Spanish-, and American English-speaking cultures.", "labels": [], "entities": []}, {"text": "identified coordination, along with positive emotion and mutual attention, as a key element of interactional rapport.", "labels": [], "entities": []}, {"text": "In the verbal channel, this coordination manifests in the timing of contributions from the conversational participants, through turntaking and back-channels.", "labels": [], "entities": []}, {"text": "proposed an analysis of turn-taking as rule-governed, supported by a range of prosodic and non-verbal cues.", "labels": [], "entities": []}, {"text": "Several computational approaches have investigated prosodic and verbal cues to these phenomena.", "labels": [], "entities": []}, {"text": "( found that prosodic cues could aid in the identification of jump-in points in multi-party meetings.", "labels": [], "entities": []}, {"text": "() employed features such as pause duration and part-ofspeech (POS) tag sequences for back-channel prediction.", "labels": [], "entities": [{"text": "back-channel prediction", "start_pos": 86, "end_pos": 109, "type": "TASK", "confidence": 0.7008199095726013}]}, {"text": "() investigated back-channel-inviting cues in task-oriented dialog, identifying increases in pitch and intensity as well ascertain POS patterns as key contributors.", "labels": [], "entities": []}, {"text": "In multi-lingual comparisons, found pitch patterns, including periods of low pitch or drops in pitch, to be associated with eliciting back-channels across Japanese, English, Arabic, and Spanish.", "labels": [], "entities": []}, {"text": "() collected a corpus of multi-party interactions among American English, Mexican Spanish, and Arabic speakers to investigate cross-cultural differences in proxemics, gaze, and turn-taking.", "labels": [], "entities": []}, {"text": "() identified contrasts in narrative length and rate of verbal feedback in recordings of American English-, Mexi-can Spanish-, and Iraqi Arabic-speaking dyads.", "labels": [], "entities": []}, {"text": "This work also identified reductions in pitch and intensity associated with instances of verbal feedback as common, but not uniform, across these groups.", "labels": [], "entities": [{"text": "pitch and intensity", "start_pos": 40, "end_pos": 59, "type": "METRIC", "confidence": 0.8867854674657186}]}], "datasetContent": [{"text": "We define a Speaker pausal region as an interval in the Speaker's channel annotated with a contiguous span of silence and/or non-speech sounds.", "labels": [], "entities": []}, {"text": "These: Mean and standard deviation of proportion of pausal regions associated with listener verbal feedback region.", "labels": [], "entities": [{"text": "Mean", "start_pos": 7, "end_pos": 11, "type": "METRIC", "confidence": 0.998042106628418}]}, {"text": "We group the dyads by language/cultural group to contrast the prosodic characteristics of the speech that elicit listener feedback and to assess the effectiveness of these prosodic cues for classification.", "labels": [], "entities": []}, {"text": "The proportion of regions with listener feedback for each language appears in.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 3: Varying SVM weight and SMOTE ratio. Each  cell shows # dyads in each language (Arabic, English,  Spanish) with their best performance with this setting.", "labels": [], "entities": [{"text": "SMOTE ratio", "start_pos": 33, "end_pos": 44, "type": "METRIC", "confidence": 0.9747709631919861}]}, {"text": " Table 4: Row 1: Class distribution: # FB instances (#  total instances). Rows 2-4: Recognition under different  settings: # FB correctly recognized (total # correct)", "labels": [], "entities": [{"text": "FB", "start_pos": 39, "end_pos": 41, "type": "METRIC", "confidence": 0.8748055100440979}]}]}