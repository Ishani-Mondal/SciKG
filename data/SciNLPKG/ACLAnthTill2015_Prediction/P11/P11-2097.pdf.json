{"title": [{"text": "Identification of Domain-Specific Senses in a Machine-Readable Dictionary", "labels": [], "entities": [{"text": "Identification of Domain-Specific Senses", "start_pos": 0, "end_pos": 40, "type": "TASK", "confidence": 0.8485160768032074}]}], "abstractContent": [{"text": "This paper focuses on domain-specific senses and presents a method for assigning cate-gory/domain label to each sense of words in a dictionary.", "labels": [], "entities": []}, {"text": "The method first identifies each sense of a word in the dictionary to its corresponding category.", "labels": [], "entities": []}, {"text": "We used a text classification technique to select appropriate senses for each domain.", "labels": [], "entities": [{"text": "text classification", "start_pos": 10, "end_pos": 29, "type": "TASK", "confidence": 0.7054588794708252}]}, {"text": "Then, senses were scored by computing the rank scores.", "labels": [], "entities": []}, {"text": "We used Markov Random Walk (MRW) model.", "labels": [], "entities": []}, {"text": "The method was tested on English and Japanese resources, WordNet 3.0 and EDR Japanese dictionary.", "labels": [], "entities": [{"text": "WordNet 3.0", "start_pos": 57, "end_pos": 68, "type": "DATASET", "confidence": 0.9095627069473267}, {"text": "EDR Japanese dictionary", "start_pos": 73, "end_pos": 96, "type": "DATASET", "confidence": 0.9485369324684143}]}, {"text": "For evaluation of the method, we compared English results with the Subject Field Codes (SFC) resources.", "labels": [], "entities": []}, {"text": "We also compared each En-glish and Japanese results to the first sense heuristics in the WSD task.", "labels": [], "entities": [{"text": "WSD task", "start_pos": 89, "end_pos": 97, "type": "TASK", "confidence": 0.8668415248394012}]}, {"text": "These results suggest that identification of domain-specific senses (IDSS) may actually be of benefit.", "labels": [], "entities": [{"text": "identification of domain-specific senses (IDSS)", "start_pos": 27, "end_pos": 74, "type": "TASK", "confidence": 0.7764439753123692}]}], "introductionContent": [{"text": "Domain-specific sense of a word is crucial information for many NLP tasks and their applications, such as Word Sense Disambiguation (WSD) and Information Retrieval (IR).", "labels": [], "entities": [{"text": "Word Sense Disambiguation (WSD)", "start_pos": 106, "end_pos": 137, "type": "TASK", "confidence": 0.7585835605859756}, {"text": "Information Retrieval (IR)", "start_pos": 142, "end_pos": 168, "type": "TASK", "confidence": 0.8523080706596374}]}, {"text": "For example, in the WSD task, McCarthy et al. presented a method to find predominant noun senses automatically using a thesaurus acquired from raw textual corpora and the WordNet similarity package (.", "labels": [], "entities": [{"text": "WSD task", "start_pos": 20, "end_pos": 28, "type": "TASK", "confidence": 0.9190246164798737}]}, {"text": "They used parsed data to find words with a similar distribution to the target word.", "labels": [], "entities": []}, {"text": "Unlike), they evaluated their method using publically available resources, namely SemCor () and the SENSEVAL-2 English all-words task.", "labels": [], "entities": [{"text": "SENSEVAL-2 English all-words task", "start_pos": 100, "end_pos": 133, "type": "TASK", "confidence": 0.6705774664878845}]}, {"text": "The major motivation for their work was similar to ours, i.e., to try to capture changes in ranking of senses for documents from different domains.", "labels": [], "entities": []}, {"text": "Domain adaptation is also an approach for focussing on domain-specific senses and used in the WSD task.", "labels": [], "entities": [{"text": "Domain adaptation", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.8077853322029114}, {"text": "WSD task", "start_pos": 94, "end_pos": 102, "type": "TASK", "confidence": 0.9390279352664948}]}, {"text": "Chan et. al. proposed a supervised domain adaptation on a manually selected subset of 21 nouns from the DSO corpus having examples from the Brown corpus and Wall Street Journal corpus.", "labels": [], "entities": [{"text": "DSO corpus", "start_pos": 104, "end_pos": 114, "type": "DATASET", "confidence": 0.9714435040950775}, {"text": "Brown corpus", "start_pos": 140, "end_pos": 152, "type": "DATASET", "confidence": 0.982590913772583}, {"text": "Wall Street Journal corpus", "start_pos": 157, "end_pos": 183, "type": "DATASET", "confidence": 0.9357021450996399}]}, {"text": "They used active learning, countmerging, and predominant sense estimation in order to save target annotation effort.", "labels": [], "entities": [{"text": "countmerging", "start_pos": 27, "end_pos": 39, "type": "METRIC", "confidence": 0.7086255550384521}]}, {"text": "They showed that for the set of nouns which have different predominant senses between the training and target domains, the annotation effort was reduced up to 29%.", "labels": [], "entities": []}, {"text": "Agirre et. al. presented a method of supervised domain adaptation.", "labels": [], "entities": [{"text": "supervised domain adaptation", "start_pos": 37, "end_pos": 65, "type": "TASK", "confidence": 0.6891317963600159}]}, {"text": "They made use of unlabeled data with SVM, a combination of kernels and SVM, and showed that domain adaptation is an important technique for WSD systems.", "labels": [], "entities": [{"text": "domain adaptation", "start_pos": 92, "end_pos": 109, "type": "TASK", "confidence": 0.7295583486557007}, {"text": "WSD", "start_pos": 140, "end_pos": 143, "type": "TASK", "confidence": 0.9503222703933716}]}, {"text": "The major motivation for domain adaptation is that the sense distribution depends on the domain in which a word is used.", "labels": [], "entities": [{"text": "domain adaptation", "start_pos": 25, "end_pos": 42, "type": "TASK", "confidence": 0.7680749595165253}]}, {"text": "Most of them adapted textual corpus which is used for training on WSD.", "labels": [], "entities": [{"text": "WSD", "start_pos": 66, "end_pos": 69, "type": "TASK", "confidence": 0.9439255595207214}]}, {"text": "In the context of dictionary-based approach, the first sense heuristic applied to WordNet is often used as a baseline for supervised WSD systems, as the senses in WordNet are ordered according to the frequency data in the manually tagged resource SemCor ().", "labels": [], "entities": [{"text": "WordNet", "start_pos": 82, "end_pos": 89, "type": "DATASET", "confidence": 0.9418017864227295}]}, {"text": "The usual drawback in the first sense heuristic applied to the WordNet is the small size of the SemCor corpus.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 63, "end_pos": 70, "type": "DATASET", "confidence": 0.9644150137901306}, {"text": "SemCor corpus", "start_pos": 96, "end_pos": 109, "type": "DATASET", "confidence": 0.7407029867172241}]}, {"text": "Therefore, senses that do not occur in SemCor are often ordered arbitrarily.", "labels": [], "entities": []}, {"text": "More seriously, the decision is not based on the domain but on the frequency of SemCor data.", "labels": [], "entities": [{"text": "SemCor data", "start_pos": 80, "end_pos": 91, "type": "DATASET", "confidence": 0.7131587415933609}]}, {"text": "Magnini et al. presented a lexical resource where WordNet 2.0 synsets were annotated with Subject Field Codes (SFC) by a procedure that exploits the WordNet structure).", "labels": [], "entities": [{"text": "WordNet structure", "start_pos": 149, "end_pos": 166, "type": "DATASET", "confidence": 0.9122087955474854}]}, {"text": "The results showed that 96% of the WordNet synsets of the noun hierarchy could have been annotated using 115 different SFC, while identification of the domain labels for word senses was required a considerable amount of hand-labeling.", "labels": [], "entities": [{"text": "WordNet synsets", "start_pos": 35, "end_pos": 50, "type": "DATASET", "confidence": 0.9463205337524414}]}, {"text": "In this paper, we focus on domain-specific senses and propose a method for assigning category/domain label to each sense of words in a dictionary.", "labels": [], "entities": []}, {"text": "Our approach is automated, and requires only documents assigned to domains/categories, such as Reuters corpus, and a dictionary with gloss text, such as WordNet.", "labels": [], "entities": [{"text": "Reuters corpus", "start_pos": 95, "end_pos": 109, "type": "DATASET", "confidence": 0.9671284258365631}, {"text": "WordNet", "start_pos": 153, "end_pos": 160, "type": "DATASET", "confidence": 0.9830549955368042}]}, {"text": "Therefore, it can be applied easily to anew domain, sense inventory or different languages, given sufficient documents.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Classification performance (Baseline)", "labels": [], "entities": [{"text": "Classification", "start_pos": 10, "end_pos": 24, "type": "TASK", "confidence": 0.9477760791778564}]}, {"text": " Table 2: The # of candidate senses (WordNet)", "labels": [], "entities": [{"text": "WordNet)", "start_pos": 37, "end_pos": 45, "type": "DATASET", "confidence": 0.9636026620864868}]}, {"text": " Table 3: The results against SFC resource", "labels": [], "entities": [{"text": "SFC", "start_pos": 30, "end_pos": 33, "type": "DATASET", "confidence": 0.9689881801605225}]}, {"text": " Table 4: IDSS against the first sense heuristic (WordNet)", "labels": [], "entities": [{"text": "WordNet", "start_pos": 50, "end_pos": 57, "type": "DATASET", "confidence": 0.9534988403320312}]}, {"text": " Table 5: Text classification performance (Baseline)", "labels": [], "entities": [{"text": "Text classification", "start_pos": 10, "end_pos": 29, "type": "TASK", "confidence": 0.8449642062187195}]}, {"text": " Table 6: The # of selected senses (EDR)", "labels": [], "entities": [{"text": "EDR", "start_pos": 36, "end_pos": 39, "type": "METRIC", "confidence": 0.745756208896637}]}]}