{"title": [{"text": "Using Multiple Sources to Construct a Sentiment Sensitive Thesaurus for Cross-Domain Sentiment Classification", "labels": [], "entities": [{"text": "Cross-Domain Sentiment Classification", "start_pos": 72, "end_pos": 109, "type": "TASK", "confidence": 0.6820584436257681}]}], "abstractContent": [{"text": "We describe a sentiment classification method that is applicable when we do not have any labeled data fora target domain but have some labeled data for multiple other domains, designated as the source domains.", "labels": [], "entities": [{"text": "sentiment classification", "start_pos": 14, "end_pos": 38, "type": "TASK", "confidence": 0.9122990369796753}]}, {"text": "We automatically create a sentiment sensitive thesaurus using both labeled and unlabeled data from multiple source domains to find the association between words that express similar sentiments in different domains.", "labels": [], "entities": []}, {"text": "The created thesaurus is then used to expand feature vectors to train a binary classifier.", "labels": [], "entities": []}, {"text": "Unlike previous cross-domain sentiment classification methods , our method can efficiently learn from multiple source domains.", "labels": [], "entities": [{"text": "cross-domain sentiment classification", "start_pos": 16, "end_pos": 53, "type": "TASK", "confidence": 0.6870921154816946}]}, {"text": "Our method significantly outperforms numerous baselines and returns results that are better than or comparable to previous cross-domain sentiment classification methods on a benchmark dataset containing Amazon user reviews for different types of products.", "labels": [], "entities": [{"text": "cross-domain sentiment classification", "start_pos": 123, "end_pos": 160, "type": "TASK", "confidence": 0.6890187462170919}]}], "introductionContent": [{"text": "Users express opinions about products or services they consume in blog posts, shopping sites, or review sites.", "labels": [], "entities": []}, {"text": "It is useful for both consumers as well as for producers to know what general public think about a particular product or service.", "labels": [], "entities": []}, {"text": "Automatic document level sentiment classification () is the task of classifying a given review with respect to the sentiment expressed by the author of the review.", "labels": [], "entities": [{"text": "Automatic document level sentiment classification", "start_pos": 0, "end_pos": 49, "type": "TASK", "confidence": 0.6790638208389282}]}, {"text": "For example, a sentiment classifier might classify a user review about a movie as positive or negative depending on the sentiment expressed in the review.", "labels": [], "entities": []}, {"text": "Sentiment classification has been applied in numerous tasks such as opinion mining, opinion summarization (, contextual advertising, and market analysis ().", "labels": [], "entities": [{"text": "Sentiment classification", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.9605557322502136}, {"text": "opinion mining", "start_pos": 68, "end_pos": 82, "type": "TASK", "confidence": 0.8629247844219208}, {"text": "opinion summarization", "start_pos": 84, "end_pos": 105, "type": "TASK", "confidence": 0.7984972298145294}, {"text": "market analysis", "start_pos": 137, "end_pos": 152, "type": "TASK", "confidence": 0.7043920308351517}]}, {"text": "Supervised learning algorithms that require labeled data have been successfully used to build sentiment classifiers fora specific domain ().", "labels": [], "entities": []}, {"text": "However, sentiment is expressed differently in different domains, and it is costly to annotate data for each new domain in which we would like to apply a sentiment classifier.", "labels": [], "entities": []}, {"text": "For example, in the domain of reviews about electronics products, the words \"durable\" and \"light\" are used to express positive sentiment, whereas \"expensive\" and \"short battery life\" often indicate negative sentiment.", "labels": [], "entities": []}, {"text": "On the other hand, if we consider the books domain the words \"exciting\" and \"thriller\" express positive sentiment, whereas the words \"boring\" and \"lengthy\" usually express negative sentiment.", "labels": [], "entities": []}, {"text": "A classifier trained on one domain might not perform well on a different domain because it would fail to learn the sentiment of the unseen words.", "labels": [], "entities": []}, {"text": "Work in cross-domain sentiment classification) focuses on the challenge of training a classifier from one or more domains (source domains) and applying the trained classifier in a different domain (target domain).", "labels": [], "entities": [{"text": "cross-domain sentiment classification", "start_pos": 8, "end_pos": 45, "type": "TASK", "confidence": 0.7609498500823975}]}, {"text": "A crossdomain sentiment classification system must overcome two main challenges.", "labels": [], "entities": [{"text": "crossdomain sentiment classification", "start_pos": 2, "end_pos": 38, "type": "TASK", "confidence": 0.8738190134366354}]}, {"text": "First, it must identify which source domain features are related to which target domain features.", "labels": [], "entities": []}, {"text": "Second, it requires a learning framework to incorporate the information re-132 garding the relatedness of source and target domain features.", "labels": [], "entities": []}, {"text": "Following previous work, we define crossdomain sentiment classification as the problem of learning a binary classifier (i.e. positive or negative sentiment) given a small set of labeled data for the source domain, and unlabeled data for both source and target domains.", "labels": [], "entities": [{"text": "crossdomain sentiment classification", "start_pos": 35, "end_pos": 71, "type": "TASK", "confidence": 0.836338460445404}]}, {"text": "In particular, no labeled data is provided for the target domain.", "labels": [], "entities": []}, {"text": "In this paper, we describe a cross-domain sentiment classification method using an automatically created sentiment sensitive thesaurus.", "labels": [], "entities": [{"text": "cross-domain sentiment classification", "start_pos": 29, "end_pos": 66, "type": "TASK", "confidence": 0.65934090813001}]}, {"text": "We use labeled data from multiple source domains and unlabeled data from source and target domains to represent the distribution of features.", "labels": [], "entities": []}, {"text": "We represent a lexical element (i.e. a unigram or a bigram of word lemma) in a review using a feature vector.", "labels": [], "entities": []}, {"text": "Next, for each lexical element we measure its relatedness to other lexical elements and group related lexical elements to create a thesaurus.", "labels": [], "entities": []}, {"text": "The thesaurus captures the relatedness among lexical elements that appear in source and target domains based on the contexts in which the lexical elements appear (their distributional context).", "labels": [], "entities": []}, {"text": "A distinctive aspect of our approach is that, in addition to the usual co-occurrence features typically used in characterizing a word's distributional context, we make use, where possible, of the sentiment label of a document: i.e. sentiment labels form part of our context features.", "labels": [], "entities": []}, {"text": "This is what makes the distributional thesaurus sensitive to sentiment.", "labels": [], "entities": []}, {"text": "Unlabeled data is cheaper to collect compared to labeled data and is often available in large quantities.", "labels": [], "entities": []}, {"text": "The use of unlabeled data enables us to accurately estimate the distribution of words in source and target domains.", "labels": [], "entities": []}, {"text": "Our method can learn from a large amount of unlabeled data to leverage a robust cross-domain sentiment classifier.", "labels": [], "entities": [{"text": "cross-domain sentiment classifier", "start_pos": 80, "end_pos": 113, "type": "TASK", "confidence": 0.6353809237480164}]}, {"text": "We model the cross-domain sentiment classification problem as one of feature expansion, where we append additional related features to feature vectors that represent source and target domain reviews in order to reduce the mismatch of features between the two domains.", "labels": [], "entities": [{"text": "cross-domain sentiment classification", "start_pos": 13, "end_pos": 50, "type": "TASK", "confidence": 0.789594034353892}]}, {"text": "Methods that use related features have been successfully used in numerous tasks such as query expansion, and document classification ().", "labels": [], "entities": [{"text": "query expansion", "start_pos": 88, "end_pos": 103, "type": "TASK", "confidence": 0.8173824548721313}, {"text": "document classification", "start_pos": 109, "end_pos": 132, "type": "TASK", "confidence": 0.8026018440723419}]}, {"text": "However, feature expansion techniques have not previously been applied to the task of cross-domain sentiment classification.", "labels": [], "entities": [{"text": "feature expansion", "start_pos": 9, "end_pos": 26, "type": "TASK", "confidence": 0.720306858420372}, {"text": "cross-domain sentiment classification", "start_pos": 86, "end_pos": 123, "type": "TASK", "confidence": 0.7757381796836853}]}, {"text": "In our method, we use the automatically created thesaurus to expand feature vectors in a binary classifier at train and test times by introducing related lexical elements from the thesaurus.", "labels": [], "entities": []}, {"text": "We use L1 regularized logistic regression as the classification algorithm.", "labels": [], "entities": []}, {"text": "(However, the method is agnostic to the properties of the classifier and can be used to expand feature vectors for any binary classifier).", "labels": [], "entities": []}, {"text": "L1 regularization enables us to select a small subset of features for the classifier.", "labels": [], "entities": []}, {"text": "Unlike previous work which attempts to learn a cross-domain classifier using a single source domain, we leverage data from multiple source domains to learn a robust classifier that generalizes across multiple domains.", "labels": [], "entities": []}, {"text": "Our contributions can be summarized as follows.", "labels": [], "entities": []}, {"text": "\u2022 We describe a fully automatic method to create a thesaurus that is sensitive to the sentiment of words expressed in different domains.", "labels": [], "entities": []}, {"text": "\u2022 We describe a method to use the created thesaurus to expand feature vectors at train and test times in a binary classifier.", "labels": [], "entities": []}], "datasetContent": [{"text": "To evaluate our method we use the cross-domain sentiment classification dataset prepared by.", "labels": [], "entities": [{"text": "cross-domain sentiment classification", "start_pos": 34, "end_pos": 71, "type": "TASK", "confidence": 0.6742733816305796}]}, {"text": "This dataset consists of Amazon product reviews for four different product types: books (B), DVDs (D), electronics (E) and kitchen appliances (K).", "labels": [], "entities": []}, {"text": "There are 1000 positive and 1000 negative labeled reviews for each domain.", "labels": [], "entities": []}, {"text": "Moreover, the dataset contains some unlabeled reviews (on average 17, 547) for each domain.", "labels": [], "entities": []}, {"text": "This benchmark dataset has been used in much previous work on cross-domain sentiment classification and by evaluating on it we can directly compare our method against existing approaches.", "labels": [], "entities": [{"text": "cross-domain sentiment classification", "start_pos": 62, "end_pos": 99, "type": "TASK", "confidence": 0.8173715670903524}]}, {"text": "Following previous work, we randomly select 800 positive and 800 negative labeled reviews from each domain as training instances (i.e. 1600 \u00d7 4 = 6400); the remainder is used for testing (i.e. 400 \u00d7 4 = 1600).", "labels": [], "entities": []}, {"text": "In our experiments, we select each domain in turn as the target domain, with one or more other domains as sources.", "labels": [], "entities": []}, {"text": "Note that when we combine more than one source domain we limit the total number of source domain labeled reviews to 1600, balanced between the domains.", "labels": [], "entities": []}, {"text": "For example, if we combine two source domains, then we select 400 positive and 400 negative labeled reviews from each domain giving (400 + 400) \u00d7 2 = 1600.", "labels": [], "entities": []}, {"text": "This enables us to perform a fair evaluation when combining multiple source domains.", "labels": [], "entities": []}, {"text": "The evaluation metric is classification accuracy on a target domain, computed as the percentage of correctly classified target domain reviews out of the total number of reviews in the target domain.", "labels": [], "entities": [{"text": "classification", "start_pos": 25, "end_pos": 39, "type": "TASK", "confidence": 0.9556658267974854}, {"text": "accuracy", "start_pos": 40, "end_pos": 48, "type": "METRIC", "confidence": 0.8902505040168762}]}], "tableCaptions": [{"text": " Table 3: Cross-domain sentiment classification accuracy.", "labels": [], "entities": [{"text": "Cross-domain sentiment classification", "start_pos": 10, "end_pos": 47, "type": "TASK", "confidence": 0.8316096266110738}, {"text": "accuracy", "start_pos": 48, "end_pos": 56, "type": "METRIC", "confidence": 0.9772832989692688}]}]}