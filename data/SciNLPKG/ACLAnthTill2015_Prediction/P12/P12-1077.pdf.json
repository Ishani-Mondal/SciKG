{"title": [{"text": "Finding Salient Dates for Building Thematic Timelines", "labels": [], "entities": []}], "abstractContent": [{"text": "We present an approach for detecting salient (important) dates in texts in order to automatically build event timelines from a search query (e.g. the name of an event or person, etc.).", "labels": [], "entities": []}, {"text": "This work was carried out on a corpus of newswire texts in English provided by the Agence France Presse (AFP).", "labels": [], "entities": [{"text": "Agence France Presse (AFP)", "start_pos": 83, "end_pos": 109, "type": "DATASET", "confidence": 0.821002185344696}]}, {"text": "In order to extract salient dates that warrant inclusion in an event timeline, we first recognize and normalize temporal expressions in texts and then use a machine-learning approach to extract salient dates that relate to a particular topic.", "labels": [], "entities": []}, {"text": "We fo-cused only on extracting the dates and not the events to which they are related.", "labels": [], "entities": []}], "introductionContent": [{"text": "Our aim here was to build thematic timelines fora general domain topic defined by a user query.", "labels": [], "entities": []}, {"text": "This task, which involves the extraction of important events, is related to the tasks of Retrospective Event Detection (, or New Event Detection, as defined for example in Topic Detection and Tracking (TDT) campaigns.", "labels": [], "entities": [{"text": "Retrospective Event Detection", "start_pos": 89, "end_pos": 118, "type": "TASK", "confidence": 0.6208959023157755}, {"text": "Topic Detection and Tracking (TDT) campaigns", "start_pos": 172, "end_pos": 216, "type": "TASK", "confidence": 0.826064933091402}]}, {"text": "The majority of systems designed to tackle this task make use of textual information in a bag-ofwords manner.", "labels": [], "entities": []}, {"text": "They use little temporal information, generally only using document metadata, such as the document creation time.", "labels": [], "entities": []}, {"text": "The few systems that do make use of temporal information (such as the now discontinued Google timeline), only extract absolute, full dates (that feature a day, month and year).", "labels": [], "entities": [{"text": "Google timeline", "start_pos": 87, "end_pos": 102, "type": "DATASET", "confidence": 0.9228077828884125}]}, {"text": "In our corpus, described in Section 3.1, we found that only 7% of extracted temporal expressions are absolute dates.", "labels": [], "entities": []}, {"text": "We distinguish our work from that of previous researchers in that we have focused primarily on extracted temporal information as opposed to other textual content.", "labels": [], "entities": []}, {"text": "We show that using linguistic temporal processing helps extract important events in texts.", "labels": [], "entities": []}, {"text": "Our system extracts a maximum of temporal information and uses only this information to detect salient dates for the construction of event timelines.", "labels": [], "entities": []}, {"text": "Other types of content are used for initial thematic document retrieval.", "labels": [], "entities": [{"text": "initial thematic document retrieval", "start_pos": 36, "end_pos": 71, "type": "TASK", "confidence": 0.7648146748542786}]}, {"text": "Output is a list of dates, ranked from most important to least important with respect to the given topic.", "labels": [], "entities": [{"text": "Output", "start_pos": 0, "end_pos": 6, "type": "METRIC", "confidence": 0.9078231453895569}]}, {"text": "Each date is presented with a set of relevant sentences.", "labels": [], "entities": []}, {"text": "We can see this work as anew, easily evaluable task of \"date extraction\", which is an important component of timeline summarization.", "labels": [], "entities": [{"text": "date extraction", "start_pos": 56, "end_pos": 71, "type": "TASK", "confidence": 0.6560597866773605}, {"text": "timeline summarization", "start_pos": 109, "end_pos": 131, "type": "TASK", "confidence": 0.5934443771839142}]}, {"text": "In what follows, we first review some of the related work in Section 2.", "labels": [], "entities": []}, {"text": "Section 3 presents the resources used and gives an overview of the system.", "labels": [], "entities": []}, {"text": "The system used for temporal analysis is described in Section 4, and the strategy used for indexing and finding salient dates, as well as the results obtained, are given in Section 5 1 .", "labels": [], "entities": [{"text": "temporal analysis", "start_pos": 20, "end_pos": 37, "type": "TASK", "confidence": 0.6722560673952103}]}], "datasetContent": [{"text": "In Section 5.1, we propose two baseline approaches in order to give a good idea of the difficulty of the task (Section 5.4 also discusses this point).", "labels": [], "entities": []}, {"text": "In Section 5.2, we present our experiments using simple filtering and statistics on dates calculated by Lucene.", "labels": [], "entities": [{"text": "Lucene", "start_pos": 104, "end_pos": 110, "type": "DATASET", "confidence": 0.8618579506874084}]}, {"text": "Finally, Section 5.3 gives details of our experiments with a learning approach.", "labels": [], "entities": []}, {"text": "In our experiments, we used three different values to rank dates: \u2022 occ(d) is the number of textual units (documents or sentences) containing the dated.", "labels": [], "entities": [{"text": "occ(d)", "start_pos": 68, "end_pos": 74, "type": "METRIC", "confidence": 0.935981959104538}]}, {"text": "\u2022 Lucene provides ranked documents together with their relevance score.", "labels": [], "entities": [{"text": "Lucene", "start_pos": 2, "end_pos": 8, "type": "DATASET", "confidence": 0.932981550693512}, {"text": "relevance score", "start_pos": 55, "end_pos": 70, "type": "METRIC", "confidence": 0.9472627639770508}]}, {"text": "luc(d) is the sum of Lucene scores for textual units containing the dated.", "labels": [], "entities": []}, {"text": "\u2022 An adaptation of classical tf.idf for dates: where f (d) is the number of occurrences of dated in the sentence (generally, f (d) = 1), N is the number of indexed sentences and df (d) is the number of sentences containing dated.", "labels": [], "entities": []}, {"text": "In all experiments (including baselines), timelines have been built by considering only dates between the first and the last dates of the corresponding manual chronology.", "labels": [], "entities": []}, {"text": "Processing runs were evaluated on manually-written chronologies (see Section 3.2) according to Mean Average Precision (MAP), which is a widely accepted metric for ranked lists.", "labels": [], "entities": [{"text": "Mean Average Precision (MAP)", "start_pos": 95, "end_pos": 123, "type": "METRIC", "confidence": 0.9753541449705759}]}, {"text": "MAP gives a higher weight to higher ranked elements than lower ranked elements.", "labels": [], "entities": [{"text": "MAP", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.5026407837867737}]}, {"text": "Significance of evaluation results are indicated by the p-value results of the Student's t-test (t(90) = 1.9867).: MAP results for baseline runs.", "labels": [], "entities": [{"text": "MAP", "start_pos": 115, "end_pos": 118, "type": "METRIC", "confidence": 0.9727938771247864}]}, {"text": "Chronologies hand-written by journalists area very useful resources for evaluation of our system, as they are completely dissociated from our research and are an exact representation of the output we aim to obtain.", "labels": [], "entities": []}, {"text": "However, assembling such a chronology is a very subjective task, and no clear method for evaluation agreement between two journalists seems immediately apparent.", "labels": [], "entities": []}, {"text": "Only experts can build such chronologies, and calculating this agreement would require at least two experts from each domain, which are hard to come by.", "labels": [], "entities": []}, {"text": "One may then consider our system as a useful tool for building a chronology more objectively.", "labels": [], "entities": []}, {"text": "To illustrate this point, we chose four specific topics and showed one of our runs on each topic to an AFP expert for these subjects.", "labels": [], "entities": [{"text": "AFP", "start_pos": 103, "end_pos": 106, "type": "DATASET", "confidence": 0.8984347581863403}]}, {"text": "We asked him to assess the first 30 dates of these runs.", "labels": [], "entities": []}, {"text": "Namely, \"Arab revolt timeline for Morocco\", \"Kyrgyzstan unrest timeline\", \"Lebanon's new government: a timeline\", \"Libya timeline\".: Average precision results for manual evaluation on 4 topics, against the original chronologies (AP C ), and the expert assessment (AP E ).", "labels": [], "entities": [{"text": "precision", "start_pos": 141, "end_pos": 150, "type": "METRIC", "confidence": 0.9942682981491089}, {"text": "AP C )", "start_pos": 229, "end_pos": 235, "type": "METRIC", "confidence": 0.9531063238779703}, {"text": "expert assessment (AP E )", "start_pos": 245, "end_pos": 270, "type": "METRIC", "confidence": 0.9235343337059021}]}, {"text": "presents results for this evaluation, comparing average precision values obtained 1) against the original, manual chronologies (AP C ), and 2) against the expert assessment (AP E ).", "labels": [], "entities": [{"text": "precision", "start_pos": 56, "end_pos": 65, "type": "METRIC", "confidence": 0.9554367065429688}, {"text": "expert assessment (AP E )", "start_pos": 155, "end_pos": 180, "type": "METRIC", "confidence": 0.9127174317836761}]}, {"text": "These values show that, for 3 runs out of 4, many dates returned by the system are considered as valid by the expert, even if not presented in the original chronology.", "labels": [], "entities": []}, {"text": "Even if this experiment is not strong enough to lead to a formal conclusion (post-hoc evaluation with only 4 topics and a single assessor), this tends to show that our system produces usable outputs and that our system can be of help to journalists by providing them with chronologies that are as useful and objective as possible.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: MAP results for baseline runs.", "labels": [], "entities": [{"text": "MAP", "start_pos": 10, "end_pos": 13, "type": "METRIC", "confidence": 0.8783029913902283}]}, {"text": " Table 2: MAP results for salient date extraction with XIP  and simple filtering. The significance of the improvement  due to filtering wrt no filtering is indicated by the Student  t-test (  *  : p < 0.05 (significant);  *  *  : p < 0.01 (highly  significant)). The improvement due to using tf.idf (d) as  opposed to occ(d) is also highly significant.", "labels": [], "entities": [{"text": "date extraction", "start_pos": 34, "end_pos": 49, "type": "TASK", "confidence": 0.6950243413448334}]}, {"text": " Table 4: Average precision results for manual evaluation  on 4 topics, against the original chronologies (AP C ), and  the expert assessment (AP E ).", "labels": [], "entities": [{"text": "precision", "start_pos": 18, "end_pos": 27, "type": "METRIC", "confidence": 0.9948428273200989}, {"text": "AP C )", "start_pos": 107, "end_pos": 113, "type": "METRIC", "confidence": 0.890112022558848}, {"text": "expert assessment (AP E )", "start_pos": 124, "end_pos": 149, "type": "METRIC", "confidence": 0.9209719002246857}]}]}