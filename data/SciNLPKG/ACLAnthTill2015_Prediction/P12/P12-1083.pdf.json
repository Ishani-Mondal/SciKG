{"title": [{"text": "Chinese Comma Disambiguation for Discourse Analysis", "labels": [], "entities": [{"text": "Chinese Comma Disambiguation", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.7552229166030884}, {"text": "Discourse Analysis", "start_pos": 33, "end_pos": 51, "type": "TASK", "confidence": 0.7534344494342804}]}], "abstractContent": [{"text": "The Chinese comma signals the boundary of discourse units and also anchors discourse relations between adjacent text spans.", "labels": [], "entities": []}, {"text": "In this work, we propose a discourse structure-oriented classification of the comma that can be automatically extracted from the Chinese Treebank based on syntactic patterns.", "labels": [], "entities": [{"text": "Chinese Treebank", "start_pos": 129, "end_pos": 145, "type": "DATASET", "confidence": 0.9697330296039581}]}, {"text": "We then experimented with two supervised learning methods that automatically disambiguate the Chinese comma based on this classification.", "labels": [], "entities": []}, {"text": "The first method integrates comma classification into parsing, and the second method adopts a \"post-processing\" approach that extracts features from automatic parses to train a classifier.", "labels": [], "entities": [{"text": "comma classification", "start_pos": 28, "end_pos": 48, "type": "TASK", "confidence": 0.7807585299015045}, {"text": "parsing", "start_pos": 54, "end_pos": 61, "type": "TASK", "confidence": 0.9582598805427551}]}, {"text": "The experimental results show that the second approach compares favorably against the first approach.", "labels": [], "entities": []}], "introductionContent": [{"text": "The Chinese comma, which looks graphically very similar to its English counterpart, is functionally quite different.", "labels": [], "entities": []}, {"text": "It has attracted a significant amount of research that studied the problem from the viewpoint of natural language processing.", "labels": [], "entities": [{"text": "natural language processing", "start_pos": 97, "end_pos": 124, "type": "TASK", "confidence": 0.6467930873235067}]}, {"text": "For example, and view the disambiguation of the Chinese comma as away of breaking up long Chinese sentences into shorter ones to facilitate parsing.", "labels": [], "entities": []}, {"text": "The idea is to split along sentence into multiple comma-separated segments, parse them individually, and reconstruct the syntactic parse for the original sentence.", "labels": [], "entities": []}, {"text": "Although both studies show a positive impact of this approach, comma disambiguation is viewed merely as a convenient tool to help achieve a more important goal.", "labels": [], "entities": [{"text": "comma disambiguation", "start_pos": 63, "end_pos": 83, "type": "TASK", "confidence": 0.8382139801979065}]}, {"text": "point out that the very reason for the existence of these long Chinese sentences is because the Chinese comma is ambiguous and in some context, it identifies the boundary of a sentence just as a period, a question mark, or an exclamation mark does.", "labels": [], "entities": []}, {"text": "The disambiguation of comma is viewed as a necessary step to detect sentence boundaries in Chinese and it can benefit a whole range of downstream NLP applications such as syntactic parsing and Machine Translation.", "labels": [], "entities": [{"text": "syntactic parsing", "start_pos": 171, "end_pos": 188, "type": "TASK", "confidence": 0.7581882476806641}, {"text": "Machine Translation", "start_pos": 193, "end_pos": 212, "type": "TASK", "confidence": 0.8499037325382233}]}, {"text": "In Machine Translation, for example, it is very typical for \"one\" Chinese sentence to be translated into multiple English sentences, with each comma-separated segment corresponding to one English sentence.", "labels": [], "entities": [{"text": "Machine Translation", "start_pos": 3, "end_pos": 22, "type": "TASK", "confidence": 0.810312032699585}]}, {"text": "In the present work, we expand this view and propose to look at the Chinese comma in the context of discourse analysis.", "labels": [], "entities": [{"text": "discourse analysis", "start_pos": 100, "end_pos": 118, "type": "TASK", "confidence": 0.7123816460371017}]}, {"text": "The Chinese comma is viewed as a delimiter of elementary discourse units (EDUs), in the sense of the Rhetorical Structure Theory (.", "labels": [], "entities": []}, {"text": "It is also considered to be the anchor of discourse relations, in the sense of the Penn Discourse Treebank (PDT) (.", "labels": [], "entities": [{"text": "Penn Discourse Treebank (PDT)", "start_pos": 83, "end_pos": 112, "type": "DATASET", "confidence": 0.9491332769393921}]}, {"text": "Disambiguating the comma is thus necessary for the purpose of discourse segmentation, the identification of EDUs, a first step in building up the discourse structure of a Chinese text.", "labels": [], "entities": [{"text": "discourse segmentation", "start_pos": 62, "end_pos": 84, "type": "TASK", "confidence": 0.734761044383049}, {"text": "identification of EDUs", "start_pos": 90, "end_pos": 112, "type": "TASK", "confidence": 0.7700190742810568}]}, {"text": "Developing a supervised or semi-supervised model of discourse segmentation would require ground truth annotated based on a well-established representation scheme, but as of right now no such annotation exists for Chinese to the best of our knowledge.", "labels": [], "entities": [{"text": "discourse segmentation", "start_pos": 52, "end_pos": 74, "type": "TASK", "confidence": 0.738169401884079}]}, {"text": "However, syntactically annotated treebanks often contain important clues that can be used to infer discourse-level information.", "labels": [], "entities": []}, {"text": "We present a method of automatically deriving a preliminary form of discourse structure anchored by the Chinese comma from the Penn Chinese Treebank (CTB) (), and using this information to train and test supervised models.", "labels": [], "entities": [{"text": "Penn Chinese Treebank (CTB)", "start_pos": 127, "end_pos": 154, "type": "DATASET", "confidence": 0.9691634873549143}]}, {"text": "This discourse information is formalized as a classification of the Chinese comma, with each class representing the boundary of an elementary discourse unit as well as the anchor of a coarse-grained discourse relation between the two discourse units that it delimits.", "labels": [], "entities": []}, {"text": "We then develop two comma classification methods.", "labels": [], "entities": [{"text": "comma classification", "start_pos": 20, "end_pos": 40, "type": "TASK", "confidence": 0.7033504396677017}]}, {"text": "In the first method, we replace the part-of-speech (POS) tag of each comma in the CTB with a derived discourse category and retrain a state-of-theart Chinese parser on the relabeled data.", "labels": [], "entities": []}, {"text": "We then evaluate how accurately the commas are classified in the parsing process.", "labels": [], "entities": [{"text": "parsing process", "start_pos": 65, "end_pos": 80, "type": "TASK", "confidence": 0.8952030837535858}]}, {"text": "In the second method, we parse these sentences and extract lexical and syntactic information as features to predict these new discourse categories.", "labels": [], "entities": []}, {"text": "The second approach gives us more control over what features to extract and our results show that it compares favorably against the first approach.", "labels": [], "entities": []}, {"text": "The rest of the paper is organized as follows.", "labels": [], "entities": []}, {"text": "In Section 2, we present our approach to automatically extract discourse information from a syntactically annotated treebank and present our classification scheme.", "labels": [], "entities": []}, {"text": "In Section 3, we describe our supervised learning methods and the features we extracted.", "labels": [], "entities": []}, {"text": "Section 4 presents our experiment setup and experimental results.", "labels": [], "entities": []}, {"text": "Related work is reviewed in Section 5.", "labels": [], "entities": []}, {"text": "We conclude in Section 6.", "labels": [], "entities": []}], "datasetContent": [{"text": "We use the CTB 6.0 in our experiments and divide it into training, development and test sets using the data split recommended in the CTB 6.0 documentation, as shown in.", "labels": [], "entities": [{"text": "CTB 6.0", "start_pos": 11, "end_pos": 18, "type": "DATASET", "confidence": 0.9569457471370697}, {"text": "CTB 6.0 documentation", "start_pos": 133, "end_pos": 154, "type": "DATASET", "confidence": 0.9479125539461771}]}, {"text": "There are 5436 commas in the test set, including 1327 commas that are sentence boundaries (SB), 539 commas that connect coordinated IPs (IP COORD), 1173 commas that join coordinated VPs (VP COORD), 379 commas that delimits a subordinate clause and its main clause (ADJ), 314 commas that anchor complementation relations (COMP), and 1625 commas that belong to the OTHER category.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Overall accuracy of the two methods as well as  the results for each individual category.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 18, "end_pos": 26, "type": "METRIC", "confidence": 0.9994781613349915}]}, {"text": " Table 3: Subject continuity results based on Maximum  Entropy model", "labels": [], "entities": [{"text": "Subject continuity", "start_pos": 10, "end_pos": 28, "type": "TASK", "confidence": 0.8209612667560577}]}, {"text": " Table 4: Results on different genres based on Maximum  Entropy model", "labels": [], "entities": []}, {"text": " Table 5: Comparison of (Xue and Yang, 2011) and the  present work based on Maximum Entropy model", "labels": [], "entities": []}]}