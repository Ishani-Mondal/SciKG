{"title": [{"text": "Word Sense Disambiguation Improves Information Retrieval", "labels": [], "entities": [{"text": "Word Sense Disambiguation Improves Information Retrieval", "start_pos": 0, "end_pos": 56, "type": "TASK", "confidence": 0.8396106461683909}]}], "abstractContent": [{"text": "Previous research has conflicting conclusions on whether word sense disambiguation (WSD) systems can improve information retrieval (IR) performance.", "labels": [], "entities": [{"text": "word sense disambiguation (WSD)", "start_pos": 57, "end_pos": 88, "type": "TASK", "confidence": 0.7887697567542394}, {"text": "information retrieval (IR)", "start_pos": 109, "end_pos": 135, "type": "TASK", "confidence": 0.8197671175003052}]}, {"text": "In this paper, we propose a method to estimate sense distributions for short queries.", "labels": [], "entities": []}, {"text": "Together with the senses predicted for words in documents, we propose a novel approach to incorporate word senses into the language modeling approach to IR and also exploit the integration of synonym relations.", "labels": [], "entities": [{"text": "IR", "start_pos": 153, "end_pos": 155, "type": "TASK", "confidence": 0.9727317690849304}]}, {"text": "Our experimental results on standard TREC collections show that using the word senses tagged by a supervised WSD system , we obtain significant improvements over a state-of-the-art IR system.", "labels": [], "entities": [{"text": "TREC collections", "start_pos": 37, "end_pos": 53, "type": "DATASET", "confidence": 0.7144220471382141}]}], "introductionContent": [{"text": "Word sense disambiguation (WSD) is the task of identifying the correct meaning of a word in context.", "labels": [], "entities": [{"text": "Word sense disambiguation (WSD)", "start_pos": 0, "end_pos": 31, "type": "TASK", "confidence": 0.8371227333943049}, {"text": "identifying the correct meaning of a word in context", "start_pos": 47, "end_pos": 99, "type": "TASK", "confidence": 0.4860156642066108}]}, {"text": "As a basic semantic understanding task at the lexical level, WSD is a fundamental problem in natural language processing.", "labels": [], "entities": [{"text": "semantic understanding", "start_pos": 11, "end_pos": 33, "type": "TASK", "confidence": 0.772109717130661}, {"text": "WSD", "start_pos": 61, "end_pos": 64, "type": "TASK", "confidence": 0.977400004863739}, {"text": "natural language processing", "start_pos": 93, "end_pos": 120, "type": "TASK", "confidence": 0.6438483496507009}]}, {"text": "It can be potentially used as a component in many applications, such as machine translation (MT) and information retrieval (IR).", "labels": [], "entities": [{"text": "machine translation (MT)", "start_pos": 72, "end_pos": 96, "type": "TASK", "confidence": 0.8567384362220765}, {"text": "information retrieval (IR)", "start_pos": 101, "end_pos": 127, "type": "TASK", "confidence": 0.8593927204608918}]}, {"text": "In recent years, driven by Senseval/Semeval workshops, WSD systems achieve promising performance.", "labels": [], "entities": [{"text": "WSD", "start_pos": 55, "end_pos": 58, "type": "TASK", "confidence": 0.945723831653595}]}, {"text": "In the application of WSD to MT, research has shown that integrating WSD inappropriate ways significantly improves the performance of MT systems (.", "labels": [], "entities": [{"text": "WSD", "start_pos": 22, "end_pos": 25, "type": "TASK", "confidence": 0.9428655505180359}, {"text": "MT", "start_pos": 29, "end_pos": 31, "type": "TASK", "confidence": 0.921068549156189}, {"text": "MT", "start_pos": 134, "end_pos": 136, "type": "TASK", "confidence": 0.9895373582839966}]}, {"text": "In the application to IR, WSD can bring two kinds of benefits.", "labels": [], "entities": [{"text": "IR", "start_pos": 22, "end_pos": 24, "type": "TASK", "confidence": 0.8927558660507202}, {"text": "WSD", "start_pos": 26, "end_pos": 29, "type": "TASK", "confidence": 0.9417778253555298}]}, {"text": "First, queries may contain ambiguous words (terms), which have multiple meanings.", "labels": [], "entities": []}, {"text": "The ambiguities of these query words can hurt retrieval precision.", "labels": [], "entities": [{"text": "precision", "start_pos": 56, "end_pos": 65, "type": "METRIC", "confidence": 0.9595166444778442}]}, {"text": "Identifying the correct meaning of the ambiguous words in both queries and documents can help improve retrieval precision.", "labels": [], "entities": [{"text": "precision", "start_pos": 112, "end_pos": 121, "type": "METRIC", "confidence": 0.9786993265151978}]}, {"text": "Second, query words may have tightly related meanings with other words not in the query.", "labels": [], "entities": []}, {"text": "Making use of these relations between words can improve retrieval recall.", "labels": [], "entities": [{"text": "recall", "start_pos": 66, "end_pos": 72, "type": "METRIC", "confidence": 0.9298073053359985}]}, {"text": "Overall, IR systems can potentially benefit from the correct meanings of words provided by WSD systems.", "labels": [], "entities": [{"text": "IR", "start_pos": 9, "end_pos": 11, "type": "TASK", "confidence": 0.9792769551277161}]}, {"text": "However, in previous investigations of the usage of WSD in IR, different researchers arrived at conflicting observations and conclusions.", "labels": [], "entities": [{"text": "WSD", "start_pos": 52, "end_pos": 55, "type": "TASK", "confidence": 0.9598211050033569}, {"text": "IR", "start_pos": 59, "end_pos": 61, "type": "TASK", "confidence": 0.9207471013069153}]}, {"text": "Some of the early research showed a drop in retrieval performance by using word senses (.", "labels": [], "entities": []}, {"text": "Some other experiments observed improvements by integrating word senses in IR systems.", "labels": [], "entities": [{"text": "IR", "start_pos": 75, "end_pos": 77, "type": "TASK", "confidence": 0.9561434388160706}]}, {"text": "This paper proposes the use of word senses to improve the performance of IR.", "labels": [], "entities": [{"text": "IR", "start_pos": 73, "end_pos": 75, "type": "TASK", "confidence": 0.9915964007377625}]}, {"text": "We propose an approach to annotate the senses for short queries.", "labels": [], "entities": []}, {"text": "We incorporate word senses into the language modeling (LM) approach to IR, and utilize sense synonym relations to further improve the performance.", "labels": [], "entities": [{"text": "IR", "start_pos": 71, "end_pos": 73, "type": "TASK", "confidence": 0.9904187321662903}]}, {"text": "Our evaluation on standard TREC 1 data sets shows that supervised WSD outperforms two other WSD baselines and significantly improves IR.", "labels": [], "entities": [{"text": "TREC 1 data sets", "start_pos": 27, "end_pos": 43, "type": "DATASET", "confidence": 0.8266425430774689}, {"text": "WSD", "start_pos": 66, "end_pos": 69, "type": "TASK", "confidence": 0.8718122243881226}, {"text": "IR", "start_pos": 133, "end_pos": 135, "type": "TASK", "confidence": 0.6453601717948914}]}, {"text": "The rest of this paper is organized as follows.", "labels": [], "entities": []}, {"text": "In Section 2, we first review previous work using WSD in IR.", "labels": [], "entities": [{"text": "IR", "start_pos": 57, "end_pos": 59, "type": "TASK", "confidence": 0.8261095285415649}]}, {"text": "Section 3 introduces the LM approach to IR, including the pseudo relevance feedback method.", "labels": [], "entities": [{"text": "IR", "start_pos": 40, "end_pos": 42, "type": "TASK", "confidence": 0.9953756332397461}]}, {"text": "We describe our WSD system and the method of generating word senses for query terms in Section 4, followed by presenting our novel method of incorporating word senses and their synonyms into the LM approach in Section 5.", "labels": [], "entities": [{"text": "WSD", "start_pos": 16, "end_pos": 19, "type": "TASK", "confidence": 0.8399403691291809}]}, {"text": "We present experiments and analyze the results in Section 6.", "labels": [], "entities": []}, {"text": "Finally, we conclude in Section 7.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section, we evaluate and analyze the models proposed in Section 5 on standard TREC collections.", "labels": [], "entities": [{"text": "TREC collections", "start_pos": 86, "end_pos": 102, "type": "DATASET", "confidence": 0.8005280494689941}]}, {"text": "We conduct experiments on the TREC collection.", "labels": [], "entities": [{"text": "TREC collection", "start_pos": 30, "end_pos": 45, "type": "DATASET", "confidence": 0.9355787038803101}]}, {"text": "The text collection C includes the documents from TREC disk 4 and 5, minus the CR (Congressional Record) corpus, with 528,155 documents in total.", "labels": [], "entities": [{"text": "TREC disk 4", "start_pos": 50, "end_pos": 61, "type": "DATASET", "confidence": 0.9157224893569946}, {"text": "CR", "start_pos": 79, "end_pos": 81, "type": "METRIC", "confidence": 0.9417193531990051}, {"text": "Congressional Record) corpus", "start_pos": 83, "end_pos": 111, "type": "DATASET", "confidence": 0.8465275466442108}]}, {"text": "In addition, the other documents in TREC disk 1 to 5 are used as the external text collection X.", "labels": [], "entities": [{"text": "TREC disk 1", "start_pos": 36, "end_pos": 47, "type": "DATASET", "confidence": 0.8953962127367655}]}, {"text": "We use 50 queries from TREC6 Ad Hoc task as the development set, and evaluate on 50 queries from TREC7 Ad Hoc task, 50 queries from TREC8 Ad Hoc task, 50 queries from ROBUST 2003 (RB03), and 49 queries from ROBUST 2004 (RB04).", "labels": [], "entities": [{"text": "TREC7 Ad Hoc task", "start_pos": 97, "end_pos": 114, "type": "DATASET", "confidence": 0.8274981826543808}, {"text": "ROBUST 2003 (RB03)", "start_pos": 167, "end_pos": 185, "type": "DATASET", "confidence": 0.905980920791626}, {"text": "ROBUST 2004 (RB04)", "start_pos": 207, "end_pos": 225, "type": "DATASET", "confidence": 0.9190272927284241}]}, {"text": "In total, our test set includes 199 queries.", "labels": [], "entities": []}, {"text": "We use the terms in the title field of TREC topics as queries.", "labels": [], "entities": [{"text": "TREC topics", "start_pos": 39, "end_pos": 50, "type": "TASK", "confidence": 0.639326423406601}]}, {"text": "shows the statistics of the five query sets.", "labels": [], "entities": []}, {"text": "The first column lists the query topics, and the column #qry is the number of queries.", "labels": [], "entities": []}, {"text": "The column Ave gives the average query length, and the column Rels is the total number of relevant documents.", "labels": [], "entities": [{"text": "Ave", "start_pos": 11, "end_pos": 14, "type": "METRIC", "confidence": 0.9905243515968323}, {"text": "Rels", "start_pos": 62, "end_pos": 66, "type": "METRIC", "confidence": 0.9925783276557922}]}, {"text": "We use the Lemur toolkit () version 4.11 as the basic retrieval tool, and select the default unigram LM approach based on KLdivergence and Dirichlet-prior smoothing method in Lemur as our basic retrieval approach.", "labels": [], "entities": []}, {"text": "Stop words are removed from queries and documents using the standard INQUERY stop words list (), and then the Porter stemmer is applied to perform stemming.", "labels": [], "entities": []}, {"text": "The stem forms are finally used for indexing and retrieval.", "labels": [], "entities": [{"text": "indexing", "start_pos": 36, "end_pos": 44, "type": "TASK", "confidence": 0.978278636932373}]}, {"text": "We set the smoothing parameter \u00b5 in Equation 3 to 400 by tuning on TREC6 query set in a range of {100, 400, 700, 1000, 1500, 2000, 3000, 4000, 5000}.", "labels": [], "entities": [{"text": "TREC6 query set", "start_pos": 67, "end_pos": 82, "type": "DATASET", "confidence": 0.6710872451464335}]}, {"text": "With this basic method, up to 10 top ranked documents D q are retrieved for each query q from the extended text collection C \u222a X, for the usage of performing PRF and generating query senses.", "labels": [], "entities": []}, {"text": "For PRF, we follow the implementation of Indri's PRF method and further apply the CE technique as described in Section 3.2.: Results on test set in MAP score.", "labels": [], "entities": [{"text": "PRF", "start_pos": 4, "end_pos": 7, "type": "TASK", "confidence": 0.9490973353385925}, {"text": "CE", "start_pos": 82, "end_pos": 84, "type": "METRIC", "confidence": 0.9784579873085022}]}, {"text": "The first three rows show the results of the top participating systems, the next row shows the performance of the baseline method, and the rest rows are the results of our method with different settings.", "labels": [], "entities": []}, {"text": "Single dagger ( \u2020 ) and double dagger ( \u2021 ) indicate statistically significant improvement over Stem prf at the 95% and 99% confidence level with a two-tailed paired t-test, respectively.", "labels": [], "entities": [{"text": "double dagger ( \u2021 )", "start_pos": 24, "end_pos": 43, "type": "METRIC", "confidence": 0.890397047996521}]}, {"text": "The best results are highlighted in bold.", "labels": [], "entities": []}, {"text": "{0.1, 0.2, ..., 0.9}.", "labels": [], "entities": []}, {"text": "The CE-PRF method with this parameter setting is chosen as the baseline.", "labels": [], "entities": []}, {"text": "To estimate the sense distributions for terms in query q, the method described in Section 4.2 is applied with D q . To disambiguate the documents in the text collection, besides the usage of the supervised WSD system described in Section 4.1, two WSD baseline methods, Even and MFS, are applied for comparison.", "labels": [], "entities": [{"text": "Even", "start_pos": 269, "end_pos": 273, "type": "METRIC", "confidence": 0.975470781326294}]}, {"text": "The method Even assigns equal probabilities to all senses for each word, and the method MFS tags the words with their corresponding most frequent senses.", "labels": [], "entities": []}, {"text": "The parameter \u03b1 in Equation 6 is tuned on TREC6 from 1 to 10 in increment of 1 for each sense tagging method.", "labels": [], "entities": [{"text": "TREC6", "start_pos": 42, "end_pos": 47, "type": "METRIC", "confidence": 0.7363342046737671}, {"text": "sense tagging", "start_pos": 88, "end_pos": 101, "type": "TASK", "confidence": 0.6282971650362015}]}, {"text": "It is set to 7, 6, and 9 for the supervised WSD method, the Even method, and the MFS method, respectively.", "labels": [], "entities": []}, {"text": "Notice that the sense in our WSD system is conducted with two parts, a morphological root and a Chinese translation.", "labels": [], "entities": [{"text": "WSD", "start_pos": 29, "end_pos": 32, "type": "TASK", "confidence": 0.8557837605476379}]}, {"text": "The Chinese parts not only disambiguate senses, but also provide clues of connections among different words.", "labels": [], "entities": []}, {"text": "Assume that the senses with the same Chinese part are synonyms, therefore, we can generate a set of synonyms for each sense, and then utilize these synonym relations in the method proposed in Section 5.2.", "labels": [], "entities": []}, {"text": "For evaluation, we use average precision (AP) as the metric to evaluate the performance on each query q: relevance(q) , where relevance(q) is the number of documents relevant to q, R is the number of retrieved documents, r is the rank, p(r) is the precision of the top r retrieved documents, and rel (r) equals to 1 if the rth document is relevant, and 0 otherwise.", "labels": [], "entities": [{"text": "average precision (AP)", "start_pos": 23, "end_pos": 45, "type": "METRIC", "confidence": 0.8921347260475159}, {"text": "precision", "start_pos": 248, "end_pos": 257, "type": "METRIC", "confidence": 0.9858285188674927}, {"text": "rel (r)", "start_pos": 296, "end_pos": 303, "type": "METRIC", "confidence": 0.9522026628255844}]}, {"text": "Mean average precision (MAP) is a metric to evaluate the performance on a set of queries Q: where |Q| is the number of queries in Q.", "labels": [], "entities": [{"text": "Mean average precision (MAP)", "start_pos": 0, "end_pos": 28, "type": "METRIC", "confidence": 0.9602282245953878}]}, {"text": "We retrieve the top-ranked 1,000 documents for each query, and use the MAP score as the main comparing metric.", "labels": [], "entities": [{"text": "MAP score", "start_pos": 71, "end_pos": 80, "type": "METRIC", "confidence": 0.9287361204624176}]}, {"text": "In, the first four columns are the MAP scores of various methods on the TREC7, TREC8, RB03, and RB04 query sets, respectively.", "labels": [], "entities": [{"text": "MAP", "start_pos": 35, "end_pos": 38, "type": "METRIC", "confidence": 0.7499183416366577}, {"text": "TREC7", "start_pos": 72, "end_pos": 77, "type": "DATASET", "confidence": 0.7840954065322876}, {"text": "TREC8", "start_pos": 79, "end_pos": 84, "type": "DATASET", "confidence": 0.5290229320526123}]}, {"text": "The column Comb shows the results on the union of the four test query sets.", "labels": [], "entities": [{"text": "Comb", "start_pos": 11, "end_pos": 15, "type": "METRIC", "confidence": 0.9229794144630432}]}, {"text": "The first three rows list the results of the top three systems that participated in the corresponding tasks.", "labels": [], "entities": []}, {"text": "The row Stem prf shows the performance of our baseline method, the stem-based CE-PRF method.", "labels": [], "entities": []}, {"text": "The column Impr calculates the percentage improvement of each method over the baseline Stem prf in column Comb.", "labels": [], "entities": [{"text": "Impr", "start_pos": 11, "end_pos": 15, "type": "METRIC", "confidence": 0.9937599301338196}]}, {"text": "The last column #ret-rel lists the total numbers of relevant documents retrieved by different methods.", "labels": [], "entities": []}, {"text": "The rows Stem prf +{MFS, Even, WSD} are the results of Stem prf incorporating with the senses generated for the original query terms, by applying the approach proposed in Section 5.1, with the MFS method, the Even method, and our supervised WSD method, respectively.", "labels": [], "entities": []}, {"text": "Comparing to the baseline method, all methods with sense integrated achieve consistent improvements on all query sets.", "labels": [], "entities": []}, {"text": "The usage of the supervised WSD method outperforms the other two WSD baselines, and it achieves sta-tistically significant improvements over Stem prf on TREC7, TREC8, and RB03.", "labels": [], "entities": [{"text": "TREC8", "start_pos": 160, "end_pos": 165, "type": "DATASET", "confidence": 0.7806389331817627}]}, {"text": "The integration of senses into the baseline method has two aspects of impact.", "labels": [], "entities": []}, {"text": "First, the morphological roots of senses conquer the irregular inflection problem.", "labels": [], "entities": []}, {"text": "Thus, the documents containing the irregular inflections are retrieved when senses are integrated.", "labels": [], "entities": []}, {"text": "For example, in topic 326 {ferry sinkings}, the stem form of sinkings is sink.", "labels": [], "entities": [{"text": "topic 326 {ferry sinkings}", "start_pos": 16, "end_pos": 42, "type": "TASK", "confidence": 0.5962752749522527}, {"text": "sink", "start_pos": 73, "end_pos": 77, "type": "METRIC", "confidence": 0.9731763601303101}]}, {"text": "As sink is an irregular verb, the usage of senses improves the retrieval recall by retrieving the documents containing the inflection forms sunk, sank, and sunken.", "labels": [], "entities": [{"text": "recall", "start_pos": 73, "end_pos": 79, "type": "METRIC", "confidence": 0.9115221500396729}]}, {"text": "Second, the senses output by supervised WSD system help identify the meanings of query terms.", "labels": [], "entities": [{"text": "WSD", "start_pos": 40, "end_pos": 43, "type": "TASK", "confidence": 0.7389384508132935}]}, {"text": "Take topic 357 {territorial waters dispute} for example, the stem form of waters is water and its appropriate sense in this query should be water (body of water) instead of the most frequent sense of water (H 2 O).", "labels": [], "entities": []}, {"text": "In Stem prf +WSD, we correctly identify the minority sense for this query term.", "labels": [], "entities": []}, {"text": "In another example, topic 425 {counterfeiting money}, the stem form of counterfeiting is counterfeit.", "labels": [], "entities": []}, {"text": "Although the most frequent sense counterfeit (not genuine) is not wrong, another sense counterfeit (forged money) is more accurate for this query term.", "labels": [], "entities": []}, {"text": "The Chinese translation in the latter sense represents the meaning of the phrase in original query.", "labels": [], "entities": []}, {"text": "Thus, Stem prf +WSD outperforms the other two methods on this query by assigning the highest probability for this sense.", "labels": [], "entities": []}, {"text": "Overall, the performance of Stem prf +WSD is better than Stem prf +{MFS, Even} on 121 queries and 119 queries, respectively.", "labels": [], "entities": []}, {"text": "The t-test at the confidence level of 99% indicates that the improvements are statistically significant.", "labels": [], "entities": [{"text": "t-test", "start_pos": 4, "end_pos": 10, "type": "METRIC", "confidence": 0.9641304612159729}]}, {"text": "The results of expanding with synonym relations in the above three methods are shown in the last three rows, Stem prf +{MFS, Even, WSD}+Syn.", "labels": [], "entities": []}, {"text": "The integration of synonym relations further improves the performance no matter what kind of sense tagging method is applied.", "labels": [], "entities": [{"text": "sense tagging", "start_pos": 93, "end_pos": 106, "type": "TASK", "confidence": 0.718320906162262}]}, {"text": "The improvement varies with different methods on different query sets.", "labels": [], "entities": []}, {"text": "As shown in the last column of, the number of relevant documents retrieved is increased for each method.", "labels": [], "entities": []}, {"text": "Stem prf +Even+Syn retrieves more relevant documents than Stem prf +MFS+Syn, because the former method expands more senses.", "labels": [], "entities": []}, {"text": "Overall, the improvement achieved by Stem prf +WSD+Syn is larger than the other two methods.", "labels": [], "entities": []}, {"text": "It shows that the WSD technique can help choose the appropriate senses for synonym expansion.", "labels": [], "entities": [{"text": "WSD", "start_pos": 18, "end_pos": 21, "type": "TASK", "confidence": 0.8823662996292114}, {"text": "synonym expansion", "start_pos": 75, "end_pos": 92, "type": "TASK", "confidence": 0.9569924771785736}]}, {"text": "Among the different settings, Stem prf +WSD+Syn achieves the best performance.", "labels": [], "entities": []}, {"text": "Its improvement over the baseline method is statistically significant at the 95% confidence level on RB04 and at the 99% confidence level on the other three query sets, with an overall improvement of 4.39%.", "labels": [], "entities": [{"text": "RB04", "start_pos": 101, "end_pos": 105, "type": "DATASET", "confidence": 0.8996735215187073}]}, {"text": "It beats the best participated systems on three out of four query sets 5 , including TREC7, TREC8, and RB03.", "labels": [], "entities": [{"text": "TREC7", "start_pos": 85, "end_pos": 90, "type": "METRIC", "confidence": 0.5384716391563416}, {"text": "TREC8", "start_pos": 92, "end_pos": 97, "type": "METRIC", "confidence": 0.553473711013794}]}], "tableCaptions": [{"text": " Table 1: Statistics of query sets", "labels": [], "entities": []}, {"text": " Table 2: Results on test set in MAP score. The first three rows show the results of the top participating systems, the  next row shows the performance of the baseline method, and the rest rows are the results of our method with different  settings. Single dagger (  \u2020 ) and double dagger (  \u2021 ) indicate statistically significant improvement over Stem prf at the  95% and 99% confidence level with a two-tailed paired t-test, respectively. The best results are highlighted in bold.", "labels": [], "entities": [{"text": "MAP score", "start_pos": 33, "end_pos": 42, "type": "METRIC", "confidence": 0.5419626533985138}, {"text": "Single dagger (  \u2020 )", "start_pos": 250, "end_pos": 270, "type": "METRIC", "confidence": 0.9067545533180237}, {"text": "double dagger (  \u2021 )", "start_pos": 275, "end_pos": 295, "type": "METRIC", "confidence": 0.8848270058631897}]}]}