{"title": [{"text": "Discriminative Learning for Joint Template Filling", "labels": [], "entities": [{"text": "Joint Template Filling", "start_pos": 28, "end_pos": 50, "type": "TASK", "confidence": 0.7827254136403402}]}], "abstractContent": [{"text": "This paper presents a joint model for template filling, where the goal is to automatically specify the fields of target relations such as seminar announcements or corporate acquisition events.", "labels": [], "entities": [{"text": "template filling", "start_pos": 38, "end_pos": 54, "type": "TASK", "confidence": 0.852398008108139}]}, {"text": "The approach models mention detection, unification and field extraction in a flexible, feature-rich model that allows for joint modeling of interdependencies at all levels and across fields.", "labels": [], "entities": [{"text": "field extraction", "start_pos": 55, "end_pos": 71, "type": "TASK", "confidence": 0.6947475522756577}]}, {"text": "Such an approach can, for example, learn likely event durations and the fact that start times should come before end times.", "labels": [], "entities": []}, {"text": "While the joint inference space is large, we demonstrate effective learning with a Perceptron-style approach that uses simple, greedy beam decoding.", "labels": [], "entities": []}, {"text": "Empirical results in two benchmark domains demonstrate consistently strong performance on both mention detection and template filling tasks.", "labels": [], "entities": [{"text": "mention detection", "start_pos": 95, "end_pos": 112, "type": "TASK", "confidence": 0.8182190358638763}, {"text": "template filling tasks", "start_pos": 117, "end_pos": 139, "type": "TASK", "confidence": 0.8201211293538412}]}], "introductionContent": [{"text": "Information extraction (IE) systems recover structured information from text.", "labels": [], "entities": [{"text": "Information extraction (IE)", "start_pos": 0, "end_pos": 27, "type": "TASK", "confidence": 0.8529650807380676}]}, {"text": "Template filling is an IE task where the goal is to populate the fields of a target relation, for example to extract the attributes of a job posting or to recover the details of a corporate acquisition event from a news story).", "labels": [], "entities": [{"text": "Template filling", "start_pos": 0, "end_pos": 16, "type": "TASK", "confidence": 0.9015379250049591}, {"text": "IE task", "start_pos": 23, "end_pos": 30, "type": "TASK", "confidence": 0.8991291224956512}, {"text": "recover the details of a corporate acquisition event from a news story", "start_pos": 155, "end_pos": 225, "type": "TASK", "confidence": 0.5172804271181425}]}, {"text": "This task is challenging due to the wide range of cues from the input documents, as well as nontextual background knowledge, that must be considered to find the best joint assignment for the fields of the extracted relation.", "labels": [], "entities": []}, {"text": "For example, shows an extraction from CMU seminar announcement corpus).", "labels": [], "entities": [{"text": "CMU seminar announcement corpus", "start_pos": 38, "end_pos": 69, "type": "DATASET", "confidence": 0.9572426378726959}]}, {"text": "Here, the goal is to perform mention detection and extraction, by finding all of the text spans, or mentions,  that describe field values, unify these mentions by grouping them according to target field, and normalizing the results within each group to provide the final extractions.", "labels": [], "entities": [{"text": "mention detection and extraction", "start_pos": 29, "end_pos": 61, "type": "TASK", "confidence": 0.773583248257637}]}, {"text": "Each of these steps requires significant knowledge about the target relation.", "labels": [], "entities": []}, {"text": "For example, in, the mention \"3:30\" appears three times and provides the only reference to a time.", "labels": [], "entities": []}, {"text": "We must infer that this is the starting time, that the end time is never explicitly mentioned, and also that the event is in the afternoon.", "labels": [], "entities": []}, {"text": "Such inferences may not hold in more general settings, such as extraction for medical emergencies or related events.", "labels": [], "entities": [{"text": "extraction for medical emergencies", "start_pos": 63, "end_pos": 97, "type": "TASK", "confidence": 0.8485524654388428}]}, {"text": "In this paper, we present a joint modeling and learning approach for the combined tasks of mention detection, unification, and template filling, as described above.", "labels": [], "entities": [{"text": "mention detection", "start_pos": 91, "end_pos": 108, "type": "TASK", "confidence": 0.8235024809837341}, {"text": "template filling", "start_pos": 127, "end_pos": 143, "type": "TASK", "confidence": 0.8044489324092865}]}, {"text": "As we will see in Section 2, previous work has mostly focused on learning tagging models for mention detection, which can be difficult to aggregate into a full template extraction, or directly learning template field value extractors, often in isolation and with no reasoning across different fields in the same relation.", "labels": [], "entities": [{"text": "mention detection", "start_pos": 93, "end_pos": 110, "type": "TASK", "confidence": 0.7483647465705872}]}, {"text": "We present a simple, feature-rich, discriminative model that readily incorporates abroad range of possible constraints on the mentions and joint field assignments.", "labels": [], "entities": []}, {"text": "Such an approach allows us to learn, for each target relation, an integrated model to weight the different extraction options, including for example the likely lengths for events, or the fact that start times should come before end times.", "labels": [], "entities": []}, {"text": "However, there are significant computation challenges that come with this style of joint learning.", "labels": [], "entities": []}, {"text": "We demonstrate empirically that these challenges can be solved with a combination of greedy beam decoding, performed directly in the joint space of possible mention clusters and field assignments, and structured Perceptronstyle learning algorithm.", "labels": [], "entities": []}, {"text": "We report experimental evaluations on two benchmark datasets in different genres, the CMU seminar announcements and corporate acquisitions).", "labels": [], "entities": [{"text": "CMU seminar announcements", "start_pos": 86, "end_pos": 111, "type": "DATASET", "confidence": 0.9515900015830994}]}, {"text": "In each case, we evaluated both template extraction and mention detection performance.", "labels": [], "entities": [{"text": "template extraction", "start_pos": 32, "end_pos": 51, "type": "TASK", "confidence": 0.8297628462314606}, {"text": "mention detection", "start_pos": 56, "end_pos": 73, "type": "TASK", "confidence": 0.6638201624155045}]}, {"text": "Our joint learning approach provides consistently strong results across every setting, including new state-of-the-art results.", "labels": [], "entities": []}, {"text": "We also demonstrate, through ablation studies on the feature set, the need for joint modeling and the relative importance of the different types of joint constraints.", "labels": [], "entities": [{"text": "joint modeling", "start_pos": 79, "end_pos": 93, "type": "TASK", "confidence": 0.7197083830833435}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Seminar extraction results (5-fold CV): Field-level F1", "labels": [], "entities": [{"text": "Seminar extraction", "start_pos": 10, "end_pos": 28, "type": "TASK", "confidence": 0.8138517141342163}]}, {"text": " Table 2: Seminar extraction results (5-fold CV, trained on 50% of corpus): Field-level F1", "labels": [], "entities": [{"text": "Seminar extraction", "start_pos": 10, "end_pos": 28, "type": "TASK", "confidence": 0.7800975143909454}, {"text": "Field-level F1", "start_pos": 76, "end_pos": 90, "type": "METRIC", "confidence": 0.8337113261222839}]}, {"text": " Table 3: Seminar extraction results: Token-level F1", "labels": [], "entities": [{"text": "Seminar extraction", "start_pos": 10, "end_pos": 28, "type": "TASK", "confidence": 0.825170636177063}]}, {"text": " Table 4: Corp. acquisition extraction results: Field-level F1", "labels": [], "entities": [{"text": "Corp. acquisition extraction", "start_pos": 10, "end_pos": 38, "type": "TASK", "confidence": 0.6828319653868675}, {"text": "Field-level", "start_pos": 48, "end_pos": 59, "type": "METRIC", "confidence": 0.8949077129364014}]}, {"text": " Table 5: Corp. acquisition extraction results: Entity-level F1", "labels": [], "entities": [{"text": "Corp. acquisition extraction", "start_pos": 10, "end_pos": 38, "type": "TASK", "confidence": 0.7077202349901199}]}]}