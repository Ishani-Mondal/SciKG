{"title": [{"text": "A Cost Sensitive Part-of-Speech Tagging: Differentiating Serious Errors from Minor Errors", "labels": [], "entities": [{"text": "Cost Sensitive Part-of-Speech Tagging", "start_pos": 2, "end_pos": 39, "type": "TASK", "confidence": 0.7897660955786705}]}], "abstractContent": [{"text": "All types of part-of-speech (POS) tagging errors have been equally treated by existing tag-gers.", "labels": [], "entities": [{"text": "part-of-speech (POS) tagging", "start_pos": 13, "end_pos": 41, "type": "TASK", "confidence": 0.5801478147506713}]}, {"text": "However, the errors are not equally important , since some errors affect the performance of subsequent natural language processing (NLP) tasks seriously while others do not.", "labels": [], "entities": []}, {"text": "This paper aims to minimize these serious errors while retaining the overall performance of POS tagging.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 92, "end_pos": 103, "type": "TASK", "confidence": 0.8202429413795471}]}, {"text": "Two gradient loss functions are proposed to reflect the different types of errors.", "labels": [], "entities": []}, {"text": "They are designed to assign a larger cost to serious errors and a smaller one to minor errors.", "labels": [], "entities": []}, {"text": "Through a set of POS tagging experiments , it is shown that the classifier trained with the proposed loss functions reduces serious errors compared to state-of-the-art POS taggers.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 17, "end_pos": 28, "type": "TASK", "confidence": 0.8410603404045105}, {"text": "POS taggers", "start_pos": 168, "end_pos": 179, "type": "TASK", "confidence": 0.6608699858188629}]}, {"text": "In addition, the experimental result on text chunking shows that fewer serious errors help to improve the performance of subsequent NLP tasks.", "labels": [], "entities": [{"text": "text chunking", "start_pos": 40, "end_pos": 53, "type": "TASK", "confidence": 0.8052026927471161}]}], "introductionContent": [{"text": "Part-of-speech (POS) tagging is needed as a preprocessor for various natural language processing (NLP) tasks such as parsing, named entity recognition (NER), and text chunking.", "labels": [], "entities": [{"text": "Part-of-speech (POS) tagging", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.5647299468517304}, {"text": "parsing", "start_pos": 117, "end_pos": 124, "type": "TASK", "confidence": 0.9526322484016418}, {"text": "named entity recognition (NER)", "start_pos": 126, "end_pos": 156, "type": "TASK", "confidence": 0.7640296518802643}, {"text": "text chunking", "start_pos": 162, "end_pos": 175, "type": "TASK", "confidence": 0.774468332529068}]}, {"text": "Since POS tagging is normally performed in the early step of NLP tasks, the errors in POS tagging are critical in that they affect subsequent steps and often lower the overall performance of NLP tasks.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 6, "end_pos": 17, "type": "TASK", "confidence": 0.8480395376682281}, {"text": "POS tagging", "start_pos": 86, "end_pos": 97, "type": "TASK", "confidence": 0.8343275487422943}]}, {"text": "Previous studies on POS tagging have shown high performance with machine learning techniques).", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 20, "end_pos": 31, "type": "TASK", "confidence": 0.8697644174098969}]}, {"text": "Among the types of machine learning approaches, supervised machine learning techniques were commonly used in early studies on POS tagging.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 126, "end_pos": 137, "type": "TASK", "confidence": 0.8829452693462372}]}, {"text": "With the characteristics of a language) and informative features for POS tagging), the state-of-the-art supervised POS tagging achieves over 97% of accuracy.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 69, "end_pos": 80, "type": "TASK", "confidence": 0.8465352356433868}, {"text": "POS tagging", "start_pos": 115, "end_pos": 126, "type": "TASK", "confidence": 0.7933593690395355}, {"text": "accuracy", "start_pos": 148, "end_pos": 156, "type": "METRIC", "confidence": 0.9985023736953735}]}, {"text": "This performance is generally regarded as the maximum performance that can be achieved by supervised machine learning techniques.", "labels": [], "entities": []}, {"text": "There have also been many studies on POS tagging with semi-supervised () or unsupervised machine learning methods) recently.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 37, "end_pos": 48, "type": "TASK", "confidence": 0.9440722763538361}]}, {"text": "However, there still exists room to improve supervised POS tagging in terms of error differentiation.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 55, "end_pos": 66, "type": "TASK", "confidence": 0.885275661945343}, {"text": "error differentiation", "start_pos": 79, "end_pos": 100, "type": "TASK", "confidence": 0.7316072881221771}]}, {"text": "It should be noted that not all errors are equally important in POS tagging.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 64, "end_pos": 75, "type": "TASK", "confidence": 0.8116928935050964}]}, {"text": "Let us consider the parse trees in as an example.", "labels": [], "entities": []}, {"text": "In(a), the word \"plans\" is mistagged as a noun where it should be a verb.", "labels": [], "entities": []}, {"text": "This error results in a wrong parse tree that is severely different from the correct tree shown in(b).", "labels": [], "entities": []}, {"text": "The verb phrase of the verb \"plans\" in(b) is discarded in(a) and the whole sentence is analyzed as a single noun phrase.(c) and (d) show another tagging error and its effect.", "labels": [], "entities": []}, {"text": "In(c), a noun is tagged as a NNS (plural noun) where its correct tag is NN (singular or mass noun).", "labels": [], "entities": []}, {"text": "However, the error in(c) affects only locally the noun phrase to which \"physics\" belongs.", "labels": [], "entities": []}, {"text": "As a result, the general structure of the parse tree in   the correct one in.", "labels": [], "entities": []}, {"text": "That is, a sentence analyzed with this type of error would yield a corrector near-correct result in many NLP tasks such as machine translation and text chunking.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 123, "end_pos": 142, "type": "TASK", "confidence": 0.7974085509777069}, {"text": "text chunking", "start_pos": 147, "end_pos": 160, "type": "TASK", "confidence": 0.7486955225467682}]}, {"text": "The goal of this paper is to differentiate the serious POS tagging errors from the minor errors.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 55, "end_pos": 66, "type": "TASK", "confidence": 0.8268365561962128}]}, {"text": "POS tagging is generally regarded as a classification task, and zero-one loss is commonly used in learning classifiers (.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 0, "end_pos": 11, "type": "TASK", "confidence": 0.7504874169826508}]}, {"text": "Since zero-one loss considers all errors equally, it cannot distinguish error types.", "labels": [], "entities": []}, {"text": "Therefore, anew loss is required to incorporate different error types into the learning machines.", "labels": [], "entities": []}, {"text": "This paper proposes two gradient loss functions to reflect differences among POS tagging errors.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 77, "end_pos": 88, "type": "TASK", "confidence": 0.8006543219089508}]}, {"text": "The functions assign relatively small cost to minor errors, while larger cost is given to serious errors.", "labels": [], "entities": []}, {"text": "They are applied to learning multiclass support vector machines) which is trained to minimize the serious errors.", "labels": [], "entities": []}, {"text": "Overall accuracy of this SVM is not improved against the stateof-the-art POS tagger, but the serious errors are significantly reduced with the proposed method.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 8, "end_pos": 16, "type": "METRIC", "confidence": 0.9995904564857483}, {"text": "SVM", "start_pos": 25, "end_pos": 28, "type": "TASK", "confidence": 0.8814103603363037}, {"text": "POS tagger", "start_pos": 73, "end_pos": 83, "type": "TASK", "confidence": 0.600181519985199}]}, {"text": "The effect of the fewer serious errors is shown by applying it to the well-known NLP task of text chunking.", "labels": [], "entities": [{"text": "text chunking", "start_pos": 93, "end_pos": 106, "type": "TASK", "confidence": 0.7716555893421173}]}, {"text": "Experimental results show that the proposed method achieves a higher F1-score compared to other POS taggers.", "labels": [], "entities": [{"text": "F1-score", "start_pos": 69, "end_pos": 77, "type": "METRIC", "confidence": 0.9995718598365784}, {"text": "POS taggers", "start_pos": 96, "end_pos": 107, "type": "TASK", "confidence": 0.7595300078392029}]}, {"text": "The rest of the paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 reviews the related studies on POS tagging.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 41, "end_pos": 52, "type": "TASK", "confidence": 0.8878211081027985}]}, {"text": "In Section 3, serious and minor errors are defined, and it is shown that both errors are observable in a general corpus.", "labels": [], "entities": []}, {"text": "Section 4 proposes two new loss functions for discriminating the error types in POS tagging.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 80, "end_pos": 91, "type": "TASK", "confidence": 0.7320532500743866}]}, {"text": "Experimental results are presented in Section 5.", "labels": [], "entities": []}, {"text": "Finally, Section 6 draws some conclusions.", "labels": [], "entities": []}], "datasetContent": [{"text": "Experiments are performed with a well-known standard data set, the Wall Street Journal (WSJ) corpus.", "labels": [], "entities": [{"text": "Wall Street Journal (WSJ) corpus", "start_pos": 67, "end_pos": 99, "type": "DATASET", "confidence": 0.9592133334704808}]}, {"text": "The data is divided into training, development and test sets as in (.", "labels": [], "entities": []}, {"text": "shows some simple statistics of these data sets.", "labels": [], "entities": []}, {"text": "As shown in this table, training data contains 38,219 sentences with 912,344 words.", "labels": [], "entities": []}, {"text": "In the development data set, there are 5,527 sentences with about 131,768 words, those in the test set are 5,462 sentences and 129,654 words.", "labels": [], "entities": [{"text": "development data set", "start_pos": 7, "end_pos": 27, "type": "DATASET", "confidence": 0.7761766811211904}]}, {"text": "The development data set is used only to select \u03b4 in Equation (2) and \u03b3 in Equation (3).", "labels": [], "entities": []}, {"text": "shows the feature set for our experiments.", "labels": [], "entities": []}, {"text": "In this table, w i and ti denote the lexicon and POS tag for the i-th word in a sentence respectively.", "labels": [], "entities": [{"text": "POS tag", "start_pos": 49, "end_pos": 56, "type": "METRIC", "confidence": 0.9441152513027191}]}, {"text": "We use almost the same feature set as used in Tag features prefixes of w i (up to length 9) Suffix features suffixes of w i (up to length 9) Lexical features whether w i contains capitals whether w i has a number whether w i has a hyphen whether w i is all capital whether w i starts with capital and locates at the middle of sentence tures, word/tag combination features, prefix and suffix features as well as lexical features.", "labels": [], "entities": []}, {"text": "The POS tags for words are obtained from a two-pass approach proposed by.", "labels": [], "entities": []}, {"text": "In the experiments, two multiclass SVMs with the proposed loss functions are used.", "labels": [], "entities": []}, {"text": "One is CL-MSVM with category loss and the other is TL-MSVM with tree loss.", "labels": [], "entities": []}, {"text": "A linear kernel is used for both SVMs.", "labels": [], "entities": []}, {"text": "CL-MSVM with \u03b4 = 0.4 shows the best overall performance on the development data where its error rate is as low as 2.71%.", "labels": [], "entities": [{"text": "CL-MSVM", "start_pos": 0, "end_pos": 7, "type": "DATASET", "confidence": 0.8648043274879456}, {"text": "\u03b4", "start_pos": 13, "end_pos": 14, "type": "METRIC", "confidence": 0.965070366859436}, {"text": "error rate", "start_pos": 90, "end_pos": 100, "type": "METRIC", "confidence": 0.9865766763687134}]}, {"text": "\u03b4 = 0.4 implies that the cost of intra-category errors is set to 40% of that of inter-category errors.", "labels": [], "entities": [{"text": "\u03b4", "start_pos": 0, "end_pos": 1, "type": "METRIC", "confidence": 0.9277420043945312}]}, {"text": "The error rate of TL-MSVM is 2.69% when \u03b3 is 0.6.", "labels": [], "entities": [{"text": "error rate", "start_pos": 4, "end_pos": 14, "type": "METRIC", "confidence": 0.9926630258560181}]}, {"text": "\u03b4 = 0.4 and \u03b3 = 0.6 are set in the all experiments below.", "labels": [], "entities": []}, {"text": "gives the comparison with the previous work and proposed methods on the test data.", "labels": [], "entities": []}, {"text": "As can be seen from this table, the best performing algorithms achieve near 2.67% error rate  achieve an error rate of 2.69% and 2.68% respectively.", "labels": [], "entities": [{"text": "error rate", "start_pos": 82, "end_pos": 92, "type": "METRIC", "confidence": 0.969517320394516}, {"text": "error rate", "start_pos": 105, "end_pos": 115, "type": "METRIC", "confidence": 0.9852260649204254}]}, {"text": "Although overall error rates of CL-MSVM and TL-MSVM are not improved compared to the previous state-of-the-art methods, they show reasonable performance.", "labels": [], "entities": [{"text": "error", "start_pos": 17, "end_pos": 22, "type": "METRIC", "confidence": 0.9729920625686646}]}, {"text": "For inter-category error, CL-MSVM achieves the best performance.", "labels": [], "entities": []}, {"text": "The number of inter-category error is 1,567, which shows 23 errors reduction compared to previous best inter-category result by).", "labels": [], "entities": []}, {"text": "TL-MSVM also makes 16 less intercategory errors than Manning's tagger.", "labels": [], "entities": [{"text": "TL-MSVM", "start_pos": 0, "end_pos": 7, "type": "DATASET", "confidence": 0.7793594598770142}]}, {"text": "When compared with Shen's tagger, both CL-MSVM and TL-MSVM make far less inter-category errors even if their overall performance is slightly lower than that of Shen's tagger.", "labels": [], "entities": [{"text": "errors", "start_pos": 88, "end_pos": 94, "type": "METRIC", "confidence": 0.705391526222229}]}, {"text": "However, the intra-category error rate of the proposed methods has some slight increases.", "labels": [], "entities": [{"text": "intra-category error rate", "start_pos": 13, "end_pos": 38, "type": "METRIC", "confidence": 0.7271298766136169}]}, {"text": "The purpose of proposed methods is to minimize inter-category errors but preserving overall performance.", "labels": [], "entities": []}, {"text": "From these results, it can be found that the proposed methods which are trained with the proposed loss functions do differentiate serious and minor POS tagging errors.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 148, "end_pos": 159, "type": "TASK", "confidence": 0.8421688377857208}]}, {"text": "The task of chunking is to identify the non-recursive cores for various types of phrases.", "labels": [], "entities": []}, {"text": "In chunking, the POS information is one of the most crucial aspects in identifying chunks.", "labels": [], "entities": [{"text": "chunking", "start_pos": 3, "end_pos": 11, "type": "TASK", "confidence": 0.9629654884338379}]}, {"text": "Especially inter-category POS errors seriously affect the performance of chunking because they are more likely to mislead the chunk compared to intra-category errors.", "labels": [], "entities": []}, {"text": "Here, with default feature template and parameter settings of the package.", "labels": [], "entities": []}, {"text": "For simplicity in the experiments, the values of \u03b4 in Equation (2) and \u03b3 in Equation (3) are set to be 0.4 and 0.6 respectively which are same as the previous section.", "labels": [], "entities": []}, {"text": "gives the experimental results of text chunking according to the kinds of POS taggers including two previous works, CL-MSVM, and TL-MSVM.", "labels": [], "entities": [{"text": "text chunking", "start_pos": 34, "end_pos": 47, "type": "TASK", "confidence": 0.7660999298095703}, {"text": "POS taggers", "start_pos": 74, "end_pos": 85, "type": "TASK", "confidence": 0.7483748197555542}]}, {"text": "Shen's tagger and Manning's tagger show nearly the same performance.", "labels": [], "entities": []}, {"text": "They achieve an accuracy of 96.08% and around 93.9 F1-score.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 16, "end_pos": 24, "type": "METRIC", "confidence": 0.9998202919960022}, {"text": "F1-score", "start_pos": 51, "end_pos": 59, "type": "METRIC", "confidence": 0.9951245188713074}]}, {"text": "On the other hand, CL-MSVM achieves 96.13% accuracy and 94.00 F1-score.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 43, "end_pos": 51, "type": "METRIC", "confidence": 0.9991638660430908}, {"text": "F1-score", "start_pos": 62, "end_pos": 70, "type": "METRIC", "confidence": 0.9969335794448853}]}, {"text": "The accuracy and F1-score of TL-MSVM are 96.12% and 94.00.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.9999006986618042}, {"text": "F1-score", "start_pos": 17, "end_pos": 25, "type": "METRIC", "confidence": 0.9998086094856262}]}, {"text": "Both CL-MSVM and TL-MSVM show slightly better performances than other POS taggers.", "labels": [], "entities": [{"text": "POS taggers", "start_pos": 70, "end_pos": 81, "type": "TASK", "confidence": 0.7979204952716827}]}, {"text": "As shown in, both CL-MSVM and TL-MSVM achieve lower accuracies than other methods, while their inter-category errors are less than that of other experimental methods.", "labels": [], "entities": [{"text": "accuracies", "start_pos": 52, "end_pos": 62, "type": "METRIC", "confidence": 0.9924442172050476}]}, {"text": "Thus, the improvement of CL-MSVM and TL-MSVM implies that, for the subsequent natural language processing, a POS tagger should considers different cost of tagging errors.", "labels": [], "entities": [{"text": "POS tagger", "start_pos": 109, "end_pos": 119, "type": "TASK", "confidence": 0.7423937320709229}]}], "tableCaptions": [{"text": " Table 2: The distribution of tagging errors on WSJ corpus by Stanford Part-Of-Speech Tagger.", "labels": [], "entities": [{"text": "WSJ corpus", "start_pos": 48, "end_pos": 58, "type": "DATASET", "confidence": 0.9161994755268097}]}, {"text": " Table 3: Simple statistics of experimental data", "labels": [], "entities": []}, {"text": " Table 5: Comparison with the previous works", "labels": [], "entities": []}, {"text": " Table 6: The experimental results for chunking", "labels": [], "entities": [{"text": "chunking", "start_pos": 39, "end_pos": 47, "type": "TASK", "confidence": 0.9673811793327332}]}]}