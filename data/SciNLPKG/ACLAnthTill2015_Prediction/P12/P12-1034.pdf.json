{"title": [], "abstractContent": [{"text": "Writing comments about news articles, blogs, or reviews have become a popular activity in social media.", "labels": [], "entities": [{"text": "Writing comments about news articles, blogs", "start_pos": 0, "end_pos": 43, "type": "TASK", "confidence": 0.873197180884225}]}, {"text": "In this paper, we analyze reader comments about reviews.", "labels": [], "entities": []}, {"text": "Analyzing review comments is important because reviews only tell the experiences and evaluations of reviewers about the reviewed products or services.", "labels": [], "entities": []}, {"text": "Comments, on the other hand, are readers' evaluations of reviews, their questions and concerns.", "labels": [], "entities": []}, {"text": "Clearly, the information in comments is valuable for both future readers and brands.", "labels": [], "entities": []}, {"text": "This paper proposes two latent variable models to simultaneously model and extract these key pieces of information.", "labels": [], "entities": []}, {"text": "The results also enable classification of comments accurately.", "labels": [], "entities": [{"text": "classification of comments", "start_pos": 24, "end_pos": 50, "type": "TASK", "confidence": 0.8783461650212606}]}, {"text": "Experiments using Amazon review comments demonstrate the effectiveness of the proposed models.", "labels": [], "entities": []}], "introductionContent": [{"text": "Online reviews enable consumers to evaluate the products and services that they have used.", "labels": [], "entities": []}, {"text": "These reviews are also used by other consumers and businesses as a valuable source of opinions.", "labels": [], "entities": []}, {"text": "However, reviews only give the evaluations and experiences of the reviewers.", "labels": [], "entities": []}, {"text": "Often a reviewer may not bean expert of the product and may misuse the product or make other mistakes.", "labels": [], "entities": []}, {"text": "There may also be aspects of the product that the reviewer did not mention but a reader wants to know.", "labels": [], "entities": []}, {"text": "Some reviewers may even write fake reviews to promote some products, which is called opinion spamming.", "labels": [], "entities": []}, {"text": "To improve the online review system and user experience, some review hosting sites allow readers to write comments about reviews (apart from just providing a feedback by clicking whether the review is helpful or not).", "labels": [], "entities": []}, {"text": "Many reviews receive a large number of comments.", "labels": [], "entities": []}, {"text": "It is difficult fora reader to read them to get a gist of them.", "labels": [], "entities": []}, {"text": "An automated comment analysis would be very helpful.", "labels": [], "entities": [{"text": "comment analysis", "start_pos": 13, "end_pos": 29, "type": "TASK", "confidence": 0.7145058363676071}]}, {"text": "Review comments mainly contain the following information: Thumbs-up or thumbs-down: Some readers may comment on whether they find the review useful in helping them make a buying decision.", "labels": [], "entities": [{"text": "Thumbs-up", "start_pos": 58, "end_pos": 67, "type": "METRIC", "confidence": 0.9977204203605652}]}, {"text": "Agreement or disagreement: Some readers who comment on a review maybe users of the product themselves.", "labels": [], "entities": []}, {"text": "They often state whether they agree or disagree with the review.", "labels": [], "entities": []}, {"text": "Such comments are valuable as they provide a second opinion, which may even identify fake reviews because a genuine user often can easily spot reviewers who have never used the product.", "labels": [], "entities": []}, {"text": "Question and answer: A commenter may ask for clarification or about some aspects of the product that are not covered in the review.", "labels": [], "entities": []}, {"text": "In this paper, we use statistical modeling to model review comments.", "labels": [], "entities": []}, {"text": "Two new generative models are proposed.", "labels": [], "entities": []}, {"text": "The first model is called the Topic and Multi-Expression model (TME).", "labels": [], "entities": []}, {"text": "It models topics and different types of expressions, which represent different types of comment posts: 1.", "labels": [], "entities": []}, {"text": "Thumbs-up (e.g., \"review helped me\") 2.", "labels": [], "entities": [{"text": "Thumbs-up", "start_pos": 0, "end_pos": 9, "type": "METRIC", "confidence": 0.9627432227134705}]}, {"text": "Thumbs-down (e.g., \"poor review\") 3.", "labels": [], "entities": [{"text": "Thumbs-down", "start_pos": 0, "end_pos": 11, "type": "METRIC", "confidence": 0.9866039752960205}]}, {"text": "Question (e.g., \"how to\") 4.", "labels": [], "entities": []}, {"text": "Answer acknowledgement (e.g., \"thank you for clarifying\").", "labels": [], "entities": [{"text": "Answer acknowledgement", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.6261628419160843}]}, {"text": "Note that we have no expressions for answers to questions as there are usually no specific phrases indicating that a post answers a question except starting with the name of the person who asked the question.", "labels": [], "entities": []}, {"text": "However, there are typical phrases for acknowledging answers, thus answer acknowledgement expressions.", "labels": [], "entities": [{"text": "answer acknowledgement expressions", "start_pos": 67, "end_pos": 101, "type": "TASK", "confidence": 0.9077094992001852}]}, {"text": "5. Disagreement (contention) (e.g., \"I disagree\") 6.", "labels": [], "entities": []}, {"text": "Agreement (e.g., \"I agree\").", "labels": [], "entities": []}, {"text": "For ease of presentation, we call these expressions the comment expressions.", "labels": [], "entities": []}, {"text": "TME provides a basic model for extracting these pieces of information and topics.", "labels": [], "entities": [{"text": "TME", "start_pos": 0, "end_pos": 3, "type": "TASK", "confidence": 0.5311651825904846}]}, {"text": "Its generative process separates topics and Cexpression types using a switch variable and treats posts as random mixtures over latent topics and Cexpression types.", "labels": [], "entities": []}, {"text": "The second model, called ME-TME, improves TME by using Maximum-Entropy priors to guide topic/expression switching.", "labels": [], "entities": [{"text": "TME", "start_pos": 42, "end_pos": 45, "type": "TASK", "confidence": 0.9520865678787231}, {"text": "topic/expression switching", "start_pos": 87, "end_pos": 113, "type": "TASK", "confidence": 0.588375024497509}]}, {"text": "In short, the two models provide a principled and integrated approach to simultaneously discover topics and Cexpressions, which is the goal of this work.", "labels": [], "entities": []}, {"text": "Note that topics are usually product aspects in this work.", "labels": [], "entities": []}, {"text": "The extracted C-expressions and topics from review comments are very useful in practice.", "labels": [], "entities": []}, {"text": "First of all, C-expressions enable us to perform more accurate classification of comments, which can give us a good evaluation of the review quality and credibility.", "labels": [], "entities": []}, {"text": "For example, a review with many Disagreeing and Thumbs-down comments is dubious.", "labels": [], "entities": []}, {"text": "Second, the extracted C-expressions and topics help identify the key product aspects that people are troubled within disagreements and in questions.", "labels": [], "entities": []}, {"text": "Our experimental results in Section 5 will demonstrate these capabilities of our models.", "labels": [], "entities": []}, {"text": "With these pieces of information, comments fora review can be summarized.", "labels": [], "entities": []}, {"text": "The summary may include, but not limited to, the following: (1) percent of people who give the review thumbs-up or thumbs-down; (2) percent of people who agree or disagree (or contend) with the reviewer; (3) contentious (disagreed) aspects (or topics); (4) aspects about which people often have questions.", "labels": [], "entities": []}, {"text": "To the best of our knowledge, there is no reported work on such a fine-grained modeling of review comments.", "labels": [], "entities": []}, {"text": "The related works are mainly in sentiment analysis), e.g., topic and sentiment modeling, review quality prediction and review spam detection.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 32, "end_pos": 50, "type": "TASK", "confidence": 0.9435147345066071}, {"text": "topic and sentiment modeling", "start_pos": 59, "end_pos": 87, "type": "TASK", "confidence": 0.6438064500689507}, {"text": "review quality prediction", "start_pos": 89, "end_pos": 114, "type": "TASK", "confidence": 0.6394450863202413}, {"text": "review spam detection", "start_pos": 119, "end_pos": 140, "type": "TASK", "confidence": 0.6476382116476694}]}, {"text": "However, our work is different from them.", "labels": [], "entities": []}, {"text": "We will compare with them in detail in Section 2.", "labels": [], "entities": []}, {"text": "The proposed models have been evaluated both qualitatively and quantitatively using a large number of review comments from Amazon.com.", "labels": [], "entities": []}, {"text": "Experimental results show that both TME and ME-TME are effective in performing their tasks.", "labels": [], "entities": [{"text": "ME-TME", "start_pos": 44, "end_pos": 50, "type": "METRIC", "confidence": 0.8582080602645874}]}, {"text": "ME-TME also outperforms TME significantly.", "labels": [], "entities": [{"text": "TME", "start_pos": 24, "end_pos": 27, "type": "METRIC", "confidence": 0.635187566280365}]}], "datasetContent": [{"text": "We now evaluate the proposed TME and ME-TME models.", "labels": [], "entities": []}, {"text": "Specifically, we evaluate the discovered C-expressions, contentious aspects, and aspects often mentioned in questions.", "labels": [], "entities": []}, {"text": "comments of reviews in Amazon.com fora variety of products.", "labels": [], "entities": []}, {"text": "For each comment we extracted its id, the comment author id, the review id on which it commented, and the review author id.", "labels": [], "entities": []}, {"text": "Our database consisted of 21,316 authors, 37,548 reviews, and 88,345 comments with an average of 124 words per comment post.", "labels": [], "entities": []}, {"text": "For all our experiments, the hyper-parameters for TME and ME-TME were set to the heuristic values \u03b1 T = 50/T, \u03b1 E = 50/E, \u03b2 T = \u03b2 E = 0.1 as suggested in ().", "labels": [], "entities": []}, {"text": "For \ud97b\udf59, we estimated the asymmetric Beta priors using the method of moments discussed in Section 3.", "labels": [], "entities": []}, {"text": "We sampled 1000 random posts and for each post we identified the C-expressions emitted.", "labels": [], "entities": []}, {"text": "We thus computed the per-post probability of C-expression emission (1 1 \ud97b\udf59 \ud97b\udf59 and used Eq.", "labels": [], "entities": []}, {"text": "(3) to get the final estimates, \ud97b\udf59 \ud97b\udf59 = 3.66, \ud97b\udf59 \ud97b\udf59 = 1.21.", "labels": [], "entities": []}, {"text": "To learn the MaxEnt parameters \ud97b\udf59, we randomly sampled 500 terms from our corpus appearing at least 10 times and labeled them as topical (332) or C-expressions (168) and used the corresponding feature vector of each term (in the context of posts where it occurs) to train the Max-Ent model.", "labels": [], "entities": []}, {"text": "We set the number of topics, T = 100 and the number of C-expression types, E = 6 (Thumbs-up, Thumbs-down, Question, Answer acknowledgement, Agreement and Disagreement) as in review comments, we usually find these six dominant expression types.", "labels": [], "entities": [{"text": "T", "start_pos": 29, "end_pos": 30, "type": "METRIC", "confidence": 0.9600158333778381}]}, {"text": "Note that knowing the exact number of topics, T and expression types, E in a corpus is difficult.", "labels": [], "entities": []}, {"text": "While non-parametric Bayesian approaches () aim to estimate T from the corpus, in this work the heuristic values obtained from our initial experiments produced good results.", "labels": [], "entities": []}, {"text": "We also tried increasing E to 7, 8, etc.", "labels": [], "entities": [{"text": "E", "start_pos": 25, "end_pos": 26, "type": "METRIC", "confidence": 0.9961102604866028}]}, {"text": "However, it did not produce any new dominant expression type.", "labels": [], "entities": []}, {"text": "Instead, the expression types became less specific as the expression term space became sparser.", "labels": [], "entities": []}, {"text": "We now evaluate the discovered C-expressions.", "labels": [], "entities": []}, {"text": "We first evaluate them qualitatively in shows the top terms of all expression types using the TME model.", "labels": [], "entities": []}, {"text": "We find that TME can discover and cluster many correct Cexpressions, e.g., \"great review\", \"review helped me\" in Thumbs-up; \"poor review\", \"very unfair review\" in Thumbs-down; \"how do I\", \"help me decide\" in Question; \"good reply\", \"thank you for clarifying\" in Answer Acknowledgement; \"I disagree\", \"I refute\" in Disagreement; and \"I agree\", \"true in fact\" in Agreement.", "labels": [], "entities": [{"text": "Agreement", "start_pos": 361, "end_pos": 370, "type": "DATASET", "confidence": 0.8650672435760498}]}, {"text": "However, with the guidance of Max-Ent priors, ME-TME did much better).", "labels": [], "entities": [{"text": "ME-TME", "start_pos": 46, "end_pos": 52, "type": "METRIC", "confidence": 0.4671518802642822}]}, {"text": "For example, we find \"level headed review\", \"review convinced me\" in Thumbs-up; \"biased review\", \"is flawed\" in Thumbs-down; \"any clues\", \"I was wondering how\" in Question; \"clears my\", \"valid answer\" in Answer-acknowledgement; \"I don't buy your\", \"sheer nonsense\" in Disagreement; \"agree completely\", \"well said\" in Agreement.", "labels": [], "entities": [{"text": "Thumbs-up", "start_pos": 69, "end_pos": 78, "type": "DATASET", "confidence": 0.8852409720420837}, {"text": "agree", "start_pos": 283, "end_pos": 288, "type": "METRIC", "confidence": 0.9594311714172363}]}, {"text": "These newly discovered phrases by ME-TME are marked in blue in.", "labels": [], "entities": []}, {"text": "ME-TME also has fewer errors.", "labels": [], "entities": [{"text": "ME-TME", "start_pos": 0, "end_pos": 6, "type": "DATASET", "confidence": 0.7428550124168396}, {"text": "errors", "start_pos": 22, "end_pos": 28, "type": "METRIC", "confidence": 0.9733443856239319}]}, {"text": "Next, we evaluate them quantitatively using the metric precision @ n, which gives the precision at different rank positions.", "labels": [], "entities": [{"text": "metric precision", "start_pos": 48, "end_pos": 64, "type": "METRIC", "confidence": 0.7114070057868958}, {"text": "precision", "start_pos": 86, "end_pos": 95, "type": "METRIC", "confidence": 0.9969536066055298}]}, {"text": "This metric is appropriate here because the C-expressions (according to top terms in \u03a6 E ) produced by TME and ME-TME are rankings.", "labels": [], "entities": [{"text": "ME-TME", "start_pos": 111, "end_pos": 117, "type": "METRIC", "confidence": 0.7998268604278564}]}, {"text": "reports the precisions @ top 25, 50, 75, and 100 rank positions for all six expression types across both models.", "labels": [], "entities": [{"text": "precisions", "start_pos": 12, "end_pos": 22, "type": "METRIC", "confidence": 0.9985812902450562}]}, {"text": "We evaluated till top 100 positions because it is usually important to see whether a model can discover and rank those major expressions of a type at the top.", "labels": [], "entities": []}, {"text": "We believe that top 100 are sufficient for most applications.", "labels": [], "entities": []}, {"text": "From, we observe that ME-TME consistently outperforms TME in precisions across all expression types and all rank positions.", "labels": [], "entities": [{"text": "ME-TME", "start_pos": 22, "end_pos": 28, "type": "METRIC", "confidence": 0.7794276475906372}, {"text": "precisions", "start_pos": 61, "end_pos": 71, "type": "METRIC", "confidence": 0.9954143762588501}]}, {"text": "This shows that Max-Ent priors are more effective in discovering expressions than Beta priors.", "labels": [], "entities": []}, {"text": "Note that we couldn't compare with an existing baseline because there is no reported study on this problem.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 3: Precision @ top 25, 50, 75, and 100 rank positions for all C-expression types.", "labels": [], "entities": [{"text": "Precision", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9855174422264099}]}, {"text": " Table 4: Precision (P), Recall (R), and F 1 scores of binary classification using SVM and different features. The  improvements of our models are significant (p<0.001) over paired t-test across 10-fold cross validation.", "labels": [], "entities": [{"text": "Precision (P)", "start_pos": 10, "end_pos": 23, "type": "METRIC", "confidence": 0.9236124157905579}, {"text": "Recall (R)", "start_pos": 25, "end_pos": 35, "type": "METRIC", "confidence": 0.9435461312532425}, {"text": "F 1 scores", "start_pos": 41, "end_pos": 51, "type": "METRIC", "confidence": 0.9736786683400472}]}, {"text": " Table 5: Points of Contention (a), Questioned aspects (b). D1: Ipod, D2: Kindle, D3: Nikon, D4: Garmin. We report the  average precision (P), recall (R), and F 1 score over 100 comments for each particular domain.  Statistical significance: Differences between Nearest Noun Phrase and TME for both judges (J 1 , J 2 ) across all domains were  significant at 97% confidence level (p<0.03). Differences among TME and ME-TME for both judges (J 1 , J 2 ) across all  domains were significant at 95% confidence level (p<0.05). A paired t-test was used for testing significance.", "labels": [], "entities": [{"text": "Kindle", "start_pos": 74, "end_pos": 80, "type": "DATASET", "confidence": 0.9386033415794373}, {"text": "precision (P)", "start_pos": 128, "end_pos": 141, "type": "METRIC", "confidence": 0.9472857266664505}, {"text": "recall (R)", "start_pos": 143, "end_pos": 153, "type": "METRIC", "confidence": 0.9557088613510132}, {"text": "F 1", "start_pos": 159, "end_pos": 162, "type": "METRIC", "confidence": 0.9861259758472443}]}]}