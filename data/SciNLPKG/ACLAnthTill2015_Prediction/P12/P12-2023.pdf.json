{"title": [{"text": "Topic Models for Dynamic Translation Model Adaptation", "labels": [], "entities": [{"text": "Dynamic Translation Model Adaptation", "start_pos": 17, "end_pos": 53, "type": "TASK", "confidence": 0.8672285377979279}]}], "abstractContent": [{"text": "We propose an approach that biases machine translation systems toward relevant translations based on topic-specific contexts, where topics are induced in an unsupervised way using topic models; this can bethought of as inducing subcorpora for adaptation without any human annotation.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 35, "end_pos": 54, "type": "TASK", "confidence": 0.7056535184383392}]}, {"text": "We use these topic distributions to compute topic-dependent lexical weighting probabilities and directly incorporate them into our translation model as features.", "labels": [], "entities": []}, {"text": "Conditioning lexical probabilities on the topic biases translations toward topic-relevant output, resulting in significant improvements of up to 1 BLEU and 3 TER on Chinese to English translation over a strong baseline.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 147, "end_pos": 151, "type": "METRIC", "confidence": 0.9996777772903442}, {"text": "TER", "start_pos": 158, "end_pos": 161, "type": "METRIC", "confidence": 0.9971931576728821}]}], "introductionContent": [{"text": "The performance of a statistical machine translation (SMT) system on a translation task depends largely on the suitability of the available parallel training data.", "labels": [], "entities": [{"text": "statistical machine translation (SMT)", "start_pos": 21, "end_pos": 58, "type": "TASK", "confidence": 0.781100869178772}]}, {"text": "Domains (e.g., newswire vs. blogs) may vary widely in their lexical choices and stylistic preferences, and what maybe preferable in a general setting, or in one domain, is not necessarily preferable in another domain.", "labels": [], "entities": []}, {"text": "Indeed, sometimes the domain can change the meaning of a phrase entirely.", "labels": [], "entities": []}, {"text": "Ina food related context, the Chinese sentence \"\u7c89\u4e1d\u5f88\u591a \" (\"f\u011bns \u00af i h\u011bndu\u00af o\") would mean \"They have a lot of vermicelli\"; however, in an informal Internet conversation, this sentence would mean \"They have a lot of fans\".", "labels": [], "entities": []}, {"text": "Without the broader context, it is impossible to determine the correct translation in otherwise identical sentences.", "labels": [], "entities": []}, {"text": "This problem has led to a substantial amount of recent work in trying to bias, or adapt, the translation model (TM) toward particular domains of interest.", "labels": [], "entities": [{"text": "translation model (TM)", "start_pos": 93, "end_pos": 115, "type": "TASK", "confidence": 0.7547353625297546}]}, {"text": "The intuition behind TM adaptation is to increase the likelihood of selecting relevant phrases for translation.", "labels": [], "entities": [{"text": "TM adaptation", "start_pos": 21, "end_pos": 34, "type": "TASK", "confidence": 0.9898727834224701}]}, {"text": "introduced assigning a pair of binary features to each training sentence, indicating sentences' genre and collection as away to capture domains.", "labels": [], "entities": []}, {"text": "They then learn a mapping from these features to sentence weights, use the sentence weights to bias the model probability estimates and subsequently learn the model weights.", "labels": [], "entities": []}, {"text": "As sentence weights were found to be most beneficial for lexical extends the same notion of conditioning on provenance (i.e., the origin of the text) by removing the separate mapping step, directly optimizing the weight of the genre and collection features by computing a separate word translation table for each feature, estimated from only those sentences that comprise that genre or collection.", "labels": [], "entities": []}, {"text": "The common thread throughout prior work is the concept of a domain.", "labels": [], "entities": []}, {"text": "A domain is typically a hard constraint that is externally imposed and hand labeled, such as genre or corpus collection.", "labels": [], "entities": []}, {"text": "For example, a sentence either comes from newswire, or weblog, but not both.", "labels": [], "entities": []}, {"text": "However, this poses several problems.", "labels": [], "entities": []}, {"text": "First, since a sentence contributes its counts only to the translation table for the source it came from, many word pairs will be unobserved fora given table.", "labels": [], "entities": []}, {"text": "Second, we may not know the (sub)corpora our training data come from; and even if we do, \"subcorpus\" may not be the most useful notion of domain for better translations.", "labels": [], "entities": []}, {"text": "We take a finer-grained, flexible, unsupervised approach for lexical weighting by domain.", "labels": [], "entities": []}, {"text": "We induce unsupervised domains from large corpora, and we incorporate soft, probabilistic domain membership into a translation model.", "labels": [], "entities": []}, {"text": "Unsupervised modeling of the training data produces naturally occurring subcorpora, generalizing beyond corpus and genre.", "labels": [], "entities": []}, {"text": "Depending on the model used to select subcorpora, we can bias our translation toward any arbitrary distinction.", "labels": [], "entities": []}, {"text": "This reduces the problem to identifying what automatically defined subsets of the training corpus maybe beneficial for translation.", "labels": [], "entities": [{"text": "translation", "start_pos": 119, "end_pos": 130, "type": "TASK", "confidence": 0.9804578423500061}]}, {"text": "In this work, we consider the underlying latent topics of the documents (.", "labels": [], "entities": []}, {"text": "Topic modeling has received some use in SMT, for instance Bilingual LSA adaptation (, and the BiTAM model (), which uses a bilingual topic model for learning alignment.", "labels": [], "entities": [{"text": "Topic modeling", "start_pos": 0, "end_pos": 14, "type": "TASK", "confidence": 0.7809457778930664}, {"text": "SMT", "start_pos": 40, "end_pos": 43, "type": "TASK", "confidence": 0.995995044708252}, {"text": "Bilingual LSA adaptation", "start_pos": 58, "end_pos": 82, "type": "TASK", "confidence": 0.6400310595830282}]}, {"text": "In our case, by building a topic distribution for the source side of the training data, we abstract the notion of domain to include automatically derived subcorpora with probabilistic membership.", "labels": [], "entities": []}, {"text": "This topic model infers the topic distribution of a test set and biases sentence translations to appropriate topics.", "labels": [], "entities": []}, {"text": "We accomplish this by introducing topic dependent lexical probabilities directly as features in the translation model, and interpolating them log-linearly with our other features, thus allowing us to discriminatively optimize their weights on an arbitrary objective function.", "labels": [], "entities": []}, {"text": "Incorporating these features into our hierarchical phrase-based translation system significantly improved translation performance, by up to 1 BLEU and 3 TER over a strong Chinese to English baseline.", "labels": [], "entities": [{"text": "translation", "start_pos": 106, "end_pos": 117, "type": "TASK", "confidence": 0.9599428176879883}, {"text": "BLEU", "start_pos": 142, "end_pos": 146, "type": "METRIC", "confidence": 0.9995889067649841}, {"text": "TER", "start_pos": 153, "end_pos": 156, "type": "METRIC", "confidence": 0.9958173632621765}]}], "datasetContent": [{"text": "Setup To evaluate our approach, we performed experiments on Chinese to English MT in two settings.", "labels": [], "entities": [{"text": "Chinese to English MT", "start_pos": 60, "end_pos": 81, "type": "TASK", "confidence": 0.5037418380379677}]}, {"text": "First, we use the FBIS corpus as our training bitext.", "labels": [], "entities": [{"text": "FBIS corpus", "start_pos": 18, "end_pos": 29, "type": "DATASET", "confidence": 0.9423049986362457}]}, {"text": "Since FBIS has document delineations, we compare local topic modeling (LTM) with modeling at the document level (GTM).", "labels": [], "entities": []}, {"text": "The second setting uses the non-UN and non-HK Hansards portions of the NIST training corpora with LTM only.", "labels": [], "entities": [{"text": "Hansards", "start_pos": 46, "end_pos": 54, "type": "DATASET", "confidence": 0.9556329250335693}, {"text": "NIST training corpora", "start_pos": 71, "end_pos": 92, "type": "DATASET", "confidence": 0.9368210037549337}]}, {"text": "For both settings, the data were lowercased, tokenized and aligned using GIZA++ to obtain bidirectional alignments, which were symmetrized using the grow-diag-final-and method ().", "labels": [], "entities": []}, {"text": "The Chinese data were segmented using the Stanford segmenter.", "labels": [], "entities": [{"text": "Chinese data", "start_pos": 4, "end_pos": 16, "type": "DATASET", "confidence": 0.825758546590805}, {"text": "Stanford segmenter", "start_pos": 42, "end_pos": 60, "type": "DATASET", "confidence": 0.9350452125072479}]}, {"text": "We trained a trigram LM on the English side of the corpus with an additional 150M words randomly selected from the non-NYT and non-LAT portions of the Gigaword v4 corpus using modified Kneser-Ney smoothing), a standard implementation of LDA, using a Chinese stoplist and setting the per-document Dirichlet parameter \u03b1 = 0.01.", "labels": [], "entities": [{"text": "Gigaword v4 corpus", "start_pos": 151, "end_pos": 169, "type": "DATASET", "confidence": 0.8622133731842041}]}, {"text": "This setting of was chosen to encourage sparse topic assignments, which make induced subdomains consistent within a document.", "labels": [], "entities": []}, {"text": "Results Results for both settings are shown in Table 2.", "labels": [], "entities": []}, {"text": "GTM models the latent topics at the document level, while LTM models each sentence as a separate document.", "labels": [], "entities": [{"text": "GTM", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.8834357857704163}]}, {"text": "To evaluate the effect topic granularity would have on translation, we varied the number of latent topics in each model to be 5, 10, and 20.", "labels": [], "entities": [{"text": "translation", "start_pos": 55, "end_pos": 66, "type": "TASK", "confidence": 0.9797219038009644}]}, {"text": "On FBIS, we can see that both models achieve moderate but consistent gains over the baseline on both BLEU and TER.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 101, "end_pos": 105, "type": "METRIC", "confidence": 0.9978431463241577}, {"text": "TER", "start_pos": 110, "end_pos": 113, "type": "METRIC", "confidence": 0.973478376865387}]}, {"text": "The best model, LTM-10, achieves again of about 0.5 and 0.6 BLEU and 2 TER.", "labels": [], "entities": [{"text": "LTM-10", "start_pos": 16, "end_pos": 22, "type": "DATASET", "confidence": 0.8522128462791443}, {"text": "BLEU", "start_pos": 60, "end_pos": 64, "type": "METRIC", "confidence": 0.999649167060852}, {"text": "TER", "start_pos": 71, "end_pos": 74, "type": "METRIC", "confidence": 0.9984233379364014}]}, {"text": "Although the performance on BLEU for both the 20 topic models LTM-20 and GTM-20 is suboptimal, the TER improvement is better.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 28, "end_pos": 32, "type": "METRIC", "confidence": 0.9960581064224243}, {"text": "LTM-20", "start_pos": 62, "end_pos": 68, "type": "DATASET", "confidence": 0.9772027134895325}, {"text": "GTM-20", "start_pos": 73, "end_pos": 79, "type": "DATASET", "confidence": 0.8420169949531555}, {"text": "TER", "start_pos": 99, "end_pos": 102, "type": "METRIC", "confidence": 0.9988981485366821}]}, {"text": "Interestingly, the difference in translation quality between capturing document coherence in GTM and modeling purely on the sentence level is not substantial.", "labels": [], "entities": []}, {"text": "In fact, the opposite is true, with the LTM models achieving better performance.", "labels": [], "entities": [{"text": "LTM", "start_pos": 40, "end_pos": 43, "type": "DATASET", "confidence": 0.8780524134635925}]}, {"text": "On the NIST corpus, LTM-10 again achieves the best gain of approximately 1 BLEU and up to 3 TER.", "labels": [], "entities": [{"text": "NIST corpus", "start_pos": 7, "end_pos": 18, "type": "DATASET", "confidence": 0.9746688306331635}, {"text": "BLEU", "start_pos": 75, "end_pos": 79, "type": "METRIC", "confidence": 0.9993656277656555}, {"text": "TER", "start_pos": 92, "end_pos": 95, "type": "METRIC", "confidence": 0.9958784580230713}]}, {"text": "LTM performs on par with or better than GTM, and provides significant gains even in the NIST data setting, showing that this method can be effectively applied directly on the sentence level to large training An avenue of future work would condition the sentence topic distribution on a document distribution over topics ().", "labels": [], "entities": [{"text": "NIST data setting", "start_pos": 88, "end_pos": 105, "type": "DATASET", "confidence": 0.9144354661305746}]}, {"text": "As an empirical validation of our earlier intuition regarding feature representation, presenting the features in the form of F1 caused the performance to remain virtually unchanged from the baseline model.", "labels": [], "entities": [{"text": "feature representation", "start_pos": 62, "end_pos": 84, "type": "TASK", "confidence": 0.6960001438856125}, {"text": "F1", "start_pos": 125, "end_pos": 127, "type": "METRIC", "confidence": 0.9969778060913086}]}, {"text": "corpora which have no document markings.", "labels": [], "entities": []}, {"text": "Depending on the diversity of training corpus, a varying number of underlying topics maybe appropriate.", "labels": [], "entities": []}, {"text": "However, in both settings, 10 topics performed best.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Performance using FBIS training corpus (top)  and NIST corpus (bottom). Improvements are significant  at the p <0.05 level, except where indicated ( ns ).", "labels": [], "entities": [{"text": "FBIS training corpus", "start_pos": 28, "end_pos": 48, "type": "DATASET", "confidence": 0.7941177090009054}, {"text": "NIST corpus", "start_pos": 60, "end_pos": 71, "type": "DATASET", "confidence": 0.9585139155387878}]}]}