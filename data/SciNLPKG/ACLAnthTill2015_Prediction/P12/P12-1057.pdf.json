{"title": [{"text": "Spice it Up? Mining Refinements to Online Instructions from User Generated Content", "labels": [], "entities": [{"text": "Spice it Up", "start_pos": 0, "end_pos": 11, "type": "TASK", "confidence": 0.8967177271842957}]}], "abstractContent": [{"text": "There area growing number of popular web sites where users submit and review instructions for completing tasks as varied as building a table and baking a pie.", "labels": [], "entities": []}, {"text": "In addition to providing their subjective evaluation, reviewers often provide actionable refinements.", "labels": [], "entities": []}, {"text": "These refinements clarify, correct, improve, or provide alternatives to the original instructions.", "labels": [], "entities": []}, {"text": "However, identifying and reading all relevant reviews is a daunting task fora user.", "labels": [], "entities": []}, {"text": "In this paper, we propose a generative model that jointly identifies user-proposed refinements in instruction reviews at multiple granularities, and aligns them to the appropriate steps in the original instructions.", "labels": [], "entities": []}, {"text": "Labeled data is not readily available for these tasks, so we focus on the unsupervised setting.", "labels": [], "entities": []}, {"text": "In experiments in the recipe domain, our model provides 90.1% F 1 for predicting refinements at the review level, and 77.0% F 1 for predicting refinement segments within reviews.", "labels": [], "entities": [{"text": "F 1", "start_pos": 62, "end_pos": 65, "type": "METRIC", "confidence": 0.9945444762706757}, {"text": "F 1", "start_pos": 124, "end_pos": 127, "type": "METRIC", "confidence": 0.99227374792099}]}], "introductionContent": [{"text": "People turn to the web to seek advice on a wide variety of subjects.", "labels": [], "entities": []}, {"text": "An analysis of web search queries posed as questions revealed that \"how to\" questions are the most popular ().", "labels": [], "entities": []}, {"text": "People consult online resources to answer technical questions like \"how to put music on my ipod,\" and to find instructions for tasks like tying a tie and cooking Thanksgiving dinner.", "labels": [], "entities": []}, {"text": "Not surprisingly, there are many Web sites dedicated to providing instructions.", "labels": [], "entities": []}, {"text": "For instance, on the popular DIY site instructables.com (\"share what you make\"), users post instructions for making a wide variety of objects ranging from bed frames to \"The Stirling Engine, absorb energy from candles, coffee, and more!", "labels": [], "entities": []}, {"text": "1 \" There are also sites like allrecipes.com that are dedicated to a specific domain.", "labels": [], "entities": []}, {"text": "On these community-based instruction sites, instructions are posted and reviewed by users.", "labels": [], "entities": []}, {"text": "For instance, the aforementioned \"Stirling engine\" has received over 350 reviews on instructables.com.", "labels": [], "entities": []}, {"text": "While user-generated instructions greatly increase the variety of instructions available online, they are not necessarily foolproof, or appropriate for all users.", "labels": [], "entities": []}, {"text": "For instance, in the case of recipes, a user missing a certain ingredient at home might wonder whether it can be safely omitted; a user who wants to get a slightly different flavor might want to find out what substitutions can be used to achieve that effect.", "labels": [], "entities": []}, {"text": "Reviews posted by other users provide a great resource for mining such information.", "labels": [], "entities": []}, {"text": "In recipe reviews, users often offer their customized version of the recipe by describing changes they made: e.g., \"I halved the salt\" or \"I used honey instead of sugar.\"", "labels": [], "entities": []}, {"text": "In addition, they may clarify portions of the instructions that are too concise fora novice to follow, or describe changes to the cooking method that result in a better dish.", "labels": [], "entities": []}, {"text": "We refer to such actionable information as a refinement.", "labels": [], "entities": []}, {"text": "Refinements can be quite prevalent in instruction reviews.", "labels": [], "entities": [{"text": "Refinements", "start_pos": 0, "end_pos": 11, "type": "METRIC", "confidence": 0.9656004905700684}]}, {"text": "Ina random sample of recipe reviews from allrecipes.com, we found that 57.8% contain refinements of the original recipe.", "labels": [], "entities": []}, {"text": "However, sifting through all reviews for refinements is a daunting task fora user.", "labels": [], "entities": []}, {"text": "Instead, we would like to automatically identify refinements in reviews, summarize them, and either create an annotated version of the instructions that reflects the collective experience of the community, or, more ambitiously, revise the instructions directly.", "labels": [], "entities": []}, {"text": "In this paper, we take first steps toward these goals by addressing the following tasks: (1) identifying reviews that contain refinements, (2) identifying text segments within reviews that describe refinements, and (3) aligning these refinement segments to steps in the instructions being reviewed provides an example).", "labels": [], "entities": []}, {"text": "Solving these tasks provides a foundation for downstream summarization and semantic analysis, and also suggests intermediate applications.", "labels": [], "entities": [{"text": "summarization", "start_pos": 57, "end_pos": 70, "type": "TASK", "confidence": 0.8214752674102783}, {"text": "semantic analysis", "start_pos": 75, "end_pos": 92, "type": "TASK", "confidence": 0.9033759832382202}]}, {"text": "For example, we can use review classification to filter or rank reviews as they are presented to future users, since reviews that contain refinements are more informative than a review which only says \"Great recipe, thanks for posting!\"", "labels": [], "entities": []}, {"text": "To the best of our knowledge, no previous work has explored this aspect of user-generated text.", "labels": [], "entities": []}, {"text": "While review mining has been studied extensively, we differ from previous work in that instead of focusing on evaluative information, we focus actionable information in the reviews.", "labels": [], "entities": [{"text": "review mining", "start_pos": 6, "end_pos": 19, "type": "TASK", "confidence": 0.7944735884666443}]}, {"text": "(See Section 2 fora more detailed discussion.)", "labels": [], "entities": []}, {"text": "There is no existing labeled data for the tasks of interest, and we would like the methods we develop to be easily applied in multiple domains.", "labels": [], "entities": []}, {"text": "Motivated by this, we propose a generative model for solving these tasks jointly without labeled data.", "labels": [], "entities": []}, {"text": "Interestingly, we find that jointly modeling refinements at both the review and segment level is beneficial.", "labels": [], "entities": []}, {"text": "We created anew recipe data set, and manually labeled a random sample to evaluate our model and several baselines.", "labels": [], "entities": []}, {"text": "We obtain 90.1% F 1 for predicting refinements at the review level, and 77.0% F 1 for predicting refinement segments within reviews.", "labels": [], "entities": [{"text": "F 1", "start_pos": 16, "end_pos": 19, "type": "METRIC", "confidence": 0.994174063205719}, {"text": "F 1", "start_pos": 78, "end_pos": 81, "type": "METRIC", "confidence": 0.9921551048755646}]}], "datasetContent": [{"text": "We first describe the methods we evaluate.", "labels": [], "entities": []}, {"text": "For comparison, we provide results with a baseline that randomly guesses according to the class distribution for each task.", "labels": [], "entities": []}, {"text": "We also evaluate a Review-level model: \u2022 R-Mix: A review-level mixture of multinomials with two latent states.", "labels": [], "entities": []}, {"text": "Note that this is similar to clustering at the review level, except that class priors are estimated.", "labels": [], "entities": []}, {"text": "R-Mix does not provide segment labels, though they can be obtained by labeling all segments with the review label.", "labels": [], "entities": [{"text": "R-Mix", "start_pos": 0, "end_pos": 5, "type": "DATASET", "confidence": 0.9201353192329407}]}, {"text": "We also evaluate the two Segment-level models described in Section 4.1 (with two latent states): \u2022 S-Mix: A segment-level mixture model.", "labels": [], "entities": []}, {"text": "\u2022 S-HMM: A segment-level HMM (Eq. 1).", "labels": [], "entities": []}, {"text": "These models do not provide review labels.", "labels": [], "entities": []}, {"text": "To obtain them, we assign y = yes if any segment is labeled as a refinement, and y = no otherwise.", "labels": [], "entities": []}, {"text": "Finally, we evaluate three versions of our model (Review + Segment and Review + Segment + Alignment) with one refinement segment label and one background segment label 5 : \u2022 RS-MixHMM: A mixture of HMMs (Eq. 2) with constraints (1) and (2) (see Section 4).", "labels": [], "entities": []}, {"text": "\u2022 RS-MixMix: A variant of RS-MixHMM without sequential dependencies.", "labels": [], "entities": []}, {"text": "\u2022 RSA-MixHMM: The full model that also incorporates alignment (Eq. 3).", "labels": [], "entities": []}, {"text": "Segment multinomials are initialized with a small amount of random noise to break the initial symmetry.", "labels": [], "entities": []}, {"text": "RSA-MixHMM segment multinomials are instead initialized to the RS-MixHMM solution.", "labels": [], "entities": []}, {"text": "We apply add-0.01 smoothing to the emission multinomials and add-1 smoothing to the transition multinomials in the M-step.", "labels": [], "entities": []}, {"text": "We estimate parameters with 21,887 unlabeled reviews by running EM until the relative percentage decrease in the marginal likelihood is \u2264 10 \u22124 (typically 10-20 iterations).", "labels": [], "entities": []}, {"text": "The models are evaluated on refinement F 1 and accuracy for both review and segment predictions using the annotated data described in Section 5.1.", "labels": [], "entities": [{"text": "refinement F 1", "start_pos": 28, "end_pos": 42, "type": "METRIC", "confidence": 0.8519423405329386}, {"text": "accuracy", "start_pos": 47, "end_pos": 55, "type": "METRIC", "confidence": 0.9997147917747498}]}, {"text": "For R-Mix and the segment (S-) models, we select the 1:1 mapping of latent states to labels that maximizes F 1 . For RSA-MixHMM and the RS-models this was not necessary (see Section 4.1).", "labels": [], "entities": [{"text": "F 1", "start_pos": 107, "end_pos": 110, "type": "METRIC", "confidence": 0.9770793914794922}]}, {"text": "R-Mix fails to accurately distinguish refinement and background reviews.", "labels": [], "entities": [{"text": "R-Mix", "start_pos": 0, "end_pos": 5, "type": "DATASET", "confidence": 0.8201636075973511}]}, {"text": "The words that best discriminate the two discovered review classes are \"savory ingredients\" (chicken, pepper, meat, garlic, soup) and \"baking/dessert ingredients\" (chocolate, cake, pie, these, flour).", "labels": [], "entities": []}, {"text": "In other words, reviews naturally cluster by topics rather than whether they contain refinements.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Unsupervised experiments comparing models for review and segment refinement identification on the recipe  data. Bold indicates the best result, and a  \u2020 next to an accuracy or F 1 value indicates that the improvements obtained  by RS-MixMix, RS-MixHMM, and RSA-MixHMM are significant (p = 0.05 according to a bootstrap test).", "labels": [], "entities": [{"text": "segment refinement identification", "start_pos": 67, "end_pos": 100, "type": "TASK", "confidence": 0.844149092833201}, {"text": "accuracy", "start_pos": 174, "end_pos": 182, "type": "METRIC", "confidence": 0.9990918636322021}, {"text": "F 1 value", "start_pos": 186, "end_pos": 195, "type": "METRIC", "confidence": 0.946502149105072}]}]}