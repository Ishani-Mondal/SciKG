{"title": [{"text": "Text-level Discourse Parsing with Rich Linguistic Features", "labels": [], "entities": [{"text": "Text-level Discourse Parsing", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.5702970723311106}]}], "abstractContent": [{"text": "In this paper, we develop an RST-style text-level discourse parser, based on the HILDA discourse parser (Hernault et al., 2010b).", "labels": [], "entities": [{"text": "RST-style text-level discourse parser", "start_pos": 29, "end_pos": 66, "type": "TASK", "confidence": 0.8532441407442093}, {"text": "HILDA discourse parser", "start_pos": 81, "end_pos": 103, "type": "TASK", "confidence": 0.7527827421824137}]}, {"text": "We significantly improve its tree-building step by incorporating our own rich linguistic features.", "labels": [], "entities": []}, {"text": "We also analyze the difficulty of extending traditional sentence-level discourse parsing to text-level parsing by comparing discourse-parsing performance under different discourse conditions.", "labels": [], "entities": [{"text": "sentence-level discourse parsing", "start_pos": 56, "end_pos": 88, "type": "TASK", "confidence": 0.7009080251057943}, {"text": "text-level parsing", "start_pos": 92, "end_pos": 110, "type": "TASK", "confidence": 0.6954925507307053}]}], "introductionContent": [{"text": "Ina well-written text, no unit of the text is completely isolated; interpretation requires understanding the unit's relation with the context.", "labels": [], "entities": []}, {"text": "Research in discourse parsing aims to unmask such relations in text, which is helpful for many downstream applications such as summarization, information retrieval, and question answering.", "labels": [], "entities": [{"text": "discourse parsing", "start_pos": 12, "end_pos": 29, "type": "TASK", "confidence": 0.7153728157281876}, {"text": "summarization", "start_pos": 127, "end_pos": 140, "type": "TASK", "confidence": 0.9920477271080017}, {"text": "information retrieval", "start_pos": 142, "end_pos": 163, "type": "TASK", "confidence": 0.792531281709671}, {"text": "question answering", "start_pos": 169, "end_pos": 187, "type": "TASK", "confidence": 0.9158985018730164}]}, {"text": "However, most existing discourse parsers operate on individual sentences alone, whereas discourse parsing is more powerful for text-level analysis.", "labels": [], "entities": [{"text": "discourse parsing", "start_pos": 88, "end_pos": 105, "type": "TASK", "confidence": 0.7478585243225098}]}, {"text": "Therefore, in this work, we aim to develop a textlevel discourse parser.", "labels": [], "entities": [{"text": "textlevel discourse parser", "start_pos": 45, "end_pos": 71, "type": "TASK", "confidence": 0.5898827215035757}]}, {"text": "We follow the framework of Rhetorical Structure Theory ( and we take the HILDA discourse parser) as the basis of our work, because it is the first fully implemented text-level discourse parser with state-of-the-art performance.", "labels": [], "entities": [{"text": "Rhetorical Structure Theory", "start_pos": 27, "end_pos": 54, "type": "TASK", "confidence": 0.6956934233506521}, {"text": "HILDA discourse parser", "start_pos": 73, "end_pos": 95, "type": "TASK", "confidence": 0.762086013952891}, {"text": "text-level discourse parser", "start_pos": 165, "end_pos": 192, "type": "TASK", "confidence": 0.7049587170282999}]}, {"text": "We significantly improve the performance of HILDA's treebuilding step (introduced in Section 5.1 below) by incorporating rich linguistic features (Section 5.3).", "labels": [], "entities": []}, {"text": "In our experiments (Section 6), we also analyze the difficulty with extending traditional sentence-level discourse parsing to text-level parsing, by comparing discourse parsing performance under different discourse conditions.", "labels": [], "entities": [{"text": "sentence-level discourse parsing", "start_pos": 90, "end_pos": 122, "type": "TASK", "confidence": 0.6972789764404297}, {"text": "text-level parsing", "start_pos": 126, "end_pos": 144, "type": "TASK", "confidence": 0.6715912371873856}, {"text": "discourse parsing", "start_pos": 159, "end_pos": 176, "type": "TASK", "confidence": 0.7378400266170502}]}], "datasetContent": [{"text": "As discussed in Section 5.1, our research focus in this paper is the tree-building step of the HILDA discourse parser, which consists of two classifications: Structure and Relation classification.", "labels": [], "entities": [{"text": "HILDA discourse parser", "start_pos": 95, "end_pos": 117, "type": "TASK", "confidence": 0.6699674129486084}, {"text": "Relation classification", "start_pos": 172, "end_pos": 195, "type": "TASK", "confidence": 0.7106432914733887}]}, {"text": "The binary Structure classifier decides whether a discourse relation is likely to hold between consecutive text spans, and the multi-class Relation classifier decides which discourse relation label holds between these two text spans if the Structure classifier predicts the existence of such a relation.", "labels": [], "entities": []}, {"text": "Although HILDA's bottom-up approach is aimed at building a discourse tree for the full text, it does not explicitly employ different strategies for withinsentence text spans and cross-sentence text spans.", "labels": [], "entities": []}, {"text": "However, we believe that discourse parsing is significantly more difficult for text spans at higher levels of the discourse tree structure.", "labels": [], "entities": [{"text": "discourse parsing", "start_pos": 25, "end_pos": 42, "type": "TASK", "confidence": 0.7038348615169525}]}, {"text": "Therefore, we conduct the following three sub-experiments to explore whether the two classifiers behave differently under different discourse conditions.", "labels": [], "entities": []}, {"text": "Within-sentence: Trained and tested on text span pairs belonging to the same sentence.", "labels": [], "entities": []}, {"text": "Cross-sentence: Trained and tested on text span pairs belonging to different sentences.", "labels": [], "entities": []}, {"text": "Hybrid: Trained and tested on all text span pairs.", "labels": [], "entities": []}, {"text": "In particular, we split the training set and the testing set following the convention of RST-DT, and conduct Structure and Relation classification by incorporating our rich linguistic features, as listed in Section 5.3 above.", "labels": [], "entities": [{"text": "Structure and Relation classification", "start_pos": 109, "end_pos": 146, "type": "TASK", "confidence": 0.8019263446331024}]}, {"text": "To rule out all confounding factors, all classifiers are trained and tested on the basis of individual text span pairs, by assuming the discourse subtree structure (if any) covering each individual text span has been already correctly identified (no error propagation).", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Number of training and testing instances used in  Structure classification.", "labels": [], "entities": [{"text": "Structure classification", "start_pos": 60, "end_pos": 84, "type": "TASK", "confidence": 0.9449504613876343}]}, {"text": " Table 2: Structure classification performance (in percent- age) on text spans of within-sentence, cross-sentence, and  all level. Performance that is significantly superior to that  of HILDA (p < .01, using the Wilcoxon sign-rank test for  significance) is denoted by *.", "labels": [], "entities": [{"text": "Structure classification", "start_pos": 10, "end_pos": 34, "type": "TASK", "confidence": 0.8061362206935883}, {"text": "HILDA", "start_pos": 186, "end_pos": 191, "type": "METRIC", "confidence": 0.7113519906997681}]}, {"text": " Table 3: Relation classification performance on text  spans of within-sentence, cross-sentence, and all levels.", "labels": [], "entities": [{"text": "Relation classification", "start_pos": 10, "end_pos": 33, "type": "TASK", "confidence": 0.8851864635944366}]}]}