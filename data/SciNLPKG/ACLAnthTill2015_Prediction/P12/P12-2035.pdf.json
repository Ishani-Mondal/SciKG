{"title": [{"text": "Transforming Standard Arabic to Colloquial Arabic", "labels": [], "entities": [{"text": "Transforming Standard Arabic", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.8414027293523153}]}], "abstractContent": [{"text": "We present a method for generating Colloquial Egyptian Arabic (CEA) from morphologically dis-ambiguated Modern Standard Arabic (MSA).", "labels": [], "entities": [{"text": "generating Colloquial Egyptian Arabic (CEA)", "start_pos": 24, "end_pos": 67, "type": "TASK", "confidence": 0.56943308029856}]}, {"text": "When used in POS tagging, this process improves the accuracy from 73.24% to 86.84% on unseen CEA text, and reduces the percentage of out-of-vocabulary words from 28.98% to 16.66%.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 13, "end_pos": 24, "type": "TASK", "confidence": 0.8107357323169708}, {"text": "accuracy", "start_pos": 52, "end_pos": 60, "type": "METRIC", "confidence": 0.9994462132453918}]}, {"text": "The process holds promise for any NLP task targeting the dialectal varieties of Arabic; e.g., this approach may provide a cheap way to leverage MSA data and morphological resources to create resources for colloquial Arabic to English machine translation.", "labels": [], "entities": [{"text": "colloquial Arabic to English machine translation", "start_pos": 205, "end_pos": 253, "type": "TASK", "confidence": 0.7259904146194458}]}, {"text": "It can also considerably speedup the annotation of Arabic dialects.", "labels": [], "entities": []}], "introductionContent": [{"text": "Most of the research on Arabic is focused on Modern Standard Arabic.", "labels": [], "entities": [{"text": "Modern Standard Arabic", "start_pos": 45, "end_pos": 67, "type": "DATASET", "confidence": 0.8748544454574585}]}, {"text": "Dialectal varieties have not received much attention due to the lack of dialectal tools and annotated texts.", "labels": [], "entities": []}, {"text": "In this paper, we present a rule-based method to generate Colloquial Egyptian Arabic (CEA) from Modern Standard Arabic (MSA), relying on segment-based part-of-speech tags.", "labels": [], "entities": []}, {"text": "The transformation process relies on the observation that dialectal varieties of Arabic differ mainly in the use of affixes and function words while the word stem mostly remains unchanged.", "labels": [], "entities": []}, {"text": "For example, given the Buckwalter-encoded MSA sentence \"AlAxwAn Almslmwn lm yfwzwA fy AlAntxbAt\" the rules produce \"AlAxwAn Almslmyn mfAzw$ f AlAntxAbAt\" (\u202b\u0627\u0627\u0644\u0648\u062a\u062e\u0627\u0628\u0627\u062a\u202c \u202b\u0641\u202c \u202b\u0645\u0641\u0627\u0632\u0648\u0634\u202c \u202b\u0627\u0644\u0645\u0633\u0644\u0645\u064a\u0647\u202c \u202b,\u0627\u0627\u0644\u062e\u0649\u0627\u0646\u202c The Muslim Brotherhood did not win the elections).", "labels": [], "entities": []}, {"text": "The availability of segment-based part-of-speech tags is essential since many of the affixes in MSA are ambiguous.", "labels": [], "entities": []}, {"text": "For example, lm could be either a negative particle or a question work, and the word AlAxwAn could be either made of two segments (Al+<xwAn, the brothers), or three segments (Al+>xw+An, the two brothers).", "labels": [], "entities": []}, {"text": "We first introduce the transformation rules, and show that in many cases it is feasible to transform MSA to CEA, although there are cases that require much more than POS tags.", "labels": [], "entities": []}, {"text": "We then provide atypical casein which we utilize the transformed text of the Arabic Treebank ( to build a part-of-speech tagger for CEA.", "labels": [], "entities": [{"text": "Arabic Treebank", "start_pos": 77, "end_pos": 92, "type": "DATASET", "confidence": 0.9029904007911682}, {"text": "CEA", "start_pos": 132, "end_pos": 135, "type": "DATASET", "confidence": 0.8772217035293579}]}, {"text": "The tagger improves the accuracy of POS tagging on authentic Egyptian Arabic by 13% absolute (from 73.24% to 86.84%) and reduces the percentage of out-of-vocabulary words from 28.98% to 16.66%.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 24, "end_pos": 32, "type": "METRIC", "confidence": 0.9995926022529602}, {"text": "POS tagging", "start_pos": 36, "end_pos": 47, "type": "TASK", "confidence": 0.8403000235557556}]}, {"text": "shows a sentence in MSA and its CEA counterpart.", "labels": [], "entities": [{"text": "MSA", "start_pos": 20, "end_pos": 23, "type": "DATASET", "confidence": 0.8966949582099915}]}, {"text": "Both can be translated into: \"We did not write it for them.\"", "labels": [], "entities": []}, {"text": "MSA has three words while CEA is more synthetic as the preposition and the negative particle turn into clitics.", "labels": [], "entities": [{"text": "MSA", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.8659160137176514}, {"text": "CEA", "start_pos": 26, "end_pos": 29, "type": "METRIC", "confidence": 0.9659742116928101}]}, {"text": "illustrates the end product of one of the Imperfect transformation rules, namely the case where the Imperfect Verb is preceded by the negative particle lm.", "labels": [], "entities": [{"text": "Imperfect transformation", "start_pos": 42, "end_pos": 66, "type": "TASK", "confidence": 0.7403798997402191}]}, {"text": "Our 103 rules cover nominals (number and case affixes), verbs (tense, number, gender, and modality), pronouns (number and gender), and demonstrative pronouns (number and gender).", "labels": [], "entities": []}, {"text": "The rules also cover certain lexical items as 400 words in MSA have been converted to their com-mon CEA counterparts.", "labels": [], "entities": []}, {"text": "Examples of lexical conversions include ZlAm and Dlmp (darkness), rjl and rAjl (man), rjAl and rjAlp (men), and kvyr and ktyr (many), where the first word is the MSA version and the second is the CEA version.", "labels": [], "entities": []}], "datasetContent": [{"text": "We ran five experiments to test the effect of MSA to CEA conversion on POS tagging: (a) Standard, where we train the tagger on the ATB MSA data, (b) 3-gram LM, where for each MSA sentence we generate all transformed sentences (see Section 2.1 and) and pick the most probable sentence according to a trigram language model built from an 11.5 million words of user contributed comments.", "labels": [], "entities": [{"text": "MSA to CEA conversion", "start_pos": 46, "end_pos": 67, "type": "TASK", "confidence": 0.6778495982289314}, {"text": "POS tagging", "start_pos": 71, "end_pos": 82, "type": "TASK", "confidence": 0.7844812870025635}, {"text": "Standard", "start_pos": 88, "end_pos": 96, "type": "METRIC", "confidence": 0.9546292424201965}, {"text": "ATB MSA data", "start_pos": 131, "end_pos": 143, "type": "DATASET", "confidence": 0.9382214347521464}]}, {"text": "1 This corpus is highly dialectal 1 Available from http://www.cs.jhu.edu/~ozaidan/AOC Egyptian Arabic, but like all similar collections, it is diglossic and demonstrates a high degree of code-switching between MSA and CEA.", "labels": [], "entities": []}, {"text": "We use the SRILM toolkit) for language modeling and sentence scoring, (c) Random, where we choose a random sentence from all the correct sentences generated for each MSA sentence, (d) Hybrid, where we combine the data in a) with the best settings (as measured on the dev set) using the converted colloquial data (namely experiment c).", "labels": [], "entities": [{"text": "language modeling", "start_pos": 30, "end_pos": 47, "type": "TASK", "confidence": 0.7731467485427856}, {"text": "sentence scoring", "start_pos": 52, "end_pos": 68, "type": "TASK", "confidence": 0.7468853890895844}]}, {"text": "Hybridization is necessary since most Arabic data in blogs and comments area mix of MSA and CEA, and (e) Hybrid + dev, where we enrich the Hybrid training set with the dev data.", "labels": [], "entities": []}, {"text": "We use the following metrics for evaluation: KWA: Known Word Accuracy (%), UWA: Unknown Word Accuracy (%), TA: Total Accuracy (%), and UW: unknown words (%) in the respective set in the respective experiment.", "labels": [], "entities": [{"text": "UWA: Unknown Word Accuracy", "start_pos": 75, "end_pos": 101, "type": "METRIC", "confidence": 0.7162534773349762}, {"text": "TA: Total Accuracy", "start_pos": 107, "end_pos": 125, "type": "METRIC", "confidence": 0.8791239410638809}, {"text": "UW", "start_pos": 135, "end_pos": 137, "type": "METRIC", "confidence": 0.8064217567443848}]}, {"text": "We notice that randomly selecting a sentence from the correct generated sentences yields better results than choosing the most probable sentence according to a language model.", "labels": [], "entities": []}, {"text": "The reason for this maybe that randomization guarantees more coverage of the various forms.", "labels": [], "entities": []}, {"text": "We have found that the vocabulary size (the number of unique word types) for the training set generated for the Random experiment is considerably larger than the vocabulary size for the 3-gram LM experiment (55367 unique word types in Random versus 51306 in 3-gram LM), which results in a drop of 4.6% absolute in the percentage of unknown words: 27.31% versus 22.30%).", "labels": [], "entities": []}, {"text": "This drop in the percentage of unknown words may indicate that generating all possible variations of CEA maybe more useful than using a language model in general.", "labels": [], "entities": []}, {"text": "Even in a CEA corpus of 35 million words, one third of the words generated by the rules are not in the corpus, while many of these are in both the test set and the development set.", "labels": [], "entities": [{"text": "CEA corpus", "start_pos": 10, "end_pos": 20, "type": "DATASET", "confidence": 0.8870780169963837}]}, {"text": "We also notice that the conversion alone improves tagging accuracy from 75.77% to 79.25% on the development set, and from 73.24% to 79.67% on the test set.", "labels": [], "entities": [{"text": "tagging", "start_pos": 50, "end_pos": 57, "type": "TASK", "confidence": 0.9505428075790405}, {"text": "accuracy", "start_pos": 58, "end_pos": 66, "type": "METRIC", "confidence": 0.980868399143219}]}, {"text": "Combining the original MSA and the best scoring converted data (Random) raises the accuracies to 84.87% and 83.81% respectively.", "labels": [], "entities": [{"text": "Random)", "start_pos": 64, "end_pos": 71, "type": "METRIC", "confidence": 0.9568765163421631}, {"text": "accuracies", "start_pos": 83, "end_pos": 93, "type": "METRIC", "confidence": 0.9993599057197571}]}, {"text": "The percentage of unknown words drops from 29.98% to 19.45% in the test set when we used the hybrid data.", "labels": [], "entities": []}, {"text": "The fact that the percentage of unknown words drops further to 16.66% in the Hybrid+dev experiment points out the authentic colloquial data contains elements that have not been captured using conversion alone.", "labels": [], "entities": []}], "tableCaptions": []}