{"title": [{"text": "Maximum Expected BLEU Training of Phrase and Lexicon Translation Models", "labels": [], "entities": [{"text": "BLEU", "start_pos": 17, "end_pos": 21, "type": "METRIC", "confidence": 0.8814747333526611}, {"text": "Phrase and Lexicon Translation", "start_pos": 34, "end_pos": 64, "type": "TASK", "confidence": 0.6521585807204247}]}], "abstractContent": [{"text": "This paper proposes anew discriminative training method in constructing phrase and lexicon translation models.", "labels": [], "entities": [{"text": "phrase and lexicon translation", "start_pos": 72, "end_pos": 102, "type": "TASK", "confidence": 0.6231023296713829}]}, {"text": "In order to reliably learn a myriad of parameters in these models, we propose an expected BLEU score-based utility function with KL regularization as the objective, and train the models on a large parallel dataset.", "labels": [], "entities": [{"text": "BLEU score-based utility function", "start_pos": 90, "end_pos": 123, "type": "METRIC", "confidence": 0.9346144199371338}]}, {"text": "For training, we derive growth transformations for phrase and lexicon translation probabilities to iteratively improve the objective.", "labels": [], "entities": [{"text": "phrase and lexicon translation probabilities", "start_pos": 51, "end_pos": 95, "type": "TASK", "confidence": 0.6912923514842987}]}, {"text": "The proposed method, evaluated on the Europarl German-to-English dataset, leads to a 1.1 BLEU point improvement over a state-of-the-art baseline translation system.", "labels": [], "entities": [{"text": "Europarl German-to-English dataset", "start_pos": 38, "end_pos": 72, "type": "DATASET", "confidence": 0.9426477551460266}, {"text": "BLEU", "start_pos": 89, "end_pos": 93, "type": "METRIC", "confidence": 0.9986741542816162}]}, {"text": "In IWSLT 2011 Benchmark, our system using the proposed method achieves the best Chinese-to-English translation result on the task of translating TED talks.", "labels": [], "entities": [{"text": "IWSLT 2011 Benchmark", "start_pos": 3, "end_pos": 23, "type": "DATASET", "confidence": 0.9275627334912618}, {"text": "Chinese-to-English translation", "start_pos": 80, "end_pos": 110, "type": "TASK", "confidence": 0.6100666970014572}, {"text": "translating TED talks", "start_pos": 133, "end_pos": 154, "type": "TASK", "confidence": 0.8239238858222961}]}], "introductionContent": [{"text": "Discriminative training is an active area in statistical machine translation (SMT) (e.g.,).", "labels": [], "entities": [{"text": "Discriminative training", "start_pos": 0, "end_pos": 23, "type": "TASK", "confidence": 0.9008017182350159}, {"text": "statistical machine translation (SMT)", "start_pos": 45, "end_pos": 82, "type": "TASK", "confidence": 0.8228816489378611}]}, {"text": "proposed using a loglinear model to incorporate multiple features for translation, and proposed a minimum error rate training (MERT) method to train the feature weights to optimize a desirable translation metric.", "labels": [], "entities": [{"text": "translation", "start_pos": 70, "end_pos": 81, "type": "TASK", "confidence": 0.9864873290061951}, {"text": "minimum error rate training (MERT)", "start_pos": 98, "end_pos": 132, "type": "METRIC", "confidence": 0.844684009041105}]}, {"text": "While the log-linear model itself is discriminative, the phrase and lexicon translation features, which are among the most important components of SMT, are derived from either generative models or heuristics (.", "labels": [], "entities": [{"text": "phrase and lexicon translation", "start_pos": 57, "end_pos": 87, "type": "TASK", "confidence": 0.6970239952206612}, {"text": "SMT", "start_pos": 147, "end_pos": 150, "type": "TASK", "confidence": 0.990019679069519}]}, {"text": "Moreover, the parameters in the phrase and lexicon translation models are estimated by relative frequency or maximizing joint likelihood, which may not correspond closely to the translation measure, e.g., bilingual evaluation understudy (BLEU) ().", "labels": [], "entities": [{"text": "bilingual evaluation understudy (BLEU)", "start_pos": 205, "end_pos": 243, "type": "METRIC", "confidence": 0.5904850512742996}]}, {"text": "Therefore, it is desirable to train all these parameters to directly maximize an objective that directly links to translation quality.", "labels": [], "entities": []}, {"text": "However, there area large number of parameters in these models, making discriminative training for them non-trivial (e.g.,).", "labels": [], "entities": []}, {"text": "proposed a large set of lexical and Part-of-Speech features and trained the model weights associated with these features using perceptron.", "labels": [], "entities": []}, {"text": "Since many of the reference translations are non-reachable, an empirical local updating strategy had to be devised to fix this problem by picking a pseudo reference.", "labels": [], "entities": []}, {"text": "Many such non-desirable heuristics led to moderate gains reported in that work.", "labels": [], "entities": []}, {"text": "improved a syntactic SMT system by adding as many as ten thousand syntactic features, and used Margin Infused Relaxed Algorithm (MIRA) to train the feature weights.", "labels": [], "entities": [{"text": "SMT", "start_pos": 21, "end_pos": 24, "type": "TASK", "confidence": 0.7020676136016846}, {"text": "Margin Infused Relaxed Algorithm (MIRA)", "start_pos": 95, "end_pos": 134, "type": "METRIC", "confidence": 0.8485049520220075}]}, {"text": "However, the number of parameters in common phrase and lexicon translation models is much larger.", "labels": [], "entities": [{"text": "common phrase and lexicon translation", "start_pos": 37, "end_pos": 74, "type": "TASK", "confidence": 0.682472026348114}]}, {"text": "In this work, we present anew, highly effective discriminative learning method for phrase and lexicon translation models.", "labels": [], "entities": [{"text": "phrase and lexicon translation models", "start_pos": 83, "end_pos": 120, "type": "TASK", "confidence": 0.7386352062225342}]}, {"text": "The training objective is an expected BLEU score, which is closely linked to translation quality.", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 38, "end_pos": 48, "type": "METRIC", "confidence": 0.9800853431224823}, {"text": "translation", "start_pos": 77, "end_pos": 88, "type": "TASK", "confidence": 0.9538329839706421}]}, {"text": "Further, we apply a Kullback-Leibler (KL) divergence regularization to prevent over-fitting.", "labels": [], "entities": [{"text": "divergence regularization", "start_pos": 42, "end_pos": 67, "type": "TASK", "confidence": 0.8446265459060669}]}, {"text": "For effective optimization, we derive updating formulas of growth transformation (GT) for phrase and lexicon translation probabilities.", "labels": [], "entities": [{"text": "phrase and lexicon translation probabilities", "start_pos": 90, "end_pos": 134, "type": "TASK", "confidence": 0.6648297190666199}]}, {"text": "A GT is a transformation of the probabilities that guarantees strict non-decrease of the objective over each GT iteration unless a local maximum is reached.", "labels": [], "entities": []}, {"text": "A similar GT technique has been successfully used in speech recognition (.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 53, "end_pos": 71, "type": "TASK", "confidence": 0.8633013367652893}]}, {"text": "Our work demonstrates that it works with large scale discriminative training of SMT model as well.", "labels": [], "entities": [{"text": "SMT", "start_pos": 80, "end_pos": 83, "type": "TASK", "confidence": 0.9863907098770142}]}, {"text": "Our work is based on a phrase-based SMT system.", "labels": [], "entities": [{"text": "SMT", "start_pos": 36, "end_pos": 39, "type": "TASK", "confidence": 0.8456867337226868}]}, {"text": "Experiments on the Europarl German-toEnglish dataset show that the proposed method leads to a 1.1 BLEU point improvement over a strong baseline.", "labels": [], "entities": [{"text": "Europarl German-toEnglish dataset", "start_pos": 19, "end_pos": 52, "type": "DATASET", "confidence": 0.9317858815193176}, {"text": "BLEU", "start_pos": 98, "end_pos": 102, "type": "METRIC", "confidence": 0.9960020184516907}]}, {"text": "The proposed method is also successfully evaluated on the IWSLT 2011 benchmark test set, where the task is to translate TED talks (www.ted.com).", "labels": [], "entities": [{"text": "IWSLT 2011 benchmark test set", "start_pos": 58, "end_pos": 87, "type": "DATASET", "confidence": 0.9614508032798768}, {"text": "translate TED talks", "start_pos": 110, "end_pos": 129, "type": "TASK", "confidence": 0.8479767839113871}]}, {"text": "Our experimental results on this open-domain spoken language translation task show that the proposed method leads to significant translation performance improvement over a state-of-the-art baseline, and the system using the proposed method achieved the best single system translation result in the Chineseto-English MT track.", "labels": [], "entities": [{"text": "open-domain spoken language translation task", "start_pos": 33, "end_pos": 77, "type": "TASK", "confidence": 0.6821412146091461}, {"text": "Chineseto-English MT track", "start_pos": 298, "end_pos": 324, "type": "DATASET", "confidence": 0.6421032746632894}]}], "datasetContent": [{"text": "In evaluating the proposed method, we use two separate datasets.", "labels": [], "entities": []}, {"text": "We first describe the experiments with the Europarl dataset (Koehn 2002), followed by the experiments with the more recent IWSLT-2011 task).", "labels": [], "entities": [{"text": "Europarl dataset", "start_pos": 43, "end_pos": 59, "type": "DATASET", "confidence": 0.9964756071567535}, {"text": "IWSLT-2011 task", "start_pos": 123, "end_pos": 138, "type": "DATASET", "confidence": 0.8211733400821686}]}, {"text": "In evaluating the proposed method, we use two separate datasets.", "labels": [], "entities": []}, {"text": "First, we conduct experiments on the Europarl German-to-English dataset.", "labels": [], "entities": [{"text": "Europarl German-to-English dataset", "start_pos": 37, "end_pos": 71, "type": "DATASET", "confidence": 0.9619662960370382}]}, {"text": "The training corpus contains 751K sentence pairs, 21 words per sentence on average.", "labels": [], "entities": []}, {"text": "2000 sentences are provided in the development set.", "labels": [], "entities": []}, {"text": "We use the first 1000 sentences for \u00ed \u00b5\u00ed\u00bb\u008c tuning, and the rest for validation.", "labels": [], "entities": []}, {"text": "The test set consists of 2000 sentences.", "labels": [], "entities": []}, {"text": "Usually, the tuning set matches the test condition better, and therefore is preferable for \u03bb tuning.", "labels": [], "entities": []}, {"text": "To build the baseline phrase-based SMT system, we first perform word alignment on the training set using a hidden Markov model with lexicalized distortion, then extract the phrase table from the word aligned bilingual texts (.", "labels": [], "entities": [{"text": "SMT", "start_pos": 35, "end_pos": 38, "type": "TASK", "confidence": 0.90496826171875}, {"text": "word alignment", "start_pos": 64, "end_pos": 78, "type": "TASK", "confidence": 0.7473902702331543}]}, {"text": "The maximum phrase length is set to four.", "labels": [], "entities": []}, {"text": "Other models used in the baseline system include lexicalized ordering model, word count and phrase count, and a 3-gram LM trained on the English side of the parallel training corpus.", "labels": [], "entities": []}, {"text": "Feature weights are tuned by MERT.", "labels": [], "entities": [{"text": "MERT", "start_pos": 29, "end_pos": 33, "type": "DATASET", "confidence": 0.8010246157646179}]}, {"text": "A fast beam-search phrasebased decoder) is used and the distortion limit is set to four.", "labels": [], "entities": []}, {"text": "Details of the phrase and lexicon translation models are given in.", "labels": [], "entities": []}, {"text": "This baseline achieves a BLEU score of 26.22% on the test set.", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 25, "end_pos": 35, "type": "METRIC", "confidence": 0.987102746963501}]}, {"text": "This baseline system is also used to generate a 100-best list of the training corpus during maximum expected BLEU training..", "labels": [], "entities": [{"text": "BLEU", "start_pos": 109, "end_pos": 113, "type": "METRIC", "confidence": 0.9548273682594299}]}, {"text": "Summary of phrase and lexicon translation models  During training, we first tune the regularization factor \u03c4 based on the performance on the validation set.", "labels": [], "entities": [{"text": "phrase and lexicon translation", "start_pos": 11, "end_pos": 41, "type": "TASK", "confidence": 0.6581235900521278}]}, {"text": "For simplicity reasons, the tuning of \u03c4 makes use of only the phrase translation models.", "labels": [], "entities": [{"text": "phrase translation", "start_pos": 62, "end_pos": 80, "type": "TASK", "confidence": 0.7190120965242386}]}, {"text": "reports the BLEU scores and gains over the baseline given different values of \u03c4.", "labels": [], "entities": [{"text": "BLEU scores", "start_pos": 12, "end_pos": 23, "type": "METRIC", "confidence": 0.9737533330917358}]}, {"text": "The results highlight the importance of regularization.", "labels": [], "entities": [{"text": "regularization", "start_pos": 40, "end_pos": 54, "type": "TASK", "confidence": 0.9599120616912842}]}, {"text": "While \u03c4 = 5\u00d710 !!", "labels": [], "entities": []}, {"text": "gives the best score on the validation set, the gain is shown to be substantially reduced to merely 0.2 BLEU point when \u03c4 = 0, i.e., no regularization.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 104, "end_pos": 108, "type": "METRIC", "confidence": 0.998941957950592}]}, {"text": "We set the optimal value of \u03c4 = 5\u00d710 !!", "labels": [], "entities": []}, {"text": "Results on degrees of regularizations.", "labels": [], "entities": []}, {"text": "BLEU scores are reported on the validation set.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 0, "end_pos": 4, "type": "METRIC", "confidence": 0.9853034019470215}, {"text": "validation set", "start_pos": 32, "end_pos": 46, "type": "DATASET", "confidence": 0.6945656538009644}]}, {"text": "\u0394\u00ed \u00b5\u00ed\u00b0\u00b5\u00ed \u00b5\u00ed\u00b0\u00bf\u00ed \u00b5\u00ed\u00b0\u00b8\u00ed \u00b5\u00ed\u00b1\u0088 denotes the gain over the baseline.", "labels": [], "entities": []}, {"text": "Fixing the optimal regularization factor \u03c4, we then study the relationship between the expected sentence-level BLEU (Exp.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 111, "end_pos": 115, "type": "METRIC", "confidence": 0.9794166684150696}]}, {"text": "BLEU) score of N-best lists and the corpus-level BLEU score of 1-best translations.", "labels": [], "entities": [{"text": "BLEU) score", "start_pos": 0, "end_pos": 11, "type": "METRIC", "confidence": 0.9462181329727173}, {"text": "BLEU score", "start_pos": 49, "end_pos": 59, "type": "METRIC", "confidence": 0.9711398184299469}]}, {"text": "The conjectured close relationship between the two is important in justifying our use of the former as the training objective.", "labels": [], "entities": []}, {"text": "shows these two scores on the training set over training iterations.", "labels": [], "entities": []}, {"text": "Since the expected BLEU is affected by \u03bb strongly, we fix the value of \u03bb in order to make the expected BLEU comparable across different iterations.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 19, "end_pos": 23, "type": "METRIC", "confidence": 0.9978485107421875}, {"text": "BLEU", "start_pos": 103, "end_pos": 107, "type": "METRIC", "confidence": 0.997403085231781}]}, {"text": "From it is clear that the expected BLEU score correlates strongly with the real BLEU score, justifying its use as our training objective.", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 35, "end_pos": 45, "type": "METRIC", "confidence": 0.9842513501644135}, {"text": "BLEU score", "start_pos": 80, "end_pos": 90, "type": "METRIC", "confidence": 0.9821546971797943}]}, {"text": "Next, we study the effects of training the phrase translation probabilities and the lexicon translation probabilities according to the GT formulas presented in the preceding section.", "labels": [], "entities": [{"text": "phrase translation", "start_pos": 43, "end_pos": 61, "type": "TASK", "confidence": 0.6891959011554718}]}, {"text": "The breakdown results are shown in.", "labels": [], "entities": []}, {"text": "Compared with the baseline, training phrase or lexicon models alone gives again of 0.7 and 0.5 BLEU points, respectively, on the test set.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 95, "end_pos": 99, "type": "METRIC", "confidence": 0.9994401335716248}]}, {"text": "For a full training of both phrase and lexicon models, we adopt two learning schedules: update both models together at each iteration (simultaneously), or update them in two stages (two-stage), where the phrase models are trained first until reaching the best score on the validation set and then the lexicon models are trained.", "labels": [], "entities": []}, {"text": "Both learning schedules give significant improvements over the baseline and also over training phrase or lexicon models alone.", "labels": [], "entities": []}, {"text": "The twostage training of both models gives the best result of 27.33%, outperforming the baseline by 1.1 BLEU points.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 104, "end_pos": 108, "type": "METRIC", "confidence": 0.9995585083961487}]}, {"text": "More detail of the two-stage training is provided in, where BLEU scores in each stage are shown as a function of the GT training iteration.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 60, "end_pos": 64, "type": "METRIC", "confidence": 0.9988569021224976}]}, {"text": "The phrase translation probabilities (PT) are trained alone in the first stage, shown in blue color.", "labels": [], "entities": [{"text": "phrase translation probabilities (PT)", "start_pos": 4, "end_pos": 41, "type": "TASK", "confidence": 0.7181207736333212}]}, {"text": "After five iterations, the BLEU score on the validation set reaches the peak value, with further iteration giving BLEU score fluctuation.", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 27, "end_pos": 37, "type": "METRIC", "confidence": 0.9814353585243225}, {"text": "BLEU score fluctuation", "start_pos": 114, "end_pos": 136, "type": "METRIC", "confidence": 0.9703638752301534}]}, {"text": "Hence, we perform lexicon model (LEX) training starting from the sixth iteration with the corresponding BLEU scores shown in red color in.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 104, "end_pos": 108, "type": "METRIC", "confidence": 0.998874843120575}]}, {"text": "The BLEU score is further improved by 0.4 points after additional three iterations of training the lexicon models.", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 4, "end_pos": 14, "type": "METRIC", "confidence": 0.9781903028488159}]}, {"text": "In total, nine iterations are performed to complete the two-stage GT training of all phrase and lexicon models.", "labels": [], "entities": [{"text": "GT training", "start_pos": 66, "end_pos": 77, "type": "TASK", "confidence": 0.87718266248703}]}, {"text": "As the second evaluation task, we apply our new method described in this paper to the 2011 IWSLT Chinese-to-English machine translation benchmark).", "labels": [], "entities": [{"text": "IWSLT Chinese-to-English machine translation", "start_pos": 91, "end_pos": 135, "type": "TASK", "confidence": 0.7427443861961365}]}, {"text": "The main focus of the IWSLT2011 Evaluation is the translation of TED talks (www.ted.com).", "labels": [], "entities": [{"text": "IWSLT2011 Evaluation", "start_pos": 22, "end_pos": 42, "type": "DATASET", "confidence": 0.7468646764755249}, {"text": "translation of TED talks", "start_pos": 50, "end_pos": 74, "type": "TASK", "confidence": 0.870912030339241}]}, {"text": "These talks are originally given in English.", "labels": [], "entities": []}, {"text": "In the Chinese-to-English translation task, we are provided with human translated Chinese text with punctuations inserted.", "labels": [], "entities": [{"text": "Chinese-to-English translation", "start_pos": 7, "end_pos": 37, "type": "TASK", "confidence": 0.687065064907074}]}, {"text": "The goal is to match the human transcribed English speech with punctuations.", "labels": [], "entities": []}, {"text": "This is an open-domain spoken language translation task.", "labels": [], "entities": [{"text": "open-domain spoken language translation task", "start_pos": 11, "end_pos": 55, "type": "TASK", "confidence": 0.6750085353851318}]}, {"text": "The training data consist of 110K sentences in the transcripts of the TED talks and their translations, in English and Chinese, respectively.", "labels": [], "entities": [{"text": "TED talks", "start_pos": 70, "end_pos": 79, "type": "DATASET", "confidence": 0.7068619430065155}]}, {"text": "Each sentence consists of 20 words on average.", "labels": [], "entities": []}, {"text": "Two development sets are provided, namely, dev2010 and tst2010.", "labels": [], "entities": []}, {"text": "They consist of 934 sentences and 1664 sentences, respectively.", "labels": [], "entities": []}, {"text": "We use dev2010 for \u03bb tuning and tst2010 for validation.", "labels": [], "entities": []}, {"text": "The test set tst2011 consists of 1450 sentences.", "labels": [], "entities": []}, {"text": "In our system, a primary phrase table is trained from the 110K TED parallel training data, and a 3-gram LM is trained on the English side of the parallel data.", "labels": [], "entities": [{"text": "110K TED parallel training data", "start_pos": 58, "end_pos": 89, "type": "DATASET", "confidence": 0.5873871684074402}]}, {"text": "We are also provided additional outof-domain data for potential usage.", "labels": [], "entities": []}, {"text": "From them, we train a secondary 5-gram LM on 115M sentences of supplementary English data, and a secondary phrase table from 500K sentences selected from the supplementary UN corpus by the method proposed by.", "labels": [], "entities": [{"text": "UN corpus", "start_pos": 172, "end_pos": 181, "type": "DATASET", "confidence": 0.6872179359197617}]}, {"text": "In carrying out the maximum expected BLEU training, we use 100-best list and tune the regularization factor to the optimal value of \u03c4 = 1\u00d710 !!", "labels": [], "entities": [{"text": "BLEU", "start_pos": 37, "end_pos": 41, "type": "METRIC", "confidence": 0.9972686767578125}]}, {"text": "We only train the parameters of the primary phrase table.", "labels": [], "entities": []}, {"text": "The secondary phrase table and LM are excluded from the training process since the out-of-domain phrase table is less relevant to the TED translation task, and the large LM slows down the N-best generation process significantly.", "labels": [], "entities": [{"text": "TED translation task", "start_pos": 134, "end_pos": 154, "type": "TASK", "confidence": 0.9465133547782898}]}, {"text": "At the end, we perform one final MERT to tune the relative weights with all features including the secondary phrase table and LM.", "labels": [], "entities": [{"text": "MERT", "start_pos": 33, "end_pos": 37, "type": "METRIC", "confidence": 0.9450748562812805}]}, {"text": "The translation results are presented in.", "labels": [], "entities": []}, {"text": "The baseline is a phrase-based system with all features including the secondary phrase table and LM.", "labels": [], "entities": []}, {"text": "The new system uses the same features except that the primary phrase table is discriminatively trained using maximum expected-BLEU and GT optimization as described earlier in this paper.", "labels": [], "entities": []}, {"text": "The results are obtained using the two-stage training schedule, including six iterations for training phrase translation models and two iterations for training lexicon translation models.", "labels": [], "entities": [{"text": "phrase translation", "start_pos": 102, "end_pos": 120, "type": "TASK", "confidence": 0.727624848484993}, {"text": "training lexicon translation", "start_pos": 151, "end_pos": 179, "type": "TASK", "confidence": 0.7103136777877808}]}, {"text": "The results in show that the proposed method leads to an improvement of 1.2 BLEU point over the baseline.", "labels": [], "entities": [{"text": "BLEU point", "start_pos": 76, "end_pos": 86, "type": "METRIC", "confidence": 0.9766669869422913}]}, {"text": "This gives the best single system result on this task.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 3. Results on the Europarl German-to-English  dataset. The BLEU measures from various settings of  maximum expected BLEU training are compared with  the baseline, where * denotes that the gain over the  baseline is statistically significant with a significance  level > 99%, measured by paired bootstrap resampling  method proposed by Koehn (2004).", "labels": [], "entities": [{"text": "Europarl German-to-English  dataset", "start_pos": 25, "end_pos": 60, "type": "DATASET", "confidence": 0.9457423488299052}, {"text": "BLEU", "start_pos": 66, "end_pos": 70, "type": "METRIC", "confidence": 0.9973219037055969}, {"text": "BLEU", "start_pos": 123, "end_pos": 127, "type": "METRIC", "confidence": 0.9687419533729553}]}, {"text": " Table 4.  The baseline is a phrase-based system with all  features including the secondary phrase table and  LM. The new system uses the same features except  that the primary phrase table is discriminatively", "labels": [], "entities": []}, {"text": " Table 4. The translation results on IWSLT 2011  MT_CE task.", "labels": [], "entities": [{"text": "translation", "start_pos": 14, "end_pos": 25, "type": "TASK", "confidence": 0.9767321944236755}, {"text": "IWSLT 2011  MT_CE task", "start_pos": 37, "end_pos": 59, "type": "DATASET", "confidence": 0.863887776931127}]}]}