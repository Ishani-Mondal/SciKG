{"title": [{"text": "A Corpus of Textual Revisions in Second Language Writing", "labels": [], "entities": [{"text": "Textual Revisions in Second Language Writing", "start_pos": 12, "end_pos": 56, "type": "TASK", "confidence": 0.7818188965320587}]}], "abstractContent": [{"text": "This paper describes the creation of the first large-scale corpus containing drafts and final versions of essays written by non-native speakers, with the sentences aligned across different versions.", "labels": [], "entities": []}, {"text": "Furthermore, the sentences in the drafts are annotated with comments from teachers.", "labels": [], "entities": []}, {"text": "The corpus is intended to support research on textual revision by language learners, and how it is influenced by feedback.", "labels": [], "entities": [{"text": "textual revision", "start_pos": 46, "end_pos": 62, "type": "TASK", "confidence": 0.7111735641956329}]}, {"text": "This corpus has been converted into an XML format conforming to the standards of the Text Encoding Initiative (TEI).", "labels": [], "entities": [{"text": "Text Encoding Initiative (TEI)", "start_pos": 85, "end_pos": 115, "type": "TASK", "confidence": 0.631499578555425}]}], "introductionContent": [{"text": "Learner corpora have been playing an increasingly important role in both Second Language Acquisition and Foreign Language Teaching research).", "labels": [], "entities": [{"text": "Second Language Acquisition", "start_pos": 73, "end_pos": 100, "type": "TASK", "confidence": 0.6378759940465292}]}, {"text": "These corpora contain texts written by non-native speakers of the language (); many also annotate text segments where there are errors, and the corresponding error categories ).", "labels": [], "entities": []}, {"text": "In addition, some learner corpora contain pairs of sentences: a sentence written by a learner of English as a second language (ESL), paired with its correct version produced by a native speaker ().", "labels": [], "entities": []}, {"text": "These datasets are intended to support the training of automatic text correction systems (.", "labels": [], "entities": [{"text": "text correction", "start_pos": 65, "end_pos": 80, "type": "TASK", "confidence": 0.7538579404354095}]}, {"text": "Less attention has been paid to how a language learner produces a text.", "labels": [], "entities": []}, {"text": "Writing is often an iterative and interactive process, with cycles of textual revision, guided by comments from language teachers.", "labels": [], "entities": []}, {"text": "Understanding the dynamics of this process would benefit not only language teachers, but also the design of writing assistance tools that provide automatic feedback ().", "labels": [], "entities": []}, {"text": "This paper presents the first large-scale corpus that will enable research in this direction.", "labels": [], "entities": []}, {"text": "After a review of previous work ( \u00a72), we describe the design and a preliminary analysis of our corpus ( \u00a73).", "labels": [], "entities": []}], "datasetContent": [{"text": "To evaluate the performance of the conversion algorithm described in \u00a73.3, we asked a human to manually construct the TEI XML files for 14 pairs of draft versions.", "labels": [], "entities": [{"text": "TEI XML files", "start_pos": 118, "end_pos": 131, "type": "DATASET", "confidence": 0.7903578678766886}]}, {"text": "These gold files are then compared to the output of our algorithm.", "labels": [], "entities": []}, {"text": "The results are shown in.", "labels": [], "entities": []}, {"text": "In comment extraction, codes can be reliably identified.", "labels": [], "entities": [{"text": "comment extraction", "start_pos": 3, "end_pos": 21, "type": "TASK", "confidence": 0.7770830392837524}]}, {"text": "Among the open-ended comments, however, those at the beginning and end of the drafts severely affected the precision, since they are often not quoted in brackets and are therefore indistinguishable from the text proper.", "labels": [], "entities": [{"text": "precision", "start_pos": 107, "end_pos": 116, "type": "METRIC", "confidence": 0.9994951486587524}]}, {"text": "In comment-to-text alignment, most errors were caused by inconsistent or missing highlighting and background colors.", "labels": [], "entities": [{"text": "comment-to-text alignment", "start_pos": 3, "end_pos": 28, "type": "TASK", "confidence": 0.6961008012294769}]}, {"text": "The accuracy of sentence alignment is 89.8%, measured from the perspective of sentences in Version 1.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.9996929168701172}, {"text": "sentence alignment", "start_pos": 16, "end_pos": 34, "type": "TASK", "confidence": 0.7300809919834137}]}, {"text": "It is sometimes difficult to decide whether a sentence has simply been edited (and should therefore be aligned), or has been deleted with anew sentence inserted in the next draft.", "labels": [], "entities": []}, {"text": "3 That is, the order of two sentences is flipped.", "labels": [], "entities": []}, {"text": "Tuned to 0.5 based on a random subset of sentence pairs.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Draft essays are collected from courses in vari- ous disciplines at City University of Hong Kong. These  drafts include lab reports, data analysis, argumentative  essays, and article summaries. There are 3760 distinct  essays, most of which consist of two to four successive  drafts. Each draft has on average 44.2 sentences, and the  average length of a sentence is 13.3 words. In total, the  corpus contains 7.9 million words.", "labels": [], "entities": []}, {"text": " Table 3: Evaluation results of the conversion process de- scribed in  \u00a73.3. Precision and recall are calculated on  correct detection of the start and end points of comments  and boundaries.", "labels": [], "entities": [{"text": "Precision", "start_pos": 77, "end_pos": 86, "type": "METRIC", "confidence": 0.998570442199707}, {"text": "recall", "start_pos": 91, "end_pos": 97, "type": "METRIC", "confidence": 0.9991694688796997}]}, {"text": " Table 4: Distribution of the three kinds of comments  ( \u00a73.2), with the Comment Bank codes further subdivided  into different levels (See", "labels": [], "entities": [{"text": "Distribution", "start_pos": 10, "end_pos": 22, "type": "TASK", "confidence": 0.9575022459030151}]}]}