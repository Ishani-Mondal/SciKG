{"title": [{"text": "Automatically Learning Measures of Child Language Development", "labels": [], "entities": [{"text": "Automatically Learning Measures of Child Language Development", "start_pos": 0, "end_pos": 61, "type": "TASK", "confidence": 0.583317871604647}]}], "abstractContent": [{"text": "We propose anew approach for the creation of child language development metrics.", "labels": [], "entities": []}, {"text": "A set of linguistic features is computed on child speech samples and used as input in two age prediction experiments.", "labels": [], "entities": []}, {"text": "In the first experiment, we learn a child-specific metric and predicts the ages at which speech samples were produced.", "labels": [], "entities": []}, {"text": "We then learn a more general developmental index by applying our method across children , predicting relative temporal orderings of speech samples.", "labels": [], "entities": []}, {"text": "In both cases we compare our results with established measures of language development, showing improvements in age prediction performance.", "labels": [], "entities": []}], "introductionContent": [{"text": "The rapid childhood development from a seemingly blank slate to language mastery is a puzzle that linguists and psychologists continue to ponder.", "labels": [], "entities": [{"text": "language mastery", "start_pos": 64, "end_pos": 80, "type": "TASK", "confidence": 0.7140497863292694}]}, {"text": "While the precise mechanism of language learning remains poorly understood, researchers have developed measures of developmental language progress using child speech patterns.", "labels": [], "entities": []}, {"text": "These metrics provide a means of diagnosing early language disorders.", "labels": [], "entities": [{"text": "diagnosing early language disorders", "start_pos": 33, "end_pos": 68, "type": "TASK", "confidence": 0.7852907329797745}]}, {"text": "Besides this practical benefit, precisely measuring grammatical development is a step towards understanding the underlying language learning process.", "labels": [], "entities": []}, {"text": "Previous NLP work has sought to automate the calculation of handcrafted developmental metrics proposed by psychologists and linguists.", "labels": [], "entities": []}, {"text": "In this paper, we investigate a more fundamental question: Can we use machine learning techniques to create a more robust developmental measure itself?", "labels": [], "entities": []}, {"text": "If so, how well would such a measure generalize across children?", "labels": [], "entities": []}, {"text": "This last question touches on an underlying assumption made in much of the child language literature-that while children progress grammatically at different rates, they follow fixed stages in their development.", "labels": [], "entities": []}, {"text": "If a developmental index automatically learned from one set of children could be accurately applied to others, it would vindicate this assumption of shared developmental paths.", "labels": [], "entities": []}, {"text": "Several metrics of language development have been set forth in the psycholinguistics literature.", "labels": [], "entities": []}, {"text": "Standard measures include Mean Length of Utterance (MLU)-the average length in morphemes of conversational turns, Index of Productive Syntax (IPSYN))-a multi-tiered scoring process where over 60 individual features are counted by hand and combined into tiered scores, and D-Level ()-a score for individual sentences based on the observed presence of key syntactic structures.", "labels": [], "entities": [{"text": "Mean Length of Utterance (MLU)-", "start_pos": 26, "end_pos": 57, "type": "METRIC", "confidence": 0.9576881357601711}, {"text": "Index", "start_pos": 114, "end_pos": 119, "type": "METRIC", "confidence": 0.9635966420173645}]}, {"text": "Today, these hand-crafted metrics persist as measurements of child language development, each taking a slightly different angle to assess the same question: Exactly how much grammatical knowledge does a young learner possess?", "labels": [], "entities": []}, {"text": "NLP technology has been applied to help automate the otherwise tedious calculation of these measures.", "labels": [], "entities": []}, {"text": "Computerized Profiling (CP)) is a software package that produces semi-automated language assessments, using partof-speech tagging and human supervision.", "labels": [], "entities": [{"text": "Computerized Profiling (CP))", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.7331026375293732}, {"text": "partof-speech tagging", "start_pos": 108, "end_pos": 129, "type": "TASK", "confidence": 0.7407039999961853}]}, {"text": "In response to its limited depth of analysis and the necessity for human supervision in CP, there have since Thus, it has been demonstrated that NLP techniques can compute existing scores of language proficiency.", "labels": [], "entities": []}, {"text": "However, the definition of first-language developmental metrics has as yet been left up to human reasoning.", "labels": [], "entities": []}, {"text": "In this paper, we consider the automatic induction of more accurate developmental metrics using child language data.", "labels": [], "entities": []}, {"text": "We extract features from longitudinal child language data and conduct two sets of experiments.", "labels": [], "entities": []}, {"text": "For individual children, we use least-squares regression over our features to predict the age of a held-out language sample.", "labels": [], "entities": []}, {"text": "We find that on average, existing single metrics of development are outperformed by a weighted combination of our features.", "labels": [], "entities": []}, {"text": "In our second set of experiments, we investigate whether metrics can be learned across children.", "labels": [], "entities": []}, {"text": "To do so, we consider a speech sample ordering task.", "labels": [], "entities": [{"text": "speech sample ordering task", "start_pos": 24, "end_pos": 51, "type": "TASK", "confidence": 0.6869204118847847}]}, {"text": "We use optimization techniques to learn weightings over features that allow generalization across children.", "labels": [], "entities": []}, {"text": "Although traditional measures like MLU and D-level perform well on this task, we find that a learned combination of features outperforms any single pre-defined developmental score.", "labels": [], "entities": [{"text": "MLU", "start_pos": 35, "end_pos": 38, "type": "METRIC", "confidence": 0.9934383034706116}, {"text": "D-level", "start_pos": 43, "end_pos": 50, "type": "METRIC", "confidence": 0.9914129972457886}]}], "datasetContent": [{"text": "Learning Individual Child Metrics Our first task is to predict the age at which a held-out speech sample was produced, given a set of age-stamped samples from the same child.", "labels": [], "entities": []}, {"text": "We perform a least squares regression on each child, treating age as the dependent variable, and our features as independent variables.", "labels": [], "entities": []}, {"text": "Each data set is split into 10 random folds of 90% training and 10% test data.", "labels": [], "entities": []}, {"text": "Mean squared error is reported in  achieves lower error than any individual feature by itself.", "labels": [], "entities": [{"text": "Mean squared error", "start_pos": 0, "end_pos": 18, "type": "METRIC", "confidence": 0.9726832111676534}]}, {"text": "Learning General Metrics Across Children To produce a universal metric of language development like MLU or D-Level, we train on data pooled across many children.", "labels": [], "entities": []}, {"text": "For each of 7 folds, a single child's data is separated as a test set while the remaining children are used for training.", "labels": [], "entities": []}, {"text": "Since Ross is the only child with samples beyond 62 months, we do not attempt to learn a general measure of language development at these ages, but rather remove these data points.", "labels": [], "entities": []}, {"text": "Unlike the individual-child case, we do not predict absolute ages based on speech samples, as each child is expected to learn at a different rate.", "labels": [], "entities": []}, {"text": "Instead, we learn an ordering model which attempts to place each sample in its relative place in time.", "labels": [], "entities": []}, {"text": "The model computes a score from a weighted quadratic combination of our features and orders the samples based on their computed scores.", "labels": [], "entities": []}, {"text": "To learn the parameters of the model, we seek to maximize the Kendall \u03c4 between true and predicted orderings, summed over the training children.", "labels": [], "entities": [{"text": "Kendall \u03c4", "start_pos": 62, "end_pos": 71, "type": "METRIC", "confidence": 0.9444312155246735}]}, {"text": "We pass this objective function to, a standard gradient-free optimization algorithm.", "labels": [], "entities": []}, {"text": "NelderMead constructs a simplex at its initial guess of parameter values and iteratively makes small shifts in the simplex to satisfy a descent condition until a local maximum is reached.", "labels": [], "entities": []}, {"text": "We report the average Kendall \u03c4 achieved by this algorithm over several feature combinations in Table 3.", "labels": [], "entities": [{"text": "Kendall \u03c4", "start_pos": 22, "end_pos": 31, "type": "METRIC", "confidence": 0.9809702634811401}]}, {"text": "Because we modify our data set in this experiment, for comparison we also show the average Kendall \u03c4 achieved by MLU on the truncated data.", "labels": [], "entities": [{"text": "Kendall \u03c4", "start_pos": 91, "end_pos": 100, "type": "METRIC", "confidence": 0.9805965423583984}, {"text": "MLU", "start_pos": 113, "end_pos": 116, "type": "METRIC", "confidence": 0.8739756345748901}]}], "tableCaptions": [{"text": " Table 2: Mean squared error from 10-fold cross valida- tion of linear regression on individual children. The low- est error for each child is shown in bold.", "labels": [], "entities": [{"text": "Mean squared error", "start_pos": 10, "end_pos": 28, "type": "METRIC", "confidence": 0.9727426767349243}]}, {"text": " Table 3: Average \u03c4 of orderings produced by MLU (the  best traditional index) and our learned metric, versus true  chronological order. Highest \u03c4 is shown in bold.", "labels": [], "entities": [{"text": "MLU", "start_pos": 45, "end_pos": 48, "type": "DATASET", "confidence": 0.8747310042381287}]}]}