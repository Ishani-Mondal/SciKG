{"title": [{"text": "Unsupervised Morphology Rivals Supervised Morphology for Arabic MT", "labels": [], "entities": [{"text": "MT", "start_pos": 64, "end_pos": 66, "type": "TASK", "confidence": 0.435188353061676}]}], "abstractContent": [{"text": "If unsupervised morphological analyzers could approach the effectiveness of supervised ones, they would be a very attractive choice for improving MT performance on low-resource inflected languages.", "labels": [], "entities": [{"text": "MT", "start_pos": 146, "end_pos": 148, "type": "TASK", "confidence": 0.9962459206581116}]}, {"text": "In this paper, we compare performance gains for state-of-the-art supervised vs. unsupervised morphological analyzers, using a state-of-the-art Arabic-to-English MT system.", "labels": [], "entities": [{"text": "MT", "start_pos": 161, "end_pos": 163, "type": "TASK", "confidence": 0.9261958599090576}]}, {"text": "We apply maximum marginal decoding to the unsu-pervised analyzer, and show that this yields the best published segmentation accuracy for Arabic, while also making segmentation output more stable.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 124, "end_pos": 132, "type": "METRIC", "confidence": 0.7646721601486206}]}, {"text": "Our approach gives an 18% relative BLEU gain for Levantine dialectal Arabic.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 35, "end_pos": 39, "type": "METRIC", "confidence": 0.9997110962867737}]}, {"text": "Furthermore, it gives higher gains for Modern Standard Arabic (MSA), as measured on NIST MT-08, than does MADA (Habash and Rambow, 2005), a leading supervised MSA segmenter.", "labels": [], "entities": [{"text": "Modern Standard Arabic (MSA)", "start_pos": 39, "end_pos": 67, "type": "TASK", "confidence": 0.7358716825644175}, {"text": "NIST MT-08", "start_pos": 84, "end_pos": 94, "type": "DATASET", "confidence": 0.85657799243927}, {"text": "MADA", "start_pos": 106, "end_pos": 110, "type": "METRIC", "confidence": 0.716668426990509}, {"text": "MSA segmenter", "start_pos": 159, "end_pos": 172, "type": "TASK", "confidence": 0.9150963127613068}]}], "introductionContent": [{"text": "If unsupervised morphological segmenters could approach the effectiveness of supervised ones, they would be a very attractive choice for improving machine translation (MT) performance in low-resource inflected languages.", "labels": [], "entities": [{"text": "machine translation (MT)", "start_pos": 147, "end_pos": 171, "type": "TASK", "confidence": 0.8435015916824341}]}, {"text": "An example of particular current interest is Arabic, whose various colloquial dialects are sufficiently different from Modern Standard Arabic (MSA) in lexicon, orthography, and morphology, as to be low-resource languages themselves.", "labels": [], "entities": []}, {"text": "An additional advantage of Arabic for study is the availability of high-quality supervised segmenters for MSA, such as MADA), for performance comparison.", "labels": [], "entities": []}, {"text": "The MT gain for supervised MSA segmenters on dialect establishes a lower bound, which the unsupervised segmenter must exceed if it is to be useful for dialect.", "labels": [], "entities": [{"text": "MT", "start_pos": 4, "end_pos": 6, "type": "TASK", "confidence": 0.7641865015029907}, {"text": "MSA segmenters", "start_pos": 27, "end_pos": 41, "type": "TASK", "confidence": 0.9102285802364349}]}, {"text": "And comparing the gain for supervised and unsupervised segmenters on MSA tells us how useful the unsupervised segmenter is, relative to the ideal casein which a supervised segmenter is available.", "labels": [], "entities": []}, {"text": "In this paper, we show that an unsupervised segmenter can in fact rival or surpass supervised MSA segmenters on MSA itself, while at the same time providing superior performance on dialect.", "labels": [], "entities": [{"text": "MSA segmenters", "start_pos": 94, "end_pos": 108, "type": "TASK", "confidence": 0.8176452815532684}]}, {"text": "Specifically, we compare the state-of-the-art morphological analyzer of Lee et al.", "labels": [], "entities": []}, {"text": "(2011) with two leading supervised analyzers for MSA, MADA and Sakhr 1 , each serving as an alternative preprocessor fora state-ofthe-art statistical MT system.", "labels": [], "entities": [{"text": "MADA", "start_pos": 54, "end_pos": 58, "type": "METRIC", "confidence": 0.5623903870582581}, {"text": "MT", "start_pos": 150, "end_pos": 152, "type": "TASK", "confidence": 0.9238777160644531}]}, {"text": "We measure MSA performance on NIST MT-08, and dialect performance on a Levantine dialect web corpus (.", "labels": [], "entities": [{"text": "NIST MT-08", "start_pos": 30, "end_pos": 40, "type": "DATASET", "confidence": 0.8691858649253845}, {"text": "Levantine dialect web corpus", "start_pos": 71, "end_pos": 99, "type": "DATASET", "confidence": 0.7616881281137466}]}, {"text": "To improve performance, we apply maximum marginal decoding) (MM) to combine multiple runs of the Lee segmenter, and show that this dramatically reduces the variance and noise in the segmenter output, while yielding an improved segmentation accuracy that exceeds the best published scores for unsupervised segmentation on Arabic Treebank ().", "labels": [], "entities": [{"text": "maximum marginal decoding) (MM)", "start_pos": 33, "end_pos": 64, "type": "METRIC", "confidence": 0.7256119634423938}, {"text": "accuracy", "start_pos": 240, "end_pos": 248, "type": "METRIC", "confidence": 0.8371070027351379}, {"text": "Arabic Treebank", "start_pos": 321, "end_pos": 336, "type": "DATASET", "confidence": 0.9870733618736267}]}, {"text": "We also show that it yields MT-08 BLEU scores that are higher than those obtained with MADA, a leading supervised MSA segmenter.", "labels": [], "entities": [{"text": "MT-08", "start_pos": 28, "end_pos": 33, "type": "METRIC", "confidence": 0.6011466383934021}, {"text": "BLEU", "start_pos": 34, "end_pos": 38, "type": "METRIC", "confidence": 0.9009923338890076}, {"text": "MADA", "start_pos": 87, "end_pos": 91, "type": "DATASET", "confidence": 0.6249290108680725}, {"text": "MSA segmenter", "start_pos": 114, "end_pos": 127, "type": "TASK", "confidence": 0.9418413639068604}]}, {"text": "For Levantine, the segmenter increases BLEU score by 18% over the unsegmented baseline.", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 39, "end_pos": 49, "type": "METRIC", "confidence": 0.9398537576198578}]}], "datasetContent": [{"text": "Our experiments were performed using a state-of-the-art, hierarchical string-todependency-tree MT system, described in.", "labels": [], "entities": [{"text": "MT", "start_pos": 95, "end_pos": 97, "type": "TASK", "confidence": 0.9395104646682739}]}, {"text": "We compare the Lee segmenter with the supervised MSA segmenter MADA, using its \"D3\" scheme.", "labels": [], "entities": [{"text": "MSA segmenter MADA", "start_pos": 49, "end_pos": 67, "type": "TASK", "confidence": 0.8401253819465637}]}, {"text": "We also compare with Sakhr, an intensively-engineered, supervised MSA segmenter which applies multiple NLP technologies to the segmentation problem, and which has given the best results for our MT system in previous work ().", "labels": [], "entities": [{"text": "MSA segmenter", "start_pos": 66, "end_pos": 79, "type": "TASK", "confidence": 0.9280516803264618}, {"text": "segmentation problem", "start_pos": 127, "end_pos": 147, "type": "TASK", "confidence": 0.941663384437561}, {"text": "MT", "start_pos": 194, "end_pos": 196, "type": "TASK", "confidence": 0.9758940935134888}]}, {"text": "We also compare with Morfessor.", "labels": [], "entities": [{"text": "Morfessor", "start_pos": 21, "end_pos": 30, "type": "DATASET", "confidence": 0.9315525889396667}]}, {"text": "We apply the appropriate segmenter to split words into morphemes, which we then treat as words for alignment and decoding.", "labels": [], "entities": []}, {"text": "Following, we segment the test and training sets jointly, estimating separate translation models for each segmenter/dataset combination.", "labels": [], "entities": []}, {"text": "Our \"Full MSA\" corpus is the NIST MT-08 Constrained Data Track Arabic training corpus (35M total, 336K unique words); our \"Small MSA\" corpus is a 1.3M-word subset.", "labels": [], "entities": [{"text": "NIST MT-08 Constrained Data Track Arabic training corpus", "start_pos": 29, "end_pos": 85, "type": "DATASET", "confidence": 0.8984720408916473}, {"text": "Small MSA\" corpus", "start_pos": 123, "end_pos": 140, "type": "DATASET", "confidence": 0.6146193221211433}]}, {"text": "Both are tested on the MT-08 evaluation set.", "labels": [], "entities": [{"text": "MT-08 evaluation set", "start_pos": 23, "end_pos": 43, "type": "DATASET", "confidence": 0.8586492339769999}]}, {"text": "For dialect, we use a Levantine dialectal Arabic corpus collected from the web with 1.5M total, 160K unique words and 18K words held-out for test) Performance Metrics.", "labels": [], "entities": [{"text": "Levantine dialectal Arabic corpus", "start_pos": 22, "end_pos": 55, "type": "DATASET", "confidence": 0.5441021025180817}]}, {"text": "We evaluate MT with BLEU score.", "labels": [], "entities": [{"text": "MT", "start_pos": 12, "end_pos": 14, "type": "TASK", "confidence": 0.9108874201774597}, {"text": "BLEU score", "start_pos": 20, "end_pos": 30, "type": "METRIC", "confidence": 0.9754112660884857}]}, {"text": "To calculate statistical significance, we use the boot-strap resampling method of Koehn (2004).", "labels": [], "entities": []}, {"text": "summarizes the BLEU scores obtained from using various segmenters, for three training/test sets: Full MSA, Small MSA, and Levantine dialect.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 15, "end_pos": 19, "type": "METRIC", "confidence": 0.9934883117675781}]}, {"text": "As expected, Sakhr gives the best results for MSA.", "labels": [], "entities": [{"text": "MSA", "start_pos": 46, "end_pos": 49, "type": "TASK", "confidence": 0.9131096005439758}]}, {"text": "Morfessor underperforms the other segmenters, perhaps because of its lower accuracy on Arabic, as reported by.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 75, "end_pos": 83, "type": "METRIC", "confidence": 0.9985669255256653}]}, {"text": "The Lee segmenter gives the best results for Levantine, inducing valid Levantine affixes (e.g \"hAl+\" for MSA's \"h*A-Al+\", English \"this-the\") and yielding an 18% relative gain over the unsegmented baseline.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Comparison of agreement in outputs between  25 runs of Gibbs sampling vs. 2 runs of MM on the  full MT-08 data set. We give the average segmentation  recall, precision, F1-measure, and exact-match accuracy  between outputs, at word-type and word-token levels.", "labels": [], "entities": [{"text": "agreement", "start_pos": 24, "end_pos": 33, "type": "METRIC", "confidence": 0.9319807887077332}, {"text": "MT-08 data set", "start_pos": 110, "end_pos": 124, "type": "DATASET", "confidence": 0.9249999721844991}, {"text": "recall", "start_pos": 160, "end_pos": 166, "type": "METRIC", "confidence": 0.9856529235839844}, {"text": "precision", "start_pos": 168, "end_pos": 177, "type": "METRIC", "confidence": 0.9993652701377869}, {"text": "F1-measure", "start_pos": 179, "end_pos": 189, "type": "METRIC", "confidence": 0.9983021020889282}, {"text": "exact-match", "start_pos": 195, "end_pos": 206, "type": "METRIC", "confidence": 0.9463123679161072}, {"text": "accuracy", "start_pos": 207, "end_pos": 215, "type": "METRIC", "confidence": 0.5328927636146545}]}, {"text": " Table 2: Affix statistics of unsupervised segmenters. For  the ATB lexicon, we show statistics for the Lee seg- menter with regular Gibbs sampling (GS). For the MT- 08 lexicon, we also show the output of the Lee segmenter  with maximum marginal decoding (MM). In addition, we  show statistics for Morfessor.", "labels": [], "entities": [{"text": "ATB lexicon", "start_pos": 64, "end_pos": 75, "type": "DATASET", "confidence": 0.974363774061203}, {"text": "regular Gibbs sampling (GS)", "start_pos": 125, "end_pos": 152, "type": "METRIC", "confidence": 0.7406702140967051}, {"text": "MT- 08 lexicon", "start_pos": 162, "end_pos": 176, "type": "DATASET", "confidence": 0.7264594584703445}, {"text": "Morfessor", "start_pos": 298, "end_pos": 307, "type": "DATASET", "confidence": 0.9242729544639587}]}, {"text": " Table 3: Segmentation F-scores on ATB dataset for Lee  segmenter, shown for each Model level M1-M4 on the  Arabic segmentation dataset used by (Poon et al., 2009):", "labels": [], "entities": [{"text": "F-scores", "start_pos": 23, "end_pos": 31, "type": "METRIC", "confidence": 0.5834091305732727}, {"text": "ATB dataset", "start_pos": 35, "end_pos": 46, "type": "DATASET", "confidence": 0.9432293772697449}, {"text": "Lee  segmenter", "start_pos": 51, "end_pos": 65, "type": "TASK", "confidence": 0.643008753657341}, {"text": "Arabic segmentation dataset", "start_pos": 108, "end_pos": 135, "type": "DATASET", "confidence": 0.6709782679875692}]}, {"text": " Table 4: BLEU scores for all experiments. Full MSA is  the the full MT-08 corpus, Small MSA is a 1.3M-word  subset, Lev Dial our Levantine dataset. For each of these,  the highest Lee segmenter score is in bold, with \"+\" if  statistically significant vs. MADA at the 95% confidence  level or higher. The highest overall score is in bold italic.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9987456798553467}, {"text": "MT-08 corpus", "start_pos": 69, "end_pos": 81, "type": "DATASET", "confidence": 0.9066639244556427}, {"text": "Levantine dataset", "start_pos": 130, "end_pos": 147, "type": "DATASET", "confidence": 0.781573086977005}, {"text": "MADA", "start_pos": 256, "end_pos": 260, "type": "METRIC", "confidence": 0.9471133947372437}]}]}