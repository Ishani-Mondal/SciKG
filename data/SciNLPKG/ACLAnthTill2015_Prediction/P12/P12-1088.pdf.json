{"title": [{"text": "Automatic Event Extraction with Structured Preference Modeling", "labels": [], "entities": [{"text": "Automatic Event Extraction", "start_pos": 0, "end_pos": 26, "type": "TASK", "confidence": 0.5794509549935659}, {"text": "Structured Preference Modeling", "start_pos": 32, "end_pos": 62, "type": "TASK", "confidence": 0.6556723217169443}]}], "abstractContent": [{"text": "This paper presents a novel sequence labeling model based on the latent-variable semi-Markov conditional random fields for jointly extracting argument roles of events from texts.", "labels": [], "entities": [{"text": "sequence labeling", "start_pos": 28, "end_pos": 45, "type": "TASK", "confidence": 0.6459687054157257}]}, {"text": "The model takes in coarse mention and type information and predicts argument roles fora given event template.", "labels": [], "entities": []}, {"text": "This paper addresses the event extraction problem in a primarily unsupervised setting, where no labeled training instances are available.", "labels": [], "entities": [{"text": "event extraction", "start_pos": 25, "end_pos": 41, "type": "TASK", "confidence": 0.8411625325679779}]}, {"text": "Our key contribution is a novel learning framework called structured preference mod-eling (PM), that allows arbitrary preference to be assigned to certain structures during the learning procedure.", "labels": [], "entities": []}, {"text": "We establish and discuss connections between this framework and other existing works.", "labels": [], "entities": []}, {"text": "We show empirically that the structured preferences are crucial to the success of our task.", "labels": [], "entities": []}, {"text": "Our model, trained without annotated data and with a small number of structured preferences, yields performance competitive to some baseline supervised approaches .", "labels": [], "entities": []}], "introductionContent": [{"text": "Automatic template-filling-based event extraction is an important and challenging task.", "labels": [], "entities": [{"text": "template-filling-based event extraction", "start_pos": 10, "end_pos": 49, "type": "TASK", "confidence": 0.6569898625214895}]}, {"text": "Consider the following text span that describes an \"Attack\" event: . .", "labels": [], "entities": []}, {"text": "North Korea's military may have fired a laser at a U.S. helicopter in March, a U.S. official said Tuesday, as the communist state ditched its last legal obligation to keep itself free of nuclear weapons . .", "labels": [], "entities": []}, {"text": "A partial event template for the \"Attack\" event is shown on the left of.", "labels": [], "entities": []}, {"text": "Each row shows an argument for the event, together with a set of its acceptable mention types, where the type specifies a high-level semantic class a mention belongs to.", "labels": [], "entities": []}, {"text": "The task is to automatically fill the template entries with texts extracted from the text span above.", "labels": [], "entities": []}, {"text": "The correct filling of the template for this particular example is shown on the right of.", "labels": [], "entities": []}, {"text": "Performing such a task without any knowledge about the semantics of the texts is hard.", "labels": [], "entities": []}, {"text": "One typical assumption is that certain coarse mention-level information, such as mention boundaries and their semantic class (a.k.a. types), are available.", "labels": [], "entities": []}, {"text": "E.g.: Such mention type information as shown on the left of can be obtained from various sources such as dictionaries, gazetteers, rule-based systems, statistically trained classifiers, or some web resources such as).", "labels": [], "entities": []}, {"text": "However, in practice, outputs from existing mention identification and typing systems can be far from ideal.", "labels": [], "entities": [{"text": "mention identification and typing", "start_pos": 44, "end_pos": 77, "type": "TASK", "confidence": 0.7175067812204361}]}, {"text": "Instead of obtaining the above ideal annotation, one might observe the following noisy and ambiguous annotation for the given event span:: The partial event template for the Attack event (left), and the correct event template annotation for the example event span given in Sec 1 (right).", "labels": [], "entities": []}, {"text": "We primarily follow the ACE standard in defining arguments and types. and often noisy mention type annotations.", "labels": [], "entities": [{"text": "ACE", "start_pos": 24, "end_pos": 27, "type": "DATASET", "confidence": 0.8987869620323181}]}, {"text": "This work addresses this problem by making the following contributions: \u2022 Naturally, we are interested in identifying the active mentions (the mentions that serve as arguments) and their correct boundaries from the data.", "labels": [], "entities": []}, {"text": "This motivates us to build a novel latentvariable semi-Markov conditional random fields model () for such an event extraction task.", "labels": [], "entities": [{"text": "event extraction task", "start_pos": 109, "end_pos": 130, "type": "TASK", "confidence": 0.7850123643875122}]}, {"text": "The learned model takes in coarse information as produced by existing mention identification and typing modules, and jointly outputs selected mentions and their corresponding argument roles.", "labels": [], "entities": []}, {"text": "\u2022 We address the problem in a more realistic scenario where annotated training instances are not available.", "labels": [], "entities": []}, {"text": "We propose a novel general learning framework called structured preference modeling (or preference modeling, PM), which encompasses both the fully supervised and the latent-variable conditional models as special cases.", "labels": [], "entities": [{"text": "preference modeling, PM)", "start_pos": 88, "end_pos": 112, "type": "TASK", "confidence": 0.7290237665176391}]}, {"text": "The framework allows arbitrary declarative structured preference knowledge to be introduced to guide the learning procedure in a primarily unsupervised setting.", "labels": [], "entities": []}, {"text": "We present our semi-Markov model and discuss our preference modeling framework in Section 2 and 3 respectively.", "labels": [], "entities": []}, {"text": "We then discuss the model's relation with existing constraint-driven learning frameworks in Section 4.", "labels": [], "entities": []}, {"text": "Finally, we demonstrate through experiments that structured preference information is crucial to model and present empirical results on a standard dataset in Section 5.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section, we present our experimental results on the standard ACE05 3 dataset (newswire portion).", "labels": [], "entities": [{"text": "ACE05 3 dataset", "start_pos": 69, "end_pos": 84, "type": "DATASET", "confidence": 0.9163419206937155}]}, {"text": "We choose to perform our evaluations on 4 events (namely, \"Attack\", \"Meet\", \"Die\" and \"Transport\"), which are the only events in this dataset that have more than 50 instances.", "labels": [], "entities": []}, {"text": "For each event, we randomly split the instances into two portions, where 70% are used for learning, and the remaining 30% for evaluation.", "labels": [], "entities": []}, {"text": "We list the corpus statistics in.", "labels": [], "entities": []}, {"text": "To present general results while making minimal assumptions, our primary event extraction results  are independent of mention identification and typing modules, which are based on the gold mention information as given by the dataset.", "labels": [], "entities": [{"text": "mention identification", "start_pos": 118, "end_pos": 140, "type": "TASK", "confidence": 0.6950423419475555}]}, {"text": "Additionally, we present results obtained by exploiting our in-house automatic mention identification and typing module, which is a hybrid system that combines statistical and rule-based approaches.", "labels": [], "entities": [{"text": "automatic mention identification and typing", "start_pos": 69, "end_pos": 112, "type": "TASK", "confidence": 0.678618973493576}]}, {"text": "The module's statistical component is trained on the ACE04 dataset (newswire portion) and overall it achieves a microaveraged F1-measure of 71.25% at our dataset.", "labels": [], "entities": [{"text": "ACE04 dataset", "start_pos": 53, "end_pos": 66, "type": "DATASET", "confidence": 0.9875473380088806}, {"text": "F1-measure", "start_pos": 126, "end_pos": 136, "type": "METRIC", "confidence": 0.9248853325843811}]}], "tableCaptions": [{"text": " Table 1: Performance for different events under different experimental settings, with gold mention boundaries and types. We report  F1-measure percentages.", "labels": [], "entities": [{"text": "F1-measure percentages", "start_pos": 133, "end_pos": 155, "type": "METRIC", "confidence": 0.9755256474018097}]}, {"text": " Table 2: Corpus statistics (#A: number of possible arguments  for the event; #I: number of instances; #M: number of ac- tive/total mentions; #P: number of preference patterns used  for performing our structured preference modeling.)", "labels": [], "entities": []}, {"text": " Table 3: Event extraction performance with automatic mention  identifier and typer. We report F1 percentage scores for pref- erence modeling (PM) as well as two baseline approaches. We  also report performance of the supervised approach trained with  the semi-CRF model for comparison.", "labels": [], "entities": [{"text": "Event extraction", "start_pos": 10, "end_pos": 26, "type": "TASK", "confidence": 0.8223083317279816}, {"text": "F1 percentage scores", "start_pos": 95, "end_pos": 115, "type": "METRIC", "confidence": 0.9773727854092916}, {"text": "pref- erence modeling (PM", "start_pos": 120, "end_pos": 145, "type": "METRIC", "confidence": 0.7656927108764648}]}]}