{"title": [{"text": "Extracting Narrative Timelines as Temporal Dependency Structures", "labels": [], "entities": [{"text": "Extracting Narrative Timelines", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.8351105650266012}]}], "abstractContent": [{"text": "We propose anew approach to characterizing the timeline of a text: temporal dependency structures, where all the events of a narrative are linked via partial ordering relations like BEFORE , AFTER, OVERLAP and IDENTITY.", "labels": [], "entities": [{"text": "BEFORE", "start_pos": 182, "end_pos": 188, "type": "METRIC", "confidence": 0.9977360963821411}, {"text": "AFTER", "start_pos": 191, "end_pos": 196, "type": "METRIC", "confidence": 0.9531090259552002}, {"text": "OVERLAP", "start_pos": 198, "end_pos": 205, "type": "METRIC", "confidence": 0.911962628364563}]}, {"text": "We annotate a corpus of children's stories with temporal dependency trees, achieving agreement (Krippendorff's Alpha) of 0.856 on the event words, 0.822 on the links between events, and of 0.700 on the ordering relation labels.", "labels": [], "entities": [{"text": "agreement", "start_pos": 85, "end_pos": 94, "type": "METRIC", "confidence": 0.9936326146125793}, {"text": "Alpha)", "start_pos": 111, "end_pos": 117, "type": "METRIC", "confidence": 0.8084031343460083}]}, {"text": "We compare two parsing models for temporal dependency structures, and show that a determin-istic non-projective dependency parser outper-forms a graph-based maximum spanning tree parser, achieving labeled attachment accuracy of 0.647 and labeled tree edit distance of 0.596.", "labels": [], "entities": [{"text": "labeled attachment accuracy", "start_pos": 197, "end_pos": 224, "type": "METRIC", "confidence": 0.48785866300264996}, {"text": "labeled tree edit distance", "start_pos": 238, "end_pos": 264, "type": "METRIC", "confidence": 0.5820823162794113}]}, {"text": "Our analysis of the dependency parser errors gives some insights into future research directions .", "labels": [], "entities": [{"text": "dependency parser", "start_pos": 20, "end_pos": 37, "type": "TASK", "confidence": 0.7835635840892792}]}], "introductionContent": [{"text": "There has been much recent interest in identifying events, times and their relations along the timeline, from event and time ordering problems in the TempEval shared tasks (, to identifying time arguments of event structures in the Automated Content Extraction program (Linguistic Data, to timestamping event intervals in the Knowledge Base Population shared task.", "labels": [], "entities": [{"text": "Knowledge Base Population shared task", "start_pos": 326, "end_pos": 363, "type": "DATASET", "confidence": 0.8297015786170959}]}, {"text": "However, to date, this research has produced fragmented document timelines, because only specific types of temporal relations in specific contexts have been targeted.", "labels": [], "entities": []}, {"text": "For example, the TempEval tasks only looked at relations between events in the same or adjacent sentences, and the Automated Content Extraction program only looked at time arguments for specific types of events, like being born or transferring money.", "labels": [], "entities": [{"text": "Automated Content Extraction", "start_pos": 115, "end_pos": 143, "type": "TASK", "confidence": 0.5470391809940338}]}, {"text": "In this article, we propose an approach to temporal information extraction that identifies a single connected timeline fora text.", "labels": [], "entities": [{"text": "temporal information extraction", "start_pos": 43, "end_pos": 74, "type": "TASK", "confidence": 0.6569635570049286}]}, {"text": "The temporal language in a text often fails to specify a total ordering overall the events, so we annotate the timelines as temporal dependency structures, where each event is anode in the dependency tree, and each edge between nodes represents a temporal ordering relation such as BEFORE, AFTER, OVERLAP or IDENTITY.", "labels": [], "entities": [{"text": "BEFORE", "start_pos": 282, "end_pos": 288, "type": "METRIC", "confidence": 0.9974855184555054}, {"text": "AFTER", "start_pos": 290, "end_pos": 295, "type": "METRIC", "confidence": 0.8887261748313904}, {"text": "OVERLAP", "start_pos": 297, "end_pos": 304, "type": "METRIC", "confidence": 0.8353097438812256}]}, {"text": "We construct an evaluation corpus by annotating such temporal dependency trees over a set of children's stories.", "labels": [], "entities": []}, {"text": "We then demonstrate how to train a timeline extraction system based on dependency parsing techniques instead of the pair-wise classification approaches typical of prior work.", "labels": [], "entities": [{"text": "timeline extraction", "start_pos": 35, "end_pos": 54, "type": "TASK", "confidence": 0.8396537005901337}, {"text": "dependency parsing", "start_pos": 71, "end_pos": 89, "type": "TASK", "confidence": 0.7750035226345062}]}, {"text": "The main contributions of this article are: \u2022 We propose anew approach to characterizing temporal structure via dependency trees.", "labels": [], "entities": [{"text": "characterizing temporal structure", "start_pos": 74, "end_pos": 107, "type": "TASK", "confidence": 0.8129687706629435}]}, {"text": "\u2022 We produce an annotated corpus of temporal dependency trees in children's stories.", "labels": [], "entities": []}, {"text": "\u2022 We design a non-projective dependency parser for inferring timelines from text.", "labels": [], "entities": []}, {"text": "The following sections first review some relevant prior work, then describe the corpus annotation and the dependency parsing algorithm, and finally present our evaluation results.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 106, "end_pos": 124, "type": "TASK", "confidence": 0.7402015626430511}]}], "datasetContent": [{"text": "Evaluations were performed using 10-fold crossvalidation on the fables annotated in Section 3.", "labels": [], "entities": []}, {"text": "To evaluate the parsing models (SRP and MST) we proposed two baselines.", "labels": [], "entities": [{"text": "parsing", "start_pos": 16, "end_pos": 23, "type": "TASK", "confidence": 0.974435567855835}]}, {"text": "Both are based on the assumption of linear temporal structures of narratives as the temporal ordering process that was evidenced by studies inhuman text rewriting.", "labels": [], "entities": []}, {"text": "The proposed baselines are: \u2022 LinearSeq: A model that assumes all events occur in the order they are written, adding links between each pair of adjacent events, and labeling all links with the relation BEFORE.", "labels": [], "entities": [{"text": "BEFORE", "start_pos": 202, "end_pos": 208, "type": "METRIC", "confidence": 0.9933871626853943}]}, {"text": "\u2022 ClassifySeq: A model that links each pair of adjacent events, but trains a pair-wise classifier to predict the relation label for each pair.", "labels": [], "entities": []}, {"text": "The classifier is a support vector machine trained using the same features as the MST parser.", "labels": [], "entities": []}, {"text": "This is an approximation of prior work, where the pairs of events to classify with a temporal relation were given as an input to the system.", "labels": [], "entities": []}, {"text": "(Note that Section 6.2 will show that for our corpus, applying the model only to adjacent pairs of events is quite competitive for just getting the basic unlabeled link structure right.)", "labels": [], "entities": []}, {"text": "The Shift-Reduce parser (SRP; Section 4.1) and the graph-based, maximum spanning tree parser (MST; Section 4.2) are compared to these baselines.", "labels": [], "entities": []}, {"text": "Model performance was evaluated using standard evaluation criteria for parser evaluations: Unlabeled Attachment Score (UAS) The fraction of events whose head events were correctly predicted.", "labels": [], "entities": [{"text": "Unlabeled Attachment Score (UAS)", "start_pos": 91, "end_pos": 123, "type": "METRIC", "confidence": 0.9007391134897867}]}, {"text": "This measures whether the correct pairs of events were linked, but not if they were linked by the correct relations.", "labels": [], "entities": []}, {"text": "Labeled Attachment Score (LAS) The fraction of events whose head events were correctly predicted with the correct relations.", "labels": [], "entities": [{"text": "Labeled Attachment Score (LAS)", "start_pos": 0, "end_pos": 30, "type": "METRIC", "confidence": 0.8180316885312399}]}, {"text": "This measures both whether the correct pairs of events were linked and whether their temporal ordering is correct.", "labels": [], "entities": []}, {"text": "Tree Edit Distance In addition to the UAS and LAS the tree edit distance score has been recently introduced for evaluating dependency structures (Tsarfaty et al., 2011).", "labels": [], "entities": [{"text": "UAS", "start_pos": 38, "end_pos": 41, "type": "DATASET", "confidence": 0.8709118366241455}, {"text": "LAS", "start_pos": 46, "end_pos": 49, "type": "METRIC", "confidence": 0.7038540244102478}]}, {"text": "The tree edit distance score fora tree \u03c0 is based on the following operations \u03bb \u2208 \u039b : \u039b = {DELETE, INSERT, RELABEL}: \u2022 \u03bb =DELETE delete a non-root node v in \u03c0 with parent u, making the children of v the children of u, inserted in the place of v as a subsequence in the left-to-right order of the children of u.", "labels": [], "entities": [{"text": "DELETE", "start_pos": 91, "end_pos": 97, "type": "METRIC", "confidence": 0.9945999383926392}, {"text": "INSERT", "start_pos": 99, "end_pos": 105, "type": "METRIC", "confidence": 0.989024817943573}, {"text": "RELABEL", "start_pos": 107, "end_pos": 114, "type": "METRIC", "confidence": 0.984050452709198}, {"text": "DELETE", "start_pos": 122, "end_pos": 128, "type": "METRIC", "confidence": 0.9889755249023438}]}, {"text": "\u2022 \u03bb =INSERT insert anode v as a child of u in \u03c0 making it the parent of a consecutive subsequence of the children of u.", "labels": [], "entities": [{"text": "INSERT", "start_pos": 5, "end_pos": 11, "type": "METRIC", "confidence": 0.9990007281303406}]}, {"text": "\u2022 \u03bb =RELABEL change the label of node v in \u03c0 Any two trees \u03c0 1 and \u03c0 2 can be turned one into another by a sequence of edit operations {\u03bb 1 , ..., \u03bb n }.: Performance levels of temporal structure parsing methods.", "labels": [], "entities": [{"text": "RELABEL", "start_pos": 5, "end_pos": 12, "type": "METRIC", "confidence": 0.9981332421302795}, {"text": "temporal structure parsing", "start_pos": 177, "end_pos": 203, "type": "TASK", "confidence": 0.6624870896339417}]}, {"text": "A * indicates that the model outperforms LinearSeq and ClassifiedSeq at p < 0.01 and a \u2020 indicates that the model outperforms MST at p < 0.05.", "labels": [], "entities": [{"text": "MST", "start_pos": 126, "end_pos": 129, "type": "DATASET", "confidence": 0.7919179797172546}]}], "tableCaptions": [{"text": " Table 3: Performance levels of temporal structure pars- ing methods. A  *  indicates that the model outperforms  LinearSeq and ClassifiedSeq at p < 0.01 and a  \u2020 indicates  that the model outperforms MST at p < 0.05.", "labels": [], "entities": []}, {"text": " Table 4: Error distribution from the analysis of 55 errors  of the Shift-Reduce parsing model.", "labels": [], "entities": [{"text": "Error", "start_pos": 10, "end_pos": 15, "type": "METRIC", "confidence": 0.9917279481887817}, {"text": "Shift-Reduce parsing", "start_pos": 68, "end_pos": 88, "type": "TASK", "confidence": 0.787859320640564}]}]}