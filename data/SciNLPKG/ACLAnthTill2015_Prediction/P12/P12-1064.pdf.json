{"title": [{"text": "Iterative Viterbi A* Algorithm for K-Best Sequential Decoding", "labels": [], "entities": []}], "abstractContent": [{"text": "Sequential modeling has been widely used in a variety of important applications including named entity recognition and shallow parsing.", "labels": [], "entities": [{"text": "Sequential modeling", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.9016442596912384}, {"text": "named entity recognition", "start_pos": 90, "end_pos": 114, "type": "TASK", "confidence": 0.7323524157206217}, {"text": "shallow parsing", "start_pos": 119, "end_pos": 134, "type": "TASK", "confidence": 0.7591349482536316}]}, {"text": "However, as more and more real time large-scale tagging applications arise, decoding speed has become a bottleneck for existing sequential tagging algorithms.", "labels": [], "entities": [{"text": "sequential tagging", "start_pos": 128, "end_pos": 146, "type": "TASK", "confidence": 0.728097140789032}]}, {"text": "In this paper we propose 1-best A*, 1-best iterative A*, k-best A* and k-best iterative Viterbi A* algorithms for sequential decoding.", "labels": [], "entities": []}, {"text": "We show the efficiency of these proposed algorithms for five NLP tagging tasks.", "labels": [], "entities": [{"text": "NLP tagging tasks", "start_pos": 61, "end_pos": 78, "type": "TASK", "confidence": 0.896113912264506}]}, {"text": "In particular, we show that iterative Viterbi A* decoding can be several times or orders of magnitude faster than the state-of-the-art algorithm for tagging tasks with a large number of labels.", "labels": [], "entities": []}, {"text": "This algorithm makes real-time large-scale tagging applications with thousands of labels feasible.", "labels": [], "entities": [{"text": "real-time large-scale tagging", "start_pos": 21, "end_pos": 50, "type": "TASK", "confidence": 0.6058091719945272}]}], "introductionContent": [{"text": "Sequence tagging algorithms including HMMs), CRFs (), and Collins's perceptron) have been widely employed in NLP applications.", "labels": [], "entities": [{"text": "Sequence tagging", "start_pos": 0, "end_pos": 16, "type": "TASK", "confidence": 0.8049219846725464}]}, {"text": "Sequential decoding, which finds the best tag sequences forgiven inputs, is an important part of the sequential tagging framework.", "labels": [], "entities": [{"text": "sequential tagging", "start_pos": 101, "end_pos": 119, "type": "TASK", "confidence": 0.8649964928627014}]}, {"text": "Traditionally, the Viterbi algorithm is used.", "labels": [], "entities": []}, {"text": "This algorithm is quite efficient when the label size of problem modeled is low.", "labels": [], "entities": []}, {"text": "Unfortunately, due to its O(T L 2 ) time complexity, where T is the input token size and L is the label size, the Viterbi decoding can become prohibitively slow when the label size is large (say, larger than 200).", "labels": [], "entities": [{"text": "O(T L 2 ) time complexity", "start_pos": 26, "end_pos": 51, "type": "METRIC", "confidence": 0.9302339404821396}]}, {"text": "It is not uncommon that the problem modeled consists of more than 200 labels.", "labels": [], "entities": []}, {"text": "The Viterbi algorithm cannot find the best sequences in tolerable response time.", "labels": [], "entities": []}, {"text": "To resolve this, have proposed a Carpediem algorithm which opens only necessary nodes in searching the best sequence.", "labels": [], "entities": []}, {"text": "More recently, proposed a staggered decoding algorithm, which proves to be very efficient on datasets with a large number of labels.", "labels": [], "entities": []}, {"text": "What the aforementioned literature does not cover is the k-best sequential decoding problem, which is indeed frequently required in practice.", "labels": [], "entities": []}, {"text": "For example to pursue a high recall ratio, a named entity recognition system may have to adopt k-best sequences in case the true entities are not recognized at the best one.", "labels": [], "entities": [{"text": "recall ratio", "start_pos": 29, "end_pos": 41, "type": "METRIC", "confidence": 0.9838984906673431}, {"text": "named entity recognition", "start_pos": 45, "end_pos": 69, "type": "TASK", "confidence": 0.6726487278938293}]}, {"text": "The k-best parses have been extensively studied in syntactic parsing context), but it is not well accommodated in sequential decoding context.", "labels": [], "entities": [{"text": "syntactic parsing context", "start_pos": 51, "end_pos": 76, "type": "TASK", "confidence": 0.7566699087619781}]}, {"text": "To our best knowledge, the state-of-the-art k-best sequential decoding algorithm is Viterbi A* 1 . In this paper, we generalize the iterative process from the work of ( and propose a k-best sequential decoding algorithm, namely iterative Viterbi A*.", "labels": [], "entities": []}, {"text": "We show that the proposed algorithm is several times or orders of magnitude faster than the state-of-the-art in all tagging tasks which consist of more than 200 labels.", "labels": [], "entities": [{"text": "tagging tasks", "start_pos": 116, "end_pos": 129, "type": "TASK", "confidence": 0.9099886119365692}]}, {"text": "Our contributions can be summarized as follows.", "labels": [], "entities": []}, {"text": "(1) We apply the A* search framework to sequential decoding problem.", "labels": [], "entities": []}, {"text": "We show that A* with a proper heuristic can outperform the classic Viterbi decoding.", "labels": [], "entities": []}, {"text": "(2) We propose 1-best A*, 1-best iterative A* decoding algorithms which are the second and third fastest decoding algorithms among the five decoding algorithms for comparison, although there is a significant gap to the fastest 1-best decoding algorithm.", "labels": [], "entities": []}, {"text": "(3) We propose k-best A* and k-best iterative Viterbi A* algorithms.", "labels": [], "entities": []}, {"text": "The latter is several times or orders of magnitude faster than the state-of-the-art k-best decoding algorithm.", "labels": [], "entities": []}, {"text": "This algorithm makes real-time large-scale tagging applications with thousands of labels feasible.", "labels": [], "entities": [{"text": "real-time large-scale tagging", "start_pos": 21, "end_pos": 50, "type": "TASK", "confidence": 0.6058091719945272}]}], "datasetContent": [{"text": "We compare aforementioned 1-best and k-best sequential decoding algorithms using five datasets in this section.", "labels": [], "entities": []}, {"text": "We apply 1-best and k-best sequential decoding algorithms to five NLP tagging tasks: Penn TreeBank (PTB) POS tagging, CoNLL2000 joint POS tagging and chunking, CoNLL 2003 joint POS tagging, chunking and named entity tagging, HPSG supertagging () and a search query named entity recognition (NER) dataset.", "labels": [], "entities": [{"text": "NLP tagging", "start_pos": 66, "end_pos": 77, "type": "TASK", "confidence": 0.6371661573648453}, {"text": "Penn TreeBank (PTB)", "start_pos": 85, "end_pos": 104, "type": "DATASET", "confidence": 0.9605355858802795}, {"text": "POS tagging", "start_pos": 105, "end_pos": 116, "type": "TASK", "confidence": 0.7743587791919708}, {"text": "CoNLL2000 joint POS tagging and chunking", "start_pos": 118, "end_pos": 158, "type": "TASK", "confidence": 0.6466951469580332}, {"text": "CoNLL 2003 joint POS tagging", "start_pos": 160, "end_pos": 188, "type": "TASK", "confidence": 0.7297629237174987}, {"text": "named entity tagging", "start_pos": 203, "end_pos": 223, "type": "TASK", "confidence": 0.6339346071084341}]}, {"text": "We used sections 02-21 of PTB for training and section 23 for testing in POS task.", "labels": [], "entities": [{"text": "PTB", "start_pos": 26, "end_pos": 29, "type": "DATASET", "confidence": 0.9507098197937012}, {"text": "POS task", "start_pos": 73, "end_pos": 81, "type": "TASK", "confidence": 0.5874819159507751}]}, {"text": "As in (, we combine the POS tags and chunk tags to form joint tags for CoNLL 2000 dataset, e.g., NN|B-NP.", "labels": [], "entities": [{"text": "CoNLL 2000 dataset", "start_pos": 71, "end_pos": 89, "type": "DATASET", "confidence": 0.928457776705424}]}, {"text": "Similarly we combine the POS tags, chunk tags, and named entity tags to form joint tags for CoNLL 2003 dataset, e.g., PRP$|I-NP|O.", "labels": [], "entities": [{"text": "CoNLL 2003 dataset", "start_pos": 92, "end_pos": 110, "type": "DATASET", "confidence": 0.9409873882929484}]}, {"text": "Note that by such tag joining, we are able to offer different tag decodings (for example, chunking and named entity tagging) simultaneously.", "labels": [], "entities": []}, {"text": "This indeed is one of the effective approaches for joint tag decoding problems.", "labels": [], "entities": [{"text": "joint tag decoding", "start_pos": 51, "end_pos": 69, "type": "TASK", "confidence": 0.6655247509479523}]}, {"text": "The search query NER dataset is an in-house annotated dataset which assigns semantic labels, such as product, business tags to web search queries.", "labels": [], "entities": []}, {"text": "shows the training and test sets size (sentence #), the average token length of test dataset and the label size for the five datasets.", "labels": [], "entities": []}, {"text": "POS and supertag datasets assign tags to tokens while CoNLL 2000 , CoNLL 2003 and search query datasets assign tags to phrases.", "labels": [], "entities": [{"text": "POS", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.8534123301506042}, {"text": "CoNLL 2000", "start_pos": 54, "end_pos": 64, "type": "DATASET", "confidence": 0.9101313054561615}, {"text": "CoNLL 2003", "start_pos": 67, "end_pos": 77, "type": "DATASET", "confidence": 0.8698604106903076}]}, {"text": "We use the standard BIO encoding for CoNLL 2000, CoNLL 2003 and search query datasets.", "labels": [], "entities": [{"text": "BIO", "start_pos": 20, "end_pos": 23, "type": "METRIC", "confidence": 0.9075210094451904}, {"text": "CoNLL 2000", "start_pos": 37, "end_pos": 47, "type": "DATASET", "confidence": 0.9044809341430664}, {"text": "CoNLL 2003 and search query datasets", "start_pos": 49, "end_pos": 85, "type": "DATASET", "confidence": 0.7635943392912546}]}, {"text": "Due to the long CRF training time (days to weeks even for stochastic gradient descent training) for these large label size datasets, we choose the perceptron algorithm for training.", "labels": [], "entities": []}, {"text": "The models are averaged over 10 iterations).", "labels": [], "entities": []}, {"text": "The training time takes minutes to hours for all datasets.", "labels": [], "entities": []}, {"text": "We note that the selection of training algorithm does not affect the decoding process: the decoding is identical for both CRF and perceptron training algorithms.", "labels": [], "entities": []}, {"text": "We use the common features which are adopted in previous studies, for example.", "labels": [], "entities": []}, {"text": "In particular, we use the unigrams of the current and its neighboring words, word bigrams, prefixes and suffixes of the current word, capitalization, all-number, punctuation, and tag bigrams for POS, CoNLL2000 and CoNLL 2003 datasets.", "labels": [], "entities": [{"text": "POS", "start_pos": 195, "end_pos": 198, "type": "DATASET", "confidence": 0.878415048122406}, {"text": "CoNLL2000", "start_pos": 200, "end_pos": 209, "type": "DATASET", "confidence": 0.8299543261528015}, {"text": "CoNLL 2003 datasets", "start_pos": 214, "end_pos": 233, "type": "DATASET", "confidence": 0.9184392094612122}]}, {"text": "For supertag dataset, we use the same features for the word inputs, and the unigrams and bigrams for gold POS inputs.", "labels": [], "entities": []}, {"text": "For search query dataset, we use the same features plus gazetteer based features.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Training and test datasets size, average token  length of test set and label size for five datasets.", "labels": [], "entities": []}, {"text": " Table 3: Iteration numbers of iterative Viterbi and itera- tive Viterbi A* algorithms for five datasets.", "labels": [], "entities": []}]}