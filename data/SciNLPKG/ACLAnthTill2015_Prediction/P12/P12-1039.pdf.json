{"title": [], "abstractContent": [{"text": "This paper proposes a data-driven method for concept-to-text generation, the task of automatically producing textual output from non-linguistic input.", "labels": [], "entities": [{"text": "concept-to-text generation", "start_pos": 45, "end_pos": 71, "type": "TASK", "confidence": 0.7827746570110321}]}, {"text": "A key insight in our approach is to reduce the tasks of content selection (\"what to say\") and surface realization (\"how to say\") into a common parsing problem.", "labels": [], "entities": []}, {"text": "We define a probabilistic context-free grammar that describes the structure of the input (a corpus of database records and text describing some of them) and represent it compactly as a weighted hypergraph.", "labels": [], "entities": []}, {"text": "The hyper-graph structure encodes exponentially many derivations, which we rerank discriminatively using local and global features.", "labels": [], "entities": []}, {"text": "We propose a novel decoding algorithm for finding the best scoring derivation and generating in this setting.", "labels": [], "entities": []}, {"text": "Experimental evaluation on the ATIS domain shows that our model outperforms a competitive discriminative system both using BLEU and in a judgment elicitation study.", "labels": [], "entities": [{"text": "ATIS domain", "start_pos": 31, "end_pos": 42, "type": "DATASET", "confidence": 0.8791418075561523}, {"text": "BLEU", "start_pos": 123, "end_pos": 127, "type": "METRIC", "confidence": 0.997318685054779}]}], "introductionContent": [{"text": "Concept-to-text generation broadly refers to the task of automatically producing textual output from non-linguistic input such as databases of records, logical form, and expert system knowledge bases.", "labels": [], "entities": [{"text": "Concept-to-text generation", "start_pos": 0, "end_pos": 26, "type": "TASK", "confidence": 0.7032458037137985}]}, {"text": "A variety of concept-totext generation systems have been engineered over the years, with considerable success (e.g.,,,,).", "labels": [], "entities": []}, {"text": "Unfortunately, it is often difficult to adapt them across different domains as they rely mostly on handcrafted components.", "labels": [], "entities": []}, {"text": "In this paper we present a data-driven approach to concept-to-text generation that is domainindependent, conceptually simple, and flexible.", "labels": [], "entities": [{"text": "concept-to-text generation", "start_pos": 51, "end_pos": 77, "type": "TASK", "confidence": 0.7806575894355774}]}, {"text": "Our generator learns from a set of database records and textual descriptions (for some of them).", "labels": [], "entities": []}, {"text": "An example from the air travel domain is shown in.", "labels": [], "entities": []}, {"text": "Here, the records provide a structured representation of the flight details (e.g., departure and arrival time, location), and the text renders some of this information in natural language.", "labels": [], "entities": []}, {"text": "Given such input, our model determines which records to talk about (content selection) and which words to use for describing them (surface realization).", "labels": [], "entities": []}, {"text": "Rather than breaking up the generation process into a sequence of local decisions, we perform both tasks jointly.", "labels": [], "entities": []}, {"text": "A key insight in our approach is to reduce content selection and surface realization into a common parsing problem.", "labels": [], "entities": [{"text": "surface realization", "start_pos": 65, "end_pos": 84, "type": "TASK", "confidence": 0.7683677673339844}]}, {"text": "Specifically, we define a probabilistic context-free grammar (PCFG) that captures the structure of the database and its correspondence to natural language.", "labels": [], "entities": []}, {"text": "This grammar represents multiple derivations which we encode compactly using a weighted hypergraph (or packed forest), a data structure that defines a weight for each tree.", "labels": [], "entities": []}, {"text": "Following a generative approach, we could first learn the weights of the PCFG by maximising the joint likelihood of the model and then perform generation by finding the best derivation tree in the hypergraph.", "labels": [], "entities": [{"text": "PCFG", "start_pos": 73, "end_pos": 77, "type": "DATASET", "confidence": 0.9367027878761292}]}, {"text": "The performance of this baseline system could be potentially further improved using discriminative reranking).", "labels": [], "entities": []}, {"text": "Typically, this method first creates a list of n-best candidates from a generative model, and then reranks them with arbitrary features (both local and global) that are either not computable or intractable to compute within the \u03bbx. f light(x) \u2227 f rom(x, denver) \u2227 to(x, boston) \u2227 day number(x, 9) \u2227 month(x, august)\u2227 less than(arrival time(x), 1600) Give me the flights leaving Denver August ninth coming back to Boston before 4pm.: Example of non-linguistic input as a structured database and logical form and its corresponding text.", "labels": [], "entities": []}, {"text": "We omit record fields that have no value, for the sake of brevity.", "labels": [], "entities": []}, {"text": "An appealing alternative is to rerank the hypergraph directly.", "labels": [], "entities": []}, {"text": "As it compactly encodes exponentially many derivations, we can explore a much larger hypothesis space than would have been possible with an n-best list.", "labels": [], "entities": []}, {"text": "Importantly, in this framework non-local features are computed at all internal hypergraph nodes, allowing the decoder to take advantage of them continuously at all stages of the generation process.", "labels": [], "entities": []}, {"text": "We incorporate features that are local with respect to a span of a sub-derivation in the packed forest; we also (approximately) include features that arbitrarily exceed span boundaries, thus capturing more global knowledge.", "labels": [], "entities": []}, {"text": "Experimental results on the ATIS domain () demonstrate that our model outperforms a baseline based on the best derivation and a stateof-the-art discriminative system () by a wide margin.", "labels": [], "entities": [{"text": "ATIS domain", "start_pos": 28, "end_pos": 39, "type": "DATASET", "confidence": 0.9127705991268158}]}, {"text": "Our contributions in this paper are threefold: we recast concept-to-text generation in a probabilistic parsing framework that allows to jointly optimize content selection and surface realization; we represent parse derivations compactly using hypergraphs and illustrate the use of an algorithm for generating (rather than parsing) in this framework; finally, the application of discriminative reranking to conceptto-text generation is novel to our knowledge and as our experiments show beneficial.", "labels": [], "entities": [{"text": "concept-to-text generation", "start_pos": 57, "end_pos": 83, "type": "TASK", "confidence": 0.7641193866729736}, {"text": "conceptto-text generation", "start_pos": 406, "end_pos": 431, "type": "TASK", "confidence": 0.7701684832572937}]}], "datasetContent": [{"text": "In this section we present our experimental setup for assessing the performance of our model.", "labels": [], "entities": []}, {"text": "We give details on our dataset, model parameters and features, the approaches used for comparison, and explain how system output was evaluated.", "labels": [], "entities": []}, {"text": "We conducted our experiments on the Air Travel Information System (ATIS) dataset which consists of transcriptions of spontaneous utterances of users interacting with a hypothetical online flight booking system.", "labels": [], "entities": [{"text": "Air Travel Information System (ATIS) dataset", "start_pos": 36, "end_pos": 80, "type": "DATASET", "confidence": 0.8420923352241516}]}, {"text": "The dataset was originally created for the development of spoken language systems and is partitioned in individual user turns (e.g., flights from orlando to milwaukee, show flights from orlando to milwaukee leaving after six o'clock) each accompanied with an SQL query to a booking system and the results of this query.", "labels": [], "entities": []}, {"text": "These utterances are typically short expressing a specific communicative goal (e.g., a question about the origin of a flight or its time of arrival).", "labels": [], "entities": []}, {"text": "This inevitably results in small scenarios with a few words that often unambiguously correspond to a single record.", "labels": [], "entities": []}, {"text": "To avoid training our model on a somewhat trivial corpus, we used the dataset introduced in Zettlemoyer and Collins (2007) instead, which combines the utterances of a single user in one scenario and contains 5,426 scenarios in total; each scenario corresponds to a (manually annotated) formal meaning representation (\u03bb-expression) and its translation in natural language.", "labels": [], "entities": []}, {"text": "Lambda expressions were automatically converted into records, fields and values following the conventions adopted in.", "labels": [], "entities": []}, {"text": "Given a lambda expression like the one shown in, we first create a record for each variable and constant (e.g., x, 9, august).", "labels": [], "entities": []}, {"text": "We then assign record types according to the corresponding class types (e.g., variable x has class type flight).", "labels": [], "entities": []}, {"text": "Next, fields and values are added from predicates with two arguments with the class type of the first argument matching that of the record type.", "labels": [], "entities": []}, {"text": "The name of the predicate denotes the field, and the second argument denotes the value.", "labels": [], "entities": []}, {"text": "We also defined special record types, such as condition and search.", "labels": [], "entities": []}, {"text": "The latter is introduced for every lambda operator and assigned the categorical field what with the value flight which refers to the record type of variable x.", "labels": [], "entities": []}, {"text": "Contrary to datasets used in previous generation studies (e.g., and WEATHERGOV (), ATIS has a much richer vocabulary (927 words); each scenario corresponds to a single sentence (average length is 11.2 words) with 2.65 out of 19 record types mentioned on average.", "labels": [], "entities": [{"text": "WEATHERGOV", "start_pos": 68, "end_pos": 78, "type": "DATASET", "confidence": 0.761093020439148}, {"text": "ATIS", "start_pos": 83, "end_pos": 87, "type": "DATASET", "confidence": 0.45211467146873474}]}, {"text": "Following, we trained on 4,962 scenarios and tested on ATIS NOV93 which contains 448 examples.", "labels": [], "entities": [{"text": "ATIS NOV93", "start_pos": 55, "end_pos": 65, "type": "DATASET", "confidence": 0.7808395028114319}]}, {"text": "We evaluated three configurations of our model.", "labels": [], "entities": []}, {"text": "A system that only uses the top scoring derivation in each sub-generation and incorporates only the baseline and alignment features (1-BEST+BASE+ALIGN).", "labels": [], "entities": [{"text": "alignment", "start_pos": 113, "end_pos": 122, "type": "METRIC", "confidence": 0.963075578212738}, {"text": "BASE", "start_pos": 140, "end_pos": 144, "type": "METRIC", "confidence": 0.9979283809661865}, {"text": "ALIGN", "start_pos": 145, "end_pos": 150, "type": "METRIC", "confidence": 0.8766860365867615}]}, {"text": "Our second system considers the k-best derivations and additionally includes lexical features (k-BEST+BASE+ALIGN+LEX).", "labels": [], "entities": [{"text": "BASE+ALIGN+LEX", "start_pos": 102, "end_pos": 116, "type": "METRIC", "confidence": 0.7531501293182373}]}, {"text": "The number of k-best derivations was set to 40 and estimated experimentally on held-out data.", "labels": [], "entities": []}, {"text": "And finally, our third system includes the full feature set (k-BEST+BASE+ALIGN+LEX+STR).", "labels": [], "entities": [{"text": "BASE", "start_pos": 68, "end_pos": 72, "type": "METRIC", "confidence": 0.9963313937187195}, {"text": "ALIGN+LEX+", "start_pos": 73, "end_pos": 83, "type": "METRIC", "confidence": 0.7287209182977676}, {"text": "STR", "start_pos": 83, "end_pos": 86, "type": "METRIC", "confidence": 0.5393361449241638}]}, {"text": "Note, that the second and third system incorporate non-local features, hence the use of k-best derivation lists.", "labels": [], "entities": []}, {"text": "We compared our model to whose approach is closest to ours.", "labels": [], "entities": []}, {"text": "We evaluated system output automatically, using the BLEU-4 modified precision score () with the human-written text as reference.", "labels": [], "entities": [{"text": "BLEU-4 modified precision score", "start_pos": 52, "end_pos": 83, "type": "METRIC", "confidence": 0.8725942224264145}]}, {"text": "We also report results with the METEOR score (, which takes into account word re-ordering and has been shown to correlate better with human judgments at the sentence level.", "labels": [], "entities": [{"text": "METEOR score", "start_pos": 32, "end_pos": 44, "type": "METRIC", "confidence": 0.9830784499645233}]}, {"text": "In addition, we evaluated the generated text by eliciting human judgments.", "labels": [], "entities": []}, {"text": "Participants were presented with a scenario and its corresponding verbalization (see) and were asked to rate the latter along two dimensions: fluency (is the text grammatical and overall understandable?) and semantic correctness (does the meaning conveyed by the text correspond to the database input?).", "labels": [], "entities": []}, {"text": "The subjects used a five point rating scale where a high number indicates better performance.", "labels": [], "entities": []}, {"text": "We randomly selected 12 documents from the test set and generated output with two of our models (1-BEST+BASE+ALIGN and k-BEST+BASE+ALIGN+LEX+STR) and model.", "labels": [], "entities": [{"text": "BASE", "start_pos": 104, "end_pos": 108, "type": "METRIC", "confidence": 0.9956544637680054}, {"text": "BASE+ALIGN+LEX+STR)", "start_pos": 126, "end_pos": 145, "type": "METRIC", "confidence": 0.6521558351814747}]}, {"text": "We also included the original text (HUMAN) as a gold standard.", "labels": [], "entities": [{"text": "HUMAN", "start_pos": 36, "end_pos": 41, "type": "METRIC", "confidence": 0.7601039409637451}]}, {"text": "We thus obtained ratings for 48 (12 \u00d7 4) scenario-text pairs.", "labels": [], "entities": []}, {"text": "The study was conducted over the Internet, using Amazon Mechanical Turk, and was completed by 51 volunteers, all self reported native English speakers.", "labels": [], "entities": [{"text": "Amazon Mechanical Turk", "start_pos": 49, "end_pos": 71, "type": "DATASET", "confidence": 0.8981995979944865}]}, {"text": "over the 1-BEST system and 3.85% over ANGELI in terms of BLEU.", "labels": [], "entities": [{"text": "ANGELI", "start_pos": 38, "end_pos": 44, "type": "METRIC", "confidence": 0.5127252340316772}, {"text": "BLEU", "start_pos": 57, "end_pos": 61, "type": "METRIC", "confidence": 0.9993213415145874}]}, {"text": "We observe a similar trend when evaluating system output with METEOR.", "labels": [], "entities": [{"text": "METEOR", "start_pos": 62, "end_pos": 68, "type": "METRIC", "confidence": 0.8017203211784363}]}, {"text": "Differences in magnitude are larger with the latter metric.", "labels": [], "entities": [{"text": "Differences", "start_pos": 0, "end_pos": 11, "type": "METRIC", "confidence": 0.9563412070274353}]}], "tableCaptions": [{"text": " Table 2: BLEU-4 and METEOR results on ATIS.", "labels": [], "entities": [{"text": "BLEU-4", "start_pos": 10, "end_pos": 16, "type": "METRIC", "confidence": 0.9984583854675293}, {"text": "METEOR", "start_pos": 21, "end_pos": 27, "type": "METRIC", "confidence": 0.9775675535202026}, {"text": "ATIS", "start_pos": 39, "end_pos": 43, "type": "METRIC", "confidence": 0.4940110445022583}]}, {"text": " Table 3: Mean ratings for fluency and semantic correct- ness (SemCor) on system output elicited by humans.", "labels": [], "entities": [{"text": "semantic correct- ness (SemCor)", "start_pos": 39, "end_pos": 70, "type": "METRIC", "confidence": 0.7852254169327872}]}]}