{"title": [{"text": "Modeling Topic Dependencies in Hierarchical Text Categorization", "labels": [], "entities": [{"text": "Hierarchical Text Categorization", "start_pos": 31, "end_pos": 63, "type": "TASK", "confidence": 0.6083941658337911}]}], "abstractContent": [{"text": "In this paper, we encode topic dependencies in hierarchical multi-label Text Categoriza-tion (TC) by means of rerankers.", "labels": [], "entities": []}, {"text": "We represent reranking hypotheses with several innovative kernels considering both the structure of the hierarchy and the probability of nodes.", "labels": [], "entities": []}, {"text": "Additionally, to better investigate the role of category relationships, we consider two interesting cases: (i) traditional schemes in which node-fathers include all the documents of their child-categories; and (ii) more general schemes, in which children can include documents not belonging to their fathers.", "labels": [], "entities": []}, {"text": "The extensive experimentation on Reuters Corpus Volume 1 shows that our rerankers inject effective structural semantic dependencies in multi-classifiers and significantly outperform the state-of-the-art.", "labels": [], "entities": [{"text": "Reuters Corpus Volume 1", "start_pos": 33, "end_pos": 56, "type": "DATASET", "confidence": 0.9248341768980026}]}], "introductionContent": [{"text": "Automated Text Categorization (TC) algorithms for hierarchical taxonomies are typically based on flat schemes, e.g., one-vs.-all, which do not take topic relationships into account.", "labels": [], "entities": [{"text": "Automated Text Categorization (TC)", "start_pos": 0, "end_pos": 34, "type": "TASK", "confidence": 0.7816915512084961}]}, {"text": "This is due to two major problems: (i) complexity in introducing them in the learning algorithm and (ii) the small or no advantage that they seem to provide ().", "labels": [], "entities": []}, {"text": "We speculate that the failure of using hierarchical approaches is caused by the inherent complexity of modeling all possible topic dependencies rather than the uselessness of such relationships.", "labels": [], "entities": []}, {"text": "More precisely, although hierarchical multi-label classifiers can exploit machine learning algorithms for structural output, e.g.,, they often impose a number of simplifying restrictions on some category assignments.", "labels": [], "entities": []}, {"text": "Typically, the probability of a document d to belong to a subcategory Ci of a category C is assumed to depend only on d and C, but not on other subcategories of C, or any other categories in the hierarchy.", "labels": [], "entities": []}, {"text": "Indeed, the introduction of these long-range dependencies lead to computational intractability or more in general to the problem of how to select an effective subset of them.", "labels": [], "entities": []}, {"text": "It is important to stress that (i) there is no theory that can suggest which are the dependencies to be included in the model and (ii) their exhaustive explicit generation (i.e., the generation of all hierarchy subparts) is computationally infeasible.", "labels": [], "entities": []}, {"text": "In this perspective, kernel methods area viable approach to implicitly and easily explore feature spaces encoding dependencies.", "labels": [], "entities": []}, {"text": "Unfortunately, structural kernels, e.g., tree kernels, cannot be applied in structured output algorithms such as (), again for the lack of a suitable theory.", "labels": [], "entities": []}, {"text": "In this paper, we propose to use the combination of reranking with kernel methods as away to handle the computational and feature design issues.", "labels": [], "entities": []}, {"text": "We first use a basic hierarchical classifier to generate a hypothesis set of limited size, and then apply reranking models.", "labels": [], "entities": []}, {"text": "Since our rerankers are simple binary classifiers of hypothesis pairs, they can encode complex dependencies thanks to kernel methods.", "labels": [], "entities": []}, {"text": "In particular, we used tree, sequence and linear kernels applied to structural and feature-vector representations describing hierarchical dependencies.", "labels": [], "entities": []}, {"text": "Additionally, to better investigate the role of topical relationships, we consider two interesting cases: (i) traditional categorization schemes in which node-fathers include all the documents of their childcategories; and (ii) more general schemes, in which children can include documents not belonging to their fathers.", "labels": [], "entities": []}, {"text": "The intuition under the above setting is that shared documents between categories create semantic links between them.", "labels": [], "entities": []}, {"text": "Thus, if we remove common documents between father and children, we reduce the dependencies that can be captured with traditional bag-of-words representation.", "labels": [], "entities": []}, {"text": "We carried out experiments on two entire hierarchies TOPICS (103 nodes organized in 5 levels) and INDUSTRIAL (365 nodes organized in 6 levels) of the well-known Reuters Corpus Volume 1 (RCV1).", "labels": [], "entities": [{"text": "TOPICS", "start_pos": 53, "end_pos": 59, "type": "METRIC", "confidence": 0.9643001556396484}, {"text": "INDUSTRIAL", "start_pos": 98, "end_pos": 108, "type": "METRIC", "confidence": 0.9634143710136414}, {"text": "Reuters Corpus Volume 1 (RCV1)", "start_pos": 161, "end_pos": 191, "type": "DATASET", "confidence": 0.9565182413373675}]}, {"text": "We first evaluate the accuracy as well as the efficiency of several reranking models.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 22, "end_pos": 30, "type": "METRIC", "confidence": 0.9996280670166016}]}, {"text": "The results show that all our rerankers consistently and significantly improve on the traditional approaches to TC up to 10 absolute percent points.", "labels": [], "entities": [{"text": "TC", "start_pos": 112, "end_pos": 114, "type": "TASK", "confidence": 0.9363034963607788}]}, {"text": "Very interestingly, the combination of structural kernels with the linear kernel applied to vectors of category probabilities further improves on reranking: such a vector provides a more effective information than the joint global probability of the reranking hypothesis.", "labels": [], "entities": [{"text": "reranking", "start_pos": 146, "end_pos": 155, "type": "TASK", "confidence": 0.9668991565704346}]}, {"text": "In the rest of the paper, Section 2 describes the hypothesis generation algorithm, Section 3 illustrates our reranking approach based on tree kernels, Section 4 reports on our experiments, Section 5 illustrates the related work and finally Section 6 derives the conclusions.", "labels": [], "entities": [{"text": "hypothesis generation", "start_pos": 50, "end_pos": 71, "type": "TASK", "confidence": 0.7589443922042847}]}], "datasetContent": [{"text": "The aim of the experiments is to demonstrate that our reranking approach can introduce semantic dependencies in the hierarchical classification model, which can improve accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 169, "end_pos": 177, "type": "METRIC", "confidence": 0.9964780211448669}]}, {"text": "For this purpose, we show that several reranking models based on tree kernels improve the classification based on the flat one-vs.-all approach.", "labels": [], "entities": []}, {"text": "Then, we analyze the efficiency of our models, demonstrating their applicability.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Instance distributions of RCV1: the most populated categories are on the top, the medium sized ones follow  and the smallest ones are at the bottom. There are some difference between child-free and child-full setting since for  the former, from each node, we removed all the documents in its children.", "labels": [], "entities": []}, {"text": " Table 2: Comparison of rerankers using different kernels,  child-full setting (K J model).", "labels": [], "entities": []}, {"text": " Table 3: Comparison of rerankers using different kernels,  child-free setting (K J model).", "labels": [], "entities": []}, {"text": " Table 1. The training set is used for learning  the binary classifiers needed to build the multiclass- classifier (MCC). To compare with previous work  we also considered the Lewis' split (", "labels": [], "entities": []}, {"text": " Table 4: F1 of some binary classifiers along with the  Micro and Macro-Average F1 over all 103 categories  of RCV1, 8 hypotheses and 32k of training data for  rerankers using STK.", "labels": [], "entities": [{"text": "F1", "start_pos": 10, "end_pos": 12, "type": "METRIC", "confidence": 0.9994966983795166}, {"text": "F1", "start_pos": 80, "end_pos": 82, "type": "METRIC", "confidence": 0.792669951915741}, {"text": "STK", "start_pos": 176, "end_pos": 179, "type": "DATASET", "confidence": 0.8962638974189758}]}, {"text": " Table 5: Comparison between rankers using STK or BOL (when indicated) with the K J and K P schema. 32k  examples are used for training the rerankers with child-full setting.", "labels": [], "entities": [{"text": "STK", "start_pos": 43, "end_pos": 46, "type": "METRIC", "confidence": 0.8178223371505737}, {"text": "BOL", "start_pos": 50, "end_pos": 53, "type": "METRIC", "confidence": 0.9533883929252625}]}, {"text": " Table 6: Oracle performance according to the number of  hypotheses (child-free setting).", "labels": [], "entities": []}]}