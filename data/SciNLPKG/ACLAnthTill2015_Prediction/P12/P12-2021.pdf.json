{"title": [{"text": "Robust Conversion of CCG Derivations to Phrase Structure Trees", "labels": [], "entities": []}], "abstractContent": [{"text": "We propose an improved, bottom-up method for converting CCG derivations into PTB-style phrase structure trees.", "labels": [], "entities": []}, {"text": "In contrast with past work (Clark and Curran, 2009), which used simple transductions on category pairs, our approach uses richer transductions attached to single categories.", "labels": [], "entities": []}, {"text": "Our conversion preserves more sentences under round-trip conversion (51.1% vs. 39.6%) and is more robust.", "labels": [], "entities": [{"text": "conversion", "start_pos": 4, "end_pos": 14, "type": "TASK", "confidence": 0.9710753560066223}]}, {"text": "In particular , unlike past methods, ours does not require ad-hoc rules over non-local features, and so can be easily integrated into a parser.", "labels": [], "entities": []}], "introductionContent": [{"text": "Converting the Penn Treebank (PTB,) to other formalisms, such as HPSG (),, LTAG, and CCG, is a complex process that renders linguistic phenomena in formalism-specific ways.", "labels": [], "entities": [{"text": "Penn Treebank (PTB", "start_pos": 15, "end_pos": 33, "type": "DATASET", "confidence": 0.9595602303743362}]}, {"text": "Tools for reversing these conversions are desirable for downstream parser use and parser comparison.", "labels": [], "entities": [{"text": "parser comparison", "start_pos": 82, "end_pos": 99, "type": "TASK", "confidence": 0.9011514484882355}]}, {"text": "However, reversing conversions is difficult, as corpus conversions may lose information or smooth over PTB inconsistencies.", "labels": [], "entities": [{"text": "reversing conversions", "start_pos": 9, "end_pos": 30, "type": "TASK", "confidence": 0.8681014776229858}]}, {"text": "Clark and Curran (2009) developed a CCG to PTB conversion that treats the CCG derivation as a phrase structure tree and applies hand-crafted rules to every pair of categories that combine in the derivation.", "labels": [], "entities": []}, {"text": "Because their approach does not exploit the generalisations inherent in the CCG formalism, they must resort to ad-hoc rules over non-local features of the CCG constituents being combined (when a fixed pair of CCG categories correspond to multiple PTB structures).", "labels": [], "entities": []}, {"text": "Even with such rules, they correctly convert only 39.6% of gold CCGbank derivations.", "labels": [], "entities": []}, {"text": "Our conversion assigns a set of bracket instructions to each word based on its CCG category, then follows the CCG derivation, applying and combining instructions at each combinatory step to build a phrase structure tree.", "labels": [], "entities": []}, {"text": "This requires specific instructions for each category (not all pairs), and generic operations for each combinator.", "labels": [], "entities": []}, {"text": "We coverall categories in the development set and correctly convert 51.1% of sentences.", "labels": [], "entities": []}, {"text": "Unlike Clark and Curran's approach, we require no rules that consider non-local features of constituents, which enables the possibility of simple integration with a CKY-based parser.", "labels": [], "entities": []}, {"text": "The most common errors our approach makes involve nodes for clauses and rare spans such as QPs, NXs, and NACs.", "labels": [], "entities": []}, {"text": "Many of these errors are inconsistencies in the original PTB annotations that are not recoverable.", "labels": [], "entities": [{"text": "PTB", "start_pos": 57, "end_pos": 60, "type": "DATASET", "confidence": 0.8410006165504456}]}, {"text": "These issues make evaluating parser output difficult, but our method does enable an improved comparison of CCG and PTB parsers.", "labels": [], "entities": []}], "datasetContent": [{"text": "Using sections 00-21 of the treebanks, we handcrafted instructions for 527 lexical categories, a process that took under 100 hours, and includes all the categories used by the C&C parser.", "labels": [], "entities": []}, {"text": "There are 647 further categories and 35 non-combinatory binary rules in sections 00-21 that we did not annotate.", "labels": [], "entities": []}, {"text": "For unannotated categories, we use the instructions of the result category with an added instruction.", "labels": [], "entities": []}, {"text": "compares our approach with C&C-CONV on gold CCG derivations.", "labels": [], "entities": []}, {"text": "The results shown are as reported by EVALB () using the Collins (1997) parameters.", "labels": [], "entities": [{"text": "EVALB", "start_pos": 37, "end_pos": 42, "type": "DATASET", "confidence": 0.7720461487770081}]}, {"text": "Our approach leads to increases on all metrics of at least 1.1%, and increases exact sentence match by over 11% (both absolute).", "labels": [], "entities": [{"text": "exact sentence match", "start_pos": 79, "end_pos": 99, "type": "METRIC", "confidence": 0.8417319655418396}]}, {"text": "Many of the remaining errors relate to missing and extra clause nodes and a range of rare structures, such as QPs, NACs, and NXs.", "labels": [], "entities": []}, {"text": "The only other prominent errors are single word spans, e.g. extra or missing ADVPs.", "labels": [], "entities": []}, {"text": "Many of these errors are unrecoverable from CCGbank, either because inconsistencies in the PTB have been smoothed over or because they are genuine but rare constructions that were lost.", "labels": [], "entities": [{"text": "CCGbank", "start_pos": 44, "end_pos": 51, "type": "DATASET", "confidence": 0.9762144684791565}, {"text": "PTB", "start_pos": 91, "end_pos": 94, "type": "DATASET", "confidence": 0.9283496141433716}]}], "tableCaptions": [{"text": " Table 3: Instruction sets for the categories in Figure 1.", "labels": [], "entities": []}, {"text": " Table 4: PARSEVAL Precision, Recall, F-Score, and exact  sentence match for converted gold CCG derivations.", "labels": [], "entities": [{"text": "PARSEVAL", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9169068336486816}, {"text": "Precision", "start_pos": 19, "end_pos": 28, "type": "METRIC", "confidence": 0.8382378220558167}, {"text": "Recall", "start_pos": 30, "end_pos": 36, "type": "METRIC", "confidence": 0.9976523518562317}, {"text": "F-Score", "start_pos": 38, "end_pos": 45, "type": "METRIC", "confidence": 0.9965079426765442}, {"text": "exact  sentence match", "start_pos": 51, "end_pos": 72, "type": "METRIC", "confidence": 0.8759089509646097}]}]}