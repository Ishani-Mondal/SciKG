{"title": [{"text": "Corpus-based interpretation of instructions in virtual environments", "labels": [], "entities": [{"text": "Corpus-based interpretation of instructions", "start_pos": 0, "end_pos": 43, "type": "TASK", "confidence": 0.7465035766363144}]}], "abstractContent": [{"text": "Previous approaches to instruction interpretation have required either extensive domain adaptation or manually annotated corpora.", "labels": [], "entities": [{"text": "instruction interpretation", "start_pos": 23, "end_pos": 49, "type": "TASK", "confidence": 0.7625812292098999}]}, {"text": "This paper presents a novel approach to instruction interpretation that leverages a large amount of unannotated, easy-to-collect data from humans interacting with a virtual world.", "labels": [], "entities": [{"text": "instruction interpretation", "start_pos": 40, "end_pos": 66, "type": "TASK", "confidence": 0.7553293108940125}]}, {"text": "We compare several algorithms for automatically segmenting and discretizing this data into (utterance, reaction) pairs and training a classifier to predict reactions given the next utterance.", "labels": [], "entities": []}, {"text": "Our empirical analysis shows that the best algorithm achieves 70% accuracy on this task, with no manual annotation required.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 66, "end_pos": 74, "type": "METRIC", "confidence": 0.9994547963142395}]}], "introductionContent": [], "datasetContent": [{"text": "For the evaluation phase, we annotated both the Cm and C s corpora entirely, and then we split them in an 80/20 proportion; the first 80% of data collected in each virtual world was used for training, while the remaining 20% was used for testing.", "labels": [], "entities": []}, {"text": "For each pair (u k , ck ) in the testing set, we used our algorithm to predict the reaction to the selected utterance, and then compared this result against the automatically annotated reaction.", "labels": [], "entities": []}, {"text": "Comparing the Bhv and Vis segmentation strategies, Vis tends to obtain better results than Bhv.", "labels": [], "entities": [{"text": "Bhv", "start_pos": 14, "end_pos": 17, "type": "METRIC", "confidence": 0.8617100715637207}, {"text": "Vis segmentation", "start_pos": 22, "end_pos": 38, "type": "TASK", "confidence": 0.6316663026809692}]}, {"text": "In addition, accuracy on the C s corpus was generally higher than Cm . Given that C s contained only one IG, we believe this led to less variability in the instructions and less noise in the training data.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 13, "end_pos": 21, "type": "METRIC", "confidence": 0.9994603991508484}]}, {"text": "We evaluated the impact of user corrections by simulating them using the existing corpus.", "labels": [], "entities": [{"text": "user corrections", "start_pos": 27, "end_pos": 43, "type": "TASK", "confidence": 0.6940783709287643}]}, {"text": "In case of a wrong response, the algorithm receives a second utterance with the same reaction (a paraphrase of the previous one).", "labels": [], "entities": []}, {"text": "Then the new utterance is tested over the same set of possible groups, except for the one which was returned before.", "labels": [], "entities": []}, {"text": "If the correct reaction is not predicted after four tries, or there are no utterances with the same reaction, the predictions are registered as wrong.", "labels": [], "entities": []}, {"text": "To measure the effects of user corrections vs. without, we used a different evaluation process for this algorithm: first, we split the corpus in a 50/50 proportion, and then we moved correctly predicted utterances from the testing set towards training, until either there was nothing more to learn or the training set reached 80% of the entire corpus size.", "labels": [], "entities": []}, {"text": "As expected, user corrections significantly improve accuracy, as shown in.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 52, "end_pos": 60, "type": "METRIC", "confidence": 0.9993820190429688}]}, {"text": "The worst algorithm's results improve linearly with each try, while the best ones behave asymptotically, barely improving after the second try.", "labels": [], "entities": []}, {"text": "The best algorithm reaches 92% with just one correction from the IG.", "labels": [], "entities": [{"text": "IG", "start_pos": 65, "end_pos": 67, "type": "DATASET", "confidence": 0.8243682980537415}]}], "tableCaptions": []}