{"title": [{"text": "A Class-Based Agreement Model for Generating Accurately Inflected Translations", "labels": [], "entities": [{"text": "Generating Accurately Inflected Translations", "start_pos": 34, "end_pos": 78, "type": "TASK", "confidence": 0.6053763404488564}]}], "abstractContent": [{"text": "When automatically translating from a weakly inflected source language like English to a target language with richer grammatical features such as gender and dual number, the output commonly contains morpho-syntactic agreement errors.", "labels": [], "entities": []}, {"text": "To address this issue, we present a target-side, class-based agreement model.", "labels": [], "entities": []}, {"text": "Agreement is promoted by scoring a sequence of fine-grained morpho-syntactic classes that are predicted during decoding for each translation hypothesis.", "labels": [], "entities": []}, {"text": "For English-to-Arabic translation , our model yields a +1.04 BLEU average improvement over a state-of-the-art baseline.", "labels": [], "entities": [{"text": "English-to-Arabic translation", "start_pos": 4, "end_pos": 33, "type": "TASK", "confidence": 0.4944816380739212}, {"text": "BLEU", "start_pos": 61, "end_pos": 65, "type": "METRIC", "confidence": 0.9990811347961426}]}, {"text": "The model does not require bitext or phrase table annotations and can be easily implemented as a feature in many phrase-based decoders.", "labels": [], "entities": []}], "introductionContent": [{"text": "Languages vary in the degree to which surface forms reflect grammatical relations.", "labels": [], "entities": []}, {"text": "English is a weakly inflected language: it has a narrow verbal paradigm, restricted nominal inflection (plurals), and only the vestiges of a case system.", "labels": [], "entities": []}, {"text": "Consequently, translation into English-which accounts for much of the machine translation (MT) literature-often involves some amount of morpho-syntactic dimensionality reduction.", "labels": [], "entities": [{"text": "translation", "start_pos": 14, "end_pos": 25, "type": "TASK", "confidence": 0.963996410369873}, {"text": "machine translation (MT)", "start_pos": 70, "end_pos": 94, "type": "TASK", "confidence": 0.8379485547542572}]}, {"text": "Less attention has been paid to what happens during translation from English: richer grammatical features such as gender, dual number, and overt case are effectively latent variables that must be inferred during decoding.", "labels": [], "entities": []}, {"text": "Consider the output of Google Translate for the simple English sentence in.", "labels": [], "entities": []}, {"text": "The correct translation is a monotone mapping of the input.", "labels": [], "entities": []}, {"text": "However, in Arabic, SVO word order requires both gender and number agreement between the subject 'the car' and verb 'go'.", "labels": [], "entities": [{"text": "SVO word order", "start_pos": 20, "end_pos": 34, "type": "TASK", "confidence": 0.6942462821801504}]}, {"text": "The MT system selects the correct verb stem, but with masculine inflection.", "labels": [], "entities": [{"text": "MT", "start_pos": 4, "end_pos": 6, "type": "TASK", "confidence": 0.9685859084129333}]}, {"text": "Although the translation has go . with-speed ....", "labels": [], "entities": []}, {"text": "The cargoes quickly the correct semantics, it is ultimately ungrammatical.", "labels": [], "entities": []}, {"text": "This paper addresses the problem of generating text that conforms to morpho-syntactic agreement rules.", "labels": [], "entities": []}, {"text": "Agreement relations that cross statistical phrase boundaries are not explicitly modeled inmost phrasebased MT systems.", "labels": [], "entities": []}, {"text": "We address this shortcoming with an agreement model that scores sequences of fine-grained morphosyntactic classes.", "labels": [], "entities": []}, {"text": "First, bound morphemes in translation hypotheses are segmented.", "labels": [], "entities": []}, {"text": "Next, the segments are labeled with classes that encode both syntactic category information (i.e., parts of speech) and grammatical features such as number and gender.", "labels": [], "entities": []}, {"text": "Finally, agreement is promoted by scoring the predicted class sequences with a generative Markov model.", "labels": [], "entities": []}, {"text": "Our model scores hypotheses during decoding.", "labels": [], "entities": []}, {"text": "Unlike previous models for scoring syntactic relations, our model does not require bitext annotations, phrase table features, or decoder modifications.", "labels": [], "entities": []}, {"text": "The model can be implemented using the feature APIs of popular phrase-based decoders such as Moses (  and.", "labels": [], "entities": []}, {"text": "Intuition might suggest that the standard n-gram language model (LM) is sufficient to handle agreement phenomena.", "labels": [], "entities": []}, {"text": "However, LM statistics are sparse, and they are made sparser by morphological variation.", "labels": [], "entities": []}, {"text": "For English-to-Arabic translation, we achieve a +1.04 BLEU average improvement by tiling our model on top of a large LM.", "labels": [], "entities": [{"text": "English-to-Arabic translation", "start_pos": 4, "end_pos": 33, "type": "TASK", "confidence": 0.5602418929338455}, {"text": "BLEU", "start_pos": 54, "end_pos": 58, "type": "METRIC", "confidence": 0.9987922310829163}]}, {"text": "It has also been suggested that this setting requires morphological generation because the bitext may not contain all inflected variants ().", "labels": [], "entities": [{"text": "morphological generation", "start_pos": 54, "end_pos": 78, "type": "TASK", "confidence": 0.7323234975337982}]}, {"text": "However, using lexical coverage experiments, we show that there is ample room for translation quality improvements through better selection of forms that already exist in the translation model.", "labels": [], "entities": []}], "datasetContent": [{"text": "We first evaluate the Arabic segmenter and tagger components independently, then provide EnglishArabic translation quality results.", "labels": [], "entities": []}, {"text": "Experimental Setup All experiments use the Penn Arabic Treebank (ATB) () parts 1-3 divided into training/dev/test sections according to the canonical split (  The ATB contains clitic-segmented text with persegment morphological analyses (in addition to phrase-structure trees, which we discard).", "labels": [], "entities": [{"text": "Penn Arabic Treebank (ATB)", "start_pos": 43, "end_pos": 69, "type": "DATASET", "confidence": 0.9664788742860159}]}, {"text": "For training the segmenter, we used markers in the vocalized section to construct the IOB character sequences.", "labels": [], "entities": [{"text": "IOB character sequences", "start_pos": 86, "end_pos": 109, "type": "TASK", "confidence": 0.7420137524604797}]}, {"text": "For training the tagger, we automatically converted the ATB morphological analyses to the fine-grained class set.", "labels": [], "entities": [{"text": "tagger", "start_pos": 17, "end_pos": 23, "type": "TASK", "confidence": 0.9585949778556824}]}, {"text": "This procedure resulted in 89 classes.", "labels": [], "entities": []}, {"text": "For the segmentation evaluation, we report percharacter labeling accuracy.", "labels": [], "entities": [{"text": "segmentation", "start_pos": 8, "end_pos": 20, "type": "TASK", "confidence": 0.9858609437942505}, {"text": "accuracy", "start_pos": 65, "end_pos": 73, "type": "METRIC", "confidence": 0.9874460697174072}]}, {"text": "8 For the tagger, we report per-token accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 38, "end_pos": 46, "type": "METRIC", "confidence": 0.9736193418502808}]}, {"text": "1 shows development set accuracy for two settings.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 24, "end_pos": 32, "type": "METRIC", "confidence": 0.8849847912788391}]}, {"text": "FFFF is a standard evaluation in which features maybe defined over the whole sentence.", "labels": [], "entities": [{"text": "FFFF", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.7094431519508362}]}, {"text": "This includes next-character segmenter features and nextword tagger features.", "labels": [], "entities": [{"text": "nextword tagger", "start_pos": 52, "end_pos": 67, "type": "TASK", "confidence": 0.743147611618042}]}, {"text": "II emulates the MT setting in which the models are restricted to current and previous observation features.", "labels": [], "entities": [{"text": "MT", "start_pos": 16, "end_pos": 18, "type": "TASK", "confidence": 0.8921740651130676}]}, {"text": "Since the segmenter operates at the character level, we can use the same feature set.", "labels": [], "entities": []}, {"text": "However, next-observation features must be removed from the tagger.", "labels": [], "entities": []}, {"text": "Nonetheless, tagging accuracy only decreases by 0.1%.", "labels": [], "entities": [{"text": "tagging", "start_pos": 13, "end_pos": 20, "type": "TASK", "confidence": 0.9603628516197205}, {"text": "accuracy", "start_pos": 21, "end_pos": 29, "type": "METRIC", "confidence": 0.9850991368293762}]}], "tableCaptions": [{"text": " Table 1: Intrinsic evaluation accuracy [%] (development  set) for Arabic segmentation and tagging.", "labels": [], "entities": [{"text": "Intrinsic evaluation accuracy", "start_pos": 10, "end_pos": 39, "type": "METRIC", "confidence": 0.7962072690327963}, {"text": "Arabic segmentation", "start_pos": 67, "end_pos": 86, "type": "TASK", "confidence": 0.6850896626710892}]}, {"text": " Table 2: Translation quality results (BLEU-4 [%]) for newswire (nw) sets. Avg is the weighted averaged (by number of  sentences) of the individual test set gains. All improvements are statistically significant at p \u2264 0.01.", "labels": [], "entities": [{"text": "BLEU-4", "start_pos": 39, "end_pos": 45, "type": "METRIC", "confidence": 0.9977808594703674}, {"text": "Avg", "start_pos": 75, "end_pos": 78, "type": "METRIC", "confidence": 0.9981024861335754}]}, {"text": " Table 3: Mixed genre test set results (BLEU-4 [%]). The  MT06 result is statistically significant at p \u2264 0.01; MT08  is significant at p \u2264 0.02. The genres are: nw, broadcast  news (bn), newsgroups (ng), and weblog (wb).", "labels": [], "entities": [{"text": "BLEU-4", "start_pos": 40, "end_pos": 46, "type": "METRIC", "confidence": 0.9982561469078064}, {"text": "MT06", "start_pos": 58, "end_pos": 62, "type": "DATASET", "confidence": 0.7561231851577759}, {"text": "MT08", "start_pos": 112, "end_pos": 116, "type": "DATASET", "confidence": 0.8091694712638855}]}]}