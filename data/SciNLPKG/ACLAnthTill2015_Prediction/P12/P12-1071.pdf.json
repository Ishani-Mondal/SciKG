{"title": [{"text": "Exploiting Multiple Treebanks for Parsing with Quasi-synchronous Grammars", "labels": [], "entities": []}], "abstractContent": [{"text": "We present a simple and effective framework for exploiting multiple monolingual treebanks with different annotation guidelines for parsing.", "labels": [], "entities": []}, {"text": "Several types of transformation patterns (TP) are designed to capture the systematic annotation inconsistencies among different tree-banks.", "labels": [], "entities": []}, {"text": "Based on such TPs, we design quasi-synchronous grammar features to augment the baseline parsing models.", "labels": [], "entities": []}, {"text": "Our approach can significantly advance the state-of-the-art parsing accuracy on two widely used target tree-banks (Penn Chinese Treebank 5.1 and 6.0) using the Chinese Dependency Treebank as the source treebank.", "labels": [], "entities": [{"text": "parsing", "start_pos": 60, "end_pos": 67, "type": "TASK", "confidence": 0.93869549036026}, {"text": "accuracy", "start_pos": 68, "end_pos": 76, "type": "METRIC", "confidence": 0.9547199010848999}, {"text": "Penn Chinese Treebank 5.1", "start_pos": 115, "end_pos": 140, "type": "DATASET", "confidence": 0.9724549949169159}, {"text": "Chinese Dependency Treebank", "start_pos": 160, "end_pos": 187, "type": "DATASET", "confidence": 0.9493067661921183}]}, {"text": "The improvements are respectively 1.37% and 1.10% with automatic part-of-speech tags.", "labels": [], "entities": []}, {"text": "Moreover, an indirect comparison indicates that our approach also outperforms previous work based on treebank conversion.", "labels": [], "entities": []}], "introductionContent": [{"text": "The scale of available labeled data significantly affects the performance of statistical data-driven models.", "labels": [], "entities": []}, {"text": "As a structural classification problem that is more challenging than binary classification and sequence labeling problems, syntactic parsing is more prone to suffer from the data sparseness problem.", "labels": [], "entities": [{"text": "structural classification", "start_pos": 5, "end_pos": 30, "type": "TASK", "confidence": 0.7329629063606262}, {"text": "binary classification and sequence labeling", "start_pos": 69, "end_pos": 112, "type": "TASK", "confidence": 0.6762756049633026}, {"text": "syntactic parsing", "start_pos": 123, "end_pos": 140, "type": "TASK", "confidence": 0.7776466608047485}]}, {"text": "However, the heavy cost of treebanking typically limits one single treebank in both scale and genre.", "labels": [], "entities": []}, {"text": "At present, learning from one single treebank seems inadequate for further boosting parsing accuracy.", "labels": [], "entities": [{"text": "parsing", "start_pos": 84, "end_pos": 91, "type": "TASK", "confidence": 0.9815764427185059}, {"text": "accuracy", "start_pos": 92, "end_pos": 100, "type": "METRIC", "confidence": 0.920894980430603}]}, {"text": "1 * Correspondence author: tliu@ir.hit.edu.cn Incorporating an increased number of global features, such as third-order features in graph-based parsers, slightly affects parsing accuracy ( Therefore, studies have recently resorted to other resources for the enhancement of parsing models, such as large-scale unlabeled data (), and bilingual texts or cross-lingual treebanks).", "labels": [], "entities": [{"text": "parsing", "start_pos": 170, "end_pos": 177, "type": "TASK", "confidence": 0.9594103097915649}, {"text": "accuracy", "start_pos": 178, "end_pos": 186, "type": "METRIC", "confidence": 0.9036151170730591}]}, {"text": "The existence of multiple monolingual treebanks opens another door for this issue.", "labels": [], "entities": []}, {"text": "For example, table 1 lists a few publicly available Chinese treebanks that are motivated by different linguistic theories or applications.", "labels": [], "entities": []}, {"text": "In the current paper, we utilize the first three treebanks, i.e., the Chinese Penn Treebank 5.1 (CTB5) and 6.0 (CTB6) (, and the Chinese Dependency Treebank (CDT) ().", "labels": [], "entities": [{"text": "Chinese Penn Treebank 5.1 (CTB5", "start_pos": 70, "end_pos": 101, "type": "DATASET", "confidence": 0.8613722324371338}, {"text": "Chinese Dependency Treebank (CDT)", "start_pos": 129, "end_pos": 162, "type": "DATASET", "confidence": 0.9252352118492126}]}, {"text": "The Sinica treebank and the Tsinghua Chinese Treebank (TCT)) can be similarly exploited with our proposed approach, which we leave as future work.", "labels": [], "entities": [{"text": "Sinica treebank", "start_pos": 4, "end_pos": 19, "type": "DATASET", "confidence": 0.8475966155529022}, {"text": "Chinese Treebank (TCT))", "start_pos": 37, "end_pos": 60, "type": "DATASET", "confidence": 0.8415681719779968}]}, {"text": "Despite the divergence of annotation philosophy, these treebanks contain rich human knowledge on the Chinese syntax, thereby having a great deal of common ground.", "labels": [], "entities": []}, {"text": "Therefore, exploiting multiple treebanks is very attractive for boosting parsing accuracy.", "labels": [], "entities": [{"text": "parsing", "start_pos": 73, "end_pos": 80, "type": "TASK", "confidence": 0.9804118871688843}, {"text": "accuracy", "start_pos": 81, "end_pos": 89, "type": "METRIC", "confidence": 0.9233319163322449}]}, {"text": "gives an example with different an-notations from CTB5 and CDT.", "labels": [], "entities": []}, {"text": "This example illustrates that the two treebanks annotate coordination constructions differently.", "labels": [], "entities": []}, {"text": "In CTB5, the last noun is the head, whereas the first noun is the head in CDT.", "labels": [], "entities": [{"text": "CTB5", "start_pos": 3, "end_pos": 7, "type": "DATASET", "confidence": 0.9425298571586609}, {"text": "CDT", "start_pos": 74, "end_pos": 77, "type": "DATASET", "confidence": 0.9643785357475281}]}, {"text": "One natural idea for multiple treebank exploitation is treebank conversion.", "labels": [], "entities": [{"text": "treebank conversion", "start_pos": 55, "end_pos": 74, "type": "TASK", "confidence": 0.6453885436058044}]}, {"text": "First, the annotations in the source treebank are converted into the style of the target treebank.", "labels": [], "entities": []}, {"text": "Then, both the converted treebank and the target treebank are combined.", "labels": [], "entities": []}, {"text": "Finally, the combined treebank are used to train a better parser.", "labels": [], "entities": []}, {"text": "However, the inconsistencies among different treebanks are normally nontrivial, which makes rule-based conversion infeasible.", "labels": [], "entities": []}, {"text": "For example, a number of inconsistencies between CTB5 and CDT are lexicon-sensitive, that is, they adopt different annotations for some particular lexicons (or word senses).", "labels": [], "entities": []}, {"text": "use sophisticated strategies to reduce the noises of the converted treebank after automatic treebank conversion.", "labels": [], "entities": []}, {"text": "The present paper proposes a simple and effective framework for this problem.", "labels": [], "entities": []}, {"text": "The proposed framework avoids directly addressing the difficult annotation transformation problem, but focuses on modeling the annotation inconsistencies using transformation patterns (TP).", "labels": [], "entities": []}, {"text": "The TPs are used to compose quasi-synchronous grammar (QG) features, such that the knowledge of the source treebank can inspire the target parser to build better trees.", "labels": [], "entities": []}, {"text": "We conduct extensive experiments using CDT as the source treebank to enhance two target treebanks (CTB5 and CTB6).", "labels": [], "entities": []}, {"text": "Results show that our approach can significantly boost state-of-the-art parsing accuracy.", "labels": [], "entities": [{"text": "parsing", "start_pos": 72, "end_pos": 79, "type": "TASK", "confidence": 0.7568604946136475}, {"text": "accuracy", "start_pos": 80, "end_pos": 88, "type": "METRIC", "confidence": 0.938359260559082}]}, {"text": "Moreover, an indirect comparison indicates that our ap-2 CTB5 is converted to dependency structures following the standard practice of dependency parsing.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 135, "end_pos": 153, "type": "TASK", "confidence": 0.789569079875946}]}, {"text": "Notably, converting a phrase-structure tree into its dependency-structure counterpart is straightforward and can be performed by applying heuristic head-finding rules.", "labels": [], "entities": []}, {"text": "proach also outperforms the treebank conversion approach of.", "labels": [], "entities": []}], "datasetContent": [{"text": "We use the CDT as the source treebank ().", "labels": [], "entities": [{"text": "CDT", "start_pos": 11, "end_pos": 14, "type": "DATASET", "confidence": 0.9662510752677917}]}, {"text": "CDT consists of 60,000 sentences from the People's Daily in 1990s.", "labels": [], "entities": [{"text": "CDT consists of 60,000 sentences from the People's Daily", "start_pos": 0, "end_pos": 56, "type": "DATASET", "confidence": 0.8002831041812897}]}, {"text": "For the target treebank, we use two widely used versions of Penn Chinese Treebank, i.e., CTB5 and CTB6, which consist of Xinhua newswire, Hong Kong news and articles from Sinarama news magazine ().", "labels": [], "entities": [{"text": "Penn Chinese Treebank", "start_pos": 60, "end_pos": 81, "type": "DATASET", "confidence": 0.9813197056452433}, {"text": "CTB5", "start_pos": 89, "end_pos": 93, "type": "DATASET", "confidence": 0.9589648246765137}, {"text": "CTB6", "start_pos": 98, "end_pos": 102, "type": "DATASET", "confidence": 0.8787893652915955}, {"text": "Sinarama news magazine", "start_pos": 171, "end_pos": 193, "type": "DATASET", "confidence": 0.8530798554420471}]}, {"text": "To facilitate comparison with previous results, we follow Zhang and Clark (2008b) for data split and constituency-to-dependency conversion of CTB5.", "labels": [], "entities": [{"text": "constituency-to-dependency conversion", "start_pos": 101, "end_pos": 138, "type": "TASK", "confidence": 0.7397581934928894}, {"text": "CTB5", "start_pos": 142, "end_pos": 146, "type": "DATASET", "confidence": 0.96161949634552}]}, {"text": "CTB6 is used as the Chinese data set in the CoNLL 2009 shared task.", "labels": [], "entities": [{"text": "CTB6", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.9582167863845825}, {"text": "Chinese data set", "start_pos": 20, "end_pos": 36, "type": "DATASET", "confidence": 0.9127342303593954}, {"text": "CoNLL 2009 shared task", "start_pos": 44, "end_pos": 66, "type": "DATASET", "confidence": 0.8968885838985443}]}, {"text": "Therefore, we adopt the same setting.", "labels": [], "entities": []}, {"text": "CDT and CTB5/6 adopt different POS tag sets, and converting from one tag set to another is difficult (.", "labels": [], "entities": [{"text": "CDT", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.968404233455658}, {"text": "CTB5/6", "start_pos": 8, "end_pos": 14, "type": "DATASET", "confidence": 0.9362481236457825}]}, {"text": "To overcome this problem, we use the People's Daily corpus (PD), 6 a large-scale corpus annotated with word segmentation and POS tags, to train a statistical POS tagger.", "labels": [], "entities": [{"text": "People's Daily corpus (PD)", "start_pos": 37, "end_pos": 63, "type": "DATASET", "confidence": 0.9052865930965969}, {"text": "word segmentation", "start_pos": 103, "end_pos": 120, "type": "TASK", "confidence": 0.6991177946329117}, {"text": "POS tagger", "start_pos": 158, "end_pos": 168, "type": "TASK", "confidence": 0.7204551100730896}]}, {"text": "The tagger produces a universal layer of POS tags for both the source and target treebanks.", "labels": [], "entities": []}, {"text": "Based on the common tags, the source parser projects the source annotations into the target treebanks.", "labels": [], "entities": []}, {"text": "PD comprises approximately 300 thousand sentences of with approximately 7 million words from the first half of 1998 of People's Daily.", "labels": [], "entities": [{"text": "PD", "start_pos": 0, "end_pos": 2, "type": "DATASET", "confidence": 0.5795010328292847}, {"text": "People's Daily", "start_pos": 119, "end_pos": 133, "type": "DATASET", "confidence": 0.8879415591557821}]}, {"text": "summarizes the data sets used in the present work.", "labels": [], "entities": []}, {"text": "CTB5X is the same with CTB5 but follows the data split of.", "labels": [], "entities": [{"text": "CTB5X", "start_pos": 0, "end_pos": 5, "type": "DATASET", "confidence": 0.9543873071670532}, {"text": "CTB5", "start_pos": 23, "end_pos": 27, "type": "DATASET", "confidence": 0.9699791073799133}]}, {"text": "We use CTB5X to compare our approach with their treebank conversion method (see).", "labels": [], "entities": [{"text": "CTB5X", "start_pos": 7, "end_pos": 12, "type": "DATASET", "confidence": 0.9563161134719849}]}, {"text": "We adopt unlabeled attachment score (UAS) as the primary evaluation metric.", "labels": [], "entities": [{"text": "unlabeled attachment score (UAS)", "start_pos": 9, "end_pos": 41, "type": "METRIC", "confidence": 0.7939662585655848}]}, {"text": "We also use Root accuracy (RA) and complete match rate (CM) to give more insights.", "labels": [], "entities": [{"text": "Root accuracy (RA)", "start_pos": 12, "end_pos": 30, "type": "METRIC", "confidence": 0.876738166809082}, {"text": "complete match rate (CM)", "start_pos": 35, "end_pos": 59, "type": "METRIC", "confidence": 0.8987271388371786}]}, {"text": "We adopt Dan Bikel's randomized parsing evaluation comparator for significance test.", "labels": [], "entities": [{"text": "significance", "start_pos": 66, "end_pos": 78, "type": "METRIC", "confidence": 0.908041775226593}]}, {"text": "For all models used in current work (POS tagging and parsing), we adopt averaged perceptron to train the feature weights.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 37, "end_pos": 48, "type": "TASK", "confidence": 0.6946498900651932}]}, {"text": "We train each model for 10 iterations and select the parameters that perform best on the development set.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Several publicly available Chinese treebanks.", "labels": [], "entities": []}, {"text": " Table 2: QG features used to enhance the baseline parsing models. dir(h, m) denotes the direction of the dependency  (h, m), whereas dist(h, m) is the distance |h \u2212 m|. \u2295dir(h, m) \u2022 dist(h, m) indicates that the features listed in the  corresponding column are also conjoined with dir(h, m) \u2022 dist(h, m) to form new features.", "labels": [], "entities": []}, {"text": " Table 3: Data used in this work (in sentence number).", "labels": [], "entities": []}, {"text": " Table 5: Parsing accuracy (UAS) comparison on CTB5- test with automatic POS tags. The improvements shown  in parentheses are all statistically significant (p < 10 \u22125 ).", "labels": [], "entities": [{"text": "Parsing accuracy (UAS)", "start_pos": 10, "end_pos": 32, "type": "METRIC", "confidence": 0.8144547820091248}, {"text": "CTB5- test", "start_pos": 47, "end_pos": 57, "type": "DATASET", "confidence": 0.8353188832600912}]}, {"text": " Table 6: Feature ablation for Parser-O2 on CTB5-test  with automatic POS tags.", "labels": [], "entities": [{"text": "CTB5-test", "start_pos": 44, "end_pos": 53, "type": "DATASET", "confidence": 0.9733336567878723}]}, {"text": " Table 8: Parsing accuracy (UAS) comparison on CTB6- test with automatic POS tags. The improvements shown  in parentheses are all statistically significant (p < 10 \u22125 ).", "labels": [], "entities": [{"text": "accuracy (UAS)", "start_pos": 18, "end_pos": 32, "type": "METRIC", "confidence": 0.8434863537549973}, {"text": "CTB6- test", "start_pos": 47, "end_pos": 57, "type": "DATASET", "confidence": 0.8624108632405599}]}, {"text": " Table 9: Parsing accuracy (UAS) comparison on the test  set of CTB5X. Niu et al. (2009) use the maximum en- tropy inspired generative parser (GP) of Charniak", "labels": [], "entities": [{"text": "Parsing accuracy (UAS)", "start_pos": 10, "end_pos": 32, "type": "METRIC", "confidence": 0.8090577483177185}, {"text": "CTB5X", "start_pos": 64, "end_pos": 69, "type": "DATASET", "confidence": 0.9196509122848511}]}]}