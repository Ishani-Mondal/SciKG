{"title": [], "abstractContent": [{"text": "This paper studies the problem of sentence-level semantic coherence by answering SAT-style sentence completion questions.", "labels": [], "entities": [{"text": "answering SAT-style sentence completion", "start_pos": 71, "end_pos": 110, "type": "TASK", "confidence": 0.539497897028923}]}, {"text": "These questions test the ability of algorithms to distinguish sense from nonsense based on a variety of sentence-level phenomena.", "labels": [], "entities": []}, {"text": "We tackle the problem with two approaches: methods that use local lexical information, such as the n-grams of a classical language model; and methods that evaluate global coherence, such as latent semantic analysis.", "labels": [], "entities": [{"text": "latent semantic analysis", "start_pos": 190, "end_pos": 214, "type": "TASK", "confidence": 0.6500557164351145}]}, {"text": "We evaluate these methods on a suite of practice SAT questions, and on a recently released sentence completion task based on data taken from five Conan Doyle novels.", "labels": [], "entities": [{"text": "sentence completion", "start_pos": 91, "end_pos": 110, "type": "TASK", "confidence": 0.744516909122467}]}, {"text": "We find that by fusing local and global information, we can exceed 50% on this task (chance baseline is 20%), and we suggest some avenues for further research.", "labels": [], "entities": []}], "introductionContent": [{"text": "In recent years, standardized examinations have proved a fertile source of evaluation data for language processing tasks.", "labels": [], "entities": [{"text": "language processing tasks", "start_pos": 95, "end_pos": 120, "type": "TASK", "confidence": 0.8164161642392477}]}, {"text": "They are valuable for many reasons: they represent facets of language understanding recognized as important by educational experts; they are organized in various formats designed to evaluate specific capabilities; they are yardsticks by which society measures educational progress; and they affect a large number of people.", "labels": [], "entities": []}, {"text": "Previous researchers have taken advantage of this material to test both narrow and general language processing capabilities.", "labels": [], "entities": []}, {"text": "Among the narrower tasks, the identification of synonyms and antonyms has been studied by, who used questions from the Test of English as a Foreign Language (TOEFL), Graduate Record Exams (GRE) and English as a Second Language (ESL) exams.", "labels": [], "entities": [{"text": "identification of synonyms and antonyms", "start_pos": 30, "end_pos": 69, "type": "TASK", "confidence": 0.8648564219474792}]}, {"text": "Tasks requiring broader competencies include logic puzzles and reading comprehension.", "labels": [], "entities": [{"text": "logic puzzles", "start_pos": 45, "end_pos": 58, "type": "TASK", "confidence": 0.9381901919841766}]}, {"text": "Logic puzzles drawn from the Law School Administration Test (LSAT) and the GRE were studied in (), which combined an extensive array of techniques to solve the problems.", "labels": [], "entities": [{"text": "Law School Administration Test (LSAT)", "start_pos": 29, "end_pos": 66, "type": "DATASET", "confidence": 0.8361431956291199}, {"text": "GRE", "start_pos": 75, "end_pos": 78, "type": "DATASET", "confidence": 0.5112214088439941}]}, {"text": "The DeepRead system () initiated along line of research into reading comprehension based on test prep material (;;;).", "labels": [], "entities": []}, {"text": "In this paper, we study anew class of problems intermediate in difficulty between the extremes of synonym detection and general question answering -the sentence completion questions found on the Scholastic Aptitude Test.", "labels": [], "entities": [{"text": "synonym detection", "start_pos": 98, "end_pos": 115, "type": "TASK", "confidence": 0.9488006234169006}, {"text": "general question answering", "start_pos": 120, "end_pos": 146, "type": "TASK", "confidence": 0.6902975142002106}]}, {"text": "These questions present a sentence with one or two blanks that need to be filled in.", "labels": [], "entities": []}, {"text": "Five possible words (or short phrases) are given as options for each blank.", "labels": [], "entities": []}, {"text": "All possible answers except one result in a nonsense sentence.", "labels": [], "entities": []}, {"text": "Two examples are shown in.", "labels": [], "entities": []}, {"text": "The questions are highly constrained in the sense that all the information necessary is present in the sentence itself without any other context.", "labels": [], "entities": []}, {"text": "Nevertheless, they vary widely in difficulty.", "labels": [], "entities": []}, {"text": "The first of these examples is relatively simple: the second half of the sentence is a clear description of the type of behavior characterized by the desired adjective.", "labels": [], "entities": []}, {"text": "The second example is more sophisticated; one must infer from.", "labels": [], "entities": []}, {"text": "One of the characters in Milton Murayama's novel is considered because he deliberately defies an oppressive hierarchical society.", "labels": [], "entities": []}, {"text": "the contrast between medicine and poison that the correct answer involves a contrast, either useless vs. effective or curative vs. toxic.", "labels": [], "entities": []}, {"text": "Moreover, the first, incorrect, possibility is perfectly acceptable in the context of the second clause alone; only irrelevance to the contrast between medicine and poison eliminates it.", "labels": [], "entities": []}, {"text": "In general, the questions require a combination of semantic and world knowledge as well as occasional logical reasoning.", "labels": [], "entities": []}, {"text": "We study the sentence completion task because we believe it is complex enough to pose a significant challenge, yet structured enough that progress maybe possible.", "labels": [], "entities": [{"text": "sentence completion task", "start_pos": 13, "end_pos": 37, "type": "TASK", "confidence": 0.8063129385312399}]}, {"text": "As a first step, we have approached the problem from two points-of-view: first by exploiting local sentence structure, and secondly by measuring a novel form of global sentence coherence based on latent semantic analysis.", "labels": [], "entities": []}, {"text": "To investigate the usefulness of local information, we evaluated n-gram language model scores, from both a conventional model with Good-Turing smoothing, and with a recently proposed maximum-entropy class-based ngram model.", "labels": [], "entities": []}, {"text": "Also in the language modeling vein, but with potentially global context, we evaluate the use of a recurrent neural network language model.", "labels": [], "entities": [{"text": "language modeling", "start_pos": 12, "end_pos": 29, "type": "TASK", "confidence": 0.7075246274471283}]}, {"text": "In all the language modeling approaches, a model is used to compute a sentence probability with each of the potential completions.", "labels": [], "entities": []}, {"text": "To measure global coherence, we propose a novel method based on latent semantic analysis (LSA).", "labels": [], "entities": [{"text": "latent semantic analysis (LSA)", "start_pos": 64, "end_pos": 94, "type": "TASK", "confidence": 0.7050531208515167}]}, {"text": "We find that the LSA based method performs best, and that both local and global information can be combined to exceed 50% accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 122, "end_pos": 130, "type": "METRIC", "confidence": 0.9981422424316406}]}, {"text": "We report results on a set of questions taken from a collection of SAT practice exams, and further validate the methods with the recently proposed MSR Sentence Completion Challenge set (.", "labels": [], "entities": [{"text": "MSR Sentence Completion Challenge set", "start_pos": 147, "end_pos": 184, "type": "DATASET", "confidence": 0.7271778225898743}]}, {"text": "Our paper thus makes the following contributions: First, we present the first published results on the SAT sentence completion task.", "labels": [], "entities": [{"text": "SAT sentence completion task", "start_pos": 103, "end_pos": 131, "type": "TASK", "confidence": 0.7571940198540688}]}, {"text": "Secondly, we evaluate the effectiveness of both local n-gram information, and global coherence in the form of a novel LSA-based metric.", "labels": [], "entities": []}, {"text": "Finally, we illustrate that the local and global information can be effectively fused.", "labels": [], "entities": []}, {"text": "The remainder of this paper is organized as follows.", "labels": [], "entities": []}, {"text": "In Section 2 we discuss related work.", "labels": [], "entities": []}, {"text": "Section 3 describes the language modeling methods we have evaluated.", "labels": [], "entities": [{"text": "language modeling", "start_pos": 24, "end_pos": 41, "type": "TASK", "confidence": 0.6947459280490875}]}, {"text": "Section 4 outlines the LSA-based methods.", "labels": [], "entities": [{"text": "LSA-based", "start_pos": 23, "end_pos": 32, "type": "TASK", "confidence": 0.8467170000076294}]}, {"text": "Section 5 presents our experimental results.", "labels": [], "entities": []}, {"text": "We conclude with a discussion in Section 6.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Effectiveness of different types of training data.", "labels": [], "entities": []}, {"text": " Table 2: Performance of language modeling methods on  SAT questions.", "labels": [], "entities": []}, {"text": " Table 3: Performance of language modeling methods us- ing identical training data and vocabularies.", "labels": [], "entities": []}, {"text": " Table 4: SAT performance of LSA based methods.", "labels": [], "entities": []}, {"text": " Table 5: SAT test set accuracy with combined methods.", "labels": [], "entities": [{"text": "SAT test set", "start_pos": 10, "end_pos": 22, "type": "DATASET", "confidence": 0.6969980994860331}, {"text": "accuracy", "start_pos": 23, "end_pos": 31, "type": "METRIC", "confidence": 0.7977427244186401}]}, {"text": " Table 6: Performance of methods on the MSR Sentence  Completion Challenge, contrasted with SAT test set.", "labels": [], "entities": [{"text": "MSR Sentence  Completion Challenge", "start_pos": 40, "end_pos": 74, "type": "TASK", "confidence": 0.8648184537887573}, {"text": "SAT test set", "start_pos": 92, "end_pos": 104, "type": "DATASET", "confidence": 0.8664009173711141}]}]}