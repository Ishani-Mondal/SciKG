{"title": [{"text": "Discriminative Pronunciation Modeling: A Large-Margin, Feature-Rich Approach", "labels": [], "entities": [{"text": "Discriminative Pronunciation Modeling", "start_pos": 0, "end_pos": 37, "type": "TASK", "confidence": 0.6236922740936279}]}], "abstractContent": [{"text": "We address the problem of learning the mapping between words and their possible pronunciations in terms of sub-word units.", "labels": [], "entities": []}, {"text": "Most previous approaches have involved genera-tive modeling of the distribution of pronunciations , usually trained to maximize likelihood.", "labels": [], "entities": []}, {"text": "We propose a discriminative, feature-rich approach using large-margin learning.", "labels": [], "entities": []}, {"text": "This approach allows us to optimize an objective closely related to a discriminative task, to incorporate a large number of complex features , and still do inference efficiently.", "labels": [], "entities": []}, {"text": "We test the approach on the task of lexical access; that is, the prediction of a word given a pho-netic transcription.", "labels": [], "entities": []}, {"text": "In experiments on a subset of the Switchboard conversational speech corpus, our models thus far improve classification error rates from a previously published result of 29.1% to about 15%.", "labels": [], "entities": [{"text": "Switchboard conversational speech corpus", "start_pos": 34, "end_pos": 74, "type": "DATASET", "confidence": 0.6443545445799828}, {"text": "classification error rates", "start_pos": 104, "end_pos": 130, "type": "METRIC", "confidence": 0.7743355929851532}]}, {"text": "We find that large-margin approaches outperform conditional random field learning, and that the Passive-Aggressive algorithm for large-margin learning is faster to converge than the Pegasos algorithm.", "labels": [], "entities": []}], "introductionContent": [{"text": "One of the problems faced by automatic speech recognition, especially of conversational speech, is that of modeling the mapping between words and their possible pronunciations in terms of sub-word units such as phones.", "labels": [], "entities": [{"text": "automatic speech recognition", "start_pos": 29, "end_pos": 57, "type": "TASK", "confidence": 0.7061407367388407}]}, {"text": "While pronouncing dictionaries provide each word's canonical pronunciation(s) in terms of phoneme strings, running speech often includes pronunciations that differ greatly from the dictionary.", "labels": [], "entities": []}, {"text": "For example, some pronunciations of \"probably\" in the Switchboard conversational speech database are [p r aa b iy], [p r aa l iy], [p r ay], and [p ow ih] (.", "labels": [], "entities": [{"text": "Switchboard conversational speech database", "start_pos": 54, "end_pos": 96, "type": "DATASET", "confidence": 0.8004516512155533}]}, {"text": "While some words (e.g., common words) are more prone to such variation than others, the effect is extremely general: In the phonetically transcribed portion of Switchboard, fewer than half of the word tokens are pronounced canonically).", "labels": [], "entities": []}, {"text": "In addition, pronunciation variants sometimes include sounds not present in the dictionary at all, such as nasalized vowels (\"can't\" \u2192 [k ae n n t]) or fricatives introduced due to incomplete consonant closures (\"legal\" \u2192 [l iy g fr ix l]).", "labels": [], "entities": []}, {"text": "This variation makes pronunciation modeling one of the major challenges facing speech recognition).", "labels": [], "entities": [{"text": "pronunciation modeling", "start_pos": 21, "end_pos": 43, "type": "TASK", "confidence": 0.9161222875118256}, {"text": "speech recognition", "start_pos": 79, "end_pos": 97, "type": "TASK", "confidence": 0.745465874671936}]}, {"text": "Most efforts to address the problem have involved either learning alternative pronunciations and/or their probabilities) or using phonetic transformation (substitution, insertion, and deletion) rules, which can come from linguistic knowledge or be learned from data ().", "labels": [], "entities": [{"text": "phonetic transformation (substitution, insertion, and deletion)", "start_pos": 130, "end_pos": 193, "type": "TASK", "confidence": 0.8239471226930618}]}, {"text": "These have produced some improvements in recognition performance.", "labels": [], "entities": [{"text": "recognition", "start_pos": 41, "end_pos": 52, "type": "TASK", "confidence": 0.9478973150253296}]}, {"text": "However, they also tend to cause additional confusability due to the introduction of additional homonyms).", "labels": [], "entities": []}, {"text": "Some other alternatives are articulatory pronunciation models, in which words are represented as multiple parallel sequences of articulatory features rather than single sequences of phones, and which outperform phone-based models on some tasks (); and models for learning edit distances between dictionary and actual pronunciations ().", "labels": [], "entities": [{"text": "learning edit distances between dictionary and actual pronunciations", "start_pos": 263, "end_pos": 331, "type": "TASK", "confidence": 0.6570919267833233}]}, {"text": "All of these approaches are generative-i.e., they provide distributions over possible pronunciations given the canonical one(s)-and they are typically trained by maximizing the likelihood over training data.", "labels": [], "entities": []}, {"text": "In some recent work, discriminative approaches have been proposed, in which an objective more closely related to the task at hand is optimized.", "labels": [], "entities": []}, {"text": "For example, () optimize a minimum classification error (MCE) criterion to learn the weights (equivalently, probabilities) of alternative pronunciations for each word;) use a similar approach with discriminative model combination.", "labels": [], "entities": [{"text": "minimum classification error (MCE) criterion", "start_pos": 27, "end_pos": 71, "type": "METRIC", "confidence": 0.7862253614834377}]}, {"text": "In this work, the weighted alternatives are then used in a standard (generative) speech recognizer.", "labels": [], "entities": [{"text": "generative) speech recognizer", "start_pos": 69, "end_pos": 98, "type": "TASK", "confidence": 0.8310388028621674}]}, {"text": "In other words, these approaches optimize generative models using discriminative criteria.", "labels": [], "entities": []}, {"text": "We propose a general, flexible discriminative approach to pronunciation modeling, rather than discriminatively optimizing a generative model.", "labels": [], "entities": [{"text": "pronunciation modeling", "start_pos": 58, "end_pos": 80, "type": "TASK", "confidence": 0.9561884701251984}]}, {"text": "We formulate a linear model with a large number of word-level and subword-level feature functions, whose weights are learned by optimizing a discriminative criterion.", "labels": [], "entities": []}, {"text": "The approach is related to the recently proposed segmental conditional random field (SCRF) approach to speech recognition).", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 103, "end_pos": 121, "type": "TASK", "confidence": 0.8219569623470306}]}, {"text": "The main differences are that we optimize large-margin objective functions, which lead to sparser, faster, and better-performing models than conditional random field optimization in our experiments; and we use a large set of different feature functions tailored to pronunciation modeling.", "labels": [], "entities": [{"text": "pronunciation modeling", "start_pos": 265, "end_pos": 287, "type": "TASK", "confidence": 0.9094630777835846}]}, {"text": "In order to focus attention on the pronunciation model alone, our experiments focus on a task that measures only the mapping between words and subword units.", "labels": [], "entities": []}, {"text": "Pronunciation models have in the past been tested using a variety of measures.", "labels": [], "entities": []}, {"text": "For generative models, phonetic error rate of generated pronunciations) and phone-or frame-level perplexity () are appropriate measures.", "labels": [], "entities": [{"text": "phonetic error rate", "start_pos": 23, "end_pos": 42, "type": "METRIC", "confidence": 0.6074567834536234}]}, {"text": "For our discriminative models, we consider the task of lexical access; that is, prediction of a single word given its pronunciation in terms of sub-word units ().", "labels": [], "entities": [{"text": "prediction of a single word", "start_pos": 80, "end_pos": 107, "type": "TASK", "confidence": 0.8469480752944947}]}, {"text": "This task is also sometimes referred to as \"pronunciation recognition\" ( or \"pronunciation classification\").)", "labels": [], "entities": [{"text": "pronunciation recognition", "start_pos": 44, "end_pos": 69, "type": "TASK", "confidence": 0.8913708627223969}, {"text": "pronunciation classification\").)", "start_pos": 77, "end_pos": 109, "type": "TASK", "confidence": 0.8404147227605184}]}, {"text": "As we show below, our approach outperforms both traditional phonetic rule-based models and the best previously published results on our data set obtained with generative articulatory approaches.", "labels": [], "entities": []}], "datasetContent": [{"text": "All experiments are conducted on a subset of the Switchboard conversational speech corpus that has been labeled at a fine phonetic level (; these phonetic transcriptions are the input to our lexical access models.", "labels": [], "entities": [{"text": "Switchboard conversational speech corpus", "start_pos": 49, "end_pos": 89, "type": "DATASET", "confidence": 0.7779132127761841}]}, {"text": "The data subset, phone set P, and dictionary are the same as ones previously used in ().", "labels": [], "entities": []}, {"text": "The dictionary contains 3328 words, consisting of the 5000 most frequent words in Switchboard, excluding ones with fewer than four phones in their baseforms.", "labels": [], "entities": [{"text": "Switchboard", "start_pos": 82, "end_pos": 93, "type": "DATASET", "confidence": 0.9247563481330872}]}, {"text": "The baseforms use a similar, slightly smaller phone set (lacking, e.g., nasalization).", "labels": [], "entities": []}, {"text": "We measure performance by error rate (ER), the proportion of test examples predicted incorrectly.", "labels": [], "entities": [{"text": "error rate (ER)", "start_pos": 26, "end_pos": 41, "type": "METRIC", "confidence": 0.9773189783096313}]}, {"text": "The TF-IDF features used in the experiments are based on phone bigrams.", "labels": [], "entities": []}, {"text": "For all of the articulatory DBN features, we use the DBN from () (the one in) is more sophisticated and maybe used in future work).", "labels": [], "entities": []}, {"text": "For the asynchrony features, the articulatory pairs are (F 1 , F 2 ) \u2208 {({tongue tip}, {tongue body}), ({lip opening}, {tongue tip, tongue body}), and ({lip opening, tongue tip, tongue body}, {glottis, velum})}, as in (.", "labels": [], "entities": []}, {"text": "The parameters (a, b) of the length and asynchrony features are drawn from (a, b) \u2208 {(\u22123, \u22122), (\u22122, \u22121), . .", "labels": [], "entities": []}, {"text": "(2, 3)}.", "labels": [], "entities": []}, {"text": "We compare the CRF 4 , Passive-Aggressive (PA), and Pegasos learning algorithms.", "labels": [], "entities": []}, {"text": "The regularization parameter \u03bb is tuned on the development set.", "labels": [], "entities": []}, {"text": "We run all three algorithms for multiple epochs and pick the best epoch based on development set performance.", "labels": [], "entities": []}, {"text": "For the first set of experiments, we use the same division of the corpus as in () into a 2492-word training set, a 165-word development set, and a 236-word test set.", "labels": [], "entities": []}, {"text": "To give a sense of the difficulty of the task, we test two simple baselines.", "labels": [], "entities": []}, {"text": "One is a lexicon lookup: If the surface form is found in the dictionary, predict the corresponding word; otherwise, guess randomly.", "labels": [], "entities": []}, {"text": "For a second baseline, we calculate the Levenshtein (0-1 edit) distance between the input pronunciation and each dictionary baseform, and predict the word corresponding to the baseform closest to the input.", "labels": [], "entities": [{"text": "Levenshtein (0-1 edit) distance", "start_pos": 40, "end_pos": 71, "type": "METRIC", "confidence": 0.9465854267279307}]}, {"text": "The results are shown in the first two rows of  icantly.", "labels": [], "entities": []}, {"text": "However, both baselines do quite poorly.", "labels": [], "entities": []}, {"text": "shows the best previous result on this data set from the articulatory model of Jyothi et al., which greatly improves over our baselines as well as over a much more complex phone-based model).", "labels": [], "entities": []}, {"text": "The remaining rows of give results with our feature functions and various learning algorithms.", "labels": [], "entities": []}, {"text": "The best result for PA/DP+ (the PA algorithm using all features besides the DBN features) on the development set is with \u03bb = 100 and 5 epochs.", "labels": [], "entities": []}, {"text": "Tested on the test set, this model improves over) by 13.9% absolute (47.8% relative).", "labels": [], "entities": []}, {"text": "The best result for Pegasos with the same features on the development set is with \u03bb = 0.01 and 10 epochs.", "labels": [], "entities": []}, {"text": "On the test set, this model gives a 14.3% absolute improvement (49.1% relative).", "labels": [], "entities": []}, {"text": "CRF learning with the same features performs about 6% worse than the corresponding PA and Pegasos models.", "labels": [], "entities": []}, {"text": "The single-threaded running time for PA/DP+ and Pegasos/DP+ is about 40 minutes per epoch, measured on a dual-core AMD 2.4GHz CPU with 8GB of memory; for CRF, it takes about 100 minutes for each epoch, which is almost entirely because the weight vector \u03b8 is less sparse with CRF learning.", "labels": [], "entities": [{"text": "CRF", "start_pos": 154, "end_pos": 157, "type": "TASK", "confidence": 0.935430109500885}]}, {"text": "In the PA and Pegasos algorithms, we only update \u03b8 for the most confusable word, while in CRF learning, we sum overall words.", "labels": [], "entities": []}, {"text": "In our case, the number of non-zero entries in \u03b8 for PA and Pegasos is around 800,000; for CRF, it is over 4,000,000.", "labels": [], "entities": [{"text": "Pegasos", "start_pos": 60, "end_pos": 67, "type": "DATASET", "confidence": 0.7895106673240662}, {"text": "CRF", "start_pos": 91, "end_pos": 94, "type": "DATASET", "confidence": 0.7691872119903564}]}, {"text": "Though PA and Pegasos take roughly the same amount of time per epoch, Pegasos tends to require more epochs to achieve the same performance as PA.", "labels": [], "entities": []}, {"text": "For the second experiment, we perform 5-fold cross-validation.", "labels": [], "entities": []}, {"text": "We combine the training, development, and test sets from the previous experiment, and divide the data into five folds.", "labels": [], "entities": []}, {"text": "We take three folds for training, one fold for tuning \u03bb and the best epoch, and the remaining fold for testing.", "labels": [], "entities": []}, {"text": "The results on the test fold are shown in, which compares the learning algorithms, and, which compares feature sets.", "labels": [], "entities": []}, {"text": "Overall, the results are consistent with our first experiment.", "labels": [], "entities": []}, {"text": "The feature selection experiments in shows that the TF-IDF features alone are quite weak, while the dynamic programming alignment features alone are quite good.", "labels": [], "entities": []}, {"text": "Combining the two gives close to our best result.", "labels": [], "entities": []}, {"text": "Although the marginal improvement gets smaller as we add more features, in general performance keeps improving the more features we add.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2. We can see that, by adding just  the Levenshtein distance, the error rate drops signif-Model  ER  lexicon lookup (from (Livescu, 2005)) 59.3%  lexicon + Levenshtein distance  41.8%  (Jyothi et al., 2011)  29.1%  CRF/DP+  21.5%  PA/DP+  15.2%  Pegasos/DP+  14.8%  PA/ALL  15.2%", "labels": [], "entities": [{"text": "error rate", "start_pos": 73, "end_pos": 83, "type": "METRIC", "confidence": 0.9695092439651489}, {"text": "PA", "start_pos": 273, "end_pos": 275, "type": "METRIC", "confidence": 0.7573317885398865}]}]}