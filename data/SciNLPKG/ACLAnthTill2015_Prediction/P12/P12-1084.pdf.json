{"title": [{"text": "Collective Classification for Fine-grained Information Status", "labels": [], "entities": []}], "abstractContent": [{"text": "Previous work on classifying information status (Nissim, 2006; Rahman and Ng, 2011) is restricted to coarse-grained classification and focuses on conversational dialogue.", "labels": [], "entities": [{"text": "classifying information status", "start_pos": 17, "end_pos": 47, "type": "TASK", "confidence": 0.8846886356671652}]}, {"text": "We here introduce the task of classifying fine-grained information status and work on written text.", "labels": [], "entities": [{"text": "classifying fine-grained information status", "start_pos": 30, "end_pos": 73, "type": "TASK", "confidence": 0.874180868268013}]}, {"text": "We add a fine-grained information status layer to the Wall Street Journal portion of the OntoNotes corpus.", "labels": [], "entities": [{"text": "Wall Street Journal portion", "start_pos": 54, "end_pos": 81, "type": "DATASET", "confidence": 0.9711201786994934}, {"text": "OntoNotes corpus", "start_pos": 89, "end_pos": 105, "type": "DATASET", "confidence": 0.8896359205245972}]}, {"text": "We claim that the information status of a mention depends not only on the mention itself but also on other mentions in the vicinity and solve the task by collectively classifying the information status of all mentions.", "labels": [], "entities": []}, {"text": "Our approach strongly outper-forms reimplementations of previous work.", "labels": [], "entities": []}], "introductionContent": [{"text": "Speakers present already known and yet to be established information according to principles referred to as information structure, inter alia).", "labels": [], "entities": []}, {"text": "While information structure affects all kinds of constituents in a sentence, we here adopt the more restricted notion of information status which concerns only discourse entities realized as noun phrases, i.e. mentions . Information status (IS henceforth) describes the degree to which a discourse entity is available to the hearer with regard to the speaker's assumptions about the hearer's knowledge and beliefs).", "labels": [], "entities": []}, {"text": "Old mentions are known to the hearer and have been referred to previously.", "labels": [], "entities": []}, {"text": "Mediated mentions have not been mentioned before but are also not autonomous, i.e., they can only be correctly interpreted by reference to another mention or to prior world knowledge.", "labels": [], "entities": []}, {"text": "All other mentions are new.", "labels": [], "entities": []}, {"text": "IS can be beneficial fora number of NLP tasks, though the results have been mixed.", "labels": [], "entities": [{"text": "IS", "start_pos": 0, "end_pos": 2, "type": "TASK", "confidence": 0.9513854384422302}]}, {"text": "used IS as a feature for generating pitch accent in conversational speech.", "labels": [], "entities": [{"text": "IS", "start_pos": 5, "end_pos": 7, "type": "METRIC", "confidence": 0.6714185476303101}]}, {"text": "As IS is restricted to noun phrases, while pitch accent can be assigned to any word in an utterance, the experiments were not conclusive.", "labels": [], "entities": [{"text": "IS", "start_pos": 3, "end_pos": 5, "type": "TASK", "confidence": 0.9072896838188171}]}, {"text": "For determining constituent order of German sentences, incorporate features modeling IS to good effect.", "labels": [], "entities": [{"text": "determining constituent order of German sentences", "start_pos": 4, "end_pos": 53, "type": "TASK", "confidence": 0.7191669642925262}]}, {"text": "showed that IS is a useful feature for coreference resolution.", "labels": [], "entities": [{"text": "IS", "start_pos": 12, "end_pos": 14, "type": "TASK", "confidence": 0.8286057114601135}, {"text": "coreference resolution", "start_pos": 39, "end_pos": 61, "type": "TASK", "confidence": 0.9780261814594269}]}, {"text": "Previous work on learning IS) is restricted in several ways.", "labels": [], "entities": []}, {"text": "It deals with conversational dialogue, in particular with the corpus annotated by.", "labels": [], "entities": []}, {"text": "However, many applications that can profit from IS concentrate on written texts, such as summarization.", "labels": [], "entities": [{"text": "IS", "start_pos": 48, "end_pos": 50, "type": "TASK", "confidence": 0.9671933054924011}, {"text": "summarization", "start_pos": 89, "end_pos": 102, "type": "TASK", "confidence": 0.9813651442527771}]}, {"text": "For example, show that solving the IS subproblem of whether a person proper name is already known to the reader improves automatic summarization of news.", "labels": [], "entities": [{"text": "IS subproblem of whether a person proper name is already known", "start_pos": 35, "end_pos": 97, "type": "TASK", "confidence": 0.7868220806121826}, {"text": "summarization of news", "start_pos": 131, "end_pos": 152, "type": "TASK", "confidence": 0.8865307569503784}]}, {"text": "Therefore, we here model IS in written text, creating anew dataset which adds an IS layer to the already existing comprehensive annotation in the OntoNotes corpus).", "labels": [], "entities": [{"text": "OntoNotes corpus", "start_pos": 146, "end_pos": 162, "type": "DATASET", "confidence": 0.921095460653305}]}, {"text": "We also report the first results on fine-grained IS classification by modelling further distinctions within the category of mediated mentions, such as comparative and bridging anaphora (see Examples 1 and 2, re-spectively).", "labels": [], "entities": [{"text": "IS classification", "start_pos": 49, "end_pos": 66, "type": "TASK", "confidence": 0.91492560505867}]}, {"text": "Fine-grained IS is a prerequisite to full bridging/comparative anaphora resolution, and therefore necessary to fill gaps in entity grids) based on coreference only.", "labels": [], "entities": [{"text": "comparative anaphora resolution", "start_pos": 51, "end_pos": 82, "type": "TASK", "confidence": 0.6178116202354431}]}, {"text": "Thus, Examples 1 and 2 do not exhibit any coreferential entity coherence but coherence can be established when the comparative anaphor others is resolved to others than freeway survivor Buck Helm, and the bridging anaphor the streets is resolved to the streets of Oranjemund, respectively.", "labels": [], "entities": []}, {"text": "(1) the condition of freeway survivor Buck Helm . .", "labels": [], "entities": [{"text": "freeway survivor Buck Helm", "start_pos": 21, "end_pos": 47, "type": "DATASET", "confidence": 0.63552675396204}]}, {"text": ", improved, hospital officials said.", "labels": [], "entities": []}, {"text": "Rescue crews, however, gave up hope that others would be found.", "labels": [], "entities": []}], "datasetContent": [{"text": "We use our gold standard corpus (see Section 3.3) via 10-fold cross-validation on documents for all experiments.", "labels": [], "entities": [{"text": "gold standard corpus", "start_pos": 11, "end_pos": 31, "type": "DATASET", "confidence": 0.6876555780569712}]}, {"text": "Following Nissim (2006) and Rahman and Ng (2011), we perform all experiments on gold standard mentions and use the human WSJ syntactic annotation for feature extraction, when necessary.", "labels": [], "entities": [{"text": "feature extraction", "start_pos": 150, "end_pos": 168, "type": "TASK", "confidence": 0.6741390228271484}]}, {"text": "For the extraction of semantic class, we use OntoNotes entity type annotation for proper names and an automatic assignment of semantic class via WordNet hypernyms for common nouns.", "labels": [], "entities": []}, {"text": "Coarse-grained versions of all algorithms distinguish only between the three old, mediated, new categories.", "labels": [], "entities": []}, {"text": "Fine-grained versions distinguish between the categories old, the six mediated subtypes, and new.", "labels": [], "entities": []}, {"text": "We report overall accuracy as well as precision, recall and F-measure per category.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 18, "end_pos": 26, "type": "METRIC", "confidence": 0.9986636638641357}, {"text": "precision", "start_pos": 38, "end_pos": 47, "type": "METRIC", "confidence": 0.9998051524162292}, {"text": "recall", "start_pos": 49, "end_pos": 55, "type": "METRIC", "confidence": 0.9997383952140808}, {"text": "F-measure", "start_pos": 60, "end_pos": 69, "type": "METRIC", "confidence": 0.9987651109695435}]}, {"text": "Significance tests are conducted using McNemar's test on overall algorithm accuracy, at the level of 1%.", "labels": [], "entities": [{"text": "McNemar's test", "start_pos": 39, "end_pos": 53, "type": "DATASET", "confidence": 0.8263500332832336}, {"text": "accuracy", "start_pos": 75, "end_pos": 83, "type": "METRIC", "confidence": 0.980952799320221}]}], "tableCaptions": [{"text": " Table 2: Agreement Results for individual categories", "labels": [], "entities": [{"text": "Agreement", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9956511855125427}]}, {"text": " Table 3: Gold Standard Distribution", "labels": [], "entities": [{"text": "Gold Standard", "start_pos": 10, "end_pos": 23, "type": "DATASET", "confidence": 0.9534830451011658}]}, {"text": " Table 6: Precedence relations in our corpus", "labels": [], "entities": []}, {"text": " Table 7: Collective classification compared to Nissim's local classifier. Best performing algorithms are bolded.", "labels": [], "entities": [{"text": "Collective classification", "start_pos": 10, "end_pos": 35, "type": "TASK", "confidence": 0.7807277739048004}]}, {"text": " Table 8: Collective classification compared to Rahman and Ng's local classifier. Best performing algorithms are  bolded.", "labels": [], "entities": [{"text": "Collective classification", "start_pos": 10, "end_pos": 35, "type": "TASK", "confidence": 0.7199426889419556}]}]}