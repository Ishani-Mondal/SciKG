{"title": [{"text": "Unsupervized Word Segmentation: the case for Mandarin Chinese", "labels": [], "entities": [{"text": "Unsupervized Word Segmentation", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.6161332726478577}]}], "abstractContent": [{"text": "In this paper, we present an unsupervized seg-mentation system tested on Mandarin Chi-nese.", "labels": [], "entities": []}, {"text": "Following Harris's Hypothesis in Kempe (1999) and Tanaka-Ishii's (2005) reformulation, we base our work on the Variation of Branching Entropy.", "labels": [], "entities": []}, {"text": "We improve on (Jin and Tanaka-Ishii, 2006) by adding normalization and viterbi-decoding.", "labels": [], "entities": []}, {"text": "This enable us to remove most of the thresholds and parameters from their model and to reach near state-of-the-art results (Wang et al., 2011) with a simpler system.", "labels": [], "entities": []}, {"text": "We provide evaluation on different corpora available from the Segmentation bake-off II (Emerson, 2005) and define a more precise topline for the task using cross-trained supervized system available off-the-shelf (Zhang and Clark, 2010; Zhao and Kit, 2008; Huang and Zhao, 2007)", "labels": [], "entities": [{"text": "Segmentation bake-off II", "start_pos": 62, "end_pos": 86, "type": "TASK", "confidence": 0.8302093744277954}]}], "introductionContent": [{"text": "The Chinese script has no explicit \"word\" boundaries.", "labels": [], "entities": []}, {"text": "Therefore, tokenization itself, although the very first step of many text processing systems, is a challenging task.", "labels": [], "entities": [{"text": "tokenization", "start_pos": 11, "end_pos": 23, "type": "TASK", "confidence": 0.9780750274658203}]}, {"text": "Supervized segmentation systems exist but rely on manually segmented corpora, which are often specific to a genre or a domain and use many different segmentation guidelines.", "labels": [], "entities": []}, {"text": "In order to deal with a larger variety of genres and domains, or to tackle more theoretic questions about linguistic units, unsupervized segmentation is still an important issue.", "labels": [], "entities": []}, {"text": "After a short review of the corresponding literature in Section 2, we discuss the challenging issue of evaluating unsupervized word segmentation systems in Section 3.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 127, "end_pos": 144, "type": "TASK", "confidence": 0.7394407689571381}]}, {"text": "Section 4 and Section 5 present the core of our system.", "labels": [], "entities": []}, {"text": "Finally, in Section 6, we detail and discuss our results.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this paper, in order to be comparable with, we evaluate our system against the corpora from the Second International Chinese Word Segmentation Bakeoff ().", "labels": [], "entities": [{"text": "Second International Chinese Word Segmentation Bakeoff", "start_pos": 99, "end_pos": 153, "type": "DATASET", "confidence": 0.748248279094696}]}, {"text": "These corpora cover 4 different segmentation guidelines from various origins: Academia Sinica (AS), City-University of Hong-Kong (CITYU), Microsoft Research (MSR) and Peking University (PKU).", "labels": [], "entities": []}, {"text": "Evaluating unsupervized systems is a challenge by itself.", "labels": [], "entities": []}, {"text": "As an agreement on the exact definition of what a word is remains hard to reach, various segmentation guidelines have been proposed and followed for the annotation of different corpora.", "labels": [], "entities": []}, {"text": "The evaluation of supervized systems can be achieved on any corpus using any guidelines: when trained on data that follows particular guidelines, the resulting system will follow as well as possible these guidelines, and can be evaluated on data annotated accordingly.", "labels": [], "entities": []}, {"text": "However, for unsupervized systems, there is no reason why a system should be closer to one reference than another or even not to lie somewhere in between the different existing guidelines.", "labels": [], "entities": []}, {"text": "propose to use cross-training of a supervized segmentation system in order to have an estimation of the consistency between different segmentation guidelines, and therefore an upper bound of what can be expected from an unsupervized system (.", "labels": [], "entities": []}, {"text": "The average consistency is found to be as low as 0.85 (f-score).", "labels": [], "entities": [{"text": "consistency", "start_pos": 12, "end_pos": 23, "type": "METRIC", "confidence": 0.9642884135246277}, {"text": "f-score", "start_pos": 55, "end_pos": 62, "type": "METRIC", "confidence": 0.984430730342865}]}, {"text": "Therefore this figure can be considered as a sensible topline for unsupervized systems.", "labels": [], "entities": []}, {"text": "The standard baseline which consists in segmenting each character leads to a baseline around 0.35 (f-score) -almost half of the tokens in a manually segmented corpus are unigrams.", "labels": [], "entities": [{"text": "f-score)", "start_pos": 99, "end_pos": 107, "type": "METRIC", "confidence": 0.965325266122818}]}, {"text": "Per word-length evaluation is also important as units of various lengths tend to have different distributions.", "labels": [], "entities": []}, {"text": "We used ZPAR () on the four corpora from the Second Bakeoff to reproduce experiments, but also to measure cross-corpus consistency at a per-wordlength level.", "labels": [], "entities": [{"text": "ZPAR", "start_pos": 8, "end_pos": 12, "type": "METRIC", "confidence": 0.8277060389518738}]}, {"text": "Our overall results are comparable to what report.", "labels": [], "entities": []}, {"text": "However, the consistency is quickly falling for longer words: on unigrams, f-scores range from 0.81 to 0.90 (the same as the overall results).", "labels": [], "entities": [{"text": "consistency", "start_pos": 13, "end_pos": 24, "type": "METRIC", "confidence": 0.9989644289016724}]}, {"text": "We get slightly higher figures on bigrams (0.85-0.92) but much lower on trigrams with only 0.59-0.79.", "labels": [], "entities": []}, {"text": "Ina segmented Chinese text, most of the tokens are uni-and bigrams but most of the types are bi-and trigrams (as unigrams are often high frequency grammatical words and trigrams the result of more or less productive affixations).", "labels": [], "entities": []}, {"text": "Therefore the results of evaluations only based on tokens do not suffer much from poor performances on trigrams even if a large part of the lexicon maybe incorrectly processed.", "labels": [], "entities": []}, {"text": "Another issue about the evaluation and comparison of unsupervized systems is to try and remain fair in terms of preprocessing and prior knowledge given to the systems.", "labels": [], "entities": []}, {"text": "For example, used different levels of preprocessing (which they call \"settings\").", "labels": [], "entities": []}, {"text": "In their settings 1 and 2, try not to rely on punctuation and character encoding information (such as distinguishing Latin and Chinese characters).", "labels": [], "entities": []}, {"text": "However, they optimize their parameter for each setting.", "labels": [], "entities": []}, {"text": "We therefore consider that their system does take into account the level of processing which is performed on Latin characters and Arabic numbers, and therefore \"knows\" whether to expect such characters or not.", "labels": [], "entities": []}, {"text": "In setting 3 they add the knowledge of punctuation as clear boundaries and insetting 4 they preprocess Arabic and Latin and obtain better, more consistent and less questionable results.", "labels": [], "entities": []}, {"text": "As we are more interested in reducing the amount of human labor needed than in achieving by all means fully unsupervized learning, we do not refrain from performing basic and straightforward preprocessing such as detection of punctuation marks, Latin characters and Arabic numbers.", "labels": [], "entities": []}, {"text": "2 Therefore, our experiments rely on settings similar to their settings 3 and 4, and are evaluated against the same corpora.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Evaluation on the Second Bakeoff data with  Wang et al.'s (2011) settings. \"Worst\" and \"best\" give the  range of the reported results with differents values of the  parameter in Wang et al.'s system. VBE > 0 correspond  to a cut whenever BE is raising. nVBE corresponds to our  proposal, based on normalized VBE with maximization at  word boundaries. Recall that the topline is around 0.85", "labels": [], "entities": [{"text": "BE", "start_pos": 248, "end_pos": 250, "type": "METRIC", "confidence": 0.9890727400779724}]}, {"text": " Table 2: Per word-length details of our results with our  nVBE algorithm and setting 4. Recall that the toplines  are respectively 0.85, 0.81, 0.85 and 0.59 (see Section 3)", "labels": [], "entities": []}]}