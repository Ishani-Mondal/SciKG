{"title": [{"text": "DOMCAT: A Bilingual Concordancer for Domain-Specific Computer Assisted Translation", "labels": [], "entities": [{"text": "Domain-Specific Computer Assisted Translation", "start_pos": 37, "end_pos": 82, "type": "TASK", "confidence": 0.7167278677225113}]}], "abstractContent": [{"text": "In this paper, we propose a web-based bilingual concordancer, DOMCAT 1 , for domain-specific computer assisted translation.", "labels": [], "entities": [{"text": "domain-specific computer assisted translation", "start_pos": 77, "end_pos": 122, "type": "TASK", "confidence": 0.5897989943623543}]}, {"text": "Given a multi-word expression as a query, the system involves retrieving sentence pairs from a bilingual corpus, identifying translation equivalents of the query in the sentence pairs (translation spotting) and ranking the retrieved sentence pairs according to the relevance between the query and the translation equivalents.", "labels": [], "entities": []}, {"text": "To provide high-precision translation spotting for domain-specific translation tasks, we exploited a normalized correlation method to spot the translation equivalents.", "labels": [], "entities": [{"text": "translation spotting", "start_pos": 26, "end_pos": 46, "type": "TASK", "confidence": 0.9395409524440765}]}, {"text": "To ranking the retrieved sentence pairs, we propose a correlation function modified from the Dice coefficient for assessing the correlation between the query and the translation equivalents.", "labels": [], "entities": []}, {"text": "The performances of the translation spotting module and the ranking module are evaluated in terms of precision-recall measures and coverage rate respectively.", "labels": [], "entities": [{"text": "translation spotting", "start_pos": 24, "end_pos": 44, "type": "TASK", "confidence": 0.965696781873703}, {"text": "precision-recall", "start_pos": 101, "end_pos": 117, "type": "METRIC", "confidence": 0.9986108541488647}, {"text": "coverage rate", "start_pos": 131, "end_pos": 144, "type": "METRIC", "confidence": 0.9758528470993042}]}], "introductionContent": [{"text": "A bilingual concordancer is a tool that can retrieve aligned sentence pairs in a parallel corpus whose source sentences contain the query and the translation equivalents of the query are identified in the target sentences.", "labels": [], "entities": []}, {"text": "It helps not only on finding translation equivalents of the query but also presenting various contexts of occurrence.", "labels": [], "entities": []}, {"text": "As a result, it is extremely useful for bilingual http://ckip.iis.sinica.edu.tw/DOMCAT/ lexicographers, human translators and second language learners.", "labels": [], "entities": []}, {"text": "Identifying the translation equivalents, translation spotting, is the most challenging part of a bilingual concordancer.", "labels": [], "entities": [{"text": "translation spotting", "start_pos": 41, "end_pos": 61, "type": "TASK", "confidence": 0.9590778350830078}]}, {"text": "Recently, most of the existing bilingual concordancers spot translation equivalents in terms of word alignment-based method.", "labels": [], "entities": [{"text": "word alignment-based", "start_pos": 96, "end_pos": 116, "type": "TASK", "confidence": 0.723463162779808}]}, {"text": "(. However, word alignment-based translation spotting has some drawbacks.", "labels": [], "entities": [{"text": "word alignment-based translation spotting", "start_pos": 12, "end_pos": 53, "type": "TASK", "confidence": 0.8894115090370178}]}, {"text": "First, aligning a rare (low frequency) term may encounter the garbage collection effect) that cause the term to align to many unrelated words.", "labels": [], "entities": []}, {"text": "Second, the statistical word alignment model is not good at many-to-many alignment due to the fact that translation equivalents are not always correlated in lexical level.", "labels": [], "entities": [{"text": "statistical word alignment", "start_pos": 12, "end_pos": 38, "type": "TASK", "confidence": 0.5918408334255219}]}, {"text": "Unfortunately, the above effects will be intensified in a domain-specific concordancer because the queries are usually domain-specific terms, which are mostly multi-word low-frequency terms and semantically non-compositional terms.", "labels": [], "entities": []}, {"text": "employed a statistical association criterion to spot translation equivalents in their bilingual concordancer.", "labels": [], "entities": []}, {"text": "The associationbased criterion can avoid the above mentioned effects.", "labels": [], "entities": []}, {"text": "However, it has other drawbacks in translation spotting task.", "labels": [], "entities": [{"text": "translation spotting", "start_pos": 35, "end_pos": 55, "type": "TASK", "confidence": 0.9876416325569153}]}, {"text": "First, it will encounter the contextual effect that causes the system incorrectly spot the translations of the strongly collocated context.", "labels": [], "entities": []}, {"text": "Second, the association-based translation spotting tends to spot the common subsequence of a set of similar translations instead of the full translations.", "labels": [], "entities": [{"text": "translation spotting", "start_pos": 30, "end_pos": 50, "type": "TASK", "confidence": 0.8199357688426971}]}, {"text": "illustrates an example of contextual effect, in which 'Fan K'uan' is incorrectly spotted as part of the translation of the query term ' \u8c3f \u5c71 \u884c \u65c5 \u5716 ' (Travelers Among Mountains and Streams), which is the name of the painting painted by 'Fan K'uan/\u8303\u5bec' since the painter's name is strongly collocated with the name of the painting.", "labels": [], "entities": []}, {"text": "Sung , Travelers Among Mountains and Streams , Fan K'uan \u5b8b\u8c3f\u5c71\u884c\u65c5\u5716\u8303\u5bec.", "labels": [], "entities": []}, {"text": "'Fan K'uan' maybe incorrectly spotted as part of the translation of '\u8c3f\u5c71\u884c\u65c5\u5716', if pure association method is applied.", "labels": [], "entities": []}, {"text": "proposed a normalized frequency criterion to extract translation equivalents form sentence aligned parallel corpus.", "labels": [], "entities": []}, {"text": "This criterion takes lexical-level contexture effect into account, so it can effectively resolve the above mentioned effect.", "labels": [], "entities": []}, {"text": "But the goal of their method is to find most common translations instead of spotting translations, so the normalized frequency criterion tends to ignore rare translations.", "labels": [], "entities": []}, {"text": "In this paper, we propose a bilingual concordancer, DOMCAT, for computer assisted domain-specific term translation.", "labels": [], "entities": [{"text": "domain-specific term translation", "start_pos": 82, "end_pos": 114, "type": "TASK", "confidence": 0.625667949517568}]}, {"text": "To remedy the above mentioned effects, we extended the normalized frequency of to a normalized correlation criterion to spot translation equivalents.", "labels": [], "entities": []}, {"text": "The normalized correlation inherits the characteristics of normalized frequency and is adjusted for spotting rare translations.", "labels": [], "entities": [{"text": "spotting rare translations", "start_pos": 100, "end_pos": 126, "type": "TASK", "confidence": 0.8713321288426717}]}, {"text": "These characteristics are especially important fora domain-specific bilingual concordancer to spot translation pairs of low-frequency and semantically non-compositional terms.", "labels": [], "entities": []}, {"text": "The remainder of this paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 describes the DOMCAT system.", "labels": [], "entities": []}, {"text": "In Section 3, we describe the evaluation of the DOMCAT system.", "labels": [], "entities": []}, {"text": "Section 4 contains some concluding remarks.", "labels": [], "entities": []}], "datasetContent": [{"text": "We use the Chinese/English web pages of the National Palace Museum 2 as our underlying parallel corpus.", "labels": [], "entities": [{"text": "Chinese/English web pages of the National Palace Museum 2", "start_pos": 11, "end_pos": 68, "type": "DATASET", "confidence": 0.8327000466260043}]}, {"text": "It contains about 30,000 sentences in each language.", "labels": [], "entities": []}, {"text": "We exploited the Champollion Toolkit () to align the sentence pairs.", "labels": [], "entities": [{"text": "Champollion Toolkit", "start_pos": 17, "end_pos": 36, "type": "DATASET", "confidence": 0.8839351534843445}]}, {"text": "The English sentences are tokenized and lemmatized by using the NLTK () and the Chinese sentences are segmented by the CKIP Chinese segmenter.", "labels": [], "entities": [{"text": "CKIP Chinese segmenter", "start_pos": 119, "end_pos": 141, "type": "DATASET", "confidence": 0.9347289403279623}]}, {"text": "To evaluate the performance of the translation spotting, we selected 12 domain-specific terms to query the concordancer.", "labels": [], "entities": [{"text": "translation spotting", "start_pos": 35, "end_pos": 55, "type": "TASK", "confidence": 0.977442592382431}]}, {"text": "Then, the returned spotted translation equivalents are evaluated against a manually annotated gold standard in terms of recall and precision metrics.", "labels": [], "entities": [{"text": "recall", "start_pos": 120, "end_pos": 126, "type": "METRIC", "confidence": 0.9986914992332458}, {"text": "precision", "start_pos": 131, "end_pos": 140, "type": "METRIC", "confidence": 0.9950095415115356}]}, {"text": "We also build two different translation spotting modules by using the GIZA++ toolkit) with the intersection/union of the bidirectional word alignment as baseline systems.", "labels": [], "entities": [{"text": "translation spotting", "start_pos": 28, "end_pos": 48, "type": "TASK", "confidence": 0.9541938900947571}, {"text": "GIZA++ toolkit", "start_pos": 70, "end_pos": 84, "type": "DATASET", "confidence": 0.8424037098884583}]}, {"text": "To evaluate the performance of the ranking criterion, we compiled a reference translation set for each query by collecting the manually annotated translation spotting set and selecting 1 to 3 frequently used translations.", "labels": [], "entities": []}, {"text": "Then, the outputs of each query are ranked by the nf_dice function and evaluated against the reference translation set.", "labels": [], "entities": []}, {"text": "We also compared the ranking performance with the Dice coefficient.", "labels": [], "entities": [{"text": "Dice coefficient", "start_pos": 50, "end_pos": 66, "type": "METRIC", "confidence": 0.7349314987659454}]}, {"text": "We evaluate the translation spotting in terms of the Recall and Precision metrics defined as follows: shows the evaluation of translation spotting for normalized correlation, NC, compared with the intersection and union of GIZA++ word alignment.", "labels": [], "entities": [{"text": "translation spotting", "start_pos": 16, "end_pos": 36, "type": "TASK", "confidence": 0.90670445561409}, {"text": "Recall", "start_pos": 53, "end_pos": 59, "type": "METRIC", "confidence": 0.9806693196296692}, {"text": "Precision", "start_pos": 64, "end_pos": 73, "type": "METRIC", "confidence": 0.9726709723472595}, {"text": "translation spotting", "start_pos": 126, "end_pos": 146, "type": "TASK", "confidence": 0.8019991219043732}, {"text": "GIZA++ word alignment", "start_pos": 223, "end_pos": 244, "type": "TASK", "confidence": 0.7078641951084137}]}, {"text": "The F-score of the normalized correlation is much higher than that of the word alignment methods.", "labels": [], "entities": [{"text": "F-score", "start_pos": 4, "end_pos": 11, "type": "METRIC", "confidence": 0.9989792108535767}, {"text": "word alignment", "start_pos": 74, "end_pos": 88, "type": "TASK", "confidence": 0.7288702726364136}]}, {"text": "It is noteworthy that the normalized correlation increased the recall rate without losing the precision rate.", "labels": [], "entities": [{"text": "recall rate", "start_pos": 63, "end_pos": 74, "type": "METRIC", "confidence": 0.9855517148971558}, {"text": "precision rate", "start_pos": 94, "end_pos": 108, "type": "METRIC", "confidence": 0.9891518354415894}]}, {"text": "This may indicate that the normalized correlation can effectively conquer the drawbacks of the word alignmentbased translation spotting and the associationbased translation spotting mentioned in Section 1.", "labels": [], "entities": [{"text": "word alignmentbased translation spotting", "start_pos": 95, "end_pos": 135, "type": "TASK", "confidence": 0.550957977771759}, {"text": "associationbased translation spotting", "start_pos": 144, "end_pos": 181, "type": "TASK", "confidence": 0.5721431871255239}]}, {"text": "To evaluate the performance of a ranking function, we ranked the retrieved sentences of the queries by the function.", "labels": [], "entities": []}, {"text": "Then, the top-n sentences of the output are evaluated in terms of the coverage rate defined as follows: \uf03d coverage queries of # top-n in on translati a find can queries of # The meaning of the coverage rate can be interpreted as: how many percent of the query can find an acceptable translation in the top-n results.", "labels": [], "entities": []}, {"text": "We use the reference translations, as described in Section 3.1, as acceptable translation set for each query of our experiment.", "labels": [], "entities": []}, {"text": "shows the coverage rate of the nf_dice function compared with the Dice coefficient.", "labels": [], "entities": [{"text": "coverage rate", "start_pos": 10, "end_pos": 23, "type": "METRIC", "confidence": 0.9791834652423859}]}, {"text": "As it shows, in the outputs ranked by the Dice coefficient, uses usually have to lookup more than 3 sentences to find an acceptable translation; while in the outputs ranked by the nf_dice function, users can find an acceptable translation in top-2 sentences.", "labels": [], "entities": []}, {"text": "dice nf_dice top-1 0.42 0.92 top-2 0.75 1.00 top-3 0.92 1.00.", "labels": [], "entities": []}, {"text": "Evaluation of the ranking criteria.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1. Evaluation of the translation spotting  queried by 12 domain-specific terms.", "labels": [], "entities": [{"text": "translation spotting  queried", "start_pos": 28, "end_pos": 57, "type": "TASK", "confidence": 0.9563387036323547}]}, {"text": " Table 2. Evaluation of the translation spotting for each term", "labels": [], "entities": [{"text": "translation spotting", "start_pos": 28, "end_pos": 48, "type": "TASK", "confidence": 0.9740869700908661}]}]}