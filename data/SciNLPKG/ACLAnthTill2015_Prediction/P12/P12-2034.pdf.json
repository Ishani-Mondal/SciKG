{"title": [], "abstractContent": [{"text": "Most previous studies in computerized deception detection have relied only on shallow lexico-syntactic patterns.", "labels": [], "entities": [{"text": "computerized deception detection", "start_pos": 25, "end_pos": 57, "type": "TASK", "confidence": 0.7321385741233826}]}, {"text": "This paper investigates syntactic stylometry for deception detection, adding a somewhat unconventional angle to prior literature.", "labels": [], "entities": [{"text": "deception detection", "start_pos": 49, "end_pos": 68, "type": "TASK", "confidence": 0.9753069877624512}]}, {"text": "Over four different datasets spanning from the product review to the essay domain, we demonstrate that features driven from Context Free Grammar (CFG) parse trees consistently improve the detection performance over several baselines that are based only on shallow lexico-syntactic features.", "labels": [], "entities": []}, {"text": "Our results improve the best published result on the hotel review data (Ott et al., 2011) reaching 91.2% accuracy with 14% error reduction.", "labels": [], "entities": [{"text": "hotel review data (Ott et al., 2011)", "start_pos": 53, "end_pos": 89, "type": "DATASET", "confidence": 0.7788538217544556}, {"text": "accuracy", "start_pos": 105, "end_pos": 113, "type": "METRIC", "confidence": 0.9980775117874146}, {"text": "error reduction", "start_pos": 123, "end_pos": 138, "type": "METRIC", "confidence": 0.9890038073062897}]}], "introductionContent": [{"text": "Previous studies in computerized deception detection have relied only on shallow lexicosyntactic cues.", "labels": [], "entities": [{"text": "computerized deception detection", "start_pos": 20, "end_pos": 52, "type": "TASK", "confidence": 0.7044481039047241}]}, {"text": "Most are based on dictionarybased word counting using LIWC) (e.g.,,), while some recent ones explored the use of machine learning techniques using simple lexico-syntactic patterns, such as n-grams and part-of-speech (POS) tags,).", "labels": [], "entities": [{"text": "dictionarybased word counting", "start_pos": 18, "end_pos": 47, "type": "TASK", "confidence": 0.6057753562927246}]}, {"text": "These previous studies unveil interesting correlations between certain lexical items or categories with deception that may not be readily apparent to human judges.", "labels": [], "entities": []}, {"text": "For instance, the work of in the hotel review domain results in very insightful observations that deceptive reviewers tend to use verbs and personal pronouns (e.g., \"I\", \"my\") more often, while truthful reviewers tend to use more of nouns, adjectives, prepositions.", "labels": [], "entities": []}, {"text": "In parallel to these shallow lexical patterns, might there be deep syntactic structures that are lurking in deceptive writing?", "labels": [], "entities": []}, {"text": "This paper investigates syntactic stylometry for deception detection, adding a somewhat unconventional angle to prior literature.", "labels": [], "entities": [{"text": "deception detection", "start_pos": 49, "end_pos": 68, "type": "TASK", "confidence": 0.9753069877624512}]}, {"text": "Over four different datasets spanning from the product review domain to the essay domain, we find that features driven from Context Free Grammar (CFG) parse trees consistently improve the detection performance over several baselines that are based only on shallow lexico-syntactic features.", "labels": [], "entities": []}, {"text": "Our results improve the best published result on the hotel review data of reaching 91.2% accuracy with 14% error reduction.", "labels": [], "entities": [{"text": "hotel review data", "start_pos": 53, "end_pos": 70, "type": "DATASET", "confidence": 0.759253720442454}, {"text": "accuracy", "start_pos": 89, "end_pos": 97, "type": "METRIC", "confidence": 0.9989155530929565}, {"text": "error reduction", "start_pos": 107, "end_pos": 122, "type": "METRIC", "confidence": 0.9893655180931091}]}, {"text": "We also achieve substantial improvement over the essay data of, obtaining upto 85.0% accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 85, "end_pos": 93, "type": "METRIC", "confidence": 0.9990572333335876}]}], "datasetContent": [{"text": "To explore different types of deceptive writing, we consider the following four datasets spanning from the product review to the essay domain: I.", "labels": [], "entities": []}, {"text": "TripAdvisor-Gold: Introduced in, this dataset contains 400 truthful reviews obtained from www.tripadviser.com and 400 deceptive reviews gathered using Amazon Mechanical Turk, evenly distributed across 20 Chicago hotels.", "labels": [], "entities": [{"text": "TripAdvisor-Gold", "start_pos": 0, "end_pos": 16, "type": "DATASET", "confidence": 0.9328153729438782}]}, {"text": "For all classification tasks, we use SVM classifier, 80% of data for training and 20% for testing, with 5-fold cross validation.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 3: Most discriminative phrasal tags in PCFG  parse trees: TripAdvisor data.", "labels": [], "entities": [{"text": "PCFG  parse trees", "start_pos": 46, "end_pos": 63, "type": "DATASET", "confidence": 0.7148540019989014}, {"text": "TripAdvisor data", "start_pos": 65, "end_pos": 81, "type": "DATASET", "confidence": 0.9545672237873077}]}, {"text": " Table 1. We order the rules  based on the feature weights assigned by LIB- LINEAR classifier. Notice that the two produc- tion rules in bolds -[SBAR\u02c6NP \u2192 S] and [NP\u02c6VP NP\u02c6VP \u2192 NP SBAR] -are parts of the parse tree  shown in", "labels": [], "entities": []}]}