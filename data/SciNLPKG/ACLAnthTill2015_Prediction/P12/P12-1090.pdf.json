{"title": [{"text": "Classifying French Verbs Using French and English Lexical Resources", "labels": [], "entities": [{"text": "Classifying French Verbs", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.7981516122817993}]}], "abstractContent": [{"text": "We present a novel approach to the automatic acquisition of a Verbnet like classification of French verbs which involves the use (i) of a neural clustering method which associates clusters with features, (ii) of several supervised and unsupervised evaluation metrics and (iii) of various existing syntactic and semantic lexical resources.", "labels": [], "entities": [{"text": "Verbnet like classification of French verbs", "start_pos": 62, "end_pos": 105, "type": "TASK", "confidence": 0.6537803560495377}]}, {"text": "We evaluate our approach on an established test set and show that it outperforms previous related work with an F-measure of 0.70.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 111, "end_pos": 120, "type": "METRIC", "confidence": 0.9984281063079834}]}], "introductionContent": [{"text": "Verb classifications have been shown to be useful both from a theoretical and from a practical perspective.", "labels": [], "entities": [{"text": "Verb classifications", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.8374854028224945}]}, {"text": "From the theoretical viewpoint, they permit capturing syntactic and/or semantic generalisations about verbs).", "labels": [], "entities": [{"text": "capturing syntactic and/or semantic generalisations about verbs", "start_pos": 44, "end_pos": 107, "type": "TASK", "confidence": 0.6572859949535794}]}, {"text": "From a practical perspective, they support factorisation and have been shown to be effective in various NLP (Natural language Processing) tasks such as semantic role labelling) or word sense disambiguation.", "labels": [], "entities": [{"text": "semantic role labelling", "start_pos": 152, "end_pos": 175, "type": "TASK", "confidence": 0.623550554116567}, {"text": "word sense disambiguation", "start_pos": 180, "end_pos": 205, "type": "TASK", "confidence": 0.7492386897404989}]}, {"text": "While there has been much work on automatically acquiring verb classes for English ( and to a lesser extent for German (; Schulte im), Japanese) and Italian (), few studies have been conducted on the automatic classification of French verbs.", "labels": [], "entities": [{"text": "automatic classification of French verbs", "start_pos": 200, "end_pos": 240, "type": "TASK", "confidence": 0.7336544275283814}]}, {"text": "Recently however, two proposals have been put forward.", "labels": [], "entities": []}, {"text": "On the one hand, () applied a clustering approach developed for English to French.", "labels": [], "entities": []}, {"text": "They exploit features extracted from a large scale subcategorisation lexicon) acquired fully automatically from Le Monde newspaper corpus and show that, as for English, syntactic frames and verb selectional preferences perform better than lexical cooccurence features.", "labels": [], "entities": [{"text": "Le Monde newspaper corpus", "start_pos": 112, "end_pos": 137, "type": "DATASET", "confidence": 0.8791535049676895}]}, {"text": "Their approach achieves a F-measure of 55.1 on 116 verbs occurring at least 150 times in Lexschem.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 26, "end_pos": 35, "type": "METRIC", "confidence": 0.9995393753051758}, {"text": "Lexschem", "start_pos": 89, "end_pos": 97, "type": "DATASET", "confidence": 0.9628015756607056}]}, {"text": "The best performance is achieved when restricting the approach to verbs occurring at least 4000 times (43 verbs) with an F-measure of 65.4.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 121, "end_pos": 130, "type": "METRIC", "confidence": 0.9993928670883179}]}, {"text": "On the other hand, Falk and Gardent (2011) present a classification approach for French verbs based on the use of Formal Concept Analysis (FCA).", "labels": [], "entities": [{"text": "Formal Concept Analysis (FCA)", "start_pos": 114, "end_pos": 143, "type": "TASK", "confidence": 0.6704364319642385}]}, {"text": "FCA () is a symbolic classification technique which permits creating classes associating sets of objects (eg. French verbs) with sets of features (eg. syntactic frames).", "labels": [], "entities": [{"text": "symbolic classification", "start_pos": 12, "end_pos": 35, "type": "TASK", "confidence": 0.7274070382118225}]}, {"text": "Falk and Gardent (2011) provide no evaluation for their results however, only a qualitative analysis.", "labels": [], "entities": []}, {"text": "In this paper, we describe a novel approach to the clustering of French verbs which (i) gives good results on the established benchmark used in and (ii) associates verbs with a feature profile describing their syntactic and semantic properties.", "labels": [], "entities": [{"text": "clustering of French verbs", "start_pos": 51, "end_pos": 77, "type": "TASK", "confidence": 0.8455799221992493}]}, {"text": "The approach exploits a clustering method called IGNGF (Incremental Growing Neural Gas with Feature Maximisation, () which uses the features characterising each cluster both to guide the clustering process and to label the output clusters.", "labels": [], "entities": [{"text": "IGNGF", "start_pos": 49, "end_pos": 54, "type": "METRIC", "confidence": 0.9025054574012756}]}, {"text": "We apply this method to the data contained in various verb lexicons and we evalu-ate the resulting classification on a slightly modified version of the gold standard provided by.", "labels": [], "entities": []}, {"text": "We show that the approach yields promising results (F-measure of 70%) and that the clustering produced systematically associates verbs with syntactic frames and thematic grids thereby providing an interesting basis for the creation and evaluation of a Verbnet-like classification.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 52, "end_pos": 61, "type": "METRIC", "confidence": 0.999478280544281}]}, {"text": "Section 2 describes the lexical resources used for feature extraction and Section 3 the experimental setup.", "labels": [], "entities": [{"text": "feature extraction", "start_pos": 51, "end_pos": 69, "type": "TASK", "confidence": 0.7911499738693237}]}, {"text": "Sections 4 and 5 present the data used for and the results obtained.", "labels": [], "entities": []}], "datasetContent": [{"text": "and Experimental Setup  We use several evaluation metrics which bear on different properties of the clustering.", "labels": [], "entities": []}, {"text": "Following (, we use modified purity (mPUR); weighted class accuracy (ACC) and F-measure to evaluate the clusterings produced.", "labels": [], "entities": [{"text": "purity (mPUR)", "start_pos": 29, "end_pos": 42, "type": "METRIC", "confidence": 0.8681290298700333}, {"text": "weighted class accuracy (ACC)", "start_pos": 44, "end_pos": 73, "type": "METRIC", "confidence": 0.765427773197492}, {"text": "F-measure", "start_pos": 78, "end_pos": 87, "type": "METRIC", "confidence": 0.997655987739563}]}, {"text": "These are computed as follows.", "labels": [], "entities": []}, {"text": "Each induced cluster is assigned the gold class (its prevalent class, prev(C)) to which most of its member verbs belong.", "labels": [], "entities": []}, {"text": "A verb is then said to be correct if the gold associates it with the prevalent class of the cluster it is in.", "labels": [], "entities": []}, {"text": "Given this, purity is the ratio between the number of correct gold verbs in the clustering and the total number of gold verbs in the clustering : where Verbs Gold\u2229Clustering is the total number of gold verbs in the clustering.", "labels": [], "entities": [{"text": "purity", "start_pos": 12, "end_pos": 18, "type": "METRIC", "confidence": 0.9947777986526489}]}, {"text": "Accuracy represents the proportion of gold verbs in those clusters which are associated with a gold class, compared to all the gold verbs in the clustering.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 0, "end_pos": 8, "type": "METRIC", "confidence": 0.9935989379882812}]}, {"text": "To compute accuracy we associate to each gold class C Golda dominant cluster, ie. the cluster dom(C Gold ) which has most verbs in common with the gold class.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 11, "end_pos": 19, "type": "METRIC", "confidence": 0.9992843270301819}]}, {"text": "Then accuracy is given by the following formula: Finally, F-measure is the harmonic mean of mPUR and ACC.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 5, "end_pos": 13, "type": "METRIC", "confidence": 0.9994449019432068}, {"text": "F-measure", "start_pos": 58, "end_pos": 67, "type": "METRIC", "confidence": 0.994905948638916}, {"text": "ACC", "start_pos": 101, "end_pos": 104, "type": "METRIC", "confidence": 0.9448326826095581}]}, {"text": "To assess the extent to which a clustering matches the gold classification, we additionally compute the coverage of each clustering that is, the proportion of gold classes that are prevalent classes in the clustering.", "labels": [], "entities": []}, {"text": "Cumulative Micro Precision (CMP to a gold standard.", "labels": [], "entities": []}, {"text": "It was shown in () to be effective in detecting degenerated clustering results including a small number of large heterogeneous, \"garbage\" clusters and a big number of small size \"chunk\" clusters.", "labels": [], "entities": []}, {"text": "First, the local Recall (R f c ) and the local Precision (P f c ) of a feature fin a cluster care defined as follows: where v f c is the set of verbs having feature fin c, V c the set of verbs inc and V f , the set of verbs with feature f . Cumulative Micro-Precision (CMP) is then defined as follows: where C i+ represents the subset of clusters of C for which the number of associated verbs is greater than i, and:  We applied an IDF-Norm weighting scheme to decrease the influence of the most frequent features (IDF component) and to compensate for discrepancies in feature number (normalisation).: Sample output fora cluster produced with the grid-scf-sem feature set and the IGNGF clustering method.", "labels": [], "entities": [{"text": "Recall", "start_pos": 17, "end_pos": 23, "type": "METRIC", "confidence": 0.9529141187667847}]}, {"text": "We use K-Means as a baseline.", "labels": [], "entities": []}, {"text": "For each clustering method (K-Means and IGNGF), we let the number of clusters vary between 1 and 30 to obtain a partition that reaches an optimum F-measure and a number of clusters that is in the same order of magnitude as the initial number of Gold classes (i.e. 11 classes).", "labels": [], "entities": [{"text": "IGNGF", "start_pos": 40, "end_pos": 45, "type": "METRIC", "confidence": 0.6929029226303101}, {"text": "F-measure", "start_pos": 146, "end_pos": 155, "type": "METRIC", "confidence": 0.9937832355499268}]}], "tableCaptions": [{"text": " Table 1: Sample output for a cluster produced with  the grid-scf-sem feature set and the IGNGF clustering  method.", "labels": [], "entities": [{"text": "IGNGF clustering", "start_pos": 90, "end_pos": 106, "type": "TASK", "confidence": 0.5897871255874634}]}, {"text": " Table 2: Additional syntactic (a) and semantic (b) fea- tures extracted from the LADL and Dicovalence re- sources and the alternations/roles they are possibly re- lated to.", "labels": [], "entities": []}, {"text": " Table 5: Results. Cumulative micro precision (CMP) is given for the clustering at the mPUR optimum and in paran- theses for 13 classes clustering.", "labels": [], "entities": [{"text": "Cumulative micro precision (CMP)", "start_pos": 19, "end_pos": 51, "type": "METRIC", "confidence": 0.874914139509201}]}]}