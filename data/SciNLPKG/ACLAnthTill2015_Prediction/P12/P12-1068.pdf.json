{"title": [], "abstractContent": [{"text": "We argue that multilingual parallel data provides a valuable source of indirect supervision for induction of shallow semantic representations.", "labels": [], "entities": [{"text": "induction of shallow semantic representations", "start_pos": 96, "end_pos": 141, "type": "TASK", "confidence": 0.7529423832893372}]}, {"text": "Specifically, we consider unsupervised induction of semantic roles from sentences annotated with automatically-predicted syntactic dependency representations and use a state-of-the-art generative Bayesian non-parametric model.", "labels": [], "entities": []}, {"text": "At inference time, instead of only seeking the model which explains the mono-lingual data available for each language, we regularize the objective by introducing a soft constraint penalizing for disagreement in argument labeling on aligned sentences.", "labels": [], "entities": []}, {"text": "We propose a simple approximate learning algorithm for our setup which results in efficient inference.", "labels": [], "entities": []}, {"text": "When applied to German-English parallel data, our method obtains a substantial improvement over a model trained without using the agreement signal, when both are tested on non-parallel sentences.", "labels": [], "entities": []}], "introductionContent": [{"text": "Learning in the context of multiple languages simultaneously has been shown to be beneficial to a number of NLP tasks from morphological analysis to syntactic parsing).", "labels": [], "entities": [{"text": "syntactic parsing", "start_pos": 149, "end_pos": 166, "type": "TASK", "confidence": 0.6979272067546844}]}, {"text": "The goal of this work is to show that parallel data is useful in unsupervised induction of shallow semantic representations.", "labels": [], "entities": [{"text": "induction of shallow semantic representations", "start_pos": 78, "end_pos": 123, "type": "TASK", "confidence": 0.6794046401977539}]}, {"text": "Semantic role labeling (SRL) () involves predicting predicate argument structure, i.e. both the identification of arguments and their assignment to underlying semantic roles.", "labels": [], "entities": [{"text": "Semantic role labeling (SRL)", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.8473637799421946}, {"text": "predicting predicate argument structure", "start_pos": 41, "end_pos": 80, "type": "TASK", "confidence": 0.7714903503656387}]}, {"text": "For example, in the following sentences: (a)  the arguments 'Peter', 'Mary', and 'planning a theft' of the predicate 'blame' take the agent (A0), patient (A1) and reason (A2) roles, respectively.", "labels": [], "entities": []}, {"text": "In this work, we focus on predicting argument roles.", "labels": [], "entities": [{"text": "predicting argument roles", "start_pos": 26, "end_pos": 51, "type": "TASK", "confidence": 0.9009246428807577}]}, {"text": "SRL representations have many potential applications in NLP and have recently been shown to benefit question answering, textual entailment (, machine translation (, and dialogue systems (), among others.", "labels": [], "entities": [{"text": "SRL representations", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.8721963763237}, {"text": "NLP", "start_pos": 56, "end_pos": 59, "type": "TASK", "confidence": 0.9512754082679749}, {"text": "question answering", "start_pos": 100, "end_pos": 118, "type": "TASK", "confidence": 0.862551748752594}, {"text": "textual entailment", "start_pos": 120, "end_pos": 138, "type": "TASK", "confidence": 0.7358666062355042}, {"text": "machine translation", "start_pos": 142, "end_pos": 161, "type": "TASK", "confidence": 0.7395123392343521}]}, {"text": "Though syntactic representations are often predictive of semantic roles, the interface between syntactic and semantic representations is far from trivial.", "labels": [], "entities": []}, {"text": "Lack of simple deterministic rules for mapping syntax to shallow semantics motivates the use of statistical methods.", "labels": [], "entities": []}, {"text": "Most of the current statistical approaches to SRL are supervised, requiring large quantities of human annotated data to estimate model parameters.", "labels": [], "entities": [{"text": "SRL", "start_pos": 46, "end_pos": 49, "type": "TASK", "confidence": 0.9943752288818359}]}, {"text": "However, such resources are expensive to create and only available fora small number of languages and domains.", "labels": [], "entities": []}, {"text": "Moreover, when moved to anew domain, performance of these models tends to degrade substantially ().", "labels": [], "entities": []}, {"text": "Sparsity of annotated data motivates the need to look to alternative resources.", "labels": [], "entities": []}, {"text": "In this work, we make use of unsupervised data along with parallel texts and learn to induce semantic structures in two languages simultaneously.", "labels": [], "entities": []}, {"text": "As does most of the recent work on unsupervised SRL, we assume that our data is annotated with automatically-predicted syntactic dependency parses and aim to induce a model of linking between syntax and semantics in an unsupervised way.", "labels": [], "entities": [{"text": "SRL", "start_pos": 48, "end_pos": 51, "type": "TASK", "confidence": 0.8819027543067932}]}, {"text": "We expect that both linguistic relatedness and variability can serve to improve semantic parses in individual languages: while the former can provide additional evidence, the latter can serve to reduce uncertainty in ambiguous cases.", "labels": [], "entities": [{"text": "semantic parses", "start_pos": 80, "end_pos": 95, "type": "TASK", "confidence": 0.7403694987297058}]}, {"text": "For example, in our sentences (a) and (b) representing so-called blame alternation, the same information is conveyed in two different ways and a successful model of semantic role labeling needs to learn the corresponding linkings from the data.", "labels": [], "entities": [{"text": "semantic role labeling", "start_pos": 165, "end_pos": 187, "type": "TASK", "confidence": 0.6736247142155966}]}, {"text": "Inducing them solely based on monolingual data, though possible, maybe tricky as selectional preferences of the roles are not particularly restrictive; similar restrictions for patient and agent roles may further complicate the process.", "labels": [], "entities": []}, {"text": "However, both sentences (a) and (b) are likely to be translated in German as Maximizing agreement between the roles predicted for both languages would provide a strong signal for inducing the proper linkings in our examples.", "labels": [], "entities": [{"text": "Maximizing", "start_pos": 77, "end_pos": 87, "type": "TASK", "confidence": 0.9659526348114014}]}, {"text": "In this work, we begin with a state-of-the-art monolingual unsupervised Bayesian model and focus on improving its performance in the crosslingual setting.", "labels": [], "entities": []}, {"text": "It induces a linking between syntax and semantics, encoded as a clustering of syntactic signatures of predicate arguments.", "labels": [], "entities": []}, {"text": "The clustering implicitly defines the set of permissible alternations.", "labels": [], "entities": []}, {"text": "For predicates present in both sides of a bitext, we guide models in both languages to prefer clusterings which maximize agreement between predicate argument structures predicted for each aligned predicate pair.", "labels": [], "entities": []}, {"text": "We experimentally show the effectiveness of the crosslingual learning on the English-German language pair.", "labels": [], "entities": []}, {"text": "Our model admits efficient inference: the estimation time on and Europarl v.6 bitext () does not exceed 5 hours on a single processor and the inference algorithm is highly parallelizable, reducing inference time down to less than half an hour on multiple processors.", "labels": [], "entities": [{"text": "Europarl v.6 bitext", "start_pos": 65, "end_pos": 84, "type": "DATASET", "confidence": 0.8107699751853943}]}, {"text": "This suggests that the models scale to much larger corpora, which is an important property fora successful unsupervised learning method, as unlabeled data is abundant.", "labels": [], "entities": []}, {"text": "In summary, our contributions are as follows.", "labels": [], "entities": []}, {"text": "\u2022 This work is the first to consider the crosslingual setting for unsupervised SRL.", "labels": [], "entities": [{"text": "SRL", "start_pos": 79, "end_pos": 82, "type": "TASK", "confidence": 0.8973195552825928}]}, {"text": "\u2022 We propose a form of agreement penalty and show its efficacy on English-German language pair when used in conjunction with a state-ofthe-art non-parametric Bayesian model.", "labels": [], "entities": []}, {"text": "\u2022 We demonstrate that efficient approximate inference is feasible in the multilingual setting.", "labels": [], "entities": []}, {"text": "The rest of the paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 begins with a definition of the crosslingual semantic role induction task we address in this paper.", "labels": [], "entities": [{"text": "crosslingual semantic role induction task", "start_pos": 42, "end_pos": 83, "type": "TASK", "confidence": 0.6679852247238159}]}, {"text": "In Section 3, we describe the base monolingual model, and in Section 4 we propose an extension for the crosslingual setting.", "labels": [], "entities": []}, {"text": "In Section 5, we describe our inference procedure.", "labels": [], "entities": []}, {"text": "Section 6 provides both evaluation and analysis.", "labels": [], "entities": []}, {"text": "Finally, additional related work is presented in Section 7.", "labels": [], "entities": []}], "datasetContent": [{"text": "We begin by describing the data and evaluation metrics we use before discussing results.", "labels": [], "entities": []}, {"text": "We use the standard purity (PU) and collocation (CO) metrics as well as their harmonic mean (F1) to measure the quality of the resulting clusters.", "labels": [], "entities": [{"text": "standard purity (PU) and collocation (CO)", "start_pos": 11, "end_pos": 52, "type": "METRIC", "confidence": 0.7290419220924378}, {"text": "harmonic mean (F1)", "start_pos": 78, "end_pos": 96, "type": "METRIC", "confidence": 0.8742612957954407}]}, {"text": "Purity measures the degree to which each cluster contains arguments sharing the same gold role: where Ci is the set of arguments in the i-th induced cluster, G j is the set of arguments in the jth gold cluster, and N is the total number of arguments.", "labels": [], "entities": []}, {"text": "Collocation evaluates the degree to which arguments with the same gold roles are assigned to a single cluster: We compute the aggregate PU, CO, and F1 scores overall predicates in the same way as) by weighting the scores of each predicate by the number of its argument occurrences.", "labels": [], "entities": [{"text": "CO", "start_pos": 140, "end_pos": 142, "type": "METRIC", "confidence": 0.8034011721611023}, {"text": "F1", "start_pos": 148, "end_pos": 150, "type": "METRIC", "confidence": 0.9642719626426697}]}, {"text": "Since our goal is to evaluate the clustering algorithms, we do not include incorrectly identified arguments when computing these metrics.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Argument clustering performance with gold  argument identification and gold syntactic parses on  CoNLL 2008 shared-task dataset. Bold-face is used to  highlight the best F1 scores.", "labels": [], "entities": [{"text": "CoNLL 2008 shared-task dataset", "start_pos": 107, "end_pos": 137, "type": "DATASET", "confidence": 0.9489721804857254}, {"text": "F1", "start_pos": 180, "end_pos": 182, "type": "METRIC", "confidence": 0.9965219497680664}]}, {"text": " Table 2: Results on CoNLL 2009 with automatic argu- ment identification and automatic syntactic parses.", "labels": [], "entities": [{"text": "CoNLL 2009", "start_pos": 21, "end_pos": 31, "type": "DATASET", "confidence": 0.8939668536186218}, {"text": "argu- ment identification", "start_pos": 47, "end_pos": 72, "type": "TASK", "confidence": 0.6827718615531921}]}]}