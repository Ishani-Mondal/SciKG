{"title": [{"text": "Fast Online Training with Frequency-Adaptive Learning Rates for Chinese Word Segmentation and New Word Detection", "labels": [], "entities": [{"text": "Chinese Word Segmentation", "start_pos": 64, "end_pos": 89, "type": "TASK", "confidence": 0.5979337890942892}, {"text": "New Word Detection", "start_pos": 94, "end_pos": 112, "type": "TASK", "confidence": 0.6309861540794373}]}], "abstractContent": [{"text": "We present a joint model for Chinese word segmentation and new word detection.", "labels": [], "entities": [{"text": "Chinese word segmentation", "start_pos": 29, "end_pos": 54, "type": "TASK", "confidence": 0.6018367906411489}, {"text": "word detection", "start_pos": 63, "end_pos": 77, "type": "TASK", "confidence": 0.7151220589876175}]}, {"text": "We present high dimensional new features, including word-based features and enriched edge (label-transition) features, for the joint modeling.", "labels": [], "entities": []}, {"text": "As we know, training a word segmentation system on large-scale datasets is already costly.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 23, "end_pos": 40, "type": "TASK", "confidence": 0.751878559589386}]}, {"text": "In our case, adding high dimensional new features will further slowdown the training speed.", "labels": [], "entities": []}, {"text": "To solve this problem, we propose anew training method, adaptive online gradient descent based on feature frequency information, for very fast online training of the parameters, even given large-scale datasets with high dimensional features.", "labels": [], "entities": []}, {"text": "Compared with existing training methods, our training method is an order magnitude faster in terms of training time, and can achieve equal or even higher accuracies.", "labels": [], "entities": [{"text": "accuracies", "start_pos": 154, "end_pos": 164, "type": "METRIC", "confidence": 0.9627270698547363}]}, {"text": "The proposed fast training method is a general purpose optimization method, and it is not limited in the specific task discussed in this paper.", "labels": [], "entities": []}], "introductionContent": [{"text": "Since Chinese sentences are written as continuous sequences of characters, segmenting a character sequence into words is normally the first step in the pipeline of Chinese text processing.", "labels": [], "entities": [{"text": "Chinese text processing", "start_pos": 164, "end_pos": 187, "type": "TASK", "confidence": 0.6074111262957255}]}, {"text": "The major problem of Chinese word segmentation is the ambiguity.", "labels": [], "entities": [{"text": "Chinese word segmentation", "start_pos": 21, "end_pos": 46, "type": "TASK", "confidence": 0.588196595509847}]}, {"text": "Chinese character sequences are normally ambiguous, and new words (outof-vocabulary words) area major source of the ambiguity.", "labels": [], "entities": []}, {"text": "A typical category of new words is named entities, including organization names, person names, location names, and soon.", "labels": [], "entities": []}, {"text": "In this paper, we present high dimensional new features, including word-based features and enriched edge (label-transition) features, for the joint modeling of Chinese word segmentation (CWS) and new word detection (NWD).", "labels": [], "entities": [{"text": "Chinese word segmentation (CWS)", "start_pos": 160, "end_pos": 191, "type": "TASK", "confidence": 0.7385125408569971}, {"text": "new word detection (NWD)", "start_pos": 196, "end_pos": 220, "type": "TASK", "confidence": 0.7740431427955627}]}, {"text": "While most of the state-of-the-art CWS systems used semiMarkov conditional random fields or latent variable conditional random fields, we simply use a single first-order conditional random fields (CRFs) for the joint modeling.", "labels": [], "entities": []}, {"text": "The semi-Markov CRFs and latent variable CRFs relax the Markov assumption of CRFs to express more complicated dependencies, and therefore to achieve higher disambiguation power.", "labels": [], "entities": []}, {"text": "Alternatively, our plan is not to relax Markov assumption of CRFs, but to exploit more complicated dependencies via using refined highdimensional features.", "labels": [], "entities": []}, {"text": "The advantage of our choice is the simplicity of our model.", "labels": [], "entities": []}, {"text": "As a result, our CWS model can be more efficient compared with the heavier systems, and with similar or even higher accuracy because of using refined features.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 116, "end_pos": 124, "type": "METRIC", "confidence": 0.9990271329879761}]}, {"text": "As we know, training a word segmentation system on large-scale datasets is already costly.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 23, "end_pos": 40, "type": "TASK", "confidence": 0.751878559589386}]}, {"text": "In our case, adding high dimensional new features will further slowdown the training speed.", "labels": [], "entities": []}, {"text": "To solve this challenging problem, we propose anew training method, adaptive online gradient descent based on feature frequency information (ADF), for very fast word segmentation with new word detection, even given large-scale datasets with high dimensional features.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 161, "end_pos": 178, "type": "TASK", "confidence": 0.7160242795944214}, {"text": "word detection", "start_pos": 188, "end_pos": 202, "type": "TASK", "confidence": 0.7256017476320267}]}, {"text": "In the proposed training method, we try to use more refined learning rates.", "labels": [], "entities": []}, {"text": "Instead of using a single learning rate (a scalar) for all weights, we extend the learning rate scalar to a learning rate vector based on feature frequency information in the updating.", "labels": [], "entities": []}, {"text": "By doing so, each weight has its own learning rate adapted on feature frequency information.", "labels": [], "entities": []}, {"text": "We will show that this can significantly improve the convergence speed of online learning.", "labels": [], "entities": []}, {"text": "We approximate the learning rate vector based on feature frequency information in the updating process.", "labels": [], "entities": []}, {"text": "Our proposal is based on the intuition that a feature with higher frequency in the training process should be with a learning rate that is decayed faster.", "labels": [], "entities": []}, {"text": "Based on this intuition, we will show the formalized training algorithm later.", "labels": [], "entities": []}, {"text": "We will show in experiments that our solution is an order magnitude faster compared with exiting learning methods, and can achieve equal or even higher accuracies.", "labels": [], "entities": []}, {"text": "The contribution of this work is as follows: \u2022 We propose a general purpose fast online training method, ADF.", "labels": [], "entities": []}, {"text": "The proposed training method requires only a few passes to complete the training.", "labels": [], "entities": []}, {"text": "\u2022 We propose a joint model for Chinese word segmentation and new word detection.", "labels": [], "entities": [{"text": "Chinese word segmentation", "start_pos": 31, "end_pos": 56, "type": "TASK", "confidence": 0.5988584260145823}, {"text": "word detection", "start_pos": 65, "end_pos": 79, "type": "TASK", "confidence": 0.7195600867271423}]}, {"text": "\u2022 Compared with prior work, our system achieves better accuracies on both word segmentation and new word detection.", "labels": [], "entities": [{"text": "accuracies", "start_pos": 55, "end_pos": 65, "type": "METRIC", "confidence": 0.9783112406730652}, {"text": "word segmentation", "start_pos": 74, "end_pos": 91, "type": "TASK", "confidence": 0.7432481646537781}, {"text": "word detection", "start_pos": 100, "end_pos": 114, "type": "TASK", "confidence": 0.7045218348503113}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 2: Incremental evaluations, by incrementally adding new features (word features and high dimensional edge  features), new word detection, and ADF training (replacing SGD training with ADF training). Number of passes is  decided by empirical convergence of the training methods.", "labels": [], "entities": [{"text": "word detection", "start_pos": 129, "end_pos": 143, "type": "TASK", "confidence": 0.7722981572151184}, {"text": "ADF", "start_pos": 149, "end_pos": 152, "type": "METRIC", "confidence": 0.8251297473907471}, {"text": "Number of passes", "start_pos": 206, "end_pos": 222, "type": "METRIC", "confidence": 0.8914346297581991}]}, {"text": " Table 1: Details of the datasets. W.T. represents word  types; C.T. represents character types.", "labels": [], "entities": []}, {"text": " Table 3: Comparing our method with the state-of-the-art CWS systems.", "labels": [], "entities": []}]}