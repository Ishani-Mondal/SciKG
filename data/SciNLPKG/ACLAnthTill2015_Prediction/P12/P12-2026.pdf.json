{"title": [{"text": "Learning to Find Translations and Transliterations on the Web", "labels": [], "entities": [{"text": "Learning to Find Translations and Transliterations on the Web", "start_pos": 0, "end_pos": 61, "type": "TASK", "confidence": 0.7497288717163934}]}], "abstractContent": [{"text": "In this paper, we present anew method for learning to finding translations and transliterations on the Web fora given term.", "labels": [], "entities": [{"text": "finding translations and transliterations", "start_pos": 54, "end_pos": 95, "type": "TASK", "confidence": 0.6703253239393234}]}, {"text": "The approach involves using a small set of terms and translations to obtain mixed-code snippets from a search engine, and automatically annotating the snippets with tags and features for training a conditional random field model.", "labels": [], "entities": []}, {"text": "At run-time, the model is used to extracting translation candidates fora given term.", "labels": [], "entities": []}, {"text": "Preliminary experiments and evaluation show our method cleanly combining various features, resulting in a system that outperforms previous work.", "labels": [], "entities": []}], "introductionContent": [{"text": "The phrase translation problem is critical to machine translation, cross-lingual information retrieval, and multilingual terminology.", "labels": [], "entities": [{"text": "phrase translation", "start_pos": 4, "end_pos": 22, "type": "TASK", "confidence": 0.8270300626754761}, {"text": "machine translation", "start_pos": 46, "end_pos": 65, "type": "TASK", "confidence": 0.795135498046875}, {"text": "cross-lingual information retrieval", "start_pos": 67, "end_pos": 102, "type": "TASK", "confidence": 0.6652159690856934}]}, {"text": "Such systems typically use a parallel corpus.", "labels": [], "entities": []}, {"text": "However, the out of vocabulary problem (OOV) is hard to overcome even with a very large training corpus due to the Zipf nature of word distribution, and ever growing new terminology and named entities.", "labels": [], "entities": [{"text": "out of vocabulary problem (OOV)", "start_pos": 13, "end_pos": 44, "type": "TASK", "confidence": 0.6225853392056057}]}, {"text": "Luckily, there are an abundant of webpages consisting mixed-code text, typically written in one language but interspersed with some sentential or phrasal translations in another language.", "labels": [], "entities": []}, {"text": "By retrieving and identifying such translation counterparts on the Web, we can cope with the OOV problem.", "labels": [], "entities": [{"text": "OOV", "start_pos": 93, "end_pos": 96, "type": "TASK", "confidence": 0.6673606634140015}]}, {"text": "Consider the technical term named-entity recognition.", "labels": [], "entities": [{"text": "named-entity recognition", "start_pos": 28, "end_pos": 52, "type": "TASK", "confidence": 0.7162092328071594}]}, {"text": "The best places to find the Chinese translations for named-entity recognition are probably not some parallel corpus or dictionary, but rather mixed-code webpages.", "labels": [], "entities": [{"text": "named-entity recognition", "start_pos": 53, "end_pos": 77, "type": "TASK", "confidence": 0.7665117383003235}]}, {"text": "The following example is a snippet returned by the Bing search engine for the query, named entity recognition:", "labels": [], "entities": [{"text": "entity recognition", "start_pos": 91, "end_pos": 109, "type": "TASK", "confidence": 0.7435660362243652}]}], "datasetContent": [{"text": "We extracted the Wikipedia titles of English and Chinese articles connected through language links for training and testing.", "labels": [], "entities": []}, {"text": "We obtained a total of 155,310 article pairs, from which we then randomly selected 13,150 and 2,181 titles as seeds to obtain the training and test data.", "labels": [], "entities": []}, {"text": "Since we are using Wikipedia bilingual titles as the gold standard, we exclude any snippets from the wikipedia.org domain, so that we are not using Wikipedia article content in both training and testing stage.", "labels": [], "entities": []}, {"text": "To compare our method with previous work, we used a similar evaluation procedure as described in.", "labels": [], "entities": []}, {"text": "We ran the system and produced the translations for these 2,181 test data, and automatically evaluate the results using the metrics of coverage, i.e. when system was able to produce translation candidates, and exact match precision.", "labels": [], "entities": [{"text": "coverage", "start_pos": 135, "end_pos": 143, "type": "METRIC", "confidence": 0.9907267093658447}, {"text": "precision", "start_pos": 222, "end_pos": 231, "type": "METRIC", "confidence": 0.8781747221946716}]}, {"text": "This precision rate is an under-estimations, since a term may have many alternative translations that does not match exactly with one single reference translation.", "labels": [], "entities": [{"text": "precision rate", "start_pos": 5, "end_pos": 19, "type": "METRIC", "confidence": 0.9822394549846649}]}, {"text": "To give a more accurate estimate of real precision, we resorted to manual evaluation on a small part of the 2,181 English phrases and a small set of English Wikipedia titles without a Chinese language link.", "labels": [], "entities": [{"text": "precision", "start_pos": 41, "end_pos": 50, "type": "METRIC", "confidence": 0.9977091550827026}]}, {"text": "In this section, we describe the evaluation based on English-Chinese titles extracted from Wikipedia as the gold standard.", "labels": [], "entities": []}, {"text": "Our system produce the top-1 translations by ranking candidates by frequency and output the most frequent translations.", "labels": [], "entities": []}, {"text": "shows the results we have obtained as compared to the results of. shows the evaluation results of 8 experiments.", "labels": [], "entities": []}, {"text": "The results indicate that using external knowledge to generate feature improves system performance significantly.", "labels": [], "entities": []}, {"text": "By adding translation feature (TL) or transliteration feature (TR) to the system with no external knowledge features (-TL-TR) improves exact match precision by about 6% and 16% respectively.", "labels": [], "entities": [{"text": "exact match", "start_pos": 135, "end_pos": 146, "type": "METRIC", "confidence": 0.831927090883255}, {"text": "precision", "start_pos": 147, "end_pos": 156, "type": "METRIC", "confidence": 0.5080535411834717}]}, {"text": "Because many Wikipedia titles are named entities, transliteration feature is the most important.", "labels": [], "entities": []}, {"text": "Overall, the system with full features perform the best, finding reasonably correct translations for 8 out of 10 phrases.", "labels": [], "entities": []}, {"text": "Evaluation based on exact match against a single reference answer leads to under-estimation, because an English phrase is often translated into several Chinese counterparts.", "labels": [], "entities": []}, {"text": "Therefore, we asked a human judge to examine and mark the outputs of our full system.", "labels": [], "entities": []}, {"text": "The judge was instructed to mark each output as A: correct translation alternative, B: correct translation but with a difference sense from the reference, P: partially correct translation, and E: incorrect translation.", "labels": [], "entities": []}, {"text": "shows some translations generated by the full system that does not match the single reference translation.", "labels": [], "entities": []}, {"text": "Half of the translations are correct translations (A and B), while a third are partially correct translation (P).", "labels": [], "entities": []}, {"text": "Notice that it is a common practice to translate only the surname of a foreign person.", "labels": [], "entities": []}, {"text": "Therefore, some partial translations may still be considered as correct (B).", "labels": [], "entities": []}, {"text": "To Evaluate titles without a language link, we sampled a list of 95 terms from the unlinked portion of Wikipedia using the criteria: (1) with a frequency count of over 2,000 in Google Web 1T.", "labels": [], "entities": [{"text": "Google Web 1T", "start_pos": 177, "end_pos": 190, "type": "DATASET", "confidence": 0.8316641847292582}]}, {"text": "(2) containing at least three English words.", "labels": [], "entities": []}, {"text": "(3) not a proper name.", "labels": [], "entities": []}, {"text": "Interestingly, our system provides correct translations for over 50% of the cases, and at least partially correct almost 90% of the cases.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1. Automatic evaluation results of 8 experiments:  (1) Full system (2-4) -TL, -TR, -TL-TR : Full system  deprecating TL, TR, and TL+TL features (5,6) LIN En- Ch and En-Ch : the results in Lin et al. (2008) (6) LDC:  LDC E-C dictionary (7) NICT : NICT term bank.", "labels": [], "entities": []}, {"text": " Table 2. Cases failing the exact match test.", "labels": [], "entities": [{"text": "exact match test", "start_pos": 28, "end_pos": 44, "type": "METRIC", "confidence": 0.8796444336573283}]}, {"text": " Table 3. Manual evaluation of unlink titles.", "labels": [], "entities": []}]}