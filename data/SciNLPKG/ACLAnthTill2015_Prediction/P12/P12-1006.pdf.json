{"title": [{"text": "Automated Essay Scoring Based on Finite State Transducer: towards ASR Transcription of Oral English Speech", "labels": [], "entities": [{"text": "Automated Essay Scoring", "start_pos": 0, "end_pos": 23, "type": "TASK", "confidence": 0.5752969086170197}, {"text": "ASR Transcription of Oral English Speech", "start_pos": 66, "end_pos": 106, "type": "TASK", "confidence": 0.8862286706765493}]}], "abstractContent": [{"text": "Conventional Automated Essay Scoring (AES) measures may cause severe problems when directly applied in scoring Automatic Speech Recognition (ASR) transcription as they are error sensitive and unsuitable for the characteristic of ASR transcription.", "labels": [], "entities": [{"text": "Automated Essay Scoring (AES)", "start_pos": 13, "end_pos": 42, "type": "TASK", "confidence": 0.7991360028584799}, {"text": "scoring Automatic Speech Recognition (ASR) transcription", "start_pos": 103, "end_pos": 159, "type": "TASK", "confidence": 0.7515002153813839}, {"text": "ASR transcription", "start_pos": 229, "end_pos": 246, "type": "TASK", "confidence": 0.9282183647155762}]}, {"text": "Therefore, we introduce a framework of Finite State Transducer (FST) to avoid the shortcomings.", "labels": [], "entities": [{"text": "Finite State Transducer (FST)", "start_pos": 39, "end_pos": 68, "type": "TASK", "confidence": 0.7052630037069321}]}, {"text": "Compared with the Latent Semantic Analysis with Support Vector Regression (LSA-SVR) method (stands for the conventional measures), our FST method shows better performance especially towards the ASR transcription.", "labels": [], "entities": [{"text": "ASR transcription", "start_pos": 194, "end_pos": 211, "type": "TASK", "confidence": 0.9062070548534393}]}, {"text": "In addition, we apply the synonyms similarity to expand the FST model.", "labels": [], "entities": [{"text": "FST", "start_pos": 60, "end_pos": 63, "type": "DATASET", "confidence": 0.4799658954143524}]}, {"text": "The final scoring performance reaches an acceptable level of 0.80 which is only 0.07 lower than the correlation (0.87) between human raters.", "labels": [], "entities": []}], "introductionContent": [{"text": "The assessment of learners' language abilities is a significant part in language learning.", "labels": [], "entities": [{"text": "language learning", "start_pos": 72, "end_pos": 89, "type": "TASK", "confidence": 0.808833122253418}]}, {"text": "In conventional assessment, the problem of limited teacher availability has become increasingly serious with the population increase of language learners.", "labels": [], "entities": []}, {"text": "Fortunately, with the development of computer techniques and machine learning techniques (natural language processing and automatic speech recognition), Computer-Assisted Language Learning (CALL) systems help people to learn language by themselves.", "labels": [], "entities": [{"text": "automatic speech recognition", "start_pos": 122, "end_pos": 150, "type": "TASK", "confidence": 0.7782792647679647}]}, {"text": "One form of CALL is evaluating the speech of the learner.", "labels": [], "entities": [{"text": "CALL", "start_pos": 12, "end_pos": 16, "type": "TASK", "confidence": 0.9838860034942627}]}, {"text": "Efforts in speech assessment usually focus on the integrality, fluency, pronunciation, and prosody ( of the speech, which are highly predictable like the exam form of the read-aloud text passage.", "labels": [], "entities": []}, {"text": "Another form of CALL is textual assessment.", "labels": [], "entities": [{"text": "CALL", "start_pos": 16, "end_pos": 20, "type": "TASK", "confidence": 0.9848092198371887}, {"text": "textual assessment", "start_pos": 24, "end_pos": 42, "type": "TASK", "confidence": 0.6949085891246796}]}, {"text": "This work is also named AES.", "labels": [], "entities": [{"text": "AES", "start_pos": 24, "end_pos": 27, "type": "METRIC", "confidence": 0.6124866008758545}]}, {"text": "Efforts in this area usually focus on the content, arrangement and language usage () of the text written by the learner under a certain form of examination.", "labels": [], "entities": []}, {"text": "In this paper, our evaluation objects are the oral English picture compositions in English as a Second Language (ESL) examination.", "labels": [], "entities": []}, {"text": "This examination requires students to talk about four successive pictures with at least five sentences in one minute, and the beginning sentence is given.", "labels": [], "entities": []}, {"text": "This examination form combines both of the two forms described above.", "labels": [], "entities": []}, {"text": "Therefore, we need two steps in the scoring task.", "labels": [], "entities": []}, {"text": "The first step is Automatic Speech Recognition (ASR), in which we get the speech scoring features as well as the textual transcriptions of the speeches.", "labels": [], "entities": [{"text": "Automatic Speech Recognition (ASR)", "start_pos": 18, "end_pos": 52, "type": "TASK", "confidence": 0.7835642546415329}]}, {"text": "Then, the second step could grade the text-free transcription in an (conventional) AES system.", "labels": [], "entities": []}, {"text": "The present work is mainly about the AES system under the certain situation as the examination grading criterion is more concerned about the integrated content of the speech (the reason will be given in subsection 3.1).", "labels": [], "entities": [{"text": "AES", "start_pos": 37, "end_pos": 40, "type": "METRIC", "confidence": 0.3988272547721863}]}, {"text": "There are many features and techniques which are very powerful in conventional AES systems, but applying them in this task will cause two different problems as the scoring objects are the ASR output results.", "labels": [], "entities": []}, {"text": "The first problem is that the inevitable recognition errors of the ASR will affect the performance of the feature extractions and scoring system.", "labels": [], "entities": [{"text": "ASR", "start_pos": 67, "end_pos": 70, "type": "TASK", "confidence": 0.9391080737113953}, {"text": "feature extractions", "start_pos": 106, "end_pos": 125, "type": "TASK", "confidence": 0.700094610452652}]}, {"text": "The second problem is caused by the special characteristic of the ASR result.", "labels": [], "entities": [{"text": "ASR", "start_pos": 66, "end_pos": 69, "type": "TASK", "confidence": 0.7896241545677185}]}, {"text": "As all these methods are designed under the normal AES situation that they are not suitable for the characteristic.", "labels": [], "entities": [{"text": "AES", "start_pos": 51, "end_pos": 54, "type": "METRIC", "confidence": 0.6128338575363159}]}, {"text": "The impact of the first problem can be reduced by either perfecting the results of the ASR system or building the AES system which is not sensitive to the ASR errors.", "labels": [], "entities": [{"text": "ASR", "start_pos": 87, "end_pos": 90, "type": "TASK", "confidence": 0.8756540417671204}, {"text": "AES", "start_pos": 114, "end_pos": 117, "type": "METRIC", "confidence": 0.8037864565849304}]}, {"text": "Improving the performance of the ASR is not what we concern about, so building an error insensitive AES system is what we care about in this paper.", "labels": [], "entities": [{"text": "ASR", "start_pos": 33, "end_pos": 36, "type": "TASK", "confidence": 0.9291117191314697}]}, {"text": "This makes many conventional features no longer useful in the AES system, such as spelling errors, punctuation errors and even grammar errors.", "labels": [], "entities": [{"text": "AES system", "start_pos": 62, "end_pos": 72, "type": "DATASET", "confidence": 0.8524289727210999}]}, {"text": "The second problem is caused by applying the bag-of-words (BOW) techniques to score the ASR transcription.", "labels": [], "entities": [{"text": "BOW", "start_pos": 59, "end_pos": 62, "type": "METRIC", "confidence": 0.709054172039032}, {"text": "ASR transcription", "start_pos": 88, "end_pos": 105, "type": "TASK", "confidence": 0.8903345763683319}]}, {"text": "The BOW are very useful in measuring the content features and are usually robust even if there are some errors in the scoring transcription.", "labels": [], "entities": [{"text": "BOW", "start_pos": 4, "end_pos": 7, "type": "METRIC", "confidence": 0.9925151467323303}]}, {"text": "However, the robustness would not exist anymore because of the characteristic of the ASR result.", "labels": [], "entities": [{"text": "ASR", "start_pos": 85, "end_pos": 88, "type": "TASK", "confidence": 0.753791332244873}]}, {"text": "It is known that better performance of ASR (reduce the word error rate in ASR) usually requires a strong constrain Language Model (LM).", "labels": [], "entities": [{"text": "ASR", "start_pos": 39, "end_pos": 42, "type": "TASK", "confidence": 0.9582418203353882}, {"text": "word error rate", "start_pos": 55, "end_pos": 70, "type": "METRIC", "confidence": 0.7053262492020925}]}, {"text": "It means that more meaningless parts of the oral speeches would be recognized as the words quite related to the topic content.", "labels": [], "entities": []}, {"text": "These words will usually be the key words in the BOW methods, which will lead to a great disturbrance for the methods.", "labels": [], "entities": [{"text": "BOW", "start_pos": 49, "end_pos": 52, "type": "TASK", "confidence": 0.4143739938735962}, {"text": "disturbrance", "start_pos": 89, "end_pos": 101, "type": "METRIC", "confidence": 0.9322715401649475}]}, {"text": "Therefore, the conventional BOW methods are no longer appropriate because of the characteristic of the ASR result.", "labels": [], "entities": [{"text": "BOW", "start_pos": 28, "end_pos": 31, "type": "METRIC", "confidence": 0.8623968958854675}, {"text": "ASR", "start_pos": 103, "end_pos": 106, "type": "TASK", "confidence": 0.8786095976829529}]}, {"text": "To tackle the two problems described above, we apply the FST.", "labels": [], "entities": [{"text": "FST", "start_pos": 57, "end_pos": 60, "type": "METRIC", "confidence": 0.7649261951446533}]}, {"text": "As the evaluating objects are from an oral English picture composition examination, it has two important features that make the FST algorithm quite suitable.", "labels": [], "entities": [{"text": "FST", "start_pos": 128, "end_pos": 131, "type": "TASK", "confidence": 0.9053588509559631}]}, {"text": "\u2022 Picture composition examinations require students to speak according to the sequence of the pictures, so there is strong sequentiality in the speech.", "labels": [], "entities": [{"text": "Picture composition", "start_pos": 2, "end_pos": 21, "type": "TASK", "confidence": 0.742113932967186}]}, {"text": "\u2022 The sentences for describing the same picture are very identical in expression, so there is a hierarchy between the word sequences in the sentences (the expression) and the sense for the same picture.", "labels": [], "entities": []}, {"text": "FST is designed to describe a structure mapping two different types of information sequences.", "labels": [], "entities": [{"text": "FST", "start_pos": 0, "end_pos": 3, "type": "TASK", "confidence": 0.5124978423118591}]}, {"text": "It is very useful in expressing the sequences and the hierarchy in picture composition.", "labels": [], "entities": [{"text": "picture composition", "start_pos": 67, "end_pos": 86, "type": "TASK", "confidence": 0.7461211383342743}]}, {"text": "Therefore, we build a FST-based model to extract features related to the transcription assessment in this paper.", "labels": [], "entities": [{"text": "FST-based", "start_pos": 22, "end_pos": 31, "type": "TASK", "confidence": 0.6579706072807312}]}, {"text": "As the FSTbased model is similar to the BOW metrics, it is also an error insensitive model.", "labels": [], "entities": [{"text": "FSTbased", "start_pos": 7, "end_pos": 15, "type": "DATASET", "confidence": 0.3976772129535675}, {"text": "BOW metrics", "start_pos": 40, "end_pos": 51, "type": "DATASET", "confidence": 0.6353641003370285}]}, {"text": "In this way, the impact of the first problem could be reduced.", "labels": [], "entities": []}, {"text": "The FST model is very powerful in delivering the sequence information that a meaningless sequence of words related to the topic content will get low score under the model.", "labels": [], "entities": [{"text": "FST", "start_pos": 4, "end_pos": 7, "type": "TASK", "confidence": 0.500949501991272}]}, {"text": "Therefore, it works well concerning the second problem.", "labels": [], "entities": []}, {"text": "Ina word, the FST model cannot only be insensitive to the recognition error in the ASR system, but also remedy the weakness of BOW methods in ASR result scoring.", "labels": [], "entities": [{"text": "FST", "start_pos": 14, "end_pos": 17, "type": "METRIC", "confidence": 0.49626144766807556}, {"text": "ASR", "start_pos": 83, "end_pos": 86, "type": "TASK", "confidence": 0.9478217363357544}, {"text": "BOW", "start_pos": 127, "end_pos": 130, "type": "METRIC", "confidence": 0.9870989918708801}, {"text": "ASR result scoring", "start_pos": 142, "end_pos": 160, "type": "TASK", "confidence": 0.9087771574656168}]}, {"text": "In the remainder of the paper, the related work of conventional AES methods is addressed in section 2.", "labels": [], "entities": [{"text": "AES", "start_pos": 64, "end_pos": 67, "type": "TASK", "confidence": 0.6575508117675781}]}, {"text": "The details of the speech corpus and the examination grading criterion are introduced in section 3.", "labels": [], "entities": []}, {"text": "The FST model and its improved method are proposed in section 4.", "labels": [], "entities": [{"text": "FST", "start_pos": 4, "end_pos": 7, "type": "TASK", "confidence": 0.40773555636405945}]}, {"text": "The experiments and the results are presented in section 5.", "labels": [], "entities": []}, {"text": "The final section presents the conclusion and future work.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section, the proposed features and our FST methods will be evaluated on the corpus we mentioned above.", "labels": [], "entities": [{"text": "FST", "start_pos": 47, "end_pos": 50, "type": "TASK", "confidence": 0.7561694979667664}]}, {"text": "The contrasting approach, the LSA-SVR approach, will also be presented.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: WER and MR of ASR result", "labels": [], "entities": [{"text": "WER", "start_pos": 10, "end_pos": 13, "type": "METRIC", "confidence": 0.9978622794151306}, {"text": "MR", "start_pos": 18, "end_pos": 20, "type": "METRIC", "confidence": 0.9990252256393433}, {"text": "ASR", "start_pos": 24, "end_pos": 27, "type": "TASK", "confidence": 0.7761448621749878}]}, {"text": " Table 3: Correlations of Human Scores", "labels": [], "entities": []}, {"text": " Table 4: Correlation Between the SSF and the Expert S- cores", "labels": [], "entities": []}, {"text": " Table 5: Correlations Between the Six Features and the Expert Scores", "labels": [], "entities": []}, {"text": " Table 6: Performance of the FST Method, the LSA-SVR  Approach and the Length Feature", "labels": [], "entities": [{"text": "FST", "start_pos": 29, "end_pos": 32, "type": "TASK", "confidence": 0.7266247272491455}, {"text": "LSA-SVR  Approach", "start_pos": 45, "end_pos": 62, "type": "METRIC", "confidence": 0.5570075660943985}]}, {"text": " Table 7: Performance of the FST Method and the Im- proved FST Method", "labels": [], "entities": [{"text": "FST", "start_pos": 29, "end_pos": 32, "type": "TASK", "confidence": 0.6730777025222778}, {"text": "Im- proved FST", "start_pos": 48, "end_pos": 62, "type": "DATASET", "confidence": 0.5578350648283958}]}]}