{"title": [{"text": "Unsupervised Semantic Role Induction with Global Role Ordering", "labels": [], "entities": [{"text": "Semantic Role Induction", "start_pos": 13, "end_pos": 36, "type": "TASK", "confidence": 0.5938820342222849}, {"text": "Global Role Ordering", "start_pos": 42, "end_pos": 62, "type": "TASK", "confidence": 0.6288591424624125}]}], "abstractContent": [{"text": "We propose a probabilistic generative model for unsupervised semantic role induction, which integrates local role assignment decisions and a global role ordering decision in a unified model.", "labels": [], "entities": [{"text": "semantic role induction", "start_pos": 61, "end_pos": 84, "type": "TASK", "confidence": 0.6377539932727814}]}, {"text": "The role sequence is divided into intervals based on the notion of primary roles, and each interval generates a sequence of secondary roles and syntactic constituents using local features.", "labels": [], "entities": []}, {"text": "The global role ordering consists of the sequence of primary roles only, thus making it a partial ordering.", "labels": [], "entities": []}], "introductionContent": [{"text": "Unsupervised semantic role induction has gained significant interest recently) due to limited amounts of annotated corpora.", "labels": [], "entities": [{"text": "semantic role induction", "start_pos": 13, "end_pos": 36, "type": "TASK", "confidence": 0.6626697182655334}]}, {"text": "A Semantic Role Labeling (SRL) system should provide consistent argument labels across different syntactic realizations of the same verb (, as in (a.)", "labels": [], "entities": [{"text": "Semantic Role Labeling (SRL)", "start_pos": 2, "end_pos": 30, "type": "TASK", "confidence": 0.7764802277088165}]}, {"text": "A0 drove [ the car ] A1 (b.)", "labels": [], "entities": [{"text": "A0", "start_pos": 0, "end_pos": 2, "type": "METRIC", "confidence": 0.9346108436584473}]}, {"text": "The car ] A1 was driven by A0 This simple example also shows that while certain local syntactic and semantic features could provide clues to the semantic role label of a constituent, nonlocal features such as predicate voice could provide information about the expected semantic role sequence.", "labels": [], "entities": []}, {"text": "Sentence a is in active voice with sequence (A0, P REDICAT E, A1) and sentence b is in passive voice with sequence (A1, P REDICAT E, A0).", "labels": [], "entities": []}, {"text": "Additional global preferences, such as arguments A0 and A1 rarely repeat in a frame (as seen in the corpus), could also be useful in addition to local features.", "labels": [], "entities": [{"text": "A1", "start_pos": 56, "end_pos": 58, "type": "METRIC", "confidence": 0.9131449460983276}]}, {"text": "Supervised SRL systems have mostly used local classifiers that assign a role to each constituent independently of others, and only modeled limited correlations among roles in a sequence ().", "labels": [], "entities": [{"text": "SRL", "start_pos": 11, "end_pos": 14, "type": "TASK", "confidence": 0.9759728908538818}]}, {"text": "The correlations have been modeled via role sets (), role repetition constraints), language model over roles (), and global role sequence (.", "labels": [], "entities": []}, {"text": "Unsupervised SRL systems have explored even fewer correlations.", "labels": [], "entities": [{"text": "SRL", "start_pos": 13, "end_pos": 16, "type": "TASK", "confidence": 0.9759472012519836}]}, {"text": "use the relative position (left/right) of the argument w.r.t. the predicate.", "labels": [], "entities": []}, {"text": "use an ordering of the linking of semantic roles and syntactic relations.", "labels": [], "entities": []}, {"text": "However, as the space of possible linkings is large, language-specific knowledge is used to constrain this space.", "labels": [], "entities": []}, {"text": "Similar to, we propose to use global role ordering preferences but in a generative model in contrast to their discriminative one.", "labels": [], "entities": []}, {"text": "Further, unlike, we do not explicitly generate the linking of semantic roles and syntactic relations, thus keeping the parameter space tractable.", "labels": [], "entities": []}, {"text": "The main contribution of this work is an unsupervised model that uses global role ordering and repetition preferences without assuming any language-specific constraints.", "labels": [], "entities": []}, {"text": "Following, previous work has typically broken the SRL task into (i) argument identification, and (ii) argument classification).", "labels": [], "entities": [{"text": "SRL task", "start_pos": 50, "end_pos": 58, "type": "TASK", "confidence": 0.9176670908927917}, {"text": "argument identification", "start_pos": 68, "end_pos": 91, "type": "TASK", "confidence": 0.7281374931335449}, {"text": "argument classification", "start_pos": 102, "end_pos": 125, "type": "TASK", "confidence": 0.7132161110639572}]}, {"text": "The latter is our focus in this work.", "labels": [], "entities": []}, {"text": "Given the dependency parse tree of a sentence with correctly identified arguments, the aim is to assign a semantic role label to each argument.", "labels": [], "entities": [{"text": "dependency parse tree of a sentence with correctly identified arguments", "start_pos": 10, "end_pos": 81, "type": "TASK", "confidence": 0.7896827340126038}]}], "datasetContent": [{"text": "Following the experimental settings of Lang and Lapata (2011b), we use the CoNLL 2008 shared task dataset (, only consider verbal predicates, and run unsupervised training on the standard training set.", "labels": [], "entities": [{"text": "CoNLL 2008 shared task dataset", "start_pos": 75, "end_pos": 105, "type": "DATASET", "confidence": 0.9335340857505798}]}, {"text": "The evaluation measures are also the same: (i) Purity (PU) that measures how well an induced cluster corresponds to a single gold role, (ii) Collocation (CO) that measures how well a gold role corresponds to a single induced cluster, and (iii) F1 which is the harmonic mean of PU and CO.", "labels": [], "entities": [{"text": "F1", "start_pos": 244, "end_pos": 246, "type": "METRIC", "confidence": 0.9996680021286011}]}, {"text": "Final scores are computed by weighting each predicate by the number of its argument instances.", "labels": [], "entities": []}, {"text": "We chose a uniform Dirichlet prior with concentration parameter as 0.1 for all the model parameters in Algorithm 1 (set roughly, without optimization 1 ).", "labels": [], "entities": []}, {"text": "50 training iterations were used.", "labels": [], "entities": []}, {"text": "3 Note that the system might not use all available PRs to label a given frame instance.", "labels": [], "entities": []}, {"text": "#PRs refers to the max #PRs.", "labels": [], "entities": []}, {"text": "With only this additional ordering information, the performance is the same as the baseline.", "labels": [], "entities": []}, {"text": "Adding just 1 PR leads to a big increase in both purity and collocation.", "labels": [], "entities": [{"text": "PR", "start_pos": 14, "end_pos": 16, "type": "METRIC", "confidence": 0.9883049726486206}, {"text": "purity", "start_pos": 49, "end_pos": 55, "type": "METRIC", "confidence": 0.9972680807113647}]}, {"text": "Increasing the number of PRs beyond 1 leads to a gradual increase in purity and decline in collocation, with the best F1 score at 2 PRs.", "labels": [], "entities": [{"text": "purity", "start_pos": 69, "end_pos": 75, "type": "METRIC", "confidence": 0.9982901215553284}, {"text": "F1 score", "start_pos": 118, "end_pos": 126, "type": "METRIC", "confidence": 0.9834338128566742}]}, {"text": "This behavior could be explained by the fact that increasing the number of PRs also increases the number of intervals, which makes the probability distributions more sparse.", "labels": [], "entities": []}, {"text": "In the extreme case, where all the roles are PRs and there are no SRs, the model would just learn the complete sequence of roles, which would make the parameter space too large to be tractable.", "labels": [], "entities": []}, {"text": "For calculating purity, each induced cluster (or role) is mapped to a particular gold role that has the maximum instances in the cluster.", "labels": [], "entities": []}, {"text": "Analyzing the output of our model (line 1c in), we found that about 98% of the PRs and 40% of the SRs got mapped to the gold core roles (A0,A1, etc.).", "labels": [], "entities": []}, {"text": "This suggests that the model is indeed following the intuition that (i) the ordering of core roles is important information for SRL systems, and (ii) the intervals bounded by core roles provide good context information for classification of other roles.", "labels": [], "entities": [{"text": "SRL", "start_pos": 128, "end_pos": 131, "type": "TASK", "confidence": 0.9854207634925842}]}], "tableCaptions": [{"text": " Table 1: Evaluation. d refers to deprel, h refers to  head and p-h refers to pos-head.", "labels": [], "entities": []}, {"text": " Table 2: Performance variation with the number of  PRs (excluding ST ART , EN D and P RED)", "labels": [], "entities": [{"text": "ST ART", "start_pos": 67, "end_pos": 73, "type": "METRIC", "confidence": 0.7486553490161896}, {"text": "P RED", "start_pos": 85, "end_pos": 90, "type": "METRIC", "confidence": 0.7649466693401337}]}]}