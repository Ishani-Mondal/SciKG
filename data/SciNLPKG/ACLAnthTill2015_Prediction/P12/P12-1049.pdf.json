{"title": [{"text": "A Statistical Model for Unsupervised and Semi-supervised Transliteration Mining", "labels": [], "entities": []}], "abstractContent": [{"text": "We propose a novel model to automatically extract transliteration pairs from parallel corpora.", "labels": [], "entities": []}, {"text": "Our model is efficient, language pair independent and mines transliteration pairs in a consistent fashion in both unsupervised and semi-supervised settings.", "labels": [], "entities": []}, {"text": "We model transliter-ation mining as an interpolation of translitera-tion and non-transliteration sub-models.", "labels": [], "entities": [{"text": "transliter-ation mining", "start_pos": 9, "end_pos": 32, "type": "TASK", "confidence": 0.8040543794631958}]}, {"text": "We evaluate on NEWS 2010 shared task data and on parallel corpora with competitive results.", "labels": [], "entities": [{"text": "NEWS 2010 shared task data", "start_pos": 15, "end_pos": 41, "type": "DATASET", "confidence": 0.9310120582580567}]}], "introductionContent": [{"text": "Transliteration mining is the extraction of transliteration pairs from unlabelled data.", "labels": [], "entities": [{"text": "Transliteration mining", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.9091967344284058}]}, {"text": "Most transliteration mining systems are built using labelled training data or using heuristics to extract transliteration pairs.", "labels": [], "entities": [{"text": "transliteration mining", "start_pos": 5, "end_pos": 27, "type": "TASK", "confidence": 0.9124860167503357}]}, {"text": "These systems are language pair dependent or require labelled information for training.", "labels": [], "entities": []}, {"text": "Our system extracts transliteration pairs in an unsupervised fashion.", "labels": [], "entities": []}, {"text": "It is also able to utilize labelled information if available, obtaining improved performance.", "labels": [], "entities": []}, {"text": "We present a novel model of transliteration mining defined as a mixture of a transliteration model and a non-transliteration model.", "labels": [], "entities": [{"text": "transliteration mining", "start_pos": 28, "end_pos": 50, "type": "TASK", "confidence": 0.901172012090683}]}, {"text": "The transliteration model is a joint source channel model ().", "labels": [], "entities": []}, {"text": "The non-transliteration model assumes no correlation between source and target word characters, and independently generates a source and a target word using two fixed unigram character models.", "labels": [], "entities": []}, {"text": "We use Expectation Maximization (EM) to learn parameters maximizing the likelihood of the interpolation of both sub-models.", "labels": [], "entities": [{"text": "Expectation Maximization (EM", "start_pos": 7, "end_pos": 35, "type": "TASK", "confidence": 0.7332878708839417}]}, {"text": "At test time, we label word pairs as transliterations if they have a higher probability assigned by the transliteration sub-model than by the non-transliteration sub-model.", "labels": [], "entities": []}, {"text": "We extend the unsupervised system to a semisupervised system by adding anew S-step to the EM algorithm.", "labels": [], "entities": []}, {"text": "The S-step takes the probability estimates from unlabelled data (computed in the Mstep) and uses them as a backoff distribution to smooth probabilities which were estimated from labelled data.", "labels": [], "entities": []}, {"text": "The smoothed probabilities are then used in the next E-step.", "labels": [], "entities": []}, {"text": "In this way, the parameters learned by EM are constrained to values which are close to those estimated from the labelled data.", "labels": [], "entities": []}, {"text": "We evaluate our unsupervised and semisupervised transliteration mining system on the datasets available from the NEWS 2010 shared task on transliteration mining ().", "labels": [], "entities": [{"text": "transliteration mining", "start_pos": 48, "end_pos": 70, "type": "TASK", "confidence": 0.774875819683075}, {"text": "NEWS 2010 shared task", "start_pos": 113, "end_pos": 134, "type": "DATASET", "confidence": 0.8954025208950043}, {"text": "transliteration mining", "start_pos": 138, "end_pos": 160, "type": "TASK", "confidence": 0.7248110771179199}]}, {"text": "We call this task NEWS10 later on.", "labels": [], "entities": [{"text": "NEWS10", "start_pos": 18, "end_pos": 24, "type": "DATASET", "confidence": 0.6475180983543396}]}, {"text": "Compared with a baseline unsupervised system our unsupervised system achieves up to 5% better F-measure.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 94, "end_pos": 103, "type": "METRIC", "confidence": 0.9966722726821899}]}, {"text": "On the NEWS10 dataset, our unsupervised system achieves an F-measure of up to 95.7%, and on three language pairs, it performs better than all systems which participated in NEWS10.", "labels": [], "entities": [{"text": "NEWS10 dataset", "start_pos": 7, "end_pos": 21, "type": "DATASET", "confidence": 0.9724693298339844}, {"text": "F-measure", "start_pos": 59, "end_pos": 68, "type": "METRIC", "confidence": 0.9995253086090088}, {"text": "NEWS10", "start_pos": 172, "end_pos": 178, "type": "DATASET", "confidence": 0.8918508291244507}]}, {"text": "We also evaluate our semi-supervised system which additionally uses the NEWS10 labelled data for training.", "labels": [], "entities": [{"text": "NEWS10 labelled data", "start_pos": 72, "end_pos": 92, "type": "DATASET", "confidence": 0.9233787854512533}]}, {"text": "It achieves an improvement of up to 3.7% F-measure over our unsupervised system.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 41, "end_pos": 50, "type": "METRIC", "confidence": 0.9996098875999451}]}, {"text": "Additional experiments on parallel corpora show that we are able to effectively mine transliteration pairs from very noisy data.", "labels": [], "entities": []}, {"text": "The paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 describes previous work.", "labels": [], "entities": []}, {"text": "Sections 3 and 4 define our unsupervised and semi-supervised models.", "labels": [], "entities": []}, {"text": "Section 5 presents the evaluation.", "labels": [], "entities": []}], "datasetContent": [{"text": "We evaluate our unsupervised system and semisupervised system on two tasks, NEWS10 and parallel corpora.", "labels": [], "entities": [{"text": "NEWS10", "start_pos": 76, "end_pos": 82, "type": "DATASET", "confidence": 0.8811190724372864}]}, {"text": "NEWS10 is a standard task on transliteration mining from WIL.", "labels": [], "entities": [{"text": "NEWS10", "start_pos": 0, "end_pos": 6, "type": "DATASET", "confidence": 0.965945303440094}, {"text": "transliteration mining", "start_pos": 29, "end_pos": 51, "type": "TASK", "confidence": 0.925314724445343}, {"text": "WIL", "start_pos": 57, "end_pos": 60, "type": "DATASET", "confidence": 0.8829811811447144}]}, {"text": "On NEWS10, we compare our results with the unsupervised mining system of, the best supervised and semi-supervised systems presented at NEWS10 () and the best supervised and semi-supervised results reported in the literature for the NEWS10 task.", "labels": [], "entities": [{"text": "NEWS10", "start_pos": 3, "end_pos": 9, "type": "DATASET", "confidence": 0.9476617574691772}, {"text": "NEWS10", "start_pos": 135, "end_pos": 141, "type": "DATASET", "confidence": 0.9706416130065918}]}, {"text": "For the challenging task of mining from parallel corpora, we use the English/Hindi and English/Arabic gold standard provided by to evaluate our results.", "labels": [], "entities": []}, {"text": "We conduct experiments on four language pairs: English/Arabic, English/Hindi, English/Tamil and English/Russian using data provided at NEWS10.", "labels": [], "entities": [{"text": "NEWS10", "start_pos": 135, "end_pos": 141, "type": "DATASET", "confidence": 0.9861217141151428}]}, {"text": "Every dataset contains training data, seed data and reference data.", "labels": [], "entities": []}, {"text": "The NEWS10 data consists of pairs of titles of the same Wikipedia pages written in different languages, which maybe transliterations or translations.", "labels": [], "entities": [{"text": "NEWS10 data", "start_pos": 4, "end_pos": 15, "type": "DATASET", "confidence": 0.9758481681346893}]}, {"text": "The seed data is a list of 1000 transliteration pairs provided to semi-supervised systems for initial training.", "labels": [], "entities": []}, {"text": "We use the seed data only in our semi-supervised system, and not in the unsupervised system.", "labels": [], "entities": []}, {"text": "The reference data is a small subset of the training data which is manually annotated with positive and negative examples.", "labels": [], "entities": []}, {"text": "We follow the procedure for creating the training data described in Section 5.1.1 and build a wordaligned list and a cross-product list from the parallel corpus.", "labels": [], "entities": []}, {"text": "We first train and test our unsupervised mining system on the word-aligned list and compare our results with Sajjad et al. shows the results.", "labels": [], "entities": []}, {"text": "Our unsupervised system achieves 0.6% and 1.8% higher F-measure than Sajjad et al. respectively.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 54, "end_pos": 63, "type": "METRIC", "confidence": 0.9993231296539307}]}, {"text": "The cross-product list is huge in comparison to the word-aligned list.", "labels": [], "entities": []}, {"text": "It is noisier than the word-   aligned list but has almost 100% recall of transliteration pairs.", "labels": [], "entities": [{"text": "recall", "start_pos": 64, "end_pos": 70, "type": "METRIC", "confidence": 0.9991735816001892}]}, {"text": "The English-Hindi cross-product list has almost 55% more transliteration pairs (412 types) than the word-aligned list (180 types).", "labels": [], "entities": []}, {"text": "We cannot report these numbers on the English/Arabic crossproduct list since the English/Arabic gold standard is built on the word-aligned list.", "labels": [], "entities": [{"text": "English/Arabic crossproduct list", "start_pos": 38, "end_pos": 70, "type": "DATASET", "confidence": 0.6114301264286042}]}, {"text": "In order to keep the experiment computationally inexpensive, we train our mining systems on the word-aligned list and test them on the cross-product list.", "labels": [], "entities": []}, {"text": "We also perform the first semi-supervised evaluation on this task.", "labels": [], "entities": []}, {"text": "For our semi-supervised system, we additionally use the English/Hindi and English/Arabic seed data provided by NEWS10.", "labels": [], "entities": [{"text": "English/Arabic seed data", "start_pos": 74, "end_pos": 98, "type": "DATASET", "confidence": 0.6400188326835632}, {"text": "NEWS10", "start_pos": 111, "end_pos": 117, "type": "DATASET", "confidence": 0.941191554069519}]}, {"text": "shows the results of our unsupervised and semi-supervised systems on the English/Hindi and English/Arabic parallel corpora.", "labels": [], "entities": []}, {"text": "Our unsupervised system achieves higher recall than our semi-supervised system but lower precision.", "labels": [], "entities": [{"text": "recall", "start_pos": 40, "end_pos": 46, "type": "METRIC", "confidence": 0.9995169639587402}, {"text": "precision", "start_pos": 89, "end_pos": 98, "type": "METRIC", "confidence": 0.9991047978401184}]}, {"text": "The semi-supervised system shows an improvement in F-measure for both language pairs.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 51, "end_pos": 60, "type": "METRIC", "confidence": 0.988520622253418}]}, {"text": "We looked into the errors made by our systems.", "labels": [], "entities": []}, {"text": "The mined transliteration pairs of our unsupervised system contains 65 and 111 close transliterations for the English/Hindi and English/Arabic task respectively.", "labels": [], "entities": []}, {"text": "The close transliterations only differ by one or two characters from correct transliterations.", "labels": [], "entities": []}, {"text": "We think these pairs provide transliteration information to the systems and help them to avoid problems with data sparseness.", "labels": [], "entities": []}, {"text": "Our semi-supervised system uses the seed data to identify close transliterations as non-transliterations and decreases the number of false positives.", "labels": [], "entities": []}, {"text": "They are reduced to 35 and 89 for English/Hindi and English/Arabic respectively.", "labels": [], "entities": []}, {"text": "The seed data and the training data used in the semi-supervised system are from different domains (Wikipedia and UN).", "labels": [], "entities": []}, {"text": "Seed data extracted from the same domain is likely to work better, resulting in even higher scores than we have reported.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Statistics of word-aligned and cross-product  list calculated from the NEWS10 dataset, before min- ing. EA is English/Arabic, EH is English/Hindi, ET is  English/Tamil and ER is English/Russian", "labels": [], "entities": [{"text": "NEWS10 dataset", "start_pos": 81, "end_pos": 95, "type": "DATASET", "confidence": 0.989422619342804}, {"text": "EA", "start_pos": 114, "end_pos": 116, "type": "METRIC", "confidence": 0.9887925982475281}, {"text": "ET", "start_pos": 157, "end_pos": 159, "type": "METRIC", "confidence": 0.9457910060882568}, {"text": "ER", "start_pos": 182, "end_pos": 184, "type": "METRIC", "confidence": 0.989384114742279}]}, {"text": " Table 2: F-measure results on NEWS10 datasets where  SJD is the unsupervised system of Sajjad11, O U is  our unsupervised system built on the cross-product list,  O S is our semi-supervised system, S Best is the best  NEWS10 system, GR is the supervised system of", "labels": [], "entities": [{"text": "F-measure", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9849143624305725}, {"text": "NEWS10 datasets", "start_pos": 31, "end_pos": 46, "type": "DATASET", "confidence": 0.9582104682922363}]}, {"text": " Table 3: Precision(P), Recall(R) and F-measure(F) of our  unsupervised and semi-supervised transliteration mining  systems on NEWS10 datasets", "labels": [], "entities": [{"text": "Precision(P)", "start_pos": 10, "end_pos": 22, "type": "METRIC", "confidence": 0.9302492439746857}, {"text": "Recall(R)", "start_pos": 24, "end_pos": 33, "type": "METRIC", "confidence": 0.9542723596096039}, {"text": "F-measure(F)", "start_pos": 38, "end_pos": 50, "type": "METRIC", "confidence": 0.9696484208106995}, {"text": "NEWS10 datasets", "start_pos": 127, "end_pos": 142, "type": "DATASET", "confidence": 0.9662213921546936}]}, {"text": " Table 7: Transliteration mining results of our unsuper- vised system and Sajjad11 system trained and tested  on the word-aligned list of English/Hindi and En- glish/Arabic parallel corpus", "labels": [], "entities": [{"text": "Transliteration mining", "start_pos": 10, "end_pos": 32, "type": "TASK", "confidence": 0.8186184763908386}]}, {"text": " Table 8: Transliteration mining results of our unsuper- vised and semi-supervised systems trained on the word- aligned list and tested on the cross-product list of En- glish/Hindi and English/Arabic parallel corpus", "labels": [], "entities": [{"text": "Transliteration mining", "start_pos": 10, "end_pos": 32, "type": "TASK", "confidence": 0.8458468914031982}]}]}