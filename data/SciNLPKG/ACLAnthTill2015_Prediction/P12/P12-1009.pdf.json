{"title": [{"text": "SITS: A Hierarchical Nonparametric Model using Speaker Identity for Topic Segmentation in Multiparty Conversations", "labels": [], "entities": [{"text": "Topic Segmentation", "start_pos": 68, "end_pos": 86, "type": "TASK", "confidence": 0.7669122517108917}]}], "abstractContent": [{"text": "One of the key tasks for analyzing conversational data is segmenting it into coherent topic segments.", "labels": [], "entities": []}, {"text": "However, most models of topic segmentation ignore the social aspect of conversations , focusing only on the words used.", "labels": [], "entities": [{"text": "topic segmentation", "start_pos": 24, "end_pos": 42, "type": "TASK", "confidence": 0.7190093547105789}]}, {"text": "We introduce a hierarchical Bayesian nonpara-metric model, Speaker Identity for Topic Seg-mentation (SITS), that discovers (1) the topics used in a conversation, (2) how these topics are shared across conversations, (3) when these topics shift, and (4) a person-specific tendency to introduce new topics.", "labels": [], "entities": []}, {"text": "We evaluate against current unsupervised segmenta-tion models to show that including person-specific information improves segmentation performance on meeting corpora and on political debates.", "labels": [], "entities": []}, {"text": "Moreover, we provide evidence that SITS captures an individual's tendency to introduce new topics in political contexts, via analysis of the 2008 US presidential debates and the television program Crossfire.", "labels": [], "entities": [{"text": "SITS", "start_pos": 35, "end_pos": 39, "type": "TASK", "confidence": 0.9388464689254761}, {"text": "Crossfire", "start_pos": 197, "end_pos": 206, "type": "DATASET", "confidence": 0.9059780836105347}]}], "introductionContent": [], "datasetContent": [{"text": "This section introduces the three corpora we use.", "labels": [], "entities": []}, {"text": "We preprocess the data to remove stopwords and remove turns containing fewer than five tokens.", "labels": [], "entities": []}, {"text": "In this section, we examine how well SITS can replicate annotations of when new topics are introduced.).", "labels": [], "entities": []}, {"text": "Both metrics measure the probability that two points in a document will be incorrectly separated by a segment boundary.", "labels": [], "entities": []}, {"text": "Both techniques consider all spans of length kin the document and count whether the two endpoints of the window are (im)properly segmented against the gold segmentation.", "labels": [], "entities": []}, {"text": "However, these metrics have drawbacks.", "labels": [], "entities": []}, {"text": "First, they require both hypothesized and reference segmentations to be binary.", "labels": [], "entities": []}, {"text": "Many algorithms (e.g., probabilistic approaches) give non-binary segmentations where candidate boundaries have real-valued scores (e.g., probability or confidence).", "labels": [], "entities": []}, {"text": "Thus, evaluation requires arbitrary thresholding to binarize soft scores.", "labels": [], "entities": []}, {"text": "To be fair, thresholds are set so the number of segments are equal to a predefined value (Purver et al.,;.", "labels": [], "entities": []}, {"text": "To overcome these limitations, we also use Earth Mover's Distance (EMD) (), a metric that measures the distance between two distributions.", "labels": [], "entities": [{"text": "Earth Mover's Distance (EMD)", "start_pos": 43, "end_pos": 71, "type": "METRIC", "confidence": 0.6516418584755489}]}, {"text": "The EMD is the minimal cost to transform one distribution into the other.", "labels": [], "entities": [{"text": "EMD", "start_pos": 4, "end_pos": 7, "type": "METRIC", "confidence": 0.998056173324585}]}, {"text": "Each segmentation can be considered a multi-dimensional distribution where each candidate boundary is a dimension.", "labels": [], "entities": []}, {"text": "In EMD, a distance function across features allows partial credit for \"near miss\" segment boundaries.", "labels": [], "entities": []}, {"text": "In addition, because EMD operates on distributions, we can compute the distance between non-binary hypothesized segmentations with binary or real-valued reference segmentations.", "labels": [], "entities": []}, {"text": "We use the FastEMD implementation ().", "labels": [], "entities": [{"text": "FastEMD implementation", "start_pos": 11, "end_pos": 33, "type": "DATASET", "confidence": 0.8844909071922302}]}, {"text": "Experimental Methods We applied the following methods to discover topic segmentations in a document: \u2022 TextTiling (Hearst, 1997) is one of the earliest generalpurpose topic segmentation algorithms, sliding a fixedwidth window to detect major changes in lexical similarity.", "labels": [], "entities": [{"text": "discover topic segmentations in a document", "start_pos": 57, "end_pos": 99, "type": "TASK", "confidence": 0.8142717580000559}, {"text": "generalpurpose topic segmentation", "start_pos": 152, "end_pos": 185, "type": "TASK", "confidence": 0.6561565200487772}]}, {"text": "\u2022 P-NoSpeaker-S: parametric version without speaker identity run on each conversation ( ) \u2022 P-NoSpeaker-M: parametric version without speaker identity run on all conversations \u2022 P-SITS: the parametric version of SITS with speaker identity run on all conversations \u2022 NP-HMM: the HMM-based nonparametric model which a single topic per turn.", "labels": [], "entities": []}, {"text": "This model can be considered a Sticky HDP-HMM () with speaker identity.", "labels": [], "entities": []}, {"text": "\u2022 NP-SITS: the nonparametric version of SITS with speaker identity run on all conversations.", "labels": [], "entities": []}, {"text": "Parameter Settings and Implementations In our experiment, all parameters of TextTiling are the same as in.", "labels": [], "entities": [{"text": "Parameter Settings and Implementations", "start_pos": 0, "end_pos": 38, "type": "TASK", "confidence": 0.6652352213859558}]}, {"text": "For statistical models, Gibbs sampling with 10 randomly initialized chains is used.", "labels": [], "entities": []}, {"text": "Initial hyperparameter values are sampled from U (0, 1) to favor sparsity; statistics are collected after 500 burn-in iterations with a lag of 25 iterations over a total of 5000 iterations; and slice sampling optimizes hyperparameters.", "labels": [], "entities": []}, {"text": "shows the performance of various models on the topic segmentation problem, using the ICSI corpus and the 2008 debates.", "labels": [], "entities": [{"text": "topic segmentation problem", "start_pos": 47, "end_pos": 73, "type": "TASK", "confidence": 0.8009698788324991}, {"text": "ICSI corpus and the 2008 debates", "start_pos": 85, "end_pos": 117, "type": "DATASET", "confidence": 0.8399086793263754}]}, {"text": "Consistent with previous results, probabilistic models outperform TextTiling.", "labels": [], "entities": []}, {"text": "In addition, among the probabilistic models, the models that had access to speaker information consistently segment better than those lacking such information, supporting our assertion that there is benefit to modeling conversation as asocial process.", "labels": [], "entities": []}, {"text": "Furthermore, NP-SITS outperforms NP-HMM in both experiments, suggesting that using a distribution over topics to turns is better than using a single topic.", "labels": [], "entities": []}, {"text": "This is consistent with parametric results reported in ).", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Example turns from the annotated 2008 election debates. The topics (T Q and T R ) are from the Policy  Agendas Topics Codebook which contains the following codes of topic: Macroeconomics (1), Housing &  Community Development (14), Government Operations (20).", "labels": [], "entities": [{"text": "Policy  Agendas Topics Codebook", "start_pos": 105, "end_pos": 136, "type": "DATASET", "confidence": 0.644322007894516}]}, {"text": " Table 2: Results on the topic segmentation task.  Lower is better. The parameter k is the window  size of the metrics P k and WindowDiff chosen to  replicate previous results.", "labels": [], "entities": [{"text": "topic segmentation task", "start_pos": 25, "end_pos": 48, "type": "TASK", "confidence": 0.7980905075867971}]}, {"text": " Table 4: Example of turns designated as a topic shift by SITS. Turns were chosen with speakers to give  examples of those with high topic shift tendency \u03c0.", "labels": [], "entities": [{"text": "SITS", "start_pos": 58, "end_pos": 62, "type": "DATASET", "confidence": 0.7858322262763977}]}, {"text": " Table 5: Top speakers by topic shift tendencies. We  mark hosts ( \u2020) and \"speakers\" who often (but not al- ways) appeared in clips ( \u2021). Apart from those groups,  speakers with the highest tendency were political  moderates.", "labels": [], "entities": []}]}