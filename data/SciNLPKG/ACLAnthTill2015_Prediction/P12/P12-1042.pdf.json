{"title": [], "abstractContent": [{"text": "The rapid and continuous growth of social networking sites has led to the emergence of many communities of communicating groups.", "labels": [], "entities": []}, {"text": "Many of these groups discuss ideological and political topics.", "labels": [], "entities": []}, {"text": "It is not uncommon that the participants in such discussions split into two or more subgroups.", "labels": [], "entities": []}, {"text": "The members of each subgroup share the same opinion toward the discussion topic and are more likely to agree with members of the same subgroup and disagree with members from opposing subgroups.", "labels": [], "entities": []}, {"text": "In this paper, we propose an unsupervised approach for automatically detecting discussant subgroups in online communities.", "labels": [], "entities": [{"text": "automatically detecting discussant subgroups in online communities", "start_pos": 55, "end_pos": 121, "type": "TASK", "confidence": 0.7265359248433795}]}, {"text": "We analyze the text exchanged between the participants of a discussion to identify the attitude they carry toward each other and towards the various aspects of the discussion topic.", "labels": [], "entities": []}, {"text": "We use attitude predictions to construct an attitude vector for each discussant.", "labels": [], "entities": []}, {"text": "We use clustering techniques to cluster these vectors and, hence, determine the subgroup membership of each participant.", "labels": [], "entities": []}, {"text": "We compare our methods to text clustering and other baselines, and show that our method achieves promising results.", "labels": [], "entities": [{"text": "text clustering", "start_pos": 26, "end_pos": 41, "type": "TASK", "confidence": 0.783452570438385}]}], "introductionContent": [{"text": "Online forums discussing ideological and political topics are common . When people discuss a disputed topic they usually split into subgroups.", "labels": [], "entities": []}, {"text": "The members of each subgroup carry the same opinion www.politicalforum.com, www.createdebate.com, www.forandagainst.com, etc toward the discission topic.", "labels": [], "entities": []}, {"text": "The member of a subgroup is more likely to show positive attitude to the members of the same subgroup, and negative attitude to the members of opposing subgroups.", "labels": [], "entities": []}, {"text": "For example, let us consider the following two snippets from a debate about the enforcement of anew immigration law in Arizona state in the United States: (1) Discussant 1: Arizona immigration law is good.", "labels": [], "entities": []}, {"text": "(2) Discussant 2: I totally disagree with you.", "labels": [], "entities": []}, {"text": "Arizona immigration law is blatant racism, and quite unconstitutional.", "labels": [], "entities": []}, {"text": "In (1), the writer is expressing positive attitude regarding the immigration law and negative attitude regarding illegal immigration.", "labels": [], "entities": []}, {"text": "The writer of (2) is expressing negative attitude towards the writer of (1) and negative attitude regarding the immigration law.", "labels": [], "entities": []}, {"text": "It is clear from this short dialog that the writer of (1) and the writer of (2) are members of two opposing subgroups.", "labels": [], "entities": []}, {"text": "Discussant 1 is supporting the new law, while Discussant 2 is against it.", "labels": [], "entities": []}, {"text": "In this paper, we present an unsupervised approach for determining the subgroup membership of each participant in a discussion.", "labels": [], "entities": []}, {"text": "We use linguistic techniques to identify attitude expressions, their polarities, and their targets.", "labels": [], "entities": []}, {"text": "The target of attitude could be another discussant or an entity mentioned in the discussion.", "labels": [], "entities": []}, {"text": "We use sentiment analysis techniques to identify opinion expressions.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 7, "end_pos": 25, "type": "TASK", "confidence": 0.9329423606395721}]}, {"text": "We use named en-tity recognition and noun phrase chunking to identify the entities mentioned in the discussion.", "labels": [], "entities": [{"text": "named en-tity recognition", "start_pos": 7, "end_pos": 32, "type": "TASK", "confidence": 0.7387114763259888}, {"text": "noun phrase chunking", "start_pos": 37, "end_pos": 57, "type": "TASK", "confidence": 0.6233491599559784}]}, {"text": "The opinion-target pairs are identified using a number of syntactic and semantic rules.", "labels": [], "entities": []}, {"text": "For each participant in the discussion, we construct a vector of attitude features.", "labels": [], "entities": []}, {"text": "We call this vector the discussant attitude profile.", "labels": [], "entities": []}, {"text": "The attitude profile of a discussant contains an entry for every other discussant and an entry for every entity mentioned in the discission.", "labels": [], "entities": []}, {"text": "We use clustering techniques to cluster the attitude vector space.", "labels": [], "entities": []}, {"text": "We use the clustering results to determine the subgroup structure of the discussion group and the subgroup membership of each participant.", "labels": [], "entities": []}, {"text": "The rest of this paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 examines the previous work.", "labels": [], "entities": []}, {"text": "We describe the data used in the paper in Section 2.4.", "labels": [], "entities": []}, {"text": "Section 3 presents our approach.", "labels": [], "entities": []}, {"text": "Experiments, results and analysis are presented in Section 4.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section, we present several levels of evaluation of our system.", "labels": [], "entities": []}, {"text": "First, we compare our system to baseline systems.", "labels": [], "entities": []}, {"text": "Second, we study how the choice of the clustering algorithm impacts the results.", "labels": [], "entities": []}, {"text": "Third, we study the impact of each component in our system on the performance.", "labels": [], "entities": []}, {"text": "All the results reported in this section that show difference in the performance are statistically significant at the 0.05 level (as indicated by a 2-tailed paired t-test).", "labels": [], "entities": []}, {"text": "Before describing the experiments and presenting the results, we first describe the evaluation metrics we use.", "labels": [], "entities": []}, {"text": "We use two evaluation metrics to evaluate subgroups detection accuracy: Purity and Entropy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 62, "end_pos": 70, "type": "METRIC", "confidence": 0.7806329727172852}, {"text": "Purity", "start_pos": 72, "end_pos": 78, "type": "METRIC", "confidence": 0.9674732089042664}, {"text": "Entropy", "start_pos": 83, "end_pos": 90, "type": "METRIC", "confidence": 0.9838815927505493}]}, {"text": "To compute Purity (), each cluster is assigned the class of the majority vote within the cluster, and then the accuracy of this assignment is measured by dividing the number of correctly assigned members by the total number of instances.", "labels": [], "entities": [{"text": "Purity", "start_pos": 11, "end_pos": 17, "type": "METRIC", "confidence": 0.9743837714195251}, {"text": "accuracy", "start_pos": 111, "end_pos": 119, "type": "METRIC", "confidence": 0.9992434978485107}]}, {"text": "It can be formally defined as: where \u2126 = {\u03c9 1 , \u03c9 2 , ..., \u03c9 k } is the set of clusters and C = {c 1 , c 2 , ..., c J } is the set of classes.", "labels": [], "entities": []}, {"text": "\u03c9 k is interpreted as the set of documents in \u03c9 k and c j as the set of documents inc j . The purity increases as the quality of clustering improves.", "labels": [], "entities": [{"text": "purity", "start_pos": 94, "end_pos": 100, "type": "METRIC", "confidence": 0.9980060458183289}]}, {"text": "The second metric is Entropy.", "labels": [], "entities": [{"text": "Entropy", "start_pos": 21, "end_pos": 28, "type": "METRIC", "confidence": 0.9662014245986938}]}, {"text": "The Entropy of a cluster reflects how the members of the k distinct subgroups are distributed within each resulting cluster; the global quality measure is computed by averaging the entropy of all clusters: (2) where P (i, j) is the probability of finding an element from the category i in the cluster j, n j is the number of items in cluster j, and n the total number of items in the distribution.", "labels": [], "entities": []}, {"text": "In contrast to purity, the entropy decreases as the quality of clustering improves.", "labels": [], "entities": []}, {"text": "In this subsection, we evaluate the impact of the different components in the pipeline on the system performance.", "labels": [], "entities": []}, {"text": "We do that by removing each component from the pipeline and measuring the change in performance.", "labels": [], "entities": []}, {"text": "We perform the following experiments: 1) We run the full system with all its components included (DAPC).", "labels": [], "entities": [{"text": "DAPC", "start_pos": 98, "end_pos": 102, "type": "METRIC", "confidence": 0.6983068585395813}]}, {"text": "2) We run the system and include only discussant-to-discussant attitude features in the attitude vectors (DAPC-DD).", "labels": [], "entities": []}, {"text": "3) We include only discussant-to-entity attitude features in the attitude vectors (DAPC-DE).", "labels": [], "entities": []}, {"text": "4) We include only sentiment features in the attitude vector; i.e. we exclude the interaction count features (DAPC-SE).", "labels": [], "entities": [{"text": "DAPC-SE", "start_pos": 110, "end_pos": 117, "type": "METRIC", "confidence": 0.7730560898780823}]}, {"text": "5) We include only interaction count features to the attitude vector; i.e. we exclude sentiment features (DAPC-INT).", "labels": [], "entities": [{"text": "DAPC-INT", "start_pos": 106, "end_pos": 114, "type": "METRIC", "confidence": 0.7958566546440125}]}, {"text": "6) We skip the anaphora resolution step in the entity identification component (DAPC-NO AR).", "labels": [], "entities": [{"text": "anaphora resolution", "start_pos": 15, "end_pos": 34, "type": "TASK", "confidence": 0.66696597635746}, {"text": "entity identification", "start_pos": 47, "end_pos": 68, "type": "TASK", "confidence": 0.698579952120781}, {"text": "DAPC-NO AR)", "start_pos": 80, "end_pos": 91, "type": "METRIC", "confidence": 0.8305447498957316}]}, {"text": "7) We only use named entity recognition to identify entity targets; i.e. we exclude the entities identified through noun phrasing chunking (DAPC-NER).", "labels": [], "entities": [{"text": "named entity recognition", "start_pos": 15, "end_pos": 39, "type": "TASK", "confidence": 0.7670035560925802}, {"text": "noun phrasing chunking", "start_pos": 116, "end_pos": 138, "type": "TASK", "confidence": 0.622463047504425}]}, {"text": "8) Finally, we only noun phrase chunking to identify entity targets (DAPC-NP).", "labels": [], "entities": [{"text": "noun phrase chunking", "start_pos": 20, "end_pos": 40, "type": "TASK", "confidence": 0.7078048586845398}]}, {"text": "In all these experiments k-means is used for clustering and the number of clusters is set as explained in the previous subsection.", "labels": [], "entities": []}, {"text": "The results show that all the components in the system contribute to better performance of the system.", "labels": [], "entities": []}, {"text": "We notice from the results that the performance of the system drops significantly if sentiment features are not included.", "labels": [], "entities": []}, {"text": "This is result corroborates our hypothesis that interaction features are not sufficient factors for detecting rift in discussion groups.", "labels": [], "entities": [{"text": "detecting rift in discussion groups", "start_pos": 100, "end_pos": 135, "type": "TASK", "confidence": 0.9202512264251709}]}, {"text": "Including interaction features improve the performance (although not by a big difference) because they help differentiate between the case where participants A and B never interacted with each other and the case where they interact several time but never posted text that indicate difference in opinion between them.", "labels": [], "entities": []}, {"text": "We also notice that the performance drops significantly in DAPC-DD and DAPC-DD which also supports our hypotheses that both the sentiment discussants show toward one another and the sentiment they show toward the aspects of the discussed topic are important for the task.", "labels": [], "entities": []}, {"text": "Although using both named entity recognition (NER) and noun phrase chunking achieves better results, it: Impact of system components on the performance can also be noted from the results that NER contributes more to the system performance.", "labels": [], "entities": [{"text": "named entity recognition (NER)", "start_pos": 20, "end_pos": 50, "type": "TASK", "confidence": 0.8007210691769918}, {"text": "noun phrase chunking", "start_pos": 55, "end_pos": 75, "type": "TASK", "confidence": 0.6191533207893372}]}, {"text": "Finally, the results support Jakob and Gurevych (2010) findings that anaphora resolution aids opinion mining systems.", "labels": [], "entities": [{"text": "anaphora resolution", "start_pos": 69, "end_pos": 88, "type": "TASK", "confidence": 0.7959752082824707}, {"text": "opinion mining", "start_pos": 94, "end_pos": 108, "type": "TASK", "confidence": 0.8356151282787323}]}], "tableCaptions": [{"text": " Table 2: Example threads from our three datasets", "labels": [], "entities": []}, {"text": " Table 5: Comparison to baseline systems", "labels": [], "entities": []}, {"text": " Table 6: Comparison of different clustering algorithms", "labels": [], "entities": []}, {"text": " Table 7: Impact of system components on the perfor- mance", "labels": [], "entities": []}]}