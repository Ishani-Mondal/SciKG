{"title": [], "abstractContent": [{"text": "This paper presents an extension of Chi-ang's hierarchical phrase-based (HPB) model, called Head-Driven HPB (HD-HPB), which incorporates head information in translation rules to better capture syntax-driven information , as well as improved reordering between any two neighboring non-terminals at any stage of a derivation to explore a larger reordering search space.", "labels": [], "entities": []}, {"text": "Experiments on Chinese-English translation on four NIST MT test sets show that the HD-HPB model significantly outperforms Chiang's model with average gains of 1.91 points absolute in BLEU.", "labels": [], "entities": [{"text": "NIST MT test sets", "start_pos": 51, "end_pos": 68, "type": "DATASET", "confidence": 0.9032649844884872}, {"text": "BLEU", "start_pos": 183, "end_pos": 187, "type": "METRIC", "confidence": 0.9963979721069336}]}], "introductionContent": [{"text": "Chiang's hierarchical phrase-based (HPB) translation model utilizes synchronous context free grammar (SCFG) for translation derivation and has been widely adopted in statistical machine translation (SMT).", "labels": [], "entities": [{"text": "phrase-based (HPB) translation", "start_pos": 22, "end_pos": 52, "type": "TASK", "confidence": 0.6773794174194336}, {"text": "translation derivation", "start_pos": 112, "end_pos": 134, "type": "TASK", "confidence": 0.9301728308200836}, {"text": "statistical machine translation (SMT)", "start_pos": 166, "end_pos": 203, "type": "TASK", "confidence": 0.790505642692248}]}, {"text": "Typically, such models define two types of translation rules: hierarchical (translation) rules which consist of both terminals and non-terminals, and glue (grammar) rules which combine translated phrases in a monotone fashion.", "labels": [], "entities": []}, {"text": "Due to lack of linguistic knowledge, Chiang's HPB model contains only one type of nonterminal symbol X, often making it difficult to select the most appropriate translation rules.", "labels": [], "entities": []}, {"text": "What is more, Chiang's HPB model suffers from limited phrase reordering combining translated phrases in a monotonic way with glue rules.", "labels": [], "entities": [{"text": "phrase reordering", "start_pos": 54, "end_pos": 71, "type": "TASK", "confidence": 0.7160656750202179}]}, {"text": "In addition, once a 1 Another non-terminal symbol S is used in glue rules.", "labels": [], "entities": []}, {"text": "glue rule is adopted, it requires all rules above it to be glue rules.", "labels": [], "entities": []}, {"text": "One important research question is therefore how to refine the non-terminal category X using linguistically motivated information: Zollmann and Venugopal (2006) (SAMT) e.g. use (partial) syntactic categories derived from CFG trees while use word tags, generated by either POS analysis or unsupervised word class induction.", "labels": [], "entities": []}, {"text": "use linguistic information of various granularities such as Phrase-Pair, Constituent, Concatenation of Constituents, and Partial Constituents, where applicable.", "labels": [], "entities": []}, {"text": "Inspired by previous work in parsing, our Head-Driven HPB (HD-HPB) model is based on the intuition that linguistic heads provide important information about a constituent or distributionally defined fragment, as in HPB.", "labels": [], "entities": [{"text": "parsing", "start_pos": 29, "end_pos": 36, "type": "TASK", "confidence": 0.9722221493721008}]}, {"text": "We identify heads using linguistically motivated dependency parsing, and use their POS to refine X.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 49, "end_pos": 67, "type": "TASK", "confidence": 0.7130549401044846}]}, {"text": "In addition HD-HPB provides flexible reordering rules freely mixing translation and reordering (including swap) at any stage in a derivation.", "labels": [], "entities": []}, {"text": "Different from the soft constraint modeling adopted in), our approach encodes syntactic information in translation rules.", "labels": [], "entities": []}, {"text": "However, the two approaches are not mutually exclusive, as we could also include a set of syntax-driven features into our translation model.", "labels": [], "entities": []}, {"text": "Our approach maintains the advantages of Chiang's HPB model while at the same time incorporating head information and flex- ible reordering in a derivation in a natural way.", "labels": [], "entities": [{"text": "Chiang's HPB model", "start_pos": 41, "end_pos": 59, "type": "DATASET", "confidence": 0.8103703111410141}]}, {"text": "Experiments on Chinese-English translation using four NIST MT test sets show that our HD-HPB model significantly outperforms Chiang's HPB as well as a SAMT-style refined version of HPB.", "labels": [], "entities": [{"text": "Chinese-English translation", "start_pos": 15, "end_pos": 42, "type": "TASK", "confidence": 0.6214421540498734}, {"text": "NIST MT test sets", "start_pos": 54, "end_pos": 71, "type": "DATASET", "confidence": 0.8964710086584091}, {"text": "Chiang's HPB", "start_pos": 125, "end_pos": 137, "type": "DATASET", "confidence": 0.5809327165285746}, {"text": "HPB", "start_pos": 181, "end_pos": 184, "type": "DATASET", "confidence": 0.9638357162475586}]}], "datasetContent": [{"text": "We evaluate the performance of our HD-HPB model and compare it with our implementation of Chiang's HPB model, a source-side SAMTstyle refined version of HPB (SAMT-HPB), and the Moses implementation of HPB.", "labels": [], "entities": [{"text": "Chiang's HPB model", "start_pos": 90, "end_pos": 108, "type": "DATASET", "confidence": 0.7679409235715866}, {"text": "HPB", "start_pos": 201, "end_pos": 204, "type": "DATASET", "confidence": 0.9597353339195251}]}, {"text": "For fair comparison, we adopt the same parameter settings for our HD-HPB and HPB systems, including initial phrase length (as 10) in training, the maximum number of non-terminals (as 2) in translation rules, maximum number of non-terminals plus terminals (as 5) on the source, beam threshold \u03b2 (as 10 \u22125 ) (to discard derivations with a score worse than \u03b2 times the best score in the same chart cell), beam size b (as 200) (i.e. each chart cell contains at most b derivations).", "labels": [], "entities": [{"text": "beam threshold \u03b2", "start_pos": 277, "end_pos": 293, "type": "METRIC", "confidence": 0.7902955810228983}]}, {"text": "For Moses HPB, we use \"grow-diag-final-and\" to obtain symmetric word alignments, 10 for the maximum phrase length, and the recommended default values for all other parameters.", "labels": [], "entities": [{"text": "Moses HPB", "start_pos": 4, "end_pos": 13, "type": "DATASET", "confidence": 0.8270435333251953}]}, {"text": "We train our model on a dataset with\u02dc1with\u02dc1.5M sentence pairs from the LDC dataset.", "labels": [], "entities": [{"text": "LDC dataset", "start_pos": 72, "end_pos": 83, "type": "DATASET", "confidence": 0.955324649810791}]}, {"text": "We use the 2002 NIST MT evaluation test data (878 sentence pairs) as the development data, and the-news NIST MT evaluation test data, and 616 sentence pairs, respectively) as the test data.", "labels": [], "entities": [{"text": "NIST MT evaluation test data", "start_pos": 16, "end_pos": 44, "type": "DATASET", "confidence": 0.8873417735099792}, {"text": "NIST MT evaluation test data", "start_pos": 104, "end_pos": 132, "type": "DATASET", "confidence": 0.9295795917510986}]}, {"text": "To find heads, we parse the source sentences with the Berkeley Parser 3 (Petrov and Klein, 2007) trained on Chinese TreeBank 6.0 and use the Penn2Malt toolkit 4 to obtain (unlabeled) dependency structures.", "labels": [], "entities": [{"text": "Chinese TreeBank 6.0", "start_pos": 108, "end_pos": 128, "type": "DATASET", "confidence": 0.8972256382306417}]}, {"text": "We obtain the word alignments by running GIZA++) on the corpus in both directions and applying \"grow-diag-final-and\" refinement (.", "labels": [], "entities": [{"text": "word alignments", "start_pos": 14, "end_pos": 29, "type": "TASK", "confidence": 0.6980655789375305}]}, {"text": "We use the SRI language modeling toolkit to train a 5-gram language model on the Xinhua portion of the Gigaword corpus and standard MERT to tune the feature weights on the development data.", "labels": [], "entities": [{"text": "SRI language modeling", "start_pos": 11, "end_pos": 32, "type": "TASK", "confidence": 0.6931558052698771}, {"text": "Gigaword corpus", "start_pos": 103, "end_pos": 118, "type": "DATASET", "confidence": 0.8076908588409424}, {"text": "MERT", "start_pos": 132, "end_pos": 136, "type": "METRIC", "confidence": 0.9739795327186584}]}, {"text": "For evaluation, the NIST BLEU script (version 12) with the default settings is used to calculate the BLEU scores.", "labels": [], "entities": [{"text": "NIST", "start_pos": 20, "end_pos": 24, "type": "DATASET", "confidence": 0.8209505081176758}, {"text": "BLEU", "start_pos": 25, "end_pos": 29, "type": "METRIC", "confidence": 0.9447823166847229}, {"text": "BLEU", "start_pos": 101, "end_pos": 105, "type": "METRIC", "confidence": 0.9980009198188782}]}, {"text": "To test whether a performance difference is statistically significant, we conduct significance tests following the paired bootstrap approach.", "labels": [], "entities": []}, {"text": "In this paper, '**' and '*' denote p-values less than 0.01 and in-between [0.01, 0.05), respectively.", "labels": [], "entities": []}, {"text": "lists the rule table sizes.", "labels": [], "entities": []}, {"text": "The full rule table size (including HD-HRs and NRRs) of our HD-HPB model is\u02dc1is\u02dc1.5 times that of Chiang's, largely due to refining the non-terminal symbol X in Chiang's model into head-informed ones in our model.", "labels": [], "entities": [{"text": "rule table size", "start_pos": 9, "end_pos": 24, "type": "METRIC", "confidence": 0.8196958502133688}]}, {"text": "It is also unsurprising, that the test set-filtered rule table size of our model is only\u02dc0only\u02dc0.7 times that of Chiang's: this is due to the fact that some of the refined translation rule patterns required by the test set are unattested in the training data.", "labels": [], "entities": []}, {"text": "Furthermore, the rule table size of NRRs is much smaller than that of HDHRs since a NRR contains only two non-terminals.", "labels": [], "entities": []}, {"text": "lists the translation performance with BLEU scores.", "labels": [], "entities": [{"text": "translation", "start_pos": 10, "end_pos": 21, "type": "TASK", "confidence": 0.9755046963691711}, {"text": "BLEU", "start_pos": 39, "end_pos": 43, "type": "METRIC", "confidence": 0.998445451259613}]}, {"text": "Note that our re-implementation of Chiang's original HPB model performs on a par with Moses HPB.", "labels": [], "entities": [{"text": "Chiang's original HPB model", "start_pos": 35, "end_pos": 62, "type": "DATASET", "confidence": 0.8026850581169128}, {"text": "Moses HPB", "start_pos": 86, "end_pos": 95, "type": "DATASET", "confidence": 0.640548586845398}]}, {"text": "shows that our HD-HPB model significantly outperforms Chiang's HPB model with an average improvement of 1.91 in BLEU (and similar improvements over Moses HPB).", "labels": [], "entities": [{"text": "BLEU", "start_pos": 112, "end_pos": 116, "type": "METRIC", "confidence": 0.9992231130599976}]}, {"text": "shows that the head-driven scheme outperforms a SAMT-style approach (for each test set p < 0.01), indicating that head information is more effective than (partial) CFG categories.", "labels": [], "entities": []}, {"text": "Taking lianming zhichi in as an example, HD-HPB labels the span VV, as lianming is dominated by zhichi, effecively ignoring lianming in the translation rule, while the SAMT label is ADVP:AD+VV 5 which is more susceptible to data sparsity.", "labels": [], "entities": []}, {"text": "In addition, SAMT resorts to X if a text span fails to satisify pre-defined categories.", "labels": [], "entities": [{"text": "SAMT", "start_pos": 13, "end_pos": 17, "type": "TASK", "confidence": 0.9596775770187378}]}, {"text": "Examining initial phrases 5 the constituency structure for lianming zhichi is (VP (ADVP (AD lianming)) (VP (VV zhichi) ...)).", "labels": [], "entities": []}, {"text": "extracted from the SAMT training data shows that 28% of them are labeled as X.", "labels": [], "entities": [{"text": "SAMT training data", "start_pos": 19, "end_pos": 37, "type": "DATASET", "confidence": 0.7355532050132751}]}, {"text": "In order to separate out the individual contributions of the novel HD-HRs and NRRs, we carryout an additional experiment (HD-HR+Glue) using HDHRs with monotonic glue rules only (adjusted to refined rule labels, but effectively switching off the extra reordering power of full NRRs).", "labels": [], "entities": []}, {"text": "shows that on average more than half of the improvement over HPB (Chiang and Moses) comes from the refined HD-HRs, the rest from NRRs.", "labels": [], "entities": [{"text": "HPB", "start_pos": 61, "end_pos": 64, "type": "DATASET", "confidence": 0.9254066944122314}]}, {"text": "Examining translation rules extracted from the training data shows that there are 72,366 types of non-terminals with respect to 33 types of POS tags.", "labels": [], "entities": []}, {"text": "On average each sentence employs 16.6/5.2 HDHRs/NRRs in our HD-HPB model, compared to 15.9/3.6 hierarchical rules/glue rules in Chiang's model, providing further indication of the importance of NRRs in translation.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Rule table sizes (in million) of different mod- els. Note: 1) For HD-HPB, the rule sizes separated by /  indicate HD-HRs and NRRs, respectively; 2) Except for  \"Total\", the figures correspond to rules filtered on the cor- responding test set.", "labels": [], "entities": [{"text": "Total", "start_pos": 171, "end_pos": 176, "type": "METRIC", "confidence": 0.9750040173530579}]}, {"text": " Table 3: BLEU (%) scores of different models. Note:  1) SAMT-HPB indicates our HD-HPB model with non- terminal scheme of Zollmann and Venugopal (2006);  2) HD-HR+Glue indicates our HD-HPB model replac- ing NRRs with glue rules; 3) Significance tests for  Moses HPB, HD-HPB, SAMT-HPB, and HD-HR+Glue  are done against HPB.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9996547698974609}, {"text": "Moses HPB", "start_pos": 256, "end_pos": 265, "type": "DATASET", "confidence": 0.8276585936546326}]}]}