{"title": [{"text": "Heuristic Cube Pruning in Linear Time", "labels": [], "entities": []}], "abstractContent": [{"text": "We propose a novel heuristic algorithm for Cube Pruning running in linear time in the beam size.", "labels": [], "entities": [{"text": "Cube Pruning", "start_pos": 43, "end_pos": 55, "type": "TASK", "confidence": 0.7630438208580017}]}, {"text": "Empirically, we show again in running time of a standard machine translation system, at a small loss inaccuracy.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 57, "end_pos": 76, "type": "TASK", "confidence": 0.7458539605140686}]}], "introductionContent": [{"text": "Since its first appearance in), the Cube Pruning (CP) algorithm has quickly gained popularity in statistical natural language processing.", "labels": [], "entities": [{"text": "statistical natural language processing", "start_pos": 97, "end_pos": 136, "type": "TASK", "confidence": 0.6961924284696579}]}, {"text": "Informally, this algorithm applies to scenarios in which we have the k-best solutions for two input sub-problems, and we need to compute the kbest solutions for the new problem representing the combination of the two sub-problems.", "labels": [], "entities": []}, {"text": "CP has applications in tree and phrase based machine translation, parsing), sentence alignment (, and in general in all systems combining inexact beam decoding with dynamic programming under certain monotonic conditions on the definition of the scores in the search space.", "labels": [], "entities": [{"text": "tree and phrase based machine translation", "start_pos": 23, "end_pos": 64, "type": "TASK", "confidence": 0.7299789190292358}, {"text": "sentence alignment", "start_pos": 76, "end_pos": 94, "type": "TASK", "confidence": 0.8154671490192413}]}, {"text": "Standard implementations of CP run in time O(k log(k)), with k being the size of the input/output beams).", "labels": [], "entities": []}, {"text": "Gesmundo and propose Faster CP (FCP) which optimizes the algorithm but keeps the O(k log(k)) time complexity.", "labels": [], "entities": [{"text": "Faster CP", "start_pos": 21, "end_pos": 30, "type": "METRIC", "confidence": 0.8949142694473267}, {"text": "O(k log(k)) time complexity", "start_pos": 81, "end_pos": 108, "type": "METRIC", "confidence": 0.9093118574884202}]}, {"text": "Here, we propose a novel heuristic algorithm for CP running in time O(k) and evaluate its impact on the efficiency and performance of a real-world machine translation system.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 147, "end_pos": 166, "type": "TASK", "confidence": 0.7188861966133118}]}], "datasetContent": [{"text": "We implement Linear CP (LCP) on top of Cdec (), a widely-used hierarchical MT system that includes implementations of standard CP and FCP algorithms.", "labels": [], "entities": [{"text": "MT", "start_pos": 75, "end_pos": 77, "type": "TASK", "confidence": 0.9282503724098206}]}, {"text": "The experiments were executed on the NIST 2003 Chinese-English parallel corpus.", "labels": [], "entities": [{"text": "NIST 2003 Chinese-English parallel corpus", "start_pos": 37, "end_pos": 78, "type": "DATASET", "confidence": 0.9683552265167237}]}, {"text": "The training corpus contains 239k sentence pairs.", "labels": [], "entities": []}, {"text": "A binary translation grammar was extracted using a suffix array rule extractor.", "labels": [], "entities": []}, {"text": "The model was tuned using MERT.", "labels": [], "entities": [{"text": "MERT", "start_pos": 26, "end_pos": 30, "type": "METRIC", "confidence": 0.7732980847358704}]}, {"text": "The algorithms are compared on the NIST-03 test set, which contains 919 sentence pairs.", "labels": [], "entities": [{"text": "NIST-03 test set", "start_pos": 35, "end_pos": 51, "type": "DATASET", "confidence": 0.9867904782295227}]}, {"text": "The features used are basic lexical features, word penalty and a 3-gram Language Model (Heafield, 2011).", "labels": [], "entities": []}, {"text": "Since we compare decoding algorithms on the same search space, the accuracy comparison is done in terms of search score.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 67, "end_pos": 75, "type": "METRIC", "confidence": 0.9994468092918396}]}, {"text": "For each algorithm we compute the average score of the best translation found for the test sentences.", "labels": [], "entities": []}, {"text": "In we plot the score-loss relative to standard CP average score.", "labels": [], "entities": [{"text": "CP average score", "start_pos": 47, "end_pos": 63, "type": "METRIC", "confidence": 0.8503379424413046}]}, {"text": "Note that the FCP loss is always < 3%, and the LCP loss is always < 7%.", "labels": [], "entities": [{"text": "FCP loss", "start_pos": 14, "end_pos": 22, "type": "METRIC", "confidence": 0.7954277992248535}, {"text": "LCP loss", "start_pos": 47, "end_pos": 55, "type": "METRIC", "confidence": 0.8345394730567932}]}, {"text": "The dotted line plots the loss of a baseline linear time heuristic algorithm which assumes that both input lists have constant slope, and that scans L along parallel lines whose steep is the ratio of the average slope of each input list.", "labels": [], "entities": []}, {"text": "The baseline greatly deteriorates the accuracy: this shows that finding a reasonable linear time heuristic algorithm is not trivial.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 38, "end_pos": 46, "type": "METRIC", "confidence": 0.999542236328125}]}, {"text": "We can assume a bounded loss inaccuracy, because for larger beam size all the algorithms tend to converge to exhaustive search.", "labels": [], "entities": []}, {"text": "We found that these differences in search score resulted in no significant variations in BLEU score (e.g. with k = 30, CP reaches 32.2 while LCP 32.3).", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 89, "end_pos": 99, "type": "METRIC", "confidence": 0.9855070412158966}]}, {"text": "The speed comparison is done in terms of algorithm run-time.", "labels": [], "entities": []}, {"text": "plots the relative speed gain of LCP over standard CP and over FCP.", "labels": [], "entities": [{"text": "FCP", "start_pos": 63, "end_pos": 66, "type": "DATASET", "confidence": 0.8847062587738037}]}, {"text": "Given the log-scale used for the beam size k, the linear shape of the speed gain over FCP (and CP) in empirically confirms that LCP has a log(k) asymptotic advantage over FCP and CP.", "labels": [], "entities": [{"text": "FCP", "start_pos": 86, "end_pos": 89, "type": "DATASET", "confidence": 0.8088873028755188}]}, {"text": "In addition to Chinese-English, we ran experiments on translating English to French (from Europarl corpus), and find that the LCP score-loss relative to CP is < 9% while the speed relative advantage of LCP over CP increases in average by 11.4% every time the beam size is multiplied by 10 (e.g. with k = 1000 the speed advantage is 34.3%).", "labels": [], "entities": [{"text": "Europarl corpus", "start_pos": 90, "end_pos": 105, "type": "DATASET", "confidence": 0.9910027384757996}, {"text": "LCP score-loss", "start_pos": 126, "end_pos": 140, "type": "METRIC", "confidence": 0.7675732970237732}]}, {"text": "These results confirm the bounded accuracy loss and log(k) speed advantage of LCP.", "labels": [], "entities": [{"text": "accuracy loss", "start_pos": 34, "end_pos": 47, "type": "METRIC", "confidence": 0.9910507798194885}, {"text": "speed", "start_pos": 59, "end_pos": 64, "type": "METRIC", "confidence": 0.6183602809906006}]}], "tableCaptions": []}