{"title": [{"text": "Learning Syntactic Verb Frames Using Graphical Models", "labels": [], "entities": []}], "abstractContent": [{"text": "We present a novel approach for building verb subcategorization lexicons using a simple graphical model.", "labels": [], "entities": []}, {"text": "In contrast to previous methods , we show how the model can be trained without parsed input or a predefined subcate-gorization frame inventory.", "labels": [], "entities": []}, {"text": "Our method out-performs the state-of-the-art on a verb clustering task, and is easily trained on arbitrary domains.", "labels": [], "entities": [{"text": "verb clustering task", "start_pos": 50, "end_pos": 70, "type": "TASK", "confidence": 0.7914753258228302}]}, {"text": "This quantitative evaluation is complemented by a qualitative discussion of verbs and their frames.", "labels": [], "entities": []}, {"text": "We discuss the advantages of graphical models for this task, in particular the ease of integrating semantic information about verbs and arguments in a principled fashion.", "labels": [], "entities": []}, {"text": "We conclude with future work to augment the approach.", "labels": [], "entities": []}], "introductionContent": [{"text": "Subcategorization frames (SCFs) give a compact description of a verb's syntactic preferences.", "labels": [], "entities": []}, {"text": "These two sentences have the same sequence of lexical syntactic categories (VP-NP-SCOMP), but the first is a simple transitive (\"X understood Y\"), while the second is a ditransitive with a sentential complement (\"X persuaded Y that Z\"): 1.", "labels": [], "entities": []}, {"text": "Kim (VP understood (NP the evidence (SCOMP that Sandy was present))) 2.", "labels": [], "entities": []}, {"text": "Kim (VP persuaded (NP the judge) (SCOMP that Sandy was present)) An SCF lexicon would indicate that \"persuade\" is likely to take a direct object and sentential complement (NP-SCOMP), while \"understand\" is more likely to take just a direct object (NP).", "labels": [], "entities": []}, {"text": "A comprehensive lexicon would also include semantic information about selectional preferences (or restrictions) on argument heads of verbs, diathesis alternations (i.e. semantically-motivated alternations between pairs of SCFs) and a mapping from surface frames to the underlying predicate-argument structure.", "labels": [], "entities": []}, {"text": "Information about verb subcategorization is useful for tasks like information extraction, verb clustering () and parsing).", "labels": [], "entities": [{"text": "information extraction", "start_pos": 66, "end_pos": 88, "type": "TASK", "confidence": 0.8243336975574493}, {"text": "verb clustering", "start_pos": 90, "end_pos": 105, "type": "TASK", "confidence": 0.7487290501594543}]}, {"text": "In general, tasks that depend on predicate-argument structure can benefit from a high-quality SCF lexicon ().", "labels": [], "entities": []}, {"text": "Large, manually-constructed SCF lexicons mostly target general language.", "labels": [], "entities": [{"text": "SCF lexicons", "start_pos": 28, "end_pos": 40, "type": "TASK", "confidence": 0.8892723023891449}]}, {"text": "However, in many domains verbs exhibit different syntactic behavior.", "labels": [], "entities": []}, {"text": "For example, the verb \"develop\" has specific usages in newswire, biomedicine and engineering that dramatically change its probability distribution over SCFs.", "labels": [], "entities": []}, {"text": "Ina few domains like biomedicine, the need for focused SCF lexicons has led to manually-built resources.", "labels": [], "entities": []}, {"text": "Such resources, however, are costly, prone to human error, and in domains where new lexical and syntactic constructs are frequently coined, quickly become obsolete).", "labels": [], "entities": []}, {"text": "Datadriven methods for SCF acquisition can alleviate these problems by building lexicons tailored to new domains with less manual effort, and higher coverage and scalability.", "labels": [], "entities": [{"text": "SCF acquisition", "start_pos": 23, "end_pos": 38, "type": "TASK", "confidence": 0.9901281297206879}]}, {"text": "Unfortunately, high quality SCF lexicons are difficult to build automatically.", "labels": [], "entities": [{"text": "SCF lexicons", "start_pos": 28, "end_pos": 40, "type": "TASK", "confidence": 0.9222823977470398}]}, {"text": "The argument-adjunct distinction is challenging even for humans, many SCFs have no reliable cues in data, and some SCFs (e.g. those involving control such as type raising) rely on semantic distinctions.", "labels": [], "entities": [{"text": "type raising", "start_pos": 158, "end_pos": 170, "type": "TASK", "confidence": 0.7414243668317795}]}, {"text": "As SCFs follow a Zipfian distribution (), many genuine frames are also low in frequency.", "labels": [], "entities": []}, {"text": "State-of-theart methods for building data-driven SCF lexicons typically rely on parsed input (see section 2).", "labels": [], "entities": []}, {"text": "However, the treebanks necessary for training a highaccuracy parsing model are expensive to build for new domains.", "labels": [], "entities": []}, {"text": "Moreover, while parsing may aid the detection of some frames, many experiments have also reported SCF errors due to noise from parsing (.", "labels": [], "entities": [{"text": "parsing", "start_pos": 16, "end_pos": 23, "type": "TASK", "confidence": 0.9714945554733276}]}, {"text": "Finally, many SCF acquisition methods operate with predefined SCF inventories.", "labels": [], "entities": [{"text": "SCF acquisition", "start_pos": 14, "end_pos": 29, "type": "TASK", "confidence": 0.9750601649284363}]}, {"text": "This subscribes to a single (often language or domain-specific) interpretation of subcategorization a priori, and ignores the ongoing debate on how this interpretation should be tailored to new domains and applications, such as the more prominent role of adjuncts in information extraction.", "labels": [], "entities": [{"text": "information extraction", "start_pos": 267, "end_pos": 289, "type": "TASK", "confidence": 0.8018328249454498}]}, {"text": "In this paper, we describe and evaluate a novel probabilistic data-driven method for SCF acquisition aimed at addressing some of the problems with current approaches.", "labels": [], "entities": [{"text": "SCF acquisition", "start_pos": 85, "end_pos": 100, "type": "TASK", "confidence": 0.9909150898456573}]}, {"text": "In our model, a Bayesian network describes how verbs choose their arguments in terms of a small number of frames, which are represented as distributions over syntactic relationships.", "labels": [], "entities": []}, {"text": "First, we show that by allowing the inference process to automatically define a probabilistic SCF inventory, we outperform systems with handcrafted rules and inventories, using identical syntactic features.", "labels": [], "entities": []}, {"text": "Second, by replacing the syntactic features with an approximation based on POS tags, we achieve state-of-the-art performance without relying on error-prone unlexicalized or domain-specific lexicalized parsers.", "labels": [], "entities": []}, {"text": "Third, we highlight a key advantage of our method compared to previous approaches: the ease of integrating and performing joint inference of additional syntactic and semantic information.", "labels": [], "entities": []}, {"text": "We describe how we plan to exploit this in our future research.", "labels": [], "entities": []}], "datasetContent": [{"text": "Quantitative: cluster gold standard Evaluating the output of unsupervised methods is not straightforward: discrete, expert-defined categories (like many SCF inventories) are unlikely to lineup perfectly with data-driven, probabilistic output.", "labels": [], "entities": []}, {"text": "Even if they do, finding a mapping between them is a problem of its own Our goal is to define a fair quantitative comparison between arbitrary SCF lexicons.", "labels": [], "entities": []}, {"text": "An SCF lexicon makes two claims: first, that it defines a reasonable SCF inventory.", "labels": [], "entities": []}, {"text": "Second, that for each verb, it has an accurate distribution over that inventory.", "labels": [], "entities": []}, {"text": "We therefore compare the lexicons based on their performance on a task that a good SCF lexicon should be useful for: clustering verbs into lexical-semantic classes.", "labels": [], "entities": []}, {"text": "Our gold standard is from, where 200 verbs were assigned to 17 classes based on their alternation patterns.", "labels": [], "entities": []}, {"text": "Previous work (Schulte im has demonstrated that the quality of an SCF lexicon's inventory and probability estimates corresponds to its predictive power for membership in such alternation classes.", "labels": [], "entities": []}, {"text": "To compare the performance of our feature sets, we chose the simple and familiar K-Means clustering algorithm.", "labels": [], "entities": []}, {"text": "The instances are the verbs' SCF distributions, and we select the number of clusters by the Silhouette validation technique.", "labels": [], "entities": []}, {"text": "The clusters are then compared to the gold standard clusters with the purity-based F-Score from and the more familiar Adjusted Rand Index.", "labels": [], "entities": [{"text": "F-Score", "start_pos": 83, "end_pos": 90, "type": "METRIC", "confidence": 0.8156722784042358}, {"text": "Adjusted Rand Index", "start_pos": 118, "end_pos": 137, "type": "DATASET", "confidence": 0.5227038164933523}]}, {"text": "Our main point of comparison is the VALEX lexicon of SCF distributions, whose scores we report alongside ours.", "labels": [], "entities": [{"text": "VALEX", "start_pos": 36, "end_pos": 41, "type": "METRIC", "confidence": 0.9627711772918701}]}], "tableCaptions": [{"text": " Table 1: Simplified CONLL format for example sen- tence \"We run training programmes in Romania and  other countries\". Head=0 indicates the token is the  root.", "labels": [], "entities": [{"text": "Head", "start_pos": 119, "end_pos": 123, "type": "METRIC", "confidence": 0.9319334626197815}]}, {"text": " Table 4: Task-based evaluation of lexicons acquired  with each of the eight feature types, and the state-of- the-art rule-based VALEX lexicon.", "labels": [], "entities": []}, {"text": " Table 5: Clusters (of size >2 and <20) produced  using tGR param,lex,lim", "labels": [], "entities": []}]}