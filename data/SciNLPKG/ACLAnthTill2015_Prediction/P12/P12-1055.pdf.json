{"title": [{"text": "Joint Inference of Named Entity Recognition and Normalization for Tweets", "labels": [], "entities": [{"text": "Joint Inference of Named Entity Recognition", "start_pos": 0, "end_pos": 43, "type": "TASK", "confidence": 0.5418097078800201}]}], "abstractContent": [{"text": "Tweets represent a critical source of fresh information , in which named entities occur frequently with rich variations.", "labels": [], "entities": []}, {"text": "We study the problem of named entity normalization (NEN) for tweets.", "labels": [], "entities": [{"text": "named entity normalization (NEN)", "start_pos": 24, "end_pos": 56, "type": "TASK", "confidence": 0.8028557499249777}]}, {"text": "Two main challenges are the errors propagated from named entity recognition (NER) and the dearth of information in a single tweet.", "labels": [], "entities": [{"text": "named entity recognition (NER)", "start_pos": 51, "end_pos": 81, "type": "TASK", "confidence": 0.8045367300510406}]}, {"text": "We propose a novel graphi-cal model to simultaneously conduct NER and NEN on multiple tweets to address these challenges.", "labels": [], "entities": []}, {"text": "Particularly, our model introduces a binary random variable for each pair of words with the same lemma across similar tweets, whose value indicates whether the two related words are mentions of the same entity.", "labels": [], "entities": []}, {"text": "We evaluate our method on a manually annotated data set, and show that our method outper-forms the baseline that handles these two tasks separately, boosting the F1 from 80.2% to 83.6% for NER, and the Accuracy from 79.4% to 82.6% for NEN, respectively.", "labels": [], "entities": [{"text": "F1", "start_pos": 162, "end_pos": 164, "type": "METRIC", "confidence": 0.9994376301765442}, {"text": "NER", "start_pos": 189, "end_pos": 192, "type": "DATASET", "confidence": 0.7795923948287964}, {"text": "Accuracy", "start_pos": 202, "end_pos": 210, "type": "METRIC", "confidence": 0.9995224475860596}, {"text": "NEN", "start_pos": 235, "end_pos": 238, "type": "DATASET", "confidence": 0.8169962763786316}]}], "introductionContent": [{"text": "Tweets, short messages of less than 140 characters shared through the Twitter service 1 , have become an important source of fresh information.", "labels": [], "entities": []}, {"text": "As a result, the task of named entity recognition (NER) for tweets, which aims to identify mentions of rigid designators from tweets belonging to named-entity types such as persons, organizations and locations, has attracted increasing research interest.", "labels": [], "entities": [{"text": "named entity recognition (NER)", "start_pos": 25, "end_pos": 55, "type": "TASK", "confidence": 0.8249858021736145}, {"text": "identify mentions of rigid designators from tweets belonging to named-entity types such as persons, organizations and locations", "start_pos": 82, "end_pos": 209, "type": "TASK", "confidence": 0.7161773078971438}]}, {"text": "For example, develop a system that exploits a CRF model to segment named 1 http://www.twitter.com entities and then uses a distantly supervised approach based on LabeledLDA to classify named entities.", "labels": [], "entities": []}, {"text": "combine a classifier based on the k-nearest neighbors algorithm with a CRFbased model to leverage cross tweets information, and adopt the semi-supervised learning to leverage unlabeled tweets.", "labels": [], "entities": []}, {"text": "However, named entity normalization (NEN) for tweets, which transforms named entities mentioned in tweets to their unambiguous canonical forms, has not been well studied.", "labels": [], "entities": [{"text": "named entity normalization (NEN)", "start_pos": 9, "end_pos": 41, "type": "TASK", "confidence": 0.7847817540168762}]}, {"text": "Owing to the informal nature of tweets, there are rich variations of named entities in them.", "labels": [], "entities": []}, {"text": "According to our investigation on the data set provided by, every named entity in tweets has an average of 3.3 variations 2 . As an illustrative example, we show \"Anneke Gronloh\", which may occur as \"Mw.,Gronloh\", \"Anneke Kronloh\" or \"Mevrouw G\".", "labels": [], "entities": []}, {"text": "We thus propose NEN for tweets, which plays an important role in entity retrieval, trend detection, and event and entity tracking.", "labels": [], "entities": [{"text": "entity retrieval", "start_pos": 65, "end_pos": 81, "type": "TASK", "confidence": 0.7335580587387085}, {"text": "trend detection", "start_pos": 83, "end_pos": 98, "type": "TASK", "confidence": 0.7205232828855515}, {"text": "event and entity tracking", "start_pos": 104, "end_pos": 129, "type": "TASK", "confidence": 0.6309654042124748}]}, {"text": "For example,  show that even a simple normalization method leads to improvements of early precision, for both document and passage retrieval, and better normalization results in better retrieval performance.", "labels": [], "entities": [{"text": "early", "start_pos": 84, "end_pos": 89, "type": "METRIC", "confidence": 0.9909470081329346}, {"text": "precision", "start_pos": 90, "end_pos": 99, "type": "METRIC", "confidence": 0.7637611031532288}, {"text": "document and passage retrieval", "start_pos": 110, "end_pos": 140, "type": "TASK", "confidence": 0.5623315945267677}]}, {"text": "Traditionally, NEN is regarded as a septated task, which takes the output of NER as its input (.", "labels": [], "entities": []}, {"text": "One limitation of this cascaded approach is that errors propagate from NER to NEN and there is no feedback from NEN to NER.", "labels": [], "entities": []}, {"text": "As demonstrated by , most NEN errors are caused by recognition errors.", "labels": [], "entities": []}, {"text": "Another challenge of NEN is the dearth of information in a single tweet, due to the short and noise-prone nature of tweets.", "labels": [], "entities": []}, {"text": "Reportedly, the accuracy of a baseline NEN system based on Wikipedia drops considerably from 94% on edited news to 77% on news comments, a kind of user generated content (UGC) with similar style to tweets . We propose jointly conducting NER and NEN on multiple tweets using a graphical model, to address these challenges.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 16, "end_pos": 24, "type": "METRIC", "confidence": 0.9996050000190735}]}, {"text": "Intuitively, improving the performance of NER boosts the performance of NEN.", "labels": [], "entities": [{"text": "NER", "start_pos": 42, "end_pos": 45, "type": "TASK", "confidence": 0.7784255743026733}]}, {"text": "For example, consider the following two tweets: \"\u00b7 \u00b7 \u00b7 Alex's jokes.", "labels": [], "entities": []}, {"text": "Max's randomnes\u00b7 \u00b7 \u00b7 \" and \"\u00b7 \u00b7 \u00b7 Alex Russo was like the best character on Disney Channel\u00b7 \u00b7 \u00b7 \".", "labels": [], "entities": []}, {"text": "Identifying \"Alex\" and \"Alex Russo\" as PERSON will encourage NEN systems to normalize \"Alex\" into \"Alex Russo\".", "labels": [], "entities": [{"text": "PERSON", "start_pos": 39, "end_pos": 45, "type": "METRIC", "confidence": 0.9312949180603027}]}, {"text": "On the other hand, NEN can guide NER.", "labels": [], "entities": [{"text": "NER", "start_pos": 33, "end_pos": 36, "type": "TASK", "confidence": 0.7742778658866882}]}, {"text": "For instance, consider the following two tweets: \"\u00b7 \u00b7 \u00b7 she knew Burger King when he was a Prince!\u00b7 \u00b7 \u00b7 \" and \"\u00b7 \u00b7 \u00b7 I'm craving all sorts of food: mcdonalds, burger king, pizza, chinese\u00b7 \u00b7 \u00b7 \".", "labels": [], "entities": []}, {"text": "Suppose the NEN system believes that \"burger king\" cannot be mapped to \"Burger King\" since these two tweets are not similar in content.", "labels": [], "entities": [{"text": "NEN", "start_pos": 12, "end_pos": 15, "type": "DATASET", "confidence": 0.8893259763717651}]}, {"text": "This will help NER to assign them different types of labels.", "labels": [], "entities": [{"text": "NER", "start_pos": 15, "end_pos": 18, "type": "TASK", "confidence": 0.9456658363342285}]}, {"text": "Our method optimizes these two tasks simultaneously by enabling them to interact with each other.", "labels": [], "entities": []}, {"text": "This largely differentiates our method from existing work.", "labels": [], "entities": []}, {"text": "Furthermore, considering multiple tweets simultaneously allows us to exploit the redundancy in tweets, as suggested by.", "labels": [], "entities": []}, {"text": "For example, consider the following two tweets: \"\u00b7 \u00b7 \u00b7 Bobby Shaw you don't invite the wind\u00b7 \u00b7 \u00b7 \" and \"\u00b7 \u00b7 \u00b7 I own yah ! Loool bobby shaw\u00b7 \u00b7 \u00b7 \".", "labels": [], "entities": []}, {"text": "Recognizing \"Bobby Shaw\" in the first tweet as a PERSON is easy owing to its capitalization and the following word \"you\", which in turn helps to identify \"bobby shaw\" in the second tweet as a PERSON.", "labels": [], "entities": [{"text": "PERSON", "start_pos": 49, "end_pos": 55, "type": "METRIC", "confidence": 0.8552798628807068}, {"text": "PERSON", "start_pos": 192, "end_pos": 198, "type": "DATASET", "confidence": 0.7180789709091187}]}, {"text": "We adopt a factor graph as our graphical model, which is constructed in the following manner.", "labels": [], "entities": []}, {"text": "We first introduce a random variable for each word in every tweet, which represents the BILOU (Beginning, the Inside and the Last tokens of multi-token entities as well as Unit-length entities) label of the corresponding word.", "labels": [], "entities": [{"text": "BILOU", "start_pos": 88, "end_pos": 93, "type": "METRIC", "confidence": 0.9988982677459717}]}, {"text": "Then we add a factor to connect two neighboring variables, forming a conventional linear chain CRFs.", "labels": [], "entities": []}, {"text": "Hereafter, we use t m to denote them th tweet ,t i m and y i m to denote the i th word of oft m and its BILOU label, respectively, and f i m to denote the factor related toy i\u22121 m and y i m . Next, for each word pair with the same lemma, denoted by ti m and t j n , we introduce a binary random variable, denoted by z ij mn , whose value indicates whether ti m and t j n belong to two mentions of the same entity.", "labels": [], "entities": [{"text": "BILOU", "start_pos": 104, "end_pos": 109, "type": "METRIC", "confidence": 0.9904048442840576}]}, {"text": "Finally, for any z ij mn we add a factor, denoted by f ij mn , to connect y i m , y j n and z ij mn . Factors in the same group ({f ij mn } or {f i m }) share the same set of feature templates.", "labels": [], "entities": []}, {"text": "illustrates an example of our factor graph for two tweets.", "labels": [], "entities": []}, {"text": "It is worth noting that our factor graph is different from the skip-chain CRFs () in the sense that any skip-chain factor of our model consists not only of two NE type variables (y i m and y j n ), which is the case for skip-chain CRFs, but also a normalization variable (z ij mn ).", "labels": [], "entities": []}, {"text": "It is these normalization variables that enable us to conduct NER and NEN jointly.", "labels": [], "entities": []}, {"text": "We manually add normalization information to the data set shared by, to evaluate our method.", "labels": [], "entities": []}, {"text": "Experimental results show that our method achieves 83.6% F1 for NER and 82.6% Accuracy for NEN, outperforming the baseline with 80.2%F1 for NER and 79.4% Accuracy for NEN.", "labels": [], "entities": [{"text": "F1", "start_pos": 57, "end_pos": 59, "type": "METRIC", "confidence": 0.9997169375419617}, {"text": "Accuracy", "start_pos": 78, "end_pos": 86, "type": "METRIC", "confidence": 0.9995943903923035}, {"text": "F1", "start_pos": 133, "end_pos": 135, "type": "METRIC", "confidence": 0.9976644515991211}, {"text": "Accuracy", "start_pos": 154, "end_pos": 162, "type": "METRIC", "confidence": 0.9990591406822205}]}, {"text": "We summarize our contributions as follows.", "labels": [], "entities": []}, {"text": "1. We introduce the task of NEN for tweets, and propose jointly conducting NER and NEN for multiple tweets using a factor graph, which leverages redundancy in tweets to makeup for the dearth of information in a single tweet and allows these two tasks to inform each other.", "labels": [], "entities": []}, {"text": "2. We evaluate our method on a human annotated data set, and show that our method compares favorably with the baseline, achieving better performance in both tasks.", "labels": [], "entities": []}, {"text": "Our paper is organized as follows.", "labels": [], "entities": []}, {"text": "In the next section, we introduce related work.", "labels": [], "entities": []}, {"text": "In Section 3 and 4, we formally define the task and present our method.", "labels": [], "entities": []}, {"text": "In Section 5, we evaluate our method.", "labels": [], "entities": []}, {"text": "And finally we conclude our work in Section 6.", "labels": [], "entities": []}], "datasetContent": [{"text": "We manually annotate a data set to evaluate our method.", "labels": [], "entities": []}, {"text": "We show that our method outperforms the baseline, a cascaded system that conducts NER and NEN individually.", "labels": [], "entities": []}, {"text": "We adopt the widely-used Precision, Recall and F1 to measure the performance of NER fora particular type of entity, and the average Precision, Recall and F1 to measure the overall performance of NER (.", "labels": [], "entities": [{"text": "Recall", "start_pos": 36, "end_pos": 42, "type": "METRIC", "confidence": 0.9172974228858948}, {"text": "F1", "start_pos": 47, "end_pos": 49, "type": "METRIC", "confidence": 0.9234225749969482}, {"text": "F1", "start_pos": 154, "end_pos": 156, "type": "METRIC", "confidence": 0.9746580719947815}]}, {"text": "As for NEN, we adopt the widely-used Accuracy, i.e., to what percentage the outputted canonical forms are correct ().", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 37, "end_pos": 45, "type": "METRIC", "confidence": 0.9989185333251953}]}], "tableCaptions": [{"text": " Table 1: Overall performance (%) of NER.", "labels": [], "entities": [{"text": "NER", "start_pos": 37, "end_pos": 40, "type": "TASK", "confidence": 0.8793768286705017}]}, {"text": " Table 2: Overall Accuracy (%) of NEN .", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 18, "end_pos": 26, "type": "METRIC", "confidence": 0.9826755523681641}, {"text": "NEN", "start_pos": 34, "end_pos": 37, "type": "TASK", "confidence": 0.5766423940658569}]}, {"text": " Table 3: F1 (%) of NER on different entity types.", "labels": [], "entities": [{"text": "F1", "start_pos": 10, "end_pos": 12, "type": "METRIC", "confidence": 0.9995225667953491}, {"text": "NER", "start_pos": 20, "end_pos": 23, "type": "TASK", "confidence": 0.843381941318512}]}, {"text": " Table 4: Overall F1 (%) of NER and Accuracy (%) of  NEN with different feature sets.", "labels": [], "entities": [{"text": "F1", "start_pos": 18, "end_pos": 20, "type": "METRIC", "confidence": 0.9997445940971375}, {"text": "Accuracy", "start_pos": 36, "end_pos": 44, "type": "METRIC", "confidence": 0.9991445541381836}]}]}