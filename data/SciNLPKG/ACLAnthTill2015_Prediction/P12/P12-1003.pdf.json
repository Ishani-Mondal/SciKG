{"title": [{"text": "Prediction of Learning Curves in Machine Translation", "labels": [], "entities": [{"text": "Machine Translation", "start_pos": 33, "end_pos": 52, "type": "TASK", "confidence": 0.7132584452629089}]}], "abstractContent": [{"text": "Parallel data in the domain of interest is the key resource when training a statistical machine translation (SMT) system fora specific purpose.", "labels": [], "entities": [{"text": "statistical machine translation (SMT)", "start_pos": 76, "end_pos": 113, "type": "TASK", "confidence": 0.7816093862056732}]}, {"text": "Since ad-hoc manual translation can represent a significant investment in time and money, a prior assesment of the amount of training data required to achieve a satisfactory accuracy level can be very useful.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 174, "end_pos": 182, "type": "METRIC", "confidence": 0.9920753240585327}]}, {"text": "In this work, we show how to predict what the learning curve would look like if we were to manually translate increasing amounts of data.", "labels": [], "entities": []}, {"text": "We consider two scenarios, 1) Monolingual samples in the source and target languages are available and 2) An additional small amount of parallel corpus is also available.", "labels": [], "entities": []}, {"text": "We propose methods for predicting learning curves in both these scenarios.", "labels": [], "entities": []}], "introductionContent": [{"text": "Parallel data in the domain of interest is the key resource when training a statistical machine translation (SMT) system fora specific business purpose.", "labels": [], "entities": [{"text": "statistical machine translation (SMT)", "start_pos": 76, "end_pos": 113, "type": "TASK", "confidence": 0.7774657060702642}]}, {"text": "In many cases it is possible to allocate some budget for manually translating a limited sample of relevant documents, be it via professional translation services or through increasingly fashionable crowdsourcing.", "labels": [], "entities": []}, {"text": "However, it is often difficult to predict how much training data will be required to achieve satisfactory translation accuracy, preventing sound provisional budgetting.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 118, "end_pos": 126, "type": "METRIC", "confidence": 0.8605806231498718}]}, {"text": "This prediction, or more generally the prediction of the learning curve of an SMT system as a function of available in-domain parallel data, is the objective of this paper.", "labels": [], "entities": [{"text": "SMT", "start_pos": 78, "end_pos": 81, "type": "TASK", "confidence": 0.9912234544754028}]}, {"text": "We consider two scenarios, representative of realistic situations.", "labels": [], "entities": []}, {"text": "1. In the first scenario (S1), the SMT developer is given only monolingual source and target samples from the relevant domain, and a small test parallel corpus.", "labels": [], "entities": [{"text": "SMT developer", "start_pos": 35, "end_pos": 48, "type": "TASK", "confidence": 0.9116111993789673}]}, {"text": "2. In the second scenario (S2), an additional small seed parallel corpus is given that can be used to train small in-domain models and measure (with some variance) the evaluation score at a few points on the initial portion of the learning curve.", "labels": [], "entities": []}, {"text": "In both cases, the task consists in predicting an evaluation score (BLEU, throughout this work) on the test corpus as a function of the size of a subset of the source sample, assuming that we could have it manually translated and use the resulting bilingual corpus for training.", "labels": [], "entities": [{"text": "predicting an evaluation score (", "start_pos": 36, "end_pos": 68, "type": "METRIC", "confidence": 0.6495115697383881}, {"text": "BLEU", "start_pos": 68, "end_pos": 72, "type": "METRIC", "confidence": 0.5102347731590271}]}, {"text": "In this paper we provide the following contributions: 1.", "labels": [], "entities": []}, {"text": "An extensive study across six parametric function families, empirically establishing that a certain three-parameter power-law family is well suited for modeling learning curves for the Moses SMT system when the evaluation score is BLEU.", "labels": [], "entities": [{"text": "SMT", "start_pos": 191, "end_pos": 194, "type": "TASK", "confidence": 0.8440085053443909}, {"text": "BLEU", "start_pos": 231, "end_pos": 235, "type": "METRIC", "confidence": 0.9977564215660095}]}, {"text": "Our methodology can be easily generalized to other systems and evaluation scores (Section 3); 2.", "labels": [], "entities": []}, {"text": "A method for inferring learning curves based on features computed from the resources available in scenario S1, suitable for both the scenarios described above (S1) and (S2) (Section 4); 3.", "labels": [], "entities": []}, {"text": "A method for extrapolating the learning curve from a few measurements, suitable for scenario S2 (Section 5); 4.", "labels": [], "entities": []}, {"text": "A method for combining the two approaches above, achieving on S2 better prediction accuracy than either of the two in isolation (Section 6).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 83, "end_pos": 91, "type": "METRIC", "confidence": 0.9673215746879578}]}, {"text": "In this study we limit tuning to the mixing parameters of the Moses log-linear model through MERT, keeping all meta-parameters (e.g. maximum phrase length, maximum allowed distortion, etc.) at their default values.", "labels": [], "entities": [{"text": "MERT", "start_pos": 93, "end_pos": 97, "type": "METRIC", "confidence": 0.8762325644493103}]}, {"text": "One can expect further tweaking to lead to performance improvements, but this was a necessary simplification in order to execute the tests on a sufficiently large scale.", "labels": [], "entities": []}, {"text": "Our experiments involve 30 distinct language pair and domain combinations and 96 different learning curves.", "labels": [], "entities": []}, {"text": "They show that without any parallel data we can predict the expected translation accuracy at 75K segments within an error of 6 BLEU points (Table 4), while using a seed training corpus of 10K segments narrows this error to within 1.5 points (Table 6).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 81, "end_pos": 89, "type": "METRIC", "confidence": 0.871368408203125}, {"text": "BLEU", "start_pos": 127, "end_pos": 131, "type": "METRIC", "confidence": 0.9984757304191589}]}], "datasetContent": [{"text": "In this section, we report the results of our experiments on predicting the learning curves.", "labels": [], "entities": []}, {"text": "In the case of inference from mostly monolingual data, the accuracy of the predictions at each of the anchor sizes is evaluated using root mean-squared error over the predictions obtained in a leave-oneout manner over the set of configurations from Table 2.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 59, "end_pos": 67, "type": "METRIC", "confidence": 0.9991674423217773}]}, {"text": "shows these results for Ridge and Lasso regression models at the three anchor sizes.", "labels": [], "entities": []}, {"text": "As an example, the model estimated using Lasso for the 75K anchor size exhibits a root mean squared error of 6 BLEU points.", "labels": [], "entities": [{"text": "75K anchor size", "start_pos": 55, "end_pos": 70, "type": "DATASET", "confidence": 0.880708634853363}, {"text": "root mean squared error", "start_pos": 82, "end_pos": 105, "type": "METRIC", "confidence": 0.7170508056879044}, {"text": "BLEU", "start_pos": 111, "end_pos": 115, "type": "METRIC", "confidence": 0.9965862035751343}]}, {"text": "The errors we obtain are lower than the error of the baseline consisting in taking, for each anchor size s j , the average of all the \u00b5 ctj . The Lasso regression model selected four features from the entire feature set: i) Size of the test set (sentences & tokens) ii) Perplexity of language model (order 5) on the test set iii) Type-token ratio of the target monolingual corpus . Feature correlation measures such as Pearsons R showed that the features corresponding to type-token ratios of both source and target languages and size of test set have a high correlation with the BLEU scores at the three anchor sizes.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 580, "end_pos": 584, "type": "METRIC", "confidence": 0.9992939233779907}]}, {"text": "shows an instance of the inferred learning curves obtained using a weighted least squares method on the predictions at the anchor sizes.", "labels": [], "entities": []}, {"text": "Table 7 presents the cumulative error of the inferred learning curves with respect to the gold curves, measured as the average distance between the curves in the range x \u2208 [0.1K, 100K].", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 3: Evaluation of the goodness of fit for the six fam- ilies.", "labels": [], "entities": [{"text": "Evaluation", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.8402443528175354}]}, {"text": " Table 4: Root mean squared error of the linear regression  models for each anchor size", "labels": [], "entities": [{"text": "Root mean squared error", "start_pos": 10, "end_pos": 33, "type": "METRIC", "confidence": 0.9106129556894302}]}, {"text": " Table 6: Root mean squared error of the combined curves  at the three anchor sizes", "labels": [], "entities": [{"text": "Root mean squared error", "start_pos": 10, "end_pos": 33, "type": "METRIC", "confidence": 0.9592790305614471}]}, {"text": " Table 7: Average distance of different predicted  learning curves relative to the gold curve. Columns:  IR=\"Inference using Ridge model\", IL=\"Inference  using Lasso model\", EC=\"Extrapolated curve\",  CR=\"Combined curve using Ridge\", CL=\"Combined  curve using", "labels": [], "entities": [{"text": "IR", "start_pos": 105, "end_pos": 107, "type": "METRIC", "confidence": 0.9982013702392578}]}]}