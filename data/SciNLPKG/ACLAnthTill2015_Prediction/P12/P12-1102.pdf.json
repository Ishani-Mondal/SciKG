{"title": [{"text": "Text Segmentation by Language Using Minimum Description Length", "labels": [], "entities": [{"text": "Text Segmentation", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.7003586739301682}]}], "abstractContent": [{"text": "The problem addressed in this paper is to segment a given multilingual document into segments for each language and then identify the language of each segment.", "labels": [], "entities": []}, {"text": "The problem was motivated by an attempt to collect a large amount of linguistic data for non-major languages from the web.", "labels": [], "entities": []}, {"text": "The problem is formulated in terms of obtaining the minimum description length of a text, and the proposed solution finds the segments and their languages through dynamic programming.", "labels": [], "entities": []}, {"text": "Empirical results demonstrating the potential of this approach are presented for experiments using texts taken from the Universal Declaration of Human Rights and Wikipedia, covering more than 200 languages.", "labels": [], "entities": [{"text": "Universal Declaration of Human Rights", "start_pos": 120, "end_pos": 157, "type": "DATASET", "confidence": 0.9147599458694458}]}], "introductionContent": [{"text": "For the purposes of this paper, a multilingual text means one containing text segments, limited to those longer than a clause, written in different languages.", "labels": [], "entities": []}, {"text": "We can often find such texts in linguistic resources collected from the World Wide Web for many nonmajor languages, which tend to also contain portions of text in a major language.", "labels": [], "entities": []}, {"text": "In automatic processing of such multilingual texts, they must first be segmented by language, and the language of each segment must be identified, since many state-of-the-art NLP applications are built by learning a gold standard for one specific language.", "labels": [], "entities": []}, {"text": "Moreover, segmentation is useful for other objectives such as collecting linguistic resources for non-major languages and automatically removing portions written in major languages, as noted above.", "labels": [], "entities": [{"text": "segmentation", "start_pos": 10, "end_pos": 22, "type": "TASK", "confidence": 0.9684354066848755}]}, {"text": "The study reported here was motivated by this objective.", "labels": [], "entities": []}, {"text": "The problem addressed in this article is thus to segment a multilingual text by language and identify the language of each segment.", "labels": [], "entities": []}, {"text": "In addition, for our objective, the set of target languages consists of not only major languages but also many non-major languages: more than 200 languages in total.", "labels": [], "entities": []}, {"text": "Previous work that directly concerns the problem addressed in this paper is rare.", "labels": [], "entities": []}, {"text": "The most similar previous work that we know of comes from two sources and can be summarized as follows.", "labels": [], "entities": []}, {"text": "First,) attempted to segment multilingual texts by using text segmentation methods used for non-segmented languages.", "labels": [], "entities": [{"text": "text segmentation", "start_pos": 57, "end_pos": 74, "type": "TASK", "confidence": 0.7346176505088806}]}, {"text": "For this purpose, he used a gold standard of multilingual texts annotated by borders and languages.", "labels": [], "entities": []}, {"text": "This segmentation approach is similar to that of word segmentation for nonsegmented texts, and he tested it on six different European languages.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 49, "end_pos": 66, "type": "TASK", "confidence": 0.7147645056247711}]}, {"text": "Although the problem setting is similar to ours, the formulation and solution are different, particularly in that our method uses only a monolingual gold standard, not a multilingual one as in Teahan's study.", "labels": [], "entities": []}, {"text": "Second,) () solved the problem of detecting words and phrases in languages other than the principal language of a given text.", "labels": [], "entities": [{"text": "detecting words and phrases in languages other than the principal language of a given text", "start_pos": 34, "end_pos": 124, "type": "TASK", "confidence": 0.7620021581649781}]}, {"text": "They used statistical language modeling and heuristics to detect foreign words and tested the case of English embedded in German texts.", "labels": [], "entities": []}, {"text": "They also reported that such processing would raise the performance of German parsers.", "labels": [], "entities": []}, {"text": "Here again, the problem setting is similar to ours but not exactly the same, since the embedded text portions were assumed to be words.", "labels": [], "entities": []}, {"text": "Moreover, the authors only tested for the specific language pair of English embedded in German texts.", "labels": [], "entities": []}, {"text": "In contrast, our work considers more than 200 languages, and the portions of embedded text are larger: up to the paragraph level to accommodate the reality of multilingual texts.", "labels": [], "entities": []}, {"text": "The extension of our work to address the foreign word detection problem would bean interesting future work.", "labels": [], "entities": [{"text": "foreign word detection problem", "start_pos": 41, "end_pos": 71, "type": "TASK", "confidence": 0.8065716326236725}]}, {"text": "From a broader view, the problem addressed in this paper is further related to two genres of previous work.", "labels": [], "entities": []}, {"text": "The first genre is text segmentation.", "labels": [], "entities": [{"text": "text segmentation", "start_pos": 19, "end_pos": 36, "type": "TASK", "confidence": 0.8412341773509979}]}, {"text": "Our problem can be situated as a sub-problem from the viewpoint of language change.", "labels": [], "entities": [{"text": "language change", "start_pos": 67, "end_pos": 82, "type": "TASK", "confidence": 0.700517550110817}]}, {"text": "A more common setting in the NLP context is segmentation into semantically coherent text portions, of which a representative method is text tiling as reported by).", "labels": [], "entities": [{"text": "segmentation into semantically coherent text portions", "start_pos": 44, "end_pos": 97, "type": "TASK", "confidence": 0.7924422919750214}]}, {"text": "There could be other possible bases for text segmentation, and our study, in away, could lead to generalizing the problem.", "labels": [], "entities": [{"text": "text segmentation", "start_pos": 40, "end_pos": 57, "type": "TASK", "confidence": 0.825011819601059}]}, {"text": "The second genre is classification, and the specific problem of text classification by language has drawn substantial attention).", "labels": [], "entities": [{"text": "classification", "start_pos": 20, "end_pos": 34, "type": "TASK", "confidence": 0.9776246547698975}, {"text": "text classification", "start_pos": 64, "end_pos": 83, "type": "TASK", "confidence": 0.6984090209007263}]}, {"text": "Current state-of-the-art solutions use machine learning methods for languages with abundant supervision, and the performance is usually high enough for practical use.", "labels": [], "entities": []}, {"text": "This article concerns that problem together with segmentation but has another particularity in aiming at classification into a substantial number of categories, i.e., more than 200 languages.", "labels": [], "entities": []}, {"text": "This means that the amount of training data has to remain small, so the methods to be adopted must take this point into consideration.", "labels": [], "entities": []}, {"text": "Among works on text classification into languages, our proposal is based on previous studies using cross-entropy such as) and.", "labels": [], "entities": [{"text": "text classification", "start_pos": 15, "end_pos": 34, "type": "TASK", "confidence": 0.7542440593242645}]}, {"text": "We explain these works in further detail in \u00a73.", "labels": [], "entities": []}, {"text": "This article presents one way to formulate the segmentation and identification problem as a combinatorial optimization problem; specifically, to find the set of segments and their languages that minimizes the description length of a given multilingual text.", "labels": [], "entities": [{"text": "segmentation and identification", "start_pos": 47, "end_pos": 78, "type": "TASK", "confidence": 0.8896728952725729}]}, {"text": "In the following, we describe the problem formulation and a solution to the problem, and then discuss the performance of our method.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Number of languages for each writing system", "labels": [], "entities": []}]}