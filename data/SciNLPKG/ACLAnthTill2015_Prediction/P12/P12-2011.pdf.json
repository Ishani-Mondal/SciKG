{"title": [{"text": "Pattern Learning for Relation Extraction with a Hierarchical Topic Model", "labels": [], "entities": [{"text": "Relation Extraction", "start_pos": 21, "end_pos": 40, "type": "TASK", "confidence": 0.936194121837616}]}], "abstractContent": [{"text": "We describe the use of a hierarchical topic model for automatically identifying syntactic and lexical patterns that explicitly state ontological relations.", "labels": [], "entities": []}, {"text": "We leverage distant supervision using relations from the knowledge base FreeBase, but do not require any manual heuristic nor manual seed list selections.", "labels": [], "entities": [{"text": "FreeBase", "start_pos": 72, "end_pos": 80, "type": "DATASET", "confidence": 0.9185673594474792}]}, {"text": "Results show that the learned patterns can be used to extract new relations with good precision .", "labels": [], "entities": [{"text": "precision", "start_pos": 86, "end_pos": 95, "type": "METRIC", "confidence": 0.9936707019805908}]}], "introductionContent": [{"text": "The detection of relations between entities for the automatic population of knowledge bases is very useful for solving tasks such as Entity Disambiguation, Information Retrieval and Question Answering.", "labels": [], "entities": [{"text": "Entity Disambiguation", "start_pos": 133, "end_pos": 154, "type": "TASK", "confidence": 0.8463977873325348}, {"text": "Information Retrieval", "start_pos": 156, "end_pos": 177, "type": "TASK", "confidence": 0.8134858906269073}, {"text": "Question Answering", "start_pos": 182, "end_pos": 200, "type": "TASK", "confidence": 0.8472949266433716}]}, {"text": "The availability of high-coverage, generalpurpose knowledge bases enable the automatic identification and disambiguation of entities in text and its applications (.", "labels": [], "entities": [{"text": "automatic identification and disambiguation of entities in text", "start_pos": 77, "end_pos": 140, "type": "TASK", "confidence": 0.7049152217805386}]}, {"text": "Most early works in this area were designed for supervised Information Extraction competitions such as MUC) and ACE), which rely on the availability of annotated data.", "labels": [], "entities": [{"text": "Information Extraction competitions", "start_pos": 59, "end_pos": 94, "type": "TASK", "confidence": 0.7527818183104197}, {"text": "MUC", "start_pos": 103, "end_pos": 106, "type": "DATASET", "confidence": 0.6832976937294006}]}, {"text": "Open Information Extraction started as an effort to approach relation extraction in * Work done during an internship at Google Zurich.", "labels": [], "entities": [{"text": "Open Information Extraction", "start_pos": 0, "end_pos": 27, "type": "TASK", "confidence": 0.700032631556193}, {"text": "relation extraction", "start_pos": 61, "end_pos": 80, "type": "TASK", "confidence": 0.8747489750385284}]}, {"text": "a completely unsupervised way, by learning regularities and patterns from the web.", "labels": [], "entities": []}, {"text": "Two example systems implementing this paradigm are TEXTRUN-NER () and REVERB).", "labels": [], "entities": [{"text": "TEXTRUN-NER", "start_pos": 51, "end_pos": 62, "type": "METRIC", "confidence": 0.8537130951881409}, {"text": "REVERB", "start_pos": 70, "end_pos": 76, "type": "METRIC", "confidence": 0.9803785681724548}]}, {"text": "These systems do not need any manual data or rules, but the relational facts they extract are not immediately disambiguated to entities and relations from a knowledge base.", "labels": [], "entities": []}, {"text": "A different family of unsupervised methods for relation extraction is unsupervised semantic parsing, which aims at clustering entity mentions and relation surface forms, thus generating a semantic representation of the texts on which inference maybe used.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 47, "end_pos": 66, "type": "TASK", "confidence": 0.8262285590171814}, {"text": "unsupervised semantic parsing", "start_pos": 70, "end_pos": 99, "type": "TASK", "confidence": 0.6793244779109955}, {"text": "clustering entity mentions and relation surface forms", "start_pos": 115, "end_pos": 168, "type": "TASK", "confidence": 0.8069794688905988}]}, {"text": "Some techniques that have been used are Markov Random Fields ( and Bayesian generative models).", "labels": [], "entities": []}, {"text": "These are quite powerful approaches but have very high computational requirements).", "labels": [], "entities": []}, {"text": "A good trade-off between fully supervised and fully unsupervised approaches is distant supervision, a semi-supervised procedure consisting of finding sentences that contain two entities whose relation we know, and using those sentences as training examples fora supervised classifier (.", "labels": [], "entities": []}, {"text": "A usual problem is that two related entities may co-occur in one sentence for many unrelated reasons.", "labels": [], "entities": []}, {"text": "For example, Barack Obama is the president of the United States, but not every sentence including the two entities supports and states this relation.", "labels": [], "entities": []}, {"text": "Much of the previous work uses heuristics, e.g. extracting sentences only from encyclopedic entries (), or syntactic restrictions on the sentences and the entity mentions (.", "labels": [], "entities": []}, {"text": "These are usually defined manually and may need to be adapted to different languages and domains.", "labels": [], "entities": []}, {"text": "Manually selected seeds can also be used.", "labels": [], "entities": []}, {"text": "The main contribution of this work is presenting a variant of distance supervision for relation extraction where we do not use heuristics in the selection of the training data.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 87, "end_pos": 106, "type": "TASK", "confidence": 0.927009791135788}]}, {"text": "Instead, we use topic models to discriminate between the patterns that are expressing the relation and those that are ambiguous and can be applied across relations.", "labels": [], "entities": []}, {"text": "In this way, high-precision extraction patterns can be learned without the need of any manual intervention.", "labels": [], "entities": []}], "datasetContent": [{"text": "Settings We use Freebase as our knowledge base.", "labels": [], "entities": [{"text": "Freebase", "start_pos": 16, "end_pos": 24, "type": "DATASET", "confidence": 0.9840514063835144}]}, {"text": "It can be freely downloaded . text corpus used contains 33 million English news articles that we downloaded between January 2004 and December 2011.", "labels": [], "entities": []}, {"text": "A random sample of 3M of them is used for building the document collections on which to train the topic models, and the remaining 30M is used for testing.", "labels": [], "entities": []}, {"text": "The corpus is preprocessed by identifying Freebase entity mentions, using an approach similar to, and parsing it with an inductive dependency parser).", "labels": [], "entities": []}, {"text": "From the three million training documents, a set of document collections (one per relation) has been generated, by considering the sentences that contain two entities which are related in FreeBase through any binary relation and restricting to high-frequency 200 relations.", "labels": [], "entities": []}, {"text": "Two ways of extracting patterns have been used: (a) Syntactic, taking the dependency path between the two entities, and (b) Intertext, taking the text between the two.", "labels": [], "entities": []}, {"text": "In both cases, a topic model has been trained to learn the probability of a relation given a pattern w: p(r|w).", "labels": [], "entities": []}, {"text": "For \u03bb we use symmetric Dirichlet priors \u03bb G = 0.1 and \u03bb D = \u03bb A = 0.001, following the intuition that for the background the probability mass across patterns should be more evenly distributed.", "labels": [], "entities": []}, {"text": "\u03b3 is set as, indicating in the prior that we expect more patterns to belong to the background and entity-pairspecific distributions due to the very noisy nature of the input data.", "labels": [], "entities": []}, {"text": "These values have not been tuned.", "labels": [], "entities": []}, {"text": "As a baseline, using the same training corpus, we have calculated p(r|w) using the maximum likelihood estimate: the number of times that a pattern w has been seen connecting two entities for which r holds divided by the total frequency of the pattern.", "labels": [], "entities": [{"text": "maximum likelihood estimate", "start_pos": 83, "end_pos": 110, "type": "METRIC", "confidence": 0.8490318258603414}]}, {"text": "Extractions evaluation The patterns have been applied to the 30 million documents left for testing.", "labels": [], "entities": []}, {"text": "For each pair of entities disambiguated as FreeBase entities, if they are connected through a known pattern, they are assigned arg max r p(r|w).", "labels": [], "entities": []}, {"text": "We have randomly sampled 4,000 such extractions and sent them to raters.", "labels": [], "entities": []}, {"text": "An extraction is to be judged correct if both it is correct in real life and the sentence from which it was extracted really supports it.", "labels": [], "entities": []}, {"text": "We have collected three ratings per example and taken the majority decision.", "labels": [], "entities": []}, {"text": "There was disagreement for 9.4% of the items on whether the sentence supports the relation, and for 20% of the items on whether the relation holds in the real world.", "labels": [], "entities": []}, {"text": "The results for different thresholds of p(r|w) are shown in.", "labels": [], "entities": []}, {"text": "As can be seen, the MLE baselines (in red with syntactic patterns and green with intertext) perform consistently worse than the models learned using the topic models (in pink and blue).", "labels": [], "entities": []}, {"text": "The difference in precision, aggregated across all relations, is statistically significant at 95% confidence for most of the thresholds.", "labels": [], "entities": [{"text": "precision", "start_pos": 18, "end_pos": 27, "type": "METRIC", "confidence": 0.9992086291313171}]}, {"text": "Extractions aggregation We can take advantage of redundancy on the web to calculate a support metric for the extractions.", "labels": [], "entities": []}, {"text": "In this experiment, for every extracted relation (r, e 1 , e 2 ), for every occurrence of a pattern w i connecting e 1 and e 2 , we add up p(r|w i ).", "labels": [], "entities": []}, {"text": "Extractions that are obtained many times and from high-precision patterns will rank higher.", "labels": [], "entities": []}, {"text": "describes the results of this aggregation.", "labels": [], "entities": []}, {"text": "We have considered the top four highest-frequency relations for people.", "labels": [], "entities": []}, {"text": "After aggregating all the extracted relations and ranking them by support, we have divided the evaluation set into two parts: (a) for relations that were not already in FreeBase, we evaluate the precision; (b) for extractions that were already in FreeBase, we take the top-confidence sentence identified and evaluate whether the sentence is providing support to the relation.", "labels": [], "entities": [{"text": "FreeBase", "start_pos": 169, "end_pos": 177, "type": "DATASET", "confidence": 0.9533798098564148}, {"text": "precision", "start_pos": 195, "end_pos": 204, "type": "METRIC", "confidence": 0.9991908669471741}, {"text": "FreeBase", "start_pos": 247, "end_pos": 255, "type": "DATASET", "confidence": 0.9679614901542664}]}, {"text": "For each of these, both syntactic patterns and intermediate-text patterns have been evaluated.", "labels": [], "entities": []}, {"text": "The results are very interesting: using syntax, Death place appears easy to extract new relations and to find support.", "labels": [], "entities": []}, {"text": "The patterns obtained are quite unambiguous, e.g. On the other hand, birthplace and nationality have very different results for new relation acquisition vs. finding sentence support for new relations.", "labels": [], "entities": [{"text": "relation acquisition", "start_pos": 132, "end_pos": 152, "type": "TASK", "confidence": 0.6896035075187683}]}, {"text": "The reason is that these relations are very correlated to other relations that we did not have in our training set.", "labels": [], "entities": []}, {"text": "In the case of birthplace, many relations refer to having an official position in the city, such as mayor; and for nationality, many of the patterns extract presidents or ministers.", "labels": [], "entities": []}, {"text": "Not having mayor or president in our initial collection (see), the support for these patterns is incorrectly learned.", "labels": [], "entities": []}, {"text": "In the case of nationality, however, even though the extracted sentences do not support the relation (P@50 = 0.34 for intertext), the new relations extracted are mostly correct (P@50 = 0.86) as most presidents and ministers in the real world have the nationality of the country where they govern.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Evaluation on aggregated extractions.", "labels": [], "entities": [{"text": "aggregated extractions", "start_pos": 24, "end_pos": 46, "type": "TASK", "confidence": 0.7254210710525513}]}]}