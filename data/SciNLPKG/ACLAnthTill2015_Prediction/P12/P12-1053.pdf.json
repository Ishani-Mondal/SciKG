{"title": [{"text": "Strong Lexicalization of Tree Adjoining Grammars", "labels": [], "entities": [{"text": "Lexicalization of Tree Adjoining Grammars", "start_pos": 7, "end_pos": 48, "type": "TASK", "confidence": 0.716557627916336}]}], "abstractContent": [{"text": "Recently, it was shown (KUHLMANN, SATTA: Tree-adjoining grammars are not closed under strong lexicalization.", "labels": [], "entities": [{"text": "SATTA", "start_pos": 34, "end_pos": 39, "type": "METRIC", "confidence": 0.8681726455688477}]}, {"text": "Linguist., 2012) that finitely ambiguous tree adjoining grammars cannot be transformed into a normal form (preserving the generated tree language), in which each production contains a lexical symbol.", "labels": [], "entities": []}, {"text": "A more powerful model, the simple context-free tree grammar, admits such a normal form.", "labels": [], "entities": []}, {"text": "It can be effectively constructed and the maximal rank of the non-terminals only increases by 1.", "labels": [], "entities": []}, {"text": "Thus, simple context-free tree grammars strongly lexicalize tree adjoining grammars and themselves.", "labels": [], "entities": []}], "introductionContent": [{"text": "Tree adjoining grammars () area mildly context-sensitive grammar formalism that can handle certain nonlocal dependencies (), which occur in several natural languages.", "labels": [], "entities": []}, {"text": "A good overview on TAG, their formal properties, their linguistic motivation, and their applications is presented by and, in which also strong lexicalization is discussed.", "labels": [], "entities": [{"text": "TAG", "start_pos": 19, "end_pos": 22, "type": "TASK", "confidence": 0.9770391583442688}]}, {"text": "In general, lexicalization is the process of transforming a grammar into an equivalent one (potentially expressed in another formalism) such that each production contains a lexical item (or anchor).", "labels": [], "entities": []}, {"text": "Each production can then be viewed as lexical information on its anchor.", "labels": [], "entities": []}, {"text": "It demonstrates a syntactical construction in which the anchor can occur.", "labels": [], "entities": []}, {"text": "Since a lexical item is a letter of the string * Financially supported by the German Research Foundation (DFG) grant MA 4959 / 1-1.", "labels": [], "entities": [{"text": "German Research Foundation (DFG) grant MA 4959 / 1-1", "start_pos": 78, "end_pos": 130, "type": "DATASET", "confidence": 0.8287769285115328}]}, {"text": "alphabet, each production of a lexicalized grammar produces at least one letter of the generated string.", "labels": [], "entities": []}, {"text": "Consequently, lexicalized grammars offer significant parsing benefits ( as the number of applications of productions (i.e., derivation steps) is clearly bounded by the length of the input string.", "labels": [], "entities": []}, {"text": "In addition, the lexical items in the productions guide the production selection in a derivation, which works especially well in scenarios with large alphabets.", "labels": [], "entities": []}, {"text": "The GREIBACH normal form) offers those benefits for context-free grammars, but it changes the parse trees.", "labels": [], "entities": [{"text": "GREIBACH", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.7659162282943726}]}, {"text": "Thus, we distinguish between two notions of equivalence: Weak equivalence () only requires that the generated string languages coincide, whereas strong equivalence requires that even the generated tree languages coincide.", "labels": [], "entities": []}, {"text": "Correspondingly, we obtain weak and strong lexicalization based on the required equivalence.", "labels": [], "entities": []}, {"text": "The GREIBACH normal form shows that CFG can weakly lexicalize themselves, but they cannot strongly lexicalize themselves.", "labels": [], "entities": [{"text": "GREIBACH", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.9921424388885498}, {"text": "CFG", "start_pos": 36, "end_pos": 39, "type": "DATASET", "confidence": 0.7779209017753601}]}, {"text": "It is a prominent feature of tree adjoining grammars that they can strongly lexicalize CFG), and it was claimed and widely believed that they can strongly lexicalize themselves.", "labels": [], "entities": [{"text": "CFG", "start_pos": 87, "end_pos": 90, "type": "DATASET", "confidence": 0.8457633256912231}]}, {"text": "Recently, proved that TAG actually cannot strongly lexicalize themselves.", "labels": [], "entities": []}, {"text": "In fact, they prove that TAG cannot even strongly lexicalize the weaker tree insertion grammars ().", "labels": [], "entities": []}, {"text": "However, TAG can weakly lexicalize themselves).", "labels": [], "entities": []}, {"text": "Simple (i.e., linear and nondeleting) context-free tree grammars area more powerful grammar formalism than TAG.", "labels": [], "entities": []}, {"text": "However, the monadic variant is strongly equivalent to a slightly extended version of TAG, which is called non-strict TAG (.", "labels": [], "entities": []}, {"text": "A GREIBACH normal form fora superclass of CFTG (viz., second-order abstract categorial grammars) was discussed by and.", "labels": [], "entities": [{"text": "GREIBACH", "start_pos": 2, "end_pos": 10, "type": "METRIC", "confidence": 0.9809369444847107}, {"text": "CFTG", "start_pos": 42, "end_pos": 46, "type": "DATASET", "confidence": 0.9411396384239197}]}, {"text": "In particular, they also demonstrate that monadic CFTG can strongly lexicalize regular tree grammars.", "labels": [], "entities": [{"text": "CFTG", "start_pos": 50, "end_pos": 54, "type": "DATASET", "confidence": 0.8369606733322144}]}, {"text": "CFTG are weakly equivalent to the simple macro grammars of, which area notational variant of the well-nested linear context-free rewriting systems (LCFRS) of and the well-nested multiple context-free grammars (MCFG) of.", "labels": [], "entities": [{"text": "CFTG", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.9433404803276062}]}, {"text": "Thus, CFTG are mildly context-sensitive since their generated string languages are semi-linear and can be parsed in polynomial time.", "labels": [], "entities": [{"text": "CFTG", "start_pos": 6, "end_pos": 10, "type": "DATASET", "confidence": 0.8438619375228882}]}, {"text": "In this contribution, we show that CFTG can strongly lexicalize TAG and also themselves, thus answering the second question in the conclusion of.", "labels": [], "entities": [{"text": "CFTG", "start_pos": 35, "end_pos": 39, "type": "DATASET", "confidence": 0.7793110013008118}]}, {"text": "This is achieved by a series of normalization steps (see Section 4) and a final lexicalization step (see Section 5), in which a lexical item is guessed for each production that does not already contain one.", "labels": [], "entities": []}, {"text": "This item is then transported in an additional argument until it is exchanged for the same item in a terminal production.", "labels": [], "entities": []}, {"text": "The lexicalization is effective and increases the maximal rank (number of arguments) of the nonterminals by at most 1.", "labels": [], "entities": []}, {"text": "In contrast to a transformation into GREIBACH normal form, our lexicalization does not radically change the structure of the derivations.", "labels": [], "entities": [{"text": "GREIBACH", "start_pos": 37, "end_pos": 45, "type": "METRIC", "confidence": 0.9213383793830872}]}, {"text": "Overall, our result shows that if we consider only lexicalization, then CFTG area more natural generalization of CFG than TAG.", "labels": [], "entities": [{"text": "CFTG", "start_pos": 72, "end_pos": 76, "type": "DATASET", "confidence": 0.7609007358551025}, {"text": "CFG", "start_pos": 113, "end_pos": 116, "type": "DATASET", "confidence": 0.9156072735786438}]}], "datasetContent": [], "tableCaptions": []}