{"title": [{"text": "Smaller Alignment Models for Better Translations: Unsupervised Word Alignment with the 0 -norm", "labels": [], "entities": [{"text": "Word Alignment", "start_pos": 63, "end_pos": 77, "type": "TASK", "confidence": 0.6685080826282501}]}], "abstractContent": [{"text": "Two decades after their invention, the IBM word-based translation models, widely available in the GIZA++ toolkit, remain the dominant approach to word alignment and an integral part of many statistical translation systems.", "labels": [], "entities": [{"text": "word-based translation", "start_pos": 43, "end_pos": 65, "type": "TASK", "confidence": 0.6006125807762146}, {"text": "word alignment", "start_pos": 146, "end_pos": 160, "type": "TASK", "confidence": 0.8046888411045074}, {"text": "statistical translation", "start_pos": 190, "end_pos": 213, "type": "TASK", "confidence": 0.7642787098884583}]}, {"text": "Although many models have surpassed them inaccuracy, none have supplanted them in practice.", "labels": [], "entities": []}, {"text": "In this paper, we propose a simple extension to the IBM models: an 0 prior to encourage sparsity in the word-to-word translation model.", "labels": [], "entities": [{"text": "word-to-word translation", "start_pos": 104, "end_pos": 128, "type": "TASK", "confidence": 0.7047316133975983}]}, {"text": "We explain how to implement this extension efficiently for large-scale data (also released as a modification to GIZA++) and demonstrate, in experiments on Czech, Ara-bic, Chinese, and Urdu to English translation, significant improvements over IBM Model 4 in both word alignment (up to +6.7 F1) and translation quality (up to +1.4 Bleu).", "labels": [], "entities": [{"text": "Chinese, and Urdu to English translation", "start_pos": 171, "end_pos": 211, "type": "TASK", "confidence": 0.7329189607075283}, {"text": "word alignment", "start_pos": 263, "end_pos": 277, "type": "TASK", "confidence": 0.7359722852706909}, {"text": "F1", "start_pos": 290, "end_pos": 292, "type": "METRIC", "confidence": 0.9952850937843323}, {"text": "Bleu", "start_pos": 330, "end_pos": 334, "type": "METRIC", "confidence": 0.984932005405426}]}], "introductionContent": [{"text": "Automatic word alignment is a vital component of nearly all current statistical translation pipelines.", "labels": [], "entities": [{"text": "Automatic word alignment", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.6156649688879648}, {"text": "statistical translation pipelines", "start_pos": 68, "end_pos": 101, "type": "TASK", "confidence": 0.7847372690836588}]}, {"text": "Although state-of-the-art translation models use rules that operate on units bigger than words (like phrases or tree fragments), they nearly always use word alignments to drive extraction of those translation rules.", "labels": [], "entities": []}, {"text": "The dominant approach to word alignment has been the IBM models together with the HMM model ().", "labels": [], "entities": [{"text": "word alignment", "start_pos": 25, "end_pos": 39, "type": "TASK", "confidence": 0.8317137956619263}]}, {"text": "These models are unsupervised, making them applicable to any language pair for which parallel text is available.", "labels": [], "entities": []}, {"text": "Moreover, they are widely disseminated in the open-source GIZA++ toolkit ().", "labels": [], "entities": []}, {"text": "These properties make them the default choice for most statistical MT systems.", "labels": [], "entities": [{"text": "MT", "start_pos": 67, "end_pos": 69, "type": "TASK", "confidence": 0.9033401608467102}]}, {"text": "In the decades since their invention, many models have surpassed them inaccuracy, but none has supplanted them in practice.", "labels": [], "entities": []}, {"text": "Some of these models are partially supervised, combining unlabeled parallel text with manually-aligned parallel text.", "labels": [], "entities": []}, {"text": "Although manually-aligned data is very valuable, it is only available fora small number of language pairs.", "labels": [], "entities": []}, {"text": "Other models are unsupervised like the IBM models (), but have not been as widely adopted as GIZA++ has.", "labels": [], "entities": []}, {"text": "In this paper, we propose a simple extension to the IBM/HMM models that is unsupervised like the IBM models, is as scalable as GIZA++ because it is implemented on top of GIZA++, and provides significant improvements in both alignment and translation quality.", "labels": [], "entities": [{"text": "IBM/HMM", "start_pos": 52, "end_pos": 59, "type": "DATASET", "confidence": 0.8649807572364807}, {"text": "translation", "start_pos": 238, "end_pos": 249, "type": "TASK", "confidence": 0.9234234094619751}]}, {"text": "It extends the IBM/HMM models by incorporating an 0 prior, inspired by the principle of minimum description length (, to encourage sparsity in the word-to-word translation model.", "labels": [], "entities": [{"text": "word-to-word translation", "start_pos": 147, "end_pos": 171, "type": "TASK", "confidence": 0.6958046853542328}]}, {"text": "This extension follows our previous work on unsupervised part-ofspeech tagging (, but enables it to scale to the large datasets typical in word alignment, using an efficient training method based on projected gradient descent (Section 2.3).", "labels": [], "entities": [{"text": "part-ofspeech tagging", "start_pos": 57, "end_pos": 78, "type": "TASK", "confidence": 0.6558974534273148}, {"text": "word alignment", "start_pos": 139, "end_pos": 153, "type": "TASK", "confidence": 0.7932040989398956}]}, {"text": "Experiments on Czech-, Arabic-, Chinese-and UrduEnglish translation (Section 3) demonstrate consistent significant improvements over IBM Model 4 in both word alignment (up to +6.7 F1) and translation quality (up to +1.4 Bleu).", "labels": [], "entities": [{"text": "Czech-, Arabic-, Chinese-and UrduEnglish translation", "start_pos": 15, "end_pos": 67, "type": "TASK", "confidence": 0.5125036305851407}, {"text": "word alignment", "start_pos": 153, "end_pos": 167, "type": "TASK", "confidence": 0.7095836251974106}, {"text": "F1", "start_pos": 180, "end_pos": 182, "type": "METRIC", "confidence": 0.9937717318534851}, {"text": "Bleu", "start_pos": 220, "end_pos": 224, "type": "METRIC", "confidence": 0.9876347184181213}]}, {"text": "Our implementation has been released as a simple modification to the GIZA++ toolkit that can be used as a drop-in replacement for GIZA++ in any existing MT pipeline.", "labels": [], "entities": [{"text": "GIZA++ toolkit", "start_pos": 69, "end_pos": 83, "type": "DATASET", "confidence": 0.9032084743181864}, {"text": "MT pipeline", "start_pos": 153, "end_pos": 164, "type": "TASK", "confidence": 0.7860694825649261}]}], "datasetContent": [{"text": "To demonstrate the effect of the 0 -norm on the IBM models, we performed experiments on four translation tasks: Arabic-English, Chinese-English, and Urdu-English from the NIST Open MT Evaluation, and the Czech-English translation from the Workshop on Machine Translation (WMT) shared task.", "labels": [], "entities": [{"text": "NIST Open MT Evaluation", "start_pos": 171, "end_pos": 194, "type": "DATASET", "confidence": 0.818585067987442}, {"text": "Workshop on Machine Translation (WMT) shared task", "start_pos": 239, "end_pos": 288, "type": "TASK", "confidence": 0.8215539521641202}]}, {"text": "We measured the accuracy of word alignments generated by GIZA++ with and without the 0 -norm, and also translation accuracy of systems trained using the word alignments.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 16, "end_pos": 24, "type": "METRIC", "confidence": 0.9992614388465881}, {"text": "word alignments generated", "start_pos": 28, "end_pos": 53, "type": "TASK", "confidence": 0.7500587304433187}, {"text": "accuracy", "start_pos": 115, "end_pos": 123, "type": "METRIC", "confidence": 0.8970366716384888}]}, {"text": "Across all tests, we found strong improvements from adding the 0 -norm.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Adding the 0 -norm to the IBM models improves both alignment and translation accuracy across four different  language pairs. The word trans column also shows that the number of distinct word translations (i.e., the size of the  lexical weighting table) is reduced. The\u02dc\u03c6The\u02dc The\u02dc\u03c6 sing. column shows the average fertility of once-seen source words. For  Czech-English, the year refers to the WMT shared task; for all other language pairs, the year refers to the NIST Open  MT Evaluation.  *  Half of this test set was also used for tuning feature weights.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 87, "end_pos": 95, "type": "METRIC", "confidence": 0.8546926379203796}, {"text": "WMT shared task", "start_pos": 402, "end_pos": 417, "type": "TASK", "confidence": 0.66975337266922}, {"text": "NIST Open  MT Evaluation", "start_pos": 472, "end_pos": 496, "type": "DATASET", "confidence": 0.7029131799936295}]}, {"text": " Table 2: Almost all hyperparameter settings achieve higher F-scores than the baseline IBM Model 4 and HMM model  for Arabic-English alignment (\u03b1 = 0).", "labels": [], "entities": [{"text": "F-scores", "start_pos": 60, "end_pos": 68, "type": "METRIC", "confidence": 0.9977847933769226}, {"text": "Arabic-English alignment", "start_pos": 118, "end_pos": 142, "type": "TASK", "confidence": 0.66842220723629}]}, {"text": " Table 3: Adding word classes improves the F-score in  both directions for Arabic-English alignment by a little,  for the baseline system more so than ours.", "labels": [], "entities": [{"text": "F-score", "start_pos": 43, "end_pos": 50, "type": "METRIC", "confidence": 0.9984766840934753}, {"text": "Arabic-English alignment", "start_pos": 75, "end_pos": 99, "type": "TASK", "confidence": 0.6238729804754257}]}, {"text": " Table 4: Optimizing hyperparameters on alignment F1  score does not necessarily lead to optimal Bleu. The  first two columns indicate whether we used the first-or  second-best alignments in each direction (according to  F1); the third column shows the F1 of the symmetrized  alignments, whose corresponding Bleu scores are shown  in the last two columns.", "labels": [], "entities": [{"text": "F1  score", "start_pos": 50, "end_pos": 59, "type": "METRIC", "confidence": 0.9309379756450653}, {"text": "Bleu", "start_pos": 97, "end_pos": 101, "type": "METRIC", "confidence": 0.9750165939331055}, {"text": "F1", "start_pos": 221, "end_pos": 223, "type": "METRIC", "confidence": 0.9920856356620789}, {"text": "F1", "start_pos": 253, "end_pos": 255, "type": "METRIC", "confidence": 0.9957707524299622}, {"text": "Bleu", "start_pos": 308, "end_pos": 312, "type": "METRIC", "confidence": 0.9752172231674194}]}]}