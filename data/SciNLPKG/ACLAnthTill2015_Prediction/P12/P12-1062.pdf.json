{"title": [], "abstractContent": [{"text": "In recent years, error mining approaches were developed to help identify the most likely sources of parsing failures in parsing systems using handcrafted grammars and lexicons.", "labels": [], "entities": [{"text": "error mining", "start_pos": 17, "end_pos": 29, "type": "TASK", "confidence": 0.7176313102245331}]}, {"text": "However the techniques they use to enumerate and count n-grams builds on the sequential nature of a text corpus and do not easily extend to structured data.", "labels": [], "entities": []}, {"text": "In this paper, we propose an algorithm for mining trees and apply it to detect the most likely sources of generation failure.", "labels": [], "entities": []}, {"text": "We show that this tree mining algorithm permits identifying not only errors in the generation system (grammar, lexicon) but also mismatches between the structures contained in the input and the input structures expected by our generator as well as a few id-iosyncrasies/error in the input data.", "labels": [], "entities": []}], "introductionContent": [{"text": "In recent years, error mining techniques have been developed to help identify the most likely sources of parsing failure; Sagot and de la).", "labels": [], "entities": [{"text": "error mining", "start_pos": 17, "end_pos": 29, "type": "TASK", "confidence": 0.6594931781291962}, {"text": "parsing", "start_pos": 105, "end_pos": 112, "type": "TASK", "confidence": 0.9663497805595398}]}, {"text": "First, the input data (text) is separated into two subcorpora, a corpus of sentences that could be parsed (PASS) and a corpus of sentences that failed to be parsed (FAIL).", "labels": [], "entities": [{"text": "PASS", "start_pos": 107, "end_pos": 111, "type": "METRIC", "confidence": 0.9401363134384155}, {"text": "FAIL", "start_pos": 165, "end_pos": 169, "type": "METRIC", "confidence": 0.9829040169715881}]}, {"text": "For each n-gram of words (and/or part of speech tag) occurring in the corpus to be parsed, a suspicion rate is then computed which, in essence, captures the likelihood that this n-gram causes parsing to fail.", "labels": [], "entities": [{"text": "suspicion rate", "start_pos": 93, "end_pos": 107, "type": "METRIC", "confidence": 0.904704749584198}, {"text": "parsing", "start_pos": 192, "end_pos": 199, "type": "TASK", "confidence": 0.9647369980812073}]}, {"text": "These error mining techniques have been applied with good results on parsing output and shown to help improve the large scale symbolic grammars and lexicons used by the parser.", "labels": [], "entities": [{"text": "error mining", "start_pos": 6, "end_pos": 18, "type": "TASK", "confidence": 0.708515927195549}, {"text": "parsing output", "start_pos": 69, "end_pos": 83, "type": "TASK", "confidence": 0.893973171710968}]}, {"text": "However the techniques they use (e.g., suffix arrays) to enumerate and count n-grams builds on the sequential nature of a text corpus and cannot easily extend to structured data.", "labels": [], "entities": []}, {"text": "There are some NLP applications though where the processed data is structured data such as trees or graphs and which would benefit from error mining.", "labels": [], "entities": [{"text": "error mining", "start_pos": 136, "end_pos": 148, "type": "TASK", "confidence": 0.7108626514673233}]}, {"text": "For instance, when generating sentences from dependency trees, as was proposed recently in the Generation Challenge Surface Realisation Task (SR Task,), it would be useful to be able to apply error mining on the input trees to find the most likely causes of generation failure.", "labels": [], "entities": [{"text": "Generation Challenge Surface Realisation Task (SR Task", "start_pos": 95, "end_pos": 149, "type": "TASK", "confidence": 0.7421908862888813}]}, {"text": "In this paper, we address this issue and propose an approach that supports error mining on trees.", "labels": [], "entities": [{"text": "error mining", "start_pos": 75, "end_pos": 87, "type": "TASK", "confidence": 0.7101257294416428}]}, {"text": "We adapt an existing algorithm for tree mining which we then use to mine the Generation Challenge dependency trees and identify the most likely causes of generation failure.", "labels": [], "entities": [{"text": "tree mining", "start_pos": 35, "end_pos": 46, "type": "TASK", "confidence": 0.7604278028011322}]}, {"text": "We show in particular, that this tree mining algorithm permits identifying not only errors in the grammar and the lexicon used by generation but also a few idiosyncrasies/error in the input data as well as mismatches between the structures contained in the SR input and the input structures expected by our generator.", "labels": [], "entities": []}, {"text": "The latter is an important point since, for symbolic approaches, a major hurdle to participation in the SR challenge is known to be precisely these mismatches i.e., the fact that the input provided by the SR task fails to match the input expected by the symbolic generation systems).", "labels": [], "entities": [{"text": "SR challenge", "start_pos": 104, "end_pos": 116, "type": "TASK", "confidence": 0.9328581392765045}]}, {"text": "The paper is structured as follows.", "labels": [], "entities": []}, {"text": "Section 2 presents the HybridTreeMiner algorithm, a complete and computationally efficient algorithm developed) for discovering frequently occurring subtrees in a database of labelled unordered trees.", "labels": [], "entities": []}, {"text": "Section 3 shows how to adapt this algorithm to mine the SR dependency trees for subtrees with high suspicion rate.", "labels": [], "entities": []}, {"text": "Section 4 presents an experiment we made using the resulting tree mining algorithm on SR dependency trees and summarises the results.", "labels": [], "entities": [{"text": "tree mining", "start_pos": 61, "end_pos": 72, "type": "TASK", "confidence": 0.7767559587955475}]}, {"text": "Section 5 discusses related work.", "labels": [], "entities": []}], "datasetContent": [{"text": "Using the input data provided by the Generation Challenge SR Task, we applied the error mining algorithm described in the preceding Section to debug and extend a symbolic surface realiser developed for this task.", "labels": [], "entities": [{"text": "Generation Challenge SR Task", "start_pos": 37, "end_pos": 65, "type": "TASK", "confidence": 0.5050849318504333}, {"text": "error mining", "start_pos": 82, "end_pos": 94, "type": "TASK", "confidence": 0.6495917737483978}]}, {"text": "To facilitate interpretation, we first chunked the input data in NPs, PPs and Clauses and performed error mining on the resulting sets of data.", "labels": [], "entities": [{"text": "interpretation", "start_pos": 14, "end_pos": 28, "type": "TASK", "confidence": 0.9794440269470215}]}, {"text": "The chunking was performed by retrieving from the Penn Treebank (PTB), for each phrase type, the yields of the constituents of that type and by using the alignment between words and dependency tree nodes provided by the organisers of the SR Task.", "labels": [], "entities": [{"text": "Penn Treebank (PTB)", "start_pos": 50, "end_pos": 69, "type": "DATASET", "confidence": 0.9715310215950013}]}, {"text": "For instance, given the sentence \"The most troublesome report maybe the August merchandise trade deficit due out tomorrow\", the NPs \"The most troublesome report\" and \"the August merchandise trade deficit due out tomorrow\" will be extracted from the PTB and the corresponding dependency structures from the SR Task data.", "labels": [], "entities": [{"text": "PTB", "start_pos": 249, "end_pos": 252, "type": "DATASET", "confidence": 0.9823827743530273}, {"text": "SR Task data", "start_pos": 306, "end_pos": 318, "type": "DATASET", "confidence": 0.8827320337295532}]}, {"text": "Using this chunked data, we then ran the generator on the corresponding SR Task dependency trees and stored separately, the input dependency trees for which generation succeeded and the input dependency trees for which generation failed.", "labels": [], "entities": [{"text": "SR Task dependency trees", "start_pos": 72, "end_pos": 96, "type": "DATASET", "confidence": 0.7653999328613281}]}, {"text": "Using information provided by the generator, we then removed from the failed data, those cases where generation failed either because a word was missing in the lexicon or because a TAG tree/family was missing in the grammar but required by the lexicon and the input data.", "labels": [], "entities": []}, {"text": "These cases can easily be detected using the generation system and thus do not need to be handled by error mining.", "labels": [], "entities": []}, {"text": "Finally, we performed error mining on the data using different minimal support thresholds, different display modes (sorted first by size and second by suspicion rate vs sorted by suspicion rate) and different labels (part of speech, words and part of speech, dependency, dependency and part of speech).", "labels": [], "entities": [{"text": "error mining", "start_pos": 22, "end_pos": 34, "type": "TASK", "confidence": 0.6832202225923538}]}], "tableCaptions": [{"text": " Table 1: Error Mining on POS tags with frequency  cutoff 0.1 and displaying only trees of size 1 sorted  by decreasing suspicion rate (Sus)", "labels": [], "entities": [{"text": "Error Mining", "start_pos": 10, "end_pos": 22, "type": "TASK", "confidence": 0.7306034564971924}, {"text": "suspicion rate (Sus)", "start_pos": 120, "end_pos": 140, "type": "METRIC", "confidence": 0.8350656032562256}]}]}