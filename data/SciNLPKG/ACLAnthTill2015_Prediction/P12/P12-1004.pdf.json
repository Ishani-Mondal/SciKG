{"title": [{"text": "Probabilistic Integration of Partial Lexical Information for Noise Robust Haptic Voice Recognition", "labels": [], "entities": [{"text": "Noise Robust Haptic Voice Recognition", "start_pos": 61, "end_pos": 98, "type": "TASK", "confidence": 0.7772807598114013}]}], "abstractContent": [{"text": "This paper presents a probabilistic framework that combines multiple knowledge sources for Haptic Voice Recognition (HVR), a multi-modal input method designed to provide efficient text entry on modern mobile devices.", "labels": [], "entities": [{"text": "Haptic Voice Recognition (HVR)", "start_pos": 91, "end_pos": 121, "type": "TASK", "confidence": 0.7478588670492172}, {"text": "text entry", "start_pos": 180, "end_pos": 190, "type": "TASK", "confidence": 0.73637655377388}]}, {"text": "HVR extends the conventional voice input by allowing users to provide complementary partial lexical information via touch input to improve the efficiency and accuracy of voice recognition.", "labels": [], "entities": [{"text": "HVR", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.8662912249565125}, {"text": "accuracy", "start_pos": 158, "end_pos": 166, "type": "METRIC", "confidence": 0.9970824122428894}, {"text": "voice recognition", "start_pos": 170, "end_pos": 187, "type": "TASK", "confidence": 0.7341232895851135}]}, {"text": "This paper investigates the use of the initial letter of the words in the utterance as the partial lexical information.", "labels": [], "entities": []}, {"text": "In addition to the acoustic and language models used in automatic speech recognition systems, HVR uses the haptic and partial lexical models as additional knowledge sources to reduce the recognition search space and suppress confusions.", "labels": [], "entities": [{"text": "automatic speech recognition", "start_pos": 56, "end_pos": 84, "type": "TASK", "confidence": 0.6650025645891825}]}, {"text": "Experimental results show that both the word error rate and runtime factor can be reduced by a factor of two using HVR.", "labels": [], "entities": [{"text": "word error rate", "start_pos": 40, "end_pos": 55, "type": "METRIC", "confidence": 0.624191035827001}, {"text": "HVR", "start_pos": 115, "end_pos": 118, "type": "DATASET", "confidence": 0.8677921891212463}]}], "introductionContent": [{"text": "Nowadays, modern portable devices, such as the smartphones and tablets, are equipped with microphone and touchscreen display.", "labels": [], "entities": []}, {"text": "With these devices becoming increasingly popular, there is an urgent need for an efficient and reliable text entry method on these small devices.", "labels": [], "entities": [{"text": "text entry", "start_pos": 104, "end_pos": 114, "type": "TASK", "confidence": 0.71573805809021}]}, {"text": "Currently, text entry using an onscreen virtual keyboard is the most widely adopted input method on these modern mobile devices.", "labels": [], "entities": [{"text": "text entry", "start_pos": 11, "end_pos": 21, "type": "TASK", "confidence": 0.7899855077266693}]}, {"text": "Unfortunately, typing with a small virtual keyboard can sometimes be cumbersome and frustratingly slow for many people.", "labels": [], "entities": []}, {"text": "Instead of using a virtual keyboard, it is also possible to use handwriting gestures to input text.", "labels": [], "entities": []}, {"text": "Handwriting input offers a more convenient input method for writing systems with complex orthography, including many Asian languages such as Chinese, Japanese and Korean.", "labels": [], "entities": []}, {"text": "However, handwriting input is not necessarily more efficient compared to keyboard input for English.", "labels": [], "entities": []}, {"text": "Moreover, handwriting recognition is susceptible to recognition errors, too.", "labels": [], "entities": [{"text": "handwriting recognition", "start_pos": 10, "end_pos": 33, "type": "TASK", "confidence": 0.9060019552707672}]}, {"text": "Voice input offers a hands-free solution for text entry.", "labels": [], "entities": [{"text": "text entry", "start_pos": 45, "end_pos": 55, "type": "TASK", "confidence": 0.7858771979808807}]}, {"text": "This is an attractive alternative for text entry because it completely eliminates the need for typing.", "labels": [], "entities": [{"text": "text entry", "start_pos": 38, "end_pos": 48, "type": "TASK", "confidence": 0.8480539321899414}]}, {"text": "Voice input is also more natural and faster for human to convey messages.", "labels": [], "entities": []}, {"text": "Normally, the average human speaking rate is approximately 100 words per minute (WPM).", "labels": [], "entities": []}, {"text": "showed that the typing speed for regular users reaches only 86.79 -98.31 using a full-size keyboard and 58.61 -61.44 WPM using a mini-QWERTY keyboard.", "labels": [], "entities": []}, {"text": "Evidently, speech input is the preferred text entry method, provided that speech signals can be reliably and efficiently converted into texts.", "labels": [], "entities": [{"text": "text entry", "start_pos": 41, "end_pos": 51, "type": "TASK", "confidence": 0.7312838137149811}]}, {"text": "Unfortunately, voice input relies on automatic speech recognition (ASR) technology, which requires high computational resources and is susceptible to performance degradation due to acoustic interference, such as the presence of noise.", "labels": [], "entities": [{"text": "automatic speech recognition (ASR)", "start_pos": 37, "end_pos": 71, "type": "TASK", "confidence": 0.8242603540420532}]}, {"text": "In order to improve the reliability and efficiency of ASR, Haptic Voice Recognition (HVR) was proposed by as a novel multimodal input method combining both speech and touch inputs.", "labels": [], "entities": [{"text": "ASR", "start_pos": 54, "end_pos": 57, "type": "TASK", "confidence": 0.9938539266586304}, {"text": "Haptic Voice Recognition (HVR)", "start_pos": 59, "end_pos": 89, "type": "TASK", "confidence": 0.7402676343917847}]}, {"text": "Touch inputs are used to generate haptic events, which correspond to the initial letters of the words in the spoken utterance.", "labels": [], "entities": []}, {"text": "In addition to the regular beam pruning used in traditional ASR (, search paths which are inconsistent with the haptic events are also pruned away to achieve further reduction in the recognition search space.", "labels": [], "entities": [{"text": "ASR", "start_pos": 60, "end_pos": 63, "type": "TASK", "confidence": 0.9835802912712097}]}, {"text": "As a result, the runtime of HVR is generally more efficient than ASR.", "labels": [], "entities": []}, {"text": "Furthermore, haptic events are not susceptible to acoustic distortion, making HVR more robust to noise.", "labels": [], "entities": []}, {"text": "This paper proposes a probabilistic framework that encompasses multiple knowledge sources for combining the speech and touch inputs.", "labels": [], "entities": []}, {"text": "This framework allows coherent probabilistic models of different knowledge sources to be tightly integrated.", "labels": [], "entities": []}, {"text": "In addition to the acoustic model and language model used in ASR, haptic model and partial lexical model are also introduced to facilitate the integration of more sophisticated haptic events, such as the keystrokes, into HVR.", "labels": [], "entities": [{"text": "ASR", "start_pos": 61, "end_pos": 64, "type": "TASK", "confidence": 0.9892517924308777}]}, {"text": "The remaining of this paper is organised as follows.", "labels": [], "entities": []}, {"text": "Section 2 gives an overview of existing techniques in the literature that aim at improving noise robustness for automatic speech recognition.", "labels": [], "entities": [{"text": "automatic speech recognition", "start_pos": 112, "end_pos": 140, "type": "TASK", "confidence": 0.6076391836007436}]}, {"text": "Section 3 gives a brief introduction to HVR.", "labels": [], "entities": [{"text": "HVR", "start_pos": 40, "end_pos": 43, "type": "DATASET", "confidence": 0.6341270804405212}]}, {"text": "Section 4 proposes a probabilistic framework for HVR that unifies multiple knowledge sources as an integrated probabilistic generative model.", "labels": [], "entities": []}, {"text": "Next, Section 5 describes how multiple knowledge sources can be integrated using Weighted Finite State Transducer (WFST) operations.", "labels": [], "entities": []}, {"text": "Experimental results are presented in Section 6.", "labels": [], "entities": []}, {"text": "Finally, conclusions are given in Section 7.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section, experimental results are reported based on the data collected using a prototype HVR interface implemented on an iPad.", "labels": [], "entities": []}, {"text": "This prototype HVR interface allows both speech and haptic input data to be captured either synchronously or asynchronously and the partial lexical information can be entered using either a soft keyboard or handwriting gestures.", "labels": [], "entities": []}, {"text": "shows the screenshot of the HVR prototype iPad app using the key-Donna was in Cincinnati last Thursday.", "labels": [], "entities": [{"text": "Cincinnati last Thursday", "start_pos": 78, "end_pos": 102, "type": "DATASET", "confidence": 0.8858647346496582}]}, {"text": "Adam will be visiting Charlotte tomorrow Janice will be in Chattanooga next month.", "labels": [], "entities": [{"text": "Charlotte", "start_pos": 22, "end_pos": 31, "type": "DATASET", "confidence": 0.877715528011322}]}, {"text": "Christine will be visiting Corpus Christi next Tuesday.", "labels": [], "entities": [{"text": "Corpus Christi", "start_pos": 27, "end_pos": 41, "type": "DATASET", "confidence": 0.8656051754951477}]}, {"text": "board and keystroke inputs respectively.", "labels": [], "entities": []}, {"text": "Therefore, there are altogether four input configurations.", "labels": [], "entities": []}, {"text": "For each configuration, 250 sentences were collected from a non-native fluent English speaker.", "labels": [], "entities": []}, {"text": "200 sentences were used as test data while the remaining 50 sentences were used for acoustic model adaptation.", "labels": [], "entities": [{"text": "acoustic model adaptation", "start_pos": 84, "end_pos": 109, "type": "TASK", "confidence": 0.6553335785865784}]}, {"text": "These sentences contain a variety of given names, surnames and city names so that confusions cannot be easily resolved using a language model.", "labels": [], "entities": []}, {"text": "Example sentences used for data collection are shown in.", "labels": [], "entities": [{"text": "data collection", "start_pos": 27, "end_pos": 42, "type": "TASK", "confidence": 0.7114537954330444}]}, {"text": "In order to investigate the robustness of HVR in noisy environment, the collected speech data were also artificially corrupted with additive babble noise from the NOISEX database to synthesise noisy speech signalto-noise (SNR) levels of 20 and 10 decibels 2 . The ASR system used in all the experiments reported in this paper consists of a set of HMM-based triphone acoustic models and an n-gram language model.", "labels": [], "entities": [{"text": "NOISEX database", "start_pos": 163, "end_pos": 178, "type": "DATASET", "confidence": 0.9771519601345062}]}, {"text": "The HMM models were trained using 39-dimensional MFCC features.", "labels": [], "entities": []}, {"text": "Each HMM has a left-to-right topology and three emitting states.", "labels": [], "entities": []}, {"text": "The emission probability for each state is represented by a single Gaussian component . A bigram language model with a vocabulary size of 200 words was used for testing.", "labels": [], "entities": []}, {"text": "The acoustic models were also noisecompensated using VTS () in order achieve a better baseline performance.", "labels": [], "entities": []}, {"text": "shows the speech, letter and total input speed using different input configurations.", "labels": [], "entities": []}, {"text": "For synchronous HVR, the total input speed is the same as the speech and letter input speed since both the speech and haptic inputs are provided concurrently.", "labels": [], "entities": []}, {"text": "According to this study, synchronous keyboard input speed is 86 words per minutes (WPM).", "labels": [], "entities": []}, {"text": "This is: Comparison of the speech and letter input speed, measured in Words-Per-Minute (WPM), for different HVR input configurations slightly faster than keystroke input using handwriting gestures, where the input speed is 78 WPM.", "labels": [], "entities": [{"text": "Words-Per-Minute (WPM)", "start_pos": 70, "end_pos": 92, "type": "METRIC", "confidence": 0.7426871508359909}]}, {"text": "This is not surprising since key taps are much quicker to generate compared to handwriting gestures.", "labels": [], "entities": []}, {"text": "On the other hand, the individual speech and letter input speed are faster for asynchronous mode because users do not need to multi-task.", "labels": [], "entities": []}, {"text": "However, since the speech and haptic inputs are provided concurrently, the resulting total input speed for asynchronous HVR is much slower compared to synchronous HVR.", "labels": [], "entities": []}, {"text": "Therefore, synchronous HVR is potentially more efficient than asynchronous HVR.", "labels": [], "entities": []}, {"text": "First of all, the Word Error Rate (WER) and Letter Error Rate (LER) performances for standard ASR systems in different noise conditions are summarized in.", "labels": [], "entities": [{"text": "Word Error Rate (WER)", "start_pos": 18, "end_pos": 39, "type": "METRIC", "confidence": 0.8672291934490204}, {"text": "Letter Error Rate (LER)", "start_pos": 44, "end_pos": 67, "type": "METRIC", "confidence": 0.9215124646822611}, {"text": "ASR", "start_pos": 94, "end_pos": 97, "type": "TASK", "confidence": 0.9753671288490295}]}, {"text": "These are results using pure ASR, without adding the haptic inputs.", "labels": [], "entities": [{"text": "ASR", "start_pos": 29, "end_pos": 32, "type": "TASK", "confidence": 0.9806914329528809}]}, {"text": "Speech recorded using asynchronous HVR is considered normal speech.", "labels": [], "entities": []}, {"text": "The ASR system achieved 22.2%, 30.2% and 33.3% WER in clean, 20dB and 10dB conditions respectively.", "labels": [], "entities": [{"text": "ASR", "start_pos": 4, "end_pos": 7, "type": "TASK", "confidence": 0.49499279260635376}, {"text": "WER", "start_pos": 47, "end_pos": 50, "type": "METRIC", "confidence": 0.9989307522773743}]}, {"text": "Note that the acoustic models have been compensated using VTS () for noisy conditions.", "labels": [], "entities": [{"text": "VTS", "start_pos": 58, "end_pos": 61, "type": "METRIC", "confidence": 0.790967583656311}]}, {"text": "Table 3 also shows the system performance considering on the initial letter sequence of the recognition output.", "labels": [], "entities": []}, {"text": "This indicates the potential improvements that can be obtained with the additional first letter information.", "labels": [], "entities": []}, {"text": "Note that the pure ASR system output contains substantial initial letter errors.", "labels": [], "entities": [{"text": "ASR", "start_pos": 19, "end_pos": 22, "type": "TASK", "confidence": 0.9885488152503967}]}], "tableCaptions": [{"text": " Table 2: Comparison of the speech and letter input  speed, measured in Words-Per-Minute (WPM), for dif- ferent HVR input configurations", "labels": [], "entities": [{"text": "Words-Per-Minute (WPM)", "start_pos": 72, "end_pos": 94, "type": "METRIC", "confidence": 0.7586234211921692}]}, {"text": " Table 3: WER and LER performance of ASR in different  noise conditions", "labels": [], "entities": [{"text": "WER", "start_pos": 10, "end_pos": 13, "type": "METRIC", "confidence": 0.9903096556663513}, {"text": "LER", "start_pos": 18, "end_pos": 21, "type": "METRIC", "confidence": 0.996264636516571}, {"text": "ASR", "start_pos": 37, "end_pos": 40, "type": "TASK", "confidence": 0.8786346316337585}]}, {"text": " Table 4: WER and LER performance of synchronous  HVR in different noise conditions", "labels": [], "entities": [{"text": "WER", "start_pos": 10, "end_pos": 13, "type": "METRIC", "confidence": 0.9871238470077515}, {"text": "LER", "start_pos": 18, "end_pos": 21, "type": "METRIC", "confidence": 0.9954410791397095}]}, {"text": " Table 5: WER and LER performance of asynchronous  HVR in different noise conditions", "labels": [], "entities": [{"text": "WER", "start_pos": 10, "end_pos": 13, "type": "METRIC", "confidence": 0.9878495335578918}, {"text": "LER", "start_pos": 18, "end_pos": 21, "type": "METRIC", "confidence": 0.9957833290100098}]}, {"text": " Table 6: WER performance of keyboard synchronous  HVR using integrated decoding and lattice rescoring", "labels": [], "entities": [{"text": "WER", "start_pos": 10, "end_pos": 13, "type": "METRIC", "confidence": 0.9489442110061646}]}, {"text": " Table 7: WER and LER performance of integrated and  rescoring synchronous HVR in different noise conditions", "labels": [], "entities": [{"text": "WER", "start_pos": 10, "end_pos": 13, "type": "METRIC", "confidence": 0.9581793546676636}, {"text": "LER", "start_pos": 18, "end_pos": 21, "type": "METRIC", "confidence": 0.9906546473503113}]}]}