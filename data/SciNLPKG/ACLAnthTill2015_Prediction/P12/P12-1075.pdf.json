{"title": [{"text": "Unsupervised Relation Discovery with Sense Disambiguation", "labels": [], "entities": [{"text": "Unsupervised Relation Discovery", "start_pos": 0, "end_pos": 31, "type": "TASK", "confidence": 0.6537642180919647}]}], "abstractContent": [{"text": "To discover relation types from text, most methods cluster shallow or syntactic patterns of relation mentions, but consider only one possible sense per pattern.", "labels": [], "entities": []}, {"text": "In practice this assumption is often violated.", "labels": [], "entities": []}, {"text": "In this paper we overcome this issue by inducing clusters of pattern senses from feature representations of patterns.", "labels": [], "entities": []}, {"text": "In particular, we employ a topic model to partition entity pairs associated with patterns into sense clusters using local and global features.", "labels": [], "entities": []}, {"text": "We merge these sense clusters into semantic relations using hierarchical agglomerative clustering.", "labels": [], "entities": []}, {"text": "We compare against several baselines: a generative latent-variable model, a clustering method that does not dis-ambiguate between path senses, and our own approach but with only local features.", "labels": [], "entities": []}, {"text": "Experimental results show our proposed approach discovers dramatically more accurate clusters than models without sense disambiguation, and that incorporating global features, such as the document theme, is crucial.", "labels": [], "entities": []}], "introductionContent": [{"text": "Relation extraction (RE) is the task of determining semantic relations between entities mentioned in text.", "labels": [], "entities": [{"text": "Relation extraction (RE)", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.9117332696914673}]}, {"text": "RE is an essential part of information extraction and is useful for question answering), textual entailment () and many other applications.", "labels": [], "entities": [{"text": "RE", "start_pos": 0, "end_pos": 2, "type": "TASK", "confidence": 0.7991243600845337}, {"text": "information extraction", "start_pos": 27, "end_pos": 49, "type": "TASK", "confidence": 0.8388518989086151}, {"text": "question answering", "start_pos": 68, "end_pos": 86, "type": "TASK", "confidence": 0.8877330124378204}, {"text": "textual entailment", "start_pos": 89, "end_pos": 107, "type": "TASK", "confidence": 0.7344210147857666}]}, {"text": "A common approach to RE is to assume that relations to be extracted are part of a predefined ontology.", "labels": [], "entities": [{"text": "RE", "start_pos": 21, "end_pos": 23, "type": "TASK", "confidence": 0.9929551482200623}]}, {"text": "For example, the relations are given in knowledge bases such as Freebase ( or DBpedia ().", "labels": [], "entities": [{"text": "Freebase", "start_pos": 64, "end_pos": 72, "type": "DATASET", "confidence": 0.9779331684112549}, {"text": "DBpedia", "start_pos": 78, "end_pos": 85, "type": "DATASET", "confidence": 0.9449176788330078}]}, {"text": "However, in many applications, ontologies do not yet exist or have low coverage.", "labels": [], "entities": []}, {"text": "Even when they do exist, their maintenance and extension are considered to be a substantial bottleneck.", "labels": [], "entities": []}, {"text": "This has led to considerable interest in unsupervised relation discovery).", "labels": [], "entities": [{"text": "relation discovery", "start_pos": 54, "end_pos": 72, "type": "TASK", "confidence": 0.823552280664444}]}, {"text": "Here, the relation extractor simultaneously discovers facts expressed in natural language, and the ontology into which they are assigned.", "labels": [], "entities": []}, {"text": "Many relation discovery methods rely exclusively on the notion of either shallow or syntactic patterns that appear between two named entities ().", "labels": [], "entities": [{"text": "relation discovery", "start_pos": 5, "end_pos": 23, "type": "TASK", "confidence": 0.9240792691707611}]}, {"text": "Such patterns could be sequences of lemmas and Part-of-Speech tags, or lexicalized dependency paths.", "labels": [], "entities": []}, {"text": "Generally speaking, relation discovery attempts to cluster such patterns into sets of equivalent or similar meaning.", "labels": [], "entities": [{"text": "relation discovery", "start_pos": 20, "end_pos": 38, "type": "TASK", "confidence": 0.9683622717857361}]}, {"text": "Whether we use sequences or dependency paths, we will encounter the problem of polysemy.", "labels": [], "entities": []}, {"text": "For example, a pattern such as \"A beat B\" can mean that person A wins over B in competing fora political position, as pair \"(Hillary Rodham Clinton, Jonathan Tasini)\" in \"Sen Hillary Rodham Clinton beats rival Jonathan Tasini for Senate.\"", "labels": [], "entities": []}, {"text": "It can also indicate that an athlete A beat B in a sports match, as pair \"(Dmitry Tursunov, Andy Roddick)\" in \"Dmitry Tursunov beat the best American player Andy Roddick.\"", "labels": [], "entities": []}, {"text": "Moreover, it can mean \"physically beat\" as pair \"(Mr. Harris, Mr. Simon)\" in \"On Sept. 7, 1999, Mr. Harris fatally beat Mr. Simon.\"", "labels": [], "entities": []}, {"text": "This is known as polysemy.", "labels": [], "entities": []}, {"text": "If we work with patterns alone, our extractor will not be able to differentiate between these cases.", "labels": [], "entities": []}, {"text": "Most previous approaches do not explicitly address this problem.", "labels": [], "entities": []}, {"text": "assumes only one sense per path.", "labels": [], "entities": []}, {"text": "In (, they augment each relation with its selectional pref-erences, i.e. fine-grained entity types of two arguments, to handle polysemy.", "labels": [], "entities": []}, {"text": "However, such fine grained entity types come at a high cost.", "labels": [], "entities": []}, {"text": "It is difficult to discover a high-quality set of fine-grained entity types due to unknown criteria for developing such a set.", "labels": [], "entities": []}, {"text": "In particular, the optimal granularity of entity types depends on the particular pattern we consider.", "labels": [], "entities": []}, {"text": "For example, a pattern like \"A beat B\" could refer to A winning a sports competition against B, or apolitical election.", "labels": [], "entities": []}, {"text": "To differentiate between these senses we need types such as \"Politician\" or \"Athlete\".", "labels": [], "entities": []}, {"text": "However, for \"A, the parent of B\" we only need to distinguish between persons and organizations (for the case of the sub-organization relation).", "labels": [], "entities": []}, {"text": "In addition, there are senses that just cannot be determined by entity types alone: Take the meaning of \"A beat B\" where A and B are both persons; this could mean A physically beats B, or it could mean that A defeated B in a competition.", "labels": [], "entities": []}, {"text": "In this paper we address the problem of polysemy, while we circumvent the problem of finding finegrained entity types.", "labels": [], "entities": []}, {"text": "Instead of mapping entities to fine-grained types, we directly induce pattern senses by clustering feature representations of pattern contexts, i.e. the entity pairs associated with a pattern.", "labels": [], "entities": []}, {"text": "This allows us to employ not only local features such as words, but also global features such as the document and sentence themes.", "labels": [], "entities": []}, {"text": "To cluster the entity pairs of a single relation pattern into senses, we develop a simple extension to Latent Dirichlet Allocation ().", "labels": [], "entities": []}, {"text": "Once we have our pattern senses, we merge them into clusters of different patterns with a similar sense.", "labels": [], "entities": []}, {"text": "We employ hierarchical agglomerative clustering with a similarity metric that considers features such as the entity arguments, and the document and sentence themes.", "labels": [], "entities": []}, {"text": "We perform experiments on New York Times articles and consider lexicalized dependency paths as patterns in our data.", "labels": [], "entities": []}, {"text": "In the following we shall use the term path and pattern exchangeably.", "labels": [], "entities": []}, {"text": "We compare our approach with several baseline systems, including a generative model approach, a clustering method that does not disambiguate between senses, and our approach with different features.", "labels": [], "entities": []}, {"text": "We perform both automatic and manual evaluations.", "labels": [], "entities": []}, {"text": "For automatic evaluation, we use relation instances in Freebase as ground truth, and employ two clustering metrics, pairwise F-score and B 3 (as used in coference).", "labels": [], "entities": [{"text": "Freebase", "start_pos": 55, "end_pos": 63, "type": "DATASET", "confidence": 0.9557461738586426}, {"text": "F-score", "start_pos": 125, "end_pos": 132, "type": "METRIC", "confidence": 0.8267776966094971}, {"text": "B 3", "start_pos": 137, "end_pos": 140, "type": "METRIC", "confidence": 0.9511553049087524}]}, {"text": "Experimental results show that our approach improves over the baselines, and that using global features achieves better performance than using entity type based features.", "labels": [], "entities": []}, {"text": "For manual evaluation, we employ a set intrusion method (.", "labels": [], "entities": []}, {"text": "The results also show that our approach discovers relation clusters that human evaluators find coherent.", "labels": [], "entities": []}], "datasetContent": [{"text": "We carryout experiments on New York Times articles from years: Example semantic relation clusters produced by our approach.", "labels": [], "entities": []}, {"text": "For each cluster, we list the top paths in it, and each is followed by \":number\", indicating its sense obtained from sense disambiguation.", "labels": [], "entities": []}, {"text": "They are ranked by the number of entity pairs they take.", "labels": [], "entities": []}, {"text": "The column on the left shows sense of each relation.", "labels": [], "entities": []}, {"text": "They are added manually by looking at the sense numbers associated with each path.", "labels": [], "entities": []}, {"text": "for words on the dependency paths.", "labels": [], "entities": []}, {"text": "Each entity pair and the dependency path which connects them form a tuple.", "labels": [], "entities": []}, {"text": "We filter out paths which occur fewer than 200 times and use some heuristic rules to filter out paths which are unlikely to represent a relation, for example, paths in with both arguments take the syntactic role \"dobj\" (direct objective) in the dependency path.", "labels": [], "entities": []}, {"text": "In such cases both arguments are often part of a coordination structure, and it is unlikely that they are related.", "labels": [], "entities": []}, {"text": "In summary, we collect about one million tuples, 1300 patterns and half million named entities.", "labels": [], "entities": []}, {"text": "In terms of named entities, the data is very sparse.", "labels": [], "entities": []}, {"text": "On average one named entity occurs four times.", "labels": [], "entities": []}, {"text": "We evaluate relation clusters discovered by all approaches against Freebase.", "labels": [], "entities": [{"text": "Freebase", "start_pos": 67, "end_pos": 75, "type": "DATASET", "confidence": 0.9822763800621033}]}, {"text": "Freebase comprises a large collection of entities and relations which come from varieties of data sources, including Wikipedia infoboxes.", "labels": [], "entities": [{"text": "Freebase", "start_pos": 0, "end_pos": 8, "type": "DATASET", "confidence": 0.9410362839698792}]}, {"text": "Many users also contribute to Freebase by annotating relation instances.", "labels": [], "entities": [{"text": "Freebase", "start_pos": 30, "end_pos": 38, "type": "DATASET", "confidence": 0.9440139532089233}]}, {"text": "We use coreference evaluation metrics: pairwise F-score and B 3 (Bagga and.", "labels": [], "entities": [{"text": "F-score", "start_pos": 48, "end_pos": 55, "type": "METRIC", "confidence": 0.9542735815048218}]}, {"text": "Pairwise metrics measure how often two tuples which are clustered in one semantic relation are labeled with the same Freebase label.", "labels": [], "entities": []}, {"text": "We evaluate approximately 10,000 tuples which occur in both our data and Freebase.", "labels": [], "entities": [{"text": "Freebase", "start_pos": 73, "end_pos": 81, "type": "DATASET", "confidence": 0.9914312362670898}]}, {"text": "Since our system predicts fine-grained clusters comparing against Freebase relations, the measure of recall is underestimated.", "labels": [], "entities": [{"text": "recall", "start_pos": 101, "end_pos": 107, "type": "METRIC", "confidence": 0.9993858337402344}]}, {"text": "The precision measure is more reliable and we employ F-0.5 measure, which places more emphasis on precision.", "labels": [], "entities": [{"text": "precision measure", "start_pos": 4, "end_pos": 21, "type": "METRIC", "confidence": 0.9750224649906158}, {"text": "F-0.5 measure", "start_pos": 53, "end_pos": 66, "type": "METRIC", "confidence": 0.9805406332015991}, {"text": "precision", "start_pos": 98, "end_pos": 107, "type": "METRIC", "confidence": 0.9984898567199707}]}, {"text": "Matthews correlation coefficient (MCC) () is another measure used in machine learning, which takes into account true and false positives and negatives and is generally regarded as a balanced measure which can be used when the classes are of very different sizes.", "labels": [], "entities": [{"text": "Matthews correlation coefficient (MCC)", "start_pos": 0, "end_pos": 38, "type": "METRIC", "confidence": 0.8682170659303665}]}, {"text": "In our case, the true negative number is 100 times larger than the true positive number.", "labels": [], "entities": []}, {"text": "Therefor we also employ MCC, calculated as MCC = The MCC score is between -1 and 1.", "labels": [], "entities": [{"text": "MCC", "start_pos": 24, "end_pos": 27, "type": "METRIC", "confidence": 0.9912739396095276}, {"text": "MCC", "start_pos": 43, "end_pos": 46, "type": "METRIC", "confidence": 0.9865586757659912}, {"text": "MCC score", "start_pos": 53, "end_pos": 62, "type": "METRIC", "confidence": 0.9424790441989899}]}, {"text": "In perfect predictions, F P and F N are 0, and the MCC score is 1.", "labels": [], "entities": [{"text": "MCC score", "start_pos": 51, "end_pos": 60, "type": "METRIC", "confidence": 0.9732544124126434}]}, {"text": "A random prediction results in score 0.", "labels": [], "entities": []}, {"text": "shows the results of all systems.", "labels": [], "entities": []}, {"text": "Our approach achieves the best performance inmost measures.", "labels": [], "entities": []}, {"text": "Without using sense disambiguation, the performance of hierarchical clustering decreases significantly, losing 17% in precision in the pairwise measure, and 15% in terms of B 3 . The generative model approach with 300 topics achieves similar precision to the hierarchical clustering approach.", "labels": [], "entities": [{"text": "precision", "start_pos": 118, "end_pos": 127, "type": "METRIC", "confidence": 0.9994401335716248}, {"text": "B 3", "start_pos": 173, "end_pos": 176, "type": "METRIC", "confidence": 0.9607645869255066}, {"text": "precision", "start_pos": 242, "end_pos": 251, "type": "METRIC", "confidence": 0.9951320886611938}]}, {"text": "With more topics, the precision increases, however, the recall of the generative model is much lower than those of other approaches.", "labels": [], "entities": [{"text": "precision", "start_pos": 22, "end_pos": 31, "type": "METRIC", "confidence": 0.999575674533844}, {"text": "recall", "start_pos": 56, "end_pos": 62, "type": "METRIC", "confidence": 0.9996906518936157}, {"text": "generative", "start_pos": 70, "end_pos": 80, "type": "TASK", "confidence": 0.9563088417053223}]}, {"text": "We also show the results of our approach without global document and sentence theme features (Local).", "labels": [], "entities": []}, {"text": "In this case, both precision and recall decrease.", "labels": [], "entities": [{"text": "precision", "start_pos": 19, "end_pos": 28, "type": "METRIC", "confidence": 0.9997723698616028}, {"text": "recall", "start_pos": 33, "end_pos": 39, "type": "METRIC", "confidence": 0.999664306640625}]}, {"text": "We compare global features (Our approach) against Wikipedia entity type features (Local+Type).", "labels": [], "entities": []}, {"text": "We see that using global features achieves better performance than using entity type based features.", "labels": [], "entities": []}, {"text": "When we add entity type features to our approach, the performance does not increase.", "labels": [], "entities": []}, {"text": "The entity type features do not help much is due to that we cannot determine which particular type to choose for an entity pair.", "labels": [], "entities": []}, {"text": "Take pair \"(Hillary Rodham Clinton, Jonathan Tasini)\" as an example, choosing politician for both arguments instead of person will help.", "labels": [], "entities": []}, {"text": "We should note that these measures provide comparison between different systems although they are not accurate.", "labels": [], "entities": []}, {"text": "One reason is the following: some relation instances should have multiple labels but they have only one label in Freebase.", "labels": [], "entities": [{"text": "Freebase", "start_pos": 113, "end_pos": 121, "type": "DATASET", "confidence": 0.9421229362487793}]}, {"text": "For example, instances of a relation that a person \"was born in\" a country could be labeled as \"/people/person/place of birth\" and as \"/people/person/nationality\".", "labels": [], "entities": []}, {"text": "This decreases the pairwise precision.", "labels": [], "entities": [{"text": "precision", "start_pos": 28, "end_pos": 37, "type": "METRIC", "confidence": 0.9770699739456177}]}, {"text": "Further discussion is in Section 4.3.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 3: Pairwise and B 3 evaluation for various systems. Since our systems predict more fine-grained clusters than  Freebase, the recall measure is underestimated.", "labels": [], "entities": [{"text": "B 3", "start_pos": 23, "end_pos": 26, "type": "METRIC", "confidence": 0.9561546742916107}, {"text": "recall", "start_pos": 132, "end_pos": 138, "type": "METRIC", "confidence": 0.9993938207626343}]}, {"text": " Table 4: A path intrusion task. We show 5 paths and ask the annotator to identify one path which does not belong to  the cluster. And we show one example sentence for each path. The entities (As and Bs) in the sentences are bold. And  the italic row here indicates the intruder.", "labels": [], "entities": []}, {"text": " Table 5: Results of intruding tasks of all systems.", "labels": [], "entities": []}]}