{"title": [{"text": "Fast and Scalable Decoding with Language Model Look-Ahead for Phrase-based Statistical Machine Translation", "labels": [], "entities": [{"text": "Phrase-based Statistical Machine Translation", "start_pos": 62, "end_pos": 106, "type": "TASK", "confidence": 0.7243694290518761}]}], "abstractContent": [{"text": "In this work we present two extensions to the well-known dynamic programming beam search in phrase-based statistical machine translation (SMT), aiming at increased efficiency of decoding by minimizing the number of language model computations and hypothesis expansions.", "labels": [], "entities": [{"text": "phrase-based statistical machine translation (SMT)", "start_pos": 92, "end_pos": 142, "type": "TASK", "confidence": 0.7263376116752625}]}, {"text": "Our results show that language model based pre-sorting yields a small improvement in translation quality and a speedup by a factor of 2.", "labels": [], "entities": [{"text": "speedup", "start_pos": 111, "end_pos": 118, "type": "METRIC", "confidence": 0.9767027497291565}]}, {"text": "Two look-ahead methods are shown to further increase translation speed by a factor of 2 without changing the search space and a factor of 4 with the side-effect of some additional search errors.", "labels": [], "entities": [{"text": "translation", "start_pos": 53, "end_pos": 64, "type": "TASK", "confidence": 0.9466433525085449}]}, {"text": "We compare our approach with Moses and observe the same performance , but a substantially better trade-off between translation quality and speed.", "labels": [], "entities": [{"text": "translation", "start_pos": 115, "end_pos": 126, "type": "TASK", "confidence": 0.9477081298828125}, {"text": "speed", "start_pos": 139, "end_pos": 144, "type": "METRIC", "confidence": 0.9632894992828369}]}, {"text": "At a speed of roughly 70 words per second, Moses reaches 17.2% BLEU, whereas our approach yields 20.0% with identical models.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 63, "end_pos": 67, "type": "METRIC", "confidence": 0.9995891451835632}]}], "introductionContent": [{"text": "Research efforts to increase search efficiency for phrase-based MT () have explored several directions, ranging from generalizing the stack decoding algorithm () to additional early pruning techniques), and more efficient language model (LM) querying).", "labels": [], "entities": [{"text": "MT", "start_pos": 64, "end_pos": 66, "type": "TASK", "confidence": 0.7080550789833069}]}, {"text": "This work extends the approach by) with two techniques to increase translation speed and scalability.", "labels": [], "entities": [{"text": "translation", "start_pos": 67, "end_pos": 78, "type": "TASK", "confidence": 0.9589617252349854}]}, {"text": "We show that taking a heuristic LM score estimate for pre-sorting the phrase translation candidates has a positive effect on both translation quality and speed.", "labels": [], "entities": [{"text": "phrase translation candidates", "start_pos": 70, "end_pos": 99, "type": "TASK", "confidence": 0.7528362174828848}, {"text": "speed", "start_pos": 154, "end_pos": 159, "type": "METRIC", "confidence": 0.9701955914497375}]}, {"text": "Further, we introduce two novel LM look-ahead methods.", "labels": [], "entities": [{"text": "LM look-ahead", "start_pos": 32, "end_pos": 45, "type": "TASK", "confidence": 0.8572683334350586}]}, {"text": "The idea of LM look-ahead is to incorporate the LM probabilities into the pruning process of the beam search as early as possible.", "labels": [], "entities": []}, {"text": "In speech recognition it has been used for many years ().", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 3, "end_pos": 21, "type": "TASK", "confidence": 0.9045095443725586}]}, {"text": "First-word LM look-ahead exploits the search structure to use the LM costs of the first word of anew phrase as a lower bound for the full LM costs of the phrase.", "labels": [], "entities": []}, {"text": "Phrase-only LM look-ahead makes use of a pre-computed estimate of the full LM costs for each phrase.", "labels": [], "entities": [{"text": "Phrase-only LM look-ahead", "start_pos": 0, "end_pos": 25, "type": "TASK", "confidence": 0.6938254038492838}]}, {"text": "We detail the implementation of these methods and analyze their effect with respect to the number of LM computations and hypothesis expansions as well as on translation speed and quality.", "labels": [], "entities": []}, {"text": "We also run comparisons with the Moses decoder (, which yields the same performance in BLEU, but is outperformed significantly in terms of scalability for faster translation.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 87, "end_pos": 91, "type": "METRIC", "confidence": 0.993507981300354}]}, {"text": "Our implementation is available under a non-commercial open source licence \u2020 .", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section we evaluate the proposed extensions to the original beam search algorithm in terms of scalability and their usefulness for different application constraints.", "labels": [], "entities": [{"text": "beam search", "start_pos": 68, "end_pos": 79, "type": "TASK", "confidence": 0.8471873700618744}]}, {"text": "We compare Moses and four different setups of our decoder: LM score pre-sorting switched on or off without LM look-ahead and both LM look-ahead methods with LM score pre-sorting.", "labels": [], "entities": []}, {"text": "We translated the test set with the beam sizes set to N c = N l = {1, 2, 4, 8, 16, 24, 32, 48, 64}.", "labels": [], "entities": []}, {"text": "For Moses we used the beam sizes 2 i , i \u2208 {1, . .", "labels": [], "entities": []}, {"text": "Transla-: Comparison of Moses with this work.", "labels": [], "entities": []}, {"text": "Either first-word or phrase-only LM look-ahead is applied.", "labels": [], "entities": []}, {"text": "We consider both the best and the fastest possible translation, as well as the fastest settings resulting in no more than 1% and 2% BLEU loss on the development set.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 132, "end_pos": 136, "type": "METRIC", "confidence": 0.9995899796485901}]}, {"text": "Results are given on the test set (newstest2009).", "labels": [], "entities": [{"text": "newstest2009", "start_pos": 35, "end_pos": 47, "type": "DATASET", "confidence": 0.8664283156394958}]}, {"text": "tion performance in BLEU is plotted against speed in.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 20, "end_pos": 24, "type": "METRIC", "confidence": 0.9936291575431824}]}, {"text": "Without the proposed extensions, Moses slightly outperforms our decoder in terms of BLEU.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 84, "end_pos": 88, "type": "METRIC", "confidence": 0.9951747059822083}]}, {"text": "However, the latter already scales better for higher speed.", "labels": [], "entities": []}, {"text": "With LM score pre-sorting, the best BLEU value is similar to Moses while further accelerating translation, yielding identical performance at 16 words/sec as Moses at 1.8 words/sec.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 36, "end_pos": 40, "type": "METRIC", "confidence": 0.9987408518791199}, {"text": "translation", "start_pos": 94, "end_pos": 105, "type": "TASK", "confidence": 0.9533785581588745}]}, {"text": "Application of first-word LM look-ahead shifts the graph to the right, now reaching the same performance at 31 words/sec.", "labels": [], "entities": []}, {"text": "At a fixed translation speed of roughly 70 words/sec, our approach yields 20.0% BLEU, whereas Moses reaches 17.2%.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 80, "end_pos": 84, "type": "METRIC", "confidence": 0.999534010887146}]}, {"text": "For phrase-only LM look-ahead the graph is somewhat flatter.", "labels": [], "entities": []}, {"text": "It yields nearly the same top performance with an even better trade-off between translation quality and speed.", "labels": [], "entities": [{"text": "translation", "start_pos": 80, "end_pos": 91, "type": "TASK", "confidence": 0.9307644963264465}]}, {"text": "The final set of experiments is performed on both the WMT and the IWSLT task.", "labels": [], "entities": [{"text": "WMT", "start_pos": 54, "end_pos": 57, "type": "DATASET", "confidence": 0.688223123550415}, {"text": "IWSLT task", "start_pos": 66, "end_pos": 76, "type": "DATASET", "confidence": 0.8181751668453217}]}, {"text": "We directly compare our decoder with the two LM look-ahead methods with Moses in four scenarios: the best possible translation, the fastest possible translation without performance constraint and the fastest possible translation with no more than 1% and 2% loss in BLEU on the dev set compared to the best value.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 265, "end_pos": 269, "type": "METRIC", "confidence": 0.9985389709472656}]}, {"text": "shows that on the WMT data, the top performance is similar for both decoders.", "labels": [], "entities": [{"text": "WMT data", "start_pos": 18, "end_pos": 26, "type": "DATASET", "confidence": 0.9051660299301147}]}, {"text": "However, if we allow fora small degradation in translation performance, our approaches clearly outperform Moses in terms of translation speed.", "labels": [], "entities": []}, {"text": "With phrase-only LM look-ahead, our decoder is faster by a factor of 6 for no more than 1% BLEU loss, a factor of 11 for 2% BLEU loss and a factor of 22 in the fastest setting.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 91, "end_pos": 95, "type": "METRIC", "confidence": 0.9963251948356628}, {"text": "BLEU loss", "start_pos": 124, "end_pos": 133, "type": "METRIC", "confidence": 0.9749995768070221}]}, {"text": "The results on the IWSLT data are very similar.", "labels": [], "entities": [{"text": "IWSLT data", "start_pos": 19, "end_pos": 29, "type": "DATASET", "confidence": 0.9567348659038544}]}, {"text": "Here, the speed difference reaches a factor of 19 in the fastest setting.", "labels": [], "entities": [{"text": "speed difference", "start_pos": 10, "end_pos": 26, "type": "METRIC", "confidence": 0.9460943639278412}]}], "tableCaptions": [{"text": " Table 1: Comparison of the number of hypothesis expan- sions per source word (#HYP) and LM computations per  source word (#LM) with respect to LM pre-sorting, first- word LM look-ahead and phrase-only LM look-ahead on  newstest2009. Speed is given in words per second.  Results are given with (N o = 100) and without (N o = \u221e)  observation pruning.", "labels": [], "entities": [{"text": "Speed", "start_pos": 234, "end_pos": 239, "type": "METRIC", "confidence": 0.9598391056060791}]}, {"text": " Table 2: Comparison of Moses with this work. Either first-word or phrase-only LM look-ahead is applied. We consider  both the best and the fastest possible translation, as well as the fastest settings resulting in no more than 1% and 2%  BLEU loss on the development set. Results are given on the test set (newstest2009).", "labels": [], "entities": [{"text": "BLEU", "start_pos": 239, "end_pos": 243, "type": "METRIC", "confidence": 0.999383807182312}, {"text": "newstest2009", "start_pos": 308, "end_pos": 320, "type": "DATASET", "confidence": 0.895304262638092}]}]}