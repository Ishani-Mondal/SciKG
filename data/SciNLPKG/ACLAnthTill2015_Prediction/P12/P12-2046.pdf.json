{"title": [{"text": "Coupling Label Propagation and Constraints for Temporal Fact Extraction", "labels": [], "entities": [{"text": "Temporal Fact Extraction", "start_pos": 47, "end_pos": 71, "type": "TASK", "confidence": 0.7365843653678894}]}], "abstractContent": [{"text": "The Web and digitized text sources contain a wealth of information about named entities such as politicians, actors, companies, or cultural landmarks.", "labels": [], "entities": []}, {"text": "Extracting this information has enabled the automated construction of large knowledge bases, containing hundred millions of binary relationships or attribute values about these named entities.", "labels": [], "entities": []}, {"text": "However, in reality most knowledge is transient, i.e. changes overtime, requiring a temporal dimension in fact extraction.", "labels": [], "entities": [{"text": "fact extraction", "start_pos": 106, "end_pos": 121, "type": "TASK", "confidence": 0.7368868142366409}]}, {"text": "In this paper we develop a methodology that combines label propagation with constraint reasoning for temporal fact extraction.", "labels": [], "entities": [{"text": "label propagation", "start_pos": 53, "end_pos": 70, "type": "TASK", "confidence": 0.8507674932479858}, {"text": "temporal fact extraction", "start_pos": 101, "end_pos": 125, "type": "TASK", "confidence": 0.6187156041463217}]}, {"text": "Label propagation aggressively gathers fact candidates , and an Integer Linear Program is used to clean out false hypotheses that violate temporal constraints.", "labels": [], "entities": [{"text": "Label propagation", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.782517671585083}]}, {"text": "Our method is able to improve on recall while keeping up with precision , which we demonstrate by experiments with biography-style Wikipedia pages and a large corpus of news articles.", "labels": [], "entities": [{"text": "recall", "start_pos": 33, "end_pos": 39, "type": "METRIC", "confidence": 0.9988119602203369}, {"text": "precision", "start_pos": 62, "end_pos": 71, "type": "METRIC", "confidence": 0.999488353729248}]}], "introductionContent": [{"text": "In recent years, automated fact extraction from Web contents has seen significant progress with the emergence of freely available knowledge bases, such as DBpedia (,), TextRunner (, or ReadTheWeb ().", "labels": [], "entities": [{"text": "fact extraction from Web contents", "start_pos": 27, "end_pos": 60, "type": "TASK", "confidence": 0.8408889472484589}, {"text": "DBpedia", "start_pos": 155, "end_pos": 162, "type": "DATASET", "confidence": 0.9210572242736816}]}, {"text": "These knowledge bases are constantly growing and contain currently (by example of DBpedia) several million entities and half a billion facts about them.", "labels": [], "entities": [{"text": "DBpedia", "start_pos": 82, "end_pos": 89, "type": "DATASET", "confidence": 0.9621889591217041}]}, {"text": "This wealth of data allows to satisfy the information needs of advanced Internet users by raising queries from keywords to entities.", "labels": [], "entities": []}, {"text": "This enables queries like \"Who is married to Prince Charles?\" or \"Who are the teammates of Lionel Messi at FC Barcelona?\".", "labels": [], "entities": []}, {"text": "However, factual knowledge is highly ephemeral: Royals get married and divorced, politicians hold positions only fora limited time and soccer players transfer from one club to another.", "labels": [], "entities": []}, {"text": "Consequently, knowledge bases should be able to support more sophisticated temporal queries at entity-level, such as \"Who have been the spouses of Prince Charles before 2000?\" or \"Who are the teammates of Lionel Messi at FC Barcelona in the season In order to achieve this goal, the next big step is to distill temporal knowledge from the Web.", "labels": [], "entities": []}, {"text": "Extracting temporal facts is a complex and timeconsuming endeavor.", "labels": [], "entities": [{"text": "Extracting temporal facts", "start_pos": 0, "end_pos": 25, "type": "TASK", "confidence": 0.9157854914665222}]}, {"text": "There are \"conservative\" strategies that aim at high precision, but they tend to suffer from low recall.", "labels": [], "entities": [{"text": "precision", "start_pos": 53, "end_pos": 62, "type": "METRIC", "confidence": 0.9975038170814514}, {"text": "recall", "start_pos": 97, "end_pos": 103, "type": "METRIC", "confidence": 0.9991292357444763}]}, {"text": "On the contrary, there are \"aggressive\" approaches that target at high recall, but frequently suffer from low precision.", "labels": [], "entities": [{"text": "recall", "start_pos": 71, "end_pos": 77, "type": "METRIC", "confidence": 0.9993078708648682}, {"text": "precision", "start_pos": 110, "end_pos": 119, "type": "METRIC", "confidence": 0.9975233674049377}]}, {"text": "To this end, we introduce a method that allows us to gain maximum benefit from both \"worlds\" by \"aggressively\" gathering fact candidates and subsequently \"cleaning-up\" the incorrect ones.", "labels": [], "entities": []}, {"text": "The salient properties of our approach and the novel contributions of this paper are the following: \u2022 A temporal fact extraction strategy that is able to efficiently gather thousands of fact candidates based on a handful of seed facts.", "labels": [], "entities": [{"text": "temporal fact extraction", "start_pos": 104, "end_pos": 128, "type": "TASK", "confidence": 0.658616304397583}]}, {"text": "\u2022 An ILP solver incorporating constraints on temporal relations among events (e.g., marriage of a person must be non-overlapping in time).", "labels": [], "entities": [{"text": "ILP solver", "start_pos": 5, "end_pos": 15, "type": "TASK", "confidence": 0.8724996149539948}]}, {"text": "\u2022 Experiments on real world news and Wikipedia articles showing that we gain recall while keeping up with precision.", "labels": [], "entities": [{"text": "recall", "start_pos": 77, "end_pos": 83, "type": "METRIC", "confidence": 0.9993657469749451}, {"text": "precision", "start_pos": 106, "end_pos": 115, "type": "METRIC", "confidence": 0.9991833567619324}]}], "datasetContent": [{"text": "Experiments are conducted in the soccer and the celebrity domain by considering the worksForClub and isMarriedTo relation, respectively.", "labels": [], "entities": []}, {"text": "For each person in the \"FIFA 100 list\" and \"Forbes 100 list\" we retrieve their Wikipedia article.", "labels": [], "entities": [{"text": "FIFA 100 list", "start_pos": 24, "end_pos": 37, "type": "DATASET", "confidence": 0.9354597528775533}, {"text": "Forbes 100 list", "start_pos": 44, "end_pos": 59, "type": "DATASET", "confidence": 0.9264098405838013}]}, {"text": "In addition, we obtained about 80,000 documents for the soccer domain and 370,000 documents for the celebrity domain from BBC, The Telegraph, Times Online and ESPN by querying Google's News Archive Search 1 in the time window from 1990-2011.", "labels": [], "entities": [{"text": "BBC", "start_pos": 122, "end_pos": 125, "type": "DATASET", "confidence": 0.9213576912879944}, {"text": "The Telegraph", "start_pos": 127, "end_pos": 140, "type": "DATASET", "confidence": 0.8913786709308624}, {"text": "Times Online", "start_pos": 142, "end_pos": 154, "type": "DATASET", "confidence": 0.8870817720890045}, {"text": "News Archive Search 1", "start_pos": 185, "end_pos": 206, "type": "DATASET", "confidence": 0.838507741689682}]}, {"text": "All hyperparameters are tuned on a separate data-set.", "labels": [], "entities": []}, {"text": "For each relation we manually select the 10 positive and negative fact candidates with highest occurrence frequencies in the corpus as seeds.", "labels": [], "entities": []}, {"text": "We evaluate precision by randomly sampling 50 (isMarriedTo) and 100 (worksForClub) facts for each observation type and manually evaluating them against the text documents.", "labels": [], "entities": [{"text": "precision", "start_pos": 12, "end_pos": 21, "type": "METRIC", "confidence": 0.9991002082824707}]}, {"text": "All experimental data is available for download from our website 2 .", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Pipeline vs. Joint Model", "labels": [], "entities": []}]}