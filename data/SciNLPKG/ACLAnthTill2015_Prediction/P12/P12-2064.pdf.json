{"title": [{"text": "A Meta Learning Approach to Grammatical Error Correction", "labels": [], "entities": [{"text": "Grammatical Error Correction", "start_pos": 28, "end_pos": 56, "type": "TASK", "confidence": 0.7559543550014496}]}], "abstractContent": [{"text": "We introduce a novel method for grammatical error correction with a number of small corpora.", "labels": [], "entities": [{"text": "grammatical error correction", "start_pos": 32, "end_pos": 60, "type": "TASK", "confidence": 0.6209075351556143}]}, {"text": "To make the best use of several corpora with different characteristics, we employ a meta-learning with several base classifiers trained on different corpora.", "labels": [], "entities": []}, {"text": "This research focuses on a grammatical error correction task for article errors.", "labels": [], "entities": [{"text": "grammatical error correction", "start_pos": 27, "end_pos": 55, "type": "TASK", "confidence": 0.5886207421620687}]}, {"text": "A series of experiments is presented to show the effectiveness of the proposed approach on two different grammatical error tagged corpora.", "labels": [], "entities": []}], "introductionContent": [{"text": "As language learning has drawn significant attention in the community, grammatical error correction (GEC), consequently, has attracted a fair amount of attention.", "labels": [], "entities": [{"text": "grammatical error correction (GEC)", "start_pos": 71, "end_pos": 105, "type": "TASK", "confidence": 0.7097494254509608}]}, {"text": "Several organizations have built diverse resources including grammatical error (GE) tagged corpora.", "labels": [], "entities": [{"text": "grammatical error (GE) tagged corpora", "start_pos": 61, "end_pos": 98, "type": "TASK", "confidence": 0.7175675673144204}]}, {"text": "Although there are some publicly released GE tagged corpora, it is still challenging to train a good GEC model due to the lack of large GE tagged learner corpus.", "labels": [], "entities": [{"text": "GE tagged learner corpus", "start_pos": 136, "end_pos": 160, "type": "DATASET", "confidence": 0.7921796143054962}]}, {"text": "The available GE tagged corpora are mostly small datasets having different characteristics depending on the development methods, e.g. spoken corpus vs. written corpus.", "labels": [], "entities": []}, {"text": "This situation forced researchers to utilize native corpora rather than GE tagged learner corpora for the GEC task.", "labels": [], "entities": []}, {"text": "The native corpus approach consists of learning a model that predicts the correct form of an article given the surrounding context.", "labels": [], "entities": []}, {"text": "Some researchers focused on mining better features from the linguistic and pedagogic knowledge, whereas others focused on testing different classification methods.", "labels": [], "entities": []}, {"text": "Recently, a group of researchers introduced methods utilizing a GE tagged learner corpus to derive more accurate results (.", "labels": [], "entities": [{"text": "GE tagged learner corpus", "start_pos": 64, "end_pos": 88, "type": "DATASET", "confidence": 0.7110064029693604}]}, {"text": "Since the two approaches are closely related to each other, they can be informative to each other.", "labels": [], "entities": []}, {"text": "For example, proposed a method that combines a native corpus and a GE tagged learner corpus and it outperformed models trained with either a native or GE tagged learner corpus alone.", "labels": [], "entities": []}, {"text": "However, methods which train a GEC model from various GE tagged corpora have received less focus.", "labels": [], "entities": []}, {"text": "In this paper, we present a novel approach to the GEC task using meta-learning.", "labels": [], "entities": [{"text": "GEC task", "start_pos": 50, "end_pos": 58, "type": "TASK", "confidence": 0.8982803225517273}]}, {"text": "We focus mainly on article errors for two reasons.", "labels": [], "entities": []}, {"text": "First, articles are one of the most significant sources of GE for the learners with various L1 backgrounds.", "labels": [], "entities": [{"text": "GE", "start_pos": 59, "end_pos": 61, "type": "METRIC", "confidence": 0.5212078094482422}]}, {"text": "Second, the effective features for article error correction are already well engineered allowing for quick analysis of the method.", "labels": [], "entities": [{"text": "article error correction", "start_pos": 35, "end_pos": 59, "type": "TASK", "confidence": 0.73476775487264}]}, {"text": "Our approach is distinguished from others by integrating the predictive models trained on several GE tagged learner corpora, rather than just one GE tagged corpus.", "labels": [], "entities": []}, {"text": "Moreover, the framework is compatible to any classification technique.", "labels": [], "entities": []}, {"text": "In this study, we also use a native corpus employing Dahlmeier and Ng's approach.", "labels": [], "entities": []}, {"text": "We demonstrate the effectiveness of the proposed method against baseline models in article error correction tasks.", "labels": [], "entities": [{"text": "article error correction tasks", "start_pos": 83, "end_pos": 113, "type": "TASK", "confidence": 0.7675247043371201}]}, {"text": "The remainder of this paper is organized as follows: Section 2 explains our proposed method.", "labels": [], "entities": []}, {"text": "The experiments are presented in Section 3.", "labels": [], "entities": []}, {"text": "Finally, Section 4 concludes the paper.", "labels": [], "entities": []}], "datasetContent": [{"text": "The effectiveness of the proposed method is evaluated in terms of accuracy, precision, recall, and F 1 -score ().", "labels": [], "entities": [{"text": "accuracy", "start_pos": 66, "end_pos": 74, "type": "METRIC", "confidence": 0.9996477365493774}, {"text": "precision", "start_pos": 76, "end_pos": 85, "type": "METRIC", "confidence": 0.9997116923332214}, {"text": "recall", "start_pos": 87, "end_pos": 93, "type": "METRIC", "confidence": 0.9998279809951782}, {"text": "F 1 -score", "start_pos": 99, "end_pos": 109, "type": "METRIC", "confidence": 0.9880076199769974}]}, {"text": "Accuracy is the number of correct predictions divided by the total number of instances.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 0, "end_pos": 8, "type": "METRIC", "confidence": 0.9952072501182556}]}, {"text": "Precision is the ratio of the suggested corrections that agree with the tagged answer to the total number of the suggested corrections whereas recall is the ratio of the suggested corrections that agree with the tagged answer to the total number of corrections in the corpus.", "labels": [], "entities": [{"text": "Precision", "start_pos": 0, "end_pos": 9, "type": "METRIC", "confidence": 0.9899863600730896}, {"text": "recall", "start_pos": 143, "end_pos": 149, "type": "METRIC", "confidence": 0.9993896484375}]}, {"text": "In this work we used a native corpus and two GE tagged corpora.", "labels": [], "entities": []}, {"text": "For the native corpus, we used 1 http://nlp.stanford.edu/software/corenlp.shtml news data 2 which is a large English text extracted from news articles.", "labels": [], "entities": []}, {"text": "The First Certificate in English exams in the Cambridge Learner Corpus 3 (hereafter, CLC-FCE;) and the Japanese Learner English corpus) were used for the GE tagged corpora.", "labels": [], "entities": [{"text": "Cambridge Learner Corpus 3", "start_pos": 46, "end_pos": 72, "type": "DATASET", "confidence": 0.9548785239458084}, {"text": "Japanese Learner English corpus", "start_pos": 103, "end_pos": 134, "type": "DATASET", "confidence": 0.8541908860206604}, {"text": "GE tagged corpora", "start_pos": 154, "end_pos": 171, "type": "DATASET", "confidence": 0.776747465133667}]}, {"text": "We extracted noun phrases from each corpus by parsing the text of the respective corpora.", "labels": [], "entities": []}, {"text": "(1) We parsed the native corpus from the beginning until approximately a million noun phrases are extracted.", "labels": [], "entities": []}, {"text": "(2) About 90k noun phrases containing ~3,300 mistakes in article usage were extracted from the entire CLC-FCE corpus, and (3) about 30k noun phrases containing ~2,500 mistakes were extracted from the JLE corpus.", "labels": [], "entities": [{"text": "CLC-FCE corpus", "start_pos": 102, "end_pos": 116, "type": "DATASET", "confidence": 0.9245785176753998}, {"text": "JLE corpus", "start_pos": 200, "end_pos": 210, "type": "DATASET", "confidence": 0.9383930563926697}]}, {"text": "The extracted noun phrases were used for our training and test data.", "labels": [], "entities": []}, {"text": "We holdout 10% of the data for the test.", "labels": [], "entities": []}, {"text": "We applied 20% under-sampling to the training instances that do not have any errors to alleviate data imbalance in the training set.", "labels": [], "entities": []}, {"text": "We emphasize the fact that the two learner corpora differ from each other in three aspects.", "labels": [], "entities": []}, {"text": "The first aspect is the styles of the texts: the CLC is literary whereas the JLE is colloquial.", "labels": [], "entities": [{"text": "JLE", "start_pos": 77, "end_pos": 80, "type": "DATASET", "confidence": 0.7784356474876404}]}, {"text": "The second is the error rate: about 3.5% for CLC-FCE and 8.5% for JLE.", "labels": [], "entities": [{"text": "error rate", "start_pos": 18, "end_pos": 28, "type": "METRIC", "confidence": 0.9872323274612427}, {"text": "JLE", "start_pos": 66, "end_pos": 69, "type": "DATASET", "confidence": 0.5827791094779968}]}, {"text": "Finally, the third is the distribution of L1 languages of the learners: the learners of the CLC corpus have various L1 backgrounds whereas the learners of the JLE consist of only Japanese.", "labels": [], "entities": [{"text": "CLC corpus", "start_pos": 92, "end_pos": 102, "type": "DATASET", "confidence": 0.8505231440067291}]}, {"text": "These experiments demonstrate the effectiveness of the proposed method relying on the diversity of the corpora.", "labels": [], "entities": []}, {"text": "The native corpus was used to find the common structure using structural learning and two GE tagged learner corpora are used to train the base classifiers by structural learning with the common structure obtained from the news corpus.", "labels": [], "entities": []}, {"text": "We trained three classifiers for comparison; (1) the classifier (INTEG) trained with the integrated training set of the two GE tagged corpora, and two base classifiers used for the ensemble: (2) the base classifier (CB) trained only with the CLC-FCE and (3) the other base classifier (JB) trained with the JLE.", "labels": [], "entities": [{"text": "INTEG", "start_pos": 65, "end_pos": 70, "type": "METRIC", "confidence": 0.9690574407577515}, {"text": "JLE", "start_pos": 306, "end_pos": 309, "type": "DATASET", "confidence": 0.8459761142730713}]}], "tableCaptions": [{"text": " Table 1: Best results for GEC task on CLC-FCE  test set.", "labels": [], "entities": [{"text": "GEC task", "start_pos": 27, "end_pos": 35, "type": "TASK", "confidence": 0.6041669845581055}, {"text": "CLC-FCE  test set", "start_pos": 39, "end_pos": 56, "type": "DATASET", "confidence": 0.9597131609916687}]}, {"text": " Table 2: Best results for GEC task on JLE test set.", "labels": [], "entities": [{"text": "GEC task", "start_pos": 27, "end_pos": 35, "type": "TASK", "confidence": 0.4536198526620865}, {"text": "JLE test set", "start_pos": 39, "end_pos": 51, "type": "DATASET", "confidence": 0.9111099640528361}]}, {"text": " Table 3: Best results for GEC task on the  integrated set of CLC-FCE and JLE test sets.", "labels": [], "entities": [{"text": "GEC task", "start_pos": 27, "end_pos": 35, "type": "TASK", "confidence": 0.6883901357650757}, {"text": "JLE test sets", "start_pos": 74, "end_pos": 87, "type": "DATASET", "confidence": 0.795363038778305}]}]}