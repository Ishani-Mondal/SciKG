{"title": [{"text": "FLOW: A First-Language-Oriented Writing Assistant System", "labels": [], "entities": [{"text": "FLOW", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.6161037683486938}]}], "abstractContent": [{"text": "Writing in English might be one of the most difficult tasks for EFL (English as a Foreign Language) learners.", "labels": [], "entities": [{"text": "Writing in English", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.8882313966751099}, {"text": "EFL (English as a Foreign Language) learners", "start_pos": 64, "end_pos": 108, "type": "DATASET", "confidence": 0.7677831980917189}]}, {"text": "This paper presents FLOW, a writing assistance system.", "labels": [], "entities": [{"text": "FLOW", "start_pos": 20, "end_pos": 24, "type": "METRIC", "confidence": 0.4836512506008148}]}, {"text": "It is built based on first-language-oriented input function and context sensitive approach, aiming at providing immediate and appropriate suggestions including translations, paraphrases, and n-grams during composing and revising processes.", "labels": [], "entities": []}, {"text": "FLOW is expected to help EFL writers achieve their writing flow without being interrupted by their insufficient lexical knowledge.", "labels": [], "entities": [{"text": "FLOW", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.7110908627510071}]}], "introductionContent": [{"text": "Writing in a second language (L2) is a challenging and complex process for foreign language learners.", "labels": [], "entities": [{"text": "Writing in a second language (L2)", "start_pos": 0, "end_pos": 33, "type": "TASK", "confidence": 0.8864471092820168}]}, {"text": "Insufficient lexical knowledge and limited exposure to English might interrupt their writing flow.", "labels": [], "entities": []}, {"text": "Numerous writing instructions have been proposed as well as writing handbooks have been available for learners.", "labels": [], "entities": []}, {"text": "Studies have revealed that during the writing process, EFL learners show the inclination to rely on their native languages to prevent a breakdown in the writing process.", "labels": [], "entities": []}, {"text": "However, existing writing courses and instruction materials, almost second-language-oriented, seem unable to directly assist EFL writers while writing.", "labels": [], "entities": []}, {"text": "This paper presents FLOW 1), an interactive system for assisting EFL writers in 1 FLOW: http:// flowacldemo.appspot.com composing and revising writing.", "labels": [], "entities": []}, {"text": "Different from existing tools, its context-sensitive and firstlanguage-oriented features enable EFL writers to concentrate on their ideas and thoughts without being hampered by the limited lexical resources.", "labels": [], "entities": []}, {"text": "Based on the studies that first language use can positively affect second language composing, FLOW attempts to meet such needs.", "labels": [], "entities": [{"text": "second language composing", "start_pos": 67, "end_pos": 92, "type": "TASK", "confidence": 0.6653580069541931}, {"text": "FLOW", "start_pos": 94, "end_pos": 98, "type": "TASK", "confidence": 0.6242533922195435}]}, {"text": "Given any L1 input, FLOW displays appropriate suggestions including translation, paraphrases, and n-grams during composing and revising processes.", "labels": [], "entities": []}, {"text": "We use the following example sentences to illustrate these two functionalities.", "labels": [], "entities": []}, {"text": "Consider the sentence \"We propose a method to\".", "labels": [], "entities": []}, {"text": "During the composing stage, suppose a writer is unsure of the phrase \"solve the problem\", he could write \"\u89e3\u6c7a\u554f\u984c\", a corresponding word in his native language, like \"We propose a method to \u89e3\u6c7a\u554f\u984c\".", "labels": [], "entities": []}, {"text": "The writer's input in the writing area of FLOW actively triggers a set of translation suggestions such as \"solve the problem\" and \"tackle the problem\" for him/her to complete the sentence.", "labels": [], "entities": []}, {"text": "In the revising stage, the writer intends to improve or correct the content.", "labels": [], "entities": []}, {"text": "He/She is likely to change the sentence illustrated above into \"We try all means to solve the problem.\"", "labels": [], "entities": []}, {"text": "He would select the phrase \"propose a method\" in the original sentence and input a L1 phrase \"\u76e1\u529b\", which specifies the meaning he prefers.", "labels": [], "entities": []}, {"text": "The L1 input triggers a set of context-aware suggestions corresponding to the translations such as \"try our best\" and \"do our best\" rather than \"try your best\" and \"do your best\".", "labels": [], "entities": []}, {"text": "The system is able to do that mainly by taking a context-sensitive approach.", "labels": [], "entities": []}, {"text": "FLOW then inserts the phrase the writer selects into the sentence.", "labels": [], "entities": [{"text": "FLOW", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.7973184585571289}]}, {"text": "In this paper, we propose a context-sensitive disambiguation model which aims to automatically choose the appropriate phrases in different contexts when performing n-gram prediction, paraphrase suggestion and translation tasks.", "labels": [], "entities": [{"text": "n-gram prediction", "start_pos": 164, "end_pos": 181, "type": "TASK", "confidence": 0.701811283826828}, {"text": "paraphrase suggestion and translation", "start_pos": 183, "end_pos": 220, "type": "TASK", "confidence": 0.6407881751656532}]}, {"text": "As described in), the disambiguation model plays an important role in the machine translation task.", "labels": [], "entities": [{"text": "machine translation task", "start_pos": 74, "end_pos": 98, "type": "TASK", "confidence": 0.8544372717539469}]}, {"text": "Similar to their work, we further integrate the multi-word phrasal lexical disambiguation model to the n-gram prediction model, paraphrase model and translation model of our system.", "labels": [], "entities": []}, {"text": "With the phrasal disambiguation model, the output of the system is sensitive to the context the writer is working on.", "labels": [], "entities": []}, {"text": "The context-sensitive feature helps writers find the appropriate phrase while composing and revising.", "labels": [], "entities": []}, {"text": "This paper is organized as follows.", "labels": [], "entities": []}, {"text": "We review the related work in the next section.", "labels": [], "entities": []}, {"text": "In Section 3, we brief our system and method.", "labels": [], "entities": []}, {"text": "Section 4 reports the evaluation results.", "labels": [], "entities": []}, {"text": "We conclude this paper and point out future directions to research in Section 5.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section, we describe the experimental setting and the preliminary results.", "labels": [], "entities": []}, {"text": "Instead of training a whole machine translation using toolkits such as Moses, we used only bilingual phrase alignment as translations to prevent from the noise produced by the machine translation decoder.", "labels": [], "entities": [{"text": "phrase alignment", "start_pos": 101, "end_pos": 117, "type": "TASK", "confidence": 0.725067064166069}]}, {"text": "Word alignments were produced using Giza++ toolkit, over a set of 2,220,570 Chinese-English sentence pairs in Hong Kong Parallel Text (LDC2004T08) with sentences segmented using the CKIP Chinese word segmentation system.", "labels": [], "entities": [{"text": "Word alignments", "start_pos": 0, "end_pos": 15, "type": "TASK", "confidence": 0.694128543138504}, {"text": "Hong Kong Parallel Text (LDC2004T08)", "start_pos": 110, "end_pos": 146, "type": "DATASET", "confidence": 0.8553716880934579}, {"text": "CKIP Chinese word segmentation", "start_pos": 182, "end_pos": 212, "type": "TASK", "confidence": 0.8619387596845627}]}, {"text": "In training the phrasal lexical disambiguation model, we used the English part of Hong Kong Parallel Text as our training data.", "labels": [], "entities": [{"text": "phrasal lexical disambiguation", "start_pos": 16, "end_pos": 46, "type": "TASK", "confidence": 0.6312406659126282}, {"text": "English part of Hong Kong Parallel Text", "start_pos": 66, "end_pos": 105, "type": "DATASET", "confidence": 0.7185834731374469}]}, {"text": "To assess the effectiveness of FLOW, we selected 10 Chinese sentences and asked two students to translate the Chinese sentences to English sentences using FLOW.", "labels": [], "entities": [{"text": "FLOW", "start_pos": 31, "end_pos": 35, "type": "TASK", "confidence": 0.7244908809661865}, {"text": "FLOW", "start_pos": 155, "end_pos": 159, "type": "DATASET", "confidence": 0.9530738592147827}]}, {"text": "We kept track of the sentences the two students entered.", "labels": [], "entities": []}, {"text": "Both of the paraphrase models CS-PS and TB-PS perform quite well in assisting the user in the writing task.", "labels": [], "entities": []}, {"text": "However, there are still some problems such as the redundancy suggestions, e.g., \"look forward to\" and \"looked forward to\".", "labels": [], "entities": []}, {"text": "Besides, although we used the POS tags as features, the syntactic structures of the suggestions are still not consistent to an input or selected phrases.", "labels": [], "entities": []}, {"text": "The CS-NP and the TB-NP model also perform a good task.", "labels": [], "entities": []}, {"text": "However, the suggested phrases are usually too short to be a semantic unit.", "labels": [], "entities": []}, {"text": "The disambiguation model tends to produce shorter phrases because they have more common context features.", "labels": [], "entities": []}], "tableCaptions": []}