{"title": [{"text": "Historical Analysis of Legal Opinions with a Sparse Mixed-Effects Latent Variable Model", "labels": [], "entities": [{"text": "Historical Analysis of Legal Opinions", "start_pos": 0, "end_pos": 37, "type": "TASK", "confidence": 0.7964013099670411}]}], "abstractContent": [{"text": "We propose a latent variable model to enhance historical analysis of large corpora.", "labels": [], "entities": []}, {"text": "This work extends prior work in topic modelling by incorporating metadata, and the interactions between the components in metadata, in a general way.", "labels": [], "entities": [{"text": "topic modelling", "start_pos": 32, "end_pos": 47, "type": "TASK", "confidence": 0.7739091515541077}]}, {"text": "To test this, we collect a corpus of slavery-related United States property law judgements sampled from the years 1730 to 1866.", "labels": [], "entities": []}, {"text": "We study the language use in these legal cases, with a special focus on shifts in opinions on controversial topics across different regions.", "labels": [], "entities": []}, {"text": "Because this is a longitudinal data set, we are also interested in understanding how these opinions changeover the course of decades.", "labels": [], "entities": []}, {"text": "We show that the joint learning scheme of our sparse mixed-effects model improves on other state-of-the-art generative and discriminative models on the region and time period identification tasks.", "labels": [], "entities": [{"text": "time period identification tasks", "start_pos": 163, "end_pos": 195, "type": "TASK", "confidence": 0.7145766317844391}]}, {"text": "Experiments show that our sparse mixed-effects model is more accurate quantitatively and qualitatively interesting , and that these improvements are robust across different parameter settings.", "labels": [], "entities": []}], "introductionContent": [{"text": "Many scientific subjects, such as psychology, learning sciences, and biology, have adopted computational approaches to discover latent patterns in large scale datasets.", "labels": [], "entities": []}, {"text": "In contrast, the primary methods for historical research still rely on individual judgement and reading primary and secondary sources, which are time consuming and expensive.", "labels": [], "entities": []}, {"text": "Furthermore, traditional human-based methods might have good precision when searching for relevant information, but suffer from low recall.", "labels": [], "entities": [{"text": "precision", "start_pos": 61, "end_pos": 70, "type": "METRIC", "confidence": 0.9985729455947876}, {"text": "recall", "start_pos": 132, "end_pos": 138, "type": "METRIC", "confidence": 0.9985718727111816}]}, {"text": "Even when language technologies have been applied to historical problems, their focus has often been on information retrieval (, to improve accessibility of texts.", "labels": [], "entities": [{"text": "information retrieval", "start_pos": 104, "end_pos": 125, "type": "TASK", "confidence": 0.7379758358001709}]}, {"text": "Empirical methods for analysis and interpretation of these texts is therefore a burgeoning new field.", "labels": [], "entities": [{"text": "analysis and interpretation of these texts", "start_pos": 22, "end_pos": 64, "type": "TASK", "confidence": 0.7524353861808777}]}, {"text": "Court opinions form one of the most important parts of the legal domain, and can serve as an excellent resource to understand both legal and political history.", "labels": [], "entities": []}, {"text": "Historians often use court opinions as a primary source for constructing interpretations of the past.", "labels": [], "entities": []}, {"text": "They not only report the proceedings of a court, but also express a judges' views toward the issues at hand in a case, and reflect the legal and political environment of the region and period.", "labels": [], "entities": []}, {"text": "Since there exists many thousands of early court opinions, however, it is difficult for legal historians to manually analyze the documents case by case.", "labels": [], "entities": []}, {"text": "Instead, historians often restrict themselves to discussing a relatively small subset of legal opinions that are considered decisive.", "labels": [], "entities": []}, {"text": "While this approach has merit, new technologies should allow extraction of patterns from large samples of opinions.", "labels": [], "entities": [{"text": "extraction of patterns from large samples of opinions", "start_pos": 61, "end_pos": 114, "type": "TASK", "confidence": 0.7882473990321159}]}, {"text": "Latent variable models, such as latent Dirichlet allocation (LDA) ( and probabilistic latent semantic analysis (PLSA), have been used in the past to facilitate social science research.", "labels": [], "entities": [{"text": "latent Dirichlet allocation (LDA)", "start_pos": 32, "end_pos": 65, "type": "TASK", "confidence": 0.642127051949501}, {"text": "probabilistic latent semantic analysis (PLSA)", "start_pos": 72, "end_pos": 117, "type": "TASK", "confidence": 0.7480090260505676}]}, {"text": "However, they have numerous drawbacks, as many topics are uninterpretable, overwhelmed by uninformative words, or represent background language use that is unrelated to the dimensions of analysis that qualitative researchers are interested in.", "labels": [], "entities": []}, {"text": "SAGE (), a recently proposed sparse additive generative model of language, addresses many of the drawbacks of LDA.", "labels": [], "entities": []}, {"text": "SAGE assumes a background distribution of language use, and enforces sparsity in individual topics.", "labels": [], "entities": []}, {"text": "Another advantage, from asocial science perspective, is that SAGE can be derived from a standard logit randomutility model of judicial opinion writing, in contrast to LDA.", "labels": [], "entities": [{"text": "SAGE", "start_pos": 61, "end_pos": 65, "type": "TASK", "confidence": 0.9018944501876831}, {"text": "judicial opinion writing", "start_pos": 126, "end_pos": 150, "type": "TASK", "confidence": 0.6734295686086019}]}, {"text": "In this work we extend SAGE to the supervised case of joint region and time period prediction.", "labels": [], "entities": [{"text": "SAGE", "start_pos": 23, "end_pos": 27, "type": "TASK", "confidence": 0.9749994874000549}, {"text": "joint region and time period prediction", "start_pos": 54, "end_pos": 93, "type": "TASK", "confidence": 0.5770240376393}]}, {"text": "We formulate the resulting sparse mixedeffects (SME) model as being made up of mixed effects that not only contain random effects from sparse topics, but also mixed effects from available metadata.", "labels": [], "entities": []}, {"text": "To do this we augment SAGE with two sparse latent variables that model the region and time of a document, as well as a third sparse latent variable that captures the interactions among the region, time and topic latent variables.", "labels": [], "entities": []}, {"text": "We also introduce a multiclass perceptron-style weight estimation method to model the contributions from different sparse latent variables to the word posterior probabilities in this predictive task.", "labels": [], "entities": []}, {"text": "Importantly, the resulting distributions are still sparse and can therefore be qualitatively analyzed by experts with relatively little noise.", "labels": [], "entities": []}, {"text": "In the next two sections, we overview work related to qualitative social science analysis using latent variable models, and introduce our slaveryrelated early United States court opinion data.", "labels": [], "entities": [{"text": "qualitative social science analysis", "start_pos": 54, "end_pos": 89, "type": "TASK", "confidence": 0.6202409118413925}]}, {"text": "We describe our sparse mixed-effects model for joint modeling of region, time, and topic in section 4.", "labels": [], "entities": []}, {"text": "Experiments are presented in section 5, with a robust analysis from qualitative and quantitative standpoints in section 5.2, and we discuss the conclusions of this work in section 6.", "labels": [], "entities": []}], "datasetContent": [{"text": "We perform three quantitative experiments to evaluate the predictive power of the sparse mixed-effects model.", "labels": [], "entities": []}, {"text": "In these experiments, to predict the region and time period labels of a given document, we jointly learn the two labels in the SME model, and choose the pair which maximizes the probability of the document.", "labels": [], "entities": [{"text": "SME", "start_pos": 127, "end_pos": 130, "type": "TASK", "confidence": 0.9742257595062256}]}, {"text": "In the first experiment, we compare the prediction accuracy of our SME model to a widely used discriminative learner in NLP -the linear kernel support vector machine (SVM) 3 . In the second experiment, in addition to the linear kernel SVM, we also compare our SME model to a state-of-the-art sparse generative model of text, and vary the size of input vocabulary W exponentially from 2 9 to the full size of our training vocabulary . In the third experiment, we examine the robustness of our model by examining how the number of topics influences the prediction accuracy when varying the K from 10 to 50.", "labels": [], "entities": [{"text": "SME", "start_pos": 67, "end_pos": 70, "type": "TASK", "confidence": 0.9784796833992004}, {"text": "SME", "start_pos": 260, "end_pos": 263, "type": "TASK", "confidence": 0.9696126580238342}, {"text": "accuracy", "start_pos": 562, "end_pos": 570, "type": "METRIC", "confidence": 0.930905282497406}]}, {"text": "Our data consists of 4615 training documents and 625 held-out documents for testing.", "labels": [], "entities": []}, {"text": "While individual judges wrote multiple opinions in our corpus, no judges overlapped between training and test sets.", "labels": [], "entities": []}, {"text": "When measuring by the majority class in the testing condition, the chance baseline for the region identification task is 57.1% and the time identification task is 32.3%.", "labels": [], "entities": [{"text": "region identification task", "start_pos": 91, "end_pos": 117, "type": "TASK", "confidence": 0.7257702946662903}]}, {"text": "We use three-fold cross-validation to infer the learning rate \u03b4 and cost C hyperpriors in the SME and SVM model respectively.", "labels": [], "entities": [{"text": "learning rate \u03b4", "start_pos": 48, "end_pos": 63, "type": "METRIC", "confidence": 0.8749669790267944}, {"text": "SME", "start_pos": 94, "end_pos": 97, "type": "TASK", "confidence": 0.7134490013122559}]}, {"text": "We use the paired student t-test to measure the statistical significance.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Compare the accuracy of the linear kernel sup- port vector machine to our sparse mixed-effects model in  the region and time identification tasks (K = 25). Gain:  the relative improvement of SME over SVM.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 22, "end_pos": 30, "type": "METRIC", "confidence": 0.9996052384376526}, {"text": "SME", "start_pos": 201, "end_pos": 204, "type": "TASK", "confidence": 0.9900632500648499}]}, {"text": " Table 2: A partial listing of an example for early United States state supreme court opinion keywords generated from  the time quartile \u03b7 (Q) , region \u03b7 (R) and topic-region-time \u03b7 (I) interactive variables in the sparse mixed-effects model.", "labels": [], "entities": []}]}