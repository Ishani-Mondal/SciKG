{"title": [{"text": "langid.py: An Off-the-shelf Language Identification Tool", "labels": [], "entities": []}], "abstractContent": [{"text": "We present langid.py, an off-the-shelf language identification tool.", "labels": [], "entities": [{"text": "language identification", "start_pos": 39, "end_pos": 62, "type": "TASK", "confidence": 0.736289769411087}]}, {"text": "We discuss the design and implementation of langid.py, and provide an empirical comparison on 5 long-document datasets, and 2 datasets from the mi-croblog domain.", "labels": [], "entities": []}, {"text": "We find that langid.py maintains consistently high accuracy across all domains, making it ideal for end-users that require language identification without wanting to invest in preparation of in-domain training data.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 51, "end_pos": 59, "type": "METRIC", "confidence": 0.9962424039840698}, {"text": "language identification", "start_pos": 123, "end_pos": 146, "type": "TASK", "confidence": 0.7152874916791916}]}], "introductionContent": [{"text": "Language identification (LangID) is the task of determining the natural language that a document is written in.", "labels": [], "entities": [{"text": "Language identification (LangID)", "start_pos": 0, "end_pos": 32, "type": "TASK", "confidence": 0.8199665665626525}]}, {"text": "It is a key step in automatic processing of real-world data, where a multitude of languages maybe present.", "labels": [], "entities": []}, {"text": "Natural language processing techniques typically pre-suppose that all documents being processed are written in a given language (e.g. English), but as focus shifts onto processing documents from internet sources such as microblogging services, this becomes increasingly difficult to guarantee.", "labels": [], "entities": [{"text": "Natural language processing", "start_pos": 0, "end_pos": 27, "type": "TASK", "confidence": 0.598207970460256}]}, {"text": "Language identification is also a key component of many web services.", "labels": [], "entities": [{"text": "Language identification", "start_pos": 0, "end_pos": 23, "type": "TASK", "confidence": 0.6972752511501312}]}, {"text": "For example, the language that a web page is written in is an important consideration in determining whether it is likely to be of interest to a particular user of a search engine, and automatic identification is an essential step in building language corpora from the web.", "labels": [], "entities": [{"text": "automatic identification", "start_pos": 185, "end_pos": 209, "type": "TASK", "confidence": 0.6161003410816193}]}, {"text": "It has practical implications for social networking and social media, where it maybe desirable to organize comments and other user-generated content by language.", "labels": [], "entities": []}, {"text": "It also has implications for accessibility, since it enables automatic determination of the target language for automatic machine translation purposes.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 122, "end_pos": 141, "type": "TASK", "confidence": 0.7318284213542938}]}, {"text": "Many applications could potentially benefit from automatic language identification, but building a customized solution per-application is prohibitively expensive, especially if human annotation is required to produce a corpus of language-labelled training documents from the application domain.", "labels": [], "entities": [{"text": "automatic language identification", "start_pos": 49, "end_pos": 82, "type": "TASK", "confidence": 0.6735400954882304}]}, {"text": "What is required is thus a generic language identification tool that is usable off-the-shelf, i.e. with no end-user training and minimal configuration.", "labels": [], "entities": [{"text": "generic language identification", "start_pos": 27, "end_pos": 58, "type": "TASK", "confidence": 0.6449147860209147}]}, {"text": "In this paper, we present langid.py, a LangID tool with the following characteristics: (1) fast, (2) usable off-the-shelf, (3) unaffected by domainspecific features (e.g. HTML, XML, markdown), (4) single file with minimal dependencies, and (5) flexible interface", "labels": [], "entities": []}], "datasetContent": [{"text": "In order to benchmark langid.py, we carried out an empirical evaluation using a number of languagelabelled datasets.", "labels": [], "entities": []}, {"text": "We compare the empirical results obtained from langid.py to those obtained from other language identification toolkits which incorporate a pre-trained model, and are thus usable offthe-shelf for language identification.", "labels": [], "entities": [{"text": "language identification", "start_pos": 86, "end_pos": 109, "type": "TASK", "confidence": 0.7043094635009766}, {"text": "language identification", "start_pos": 195, "end_pos": 218, "type": "TASK", "confidence": 0.7971543073654175}]}, {"text": "These tools are listed in.", "labels": [], "entities": []}, {"text": "We compared the four systems on datasets used in previous language identification research) (EUROGOV, TCL, WIKIPEDIA), as well as an extract from a biomedical parallel corpus (Tiedemann, 2009) (EMEA) and a corpus of samples from the Europarl Parallel Corpus () (EUROPARL).", "labels": [], "entities": [{"text": "language identification", "start_pos": 58, "end_pos": 81, "type": "TASK", "confidence": 0.7696095705032349}, {"text": "EUROGOV", "start_pos": 93, "end_pos": 100, "type": "DATASET", "confidence": 0.8368920683860779}, {"text": "Europarl Parallel Corpus", "start_pos": 233, "end_pos": 257, "type": "DATASET", "confidence": 0.9361905852953593}]}, {"text": "The sample of EUROPARL we use was originally prepared by Shuyo Nakatani (author of LangDetect) as a validation set.", "labels": [], "entities": [{"text": "EUROPARL", "start_pos": 14, "end_pos": 22, "type": "DATASET", "confidence": 0.9260138869285583}]}, {"text": "langid.py compares very favorably with other language identification tools.", "labels": [], "entities": [{"text": "langid.py", "start_pos": 0, "end_pos": 9, "type": "DATASET", "confidence": 0.9070808291435242}, {"text": "language identification", "start_pos": 45, "end_pos": 68, "type": "TASK", "confidence": 0.7605670988559723}]}, {"text": "It outperforms TextCat in terms of speed and accuracy on all of the datasets considered.", "labels": [], "entities": [{"text": "TextCat", "start_pos": 15, "end_pos": 22, "type": "DATASET", "confidence": 0.9075596928596497}, {"text": "speed", "start_pos": 35, "end_pos": 40, "type": "METRIC", "confidence": 0.9954965114593506}, {"text": "accuracy", "start_pos": 45, "end_pos": 53, "type": "METRIC", "confidence": 0.998685896396637}]}, {"text": "langid.py is generally orders of magnitude faster than TextCat, but this advantage is reduced on larger documents.", "labels": [], "entities": [{"text": "langid.py", "start_pos": 0, "end_pos": 9, "type": "DATASET", "confidence": 0.9309016466140747}, {"text": "TextCat", "start_pos": 55, "end_pos": 62, "type": "DATASET", "confidence": 0.9552440047264099}]}, {"text": "This is primarily due to the design of TextCat, which requires that the supplied models be read from file for each document classified.", "labels": [], "entities": [{"text": "TextCat", "start_pos": 39, "end_pos": 46, "type": "DATASET", "confidence": 0.9444120526313782}]}], "tableCaptions": [{"text": " Table 1: Summary of the LangID datasets", "labels": [], "entities": [{"text": "LangID datasets", "start_pos": 25, "end_pos": 40, "type": "DATASET", "confidence": 0.9362877607345581}]}, {"text": " Table 2: Comparison of standalone classification tools, in terms of accuracy and speed (documents/second), relative  to langid.py", "labels": [], "entities": [{"text": "accuracy", "start_pos": 69, "end_pos": 77, "type": "METRIC", "confidence": 0.9993342757225037}, {"text": "speed", "start_pos": 82, "end_pos": 87, "type": "METRIC", "confidence": 0.9688462615013123}, {"text": "langid.py", "start_pos": 121, "end_pos": 130, "type": "DATASET", "confidence": 0.5808767676353455}]}]}