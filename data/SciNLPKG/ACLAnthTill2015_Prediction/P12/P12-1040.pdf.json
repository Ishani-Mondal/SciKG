{"title": [{"text": "A Discriminative Hierarchical Model for Fast Coreference at Large Scale", "labels": [], "entities": []}], "abstractContent": [{"text": "Methods that measure compatibility between mention pairs are currently the dominant approach to coreference.", "labels": [], "entities": [{"text": "coreference", "start_pos": 96, "end_pos": 107, "type": "TASK", "confidence": 0.9678164124488831}]}, {"text": "However, they suffer from a number of drawbacks including difficulties scaling to large numbers of mentions and limited representational power.", "labels": [], "entities": []}, {"text": "As these drawbacks become increasingly restrictive, the need to replace the pairwise approaches with a more expressive, highly scalable alternative is becoming urgent.", "labels": [], "entities": []}, {"text": "In this paper we propose a novel discriminative hierarchical model that recursively partitions entities into trees of latent sub-entities.", "labels": [], "entities": []}, {"text": "These trees succinctly summarize the mentions providing a highly compact, information-rich structure for reasoning about entities and coreference uncertainty at massive scales.", "labels": [], "entities": []}, {"text": "We demonstrate that the hierarchical model is several orders of magnitude faster than pairwise, allowing us to perform coreference on six million author mentions in under four hours on a single CPU.", "labels": [], "entities": []}], "introductionContent": [{"text": "Coreference resolution, the task of clustering mentions into partitions representing their underlying real-world entities, is fundamental for high-level information extraction and data integration, including semantic search, question answering, and knowledge base construction.", "labels": [], "entities": [{"text": "Coreference resolution", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.9194900691509247}, {"text": "information extraction", "start_pos": 153, "end_pos": 175, "type": "TASK", "confidence": 0.7508299946784973}, {"text": "data integration", "start_pos": 180, "end_pos": 196, "type": "TASK", "confidence": 0.7216465324163437}, {"text": "question answering", "start_pos": 225, "end_pos": 243, "type": "TASK", "confidence": 0.8851540088653564}, {"text": "knowledge base construction", "start_pos": 249, "end_pos": 276, "type": "TASK", "confidence": 0.6527811388174692}]}, {"text": "For example, coreference is vital for determining author publication lists in bibliographic knowledge bases such as CiteSeer and Google Scholar, where the repository must know if the \"R.", "labels": [], "entities": [{"text": "coreference", "start_pos": 13, "end_pos": 24, "type": "TASK", "confidence": 0.9568605422973633}]}, {"text": "Hamming\" who authored \"Error detecting and error correcting codes\" is the same\" \"R.", "labels": [], "entities": [{"text": "Error detecting and error correcting", "start_pos": 23, "end_pos": 59, "type": "TASK", "confidence": 0.6819692075252533}]}, {"text": "Hamming\" who authored \"The unreasonable effectiveness of mathematics.\"", "labels": [], "entities": []}, {"text": "Features of the mentions (e.g., bags-of-words in titles, contextual snippets and co-author lists) provide evidence for resolving such entities.", "labels": [], "entities": []}, {"text": "Over the years, various machine learning techniques have been applied to different variations of the coreference problem.", "labels": [], "entities": [{"text": "coreference problem", "start_pos": 101, "end_pos": 120, "type": "TASK", "confidence": 0.9363825023174286}]}, {"text": "A commonality in many of these approaches is that they model the problem of entity coreference as a collection of decisions between mention pairs (.", "labels": [], "entities": [{"text": "entity coreference", "start_pos": 76, "end_pos": 94, "type": "TASK", "confidence": 0.6903131008148193}]}, {"text": "That is, coreference is solved by answering a quadratic number of questions of the form \"does mention A refer to the same entity as mention B?\" with a compatibility function that indicates how likely A and B are coreferent.", "labels": [], "entities": [{"text": "coreference", "start_pos": 9, "end_pos": 20, "type": "TASK", "confidence": 0.985958993434906}]}, {"text": "While these models have been successful in some domains, they also exhibit several undesirable characteristics.", "labels": [], "entities": []}, {"text": "The first is that pairwise models lack the expressivity required to represent aggregate properties of the entities.", "labels": [], "entities": []}, {"text": "Recent work has shown that these entity-level properties allow systems to correct coreference errors made from myopic pairwise decisions, and can even provide a strong signal for unsupervised coreference.", "labels": [], "entities": []}, {"text": "A second problem, that has received significantly less attention in the literature, is that the pairwise coreference models scale poorly to large collections of mentions especially when the expected number of mentions in each entity cluster is also large.", "labels": [], "entities": []}, {"text": "Current systems cope with this by either dividing the data into blocks to reduce the search space (), using fixed heuristics to greedily compress the mentions, employing specialized Markov chain Monte Carlo procedures (;, or introducing shallow hierarchies of sub-entities for MCMC block moves and superentities for adaptive distributed inference).", "labels": [], "entities": [{"text": "MCMC block moves", "start_pos": 277, "end_pos": 293, "type": "TASK", "confidence": 0.6265893975893656}]}, {"text": "However, while these methods help manage the search space for medium-scale data, evaluating each coreference decision in many of these systems still scales linearly with the number of mentions in an entity, resulting in prohibitive computational costs associated with large datasets.", "labels": [], "entities": []}, {"text": "This scaling with the number of mentions per entity seems particularly wasteful because although it is common for an entity to be referenced by a large number of mentions, many of these coreferent mentions are highly similar to each other.", "labels": [], "entities": []}, {"text": "For example, in author coreference the two most common strings that refer to Richard Hamming might have the form \"R.", "labels": [], "entities": [{"text": "author coreference", "start_pos": 16, "end_pos": 34, "type": "TASK", "confidence": 0.7357447445392609}]}, {"text": "Hamming\" and \"Richard Hamming.\"", "labels": [], "entities": [{"text": "Richard Hamming", "start_pos": 14, "end_pos": 29, "type": "DATASET", "confidence": 0.882649302482605}]}, {"text": "In newswire coreference, a prominent entity like Barack Obama may have millions of \"Obama\" mentions (many occurring in similar semantic contexts).", "labels": [], "entities": []}, {"text": "Deciding whether a mention belongs to this entity need not involve comparisons to all contextually similar \"Obama\" mentions; rather we prefer a more compact representation in order to efficiently reason about them.", "labels": [], "entities": []}, {"text": "In this paper we propose a novel hierarchical discriminative factor graph for coreference resolution that recursively structures each entity as a tree of latent sub-entities with mentions at the leaves.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 78, "end_pos": 100, "type": "TASK", "confidence": 0.9772979021072388}]}, {"text": "Our hierarchical model avoids the aforementioned problems of the pairwise approach: not only can it jointly reason about attributes of entire entities (using the power of discriminative conditional random fields), but it is also able to scale to datasets with enormous numbers of mentions because scoring entities does not require computing a quadratic number of compatibility functions.", "labels": [], "entities": []}, {"text": "The key insight is that each node in the tree functions as a highly compact information-rich summary of its children.", "labels": [], "entities": []}, {"text": "Thus, a small handful of upper-level nodes may summarize millions of mentions (for example, a single node may summarize all contextually similar \"R. Hamming\" mentions).", "labels": [], "entities": [{"text": "summarize all contextually similar \"R. Hamming\" mentions", "start_pos": 110, "end_pos": 166, "type": "TASK", "confidence": 0.6397273739178976}]}, {"text": "Although inferring the structure of the entities requires reasoning over a larger statespace, the latent trees are actually beneficial to inference (as shown for shallow trees in), resulting in rapid progress toward high probability regions, and mirroring known benefits of auxiliary variable methods in statistical physics (such as).", "labels": [], "entities": []}, {"text": "Moreover, each step of inference is computationally efficient because evaluating the cost of attaching (or detaching) sub-trees requires computing just a single compatibility function (as seen in).", "labels": [], "entities": []}, {"text": "Further, our hierarchical approach provides a number of additional advantages.", "labels": [], "entities": []}, {"text": "First, the recursive nature of the tree (arbitrary depth and width) allows the model to adapt to different types of data and effectively compress entities of different scales (e.g., entities with more mentions may require a deeper hierarchy to compress).", "labels": [], "entities": []}, {"text": "Second, the model contains compatibility functions at all levels of the tree enabling it to simultaneously reason at multiple granularities of entity compression.", "labels": [], "entities": []}, {"text": "Third, the trees can provide split points for finer-grained entities by placing contextually similar mentions under the same subtree.", "labels": [], "entities": []}, {"text": "Finally, if memory is limited, redundant mentions can be pruned by replacing subtrees with their roots.", "labels": [], "entities": []}, {"text": "Empirically, we demonstrate that our model is several orders of magnitude faster than a pairwise model, allowing us to perform efficient coreference on nearly six million author mentions in under four hours using a single CPU.", "labels": [], "entities": []}], "datasetContent": [{"text": "Author coreference is a tremendously important task, enabling improved search and mining of scientific papers by researchers, funding agencies, and governments.", "labels": [], "entities": [{"text": "Author coreference", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.6403814554214478}]}, {"text": "The problem is extremely difficult due to the wide variations of names, limited contextual evidence, misspellings, people with common names, lack of standard citation formats, and large numbers of mentions.", "labels": [], "entities": []}, {"text": "For this task we use a publicly available collection of 4,394 BibTeX files containing 817,193 entries.", "labels": [], "entities": []}, {"text": "We extract 1,322,985 author mentions, each containing first, middle, last names, bags-of-words of paper titles, topics in paper titles (by running latent Dirichlet allocation (), and last names of co-authors.", "labels": [], "entities": []}, {"text": "In addition we include 2,833 mentions from the REXA dataset 4 labeled for coreference, in order to assess accuracy.", "labels": [], "entities": [{"text": "REXA dataset", "start_pos": 47, "end_pos": 59, "type": "DATASET", "confidence": 0.8989969193935394}, {"text": "accuracy", "start_pos": 106, "end_pos": 114, "type": "METRIC", "confidence": 0.9984174966812134}]}, {"text": "We also include \u223c5 million mentions from DBLP.", "labels": [], "entities": [{"text": "DBLP", "start_pos": 41, "end_pos": 45, "type": "DATASET", "confidence": 0.9703097343444824}]}, {"text": "In order to demonstrate the scalability of the hierarchical model, we run it on nearly 5 million author mentions from DBLP.", "labels": [], "entities": [{"text": "DBLP", "start_pos": 118, "end_pos": 122, "type": "DATASET", "confidence": 0.9202219247817993}]}, {"text": "In under two hours (6,700 seconds), we achieve an accuracy of 80%, and in under three hours (10,600 seconds), we achieve an accuracy of over 90%.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 50, "end_pos": 58, "type": "METRIC", "confidence": 0.9995723366737366}, {"text": "accuracy", "start_pos": 124, "end_pos": 132, "type": "METRIC", "confidence": 0.9994377493858337}]}, {"text": "Finally, we combine DBLP with BibTeX data to produce a dataset with almost 6 million mentions.", "labels": [], "entities": [{"text": "DBLP", "start_pos": 20, "end_pos": 24, "type": "DATASET", "confidence": 0.8299773931503296}, {"text": "BibTeX data", "start_pos": 30, "end_pos": 41, "type": "DATASET", "confidence": 0.8938429653644562}]}, {"text": "Our performance on this dataset is similar to DBLP, taking just 13,500 seconds to reach a 90% accuracy.", "labels": [], "entities": [{"text": "DBLP", "start_pos": 46, "end_pos": 50, "type": "DATASET", "confidence": 0.7015506625175476}, {"text": "accuracy", "start_pos": 94, "end_pos": 102, "type": "METRIC", "confidence": 0.9979454874992371}]}], "tableCaptions": []}