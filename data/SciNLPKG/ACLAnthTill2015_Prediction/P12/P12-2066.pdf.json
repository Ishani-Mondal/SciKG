{"title": [{"text": "Identifying High-Impact Sub-Structures for Convolution Kernels in Document-level Sentiment Classification", "labels": [], "entities": [{"text": "Identifying High-Impact Sub-Structures", "start_pos": 0, "end_pos": 38, "type": "TASK", "confidence": 0.8701622486114502}, {"text": "Document-level Sentiment Classification", "start_pos": 66, "end_pos": 105, "type": "TASK", "confidence": 0.693458358446757}]}], "abstractContent": [{"text": "Convolution kernels support the modeling of complex syntactic information in machine-learning tasks.", "labels": [], "entities": []}, {"text": "However, such models are highly sensitive to the type and size of syntactic structure used.", "labels": [], "entities": []}, {"text": "It is therefore an important challenge to automatically identify high impact sub-structures relevant to a given task.", "labels": [], "entities": []}, {"text": "In this paper we present a systematic study investigating (combinations of) sequence and con-volution kernels using different types of sub-structures in document-level sentiment classification.", "labels": [], "entities": [{"text": "document-level sentiment classification", "start_pos": 153, "end_pos": 192, "type": "TASK", "confidence": 0.6821272075176239}]}, {"text": "We show that minimal sub-structures extracted from constituency and dependency trees guided by a polarity lexicon show 1.45 point absolute improvement inaccuracy over a bag-of-words classifier on a widely used sentiment corpus.", "labels": [], "entities": []}], "introductionContent": [{"text": "An important subtask in sentiment analysis is sentiment classification.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 24, "end_pos": 42, "type": "TASK", "confidence": 0.9549156427383423}, {"text": "sentiment classification", "start_pos": 46, "end_pos": 70, "type": "TASK", "confidence": 0.9457167088985443}]}, {"text": "Sentiment classification involves the identification of positive and negative opinions from a text segment at various levels of granularity including document-level, paragraphlevel, sentence-level and phrase-level.", "labels": [], "entities": [{"text": "Sentiment classification", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.944274365901947}, {"text": "identification of positive and negative opinions from a text segment", "start_pos": 38, "end_pos": 106, "type": "TASK", "confidence": 0.7436360538005828}]}, {"text": "This paper focuses on document-level sentiment classification.", "labels": [], "entities": [{"text": "document-level sentiment classification", "start_pos": 22, "end_pos": 61, "type": "TASK", "confidence": 0.7509603500366211}]}, {"text": "There has been a substantial amount of work on document-level sentiment classification.", "labels": [], "entities": [{"text": "document-level sentiment classification", "start_pos": 47, "end_pos": 86, "type": "TASK", "confidence": 0.7808159093062083}]}, {"text": "In early pioneering work, use a flat feature vector (e.g., a bag-of-words) to represent the documents.", "labels": [], "entities": []}, {"text": "A bag-of-words approach, however, cannot capture important information obtained from structural linguistic analysis of the documents.", "labels": [], "entities": []}, {"text": "More recently, there have been several approaches which employ features based on deep linguistic analysis with encouraging results including and.", "labels": [], "entities": []}, {"text": "However, as they select features manually, these methods would require additional labor when ported to other languages and domains.", "labels": [], "entities": []}, {"text": "In this paper, we study and evaluate diverse linguistic structures encoded as convolution kernels for the document-level sentiment classification problem, in order to utilize syntactic structures without defining explicit linguistic rules.", "labels": [], "entities": [{"text": "document-level sentiment classification problem", "start_pos": 106, "end_pos": 153, "type": "TASK", "confidence": 0.752730131149292}]}, {"text": "While the application of kernel methods could seem intuitive for many tasks, it is non-trivial to apply convolution kernels to document-level sentiment classification: previous work has already shown that categorically using the entire syntactic structure of a single sentence would produce too many features fora convolution kernel (.", "labels": [], "entities": [{"text": "document-level sentiment classification", "start_pos": 127, "end_pos": 166, "type": "TASK", "confidence": 0.6744620005289713}]}, {"text": "We expect the situation to be worse for our task as we work with documents that tend to comprise dozens of sentences.", "labels": [], "entities": []}, {"text": "It is therefore necessary to choose appropriate substructures of a sentence as opposed to using the whole structure in order to effectively use convolution kernels in our task.", "labels": [], "entities": []}, {"text": "It has been observed that not every part of a document is equally informative for identifying the polarity of the whole document (): a film review often uses lengthy objective paragraphs to simply describe the plot.", "labels": [], "entities": []}, {"text": "Such objective portions do not contain the author's opinion and are irrelevant with respect to the sentiment classifi-cation task.", "labels": [], "entities": []}, {"text": "Indeed, separating objective sentences from subjective sentences in a document produces encouraging results (.", "labels": [], "entities": []}, {"text": "Our research is inspired by these observations.", "labels": [], "entities": []}, {"text": "Unlike in the previous work, however, we focus on syntactic substructures (rather than entire paragraphs or sentences) that contain subjective words.", "labels": [], "entities": []}, {"text": "More specifically, we use the terms in the lexicon constructed from () as the indicators to identify the substructures for the convolution kernels, and extract different sub-structures according to these indicators for various types of parse trees).", "labels": [], "entities": []}, {"text": "An empirical evaluation on a widely used sentiment corpus shows an improvement of 1.45 point inaccuracy over the baseline resulting from a combination of bag-of-words and high-impact parse features (Section 4).", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: The detail of the corpus. Here Trees denotes the  average number of trees, and Size denotes the averaged  number of words in each tree.", "labels": [], "entities": [{"text": "detail", "start_pos": 14, "end_pos": 20, "type": "METRIC", "confidence": 0.9886924028396606}]}, {"text": " Table 2: Results of kernels. Here Doc denotes the whole  document of the text, Sent denotes the sentences that con- tains subjective terms in the lexicon, Rand denotes ran- domly selected substructures, and Sub denotes the sub- structures defined in Section 3.2. We use \"*\" and \"**\" to  denote a result is better than baseline VK significantly at  p < 0.05 and p < 0.01 (sign test), respectively.", "labels": [], "entities": [{"text": "Rand", "start_pos": 156, "end_pos": 160, "type": "METRIC", "confidence": 0.9167990684509277}]}]}