{"title": [{"text": "Automatically Mining Question Reformulation Patterns from Search Log Data", "labels": [], "entities": [{"text": "Automatically Mining Question Reformulation Patterns", "start_pos": 0, "end_pos": 52, "type": "TASK", "confidence": 0.7080031931400299}]}], "abstractContent": [{"text": "Natural language questions have become popular in web search.", "labels": [], "entities": []}, {"text": "However, various questions can be formulated to convey the same information need, which poses a great challenge to search systems.", "labels": [], "entities": []}, {"text": "In this paper, we automatically mined 5w1h question reformula-tion patterns from large scale search log data.", "labels": [], "entities": []}, {"text": "The question reformulations generated from these patterns are further incorporated into the retrieval model.", "labels": [], "entities": []}, {"text": "Experiments show that using question reformulation patterns can significantly improve the search performance of natural language questions.", "labels": [], "entities": [{"text": "question reformulation", "start_pos": 28, "end_pos": 50, "type": "TASK", "confidence": 0.7411147356033325}]}], "introductionContent": [{"text": "More and more web users tend to use natural language questions as queries for web search.", "labels": [], "entities": []}, {"text": "Some commercial natural language search engines such as InQuira and Ask have also been developed to answer this type of queries.", "labels": [], "entities": [{"text": "InQuira", "start_pos": 56, "end_pos": 63, "type": "DATASET", "confidence": 0.9374656677246094}]}, {"text": "One major challenge is that various questions can be formulated for the same information need.", "labels": [], "entities": []}, {"text": "shows some alternative expressions for the question \"how far is it from Boston to Seattle\".", "labels": [], "entities": []}, {"text": "It is difficult for search systems to achieve satisfactory retrieval performance without considering these alternative expressions.", "labels": [], "entities": []}, {"text": "In this paper, we propose a method of automatically mining 5w1h question 1 reformulation patterns to improve the search relevance of 5w1h questions.", "labels": [], "entities": []}, {"text": "Question reformulations represent the alternative expressions for 5w1h questions.", "labels": [], "entities": []}, {"text": "A question * Contribution during internship at Microsoft Research Asia 1 5w1h questions start with \"Who\", \"What\", \"Where\", \"When\", \"Why\" and \"How\".", "labels": [], "entities": [{"text": "Microsoft Research Asia 1 5w1h", "start_pos": 47, "end_pos": 77, "type": "DATASET", "confidence": 0.8598366260528565}]}], "datasetContent": [{"text": "A large scale search log from a commercial search engine) is used in experiments.", "labels": [], "entities": []}, {"text": "From the search log, we extract all successive query pairs issued by the same user within 30 minutes ( where the first query is a 5w1h question.", "labels": [], "entities": []}, {"text": "Finally, we extracted 6,680,278 question reformulation patterns.", "labels": [], "entities": [{"text": "question reformulation", "start_pos": 32, "end_pos": 54, "type": "TASK", "confidence": 0.7084827125072479}]}, {"text": "For the retrieval experiments, we randomly sample 10,000 natural language questions as queries shows examples of the generated questions reformulations.", "labels": [], "entities": []}, {"text": "Several interesting expressions are generated to reformulate the original question.", "labels": [], "entities": []}, {"text": "We compare the retrieval performance of using the question reformulations (QDist) with the performance of using the original question (Orig) in.", "labels": [], "entities": []}, {"text": "The parameter \u03bb of QDist is decided using tenfold cross validation.", "labels": [], "entities": []}, {"text": "Two sided t-test are conducted to measure significance.", "labels": [], "entities": [{"text": "significance", "start_pos": 42, "end_pos": 54, "type": "METRIC", "confidence": 0.9355846047401428}]}, {"text": "shows that using the question reformulations can significantly improve the retrieval performance of natural language questions.", "labels": [], "entities": []}, {"text": "Note that, considering the scale of experiments (10,000 queries), around 3% improvement with respect to NDCG is a very interesting result for web search.", "labels": [], "entities": [{"text": "NDCG", "start_pos": 104, "end_pos": 108, "type": "DATASET", "confidence": 0.6477692723274231}]}], "tableCaptions": [{"text": " Table 4: Retrieval Performance of using question refor- mulations. \u22c6 denotes significantly different with Orig.  NDCG@1 NDCG@3 NDCG@5  Orig  0.2946  0.2923  0.2991  QDist 0.3032 \u22c6  0.2991 \u22c6  0.3067 \u22c6", "labels": [], "entities": [{"text": "Retrieval", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.8845933675765991}, {"text": "Orig  0.2946  0.2923  0.2991  QDist 0.3032", "start_pos": 136, "end_pos": 178, "type": "DATASET", "confidence": 0.671486054857572}]}, {"text": " Table 5: Performance of the upper bound.  NDCG@1 NDCG@3 NDCG@5  Orig  0.2946  0.2923  0.2991  QDist 0.3032  0.2991  0.3067  Upper 0.3826  0.3588  0.3584", "labels": [], "entities": [{"text": "Orig  0.2946  0.2923  0.2991  QDist 0.3032  0.2991  0.3067  Upper 0.3826  0.3588  0.3584", "start_pos": 65, "end_pos": 153, "type": "DATASET", "confidence": 0.9075254251559576}]}, {"text": " Table 6: Best reformulation within different positions.  top 1  within top 2 within top 3  49.2% 64.7%  75.4%", "labels": [], "entities": []}, {"text": " Table 7: Analysis of different types of reformulations.  Type  increase decrease same  Morphological change  11%  10%  79%  Equivalent meaning  32%  30%  38%  More specific/Add words  45%  39%  16%  More general/Remove words 38%  48%  14%  Not relevant  14%  72%  14%", "labels": [], "entities": [{"text": "Type", "start_pos": 58, "end_pos": 62, "type": "METRIC", "confidence": 0.9681822657585144}, {"text": "Morphological", "start_pos": 88, "end_pos": 101, "type": "METRIC", "confidence": 0.9839143753051758}]}, {"text": " Table 8: Retrieval Performance of other query processing  techniques.  NDCG@1 NDCG@3 NDCG@5  ORIG  0.2720  0.2937  0.3151  NoStop  0.2697  0.2893  0.3112  DropOne 0.2630  0.2888  0.3102  QDist  0.2978  0.3052  0.3250", "labels": [], "entities": [{"text": "ORIG  0.2720  0.2937  0.3151  NoStop  0.2697  0.2893  0.3112  DropOne 0.2630  0.2888  0.3102  QDist  0.2978  0.3052  0.3250", "start_pos": 94, "end_pos": 217, "type": "DATASET", "confidence": 0.8139146361500025}]}]}