{"title": [], "abstractContent": [{"text": "Bootstrapping a classifier from a small set of seed rules can be viewed as the propagation of labels between examples via features shared between them.", "labels": [], "entities": []}, {"text": "This paper introduces a novel variant of the Yarowsky algorithm based on this view.", "labels": [], "entities": []}, {"text": "It is a bootstrapping learning method which uses a graph propagation algorithm with a well defined objective function.", "labels": [], "entities": []}, {"text": "The experimental results show that our proposed bootstrapping algorithm achieves state of the art performance or better on several different natural language data sets.", "labels": [], "entities": []}], "introductionContent": [{"text": "In this paper, we are concerned with a case of semisupervised learning that is close to unsupervised learning, in that the labelled and unlabelled data points are from the same domain and only a small set of seed rules is used to derive the labelled points.", "labels": [], "entities": []}, {"text": "We refer to this setting as bootstrapping.", "labels": [], "entities": []}, {"text": "In contrast, typical semi-supervised learning deals with a large number of labelled points, and a domain adaptation task with unlabelled points from the new domain.", "labels": [], "entities": []}, {"text": "The two dominant discriminative learning methods for bootstrapping are self-training) and co-training.", "labels": [], "entities": []}, {"text": "In this paper we focus on a self-training style bootstrapping algorithm, the Yarowsky algorithm.", "labels": [], "entities": []}, {"text": "Variants of this algorithm have been formalized as optimizing an objective function in previous work by and, but it is not clear that any perform as well as the Yarowsky algorithm itself.", "labels": [], "entities": []}, {"text": "We take advantage of this formalization and introduce a novel algorithm called Yarowsky-prop which builds on the algorithms of and set of currently labelled examples with f V f set of currently unlabelled examples with f \u039b j set of examples currently labelled with j \u039b f j set of examples with f currently labelled with j well-understood as minimizing an objective function at each iteration, and it obtains state of the art performance on several different NLP data sets.", "labels": [], "entities": [{"text": "NLP data sets", "start_pos": 458, "end_pos": 471, "type": "DATASET", "confidence": 0.8523831566174825}]}, {"text": "To our knowledge, this is the first theoretically motivated self-training bootstrapping algorithm which performs as well as the Yarowsky algorithm.", "labels": [], "entities": []}], "datasetContent": [{"text": "Where applicable we use smoothing = 0.1, a threshold \u03b6 = 0.95, and cautiousness parameters n 0 = \u2206n = 5 as in and propagation parameters \u00b5 = 0.6, \u03bd = 0.01 as in.", "labels": [], "entities": []}, {"text": "Initial experiments with different propagation parameters suggested that as long as \u03bd was set at this value changing \u00b5 had relatively little effect on the accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 155, "end_pos": 163, "type": "METRIC", "confidence": 0.9987195730209351}]}, {"text": "We did not find any propagation parameter settings that outperformed this choice.", "labels": [], "entities": []}, {"text": "For the Yarowsky-prop algorithms we perform a single iteration of the propagation update for each iteration of the algorithm.", "labels": [], "entities": []}, {"text": "For EM we use weights \u03bb 1 = 0.98, and \u03bb 2 = 0.02 (see section 3.8), which were found in initial experiments to be the best values, and results are averaged over 10 random initializations.", "labels": [], "entities": [{"text": "EM", "start_pos": 4, "end_pos": 6, "type": "TASK", "confidence": 0.8870704174041748}]}, {"text": "The named entity test set contains some examples that are neither person, organization, nor location.", "labels": [], "entities": []}, {"text": "define noise accuracy as accuracy that includes such instances, and clean accuracy as accuracy calculated across only the examples which are one of the known labels.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 13, "end_pos": 21, "type": "METRIC", "confidence": 0.8088295459747314}, {"text": "accuracy", "start_pos": 25, "end_pos": 33, "type": "METRIC", "confidence": 0.9906874299049377}, {"text": "accuracy", "start_pos": 74, "end_pos": 82, "type": "METRIC", "confidence": 0.5176905393600464}, {"text": "accuracy", "start_pos": 86, "end_pos": 94, "type": "METRIC", "confidence": 0.9918851852416992}]}, {"text": "We report only clean accuracy in this paper; noise accuracy tracks clean accuracy but is a little lower.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 21, "end_pos": 29, "type": "METRIC", "confidence": 0.9323093295097351}, {"text": "accuracy", "start_pos": 51, "end_pos": 59, "type": "METRIC", "confidence": 0.8585302233695984}, {"text": "accuracy", "start_pos": 73, "end_pos": 81, "type": "METRIC", "confidence": 0.9198011755943298}]}, {"text": "There is no difference on the word sense data sets.", "labels": [], "entities": [{"text": "word sense data sets", "start_pos": 30, "end_pos": 50, "type": "DATASET", "confidence": 0.7211461812257767}]}, {"text": "We also report (clean) non-seeded accuracy, which we define to be clean accuracy over only examples which are not assigned a label by the seed rules.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 34, "end_pos": 42, "type": "METRIC", "confidence": 0.9922271966934204}, {"text": "accuracy", "start_pos": 72, "end_pos": 80, "type": "METRIC", "confidence": 0.7751464247703552}]}, {"text": "This is intended to evaluate what the algorithm has learned, rather than what it can achieve by using the input information directly.", "labels": [], "entities": []}, {"text": "We test Yarowsky, Yarowsky-cautious, Yarowsky-sum, DL-CoTrain, HS-bipartite in all four forms, and Yarowsky-prop cautious and non-cautious and in all four forms.", "labels": [], "entities": []}, {"text": "For each algorithm except EM we perform a final retraining step Waukegan maker, LEFT loc.", "labels": [], "entities": [{"text": "LEFT", "start_pos": 80, "end_pos": 84, "type": "METRIC", "confidence": 0.9930891394615173}]}, {"text": "Mexico, president, of president-of, RIGHT loc.", "labels": [], "entities": [{"text": "RIGHT loc", "start_pos": 36, "end_pos": 45, "type": "DATASET", "confidence": 0.7222320139408112}]}, {"text": "La-Jolla, La Jolla company, LEFT: Named entity test set examples where Yarowsky-prop \u03b8-only is correct and no other tested algorithms are correct.", "labels": [], "entities": [{"text": "La-Jolla, La Jolla company", "start_pos": 0, "end_pos": 26, "type": "DATASET", "confidence": 0.8256247878074646}, {"text": "LEFT", "start_pos": 28, "end_pos": 32, "type": "METRIC", "confidence": 0.9739307761192322}]}, {"text": "The specific feature types are omitted.", "labels": [], "entities": []}, {"text": "as described for Yarowsky-cautious (section 3.2).", "labels": [], "entities": []}, {"text": "Our programs and experiment scripts have been made available.", "labels": [], "entities": []}, {"text": "shows the final test set accuracies for the all the algorithms.", "labels": [], "entities": []}, {"text": "The seed DL accuracy is also included for reference.", "labels": [], "entities": [{"text": "seed DL accuracy", "start_pos": 4, "end_pos": 20, "type": "METRIC", "confidence": 0.6279102166493734}]}], "tableCaptions": [{"text": " Table 3: Test set percent accuracy and non-seeded test set percent accuracy (respectively) for the algorithms on all tasks. Bold  items are a maximum in their column. Italic items have a statistically significant difference versus DL-CoTrain (p < 0.05 with a  McNemar test). For EM, \u00b1 indicates one standard deviation but statistical significance was not measured.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 27, "end_pos": 35, "type": "METRIC", "confidence": 0.7418000102043152}, {"text": "accuracy", "start_pos": 68, "end_pos": 76, "type": "METRIC", "confidence": 0.9497209787368774}]}]}