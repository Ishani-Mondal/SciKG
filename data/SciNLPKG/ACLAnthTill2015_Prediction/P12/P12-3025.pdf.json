{"title": [{"text": "Online Plagiarism Detection Through Exploiting Lexical, Syntactic, and Semantic Information", "labels": [], "entities": [{"text": "Online Plagiarism Detection", "start_pos": 0, "end_pos": 27, "type": "TASK", "confidence": 0.5870225528875986}]}], "abstractContent": [{"text": "In this paper, we introduce a framework that identifies online plagiarism by exploiting lexical, syntactic and semantic features that includes duplication-gram, reordering and alignment of words, POS and phrase tags, and semantic similarity of sentences.", "labels": [], "entities": []}, {"text": "We establish an ensemble framework to combine the predictions of each model.", "labels": [], "entities": []}, {"text": "Results demonstrate that our system cannot only find considerable amount of real-world online plagiarism cases but also outperforms several state-of-the-art algorithms and commercial software.", "labels": [], "entities": []}], "introductionContent": [{"text": "Online plagiarism, the action of trying to create anew piece of writing by copying, reorganizing or rewriting others' work identified through search engines, is one of the most commonly seen misusage of the highly matured web technologies.", "labels": [], "entities": [{"text": "Online plagiarism, the action of trying to create anew piece of writing by copying, reorganizing or rewriting others' work identified through search engines", "start_pos": 0, "end_pos": 156, "type": "Description", "confidence": 0.8294208240509033}]}, {"text": "As implied by the experiment conducted by), a powerful plagiarism detection system can effectively discourage people from plagiarizing others' work.", "labels": [], "entities": []}, {"text": "A common strategy people adopt for onlineplagiarism detection is as follows.", "labels": [], "entities": [{"text": "onlineplagiarism detection", "start_pos": 35, "end_pos": 61, "type": "TASK", "confidence": 0.7281098663806915}]}, {"text": "First they identify several suspicious sentences from the write-up and feed them one by one as a query to a search engine to obtain a set of documents.", "labels": [], "entities": []}, {"text": "Then human reviewers can manually examine whether these documents are truly the sources of the suspicious sentences.", "labels": [], "entities": []}, {"text": "While it is quite straightforward and effective, the limitation of this strategy is obvious.", "labels": [], "entities": []}, {"text": "First, since the length of search query is limited, suspicious sentences are usually queried and examined independently.", "labels": [], "entities": []}, {"text": "Therefore, it is harder to identify document level plagiarism than sentence level plagiarism.", "labels": [], "entities": []}, {"text": "Second, manually checking whether a query sentence plagiarizes certain websites requires specific domain and language knowledge as well as considerable amount of energy and time.", "labels": [], "entities": []}, {"text": "To overcome the above shortcomings, we introduce an online plagiarism detection system using natural language processing techniques to simulate the above reverse-engineering approach.", "labels": [], "entities": [{"text": "online plagiarism detection", "start_pos": 52, "end_pos": 79, "type": "TASK", "confidence": 0.6982367833455404}]}, {"text": "We develop an ensemble framework that integrates lexical, syntactic and semantic features to achieve this goal.", "labels": [], "entities": []}, {"text": "Our system is language independent and we have implemented both Chinese and English versions for evaluation.", "labels": [], "entities": []}], "datasetContent": [{"text": "We evaluate our system from two different angles.", "labels": [], "entities": []}, {"text": "We first evalaute the sentence level plagirism detection using the PAN corpus in English.", "labels": [], "entities": [{"text": "sentence level plagirism detection", "start_pos": 22, "end_pos": 56, "type": "TASK", "confidence": 0.6127535402774811}, {"text": "PAN corpus", "start_pos": 67, "end_pos": 77, "type": "DATASET", "confidence": 0.8161478042602539}]}, {"text": "We then evaluate the capability of the full system to detect on-line plagiarism cases using annotated results in Chinese.", "labels": [], "entities": []}, {"text": "We want to compare our model with the state-ofthe-art methods, in particular the winning entries in plagiarism detection competition in PAN 1 . However, the competition in PAN is designed for off-line plagiarism detection; the entries did not exploit an IR system to search the Web like we do.", "labels": [], "entities": [{"text": "plagiarism detection competition", "start_pos": 100, "end_pos": 132, "type": "TASK", "confidence": 0.7959903478622437}, {"text": "off-line plagiarism detection", "start_pos": 192, "end_pos": 221, "type": "TASK", "confidence": 0.8030861417452494}]}, {"text": "Nevertheless, we can still compare the core component of our system, the sentence-based measuring model with that of other systems.", "labels": [], "entities": []}, {"text": "To achieve such goal, we first randomly sampled 370 documents from PAN-2011 external plagiarism corpus (M.) containing 2882 labeled plagiarism cases.", "labels": [], "entities": [{"text": "PAN-2011 external plagiarism corpus (M.)", "start_pos": 67, "end_pos": 107, "type": "DATASET", "confidence": 0.8789093238966805}]}, {"text": "To obtain high-quality negative examples for evaluation, we built a full-text index on the corpus using Lucene package.", "labels": [], "entities": [{"text": "Lucene package", "start_pos": 104, "end_pos": 118, "type": "DATASET", "confidence": 0.97055983543396}]}, {"text": "Then we use the suspicious passages as queries to search the whole dataset using Lucene.", "labels": [], "entities": [{"text": "Lucene", "start_pos": 81, "end_pos": 87, "type": "DATASET", "confidence": 0.9811551570892334}]}, {"text": "Since there is length limitation in Lucene (as well as in the real search engines), we further break the 2882 plagiarism cases into 6477 queries.", "labels": [], "entities": [{"text": "Lucene", "start_pos": 36, "end_pos": 42, "type": "DATASET", "confidence": 0.9086625576019287}]}, {"text": "We then extract the top 30 snippets returned by the search engine as the potential negative candidates for each plagiarism case.", "labels": [], "entities": []}, {"text": "Note that for each suspicious passage, there is only one target passage (given by the ground truth) that is considered as a positive plagiarism casein this data, and it can be either among these 30 cases or not.", "labels": [], "entities": []}, {"text": "However, we union these 30 cases with the ground truth as a set, and use our (as well as the competitors') models to rank the degree-ofplagiarism for all the candidates.", "labels": [], "entities": []}, {"text": "We then evaluate the rank by the area-under-PR-curve (AUC) score.", "labels": [], "entities": [{"text": "area-under-PR-curve (AUC) score", "start_pos": 33, "end_pos": 64, "type": "METRIC", "confidence": 0.9227946162223816}]}, {"text": "We compared our system with the winning entry of and the stopword ngram model that claims to perform better than this winning entry by.", "labels": [], "entities": []}, {"text": "The results of each individual model and ensemble using 5-fold cross validation are listed in.", "labels": [], "entities": []}, {"text": "It shows that NM is the best individual model, and The website of PAN-2011 is http://pan.webis.de/ an ensemble of three features outperforms the state-of-the-art by 26%.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 3. (a) AUC for each individual model (b) AUC of  our ensemble and other state-of-the-art algorithms", "labels": [], "entities": [{"text": "AUC", "start_pos": 14, "end_pos": 17, "type": "METRIC", "confidence": 0.9951357245445251}, {"text": "AUC", "start_pos": 48, "end_pos": 51, "type": "METRIC", "confidence": 0.9861472249031067}]}, {"text": " Table 5. shows the average AUC of 5-fold cross  validation. The results show that our method  outperforms the Pan-11 winner slightly, and much  better than the Stopword Ngram.", "labels": [], "entities": [{"text": "AUC", "start_pos": 28, "end_pos": 31, "type": "METRIC", "confidence": 0.9984182119369507}, {"text": "Pan-11 winner", "start_pos": 111, "end_pos": 124, "type": "DATASET", "confidence": 0.8857470750808716}, {"text": "Stopword Ngram", "start_pos": 161, "end_pos": 175, "type": "DATASET", "confidence": 0.8744265735149384}]}, {"text": " Table 5. (a) AUC for each individual model (b) AUC of  our ensemble and other state-of-the-art algorithms", "labels": [], "entities": [{"text": "AUC", "start_pos": 14, "end_pos": 17, "type": "METRIC", "confidence": 0.9948832988739014}, {"text": "AUC", "start_pos": 48, "end_pos": 51, "type": "METRIC", "confidence": 0.9863961935043335}]}]}