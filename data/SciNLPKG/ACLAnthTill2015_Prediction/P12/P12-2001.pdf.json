{"title": [{"text": "Higher-Order Constituent Parsing and Parser Combination *", "labels": [], "entities": []}], "abstractContent": [{"text": "This paper presents a higher-order model for constituent parsing aimed at utilizing more local structural context to decide the score of a grammar rule instance in a parse tree.", "labels": [], "entities": [{"text": "constituent parsing", "start_pos": 45, "end_pos": 64, "type": "TASK", "confidence": 0.6921258270740509}]}, {"text": "Experiments on English and Chinese treebanks confirm its advantage over its first-order version.", "labels": [], "entities": []}, {"text": "It achieves its best F1 scores of 91.86% and 85.58% on the two languages, respectively , and further pushes them to 92.80% and 85.60% via combination with other high-performance parsers.", "labels": [], "entities": [{"text": "F1 scores", "start_pos": 21, "end_pos": 30, "type": "METRIC", "confidence": 0.9822401106357574}]}], "introductionContent": [{"text": "Factorization is crucial to discriminative parsing.", "labels": [], "entities": [{"text": "discriminative parsing", "start_pos": 28, "end_pos": 50, "type": "TASK", "confidence": 0.6190862208604813}]}, {"text": "Previous discriminative parsing models usually factor a parse tree into a set of parts.", "labels": [], "entities": []}, {"text": "Each part is scored separately to ensure tractability.", "labels": [], "entities": []}, {"text": "In dependency parsing (DP), the number of dependencies in apart is called the order of a DP model (.", "labels": [], "entities": [{"text": "dependency parsing (DP)", "start_pos": 3, "end_pos": 26, "type": "TASK", "confidence": 0.8849356055259705}]}, {"text": "Accordingly, existing graph-based DP models can be categorized into tree groups, namely, the first-order), second-order ( and third-order () models.", "labels": [], "entities": []}, {"text": "Similarly, we can define the order of constituent parsing in terms of the number of grammar rules in apart.", "labels": [], "entities": []}, {"text": "Then, the previous discriminative constituent parsing models; * The research reported in this paper was partially supported by the Research Grants Council of HKSAR, China, through the GRF Grant 9041597 (CityU 144410).) are the first-order ones, because there is only one grammar rule in apart.", "labels": [], "entities": [{"text": "GRF Grant 9041597 (CityU 144410", "start_pos": 184, "end_pos": 215, "type": "DATASET", "confidence": 0.8969772458076477}]}, {"text": "The discriminative re-scoring models can be viewed as previous attempts to higher-order constituent parsing, using some parts containing more than one grammar rule as non-local features.", "labels": [], "entities": [{"text": "constituent parsing", "start_pos": 88, "end_pos": 107, "type": "TASK", "confidence": 0.7380201518535614}]}, {"text": "In this paper, we present a higher-order constituent parsing model 1 based on these previous works.", "labels": [], "entities": [{"text": "constituent parsing", "start_pos": 41, "end_pos": 60, "type": "TASK", "confidence": 0.6469757854938507}]}, {"text": "It allows multiple adjacent grammar rules in each part of a parse tree, so as to utilize more local structural context to decide the plausibility of a grammar rule instance.", "labels": [], "entities": []}, {"text": "Evaluated on the PTB WSJ and Chinese Treebank, it achieves its best F1 scores of 91.86% and 85.58%, respectively.", "labels": [], "entities": [{"text": "PTB WSJ", "start_pos": 17, "end_pos": 24, "type": "DATASET", "confidence": 0.9666556119918823}, {"text": "Chinese Treebank", "start_pos": 29, "end_pos": 45, "type": "DATASET", "confidence": 0.9760843217372894}, {"text": "F1", "start_pos": 68, "end_pos": 70, "type": "METRIC", "confidence": 0.9996292591094971}]}, {"text": "Combined with other high-performance parsers under the framework of constituent recombination, this model further enhances the F1 scores to 92.80% and 85.60%, the highest ones achieved so far on these two data sets.", "labels": [], "entities": [{"text": "F1 scores", "start_pos": 127, "end_pos": 136, "type": "METRIC", "confidence": 0.9835575222969055}]}], "datasetContent": [{"text": "Our parsing models are evaluated on both English and Chinese treebanks, i.e., the WSJ section of Penn Treebank 3.0 (LDC99T42) and the Chinese Treebank 5.1 (LDC2005T01U01).", "labels": [], "entities": [{"text": "WSJ", "start_pos": 82, "end_pos": 85, "type": "DATASET", "confidence": 0.9359197020530701}, {"text": "Penn Treebank 3.0 (LDC99T42)", "start_pos": 97, "end_pos": 125, "type": "DATASET", "confidence": 0.8918250401814779}, {"text": "Chinese Treebank 5.1 (LDC2005T01U01)", "start_pos": 134, "end_pos": 170, "type": "DATASET", "confidence": 0.9380327264467875}]}, {"text": "In order to compare with previous works, we opt for the same split as in, as listed in.", "labels": [], "entities": []}, {"text": "For parser combination, we follow the setting of, using Section 24 instead of Section 22 of WSJ treebank as development set.", "labels": [], "entities": [{"text": "parser combination", "start_pos": 4, "end_pos": 22, "type": "TASK", "confidence": 0.8299946188926697}, {"text": "WSJ treebank", "start_pos": 92, "end_pos": 104, "type": "DATASET", "confidence": 0.9499940872192383}]}, {"text": "In this work, the lexical model of is combined with our syntactic model under the framework of product-of-experts.", "labels": [], "entities": []}, {"text": "A factor \u03bb is introduced to balance the two models.", "labels": [], "entities": []}, {"text": "It is tuned on a development set using the gold sec-English Chinese R(%) P(%) F1(%) R(%) P(%) F1.", "labels": [], "entities": [{"text": "R(%) P(%) F1(%) R(%) P(%) F1", "start_pos": 68, "end_pos": 96, "type": "METRIC", "confidence": 0.7911256931044839}]}, {"text": "The parameters \u03b8 of each parsing model are estimated from a training set using an averaged perceptron algorithm, following and.", "labels": [], "entities": []}, {"text": "The performance of our first-and higher-order parsing models on all sentences of the two test sets is presented in, where \u03bb indicates a tuned balance factor.", "labels": [], "entities": []}, {"text": "This parser is also combined with the parser of and the Stanford.", "labels": [], "entities": []}, {"text": "parser The best combination results in are achieved with k=70 for English and k=100 for Chinese for selecting the k-best parses.", "labels": [], "entities": []}, {"text": "Our results are compared with the best previous ones on the same test sets in", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 3: The performance of our parsing models on the English and Chinese test sets.", "labels": [], "entities": [{"text": "English and Chinese test sets", "start_pos": 55, "end_pos": 84, "type": "DATASET", "confidence": 0.7277903258800507}]}, {"text": " Table 4: Performance comparison on the English test set", "labels": [], "entities": [{"text": "English test set", "start_pos": 40, "end_pos": 56, "type": "DATASET", "confidence": 0.9598858952522278}]}]}