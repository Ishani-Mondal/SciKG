{"title": [{"text": "AUTOMATIC LEARNING OF WORD TRANSDUCERS FROM EXAMPLES Michel Gilloux Centre National d'l~tudes des T616communlcations", "labels": [], "entities": []}], "abstractContent": [{"text": "ABBTRACT This paper describes the application of markovian teaming methods to the inference of word transducers.", "labels": [], "entities": [{"text": "ABBTRACT", "start_pos": 0, "end_pos": 8, "type": "DATASET", "confidence": 0.573857843875885}, {"text": "inference of word transducers", "start_pos": 82, "end_pos": 111, "type": "TASK", "confidence": 0.6006969511508942}]}, {"text": "We show how the proposed method dispenses from the difficult design of hand-crafted rules, allows the use of weighed non deterministic transducers and is able to translate words by taking into account their whole rather than by making decisions locally.", "labels": [], "entities": []}, {"text": "These arguments are illustrated on two examples: morphological analysis and grapheme-to-phoneme transcription.", "labels": [], "entities": [{"text": "morphological analysis", "start_pos": 49, "end_pos": 71, "type": "TASK", "confidence": 0.7225086987018585}, {"text": "grapheme-to-phoneme transcription", "start_pos": 76, "end_pos": 109, "type": "TASK", "confidence": 0.688564345240593}]}], "introductionContent": [{"text": "Several tasks associated with electronic lexicons maybe viewed as transductions between character strings.", "labels": [], "entities": []}, {"text": "This maybe the decomposition of words into morphemes in morphology or the grapheme-tophoneme transcription in phonology.", "labels": [], "entities": []}, {"text": "one has for example to decompose the French word \"chronom~trage\" into the sequence of affixes \"chrono+m~tre+er\u00f7-age\".", "labels": [], "entities": []}, {"text": "In the second, \"abstenlr\" should be translated into \"abstoniR\",or \"apstoniR\" I.", "labels": [], "entities": [{"text": "abstenlr", "start_pos": 16, "end_pos": 24, "type": "METRIC", "confidence": 0.946983277797699}, {"text": "abstoniR", "start_pos": 53, "end_pos": 61, "type": "METRIC", "confidence": 0.9455041289329529}]}, {"text": "Most of the proposed methods in the IThese two tasks are in fact closely related in that {I) the correct phoneme transcription may mirror an underlying morphological structure, like for \"asoc/a/\" whose phonemic form is \"asos jal\" rather than \"azosjal\" due to the decomposition \"a+soclal\", and (2) the surface form of a derived word may depend on the pronunclaUon of its component morphemes, llke for \"d~+harnacher\" which results in \"d~harnacher\" and not \"d~sharnachet\".", "labels": [], "entities": []}, {"text": "domain) are based on the availability of local rules whose combination, either through direct interpretation or by being compiled, form the target transducer.", "labels": [], "entities": []}, {"text": "Although these methods make it possible -at least in theory -to design suitable transducers, provided that the rule descrlpUon language has the right expressive power, they are complex to use because of the difficulty of writing down rules.", "labels": [], "entities": []}, {"text": "Moreover, fora given rule language, there may not exist an algorithm for compiling rules into a form better suited to the translation process.", "labels": [], "entities": []}, {"text": "Lastly, in numerous cases, the translation procedures are improperly deterministic as shown by the example of\"abstcnlf so that it is not possible to consider several competing hypotheses in parallel not to speak of ranking them according to some certainty factor.", "labels": [], "entities": [{"text": "abstcnlf", "start_pos": 110, "end_pos": 118, "type": "METRIC", "confidence": 0.9390380382537842}]}, {"text": "We have designed a program which allows to construct transducers without retaming the above shortcomings.", "labels": [], "entities": []}, {"text": "It is no longer necessary to write down translation rules since the transducer is obtained as the result of an automatic learning over a set of examples.", "labels": [], "entities": []}, {"text": "The transducer is represented into the language of probabillstic finite state automata (Markov models] so that its use is straightforward.", "labels": [], "entities": []}, {"text": "Lastly, tt produces results which are assigned a probability and makes it possible to llst them by decreasing order of likelihood.", "labels": [], "entities": []}, {"text": "After stating the problem of character strings translation and defining the few central notions of markovian learnJng, this paper describes their adaptation to the word translation problem in the learning and translating phases.", "labels": [], "entities": [{"text": "character strings translation", "start_pos": 29, "end_pos": 58, "type": "TASK", "confidence": 0.6653221646944681}, {"text": "word translation", "start_pos": 164, "end_pos": 180, "type": "TASK", "confidence": 0.7404380738735199}]}, {"text": "This adaptation is illustrated through two applications: morphological analysis and grapheme-to-phoneme transcription.", "labels": [], "entities": [{"text": "morphological analysis", "start_pos": 57, "end_pos": 79, "type": "TASK", "confidence": 0.7677258849143982}, {"text": "grapheme-to-phoneme transcription", "start_pos": 84, "end_pos": 117, "type": "TASK", "confidence": 0.6863311529159546}]}], "datasetContent": [], "tableCaptions": []}