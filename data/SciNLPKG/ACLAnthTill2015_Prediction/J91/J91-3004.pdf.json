{"title": [{"text": "Computation of the Probability of Initial Substring Generation by Stochastic Context-Free Grammars", "labels": [], "entities": []}], "abstractContent": [{"text": "Speech recognition language models are based on probabilities P(Wk+I = v [ WlW2~..., Wk) that the next word Wk+l will be any particular word v of the vocabulary, given that the word sequence Wl, w2,..., Wk is hypothesized to have been uttered in the past.", "labels": [], "entities": [{"text": "Speech recognition language", "start_pos": 0, "end_pos": 27, "type": "TASK", "confidence": 0.8070017298062643}]}, {"text": "If probabilistic context-free grammars are to be used as the basis of the language model, it will be necessary to compute the probability that successive application of the grammar rewrite rules (beginning with the sentence start symbol s) produces a word string whose initial substring is an arbitrary sequence wl, w2,.", "labels": [], "entities": []}, {"text": ".. , Wk+l.", "labels": [], "entities": []}, {"text": "In this paper we describe anew algorithm that achieves the required computation in at most a constant times k3-steps.", "labels": [], "entities": []}], "introductionContent": [{"text": "The purpose of this article is to develop an algorithm for computing the probability that a stochastic context-free grammar (SCFG) (that is, a grammar whose production rules have attached to them a probability of being used) generates an arbitrary initial substring of terminals.", "labels": [], "entities": []}, {"text": "Thus, we treat the same problem recently considered by from the point of view of LR grammars.", "labels": [], "entities": []}, {"text": "Probabilistic methods have been shown most effective in automatic speech recognition.", "labels": [], "entities": [{"text": "automatic speech recognition", "start_pos": 56, "end_pos": 84, "type": "TASK", "confidence": 0.6739339729150137}]}, {"text": "Recognition (actually transcription) of natural unrestricted speech requires a \"language model\" that attaches probabilities to the production of all possible strings of words ().", "labels": [], "entities": [{"text": "Recognition (actually transcription) of natural unrestricted speech", "start_pos": 0, "end_pos": 67, "type": "TASK", "confidence": 0.7789348264535269}]}, {"text": "Consequently, if we believe that word generation can be modeled by context-free grammars, and if we want to base speech recognition (or handwriting recognition, optical character recogition, etc.) on such models, then it will become necessary to embed them into a probabilistic framework.", "labels": [], "entities": [{"text": "word generation", "start_pos": 33, "end_pos": 48, "type": "TASK", "confidence": 0.734865203499794}, {"text": "speech recognition", "start_pos": 113, "end_pos": 131, "type": "TASK", "confidence": 0.7628859877586365}, {"text": "handwriting recognition", "start_pos": 136, "end_pos": 159, "type": "TASK", "confidence": 0.7238387018442154}, {"text": "optical character recogition", "start_pos": 161, "end_pos": 189, "type": "TASK", "confidence": 0.6388301054636637}]}, {"text": "In speech recognition we are presented with words one at a time, in sequence, and so we would like to calculate the probability P(s --* w~w2... Wk...) that an arbitrary string wlw2...", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 3, "end_pos": 21, "type": "TASK", "confidence": 0.7154465466737747}]}, {"text": "Wk is the initial substring of a sentence generated by the given SCFG.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": []}