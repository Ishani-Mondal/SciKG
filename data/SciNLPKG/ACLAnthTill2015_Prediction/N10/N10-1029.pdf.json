{"title": [{"text": "Task-based Evaluation of Multiword Expressions: a Pilot Study in Statistical Machine Translation", "labels": [], "entities": [{"text": "Statistical Machine Translation", "start_pos": 65, "end_pos": 96, "type": "TASK", "confidence": 0.788084089756012}]}], "abstractContent": [{"text": "We conduct a pilot study for task-oriented evaluation of Multiword Expression (MWE) in Statistical Machine Translation (SMT).", "labels": [], "entities": [{"text": "Multiword Expression (MWE)", "start_pos": 57, "end_pos": 83, "type": "TASK", "confidence": 0.7660686671733856}, {"text": "Statistical Machine Translation (SMT)", "start_pos": 87, "end_pos": 124, "type": "TASK", "confidence": 0.7915790925423304}]}, {"text": "We propose two different integration strategies for MWE in SMT, which take advantage of different degrees of MWE semantic compositional-ity and yield complementary improvements in SMT quality on a large-scale translation task.", "labels": [], "entities": [{"text": "MWE", "start_pos": 52, "end_pos": 55, "type": "TASK", "confidence": 0.9759665131568909}, {"text": "SMT", "start_pos": 59, "end_pos": 62, "type": "TASK", "confidence": 0.9352238178253174}, {"text": "SMT", "start_pos": 180, "end_pos": 183, "type": "TASK", "confidence": 0.9868265390396118}]}], "introductionContent": [{"text": "A multiword expression (MWE) generally refers to a multiword unit or a collocation of words that cooccur together statistically more than chance.", "labels": [], "entities": [{"text": "multiword expression (MWE)", "start_pos": 2, "end_pos": 28, "type": "TASK", "confidence": 0.6927176475524902}]}, {"text": "A MWE is a cover term for different types of collocations which vary in their transparency and fixedness.", "labels": [], "entities": []}, {"text": "Identifying MWEs and understanding their meaning is considered essential to language understanding, and of crucial importance for any Natural Language Processing (NLP) applications that aim at handling robust language meaning and use.", "labels": [], "entities": [{"text": "Identifying MWEs", "start_pos": 0, "end_pos": 16, "type": "TASK", "confidence": 0.8745649456977844}, {"text": "language understanding", "start_pos": 76, "end_pos": 98, "type": "TASK", "confidence": 0.7530920803546906}]}, {"text": "In fact, the seminal paper () refers to this problem as a key issue for the development of high-quality NLP applications.", "labels": [], "entities": []}, {"text": "() identify Machine Translation as an application of particular interest since \" recognition of MWEs is necessary for systems to preserve the meaning and produce appropriate translations and avoid the generation of unnatural or nonsensical sentences in the target language.\"", "labels": [], "entities": [{"text": "Machine Translation", "start_pos": 12, "end_pos": 31, "type": "TASK", "confidence": 0.822747528553009}, {"text": "recognition of MWEs", "start_pos": 81, "end_pos": 100, "type": "TASK", "confidence": 0.735158642133077}]}, {"text": "However, statistical machine translation (SMT) typically does not model MWEs explicitly.", "labels": [], "entities": [{"text": "statistical machine translation (SMT)", "start_pos": 9, "end_pos": 46, "type": "TASK", "confidence": 0.8264550765355428}]}, {"text": "SMT The research was partially funded by IBM under the DARPA GALE project.", "labels": [], "entities": [{"text": "SMT", "start_pos": 0, "end_pos": 3, "type": "TASK", "confidence": 0.6829332113265991}, {"text": "DARPA GALE project", "start_pos": 55, "end_pos": 73, "type": "DATASET", "confidence": 0.6527942617734274}]}, {"text": "units are typically phrasal translations, defined without any direct syntactic or lexical semantic motivation: they are simply n-grams that are consistently translated in parallel corpora.", "labels": [], "entities": []}, {"text": "Phrasal translations might indirectly capture MWEs, but they are not distinguished from any other n-gram.", "labels": [], "entities": []}, {"text": "As a result, the usefulness of explicitly modeling MWEs in the SMT framework has not yet been studied systematically.", "labels": [], "entities": [{"text": "SMT", "start_pos": 63, "end_pos": 66, "type": "TASK", "confidence": 0.9627506136894226}]}, {"text": "Previous work has focused on automatically learning and integrating translations of very specific MWE categories, such as, for instance, idiomatic Chinese four character expressions () or domain specific MWEs ().", "labels": [], "entities": []}, {"text": "MWEs have also been defined not from a lexical semantics perspective but from a SMT error reduction perspective, as phrases that are hard to align during SMT training).", "labels": [], "entities": [{"text": "SMT error reduction", "start_pos": 80, "end_pos": 99, "type": "TASK", "confidence": 0.8933771252632141}, {"text": "SMT training", "start_pos": 154, "end_pos": 166, "type": "TASK", "confidence": 0.8979029357433319}]}, {"text": "For each of these particular cases, translation quality improved by augmenting the SMT translation lexicon with the learned bilingual MWEs either directly or through improved word alignments.", "labels": [], "entities": [{"text": "SMT translation lexicon", "start_pos": 83, "end_pos": 106, "type": "TASK", "confidence": 0.9265720645586649}]}, {"text": "In this paper, we consider a more general problem: we view SMT as an extrinsic evaluation of the usefulness of monolingual MWEs as used pervasively in natural language regardless of domain, idiomaticity and compositionality.", "labels": [], "entities": [{"text": "SMT", "start_pos": 59, "end_pos": 62, "type": "TASK", "confidence": 0.9906094074249268}]}, {"text": "A MWE is compositional if its meaning as a unit can be predicted from the meaning of its component words such as in make a decision meaning to decide.", "labels": [], "entities": []}, {"text": "Some MWEs are more predictable than others, for instance, kick the bucket, when used idiomatically to mean to die, has nothing in common with the literal meaning of either kick or bucket, while make a decision is very clearly related to to decide.", "labels": [], "entities": []}, {"text": "These expressions are both considered MWEs but have varying degrees of compositionality and predictability.", "labels": [], "entities": []}, {"text": "We explore strategies for integrating all MWEs along this continuum in SMT.", "labels": [], "entities": [{"text": "SMT", "start_pos": 71, "end_pos": 74, "type": "TASK", "confidence": 0.979574978351593}]}, {"text": "Given a monolingual MWE lexicon, we propose (1) a static integration strategy that segments training and test sentences according to the MWE vocabulary, and (2) a dynamic integration strategy that adds anew MWE-based feature in SMT translation lexicons.", "labels": [], "entities": [{"text": "SMT translation lexicons", "start_pos": 228, "end_pos": 252, "type": "TASK", "confidence": 0.9418574571609497}]}, {"text": "Ina pilot study of the impact of WordNet MWEs on a large-scale English to Arabic SMT system, we show that static and dynamic strategies both improve translation quality and that their impact is not the same for different types of MWEs.", "labels": [], "entities": [{"text": "SMT", "start_pos": 81, "end_pos": 84, "type": "TASK", "confidence": 0.6287961006164551}]}, {"text": "This suggests that the proposed framework would bean interesting testbed fora task-driven evaluation of automatic MWE extraction.", "labels": [], "entities": [{"text": "MWE extraction", "start_pos": 114, "end_pos": 128, "type": "TASK", "confidence": 0.9333412349224091}]}], "datasetContent": [{"text": "We evaluate the impact of MWEs in SMT on a largescale English-Arabic translation task.", "labels": [], "entities": [{"text": "MWEs", "start_pos": 26, "end_pos": 30, "type": "TASK", "confidence": 0.9595752954483032}, {"text": "SMT", "start_pos": 34, "end_pos": 37, "type": "TASK", "confidence": 0.8455511331558228}, {"text": "largescale English-Arabic translation task", "start_pos": 43, "end_pos": 85, "type": "TASK", "confidence": 0.6661389619112015}]}, {"text": "Using two languages from different families is a challenging testbed for MWEs in SMT.", "labels": [], "entities": [{"text": "MWEs", "start_pos": 73, "end_pos": 77, "type": "TASK", "confidence": 0.9845020174980164}, {"text": "SMT", "start_pos": 81, "end_pos": 84, "type": "TASK", "confidence": 0.980991780757904}]}, {"text": "In contrast, very closely related languages such as English and French might present less divergence in lexicalization.", "labels": [], "entities": []}, {"text": "In addition, Arabic-English is a well-studied language pair in SMT, with large amounts of data available.", "labels": [], "entities": [{"text": "SMT", "start_pos": 63, "end_pos": 66, "type": "TASK", "confidence": 0.9871562719345093}]}, {"text": "However, we tackle the less common English to Arabic direction in order to take advantage of the rich lexical resources available for English on the input side.", "labels": [], "entities": []}, {"text": "Our test set consists of the 813 newswire sentences of the 2008 NIST Open Machine Translation Evaluation, which is standard evaluation data for Arabic-English translation.", "labels": [], "entities": [{"text": "NIST Open Machine Translation Evaluation", "start_pos": 64, "end_pos": 104, "type": "TASK", "confidence": 0.6831872940063477}]}, {"text": "The first English reference translation is used as the input to our SMT system, and the single Arabic translation is used as the unique reference 2 . Translation quality is evaluated using two automatic evaluation metrics: (1) BLEUr1n4 (), which is based on n-gram precisions for n = 1..4, and (2) Translation Edit Rate (TER) (), which generalizes edit distance beyond single-word edits.", "labels": [], "entities": [{"text": "SMT", "start_pos": 68, "end_pos": 71, "type": "TASK", "confidence": 0.9835361242294312}, {"text": "BLEUr1n4", "start_pos": 227, "end_pos": 235, "type": "METRIC", "confidence": 0.9986056685447693}, {"text": "Translation Edit Rate (TER)", "start_pos": 298, "end_pos": 325, "type": "METRIC", "confidence": 0.800074577331543}]}], "tableCaptions": [{"text": " Table 1: Impact of MWE integration measured on NIST  MT08", "labels": [], "entities": [{"text": "MWE integration", "start_pos": 20, "end_pos": 35, "type": "TASK", "confidence": 0.9649405479431152}, {"text": "NIST  MT08", "start_pos": 48, "end_pos": 58, "type": "DATASET", "confidence": 0.8440269827842712}]}]}