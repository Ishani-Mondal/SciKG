{"title": [{"text": "Softmax-Margin CRFs: Training Log-Linear Models with Cost Functions", "labels": [], "entities": [{"text": "Softmax-Margin CRFs", "start_pos": 0, "end_pos": 19, "type": "DATASET", "confidence": 0.835762232542038}]}], "abstractContent": [{"text": "We describe a method of incorporating task-specific cost functions into standard conditional log-likelihood (CLL) training of linear structured prediction models.", "labels": [], "entities": []}, {"text": "Recently introduced in the speech recognition community, we describe the method generally for struc-tured models, highlight connections to CLL and max-margin learning for structured prediction (Taskar et al., 2003), and show that the method optimizes abound on risk.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 27, "end_pos": 45, "type": "TASK", "confidence": 0.8005826771259308}, {"text": "structured prediction", "start_pos": 171, "end_pos": 192, "type": "TASK", "confidence": 0.7029854655265808}]}, {"text": "The approach is simple, efficient, and easy to implement , requiring very little change to an existing CLL implementation.", "labels": [], "entities": []}, {"text": "We present experimental results comparing with several commonly-used methods for training struc-tured predictors for named-entity recognition.", "labels": [], "entities": [{"text": "named-entity recognition", "start_pos": 117, "end_pos": 141, "type": "TASK", "confidence": 0.7532332837581635}]}], "introductionContent": [{"text": "Conditional random fields (CRFs;) and other conditional log-linear models) achieve strong performance for many NLP problems, but the conditional loglikelihood (CLL) criterion optimized when training these models cannot take a task-specific cost function into account.", "labels": [], "entities": []}, {"text": "In this paper, we describe a simple approach for training conditional log-linear models with cost functions.", "labels": [], "entities": []}, {"text": "We show how the method relates to other methods and how it provides abound on risk.", "labels": [], "entities": []}, {"text": "We apply the method to train a discriminative model for named-entity recognition, showing a statistically significant improvement over CLL.", "labels": [], "entities": [{"text": "named-entity recognition", "start_pos": 56, "end_pos": 80, "type": "TASK", "confidence": 0.7624724507331848}]}], "datasetContent": [{"text": "We consider the problem of named-entity recognition (NER) and use the English data from the CoNLL 2003 shared task.", "labels": [], "entities": [{"text": "named-entity recognition (NER)", "start_pos": 27, "end_pos": 57, "type": "TASK", "confidence": 0.8472874522209167}, {"text": "CoNLL 2003 shared task", "start_pos": 92, "end_pos": 114, "type": "DATASET", "confidence": 0.9050503969192505}]}, {"text": "The data consist of news articles Max-Margin: min Risk: min annotated with four entity types: person, location, organization, and miscellaneous.", "labels": [], "entities": []}, {"text": "Our experiments focus on comparing training objectives for structured sequential models for this task.", "labels": [], "entities": []}, {"text": "For all objectives, we use the same standard set of feature templates, following with additional token shape like those in and simple gazetteer features.", "labels": [], "entities": []}, {"text": "A feature was included if it occurred at least once in training data (total 1,312,255 features).", "labels": [], "entities": []}, {"text": "The task is evaluated using the F 1 score, which is the harmonic mean of precision and recall (computed at the level of entire entities).", "labels": [], "entities": [{"text": "F 1 score", "start_pos": 32, "end_pos": 41, "type": "METRIC", "confidence": 0.9866286317507426}, {"text": "precision", "start_pos": 73, "end_pos": 82, "type": "METRIC", "confidence": 0.9993780851364136}, {"text": "recall", "start_pos": 87, "end_pos": 93, "type": "METRIC", "confidence": 0.9982678890228271}]}, {"text": "Since this metric is computed from corpus-level precision and recall, it is not easily decomposable into features used in standard chain CRFs.", "labels": [], "entities": [{"text": "precision", "start_pos": 48, "end_pos": 57, "type": "METRIC", "confidence": 0.9679053425788879}, {"text": "recall", "start_pos": 62, "end_pos": 68, "type": "METRIC", "confidence": 0.9973244667053223}]}, {"text": "For simplicity, we only consider Hamming cost in this paper; experiments with other cost functions more targeted to NER are presented in.", "labels": [], "entities": [{"text": "NER", "start_pos": 116, "end_pos": 119, "type": "TASK", "confidence": 0.8352039456367493}]}], "tableCaptions": [{"text": " Table 1: Results on development and test sets, along with  hyperparameter values chosen using development set.", "labels": [], "entities": []}]}