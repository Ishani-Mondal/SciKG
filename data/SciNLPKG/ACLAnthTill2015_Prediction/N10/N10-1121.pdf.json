{"title": [{"text": "Convolution Kernels for Opinion Holder Extraction", "labels": [], "entities": [{"text": "Opinion Holder Extraction", "start_pos": 24, "end_pos": 49, "type": "TASK", "confidence": 0.7947146495183309}]}], "abstractContent": [{"text": "Opinion holder extraction is one of the important subtasks in sentiment analysis.", "labels": [], "entities": [{"text": "Opinion holder extraction", "start_pos": 0, "end_pos": 25, "type": "TASK", "confidence": 0.8385019699732462}, {"text": "sentiment analysis", "start_pos": 62, "end_pos": 80, "type": "TASK", "confidence": 0.9520893692970276}]}, {"text": "The effective detection of an opinion holder depends on the consideration of various cues on various levels of representation, though they are hard to formulate explicitly as features.", "labels": [], "entities": []}, {"text": "In this work, we propose to use convolution kernels for that task which identify meaningful fragments of sequences or trees by themselves.", "labels": [], "entities": []}, {"text": "We not only investigate how different levels of information can be effectively combined in different kernels but also examine how the scope of these kernels should be chosen.", "labels": [], "entities": []}, {"text": "In general relation extraction, the two candidate entities thought to be involved in a relation are commonly chosen to be the boundaries of sequences and trees.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 11, "end_pos": 30, "type": "TASK", "confidence": 0.8148247301578522}]}, {"text": "The definition of boundaries in opinion holder extraction, however, is less straightforward since there might be several expressions beside the candidate opinion holder to be eligible for being a boundary.", "labels": [], "entities": [{"text": "opinion holder extraction", "start_pos": 32, "end_pos": 57, "type": "TASK", "confidence": 0.6826343735059103}]}], "introductionContent": [{"text": "In recent years, there has been a growing interest in the automatic detection of opinionated content in natural language text.", "labels": [], "entities": [{"text": "automatic detection of opinionated content in natural language text", "start_pos": 58, "end_pos": 125, "type": "TASK", "confidence": 0.847511887550354}]}, {"text": "One of the more important tasks in sentiment analysis is the extraction of opinion holders.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 35, "end_pos": 53, "type": "TASK", "confidence": 0.9552695751190186}, {"text": "extraction of opinion holders", "start_pos": 61, "end_pos": 90, "type": "TASK", "confidence": 0.8509733825922012}]}, {"text": "Opinion holder extraction is one of the critical components of an opinion questionanswering system (i.e. systems which automatically answer opinion questions, such as \"What does like about?\").", "labels": [], "entities": [{"text": "Opinion holder extraction", "start_pos": 0, "end_pos": 25, "type": "TASK", "confidence": 0.6869521538416544}]}, {"text": "Such systems need to be able to distinguish which entities in a candidate answer sentence are the sources of opinions (= opinion holder) and which are the targets.", "labels": [], "entities": []}, {"text": "On other NLP tasks, in particular, on relation extraction, there has been much work on convolution kernels, i.e. kernel functions exploiting huge amounts of features without an explicit feature representation.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 38, "end_pos": 57, "type": "TASK", "confidence": 0.8667566180229187}]}, {"text": "Previous research on that task has shown that convolution kernels, such as sequence and tree kernels, are quite effective when compared to manual feature engineering.", "labels": [], "entities": []}, {"text": "In order to effectively use convolution kernels, it is often necessary to choose appropriate substructures of a sentence rather than represent the sentence as a whole structure (.", "labels": [], "entities": []}, {"text": "As for tree kernels, for example, one typically chooses the syntactic subtree immediately enclosing two entities potentially expressing a specific relation in a given sentence.", "labels": [], "entities": []}, {"text": "The opinion holder detection task is different from this scenario.", "labels": [], "entities": [{"text": "opinion holder detection", "start_pos": 4, "end_pos": 28, "type": "TASK", "confidence": 0.7880706687768301}]}, {"text": "There can be several cues within a sentence to indicate the presence of a genuine opinion holder and these cues need not be member of a particular word group, e.g. they can be opinion words (see Sentences 1-3), communication words, such as maintained in Sentence 2, or other lexical cues, such as according in Sentence 3.", "labels": [], "entities": []}, {"text": "Thus, the definition of boundaries of the structures for the convolution kernels is less straightforward in opinion holder extraction.", "labels": [], "entities": [{"text": "opinion holder extraction", "start_pos": 108, "end_pos": 133, "type": "TASK", "confidence": 0.6093719204266866}]}, {"text": "The aim of this paper is to explore in how far convolution kernels can be beneficial for effective opinion holder detection.", "labels": [], "entities": [{"text": "opinion holder detection", "start_pos": 99, "end_pos": 123, "type": "TASK", "confidence": 0.7801294227441152}]}, {"text": "We are not only interested in how far different kernel types contribute to this extraction task but we also contrast the performance of these kernels with a manually designed feature set used as a standard vector kernel.", "labels": [], "entities": []}, {"text": "Finally, we also examine the effectiveness of expanding word sequences or syntactic trees by additional prior knowledge.", "labels": [], "entities": []}, {"text": "examine opinion holder extraction using CRFs with various manually defined linguistic features and patterns automatically learnt by the AutoSlog system.", "labels": [], "entities": [{"text": "opinion holder extraction", "start_pos": 8, "end_pos": 33, "type": "TASK", "confidence": 0.662375420331955}]}, {"text": "The linguistic features focus on named-entity information and syntactic relations to opinion words.", "labels": [], "entities": []}, {"text": "In this paper, we use very similar settings.", "labels": [], "entities": []}, {"text": "The features presented in and resemble very much.", "labels": [], "entities": []}, {"text": "also consider communication words to be predictive cues for opinion holders. and explore the usefulness of semantic roles provided by FrameNet () for both opinion holder and opinion target extraction.", "labels": [], "entities": [{"text": "FrameNet", "start_pos": 134, "end_pos": 142, "type": "DATASET", "confidence": 0.9026883840560913}, {"text": "opinion target extraction", "start_pos": 174, "end_pos": 199, "type": "TASK", "confidence": 0.6622791588306427}]}, {"text": "Due to data sparseness, expand FrameNet data by using an unsupervised clustering algorithm. is an extension of in that opinion holder extraction is learnt jointly with opinion detection.", "labels": [], "entities": [{"text": "FrameNet data", "start_pos": 31, "end_pos": 44, "type": "DATASET", "confidence": 0.8431974053382874}, {"text": "opinion holder extraction", "start_pos": 119, "end_pos": 144, "type": "TASK", "confidence": 0.6178549329439799}, {"text": "opinion detection", "start_pos": 168, "end_pos": 185, "type": "TASK", "confidence": 0.7936899662017822}]}, {"text": "This requires that opinion expressions and their relations to opinion holders are annotated in the training data.", "labels": [], "entities": []}, {"text": "Semantic roles are also taken as a potential source of information.", "labels": [], "entities": []}, {"text": "In our work, we deliberately work with minimal annotation and, thus, do not consider any labeled opinion expressions and relations to opinion holders in the training data.", "labels": [], "entities": []}, {"text": "We exclusively rely on entities marked as opinion holders.", "labels": [], "entities": []}, {"text": "In many practical situations, the annotation beyond opinion holder labeling is too expensive.", "labels": [], "entities": []}, {"text": "Complex convolution kernels have been successfully applied to various NLP tasks, such as relation extraction (, question answering (, and semantic role labeling ( . In all these tasks, they offer competitive performance to manually designed feature sets.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 89, "end_pos": 108, "type": "TASK", "confidence": 0.8585228621959686}, {"text": "question answering", "start_pos": 112, "end_pos": 130, "type": "TASK", "confidence": 0.8741692900657654}, {"text": "semantic role labeling", "start_pos": 138, "end_pos": 160, "type": "TASK", "confidence": 0.6736700932184855}]}, {"text": "combine different sequence kernels encoding different contexts of candidate entities in a sentence.", "labels": [], "entities": []}, {"text": "They argue that several kernels encoding different contexts are more effective than just using one kernel with one specific context.", "labels": [], "entities": []}, {"text": "We build on that idea and compare various scopes eligible for opinion holder extraction. and suggest that different kinds of information, such as word sequences, part-of-speech tags, syntactic and semantic information should be contained in separate convolution kernels.", "labels": [], "entities": [{"text": "opinion holder extraction.", "start_pos": 62, "end_pos": 88, "type": "TASK", "confidence": 0.6711351672808329}]}, {"text": "We also adhere to this notion.", "labels": [], "entities": []}], "datasetContent": [{"text": "We used 400 documents of the MPQA corpus for five-fold crossvalidation and 133 documents as a development set.", "labels": [], "entities": [{"text": "MPQA corpus", "start_pos": 29, "end_pos": 40, "type": "DATASET", "confidence": 0.9637060165405273}]}, {"text": "We report statistical significance on the basis of a paired t-test using 0.05 as the significance level.", "labels": [], "entities": [{"text": "significance", "start_pos": 22, "end_pos": 34, "type": "METRIC", "confidence": 0.7856845855712891}, {"text": "significance", "start_pos": 85, "end_pos": 97, "type": "METRIC", "confidence": 0.9817792773246765}]}, {"text": "All experiments were done with the SVM-Light-TK toolkit . We evaluated on the basis of exact phrase matching.", "labels": [], "entities": [{"text": "phrase matching", "start_pos": 93, "end_pos": 108, "type": "TASK", "confidence": 0.6734470874071121}]}, {"text": "We set the trade-off parameter j = 5 for all feature sets.", "labels": [], "entities": []}, {"text": "For the manual feature set we used a polynomial kernel of third degree.", "labels": [], "entities": []}, {"text": "These two critical parameters were tuned on the development set.", "labels": [], "entities": []}, {"text": "As far as the sequence and tree kernels are concerned, we used the parameter settings from, i.e. \u03bb = 0.4 and \u00b5 = 0.4.", "labels": [], "entities": []}, {"text": "Kernels were combined using plain summation.", "labels": [], "entities": []}, {"text": "The documents were parsed using the Stanford Parser (.", "labels": [], "entities": [{"text": "Stanford Parser (.", "start_pos": 36, "end_pos": 54, "type": "DATASET", "confidence": 0.9726852774620056}]}, {"text": "Namedentity information was obtained by the Stanford tagger ().", "labels": [], "entities": [{"text": "Stanford tagger", "start_pos": 44, "end_pos": 59, "type": "DATASET", "confidence": 0.9429293274879456}]}, {"text": "Semantic roles were obtained by using the parser by.", "labels": [], "entities": []}, {"text": "Opinion expressions were identified using the Subjectivity Lexicon from the MPQA project).", "labels": [], "entities": [{"text": "Subjectivity Lexicon from the MPQA project", "start_pos": 46, "end_pos": 88, "type": "DATASET", "confidence": 0.6840110868215561}]}, {"text": "Communication words were obtained by using the Appraisal Lexicon (  up nouns in NOMLEX ().", "labels": [], "entities": [{"text": "Appraisal Lexicon", "start_pos": 47, "end_pos": 64, "type": "DATASET", "confidence": 0.8543526530265808}, {"text": "NOMLEX", "start_pos": 80, "end_pos": 86, "type": "DATASET", "confidence": 0.9598217606544495}]}], "tableCaptions": [{"text": " Table 7: Results of kernel combinations (  *  : significantly  better than best SKs;  \u2020 : significantly better than best TKs;  all convolution kernels are significantly better than VK).", "labels": [], "entities": []}, {"text": " Table 5: Results of the different sequence kernels.", "labels": [], "entities": []}, {"text": " Table 6: Results of the different tree kernels.", "labels": [], "entities": []}]}