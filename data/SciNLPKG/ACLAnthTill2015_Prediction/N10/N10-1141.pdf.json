{"title": [], "abstractContent": [{"text": "Machine translation benefits from two types of decoding techniques: consensus decoding over multiple hypotheses under a single model and system combination over hypotheses from different models.", "labels": [], "entities": [{"text": "Machine translation", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.807836651802063}]}, {"text": "We present model combination , a method that integrates consensus decoding and system combination into a unified , forest-based technique.", "labels": [], "entities": []}, {"text": "Our approach makes few assumptions about the underlying component models, enabling us to combine systems with heterogenous structure.", "labels": [], "entities": []}, {"text": "Unlike most system combination techniques, we reuse the search space of component models, which entirely avoids the need to align translation hypotheses.", "labels": [], "entities": []}, {"text": "Despite its relative simplicity , model combination improves translation quality over a pipelined approach of first applying consensus decoding to individual systems, and then applying system combination to their output.", "labels": [], "entities": [{"text": "translation", "start_pos": 61, "end_pos": 72, "type": "TASK", "confidence": 0.9616516828536987}]}, {"text": "We demonstrate BLEU improvements across data sets and language pairs in large-scale experiments.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 15, "end_pos": 19, "type": "METRIC", "confidence": 0.9974164962768555}]}], "introductionContent": [{"text": "Once statistical translation models are trained, a decoding approach determines what translations are finally selected.", "labels": [], "entities": []}, {"text": "Two parallel lines of research have shown consistent improvements over the standard max-derivation decoding objective, which selects the highest probability derivation.", "labels": [], "entities": []}, {"text": "Consensus decoding procedures select translations fora single system by optimizing for model predictions about n-grams, motivated either as minimizing Bayes risk (), maximizing sentence similarity (, or approximating a max-translation objective (.", "labels": [], "entities": []}, {"text": "System combination procedures, on the other hand, generate translations from the output of multiple component systems (.", "labels": [], "entities": []}, {"text": "In this paper, we present model combination, a technique that unifies these two approaches by learning a consensus model over the n-gram features of multiple underlying component models.", "labels": [], "entities": []}, {"text": "Model combination operates over the component models' posterior distributions over translation derivations, encoded as a forest of derivations.", "labels": [], "entities": []}, {"text": "We combine these components by constructing a linear consensus model that includes features from each component.", "labels": [], "entities": []}, {"text": "We then optimize this consensus model over the space of all translation derivations in the support of all component models' posterior distributions.", "labels": [], "entities": []}, {"text": "By reusing the components' search spaces, we entirely avoid the hypothesis alignment problem that is central to standard system combination approaches (.", "labels": [], "entities": [{"text": "hypothesis alignment", "start_pos": 64, "end_pos": 84, "type": "TASK", "confidence": 0.7179770320653915}]}, {"text": "Forest-based consensus decoding techniques differ in whether they capture model predictions through n-gram posteriors () or expected n-gram counts ().", "labels": [], "entities": []}, {"text": "We evaluate both in controlled experiments, demonstrating their empirical similarity.", "labels": [], "entities": []}, {"text": "We also describe algorithms for expanding translation forests to ensure that n-grams are local to a forest's hyperedges, and for exactly computing n-gram posteriors efficiently.", "labels": [], "entities": []}, {"text": "Model combination assumes only that each translation model can produce expectations of n-gram features; the latent derivation structures of component systems can differ arbitrarily.", "labels": [], "entities": []}, {"text": "This flexibility allows us to combine phrase-based, hierarchical, and syntax-augmented translation models.", "labels": [], "entities": []}, {"text": "We evaluate by combining three large-scale systems on ChineseEnglish and Arabic-English NIST data sets, demonstrating improvements of up to 1.4 BLEU over the best single system max-derivation baseline, and consistent improvements over a more complex multisystem pipeline that includes independent consensus decoding and system combination.", "labels": [], "entities": [{"text": "ChineseEnglish and Arabic-English NIST data sets", "start_pos": 54, "end_pos": 102, "type": "DATASET", "confidence": 0.7354205946127573}, {"text": "BLEU", "start_pos": 144, "end_pos": 148, "type": "METRIC", "confidence": 0.9988412261009216}]}], "datasetContent": [{"text": "We report results on the constrained data track of the NIST 2008 Arabic-to-English (ar-en) and Chineseto-English (zh-en) translation tasks.", "labels": [], "entities": [{"text": "NIST 2008 Arabic-to-English", "start_pos": 55, "end_pos": 82, "type": "DATASET", "confidence": 0.9311041235923767}, {"text": "Chineseto-English (zh-en) translation", "start_pos": 95, "end_pos": 132, "type": "TASK", "confidence": 0.6560963988304138}]}, {"text": "We train on all parallel and monolingual data allowed in the track.", "labels": [], "entities": []}, {"text": "We use the NIST 2004 eval set (dev) for optimizing parameters in model combination and test on the NIST 2008 evaluation set.", "labels": [], "entities": [{"text": "NIST 2004 eval set", "start_pos": 11, "end_pos": 29, "type": "DATASET", "confidence": 0.9373566955327988}, {"text": "NIST 2008 evaluation set", "start_pos": 99, "end_pos": 123, "type": "DATASET", "confidence": 0.9710814952850342}]}, {"text": "We report results using the IBM implementation of the BLEU score which computes the brevity penalty using the closest reference translation for each segment).", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 54, "end_pos": 64, "type": "METRIC", "confidence": 0.962344229221344}]}, {"text": "We measure statistical significance using 95% confidence intervals computed using paired bootstrap resampling.", "labels": [], "entities": []}, {"text": "In) systems without statistically significant differences are marked with the same superscript.", "labels": [], "entities": []}, {"text": "We first perform MBR on the conjoined hypergraph (MBR-Conjoin).", "labels": [], "entities": []}, {"text": "In this case, each edge is tagged with 4 conjoined n-gram features v n , along with length and base model features.", "labels": [], "entities": []}, {"text": "MBR-Conjoin is worse than MBR on the hypergraph from the single best system.", "labels": [], "entities": [{"text": "MBR-Conjoin", "start_pos": 0, "end_pos": 11, "type": "DATASET", "confidence": 0.6357464790344238}, {"text": "MBR", "start_pos": 26, "end_pos": 29, "type": "METRIC", "confidence": 0.7855985760688782}]}, {"text": "This could imply that either the larger search space introduces poor hypotheses or that the n-gram posteriors obtained are weaker.", "labels": [], "entities": []}, {"text": "When we now restrict the n-gram features to those from the best system (MBR Conjoin/feats-best), BLEU scores increase relative to MBR-Conjoin.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 97, "end_pos": 101, "type": "METRIC", "confidence": 0.9996141195297241}, {"text": "MBR-Conjoin", "start_pos": 130, "end_pos": 141, "type": "DATASET", "confidence": 0.9319509863853455}]}, {"text": "This implies that the n-gram features computed over the conjoined hypergraph are weaker than the corresponding features from the best system.", "labels": [], "entities": []}, {"text": "Adding system indicator features (MBR Conjoin+SI) helps the MBR-Conjoin system considerably; the resulting system is better than the best MBR system.", "labels": [], "entities": [{"text": "MBR-Conjoin", "start_pos": 60, "end_pos": 71, "type": "DATASET", "confidence": 0.8803689479827881}]}, {"text": "This could mean that the SI features guide search towards stronger parts of the larger search space.", "labels": [], "entities": []}, {"text": "In addition, these features provide a normalization of scores across systems.", "labels": [], "entities": []}, {"text": "We next do several model-combination experiments.", "labels": [], "entities": []}, {"text": "We perform model combination using the search space of only the best MBR system (MC 1best HG).", "labels": [], "entities": [{"text": "MC 1best HG", "start_pos": 81, "end_pos": 92, "type": "DATASET", "confidence": 0.7775810956954956}]}, {"text": "Here, the hypergraph is annotated with n-gram features from the 3 base systems, as well as length and base model features.", "labels": [], "entities": []}, {"text": "A total of 3 \u00d7 4 + 1 + 1 = 14 features are added to each edge.", "labels": [], "entities": []}, {"text": "Sur-: BLEU performance for different system and model combination approaches.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 6, "end_pos": 10, "type": "METRIC", "confidence": 0.9951096177101135}]}, {"text": "Sentence-level and word-level system combination operate over the sentence output of the base systems, which are either decoded to maximize derivation score (MAX) or to minimize Bayes risk (MBR).", "labels": [], "entities": [{"text": "maximize derivation score (MAX)", "start_pos": 131, "end_pos": 162, "type": "METRIC", "confidence": 0.7578377425670624}, {"text": "Bayes risk (MBR)", "start_pos": 178, "end_pos": 194, "type": "METRIC", "confidence": 0.9360986232757569}]}, {"text": "prisingly, n-gram features from the additional systems did not help select a better hypothesis within the search space of a single system.", "labels": [], "entities": []}, {"text": "When we expand the search space to the conjoined hypergraph (MC Conjoin), it performs worse relative to MC 1-best.", "labels": [], "entities": []}, {"text": "Since these two systems are identical in their feature set, we hypothesize that the larger search space has introduced erroneous hypotheses.", "labels": [], "entities": []}, {"text": "This is similar to the scenario where MBR Conjoin is worse than MBR 1-best.", "labels": [], "entities": [{"text": "MBR", "start_pos": 38, "end_pos": 41, "type": "DATASET", "confidence": 0.5489748120307922}, {"text": "Conjoin", "start_pos": 42, "end_pos": 49, "type": "METRIC", "confidence": 0.645586371421814}]}, {"text": "As in the MBR case, adding system indicator features helps (MC Conjoin/base/SI).", "labels": [], "entities": [{"text": "MBR", "start_pos": 10, "end_pos": 13, "type": "DATASET", "confidence": 0.7888889312744141}]}, {"text": "The result is comparable to MBR on the conjoined hypergraph with SI features.", "labels": [], "entities": [{"text": "MBR", "start_pos": 28, "end_pos": 31, "type": "METRIC", "confidence": 0.9121192097663879}]}, {"text": "We finally add extra n-gram features which are computed from the conjoined hypergraph (MC Conjoin + SI).", "labels": [], "entities": []}, {"text": "This gives the best performance although the gains over MC Conjoin/base/SI are quite small.", "labels": [], "entities": []}, {"text": "Note that these added features are the same n-gram features used in MBR Conjoin.", "labels": [], "entities": [{"text": "MBR Conjoin", "start_pos": 68, "end_pos": 79, "type": "DATASET", "confidence": 0.9371263980865479}]}, {"text": "Although they are not strong by themselves, they provide additional discriminative power by providing a consensus score across all 3 base systems.", "labels": [], "entities": []}, {"text": "compares model combination to two system combination algorithms.", "labels": [], "entities": []}, {"text": "The first, which we call sentence-level combination, chooses among the base systems' three translations the sentence that has the highest consensus score.", "labels": [], "entities": []}, {"text": "The second, wordlevel combination, builds a \"word sausage\" from the outputs of the three systems and chooses a path through the sausage with the highest score under a similar model: MBR decoding on the syntax augmented system, with and without hypergraph expansion.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Performance of baseline systems.", "labels": [], "entities": []}, {"text": " Table 2: Performance from the best single system for  each language pair without consensus decoding (Best  MAX system), the best system with minimum Bayes risk  decoding (Best MBR system), and model combination  across three systems.", "labels": [], "entities": []}, {"text": " Table 3: Model Combination experiments.", "labels": [], "entities": []}, {"text": " Table 4: BLEU performance for different system and  model combination approaches. Sentence-level and  word-level system combination operate over the sentence  output of the base systems, which are either decoded to  maximize derivation score (MAX) or to minimize Bayes  risk (MBR).", "labels": [], "entities": [{"text": "BLEU", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9972479939460754}, {"text": "maximize derivation score (MAX)", "start_pos": 217, "end_pos": 248, "type": "METRIC", "confidence": 0.7094515065352122}, {"text": "Bayes  risk (MBR)", "start_pos": 264, "end_pos": 281, "type": "METRIC", "confidence": 0.9347742438316345}]}]}