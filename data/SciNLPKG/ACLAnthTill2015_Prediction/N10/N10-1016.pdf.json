{"title": [{"text": "Learning Translation Boundaries for Phrase-Based Decoding", "labels": [], "entities": [{"text": "Learning Translation Boundaries", "start_pos": 0, "end_pos": 31, "type": "TASK", "confidence": 0.7776366472244263}, {"text": "Phrase-Based Decoding", "start_pos": 36, "end_pos": 57, "type": "TASK", "confidence": 0.8266089558601379}]}], "abstractContent": [{"text": "Constrained decoding is of great importance not only for speed but also for translation quality.", "labels": [], "entities": [{"text": "speed", "start_pos": 57, "end_pos": 62, "type": "METRIC", "confidence": 0.9836941361427307}, {"text": "translation", "start_pos": 76, "end_pos": 87, "type": "TASK", "confidence": 0.9737704396247864}]}, {"text": "Previous efforts explore soft syntactic constraints which are based on constituent boundaries deduced from parse trees of the source language.", "labels": [], "entities": []}, {"text": "We present anew framework to establish soft constraints based on a more natural alternative: translation boundary rather than constituent boundary.", "labels": [], "entities": []}, {"text": "We propose simple classifiers to learn translation boundaries for any source sentences.", "labels": [], "entities": []}, {"text": "The classifiers are trained directly on word-aligned corpus without using any additional resources.", "labels": [], "entities": []}, {"text": "We report the accuracy of our translation boundary clas-sifiers.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 14, "end_pos": 22, "type": "METRIC", "confidence": 0.9995922446250916}]}, {"text": "We show that using constraints based on translation boundaries predicted by our classifiers achieves significant improvements over the baseline on large-scale Chinese-to-English translation experiments.", "labels": [], "entities": []}, {"text": "The new constraints also significantly outperform constituent boundary based syntactic constrains.", "labels": [], "entities": []}], "introductionContent": [{"text": "It has been known that phrase-based decoding (phrase segmentation/translation/reordering)) should be constrained to some extent not only for transferring the NP-hard problem) into a tractable one in practice but also for improving translation quality.", "labels": [], "entities": [{"text": "phrase segmentation/translation/reordering", "start_pos": 46, "end_pos": 88, "type": "TASK", "confidence": 0.8572278618812561}]}, {"text": "For example, find that translation quality can be significantly improved by either prohibiting reorderings around punctuation or restricting reorderings within a 15-word window.", "labels": [], "entities": []}, {"text": "Recently, more linguistically motivated constraints are introduced to improve phrase-based and) introduce syntactic constraints into the standard phrase-based decoding ( and hierarchical phrase-based decoding respectively by using a counting feature which accumulates whenever hypotheses violate syntactic boundaries of source-side parse trees.", "labels": [], "entities": []}, {"text": "( further presents a bracketing model to include thousands of context-sensitive syntactic constraints.", "labels": [], "entities": []}, {"text": "All of these approaches achieve their improvements by guiding the phrase-based decoder to prefer translations which respect source-side parse trees.", "labels": [], "entities": []}, {"text": "One major problem with such constituent boundary based constraints is that syntactic structures of the source language do not necessarily reflect translation structures where the source and target language correspond to each other.", "labels": [], "entities": []}, {"text": "In this paper, we investigate building classifiers that directly address the problem of translation boundary, rather than extracting constituent boundary from sourceside parsers built fora different purpose.", "labels": [], "entities": []}, {"text": "A translation boundary is a position in the source sequence which begins or ends a translation zone 1 spanning multiple source words.", "labels": [], "entities": []}, {"text": "Ina translation zone, the source phrase is translated as a unit.", "labels": [], "entities": []}, {"text": "Reorderings which cross translation zones are not desirable.", "labels": [], "entities": []}, {"text": "Inspired by) which introduces classifiers to decide if a word can begin/end a multi-word constituent, we build two discriminative classifiers to tag each word in the source sequence with a binary class label.", "labels": [], "entities": []}, {"text": "The first classifier decides if a word can begin a multi-sourceword translation zone; the second classifier decides if a word can end a multi-source-word translation zone.", "labels": [], "entities": []}, {"text": "Given a partial translation covering source sequence (i, j) with start word c i and end word c j 2 , this translation can be penalized if the first classifier decides that the start word c i cannot be a beginning translation boundary or the second classifier decides that the end word c j cannot bean ending translation boundary.", "labels": [], "entities": []}, {"text": "In such away, we can guide the decoder to boost hypotheses that respect translation boundaries and therefore the common translation structure shared by the source and target language, rather than the syntactic structure of the source language.", "labels": [], "entities": []}, {"text": "We report the accuracy of such classifiers by comparing their outputs with \"gold\" translation boundaries obtained from reference translations on the development set.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 14, "end_pos": 22, "type": "METRIC", "confidence": 0.9990479350090027}]}, {"text": "We integrate translation boundary based constraints into phrase-based decoding and display that they improve translation quality significantly in large-scale experiments.", "labels": [], "entities": []}, {"text": "Furthermore, we confirm that they also significantly outperform constituent boundary based syntactic constraints.", "labels": [], "entities": []}], "datasetContent": [{"text": "Our baseline system is a phrase-based system using BTGs (Wu, 1997), which includes a contentdependent reordering model discriminatively trained using reordering examples ().", "labels": [], "entities": []}, {"text": "We carried out various experiments to evaluate the impact of integrating translation boundary based soft constraints into decoding on the system performance on the Chinese-to-English translation task of the NIST MT-05 using large scale training data.", "labels": [], "entities": [{"text": "Chinese-to-English translation task", "start_pos": 164, "end_pos": 199, "type": "TASK", "confidence": 0.7329210241635641}, {"text": "NIST MT-05", "start_pos": 207, "end_pos": 217, "type": "DATASET", "confidence": 0.9033582806587219}]}, {"text": "Our training corpora are listed in.", "labels": [], "entities": []}, {"text": "The whole corpora consist of 96.9M Chinese words and 109.5M English words in 3.8M sentence pairs.", "labels": [], "entities": []}, {"text": "We ran GIZA++) on the parallel corpora in both directions and then applied the \"grow-diag-final\" refinement rule ( ) to obtain many-to-many word alignments.", "labels": [], "entities": []}, {"text": "From the word-aligned corpora, we extracted bilingual phrases and trained our translation model.", "labels": [], "entities": []}, {"text": "We used all corpora in except for the United Nations corpus to train our MaxEnt based reordering model (), which con-sist of 33.3M Chinese words and 35.8M English words.", "labels": [], "entities": [{"text": "United Nations corpus", "start_pos": 38, "end_pos": 59, "type": "DATASET", "confidence": 0.9420136213302612}]}, {"text": "We built a four-gram language model using the SRILM toolkit, which was trained on Xinhua section of the English Gigaword corpus (181.1M words).", "labels": [], "entities": [{"text": "SRILM toolkit", "start_pos": 46, "end_pos": 59, "type": "DATASET", "confidence": 0.8704067468643188}, {"text": "English Gigaword corpus", "start_pos": 104, "end_pos": 127, "type": "DATASET", "confidence": 0.870051642258962}]}, {"text": "To train our translation boundary classifiers, we extract training instances from the whole wordaligned corpora, from which we obtain 96.9M training instances for the B y /B n and E y /E n classifier.", "labels": [], "entities": []}, {"text": "We ran the off-the-shelf MaxEnt toolkit) to tune classifier feature weights with Gaussian prior set to 1 to avoid overfitting.", "labels": [], "entities": []}, {"text": "We used the NIST MT-03 evaluation test data as our development set (919 sentences in total, 27.1 words per sentence).", "labels": [], "entities": [{"text": "NIST MT-03 evaluation test data", "start_pos": 12, "end_pos": 43, "type": "DATASET", "confidence": 0.9212086915969848}]}, {"text": "The NIST MT-05 test set includes 1082 sentences with an average of 27.4 words per sentence.", "labels": [], "entities": [{"text": "NIST MT-05 test set", "start_pos": 4, "end_pos": 23, "type": "DATASET", "confidence": 0.9055164605379105}]}, {"text": "Both the reference corpus for the NIST MT-03 set and the reference corpus for the NIST MT-05 set contain 4 translations per source sentence.", "labels": [], "entities": [{"text": "NIST MT-03 set", "start_pos": 34, "end_pos": 48, "type": "DATASET", "confidence": 0.8894787629445394}, {"text": "NIST MT-05 set", "start_pos": 82, "end_pos": 96, "type": "DATASET", "confidence": 0.8905433416366577}]}, {"text": "To compare with constituent boundary based constraints, we parsed source sentences of both the development and test sets using a Chinese parser () which was trained on the Penn Chinese Treebank with an F 1 -score of 79.4%.", "labels": [], "entities": [{"text": "Penn Chinese Treebank", "start_pos": 172, "end_pos": 193, "type": "DATASET", "confidence": 0.9871209859848022}, {"text": "F 1 -score", "start_pos": 202, "end_pos": 212, "type": "METRIC", "confidence": 0.9738048017024994}]}, {"text": "Our evaluation metric is case-insensitive BLEU-4 () using the shortest reference sentence length for the brevity penalty.", "labels": [], "entities": [{"text": "BLEU-4", "start_pos": 42, "end_pos": 48, "type": "METRIC", "confidence": 0.9858770370483398}]}, {"text": "Statistical significance in BLEU score differences was tested by paired bootstrap re-sampling).", "labels": [], "entities": [{"text": "BLEU score differences", "start_pos": 28, "end_pos": 50, "type": "METRIC", "confidence": 0.966862142086029}]}], "tableCaptions": [{"text": " Table 1: Statistics on word classes from our bilingual  training data. All numbers are calculated on the source  side. P means the percentage.", "labels": [], "entities": [{"text": "P", "start_pos": 120, "end_pos": 121, "type": "METRIC", "confidence": 0.9761952757835388}]}, {"text": " Table 3: Average classification accuracy on the develop- ment set for our MEMM based translation boundary clas- sifiers with various Markov orders.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 33, "end_pos": 41, "type": "METRIC", "confidence": 0.9906965494155884}]}, {"text": " Table 6: Results of using translation boundaries obtained  from reference translations. *: significantly better than  baseline (p < 0.01).", "labels": [], "entities": []}, {"text": " Table 7: Results of using automatically learned trans- lation boundaries. Condeducer means using pure con- stituent boundary based soft constraint. XP+ is another  constituent boundary based soft constraint but with dis- tinction among special constituent types", "labels": [], "entities": []}]}