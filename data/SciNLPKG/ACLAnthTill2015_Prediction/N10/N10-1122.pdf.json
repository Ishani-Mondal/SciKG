{"title": [{"text": "An Unsupervised Aspect-Sentiment Model for Online Reviews", "labels": [], "entities": []}], "abstractContent": [{"text": "With the increase in popularity of online review sites comes a corresponding need for tools capable of extracting the information most important to the user from the plain text data.", "labels": [], "entities": []}, {"text": "Due to the diversity in products and services being reviewed, supervised methods are often not practical.", "labels": [], "entities": []}, {"text": "We present an unsuper-vised system for extracting aspects and determining sentiment in review text.", "labels": [], "entities": []}, {"text": "The method is simple and flexible with regard to domain and language, and takes into account the influence of aspect on sentiment polarity, an issue largely ignored in previous literature.", "labels": [], "entities": [{"text": "sentiment polarity", "start_pos": 120, "end_pos": 138, "type": "TASK", "confidence": 0.8226761817932129}]}, {"text": "We demonstrate its effectiveness on both component tasks, where it achieves similar results to more complex semi-supervised methods that are restricted by their reliance on manual annotation and extensive knowledge sources.", "labels": [], "entities": []}], "introductionContent": [{"text": "Online review sites continue to grow in popularity as more people seek the advice of fellow users regarding services and products.", "labels": [], "entities": []}, {"text": "Unfortunately, users are often forced to wade through large quantities of written data in order to find the information they want.", "labels": [], "entities": []}, {"text": "This has led to an increase in research in the areas of opinion mining and sentiment analysis, with the aim of providing systems that can automatically analyze user reviews and extract the information most relevant to the user.", "labels": [], "entities": [{"text": "opinion mining", "start_pos": 56, "end_pos": 70, "type": "TASK", "confidence": 0.8020524084568024}, {"text": "sentiment analysis", "start_pos": 75, "end_pos": 93, "type": "TASK", "confidence": 0.9336613118648529}]}, {"text": "One example of such an application is generating a summary of the important factors mentioned in the reviews of a product (see).", "labels": [], "entities": []}, {"text": "Another application is comparing two similar products.", "labels": [], "entities": []}, {"text": "In this case, it is important to present to the user the aspects in which the products differ, rather than just provide a general star rating.", "labels": [], "entities": []}, {"text": "A third example is systems for generating automatic recommendations, based on similarity between products, user reviews, and history of previous purchases.", "labels": [], "entities": []}, {"text": "These types of application require an underlying framework to identify the important aspects of the product (also known as features or attributes), and the sentiment expressed by the review writer.", "labels": [], "entities": []}, {"text": "Unsupervised Methods are desirable for this task, for two reasons.", "labels": [], "entities": []}, {"text": "First, due to the wide range and variety of products and services being reviewed, the framework must be robust and easily transferable between domains.", "labels": [], "entities": []}, {"text": "The second reason is the nature of the data.", "labels": [], "entities": []}, {"text": "Online reviews are often short and unstructured, and may contain many spelling and grammatical errors, as well as slang or specialized jargon.", "labels": [], "entities": []}, {"text": "These factors often present a problem to methods relying exclusively on dictionaries, manuallyconstructed knowledge resources, and gazetteers, as they may miss out on an important aspect of the product or an indicator of sentiment.", "labels": [], "entities": []}, {"text": "Unsupervised methods, on the other hand, are not influenced by the lexical form, and can handle unknown words or word-forms, provided they occur frequently enough.", "labels": [], "entities": []}, {"text": "This insures that any emergent topic that is salient in the data will be addressed by the system.", "labels": [], "entities": []}, {"text": "In this paper, we present an unsupervised system which addresses the core tasks necessary to enable advanced applications to handle review data.", "labels": [], "entities": []}, {"text": "We introduce a local topic model, which works at the sentence level and employs a small number of topics, to automatically infer the aspects.", "labels": [], "entities": []}, {"text": "For sentiment detection, we present a method for automatically deriving an unsupervised seed set of positive and negative adjectives that replaces the manually constructed ones commonly used in the literature.", "labels": [], "entities": [{"text": "sentiment detection", "start_pos": 4, "end_pos": 23, "type": "TASK", "confidence": 0.9817506670951843}]}, {"text": "Our approach is specifically designed to take into account the inter-action between the two tasks.", "labels": [], "entities": []}, {"text": "The rest of the paper is structured as follows.", "labels": [], "entities": []}, {"text": "2 we provide relevant background, and place our method in the context of previous work in the field.", "labels": [], "entities": []}, {"text": "We describe the data we used in Sec.", "labels": [], "entities": [{"text": "Sec.", "start_pos": 32, "end_pos": 36, "type": "TASK", "confidence": 0.855892688035965}]}, {"text": "3, and our experiments on the aspect and sentiment-polarity components in Sec.", "labels": [], "entities": []}, {"text": "4 and 5, respectively.", "labels": [], "entities": []}, {"text": "6 with a discussion of our results and findings and directions for future research.", "labels": [], "entities": []}], "datasetContent": [{"text": "To determine the quality of our automatically inferred aspects, we compared the output of our system to the sentence-level manual annotation of.", "labels": [], "entities": []}, {"text": "To each sentence in the data, the LDA model assigns a distribution {P(a)} a\u2208A over the set A of inferred aspects.", "labels": [], "entities": []}, {"text": "By defining a threshold ta for each aspect, we can label a sentence as belonging to aspect a if P(a) > ta . By varying the threshold ta we created precision-recall curves for the top three rateable aspects in the restaurant domain, shown in: List of automatically inferred aspects for the netbook dataset, with representative words for each aspect . 3 . Although the data used in Titov and McDonald (2008a) was unavailable for direct comparison, our method exhibits similar behavior and performance (compare, there) on a domain with similar characteristics (abstract aspects which encompass many low frequency words).", "labels": [], "entities": [{"text": "precision-recall", "start_pos": 147, "end_pos": 163, "type": "METRIC", "confidence": 0.9956521391868591}, {"text": "netbook dataset", "start_pos": 289, "end_pos": 304, "type": "DATASET", "confidence": 0.7567710280418396}]}, {"text": "This demonstrates that our local version of LDA with few topics overcomes the issues which confronted the authors of that work (i.e., global topics and many-toone mapping of topics to aspects), without requiring specially designed models or additional information in the form of user-provided aspect-specific ratings (see Sec. 2).", "labels": [], "entities": []}, {"text": "We believe the reason for this stems from the composition of online reviews.", "labels": [], "entities": []}, {"text": "Since many reviews have similar mixtures of local topics (e.g., food, service), standard LDA prefers global topics, which distinguish more strongly between reviews (e.g., cuisine type, restaurant type).", "labels": [], "entities": []}, {"text": "However, when employed at the sentence level, local topics (corresponding to rateable aspects) provide a stronger way to distinguish between individual sentences.", "labels": [], "entities": []}, {"text": "Kendall's tau coefficient (\u03c4 k ) and Kendall's distance (D k ) are commonly used (e.g., Jijkoun and Hofmann 2009) to compare rankings.", "labels": [], "entities": [{"text": "Kendall's tau coefficient (\u03c4 k )", "start_pos": 0, "end_pos": 32, "type": "METRIC", "confidence": 0.7368148751556873}, {"text": "Kendall's distance (D k )", "start_pos": 37, "end_pos": 62, "type": "METRIC", "confidence": 0.8238407926900047}]}, {"text": "These measures look at the number of pairs of ranked items that agree or disagree with the ordering in the gold standard.", "labels": [], "entities": []}, {"text": "The value of \u03c4 k ranges from -1 (perfect disagreement) to 1 (perfect agreement), with 0 indicating an almost random ranking.", "labels": [], "entities": []}, {"text": "The value of D k ranges from 0 (perfect agreement) to 1 (perfect disagreement).", "labels": [], "entities": []}, {"text": "It is important to note that only pairs that are ordered in the gold standard are used in the comparison.", "labels": [], "entities": []}, {"text": "reports Kendall's coefficient (\u03c4 k ) and distance (D k ) values for our method when using our automatically derived seed set (Auto.).", "labels": [], "entities": [{"text": "Kendall's coefficient (\u03c4 k )", "start_pos": 8, "end_pos": 36, "type": "METRIC", "confidence": 0.7939754298755101}, {"text": "distance (D k )", "start_pos": 41, "end_pos": 56, "type": "METRIC", "confidence": 0.9415677547454834}]}, {"text": "For comparison, we ran our procedure using the manually compiled seed set (Manual) of Fahrni and Klenner Food -General: Mexican, French, Eastern, Turkish, European, Tuscan, Mediterranean, American, Cuban, Thai, Peruvian, Spanish, Korean, Vietnamese, Indian, African, Japanese, Italian, Chinese, Asian Mood: Vietnamese, Brazilian, Turkish, Eastern, Caribbean, Cuban, Italian, Spanish, Japanese, European, Mediterranean, Colombian, Mexican, Asian, Indian, Thai, British, American, French, Korean, Chinese, Russian, Moroccan Staff: British, European, Chinese, Indian, American, Spanish, Asian, Italian, French: Polarity ranking of cuisine adjectives (from most positive) for three aspects.", "labels": [], "entities": []}, {"text": "Using the manual seed set obtains results that correspond better to our gold standard.", "labels": [], "entities": []}, {"text": "Our automatic method also achieves good results, and can be used when a manual seed set is not available.", "labels": [], "entities": []}, {"text": "More importantly, correlation with the gold standard may not indicate better suitability to the sentiment detection task in reviews.", "labels": [], "entities": [{"text": "sentiment detection task", "start_pos": 96, "end_pos": 120, "type": "TASK", "confidence": 0.9521072308222452}]}, {"text": "For instance, it is interesting to note that the worst correlation scores were on the Main Dishes and Food -General aspects.", "labels": [], "entities": [{"text": "correlation", "start_pos": 55, "end_pos": 66, "type": "METRIC", "confidence": 0.976214587688446}]}, {"text": "If we compare to, we can see these aspects have the highest percentage of adjectives rated as neutral by the annotators.", "labels": [], "entities": []}, {"text": "However, in many cases, these adjectives actually carry some sentiment in their context.", "labels": [], "entities": []}, {"text": "An example of this are adjectives describing the type of cuisine, which are objective, and therefore usually considered neutral by annotators.", "labels": [], "entities": []}, {"text": "shows the automatic ranking of cuisine type from positive to negative in three aspects.", "labels": [], "entities": []}, {"text": "It is interesting to see that the rankings change according to the aspect, and certain cuisines are strongly associated with specific aspects and not with others.", "labels": [], "entities": []}, {"text": "This is supported by, who observed during the annotation that, in the restaurant corpus, French and Italian restaurants were strongly associated with the service aspect.", "labels": [], "entities": []}, {"text": "This trend can be identified automatically by our method, and at a much more detailed level than that noticed by a human analyzing the data.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 3: For each aspect, the number of frequently oc- curring adjectives for each aspect (# Adj.), number of  adjectives remaining after removing those labeled 'N/A'  (# Rated), and percent of rated adjectives labeled 'Neu- tral' by both annotators (% Neu.).", "labels": [], "entities": []}, {"text": " Table 4: Kendall coefficient and distance scores for eight  inferred aspects.", "labels": [], "entities": [{"text": "Kendall coefficient", "start_pos": 10, "end_pos": 29, "type": "METRIC", "confidence": 0.9369284212589264}, {"text": "distance scores", "start_pos": 34, "end_pos": 49, "type": "METRIC", "confidence": 0.9697757959365845}]}]}