{"title": [{"text": "Integer Linear Programming in NLP -Constrained Conditional Models", "labels": [], "entities": []}], "abstractContent": [{"text": "Making decisions in natural language processing problems often involves assigning values to sets of interdependent variables where the expressive dependency structure can influence, or even dictate, what assignments are possible.", "labels": [], "entities": []}, {"text": "Structured learning problems such as semantic role labeling provide one such example, but the setting is broader and includes a range of problems such as name entity and relation recognition and co-reference resolution.", "labels": [], "entities": [{"text": "semantic role labeling", "start_pos": 37, "end_pos": 59, "type": "TASK", "confidence": 0.6056737701098124}, {"text": "name entity and relation recognition", "start_pos": 154, "end_pos": 190, "type": "TASK", "confidence": 0.6011127054691314}, {"text": "co-reference resolution", "start_pos": 195, "end_pos": 218, "type": "TASK", "confidence": 0.7351594716310501}]}, {"text": "The setting is also appropriate for cases that may require a solution to make use of multiple (possible pre-designed or pre-learned components) as in summarization, textual entailment and question answering.", "labels": [], "entities": [{"text": "summarization", "start_pos": 150, "end_pos": 163, "type": "TASK", "confidence": 0.986634373664856}, {"text": "textual entailment", "start_pos": 165, "end_pos": 183, "type": "TASK", "confidence": 0.7035619765520096}, {"text": "question answering", "start_pos": 188, "end_pos": 206, "type": "TASK", "confidence": 0.8951968252658844}]}, {"text": "In all these cases, it is natural to formulate the decision problem as a constrained optimization problem, with an objective function that is composed of learned models, subject to domain or problem specific constraints.", "labels": [], "entities": []}, {"text": "Constrained Conditional Models (aka Integer Linear Programming formulation of NLP problems) is a learning and inference framework that augments the learning of conditional (probabilistic or discriminative) models with declarative constraints (written, for example, using a first-order representation) as away to support decisions in an expressive output space while maintaining modularity and tractability of training and inference.", "labels": [], "entities": []}, {"text": "In most applications of this framework in NLP, following [Roth & Yih, CoNLL\u02bc04], Integer Linear Programming (ILP) was used as the inference framework, although other algorithms can be used for that purpose.", "labels": [], "entities": []}, {"text": "This framework, with and without Integer Linear Programming as its inference engine, has recently attracted much attention within the NLP community, with multiple papers in all the recent major conferences, and a related workshop in NAACL\u02bc09.", "labels": [], "entities": [{"text": "NAACL\u02bc09", "start_pos": 233, "end_pos": 241, "type": "DATASET", "confidence": 0.9552751183509827}]}, {"text": "Formulating problems as constrained optimization problems over the output of learned models has several advantages.", "labels": [], "entities": []}, {"text": "It allows one to focus on the modeling of problems by providing the opportunity to incorporate problem specific global constraints using a first order language-thus frees the developer from (much of the) low level feature engineering-and it guarantees exact inference.", "labels": [], "entities": []}, {"text": "It provides also the freedom of decoupling the stage of model generation (learning) from that of the constrained inference stage, often resulting in simplifying the learning stage as well as the engineering problem of building an NLP system, while improving the quality of the solutions.", "labels": [], "entities": []}, {"text": "These advantages and the availability of off-the-shelf solvers have led to a large variety of natural language processing tasks being formulated within framework, including semantic role labeling, syntactic parsing, coreference resolution, summarization, transliteration and joint information extraction.", "labels": [], "entities": [{"text": "semantic role labeling", "start_pos": 173, "end_pos": 195, "type": "TASK", "confidence": 0.6499650577704111}, {"text": "syntactic parsing", "start_pos": 197, "end_pos": 214, "type": "TASK", "confidence": 0.7264252156019211}, {"text": "coreference resolution", "start_pos": 216, "end_pos": 238, "type": "TASK", "confidence": 0.934799075126648}, {"text": "summarization", "start_pos": 240, "end_pos": 253, "type": "TASK", "confidence": 0.9886839985847473}, {"text": "joint information extraction", "start_pos": 275, "end_pos": 303, "type": "TASK", "confidence": 0.6026394267876943}]}, {"text": "The goal of this tutorial is to introduce the framework of Constrained Conditional Models (CCMs) to the broader ACL community, motivate it as a generic framework for learning and inference in global NLP decision problems, present some of the key theoretical and 9", "labels": [], "entities": []}], "introductionContent": [], "datasetContent": [], "tableCaptions": []}