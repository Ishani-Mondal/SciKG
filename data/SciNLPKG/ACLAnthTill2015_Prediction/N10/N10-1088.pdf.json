{"title": [{"text": "Extracting Glosses to Disambiguate Word Senses", "labels": [], "entities": [{"text": "Extracting Glosses to Disambiguate Word Senses", "start_pos": 0, "end_pos": 46, "type": "TASK", "confidence": 0.7027873198191324}]}], "abstractContent": [{"text": "Like most natural language disambiguation tasks, word sense disambiguation (WSD) requires world knowledge for accurate predictions.", "labels": [], "entities": [{"text": "natural language disambiguation tasks", "start_pos": 10, "end_pos": 47, "type": "TASK", "confidence": 0.8215908408164978}, {"text": "word sense disambiguation (WSD)", "start_pos": 49, "end_pos": 80, "type": "TASK", "confidence": 0.8208566606044769}]}, {"text": "Several proxies for this knowledge have been investigated, including labeled corpora , user-contributed knowledge, and machine readable dictionaries, but each of these proxies requires significant manual effort to create, and they do not coverall of the ambiguous terms in a language.", "labels": [], "entities": []}, {"text": "We investigate the task of automatically extracting world knowledge , in the form of glosses, from an unlabeled corpus.", "labels": [], "entities": []}, {"text": "We demonstrate how to use these glosses to automatically label a training corpus to build a statistical WSD system that uses no manually-labeled data, with experimental results approaching that of a supervised SVM-based classifier.", "labels": [], "entities": []}], "introductionContent": [{"text": "For many semantic natural language processing tasks, systems require world knowledge to disambiguate language utterances.", "labels": [], "entities": [{"text": "semantic natural language processing tasks", "start_pos": 9, "end_pos": 51, "type": "TASK", "confidence": 0.7069331526756286}]}, {"text": "Word sense disambiguation (WSD) is no exception -systems for WSD require world knowledge to figure out which aspects of a word's context indicate one sense over another.", "labels": [], "entities": [{"text": "Word sense disambiguation (WSD)", "start_pos": 0, "end_pos": 31, "type": "TASK", "confidence": 0.8169927249352137}]}, {"text": "A fundamental problem for WSD is that the required knowledge is open-ended.", "labels": [], "entities": [{"text": "WSD", "start_pos": 26, "end_pos": 29, "type": "TASK", "confidence": 0.9833108186721802}]}, {"text": "That is, for every ambiguous term, new kinds of information about the world become important, and the knowledge that a system may have acquired for previously-studied ambiguous terms may have little or no impact on the next ambiguous term.", "labels": [], "entities": []}, {"text": "Thus open-ended knowledge acquisition is a fundamental obstacle to strong performance for this disambiguation task.", "labels": [], "entities": [{"text": "open-ended knowledge acquisition", "start_pos": 5, "end_pos": 37, "type": "TASK", "confidence": 0.6364408433437347}]}, {"text": "Researchers have investigated a variety of techniques that address this knowledge acquisition bottleneck in different ways.", "labels": [], "entities": [{"text": "knowledge acquisition bottleneck", "start_pos": 72, "end_pos": 104, "type": "TASK", "confidence": 0.8119105497996012}]}, {"text": "Supervised WSD techniques, for instance, can learn to associate features in the context of a word with a particular sense of that word.", "labels": [], "entities": [{"text": "WSD", "start_pos": 11, "end_pos": 14, "type": "TASK", "confidence": 0.9630799889564514}]}, {"text": "Knowledge-based techniques rely on machine-readable dictionaries or lexical resources like WordNet to provide the necessary knowledge.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 91, "end_pos": 98, "type": "DATASET", "confidence": 0.9675444960594177}]}, {"text": "And most recently, systems have used resources like Wikipedia, which contain user-contributed knowledge in the form of sensedisambiguated links, to acquire world knowledge for WSD.", "labels": [], "entities": [{"text": "WSD", "start_pos": 176, "end_pos": 179, "type": "TASK", "confidence": 0.9534821510314941}]}, {"text": "Yet each of these approaches is limited by the amount of manual effort that is needed to build the necessary resources, and as a result the techniques are limited to a subset of English words for which the manually-constructed resources are available.", "labels": [], "entities": []}, {"text": "In this work we investigate an alternative approach that attacks the problem of knowledge acquisition head-on.", "labels": [], "entities": [{"text": "knowledge acquisition", "start_pos": 80, "end_pos": 101, "type": "TASK", "confidence": 0.7992996573448181}]}, {"text": "We use information extraction (IE) techniques to extract glosses, or short textual characterizations of the meaning of one sense of a word.", "labels": [], "entities": [{"text": "information extraction (IE)", "start_pos": 7, "end_pos": 34, "type": "TASK", "confidence": 0.8627049207687378}]}, {"text": "In the ideal case, we would extract full logical forms to define word senses, but here we instead focus on a more feasible, but still very useful, sub-task: fora given word sense, extract a collection of terms that are highly correlated with that sense and no other sense of the ambiguous word.", "labels": [], "entities": []}, {"text": "Our system requires as input only an unlabeled corpus of documents that each contain the ambiguous term of interest.", "labels": [], "entities": []}, {"text": "In experiments, we demonstrate that our gloss extraction system can often determine key aspects of a word's senses.", "labels": [], "entities": [{"text": "gloss extraction", "start_pos": 40, "end_pos": 56, "type": "TASK", "confidence": 0.6711530089378357}]}, {"text": "In one experiment our system was able to extract glosses with 60% precision for 20 ambiguous biomedical terms, while discovering 7 senses of those terms that never appeared in a widely-used dictionary of biomedical terminology.", "labels": [], "entities": [{"text": "precision", "start_pos": 66, "end_pos": 75, "type": "METRIC", "confidence": 0.9980624318122864}]}, {"text": "In addition, we demonstrate that our extracted glosses are useful for real WSD problems: our sys-tem outperforms a state-of-the-art unsupervised system, and it comes close to the performance of a supervised WSD system on a challenging dataset.", "labels": [], "entities": [{"text": "WSD", "start_pos": 75, "end_pos": 78, "type": "TASK", "confidence": 0.9782870411872864}]}, {"text": "In the next section, we describe previous work.", "labels": [], "entities": []}, {"text": "In Section 3, we formally define the gloss extraction task and refine it into a sub-task that is feasible for an IE approach, and Section 5 presents our technique for using extracted glosses in a WSD task.", "labels": [], "entities": [{"text": "gloss extraction task", "start_pos": 37, "end_pos": 58, "type": "TASK", "confidence": 0.793751855691274}, {"text": "IE", "start_pos": 113, "end_pos": 115, "type": "TASK", "confidence": 0.9200208783149719}, {"text": "WSD task", "start_pos": 196, "end_pos": 204, "type": "TASK", "confidence": 0.9096923768520355}]}, {"text": "Section 6 discusses our experiments and results.", "labels": [], "entities": []}], "datasetContent": [{"text": "We ran two types of experiments, one to measure the accuracy of our sense gloss extractor, and one to measure the usefulness of the extracted knowledge for word sense disambiguation.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 52, "end_pos": 60, "type": "METRIC", "confidence": 0.99928879737854}, {"text": "word sense disambiguation", "start_pos": 156, "end_pos": 181, "type": "TASK", "confidence": 0.7533583641052246}]}], "tableCaptions": [{"text": " Table 1: GLOSSY's extracted glosses and UMLS dictionary entries for the example term \"mole\".", "labels": [], "entities": []}, {"text": " Table 2: GLOSSY can automatically discover glosses that match definitions in an online dictionary. \"Without  Discovered Senses\" counts only the senses that are listed in the UMLS Metathesaurus; \"With Discovered Senses\"  enhances the Metathesaurus with 7 new senses that GLOSSY has automatically discovered.", "labels": [], "entities": [{"text": "UMLS Metathesaurus", "start_pos": 175, "end_pos": 193, "type": "DATASET", "confidence": 0.9484212696552277}, {"text": "GLOSSY", "start_pos": 271, "end_pos": 277, "type": "DATASET", "confidence": 0.8640352487564087}]}, {"text": " Table 3: GLOSSY's extracted glosses can be used to create an unsupervised WSD system that achieves an accu- racy within 3% of a supervised system. Our WSD system outperforms our BASELINE system, widely recognized  as a difficult baseline for unsupervised WSD, by 16.9% and 3.3% on two different datasets.", "labels": [], "entities": [{"text": "accu- racy", "start_pos": 103, "end_pos": 113, "type": "METRIC", "confidence": 0.9298639496167501}, {"text": "BASELINE", "start_pos": 179, "end_pos": 187, "type": "METRIC", "confidence": 0.7889958620071411}]}]}