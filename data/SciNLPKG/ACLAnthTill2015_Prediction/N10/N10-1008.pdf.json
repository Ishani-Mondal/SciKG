{"title": [{"text": "Dialogue-Oriented Review Summary Generation for Spoken Dialogue Recommendation Systems", "labels": [], "entities": [{"text": "Spoken Dialogue Recommendation", "start_pos": 48, "end_pos": 78, "type": "TASK", "confidence": 0.7753224571545919}]}], "abstractContent": [{"text": "In this paper we present an opinion summari-zation technique in spoken dialogue systems.", "labels": [], "entities": []}, {"text": "Opinion mining has been well studied for years, but very few have considered its application in spoken dialogue systems.", "labels": [], "entities": [{"text": "Opinion mining", "start_pos": 0, "end_pos": 14, "type": "TASK", "confidence": 0.8842156529426575}]}, {"text": "Review summarization, when applied to real dialogue systems, is much more complicated than pure text-based summarization.", "labels": [], "entities": [{"text": "Review summarization", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.7057638168334961}]}, {"text": "We conduct a systematic study on dialogue-system-oriented review analysis and propose a three-level framework fora recommendation dialogue system.", "labels": [], "entities": [{"text": "dialogue-system-oriented review analysis", "start_pos": 33, "end_pos": 73, "type": "TASK", "confidence": 0.6431724031766256}]}, {"text": "In previous work we have explored a linguistic parsing approach to phrase extraction from reviews.", "labels": [], "entities": [{"text": "linguistic parsing", "start_pos": 36, "end_pos": 54, "type": "TASK", "confidence": 0.7516116201877594}, {"text": "phrase extraction from reviews", "start_pos": 67, "end_pos": 97, "type": "TASK", "confidence": 0.8754810839891434}]}, {"text": "In this paper we will describe an approach using statistical models such as decision trees and SVMs to select the most representative phrases from the extracted phrase set.", "labels": [], "entities": []}, {"text": "We will also explain how to generate informative yet concise review summaries for dialogue purposes.", "labels": [], "entities": []}, {"text": "Experimental results in the restaurant domain show that the proposed approach using decision tree algorithms achieves an outperformance of 13% compared to SVM models and an improvement of 36% over a heuristic rule baseline.", "labels": [], "entities": []}, {"text": "Experiments also show that the decision-tree-based phrase selection model can achieve rather reliable predictions on the phrase label, comparable to human judgment.", "labels": [], "entities": [{"text": "phrase selection", "start_pos": 51, "end_pos": 67, "type": "TASK", "confidence": 0.7457287013530731}]}, {"text": "The proposed statistical approach is based on domain independent learning features and can be extended to other domains effectively.", "labels": [], "entities": []}], "introductionContent": [{"text": "Spoken dialogue systems are presently available for many purposes, such as weather inquiry (), bus schedules and route guidance, customer service (, and train timetable inquiry.", "labels": [], "entities": [{"text": "bus schedules and route guidance", "start_pos": 95, "end_pos": 127, "type": "TASK", "confidence": 0.6427217960357666}, {"text": "train timetable inquiry", "start_pos": 153, "end_pos": 176, "type": "TASK", "confidence": 0.6003359655539194}]}, {"text": "These systems have been well developed for laboratory research, and some have become commercially viable.", "labels": [], "entities": []}, {"text": "The next generation of intelligent dialogue systems is expected to go beyond factoid question answering and straightforward task fulfillment, by providing active assistance and subjective recommendations, thus behaving more like human agents.", "labels": [], "entities": [{"text": "factoid question answering", "start_pos": 77, "end_pos": 103, "type": "TASK", "confidence": 0.6962023576100668}]}, {"text": "For example, an intelligent dialogue system may suggest which airline is a better choice, considering cost, flight duration, take-off time, available seats, etc.; or suggest which digital camera is the most popular among teenagers or highest rated by professional photographers; or which restaurant is a perfect spot fora semi-formal business meeting or a romantic date.", "labels": [], "entities": []}, {"text": "Luckily, there are enormous amounts of reviews published by general users on the web everyday.", "labels": [], "entities": []}, {"text": "These are perfect resources for providing subjective recommendations and collective opinions.", "labels": [], "entities": []}, {"text": "If there exists a systematic framework that harvests these reviews from general users, extracts the essence from the reviews and presents it appropriately in human-computer conversations, then we can enable dialogue systems to behave like a human shopping assistant, a travel agent, or a local friend who tells you whereto find the best restaurant.", "labels": [], "entities": []}, {"text": "Summarization from online reviews, therefore, plays an important role for such dialogue systems.", "labels": [], "entities": []}, {"text": "There have been previous studies on review analysis for text-based summarization systems (.", "labels": [], "entities": [{"text": "summarization", "start_pos": 67, "end_pos": 80, "type": "TASK", "confidence": 0.7861580848693848}]}, {"text": "Mixture models and topic models are used to predict the underlying topics of each document and generate a phrase-level summary.", "labels": [], "entities": []}, {"text": "An aspect rating on each facet is also automatically learned with statistical models).", "labels": [], "entities": []}, {"text": "These approaches are all very effective, and the review databases generated are well presented.", "labels": [], "entities": []}, {"text": "So the first thought for developing a recommendation dialogue system is to use such a categorized summary in a table-lookup fashion.", "labels": [], "entities": []}, {"text": "For example, a dialogue system for restaurant recommendations can lookup a summary table as exemplified in, and generate a response utterance from each row: \"Restaurant A has good service and bad food; restaurant B has good service and good food; restaurant C has great service and nice atmosphere; restaurant D has poor service and reasonable price.\"", "labels": [], "entities": []}, {"text": "Such a dialogue system is, however, not very informative.", "labels": [], "entities": []}, {"text": "First of all, there is too much redundancy.", "labels": [], "entities": []}, {"text": "Long utterances repeated in the same pattern on the same topic are quite boring, and the information density is very low.", "labels": [], "entities": []}, {"text": "Second, such a summary is too coarse-grained to be helpful.", "labels": [], "entities": []}, {"text": "A user querying a restaurant recommendation system expects more fine-grained information such as house specials, wine selections and choices on desserts rather than just general 'good food.'", "labels": [], "entities": []}, {"text": "In contrast to a 'text' summarization system, the textual space in a dialogue turn is often very limited.", "labels": [], "entities": []}, {"text": "Speech is inherently serial, and it cannot be skipped and scanned easily.", "labels": [], "entities": []}, {"text": "A dialogue system which speaks long diatribes in each single conversation turn would likely not be well received.", "labels": [], "entities": []}, {"text": "We believe that the best unit of review summary for dialogue purposes is short succinct phrases (e.g., 'amazing sauce' and 'romantic ambiance') which are catalogued into categories to answer high-level questions such as \"How is the food at this restaurant?\" or \"What about the atmosphere?\"", "labels": [], "entities": []}, {"text": "Also, domain-specific phrases are greatly needed to generate correct answers to specific queries, such as \"Which restaurants have fresh sushi?\" and \"Show me restaurants that serve fantastic cocktails.\"", "labels": [], "entities": []}, {"text": "Thus, the generally used correlated topic models, although very effective in text-based systems, are not quite suitable for interactive dialogue systems.", "labels": [], "entities": []}, {"text": "The missing piece is an HCI-oriented (human computer interaction), fine-grained, informative yet concise review summarization.", "labels": [], "entities": []}, {"text": "A good recommendation system should be able to provide sufficient yet specific information to help users choose a restaurant, a movie or a consumer product.", "labels": [], "entities": []}, {"text": "shows an example of a conversation with a good recommendation system, which 1) provides a generalized yet high-density review summary in human-friendly dialogue; 2) provides both a coarse-grained summary (e.g., 'authentic food') and fine-grained information such as house specialties.", "labels": [], "entities": []}, {"text": "Example of a conversation with a good recommendation dialogue system ('U' denotes the user and 'S' denotes the dialogue system.", "labels": [], "entities": []}, {"text": "The responses to the user queries are produced by our system and the actual dialogue was an illustration of system capacities).", "labels": [], "entities": []}, {"text": "Therefore, the task of developing recommendation dialogue systems is decomposed into three problems: 1) how to extract context-related phrases, both coarse-grained and fine-grained, from online reviews; 2) how to select a representative set from the extracted phrases to create an informative yet concise dialogue-oriented summary database; 3) how to generate human-friendly dialogue responses from the review summary database.", "labels": [], "entities": []}, {"text": "To tackle these problems, we propose a threelevel framework.", "labels": [], "entities": []}, {"text": "In previous work (), we explored the first level by proposing a linguistic parse-and-paraphrase paradigm for re-view phrase extraction.", "labels": [], "entities": [{"text": "re-view phrase extraction", "start_pos": 109, "end_pos": 134, "type": "TASK", "confidence": 0.6735572020212809}]}, {"text": "In this paper, we address the second problem: dialogue-oriented review summary generation.", "labels": [], "entities": [{"text": "dialogue-oriented review summary generation", "start_pos": 46, "end_pos": 89, "type": "TASK", "confidence": 0.6629932895302773}]}, {"text": "We propose an automatic approach to classifying high/low informative phrases using statistical models.", "labels": [], "entities": [{"text": "classifying high/low informative phrases", "start_pos": 36, "end_pos": 76, "type": "TASK", "confidence": 0.8132484058539072}]}, {"text": "Experiments conducted on a restaurant-domain dataset indicate that the proposed approach can predict phrase labels consistently with human judgment and can generate high-quality review summaries for dialogue purposes.", "labels": [], "entities": []}, {"text": "The rest of the paper is organized as follows: Section 2 gives an overview of the three-level framework for recommendation dialogue systems.", "labels": [], "entities": []}, {"text": "In Section 3, we explain the proposed approach to dialogue-oriented review summary generation.", "labels": [], "entities": [{"text": "dialogue-oriented review summary generation", "start_pos": 50, "end_pos": 93, "type": "TASK", "confidence": 0.6164195314049721}]}, {"text": "Section 4 provides a systematic evaluation of the proposed approach, and Section 5 gives a further discussion on the experimental results.", "labels": [], "entities": []}, {"text": "Section 6 summarizes the paper as well as pointing to future work.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this project, we substantiate the proposed approach in a restaurant domain for our spoken dialogue system, which is a web-based multimodal dialogue system allowing users to inquire about information about restaurants, museums, subways, etc.", "labels": [], "entities": []}, {"text": "We harvested a data collection of 137,569 reviews on 24,043 restaurants in 9 cities in the U.S. from an online restaurant evaluation website . From the dataset, 857,466 sentences were subjected to parse analysis; and a total of 434,372 phrases (114,369 unique ones) were extracted from the parsable subset (78.6%) of the sentences.", "labels": [], "entities": []}, {"text": "Most pros/cons consist of well-formatted phrases; thus, we select 3,000 phrases extracted from pros/cons as training data.", "labels": [], "entities": []}, {"text": "To generate a human judgment-consistent training set, we manually label the training samples with 'good' and 'bad' labels.", "labels": [], "entities": []}, {"text": "We then randomly select a subset of 3,000 phrases extracted from review texts as the test set and label the phrases.", "labels": [], "entities": []}, {"text": "The kappa agreement between two sets of annotations is 0.73, indicating substantial consistency.", "labels": [], "entities": [{"text": "consistency", "start_pos": 84, "end_pos": 95, "type": "METRIC", "confidence": 0.975636899471283}]}, {"text": "We use the two annotation sets as the ground truth.", "labels": [], "entities": []}, {"text": "To extract context-related semantic features, we collect a large pool of well-formatted menus from an online resource 2 , which contains 16,141 restaurant menus.", "labels": [], "entities": []}, {"text": "Based on the hierarchical structure of these collected menus, we buildup a contextrelated ontology and extract a set of semantic features from the ontology, such as whether the topic of a phrase is on category-level (e.g., 'entr\u00e9e', 'dessert', 'appetizers', 'salad'), whether the topic is on course-level (e.g., 'Roasted Pork Loin', 'Spicy Halibut and Clam Roast'), and whether the topic is on ingredient-level (e.g., 'beans', 'chicken', 'mushrooms', 'scallop').", "labels": [], "entities": []}, {"text": "We employ the three types of features as aforementioned to train the SVMs and the decision tree models.", "labels": [], "entities": []}, {"text": "To select the most valuable features for model training, we conducted a set of leave-onefeature-out experiments for both the SVMs and the decision tree models.", "labels": [], "entities": []}, {"text": "We found that all the features except the adjective unigram probability contribute positively to model learning.", "labels": [], "entities": []}, {"text": "From further data analysis we observed that many phrases with popular adjectives have context-unrelated nouns, which makes the adjective unigram probability fail to become a dominant factor for phrase relevance.", "labels": [], "entities": [{"text": "phrase relevance", "start_pos": 194, "end_pos": 210, "type": "TASK", "confidence": 0.7510811984539032}]}, {"text": "Using the adjective unigram probability as a learning feature will mislead the system into trusting an adjective that is common but has a poor bigram affinity to the noun in the phrase.", "labels": [], "entities": []}, {"text": "Thus, we eliminate this feature for both the SVMs and the decision tree learning.", "labels": [], "entities": []}, {"text": "To evaluate the performance of the classification models, we take a set of intuitively motivated heuristic rules as the baseline.", "labels": [], "entities": []}, {"text": "gives the pseudo-code of the heuristic rule algorithm, which uses variations of all the features except the unigram probability of adjectives..", "labels": [], "entities": []}, {"text": "Although the heuristic rule algorithm is complicated and involves human knowledge, the statistical models trained by SVMs and the decision tree algorithms both outperform the baseline significantly.", "labels": [], "entities": []}, {"text": "The SVM model outperforms the baseline by 10.5% and 11.9% on the two annotation sets respectively.", "labels": [], "entities": []}, {"text": "The decision tree model outperforms the baseline by 16.4% and 23.2% (average relative improvement of 36%), and it also outperforms the SVM model by 5.9% and 11.3% (average relative improvement of 13%).", "labels": [], "entities": []}, {"text": "The classification model using the decision tree algorithm can achieve a precision of 77.9% and 74.5% compared with the ground truth, which is quite comparable to human judgment (the precision of one annotation set based on the other is 74%).", "labels": [], "entities": [{"text": "precision", "start_pos": 73, "end_pos": 82, "type": "METRIC", "confidence": 0.9993563294410706}, {"text": "precision", "start_pos": 183, "end_pos": 192, "type": "METRIC", "confidence": 0.9933331608772278}]}, {"text": "This shows that the decision tree model can predict phrase labels as reliably as human judgment..", "labels": [], "entities": []}, {"text": "Precision of phrase classification using the heuristic rule baseline, the SVM model, and the decision tree algorithm.", "labels": [], "entities": [{"text": "phrase classification", "start_pos": 13, "end_pos": 34, "type": "TASK", "confidence": 0.7572973966598511}]}, {"text": "To gain further insight on the contributions of each feature set to the decision tree learning, gives the experimental results on leaving each feature out of model training.", "labels": [], "entities": [{"text": "decision tree learning", "start_pos": 72, "end_pos": 94, "type": "TASK", "confidence": 0.7882701555887858}]}, {"text": "As shown, without semantic features, the precision is 70.6% and 65.4% on the two annotation sets, lower by 7.3% and 9.1% than the case of training the model with all the features (77.9% and 74.5%).", "labels": [], "entities": [{"text": "precision", "start_pos": 41, "end_pos": 50, "type": "METRIC", "confidence": 0.9997667670249939}]}, {"text": "This shows that the semantic features significantly contribute to the decision tree learning..", "labels": [], "entities": [{"text": "decision tree learning.", "start_pos": 70, "end_pos": 93, "type": "TASK", "confidence": 0.8024481534957886}]}, {"text": "Performance of the decision tree model by leaving each feature out of model training ('A1' and 'A2' represent the annotation set 1 and 2 respectively).", "labels": [], "entities": []}, {"text": "The experimental results also show that the feature of bigram probability of the adjective-noun pair contributes the most to the model learning.", "labels": [], "entities": []}, {"text": "Without this feature, the precision drops by 21.3% and 10.6%, reaching the lowest precision among all the leave-one-out experiments.", "labels": [], "entities": [{"text": "precision", "start_pos": 26, "end_pos": 35, "type": "METRIC", "confidence": 0.999572217464447}, {"text": "precision", "start_pos": 82, "end_pos": 91, "type": "METRIC", "confidence": 0.9977256655693054}]}, {"text": "This confirms our observation that although a single adjective is not dominant, the pair of the adjective and the noun that co-occurs with it plays an important role in the classification.", "labels": [], "entities": []}, {"text": "The sentiment of phrases also plays an important role.", "labels": [], "entities": []}, {"text": "Without sentiment features, the precision drops to 63.4% and 66.6% respectively on the two annotations, decreasing by 14.5% and 7.9%.", "labels": [], "entities": [{"text": "precision", "start_pos": 32, "end_pos": 41, "type": "METRIC", "confidence": 0.9997122883796692}]}, {"text": "This shows that the sentiment features contribute significantly to the classification.", "labels": [], "entities": [{"text": "classification", "start_pos": 71, "end_pos": 85, "type": "TASK", "confidence": 0.972102165222168}]}], "tableCaptions": [{"text": " Table 4. Precision of phrase classification using the  heuristic rule baseline, the SVM model, and the deci- sion tree algorithm.", "labels": [], "entities": [{"text": "Precision of phrase classification", "start_pos": 10, "end_pos": 44, "type": "TASK", "confidence": 0.7064173221588135}]}, {"text": " Table 5. Performance of the decision tree model by  leaving each feature out of model training ('A1' and  'A2' represent the annotation set 1 and 2 respectively).", "labels": [], "entities": []}]}