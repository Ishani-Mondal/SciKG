{"title": [{"text": "Is Arabic Part of Speech Tagging Feasible Without Word Segmentation?", "labels": [], "entities": [{"text": "Speech Tagging Feasible", "start_pos": 18, "end_pos": 41, "type": "TASK", "confidence": 0.7800867259502411}, {"text": "Word Segmentation", "start_pos": 50, "end_pos": 67, "type": "TASK", "confidence": 0.6865329146385193}]}], "abstractContent": [{"text": "In this paper, we compare two novel methods for part of speech tagging of Arabic without the use of gold standard word segmentation but with the full POS tagset of the Penn Ara-bic Treebank.", "labels": [], "entities": [{"text": "speech tagging of Arabic", "start_pos": 56, "end_pos": 80, "type": "TASK", "confidence": 0.7841822728514671}, {"text": "Penn Ara-bic Treebank", "start_pos": 168, "end_pos": 189, "type": "DATASET", "confidence": 0.9794580737749735}]}, {"text": "The first approach uses complex tags without any word segmentation, the second approach is segmention-based, using a machine learning segmenter.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 49, "end_pos": 66, "type": "TASK", "confidence": 0.7302294820547104}]}, {"text": "Surprisingly, word-based POS tagging yields the best results , with a word accuracy of 94.74%.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 25, "end_pos": 36, "type": "TASK", "confidence": 0.7612082660198212}, {"text": "accuracy", "start_pos": 75, "end_pos": 83, "type": "METRIC", "confidence": 0.8692807555198669}]}], "introductionContent": [{"text": "Arabic is a morphologically rich language, in which a word carries not only inflections but also clitics, such as pronouns, conjunctions, and prepositions.", "labels": [], "entities": []}, {"text": "This morphological complexity also has consequences for the part-of-speech (POS) annotation of Arabic: Since words can be complex, POS tags refer to segments rather than to whole words.", "labels": [], "entities": []}, {"text": "Thus, the word wsyrfEwnhA (in Buckwalter transliteration; engl.: and they will raise it) is assigned the following POS tag: [CONJ+FUTURE PARTICLE+IMPERFECT VERB PREFIX +IMPERFECT VERB+IMPERFECT VERB SUFFIX MAS-CULINE PLURAL 3RD PERSON+OBJECT PRONOUN in the Penn Arabic Treebank (ATB); the boundaries between segments are depicted by + signs.", "labels": [], "entities": [{"text": "Buckwalter", "start_pos": 30, "end_pos": 40, "type": "DATASET", "confidence": 0.940484344959259}, {"text": "POS tag", "start_pos": 115, "end_pos": 122, "type": "METRIC", "confidence": 0.9599220454692841}, {"text": "CONJ", "start_pos": 125, "end_pos": 129, "type": "METRIC", "confidence": 0.874290943145752}, {"text": "FUTURE PARTICLE", "start_pos": 130, "end_pos": 145, "type": "METRIC", "confidence": 0.7760728597640991}, {"text": "MAS-CULINE PLURAL 3RD PERSON", "start_pos": 206, "end_pos": 234, "type": "METRIC", "confidence": 0.7770132422447205}, {"text": "OBJECT", "start_pos": 235, "end_pos": 241, "type": "METRIC", "confidence": 0.8922182321548462}, {"text": "Penn Arabic Treebank (ATB)", "start_pos": 257, "end_pos": 283, "type": "DATASET", "confidence": 0.9761640032132467}]}, {"text": "Automatic approaches to POS tagging either must assign such complex tags from a large tagset to complete words, or they must segment the word first and then assign POS tags to the segments.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 24, "end_pos": 35, "type": "TASK", "confidence": 0.9304393827915192}]}, {"text": "Previous approaches () chose the segmentation approach but concentrated on POS tagging by using the segmentation provided by the ATB.", "labels": [], "entities": [{"text": "segmentation", "start_pos": 33, "end_pos": 45, "type": "TASK", "confidence": 0.9804461598396301}, {"text": "POS tagging", "start_pos": 75, "end_pos": 86, "type": "TASK", "confidence": 0.8316315412521362}, {"text": "ATB", "start_pos": 129, "end_pos": 132, "type": "DATASET", "confidence": 0.9650981426239014}]}, {"text": "Additionally, Habash and Rambow used a reduced tagset.", "labels": [], "entities": [{"text": "Rambow", "start_pos": 25, "end_pos": 31, "type": "DATASET", "confidence": 0.9347609877586365}]}, {"text": "Machines, the former with a standard windowing approach, the latter performing a full morphological analysis before POS tagging.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 116, "end_pos": 127, "type": "TASK", "confidence": 0.6878891885280609}]}, {"text": "Van den Bosch et al., whose approach is the most similar to ours, used memory-based learning with the full ATB tagset.", "labels": [], "entities": []}, {"text": "They report a POS tagging accuracy of 91.5% (93.3% on known words, 66.4% on unknown words).", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 14, "end_pos": 25, "type": "TASK", "confidence": 0.7246694564819336}, {"text": "accuracy", "start_pos": 26, "end_pos": 34, "type": "METRIC", "confidence": 0.9500992894172668}]}, {"text": "However, they also evaluated on words as defined in the ATB, which differs from written Arabic in the treatment of affixes with syntactic functions (see section 2 for details).", "labels": [], "entities": []}, {"text": "AlGahtani et al. used transformation-based learning combined with a morphological analysis for unknown words and words containing clitics.", "labels": [], "entities": []}, {"text": "They reached a POS tagging accuracy of 96.9% on ATB1.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 15, "end_pos": 26, "type": "TASK", "confidence": 0.7458228766918182}, {"text": "accuracy", "start_pos": 27, "end_pos": 35, "type": "METRIC", "confidence": 0.9367971420288086}, {"text": "ATB1", "start_pos": 48, "end_pos": 52, "type": "DATASET", "confidence": 0.987632155418396}]}, {"text": "Surprisingly, their results are lower for the experiment using the whole ATB (96.1%).", "labels": [], "entities": [{"text": "ATB", "start_pos": 73, "end_pos": 76, "type": "DATASET", "confidence": 0.6590447425842285}]}, {"text": "In this paper, we present two methods for Arabic POS tagging that do not require gold standard segmentation but can rather be used for naturally occurring Arabic.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 49, "end_pos": 60, "type": "TASK", "confidence": 0.817537248134613}]}, {"text": "We investigate two different approaches: (1) Assigning complete POS tags to whole words, without any segmentation, and (2) a segmentation-based approach, for which we developed a machine learning based segmenter.", "labels": [], "entities": [{"text": "Assigning complete POS tags to whole words", "start_pos": 45, "end_pos": 87, "type": "TASK", "confidence": 0.869677015713283}]}, {"text": "In this approach, the words are first passed to the segmenter, then to the POS tagger.", "labels": [], "entities": []}, {"text": "The first approach is surprisingly successful given the complex-ity of the task, reaching an accuracy on the word level of 94.74%, as compared to 93.47% for the segmentation-based approach.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 93, "end_pos": 101, "type": "METRIC", "confidence": 0.9995924830436707}]}, {"text": "Thus, the result for the whole word approach is very close to the result obtained by using gold standard segmentation (94.91%).", "labels": [], "entities": []}, {"text": "However, a more detailed analysis shows that this good performance of the word-based approach is due to its performance on known words while the few unknown words are more often misclassified: we reach an accuracy of 96.61% on known words but only 74.64% on unknown words.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 205, "end_pos": 213, "type": "METRIC", "confidence": 0.999160885810852}]}], "datasetContent": [{"text": "Like the previous approaches, we base our experiments on the ATB, specifically on the after-treebank POS files, for extracting our training and test sets.", "labels": [], "entities": [{"text": "ATB", "start_pos": 61, "end_pos": 64, "type": "DATASET", "confidence": 0.9650547504425049}]}, {"text": "More specifically, we use two sections of the ATB (P1V3 and P3V1) since those two sets do not contain duplicate sentences.", "labels": [], "entities": []}, {"text": "This data set contains approximately 500,000 words.", "labels": [], "entities": []}, {"text": "In order to be as representative of real-world Arabic, we use the non-vocalized version of the treebank.", "labels": [], "entities": []}, {"text": "Since previous approaches, to our knowledge, used different data sets, our results are not directly comparable.", "labels": [], "entities": []}, {"text": "For both segmentation and POS tagging, we modified the ATB representation of words in order to obtain the text, as it would occur in newscasts.", "labels": [], "entities": [{"text": "segmentation", "start_pos": 9, "end_pos": 21, "type": "TASK", "confidence": 0.9644920825958252}, {"text": "POS tagging", "start_pos": 26, "end_pos": 37, "type": "TASK", "confidence": 0.8359032273292542}]}, {"text": "The ATB treats inflectional affixes, including the definite article Al, as part of a word but splits off those affixes that serve a syntactic function into separate words.", "labels": [], "entities": []}, {"text": "In order to obtain text as it occurs in newscasts, we re-attached all conjunctions, prepositions, pronouns, and any elements that constitute parts of the word as an orthographic unit (with the exception of punctuation) to the word.", "labels": [], "entities": []}, {"text": "The word ltxbrh (engl.: in order to tell him), for example, is represented as three words in the ATB, l, txbr, and h, but is treated as one single unit in our experiment.", "labels": [], "entities": []}, {"text": "Our second modification concerns the null element in Arabic verbs.", "labels": [], "entities": []}, {"text": "Since Arabic is pro-drop, the ATB annotation includes a null element in place of the omitted subject plus the POS tag it would receive.", "labels": [], "entities": []}, {"text": "Since this information is not available in naturally occurring text, we delete the null element and its tag.", "labels": [], "entities": []}, {"text": "For example, {i$otaraY+(null) and its tag PV+PVSUFF SUBJ: 3MS would occur as {i$otaraY with the tag PV in our representation (we additionally remove the short vowels).", "labels": [], "entities": []}, {"text": "We perform 5-fold cross validation and use the same data split for all three types of experiments: (1) POS tagging using gold standard segmentation taken from the ATB, (2) POS tagging using a segmenter, and (3) POS tagging whole words with complex POS tags.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 103, "end_pos": 114, "type": "TASK", "confidence": 0.7953000068664551}, {"text": "ATB", "start_pos": 163, "end_pos": 166, "type": "DATASET", "confidence": 0.9251145124435425}, {"text": "POS tagging", "start_pos": 172, "end_pos": 183, "type": "TASK", "confidence": 0.8040429055690765}, {"text": "POS tagging whole words", "start_pos": 211, "end_pos": 234, "type": "TASK", "confidence": 0.867786318063736}]}, {"text": "The first experiment serves as the upper bound and as a comparison to previous approaches.", "labels": [], "entities": []}, {"text": "The second experiment uses an automatic segmenter as a pre-processing component to the POS tagger.", "labels": [], "entities": [{"text": "POS tagger", "start_pos": 87, "end_pos": 97, "type": "TASK", "confidence": 0.5922533571720123}]}, {"text": "This means that the accuracy of the segmenter is also the upper limit of the POS tagger since errors in segmentation inevitably lead to errors in POS tagging.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 20, "end_pos": 28, "type": "METRIC", "confidence": 0.9993900060653687}, {"text": "POS tagger", "start_pos": 77, "end_pos": 87, "type": "TASK", "confidence": 0.6497659683227539}, {"text": "POS tagging", "start_pos": 146, "end_pos": 157, "type": "TASK", "confidence": 0.7396306097507477}]}, {"text": "The last experiment uses full words and complex POS tags.", "labels": [], "entities": []}, {"text": "The purpose of this experiment is to determine whether it is possible to tag complete words without segmentation.", "labels": [], "entities": []}, {"text": "The segmenter and the two POS taggers use memory-based learning.", "labels": [], "entities": [{"text": "POS taggers", "start_pos": 26, "end_pos": 37, "type": "TASK", "confidence": 0.627816766500473}]}, {"text": "For segmentation, we use TiMBL (Daelemans and van den); for POS tagging MBT, a memory-based tagger.", "labels": [], "entities": [{"text": "segmentation", "start_pos": 4, "end_pos": 16, "type": "TASK", "confidence": 0.980575442314148}, {"text": "POS tagging MBT", "start_pos": 60, "end_pos": 75, "type": "TASK", "confidence": 0.6652057766914368}]}, {"text": "Memory-based learning is a lazy learning paradigm that does not abstract over the training data.", "labels": [], "entities": []}, {"text": "During classification, the k nearest neighbors to anew example are retrieved from the training data, and the class that was assigned to the majority of the neighbors is assigned to the new example.", "labels": [], "entities": []}, {"text": "MBT uses TiMBL as classifier; it offers the possibility to use words from both sides of the focus word as well as previous tagging decisions and ambitags as features.", "labels": [], "entities": [{"text": "MBT", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.9712896347045898}]}, {"text": "An ambitag is a combination of all POS tags of the ambiguity class of the word.", "labels": [], "entities": []}, {"text": "Word segmentation is defined as a per-letter classification task: If a character in the word constitutes the end of a segment, its class is '+', otherwise '-'.", "labels": [], "entities": [{"text": "Word segmentation", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.7203539162874222}]}, {"text": "We use a sliding window approach with 5 characters before and 5 characters after the focus character, the previous decisions of the classifier, and the POS tag of the focus word assigned by the whole word tagger (cf. below) as features.", "labels": [], "entities": []}, {"text": "The best results were obtained for all experiments with the IB1 algorithm with similarity computed as weighted overlap, relevance weights computed with gain ratio, and the number of k nearest neighbors equal to 1.", "labels": [], "entities": []}, {"text": "For POS tagging, we use the full tagset, with information about every segment in the word, rather than the reduced tagset (RTS) used by  a segmentation of words in which syntactically relevant affixes are split from the stem.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 4, "end_pos": 15, "type": "TASK", "confidence": 0.9281319975852966}]}, {"text": "The word w+y+bHv+wn+hA, for example, in RTS is split into 3 separate tokens, w, ybHvwn, hA.", "labels": [], "entities": [{"text": "RTS", "start_pos": 40, "end_pos": 43, "type": "TASK", "confidence": 0.7320501208305359}]}, {"text": "Then, each of these tokens is assigned one POS tag, Conjunction for w, Imperfective Verb for ybHvwn, and Pronoun for hA.", "labels": [], "entities": [{"text": "Conjunction", "start_pos": 52, "end_pos": 63, "type": "METRIC", "confidence": 0.9776217937469482}, {"text": "Imperfective Verb", "start_pos": 71, "end_pos": 88, "type": "METRIC", "confidence": 0.9416070282459259}, {"text": "Pronoun", "start_pos": 105, "end_pos": 112, "type": "METRIC", "confidence": 0.9782326221466064}]}, {"text": "The split into tokens makes a preprocessing step necessary, and it also affects evaluation since a word-based evaluation is based on one word, the RTS evaluation on 3 tokens for the above example.", "labels": [], "entities": []}, {"text": "For all the POS tagging experiments, we use MBT.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 12, "end_pos": 23, "type": "TASK", "confidence": 0.8565258085727692}, {"text": "MBT", "start_pos": 44, "end_pos": 47, "type": "METRIC", "confidence": 0.5012751817703247}]}, {"text": "The best results were obtained with the Modified Value Difference Metric as a distance metric and with k = 25.", "labels": [], "entities": [{"text": "Modified Value Difference Metric", "start_pos": 40, "end_pos": 72, "type": "TASK", "confidence": 0.5376956313848495}]}, {"text": "For known words, we use the IGTree algorithm and 2 words to the left, their POS tags, the focus word and its ambitag, 1 right context word and its ambitag as features.", "labels": [], "entities": []}, {"text": "For unknown words, we use IB1 as algorithm and the unknown word itself, its first 5 and last 3 characters, 1 left context word and its POS tag, and 1 right context word and its ambitag tag as features.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: POS tagging results.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 10, "end_pos": 21, "type": "TASK", "confidence": 0.7504701018333435}]}]}