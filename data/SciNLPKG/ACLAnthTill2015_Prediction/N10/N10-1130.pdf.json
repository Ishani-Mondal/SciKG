{"title": [{"text": "Why Synchronous Tree Substitution Grammars?", "labels": [], "entities": [{"text": "Synchronous Tree Substitution Grammars", "start_pos": 4, "end_pos": 42, "type": "TASK", "confidence": 0.7702602297067642}]}], "abstractContent": [{"text": "Synchronous tree substitution grammars area translation model that is used in syntax-based machine translation.", "labels": [], "entities": [{"text": "Synchronous tree substitution grammars area translation", "start_pos": 0, "end_pos": 55, "type": "TASK", "confidence": 0.7486330370108286}, {"text": "machine translation", "start_pos": 91, "end_pos": 110, "type": "TASK", "confidence": 0.7177156507968903}]}, {"text": "They are investigated in a formal setting and compared to a competitor that is at least as expressive.", "labels": [], "entities": []}, {"text": "The competitor is the extended multi bottom-up tree transducer , which is the bottom-up analogue with one essential additional feature.", "labels": [], "entities": []}, {"text": "This model has been investigated in theoretical computer science, but seems widely unknown in natural language processing.", "labels": [], "entities": []}, {"text": "The two models are compared with respect to standard algorithms (binarization, regular restriction, composition, application).", "labels": [], "entities": []}, {"text": "Particular attention is paid to the complexity of the algorithms.", "labels": [], "entities": []}], "introductionContent": [{"text": "Every machine translation system uses a translation model, which is a formal model that describes the translation process.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 6, "end_pos": 25, "type": "TASK", "confidence": 0.7045100629329681}]}, {"text": "Either this system is handcrafted (in rule-based translation systems) or it is trained with the help of statistical processes.", "labels": [], "entities": []}, {"text": "discuss automatically trainable translation models in their seminal paper on the latter approach.", "labels": [], "entities": []}, {"text": "The IBM models of are string-based in the sense that they base the translation decision on the words and the surrounding context.", "labels": [], "entities": []}, {"text": "In the field of syntax-based machine translation, the translation models have access to the syntax (in the form of parse trees) of the sentences.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 29, "end_pos": 48, "type": "TASK", "confidence": 0.7417924702167511}]}, {"text": "presents a good exposition to both fields.", "labels": [], "entities": []}, {"text": "In this paper, we focus on syntax-based translation models, and in particular, synchronous tree substitution grammars (STSGs), or the equally powerful (linear and nondeleting) extended (top-down) tree transducers of. gives a good introduction to STSGs, which originate from the syntax-directed translation schemes of [nowadays more commonly known as synchronous context-free grammars].", "labels": [], "entities": [{"text": "synchronous tree substitution grammars (STSGs", "start_pos": 79, "end_pos": 124, "type": "TASK", "confidence": 0.6448057293891907}]}, {"text": "Roughly speaking, an STSG has rules in which a nonterminal is replaced by two trees containing terminal and nonterminal symbols.", "labels": [], "entities": []}, {"text": "In addition, the nonterminals in the two trees are linked and a rule is only applied to linked nonterminals.", "labels": [], "entities": []}, {"text": "Several algorithms for STSGs have been discussed in the literature.", "labels": [], "entities": [{"text": "STSGs", "start_pos": 23, "end_pos": 28, "type": "TASK", "confidence": 0.9835407137870789}]}, {"text": "For example, we can \u2022 train them [see], \u2022 attempt to binarize them using the methods of (), \u2022 parse them [see], or \u2022 attempt to compose them.", "labels": [], "entities": []}, {"text": "However, some important algorithms are partial because it is known that the construction might not be possible in general.", "labels": [], "entities": []}, {"text": "This is the case, for example, for binarization and composition.", "labels": [], "entities": []}, {"text": "In the theoretical computer science community, alternative models have been explored.", "labels": [], "entities": []}, {"text": "Such a model is the multi bottom-up tree transducer (MBOT) of and, which essentially is the bottom-up analogue of STSGs with the additional feature that nonterminals can have an arbitrary rank (the rank of a nonterminal of an STSG can be considered to be fixed to 1).", "labels": [], "entities": []}, {"text": "This model is even more expressive than STSGs, but still offers good computational properties.", "labels": [], "entities": []}, {"text": "In this contribution, we will compare STSGs and MBOTs with respect to some standard algorithms.", "labels": [], "entities": [{"text": "MBOTs", "start_pos": 48, "end_pos": 53, "type": "METRIC", "confidence": 0.6424002051353455}]}, {"text": "Generally, MBOTs offer algorithmic benefits over STSG, which can be summarized as fol-lows: \u2022 Every STSG can be transformed into an equivalent MBOT in linear time.", "labels": [], "entities": []}, {"text": "\u2022 MBOTs can be fully binarized in linear time whereas only partial binarizations (or asynchronous binarizations) are possible for STSGs.", "labels": [], "entities": []}, {"text": "\u2022 The input language of an MBOT M can be regularly restricted in O(|M | \u00b7 |S| 3 ), whereas the corresponding construction for an STSG M is in O(|M | \u00b7 |S| 2 rk(M )+5 ) where rk(M ) is the maximal number of nonterminals in a rule of the STSG M . \u2022 MBOTs can be composed, whereas this cannot be achieved for STSGs.", "labels": [], "entities": []}, {"text": "Overall, we thus conclude that, from an algorithmic perspective, it would be beneficial to work with MBOTs instead of STSGs.", "labels": [], "entities": [{"text": "MBOTs", "start_pos": 101, "end_pos": 106, "type": "DATASET", "confidence": 0.7678307294845581}]}, {"text": "However, the full power of MBOTs should not be tapped because, in general, MBOTs have the finite-copying property [see], which complicates the algorithms for forward and backward application (see Section 7).", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": []}