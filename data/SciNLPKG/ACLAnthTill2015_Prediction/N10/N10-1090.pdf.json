{"title": [{"text": "A Simple Approach for HPSG Supertagging Using Dependency Information", "labels": [], "entities": [{"text": "HPSG Supertagging", "start_pos": 22, "end_pos": 39, "type": "TASK", "confidence": 0.6640423238277435}]}], "abstractContent": [{"text": "Ina supertagging task, sequence labeling models are commonly used.", "labels": [], "entities": [{"text": "sequence labeling", "start_pos": 23, "end_pos": 40, "type": "TASK", "confidence": 0.6234141141176224}]}, {"text": "But their limited ability to model long-distance information presents a bottleneck to make further improvements.", "labels": [], "entities": []}, {"text": "In this paper, we modeled this long-distance information in dependency formalism and integrated it into the process of HPSG supertagging.", "labels": [], "entities": []}, {"text": "The experiments showed that the dependency information is very informative for supertag disambiguation.", "labels": [], "entities": [{"text": "supertag disambiguation", "start_pos": 79, "end_pos": 102, "type": "TASK", "confidence": 0.8962784707546234}]}, {"text": "We also evaluated the improved supertagger in the HPSG parser.", "labels": [], "entities": [{"text": "HPSG parser", "start_pos": 50, "end_pos": 61, "type": "DATASET", "confidence": 0.9167089760303497}]}], "introductionContent": [{"text": "Supertagging is a widely used speed-up technique for lexicalized grammar parsing.", "labels": [], "entities": [{"text": "lexicalized grammar parsing", "start_pos": 53, "end_pos": 80, "type": "TASK", "confidence": 0.6539449195067087}]}, {"text": "It was first proposed for lexicalized tree adjoining grammar (LTAG) (, then extended to combinatory categorial grammar (CCG)) and head-driven phrase structure grammar (HPSG) ().", "labels": [], "entities": [{"text": "phrase structure grammar (HPSG)", "start_pos": 142, "end_pos": 173, "type": "TASK", "confidence": 0.7699768096208572}]}, {"text": "For deep parsing, supertagging is an important preprocessor: an accurate supertagger greatly reduces search space of a parser.", "labels": [], "entities": []}, {"text": "Not limited to parsing, supertags can be used for NP chunking, semantic role labeling and machine translation () to explore rich syntactic information contained in them.", "labels": [], "entities": [{"text": "NP chunking", "start_pos": 50, "end_pos": 61, "type": "TASK", "confidence": 0.8529395461082458}, {"text": "semantic role labeling", "start_pos": 63, "end_pos": 85, "type": "TASK", "confidence": 0.6617473661899567}, {"text": "machine translation", "start_pos": 90, "end_pos": 109, "type": "TASK", "confidence": 0.7441955208778381}]}, {"text": "Generally speaking, supertags are lexical templates extracted from a grammar.", "labels": [], "entities": []}, {"text": "These templates encode possible syntactic behavior of a word.", "labels": [], "entities": []}, {"text": "Although the number of supertags is far larger than the 45 POS tags defined in Penn Treebank, sequence labeling techniques are still effective for supertagging.", "labels": [], "entities": [{"text": "Penn Treebank", "start_pos": 79, "end_pos": 92, "type": "DATASET", "confidence": 0.9449310898780823}, {"text": "sequence labeling", "start_pos": 94, "end_pos": 111, "type": "TASK", "confidence": 0.6457305699586868}]}, {"text": "Previous research showed that a POS sequence is very informative for supertagging, and some extent of local syntactic information can be captured by the context of surrounding words and POS tags.", "labels": [], "entities": []}, {"text": "However, since the context window length is limited for the computational cost reasons, there are still long-range dependencies which are not easily captured in sequential models (.", "labels": [], "entities": []}, {"text": "In practice, the multi-tagging technique proposed by assigned more than one supertag to each word and let the ambiguous supertags be selected by the parser.", "labels": [], "entities": []}, {"text": "As for other NLP applications which use supertags, resolving more supertag ambiguities in supertagging stage is preferred.", "labels": [], "entities": []}, {"text": "With this consideration, we focus on supertagging and aim to make it as accurate as possible.", "labels": [], "entities": []}, {"text": "In this paper, we incorporated long-distance information into supertagging.", "labels": [], "entities": []}, {"text": "First, we used dependency parser formalism to model long-distance relationships between the input words, which is hard to model in sequence labeling models.", "labels": [], "entities": [{"text": "dependency parser formalism", "start_pos": 15, "end_pos": 42, "type": "TASK", "confidence": 0.832974930604299}]}, {"text": "Then, we combined the dependency information with local context in a simple point-wise model.", "labels": [], "entities": []}, {"text": "The experiments showed that dependency information is very informative for supertagging and we got a competitive 93.70% on supertagging accuracy (fed golden POS).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 136, "end_pos": 144, "type": "METRIC", "confidence": 0.9675540924072266}]}, {"text": "In addition, we also evaluated the improved supertagger in the HPSG parser.", "labels": [], "entities": [{"text": "HPSG parser", "start_pos": 63, "end_pos": 74, "type": "DATASET", "confidence": 0.9170540273189545}]}], "datasetContent": [{"text": "We evaluated dependency-informed supertagger (PW-DEP) both by supertag accuracy 2 and by a HPSG parser.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 71, "end_pos": 79, "type": "METRIC", "confidence": 0.7368102669715881}, {"text": "HPSG", "start_pos": 91, "end_pos": 95, "type": "DATASET", "confidence": 0.9406711459159851}]}, {"text": "The experiments were conducted on WSJ-HPSG treebank).", "labels": [], "entities": [{"text": "WSJ-HPSG treebank", "start_pos": 34, "end_pos": 51, "type": "DATASET", "confidence": 0.983026921749115}]}, {"text": "Sections 02-21 were used to train the dependency parser, the dependency-informed supertagger and the HPSG parser.", "labels": [], "entities": [{"text": "dependency parser", "start_pos": 38, "end_pos": 55, "type": "TASK", "confidence": 0.7714506983757019}, {"text": "HPSG parser", "start_pos": 101, "end_pos": 112, "type": "DATASET", "confidence": 0.886380672454834}]}, {"text": "Section 23 was used as the testing set.", "labels": [], "entities": []}, {"text": "The evaluation metric for HPSG parser is the accuracy of predicate-argument relations in the parser's output, as in previous work", "labels": [], "entities": [{"text": "HPSG parser", "start_pos": 26, "end_pos": 37, "type": "TASK", "confidence": 0.6598221957683563}, {"text": "accuracy", "start_pos": 45, "end_pos": 53, "type": "METRIC", "confidence": 0.9988619089126587}]}], "tableCaptions": [{"text": " Table 2: Supertagging accuracy on section 23. ( \u2020)  Dependencies are given by MSTParser evaluated with  labeled accuracy. PW-AP is the baseline point-wise  averaged perceptron model. PW-DEP is point-wise  dependency-informed model. The automatically tagged  POS tags were given by a maximum entropy tagger with  97.39% accuracy.", "labels": [], "entities": [{"text": "Supertagging", "start_pos": 10, "end_pos": 22, "type": "TASK", "confidence": 0.9420799612998962}, {"text": "accuracy", "start_pos": 23, "end_pos": 31, "type": "METRIC", "confidence": 0.9440183043479919}, {"text": "MSTParser", "start_pos": 79, "end_pos": 88, "type": "DATASET", "confidence": 0.8734551072120667}, {"text": "accuracy", "start_pos": 113, "end_pos": 121, "type": "METRIC", "confidence": 0.5355292558670044}, {"text": "accuracy", "start_pos": 320, "end_pos": 328, "type": "METRIC", "confidence": 0.9943168759346008}]}]}