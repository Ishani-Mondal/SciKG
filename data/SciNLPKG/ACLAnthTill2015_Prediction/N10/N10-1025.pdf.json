{"title": [{"text": "Contextual Information Improves OOV Detection in Speech", "labels": [], "entities": [{"text": "Contextual Information Improves OOV Detection", "start_pos": 0, "end_pos": 45, "type": "TASK", "confidence": 0.7996390104293823}]}], "abstractContent": [{"text": "Out-of-vocabulary (OOV) words represent an important source of error in large vocabulary continuous speech recognition (LVCSR) systems.", "labels": [], "entities": [{"text": "large vocabulary continuous speech recognition (LVCSR)", "start_pos": 72, "end_pos": 126, "type": "TASK", "confidence": 0.7378437332808971}]}, {"text": "These words cause recognition failures, which propagate through pipeline systems im-pacting the performance of downstream applications.", "labels": [], "entities": []}, {"text": "The detection of OOV regions in the output of a LVCSR system is typically addressed as a binary classification task, where each region is independently classified using local information.", "labels": [], "entities": []}, {"text": "In this paper, we show that jointly predicting OOV regions, and including contextual information from each region, leads to substantial improvement in OOV detection.", "labels": [], "entities": [{"text": "OOV detection", "start_pos": 151, "end_pos": 164, "type": "TASK", "confidence": 0.9730812907218933}]}, {"text": "Compared to the state-of-the-art, we reduce the missed OOV rate from 42.6% to 28.4% at 10% false alarm rate.", "labels": [], "entities": [{"text": "missed OOV rate", "start_pos": 48, "end_pos": 63, "type": "METRIC", "confidence": 0.8689579168955485}]}], "introductionContent": [{"text": "Even with a vocabulary of one hundred thousand words, a large vocabulary continuous speech recognition (LVCSR) system encounters out-ofvocabulary (OOV) words, especially in new domains or genres.", "labels": [], "entities": [{"text": "continuous speech recognition (LVCSR)", "start_pos": 73, "end_pos": 110, "type": "TASK", "confidence": 0.7807116905848185}]}, {"text": "New words often include named entities, foreign words, rare and invented words.", "labels": [], "entities": []}, {"text": "Since these words were not seen during training, the LVCSR system has noway to recognize them.", "labels": [], "entities": []}, {"text": "OOV words are an important source of error in LVCSR systems for three reasons.", "labels": [], "entities": []}, {"text": "First, OOVs can never be recognized by the LVCSR system, even if repeated.", "labels": [], "entities": []}, {"text": "Second, OOV words contribute to recognition errors in surrounding words, which propagate into to later processing stages (translation, understanding, document retrieval, etc.).", "labels": [], "entities": [{"text": "translation, understanding, document retrieval", "start_pos": 122, "end_pos": 168, "type": "TASK", "confidence": 0.6182360549767812}]}, {"text": "Third, OOVs are often information-rich nouns -mis-recognized OOVs can have a greater impact on the understanding of the transcript than other words.", "labels": [], "entities": []}, {"text": "One solution is to simply increase the LVCSR system's vocabulary, but there are always new words.", "labels": [], "entities": []}, {"text": "Additionally, increasing the vocabulary size without limit can sometimes produce higher word error rates (WER), leading to a tradeoff between recognition accuracy of frequent and rare words.", "labels": [], "entities": [{"text": "word error rates (WER)", "start_pos": 88, "end_pos": 110, "type": "METRIC", "confidence": 0.9034151832262675}, {"text": "accuracy", "start_pos": 154, "end_pos": 162, "type": "METRIC", "confidence": 0.9287645816802979}]}, {"text": "A more effective solution is to detect the presence of OOVs directly.", "labels": [], "entities": []}, {"text": "Once identified, OOVs can be flagged for annotation and addition to the system's vocabulary, or OOV segments can be transcribed with a phone recognizer, creating an open vocabulary LVCSR system.", "labels": [], "entities": []}, {"text": "Identified OOVs prevent error propagation in the application pipeline.", "labels": [], "entities": [{"text": "error propagation", "start_pos": 24, "end_pos": 41, "type": "TASK", "confidence": 0.7128904163837433}]}, {"text": "In the literature, there are two basic approaches to OOV detection: 1) filler models, which explicitly represent OOVs using a filler, sub-word, or generic word model; and 2) confidence estimation models, which use different confidence scores to find unreliable regions and label them as OOV ().", "labels": [], "entities": [{"text": "OOV detection", "start_pos": 53, "end_pos": 66, "type": "TASK", "confidence": 0.9494431912899017}]}, {"text": "Recently, presented an approach that combined confidence estimation models and filler models to improve state-of-the-art results for OOV detection.", "labels": [], "entities": [{"text": "OOV detection", "start_pos": 133, "end_pos": 146, "type": "TASK", "confidence": 0.9646102488040924}]}, {"text": "This approach and other confidence based systems, treat OOV detection as a binary classification task; each region is independently classified using local information as IV or OOV.", "labels": [], "entities": [{"text": "OOV detection", "start_pos": 56, "end_pos": 69, "type": "TASK", "confidence": 0.9214569926261902}]}, {"text": "This work moves beyond this independence assumption that considers regions independently for OOV detection.", "labels": [], "entities": [{"text": "OOV detection", "start_pos": 93, "end_pos": 106, "type": "TASK", "confidence": 0.9066824018955231}]}, {"text": "We treat OOV detection as a sequence labeling problem and add features based on the local lexical context of each region as well as global features from a language model using the entire utterance.", "labels": [], "entities": [{"text": "OOV detection", "start_pos": 9, "end_pos": 22, "type": "TASK", "confidence": 0.8794001638889313}]}, {"text": "Our results show that such information improves OOV detection and we obtain large reductions in error compared to the best previously reported results.", "labels": [], "entities": [{"text": "OOV detection", "start_pos": 48, "end_pos": 61, "type": "TASK", "confidence": 0.9591510593891144}, {"text": "error", "start_pos": 96, "end_pos": 101, "type": "METRIC", "confidence": 0.9942741990089417}]}, {"text": "Furthermore, our approach can be combined with any confidence based system.", "labels": [], "entities": []}, {"text": "We begin by reviewing the current state-of-the-art results for OOV detection.", "labels": [], "entities": [{"text": "OOV detection", "start_pos": 63, "end_pos": 76, "type": "TASK", "confidence": 0.946042001247406}]}, {"text": "After describing our experimental setup, we generalize the framework to a sequence labeling problem, which includes features from the local context, lexical context, and entire utterance.", "labels": [], "entities": [{"text": "sequence labeling", "start_pos": 74, "end_pos": 91, "type": "TASK", "confidence": 0.7091967165470123}]}, {"text": "Each stage yields additional improvements over the baseline system.", "labels": [], "entities": []}, {"text": "We conclude with a review of related work.", "labels": [], "entities": []}], "datasetContent": [{"text": "Before we introduce and evaluate our context approach, we establish an experimental setup.", "labels": [], "entities": []}, {"text": "We used the dataset constructed by to evaluate Spoken Term Detection (STD) of OOVs; we refer to this corpus as OOVCORP.", "labels": [], "entities": [{"text": "Spoken Term Detection (STD) of OOVs", "start_pos": 47, "end_pos": 82, "type": "TASK", "confidence": 0.6521471180021763}]}, {"text": "The corpus contains 100 hours of transcribed Broadcast News English speech emphasizing OOVs.", "labels": [], "entities": [{"text": "Broadcast News English speech emphasizing OOVs", "start_pos": 45, "end_pos": 91, "type": "DATASET", "confidence": 0.7588263849417368}]}, {"text": "There are 1290 unique OOVs in the corpus, which were selected with a minimum of 5 acoustic instances per word.", "labels": [], "entities": []}, {"text": "Common English words were filtered out to obtain meaningful OOVs: e.g. NATALIE, PUTIN, QAEDA, HOLLOWAY.", "labels": [], "entities": [{"text": "OOVs", "start_pos": 60, "end_pos": 64, "type": "METRIC", "confidence": 0.9034034609794617}, {"text": "NATALIE", "start_pos": 71, "end_pos": 78, "type": "METRIC", "confidence": 0.9379408359527588}, {"text": "PUTIN", "start_pos": 80, "end_pos": 85, "type": "METRIC", "confidence": 0.9588161706924438}, {"text": "QAEDA", "start_pos": 87, "end_pos": 92, "type": "METRIC", "confidence": 0.7965164184570312}, {"text": "HOLLOWAY", "start_pos": 94, "end_pos": 102, "type": "METRIC", "confidence": 0.9096089005470276}]}, {"text": "Since the corpus was designed for STD, short OOVs (less than 4 phones) were explicitly excluded.", "labels": [], "entities": [{"text": "STD", "start_pos": 34, "end_pos": 37, "type": "TASK", "confidence": 0.9260994791984558}]}, {"text": "This resulted in roughly 24K (2%) OOV tokens.", "labels": [], "entities": []}, {"text": "For a LVCSR system we used the IBM Speech Recognition Toolkit () with acoustic models trained on 300 hours of HUB4 data () and excluded utterances containing OOV words as marked in OOVCORP.", "labels": [], "entities": [{"text": "IBM Speech Recognition", "start_pos": 31, "end_pos": 53, "type": "TASK", "confidence": 0.6973046461741129}]}, {"text": "The language model was trained on 400M words from various text sources with a 83K word vocabulary.", "labels": [], "entities": []}, {"text": "The LVCSR system's WER on the standard RT04 BN test set was 19.4%.", "labels": [], "entities": [{"text": "WER", "start_pos": 19, "end_pos": 22, "type": "METRIC", "confidence": 0.9996234178543091}, {"text": "RT04 BN test set", "start_pos": 39, "end_pos": 55, "type": "DATASET", "confidence": 0.947645977139473}]}, {"text": "Excluded utterances were divided into 5 hours of training and 95 hours of test data for the OOV detector.", "labels": [], "entities": [{"text": "OOV detector", "start_pos": 92, "end_pos": 104, "type": "TASK", "confidence": 0.5686970800161362}]}, {"text": "Both train and test sets have a 2% OOV rate.", "labels": [], "entities": [{"text": "OOV rate", "start_pos": 35, "end_pos": 43, "type": "METRIC", "confidence": 0.9826700091362}]}, {"text": "We used this split for all experiments.", "labels": [], "entities": []}, {"text": "Note that the OOV training set is different from the LVCSR training set.", "labels": [], "entities": [{"text": "OOV training set", "start_pos": 14, "end_pos": 30, "type": "DATASET", "confidence": 0.7234906951586405}, {"text": "LVCSR training set", "start_pos": 53, "end_pos": 71, "type": "DATASET", "confidence": 0.9637173016866049}]}, {"text": "In addition to a word-based LVCSR system, we use a hybrid LVCSR system, combining word and sub-word (fragments) units.", "labels": [], "entities": []}, {"text": "Combined word/subword systems have improved OOV Spoken Term Detection performance (, better phone error rates, especially in OOV regions (, and state-ofthe-art performance for OOV detection.", "labels": [], "entities": [{"text": "OOV Spoken Term Detection", "start_pos": 44, "end_pos": 69, "type": "TASK", "confidence": 0.7290699481964111}, {"text": "OOV detection", "start_pos": 176, "end_pos": 189, "type": "TASK", "confidence": 0.9306077063083649}]}, {"text": "Our hybrid system's lexicon has 83K words and 20K fragments derived using.", "labels": [], "entities": []}, {"text": "The 1290 excluded words are OOVs to both the word and hybrid We use the IBM system with speaker adaptive training based on maximum likelihood with no discriminative training.", "labels": [], "entities": []}, {"text": "Confusion networks are obtained from both the word and hybrid LVCSR systems.", "labels": [], "entities": []}, {"text": "In order to evaluate the performance of the OOV detector, we align the reference transcript to the audio.", "labels": [], "entities": []}, {"text": "The LVCSR transcript is compared to the reference transcript at the confused region level, so each confused region is tagged as either OOV or IV.", "labels": [], "entities": [{"text": "OOV", "start_pos": 135, "end_pos": 138, "type": "METRIC", "confidence": 0.9212783575057983}]}, {"text": "The OOV detector assigns a score/probability for IV/OOV to each of these regions.", "labels": [], "entities": [{"text": "OOV", "start_pos": 4, "end_pos": 7, "type": "METRIC", "confidence": 0.7847155332565308}, {"text": "IV/OOV", "start_pos": 49, "end_pos": 55, "type": "METRIC", "confidence": 0.8117950757344564}]}, {"text": "Previous research reported OOV detection accuracy on all test data.", "labels": [], "entities": [{"text": "OOV detection", "start_pos": 27, "end_pos": 40, "type": "TASK", "confidence": 0.7784842252731323}, {"text": "accuracy", "start_pos": 41, "end_pos": 49, "type": "METRIC", "confidence": 0.8917784690856934}]}, {"text": "However, once an OOV word has been observed in the training data for the OOV detector, even if it never appeared in the LVCSR training data, it is no longer truly OOV.", "labels": [], "entities": [{"text": "LVCSR training data", "start_pos": 120, "end_pos": 139, "type": "DATASET", "confidence": 0.9234046538670858}]}, {"text": "The features used in previous approaches did not necessarily provide an advantage on observed versus unobserved OOVs, but our features do yield an advantage.", "labels": [], "entities": []}, {"text": "Therefore, in the sections that follow we report unobserved OOV accuracy: OOV words that do not appear in either the OOV detector's or the LVCSR's training data.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 64, "end_pos": 72, "type": "METRIC", "confidence": 0.5350180268287659}, {"text": "LVCSR's training data", "start_pos": 139, "end_pos": 160, "type": "DATASET", "confidence": 0.8234798163175583}]}, {"text": "While this penalizes our results, it is a more informative metric of true system performance.", "labels": [], "entities": []}, {"text": "We present results using standard detection error tradeoff (DET) curves ().", "labels": [], "entities": [{"text": "standard detection error tradeoff (DET)", "start_pos": 25, "end_pos": 64, "type": "METRIC", "confidence": 0.7262567835194724}]}, {"text": "DET curves measure tradeoffs between misses and false alarms and can be used to determine the optimal operating point of a system.", "labels": [], "entities": []}, {"text": "The x-axis varies the false alarm rate (false positive) and the y-axis varies the miss (false negative) rate; lower curves are better.", "labels": [], "entities": [{"text": "false alarm rate", "start_pos": 22, "end_pos": 38, "type": "METRIC", "confidence": 0.9060172239939371}, {"text": "miss (false negative) rate", "start_pos": 82, "end_pos": 108, "type": "METRIC", "confidence": 0.9237298766771952}]}], "tableCaptions": []}