{"title": [{"text": "Detecting Novelty in the context of Progressive Summarization", "labels": [], "entities": [{"text": "Detecting Novelty", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.9367121458053589}, {"text": "Progressive Summarization", "start_pos": 36, "end_pos": 61, "type": "TASK", "confidence": 0.6618871241807938}]}], "abstractContent": [{"text": "A Progressive summary helps a user to monitor changes in evolving news topics over a period of time.", "labels": [], "entities": []}, {"text": "Detecting novel information is the essential part of progressive summariza-tion that differentiates it from normal multi document summarization.", "labels": [], "entities": [{"text": "Detecting novel information", "start_pos": 0, "end_pos": 27, "type": "TASK", "confidence": 0.8947398066520691}, {"text": "multi document summarization", "start_pos": 115, "end_pos": 143, "type": "TASK", "confidence": 0.595988521973292}]}, {"text": "In this work, we explore the possibility of detecting novelty at various stages of summarization.", "labels": [], "entities": [{"text": "summarization", "start_pos": 83, "end_pos": 96, "type": "TASK", "confidence": 0.9731258749961853}]}, {"text": "New scoring features, Re-ranking criterions and filtering strategies are proposed to identify \"relevant novel\" information.", "labels": [], "entities": []}, {"text": "We compare these techniques using an automated evaluation framework ROUGE, and determine the best.", "labels": [], "entities": [{"text": "ROUGE", "start_pos": 68, "end_pos": 73, "type": "METRIC", "confidence": 0.9704712629318237}]}, {"text": "Overall , our summarizer is able to perform on par with existing prime methods in progressive summarization.", "labels": [], "entities": [{"text": "summarizer", "start_pos": 14, "end_pos": 24, "type": "TASK", "confidence": 0.9657246470451355}]}], "introductionContent": [{"text": "Summarization is the process of condensing text to its most essential facts.", "labels": [], "entities": [{"text": "Summarization", "start_pos": 0, "end_pos": 13, "type": "TASK", "confidence": 0.9846349358558655}]}, {"text": "Summarization is challenging for its associated cognitive task and interesting because of its practical usage.", "labels": [], "entities": [{"text": "Summarization", "start_pos": 0, "end_pos": 13, "type": "TASK", "confidence": 0.9750261306762695}]}, {"text": "It has been successfully applied for text content such as news articles 1 , scientific papers () that follow a discourse structure.", "labels": [], "entities": []}, {"text": "Update summarization is an emerging area within summarization, acquiring significant research focus during recent times.", "labels": [], "entities": [{"text": "Update summarization", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.816272646188736}, {"text": "summarization", "start_pos": 48, "end_pos": 61, "type": "TASK", "confidence": 0.9868107438087463}]}, {"text": "The task was introduced at DUC 2007 2 and continued during . We refer to update summariztion as \"Progressive Summarization\" in rest of this paper, as summaries are produced periodically in a progressive manner and the latter title is more apt to the task.", "labels": [], "entities": [{"text": "DUC 2007 2", "start_pos": 27, "end_pos": 37, "type": "DATASET", "confidence": 0.9558741450309753}, {"text": "summariztion", "start_pos": 80, "end_pos": 92, "type": "TASK", "confidence": 0.9084524512290955}]}, {"text": "Progressive summaries contain information which is both relevant and novel, since they are produced under the assumption that user has already read some previous documents/articles on the topic.", "labels": [], "entities": []}, {"text": "Such summaries are extremely useful in tracking news stories, tracing new product reviews etc.", "labels": [], "entities": [{"text": "tracing new product reviews", "start_pos": 62, "end_pos": 89, "type": "TASK", "confidence": 0.8799183070659637}]}, {"text": "Unlike dynamic summarization) where a single summary transforms periodically, reflecting changes in source text, Progressive summarizer produce multiple summaries at specific time intervals updating user knowledge.", "labels": [], "entities": []}, {"text": "Temporal Summarization () generate summaries, similar to progressive summaries by ranking sentences as combination of relevant and new scores.", "labels": [], "entities": [{"text": "Temporal Summarization", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.8996475040912628}]}, {"text": "In this work, summaries are produced not just by reforming ranking scheme but also altering scoring and extraction stages of summarization.", "labels": [], "entities": [{"text": "summaries", "start_pos": 14, "end_pos": 23, "type": "TASK", "confidence": 0.9811398983001709}, {"text": "summarization", "start_pos": 125, "end_pos": 138, "type": "TASK", "confidence": 0.9694947004318237}]}, {"text": "Progressive summarization requires differentiating Relevant and Novel Vs Non-Relevant and Novel Vs Relevant and Redundant information.", "labels": [], "entities": [{"text": "summarization", "start_pos": 12, "end_pos": 25, "type": "TASK", "confidence": 0.9843748211860657}]}, {"text": "Such discrimination is feasible only with efficient Novelty detection techniques.", "labels": [], "entities": [{"text": "Novelty detection", "start_pos": 52, "end_pos": 69, "type": "TASK", "confidence": 0.9733235836029053}]}, {"text": "We define Novelty detection as identifying relevant sentences containing new information.", "labels": [], "entities": [{"text": "Novelty detection", "start_pos": 10, "end_pos": 27, "type": "TASK", "confidence": 0.9246056973934174}]}, {"text": "This task shares similarity with TREC Novelty Track 4 , that is designed to investigate systems abilities to locate sentences containing relevant and/or new information given the topic and a set of relevant documents ordered by date.", "labels": [], "entities": [{"text": "TREC Novelty Track 4", "start_pos": 33, "end_pos": 53, "type": "TASK", "confidence": 0.5490429550409317}]}, {"text": "A progressive summarizer needs to identify, score and then finally rank \"relevant novel\" sentences to produce a summary.", "labels": [], "entities": []}, {"text": "Previous approaches to Novelty detection at TREC) include cosine filtering (), where a sentence having maximum cosine similarity value with previous set of sentences, lower than a preset threshold is considered novel.", "labels": [], "entities": [{"text": "Novelty detection", "start_pos": 23, "end_pos": 40, "type": "TASK", "confidence": 0.8230271935462952}]}, {"text": "Alternatively, () considered previously unseen words as an evidence of Novelty.", "labels": [], "entities": []}, {"text": "() expanded all noun phrases in a sentence using wordnet and used corresponding sysnsets for novelty comparisions.", "labels": [], "entities": []}, {"text": "Our work targets exploring the effect of detecting novelty at different stages of summarization on the quality of progressive summaries.", "labels": [], "entities": [{"text": "summarization", "start_pos": 82, "end_pos": 95, "type": "TASK", "confidence": 0.9856135249137878}]}, {"text": "Unlike most of the previous work () ( ) in progressive summarization, we employ multiple novelty detection techniques at different stages and analyze them all to find the best.", "labels": [], "entities": [{"text": "summarization", "start_pos": 55, "end_pos": 68, "type": "TASK", "confidence": 0.6342610716819763}, {"text": "novelty detection", "start_pos": 89, "end_pos": 106, "type": "TASK", "confidence": 0.7407086491584778}]}], "datasetContent": [{"text": "We conducted all the experiments on TAC 2009 Update Summarization dataset.", "labels": [], "entities": [{"text": "TAC 2009 Update Summarization dataset", "start_pos": 36, "end_pos": 73, "type": "DATASET", "confidence": 0.9540164351463318}]}, {"text": "It consists of 48 topics, each having 20 documents divided into two clusters \"A\" and \"B\" based on their chronological coverage of topic.", "labels": [], "entities": []}, {"text": "It serves as an ideal setting for evaluating our progressive summaries.", "labels": [], "entities": []}, {"text": "Summary for cluster A (pdocs) is a normal multi document summary whereas summary for cluster B (ndocs) is a Progressive summary, both of length 100 words.", "labels": [], "entities": []}, {"text": "Each topic has associated 4 model summaries written by human assessors.", "labels": [], "entities": []}, {"text": "TAC 2008 Update summarization data that follow similar structure is used to build training model for support vectors as mentioned in Section 2.", "labels": [], "entities": [{"text": "TAC 2008 Update summarization data", "start_pos": 0, "end_pos": 34, "type": "DATASET", "confidence": 0.9509469509124756}]}, {"text": "Thresholds for dom ndocs , dom pdocs are set to 0.6, 0.3 respectively and relweight to 0.8 for optimal results.", "labels": [], "entities": []}, {"text": "Summaries are evaluated using ROUGE), a recall oriented metric that automatically assess machine generated summaries based on their overlap with models.", "labels": [], "entities": [{"text": "ROUGE", "start_pos": 30, "end_pos": 35, "type": "METRIC", "confidence": 0.9844517707824707}, {"text": "recall", "start_pos": 40, "end_pos": 46, "type": "METRIC", "confidence": 0.9630098938941956}]}, {"text": "ROUGE-2 and ROUGE-SU4 are standard measures for automated summary evaluation.", "labels": [], "entities": [{"text": "ROUGE-2", "start_pos": 0, "end_pos": 7, "type": "DATASET", "confidence": 0.6230970025062561}, {"text": "ROUGE-SU4", "start_pos": 12, "end_pos": 21, "type": "METRIC", "confidence": 0.6526104211807251}, {"text": "summary evaluation", "start_pos": 58, "end_pos": 76, "type": "TASK", "confidence": 0.7816498577594757}]}, {"text": "In ROUGE scores of baseline systems(Section 2.1) are presented.", "labels": [], "entities": []}, {"text": "Five progressive runs are generated, each having a novelty detection scheme at either scoring, ranking or summary extraction stages.", "labels": [], "entities": [{"text": "summary extraction", "start_pos": 106, "end_pos": 124, "type": "TASK", "confidence": 0.6701805889606476}]}, {"text": "ROUGE scores of these runs are presented in.", "labels": [], "entities": [{"text": "ROUGE", "start_pos": 0, "end_pos": 5, "type": "METRIC", "confidence": 0.9735315442085266}]}], "tableCaptions": [{"text": " Table 1: Average ROUGE-2, ROUGE-SU4 recall scores  of baselines for TAC 2009, cluster B", "labels": [], "entities": [{"text": "ROUGE-2", "start_pos": 18, "end_pos": 25, "type": "METRIC", "confidence": 0.7467632293701172}, {"text": "ROUGE-SU4", "start_pos": 27, "end_pos": 36, "type": "METRIC", "confidence": 0.9700956344604492}, {"text": "recall", "start_pos": 37, "end_pos": 43, "type": "METRIC", "confidence": 0.8158924579620361}, {"text": "TAC 2009", "start_pos": 69, "end_pos": 77, "type": "TASK", "confidence": 0.566477507352829}]}, {"text": " Table 2: Average ROUGE-2, ROUGE-SU4 recall scores  for TAC 2009, cluster B", "labels": [], "entities": [{"text": "ROUGE-2", "start_pos": 18, "end_pos": 25, "type": "METRIC", "confidence": 0.7706431746482849}, {"text": "ROUGE-SU4", "start_pos": 27, "end_pos": 36, "type": "METRIC", "confidence": 0.9803118705749512}, {"text": "recall", "start_pos": 37, "end_pos": 43, "type": "METRIC", "confidence": 0.8274518847465515}, {"text": "TAC 2009", "start_pos": 56, "end_pos": 64, "type": "DATASET", "confidence": 0.7097482979297638}]}, {"text": " Table 3: Average ROUGE-2, ROUGE-SU4 recall scores  for TAC 2009, cluster B", "labels": [], "entities": [{"text": "ROUGE-2", "start_pos": 18, "end_pos": 25, "type": "METRIC", "confidence": 0.7843364477157593}, {"text": "ROUGE-SU4", "start_pos": 27, "end_pos": 36, "type": "METRIC", "confidence": 0.9808972477912903}, {"text": "recall", "start_pos": 37, "end_pos": 43, "type": "METRIC", "confidence": 0.8315570950508118}, {"text": "TAC 2009", "start_pos": 56, "end_pos": 64, "type": "DATASET", "confidence": 0.7110535800457001}]}]}