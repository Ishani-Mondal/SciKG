{"title": [{"text": "Joint Inference for Knowledge Extraction from Biomedical Literature", "labels": [], "entities": [{"text": "Knowledge Extraction from Biomedical Literature", "start_pos": 20, "end_pos": 67, "type": "TASK", "confidence": 0.8202118098735809}]}], "abstractContent": [{"text": "Knowledge extraction from online repositories such as PubMed holds the promise of dramatically speeding up biomedical research and drug design.", "labels": [], "entities": [{"text": "PubMed", "start_pos": 54, "end_pos": 60, "type": "DATASET", "confidence": 0.9597072601318359}]}, {"text": "After initially focusing on recognizing proteins and binary interactions, the community has recently shifted their attention to the more ambitious task of recognizing complex, nested event structures.", "labels": [], "entities": [{"text": "recognizing complex, nested event structures", "start_pos": 155, "end_pos": 199, "type": "TASK", "confidence": 0.7152763505776724}]}, {"text": "State-of-the-art systems use a pipeline architecture in which the candidate events are identified first, and subsequently the arguments.", "labels": [], "entities": []}, {"text": "This fails to leverage joint inference among events and arguments for mutual disambiguation.", "labels": [], "entities": []}, {"text": "Some joint approaches have been proposed, but they still lag much behind inaccuracy.", "labels": [], "entities": []}, {"text": "In this paper , we present the first joint approach for bio-event extraction that obtains state-of-the-art results.", "labels": [], "entities": [{"text": "bio-event extraction", "start_pos": 56, "end_pos": 76, "type": "TASK", "confidence": 0.8433786034584045}]}, {"text": "Our system is based on Markov logic and adopts a novel formulation by jointly predicting events and arguments, as well as individual dependency edges that compose the argument paths.", "labels": [], "entities": []}, {"text": "On the BioNLP'09 Shared Task dataset, it reduced F1 errors by more than 10% compared to the previous best joint approach.", "labels": [], "entities": [{"text": "BioNLP'09 Shared Task dataset", "start_pos": 7, "end_pos": 36, "type": "DATASET", "confidence": 0.7841936200857162}, {"text": "F1 errors", "start_pos": 49, "end_pos": 58, "type": "METRIC", "confidence": 0.9245954751968384}]}], "introductionContent": [{"text": "Extracting knowledge from unstructured text has been a long-standing goal of NLP and AI.", "labels": [], "entities": [{"text": "Extracting knowledge from unstructured text", "start_pos": 0, "end_pos": 43, "type": "TASK", "confidence": 0.8775002837181092}]}, {"text": "The advent of the World Wide Web further increases its importance and urgency by making available an astronomical number of online documents containing virtually unlimited amount of knowledge.", "labels": [], "entities": []}, {"text": "A salient example domain is biomedical literature: the PubMed 1 online repository contains over 18 million abstracts on biomedical research, with more than two thousand new abstracts added each day; the abstracts are written in grammatical English, which enables the use of advanced NLP tools such as syntactic and semantic parsers.", "labels": [], "entities": [{"text": "PubMed 1 online repository", "start_pos": 55, "end_pos": 81, "type": "DATASET", "confidence": 0.9355661123991013}]}, {"text": "Traditionally, research on knowledge extraction from text is primarily pursued in the field of information extraction with a rather confined goal of extracting instances for flat relational schemas with no nested structures (e.g, recognizing protein names and protein-protein interaction (PPI)).", "labels": [], "entities": [{"text": "knowledge extraction from text", "start_pos": 27, "end_pos": 57, "type": "TASK", "confidence": 0.8346145302057266}, {"text": "information extraction", "start_pos": 95, "end_pos": 117, "type": "TASK", "confidence": 0.7297472059726715}]}, {"text": "This restriction mainly stems from limitations in available resources and algorithms.", "labels": [], "entities": []}, {"text": "The BioNLP'09 Shared Task () is one of the first that faced squarely information needs that are complex and highly structured.", "labels": [], "entities": []}, {"text": "It aims to extract nested bio-molecular events from research abstracts, where an event may have variable number of arguments and may contain other events as arguments.", "labels": [], "entities": []}, {"text": "Such nested events are ubiquitous in biomedical literature and can effectively represent complex biomedical knowledge and subsequently support reasoning and automated discovery.", "labels": [], "entities": []}, {"text": "The task has generated much interest, with twenty-four teams having submitted their results.", "labels": [], "entities": []}, {"text": "The top system by UTurku () attained the state-of-the-art F1 of 52.0%.", "labels": [], "entities": [{"text": "UTurku", "start_pos": 18, "end_pos": 24, "type": "DATASET", "confidence": 0.857877790927887}, {"text": "F1", "start_pos": 58, "end_pos": 60, "type": "METRIC", "confidence": 0.9957712292671204}]}, {"text": "The nested event structures make this task particularly attractive for applying joint inference.", "labels": [], "entities": []}, {"text": "By allowing information to propagate among events and arguments, joint inference can facilitate mutual disambiguation and potentially lead to substantial gain in predictive accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 173, "end_pos": 181, "type": "METRIC", "confidence": 0.8577129244804382}]}, {"text": "However, joint inference is underexplored for this task.", "labels": [], "entities": []}, {"text": "Most participants either reduced the task to classification (e.g., by using SVM), or used heuristics to combine manual rules and statistics.", "labels": [], "entities": []}, {"text": "The previous best joint approach was.", "labels": [], "entities": []}, {"text": "While competitive, it still lags UTurku by more than 7 points in F1.", "labels": [], "entities": [{"text": "UTurku", "start_pos": 33, "end_pos": 39, "type": "DATASET", "confidence": 0.8813566565513611}, {"text": "F1", "start_pos": 65, "end_pos": 67, "type": "METRIC", "confidence": 0.9500747323036194}]}, {"text": "In this paper, we present the first joint approach that achieves state-of-the-art results for bio-event extraction.", "labels": [], "entities": [{"text": "bio-event extraction", "start_pos": 94, "end_pos": 114, "type": "TASK", "confidence": 0.851944088935852}]}, {"text": "Like, our system is based on Markov logic, but we adopted a novel formulation that models dependency edges in argument paths and jointly predicts them along with events and arguments.", "labels": [], "entities": []}, {"text": "By expanding the scope of joint inference to include individual argument edges, our system can leverage fine-grained correlations to make learning more effective.", "labels": [], "entities": []}, {"text": "On the development set, by merely adding a few joint inference formulas to a simple logistic regression model, our system raised F1 from 28% to 54%, already tying UTurku.", "labels": [], "entities": [{"text": "F1", "start_pos": 129, "end_pos": 131, "type": "METRIC", "confidence": 0.9997592568397522}, {"text": "UTurku", "start_pos": 163, "end_pos": 169, "type": "DATASET", "confidence": 0.9556394815444946}]}, {"text": "We also presented a heuristic method to fix errors in syntactic parsing by leveraging available semantic information from task input, and showed that this in turn led to substantial performance gain in the task.", "labels": [], "entities": [{"text": "syntactic parsing", "start_pos": 54, "end_pos": 71, "type": "TASK", "confidence": 0.7098489254713058}]}, {"text": "Overall, our final system reduced F1 error by more than 10% compared to.", "labels": [], "entities": [{"text": "F1 error", "start_pos": 34, "end_pos": 42, "type": "METRIC", "confidence": 0.7846919894218445}]}, {"text": "We begin by describing the shared task and related work.", "labels": [], "entities": []}, {"text": "We then introduce Markov logic and our Markov Logic Network (MLN) for joint bio-event extraction.", "labels": [], "entities": [{"text": "bio-event extraction", "start_pos": 76, "end_pos": 96, "type": "TASK", "confidence": 0.7090819627046585}]}, {"text": "Finally, we present our experimental results and conclude.", "labels": [], "entities": []}], "datasetContent": [{"text": "We evaluated our system on the dataset for Task 1 in the BioNLP'09 Shared Task (.", "labels": [], "entities": [{"text": "BioNLP'09 Shared Task", "start_pos": 57, "end_pos": 78, "type": "DATASET", "confidence": 0.7508072853088379}]}, {"text": "It consists of 800 abstracts for training, 150 for development and 260 for test.", "labels": [], "entities": []}, {"text": "We conducted feature development and tuned hyperparameters using the development set, and evaluated our final system on test using the online tool provided by the organizers.", "labels": [], "entities": []}, {"text": "(The test annotations are not released to the public.)", "labels": [], "entities": []}, {"text": "All results reported were obtained using the main evaluation criteria for the shared task.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Comparison of our full system with its variants  and with UTurku on the development set.", "labels": [], "entities": [{"text": "UTurku", "start_pos": 68, "end_pos": 74, "type": "DATASET", "confidence": 0.9142389893531799}]}, {"text": " Table 3: Per-type recall/precision/F1 for our full system  on the development set.", "labels": [], "entities": [{"text": "recall", "start_pos": 19, "end_pos": 25, "type": "METRIC", "confidence": 0.9102616310119629}, {"text": "precision", "start_pos": 26, "end_pos": 35, "type": "METRIC", "confidence": 0.9840252995491028}, {"text": "F1", "start_pos": 36, "end_pos": 38, "type": "METRIC", "confidence": 0.9463551044464111}]}, {"text": " Table 4: Predicate recall/precision/F1 for our full system  on the development set.", "labels": [], "entities": [{"text": "Predicate", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9984273910522461}, {"text": "recall", "start_pos": 20, "end_pos": 26, "type": "METRIC", "confidence": 0.9106850028038025}, {"text": "precision", "start_pos": 27, "end_pos": 36, "type": "METRIC", "confidence": 0.9820882678031921}, {"text": "F1", "start_pos": 37, "end_pos": 39, "type": "METRIC", "confidence": 0.9497076272964478}]}, {"text": " Table 5: Comparison of our full system with top systems  on the test set.", "labels": [], "entities": []}]}