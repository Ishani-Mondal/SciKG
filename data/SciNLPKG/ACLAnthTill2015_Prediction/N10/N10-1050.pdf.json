{"title": [{"text": "Word Alignment with Stochastic Bracketing Linear Inversion Transduction Grammar", "labels": [], "entities": [{"text": "Word Alignment", "start_pos": 0, "end_pos": 14, "type": "TASK", "confidence": 0.7161467969417572}]}], "abstractContent": [{"text": "The class of Linear Inversion Transduction Grammars (LITGs) is introduced, and used to induce a word alignment over a parallel corpus.", "labels": [], "entities": [{"text": "Linear Inversion Transduction Grammars (LITGs)", "start_pos": 13, "end_pos": 59, "type": "TASK", "confidence": 0.7862753186907087}, {"text": "word alignment", "start_pos": 96, "end_pos": 110, "type": "TASK", "confidence": 0.6898233443498611}]}, {"text": "We show that alignment via Stochas-tic Bracketing LITGs is considerably faster than Stochastic Bracketing ITGs, while still yielding alignments superior to the widely-used heuristic of intersecting bidirectional IBM alignments.", "labels": [], "entities": []}, {"text": "Performance is measured as the translation quality of a phrase-based machine translation system built upon the word alignments, and an improvement of 2.85 BLEU points over baseline is noted for French-English.", "labels": [], "entities": [{"text": "phrase-based machine translation", "start_pos": 56, "end_pos": 88, "type": "TASK", "confidence": 0.6517536540826162}, {"text": "BLEU", "start_pos": 155, "end_pos": 159, "type": "METRIC", "confidence": 0.9990886449813843}]}], "introductionContent": [{"text": "Machine translation relies heavily on word alignments, which are usually produced by training IBMmodels () in both directions and combining the resulting alignments via some heuristic.", "labels": [], "entities": [{"text": "Machine translation", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.8266416192054749}, {"text": "word alignments", "start_pos": 38, "end_pos": 53, "type": "TASK", "confidence": 0.7210381478071213}]}, {"text": "Automatically training an Inversion Transduction Grammar (ITG) has been suggested as a viable way of producing superior alignments . The main problem of using Bracketing ITGs for alignment is that exhaustive biparsing runs in O(n 6 ) time.", "labels": [], "entities": [{"text": "Inversion Transduction Grammar (ITG)", "start_pos": 26, "end_pos": 62, "type": "TASK", "confidence": 0.7016004323959351}]}, {"text": "Several ways to lower the complexity of ITGs has been suggested, but in this paper, a different approach is taken.", "labels": [], "entities": []}, {"text": "Instead of using full ITGs, we explore the possibility of subjecting the grammar to a linear constraint, making exhaustive biparsing of a sentence pair in O(n 4 ) time possible.", "labels": [], "entities": []}, {"text": "This can be further improved by applying pruning.", "labels": [], "entities": []}], "datasetContent": [{"text": "We used the guidelines of the shared task of WMT'08 1 to train our baseline system as well as our experimental system.", "labels": [], "entities": [{"text": "WMT'08 1", "start_pos": 45, "end_pos": 53, "type": "DATASET", "confidence": 0.8708402216434479}]}, {"text": "This includes induction of word alignments with GIZA++, induction of a Phrase-based SMT system (, and tuning with minimum error rate training, as well as applying some utility scripts provided for the workshop.", "labels": [], "entities": [{"text": "word alignments", "start_pos": 27, "end_pos": 42, "type": "TASK", "confidence": 0.7121056467294693}, {"text": "Phrase-based SMT", "start_pos": 71, "end_pos": 87, "type": "TASK", "confidence": 0.5171312391757965}]}, {"text": "The translation model is combined with a 5-gram language model).", "labels": [], "entities": [{"text": "translation", "start_pos": 4, "end_pos": 15, "type": "TASK", "confidence": 0.9680686593055725}]}, {"text": "Our experimental system uses alignments from the Viterbi parses, extracted during EM training of an SBLITG on the training corpus, instead of GIZA++.", "labels": [], "entities": []}, {"text": "Since EM will converge fairly slowly, it was limited to 10 iterations, after which it was halted.", "labels": [], "entities": [{"text": "EM", "start_pos": 6, "end_pos": 8, "type": "DATASET", "confidence": 0.6856737732887268}]}, {"text": "We used the French-English part of the WMT'08 shared task, but limited the training set to sentence pairs where both sentences were of length 20 or less.", "labels": [], "entities": [{"text": "WMT'08 shared task", "start_pos": 39, "end_pos": 57, "type": "TASK", "confidence": 0.6453138589859009}]}, {"text": "This was necessary in order to carryout exhaustive search in the SBLITG algorithm.", "labels": [], "entities": []}, {"text": "In total, we had 381,780 sentence pairs for training, and 2,000 sentence pairs each for tuning and testing.", "labels": [], "entities": []}, {"text": "The language model was trained with the entire training set.", "labels": [], "entities": []}, {"text": "To evaluate the systems we used) and NIST Results are presented in.", "labels": [], "entities": [{"text": "NIST", "start_pos": 37, "end_pos": 41, "type": "DATASET", "confidence": 0.6383607387542725}]}, {"text": "It is interesting to note that there is no correlation between the number of phrases extracted and translation quality.", "labels": [], "entities": []}, {"text": "The only explanation for the results we are seeing is that the SBLITGs find better phrases.", "labels": [], "entities": [{"text": "SBLITGs", "start_pos": 63, "end_pos": 70, "type": "TASK", "confidence": 0.6169708967208862}]}, {"text": "Since the only difference is the word alignment strategy, this suggests that the word alignments from SBLITGs are better suited for phrase extraction than those from bidirectional IBM-models.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 33, "end_pos": 47, "type": "TASK", "confidence": 0.7620827555656433}, {"text": "phrase extraction", "start_pos": 132, "end_pos": 149, "type": "TASK", "confidence": 0.8681729435920715}]}, {"text": "The fact that SBLITGs extract more phrases than bidirectional IBM-models under the grow-diag-x heuristics is significant, since more phrases means that more translation possibilities are extracted.", "labels": [], "entities": []}, {"text": "The fact that SBLITGs extract fewer phrases than bidirectional IBM-models under the intersect heuristic is also significant, since it implies that simply adding more phrases is a bad strategy.", "labels": [], "entities": []}, {"text": "Combined, the two observations leads us to believe that there are some alignments missed by the bidirectional IBM-models that are found by the SBLITG-models.", "labels": [], "entities": [{"text": "IBM-models", "start_pos": 110, "end_pos": 120, "type": "DATASET", "confidence": 0.8240589499473572}, {"text": "SBLITG-models", "start_pos": 143, "end_pos": 156, "type": "DATASET", "confidence": 0.7913891673088074}]}, {"text": "It is also interesting to see that the pruned version outperforms the exhaustive version.", "labels": [], "entities": []}, {"text": "We believe this to be because the pruned version approaches the correct grammar faster than the exhaustive.", "labels": [], "entities": []}, {"text": "That would mean that the exhaustive SBLITG would be better in the limit, but the experiment was limited to 10 iterations.", "labels": [], "entities": [{"text": "SBLITG", "start_pos": 36, "end_pos": 42, "type": "TASK", "confidence": 0.6082203388214111}]}], "tableCaptions": [{"text": " Table 1: Results for French-English.", "labels": [], "entities": []}]}