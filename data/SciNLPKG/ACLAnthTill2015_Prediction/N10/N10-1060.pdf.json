{"title": [{"text": "\"cba to check the spelling\" Investigating Parser Performance on Discussion Forum Posts", "labels": [], "entities": []}], "abstractContent": [{"text": "We evaluate the Berkeley parser on text from an online discussion forum.", "labels": [], "entities": []}, {"text": "We evaluate the parser output with and without gold tokens and spellings (using Sparseval and Parseval), and we compile a list of problematic phenomena for this domain.", "labels": [], "entities": [{"text": "Sparseval", "start_pos": 80, "end_pos": 89, "type": "METRIC", "confidence": 0.8648165464401245}, {"text": "Parseval", "start_pos": 94, "end_pos": 102, "type": "METRIC", "confidence": 0.9326454997062683}]}, {"text": "The Parseval f-score fora small development set is 77.56.", "labels": [], "entities": [{"text": "Parseval f-score", "start_pos": 4, "end_pos": 20, "type": "METRIC", "confidence": 0.8650274574756622}]}, {"text": "This increases to 80.27 when we apply a set of simple transformations to the input sentences and to the Wall Street Journal (WSJ) training sections.", "labels": [], "entities": [{"text": "Wall Street Journal (WSJ) training sections", "start_pos": 104, "end_pos": 147, "type": "DATASET", "confidence": 0.9460565522313118}]}], "introductionContent": [{"text": "Parsing techniques have recently become efficient enough for parsers to be used as part of a pipeline in a variety of tasks.", "labels": [], "entities": []}, {"text": "Another recent development is the rise of user-generated content in the form of blogs, wikis and discussion forums.", "labels": [], "entities": []}, {"text": "Thus, it is both interesting and necessary to investigate the performance of NLP tools trained on edited text when applied to unedited Web 2.0 text.", "labels": [], "entities": []}, {"text": "report a Parseval f-score decrease of 5% when a WSJtrained parser is applied to Brown corpus sentences.", "labels": [], "entities": [{"text": "Parseval f-score decrease", "start_pos": 9, "end_pos": 34, "type": "METRIC", "confidence": 0.9520520766576132}, {"text": "WSJtrained", "start_pos": 48, "end_pos": 58, "type": "DATASET", "confidence": 0.855432391166687}, {"text": "Brown corpus sentences", "start_pos": 80, "end_pos": 102, "type": "DATASET", "confidence": 0.8662634889284769}]}, {"text": "In this paper, we move even further from the WSJ by investigating the performance of the Berkeley parser () on user-generated content.", "labels": [], "entities": [{"text": "WSJ", "start_pos": 45, "end_pos": 48, "type": "DATASET", "confidence": 0.9024197459220886}]}, {"text": "We create gold standard phrase structure trees for the posts on two threads of the same online discussion forum.", "labels": [], "entities": []}, {"text": "We then parse the sentences in one thread, our development set, with the Berkeley parser under three conditions: 1) when it performs its own tokenisation, 2) when it is provided with gold tokens and 3) when misspellings in the input have been corrected.", "labels": [], "entities": []}, {"text": "A qualitative evaluation is then carried out on parser output under the third condition.", "labels": [], "entities": []}, {"text": "Based on this evaluation, we identify some \"low-hanging fruit\" which we attempt to handle either by transforming the input sentence or by transforming the WSJ training material.", "labels": [], "entities": [{"text": "WSJ training material", "start_pos": 155, "end_pos": 176, "type": "DATASET", "confidence": 0.8512334028879801}]}, {"text": "The success of these transformations is evaluated on our development and test sets, with encouraging results.", "labels": [], "entities": []}], "datasetContent": [{"text": "Data Our data consists of sentences that occur on the BBC Sport 606 Football discussion forum.", "labels": [], "entities": [{"text": "BBC Sport 606 Football discussion forum", "start_pos": 54, "end_pos": 93, "type": "DATASET", "confidence": 0.9718008637428284}]}, {"text": "The posts on this forum are quite varied, ranging from throwaway comments to more considered essay-like contributions.", "labels": [], "entities": []}, {"text": "The development set consists of 42 posts (185 sentences) on a thread discussing a controversial refereeing decision in a soccer match.", "labels": [], "entities": []}, {"text": "The test set is made up of 40 posts (170 sentences) on a thread discussing a player's behaviour in the same match.", "labels": [], "entities": []}, {"text": "The average sentence length in the development set is 18 words and the test set 15 words.", "labels": [], "entities": []}, {"text": "Tokenisation and spelling correction were carried out by hand on the sentences in both sets.", "labels": [], "entities": [{"text": "Tokenisation", "start_pos": 0, "end_pos": 12, "type": "TASK", "confidence": 0.8189237713813782}, {"text": "spelling correction", "start_pos": 17, "end_pos": 36, "type": "TASK", "confidence": 0.8772852420806885}]}, {"text": "They were then parsed using Bikel's parser) and corrected by hand using the Penn Treebank Bracketing Guidelines (.", "labels": [], "entities": [{"text": "Penn Treebank Bracketing Guidelines", "start_pos": 76, "end_pos": 111, "type": "DATASET", "confidence": 0.9913377016782761}]}, {"text": "Parser The Berkeley parser is an unlexicalised phrase structure parser which learns a latent variable PCFG by iteratively splitting the treebank non-terminals, estimating rule probabilities for the new grammar using EM and merging the less useful splits.", "labels": [], "entities": [{"text": "phrase structure parser", "start_pos": 47, "end_pos": 70, "type": "TASK", "confidence": 0.7185189922650655}]}, {"text": "We train a PCFG from WSJ2-21 by carrying out five cycles of the split-merge process (SM5).", "labels": [], "entities": [{"text": "WSJ2-21", "start_pos": 21, "end_pos": 28, "type": "DATASET", "confidence": 0.8210173845291138}]}], "tableCaptions": [{"text": " Table 1: Sparseval scores for Berkeley SM5", "labels": [], "entities": [{"text": "Sparseval", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.967853307723999}, {"text": "Berkeley SM5", "start_pos": 31, "end_pos": 43, "type": "DATASET", "confidence": 0.7334551513195038}]}, {"text": " Table 2: Parseval scores for Berkeley SM5", "labels": [], "entities": [{"text": "Parseval", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.7030174136161804}, {"text": "Berkeley SM5", "start_pos": 30, "end_pos": 42, "type": "DATASET", "confidence": 0.7628025710582733}]}, {"text": " Table 4: Cross-parser and cross-grammar comparison", "labels": [], "entities": []}, {"text": " Table 5: Input Sentence and Treebank Transformations", "labels": [], "entities": []}]}