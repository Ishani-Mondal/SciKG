{"title": [{"text": "Arabic Mention Detection: Toward Better Unit of Analysis", "labels": [], "entities": [{"text": "Arabic Mention Detection", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.7473915616671244}]}], "abstractContent": [{"text": "We investigate in this paper the adequate unit of analysis for Arabic Mention Detection.", "labels": [], "entities": [{"text": "Arabic Mention Detection", "start_pos": 63, "end_pos": 87, "type": "TASK", "confidence": 0.6264780759811401}]}, {"text": "We experiment different segmentation schemes with various feature-sets.", "labels": [], "entities": []}, {"text": "Results show that when limited resources are available, models built on morphologically segmented data out-perform other models by up to 4F points.", "labels": [], "entities": []}, {"text": "On the other hand, when more resources extracted from morphologically segmented data become available, models built with Arabic TreeBank style segmentation yield to better results.", "labels": [], "entities": []}, {"text": "We also show additional improvement by combining different segmentation schemes.", "labels": [], "entities": []}], "introductionContent": [{"text": "This paper addresses an important and basic task of information extraction: Mention Detection (MD) : the identification and classification of textual references to objects/abstractions (i.e., mentions).", "labels": [], "entities": [{"text": "information extraction", "start_pos": 52, "end_pos": 74, "type": "TASK", "confidence": 0.7273133248090744}, {"text": "Mention Detection (MD)", "start_pos": 76, "end_pos": 98, "type": "TASK", "confidence": 0.8345070004463195}, {"text": "identification and classification of textual references to objects/abstractions (i.e., mentions)", "start_pos": 105, "end_pos": 201, "type": "TASK", "confidence": 0.8465066313743591}]}, {"text": "These mentions can be either named (e.g. Mohammed, John), nominal (city, president) or pronominal (e.g. he, she).", "labels": [], "entities": []}, {"text": "For instance, in the sentence \"President Obama said he will visit ...\" there are three mentions: President, Obama and he.", "labels": [], "entities": []}, {"text": "This is similar to the Named Entity Recognition (NER) task with the additional twist of also identifying nominal and pronominal mentions.", "labels": [], "entities": [{"text": "Named Entity Recognition (NER) task", "start_pos": 23, "end_pos": 58, "type": "TASK", "confidence": 0.808169309582029}]}, {"text": "We formulate the mention detection problem as a classification problem, by assigning to each token in the text a label, indicating whether it starts a specific mention, is inside a specific mention, or is outside all mentions.", "labels": [], "entities": [{"text": "mention detection", "start_pos": 17, "end_pos": 34, "type": "TASK", "confidence": 0.7576273083686829}]}, {"text": "The selection of the unit of analysis is an important step toward a better classification.", "labels": [], "entities": []}, {"text": "When processing languages, such as English, using the word itself as the We adopt here the ACE nomenclature: http://www.nist.gov/speech/tests/ace/index.html unit of analysis (after separating punctuations) leads to a good performance ().", "labels": [], "entities": []}, {"text": "For other languages, such as Chinese, character is considered as the adequate unit of analysis (.", "labels": [], "entities": []}, {"text": "In this paper, we investigate different segmentation schemes in order to define the best unit of analysis for Arabic MD.", "labels": [], "entities": [{"text": "Arabic MD", "start_pos": 110, "end_pos": 119, "type": "TASK", "confidence": 0.6222467720508575}]}, {"text": "Arabic adopts a very complex morphology, i.e. each word is composed of zero or more prefixes, one stem and zero or more suffixes.", "labels": [], "entities": []}, {"text": "Consequently, the Arabic data is sparser than other languages, such as English, and it is necessary to \"segment\" the words into several units of analysis in order to achieve a good performance.", "labels": [], "entities": []}, {"text": "() used Arabic morphologically segmented data and claimed to have very competitive results in ACE 2003 and ACE 2004 data.", "labels": [], "entities": [{"text": "ACE 2003 and ACE 2004 data", "start_pos": 94, "end_pos": 120, "type": "DATASET", "confidence": 0.8202690780162811}]}, {"text": "On the other hand, () report good results for Arabic NER on data using Arabic TreeBank (ATB) segmentation.", "labels": [], "entities": [{"text": "Arabic TreeBank (ATB) segmentation", "start_pos": 71, "end_pos": 105, "type": "DATASET", "confidence": 0.8826178510983785}]}, {"text": "In all published works, authors do not mention a specific motivation for the segmentation scheme they have adopted.", "labels": [], "entities": [{"text": "segmentation", "start_pos": 77, "end_pos": 89, "type": "TASK", "confidence": 0.980160117149353}]}, {"text": "Only for the Machine Translation task,) report several results using different Arabic segmentation schemes.", "labels": [], "entities": [{"text": "Machine Translation task", "start_pos": 13, "end_pos": 37, "type": "TASK", "confidence": 0.8824345668156942}]}, {"text": "They report that the best results were obtained when the ATB-like segmentation was used.", "labels": [], "entities": [{"text": "ATB-like segmentation", "start_pos": 57, "end_pos": 78, "type": "TASK", "confidence": 0.6832110285758972}]}, {"text": "We explore here the four known and linguistically-motivated sorts of segmentation: punctuation separation, ATB, morphological and character-level segmentations.", "labels": [], "entities": [{"text": "punctuation separation", "start_pos": 83, "end_pos": 105, "type": "TASK", "confidence": 0.7368704825639725}, {"text": "ATB", "start_pos": 107, "end_pos": 110, "type": "METRIC", "confidence": 0.822717547416687}]}, {"text": "To our knowledge, this is the first paper which investigates different segmentation schemes to define the unit of analysis which best fits Arabic MD.", "labels": [], "entities": [{"text": "Arabic MD", "start_pos": 139, "end_pos": 148, "type": "DATASET", "confidence": 0.8161729872226715}]}], "datasetContent": [{"text": "We show in this section the experimental results when using Arabic MD system with different segmentation schemes and different feature sets.", "labels": [], "entities": [{"text": "Arabic MD", "start_pos": 60, "end_pos": 69, "type": "DATASET", "confidence": 0.8807365000247955}]}, {"text": "We explore in this paper four categories of features (c.f.", "labels": [], "entities": []}, {"text": "Section 3): Lex f : lexical features; Stem f : Lex f + morphological features; Synt f : Stem f + syntactic features; Sem f : Synt f + output of other MD classifiers.", "labels": [], "entities": []}, {"text": "Lex f and Stem f features are directly extracted from the appropriate corpus based on the used segmentation style.", "labels": [], "entities": []}, {"text": "This is different for Sem f : we first run classifiers on the morphologically segmented data.", "labels": [], "entities": []}, {"text": "Thereafter, we project those labels to other corpora.", "labels": [], "entities": []}, {"text": "This is because, we use classifiers initially trained on morphologically segmented data such as In such data, two morphs belonging to the same word or ATB token may have 2 different mentions.", "labels": [], "entities": []}, {"text": "During transfer, a token will have the label of the corresponding stem in the morphologically segmented data.", "labels": [], "entities": []}, {"text": "One motivation to not re-train classifiers on each corpus separately is to be able to extract Sem f features from classifiers with similar performance.", "labels": [], "entities": []}, {"text": "Results in show that classifiers built on AT B sand M orph shave shown to perform better than classifiers trained on data with other segmentation styles.", "labels": [], "entities": []}, {"text": "When the system uses character as the unit of analysis, performance is poor.", "labels": [], "entities": []}, {"text": "This is because the token itself becomes insignificant information to the classifier.", "labels": [], "entities": []}, {"text": "On the other hand, when only punctuation separation is performed (W ord s ), the data is significantly sparse and the obtained results achieves high F-measure (77.1) only when outputs of other classifiers are used.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 149, "end_pos": 158, "type": "METRIC", "confidence": 0.9990808963775635}]}, {"text": "As mentioned earlier, classifiers used to extract those features are trained on M orph s (less sparse), which explains their remarkable positive impact since they resolve part of the data sparseness problem in W ord s . When using full morphological segmentation, the data is less sparse, which leads to less Out-Of-Vocabulary tokens (OOVs): the number of OOVs in the M orph s data is 1,518 whereas it is 2,464 in the AT B s . As an example, the word (Alrhynp -the hostage), which is person mention in the training data.", "labels": [], "entities": [{"text": "Alrhynp", "start_pos": 452, "end_pos": 459, "type": "METRIC", "confidence": 0.8407328724861145}]}, {"text": "This word is kept unchanged after ATB segmentation and is segmented to \" \" (Al+ rhyn +p) in M orph s . In the development set the same word appears in its dual form without definite article, i.e. .", "labels": [], "entities": [{"text": "ATB segmentation", "start_pos": 34, "end_pos": 50, "type": "TASK", "confidence": 0.7253938764333725}]}, {"text": "This word is unchanged in AT B sand is segmented to \" \" (rhyn +p +yn) in M orph s . For the model built on AT B s , this word is an OOV, whereas for the model built on M orph s the stem has been seen as part of a person mention and consequently has a better chance to tag it correctly.", "labels": [], "entities": [{"text": "OOV", "start_pos": 132, "end_pos": 135, "type": "METRIC", "confidence": 0.98948073387146}]}, {"text": "These phenomena are frequent, which make the classifier trained on M orph s more robust for such cases.", "labels": [], "entities": []}, {"text": "Also, we observed that models trained on AT B s perform better on long span mentions.", "labels": [], "entities": []}, {"text": "We think this is because a model trained on AT B s has access to larger context.", "labels": [], "entities": []}, {"text": "One may argue that a similar behavior of the model built on the M orph s might be obtained if we use a wider context window than the one used for AT B sin order to have similar contextual information.", "labels": [], "entities": []}, {"text": "In order to confirm this statement, we have carried out a set of experiments using all features over M orph s data fora context window up to \u22125/ + 5, the obtained results show no improvement.", "labels": [], "entities": []}, {"text": "Similar behavior is observed when looking to results on identified named (Nam.), nominal (Nom.) and pronominal (Pro.) mentions on AT B sand M orph s (c.f.", "labels": [], "entities": [{"text": "AT B sand M orph s", "start_pos": 130, "end_pos": 148, "type": "DATASET", "confidence": 0.8726967573165894}]}, {"text": "Table 2); we remind the reader that NER is about recognizing named mentions.", "labels": [], "entities": [{"text": "NER", "start_pos": 36, "end_pos": 39, "type": "TASK", "confidence": 0.9574825763702393}]}, {"text": "When limited resources are available (e.g. Lex f , Stem for Synt f ), we believe that it is more effective to morphologically segment the text (M orph s ) as a pre-processing step.", "labels": [], "entities": []}, {"text": "The use of morph as a unit of analysis reduces the data sparseness issue and at the same time allows better context handling when compared to character.", "labels": [], "entities": []}, {"text": "On the other hand, when a larger set of resources are available (e.g., Sem f ), the use of the ATB token as a unit of analysis combined with morphbased features leads to better performance (79.0 vs. 78.3 on M orph s ).", "labels": [], "entities": []}, {"text": "This is because (1) classifiers trained on AT B s handle better the context and (2) the use of morph-based features (output of classi-fiers trained on morphologically segmented data) removes some of the data sparseness from which classifiers trained on AT B s suffer.", "labels": [], "entities": []}, {"text": "The obtained improvement in performance is statistically significant when using the stratified bootstrap re-sampling significance test.", "labels": [], "entities": []}, {"text": "We consider results as statistically significant when p < 0.02, which is the casein this paper.", "labels": [], "entities": []}, {"text": "For an accurate MD system, we think it is appropriate to benefit from AT B s tokens and M orph s . We investigate in the following the combination of these two segmentation styles.", "labels": [], "entities": [{"text": "AT B s tokens", "start_pos": 70, "end_pos": 83, "type": "METRIC", "confidence": 0.7620968967676163}]}], "tableCaptions": [{"text": " Table 1: Results in terms of F-measure per feature-set and  segmentation scheme", "labels": [], "entities": [{"text": "F-measure", "start_pos": 30, "end_pos": 39, "type": "METRIC", "confidence": 0.9851709008216858}]}, {"text": " Table 2: Performance in terms of F-measure per level on  AT B s and M orph s", "labels": [], "entities": [{"text": "F-measure", "start_pos": 34, "end_pos": 43, "type": "METRIC", "confidence": 0.9989228844642639}]}, {"text": " Table 3: Results in terms of F-measure of the combina- tion experiments", "labels": [], "entities": [{"text": "F-measure", "start_pos": 30, "end_pos": 39, "type": "METRIC", "confidence": 0.9975264668464661}]}]}