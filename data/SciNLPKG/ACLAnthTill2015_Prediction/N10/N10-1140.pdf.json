{"title": [], "abstractContent": [{"text": "A principal weakness of conventional (i.e., non-hierarchical) phrase-based statistical machine translation is that it can only exploit continuous phrases.", "labels": [], "entities": [{"text": "phrase-based statistical machine translation", "start_pos": 62, "end_pos": 106, "type": "TASK", "confidence": 0.6072389259934425}]}, {"text": "In this paper, we extend phrase-based decoding to allow both source and target phrasal discontinuities, which provide better generalization on unseen data and yield significant improvements to a standard phrase-based system (Moses).", "labels": [], "entities": []}, {"text": "More interestingly, our discontinuous phrase-based system also outperforms a state-of-the-art hierarchical system (Joshua) by a very significant margin (+1.03 BLEU on average on five Chinese-English NIST test sets), even though both Joshua and our system support discontinuous phrases.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 159, "end_pos": 163, "type": "METRIC", "confidence": 0.9972355961799622}, {"text": "NIST test sets", "start_pos": 199, "end_pos": 213, "type": "DATASET", "confidence": 0.8508235216140747}]}, {"text": "Since the key difference between these two systems is that ours is not hierarchical-i.e., our system uses a string-based decoder instead of CKY, and it imposes no hard hierarchical reordering constraints during training and decoding-this paper sets out to challenge the commonly held belief that the tree-based parameterization of systems such as Hiero and Joshua is crucial to their good performance against Moses.", "labels": [], "entities": []}], "introductionContent": [{"text": "Phrase-based machine translation models () advanced the state of the art by extending the basic translation unit from words to phrases.", "labels": [], "entities": [{"text": "Phrase-based machine translation", "start_pos": 0, "end_pos": 32, "type": "TASK", "confidence": 0.6526597440242767}]}, {"text": "By conditioning translations on more than a single word, a statistical machine translation (SMT) system benefits from the larger context of a phrase pair to properly handle multi-word units and local reorderings.", "labels": [], "entities": [{"text": "statistical machine translation (SMT)", "start_pos": 59, "end_pos": 96, "type": "TASK", "confidence": 0.770507295926412}]}, {"text": "Experimentally, it was found that longer phrases yield better MT output (.", "labels": [], "entities": [{"text": "MT", "start_pos": 62, "end_pos": 64, "type": "TASK", "confidence": 0.9547496438026428}]}, {"text": "However, while it is computationally feasible at training time to extract phrase pairs of nearly unbounded size (), phrase pairs applicable attest time tend to be fairly short.", "labels": [], "entities": []}, {"text": "Indeed, data sparsity often forces conventional phrase-based systems to segment test sentences into small phrases, and therefore to translate dependent words (e.g., the French ne . .", "labels": [], "entities": []}, {"text": "pas) separately instead of jointly.", "labels": [], "entities": []}, {"text": "We present a solution to this sparsity problem by going beyond using only continuous phrases, and instead define our translation unit as any subset of words of a sentence, i.e., a discontinuous phrase.", "labels": [], "entities": []}, {"text": "We generalize conventional multi-beam string-based decoding) to allow variable-size discontinuities in both source and target phrases.", "labels": [], "entities": []}, {"text": "Since each sentence pair can be more flexibly decomposed into translation units, it is possible to exploit the rich context of longer (possibly discontinuous) phrases to improve translation quality.", "labels": [], "entities": []}, {"text": "Our decoder provides two extensions to Moses ( : (a) to cope with source gaps, we follow ( to efficiently find all discontinuous phrases in the training data that also appear in the input sentence; (b) to enable target discontinuities, we augment translation hypotheses to not only record the current partial translation, but also a set of subphrases that maybe appended to the partial translation at some later stages of decoding.", "labels": [], "entities": []}, {"text": "With these enhancements, our best discontinuous system outperforms Moses with lexicalized reordering by 0.77 BLEU and 1.53 TER points on average.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 109, "end_pos": 113, "type": "METRIC", "confidence": 0.9994513392448425}, {"text": "TER", "start_pos": 123, "end_pos": 126, "type": "METRIC", "confidence": 0.9979656934738159}]}, {"text": "We also show that our approach compares favorably to binary synchronous context-free grammar (2-SCFG) systems such as Hiero, even though 2-SCFG systems also allow phrasal discontinuities.", "labels": [], "entities": [{"text": "Hiero", "start_pos": 118, "end_pos": 123, "type": "DATASET", "confidence": 0.8651412725448608}]}, {"text": "Part of this difference maybe due to a difference of expressiveness, since 2-SCFG models impose hard hierarchical constraints that our models do not impose.", "labels": [], "entities": []}, {"text": "Recent work Figure 1: 2-SCFG systems such as Hiero are unable to independently generate translation units a, b, c, and d with the following types of alignments: (i) inside-out (Wu, 1997); (ii) cross-serial DTU; (iii) \"bonbon\" ().", "labels": [], "entities": [{"text": "Hiero", "start_pos": 45, "end_pos": 50, "type": "DATASET", "confidence": 0.9326303601264954}]}, {"text": "Standard phrasebased decoders cope with (i), but not (ii) and (iii).", "labels": [], "entities": []}, {"text": "Our phrase-based decoder handles all three cases.) has questioned the empirical adequacy of 2-SCFG systems, which are unable to perform any of the transformations shown in.", "labels": [], "entities": []}, {"text": "For instance, using manually-aligned bitexts for 12 European languages pairs, S\u00f8gaard and Kuhn found that insideout and cross-serial discontinuous translation units (DTU) account for 1.6% (Danish-English) to 18.6% (French-English) of all translation units.", "labels": [], "entities": [{"text": "cross-serial discontinuous translation units (DTU)", "start_pos": 120, "end_pos": 170, "type": "METRIC", "confidence": 0.6884868783610207}]}, {"text": "The empirical adequacy of 2-SCFG models would presumably be lower with automatically-aligned texts and if the study also included non-European languages.", "labels": [], "entities": []}, {"text": "In contrast, phrase-based systems can properly handle inside-out alignments when used with a reasonably large distortion limit, and all configurations in are accounted for in our system.", "labels": [], "entities": []}, {"text": "In our experiments, we show that our discontinuous phrase-based system outperforms Joshua (), a reimplementation of Hiero, by 1.03 BLEU points and 1.19 TER points on average.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 131, "end_pos": 135, "type": "METRIC", "confidence": 0.9990917444229126}, {"text": "TER", "start_pos": 152, "end_pos": 155, "type": "METRIC", "confidence": 0.9989439845085144}]}, {"text": "A final compelling advantage of our decoder is that it preserves the computational efficiency of Moses (i.e., time complexity is linear when a distortion limit is used), while SCFG decoders have a running time that is at least cubic ().", "labels": [], "entities": []}], "datasetContent": [{"text": "Three systems are evaluated in this paper: Moses ( ), Joshua () -a reimplementation of Hiero, and our phrase-based system.", "labels": [], "entities": []}, {"text": "We made our best attempts to make our system comparable to Moses.", "labels": [], "entities": []}, {"text": "That is, when no discontinuous phrases are provided to our system, it generates an output that is almost identical to Moses (only about 1% of translations differ on average).", "labels": [], "entities": []}, {"text": "In both systems, we use the default settings of Moses, i.e., we set the beam size to 200, the distortion limit to 6, we limit to 20 the number of target phrases that are loaded for each source phrase, and we use the same default eight features of Moses.", "labels": [], "entities": [{"text": "distortion", "start_pos": 94, "end_pos": 104, "type": "METRIC", "confidence": 0.9664926528930664}]}, {"text": "We use version 1.3 of Joshua with its default settings.", "labels": [], "entities": []}, {"text": "Both Moses and our system are evaluated with and without lexicalized reordering).", "labels": [], "entities": []}, {"text": "We believe it to be fair to compare Joshua against phrase-based systems that exploit lexicalized reordering, since Hiero's hierarchical rules are also lexically sensitive.", "labels": [], "entities": []}, {"text": "The language pair for our experiments is Chineseto-English.", "labels": [], "entities": []}, {"text": "The training data consists of about 28 million English words and 23.3 million Chinese words drawn from various news parallel corpora distributed by the Linguistic Data Consortium (LDC).", "labels": [], "entities": []}, {"text": "In order to provide experiments comparable to previous work, we used the same corpora as (.", "labels": [], "entities": []}, {"text": "We performed word alignment using a cross-EM word aligner ().", "labels": [], "entities": [{"text": "word alignment", "start_pos": 13, "end_pos": 27, "type": "TASK", "confidence": 0.8031889498233795}]}, {"text": "For this, we ran two iterations of IBM Model 1 and two HMM iterations.", "labels": [], "entities": [{"text": "IBM Model 1", "start_pos": 35, "end_pos": 46, "type": "DATASET", "confidence": 0.9209433595339457}]}, {"text": "Finally, we generated asymmetric word alignment from cross-EM Viterbi alignment using the Moses grow-diag heuristic in the case Moses and our system.", "labels": [], "entities": []}, {"text": "In the case of Joshua, we used the growdiag-final heuristic since this gave better results.", "labels": [], "entities": []}, {"text": "In order to train a competitive baseline given our computational resources, we built a large 5-gram language model using the Xinhua and AFP sections We use Moses' default orientations: monotone, swap, and discontinuous.", "labels": [], "entities": [{"text": "AFP", "start_pos": 136, "end_pos": 139, "type": "DATASET", "confidence": 0.906328558921814}]}, {"text": "As far as this reordering model is concerned, we treat discontinuous phrases as continuous, i.e., we simply ignore what lies within gaps to determine phrase orientation.", "labels": [], "entities": [{"text": "phrase orientation", "start_pos": 150, "end_pos": 168, "type": "TASK", "confidence": 0.7214973568916321}]}, {"text": "5) learns for each phrase a tendency to either remain monotone or to swap with other phrases.", "labels": [], "entities": []}, {"text": "As noted in, Hiero can represent the same information with hierarchical rules of the form uX, Xu, and XuX.", "labels": [], "entities": [{"text": "Hiero", "start_pos": 13, "end_pos": 18, "type": "DATASET", "confidence": 0.8961018323898315}]}, {"text": "Hiero actually models lexicalized reordering patterns that () does not account for, e.g., a transformation from of the Gigaword corpus (LDC2007T40) in addition to the target side of the parallel data.", "labels": [], "entities": [{"text": "Gigaword corpus (LDC2007T40)", "start_pos": 119, "end_pos": 147, "type": "DATASET", "confidence": 0.9231275916099548}]}, {"text": "This data represents a total of about 700 million words.", "labels": [], "entities": []}, {"text": "We manually removed documents of Gigaword that were released during periods that overlap with those of our development and test sets.", "labels": [], "entities": []}, {"text": "The language model was smoothed with the modified Kneser-Ney algorithm as implemented in SRILM), and we only kept 4-grams and 5-grams that occurred at least three times in the training data.", "labels": [], "entities": [{"text": "SRILM", "start_pos": 89, "end_pos": 94, "type": "DATASET", "confidence": 0.838512122631073}]}, {"text": "For tuning and testing, we use the official NIST MT evaluation data for Chinese from, which all have four English references for each input sentence.", "labels": [], "entities": [{"text": "NIST MT evaluation data", "start_pos": 44, "end_pos": 67, "type": "DATASET", "confidence": 0.9013284295797348}]}, {"text": "We used the 1664 sentences of MT06 for tuning and development and all other sets for testing.", "labels": [], "entities": [{"text": "1664 sentences of MT06", "start_pos": 12, "end_pos": 34, "type": "DATASET", "confidence": 0.7255241721868515}]}, {"text": "Parameter tuning was done with minimum error rate training, which was used to maximize IBM BLEU-4 ().", "labels": [], "entities": [{"text": "Parameter tuning", "start_pos": 0, "end_pos": 16, "type": "TASK", "confidence": 0.8587669730186462}, {"text": "IBM", "start_pos": 87, "end_pos": 90, "type": "METRIC", "confidence": 0.838700532913208}, {"text": "BLEU-4", "start_pos": 91, "end_pos": 97, "type": "METRIC", "confidence": 0.8641986846923828}]}, {"text": "Since MERT is prone to search errors, especially with large numbers of parameters, we ran each tuning experiment four times with different initial conditions.", "labels": [], "entities": [{"text": "MERT", "start_pos": 6, "end_pos": 10, "type": "METRIC", "confidence": 0.42662373185157776}]}, {"text": "We used n-best lists of size 200.", "labels": [], "entities": []}, {"text": "In the final evaluations, we report results using both TER version 0.7.25) and BLEU-4 (both uncased).", "labels": [], "entities": [{"text": "TER version 0.7.25", "start_pos": 55, "end_pos": 73, "type": "DATASET", "confidence": 0.7481489380200704}, {"text": "BLEU-4", "start_pos": 79, "end_pos": 85, "type": "METRIC", "confidence": 0.9966620206832886}]}], "tableCaptions": []}