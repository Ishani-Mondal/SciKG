{"title": [{"text": "Good Question! Statistical Ranking for Question Generation", "labels": [], "entities": [{"text": "Question Generation", "start_pos": 39, "end_pos": 58, "type": "TASK", "confidence": 0.7217534631490707}]}], "abstractContent": [{"text": "We address the challenge of automatically generating questions from reading materials for educational practice and assessment.", "labels": [], "entities": []}, {"text": "Our approach is to overgenerate questions, then rank them.", "labels": [], "entities": []}, {"text": "We use manually written rules to perform a sequence of general purpose syntactic transformations (e.g., subject-auxiliary inversion) to turn declarative sentences into questions.", "labels": [], "entities": []}, {"text": "These questions are then ranked by a logistic regression model trained on a small, tailored dataset consisting of labeled output from our system.", "labels": [], "entities": []}, {"text": "Experimental results show that ranking nearly doubles the percentage of questions rated as acceptable by annotators, from 27% of all questions to 52% of the top ranked 20% of questions.", "labels": [], "entities": []}], "introductionContent": [{"text": "In this paper, we focus on question generation (QG) for the creation of educational materials for reading practice and assessment.", "labels": [], "entities": [{"text": "question generation (QG)", "start_pos": 27, "end_pos": 51, "type": "TASK", "confidence": 0.8388333678245544}]}, {"text": "Our goal is to generate fact-based questions about the content of a given article.", "labels": [], "entities": []}, {"text": "The top-ranked questions could be filtered and revised by educators, or given directly to students for practice.", "labels": [], "entities": []}, {"text": "Here we restrict our investigation to questions about factual information in texts.", "labels": [], "entities": []}, {"text": "We begin with a motivating example.", "labels": [], "entities": []}, {"text": "Consider the following sentence from the Wikipedia article on the history of Los Angeles: 1 During the Gold Rush years in northern California, Los Angeles became known as the \"Queen of the Cow Counties\" for its role in supplying beef and other foodstuffs to hungry miners in the north.", "labels": [], "entities": []}, {"text": "Consider generating the following question from that sentence: What did Los Angeles become known as the \"Queen of the Cow Counties\" for?", "labels": [], "entities": []}, {"text": "We observe that the QG process can be viewed as a two-step process that essentially \"factors\" the problem into simpler components.", "labels": [], "entities": []}, {"text": "Rather than simultaneously trying to remove extraneous information and transform a declarative sentence into an interrogative one, we first transform the input sentence into a simpler sentence such as Los Angeles become known as the \"Queen of the Cow Counties\" for its role in supplying beef and other foodstuffs to hungry miners in the north, which we then can then transform into a more succinct question.", "labels": [], "entities": []}, {"text": "Question transformation involves complex long distance dependencies.", "labels": [], "entities": [{"text": "Question transformation", "start_pos": 0, "end_pos": 23, "type": "TASK", "confidence": 0.8046637773513794}]}, {"text": "For example, in the question about Los Angeles, the word what at the beginning of the sentence is a semantic argument of the verb phrase known as . .", "labels": [], "entities": []}, {"text": "at the end of the question.", "labels": [], "entities": []}, {"text": "The characteristics of such phenomena are (arguably) difficult to learn from corpora, but they have been studied extensively in linguistics.", "labels": [], "entities": []}, {"text": "We take a rule-based approach in order to leverage this linguistic knowledge.", "labels": [], "entities": []}, {"text": "However, since many phenomena pertaining to question generation are not so easily encoded with rules, we include statistical ranking as an integral component.", "labels": [], "entities": [{"text": "question generation", "start_pos": 44, "end_pos": 63, "type": "TASK", "confidence": 0.7437368929386139}]}, {"text": "Thus, we employ an overgenerate-andrank approach, which has been applied successfully in areas such as generation () and syntactic parsing.", "labels": [], "entities": [{"text": "syntactic parsing", "start_pos": 121, "end_pos": 138, "type": "TASK", "confidence": 0.7530463933944702}]}, {"text": "Since large datasets of the appropriate domain, style, and form of questions are not available to train our ranking model, we learn to rank from a relatively small, tailored dataset of humanlabeled output from our rule-based system.", "labels": [], "entities": []}, {"text": "The remainder of the paper is organized as fol-lows.", "labels": [], "entities": []}, {"text": "\u00a72 clarifies connections to prior work and enumerates our contributions.", "labels": [], "entities": []}, {"text": "\u00a73 discusses particular terms and conventions we will employ.", "labels": [], "entities": []}, {"text": "\u00a74 discusses rule-based question transformation.", "labels": [], "entities": [{"text": "rule-based question transformation", "start_pos": 13, "end_pos": 47, "type": "TASK", "confidence": 0.619675894578298}]}, {"text": "\u00a75 describes the data used to learn and to evaluate our question ranking model, and \u00a76 then follows with details on the ranking approach itself.", "labels": [], "entities": [{"text": "question ranking", "start_pos": 56, "end_pos": 72, "type": "TASK", "confidence": 0.7350678145885468}]}, {"text": "We then present and discuss results from an evaluation of ranked question output in \u00a77 and conclude in \u00a78.", "labels": [], "entities": []}], "datasetContent": [{"text": "This section describes the results of experiments to evaluate the quality of generated questions before and after ranking.", "labels": [], "entities": []}, {"text": "Results are aggregated across the 3 corpora ( \u00a75.1).", "labels": [], "entities": []}, {"text": "The evaluation metric we employ is the percentage of test set questions labeled as acceptable.", "labels": [], "entities": []}, {"text": "For rankings, our metric is the percentage of the top N % labeled as acceptable, for various N .", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: The total numbers of features (#) and the per- centages of the top 20% and 40% of ranked test set ques- tions labeled acceptable, for rankers built from variations  of the complete set of features (\"All\"). E.g., \"All -WH\"  is the set of all features except WH word features.", "labels": [], "entities": []}]}