{"title": [{"text": "Streaming First Story Detection with application to Twitter", "labels": [], "entities": [{"text": "Streaming First Story Detection", "start_pos": 0, "end_pos": 31, "type": "TASK", "confidence": 0.545596532523632}]}], "abstractContent": [{"text": "With the recent rise in popularity and size of social media, there is a growing need for systems that can extract useful information from this amount of data.", "labels": [], "entities": []}, {"text": "We address the problem of detecting new events from a stream of Twitter posts.", "labels": [], "entities": []}, {"text": "To make event detection feasible on web-scale corpora, we present an algorithm based on locality-sensitive hashing which is able overcome the limitations of traditional approaches, while maintaining competitive results.", "labels": [], "entities": [{"text": "event detection", "start_pos": 8, "end_pos": 23, "type": "TASK", "confidence": 0.8080896437168121}]}, {"text": "In particular, a comparison with a state-of-the-art system on the first story detection task shows that we achieve over an order of magnitude speedup in processing time, while retaining comparable performance.", "labels": [], "entities": [{"text": "story detection task", "start_pos": 72, "end_pos": 92, "type": "TASK", "confidence": 0.7885917524496714}]}, {"text": "Event detection experiments on a collection of 160 million Twitter posts show that celebrity deaths are the fastest spreading news on Twitter.", "labels": [], "entities": [{"text": "Event detection", "start_pos": 0, "end_pos": 15, "type": "TASK", "confidence": 0.7661886513233185}]}], "introductionContent": [{"text": "In the recent years, the microblogging service Twitter has become a very popular tool for expressing opinions, broadcasting news, and simply communicating with friends.", "labels": [], "entities": []}, {"text": "People often comment on events in real time, with several hundred micro-blogs (tweets) posted each second for significant events.", "labels": [], "entities": []}, {"text": "Twitter is not only interesting because of this realtime response, but also because it is sometimes ahead of newswire.", "labels": [], "entities": []}, {"text": "For example, during the protests following Iranian presidential elections in 2009, Iranian people first posted news on Twitter, where they were later picked up by major broadcasting corporations.", "labels": [], "entities": []}, {"text": "Another example was the swine flu outbreak when the US Centre for disease control (CDC) used Twitter to post latest updates on the pandemic.", "labels": [], "entities": []}, {"text": "In addition to this, subjective opinion expressed in posts is also an important feature that sets Twitter apart from traditional newswire.", "labels": [], "entities": []}, {"text": "New event detection, also known as first story detection (FSD) 1 is defined within the topic detection and tracking as one of the subtasks.", "labels": [], "entities": [{"text": "New event detection", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.671838233868281}, {"text": "first story detection (FSD) 1", "start_pos": 35, "end_pos": 64, "type": "METRIC", "confidence": 0.6420321762561798}, {"text": "topic detection and tracking", "start_pos": 87, "end_pos": 115, "type": "TASK", "confidence": 0.8002825975418091}]}, {"text": "Given a sequence of stories, the goal of FSD is to identify the first story to discuss a particular event.", "labels": [], "entities": [{"text": "FSD", "start_pos": 41, "end_pos": 44, "type": "TASK", "confidence": 0.9742717146873474}]}, {"text": "In this context, an event is taken to be something that happens at some specific time and place, e.g., an earthquake striking the town of L'Aquila in Italy on April 6th 2009.", "labels": [], "entities": []}, {"text": "Detecting new events from tweets carries additional problems and benefits compared to traditional new event detection from newswire.", "labels": [], "entities": [{"text": "Detecting new events from tweets", "start_pos": 0, "end_pos": 32, "type": "TASK", "confidence": 0.8927200317382813}]}, {"text": "Problems include a much higher volume of data to deal with and also a higher level of noise.", "labels": [], "entities": []}, {"text": "A major benefit of doing new event detection from tweets is the added social component -we can understand the impact an event had and how people reacted to it.", "labels": [], "entities": [{"text": "event detection", "start_pos": 29, "end_pos": 44, "type": "TASK", "confidence": 0.8079498708248138}]}, {"text": "The speed and volume at which data is coming from Twitter warrants the use of streaming algorithms to make first story detection feasible.", "labels": [], "entities": [{"text": "first story detection", "start_pos": 107, "end_pos": 128, "type": "TASK", "confidence": 0.7773542006810507}]}, {"text": "In the streaming model of computation), items (tweets in our case) arrive continuously in a chronological order, and we have to process each new one in bounded space and time.", "labels": [], "entities": []}, {"text": "Recent examples of problems set in the streaming model include stream-based machine translation (, approximating kernel matrices of data streams, and topic modelling on streaming document collections ().", "labels": [], "entities": [{"text": "stream-based machine translation", "start_pos": 63, "end_pos": 95, "type": "TASK", "confidence": 0.615107258160909}]}, {"text": "The traditional approach to FSD, where each new story is compared to all, or a constantly growing subset, of previously seen stories, does not scale to the Twitter streaming setting.", "labels": [], "entities": [{"text": "FSD", "start_pos": 28, "end_pos": 31, "type": "TASK", "confidence": 0.9789496660232544}]}, {"text": "We present a FSD system that works in the streaming model and takes constant time to process each new document, while also using constant space.", "labels": [], "entities": []}, {"text": "Constant processing time is achieved by employing locality sensitive hashing (LSH)), a randomized technique that dramatically reduces the time needed to find a nearest neighbor in vector space, and the space saving is achieved by keeping the amount of stories in memory constant.", "labels": [], "entities": []}, {"text": "We find that simply applying pure LSH in a FSD task yields poor performance and a high variance in results, and so introduce a modification which virtually eliminates variance and significantly improves performance.", "labels": [], "entities": [{"text": "FSD task", "start_pos": 43, "end_pos": 51, "type": "TASK", "confidence": 0.8720079958438873}]}, {"text": "We show that our FSD system gives comparable results as a state-of-the-art system on the standard TDT5 dataset, while achieving an order of magnitude speedup.", "labels": [], "entities": [{"text": "TDT5 dataset", "start_pos": 98, "end_pos": 110, "type": "DATASET", "confidence": 0.9858424961566925}]}, {"text": "Using our system for event detection on 160 million Twitter posts shows that i) the number of users that write about an event is more indicative than the volume of tweets written about it, ii) spam tweets can be detected with reasonable precision, and iii) news about deaths of famous people spreads the fastest on Twitter.", "labels": [], "entities": [{"text": "event detection", "start_pos": 21, "end_pos": 36, "type": "TASK", "confidence": 0.7326212823390961}, {"text": "precision", "start_pos": 237, "end_pos": 246, "type": "METRIC", "confidence": 0.9895755052566528}]}], "datasetContent": [{"text": "Before applying our FSD system on Twitter data, we first compared it to a state-of-theart FSD system on the standard TDT5 dataset.", "labels": [], "entities": [{"text": "TDT5 dataset", "start_pos": 117, "end_pos": 129, "type": "DATASET", "confidence": 0.9910123646259308}]}, {"text": "This way, we can test if our system is on par with the best existing systems, and also accurately measure the speedup that we get over a traditional approach.", "labels": [], "entities": []}, {"text": "In particular, we compare our system with the UMass FSD system ().", "labels": [], "entities": [{"text": "UMass FSD system", "start_pos": 46, "end_pos": 62, "type": "DATASET", "confidence": 0.8578417698542277}]}, {"text": "The UMass system has participated in the TDT2 and TDT3 competitions and is known to perform at least as well as other existing systems who also took part in the competition.", "labels": [], "entities": [{"text": "UMass", "start_pos": 4, "end_pos": 9, "type": "DATASET", "confidence": 0.9006993174552917}, {"text": "TDT2", "start_pos": 41, "end_pos": 45, "type": "DATASET", "confidence": 0.7747924327850342}, {"text": "TDT3", "start_pos": 50, "end_pos": 54, "type": "DATASET", "confidence": 0.4687258303165436}]}, {"text": "Note that the UMass system uses an inverted index (as shown in Algorithm 1) which optimizes the system for speed and makes sure a minimal number of comparisons is made.", "labels": [], "entities": []}, {"text": "We compare the systems on the English part of the TDT5 dataset, consisting of 221, 306 documents from a time period spanning April 2003 to September 2003.", "labels": [], "entities": [{"text": "TDT5 dataset", "start_pos": 50, "end_pos": 62, "type": "DATASET", "confidence": 0.9736514091491699}]}, {"text": "To make sure that any difference in results is due to approximations we make, we use the same settings as the UMass system: 1-NN clustering, cosine as a similarity measure, and TFIDF weighted document representation, where the IDF weights are incrementally updated.", "labels": [], "entities": []}, {"text": "These particular settings were found by to perform the best for the FSD task.", "labels": [], "entities": [{"text": "FSD task", "start_pos": 68, "end_pos": 76, "type": "TASK", "confidence": 0.9058415293693542}]}, {"text": "We limit both systems to keeping only top 300 features in each document.", "labels": [], "entities": []}, {"text": "Using more than 300 features barely improves performance while taking significantly more time for the UMass system.", "labels": [], "entities": []}, {"text": "In addition, our system has two LSH parameters that need to beset.", "labels": [], "entities": [{"text": "LSH", "start_pos": 32, "end_pos": 35, "type": "METRIC", "confidence": 0.7273565530776978}]}, {"text": "The number of hyperplanes k gives a tradeoff between time spent computing the hash functions and the time spent computing the distances.", "labels": [], "entities": []}, {"text": "A lower k means more documents per bucket and thus more distance computations, whereas a higher k means less documents per bucket, but more hash tables and thus more time spent computing hash functions.", "labels": [], "entities": []}, {"text": "Given k, we can use equation to compute L.", "labels": [], "entities": []}, {"text": "In our case, we chose k to be 13, and L such that the probability of missing a neighbor within the distance of 0.2 is less than 2.5%.", "labels": [], "entities": []}, {"text": "The distance of 0.2 was chosen as a reasonable estimate of the threshold when two documents are very similar.", "labels": [], "entities": [{"text": "distance", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.9572681784629822}]}, {"text": "In general, this distance will depend on the application, and suggest guessing the value and then doing a binary search to set it more accurately.", "labels": [], "entities": []}, {"text": "We set k to 13 be-cause it achieved a reasonable balance between time spent computing the distances and the time spent computing the hash functions.", "labels": [], "entities": []}, {"text": "The official TDT evaluation requires each system to assign a confidence score for its decision, and this assignment can be made either immediately after the story arrives, or after a fixed number of new stories have been observed.", "labels": [], "entities": [{"text": "TDT", "start_pos": 13, "end_pos": 16, "type": "TASK", "confidence": 0.7155125737190247}]}, {"text": "Because we assume that we are working in a true streaming setting, systems are required to assign a confidence score as soon as the new story arrives.", "labels": [], "entities": []}, {"text": "The actual performance of a system is measured in terms of detection error tradeoff (DET) curves and the minimal normalized cost.", "labels": [], "entities": [{"text": "detection error tradeoff (DET)", "start_pos": 59, "end_pos": 89, "type": "METRIC", "confidence": 0.946003645658493}]}, {"text": "Evaluation is carried out by first sorting all stories according to their scores and then performing a threshold sweep.", "labels": [], "entities": []}, {"text": "For each value of the threshold, stories with a score above the threshold are considered new, and all others are considered old.", "labels": [], "entities": []}, {"text": "Therefore, for each threshold value, one can compute the probability of a false alarm, i.e., probability of declaring a story new when it is actually not, and the miss probability, i.e., probability of declaring anew story old (missing anew story).", "labels": [], "entities": [{"text": "miss probability", "start_pos": 163, "end_pos": 179, "type": "METRIC", "confidence": 0.9854220449924469}]}, {"text": "Having computed all the miss and false alarm probabilities, we can plot them on a graph showing the tradeoff between these two quantities -such graphs are called detection error tradeoff curves.", "labels": [], "entities": []}, {"text": "The normalized cost C det is computed as where C miss and C FA are costs of miss and false alarm, P miss and P FA are probabilities of amiss and false alarm, and P target and P non\u2212target are the prior target and non-target probabilities.", "labels": [], "entities": [{"text": "FA", "start_pos": 60, "end_pos": 62, "type": "METRIC", "confidence": 0.8348045945167542}, {"text": "P miss and P FA", "start_pos": 98, "end_pos": 113, "type": "METRIC", "confidence": 0.5742232799530029}]}, {"text": "Minimal normalized cost C min is the minimal value of C det overall threshold values (a lower value of C min indicates better performance).", "labels": [], "entities": [{"text": "normalized cost C min", "start_pos": 8, "end_pos": 29, "type": "METRIC", "confidence": 0.6169049218297005}]}, {"text": "We used our streaming FSD system to detect new events from a collection of Twitter data gathered over a period of six months (April 1st 2009 to October 14th 2009).", "labels": [], "entities": [{"text": "April 1st 2009 to October 14th 2009)", "start_pos": 126, "end_pos": 162, "type": "DATASET", "confidence": 0.6136917993426323}]}, {"text": "Data was collected through Twitter's streaming API.", "labels": [], "entities": []}, {"text": "Our corpus consists of 163.5 million timestamped tweets, totalling over 2 billion tokens.", "labels": [], "entities": []}, {"text": "All the tweets in our corpus contain only ASCII characters and we additionally stripped the tweets of words beginning with the @ or # symbol.", "labels": [], "entities": []}, {"text": "This is because on Twitter words beginning with @ indicate a reply to someone, and words beginning with # are topic tags.", "labels": [], "entities": []}, {"text": "Although these features would probably be helpful for our task, we decided not to use them as they are specific to Twitter and our approach should be independent of the stream type.", "labels": [], "entities": []}, {"text": "In order to measure how well our system performs on the Twitter data, we employed two human experts to manually label all the tweets returned by our system as either Event, Neutral, or Spam.", "labels": [], "entities": []}, {"text": "Note that each tweet that is returned by our system is actually the first tweet in a thread, and thus serves as the representative of what the thread is about.", "labels": [], "entities": []}, {"text": "Spam tweets include various advertisements, automatic weather updates, automatic radio station updates, etc.", "labels": [], "entities": []}, {"text": "For a tweet to be labeled as an event, it had to be clear from the tweet alone what exactly happened without having any prior knowledge about the event, and the event referenced in the tweet had to be sufficiently important.", "labels": [], "entities": []}, {"text": "Important events include celebrity deaths, natural disasters, major sports, political, entertainment, and business events, shootings, plane crashes and other disasters.", "labels": [], "entities": []}, {"text": "Neutral tweets include everything not labeled as spam or event.", "labels": [], "entities": []}, {"text": "Because the process of manual labeling is tedious and time-consuming, we only labeled the 1000 fastest growing threads from June 2009.", "labels": [], "entities": []}, {"text": "Rate of growth of a thread is measured by the number of tweets that belong to that thread in a window of 100,000 tweets, starting from the beginning of the thread.", "labels": [], "entities": [{"text": "Rate", "start_pos": 0, "end_pos": 4, "type": "METRIC", "confidence": 0.9674578905105591}]}, {"text": "Agreement between our two annotators, measured using Cohen's kappa coefficient, was substantial (kappa = 0.65).", "labels": [], "entities": [{"text": "Agreement", "start_pos": 0, "end_pos": 9, "type": "METRIC", "confidence": 0.9821943044662476}]}, {"text": "We use 820 tweets on which both annotators agreed as the gold standard.", "labels": [], "entities": []}, {"text": "Evaluation is performed by computing average precision (AP) on the gold standard sorted according to different criteria, where event tweets are taken to be relevant, and neutral and spam tweets are treated as non-relevant documents.", "labels": [], "entities": [{"text": "average precision (AP)", "start_pos": 37, "end_pos": 59, "type": "METRIC", "confidence": 0.8736213326454163}]}, {"text": "Average precision is a common evaluation metric in tasks like ad-hoc retrieval where only the set of returned documents and their relevance judgements are available, as is the case here.", "labels": [], "entities": [{"text": "precision", "start_pos": 8, "end_pos": 17, "type": "METRIC", "confidence": 0.693386971950531}]}, {"text": "Note that we are not evaluating our FSD system here.", "labels": [], "entities": [{"text": "FSD", "start_pos": 36, "end_pos": 39, "type": "TASK", "confidence": 0.7697464227676392}]}, {"text": "There are two main reasons for this: i) we already have a very good idea about the first story detection performance from the experiments on TDT5 data, and ii) evaluating a FSD system on this scale would be prohibitively expensive as it would involve human experts going through 30 million tweets looking for first stories.", "labels": [], "entities": [{"text": "first story detection", "start_pos": 83, "end_pos": 104, "type": "TASK", "confidence": 0.6078911324342092}, {"text": "TDT5 data", "start_pos": 141, "end_pos": 150, "type": "DATASET", "confidence": 0.9642298817634583}]}, {"text": "Rather, we are evaluating different methods of ranking threads which are output from a FSD system for the purpose of detecting important events in a very noisy and unstructured stream such as Twitter.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Summary of TDT5 results. Numbers next to LSH  ts indicate the maximal number of documents in a bucket,  measured in terms of percentage of the expected number of collisions.", "labels": [], "entities": [{"text": "LSH", "start_pos": 51, "end_pos": 54, "type": "METRIC", "confidence": 0.8975319266319275}]}, {"text": " Table 2: Average precision for Events vs. Rest and for  Events and Neutral vs. Spam.", "labels": [], "entities": [{"text": "Average", "start_pos": 10, "end_pos": 17, "type": "METRIC", "confidence": 0.9721680879592896}, {"text": "precision", "start_pos": 18, "end_pos": 27, "type": "METRIC", "confidence": 0.9361456036567688}]}, {"text": " Table 3: Average precision as a function of the entropy  threshold on the Events vs. Rest task.", "labels": [], "entities": [{"text": "precision", "start_pos": 18, "end_pos": 27, "type": "METRIC", "confidence": 0.9228328466415405}]}]}