{"title": [{"text": "Syntactic/Semantic Structures for Textual Entailment Recognition", "labels": [], "entities": [{"text": "Textual Entailment Recognition", "start_pos": 34, "end_pos": 64, "type": "TASK", "confidence": 0.829456647237142}]}], "abstractContent": [{"text": "In this paper, we describe an approach based on off-the-shelf parsers and semantic resources for the Recognizing Textual Entail-ment (RTE) challenge that can be generally applied to any domain.", "labels": [], "entities": [{"text": "Recognizing Textual Entail-ment (RTE) challenge", "start_pos": 101, "end_pos": 148, "type": "TASK", "confidence": 0.6874193676880428}]}, {"text": "Syntax is exploited by means of tree kernels whereas lexical semantics is derived from heterogeneous resources , e.g. WordNet or distributional semantics through Wikipedia.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 118, "end_pos": 125, "type": "DATASET", "confidence": 0.9202919006347656}]}, {"text": "The joint syn-tactic/semantic model is realized by means of tree kernels, which can exploit lexical related-ness to match syntactically similar structures, i.e. whose lexical compounds are related.", "labels": [], "entities": []}, {"text": "The comparative experiments across different RTE challenges and traditional systems show that our approach consistently and meaningfully achieves high accuracy, without requiring any adaptation or tuning.", "labels": [], "entities": [{"text": "RTE", "start_pos": 45, "end_pos": 48, "type": "TASK", "confidence": 0.9194400906562805}, {"text": "accuracy", "start_pos": 151, "end_pos": 159, "type": "METRIC", "confidence": 0.998749852180481}]}], "introductionContent": [{"text": "Recognizing Textual Entailment (RTE) is rather challenging as effectively modeling syntactic and semantic for this task is difficult.", "labels": [], "entities": [{"text": "Recognizing Textual Entailment (RTE)", "start_pos": 0, "end_pos": 36, "type": "TASK", "confidence": 0.8597297072410583}]}, {"text": "Early deep semantic models (e.g.,) as well as more recent ones (e.g.,) rely on specific world knowledge encoded in rules for drawing decisions.", "labels": [], "entities": []}, {"text": "Shallower models exploit matching methods between syntactic/semantic graphs of texts and hypotheses).", "labels": [], "entities": []}, {"text": "The matching step is carried out after the application of some lexical-syntactic rules that are used to transform the text T or the hypothesis H ( at surface form level.", "labels": [], "entities": []}, {"text": "For all these methods, the effective use of syntactic and semantic information depends on the coverage and the quality of the specific rules.", "labels": [], "entities": []}, {"text": "Lexical-syntactic rules can be automatically extracted from plain corpora (e.g.,) but the quality (also in terms of little noise) and the coverage is low.", "labels": [], "entities": [{"text": "coverage", "start_pos": 138, "end_pos": 146, "type": "METRIC", "confidence": 0.9826229810714722}]}, {"text": "In contrast, rules written at the semantic level are more accurate but their automatic design is difficult and so they are typically hand-coded for the specific phenomena.", "labels": [], "entities": []}, {"text": "In this paper, we propose models for effectively using syntactic and semantic information in RTE, without requiring either large automatic rule acquisition or hand-coding.", "labels": [], "entities": [{"text": "RTE", "start_pos": 93, "end_pos": 96, "type": "TASK", "confidence": 0.9168306589126587}, {"text": "rule acquisition", "start_pos": 139, "end_pos": 155, "type": "TASK", "confidence": 0.7148967981338501}]}, {"text": "These models exploit lexical similarities to generalize lexical-syntactic rules automatically derived by supervised learning methods.", "labels": [], "entities": []}, {"text": "In more detail, syntax is encoded in the form of parse trees whereas similarities are defined by means of WordNet simlilarity measures or Latent Semantic Analysis (LSA) applied to Wikipedia or to the British National Corpus (BNC).", "labels": [], "entities": [{"text": "British National Corpus (BNC)", "start_pos": 200, "end_pos": 229, "type": "DATASET", "confidence": 0.9673643410205841}]}, {"text": "The joint syntactic/semantic model is realized by means of novel tree kernels, which can match subtrees whose leaves are lexically similar (so not just identical).", "labels": [], "entities": []}, {"text": "To assess the benefit of our approach, we carried out comparative experiments with previous work: especially with the method described in (.", "labels": [], "entities": []}, {"text": "This constitutes our strong baseline as, although it can only exploit lexical-syntactic rules, it has achieved top accuracy in all RTE challenges.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 115, "end_pos": 123, "type": "METRIC", "confidence": 0.9992892742156982}, {"text": "RTE", "start_pos": 131, "end_pos": 134, "type": "TASK", "confidence": 0.9012007117271423}]}, {"text": "The results, across different RTE challenges, show that our approach constantly and significantly improves the baseline model.", "labels": [], "entities": [{"text": "RTE", "start_pos": 30, "end_pos": 33, "type": "TASK", "confidence": 0.9259675145149231}]}, {"text": "Moreover, our approach does not require any adaptation or tuning and uses a computation for the similarity function based on Wikipedia which is faster than the computation of tools based on WordNet or other resources ( ).", "labels": [], "entities": [{"text": "WordNet", "start_pos": 190, "end_pos": 197, "type": "DATASET", "confidence": 0.9384866952896118}]}, {"text": "The remainder of the paper is organized as follows: Section 2 critically reviews the previous work by highlighting the need of generalizing lexicosyntactic rules.", "labels": [], "entities": []}, {"text": "Section 3 describes lexical similarity approaches, which can serve the generalization purpose.", "labels": [], "entities": []}, {"text": "Section 4 describes how to integrate lexical similarity in syntactic structures using syntactic/semantic tree kernels (SSTK) whereas Section 5 shows how to use SSTK in a kernel-based RTE system.", "labels": [], "entities": []}, {"text": "Section 6 describes the experiments and results.", "labels": [], "entities": []}, {"text": "Section 7 discusses the efficiency and accuracy of our system compared with other RTE systems.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 39, "end_pos": 47, "type": "METRIC", "confidence": 0.9996097683906555}]}, {"text": "Finally, we draw the conclusions in Section 8.", "labels": [], "entities": []}], "datasetContent": [{"text": "The aim of the experiments is to investigate if our RTE system exploiting syntactic semantic kernels (SSTK) can effectively derive generalized lexicosyntactic rules.", "labels": [], "entities": []}, {"text": "In more detail, first, we determine the best lexical similarity suitable for the task, i.e. For this purpose, we tested four different version of SSTK, i.e. using Path, WUP, BNC and WIKI lexical similarities on three different RTE datasets.", "labels": [], "entities": [{"text": "BNC", "start_pos": 174, "end_pos": 177, "type": "METRIC", "confidence": 0.7380263805389404}, {"text": "RTE datasets", "start_pos": 227, "end_pos": 239, "type": "DATASET", "confidence": 0.7745437324047089}]}, {"text": "These correspond to the three different challenges in which the development set was provided.", "labels": [], "entities": []}, {"text": "We used the data from three recognizing textual entailment challenge: RTE2 (), RTE3 (, and RTE5, along with the standard split between training and test sets.", "labels": [], "entities": [{"text": "RTE2", "start_pos": 70, "end_pos": 74, "type": "DATASET", "confidence": 0.9101753234863281}, {"text": "RTE3", "start_pos": 79, "end_pos": 83, "type": "DATASET", "confidence": 0.7291320562362671}, {"text": "RTE5", "start_pos": 91, "end_pos": 95, "type": "DATASET", "confidence": 0.8351109027862549}]}, {"text": "We did not use RTE1 as it was differently built from the others and RTE4 as it does not contain the development set.", "labels": [], "entities": [{"text": "RTE1", "start_pos": 15, "end_pos": 19, "type": "DATASET", "confidence": 0.7612073421478271}, {"text": "RTE4", "start_pos": 68, "end_pos": 72, "type": "DATASET", "confidence": 0.9107813835144043}]}, {"text": "We used the following publicly available tools: the Charniak Parser) for parsing sentences and SVM-light-TK, in which we coded our new kernels for RTE.", "labels": [], "entities": [{"text": "parsing sentences", "start_pos": 73, "end_pos": 90, "type": "TASK", "confidence": 0.8752028942108154}]}, {"text": "Additionally, we used the Jiang&Conrath (J&C) distance) computed with wn::similarity package () to measure the similarity between T and H.", "labels": [], "entities": []}, {"text": "This similarity is also used to define the texthypothesis word overlap kernel (WOK).", "labels": [], "entities": []}, {"text": "The distributional semantics is captured by means of LSA: we used the java Latent Semantic Indexing (jLSI) tool.", "labels": [], "entities": []}, {"text": "In particular, we precomputed the word-pair matrices for RTE2, RTE3, and RTE5.", "labels": [], "entities": [{"text": "RTE2", "start_pos": 57, "end_pos": 61, "type": "DATASET", "confidence": 0.8681848645210266}, {"text": "RTE3", "start_pos": 63, "end_pos": 67, "type": "DATASET", "confidence": 0.7979752421379089}, {"text": "RTE5", "start_pos": 73, "end_pos": 77, "type": "DATASET", "confidence": 0.9090864658355713}]}, {"text": "We built different LSA matrices from the British National Corpus (BNC) and Wikipedia (Wiki).", "labels": [], "entities": [{"text": "British National Corpus (BNC)", "start_pos": 41, "end_pos": 70, "type": "DATASET", "confidence": 0.9680523375670115}]}, {"text": "The British National Corpus (BNC) is a balanced synchronic text corpus containing 100 million words with morpho-syntactic annotation.", "labels": [], "entities": [{"text": "British National Corpus (BNC)", "start_pos": 4, "end_pos": 33, "type": "DATASET", "confidence": 0.9719106554985046}]}, {"text": "For Wikipedia, we created a model from the 200,000 most visited Wikipedia articles, after cleaning the unnecessary markup tags.", "labels": [], "entities": []}, {"text": "Articles are our documents for creating the term-by-document matrix.", "labels": [], "entities": []}, {"text": "Wikipedia provides the largest coverage knowledge resource developed by a community, besides the noticeable coverage of named entities.", "labels": [], "entities": [{"text": "Wikipedia", "start_pos": 0, "end_pos": 9, "type": "DATASET", "confidence": 0.918783962726593}]}, {"text": "This further motivates the design of a similarity measure.", "labels": [], "entities": []}, {"text": "We also consider two typical WordNet similarities (i.e., Path and WUP, respectively) as described in Sec.", "labels": [], "entities": []}, {"text": "The main RTE model that we consider is constituted by three main kernels: \u2022 WOK, i.e. the kernel based on only the texthypothesis lexical overlapping words (this is an intra-pair similarity); \u2022 STK, i.e. the sum of the standard tree kernel (see Section 4.1) applied to the two text parsetrees and the two hypothesis parse trees; \u2022 SSTK, i.e. the same as STK with the use of lexical similarities as explained in Section 4.2; \u2022 maxSTK and maxSSTK, i.e. the kernel for RTE, illustrated in Section 5.2, where the latter exploits similarity since it uses SSTK in Eq.", "labels": [], "entities": []}, {"text": "5. Note that the model presented in (, our baseline, corresponds to the combination kernel: WOK+maxSTK.", "labels": [], "entities": []}, {"text": "In this paper, in addition to the role of lexical similarities, we also study several combinations (we just need to sum the separated kernels), i.e. WOK+STK+maxSTK, SSTK+maxSSTK, WOK+SSTK+maxSSTK and WOK+maxSSTK.", "labels": [], "entities": []}, {"text": "Finally, we measure the performance of our system with the standard accuracy and then we determine the statistical significance by using the model: Comparing different lexico-syntactic kernels with Wiki-based semantic kernels described in) and implemented in).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 68, "end_pos": 76, "type": "METRIC", "confidence": 0.9963353872299194}]}], "tableCaptions": [{"text": " Table 1: Accuracy of plain (WOK+STK+maxSTK) and Semantic Lexico-Syntactic (WOK+SSTK+maxSSTK) Ker- nels. The latter according to different similarities", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9785894751548767}]}, {"text": " Table 2: Comparing different lexico-syntactic kernels with Wiki-based semantic kernels", "labels": [], "entities": []}, {"text": " Table 4: The comparison in terms of speed calculated  over 10000 pairs after loading the model.", "labels": [], "entities": [{"text": "speed", "start_pos": 37, "end_pos": 42, "type": "METRIC", "confidence": 0.9838961362838745}]}, {"text": " Table 5: Comparison with other approaches to RTE", "labels": [], "entities": [{"text": "RTE", "start_pos": 46, "end_pos": 49, "type": "TASK", "confidence": 0.9542279243469238}]}]}