{"title": [{"text": "A Comparative Study of Word Co-occurrence for Term Clustering in Language Model-based Sentence Retrieval", "labels": [], "entities": [{"text": "Sentence Retrieval", "start_pos": 86, "end_pos": 104, "type": "TASK", "confidence": 0.7430746704339981}]}], "abstractContent": [{"text": "Sentence retrieval is a very important part of question answering systems.", "labels": [], "entities": [{"text": "Sentence retrieval", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.9575740993022919}, {"text": "question answering", "start_pos": 47, "end_pos": 65, "type": "TASK", "confidence": 0.8947538435459137}]}, {"text": "Term clustering, in turn, is an effective approach for improving sentence retrieval performance: the more similar the terms in each cluster, the better the performance of the retrieval system.", "labels": [], "entities": [{"text": "Term clustering", "start_pos": 0, "end_pos": 15, "type": "TASK", "confidence": 0.9006978571414948}, {"text": "sentence retrieval", "start_pos": 65, "end_pos": 83, "type": "TASK", "confidence": 0.7189343869686127}]}, {"text": "A key step in obtaining appropriate word clusters is accurate estimation of pairwise word similarities, based on their tendency to co-occur in similar contexts.", "labels": [], "entities": []}, {"text": "In this paper, we compare four different methods for estimating word co-occurrence frequencies from two different corpora.", "labels": [], "entities": []}, {"text": "The results show that different, commonly-used contexts for defining word co-occurrence differ significantly in retrieval performance.", "labels": [], "entities": []}, {"text": "Using an appropriate co-occurrence criterion and corpus is shown to improve the mean average precision of sentence retrieval form 36.8% to 42.1%.", "labels": [], "entities": [{"text": "precision", "start_pos": 93, "end_pos": 102, "type": "METRIC", "confidence": 0.922443687915802}]}, {"text": "1 Corpus-Driven Clustering of Terms Since the search in Question Answering (QA) is conducted over smaller segments of text than in document retrieval, the problems of data sparsity and exact matching become more critical.", "labels": [], "entities": [{"text": "Question Answering (QA)", "start_pos": 56, "end_pos": 79, "type": "TASK", "confidence": 0.8439882695674896}, {"text": "exact matching", "start_pos": 185, "end_pos": 199, "type": "TASK", "confidence": 0.7141354084014893}]}, {"text": "The idea of using class-based language model by applying term clustering , proposed by Momtazi and Klakow (2009), is found to be effective in overcoming these problems.", "labels": [], "entities": []}, {"text": "Term clustering has a very long history in natural language processing.", "labels": [], "entities": [{"text": "Term clustering", "start_pos": 0, "end_pos": 15, "type": "TASK", "confidence": 0.9586023688316345}, {"text": "natural language processing", "start_pos": 43, "end_pos": 70, "type": "TASK", "confidence": 0.6426840424537659}]}, {"text": "The idea was introduced by Brown et al.", "labels": [], "entities": []}, {"text": "(1992) and used in different applications , including speech recognition, named entity tagging, machine translation, query expansion, text categorization, and word sense disambiguation.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 54, "end_pos": 72, "type": "TASK", "confidence": 0.7913329303264618}, {"text": "named entity tagging", "start_pos": 74, "end_pos": 94, "type": "TASK", "confidence": 0.6700270275274912}, {"text": "machine translation", "start_pos": 96, "end_pos": 115, "type": "TASK", "confidence": 0.7992231249809265}, {"text": "query expansion", "start_pos": 117, "end_pos": 132, "type": "TASK", "confidence": 0.7139673978090286}, {"text": "word sense disambiguation", "start_pos": 159, "end_pos": 184, "type": "TASK", "confidence": 0.7094527284304301}]}, {"text": "In most of the studies in term clustering, one of several well-know notions of co-occurrence-appearing in the same document, in the same sentence or following the same word-has been used to estimate term similarity.", "labels": [], "entities": [{"text": "term clustering", "start_pos": 26, "end_pos": 41, "type": "TASK", "confidence": 0.7140049189329147}]}, {"text": "However, to the best of our knowledge, none of them explored the relationship between different notions of co-occurrence and the effectiveness of their resulting clusters in an end task.", "labels": [], "entities": []}, {"text": "In this research, we present a comprehensive study of how different notions of co-occurrence impact retrieval performance.", "labels": [], "entities": []}, {"text": "To this end, the Brown algorithm (Brown et al., 1992) is applied to pairwise word co-occurrence statistics based on different definitions of word co-occurrence.", "labels": [], "entities": []}, {"text": "Then, the word clusters are used in a class-based language model for sentence retrieval.", "labels": [], "entities": [{"text": "sentence retrieval", "start_pos": 69, "end_pos": 87, "type": "TASK", "confidence": 0.7439706325531006}]}, {"text": "Additionally, impact of corpus size and domain on co-occurrence estimation is studied.", "labels": [], "entities": []}, {"text": "The paper is organized as follows.", "labels": [], "entities": []}, {"text": "In Section 2, we give a brief description of class-based language model for sentence retrieval and the Brown word clustering algorithm.", "labels": [], "entities": [{"text": "sentence retrieval", "start_pos": 76, "end_pos": 94, "type": "TASK", "confidence": 0.7576555013656616}, {"text": "Brown word clustering", "start_pos": 103, "end_pos": 124, "type": "TASK", "confidence": 0.6111565629641215}]}, {"text": "Section 3 presents different methods for estimating the word co-occurrence.", "labels": [], "entities": []}, {"text": "In Section 4, experimental results are presented.", "labels": [], "entities": []}, {"text": "Finally , Section 5 summarizes the paper.", "labels": [], "entities": []}, {"text": "2 Term Clustering Method and Application In language model-based sentence retrieval, the probability P (Q|S) of generating query Q conditioned on a candidate sentence S is first calculated.", "labels": [], "entities": [{"text": "language model-based sentence retrieval", "start_pos": 44, "end_pos": 83, "type": "TASK", "confidence": 0.5896775349974632}]}, {"text": "Thereafter sentences in the search collection are ranked in descending order of this probability.", "labels": [], "entities": []}, {"text": "For word-based unigram, P (Q|S) is estimated as P (Q|S) = i=1...M P (q i |S), (1) where M is the number of query terms, q i denotes the i th query term in Q, and S is the sentence model.", "labels": [], "entities": []}], "introductionContent": [], "datasetContent": [], "tableCaptions": []}