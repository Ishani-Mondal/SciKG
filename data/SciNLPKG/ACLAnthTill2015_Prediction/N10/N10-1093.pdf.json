{"title": [{"text": "Improving Data Driven Dependency Parsing using Clausal Information \ud97b\udf59", "labels": [], "entities": [{"text": "Improving Data Driven Dependency Parsing", "start_pos": 0, "end_pos": 40, "type": "TASK", "confidence": 0.9189983606338501}, {"text": "Clausal Information", "start_pos": 47, "end_pos": 66, "type": "TASK", "confidence": 0.9229010939598083}]}], "abstractContent": [{"text": "The paper describes a data driven dependency parsing approach which uses clausal information of a sentence to improve the parser performance.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 34, "end_pos": 52, "type": "TASK", "confidence": 0.6932377219200134}]}, {"text": "The clausal information is added automatically during the parsing process.", "labels": [], "entities": [{"text": "parsing process", "start_pos": 58, "end_pos": 73, "type": "TASK", "confidence": 0.8925220668315887}]}, {"text": "We demonstrate the experiments on Hindi, a language with relatively rich case marking system and free-word-order.", "labels": [], "entities": []}, {"text": "All the experiments are done using a modified version of MSTParser.", "labels": [], "entities": [{"text": "MSTParser", "start_pos": 57, "end_pos": 66, "type": "DATASET", "confidence": 0.9675635695457458}]}, {"text": "We did all the experiments on the ICON 2009 parsing contest data.", "labels": [], "entities": [{"text": "ICON 2009 parsing contest data", "start_pos": 34, "end_pos": 64, "type": "DATASET", "confidence": 0.74932501912117}]}, {"text": "We achieved an improvement of 0.87% and 0.77% in unla-beled attachment and labeled attachment accuracies respectively over the baseline parsing accuracies.", "labels": [], "entities": []}], "introductionContent": [{"text": "Linguistic analysis of morphologically rich freeword-order languages (MoRFWO) using dependency framework have been argued to be more effective.", "labels": [], "entities": []}, {"text": "Not surprisingly, most parsers for such languages are dependency based (.", "labels": [], "entities": []}, {"text": "In spite of availability of annotated treebanks, stateof-the-art parsers for MoRFWO have not reached the performance obtained for English.", "labels": [], "entities": [{"text": "MoRFWO", "start_pos": 77, "end_pos": 83, "type": "DATASET", "confidence": 0.9204537868499756}]}, {"text": "Some of the reasons stated for the low performance are small treebank size, complex linguistic phenomenon, long-distance dependencies, and non-projective structures ().", "labels": [], "entities": []}, {"text": "Several approaches have been tried to handle these difficulties in such languages.", "labels": [], "entities": []}, {"text": "For Hindi, and  used semantic features in parsing to reduce the negative impact of unavailable syntactic features and showed that use of minimal semantics can help in identifying certain core dependency labels.", "labels": [], "entities": []}, {"text": "Various attempts have proved to simplify the structure by dividing the sentence into suitable linguistic units).", "labels": [], "entities": []}, {"text": "These approaches handle complex structures by breaking the parsing process into several steps.", "labels": [], "entities": [{"text": "parsing process", "start_pos": 59, "end_pos": 74, "type": "TASK", "confidence": 0.8908864557743073}]}, {"text": "used chunk information as a feature to) for parsing English.", "labels": [], "entities": [{"text": "parsing English", "start_pos": 44, "end_pos": 59, "type": "TASK", "confidence": 0.887396365404129}]}, {"text": "used the notion of local word groups, while In this paper, we describe a data driven dependency parsing approach which uses clausal information of a sentence to improve the parser performance.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 85, "end_pos": 103, "type": "TASK", "confidence": 0.7339574098587036}]}, {"text": "Previous attempts at data driven parsing for Hindi have failed to exploit this feature explicitly.", "labels": [], "entities": []}, {"text": "The clausal information is added automatically during the parsing process.", "labels": [], "entities": [{"text": "parsing process", "start_pos": 58, "end_pos": 73, "type": "TASK", "confidence": 0.8925220668315887}]}, {"text": "We demonstrate the experiments on Hindi 1 . All the experiments are done using a modified version of MSTParser ( and the references therein) (henceforth MST) on the ICON 2009 parsing contest 2 (Husain, 2009) data.", "labels": [], "entities": [{"text": "Hindi 1", "start_pos": 34, "end_pos": 41, "type": "DATASET", "confidence": 0.9617452025413513}, {"text": "MSTParser", "start_pos": 101, "end_pos": 110, "type": "DATASET", "confidence": 0.9404208064079285}, {"text": "ICON 2009 parsing contest 2 (Husain, 2009) data", "start_pos": 165, "end_pos": 212, "type": "DATASET", "confidence": 0.7220931920138273}]}, {"text": "We achieved an improvement of 0.87% and 0.77% in unlabeled attachment and labeled attachment accuracies respectively over the baseline parsing accuracies.", "labels": [], "entities": []}], "datasetContent": [{"text": "The experiments reported in this paper have been done on Hindi; the data was released as part of the ICON 2009 parsing contest.", "labels": [], "entities": [{"text": "ICON 2009 parsing contest", "start_pos": 101, "end_pos": 126, "type": "TASK", "confidence": 0.7253908514976501}]}, {"text": "The sentences used for this contest are subset of the Hyderabad Dependency Treebank (HyDT) developed for Hindi ().", "labels": [], "entities": [{"text": "Hyderabad Dependency Treebank (HyDT)", "start_pos": 54, "end_pos": 90, "type": "DATASET", "confidence": 0.8980970978736877}]}, {"text": "The dependency relations in the treebank are syntacticosemantic.", "labels": [], "entities": []}, {"text": "The dependency tagset in the annotation scheme has around 28 relations.", "labels": [], "entities": []}, {"text": "The dependency trees in the treebank show relations between chunk heads.", "labels": [], "entities": []}, {"text": "Note, therefore, that the experiments and results described in this paper are based on parse trees that have chunk head as nodes.", "labels": [], "entities": []}, {"text": "The data provided in the task contained morphological features along with the lemma, POS tag, and coarse POS tag, for each word.", "labels": [], "entities": []}, {"text": "These are six morphological features namely category, gender, number, person, vibhakti 3 or TAM 4 markers of the node  We experimented with different combinations of the information provided in the data (as mentioned in 3.1).", "labels": [], "entities": [{"text": "TAM 4 markers", "start_pos": 92, "end_pos": 105, "type": "METRIC", "confidence": 0.9587812423706055}]}, {"text": "Vibhakti and TAM fields gave better results than others.", "labels": [], "entities": [{"text": "TAM", "start_pos": 13, "end_pos": 16, "type": "DATASET", "confidence": 0.4560660123825073}]}, {"text": "This is consistent with the best previous settings for Hindi parsing (.", "labels": [], "entities": [{"text": "Hindi parsing", "start_pos": 55, "end_pos": 68, "type": "TASK", "confidence": 0.6528902649879456}]}, {"text": "We used the results obtained using this setting as our baseline (F1).", "labels": [], "entities": [{"text": "F1", "start_pos": 65, "end_pos": 67, "type": "METRIC", "confidence": 0.9983556866645813}]}, {"text": "We first experimented by giving only the clause inclusion (boundary) information to each node (F2).", "labels": [], "entities": []}, {"text": "This feature should help the parser reduce its search space during parsing decisions.", "labels": [], "entities": []}, {"text": "Then, we provided only the head and non-head information (whether that node is the head of the clause or not) (F3).", "labels": [], "entities": [{"text": "F3", "start_pos": 111, "end_pos": 113, "type": "METRIC", "confidence": 0.9240227937698364}]}, {"text": "The head or non-head information helps in handling complex sentences that have more than MST version 0.4b one clause and each verb in the sentence has its own argument structure.", "labels": [], "entities": [{"text": "MST version 0.4b", "start_pos": 89, "end_pos": 105, "type": "DATASET", "confidence": 0.7610230445861816}]}, {"text": "We achieved the best performance by using both as features (F4) during the parsing process.", "labels": [], "entities": [{"text": "F4", "start_pos": 60, "end_pos": 62, "type": "METRIC", "confidence": 0.9317293167114258}, {"text": "parsing", "start_pos": 75, "end_pos": 82, "type": "TASK", "confidence": 0.9753427505493164}]}], "tableCaptions": [{"text": " Table 1. Accuracies of the features being used", "labels": [], "entities": [{"text": "Accuracies", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.998439371585846}]}, {"text": " Table 2. Parsing accuracies with different features", "labels": [], "entities": [{"text": "Parsing", "start_pos": 10, "end_pos": 17, "type": "TASK", "confidence": 0.9276158213615417}]}]}