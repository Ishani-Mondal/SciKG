{"title": [{"text": "Ensemble Models for Dependency Parsing: Cheap and Good?", "labels": [], "entities": [{"text": "Dependency Parsing", "start_pos": 20, "end_pos": 38, "type": "TASK", "confidence": 0.7721977531909943}]}], "abstractContent": [{"text": "Previous work on dependency parsing used various kinds of combination models but a systematic analysis and comparison of these approaches is lacking.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 17, "end_pos": 35, "type": "TASK", "confidence": 0.8438394367694855}]}, {"text": "In this paper we implemented such a study for English dependency parsing and find several non-obvious facts: (a) the diversity of base parsers is more important than complex models for learning (e.g., stacking , supervised meta-classification), (b) approximate , linear-time re-parsing algorithms guarantee well-formed dependency trees without significant performance loss, and (c) the simplest scoring model for re-parsing (un-weighted voting) performs essentially as well as other more complex models.", "labels": [], "entities": [{"text": "English dependency parsing", "start_pos": 46, "end_pos": 72, "type": "TASK", "confidence": 0.5771470765272776}]}, {"text": "This study proves that fast and accurate ensemble parsers can be built with minimal effort.", "labels": [], "entities": []}], "introductionContent": [{"text": "Several ensemble models have been proposed for the parsing of syntactic dependencies.", "labels": [], "entities": [{"text": "parsing of syntactic dependencies", "start_pos": 51, "end_pos": 84, "type": "TASK", "confidence": 0.8369258791208267}]}, {"text": "These approaches can generally be classified in two categories: models that integrate base parsers at learning time, e.g., using stacking, and approaches that combine independently-trained models only at parsing time ().", "labels": [], "entities": []}, {"text": "In the latter case, the correctness of the final dependency tree is ensured by: (a) selecting entire trees proposed by the base parsers (); or (b) re-parsing the pool of dependencies proposed by the base models ().", "labels": [], "entities": []}, {"text": "The latter approach was shown to perform better for constituent parsing.", "labels": [], "entities": [{"text": "constituent parsing", "start_pos": 52, "end_pos": 71, "type": "TASK", "confidence": 0.8290907740592957}]}, {"text": "While all these models achieved good performance, the previous work has left several questions", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Labeled attachment scores (LAS) and unlabeled at-", "labels": [], "entities": [{"text": "Labeled attachment scores (LAS)", "start_pos": 10, "end_pos": 41, "type": "METRIC", "confidence": 0.868215799331665}]}, {"text": " Table 2: Scores of unsupervised combination models using different voting strategies. The combined trees are assembled using a", "labels": [], "entities": []}, {"text": " Table 2: in the \"unweighted\"  strategy all votes have the same weight; in all other  strategies each vote is assigned a value equal to  the accuracy of the given parser in the particular  instance of the context considered, e.g., in the  \"weighted by POS of modifier\" model we use the  accuracies of the base models for each possible  part-of-speech (POS) tag of a modifier token. In  the table we show results as more base parsers are  added to the ensemble (we add parsers in the order  given by", "labels": [], "entities": [{"text": "accuracy", "start_pos": 141, "end_pos": 149, "type": "METRIC", "confidence": 0.9974111914634705}]}, {"text": " Table 4. The table shows  that the percentage of badly-formed trees is rela- tively large: almost 10% out of domain. This in- dicates that the focus on algorithms that guarantee  well-formed trees is justified.  However, it is not clear how the Eisner algo- rithm, which has runtime complexity of O(n 3 ) (n  -number of tokens per sentence), compares against  approximate re-parsing algorithms that have lower  runtime complexity. One such algorithm was pro- posed by", "labels": [], "entities": [{"text": "O", "start_pos": 298, "end_pos": 299, "type": "METRIC", "confidence": 0.9753182530403137}]}, {"text": " Table 4: Percentage of badly-formed dependency trees when", "labels": [], "entities": []}, {"text": " Table 5: Scores of different combination schemes.  *  indicates", "labels": [], "entities": []}, {"text": " Table 6: Comparison of different combination strategies.", "labels": [], "entities": []}, {"text": " Table 7: Comparison with state of the art parsers.", "labels": [], "entities": []}]}