{"title": [{"text": "Clinical Information Retrieval using Document and PICO Structure", "labels": [], "entities": [{"text": "Clinical Information Retrieval", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.5437189936637878}]}], "abstractContent": [{"text": "In evidence-based medicine, clinical questions involve four aspects: Patient/Problem (P), Intervention (I), Comparison (C) and Outcome (O), known as PICO elements.", "labels": [], "entities": [{"text": "Outcome (O)", "start_pos": 127, "end_pos": 138, "type": "METRIC", "confidence": 0.934019610285759}]}, {"text": "In this paper we present a method that extends the language modeling approach to incorporate both document structure and PICO query formulation.", "labels": [], "entities": [{"text": "PICO query formulation", "start_pos": 121, "end_pos": 143, "type": "TASK", "confidence": 0.7036436994870504}]}, {"text": "We present an analysis of the distribution of PICO elements in medical abstracts that motivates the use of a location-based weighting strategy.", "labels": [], "entities": []}, {"text": "In experiments carried out on a collection of 1.5 million abstracts, the method was found to lead to an improvement of roughly 60% in MAP and 70% in P@10 as compared to state-of-the-art methods.", "labels": [], "entities": [{"text": "MAP", "start_pos": 134, "end_pos": 137, "type": "METRIC", "confidence": 0.8872005343437195}, {"text": "P@10", "start_pos": 149, "end_pos": 153, "type": "METRIC", "confidence": 0.9486549099286398}]}], "introductionContent": [{"text": "As the volume of published medical literature continues to grow exponentially, there is more and more research for physicians to assess and evaluate and less time to do so.", "labels": [], "entities": []}, {"text": "Evidence-based medicine (EBM)) is a widely accepted paradigm in medical practice that relies on evidence from patient-centered clinical research to make decisions.", "labels": [], "entities": [{"text": "Evidence-based medicine (EBM))", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.7759058952331543}]}, {"text": "Taking an evidence-based approach to searching means doing a systematic search of all the available literature, individually critically appraising each research study and then applying the findings in clinical practice.", "labels": [], "entities": []}, {"text": "However, this is a time consuming activity.", "labels": [], "entities": []}, {"text": "One way to facilitate searching fora precise answer is to formulate a well-focused and structured question (.", "labels": [], "entities": []}, {"text": "Physicians are educated to formulate their clinical questions according to several well defined aspects in EBM: Patient/Problem (P), Intervention (I), Comparison (C) and Outcome (O), which are called PICO elements.", "labels": [], "entities": []}, {"text": "In many documents in medical literature (e.g. MEDLINE), one can find the elements of the PICO structure, but rarely explicitly annotated (.", "labels": [], "entities": [{"text": "MEDLINE", "start_pos": 46, "end_pos": 53, "type": "DATASET", "confidence": 0.8046458959579468}]}, {"text": "To identify documents corresponding to a patient's state, physicians also construct their queries according to the PICO structure.", "labels": [], "entities": []}, {"text": "For example, in the question \"In children with pain and fever how does paracetamol compared with ibuprofen affect levels of pain and fever?\" one can identify the following PICO elements: Patient/Problem: children/pain and fever Intervention: paracetamol Comparison: ibuprofen Outcome: levels of pain and fever Very little work, if any, has been carried out on the use of these elements in the Information Retrieval (IR) process.", "labels": [], "entities": [{"text": "Information Retrieval (IR) process", "start_pos": 393, "end_pos": 427, "type": "TASK", "confidence": 0.8242287039756775}]}, {"text": "There are several reasons for that.", "labels": [], "entities": []}, {"text": "It is not easy to identify PICO elements in documents, as well as in the question if these are not explicitly separated in it.", "labels": [], "entities": []}, {"text": "Several studies have been performed on identifying PICO elements in abstracts.", "labels": [], "entities": []}, {"text": "However, all of them are reporting coarsegrain (sentence-level) tagging methods that have not yet been shown to be sufficient for the purpose of IR.", "labels": [], "entities": [{"text": "sentence-level) tagging", "start_pos": 48, "end_pos": 71, "type": "TASK", "confidence": 0.6416781942049662}, {"text": "IR", "start_pos": 145, "end_pos": 147, "type": "TASK", "confidence": 0.9914103150367737}]}, {"text": "Moreover, there is currently no standard test collection of questions in PICO structure available for evaluation.", "labels": [], "entities": [{"text": "PICO structure", "start_pos": 73, "end_pos": 87, "type": "DATASET", "confidence": 0.82707878947258}]}, {"text": "On the other hand, the most critical aspect in IR is term weighting.", "labels": [], "entities": [{"text": "IR", "start_pos": 47, "end_pos": 49, "type": "TASK", "confidence": 0.9964020252227783}, {"text": "term weighting", "start_pos": 53, "end_pos": 67, "type": "TASK", "confidence": 0.6086573302745819}]}, {"text": "One of the purpose of tagging PICO elements is to assign appropriate weights to these elements during the retrieval process.", "labels": [], "entities": []}, {"text": "From this perspective, a semantic tagging of PICO elements maybe a task that goes well beyond that is required for IR.", "labels": [], "entities": [{"text": "semantic tagging of PICO elements", "start_pos": 25, "end_pos": 58, "type": "TASK", "confidence": 0.7778352856636047}, {"text": "IR", "start_pos": 115, "end_pos": 117, "type": "TASK", "confidence": 0.9766695499420166}]}, {"text": "It maybe sufficient to have a method that assigns appropriate weights to elements rather than recognizing their semantic roles.", "labels": [], "entities": []}, {"text": "In this paper, we will propose an approach to determine term weights according to document structure.", "labels": [], "entities": []}, {"text": "This method will be compared to that using tagging of PICO elements.", "labels": [], "entities": []}, {"text": "In this paper, we first report an attempt to manually annotate the PICO elements in documents by physicians and use them as training data to build an automatic tagging tool.", "labels": [], "entities": []}, {"text": "It turns out that there is a high disagreement rate between human annotators.", "labels": [], "entities": []}, {"text": "The utilization of the automatic tagging tool in an IR experiment shows only a small gain in retrieval effectiveness.", "labels": [], "entities": [{"text": "IR", "start_pos": 52, "end_pos": 54, "type": "TASK", "confidence": 0.9651944041252136}]}, {"text": "We therefore propose an alternative to PICO element detection that uses the structural information of documents.", "labels": [], "entities": [{"text": "PICO element detection", "start_pos": 39, "end_pos": 61, "type": "TASK", "confidence": 0.8094334801038107}]}, {"text": "This solution turns out to be robust and effective.", "labels": [], "entities": []}, {"text": "The alternative approach is motivated by a strong trend that we observe in the distribution of PICO elements in documents.", "labels": [], "entities": []}, {"text": "We then make use of both PICO query and document structure to extend the classical language modeling approach to IR.", "labels": [], "entities": [{"text": "IR", "start_pos": 113, "end_pos": 115, "type": "TASK", "confidence": 0.9692549705505371}]}, {"text": "Specifically, we investigate how each element of a PICO query should be weighted and how a location-based weighting strategy can be used to emphasize the most informative parts (i.e. containing the most PICO elements) of documents.", "labels": [], "entities": []}, {"text": "The paper is organized as follows.", "labels": [], "entities": []}, {"text": "We first briefly review the previous work, followed by a description of the method we propose.", "labels": [], "entities": []}, {"text": "Next, we present our experiments and results.", "labels": [], "entities": []}, {"text": "Lastly, we conclude with a discussion and directions for future work.", "labels": [], "entities": []}], "datasetContent": [{"text": "We have seen that both the use of a location-based weighting and a PICO-structure weighting scheme increase the retrieval accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 122, "end_pos": 130, "type": "METRIC", "confidence": 0.9870280027389526}]}, {"text": "In this last series of experiments, we analyse the results of their combination.", "labels": [], "entities": []}, {"text": "We can observe that fusing model-1 and model-2 allows us to obtain the best retrieval accuracy with a MAP score increase of 61.5% and a P@10 increase of 70.0%.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 86, "end_pos": 94, "type": "METRIC", "confidence": 0.9921169877052307}, {"text": "MAP score increase", "start_pos": 102, "end_pos": 120, "type": "METRIC", "confidence": 0.9667490522066752}, {"text": "P@10 increase", "start_pos": 136, "end_pos": 149, "type": "METRIC", "confidence": 0.9685950577259064}]}, {"text": "It is a large improvement over the baseline as it means that instead of about two relevant documents in the top 10, our system can retrieve nearly four.", "labels": [], "entities": []}, {"text": "These results confirm that both PICO framework and document structure can be very helpful for the IR process.", "labels": [], "entities": [{"text": "IR process", "start_pos": 98, "end_pos": 108, "type": "TASK", "confidence": 0.9260786473751068}]}, {"text": "We gathered a collection of nearly 1.5 million abstracts from PubMed with the following requirements: with abstract, humans subjects, in english and selecting the following publication types: RCT, reviews, clinical trials, letters, practice guidelines, editorials and meta-analysis.", "labels": [], "entities": []}, {"text": "Prior to the index construction, each abstract is automatically divided into 10 parts of equal length, abstracts containing less than 10 words are discarded.", "labels": [], "entities": []}, {"text": "The following fields are then marked: TITLE, P1, P2, ...", "labels": [], "entities": [{"text": "TITLE", "start_pos": 38, "end_pos": 43, "type": "METRIC", "confidence": 0.9899550676345825}]}, {"text": "P10 with P1 being the begining of the document and P10 the ending.", "labels": [], "entities": []}, {"text": "Unfortunately, there is no standard test collection appropriate for testing the use of PICO in IR and we had to manually create one.", "labels": [], "entities": [{"text": "IR", "start_pos": 95, "end_pos": 97, "type": "TASK", "confidence": 0.9276602268218994}]}, {"text": "For queries, we use the Cochrane systematic reviews 4 on 10 clinical questions about different aspects of \"diabetes\".", "labels": [], "entities": []}, {"text": "These reviews contain the best available information about an healthcare intervention and are designed to facilitate the choices that doctors face in healthcare.", "labels": [], "entities": []}, {"text": "All the documents in the \"Included studies\" section are judged to be relevant for the question.", "labels": [], "entities": []}, {"text": "These included studies are selected by the reviewers (authors of the review article) and judged to be highly related to the clinical question.", "labels": [], "entities": []}, {"text": "In our experiments, we consider these documents as relevant ones.", "labels": [], "entities": []}, {"text": "From the 10 selected questions, professors in family medicine have formulated a set of 52 queries, each of which was manually annotated according to the PICO structure.", "labels": [], "entities": [{"text": "PICO structure", "start_pos": 153, "end_pos": 167, "type": "DATASET", "confidence": 0.8185292780399323}]}, {"text": "The resulting testing corpus is composed of 52 queries (average length of 14.7 words) and 378 relevant documents.", "labels": [], "entities": []}, {"text": "Below are some of the alternative formulations of queries for the question \"Pioglitazone for type 2 diabetes mellitus\": In patients with type 2 diabetes (P) | does pioglitazone (I) | compared to placebo (C) | reduce stroke and myocardial infarction In patients with type 2 diabetes who have a high risk of macrovascular events (P) | does pioglitazone (I) | compared to placebo (C) | reduce mortality We use cross-validation to determine reasonable weights and avoid over-fitting.", "labels": [], "entities": []}, {"text": "We have divided the queries into two groups of 26 queries: Qa and Qb.", "labels": [], "entities": []}, {"text": "The best parameters found for Qa are used to test on Qb, and vice versa.", "labels": [], "entities": []}, {"text": "In our experiments, we use the KL divergence ranking (equation 1) as baseline.", "labels": [], "entities": [{"text": "KL divergence ranking", "start_pos": 31, "end_pos": 52, "type": "METRIC", "confidence": 0.6592195332050323}]}, {"text": "The following evaluation measures are considered relevant: Precision at n (P@n).", "labels": [], "entities": [{"text": "Precision", "start_pos": 59, "end_pos": 68, "type": "METRIC", "confidence": 0.9959075450897217}]}, {"text": "Precision computed on only then topmost retrieved documents.", "labels": [], "entities": [{"text": "Precision", "start_pos": 0, "end_pos": 9, "type": "METRIC", "confidence": 0.8908161520957947}]}, {"text": "Mean Average Precision (MAP).", "labels": [], "entities": [{"text": "Mean Average Precision (MAP)", "start_pos": 0, "end_pos": 28, "type": "METRIC", "confidence": 0.9085455238819122}]}, {"text": "Average of precisions computed at the point of each relevant document in the ranked list of retrieved documents.", "labels": [], "entities": [{"text": "precisions", "start_pos": 11, "end_pos": 21, "type": "METRIC", "confidence": 0.9993661046028137}]}, {"text": "MAP is a popular measure that gives a global quality score of the entire ranked list of retrieved documents.", "labels": [], "entities": []}, {"text": "In the case of clinical searches, one could also imagine this scenario: a search performed by a physician who does not have the time to look into large sets of results, but for whom it is important to have relevant results in the top 10.", "labels": [], "entities": []}, {"text": "In such case, P@10 is also an appropriate measure.", "labels": [], "entities": [{"text": "P@10", "start_pos": 14, "end_pos": 18, "type": "METRIC", "confidence": 0.9703817367553711}]}, {"text": "Student's t-test is performed to determine statistical significance.", "labels": [], "entities": []}, {"text": "The Lemur Toolkit 5 was used for all retrieval tasks.", "labels": [], "entities": [{"text": "Lemur Toolkit 5", "start_pos": 4, "end_pos": 19, "type": "DATASET", "confidence": 0.8122197588284811}]}, {"text": "Experiments were performed with an \"out-of-the-box\" version of Lemur, using its tokenization algorithm and porter stemmer.", "labels": [], "entities": []}, {"text": "The Dirichlet prior smoothing parameter was set to its default value \u00b5 = 2500.", "labels": [], "entities": [{"text": "Dirichlet prior smoothing", "start_pos": 4, "end_pos": 29, "type": "TASK", "confidence": 0.49746384223302204}, {"text": "\u00b5", "start_pos": 69, "end_pos": 70, "type": "METRIC", "confidence": 0.9425945281982422}]}, {"text": "Experiments with model-1 We first investigated whether assigning a weight to each part of the document can improve the retrieval accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 129, "end_pos": 137, "type": "METRIC", "confidence": 0.990445613861084}]}, {"text": "It is however difficult to determine a set of reasonable values for all the parts together, as the value of one part will affect those of the others.", "labels": [], "entities": []}, {"text": "In this study, we perform a two pass tuning.", "labels": [], "entities": []}, {"text": "First, we consider the \u03b3 p weights to be independent.", "labels": [], "entities": []}, {"text": "By doing so, searching for the optimal weight distribution can be seen as tuning the weight of each part separately.", "labels": [], "entities": []}, {"text": "When searching the optimal weight of apart, the weight for other parts is assigned 0.", "labels": [], "entities": []}, {"text": "Second, these approximations of the optimum values are used as initial weights prior to the second pass.", "labels": [], "entities": []}, {"text": "The final weight distribution is obtained by searching for the best weight combination around the initial values.", "labels": [], "entities": []}, {"text": "The shows the optimal weight distributions along with the best relative MAP increase for each part.", "labels": [], "entities": [{"text": "MAP increase", "start_pos": 72, "end_pos": 84, "type": "METRIC", "confidence": 0.9850910305976868}]}, {"text": "A noticeable improvement is obtained by increasing the weights associated to the title/introduction and conclusion of documents.", "labels": [], "entities": []}, {"text": "This is consistent with the results observed on the distribution of PICO elements in abstracts.", "labels": [], "entities": []}, {"text": "Boosting middle parts of documents seems to have no impact at all.", "labels": [], "entities": [{"text": "Boosting middle parts of documents", "start_pos": 0, "end_pos": 34, "type": "TASK", "confidence": 0.8496489644050598}]}, {"text": "We can see that the two \u03b3 p weight distributions (1-pass and 2-pass) are very close.", "labels": [], "entities": []}, {"text": "Performance measures obtained by model-1 are presented in.", "labels": [], "entities": []}, {"text": "With 1-pass tuning, we observe a MAP score increase of 37.5% and a P@10 increase of 64.1%.", "labels": [], "entities": [{"text": "MAP score increase", "start_pos": 33, "end_pos": 51, "type": "METRIC", "confidence": 0.9847794969876608}, {"text": "P@10 increase", "start_pos": 67, "end_pos": 80, "type": "METRIC", "confidence": 0.9726951271295547}]}, {"text": "After the second pass, scores are lower with 35% and 60.5% for MAP and P@10 respectively.", "labels": [], "entities": [{"text": "MAP", "start_pos": 63, "end_pos": 66, "type": "METRIC", "confidence": 0.9763520359992981}, {"text": "P@10", "start_pos": 71, "end_pos": 75, "type": "METRIC", "confidence": 0.9455174406369528}]}, {"text": "This result indicates that there is possibly overfitting when we perform the two pass parameter tuning.", "labels": [], "entities": []}, {"text": "It could also be caused by the limited number of query in our test collection.", "labels": [], "entities": []}, {"text": "However, we can determine reasonable weights by tuning each part weight separately.", "labels": [], "entities": []}, {"text": "We have seen that a large improvement could come from weighting each part accordingly.", "labels": [], "entities": []}, {"text": "Ina second series of experiments, we try to assign a different weight to each PICO element in queries.", "labels": [], "entities": []}, {"text": "A grid search was used to find the optimal \u03b4 e weights combination.", "labels": [], "entities": []}, {"text": "The results are shown in.", "labels": [], "entities": []}, {"text": "We observe a MAP score increase of 22.5% and an increase of 11% in P@10.", "labels": [], "entities": [{"text": "MAP score increase", "start_pos": 13, "end_pos": 31, "type": "METRIC", "confidence": 0.972197949886322}, {"text": "P", "start_pos": 67, "end_pos": 68, "type": "METRIC", "confidence": 0.9849275350570679}]}, {"text": "Though the use of a PICO weighting scheme increases the retrieval accuracy, there is clearly much to gain by using the document structure.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 66, "end_pos": 74, "type": "METRIC", "confidence": 0.9854132533073425}]}, {"text": "The optimal [\u03b4 p , \u03b4 i , \u03b4 c , \u03b4 o ] weights distribution is [0.3, 1.2, 0, 0.1] for Qa and [0.2, 1, 0, 0.2] for Qb.", "labels": [], "entities": []}, {"text": "That means that the most important words in queries belong to the Intervention element.", "labels": [], "entities": [{"text": "Intervention", "start_pos": 66, "end_pos": 78, "type": "TASK", "confidence": 0.934434175491333}]}, {"text": "This supports the manual search strategy proposed by), in which they suggested that I and P elements should be used first to construct queries, and only if too many results are obtained that other elements should be considered.", "labels": [], "entities": []}, {"text": "It is interesting to see that query words belonging to the Comparison element have to be considered as the least important part of a query.", "labels": [], "entities": []}, {"text": "Even more so because they are in the same semantic group as the Intervention words.", "labels": [], "entities": []}, {"text": "A reason for that could be the use of vague words such as \"no-intervention\" or \"placebo\".", "labels": [], "entities": []}, {"text": "The methodology employed to construct the queries is also responsible.", "labels": [], "entities": []}, {"text": "Indeed, physicians have focused on producing alternative formulations of 10 general clinical questions by predominantly modifying the one of the PICO elements.", "labels": [], "entities": []}, {"text": "As a result, some of them do share the same vague Comparison words.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Agreement measures computed for each ele- ment. Cohen's kappa and loose agreement are presented.", "labels": [], "entities": []}, {"text": " Table 3: Cross-validation (train\u2192test) scores for the baseline (Kullback-Leibler divergence), model-1 with 1 and 2- pass tuning, model-2 and their combination (model-1+2). Relative increase over the baseline is also given (averaged  between Qa and Qb). (  \u2021 : t.test < 0.01)", "labels": [], "entities": [{"text": "Relative increase", "start_pos": 173, "end_pos": 190, "type": "METRIC", "confidence": 0.9701665937900543}]}]}