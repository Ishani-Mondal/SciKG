{"title": [{"text": "Improving Semantic Role Labeling with Word Sense", "labels": [], "entities": [{"text": "Improving Semantic Role Labeling", "start_pos": 0, "end_pos": 32, "type": "TASK", "confidence": 0.8799426108598709}]}], "abstractContent": [{"text": "Semantic role labeling (SRL) not only needs lexical and syntactic information, but also needs word sense information.", "labels": [], "entities": [{"text": "Semantic role labeling (SRL)", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.8434183299541473}]}, {"text": "However, because of the lack of corpus annotated with both word senses and semantic roles, there is few research on using word sense for SRL.", "labels": [], "entities": [{"text": "SRL", "start_pos": 137, "end_pos": 140, "type": "TASK", "confidence": 0.9822439551353455}]}, {"text": "The release of OntoNotes provides an opportunity for us to study how to use word sense for SRL.", "labels": [], "entities": [{"text": "SRL", "start_pos": 91, "end_pos": 94, "type": "TASK", "confidence": 0.9592437744140625}]}, {"text": "In this paper, we present some novel word sense features for SRL and find that they can improve the performance significantly.", "labels": [], "entities": [{"text": "SRL", "start_pos": 61, "end_pos": 64, "type": "TASK", "confidence": 0.9881415367126465}]}], "introductionContent": [{"text": "Semantic role labeling (SRL) is a kind of shallow sentence-level semantic analysis and is becoming a hot task in natural language processing.", "labels": [], "entities": [{"text": "Semantic role labeling (SRL)", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.837411363919576}, {"text": "sentence-level semantic analysis", "start_pos": 50, "end_pos": 82, "type": "TASK", "confidence": 0.6990513106187185}]}, {"text": "SRL aims at identifying the relations between the predicates in a sentence and their associated arguments.", "labels": [], "entities": [{"text": "SRL", "start_pos": 0, "end_pos": 3, "type": "TASK", "confidence": 0.9028214812278748}]}, {"text": "At present, the mainstream researches are focusing on feature engineering or combination of multiple results.", "labels": [], "entities": []}, {"text": "Word senses are important information for recognizing semantic roles.", "labels": [], "entities": [{"text": "recognizing semantic roles", "start_pos": 42, "end_pos": 68, "type": "TASK", "confidence": 0.8387857874234518}]}, {"text": "For example, if we know \"cat\" is an \"agent\" of the predicate \"eat\" in a sentence, we can guess that \"dog\" can also bean \"agent\" of \"eat\".", "labels": [], "entities": []}, {"text": "Word sense has been successfully used in many natural language processing tasks, such as machine translation).", "labels": [], "entities": [{"text": "Word sense", "start_pos": 0, "end_pos": 10, "type": "TASK", "confidence": 0.6448215991258621}, {"text": "machine translation", "start_pos": 89, "end_pos": 108, "type": "TASK", "confidence": 0.7926481664180756}]}, {"text": "CoNLL 2008 shared task () first introduced the predicate classification task, which can be regarded as the predicate sense disambiguation.", "labels": [], "entities": [{"text": "CoNLL 2008 shared task", "start_pos": 0, "end_pos": 22, "type": "DATASET", "confidence": 0.9260770231485367}, {"text": "predicate classification task", "start_pos": 47, "end_pos": 76, "type": "TASK", "confidence": 0.8787570794423422}, {"text": "predicate sense disambiguation", "start_pos": 107, "end_pos": 137, "type": "TASK", "confidence": 0.6477673550446829}]}, {"text": "Meza-Ruiz and has shown that the predicate sense can improve the final SRL performance.", "labels": [], "entities": [{"text": "SRL", "start_pos": 71, "end_pos": 74, "type": "TASK", "confidence": 0.9225875735282898}]}, {"text": "However, there is few discussion about the concrete influence of all word senses, i.e. the words besides predicates.", "labels": [], "entities": []}, {"text": "The major reason is lacking the corpus, which is both annotated with all word senses and semantic roles.", "labels": [], "entities": []}, {"text": "The release of OntoNotes corpus provides an opportunity for us to verify whether all word senses can help SRL.", "labels": [], "entities": [{"text": "OntoNotes corpus", "start_pos": 15, "end_pos": 31, "type": "DATASET", "confidence": 0.808668851852417}, {"text": "SRL", "start_pos": 106, "end_pos": 109, "type": "TASK", "confidence": 0.9939684867858887}]}, {"text": "OntoNotes is a large corpus annotated with constituency trees (based on Penn Treebank), predicate argument structures (based on Penn PropBank) and word senses.", "labels": [], "entities": [{"text": "Penn Treebank", "start_pos": 72, "end_pos": 85, "type": "DATASET", "confidence": 0.9953770339488983}, {"text": "Penn PropBank", "start_pos": 128, "end_pos": 141, "type": "DATASET", "confidence": 0.9733148813247681}]}, {"text": "It has been used in some natural language processing tasks, such as joint parsing and named entity recognition) and word sense disambiguation (.", "labels": [], "entities": [{"text": "joint parsing", "start_pos": 68, "end_pos": 81, "type": "TASK", "confidence": 0.7020254880189896}, {"text": "named entity recognition", "start_pos": 86, "end_pos": 110, "type": "TASK", "confidence": 0.6109756628672282}, {"text": "word sense disambiguation", "start_pos": 116, "end_pos": 141, "type": "TASK", "confidence": 0.7325850129127502}]}, {"text": "In this paper, we regard the word sense information as additional SRL features.", "labels": [], "entities": [{"text": "SRL", "start_pos": 66, "end_pos": 69, "type": "TASK", "confidence": 0.9323346018791199}]}, {"text": "We compare three categories of word sense features (subtree-word related sense, predicate sense, and sense path) and find that the subtree-word related sense feature is ineffective, however, the predicate sense and the sense path features can improve the SRL performance significantly.", "labels": [], "entities": [{"text": "SRL", "start_pos": 255, "end_pos": 258, "type": "TASK", "confidence": 0.9837942719459534}]}], "datasetContent": [{"text": "We will do our experiments on seven of the OntoNotes English datasets described in Section 2.", "labels": [], "entities": [{"text": "OntoNotes English datasets", "start_pos": 43, "end_pos": 69, "type": "DATASET", "confidence": 0.8969374497731527}]}, {"text": "For each dataset, we aimed for roughly a 60% train / 20% development / 20% test split.", "labels": [], "entities": []}, {"text": "See for the detailed statistics.", "labels": [], "entities": []}, {"text": "In order to examine the influence of word senses in isolation, we use the human annotated POS, parse trees, and word senses provided by OntoNotes.", "labels": [], "entities": [{"text": "OntoNotes", "start_pos": 136, "end_pos": 145, "type": "DATASET", "confidence": 0.9182648062705994}]}, {"text": "The lemma of each word is extracted using WordNet tool.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 42, "end_pos": 49, "type": "DATASET", "confidence": 0.9477108716964722}]}, {"text": "The baseline SRL system without sense information is trained with all the training corpus as described in Section 3.", "labels": [], "entities": [{"text": "SRL", "start_pos": 13, "end_pos": 16, "type": "TASK", "confidence": 0.9633495211601257}]}, {"text": "Its performance on the development data is F1 = 85.48%.", "labels": [], "entities": [{"text": "F1", "start_pos": 43, "end_pos": 45, "type": "METRIC", "confidence": 0.9997132420539856}]}, {"text": "shows the performance (F1) comparison on the development data among different sense extracting strategies with different feature categories.", "labels": [], "entities": [{"text": "F1)", "start_pos": 23, "end_pos": 26, "type": "METRIC", "confidence": 0.9778639674186707}, {"text": "sense extracting", "start_pos": 78, "end_pos": 94, "type": "TASK", "confidence": 0.7301373779773712}]}, {"text": "The numbers are the parameter n used in Hypernym and Root Hyper strategies.", "labels": [], "entities": [{"text": "Hypernym", "start_pos": 40, "end_pos": 48, "type": "DATASET", "confidence": 0.7393194437026978}]}, {"text": "From  the predicate sense feature, we arrive at the same conclusion with Meza-Ruiz and.", "labels": [], "entities": []}, {"text": "As for the sense path feature, it is more special than the POS, therefore, it can enhance the precision.", "labels": [], "entities": [{"text": "POS", "start_pos": 59, "end_pos": 62, "type": "DATASET", "confidence": 0.7724839448928833}, {"text": "precision", "start_pos": 94, "end_pos": 103, "type": "METRIC", "confidence": 0.9984484910964966}]}, {"text": "2. The subtree-word related sense is almost useless.", "labels": [], "entities": []}, {"text": "The reason is that the original lemma and POS features have been able to describe the subtree-word related information.", "labels": [], "entities": []}, {"text": "This kind of sense features is just reduplicate.", "labels": [], "entities": []}, {"text": "3. For different sense feature categories (columns), the performance is not very seriously affected by different sense extracting strategies (rows).", "labels": [], "entities": [{"text": "sense extracting", "start_pos": 113, "end_pos": 129, "type": "TASK", "confidence": 0.7299673855304718}]}, {"text": "That is to say, once the sense of a word is disambiguated, the sense expressing form is not important for SRL.", "labels": [], "entities": [{"text": "SRL", "start_pos": 106, "end_pos": 109, "type": "TASK", "confidence": 0.9897860288619995}]}, {"text": "In order to further improve the performance, we add the predicate sense and the sense path features simultaneously.", "labels": [], "entities": []}, {"text": "Here, we select the Lemma+Sense strategy for the predicate sense and the Root Hyper(1) strategy for the sense path.", "labels": [], "entities": []}, {"text": "The final performance achieves F1 = 86.44%, which is about 1% higher than the baseline (F1 = 85.48%).", "labels": [], "entities": [{"text": "F1", "start_pos": 31, "end_pos": 33, "type": "METRIC", "confidence": 0.9999136924743652}, {"text": "F1", "start_pos": 88, "end_pos": 90, "type": "METRIC", "confidence": 0.9983413219451904}]}, {"text": "Finally, we compare the baseline (without sense) result with the word sense result on the test data.", "labels": [], "entities": []}, {"text": "In order to seethe contribution of correct word senses, we introduce a simple sense determining strategy, which use the first (the most popular) WordNet sense for each word.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 145, "end_pos": 152, "type": "DATASET", "confidence": 0.9320907592773438}]}, {"text": "The final detailed comparison results are listed in.", "labels": [], "entities": []}, {"text": "Averagely, both of the methods with the first sense and the correct sense can perform better than the baseline.", "labels": [], "entities": []}, {"text": "However, the improvement of the method with the first sense is not significant (\u03c7 2 -test   \u03c1 < 0.01).", "labels": [], "entities": [{"text": "\u03c7 2 -test   \u03c1", "start_pos": 80, "end_pos": 93, "type": "METRIC", "confidence": 0.6658521592617035}]}, {"text": "Especially, for some sections, such as ABC and MNB, it is harmful to the performance.", "labels": [], "entities": [{"text": "ABC", "start_pos": 39, "end_pos": 42, "type": "DATASET", "confidence": 0.7048199772834778}, {"text": "MNB", "start_pos": 47, "end_pos": 50, "type": "DATASET", "confidence": 0.5969630479812622}]}, {"text": "In contrast, the correct word sense can improve the performance significantly (\u03c7 2 -test with \u03c1 < 0.01)and consistently.", "labels": [], "entities": []}, {"text": "These can further prove that the word sense can enhance the semantic role labeling.", "labels": [], "entities": [{"text": "semantic role labeling", "start_pos": 60, "end_pos": 82, "type": "TASK", "confidence": 0.6519552866617838}]}], "tableCaptions": [{"text": " Table 2: Training, developing and testing set sizes for the  seven datasets in sentences. The file ranges (in parenthe- sis) refer to the numbers within the names of the original  OntoNotes files.", "labels": [], "entities": [{"text": "OntoNotes files", "start_pos": 181, "end_pos": 196, "type": "DATASET", "confidence": 0.8860391676425934}]}, {"text": " Table 3: The performance comparison on the devel- opment data among different sense extracting strategies  with different feature categories.", "labels": [], "entities": [{"text": "sense extracting", "start_pos": 79, "end_pos": 95, "type": "TASK", "confidence": 0.7388344705104828}]}, {"text": " Table 4: The testing performance comparison among  the baseline without (w/o) sense information, the method  with the first sense, and the method with the correct word  sense.", "labels": [], "entities": []}]}