{"title": [{"text": "Omni-word Feature and Soft Constraint for Chinese Relation Extraction", "labels": [], "entities": [{"text": "Chinese Relation Extraction", "start_pos": 42, "end_pos": 69, "type": "TASK", "confidence": 0.7814706762631735}]}], "abstractContent": [{"text": "Chinese is an ancient hieroglyphic.", "labels": [], "entities": []}, {"text": "It is inattentive to structure.", "labels": [], "entities": []}, {"text": "Therefore, segmenting and parsing Chinese are more difficult and less accurate.", "labels": [], "entities": [{"text": "segmenting", "start_pos": 11, "end_pos": 21, "type": "TASK", "confidence": 0.9797731637954712}, {"text": "parsing Chinese", "start_pos": 26, "end_pos": 41, "type": "TASK", "confidence": 0.8812844455242157}]}, {"text": "In this paper, we propose an Omni-word feature and a soft constraint method for Chinese relation extraction.", "labels": [], "entities": [{"text": "Chinese relation extraction", "start_pos": 80, "end_pos": 107, "type": "TASK", "confidence": 0.7028165956338247}]}, {"text": "The Omni-word feature uses every potential word in a sentence as lexicon feature, reducing errors caused byword segmentation.", "labels": [], "entities": []}, {"text": "In order to utilize the structure information of a relation instance, we discuss how soft constraint can be used to capture the local dependency.", "labels": [], "entities": []}, {"text": "Both Omni-word feature and soft constraint make a better use of sentence information and minimize the influences caused by Chinese word segmenta-tion and parsing.", "labels": [], "entities": []}, {"text": "We test these methods on the ACE 2005 RDC Chinese corpus.", "labels": [], "entities": [{"text": "ACE 2005 RDC Chinese corpus", "start_pos": 29, "end_pos": 56, "type": "DATASET", "confidence": 0.972005832195282}]}, {"text": "The results show a significant improvement in Chi-nese relation extraction, outperforming other methods in F-score by 10% in 6 relation types and 15% in 18 relation subtypes.", "labels": [], "entities": [{"text": "Chi-nese relation extraction", "start_pos": 46, "end_pos": 74, "type": "TASK", "confidence": 0.5688330233097076}, {"text": "F-score", "start_pos": 107, "end_pos": 114, "type": "METRIC", "confidence": 0.9922738671302795}]}], "introductionContent": [{"text": "Information Extraction (IE) aims at extracting syntactic or semantic units with concrete concepts or linguistic functions).", "labels": [], "entities": [{"text": "Information Extraction (IE)", "start_pos": 0, "end_pos": 27, "type": "TASK", "confidence": 0.849209189414978}]}, {"text": "Instead of dealing with the whole documents, focusing on designated information, most of the IE systems extract named entities, relations, quantifiers or events from sentences.", "labels": [], "entities": [{"text": "IE systems extract named entities, relations, quantifiers or events from sentences", "start_pos": 93, "end_pos": 175, "type": "TASK", "confidence": 0.5451187239243434}]}, {"text": "The relation recognition task is to find the relationships between two entities.", "labels": [], "entities": [{"text": "relation recognition", "start_pos": 4, "end_pos": 24, "type": "TASK", "confidence": 0.8880512714385986}]}, {"text": "Successful recognition of relation implies correctly detecting both the relation arguments and relation type.", "labels": [], "entities": []}, {"text": "Although this task has received extensive research.", "labels": [], "entities": []}, {"text": "The performance of relation extraction is still unsatisfactory with a F-score of 67.5% for English (23 subtypes) (.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 19, "end_pos": 38, "type": "TASK", "confidence": 0.9225461184978485}, {"text": "F-score", "start_pos": 70, "end_pos": 77, "type": "METRIC", "confidence": 0.9992285966873169}]}, {"text": "Chinese relation extraction also faces a weak performance having F-score about 66.6% in 18 subtypes ().", "labels": [], "entities": [{"text": "Chinese relation extraction", "start_pos": 0, "end_pos": 27, "type": "TASK", "confidence": 0.5781465272108713}, {"text": "F-score", "start_pos": 65, "end_pos": 72, "type": "METRIC", "confidence": 0.9991697072982788}]}, {"text": "The difficulty of Chinese IE is that Chinese words are written next to each other without delimiter in between.", "labels": [], "entities": [{"text": "Chinese IE", "start_pos": 18, "end_pos": 28, "type": "TASK", "confidence": 0.4388509690761566}]}, {"text": "Lacking of orthographic word makes Chinese word segmentation difficult.", "labels": [], "entities": [{"text": "Chinese word segmentation", "start_pos": 35, "end_pos": 60, "type": "TASK", "confidence": 0.6607131163279215}]}, {"text": "In Chinese, a single sentence often has several segmentation paths leading to the segmentation ambiguity problem.", "labels": [], "entities": []}, {"text": "The lack of delimiter also causes the Out-of-Vocabulary problem (OOV, also known as new word detection)).", "labels": [], "entities": [{"text": "Out-of-Vocabulary problem (OOV", "start_pos": 38, "end_pos": 68, "type": "METRIC", "confidence": 0.8145375847816467}, {"text": "word detection", "start_pos": 88, "end_pos": 102, "type": "TASK", "confidence": 0.6539715528488159}]}, {"text": "These problems are worsened by the fact that Chinese has a large number of characters and words.", "labels": [], "entities": []}, {"text": "Currently, the state-of-the-art Chinese OOV recognition system has performance about 75% in recall ().", "labels": [], "entities": [{"text": "OOV recognition", "start_pos": 40, "end_pos": 55, "type": "TASK", "confidence": 0.6520877629518509}, {"text": "recall", "start_pos": 92, "end_pos": 98, "type": "METRIC", "confidence": 0.9993489384651184}]}, {"text": "The errors caused by segmentation and OOV will accumulate and propagate to subsequent processing (e.g. partof-speech (POS) tagging or parsing).", "labels": [], "entities": [{"text": "OOV", "start_pos": 38, "end_pos": 41, "type": "METRIC", "confidence": 0.7602975368499756}, {"text": "partof-speech (POS) tagging", "start_pos": 103, "end_pos": 130, "type": "TASK", "confidence": 0.5828834652900696}]}, {"text": "Therefore, the Chinese relation extraction is more difficult.", "labels": [], "entities": [{"text": "Chinese relation extraction", "start_pos": 15, "end_pos": 42, "type": "TASK", "confidence": 0.6192439794540405}]}, {"text": "According to our survey, compared to the same work in English, the Chinese relation extraction researches make less significant progress.", "labels": [], "entities": [{"text": "Chinese relation extraction", "start_pos": 67, "end_pos": 94, "type": "TASK", "confidence": 0.63400932153066}]}, {"text": "Based on the characteristics of Chinese, in this paper, an Omni-word feature and a soft constraint method are proposed for Chinese relation extraction.", "labels": [], "entities": [{"text": "Chinese relation extraction", "start_pos": 123, "end_pos": 150, "type": "TASK", "confidence": 0.6710056563218435}]}, {"text": "We apply these approaches in a maximum entropy based system to extract relations from the ACE 2005 corpus.", "labels": [], "entities": [{"text": "ACE 2005 corpus", "start_pos": 90, "end_pos": 105, "type": "DATASET", "confidence": 0.9868074854214987}]}, {"text": "Experimental results show that our method has made a significant improvement.", "labels": [], "entities": []}, {"text": "The contributions of this paper include 1.", "labels": [], "entities": []}, {"text": "Propose a novel Omni-word feature for Chinese relation extraction.", "labels": [], "entities": [{"text": "Chinese relation extraction", "start_pos": 38, "end_pos": 65, "type": "TASK", "confidence": 0.6743578016757965}]}, {"text": "Unlike the traditional segmentation based method, which is a partition of the sentence, the Omni-word feature uses every potential word in a sentence as lexicon feature.", "labels": [], "entities": []}, {"text": "2. Aiming at the Chinese inattentive structure, we utilize the soft constraint to capture the local dependency in a relation instance.", "labels": [], "entities": []}, {"text": "Four constraint conditions are proposed to gener-ate combined features to capture the local dependency and maximize the classification determination.", "labels": [], "entities": [{"text": "classification determination", "start_pos": 120, "end_pos": 148, "type": "TASK", "confidence": 0.9510868489742279}]}, {"text": "The rest of this paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 introduces the related work.", "labels": [], "entities": []}, {"text": "The Omniword feature and soft constrain are proposed in Section 3.", "labels": [], "entities": []}, {"text": "We give the experimental results in Section 3.2 and analyze the performance in Section 4.", "labels": [], "entities": []}, {"text": "Conclusions are given in Section 5.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Performance on Type (Subtype)", "labels": [], "entities": [{"text": "Performance", "start_pos": 10, "end_pos": 21, "type": "METRIC", "confidence": 0.9737006425857544}]}, {"text": " Table 2: Survey of Other Systems", "labels": [], "entities": []}, {"text": " Table 3: Comparing With the State-of-the-Art Methods", "labels": [], "entities": []}, {"text": " Table 4: Influence of Feature Set", "labels": [], "entities": []}]}