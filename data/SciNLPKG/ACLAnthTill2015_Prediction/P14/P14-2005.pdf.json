{"title": [{"text": "An Extension of BLANC to System Mentions", "labels": [], "entities": [{"text": "BLANC", "start_pos": 16, "end_pos": 21, "type": "TASK", "confidence": 0.5981473326683044}, {"text": "System Mentions", "start_pos": 25, "end_pos": 40, "type": "TASK", "confidence": 0.6334334909915924}]}], "abstractContent": [{"text": "BLANC is a link-based coreference evaluation metric for measuring the quality of coreference systems on gold mentions.", "labels": [], "entities": [{"text": "BLANC", "start_pos": 0, "end_pos": 5, "type": "METRIC", "confidence": 0.8549747467041016}]}, {"text": "This paper extends the original BLANC (\"BLANC-gold\" henceforth) to system mentions, removing the gold mention assumption.", "labels": [], "entities": [{"text": "BLANC", "start_pos": 32, "end_pos": 37, "type": "METRIC", "confidence": 0.9841523766517639}]}, {"text": "The proposed BLANC falls back seamlessly to the original one if system mentions are identical to gold mentions , and it is shown to strongly correlate with existing metrics on the 2011 and 2012 CoNLL data.", "labels": [], "entities": [{"text": "BLANC", "start_pos": 13, "end_pos": 18, "type": "METRIC", "confidence": 0.9900702834129333}, {"text": "CoNLL data", "start_pos": 194, "end_pos": 204, "type": "DATASET", "confidence": 0.906656414270401}]}], "introductionContent": [{"text": "Coreference resolution aims at identifying natural language expressions (or mentions) that refer to the same entity.", "labels": [], "entities": [{"text": "Coreference resolution", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.9262050986289978}]}, {"text": "It entails partitioning (often imperfect) mentions into equivalence classes.", "labels": [], "entities": []}, {"text": "A critically important problem is how to measure the quality of a coreference resolution system.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 66, "end_pos": 88, "type": "TASK", "confidence": 0.9471823871135712}]}, {"text": "Many evaluation metrics have been proposed in the past two decades, including the MUC measure (, B-cubed (, CEAF () and, more recently, BLANCgold ().", "labels": [], "entities": [{"text": "MUC measure", "start_pos": 82, "end_pos": 93, "type": "METRIC", "confidence": 0.5133942663669586}, {"text": "B-cubed", "start_pos": 97, "end_pos": 104, "type": "METRIC", "confidence": 0.9907566905021667}, {"text": "CEAF", "start_pos": 108, "end_pos": 112, "type": "METRIC", "confidence": 0.6937060952186584}, {"text": "BLANCgold", "start_pos": 136, "end_pos": 145, "type": "METRIC", "confidence": 0.9942460656166077}]}, {"text": "B-cubed and CEAF treat entities as sets of mentions and measure the agreement between key (or gold standard) entities and response (or system-generated) entities, while MUC and BLANC-gold are link-based.", "labels": [], "entities": [{"text": "B-cubed", "start_pos": 0, "end_pos": 7, "type": "METRIC", "confidence": 0.6351818442344666}, {"text": "MUC", "start_pos": 169, "end_pos": 172, "type": "DATASET", "confidence": 0.8719387650489807}, {"text": "BLANC-gold", "start_pos": 177, "end_pos": 187, "type": "METRIC", "confidence": 0.7225272059440613}]}, {"text": "In particular, MUC measures the degree of agreement between key coreference links (i.e., links among mentions within entities) and response coreference links, while non-coreference links (i.e., links formed by mentions from different entities) are not explicitly taken into account.", "labels": [], "entities": [{"text": "MUC", "start_pos": 15, "end_pos": 18, "type": "METRIC", "confidence": 0.5797274708747864}]}, {"text": "This leads to a phenomenon where coreference systems outputting large entities are scored more favorably than those outputting small entities (.", "labels": [], "entities": []}, {"text": "BLANC (), on the other hand, considers both coreference links and noncoreference links.", "labels": [], "entities": [{"text": "BLANC", "start_pos": 0, "end_pos": 5, "type": "METRIC", "confidence": 0.558765172958374}]}, {"text": "It calculates recall, precision and F-measure separately on coreference and noncoreference links in the usual way, and defines the overall recall, precision and F-measure as the mean of the respective measures for coreference and non-coreference links.", "labels": [], "entities": [{"text": "recall", "start_pos": 14, "end_pos": 20, "type": "METRIC", "confidence": 0.9982225298881531}, {"text": "precision", "start_pos": 22, "end_pos": 31, "type": "METRIC", "confidence": 0.9875811338424683}, {"text": "F-measure", "start_pos": 36, "end_pos": 45, "type": "METRIC", "confidence": 0.9847315549850464}, {"text": "recall", "start_pos": 139, "end_pos": 145, "type": "METRIC", "confidence": 0.9957044720649719}, {"text": "precision", "start_pos": 147, "end_pos": 156, "type": "METRIC", "confidence": 0.9777440428733826}, {"text": "F-measure", "start_pos": 161, "end_pos": 170, "type": "METRIC", "confidence": 0.9862521290779114}]}, {"text": "The BLANC-gold metric was developed with the assumption that response mentions and key mentions are identical.", "labels": [], "entities": [{"text": "BLANC-gold", "start_pos": 4, "end_pos": 14, "type": "METRIC", "confidence": 0.9638544321060181}]}, {"text": "In reality, however, mentions need to be detected from natural language text and the result is, more often than not, imperfect: some key mentions maybe missing in the response, and some response mentions maybe spurious-so-called \"twinless\" mentions by.", "labels": [], "entities": []}, {"text": "Therefore, the identicalmention-set assumption limits BLANC-gold's applicability when gold mentions are not available, or when one wants to have a single score measuring both the quality of mention detection and coreference resolution.", "labels": [], "entities": [{"text": "BLANC-gold", "start_pos": 54, "end_pos": 64, "type": "METRIC", "confidence": 0.8533156514167786}, {"text": "mention detection", "start_pos": 190, "end_pos": 207, "type": "TASK", "confidence": 0.7259005308151245}, {"text": "coreference resolution", "start_pos": 212, "end_pos": 234, "type": "TASK", "confidence": 0.8877118527889252}]}, {"text": "The goal of this paper is to extend the BLANC-gold metric to imperfect response mentions.", "labels": [], "entities": [{"text": "BLANC-gold metric", "start_pos": 40, "end_pos": 57, "type": "METRIC", "confidence": 0.9645999372005463}]}, {"text": "We first briefly review the original definition of BLANC, and rewrite its definition using set notation.", "labels": [], "entities": [{"text": "BLANC", "start_pos": 51, "end_pos": 56, "type": "METRIC", "confidence": 0.5538269281387329}]}, {"text": "We then argue that the gold-mention assumption in Recasens and Hovy (2011) can be lifted without changing the original definition.", "labels": [], "entities": []}, {"text": "In fact, the proposed BLANC metric subsumes the original one in that its value is identical to the original one when response mentions are identical to key mentions.", "labels": [], "entities": [{"text": "BLANC", "start_pos": 22, "end_pos": 27, "type": "METRIC", "confidence": 0.7515392899513245}]}, {"text": "The rest of the paper is organized as follows.", "labels": [], "entities": []}, {"text": "We introduce the notions used in this paper in Section 2.", "labels": [], "entities": []}, {"text": "We then present the original BLANCgold in Section 3 using the set notation defined in Section 2.", "labels": [], "entities": [{"text": "BLANCgold", "start_pos": 29, "end_pos": 38, "type": "DATASET", "confidence": 0.5361523032188416}]}, {"text": "This paves the way to generalize it to imperfect system mentions, which is presented in Section 4.", "labels": [], "entities": []}, {"text": "The proposed BLANC is applied to the CoNLL 2011 and 2012 shared task participants, and the scores and its correlations with existing metrics are shown in Section 5.", "labels": [], "entities": [{"text": "BLANC", "start_pos": 13, "end_pos": 18, "type": "METRIC", "confidence": 0.9862529635429382}, {"text": "CoNLL 2011 and 2012 shared task participants", "start_pos": 37, "end_pos": 81, "type": "DATASET", "confidence": 0.9092447076525006}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: The proposed BLANC scores of the  CoNLL-2011 shared task participants.", "labels": [], "entities": [{"text": "BLANC", "start_pos": 23, "end_pos": 28, "type": "METRIC", "confidence": 0.981316328048706}, {"text": "CoNLL-2011 shared task participants", "start_pos": 44, "end_pos": 79, "type": "DATASET", "confidence": 0.8343973904848099}]}, {"text": " Table 2: The proposed BLANC scores of the  CoNLL-2012 shared task participants.", "labels": [], "entities": [{"text": "BLANC", "start_pos": 23, "end_pos": 28, "type": "METRIC", "confidence": 0.9833933711051941}, {"text": "CoNLL-2012 shared task participants", "start_pos": 44, "end_pos": 79, "type": "DATASET", "confidence": 0.8242939710617065}]}, {"text": " Table 3: Pearson's r correlation coefficients be- tween the proposed BLANC and the other coref- erence measures based on the CoNLL 2011/2012  results. All p-values are significant at < 0.001.", "labels": [], "entities": [{"text": "Pearson's r correlation", "start_pos": 10, "end_pos": 33, "type": "METRIC", "confidence": 0.6545378267765045}, {"text": "BLANC", "start_pos": 70, "end_pos": 75, "type": "METRIC", "confidence": 0.7256945967674255}, {"text": "coref- erence", "start_pos": 90, "end_pos": 103, "type": "METRIC", "confidence": 0.5367074012756348}, {"text": "CoNLL 2011/2012", "start_pos": 126, "end_pos": 141, "type": "DATASET", "confidence": 0.9614980071783066}]}]}