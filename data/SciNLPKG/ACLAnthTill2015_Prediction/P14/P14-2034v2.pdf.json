{"title": [{"text": "Word Segmentation of Informal Arabic with Domain Adaptation", "labels": [], "entities": [{"text": "Word Segmentation", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.6145941317081451}]}], "abstractContent": [{"text": "Segmentation of clitics has been shown to improve accuracy on a variety of Arabic NLP tasks.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 50, "end_pos": 58, "type": "METRIC", "confidence": 0.9989140033721924}]}, {"text": "However, state-of-the-art Ara-bic word segmenters are either limited to formal Modern Standard Arabic, performing poorly on Arabic text featuring dialectal vocabulary and grammar, or rely on linguistic knowledge that is hand-tuned for each dialect.", "labels": [], "entities": [{"text": "Ara-bic word segmenters", "start_pos": 26, "end_pos": 49, "type": "TASK", "confidence": 0.613325297832489}]}, {"text": "We extend an existing MSA segmenter with a simple domain adaptation technique and new features in order to segment informal and dialectal Arabic text.", "labels": [], "entities": [{"text": "MSA segmenter", "start_pos": 22, "end_pos": 35, "type": "TASK", "confidence": 0.8681968450546265}]}, {"text": "Experiments show that our system outper-forms existing systems on broadcast news and Egyptian dialect, improving segmenta-tion F 1 score on a recently released Egyp-tian Arabic corpus to 92.09%, compared to 91.60% for another segmenter designed specifically for Egyptian Arabic.", "labels": [], "entities": [{"text": "segmenta-tion F 1 score", "start_pos": 113, "end_pos": 136, "type": "METRIC", "confidence": 0.7326590195298195}, {"text": "Egyp-tian Arabic corpus", "start_pos": 160, "end_pos": 183, "type": "DATASET", "confidence": 0.875464936097463}]}], "introductionContent": [{"text": "Segmentation of words, clitics, and affixes is essential fora number of natural language processing (NLP) applications, including machine translation, parsing, and speech recognition ().", "labels": [], "entities": [{"text": "Segmentation of words, clitics", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.8308149695396423}, {"text": "machine translation", "start_pos": 130, "end_pos": 149, "type": "TASK", "confidence": 0.7728138864040375}, {"text": "speech recognition", "start_pos": 164, "end_pos": 182, "type": "TASK", "confidence": 0.7260358780622482}]}, {"text": "Segmentation is a common practice in Arabic NLP due to the language's morphological richness.", "labels": [], "entities": []}, {"text": "Specifically, clitic separation has been shown to improve performance on Arabic parsing and Arabic-English machine translation).", "labels": [], "entities": [{"text": "clitic separation", "start_pos": 14, "end_pos": 31, "type": "TASK", "confidence": 0.913485199213028}, {"text": "Arabic parsing", "start_pos": 73, "end_pos": 87, "type": "TASK", "confidence": 0.5883272588253021}, {"text": "Arabic-English machine translation", "start_pos": 92, "end_pos": 126, "type": "TASK", "confidence": 0.7060082952181498}]}, {"text": "However, the variety of Arabic dialects presents challenges in Arabic NLP.", "labels": [], "entities": []}, {"text": "Dialectal Arabic contains non-standard orthography, vocabulary, morphology, and syntax.", "labels": [], "entities": []}, {"text": "Tools that depend on corpora or grammatical properties that only consider formal Modern Standard Arabic (MSA) do not perform well when confronted with these differences.", "labels": [], "entities": []}, {"text": "The creation of annotated corpora in dialectal Arabic () has promoted the development of new systems that support dialectal Arabic, but these systems tend to be tailored to specific dialects and require separate, costly efforts for Egyptian Arabic, Levantine Arabic, Maghrebi Arabic, etc.", "labels": [], "entities": []}, {"text": "We present a single clitic segmentation model that is accurate on both MSA and informal Arabic.", "labels": [], "entities": []}, {"text": "The model is an extension of the character-level conditional random field (CRF) model of.", "labels": [], "entities": []}, {"text": "Our work goes beyond theirs in three aspects.", "labels": [], "entities": []}, {"text": "First, we handle two Arabic orthographic normalization rules that commonly require rewriting of tokens after segmentation.", "labels": [], "entities": [{"text": "Arabic orthographic normalization", "start_pos": 21, "end_pos": 54, "type": "TASK", "confidence": 0.6607313752174377}]}, {"text": "Second, we add new features that improve segmentation accuracy.", "labels": [], "entities": [{"text": "segmentation", "start_pos": 41, "end_pos": 53, "type": "TASK", "confidence": 0.9779535531997681}, {"text": "accuracy", "start_pos": 54, "end_pos": 62, "type": "METRIC", "confidence": 0.876044511795044}]}, {"text": "Third, we show that dialectal data can be handled in the framework of domain adaptation.", "labels": [], "entities": []}, {"text": "Specifically, we show that even simple feature space augmentation) yields significant improvements in task accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 107, "end_pos": 115, "type": "METRIC", "confidence": 0.9819751381874084}]}, {"text": "We compare our work to the original Green and DeNero model and two other Arabic segmentation systems: the MADA+TOKAN toolkit v.", "labels": [], "entities": [{"text": "MADA+TOKAN toolkit", "start_pos": 106, "end_pos": 124, "type": "DATASET", "confidence": 0.6306024938821793}]}, {"text": "3.1 () and its Egyptian dialect variant, MADA-ARZ v.", "labels": [], "entities": []}, {"text": "We demonstrate that our system outperforms all three other systems on broadcast news and Egyptian dialect in F 1 segmentation score, achieving a 92.09% F 1 score evaluated against a gold standard on Egyptian dialect data, compared to 91.60% for MADA-ARZ and 88.64% for Green and DeNero.", "labels": [], "entities": [{"text": "F 1 segmentation score", "start_pos": 109, "end_pos": 131, "type": "METRIC", "confidence": 0.8272331804037094}, {"text": "F 1 score", "start_pos": 152, "end_pos": 161, "type": "METRIC", "confidence": 0.9825290640195211}]}, {"text": "In addition, our model decodes input an order of magnitude faster than either version of MADA.", "labels": [], "entities": [{"text": "MADA", "start_pos": 89, "end_pos": 93, "type": "DATASET", "confidence": 0.7560383677482605}]}, {"text": "Like the Green and DeNero system, but unlike MADA and MADA-ARZ, our system does not rely on a morphological analyzer, and can be applied directly to any dialect for which segmented training data is available.", "labels": [], "entities": []}, {"text": "The source code is available in the latest public release of the Stanford Word Segmenter (http://nlp.stanford.edu/software/ segmenter.shtml).", "labels": [], "entities": []}, {"text": "A CRF model) defines a distribution p(Y|X; \u03b8), where X = {x 1 , . .", "labels": [], "entities": []}, {"text": ", x N } is the observed input sequence and Y = {y 1 , . .", "labels": [], "entities": []}, {"text": ", y N } is the sequence of labels we seek to predict.", "labels": [], "entities": []}, {"text": "Green and DeNero use a linear-chain model with X as the sequence of input characters, and Y * chosen according to the decision rule where \u03c6 is the feature map defined in Section 2.1.", "labels": [], "entities": []}, {"text": "Their model classifies each y i as one of I (continuation of a segment), O (whitespace outside any segment), B (beginning of a segment), or F (pregrouped foreign characters).", "labels": [], "entities": []}, {"text": "Our segmenter expands this label space in order to handle four Arabic-specific orthographic rules.", "labels": [], "entities": []}, {"text": "In our model, each y i can take on one of the five values {I, O, B, F, RRR}, where the label RRR indicates one of the following orthographic rewrites: \u2022 if the current character is the Arabic letter l, it should start anew segment and be transformed into the definite article al-when segmented.", "labels": [], "entities": [{"text": "RRR", "start_pos": 71, "end_pos": 74, "type": "METRIC", "confidence": 0.9574043154716492}, {"text": "RRR", "start_pos": 93, "end_pos": 96, "type": "METRIC", "confidence": 0.9324886202812195}]}, {"text": "This type of transformation occurs after the prefix li-\"to\".", "labels": [], "entities": []}, {"text": "\u2022 if the current character is the letter t, it is a continuation but should become the letter h when segmented.", "labels": [], "entities": []}, {"text": "Arabic orthography rules restrict the occurrence of h to the word-final position, writing it instead as t whenever it is followed by a clitic.", "labels": [], "entities": []}, {"text": "\u2022 if the current character is the letter y or \u00af a, it is a continuation but should become the opposite letter.", "labels": [], "entities": []}, {"text": "In MSA, certain prepositions are spelled with a \u00af a that becomes y when a clitic follows; in Egyptian dialect, these two letters are often interchangeable.", "labels": [], "entities": []}], "datasetContent": [{"text": "We train and evaluate on three corpora: parts 1-3 of the newswire Arabic Treebank (ATB),  ATB, we use the same split as.", "labels": [], "entities": [{"text": "Arabic Treebank (ATB)", "start_pos": 66, "end_pos": 87, "type": "DATASET", "confidence": 0.9202099680900574}, {"text": "ATB", "start_pos": 90, "end_pos": 93, "type": "DATASET", "confidence": 0.9278756380081177}]}, {"text": "For the other two corpora, we use the procedure defined by.", "labels": [], "entities": []}, {"text": "We train the Green and DeNero model and our improvements using L-BFGS with L 2 regularization.", "labels": [], "entities": []}, {"text": "We use two evaluation metrics in our experiments.", "labels": [], "entities": []}, {"text": "The first is an F 1 precision-recall measure, ignoring orthographic rewrites.", "labels": [], "entities": [{"text": "F 1 precision-recall measure", "start_pos": 16, "end_pos": 44, "type": "METRIC", "confidence": 0.846075564622879}]}, {"text": "F 1 scores provide a more informative assessment of performance than wordlevel or character-level accuracy scores, as over 80% of tokens in the development sets consist of only one segment, with an average of one segmentation every 4.7 tokens (or one every 20.4 characters).", "labels": [], "entities": [{"text": "F 1 scores", "start_pos": 0, "end_pos": 10, "type": "METRIC", "confidence": 0.7315697769323984}, {"text": "accuracy", "start_pos": 98, "end_pos": 106, "type": "METRIC", "confidence": 0.9327690005302429}]}, {"text": "The second metric we use is the TEDEval metric (.", "labels": [], "entities": [{"text": "TEDEval metric", "start_pos": 32, "end_pos": 46, "type": "METRIC", "confidence": 0.8565901219844818}]}, {"text": "TEDEval was developed to evaluate joint segmentation and parsing 5 in Hebrew, which requires a greater variety of orthographic rewrites than those possible in Arabic.", "labels": [], "entities": [{"text": "joint segmentation", "start_pos": 34, "end_pos": 52, "type": "TASK", "confidence": 0.595390111207962}]}, {"text": "Its edit distance-based scoring algorithm is robust enough to handle the rewrites produced by both MADA and our segmenter.", "labels": [], "entities": [{"text": "MADA", "start_pos": 99, "end_pos": 103, "type": "DATASET", "confidence": 0.8090541362762451}]}, {"text": "We measure the statistical significance of differences in these metrics with an approximate randomization test), with R = 10,000 samples.: Test set results.", "labels": [], "entities": []}, {"text": "Our final model (last row) is trained on all available data (ATB+BN+ARZ).", "labels": [], "entities": [{"text": "ATB+BN+ARZ)", "start_pos": 61, "end_pos": 72, "type": "METRIC", "confidence": 0.8100447356700897}]}, {"text": "Font style indicates significance relative to the next highest model (bold: p < 0.001, bold italic: p < 0.05).", "labels": [], "entities": [{"text": "Font", "start_pos": 0, "end_pos": 4, "type": "METRIC", "confidence": 0.9908113479614258}, {"text": "significance", "start_pos": 21, "end_pos": 33, "type": "METRIC", "confidence": 0.8972482681274414}]}], "tableCaptions": [{"text": " Table 1: Development set results. GD is the model of", "labels": [], "entities": []}, {"text": " Table 2: Test set results. Our final model (last row) is trained on all available data (ATB+BN+ARZ). Font  style indicates significance relative to the next highest model (bold: p < 0.001, bold italic: p < 0.05).", "labels": [], "entities": [{"text": "ATB+BN+ARZ)", "start_pos": 89, "end_pos": 100, "type": "METRIC", "confidence": 0.8379684686660767}, {"text": "Font", "start_pos": 102, "end_pos": 106, "type": "METRIC", "confidence": 0.9895293116569519}]}, {"text": " Table 4: Counts of error categories (out of 100  randomly sampled ARZ development set errors).", "labels": [], "entities": [{"text": "Counts", "start_pos": 10, "end_pos": 16, "type": "METRIC", "confidence": 0.959471583366394}, {"text": "ARZ development set errors", "start_pos": 67, "end_pos": 93, "type": "DATASET", "confidence": 0.7735601961612701}]}]}