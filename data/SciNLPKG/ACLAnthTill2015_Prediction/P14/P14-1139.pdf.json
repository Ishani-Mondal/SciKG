{"title": [{"text": "A Constrained Viterbi Relaxation for Bidirectional Word Alignment", "labels": [], "entities": [{"text": "Bidirectional Word Alignment", "start_pos": 37, "end_pos": 65, "type": "TASK", "confidence": 0.5928341746330261}]}], "abstractContent": [{"text": "Bidirectional models of word alignment are an appealing alternative to post-hoc combinations of directional word align-ers.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 24, "end_pos": 38, "type": "TASK", "confidence": 0.7726923823356628}]}, {"text": "Unfortunately, most bidirectional formulations are NP-Hard to solve, and a previous attempt to use a relaxation-based decoder yielded few exact solutions (6%).", "labels": [], "entities": []}, {"text": "We present a novel relaxation for decoding the bidirectional model of DeNero and Macherey (2011).", "labels": [], "entities": []}, {"text": "The relaxation can be solved with a modified version of the Viterbi algorithm.", "labels": [], "entities": []}, {"text": "To find optimal solutions on difficult instances, we alternate between incre-mentally adding constraints and applying optimality-preserving coarse-to-fine pruning.", "labels": [], "entities": []}, {"text": "The algorithm finds provably exact solutions on 86% of sentence pairs and shows improvements over directional models.", "labels": [], "entities": []}], "introductionContent": [{"text": "Word alignment is a critical first step for building statistical machine translation systems.", "labels": [], "entities": [{"text": "Word alignment", "start_pos": 0, "end_pos": 14, "type": "TASK", "confidence": 0.7413723021745682}, {"text": "statistical machine translation", "start_pos": 53, "end_pos": 84, "type": "TASK", "confidence": 0.634986678759257}]}, {"text": "In order to ensure accurate word alignments, most systems employ a post-hoc symmetrization step to combine directional word aligners, such as IBM Model 4 () or hidden Markov model (HMM) based aligners (.", "labels": [], "entities": [{"text": "word alignments", "start_pos": 28, "end_pos": 43, "type": "TASK", "confidence": 0.6991418749094009}]}, {"text": "Several authors have proposed bidirectional models that incorporate this step directly, but decoding under many bidirectional models is NP-Hard and finding exact solutions has proven difficult.", "labels": [], "entities": []}, {"text": "In this paper, we describe a novel Lagrangianrelaxation based decoder for the bidirectional model proposed by, with the goal of improving search accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 145, "end_pos": 153, "type": "METRIC", "confidence": 0.9785861968994141}]}, {"text": "In that work, the authors implement a dual decomposition-based decoder for the problem, but are only able to find exact solutions for around 6% of instances.", "labels": [], "entities": []}, {"text": "Our decoder uses a simple variant of the Viterbi algorithm for solving a relaxed version of this model.", "labels": [], "entities": []}, {"text": "The algorithm makes it easy to reintroduce constraints for difficult instances, at the cost of increasing run-time complexity.", "labels": [], "entities": []}, {"text": "To offset this cost, we employ optimality-preserving coarseto-fine pruning to reduce the search space.", "labels": [], "entities": []}, {"text": "The pruning method utilizes lower bounds on the cost of valid bidirectional alignments, which we obtain from a fast, greedy decoder.", "labels": [], "entities": []}, {"text": "The method has the following properties: \u2022 It is based on a novel relaxation for the model of, solvable with a variant of the Viterbi algorithm.", "labels": [], "entities": []}, {"text": "\u2022 To find optimal solutions, it employs an efficient strategy that alternates between adding constraints and applying pruning.", "labels": [], "entities": []}, {"text": "\u2022 Empirically, it is able to find exact solutions on 86% of sentence pairs and is significantly faster than general-purpose solvers.", "labels": [], "entities": []}, {"text": "We begin in Section 2 by formally describing the directional word alignment problem.", "labels": [], "entities": [{"text": "directional word alignment", "start_pos": 49, "end_pos": 75, "type": "TASK", "confidence": 0.6217830578486124}]}, {"text": "Section 3 describes a preliminary bidirectional model using full agreement constraints and a Lagrangian relaxation-based solver.", "labels": [], "entities": []}, {"text": "Section 4 modifies this model to include adjacency constraints.", "labels": [], "entities": []}, {"text": "Section 5 describes an extension to the relaxed algorithm to explicitly enforce constraints, and Section 6 gives a pruning method for improving the efficiency of the algorithm.", "labels": [], "entities": []}, {"text": "Experiments compare the search error and accuracy of the new bidirectional algorithm to several directional combiners and other bidirectional algorithms.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 41, "end_pos": 49, "type": "METRIC", "confidence": 0.9996116757392883}]}, {"text": "Results show that the new relaxation is much more effective at finding exact solutions and is able to produce comparable alignment accuracy.", "labels": [], "entities": [{"text": "alignment", "start_pos": 121, "end_pos": 130, "type": "TASK", "confidence": 0.9024688005447388}, {"text": "accuracy", "start_pos": 131, "end_pos": 139, "type": "METRIC", "confidence": 0.9038171172142029}]}], "datasetContent": [{"text": "Our experimental results compare the accuracy and optimality of our decoding algorithm to directional alignment models and previous work on this bidirectional model.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 37, "end_pos": 45, "type": "METRIC", "confidence": 0.9993533492088318}]}], "tableCaptions": [{"text": " Table 1: Experimental results for model accuracy of bilingual alignment. Column time is the mean time per sentence pair in  seconds; cert is the percentage of sentence pairs solved with a certificate of optimality; exact is the percentage of sentence pairs  solved exactly. Results are grouped by sentence length. The percentage of sentence pairs in each group is shown in parentheses.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 41, "end_pos": 49, "type": "METRIC", "confidence": 0.9868885278701782}, {"text": "bilingual alignment", "start_pos": 53, "end_pos": 72, "type": "TASK", "confidence": 0.7223600447177887}, {"text": "Column time", "start_pos": 74, "end_pos": 85, "type": "METRIC", "confidence": 0.9199468493461609}]}, {"text": " Table 2: Alignment accuracy and phrase pair extraction ac- curacy for directional and bidirectional models. Prec is the  precision. Rec is the recall. AER is alignment error rate and  F1 is the phrase pair extraction F1 score.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 20, "end_pos": 28, "type": "METRIC", "confidence": 0.934289813041687}, {"text": "phrase pair extraction", "start_pos": 33, "end_pos": 55, "type": "TASK", "confidence": 0.6851171652475992}, {"text": "Prec", "start_pos": 109, "end_pos": 113, "type": "METRIC", "confidence": 0.9927129149436951}, {"text": "precision", "start_pos": 122, "end_pos": 131, "type": "METRIC", "confidence": 0.9976682066917419}, {"text": "recall", "start_pos": 144, "end_pos": 150, "type": "METRIC", "confidence": 0.9977869987487793}, {"text": "AER", "start_pos": 152, "end_pos": 155, "type": "METRIC", "confidence": 0.9983892440795898}, {"text": "alignment error rate", "start_pos": 159, "end_pos": 179, "type": "METRIC", "confidence": 0.8500743905703226}, {"text": "F1", "start_pos": 185, "end_pos": 187, "type": "METRIC", "confidence": 0.9977706670761108}, {"text": "F1 score", "start_pos": 218, "end_pos": 226, "type": "METRIC", "confidence": 0.8668291568756104}]}]}