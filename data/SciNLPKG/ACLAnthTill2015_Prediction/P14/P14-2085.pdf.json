{"title": [{"text": "Automatic prediction of aspectual class of verbs in context", "labels": [], "entities": []}], "abstractContent": [{"text": "This paper describes anew approach to predicting the aspectual class of verbs in context, i.e., whether a verb is used in a stative or dynamic sense.", "labels": [], "entities": [{"text": "predicting the aspectual class of verbs in context", "start_pos": 38, "end_pos": 88, "type": "TASK", "confidence": 0.7597844041883945}]}, {"text": "We identify two challenging cases of this problem: when the verb is unseen in training data, and when the verb is ambiguous for aspec-tual class.", "labels": [], "entities": []}, {"text": "A semi-supervised approach using linguistically-motivated features and a novel set of distributional features based on representative verb types allows us to predict classes accurately, even for unseen verbs.", "labels": [], "entities": []}, {"text": "Many frequent verbs can be either stative or dynamic in different contexts, which has not been modeled by previous work; we use contextual features to resolve this ambiguity.", "labels": [], "entities": []}, {"text": "In addition, we introduce two new datasets of clauses marked for aspectual class.", "labels": [], "entities": []}], "introductionContent": [{"text": "In this work, we focus on the automatic prediction of whether a verb in context is used in a stative or in a dynamic sense, the most fundamental distinction in all taxonomies of aspectual class.", "labels": [], "entities": []}, {"text": "The aspectual class of a discourse's finite verbs is an important factor in conveying and interpreting temporal structure; others are tense, grammatical aspect, mood and whether the utterance represents an event as completed.", "labels": [], "entities": [{"text": "conveying and interpreting temporal structure", "start_pos": 76, "end_pos": 121, "type": "TASK", "confidence": 0.7175953567028046}]}, {"text": "More accurate temporal information processing is expected to be beneficial fora variety of natural language processing tasks (.", "labels": [], "entities": [{"text": "temporal information processing", "start_pos": 14, "end_pos": 45, "type": "TASK", "confidence": 0.6444074610869089}]}, {"text": "While most verbs have one predominant interpretation, others are more flexible for aspectual class and can occur as either stative (1) or dynamic (2) depending on the context.", "labels": [], "entities": []}, {"text": "There are also cases that allow for both readings, such as (3).", "labels": [], "entities": []}, {"text": "Cases like (3) do not imply that there is a third class, but rather that two interpretations are available for the sentence, of which usually one will be chosen by a reader.", "labels": [], "entities": []}, {"text": "Following, we aim to automatically classify clauses for fundamental aspectual class, a function of the main verb and a select group of complements, which may differ per verb.", "labels": [], "entities": []}, {"text": "This corresponds to the aspectual class of the clause's main verb when ignoring any aspectual markers or transformations.", "labels": [], "entities": []}, {"text": "For example, English sentences with perfect tense are usually considered to introduce states to the discourse), but we are interested in the aspectual class before this transformation takes place.", "labels": [], "entities": []}, {"text": "The clause John has kissed Mary introduces a state, but the fundamental aspectual class of the 'tenseless' clause John kiss Mary is dynamic.", "labels": [], "entities": []}, {"text": "In contrast to, we do not conduct the task of predicting aspectual class solely at the type level, as such an approach ignores the minority class of ambiguous verbs.", "labels": [], "entities": [{"text": "predicting aspectual class", "start_pos": 46, "end_pos": 72, "type": "TASK", "confidence": 0.8967665036519369}]}, {"text": "Instead we predict the aspectual class of verbs in the context of their arguments and modifiers.", "labels": [], "entities": []}, {"text": "We show that this method works better than using only type-based features, especially for verbs with ambiguous aspectual class.", "labels": [], "entities": []}, {"text": "In addition, we show that type-based features, including novel distributional features based on representative verbs, accurately predict predominant aspectual class for unseen verb types.", "labels": [], "entities": []}, {"text": "Our work differs from prior work in that we treat the problem as a three-way classification task, predicting DYNAMIC, STATIVE or BOTH as the aspectual class of a verb in context.", "labels": [], "entities": [{"text": "DYNAMIC", "start_pos": 109, "end_pos": 116, "type": "METRIC", "confidence": 0.8278412222862244}, {"text": "STATIVE", "start_pos": 118, "end_pos": 125, "type": "METRIC", "confidence": 0.9479357004165649}, {"text": "BOTH", "start_pos": 129, "end_pos": 133, "type": "METRIC", "confidence": 0.8340277075767517}]}], "datasetContent": [{"text": "The experiments presented in this section aim to evaluate the effectiveness of the feature sets described in the previous section, focusing on the challenging cases of verb types unseen in the training data and highly ambiguous verbs.", "labels": [], "entities": []}, {"text": "The feature Lemma indicates that the verb's lemma is used as an additional feature.", "labels": [], "entities": []}, {"text": "The setting of our first experiment follows..", "labels": [], "entities": []}, {"text": "*Indicates that result is significantly 4 different from the respective baseline. of a verb type in the respective training folds.", "labels": [], "entities": []}, {"text": "This experiment shows a successful case of semisupervised learning: while type-based feature values can be estimated from large corpora in an unsupervised way, some labeled training data is necessary to learn their best combination.", "labels": [], "entities": []}, {"text": "This experiment specifically examines performance on verbs not seen in labeled training data.", "labels": [], "entities": []}, {"text": "We use 10-fold cross validation but ensure that all occurrences of a verb type appear in the same fold: verb types in each test fold have not been seen in the respective training data, ruling out the Lemma feature.", "labels": [], "entities": []}, {"text": "A Logistic regression classifier () works better here (using only numeric features), and we present results in: Experiment 3: 'MULTI-LABEL', precision, recall and F-measure, detailed class statistics for the best-performing system from for multi-label verbs (instances have differing labels in Asp-MASC).", "labels": [], "entities": [{"text": "MULTI-LABEL", "start_pos": 127, "end_pos": 138, "type": "METRIC", "confidence": 0.9900907278060913}, {"text": "precision", "start_pos": 141, "end_pos": 150, "type": "METRIC", "confidence": 0.9994599223136902}, {"text": "recall", "start_pos": 152, "end_pos": 158, "type": "METRIC", "confidence": 0.9983970522880554}, {"text": "F-measure", "start_pos": 163, "end_pos": 172, "type": "METRIC", "confidence": 0.9920151233673096}]}, {"text": "We expect one-label verbs to have a strong predominant aspectual class, and multi-label verbs to be more flexible.", "labels": [], "entities": []}, {"text": "Otherwise, the experimental setup is as in experiment 1.", "labels": [], "entities": []}, {"text": "In each case, the linguistic indicator features again perform on par with the baseline.", "labels": [], "entities": []}, {"text": "For multi-label verbs, the feature combination Lemma+LingInd+Inst leads to significant 4 improvement of 2% gain inaccuracy over the baseline; reports detailed class statistics and reveals again in F-measure of 3 points over the baseline.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 197, "end_pos": 206, "type": "METRIC", "confidence": 0.9966390132904053}]}, {"text": "To sum up, Inst features are essential for classifying multi-label verbs, and the LingInd features provide some useful prior.", "labels": [], "entities": [{"text": "Inst", "start_pos": 11, "end_pos": 15, "type": "METRIC", "confidence": 0.907627284526825}]}, {"text": "These results motivate the need for an instance-based approach.", "labels": [], "entities": []}, {"text": "For verbs with ambiguous aspectual class, typebased classification is not sufficient, as this approach selects a dominant sense for any given verb and then always assigns that.", "labels": [], "entities": [{"text": "typebased classification", "start_pos": 42, "end_pos": 66, "type": "TASK", "confidence": 0.7351649105548859}]}, {"text": "Therefore we propose handling ambiguous verbs separately.", "labels": [], "entities": []}, {"text": "As Asp-MASC contains only few instances of each of the ambiguous verbs, we turn to the Asp-Ambig dataset.", "labels": [], "entities": [{"text": "Asp-Ambig dataset", "start_pos": 87, "end_pos": 104, "type": "DATASET", "confidence": 0.9773592054843903}]}, {"text": "We perform a Leave-One-Out (LOO) cross validation evaluation, with results reported in.", "labels": [], "entities": []}, {"text": "Using the Inst features alone (not shown in) results in a micro-average accuracy of only 58.1%: these features are only useful when combined with the feature Lemma.", "labels": [], "entities": [{"text": "Inst", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9930440783500671}, {"text": "accuracy", "start_pos": 72, "end_pos": 80, "type": "METRIC", "confidence": 0.9743914604187012}]}, {"text": "For classifying verbs whose most frequent class occurs less than 56% of the time, Lemma+Inst features are essential.", "labels": [], "entities": [{"text": "Lemma", "start_pos": 82, "end_pos": 87, "type": "METRIC", "confidence": 0.9878908395767212}, {"text": "Inst", "start_pos": 88, "end_pos": 92, "type": "METRIC", "confidence": 0.5281811952590942}]}, {"text": "Whether or not performance is improved by adding LingInd/Dist features, with their bias towards one aspectual class, depends on the verb type.", "labels": [], "entities": []}, {"text": "It is an open research question which verb types should be treated in which way.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Asp-MASC: Cohen's observed un- weighted \u03ba.", "labels": [], "entities": []}, {"text": " Table 2: Asp-MASC: confusion matrix for two  annotators, without have/be/none clauses, \u03ba is 0.7.", "labels": [], "entities": [{"text": "Asp-MASC", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.8752480149269104}]}, {"text": " Table 3: Asp-Ambig: confusion matrix for two  annotators. Cohen's \u03ba is 0.6.", "labels": [], "entities": []}, {"text": " Table 5: Instance-based (Inst) features", "labels": [], "entities": [{"text": "Instance-based", "start_pos": 10, "end_pos": 24, "type": "METRIC", "confidence": 0.8105050325393677}]}, {"text": " Table 6: Experiment 1: SEEN verbs, using Asp- MASC. Baseline memorizes most frequent class  per verb type in training folds.", "labels": [], "entities": [{"text": "SEEN", "start_pos": 24, "end_pos": 28, "type": "METRIC", "confidence": 0.7838668823242188}, {"text": "Asp- MASC", "start_pos": 42, "end_pos": 51, "type": "METRIC", "confidence": 0.7808691263198853}]}, {"text": " Table 7: Experiment 2: UNSEEN verb types, Lo- gistic regression, Asp-MASC. Baseline labels ev- erything with the most frequent class in the train- ing set (DYNAMIC). *Significantly 4 different from  line 1.  \u2020Significantly 4 different from line 3.", "labels": [], "entities": [{"text": "UNSEEN verb types", "start_pos": 24, "end_pos": 41, "type": "TASK", "confidence": 0.6105962991714478}, {"text": "Asp-MASC", "start_pos": 66, "end_pos": 74, "type": "METRIC", "confidence": 0.9351422786712646}]}, {"text": " Table 8: Experiment 3: 'ONE-VS. MULTI- LABEL' verbs, Asp-MASC. Baseline as in", "labels": [], "entities": [{"text": "ONE-VS", "start_pos": 25, "end_pos": 31, "type": "METRIC", "confidence": 0.9219922423362732}, {"text": "MULTI- LABEL", "start_pos": 33, "end_pos": 45, "type": "METRIC", "confidence": 0.8575513164202372}]}, {"text": " Table  6. *Indicates that result is significantly 4 different  from the respective baseline.", "labels": [], "entities": [{"text": "Indicates", "start_pos": 12, "end_pos": 21, "type": "METRIC", "confidence": 0.982067346572876}]}, {"text": " Table 9: Experiment 3: 'MULTI-LABEL', preci- sion, recall and F-measure, detailed class statistics  for the best-performing system from", "labels": [], "entities": [{"text": "MULTI-LABEL", "start_pos": 25, "end_pos": 36, "type": "METRIC", "confidence": 0.9758150577545166}, {"text": "recall", "start_pos": 52, "end_pos": 58, "type": "METRIC", "confidence": 0.9980880618095398}, {"text": "F-measure", "start_pos": 63, "end_pos": 72, "type": "METRIC", "confidence": 0.9861878752708435}]}]}