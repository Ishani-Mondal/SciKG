{"title": [{"text": "Learning to Predict Distributions of Words Across Domains", "labels": [], "entities": [{"text": "Learning to Predict Distributions of Words Across Domains", "start_pos": 0, "end_pos": 57, "type": "TASK", "confidence": 0.7592566758394241}]}], "abstractContent": [{"text": "Although the distributional hypothesis has been applied successfully in many natural language processing tasks, systems using distributional information have been limited to a single domain because the distribution of a word can vary between domains as the word's predominant meaning changes.", "labels": [], "entities": []}, {"text": "However, if it were possible to predict how the distribution of a word changes from one domain to another , the predictions could be used to adapt a system trained in one domain to work in another.", "labels": [], "entities": []}, {"text": "We propose an unsuper-vised method to predict the distribution of a word in one domain, given its distribution in another domain.", "labels": [], "entities": []}, {"text": "We evaluate our method on two tasks: cross-domain part-of-speech tagging and cross-domain sentiment classification.", "labels": [], "entities": [{"text": "cross-domain part-of-speech tagging", "start_pos": 37, "end_pos": 72, "type": "TASK", "confidence": 0.608519027630488}, {"text": "cross-domain sentiment classification", "start_pos": 77, "end_pos": 114, "type": "TASK", "confidence": 0.7196880777676901}]}, {"text": "In both tasks, our method significantly outperforms competitive baselines and returns results that are statistically comparable to current state-of-the-art methods, while requiring no task-specific customisations.", "labels": [], "entities": []}], "introductionContent": [{"text": "The Distributional Hypothesis, summarised by the memorable line of -You shall know a word by the company it keeps -has inspired a diverse range of research in natural language processing.", "labels": [], "entities": [{"text": "Distributional Hypothesis", "start_pos": 4, "end_pos": 29, "type": "TASK", "confidence": 0.8531000018119812}, {"text": "natural language processing", "start_pos": 159, "end_pos": 186, "type": "TASK", "confidence": 0.6286331514517466}]}, {"text": "In such work, a word is represented by the distribution of other words that co-occur with it.", "labels": [], "entities": []}, {"text": "Distributional representations of words have been successfully used in many language processing tasks such as entity set expansion (, part-of-speech (POS) tagging and chunking (, ontology learning, computing semantic textual similarity), and lexical inference ().", "labels": [], "entities": [{"text": "entity set expansion", "start_pos": 110, "end_pos": 130, "type": "TASK", "confidence": 0.6295137604077657}, {"text": "part-of-speech (POS) tagging and chunking", "start_pos": 134, "end_pos": 175, "type": "TASK", "confidence": 0.6723397629601615}]}, {"text": "However, the distribution of a word often varies from one domain 1 to another.", "labels": [], "entities": []}, {"text": "For example, in the domain of portable computer reviews the word lightweight is often associated with positive sentiment bearing words such as sleek or compact, whereas in the movie review domain the same word is often associated with negative sentimentbearing words such as superficial or formulaic.", "labels": [], "entities": []}, {"text": "Consequently, the distributional representations of the word lightweight will differ considerably between the two domains.", "labels": [], "entities": []}, {"text": "In this paper, given the distribution w S of a word win the source domain S, we propose an unsupervised method for predicting its distribution w T in a different target domain T . The ability to predict how the distribution of a word varies from one domain to another is vital for numerous adaptation tasks.", "labels": [], "entities": []}, {"text": "For example, unsupervised cross-domain sentiment classification) involves using sentiment-labeled user reviews from the source domain, and unlabeled reviews from both the source and the target domains to learn a sentiment classifier for the target domain.", "labels": [], "entities": [{"text": "cross-domain sentiment classification", "start_pos": 26, "end_pos": 63, "type": "TASK", "confidence": 0.7538022597630819}]}, {"text": "Domain adaptation (DA) of sentiment classification becomes extremely challenging when the distributions of words in the source and the target domains are very different, because the features learnt from the source domain labeled reviews might not appear in the target domain reviews that must be classified.", "labels": [], "entities": [{"text": "Domain adaptation (DA) of sentiment classification", "start_pos": 0, "end_pos": 50, "type": "TASK", "confidence": 0.7982950769364834}]}, {"text": "By predicting the distribution of a word across different domains, we can find source domain features that are similar to the features in target domain reviews, thereby reducing the mismatch of features between the two domains.", "labels": [], "entities": []}, {"text": "We propose a two-step unsupervised approach to predict the distribution of a word across domains.", "labels": [], "entities": []}, {"text": "First, we create two lower dimensional la-tent feature spaces separately for the source and the target domains using Singular Value Decomposition (SVD).", "labels": [], "entities": []}, {"text": "Second, we learn a mapping from the source domain latent feature space to the target domain latent feature space using Partial Least Square Regression (PLSR).", "labels": [], "entities": []}, {"text": "The SVD smoothing in the first step both reduces the data sparseness in distributional representations of individual words, as well as the dimensionality of the feature space, thereby enabling us to efficiently and accurately learn a prediction model using PLSR in the second step.", "labels": [], "entities": [{"text": "SVD smoothing", "start_pos": 4, "end_pos": 17, "type": "TASK", "confidence": 0.8575355708599091}]}, {"text": "Our proposed cross-domain word distribution prediction method is unsupervised in the sense that it does not require any labeled data in either of the two steps.", "labels": [], "entities": [{"text": "cross-domain word distribution prediction", "start_pos": 13, "end_pos": 54, "type": "TASK", "confidence": 0.6967796385288239}]}, {"text": "Using two popular multi-domain datasets, we evaluate the proposed method in two prediction tasks: (a) predicting the POS of a word in a target domain, and (b) predicting the sentiment of a review in a target domain.", "labels": [], "entities": [{"text": "POS", "start_pos": 117, "end_pos": 120, "type": "METRIC", "confidence": 0.5301774144172668}, {"text": "predicting the sentiment of a review in a target domain", "start_pos": 159, "end_pos": 214, "type": "TASK", "confidence": 0.8467947363853454}]}, {"text": "Without requiring any task specific customisations, systems based on our distribution prediction method significantly outperform competitive baselines in both tasks.", "labels": [], "entities": []}, {"text": "Because our proposed distribution prediction method is unsupervised and task independent, it is potentially useful fora wide range of DA tasks such entity extraction) or dependency parsing (.", "labels": [], "entities": [{"text": "distribution prediction", "start_pos": 21, "end_pos": 44, "type": "TASK", "confidence": 0.7429414093494415}, {"text": "entity extraction", "start_pos": 148, "end_pos": 165, "type": "TASK", "confidence": 0.7141978740692139}, {"text": "dependency parsing", "start_pos": 170, "end_pos": 188, "type": "TASK", "confidence": 0.8506442308425903}]}, {"text": "Our contributions are summarised as follows: \u2022 Given the distribution w S of a word win a source domain S, we propose a method for learning its distribution w T in a target domain T . \u2022 Using the learnt distribution prediction model, we propose a method to learn a crossdomain POS tagger.", "labels": [], "entities": [{"text": "learnt distribution prediction", "start_pos": 196, "end_pos": 226, "type": "TASK", "confidence": 0.6402724981307983}, {"text": "POS tagger", "start_pos": 277, "end_pos": 287, "type": "TASK", "confidence": 0.6429469585418701}]}, {"text": "\u2022 Using the learnt distribution prediction model, we propose a method to learn a crossdomain sentiment classifier.", "labels": [], "entities": [{"text": "learnt distribution prediction", "start_pos": 12, "end_pos": 42, "type": "TASK", "confidence": 0.5749584833780924}, {"text": "crossdomain sentiment classifier", "start_pos": 81, "end_pos": 113, "type": "TASK", "confidence": 0.6487594048182169}]}, {"text": "To our knowledge, ours is the first successful attempt to learn a model that predicts the distribution of a word across different domains.", "labels": [], "entities": []}], "datasetContent": [{"text": "To evaluate DA for POS tagging, following, we use sections 2 \u2212 21 from Wall Street Journal (WSJ) as the source domain labeled data.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 19, "end_pos": 30, "type": "TASK", "confidence": 0.9323252141475677}, {"text": "Wall Street Journal (WSJ)", "start_pos": 71, "end_pos": 96, "type": "DATASET", "confidence": 0.968837837378184}]}, {"text": "An additional 100, 000 WSJ sentences from the 1988 release of the WSJ corpus are used as the source domain unlabeled data.", "labels": [], "entities": [{"text": "WSJ sentences from the 1988 release of the WSJ corpus", "start_pos": 23, "end_pos": 76, "type": "DATASET", "confidence": 0.8979069411754608}]}, {"text": "Following, we use the POS labeled sentences in the SACNL dataset) for the five target domains: QA forums, Emails, Newsgroups, Reviews, and Blogs.", "labels": [], "entities": [{"text": "SACNL dataset", "start_pos": 51, "end_pos": 64, "type": "DATASET", "confidence": 0.9742964208126068}]}, {"text": "Each target domain contains around 1000 POS labeled test sentences and around 100, 000 unlabeled sentences.", "labels": [], "entities": []}, {"text": "To evaluate DA for sentiment classification, we use the Amazon product reviews collected by for four different product categories: books (B), DVDs (D), electronic items (E), and kitchen appliances (K).", "labels": [], "entities": [{"text": "sentiment classification", "start_pos": 19, "end_pos": 43, "type": "TASK", "confidence": 0.9786193668842316}, {"text": "Amazon product reviews collected", "start_pos": 56, "end_pos": 88, "type": "DATASET", "confidence": 0.8457868844270706}]}, {"text": "There are 1000 positive and 1000 negative sentiment labeled reviews for each domain.", "labels": [], "entities": []}, {"text": "Moreover, each domain has on average 17, 547 unlabeled reviews.", "labels": [], "entities": []}, {"text": "We use the standard split of 800 positive and 800 negative labeled reviews from each domain as training data, and the remainder for testing.", "labels": [], "entities": []}, {"text": "For each domain D in the SANCL (POS tagging) and Amazon review (sentiment classification) datasets, we create a PPMI weighted cooccurrence matrix FD . On average, FD created fora target domain in the SANCL dataset contains 104, 598 rows and 65, 528 columns, whereas those numbers in the Amazon dataset are respectively.", "labels": [], "entities": [{"text": "SANCL (POS tagging) and Amazon review (sentiment classification)", "start_pos": 25, "end_pos": 89, "type": "TASK", "confidence": 0.5586276774605116}, {"text": "PPMI weighted cooccurrence matrix FD", "start_pos": 112, "end_pos": 148, "type": "METRIC", "confidence": 0.6051976144313812}, {"text": "SANCL dataset", "start_pos": 200, "end_pos": 213, "type": "DATASET", "confidence": 0.815369725227356}, {"text": "Amazon dataset", "start_pos": 287, "end_pos": 301, "type": "DATASET", "confidence": 0.9438987374305725}]}, {"text": "In cross-domain sentiment classification, we measure the binary sentiment classification accuracy for the target domain test reviews for each pair of domains (12 pairs in total for 4 domains).", "labels": [], "entities": [{"text": "cross-domain sentiment classification", "start_pos": 3, "end_pos": 40, "type": "TASK", "confidence": 0.8146860599517822}, {"text": "binary sentiment classification", "start_pos": 57, "end_pos": 88, "type": "TASK", "confidence": 0.5698914229869843}, {"text": "accuracy", "start_pos": 89, "end_pos": 97, "type": "METRIC", "confidence": 0.7896943688392639}]}, {"text": "On average, we have 40, 176 pivots fora pair of domains in the Amazon dataset.", "labels": [], "entities": [{"text": "Amazon dataset", "start_pos": 63, "end_pos": 77, "type": "DATASET", "confidence": 0.9527289867401123}]}, {"text": "In cross-domain POS tagging, WSJ is always the source domain, whereas the five domains in SANCL dataset are considered as the target domains.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 16, "end_pos": 27, "type": "TASK", "confidence": 0.844671905040741}, {"text": "WSJ", "start_pos": 29, "end_pos": 32, "type": "DATASET", "confidence": 0.6225464344024658}, {"text": "SANCL dataset", "start_pos": 90, "end_pos": 103, "type": "DATASET", "confidence": 0.8775149285793304}]}, {"text": "For this setting we have 9822 pivots on average.", "labels": [], "entities": []}, {"text": "The number of singular vectors k selected in SVD, and the number of PLSR dimensions L are set respectively to 1000 and 50 for the remainder of the experiments described in the paper.", "labels": [], "entities": []}, {"text": "Later we study the effect of those two parameters on the performance of the proposed method.", "labels": [], "entities": []}, {"text": "The L-BFGS ( method is used to train the CRF and logistic regression models.", "labels": [], "entities": []}, {"text": "shows the token-level POS tagging accuracy for unseen words (i.e. words that appear in the target domain test sentences but not in the source domain labeled train sentences).", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 22, "end_pos": 33, "type": "TASK", "confidence": 0.6852830052375793}, {"text": "accuracy", "start_pos": 34, "end_pos": 42, "type": "METRIC", "confidence": 0.8984469771385193}]}, {"text": "By limiting the evaluation to unseen words instead of all words, we can evaluate the gain in POS tagging accuracy solely due to DA.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 93, "end_pos": 104, "type": "TASK", "confidence": 0.7767570316791534}, {"text": "accuracy", "start_pos": 105, "end_pos": 113, "type": "METRIC", "confidence": 0.9270674586296082}, {"text": "DA", "start_pos": 128, "end_pos": 130, "type": "METRIC", "confidence": 0.665363073348999}]}, {"text": "The NA (no-adapt) baseline simulates the effect of not performing any DA.", "labels": [], "entities": []}, {"text": "Specifically, in POS tagging, a CRF trained on source domain labeled sentences is applied to target domain test sentences, whereas in sentiment classification, a logistic regression classifier trained using source domain labeled reviews is applied to the target domain test reviews.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 17, "end_pos": 28, "type": "TASK", "confidence": 0.8094898164272308}, {"text": "sentiment classification", "start_pos": 134, "end_pos": 158, "type": "TASK", "confidence": 0.9380616247653961}]}, {"text": "The S pred baseline directly uses the source domain distributions for the words instead of projecting them to the target domain.", "labels": [], "entities": [{"text": "S pred baseline", "start_pos": 4, "end_pos": 19, "type": "DATASET", "confidence": 0.6639507611592611}]}, {"text": "This is equivalent to setting the prediction matrix M to the unit matrix.", "labels": [], "entities": []}, {"text": "The T pred baseline uses the target domain distribution w T fora word w instead of Mw S . If w does not appear in the target domain, then w T is set to the zero vector.", "labels": [], "entities": [{"text": "T pred baseline", "start_pos": 4, "end_pos": 19, "type": "DATASET", "confidence": 0.5865322649478912}]}, {"text": "The S pred and T pred baselines simulate the two alternatives of using source and target domain distributions instead of learning a PLSR model.", "labels": [], "entities": []}, {"text": "The DA method proposed in Section 4.1 is shown as the Proposed method.", "labels": [], "entities": [{"text": "Proposed", "start_pos": 54, "end_pos": 62, "type": "DATASET", "confidence": 0.6773640513420105}]}, {"text": "Filter denotes the training set filtering method proposed by for the DA of POS taggers.", "labels": [], "entities": [{"text": "POS taggers", "start_pos": 75, "end_pos": 86, "type": "TASK", "confidence": 0.6089160889387131}]}], "tableCaptions": [{"text": " Table 2: POS tagging accuracies on SANCL.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 10, "end_pos": 21, "type": "TASK", "confidence": 0.7254559099674225}, {"text": "SANCL", "start_pos": 36, "end_pos": 41, "type": "DATASET", "confidence": 0.7960250377655029}]}, {"text": " Table 3: Top 3 distributional features u \u2208 S for  the word lightweight (w).", "labels": [], "entities": []}]}