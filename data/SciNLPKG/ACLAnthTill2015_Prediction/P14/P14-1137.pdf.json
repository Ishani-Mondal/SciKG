{"title": [{"text": "A Sense-Based Translation Model for Statistical Machine Translation", "labels": [], "entities": [{"text": "Sense-Based Translation", "start_pos": 2, "end_pos": 25, "type": "TASK", "confidence": 0.6638230979442596}, {"text": "Statistical Machine Translation", "start_pos": 36, "end_pos": 67, "type": "TASK", "confidence": 0.7961305578549703}]}], "abstractContent": [{"text": "The sense in which a word is used determines the translation of the word.", "labels": [], "entities": []}, {"text": "In this paper, we propose a sense-based translation model to integrate word senses into statistical machine translation.", "labels": [], "entities": [{"text": "sense-based translation", "start_pos": 28, "end_pos": 51, "type": "TASK", "confidence": 0.669083297252655}, {"text": "statistical machine translation", "start_pos": 88, "end_pos": 119, "type": "TASK", "confidence": 0.6275168458620707}]}, {"text": "We build a broad-coverage sense tagger based on a nonparametric Bayesian topic model that automatically learns sense clusters for words in the source language.", "labels": [], "entities": [{"text": "broad-coverage sense tagger", "start_pos": 11, "end_pos": 38, "type": "TASK", "confidence": 0.6023421287536621}]}, {"text": "The proposed sense-based translation model enables the decoder to select appropriate translations for source words according to the inferred senses for these words using maximum entropy classifiers.", "labels": [], "entities": []}, {"text": "Our method is significantly different from previous word sense disambiguation reformu-lated for machine translation in that the latter neglects word senses in nature.", "labels": [], "entities": [{"text": "word sense disambiguation reformu-lated", "start_pos": 52, "end_pos": 91, "type": "TASK", "confidence": 0.6906823441386223}, {"text": "machine translation", "start_pos": 96, "end_pos": 115, "type": "TASK", "confidence": 0.7332360446453094}]}, {"text": "We test the effectiveness of the proposed sense-based translation model on a large-scale Chinese-to-English translation task.", "labels": [], "entities": [{"text": "Chinese-to-English translation task", "start_pos": 89, "end_pos": 124, "type": "TASK", "confidence": 0.7735393345355988}]}, {"text": "Results show that the proposed model substantially outperforms not only the base-line but also the previous reformulated word sense disambiguation.", "labels": [], "entities": [{"text": "word sense disambiguation", "start_pos": 121, "end_pos": 146, "type": "TASK", "confidence": 0.6543212234973907}]}], "introductionContent": [{"text": "One of very common phenomena in language is that aplenty of words have multiple meanings.", "labels": [], "entities": []}, {"text": "In the context of machine translation, such different meanings normally produce different target translations.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 18, "end_pos": 37, "type": "TASK", "confidence": 0.7898449003696442}]}, {"text": "Therefore a natural assumption is that word sense disambiguation (WSD) may contribute to statistical machine translation (SMT) by providing appropriate word senses for target translation selection with context features).", "labels": [], "entities": [{"text": "word sense disambiguation (WSD)", "start_pos": 39, "end_pos": 70, "type": "TASK", "confidence": 0.7500592619180679}, {"text": "statistical machine translation (SMT)", "start_pos": 89, "end_pos": 126, "type": "TASK", "confidence": 0.7805143048365911}]}, {"text": "* Corresponding author This assumption, however, has not been empirically verified in the early days.", "labels": [], "entities": []}, {"text": "Carpuat and adopt a standard formulation of WSD: predicting word senses that are defined on an ontology for ambiguous words.", "labels": [], "entities": [{"text": "Carpuat", "start_pos": 0, "end_pos": 7, "type": "DATASET", "confidence": 0.961468517780304}, {"text": "WSD", "start_pos": 44, "end_pos": 47, "type": "TASK", "confidence": 0.8851501941680908}, {"text": "predicting word senses", "start_pos": 49, "end_pos": 71, "type": "TASK", "confidence": 0.888556718826294}]}, {"text": "As they apply WSD to Chinese-to-English translation, they predict word senses from a Chinese ontology HowNet and project the predicted senses to English glosses provided by HowNet.", "labels": [], "entities": [{"text": "WSD", "start_pos": 14, "end_pos": 17, "type": "TASK", "confidence": 0.9129069447517395}, {"text": "HowNet", "start_pos": 102, "end_pos": 108, "type": "DATASET", "confidence": 0.9416284561157227}, {"text": "HowNet", "start_pos": 173, "end_pos": 179, "type": "DATASET", "confidence": 0.9871782064437866}]}, {"text": "These glosses, used as the sense predictions of their WSD system, are integrated into a word-based SMT system either to substitute for translation candidates of their translation model or to postedit the output of their SMT system.", "labels": [], "entities": [{"text": "SMT", "start_pos": 99, "end_pos": 102, "type": "TASK", "confidence": 0.8740289211273193}]}, {"text": "They report that WSD degenerates the translation quality of SMT.", "labels": [], "entities": [{"text": "WSD", "start_pos": 17, "end_pos": 20, "type": "TASK", "confidence": 0.9143995046615601}, {"text": "translation", "start_pos": 37, "end_pos": 48, "type": "TASK", "confidence": 0.9592138528823853}, {"text": "SMT", "start_pos": 60, "end_pos": 63, "type": "TASK", "confidence": 0.977971613407135}]}, {"text": "In contrast to the standard WSD formulation, reformulate the task of WSD for SMT as predicting possible target translations rather than senses for ambiguous source words.", "labels": [], "entities": [{"text": "WSD", "start_pos": 28, "end_pos": 31, "type": "TASK", "confidence": 0.8966521620750427}, {"text": "SMT", "start_pos": 77, "end_pos": 80, "type": "TASK", "confidence": 0.9933546781539917}, {"text": "predicting possible target translations", "start_pos": 84, "end_pos": 123, "type": "TASK", "confidence": 0.8523392826318741}]}, {"text": "They show that such a reformulated WSD can improve the accuracy of a simplified word translation task.", "labels": [], "entities": [{"text": "WSD", "start_pos": 35, "end_pos": 38, "type": "TASK", "confidence": 0.8888922929763794}, {"text": "accuracy", "start_pos": 55, "end_pos": 63, "type": "METRIC", "confidence": 0.9984616041183472}, {"text": "word translation task", "start_pos": 80, "end_pos": 101, "type": "TASK", "confidence": 0.7742882172266642}]}, {"text": "Following this WSD reformulation for SMT, integrate a state-of-the-art WSD system into a hierarchical phrase-based system.", "labels": [], "entities": [{"text": "WSD reformulation", "start_pos": 15, "end_pos": 32, "type": "TASK", "confidence": 0.8590660989284515}, {"text": "SMT", "start_pos": 37, "end_pos": 40, "type": "TASK", "confidence": 0.9883082509040833}]}, {"text": "also use this reformulated WSD and further adapt it to multi-word phrasal disambiguation.", "labels": [], "entities": [{"text": "WSD", "start_pos": 27, "end_pos": 30, "type": "TASK", "confidence": 0.6052427887916565}, {"text": "multi-word phrasal disambiguation", "start_pos": 55, "end_pos": 88, "type": "TASK", "confidence": 0.6648549834887186}]}, {"text": "They both report that the redefined WSD can significantly improve SMT.", "labels": [], "entities": [{"text": "WSD", "start_pos": 36, "end_pos": 39, "type": "TASK", "confidence": 0.682706356048584}, {"text": "SMT", "start_pos": 66, "end_pos": 69, "type": "TASK", "confidence": 0.9939407110214233}]}, {"text": "Although this reformulated WSD has proved helpful for SMT, one question is not answered yet: are pure word senses useful for SMT?", "labels": [], "entities": [{"text": "WSD", "start_pos": 27, "end_pos": 30, "type": "TASK", "confidence": 0.8272705078125}, {"text": "SMT", "start_pos": 54, "end_pos": 57, "type": "TASK", "confidence": 0.9966287016868591}, {"text": "SMT", "start_pos": 125, "end_pos": 128, "type": "TASK", "confidence": 0.9955081939697266}]}, {"text": "The early WSD for SMT) uses projected word senses while the reformulated WSD sidesteps word senses.", "labels": [], "entities": [{"text": "SMT)", "start_pos": 18, "end_pos": 22, "type": "TASK", "confidence": 0.9449525773525238}]}, {"text": "In this paper we would like to re-investigate this question by resorting to word sense induction (WSI) that is related to but different from WSD.", "labels": [], "entities": [{"text": "word sense induction (WSI)", "start_pos": 76, "end_pos": 102, "type": "METRIC", "confidence": 0.6425671776135763}]}, {"text": "We use WSI to obtain word senses for large-scale data.", "labels": [], "entities": []}, {"text": "With these word senses, we study in particular: 1) whether word senses can be directly integrated to SMT to improve translation quality and 2) whether WSI-based model can outperform the reformulated WSD in the context of SMT.", "labels": [], "entities": [{"text": "SMT", "start_pos": 101, "end_pos": 104, "type": "TASK", "confidence": 0.9815249443054199}, {"text": "SMT", "start_pos": 221, "end_pos": 224, "type": "TASK", "confidence": 0.983985960483551}]}, {"text": "In order to incorporate word senses into SMT, we propose a sense-based translation model that is built on maximum entropy classifiers.", "labels": [], "entities": [{"text": "SMT", "start_pos": 41, "end_pos": 44, "type": "TASK", "confidence": 0.9904338121414185}]}, {"text": "We use a nonparametric Bayesian topic model based WSI to infer word senses for source words in our training, development and test set.", "labels": [], "entities": []}, {"text": "We collect training instances from the sense-tagged training data to train the proposed sense-based translation model.", "labels": [], "entities": [{"text": "sense-based translation", "start_pos": 88, "end_pos": 111, "type": "TASK", "confidence": 0.6232751905918121}]}, {"text": "Specially, \u2022 Instead of predicting target translations for ambiguous source words as the previous reformulated WSD does, we first predict word senses for ambiguous source words.", "labels": [], "entities": [{"text": "predicting target translations", "start_pos": 24, "end_pos": 54, "type": "TASK", "confidence": 0.9039501547813416}]}, {"text": "The predicted word senses together with other context features are then used to predict possible target translations for these words.", "labels": [], "entities": []}, {"text": "\u2022 Instead of using word senses defined by a prespecified sense inventory as the standard WSD does, we incorporate word senses that are automatically learned from data into our sense-based translation model.", "labels": [], "entities": []}, {"text": "We integrate the proposed sense-based translation model into a state-of-the-art SMT system and conduct experiments on Chines-to-English translation using large-scale training data.", "labels": [], "entities": [{"text": "SMT", "start_pos": 80, "end_pos": 83, "type": "TASK", "confidence": 0.9907971620559692}, {"text": "Chines-to-English translation", "start_pos": 118, "end_pos": 147, "type": "TASK", "confidence": 0.8381522297859192}]}, {"text": "Results show that automatically learned word senses are able to improve translation quality and the sensebased translation model is better than the previous reformulated WSD.", "labels": [], "entities": [{"text": "sensebased translation", "start_pos": 100, "end_pos": 122, "type": "TASK", "confidence": 0.5861410796642303}]}, {"text": "The remainder of this paper proceeds as follows.", "labels": [], "entities": []}, {"text": "Section 2 introduces how we obtain word senses for our large-scale training data via a WSIbased broad-coverage sense tagger.", "labels": [], "entities": [{"text": "WSIbased broad-coverage sense tagger", "start_pos": 87, "end_pos": 123, "type": "TASK", "confidence": 0.6945003271102905}]}, {"text": "Section 3 presents our sense-based translation model.", "labels": [], "entities": [{"text": "sense-based translation", "start_pos": 23, "end_pos": 46, "type": "TASK", "confidence": 0.5198048949241638}]}, {"text": "Section 4 describes how we integrate the sense-based translation model into SMT.", "labels": [], "entities": [{"text": "sense-based translation", "start_pos": 41, "end_pos": 64, "type": "TASK", "confidence": 0.5877428352832794}, {"text": "SMT", "start_pos": 76, "end_pos": 79, "type": "TASK", "confidence": 0.9877372980117798}]}, {"text": "Section 5 elaborates our experiments on the large-scale Chinese-toEnglish translation task.", "labels": [], "entities": [{"text": "large-scale Chinese-toEnglish translation task", "start_pos": 44, "end_pos": 90, "type": "TASK", "confidence": 0.6463005915284157}]}, {"text": "Section 6 introduces related studies and highlights significant differences from them.", "labels": [], "entities": []}, {"text": "Finally, we conclude in Section 7 with future directions.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section, we carried out a series of experiments on Chinese-to-English translation using large-scale bilingual training data.", "labels": [], "entities": [{"text": "Chinese-to-English translation", "start_pos": 59, "end_pos": 89, "type": "TASK", "confidence": 0.6473130583763123}]}, {"text": "In order to build the proposed sense-based translation model, we annotated the source part of the bilingual training data with word senses induced by the HDPbased WSI.", "labels": [], "entities": [{"text": "sense-based translation", "start_pos": 31, "end_pos": 54, "type": "TASK", "confidence": 0.6405244618654251}, {"text": "HDPbased WSI", "start_pos": 154, "end_pos": 166, "type": "DATASET", "confidence": 0.8815116882324219}]}, {"text": "With the trained sense-based translation model, we would like to investigate the following two questions: \u2022 Do word senses automatically induced by the HDP-based WSI improve translation quality?", "labels": [], "entities": []}, {"text": "\u2022 Does the sense-based translation model outperform the reformulated WSD for SMT?", "labels": [], "entities": [{"text": "SMT", "start_pos": 77, "end_pos": 80, "type": "TASK", "confidence": 0.9891608357429504}]}], "tableCaptions": [{"text": " Table 2: Statistics of the HDP-based word sense  induction on the training and test data.", "labels": [], "entities": [{"text": "HDP-based word sense  induction", "start_pos": 28, "end_pos": 59, "type": "TASK", "confidence": 0.6994453445076942}]}, {"text": " Table 5: Experiment results of the sense-based  translation model (STM) against the baseline.", "labels": [], "entities": [{"text": "sense-based  translation", "start_pos": 36, "end_pos": 60, "type": "TASK", "confidence": 0.6168891042470932}]}, {"text": " Table 6: Comparison results of the sense-based  translation model vs. the reformulated WSD for  SMT.", "labels": [], "entities": [{"text": "SMT", "start_pos": 97, "end_pos": 100, "type": "TASK", "confidence": 0.9851542115211487}]}]}