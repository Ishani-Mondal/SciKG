{"title": [], "abstractContent": [{"text": "We present a generalized discrimina-tive model for spelling error correction which targets character-level transformations.", "labels": [], "entities": [{"text": "spelling error correction", "start_pos": 51, "end_pos": 76, "type": "TASK", "confidence": 0.8886529207229614}]}, {"text": "While operating at the character level, the model makes use of word-level and contextual information.", "labels": [], "entities": []}, {"text": "In contrast to previous work, the proposed approach learns to correct a variety of error types without guidance of manually-selected constraints or language-specific features.", "labels": [], "entities": []}, {"text": "We apply the model to correct errors in Egyptian Arabic dialect text, achieving 65% reduction in word error rate over the input baseline, and improving over the earlier state-of-the-art system.", "labels": [], "entities": [{"text": "word error rate", "start_pos": 97, "end_pos": 112, "type": "METRIC", "confidence": 0.7753313183784485}]}], "introductionContent": [{"text": "Spelling error correction is a longstanding Natural Language Processing (NLP) problem, and it has recently become especially relevant because of the many potential applications to the large amount of informal and unedited text generated online, including web forums, tweets, blogs, and email.", "labels": [], "entities": [{"text": "Spelling error correction", "start_pos": 0, "end_pos": 25, "type": "TASK", "confidence": 0.8950509230295817}]}, {"text": "Misspellings in such text can lead to increased sparsity and errors, posing a challenge for many NLP applications such as text summarization, sentiment analysis and machine translation.", "labels": [], "entities": [{"text": "text summarization", "start_pos": 122, "end_pos": 140, "type": "TASK", "confidence": 0.7427442073822021}, {"text": "sentiment analysis", "start_pos": 142, "end_pos": 160, "type": "TASK", "confidence": 0.965876430273056}, {"text": "machine translation", "start_pos": 165, "end_pos": 184, "type": "TASK", "confidence": 0.820782870054245}]}, {"text": "In this work, we present GSEC, a Generalized character-level Spelling Error Correction model, which uses supervised learning to map input characters into output characters in context.", "labels": [], "entities": [{"text": "GSEC", "start_pos": 25, "end_pos": 29, "type": "METRIC", "confidence": 0.5985931158065796}]}, {"text": "The approach has the following characteristics: Character-level Corrections are learned at the character-level 1 using a supervised sequence labeling approach.", "labels": [], "entities": []}, {"text": "Generalized The input space consists of all characters, and a single classifier is used to learn common error patterns overall the training data, without guidance of specific rules.", "labels": [], "entities": []}, {"text": "Context-sensitive The model looks beyond the context of the current word, when making a decision at the character-level.", "labels": [], "entities": []}, {"text": "Discriminative The model provides the freedom of adding a number of different features, which mayor may not be language-specific.", "labels": [], "entities": []}, {"text": "Language-Independent In this work, we integrate only language-independent features, and therefore do not consider morphological or linguistic features.", "labels": [], "entities": []}, {"text": "However, we apply the model to correct errors in Egyptian Arabic dialect text, following a conventional orthography standard, CODA.", "labels": [], "entities": []}, {"text": "Using the described approach, we demonstrate a word-error-rate (WER) reduction of 65% over a do-nothing input baseline, and we improve over a state-of-the-art system which relies heavily on language-specific and manually-selected constraints.", "labels": [], "entities": [{"text": "word-error-rate (WER) reduction", "start_pos": 47, "end_pos": 78, "type": "METRIC", "confidence": 0.8204462051391601}]}, {"text": "We present a detailed analysis of mistakes and demonstrate that the proposed model indeed learns to correct a wider variety of errors.", "labels": [], "entities": []}], "datasetContent": [{"text": "Setup The training data was extracted to generate the form described in Section 3.1, using the Sclite tool to align the input and reference sentences.", "labels": [], "entities": []}, {"text": "A speech effect handling step was applied as a preprocessing step to all models.", "labels": [], "entities": [{"text": "speech effect handling", "start_pos": 2, "end_pos": 24, "type": "TASK", "confidence": 0.7012943029403687}]}, {"text": "This step removes redundant repetitions of characters in sequence, e.g., ktyyyyyr 'veeeeery'.", "labels": [], "entities": []}, {"text": "The same speech effect handling was applied by.", "labels": [], "entities": []}, {"text": "For classification, we used the SVM implementation in YamCha (, and trained with different variations of the features described above.", "labels": [], "entities": [{"text": "classification", "start_pos": 4, "end_pos": 18, "type": "TASK", "confidence": 0.9717165231704712}, {"text": "YamCha", "start_pos": 54, "end_pos": 60, "type": "DATASET", "confidence": 0.9369605779647827}]}, {"text": "Default parameters were selected for training (c=1, quadratic kernel, and context window of +/-2).", "labels": [], "entities": []}, {"text": "In all results listed below, the baseline corresponds to the do-nothing baseline of the input text.", "labels": [], "entities": []}, {"text": "Metrics Three evaluation metrics are used.", "labels": [], "entities": []}, {"text": "The word-error-rate WER metric is computed by summing the total number of word-level substitution errors, insertion errors, and deletion errors in the output, and dividing by the number of words in the reference.", "labels": [], "entities": [{"text": "WER", "start_pos": 20, "end_pos": 23, "type": "METRIC", "confidence": 0.7155153751373291}]}, {"text": "The correct-rate Corr metric is computed by dividing the number of correct output words by the total number of words in the reference.", "labels": [], "entities": [{"text": "correct-rate Corr metric", "start_pos": 4, "end_pos": 28, "type": "METRIC", "confidence": 0.814753790696462}]}, {"text": "These two metrics are produced by Sclite, using automatic alignment.", "labels": [], "entities": []}, {"text": "Finally, the accuracy Acc metric, used by, is a simple string matching metric which enforces a word alignment that pairs words in the reference to those of the output.", "labels": [], "entities": [{"text": "accuracy Acc metric", "start_pos": 13, "end_pos": 32, "type": "METRIC", "confidence": 0.8475382328033447}]}, {"text": "It is calculated by dividing the number of correct output words by the number of words in the input.", "labels": [], "entities": []}, {"text": "This metric assumes no split errors in the data (a word incorrectly split into two words), which is the casein the data we are working with.", "labels": [], "entities": []}, {"text": "Character-level Model Evaluation The performance of the generalized spelling correction model (GSEC) on the dev data is presented in the first half of.", "labels": [], "entities": [{"text": "Character-level Model Evaluation", "start_pos": 0, "end_pos": 32, "type": "TASK", "confidence": 0.5928759872913361}, {"text": "spelling correction", "start_pos": 68, "end_pos": 87, "type": "TASK", "confidence": 0.61732417345047}]}, {"text": "The results of the Eskander et al.", "labels": [], "entities": []}, {"text": "(2013) CEC system are also presented for the purpose of comparison.", "labels": [], "entities": []}, {"text": "We can see that using a single classifier, the generalized model is able to outperform CEC, which relies on a cascade of classifiers (p = 0.03 for the basic model and p < 0.0001 for the best model, GSEC+4grams).", "labels": [], "entities": []}, {"text": "Model Combination Evaluation Here we present results on combining GSEC with the MLE component (GSEC+MLE).", "labels": [], "entities": []}, {"text": "We combine the two models in cascade: the MLE component is applied to the output of GSEC.", "labels": [], "entities": [{"text": "MLE", "start_pos": 42, "end_pos": 45, "type": "METRIC", "confidence": 0.8416270017623901}, {"text": "GSEC", "start_pos": 84, "end_pos": 88, "type": "DATASET", "confidence": 0.8737216591835022}]}, {"text": "To train the MLE model, we use the word pairs obtained from the original training data, rather than from the output of GSEC.", "labels": [], "entities": [{"text": "MLE", "start_pos": 13, "end_pos": 16, "type": "TASK", "confidence": 0.9400067329406738}, {"text": "GSEC", "start_pos": 119, "end_pos": 123, "type": "DATASET", "confidence": 0.929115355014801}]}, {"text": "We found that this configuration allows Significance results are obtained using McNemar's test.", "labels": [], "entities": [{"text": "McNemar's test", "start_pos": 80, "end_pos": 94, "type": "DATASET", "confidence": 0.8741434017817179}]}], "tableCaptions": [{"text": " Table 3: Character-level distribution of correction labels. We model all types of transformations except complex actions, and", "labels": [], "entities": []}, {"text": " Table 4: Model Evaluation. GSEC represents the gener-", "labels": [], "entities": []}, {"text": " Table 5: Evaluation on test data.", "labels": [], "entities": []}, {"text": " Table 6: Accuracy of character-level models shown sepa-", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.997848629951477}]}, {"text": " Table 7: Character-level accuracy on different transforma-", "labels": [], "entities": [{"text": "accuracy", "start_pos": 26, "end_pos": 34, "type": "METRIC", "confidence": 0.9924615025520325}]}]}