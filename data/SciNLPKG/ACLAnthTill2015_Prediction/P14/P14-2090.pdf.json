{"title": [{"text": "Optimizing Segmentation Strategies for Simultaneous Speech Translation", "labels": [], "entities": [{"text": "Optimizing Segmentation Strategies", "start_pos": 0, "end_pos": 34, "type": "TASK", "confidence": 0.7726621230443319}, {"text": "Simultaneous Speech Translation", "start_pos": 39, "end_pos": 70, "type": "TASK", "confidence": 0.9027893543243408}]}], "abstractContent": [{"text": "In this paper, we propose new algorithms for learning segmentation strategies for simultaneous speech translation.", "labels": [], "entities": [{"text": "simultaneous speech translation", "start_pos": 82, "end_pos": 113, "type": "TASK", "confidence": 0.654548833767573}]}, {"text": "In contrast to previously proposed heuristic methods, our method finds a segmentation that directly maximizes the performance of the machine translation system.", "labels": [], "entities": []}, {"text": "We describe two methods based on greedy search and dynamic programming that search for the optimal segmentation strategy.", "labels": [], "entities": []}, {"text": "An experimental evaluation finds that our algorithm is able to segment the input two to three times more frequently than conventional methods in terms of number of words, while maintaining the same score of automatic evaluation.", "labels": [], "entities": []}], "introductionContent": [{"text": "The performance of speech translation systems has greatly improved in the past several years, and these systems are starting to find wide use in a number of applications.", "labels": [], "entities": [{"text": "speech translation", "start_pos": 19, "end_pos": 37, "type": "TASK", "confidence": 0.7947697937488556}]}, {"text": "Simultaneous speech translation, which translates speech from the source language into the target language in real time, is one example of such an application.", "labels": [], "entities": [{"text": "Simultaneous speech translation", "start_pos": 0, "end_pos": 31, "type": "TASK", "confidence": 0.6243719955285391}]}, {"text": "When translating dialogue, the length of each utterance will usually be short, so the system can simply start the translation process when it detects the end of an utterance.", "labels": [], "entities": [{"text": "translating dialogue", "start_pos": 5, "end_pos": 25, "type": "TASK", "confidence": 0.9016485512256622}]}, {"text": "However, in the case of lectures, for example, there is often no obvious boundary between utterances.", "labels": [], "entities": []}, {"text": "Thus, translation systems require a method of deciding the timing at which to start the translation process.", "labels": [], "entities": [{"text": "translation", "start_pos": 6, "end_pos": 17, "type": "TASK", "confidence": 0.9799470901489258}]}, {"text": "Using estimated ends of sentences as the timing with which to start translation, in the same way as a normal text translation, is a straightforward solution to this problem ().", "labels": [], "entities": []}, {"text": "However, this approach The implementation is available at http://odaemon.com/docs/codes/greedyseg.html.", "labels": [], "entities": []}, {"text": "impairs the simultaneity of translation because the system needs to wait too long until the appearance of a estimated sentence boundary.", "labels": [], "entities": []}, {"text": "For this reason, segmentation strategies, which separate the input at appropriate positions other than end of the sentence, have been studied.", "labels": [], "entities": []}, {"text": "A number of segmentation strategies for simultaneous speech translation have been proposed in recent years. and propose using prosodic pauses in speech recognition to denote segmentation boundaries, but this method strongly depends on characteristics of the speech, such as the speed of speaking.", "labels": [], "entities": [{"text": "simultaneous speech translation", "start_pos": 40, "end_pos": 71, "type": "TASK", "confidence": 0.6681117415428162}, {"text": "speech recognition", "start_pos": 145, "end_pos": 163, "type": "TASK", "confidence": 0.7642414271831512}]}, {"text": "There is also research on methods that depend on linguistic or non-linguistic heuristics over recognized text , and it was found that a method that predicts the location of commas or periods achieves the highest performance.", "labels": [], "entities": []}, {"text": "Methods have also been proposed using the phrase table ( or the right probability (RP) of phrases (, which indicates whether a phrase reordering occurs or not.", "labels": [], "entities": [{"text": "right probability (RP)", "start_pos": 64, "end_pos": 86, "type": "METRIC", "confidence": 0.87411869764328}]}, {"text": "However, each of the previously mentioned methods decides the segmentation on the basis of heuristics, so the impact of each segmentation strategy on translation performance is not directly considered.", "labels": [], "entities": []}, {"text": "In addition, the mean number of words in the translation unit, which strongly affects the delay of translation, cannot be directly controlled by these methods.", "labels": [], "entities": []}, {"text": "In this paper, we propose new segmentation algorithms that directly optimize translation performance given the mean number of words in the translation unit.", "labels": [], "entities": []}, {"text": "Our approaches find appropriate segmentation boundaries incrementally using greedy search and dynamic programming.", "labels": [], "entities": []}, {"text": "Each boundary is selected to explicitly maximize trans-lation accuracy as measured by BLEU or another evaluation measure.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 62, "end_pos": 70, "type": "METRIC", "confidence": 0.9852560758590698}, {"text": "BLEU", "start_pos": 86, "end_pos": 90, "type": "METRIC", "confidence": 0.9948315024375916}]}, {"text": "We evaluate our methods on a speech translation task, and we confirm that our approaches can achieve translation units two to three times as finegrained as other methods, while maintaining the same accuracy.", "labels": [], "entities": [{"text": "speech translation task", "start_pos": 29, "end_pos": 52, "type": "TASK", "confidence": 0.8140125870704651}, {"text": "accuracy", "start_pos": 198, "end_pos": 206, "type": "METRIC", "confidence": 0.9974287152290344}]}], "datasetContent": [{"text": "We evaluated the performance of our segmentation strategies by applying them to English-German and English-Japanese TED speech translation data from WIT3 ().", "labels": [], "entities": [{"text": "TED speech translation", "start_pos": 116, "end_pos": 138, "type": "TASK", "confidence": 0.5631359616915385}, {"text": "WIT3", "start_pos": 149, "end_pos": 153, "type": "DATASET", "confidence": 0.6190614700317383}]}, {"text": "For EnglishGerman, we used the TED data and splits from the IWSLT2013 evaluation campaign (, as well as 1M sentences selected from the out-of-domain training data using the method of.", "labels": [], "entities": [{"text": "TED data", "start_pos": 31, "end_pos": 39, "type": "DATASET", "confidence": 0.7247150540351868}, {"text": "IWSLT2013 evaluation campaign", "start_pos": 60, "end_pos": 89, "type": "DATASET", "confidence": 0.9380865891774496}]}, {"text": "For English-Japanese, we used TED data and the dictionary entries and sentences from EIJIRO.", "labels": [], "entities": [{"text": "TED data", "start_pos": 30, "end_pos": 38, "type": "DATASET", "confidence": 0.8099973499774933}, {"text": "EIJIRO", "start_pos": 85, "end_pos": 91, "type": "DATASET", "confidence": 0.9524148106575012}]}, {"text": "4 shows summaries of the datasets we used.", "labels": [], "entities": []}, {"text": "We use the Stanford POS Tagger () to tokenize and POS tag English and German sentences, and) to tokenize Japanese sentences.", "labels": [], "entities": [{"text": "Stanford POS Tagger", "start_pos": 11, "end_pos": 30, "type": "DATASET", "confidence": 0.7048795024553934}, {"text": "tokenize Japanese sentences", "start_pos": 96, "end_pos": 123, "type": "TASK", "confidence": 0.8699043989181519}]}, {"text": "A phrasebased machine translation (PBMT) system learned by Moses () is used as the translation system MT . We use BLEU+1 as the evaluation measure EV in the proposed method.", "labels": [], "entities": [{"text": "phrasebased machine translation (PBMT)", "start_pos": 2, "end_pos": 40, "type": "TASK", "confidence": 0.7326264828443527}, {"text": "MT", "start_pos": 102, "end_pos": 104, "type": "TASK", "confidence": 0.8152408003807068}, {"text": "BLEU+1", "start_pos": 114, "end_pos": 120, "type": "METRIC", "confidence": 0.9654843409856161}, {"text": "EV", "start_pos": 147, "end_pos": 149, "type": "METRIC", "confidence": 0.5150593519210815}]}, {"text": "The results on the test data are evaluated by BLEU and RIBES (, which is an evaluation measure more sensitive to global reordering than BLEU.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 46, "end_pos": 50, "type": "METRIC", "confidence": 0.9954386353492737}, {"text": "RIBES", "start_pos": 55, "end_pos": 60, "type": "METRIC", "confidence": 0.9833138585090637}, {"text": "BLEU", "start_pos": 136, "end_pos": 140, "type": "METRIC", "confidence": 0.9323192834854126}]}, {"text": "We evaluated our algorithm and two conventional methods listed below: Greedy is our first method that uses simple greedy search and a linear SVM (using surrounding word/POS 1, 2 and 3-grams as features) to learn the segmentation model.", "labels": [], "entities": []}, {"text": "Greedy+DP is the algorithm that introduces grouping the positions in the source sentence by POS bigrams.", "labels": [], "entities": [{"text": "grouping the positions in the source sentence", "start_pos": 43, "end_pos": 88, "type": "TASK", "confidence": 0.7774824925831386}]}, {"text": "Punct-Predict is the method using predicted positions of punctuation . RP is the method using right probability).", "labels": [], "entities": []}], "tableCaptions": []}