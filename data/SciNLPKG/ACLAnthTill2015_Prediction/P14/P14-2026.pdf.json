{"title": [{"text": "Dependency-based Pre-ordering for Chinese-English Machine Translation", "labels": [], "entities": [{"text": "Chinese-English Machine Translation", "start_pos": 34, "end_pos": 69, "type": "TASK", "confidence": 0.6145546933015188}]}], "abstractContent": [{"text": "In statistical machine translation (SMT), syntax-based pre-ordering of the source language is an effective method for dealing with language pairs where there are great differences in their respective word orders.", "labels": [], "entities": [{"text": "statistical machine translation (SMT)", "start_pos": 3, "end_pos": 40, "type": "TASK", "confidence": 0.8094782282908758}]}, {"text": "This paper introduces a novel pre-ordering approach based on dependency parsing for Chinese-English SMT.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 61, "end_pos": 79, "type": "TASK", "confidence": 0.7362366616725922}, {"text": "SMT", "start_pos": 100, "end_pos": 103, "type": "TASK", "confidence": 0.8059346079826355}]}, {"text": "We present a set of dependency-based pre-ordering rules which improved the BLEU score by 1.61 on the NIST 2006 evaluation data.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 75, "end_pos": 79, "type": "METRIC", "confidence": 0.9991390705108643}, {"text": "NIST 2006 evaluation data", "start_pos": 101, "end_pos": 126, "type": "DATASET", "confidence": 0.9742382615804672}]}, {"text": "We also investigate the accuracy of the rule set by conducting human evaluations .", "labels": [], "entities": [{"text": "accuracy", "start_pos": 24, "end_pos": 32, "type": "METRIC", "confidence": 0.9987247586250305}]}], "introductionContent": [{"text": "SMT systems have difficulties translating between distant language pairs such as Chinese and English.", "labels": [], "entities": [{"text": "SMT", "start_pos": 0, "end_pos": 3, "type": "TASK", "confidence": 0.9855594635009766}]}, {"text": "The reason for this is that there are great differences in their word orders.", "labels": [], "entities": []}, {"text": "Reordering therefore becomes a key issue in SMT systems between distant language pairs.", "labels": [], "entities": [{"text": "SMT", "start_pos": 44, "end_pos": 47, "type": "TASK", "confidence": 0.9965863227844238}]}, {"text": "Previous work has shown that the approaches tackling the problem by introducing a pre-ordering procedure into phrase-based SMT (PBSMT) were effective.", "labels": [], "entities": [{"text": "phrase-based SMT (PBSMT)", "start_pos": 110, "end_pos": 134, "type": "TASK", "confidence": 0.6827524542808533}]}, {"text": "These pre-ordering approaches first parse the source language sentences to create parse trees.", "labels": [], "entities": []}, {"text": "Then, syntactic reordering rules are applied to these parse trees with the goal of reordering the source language sentences into the word order of the target language.", "labels": [], "entities": []}, {"text": "Syntax-based pre-ordering by employing constituent parsing have demonstrated effectiveness in many language pairs, such as English-French (), German-English (), Chinese-English (, and English-Japanese (.", "labels": [], "entities": [{"text": "constituent parsing", "start_pos": 39, "end_pos": 58, "type": "TASK", "confidence": 0.743927538394928}]}, {"text": "As a kind of constituent structure, HPSG parsing-based pre-ordering showed improvements in SVO-SOV translations, such as English-Japanese () and Chinese-Japanese (.", "labels": [], "entities": [{"text": "HPSG parsing-based pre-ordering", "start_pos": 36, "end_pos": 67, "type": "TASK", "confidence": 0.7288689613342285}]}, {"text": "Since dependency parsing is more concise than constituent parsing in describing sentences, some research has used dependency parsing in pre-ordering approaches for language pairs such as, and English-SOV languages ().", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 6, "end_pos": 24, "type": "TASK", "confidence": 0.7967861890792847}, {"text": "constituent parsing", "start_pos": 46, "end_pos": 65, "type": "TASK", "confidence": 0.7789600789546967}, {"text": "dependency parsing", "start_pos": 114, "end_pos": 132, "type": "TASK", "confidence": 0.7927630841732025}]}, {"text": "The pre-ordering rules can be made manually () or extracted automatically from a parallel corpus ().", "labels": [], "entities": []}, {"text": "The purpose of this paper is to introduce a novel dependency-based pre-ordering approach through creating a pre-ordering rule set and applying it to the Chinese-English PBSMT system.", "labels": [], "entities": []}, {"text": "Experiment results showed that our pre-ordering rule set improved the BLEU score on the NIST 2006 evaluation data by 1.61.", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 70, "end_pos": 80, "type": "METRIC", "confidence": 0.9818446338176727}, {"text": "NIST 2006 evaluation data", "start_pos": 88, "end_pos": 113, "type": "DATASET", "confidence": 0.960725337266922}]}, {"text": "Moreover, this rule set substantially decreased the total times of rule application about 60%, compared with a constituent-based approach ().", "labels": [], "entities": []}, {"text": "We also conducted human evaluations in order to assess its accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 59, "end_pos": 67, "type": "METRIC", "confidence": 0.9975845813751221}]}, {"text": "To our knowledge, our manually created pre-ordering rule set is the first Chinese-English dependencybased pre-ordering rule set.", "labels": [], "entities": []}, {"text": "The most similar work to this paper is that of.", "labels": [], "entities": []}, {"text": "They created a set of preordering rules for constituent parsers for ChineseEnglish PBSMT.", "labels": [], "entities": [{"text": "ChineseEnglish PBSMT", "start_pos": 68, "end_pos": 88, "type": "DATASET", "confidence": 0.9545168280601501}]}, {"text": "In contrast, we propose a set of pre-ordering rules for dependency parsers.", "labels": [], "entities": []}, {"text": "We argue that even though the rules by exist, it is almost impossible to automatically convert their rules into rules that are applicable to dependency parsers.", "labels": [], "entities": []}, {"text": "In fact, we abandoned our initial attempts to automatically convert their rules into rules for dependency parsers, and This is especially important on the point of the system combination of PBSMT systems, because the diversity of outputs from machine translation systems is important for system combination.", "labels": [], "entities": [{"text": "system combination", "start_pos": 288, "end_pos": 306, "type": "TASK", "confidence": 0.73487389087677}]}, {"text": "By using both our rules and Wang et al.'s rules, one can obtain diverse machine translation results because the pre-ordering results of these two rule sets are generally different.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 72, "end_pos": 91, "type": "TASK", "confidence": 0.6989954560995102}]}, {"text": "Another similar work is that of ().", "labels": [], "entities": []}, {"text": "They created a pre-ordering rule set for dependency parsers from English to several SOV languages.", "labels": [], "entities": []}, {"text": "In contrast, our rule set is for ChineseEnglish PBSMT.", "labels": [], "entities": [{"text": "ChineseEnglish PBSMT", "start_pos": 33, "end_pos": 53, "type": "DATASET", "confidence": 0.9380780458450317}]}, {"text": "That is, the direction of translation is opposite.", "labels": [], "entities": [{"text": "translation", "start_pos": 26, "end_pos": 37, "type": "TASK", "confidence": 0.947309136390686}]}, {"text": "Because there area lot of language specific decisions that reflect specific aspects of the source language and the language pair combination, our rule set provides a valuable resource for pre-ordering in Chinese-English PB-SMT.", "labels": [], "entities": []}, {"text": "2 Dependency-based Pre-ordering Rule Set shows a constituent parse tree and its Stanford typed dependency parse tree for the same: An example of a preposition phrase with a plmod structure.", "labels": [], "entities": []}, {"text": "The phrase translates into \"in front of the US embassy\".", "labels": [], "entities": []}, {"text": "As shown in the figure, the number of nodes in the dependency parse tree (i.e. 9) is much fewer than that in its corresponding constituent parse tree (i.e. 17).", "labels": [], "entities": []}, {"text": "Because dependency parse trees are generally more concise than the constituent ones, they can conduct longdistance reorderings in a finer way.", "labels": [], "entities": [{"text": "dependency parse", "start_pos": 8, "end_pos": 24, "type": "TASK", "confidence": 0.772917628288269}]}, {"text": "Thus, we attempted to conduct pre-ordering based on dependency parsing.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 52, "end_pos": 70, "type": "TASK", "confidence": 0.7020137310028076}]}, {"text": "There are two widely-used dependency systems -Stanford typed dependencies and CoNLL typed dependencies.", "labels": [], "entities": []}, {"text": "For Chinese, there are 45 types of grammatical relations for Stanford typed dependencies ( and 25 for CoNLL typed dependencies.", "labels": [], "entities": [{"text": "CoNLL typed dependencies", "start_pos": 102, "end_pos": 126, "type": "DATASET", "confidence": 0.7928419907887777}]}, {"text": "As we thought that Stanford typed dependencies could describe language phenomena more meticulously owing to more types of grammatical relations, we preferred to use it for searching candidate preordering rules.", "labels": [], "entities": []}, {"text": "We designed two types of formats in our dependency-based pre-ordering rules.", "labels": [], "entities": []}, {"text": "They are: Type-1: x : y Type-2: x -y Here, both x and y are dependency relations (e.g., plmod or lobj in).", "labels": [], "entities": []}, {"text": "We define the dependency structure of a dependency relation as the structure containing the dependent word (e.g., the word directly indicated by plmod, or \"\" in) and the whole subtree under the dependency relation (all of the words that directly or indirectly depend on the dependent word, or the words under \"\" in).", "labels": [], "entities": []}, {"text": "Further, we define X and Y as the corresponding dependency structures of the dependency relations x and y, respectively.", "labels": [], "entities": []}, {"text": "We define X\\Y as structure X except Y.", "labels": [], "entities": []}, {"text": "For example, in, let x and y denote plmod and lobj dependency relations, then X represents \"\" and all words under \"\", Y represents \"\" and all words under \"\", and X\\Y represents We obtained rules as the following steps: 1 Search the Chinese dependency parse trees in the corpus and rank all of the structures matching the two types of rules respectively according to their frequencies.", "labels": [], "entities": []}, {"text": "Note that while calculating the frequencies of Type-1 structures, we dismissed the structures in which X occurred before Y originally.", "labels": [], "entities": []}, {"text": "1) Filter out the structures which occurred less than 5,000 times.", "labels": [], "entities": []}, {"text": "2) Filter out the structures from which it was almost impossible to derive candidate pre-ordering rules because xor y was an \"irrespective\" dependency relation, for example, root, conj, cc and soon.", "labels": [], "entities": []}, {"text": "3 Investigate the remaining structures.", "labels": [], "entities": []}, {"text": "For each kind of structure, we selected some of the sample dependency parse trees that contained it, tried to restructure the parse trees according to the matched rule and judged the reordered Chinese phrases.", "labels": [], "entities": []}, {"text": "If the reordering produced a Chinese phrase that had a closer word order to that of the English one, this structure would be a candidate pre-ordering rule.", "labels": [], "entities": []}, {"text": "4 Conduct primary experiments which used the same training set and development set as the experiments described in Section 3.", "labels": [], "entities": []}, {"text": "In the primary experiments, we tested the effectiveness of the candidate rules and filtered the ones that did notwork based on the BLEU scores on the development set.: An example of rcmod structure with a preposition modifier.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 131, "end_pos": 135, "type": "METRIC", "confidence": 0.9993187189102173}]}, {"text": "The phrase translates into \"a press conference held in Kabul\".", "labels": [], "entities": []}, {"text": "As a result, we obtained eight pre-ordering rules in total, which can be divided into three dependency relation categories.", "labels": [], "entities": []}, {"text": "They are: plmod (localizer modifier of a preposition), rcmod (relative clause modifier) and prep (preposition modifer).", "labels": [], "entities": []}, {"text": "Each of these categories are discussed in detail below.", "labels": [], "entities": []}, {"text": "plmod shows an example of a prepositional phrase with a plmod structure, which translates literally into \"in the US embassy front\".", "labels": [], "entities": []}, {"text": "In Chinese, the dependent word of a plmod relation (e.g., \"\" in) occurs in the last position of the prepositional phrase.", "labels": [], "entities": []}, {"text": "However, in English, this kind of word (e.g., \"front\" in the caption of) always occur directly after prepositions, which is to say, in the second position in a prepositional phrase.", "labels": [], "entities": []}, {"text": "Therefore, we applied a rule plmod : lobj (localizer object) to reposition the dependent word of the plmod relation (e.g., \"\" in to the position before the lobj structure (e.g., \" \" in).", "labels": [], "entities": []}, {"text": "In this case, it also comes directly after the preposition.", "labels": [], "entities": []}, {"text": "Similarly, we created a rule plmod : lccomp (clausal complement of a localizer).", "labels": [], "entities": []}, {"text": "rcmod shows an example of an rcmod structure under an nsubj (nominal subject) structure.", "labels": [], "entities": [{"text": "rcmod", "start_pos": 0, "end_pos": 5, "type": "DATASET", "confidence": 0.8742934465408325}]}, {"text": "Here \"mw\" means \"measure word\".", "labels": [], "entities": []}, {"text": "As shown in the figure, relative clause modifiers in Chinese (e.g., \" \" in) occurs before the noun being modified, which is in contrast to English (e.g., \"close to Sharon\" in the caption of), where they come after.", "labels": [], "entities": []}, {"text": "Thus, we introduced a series of rules NOUN : rcmod to restructure rcmod structures so that the noun is moved to the head.", "labels": [], "entities": []}, {"text": "In this example, with the application of an nsubj : rcmod rule, the phrase can be translated into \"a senior official close to Sharon say\", which has a word order very close to English.", "labels": [], "entities": []}, {"text": "Since a noun can be nsubj, dobj (direct object), pobj (prepositional object) and lobj: The comparison of four systems, including the performance (BLEU) on the test set, the total count of each rule set and the number of sentences they were applied to on the training set.", "labels": [], "entities": [{"text": "BLEU)", "start_pos": 146, "end_pos": 151, "type": "METRIC", "confidence": 0.9577704966068268}]}, {"text": "in Stanford typed dependencies, we created four rules from the NOUN pattern.", "labels": [], "entities": [{"text": "NOUN pattern", "start_pos": 63, "end_pos": 75, "type": "DATASET", "confidence": 0.83205246925354}]}, {"text": "Note that for some preposition modifiers, we needed a rule rcmod : prep to conduct the same work.", "labels": [], "entities": []}, {"text": "For instance, the Chinese phrase in can be translated into \"hold in Kabul press conference\" with the application of this rule.", "labels": [], "entities": []}, {"text": "prep Within verb phrases, the positions of prep structures are quite different between Chinese and English.", "labels": [], "entities": []}, {"text": "shows an example of a verb phrase with a preposition modifier (prep), which literally translates into \"Musharraf at this place tell reporter\".", "labels": [], "entities": []}, {"text": "Recognizing that prep structures occur before the verb in Chinese (e.g., \" \" in) but after the verb in English (usually in the last position of a verb phrase, e.g., \"here\" in the caption of), we applied a rule prep -dobj to reposition prep structures after their sibling dobj structures.", "labels": [], "entities": []}, {"text": "In summary, the dependency-based preordering rule set has eight rules: plmod : lobj, plmod : lccomp, nsubj : rcmod, dobj : rcmod, pobj : rcmod, lobj : rcmod, rcmod : prep, and prep -dobj.", "labels": [], "entities": []}], "datasetContent": [{"text": "We used the MOSES PBSMT system ( ) in our experiments.", "labels": [], "entities": [{"text": "MOSES PBSMT system", "start_pos": 12, "end_pos": 30, "type": "DATASET", "confidence": 0.7880931893984476}]}, {"text": "The training data, which included those data used in, contained 1 million pairs of sentences extracted from the Linguistic Data Consortium's parallel news corpora.", "labels": [], "entities": []}, {"text": "Our development set was the official NIST MT evaluation data from 2002 to 2005, consisting of 4476 Chinese-English sentences pairs.", "labels": [], "entities": [{"text": "NIST MT evaluation data", "start_pos": 37, "end_pos": 60, "type": "DATASET", "confidence": 0.8409166932106018}]}, {"text": "Our test set was the NIST 2006 MT evaluation data, consisting of 1664 sentence pairs.", "labels": [], "entities": [{"text": "NIST 2006 MT evaluation data", "start_pos": 21, "end_pos": 49, "type": "DATASET", "confidence": 0.9133414030075073}]}, {"text": "We employed the Stanford Segmenter 1 to segment all of the data sets.", "labels": [], "entities": [{"text": "Stanford Segmenter 1", "start_pos": 16, "end_pos": 36, "type": "DATASET", "confidence": 0.9554448127746582}]}, {"text": "For evaluation, we used BLEU scores ().", "labels": [], "entities": [{"text": "BLEU", "start_pos": 24, "end_pos": 28, "type": "METRIC", "confidence": 0.9991851449012756}]}, {"text": "We implemented the constituent-based preordering rule set in for comparison, which is called WR07 below.", "labels": [], "entities": [{"text": "WR07", "start_pos": 93, "end_pos": 97, "type": "DATASET", "confidence": 0.9008913040161133}]}, {"text": "The Berkeley Parser () was employed for parsing the Chinese sentences.", "labels": [], "entities": [{"text": "Berkeley Parser", "start_pos": 4, "end_pos": 19, "type": "DATASET", "confidence": 0.8273789286613464}, {"text": "parsing the Chinese sentences", "start_pos": 40, "end_pos": 69, "type": "TASK", "confidence": 0.8117458820343018}]}, {"text": "For training the Berkeley Parser, we used Chinese Treebank (CTB) 7.0.", "labels": [], "entities": [{"text": "Chinese Treebank (CTB) 7.0", "start_pos": 42, "end_pos": 68, "type": "DATASET", "confidence": 0.9608190755049387}]}, {"text": "We conducted our dependency-based preordering experiments on the Berkeley Parser and the Mate Parser, which were shown to be the two best parsers for Stanford typed dependencies ().", "labels": [], "entities": []}, {"text": "First, we converted the constituent parse trees in the results of the Berkeley Parser into dependency parse trees by employing a tool in the Stanford Parser (.", "labels": [], "entities": []}, {"text": "For the Mate Parser, POS tagged inputs are required both in training and in inference.", "labels": [], "entities": []}, {"text": "Thus, we then extracted the POS information from the results of the Berkeley Parser and used these as the pre-specified POS tags for the Mate Parser.", "labels": [], "entities": []}, {"text": "Finally, we applied our dependency-based pre-ordering rule set to the dependency parse trees created from the converted Berkeley Parser and the Mate Parser, respectively.", "labels": [], "entities": []}, {"text": "presents a comparison of the system without pre-ordering, the constituent system using WR07 and two dependency systems employing the converted Berkeley Parser and the Mate Parser, respectively.", "labels": [], "entities": [{"text": "WR07", "start_pos": 87, "end_pos": 91, "type": "DATASET", "confidence": 0.937136709690094}]}, {"text": "It shows the BLEU scores on the test set and the statistics of pre-ordering on the training set, which includes the total count of each rule set and the number of sentences they were ap-: Accuracy of the dependency-based pre-ordering rules on a set of 200 sentences randomly selected from the development set.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 13, "end_pos": 17, "type": "METRIC", "confidence": 0.9989063739776611}]}, {"text": "Both of our dependency systems outperformed WR07 slightly but were not significant at p = 0.05.", "labels": [], "entities": [{"text": "WR07", "start_pos": 44, "end_pos": 48, "type": "DATASET", "confidence": 0.760676920413971}]}, {"text": "However, both of them substantially decreased the total times about 60% (or 1,600,000) for pre-ordering rule applications on the training set, compared with WR07.", "labels": [], "entities": [{"text": "WR07", "start_pos": 157, "end_pos": 161, "type": "DATASET", "confidence": 0.938784122467041}]}, {"text": "In our opinion, the reason for the great decrease was that the dependency parse trees were more concise than the constituent parse trees in describing sentences and they could also describe the reordering at the sentence level in a finer way.", "labels": [], "entities": []}, {"text": "In contrast, the constituent parse trees were more redundant and they needed more nodes to conduct long-distance reordering.", "labels": [], "entities": []}, {"text": "In this case, the affect of the performance of the constituent parsers on pre-ordering is larger than that of the dependency ones so that the constituent parsers are likely to bring about more incorrect pre-orderings.", "labels": [], "entities": []}, {"text": "Similar to, we carried out human evaluations to assess the accuracy of our dependency-based pre-ordering rules by employing the system \"OUR DEP 2\" in.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 59, "end_pos": 67, "type": "METRIC", "confidence": 0.9988805651664734}, {"text": "OUR DEP 2", "start_pos": 136, "end_pos": 145, "type": "METRIC", "confidence": 0.8763166069984436}]}, {"text": "The evaluation set contained 200 sentences randomly selected from the development set.", "labels": [], "entities": []}, {"text": "Among them, 107 sentences contained at least one rule and the rules were applied 185 times totally.", "labels": [], "entities": []}, {"text": "Since the accuracy check for dependency parse trees took great deal of time, we did not try to select error free (100% accurately parsed) sentences.", "labels": [], "entities": [{"text": "accuracy check", "start_pos": 10, "end_pos": 24, "type": "METRIC", "confidence": 0.9747664630413055}, {"text": "dependency parse trees", "start_pos": 29, "end_pos": 51, "type": "TASK", "confidence": 0.8258686065673828}]}, {"text": "A bilingual speaker of Chinese and English looked at an original Chinese phrase and the pre-ordered one with their corresponding English phrase and judged whether the pre-ordering obtained a Chinese phrase that had a closer word order to the English one.", "labels": [], "entities": []}, {"text": "shows the accuracies of three categories of our dependency-based pre-ordering rules.", "labels": [], "entities": []}, {"text": "The overall accuracy of this rule set is 60.0%, which is almost at the same level as the WR07 rule set (62.1%), according to the similar evaluation (200 sentences and one annotator) conducted in.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 12, "end_pos": 20, "type": "METRIC", "confidence": 0.999594509601593}, {"text": "WR07 rule set", "start_pos": 89, "end_pos": 102, "type": "DATASET", "confidence": 0.9748687346776327}]}, {"text": "Notice that some of the incorrect pre-orderings maybe caused by erroneous parsing as also suggested by.", "labels": [], "entities": []}, {"text": "Through human evaluations, we found that 19 out of the total 74 incorrect pre-orderings resulted from errors in parsing.", "labels": [], "entities": []}, {"text": "Among them, 13 incorrect pre-orderings applied the rules of the rcmod category.", "labels": [], "entities": []}, {"text": "The analysis suggests that we need to introduce constraints on the rule application of this category in the future.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: The comparison of four systems, including the performance (BLEU) on the test set, the total  count of each rule set and the number of sentences they were applied to on the training set.", "labels": [], "entities": [{"text": "BLEU)", "start_pos": 69, "end_pos": 74, "type": "METRIC", "confidence": 0.9771188795566559}]}, {"text": " Table 2: Accuracy of the dependency-based pre-ordering rules on a set of 200 sentences randomly se- lected from the development set.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9696350693702698}]}]}