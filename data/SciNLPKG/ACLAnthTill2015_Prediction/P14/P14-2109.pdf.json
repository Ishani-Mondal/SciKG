{"title": [{"text": "Parser Evaluation Using Derivation Trees: A Complement to evalb", "labels": [], "entities": [{"text": "Parser Evaluation", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.8616961240768433}]}], "abstractContent": [{"text": "This paper introduces anew technique for phrase-structure parser analysis, categorizing possible treebank structures by integrating regular expressions into derivation trees.", "labels": [], "entities": [{"text": "phrase-structure parser analysis", "start_pos": 41, "end_pos": 73, "type": "TASK", "confidence": 0.8843620618184408}]}, {"text": "We analyze the performance of the Berkeley parser on OntoNotes WSJ and the English Web Treebank.", "labels": [], "entities": [{"text": "OntoNotes WSJ", "start_pos": 53, "end_pos": 66, "type": "DATASET", "confidence": 0.833720862865448}, {"text": "English Web Treebank", "start_pos": 75, "end_pos": 95, "type": "DATASET", "confidence": 0.9543763597806295}]}, {"text": "This provides some insight into the evalb scores, and the problem of domain adaptation with the web data.", "labels": [], "entities": [{"text": "domain adaptation", "start_pos": 69, "end_pos": 86, "type": "TASK", "confidence": 0.7177869528532028}]}, {"text": "We also analyze a \"test-on-train\" dataset, showing a wide variance in how the parser is generalizing from different structures in the training material.", "labels": [], "entities": []}], "introductionContent": [{"text": "Phrase-structure parsing is usually evaluated using evalb, which provides a score based on matching brackets.", "labels": [], "entities": [{"text": "Phrase-structure parsing", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.9397826194763184}]}, {"text": "While this metric serves a valuable purpose in pushing parser research forward, it has limited utility for understanding what sorts of errors a parser is making.", "labels": [], "entities": []}, {"text": "This is the case even if the score is broken down by brackets (NP, VP, etc.), because the brackets can represent different types of structures.", "labels": [], "entities": []}, {"text": "We would also like to have answers to such questions as \"How does the parser do on non-recursive NPs, separate from NPs resulting from modification?", "labels": [], "entities": []}, {"text": "On PP attachment?\" etc.", "labels": [], "entities": [{"text": "PP attachment", "start_pos": 3, "end_pos": 16, "type": "TASK", "confidence": 0.7018868029117584}]}, {"text": "Answering such questions is the goal of this work, which combines two strands of research.", "labels": [], "entities": []}, {"text": "First, inspired by the tradition of Tree Adjoining Grammar-based research, we use a decomposition of the full trees into \"elementary trees\" (henceforth \"etrees\"), with a derivation tree that records how the etrees relate to each other, as in.", "labels": [], "entities": []}, {"text": "In particular, we use the \"spinal\" structure approach of , where etrees are constrained to be unary-branching.", "labels": [], "entities": []}, {"text": "Second, we use a set of regular expressions (henceforth \"regexes\") that categorize the possible structures in the treebank.", "labels": [], "entities": []}, {"text": "These are best thought of as an extension of head-finding rules, which not only find ahead but simultaneously identify each parent/children relation as one of a limited number of types of structures (right-modification, etc.).", "labels": [], "entities": []}, {"text": "The crucial step is that we integrate these regexes into the spinal etrees.", "labels": [], "entities": []}, {"text": "The derivation trees provide elements of a dependency analysis, which allow us to calculate scores for head identification and attachment for different projections (e.g., PP).", "labels": [], "entities": [{"text": "head identification", "start_pos": 103, "end_pos": 122, "type": "TASK", "confidence": 0.8266027569770813}]}, {"text": "The regexes allow us to also provide scores based on spans of different construction types.", "labels": [], "entities": []}, {"text": "Together these two aspects breakdown the evalb brackets into more meaningful categories, and the simultaneous head and span scoring allows us to separate these aspects in the analysis.", "labels": [], "entities": []}, {"text": "After describing in more detail the basic framework, we show some aspects of the resulting analysis of the performance of the Berkeley parser () on three datasets: (a) OntoNotes WSJ sections 2-21 () 1 , (b) OntoNotes WSJ section 22, and (c) the \"Answers\" section of the English Web Treebank ( . We trained the parser on sections 2-21, and so (a) is \"test-on-train\".", "labels": [], "entities": [{"text": "OntoNotes WSJ section 22", "start_pos": 207, "end_pos": 231, "type": "DATASET", "confidence": 0.7861060202121735}, {"text": "English Web Treebank", "start_pos": 270, "end_pos": 290, "type": "DATASET", "confidence": 0.9493585228919983}]}, {"text": "These three results together show how the parser is generalizing from the training data, and what aspects of the \"domain adaptation\" problem to the web material are particularly important.", "labels": [], "entities": [{"text": "domain adaptation\"", "start_pos": 114, "end_pos": 132, "type": "TASK", "confidence": 0.8024866978327433}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Corpus information for gold(g) and  parsed(p) sections of each corpus", "labels": [], "entities": []}, {"text": " Table 2: Scores for the most frequent categories of brackets in the three datasets of corpora, as determined  by the regexes. % gold is the frequency of this regex type compared to all the brackets in the gold. F-h  is the score based on matching heads, F-s also incorporates the span information, att is the attachment  accuracy for words that match in F-h, and spanR is the span-right accuracy for words that match in F-h.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 322, "end_pos": 330, "type": "METRIC", "confidence": 0.5467062592506409}, {"text": "spanR", "start_pos": 364, "end_pos": 369, "type": "METRIC", "confidence": 0.9871498346328735}, {"text": "span-right accuracy", "start_pos": 377, "end_pos": 396, "type": "METRIC", "confidence": 0.6686355173587799}]}]}