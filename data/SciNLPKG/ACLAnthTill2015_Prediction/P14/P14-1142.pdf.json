{"title": [{"text": "A Joint Graph Model for Pinyin-to-Chinese Conversion with Typo Correction *", "labels": [], "entities": [{"text": "Pinyin-to-Chinese Conversion", "start_pos": 24, "end_pos": 52, "type": "TASK", "confidence": 0.8629603385925293}]}], "abstractContent": [{"text": "It is very import for Chinese language processing with the aid of an efficient input method engine (IME), of which pinyin-to-Chinese (PTC) conversion is the core part.", "labels": [], "entities": [{"text": "Chinese language processing", "start_pos": 22, "end_pos": 49, "type": "TASK", "confidence": 0.6131601432959238}]}, {"text": "Meanwhile, though typos are inevitable during user pinyin inputting, existing IMEs paid little attention to such big inconvenience.", "labels": [], "entities": []}, {"text": "In this paper, motivated by a key equivalence of two decoding algorithms , we propose a joint graph model to globally optimize PTC and typo correction for IME.", "labels": [], "entities": [{"text": "PTC", "start_pos": 127, "end_pos": 130, "type": "METRIC", "confidence": 0.6394405961036682}, {"text": "IME", "start_pos": 155, "end_pos": 158, "type": "TASK", "confidence": 0.917554497718811}]}, {"text": "The evaluation results show that the proposed method outperforms both existing academic and commercial IMEs.", "labels": [], "entities": []}], "introductionContent": [], "datasetContent": [{"text": "The corpus for evaluation is the one provided in (, which is originally extracted from the People's Daily corpus and labeled with pinyin.", "labels": [], "entities": [{"text": "People's Daily corpus", "start_pos": 91, "end_pos": 112, "type": "DATASET", "confidence": 0.9487027823925018}]}, {"text": "The corpus has already been split into training T\uf772\uf761\uf769\uf76e, development D\uf765\uf776 and test T\uf765\uf773\uf774 sets as shown in) is adopted for language model training and KenLM) for language model query.", "labels": [], "entities": []}, {"text": "The Chinese part of the corpus is segmented into words before LM training.", "labels": [], "entities": []}, {"text": "Maximum matching word segmentation is used with a large word vocabulary V extracted from web data provided by ().", "labels": [], "entities": [{"text": "matching word segmentation", "start_pos": 8, "end_pos": 34, "type": "TASK", "confidence": 0.6905338764190674}]}, {"text": "The pinyin part is segmented according to the Chinese part.", "labels": [], "entities": []}, {"text": "This vocabulary V also serves as the PTC dictionary.", "labels": [], "entities": [{"text": "PTC dictionary", "start_pos": 37, "end_pos": 51, "type": "DATASET", "confidence": 0.9403618574142456}]}, {"text": "The original vocabulary is not labeled with pinyin, thus we use the PTC dictionary of sunpinyin 1 which is an open source Chinese pinyin IME, to label the vocabulary V with pinyin.", "labels": [], "entities": [{"text": "PTC dictionary of sunpinyin 1", "start_pos": 68, "end_pos": 97, "type": "DATASET", "confidence": 0.9653202533721924}]}, {"text": "The emission probabilities are estimated using the lexical translation module of MOSES ( as \"translation probability\" from pinyin to Chinese.", "labels": [], "entities": [{"text": "MOSES", "start_pos": 81, "end_pos": 86, "type": "DATASET", "confidence": 0.7375621199607849}]}, {"text": "We will use conventional sequence labeling evaluation metrics such as sequence accuracy and character accuracy 2 . Chinese characters in a sentence maybe separated by digits, punctuation and alphabets which are directly inputted without the IME.", "labels": [], "entities": [{"text": "sequence labeling evaluation", "start_pos": 25, "end_pos": 53, "type": "TASK", "confidence": 0.7442442377408346}, {"text": "accuracy", "start_pos": 79, "end_pos": 87, "type": "METRIC", "confidence": 0.6370783448219299}, {"text": "IME", "start_pos": 241, "end_pos": 244, "type": "DATASET", "confidence": 0.7083728909492493}]}, {"text": "We follow the so-called term Max Input Unit (MIU), the longest consecutive Chinese character sequence proposed by ).", "labels": [], "entities": [{"text": "Max Input Unit (MIU)", "start_pos": 29, "end_pos": 49, "type": "METRIC", "confidence": 0.9354368348916372}]}, {"text": "We will mainly consider MIU accuracy (MIU-Acc) which is the ratio of the number of completely corrected generated MIUs over the number of all MIUs, and character accuracy (Ch-Acc), but the sentence accuracy (S-Acc) will also be reported in evaluation results.", "labels": [], "entities": [{"text": "accuracy (MIU-Acc)", "start_pos": 28, "end_pos": 46, "type": "METRIC", "confidence": 0.6960231587290764}, {"text": "accuracy", "start_pos": 162, "end_pos": 170, "type": "METRIC", "confidence": 0.5276597738265991}, {"text": "sentence accuracy", "start_pos": 189, "end_pos": 206, "type": "METRIC", "confidence": 0.5186308920383453}]}, {"text": "We will also report the conversion error rate (ConvER) proposed by, which is the ratio of the number of mistyped pinyin word that is not converted to the right Chinese word over the total number of mistyped pinyin words 3 .", "labels": [], "entities": [{"text": "conversion error rate (ConvER)", "start_pos": 24, "end_pos": 54, "type": "METRIC", "confidence": 0.8804847796758016}]}], "tableCaptions": [{"text": " Table 1: Data set size", "labels": [], "entities": []}, {"text": " Table 2: Baseline system compared to other  IMEs (%)", "labels": [], "entities": []}, {"text": " Table 3: Test results on 10K sentences from T\uf765\uf773\uf774  (%)", "labels": [], "entities": [{"text": "T", "start_pos": 45, "end_pos": 46, "type": "METRIC", "confidence": 0.9921410083770752}]}, {"text": " Table 4: Test results on T\uf765\uf773\uf774 (%)", "labels": [], "entities": [{"text": "T", "start_pos": 26, "end_pos": 27, "type": "METRIC", "confidence": 0.996263325214386}]}]}