{"title": [{"text": "Context-aware Learning for Sentence-level Sentiment Analysis with Posterior Regularization", "labels": [], "entities": [{"text": "Sentence-level Sentiment Analysis", "start_pos": 27, "end_pos": 60, "type": "TASK", "confidence": 0.817595362663269}]}], "abstractContent": [{"text": "This paper proposes a novel context-aware method for analyzing sentiment at the level of individual sentences.", "labels": [], "entities": [{"text": "analyzing sentiment", "start_pos": 53, "end_pos": 72, "type": "TASK", "confidence": 0.8056829869747162}]}, {"text": "Most existing machine learning approaches suffer from limitations in the modeling of complex linguistic structures across sentences and often fail to capture non-local contextual cues that are important for sentiment interpretation.", "labels": [], "entities": [{"text": "sentiment interpretation", "start_pos": 207, "end_pos": 231, "type": "TASK", "confidence": 0.926747053861618}]}, {"text": "In contrast, our approach allows structured modeling of sentiment while taking into account both local and global contextual information.", "labels": [], "entities": [{"text": "modeling of sentiment", "start_pos": 44, "end_pos": 65, "type": "TASK", "confidence": 0.6408572296301523}]}, {"text": "Specifically, we encode intuitive lexical and discourse knowledge as expressive constraints and integrate them into the learning of conditional random field models via posterior regularization.", "labels": [], "entities": []}, {"text": "The context-aware constraints provide additional power to the CRF model and can guide semi-supervised learning when labeled data is limited.", "labels": [], "entities": []}, {"text": "Experiments on standard product review datasets show that our method outperforms the state-of-the-art methods in both the supervised and semi-supervised settings.", "labels": [], "entities": []}], "introductionContent": [{"text": "The ability to extract sentiment from text is crucial for many opinion-mining applications such as opinion summarization, opinion question answering and opinion retrieval.", "labels": [], "entities": [{"text": "opinion summarization", "start_pos": 99, "end_pos": 120, "type": "TASK", "confidence": 0.7605009377002716}, {"text": "opinion question answering", "start_pos": 122, "end_pos": 148, "type": "TASK", "confidence": 0.7362914681434631}, {"text": "opinion retrieval", "start_pos": 153, "end_pos": 170, "type": "TASK", "confidence": 0.8061671257019043}]}, {"text": "Accordingly, extracting sentiment at the fine-grained level (e.g. at the sentence-or phrase-level) has received increasing attention recently due to its challenging nature and its importance in supporting these opinion analysis tasks.", "labels": [], "entities": [{"text": "extracting sentiment", "start_pos": 13, "end_pos": 33, "type": "TASK", "confidence": 0.8873131275177002}, {"text": "opinion analysis", "start_pos": 211, "end_pos": 227, "type": "TASK", "confidence": 0.8306536972522736}]}, {"text": "In this paper, we focus on the task of sentencelevel sentiment classification in online reviews.", "labels": [], "entities": [{"text": "sentencelevel sentiment classification", "start_pos": 39, "end_pos": 77, "type": "TASK", "confidence": 0.8126837015151978}]}, {"text": "Typical approaches to the task employ supervised machine learning algorithms with rich features and take into account the interactions between words to handle compositional effects such as polarity reversal (e.g. ().", "labels": [], "entities": []}, {"text": "Still, their methods can encounter difficulty when the sentence on its own does not contain strong enough sentiment signals (due to the lack of statistical evidence or the requirement for background knowledge).", "labels": [], "entities": []}, {"text": "Consider the following review for example,.", "labels": [], "entities": []}, {"text": "Hearing the music in real stereo is a true revelation.", "labels": [], "entities": []}, {"text": "2. You can feel that the music is no longer constrained by the mono recording.", "labels": [], "entities": []}, {"text": "3. In fact, it is more like the players are performing on a stage in front of you ...", "labels": [], "entities": []}, {"text": "Existing feature-based classifiers maybe effective in identifying the positive sentiment of the first sentence due to the use of the word revelation, but they could be less effective in the last two sentences due to the lack of explicit sentiment signals.", "labels": [], "entities": []}, {"text": "However, if we examine these sentences within the discourse context, we can see that: the second sentence expresses sentiment towards the same aspect -the music -as the first sentence; the third sentence expands the second sentence with the discourse connective In fact.", "labels": [], "entities": []}, {"text": "These discourse-level relations help indicate that sentence 2 and 3 are likely to have positive sentiment as well.", "labels": [], "entities": []}, {"text": "The importance of discourse for sentiment analysis has become increasingly recognized.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 32, "end_pos": 50, "type": "TASK", "confidence": 0.9716274440288544}]}, {"text": "Most existing work considers discourse relations between adjacent sentences or clauses and incorporates them as constraints; Zhou et al., 2011) or features in classifiers.", "labels": [], "entities": []}, {"text": "Very little work has explored long-distance discourse relations for sentiment analysis.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 68, "end_pos": 86, "type": "TASK", "confidence": 0.961868017911911}]}, {"text": "defines coreference relations on opinion targets and applies them to constrain the polarity of sentences.", "labels": [], "entities": []}, {"text": "However, the discourse relations were obtained from fine-grained annotations and implemented as hard constraints on polarity.", "labels": [], "entities": []}, {"text": "Obtaining sentiment labels at the fine-grained level is costly.", "labels": [], "entities": []}, {"text": "Semi-supervised techniques have been proposed for sentence-level sentiment classification).", "labels": [], "entities": [{"text": "sentence-level sentiment classification", "start_pos": 50, "end_pos": 89, "type": "TASK", "confidence": 0.7930073936780294}]}, {"text": "However, they rely on a large amount of document-level sentiment labels that may not be naturally available in many domains.", "labels": [], "entities": []}, {"text": "In this paper, we propose a sentence-level sentiment classification method that can (1) incorporate rich discourse information at both local and global levels; (2) encode discourse knowledge as soft constraints during learning; (3) make use of unlabeled data to enhance learning.", "labels": [], "entities": [{"text": "sentence-level sentiment classification", "start_pos": 28, "end_pos": 67, "type": "TASK", "confidence": 0.7492479880650839}]}, {"text": "Specifically, we use the Conditional Random Field (CRF) model as the learner for sentence-level sentiment classification, and incorporate rich discourse and lexical knowledge as soft constraints into the learning of CRF parameters via Posterior Regularization (PR) (.", "labels": [], "entities": [{"text": "sentence-level sentiment classification", "start_pos": 81, "end_pos": 120, "type": "TASK", "confidence": 0.7390283246835073}]}, {"text": "As a framework for structured learning with constraints, PR has been successfully applied to many structural NLP tasks (.", "labels": [], "entities": []}, {"text": "Our work is the first to explore PR for sentiment analysis.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 40, "end_pos": 58, "type": "TASK", "confidence": 0.933178573846817}]}, {"text": "Unlike most previous work, we explore a rich set of structural constraints that cannot be naturally encoded in the feature-label form, and show that such constraints can improve the performance of the CRF model.", "labels": [], "entities": []}, {"text": "We evaluate our approach on the sentencelevel sentiment classification task using two standard product review datasets.", "labels": [], "entities": [{"text": "sentencelevel sentiment classification task", "start_pos": 32, "end_pos": 75, "type": "TASK", "confidence": 0.8604229837656021}]}, {"text": "Experimental results show that our model outperforms state-ofthe-art methods in both the supervised and semisupervised settings.", "labels": [], "entities": []}, {"text": "We also show that discourse knowledge is highly useful for improving sentence-level sentiment classification.", "labels": [], "entities": [{"text": "sentence-level sentiment classification", "start_pos": 69, "end_pos": 108, "type": "TASK", "confidence": 0.7836239735285441}]}], "datasetContent": [{"text": "We experimented with two product review datasets for sentence-level sentiment classification: the Customer Review (CR) data ( which contains 638 reviews of 14 products such as cameras and cell phones, and the Multi-domain Amazon (MD) data from the test set of T\u00e4ckstr\u00f6m and McDonald (2011a) which contains 294 reivews from 5 different domains.", "labels": [], "entities": [{"text": "sentence-level sentiment classification", "start_pos": 53, "end_pos": 92, "type": "TASK", "confidence": 0.7652133405208588}, {"text": "Customer Review (CR)", "start_pos": 98, "end_pos": 118, "type": "METRIC", "confidence": 0.7164210140705108}, {"text": "Multi-domain Amazon (MD) data from the test set of T\u00e4ckstr\u00f6m and McDonald (2011a)", "start_pos": 209, "end_pos": 290, "type": "DATASET", "confidence": 0.7252556085586548}]}, {"text": "As in, we chose the books, electronics and music domains for evaluation.", "labels": [], "entities": []}, {"text": "Each domain also comes with 33,000 extra reviews with only document-level sentiment labels.", "labels": [], "entities": []}, {"text": "We evaluated our method in two settings: supervised and semi-supervised.", "labels": [], "entities": []}, {"text": "In the supervised setting, we treated the test data as unlabeled data and performed transductive learning.", "labels": [], "entities": []}, {"text": "In the semisupervised setting, our unlabeled data consists of both the available unlabeled data and the test data.", "labels": [], "entities": []}, {"text": "For each domain in the MD dataset, we made use of no more than 100 unlabeled documents in which our posterior constraints apply.", "labels": [], "entities": [{"text": "MD dataset", "start_pos": 23, "end_pos": 33, "type": "DATASET", "confidence": 0.8740816414356232}]}, {"text": "We adopted the evaluation schemes used in previous work: 10-fold cross validation for the CR dataset and 3-fold cross validation for the MD dataset.", "labels": [], "entities": [{"text": "CR dataset", "start_pos": 90, "end_pos": 100, "type": "DATASET", "confidence": 0.8281356692314148}, {"text": "MD dataset", "start_pos": 137, "end_pos": 147, "type": "DATASET", "confidence": 0.9252855181694031}]}, {"text": "We also report both two-way classification (positive vs. negative) and three-way classification results (positive, negative or neutral).", "labels": [], "entities": []}, {"text": "We use accuracy as the performance measure.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 7, "end_pos": 15, "type": "METRIC", "confidence": 0.9995805621147156}]}, {"text": "In our tables, boldface numbers are statistically significant by paired t-test for p < 0.05 against the best baseline developed in this paper . We trained our model using a CRF incorporated with the proposed posterior constraints.", "labels": [], "entities": []}, {"text": "For the CRF features, we include the tokens, the partof-speech tags, the prior polarities of lexical patterns indicated by the opinion lexicon and the negator lexicon, the number of positive and negative tokens and the output of the vote-flip algorithm ().", "labels": [], "entities": []}, {"text": "In addition, we include the discourse connectives as local or transition features and the document-level sentiment labels as features (only available in the MD dataset).", "labels": [], "entities": [{"text": "MD dataset", "start_pos": 157, "end_pos": 167, "type": "DATASET", "confidence": 0.7739297449588776}]}, {"text": "We set the CRF regularization parameter \u03c3 = 1 and set the posterior regularization parameter \u03b2 and \u03b3 (a trade-off parameter we introduce to balance the supervised objective and the posterior regularizer in 2) by using grid search 8 . For approximation inference with higher-order constraints, we perform 2000 Gibbs sampling iterations where the first 1000 iterations are burn-in iterations.", "labels": [], "entities": []}, {"text": "To make the results more stable, we construct three Markov chains that run in parallel, and select the sample with the largest objective value.", "labels": [], "entities": []}, {"text": "All posterior constraints were developed using the training data on each training fold.", "labels": [], "entities": []}, {"text": "For the MD dataset, we also used the dvd domain as additional labeled data for developing the constraints.", "labels": [], "entities": [{"text": "MD dataset", "start_pos": 8, "end_pos": 18, "type": "DATASET", "confidence": 0.8714558184146881}]}, {"text": "We compared our method to a number of baselines: (1) CRF: CRF with the same set of model features as in our method.", "labels": [], "entities": []}, {"text": "(2) CRF-INF: CRF augmented with inference constraints.", "labels": [], "entities": []}, {"text": "We can incorporate the proposed constraints (constraints derived from lexical patterns and discourse connectives) as hard constraints into CRF during: Accuracy results (%) for semi-supervised sentiment classification (three-way) on the MD dataset inference by manually setting \u03bb in equation 4 to a large value, . When \u03bb is large enough, it is equivalent to adding hard constraints to the viterbi inference.", "labels": [], "entities": [{"text": "semi-supervised sentiment classification", "start_pos": 176, "end_pos": 216, "type": "TASK", "confidence": 0.6653202176094055}]}, {"text": "To better understand the different effects of lexical and discourse constraints, we report results for applying only the lexical constraints (CRF-INF lex ) as well as results for applying only the discourse constraints (CRF-INF disc ).", "labels": [], "entities": []}, {"text": "(3) PR lex : a variant of our PR model which only applies the lexical constraints.", "labels": [], "entities": []}, {"text": "For the three-way classification task on the MD dataset, we also implemented the following baselines: (4) VOTEFLIP: a rulebased algorithm that leverages the positive, negative and neutral cues along with the effect of negation to determine the sentence sentiment).", "labels": [], "entities": [{"text": "MD dataset", "start_pos": 45, "end_pos": 55, "type": "DATASET", "confidence": 0.8169734179973602}, {"text": "VOTEFLIP", "start_pos": 106, "end_pos": 114, "type": "METRIC", "confidence": 0.9542383551597595}]}, {"text": "(5) DOCORACLE: assigns each sentence the label of its corresponding document.", "labels": [], "entities": [{"text": "DOCORACLE", "start_pos": 4, "end_pos": 13, "type": "METRIC", "confidence": 0.7626475691795349}]}], "tableCaptions": [{"text": " Table 2: Accuracy results (%) for supervised sen- timent classification (two-way)", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9995418787002563}]}, {"text": " Table 3: Accuracy results (%) for semi-supervised  sentiment classification (three-way) on the MD  dataset", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9992351531982422}, {"text": "semi-supervised  sentiment classification", "start_pos": 35, "end_pos": 76, "type": "TASK", "confidence": 0.6787816882133484}, {"text": "MD  dataset", "start_pos": 96, "end_pos": 107, "type": "DATASET", "confidence": 0.9339670240879059}]}, {"text": " Table 4: F1 scores for each sentiment cate- gory (positive, negative and neutral) for semi- supervised sentiment classification on the MD  dataset", "labels": [], "entities": [{"text": "F1", "start_pos": 10, "end_pos": 12, "type": "METRIC", "confidence": 0.9994181394577026}, {"text": "semi- supervised sentiment classification", "start_pos": 87, "end_pos": 128, "type": "TASK", "confidence": 0.6929471373558045}, {"text": "MD  dataset", "start_pos": 136, "end_pos": 147, "type": "DATASET", "confidence": 0.95498988032341}]}]}