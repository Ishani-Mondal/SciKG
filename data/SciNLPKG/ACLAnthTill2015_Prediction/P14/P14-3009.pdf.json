{"title": [], "abstractContent": [{"text": "The current work adapts the optimal tree pruning algorithm(BFOS) introduced by Breiman et al.(1984) and extended by Chou et al.(1989) to the multi-document summarization task.", "labels": [], "entities": [{"text": "multi-document summarization task", "start_pos": 141, "end_pos": 174, "type": "TASK", "confidence": 0.690834661324819}]}, {"text": "BFOS algorithm is used to eliminate redundancy which is one of the main issues in multi-document sum-marization.", "labels": [], "entities": [{"text": "BFOS", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.48657360672950745}]}, {"text": "Hierarchical Agglomerative Clustering algorithm(HAC) is employed to detect the redundancy.", "labels": [], "entities": []}, {"text": "The tree designed by HAC algorithm is successively pruned with the optimal tree pruning algorithm to optimize the distortion vs. rate cost of the resultant tree.", "labels": [], "entities": []}, {"text": "Rate parameter is defined to be the number of the sentences in the leaves of the tree.", "labels": [], "entities": [{"text": "Rate", "start_pos": 0, "end_pos": 4, "type": "METRIC", "confidence": 0.9024112820625305}]}, {"text": "Distortion is the sum of the distances between the representative sentence of the cluster at each node and the other sentences in the same cluster.", "labels": [], "entities": [{"text": "Distortion", "start_pos": 0, "end_pos": 10, "type": "METRIC", "confidence": 0.9779880046844482}]}, {"text": "The sentences assigned to the leaves of the resultant tree are included in the summary.", "labels": [], "entities": []}, {"text": "The performance of the proposed system assessed with the Rouge-1 metric is seen to be better than the performance of the DUC-2002 winners on DUC-2002 data set.", "labels": [], "entities": [{"text": "DUC-2002 winners", "start_pos": 121, "end_pos": 137, "type": "DATASET", "confidence": 0.9163094758987427}, {"text": "DUC-2002 data set", "start_pos": 141, "end_pos": 158, "type": "DATASET", "confidence": 0.963599701722463}]}], "introductionContent": [{"text": "Nowadays, the massive amount of information available in the form of digital media over the internet makes us seek effective ways of accessing this information.", "labels": [], "entities": []}, {"text": "Textual documents, audio and video materials are uploaded every second.", "labels": [], "entities": []}, {"text": "For instance, the number of Google's indexed web pages has exceeded 30 billion web pages in the last two years.", "labels": [], "entities": []}, {"text": "Extraction of the needed information from a massive information pool is a challenging task.", "labels": [], "entities": [{"text": "Extraction", "start_pos": 0, "end_pos": 10, "type": "TASK", "confidence": 0.9525968432426453}]}, {"text": "The task of skimming all the documents in their entirety before deciding which information is relevant is very time consuming.", "labels": [], "entities": []}, {"text": "One of the well known and extensively studied methods for solving this problem is summarization.", "labels": [], "entities": [{"text": "summarization", "start_pos": 82, "end_pos": 95, "type": "TASK", "confidence": 0.9914381504058838}]}, {"text": "Text summarization produces a short version of a document that covers the main topics in it).", "labels": [], "entities": [{"text": "Text summarization", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.7165794670581818}]}, {"text": "It enables the reader to determine in a timely manner whether a given document satisfies his/her needs or not.", "labels": [], "entities": []}, {"text": "A single document summarization system produces a summary of only one document whereas a multi-document summarization system produces a summary based on multiple documents on the same topic.", "labels": [], "entities": []}, {"text": "Summarization systems can also be categorized as generic or query-based . A generic summary contains general information about particular documents.", "labels": [], "entities": []}, {"text": "It includes any information supposed to be important and somehow linked to the topics of the document set.", "labels": [], "entities": []}, {"text": "In contrast, a query based summary comprises information relevant to the given query.", "labels": [], "entities": []}, {"text": "In this case, query is a rule according to which a summary is to be generated.", "labels": [], "entities": []}, {"text": "Summarization systems can be also classified as extractive or abstractive.", "labels": [], "entities": []}, {"text": "In extractive systems, a summary is created by selecting important sentences from a document.", "labels": [], "entities": []}, {"text": "Here, only sentences containing information related to the main topics of the document are considered to be important.", "labels": [], "entities": []}, {"text": "These sentences are added to the summary without any modification.", "labels": [], "entities": []}, {"text": "On the other hand, abstractive systems can modify the existing sentences or even generate new sentences to be included in the summary.", "labels": [], "entities": []}, {"text": "Therefore, abstractive summarization is typically more complex than extractive summarization.", "labels": [], "entities": [{"text": "abstractive summarization", "start_pos": 11, "end_pos": 36, "type": "TASK", "confidence": 0.5848121345043182}]}, {"text": "The main goal in multi-document summarization is redundancy elimination.", "labels": [], "entities": [{"text": "multi-document summarization", "start_pos": 17, "end_pos": 45, "type": "TASK", "confidence": 0.6184550225734711}, {"text": "redundancy elimination", "start_pos": 49, "end_pos": 71, "type": "TASK", "confidence": 0.7870152294635773}]}, {"text": "Since the documents are related to the same topics, similar text units(passages, sentences etc.) are encountered frequently in different documents.", "labels": [], "entities": []}, {"text": "Such text units that indicate the importance of the topics discussed within them should be detected in order to reduce the redundancy.", "labels": [], "entities": []}, {"text": "Some of the well-known ap-proaches that address this problem are briefly explained in the following section.", "labels": [], "entities": []}, {"text": "Although much work has been done to eliminate the redundancy in multi-document summarization, the problem is still actual and addressed in the current work as well.", "labels": [], "entities": [{"text": "multi-document summarization", "start_pos": 64, "end_pos": 92, "type": "TASK", "confidence": 0.5630407333374023}]}, {"text": "The current work proposes to integrate the generalized BFOS algorithm ( adopted by for pruned tree structured quantizer design with the HAC (Hierarchical Agglomerative Clustering) algorithm.", "labels": [], "entities": [{"text": "BFOS", "start_pos": 55, "end_pos": 59, "type": "METRIC", "confidence": 0.7079895734786987}]}, {"text": "The two main parameters (distortion and rate) in the latter work are adopted to the multi-document summarization task.", "labels": [], "entities": [{"text": "distortion", "start_pos": 25, "end_pos": 35, "type": "METRIC", "confidence": 0.9784160852432251}, {"text": "multi-document summarization", "start_pos": 84, "end_pos": 112, "type": "TASK", "confidence": 0.575289785861969}]}, {"text": "Distortion can be succinctly defined as the information loss in the meaning of the sentences due to their representation with other sentences.", "labels": [], "entities": []}, {"text": "More specifically, in the current context, distortion contribution of a cluster is taken to be the sum of the distances between the vector representations of the sentences in the cluster and representative sentence of that cluster.", "labels": [], "entities": []}, {"text": "Rate of a summary is defined to be the number of sentences in the summary, but more precise definitions involving word or character counts are also possible.", "labels": [], "entities": [{"text": "Rate", "start_pos": 0, "end_pos": 4, "type": "METRIC", "confidence": 0.9448140263557434}]}, {"text": "BFOS based tree pruning algorithm is applied to the tree built with the HAC algorithm.", "labels": [], "entities": [{"text": "BFOS", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.8663148283958435}]}, {"text": "HAC algorithm is used for clustering purposes since BFOS algorithm gets tree structured data as an input.", "labels": [], "entities": []}, {"text": "It is found that the suggested approach yields better results in terms of the ROUGE-1 Recall measure () when compared to 400 word extractive summaries(400E) included in DUC-2002 data set.", "labels": [], "entities": [{"text": "ROUGE-1 Recall measure", "start_pos": 78, "end_pos": 100, "type": "METRIC", "confidence": 0.8452888528505961}, {"text": "DUC-2002 data set", "start_pos": 169, "end_pos": 186, "type": "DATASET", "confidence": 0.9766201774279276}]}, {"text": "Also, the results with the proposed method are higher than the ones obtained with the best systems of DUC-2002 in terms of sentence recall and precision).", "labels": [], "entities": [{"text": "DUC-2002", "start_pos": 102, "end_pos": 110, "type": "DATASET", "confidence": 0.9086976647377014}, {"text": "recall", "start_pos": 132, "end_pos": 138, "type": "METRIC", "confidence": 0.8690537214279175}, {"text": "precision", "start_pos": 143, "end_pos": 152, "type": "METRIC", "confidence": 0.999004065990448}]}], "datasetContent": [{"text": "The testing of the system performed on DUC-2002 data set) since the proposed system is designed to produce a generic summary without specified information need of users or predefined user profile.", "labels": [], "entities": [{"text": "DUC-2002 data set", "start_pos": 39, "end_pos": 56, "type": "DATASET", "confidence": 0.9869675040245056}]}, {"text": "This data set contains 59 document sets.", "labels": [], "entities": []}, {"text": "For each document set extraction based summaries with the length 200 and 400 words are provided.", "labels": [], "entities": []}, {"text": "Document sets related to the single event are used for testing purposes.", "labels": [], "entities": []}, {"text": "Evaluation of the system is carried out using ROUGE package).", "labels": [], "entities": [{"text": "ROUGE", "start_pos": 46, "end_pos": 51, "type": "METRIC", "confidence": 0.926771879196167}]}, {"text": "Rouge is a summary evaluation approach based on n-gram cooccurrence , longest common subsequence and skip bigram statistics (.", "labels": [], "entities": []}, {"text": "The performance of the summarizing system is measured with Rouge-1 Recall, Rouge-1 Precision and F1 measure).", "labels": [], "entities": [{"text": "summarizing", "start_pos": 23, "end_pos": 34, "type": "TASK", "confidence": 0.9679424166679382}, {"text": "Rouge-1", "start_pos": 59, "end_pos": 66, "type": "DATASET", "confidence": 0.48512163758277893}, {"text": "Recall", "start_pos": 67, "end_pos": 73, "type": "METRIC", "confidence": 0.6951808929443359}, {"text": "Precision", "start_pos": 83, "end_pos": 92, "type": "METRIC", "confidence": 0.7779648303985596}, {"text": "F1 measure", "start_pos": 97, "end_pos": 107, "type": "METRIC", "confidence": 0.9884163439273834}]}, {"text": "400E stood for the extractive 400 word summary provided by DUC-2002 data set.", "labels": [], "entities": [{"text": "DUC-2002 data set", "start_pos": 59, "end_pos": 76, "type": "DATASET", "confidence": 0.9841853976249695}]}, {"text": "It was created manually as an extractive summary for evaluation purposes.", "labels": [], "entities": []}, {"text": "Candidate summary(CS) was produced by the proposed system.", "labels": [], "entities": [{"text": "Candidate summary(CS)", "start_pos": 0, "end_pos": 21, "type": "TASK", "confidence": 0.7487693428993225}]}, {"text": "Both summaries were compared against a 200 word abstractive summary included in DUC-2002 data set.", "labels": [], "entities": [{"text": "DUC-2002 data set", "start_pos": 80, "end_pos": 97, "type": "DATASET", "confidence": 0.9860166311264038}]}, {"text": "200 word abstractive summary was considered as the model summary in ROUGE package.", "labels": [], "entities": []}, {"text": "As shown, the summary of the proposed system gives better results in Rouge-1 recall measure.", "labels": [], "entities": [{"text": "Rouge-1", "start_pos": 69, "end_pos": 76, "type": "DATASET", "confidence": 0.687149167060852}, {"text": "recall measure", "start_pos": 77, "end_pos": 91, "type": "METRIC", "confidence": 0.9554190337657928}]}, {"text": "However, the highest precision is achieved in the 400E summary.", "labels": [], "entities": [{"text": "precision", "start_pos": 21, "end_pos": 30, "type": "METRIC", "confidence": 0.9996823072433472}, {"text": "400E summary", "start_pos": 50, "end_pos": 62, "type": "DATASET", "confidence": 0.7174519747495651}]}, {"text": "Generally, the proposed system outperforms the 400E summary, since F1-score which takes into account precision and recall is higher.", "labels": [], "entities": [{"text": "F1-score", "start_pos": 67, "end_pos": 75, "type": "METRIC", "confidence": 0.999091386795044}, {"text": "precision", "start_pos": 101, "end_pos": 110, "type": "METRIC", "confidence": 0.9993195533752441}, {"text": "recall", "start_pos": 115, "end_pos": 121, "type": "METRIC", "confidence": 0.9989311099052429}]}, {"text": "In addition, the performance of the system was compared with the best systems(BEST) of.", "labels": [], "entities": [{"text": "BEST", "start_pos": 78, "end_pos": 82, "type": "METRIC", "confidence": 0.9959593415260315}]}, {"text": "The results of the best systems(BEST) in terms of sentence recall and sentence precision are provided by DUC-2002.", "labels": [], "entities": [{"text": "BEST", "start_pos": 32, "end_pos": 36, "type": "METRIC", "confidence": 0.9970265030860901}, {"text": "recall", "start_pos": 59, "end_pos": 65, "type": "METRIC", "confidence": 0.7613339424133301}, {"text": "precision", "start_pos": 79, "end_pos": 88, "type": "METRIC", "confidence": 0.9241799712181091}, {"text": "DUC-2002", "start_pos": 105, "end_pos": 113, "type": "DATASET", "confidence": 0.9701099991798401}]}, {"text": "Sentence recall and sentence precision of the candidate summary(produced by the proposed system) were calculated by using 400 word extract based summary(provided by DUC-2002) and a candidate summary.", "labels": [], "entities": [{"text": "recall", "start_pos": 9, "end_pos": 15, "type": "METRIC", "confidence": 0.5483897924423218}, {"text": "precision", "start_pos": 29, "end_pos": 38, "type": "METRIC", "confidence": 0.8870439529418945}, {"text": "DUC-2002", "start_pos": 165, "end_pos": 173, "type": "DATASET", "confidence": 0.9614483714103699}]}, {"text": "Sentence recall and sentence precision are defined as follows: where M is the number of the sentences included  As shown, the proposed system performs better than the best systems of DUC-2002 in terms of sentence recall.", "labels": [], "entities": [{"text": "Sentence recall", "start_pos": 0, "end_pos": 15, "type": "TASK", "confidence": 0.8638718724250793}, {"text": "precision", "start_pos": 29, "end_pos": 38, "type": "METRIC", "confidence": 0.9356168508529663}, {"text": "DUC-2002", "start_pos": 183, "end_pos": 191, "type": "DATASET", "confidence": 0.9093050956726074}, {"text": "sentence recall", "start_pos": 204, "end_pos": 219, "type": "TASK", "confidence": 0.6804207116365433}]}, {"text": "We are more interested in sentence recall because it states the ratio of the important sentences contained in the candidate summary if the sentences included in the 400E summary are supposed to be important ones.", "labels": [], "entities": [{"text": "sentence recall", "start_pos": 26, "end_pos": 41, "type": "TASK", "confidence": 0.7023633122444153}]}, {"text": "Furthermore, sentence precision is affected from the length of the candidate summary.", "labels": [], "entities": [{"text": "precision", "start_pos": 22, "end_pos": 31, "type": "METRIC", "confidence": 0.9614700675010681}]}, {"text": "Summarizing the text can be considered as the compression of the text.", "labels": [], "entities": []}, {"text": "Thus it is possible to depict the graph of dependence of distortion on rate).", "labels": [], "entities": [{"text": "distortion", "start_pos": 57, "end_pos": 67, "type": "METRIC", "confidence": 0.8053845167160034}]}, {"text": "The graph shows that as rate decreases distortion increases monotonically.", "labels": [], "entities": [{"text": "distortion", "start_pos": 39, "end_pos": 49, "type": "METRIC", "confidence": 0.9742534756660461}]}, {"text": "Therefore, if distortion is assumed to be the information loss oc-curred when the original text is summarized then the summaries of different quality can be produced by restricting rate (the number of sentences).", "labels": [], "entities": []}, {"text": "Another graph shows the change of the lambda value).", "labels": [], "entities": []}, {"text": "The iteration number of the pruning is on X axis and lambda value is on Y one.", "labels": [], "entities": []}, {"text": "If \u03bb value of the pruned points are sorted in ascending order and then the graph of ordered \u03bb values is depicted according to their order then the graph identical to the one shown below is obtained).", "labels": [], "entities": []}, {"text": "This indicates that the node with minimal lambda value is selected in each iteration.", "labels": [], "entities": []}, {"text": "Consequently, the sentences are eliminated so that increase in distortion is minimal for decrease in rate.", "labels": [], "entities": [{"text": "distortion", "start_pos": 63, "end_pos": 73, "type": "METRIC", "confidence": 0.7431145906448364}]}, {"text": "All in all, the quantitative analyses show that the proposed system can be used as one of the redundancy reduction methods.", "labels": [], "entities": [{"text": "redundancy reduction", "start_pos": 94, "end_pos": 114, "type": "TASK", "confidence": 0.8537040650844574}]}, {"text": "However, in order to achieve the good results, the parameters of BFOS algorithm have to beset appropriately.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: ROUGE-1 Results. Candidate sum- mary(produced by the proposed system) and 400E  summary provided by DUC 2002 are compared  with 200 word abstract created manually.", "labels": [], "entities": [{"text": "ROUGE-1", "start_pos": 10, "end_pos": 17, "type": "METRIC", "confidence": 0.9416541457176208}, {"text": "Candidate sum- mary", "start_pos": 27, "end_pos": 46, "type": "METRIC", "confidence": 0.7251554504036903}, {"text": "400E  summary", "start_pos": 84, "end_pos": 97, "type": "METRIC", "confidence": 0.8926840722560883}, {"text": "DUC 2002", "start_pos": 110, "end_pos": 118, "type": "DATASET", "confidence": 0.9528048038482666}]}, {"text": " Table 2: Results. The best systems of DUC-2002  results and the results of the proposed system. Pro- posed system is compared with 400 word extracts  provided by DUC-2002.", "labels": [], "entities": [{"text": "DUC-2002", "start_pos": 39, "end_pos": 47, "type": "DATASET", "confidence": 0.9331639409065247}, {"text": "DUC-2002", "start_pos": 163, "end_pos": 171, "type": "DATASET", "confidence": 0.971247136592865}]}]}