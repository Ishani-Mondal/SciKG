{"title": [{"text": "Descending-Path Convolution Kernel for Syntactic Structures", "labels": [], "entities": []}], "abstractContent": [{"text": "Convolution tree kernels are an efficient and effective method for comparing syntactic structures in NLP methods.", "labels": [], "entities": []}, {"text": "However, current kernel methods such as subset tree kernel and partial tree kernel understate the similarity of very similar tree structures.", "labels": [], "entities": []}, {"text": "Although soft-matching approaches can improve the similarity scores, they are corpus-dependent and match relaxations maybe task-specific.", "labels": [], "entities": []}, {"text": "We propose an alternative approach called descending path kernel which gives intuitive similarity scores on comparable structures.", "labels": [], "entities": []}, {"text": "This method is evaluated on two temporal relation extraction tasks and demonstrates its advantage over rich syntactic representations.", "labels": [], "entities": [{"text": "temporal relation extraction", "start_pos": 32, "end_pos": 60, "type": "TASK", "confidence": 0.6862123211224874}]}], "introductionContent": [{"text": "Syntactic structure can provide useful features for many natural language processing (NLP) tasks such as semantic role labeling, coreference resolution, temporal relation discovery, and others.", "labels": [], "entities": [{"text": "semantic role labeling", "start_pos": 105, "end_pos": 127, "type": "TASK", "confidence": 0.6768786708513895}, {"text": "coreference resolution", "start_pos": 129, "end_pos": 151, "type": "TASK", "confidence": 0.9407323002815247}, {"text": "temporal relation discovery", "start_pos": 153, "end_pos": 180, "type": "TASK", "confidence": 0.6336308419704437}]}, {"text": "However, the choice of features to be extracted from a tree fora given task is not always clear.", "labels": [], "entities": []}, {"text": "Convolution kernels over syntactic trees (tree kernels) offer a potential solution to this problem by providing relatively efficient algorithms for computing similarities between entire discrete structures.", "labels": [], "entities": []}, {"text": "These kernels use tree fragments as features and count the number of common fragments as a measure of similarity between any two trees.", "labels": [], "entities": []}, {"text": "However, conventional tree kernels are sensitive to pattern variations.", "labels": [], "entities": []}, {"text": "For example, two trees in Figure 1(a) sharing the same structure except for one terminal symbol are deemed at most 67% similar by the conventional tree kernel (PTK)).", "labels": [], "entities": []}, {"text": "Yet one might expect a higher similarity given their structural correspondence.", "labels": [], "entities": [{"text": "similarity", "start_pos": 30, "end_pos": 40, "type": "METRIC", "confidence": 0.9853020906448364}]}, {"text": "The similarity is further attenuated by trivial structure changes such as the insertion of an adjective in one of the trees in(a), which would reduce the similarity close to zero.", "labels": [], "entities": [{"text": "similarity", "start_pos": 4, "end_pos": 14, "type": "METRIC", "confidence": 0.9511442184448242}]}, {"text": "Such an abrupt attenuation would potentially propel a model to memorize training instances rather than generalize from trends, leading towards overfitting.", "labels": [], "entities": []}, {"text": "In this paper, we describe anew kernel over syntactic trees that operates on descending paths through the tree rather than production rules as used inmost existing methods.", "labels": [], "entities": []}, {"text": "This representation is reminiscent of leaf-ancestor paths for scoring parse similarities, but here it is generalized overall ancestor paths, not just those from the root to a leaf.", "labels": [], "entities": []}, {"text": "This approach assigns more robust similarity scores (e.g., 78% similarity in the above example) than other soft matching tree kernels, is faster than the partial tree kernel), and is less ad hoc than the grammar-based convolution kernel ().", "labels": [], "entities": []}], "datasetContent": [{"text": "We applied DPK to two published temporal relation extraction systems:) in the clinical domain and Cleartk-TimeML) in the general domain respectively.", "labels": [], "entities": [{"text": "temporal relation extraction", "start_pos": 32, "end_pos": 60, "type": "TASK", "confidence": 0.6682038307189941}, {"text": "Cleartk-TimeML", "start_pos": 98, "end_pos": 112, "type": "DATASET", "confidence": 0.6090294718742371}]}], "tableCaptions": [{"text": " Table 1: Comparison of the worst case computa- tional complexicity (\u03c1 -the maximum branching  factor) and kernel performance on the 3 examples  from", "labels": [], "entities": []}, {"text": " Table 2: Comparison of tree kernel performance  for temporal relation extraction on THYME and  TempEval-2013 data.", "labels": [], "entities": [{"text": "temporal relation extraction", "start_pos": 53, "end_pos": 81, "type": "TASK", "confidence": 0.609421581029892}, {"text": "THYME and  TempEval-2013 data", "start_pos": 85, "end_pos": 114, "type": "DATASET", "confidence": 0.7244022116065025}]}]}