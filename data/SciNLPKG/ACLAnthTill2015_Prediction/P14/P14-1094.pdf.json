{"title": [{"text": "Cross-narrative temporal ordering of medical events", "labels": [], "entities": [{"text": "Cross-narrative temporal ordering of medical events", "start_pos": 0, "end_pos": 51, "type": "TASK", "confidence": 0.757635181148847}]}], "abstractContent": [{"text": "Cross-narrative temporal ordering of medical events is essential to the task of generating a comprehensive timeline over a patient's history.", "labels": [], "entities": [{"text": "Cross-narrative temporal ordering of medical events", "start_pos": 0, "end_pos": 51, "type": "TASK", "confidence": 0.8081555366516113}]}, {"text": "We address the problem of aligning multiple medical event sequences , corresponding to different clinical narratives, comparing the following approaches: (1) A novel weighted finite state transducer representation of medical event sequences that enables composition and search for decoding, and (2) Dynamic programming with iterative pair-wise alignment of multiple sequences using global and local alignment algorithms.", "labels": [], "entities": []}, {"text": "The cross-narrative coreference and temporal relation weights used in both these approaches are learned from a corpus of clinical narratives.", "labels": [], "entities": []}, {"text": "We present results using both approaches and observe that the finite state transducer approach performs performs significantly better than the dynamic programming one by 6.8% for the problem of multiple-sequence alignment.", "labels": [], "entities": [{"text": "multiple-sequence alignment", "start_pos": 194, "end_pos": 221, "type": "TASK", "confidence": 0.7718073725700378}]}], "introductionContent": [{"text": "Discourse structure, logical flow of sentences, and context play a large part in ordering medical events based on temporal relations within a clinical narrative.", "labels": [], "entities": [{"text": "Discourse structure", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.7389722764492035}]}, {"text": "However, cross-narrative temporal relation ordering is a challenging task as it is difficult to learn temporal relations among medical events which are not part of the logically coherent discourse of a single narrative.", "labels": [], "entities": [{"text": "cross-narrative temporal relation ordering", "start_pos": 9, "end_pos": 51, "type": "TASK", "confidence": 0.7129531353712082}]}, {"text": "Resolving crossnarrative temporal relationships between medical events is essential to the task of generating an event timeline from across unstructured clinical narratives such as admission notes, radiology reports, history and physical reports and discharge summaries.", "labels": [], "entities": []}, {"text": "Such a timeline has multiple applications in clinical trial recruitment), medical document summarization ( and clinical decision making).", "labels": [], "entities": [{"text": "clinical trial recruitment", "start_pos": 45, "end_pos": 71, "type": "TASK", "confidence": 0.6391282379627228}, {"text": "medical document summarization", "start_pos": 74, "end_pos": 104, "type": "TASK", "confidence": 0.6786454916000366}, {"text": "clinical decision making", "start_pos": 111, "end_pos": 135, "type": "TASK", "confidence": 0.6428569356600443}]}, {"text": "Given multiple temporally ordered medical event sequences generated from each clinical narrative in a patient record, how can we combine the events to create a timeline across all the narratives?", "labels": [], "entities": []}, {"text": "The tendency to copy-paste text and summarize past information in newly generated clinical narratives leads to multiple mentions of the same medical event across narratives).", "labels": [], "entities": []}, {"text": "These cross-narrative coreferences act as important anchors for reasoning with information across narratives.", "labels": [], "entities": []}, {"text": "We leverage crossnarrative coreference information along with confident cross-narrative temporal relation predictions and learn to align and temporally order medical event sequences across longitudinal clinical narratives.", "labels": [], "entities": []}, {"text": "We model the problem as a sequence alignment task and propose solving this using two approaches.", "labels": [], "entities": [{"text": "sequence alignment task", "start_pos": 26, "end_pos": 49, "type": "TASK", "confidence": 0.7742018699645996}]}, {"text": "First, we use weighted finite state machines to represent medical events sequences, thus enabling composition and search to obtain the most probable combined sequence of medical events.", "labels": [], "entities": []}, {"text": "As a contrast, we adapt dynamic programming algorithms used to produce global and local alignments for aligning sequences of medical events across narratives.", "labels": [], "entities": []}, {"text": "We also compare the proposed methods with an Integer Linear Programming (ILP) based method for timeline construction ().", "labels": [], "entities": [{"text": "timeline construction", "start_pos": 95, "end_pos": 116, "type": "TASK", "confidence": 0.8654460310935974}]}, {"text": "The cross-narrative coreference and temporal relation scores used in both these approaches are learned from a corpus of patient narratives from The Ohio State University Wexner Medical Center.", "labels": [], "entities": [{"text": "Ohio State University Wexner Medical Center", "start_pos": 148, "end_pos": 191, "type": "DATASET", "confidence": 0.6705710391203562}]}, {"text": "The main contribution of this paper is a general framework that allows aligning multiple event sequences using cascaded weighted finite state transducers (WFSTs) with the help of efficient composition and decoding.", "labels": [], "entities": []}, {"text": "Moreover, we demonstrate that this method can be used for more accurate multiple sequence alignment when compared to dynamic programming or other ILP-based methods proposed in literature.", "labels": [], "entities": [{"text": "multiple sequence alignment", "start_pos": 72, "end_pos": 99, "type": "TASK", "confidence": 0.6115569770336151}]}], "datasetContent": [{"text": "The corpus consists of a dataset of clinical narratives obtained from the [redacted] medical center.", "labels": [], "entities": []}, {"text": "The corpus has a total of 2060 patients, and 100704 clinical narratives.", "labels": [], "entities": []}, {"text": "We gathered a gold standard set of seven patients (80 clinical narratives overall) with manual annotation of all medical events mentioned in the narratives, coreferences, and medical event sequence information.", "labels": [], "entities": []}, {"text": "The annotation agreement across annotators is high, with 89.5% agreement corresponding to inter-annotator Cohen's kappa statistic of 0.86 ().", "labels": [], "entities": [{"text": "annotation agreement", "start_pos": 4, "end_pos": 24, "type": "METRIC", "confidence": 0.9301891028881073}, {"text": "inter-annotator Cohen's kappa statistic", "start_pos": 90, "end_pos": 129, "type": "METRIC", "confidence": 0.7116653621196747}]}, {"text": "The types of clinical narratives included 27 discharge summaries, 30 history and physical reports, 15 radiology reports and 8 pathology reports.", "labels": [], "entities": []}, {"text": "The distribution of the number of medical event sequences and unique medical events across patients is shown in.", "labels": [], "entities": []}, {"text": "The annotated dataset is used to crossvalidate and train our coreference and temporal relation learning models and to evaluate our crossnarrative medical event timeline.: The distribution of medical events across narrative sequences and sequences across patients and multiple sequence alignment results for the WFST-based framework, and dynamic programming using just coreference scores and using coreference as well as temporal relation scores.", "labels": [], "entities": [{"text": "multiple sequence alignment", "start_pos": 267, "end_pos": 294, "type": "TASK", "confidence": 0.6883330146471659}, {"text": "WFST-based", "start_pos": 311, "end_pos": 321, "type": "DATASET", "confidence": 0.8851354122161865}]}, {"text": "For each patient and each method (WFST or dynamic programming), the output timeline to evaluate is the highest scoring candidate hypothesis derived as described above.", "labels": [], "entities": [{"text": "WFST", "start_pos": 34, "end_pos": 38, "type": "DATASET", "confidence": 0.8612483739852905}]}, {"text": "Accuracy of the timeline is calculated as the number of transformations required to obtain the reference sequence in the annotated gold-standard from the one generated by our system.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 0, "end_pos": 8, "type": "METRIC", "confidence": 0.9800476431846619}]}, {"text": "Transformations are measured in terms of the minimum edit distance, insertions, deletions, and substitutions of medical events.", "labels": [], "entities": [{"text": "Transformations", "start_pos": 0, "end_pos": 15, "type": "TASK", "confidence": 0.900964081287384}]}, {"text": "We first temporally order medical events within each clinical narrative by learning to rank them in relative order of occurence as described in our previous work).", "labels": [], "entities": []}, {"text": "The overall accuracy of ranking medical events using leave-one-out cross validation is 82.1%.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 12, "end_pos": 20, "type": "METRIC", "confidence": 0.9997780919075012}]}, {"text": "The resulting medical event sequences serve as the input to the problem of crossnarrative sequence alignment.", "labels": [], "entities": [{"text": "crossnarrative sequence alignment", "start_pos": 75, "end_pos": 108, "type": "TASK", "confidence": 0.8407248258590698}]}, {"text": "The cross-narrative coreference and temporal relation pairwise classification models described in Section 4 are trained using a Maximum entropy classifier.", "labels": [], "entities": [{"text": "temporal relation pairwise classification", "start_pos": 36, "end_pos": 77, "type": "TASK", "confidence": 0.6110565140843391}]}, {"text": "The coreference resolution performs with 71.5% precision and 82.3% recall.", "labels": [], "entities": [{"text": "precision", "start_pos": 47, "end_pos": 56, "type": "METRIC", "confidence": 0.99954754114151}, {"text": "recall", "start_pos": 67, "end_pos": 73, "type": "METRIC", "confidence": 0.999221920967102}]}, {"text": "The temporal relation classifier performs with 60.2% precision and 76.3% recall.", "labels": [], "entities": [{"text": "precision", "start_pos": 53, "end_pos": 62, "type": "METRIC", "confidence": 0.9995110034942627}, {"text": "recall", "start_pos": 73, "end_pos": 79, "type": "METRIC", "confidence": 0.9991551637649536}]}, {"text": "The learned pairwise coreference and temporal relation probabilities are now used to derive the score for the WFST and dynamic programming approaches.", "labels": [], "entities": [{"text": "WFST", "start_pos": 110, "end_pos": 114, "type": "DATASET", "confidence": 0.8481689691543579}]}, {"text": "We build finite-state machines using the open source OpenFST library.", "labels": [], "entities": [{"text": "OpenFST library", "start_pos": 53, "end_pos": 68, "type": "DATASET", "confidence": 0.9452008903026581}]}, {"text": "We use a tropical semi-ring weighted using the negative log-likelihood of the computed scores.", "labels": [], "entities": []}, {"text": "OpenFST provides tools that can search for the highest scoring sequences accepted by the machine, and can sample from highscoring sequences probabilistically, by treating the 2 www.openfst.org scores of each transition within the machine as a negative log probability.", "labels": [], "entities": [{"text": "OpenFST", "start_pos": 0, "end_pos": 7, "type": "DATASET", "confidence": 0.9472002387046814}]}, {"text": "The decoding process to compute the most likely combined medical event sequence can be defined as searching for the best path in the combined graph representation (Equation 2).", "labels": [], "entities": []}, {"text": "The best path is the one that minimizes the total weight on a path (since the arcs are negative log probabilities).", "labels": [], "entities": []}, {"text": "In searching for the best path, the beam size is set to 5.", "labels": [], "entities": []}, {"text": "The accuracy of the WFST-based representation and beam search across all sequences using the coreference and temporal relation scores to obtain the combined aligned sequence is 78.9%.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.9997072815895081}]}, {"text": "We use the NW and SW algorithms described in Section 5.3 to produce local and global alignments respectively.", "labels": [], "entities": []}, {"text": "We use the scoring scheme described in Section 5.1 to update the cost matrix for dynamic programming and implement the algorithms as described in Section 5.3.", "labels": [], "entities": []}, {"text": "The overall accuracy of sequence alignment with both coreference and temporal relation scores using NW is 68.7% whereas SW gives an accuracy of 72.1%.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 12, "end_pos": 20, "type": "METRIC", "confidence": 0.9995203018188477}, {"text": "sequence alignment", "start_pos": 24, "end_pos": 42, "type": "TASK", "confidence": 0.6844503581523895}, {"text": "accuracy", "start_pos": 132, "end_pos": 140, "type": "METRIC", "confidence": 0.9972461462020874}]}, {"text": "In case of aligning just two sequences, both methods yield the same results.", "labels": [], "entities": []}, {"text": "The accuracy of cross-narrative MSA for each patient, for each method, using cross validation, is shown in.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.9994179010391235}, {"text": "MSA", "start_pos": 32, "end_pos": 35, "type": "TASK", "confidence": 0.6753531098365784}]}, {"text": "Results indicate that the WFSTbased method outperforms the dynamic programming approach for multi-sequence alignment (statistical significance p<0.05).", "labels": [], "entities": [{"text": "WFSTbased", "start_pos": 26, "end_pos": 35, "type": "DATASET", "confidence": 0.6193300485610962}, {"text": "multi-sequence alignment", "start_pos": 92, "end_pos": 116, "type": "TASK", "confidence": 0.7447920739650726}]}, {"text": "Morever, the results using both coreference and temporal realtion scores for alignment outperform using only coreference scores for alignment using all approaches.", "labels": [], "entities": []}, {"text": "This indicates that cross-narrative temporal relations are important for accurately aligning medical event sequences across narratives.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: The distribution of medical events across narrative sequences and sequences across patients and  multiple sequence alignment results for the WFST-based framework, and dynamic programming using  just coreference scores", "labels": [], "entities": [{"text": "multiple sequence alignment", "start_pos": 107, "end_pos": 134, "type": "TASK", "confidence": 0.703945517539978}, {"text": "WFST-based", "start_pos": 151, "end_pos": 161, "type": "DATASET", "confidence": 0.8698417544364929}]}]}