{"title": [{"text": "A Unified Model for Soft Linguistic Reordering Constraints in Statistical Machine Translation", "labels": [], "entities": [{"text": "Soft Linguistic Reordering Constraints", "start_pos": 20, "end_pos": 58, "type": "TASK", "confidence": 0.6989123225212097}, {"text": "Statistical Machine Translation", "start_pos": 62, "end_pos": 93, "type": "TASK", "confidence": 0.6717272301514944}]}], "abstractContent": [{"text": "This paper explores a simple and effective unified framework for incorporating soft linguistic reordering constraints into a hierarchical phrase-based translation system: 1) a syntactic reordering model that explores reorderings for context free grammar rules; and 2) a semantic reordering model that focuses on the reordering of predicate-argument structures.", "labels": [], "entities": []}, {"text": "We develop novel features based on both models and use them as soft constraints to guide the translation process.", "labels": [], "entities": [{"text": "translation", "start_pos": 93, "end_pos": 104, "type": "TASK", "confidence": 0.9702308177947998}]}, {"text": "Experiments on Chinese-English translation show that the reordering approach can significantly improve a state-of-the-art hierarchical phrase-based translation system.", "labels": [], "entities": [{"text": "Chinese-English translation", "start_pos": 15, "end_pos": 42, "type": "TASK", "confidence": 0.6781103909015656}]}, {"text": "However, the gain achieved by the semantic reordering model is limited in the presence of the syntactic reordering model, and we therefore provide a detailed analysis of the behavior differences between the two.", "labels": [], "entities": []}], "introductionContent": [{"text": "Reordering models in statistical machine translation (SMT) model the word order difference when translating from one language to another.", "labels": [], "entities": [{"text": "statistical machine translation (SMT)", "start_pos": 21, "end_pos": 58, "type": "TASK", "confidence": 0.7784034808476766}]}, {"text": "The popular distortion or lexicalized reordering models in phrase-based SMT make good local predictions by focusing on reordering on word level, while the synchronous context free grammars in hierarchical phrase-based (HPB) translation models are capable of handling non-local reordering on the translation phrase level.", "labels": [], "entities": [{"text": "SMT", "start_pos": 72, "end_pos": 75, "type": "TASK", "confidence": 0.7100564241409302}]}, {"text": "However, reordering, especially without any help of external knowledge, remains a great challenge because an accurate reordering is usually beyond these word level or translation phrase level reordering models' ability.", "labels": [], "entities": []}, {"text": "In addition, often these translation models fail to respect linguistically-motivated syntax and semantics.", "labels": [], "entities": []}, {"text": "As a result, they tend to produce translations containing both syntactic and semantic reordering confusions.", "labels": [], "entities": []}, {"text": "In this paper our goal is to take advantage of syntactic and semantic parsing to improve translation quality.", "labels": [], "entities": [{"text": "semantic parsing", "start_pos": 61, "end_pos": 77, "type": "TASK", "confidence": 0.7277586162090302}, {"text": "translation", "start_pos": 89, "end_pos": 100, "type": "TASK", "confidence": 0.9617412090301514}]}, {"text": "Rather than introducing reordering models on either the word level or the translation phrase level, we propose a unified approach to modeling reordering on the linguistic unit level, e.g., syntactic constituents and semantic roles.", "labels": [], "entities": []}, {"text": "The reordering unit falls into multiple granularities, from single words to more complex constituents and semantic roles, and often crosses translation phrases.", "labels": [], "entities": []}, {"text": "To show the effectiveness of our reordering models, we integrate both syntactic constituent reordering models and semantic role reordering models into a state-ofthe-art HPB system.", "labels": [], "entities": []}, {"text": "We further contrast it with a stronger baseline, already including fine-grained soft syntactic constraint features).", "labels": [], "entities": []}, {"text": "The general ideas, however, are applicable to other translation models, e.g., phrase-based model, as well.", "labels": [], "entities": []}, {"text": "Our syntactic constituent reordering model considers context free grammar (CFG) rules in the source language and predicts the reordering of their elements on the target side, using word alignment information.", "labels": [], "entities": [{"text": "syntactic constituent reordering", "start_pos": 4, "end_pos": 36, "type": "TASK", "confidence": 0.6421746710936228}]}, {"text": "Due to the fact that a constituent, especially along one, usually maps into multiple discontinuous blocks in the target language, there is more than one way to describe the monotonicity or swapping patterns; we therefore design two reordering models: one is based on the leftmost aligned target word and the other based on the rightmost target word.", "labels": [], "entities": []}, {"text": "While recently there has also been some encouraging work on incorporating semantic structure (or, more specifically, predicate-argument structure: PAS) reordering in SMT, it is still an open question whether semantic structure reordering strongly overlaps with syntactic structure reordering, since the semantic structure is closely tied to syntax.", "labels": [], "entities": [{"text": "SMT", "start_pos": 166, "end_pos": 169, "type": "TASK", "confidence": 0.9397218227386475}, {"text": "syntactic structure reordering", "start_pos": 261, "end_pos": 291, "type": "TASK", "confidence": 0.6653161744276682}]}, {"text": "To this end, we employ the same reordering framework as syntactic constituent reordering and focus on semantic roles in a PAS.", "labels": [], "entities": []}, {"text": "We then analyze the differences between the syntactic and semantic features.", "labels": [], "entities": []}, {"text": "The contributions of this paper include the following: \u2022 We introduce novel soft reordering constraints, using syntactic constituents or semantic roles, composed over word alignment information in translation rules used during decoding time; \u2022 We introduce a unified framework to incorporate syntactic and semantic reordering constraints; \u2022 We provide a detailed analysis providing insight into why the semantic reordering model is significantly less effective when syntactic reordering features are also present.", "labels": [], "entities": []}, {"text": "The rest of the paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 provides an overview of HPB translation model.", "labels": [], "entities": [{"text": "HPB translation", "start_pos": 34, "end_pos": 49, "type": "TASK", "confidence": 0.6972948908805847}]}, {"text": "Section 3 describes the details of our unified reordering models.", "labels": [], "entities": []}, {"text": "Section 4 gives our experimental results and Section 5 discusses the behavior difference between syntactic constituent reordering and semantic role reordering.", "labels": [], "entities": [{"text": "syntactic constituent reordering", "start_pos": 97, "end_pos": 129, "type": "TASK", "confidence": 0.6304352283477783}, {"text": "semantic role reordering", "start_pos": 134, "end_pos": 158, "type": "TASK", "confidence": 0.6046863496303558}]}, {"text": "Section 6 reviews related work and, finally Section 7 concludes the paper.", "labels": [], "entities": []}], "datasetContent": [{"text": "We have presented our unified approach to incorporating syntactic and semantic soft reordering constraints in an HPB system.", "labels": [], "entities": []}, {"text": "In this section, we test its effectiveness in Chinese-English translation.", "labels": [], "entities": [{"text": "Chinese-English translation", "start_pos": 46, "end_pos": 73, "type": "TASK", "confidence": 0.643498569726944}]}, {"text": "For training we use 1.6M sentence pairs of the non-UN and non-HK Hansards portions of NIST MT training corpora, segmented with the Stanford segmenter ().", "labels": [], "entities": [{"text": "Hansards portions of NIST MT training corpora", "start_pos": 65, "end_pos": 110, "type": "DATASET", "confidence": 0.7536793947219849}]}, {"text": "The English data is lowercased, tokenized and aligned with GIZA++) to obtain bidirectional alignments, which are symmetrized using the grow-diag-final-and method ().", "labels": [], "entities": []}, {"text": "We train a 4-gram LM on the English side of the corpus with 600M additional words from non-NYT and non-LAT, randomly selected portions of the Gigaword v4 corpus, using modified Kneser-Ney smoothing.", "labels": [], "entities": [{"text": "Gigaword v4 corpus", "start_pos": 142, "end_pos": 160, "type": "DATASET", "confidence": 0.8844903906186422}]}, {"text": "We use the HPB decoder cdec, with Mr. Mira (, which is a k-best variant of MIRA (, to tune the parameters of the system.", "labels": [], "entities": [{"text": "HPB decoder cdec", "start_pos": 11, "end_pos": 27, "type": "DATASET", "confidence": 0.9617353479067484}, {"text": "MIRA", "start_pos": 75, "end_pos": 79, "type": "METRIC", "confidence": 0.9762253761291504}]}, {"text": "We use NIST MT 06 dataset (1664 sentence pairs) for tuning, and NIST MT 03, 05, and 08 datasets (919, 1082, and 1357 sentence pairs, respectively) for evaluation.", "labels": [], "entities": [{"text": "NIST MT 06 dataset", "start_pos": 7, "end_pos": 25, "type": "DATASET", "confidence": 0.8714694678783417}, {"text": "NIST MT 03", "start_pos": 64, "end_pos": 74, "type": "DATASET", "confidence": 0.8401669065157572}]}, {"text": "We use BLEU) for both tuning and evaluation.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 7, "end_pos": 11, "type": "METRIC", "confidence": 0.9987056255340576}]}, {"text": "To obtain syntactic parse trees and semantic roles on the tuning and test datasets, we first parse the source sentences with the Berkeley Parser (, trained on the Chinese Treebank 7.0 ().", "labels": [], "entities": [{"text": "Chinese Treebank 7.0", "start_pos": 163, "end_pos": 183, "type": "DATASET", "confidence": 0.9353775978088379}]}, {"text": "We then pass the parses to a Chinese semantic role labeler (, trained on the Chinese PropBank 3.0 (, to annotate semantic roles for all verbal predicates (partof-speech tag VV, VE, or VC).", "labels": [], "entities": []}, {"text": "Our basic baseline system employs 19 basic features: a language model feature, 7 translation model features, word penalty, unknown word penalty, the glue rule, date, number and 6 passthrough features.", "labels": [], "entities": []}, {"text": "Our stronger baseline employs, in addition, the fine-grained syntactic soft constraint features of , hereafter MR08.", "labels": [], "entities": [{"text": "MR08", "start_pos": 111, "end_pos": 115, "type": "DATASET", "confidence": 0.8607189059257507}]}, {"text": "The syntactic soft constraint features include both MR08 exact-matching and crossboundary constraints (denoted XP= and XP+).", "labels": [], "entities": [{"text": "MR08", "start_pos": 52, "end_pos": 56, "type": "DATASET", "confidence": 0.6491169333457947}]}, {"text": "Since the syntactic parses of the tuning and test data contain 29 types of constituent labels and 35 types of POS tags, we have 29 types of XP+ features and 64 types of XP= features.", "labels": [], "entities": []}, {"text": "Our first group of experiments investigates whether the syntactic reordering models are able to improve translation quality in terms of BLEU.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 136, "end_pos": 140, "type": "METRIC", "confidence": 0.9968007802963257}]}, {"text": "To this end, we respectively add our syntactic reordering models into both the baseline and MR08 systems.", "labels": [], "entities": [{"text": "MR08", "start_pos": 92, "end_pos": 96, "type": "DATASET", "confidence": 0.8245233297348022}]}, {"text": "The effect is shown in the rows of \"+ synreorder\" in.", "labels": [], "entities": []}, {"text": "From the table, we have the following two observations.", "labels": [], "entities": []}, {"text": "\u2022 Although the HPB model is capable of handling non-local phrase reordering using synchronous context free grammars, both our syntactic leftmost reordering model and rightmost model are still able to achieve improvement over both the baseline and MR08.", "labels": [], "entities": [{"text": "phrase reordering", "start_pos": 58, "end_pos": 75, "type": "TASK", "confidence": 0.7242373526096344}, {"text": "MR08", "start_pos": 247, "end_pos": 251, "type": "DATASET", "confidence": 0.9460272192955017}]}, {"text": "This suggests that our syntactic reordering features interact well with the MR08 syntactic soft constraints: the XP+ and XP= features focus on a single constituent each, while our reordering features focus on a pair of constituents each.", "labels": [], "entities": []}, {"text": "\u2022 There is no clear indication of whether the leftmost reordering model works better than the other.", "labels": [], "entities": []}, {"text": "In addition, integrating both the leftmost and rightmost reordering models has limited improvement over a single reordering model.", "labels": [], "entities": []}, {"text": "shown in the rows of \"+ sem-reorder\" in.", "labels": [], "entities": []}, {"text": "Here we observe: \u2022 The semantic reordering models also achieve significant gain of 0.8 BLEU on average over the baseline system, demonstrating the effectiveness of PAS-based reordering.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 87, "end_pos": 91, "type": "METRIC", "confidence": 0.9989425539970398}]}, {"text": "However, the gain diminishes to 0.3 BLEU on the MR08 system.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 36, "end_pos": 40, "type": "METRIC", "confidence": 0.9994321465492249}, {"text": "MR08 system", "start_pos": 48, "end_pos": 59, "type": "DATASET", "confidence": 0.927976667881012}]}, {"text": "\u2022 The syntactic reordering models outperform the semantic reordering models on both the baseline and MR08 systems.", "labels": [], "entities": [{"text": "MR08", "start_pos": 101, "end_pos": 105, "type": "DATASET", "confidence": 0.8999229073524475}]}, {"text": "Finally, we integrate both the syntactic and semantic reordering models into the final system.", "labels": [], "entities": []}, {"text": "The two models collectively achieve again of up to 1.4 BLEU over the baseline and 1.0 BLEU over MR08 on average, which is shown in the rows of \"+syn+sem\" in.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 55, "end_pos": 59, "type": "METRIC", "confidence": 0.9988781809806824}, {"text": "BLEU", "start_pos": 86, "end_pos": 90, "type": "METRIC", "confidence": 0.9989548921585083}, {"text": "MR08", "start_pos": 96, "end_pos": 100, "type": "DATASET", "confidence": 0.7692921161651611}]}], "tableCaptions": [{"text": " Table 3: Reordering type distribution over the re- ordering model's training data. Hereafter, l-m and  r-m are for leftmost and rightmost, respectively.", "labels": [], "entities": []}, {"text": " Table 4: Examples of the reordering distribution  (%) of gold alignment and the MR08 system out- put. For simplicity, we only focus on (M)onotone  and (S)wap based on leftmost reordering.", "labels": [], "entities": []}, {"text": " Table 5: System performance in BLEU scores.   \u2021/ \u2020: significant over baseline or MR08 at 0.01  / 0.05, respectively, as tested by bootstrap re- sampling", "labels": [], "entities": [{"text": "BLEU", "start_pos": 32, "end_pos": 36, "type": "METRIC", "confidence": 0.9917259216308594}, {"text": "MR08", "start_pos": 82, "end_pos": 86, "type": "METRIC", "confidence": 0.9893798232078552}]}, {"text": " Table 7: Reordering accuracy on four gold sets.", "labels": [], "entities": [{"text": "Reordering", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.6352039575576782}, {"text": "accuracy", "start_pos": 21, "end_pos": 29, "type": "METRIC", "confidence": 0.9172990322113037}]}, {"text": " Table 8: Reordering feature weights.", "labels": [], "entities": [{"text": "Reordering feature", "start_pos": 10, "end_pos": 28, "type": "TASK", "confidence": 0.8378801047801971}]}, {"text": " Table 9: Performance (BLEU score) comparison  between non-oracle and oracle experiments.", "labels": [], "entities": [{"text": "BLEU score)", "start_pos": 23, "end_pos": 34, "type": "METRIC", "confidence": 0.9307161172231039}]}]}