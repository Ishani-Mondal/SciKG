{"title": [{"text": "Detecting Retries of Voice Search Queries", "labels": [], "entities": [{"text": "Detecting Retries of Voice Search Queries", "start_pos": 0, "end_pos": 41, "type": "TASK", "confidence": 0.9095751245816549}]}], "abstractContent": [{"text": "When a system fails to correctly recognize a voice search query, the user will frequently retry the query, either by repeating it exactly or rephrasing it in an attempt to adapt to the system's failure.", "labels": [], "entities": []}, {"text": "It is desirable to be able to identify queries as retries both offline, as a valuable quality signal, and online, as contextual information that can aid recognition.", "labels": [], "entities": []}, {"text": "We present a method than can identify retries offline with 81% accuracy using similarity measures between two subsequent queries as well as system and user signals of recognition accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 63, "end_pos": 71, "type": "METRIC", "confidence": 0.9985617995262146}, {"text": "accuracy", "start_pos": 179, "end_pos": 187, "type": "METRIC", "confidence": 0.8984103798866272}]}, {"text": "The retry rate predicted by this method correlates significantly with a gold standard measure of accuracy, suggesting that it maybe useful as an offline predictor of accuracy.", "labels": [], "entities": [{"text": "retry rate", "start_pos": 4, "end_pos": 14, "type": "METRIC", "confidence": 0.8529976904392242}, {"text": "accuracy", "start_pos": 97, "end_pos": 105, "type": "METRIC", "confidence": 0.997936487197876}, {"text": "accuracy", "start_pos": 166, "end_pos": 174, "type": "METRIC", "confidence": 0.9945926070213318}]}], "introductionContent": [{"text": "With evermore capable smartphones connecting users to cloud-based computing, voice has been a rapidly growing modality for searching for information online.", "labels": [], "entities": []}, {"text": "Our voice search application connects a speech recognition service with a search engine, providing users with structured answers to questions, Web results, voice actions such as setting an alarm, and more.", "labels": [], "entities": []}, {"text": "In the multimodal smartphone interface, users can press a button to activate the microphone, and then speak the query when prompted by a beep; after receiving results, the microphone button is available if they wish to followup with a subsequent voice query.", "labels": [], "entities": []}, {"text": "Traditionally, the evaluation of speech recognition systems has been carried by preparing a test set of annotated utterances and comparing the accuracy of a system's transcripts of those utterances against the annotations.", "labels": [], "entities": [{"text": "evaluation of speech recognition", "start_pos": 19, "end_pos": 51, "type": "TASK", "confidence": 0.6502396464347839}, {"text": "accuracy", "start_pos": 143, "end_pos": 151, "type": "METRIC", "confidence": 0.9982649683952332}]}, {"text": "In particular, we seek to measure and minimize the word error rate (WER) of a system, with a WER of zero indicating perfect transcription.", "labels": [], "entities": [{"text": "word error rate (WER)", "start_pos": 51, "end_pos": 72, "type": "METRIC", "confidence": 0.887047161658605}, {"text": "WER", "start_pos": 93, "end_pos": 96, "type": "METRIC", "confidence": 0.9955306649208069}]}, {"text": "For voice search interfaces such as the present one, though, query-level metrics like WER only tell part of the story.", "labels": [], "entities": [{"text": "WER", "start_pos": 86, "end_pos": 89, "type": "METRIC", "confidence": 0.915542721748352}]}, {"text": "When a user issues two queries in a row, she might be seeking the same information fora second time due to a system failure the first time.", "labels": [], "entities": []}, {"text": "When this happens, from an evaluation standpoint it is helpful to breakdown why the first query was unsuccessful: it might be a speech recognition issue (in particular, a mistaken transcription), a search quality issue (where a correct transcript is interpreted incorrectly by the semantic understanding systems), a user interface issue, or another factor.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 128, "end_pos": 146, "type": "TASK", "confidence": 0.6911392658948898}]}, {"text": "As a second voice query may also be anew query or a follow-up query, as opposed to a retry of the first query, the detection of voice search retry pairs in the query steam is non-trivial.", "labels": [], "entities": []}, {"text": "Correctly identifying a retry situation in the query stream has two main benefits.", "labels": [], "entities": []}, {"text": "The first involves offline evaluation and monitoring.", "labels": [], "entities": []}, {"text": "We would like to know the rate at which users were forced to retry their voice queries, as a measure of quality.", "labels": [], "entities": []}, {"text": "The second has a more immediate benefit for individual users: if we can detect in real time that anew voice search is really a retry of a previous voice search, we can take immediate corrective action, such as reranking transcription hypotheses to avoid making the same mistake twice, or presenting alternative searches in the user interface to indicate that the system acknowledges it is having difficulty.", "labels": [], "entities": []}, {"text": "In this paper, we describe a method for the classification of subsequent voice searches as either retry pairs of a certain type, or non-retry pairs.", "labels": [], "entities": [{"text": "classification of subsequent voice searches", "start_pos": 44, "end_pos": 87, "type": "TASK", "confidence": 0.7138154745101929}]}, {"text": "We identify four salient types of retry pairs, describe a test set and identify the features we extracted to build an automatic classifier.", "labels": [], "entities": []}, {"text": "We then describe the models we used to build the classifier and their rel-ative performance on the task, and leave the issue of real-time corrective action to future work.", "labels": [], "entities": []}], "datasetContent": [{"text": "A logistic regression model was trained on these features to predict the collapsed binary categories of NO RETRY (search retry, other, no retry) vs. RETRY (rephrase, repetition).", "labels": [], "entities": [{"text": "NO", "start_pos": 104, "end_pos": 106, "type": "METRIC", "confidence": 0.9929823875427246}, {"text": "RETRY", "start_pos": 107, "end_pos": 112, "type": "METRIC", "confidence": 0.5214994549751282}, {"text": "RETRY", "start_pos": 149, "end_pos": 154, "type": "METRIC", "confidence": 0.9970658421516418}]}, {"text": "The results of running this model with each combination of the feature groups are shown in Individually, each feature group peformed significantly better than the baseline strategy of always predicting NO RETRY (62.4%).", "labels": [], "entities": [{"text": "NO", "start_pos": 202, "end_pos": 204, "type": "METRIC", "confidence": 0.8887957334518433}, {"text": "RETRY", "start_pos": 205, "end_pos": 210, "type": "METRIC", "confidence": 0.5126470923423767}]}, {"text": "Each pair of feature groups performed better than any individual group, and the final combination of all three feature groups had the highest precision, recall, and accuracy, suggesting that each aspect of the retry conceptualization provides valuable information to the model.", "labels": [], "entities": [{"text": "precision", "start_pos": 142, "end_pos": 151, "type": "METRIC", "confidence": 0.9994527697563171}, {"text": "recall", "start_pos": 153, "end_pos": 159, "type": "METRIC", "confidence": 0.9989006519317627}, {"text": "accuracy", "start_pos": 165, "end_pos": 173, "type": "METRIC", "confidence": 0.9995724558830261}, {"text": "retry conceptualization", "start_pos": 210, "end_pos": 233, "type": "TASK", "confidence": 0.8978738486766815}]}, {"text": "Of the similarity features, the ones that contributed significantly in the final model were character edit distance (normalized) and phoneme edit distance (raw and normalized); as expected, retries are associated with more similar query pairs.", "labels": [], "entities": []}, {"text": "Of the correctness features, high recognizer confidence, the presence of a positive reaction from the user such as a link click, and along interval between queries were all negatively associated with retries.", "labels": [], "entities": []}, {"text": "The significant recognizability features included length of the first query in characters (longer queries were less likely to be retried) and the number of capital letters in each query (as our LM is case-sensitive): queries transcribed with more capital letters were more likely to be retried, but less likely to themselves be retries.", "labels": [], "entities": [{"text": "length", "start_pos": 50, "end_pos": 56, "type": "METRIC", "confidence": 0.9790045022964478}]}, {"text": "In addition, the language model likelihood for the first query was, as expected, significantly lower for retries.", "labels": [], "entities": []}, {"text": "Interestingly, the score of the second query was lower for retries as well.", "labels": [], "entities": []}, {"text": "This accords with our finding that retries of misrecognized queries are themselves misrecognized 60%-70% of the time, which highlights the potential value of corrective action informed by the retry context.", "labels": [], "entities": []}, {"text": "Several features, though not significant in the model, are significantly different between the RETRY and NO RETRY categories, which affords us further insight into the characteristics of a retry.", "labels": [], "entities": [{"text": "RETRY", "start_pos": 95, "end_pos": 100, "type": "METRIC", "confidence": 0.9709644913673401}, {"text": "NO RETRY", "start_pos": 105, "end_pos": 113, "type": "METRIC", "confidence": 0.8388631641864777}]}, {"text": "T -tests between the two categories showed that all edit distance features-character, word, reduced, and phonetic; raw and normalized-are significantly more similar between retry query pairs.", "labels": [], "entities": [{"text": "T -", "start_pos": 0, "end_pos": 3, "type": "METRIC", "confidence": 0.9195380806922913}]}, {"text": "1 Similarly, the number of unigrams the two queries have in common is significantly higher for retries.", "labels": [], "entities": []}, {"text": "The duration of each member of the query pair, in seconds and word count, is significantly more similar between retry pairs, and each member of a retry pair tends to be shorter than members of a no retry pair.", "labels": [], "entities": []}, {"text": "Finally, members of NO RETRY query pairs were significantly more similar in speaking rate, and the relative speaking rate of the second query was significantly slower for RETRY pairs, possibly due to hyperarticulation.", "labels": [], "entities": []}, {"text": "shows a breakdown of the true granular labels versus the predicted binary labels.", "labels": [], "entities": []}, {"text": "The primary source of error is the REPHRASE category, which is identified as a retry with only 16.5% ac- curacy.", "labels": [], "entities": [{"text": "REPHRASE", "start_pos": 35, "end_pos": 43, "type": "METRIC", "confidence": 0.7863588333129883}]}, {"text": "This result reflects the fact that although rephrases conceptually belong in the retry category, their characteristics are materially different.", "labels": [], "entities": []}, {"text": "Most notably, all edit distance features are significantly greater for rephrases.", "labels": [], "entities": []}, {"text": "Differences in duration between the two queries in a pair, in seconds and words, are significantly greater as well.", "labels": [], "entities": [{"text": "duration", "start_pos": 15, "end_pos": 23, "type": "METRIC", "confidence": 0.9693477153778076}]}, {"text": "Rephrases also are significantly longer, in seconds and words, than strict retries.", "labels": [], "entities": [{"text": "Rephrases", "start_pos": 0, "end_pos": 9, "type": "METRIC", "confidence": 0.887421190738678}]}, {"text": "The model including only correctness and recognizability features does significantly better on rephrases than the full model, identifying them as retries with 25.6% accuracy, confirming that the similarity features are the primary culprit.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 165, "end_pos": 173, "type": "METRIC", "confidence": 0.9987402558326721}]}, {"text": "Future work may address this issue by including features crafted to examine the similarity between substrings of the two queries, rather than the query as a whole, and by expanding the similarity definition to include synonyms.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Results of the binary prediction task.", "labels": [], "entities": [{"text": "binary prediction task", "start_pos": 25, "end_pos": 47, "type": "TASK", "confidence": 0.7878503302733103}]}]}