{"title": [{"text": "Unsupervised Alignment of Privacy Policies using Hidden Markov Models", "labels": [], "entities": [{"text": "Unsupervised Alignment of Privacy Policies", "start_pos": 0, "end_pos": 42, "type": "TASK", "confidence": 0.793269944190979}]}], "abstractContent": [{"text": "To support empirical study of online privacy policies, as well as tools for users with privacy concerns, we consider the problem of aligning sections of a thousand policy documents, based on the issues they address.", "labels": [], "entities": []}, {"text": "We apply an unsupervised HMM; in two new (and reusable) evaluations, we find the approach more effective than clustering and topic models.", "labels": [], "entities": []}], "introductionContent": [{"text": "Privacy policy documents are verbose, often esoteric legal documents that many people encounter as clients of companies that provide services on the web.", "labels": [], "entities": []}, {"text": "showed that, if users were to read the privacy policies of every website they access during the course of a year, they would end up spending a substantial amount of their time doing just that and would often still not be able to answer basic questions about what these policies really say.", "labels": [], "entities": []}, {"text": "Unsurprisingly, many people do not read them.", "labels": [], "entities": []}, {"text": "Such policies therefore offer an excellent opportunity for NLP tools that summarize or extract key information that (i) helps users understand the implications of agreeing to these policies and (ii) helps legal analysts understand the contents of these policies and make recommendations on how they can be improved or made more clear.", "labels": [], "entities": [{"text": "summarize or extract key information", "start_pos": 74, "end_pos": 110, "type": "TASK", "confidence": 0.84835764169693}]}, {"text": "Past applications of NLP have sought to parse privacy policies into machine-readable representations () or extract subpolicies from larger documents (.", "labels": [], "entities": [{"text": "parse privacy policies", "start_pos": 40, "end_pos": 62, "type": "TASK", "confidence": 0.8813510735829672}]}, {"text": "Machine learning has been applied to assess certain attributes of policies (.", "labels": [], "entities": []}, {"text": "This paper instead analyzes policies in aggregate, seeking to align sections of policies.", "labels": [], "entities": []}, {"text": "This task is motivated by an expectation that many policies will address similar issues, 1 such as collection of a user's contact, location, health, and financial information, sharing with third parties, and deletion of data.", "labels": [], "entities": []}, {"text": "This expectation is supported by recommendation by privacy experts and policymakers; in the financial services sector, the Gramm-Leach-Bliley Act requires these institutions to address a specific set of issues.", "labels": [], "entities": []}, {"text": "Aligning policy sections is a first step toward our aforementioned summarization and extraction goals.", "labels": [], "entities": [{"text": "summarization and extraction", "start_pos": 67, "end_pos": 95, "type": "TASK", "confidence": 0.7375031014283498}]}, {"text": "We present the following contributions: \u2022 A new corpus of over 1,000 privacy policies gathered from widely used websites, manually segmented into subtitled sections by crowdworkers ( \u00a72).", "labels": [], "entities": []}, {"text": "\u2022 An unsupervised approach to aligning the policy sections based on the issues they discuss.", "labels": [], "entities": []}, {"text": "For example, sections that discuss \"user data on the company's server\" should be grouped together.", "labels": [], "entities": []}, {"text": "The approach is inspired by the application of hidden Markov models to sequence alignment in computational biology (.", "labels": [], "entities": [{"text": "sequence alignment", "start_pos": 71, "end_pos": 89, "type": "TASK", "confidence": 0.7252777814865112}]}, {"text": "\u2022 Two reusable evaluation benchmarks for the resulting alignment of policy sections ( \u00a74).", "labels": [], "entities": []}, {"text": "We demonstrate that our approach outperforms na\u00a8\u0131vena\u00a8\u0131ve methods ( \u00a75).", "labels": [], "entities": []}, {"text": "Our corpus and benchmarks are available at http://usableprivacy.org/data.", "labels": [], "entities": []}], "datasetContent": [{"text": "Developing a gold-standard alignment of privacy policies would either require an interface that allows each annotator to interact with the entire corpus of previously aligned documents while reading the one she is annotating, or the definition (and likely iterative refinement) of a set of categories for manually labeling policy sections.", "labels": [], "entities": []}, {"text": "These were too costly for us to consider, so we instead propose two generic methods to evaluate models for sequence alignment of a collection of documents with generally similar content.", "labels": [], "entities": []}, {"text": "Though our model (particularly the restricted variants) treats the problem as one of alignment, our evaluations consider groupings of policy sections.", "labels": [], "entities": []}, {"text": "In the sequel, a grouping on a set X is defined as a collection of subsets X i \u2286 X; these may overlap (i.e., there might be x \u2208 X i \u2229 X j ) and need not be exhaustive (i.e., there might be x \u2208 X \\ i X i ).", "labels": [], "entities": []}, {"text": "This study was carried out as part of a larger collaboration with legal scholars who study privacy.", "labels": [], "entities": []}, {"text": "In that work, we have formulated a set of nine multiple choice questions about a single policy that ask about collection of contact, location, health, and financial information, sharing of each with \u03b3(y t+1 | y t ): The likelihood function for the alignment model (one privacy policy).", "labels": [], "entities": []}, {"text": "yt is the hidden state for the tth section, ot is the bag of unigram and bigram terms observed in that section, and t is the size of the bag.", "labels": [], "entities": []}, {"text": "Start-state, emission, and transition distributions are denoted respectively by \u03c0, \u03b7, and \u03b3. yn+1 is the silent stopping state.", "labels": [], "entities": []}, {"text": "third parties, and deletion of data.", "labels": [], "entities": []}, {"text": "The questions were inspired primarily by the substantive interest of these domain experts-not by this particular algorithmic study.", "labels": [], "entities": []}, {"text": "For thirty policies, we obtained answers from each of six domain experts who were not involved in designing the questions.", "labels": [], "entities": []}, {"text": "For the purposes of this study, the experts' answers are not important.", "labels": [], "entities": []}, {"text": "In addition to answering each question for each policy, we also asked each expert to copy and paste the text of the policy that contains the answer.", "labels": [], "entities": []}, {"text": "Experts were allowed to select as many sections for each question as they saw fit, since answering some questions may require synthesizing information from different sections.", "labels": [], "entities": []}, {"text": "For each of the nine questions, we take the union of all policy sections that contain text selected by any annotator as support for her answer.", "labels": [], "entities": []}, {"text": "This results in nine groups of policy sections, which we call answer-sets denoted A 1 , . .", "labels": [], "entities": []}, {"text": ", A 9 . Our method allows these to overlap (63% of the sections in any A i occurred in more than one A i ), and they are not exhaustive (since many sections of the policies were not deemed to contain answers to any of the nine questions by any expert).", "labels": [], "entities": [{"text": "A", "start_pos": 2, "end_pos": 3, "type": "METRIC", "confidence": 0.8898144364356995}]}, {"text": "Together, these can be used as a gold standard grouping of policy sections, against which we can compare our system's output.", "labels": [], "entities": []}, {"text": "To do this, we define the set of section pairs that are grouped together in answer sets, G = |{{a, b | \u2203A i a, b}|, and a similar set of pairs H from a model's grouping.", "labels": [], "entities": []}, {"text": "From these sets, we calculate estimates of precision (|G \u2229 H|/|H|) and recall (|G \u2229 H|/|G|).", "labels": [], "entities": [{"text": "precision", "start_pos": 43, "end_pos": 52, "type": "METRIC", "confidence": 0.9995328187942505}, {"text": "recall", "start_pos": 71, "end_pos": 77, "type": "METRIC", "confidence": 0.9996896982192993}]}, {"text": "One shortcoming of this approach, for which the second evaluation seeks to compensate, is that a very small, and likely biased, subset of the policy sections is considered.", "labels": [], "entities": []}, {"text": "We created a separate gold standard of judgments of pairs of privacy policy sections.", "labels": [], "entities": []}, {"text": "The data selected for judgment was a sample of pairs stratified by a simple measure of text similarity.", "labels": [], "entities": []}, {"text": "We derived unigram tfidf vectors for each section in each of 50 randomly sampled policies per category.", "labels": [], "entities": []}, {"text": "We then binned pairs of sections by cosine similarity (into four bins bounded by 0.25, 0.5, and 0.75).", "labels": [], "entities": []}, {"text": "We sampled 994 section pairs uniformly across the 15 categories' four bins each.", "labels": [], "entities": []}, {"text": "Crowdsourcing was used to determine, for each pair, whether the two sections should be grouped together.", "labels": [], "entities": []}, {"text": "A HIT consisted of a pair of policy sections and a multiple choice question, \"After reading the two sections given below, would you say that they broadly discuss the same topic?\"", "labels": [], "entities": []}, {"text": "The possible answers were: 1.", "labels": [], "entities": []}, {"text": "Yes, both the sections essentially convey the same message in a privacy policy.", "labels": [], "entities": []}, {"text": "2. Although, the sections do not convey the same message, the broadly discuss the same topic.", "labels": [], "entities": []}, {"text": "(For ease of understanding, some examples of content on \"the same topic\" were included.)", "labels": [], "entities": []}, {"text": "3. No, the sections discuss two different topics.", "labels": [], "entities": []}, {"text": "The first two options were considered a \"yes\" for the majority voting and for defining a gold standard.", "labels": [], "entities": []}, {"text": "Every section-pair was annotated by at least three annotators (as many as 15, increased until an absolute majority was reached).", "labels": [], "entities": []}, {"text": "Turkers with an acceptance rate greater than 95% with an experience of at least 100 HITs were allowed and paid $0.03 per annotation.", "labels": [], "entities": [{"text": "acceptance rate", "start_pos": 16, "end_pos": 31, "type": "METRIC", "confidence": 0.9655459821224213}]}, {"text": "The total cost including some initial trials was $130.", "labels": [], "entities": []}, {"text": "535 out of the 994 pairs were annotated to be similar in topic.", "labels": [], "entities": []}, {"text": "An example is shown in.", "labels": [], "entities": []}, {"text": "As in \u00a74.1, we calculate precision and recall on pairs.", "labels": [], "entities": [{"text": "precision", "start_pos": 25, "end_pos": 34, "type": "METRIC", "confidence": 0.999235987663269}, {"text": "recall", "start_pos": 39, "end_pos": 45, "type": "METRIC", "confidence": 0.9993409514427185}]}, {"text": "This does not penalize the model for grouping together a \"no\" pair; we chose it nonetheless because it is interpretable.: Selections from sections that discuss the issue of \"deletion of personal information\" and were labeled as discussing the same issue by crowdworkers.", "labels": [], "entities": []}, {"text": "Both na\u00a8\u0131vena\u00a8\u0131ve grouping and LDA put them in two different groups, but the Strict Forward variant of our model correctly groups them together.", "labels": [], "entities": [{"text": "LDA", "start_pos": 31, "end_pos": 34, "type": "METRIC", "confidence": 0.950924277305603}]}], "tableCaptions": [{"text": " Table 2: Statistics of each website category, including (i) the number of websites with an identified privacy policy link; (ii)  number of unique privacy policies in each category (note that in rare cases, multiple unique privacy policies were identified  for the same website, e.g., a website that contains links to both new and old versions of its privacy policy); (iii) number of  websites with an identified privacy modification date; (iv) average number of sections per policy; (v) average number of tokens  per policy.", "labels": [], "entities": []}, {"text": " Table 3: Evaluation by human QA (above) and direct judg- ment (below), aggregated across ten independent runs where  appropriate (see text). Vanilla, All F(orward), and Strict  F(orward) are three variants of our HMM.", "labels": [], "entities": []}]}