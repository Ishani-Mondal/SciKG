{"title": [], "abstractContent": [{"text": "Most approaches to incremental parsing either incur a degradation of accuracy or they have to postpone decisions, yielding underspecified intermediate output.", "labels": [], "entities": [{"text": "incremental parsing", "start_pos": 19, "end_pos": 38, "type": "TASK", "confidence": 0.49743908643722534}, {"text": "accuracy", "start_pos": 69, "end_pos": 77, "type": "METRIC", "confidence": 0.9989838004112244}]}, {"text": "We present an incremental predictive dependency parser that is fast, accurate, and largely language independent.", "labels": [], "entities": [{"text": "predictive dependency parser", "start_pos": 26, "end_pos": 54, "type": "TASK", "confidence": 0.794069250424703}]}, {"text": "By extending a state-of-the-art dependency parser, connected analyses for sentence prefixes are obtained, which even predict properties and the structural embedding of upcoming words.", "labels": [], "entities": []}, {"text": "In contrast to other approaches, accuracy for complete sentence analyses does not decrease.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 33, "end_pos": 41, "type": "METRIC", "confidence": 0.9993839263916016}, {"text": "complete sentence analyses", "start_pos": 46, "end_pos": 72, "type": "TASK", "confidence": 0.5842864016691843}]}], "introductionContent": [{"text": "When humans communicate by means of a natural language, utterances are not produced at once but evolve overtime.", "labels": [], "entities": []}, {"text": "Human interaction benefits from this property by processing yet unfinished utterances and reacting on them.", "labels": [], "entities": []}, {"text": "Computational parsing on the other hand is mostly performed on complete sentences, a processing mode which renders a responsive interaction based on incomplete utterances impossible.", "labels": [], "entities": [{"text": "Computational parsing", "start_pos": 0, "end_pos": 21, "type": "TASK", "confidence": 0.7995636463165283}]}, {"text": "When spoken language is analyzed, a mismatch between speech recognition and parsing occurs: If parsing does notwork incrementally, the overall system loses all the desirable properties made possible by incremental processing.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 53, "end_pos": 71, "type": "TASK", "confidence": 0.7322286665439606}]}, {"text": "For speech dialogue systems, this leads to increased reaction times and an unnatural ping-pong style of interaction ().", "labels": [], "entities": []}], "datasetContent": [{"text": "The usual methods to determine the quality of a dependency parser -labeled and unlabeled attachment scores (AS) -are not sufficient for the evaluation of incremental parsers.", "labels": [], "entities": [{"text": "unlabeled attachment scores (AS)", "start_pos": 79, "end_pos": 111, "type": "METRIC", "confidence": 0.7973679353793462}]}, {"text": "If the AS is computed for whole sentences, all incremental output is discarded and not considered at all.", "labels": [], "entities": [{"text": "AS", "start_pos": 7, "end_pos": 9, "type": "METRIC", "confidence": 0.9391937255859375}]}, {"text": "If every intermediate PDA is used, words at the start of a sentence are counted more often than the ones at the end.", "labels": [], "entities": []}, {"text": "No information becomes available on how the accuracy of attachments evolves while parsing proceeds, and the prediction quality (i.e. the VNs) is completely ignored.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 44, "end_pos": 52, "type": "METRIC", "confidence": 0.9986925721168518}, {"text": "parsing", "start_pos": 82, "end_pos": 89, "type": "TASK", "confidence": 0.9582638144493103}]}, {"text": "Therefore, we adopt the enhanced mode of evaluation proposed by : In addition to the accuracy for whole sentences, the accuracies of then newest words of each analysis are computed.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 85, "end_pos": 93, "type": "METRIC", "confidence": 0.999421238899231}, {"text": "accuracies", "start_pos": 119, "end_pos": 129, "type": "METRIC", "confidence": 0.9695438742637634}]}, {"text": "This yields a curve that shows how good a word can be assumed to be attached depending on its distance to the most recent word.", "labels": [], "entities": []}, {"text": "Let V, G be the gold standard analysis of an increment and V , P the corresponding parser output.", "labels": [], "entities": []}, {"text": "V and V are the vertices and G and P the respective edges of the analyses.", "labels": [], "entities": []}, {"text": "Let V p and V v be the in-prefix and virtual subset of V , respectively.", "labels": [], "entities": []}, {"text": "To evaluate the prediction capabilities of a parser, for each increment an optimal partial, surjective mapping 1 V \u2192 V from the output produced by the parser to the (automatically generated) gold standard is computed, where each non-virtual element of V has to be mapped to the corresponding element in V . Let M be the set of all such mappings.", "labels": [], "entities": []}, {"text": "Then the best mapping is defined as follows: The mapping is partial because for some VNs in V there might be no corresponding VN in the gold standard.", "labels": [], "entities": []}, {"text": "We define a word was correctly attached (ignoring the label) if \u03c0(\u03c6 (w)) = \u03c6 (\u03c0(w)).", "labels": [], "entities": []}, {"text": "In an incremental analysis, an attachment of a word w can be classified into four cases: We can count the number of VNs that have been correctly attached: Let T be the set of all analyses produced by the parser and \u03c6 t the best mapping as defined above for each t \u2208 T . Furthermore, let vn(t) be the set of VNs int.", "labels": [], "entities": []}, {"text": "The total number of correct predictions of VNs is then defined as: Precision and recall for the prediction with VNs can be computed by dividing corr by the number of predicted VNs and the number of VNs in the gold standard, respectively.", "labels": [], "entities": [{"text": "Precision", "start_pos": 67, "end_pos": 76, "type": "METRIC", "confidence": 0.99857497215271}, {"text": "recall", "start_pos": 81, "end_pos": 87, "type": "METRIC", "confidence": 0.9992615580558777}]}, {"text": "Evaluation has been carried out on the PTB converted to dependency structure using the LTH converter () and on the Hamburg Dependency Treebank ().", "labels": [], "entities": [{"text": "PTB", "start_pos": 39, "end_pos": 42, "type": "DATASET", "confidence": 0.8419186472892761}, {"text": "LTH converter", "start_pos": 87, "end_pos": 100, "type": "DATASET", "confidence": 0.810118556022644}, {"text": "Hamburg Dependency Treebank", "start_pos": 115, "end_pos": 142, "type": "DATASET", "confidence": 0.9640762607256571}]}, {"text": "From both corpora predictive PDAs padded with unused virtual nodes have been created for training.", "labels": [], "entities": []}, {"text": "For English, the sentences of part 1-9 of the PTB were used, for German the first 50,000 sentences of the HDT have been selected.", "labels": [], "entities": [{"text": "PTB", "start_pos": 46, "end_pos": 49, "type": "DATASET", "confidence": 0.8346846103668213}]}, {"text": "Testing was done using one virtual noun and one virtual verb for English and two virtual nouns and one virtual verb for German because these sets cover about 90% of the prefixes in both training sets.", "labels": [], "entities": []}, {"text": "shows the evaluation results for parsing German and English using TurboParser.", "labels": [], "entities": [{"text": "parsing German and English", "start_pos": 33, "end_pos": 59, "type": "TASK", "confidence": 0.8686069399118423}]}, {"text": "For both languages the attachment accuracy rises with the amount of context available.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 34, "end_pos": 42, "type": "METRIC", "confidence": 0.9566985964775085}]}, {"text": "The difference between the attachment accuracy of the most recent word (relative time point 0, no word to the right of it) and the second newest word (time point 1) is strongest, especially for English.", "labels": [], "entities": [{"text": "attachment", "start_pos": 27, "end_pos": 37, "type": "METRIC", "confidence": 0.8676817417144775}, {"text": "accuracy", "start_pos": 38, "end_pos": 46, "type": "METRIC", "confidence": 0.5172535181045532}]}, {"text": "The word five elements left of the newest word (time point 5) gets attached with an accuracy that is nearly as high as the accuracy for the whole sentence (final).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 84, "end_pos": 92, "type": "METRIC", "confidence": 0.999313235282898}, {"text": "accuracy", "start_pos": 123, "end_pos": 131, "type": "METRIC", "confidence": 0.9987899661064148}]}, {"text": "The types of errors made for German and English are similar.", "labels": [], "entities": []}, {"text": "For both German and English the unlabeled precision reaches more than 70% (see).", "labels": [], "entities": [{"text": "precision", "start_pos": 42, "end_pos": 51, "type": "METRIC", "confidence": 0.9565680027008057}]}, {"text": "Even the correct dependency label of upcoming words can be predicted with a fairly high precision.", "labels": [], "entities": [{"text": "precision", "start_pos": 88, "end_pos": 97, "type": "METRIC", "confidence": 0.9904507994651794}]}, {"text": "TurboParser parses an increment in about 0.015 seconds, which is much faster than WCDG    . The prediction recall is higher for English than for German which could be due to the differences in gold-standard annotation.", "labels": [], "entities": [{"text": "TurboParser", "start_pos": 0, "end_pos": 11, "type": "DATASET", "confidence": 0.7026994228363037}, {"text": "parses", "start_pos": 12, "end_pos": 18, "type": "METRIC", "confidence": 0.8232126832008362}, {"text": "WCDG", "start_pos": 82, "end_pos": 86, "type": "DATASET", "confidence": 0.7988742589950562}, {"text": "prediction", "start_pos": 96, "end_pos": 106, "type": "METRIC", "confidence": 0.822153627872467}, {"text": "recall", "start_pos": 107, "end_pos": 113, "type": "METRIC", "confidence": 0.6932982206344604}]}, {"text": "Training TurboParser on the non-incremental data sets results in a labeled whole-sentence accuracy of 93.02% for German.The whole-sentence accuracy for parsing with VNs is 93.33%.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 90, "end_pos": 98, "type": "METRIC", "confidence": 0.8289093375205994}, {"text": "accuracy", "start_pos": 139, "end_pos": 147, "type": "METRIC", "confidence": 0.9198243021965027}, {"text": "parsing", "start_pos": 152, "end_pos": 159, "type": "TASK", "confidence": 0.9623219966888428}]}, {"text": "This shows that the additional mechanism of VNs has no negative effects on the overall parsing quality.", "labels": [], "entities": [{"text": "parsing", "start_pos": 87, "end_pos": 94, "type": "TASK", "confidence": 0.9686139822006226}]}, {"text": "To compare TurboParser and WCDG running both in the predictive incremental mode, we use jwcdg, the current implementation of this approach.", "labels": [], "entities": []}, {"text": "jwcdg differs from most other parsers in that it does not act on pre-tagged data but runs an external tagger itself in a multi-tag mode.", "labels": [], "entities": []}, {"text": "To compare both systems, TurboParser needs to be run in a tagger-parser pipeline.", "labels": [], "entities": []}, {"text": "We have chosen TurboTagger without look-ahead for this purpose.", "labels": [], "entities": [{"text": "TurboTagger", "start_pos": 15, "end_pos": 26, "type": "DATASET", "confidence": 0.9477846622467041}]}, {"text": "Running TurboParser in this pipeline leads to only slightly worse results compared to the use of gold-standard tags (see).", "labels": [], "entities": []}, {"text": "TurboParser's attachment accuracy is about ten percentage points better than jwcdg's across the board.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 25, "end_pos": 33, "type": "METRIC", "confidence": 0.9610646963119507}]}, {"text": "In addition, its VN prediction is considerably better.", "labels": [], "entities": [{"text": "VN prediction", "start_pos": 17, "end_pos": 30, "type": "METRIC", "confidence": 0.7571481466293335}]}, {"text": "To measure the stability, let P i be a prefix of the sentence P n and a i and an be the corresponding analyses produced by the parser.", "labels": [], "entities": []}, {"text": "An attachment of a word w \u2208 P i is stable if either w's head is the same in a i and an or w's head is not part of P i in both a i and an . The second part covers the case where the parser predicts the head of w to lie in the future and it really does, according to the final parse.", "labels": [], "entities": []}, {"text": "shows the attachment stability of the newest word at time point 0 compared to the word five positions to the left of time point 0.", "labels": [], "entities": []}, {"text": "TurboParser's stability turns out to be much higher than jwcdg's: For German  report a stability of only 80% at the most recent word.", "labels": [], "entities": [{"text": "TurboParser", "start_pos": 0, "end_pos": 11, "type": "DATASET", "confidence": 0.8730922341346741}]}, {"text": "Interestingly, labeling the newest attachment for English seems to be much harder than for German.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Precision and recall for the prediction of virtual nodes", "labels": [], "entities": [{"text": "Precision", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9916998147964478}, {"text": "recall", "start_pos": 24, "end_pos": 30, "type": "METRIC", "confidence": 0.9988786578178406}]}]}