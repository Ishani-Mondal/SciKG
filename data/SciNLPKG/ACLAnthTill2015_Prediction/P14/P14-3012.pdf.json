{"title": [{"text": "Improving Text Normalization via Unsupervised Model and Discriminative Reranking", "labels": [], "entities": [{"text": "Improving Text Normalization", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.8985803325970968}]}], "abstractContent": [{"text": "Various models have been developed for normalizing informal text.", "labels": [], "entities": [{"text": "normalizing informal text", "start_pos": 39, "end_pos": 64, "type": "TASK", "confidence": 0.8841464519500732}]}, {"text": "In this paper, we propose two methods to improve nor-malization performance.", "labels": [], "entities": []}, {"text": "First is an unsu-pervised approach that automatically identifies pairs of a non-standard token and proper word from a large unlabeled corpus.", "labels": [], "entities": []}, {"text": "We use semantic similarity based on continuous word vector representation, together with other surface similarity measurement.", "labels": [], "entities": []}, {"text": "Second we propose a reranking strategy to combine the results from different systems.", "labels": [], "entities": []}, {"text": "This allows us to incorporate information that is hard to model in individual systems as well as consider multiple systems to generate a final rank fora test case.", "labels": [], "entities": []}, {"text": "Both word-and sentence-level optimization schemes are explored in this study.", "labels": [], "entities": [{"text": "word-and sentence-level optimization", "start_pos": 5, "end_pos": 41, "type": "TASK", "confidence": 0.5970674852530161}]}, {"text": "We evaluate our approach on data sets used in prior studies, and demonstrate that our proposed methods perform better than the state-of-the-art systems.", "labels": [], "entities": []}], "introductionContent": [{"text": "There has been a lot of research efforts recently on analysis of social media text (e.g., from Twitter and Facebook) ().", "labels": [], "entities": []}, {"text": "One challenge in processing social media text is how to deal with the frequently occurring non-standard words, such as bday (meaning birthday), snd (meaning sound) and gl (meaning girl) . Normalizing informal text (changing non-standard words to standard ones) will ease subsequent language processing modules.", "labels": [], "entities": []}, {"text": "Text normalization has been an important topic for the text-to-speech field.", "labels": [], "entities": [{"text": "Text normalization", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.8428581357002258}]}, {"text": "See () fora good report of this problem.", "labels": [], "entities": []}, {"text": "Recently, much research on normalization has been done for social text domain, which has many abbreviations or non-standard tokens.", "labels": [], "entities": [{"text": "normalization", "start_pos": 27, "end_pos": 40, "type": "TASK", "confidence": 0.9695003032684326}]}, {"text": "A simple approach for normalization would be applying traditional spell checking model, which is usually based on edit distance.", "labels": [], "entities": [{"text": "spell checking", "start_pos": 66, "end_pos": 80, "type": "TASK", "confidence": 0.7638556659221649}]}, {"text": "However, this model cannot well handle the nonstandard words in social media text due to the large variation in generating them.", "labels": [], "entities": []}, {"text": "Another line of work in normalization adopts a noisy channel model.", "labels": [], "entities": [{"text": "normalization", "start_pos": 24, "end_pos": 37, "type": "TASK", "confidence": 0.983144998550415}]}, {"text": "For a non-standard token A, this method finds the most possible standard word\u02c6Sword\u02c6 word\u02c6S based on the Bayes rule: \u02c6 S = argmaxP (S|A) = argmaxP (A|S) * P (S).", "labels": [], "entities": []}, {"text": "Different methods have been used to compute P (A|S).", "labels": [], "entities": []}, {"text": "Pennell and used a CRF sequence modeling approach for deletion-based abbreviations.", "labels": [], "entities": [{"text": "Pennell", "start_pos": 0, "end_pos": 7, "type": "DATASET", "confidence": 0.946198582649231}, {"text": "CRF sequence modeling", "start_pos": 19, "end_pos": 40, "type": "TASK", "confidence": 0.7049992084503174}]}, {"text": "further extended this work by considering more types of non-standard words without explicit pre-categorization for nonstandard tokens.", "labels": [], "entities": []}, {"text": "In addition, the noisy channel model has also been utilized on the sentence level.", "labels": [], "entities": []}, {"text": "used a hidden Markov model to simulate SMS message generation, considering the non-standard tokens in the input sentence as emission states in HMM and labeling results as possible candidates.", "labels": [], "entities": [{"text": "SMS message generation", "start_pos": 39, "end_pos": 61, "type": "TASK", "confidence": 0.8658807476361593}]}, {"text": "extended work by adding several more subsystems in this error model according to the most common non-standard token's formation process.", "labels": [], "entities": []}, {"text": "Machine translation (MT) is another commonly chosen method for text normalization.", "labels": [], "entities": [{"text": "Machine translation (MT)", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.8878240942955017}, {"text": "text normalization", "start_pos": 63, "end_pos": 81, "type": "TASK", "confidence": 0.8001313507556915}]}, {"text": "It is also used on both the token and the sentence level.", "labels": [], "entities": []}, {"text": "treated SMS as another language, and used MT methods to translate this 'foreign language' to regular English.", "labels": [], "entities": [{"text": "MT", "start_pos": 42, "end_pos": 44, "type": "TASK", "confidence": 0.8450008034706116}]}, {"text": "used an MT model as well but the focus of their work is to utilize an unsupervised method to clean noisy text.", "labels": [], "entities": [{"text": "MT", "start_pos": 8, "end_pos": 10, "type": "TASK", "confidence": 0.9005848169326782}]}, {"text": "Pennell and Liu (2011) firstly introduced an MT method at the token level which translates an unnormalized token to a possible cor-rect word.", "labels": [], "entities": [{"text": "MT", "start_pos": 45, "end_pos": 47, "type": "TASK", "confidence": 0.9904735684394836}]}, {"text": "Recently, anew line of work surges relying on the analysis of huge amount of twitter data, often in an unsupervised fashion.", "labels": [], "entities": []}, {"text": "By using context information from a large corpus, generated possible variant and normalization pairs, and constructed a dictionary of lexical variants of known words, which are further ranked by string similarity.", "labels": [], "entities": []}, {"text": "This dictionary can facilitate lexical normalization via simple string substitution.", "labels": [], "entities": []}, {"text": "proposed an approach based on the random walk algorithm on a contextual similarity bipartite graph, constructed from n-gram sequences on a large unlabeled text corpus.", "labels": [], "entities": []}, {"text": "presented a unified unsupervised statistical model for text normalization.", "labels": [], "entities": [{"text": "text normalization", "start_pos": 55, "end_pos": 73, "type": "TASK", "confidence": 0.824393093585968}]}], "datasetContent": [{"text": "The following data sets are used in our experiments.", "labels": [], "entities": []}, {"text": "We use Data 1 and Data 2 as test data, and Data 3 as training data for all the supervised models.", "labels": [], "entities": []}, {"text": "\u2022 Data 1: 558 pairs of non-standard tokens and standard words collected from 549 tweets in 2010 by).", "labels": [], "entities": []}, {"text": "\u2022 Data 2: 3,962 pairs of non-standard tokens and standard words collected from 6,160 tweets between 2009 and 2010 by (Liu et al., 2011).", "labels": [], "entities": []}, {"text": "\u2022 Data 3: 2,333 unique pairs of non-standard tokens and standard words, collected from 2,577 Twitter messages (selected from the Edinburgh Twitter corpus) used in (Pennell and Liu, 2011).", "labels": [], "entities": [{"text": "Edinburgh Twitter corpus", "start_pos": 129, "end_pos": 153, "type": "DATASET", "confidence": 0.9800313512484232}]}, {"text": "We made some changes on this data, removing the pairs that have more than one proper words, and sentences that only contain such pairs.", "labels": [], "entities": []}, {"text": "3 \u2022 Data 4: About 10 million twitter messages selected from the the Edinburgh Twitter corpus mentioned above, consisting of 3 million unique tokens.", "labels": [], "entities": [{"text": "Edinburgh Twitter corpus", "start_pos": 68, "end_pos": 92, "type": "DATASET", "confidence": 0.9808906118075053}]}, {"text": "This data is used by the unsupervised method to create the mapping table, and also for building the word-based language model needed in sentence level normalization.", "labels": [], "entities": [{"text": "sentence level normalization", "start_pos": 136, "end_pos": 164, "type": "TASK", "confidence": 0.6346257030963898}]}, {"text": "The dictionary we used is obtained from http://ciba.iciba.com/, which includes 75,262 English word entries and their corresponding phonetic symbols (IPA symbols).", "labels": [], "entities": []}, {"text": "This is used in various modules in the normalization systems.", "labels": [], "entities": [{"text": "normalization", "start_pos": 39, "end_pos": 52, "type": "TASK", "confidence": 0.9788103103637695}]}, {"text": "The number of the final standard words used to create the look-up table is 10,105 because we only use the words that have the same number of characterblock segments and phones.", "labels": [], "entities": []}, {"text": "These 10,105 words cover 90.77% and 93.74% standard words in Data set 1 and Data set 2 respectively.", "labels": [], "entities": [{"text": "Data set 1", "start_pos": 61, "end_pos": 71, "type": "DATASET", "confidence": 0.9553922613461813}, {"text": "Data set 2", "start_pos": 76, "end_pos": 86, "type": "DATASET", "confidence": 0.8537285923957825}]}, {"text": "For the nonstandard words created in the CRF model, they cover 80.47% and 86.47% non-standard words in Data set1 and Data set 2.", "labels": [], "entities": []}, {"text": "This coverage using the non-standard words identified by the new unsupervised model is 91.99% and 92.32% for the two data sets, higher than that by the CRF model.", "labels": [], "entities": [{"text": "coverage", "start_pos": 5, "end_pos": 13, "type": "METRIC", "confidence": 0.9701664447784424}]}, {"text": "During experiments, we use CRF++ toolkit 4 for our sequence labeling model, SRILM toolkit) to build all the language models, Giza++ (Och and Ney, 2003) for automatic word alignment, and Moses () for translation decoding in three MT systems.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 166, "end_pos": 180, "type": "TASK", "confidence": 0.7051070481538773}, {"text": "translation decoding", "start_pos": 199, "end_pos": 219, "type": "TASK", "confidence": 0.9544335901737213}]}, {"text": "shows the isolated word normalization results on the two test data sets for various systems.", "labels": [], "entities": []}, {"text": "The performance metrics include the accuracy for the top-1 candidate and other top-N candidates.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 36, "end_pos": 44, "type": "METRIC", "confidence": 0.9995250701904297}]}, {"text": "Coverage means how many test cases correct answers can be obtained in the final list regardless of its positions.", "labels": [], "entities": [{"text": "Coverage", "start_pos": 0, "end_pos": 8, "type": "METRIC", "confidence": 0.9785471558570862}]}, {"text": "The top part presents the results on Data Set 1 and the bottom shows the results on Data Set 2.", "labels": [], "entities": [{"text": "Data Set 1", "start_pos": 37, "end_pos": 47, "type": "DATASET", "confidence": 0.9583320021629333}, {"text": "Data Set 2", "start_pos": 84, "end_pos": 94, "type": "DATASET", "confidence": 0.9602634310722351}]}, {"text": "We can see that our proposed unsupervised corpus similarity model achieves better top-1 accuracy than the other individual systems described in Section 2.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 88, "end_pos": 96, "type": "METRIC", "confidence": 0.9872616529464722}]}, {"text": "Its top-n coverage is not always the best -the 2-step MT method has advantages in its coverage.", "labels": [], "entities": [{"text": "MT", "start_pos": 54, "end_pos": 56, "type": "TASK", "confidence": 0.9708734750747681}]}, {"text": "The results in the table also show that reranking improves system performance over any of the used individual systems, which is expected.", "labels": [], "entities": []}, {"text": "After reranking, on Data set 1, our system yields better performance than previously reported ones.", "labels": [], "entities": [{"text": "Data set 1", "start_pos": 20, "end_pos": 30, "type": "DATASET", "confidence": 0.9386386473973592}]}, {"text": "On Data set 2, it has better top-1 accuracy than ( ), but slightly worse top-N coverage.", "labels": [], "entities": [{"text": "Data set 2", "start_pos": 3, "end_pos": 13, "type": "DATASET", "confidence": 0.9390714764595032}, {"text": "accuracy", "start_pos": 35, "end_pos": 43, "type": "METRIC", "confidence": 0.9817402362823486}]}, {"text": "However, the method in ( ) has higher computational cost because of the calculation of the prime visual values for each non-standard word on the fly during testing.", "labels": [], "entities": []}, {"text": "In addition, they also used more training data than ours.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2:  MT: Character-block Level MT;  MT21&MT22: First&Second step in Character- level Two-step MT; SL: Sequence Labeling sys- tem; SC: Spell Checker; UCS: Unsupervised Cor- pus Similarity Model; Sys1 is from (Liu et al.,  2012a); Sys2 is from (Li and Liu, 2012a); Sys3  is from", "labels": [], "entities": [{"text": "MT", "start_pos": 11, "end_pos": 13, "type": "TASK", "confidence": 0.8613789081573486}, {"text": "Sequence Labeling sys", "start_pos": 108, "end_pos": 129, "type": "TASK", "confidence": 0.7451020975907644}]}, {"text": " Table 3: Sentence level normalization results on  Data Set 1 using different reranking setups. Sys1  is from (Liu et al., 2012a); Sys2 is from (Yang", "labels": [], "entities": [{"text": "Sentence level normalization", "start_pos": 10, "end_pos": 38, "type": "TASK", "confidence": 0.8506466348965963}]}, {"text": " Table 4: Word level and Sentence level normaliza- tion results (top-1 accuracy in %) after reranking  on Data Set 1 and 2. System-A is without using  the unsupervised model, system-B is without its  semantic similarity measure, and system-C is our  proposed system.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 71, "end_pos": 79, "type": "METRIC", "confidence": 0.9728606939315796}]}]}