{"title": [{"text": "Sliding Alignment Windows for Real-Time Crowd Captioning", "labels": [], "entities": [{"text": "Sliding Alignment", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.9021389484405518}, {"text": "Real-Time Crowd Captioning", "start_pos": 30, "end_pos": 56, "type": "TASK", "confidence": 0.6240449150403341}]}], "abstractContent": [{"text": "The primary way of providing real-time speech to text captioning for hard of hearing people is to employ expensive professional stenographers who can type as fast as natural speaking rates.", "labels": [], "entities": [{"text": "real-time speech to text captioning", "start_pos": 29, "end_pos": 64, "type": "TASK", "confidence": 0.6550338566303253}]}, {"text": "Recent work has shown that a feasible alternative is to combine the partial captions of ordinary typists , each of whom is able to type only part of what they hear.", "labels": [], "entities": []}, {"text": "In this paper, we extend the state of the art fixed-window alignment algorithm (Naim et al., 2013) for combining the individual captions into a final output sequence.", "labels": [], "entities": [{"text": "fixed-window alignment", "start_pos": 46, "end_pos": 68, "type": "TASK", "confidence": 0.7169598937034607}]}, {"text": "Our method performs alignment on a sliding window of the input sequences, drastically reducing both the number of errors and the latency of the system to the end user over the previously published approaches.", "labels": [], "entities": []}], "introductionContent": [{"text": "Real-time captioning provides deaf or hard of hearing people access to speech in mainstream classrooms, at public events, and on live television.", "labels": [], "entities": [{"text": "Real-time captioning", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.8190539181232452}]}, {"text": "Studies performed in the classroom setting show that the latency between when a word was said and when it is displayed must be under five seconds to maintain consistency between the captions being read and other visual cues).", "labels": [], "entities": [{"text": "consistency", "start_pos": 158, "end_pos": 169, "type": "METRIC", "confidence": 0.9581831693649292}]}, {"text": "The most common approach to real-time captioning is to recruit a trained stenographer with a special purpose phonetic keyboard, who transcribes the speech to text with less than five seconds of latency.", "labels": [], "entities": [{"text": "real-time captioning", "start_pos": 28, "end_pos": 48, "type": "TASK", "confidence": 0.7060808539390564}]}, {"text": "Unfortunately, professional captionists are quite expensive ($150 per hour), must be recruited in blocks of an hour or more, and are difficult to schedule on short: General layout of crowd captioning systems.", "labels": [], "entities": [{"text": "crowd captioning", "start_pos": 183, "end_pos": 199, "type": "TASK", "confidence": 0.7257866263389587}]}, {"text": "Captionists (C1, C2, C3) submit partial captions that are automatically combined into a highquality output. notice.", "labels": [], "entities": []}, {"text": "Automatic speech recognition (ASR) systems (), on the other hand, attempts to provide a cheap and fully automated solution to this problem.", "labels": [], "entities": [{"text": "Automatic speech recognition (ASR)", "start_pos": 0, "end_pos": 34, "type": "TASK", "confidence": 0.8226036330064138}]}, {"text": "However, the accuracy of ASR quickly plummets to below 30% when used on an untrained speaker's voice, in anew environment, or in the absence of a high quality microphone).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 13, "end_pos": 21, "type": "METRIC", "confidence": 0.9997518658638}, {"text": "ASR", "start_pos": 25, "end_pos": 28, "type": "TASK", "confidence": 0.9617710113525391}]}, {"text": "The accuracy of the ASR systems can be improved using the 're-speaking' technique, which requires a person that the ASR has been trained onto repeat the words said by a speaker as he hears them.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.9990843534469604}, {"text": "ASR", "start_pos": 20, "end_pos": 23, "type": "TASK", "confidence": 0.9768010377883911}]}, {"text": "Simultaneously hearing and speaking, however, is not straightforward, and requires some training.", "labels": [], "entities": []}, {"text": "An alternative approach is to combine the efforts of multiple non-expert captionists (anyone who can type), instead of relying on trained workers (.", "labels": [], "entities": []}, {"text": "In this approach, multiple non-expert human workers transcribe an audio stream containing speech in real-time.", "labels": [], "entities": []}, {"text": "Workers type as much as they can of the input, and, while no one worker's transcript is complete, the portions captured by various workers tend to overlap.", "labels": [], "entities": []}, {"text": "For each input word, a timestamp is recorded, indicating when the word is typed by a worker.", "labels": [], "entities": []}, {"text": "The partial inputs are combined to produce a final transcript (see).", "labels": [], "entities": []}, {"text": "This approach has been shown to dramatically outperform ASR in terms of both accuracy and Word Error Rate (WER) ().", "labels": [], "entities": [{"text": "ASR", "start_pos": 56, "end_pos": 59, "type": "TASK", "confidence": 0.9572778940200806}, {"text": "accuracy", "start_pos": 77, "end_pos": 85, "type": "METRIC", "confidence": 0.9996110796928406}, {"text": "Word Error Rate (WER)", "start_pos": 90, "end_pos": 111, "type": "METRIC", "confidence": 0.9237460792064667}]}, {"text": "Furthermore, recall of individual words irrespective of their order approached and even exceeded that of a trained expert stenographer with seven workers contributing, suggesting that the information is present to meet the performance of a stenographer ().", "labels": [], "entities": [{"text": "recall", "start_pos": 13, "end_pos": 19, "type": "METRIC", "confidence": 0.9919369220733643}]}, {"text": "However, aligning these individual words in the correct sequential order remains a challenging problem.", "labels": [], "entities": []}, {"text": "addressed this alignment problem using off-the-shelf multiple sequence alignment tools, as well as an algorithm based on incrementally building a precedence graph over output words.", "labels": [], "entities": [{"text": "multiple sequence alignment", "start_pos": 53, "end_pos": 80, "type": "TASK", "confidence": 0.6774405042330424}]}, {"text": "Improved results for the alignment problem were shown using weighted A * search by.", "labels": [], "entities": [{"text": "alignment", "start_pos": 25, "end_pos": 34, "type": "TASK", "confidence": 0.9706935286521912}]}, {"text": "To speed the search for the best alignment, divided sequences into chunks of a fixed time duration, and applied the A * alignment algorithm to each chunk independently.", "labels": [], "entities": [{"text": "A * alignment algorithm", "start_pos": 116, "end_pos": 139, "type": "METRIC", "confidence": 0.8670694828033447}]}, {"text": "Although this method speeds the search for the best alignment, it introduces a significant number of errors to the output of the system due to inconsistency at the boundaries of the chunks.", "labels": [], "entities": []}, {"text": "In this paper, we introduce a novel sliding window technique which avoids the errors produced by previous systems at the boundaries of the chunks used for alignment.", "labels": [], "entities": []}, {"text": "This technique produces dramatically fewer errors for the same amount of computation time.", "labels": [], "entities": []}], "datasetContent": [{"text": "We evaluate our system on a dataset of four 5-minute long audio clips of lectures in electrical engineering and chemistry lectures taken from MIT OpenCourseWare.", "labels": [], "entities": []}, {"text": "The same dataset used by and.", "labels": [], "entities": []}, {"text": "Each audio clip is transcribed by 10 non-expert human workers in real time.", "labels": [], "entities": []}, {"text": "We measure the accuracy in terms of Word Error Rate (WER) with respect to a reference transcription.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 15, "end_pos": 23, "type": "METRIC", "confidence": 0.999618649482727}, {"text": "Word Error Rate (WER)", "start_pos": 36, "end_pos": 57, "type": "METRIC", "confidence": 0.9197468757629395}]}, {"text": "We are interested in investigating how the three key parameters of the algorithm, i.e., the chunk size (c), the heuristic weight (w) and the keeplength (k), affect the system latency, the search speed, and the alignment accuracy.", "labels": [], "entities": [{"text": "heuristic weight (w)", "start_pos": 112, "end_pos": 132, "type": "METRIC", "confidence": 0.8507584571838379}, {"text": "keeplength (k)", "start_pos": 141, "end_pos": 155, "type": "METRIC", "confidence": 0.9428219050168991}, {"text": "accuracy", "start_pos": 220, "end_pos": 228, "type": "METRIC", "confidence": 0.954751193523407}]}, {"text": "The chunk size directly determines the latency of the system to the end user, as alignment cannot begin until an entire chunk is captured.", "labels": [], "entities": []}, {"text": "Furthermore, the chunk size, the heuristic weight, and the keep-length help us to trade-off speed versus accuracy.", "labels": [], "entities": [{"text": "speed", "start_pos": 92, "end_pos": 97, "type": "METRIC", "confidence": 0.9786633253097534}, {"text": "accuracy", "start_pos": 105, "end_pos": 113, "type": "METRIC", "confidence": 0.9982030391693115}]}, {"text": "We also compare the performance of our algorithm with that of the most accurate fixed alignment window algorithm).", "labels": [], "entities": []}, {"text": "The performance in terms of WER for sliding and fixed alignment windows is presented in.", "labels": [], "entities": [{"text": "WER", "start_pos": 28, "end_pos": 31, "type": "METRIC", "confidence": 0.9932867884635925}]}, {"text": "Out of the systems in, the first three systems consist of sliding alignment window algorithm with different values of keep-length parameter: (1) keep-length = 0.5; (2) keep-length = 0.67; and (3) keep-length = 0.85.", "labels": [], "entities": []}, {"text": "The other systems are the graph-based algorithm of (, the MUSCLE algorithm of, and the most accu-rate fixed alignment window algorithm of.", "labels": [], "entities": []}, {"text": "We set the heuristic weight parameter (w) to 3 and the chunk size parameter (c) to 5 seconds for all the three sliding window systems and the fixed window system.", "labels": [], "entities": [{"text": "chunk size parameter (c)", "start_pos": 55, "end_pos": 79, "type": "METRIC", "confidence": 0.7041720946629842}]}, {"text": "Sliding alignment window produces better results and outperforms the other algorithms even for large values of the keep-length parameter.", "labels": [], "entities": []}, {"text": "The sliding alignment window with keep-length 0.5 achieves 0.5679 average accuracy in terms of (1-WER), providing a 18.09% improvement with respect to the most accurate fixed alignment window (average accuracy 0.4857).", "labels": [], "entities": [{"text": "keep-length", "start_pos": 34, "end_pos": 45, "type": "METRIC", "confidence": 0.9603058695793152}, {"text": "accuracy", "start_pos": 74, "end_pos": 82, "type": "METRIC", "confidence": 0.9907212257385254}, {"text": "accuracy", "start_pos": 201, "end_pos": 209, "type": "METRIC", "confidence": 0.8303620219230652}]}, {"text": "On the same dataset, reported 36.6% accuracy using the Dragon Naturally Speaking ASR system (version 11.5 for Windows).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 36, "end_pos": 44, "type": "METRIC", "confidence": 0.9992874264717102}, {"text": "Dragon Naturally Speaking ASR system", "start_pos": 55, "end_pos": 91, "type": "DATASET", "confidence": 0.8281527876853942}]}, {"text": "To show the trade-off between latency and accuracy, we fix the heuristic weight (w = 3) and plot the accuracy as a function of chunk size in.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 42, "end_pos": 50, "type": "METRIC", "confidence": 0.9988415837287903}, {"text": "accuracy", "start_pos": 101, "end_pos": 109, "type": "METRIC", "confidence": 0.9991639852523804}]}, {"text": "We repeat this experiment for different values of keep-length.", "labels": [], "entities": []}, {"text": "We observe that the sliding window approach dominates the fixed window approach across a wide range of chunk sizes.", "labels": [], "entities": []}, {"text": "Furthermore, we can see that for smaller values of the chunk size parameter, increasing the keep-length makes the system less accurate.", "labels": [], "entities": []}, {"text": "As the chunk size parameter increases, the performance of sliding window systems with different values of keeplength parameter converges.", "labels": [], "entities": []}, {"text": "Therefore, at larger chunk sizes, for which there are smaller number of boundaries, the keep-length parameter has lower impact.", "labels": [], "entities": []}, {"text": "Next, we show the trade-off between computation speed and accuracy in, as we fix the heuristic weight and vary the chunk size over the range seconds.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 58, "end_pos": 66, "type": "METRIC", "confidence": 0.9995051622390747}]}, {"text": "Larger chunks are more accurately aligned but require computation time that grows as N K in the chunk size N in the worst case.", "labels": [], "entities": []}, {"text": "Furthermore, smaller weights allow faster alignment, but provide lower accuracy.", "labels": [], "entities": [{"text": "alignment", "start_pos": 42, "end_pos": 51, "type": "TASK", "confidence": 0.9514574408531189}, {"text": "accuracy", "start_pos": 71, "end_pos": 79, "type": "METRIC", "confidence": 0.9979826211929321}]}], "tableCaptions": []}