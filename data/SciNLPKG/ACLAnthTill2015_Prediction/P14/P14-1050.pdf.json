{"title": [{"text": "New Word Detection for Sentiment Analysis", "labels": [], "entities": [{"text": "Word Detection", "start_pos": 4, "end_pos": 18, "type": "TASK", "confidence": 0.6905097812414169}, {"text": "Sentiment Analysis", "start_pos": 23, "end_pos": 41, "type": "TASK", "confidence": 0.9801401197910309}]}], "abstractContent": [{"text": "Automatic extraction of new words is an indispensable precursor to many NLP tasks such as Chinese word segmentation, named entity extraction, and sentiment analysis.", "labels": [], "entities": [{"text": "Automatic extraction of new words", "start_pos": 0, "end_pos": 33, "type": "TASK", "confidence": 0.8322269916534424}, {"text": "Chinese word segmentation", "start_pos": 90, "end_pos": 115, "type": "TASK", "confidence": 0.6474512914816538}, {"text": "named entity extraction", "start_pos": 117, "end_pos": 140, "type": "TASK", "confidence": 0.620176782210668}, {"text": "sentiment analysis", "start_pos": 146, "end_pos": 164, "type": "TASK", "confidence": 0.9474986791610718}]}, {"text": "This paper aims at extracting new sentiment words from large-scale user-generated content.", "labels": [], "entities": [{"text": "extracting new sentiment words from large-scale user-generated content", "start_pos": 19, "end_pos": 89, "type": "TASK", "confidence": 0.8844770938158035}]}, {"text": "We propose a fully unsupervised, purely data-driven framework for this purpose.", "labels": [], "entities": []}, {"text": "We design statistical measures respectively to quantify the utility of a lexical pattern and to measure the possibility of a word being anew word.", "labels": [], "entities": []}, {"text": "The method is almost free of linguistic resources (except POS tags), and requires no elaborated linguistic rules.", "labels": [], "entities": []}, {"text": "We also demonstrate how new sentiment word will benefit sentiment analysis.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 56, "end_pos": 74, "type": "TASK", "confidence": 0.9709279537200928}]}, {"text": "Experiment results demonstrate the effectiveness of the proposed method.", "labels": [], "entities": []}], "introductionContent": [{"text": "New words on the Internet have been emerging all the time, particularly in user-generated content.", "labels": [], "entities": []}, {"text": "Users like to update and share their information on social websites with their own language styles, among which new political/social/cultural words are constantly used.", "labels": [], "entities": []}, {"text": "However, such new words have made many natural language processing tasks more challenging.", "labels": [], "entities": []}, {"text": "Automatic extraction of new words is indispensable to many tasks such as Chinese word segmentation, machine translation, named entity extraction, question answering, and sentiment analysis.", "labels": [], "entities": [{"text": "Automatic extraction of new words", "start_pos": 0, "end_pos": 33, "type": "TASK", "confidence": 0.8257385134696961}, {"text": "Chinese word segmentation", "start_pos": 73, "end_pos": 98, "type": "TASK", "confidence": 0.6335727969805399}, {"text": "machine translation", "start_pos": 100, "end_pos": 119, "type": "TASK", "confidence": 0.7738751471042633}, {"text": "named entity extraction", "start_pos": 121, "end_pos": 144, "type": "TASK", "confidence": 0.631227453549703}, {"text": "question answering", "start_pos": 146, "end_pos": 164, "type": "TASK", "confidence": 0.9110883474349976}, {"text": "sentiment analysis", "start_pos": 170, "end_pos": 188, "type": "TASK", "confidence": 0.9605987966060638}]}, {"text": "New word detection is one of the most critical issues in Chinese word segmentation.", "labels": [], "entities": [{"text": "New word detection", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.6011568903923035}, {"text": "Chinese word segmentation", "start_pos": 57, "end_pos": 82, "type": "TASK", "confidence": 0.6129084229469299}]}, {"text": "Recent studies have shown that more than 60% of word segmentation errors result from new words.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 48, "end_pos": 65, "type": "TASK", "confidence": 0.7226426303386688}]}, {"text": "Statistics show that more than 1000 new Chinese words appear every year.", "labels": [], "entities": []}, {"text": "These words are mostly domain-specific technical terms and time-sensitive political/social /cultural terms.", "labels": [], "entities": []}, {"text": "Most of them are not yet correctly recognized by the segmentation algorithm, and remain as out of vocabulary (OOV) words.", "labels": [], "entities": [{"text": "segmentation", "start_pos": 53, "end_pos": 65, "type": "TASK", "confidence": 0.962193489074707}]}, {"text": "New word detection is also important for sentiment analysis such as opinionated phrase extraction and polarity classification.", "labels": [], "entities": [{"text": "word detection", "start_pos": 4, "end_pos": 18, "type": "TASK", "confidence": 0.7391306459903717}, {"text": "sentiment analysis", "start_pos": 41, "end_pos": 59, "type": "TASK", "confidence": 0.9692986309528351}, {"text": "opinionated phrase extraction", "start_pos": 68, "end_pos": 97, "type": "TASK", "confidence": 0.6188221474488577}, {"text": "polarity classification", "start_pos": 102, "end_pos": 125, "type": "TASK", "confidence": 0.7119704037904739}]}, {"text": "A sentiment phrase with complete meaning should have a correct boundary, however, characters in anew word maybe broken up.", "labels": [], "entities": []}, {"text": "For example, in a sentence \" \u8868 \u6f14/ n \u975e \u5e38/ adv \u7ed9/ v \u529b/ n\uff08artists' performance is very impressive\uff09\" the two Chinese characters\"\u7ed9/v \u529b/n(cool; powerful)\"should always be extracted together.", "labels": [], "entities": []}, {"text": "In polarity classification, new words can be informative features for classification models.", "labels": [], "entities": [{"text": "polarity classification", "start_pos": 3, "end_pos": 26, "type": "TASK", "confidence": 0.7539434432983398}]}, {"text": "In the previous example, \"\u7ed9 \u529b(cool; powerful)\" is a strong feature for classification models while each single character is not.", "labels": [], "entities": []}, {"text": "Adding new words as feature in classification models will improve the performance of polarity classification, as demonstrated later in this paper.", "labels": [], "entities": [{"text": "polarity classification", "start_pos": 85, "end_pos": 108, "type": "TASK", "confidence": 0.79315185546875}]}, {"text": "This paper aims to detect new word for sentiment analysis.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 39, "end_pos": 57, "type": "TASK", "confidence": 0.9636237919330597}]}, {"text": "We are particulary interested in extracting new sentiment word that can express opinions or sentiment, which is of high value towards sentiment analysis.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 134, "end_pos": 152, "type": "TASK", "confidence": 0.9377699196338654}]}, {"text": "New sentiment word, as exemplified in, is a sub-class of multi-word expressions which is a sequence of neighboring words \"whose exact and unambiguous meaning or connotation cannot be derived from the meaning or connotation of its components\".", "labels": [], "entities": []}, {"text": "Such new words cannot be directly identified using grammatical rules, which poses a major challenge to automatic analysis.", "labels": [], "entities": [{"text": "automatic analysis", "start_pos": 103, "end_pos": 121, "type": "TASK", "confidence": 0.7383923530578613}]}, {"text": "Moreover, existing lexical resources never have adequate and timely coverage since new words appear constantly.", "labels": [], "entities": []}, {"text": "People thus resort to statistical methods such as Pointwise Mutual Information), Symmetrical Conditional Probability (da), Mutual Expectation (), Enhanced Mutual Information ( , and Multi-word Expression Distance ( Our central idea for new sentiment word detection is as follows: Starting from very few seed words (for example, just one seed word), we can extract lexical patterns that have strong statistical association with the seed words; the extracted lexical patterns can be further used in finding more new words, and the most probable new words can be added into the seed word set for the next iteration; and the process can be run iteratively until a stop condition is met.", "labels": [], "entities": [{"text": "sentiment word detection", "start_pos": 240, "end_pos": 264, "type": "TASK", "confidence": 0.6693364779154459}]}, {"text": "The key issues are to measure the utility of a pattern and to quantify the possibility of a word being anew word.", "labels": [], "entities": []}, {"text": "The main contributions of this paper are summarized as follows: \u2022 We propose a novel framework for new word detection from large-scale user-generated data.", "labels": [], "entities": [{"text": "word detection", "start_pos": 103, "end_pos": 117, "type": "TASK", "confidence": 0.755826324224472}]}, {"text": "This framework is fully unsupervised and purely data-driven, and requires very lightweight linguistic resources (i.e., only POS tags).", "labels": [], "entities": []}, {"text": "\u2022 We design statistical measures to quantify the utility of a pattern and to quantify the possibility of a word being anew word, respectively.", "labels": [], "entities": []}, {"text": "No elaborated linguistic rules are needed to filter undesirable results.", "labels": [], "entities": []}, {"text": "This feature may enable our approach to be portable to other languages.", "labels": [], "entities": []}, {"text": "\u2022 We investigate the problem of polarity prediction of new sentiment word and demonstrate that inclusion of new sentiment word benefits sentiment classification tasks.", "labels": [], "entities": [{"text": "polarity prediction of new sentiment word", "start_pos": 32, "end_pos": 73, "type": "TASK", "confidence": 0.8250712454319}, {"text": "sentiment classification", "start_pos": 136, "end_pos": 160, "type": "TASK", "confidence": 0.907763808965683}]}, {"text": "The rest of the paper is structured as follows: we will introduce related work in the next section.", "labels": [], "entities": []}, {"text": "We will describe the proposed method in Section 3, including definitions, the overview of the algorithm, and the statistical measures for addressing the two key issues.", "labels": [], "entities": []}, {"text": "We then present the experiments in Section 4.", "labels": [], "entities": []}, {"text": "Finally, the work is summarized in Section 5.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section, we will conduct the following experiments: first, we will compare our method to several baselines, and perform parameter tuning with extensive experiments; second, we will classify polarity of new sentiment words using two methods; third, we will demonstrate how new sentiment words will benefit sentiment classification.", "labels": [], "entities": [{"text": "parameter tuning", "start_pos": 128, "end_pos": 144, "type": "TASK", "confidence": 0.689492255449295}, {"text": "sentiment classification", "start_pos": 313, "end_pos": 337, "type": "TASK", "confidence": 0.8879134654998779}]}, {"text": "As our algorithm outputs a ranked list of words, we adapt average precision to evaluate the performance of new sentiment word detection.", "labels": [], "entities": [{"text": "precision", "start_pos": 66, "end_pos": 75, "type": "METRIC", "confidence": 0.7935337424278259}, {"text": "new sentiment word detection", "start_pos": 107, "end_pos": 135, "type": "TASK", "confidence": 0.6494651138782501}]}, {"text": "The metric is computed as follows: where P (k) is the precision at cut-off k, rel(k) is 1 if the word at position k is anew word and 0 otherwise, and K is the number of words in the ranked list.", "labels": [], "entities": [{"text": "precision", "start_pos": 54, "end_pos": 63, "type": "METRIC", "confidence": 0.9985247254371643}, {"text": "rel(k)", "start_pos": 78, "end_pos": 84, "type": "METRIC", "confidence": 0.9258792698383331}]}, {"text": "A perfect list (all top K items are correct) has an AP value of 1.0.", "labels": [], "entities": [{"text": "AP", "start_pos": 52, "end_pos": 54, "type": "METRIC", "confidence": 0.9989135265350342}]}, {"text": "First, we assess the influence of likelihood ratio test, which measures the association of a word to the pattern set.", "labels": [], "entities": [{"text": "likelihood ratio test", "start_pos": 34, "end_pos": 55, "type": "METRIC", "confidence": 0.9818452596664429}]}, {"text": "As can be seen from, the association model (LRT) remarkably boosts the performance of new word detection, indicating L-RT is a key factor for new sentiment word extraction.", "labels": [], "entities": [{"text": "word detection", "start_pos": 90, "end_pos": 104, "type": "TASK", "confidence": 0.7230158746242523}, {"text": "new sentiment word extraction", "start_pos": 142, "end_pos": 171, "type": "TASK", "confidence": 0.6507895961403847}]}, {"text": "From linguistic perspectives, new sentiment words are commonly modified by adverbial words and thus should have close association with lexical patterns.", "labels": [], "entities": []}, {"text": "Second, we compare different settings of our method to two baselines.", "labels": [], "entities": []}, {"text": "The first one is enhanced mutual information (EMI) where we set F (w) = EM I(w) ( ) and the second baseline is normalized multi-word expression distance (NMED) () where we set F (w) = NM ED(w).", "labels": [], "entities": [{"text": "mutual information (EMI)", "start_pos": 26, "end_pos": 50, "type": "METRIC", "confidence": 0.5776816129684448}, {"text": "multi-word expression distance (NMED)", "start_pos": 122, "end_pos": 159, "type": "METRIC", "confidence": 0.7359912296136221}]}, {"text": "The results are shown in.", "labels": [], "entities": []}, {"text": "As can be seen, all the proposed measures outperform the two baselines (EM I and NM ED) remarkably and consistently.", "labels": [], "entities": []}, {"text": "The setting of F NM ED produces the best performance.", "labels": [], "entities": [{"text": "F NM ED", "start_pos": 15, "end_pos": 22, "type": "METRIC", "confidence": 0.8261421918869019}]}, {"text": "Adding NM ED or EM I leads to remarkable improvements because of their capability of measuring non-compositionality of new words.", "labels": [], "entities": []}, {"text": "Only using LRT can obtain a fairly good results when K is small, however, the performance drops sharply because it's unable to measure non-compositionality.", "labels": [], "entities": []}, {"text": "Comparison between LRT + LP E (or LRT + LP E + NW P ) and LRT shows that inclusion of left pattern entropy also boosts the performance apparently.", "labels": [], "entities": []}, {"text": "However, the new word probability (N WP ) has only marginal contribution to improvement.", "labels": [], "entities": [{"text": "word probability (N WP )", "start_pos": 17, "end_pos": 41, "type": "METRIC", "confidence": 0.8784142434597015}]}, {"text": "In the above experiments, we set k p = 5 (the number of patterns chosen at each iteration) and kw = 10 (the number of words added at each iteration), which is the optimal setting and will be discussed in the next subsection.", "labels": [], "entities": []}, {"text": "And only one seed word \"\u5751\u7239(reverse one's expectation)\" is used.: Results with vs. without likelihood ratio test (LRT).", "labels": [], "entities": [{"text": "without likelihood ratio test (LRT)", "start_pos": 82, "end_pos": 117, "type": "METRIC", "confidence": 0.8276971450873783}]}], "tableCaptions": [{"text": " Table 4: Results with vs. without likelihood ratio test (LRT).", "labels": [], "entities": [{"text": "without likelihood ratio test (LRT)", "start_pos": 27, "end_pos": 62, "type": "METRIC", "confidence": 0.8352068151746478}]}, {"text": " Table 6: Performance with different numbers of  seed words. The measure setting is F N M ED (w),  and k p = 5, k w = 10. The seed words are chosen  from Table 1.", "labels": [], "entities": [{"text": "ED", "start_pos": 90, "end_pos": 92, "type": "METRIC", "confidence": 0.5485345125198364}]}, {"text": " Table 7: Tuning the number of patterns in P c . The measure setting is F N M ED (w), k p = 5, k w = 10,  and the seed word set is {\"\u5751\u7239(reverse one's expectation)\"}.", "labels": [], "entities": []}, {"text": " Table 8: The ten emoticons used for polarity pre- diction.", "labels": [], "entities": []}, {"text": " Table 9: The accuracy of two/three-class polarity  classification.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 14, "end_pos": 22, "type": "METRIC", "confidence": 0.9997128844261169}, {"text": "two/three-class polarity  classification", "start_pos": 26, "end_pos": 66, "type": "TASK", "confidence": 0.7059714436531067}]}, {"text": " Table 10: The accuracy of polarity classfication of  Weibo post with/without new sentiment words. N- W includes 116/112 positive/negative words, and  T100 contains 52/34 positive/negative words.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 15, "end_pos": 23, "type": "METRIC", "confidence": 0.9994996786117554}, {"text": "N- W", "start_pos": 99, "end_pos": 103, "type": "METRIC", "confidence": 0.6857050259908041}]}]}