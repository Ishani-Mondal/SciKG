{"title": [{"text": "Punctuation Processing for Projective Dependency Parsing *", "labels": [], "entities": [{"text": "Punctuation Processing", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.7999780476093292}, {"text": "Projective Dependency Parsing", "start_pos": 27, "end_pos": 56, "type": "TASK", "confidence": 0.6081518034140269}]}], "abstractContent": [{"text": "Modern statistical dependency parsers assign lexical heads to punctuations as well as words.", "labels": [], "entities": [{"text": "statistical dependency parsers assign lexical heads", "start_pos": 7, "end_pos": 58, "type": "TASK", "confidence": 0.7486369758844376}]}, {"text": "Punctuation parsing errors lead to low parsing accuracy on words.", "labels": [], "entities": [{"text": "Punctuation parsing", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.7638676464557648}, {"text": "accuracy", "start_pos": 47, "end_pos": 55, "type": "METRIC", "confidence": 0.9753961563110352}]}, {"text": "In this work, we propose an alternative approach to addressing punctuation in dependency parsing.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 78, "end_pos": 96, "type": "TASK", "confidence": 0.8051198124885559}]}, {"text": "Rather than assigning lexical heads to punctuations, we treat punctu-ations as properties of their neighbouring words, used as features to guide the parser to build the dependency graph.", "labels": [], "entities": []}, {"text": "Integrating our method with an arc-standard parser yields a 93.06% unlabelled attachment score, which is the best accuracy by a single-model transition-based parser reported so far.", "labels": [], "entities": [{"text": "unlabelled attachment score", "start_pos": 67, "end_pos": 94, "type": "METRIC", "confidence": 0.7054994304974874}, {"text": "accuracy", "start_pos": 114, "end_pos": 122, "type": "METRIC", "confidence": 0.9985396862030029}]}], "introductionContent": [{"text": "The task of dependency parsing is to identify the lexical head of each of the tokens in a string.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 12, "end_pos": 30, "type": "TASK", "confidence": 0.7976039946079254}]}, {"text": "Modern statistical parsers) treat all the tokens equally, assigning lexical heads to punctuations as well as words.", "labels": [], "entities": []}, {"text": "Punctuations arguably play an important role in syntactic analysis.", "labels": [], "entities": [{"text": "syntactic analysis", "start_pos": 48, "end_pos": 66, "type": "TASK", "confidence": 0.8684158325195312}]}, {"text": "However, there area number of reasons that it is not necessary to parse punctuations: First, the lexical heads of punctuations are not as well defined as those of words.", "labels": [], "entities": []}, {"text": "Consequently, punctuations are not as consistently annotated in treebanks as words, making it harder to parse punctuations.", "labels": [], "entities": []}, {"text": "For example, modern statistical parsers achieve above 90% unlabelled attachment score (UAS) on words.", "labels": [], "entities": [{"text": "unlabelled attachment score (UAS)", "start_pos": 58, "end_pos": 91, "type": "METRIC", "confidence": 0.813104455669721}]}, {"text": "However, the UAS on punctuations are generally below 85%.", "labels": [], "entities": [{"text": "UAS", "start_pos": 13, "end_pos": 16, "type": "METRIC", "confidence": 0.7687101364135742}]}, {"text": "* This work was done while the first author was visiting SUTD Moreover, experimental results showed that parsing accuracy of content words drops on sentences which contain higher ratios of punctuations.", "labels": [], "entities": [{"text": "SUTD", "start_pos": 57, "end_pos": 61, "type": "DATASET", "confidence": 0.8057205677032471}, {"text": "parsing", "start_pos": 105, "end_pos": 112, "type": "TASK", "confidence": 0.9435439705848694}, {"text": "accuracy", "start_pos": 113, "end_pos": 121, "type": "METRIC", "confidence": 0.9482101798057556}]}, {"text": "One reason for this result is that projective dependency parsers satisfy the \"no crossing links\" constraint, and errors in punctuations may prevent correct word-word dependencies from being created (see section 2).", "labels": [], "entities": []}, {"text": "In addition, punctuations cause certain type of features inaccurate.", "labels": [], "entities": []}, {"text": "Take valency features for example, previous work () has shown that such features are important to parsing accuracy, e.g., it may inform the parser that a verb already has two objects attached to it.", "labels": [], "entities": [{"text": "parsing", "start_pos": 98, "end_pos": 105, "type": "TASK", "confidence": 0.963281512260437}, {"text": "accuracy", "start_pos": 106, "end_pos": 114, "type": "METRIC", "confidence": 0.8556832075119019}]}, {"text": "However, such information might be inaccurate when the verb's modifiers contain punctuations.", "labels": [], "entities": []}, {"text": "Ultimately, it is the dependencies between words that provide useful information for real world applications.", "labels": [], "entities": []}, {"text": "Take machine translation or information extraction for example, most systems take advantage of the head-modifier relationships between word pairs rather than word-punctuation pairs to make better predictions.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 5, "end_pos": 24, "type": "TASK", "confidence": 0.7533415853977203}, {"text": "information extraction", "start_pos": 28, "end_pos": 50, "type": "TASK", "confidence": 0.7794874608516693}]}, {"text": "The fact that most previous work evaluates parsing accuracies without taking punctuations into account is also largely due to this reason.", "labels": [], "entities": [{"text": "parsing accuracies", "start_pos": 43, "end_pos": 61, "type": "TASK", "confidence": 0.8144855797290802}]}, {"text": "Given the above reasons, we propose an alternative approach to punctuation processing for dependency parsing.", "labels": [], "entities": [{"text": "punctuation processing", "start_pos": 63, "end_pos": 85, "type": "TASK", "confidence": 0.8772901594638824}, {"text": "dependency parsing", "start_pos": 90, "end_pos": 108, "type": "TASK", "confidence": 0.8631837666034698}]}, {"text": "In this method, punctuations are not associated with lexical heads, but are treated as properties of their neighbouring words.", "labels": [], "entities": []}, {"text": "Our method is simple and can be easily incorporated into state-of-the-art parsers.", "labels": [], "entities": []}, {"text": "In this work, we report results on an arc-standard transitionbased parser.", "labels": [], "entities": []}, {"text": "Experiments show that our method achieves about 0.90% UAS improvement over the greedy baseline parser on the standard Penn Treebank test set.", "labels": [], "entities": [{"text": "UAS", "start_pos": 54, "end_pos": 57, "type": "METRIC", "confidence": 0.9944936633110046}, {"text": "Penn Treebank test set", "start_pos": 118, "end_pos": 140, "type": "DATASET", "confidence": 0.9939165711402893}]}, {"text": "Although the improvement becomes smaller as the beam width grows larger, we still achieved 93.06% UAS with abeam of width 64, which is the best result for transition-based parsers: Parsing accuracies.", "labels": [], "entities": [{"text": "UAS", "start_pos": 98, "end_pos": 101, "type": "METRIC", "confidence": 0.9986099004745483}]}, {"text": "\"E-F\" and \"MST\" denote easy-first parser and MSTparser, respectively.", "labels": [], "entities": []}, {"text": "\"A-S\" and \"A-S 64\" denote our arc-standard parser with beam width 1 and 64, respectively.", "labels": [], "entities": []}, {"text": "\"UAS\" and \"UAS-p\" denote word and punctuation unlabelled attachment score, respectively.", "labels": [], "entities": [{"text": "UAS", "start_pos": 1, "end_pos": 4, "type": "METRIC", "confidence": 0.9545671343803406}, {"text": "UAS-p", "start_pos": 11, "end_pos": 16, "type": "METRIC", "confidence": 0.831244707107544}, {"text": "punctuation unlabelled attachment score", "start_pos": 34, "end_pos": 73, "type": "METRIC", "confidence": 0.5826101750135422}]}, {"text": "\" \u2212 \" denotes the data set with punctuations removed.", "labels": [], "entities": []}, {"text": "Our code will be available at https://github.com/majineu/Parser/Punc/A-STD.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 2: Parsing accuracies vs punctuation ratios, on the development set", "labels": [], "entities": []}, {"text": " Table 4: Parsing accuracies on the development  set. s denotes the beam width.", "labels": [], "entities": []}, {"text": " Table 5: Final result on the test set.", "labels": [], "entities": [{"text": "Final", "start_pos": 10, "end_pos": 15, "type": "METRIC", "confidence": 0.9474879503250122}]}]}