{"title": [{"text": "Bilingual Active Learning for Relation Classification via Pseudo Paral- lel Corpora", "labels": [], "entities": [{"text": "Relation Classification", "start_pos": 30, "end_pos": 53, "type": "TASK", "confidence": 0.8748721480369568}]}], "abstractContent": [{"text": "Active learning (AL) has been proven effective to reduce human annotation efforts in NLP.", "labels": [], "entities": [{"text": "Active learning (AL)", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.7112243890762329}]}, {"text": "However, previous studies on AL are limited to applications in a single language.", "labels": [], "entities": [{"text": "AL", "start_pos": 29, "end_pos": 31, "type": "TASK", "confidence": 0.9722751379013062}]}, {"text": "This paper proposes a bilingual active learning paradigm for relation classification, where the unlabeled instances are first jointly chosen in terms of their prediction uncertainty scores in two languages and then manually labeled by an oracle.", "labels": [], "entities": [{"text": "relation classification", "start_pos": 61, "end_pos": 84, "type": "TASK", "confidence": 0.9674999117851257}]}, {"text": "Instead of using a parallel corpus, labeled and unlabeled instances in one language are translated into ones in the other language and all instances in both languages are then fed into a bilingual active learning engine as pseudo parallel corpora.", "labels": [], "entities": []}, {"text": "Experimental results on the ACE RDC 2005 Chinese and English corpora show that bilingual active learning for relation classification significantly outperforms monolingual active learning.", "labels": [], "entities": [{"text": "ACE RDC 2005 Chinese and English corpora", "start_pos": 28, "end_pos": 68, "type": "DATASET", "confidence": 0.9631359066282}, {"text": "relation classification", "start_pos": 109, "end_pos": 132, "type": "TASK", "confidence": 0.954172670841217}]}], "introductionContent": [{"text": "Semantic relation extraction between named entities (aka.", "labels": [], "entities": [{"text": "Semantic relation extraction between named entities", "start_pos": 0, "end_pos": 51, "type": "TASK", "confidence": 0.8305207192897797}]}, {"text": "entity relation extraction or more concisely relation extraction) is an important subtask of Information Extraction (IE) as well as Natural Language Processing (NLP).", "labels": [], "entities": [{"text": "entity relation extraction", "start_pos": 0, "end_pos": 26, "type": "TASK", "confidence": 0.6149345537026724}, {"text": "relation extraction", "start_pos": 45, "end_pos": 64, "type": "TASK", "confidence": 0.7292283922433853}, {"text": "Information Extraction (IE)", "start_pos": 93, "end_pos": 120, "type": "TASK", "confidence": 0.8325471639633178}]}, {"text": "With its aim to identify and classify the semantic relationship between two entities, relation extraction is of great significance to many NLP applications, such as question answering, information fusion, social network construction, and knowledge mining and population etc.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 86, "end_pos": 105, "type": "TASK", "confidence": 0.8210779130458832}, {"text": "question answering", "start_pos": 165, "end_pos": 183, "type": "TASK", "confidence": 0.9072013795375824}, {"text": "information fusion", "start_pos": 185, "end_pos": 203, "type": "TASK", "confidence": 0.8188928067684174}, {"text": "social network construction", "start_pos": 205, "end_pos": 232, "type": "TASK", "confidence": 0.6777339975039164}, {"text": "knowledge mining", "start_pos": 238, "end_pos": 254, "type": "TASK", "confidence": 0.7534961998462677}]}], "datasetContent": [{"text": "We have systematically evaluated our BAL paradigm on the relation classification task using ACE RDC 2005 RDC Chinese and English corpora.", "labels": [], "entities": [{"text": "BAL", "start_pos": 37, "end_pos": 40, "type": "TASK", "confidence": 0.737314760684967}, {"text": "relation classification task", "start_pos": 57, "end_pos": 85, "type": "TASK", "confidence": 0.913971741994222}, {"text": "ACE RDC 2005 RDC Chinese and English corpora", "start_pos": 92, "end_pos": 136, "type": "DATASET", "confidence": 0.9104266986250877}]}, {"text": "Although learning curves are often used to evaluate the performance for active learning, it is preferable to quantitatively compare various active learning methods using a statistical metric deficiency () defined as: Where n is the number of iterations involved in active learning and F i is the F1-score of relation classification at the i th iteration.", "labels": [], "entities": [{"text": "F1-score", "start_pos": 296, "end_pos": 304, "type": "METRIC", "confidence": 0.9962025284767151}, {"text": "relation classification", "start_pos": 308, "end_pos": 331, "type": "TASK", "confidence": 0.8014609515666962}]}, {"text": "REF is the baseline active learning method and AL is an improved variant of REF, such as AL-CR or AL-BI.", "labels": [], "entities": [{"text": "REF", "start_pos": 76, "end_pos": 79, "type": "METRIC", "confidence": 0.8797394037246704}]}, {"text": "Essentially this deficiency metric measures the degree to which REF outperforms AL.", "labels": [], "entities": [{"text": "deficiency metric", "start_pos": 17, "end_pos": 34, "type": "METRIC", "confidence": 0.9477951526641846}, {"text": "REF", "start_pos": 64, "end_pos": 67, "type": "METRIC", "confidence": 0.9909487366676331}, {"text": "AL", "start_pos": 80, "end_pos": 82, "type": "METRIC", "confidence": 0.7316262125968933}]}, {"text": "Thus, smaller deficiency value (i.e. <1.0) indicates AL outperforms REF while a larger value (i.e. >1.0) indicates AL underperforms REF.", "labels": [], "entities": [{"text": "deficiency value", "start_pos": 14, "end_pos": 30, "type": "METRIC", "confidence": 0.9620762467384338}, {"text": "AL outperforms REF", "start_pos": 53, "end_pos": 71, "type": "METRIC", "confidence": 0.8049425482749939}, {"text": "REF", "start_pos": 132, "end_pos": 135, "type": "METRIC", "confidence": 0.4158047139644623}]}, {"text": "Comparison of overall deficiency compares the deficiency scores of relation classification on the Chinese (ACE2005c) and English corpora (ACE2005e) for various learning methods, i.e., SL-CR, AL-MO, AL-CR and AL-BI.", "labels": [], "entities": [{"text": "relation classification", "start_pos": 67, "end_pos": 90, "type": "TASK", "confidence": 0.8621852099895477}, {"text": "ACE2005e", "start_pos": 138, "end_pos": 146, "type": "DATASET", "confidence": 0.6971986889839172}]}, {"text": "Particularly, SL-MO is used as the baseline system against which deficiency scores for other methods are computed.", "labels": [], "entities": [{"text": "deficiency scores", "start_pos": 65, "end_pos": 82, "type": "METRIC", "confidence": 0.9738195538520813}]}, {"text": "The batch size n is set to 100 and iterations stop after all the unlabeled instances have run out of.", "labels": [], "entities": []}, {"text": "Deficiency scores are averaged over 10 runs and the best ones are highlighted in bold font.", "labels": [], "entities": []}, {"text": "Each run has a different test set and a different seed set.", "labels": [], "entities": []}, {"text": "The table shows that among the three active learning methods, bilingual active learning (AL-BI) achieves the best performance for both Chinese and English relation classification.", "labels": [], "entities": [{"text": "Chinese and English relation classification", "start_pos": 135, "end_pos": 178, "type": "TASK", "confidence": 0.5839402258396149}]}, {"text": "This demonstrates that, bilingual active learning with jointly selecting the unlabeled instances cannot only enhance relation classification for its own language, but also help relation classification for the other language due to the complementary nature of relation instances between Chinese and English.", "labels": [], "entities": [{"text": "relation classification", "start_pos": 117, "end_pos": 140, "type": "TASK", "confidence": 0.8662048280239105}, {"text": "relation classification", "start_pos": 177, "end_pos": 200, "type": "TASK", "confidence": 0.9049258530139923}]}, {"text": "The table also shows the consistent utility of cross-lingual information for relation classification for both languages.", "labels": [], "entities": [{"text": "relation classification", "start_pos": 77, "end_pos": 100, "type": "TASK", "confidence": 0.9085628092288971}]}, {"text": "When cross-lingual information is augmented, SL-CR outperforms SL-MO and AL-CR outperforms AL-MO.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1. Deficiency comparison of different  methods", "labels": [], "entities": [{"text": "Deficiency comparison", "start_pos": 10, "end_pos": 31, "type": "TASK", "confidence": 0.9019934237003326}]}]}