{"title": [{"text": "Content Importance Models for Scoring Writing From Sources", "labels": [], "entities": [{"text": "Scoring Writing", "start_pos": 30, "end_pos": 45, "type": "TASK", "confidence": 0.9503220021724701}]}], "abstractContent": [{"text": "Selection of information from external sources is an important skill assessed in educational measurement.", "labels": [], "entities": []}, {"text": "We address an integrative summarization task used in an assessment of English proficiency for non-native speakers applying to higher education institutions in the USA.", "labels": [], "entities": []}, {"text": "We evaluate a variety of content importance models that help predict which parts of the source material should be selected by the test-taker in order to succeed on this task.", "labels": [], "entities": []}], "introductionContent": [{"text": "Selection and integration of information from external sources is an important academic and life skill, mentioned as a critical competency in the Common Core State Standards for English Language Arts/Literacy: College-ready students will be able to \"gather relevant information from multiple print and digital sources, assess the credibility and accuracy of each source, and integrate the information while avoiding plagiarism.\"", "labels": [], "entities": [{"text": "Common Core State Standards", "start_pos": 146, "end_pos": 173, "type": "DATASET", "confidence": 0.9468420892953873}, {"text": "accuracy", "start_pos": 346, "end_pos": 354, "type": "METRIC", "confidence": 0.9842185378074646}]}, {"text": "Accordingly, large-scale assessments of writing incorporate tasks that test this skill.", "labels": [], "entities": []}, {"text": "One such test requires test-takers to read a passage, then to listen to a lecture discussing the same topic from a different point of view, and to summarize the points made in the lecture, explaining how they cast doubt on points made in the reading.", "labels": [], "entities": []}, {"text": "The quality of the information selected from the lecture is emphasized in excerpts from the scoring rubric for this test (below); essays are scored on a 1-5 scale: Score 5 successfully selects the important information from the lecture and coherently and accurately presents this information in relation to the relevant information presented in the reading.", "labels": [], "entities": []}, {"text": "Score 4 is generally good in selecting the important information from the lecture ..., but it may have a minor omission.", "labels": [], "entities": []}, {"text": "Score 3 contains some important information from the lecture ..., but it may omit one major key point.", "labels": [], "entities": []}, {"text": "Score 2 contains some relevant information from the lecture ...", "labels": [], "entities": []}, {"text": "The response significantly omits or misrepresents important points.", "labels": [], "entities": []}, {"text": "Score 1 provides little or no meaningful or relevant coherent content from the lecture.", "labels": [], "entities": []}, {"text": "The ultimate goal of our project is to improve automated scoring of such essays by taking into account the extent to which a response integrates important information from the lecture.", "labels": [], "entities": [{"text": "automated scoring of such essays", "start_pos": 47, "end_pos": 79, "type": "TASK", "confidence": 0.7522578716278077}]}, {"text": "This paper reports on the first step aimed at automatically assigning importance scores to parts of the lecture.", "labels": [], "entities": []}, {"text": "The next step -developing an essay scoring system using content importance models along with other features of writing quality, will be addressed in future work.", "labels": [], "entities": []}, {"text": "A simple essay scoring mechanism will be used for evaluation purposes in this paper, as described in the next section.", "labels": [], "entities": []}], "datasetContent": [{"text": "In evaluations of summarization algorithms, it is common practice to derive the gold standard content importance scores from human summaries, as done, for example, in the pyramid method, where the importance of a content element corresponds to the number of reference human summaries that make use of it ().", "labels": [], "entities": [{"text": "summarization", "start_pos": 18, "end_pos": 31, "type": "TASK", "confidence": 0.8462294936180115}]}, {"text": "Selection of the appropriate content plays a crucial role in attaining a high score for the essays we consider here, as suggested by the quotes from the scoring rubric in \u00a71, as well as by a corpus study by.", "labels": [], "entities": []}, {"text": "We therefore observe that high-scoring essays can bethought of as high-quality human summaries of the lecture, albeit containing, in addition, references to the reading material and language that contrasts the different viewpoints, making them a somewhat noisy gold standard.", "labels": [], "entities": []}, {"text": "On the other hand, since lowscoring essays contain deficient summaries of the lecture, our setup allows fora richer evaluation than typical in studies using gold standard human data only, in that a good model should not only agree with the gold standard human summaries but should also disagree with sub-standard human summaries.", "labels": [], "entities": []}, {"text": "We therefore use correlation with essay score to evaluate content importance models.", "labels": [], "entities": []}, {"text": "The evaluation will proceed as follows.", "labels": [], "entities": []}, {"text": "Every essay E is responding to a test prompt that contains a lecture Land a reading R.", "labels": [], "entities": []}, {"text": "We identify the essay's overlap with the lecture: where the exact definition of x, that is, what is taken to be a single unit of information, will be one of the parameters to be studied.", "labels": [], "entities": []}, {"text": "The essay is then assigned the following score by the content importance model M : where w M (x) is the importance weight assigned by model M to item x in the lecture, C(x, E) is the count of tokens in E that realize the information unit x, and n E is the number of tokens in the essay.", "labels": [], "entities": []}, {"text": "In this paper, the distinction between x and C is that between type and token count of instances of that type.", "labels": [], "entities": []}, {"text": "This simple scoring mechanism quantifies the rate of usage of important information per token in the essay.", "labels": [], "entities": []}, {"text": "Finally, we calculate the correlation of scores assigned to essays by model M with scores assigned to the same essays by human graders.", "labels": [], "entities": []}, {"text": "This design ensures that once x is fixed, all the content importance models are evaluated within the same scoring scheme, so any differences in the correlations can be attributed to the differences in the weights assigned by the importance models.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Distribution of essay scores.", "labels": [], "entities": [{"text": "Distribution of essay", "start_pos": 10, "end_pos": 31, "type": "TASK", "confidence": 0.8117084304491679}]}, {"text": " Table 2: Correlations with essay scores attained by  content models, for various definitions of informa- tion unit (n-grams with n = 1, 2, 3, 4). Five top  scores are boldfaced. The baseline performance  is shown in underlined italics. Correlations that  are significantly better (p < 0.05) than the na\u00a8\u0131vena\u00a8\u0131ve  n = 1 model are marked with an asterisk. We  use McNemar (1955, p. 148) test for significance  of difference between same-sample correlations.  N = 85, 252 for all correlations.", "labels": [], "entities": [{"text": "N", "start_pos": 459, "end_pos": 460, "type": "METRIC", "confidence": 0.9841395616531372}]}]}