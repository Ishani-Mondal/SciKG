{"title": [{"text": "Robust Logistic Regression using Shift Parameters", "labels": [], "entities": [{"text": "Robust Logistic Regression", "start_pos": 0, "end_pos": 26, "type": "TASK", "confidence": 0.8274043401082357}]}], "abstractContent": [{"text": "Annotation errors can significantly hurt classifier performance, yet datasets are only growing noisier with the increased use of Amazon Mechanical Turk and techniques like distant supervision that automatically generate labels.", "labels": [], "entities": [{"text": "Amazon Mechanical Turk", "start_pos": 129, "end_pos": 151, "type": "DATASET", "confidence": 0.9018697539965311}]}, {"text": "In this paper, we present a robust extension of logistic regression that incorporates the possibility of mislabelling directly into the objective.", "labels": [], "entities": []}, {"text": "This model can be trained through nearly the same means as logistic regression , and retains its efficiency on high-dimensional datasets.", "labels": [], "entities": []}, {"text": "We conduct experiments on named entity recognition data and find that our approach can provide a significant improvement over the standard model when annotation errors are present.", "labels": [], "entities": [{"text": "named entity recognition", "start_pos": 26, "end_pos": 50, "type": "TASK", "confidence": 0.6194849014282227}]}], "introductionContent": [{"text": "Almost any large dataset has annotation errors, especially those complex, nuanced datasets commonly used in natural language processing.", "labels": [], "entities": []}, {"text": "Lowquality annotations have become even more common in recent years with the rise of Amazon Mechanical Turk, as well as methods like distant supervision and co-training that involve automatically generating training data.", "labels": [], "entities": [{"text": "Amazon Mechanical Turk", "start_pos": 85, "end_pos": 107, "type": "DATASET", "confidence": 0.9426234364509583}]}, {"text": "Although small amounts of noise may not be detrimental, in some applications the level can be high: upon manually inspecting a relation extraction corpus commonly used in distant supervision, report a 31% false positive rate.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 127, "end_pos": 146, "type": "TASK", "confidence": 0.7329330742359161}]}, {"text": "In cases like these, annotation errors have frequently been observed to hurt performance., for example, conduct error analysis on a system to extract relations from biomedical text, and observe that over half of the system's errors could be attributed to inconsistencies in how the data was annotated.", "labels": [], "entities": []}, {"text": "Similarly, in a case study on co-training for natural language tasks, find that the degradation in data quality from automatic labelling prevents these systems from performing comparably to their fully-supervised counterparts.", "labels": [], "entities": []}, {"text": "In this work we argue that incorrect examples should be explicitly modelled during training, and present a simple extension of logistic regression that incorporates the possibility of mislabelling directly into the objective.", "labels": [], "entities": []}, {"text": "Following a technique from robust statistics, our model introduces sparse 'shift parameters' to allow datapoints to slide along the sigmoid, changing class if appropriate.", "labels": [], "entities": []}, {"text": "It has a convex objective, is well-suited to high-dimensional data, and can be efficiently trained with minimal changes to the logistic regression pipeline.", "labels": [], "entities": []}, {"text": "In experiments on a large, noisy NER dataset, we find that this method can provide an improvement over standard logistic regression when annotation errors are present.", "labels": [], "entities": [{"text": "NER dataset", "start_pos": 33, "end_pos": 44, "type": "DATASET", "confidence": 0.8258292078971863}]}, {"text": "The model also provides a means to identify which examples were mislabelled: through experiments on biological data, we demonstrate how our method can be used to accurately identify annotation errors.", "labels": [], "entities": []}, {"text": "This robust extension of logistic regression shows particular promise for NLP applications: it helps account for incorrect labels, while remaining efficient on large, high-dimensional datasets.", "labels": [], "entities": []}], "datasetContent": [{"text": "We conduct two sets of experiments to assess the effectiveness of the approach, in terms of both identifying mislabelled examples and producing accurate predictions.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Performance of standard vs. robust logis- tic regression in the Wikipedia NER experiment.  The flipping model refers to the approach from  Bootkrajang and Kaban (2012).", "labels": [], "entities": [{"text": "Wikipedia NER experiment", "start_pos": 74, "end_pos": 98, "type": "DATASET", "confidence": 0.8752543727556864}]}]}