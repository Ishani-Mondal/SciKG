{"title": [{"text": "Is this a wampimuk? Cross-modal mapping between distributional semantics and the visual world", "labels": [], "entities": []}], "abstractContent": [{"text": "Following upon recent work on establishing a mapping between vector-based semantic embeddings of words and the visual representations of the corresponding objects from natural images, we first present a simple approach to cross-modal vector-based semantics for the task of zero-shot learning, in which an image of a previously unseen object is mapped to a linguistic representation denoting its word.", "labels": [], "entities": []}, {"text": "We then introduce fast mapping, a challenging and more cognitively plausible variant of the zero-shot task, in which the learner is exposed to new objects and the corresponding words in very limited linguistic contexts.", "labels": [], "entities": []}, {"text": "By combining prior linguistic and visual knowledge acquired about words and their objects, as well as exploiting the limited new evidence available , the learner must learn to associate new objects with words.", "labels": [], "entities": []}, {"text": "Our results on this task pave the way to realistic simulations of how children or robots could use existing knowledge to bootstrap grounded semantic knowledge about new concepts.", "labels": [], "entities": []}], "introductionContent": [{"text": "Computational models of meaning that rely on corpus-extracted context vectors, such as LSA), HAL, Topic Models () and more recent neural-network approaches) have successfully tackled a number of lexical semantics tasks, where context vector similarity highly correlates with various indices of semantic relatedness.", "labels": [], "entities": []}, {"text": "Given that these models are learned from naturally occurring data using simple associative techniques, various authors have advanced the claim that they might be also capturing some crucial aspects of how humans acquire and use language.", "labels": [], "entities": []}, {"text": "However, the models induce the meaning of words entirely from their co-occurrence with other words, without links to the external world.", "labels": [], "entities": []}, {"text": "This constitutes a serious blow to claims of cognitive plausibility in at least two respects.", "labels": [], "entities": []}, {"text": "One is the grounding problem.", "labels": [], "entities": []}, {"text": "Irrespective of their relatively high performance on various semantic tasks, it is debatable whether models that have no access to visual and perceptual information can capture the holistic, grounded knowledge that humans have about concepts.", "labels": [], "entities": []}, {"text": "However, a possibly even more serious pitfall of vector models is lack of reference: natural language is, fundamentally, a means to communicate, and thus our words must be able to refer to objects, properties and events in the outside world.", "labels": [], "entities": []}, {"text": "Current vector models are purely language-internal, solipsistic models of meaning.", "labels": [], "entities": []}, {"text": "Consider the very simple scenario in which visual information is being provided to an agent about the current state of the world, and the agent's task is to determine the truth of a statement similar to There is a dog in the room.", "labels": [], "entities": []}, {"text": "Although the agent is equipped with a powerful context vector model, this will not suffice to successfully complete the task.", "labels": [], "entities": []}, {"text": "The model might suggest that the concepts of dog and cat are semantically related, but it has no means to determine the visual appearance of dogs, and consequently noway to verify the truth of such a simple statement.", "labels": [], "entities": []}, {"text": "Mapping words to the objects they denote is such a core function of language that humans are highly optimized for it, as shown by the so-called fast mapping phenomenon, whereby children can learn to associate a word to an objector property by a single exposure to it.", "labels": [], "entities": []}, {"text": "But lack of reference is not only a theoretical weakness: Without the ability to refer to the outside world, context vectors are arguably useless for practical goals such as learning to execute natural language instructions, that could greatly benefit from the rich network of lexical meaning such vectors encode, in order to scale up to real-life challenges.", "labels": [], "entities": []}, {"text": "Very recently, a number of papers have exploited advances in automated feature extraction form images and videos to enrich context vectors with visual information (.", "labels": [], "entities": []}, {"text": "This line of research tackles the grounding problem: Word representations are no longer limited to their linguistic contexts but also encode visual information present in images associated with the corresponding objects.", "labels": [], "entities": []}, {"text": "In this paper, we rely on the same image analysis techniques but instead focus on the reference problem: We do not aim at enriching word representations with visual information, although this might be aside effect of our approach, but we address the issue of automatically mapping objects, as depicted in images, to the context vectors representing the corresponding words.", "labels": [], "entities": []}, {"text": "This is achieved by means of a simple neural network trained to project image-extracted feature vectors to text-based vectors through a hidden layer that can be interpreted as a cross-modal semantic space.", "labels": [], "entities": []}, {"text": "We first test the effectiveness of our crossmodal semantic space on the so-called zero-shot learning task (, which has recently been explored in the machine learning community (.", "labels": [], "entities": []}, {"text": "In this setting, we assume that our system possesses linguistic and visual information fora set of concepts in the form of text-based representations of words and image-based vectors of the corresponding objects, used for vision-to-language-mapping training.", "labels": [], "entities": []}, {"text": "The system is then provided with visual information fora previously unseen object, and the task is to associate it with a word by cross-modal mapping.", "labels": [], "entities": []}, {"text": "Our approach is competitive with respect to the recently proposed alternatives, while being overall simpler.", "labels": [], "entities": []}, {"text": "The aforementioned task is very demanding and interesting from an engineering point of view.", "labels": [], "entities": []}, {"text": "However, from a cognitive angle, it relies on strong, unrealistic assumptions: The learner is asked to establish a link between anew object and a word for which they possess a full-fledged textbased vector extracted from a billion-word corpus.", "labels": [], "entities": []}, {"text": "On the contrary, the first time a learner is exposed to anew object, the linguistic information available is likely also very limited.", "labels": [], "entities": []}, {"text": "Thus, in order to consider vision-to-language mapping under more plausible conditions, similar to the ones that children or robots in anew environment are faced with, we next simulate a scenario akin to fast mapping.", "labels": [], "entities": []}, {"text": "We show that the induced cross-modal semantic space is powerful enough that sensible guesses about the correct word denoting an object can be made, even when the linguistic context vector representing the word has been created from as little as 1 sentence containing it.", "labels": [], "entities": []}, {"text": "The contributions of this work are three-fold.", "labels": [], "entities": []}, {"text": "First, we conduct experiments with simple imageand text-based vector representations and compare alternative methods to perform cross-modal mapping.", "labels": [], "entities": [{"text": "cross-modal mapping", "start_pos": 128, "end_pos": 147, "type": "TASK", "confidence": 0.711272343993187}]}, {"text": "Then, we complement recent work ( and show that zero-shot learning scales to a large and noisy dataset.", "labels": [], "entities": []}, {"text": "Finally, we provide preliminary evidence that cross-modal projections can be used effectively to simulate a fast mapping scenario, thus strengthening the claims of this approach as a full-fledged, fully inductive theory of meaning acquisition.", "labels": [], "entities": [{"text": "meaning acquisition", "start_pos": 223, "end_pos": 242, "type": "TASK", "confidence": 0.7359415590763092}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 2: Percentage accuracy among top k nearest  neighbors on CIFAR-100.", "labels": [], "entities": [{"text": "Percentage", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.9055076241493225}, {"text": "accuracy", "start_pos": 21, "end_pos": 29, "type": "METRIC", "confidence": 0.9315831065177917}, {"text": "CIFAR-100", "start_pos": 64, "end_pos": 73, "type": "DATASET", "confidence": 0.9457177519798279}]}, {"text": " Table 3: Categorization induced by the hidden layer of the NN; concepts belonging in the same CIFAR- 100 categories, reported in the last column, are marked in bold. Example: Unit 1 receives the highest  activation during training by the category flowers and at test time by butterfly, belonging to insects. The  same unit receives the second highest activation by the \"correct\" test concept, the flower rose.", "labels": [], "entities": [{"text": "CIFAR- 100 categories", "start_pos": 95, "end_pos": 116, "type": "DATASET", "confidence": 0.8631864041090012}]}, {"text": " Table 5: Percentage accuracy among top k nearest  neighbors on ESP.", "labels": [], "entities": [{"text": "Percentage", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.8976998925209045}, {"text": "accuracy", "start_pos": 21, "end_pos": 29, "type": "METRIC", "confidence": 0.9154917597770691}, {"text": "ESP", "start_pos": 64, "end_pos": 67, "type": "DATASET", "confidence": 0.7764782905578613}]}, {"text": " Table 6: Top-ranked concepts in cases where the  gold concepts received numerically high ranks.", "labels": [], "entities": []}, {"text": " Table 7: Mean rank results averaged across 34  concepts when mapping an image-based vector  and retrieving its linguistic neighbors (v \u2192 w) as  well as when mapping a text-based vector and  retrieving its visual neighbors (w \u2192 v). Lower  numbers cue better performance.", "labels": [], "entities": [{"text": "Mean rank", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9611025750637054}]}]}