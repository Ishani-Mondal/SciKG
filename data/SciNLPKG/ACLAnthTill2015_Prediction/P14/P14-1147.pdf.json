{"title": [{"text": "Towards a General Rule for Identifying Deceptive Opinion Spam", "labels": [], "entities": [{"text": "Identifying Deceptive Opinion Spam", "start_pos": 27, "end_pos": 61, "type": "TASK", "confidence": 0.915262296795845}]}], "abstractContent": [{"text": "Consumers' purchase decisions are increasingly influenced by user-generated online reviews.", "labels": [], "entities": []}, {"text": "Accordingly, there has been growing concern about the potential for posting deceptive opinion spam-fictitious reviews that have been deliberately written to sound authentic, to deceive the reader.", "labels": [], "entities": []}, {"text": "In this paper, we explore generalized approaches for identifying online deceptive opinion spam based on anew gold standard dataset, which is comprised of data from three different domains (i.e. Hotel, Restaurant, Doctor), each of which contains three types of reviews , i.e. customer generated truthful reviews , Turker generated deceptive reviews and employee (domain-expert) generated deceptive reviews.", "labels": [], "entities": [{"text": "identifying online deceptive opinion spam", "start_pos": 53, "end_pos": 94, "type": "TASK", "confidence": 0.7478033900260925}]}, {"text": "Our approach tries to capture the general difference of language usage between deceptive and truthful reviews , which we hope will help customers when making purchase decisions and review portal operators, such as TripAdvisor or Yelp, investigate possible fraudulent activity on their sites.", "labels": [], "entities": [{"text": "Yelp", "start_pos": 229, "end_pos": 233, "type": "DATASET", "confidence": 0.6565434336662292}]}], "introductionContent": [{"text": "Consumers increasingly rely on user-generated online reviews when making purchase decision.", "labels": [], "entities": []}, {"text": "Unfortunately, the ease of posting content to the Web, potentially anonymously, creates opportunities and incentives for unscrupulous businesses to post deceptive opinion spam-fictitious reviews that are deliberately written to sound authentic, in order to deceive the reader.", "labels": [], "entities": []}, {"text": "Accordingly, there appears Dataset available by request from the first author.", "labels": [], "entities": []}, {"text": "Manipulating online reviews may also have legal consequences.", "labels": [], "entities": []}, {"text": "For example, the Federal Trade Commission to be widespread and growing concern among both businesses and the public about this potential abuse.", "labels": [], "entities": []}, {"text": "Existing approaches for spam detection are usually focused on developing supervised learningbased algorithms to help users identify deceptive opinion spam, which are highly dependent upon high-quality gold-standard labeled data.", "labels": [], "entities": [{"text": "spam detection", "start_pos": 24, "end_pos": 38, "type": "TASK", "confidence": 0.9822759926319122}]}, {"text": "Studies in the literature rely on a couple of approaches for obtaining labeled data, which usually fall into two categories.", "labels": [], "entities": []}, {"text": "The first relies on the judgements of human annotators ().", "labels": [], "entities": []}, {"text": "However, recent studies show that deceptive opinion spam is not easily identified by human readers).", "labels": [], "entities": []}, {"text": "An alternative approach, as introduced by, crowdsourced deceptive reviews using Amazon Mechanical Turk.", "labels": [], "entities": [{"text": "Amazon Mechanical Turk", "start_pos": 80, "end_pos": 102, "type": "DATASET", "confidence": 0.923499325911204}]}, {"text": "A couple of follow-up works have been introduced based on Ott et al.'s dataset, including estimating prevalence of deception in online reviews, identification of negative deceptive opinion spam , and identifying manipulated offerings (.", "labels": [], "entities": [{"text": "Ott et al.'s dataset", "start_pos": 58, "end_pos": 78, "type": "DATASET", "confidence": 0.7467900514602661}, {"text": "estimating prevalence of deception in online reviews", "start_pos": 90, "end_pos": 142, "type": "TASK", "confidence": 0.6702540985175541}, {"text": "identification of negative deceptive opinion spam", "start_pos": 144, "end_pos": 193, "type": "TASK", "confidence": 0.8315389057000478}]}, {"text": "Despite the advantages of soliciting deceptive gold-standard material from Turkers (it is easy, large-scale, and affordable), it is unclear whether Turkers are representative of the general population that generate fake reviews, or in other words, Ott et al.'s data set may correspond to only one type of online deceptive opinion spam -fake reviews generated by people who have never been to offerings or experienced the entities.", "labels": [], "entities": [{"text": "Ott et al.'s data set", "start_pos": 248, "end_pos": 269, "type": "DATASET", "confidence": 0.6944409097943988}]}, {"text": "Specifically, according to their findings has updated their guidelines on the use of endorsements and testimonials in advertising to suggest that posting deceptive reviews maybe unlawful in the United States.", "labels": [], "entities": []}, {"text": "3 http://www.mturk.com), truthful hotel reviews encode more spatial details, characterized by terms such as \"bathroom\" and \"location\", while deceptive reviews talk about general concepts such as why or with whom they went to the hotel.", "labels": [], "entities": []}, {"text": "However, a hotel can instead solicit fake reviews from their employees or customers who possess substantial domain knowledge to write fake reviews and encode more spatial details in their lies.", "labels": [], "entities": []}, {"text": "Indeed, cases have been reported where hotel owners bribe guests in return for good reviews on TripAdvisor 4 , or companies ordered employees to pretend they were satisfied customers and write glowing reviews of its face-lift procedure on Web sites.", "labels": [], "entities": [{"text": "TripAdvisor 4", "start_pos": 95, "end_pos": 108, "type": "DATASET", "confidence": 0.9152889847755432}]}, {"text": "The domain knowledge possessed by domain experts enables them to craft reviews that are much more difficult for classifiers to detect, compared to the crowdsourced fake reviews.", "labels": [], "entities": []}, {"text": "Additionally, existing supervised algorithms in the literature are usually narrowed to one specific domain and heavily rely on domain-specific vocabulary.", "labels": [], "entities": []}, {"text": "For example, classifiers assign high weights to domain-specific terms such as \"hotel\", \"rooms\", or even the name of the hotels such as \"Hilton\" when trained on reviews on hotels.", "labels": [], "entities": []}, {"text": "It is unclear whether these classifiers will perform well at detecting deception in other domains, e.g., Restaurant or Doctor reviews.", "labels": [], "entities": [{"text": "detecting deception", "start_pos": 61, "end_pos": 80, "type": "TASK", "confidence": 0.7856204509735107}]}, {"text": "Even in a single domain, e.g., Hotel, classifiers trained from reviews of one city (e.g., Chicago) may not be effective if directly applied to reviews from other cities (e.g., New York City) ().", "labels": [], "entities": []}, {"text": "In the examples in, we trained a linear SVM classifier on Ott's Chicago-hotel dataset on unigram features and tested it on a couple of different domains (the details of data acquisition are illustrated in Section 3).", "labels": [], "entities": [{"text": "Ott's Chicago-hotel dataset", "start_pos": 58, "end_pos": 85, "type": "DATASET", "confidence": 0.8791127949953079}]}, {"text": "Good performance is obtained on Chicago-hotel reviews), but not as good on New York City ones.", "labels": [], "entities": []}, {"text": "The performance is reasonable in Restaurant reviews due to the many shared properties among restaurants and hotels, but suffers in Doctor settings.", "labels": [], "entities": []}, {"text": "In this paper, we try to obtain a deeper understanding of the general nature of deceptive opinion spam.", "labels": [], "entities": [{"text": "deceptive opinion spam", "start_pos": 80, "end_pos": 102, "type": "TASK", "confidence": 0.6059076388676962}]}, {"text": "One contribution of the work presented here is the creation of the cross-domain (i.e., Hotel, Restaurant and Doctor) gold-standard dataset.", "labels": [], "entities": [{"text": "Doctor) gold-standard dataset", "start_pos": 109, "end_pos": 138, "type": "DATASET", "confidence": 0.7880492806434631}]}, {"text": "To explore the general rule of deceptive opinion spam, we extended SAGE Model), a bayesian generative approach that can capture the multiple generative facets (i.e., deceptive vs truthful, positive vs negative, experienced vs non-experienced, hotel vs restaurant vs doctor) in the text collection.", "labels": [], "entities": []}, {"text": "We find that more general features, such as LIWC and POS, are more robust when modeled using SAGE, compared with just bag-of-words.", "labels": [], "entities": []}, {"text": "We additionally make theoretical contributions that may shed light on a longstanding debate in the literature about deception.", "labels": [], "entities": []}, {"text": "For example, in contrast to existing findings that highlight the lack of spatial detail in deceptive reviews, we find that alack of spatial detail may not be a universal cue to deception, since it does not apply to fake reviews written by domain experts.", "labels": [], "entities": []}, {"text": "Instead, our finding suggest that other linguistic features may offer more robust cues to deceptive opinion spam, such as overly highlighted sentiment in the review or the overuse of firstperson singular pronouns.", "labels": [], "entities": []}, {"text": "The rest of this paper is organized as follows.", "labels": [], "entities": []}, {"text": "In Section 2, we briefly go over related work.", "labels": [], "entities": []}, {"text": "We describe the creation of our data set in Section 3 and present our model in Section 4.", "labels": [], "entities": []}, {"text": "Experimental results are shown in Section 5.", "labels": [], "entities": []}, {"text": "We present analysis of general cues to deception in Section 6 and conclude this paper in Section 7.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section, we report our efforts to gather goldstandard opinion spam datasets.", "labels": [], "entities": []}, {"text": "Our datasets contain the following domains, namely Hotel, Restaurant, and Doctor.", "labels": [], "entities": [{"text": "Doctor", "start_pos": 74, "end_pos": 80, "type": "METRIC", "confidence": 0.5193661451339722}]}, {"text": "In this section, we report our experimental results.", "labels": [], "entities": []}, {"text": "We first restrict experiments to the within-domain task and see what features most characterize the deceptive reviews, and how.", "labels": [], "entities": []}, {"text": "We later extend it to cross domains to explore a more general classifier of deceptive opinion spam.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: SVM performance on datasets for a clas- sifier trained on Chicago hotel review based on  Unigram feature.", "labels": [], "entities": []}, {"text": " Table 2: Statistics for our dataset.", "labels": [], "entities": []}, {"text": " Table 3: Within-domain multi-class classifier performance.", "labels": [], "entities": []}, {"text": " Table 4: Classifier performance in cross-domain adaptation.", "labels": [], "entities": [{"text": "cross-domain adaptation", "start_pos": 36, "end_pos": 59, "type": "TASK", "confidence": 0.7582786083221436}]}]}