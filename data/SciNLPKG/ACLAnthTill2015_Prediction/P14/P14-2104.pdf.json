{"title": [{"text": "Training a Korean SRL System with Rich Morphological Features", "labels": [], "entities": [{"text": "Korean SRL System", "start_pos": 11, "end_pos": 28, "type": "DATASET", "confidence": 0.7689908742904663}]}], "abstractContent": [{"text": "In this paper we introduce a semantic role labeler for Korean, an agglutinative language with rich morphology.", "labels": [], "entities": []}, {"text": "First, we create a novel training source by semantically annotating a Korean corpus containing fine-grained morphological and syntactic information.", "labels": [], "entities": []}, {"text": "We then develop a supervised SRL model by leveraging morphological features of Korean that tend to correspond with semantic roles.", "labels": [], "entities": [{"text": "SRL", "start_pos": 29, "end_pos": 32, "type": "TASK", "confidence": 0.9905683398246765}]}, {"text": "Our model also employs a variety of latent morpheme representations induced from a larger body of unannotated Korean text.", "labels": [], "entities": []}, {"text": "These elements lead to state-of-the-art performance of 81.07% labeled F1, representing the best SRL performance reported to date for an agglutinative language.", "labels": [], "entities": [{"text": "F1", "start_pos": 70, "end_pos": 72, "type": "METRIC", "confidence": 0.9866092801094055}]}], "introductionContent": [{"text": "Semantic Role Labeling (SRL) is the task of automatically annotating the predicate-argument structure in a sentence with semantic roles.", "labels": [], "entities": [{"text": "Semantic Role Labeling (SRL)", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.8193482756614685}]}, {"text": "Ever since, SRL has become an important technology used in applications requiring semantic interpretation, ranging from information extraction  and question answering (, to practical problems including textual entailment ( and pictorial communication systems (.", "labels": [], "entities": [{"text": "SRL", "start_pos": 12, "end_pos": 15, "type": "TASK", "confidence": 0.9760076403617859}, {"text": "semantic interpretation", "start_pos": 82, "end_pos": 105, "type": "TASK", "confidence": 0.7464706897735596}, {"text": "information extraction", "start_pos": 120, "end_pos": 142, "type": "TASK", "confidence": 0.7609943449497223}, {"text": "question answering", "start_pos": 148, "end_pos": 166, "type": "TASK", "confidence": 0.8563604056835175}, {"text": "textual entailment", "start_pos": 202, "end_pos": 220, "type": "TASK", "confidence": 0.7147667855024338}]}, {"text": "SRL systems in many languages have been developed as the necessary linguistic resources become available).", "labels": [], "entities": [{"text": "SRL", "start_pos": 0, "end_pos": 3, "type": "TASK", "confidence": 0.9290714263916016}]}, {"text": "Seven languages were the subject of the CoNLL-2009 shared task in syntactic and semantic parsing).", "labels": [], "entities": [{"text": "syntactic and semantic parsing", "start_pos": 66, "end_pos": 96, "type": "TASK", "confidence": 0.5790515393018723}]}, {"text": "These languages can be categorized into three broad morphological types: fusional (4), analytic (2), and one agglutinative language.", "labels": [], "entities": []}, {"text": "Paul studies mathematics with Jane at a library Poleun doseogwaneseo Jeingwa suhageull gongbuhanda: English (SVO) and Korean (SOV) words alignment.", "labels": [], "entities": [{"text": "Korean (SOV) words alignment", "start_pos": 118, "end_pos": 146, "type": "TASK", "confidence": 0.6676165560881296}]}, {"text": "The subject, verb, and object are highlighted as red, blue, and green, respectively.", "labels": [], "entities": []}, {"text": "Also, prepositions and suffixes are highlighted as purple.", "labels": [], "entities": []}, {"text": "report an average labeled semantic F1-score of 80.80% across these languages.", "labels": [], "entities": [{"text": "labeled semantic F1-score", "start_pos": 18, "end_pos": 43, "type": "METRIC", "confidence": 0.5584366321563721}]}, {"text": "The highest performance was achieved for the analytic language group (82.12%), while the agglutinative language, Japanese, yielded the lowest performance (76.30%).", "labels": [], "entities": []}, {"text": "Agglutinative languages such as Japanese, Korean, and Turkish are computationally difficult due to word-form sparsity, variable word order, and the challenge of using rich morphological features.", "labels": [], "entities": []}, {"text": "In this paper, we describe a Korean SRL system which achieves 81% labeled semantic F1-score.", "labels": [], "entities": [{"text": "SRL", "start_pos": 36, "end_pos": 39, "type": "TASK", "confidence": 0.7520101070404053}, {"text": "labeled semantic F1-score", "start_pos": 66, "end_pos": 91, "type": "METRIC", "confidence": 0.8371080954869589}]}, {"text": "As far as we know, this is the highest accuracy obtained for Korean, as well as any agglutinative language.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 39, "end_pos": 47, "type": "METRIC", "confidence": 0.9985291957855225}]}, {"text": "displays a English/Korean sentence pair, highlighting the SOV word order of Korean as well as its rich morphological structure.", "labels": [], "entities": []}, {"text": "Two factors proved crucial in the performance of our SRL system: (i) The analysis of fine-grained morphological tags specific to Korean, and (ii) the use of latent stem and morpheme representations to deal with sparsity.", "labels": [], "entities": [{"text": "SRL", "start_pos": 53, "end_pos": 56, "type": "TASK", "confidence": 0.9541274905204773}]}, {"text": "We incorporated both of these elements in a CRF () role labeling model.", "labels": [], "entities": []}, {"text": "Besides the contribution of this model and SRL system, we also report on the creation and availability of anew semantically annotated Korean corpus, covering over 8,000 sentences.", "labels": [], "entities": [{"text": "SRL", "start_pos": 43, "end_pos": 46, "type": "TASK", "confidence": 0.8313825726509094}]}, {"text": "We used this corpus to develop, train, and test our Korean SRL model.", "labels": [], "entities": [{"text": "Korean SRL model", "start_pos": 52, "end_pos": 68, "type": "DATASET", "confidence": 0.8495761553446451}]}, {"text": "In the next section, we describe the process of corpus creation in more detail.", "labels": [], "entities": [{"text": "corpus creation", "start_pos": 48, "end_pos": 63, "type": "TASK", "confidence": 0.7514559030532837}]}], "datasetContent": [{"text": "We categorized our experiments by the scenarios below, and all results are summarized in.", "labels": [], "entities": []}, {"text": "The F1-score results were investigated for each scenario.", "labels": [], "entities": [{"text": "F1-score", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.9992765784263611}]}, {"text": "We randomly divided our data into 90% training and 10% test sets for all scenarios.", "labels": [], "entities": []}, {"text": "For latent morpheme representations, we used the Donga news article corpus.", "labels": [], "entities": [{"text": "Donga news article corpus", "start_pos": 49, "end_pos": 74, "type": "DATASET", "confidence": 0.9680503755807877}]}, {"text": "The Donga corpus contains 366,636 sentences with 25.09 words on average.", "labels": [], "entities": [{"text": "Donga corpus", "start_pos": 4, "end_pos": 16, "type": "DATASET", "confidence": 0.9610467851161957}]}, {"text": "The Domain of this corpus covers typical news articles such as health, entertainment, technology, politics, world and others.", "labels": [], "entities": []}, {"text": "We ran Kokoma Korean morpheme analyzer 4 on each sentence of the Donga corpus to divide words into morphemes to build latent morpheme representations.", "labels": [], "entities": [{"text": "Kokoma Korean morpheme analyzer", "start_pos": 7, "end_pos": 38, "type": "TASK", "confidence": 0.7241453379392624}, {"text": "Donga corpus", "start_pos": 65, "end_pos": 77, "type": "DATASET", "confidence": 0.9381828904151917}]}, {"text": "1st Scenario: We first tested on general features in previous work (2nd column in).", "labels": [], "entities": []}, {"text": "We achieved 64.83% and 66.88% on the PKPB and our corpus.", "labels": [], "entities": [{"text": "PKPB and our corpus", "start_pos": 37, "end_pos": 56, "type": "DATASET", "confidence": 0.8666969388723373}]}, {"text": "When the both corpora were combined, we had 64.86%.", "labels": [], "entities": []}, {"text": "2nd Scenario: We then added the Koreanspecific morphological features to signify its ap-3 http://www.donga.com 4 http://kkma.snu.ac.kr/ propriateness in this scenario.", "labels": [], "entities": []}, {"text": "These features increased greatly performance improvements (3rd column in).", "labels": [], "entities": []}, {"text": "Although both the PKPB and our corpus had improvements, the improvements were the most notable on our corpus.", "labels": [], "entities": [{"text": "PKPB", "start_pos": 18, "end_pos": 22, "type": "DATASET", "confidence": 0.9509741067886353}]}, {"text": "This is because PKPB POS tags might be too coarse.", "labels": [], "entities": []}, {"text": "We achieved 75.17%, 80.33%, and 78.61% on the PKPB, our corpus, and the combined one, respectively.", "labels": [], "entities": [{"text": "PKPB", "start_pos": 46, "end_pos": 50, "type": "DATASET", "confidence": 0.9778614640235901}]}, {"text": "3rd Scenario: This scenario is to reveal the effects of the different latent morpheme representations (4-6th columns in).", "labels": [], "entities": []}, {"text": "These three representations are from CCA, deep learning, and Brown clustering.", "labels": [], "entities": []}, {"text": "The results gave evidences that all representations increased the performance.", "labels": [], "entities": []}, {"text": "4th Scenario: We augmented our model with all kinds of features (the last column in).", "labels": [], "entities": []}, {"text": "We achieved our best F1-score of 81.07% overall scenarios on our corpus.", "labels": [], "entities": [{"text": "F1-score", "start_pos": 21, "end_pos": 29, "type": "METRIC", "confidence": 0.9993096590042114}]}], "tableCaptions": [{"text": " Table 1: Semantic roles in our annotated corpus.", "labels": [], "entities": []}, {"text": " Table 3: Experimental F1-score results on every experiment. Abbreviation on features are Gen: general  features, Kor: Korean specific features, LMR: latent morpheme representation features.", "labels": [], "entities": [{"text": "F1-score", "start_pos": 23, "end_pos": 31, "type": "METRIC", "confidence": 0.9961178302764893}]}]}