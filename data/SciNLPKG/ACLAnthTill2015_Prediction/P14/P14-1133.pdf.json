{"title": [], "abstractContent": [{"text": "A central challenge in semantic parsing is handling the myriad ways in which knowledge base predicates can be expressed.", "labels": [], "entities": [{"text": "semantic parsing", "start_pos": 23, "end_pos": 39, "type": "TASK", "confidence": 0.7697969079017639}]}, {"text": "Traditionally, semantic parsers are trained primarily from text paired with knowledge base information.", "labels": [], "entities": [{"text": "semantic parsers", "start_pos": 15, "end_pos": 31, "type": "TASK", "confidence": 0.7199105620384216}]}, {"text": "Our goal is to exploit the much larger amounts of raw text not tied to any knowledge base.", "labels": [], "entities": []}, {"text": "In this paper , we turn semantic parsing on its head.", "labels": [], "entities": [{"text": "semantic parsing", "start_pos": 24, "end_pos": 40, "type": "TASK", "confidence": 0.7871609330177307}]}, {"text": "Given an input utterance, we first use a simple method to deterministically generate a set of candidate logical forms with a canonical realization in natural language for each.", "labels": [], "entities": []}, {"text": "Then, we use a paraphrase model to choose the realization that best paraphrases the input, and output the corresponding logical form.", "labels": [], "entities": []}, {"text": "We present two simple paraphrase models, an association model and a vector space model, and train them jointly from question-answer pairs.", "labels": [], "entities": []}, {"text": "Our system PARASEMPRE improves state-of-the-art accuracies on two recently released question-answering datasets.", "labels": [], "entities": [{"text": "PARASEMPRE", "start_pos": 11, "end_pos": 21, "type": "METRIC", "confidence": 0.9769699573516846}]}], "introductionContent": [{"text": "We consider the semantic parsing problem of mapping natural language utterances into logical forms to be executed on a knowledge base (KB) (.", "labels": [], "entities": [{"text": "semantic parsing", "start_pos": 16, "end_pos": 32, "type": "TASK", "confidence": 0.748438835144043}]}, {"text": "Scaling semantic parsers to large knowledge bases has attracted substantial attention recently, since it drives applications such as question answering (QA) and information extraction (IE).", "labels": [], "entities": [{"text": "Scaling semantic parsers", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.9384701053301493}, {"text": "question answering (QA)", "start_pos": 133, "end_pos": 156, "type": "TASK", "confidence": 0.8610596656799316}, {"text": "information extraction (IE)", "start_pos": 161, "end_pos": 188, "type": "TASK", "confidence": 0.8469916820526123}]}, {"text": "Semantic parsers need to somehow associate natural language phrases with logical predicates, e.g., they must learn that the constructions \"What", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section, we evaluate our system on WE-BQUESTIONS and FREE917.", "labels": [], "entities": [{"text": "WE-BQUESTIONS", "start_pos": 43, "end_pos": 56, "type": "METRIC", "confidence": 0.9502625465393066}, {"text": "FREE917", "start_pos": 61, "end_pos": 68, "type": "METRIC", "confidence": 0.9772160053253174}]}, {"text": "After describing the setup (Section 6.1), we present our main empirical results and analyze the components of the system (Section 6.2).", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 4: Statistics on WEBQUESTIONS and FREE917.", "labels": [], "entities": [{"text": "WEBQUESTIONS", "start_pos": 24, "end_pos": 36, "type": "DATASET", "confidence": 0.5272882580757141}, {"text": "FREE917", "start_pos": 41, "end_pos": 48, "type": "METRIC", "confidence": 0.8184285163879395}]}, {"text": " Table 5: Results on the test set.", "labels": [], "entities": []}, {"text": " Table 6: Results for ablations and baselines on develop-", "labels": [], "entities": [{"text": "develop", "start_pos": 49, "end_pos": 56, "type": "DATASET", "confidence": 0.8551114201545715}]}]}