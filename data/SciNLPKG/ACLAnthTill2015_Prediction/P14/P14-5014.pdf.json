{"title": [{"text": "KyotoEBMT: An Example-Based Dependency-to-Dependency Translation Framework", "labels": [], "entities": [{"text": "KyotoEBMT", "start_pos": 0, "end_pos": 9, "type": "DATASET", "confidence": 0.9046227335929871}, {"text": "Example-Based Dependency-to-Dependency Translation", "start_pos": 14, "end_pos": 64, "type": "TASK", "confidence": 0.6061556041240692}]}], "abstractContent": [{"text": "This paper introduces the Ky-otoEBMT Example-Based Machine Translation framework.", "labels": [], "entities": [{"text": "Ky-otoEBMT Example-Based Machine Translation", "start_pos": 26, "end_pos": 70, "type": "TASK", "confidence": 0.5465001240372658}]}, {"text": "Our system uses a tree-to-tree approach, employing syntactic dependency analysis for both source and target languages in an attempt to preserve non-local structure.", "labels": [], "entities": []}, {"text": "The effectiveness of our system is maximized with online example matching and a flexible decoder.", "labels": [], "entities": [{"text": "online example matching", "start_pos": 50, "end_pos": 73, "type": "TASK", "confidence": 0.605321059624354}]}, {"text": "Evaluation demonstrates BLEU scores competitive with state-of-the-art SMT systems such as Moses.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 24, "end_pos": 28, "type": "METRIC", "confidence": 0.9975493550300598}, {"text": "SMT", "start_pos": 70, "end_pos": 73, "type": "TASK", "confidence": 0.9870245456695557}]}, {"text": "The current implementation is intended to be released as open-source in the near future.", "labels": [], "entities": []}], "introductionContent": [{"text": "Corpus-based approaches have become a major focus of Machine Translation research.", "labels": [], "entities": [{"text": "Machine Translation", "start_pos": 53, "end_pos": 72, "type": "TASK", "confidence": 0.9041556119918823}]}, {"text": "We present here a fully-fledged ExampleBased Machine Translation (EBMT) platform making use of both source-language and target-language dependency structure.", "labels": [], "entities": [{"text": "ExampleBased Machine Translation (EBMT)", "start_pos": 32, "end_pos": 71, "type": "TASK", "confidence": 0.7686761319637299}]}, {"text": "This paradigm has been explored comparatively less, as studies on Syntactic-based SMT/EBMT tend to focus on constituent trees rather than dependency trees, and on tree-to-string rather than tree-to-tree approaches.", "labels": [], "entities": [{"text": "Syntactic-based SMT/EBMT", "start_pos": 66, "end_pos": 90, "type": "TASK", "confidence": 0.730089396238327}]}, {"text": "Furthermore, we employ separate dependency parsers for each language rather than projecting the dependencies from one language to another, as in).", "labels": [], "entities": []}, {"text": "The dependency structure information is used end-to-end: for improving the quality of the alignment of the translation examples, for constraining the translation rule extraction and for guiding the decoding.", "labels": [], "entities": [{"text": "translation rule extraction", "start_pos": 150, "end_pos": 177, "type": "TASK", "confidence": 0.7454946835835775}]}, {"text": "We believe that dependency structure, which considers more than just local context, is important in order to generate fluent and accurate translations of complex sentences across distant language pairs.", "labels": [], "entities": [{"text": "dependency structure", "start_pos": 16, "end_pos": 36, "type": "TASK", "confidence": 0.7616722285747528}]}, {"text": "Our experiments focus on technical domain translation for Japanese-Chinese and Japanese-English, however our implementation is applicable to any domain and language pair for which there exist translation examples and dependency parsers.", "labels": [], "entities": [{"text": "technical domain translation", "start_pos": 25, "end_pos": 53, "type": "TASK", "confidence": 0.6786072055498759}]}, {"text": "A further unique characteristic of our system is that, again contrary to the majority of similar systems, it does not rely on precomputation of translation rules.", "labels": [], "entities": []}, {"text": "Instead it matches each input sentence to the full database of translation examples before extracting translation rules online.", "labels": [], "entities": []}, {"text": "This has the merit of maximizing the information available when creating and combining translation rules, while retaining the ability to produce excellent translations for input sentences similar to an existing translation example.", "labels": [], "entities": []}, {"text": "The system is mostly developed in C++ and incorporates a web-based translation interface for ease of use.", "labels": [], "entities": []}, {"text": "The web interface (see) also displays information useful for error analysis such as the list of translation examples used.", "labels": [], "entities": [{"text": "error analysis", "start_pos": 61, "end_pos": 75, "type": "TASK", "confidence": 0.6538797169923782}]}, {"text": "Experiments are facilitated through the inclusion of a curses-based graphical interface for performing tuning and evaluation.", "labels": [], "entities": []}, {"text": "The decoder supports multiple threads.", "labels": [], "entities": []}, {"text": "We are currently making preparations for the project to be released with an opensource license.", "labels": [], "entities": []}, {"text": "The code will be available at http://nlp.ist.i.kyoto-u.ac.jp/kyotoebmt/.", "labels": [], "entities": []}, {"text": "shows the basic structure of the proposed translation pipeline.", "labels": [], "entities": [{"text": "translation pipeline", "start_pos": 42, "end_pos": 62, "type": "TASK", "confidence": 0.9347249567508698}]}], "datasetContent": [{"text": "In order to evaluate our system, we conducted translation experiments on four language pairs: Japanese-English (JA-EN), EnglishJapanese (EN-JA), Japanese-Chinese (JA-ZH) and Chinese-Japanese (ZH-JA).", "labels": [], "entities": []}, {"text": "For Japanese-English, we evaluated on the NTCIR-10 PatentMT task data (patents) () and compared our system with the official baseline scores.", "labels": [], "entities": [{"text": "NTCIR-10 PatentMT task data", "start_pos": 42, "end_pos": 69, "type": "DATASET", "confidence": 0.8278140425682068}]}, {"text": "For JapaneseChinese, we used parallel scientific paper excerpts from the ASPEC 5 corpus and compared against the same baseline system as for Japanese-English.", "labels": [], "entities": [{"text": "JapaneseChinese", "start_pos": 4, "end_pos": 19, "type": "DATASET", "confidence": 0.915302574634552}, {"text": "ASPEC 5 corpus", "start_pos": 73, "end_pos": 87, "type": "DATASET", "confidence": 0.7334721684455872}]}, {"text": "The corpora contain 3M parallel sentences for Japanese-English and 670K for Japanese-Chinese.", "labels": [], "entities": []}, {"text": "The two baseline systems are based on the open-source GIZA++/Moses pipeline.", "labels": [], "entities": [{"text": "GIZA++/Moses pipeline", "start_pos": 54, "end_pos": 75, "type": "DATASET", "confidence": 0.8837303519248962}]}, {"text": "The baseline labeled \"Moses\" uses the classic phrase-based engine, while \"Moses-Hiero\" uses the Hierarchical Phrase-Based decoder.", "labels": [], "entities": []}, {"text": "These Further, the expansion stroke, the sectional area of the inner tube 12, and the oil is supplied to the lower oil chamber S2 from the oil reservoir chamber R \u00d7 stroke.", "labels": [], "entities": [{"text": "expansion stroke", "start_pos": 19, "end_pos": 35, "type": "METRIC", "confidence": 0.9680459201335907}]}], "tableCaptions": []}