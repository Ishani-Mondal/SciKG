{"title": [{"text": "Sentence Level Dialect Identification for Machine Translation System Selection", "labels": [], "entities": [{"text": "Sentence Level Dialect Identification", "start_pos": 0, "end_pos": 37, "type": "TASK", "confidence": 0.8819108009338379}, {"text": "Machine Translation", "start_pos": 42, "end_pos": 61, "type": "TASK", "confidence": 0.7970306277275085}]}], "abstractContent": [{"text": "In this paper we study the use of sentence-level dialect identification in optimizing machine translation system selection when translating mixed dialect input.", "labels": [], "entities": [{"text": "sentence-level dialect identification", "start_pos": 34, "end_pos": 71, "type": "TASK", "confidence": 0.6058483123779297}, {"text": "machine translation system selection", "start_pos": 86, "end_pos": 122, "type": "TASK", "confidence": 0.8207345083355904}, {"text": "translating mixed dialect input", "start_pos": 128, "end_pos": 159, "type": "TASK", "confidence": 0.8542635440826416}]}, {"text": "We test our approach on Arabic, a prototypical diglossic language; and we optimize the combination of four different machine translation systems.", "labels": [], "entities": []}, {"text": "Our best result improves over the best single MT system baseline by 1.0% BLEU and over a strong system selection baseline by 0.6% BLEU on a blind test set.", "labels": [], "entities": [{"text": "MT", "start_pos": 46, "end_pos": 48, "type": "TASK", "confidence": 0.9485462307929993}, {"text": "BLEU", "start_pos": 73, "end_pos": 77, "type": "METRIC", "confidence": 0.9995582699775696}, {"text": "BLEU", "start_pos": 130, "end_pos": 134, "type": "METRIC", "confidence": 0.9991962313652039}]}], "introductionContent": [{"text": "A language can be described as a set of dialects, among which one \"standard variety\" has a special representative status.", "labels": [], "entities": []}, {"text": "Despite being increasingly ubiquitous in informal written genres such as social media, most non-standard dialects are resource-poor compared to their standard variety.", "labels": [], "entities": []}, {"text": "For statistical machine translation (MT), which relies on the existence of parallel data, translating from non-standard dialects is a challenge.", "labels": [], "entities": [{"text": "statistical machine translation (MT)", "start_pos": 4, "end_pos": 40, "type": "TASK", "confidence": 0.8235487888256708}]}, {"text": "In this paper we study the use of sentence-level dialect identification together with various linguistic features in optimizing the selection of outputs of four different MT systems on input text that includes a mix of dialects.", "labels": [], "entities": [{"text": "sentence-level dialect identification", "start_pos": 34, "end_pos": 71, "type": "TASK", "confidence": 0.6563978592554728}, {"text": "MT", "start_pos": 171, "end_pos": 173, "type": "TASK", "confidence": 0.9684744477272034}]}, {"text": "We test our approach on Arabic, a prototypical diglossic language where the standard form of the language, Modern Standard Arabic (MSA) and the regional dialects (DA) live side-by-side and are closely related.", "labels": [], "entities": []}, {"text": "MSA is the language used in education, scripted speech and official settings while DA is the primarily spoken native vernacular.", "labels": [], "entities": []}, {"text": "We consider two DAs: Egyptian and Levantine Arabic in addition to MSA.", "labels": [], "entities": [{"text": "MSA", "start_pos": 66, "end_pos": 69, "type": "DATASET", "confidence": 0.8996596932411194}]}, {"text": "Our best system selection approach improves over our best baseline single MT system by 1.0% absolute BLEU point on a blind test set.", "labels": [], "entities": [{"text": "MT", "start_pos": 74, "end_pos": 76, "type": "TASK", "confidence": 0.942371129989624}, {"text": "BLEU", "start_pos": 101, "end_pos": 105, "type": "METRIC", "confidence": 0.9747558236122131}]}], "datasetContent": [{"text": "In this section, we present our MT experimental setup and the four baseline systems we built, and we evaluate their performance and the potential of their combination.", "labels": [], "entities": [{"text": "MT", "start_pos": 32, "end_pos": 34, "type": "TASK", "confidence": 0.9797530174255371}]}, {"text": "In the next section we present and evaluate the system selection approach.", "labels": [], "entities": [{"text": "system selection", "start_pos": 48, "end_pos": 64, "type": "TASK", "confidence": 0.7876493334770203}]}, {"text": "We use the open-source Moses toolkit () to build four Arabic-English phrase-based statistical machine translation systems (SMT).", "labels": [], "entities": [{"text": "statistical machine translation systems (SMT)", "start_pos": 82, "end_pos": 127, "type": "TASK", "confidence": 0.6543245358126504}]}, {"text": "Our systems use a standard phrase-based architecture.", "labels": [], "entities": []}, {"text": "The parallel corpora are word-aligned using GIZA++).", "labels": [], "entities": []}, {"text": "The language model for our systems is trained on English Gigaword (.", "labels": [], "entities": []}, {"text": "We use SRILM Toolkit to build a 5-gram language model with modified Kneser-Ney smoothing.", "labels": [], "entities": [{"text": "SRILM Toolkit", "start_pos": 7, "end_pos": 20, "type": "DATASET", "confidence": 0.8415327668190002}]}, {"text": "Feature weights are tuned to maximize BLEU on tuning sets using Minimum Error Rate Training.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 38, "end_pos": 42, "type": "METRIC", "confidence": 0.999503493309021}, {"text": "Minimum Error Rate", "start_pos": 64, "end_pos": 82, "type": "METRIC", "confidence": 0.7499061425526937}]}, {"text": "Results are presented in terms of BLEU ().", "labels": [], "entities": [{"text": "BLEU", "start_pos": 34, "end_pos": 38, "type": "METRIC", "confidence": 0.9987531900405884}]}, {"text": "All evaluation results are case insensitive.", "labels": [], "entities": []}, {"text": "The English data is tokenized using simple punctuation-based rules.", "labels": [], "entities": []}, {"text": "The MSA portion of the Arabic side is segmented according to the Arabic Treebank (ATB) tokenization scheme () using the MADA+TOKAN morphological analyzer and tokenizer v3.1 (, while the DA portion is ATB-tokenized with MADA-ARZ ( ).", "labels": [], "entities": [{"text": "Arabic Treebank (ATB)", "start_pos": 65, "end_pos": 86, "type": "DATASET", "confidence": 0.872171676158905}]}, {"text": "The Arabic text is also Alif/Ya normalized.", "labels": [], "entities": []}, {"text": "For more details on processing Arabic, see.", "labels": [], "entities": []}, {"text": "MT Train/Tune/Test Data.", "labels": [], "entities": [{"text": "MT Train/Tune/Test Data", "start_pos": 0, "end_pos": 23, "type": "DATASET", "confidence": 0.8849708948816571}]}, {"text": "We have two parallel corpora.", "labels": [], "entities": []}, {"text": "The first is a DA-English corpus of 5M tokenized words of Egyptian (\u223c3.5M) and Levantine (\u223c1.5M).", "labels": [], "entities": []}, {"text": "This corpus is part of BOLT data.", "labels": [], "entities": [{"text": "BOLT data", "start_pos": 23, "end_pos": 32, "type": "DATASET", "confidence": 0.9371039569377899}]}, {"text": "The second is an MSA-English corpus of 57M tokenized words obtained from several LDC corpora (10 times the size of the DAEnglish data).", "labels": [], "entities": [{"text": "DAEnglish data", "start_pos": 119, "end_pos": 133, "type": "DATASET", "confidence": 0.9105021953582764}]}, {"text": "We work with eight standard MT test sets: three MSA sets from NIST MTEval with four references (MT06, MT08, and MT09), four Egyptian sets from LDC BOLT data with two references (EgyDevV1, EgyDevV2, EgyDevV3, and EgyTestV2), and one Levantine set from BBN () with one reference which we split into LevDev and LevTest.", "labels": [], "entities": [{"text": "MT", "start_pos": 28, "end_pos": 30, "type": "TASK", "confidence": 0.983654797077179}, {"text": "NIST MTEval", "start_pos": 62, "end_pos": 73, "type": "DATASET", "confidence": 0.8366232812404633}, {"text": "MT06", "start_pos": 96, "end_pos": 100, "type": "DATASET", "confidence": 0.9247318506240845}, {"text": "LDC BOLT data", "start_pos": 143, "end_pos": 156, "type": "DATASET", "confidence": 0.5724239150683085}, {"text": "BBN", "start_pos": 251, "end_pos": 254, "type": "DATASET", "confidence": 0.8757614493370056}, {"text": "LevDev", "start_pos": 297, "end_pos": 303, "type": "DATASET", "confidence": 0.9220941066741943}, {"text": "LevTest", "start_pos": 308, "end_pos": 315, "type": "DATASET", "confidence": 0.7714450359344482}]}, {"text": "We used MT08 and EgyDevV3 to tune SMT systems while we divided the remaining sets among classifier training data (5,562 sentences), dev (1,802 sentences) and blind test (1,804 sentences) sets to ensure each of these new sets has a variety of dialects and genres (weblog and newswire).", "labels": [], "entities": [{"text": "MT08", "start_pos": 8, "end_pos": 12, "type": "DATASET", "confidence": 0.9257345199584961}, {"text": "SMT", "start_pos": 34, "end_pos": 37, "type": "TASK", "confidence": 0.9844182729721069}]}, {"text": "We build four MT systems.", "labels": [], "entities": [{"text": "MT", "start_pos": 14, "end_pos": 16, "type": "TASK", "confidence": 0.970140278339386}]}, {"text": "This system is trained on the DAEnglish data and tuned on EgyDevV3.", "labels": [], "entities": [{"text": "DAEnglish data", "start_pos": 30, "end_pos": 44, "type": "DATASET", "confidence": 0.9389668107032776}, {"text": "EgyDevV3", "start_pos": 58, "end_pos": 66, "type": "DATASET", "confidence": 0.9827898740768433}]}, {"text": "This system is trained on the MSA-English data and tuned on MT08.", "labels": [], "entities": [{"text": "MSA-English data", "start_pos": 30, "end_pos": 46, "type": "DATASET", "confidence": 0.9436391294002533}, {"text": "MT08", "start_pos": 60, "end_pos": 64, "type": "DATASET", "confidence": 0.9824361801147461}]}, {"text": "(3) DA+MSA.", "labels": [], "entities": [{"text": "DA", "start_pos": 4, "end_pos": 6, "type": "METRIC", "confidence": 0.9711241126060486}, {"text": "MSA", "start_pos": 7, "end_pos": 10, "type": "METRIC", "confidence": 0.7213086485862732}]}, {"text": "This system is trained on the combination of both corpora (resulting in 62M tokenized 2 words on the Arabic side) and tuned on EgyDevV3.", "labels": [], "entities": [{"text": "EgyDevV3", "start_pos": 127, "end_pos": 135, "type": "DATASET", "confidence": 0.9740484952926636}]}, {"text": "This MSA-pivoting system uses's DA-MSA MT system followed by an Arabic-English SMT system which is trained on both corpora augmented with the DA-English where the DA side is preprocessed with the same DA-MSA MT system then tokenized with MADA-ARZ.", "labels": [], "entities": [{"text": "SMT", "start_pos": 79, "end_pos": 82, "type": "TASK", "confidence": 0.8097496628761292}]}, {"text": "The result is 67M tokenized words on the Arabic side.", "labels": [], "entities": []}, {"text": "EgyDevV3 was similarly preprocessed with the DA-MSA MT system and MADA-ARZ and used for tuning the system parameters.", "labels": [], "entities": [{"text": "EgyDevV3", "start_pos": 0, "end_pos": 8, "type": "DATASET", "confidence": 0.950310230255127}, {"text": "DA-MSA MT system", "start_pos": 45, "end_pos": 61, "type": "DATASET", "confidence": 0.8558690547943115}]}, {"text": "Test sets are similarly preprocessed before decoding with the SMT system.", "labels": [], "entities": [{"text": "SMT", "start_pos": 62, "end_pos": 65, "type": "TASK", "confidence": 0.9759466648101807}]}, {"text": "We report the results of our dev set on the four MT systems we builtin.", "labels": [], "entities": [{"text": "MT", "start_pos": 49, "end_pos": 51, "type": "TASK", "confidence": 0.8875917196273804}]}, {"text": "The MSA-Pivot system produces the best singleton result among all systems.", "labels": [], "entities": []}, {"text": "All differences in BLEU scores between the four systems are statistically significant above the 95% level.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 19, "end_pos": 23, "type": "METRIC", "confidence": 0.9981591105461121}]}, {"text": "Statistical significance is computed using paired bootstrap re-sampling  Oracle System Selection.", "labels": [], "entities": []}, {"text": "We also report in Table 1 an oracle system selection where we pick, for each sentence, the English translation that yields the best BLEU score.", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 132, "end_pos": 142, "type": "METRIC", "confidence": 0.975052535533905}]}, {"text": "This oracle indicates that the upper bound for improvement achievable from system selection is 5.4% BLEU.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 100, "end_pos": 104, "type": "METRIC", "confidence": 0.999240517616272}]}, {"text": "Excluding different systems from the combination lowered the overall score between 0.9% and 1.8%, suggesting the systems are indeed complementary.", "labels": [], "entities": []}, {"text": "The first part of repeats the best baseline system and the four-system oracle combination from for convenience.", "labels": [], "entities": []}, {"text": "The third row shows the result of running our system selection baseline that uses the Dialect ID binary decision on the Dev set sentences to decide on the target MT system.", "labels": [], "entities": [{"text": "MT", "start_pos": 162, "end_pos": 164, "type": "TASK", "confidence": 0.9576219320297241}]}, {"text": "It improves over the best single system baseline (MSA-Pivot) by a statistically significant 0.5% BLEU.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 97, "end_pos": 101, "type": "METRIC", "confidence": 0.9991281628608704}]}, {"text": "Crucially, we should note that this is a deterministic process.", "labels": [], "entities": []}, {"text": "The second part of shows the results of our four-class Naive Bayes classifiers trained on the classification training data we created.", "labels": [], "entities": []}, {"text": "The first column shows the source of sentence level features employed.", "labels": [], "entities": []}, {"text": "As mentioned earlier, we use the Basic features alone, the Extended features alone, and then their combination.", "labels": [], "entities": []}, {"text": "The classifier that uses both feature sources simultaneously as feature vectors is our best performer.", "labels": [], "entities": []}, {"text": "It improves over our best baseline single MT system by 1.3% BLEU and over the Dialect ID Binary Classification system selection baseline by 0.8% BLEU.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 60, "end_pos": 64, "type": "METRIC", "confidence": 0.9992107152938843}, {"text": "BLEU", "start_pos": 145, "end_pos": 149, "type": "METRIC", "confidence": 0.9983554482460022}]}, {"text": "Blind Test Set.: Dialect breakdown of performance on the Dev set for our best performing classifier against our four baselines and their oracle combination.", "labels": [], "entities": [{"text": "Dev set", "start_pos": 57, "end_pos": 64, "type": "DATASET", "confidence": 0.7873749732971191}]}, {"text": "Our classifier does not know of these subsets, it runs on the set as a whole; therefore, we repeat its results in the second column for convenience.", "labels": [], "entities": []}, {"text": "MSA-Pivot is also the best performer.", "labels": [], "entities": [{"text": "MSA-Pivot", "start_pos": 0, "end_pos": 9, "type": "DATASET", "confidence": 0.9404984712600708}]}, {"text": "The differences in BLEU are statistically significant.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 19, "end_pos": 23, "type": "METRIC", "confidence": 0.9983265995979309}]}, {"text": "The second part shows the four-system oracle combination which shows a 5.5% BLEU upper bound on improvements.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 76, "end_pos": 80, "type": "METRIC", "confidence": 0.9997063279151917}]}, {"text": "The third part shows the results of the Dialect ID Binary Classification which improves by 0.4% BLEU.", "labels": [], "entities": [{"text": "Dialect ID Binary Classification", "start_pos": 40, "end_pos": 72, "type": "TASK", "confidence": 0.5965545251965523}, {"text": "BLEU", "start_pos": 96, "end_pos": 100, "type": "METRIC", "confidence": 0.9994261264801025}]}, {"text": "The last row shows the four-class classifier results which improves by 1.0% BLEU over the best single MT system baseline and by 0.6% BLEU over the Dialect ID Binary Classification.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 76, "end_pos": 80, "type": "METRIC", "confidence": 0.9993365406990051}, {"text": "BLEU", "start_pos": 133, "end_pos": 137, "type": "METRIC", "confidence": 0.9993863105773926}]}, {"text": "Results on the Blind Test set are consistent with the Dev set results.", "labels": [], "entities": [{"text": "Blind Test set", "start_pos": 15, "end_pos": 29, "type": "DATASET", "confidence": 0.8290195067723592}, {"text": "Dev set", "start_pos": 54, "end_pos": 61, "type": "DATASET", "confidence": 0.8235177397727966}]}], "tableCaptions": [{"text": " Table 1. The MSA-Pivot system produces  the best singleton result among all systems. All  differences in BLEU scores between the four sys- tems are statistically significant above the 95%  level. Statistical significance is computed using  paired bootstrap re-sampling", "labels": [], "entities": [{"text": "BLEU", "start_pos": 106, "end_pos": 110, "type": "METRIC", "confidence": 0.9987057447433472}]}, {"text": " Table 1: Results from the baseline MT systems and their or-", "labels": [], "entities": [{"text": "MT", "start_pos": 36, "end_pos": 38, "type": "TASK", "confidence": 0.9884101152420044}]}, {"text": " Table 2: Results of baselines and system selection systems", "labels": [], "entities": []}, {"text": " Table 3: Results of baselines and system selection systems", "labels": [], "entities": []}, {"text": " Table 4: Dialect breakdown of performance on the Dev set", "labels": [], "entities": [{"text": "Dev set", "start_pos": 50, "end_pos": 57, "type": "DATASET", "confidence": 0.7323640584945679}]}]}