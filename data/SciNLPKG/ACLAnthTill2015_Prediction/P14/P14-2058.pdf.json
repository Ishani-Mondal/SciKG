{"title": [{"text": "Automation and Evaluation of the Keyword Method for Second Language Learning", "labels": [], "entities": []}], "abstractContent": [{"text": "In this paper, we combine existing NLP techniques with minimal supervision to build memory tips according to the keyword method, a well established mnemonic device for second language learning.", "labels": [], "entities": []}, {"text": "We present what we believe to be the first extrinsic evaluation of a creative sentence generator on a vocabulary learning task.", "labels": [], "entities": []}, {"text": "The results demonstrate that NLP techniques can effectively support the development of resources for second language learning.", "labels": [], "entities": []}], "introductionContent": [{"text": "The keyword method is a mnemonic device that is especially suitable for vocabulary acquisition in second language learning.", "labels": [], "entities": [{"text": "vocabulary acquisition", "start_pos": 72, "end_pos": 94, "type": "TASK", "confidence": 0.7588367760181427}]}, {"text": "In this method, a target word in a foreign language L2 can be learned by a native speaker of another language L1 in two main steps: 1) one or more L1 words, possibly referring to a concrete entity, are chosen based on orthographic or phonetic similarity with the target word; 2) an L1 sentence is constructed in which an association between the translation of the target word and the keyword(s) is established, so that the learner, when seeing or hearing the word, immediately recalls the keyword(s).", "labels": [], "entities": []}, {"text": "To illustrate, for teaching the Italian word cuore which means heart in English, the learner might be asked to imagine \"a lonely heart with a hard core\".", "labels": [], "entities": []}, {"text": "The keyword method has already been proven to be a valuable teaching device.", "labels": [], "entities": []}, {"text": "However, the preparation of the memorization tips for each new word is an activity that requires considerable time, linguistic competence and creativity.", "labels": [], "entities": []}, {"text": "To the best of our knowledge, there is only one study which attempts to automate the mechanism of the keyword method.", "labels": [], "entities": []}, {"text": "In ( \u00a8 Ozbal and Strapparava, 2011), we proposed to automate the keyword method by retrieving sentences from the Web.", "labels": [], "entities": []}, {"text": "However, we did not provide any evaluation to demonstrate the effectiveness of our approach in areal life scenario.", "labels": [], "entities": []}, {"text": "In addition, we observed that retrieval poses severe limitations in terms of recall and sentence quality, and it might incur copyright violations.", "labels": [], "entities": [{"text": "recall", "start_pos": 77, "end_pos": 83, "type": "METRIC", "confidence": 0.9985764026641846}]}, {"text": "In this paper, we overcome these limitations by introducing a semi-automatic system implementing the keyword method that builds upon the keyword selection mechanism of\u00a8Ozbalof\u00a8 of\u00a8Ozbal and Strapparava (2011) and combines it with a state-of-the-art creative sentence generation framework).", "labels": [], "entities": []}, {"text": "We setup an experiment to simulate the situation in which a teacher needs to prepare material fora vocabulary teaching resource.", "labels": [], "entities": []}, {"text": "According to our scenario, the teacher relies on automatic techniques to generate relatively few, high quality mnemonics in English to teach Italian vocabulary.", "labels": [], "entities": []}, {"text": "She only applies a very light supervision in the last step of the process, in which the most suitable among the generated sentences are selected before being presented to the learners.", "labels": [], "entities": []}, {"text": "In this stage, the teacher may want to consider factors which are not yet in reach of automatic linguistic processors, such as the evocativeness or the memorability of a sentence.", "labels": [], "entities": []}, {"text": "We show that the automatically generated sentences help learners to establish memorable connections which augment their ability to assimilate new vocabulary.", "labels": [], "entities": []}, {"text": "To the best of our knowledge, this work is the first documented extrinsic evaluation of a creative sentence generator on a real-world application.", "labels": [], "entities": []}], "datasetContent": [{"text": "For our experiment, we drew inspiration from.", "labels": [], "entities": []}, {"text": "We compared the retention error rate of learners who tried to memorize new words with or without the aid of the automatically generated sentences.", "labels": [], "entities": [{"text": "retention error", "start_pos": 16, "end_pos": 31, "type": "METRIC", "confidence": 0.964572548866272}]}, {"text": "Through academic channels, we recruited 20 native English speakers with no prior knowledge of Italian.", "labels": [], "entities": []}, {"text": "After obtaining the sentences as explained in Section 3, we shuffled and then divided the whole set including 40 target words together with their translation, the generated keywords and sentences into 2 batches (A, B) and further divided each batch into 2 groups consisting of 10 elements (A1, A2, B1 and B2).", "labels": [], "entities": []}, {"text": "The set of sentences assigned to each group is listed in: Column \"Target\" reports the Italian target word being taught; Column \"Sentence\" shows the automatically generated sentence, where the translation of the target word is shown in bold and the keyword(s) in italic.", "labels": [], "entities": []}, {"text": "For the experiments, we randomly assigned each subject to one of the batches (A or B).", "labels": [], "entities": []}, {"text": "Then, each subject was asked to memorize all the word pairs in a batch, but they would seethe memory tips only for one of the two groups, which was again randomly assigned.", "labels": [], "entities": []}, {"text": "This approach resulted in 4 different memorization exercises, namely 1) A1 with tips and A2 without, 2) A2 with tips and A1 without, 3) B1 with tips and B2 without, 4) B2 with tips and B1 without.: Per-group and overall retention error rate when using rote or keyword-aided (KW) memorization.", "labels": [], "entities": [{"text": "retention error rate", "start_pos": 220, "end_pos": 240, "type": "METRIC", "confidence": 0.945513923962911}]}, {"text": "When memorizing the translations without the aid of memory tips, the subjects were instructed to focus only on the Italian word and its English translation and to repeat them over and over in their mind.", "labels": [], "entities": []}, {"text": "Conversely, when relying on the automatic memory tips the subjects were shown the word, its translation and the generated sentence including the keywords.", "labels": [], "entities": []}, {"text": "In this case, the subjects were instructed to read the sentence over and over trying to visualize it.", "labels": [], "entities": []}, {"text": "After going through each set of slides, we distracted the subjects with a short video in order to reset their short term memory.", "labels": [], "entities": [{"text": "memory", "start_pos": 121, "end_pos": 127, "type": "METRIC", "confidence": 0.8252987265586853}]}, {"text": "After that, their retention was tested.", "labels": [], "entities": [{"text": "retention", "start_pos": 18, "end_pos": 27, "type": "METRIC", "confidence": 0.9828240871429443}]}, {"text": "For each Italian word in the exercise, they were asked to select the English translation among 5 alternatives, including the correct translation and 4 other words randomly selected from the same group.", "labels": [], "entities": []}, {"text": "In this way, the subjects would always have to choose among the words that they encountered during the exercise.", "labels": [], "entities": []}, {"text": "We also added an extra option \"I already knew this word\" that the subjects were instructed to select in case they already knew the Italian word prior to taking part in the experiment.", "labels": [], "entities": []}, {"text": "summarizes the outcome of the experiment.", "labels": [], "entities": []}, {"text": "The contribution of the automatically generated sentences to the learning task is assessed in terms of error rate-reduction, which we measure both within each group (rows 1-4) and on the whole evaluation set (rows 5-6).", "labels": [], "entities": [{"text": "error rate-reduction", "start_pos": 103, "end_pos": 123, "type": "METRIC", "confidence": 0.9598666429519653}]}, {"text": "Due to the presence of the \"I already knew this word\" option in the learning-assessment questionnaire, the number of the actual answers provided by each subject can be slightly different, hence the difference between macro-and micro-average.", "labels": [], "entities": []}, {"text": "The error rate for each memorization technique t (where t = R for \"Rote memorization\" and t = K for \"keyword-aided memorization\") is calculated as: e t = it ct+it , where ct and it are the number of correct and incorrect answers provided by the subjects, respectively.", "labels": [], "entities": [{"text": "error rate", "start_pos": 4, "end_pos": 14, "type": "METRIC", "confidence": 0.9828987121582031}]}, {"text": "The absolute error rate reduction \u2206e is calculated as the absolute difference in error rate between rote and keywordaided memorization, i.e.: \u2206 e = e R \u2212 e K . Finally, the relative error rate reduction % e is calculated as the the ratio between the absolute error rate reduction \u2206e and the error rate of rote memorization e R , i.e.,: The overall results (rows 5 and 6 in show that vocabulary learning noticeably improves when supported by the generated sentences, with error rates dropping by almost 30% in terms of macro-average (almost 27% for microaverage).", "labels": [], "entities": [{"text": "absolute error rate reduction", "start_pos": 4, "end_pos": 33, "type": "METRIC", "confidence": 0.7659456953406334}]}, {"text": "The breakdown of the error rate across the 4 groups shows a clear pattern.", "labels": [], "entities": [{"text": "error rate", "start_pos": 21, "end_pos": 31, "type": "METRIC", "confidence": 0.9743712544441223}]}, {"text": "The results clearly indicate that one group (A1) by chance contained easier words to memorize as shown by the low error rate (between 3% and 4%) obtained with both methods.", "labels": [], "entities": [{"text": "error rate", "start_pos": 114, "end_pos": 124, "type": "METRIC", "confidence": 0.9799710214138031}]}, {"text": "Similarly, groups A2 and B1 are of average difficulty, whereas group B2 appears to be the most difficult, with an error rate higher than 22% when using only rote memorization.", "labels": [], "entities": [{"text": "A2", "start_pos": 18, "end_pos": 20, "type": "METRIC", "confidence": 0.94502192735672}, {"text": "error rate", "start_pos": 114, "end_pos": 124, "type": "METRIC", "confidence": 0.9874819815158844}]}, {"text": "Interestingly, there is a strong correlation (Pearson's r = 0.85) between the difficulty of the words in each group (measured as the error rate on rote memorization) and the positive contribution of the generated sentences to the learning process.", "labels": [], "entities": [{"text": "Pearson's r", "start_pos": 46, "end_pos": 57, "type": "METRIC", "confidence": 0.8960583209991455}]}, {"text": "In fact, we can see how the relative error rate reduction % e increases from \u223c17% (group A1) to almost 45% (group B2).", "labels": [], "entities": [{"text": "error rate reduction", "start_pos": 37, "end_pos": 57, "type": "METRIC", "confidence": 0.9476442138353983}]}, {"text": "Based on the results obtained by, who showed that the keyword method results in better long-term word retention than rote memorization, we would expect the error rate reduction to be even higher in a delayed post-test.", "labels": [], "entities": [{"text": "error rate reduction", "start_pos": 156, "end_pos": 176, "type": "METRIC", "confidence": 0.9800403118133545}]}, {"text": "All in all, these findings clearly support the claim that a state-ofthe-art sentence generator can be successfully employed to support keyword-based second language learning.", "labels": [], "entities": []}, {"text": "After completing their exercise, the subjects were asked to provide feedback about their experience as learners.", "labels": [], "entities": []}, {"text": "We setup a 4-items Likert scale    the memorization process; 45% found that the sentences were overall correct; 65% confirmed that the sentences were catchy and easy to remember; and 50% found the sentences to be overall witty although the sentence generator does not include a mechanism to generate humor.", "labels": [], "entities": []}, {"text": "Finally, it is worth mentioning that none of the subjects noticed that the sentences were machine generated, which we regard as a very positive assessment of the quality of the sentence generation framework.", "labels": [], "entities": []}, {"text": "From their comments, it emerges that the subjects actually believed that they were just comparing two memorization techniques.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Per-group and overall retention error rate  when using rote or keyword-aided (KW) memo- rization.", "labels": [], "entities": [{"text": "retention error rate", "start_pos": 32, "end_pos": 52, "type": "METRIC", "confidence": 0.9471471905708313}]}, {"text": " Table 3: Evaluation of the generated sentences on  a 5-point Likert scale.", "labels": [], "entities": []}]}