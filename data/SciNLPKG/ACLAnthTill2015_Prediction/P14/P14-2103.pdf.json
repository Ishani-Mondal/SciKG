{"title": [{"text": "Labelling Topics using Unsupervised Graph-based Methods", "labels": [], "entities": []}], "abstractContent": [{"text": "This paper introduces an unsupervised graph-based method that selects textual labels for automatically generated topics.", "labels": [], "entities": []}, {"text": "Our approach uses the topic keywords to query a search engine and generate a graph from the words contained in the results.", "labels": [], "entities": []}, {"text": "PageRank is then used to weigh the words in the graph and score the candidate labels.", "labels": [], "entities": []}, {"text": "The state-of-the-art method for this task is supervised (Lau et al., 2011).", "labels": [], "entities": []}, {"text": "Evaluation on a standard data set shows that the performance of our approach is consistently superior to previously reported methods.", "labels": [], "entities": []}], "introductionContent": [{"text": "Topic models have proved to be a useful way to represent the content of document collections, e.g. (. In these interfaces, topics need to be presented to users in an easily interpretable way.", "labels": [], "entities": []}, {"text": "A common way to represent topics is asset of keywords generated from then terms with the highest marginal probabilities.", "labels": [], "entities": []}, {"text": "For example, a topic about the global financial crisis could be represented by its top 10 most probable terms: FINANCIAL, BANK, MARKET, GOVERNMENT, MORTGAGE, BAILOUT, BILLION, STREET, WALL, CRISIS.", "labels": [], "entities": [{"text": "FINANCIAL", "start_pos": 111, "end_pos": 120, "type": "METRIC", "confidence": 0.9814999103546143}, {"text": "BANK", "start_pos": 122, "end_pos": 126, "type": "METRIC", "confidence": 0.960040271282196}, {"text": "MARKET", "start_pos": 128, "end_pos": 134, "type": "METRIC", "confidence": 0.9673470258712769}, {"text": "GOVERNMENT", "start_pos": 136, "end_pos": 146, "type": "METRIC", "confidence": 0.8392273783683777}, {"text": "MORTGAGE", "start_pos": 148, "end_pos": 156, "type": "METRIC", "confidence": 0.9802619218826294}, {"text": "BAILOUT", "start_pos": 158, "end_pos": 165, "type": "METRIC", "confidence": 0.9847848415374756}, {"text": "BILLION", "start_pos": 167, "end_pos": 174, "type": "METRIC", "confidence": 0.9934449195861816}, {"text": "STREET", "start_pos": 176, "end_pos": 182, "type": "METRIC", "confidence": 0.9841485619544983}, {"text": "WALL", "start_pos": 184, "end_pos": 188, "type": "METRIC", "confidence": 0.9496154189109802}]}, {"text": "But interpreting such lists is not always straightforward, particularly since background knowledge maybe required (.", "labels": [], "entities": [{"text": "interpreting", "start_pos": 4, "end_pos": 16, "type": "TASK", "confidence": 0.9820109009742737}]}, {"text": "Textual labels could assist with the interpretations of topics and researchers have developed methods to generate these automatically ().", "labels": [], "entities": []}, {"text": "For example, a topic which has keywords SCHOOL, STUDENT, UNIVERSITY, COLLEGE, TEACHER, CLASS, EDUCATION, LEARN, HIGH, PROGRAM, could be labelled as EDUCATION and a suitable label for the topic shown above would be GLOBAL FINANCIAL CRISIS.", "labels": [], "entities": [{"text": "STUDENT", "start_pos": 48, "end_pos": 55, "type": "METRIC", "confidence": 0.8966194987297058}, {"text": "COLLEGE", "start_pos": 69, "end_pos": 76, "type": "METRIC", "confidence": 0.8970959782600403}, {"text": "TEACHER", "start_pos": 78, "end_pos": 85, "type": "METRIC", "confidence": 0.9445469379425049}, {"text": "CLASS", "start_pos": 87, "end_pos": 92, "type": "METRIC", "confidence": 0.8359969258308411}, {"text": "EDUCATION", "start_pos": 94, "end_pos": 103, "type": "METRIC", "confidence": 0.8708844184875488}, {"text": "LEARN", "start_pos": 105, "end_pos": 110, "type": "METRIC", "confidence": 0.966742217540741}, {"text": "HIGH", "start_pos": 112, "end_pos": 116, "type": "METRIC", "confidence": 0.8905222415924072}, {"text": "GLOBAL FINANCIAL CRISIS", "start_pos": 214, "end_pos": 237, "type": "METRIC", "confidence": 0.7742865880330404}]}, {"text": "Approaches that make use of alternative modalities, such as images (, have also been proposed.", "labels": [], "entities": []}, {"text": "label topics using statistically significant bigrams identified in a reference collection.", "labels": [], "entities": []}, {"text": "introduced an approach for labelling topics that relied on two hierarchical knowledge resources labelled by humans, while proposed selecting the most representative word from a topic as its label.", "labels": [], "entities": []}, {"text": "make use of structured data from DBpedia to label topics.", "labels": [], "entities": [{"text": "DBpedia", "start_pos": 33, "end_pos": 40, "type": "DATASET", "confidence": 0.9365916848182678}]}, {"text": "proposed a method for automatically labelling topics using information from Wikipedia.", "labels": [], "entities": []}, {"text": "A set of candidate labels is generated from Wikipedia article titles by querying using topic terms.", "labels": [], "entities": []}, {"text": "Additional labels are then generated by chunk parsing the article titles to identify n-grams that represent Wikipedia articles as well.", "labels": [], "entities": [{"text": "chunk parsing", "start_pos": 40, "end_pos": 53, "type": "TASK", "confidence": 0.7111305445432663}]}, {"text": "Outlier labels (less relevant to the topic) are identified and removed.", "labels": [], "entities": []}, {"text": "Finally, the top-5 topic terms are added to the candidate set.", "labels": [], "entities": []}, {"text": "The labels are ranked using Support Vector Regression (SVR) and features extracted using word association measures (i.e. PMI, t-test, \u03c7 2 and Dice coefficient), lexical features and search engine ranking.", "labels": [], "entities": []}, {"text": "report two versions of their approach, one unsupervised (which is used as a baseline) and another which is supervised.", "labels": [], "entities": []}, {"text": "They reported that the supervised version achieves better performance than a previously reported approach (.", "labels": [], "entities": []}, {"text": "This paper introduces an alternative graphbased approach which is unsupervised and less computationally intensive than.", "labels": [], "entities": []}, {"text": "Our method uses topic keywords to form a query.", "labels": [], "entities": []}, {"text": "A graph is generated from the words contained in the search results and these are then ranked using the PageRank algorithm (; Mihal-: Sample of the metadata associated with a search result. cea and).", "labels": [], "entities": []}, {"text": "Evaluation on a standard data set shows that our method consistently outperforms the best performing previously reported method, which is supervised ().", "labels": [], "entities": []}], "datasetContent": [{"text": "Our evaluation follows the framework proposed by Lau et al.", "labels": [], "entities": []}, {"text": "(2011) using two metrics, i.e. Top-1 average rating and nDCG, to compare various labelling methods.", "labels": [], "entities": [{"text": "Top-1 average rating", "start_pos": 31, "end_pos": 51, "type": "METRIC", "confidence": 0.8956656058629354}]}, {"text": "Top-1 average rating is the average human rating (between 0 and 3) assigned to the top-ranked label proposed by the system.", "labels": [], "entities": [{"text": "Top-1 average rating", "start_pos": 0, "end_pos": 20, "type": "METRIC", "confidence": 0.7922292550404867}]}, {"text": "This provides an indication of the overall quality of the label the system judges as the best one.", "labels": [], "entities": []}, {"text": "Normalised discounted cumulative gain (nDCG)) compares the label ranking proposed by the system to the ranking provided by human annotators.", "labels": [], "entities": [{"text": "discounted cumulative gain (nDCG))", "start_pos": 11, "end_pos": 45, "type": "METRIC", "confidence": 0.8680721819400787}]}, {"text": "The discounted cumulative gain at position p, DCG p , is computed using the following equation: where rel i is the relevance of the label to the topic in position i.", "labels": [], "entities": []}, {"text": "Then nDCG is computed as: where IDCG p is the superviseed ranking of the image labels, in our experiments this is the ranking provided by the scores in the human annotated data set.", "labels": [], "entities": [{"text": "human annotated data set", "start_pos": 156, "end_pos": 180, "type": "DATASET", "confidence": 0.7628444135189056}]}], "tableCaptions": [{"text": " Table 1: Results for Various Approaches to Topic Labelling ( \u2020: significant difference (t-test, p < 0.05)  to Lau et al. (2011)-U;  \u2021: significant difference (p < 0.05) to Lau et al. (2011)-S).", "labels": [], "entities": [{"text": "Topic Labelling", "start_pos": 44, "end_pos": 59, "type": "TASK", "confidence": 0.8161010444164276}]}, {"text": " Table 1. Performance when  PageRank is applied to the unweighted (PR) and  NPMI-weighted graphs (PR-NPMI) (see Section", "labels": [], "entities": []}]}