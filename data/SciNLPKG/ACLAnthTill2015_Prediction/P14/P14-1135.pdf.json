{"title": [{"text": "Context-dependent Semantic Parsing for Time Expressions", "labels": [], "entities": [{"text": "Context-dependent Semantic Parsing", "start_pos": 0, "end_pos": 34, "type": "TASK", "confidence": 0.6213077008724213}]}], "abstractContent": [{"text": "We present an approach for learning context-dependent semantic parsers to identify and interpret time expressions.", "labels": [], "entities": [{"text": "learning context-dependent semantic parsers", "start_pos": 27, "end_pos": 70, "type": "TASK", "confidence": 0.6104732900857925}]}, {"text": "We use a Combinatory Categorial Grammar to construct compositional meaning representations, while considering contex-tual cues, such as the document creation time and the tense of the governing verb, to compute the final time values.", "labels": [], "entities": []}, {"text": "Experiments on benchmark datasets show that our approach outperforms previous state-of-the-art systems, with error reductions of 13% to 21% in end-to-end performance.", "labels": [], "entities": []}], "introductionContent": [{"text": "Time expressions present a number of challenges for language understanding systems.", "labels": [], "entities": [{"text": "language understanding", "start_pos": 52, "end_pos": 74, "type": "TASK", "confidence": 0.7493412494659424}]}, {"text": "They have rich, compositional structure (e.g., \"2nd Friday of July\"), can be easily confused with non-temporal phrases (e.g., the word \"May\" can be a month name or a verb), and can vary in meaning in different linguistic contexts (e.g., the word \"Friday\" refers to different dates in the sentences \"We met on Friday\" and \"We will meet on Friday\").", "labels": [], "entities": []}, {"text": "Recovering the meaning of time expressions is therefore challenging, but provides opportunities to study context-dependent language use.", "labels": [], "entities": []}, {"text": "In this paper, we present the first context-dependent semantic parsing approach for learning to identify and interpret time expressions, addressing all three challenges.", "labels": [], "entities": [{"text": "context-dependent semantic parsing", "start_pos": 36, "end_pos": 70, "type": "TASK", "confidence": 0.631572405497233}]}, {"text": "Existing state-of-the-art methods use handengineered rules for reasoning about time expressions.", "labels": [], "entities": []}, {"text": "This includes both detection, identifying a phrase as a time expression, and resolution, mapping such a phrase into a standardized time value.", "labels": [], "entities": [{"text": "resolution", "start_pos": 77, "end_pos": 87, "type": "METRIC", "confidence": 0.8101934194564819}]}, {"text": "While rule-based approaches provide a natural way to express expert knowledge, it is relatively difficult to en- * Work conducted at the University of code preferences between similar competing hypotheses and provide prediction confidence.", "labels": [], "entities": []}, {"text": "Recently, methods for learning probabilistic semantic parsers have been shown to address such limitations (.", "labels": [], "entities": [{"text": "learning probabilistic semantic parsers", "start_pos": 22, "end_pos": 61, "type": "TASK", "confidence": 0.610563613474369}]}, {"text": "However, these approaches do not account for any surrounding linguistic context and were mainly evaluated with gold standard mentions.", "labels": [], "entities": []}, {"text": "We propose to use a context-dependent semantic parser for both detection and resolution of time expressions.", "labels": [], "entities": [{"text": "detection and resolution of time expressions", "start_pos": 63, "end_pos": 107, "type": "TASK", "confidence": 0.7254880319039027}]}, {"text": "For both tasks, we make use of a hand-engineered Combinatory Categorial Grammar (CCG) to construct a set of meaning representations that identify the time being described.", "labels": [], "entities": []}, {"text": "For example, this grammar maps the phrase \"2nd Friday of July\" to the meaning representation intersect(nth(2 , friday), july), which encodes the set of all such days.", "labels": [], "entities": []}, {"text": "Detection is then performed with a binary classifier to prune the set of text spans that can be parsed with the grammar (e.g., to tell that \"born in 2000\" has a time expression but \"a 2000 piece puzzle\" does not).", "labels": [], "entities": [{"text": "Detection", "start_pos": 0, "end_pos": 9, "type": "TASK", "confidence": 0.8953824639320374}]}, {"text": "For resolution, we consider mentions sequentially and use a log-linear model to select the most likely meaning for each.", "labels": [], "entities": [{"text": "resolution", "start_pos": 4, "end_pos": 14, "type": "TASK", "confidence": 0.9765378832817078}]}, {"text": "This choice depends on contextual cues such as previous time expressions and the tense of the governing verb (e.g., as required to correctly resolve cases like \"We should meet on the 2nd Friday of July\").", "labels": [], "entities": []}, {"text": "Such an approach provides a good balance between hand engineering and learning.", "labels": [], "entities": []}, {"text": "For the relatively closed-class time expressions, we demonstrate that it is possible to engineer a high quality CCG lexicon.", "labels": [], "entities": []}, {"text": "We take a data-driven approach for grammar design, preferring a grammar with high coverage even if it results in parsing ambiguities.", "labels": [], "entities": [{"text": "grammar design", "start_pos": 35, "end_pos": 49, "type": "TASK", "confidence": 0.8350056707859039}]}, {"text": "We then learn a model to accurately select between competing parses and incorporate signals from the surrounding context, both more difficult to model with deterministic rules.", "labels": [], "entities": []}, {"text": "For both problems, we learn from TimeML an-notations (), which mark mentions and the specific times they reference.", "labels": [], "entities": []}, {"text": "Training the detector is a supervised learning problem, but resolution is more challenging, requiring us to reason about latent parsing and context-dependent decisions.", "labels": [], "entities": []}, {"text": "We evaluate performance in two domains: the TempEval-3 corpus of newswire text) and the WikiWars corpus of Wikipedia history articles.", "labels": [], "entities": [{"text": "TempEval-3 corpus of newswire text", "start_pos": 44, "end_pos": 78, "type": "DATASET", "confidence": 0.8726224064826965}, {"text": "WikiWars corpus of Wikipedia history articles", "start_pos": 88, "end_pos": 133, "type": "DATASET", "confidence": 0.8959971070289612}]}, {"text": "On these benchmark datasets, we present new state-of-theart results, with error reductions of up to 28% for the detection task and 21% for the end-to-end task.", "labels": [], "entities": [{"text": "error reductions", "start_pos": 74, "end_pos": 90, "type": "METRIC", "confidence": 0.964712530374527}]}], "datasetContent": [{"text": "Data We evaluate performance on the TempEval-3 (Uzzaman et al., 2013) and WikiWars (Mazur and Dale, 2010) datasets.", "labels": [], "entities": [{"text": "WikiWars (Mazur and Dale, 2010) datasets", "start_pos": 74, "end_pos": 114, "type": "DATASET", "confidence": 0.6590090327792697}]}, {"text": "shows summary statistics for both datasets.", "labels": [], "entities": []}, {"text": "For the TempEval-3 corpus, we use the given training and testing set splits.", "labels": [], "entities": [{"text": "TempEval-3 corpus", "start_pos": 8, "end_pos": 25, "type": "DATASET", "confidence": 0.8256407976150513}]}, {"text": "Since the training set has lower inter-annotator agreement than the testing set (, we manually corrected all of the mistakes we found in the training data.", "labels": [], "entities": []}, {"text": "The original training set is denoted Dev* and the corrected Dev.", "labels": [], "entities": [{"text": "corrected Dev", "start_pos": 50, "end_pos": 63, "type": "METRIC", "confidence": 0.8349605202674866}]}, {"text": "We report (1) cross-validation development results on Dev*, (2) cross-validation development and ablation results for Dev, and   rion of 0.01.", "labels": [], "entities": [{"text": "ablation", "start_pos": 97, "end_pos": 105, "type": "METRIC", "confidence": 0.9829224348068237}, {"text": "rion", "start_pos": 129, "end_pos": 133, "type": "METRIC", "confidence": 0.9891093969345093}]}, {"text": "For resolution, we set the learning rate to 0.25 and ran AdaGrad for 5 iterations.", "labels": [], "entities": [{"text": "resolution", "start_pos": 4, "end_pos": 14, "type": "TASK", "confidence": 0.9262412190437317}, {"text": "AdaGrad", "start_pos": 57, "end_pos": 64, "type": "DATASET", "confidence": 0.931496262550354}]}, {"text": "All features are initialized to have zero weights.", "labels": [], "entities": []}, {"text": "Evaluation Metrics We use the official TempEval-3 scoring script and report the standard metrics.", "labels": [], "entities": [{"text": "TempEval-3 scoring script", "start_pos": 39, "end_pos": 64, "type": "DATASET", "confidence": 0.7769609093666077}]}, {"text": "We report detection precision, recall and F1 with relaxed and strict metrics; a gold mention is considered detected for the relaxed metric if any of the output candidates overlap with it and is detected for the strict metric if the extent of any output candidates matches exactly.", "labels": [], "entities": [{"text": "precision", "start_pos": 20, "end_pos": 29, "type": "METRIC", "confidence": 0.9307267665863037}, {"text": "recall", "start_pos": 31, "end_pos": 37, "type": "METRIC", "confidence": 0.9996633529663086}, {"text": "F1", "start_pos": 42, "end_pos": 44, "type": "METRIC", "confidence": 0.9995030164718628}]}, {"text": "For resolution, we report value accuracy, measuring correctness of time expressions detected according to the relaxed metric.", "labels": [], "entities": [{"text": "resolution", "start_pos": 4, "end_pos": 14, "type": "TASK", "confidence": 0.9757315516471863}, {"text": "accuracy", "start_pos": 32, "end_pos": 40, "type": "METRIC", "confidence": 0.8956968188285828}]}, {"text": "We also report value precision, recall, and F1, which score an expression as correct if it is both correctly detected (relaxed) and resolved.", "labels": [], "entities": [{"text": "precision", "start_pos": 21, "end_pos": 30, "type": "METRIC", "confidence": 0.8452882170677185}, {"text": "recall", "start_pos": 32, "end_pos": 38, "type": "METRIC", "confidence": 0.9995112419128418}, {"text": "F1", "start_pos": 44, "end_pos": 46, "type": "METRIC", "confidence": 0.9998050332069397}]}, {"text": "For end-to-end performance, value F1 is the primary metric.", "labels": [], "entities": [{"text": "F1", "start_pos": 34, "end_pos": 36, "type": "METRIC", "confidence": 0.9803916215896606}]}, {"text": "Finally, we report accuracy and F1 for temporal types, as defined in Section 2, for the TempEval dataset (WikiWars does not include type labels).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 19, "end_pos": 27, "type": "METRIC", "confidence": 0.999708354473114}, {"text": "F1", "start_pos": 32, "end_pos": 34, "type": "METRIC", "confidence": 0.9997270703315735}, {"text": "TempEval dataset", "start_pos": 88, "end_pos": 104, "type": "DATASET", "confidence": 0.9315298795700073}]}, {"text": "Comparison Systems We compare our system primarily to, which is state of the art in the end-toend task.", "labels": [], "entities": []}, {"text": "For the TempEval-3 dataset, we also compare to two other strong participants of the shared task.", "labels": [], "entities": [{"text": "TempEval-3 dataset", "start_pos": 8, "end_pos": 26, "type": "DATASET", "confidence": 0.9018382132053375}]}, {"text": "These include NavyTime, which had the top relaxed detection score, and ClearTK (Bethard, 2013a), which had the top strict detection score and type F1 score.", "labels": [], "entities": [{"text": "NavyTime", "start_pos": 14, "end_pos": 22, "type": "DATASET", "confidence": 0.9515502452850342}, {"text": "ClearTK (Bethard, 2013a)", "start_pos": 71, "end_pos": 95, "type": "DATASET", "confidence": 0.8593555192152659}, {"text": "type F1 score", "start_pos": 142, "end_pos": 155, "type": "METRIC", "confidence": 0.8142422040303549}]}, {"text": "context free grammar (SCFG), which is state-of-the-art in the task of resolution with gold mention boundaries.", "labels": [], "entities": []}], "tableCaptions": []}