{"title": [], "abstractContent": [{"text": "Incorrect normalization of text can be particularly damaging for applications like text-to-speech synthesis (TTS) or typing auto-correction, where the resulting nor-malization is directly presented to the user, versus feeding downstream applications.", "labels": [], "entities": [{"text": "text-to-speech synthesis (TTS)", "start_pos": 83, "end_pos": 113, "type": "TASK", "confidence": 0.8509045958518981}]}, {"text": "In this paper, we focus on abbreviation expansion for TTS, which requires a \"do no harm\", high precision approach yielding few expansion errors at the cost of leaving relatively many abbreviations un-expanded.", "labels": [], "entities": [{"text": "abbreviation expansion", "start_pos": 27, "end_pos": 49, "type": "TASK", "confidence": 0.8963823914527893}, {"text": "TTS", "start_pos": 54, "end_pos": 57, "type": "TASK", "confidence": 0.6205422878265381}, {"text": "precision", "start_pos": 95, "end_pos": 104, "type": "METRIC", "confidence": 0.9817982316017151}]}, {"text": "In the context of a large-scale, real-world TTS scenario, we present methods for training classifiers to establish whether a particular expansion is apt.", "labels": [], "entities": [{"text": "TTS", "start_pos": 44, "end_pos": 47, "type": "TASK", "confidence": 0.9741780161857605}]}, {"text": "We achieve a large increase incorrect abbreviation expansion when combined with the baseline text normalization component of the TTS system, together with a substantial reduction in incorrect expansions.", "labels": [], "entities": [{"text": "incorrect abbreviation expansion", "start_pos": 28, "end_pos": 60, "type": "METRIC", "confidence": 0.8223544160525004}, {"text": "text normalization", "start_pos": 93, "end_pos": 111, "type": "TASK", "confidence": 0.7092258930206299}, {"text": "TTS", "start_pos": 129, "end_pos": 132, "type": "TASK", "confidence": 0.5578171610832214}]}], "introductionContent": [{"text": "Text normalization) is an important initial phase for many natural language and speech applications.", "labels": [], "entities": [{"text": "Text normalization)", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.8142627477645874}]}, {"text": "The basic task of text normalization is to convert non-standard words (NSWs) -numbers, abbreviations, dates, etc.", "labels": [], "entities": [{"text": "text normalization", "start_pos": 18, "end_pos": 36, "type": "TASK", "confidence": 0.7321884483098984}]}, {"text": "-into standard words, though depending on the task and the domain a greater or lesser number of these NSWs may need to be normalized.", "labels": [], "entities": []}, {"text": "Perhaps the most demanding such application is text-to-speech synthesis (TTS) since, while for parsing, machine translation and information retrieval it maybe acceptable to leave such things as numbers and abbreviations unexpanded, for TTS all tokens need to be read, and for that it is necessary to know how to pronounce them.", "labels": [], "entities": [{"text": "text-to-speech synthesis (TTS)", "start_pos": 47, "end_pos": 77, "type": "TASK", "confidence": 0.8659144759178161}, {"text": "parsing", "start_pos": 95, "end_pos": 102, "type": "TASK", "confidence": 0.966105580329895}, {"text": "machine translation", "start_pos": 104, "end_pos": 123, "type": "TASK", "confidence": 0.6770824790000916}, {"text": "information retrieval", "start_pos": 128, "end_pos": 149, "type": "TASK", "confidence": 0.706350713968277}]}, {"text": "Which normalizations are required depends very much on the application.", "labels": [], "entities": []}, {"text": "What is also very application-dependent is the cost of errors in normalization.", "labels": [], "entities": []}, {"text": "For some applications, where the normalized string is an intermediate stage in a larger application such as translation or information retrieval, overgeneration of normalized alternatives is often a beneficial strategy, to the extent that it may improve the accuracy of what is eventually being presented to the user.", "labels": [], "entities": [{"text": "translation", "start_pos": 108, "end_pos": 119, "type": "TASK", "confidence": 0.9624982476234436}, {"text": "information retrieval", "start_pos": 123, "end_pos": 144, "type": "TASK", "confidence": 0.640998899936676}, {"text": "accuracy", "start_pos": 258, "end_pos": 266, "type": "METRIC", "confidence": 0.9964025020599365}]}, {"text": "In other applications, such as TTS or typing auto-correction, the resulting normalized string itself is directly presented to the user; hence errors in normalization can have a very high cost relative to leaving tokens unnormalized.", "labels": [], "entities": [{"text": "TTS", "start_pos": 31, "end_pos": 34, "type": "TASK", "confidence": 0.9443774223327637}]}, {"text": "In this paper we concentrate on abbreviations, which we define as alphabetic NSWs that it would be normal to pronounce as their expansion.", "labels": [], "entities": []}, {"text": "This class of NSWs is particularly common in personal ads, product reviews, and so forth.", "labels": [], "entities": []}, {"text": "For example: home healthcare svcs stat home health llc osceola aquatic ctr stars rating write audi vw repair ser quality and customer Each of the examples above contains an abbreviation that, unlike, e.g., conventionalized state abbreviations such as ca for California, is either only slightly standard (ctr for center) or not standard at all (ser for service).", "labels": [], "entities": [{"text": "write audi vw repair ser quality", "start_pos": 88, "end_pos": 120, "type": "METRIC", "confidence": 0.6884516924619675}]}, {"text": "An important principle in text normalization for TTS is do no harm.", "labels": [], "entities": [{"text": "text normalization", "start_pos": 26, "end_pos": 44, "type": "TASK", "confidence": 0.8306577205657959}, {"text": "TTS", "start_pos": 49, "end_pos": 52, "type": "TASK", "confidence": 0.9531718492507935}]}, {"text": "If a system is unable to reliably predict the correct reading fora string, it is better to leave the string alone and have it default to, say, a character-by-character reading, than to expand it to something wrong.", "labels": [], "entities": []}, {"text": "This is particularly true in accessibility applications for users who rely on TTS for most or all of their information needs.", "labels": [], "entities": []}, {"text": "Ideally a navigation system should read turn on 30N correctly as turn on thirty north; but if it cannot resolve the ambiguity in 30N, it is far better to read it as thirty N than as thirty Newtons, since listeners can more easily recover from the first kind of error than the second.", "labels": [], "entities": []}, {"text": "We present methods for learning abbreviation expansion models that favor high precision (incorrect expansions < 2%).", "labels": [], "entities": [{"text": "precision", "start_pos": 78, "end_pos": 87, "type": "METRIC", "confidence": 0.9968883395195007}]}, {"text": "Unannotated data is used to collect evidence for contextual disambiguation and to train an abbreviation model.", "labels": [], "entities": []}, {"text": "Then a small amount of annotated data is used to build models to determine whether to accept a candidate expan-sion of an abbreviation based on these features.", "labels": [], "entities": []}, {"text": "The data we report on are taken from Google Maps TM and web pages associated with its map entries, but the methods can be applied to any data source that is relatively abbreviation rich.", "labels": [], "entities": [{"text": "Google Maps TM", "start_pos": 37, "end_pos": 51, "type": "DATASET", "confidence": 0.9253241618474325}]}, {"text": "We note in passing that similar issues arise in automatic spelling correction work, where it is better to leave a word alone than to \"correct\" it wrongly.", "labels": [], "entities": [{"text": "automatic spelling correction", "start_pos": 48, "end_pos": 77, "type": "TASK", "confidence": 0.7545368870099386}]}], "datasetContent": [{"text": "We split the 3,209 labeled abbreviations into a training set of 2,209 examples and a held aside development set of 1,000 examples.", "labels": [], "entities": []}, {"text": "We first evaluate on the development set, then perform a final 10-fold cross validation over the entire set of labeled examples.", "labels": [], "entities": []}, {"text": "We evaluate in terms of the percentage of abbreviations that were correctly expanded (true positives, TP) and that were incorrectly expanded (false positives, FP).", "labels": [], "entities": [{"text": "TP", "start_pos": 102, "end_pos": 104, "type": "METRIC", "confidence": 0.9276735782623291}, {"text": "FP", "start_pos": 159, "end_pos": 161, "type": "METRIC", "confidence": 0.9978030323982239}]}, {"text": "The first two rows show the baseline TTS system and SVM model.", "labels": [], "entities": [{"text": "TTS", "start_pos": 37, "end_pos": 40, "type": "TASK", "confidence": 0.5592307448387146}]}, {"text": "On the development set, both systems have a false positive rate near 3%, i.e., three abbreviations are expanded incorrectly for every 100 examples; and over 50% true positive rate, i.e., more than half of the abbreviations are expanded correctly.", "labels": [], "entities": [{"text": "false positive rate", "start_pos": 44, "end_pos": 63, "type": "METRIC", "confidence": 0.9061044851938883}, {"text": "true positive rate", "start_pos": 161, "end_pos": 179, "type": "METRIC", "confidence": 0.8276564081509908}]}, {"text": "To report true and false positive rates for the N-gram system we would need to select an arbitrary decision threshold operating point, unlike the deterministic TTS baseline and the SVM model with its decision threshold of 0.", "labels": [], "entities": [{"text": "TTS baseline", "start_pos": 160, "end_pos": 172, "type": "DATASET", "confidence": 0.7346717566251755}]}, {"text": "Rather than tune such a meta-parameter to the development set, we instead present an ROC curve comparison of the N-gram and SVM models, and then propose a method for \"intersecting\" their output without requiring a tuned decision threshold.", "labels": [], "entities": [{"text": "ROC curve", "start_pos": 85, "end_pos": 94, "type": "METRIC", "confidence": 0.9280989170074463}]}, {"text": "presents an ROC curve for the N-gram and SVM systems, and for the simple Bayesian fusion (sum in log space) of their scores.", "labels": [], "entities": [{"text": "ROC", "start_pos": 12, "end_pos": 15, "type": "METRIC", "confidence": 0.9952998161315918}]}, {"text": "We can see that the SVM model has very high precision for its highest ranked examples, yielding nearly 20% of the correct expansions without any incorrect expansions.", "labels": [], "entities": [{"text": "precision", "start_pos": 44, "end_pos": 53, "type": "METRIC", "confidence": 0.99906986951828}]}, {"text": "However the N-gram system achieves higher true positive rates when the false   at the SVM's decision threshold corresponding to around 3.3% false positive rate.", "labels": [], "entities": [{"text": "true positive rates", "start_pos": 42, "end_pos": 61, "type": "METRIC", "confidence": 0.9330084323883057}]}, {"text": "The simple combination of their scores achieves strong improvements over either model, with an operating point associated with the SVM decision boundary that yields a couple of points improvement in true positives and a full 1% reduction in false positive rate.", "labels": [], "entities": [{"text": "false positive rate", "start_pos": 241, "end_pos": 260, "type": "METRIC", "confidence": 0.7450253168741862}]}, {"text": "One simple way to combine these two system outputs in away that does not require tuning a decision threshold is to expand the abbreviation if and only if).", "labels": [], "entities": []}, {"text": "Using this approach, our true positive rate on the dev set declines a bit to just over 50%, but our false positive rate declines over two full percentage points to 1.1%, yielding a very high precision system.", "labels": [], "entities": [{"text": "precision", "start_pos": 191, "end_pos": 200, "type": "METRIC", "confidence": 0.9966408014297485}]}, {"text": "Taking this very high precision system combination of the N-gram and SVM models, we then combine with the baseline TTS system as follows.", "labels": [], "entities": [{"text": "precision", "start_pos": 22, "end_pos": 31, "type": "METRIC", "confidence": 0.9691521525382996}]}, {"text": "First we apply our system, and expand the item if it scores above threshold; for those items left unexpanded, we let the TTS system process it in its own way.", "labels": [], "entities": []}, {"text": "In this way, we actually reduce the false positive rate on the dev set over the baseline TTS system by over 1% absolute to less than 2%, while increase of 18.5% Of course, at whether an OOV we also looked at of the collected d neously suggests a the 11,157 examp non-abbreviations, panded 45 items, of 0.4% under the should be expande found that 20% of of abbreviations th During system mented with a num sion approaches thing in detail here, ber of expansion ca guage model score; pansion when at le text is present for and CART tree (B with real valued s very high precision leaving many more found that, for use line TTS system, l positive rate were a tem with substanti higher FP rates, sin then passed along u tem, with its relativ To ensure that w tems to the dev se performed 10-fold set of abbreviation in.", "labels": [], "entities": [{"text": "OOV", "start_pos": 186, "end_pos": 189, "type": "METRIC", "confidence": 0.9961424469947815}, {"text": "CART", "start_pos": 525, "end_pos": 529, "type": "METRIC", "confidence": 0.9651033878326416}, {"text": "FP", "start_pos": 681, "end_pos": 683, "type": "METRIC", "confidence": 0.995672881603241}]}, {"text": "Most no has a much lower tr systems achieve pe the development se with the TTS base than the numbers o", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Results on held-out labeled data, and with final", "labels": [], "entities": []}]}