{"title": [{"text": "DKPro TC: A Java-based Framework for Supervised Learning Experiments on Textual Data", "labels": [], "entities": [{"text": "DKPro TC", "start_pos": 0, "end_pos": 8, "type": "DATASET", "confidence": 0.7944128215312958}]}], "abstractContent": [{"text": "We present DKPro TC, a framework for supervised learning experiments on tex-tual data.", "labels": [], "entities": [{"text": "DKPro TC", "start_pos": 11, "end_pos": 19, "type": "DATASET", "confidence": 0.800777018070221}]}, {"text": "The main goal of DKPro TC is to enable researchers to focus on the actual research task behind the learning problem and let the framework handle the rest.", "labels": [], "entities": [{"text": "DKPro TC", "start_pos": 17, "end_pos": 25, "type": "TASK", "confidence": 0.5693432092666626}]}, {"text": "It enables rapid prototyping of experiments by relying on an easy-to-use workflow engine and standardized document prepro-cessing based on the Apache Unstruc-tured Information Management Architecture (Ferrucci and Lally, 2004).", "labels": [], "entities": []}, {"text": "It ships with standard feature extraction modules, while at the same time allowing the user to add customized extractors.", "labels": [], "entities": []}, {"text": "The extensive reporting and logging facilities make DKPro TC experiments fully replicable.", "labels": [], "entities": [{"text": "logging", "start_pos": 28, "end_pos": 35, "type": "METRIC", "confidence": 0.9470850825309753}, {"text": "DKPro TC", "start_pos": 52, "end_pos": 60, "type": "DATASET", "confidence": 0.7146464288234711}]}], "introductionContent": [{"text": "Supervised learning on textual data is a ubiquitous challenge in Natural Language Processing (NLP).", "labels": [], "entities": [{"text": "Natural Language Processing (NLP)", "start_pos": 65, "end_pos": 98, "type": "TASK", "confidence": 0.685104489326477}]}, {"text": "Applying a machine learning classifier has become the standard procedure, as soon as there is annotated data available.", "labels": [], "entities": []}, {"text": "Before a classifier can be applied, relevant information (referred to as features) needs to be extracted from the data.", "labels": [], "entities": []}, {"text": "A wide range of tasks have been tackled in this way including language identification, part-of-speech (POS) tagging, word sense disambiguation, sentiment detection, and semantic similarity.", "labels": [], "entities": [{"text": "language identification", "start_pos": 62, "end_pos": 85, "type": "TASK", "confidence": 0.7703317105770111}, {"text": "part-of-speech (POS) tagging", "start_pos": 87, "end_pos": 115, "type": "TASK", "confidence": 0.6524542331695556}, {"text": "word sense disambiguation", "start_pos": 117, "end_pos": 142, "type": "TASK", "confidence": 0.7061663071314493}, {"text": "sentiment detection", "start_pos": 144, "end_pos": 163, "type": "TASK", "confidence": 0.9567014873027802}, {"text": "semantic similarity", "start_pos": 169, "end_pos": 188, "type": "TASK", "confidence": 0.731101781129837}]}, {"text": "In order to solve a supervised learning task, each researcher needs to perform the same set of steps in a predefined order: reading input data, preprocessing, feature extraction, machine learning, and evaluation.", "labels": [], "entities": [{"text": "feature extraction", "start_pos": 159, "end_pos": 177, "type": "TASK", "confidence": 0.7940698564052582}]}, {"text": "Standardizing this process is quite challenging, as each of these steps might vary a lot depending on the task at hand.", "labels": [], "entities": []}, {"text": "To complicate matters further, the experimental process is usually embedded in a series of configuration changes.", "labels": [], "entities": []}, {"text": "For example, introducing anew feature often requires additional preprocessing.", "labels": [], "entities": []}, {"text": "Researchers should not need to think too much about such details, but focus on the actual research task.", "labels": [], "entities": []}, {"text": "DKPro TC is our take on the standardization of an inherently complex problem, namely the implementation of supervised learning experiments for new datasets or new learning tasks.", "labels": [], "entities": [{"text": "DKPro TC", "start_pos": 0, "end_pos": 8, "type": "DATASET", "confidence": 0.7951221764087677}]}, {"text": "We will make some simplifying assumptions wherever they do not harm our goal that the framework should be applicable to the widest possible range of supervised learning tasks.", "labels": [], "entities": []}, {"text": "For example, DKPro TC only supports a limited set of machine learning frameworks, as we argue that differences between frameworks will mainly influence runtime, but will have little influence on the final conclusions to be drawn from the experiment.", "labels": [], "entities": [{"text": "DKPro TC", "start_pos": 13, "end_pos": 21, "type": "DATASET", "confidence": 0.7862472832202911}]}, {"text": "The main goal of DKPro TC is to enable the researcher to quickly find an optimal experimental configuration.", "labels": [], "entities": [{"text": "DKPro TC", "start_pos": 17, "end_pos": 25, "type": "TASK", "confidence": 0.6099019646644592}]}, {"text": "One of the major contributions of DKPro TC is the modular architecture for preprocessing and feature extraction, as we believe that the focus of research should be on a meaningful and expressive feature set.", "labels": [], "entities": [{"text": "DKPro TC", "start_pos": 34, "end_pos": 42, "type": "TASK", "confidence": 0.5587407797574997}, {"text": "feature extraction", "start_pos": 93, "end_pos": 111, "type": "TASK", "confidence": 0.7851476669311523}]}, {"text": "DKPro TC has already been applied to a wide range of different supervised learning tasks, which makes us confident that it will be of use to the research community.", "labels": [], "entities": [{"text": "DKPro TC", "start_pos": 0, "end_pos": 8, "type": "DATASET", "confidence": 0.8152587413787842}]}, {"text": "DKPro TC is mostly written in Java and freely available under an open source license.", "labels": [], "entities": [{"text": "DKPro TC", "start_pos": 0, "end_pos": 8, "type": "DATASET", "confidence": 0.925024688243866}]}], "datasetContent": [{"text": "DKPro TC calculates common evaluation scores including accuracy, precision, recall, and F 1 -score.", "labels": [], "entities": [{"text": "DKPro TC", "start_pos": 0, "end_pos": 8, "type": "DATASET", "confidence": 0.8213822543621063}, {"text": "accuracy", "start_pos": 55, "end_pos": 63, "type": "METRIC", "confidence": 0.9996967315673828}, {"text": "precision", "start_pos": 65, "end_pos": 74, "type": "METRIC", "confidence": 0.9992640614509583}, {"text": "recall", "start_pos": 76, "end_pos": 82, "type": "METRIC", "confidence": 0.9993821382522583}, {"text": "F 1 -score", "start_pos": 88, "end_pos": 98, "type": "METRIC", "confidence": 0.9901688396930695}]}, {"text": "Whenever sensible, scores are reported for each individual label as well as aggregated overall labels.", "labels": [], "entities": []}, {"text": "To support users in further analyzing the performance of a classification workflow, DKPro TC outputs the confusion matrix, the ac-tual predictions assigned to each document, and a ranking of the most useful features based on the configured feature selection algorithm.", "labels": [], "entities": []}, {"text": "Additional task-specific reporting can be added by the user.", "labels": [], "entities": []}, {"text": "As mentioned before, a major goal of DKPro TC is to increase the replicability of NLP experiments.", "labels": [], "entities": [{"text": "DKPro TC", "start_pos": 37, "end_pos": 45, "type": "TASK", "confidence": 0.572691410779953}, {"text": "replicability", "start_pos": 65, "end_pos": 78, "type": "TASK", "confidence": 0.9635718464851379}]}, {"text": "Thus, for each experiment, all configuration parameters are stored and will be reported together with the classification results.", "labels": [], "entities": []}], "tableCaptions": []}