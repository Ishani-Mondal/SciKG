{"title": [], "abstractContent": [{"text": "Recent work has sparked new interest in type-supervised part-of-speech tagging, a data setting in which no labeled sentences are available, but the set of allowed tags is known for each word type.", "labels": [], "entities": [{"text": "type-supervised part-of-speech tagging", "start_pos": 40, "end_pos": 78, "type": "TASK", "confidence": 0.610302597284317}]}, {"text": "This paper describes observational initializa-tion, a novel technique for initializing EM when training a type-supervised HMM tagger.", "labels": [], "entities": [{"text": "initializing EM", "start_pos": 74, "end_pos": 89, "type": "TASK", "confidence": 0.7533181309700012}]}, {"text": "Our initializer allocates probability mass to unambiguous transitions in an unlabeled corpus, generating token-level observations from type-level supervision.", "labels": [], "entities": []}, {"text": "Experimentally, observational initializa-tion gives state-of-the-art type-supervised tagging accuracy, providing an error reduction of 56% over uniform initialization on the Penn English Treebank.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 93, "end_pos": 101, "type": "METRIC", "confidence": 0.9782652854919434}, {"text": "error reduction", "start_pos": 116, "end_pos": 131, "type": "METRIC", "confidence": 0.9731470346450806}, {"text": "Penn English Treebank", "start_pos": 174, "end_pos": 195, "type": "DATASET", "confidence": 0.9830977519353231}]}], "introductionContent": [{"text": "For many languages, there exist comprehensive dictionaries that list the possible parts-of-speech for each word type, but there are no corpora labeled with the part-of-speech of each token in context.", "labels": [], "entities": []}, {"text": "Type-supervised tagging explores this scenario; a model is provided with type-level information, such as the fact that \"only\" can bean adjective, adverb, or conjunction, but not any token-level information about which instances of \"only\" in a corpus are adjectives.", "labels": [], "entities": [{"text": "Type-supervised tagging", "start_pos": 0, "end_pos": 23, "type": "TASK", "confidence": 0.710085541009903}]}, {"text": "Recent research has focused on using type-level supervision to infer token-level tags.", "labels": [], "entities": []}, {"text": "For instance, derive type-level supervision from Wiktionary, and project type-level tag sets across languages, and solicit type-level annotations directly from speakers.", "labels": [], "entities": []}, {"text": "In all of these efforts, a probabilistic sequence model is trained to disambiguate token-level tags that are * Research conducted during an internship at Google.", "labels": [], "entities": []}, {"text": "constrained to match type-level tag restrictions.", "labels": [], "entities": []}, {"text": "This paper describes observational initialization, a simple but effective learning technique for training type-supervised taggers.", "labels": [], "entities": [{"text": "observational initialization", "start_pos": 21, "end_pos": 49, "type": "TASK", "confidence": 0.5641296803951263}]}, {"text": "A hidden Markov model (HMM) can be used to disambiguate tags of individual tokens by maximizing corpus likelihood using the expectation maximization (EM) algorithm.", "labels": [], "entities": []}, {"text": "Our approach is motivated by a suite of oracle experiments that demonstrate the effect of initialization on the final tagging accuracy of an EM-trained HMM tagger.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 126, "end_pos": 134, "type": "METRIC", "confidence": 0.8908525705337524}, {"text": "EM-trained HMM tagger", "start_pos": 141, "end_pos": 162, "type": "TASK", "confidence": 0.46381862958272296}]}, {"text": "We show that initializing EM with accurate transition model parameters is sufficient to guide learning toward a high-accuracy final model.", "labels": [], "entities": [{"text": "initializing EM", "start_pos": 13, "end_pos": 28, "type": "TASK", "confidence": 0.7191688716411591}]}, {"text": "Inspired by this finding, we introduce observational initialization, which is a simple method to heuristically estimate transition parameters fora corpus using type-level supervision.", "labels": [], "entities": []}, {"text": "Transition probabilities are estimated from unambiguous consecutive tag pairs that arise when two consecutive words each have only a single allowed tag.", "labels": [], "entities": []}, {"text": "These unambiguous word pairs can be tagged correctly without any statistical inference.", "labels": [], "entities": []}, {"text": "Initializing EM with the relative frequency of these unambiguous pairs improves tagging accuracy dramatically over uniform initialization, reducing errors by 56% in English and 29% in German.", "labels": [], "entities": [{"text": "tagging", "start_pos": 80, "end_pos": 87, "type": "TASK", "confidence": 0.9600464105606079}, {"text": "accuracy", "start_pos": 88, "end_pos": 96, "type": "METRIC", "confidence": 0.9679965972900391}, {"text": "errors", "start_pos": 148, "end_pos": 154, "type": "METRIC", "confidence": 0.9865447878837585}]}, {"text": "This efficient and data-driven approach gives the best reported tagging accuracy for type-supervised sequence models, outperforming the minimized model of, the Bayesian LDA-based model of, and an HMM trained with language-specific initialization described by.", "labels": [], "entities": [{"text": "tagging", "start_pos": 64, "end_pos": 71, "type": "TASK", "confidence": 0.9526006579399109}, {"text": "accuracy", "start_pos": 72, "end_pos": 80, "type": "METRIC", "confidence": 0.9413594007492065}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Accuracy of English (top) and German  (bottom) tagging models at initialization (left) and  after 30 iterations of EM training (right) using var- ious initializers.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9860609769821167}]}, {"text": " Table 2: Tagging accuracy of different approaches on English Penn Treebank. Columns labeled 973k  train describe models trained on the subset of 973k tokens used by", "labels": [], "entities": [{"text": "Tagging", "start_pos": 10, "end_pos": 17, "type": "TASK", "confidence": 0.9712061882019043}, {"text": "accuracy", "start_pos": 18, "end_pos": 26, "type": "METRIC", "confidence": 0.9615587592124939}, {"text": "English Penn Treebank", "start_pos": 54, "end_pos": 75, "type": "DATASET", "confidence": 0.9561686118443807}]}]}