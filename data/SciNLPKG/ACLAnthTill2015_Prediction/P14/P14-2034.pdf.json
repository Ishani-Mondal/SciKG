{"title": [{"text": "Word Segmentation of Informal Arabic with Domain Adaptation", "labels": [], "entities": [{"text": "Word Segmentation", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.6145941317081451}]}], "abstractContent": [{"text": "Segmentation of clitics has been shown to improve accuracy on a variety of Arabic NLP tasks.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 50, "end_pos": 58, "type": "METRIC", "confidence": 0.9989140033721924}]}, {"text": "However, state-of-the-art Ara-bic word segmenters are either limited to formal Modern Standard Arabic, performing poorly on Arabic text featuring dialectal vocabulary and grammar, or rely on linguistic knowledge that is hand-tuned for each dialect.", "labels": [], "entities": [{"text": "Ara-bic word segmenters", "start_pos": 26, "end_pos": 49, "type": "TASK", "confidence": 0.613325297832489}]}, {"text": "We extend an existing MSA segmenter with a simple domain adaptation technique and new features in order to segment informal and dialectal Arabic text.", "labels": [], "entities": [{"text": "MSA segmenter", "start_pos": 22, "end_pos": 35, "type": "TASK", "confidence": 0.8681968450546265}]}, {"text": "Experiments show that our system outperforms existing systems on newswire, broadcast news and Egyptian dialect, improving segmentation F 1 score on a recently released Egyptian Arabic corpus to 95.1%, compared to 90.8% for another segmenter designed specifically for Egyptian Arabic.", "labels": [], "entities": [{"text": "segmentation F 1 score", "start_pos": 122, "end_pos": 144, "type": "METRIC", "confidence": 0.8912184536457062}]}], "introductionContent": [{"text": "Segmentation of words, clitics, and affixes is essential fora number of natural language processing (NLP) applications, including machine translation, parsing, and speech recognition ().", "labels": [], "entities": [{"text": "Segmentation of words, clitics", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.8308147668838501}, {"text": "machine translation", "start_pos": 130, "end_pos": 149, "type": "TASK", "confidence": 0.7728139758110046}, {"text": "speech recognition", "start_pos": 164, "end_pos": 182, "type": "TASK", "confidence": 0.7260359674692154}]}, {"text": "Segmentation is a common practice in Arabic NLP due to the language's morphological richness.", "labels": [], "entities": []}, {"text": "Specifically, clitic separation has been shown to improve performance on Arabic parsing and Arabic-English machine translation).", "labels": [], "entities": [{"text": "clitic separation", "start_pos": 14, "end_pos": 31, "type": "TASK", "confidence": 0.913485199213028}, {"text": "Arabic parsing", "start_pos": 73, "end_pos": 87, "type": "TASK", "confidence": 0.5883272588253021}, {"text": "Arabic-English machine translation", "start_pos": 92, "end_pos": 126, "type": "TASK", "confidence": 0.7060082952181498}]}, {"text": "However, the variety of Arabic dialects presents challenges in Arabic NLP.", "labels": [], "entities": []}, {"text": "Dialectal Arabic contains non-standard orthography, vocabulary, morphology, and syntax.", "labels": [], "entities": []}, {"text": "Tools that depend on corpora or grammatical properties that only consider formal Modern Standard Arabic (MSA) do not perform well when confronted with these differences.", "labels": [], "entities": []}, {"text": "The creation of annotated corpora in dialectal Arabic () has promoted the development of new systems that support dialectal Arabic, but these systems tend to be tailored to specific dialects and require separate efforts for Egyptian Arabic, Levantine Arabic, Maghrebi Arabic, etc.", "labels": [], "entities": []}, {"text": "We present a single clitic segmentation model that is accurate on both MSA and informal Arabic.", "labels": [], "entities": []}, {"text": "The model is an extension of the character-level conditional random field (CRF) model of.", "labels": [], "entities": []}, {"text": "Our work goes beyond theirs in three aspects.", "labels": [], "entities": []}, {"text": "First, we handle two Arabic orthographic normalization rules that commonly require rewriting of tokens after segmentation.", "labels": [], "entities": [{"text": "Arabic orthographic normalization", "start_pos": 21, "end_pos": 54, "type": "TASK", "confidence": 0.6607313752174377}]}, {"text": "Second, we add new features that improve segmentation accuracy.", "labels": [], "entities": [{"text": "segmentation", "start_pos": 41, "end_pos": 53, "type": "TASK", "confidence": 0.9779535531997681}, {"text": "accuracy", "start_pos": 54, "end_pos": 62, "type": "METRIC", "confidence": 0.876044511795044}]}, {"text": "Third, we show that dialectal data can be handled in the framework of domain adaptation.", "labels": [], "entities": []}, {"text": "Specifically, we show that even simple feature space augmentation) yields significant improvements in task accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 107, "end_pos": 115, "type": "METRIC", "confidence": 0.9819751381874084}]}, {"text": "We compare our work to the original Green and DeNero model and two other Arabic segmentation systems: the MADA+TOKAN toolkit v.", "labels": [], "entities": [{"text": "MADA+TOKAN toolkit", "start_pos": 106, "end_pos": 124, "type": "DATASET", "confidence": 0.6306026875972748}]}, {"text": "3.1 () and its Egyptian dialect variant, MADA-ARZ v.", "labels": [], "entities": []}, {"text": "We demonstrate that our system achieves better performance across the board, beating all three systems on MSA newswire, informal broadcast news, and Egyptian dialect.", "labels": [], "entities": [{"text": "MSA newswire", "start_pos": 106, "end_pos": 118, "type": "DATASET", "confidence": 0.9621297419071198}]}, {"text": "Our segmenter achieves a 95.1% F 1 segmentation score evaluated against a gold standard on Egyptian dialect data, compared to 90.8% for MADA-ARZ and 92.9% for In addition, our model decodes input an order of magnitude faster than either version of MADA.", "labels": [], "entities": [{"text": "F 1 segmentation score", "start_pos": 31, "end_pos": 53, "type": "METRIC", "confidence": 0.8335632309317589}]}, {"text": "Like the Green and DeNero system, but unlike MADA and MADA-ARZ, our system does not rely on a morphological analyzer, and can be applied directly to any dialect for which segmented training data is available.", "labels": [], "entities": []}, {"text": "The source code is available in the latest public release of the Stanford Word Segmenter (http://nlp.stanford.edu/software/ segmenter.shtml).", "labels": [], "entities": []}], "datasetContent": [{"text": "We train and evaluate on three corpora: parts 1-3 of the newswire Arabic Treebank (ATB), 1 the Broadcast News Arabic Treebank (BN), 2 and parts 1-8 of the BOLT Phase 1 Egyptian Arabic Treebank (ARZ).", "labels": [], "entities": [{"text": "newswire Arabic Treebank (ATB)", "start_pos": 57, "end_pos": 87, "type": "DATASET", "confidence": 0.8254846930503845}, {"text": "Broadcast News Arabic Treebank (BN)", "start_pos": 95, "end_pos": 130, "type": "DATASET", "confidence": 0.7816844539982932}, {"text": "BOLT Phase 1 Egyptian Arabic Treebank (ARZ)", "start_pos": 155, "end_pos": 198, "type": "DATASET", "confidence": 0.7965887387593588}]}, {"text": "3 These correspond respectively to the domains in section 2.2.", "labels": [], "entities": []}, {"text": "We target the segmentation scheme used by these corpora (leaving morphological affixes and the definite article attached).", "labels": [], "entities": []}, {"text": "For the ATB, we use the same split as.", "labels": [], "entities": [{"text": "ATB", "start_pos": 8, "end_pos": 11, "type": "DATASET", "confidence": 0.9443546533584595}]}, {"text": "For each of the other two corpora, we split the data into 80% training, 10% development, and 10% test in chronological order by document.", "labels": [], "entities": []}, {"text": "We train the Green and DeNero model and our improvements using L-BFGS with L 2 regularization.", "labels": [], "entities": []}, {"text": "We use two evaluation metrics in our experiments.", "labels": [], "entities": []}, {"text": "The first is an F 1 precision-recall measure, ignoring orthographic rewrites.", "labels": [], "entities": [{"text": "F 1 precision-recall measure", "start_pos": 16, "end_pos": 44, "type": "METRIC", "confidence": 0.846075564622879}]}, {"text": "F 1 scores provide a more informative assessment of performance than wordlevel or character-level accuracy scores, as over 80% of tokens in the development sets consist of only one segment, with an average of one segmentation every 4.7 tokens (or one every 20.4 characters).", "labels": [], "entities": [{"text": "F 1 scores", "start_pos": 0, "end_pos": 10, "type": "METRIC", "confidence": 0.7315694689750671}, {"text": "accuracy", "start_pos": 98, "end_pos": 106, "type": "METRIC", "confidence": 0.9327684640884399}]}, {"text": "The second metric we use is the TEDEval metric ().", "labels": [], "entities": [{"text": "TEDEval metric", "start_pos": 32, "end_pos": 46, "type": "METRIC", "confidence": 0.9015202820301056}]}, {"text": "TEDEval was developed to evaluate joint segmentation and parsing 5 in Hebrew, which requires a greater variety of orthographic rewrites than those possible in Arabic.", "labels": [], "entities": [{"text": "joint segmentation", "start_pos": 34, "end_pos": 52, "type": "TASK", "confidence": 0.595390185713768}]}, {"text": "Its edit distance-based scoring algorithm is robust enough to handle the rewrites produced by both MADA and our segmenter.", "labels": [], "entities": [{"text": "MADA", "start_pos": 99, "end_pos": 103, "type": "DATASET", "confidence": 0.8090541362762451}]}, {"text": "We measure the statistical significance of differences in these metrics with an approximate randomization test), with R = 10,000 samples.", "labels": [], "entities": []}, {"text": "contains results on the development set for the model of Green and DeNero and our improvements.", "labels": [], "entities": [{"text": "DeNero", "start_pos": 67, "end_pos": 73, "type": "DATASET", "confidence": 0.7366767525672913}]}, {"text": "Using domain adaptation alone helps performance on two of the three datasets (with a statistically insignificant decrease on broadcast news), and that our additional features further improve: Wallclock time (in seconds) for MADA, MADA-ARZ, and our model for decoding each of the three development datasets.", "labels": [], "entities": [{"text": "Wallclock time", "start_pos": 192, "end_pos": 206, "type": "METRIC", "confidence": 0.8592747449874878}]}, {"text": "Means and standard deviations were computed for 10 independent runs.", "labels": [], "entities": [{"text": "Means", "start_pos": 0, "end_pos": 5, "type": "METRIC", "confidence": 0.9926217794418335}]}, {"text": "MADA and MADA-ARZ are single-threaded.", "labels": [], "entities": [{"text": "MADA", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.9109129905700684}, {"text": "MADA-ARZ", "start_pos": 9, "end_pos": 17, "type": "DATASET", "confidence": 0.9080192446708679}]}, {"text": "Our segmenter supports multithreaded execution, but the times reported here are for single-threaded runs.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Development set results. GD is the model of Green and DeNero (2012). Rew is support for  orthographic rewrites with the RRRAA and RRRT labels. The fifth row shows the strongest baseline,  which is the GD+Rew model trained on the concatenated training sets from all three treebanks. DA is  domain adaptation via feature space augmentation. Feat adds the additional feature templates described  in section 2.1. ATB is the newswire ATB; BN is the Broadcast News treebank; ARZ is the Egyptian  treebank. Best results (bold) are statistically significant (p < 0.001) relative to the strongest baseline.", "labels": [], "entities": [{"text": "domain adaptation", "start_pos": 299, "end_pos": 316, "type": "TASK", "confidence": 0.7101903408765793}, {"text": "Broadcast News treebank", "start_pos": 454, "end_pos": 477, "type": "DATASET", "confidence": 0.950781007607778}, {"text": "Egyptian  treebank", "start_pos": 490, "end_pos": 508, "type": "DATASET", "confidence": 0.885913074016571}]}, {"text": " Table 2: Test set results. Our final model (last row) is trained on all available data (ATB+BN+ARZ). Best  results (bold) are statistically significant (p < 0.001) relative to each MADA version.", "labels": [], "entities": [{"text": "ATB+BN+ARZ)", "start_pos": 89, "end_pos": 100, "type": "METRIC", "confidence": 0.8422459959983826}, {"text": "MADA", "start_pos": 182, "end_pos": 186, "type": "DATASET", "confidence": 0.6748721599578857}]}, {"text": " Table 3: Wallclock time (in seconds) for MADA, MADA-ARZ, and our model for decoding each of  the three development datasets. Means and standard deviations were computed for 10 independent runs.  MADA and MADA-ARZ are single-threaded. Our segmenter supports multithreaded execution, but the  times reported here are for single-threaded runs.", "labels": [], "entities": [{"text": "Wallclock time", "start_pos": 10, "end_pos": 24, "type": "METRIC", "confidence": 0.8367974758148193}]}, {"text": " Table 4: Counts of error categories (out of 100  randomly sampled ARZ development set errors).", "labels": [], "entities": [{"text": "Counts", "start_pos": 10, "end_pos": 16, "type": "METRIC", "confidence": 0.959471583366394}, {"text": "ARZ development set errors", "start_pos": 67, "end_pos": 93, "type": "DATASET", "confidence": 0.7735601961612701}]}]}