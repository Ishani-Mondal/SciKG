{"title": [{"text": "A Decision-Theoretic Approach to Natural Language Generation", "labels": [], "entities": []}], "abstractContent": [{"text": "We study the problem of generating an En-glish sentence given an underlying prob-abilistic grammar, a world and a communicative goal.", "labels": [], "entities": []}, {"text": "We model the generation problem as a Markov decision process with a suitably defined reward function that reflects the communicative goal.", "labels": [], "entities": []}, {"text": "We then use probabilistic planning to solve the MDP and generate a sentence that, with high probability, accomplishes the communicative goal.", "labels": [], "entities": []}, {"text": "We show empirically that our approach can generate complex sentences with a speed that generally matches or surpasses the state of the art.", "labels": [], "entities": []}, {"text": "Further, we show that our approach is anytime and can handle complex communicative goals, including negated goals.", "labels": [], "entities": []}], "introductionContent": [{"text": "Suppose someone wants to tell their friend that they saw a dog chasing a cat.", "labels": [], "entities": []}, {"text": "Given such a communicative goal, most people can formulate a sentence that satisfies the goal very quickly.", "labels": [], "entities": []}, {"text": "Further, they can easily provide multiple similar sentences, differing in details but all satisfying the general communicative goal, with no or very little error.", "labels": [], "entities": []}, {"text": "Natural language generation (NLG) develops techniques to extend similar capabilities to automated systems.", "labels": [], "entities": [{"text": "Natural language generation (NLG)", "start_pos": 0, "end_pos": 33, "type": "TASK", "confidence": 0.7774895230929056}]}, {"text": "In this paper, we study the restricted NLG problem: given a grammar, lexicon, world and a communicative goal, output a valid English sentence that satisfies this goal.", "labels": [], "entities": []}, {"text": "The problem is restricted because in our work, we do not consider the issue of how to fragment a complex goal into multiple sentences (discourse planning).", "labels": [], "entities": []}, {"text": "Though restricted, this NLG problem is still difficult.", "labels": [], "entities": []}, {"text": "A key source of difficulty is the nature of the grammar, which is generally large, probabilistic and ambiguous.", "labels": [], "entities": []}, {"text": "Some NLG techniques use sampling strategies where a set of sentences is sampled from a data structure created from an underlying grammar and ranked according to how well they meet the communicative goal.", "labels": [], "entities": []}, {"text": "Such approaches naturally handle statistical grammars, but do not solve the generation problem in a goal-directed manner.", "labels": [], "entities": []}, {"text": "Other approaches view NLG as a planning problem (.", "labels": [], "entities": []}, {"text": "Here, the communicative goal is treated as a predicate to be satisfied, and the grammar and vocabulary are suitably encoded as logical operators.", "labels": [], "entities": []}, {"text": "Then automated classical planning techniques are used to derive a plan which is converted into a sentence.", "labels": [], "entities": []}, {"text": "This is an elegant formalization of NLG, however, restrictions on what current planning techniques can do limit its applicability.", "labels": [], "entities": []}, {"text": "A key limitation is the logical nature of automated planning systems, which do not handle probabilistic grammars, or force ad-hoc approaches for doing so.", "labels": [], "entities": []}, {"text": "A second limitation comes from restrictions on the goal: it maybe difficult to ensure that some specific piece of information should not be communicated, or to specify preferences over communicative goals, or specify general conditions, like that the sentence should be readable by a sixth grader.", "labels": [], "entities": []}, {"text": "A third limitation comes from the search process: without strong heuristics, most planners get bogged down when given communicative goals that require chaining together long sequences of operators ().", "labels": [], "entities": []}, {"text": "In our work, we also view NLG as a planning problem.", "labels": [], "entities": []}, {"text": "However, we differ in that our underlying formalism for NLG is a suitably defined Markov decision process (MDP).", "labels": [], "entities": []}, {"text": "This setting allows us to address the limitations outlined above: it is naturally probabilistic, and handles probabilistic grammars; we are able to specify complex communicative goals and general criteria through a suitably-defined reward function; and, as we show in our experiments, recent developments in fast planning in large MDPs result in a generation system that can rapidly deal with very specific communicative goals.", "labels": [], "entities": []}, {"text": "Further, our system has several other desirable properties: it is an anytime approach; with a probabilistic grammar, it can naturally be used to sample and generate multiple sentences satisfying the communicative goal; and it is robust to large grammar sizes.", "labels": [], "entities": []}, {"text": "Finally, the decision-theoretic setting allows fora precise tradeoff between exploration of the grammar and vocabulary to find a better solution and exploitation of the current most promising (partial) solution, instead of a heuristic search through the solution space as performed by standard planning approaches.", "labels": [], "entities": []}, {"text": "Below, we first describe related work, followed by a detailed description of our approach.", "labels": [], "entities": []}, {"text": "We then empirically evaluate our approach and a state-ofthe-art baseline in several different experimental settings and demonstrate its effectiveness at solving a variety of NLG tasks.", "labels": [], "entities": []}, {"text": "Finally, we discuss future extensions and conclude.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section, we compare STRUCT to a stateof-the-art NLG system, CRISP, 1 and evaluate three hypotheses: (i) STRUCT is comparable in speed and generation quality to CRISP as it generates increasingly large referring expressions, (ii) STRUCT is comparable in speed and generation quality to CRISP as the size of the grammar which they use increases, and (iii) STRUCT is capable of communicating complex propositions, including multiple concurrent goals, negated goals, and nested subclauses.", "labels": [], "entities": []}, {"text": "For these experiments, STRUCT was implemented in Python 2.7.", "labels": [], "entities": [{"text": "STRUCT", "start_pos": 23, "end_pos": 29, "type": "METRIC", "confidence": 0.5112782120704651}]}, {"text": "We used a 2010 version of CRISP which uses a Java-based GraphPlan implementation.", "labels": [], "entities": []}, {"text": "All of our experiments were run on a 4-core AMD Phenom II X4 995 processor clocked at 3.2 GHz.", "labels": [], "entities": []}, {"text": "Both systems were given access to 8 We were unfortunately unable to get the PCRISP system to compile, and so we could not evaluate it.", "labels": [], "entities": [{"text": "PCRISP system", "start_pos": 76, "end_pos": 89, "type": "DATASET", "confidence": 0.9265973567962646}]}], "tableCaptions": []}