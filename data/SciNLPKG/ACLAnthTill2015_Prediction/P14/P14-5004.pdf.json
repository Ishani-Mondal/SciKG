{"title": [{"text": "Community Evaluation and Exchange of Word Vectors at wordvectors.org", "labels": [], "entities": []}], "abstractContent": [{"text": "Vector space word representations are useful for many natural language processing applications.", "labels": [], "entities": [{"text": "Vector space word representations", "start_pos": 0, "end_pos": 33, "type": "TASK", "confidence": 0.8298068791627884}]}, {"text": "The diversity of techniques for computing vector representations and the large number of evaluation benchmarks makes reliable comparison a tedious task both for researchers developing new vector space models and for those wishing to use them.", "labels": [], "entities": []}, {"text": "We present a website and suite of offline tools that that facilitate evaluation of word vectors on standard lexical semantics benchmarks and permit exchange and archival by users who wish to find good vectors for their applications.", "labels": [], "entities": []}, {"text": "The system is accessible at: www.wordvectors.org.", "labels": [], "entities": []}], "introductionContent": [{"text": "Data-driven learning of vector-space word embeddings that capture lexico-semantic properties is a technique of central importance in natural language processing.", "labels": [], "entities": [{"text": "Data-driven learning of vector-space word embeddings", "start_pos": 0, "end_pos": 52, "type": "TASK", "confidence": 0.6974349766969681}, {"text": "natural language processing", "start_pos": 133, "end_pos": 160, "type": "TASK", "confidence": 0.6371172666549683}]}, {"text": "Using co-occurrence statistics from a large corpus of text, it is possible to construct high-quality semantic vectors -as judged by both correlations with human judgements of semantic relatedness) and as features for downstream applications.", "labels": [], "entities": []}, {"text": "A number of approaches that use the internal representations from models of word sequences or continuous bags-of-context wordsets () to arrive at vector representations have also been shown to likewise capture co-occurrence tendencies and meanings.", "labels": [], "entities": []}, {"text": "With an overwhelming number of techniques to obtain word vector representations the task of comparison and choosing the vectors best suitable fora particular task becomes difficult.", "labels": [], "entities": []}, {"text": "This is further aggravated by the large number of existing lexical semantics evaluation benchmarks being constructed by the research community.", "labels": [], "entities": []}, {"text": "For example, to the best of our knowledge, for evaluating word similarity between a given pair of words, there are currently at least 10 existing benchmarks 1 that are being used by researchers to prove the effectiveness of their word vectors.", "labels": [], "entities": []}, {"text": "In this paper we describe an online application that provides the following utilities: \u2022 Access to a suite of word similarity evaluation benchmarks \u2022 Evaluation of user computed word vectors \u2022 Visualizing word vectors in R 2 \u2022 Evaluation and comparison of the available open-source vectors on the suite \u2022 Submission of user vectors for exhaustive offline evaluation and leader board ranking \u2022 Publicly available repository of word vectors with performance details Availability of such an evaluation system will help in enabling better consistency and uniformity in evaluation of word vector representations as well as provide an easy to use interface for endusers in a similar spirit to, a website for text classification.", "labels": [], "entities": [{"text": "text classification", "start_pos": 702, "end_pos": 721, "type": "TASK", "confidence": 0.757252424955368}]}, {"text": "Apart from the online demo version, we also provide a software that can be run in an offline mode on the command line.", "labels": [], "entities": []}, {"text": "Both the online and offline tools will be kept updated with continuous addition of new relevant tasks and vectors.", "labels": [], "entities": []}], "datasetContent": [{"text": "We provide an online portal where researchers can upload their vectors which are then be evaluated on a variety of NLP tasks and then placed on the leader board.", "labels": [], "entities": []}, {"text": "The motivation behind creating such a portal is to make it easier fora user to select the kind of vector representation that is most suitable for their task.", "labels": [], "entities": []}, {"text": "In this scenario, instead of asking the uploader to filter their word vectors fora small vocabulary, they will be requested to upload their vectors for the entire vocabulary.", "labels": [], "entities": []}, {"text": "present anew semantic and syntactic relation dataset composed of analogous word pairs of size 8869 and 10675 pairs resp..", "labels": [], "entities": []}, {"text": "It contains pairs of tuples of word relations that follow a common relation.", "labels": [], "entities": []}, {"text": "For example, in England : London :: France : Paris, the two given pairs of words follow the country-capital relation.", "labels": [], "entities": []}, {"text": "We use the vector offset method () to compute the missing word in these relations.", "labels": [], "entities": []}, {"text": "This is non-trivial |V |-way classification task where V is the size of the vocabulary.", "labels": [], "entities": []}, {"text": "The Microsoft Research sentence completion dataset contains 1040 sentences from each of which one word has been removed.", "labels": [], "entities": [{"text": "Microsoft Research sentence completion dataset", "start_pos": 4, "end_pos": 50, "type": "DATASET", "confidence": 0.8171093940734864}]}, {"text": "The task is to correctly predict the missing word from a given list of 5 other words per sentence.", "labels": [], "entities": []}, {"text": "We average the word vectors of a given sentence q sent = N i=1,i =j q w i /N , where w j is the missing word and compute the cosine similarity of q sent vector with each of the options.", "labels": [], "entities": []}, {"text": "The word with the highest similarity is chosen as the missing word placeholder.", "labels": [], "entities": []}, {"text": "have created a treebank which contains sentences annotated with fine-grained sentiment labels on both the phrase and sentence level.", "labels": [], "entities": []}, {"text": "They show that compositional vector space models can be used to predict sentiment at these levels with high accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 108, "end_pos": 116, "type": "METRIC", "confidence": 0.9933748841285706}]}, {"text": "The coarse-grained treebank, containing only positive and negative classes has been split into training, development and test datasets con- taining 6920, 872 and 1821 sentences respectively.", "labels": [], "entities": []}, {"text": "We train a logistic regression classifier with L2 regularization on the average of the word vectors of a given sentence to predict the coarse-grained sentiment tag at the sentence level.", "labels": [], "entities": []}], "tableCaptions": []}