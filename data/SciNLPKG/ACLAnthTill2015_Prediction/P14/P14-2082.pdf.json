{"title": [{"text": "An Annotation Framework for Dense Event Ordering", "labels": [], "entities": [{"text": "Dense Event Ordering", "start_pos": 28, "end_pos": 48, "type": "TASK", "confidence": 0.8615780274073283}]}], "abstractContent": [{"text": "Today's event ordering research is heavily dependent on annotated corpora.", "labels": [], "entities": [{"text": "event ordering", "start_pos": 8, "end_pos": 22, "type": "TASK", "confidence": 0.8805459439754486}]}, {"text": "Current corpora influence shared evaluations and drive algorithm development.", "labels": [], "entities": []}, {"text": "Partly due to this dependence, most research fo-cuses on partial orderings of a document's events.", "labels": [], "entities": []}, {"text": "For instance, the TempEval competitions and the TimeBank only annotate small portions of the event graph, focusing on the most salient events or on specific types of event pairs (e.g., only events in the same sentence).", "labels": [], "entities": [{"text": "TimeBank", "start_pos": 48, "end_pos": 56, "type": "DATASET", "confidence": 0.9308479428291321}]}, {"text": "Deeper temporal reason-ers struggle with this sparsity because the entire temporal picture is not represented.", "labels": [], "entities": []}, {"text": "This paper proposes anew annotation process with a mechanism to force annotators to label connected graphs.", "labels": [], "entities": []}, {"text": "It generates 10 times more relations per document than the TimeBank, and our TimeBank-Dense corpus is larger than all current corpora.", "labels": [], "entities": [{"text": "TimeBank", "start_pos": 59, "end_pos": 67, "type": "DATASET", "confidence": 0.963065505027771}, {"text": "TimeBank-Dense corpus", "start_pos": 77, "end_pos": 98, "type": "DATASET", "confidence": 0.9659989476203918}]}, {"text": "We hope this process and its dense corpus encourages research on new global models with deeper reasoning.", "labels": [], "entities": []}], "introductionContent": [{"text": "The TimeBank Corpus ( ushered in a wave of data-driven event ordering research.", "labels": [], "entities": [{"text": "TimeBank Corpus", "start_pos": 4, "end_pos": 19, "type": "DATASET", "confidence": 0.952831506729126}, {"text": "event ordering", "start_pos": 55, "end_pos": 69, "type": "TASK", "confidence": 0.72063048183918}]}, {"text": "It provided fora common dataset of relations between events and time expressions that allowed the community to compare approaches.", "labels": [], "entities": []}, {"text": "Later corpora and competitions have based their tasks on the TimeBank setup.", "labels": [], "entities": []}, {"text": "This paper addresses one of its shortcomings: sparse annotation.", "labels": [], "entities": []}, {"text": "We describe anew annotation framework (and a TimeBank-Dense corpus) that we believe is needed to fulfill the data needs of deeper reasoners.", "labels": [], "entities": [{"text": "TimeBank-Dense corpus", "start_pos": 45, "end_pos": 66, "type": "DATASET", "confidence": 0.9413352310657501}]}, {"text": "The TimeBank includes a small subset of all possible relations in its documents.", "labels": [], "entities": [{"text": "TimeBank", "start_pos": 4, "end_pos": 12, "type": "DATASET", "confidence": 0.9590398073196411}]}, {"text": "The annotators were instructed to label relations critical to the document's understanding.", "labels": [], "entities": []}, {"text": "The result is a sparse labeling that leaves much of the document unlabeled.", "labels": [], "entities": []}, {"text": "The TempEval contests have largely followed suit and focused on specific types of event pairs.", "labels": [], "entities": []}, {"text": "For instance, only labeled relations between events that syntactically dominated each other.", "labels": [], "entities": []}, {"text": "This paper is the first attempt to annotate a document's entire temporal graph.", "labels": [], "entities": []}, {"text": "A consequence of focusing on all relations is a shift from the traditional classification task, where the system is given a pair of events and asked only to label the type of relation, to an identification task, where the system must determine for itself which events in the document to pair up.", "labels": [], "entities": []}, {"text": "For example, in TempEval-1 and 2 (, systems were given event pairs in specific syntactic positions: events and times in the same noun phrase, main events in consecutive sentences, etc.", "labels": [], "entities": []}, {"text": "We now aim fora shift in the community wherein all pairs are considered candidates for temporal ordering, allowing researchers to ask questions such as: how must algorithms adapt to label the complete graph of pairs, and if the more difficult and ambiguous event pairs are included, how must feature-based learners change?", "labels": [], "entities": [{"text": "temporal ordering", "start_pos": 87, "end_pos": 104, "type": "TASK", "confidence": 0.7350896298885345}]}, {"text": "We are not the first to propose these questions, but this paper is the first to directly propose the means by which they can be addressed.", "labels": [], "entities": []}, {"text": "The stated goal of) was to focus on relation identification instead of classification, but the training and evaluation data followed the TimeBank approach where only a subset of event pairs were labeled.", "labels": [], "entities": [{"text": "relation identification", "start_pos": 36, "end_pos": 59, "type": "TASK", "confidence": 0.9179426729679108}]}, {"text": "As a result, many systems focused on classification, with the top system classifying pairs in only three syntactic constructions There were four or five people inside, and they just started firing Ms.", "labels": [], "entities": []}, {"text": "Sanders was hit several times and was pronounced dead at the scene.", "labels": [], "entities": []}, {"text": "The other customers fled, and the police said it did not appear that anyone else was injured.", "labels": [], "entities": []}, {"text": "There were four or five people inside, and they just started firing Ms.", "labels": [], "entities": []}, {"text": "Sanders was hit several times and was pronounced dead at the scene.", "labels": [], "entities": []}, {"text": "The other customers fled, and the police said it did not appear that anyone else was injured.", "labels": [], "entities": []}, {"text": "(. We describe the first annotation framework that forces annotators to annotate all pairs . With this new process, we created a dense ordering of document events that can properly evaluate both relation identification and relation annotation.", "labels": [], "entities": [{"text": "relation identification", "start_pos": 195, "end_pos": 218, "type": "TASK", "confidence": 0.7674144804477692}]}, {"text": "illustrates one document before and after our new annotations.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Events, times, relations and the ratio of  relations to events + times (R) in various corpora.", "labels": [], "entities": []}, {"text": " Table 3: Agreement between different annotators.", "labels": [], "entities": []}, {"text": " Table 4: VAGUE relation origins. Partial vague:  one annotator does not choose vague. No vague:  neither annotator chooses vague.", "labels": [], "entities": [{"text": "VAGUE relation origins", "start_pos": 10, "end_pos": 32, "type": "TASK", "confidence": 0.5039866964022318}]}, {"text": " Table 5: Relation agreement between the two main  annotators. Most disagreements involved VAGUE.", "labels": [], "entities": [{"text": "Relation", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.7034557461738586}, {"text": "VAGUE", "start_pos": 91, "end_pos": 96, "type": "METRIC", "confidence": 0.5030940175056458}]}]}