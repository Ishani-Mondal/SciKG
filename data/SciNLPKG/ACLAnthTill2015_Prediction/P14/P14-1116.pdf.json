{"title": [{"text": "Comparing Multi-label Classification with Reinforcement Learning for Summarisation of Time-series Data", "labels": [], "entities": [{"text": "Multi-label Classification", "start_pos": 10, "end_pos": 36, "type": "TASK", "confidence": 0.743047446012497}, {"text": "Summarisation of Time-series", "start_pos": 69, "end_pos": 97, "type": "TASK", "confidence": 0.8457750280698141}]}], "abstractContent": [{"text": "We present a novel approach for automatic report generation from time-series data, in the context of student feedback generation.", "labels": [], "entities": [{"text": "automatic report generation", "start_pos": 32, "end_pos": 59, "type": "TASK", "confidence": 0.6154606640338898}, {"text": "student feedback generation", "start_pos": 101, "end_pos": 128, "type": "TASK", "confidence": 0.595367838939031}]}, {"text": "Our proposed methodology treats content selection as a multi-label (ML) classification problem, which takes as input time-series data and outputs a set of templates, while capturing the dependencies between selected templates.", "labels": [], "entities": [{"text": "content selection", "start_pos": 32, "end_pos": 49, "type": "TASK", "confidence": 0.7389252185821533}, {"text": "ML) classification", "start_pos": 68, "end_pos": 86, "type": "TASK", "confidence": 0.6870672901471456}]}, {"text": "We show that this method generates output closer to the feedback that lecturers actually generated , achieving 3.5% higher accuracy and 15% higher F-score than multiple simple classifiers that keep a history of selected templates.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 123, "end_pos": 131, "type": "METRIC", "confidence": 0.9987886548042297}, {"text": "F-score", "start_pos": 147, "end_pos": 154, "type": "METRIC", "confidence": 0.9989699125289917}]}, {"text": "Furthermore, we compare a ML classifier with a Reinforcement Learning (RL) approach in simulation and using ratings from real student users.", "labels": [], "entities": [{"text": "ML classifier", "start_pos": 26, "end_pos": 39, "type": "TASK", "confidence": 0.9218645989894867}]}, {"text": "We show that the different methods have different benefits, with ML being more accurate for predicting what was seen in the training data, whereas RL is more exploratory and slightly preferred by the students.", "labels": [], "entities": [{"text": "ML", "start_pos": 65, "end_pos": 67, "type": "METRIC", "confidence": 0.5674499273300171}, {"text": "RL", "start_pos": 147, "end_pos": 149, "type": "METRIC", "confidence": 0.9045507311820984}]}], "introductionContent": [{"text": "Summarisation of time-series data refers to the task of automatically generating text from variables whose values changeover time.", "labels": [], "entities": [{"text": "Summarisation of time-series", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.8807406226793925}]}, {"text": "We consider the task of automatically generating feedback summaries for students describing their performance during the lab of a Computer Science module over the semester.", "labels": [], "entities": []}, {"text": "Students' learning can be influenced by many variables, such as difficulty of the material (, other deadlines (), attendance in lectures, etc.", "labels": [], "entities": []}, {"text": "These variables have two important qualities.", "labels": [], "entities": []}, {"text": "Firstly, they changeover time, and secondly they can be dependent on or independent of each other.", "labels": [], "entities": []}, {"text": "Therefore, when generating feedback, we need to take into account all variables simultaneously in order to capture potential dependencies and provide more effective and useful feedback that is relevant to the students.", "labels": [], "entities": []}, {"text": "In this work, we concentrate on content selection which is the task of choosing what to say, i.e. what information is to be included in a report).", "labels": [], "entities": [{"text": "content selection", "start_pos": 32, "end_pos": 49, "type": "TASK", "confidence": 0.7051438540220261}]}, {"text": "Content selection decisions based on trends in time-series data determine the selection of the useful and important variables, which we refer to here as factors, that should be conveyed in a summary.", "labels": [], "entities": [{"text": "Content selection", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.7469048798084259}]}, {"text": "The decisions of factor selection can be influenced by other factors that their values are correlated with; can be based on the appearance or absence of other factors in the summary; and can be based on the factors' behaviour overtime.", "labels": [], "entities": []}, {"text": "Moreover, some factors may have to be discussed together in order to achieve some communicative goal, for instance, a teacher might want to refer to student's marks as a motivation for increasing the number of hours studied.", "labels": [], "entities": []}, {"text": "We frame content selection as a simple classification task: given a set of time-series data, decide for each template whether it should be included in a summary or not.", "labels": [], "entities": [{"text": "content selection", "start_pos": 9, "end_pos": 26, "type": "TASK", "confidence": 0.698317363858223}]}, {"text": "In this paper, with the term 'template' we refer to a quadruple consisting of an id, a factor (bottom left of), a reference type (trend, weeks, average, other) and surface text.", "labels": [], "entities": []}, {"text": "However, simple classification assumes that the templates are independent of each other, thus the decision for each template is taken in isolation from the others, which is not appropriate for our domain.", "labels": [], "entities": []}, {"text": "In order to capture the dependencies in the context, multiple simple classifiers can make the decisions for each template iteratively.", "labels": [], "entities": []}, {"text": "After each iteration, the feature space grows by 1 feature, in order to include the history of the previous template decisions.", "labels": [], "entities": []}, {"text": "Here, we propose an alternative method that tackles the challenge of interdependent data by using multi-label (ML) classification, which is efficient in taking data dependencies into account and generating a set of labels (in our case templates) simultaneously (.", "labels": [], "entities": [{"text": "ML) classification", "start_pos": 111, "end_pos": 129, "type": "TASK", "confidence": 0.6679089864095052}]}, {"text": "ML classification requires no history, i.e. does not keep track of previous decisions, and thus has a smaller feature space.", "labels": [], "entities": [{"text": "ML classification", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.9361892342567444}]}, {"text": "Our contributions to the field are as follows: we present a novel and efficient method for tackling the challenge of content selection using a ML classification approach; we applied this method to the domain of feedback summarisation; we present a comparison with an optimisation technique (Reinforcement Learning), and we discuss the similarities and differences between the two methods.", "labels": [], "entities": [{"text": "tackling the challenge of content selection", "start_pos": 91, "end_pos": 134, "type": "TASK", "confidence": 0.5746598094701767}, {"text": "ML classification", "start_pos": 143, "end_pos": 160, "type": "TASK", "confidence": 0.8518530130386353}, {"text": "feedback summarisation", "start_pos": 211, "end_pos": 233, "type": "TASK", "confidence": 0.6745710670948029}]}, {"text": "In the next section, we refer to the related work on Natural Language Generation from time-series data and on Content Selection.", "labels": [], "entities": [{"text": "Natural Language Generation", "start_pos": 53, "end_pos": 80, "type": "TASK", "confidence": 0.6346799830595652}, {"text": "Content Selection", "start_pos": 110, "end_pos": 127, "type": "TASK", "confidence": 0.7851184010505676}]}, {"text": "In Section 4.2, we describe our approach and we carryout a comparison with simple classification methods.", "labels": [], "entities": []}, {"text": "In Section 5, we present the evaluation setup and in Section 6 we discuss the results, obtained in simulation and with real students.", "labels": [], "entities": []}, {"text": "Finally, in Section 8, directions for future work are discussed.", "labels": [], "entities": []}], "datasetContent": [{"text": "Firstly, we performed a preliminary evaluation on classification methods, comparing our proposed ML classification with multiple iterated classification approaches.", "labels": [], "entities": [{"text": "ML classification", "start_pos": 97, "end_pos": 114, "type": "TASK", "confidence": 0.9503071308135986}]}, {"text": "The summaries generated by the ML classification system are then compared with the output of a RL system and two baseline systems in simulation and with real students.", "labels": [], "entities": [{"text": "ML classification", "start_pos": 31, "end_pos": 48, "type": "TASK", "confidence": 0.9075944125652313}]}], "tableCaptions": [{"text": " Table 1: The table on the top left shows an example of the time-series raw data for feedback generation.  The table on the bottom left shows an example of described trends. The box on the right presents a target  summary (target summaries have been constructed by teaching staff).", "labels": [], "entities": [{"text": "feedback generation", "start_pos": 85, "end_pos": 104, "type": "TASK", "confidence": 0.7669520378112793}]}, {"text": " Table 2: The table presents the Pearson's correlation coefficients of the factors (* means p<0.05).", "labels": [], "entities": [{"text": "Pearson's correlation", "start_pos": 33, "end_pos": 54, "type": "METRIC", "confidence": 0.9467569986979166}]}, {"text": " Table 3: Average, precision, recall and F-score of the different classification methods (T-test, * denotes  significance with p<0.05 and ** significance with p<0.01, when comparing each result to RAkEL).", "labels": [], "entities": [{"text": "Average", "start_pos": 10, "end_pos": 17, "type": "METRIC", "confidence": 0.996338963508606}, {"text": "precision", "start_pos": 19, "end_pos": 28, "type": "METRIC", "confidence": 0.9987892508506775}, {"text": "recall", "start_pos": 30, "end_pos": 36, "type": "METRIC", "confidence": 0.9994010925292969}, {"text": "F-score", "start_pos": 41, "end_pos": 48, "type": "METRIC", "confidence": 0.9994378685951233}, {"text": "T-test", "start_pos": 90, "end_pos": 96, "type": "METRIC", "confidence": 0.9875264763832092}, {"text": "RAkEL", "start_pos": 197, "end_pos": 202, "type": "METRIC", "confidence": 0.7019230127334595}]}, {"text": " Table 4: Accuracy, average rewards (based on lecturers' preferences) and averages of the means of the  student ratings. Accuracy significance (Z-test) with RAkEL at p<0.05 is indicated as * and at p<0.01  as **. Student ratings significance (Mann Whitney U test) with RAkEL at p<0.05 is indicated as *.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9981354475021362}, {"text": "Accuracy significance", "start_pos": 121, "end_pos": 142, "type": "METRIC", "confidence": 0.9828184247016907}, {"text": "Mann Whitney U test", "start_pos": 243, "end_pos": 262, "type": "DATASET", "confidence": 0.8441280275583267}]}]}