{"title": [{"text": "Joint POS Tagging and Transition-based Constituent Parsing in Chinese with Non-local Features", "labels": [], "entities": [{"text": "POS Tagging", "start_pos": 6, "end_pos": 17, "type": "TASK", "confidence": 0.7615920007228851}, {"text": "Constituent Parsing", "start_pos": 39, "end_pos": 58, "type": "TASK", "confidence": 0.6567508578300476}]}], "abstractContent": [{"text": "We propose three improvements to address the drawbacks of state-of-the-art transition-based constituent parsers.", "labels": [], "entities": []}, {"text": "First, to resolve the error propagation problem of the traditional pipeline approach, we incorporate POS tagging into the syntactic parsing process.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 101, "end_pos": 112, "type": "TASK", "confidence": 0.7293777763843536}]}, {"text": "Second, to alleviate the negative influence of size differences among competing action sequences, we align parser states during beam-search decoding.", "labels": [], "entities": []}, {"text": "Third, to enhance the power of parsing models, we enlarge the feature set with non-local features and semi-supervised word cluster features.", "labels": [], "entities": [{"text": "parsing", "start_pos": 31, "end_pos": 38, "type": "TASK", "confidence": 0.9656094908714294}]}, {"text": "Experimental results show that these modifications improve parsing performance significantly.", "labels": [], "entities": [{"text": "parsing", "start_pos": 59, "end_pos": 66, "type": "TASK", "confidence": 0.9857140779495239}]}, {"text": "Evaluated on the Chinese Tree-Bank (CTB), our final performance reaches 86.3% (F1) when trained on CTB 5.1, and 87.1% when trained on CTB 6.0, and these results outperform all state-of-the-art parsers.", "labels": [], "entities": [{"text": "Chinese Tree-Bank (CTB)", "start_pos": 17, "end_pos": 40, "type": "DATASET", "confidence": 0.9736821174621582}, {"text": "F1)", "start_pos": 79, "end_pos": 82, "type": "METRIC", "confidence": 0.9836999177932739}, {"text": "CTB 5.1", "start_pos": 99, "end_pos": 106, "type": "DATASET", "confidence": 0.9467928111553192}]}], "introductionContent": [{"text": "Constituent parsing is one of the most fundamental tasks in Natural Language Processing (NLP).", "labels": [], "entities": [{"text": "Constituent parsing", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.9106175601482391}, {"text": "Natural Language Processing (NLP)", "start_pos": 60, "end_pos": 93, "type": "TASK", "confidence": 0.7139104803403219}]}, {"text": "It seeks to uncover the underlying recursive phrase structure of sentences.", "labels": [], "entities": []}, {"text": "Most of the state-of-theart parsers are based on the PCFG paradigm and chart-based decoding algorithms).", "labels": [], "entities": [{"text": "PCFG paradigm", "start_pos": 53, "end_pos": 66, "type": "DATASET", "confidence": 0.9178934991359711}]}, {"text": "Chart-based parsers perform exhaustive search with dynamic programming, which contributes to their high accuracy, but they also suffer from higher runtime complexity and can only exploit simple local structural information.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 104, "end_pos": 112, "type": "METRIC", "confidence": 0.9991126656532288}]}, {"text": "Transition-based constituent parsing;) is an attractive alternative.", "labels": [], "entities": [{"text": "Transition-based constituent parsing", "start_pos": 0, "end_pos": 36, "type": "TASK", "confidence": 0.6398332615693411}]}, {"text": "It utilizes a series of deterministic shift-reduce decisions to construct syntactic trees.", "labels": [], "entities": []}, {"text": "Therefore, it runs in linear time and can take advantage of arbitrarily complex structural features from already constructed subtrees.", "labels": [], "entities": []}, {"text": "The downside is that they only search a tiny fraction of the whole space and are therefore commonly considered to be less accurate than chartbased parsers.", "labels": [], "entities": []}, {"text": "Recent studies ( show, however, that this approach can also achieve the state-of-the-art performance with improved training procedures and the use of additional source of information as features.", "labels": [], "entities": []}, {"text": "However, there is still room for improvement for these state-of-the-art transition-based constituent parsers.", "labels": [], "entities": []}, {"text": "First, POS tagging is typically performed separately as a preliminary step, and POS tagging errors will propagate to the parsing process.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 7, "end_pos": 18, "type": "TASK", "confidence": 0.827136218547821}, {"text": "POS tagging", "start_pos": 80, "end_pos": 91, "type": "TASK", "confidence": 0.7217907309532166}, {"text": "parsing", "start_pos": 121, "end_pos": 128, "type": "TASK", "confidence": 0.9653879404067993}]}, {"text": "This problem is especially severe for languages where the POS tagging accuracy is relatively low, and this is the case for Chinese where there are fewer contextual clues that can be used to inform the tagging process and some of the tagging decisions are actually influenced by the syntactic structure of the sentence.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 58, "end_pos": 69, "type": "TASK", "confidence": 0.6558419466018677}, {"text": "accuracy", "start_pos": 70, "end_pos": 78, "type": "METRIC", "confidence": 0.8685068488121033}]}, {"text": "This creates a chicken and egg problem that needs to be addressed when designing a parsing model.", "labels": [], "entities": []}, {"text": "Second, due to the existence of unary rules in constituent trees, competing candidate parses often have different number of actions, and this increases the disambiguation difficulty for the parsing model.", "labels": [], "entities": []}, {"text": "Third, transition-based parsers have the freedom to define arbitrarily complex structural features, but this freedom has not fully been taken advantage of and most of the present approaches only use simple structural features.", "labels": [], "entities": []}, {"text": "In this paper, we address these drawbacks to improve the transition-based constituent parsing for Chinese.", "labels": [], "entities": [{"text": "transition-based constituent parsing", "start_pos": 57, "end_pos": 93, "type": "TASK", "confidence": 0.6288153827190399}]}, {"text": "First, we integrate POS tagging into the parsing process and jointly optimize these two processes simultaneously.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 20, "end_pos": 31, "type": "TASK", "confidence": 0.7803858816623688}, {"text": "parsing", "start_pos": 41, "end_pos": 48, "type": "TASK", "confidence": 0.9643719792366028}]}, {"text": "Because non-local syntactic information is now available to POS tag determination, the accuracy of POS tagging improves, and this will in turn improve parsing accuracy.", "labels": [], "entities": [{"text": "POS tag determination", "start_pos": 60, "end_pos": 81, "type": "TASK", "confidence": 0.7706191937128702}, {"text": "accuracy", "start_pos": 87, "end_pos": 95, "type": "METRIC", "confidence": 0.9994233846664429}, {"text": "POS tagging", "start_pos": 99, "end_pos": 110, "type": "TASK", "confidence": 0.7456350326538086}, {"text": "parsing", "start_pos": 151, "end_pos": 158, "type": "TASK", "confidence": 0.972500205039978}, {"text": "accuracy", "start_pos": 159, "end_pos": 167, "type": "METRIC", "confidence": 0.911424994468689}]}, {"text": "Second, we propose a novel state alignment strategy to align candidate parses with different action sizes during beam-search decoding.", "labels": [], "entities": [{"text": "state alignment", "start_pos": 27, "end_pos": 42, "type": "TASK", "confidence": 0.749468982219696}]}, {"text": "With this strategy, parser states and their unary extensions are put into the same beam, therefore the parsing model could decide whether or not to use unary actions within local decision beams.", "labels": [], "entities": []}, {"text": "Third, we take into account two groups of complex structural features that have not been previously used in transition-based parsing: nonlocal features) and semi-supervised word cluster features (.", "labels": [], "entities": [{"text": "transition-based parsing", "start_pos": 108, "end_pos": 132, "type": "TASK", "confidence": 0.599482387304306}]}, {"text": "With the help of the non-local features, our transition-based parsing system outperforms all previous single systems in Chinese.", "labels": [], "entities": []}, {"text": "After integrating semi-supervised word cluster features, the parsing accuracy is further improved to 86.3% when trained on CTB 5.1 and 87.1% when trained on CTB 6.0, and this is the best reported performance for Chinese.", "labels": [], "entities": [{"text": "parsing", "start_pos": 61, "end_pos": 68, "type": "TASK", "confidence": 0.9618306756019592}, {"text": "accuracy", "start_pos": 69, "end_pos": 77, "type": "METRIC", "confidence": 0.9626299738883972}, {"text": "CTB 5.1", "start_pos": 123, "end_pos": 130, "type": "DATASET", "confidence": 0.963648110628128}, {"text": "CTB 6.0", "start_pos": 157, "end_pos": 164, "type": "DATASET", "confidence": 0.948211133480072}]}, {"text": "The remainder of this paper is organized as follows: Section 2 introduces the standard transitionbased constituent parsing approach.", "labels": [], "entities": [{"text": "transitionbased constituent parsing", "start_pos": 87, "end_pos": 122, "type": "TASK", "confidence": 0.6519164641698202}]}, {"text": "Section 3 describes our three improvements to standard transition-based constituent parsing.", "labels": [], "entities": [{"text": "transition-based constituent parsing", "start_pos": 55, "end_pos": 91, "type": "TASK", "confidence": 0.6214977900187174}]}, {"text": "We discuss and analyze the experimental results in Section 4.", "labels": [], "entities": []}, {"text": "Section 5 discusses related work.", "labels": [], "entities": []}, {"text": "Finally, we conclude this paper in Section 6.", "labels": [], "entities": []}], "datasetContent": [{"text": "We conducted experiments on the Penn Chinese Treebank (CTB) version 5.1 (): Articles 001-270 and 400-1151 were used as the training set, Articles 301-325 were used as the development set, and Articles 271-300 were used as the test set.", "labels": [], "entities": [{"text": "Penn Chinese Treebank (CTB) version 5.1", "start_pos": 32, "end_pos": 71, "type": "DATASET", "confidence": 0.9797670394182205}]}, {"text": "Standard corpus preparation steps were performed before our experiments: empty nodes and functional tags were removed, and the unary chains were collapsed to single unary rules as.", "labels": [], "entities": []}, {"text": "To build word clusters, we used the unlabeled Chinese Gigaword (LDC2003T09) and conducted Chinese word segmentation using a CRF-based segmenter.", "labels": [], "entities": [{"text": "Chinese Gigaword (LDC2003T09", "start_pos": 46, "end_pos": 74, "type": "DATASET", "confidence": 0.8672495484352112}, {"text": "Chinese word segmentation", "start_pos": 90, "end_pos": 115, "type": "TASK", "confidence": 0.5993582506974539}]}, {"text": "We used EVALB 2 tool to evaluate parsing performance.", "labels": [], "entities": [{"text": "parsing", "start_pos": 33, "end_pos": 40, "type": "TASK", "confidence": 0.9794852137565613}]}, {"text": "The metrics include labeled precision (LP ), labeled recall (LR), bracketing F 1 and POS tagging accuracy.", "labels": [], "entities": [{"text": "labeled precision (LP )", "start_pos": 20, "end_pos": 43, "type": "METRIC", "confidence": 0.8323079466819763}, {"text": "recall (LR)", "start_pos": 53, "end_pos": 64, "type": "METRIC", "confidence": 0.9601302444934845}, {"text": "bracketing F 1", "start_pos": 66, "end_pos": 80, "type": "METRIC", "confidence": 0.7694060007731119}, {"text": "POS tagging", "start_pos": 85, "end_pos": 96, "type": "TASK", "confidence": 0.6697801947593689}, {"text": "accuracy", "start_pos": 97, "end_pos": 105, "type": "METRIC", "confidence": 0.5410262942314148}]}, {"text": "We set the beam size k to 16, which brings a good balance between efficiency and accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 81, "end_pos": 89, "type": "METRIC", "confidence": 0.9987680315971375}]}, {"text": "We tuned the optimal number of iterations of perceptron training algorithm on the development set.", "labels": [], "entities": []}, {"text": "We built two new systems to verify the effectiveness of our state alignment strategy proposed in: Parsing performance on Chinese development set.", "labels": [], "entities": [{"text": "Parsing", "start_pos": 98, "end_pos": 105, "type": "TASK", "confidence": 0.9011099934577942}, {"text": "Chinese development set", "start_pos": 121, "end_pos": 144, "type": "DATASET", "confidence": 0.8896116415659586}]}, {"text": "The first system Padding extends our JointParsing system by aligning terminal states with the padding strategy proposed in, and the second system StateAlign extends the JointParsing system with our state alignment strategy.", "labels": [], "entities": []}, {"text": "The fifth and sixth rows of give the performances of these two systems.", "labels": [], "entities": []}, {"text": "Compared with the JointParsing system which does not employ any alignment strategy, the Padding system only achieved a slight improvement on parsing F 1 score, but no improvement on POS tagging accuracy.", "labels": [], "entities": [{"text": "parsing", "start_pos": 141, "end_pos": 148, "type": "TASK", "confidence": 0.9447984099388123}, {"text": "F 1 score", "start_pos": 149, "end_pos": 158, "type": "METRIC", "confidence": 0.7871662378311157}, {"text": "POS tagging", "start_pos": 182, "end_pos": 193, "type": "TASK", "confidence": 0.6769296824932098}, {"text": "accuracy", "start_pos": 194, "end_pos": 202, "type": "METRIC", "confidence": 0.9349760413169861}]}, {"text": "In contrast, our StateAlign system achieved an improvement of 0.6% on parsing F 1 score and 0.4% on POS tagging accuracy.", "labels": [], "entities": [{"text": "parsing", "start_pos": 70, "end_pos": 77, "type": "TASK", "confidence": 0.8890979290008545}, {"text": "F 1 score", "start_pos": 78, "end_pos": 87, "type": "METRIC", "confidence": 0.7458829085032145}, {"text": "POS tagging", "start_pos": 100, "end_pos": 111, "type": "TASK", "confidence": 0.6590238511562347}, {"text": "accuracy", "start_pos": 112, "end_pos": 120, "type": "METRIC", "confidence": 0.9008909463882446}]}, {"text": "All these results show us that our state alignment strategy is more helpful for beam-search decoding.", "labels": [], "entities": [{"text": "state alignment", "start_pos": 35, "end_pos": 50, "type": "TASK", "confidence": 0.6798598617315292}, {"text": "beam-search decoding", "start_pos": 80, "end_pos": 100, "type": "TASK", "confidence": 0.8513479232788086}]}, {"text": "In this subsection, we examined the usefulness of the new non-local features and the semisupervised word cluster features described in Subsection 3.3.", "labels": [], "entities": []}, {"text": "We built three new parsing systems based on the StateAlign system: Nonlocal system extends the feature set of StateAlign system with non-local features, Cluster system extends the feature set with semi-supervised word cluster features, and Nonlocal&Cluster system extend the feature set with both groups of features.", "labels": [], "entities": []}, {"text": "Parsing performances of the three systems are shown in the last three rows of.", "labels": [], "entities": []}, {"text": "Compared with the StateAlign system which takes only the baseline features, the non-local features improved parsing F 1 by 0.8%, while the semi-supervised word cluster features result in an improvement of 2.3% in parsing F 1 and an 1.1% improvement on POS tagging accuracy.", "labels": [], "entities": [{"text": "parsing F", "start_pos": 108, "end_pos": 117, "type": "TASK", "confidence": 0.8238852918148041}, {"text": "parsing F", "start_pos": 213, "end_pos": 222, "type": "TASK", "confidence": 0.8295668065547943}, {"text": "POS tagging", "start_pos": 252, "end_pos": 263, "type": "TASK", "confidence": 0.7314425706863403}, {"text": "accuracy", "start_pos": 264, "end_pos": 272, "type": "METRIC", "confidence": 0.8593424558639526}]}, {"text": "When integrating both groups of features, the final parsing F 1 reaches 89.1%.", "labels": [], "entities": [{"text": "F 1", "start_pos": 60, "end_pos": 63, "type": "METRIC", "confidence": 0.8448268175125122}]}, {"text": "Al-  l these results show that both the non-local features and the semi-supervised features are helpful for our transition-based constituent parser.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 3: Parsing performance on Chinese devel- opment set.", "labels": [], "entities": [{"text": "Parsing", "start_pos": 10, "end_pos": 17, "type": "TASK", "confidence": 0.9525450468063354}, {"text": "Chinese devel- opment set", "start_pos": 33, "end_pos": 58, "type": "DATASET", "confidence": 0.8282767415046692}]}, {"text": " Table 4: Parsing performance on Chinese test set.  *  Huang (2009) adapted the parse reranker to CTB5.", "labels": [], "entities": [{"text": "Chinese test set", "start_pos": 33, "end_pos": 49, "type": "DATASET", "confidence": 0.9045735001564026}, {"text": "CTB5", "start_pos": 98, "end_pos": 102, "type": "DATASET", "confidence": 0.9788901805877686}]}, {"text": " Table 6: Parse errors on Chinese test set. The shaded area of each bar indicates average number of that  error type per sentence, and the completely full bar indicates the number in the Worst row.", "labels": [], "entities": [{"text": "Chinese test set", "start_pos": 26, "end_pos": 42, "type": "DATASET", "confidence": 0.931536078453064}]}, {"text": " Table 7: POS tagging error patterns on Chinese test set. For each error pattern, the left hand side tag is  the gold-standard tag, and the right hand side is the wrongly assigned tag.", "labels": [], "entities": [{"text": "POS tagging error patterns", "start_pos": 10, "end_pos": 36, "type": "TASK", "confidence": 0.764745905995369}, {"text": "Chinese test set", "start_pos": 40, "end_pos": 56, "type": "DATASET", "confidence": 0.9691774249076843}]}]}