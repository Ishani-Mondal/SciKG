{"title": [{"text": "Shift-Reduce CCG Parsing with a Dependency Model", "labels": [], "entities": [{"text": "Shift-Reduce CCG Parsing", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.8089383641878763}]}], "abstractContent": [{"text": "This paper presents the first dependency model fora shift-reduce CCG parser.", "labels": [], "entities": []}, {"text": "Modelling dependencies is desirable fora number of reasons, including handling the \"spurious\" ambiguity of CCG; fitting well with the theory of CCG; and optimizing for structures which are evaluated attest time.", "labels": [], "entities": []}, {"text": "We develop a novel training technique using a dependency oracle, in which all derivations are hidden.", "labels": [], "entities": []}, {"text": "A challenge arises from the fact that the oracle needs to keep track of exponentially many gold-standard derivations, which is solved by integrating a packed parse forest with the beam-search decoder.", "labels": [], "entities": []}, {"text": "Standard CCGBank tests show the model achieves up to 1.05 labeled F-score improvements over three existing, competitive CCG parsing models.", "labels": [], "entities": [{"text": "F-score", "start_pos": 66, "end_pos": 73, "type": "METRIC", "confidence": 0.9782308340072632}, {"text": "CCG parsing", "start_pos": 120, "end_pos": 131, "type": "TASK", "confidence": 0.5323928445577621}]}], "introductionContent": [{"text": "Combinatory Categorial Grammar (CCG;) is able to derive typed dependency structures, providing a useful approximation to the underlying predicate-argument relations of \"who did what to whom\".", "labels": [], "entities": [{"text": "Combinatory Categorial Grammar (CCG", "start_pos": 0, "end_pos": 35, "type": "TASK", "confidence": 0.7405182957649231}]}, {"text": "To date, CCG remains the most competitive formalism for recovering \"deep\" dependencies arising from many linguistic phenomena such as raising, control, extraction and coordination (.", "labels": [], "entities": [{"text": "raising, control, extraction and coordination", "start_pos": 134, "end_pos": 179, "type": "TASK", "confidence": 0.7011105035032544}]}, {"text": "To achieve its expressiveness, CCG exhibits so-called \"spurious\" ambiguity, permitting many non-standard surface derivations which ease the recovery of certain dependencies, especially those arising from type-raising and composition.", "labels": [], "entities": []}, {"text": "But this raises the question of what is the most suitable model for CCG: should we model the derivations, the dependencies, or both?", "labels": [], "entities": []}, {"text": "The choice for some existing parsers) is to model derivations directly, restricting the gold-standard to be the normal-form derivations from CCGBank.", "labels": [], "entities": [{"text": "CCGBank", "start_pos": 141, "end_pos": 148, "type": "DATASET", "confidence": 0.9496369957923889}]}, {"text": "Modelling dependencies, as a proxy for the semantic interpretation, fits well with the theory of CCG, in which argues that the derivation is merely a \"trace\" of the underlying syntactic process, and that the structure which is built, and predicated over when applying constraints on grammaticality, is the semantic interpretation.", "labels": [], "entities": []}, {"text": "The early dependency model of , in which model features were defined over only dependency structures, was partly motivated by these theoretical observations.", "labels": [], "entities": []}, {"text": "More generally, dependency models are desirable fora number of reasons.", "labels": [], "entities": []}, {"text": "First, modelling dependencies provides an elegant solution to the spurious ambiguity problem.", "labels": [], "entities": []}, {"text": "Second, obtaining training data for dependencies is likely to be easier than for syntactic derivations, especially for incomplete data (.", "labels": [], "entities": []}, {"text": "show how the dependency model from extends naturally to the partialtraining case, and also how to obtain dependency data cheaply from gold-standard lexical category sequences alone.", "labels": [], "entities": []}, {"text": "And third, it has been argued that dependencies are an ideal representation for parser evaluation, especially for CCG), and so optimizing for dependency recovery makes sense from an evaluation perspective.", "labels": [], "entities": [{"text": "dependency recovery", "start_pos": 142, "end_pos": 161, "type": "TASK", "confidence": 0.7728694677352905}]}, {"text": "In this paper, we fill a gap in the literature by developing the first dependency model fora shiftreduce CCG parser.", "labels": [], "entities": []}, {"text": "Shift-reduce parsing applies naturally to, and the left-to-right, incremental nature of the decoding fits with CCG's cognitive claims.", "labels": [], "entities": [{"text": "Shift-reduce parsing", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.7607410252094269}]}, {"text": "The discriminative model is global and trained with the structured perceptron.", "labels": [], "entities": []}, {"text": "The decoder is based on beam-search with the advantage of linear-time decoding.", "labels": [], "entities": []}, {"text": "A main contribution of the paper is a novel technique for training the parser using a dependency oracle, in which all derivations are hidden.", "labels": [], "entities": []}, {"text": "A challenge arises from the potentially exponential number of derivations leading to a gold-standard dependency structure, which the oracle needs to keep track of.", "labels": [], "entities": []}, {"text": "Our solution is an integration of a packed parse forest, which efficiently stores all the derivations, with the beam-search decoder at training time.", "labels": [], "entities": []}, {"text": "The derivations are not explicitly part of the data, since the forest is built from the gold-standard dependencies.", "labels": [], "entities": []}, {"text": "We also show how perceptron learning with beam-search () can be extended to handle the additional ambiguity, by adapting the \"violationfixing\" perceptron of.", "labels": [], "entities": []}, {"text": "Results on the standard CCGBank tests show that our parser achieves absolute labeled F-score gains of up to 0.5 over the shift-reduce parser of; and up to 1.05 and 0.64 over the normal-form and hybrid models of, respectively.", "labels": [], "entities": [{"text": "F-score", "start_pos": 85, "end_pos": 92, "type": "METRIC", "confidence": 0.6585684418678284}]}], "datasetContent": [{"text": "We implement our shift-reduce parser on top of the core C&C code base and evaluate it against the shift-reduce parser of Zhang and Clark (2011) (henceforth Z&C) and the chartbased normal-form and hybrid models of.", "labels": [], "entities": [{"text": "C&C code base", "start_pos": 56, "end_pos": 69, "type": "DATASET", "confidence": 0.7218439280986786}]}, {"text": "For all experiments, we use CCGBank with the standard split: sections 2-21 for training (39,604 sentences), section 00 for development (1,913 sentences) and section 23 (2,407 sentences) for testing.", "labels": [], "entities": [{"text": "CCGBank", "start_pos": 28, "end_pos": 35, "type": "DATASET", "confidence": 0.9363190531730652}]}, {"text": "The way that the CCG grammar is implemented in C&C has some implications for our parser.", "labels": [], "entities": []}, {"text": "First, unlike Z&C, which uses a context-free cover and hence is able to use all sentences in the training data, we are only able to use 36,036 sentences.", "labels": [], "entities": []}, {"text": "The reason is that the grammar in C&C does not have complete coverage of CCGBank, due to the fact that e.g. not all rules in CCGBank conform to the combinatory rules of CCG.", "labels": [], "entities": [{"text": "CCGBank", "start_pos": 73, "end_pos": 80, "type": "DATASET", "confidence": 0.9041249752044678}]}, {"text": "Second, our parser uses the unification mechanism from C&C to output dependencies directly, and hence does not need a separate postprocessing step to convert derivations into CCG dependencies, as required by Z&C.", "labels": [], "entities": []}, {"text": "The feature templates of our model consist of all of those in Z&C, except the ones which require lexical heads to come from either the left or right child, as such features are incompatible with the head passing mechanism used by C&C.", "labels": [], "entities": []}, {"text": "Each Z&C template is defined over a parse item, and captures various aspects of the stack and queue context.", "labels": [], "entities": []}, {"text": "For example, one template returns the top category on the stack plus its headword, together with the first word and its POS tag on the queue.", "labels": [], "entities": []}, {"text": "Another template returns the second category on the stack, together with the POS tag of its headword.", "labels": [], "entities": []}, {"text": "Every Z&C feature is defined as a pair, consisting of an instantiated context template and a parse action.", "labels": [], "entities": []}, {"text": "In addition, we use all the CCG predicate-argument dependency features from, which contribute to the score of a REDUCE action when dependencies  are realized.", "labels": [], "entities": []}, {"text": "Detailed descriptions of all the templates in our model can be found in the respective papers.", "labels": [], "entities": []}, {"text": "We run 20 training iterations and the resulting model contains 16.5M features with a nonzero weight.", "labels": [], "entities": []}, {"text": "We use 10-fold cross validation for POS tagging and supertagging the training data, and automatically assigned POS tags for all experiments.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 36, "end_pos": 47, "type": "TASK", "confidence": 0.8334584534168243}]}, {"text": "A probability cut-off value of 0.0001 for the \u03b2 parameter in the supertagger is used for both training and testing.", "labels": [], "entities": []}, {"text": "The \u03b2 parameter determines how many lexical categories are assigned to each word; \u03b2 = 0.0001 is a relatively small value which allows in a large number of categories, compared to the default value used in.", "labels": [], "entities": []}, {"text": "For training only, if the gold-standard lexical category is not supplied by the supertagger fora particular word, it is added to the list of categories.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Accuracy comparison on Section 00 (auto POS).", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9981215596199036}, {"text": "Section 00 (auto POS)", "start_pos": 33, "end_pos": 54, "type": "DATASET", "confidence": 0.5659547597169876}]}, {"text": " Table 2: Accuracy comparison on most frequent dependency types, for our parser (o), Z&C (z) and C&C  hybrid model (c). Categories in bold indicate the argument slot in the relation.", "labels": [], "entities": []}, {"text": " Table 3: Accuracy comparison on section 23 (auto POS).", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9967995882034302}]}]}