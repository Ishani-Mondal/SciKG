{"title": [{"text": "Response-based Learning for Grounded Machine Translation", "labels": [], "entities": [{"text": "Grounded Machine Translation", "start_pos": 28, "end_pos": 56, "type": "TASK", "confidence": 0.7484708031018575}]}], "abstractContent": [{"text": "We propose a novel learning approach for statistical machine translation (SMT) that allows to extract supervision signals for structured learning from an extrinsic response to a translation input.", "labels": [], "entities": [{"text": "statistical machine translation (SMT)", "start_pos": 41, "end_pos": 78, "type": "TASK", "confidence": 0.8101883232593536}]}, {"text": "We show how to generate responses by grounding SMT in the task of executing a semantic parse of a translated query against a database.", "labels": [], "entities": [{"text": "SMT", "start_pos": 47, "end_pos": 50, "type": "TASK", "confidence": 0.9700433611869812}]}, {"text": "Experiments on the GEO-QUERY database show an improvement of about 6 points in F1-score for response-based learning over learning from references only on returning the correct answer from a semantic parse of a translated query.", "labels": [], "entities": [{"text": "GEO-QUERY database", "start_pos": 19, "end_pos": 37, "type": "DATASET", "confidence": 0.960470050573349}, {"text": "F1-score", "start_pos": 79, "end_pos": 87, "type": "METRIC", "confidence": 0.9995463490486145}]}, {"text": "In general, our approach alleviates the dependency on human reference translations and solves the reachability problem in structured learning for SMT.", "labels": [], "entities": [{"text": "SMT", "start_pos": 146, "end_pos": 149, "type": "TASK", "confidence": 0.9922767281532288}]}], "introductionContent": [{"text": "In this paper, we propose a novel approach for learning and evaluation in statistical machine translation (SMT) that borrows ideas from response-based learning for grounded semantic parsing.", "labels": [], "entities": [{"text": "statistical machine translation (SMT)", "start_pos": 74, "end_pos": 111, "type": "TASK", "confidence": 0.7773465017477671}, {"text": "semantic parsing", "start_pos": 173, "end_pos": 189, "type": "TASK", "confidence": 0.7246566116809845}]}, {"text": "In this framework, the meaning of a sentence is defined in the context of an extrinsic task.", "labels": [], "entities": []}, {"text": "Successful communication of meaning is measured by a successful interaction in this task, and feedback from this interaction is used for learning.", "labels": [], "entities": []}, {"text": "We suggest that in a similar way the preservation of meaning in machine translation should be defined in the context of an interaction in an extrinsic task.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 64, "end_pos": 83, "type": "TASK", "confidence": 0.696746438741684}]}, {"text": "For example, in the context of a game, a description of a game rule is translated successfully if correct game moves can be performed based only on the translation.", "labels": [], "entities": []}, {"text": "In the context of a question-answering scenario, a question is translated successfully if the correct answer is returned based only on the translation of the query.", "labels": [], "entities": []}, {"text": "We propose a framework of response-based learning that allows to extract supervision signals for structured learning from the response of an extrinsic task to a translation input.", "labels": [], "entities": []}, {"text": "Here, learning proceeds by \"trying out\" translation hypotheses, receiving a response from interacting in the task, and converting this response into a supervision signal for updating model parameters.", "labels": [], "entities": []}, {"text": "In case of positive feedback, the predicted translation can be treated as reference translation fora structured learning update.", "labels": [], "entities": []}, {"text": "In case of negative feedback, a structural update can be performed against translations that have been approved previously by positive task feedback.", "labels": [], "entities": []}, {"text": "This framework has several advantages: \u2022 The supervision signal in response-based learning has a different quality than supervision by human-generated reference translations.", "labels": [], "entities": []}, {"text": "While a human reference translation is generated independently of the SMT task, conversion of predicted translations into references is always done with respect to a specific task.", "labels": [], "entities": [{"text": "SMT task", "start_pos": 70, "end_pos": 78, "type": "TASK", "confidence": 0.9221769273281097}]}, {"text": "In this sense we speak of grounding meaning transfer in an extrinsic task.", "labels": [], "entities": [{"text": "grounding meaning transfer", "start_pos": 26, "end_pos": 52, "type": "TASK", "confidence": 0.6281242469946543}]}, {"text": "\u2022 Response-based learning can repeatedly tryout system predictions by interacting in the extrinsic task.", "labels": [], "entities": []}, {"text": "Instead of and in addition to learning from human reference translations, response-based learning allows to convert multiple system translations into references.", "labels": [], "entities": []}, {"text": "This alleviates the supervision problem in cases where parallel data are scarce.", "labels": [], "entities": []}, {"text": "\u2022 Task-specific response acts upon system translations.", "labels": [], "entities": [{"text": "system translations", "start_pos": 35, "end_pos": 54, "type": "TASK", "confidence": 0.6940921396017075}]}, {"text": "This avoids the problem of unreachability of independently generated reference translations by the SMT system.", "labels": [], "entities": [{"text": "SMT", "start_pos": 99, "end_pos": 102, "type": "TASK", "confidence": 0.9819498658180237}]}, {"text": "The proposed approach of response-based learning opens the doors for various extrinsic tasks in which SMT systems can be trained and evaluated.", "labels": [], "entities": [{"text": "SMT", "start_pos": 102, "end_pos": 105, "type": "TASK", "confidence": 0.9924013614654541}]}, {"text": "In this paper, we present a proof-of-concept experiment that uses feedback from a simulated world environment.", "labels": [], "entities": []}, {"text": "Building on prior work in grounded semantic parsing, we generate translations of queries, and receive feedback by executing semantic parses of translated queries against the database.", "labels": [], "entities": [{"text": "semantic parsing", "start_pos": 35, "end_pos": 51, "type": "TASK", "confidence": 0.7678179144859314}]}, {"text": "Successful response is defined as receiving the same answer from the semantic parses for the translation and the original query.", "labels": [], "entities": []}, {"text": "Our experimental results show an improvement of about 6 points in F1-score for response-based learning over standard structured learning from reference translations.", "labels": [], "entities": [{"text": "F1-score", "start_pos": 66, "end_pos": 74, "type": "METRIC", "confidence": 0.9996035695075989}]}, {"text": "We show in an error analysis that this improvement can be attributed to using structural and lexical variants of reference translations as positive examples in response-based learning.", "labels": [], "entities": []}, {"text": "Furthermore, translations produced by responsebased learning are found to be grammatical.", "labels": [], "entities": []}, {"text": "This is due to the possibility to boost similarity to human reference translations by the additional use of a cost function in our approach.", "labels": [], "entities": [{"text": "similarity", "start_pos": 40, "end_pos": 50, "type": "METRIC", "confidence": 0.9538998007774353}]}], "datasetContent": [{"text": "In our experiments, we use the GEOQUERY database on U.S. geography as provided by Jones on the full 880 GEOQUERY examples in order to reach full parse coverage.", "labels": [], "entities": [{"text": "GEOQUERY database", "start_pos": 31, "end_pos": 48, "type": "DATASET", "confidence": 0.9057833254337311}]}, {"text": "This parser is itself based on SMT, trained on parallel data consisting of English queries and linearized logical forms, and on a language model trained on linearized logical forms.", "labels": [], "entities": [{"text": "SMT", "start_pos": 31, "end_pos": 34, "type": "TASK", "confidence": 0.9459757208824158}]}, {"text": "We used the hierarchical phrase-based variant of the parser.", "labels": [], "entities": []}, {"text": "Note that we do not use GEOQUERY test data in SMT training.", "labels": [], "entities": [{"text": "GEOQUERY test data", "start_pos": 24, "end_pos": 42, "type": "DATASET", "confidence": 0.7585444251696268}, {"text": "SMT", "start_pos": 46, "end_pos": 49, "type": "TASK", "confidence": 0.9946208000183105}]}, {"text": "Parser training includes GEOQUERY test data in order to be less dependent on parse and execution failures in the evaluation: If a translation system, response-based or reference-based, translates the German input into the gold standard English query it should be rewarded by positive task feedback.", "labels": [], "entities": [{"text": "GEOQUERY", "start_pos": 25, "end_pos": 33, "type": "METRIC", "confidence": 0.8031312823295593}]}, {"text": "To doublecheck whether including the 280 test examples in parser training gives an unfair advantage to response-based learning, we also present experimental results using the original parser of that is trained only on the 600 GEO-QUERY training examples.", "labels": [], "entities": []}, {"text": "The bilingual SMT system used in our experiments is the state-of-the-art SCFG decoder CDEC . We built grammars using its implementation of the suffix array extraction method described in.", "labels": [], "entities": [{"text": "SMT", "start_pos": 14, "end_pos": 17, "type": "TASK", "confidence": 0.9687405228614807}, {"text": "SCFG decoder CDEC", "start_pos": 73, "end_pos": 90, "type": "DATASET", "confidence": 0.8351229031880697}, {"text": "suffix array extraction", "start_pos": 143, "end_pos": 166, "type": "TASK", "confidence": 0.6790688037872314}]}, {"text": "For language modeling, we built a modified Kneser-Ney smoothed 5-gram language model using the English side of the training data.", "labels": [], "entities": [{"text": "language modeling", "start_pos": 4, "end_pos": 21, "type": "TASK", "confidence": 0.7868019044399261}]}, {"text": "We trained the SMT system on the English-German parallel web data provided in the COMMON CRAWL) dataset.", "labels": [], "entities": [{"text": "SMT", "start_pos": 15, "end_pos": 18, "type": "TASK", "confidence": 0.9936510920524597}, {"text": "COMMON CRAWL) dataset", "start_pos": 82, "end_pos": 103, "type": "DATASET", "confidence": 0.8274651765823364}]}], "tableCaptions": [{"text": " Table 1: Experimental results using extended parser for returning answers from GEOQUERY (precision,  recall, F1) and n-gram match to original English query (BLEU) on 280 re-translated test examples. Best  results for each column are highlighted in bold face. Superscripts 1234 denote a significant improvement  over the respective method.", "labels": [], "entities": [{"text": "GEOQUERY", "start_pos": 80, "end_pos": 88, "type": "METRIC", "confidence": 0.5514631271362305}, {"text": "precision", "start_pos": 90, "end_pos": 99, "type": "METRIC", "confidence": 0.9526085257530212}, {"text": "recall", "start_pos": 102, "end_pos": 108, "type": "METRIC", "confidence": 0.9446222186088562}, {"text": "F1)", "start_pos": 110, "end_pos": 113, "type": "METRIC", "confidence": 0.9502142071723938}, {"text": "BLEU", "start_pos": 158, "end_pos": 162, "type": "METRIC", "confidence": 0.8720782399177551}]}, {"text": " Table 2: Experimental results using the original parser for returning answers from GEOQUERY (preci- sion, recall, F1) and n-gram match to original English query (BLEU) on 280 re-translated test examples.", "labels": [], "entities": [{"text": "GEOQUERY", "start_pos": 84, "end_pos": 92, "type": "DATASET", "confidence": 0.5081530809402466}, {"text": "recall", "start_pos": 107, "end_pos": 113, "type": "METRIC", "confidence": 0.993188738822937}, {"text": "F1", "start_pos": 115, "end_pos": 117, "type": "METRIC", "confidence": 0.8138980865478516}, {"text": "BLEU", "start_pos": 163, "end_pos": 167, "type": "METRIC", "confidence": 0.9025822281837463}]}]}