{"title": [{"text": "Cross-Lingual Information to the Rescue in Keyword Extraction", "labels": [], "entities": [{"text": "Cross-Lingual Information to the Rescue in Keyword Extraction", "start_pos": 0, "end_pos": 61, "type": "TASK", "confidence": 0.639077115803957}]}], "abstractContent": [{"text": "We introduce a method that extracts keywords in a language with the help of the other.", "labels": [], "entities": []}, {"text": "In our approach, we bridge and fuse conventionally irrelevant word statistics in languages.", "labels": [], "entities": []}, {"text": "The method involves estimating preferences for keywords w.r.t. domain topics and generating cross-lingual bridges for word statistics integration.", "labels": [], "entities": [{"text": "word statistics integration", "start_pos": 118, "end_pos": 145, "type": "TASK", "confidence": 0.770987311999003}]}, {"text": "At run-time, we transform parallel articles into word graphs, build cross-lingual edges, and exploit PageRank with word keyness information for keyword extraction.", "labels": [], "entities": [{"text": "keyword extraction", "start_pos": 144, "end_pos": 162, "type": "TASK", "confidence": 0.7318598181009293}]}, {"text": "We present the system, BiKEA, that applies the method to keyword analysis.", "labels": [], "entities": [{"text": "BiKEA", "start_pos": 23, "end_pos": 28, "type": "DATASET", "confidence": 0.6590901017189026}, {"text": "keyword analysis", "start_pos": 57, "end_pos": 73, "type": "TASK", "confidence": 0.8756886124610901}]}, {"text": "Experiments show that keyword extraction benefits from PageRank, globally learned keyword preferences, and cross-lingual word statistics interaction which respects language diversity.", "labels": [], "entities": [{"text": "keyword extraction", "start_pos": 22, "end_pos": 40, "type": "TASK", "confidence": 0.9291839003562927}]}], "introductionContent": [{"text": "Recently, an increasing number of Web services target extracting keywords in articles for content understanding, event tracking, or opinion mining.", "labels": [], "entities": [{"text": "content understanding", "start_pos": 90, "end_pos": 111, "type": "TASK", "confidence": 0.8102465569972992}, {"text": "event tracking", "start_pos": 113, "end_pos": 127, "type": "TASK", "confidence": 0.7270485907793045}, {"text": "opinion mining", "start_pos": 132, "end_pos": 146, "type": "TASK", "confidence": 0.7739993035793304}]}, {"text": "Existing keyword extraction algorithm (KEA) typically looks at articles monolingually and calculate word significance in certain language.", "labels": [], "entities": [{"text": "Existing keyword extraction", "start_pos": 0, "end_pos": 27, "type": "TASK", "confidence": 0.6239062448342642}]}, {"text": "However, the calculation in another language may tell the story differently since languages differ in grammar, phrase structure, and word usage, thus word statistics on keyword analysis.", "labels": [], "entities": [{"text": "keyword analysis", "start_pos": 169, "end_pos": 185, "type": "TASK", "confidence": 0.7681085169315338}]}, {"text": "Consider the English article in.", "labels": [], "entities": []}, {"text": "Based on the English content alone, monolingual KEA may not derive the best keyword set.", "labels": [], "entities": []}, {"text": "A better set might be obtained by referring to the article and its counterpart in another language (e.g., Chinese).", "labels": [], "entities": []}, {"text": "Different word statistics in articles of different languages may help, due to language divergence such as phrasal structure (i.e., word order) and word usage and repetition (resulting from word translation or word sense) and soon.", "labels": [], "entities": [{"text": "word translation or word sense", "start_pos": 189, "end_pos": 219, "type": "TASK", "confidence": 0.7353366494178772}]}, {"text": "For example, bilingual phrases \"social reintegration\" and \"\u91cd\u8fd4\u793e\u6703\" in have inverse word orders (\"social\" translates into \"\u793e \u6703 \" and \"reintegration\" into \" \u91cd \u8fd4 \"), both \"prosthesis\" and \"artificial limbs\" translate into \"\u7fa9\u80a2\", and \"physical\" can be associated with \"\u7269 \u7406 \" and \" \u8eab \u9ad4 \" in \"physical therapist\" and \"physical rehabilitation\" respectively.", "labels": [], "entities": []}, {"text": "Intuitively, using cross-lingual statistics (implicitly leveraging language divergence) can help look at articles from different perspectives and extract keywords more accurately.", "labels": [], "entities": []}, {"text": "We present a system, BiKEA, that learns to identify keywords in a language with the help of the other.", "labels": [], "entities": []}, {"text": "The cross-language information is expected to reinforce language similarities and value language dissimilarities, and better understand articles in terms of keywords.", "labels": [], "entities": []}, {"text": "An example keyword analysis of an English article is shown in.", "labels": [], "entities": []}, {"text": "BiKEA has aligned the parallel articles at word level and determined the scores of topical keyword preferences for words.", "labels": [], "entities": [{"text": "BiKEA", "start_pos": 0, "end_pos": 5, "type": "DATASET", "confidence": 0.9488163590431213}]}, {"text": "BiKEA learns these topic-related scores during training by analyzing a collection of articles.", "labels": [], "entities": [{"text": "BiKEA", "start_pos": 0, "end_pos": 5, "type": "DATASET", "confidence": 0.8205065727233887}]}, {"text": "We will describe the BiKEA training process in more detail in Section 3.", "labels": [], "entities": [{"text": "BiKEA training process", "start_pos": 21, "end_pos": 43, "type": "TASK", "confidence": 0.5626542568206787}]}, {"text": "At run-time, BiKEA transforms an article in a language (e.g., English) into PageRank word graph where vertices are words in the article and edges between vertices indicate the words' cooccurrences.", "labels": [], "entities": []}, {"text": "To hear another side of the story, BiKEA also constructs graph from its counterpart in another language (e.g., Chinese).", "labels": [], "entities": [{"text": "BiKEA", "start_pos": 35, "end_pos": 40, "type": "DATASET", "confidence": 0.8229179382324219}]}, {"text": "These two independent graphs are then bridged over nodes that are bilingually equivalent or aligned.", "labels": [], "entities": []}, {"text": "The bridging is to take language divergence into account and to allow for language-wise interaction over word statistics.", "labels": [], "entities": []}, {"text": "BiKEA, then in bilingual context, iterates with learned word keyness scores to find keywords.", "labels": [], "entities": [{"text": "BiKEA", "start_pos": 0, "end_pos": 5, "type": "DATASET", "confidence": 0.7204404473304749}]}, {"text": "In our prototype, BiKEA returns keyword candidates of the article for keyword evaluation (see; alternatively, the keywords returned by BiKEA can be used as candidates for social tagging the article or used as input to an article recommendation system.", "labels": [], "entities": []}], "datasetContent": [{"text": "BiKEA was designed to identify words of importance in an article that are likely to cover the keywords of the article.", "labels": [], "entities": [{"text": "BiKEA", "start_pos": 0, "end_pos": 5, "type": "DATASET", "confidence": 0.8087449073791504}]}, {"text": "As such, BiKEA will be trained and evaluated over articles.", "labels": [], "entities": [{"text": "BiKEA", "start_pos": 9, "end_pos": 14, "type": "DATASET", "confidence": 0.7583815455436707}]}, {"text": "Furthermore, since the goal of BiKEA is to determine a good (representative) set of keywords with the help of cross-lingual information, we evaluate BiKEA on bilingual parallel articles.", "labels": [], "entities": []}, {"text": "In this section, we first present the data sets for training BiKEA (Section 4.1).", "labels": [], "entities": [{"text": "BiKEA", "start_pos": 61, "end_pos": 66, "type": "DATASET", "confidence": 0.6353364586830139}]}, {"text": "Then, Section 4.2 reports the experimental results under different system settings.", "labels": [], "entities": []}, {"text": "The evaluation metrics are nDCG.", "labels": [], "entities": []}, {"text": "System performance at (a) N=5 (b) N=7 (c) N=10.", "labels": [], "entities": []}, {"text": "As we can see, monolingual PageRank (i.e., PR) and bilingual PageRank (BiKEA), using global information tfidf, outperform tfidf.", "labels": [], "entities": []}, {"text": "They relatively boost nDCG by 32% and P by 87%.", "labels": [], "entities": [{"text": "P", "start_pos": 38, "end_pos": 39, "type": "METRIC", "confidence": 0.996296226978302}]}, {"text": "The MRR scores also indicate their superiority: their top-two candidates are often keywords vs. the 2 nd place candidates from tfidf.", "labels": [], "entities": [{"text": "MRR", "start_pos": 4, "end_pos": 7, "type": "METRIC", "confidence": 0.8399863243103027}]}, {"text": "Encouragingly, BiKEA+tfidf achieves better performance than the strong monolingual PR+tfidf across N's.", "labels": [], "entities": [{"text": "BiKEA", "start_pos": 15, "end_pos": 20, "type": "METRIC", "confidence": 0.8424797654151917}]}, {"text": "Specifically, it further improves nDCG relatively by 4.6% and MRR relatively by 5.4%.", "labels": [], "entities": [{"text": "nDCG", "start_pos": 34, "end_pos": 38, "type": "METRIC", "confidence": 0.8634952902793884}, {"text": "MRR", "start_pos": 62, "end_pos": 65, "type": "METRIC", "confidence": 0.9845208525657654}]}, {"text": "Overall, the topical keyword preferences, and the inter-language bridging and the bilingual score propagation in PageRank are simple yet effective.", "labels": [], "entities": [{"text": "PageRank", "start_pos": 113, "end_pos": 121, "type": "DATASET", "confidence": 0.9201527237892151}]}, {"text": "And respecting language statistics and properties helps keyword extraction.", "labels": [], "entities": [{"text": "keyword extraction", "start_pos": 56, "end_pos": 74, "type": "TASK", "confidence": 0.8613832890987396}]}], "tableCaptions": [{"text": " Table 1. System performance at  (a) N=5 (b) N=7 (c) N=10.", "labels": [], "entities": []}]}