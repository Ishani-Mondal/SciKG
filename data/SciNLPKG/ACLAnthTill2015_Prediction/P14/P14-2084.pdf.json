{"title": [{"text": "Humans Require Context to Infer Ironic Intent (so Computers Probably do, too)", "labels": [], "entities": [{"text": "Require Context to Infer Ironic Intent", "start_pos": 7, "end_pos": 45, "type": "TASK", "confidence": 0.7184177041053772}]}], "abstractContent": [{"text": "Automatically detecting verbal irony (roughly, sarcasm) is a challenging task because ironists say something other than-and often opposite to-what they actually mean.", "labels": [], "entities": [{"text": "Automatically detecting verbal irony (roughly, sarcasm)", "start_pos": 0, "end_pos": 55, "type": "TASK", "confidence": 0.8283929957283868}]}, {"text": "Discerning ironic intent exclusively from the words and syntax comprising texts (e.g., tweets, forum posts) is therefore not always possible: additional contextual information about the speaker and/or the topic at hand is often necessary.", "labels": [], "entities": [{"text": "Discerning ironic intent exclusively from the words and syntax comprising texts (e.g., tweets, forum posts)", "start_pos": 0, "end_pos": 107, "type": "TASK", "confidence": 0.6378340893670132}]}, {"text": "We introduce anew corpus that provides empirical evidence for this claim.", "labels": [], "entities": []}, {"text": "We show that annota-tors frequently require context to make judgements concerning ironic intent, and that machine learning approaches tend to misclassify those same comments for which annotators required additional context.", "labels": [], "entities": []}], "introductionContent": [], "datasetContent": [{"text": "Here we introduce the first version (\u03b2 1.0) of our irony corpus.", "labels": [], "entities": []}, {"text": "Reddit (http://reddit. com) is a social-news website to which news stories (and other links) are posted, voted on and commented upon.", "labels": [], "entities": [{"text": "Reddit (http://reddit. com) is a social-news website to which news stories (and other links) are posted, voted on and commented upon", "start_pos": 0, "end_pos": 132, "type": "Description", "confidence": 0.7457595350486892}]}, {"text": "The forum component of reddit is extremely active: popular posts often have well into 1000's of user comments.", "labels": [], "entities": []}, {"text": "Reddit comprises 'sub-reddits', which focus on specific topics.", "labels": [], "entities": []}, {"text": "For example, http:// reddit.com/r/politics features articles (and hence comments) centered around political news.", "labels": [], "entities": []}, {"text": "The current version of the corpus is available at: https://github.com/bwallace/ ACL-2014-irony.", "labels": [], "entities": []}, {"text": "Data collection and annotation is ongoing, so we will continue to release new (larger) versions of the corpus in the future.", "labels": [], "entities": [{"text": "Data collection", "start_pos": 0, "end_pos": 15, "type": "TASK", "confidence": 0.6602717339992523}]}, {"text": "The present version comprises 3,020 annotated comments scraped from the six subreddits enumerated in.", "labels": [], "entities": []}, {"text": "These comments in turn comprise a total of 10,401 labeled sentences.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: The six sub-reddits that we have downloaded comments from and the corresponding number of comments for which  we have acquired annotations in this \u03b2 version of the corpus. Note that we acquired labels at the sentence level, whereas the  counts above reflect comments, all of which contain at least one sentence.", "labels": [], "entities": []}]}