{"title": [{"text": "A Step-wise Usage-based Method for Inducing Polysemy-aware Verb Classes", "labels": [], "entities": []}], "abstractContent": [{"text": "We present an unsupervised method for inducing verb classes from verb uses in giga-word corpora.", "labels": [], "entities": []}, {"text": "Our method consists of two clustering steps: verb-specific semantic frames are first induced by clustering verb uses in a corpus and then verb classes are induced by clustering these frames.", "labels": [], "entities": []}, {"text": "By taking this step-wise approach, we cannot only generate verb classes based on a massive amount of verb uses in a scalable manner, but also deal with verb polysemy, which is bypassed by most of the previous studies on verb clustering.", "labels": [], "entities": [{"text": "verb clustering", "start_pos": 220, "end_pos": 235, "type": "TASK", "confidence": 0.735837996006012}]}, {"text": "In our experiments , we acquire semantic frames and verb classes from two giga-word corpora, the larger comprising 20 billion words.", "labels": [], "entities": []}, {"text": "The effectiveness of our approach is verified through quantitative evaluations based on polysemy-aware gold-standard data.", "labels": [], "entities": []}], "introductionContent": [{"text": "A verb plays a primary role in conveying the meaning of a sentence.", "labels": [], "entities": [{"text": "conveying the meaning of a sentence", "start_pos": 31, "end_pos": 66, "type": "TASK", "confidence": 0.8153878351052603}]}, {"text": "Capturing the sense of a verb is essential for natural language processing (NLP), and thus lexical resources for verbs play an important role in NLP.", "labels": [], "entities": [{"text": "Capturing the sense of a verb", "start_pos": 0, "end_pos": 29, "type": "TASK", "confidence": 0.8940835098425547}, {"text": "natural language processing (NLP)", "start_pos": 47, "end_pos": 80, "type": "TASK", "confidence": 0.7933753132820129}]}, {"text": "Verb classes are one such lexical resource.", "labels": [], "entities": []}, {"text": "Manually-crafted verb classes have been developed, such as Levin's classes ( and their extension, VerbNet), in which verbs are organized into classes on the basis of their syntactic and semantic behavior.", "labels": [], "entities": []}, {"text": "Such verb classes have been used in many NLP applications that need to consider semantics in particular, such as word sense disambiguation, semantic parsing () and discourse parsing (.", "labels": [], "entities": [{"text": "word sense disambiguation", "start_pos": 113, "end_pos": 138, "type": "TASK", "confidence": 0.6510379314422607}, {"text": "semantic parsing", "start_pos": 140, "end_pos": 156, "type": "TASK", "confidence": 0.7284121364355087}, {"text": "discourse parsing", "start_pos": 164, "end_pos": 181, "type": "TASK", "confidence": 0.7170523107051849}]}, {"text": "There have also been many attempts to automatically acquire verb classes with the goal of either adding frequency information to an existing resource or of inducing similar verb classes for other languages.", "labels": [], "entities": []}, {"text": "Most of these approaches assume that all target verbs are monosemous.", "labels": [], "entities": []}, {"text": "This monosemous assumption, however, is not realistic because many frequent verbs actually have multiple senses.", "labels": [], "entities": []}, {"text": "Moreover, to the best of our knowledge, none of the following approaches attempt to quantitatively evaluate soft clusterings of verb classes induced by polysemy-aware unsupervised approaches (.", "labels": [], "entities": []}, {"text": "In this paper, we propose an unsupervised method for inducing verb classes that is aware of verb polysemy.", "labels": [], "entities": []}, {"text": "Our method consists of two clustering steps: verb-specific semantic frames are first induced by clustering verb uses in a corpus and then verb classes are induced by clustering these frames.", "labels": [], "entities": []}, {"text": "By taking this step-wise approach, we cannot only induce verb classes with frequency information from a massive amount of verb uses in a scalable manner, but also deal with verb polysemy.", "labels": [], "entities": []}, {"text": "Our novel contributions are summarized as follows: \u2022 induce both semantic frames and verb classes from a massive amount of verb uses by a scalable method, \u2022 explicitly deal with verb polysemy, \u2022 discover effective features for each of the clustering steps, and \u2022 quantitatively evaluate a soft clustering of verbs.: Overview of our two-step approach.", "labels": [], "entities": []}, {"text": "Verb-specific semantic frames are first induced from verb uses (lower part) and then verb classes are induced from the semantic frames (upper part).", "labels": [], "entities": []}, {"text": "The labels of verb classes are manually assigned here for better understanding.", "labels": [], "entities": []}], "datasetContent": [{"text": "We first describe our experimental settings and define evaluation metrics to evaluate induced soft clusterings of verb classes.", "labels": [], "entities": []}, {"text": "Then, we conduct type-level multi-class evaluations, type-level single-class evaluations and token-level multiclass evaluations.", "labels": [], "entities": []}, {"text": "These two levels of evaluations are performed by considering the work of on clustering evaluation.", "labels": [], "entities": []}, {"text": "Finally, we discuss the results of our full experiments.", "labels": [], "entities": []}, {"text": "We use two kinds of large-scale corpora: a web corpus and the English Gigaword corpus.", "labels": [], "entities": [{"text": "English Gigaword corpus", "start_pos": 62, "end_pos": 85, "type": "DATASET", "confidence": 0.7725367148717245}]}, {"text": "To prepare a web corpus, we extracted sentences from crawled web pages that are judged to be written in English based on the encoding information.", "labels": [], "entities": []}, {"text": "Then, we selected sentences that consist of at most 40 words, and removed duplicated sentences.", "labels": [], "entities": []}, {"text": "From this process, we obtained a corpus of one billion sentences, totaling approximately 20 billion words.", "labels": [], "entities": []}, {"text": "We focused on verbs whose frequency in the web corpus was more than 1,000.", "labels": [], "entities": []}, {"text": "There were 19,649 verbs, including phrasal verbs, and separating passive and active constructions.", "labels": [], "entities": []}, {"text": "We extracted 2,032,774,982 predicate-argument structures.", "labels": [], "entities": []}, {"text": "We also used the English Gigaword corpus (LDC2011T07; English Gigaword Fifth Edition).", "labels": [], "entities": [{"text": "English Gigaword corpus (LDC2011T07; English Gigaword Fifth Edition)", "start_pos": 17, "end_pos": 85, "type": "DATASET", "confidence": 0.8553089987147938}]}, {"text": "This corpus consists of approximately 180 million sentences, which totaling four billion words.", "labels": [], "entities": []}, {"text": "There were 7,356 verbs after applying the same frequency threshold as the web corpus.", "labels": [], "entities": []}, {"text": "We extracted 423,778,278 predicate-argument structures from this corpus.", "labels": [], "entities": []}, {"text": "We set the hyper-parameters \u03b1 in (1) and \u03b2 in (3) to 1.0.", "labels": [], "entities": []}, {"text": "The cluster assignments for all the components were initialized randomly.", "labels": [], "entities": []}, {"text": "We took 100 samples for each input frame and selected the cluster assignment that has the highest probability.", "labels": [], "entities": []}, {"text": "To measure the precision and recall of a clustering, modified purity and inverse purity (also called collocation or weighted class accuracy) are commonly used in previous studies on verb clustering (e.g.,).", "labels": [], "entities": [{"text": "precision", "start_pos": 15, "end_pos": 24, "type": "METRIC", "confidence": 0.9990693926811218}, {"text": "recall", "start_pos": 29, "end_pos": 35, "type": "METRIC", "confidence": 0.9972937703132629}, {"text": "inverse purity", "start_pos": 73, "end_pos": 87, "type": "METRIC", "confidence": 0.8768681883811951}, {"text": "weighted class accuracy", "start_pos": 116, "end_pos": 139, "type": "METRIC", "confidence": 0.5340335567792257}, {"text": "verb clustering", "start_pos": 182, "end_pos": 197, "type": "TASK", "confidence": 0.7210751175880432}]}, {"text": "However, since these measures are only applicable to a hard clustering, it is necessary to extend them to be applicable to a soft clustering, because in our task a verb can belong to multiple clusters or classes.", "labels": [], "entities": []}, {"text": "We propose a normalized version of modified purity and inverse purity.", "labels": [], "entities": [{"text": "purity", "start_pos": 44, "end_pos": 50, "type": "METRIC", "confidence": 0.7906490564346313}, {"text": "inverse purity", "start_pos": 55, "end_pos": 69, "type": "METRIC", "confidence": 0.9066699743270874}]}, {"text": "This kind of normalization for soft clusterings was performed for other evaluation metrics as in.", "labels": [], "entities": []}, {"text": "To measure the precision of a clustering, a normalized version of modified purity is defined as follows.", "labels": [], "entities": [{"text": "precision", "start_pos": 15, "end_pos": 24, "type": "METRIC", "confidence": 0.9984613656997681}]}, {"text": "Suppose K is the set of automatically induced clusters and G is the set of gold classes.", "labels": [], "entities": []}, {"text": "Let K i be the verb vector of the i-th cluster and G j be the verb vector of the j-th gold class.", "labels": [], "entities": []}, {"text": "Each component of these vectors is a normalized frequency, which equals a cluster/class attribute probability given a verb.", "labels": [], "entities": []}, {"text": "Where there is no frequency information available for class distribution, such as the gold-standard data described in Section 4.3, we use a uniform distribution across the verb's classes.", "labels": [], "entities": []}, {"text": "The core idea of purity is that each cluster K i is associated with its most prevalent gold class.", "labels": [], "entities": [{"text": "purity", "start_pos": 17, "end_pos": 23, "type": "METRIC", "confidence": 0.9797083735466003}]}, {"text": "In addition, to penalize clusters that consist of only one verb, such singleton clusters in K are considered as errors, as is usual with modified purity.", "labels": [], "entities": []}, {"text": "The normalized modified purity (nmPU) can then be written as follows: where N denotes the total number of verbs, |K i | denotes the number of positive components in K i , and c iv denotes the v-th component of means the total mass of the set of verbs in K i \u2229 G j , given by summing up the values in K i . In case of evaluating a hard clustering, this is equal to |K i \u2229 G j | because all the values of c iv are equal to 1.", "labels": [], "entities": [{"text": "normalized modified purity (nmPU)", "start_pos": 4, "end_pos": 37, "type": "METRIC", "confidence": 0.7225909978151321}]}, {"text": "As usual, the following normalized inverse purity (niPU) is used to measure the recall of a clustering: Finally, we use the harmonic mean (F 1 ) of nmPU and niPU as a single measure of clustering quality.", "labels": [], "entities": [{"text": "inverse purity (niPU)", "start_pos": 35, "end_pos": 56, "type": "METRIC", "confidence": 0.8920061945915222}, {"text": "recall", "start_pos": 80, "end_pos": 86, "type": "METRIC", "confidence": 0.9985284805297852}, {"text": "harmonic mean (F 1 )", "start_pos": 124, "end_pos": 144, "type": "METRIC", "confidence": 0.7927832206090292}]}, {"text": "We first evaluate our induced verb classes on the test set created by (.", "labels": [], "entities": []}, {"text": "As our baselines, we adopt two previously proposed methods.", "labels": [], "entities": []}, {"text": "We first implemented a soft clustering method for verb class induction proposed by.", "labels": [], "entities": [{"text": "verb class induction", "start_pos": 50, "end_pos": 70, "type": "TASK", "confidence": 0.7030672430992126}]}, {"text": "They used the information bottleneck (IB) method for assigning probabilities of classes to each verb.", "labels": [], "entities": []}, {"text": "Note that   \"S\" denotes the use of slot-only features and \"SW\" denotes the use of slot-word pair features.", "labels": [], "entities": []}, {"text": "For example, \"SW-S\" means that slot-word pair features are used for semantic frame induction and slotonly features are used for verb class induction.", "labels": [], "entities": [{"text": "semantic frame induction", "start_pos": 68, "end_pos": 92, "type": "TASK", "confidence": 0.662493904431661}, {"text": "verb class induction", "start_pos": 128, "end_pos": 148, "type": "TASK", "confidence": 0.6545747717221578}]}, {"text": "the evaluations of soft clusterings for their future work.", "labels": [], "entities": []}, {"text": "For input data, we employ VALEX (), which is a publicly-available large-scale subcategorization lexicon.", "labels": [], "entities": [{"text": "VALEX", "start_pos": 26, "end_pos": 31, "type": "METRIC", "confidence": 0.9906050562858582}]}, {"text": "5 By following the method of  available on the website.", "labels": [], "entities": []}, {"text": "This frame data was induced from the BNC and consists of 1,200 frames and 400 semantic roles.", "labels": [], "entities": [{"text": "BNC", "start_pos": 37, "end_pos": 40, "type": "DATASET", "confidence": 0.9260320067405701}]}, {"text": "Again, we set a threshold for frame attribute probabilities.", "labels": [], "entities": []}, {"text": "We report results using our methods with four feature combinations (slot-only (S) and slot-word pair (SW) features each used for both the framegeneration and verb-class clustering steps) for both the Gigaword and web corpora.", "labels": [], "entities": []}, {"text": "lists evaluation results for the baseline methods and our methods.", "labels": [], "entities": []}, {"text": "The results of the IB baseline and our methods are obtained by averaging five runs.", "labels": [], "entities": [{"text": "IB baseline", "start_pos": 19, "end_pos": 30, "type": "DATASET", "confidence": 0.7339569330215454}]}, {"text": "We can see that \"web/SW-S\" achieved the best performance and obtained a higher F 1 than the baselines by more than nine points.", "labels": [], "entities": [{"text": "F 1", "start_pos": 79, "end_pos": 82, "type": "METRIC", "confidence": 0.9966221451759338}]}, {"text": "\"Web/SW-S\" uses the combination of slot-word pair features for clustering verb-specific frames and slotonly features for clustering across verbs.", "labels": [], "entities": []}, {"text": "Interestingly, this result indicates that slot distributions are more effective than lexical information in slotword pairs for inducing verb classes similar to the gold standard.", "labels": [], "entities": []}, {"text": "This result is consistent with expectations, given a gold standard based on Levin's verb classes, which are organized according to the syntactic behavior of verbs.", "labels": [], "entities": []}, {"text": "The use of slot-word pairs for verb class induction generally merged too many frames into each class, apparently due to accidental word overlaps across verbs.", "labels": [], "entities": [{"text": "verb class induction", "start_pos": 31, "end_pos": 51, "type": "TASK", "confidence": 0.6405106087525686}]}, {"text": "The verb classes induced from the web corpus achieved a higher F 1 than those from the Gigaword corpus.", "labels": [], "entities": [{"text": "F 1", "start_pos": 63, "end_pos": 66, "type": "METRIC", "confidence": 0.997037798166275}, {"text": "Gigaword corpus", "start_pos": 87, "end_pos": 102, "type": "DATASET", "confidence": 0.8836565017700195}]}, {"text": "This can be attributed to the larger size of the web corpus.", "labels": [], "entities": []}, {"text": "The employment of this kind of huge corpus is enabled by our scalable method.", "labels": [], "entities": []}, {"text": "http://nlp.fi.muni.cz/projekty/lda-frames/ Although we do not think that the classes with very small attribute probabilities are meaningful, the F1 scores for lower thresholds than 0.01 converged to about 66 in the case of LDA-frames.", "labels": [], "entities": [{"text": "F1", "start_pos": 145, "end_pos": 147, "type": "METRIC", "confidence": 0.9990654587745667}]}, {"text": "Since we focus on the handling of verb polysemy, predominant class induction for each verb is not our main objective.", "labels": [], "entities": [{"text": "predominant class induction", "start_pos": 49, "end_pos": 76, "type": "TASK", "confidence": 0.6987167199452718}]}, {"text": "However, we wish to compare our method with previous work on the induction of a predominant (monosemous) class for each verb.", "labels": [], "entities": []}, {"text": "To output a single class for each verb by using our proposed method, we skip the induction of verb-specific semantic frames and instead create a single frame for each verb by merging all predicate-argument structures of the verb.", "labels": [], "entities": []}, {"text": "Then, we apply clustering to these frames across verbs.", "labels": [], "entities": []}, {"text": "For clustering features, we again compare two representations: slot-only features (S) and slot-word pair features (SW).", "labels": [], "entities": []}, {"text": "We evaluate the single-class output for each verb based on the predominant gold-standard classes, which are defined for each verb in the test set of.", "labels": [], "entities": []}, {"text": "This data contains 110 verbs and 33 classes.", "labels": [], "entities": []}, {"text": "We evaluate these single-class outputs in the same manner as, using the gold standard with multiple classes, which we also use for our multi-class evaluations.", "labels": [], "entities": []}, {"text": "As we did with the multi-class evaluations, we adopt modified purity (mPU), inverse purity (iPU) and their harmonic mean (F 1 ) as the metrics for the evaluation with predominant classes.", "labels": [], "entities": [{"text": "inverse purity (iPU)", "start_pos": 76, "end_pos": 96, "type": "METRIC", "confidence": 0.9430518865585327}, {"text": "harmonic mean (F 1 )", "start_pos": 107, "end_pos": 127, "type": "METRIC", "confidence": 0.7466365148623785}]}, {"text": "It is not necessary to normalize these metrics when we treat verbs as monosemous, and evaluate against the predominant sense.", "labels": [], "entities": []}, {"text": "When we evaluate against the multiple classes in the gold standard, we do normalize the inverse purity.", "labels": [], "entities": [{"text": "gold standard", "start_pos": 53, "end_pos": 66, "type": "DATASET", "confidence": 0.8704153299331665}, {"text": "inverse purity", "start_pos": 88, "end_pos": 102, "type": "METRIC", "confidence": 0.8972205817699432}]}, {"text": "For baselines, we once more adopt the Nearest Neighbor (NN) and Information Bottleneck (IB) methods proposed by, and LDA-frames proposed by.", "labels": [], "entities": []}, {"text": "The clusterings with the NN and IB methods are obtained by using the VALEX subcategorization lexicon.", "labels": [], "entities": [{"text": "VALEX subcategorization lexicon", "start_pos": 69, "end_pos": 100, "type": "DATASET", "confidence": 0.7384297450383505}]}, {"text": "To harden the clusterings of the IB method and the LDA-frames, the class with the highest probability is selected for each verb.", "labels": [], "entities": []}, {"text": "This hardening process is exactly the same as.", "labels": [], "entities": [{"text": "hardening", "start_pos": 5, "end_pos": 14, "type": "TASK", "confidence": 0.9428883790969849}]}, {"text": "Note that our results of the NN and IB methods are different from those reported in their paper since the data source is different.", "labels": [], "entities": [{"text": "IB", "start_pos": 36, "end_pos": 38, "type": "METRIC", "confidence": 0.6529918313026428}]}, {"text": "8 lists accuracies of baseline methods and our methods.", "labels": [], "entities": []}, {"text": "Our proposed method using the web corpus achieved comparable performance with the baseline methods on the predominant class evaluation and outperformed them on the multiple class evaluation.", "labels": [], "entities": []}, {"text": "More sophisticated methods for predominant class induction, such as the method of using selectional preferences, could produce better single-class outputs, but have difficulty in producing polysemy-aware verb classes.", "labels": [], "entities": [{"text": "predominant class induction", "start_pos": 31, "end_pos": 58, "type": "TASK", "confidence": 0.6967289646466573}]}, {"text": "From the result, we can see that the induced verb classes based on slot-only features did not achieve a higher F 1 than those based on slot-word pair features in many cases.", "labels": [], "entities": [{"text": "F 1", "start_pos": 111, "end_pos": 114, "type": "METRIC", "confidence": 0.9962520003318787}]}, {"text": "This result is different from that of multi-class evaluations in Section 4.3.", "labels": [], "entities": []}, {"text": "We speculate that slot distributions are not so different among verbs when all uses of a verb are merged into one frame, and thus their discrimination power is lower than that in the intermediate construction of semantic frames.", "labels": [], "entities": []}, {"text": "We conduct token-level multi-class evaluations using 119 verbs, which appear 100 or more times in sections 02-21 of the SemLink WSJ corpus.", "labels": [], "entities": [{"text": "SemLink WSJ corpus", "start_pos": 120, "end_pos": 138, "type": "DATASET", "confidence": 0.7873668074607849}]}, {"text": "These 119 verbs cover 102 VerbNet classes, and 48 of them are polysemous in the sense of being in more than one VerbNet class.", "labels": [], "entities": []}, {"text": "Each instance of these 119 verbs in this corpus belongs to one of 102 VerbNet classes.", "labels": [], "entities": []}, {"text": "We first add these instances to the instances from a raw corpus and apply the twostep clustering to these merged instances.", "labels": [], "entities": []}, {"text": "Then, we compare the induced verb classes of the SemLink instances with their gold-standard VerbNet classes.", "labels": [], "entities": []}, {"text": "We report the values of modified purity (mPU), inverse purity (iPU) and their harmonic mean   For clustering features, we compare two feature combinations: \"S-S\" and \"SW-S,\" which achieved high performance in the type-level multiclass evaluations (Section 4.3).", "labels": [], "entities": [{"text": "inverse purity (iPU)", "start_pos": 47, "end_pos": 67, "type": "METRIC", "confidence": 0.9281942963600158}]}, {"text": "The results of these methods are obtained by averaging five runs.", "labels": [], "entities": []}, {"text": "For a baseline, we use verb-specific semantic frames without clustering across verbs (\"S-NIL\" and \"SW-NIL\"), where these frames are considered to be verb classes but not shared across verbs.", "labels": [], "entities": []}, {"text": "lists accuracies of these methods for the two corpora.", "labels": [], "entities": [{"text": "accuracies", "start_pos": 6, "end_pos": 16, "type": "METRIC", "confidence": 0.9614322781562805}]}, {"text": "We can see that \"SW-S\" achieved a higher F 1 than \"S-S\" and the baselines without verb class induction (\"S-NIL\" and \"SW-NIL\").", "labels": [], "entities": [{"text": "F 1", "start_pos": 41, "end_pos": 44, "type": "METRIC", "confidence": 0.9967158138751984}]}, {"text": "induced semantic frames across verbs using the monosemous assumption and reported an F 1 of 44.7% (77.9% PU and 31.4% iPU) for the assignment of FrameNet frames to the FrameNet corpus.", "labels": [], "entities": [{"text": "F 1", "start_pos": 85, "end_pos": 88, "type": "METRIC", "confidence": 0.9915109574794769}, {"text": "FrameNet corpus", "start_pos": 168, "end_pos": 183, "type": "DATASET", "confidence": 0.9286084175109863}]}, {"text": "We also conducted the above evaluation against FrameNet frames for 75 verbs.", "labels": [], "entities": [{"text": "FrameNet frames", "start_pos": 47, "end_pos": 62, "type": "DATASET", "confidence": 0.8680713772773743}]}, {"text": "We achieved an F 1 of 62.79% (66.97% mPU and 59.09% iPU) for \"web/SW-S,\" and an F 1 of 60.06% (65.58% mPU and 55.39% iPU) for \"Gigaword/SW-S.\"", "labels": [], "entities": [{"text": "F 1", "start_pos": 15, "end_pos": 18, "type": "METRIC", "confidence": 0.9955729246139526}, {"text": "F 1", "start_pos": 80, "end_pos": 83, "type": "METRIC", "confidence": 0.9951023161411285}]}, {"text": "It is difficult to directly compare these results with, but our induced verb classes seem to have higher F 1 accuracy.", "labels": [], "entities": [{"text": "F 1 accuracy", "start_pos": 105, "end_pos": 117, "type": "METRIC", "confidence": 0.8343791365623474}]}, {"text": "We finally induce verb classes from the semantic frames of 1,667 verbs, which appear at least once in sections 02-21 of the WSJ corpus.", "labels": [], "entities": [{"text": "WSJ corpus", "start_pos": 124, "end_pos": 134, "type": "DATASET", "confidence": 0.9755643010139465}]}, {"text": "Based on the best results in the above evaluations, we induced semantic frames using slot-word pair features, and then induced verb classes using slotonly features.", "labels": [], "entities": []}, {"text": "We ended with 38,481 semantic frames and 699 verb classes from the Gigaword: Examples of induced verb classes.", "labels": [], "entities": []}, {"text": "Underlined semantic frames are shown in corpus, and 61,903 semantic frames and 840 verb classes from the web corpus.", "labels": [], "entities": []}, {"text": "It took two days to induce verb classes from the Gigaword corpus and three days from the web corpus.", "labels": [], "entities": [{"text": "Gigaword corpus", "start_pos": 49, "end_pos": 64, "type": "DATASET", "confidence": 0.9014294445514679}]}, {"text": "Examples of verb classes and semantic frames induced from the web corpus are shown in and.", "labels": [], "entities": []}, {"text": "While there are many classes with consistent meanings, such as \"Class 4\" and \"Class 16,\" some classes have mixed meanings.", "labels": [], "entities": []}, {"text": "For instance, \"Class 2\" consists of the semantic frames \"need:2\" and \"say:2.\"", "labels": [], "entities": []}, {"text": "These frames were merged due to the high syntactic similarity of constituting slot distributions, which are comprised of a subject and a sentential complement.", "labels": [], "entities": []}, {"text": "To improve the quality of verb classes, it is necessary to develop a clustering model that can consider syntactic and lexical similarity in a balanced way.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: An excerpt of the gold-standard verb  classes for several verbs from Korhonen et al.  (2003). The classes starting with '0' were de- rived from the LCS database, those starting with  'A' were defined by Korhonen et al., and the other  classes were from Levin's classes. A bolded class  is the predominant class for each verb.", "labels": [], "entities": [{"text": "LCS database", "start_pos": 158, "end_pos": 170, "type": "DATASET", "confidence": 0.9623953104019165}]}, {"text": " Table 2: Type-level multi-class evaluations. K rep- resents the (average) number of induced classes.", "labels": [], "entities": []}, {"text": " Table 3: Type-level single-class evaluations against predominant/multiple classes. K represents the (av- erage) number of induced classes.", "labels": [], "entities": []}]}