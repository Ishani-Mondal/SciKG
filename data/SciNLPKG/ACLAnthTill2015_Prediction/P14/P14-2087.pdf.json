{"title": [{"text": "Applying a Naive Bayes Similarity Measure to Word Sense Disambiguation", "labels": [], "entities": [{"text": "Applying", "start_pos": 0, "end_pos": 8, "type": "METRIC", "confidence": 0.8749602437019348}, {"text": "Naive Bayes Similarity", "start_pos": 11, "end_pos": 33, "type": "TASK", "confidence": 0.8556368549664816}, {"text": "Word Sense Disambiguation", "start_pos": 45, "end_pos": 70, "type": "TASK", "confidence": 0.6156563957532247}]}], "abstractContent": [{"text": "We replace the overlap mechanism of the Lesk algorithm with a simple, general-purpose Naive Bayes model that measures many-to-many association between two sets of random variables.", "labels": [], "entities": []}, {"text": "Even with simple probability estimates such as maximum likelihood, the model gains significant improvement over the Lesk algorithm on word sense disambiguation tasks.", "labels": [], "entities": [{"text": "word sense disambiguation tasks", "start_pos": 134, "end_pos": 165, "type": "TASK", "confidence": 0.7804771214723587}]}, {"text": "With additional lexical knowledge from Word-Net, performance is further improved to surpass the state-of-the-art results.", "labels": [], "entities": [{"text": "Word-Net", "start_pos": 39, "end_pos": 47, "type": "DATASET", "confidence": 0.9344561100006104}]}], "introductionContent": [{"text": "To disambiguate a homonymous word in a given context, proposed a method that measured the degree of overlap between the glosses of the target and context words.", "labels": [], "entities": []}, {"text": "Known as the Lesk algorithm, this simple and intuitive method has since been extensively cited and extended in the word sense disambiguation (WSD) community.", "labels": [], "entities": [{"text": "word sense disambiguation (WSD)", "start_pos": 115, "end_pos": 146, "type": "TASK", "confidence": 0.7716973026593527}]}, {"text": "Nonetheless, its performance in several WSD benchmarks is less than satisfactory).", "labels": [], "entities": [{"text": "WSD benchmarks", "start_pos": 40, "end_pos": 54, "type": "DATASET", "confidence": 0.8400859236717224}]}, {"text": "Among the popular explanations is a key limitation of the algorithm, that \"Lesk's approach is very sensitive to the exact wording of definitions, so the absence of a certain word can radically change the results.\".", "labels": [], "entities": []}, {"text": "Compounding this problem is the fact that many Lesk variants limited the concept of overlap to the literal interpretation of string matching (with their own variants such as length-sensitive matching (), etc.), and it was not until recently that overlap started to take on other forms such as tree-matching ( and vector space models).", "labels": [], "entities": []}, {"text": "To address this limitation, a Naive Bayes model (NBM) is proposed in this study as a novel, probabilistic treatment of overlap in gloss-based WSD.", "labels": [], "entities": [{"text": "WSD", "start_pos": 142, "end_pos": 145, "type": "TASK", "confidence": 0.8879385590553284}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 2: Lexical knowledge sources and WSD performance (F-measure) on the Senseval-2 (fine-and  coarse-grained) and the SemEval-2007 dataset.", "labels": [], "entities": [{"text": "WSD", "start_pos": 40, "end_pos": 43, "type": "TASK", "confidence": 0.8084964752197266}, {"text": "F-measure", "start_pos": 57, "end_pos": 66, "type": "METRIC", "confidence": 0.9807687401771545}, {"text": "SemEval-2007 dataset", "start_pos": 121, "end_pos": 141, "type": "DATASET", "confidence": 0.8890587091445923}]}]}