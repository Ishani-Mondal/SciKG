{"title": [{"text": "Recurrent Neural Networks for Word Alignment Model", "labels": [], "entities": [{"text": "Recurrent Neural Networks", "start_pos": 0, "end_pos": 25, "type": "TASK", "confidence": 0.7822877963383993}, {"text": "Word Alignment", "start_pos": 30, "end_pos": 44, "type": "TASK", "confidence": 0.7395110577344894}]}], "abstractContent": [{"text": "This study proposes a word alignment model based on a recurrent neural network (RNN), in which an unlimited alignment history is represented by recurrently connected hidden layers.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 22, "end_pos": 36, "type": "TASK", "confidence": 0.7976568341255188}]}, {"text": "We perform unsupervised learning using noise-contrastive estimation (Gutmann and Hyv\u00e4rinen, 2010; Mnih and Teh, 2012), which utilizes artificially generated negative samples.", "labels": [], "entities": []}, {"text": "Our alignment model is directional, similar to the generative IBM models (Brown et al., 1993).", "labels": [], "entities": [{"text": "generative IBM", "start_pos": 51, "end_pos": 65, "type": "TASK", "confidence": 0.83016037940979}]}, {"text": "To overcome this limitation, we encourage agreement between the two directional models by introducing a penalty function that ensures word embedding consistency across two directional models during training.", "labels": [], "entities": []}, {"text": "The RNN-based model outperforms the feed-forward neural network-based model (Yang et al., 2013) as well as the IBM Model 4 under Japanese-English and French-English word alignment tasks, and achieves comparable translation performance to those baselines for Japanese-English and Chinese-English translation tasks.", "labels": [], "entities": [{"text": "Japanese-English and French-English word alignment tasks", "start_pos": 129, "end_pos": 185, "type": "TASK", "confidence": 0.6229156206051508}]}], "introductionContent": [{"text": "Automatic word alignment is an important task for statistical machine translation.", "labels": [], "entities": [{"text": "Automatic word alignment", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.6152359743913015}, {"text": "statistical machine translation", "start_pos": 50, "end_pos": 81, "type": "TASK", "confidence": 0.7907187342643738}]}, {"text": "The most classical approaches are the probabilistic IBM models 1-5 () and the HMM model (.", "labels": [], "entities": []}, {"text": "Various studies have extended those models.", "labels": [], "entities": []}, {"text": "adapted the ContextDependent Deep Neural Network for HMM (CD-DNN-HMM) (), a type of feedforward neural network (FFNN)-based model, to the HMM alignment model and achieved state-ofthe-art performance.", "labels": [], "entities": [{"text": "HMM alignment", "start_pos": 138, "end_pos": 151, "type": "TASK", "confidence": 0.7980178892612457}]}, {"text": "However, the FFNN-based model assumes a first-order Markov dependence for alignments.", "labels": [], "entities": []}, {"text": "Recurrent neural network (RNN)-based models have recently demonstrated state-of-the-art performance that outperformed FFNN-based models for various tasks).", "labels": [], "entities": []}, {"text": "An RNN has a hidden layer with recurrent connections that propagates its own previous signals.", "labels": [], "entities": []}, {"text": "Through the recurrent architecture, RNN-based models have the inherent property of modeling long-span dependencies, e.g., long contexts, in input data.", "labels": [], "entities": []}, {"text": "We assume that this property would fit with a word alignment task, and we propose an RNN-based word alignment model.", "labels": [], "entities": [{"text": "word alignment task", "start_pos": 46, "end_pos": 65, "type": "TASK", "confidence": 0.828217069307963}, {"text": "RNN-based word alignment", "start_pos": 85, "end_pos": 109, "type": "TASK", "confidence": 0.6548222601413727}]}, {"text": "Our model can maintain and arbitrarily integrate an alignment history, e.g., bilingual context, which is longer than the FFNN-based model.", "labels": [], "entities": []}, {"text": "The NN-based alignment models are supervised models.", "labels": [], "entities": []}, {"text": "Unfortunately, it is usually difficult to prepare word-by-word aligned bilingual data.", "labels": [], "entities": []}, {"text": "trained their model from word alignments produced by traditional unsupervised probabilistic models.", "labels": [], "entities": [{"text": "word alignments", "start_pos": 25, "end_pos": 40, "type": "TASK", "confidence": 0.7248396277427673}]}, {"text": "However, with this approach, errors induced by probabilistic models are learned as correct alignments; thus, generalization capabilities are limited.", "labels": [], "entities": []}, {"text": "To solve this problem, we apply noise-contrastive estimation (NCE) () for unsupervised training of our RNN-based model without gold standard alignments or pseudo-oracle alignments.", "labels": [], "entities": [{"text": "noise-contrastive estimation (NCE)", "start_pos": 32, "end_pos": 66, "type": "METRIC", "confidence": 0.8132221341133118}]}, {"text": "NCE artificially generates bilingual sentences through samplings as pseudo-negative samples, and then trains the model such that the scores of the original bilingual sentences are higher than those of the sampled bilingual sentences.", "labels": [], "entities": [{"text": "NCE", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.9034550189971924}]}, {"text": "Our RNN-based alignment model has a direc-tion, such as other alignment models, i.e., from f (source language) toe (target language) and from e to f . It has been proven that the limitation maybe overcome by encouraging two directional models to agree by training them concurrently).", "labels": [], "entities": []}, {"text": "The motivation for this stems from the fact that model and generalization errors by the two models differ, and the models must complement each other.", "labels": [], "entities": []}, {"text": "Based on this motivation, our directional models are also simultaneously trained.", "labels": [], "entities": []}, {"text": "Specifically, our training encourages word embeddings to be consistent across alignment directions by introducing a penalty term that expresses the difference between embedding of words into an objective function.", "labels": [], "entities": []}, {"text": "This constraint prevents each model from overfitting to a particular direction and leads to global optimization across alignment directions.", "labels": [], "entities": []}, {"text": "This paper presents evaluations of JapaneseEnglish and French-English word alignment tasks and Japanese-to-English and Chinese-to-English translation tasks.", "labels": [], "entities": [{"text": "JapaneseEnglish and French-English word alignment tasks", "start_pos": 35, "end_pos": 90, "type": "TASK", "confidence": 0.5627889980872472}, {"text": "Japanese-to-English and Chinese-to-English translation tasks", "start_pos": 95, "end_pos": 155, "type": "TASK", "confidence": 0.6815235435962677}]}, {"text": "The results illustrate that our RNN-based model outperforms the FFNN-based model (up to +0.0792 F1-measure) and the IBM Model 4 (up to +0.0703 F1-measure) for the word alignment tasks.", "labels": [], "entities": [{"text": "F1-measure", "start_pos": 96, "end_pos": 106, "type": "METRIC", "confidence": 0.9959253072738647}, {"text": "F1-measure", "start_pos": 143, "end_pos": 153, "type": "METRIC", "confidence": 0.9932333827018738}, {"text": "word alignment tasks", "start_pos": 163, "end_pos": 183, "type": "TASK", "confidence": 0.854147732257843}]}, {"text": "For the translation tasks, our model achieves up to 0.74% gain in BLEU as compared to the FFNN-based model, which matches the translation qualities of the IBM Model 4.", "labels": [], "entities": [{"text": "translation tasks", "start_pos": 8, "end_pos": 25, "type": "TASK", "confidence": 0.9097219407558441}, {"text": "BLEU", "start_pos": 66, "end_pos": 70, "type": "METRIC", "confidence": 0.9992771744728088}]}], "datasetContent": [{"text": "We evaluated the alignment performance of the proposed models with two tasks: JapaneseEnglish word alignment with the Basic Travel Expression Corpus (BT EC) () and French-English word alignment with the Hansard dataset (Hansards) from the 2003 NAACL shared task.", "labels": [], "entities": [{"text": "JapaneseEnglish word alignment", "start_pos": 78, "end_pos": 108, "type": "TASK", "confidence": 0.6307181616624197}, {"text": "Basic Travel Expression Corpus (BT EC)", "start_pos": 118, "end_pos": 156, "type": "DATASET", "confidence": 0.7441912442445755}, {"text": "Hansard dataset (Hansards) from the 2003 NAACL shared task", "start_pos": 203, "end_pos": 261, "type": "DATASET", "confidence": 0.9181297638199546}]}, {"text": "In addition, we evaluated the end-to-end translation performance of three tasks: a Chineseto-English translation task with the FBIS corpus (F BIS), the IWSLT 2007 Japanese-to-English translation task (IW SLT ), and the NTCIR-9 Japanese-to-English patent translation task (N T CIR) (Goto et al., 2011) . shows the sizes of our experimental datasets.", "labels": [], "entities": [{"text": "Chineseto-English translation task", "start_pos": 83, "end_pos": 117, "type": "TASK", "confidence": 0.7086805105209351}, {"text": "FBIS corpus (F BIS)", "start_pos": 127, "end_pos": 146, "type": "DATASET", "confidence": 0.7525871098041534}, {"text": "IWSLT 2007 Japanese-to-English translation task (IW SLT )", "start_pos": 152, "end_pos": 209, "type": "TASK", "confidence": 0.7861551841100057}, {"text": "NTCIR-9 Japanese-to-English patent translation task (N T CIR", "start_pos": 219, "end_pos": 279, "type": "TASK", "confidence": 0.7808632320827908}]}, {"text": "Note that the development data was not used in the alignment tasks, i.e., BT EC and Hansards, because the hyperparameters of the alignment models were set by preliminary small-scale experiments.", "labels": [], "entities": [{"text": "alignment tasks", "start_pos": 51, "end_pos": 66, "type": "TASK", "confidence": 0.8943642675876617}, {"text": "BT EC", "start_pos": 74, "end_pos": 79, "type": "DATASET", "confidence": 0.9334408640861511}, {"text": "Hansards", "start_pos": 84, "end_pos": 92, "type": "DATASET", "confidence": 0.9147758483886719}]}, {"text": "The BT EC data is the first 9,960 sentence pairs in the training data for IW SLT , which were annotated with word alignment (.", "labels": [], "entities": [{"text": "BT EC data", "start_pos": 4, "end_pos": 14, "type": "DATASET", "confidence": 0.954525351524353}, {"text": "IW SLT", "start_pos": 74, "end_pos": 80, "type": "TASK", "confidence": 0.6773450970649719}, {"text": "word alignment", "start_pos": 109, "end_pos": 123, "type": "TASK", "confidence": 0.6737613379955292}]}, {"text": "We split these pairs into the first 9,000 for training data and the remaining 960 as test data.", "labels": [], "entities": []}, {"text": "All the data in BT EC is word-aligned, and the training data in Hansards is unlabeled data.", "labels": [], "entities": [{"text": "BT EC", "start_pos": 16, "end_pos": 21, "type": "DATASET", "confidence": 0.9772314727306366}, {"text": "Hansards", "start_pos": 64, "end_pos": 72, "type": "DATASET", "confidence": 0.8796013593673706}]}, {"text": "In F BIS, we used the NIST02 evaluation data as the development data, and the NIST03 and 04 evaluation data as test data (N IST 03 and N IST 04).", "labels": [], "entities": [{"text": "F BIS", "start_pos": 3, "end_pos": 8, "type": "DATASET", "confidence": 0.6421632170677185}, {"text": "NIST02 evaluation data", "start_pos": 22, "end_pos": 44, "type": "DATASET", "confidence": 0.9208390315373739}, {"text": "NIST03 and 04 evaluation data", "start_pos": 78, "end_pos": 107, "type": "DATASET", "confidence": 0.8576457262039184}, {"text": "N IST 03 and N IST 04", "start_pos": 122, "end_pos": 143, "type": "DATASET", "confidence": 0.7758403037275586}]}], "tableCaptions": [{"text": " Table 1: Size of experimental datasets", "labels": [], "entities": [{"text": "Size", "start_pos": 10, "end_pos": 14, "type": "TASK", "confidence": 0.9832844138145447}]}, {"text": " Table 3: Translation performance (BLEU4(%))", "labels": [], "entities": [{"text": "Translation", "start_pos": 10, "end_pos": 21, "type": "TASK", "confidence": 0.8976147174835205}, {"text": "BLEU4", "start_pos": 35, "end_pos": 40, "type": "METRIC", "confidence": 0.9981808662414551}]}, {"text": " Table 5: Word alignment performance of various  FFNN-based models (F1-measure)", "labels": [], "entities": [{"text": "Word alignment", "start_pos": 10, "end_pos": 24, "type": "TASK", "confidence": 0.7993890643119812}, {"text": "F1-measure", "start_pos": 68, "end_pos": 78, "type": "METRIC", "confidence": 0.9946261048316956}]}]}