{"title": [{"text": "The effect of wording on message propagation: Topic-and author-controlled natural experiments on Twitter", "labels": [], "entities": [{"text": "message propagation", "start_pos": 25, "end_pos": 44, "type": "TASK", "confidence": 0.7531726956367493}]}], "abstractContent": [{"text": "Consider a person trying to spread an important message on asocial network.", "labels": [], "entities": []}, {"text": "He/she can spend hours trying to craft the message.", "labels": [], "entities": []}, {"text": "While there has been extensive prior work looking into predicting popularity of social-media content, the effect of wording per se has rarely been studied since it is often confounded with the popularity of the author and the topic.", "labels": [], "entities": []}, {"text": "To control for these confounding factors, we take advantage of the surprising fact that there are many pairs of tweets containing the same url and written by the same user but employing different wording.", "labels": [], "entities": []}, {"text": "Given such pairs, we ask: which version attracts more retweets?", "labels": [], "entities": []}, {"text": "This turns out to be a more difficult task than predicting popular topics.", "labels": [], "entities": [{"text": "predicting popular topics", "start_pos": 48, "end_pos": 73, "type": "TASK", "confidence": 0.9371825655301412}]}, {"text": "Still, humans can answer this question better than chance (but far from perfectly), and the computational methods we develop can do better than both an average human and a strong competing method trained on non-controlled data.", "labels": [], "entities": []}], "introductionContent": [{"text": "How does one make a message \"successful\"?", "labels": [], "entities": []}, {"text": "This question is of interest to many entities, including political parties trying to frame an issue, and individuals attempting to make a point in a group meeting.", "labels": [], "entities": []}, {"text": "In the first case, an important type of success is achieved if the national conversation adopts the rhetoric of the party; in the latter case, if other group members repeat the originating individual's point.", "labels": [], "entities": []}, {"text": "The massive availability of online messages, such as posts to social media, now affords researchers new means to investigate at a very large scale the factors affecting message propagation, also known as adoption, sharing, spread, or virality.", "labels": [], "entities": [{"text": "adoption, sharing, spread", "start_pos": 204, "end_pos": 229, "type": "TASK", "confidence": 0.7460511088371277}]}, {"text": "According to prior research, important features include characteristics of the originating author (e.g., verified Twitter user or not, author's messages' past success rate), the author's social network (e.g., number of followers), message timing, and message content or topic (.", "labels": [], "entities": []}, {"text": "Indeed, it's not surprising that one of the most retweeted tweets of all time was from user BarackObama, with 40M followers, on November 6, 2012: \"Four more years.", "labels": [], "entities": []}, {"text": "[link to photo]\".", "labels": [], "entities": []}, {"text": "Our interest in this paper is the effect of alternative message wording, meaning how the message is said, rather than what the message is about.", "labels": [], "entities": []}, {"text": "In contrast to the identity/social/timing/topic features mentioned above, wording is one of the few factors directly under an author's control when he or she seeks to convey a fixed piece of content.", "labels": [], "entities": []}, {"text": "For example, consider a speaker at the ACL business meeting who has been tasked with proposing that Paris be the next ACL location.", "labels": [], "entities": []}, {"text": "This person cannot on the spot become ACL president, change the shape of his/her social network, wait until the next morning to speak, or campaign for Rome instead; but he/she can craft the message to be more humorous, more informative, emphasize certain aspects instead of others, and soon.", "labels": [], "entities": []}, {"text": "In other words, we investigate whether a different choice of words affects message propagation, controlling for user and topic: would user BarackObama have gotten significantly more (or fewer) retweets if he had used some alternate wording to announce his reelection?", "labels": [], "entities": [{"text": "message propagation", "start_pos": 75, "end_pos": 94, "type": "TASK", "confidence": 0.7426266670227051}, {"text": "BarackObama", "start_pos": 139, "end_pos": 150, "type": "DATASET", "confidence": 0.8812623620033264}]}, {"text": "Although we cannot create a parallel universe in which BarackObama tweeted something else 1 , fortunately, a surprising characteristic of Twitter allows us to run a fairly analogous natural experiment: external forces serendipitously provide an environment that resembles the desired controlled setting.", "labels": [], "entities": []}, {"text": "Specifically, it turns out to be unexpectedly common for the same user to post different tweets regarding the same URLa good proxy for fine-grained topic 2 -within a relatively short period of time.", "labels": [], "entities": []}, {"text": "Some example pairs are shown in; we see that the paired tweets may differ dramatically, going far beyond word-for-word substitutions, so that quite interesting changes can be studied.", "labels": [], "entities": []}, {"text": "Looking at these examples, can one in fact tell from the wording which tweet in a topic-and author-controlled pair will be more successful?", "labels": [], "entities": []}, {"text": "The answer may not be a priori clear.", "labels": [], "entities": []}, {"text": "For example, for the first pair in the table, one person we asked found t 1 's invocation of a \"scandal\" to be more attention-grabbing; but another person preferred t 2 because it is more informative about the URL's content and includes \"fight media portrayal\".", "labels": [], "entities": []}, {"text": "In an Amazon Mechanical Turk (AMT) experiment ( \u00a74), we found that humans achieved an average accuracy of 61.3%: not that high, but better than chance, indicating that it is somewhat possible for humans to predict greater message spread from different deliveries of the same information.", "labels": [], "entities": [{"text": "Amazon Mechanical Turk (AMT)", "start_pos": 6, "end_pos": 34, "type": "TASK", "confidence": 0.5815732280413309}, {"text": "accuracy", "start_pos": 94, "end_pos": 102, "type": "METRIC", "confidence": 0.98406583070755}]}, {"text": "Buoyed by the evidence of our AMT study that wording effects exist, we then performed a battery of experiments to seek generally-applicable, non-1 Cf. the Music Lab \"multiple universes\" experiment to test the randomness of popularity ().", "labels": [], "entities": []}, {"text": "Although hashtags have been used as coarse-grained topic labels in prior work, for our purposes, we have no assurance that two tweets both using, say, \"#Tahrir\" would be attempting to express the same message but in different words.", "labels": [], "entities": []}, {"text": "In contrast, seethe same-URL examples in 3 Moreover, Twitter presents tweets to a reader in strict chronological order, so that there are no algorithmic-ranking effects to compensate for in determining whether readers saw a tweet.", "labels": [], "entities": []}, {"text": "And, Twitter accumulates retweet counts for the entire retweet cascade and displays them for the original tweet at the root of the propagation tree, so we can directly use Twitter's retweet counts to compare the entire reach of the different versions.", "labels": [], "entities": []}, {"text": "Twitter-specific features of more successful phrasings.", "labels": [], "entities": []}, {"text": "\u00a75.1 applies hypothesis testing (with Bonferroni correction to ameliorate issues with multiple comparisons) to investigate the utility of features like informativeness, resemblance to headlines, and conformity to the community norm in language use.", "labels": [], "entities": []}, {"text": "\u00a75.2 further validates our findings via prediction experiments, including on completely fresh held-out data, used only once and after an array of standard cross-validation experiments.", "labels": [], "entities": []}, {"text": "We achieved 66.5% cross-validation accuracy and 65.6% held-out accuracy with a combination of our custom features and bag-of-words.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 35, "end_pos": 43, "type": "METRIC", "confidence": 0.9931284189224243}, {"text": "accuracy", "start_pos": 63, "end_pos": 71, "type": "METRIC", "confidence": 0.9979350566864014}]}, {"text": "Our classifier fared significantly better than a number of baselines, including a strong classifier trained on the most-and least-retweeted tweets that was even granted access to author and timing metadata.", "labels": [], "entities": []}], "datasetContent": [{"text": "We now investigate computationally what wording features correspond to messages achieving a broader reach.", "labels": [], "entities": []}, {"text": "We start ( \u00a75.1) by introducing a set of generally-applicable and (mostly) non-Twitterspecific features to capture our intuitions about what might be better ways to phrase a message.", "labels": [], "entities": []}, {"text": "We then use hypothesis testing ( \u00a75.1) to evaluate the importance of each feature for message propluck with your research\" and \"This was very interesting and really made me think about how I word my own tweets.", "labels": [], "entities": []}, {"text": "Great job on this survey!\".", "labels": [], "entities": []}, {"text": "We only had to exclude one person (not counted among the 106 subjects), doing so because he or she gave the same uninformative justification for all pairs.", "labels": [], "entities": []}, {"text": "The accuracy range stems from whether author's social features were supplied and which subject was considered.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.9995125532150269}]}, {"text": "One-sided binomial test for feature increase (Do authors prefer to 'raise' the feature int 2 ?) YES : t 2 has a higher feature score than t 1 , \u03b1 \" .05 NO : t 2 has a lower feature score than t 1 , \u03b1 \" .05 (x%): %pf 2 \u0105 f 1 q, if sig.", "labels": [], "entities": [{"text": "YES", "start_pos": 96, "end_pos": 99, "type": "METRIC", "confidence": 0.9049729704856873}]}, {"text": "larger or smaller than 50% agation and the extent to which authors employ it, followed by experiments on a prediction task ( \u00a75.2) to further examine the utility of these features.", "labels": [], "entities": [{"text": "agation", "start_pos": 27, "end_pos": 34, "type": "METRIC", "confidence": 0.9476587772369385}]}], "tableCaptions": []}