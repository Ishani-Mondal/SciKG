{"title": [{"text": "Open Information Extraction for Spanish Language based on Syntactic Constraints", "labels": [], "entities": [{"text": "Open Information Extraction", "start_pos": 0, "end_pos": 27, "type": "TASK", "confidence": 0.679645041624705}, {"text": "Syntactic Constraints", "start_pos": 58, "end_pos": 79, "type": "TASK", "confidence": 0.7384810149669647}]}], "abstractContent": [{"text": "Open Information Extraction (Open IE) serves for the analysis of vast amounts of texts by extraction of assertions, or relations , in the form of tuples argument 1; relation; argument 2.", "labels": [], "entities": [{"text": "Open Information Extraction (Open IE)", "start_pos": 0, "end_pos": 37, "type": "TASK", "confidence": 0.7702639315809522}]}, {"text": "Various approaches to Open IE have been designed to perform in a fast, unsupervised manner.", "labels": [], "entities": [{"text": "Open IE", "start_pos": 22, "end_pos": 29, "type": "TASK", "confidence": 0.7712936997413635}]}, {"text": "All of them require language specific information for their implementation.", "labels": [], "entities": []}, {"text": "In this work, we introduce an approach to Open IE based on syntactic constraints over POS tag sequences targeted at Spanish language.", "labels": [], "entities": [{"text": "Open IE", "start_pos": 42, "end_pos": 49, "type": "TASK", "confidence": 0.6593558490276337}]}, {"text": "We describe the rules specific for Spanish language constructions and their implementation in EXTRHECH, an Open IE system for Spanish.", "labels": [], "entities": []}, {"text": "We also discuss language-specific issues of implementation.", "labels": [], "entities": []}, {"text": "We compare EXTRHECH's performance with that of REVERB, a similar Open IE system for English, on a parallel dataset and show that these systems perform at a very similar level.", "labels": [], "entities": [{"text": "REVERB", "start_pos": 47, "end_pos": 53, "type": "METRIC", "confidence": 0.883284330368042}]}, {"text": "We also compare EXTRHECH's performance on a dataset of grammatically correct sentences against its performance on a dataset of random texts extracted from the Web, drastically different in their quality from the first dataset.", "labels": [], "entities": []}, {"text": "The latter experiment shows ro-bustness of EXTRHECH on texts from the Web.", "labels": [], "entities": []}], "introductionContent": [{"text": "Open IE is a rapidly developing area in text processing, with its own applications and approaches that are different from traditional IE (.", "labels": [], "entities": [{"text": "Open IE", "start_pos": 0, "end_pos": 7, "type": "TASK", "confidence": 0.5138360261917114}, {"text": "text processing", "start_pos": 40, "end_pos": 55, "type": "TASK", "confidence": 0.7199981510639191}]}, {"text": "Unlike traditional IE, where systems are targeted at extraction of instances of particular relations with arguments restricted to certain semantic classes, e.g., to be born in(HUMAN; LOCA-TION), Open IE serves for extraction of all possible relations with arbitrary arguments.", "labels": [], "entities": [{"text": "IE", "start_pos": 19, "end_pos": 21, "type": "TASK", "confidence": 0.9578540325164795}]}, {"text": "For example, in \"Woman who drove van full of kids is charged with attempted murder\" two relations can be identified: Woman; drove; van full of kids and Woman; is charged with; attempted murder.", "labels": [], "entities": []}, {"text": "The ability to extract arbitrary relations from text allows applications of Open IE that are not possible in the frame of traditional IE.", "labels": [], "entities": []}, {"text": "Among them are fact extraction at sentence level (e.g., Mozart; was born in; Salzburg), new perspective on search as question answering (e.g., Where was Mozart born?), or assessment of the quality of text documents at Web scale (.", "labels": [], "entities": [{"text": "fact extraction", "start_pos": 15, "end_pos": 30, "type": "TASK", "confidence": 0.7377760261297226}, {"text": "question answering", "start_pos": 117, "end_pos": 135, "type": "TASK", "confidence": 0.7185943424701691}]}, {"text": "Additionally, the output of Open IE systems can serve for ontology population) and acquisition of commonsense knowledge (.", "labels": [], "entities": []}, {"text": "Although all Open IE systems are targeted at the extraction of arbitrary relations, the approaches to this task vary significantly.", "labels": [], "entities": []}, {"text": "The pilot approach suggested by is based on semi-supervised learning of general relation patterns that then serve for extraction of arbitrary relations.", "labels": [], "entities": []}, {"text": "However, the output of such systems contains many incoherent and inconsistent extractions, and the training stage is quite computationally complex.", "labels": [], "entities": []}, {"text": "suggested another approach where syntactic and lexical constraints were applied over POS-tagged input.", "labels": [], "entities": []}, {"text": "This approach has proven to be robust and fast enough for relation extraction at Web scale.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 58, "end_pos": 77, "type": "TASK", "confidence": 0.9526295959949493}]}, {"text": "Although Open IE is targeted at extraction of arbitrary relations without any semantic restrictions, all approaches have strong language dependent restrictions and require language specific information to be introduced in the corresponding systems.", "labels": [], "entities": [{"text": "Open IE", "start_pos": 9, "end_pos": 16, "type": "TASK", "confidence": 0.5917749255895615}]}, {"text": "For Spanish language, the apporach based on rules over dependency trees has been implemented both using full parsing) and using shallow dependency parsing ().", "labels": [], "entities": []}, {"text": "The former work shows that this approach is too computationally costly and is not always robust even on grammatically correct texts.", "labels": [], "entities": []}, {"text": "The latter work does not report any results for Spanish language or discusses any details specific to implementations for languages other than English.", "labels": [], "entities": []}, {"text": "Further, we are not aware of any existing research on whether the approach based on syntactic constraints over POS tags can be generalized to other languages.", "labels": [], "entities": []}, {"text": "Additionally, although Open IE is claimed to be useful for information extraction from the Web, we are not aware of any research on its applicability to texts randomly extracted from the Internet, i.e., those that have not been verified for grammatical correctness by peers or editors.", "labels": [], "entities": [{"text": "Open IE", "start_pos": 23, "end_pos": 30, "type": "TASK", "confidence": 0.5096685886383057}, {"text": "information extraction from the Web", "start_pos": 59, "end_pos": 94, "type": "TASK", "confidence": 0.8326651573181152}]}, {"text": "In this paper we discuss Open IE based on syntactic constraints over POS tag sequences, aimed at Spanish language.", "labels": [], "entities": [{"text": "Open IE", "start_pos": 25, "end_pos": 32, "type": "TASK", "confidence": 0.7206204831600189}]}, {"text": "We describe its implementation and introduce EXTRHECH, an Open IE system for Spanish.", "labels": [], "entities": []}, {"text": "We also compare its performance with that of REVERB) on a parallel dataset.", "labels": [], "entities": [{"text": "REVERB", "start_pos": 45, "end_pos": 51, "type": "METRIC", "confidence": 0.993333637714386}]}, {"text": "Additionally, we evaluate performance of our system over a dataset of texts randomly extracted from the Internet and discuss the issues that arise when processing random Internet texts.", "labels": [], "entities": []}, {"text": "We also give a brief analysis of errors.", "labels": [], "entities": [{"text": "errors", "start_pos": 33, "end_pos": 39, "type": "METRIC", "confidence": 0.966162919998169}]}, {"text": "The paper is organized as follows.", "labels": [], "entities": []}, {"text": "Related work is reviewed in Section 2.", "labels": [], "entities": []}, {"text": "Section 3 presents our approach to Open IE for Spanish and describes the EXTRHECH system.", "labels": [], "entities": [{"text": "Open IE", "start_pos": 35, "end_pos": 42, "type": "TASK", "confidence": 0.6366219818592072}]}, {"text": "Section 4 describes the experiments fora parallel English-Spanish dataset and fora Spanish dataset of texts randomly extracted from the Internet.", "labels": [], "entities": []}, {"text": "In Section 5, a brief analysis of errors is presented.", "labels": [], "entities": []}, {"text": "Section 6 draws the conclusions and outlines future work.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section we describe the experiments conducted with EXTRHECH system.", "labels": [], "entities": [{"text": "EXTRHECH", "start_pos": 59, "end_pos": 67, "type": "DATASET", "confidence": 0.8765693306922913}]}, {"text": "We compare EXTRHECH's performance with that of REVERB, an Open IE system for English based on the same algorithm).", "labels": [], "entities": [{"text": "REVERB", "start_pos": 47, "end_pos": 53, "type": "METRIC", "confidence": 0.9276183843612671}]}, {"text": "Since these systems are designed for different languages, we ran our experiment on a parallel dataset.", "labels": [], "entities": []}, {"text": "We took 300 parallel sentences from the English-Spanish part of News Commentary Corpus).", "labels": [], "entities": [{"text": "News Commentary Corpus", "start_pos": 64, "end_pos": 86, "type": "DATASET", "confidence": 0.8540163636207581}]}, {"text": "Then, we ran the extractors over the corresponding languages.", "labels": [], "entities": []}, {"text": "After that, two human annotators labeled each extraction as corrector incorrect.", "labels": [], "entities": []}, {"text": "For the Spanish part of the dataset, the annotators agreed on 80% of extractions (Cohen's kappa \u03ba = 0.60), whereas for the English part they agreed on 85% of extractions with \u03ba = 0.68.", "labels": [], "entities": []}, {"text": "For both datasets their respective \u03ba coefficients indicate substantial agreement between the annotators.", "labels": [], "entities": []}, {"text": "Precision was calculated as a fraction of correct extractions among all returned extractions.", "labels": [], "entities": [{"text": "Precision", "start_pos": 0, "end_pos": 9, "type": "METRIC", "confidence": 0.9925577640533447}]}, {"text": "We calculated Recall as a fraction of all returned correct extractions among all possible (i.e., expected) correct extractions.", "labels": [], "entities": [{"text": "Recall", "start_pos": 14, "end_pos": 20, "type": "METRIC", "confidence": 0.9872878789901733}]}, {"text": "By manual revision of the sentences in the datasets, we made a list of all expected correct extractions.", "labels": [], "entities": []}, {"text": "Their number was used to estimate the recall.", "labels": [], "entities": [{"text": "recall", "start_pos": 38, "end_pos": 44, "type": "METRIC", "confidence": 0.9962384700775146}]}, {"text": "In contrast to REVERB, our system does not have a confidence score mechnaism at this point.", "labels": [], "entities": [{"text": "REVERB", "start_pos": 15, "end_pos": 21, "type": "METRIC", "confidence": 0.9614346623420715}]}, {"text": "To make the comparison between the systems appropriate, we ran REVERB extractor with the confidence score level set to 0 that means that the system returns all relations that match the rules, i.e., in the same way as EXTRHECH does.", "labels": [], "entities": [{"text": "REVERB extractor", "start_pos": 63, "end_pos": 79, "type": "METRIC", "confidence": 0.9285003840923309}, {"text": "confidence score level", "start_pos": 89, "end_pos": 111, "type": "METRIC", "confidence": 0.9066677689552307}]}, {"text": "Hence, the systems were in equivalent conditions.", "labels": [], "entities": []}, {"text": "The results of the experiment are shown in.", "labels": [], "entities": []}, {"text": "As we see, on a parallel dataset of texts from News Commentary Corpus, both systems show a very similar performance.", "labels": [], "entities": [{"text": "News Commentary Corpus", "start_pos": 47, "end_pos": 69, "type": "DATASET", "confidence": 0.8254952629407247}]}, {"text": "Based on this observation, we can conclude that the algorithm suggested: Performance comparison of REVERB and EXTRHECH systems over a parallel dataset.", "labels": [], "entities": [{"text": "REVERB", "start_pos": 99, "end_pos": 105, "type": "METRIC", "confidence": 0.8502656817436218}]}, {"text": "in) can be easily adopted for other languages with dominating SVO word order and an available POS-tagger.", "labels": [], "entities": []}, {"text": "One of the most important goals of Open IE systems is to be able to process large amounts of texts directly from the Web.", "labels": [], "entities": []}, {"text": "This requires high performance speed and robustness on texts that often lack grammatical and orthographical correctness or coherence.", "labels": [], "entities": []}, {"text": "The study showing the approach's advantage in speed was already presented in).", "labels": [], "entities": [{"text": "speed", "start_pos": 46, "end_pos": 51, "type": "METRIC", "confidence": 0.994724690914154}]}, {"text": "In this work we focused on robustness.", "labels": [], "entities": []}, {"text": "We evaluated the performance of our system on a dataset of sentences extracted from the Internet \"as is\".", "labels": [], "entities": []}, {"text": "For this dataset, we took 200 random data chunks detected by a sentence splitter from CommonCrawl 2012 corpus), which is a collection of web texts crawled from over 5 billion web pages.", "labels": [], "entities": [{"text": "CommonCrawl 2012 corpus", "start_pos": 86, "end_pos": 109, "type": "DATASET", "confidence": 0.9479546546936035}]}, {"text": "However, 41 from those 200 chunks were not samples of textual information inhuman language but rather pieces of programming codes or numbers.", "labels": [], "entities": []}, {"text": "We took out these chunks because they are not relevant for our research.", "labels": [], "entities": []}, {"text": "Ina real life scenario they could be easily detected and eliminated from the Web data stream.", "labels": [], "entities": [{"text": "Web data stream", "start_pos": 77, "end_pos": 92, "type": "DATASET", "confidence": 0.8794167836507162}]}, {"text": "After this, our dataset consisted of 159 sentences written inhuman language.", "labels": [], "entities": []}, {"text": "We will refer to this dataset as Raw Web text dataset.", "labels": [], "entities": [{"text": "Raw Web text dataset", "start_pos": 33, "end_pos": 53, "type": "DATASET", "confidence": 0.7916441112756729}]}, {"text": "1 Of 159 sentences of the dataset, 36 sentences (22% of the dataset) were grammatically incorrect or incoherent, as evaluated by a professional linguist.", "labels": [], "entities": []}, {"text": "We ran EXTRHECH system over this dataset and asked two human judges to label extractions as corrector incorrect.", "labels": [], "entities": [{"text": "EXTRHECH", "start_pos": 7, "end_pos": 15, "type": "METRIC", "confidence": 0.7672790288925171}]}, {"text": "The annotators agreed on 70% of extractions with Cohen's \u03ba = 0.40, which indicates the lower bound of moderate agreement between judges.", "labels": [], "entities": []}, {"text": "Precision and Recall were calculated in the same manner as described in Section 4.1.", "labels": [], "entities": [{"text": "Precision", "start_pos": 0, "end_pos": 9, "type": "METRIC", "confidence": 0.989569902420044}, {"text": "Recall", "start_pos": 14, "end_pos": 20, "type": "METRIC", "confidence": 0.9920459985733032}]}, {"text": "We compare these numbers to the results obtained for the dataset of grammatically correct sentences from News Commentary Corpus in.", "labels": [], "entities": [{"text": "News Commentary Corpus", "start_pos": 105, "end_pos": 127, "type": "DATASET", "confidence": 0.9011779427528381}]}, {"text": "We can observe that system's performence has: Performance of EXTRHECH on the grammatically correct dataset and the dataset of noisy sentences extracted from the Web not lowered significantly when processing \"noisy\" texts compared to edited newspaper texts.", "labels": [], "entities": []}, {"text": "An interesting observation is that texts from the Internet are poorer in facts than the news texts.", "labels": [], "entities": []}, {"text": "The number of expected extractions was manually evaluated by a human expert for both datasets.", "labels": [], "entities": []}, {"text": "The ratio of extractions to sentences for the news dataset was 1.5:1, while for the Raw Web dataset it was only 1.03:1.", "labels": [], "entities": [{"text": "news dataset", "start_pos": 46, "end_pos": 58, "type": "DATASET", "confidence": 0.8389300405979156}, {"text": "Raw Web dataset", "start_pos": 84, "end_pos": 99, "type": "DATASET", "confidence": 0.9591920177141825}]}, {"text": "Now we will briefly discuss the issue arising due to various encoding standards used for non-ASCII characters, e.g., of\u00e1of\u00b4of\u00e1, \u00b4 e, \u02dc n, etc.", "labels": [], "entities": []}, {"text": "While applying Freeling morphological analyzer to the dataset, we encountered an issue that the sentences came in various encodings.", "labels": [], "entities": []}, {"text": "As we mentioned in Section 3, Freeling-2.2 analyzer works properly only with ISO encoded input.", "labels": [], "entities": [{"text": "Freeling-2.2 analyzer", "start_pos": 30, "end_pos": 51, "type": "TASK", "confidence": 0.6041253805160522}]}, {"text": "Therefore, we had to convert each sentence from the dataset into ISO encoding.", "labels": [], "entities": []}, {"text": "While most of the sentences were in UTF-8 encoding and were converted in a single pass, the encoding of about 3% of the sentences was initially corrupted, therefore, they were not processed correctly by the POS-tagger.", "labels": [], "entities": [{"text": "POS-tagger", "start_pos": 207, "end_pos": 217, "type": "DATASET", "confidence": 0.9099107980728149}]}, {"text": "Although the issue is manageable at the scale of a small dataset, it might affect the speed and quality of fact extraction when working at Web scale.", "labels": [], "entities": [{"text": "fact extraction", "start_pos": 107, "end_pos": 122, "type": "TASK", "confidence": 0.7353687882423401}]}], "tableCaptions": [{"text": " Table 1: Performance comparison of REVERB and  EXTRHECH systems over a parallel dataset.", "labels": [], "entities": []}, {"text": " Table 2: Performance of EXTRHECH on the gram- matically correct dataset and the dataset of noisy  sentences extracted from the Web", "labels": [], "entities": []}, {"text": " Table 3: Distribution of errors in output by  the basic error types in relation extraction for  EXTRHECH system run over Raw Web dataset", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 72, "end_pos": 91, "type": "TASK", "confidence": 0.7303832620382309}, {"text": "Raw Web dataset", "start_pos": 122, "end_pos": 137, "type": "DATASET", "confidence": 0.6783873637517294}]}]}