{"title": [{"text": "A Hybrid Approach to Skeleton-based Translation", "labels": [], "entities": []}], "abstractContent": [{"text": "In this paper we explicitly consider sentence skeleton information for Machine Translation (MT).", "labels": [], "entities": [{"text": "Machine Translation (MT)", "start_pos": 71, "end_pos": 95, "type": "TASK", "confidence": 0.8460806906223297}]}, {"text": "The basic idea is that we translate the key elements of the input sentence using a skeleton translation model , and then cover the remain segments using a full translation model.", "labels": [], "entities": []}, {"text": "We apply our approach to a state-of-the-art phrase-based system and demonstrate very promising BLEU improvements and TER reductions on the NIST Chinese-English MT evaluation data.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 95, "end_pos": 99, "type": "METRIC", "confidence": 0.9986891150474548}, {"text": "TER reductions", "start_pos": 117, "end_pos": 131, "type": "METRIC", "confidence": 0.9474748373031616}, {"text": "NIST Chinese-English MT evaluation data", "start_pos": 139, "end_pos": 178, "type": "DATASET", "confidence": 0.8667036771774292}]}], "introductionContent": [{"text": "Current Statistical Machine Translation (SMT) approaches model the translation problem as a process of generating a derivation of atomic translation units, assuming that every unit is drawn out of the same model.", "labels": [], "entities": [{"text": "Statistical Machine Translation (SMT)", "start_pos": 8, "end_pos": 45, "type": "TASK", "confidence": 0.8343985478083292}]}, {"text": "The simplest of these is the phrase-based approach which employs a global model to process any sub-strings of the input sentence.", "labels": [], "entities": []}, {"text": "In this way, all we need is to increasingly translate a sequence of source words each time until the entire sentence is covered.", "labels": [], "entities": []}, {"text": "Despite good results in many tasks, such a method ignores the roles of each source word and is somewhat different from the way used by translators.", "labels": [], "entities": []}, {"text": "For example, an important-first strategy is generally adopted inhuman translation -we translate the key elements/structures (or skeleton) of the sentence first, and then translate the remaining parts.", "labels": [], "entities": []}, {"text": "This especially makes sense for some languages, such as Chinese, where complex structures are usually involved.", "labels": [], "entities": []}, {"text": "Note that the source-language structural information has been intensively investigated in recent studies of syntactic translation models.", "labels": [], "entities": [{"text": "syntactic translation", "start_pos": 108, "end_pos": 129, "type": "TASK", "confidence": 0.7595207393169403}]}, {"text": "Some of them developed syntax-based models on complete syntactic trees with Treebank annotations (, and others used source-language syntax as soft constraints.", "labels": [], "entities": []}, {"text": "However, these approaches suffer from the same problem as the phrase-based counterpart and use the single global model to handle different translation units, no matter they are from the skeleton of the input tree/sentence or other not-soimportant sub-structures.", "labels": [], "entities": []}, {"text": "In this paper we instead explicitly model the translation problem with sentence skeleton information.", "labels": [], "entities": [{"text": "translation problem", "start_pos": 46, "end_pos": 65, "type": "TASK", "confidence": 0.9181532263755798}]}, {"text": "In particular, \u2022 We develop a skeleton-based model which divides translation into two sub-models: a skeleton translation model (i.e., translating the key elements) and a full translation model (i.e., translating the remaining source words and generating the complete translation).", "labels": [], "entities": []}, {"text": "\u2022 We develop a skeletal language model to describe the possibility of translation skeleton and handle some of the long-distance word dependencies.", "labels": [], "entities": [{"text": "translation skeleton", "start_pos": 70, "end_pos": 90, "type": "TASK", "confidence": 0.9627317786216736}]}, {"text": "\u2022 We apply the proposed model to ChineseEnglish phrase-based MT and demonstrate promising BLEU improvements and TER reductions on the NIST evaluation data.", "labels": [], "entities": [{"text": "ChineseEnglish phrase-based", "start_pos": 33, "end_pos": 60, "type": "DATASET", "confidence": 0.8640275001525879}, {"text": "MT", "start_pos": 61, "end_pos": 63, "type": "TASK", "confidence": 0.4496822953224182}, {"text": "BLEU", "start_pos": 90, "end_pos": 94, "type": "METRIC", "confidence": 0.9994162321090698}, {"text": "TER reductions", "start_pos": 112, "end_pos": 126, "type": "METRIC", "confidence": 0.9802771210670471}, {"text": "NIST evaluation data", "start_pos": 134, "end_pos": 154, "type": "DATASET", "confidence": 0.977716306845347}]}], "datasetContent": [{"text": "We experimented with our approach on ChineseEnglish translation using the NiuTrans opensource MT toolkit ().", "labels": [], "entities": [{"text": "ChineseEnglish translation", "start_pos": 37, "end_pos": 63, "type": "TASK", "confidence": 0.765479177236557}, {"text": "NiuTrans opensource MT toolkit", "start_pos": 74, "end_pos": 104, "type": "DATASET", "confidence": 0.88804030418396}]}, {"text": "Our bilingual corpus consists of 2.7M sentence pairs.", "labels": [], "entities": []}, {"text": "All these sentences were aligned in word level using the GIZA++ system and the \"grow-diag-finaland\" heuristics.", "labels": [], "entities": []}, {"text": "A 5-gram language model was trained on the Xinhua portion of the English Gigaword corpus in addition to the target-side of the bilingual data.", "labels": [], "entities": [{"text": "English Gigaword corpus", "start_pos": 65, "end_pos": 88, "type": "DATASET", "confidence": 0.844005286693573}]}, {"text": "This language model was used in both the baseline and our improved systems.", "labels": [], "entities": []}, {"text": "For our skeletal language model, we trained a 5-gram language model on the target-side of the bilingual data by generalizing non-skeleton segments to Xs.", "labels": [], "entities": []}, {"text": "We used the newswire portion of the NIST MT06 evaluation data as our development set, and used the evaluation data of MT04 and MT05 as our test sets.", "labels": [], "entities": [{"text": "NIST MT06 evaluation data", "start_pos": 36, "end_pos": 61, "type": "DATASET", "confidence": 0.843915268778801}, {"text": "MT04", "start_pos": 118, "end_pos": 122, "type": "DATASET", "confidence": 0.9542165994644165}, {"text": "MT05", "start_pos": 127, "end_pos": 131, "type": "DATASET", "confidence": 0.8697638511657715}]}, {"text": "We chose the default feature set of the NiuTrans.Phrase engine for building the baseline, including phrase translation probabilities, lexical weights, a 5-gram language model, word and phrase bonuses, a ME-based lexicalized reordering model.", "labels": [], "entities": [{"text": "phrase translation probabilities", "start_pos": 100, "end_pos": 132, "type": "TASK", "confidence": 0.7856961488723755}]}, {"text": "All feature weights were learned using minimum error rate training.", "labels": [], "entities": []}, {"text": "Our skeleton identification system was built using the t3 toolkit 2 which implements a stateof-the-art sentence simplification system.", "labels": [], "entities": [{"text": "skeleton identification", "start_pos": 4, "end_pos": 27, "type": "TASK", "confidence": 0.7026773691177368}]}, {"text": "We used the NEU Chinese sentence simplification (NEUCSS) corpus as our training data (.", "labels": [], "entities": [{"text": "NEU Chinese sentence simplification (NEUCSS) corpus", "start_pos": 12, "end_pos": 63, "type": "DATASET", "confidence": 0.7398149408400059}]}, {"text": "It contains the annotation of sentence skeleton on the Chinese-language side of the Penn Parallel Chinese-English Treebank (LD-C2003E07).", "labels": [], "entities": [{"text": "Penn Parallel Chinese-English Treebank (LD-C2003E07)", "start_pos": 84, "end_pos": 136, "type": "DATASET", "confidence": 0.9399172493389675}]}, {"text": "We trained our system using the Parts 1-8 of the NEUCSS corpus and obtained a 65.2% relational F1 score and 63.1% compression rate in held-out test (Part 10).", "labels": [], "entities": [{"text": "NEUCSS corpus", "start_pos": 49, "end_pos": 62, "type": "DATASET", "confidence": 0.9824858009815216}, {"text": "F1 score", "start_pos": 95, "end_pos": 103, "type": "METRIC", "confidence": 0.9522109627723694}, {"text": "compression rate", "start_pos": 114, "end_pos": 130, "type": "METRIC", "confidence": 0.9800122082233429}]}, {"text": "For comparison, we also manually annotated the MT development and test data with skeleton information according to the annotation standard provided within NEUCSS.", "labels": [], "entities": [{"text": "MT development", "start_pos": 47, "end_pos": 61, "type": "TASK", "confidence": 0.8635248839855194}, {"text": "NEUCSS", "start_pos": 155, "end_pos": 161, "type": "DATASET", "confidence": 0.9734897613525391}]}, {"text": "shows the case-insensitive IBM-version BLEU and TER scores of different systems.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 39, "end_pos": 43, "type": "METRIC", "confidence": 0.9087209701538086}, {"text": "TER", "start_pos": 48, "end_pos": 51, "type": "METRIC", "confidence": 0.9969435334205627}]}, {"text": "We see, first of all, that the MT system benefits from our approach inmost cases.", "labels": [], "entities": [{"text": "MT", "start_pos": 31, "end_pos": 33, "type": "TASK", "confidence": 0.981194794178009}]}, {"text": "In both the manual and automatic identification of sentence skeleton (rows 2 and 4), there is a significant improvement on the \"All\" data set.", "labels": [], "entities": [{"text": "All\" data set", "start_pos": 128, "end_pos": 141, "type": "DATASET", "confidence": 0.7363324537873268}]}, {"text": "However, using different skeleton identification results for training and inference (row 3) does not show big improvements due to the data inconsistency problem.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: BLEU4[%] and TER[%] scores of different systems. Boldface means a significant improvement  (p < 0.05)", "labels": [], "entities": [{"text": "BLEU4", "start_pos": 10, "end_pos": 15, "type": "METRIC", "confidence": 0.9986945986747742}, {"text": "TER", "start_pos": 23, "end_pos": 26, "type": "METRIC", "confidence": 0.9985353946685791}]}]}