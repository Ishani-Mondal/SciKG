{"title": [{"text": "Citation Resolution: A method for evaluating context-based citation recommendation systems", "labels": [], "entities": [{"text": "Citation Resolution", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.8071688413619995}, {"text": "context-based citation recommendation", "start_pos": 45, "end_pos": 82, "type": "TASK", "confidence": 0.6564198831717173}]}], "abstractContent": [{"text": "Wouldn't it be helpful if your text editor automatically suggested papers that are relevant to your research?", "labels": [], "entities": []}, {"text": "Wouldn't it be even better if those suggestions were contextually relevant?", "labels": [], "entities": []}, {"text": "In this paper we name a system that would accomplish this a context-based citation recommendation (CBCR) system.", "labels": [], "entities": [{"text": "context-based citation recommendation (CBCR)", "start_pos": 60, "end_pos": 104, "type": "TASK", "confidence": 0.7795663475990295}]}, {"text": "We specifically present Citation Resolution, a method for the evaluation of CBCR systems which exclusively uses readily-available scientific articles.", "labels": [], "entities": [{"text": "Citation Resolution", "start_pos": 24, "end_pos": 43, "type": "TASK", "confidence": 0.842867910861969}]}, {"text": "Exploiting the human judgements that are already implicit in available resources, we avoid purpose-specific annotation.", "labels": [], "entities": []}, {"text": "We apply this evaluation to three sets of methods for representing a document, based on a) the contents of the document, b) the surrounding contexts of citations to the document found in other documents, and c) a mixture of the two.", "labels": [], "entities": []}], "introductionContent": [{"text": "Imagine that you were working on a draft paper which contained a sentence like the following: A variety of coherence theories have been developed over the years ... and their principles have found application in many symbolic text generation systems (e.g.", "labels": [], "entities": [{"text": "symbolic text generation", "start_pos": 217, "end_pos": 241, "type": "TASK", "confidence": 0.6368536949157715}]}], "datasetContent": [{"text": "Our test corpus consists of approx. 9000 papers from the ACL Anthology 2 converted from PDF to XML format.", "labels": [], "entities": [{"text": "ACL Anthology 2", "start_pos": 57, "end_pos": 72, "type": "DATASET", "confidence": 0.9312477509180704}]}, {"text": "This corpus, the rationale behind its selection and the process used to convert the files is described in depth in.", "labels": [], "entities": []}, {"text": "This is an ideal corpus for these tests fora large number of reasons, but these are key for us: all the papers are freely available, the ratio of collection-internal references for each paper is high (the authors measure it at 0.33) and it is a familiar domain for us.", "labels": [], "entities": []}, {"text": "For our tests, we selected the documents of this corpus with at least 8 collection-internal references.", "labels": [], "entities": []}, {"text": "This yielded a total of 278 test documents and a total of 5446 resolvable citations.", "labels": [], "entities": []}, {"text": "We substitute all citations in the text with citation token placeholders and extract the citation context for each using a simple window of up tow words left and w words right around the placeholder.", "labels": [], "entities": []}, {"text": "This produces a list of word tokens that is equivalent to a query in IR.", "labels": [], "entities": []}, {"text": "This is a frequently employed technique, although it is often observed that this maybe too simplistic a method.", "labels": [], "entities": []}, {"text": "Other methods have been tried, e.g. full sentence extraction ( and comparing these methods is something we plan to incorporate in future work.", "labels": [], "entities": [{"text": "full sentence extraction", "start_pos": 36, "end_pos": 60, "type": "TASK", "confidence": 0.6772280236085256}]}, {"text": "We then make the document's collectioninternal references our test collection D and use a number of methods for generating the document representation.", "labels": [], "entities": []}, {"text": "We use the well-known Vector Space Model and a standard implementation of tfidf and cosine similarity as implemented by the scikit-learn Python framework 3 . At present, we are applying no cut-off and just rank all of the document's collection-internal references for each citation context, aiming to rank the correct one in the first positions in the list.", "labels": [], "entities": []}, {"text": "We tested three different approaches to generating a document's VSM representation: internal representations, which are based on the contents of the document, external representations, which are built using a document's incoming link citation contexts (following and) and mixed representations, which are an attempt to combine the two.", "labels": [], "entities": []}, {"text": "\u2022 The internal representations of the documents were generated using three different methods: title plus abstract, full text and passage.", "labels": [], "entities": []}, {"text": "Passage consists in splitting the document into half-overlapping passages of a fixed length of k words and choosing for each document the 3 http://scikit-learn.org passage with the maximum cosine similarity score with the query.", "labels": [], "entities": [{"text": "cosine similarity score", "start_pos": 189, "end_pos": 212, "type": "METRIC", "confidence": 0.7576263149579366}]}, {"text": "We present the results of using 250, 300 and 350 as values fork.", "labels": [], "entities": []}, {"text": "\u2022 The external representations (inlink context) are based on extracting the context around citation tokens to the document from other documents in the collection, excluding the set of test papers.", "labels": [], "entities": []}, {"text": "This is the same as using the anchor text of a hyperlink to improve results in web-based IR (see for extensive analyis).", "labels": [], "entities": []}, {"text": "This context is extracted in the same way as the query: as a window, or list of w tokens surrounding the citation left and right.", "labels": [], "entities": []}, {"text": "We present our best results, using symmetrical and asymmetrical windows of w = [(5, 5), (10, 10), (10, 5),,].", "labels": [], "entities": []}, {"text": "\u2022 We build the mixed representations by simply concatenating the internal and external bagsof-words that represent the documents, from which we then build the VSM representation.", "labels": [], "entities": []}, {"text": "For this, we combine different window sizes for the inlink context with: full text, title abstract and passage350.", "labels": [], "entities": []}, {"text": "presents a selection of the most relevant results, where the best result and document representation method of each type is highlighted.", "labels": [], "entities": []}, {"text": "We present results for the most relevant parameter values, producing the highest scores of all those tested.", "labels": [], "entities": []}, {"text": "From a close look at internal methods, we can see that the passage method with k = 400 beats both full text and title abstract, suggesting that a more elaborate way of building a document representation should improve results.", "labels": [], "entities": []}, {"text": "This is consistent with previous findings: had already reported that using selected sections plus captions of figures and title and abstract to build the internal document representation improves the results of their indexing task by 7.4% over just using title and abstract.", "labels": [], "entities": []}, {"text": "Similarly, showed that automatically generated summaries lead to similar recall and better indexing precision than full-text articles fora keywordbased indexing task.", "labels": [], "entities": [{"text": "recall", "start_pos": 73, "end_pos": 79, "type": "METRIC", "confidence": 0.9990777969360352}, {"text": "precision", "start_pos": 100, "end_pos": 109, "type": "METRIC", "confidence": 0.9622174501419067}]}], "tableCaptions": [{"text": " Table 1: Accuracy for each document representation method (rows) and context window size (columns).", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9960590600967407}]}]}