{"title": [], "abstractContent": [{"text": "The disambiguation algorithm presented in this paper is implemented in SemLinker, an entity linking system.", "labels": [], "entities": []}, {"text": "First, named entities are linked to candidate Wikipedia pages by a generic annotation engine.", "labels": [], "entities": []}, {"text": "Then, the algorithm re-ranks candidate links according to mutual relations between all the named entities found in the document.", "labels": [], "entities": []}, {"text": "The evaluation is based on experiments conducted on the test corpus of the TAC-KBP 2012 entity linking task.", "labels": [], "entities": [{"text": "TAC-KBP 2012 entity linking task", "start_pos": 75, "end_pos": 107, "type": "TASK", "confidence": 0.6718011736869812}]}], "introductionContent": [{"text": "The Entity Linking (EL) task consists in linking name mentions of named entities (NEs) found in a document to their corresponding entities in a reference Knowledge Base (KB).", "labels": [], "entities": [{"text": "Entity Linking (EL) task", "start_pos": 4, "end_pos": 28, "type": "TASK", "confidence": 0.8354525069395701}, {"text": "linking name mentions of named entities (NEs) found in a document", "start_pos": 41, "end_pos": 106, "type": "TASK", "confidence": 0.7148502377363352}]}, {"text": "These NEs can be of type person (PER), organization (ORG), etc., and they are usually represented in the KB by a Uniform Resource Identifier (URI).", "labels": [], "entities": []}, {"text": "Dealing with ambiguity is one of the key difficulties in this task, since mentions are often highly polysemous, and potentially related to many different KB entries.", "labels": [], "entities": []}, {"text": "Various approaches have been proposed to solve the named entity disambiguation (NED) problem.", "labels": [], "entities": [{"text": "named entity disambiguation (NED) problem", "start_pos": 51, "end_pos": 92, "type": "TASK", "confidence": 0.8091520369052887}]}, {"text": "Most of them involve the use of surface forms extracted from Wikipedia.", "labels": [], "entities": []}, {"text": "Surface forms consist of a word or a group of words that match lexical units like Paris or New York City.", "labels": [], "entities": []}, {"text": "They are used as matching sequences to locate corresponding candidate entries in the KB, and then to disambiguate those candidates using similarity measures.", "labels": [], "entities": []}, {"text": "The NED problem is related to the Word Sense Disambiguation (WSD) problem, and is often more challenging since mentions of NEs can be highly ambiguous.", "labels": [], "entities": [{"text": "Word Sense Disambiguation (WSD) problem", "start_pos": 34, "end_pos": 73, "type": "TASK", "confidence": 0.7751711521829877}]}, {"text": "For instance, names of places can be very common as is Paris, which refers to 26 different places in Wikipedia.", "labels": [], "entities": []}, {"text": "Hence, systems that attempt to address the NED problem must include disambiguation resources.", "labels": [], "entities": [{"text": "NED problem", "start_pos": 43, "end_pos": 54, "type": "TASK", "confidence": 0.897389829158783}]}, {"text": "In the context of the Named Entity Recognition (NER) task, such resources can be generic and generative.", "labels": [], "entities": [{"text": "Named Entity Recognition (NER) task", "start_pos": 22, "end_pos": 57, "type": "TASK", "confidence": 0.838169412953513}]}, {"text": "This generative approach does not apply to the EL task where each entity to be linked to a semantic description has a specific word context, marker of its exact identity.", "labels": [], "entities": [{"text": "EL task", "start_pos": 47, "end_pos": 54, "type": "TASK", "confidence": 0.8638917207717896}]}, {"text": "One of the classical approach to conduct the disambiguation process in NED applications is to consider the context of the mention to be mapped, and compare this context with contextual information about the potential target entities (see for instance the KIM system ().", "labels": [], "entities": []}, {"text": "This is usually done using similarity measures (such as cosine similarity, weighted Jaccard distance, KL divergence...) that evaluate the distance between a bag of words related to a candidate annotation, and the words surrounding the entity to annotate in the text.", "labels": [], "entities": [{"text": "weighted Jaccard distance", "start_pos": 75, "end_pos": 100, "type": "METRIC", "confidence": 0.7169260581334432}, {"text": "KL divergence", "start_pos": 102, "end_pos": 115, "type": "METRIC", "confidence": 0.8629408478736877}]}, {"text": "In more recent approaches, it is suggested that annotation processes based on similarity distance measures can be improved by making use of other annotations present in the same document.", "labels": [], "entities": []}, {"text": "Such techniques are referred to as semantic relatedness (), collective disambiguation), or joint disambiguation).", "labels": [], "entities": []}, {"text": "The idea is to evaluate in a set of candidate links which one is the most likely to be correct by taking the other links contained in the document into account.", "labels": [], "entities": []}, {"text": "For example, if a NE describes a city name like Paris, it is more probable that the correct link for this city name designates Paris (France) rather than Paris (Texas) if a neighbor entity offers candidate links semantically related to Paris (France) like the Seine river or the Champs-Elys\u00e9es.", "labels": [], "entities": []}, {"text": "Such techniques mostly involve exploration of graphs resulting of all the candidate annotations proposed fora given document, and try to rank the best candidates for each annotation using an ontology.", "labels": [], "entities": []}, {"text": "The ontology (like YAGO or DBPedia) provides a pre-existing set of potential relations between the entities to link (like for instance, in our previous example, Paris (France) has river Seine) that will be used to rank the best candidates according to their mutual presence in the document.", "labels": [], "entities": [{"text": "YAGO", "start_pos": 19, "end_pos": 23, "type": "DATASET", "confidence": 0.6448584794998169}, {"text": "DBPedia", "start_pos": 27, "end_pos": 34, "type": "DATASET", "confidence": 0.706499457359314}]}, {"text": "In this paper we explore the capabilities of a disambiguation algorithm using all the available annotation layers of NEs to improve their links.", "labels": [], "entities": []}, {"text": "The paper makes the following novel propositions: 1) the ontology used to evaluate the relatedness of candidates is replaced by internal links and categories from the Wikipedia corpus; 2) the coherence of entities is improved prior to the calculation of semantic relatedness using a co-reference resolution algorithm, and a NE label correction method; 3) the proposed method is robust enough to improve the performance of existing entity linking annotation engines, which are capable of providing a set of ranked candidates for each annotation in a document.", "labels": [], "entities": [{"text": "NE label correction", "start_pos": 324, "end_pos": 343, "type": "TASK", "confidence": 0.5412863194942474}]}, {"text": "This paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 describes related works.", "labels": [], "entities": []}, {"text": "The proposed method is presented in Section 3 where we explain how our SemLinker system prepares documents that contain mentions to disambiguate, then we detail the disambiguation algorithm.", "labels": [], "entities": []}, {"text": "The evaluation of the complete system is provided in Section 4.", "labels": [], "entities": []}, {"text": "Finally, we discuss the obtained results, and conclude.", "labels": [], "entities": []}], "datasetContent": [{"text": "SemLinker has been evaluated on the TAC-KBP 2012 EL task (.", "labels": [], "entities": [{"text": "TAC-KBP 2012 EL task", "start_pos": 36, "end_pos": 56, "type": "DATASET", "confidence": 0.8508090972900391}]}, {"text": "In this task, mentions of entities found in a document collection must be linked to entities in a reference KB, or to new named entities discovered in the collection.", "labels": [], "entities": []}, {"text": "The document collection built for KBP 2012 contains a combination of newswire articles (News), SemLinker TAC-KBP2012 systems modules no disambiguation MDP only all modules  posts to blogs and newsgroups (Web).", "labels": [], "entities": [{"text": "KBP 2012", "start_pos": 34, "end_pos": 42, "type": "DATASET", "confidence": 0.8636345267295837}]}, {"text": "Given a query that consists of a document with a specified name mention of an entity, the task is to determine the correct node in the reference KB for the entity, adding anew node for the entity if it is not already in the reference KB.", "labels": [], "entities": []}, {"text": "Entities can be of type person (PER), organization (ORG), or geopolitical entity (GPE).", "labels": [], "entities": []}, {"text": "The reference knowledge base is derived from an October 2008 dump of English Wikipedia, which includes 818,741 nodes.", "labels": [], "entities": [{"text": "English Wikipedia", "start_pos": 69, "end_pos": 86, "type": "DATASET", "confidence": 0.8131005167961121}]}, {"text": "A complete description of these linguistic resources can be found in).", "labels": [], "entities": []}, {"text": "For the sake of reproducibility, we applied the KBP scoring metric (B 3 + F ) described in, and we used the KBP scorer 1 . The evaluated system makes use of the Wikimeta annotation engine.", "labels": [], "entities": [{"text": "KBP scoring metric (B 3 + F )", "start_pos": 48, "end_pos": 77, "type": "METRIC", "confidence": 0.7576947642697228}, {"text": "KBP scorer 1", "start_pos": 108, "end_pos": 120, "type": "METRIC", "confidence": 0.5463690062363943}]}, {"text": "The maximum number of candidate URIs isl = 15.", "labels": [], "entities": []}, {"text": "The MDP correction parameters \u03b1 and \u03b2 described in Section 3.4 have been experimentally set to \u03b1 = 10, \u03b2 = 2.", "labels": [], "entities": [{"text": "MDP correction", "start_pos": 4, "end_pos": 18, "type": "METRIC", "confidence": 0.5998426675796509}]}, {"text": "presents the results obtained by the system in three configurations.", "labels": [], "entities": []}, {"text": "In the first column, the system is evaluated without the disambiguation module.", "labels": [], "entities": []}, {"text": "In the second column, we applied the MDP without correction processes.", "labels": [], "entities": []}, {"text": "The system with the complete disambiguation module obtained the results provided in the third column.", "labels": [], "entities": []}, {"text": "The three best results and the median from TAC-KBP 2012 systems are shown in the remaining columns for the sake of comparison.", "labels": [], "entities": [{"text": "TAC-KBP 2012", "start_pos": 43, "end_pos": 55, "type": "DATASET", "confidence": 0.814995139837265}]}, {"text": "We observe that the complete algorithm (coreferences, named entity labels and MDP) provides the best results on PER NE links.", "labels": [], "entities": []}, {"text": "On GPE and ORG entities, the simple application of MDP without prior corrections obtains the best results.", "labels": [], "entities": [{"text": "GPE", "start_pos": 3, "end_pos": 6, "type": "DATASET", "confidence": 0.8309023976325989}]}, {"text": "A slight loss of accuracy is observed on ORG NEs when the MDP is applied with corrections.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 17, "end_pos": 25, "type": "METRIC", "confidence": 0.9993627667427063}, {"text": "ORG NEs", "start_pos": 41, "end_pos": 48, "type": "TASK", "confidence": 0.5519893765449524}]}, {"text": "For those three categories of entities, we show that the complete system improves the performance of a simple algorithm using distance measures.", "labels": [], "entities": []}, {"text": "Results on categories News and Web show that the best performance on the whole KBP corpus (without distinction of NE categories) is obtained with the complete algorithm.", "labels": [], "entities": [{"text": "KBP corpus", "start_pos": 79, "end_pos": 89, "type": "DATASET", "confidence": 0.8981689214706421}]}], "tableCaptions": [{"text": " Table 1: SemLinker results on the TAC-KBP 2012 test corpus with/out disambiguation modules, and  three best results and median from TAC-KBP 2012 systems.", "labels": [], "entities": [{"text": "TAC-KBP 2012 test corpus", "start_pos": 35, "end_pos": 59, "type": "DATASET", "confidence": 0.9376094490289688}]}, {"text": " Table 2: Breakdown of the TAC-KBP 2012 test  corpus queries according to entity types, and doc- ument categories.", "labels": [], "entities": [{"text": "TAC-KBP 2012 test  corpus queries", "start_pos": 27, "end_pos": 60, "type": "DATASET", "confidence": 0.9202719807624817}]}]}