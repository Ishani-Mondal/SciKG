{"title": [{"text": "Transforming trees into hedges and parsing with \"hedgebank\" grammars", "labels": [], "entities": [{"text": "Transforming trees into hedges", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.8752776831388474}]}], "abstractContent": [{"text": "Finite-state chunking and tagging methods are very fast for annotating non-hierarchical syntactic information, and are often applied in applications that do not require full syntactic analyses.", "labels": [], "entities": [{"text": "Finite-state chunking", "start_pos": 0, "end_pos": 21, "type": "TASK", "confidence": 0.6332754045724869}]}, {"text": "Scenarios such as incremental machine translation may benefit from some degree of hierarchical syntactic analysis without requiring fully connected parses.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 30, "end_pos": 49, "type": "TASK", "confidence": 0.7409578263759613}]}, {"text": "We introduce hedge parsing as an approach to recovering constituents of length up to some maximum span L.", "labels": [], "entities": [{"text": "hedge parsing", "start_pos": 13, "end_pos": 26, "type": "TASK", "confidence": 0.8197832405567169}]}, {"text": "This approach improves efficiency by bounding constituent size, and allows for efficient segmentation strategies prior to parsing.", "labels": [], "entities": []}, {"text": "Unlike shallow parsing methods, hedge parsing yields internal hierarchical structure of phrases within its span bound.", "labels": [], "entities": [{"text": "hedge parsing", "start_pos": 32, "end_pos": 45, "type": "TASK", "confidence": 0.7629204094409943}]}, {"text": "We present the approach and some initial experiments on different inference strategies.", "labels": [], "entities": []}], "introductionContent": [{"text": "Parsing full hierarchical syntactic structures is costly, and some NLP applications that could benefit from parses instead substitute shallow proxies such as NP chunks.", "labels": [], "entities": [{"text": "Parsing full hierarchical syntactic structures", "start_pos": 0, "end_pos": 46, "type": "TASK", "confidence": 0.8455993294715881}]}, {"text": "Models to derive such non-hierarchical annotations are finite-state, so inference is very fast.", "labels": [], "entities": []}, {"text": "Still, these partial annotations omit all but the most basic syntactic segmentation, ignoring the abundant local structure that could be of utility even in the absence of fully connected structures.", "labels": [], "entities": []}, {"text": "For example, in incremental (simultaneous) machine translation (), sub-sentential segments are translated independently and sequentially, hence the fully-connected syntactic structure is not generally available.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 43, "end_pos": 62, "type": "TASK", "confidence": 0.7314658761024475}]}, {"text": "Even so, locally-connected source language parse structures can inform both segmentation and translation of each segment in such a translation scenario.", "labels": [], "entities": []}, {"text": "One way to provide local hierarchical syntactic structures without fully connected trees is to focus on providing full hierarchical annotations for structures within a local window, ignoring global constituents outside that window.", "labels": [], "entities": []}, {"text": "We follow the XML community in naming structures of this type hedges (not to be confused with the rhetorical device of the same name), due to the fact that they are like smaller versions of trees which occur in sequences.", "labels": [], "entities": []}, {"text": "Such structures maybe of utility to various structured inference tasks, as well as within a full parsing pipeline, to quickly constrain subsequent inference, much as finite-state models such as supertagging) or chart cell constraints) are used.", "labels": [], "entities": []}, {"text": "In this paper, we consider the problem of hedge parsing, i.e., discovering every constituent of length up to some span L.", "labels": [], "entities": [{"text": "hedge parsing", "start_pos": 42, "end_pos": 55, "type": "TASK", "confidence": 0.7308894097805023}]}, {"text": "Similar constraints have been used in dependency parsing), where the use of hard constraints on the distance between heads and dependents is known as vine parsing.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 38, "end_pos": 56, "type": "TASK", "confidence": 0.8347563147544861}]}, {"text": "It is also reminiscent of so-called Semi-Markov models (), which allow finite-state models to reason about segments rather than just tags by imposing segment length limits.", "labels": [], "entities": []}, {"text": "In the XML community, trees and hedges are used for models of XML document instances and for the contents of elements).", "labels": [], "entities": []}, {"text": "As far as we know, this paper is the first to consider this sort of partial parsing approach for natural language.", "labels": [], "entities": [{"text": "partial parsing", "start_pos": 68, "end_pos": 83, "type": "TASK", "confidence": 0.6837051510810852}]}, {"text": "We pursue this topic via tree transformation, whereby non-root non-terminals labeling constituents of span > Lin the tree are recursively elided and their children promoted to attach to their parent.", "labels": [], "entities": [{"text": "tree transformation", "start_pos": 25, "end_pos": 44, "type": "TASK", "confidence": 0.7784935534000397}]}, {"text": "In such away, hedges are sequentially connected to the top-most non-terminal in the tree, as demonstrated in.", "labels": [], "entities": []}, {"text": "After applying such a transform to a treebank, we can induce grammars and modify parsing to search as needed to recover just these constituents.", "labels": [], "entities": []}, {"text": "In this paper, we propose several methods to parse hedge constituents and examine their accuracy/efficiency tradeoffs.", "labels": [], "entities": [{"text": "parse hedge constituents", "start_pos": 45, "end_pos": 69, "type": "TASK", "confidence": 0.8865664800008138}, {"text": "accuracy", "start_pos": 88, "end_pos": 96, "type": "METRIC", "confidence": 0.9981012940406799}]}, {"text": "This is compared with a baseline of parsing with a typically induced context-free grammar and transforming the result via the hedge transform, which provides a ceiling on accuracy and a floor on efficiency.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 171, "end_pos": 179, "type": "METRIC", "confidence": 0.9992477893829346}]}, {"text": "We investigate pre-segmenting the sentences with a finitestate model prior to hedge parsing, and achieve large speedups relative to hedge parsing the whole string, though at a loss inaccuracy due to cascading segmentation errors.", "labels": [], "entities": [{"text": "hedge parsing", "start_pos": 78, "end_pos": 91, "type": "TASK", "confidence": 0.6858007162809372}]}, {"text": "In all cases, we find it crucial that our \"hedgebank\" grammars be retrained to match the conditions during inference.", "labels": [], "entities": []}], "datasetContent": [{"text": "We ran all experiments on the WSJ Penn Treebank corpus) using section 2-21 for training, section 24 for development, and section 23 for testing.", "labels": [], "entities": [{"text": "WSJ Penn Treebank corpus", "start_pos": 30, "end_pos": 54, "type": "DATASET", "confidence": 0.9399943351745605}]}, {"text": "We performed exhaustive CYK parsing using the BUBS parser 2 (Bodenstab et al., 2011) with Berkeley SM6 latent-variable grammars) learned by the Berkeley grammar trainer with default settings.", "labels": [], "entities": [{"text": "CYK parsing", "start_pos": 24, "end_pos": 35, "type": "TASK", "confidence": 0.6887584626674652}, {"text": "BUBS", "start_pos": 46, "end_pos": 50, "type": "DATASET", "confidence": 0.8851442933082581}]}, {"text": "We compute accuracy from the 1-best Viterbi tree extracted from the chart using the standard EVALB script.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 11, "end_pos": 19, "type": "METRIC", "confidence": 0.9994426369667053}, {"text": "EVALB script", "start_pos": 93, "end_pos": 105, "type": "DATASET", "confidence": 0.8592374622821808}]}, {"text": "Accuracy results are reported as precision, recall and F1-score, the harmonic mean between the two.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 0, "end_pos": 8, "type": "METRIC", "confidence": 0.9817682504653931}, {"text": "precision", "start_pos": 33, "end_pos": 42, "type": "METRIC", "confidence": 0.9998072981834412}, {"text": "recall", "start_pos": 44, "end_pos": 50, "type": "METRIC", "confidence": 0.9995675683021545}, {"text": "F1-score", "start_pos": 55, "end_pos": 63, "type": "METRIC", "confidence": 0.9994749426841736}]}, {"text": "In all trials, we evaluate accuracy with respect to the hedge transformed reference Rare words occur less than 5 times in the training data.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 27, "end_pos": 35, "type": "METRIC", "confidence": 0.9995415210723877}]}, {"text": "treebank, i.e., we are not penalizing the parser for not discovering constituents longer than the maximum length.", "labels": [], "entities": []}, {"text": "Segmentation accuracy is reported as an F1-score of unlabeled segment bracketing.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 13, "end_pos": 21, "type": "METRIC", "confidence": 0.9722803235054016}, {"text": "F1-score", "start_pos": 40, "end_pos": 48, "type": "METRIC", "confidence": 0.9992117881774902}]}, {"text": "We ran timing tests on an Intel 2.66GHz processor with 3MB of cache and 2GB of memory.", "labels": [], "entities": []}, {"text": "Note that segmentation time is negligible compared to the parsing time, hence is omitted in reported time.", "labels": [], "entities": [{"text": "segmentation", "start_pos": 10, "end_pos": 22, "type": "TASK", "confidence": 0.9480583667755127}, {"text": "parsing", "start_pos": 58, "end_pos": 65, "type": "TASK", "confidence": 0.9576819539070129}]}, {"text": "Efficiency results are reported as number of words parsed per second (w/s).", "labels": [], "entities": [{"text": "Efficiency", "start_pos": 0, "end_pos": 10, "type": "METRIC", "confidence": 0.9890244603157043}]}, {"text": "presents hedge parsing accuracy on the development set for the full parsing baseline, where the output of regular PCFG parsing is transformed to hedges and evaluated, versus parsing with a hedgebank grammar, with no segmentation of the strings.", "labels": [], "entities": [{"text": "hedge parsing", "start_pos": 9, "end_pos": 22, "type": "TASK", "confidence": 0.7395200431346893}, {"text": "accuracy", "start_pos": 23, "end_pos": 31, "type": "METRIC", "confidence": 0.9705520868301392}, {"text": "PCFG parsing", "start_pos": 114, "end_pos": 126, "type": "TASK", "confidence": 0.766319751739502}]}, {"text": "We find an order of magnitude speedup of parsing, but at the cost of 3 percent Fmeasure absolute.", "labels": [], "entities": [{"text": "parsing", "start_pos": 41, "end_pos": 48, "type": "TASK", "confidence": 0.9868276119232178}, {"text": "Fmeasure absolute", "start_pos": 79, "end_pos": 96, "type": "METRIC", "confidence": 0.9772860407829285}]}, {"text": "Note that most of that loss is in recall, indicating that hedges predicted in that condition are nearly as reliable as in full parsing.", "labels": [], "entities": [{"text": "recall", "start_pos": 34, "end_pos": 40, "type": "METRIC", "confidence": 0.9977450966835022}]}, {"text": "shows the results on the development set when segmenting prior to hedge parsing.", "labels": [], "entities": [{"text": "hedge parsing", "start_pos": 66, "end_pos": 79, "type": "TASK", "confidence": 0.5982632786035538}]}, {"text": "The first row shows the result with no segmentation, the same as the last row in for ease of reference.", "labels": [], "entities": []}, {"text": "The next row shows behavior with perfect segmentation.", "labels": [], "entities": []}, {"text": "The final two rows show performance with automatic segmentation, using a model that includes either unlabeled or labeled segmentation tags, as described in the last section.", "labels": [], "entities": []}, {"text": "Segmentation accuracy is better for the model with labels, although overall that accuracy is rather low.", "labels": [], "entities": [{"text": "Segmentation", "start_pos": 0, "end_pos": 12, "type": "METRIC", "confidence": 0.936174750328064}, {"text": "accuracy", "start_pos": 13, "end_pos": 21, "type": "METRIC", "confidence": 0.8622944951057434}, {"text": "accuracy", "start_pos": 81, "end_pos": 89, "type": "METRIC", "confidence": 0.9994053840637207}]}, {"text": "We achieve nearly another order of magnitude speedup over hedge parsing without segmentation, but again at the cost of nearly 5 percent F1.", "labels": [], "entities": [{"text": "hedge parsing", "start_pos": 58, "end_pos": 71, "type": "TASK", "confidence": 0.681157261133194}, {"text": "F1", "start_pos": 136, "end_pos": 138, "type": "METRIC", "confidence": 0.9985476136207581}]}, {"text": "presents results of our best configurations on the eval set, section 23.", "labels": [], "entities": []}, {"text": "The results show the same patterns as on the development set.", "labels": [], "entities": []}, {"text": "Finally, shows the speed of inference, la-   beled precision and labeled recall of annotating hedge constituents on the test set as a function of the maximum span parameter L, versus the baseline parser.", "labels": [], "entities": [{"text": "precision", "start_pos": 51, "end_pos": 60, "type": "METRIC", "confidence": 0.969512403011322}, {"text": "recall", "start_pos": 73, "end_pos": 79, "type": "METRIC", "confidence": 0.942328155040741}]}, {"text": "Keep in mind that the number of reference constituents increases as L increases, hence both precision and recall can decrease as the parameter grows.", "labels": [], "entities": [{"text": "precision", "start_pos": 92, "end_pos": 101, "type": "METRIC", "confidence": 0.9995449185371399}, {"text": "recall", "start_pos": 106, "end_pos": 112, "type": "METRIC", "confidence": 0.9992281198501587}]}, {"text": "Segmentation achieves large speedups for smaller L values, but the accuracy degradation is consistent, pointing to the need for improved segmentation.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 67, "end_pos": 75, "type": "METRIC", "confidence": 0.9990612864494324}]}], "tableCaptions": [{"text": " Table 1: Hedge parsing results on section 24 for L = 7.", "labels": [], "entities": [{"text": "Hedge parsing", "start_pos": 10, "end_pos": 23, "type": "TASK", "confidence": 0.9505100548267365}]}, {"text": " Table 2: Hedge segmentation and parsing results on section", "labels": [], "entities": [{"text": "Hedge segmentation", "start_pos": 10, "end_pos": 28, "type": "TASK", "confidence": 0.9514245092868805}]}, {"text": " Table 3: Hedge segmentation and parsing results on test data, section 23, for L = 7.", "labels": [], "entities": [{"text": "Hedge segmentation", "start_pos": 10, "end_pos": 28, "type": "TASK", "confidence": 0.9545577168464661}]}]}