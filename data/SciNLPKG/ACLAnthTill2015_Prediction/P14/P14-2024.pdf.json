{"title": [{"text": "On the Elements of an Accurate Tree-to-String Machine Translation System", "labels": [], "entities": [{"text": "Accurate Tree-to-String Machine Translation", "start_pos": 22, "end_pos": 65, "type": "TASK", "confidence": 0.6528236269950867}]}], "abstractContent": [{"text": "While tree-to-string (T2S) translation theoretically holds promise for efficient, accurate translation, in previous reports T2S systems have often proven inferior to other machine translation (MT) methods such as phrase-based or hierarchical phrase-based MT.", "labels": [], "entities": [{"text": "tree-to-string (T2S) translation", "start_pos": 6, "end_pos": 38, "type": "TASK", "confidence": 0.7559287786483765}, {"text": "machine translation (MT)", "start_pos": 172, "end_pos": 196, "type": "TASK", "confidence": 0.861255431175232}]}, {"text": "In this paper, we attempt to clarify the reason for this performance gap by investigating a number of peripheral elements that affect the accuracy of T2S systems , including parsing, alignment, and search.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 138, "end_pos": 146, "type": "METRIC", "confidence": 0.9977520108222961}, {"text": "parsing", "start_pos": 174, "end_pos": 181, "type": "TASK", "confidence": 0.979199230670929}, {"text": "alignment", "start_pos": 183, "end_pos": 192, "type": "TASK", "confidence": 0.8757728934288025}]}, {"text": "Based on detailed experiments on the English-Japanese and Japanese-English pairs, we show how a basic T2S system that performs on par with phrase-based systems can be improved by 2.6-4.6 BLEU, greatly exceeding existing state-of-the-art methods.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 187, "end_pos": 191, "type": "METRIC", "confidence": 0.9986739158630371}]}, {"text": "These results indicate that T2S systems indeed hold much promise, but the above-mentioned elements must betaken seriously in construction of these systems.", "labels": [], "entities": []}], "introductionContent": [{"text": "In recent years, syntactic parsing is being viewed as an ever-more important element of statistical machine translation (SMT) systems, particularly for translation between languages with large differences in word order.", "labels": [], "entities": [{"text": "syntactic parsing", "start_pos": 17, "end_pos": 34, "type": "TASK", "confidence": 0.7636589109897614}, {"text": "statistical machine translation (SMT)", "start_pos": 88, "end_pos": 125, "type": "TASK", "confidence": 0.7803468803564707}]}, {"text": "There are many ways of incorporating syntax into MT systems, including the use of string-to-tree translation (S2T) to ensure the syntactic well-formedness of the output (, tree-to-string (T2S) using source-side parsing as a hint during the translation process (), or preor post-ordering to help compensate for reordering problems experienced by non-syntactic methods such as phrase-based MT (PBMT)).", "labels": [], "entities": [{"text": "MT", "start_pos": 49, "end_pos": 51, "type": "TASK", "confidence": 0.9746605753898621}]}, {"text": "Among these, T2S translation has a number of attractive theoretical properties, such as joint consideration of global reordering and lexical choice while maintaining relatively fast decoding times.", "labels": [], "entities": [{"text": "T2S translation", "start_pos": 13, "end_pos": 28, "type": "TASK", "confidence": 0.845753401517868}]}, {"text": "However, building an accurate T2S system is not trivial.", "labels": [], "entities": []}, {"text": "On one hand, there have been multiple reports (mainly from groups with along history of building T2S systems) stating that systems using source-side syntax greatly out-perform phrasebased systems ().", "labels": [], "entities": []}, {"text": "On the other hand, there have been also been multiple reports noting the exact opposite result that sourceside syntax systems perform worse than Hiero, S2T, PBMT, or PBMT with pre-ordering (.", "labels": [], "entities": [{"text": "Hiero", "start_pos": 145, "end_pos": 150, "type": "DATASET", "confidence": 0.9106518626213074}]}, {"text": "In this paper, we argue that this is due to the fact that T2S systems have the potential to achieve high accuracy, but are also less robust, with a number of peripheral elements having a large effect on translation accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 105, "end_pos": 113, "type": "METRIC", "confidence": 0.9972997307777405}, {"text": "translation", "start_pos": 203, "end_pos": 214, "type": "TASK", "confidence": 0.9271551966667175}, {"text": "accuracy", "start_pos": 215, "end_pos": 223, "type": "METRIC", "confidence": 0.79889976978302}]}, {"text": "Our motivation in writing this paper is to provide a first step in examining and codifying the more important elements that make it possible to construct a highly accurate T2S MT system.", "labels": [], "entities": [{"text": "T2S MT", "start_pos": 172, "end_pos": 178, "type": "TASK", "confidence": 0.5922701954841614}]}, {"text": "To do so, we perform an empirical study of the effect of parsing accuracy, packed forest input, alignment accuracy, and search.", "labels": [], "entities": [{"text": "parsing", "start_pos": 57, "end_pos": 64, "type": "TASK", "confidence": 0.9865652918815613}, {"text": "accuracy", "start_pos": 65, "end_pos": 73, "type": "METRIC", "confidence": 0.9008176922798157}, {"text": "alignment", "start_pos": 96, "end_pos": 105, "type": "TASK", "confidence": 0.9247203469276428}, {"text": "accuracy", "start_pos": 106, "end_pos": 114, "type": "METRIC", "confidence": 0.8432808518409729}]}, {"text": "The reason why we choose these elements is that past work that has reported low accuracy for T2S systems has often neglected to consider one or all of these elements.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 80, "end_pos": 88, "type": "METRIC", "confidence": 0.9984539747238159}]}, {"text": "As a result of our tests on English-Japanese (enja) and Japanese-English (ja-en) machine translation, we find that a T2S system not considering these elements performs only slightly better than a standard PBMT system.", "labels": [], "entities": [{"text": "Japanese-English (ja-en) machine translation", "start_pos": 56, "end_pos": 100, "type": "TASK", "confidence": 0.6555660913387934}]}, {"text": "However, after accounting for all these elements we see large increases of accuracy, with the final system greatly exceeding not only standard PBMT, but also state-of-the-art methods based on syntactic pre-or post-ordering.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 75, "end_pos": 83, "type": "METRIC", "confidence": 0.9994237422943115}]}], "datasetContent": [{"text": "We perform all of our experiments on en-ja and ja-en translation over data from the NTCIR PatentMT task), the most standard benchmark task for these language pairs.", "labels": [], "entities": [{"text": "NTCIR", "start_pos": 84, "end_pos": 89, "type": "DATASET", "confidence": 0.7300004959106445}, {"text": "PatentMT", "start_pos": 90, "end_pos": 98, "type": "METRIC", "confidence": 0.5295823812484741}]}, {"text": "We use the training data from NTCIR 7/8, a total of approximately 3.0M sentences, and perform tuning on the NTCIR 7 dry run, testing on the NTCIR 7 formal run data.", "labels": [], "entities": [{"text": "NTCIR 7/8", "start_pos": 30, "end_pos": 39, "type": "DATASET", "confidence": 0.9606599509716034}, {"text": "NTCIR 7 dry run", "start_pos": 108, "end_pos": 123, "type": "DATASET", "confidence": 0.9359593391418457}, {"text": "NTCIR 7 formal run data", "start_pos": 140, "end_pos": 163, "type": "DATASET", "confidence": 0.950258731842041}]}, {"text": "As evaluation measures, we use the standard BLEU () as well as RIBES (), a reorderingbased metric that has been shown to have high correlation with human evaluations on the NTCIR data.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 44, "end_pos": 48, "type": "METRIC", "confidence": 0.9988441467285156}, {"text": "RIBES", "start_pos": 63, "end_pos": 68, "type": "METRIC", "confidence": 0.995629072189331}, {"text": "NTCIR data", "start_pos": 173, "end_pos": 183, "type": "DATASET", "confidence": 0.9645968079566956}]}, {"text": "We measure significance of results using bootstrap resampling at p < 0.05).", "labels": [], "entities": []}, {"text": "In tables, bold numbers indicate the best system and all systems that were not significantly different from the best system.", "labels": [], "entities": []}, {"text": "Before going into a detailed analysis, we first present results that stress the importance of the elements described in the introduction.", "labels": [], "entities": []}, {"text": "To do so, we compare the 3 non-T2S baselines with two T2S systems that vary the settings of the parser, alignment, and search, as described in the following Sections 3, 4, and 5.", "labels": [], "entities": []}, {"text": "The first system \"T2S-all\" is a system that uses the worst settings 1 for each of these elements, while the second system \"T2S+all\" uses the best settings.", "labels": [], "entities": []}, {"text": "The results for the systems are shown in.", "labels": [], "entities": []}, {"text": "The most striking result is that T2S+all significantly exceeds all of the baselines, even including the pre/post-ordering baselines, which provide state-of-the-art results on this task.", "labels": [], "entities": []}, {"text": "The gains are particularly striking on en-ja, with again of over 4 BLEU points over the closest system, but still significant on the ja-en task, where the use of sourceside syntax has proven less effective in previous work).", "labels": [], "entities": [{"text": "BLEU", "start_pos": 67, "end_pos": 71, "type": "METRIC", "confidence": 0.9990429282188416}]}, {"text": "The next thing to notice is that if we had instead used T2S-all, our conclusion would have been much different.", "labels": [], "entities": []}, {"text": "This system is able to achieve respectable accuracy compared to PBMT or Hiero, but does not exceed the more competitive pre/post-ordering systems.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 43, "end_pos": 51, "type": "METRIC", "confidence": 0.9990116357803345}, {"text": "PBMT", "start_pos": 64, "end_pos": 68, "type": "DATASET", "confidence": 0.8293343186378479}, {"text": "Hiero", "start_pos": 72, "end_pos": 77, "type": "DATASET", "confidence": 0.847087562084198}]}, {"text": "3 With this result in hand, we will investigate the contribution of each of these elements in detail in the following sections.", "labels": [], "entities": []}, {"text": "In the remainder of the paper settings follow T2S+all except when otherwise noted.", "labels": [], "entities": [{"text": "T2S", "start_pos": 46, "end_pos": 49, "type": "METRIC", "confidence": 0.9469473361968994}]}], "tableCaptions": [{"text": " Table 1: Overall results for five systems.", "labels": [], "entities": []}, {"text": " Table 2: Results for Stanford/Eda, Egret with tree  input, and Egret with forest input.", "labels": [], "entities": [{"text": "Stanford/Eda", "start_pos": 22, "end_pos": 34, "type": "DATASET", "confidence": 0.8879107236862183}]}, {"text": " Table 3: Alignment accuracy (%) by method and  number of manually annotated training sentences.", "labels": [], "entities": [{"text": "Alignment", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.5706652402877808}, {"text": "accuracy", "start_pos": 20, "end_pos": 28, "type": "METRIC", "confidence": 0.9221871495246887}]}, {"text": " Table 4: Results varying the aligner (GIZA++ vs.  Nile), including results for Nile when using 1/4 or  1/16 of the annotated training data.", "labels": [], "entities": [{"text": "GIZA", "start_pos": 39, "end_pos": 43, "type": "METRIC", "confidence": 0.9442533254623413}]}]}