{"title": [{"text": "Biases in Predicting the Human Language Model", "labels": [], "entities": [{"text": "Predicting the Human Language", "start_pos": 10, "end_pos": 39, "type": "TASK", "confidence": 0.8393629938364029}]}], "abstractContent": [{"text": "We consider the prediction of three human behavioral measures-lexical decision , word naming, and picture naming-through the lens of domain bias in language modeling.", "labels": [], "entities": [{"text": "word naming", "start_pos": 81, "end_pos": 92, "type": "TASK", "confidence": 0.8016275763511658}, {"text": "picture naming-through", "start_pos": 98, "end_pos": 120, "type": "TASK", "confidence": 0.7136130183935165}]}, {"text": "Contrasting the predic-tive ability of statistics derived from 6 different corpora, we find intuitive results showing that, e.g., a British corpus over-predicts the speed with which an Amer-ican will react to the words ward and duke, and that the Google n-grams over-predicts familiarity with technology terms.", "labels": [], "entities": [{"text": "British corpus", "start_pos": 132, "end_pos": 146, "type": "DATASET", "confidence": 0.9060419797897339}]}, {"text": "This study aims to provoke increased consideration of the human language model by NLP practitioners: biases are not limited to differences between corpora (i.e. \"train\" vs. \"test\"); they can exist as well between corpora and the intended user of the resultant technology.", "labels": [], "entities": []}], "introductionContent": [{"text": "Computational linguists build statistical language models for aiding in natural language processing (NLP) tasks.", "labels": [], "entities": [{"text": "natural language processing (NLP) tasks", "start_pos": 72, "end_pos": 111, "type": "TASK", "confidence": 0.7572931562151227}]}, {"text": "Computational psycholinguists build such models to aid in their study of human language processing.", "labels": [], "entities": [{"text": "human language processing", "start_pos": 73, "end_pos": 98, "type": "TASK", "confidence": 0.6750996907552084}]}, {"text": "Errors in NLP are measured with tools like precision and recall, while errors in psycholinguistics are defined as failures to model a target phenomenon.", "labels": [], "entities": [{"text": "precision", "start_pos": 43, "end_pos": 52, "type": "METRIC", "confidence": 0.9993519186973572}, {"text": "recall", "start_pos": 57, "end_pos": 63, "type": "METRIC", "confidence": 0.9991558790206909}]}, {"text": "In the current study, we exploit errors of the latter variety-failure of a language model to predict human performance-to investigate bias across several frequently used corpora in computational linguistics.", "labels": [], "entities": []}, {"text": "The human data is revealing because it trades on the fact that human language processing is probability-sensitive: language processing reflects implicit knowledge of probabilities computed over linguistic units (e.g., words).", "labels": [], "entities": []}, {"text": "For example, the amount of time required to read a word varies as a function of how predictable that word is.", "labels": [], "entities": []}, {"text": "Thus, failure of a language model to predict human performance reveals a mismatch between the language model and the human language model, i.e., bias.", "labels": [], "entities": []}, {"text": "Psycholinguists have known for sometime that the ability of a corpus to explain behavior depends on properties of the corpus and the subjects (cf.).", "labels": [], "entities": []}, {"text": "We extend that line of work by directly analyzing and quantifying this bias, and by linking the results to methodological concerns in both NLP and psycholinguistics.", "labels": [], "entities": []}, {"text": "Specifically, we predict human data from three widely used psycholinguistic experimental paradigms-lexical decision, word naming, and picture naming-using unigram frequency estimates from Google n-grams (),), spoken and written English portions of CELEX (, and spoken and written portions of the British National Corpus).", "labels": [], "entities": [{"text": "word naming", "start_pos": 117, "end_pos": 128, "type": "TASK", "confidence": 0.8158949911594391}, {"text": "picture naming-using", "start_pos": 134, "end_pos": 154, "type": "TASK", "confidence": 0.7020724266767502}, {"text": "CELEX", "start_pos": 248, "end_pos": 253, "type": "DATASET", "confidence": 0.9527061581611633}, {"text": "British National Corpus", "start_pos": 296, "end_pos": 319, "type": "DATASET", "confidence": 0.9416104157765707}]}, {"text": "While we find comparable overall fits of the behavioral data from all corpora under consideration, our analyses also reveal specific domain biases.", "labels": [], "entities": []}, {"text": "For example, Google ngrams overestimates the ease with which humans will process words related to the web (tech, code, search, site), while the Switchboard corpus-a collection of informal telephone conversations between strangers-overestimates how quickly humans will react to colloquialisms (heck, darn) and backchannels (wow, right).", "labels": [], "entities": [{"text": "Switchboard corpus-a collection of informal telephone conversations between strangers-overestimates how quickly humans will react to colloquialisms (heck, darn) and backchannels (wow", "start_pos": 144, "end_pos": 326, "type": "Description", "confidence": 0.8400488948822021}]}], "datasetContent": [], "tableCaptions": []}