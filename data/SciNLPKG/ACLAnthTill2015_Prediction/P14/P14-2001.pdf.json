{"title": [{"text": "Exploring the Relative Role of Bottom-up and Top-down Information in Phoneme Learning", "labels": [], "entities": [{"text": "Phoneme Learning", "start_pos": 69, "end_pos": 85, "type": "TASK", "confidence": 0.8869639337062836}]}], "abstractContent": [{"text": "We test both bottom-up and top-down approaches in learning the phonemic status of the sounds of English and Japanese.", "labels": [], "entities": []}, {"text": "We used large corpora of spontaneous speech to provide the learner with an input that models both the linguistic properties and statistical regularities of each language.", "labels": [], "entities": []}, {"text": "We found both approaches to help discriminate between allophonic and phone-mic contrasts with a high degree of accuracy , although top-down cues proved to be effective only on an interesting subset of the data.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 111, "end_pos": 119, "type": "METRIC", "confidence": 0.9987999200820923}]}], "introductionContent": [{"text": "Developmental studies have shown that, during their first year, infants tune in on the phonemic categories (consonants and vowels) of their language, i.e., they lose the ability to distinguish some within-category contrasts and enhance their ability to distinguish betweencategory contrasts ().", "labels": [], "entities": []}, {"text": "Current work in early language acquisition has proposed two competing hypotheses that purport to account for the acquisition of phonemes.", "labels": [], "entities": [{"text": "early language acquisition", "start_pos": 16, "end_pos": 42, "type": "TASK", "confidence": 0.6859398583571116}]}, {"text": "The bottom-up hypothesis holds that infants converge on the linguistic units of their language through a similaritybased distributional analysis of their input.", "labels": [], "entities": []}, {"text": "In contrast, the top-down hypothesis emphasizes the role of higher level linguistic structures in order to learn the lower level units.", "labels": [], "entities": []}, {"text": "The aim of the present work is to explore how much information can ideally be derived from both hypotheses.", "labels": [], "entities": []}, {"text": "The paper is organized as follows.", "labels": [], "entities": []}, {"text": "First we describe how we modeled phonetic variation from audio recordings, second we introduce a bottomup cue based on acoustic similarity and topdown cues based of the properties of the lexicon.", "labels": [], "entities": []}, {"text": "We test their performance in a task that consists in discriminating within-category contrasts from between-category contrasts.", "labels": [], "entities": []}, {"text": "Finally we discuss the role and scope of each cue for the acquisition of phonemes.", "labels": [], "entities": []}], "datasetContent": [{"text": "We use the same evaluation procedure as in.", "labels": [], "entities": []}, {"text": "It is carried out by computing the area under the curve of the Receiver Operating Characteristic (ROC).", "labels": [], "entities": [{"text": "Receiver Operating Characteristic (ROC)", "start_pos": 63, "end_pos": 102, "type": "TASK", "confidence": 0.5471610079209009}]}, {"text": "A value of 0.5 represents chance and a value of 1 represents perfect performance.", "labels": [], "entities": [{"text": "chance", "start_pos": 26, "end_pos": 32, "type": "METRIC", "confidence": 0.9812760353088379}]}, {"text": "In order to lessen the potential influence of the structure of the corpus (mainly the order of the utterances) on the results, we use a statistical resampling scheme.", "labels": [], "entities": []}, {"text": "The corpus is divided into small blocks (of 20 utterances each).", "labels": [], "entities": []}, {"text": "In each run, we draw randomly with replacement from this set of blocks a sample of the same size as the original corpus.", "labels": [], "entities": []}, {"text": "This sample is then used to retrain the acoustic models and generate a phonetic inventory that we use to re-transcribe the corpus and re-compute the cues.", "labels": [], "entities": []}, {"text": "We report scores averaged over 5 such runs.", "labels": [], "entities": []}, {"text": "shows the classification scores for the lexical cues when we vary the inventory size from 2 allophones per phoneme in average, to 20 allophones per phoneme, using the Random allophones.", "labels": [], "entities": []}, {"text": "The top-down scores are very high, replicating Martin et al.'s results, and even improving the performance using Boruta's cue and our new Normalized cue.", "labels": [], "entities": []}, {"text": "shows the results for HMM-based allophones.", "labels": [], "entities": []}, {"text": "The acoustic score is very accurate for both languages and is quite robust to variation.", "labels": [], "entities": []}, {"text": "Top-down cues, on the other hand, perform, surprisingly, almost at chance level in distinguishing between allophonic and non-allophonic pairs.", "labels": [], "entities": []}, {"text": "A similar discrepancy for the case of Japanese was actually noted, but not explained, in Boruta (2012).", "labels": [], "entities": [{"text": "Boruta", "start_pos": 89, "end_pos": 95, "type": "METRIC", "confidence": 0.8325161337852478}]}, {"text": ", and yet others will simply not generate lexical variation at all, we will call those: invisible pairs.", "labels": [], "entities": []}, {"text": "For instance, in English, /h/ and /N/ occur in different syllable positions and thus cannot appear in any minimal pair.", "labels": [], "entities": []}, {"text": "As defined above, top-down cues are set to 0 in such pairs (which means that they are systematically classified as non-allophonic).", "labels": [], "entities": []}, {"text": "This is a correct decision for /h/ vs. /N/, but not for invisible pairs that also happen to be allophonic, resulting in false negatives.", "labels": [], "entities": []}, {"text": "In tables 3, we show that, indeed, invisible pairs is a major issue, and could explain to a large extent the pattern of results found above.", "labels": [], "entities": []}, {"text": "In fact, the proportion of visible allophonic pairs (\"allo\" column) is way lower for HMM-based allophones.", "labels": [], "entities": []}, {"text": "This means that the majority of allophonic pairs in the HMM case are invisible, and therefore, will be mistakenly classified as non-allophonic.", "labels": [], "entities": []}, {"text": "There are basically two reasons why an allophonic pair would be invisible ( will not generate lexical alternants).", "labels": [], "entities": []}, {"text": "The first one is the absence of evidence, e.g., if the edges of the word with the underlying phoneme do not appear in enough contexts to generate the corresponding variants.", "labels": [], "entities": []}, {"text": "This happens when the corpus is so small that no word ending with, say, /r/ appears in both voiced and voiceless contexts.", "labels": [], "entities": []}, {"text": "The second, is when the allophones are triggered on maximally different contexts (on the right and the left) as illustrated below:", "labels": [], "entities": []}], "tableCaptions": []}