{"title": [{"text": "Detection of Topic and its Extrinsic Evaluation Through Multi-Document Summarization", "labels": [], "entities": [{"text": "Detection of Topic", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.8792087634404501}, {"text": "Extrinsic Evaluation", "start_pos": 27, "end_pos": 47, "type": "TASK", "confidence": 0.691109910607338}, {"text": "Multi-Document Summarization", "start_pos": 56, "end_pos": 84, "type": "TASK", "confidence": 0.6975136548280716}]}], "abstractContent": [{"text": "This paper presents a method for detecting words related to a topic (we call them topic words) overtime in the stream of documents.", "labels": [], "entities": []}, {"text": "Topic words are widely distributed in the stream of documents, and sometimes they frequently appear in the documents, and sometimes not.", "labels": [], "entities": []}, {"text": "We propose a method to reinforce topic words with low frequencies by collecting documents from the corpus, and applied Latent Dirichlet Allocation (Blei et al., 2003) to these documents.", "labels": [], "entities": [{"text": "Latent Dirichlet Allocation", "start_pos": 119, "end_pos": 146, "type": "METRIC", "confidence": 0.9029207229614258}]}, {"text": "For the results of LDA, we identified topic words by using Moving Average Convergence Divergence.", "labels": [], "entities": [{"text": "LDA", "start_pos": 19, "end_pos": 22, "type": "TASK", "confidence": 0.7606788873672485}, {"text": "Moving Average Convergence Divergence", "start_pos": 59, "end_pos": 96, "type": "METRIC", "confidence": 0.8014350235462189}]}, {"text": "In order to evaluate the method, we applied the results of topic detection to extractive multi-document summarization.", "labels": [], "entities": [{"text": "topic detection", "start_pos": 59, "end_pos": 74, "type": "TASK", "confidence": 0.8175925016403198}]}, {"text": "The results showed that the method was effective for sentence selection in summarization.", "labels": [], "entities": [{"text": "sentence selection", "start_pos": 53, "end_pos": 71, "type": "TASK", "confidence": 0.8421946465969086}, {"text": "summarization", "start_pos": 75, "end_pos": 88, "type": "TASK", "confidence": 0.964638352394104}]}], "introductionContent": [{"text": "As the volume of online documents has drastically increased, the analysis of topic bursts, topic drift or detection of topic is a practical problem attracting more and more attention.", "labels": [], "entities": [{"text": "analysis of topic bursts", "start_pos": 65, "end_pos": 89, "type": "TASK", "confidence": 0.7605345696210861}]}, {"text": "The earliest known approach is the work of Klinkenberg and Joachims).", "labels": [], "entities": []}, {"text": "They have attempted to handle concept changes by focusing a window with documents sufficiently close to the target concept.", "labels": [], "entities": []}, {"text": "Mane et. al. proposed a method to generate maps that support the identification of major research topics and trends ().", "labels": [], "entities": [{"text": "identification of major research topics", "start_pos": 65, "end_pos": 104, "type": "TASK", "confidence": 0.7784889817237854}]}, {"text": "The method used Kleinberg's burst detection algorithm, co-occurrences of words, and graph layout technique.", "labels": [], "entities": [{"text": "burst detection", "start_pos": 28, "end_pos": 43, "type": "TASK", "confidence": 0.6917193084955215}]}, {"text": "have attempted to use different ensembles obtained by training several data streams to detect concept drift.", "labels": [], "entities": []}, {"text": "However the ensemble method itself remains a problem that how to manage several classifiers effectively.", "labels": [], "entities": []}, {"text": "He and Parket attempted to find bursts, periods of elevated occurrence of events as a dynamic phenomenon instead of focusing on arrival rates.", "labels": [], "entities": []}, {"text": "However, the fact that topics are widely distributed in the stream of documents, and sometimes they frequently appear in the documents, and sometimes not often hamper such attempts.", "labels": [], "entities": []}, {"text": "This paper proposes a method for detecting topic overtime in series of documents.", "labels": [], "entities": [{"text": "detecting topic overtime in series of documents", "start_pos": 33, "end_pos": 80, "type": "TASK", "confidence": 0.8826032791818891}]}, {"text": "We reinforced words related to a topic with low frequencies by collecting documents from the corpus, and applied Latent Dirichlet Allocation (LDA) () to these documents in order to extract topic candidates.", "labels": [], "entities": [{"text": "Latent Dirichlet Allocation (LDA)", "start_pos": 113, "end_pos": 146, "type": "METRIC", "confidence": 0.959899773200353}]}, {"text": "For the results of LDA, we applied Moving Average Convergence Divergence (MACD) to find topic words while He et. al., applied it to find bursts.", "labels": [], "entities": [{"text": "Moving Average Convergence Divergence (MACD)", "start_pos": 35, "end_pos": 79, "type": "METRIC", "confidence": 0.8889387335096087}]}, {"text": "The MACD is a technique to analyze stock market trends.", "labels": [], "entities": []}, {"text": "It shows the relationship between two moving averages of prices modeling bursts as intervals of topic dynamics, i.e., positive acceleration.", "labels": [], "entities": []}, {"text": "Fukumoto et. al also applied MACD to find topics.", "labels": [], "entities": [{"text": "MACD", "start_pos": 29, "end_pos": 33, "type": "TASK", "confidence": 0.9586544632911682}]}, {"text": "However, they applied it only to the words with high frequencies in the documents ().", "labels": [], "entities": []}, {"text": "In contrast, we applied it to the topic candidates obtained by LDA.", "labels": [], "entities": [{"text": "LDA", "start_pos": 63, "end_pos": 66, "type": "DATASET", "confidence": 0.8791719675064087}]}, {"text": "We examined our method by extrinsic evaluation, i.e., we applied the results of topic detection to extractive multi-document summarization.", "labels": [], "entities": [{"text": "topic detection", "start_pos": 80, "end_pos": 95, "type": "TASK", "confidence": 0.7808045744895935}]}, {"text": "We assume that a salient sentence includes words related to the target topic, and an event of each documents.", "labels": [], "entities": []}, {"text": "Here, an event is something that occurs at a specific place and time associated with some specific actions().", "labels": [], "entities": []}, {"text": "We identified event words by using the traditional tf * idf method applied to the results of named entities.", "labels": [], "entities": []}, {"text": "Each sentence in documents is represented using a vector of frequency weighted words that can be event or topic words.", "labels": [], "entities": []}, {"text": "We used Markov Random Walk (MRW) to compute the rank scores for the sentences ().", "labels": [], "entities": []}, {"text": "Finally, we selected a certain number of sentences according to the rank score into a summary.", "labels": [], "entities": []}], "datasetContent": [{"text": "We applied the results of topic detection to extractive multi-document summarization task, and examined how the results of topic detection affect the overall performance of the salient sentence selection.", "labels": [], "entities": [{"text": "topic detection", "start_pos": 26, "end_pos": 41, "type": "TASK", "confidence": 0.8752886056900024}, {"text": "extractive multi-document summarization task", "start_pos": 45, "end_pos": 89, "type": "TASK", "confidence": 0.6531019508838654}, {"text": "topic detection", "start_pos": 123, "end_pos": 138, "type": "TASK", "confidence": 0.7221993952989578}]}, {"text": "We used two tasks, Japanese and English summarization tasks, NTCIR-", "labels": [], "entities": [{"text": "Japanese and English summarization tasks", "start_pos": 19, "end_pos": 59, "type": "TASK", "confidence": 0.5526438534259797}, {"text": "NTCIR", "start_pos": 61, "end_pos": 66, "type": "DATASET", "confidence": 0.745824933052063}]}], "tableCaptions": [{"text": " Table 1: Sentence Extraction (NTCIR-3 test data)", "labels": [], "entities": [{"text": "Sentence Extraction", "start_pos": 10, "end_pos": 29, "type": "TASK", "confidence": 0.9661366641521454}, {"text": "NTCIR-3 test data", "start_pos": 31, "end_pos": 48, "type": "DATASET", "confidence": 0.9156885941823324}]}, {"text": " Table 2: Comparative results (DUC2007 test data)", "labels": [], "entities": [{"text": "DUC2007 test data", "start_pos": 31, "end_pos": 48, "type": "DATASET", "confidence": 0.9675752520561218}]}]}