{"title": [{"text": "Automatic Detection of Machine Translated Text and Translation Quality Estimation", "labels": [], "entities": [{"text": "Automatic Detection of Machine Translated Text and Translation Quality Estimation", "start_pos": 0, "end_pos": 81, "type": "TASK", "confidence": 0.8575511068105698}]}], "abstractContent": [{"text": "We show that it is possible to automatically detect machine translated text at sentence level from monolingual corpora, using text classification methods.", "labels": [], "entities": [{"text": "text classification", "start_pos": 126, "end_pos": 145, "type": "TASK", "confidence": 0.7228726446628571}]}, {"text": "We show further that the accuracy with which a learned classifier can detect text as machine translated is strongly correlated with the translation quality of the machine translation system that generated it.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 25, "end_pos": 33, "type": "METRIC", "confidence": 0.9988447427749634}]}, {"text": "Finally , we offer a generic machine translation quality estimation technique based on this approach, which does not require reference sentences.", "labels": [], "entities": [{"text": "machine translation quality estimation", "start_pos": 29, "end_pos": 67, "type": "TASK", "confidence": 0.8038155734539032}]}], "introductionContent": [{"text": "The recent success and proliferation of statistical machine translation (MT) systems raise a number of important questions.", "labels": [], "entities": [{"text": "statistical machine translation (MT)", "start_pos": 40, "end_pos": 76, "type": "TASK", "confidence": 0.811273455619812}]}, {"text": "Prominent among these are how to evaluate the quality of such a system efficiently and how to detect the output of such systems (for example, to avoid using it circularly as input for refining MT systems).", "labels": [], "entities": [{"text": "MT", "start_pos": 193, "end_pos": 195, "type": "TASK", "confidence": 0.924048125743866}]}, {"text": "In this paper, we will answer both these questions.", "labels": [], "entities": []}, {"text": "First, we will show that using style-related linguistic features, such as frequencies of partsof-speech n-grams and function words, it is possible to learn classifiers that distinguish machinetranslated text from human-translated or native English text.", "labels": [], "entities": []}, {"text": "While this is a straightforward and not entirely novel result, our main contribution is to relativize the result.", "labels": [], "entities": []}, {"text": "We will see that the success of such classifiers are strongly correlated with the quality of the underlying machine translation system.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 108, "end_pos": 127, "type": "TASK", "confidence": 0.7183453738689423}]}, {"text": "Specifically, given a corpus consisting of both machine-translated English text (English being the target language) and native English text (not necessarily the reference translation of the machine-translated text), we measure the accuracy of the system in classifying the sentences in the corpus as machine-translated or not.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 231, "end_pos": 239, "type": "METRIC", "confidence": 0.9991632699966431}]}, {"text": "This accuracy will be shown to decrease as the quality of the underlying MT system increases.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 5, "end_pos": 13, "type": "METRIC", "confidence": 0.999451220035553}, {"text": "MT", "start_pos": 73, "end_pos": 75, "type": "TASK", "confidence": 0.9745920300483704}]}, {"text": "In fact, the correlation is strong enough that we propose that this accuracy measure itself can be used as a measure of MT system quality, obviating the need fora reference corpus, as for example is necessary for BLEU ().", "labels": [], "entities": [{"text": "accuracy", "start_pos": 68, "end_pos": 76, "type": "METRIC", "confidence": 0.9975054860115051}, {"text": "MT system", "start_pos": 120, "end_pos": 129, "type": "TASK", "confidence": 0.8884272575378418}, {"text": "BLEU", "start_pos": 213, "end_pos": 217, "type": "METRIC", "confidence": 0.9080477952957153}]}, {"text": "The paper is structured as follows: In the next section, we review previous related work.", "labels": [], "entities": []}, {"text": "In the third section, we describe experiments regarding the detection of machine translation and in the fourth section we discuss the use of detection techniques as a machine translation quality estimation method.", "labels": [], "entities": [{"text": "detection of machine translation", "start_pos": 60, "end_pos": 92, "type": "TASK", "confidence": 0.6616962924599648}, {"text": "machine translation quality estimation", "start_pos": 167, "end_pos": 205, "type": "TASK", "confidence": 0.6962080746889114}]}, {"text": "In the final section we offer conclusions and suggestions for future work.", "labels": [], "entities": []}], "datasetContent": [{"text": "As can be seen in the above experiments, there is a strong correlation between the BLEU score and the MT detection accuracy of our method.", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 83, "end_pos": 93, "type": "METRIC", "confidence": 0.9816155433654785}, {"text": "MT detection", "start_pos": 102, "end_pos": 114, "type": "TASK", "confidence": 0.9032883048057556}, {"text": "accuracy", "start_pos": 115, "end_pos": 123, "type": "METRIC", "confidence": 0.7975493669509888}]}, {"text": "In fact, results are linearly and negatively correlated with BLEU, as can be seen both on commercial systems and our in-house SMT systems.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 61, "end_pos": 65, "type": "METRIC", "confidence": 0.9991039633750916}, {"text": "SMT", "start_pos": 126, "end_pos": 129, "type": "TASK", "confidence": 0.9805555939674377}]}, {"text": "We also wish to consider the relationship between detection accuracy and a human quality estimation score.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 60, "end_pos": 68, "type": "METRIC", "confidence": 0.9174611568450928}]}, {"text": "To do this, we use the French-English data from the 8th Workshop on Statistical Machine Translation -WMT13' MT Engine Example Google Translate \"These days, all but one were subject to a vote, and all had a direct link to the post September 11th.\"", "labels": [], "entities": [{"text": "Statistical Machine Translation", "start_pos": 68, "end_pos": 99, "type": "TASK", "confidence": 0.7195113897323608}, {"text": "WMT13' MT Engine Example Google Translate", "start_pos": 101, "end_pos": 142, "type": "DATASET", "confidence": 0.7963219966207232}]}, {"text": "Moses \"these days , except one were the subject of a vote , and all had a direct link with the after 11 September .\" Systran \"From these days, all except one were the object of a vote, and all were connected a direct link with after September 11th.\"", "labels": [], "entities": []}, {"text": "Linguatec \"Of these days, all except one were making the object of a vote and all had a straightforward tie with after September 11.\"", "labels": [], "entities": []}, {"text": "ProMT \"These days, very safe one all made object a vote, and had a direct link with after September 11th.\"", "labels": [], "entities": [{"text": "ProMT", "start_pos": 0, "end_pos": 5, "type": "DATASET", "confidence": 0.9828758835792542}]}, {"text": "Trident \"From these all days, except one operated object voting, and all had a direct rope with after 11 septembre.\"", "labels": [], "entities": [{"text": "Trident", "start_pos": 0, "end_pos": 7, "type": "DATASET", "confidence": 0.8884624242782593}, {"text": "object voting", "start_pos": 50, "end_pos": 63, "type": "TASK", "confidence": 0.8081057965755463}]}, {"text": "Skycode \"In these days, all safe one made the object in a vote and all had a direct connection with him after 11 of September.\" ence sentences from the WMT13' English reference translations, against the matching 3000 output sentences from one MT system at a time, resulting in 6000 sentence instances per experiment.", "labels": [], "entities": [{"text": "Skycode", "start_pos": 0, "end_pos": 7, "type": "DATASET", "confidence": 0.9643286466598511}, {"text": "WMT13", "start_pos": 152, "end_pos": 157, "type": "DATASET", "confidence": 0.9720170497894287}]}, {"text": "As can be seen in, the detection accuracy is strongly correlated with the evaluations scores, yielding R 2 = 0.774.", "labels": [], "entities": [{"text": "detection", "start_pos": 23, "end_pos": 32, "type": "METRIC", "confidence": 0.7187556624412537}, {"text": "accuracy", "start_pos": 33, "end_pos": 41, "type": "METRIC", "confidence": 0.6434930562973022}, {"text": "R 2", "start_pos": 103, "end_pos": 106, "type": "METRIC", "confidence": 0.9802079200744629}]}, {"text": "To provide another measure of correlation, we compared every pair of data points in the experiment to get the proportion of pairs ordered identically by the human evaluators and our method, with a result of 0.846 (66 of 78).", "labels": [], "entities": []}, {"text": "In the second experiment, we use 3000 random, non reference sentences from the newstest 2011-2012 corpora published in WMT12') against 3000 output sentences from one MT system at a time, again resulting in 6000 sentence instances per experiment.", "labels": [], "entities": [{"text": "newstest 2011-2012 corpora published in WMT12')", "start_pos": 79, "end_pos": 126, "type": "DATASET", "confidence": 0.9213986822537014}]}, {"text": "While applying the same classification method as with the reference sentences, the detection accuracy rises, while the correlation with the translation quality yields R 2 = 0.556, as can be seen in.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 93, "end_pos": 101, "type": "METRIC", "confidence": 0.7666987776756287}, {"text": "R 2", "start_pos": 167, "end_pos": 170, "type": "METRIC", "confidence": 0.9741405546665192}]}, {"text": "Here, the proportion of identically ordered pairs is 0.782 (61 of 78).", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 3: Details for Moses based SMT systems", "labels": [], "entities": [{"text": "SMT", "start_pos": 34, "end_pos": 37, "type": "TASK", "confidence": 0.8904353380203247}]}, {"text": " Table 1: Classifier performance, including the R 2 coefficient describing the correlation with BLEU.", "labels": [], "entities": [{"text": "R 2 coefficient", "start_pos": 48, "end_pos": 63, "type": "METRIC", "confidence": 0.9369611740112305}, {"text": "BLEU", "start_pos": 96, "end_pos": 100, "type": "METRIC", "confidence": 0.9982074499130249}]}]}