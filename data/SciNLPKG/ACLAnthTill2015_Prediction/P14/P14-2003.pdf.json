{"title": [{"text": "Probabilistic Labeling for Efficient Referential Grounding based on Collaborative Discourse", "labels": [], "entities": []}], "abstractContent": [{"text": "When humans and artificial agents (e.g. robots) have mismatched perceptions of the shared environment, referential communication between them becomes difficult.", "labels": [], "entities": [{"text": "referential communication", "start_pos": 103, "end_pos": 128, "type": "TASK", "confidence": 0.9194106459617615}]}, {"text": "To mediate perceptual differences, this paper presents anew approach using probabilistic labeling for referential grounding.", "labels": [], "entities": []}, {"text": "This approach aims to integrate different types of evidence from the collaborative referential discourse into a unified scheme.", "labels": [], "entities": []}, {"text": "Its probabilistic labeling procedure can generate multiple grounding hypotheses to facilitate follow-up dialogue.", "labels": [], "entities": []}, {"text": "Our empirical results have shown the probabilistic labeling approach significantly outperforms a previous graph-matching approach for referential grounding .", "labels": [], "entities": [{"text": "referential grounding", "start_pos": 134, "end_pos": 155, "type": "TASK", "confidence": 0.8613183796405792}]}], "introductionContent": [{"text": "In situated human-robot dialogue, humans and robots have mismatched capabilities of perceiving the shared environment.", "labels": [], "entities": []}, {"text": "Thus referential communication between them becomes extremely challenging.", "labels": [], "entities": [{"text": "referential communication", "start_pos": 5, "end_pos": 30, "type": "TASK", "confidence": 0.9521913826465607}]}, {"text": "To address this problem, our previous work has conducted a simulation-based study to collect a set of human-human conversation data that explain how partners with mismatched perceptions strive to succeed in referential communication (.", "labels": [], "entities": [{"text": "referential communication", "start_pos": 207, "end_pos": 232, "type": "TASK", "confidence": 0.8502720892429352}]}, {"text": "Our data have shown that, when conversation partners have mismatched perceptions, they tend to make extra collaborative effort in referential communication.", "labels": [], "entities": [{"text": "referential communication", "start_pos": 130, "end_pos": 155, "type": "TASK", "confidence": 0.892145186662674}]}, {"text": "For example, the speaker often refers to the intended object iteratively: first issuing an initial installment, and then refashioning till the hearer identifies the referent correctly.", "labels": [], "entities": []}, {"text": "The hearer, on the other hand, often provides useful feedback based on which further refashioning can be made.", "labels": [], "entities": []}, {"text": "This data has demonstrated the importance of incorporating collaborative discourse for referential grounding.", "labels": [], "entities": [{"text": "referential grounding", "start_pos": 87, "end_pos": 108, "type": "TASK", "confidence": 0.9091101586818695}]}, {"text": "Based on this data, as a first step we developed a graph-matching approach for referential grounding (.", "labels": [], "entities": [{"text": "referential grounding", "start_pos": 79, "end_pos": 100, "type": "TASK", "confidence": 0.8841851651668549}]}, {"text": "This approach uses Attributed Relational Graph to capture collaborative discourse and employs a statespace search algorithm to find proper grounding results.", "labels": [], "entities": []}, {"text": "Although it has made meaningful progress in addressing collaborative referential grounding under mismatched perceptions, the state-space search based approach has two major limitations.", "labels": [], "entities": []}, {"text": "First, it is neither flexible to obtain multiple grounding hypotheses, nor flexible to incorporate different hypotheses incrementally for follow-up grounding.", "labels": [], "entities": []}, {"text": "Second, the search algorithm tends to have a high time complexity for optimal solutions.", "labels": [], "entities": []}, {"text": "Thus, the previous approach is not ideal for collaborative and incremental dialogue systems that interact with human users in real time.", "labels": [], "entities": []}, {"text": "To address these limitations, this paper describes anew approach to referential grounding based on probabilistic labeling.", "labels": [], "entities": [{"text": "referential grounding", "start_pos": 68, "end_pos": 89, "type": "TASK", "confidence": 0.8603001534938812}]}, {"text": "This approach aims to integrate different types of evidence from the collaborative referential discourse into a unified probabilistic scheme.", "labels": [], "entities": []}, {"text": "It is formulated under the Bayesian reasoning framework to easily support generation and incorporation of multiple grounding hypotheses for follow-up processes.", "labels": [], "entities": []}, {"text": "Our empirical results have shown that the probabilistic labeling approach significantly outperforms the state-space search approach in both grounding accuracy and efficiency.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 150, "end_pos": 158, "type": "METRIC", "confidence": 0.9977812170982361}]}, {"text": "This new approach provides a good basis for processing collaborative discourse and enabling collaborative dialogue system in situated referential communication.", "labels": [], "entities": []}], "datasetContent": [{"text": "Our dataset has 62 dialogues, each of which contains an average of 25 valid utterances from the director.", "labels": [], "entities": []}, {"text": "We first applied the semantic parser and coreference classifier as described in Section 4.1 to process each dialogue, and then built a graph representation based on the automatic processing results at the end of the dialogue.", "labels": [], "entities": []}, {"text": "On average, a dialogue graph consists of 33 discourse entities from the director's utterances that need to be grounded.", "labels": [], "entities": []}, {"text": "We then applied both the probabilistic labeling algorithm and the state-space search algorithm to ground each of the director's discourse entities onto an object perceived from the image.", "labels": [], "entities": []}, {"text": "The averaged grounding accuracies of the two algorithms are shown in the middle part of shows the grounding accuracies of the algorithm's top-1 grounding hypothesis (i.e., \u03b8 i = argmax \u03c9\u03b1 P (\u03b8 i = \u03c9 \u03b1 ) for each i).", "labels": [], "entities": [{"text": "argmax \u03c9\u03b1 P", "start_pos": 178, "end_pos": 189, "type": "METRIC", "confidence": 0.9022040367126465}]}, {"text": "The second and third column then show the \"accuracies\" of the top-2 and top-3 hypotheses 4 , respectively.", "labels": [], "entities": []}, {"text": "As shown in, probabilistic labeling (i.e. P.L.) significantly outperforms state-space search (S.S.S.), especially with regard to producing meaningful multiple grounding hypotheses.", "labels": [], "entities": []}, {"text": "The state-space search algorithm actually only results in multiple hypotheses for the overall matching, and it fails to produce multiple hypotheses for many individual discourse entities.", "labels": [], "entities": []}, {"text": "Multiple grounding hypotheses can be very useful to generate responses such as clarification questions or nonverbal feedback (e.g. pointing, gazing).", "labels": [], "entities": [{"text": "pointing, gazing", "start_pos": 131, "end_pos": 147, "type": "TASK", "confidence": 0.6064114173253378}]}, {"text": "For example, if there are two competing hypotheses, the dialogue manager can utilize them to generate a response like \"I see two objects there, are you talking about this one (pointing to) or that one (pointing to the other)?\".", "labels": [], "entities": []}, {"text": "Such proactive feedback is often an effective way in referential communication.", "labels": [], "entities": [{"text": "referential communication", "start_pos": 53, "end_pos": 78, "type": "TASK", "confidence": 0.9334831833839417}]}, {"text": "The probabilistic labeling algorithm not only produces better grounding results, it also runs much faster (with a running-time complexity of O MN 2 , 5 comparing to ON 4 of the statespace search algorithm 6 ).", "labels": [], "entities": [{"text": "O MN 2", "start_pos": 141, "end_pos": 147, "type": "METRIC", "confidence": 0.9344994028409322}]}, {"text": "shows the averaged running time of the state-space search algorithm on a Intel Core i7 1.60GHz CPU with 16G RAM computer (the running time of the probabilistic labeling algorithm is not shown in Figure 1 since it always takes less than 1 second to run).", "labels": [], "entities": []}, {"text": "As we can see, when the size of the dialogue graph becomes greater than 15, state-space search takes more than 1 minute to run.", "labels": [], "entities": [{"text": "state-space search", "start_pos": 76, "end_pos": 94, "type": "TASK", "confidence": 0.6694318056106567}]}, {"text": "The efficiency of the probabilistic labeling algorithm thus makes it more appealing for real-time interaction applications.", "labels": [], "entities": []}, {"text": "Although probabilistic labeling significantly outperforms the state-space search, the grounding performance is still rather poor (less than 50%) The accuracy of the top-2/top-3 grounding hypotheses is measured by whether the ground-truth reference is included in the top-2/top-3 hypotheses.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 149, "end_pos": 157, "type": "METRIC", "confidence": 0.9992501139640808}]}, {"text": "5 M is the number of nodes in the vision graph and N is the number of nodes in the dialogue graph.", "labels": [], "entities": []}, {"text": "even for the top-3 hypotheses.", "labels": [], "entities": []}, {"text": "With no surprise, the coreference resolution performance plays an important role in the final grounding performance (see the grounding performance of using manually annotated coreference in the bottom part of Table 1).", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 22, "end_pos": 44, "type": "TASK", "confidence": 0.8915522396564484}]}, {"text": "Due to the simplicity of our current coreference classifier and the flexibility of the humanhuman dialogue in the data, the pairwise coreference resolution only achieves 0.74 in precision and 0.43 in recall.", "labels": [], "entities": [{"text": "precision", "start_pos": 178, "end_pos": 187, "type": "METRIC", "confidence": 0.9989714622497559}, {"text": "recall", "start_pos": 200, "end_pos": 206, "type": "METRIC", "confidence": 0.9982563853263855}]}, {"text": "The low recall of coreference resolution makes it difficult to link interrelated referring expressions and resolve them jointly.", "labels": [], "entities": [{"text": "recall", "start_pos": 8, "end_pos": 14, "type": "METRIC", "confidence": 0.9989927411079407}, {"text": "coreference resolution", "start_pos": 18, "end_pos": 40, "type": "TASK", "confidence": 0.9244966506958008}]}, {"text": "So it is important to develop more sophisticated coreference resolution and dialogue management components to reliably track the discourse relations and other dynamics in the dialogue to facilitate referential grounding.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 49, "end_pos": 71, "type": "TASK", "confidence": 0.8916786313056946}, {"text": "referential grounding", "start_pos": 198, "end_pos": 219, "type": "TASK", "confidence": 0.8746959269046783}]}], "tableCaptions": [{"text": " Table 1: Comparison of the reference grounding  performances of a random guess baseline, Prob- abilistic Labeling (P.L.) and State-Space Search  (S.S.S.), and P.L. using manually annotated coref- erence.", "labels": [], "entities": [{"text": "Prob- abilistic Labeling (P.L.)", "start_pos": 90, "end_pos": 121, "type": "METRIC", "confidence": 0.8323665687016079}]}]}