{"title": [{"text": "Hierarchical MT Training using Max-Violation Perceptron", "labels": [], "entities": [{"text": "MT", "start_pos": 13, "end_pos": 15, "type": "TASK", "confidence": 0.7436478734016418}]}], "abstractContent": [{"text": "Large-scale discriminative training has become promising for statistical machine translation by leveraging the huge training corpus; for example the recent effort in phrase-based MT (Yu et al., 2013) significantly outperforms mainstream methods that only train on small tuning sets.", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 61, "end_pos": 92, "type": "TASK", "confidence": 0.673878679672877}, {"text": "phrase-based MT (Yu et al., 2013)", "start_pos": 166, "end_pos": 199, "type": "TASK", "confidence": 0.7523582643932767}]}, {"text": "However, phrase-based MT suffers from limited reorderings, and thus its training can only utilize a small portion of the bi-text due to the distortion limit.", "labels": [], "entities": [{"text": "MT", "start_pos": 22, "end_pos": 24, "type": "TASK", "confidence": 0.685714602470398}]}, {"text": "To address this problem, we extend Yu et al.", "labels": [], "entities": []}, {"text": "(2013) to syntax-based MT by generalizing their latent variable \"violation-fixing\" percep-tron from graphs to hypergraphs.", "labels": [], "entities": [{"text": "MT", "start_pos": 23, "end_pos": 25, "type": "TASK", "confidence": 0.8208390474319458}]}, {"text": "Experiments confirm that our method leads to up to +1.2 BLEU improvement over mainstream methods such as MERT and PRO.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 56, "end_pos": 60, "type": "METRIC", "confidence": 0.9973885416984558}]}], "introductionContent": [{"text": "Many natural language processing problems including part-of-speech tagging), parsing), and event extraction ( have enjoyed great success using large-scale discriminative training algorithms.", "labels": [], "entities": [{"text": "part-of-speech tagging", "start_pos": 52, "end_pos": 74, "type": "TASK", "confidence": 0.7199449390172958}, {"text": "parsing", "start_pos": 77, "end_pos": 84, "type": "TASK", "confidence": 0.9799639582633972}, {"text": "event extraction", "start_pos": 91, "end_pos": 107, "type": "TASK", "confidence": 0.8101957440376282}]}, {"text": "However, a similar success on machine translation has been elusive, where the mainstream methods still tune on small datasets.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 30, "end_pos": 49, "type": "TASK", "confidence": 0.7959833741188049}]}, {"text": "What makes large-scale MT training so hard then?", "labels": [], "entities": [{"text": "MT training", "start_pos": 23, "end_pos": 34, "type": "TASK", "confidence": 0.9263353645801544}]}, {"text": "After numerous attempts by various researchers (;, the recent work of finally reveals a major reason: it is the vast amount of (inevitable) search errors in MT decoding that astray learning.", "labels": [], "entities": [{"text": "MT decoding", "start_pos": 157, "end_pos": 168, "type": "TASK", "confidence": 0.916959136724472}]}, {"text": "To alleviate this problem, their work adopts the theoretically-motivated framework of violation-fixing perceptron) tailed for inexact search, yielding great results on phrase-based MT (outperforming small-scale MERT/PRO by a large margin for the first time).", "labels": [], "entities": [{"text": "MT", "start_pos": 181, "end_pos": 183, "type": "TASK", "confidence": 0.7639344930648804}]}, {"text": "However, the underlying phrase-based model suffers from limited distortion and thus can only employ a small portion (about 1/3 in their ChEn experiments) of the bitext in training.", "labels": [], "entities": []}, {"text": "To better utilize the large training set, we propose to generalize from phrase-based MT to syntax-based MT, in particular the hierarchical phrase-based translation model (HIERO), in order to exploit sentence pairs beyond the expressive capacity of phrase-based MT.", "labels": [], "entities": []}, {"text": "The key challenge here is to extend the latent variable violation-fixing perceptron of to handle tree-structured derivations and translation hypergraphs.", "labels": [], "entities": []}, {"text": "Luckily, have recently generalized the underlying violation-fixing perceptron of from graphs to hypergraphs for bottom-up parsing, which resembles syntax-based decoding.", "labels": [], "entities": []}, {"text": "We just need to further extend it to handle latent variables.", "labels": [], "entities": []}, {"text": "We make the following contributions: 1.", "labels": [], "entities": []}, {"text": "We generalize the latent variable violationfixing perceptron framework to inexact search over hypergraphs, which subsumes previous algorithms for PBMT and bottomup parsing as special cases (see).", "labels": [], "entities": [{"text": "bottomup parsing", "start_pos": 155, "end_pos": 171, "type": "TASK", "confidence": 0.682068407535553}]}, {"text": "2. We show that syntax-based MT, with its better handling of long-distance reordering, can exploit a larger portion of the training set, which facilitates sparse lexicalized features.", "labels": [], "entities": [{"text": "MT", "start_pos": 29, "end_pos": 31, "type": "TASK", "confidence": 0.8812918066978455}]}, {"text": "id rule held X 2 with X 1 r 6 X \u2192 y\u02c7uy\u02c7u Sh\u00af al\u00f3ng, with Sharon X X h\u00f9 \u0131t\u00e1n 5 j\u02c7ux\u00edngj\u02c7ux\u00edng 4 X X h\u00f9 \u0131t\u00e1n 5 j\u02c7ux\u00edngj\u02c7ux\u00edng 4 X Sh\u00af al\u00f3ng 3 y\u02c7uy\u02c7u 2 Figure 3: A \u2212LM hypergraph with two derivations: the gold derivation) in solid lines, and the Viterbi derivation () in dashed lines.", "labels": [], "entities": []}], "datasetContent": [{"text": "Following, we call our maxviolation method MAXFORCE.", "labels": [], "entities": [{"text": "MAXFORCE", "start_pos": 43, "end_pos": 51, "type": "METRIC", "confidence": 0.5929912328720093}]}, {"text": "Our implementation is mostly in Python on top of the cdec system () via the pycdec interface ().", "labels": [], "entities": []}, {"text": "In addition, we use minibatch parallelization of ( ) to speedup perceptron training.", "labels": [], "entities": []}, {"text": "We evaluate MAXFORCE for HIERO over two CH-EN corpora, IWSLT09 and FBIS, and compare the performance with vanilla n-best MERT (Och, 2003) from Moses ( ), Hypergraph MERT (, and PRO (Hopkins and May, 2011) from cdec.", "labels": [], "entities": [{"text": "MAXFORCE", "start_pos": 12, "end_pos": 20, "type": "METRIC", "confidence": 0.9108604788780212}, {"text": "IWSLT09", "start_pos": 55, "end_pos": 62, "type": "METRIC", "confidence": 0.5465225577354431}, {"text": "MERT", "start_pos": 121, "end_pos": 125, "type": "METRIC", "confidence": 0.917590320110321}, {"text": "PRO", "start_pos": 177, "end_pos": 180, "type": "METRIC", "confidence": 0.8029994368553162}]}, {"text": "Our first corpus, IWSLT09, contains \u223c30k short sentences collected from spoken language.", "labels": [], "entities": [{"text": "IWSLT09", "start_pos": 18, "end_pos": 25, "type": "DATASET", "confidence": 0.9498754143714905}]}, {"text": "IWSLT04 is used as development set in MAX-FORCE training, and as tuning set for n-best MERT, Hypergraph MERT, and PRO.", "labels": [], "entities": [{"text": "IWSLT04", "start_pos": 0, "end_pos": 7, "type": "DATASET", "confidence": 0.880815327167511}]}, {"text": "IWSLT05 is used as test set.", "labels": [], "entities": [{"text": "IWSLT05", "start_pos": 0, "end_pos": 7, "type": "DATASET", "confidence": 0.9374157190322876}]}, {"text": "Both IWSLT04 and IWSLT05 contain 16 references.We mainly use this corpus to investigate the properties of MAXFORCE.", "labels": [], "entities": [{"text": "IWSLT04", "start_pos": 5, "end_pos": 12, "type": "DATASET", "confidence": 0.9591070413589478}, {"text": "IWSLT05", "start_pos": 17, "end_pos": 24, "type": "DATASET", "confidence": 0.9381945133209229}]}, {"text": "The second corpus, FBIS, contains \u223c240k sentences.", "labels": [], "entities": [{"text": "FBIS", "start_pos": 19, "end_pos": 23, "type": "DATASET", "confidence": 0.8355928063392639}]}, {"text": "NIST06 newswire is used as development set for MAXFORCE training, and as tuning set for all other tuning methods.", "labels": [], "entities": [{"text": "NIST06 newswire", "start_pos": 0, "end_pos": 15, "type": "DATASET", "confidence": 0.9904371201992035}, {"text": "MAXFORCE training", "start_pos": 47, "end_pos": 64, "type": "TASK", "confidence": 0.5140084624290466}]}, {"text": "NIST08 newswire is used as test set.", "labels": [], "entities": [{"text": "NIST08 newswire", "start_pos": 0, "end_pos": 15, "type": "DATASET", "confidence": 0.9722142517566681}]}, {"text": "Both NIST06 newswire and NIST08 newswire contain 4 references.", "labels": [], "entities": [{"text": "NIST06 newswire", "start_pos": 5, "end_pos": 20, "type": "DATASET", "confidence": 0.9794192612171173}, {"text": "NIST08 newswire", "start_pos": 25, "end_pos": 40, "type": "DATASET", "confidence": 0.9796454012393951}]}, {"text": "We mainly use this corpus to demonstrate the performance of MAXFORCE in large-scale training.", "labels": [], "entities": []}, {"text": "For both corpora, we do standard tokenization, alignment and rule extraction using the cdec tools.", "labels": [], "entities": [{"text": "alignment", "start_pos": 47, "end_pos": 56, "type": "TASK", "confidence": 0.9404299855232239}, {"text": "rule extraction", "start_pos": 61, "end_pos": 76, "type": "TASK", "confidence": 0.7069717049598694}]}, {"text": "In rule extraction, we remove all 1-count rules but keep the rules mapping from one Chinese word to one English word to help balancing sent.", "labels": [], "entities": [{"text": "rule extraction", "start_pos": 3, "end_pos": 18, "type": "TASK", "confidence": 0.8311246633529663}]}, {"text": "words phrase-based MT 32% 12% HIERO 35% 30% HIERO (all rules) 65% 55% See text below for \"loose\" and \"tight\". between overfitting and coverage.", "labels": [], "entities": [{"text": "MT", "start_pos": 19, "end_pos": 21, "type": "TASK", "confidence": 0.811204195022583}, {"text": "HIERO", "start_pos": 44, "end_pos": 49, "type": "METRIC", "confidence": 0.7762390375137329}, {"text": "coverage", "start_pos": 134, "end_pos": 142, "type": "METRIC", "confidence": 0.9491777420043945}]}, {"text": "We use a trigram language model trained from the target sides of the two corpora respectively.", "labels": [], "entities": []}, {"text": "For IWSLT, we first compare the performance from various update methods in. points better than the standard perceptron (also known as \"bold-update\" in) which updates at the root of the derivation tree.", "labels": [], "entities": [{"text": "IWSLT", "start_pos": 4, "end_pos": 9, "type": "DATASET", "confidence": 0.6395795941352844}]}, {"text": "This can be explained by the fact that in training \u223c58% of the standard updates are invalid (i.e., they do not fix any violation).", "labels": [], "entities": []}, {"text": "We also use the \"skip\" strategy of which updates at the root of the derivation only when it fixes a search error, avoiding all invalid updates.", "labels": [], "entities": []}, {"text": "This achieves \u223c10 BLEU better than the standard update, but is still more than \u223c5 BLEU worse than Max-Violation update.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 18, "end_pos": 22, "type": "METRIC", "confidence": 0.9837499260902405}, {"text": "BLEU", "start_pos": 82, "end_pos": 86, "type": "METRIC", "confidence": 0.9939957857131958}]}, {"text": "Finally we also try the \"local-update\" method from which updates towards the derivation with the best Bleu +1 in the root group S . This method is about 2 BLEU points worse than max-violation.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 155, "end_pos": 159, "type": "METRIC", "confidence": 0.9990283250808716}]}, {"text": "We further investigate the contribution of sparse features in.", "labels": [], "entities": []}, {"text": "On the development set, max-violation update without Word-Edges features achieves BLEU similar to n-best MERT and We find that while MAXFORCE generates translations of length ratio close to 1 during training, the length ratios on dev/test sets are significantly lower, due to OOVs.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 82, "end_pos": 86, "type": "METRIC", "confidence": 0.9994953870773315}, {"text": "OOVs", "start_pos": 276, "end_pos": 280, "type": "METRIC", "confidence": 0.8437538743019104}]}, {"text": "So we run a binary search for the length penalty weight after each training iteration to tune the length ratio to \u223c0.97 on dev set.", "labels": [], "entities": [{"text": "length penalty weight", "start_pos": 34, "end_pos": 55, "type": "METRIC", "confidence": 0.9504457116127014}, {"text": "length ratio", "start_pos": 98, "end_pos": 110, "type": "METRIC", "confidence": 0.9513541758060455}]}, {"text": "We report BLEU with averaged reference lengths.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9987565279006958}]}, {"text": "The results of n-best MERT, Hypergraph MERT, and PRO are averages from 3 runs.", "labels": [], "entities": [{"text": "Hypergraph MERT", "start_pos": 28, "end_pos": 43, "type": "METRIC", "confidence": 0.5843564122915268}, {"text": "PRO", "start_pos": 49, "end_pos": 52, "type": "METRIC", "confidence": 0.8324657082557678}]}], "tableCaptions": [{"text": " Table 2: BLEU scores (with 16 references) of var- ious training algorithms on IWSLT09.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9992848038673401}, {"text": "IWSLT09", "start_pos": 79, "end_pos": 86, "type": "DATASET", "confidence": 0.9542456865310669}]}, {"text": " Table 3: BLEU scores (with 4 references) of vari- ous training algorithms on FBIS.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9992671608924866}]}]}