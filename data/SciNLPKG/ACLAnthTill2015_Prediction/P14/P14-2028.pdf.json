{"title": [{"text": "Improved Iterative Correction for Distant Spelling Errors", "labels": [], "entities": [{"text": "Distant Spelling Errors", "start_pos": 34, "end_pos": 57, "type": "TASK", "confidence": 0.9022809068361918}]}], "abstractContent": [{"text": "Noisy channel models, widely used in modern spellers, cope with typical mis-spellings, but do notwork well with infrequent and difficult spelling errors.", "labels": [], "entities": []}, {"text": "In this paper, we have improved the noisy channel approach by iterative stochastic search for the best correction.", "labels": [], "entities": []}, {"text": "The proposed algorithm allowed us to avoid local minima problem and improve the F 1 measure by 6.6% on distant spelling errors.", "labels": [], "entities": [{"text": "F 1 measure", "start_pos": 80, "end_pos": 91, "type": "METRIC", "confidence": 0.9871975382169088}]}], "introductionContent": [{"text": "A speller is an essential part of any program associated with text input and processing -e-mail system, search engine, browser, form editor etc.", "labels": [], "entities": []}, {"text": "To detect and correct spelling errors, the state of the art spelling correction systems use the noisy channel approach ().", "labels": [], "entities": [{"text": "spelling correction", "start_pos": 60, "end_pos": 79, "type": "TASK", "confidence": 0.8534475564956665}]}, {"text": "Its models are usually trained on large corpora and provide high effectiveness in correction of typical errors (most of which consist of 1-2 wrong characters per word), but does notwork well for complex (multicharacter) and infrequent errors.", "labels": [], "entities": []}, {"text": "In this paper, we improved effectiveness of the noisy channel for the correction of complex errors.", "labels": [], "entities": []}, {"text": "In most cases, these are cognitive errors in loan words (folsvagen \u2192 volkswagen), names of drugs (vobemzin \u2192 wobenzym), names of brands (scatcher \u2192 skechers), scientific terms (heksagidron \u2192 hexahedron) and last names.", "labels": [], "entities": []}, {"text": "In all these cases, the misspelled word contains many errors and the corresponding error model penalty cannot be compensated by the LM weight of its proper form.", "labels": [], "entities": [{"text": "error model penalty", "start_pos": 83, "end_pos": 102, "type": "METRIC", "confidence": 0.8416027824083964}]}, {"text": "As a result, either the misspelled word itself, or the other (less complicated, more frequent) misspelling of the same word wins the likelihood race.", "labels": [], "entities": []}, {"text": "To compensate for this defect of the noisy channel, the iterative approach () is typically used.", "labels": [], "entities": []}, {"text": "The search for the best variant is repeated several times, what allows correcting rather complex errors, but does not completely solve the problem of falling into local minima.", "labels": [], "entities": []}, {"text": "To overcome this issue we suggest to consider more correction hypotheses.", "labels": [], "entities": []}, {"text": "For this purpose we used a method based on the simulated annealing algorithm.", "labels": [], "entities": []}, {"text": "We experimentally demonstrate that the proposed method outperforms the baseline noisy channel and iterative spellers.", "labels": [], "entities": []}, {"text": "Many authors employ machine learning to build rankers that compensate for the drawbacks of the noisy channel model: ().", "labels": [], "entities": []}, {"text": "These techniques can be combined with the proposed method by replacing posterior probability of single correction in our method with an estimate obtained via discriminative training method.", "labels": [], "entities": [{"text": "posterior probability of single correction", "start_pos": 71, "end_pos": 113, "type": "METRIC", "confidence": 0.6940694034099579}]}, {"text": "In our work, we focus on isolated word-error correction, which, in a sense, is a harder task, than multi-word correction, because there is no context available for misspelled words.", "labels": [], "entities": [{"text": "word-error correction", "start_pos": 34, "end_pos": 55, "type": "TASK", "confidence": 0.6689548790454865}, {"text": "multi-word correction", "start_pos": 99, "end_pos": 120, "type": "TASK", "confidence": 0.7549525797367096}]}, {"text": "For experiments we used single-word queries to a commercial search engine.", "labels": [], "entities": []}], "datasetContent": [{"text": "Queries  Increased average error model score and error rate of \"common\" dataset compared to \"hard\" shows, that we have indeed managed to collect hard-to-correct queries in the \"hard\" dataset.", "labels": [], "entities": [{"text": "error model score", "start_pos": 27, "end_pos": 44, "type": "METRIC", "confidence": 0.8601069649060568}, {"text": "error rate", "start_pos": 49, "end_pos": 59, "type": "METRIC", "confidence": 0.9642969965934753}]}, {"text": "First of all, we evaluated the recall of hypotheses generator using K-best recall -the number of correct spelling corrections for misspelled queries among K hypotheses divided by the total number of misspelled queries in the test set.", "labels": [], "entities": [{"text": "recall", "start_pos": 31, "end_pos": 37, "type": "METRIC", "confidence": 0.9960278272628784}, {"text": "K-best recall", "start_pos": 68, "end_pos": 81, "type": "METRIC", "confidence": 0.6433419287204742}]}, {"text": "Resulting recall with K = 30 is 91.8% on \"hard\" and 98.6% on \"common\".", "labels": [], "entities": [{"text": "recall", "start_pos": 10, "end_pos": 16, "type": "METRIC", "confidence": 0.9911937117576599}, {"text": "K = 30", "start_pos": 22, "end_pos": 28, "type": "METRIC", "confidence": 0.9096595843633016}]}, {"text": "Next, three spelling correction methods were tested: noisy channel, iterative correction and our method (stochastic iterative correction).", "labels": [], "entities": [{"text": "spelling correction", "start_pos": 12, "end_pos": 31, "type": "TASK", "confidence": 0.8857665061950684}]}, {"text": "For evaluation of spelling correction quality, we use the following metrics: \u2022 Precision: The number of correct spelling corrections for misspelled words generated by the system divided by the total number of corrections generated by the system; \u2022 Recall: The number of correct spelling corrections for misspelled words generated by the system divided by the total number of misspelled words in the test set; For hypotheses generator, K = 30 was fixed: recall of 91.8% was considered big enough.", "labels": [], "entities": [{"text": "spelling correction", "start_pos": 18, "end_pos": 37, "type": "TASK", "confidence": 0.8017670512199402}, {"text": "Precision", "start_pos": 79, "end_pos": 88, "type": "METRIC", "confidence": 0.9849986433982849}, {"text": "Recall", "start_pos": 248, "end_pos": 254, "type": "METRIC", "confidence": 0.9962950348854065}, {"text": "K", "start_pos": 435, "end_pos": 436, "type": "METRIC", "confidence": 0.9808623194694519}, {"text": "recall", "start_pos": 453, "end_pos": 459, "type": "METRIC", "confidence": 0.9994532465934753}]}, {"text": "Precision/recall tradeoff parameters \u03bb and \u03b1 (they are applicable to each method, including baseline) were iterated by the grid (0.2, 0.25, 0.3, ..., 1.5) \u00d7 (0, 0.025, 0.05, ..., 1.0), and E (applicable to iterative and our method) and \u03b3 (just our method) were iterated by the grid  We were notable to reproduce superior performance of the iterative method over the noisy channel, reported by ().", "labels": [], "entities": [{"text": "Precision", "start_pos": 0, "end_pos": 9, "type": "METRIC", "confidence": 0.937461793422699}, {"text": "recall", "start_pos": 10, "end_pos": 16, "type": "METRIC", "confidence": 0.8297043442726135}]}, {"text": "Supposedly, it is because the iterative method benefits primarily from the sequential application of split/join operations altering query decomposition into words; since we are considering only oneword queries, such decomposition does not matter.", "labels": [], "entities": []}, {"text": "On the \"hard\" dataset the performance of the noisy channel and the iterative methods is inferior to our proposed method, see.", "labels": [], "entities": []}, {"text": "We tested all three methods on the \"common\" dataset as well to evaluate if our handling of hard cases affects the performance of our approach on the common cases of spelling error.", "labels": [], "entities": []}, {"text": "Our method performs well on the common cases as well, as shows.", "labels": [], "entities": []}, {"text": "The performance comparison for the \"common\" dataset shows comparable performance for all considered methods.", "labels": [], "entities": []}, {"text": "Noisy channel and iterative methods' frontiers are considerably inferior to the proposed method on \"hard\" dataset, which means that our method works better.", "labels": [], "entities": []}, {"text": "The results on \"common\" dataset show, that the proposed method doesn't work worse than baseline.", "labels": [], "entities": []}, {"text": "Next, we optimized parameters for each method and each dataset separately to achieve the highest F 1 measure.", "labels": [], "entities": [{"text": "F 1 measure", "start_pos": 97, "end_pos": 108, "type": "METRIC", "confidence": 0.9780979553858439}]}, {"text": "We can see, that, given the proper tuning, our method can work better on any dataset (but it cannot achieve the best performance on both datasets at once).", "labels": [], "entities": []}, {"text": "See: Best parameters and F 1 on \"common\" dataset Next, each parameter was separately iterated (by a coarser grid); initial parameters for each method were taken from.", "labels": [], "entities": [{"text": "F 1", "start_pos": 25, "end_pos": 28, "type": "METRIC", "confidence": 0.9916008710861206}]}, {"text": "Such iteration serves two purposes: to show the influence of parameters on algorithm performance, and to show differences between datasets: in such setup parameters are virtually tuned using \"hard\" dataset and evaluated using \"common\" dataset.", "labels": [], "entities": []}, {"text": "The proposed method is able to successfully correct distant spelling errors with edit distance of 3 characters (see).", "labels": [], "entities": []}, {"text": "However, if our method is applied to shorter and more frequent queries (as opposed to \"hard\" dataset), it tends to suggest frequent words as false-positive corrections (for example, grid is corrected to creed -Assassin's Creed is popular video game).", "labels": [], "entities": []}, {"text": "As can be seen in, in order to fix that, algorithm parameters need to be tuned more towards precision.", "labels": [], "entities": [{"text": "precision", "start_pos": 92, "end_pos": 101, "type": "METRIC", "confidence": 0.9974028468132019}]}], "tableCaptions": [{"text": " Table 1: Noisy-channel scores for two corrections  of vobemzin", "labels": [], "entities": []}, {"text": " Table 2. Note, that despite the fact  that most probable path does not lead to the cor- rect word, many other paths to wobenzym sum up  to 0.361, which is greater than probability of any  other word. Also note, that the method works only  because multiple misspellings of the same word  are presented in our model; for related research  see", "labels": [], "entities": []}, {"text": " Table 2: Most probable random walk paths start- ing from c 0 = q = vobemzin (the correct form is  in bold).", "labels": [], "entities": []}, {"text": " Table 4: Best parameters and F 1 on \"hard\" dataset", "labels": [], "entities": [{"text": "F 1", "start_pos": 30, "end_pos": 33, "type": "METRIC", "confidence": 0.9936973452568054}]}, {"text": " Table 5: Best parameters and F 1 on \"common\"  dataset", "labels": [], "entities": [{"text": "F 1", "start_pos": 30, "end_pos": 33, "type": "METRIC", "confidence": 0.9940765500068665}]}, {"text": " Table 6: Per-coordinate iteration of parameters  from Table 4; per-method maximum is shown in  italic, per-dataset in bold", "labels": [], "entities": []}]}