{"title": [{"text": "Distributed Representations of Geographically Situated Language", "labels": [], "entities": [{"text": "Distributed Representations of Geographically Situated Language", "start_pos": 0, "end_pos": 63, "type": "TASK", "confidence": 0.9070016841093699}]}], "abstractContent": [{"text": "We introduce a model for incorporating contextual information (such as geography) in learning vector-space representations of situated language.", "labels": [], "entities": []}, {"text": "In contrast to approaches to multimodal representation learning that have used properties of the object being described (such as its color), our model includes information about the subject (i.e., the speaker), allowing us to learn the contours of a word's meaning that are shaped by the context in which it is uttered.", "labels": [], "entities": [{"text": "multimodal representation learning", "start_pos": 29, "end_pos": 63, "type": "TASK", "confidence": 0.738845686117808}]}, {"text": "Ina quantitative evaluation on the task of judging geographically informed semantic similarity between representations learned from 1.1 billion words of geo-located tweets, our joint model out-performs comparable independent models that learn meaning in isolation.", "labels": [], "entities": [{"text": "judging geographically informed semantic similarity between representations learned from 1.1 billion words of geo-located tweets", "start_pos": 43, "end_pos": 171, "type": "TASK", "confidence": 0.7570263127485911}]}], "introductionContent": [{"text": "The vast textual resources used in NLPnewswire, web text, parliamentary proceedingscan encourage a view of language as a disembodied phenomenon.", "labels": [], "entities": []}, {"text": "The rise of social media, however, with its large volume of text paired with information about its author and social context, reminds us that each word is uttered by a particular person at a particular place and time.", "labels": [], "entities": []}, {"text": "In short: language is situated.", "labels": [], "entities": []}, {"text": "The coupling of text with demographic information has enabled computational modeling of linguistic variation, including uncovering words and topics that are characteristic of geographical regions (, learning correlations between words and socioeconomic variables (; and charting how new terms spread geographically ().", "labels": [], "entities": []}, {"text": "These models can tell us that hella was (at one time) used most often by a particular demographic group in northern California, echoing earlier linguistic studies, and that wicked is used most often in New England (Ravindranath, 2011); and they have practical applications, facilitating tasks like text-based geolocation (.", "labels": [], "entities": []}, {"text": "One desideratum that remains, however, is how the meaning of these terms is shaped by geographical influences -while wicked is used throughout the United States to mean bad or evil (\"he is a wicked man\"), in New England it is used as an adverbial intensifier (\"my boy's wicked smart\").", "labels": [], "entities": []}, {"text": "In leveraging grounded social media to uncover linguistic variation, what we want to learn is how a word's meaning is shaped by its geography.", "labels": [], "entities": []}, {"text": "In this paper, we introduce a method that extends vector-space lexical semantic models to learn representations of geographically situated language.", "labels": [], "entities": []}, {"text": "Vector-space models of lexical semantics have been a popular and effective approach to learning representations of word meaning.", "labels": [], "entities": [{"text": "learning representations of word meaning", "start_pos": 87, "end_pos": 127, "type": "TASK", "confidence": 0.7150667667388916}]}, {"text": "In bringing in extra-linguistic information to learn word representations, our work falls into the general domain of multimodal learning; while other work has used visual information to improve distributed representations, this work generally exploits information about the object being described (e.g., strawberry and a picture of a strawberry); in contrast, we use information about the speaker to learn representations that vary according to contextual variables from the speaker's perspective.", "labels": [], "entities": []}, {"text": "Unlike classic multimodal systems that incorporate multiple active modalities (such as gesture) from a user ...", "labels": [], "entities": []}, {"text": "Ballard, 2004), our primary input is textual data, supplemented with metadata about the author and the moment of authorship.", "labels": [], "entities": []}, {"text": "This information enables learning models of word meaning that are sensitive to such factors, allowing us to distinguish, for example, between the usage of wicked in Massachusetts from the usage of that word elsewhere, and letting us better associate geographically grounded named entities (e.g, Boston) with their hypernyms (city) in their respective regions.", "labels": [], "entities": []}], "datasetContent": [{"text": "We evaluate our model by confirming its face validity in a qualitative analysis and estimating its accuracy at the quantitative task of judging geographically-informed semantic similarity.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 99, "end_pos": 107, "type": "METRIC", "confidence": 0.9994662404060364}]}, {"text": "We use 1.1 billion tokens from 93 million geolocated tweets gathered between September 1, 2011 and August 30, 2013 (approximately 127,000 tweets per day evenly sampled over those two years).", "labels": [], "entities": []}, {"text": "This data only includes tweets that have been geolocated to state-level granularity in the United States using high-precision pattern matching on the user-specified location field (e.g., \"new york ny\" \u2192 NY, \"chicago\" \u2192 IL, etc.).", "labels": [], "entities": []}, {"text": "As a preprocessing step, we identify a set of target multiword expressions in this corpus as the maximal sequence of adjectives + nouns with the highest pointwise mutual information; in all experiments described below, we define the vocabulary V as the most frequent 100,000 terms (either unigrams or multiword expressions) in the total data, and set the dimensionality of the embedding k = 100.", "labels": [], "entities": []}, {"text": "In all experiments, the contextual variable is the observed US state (including DC), so that |C| = 51; the vector space representation of word win state sis w W main + w W s .  To illustrate how the model described above can learn geographically-informed semantic representations of words, table 1 displays the terms with the highest cosine similarity to wicked in Kansas and Massachusetts after running our joint model on the full 1.1 billion words of Twitter data; while wicked in Kansas is close to other evaluative terms like evil and pure and religious terms like gods and spirit, in Massachusetts it is most similar to other intensifiers like super, ridiculously and insanely.", "labels": [], "entities": []}, {"text": "(New York City's term of administrative division).", "labels": [], "entities": []}, {"text": "As a quantitative measure of our model's performance, we consider the task of judging semantic similarity among words whose meanings are likely to evoke strong geographical correlations.", "labels": [], "entities": []}, {"text": "In the absence of a sizable number of linguistically interesting terms (like wicked) that are known to be geographically variable, we consider the proxy of estimating the named entities evoked by specific terms in different geographical regions.", "labels": [], "entities": []}, {"text": "As noted above, geographic terms like city provide one such example: in Massachusetts we expect the term city to be more strongly connected to grounded named entities like Boston than to other US cities.", "labels": [], "entities": []}, {"text": "We consider seven categories for which we can reasonably expect the connotations of each term to vary by geography; in each case, we calculate the distance between two terms x and y using representations learned fora given state (\u03b4 state (x, y)).", "labels": [], "entities": []}, {"text": "For each state, we measure the distance between the word city and the state's most populous city; e.g., \u03b4 AZ (city, phoenix ).", "labels": [], "entities": [{"text": "\u03b4 AZ", "start_pos": 104, "end_pos": 108, "type": "METRIC", "confidence": 0.6465098559856415}]}, {"text": "For each state, the distance between the word state and the state's name; e.g., \u03b4 WI (state, wisconsin).", "labels": [], "entities": [{"text": "\u03b4 WI", "start_pos": 80, "end_pos": 84, "type": "METRIC", "confidence": 0.8338858783245087}]}, {"text": "For all NFL teams, the distance between the word football and the team name; e.g., \u03b4 IL (football , bears).", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Terms with the highest cosine similarity to wicked  in Kansas and Massachusetts.", "labels": [], "entities": []}, {"text": " Table 2: Terms with the highest cosine similarity to city in  California and New York.", "labels": [], "entities": []}]}