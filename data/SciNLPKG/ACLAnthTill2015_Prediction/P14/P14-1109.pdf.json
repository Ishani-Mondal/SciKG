{"title": [{"text": "A Semiparametric Gaussian Copula Regression Model for Predicting Financial Risks from Earnings Calls", "labels": [], "entities": [{"text": "Predicting Financial Risks from Earnings Calls", "start_pos": 54, "end_pos": 100, "type": "TASK", "confidence": 0.902420332034429}]}], "abstractContent": [{"text": "Earnings call summarizes the financial performance of a company, and it is an important indicator of the future financial risks of the company.", "labels": [], "entities": [{"text": "Earnings call", "start_pos": 0, "end_pos": 13, "type": "DATASET", "confidence": 0.6126924157142639}]}, {"text": "We quantitatively study how earnings calls are correlated with the financial risks, with a special focus on the financial crisis of 2009.", "labels": [], "entities": []}, {"text": "In particular , we perform a text regression task: given the transcript of an earnings call, we predict the volatility of stock prices from the week after the call is made.", "labels": [], "entities": []}, {"text": "We propose the use of copula: a powerful statistical framework that separately models the uniform marginals and their complex mul-tivariate stochastic dependencies, while not requiring any prior assumptions on the distributions of the covariate and the dependent variable.", "labels": [], "entities": []}, {"text": "By performing probability integral transform, our approach moves beyond the standard count-based bag-of-words models in NLP, and improves previous work on text regression by incorporating the correlation among local features in the form of semiparametric Gaus-sian copula.", "labels": [], "entities": [{"text": "text regression", "start_pos": 155, "end_pos": 170, "type": "TASK", "confidence": 0.7291026413440704}]}, {"text": "In experiments, we show that our model significantly outperforms strong linear and non-linear discriminative baselines on three datasets under various settings.", "labels": [], "entities": []}], "introductionContent": [{"text": "Predicting the risks of publicly listed companies is of great interests not only to the traders and analysts on the Wall Street, but also virtually anyone who has investments in the market (.", "labels": [], "entities": [{"text": "Wall Street", "start_pos": 116, "end_pos": 127, "type": "DATASET", "confidence": 0.9770174920558929}]}, {"text": "Traditionally, analysts focus on quantitative modeling of historical trading data.", "labels": [], "entities": []}, {"text": "Today, even though earnings calls transcripts are abundantly available, their distinctive communicative practices, and correlations with the financial risks, in particular, future stock performances (, are not well studied in the past.", "labels": [], "entities": []}, {"text": "Earnings calls are conference calls where a listed company discusses the financial performance.", "labels": [], "entities": []}, {"text": "Typically, a earnings call contains two parts: the senior executives first report the operational outcomes, as well as the current financial performance, and then discuss their perspectives on the future of the company.", "labels": [], "entities": []}, {"text": "The second part of the teleconference includes a question answering session where the floor will be open to investors, analysts, and other parties for inquiries.", "labels": [], "entities": [{"text": "question answering session", "start_pos": 49, "end_pos": 75, "type": "TASK", "confidence": 0.7678896089394888}]}, {"text": "The question we ask is that, even though each earnings call has distinct styles, as well as different speakers and mixed formats, can we use earnings calls to predict the financial risks of the company in the limited future?", "labels": [], "entities": []}, {"text": "Given apiece of earnings call transcript, we investigate a semiparametric approach for automatic prediction of future financial risk . To do this, we formulate the problem as a text regression task, and use a Gaussian copula with probability integral transform to model the uniform marginals and their dependencies.", "labels": [], "entities": [{"text": "automatic prediction of future financial risk", "start_pos": 87, "end_pos": 132, "type": "TASK", "confidence": 0.6859399179617564}]}, {"text": "Copula models ( are often used by statisticians and economists) to study the bivariate and multivariate stochastic dependency among random variables, but they are very new to the machine learning () and related communities.", "labels": [], "entities": []}, {"text": "To the best of our knowledge, even though the term \"copula\" is named for the resemblance to grammatical copulas in linguistics, copula models have not been explored in the NLP community.", "labels": [], "entities": []}, {"text": "To evaluate the performance of our approach, we compare with a standard squared loss linear regression baseline, as well as strong baselines such as linear and non-linear support vector machines (SVMs) that are widely used in text regression tasks.", "labels": [], "entities": [{"text": "text regression tasks", "start_pos": 226, "end_pos": 247, "type": "TASK", "confidence": 0.8156813383102417}]}, {"text": "By varying different experimental settings on three datasets concerning different periods of the Great Recession from 2006-2013, we empirically show that our approach significantly outperforms the baselines by a wide margin.", "labels": [], "entities": []}, {"text": "Our main contributions are: \u2022 We are among the first to formally study transcripts of earnings calls to predict financial risks.", "labels": [], "entities": []}, {"text": "\u2022 We propose a novel semiparametric Gaussian copula model for text regression.", "labels": [], "entities": [{"text": "text regression", "start_pos": 62, "end_pos": 77, "type": "TASK", "confidence": 0.7958686649799347}]}, {"text": "\u2022 Our results significantly outperform standard linear regression and strong SVM baselines.", "labels": [], "entities": []}, {"text": "\u2022 By varying the number of dimensions of the covariates and the size of the training data, we show that the improvements over the baselines are robust across different parameter settings on three datasets.", "labels": [], "entities": []}, {"text": "In the next section, we outline related work in modeling financial reports and text regression.", "labels": [], "entities": [{"text": "text regression", "start_pos": 79, "end_pos": 94, "type": "TASK", "confidence": 0.7208366990089417}]}, {"text": "In Section 3, the details of the semiparametric copula model are introduced.", "labels": [], "entities": []}, {"text": "We then describe the dataset and dependent variable in this study, and the experiments are shown in Section 6.", "labels": [], "entities": []}, {"text": "We discuss the results and findings in Section 7 and then conclude in Section 8.", "labels": [], "entities": []}], "datasetContent": [{"text": "We use three datasets 4 of transcribed quarterly earnings calls from the U.S. stock market, focusing on the period of the Great Recession..", "labels": [], "entities": []}, {"text": "Given: (1) training data (X (tr) , y (tr) ); (2) testing data (X (te) , y (te) ); Learning: Inference: Note that unlike the standard news corpora in NLP or the SEC-mandated financial report, Transcripts of earnings call is a very special genre of text.", "labels": [], "entities": []}, {"text": "For example, the length of WSJ documents is typically one to three hundreds, but the averaged document length of our three earnings calls datasets is 7677.", "labels": [], "entities": [{"text": "WSJ documents", "start_pos": 27, "end_pos": 40, "type": "DATASET", "confidence": 0.7555757462978363}]}, {"text": "Depending on the amount of interactions in the question answering session, the complexities of the calls vary.", "labels": [], "entities": [{"text": "question answering session", "start_pos": 47, "end_pos": 73, "type": "TASK", "confidence": 0.8354063232739767}]}, {"text": "This mixed form of formal statement and informal speech brought difficulties to machine learning algorithms.", "labels": [], "entities": []}, {"text": "In all experiments throughout this section, we use 80-20 train/test splits on all three datasets.", "labels": [], "entities": []}, {"text": "Spearman's correlation and Kendall's tau have been widely used in many regression problems in NLP, and here we use them to measure the quality of predicted values\u02c6yvalues\u02c6 values\u02c6y by comparing to the vector of ground truth y.", "labels": [], "entities": [{"text": "Spearman's correlation", "start_pos": 0, "end_pos": 22, "type": "METRIC", "confidence": 0.7919666568438212}]}, {"text": "In contrast to Pearson's correlation, Spearman's correlation has no assumptions on the relationship of the two measured variables.", "labels": [], "entities": []}, {"text": "Kendall's tau is a nonparametric statistical metric that have shown to be inexpensive, robust, and representation independent).", "labels": [], "entities": []}, {"text": "We also use paired two-tailed t-test to measure the statistical significance between the best and the second best approaches.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Statistics of three datasets. Types: unique  words. Tokens: word tokens.", "labels": [], "entities": []}, {"text": " Table 2: Comparing the learning algorithms on three datasets with all features. The best result is high- lighted in bold. * indicates p < .001 comparing to the second best result.", "labels": [], "entities": []}, {"text": " Table 3: Top-10 features that have positive corre- lations with stock volatility in three datasets.", "labels": [], "entities": []}]}