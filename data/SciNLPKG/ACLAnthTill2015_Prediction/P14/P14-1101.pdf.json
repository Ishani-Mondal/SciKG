{"title": [{"text": "Weak semantic context helps phonetic learning in a model of infant language acquisition", "labels": [], "entities": [{"text": "infant language acquisition", "start_pos": 60, "end_pos": 87, "type": "TASK", "confidence": 0.6466522713502248}]}], "abstractContent": [{"text": "Learning phonetic categories is one of the first steps to learning a language, yet is hard to do using only distributional phonetic information.", "labels": [], "entities": []}, {"text": "Semantics could potentially be useful, since words with different meanings have distinct phonetics, but it is unclear how many word meanings are known to infants learning phonetic categories.", "labels": [], "entities": []}, {"text": "We show that attending to a weaker source of semantics, in the form of a distribution over topics in the current context, can lead to improvements in phonetic category learning.", "labels": [], "entities": [{"text": "phonetic category learning", "start_pos": 150, "end_pos": 176, "type": "TASK", "confidence": 0.6621442139148712}]}, {"text": "In our model, an extension of a previous model of joint word-form and pho-netic category inference, the probability of word-forms is topic-dependent, enabling the model to find significantly better pho-netic vowel categories and word-forms than a model with no semantic knowledge.", "labels": [], "entities": []}], "introductionContent": [{"text": "Infants begin learning the phonetic categories of their native language in their first year (.", "labels": [], "entities": []}, {"text": "In theory, semantic information could offer a valuable cue for phoneme induction 1 by helping infants distinguish between minimal pairs, as linguists do.", "labels": [], "entities": [{"text": "phoneme induction 1", "start_pos": 63, "end_pos": 82, "type": "TASK", "confidence": 0.8293437560399374}]}, {"text": "However, due to a widespread assumption that infants do not know the meanings of many words at the age when they are learning phonetic categories (see fora review), most recent models of early phonetic category acquisition have explored the phonetic learning problem in the absence of semantic information (.", "labels": [], "entities": [{"text": "phonetic category acquisition", "start_pos": 193, "end_pos": 222, "type": "TASK", "confidence": 0.7304965456326803}]}, {"text": "Models without any semantic information are likely to underestimate infants' ability to learn phonetic categories.", "labels": [], "entities": []}, {"text": "Infants learn language in the wild, and quickly attune to the fact that words have (possibly unknown) meanings.", "labels": [], "entities": []}, {"text": "The extent of infants' semantic knowledge is not yet known, but existing evidence shows that six-month-olds can associate some words with their referents, leverage non-acoustic contexts such as objects or articulations to distinguish similar sounds, and map meaning (in the form of objects or images) to new word-forms in some laboratory settings ().", "labels": [], "entities": []}, {"text": "These findings indicate that young infants are sensitive to co-occurrences between linguistic stimuli and at least some aspects of the world.", "labels": [], "entities": []}, {"text": "In this paper we explore the potential contribution of semantic information to phonetic learning by formalizing a model in which learners attend to the word-level context in which phones appear (as in the lexical-phonetic learning model of) and also to the situations in which word-forms are used.", "labels": [], "entities": []}, {"text": "The modeled situations consist of combinations of categories of salient activities or objects, similar to the activity contexts explored by, e.g.,'getting dressed' or 'eating breakfast'.", "labels": [], "entities": []}, {"text": "We assume that child learners are able to infer a representation of the situational context from their non-linguistic environment.", "labels": [], "entities": []}, {"text": "However, in our simulations we approximate the environmental information by running a topic model () over a corpus of childdirected speech to infer a topic distribution for each situation.", "labels": [], "entities": []}, {"text": "These topic distributions are then used as input to our model to represent situational contexts.", "labels": [], "entities": []}, {"text": "The situational information in our model is simi-lar to that assumed by theories of cross-situational word learning), but our model does not require learners to map individual words to their referents.", "labels": [], "entities": []}, {"text": "Even in the absence of word-meaning mappings, situational information is potentially useful because similar-sounding words uttered in similar situations are more likely to be tokens of the same lexeme (containing the same phones) than similarsounding words uttered in different situations.", "labels": [], "entities": []}, {"text": "In simulations of vowel learning, inspired by, we show a clear improvement over previous models in both phonetic and lexical (word-form) categorization when situational context is used as an additional source of information.", "labels": [], "entities": [{"text": "vowel learning", "start_pos": 18, "end_pos": 32, "type": "TASK", "confidence": 0.7003812789916992}]}, {"text": "This improvement is especially noticeable when the word-level context is providing less information, arguably the more realistic setting.", "labels": [], "entities": []}, {"text": "These results demonstrate that relying on situational co-occurrence can improve phonetic learning, even if learners do not yet know the meanings of individual words.", "labels": [], "entities": [{"text": "phonetic learning", "start_pos": 80, "end_pos": 97, "type": "TASK", "confidence": 0.7636651694774628}]}], "datasetContent": [{"text": "We evaluate against adult categories, i.e., the 'goldstandard', since all learners of a language eventually converge on similar categories.", "labels": [], "entities": []}, {"text": "(Since our model is not a model of the learning process, we do not compare the infant learning process to the learning algorithm.)", "labels": [], "entities": []}, {"text": "We evaluate both the inferred phonetic categories and words using the clustering evaluation measure V-Measure (VM;.", "labels": [], "entities": []}, {"text": "6 VM is the harmonic mean of two components, similar to F-score, where the components (VC and VH) are measures of cross entropy between the gold and model categorization.", "labels": [], "entities": [{"text": "F-score", "start_pos": 56, "end_pos": 63, "type": "METRIC", "confidence": 0.9045671820640564}]}, {"text": "For vowels, VM measures how well the inferred phonetic categorizations match the gold categories; for lexemes, it measures whether tokens have been assigned to the same lexemes both by the model and the gold standard.", "labels": [], "entities": [{"text": "VM", "start_pos": 12, "end_pos": 14, "type": "METRIC", "confidence": 0.7699601054191589}]}, {"text": "Words are evaluated against gold orthography, so homophones, e.g. hole and whole, are distinct gold words.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Corpus statistics showing the increasing  amount of ambiguity as consonant categories are  merged. Input types are the number of word types  with distinct input representations (as opposed to  gold orthographic word types, of which there are  1497). Ambiguous types and tokens are those with  frames that match multiple (orthographic) word  types.", "labels": [], "entities": []}]}