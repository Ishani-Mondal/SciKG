{"title": [{"text": "Effective Document-Level Features for Chinese Patent Word Segmentation", "labels": [], "entities": [{"text": "Chinese Patent Word Segmentation", "start_pos": 38, "end_pos": 70, "type": "TASK", "confidence": 0.733736664056778}]}], "abstractContent": [{"text": "A patent is a property right for an invention granted by the government to the inventor.", "labels": [], "entities": []}, {"text": "Patents often have a high concentration of scientific and technical terms that are rare in everyday language.", "labels": [], "entities": []}, {"text": "However , some scientific and technical terms usually appear with high frequency only in one specific patent.", "labels": [], "entities": []}, {"text": "In this paper, we propose a pragmatic approach to Chinese word segmentation on patents where we train a sequence labeling model based on a group of novel document-level features.", "labels": [], "entities": [{"text": "Chinese word segmentation", "start_pos": 50, "end_pos": 75, "type": "TASK", "confidence": 0.6232457955678304}]}, {"text": "Experiments show that the accuracy of our model reached 96.3% (F 1 score) on the development set and 95.0% on a held-out test set.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 26, "end_pos": 34, "type": "METRIC", "confidence": 0.9996606111526489}, {"text": "F 1 score)", "start_pos": 63, "end_pos": 73, "type": "METRIC", "confidence": 0.9852881133556366}]}], "introductionContent": [{"text": "It is well known that Chinese text does not come with natural word delimiters, and the first step for many Chinese language processing tasks is word segmentation, the automatic determination of word boundaries in Chinese text.", "labels": [], "entities": [{"text": "Chinese language processing", "start_pos": 107, "end_pos": 134, "type": "TASK", "confidence": 0.6694023807843527}, {"text": "word segmentation", "start_pos": 144, "end_pos": 161, "type": "TASK", "confidence": 0.7477827370166779}]}, {"text": "Tremendous progress was made in this area in the last decade or so due to the availability of large-scale human segmented corpora coupled with better statistical modeling techniques.", "labels": [], "entities": []}, {"text": "On the data side, there exist a few large-scale human annotated corpora based on established word segmentation standards, and these include the Chinese TreeBank (), the Sinica Balanced Corpus ( , the PKU Peoples' Daily Corpus (, and the LIVAC balanced corpus (T'sou et al., 1997).", "labels": [], "entities": [{"text": "Chinese TreeBank", "start_pos": 144, "end_pos": 160, "type": "DATASET", "confidence": 0.9547094702720642}, {"text": "PKU Peoples' Daily Corpus", "start_pos": 200, "end_pos": 225, "type": "DATASET", "confidence": 0.9211771190166473}, {"text": "LIVAC balanced corpus", "start_pos": 237, "end_pos": 258, "type": "DATASET", "confidence": 0.6926015416781107}]}, {"text": "Another driver for the improvement in Chinese word segmentation accuracy comes from the evolution of statistical modeling techniques.", "labels": [], "entities": [{"text": "Chinese word segmentation", "start_pos": 38, "end_pos": 63, "type": "TASK", "confidence": 0.5956023832162222}, {"text": "accuracy", "start_pos": 64, "end_pos": 72, "type": "METRIC", "confidence": 0.8200978636741638}]}, {"text": "Dictionaries used to play a central role in early heuristics-based word segmentation techniques).", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 67, "end_pos": 84, "type": "TASK", "confidence": 0.725936159491539}]}, {"text": "Modern word segmentation systems have moved away from dictionary-based approaches in favor of character tagging approaches.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 7, "end_pos": 24, "type": "TASK", "confidence": 0.7802140116691589}, {"text": "character tagging", "start_pos": 94, "end_pos": 111, "type": "TASK", "confidence": 0.7172493636608124}]}, {"text": "This allows the word segmentation problem to be modeled as a sequence labeling problem, and lends itself to discriminative sequence modeling techniques.", "labels": [], "entities": [{"text": "word segmentation problem", "start_pos": 16, "end_pos": 41, "type": "TASK", "confidence": 0.8105902274449667}, {"text": "sequence labeling problem", "start_pos": 61, "end_pos": 86, "type": "TASK", "confidence": 0.7739309867223104}, {"text": "discriminative sequence modeling", "start_pos": 108, "end_pos": 140, "type": "TASK", "confidence": 0.7080169916152954}]}, {"text": "With these better modeling techniques, state-of-the-art systems routinely report accuracy in the high 90%, and a few recent systems report accuracies of over 98% in F 1 score).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 81, "end_pos": 89, "type": "METRIC", "confidence": 0.9996084570884705}, {"text": "accuracies", "start_pos": 139, "end_pos": 149, "type": "METRIC", "confidence": 0.9968243837356567}, {"text": "F 1 score", "start_pos": 165, "end_pos": 174, "type": "METRIC", "confidence": 0.987649937470754}]}, {"text": "Chinese word segmentation is not a solved problem however and significant challenges remain.", "labels": [], "entities": [{"text": "Chinese word segmentation", "start_pos": 0, "end_pos": 25, "type": "TASK", "confidence": 0.5578396817048391}]}, {"text": "Advanced word segmentation systems perform very well in domains such as newswire where everyday language is used and there is a large amount of human annotated training data.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 9, "end_pos": 26, "type": "TASK", "confidence": 0.7119432836771011}]}, {"text": "There is often a rapid degradation in performance when systems trained on one domain (let us call it the source domain) are used to segment data in a different domain (let us call it the target domain).", "labels": [], "entities": []}, {"text": "This problem is especially severe when the target domain is distant from the source domain.", "labels": [], "entities": []}, {"text": "This is the problem we are facing when we perform word segmentation on Chinese patent data.", "labels": [], "entities": [{"text": "word segmentation on Chinese patent", "start_pos": 50, "end_pos": 85, "type": "TASK", "confidence": 0.7238904654979705}]}, {"text": "The word segmentation accuracy on Chinese patents is very poor if the word segmentation model is trained on the Chinese TreeBank data, which consists of data sources from a variety of genres but no patents.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 4, "end_pos": 21, "type": "TASK", "confidence": 0.7182424813508987}, {"text": "accuracy", "start_pos": 22, "end_pos": 30, "type": "METRIC", "confidence": 0.9060754776000977}, {"text": "word segmentation", "start_pos": 70, "end_pos": 87, "type": "TASK", "confidence": 0.704110711812973}, {"text": "Chinese TreeBank data", "start_pos": 112, "end_pos": 133, "type": "DATASET", "confidence": 0.930211623509725}]}, {"text": "To address this issue, we annotated a corpus of 142 patents which contain about 440K words according to the Chinese TreeBank standards.", "labels": [], "entities": [{"text": "Chinese TreeBank standards", "start_pos": 108, "end_pos": 134, "type": "DATASET", "confidence": 0.9081922968228658}]}, {"text": "We trained a character-tagging based CRF model for word segmentation, and based on the writing style of patents, we propose a group of document-level features as well as a novel character part-of-speech feature (C_POS).", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 51, "end_pos": 68, "type": "TASK", "confidence": 0.7690345346927643}]}, {"text": "Our results show these new features are effective and we are able to achieve an accuracy of 96.3% (F 1 score) on the development set and 95% (F 1 score) on the test set.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 80, "end_pos": 88, "type": "METRIC", "confidence": 0.9995906949043274}, {"text": "F 1 score)", "start_pos": 99, "end_pos": 109, "type": "METRIC", "confidence": 0.9781530350446701}, {"text": "F 1 score)", "start_pos": 142, "end_pos": 152, "type": "METRIC", "confidence": 0.9792689979076385}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Training, development and test data on  Patent data  Data set # of words # of patent  Training  345336  113  Devel.  46196  14  Test  48351  15", "labels": [], "entities": [{"text": "Patent data  Data set", "start_pos": 50, "end_pos": 71, "type": "DATASET", "confidence": 0.8688585609197617}, {"text": "Devel.  46196  14  Test  48351", "start_pos": 119, "end_pos": 149, "type": "DATASET", "confidence": 0.8545194665590922}]}, {"text": " Table 2: Segmentation performance with different feature sets on different datasets.", "labels": [], "entities": [{"text": "Segmentation", "start_pos": 10, "end_pos": 22, "type": "TASK", "confidence": 0.9709149599075317}]}]}