{"title": [{"text": "Learning a Lexical Simplifier Using Wikipedia", "labels": [], "entities": []}], "abstractContent": [{"text": "In this paper we introduce anew lexical simplification approach.", "labels": [], "entities": []}, {"text": "We extract over 30K candidate lexical simplifications by identifying aligned words in a sentence-aligned corpus of English Wikipedia with Simple English Wikipedia.", "labels": [], "entities": [{"text": "Simple English Wikipedia", "start_pos": 138, "end_pos": 162, "type": "DATASET", "confidence": 0.7854485313097636}]}, {"text": "To apply these rules, we learn a feature-based ranker using SVM rank trained on a set of labeled simplifications collected using Amazon's Mechanical Turk.", "labels": [], "entities": []}, {"text": "Using human simplifications for evaluation, we achieve a precision of 76% with changes in 86% of the examples.", "labels": [], "entities": [{"text": "precision", "start_pos": 57, "end_pos": 66, "type": "METRIC", "confidence": 0.9994014501571655}]}], "introductionContent": [{"text": "Text simplification is aimed at reducing the reading and grammatical complexity of text while retaining the meaning.", "labels": [], "entities": [{"text": "Text simplification", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.7898404896259308}]}, {"text": "Text simplification techniques have abroad range of applications centered around increasing data availability to both targeted audiences, such as children, language learners, and people with cognitive disabilities, as well as to general readers in technical domains such as health and medicine.", "labels": [], "entities": [{"text": "Text simplification", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.7827646434307098}]}, {"text": "Simplifying a text can require a wide range of transformation operations including lexical changes, syntactic changes, sentence splitting, deletion and elaboration (.", "labels": [], "entities": [{"text": "sentence splitting", "start_pos": 119, "end_pos": 137, "type": "TASK", "confidence": 0.7529430985450745}]}, {"text": "In this paper, we examine a restricted version of the text simplification problem, lexical simplification, where text is simplified by substituting words or phrases with simpler variants.", "labels": [], "entities": [{"text": "text simplification", "start_pos": 54, "end_pos": 73, "type": "TASK", "confidence": 0.7121742069721222}, {"text": "lexical simplification", "start_pos": 83, "end_pos": 105, "type": "TASK", "confidence": 0.7394444644451141}]}, {"text": "Even with this restriction, lexical simplification techniques have been shown to positively impact the simplicity of text and to improve reader understanding and information retention ( . Additionally, restricting the set of transformation operations allows for more straightforward evaluation than the general simplification problem ().", "labels": [], "entities": [{"text": "simplicity", "start_pos": 103, "end_pos": 113, "type": "METRIC", "confidence": 0.9837744235992432}, {"text": "reader understanding", "start_pos": 137, "end_pos": 157, "type": "TASK", "confidence": 0.8115173876285553}, {"text": "information retention", "start_pos": 162, "end_pos": 183, "type": "TASK", "confidence": 0.7403874695301056}]}, {"text": "Most lexical simplification techniques rely on transformation rules that change a word or phrase into a simpler variant with similar meaning.", "labels": [], "entities": []}, {"text": "Two main challenges exist for this type of approach.", "labels": [], "entities": []}, {"text": "First, the lexical focus of the transformation rules makes generalization difficult; a large number of transformation rules is required to achieve reasonable coverage and impact.", "labels": [], "entities": [{"text": "generalization", "start_pos": 59, "end_pos": 73, "type": "TASK", "confidence": 0.9676698446273804}]}, {"text": "Second, rules do not apply in all contexts and care must betaken when performing lexical transformations to ensure local cohesion, grammaticality and, most importantly, the preservation of the original meaning.", "labels": [], "entities": []}, {"text": "In this paper, we address both of these issues.", "labels": [], "entities": []}, {"text": "We leverage a data set of 137K aligned sentence pairs between English Wikipedia and Simple English Wikipedia to learn simplification rules.", "labels": [], "entities": [{"text": "English Wikipedia", "start_pos": 62, "end_pos": 79, "type": "DATASET", "confidence": 0.899544358253479}, {"text": "Simple English Wikipedia", "start_pos": 84, "end_pos": 108, "type": "DATASET", "confidence": 0.748019685347875}]}, {"text": "Previous approaches have used unaligned versions of Simple English Wikipedia to learn rules, however, by using the aligned version we are able to learn a much larger rule set.", "labels": [], "entities": [{"text": "Simple English Wikipedia", "start_pos": 52, "end_pos": 76, "type": "DATASET", "confidence": 0.766825258731842}]}, {"text": "To apply lexical simplification rules to anew sentence, a decision must be made about which, if any, transformations should be applied.", "labels": [], "entities": []}, {"text": "Previous approaches have used similarity measures (Biran et al., 2011) and feature-based approaches ( to make this decision.", "labels": [], "entities": []}, {"text": "We take the latter approach and train a supervised model to rank candidate transformations.", "labels": [], "entities": []}, {"text": "The first school was established in 1857.", "labels": [], "entities": []}, {"text": "The first school was started in 1857.", "labels": [], "entities": []}, {"text": "The district was established in 1993 by merging the former districts of Bernau and Eberswalde.", "labels": [], "entities": [{"text": "Bernau", "start_pos": 72, "end_pos": 78, "type": "DATASET", "confidence": 0.981620192527771}, {"text": "Eberswalde", "start_pos": 83, "end_pos": 93, "type": "DATASET", "confidence": 0.8175606727600098}]}, {"text": "The district was made in 1993 by joining the old districts of Bernau and Eberswalde.: Two aligned sentence pairs.", "labels": [], "entities": [{"text": "Bernau", "start_pos": 62, "end_pos": 68, "type": "DATASET", "confidence": 0.9794778823852539}]}, {"text": "The bottom sentence is a human simplified version of the top sentence.", "labels": [], "entities": []}, {"text": "Bold words are candidate lexical simplifications.", "labels": [], "entities": []}, {"text": "1. The bottom sentence of each pair is a simplified variant of the top sentence.", "labels": [], "entities": []}, {"text": "By identifying aligned words within the aligned sentences, candidate lexical simplifications can be learned.", "labels": [], "entities": []}, {"text": "The bold words show two such examples, though other candidates exist in the bottom pair.", "labels": [], "entities": []}, {"text": "By examining aligned sentence pairs we can learn a simplification rule.", "labels": [], "entities": []}, {"text": "For example, we might learn: established \u2192 began, made, settled, started Given a sentence s 1 , s 2 , ..., s n , a simplification rule applies if the left hand side of the rule can be found in the sentence (s i = w, for some i).", "labels": [], "entities": []}, {"text": "If a rule applies, then a decision must be made about which, if any, of the candidate simplifications should be substituted for the word w to simplify the sentence.", "labels": [], "entities": []}, {"text": "For example, if we were attempting to simplify the sentence The ACL was established in 1962.", "labels": [], "entities": []}, {"text": "using the simplification rule above, some of the simplification options would not apply because of grammatical constraints, e.g. began, while others would not apply for semantic reasons, e.g. settled.", "labels": [], "entities": []}, {"text": "This does not mean that these are not good simplifications for established since in other contexts, they might be appropriate.", "labels": [], "entities": []}, {"text": "For example, in the sentence began is a reasonable option.", "labels": [], "entities": []}], "datasetContent": [{"text": "We used the 500 ranked simplification examples to train and evaluate our approach.", "labels": [], "entities": []}, {"text": "We employed 10-fold cross validation for all experiments, training on 450 examples and testing on 50.", "labels": [], "entities": []}, {"text": "We evaluated the models with four different metrics: precision: Of the words that the system changed, what percentage were found in any of the human annotations.", "labels": [], "entities": [{"text": "precision", "start_pos": 53, "end_pos": 62, "type": "METRIC", "confidence": 0.9995997548103333}]}, {"text": "precision@k: Of the words that the system changed, what percentage were found in the top k human annotations, where the annotations were ranked by response frequency.", "labels": [], "entities": [{"text": "precision", "start_pos": 0, "end_pos": 9, "type": "METRIC", "confidence": 0.9904274940490723}]}, {"text": "For example, if we were calculating the precision@1 for the example in, only \"obtained\" would be considered correct.", "labels": [], "entities": [{"text": "precision", "start_pos": 40, "end_pos": 49, "type": "METRIC", "confidence": 0.9944183826446533}]}, {"text": "accuracy: The percentage of the test examples where the system made a change to one of the annotations suggested by the human annotators.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 0, "end_pos": 8, "type": "METRIC", "confidence": 0.9973951578140259}]}, {"text": "Note that unlike precision, if the system does not suggest a change to a word that was simplified it still gets penalized.", "labels": [], "entities": [{"text": "precision", "start_pos": 17, "end_pos": 26, "type": "METRIC", "confidence": 0.9992881417274475}]}, {"text": "changed: The percentage of the test examples where the system suggested some change (even if it wasn't a \"correct\" change).", "labels": [], "entities": []}, {"text": "shows the precision, accuracy and percent changed for the three systems.", "labels": [], "entities": [{"text": "precision", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9997833371162415}, {"text": "accuracy", "start_pos": 21, "end_pos": 29, "type": "METRIC", "confidence": 0.9995645880699158}]}, {"text": "Based on all three metrics, our system achieves the best results.", "labels": [], "entities": []}, {"text": "Although the rules generated by Biran et al. have reasonable precision, they suffer from alack of coverage, only making changes on about 5% of the: Candidate simplifications generated using MTurk for the examples in: Precision, accuracy and percent changed for the three systems, averaged over the 10 folds.", "labels": [], "entities": [{"text": "precision", "start_pos": 61, "end_pos": 70, "type": "METRIC", "confidence": 0.9992259740829468}, {"text": "coverage", "start_pos": 98, "end_pos": 106, "type": "METRIC", "confidence": 0.9969747066497803}, {"text": "MTurk", "start_pos": 190, "end_pos": 195, "type": "DATASET", "confidence": 0.8537772297859192}, {"text": "Precision", "start_pos": 217, "end_pos": 226, "type": "METRIC", "confidence": 0.9989123344421387}, {"text": "accuracy", "start_pos": 228, "end_pos": 236, "type": "METRIC", "confidence": 0.9994984865188599}]}], "tableCaptions": [{"text": " Table 2: Candidate simplifications generated using MTurk for the examples in", "labels": [], "entities": [{"text": "MTurk", "start_pos": 52, "end_pos": 57, "type": "DATASET", "confidence": 0.8493947982788086}]}, {"text": " Table 3: Precision, accuracy and percent changed  for the three systems, averaged over the 10 folds.", "labels": [], "entities": [{"text": "Precision", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9993245601654053}, {"text": "accuracy", "start_pos": 21, "end_pos": 29, "type": "METRIC", "confidence": 0.9997161030769348}, {"text": "percent changed", "start_pos": 34, "end_pos": 49, "type": "METRIC", "confidence": 0.829180508852005}]}]}