{"title": [{"text": "Simple Negation Scope Resolution through Deep Parsing: A Semantic Solution to a Semantic Problem", "labels": [], "entities": [{"text": "Negation Scope Resolution", "start_pos": 7, "end_pos": 32, "type": "TASK", "confidence": 0.7146670619646708}]}], "abstractContent": [{"text": "In this work, we revisit Shared Task 1 from the 2012 *SEM Conference: the automated analysis of negation.", "labels": [], "entities": [{"text": "Shared Task 1 from the 2012 *SEM Conference", "start_pos": 25, "end_pos": 68, "type": "DATASET", "confidence": 0.6645075049665239}]}, {"text": "Unlike the vast majority of participating systems in 2012, our approach works over explicit and formal representations of proposi-tional semantics, i.e. derives the notion of negation scope assumed in this task from the structure of logical-form meaning representations.", "labels": [], "entities": []}, {"text": "We relate the task-specific interpretation of (negation) scope to the concept of (quantifier and operator) scope in mainstream underspecified semantics.", "labels": [], "entities": []}, {"text": "With reference to an explicit encoding of semantic predicate-argument structure, we can operationalize the annotation decisions made for the 2012 *SEM task, and demonstrate how a comparatively simple system for negation scope resolution can be built from an off-the-shelf deep parsing system.", "labels": [], "entities": [{"text": "SEM task", "start_pos": 147, "end_pos": 155, "type": "TASK", "confidence": 0.4992218017578125}, {"text": "negation scope resolution", "start_pos": 211, "end_pos": 236, "type": "TASK", "confidence": 0.9147014816602071}]}, {"text": "Ina system combination setting, our approach improves over the best published results on this task to date.", "labels": [], "entities": []}], "introductionContent": [{"text": "Recently, there has been increased community interest in the theoretical and practical analysis of what Morante and Sporleder (2012) call modality and negation, i.e. linguistic expressions that modulate the certainty or factuality of propositions.", "labels": [], "entities": []}, {"text": "Automated analysis of such aspects of meaning is important for natural language processing tasks which need to consider the truth value of statements, such as for example text mining () or sentiment analysis ().", "labels": [], "entities": [{"text": "Automated analysis of such aspects of meaning", "start_pos": 0, "end_pos": 45, "type": "TASK", "confidence": 0.7960971338408334}, {"text": "text mining", "start_pos": 171, "end_pos": 182, "type": "TASK", "confidence": 0.767031729221344}, {"text": "sentiment analysis", "start_pos": 189, "end_pos": 207, "type": "TASK", "confidence": 0.9429288804531097}]}, {"text": "Owing to its immediate utility in the curation of scholarly results, the analysis of negation and so-called hedges in bio-medical research literature has been the focus of several workshops, as well as the Shared Task at the 2011 Conference on Computational Language Learning (CoNLL).", "labels": [], "entities": [{"text": "Shared Task at the 2011 Conference on Computational Language Learning (CoNLL)", "start_pos": 206, "end_pos": 283, "type": "TASK", "confidence": 0.7086737522712121}]}, {"text": "Task 1 at the First Joint Conference on) provided afresh, principled annotation of negation and called for systems to analyze negation-detecting cues (affixes, words, or phrases that express negation), resolving their scopes (which parts of a sentence are actually negated), and identifying the negated event or property.", "labels": [], "entities": []}, {"text": "The task organizers designed and documented an annotation scheme and applied it to a little more than 100,000 tokens of running text by the novelist Sir Arthur Conan Doyle.", "labels": [], "entities": []}, {"text": "While the task and annotations were framed from a semantic perspective, only one participating system actually employed explicit compositional semantics (, with results ranking in the middle of the 12 participating systems.", "labels": [], "entities": []}, {"text": "Conversely, the bestperforming systems approached the task through machine learning or heuristic processing over syntactic and linguistically relatively coarse-grained representations; see \u00a7 2 below.", "labels": [], "entities": []}, {"text": "Example (1), where marks the cue and {} the in-scope elements, illustrates the annotations, including how negation inside a noun phrase can scope over discontinuous parts of the sentence.", "labels": [], "entities": []}, {"text": "(1) {The German} was sent for but professed to {know} nothing {of the matter}.", "labels": [], "entities": []}, {"text": "In this work, we return to the 2012 *SEM task from a deliberately semantics-centered point of view, focusing on the hardest of the three sub-problems: scope resolution.", "labels": [], "entities": [{"text": "SEM task", "start_pos": 37, "end_pos": 45, "type": "TASK", "confidence": 0.6218301057815552}, {"text": "scope resolution", "start_pos": 151, "end_pos": 167, "type": "TASK", "confidence": 0.829826295375824}]}, {"text": "Where Morante and characterize negation as an \"extra-propositional aspect of meaning\" (p.", "labels": [], "entities": []}, {"text": "1563), Our running example is a truncated variant of an item from the Shared Task training data.", "labels": [], "entities": [{"text": "Shared Task training data", "start_pos": 70, "end_pos": 95, "type": "DATASET", "confidence": 0.6363174691796303}]}, {"text": "The remainder of the original sentence does not form part of the scope of this cue.", "labels": [], "entities": []}, {"text": "Resolving negation scope is a more difficult sub-problem at least in part because (unlike cue and event identification) it is concerned with much larger, non-local and often discontinuous parts of each utterance.", "labels": [], "entities": [{"text": "Resolving negation scope", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.9405656655629476}, {"text": "event identification", "start_pos": 98, "end_pos": 118, "type": "TASK", "confidence": 0.7331451326608658}]}, {"text": "This intuition is confirmed by, who report results for each sub-problem using gold-standard inputs; in this setup, scope resolution showed by far the lowest performance levels.", "labels": [], "entities": []}, {"text": "we in fact see it as a core piece of compositionally constructed logical-form representations.", "labels": [], "entities": []}, {"text": "Though the task-specific concept of scope of negation is not the same as the notion of quantifier and operator scope in mainstream underspecified semantics, we nonetheless find that reviewing the 2012 *SEM Shared Task annotations with reference to an explicit encoding of semantic predicate-argument structure suggests a simple and straightforward operationalization of their concept of negation scope.", "labels": [], "entities": []}, {"text": "Our system implements these findings through a notion of functorargument 'crawling', using as our starting point the underspecified logical-form meaning representations provided by a general-purpose deep parser.", "labels": [], "entities": []}, {"text": "Our contributions are three-fold: Theoretically, we correlate the structures at play in the Morante and Daelemans (2012) view on negation with formal semantic analyses; methodologically, we demonstrate how to approach the task in terms of underspecified, logical-form semantics; and practically, our combined system retroactively 'wins' the 2012 *SEM Shared Task.", "labels": [], "entities": [{"text": "SEM Shared Task", "start_pos": 347, "end_pos": 362, "type": "TASK", "confidence": 0.5577841202418009}]}, {"text": "In the following sections, we review related work ( \u00a7 2), detail our own setup ( \u00a7 3), and present and discuss our experimental results ( \u00a7 4 and \u00a7 5, respectively).", "labels": [], "entities": []}], "datasetContent": [{"text": "We evaluated the performance of our system using the Shared Task development and evaluation data (respectively CDD and CDE in).", "labels": [], "entities": []}, {"text": "Since we do not attempt to perform cue detection, we report performance using gold cues and also using the system cues predicted by.", "labels": [], "entities": [{"text": "cue detection", "start_pos": 35, "end_pos": 48, "type": "TASK", "confidence": 0.8468281328678131}]}, {"text": "We used the official Shared Task evaluation script to compute all scores.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Scope resolution performance of various configurations over each subset of the Shared Task  data. Ranker refers to the system of Read et al.", "labels": [], "entities": [{"text": "Scope resolution", "start_pos": 10, "end_pos": 26, "type": "TASK", "confidence": 0.8491321504116058}]}, {"text": " Table 2: Comparison to Basile et al. (2012).", "labels": [], "entities": [{"text": "Basile et al. (2012)", "start_pos": 24, "end_pos": 44, "type": "DATASET", "confidence": 0.8550844618252346}]}]}