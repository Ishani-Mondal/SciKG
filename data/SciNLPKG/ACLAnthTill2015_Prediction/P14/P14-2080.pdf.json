{"title": [{"text": "Learning Translational and Knowledge-based Similarities from Relevance Rankings for Cross-Language Retrieval", "labels": [], "entities": [{"text": "Learning Translational and Knowledge-based Similarities", "start_pos": 0, "end_pos": 55, "type": "TASK", "confidence": 0.6277300953865051}, {"text": "Cross-Language Retrieval", "start_pos": 84, "end_pos": 108, "type": "TASK", "confidence": 0.8100392818450928}]}], "abstractContent": [{"text": "We present an approach to cross-language retrieval that combines dense knowledge-based features and sparse word translations.", "labels": [], "entities": [{"text": "cross-language retrieval", "start_pos": 26, "end_pos": 50, "type": "TASK", "confidence": 0.8450159132480621}]}, {"text": "Both feature types are learned directly from relevance rankings of bilingual documents in a pairwise ranking framework.", "labels": [], "entities": []}, {"text": "In large-scale experiments for patent prior art search and cross-lingual retrieval in Wikipedia, our approach yields considerable improvements over learning-to-rank with either only dense or only sparse features, and over very competitive baselines that combine state-of-the-art machine translation and retrieval.", "labels": [], "entities": [{"text": "cross-lingual retrieval", "start_pos": 59, "end_pos": 82, "type": "TASK", "confidence": 0.7393226325511932}, {"text": "machine translation", "start_pos": 279, "end_pos": 298, "type": "TASK", "confidence": 0.7561795115470886}]}], "introductionContent": [{"text": "Cross-Language Information Retrieval (CLIR) for the domain of web search successfully leverages state-of-the-art Statistical Machine Translation (SMT) to either produce a single most probable translation, or a weighted list of alternatives, that is used as search query to a standard search engine ().", "labels": [], "entities": [{"text": "Cross-Language Information Retrieval (CLIR", "start_pos": 0, "end_pos": 42, "type": "TASK", "confidence": 0.7332091152667999}, {"text": "Statistical Machine Translation (SMT)", "start_pos": 113, "end_pos": 150, "type": "TASK", "confidence": 0.8201055924097697}]}, {"text": "This approach is advantageous if large amounts of indomain sentence-parallel data are available to train SMT systems, but relevance rankings to train retrieval models are not.", "labels": [], "entities": [{"text": "SMT", "start_pos": 105, "end_pos": 108, "type": "TASK", "confidence": 0.9833080768585205}]}, {"text": "The situation is different for CLIR in special domains such as patents or Wikipedia.", "labels": [], "entities": []}, {"text": "Parallel data for translation have to be extracted with some effort from comparable or noisy parallel data (, however, relevance judgments are often straightforwardly encoded in special domains.", "labels": [], "entities": [{"text": "translation", "start_pos": 18, "end_pos": 29, "type": "TASK", "confidence": 0.9805728793144226}]}, {"text": "For example, in patent prior art search, patents granted at any patent office worldwide are considered relevant if they constitute prior art with respect to the invention claimed in the query patent.", "labels": [], "entities": [{"text": "patent prior art search", "start_pos": 16, "end_pos": 39, "type": "TASK", "confidence": 0.5871883630752563}]}, {"text": "Since patent applicants and lawyers are required to list relevant prior work explicitly in the patent application, patent citations can be used to automatically extract large amounts of relevance judgments across languages (.", "labels": [], "entities": []}, {"text": "In Wikipedia search, one can imagine a Wikipedia author trying to investigate whether a Wikipedia article covering the subject the author intends to write about already exists in another language.", "labels": [], "entities": []}, {"text": "Since authors are encouraged to avoid orphan articles and to cite their sources, Wikipedia has a rich linking structure between related articles, which can be exploited to create relevance links between articles across languages (.", "labels": [], "entities": []}, {"text": "Besides a rich citation structure, patent documents and Wikipedia articles contain a number of further cues on relatedness that can be exploited as features in learning-to-rank approaches.", "labels": [], "entities": []}, {"text": "For monolingual patent retrieval, and advocate the use of dense features encoding domain knowledge on inventors, assignees, location and date, together with dense similarity scores based on bag-of-word representations of patents.", "labels": [], "entities": [{"text": "monolingual patent retrieval", "start_pos": 4, "end_pos": 32, "type": "TASK", "confidence": 0.6609116792678833}]}, {"text": "show that for the domain of Wikipedia, learning a sparse matrix of word associations between the query and document vocabularies from relevance rankings is useful in monolingual and cross-lingual retrieval.", "labels": [], "entities": []}, {"text": "apply the idea of learning a sparse matrix of bilingual phrase associations from relevance rankings to cross-lingual retrieval in the patent domain.", "labels": [], "entities": [{"text": "cross-lingual retrieval", "start_pos": 103, "end_pos": 126, "type": "TASK", "confidence": 0.7187277972698212}]}, {"text": "Both show improvements of learning-to-rank on relevance data over SMTbased approaches on their respective domains.", "labels": [], "entities": [{"text": "SMTbased", "start_pos": 66, "end_pos": 74, "type": "TASK", "confidence": 0.9575024247169495}]}, {"text": "The main contribution of this paper is a thorough evaluation of dense and sparse features for learning-to-rank that have so far been used only monolingually or only on either patents or Wikipedia.", "labels": [], "entities": []}, {"text": "We show that for both domains, patents and Wikipedia, jointly learning bilingual sparse word associations and dense knowledgebased similarities directly on relevance ranked data improves significantly over approaches that use either only sparse or only dense features, and over approaches that combine query translation by SMT with standard retrieval in the target language.", "labels": [], "entities": [{"text": "query translation", "start_pos": 302, "end_pos": 319, "type": "TASK", "confidence": 0.7162978500127792}, {"text": "SMT", "start_pos": 323, "end_pos": 326, "type": "TASK", "confidence": 0.7858664989471436}]}, {"text": "Furthermore, we show that our approach can be seen as supervised model combination that allows to combine SMT-based and rankingbased approaches for further substantial improvements.", "labels": [], "entities": [{"text": "SMT-based", "start_pos": 106, "end_pos": 115, "type": "TASK", "confidence": 0.9880244135856628}]}, {"text": "We conjecture that the gains are due to orthogonal information contributed by domainknowledge, ranking-based word associations, and translation-based information.", "labels": [], "entities": []}], "datasetContent": [{"text": "The SMT-based models use cdec (. Word alignments were created with mgiza (JP-EN) and fast align) (DE-EN).", "labels": [], "entities": [{"text": "SMT-based", "start_pos": 4, "end_pos": 13, "type": "TASK", "confidence": 0.9812405705451965}]}, {"text": "Language models were trained with the KenLM toolkit).", "labels": [], "entities": [{"text": "KenLM toolkit", "start_pos": 38, "end_pos": 51, "type": "DATASET", "confidence": 0.7396219372749329}]}, {"text": "The JP-EN system uses a 5-gram language model from the EN side of the training data.", "labels": [], "entities": []}, {"text": "For the DE-EN system, a 4-gram model was built on the EN side of the training data and the EN Wikipedia documents.", "labels": [], "entities": [{"text": "EN Wikipedia documents", "start_pos": 91, "end_pos": 113, "type": "DATASET", "confidence": 0.9118981758753458}]}, {"text": "Weights for the standard feature set were optimized using cdec's MERT (JP-EN) and MIRA (DE-EN) implementations.", "labels": [], "entities": [{"text": "MERT", "start_pos": 65, "end_pos": 69, "type": "METRIC", "confidence": 0.9654860496520996}, {"text": "MIRA", "start_pos": 82, "end_pos": 86, "type": "METRIC", "confidence": 0.9473551511764526}]}, {"text": "PSQ on patents reuses settings found by; settings for Wikipedia were adjusted on its dev set (n=1000, \u03bb=0.4, L=0, C=1).", "labels": [], "entities": [{"text": "PSQ", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.8445026874542236}]}, {"text": "Patent retrieval for DT was done by sentencewise translation and subsequent re-joining to form one query per patent, which was ranked against the documents using BM25.", "labels": [], "entities": [{"text": "Patent retrieval", "start_pos": 0, "end_pos": 16, "type": "TASK", "confidence": 0.6680561304092407}, {"text": "DT", "start_pos": 21, "end_pos": 23, "type": "TASK", "confidence": 0.8470722436904907}, {"text": "sentencewise translation", "start_pos": 36, "end_pos": 60, "type": "TASK", "confidence": 0.6571463793516159}, {"text": "BM25", "start_pos": 162, "end_pos": 166, "type": "DATASET", "confidence": 0.9401523470878601}]}, {"text": "For PSQ, BM25 is computed on expected term and document frequencies.", "labels": [], "entities": [{"text": "PSQ", "start_pos": 4, "end_pos": 7, "type": "TASK", "confidence": 0.893856942653656}, {"text": "BM25", "start_pos": 9, "end_pos": 13, "type": "METRIC", "confidence": 0.9974433183670044}]}, {"text": "For ranking-based retrieval, we compare several combinations of learners and features.", "labels": [], "entities": []}, {"text": "VW denotes a sparse model using word-based features trained with SGD.", "labels": [], "entities": [{"text": "VW", "start_pos": 0, "end_pos": 2, "type": "DATASET", "confidence": 0.873839259147644}]}, {"text": "BM denotes a similar model trained using Boosting.", "labels": [], "entities": [{"text": "BM", "start_pos": 0, "end_pos": 2, "type": "METRIC", "confidence": 0.8723477721214294}, {"text": "Boosting", "start_pos": 41, "end_pos": 49, "type": "DATASET", "confidence": 0.8255875110626221}]}, {"text": "DK denotes VW training of a model that represents queries q and documents d by dense domain-knowledge features instead of by sparse word-based vectors.", "labels": [], "entities": [{"text": "DK", "start_pos": 0, "end_pos": 2, "type": "DATASET", "confidence": 0.8048669099807739}]}, {"text": "In order to simulate pass-through behavior of out-ofvocabulary terms in SMT systems, additional features accounting for source and target term identity were added to DK and BM models.", "labels": [], "entities": [{"text": "SMT", "start_pos": 72, "end_pos": 75, "type": "TASK", "confidence": 0.9852787256240845}]}, {"text": "The parameter \u03bb for VW was found on dev set.", "labels": [], "entities": [{"text": "VW", "start_pos": 20, "end_pos": 22, "type": "DATASET", "confidence": 0.8178412318229675}]}, {"text": "Statistical significance testing was performed using the paired randomization test.", "labels": [], "entities": []}, {"text": "Borda denotes model combination by Borda Count voting where the linear interpolation parameter is adjusted for MAP on the respective development sets with grid search.", "labels": [], "entities": [{"text": "MAP", "start_pos": 111, "end_pos": 114, "type": "METRIC", "confidence": 0.9144816398620605}]}, {"text": "This type of model combination only allows to combine pairs of rankings.", "labels": [], "entities": []}, {"text": "We present a combination of SMTbased CLIR, DT+PSQ, a combination of dense and sparse features, DK+VW, and a combination of both combinations, (DT+PSQ)+(DK+VW).", "labels": [], "entities": [{"text": "SMTbased CLIR", "start_pos": 28, "end_pos": 41, "type": "TASK", "confidence": 0.7537249028682709}]}, {"text": "LinLearn denotes model combination by overloading the vector representation of queries q and documents din the VW linear learner by incorporating arbitrary ranking models as dense features.", "labels": [], "entities": [{"text": "VW linear learner", "start_pos": 111, "end_pos": 128, "type": "DATASET", "confidence": 0.899191419283549}]}, {"text": "In difference to grid search for Borda, optimal weights for the linear combination of incorporated ranking models can be learned automatically.", "labels": [], "entities": [{"text": "Borda", "start_pos": 33, "end_pos": 38, "type": "DATASET", "confidence": 0.9141930341720581}]}, {"text": "We investigate the same combinations of ranking models as described for Borda above.", "labels": [], "entities": []}, {"text": "We do not report combination results including the sparse BM model since they were consistently lower than the ones with the sparse VW model.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Ranking data statistics: number of queries and doc- uments, avg. number of relevant documents per query, avg.  number of words per query.", "labels": [], "entities": []}, {"text": " Table 2: Test results for standalone CLIR models using di- rect translation (DT), probabilistic structured queries (PSQ),  sparse model with CFH (VW), sparse boosting model (BM),  dense domain knowledge features (DK), and model combi- nations using Borda Count voting (Borda) or linear super- vised model combination (LinLearn). Significant differences  (at p=0.01) between aggregated systems and all its compo- nents are indicated by  * , between LinLearn and the respective  Borda system by  \u2020.", "labels": [], "entities": []}]}