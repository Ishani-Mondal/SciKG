{"title": [{"text": "Bilingual Event Extraction: a Case Study on Trigger Type Determina- tion", "labels": [], "entities": [{"text": "Bilingual Event Extraction", "start_pos": 0, "end_pos": 26, "type": "TASK", "confidence": 0.815294067064921}, {"text": "Trigger Type Determina- tion", "start_pos": 44, "end_pos": 72, "type": "TASK", "confidence": 0.854145860671997}]}], "abstractContent": [{"text": "Event extraction generally suffers from the data sparseness problem.", "labels": [], "entities": [{"text": "Event extraction", "start_pos": 0, "end_pos": 16, "type": "TASK", "confidence": 0.8308272659778595}]}, {"text": "In this paper, we address this problem by utilizing the labeled data from two different languages.", "labels": [], "entities": []}, {"text": "As a preliminary study, we mainly focus on the sub-task of trigger type determination in event extraction.", "labels": [], "entities": [{"text": "trigger type determination", "start_pos": 59, "end_pos": 85, "type": "TASK", "confidence": 0.6087571779886881}, {"text": "event extraction", "start_pos": 89, "end_pos": 105, "type": "TASK", "confidence": 0.7857740521430969}]}, {"text": "To make the training data in different languages help each other, we propose a uniform text representation with bilingual features to represent the samples and handle the difficulty of locating the triggers in the translated text from both monolingual and bilingual perspectives.", "labels": [], "entities": []}, {"text": "Empirical studies demonstrate the effectiveness of the proposed approach to bilingual classification on trigger type determination.", "labels": [], "entities": [{"text": "bilingual classification", "start_pos": 76, "end_pos": 100, "type": "TASK", "confidence": 0.7015915960073471}, {"text": "trigger type determination", "start_pos": 104, "end_pos": 130, "type": "TASK", "confidence": 0.7369981408119202}]}], "introductionContent": [{"text": "Event extraction is an increasingly hot and challenging research topic in the natural language processing (NLP) community.", "labels": [], "entities": [{"text": "Event extraction", "start_pos": 0, "end_pos": 16, "type": "TASK", "confidence": 0.8345656096935272}]}, {"text": "It aims to automatically extract certain types of events with the arguments to present the texts under a structured form.", "labels": [], "entities": []}, {"text": "In event extraction, there are four primary subtasks, named trigger identification, trigger type determination, argument identification, and argument role determination.", "labels": [], "entities": [{"text": "event extraction", "start_pos": 3, "end_pos": 19, "type": "TASK", "confidence": 0.7802624702453613}, {"text": "trigger identification", "start_pos": 60, "end_pos": 82, "type": "TASK", "confidence": 0.6876559406518936}, {"text": "trigger type determination", "start_pos": 84, "end_pos": 110, "type": "TASK", "confidence": 0.6123951077461243}, {"text": "argument identification", "start_pos": 112, "end_pos": 135, "type": "TASK", "confidence": 0.7747567296028137}, {"text": "argument role determination", "start_pos": 141, "end_pos": 168, "type": "TASK", "confidence": 0.6493363678455353}]}, {"text": "As an important technology in information extraction, event extraction could be applied to many fields such as information retrieval, summarization, text mining, and question answering.", "labels": [], "entities": [{"text": "information extraction", "start_pos": 30, "end_pos": 52, "type": "TASK", "confidence": 0.8676990568637848}, {"text": "event extraction", "start_pos": 54, "end_pos": 70, "type": "TASK", "confidence": 0.8199493587017059}, {"text": "information retrieval", "start_pos": 111, "end_pos": 132, "type": "TASK", "confidence": 0.7954234480857849}, {"text": "summarization", "start_pos": 134, "end_pos": 147, "type": "TASK", "confidence": 0.9872255921363831}, {"text": "text mining", "start_pos": 149, "end_pos": 160, "type": "TASK", "confidence": 0.8135518133640289}, {"text": "question answering", "start_pos": 166, "end_pos": 184, "type": "TASK", "confidence": 0.9155450463294983}]}, {"text": "Recently, the dominative approach to event extraction is based on supervised learning where a set of labeled samples are exploited to train a model to extract the events.", "labels": [], "entities": [{"text": "event extraction", "start_pos": 37, "end_pos": 53, "type": "TASK", "confidence": 0.7542787790298462}]}, {"text": "However, the availa-\uf020 * Corresponding author ble labeled data are rather sparse due to various kinds of event categories.", "labels": [], "entities": [{"text": "availa-\uf020 * Corresponding author ble labeled", "start_pos": 13, "end_pos": 56, "type": "METRIC", "confidence": 0.8518801842417035}]}, {"text": "For example, the event taxonomy in ACE 2005 1 (Automatic Content Extraction) includes 8 types of events, with 33 subtypes, such as \"Marry/Life\" (subtype/type), and \"Transport/Movement\".", "labels": [], "entities": [{"text": "ACE 2005 1", "start_pos": 35, "end_pos": 45, "type": "DATASET", "confidence": 0.8856961528460184}, {"text": "Automatic Content Extraction)", "start_pos": 47, "end_pos": 76, "type": "TASK", "confidence": 0.7515632659196854}, {"text": "Transport/Movement", "start_pos": 165, "end_pos": 183, "type": "TASK", "confidence": 0.6799911459287008}]}, {"text": "Moreover, some subtypes such as \"Nominate/Personnel\" and \"Convict/Justice\" contain less than 10 labeled samples in the English and Chinese corpus respectively.", "labels": [], "entities": []}, {"text": "Apparently, such a small scale of training data is difficult to yield a satisfying performance.", "labels": [], "entities": []}, {"text": "One possible way to alleviate the data sparseness problem in event extraction is to conduct bilingual event extraction with training data from two different languages.", "labels": [], "entities": [{"text": "event extraction", "start_pos": 61, "end_pos": 77, "type": "TASK", "confidence": 0.8258824944496155}, {"text": "bilingual event extraction", "start_pos": 92, "end_pos": 118, "type": "TASK", "confidence": 0.6368300418059031}]}, {"text": "This is motivated by the fact that labeled data from a language is highly possible to convey similar information in another language.", "labels": [], "entities": []}, {"text": "For example, E1 is an event sample from the English corpus and E2 is another one in the Chinese corpus.", "labels": [], "entities": [{"text": "English corpus", "start_pos": 44, "end_pos": 58, "type": "DATASET", "confidence": 0.8785202205181122}]}, {"text": "Apparently, E1 and the English translation text of E2, share some important clues such as meet and Iraq which highly indicates the event type of \"Meet/Contact\".", "labels": [], "entities": [{"text": "E1", "start_pos": 12, "end_pos": 14, "type": "DATASET", "confidence": 0.9009628891944885}, {"text": "Iraq", "start_pos": 99, "end_pos": 103, "type": "METRIC", "confidence": 0.9689449667930603}]}, {"text": "In this paper, we address the data sparseness problem in event extraction with a bilingual pro-cessing approach which aims to exploit bilingual training data to enhance the extraction performance in each language.", "labels": [], "entities": [{"text": "event extraction", "start_pos": 57, "end_pos": 73, "type": "TASK", "confidence": 0.7573488056659698}]}, {"text": "As a preliminary work, we mainly focus on the subtask of trigger type determination.", "labels": [], "entities": [{"text": "trigger type determination", "start_pos": 57, "end_pos": 83, "type": "TASK", "confidence": 0.8682700196901957}]}, {"text": "Accordingly, our goal is to design a classifier which is trained with labeled data from two different languages and is capable of classifying the test data from both languages.", "labels": [], "entities": []}, {"text": "Generally, this task possesses two main challenges.", "labels": [], "entities": []}], "datasetContent": [{"text": "Data sets: The Chinese and English corpus for even extraction are from ACE2005, which involves 8 types and 33 subtypes.", "labels": [], "entities": [{"text": "even extraction", "start_pos": 46, "end_pos": 61, "type": "TASK", "confidence": 0.6413355767726898}, {"text": "ACE2005", "start_pos": 71, "end_pos": 78, "type": "DATASET", "confidence": 0.9749138355255127}]}, {"text": "All our experiments are conducted on the subtype case.", "labels": [], "entities": []}, {"text": "Due to the space limit, we only report the statistics for each type, as shown in  Classification algorithm: The maximum entropy (ME) classifier is implemented with the public tool, Mallet Toolkits 3 . Evaluation metric: The performance of event type recognition is evaluated with F-score.", "labels": [], "entities": [{"text": "maximum entropy (ME)", "start_pos": 112, "end_pos": 132, "type": "METRIC", "confidence": 0.6573797225952148}, {"text": "event type recognition", "start_pos": 239, "end_pos": 261, "type": "TASK", "confidence": 0.6732040445009867}, {"text": "F-score", "start_pos": 280, "end_pos": 287, "type": "METRIC", "confidence": 0.9969409108161926}]}, {"text": "In this section, we evaluate the performance of our approach to bilingual classification on trigger type determination.", "labels": [], "entities": [{"text": "bilingual classification", "start_pos": 64, "end_pos": 88, "type": "TASK", "confidence": 0.7003927528858185}, {"text": "trigger type determination", "start_pos": 92, "end_pos": 118, "type": "TASK", "confidence": 0.7020422617594401}]}, {"text": "For comparison, following approaches are implemented: \uf0d8 Monolingual: perform monolingual classification on the Chinese and English corpus individually, as shown in.", "labels": [], "entities": []}, {"text": "\uf0d8 Bilingual: perform bilingual classification with partial bilingual features, ignoring the context features (e.g., context words, context entities) under the assumption that the trigger location task is not done.", "labels": [], "entities": []}, {"text": "\uf0d8 Bilingual_location: perform bilingual classification by translating each sample into another language and using a uniform representation with all bilingual features as shown in Section 3.2.", "labels": [], "entities": [{"text": "bilingual classification", "start_pos": 30, "end_pos": 54, "type": "TASK", "confidence": 0.6997843980789185}]}, {"text": "This is exactly our approach.", "labels": [], "entities": []}, {"text": "The number of the context words and entities before or after the trigger words is set as 3.", "labels": [], "entities": []}, {"text": "shows the classification results of the three approaches on the Chinese and English test data.", "labels": [], "entities": [{"text": "Chinese and English test data", "start_pos": 64, "end_pos": 93, "type": "DATASET", "confidence": 0.7043367087841034}]}, {"text": "From this figure, we can see that Bilingual_location apparently outperform Monolingual, which verifies the effectiveness of using bilingual corpus.", "labels": [], "entities": []}, {"text": "Specifically, the improvement by our approach in Chinese is impressive, reaching 7.6%.", "labels": [], "entities": []}, {"text": "The results also demonstrate the importance of the operation of the trigger location, without which, bilingual classification can only slightly improve the performance, as shown in the English test data.", "labels": [], "entities": [{"text": "bilingual classification", "start_pos": 101, "end_pos": 125, "type": "TASK", "confidence": 0.6713912934064865}, {"text": "English test data", "start_pos": 185, "end_pos": 202, "type": "DATASET", "confidence": 0.7661902209122976}]}, {"text": "The results demonstrate that our bilingual classification approaches are more effective for the Chinese data.", "labels": [], "entities": []}, {"text": "This is understandable because the size of English data is much larger than that of Chinese data, 5285 vs. 2710, as shown in Table 2.", "labels": [], "entities": []}, {"text": "Specifically, after checking the results in each subtype, we find that some subtypes in Chinese have very few samples while corresponding subtypes in English have a certain number samples.", "labels": [], "entities": []}, {"text": "For example, the subtype of \"Elect/Personnel\" only contains 30 samples in the Chinese data while 161 samples can be found in the English data, which leads a very high improvement (15.4%) for the Chinese test data.", "labels": [], "entities": [{"text": "Chinese data", "start_pos": 78, "end_pos": 90, "type": "DATASET", "confidence": 0.8105202913284302}, {"text": "Chinese test data", "start_pos": 195, "end_pos": 212, "type": "DATASET", "confidence": 0.7703172365824381}]}, {"text": "In summary, our bilingual classification approach provides an effective way to handle the data sparseness problem in even extraction.", "labels": [], "entities": [{"text": "bilingual classification", "start_pos": 16, "end_pos": 40, "type": "TASK", "confidence": 0.6988708972930908}, {"text": "even extraction", "start_pos": 117, "end_pos": 132, "type": "TASK", "confidence": 0.7544632256031036}]}], "tableCaptions": [{"text": " Table 2. For each subtype,  80% samples are used as training data while the  rest are as test data.", "labels": [], "entities": []}, {"text": " Table 2: Statistics in each event type in both Chinese  and English data sets", "labels": [], "entities": []}]}