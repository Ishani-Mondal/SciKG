{"title": [{"text": "Improved Typesetting Models for Historical OCR", "labels": [], "entities": [{"text": "Improved Typesetting", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.8346291184425354}, {"text": "OCR", "start_pos": 43, "end_pos": 46, "type": "TASK", "confidence": 0.548085629940033}]}], "abstractContent": [{"text": "We present richer typesetting models that extend the unsupervised historical document recognition system of Berg-Kirkpatrick et al.", "labels": [], "entities": [{"text": "historical document recognition", "start_pos": 66, "end_pos": 97, "type": "TASK", "confidence": 0.6251530547936758}]}, {"text": "The first model breaks the independence assumption between vertical offsets of neighboring glyphs and, in experiments, substantially decreases transcription error rates.", "labels": [], "entities": []}, {"text": "The second model simultaneously learns multiple font styles and, as a result, is able to accurately track italic and non-italic portions of documents.", "labels": [], "entities": []}, {"text": "Richer models complicate inference so we present anew, streamlined procedure that is over 25x faster than the method used by Berg-Kirkpatrick et al.", "labels": [], "entities": []}, {"text": "Our final system achieves a relative word error reduction of 22% compared to state-of-the-art results on a dataset of historical newspapers .", "labels": [], "entities": [{"text": "word error reduction", "start_pos": 37, "end_pos": 57, "type": "METRIC", "confidence": 0.6887123584747314}]}], "introductionContent": [{"text": "Modern OCR systems perform poorly on historical documents from the printing-press era, often yielding error rates that are too high for downstream research projects (.", "labels": [], "entities": [{"text": "error rates", "start_pos": 102, "end_pos": 113, "type": "METRIC", "confidence": 0.959892600774765}]}, {"text": "The two primary reasons that historical documents present difficultly for automatic systems are (1) the typesetting process used to produce such documents was extremely noisy and (2) the fonts used in the documents are unknown.", "labels": [], "entities": []}, {"text": "proposed a system for historical OCR that generatively models the noisy typesetting process of printing-press era documents and learns the font for each input document in an unsupervised fashion.", "labels": [], "entities": [{"text": "OCR", "start_pos": 33, "end_pos": 36, "type": "TASK", "confidence": 0.8498220443725586}]}, {"text": "Their system achieves state-of-the-art results on the task of historical document recognition.", "labels": [], "entities": [{"text": "historical document recognition", "start_pos": 62, "end_pos": 93, "type": "TASK", "confidence": 0.6816219786802927}]}, {"text": "We take the system of Berg- as a starting point and consider extensions of the typesetting model that address two shortcomings of their model: (1) their layout model assumes that baseline offset noise is independent for each glyph and (2) their font model assumes a single font is used in every document.", "labels": [], "entities": []}, {"text": "Both of these assumptions are untrue in many historical datasets.", "labels": [], "entities": []}, {"text": "The baseline of the text in printing-press era documents is not rigid as in modern documents but rather drifts up and down noisily (see).", "labels": [], "entities": [{"text": "baseline", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.9546085000038147}]}, {"text": "In practice, the vertical offsets of character glyphs change gradually along a line.", "labels": [], "entities": []}, {"text": "This means the vertical offsets of neighboring glyphs are correlated, a relationship that is not captured by the original model.", "labels": [], "entities": []}, {"text": "In our first extension, we let the vertical offsets of character glyphs be generated from a Markov chain, penalizing large changes in offset.", "labels": [], "entities": []}, {"text": "We find that this extension decreases transcription error rates.", "labels": [], "entities": [{"text": "transcription error rates", "start_pos": 38, "end_pos": 63, "type": "METRIC", "confidence": 0.6676189104715983}]}, {"text": "Our system achieves a relative word error reduction of 22% compared to the state-ofthe-art original model on a test set of historical newspapers (see Section 4.1), and a 11% relative reduction on a test set of historical court proceedings.", "labels": [], "entities": [{"text": "word error reduction", "start_pos": 31, "end_pos": 51, "type": "METRIC", "confidence": 0.7269193828105927}]}, {"text": "Multiple font styles are also frequently used in printing-press era documents; the most common scenario is fora basic font style to co-occur with an italic variant.", "labels": [], "entities": []}, {"text": "For example, it is common for proper nouns and quotations to be italicized in the Old Bailey corpus).", "labels": [], "entities": [{"text": "Old Bailey corpus", "start_pos": 82, "end_pos": 99, "type": "DATASET", "confidence": 0.9791611830393473}]}, {"text": "In our second extension, we incorporate a Markov chain over font styles, extending the original model so that it is capable of simultaneously learning italic and non-italic fonts within a single document.", "labels": [], "entities": []}, {"text": "In experiments, this model is able to detect which words are italicized with 93% precision at 74% recall in a test set of historical court proceedings (see Section 4.2).", "labels": [], "entities": [{"text": "precision", "start_pos": 81, "end_pos": 90, "type": "METRIC", "confidence": 0.9942501783370972}, {"text": "recall", "start_pos": 98, "end_pos": 104, "type": "METRIC", "confidence": 0.9888231754302979}]}, {"text": "These richer models that we propose do increase the state space and therefore make inference more costly.", "labels": [], "entities": []}, {"text": "To remedy this, we streamline inference by replacing the coarse-to-fine inference scheme of e i\ud97b\udf591 with a forward-cost-augmented beaming scheme.", "labels": [], "entities": []}, {"text": "Our method is over 25x faster on atypical document, yet actually yields improved transcriptions.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: We evaluate the output of each system on two test  sets: Trove, a collection of historical newspapers, and Old  Bailey, a collection of historical court proceedings. We report  character error rate (CER) and word error rate (WER), macro- averaged across documents.", "labels": [], "entities": [{"text": "Trove", "start_pos": 67, "end_pos": 72, "type": "DATASET", "confidence": 0.67714524269104}, {"text": "Old  Bailey", "start_pos": 117, "end_pos": 128, "type": "DATASET", "confidence": 0.9715836942195892}, {"text": "character error rate (CER)", "start_pos": 187, "end_pos": 213, "type": "METRIC", "confidence": 0.8803184827168783}, {"text": "word error rate (WER)", "start_pos": 218, "end_pos": 239, "type": "METRIC", "confidence": 0.9122429390748342}]}]}