{"title": [{"text": "Toward Better Chinese Word Segmentation for SMT via Bilingual Constraints", "labels": [], "entities": [{"text": "Chinese Word Segmentation", "start_pos": 14, "end_pos": 39, "type": "TASK", "confidence": 0.6148530642191569}, {"text": "SMT", "start_pos": 44, "end_pos": 47, "type": "TASK", "confidence": 0.970535933971405}]}], "abstractContent": [{"text": "This study investigates on building a better Chinese word segmentation model for statistical machine translation.", "labels": [], "entities": [{"text": "Chinese word segmentation", "start_pos": 45, "end_pos": 70, "type": "TASK", "confidence": 0.6105954945087433}, {"text": "statistical machine translation", "start_pos": 81, "end_pos": 112, "type": "TASK", "confidence": 0.7368880112965902}]}, {"text": "It aims at leveraging word boundary information , automatically learned by bilingual character-based alignments, to induce a preferable segmentation model.", "labels": [], "entities": []}, {"text": "We propose dealing with the induced word boundaries as soft constraints to bias the continuous learning of a supervised CRF-s model, trained by the treebank data (la-beled), on the bilingual data (unlabeled).", "labels": [], "entities": []}, {"text": "The induced word boundary information is encoded as a graph propagation constraint.", "labels": [], "entities": []}, {"text": "The constrained model induction is accomplished by using posterior reg-ularization algorithm.", "labels": [], "entities": []}, {"text": "The experiments on a Chinese-to-English machine translation task reveal that the proposed model can bring positive segmentation effects to translation quality.", "labels": [], "entities": [{"text": "Chinese-to-English machine translation task", "start_pos": 21, "end_pos": 64, "type": "TASK", "confidence": 0.6896457374095917}]}], "introductionContent": [{"text": "Word segmentation is regarded as a critical procedure for high-level Chinese language processing tasks, since Chinese scripts are written in continuous characters without explicit word boundaries (e.g., space in English).", "labels": [], "entities": [{"text": "Word segmentation", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.7332944720983505}, {"text": "Chinese language processing", "start_pos": 69, "end_pos": 96, "type": "TASK", "confidence": 0.651746948560079}]}, {"text": "The empirical works show that word segmentation can be beneficial to Chinese-to-English statistical machine translation (SMT) (.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 30, "end_pos": 47, "type": "TASK", "confidence": 0.7494834065437317}, {"text": "Chinese-to-English statistical machine translation (SMT)", "start_pos": 69, "end_pos": 125, "type": "TASK", "confidence": 0.7155804463795253}]}, {"text": "In fact most current SMT models assume that parallel bilingual sentences should be segmented into sequences of tokens that are meant to be \"words\").", "labels": [], "entities": [{"text": "SMT", "start_pos": 21, "end_pos": 24, "type": "TASK", "confidence": 0.9942374229431152}]}, {"text": "The practice in state-of-the-art MT systems is that Chinese sentences are tokenized by a monolingual supervised word segmentation model trained on the handannotated treebank data, e.g., Chinese treebank (CTB) ().", "labels": [], "entities": [{"text": "MT", "start_pos": 33, "end_pos": 35, "type": "TASK", "confidence": 0.9884080290794373}, {"text": "Chinese treebank (CTB)", "start_pos": 186, "end_pos": 208, "type": "DATASET", "confidence": 0.8800675749778748}]}, {"text": "These models are conducive to MT to some extent, since they commonly have relatively good aggregate performance and segmentation consistency (.", "labels": [], "entities": [{"text": "MT", "start_pos": 30, "end_pos": 32, "type": "TASK", "confidence": 0.9953612685203552}, {"text": "segmentation", "start_pos": 116, "end_pos": 128, "type": "TASK", "confidence": 0.9578201174736023}, {"text": "consistency", "start_pos": 129, "end_pos": 140, "type": "METRIC", "confidence": 0.4782763123512268}]}, {"text": "But one outstanding problem is that these models may leave out some crucial segmentation features for SMT, since the output words conform to the treebank segmentation standard designed for monolingually linguistic intuition, rather than specific to the SMT task.", "labels": [], "entities": [{"text": "SMT", "start_pos": 102, "end_pos": 105, "type": "TASK", "confidence": 0.9954981803894043}, {"text": "SMT task", "start_pos": 253, "end_pos": 261, "type": "TASK", "confidence": 0.9292529821395874}]}, {"text": "In recent years, a number of works () attempted to build segmentation models for SMT based on bilingual unsegmented data, instead of monolingual segmented data.", "labels": [], "entities": [{"text": "SMT", "start_pos": 81, "end_pos": 84, "type": "TASK", "confidence": 0.9953404664993286}]}, {"text": "They proposed to learn gainful bilingual knowledge as golden-standard segmentation supervisions for training a bilingual unsupervised model.", "labels": [], "entities": []}, {"text": "Frequently, the bilingual knowledge refers to the mappings of an individual English word to one or more consecutive Chinese characters, generated via statistical character-based alignment.", "labels": [], "entities": []}, {"text": "They leverage such mappings to either constitute a Chinese word dictionary for maximum-matching segmentation (), or form labeled data for training a sequence labeling model).", "labels": [], "entities": [{"text": "maximum-matching segmentation", "start_pos": 79, "end_pos": 108, "type": "TASK", "confidence": 0.6928148567676544}]}, {"text": "The prior works showed that these models help to find some segmentations tailored for SMT, since the bilingual word occurrence feature can be captured by the character-based alignment.", "labels": [], "entities": [{"text": "SMT", "start_pos": 86, "end_pos": 89, "type": "TASK", "confidence": 0.9952346682548523}]}, {"text": "However, these models tend to miss out other linguistic segmentation patterns as monolingual supervised models, and suffer from the negative effects of erroneously alignments to word segmentation.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 178, "end_pos": 195, "type": "TASK", "confidence": 0.70716992020607}]}, {"text": "This paper proposes an alternative Chinese Word Segmentation (CWS) model adapted to the SMT task, which seeks not only to maintain the advantages of a monolingual supervised model, having hand-annotated linguistic knowledge, but also to assimilate the relevant bilingual segmenta-tion nature.", "labels": [], "entities": [{"text": "Chinese Word Segmentation (CWS)", "start_pos": 35, "end_pos": 66, "type": "TASK", "confidence": 0.7281999786694845}, {"text": "SMT task", "start_pos": 88, "end_pos": 96, "type": "TASK", "confidence": 0.9455019235610962}]}, {"text": "We propose leveraging the bilingual knowledge to form learning constraints that guide a supervised segmentation model toward a better solution for SMT.", "labels": [], "entities": [{"text": "SMT", "start_pos": 147, "end_pos": 150, "type": "TASK", "confidence": 0.9956910014152527}]}, {"text": "Besides the bilingual motivated models, character-based alignment is also employed to achieve the mappings of the successive Chinese characters and the target language words.", "labels": [], "entities": [{"text": "character-based alignment", "start_pos": 40, "end_pos": 65, "type": "TASK", "confidence": 0.7306480705738068}]}, {"text": "Instead of directly merging the characters into concrete segmentations, this work attempts to extract word boundary distributions for characterlevel trigrams (types) from the \"chars-to-word\" mappings.", "labels": [], "entities": []}, {"text": "Furthermore, these word boundaries are encoded into a graph propagation (GP) expression, in order to widen the influence of the induced bilingual knowledge among Chinese texts.", "labels": [], "entities": []}, {"text": "The G-P expression constrains similar types having approximated word boundary distributions.", "labels": [], "entities": []}, {"text": "Crucially, the GP expression with the bilingual knowledge is then used as side information to regularize a CRFs (conditional random fields) model's learning over treebank and bitext data, based on the posterior regularization (PR) framework (.", "labels": [], "entities": []}, {"text": "This constrained learning amounts to a jointly coupling of GP and CRFs, i.e., integrating GP into the estimation of a parametric structural model.", "labels": [], "entities": []}, {"text": "This paper is structured as follows: Section 2 points out the main differences with the related works of this study.", "labels": [], "entities": []}, {"text": "Section 3 presents the details of the proposed segmentation model.", "labels": [], "entities": [{"text": "segmentation", "start_pos": 47, "end_pos": 59, "type": "TASK", "confidence": 0.9756882786750793}]}, {"text": "Section 4 reports the experimental results of the proposed model fora Chinese-to-English MT task.", "labels": [], "entities": [{"text": "MT task", "start_pos": 89, "end_pos": 96, "type": "TASK", "confidence": 0.8557254374027252}]}, {"text": "The conclusion is drawn in Section 5.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Translation performances (%) on MT-05  testing data by using ten different CWS models.", "labels": [], "entities": [{"text": "Translation", "start_pos": 10, "end_pos": 21, "type": "TASK", "confidence": 0.9269922971725464}, {"text": "MT-05  testing data", "start_pos": 42, "end_pos": 61, "type": "DATASET", "confidence": 0.7044287721316019}]}]}