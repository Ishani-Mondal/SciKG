{"title": [{"text": "Does the Phonology of L1 Show Up in L2 Texts?", "labels": [], "entities": [{"text": "Phonology of L1", "start_pos": 9, "end_pos": 24, "type": "TASK", "confidence": 0.8343681891759237}]}], "abstractContent": [{"text": "The relative frequencies of character bi-grams appear to contain much information for predicting the first language (L1) of the writer of a text in another language (L2).", "labels": [], "entities": []}, {"text": "Tsur and Rappoport (2007) interpret this fact as evidence that word choice is dictated by the phonology of L1.", "labels": [], "entities": []}, {"text": "In order to test their hypothesis, we design an algorithm to identify the most discriminative words and the corresponding character bi-grams, and perform two experiments to quantify their impact on the L1 identification task.", "labels": [], "entities": [{"text": "L1 identification task", "start_pos": 202, "end_pos": 224, "type": "TASK", "confidence": 0.8117445508639017}]}, {"text": "The results strongly suggest an alternative explanation of the effectiveness of character bigrams in identifying the native language of a writer.", "labels": [], "entities": [{"text": "identifying the native language of a writer", "start_pos": 101, "end_pos": 144, "type": "TASK", "confidence": 0.8261260645730155}]}], "introductionContent": [{"text": "The task of Native Language Identification (NLI) is to determine the first language of the writer of a text in another language.", "labels": [], "entities": [{"text": "Native Language Identification (NLI)", "start_pos": 12, "end_pos": 48, "type": "TASK", "confidence": 0.8411113023757935}]}, {"text": "Ina ground-breaking paper, propose a set of features for this task: function words, character n-grams, rare part-of-speech bigrams, and various types of errors.", "labels": [], "entities": []}, {"text": "They report 80% accuracy in classifying a set of English texts into five L1 languages using a multi-class linear SVM.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 16, "end_pos": 24, "type": "METRIC", "confidence": 0.999620795249939}]}, {"text": "The First Shared Task on Native Language Identification ( ) attracted submissions from 29 teams.", "labels": [], "entities": [{"text": "Native Language Identification", "start_pos": 25, "end_pos": 55, "type": "TASK", "confidence": 0.5904770990212759}]}, {"text": "The accuracy on a set of English texts representing eleven L1 languages ranged from 31% to 83%.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.9996381998062134}]}, {"text": "Many types of features were employed, including word length, sentence length, paragraph length, document length, sentence complexity, punctuation and capitalization, cognates, dependency parses, topic models, word suffixes, collocations, function word ngrams, skip-grams, word networks, Tree Substitution Grammars, string kernels, cohesion, and passive constructions ().", "labels": [], "entities": [{"text": "dependency parses", "start_pos": 176, "end_pos": 193, "type": "TASK", "confidence": 0.735864669084549}]}, {"text": "In particular, word n-gram features appear to be particularly effective, as they were used by the most competitive teams, including the one that achieved the highest overall accuracy (.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 174, "end_pos": 182, "type": "METRIC", "confidence": 0.9787228107452393}]}, {"text": "Furthermore, the most discriminative word n-grams often contained the name of the native language, or countries where it is commonly spoken.", "labels": [], "entities": []}, {"text": "We refer to such words as toponymic terms.", "labels": [], "entities": []}, {"text": "There is no doubt that the toponymic terms are useful for increasing the NLI accuracy; however, from the psycho-linguistic perspective, we are more interested in what characteristics of L1 show up in L2 texts.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 77, "end_pos": 85, "type": "METRIC", "confidence": 0.9771832227706909}]}, {"text": "Clearly, L1 affects the L2 writing in general, and the choice of words in particular, but what is the role played by the phonology?", "labels": [], "entities": []}, {"text": "observe that limiting the set of features to the relative frequency of the 200 most frequent character bigrams yields a respectable 66% accuracy on a 5-language classification task.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 136, "end_pos": 144, "type": "METRIC", "confidence": 0.99935382604599}, {"text": "5-language classification task", "start_pos": 150, "end_pos": 180, "type": "TASK", "confidence": 0.7587298651536306}]}, {"text": "The authors propose the following hypothesis to explain this finding: \"the choice of words [emphasis added] people make when writing in a second language is strongly influenced by the phonology of their native language\".", "labels": [], "entities": []}, {"text": "As the orthography of alphabetic languages is at least partially representative of the underlying phonology, character bigrams may capture these phonological preferences.", "labels": [], "entities": []}, {"text": "In this paper, we provide evidence against the above hypothesis.", "labels": [], "entities": []}, {"text": "We design an algorithm to identify the most discriminative words and the character bigrams that are indicative of such words, and perform two experiments to quantify their impact on the NLI task.", "labels": [], "entities": []}, {"text": "The results of the first experiment demonstrate that the removal of a relatively small set of discriminative words from the training data significantly impairs the accuracy of a bigram-based classifier.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 164, "end_pos": 172, "type": "METRIC", "confidence": 0.9984210729598999}]}, {"text": "The results of the second experiment reveal that the most indicative bigrams are quite similar across different language sets.", "labels": [], "entities": []}, {"text": "We conclude that character bigrams are effective in determining L1 of the author because they reflect differences in L2 word usage that are unrelated to the phonology of L1.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section, we describe two experiments aimed at quantifying the importance of the discriminative words and the indicative character bigrams that are identified by Algorithm 1.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: The impact of subsets of word types and bigram features on the accuracy of a bigram-based NLI  classifier.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 73, "end_pos": 81, "type": "METRIC", "confidence": 0.9991698265075684}]}]}