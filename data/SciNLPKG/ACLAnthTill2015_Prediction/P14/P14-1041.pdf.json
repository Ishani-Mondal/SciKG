{"title": [{"text": "Hybrid Simplification using Deep Semantics and Machine Translation", "labels": [], "entities": [{"text": "Machine Translation", "start_pos": 47, "end_pos": 66, "type": "TASK", "confidence": 0.7441742420196533}]}], "abstractContent": [{"text": "We present a hybrid approach to sentence simplification which combines deep semantics and monolingual machine translation to derive simple sentences from complex ones.", "labels": [], "entities": [{"text": "sentence simplification", "start_pos": 32, "end_pos": 55, "type": "TASK", "confidence": 0.7341969460248947}]}, {"text": "The approach differs from previous work in two main ways.", "labels": [], "entities": []}, {"text": "First, it is semantic based in that it takes as input a deep semantic representation rather than e.g., a sentence or a parse tree.", "labels": [], "entities": []}, {"text": "Second , it combines a simplification model for splitting and deletion with a monolin-gual translation model for phrase substitution and reordering.", "labels": [], "entities": [{"text": "splitting and deletion", "start_pos": 48, "end_pos": 70, "type": "TASK", "confidence": 0.8023348251978556}, {"text": "phrase substitution", "start_pos": 113, "end_pos": 132, "type": "TASK", "confidence": 0.791619211435318}]}, {"text": "When compared against current state of the art methods, our model yields significantly simpler output that is both grammatical and meaning preserving.", "labels": [], "entities": []}], "introductionContent": [{"text": "Sentence simplification maps a sentence to a simpler, more readable one approximating its content.", "labels": [], "entities": [{"text": "Sentence simplification", "start_pos": 0, "end_pos": 23, "type": "TASK", "confidence": 0.930433988571167}]}, {"text": "Typically, a simplified sentence differs from a complex one in that it involves simpler, more usual and often shorter, words (e.g., use instead of exploit); simpler syntactic constructions (e.g., no relative clauses or apposition); and fewer modifiers (e.g., He slept vs. He also slept).", "labels": [], "entities": []}, {"text": "In practice, simplification is thus often modeled using four main operations: splitting a complex sentence into several simpler sentences; dropping and reordering phrases or constituents; substituting words/phrases with simpler ones.", "labels": [], "entities": [{"text": "simplification", "start_pos": 13, "end_pos": 27, "type": "TASK", "confidence": 0.9748795032501221}]}, {"text": "As has been argued in previous work, sentence simplification has many potential applications.", "labels": [], "entities": [{"text": "sentence simplification", "start_pos": 37, "end_pos": 60, "type": "TASK", "confidence": 0.8733311891555786}]}, {"text": "It is useful as a preprocessing step fora variety of NLP systems such as parsers and machine translation systems, summarisation), sentence fusion () and semantic role labelling (.", "labels": [], "entities": [{"text": "parsers and machine translation", "start_pos": 73, "end_pos": 104, "type": "TASK", "confidence": 0.6538377925753593}, {"text": "summarisation", "start_pos": 114, "end_pos": 127, "type": "TASK", "confidence": 0.981376051902771}, {"text": "sentence fusion", "start_pos": 130, "end_pos": 145, "type": "TASK", "confidence": 0.8066405355930328}, {"text": "semantic role labelling", "start_pos": 153, "end_pos": 176, "type": "TASK", "confidence": 0.6878316402435303}]}, {"text": "It also has wide ranging potential societal application as a reading aid for people with aphasis (), for low literacy readers () and for nonnative speakers.", "labels": [], "entities": []}, {"text": "There has been much work recently on developing computational frameworks for sentence simplification.", "labels": [], "entities": [{"text": "sentence simplification", "start_pos": 77, "end_pos": 100, "type": "TASK", "confidence": 0.8138071596622467}]}, {"text": "Synchronous grammars have been used in combination with linear integer programming to generate and rank all possible rewrites of an input sentence).", "labels": [], "entities": []}, {"text": "Machine Translation systems have been adapted to translate complex sentences into simple ones (.", "labels": [], "entities": [{"text": "Machine Translation", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.7440822422504425}]}, {"text": "And handcrafted rules have been proposed to model the syntactic transformations involved in simplifications.", "labels": [], "entities": []}, {"text": "In this paper, we present a hybrid approach to sentence simplification which departs from this previous work in two main ways.", "labels": [], "entities": [{"text": "sentence simplification", "start_pos": 47, "end_pos": 70, "type": "TASK", "confidence": 0.8042962551116943}]}, {"text": "First, it combines a model encoding probabilities for splitting and deletion with a monolingual machine translation module which handles reordering and substitution.", "labels": [], "entities": []}, {"text": "In this way, we exploit the ability of statistical machine translation (SMT) systems to capture phrasal/lexical substitution and reordering while relying on a dedicated probabilistic module to capture the splitting and deletion operations which are less well (deletion) or not at all (splitting) captured by SMT approaches.", "labels": [], "entities": [{"text": "statistical machine translation (SMT)", "start_pos": 39, "end_pos": 76, "type": "TASK", "confidence": 0.7857983311017355}, {"text": "SMT", "start_pos": 308, "end_pos": 311, "type": "TASK", "confidence": 0.9636543393135071}]}, {"text": "Second, our approach is semantic based.", "labels": [], "entities": []}, {"text": "While previous simplification approaches starts from either the input sentence or its parse tree, our model takes as input a deep semantic representation namely, the Discourse Representation Structure) assigned by Boxer ( to the input complex sentence.", "labels": [], "entities": []}, {"text": "As we shall see in Section 4, this permits a linguistically principled account of the splitting operation in that semantically shared elements are taken to be the basis for splitting a complex sentence into several simpler ones; this facilitates completion (the re-creation of the shared element in the split sentences); and this provide a natural means to avoid deleting obligatory arguments.", "labels": [], "entities": []}, {"text": "When compared against current state of the art methods (), our model yields significantly simpler output that is both grammatical and meaning preserving.", "labels": [], "entities": []}], "datasetContent": [{"text": "We trained our simplification and translation models on the PWKP corpus.", "labels": [], "entities": [{"text": "translation", "start_pos": 34, "end_pos": 45, "type": "TASK", "confidence": 0.9436231851577759}, {"text": "PWKP corpus", "start_pos": 60, "end_pos": 71, "type": "DATASET", "confidence": 0.9694391191005707}]}, {"text": "To evaluate performance, we compare our approach with three other state of the art systems using the test set provided by and relying both on automatic metrics and on human judgments.", "labels": [], "entities": []}, {"text": "To assess and compare simplification systems, two main automatic metrics have been used in previous work namely, BLEU and the Flesch-Kincaid Grade Level Index (FKG).", "labels": [], "entities": [{"text": "BLEU", "start_pos": 113, "end_pos": 117, "type": "METRIC", "confidence": 0.9987483024597168}, {"text": "Flesch-Kincaid Grade Level Index (FKG)", "start_pos": 126, "end_pos": 164, "type": "METRIC", "confidence": 0.9409939476421901}]}, {"text": "The FKG index is a readability metric taking into account the average sentence length in words and the average word length in syllables.", "labels": [], "entities": [{"text": "FKG index", "start_pos": 4, "end_pos": 13, "type": "METRIC", "confidence": 0.761177122592926}]}, {"text": "In its original context (language learning), it was applied to well formed text and thus measured the simplicity of a well formed sentence.", "labels": [], "entities": [{"text": "simplicity", "start_pos": 102, "end_pos": 112, "type": "METRIC", "confidence": 0.9928913116455078}]}, {"text": "In the context of the simplification task however, the automatically generated sentences are not necessarily well formed so that the FKG index reduces to a measure of the sentence length (in terms of words and syllables) approximating the simplicity level of an output sentence irrespective of the length of the corresponding input.", "labels": [], "entities": [{"text": "FKG index", "start_pos": 133, "end_pos": 142, "type": "METRIC", "confidence": 0.8084588646888733}, {"text": "simplicity", "start_pos": 239, "end_pos": 249, "type": "METRIC", "confidence": 0.9821088314056396}]}, {"text": "To assess simplification, we instead use metrics that are directly related to the simplification task namely, the number of splits in the overall (test and training) data and in average per sentences; the number of generated sentences with no edits i.e., which are identical to the original, complex one; and the average Levenshtein distance between the system's output and both the complex and the simple reference sentences.", "labels": [], "entities": [{"text": "Levenshtein distance", "start_pos": 321, "end_pos": 341, "type": "METRIC", "confidence": 0.8971854150295258}]}, {"text": "BLEU gives a measure of how close a system's output is to the gold standard simple sentence.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 0, "end_pos": 4, "type": "METRIC", "confidence": 0.9822591543197632}]}, {"text": "Because there are many possible ways of simplifying a sentence, BLEU alone fails to correctly assess the appropriateness of a simplification.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 64, "end_pos": 68, "type": "METRIC", "confidence": 0.9978272318840027}]}, {"text": "Moreover BLEU does not capture the degree to which the system's output differs from the complex sentence input.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 9, "end_pos": 13, "type": "METRIC", "confidence": 0.997127115726471}]}, {"text": "We therefore use BLEU as a means to evaluate how close the systems output are to the reference corpus but complement it with further manual metrics capturing other important factors when evaluating simplifications such as the fluency and the adequacy of the output sentences and the degree to which the output sentence simplifies the input.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 17, "end_pos": 21, "type": "METRIC", "confidence": 0.9938196539878845}]}, {"text": "shows the proportion of input whose simplification involved a splitting operation.", "labels": [], "entities": []}, {"text": "While our system splits in proportion similar to that observed in the training data, the other systems either split very often (80% of the time for Zhu and 63% of the time for Woodsend) or not at all (Wubben).", "labels": [], "entities": [{"text": "Woodsend", "start_pos": 176, "end_pos": 184, "type": "DATASET", "confidence": 0.9008646011352539}]}, {"text": "In other words, when compared to the other systems, our system performs splits in proportion closest to the reference both in terms of total number of splits and of average number of splits per sentence.", "labels": [], "entities": []}, {"text": "indicates the edit distance of the output sentences w.r.t. both the complex and the simple reference sentences as well as the number of input for which no simplification occur.", "labels": [], "entities": []}, {"text": "The right part of the table shows that our system generate simplifications which are closest to the reference sentence (in terms of edits) compared to those output by the other systems.", "labels": [], "entities": []}, {"text": "It also produces the highest number of simplifications which are identical to the reference.", "labels": [], "entities": []}, {"text": "Conversely our system only ranks third in terms of dissimilarity with the input complex sentences (6.32 edits away from the input sentence) behind the Woodsend (8.63 edits) and the Zhu (7.87 edits) system.", "labels": [], "entities": [{"text": "Woodsend", "start_pos": 151, "end_pos": 159, "type": "DATASET", "confidence": 0.9797898530960083}]}, {"text": "This is in part due to the difference in splitting strategies noted above : the many splits applied by these latter two systems correlate with a high number of edits.", "labels": [], "entities": []}, {"text": "show that our system produces simplifications that are closest to the reference.", "labels": [], "entities": []}, {"text": "The human evaluation was done online using the LG-Eval toolkit . The evaluators were allocated atrial set using a Latin Square Experimental Design (LSED) such that each evaluator sees the same number of output from each system and for each test set item.", "labels": [], "entities": []}, {"text": "During the experiment, the evaluators were presented with a pair of a complex and a simple sentence(s) and asked to rate this pair w.r.t. to adequacy (Does the simplified sentence(s) preserve the meaning of the input?) and simplification (Does the generated sentence(s) simplify the complex input?).", "labels": [], "entities": []}, {"text": "They were also asked to rate the second (simplified) sentence(s) of the pair w.r.t. to fluency (Is the simplified output fluent and grammatical?).", "labels": [], "entities": []}, {"text": "Similar to the Wubben's human evaluation setup, we randomly selected 20 complex sentences from Zhu's test corpus and included in the evaluation corpus: the corresponding simple (Gold) sentence from Zhu's test corpus, the output of our system (Hybrid) and the output of the other three systems (Zhu, Woodsend and Wubben) which were provided to us by the system authors.", "labels": [], "entities": [{"text": "Zhu's test corpus", "start_pos": 198, "end_pos": 215, "type": "DATASET", "confidence": 0.6279469355940819}]}, {"text": "The evaluation data thus consisted of 100 complex/simple pairs.", "labels": [], "entities": []}, {"text": "We collected ratings from 27 participants.", "labels": [], "entities": []}, {"text": "All were either native speakers or proficient in English, having taken part in a Master taught in English or lived in an English speaking country for an extended period of time.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Simplification: DELETION (Relations, modifiers and OW respectively)", "labels": [], "entities": [{"text": "DELETION", "start_pos": 26, "end_pos": 34, "type": "METRIC", "confidence": 0.9990646243095398}, {"text": "OW", "start_pos": 61, "end_pos": 63, "type": "METRIC", "confidence": 0.9792782068252563}]}, {"text": " Table 3: Proportion of Split Sentences (% split)  in the training/test data and in average per sen- tence (average split / sentence). GOLD is the  test data with the gold standard SWKP sentences;  Zhu, Woodsend, Wubben are the best output of the  models of Zhu et al. (2010), Woodsend and Lap- ata (2011) and Wubben et al. (2012) respectively;  Hybrid is our model.", "labels": [], "entities": [{"text": "GOLD", "start_pos": 135, "end_pos": 139, "type": "METRIC", "confidence": 0.700788140296936}]}, {"text": " Table 4: Automated Metrics for Simplification:  average Levenshtein distance (LD) to complex and  simple reference sentences per system ; number of  input sentences for which no simplification occur  (No edit).", "labels": [], "entities": [{"text": "Levenshtein distance (LD)", "start_pos": 57, "end_pos": 82, "type": "METRIC", "confidence": 0.9672606825828552}]}, {"text": " Table 5: Average Human Ratings for simplicity,  fluency and adequacy", "labels": [], "entities": [{"text": "simplicity", "start_pos": 36, "end_pos": 46, "type": "METRIC", "confidence": 0.9988061189651489}]}]}