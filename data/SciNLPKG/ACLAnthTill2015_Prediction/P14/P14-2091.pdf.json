{"title": [{"text": "A joint inference of deep case analysis and zero subject generation for Japanese-to-English statistical machine translation", "labels": [], "entities": [{"text": "deep case analysis", "start_pos": 21, "end_pos": 39, "type": "TASK", "confidence": 0.6497639020284017}, {"text": "Japanese-to-English statistical machine translation", "start_pos": 72, "end_pos": 123, "type": "TASK", "confidence": 0.577942781150341}]}], "abstractContent": [{"text": "We present a simple joint inference of deep case analysis and zero subject generation for the pre-ordering in Japanese-to-English machine translation.", "labels": [], "entities": [{"text": "deep case analysis", "start_pos": 39, "end_pos": 57, "type": "TASK", "confidence": 0.6387586295604706}, {"text": "Japanese-to-English machine translation", "start_pos": 110, "end_pos": 149, "type": "TASK", "confidence": 0.6139358778794607}]}, {"text": "The detection of subjects and objects from Japanese sentences is more difficult than that from English, while it is the key process to generate correct English word orders.", "labels": [], "entities": [{"text": "detection of subjects and objects from Japanese sentences", "start_pos": 4, "end_pos": 61, "type": "TASK", "confidence": 0.7977205440402031}]}, {"text": "In addition , subjects are often omitted in Japanese when they are inferable from the context.", "labels": [], "entities": []}, {"text": "We propose anew Japanese deep syntactic parser that consists of pointwise proba-bilistic models and a global inference with linguistic constraints.", "labels": [], "entities": [{"text": "Japanese deep syntactic parser", "start_pos": 16, "end_pos": 46, "type": "TASK", "confidence": 0.49968525767326355}]}, {"text": "We applied our new deep parser to pre-ordering in Japanese-to-English SMT system and show substantial improvements in automatic evaluations.", "labels": [], "entities": [{"text": "SMT", "start_pos": 70, "end_pos": 73, "type": "TASK", "confidence": 0.900246262550354}]}], "introductionContent": [{"text": "Japanese to English translation is known to be one of the most difficult language pair for statistical machine translation (SMT).", "labels": [], "entities": [{"text": "Japanese to English translation", "start_pos": 0, "end_pos": 31, "type": "TASK", "confidence": 0.5672271549701691}, {"text": "statistical machine translation (SMT)", "start_pos": 91, "end_pos": 128, "type": "TASK", "confidence": 0.807214026649793}]}, {"text": "It has been widely believed for years that the difference of word orders, i.e., Japanese is an SOV language, while English is an SVO language, makes the English-toJapanese and Japanese-to-English translation difficult.", "labels": [], "entities": []}, {"text": "However, simple, yet powerful pre-ordering techniques have made this argument a thing of the past (.", "labels": [], "entities": []}, {"text": "Preordering processes the source sentence in such away that word orders appear closer to their final positions on the target side.", "labels": [], "entities": []}, {"text": "While many successes of English-to-Japanese translation have been reported recently, the quality improvement of Japanese-to-English translation is still small even with the help of pre-ordering).", "labels": [], "entities": [{"text": "English-to-Japanese translation", "start_pos": 24, "end_pos": 55, "type": "TASK", "confidence": 0.5866647064685822}, {"text": "Japanese-to-English translation", "start_pos": 112, "end_pos": 143, "type": "TASK", "confidence": 0.6612318903207779}]}, {"text": "We found that there are two major issues that make Japanese-to-English translation difficult.", "labels": [], "entities": [{"text": "Japanese-to-English translation", "start_pos": 51, "end_pos": 82, "type": "TASK", "confidence": 0.602573037147522}]}, {"text": "One is that Japanese subject and object cannot easily be identified compared to English, while their detections are the key process to generate correct English word orders.", "labels": [], "entities": []}, {"text": "Japanese surface syntactic structures are not always corresponding to their deep structures, i.e., semantic roles.", "labels": [], "entities": []}, {"text": "The other is that Japanese is a pro-drop language in which certain classes of pronouns maybe omitted when they are pragmatically inferable.", "labels": [], "entities": []}, {"text": "In Japanese-to-English translation, these omitted pronouns have to be generated properly.", "labels": [], "entities": []}, {"text": "There are several researches that focused on the pre-ordering with Japanese deep syntactic analysis () and zero pronoun generation ( for Japanese-to-English translation.", "labels": [], "entities": [{"text": "zero pronoun generation", "start_pos": 107, "end_pos": 130, "type": "TASK", "confidence": 0.691858688990275}]}, {"text": "However, these two issues have been considered independently, while they heavily rely on one another.", "labels": [], "entities": []}, {"text": "In this paper, we propose a simple joint inference which handles both Japanese deep structure analysis and zero pronoun generation.", "labels": [], "entities": [{"text": "Japanese deep structure analysis", "start_pos": 70, "end_pos": 102, "type": "TASK", "confidence": 0.6444918811321259}, {"text": "zero pronoun generation", "start_pos": 107, "end_pos": 130, "type": "TASK", "confidence": 0.7085396846135458}]}, {"text": "To the best of our knowledge, this is the first study that addresses these two issues at the same time.", "labels": [], "entities": []}, {"text": "This paper is organized as follows.", "labels": [], "entities": []}, {"text": "First, we describe why Japanese-to-English translation is difficult.", "labels": [], "entities": [{"text": "Japanese-to-English translation", "start_pos": 23, "end_pos": 54, "type": "TASK", "confidence": 0.5936874002218246}]}, {"text": "Second, we show the basic idea of this work and its implementation based on pointwise probabilistic models and a global inference with an integer linear programming (ILP).", "labels": [], "entities": []}, {"text": "Several experiments are employed to confirm that our new model can improve the Japanese to English translation quality.", "labels": [], "entities": [{"text": "Japanese to English translation", "start_pos": 79, "end_pos": 110, "type": "TASK", "confidence": 0.514120802283287}]}, {"text": "2 What makes Japanese-to-English translation difficult?", "labels": [], "entities": [{"text": "Japanese-to-English translation", "start_pos": 13, "end_pos": 44, "type": "TASK", "confidence": 0.5944624692201614}]}, {"text": "Japanese syntactic relations between arguments and predicates are usually specified by particles.", "labels": [], "entities": []}, {"text": "There are several types of particles, but we focus on (ga), (wo) and (wa) for the sake of \u2022 ga is usually a subject marker.", "labels": [], "entities": []}, {"text": "However, it becomes an object marker if the predicate has a potential voice type, which is usually translated into can, be able to, want to, or would like to.", "labels": [], "entities": []}, {"text": "\u2022 wo is an object marker.", "labels": [], "entities": []}, {"text": "\u2022 wa is a topic case marker.", "labels": [], "entities": []}, {"text": "The topic can be anything that a speaker wants to talk about.", "labels": [], "entities": []}, {"text": "It can be subject, object, location, time or any other grammatical elements.", "labels": [], "entities": []}, {"text": "We cannot always identify Japanese subject and object only by seeing the surface case markers ga, wo and wa.", "labels": [], "entities": []}, {"text": "Especially the topic case marker is problematic, since there is no concept of topic in English.", "labels": [], "entities": []}, {"text": "It is necessary to get a deep interpretation of topic case markers in order to develop accurate Japanese-to-English SMT systems.", "labels": [], "entities": [{"text": "SMT", "start_pos": 116, "end_pos": 119, "type": "TASK", "confidence": 0.8212968707084656}]}, {"text": "Another big issue is that Japanese subject (or even an object) can be omitted when they can pragmatically be inferable from the context.", "labels": [], "entities": []}, {"text": "Such a pronoun-dropping is not a unique phenomenon in Japanese actually.", "labels": [], "entities": []}, {"text": "For instance, Spanish also allows to omit pronouns.", "labels": [], "entities": []}, {"text": "However, the inflectional suffix of Spanish verbs include a hint of the person of the subject.", "labels": [], "entities": []}, {"text": "On the other hand, inferring Japanese subjects is more difficult than Spanish, since Japanese verbs usually do not have any grammatical cues to tell the subject type.", "labels": [], "entities": []}, {"text": "shows an example Japanese sentence which cannot be parsed only with the surface structure.", "labels": [], "entities": []}, {"text": "The second token wa specifies the relation between (today) and (can drink).", "labels": [], "entities": []}, {"text": "Human can easily tell that the relation of them is not a subject but an adverb (time).", "labels": [], "entities": []}, {"text": "The topic case marker wa implies that the time when the speaker drinks liquor is the focus of this sentence.", "labels": [], "entities": []}, {"text": "The 4th token ga indicates the relation between (liquor) and (can drink).", "labels": [], "entities": []}, {"text": "Since the predicate has a potential voice (can drink), the ga particle should be interpreted as an object here.", "labels": [], "entities": []}, {"text": "In this sentence, the subject is omitted.", "labels": [], "entities": []}, {"text": "In general, it is unknown who speaks this sentence, but the first person is a natural interpretation in this context.", "labels": [], "entities": []}, {"text": "Another tricky phenomenon is that detecting voice type is not always deterministic.", "labels": [], "entities": [{"text": "detecting voice type", "start_pos": 34, "end_pos": 54, "type": "TASK", "confidence": 0.9033432006835938}]}, {"text": "There are several ways to generate a potential voice in Japanese, but we usually put the suffix word (reru) or (rareru) after predicates.", "labels": [], "entities": []}, {"text": "However, these suffix words are also used fora passive voice.", "labels": [], "entities": []}, {"text": "In summary, we can see that the following four factors are the potential causes that make the Japanese parsing difficult.", "labels": [], "entities": [{"text": "parsing", "start_pos": 103, "end_pos": 110, "type": "TASK", "confidence": 0.7176323533058167}]}, {"text": "\u2022 Japanese voice type detection is not straightforward.", "labels": [], "entities": [{"text": "Japanese voice type detection", "start_pos": 2, "end_pos": 31, "type": "TASK", "confidence": 0.7189491391181946}]}, {"text": "reru or rareru are used either for passive or potential voice.", "labels": [], "entities": [{"text": "rareru", "start_pos": 8, "end_pos": 14, "type": "METRIC", "confidence": 0.8903289437294006}]}, {"text": "\u2022 surface case ga changes its interpretation from subject to object when the predicate has a potential voice.", "labels": [], "entities": []}, {"text": "\u2022 topic case marker wa is used as a topic case marker which doesn't exist in English.", "labels": [], "entities": []}, {"text": "Topic is either subject, objector any grammatical elements depending on the context.", "labels": [], "entities": []}, {"text": "\u2022 Japanese subject is often omitted when it is inferable from the context.", "labels": [], "entities": []}, {"text": "There is no cue to tell the subject person in verb suffix (inflection) like in Spanish verbs We should note that they are not always independent issues.", "labels": [], "entities": []}, {"text": "For instance, the deep case detection helps to tell the voice type, and vice versa.", "labels": [], "entities": [{"text": "deep case detection", "start_pos": 18, "end_pos": 37, "type": "TASK", "confidence": 0.6520903507868449}]}, {"text": "Another note is that they are unique issues observed only in Japanese-to-English translation.", "labels": [], "entities": []}, {"text": "In English-to-Japanese translation, it is acceptable to generate Japanese sentences that do not use Japanese topic markers wa.", "labels": [], "entities": []}, {"text": "Also, generating Japanese pronoun from English pronoun is acceptable, although it sounds redundant and unnatural for native speakers.", "labels": [], "entities": []}], "datasetContent": [{"text": "We carried out all our experiments using a stateof-the-art phrase-based statistical Japanese-toEnglish machine translation system with pre-ordering.", "labels": [], "entities": [{"text": "phrase-based statistical Japanese-toEnglish machine translation", "start_pos": 59, "end_pos": 122, "type": "TASK", "confidence": 0.5086758732795715}]}, {"text": "During the decoding, we use the reordering window (distortion limit) to 4 words.", "labels": [], "entities": []}, {"text": "For parallel training data, we use an inhouse collection of parallel sentences.", "labels": [], "entities": []}, {"text": "These come from various sources with a substantial portion coming from the web.", "labels": [], "entities": []}, {"text": "We trained our system on about 300M source words.", "labels": [], "entities": []}, {"text": "Our test set contains about 10,000 sentences randomly sampled from the web.", "labels": [], "entities": []}, {"text": "The dependency parser we apply is an implementation of a shift-reduce dependency parser which uses a bunsetsu-chunk as a basic unit for parsing ().", "labels": [], "entities": []}, {"text": "The zero subject and voice type models were trained with about 20,000 and 5,000 manually annotated web sentences respectively.", "labels": [], "entities": []}, {"text": "In order to simplify the rating tasks for our annotators, we extracted only one candidate predicate from a sentence for annotations.", "labels": [], "entities": []}, {"text": "We tested the following six systems.", "labels": [], "entities": []}, {"text": "\u2022 baseline: no pre-ordering.", "labels": [], "entities": [{"text": "baseline", "start_pos": 2, "end_pos": 10, "type": "METRIC", "confidence": 0.9757315516471863}]}, {"text": "\u2022 surface reordering : pre-ordering only with surface dependency relations.", "labels": [], "entities": []}, {"text": "\u2022 independent deep reordering: pre-ordering using deep parser without global linguistic constraints.", "labels": [], "entities": []}, {"text": "\u2022 independent deep reordering + zero subject: pre-ordering using deep parser and zero subject generation without global linguistic constraints.", "labels": [], "entities": []}, {"text": "\u2022 joint deep reordering: pre-ordering using our new deep parser with global linguistic constraints.", "labels": [], "entities": []}, {"text": "\u2022 joint deep reordering + zero-subject: preordering using deep parser and zero subject generation with global linguistic constraints.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Examples of deep parser output  (today wa) {d=other} (liquor ga) {d=obj} (can drink) {v=potential, z=I}  (news ga) {d=subj} (was broadcast) {v=passive, z=already exist}  (pasta wa) {d=obj} (ate+question) {v=active, z=you}  (you wa) {d=subj} (ate+question) {v=active, z=already exist}", "labels": [], "entities": []}, {"text": " Table 3: Results for different reordering methods  System", "labels": [], "entities": []}]}