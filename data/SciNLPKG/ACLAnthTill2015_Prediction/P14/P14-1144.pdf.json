{"title": [{"text": "Modeling Prompt Adherence in Student Essays", "labels": [], "entities": [{"text": "Modeling Prompt Adherence", "start_pos": 0, "end_pos": 25, "type": "TASK", "confidence": 0.8670480847358704}]}], "abstractContent": [{"text": "Recently, researchers have begun exploring methods of scoring student essays with respect to particular dimensions of quality such as coherence, technical errors, and prompt adherence.", "labels": [], "entities": []}, {"text": "The work on modeling prompt adherence, however, has been focused mainly on whether individual sentences adhere to the prompt.", "labels": [], "entities": []}, {"text": "We present anew annotated corpus of essay-level prompt adherence scores and propose a feature-rich approach to scoring essays along the prompt adherence dimension.", "labels": [], "entities": []}, {"text": "Our approach significantly outper-forms a knowledge-lean baseline prompt adherence scoring system yielding improvements of up to 16.6%.", "labels": [], "entities": []}], "introductionContent": [{"text": "Automated essay scoring, the task of employing computer technology to evaluate and score written text, is one of the most important educational applications of natural language processing (NLP) (see and for an overview of the state of the art in this task).", "labels": [], "entities": [{"text": "Automated essay scoring", "start_pos": 0, "end_pos": 23, "type": "TASK", "confidence": 0.6846197446187338}, {"text": "natural language processing (NLP)", "start_pos": 160, "end_pos": 193, "type": "TASK", "confidence": 0.7868438263734182}]}, {"text": "A major weakness of many existing scoring engines such as the Intelligent Essay Assessor TM () is that they adopt a holistic scoring scheme, which summarizes the quality of an essay with a single score and thus provides very limited feedback to the writer.", "labels": [], "entities": [{"text": "Intelligent Essay Assessor TM", "start_pos": 62, "end_pos": 91, "type": "TASK", "confidence": 0.546636313199997}]}, {"text": "In particular, it is not clear which dimension of an essay (e.g., style, coherence, relevance) a score should be attributed to.", "labels": [], "entities": []}, {"text": "Recent work addresses this problem by scoring a particular dimension of essay quality such as coherence), technical errors, organization, and thesis clarity.", "labels": [], "entities": []}, {"text": "Essay grading software that provides feedback along multiple dimensions of essay quality such as E-rater/Criterion ( ) has also begun to emerge.", "labels": [], "entities": []}, {"text": "Our goal in this paper is to develop a computational model for scoring an essay along an under-investigated dimension -prompt adherence.", "labels": [], "entities": []}, {"text": "Prompt adherence refers to how related an essay's content is to the prompt for which it was written.", "labels": [], "entities": [{"text": "Prompt adherence", "start_pos": 0, "end_pos": 16, "type": "TASK", "confidence": 0.8537812829017639}]}, {"text": "An essay with a high prompt adherence score consistently remains on the topic introduced by the prompt and is free of irrelevant digressions.", "labels": [], "entities": []}, {"text": "To our knowledge, little work has been done on scoring the prompt adherence of student essays since.", "labels": [], "entities": []}, {"text": "Nevertheless, there are major differences between Higgins et al.'s work and our work with respect to both the way the task is formulated and the approach.", "labels": [], "entities": []}, {"text": "Regarding task formulation, while Higgins et al. focus on classifying each sentence as having either good or bad adherence to the prompt, we focus on assigning a prompt adherence score to the entire essay, allowing the score to range from one to four points at half-point increments.", "labels": [], "entities": [{"text": "task formulation", "start_pos": 10, "end_pos": 26, "type": "TASK", "confidence": 0.7222052365541458}]}, {"text": "As far as the approach is concerned, Higgins et al. adopt a knowledgelean approach to the task, where almost all of the features they employ are computed based on a word-based semantic similarity measure known as Random Indexing ().", "labels": [], "entities": []}, {"text": "On the other hand, we employ a large variety of features, including lexical and knowledge-based features that encode how well the concepts in an essay match those in the prompt, LDA-based features that provide semantic generalizations of lexical features, and \"error type\" features that encode different types of errors the writer made that are related to prompt adherence.", "labels": [], "entities": []}, {"text": "In sum, our contributions in this paper are twofold.", "labels": [], "entities": []}, {"text": "First, we develop a scoring model for the prompt adherence dimension on student essays using a feature-rich approach.", "labels": [], "entities": []}, {"text": "Second, in order to stimulate further research on this task, we make our data set consisting of prompt adherence an-Topic Languages Essays Most university degrees are theoretical and do not prepare students for the real world.", "labels": [], "entities": []}, {"text": "They are therefore of very little value.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section, we evaluate our system for prompt adherence scoring.", "labels": [], "entities": []}, {"text": "All the results we report are obtained via five-fold cross-validation experiments.", "labels": [], "entities": []}, {"text": "In each experiment, we use 3 5 of our labeled essays for model training, another 1 5 for parameter tuning, and the final 1 5 for testing.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 3: Distribution of prompt adherence scores.", "labels": [], "entities": []}, {"text": " Table 4: Five-fold cross-validation results for  prompt adherence scoring.", "labels": [], "entities": []}, {"text": " Table 5: Feature ablation results. In each subtable,", "labels": [], "entities": []}, {"text": " Table 6: Regressor scores for our system.", "labels": [], "entities": [{"text": "Regressor", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9222692847251892}]}]}