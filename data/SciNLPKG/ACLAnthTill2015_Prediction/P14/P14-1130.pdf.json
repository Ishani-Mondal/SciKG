{"title": [{"text": "Low-Rank Tensors for Scoring Dependency Structures", "labels": [], "entities": [{"text": "Scoring Dependency Structures", "start_pos": 21, "end_pos": 50, "type": "TASK", "confidence": 0.8880972266197205}]}], "abstractContent": [{"text": "Accurate scoring of syntactic structures such as head-modifier arcs in dependency parsing typically requires rich, high-dimensional feature representations.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 71, "end_pos": 89, "type": "TASK", "confidence": 0.7748178541660309}]}, {"text": "A small subset of such features is often selected manually.", "labels": [], "entities": []}, {"text": "This is problematic when features lack clear linguistic meaning as in embeddings or when the information is blended across features.", "labels": [], "entities": []}, {"text": "In this paper, we use tensors to map high-dimensional feature vectors into low dimensional representations.", "labels": [], "entities": []}, {"text": "We explicitly maintain the parameters as a low-rank tensor to obtain low dimensional representations of words in their syntactic roles, and to leverage mod-ularity in the tensor for easy training with online algorithms.", "labels": [], "entities": []}, {"text": "Our parser consistently outperforms the Turbo and MST parsers across 14 different languages.", "labels": [], "entities": []}, {"text": "We also obtain the best published UAS results on 5 languages.", "labels": [], "entities": [{"text": "UAS", "start_pos": 34, "end_pos": 37, "type": "DATASET", "confidence": 0.558800995349884}]}], "introductionContent": [{"text": "Finding an expressive representation of input sentences is crucial for accurate parsing.", "labels": [], "entities": []}, {"text": "Syntactic relations manifest themselves in abroad range of surface indicators, ranging from morphological to lexical, including positional and part-of-speech (POS) tagging features.", "labels": [], "entities": [{"text": "positional and part-of-speech (POS) tagging", "start_pos": 128, "end_pos": 171, "type": "TASK", "confidence": 0.6408419694219317}]}, {"text": "Traditionally, parsing research has focused on modeling the direct connection between the features and the predicted syntactic relations such as head-modifier (arc) relations in dependency parsing.", "labels": [], "entities": [{"text": "parsing", "start_pos": 15, "end_pos": 22, "type": "TASK", "confidence": 0.9824239015579224}, {"text": "dependency parsing", "start_pos": 178, "end_pos": 196, "type": "TASK", "confidence": 0.802140086889267}]}, {"text": "Even in the case of firstorder parsers, this results in a high-dimensional vector representation of each arc.", "labels": [], "entities": []}, {"text": "Discrete features, and their cross products, can be further complemented with auxiliary information about words participating in an arc, such as continuous vector representations of words.", "labels": [], "entities": []}, {"text": "The exploding dimensionality of rich feature vectors must then be balanced with the difficulty of effectively learning the associated parameters from limited training data.", "labels": [], "entities": []}, {"text": "A predominant way to counter the high dimensionality of features is to manually design or select a meaningful set of feature templates, which are used to generate different types of features).", "labels": [], "entities": []}, {"text": "Direct manual selection maybe problematic for two reasons.", "labels": [], "entities": []}, {"text": "First, features may lack clear linguistic interpretation as in distributional features or continuous vector embeddings of words.", "labels": [], "entities": []}, {"text": "Second, designing a small subset of templates (and features) is challenging when the relevant linguistic information is distributed across the features.", "labels": [], "entities": []}, {"text": "For instance, morphological properties are closely tied to part-of-speech tags, which in turn relate to positional features.", "labels": [], "entities": []}, {"text": "These features are not redundant.", "labels": [], "entities": []}, {"text": "Therefore, we may suffer a performance loss if we select only a small subset of the features.", "labels": [], "entities": []}, {"text": "On the other hand, by including all the rich features, we face over-fitting problems.", "labels": [], "entities": []}, {"text": "We depart from this view and leverage highdimensional feature vectors by mapping them into low dimensional representations.", "labels": [], "entities": []}, {"text": "We begin by representing high-dimensional feature vectors as multi-way cross-products of smaller feature vectors that represent words and their syntactic relations (arcs).", "labels": [], "entities": []}, {"text": "The associated parameters are viewed as a tensor (multi-way array) of low rank, and optimized for parsing performance.", "labels": [], "entities": [{"text": "parsing", "start_pos": 98, "end_pos": 105, "type": "TASK", "confidence": 0.9691048264503479}]}, {"text": "By explicitly representing the tensor in a low-rank form, we have direct control over the effective dimensionality of the set of parameters.", "labels": [], "entities": []}, {"text": "We obtain role-dependent low-dimensional representations for words (head, modifier) that are specifically tailored for parsing accuracy, and use standard online algorithms for optimizing the low-rank tensor components.", "labels": [], "entities": [{"text": "parsing", "start_pos": 119, "end_pos": 126, "type": "TASK", "confidence": 0.9534738063812256}, {"text": "accuracy", "start_pos": 127, "end_pos": 135, "type": "METRIC", "confidence": 0.7762846946716309}]}, {"text": "The overall approach has clear linguistic and computational advantages: \u2022 Our low dimensional embeddings are tailored to the syntactic context of words (head, modifier).", "labels": [], "entities": []}, {"text": "This low dimensional syntactic abstraction can bethought of as a proxy to manually constructed POS tags.", "labels": [], "entities": []}, {"text": "\u2022 By automatically selecting a small number of dimensions useful for parsing, we can leverage a wide array of (correlated) features.", "labels": [], "entities": [{"text": "parsing", "start_pos": 69, "end_pos": 76, "type": "TASK", "confidence": 0.9850969910621643}]}, {"text": "Unlike parsers such as MST, we can easily benefit from auxiliary information (e.g., word vectors) appended as features.", "labels": [], "entities": []}, {"text": "We implement the low-rank factorization model in the context of first-and third-order dependency parsing.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 86, "end_pos": 104, "type": "TASK", "confidence": 0.6870641559362411}]}, {"text": "The model was evaluated on 14 languages, using dependency data from.", "labels": [], "entities": []}, {"text": "We compare our results against the MST () and) parsers.", "labels": [], "entities": []}, {"text": "The low-rank parser achieves average performance of 89.08% across 14 languages, compared to 88.73% for the Turbo parser, and 87.19% for MST.", "labels": [], "entities": [{"text": "MST", "start_pos": 136, "end_pos": 139, "type": "DATASET", "confidence": 0.8872412443161011}]}, {"text": "The power of the low-rank model becomes evident in the absence of any part-of-speech tags.", "labels": [], "entities": []}, {"text": "For instance, on the English dataset, the low-rank model trained without POS tags achieves 90.49% on first-order parsing, while the baseline gets 86.70% if trained under the same conditions, and 90.58% if trained with 12 core POS tags.", "labels": [], "entities": [{"text": "English dataset", "start_pos": 21, "end_pos": 36, "type": "DATASET", "confidence": 0.9519629180431366}]}, {"text": "Finally, we demonstrate that the model can successfully leverage word vector representations, in contrast to the baselines.", "labels": [], "entities": []}], "datasetContent": [{"text": "Datasets We test our dependency model on 14 languages, including the English dataset from CoNLL 2008 shared tasks and all 13 datasets from CoNLL 2006 shared tasks ().", "labels": [], "entities": [{"text": "English dataset from CoNLL 2008 shared tasks", "start_pos": 69, "end_pos": 113, "type": "DATASET", "confidence": 0.83119940332004}, {"text": "CoNLL 2006 shared tasks", "start_pos": 139, "end_pos": 162, "type": "DATASET", "confidence": 0.9130887091159821}]}, {"text": "These datasets include manually annotated dependency trees, POS tags and morphological information.", "labels": [], "entities": []}, {"text": "Following standard practices, we encode this information as features.", "labels": [], "entities": []}, {"text": "Methods We compare our model to MST and Turbo parsers on non-projective dependency parsing.", "labels": [], "entities": []}, {"text": "For our parser, we train both a first-order parsing model (as described in Section 3 and 4) as well as a third-order model.", "labels": [], "entities": []}, {"text": "The third order parser simply adds high-order features, those typically used in MST and Turbo parsers, into our s \u03b8 (x, y) = \u03b8, \u03c6(x, y) scoring component.", "labels": [], "entities": []}, {"text": "The decoding algorithm for the third-order parsing is based on ().", "labels": [], "entities": []}, {"text": "For the Turbo parser, we directly compare with the recent published results in.", "labels": [], "entities": [{"text": "Turbo parser", "start_pos": 8, "end_pos": 20, "type": "TASK", "confidence": 0.6637378334999084}]}, {"text": "For the MST parser, we train and test using the most recent version of the code.", "labels": [], "entities": [{"text": "MST parser", "start_pos": 8, "end_pos": 18, "type": "TASK", "confidence": 0.5746557116508484}]}, {"text": "In addition, we implemented two additional baselines, NT-1st (first order) and NT-3rd (third order), corresponding to our model without the tensor component.", "labels": [], "entities": []}, {"text": "Features For the arc feature vector \u03c6 h\u2192m , we use the same set of feature templates as MST v0.5.1.", "labels": [], "entities": []}, {"text": "For head/modifier vector \u03c6 hand \u03c6 m , we show the complete set of feature templates used by our model in   and S \u00b8 ensoy, 2013), learned from raw data.", "labels": [], "entities": []}, {"text": "Three languages in our dataset -English, German and Swedish -have corresponding word vectors in this collection.", "labels": [], "entities": []}, {"text": "The dimensionality of this representation varies by language: English has 50 dimensional word vectors, while German and Swedish have 25 dimensional word vectors.", "labels": [], "entities": []}, {"text": "Each entry of the word vector is added as a feature value into feature vectors \u03c6 hand \u03c6 m . For each word in the sentence, we add its own word vector as well as the vectors of its left and right words.", "labels": [], "entities": []}, {"text": "We should note that since our model parameter A is represented and learned in the low-rank form, we only have to store and maintain the low-rank projections U \u03c6 h , V \u03c6 m and W \u03c6 h,m rather than explicitly calculate the feature tensor \u03c6 h \u2297\u03c6 m \u2297\u03c6 h,m . Therefore updating parameters and decoding a sentence is still efficient, i.e., linear in the number of values of the feature vector.", "labels": [], "entities": []}, {"text": "In contrast, assume we take the cross-product of the auxiliary word vector values, POS tags and lexical items of a word and its context, and add the crossed values into a normal model (in \u03c6 h\u2192m ).", "labels": [], "entities": []}, {"text": "The number of features for each arc would beat least quadratic, growing into thousands, and would be a significant impediment to parsing efficiency.", "labels": [], "entities": [{"text": "parsing", "start_pos": 129, "end_pos": 136, "type": "TASK", "confidence": 0.9814620018005371}]}, {"text": "Evaluation Following standard practices, we train our full model and the baselines for 10 5 https://github.com/wolet/sprml13-word-embeddings epochs.", "labels": [], "entities": []}, {"text": "As the evaluation measure, we use unlabeled attachment scores (UAS) excluding punctuation.", "labels": [], "entities": [{"text": "unlabeled attachment scores (UAS)", "start_pos": 34, "end_pos": 67, "type": "METRIC", "confidence": 0.7671232968568802}]}, {"text": "In all the reported experiments, the hyperparameters are set as follows: r = 50 (rank of the tensor), C = 1 for first-order model and C = 0.01 for third-order model.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 3: Results of adding unsupervised word vec- tors to the tensor. Adding this information yields  consistent improvement for all languages.", "labels": [], "entities": []}, {"text": " Table 4: The first three columns show parsing re- sults when models are trained without POS tags.  The last column gives the upper-bound, i.e. the  performance of a parser trained with 12 Core POS  tags. The low-rank model outperforms NT-1st by  a large margin. Adding word vector features fur- ther improves performance.", "labels": [], "entities": [{"text": "NT-1st", "start_pos": 236, "end_pos": 242, "type": "DATASET", "confidence": 0.8310853242874146}]}, {"text": " Table 5: Five closest neighbors of the queried  words (shown in bold). The upper part shows our  learned embeddings group words with similar syn- tactic behavior. The two bottom parts of the table  demonstrate that how the projections change de- pending on the syntactic context of the word.", "labels": [], "entities": []}, {"text": " Table 6: Comparison of training times across three  typical datasets. The second column is the number  of tokens in each data set. The third column shows  the average sentence length. Both first-order mod- els are implemented in Java and run as a single  process.", "labels": [], "entities": []}]}