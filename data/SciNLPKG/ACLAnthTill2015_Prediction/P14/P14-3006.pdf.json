{"title": [{"text": "An Exploration of Embeddings for Generalized Phrases", "labels": [], "entities": []}], "abstractContent": [{"text": "Deep learning embeddings have been successfully used for many natural language processing problems.", "labels": [], "entities": []}, {"text": "Embeddings are mostly computed for word forms although lots of recent papers have extended this to other linguistic units like morphemes and word sequences.", "labels": [], "entities": []}, {"text": "In this paper, we define the concept of generalized phrase that includes conventional linguistic phrases as well as skip-bigrams.", "labels": [], "entities": []}, {"text": "We compute em-beddings for generalized phrases and show in experimental evaluations on corefer-ence resolution and paraphrase identification that such embeddings perform better than word form embeddings.", "labels": [], "entities": [{"text": "corefer-ence resolution", "start_pos": 87, "end_pos": 110, "type": "TASK", "confidence": 0.8467184007167816}, {"text": "paraphrase identification", "start_pos": 115, "end_pos": 140, "type": "TASK", "confidence": 0.8031222224235535}]}], "introductionContent": [], "datasetContent": [{"text": "Our motivation for generalized phrases in Section 1 was that they can be used to infer the attributes of the context they enclose and that they can capture non-compositional semantics.", "labels": [], "entities": []}, {"text": "Our hypothesis was that they are more suitable for this than word embeddings.", "labels": [], "entities": []}, {"text": "In this section we carryout two experiments to test this hypothesis.", "labels": [], "entities": []}, {"text": "We compare the following representations for animacy classification of markables.", "labels": [], "entities": [{"text": "animacy classification of markables", "start_pos": 45, "end_pos": 80, "type": "TASK", "confidence": 0.7673760056495667}]}, {"text": "(i) Phrase embedding: Skip-bigram embeddings with skip distance k = 2 and 2 \u2264 k \u2264 3; (ii) Word embedding: concatenation of the embeddings of the two enclosing words where the embeddings are either standard word2vec embeddings (see Section 2) or the embeddings published by: Classification accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 289, "end_pos": 297, "type": "METRIC", "confidence": 0.9609478712081909}]}, {"text": "Mark \"*\" means significantly lower than \"phrase embedding\", k = 2; \" \u2020\" means significantly lower than \"phrase embedding\", 2 \u2264 k \u2264 3.", "labels": [], "entities": []}, {"text": "As significance test, we use the test of equal proportion, p < .05, throughout.", "labels": [], "entities": [{"text": "significance", "start_pos": 3, "end_pos": 15, "type": "METRIC", "confidence": 0.9826357364654541}]}, {"text": "The results show that phrase embeddings have an obvious advantage in this classification task, both fork = 2 and 2 \u2264 k \u2264 3.", "labels": [], "entities": [{"text": "fork", "start_pos": 100, "end_pos": 104, "type": "METRIC", "confidence": 0.9747505784034729}]}, {"text": "This validates our hypothesis that learning embeddings for discontinuous linguistic units is promising.", "labels": [], "entities": []}, {"text": "In our error analysis, we found two types of frequent errors.", "labels": [], "entities": []}, {"text": "(i) Unspecific SkipBs.", "labels": [], "entities": []}, {"text": "Many SkipBs are equally appropriate for animate and inanimate markables.", "labels": [], "entities": []}, {"text": "Examples of such SkipBs include \"take*in\" and \"then*goes\".", "labels": [], "entities": []}, {"text": "(ii) Untypical use of specific SkipBs.", "labels": [], "entities": []}, {"text": "Even SkipBs that are specific with respect to what type of markable they enclose sometimes occur with the \"wrong\" type of markable.", "labels": [], "entities": []}, {"text": "For example, most markables occurring in the SkipB \"of*whose\" are animate because \"whose\" usually refers to an animate markable.", "labels": [], "entities": []}, {"text": "However, in the context \".", "labels": [], "entities": []}, {"text": "the southeastern area of Fujian whose economy is the most active\" the enclosed markable is Fujian, a province of China.", "labels": [], "entities": []}, {"text": "This example shows that \"whose\" occasionally refers to an inanimate entity even though these cases are infrequent.", "labels": [], "entities": []}, {"text": "shows some SkipBs and their nearest neighbors in descending order, where similarity is computed with cosine measure.", "labels": [], "entities": [{"text": "similarity", "start_pos": 73, "end_pos": 83, "type": "METRIC", "confidence": 0.9761598110198975}]}, {"text": "We are interested in how phrase embeddings make an impact on this task.", "labels": [], "entities": []}, {"text": "To that end, we perform an analysis on test examples where word embeddings are better than phrase embeddings and vice versa.", "labels": [], "entities": []}, {"text": "shows four pairs, of which \"phrase embedding\" outperforms \"word embedding\" in the  first two examples, \"word embedding\" defeats \"phrase embedding\" in the last two examples.", "labels": [], "entities": []}, {"text": "In the first pair, successful phrase detection enables to split sentences into better units, thus the generated representation can convey the sentence meaning more exactly.", "labels": [], "entities": [{"text": "phrase detection", "start_pos": 30, "end_pos": 46, "type": "TASK", "confidence": 0.8341823518276215}]}], "tableCaptions": [{"text": " Table 1: Phrases and their nearest neighbors", "labels": [], "entities": []}, {"text": " Table 2: Classification accuracy. Mark \"*\" means  significantly lower than \"phrase embedding\", k =  2; \" \u2020\" means significantly lower than \"phrase em- bedding\", 2 \u2264 k \u2264 3. As significance test, we use  the test of equal proportion, p < .05, throughout.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 25, "end_pos": 33, "type": "METRIC", "confidence": 0.961844801902771}, {"text": "Mark", "start_pos": 35, "end_pos": 39, "type": "METRIC", "confidence": 0.9914323091506958}]}, {"text": " Table 4: Paraphrase task results.", "labels": [], "entities": []}]}