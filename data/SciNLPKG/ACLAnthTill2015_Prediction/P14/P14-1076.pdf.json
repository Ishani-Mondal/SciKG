{"title": [{"text": "Robust Domain Adaptation for Relation Extraction via Clustering Consistency", "labels": [], "entities": [{"text": "Robust Domain Adaptation", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.7948202689488729}, {"text": "Relation Extraction", "start_pos": 29, "end_pos": 48, "type": "TASK", "confidence": 0.9376239776611328}]}], "abstractContent": [{"text": "We propose a two-phase framework to adapt existing relation extraction classi-fiers to extract relations for new target domains.", "labels": [], "entities": []}, {"text": "We address two challenges: negative transfer when knowledge in source domains is used without considering the differences in relation distributions; and lack of adequate labeled samples for rarer relations in the new domain, due to a small labeled data set and imbalance relation distributions.", "labels": [], "entities": []}, {"text": "Our framework leverages on both labeled and unlabeled data in the target domain.", "labels": [], "entities": []}, {"text": "First, we determine the relevance of each source domain to the target domain for each relation type, using the consistency between the clustering given by the target domain labels and the clustering given by the predic-tors trained for the source domain.", "labels": [], "entities": []}, {"text": "To overcome the lack of labeled samples for rarer relations, these clusterings operate on both the labeled and unlabeled data in the target domain.", "labels": [], "entities": []}, {"text": "Second, we trade-off between using relevance-weighted source-domain predictors and the labeled target data.", "labels": [], "entities": []}, {"text": "Again, to overcome the imbalance distribution, the source-domain predictors operate on the unlabeled target data.", "labels": [], "entities": []}, {"text": "Our method outperforms numerous baselines and a weakly-supervised relation extraction method on ACE 2004 and YAGO.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 66, "end_pos": 85, "type": "TASK", "confidence": 0.7161021083593369}, {"text": "ACE 2004", "start_pos": 96, "end_pos": 104, "type": "DATASET", "confidence": 0.947372317314148}, {"text": "YAGO", "start_pos": 109, "end_pos": 113, "type": "DATASET", "confidence": 0.5322080850601196}]}], "introductionContent": [{"text": "The World Wide Web contains information on real-world entities, such as persons, locations and organizations, which are interconnected by various semantic relations.", "labels": [], "entities": []}, {"text": "Detecting these relations between two entities is important for many tasks on the Web, such as information retrieval and information extraction for question answering . Recent work on relation extraction has demonstrated that supervised machine learning coupled with intelligent feature engineering can provide state-of-theart performance.", "labels": [], "entities": [{"text": "information retrieval", "start_pos": 95, "end_pos": 116, "type": "TASK", "confidence": 0.7693262696266174}, {"text": "information extraction", "start_pos": 121, "end_pos": 143, "type": "TASK", "confidence": 0.7139526456594467}, {"text": "question answering", "start_pos": 148, "end_pos": 166, "type": "TASK", "confidence": 0.7369233965873718}, {"text": "relation extraction", "start_pos": 184, "end_pos": 203, "type": "TASK", "confidence": 0.765749990940094}]}, {"text": "However, most supervised learning algorithms require adequate labeled data for every relation type to be extracted.", "labels": [], "entities": []}, {"text": "Due to the large number of relations among entities, it maybe costly to annotate a large enough set of training data to cover each relation type adequately in every new domain of interest.", "labels": [], "entities": []}, {"text": "Instead, it can be more cost-effective to adapt an existing relation extraction system to the new domain using a small set of labeled data.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 60, "end_pos": 79, "type": "TASK", "confidence": 0.7422264218330383}]}, {"text": "This paper considers relation adaptation, where a relation extraction system trained on many source domains is adapted to anew target domain.", "labels": [], "entities": [{"text": "relation adaptation", "start_pos": 21, "end_pos": 40, "type": "TASK", "confidence": 0.959726095199585}, {"text": "relation extraction", "start_pos": 50, "end_pos": 69, "type": "TASK", "confidence": 0.7734990119934082}]}, {"text": "There are at least three challenges when adapting a relation extraction system to anew domain.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 52, "end_pos": 71, "type": "TASK", "confidence": 0.7909002304077148}]}, {"text": "First, the same semantic relation between two entities can be expressed using different lexical or syntactic patterns.", "labels": [], "entities": []}, {"text": "For example, the acquisition of company A by company B can be expressed with \"B bought over by A\", \"A buys B\" and \"A purchases B\".", "labels": [], "entities": []}, {"text": "To extract a relation, we need to capture the different ways in which it can be expressed across different open domains on the Web.", "labels": [], "entities": []}, {"text": "Second, the emphasis or interest on the different relation types varies from domain to domain.", "labels": [], "entities": []}, {"text": "For example, in the organization domain, we maybe more interested in extracting relations such as locatedIn (between a company and a location) and founderOf (between a company and a person), whereas in the person domain we maybe more interested in extracting relations such as liveIn (between a person and a location) and workAt (between a person and a company).", "labels": [], "entities": []}, {"text": "Therefore, although the two domains may have the same set of relations, they probably have different marginal distributions on the relations.", "labels": [], "entities": []}, {"text": "This can produce a negative transfer phenomenon (, where using knowledge from other domains degrades the performance on the target domain.", "labels": [], "entities": []}, {"text": "Hence, when transferring knowledge from multiple domains, it is overly optimistic to believe that all source domains will contribute positively.", "labels": [], "entities": []}, {"text": "We calla source domain irrelevant when it has no or negative contribution to the performance of the target domain.", "labels": [], "entities": []}, {"text": "One example is named entities extraction adaptation, where na\u00a8\u0131vena\u00a8\u0131ve transfer of information from a mixed-case domain with capitalization information (e.g., news-wire) to a single-case domain (e.g., conversational speech transcripts) will miss most names in the single-case domain due to the absence of case information, which is typically important in the mixed-case domain.", "labels": [], "entities": [{"text": "named entities extraction adaptation", "start_pos": 15, "end_pos": 51, "type": "TASK", "confidence": 0.7389656379818916}]}, {"text": "Third, the annotated instances for the target domain are typically much fewer than those for the source domains.", "labels": [], "entities": []}, {"text": "This is primarily due to the lack of resources such as raw target domain documents, time, and people with the expertise.", "labels": [], "entities": []}, {"text": "Together with imbalanced relation distributions inherent in the domain, this can cause some rarer relations to constitute only a very small proportion of the labeled data set.", "labels": [], "entities": []}, {"text": "This makes learning a relation classifier for the target domain challenging.", "labels": [], "entities": []}, {"text": "To tackle these challenges, we propose a twophase Robust Domain Adaptation (RDA) framework.", "labels": [], "entities": [{"text": "Robust Domain Adaptation (RDA)", "start_pos": 50, "end_pos": 80, "type": "TASK", "confidence": 0.7157047589619955}]}, {"text": "In the first phase, Supervised Voting is used to determine the relevance of each source domain to each region in the target domain, using both labeled and unlabeled data in the target domain.", "labels": [], "entities": []}, {"text": "By using also unlabeled data, we alleviate the lack of labeled samples for rarer relations due to imbalanced distributions in relation types.", "labels": [], "entities": []}, {"text": "The second phase uses the relevances determined the first phase to produce a reference predictor by weighing the source-domain predictors for each target domain sample separately.", "labels": [], "entities": []}, {"text": "The intention is to alleviate the effect of mismatched distributions.", "labels": [], "entities": []}, {"text": "The final predictor in the target domain is trained on the labeled target domain data while taking reference from the reference predictions on the unlabeled target domain data.", "labels": [], "entities": []}, {"text": "This ensures reasonable predictive performance even when all the source domains are irrelevant and augments the rarer classes with examples in the unlabeled data.", "labels": [], "entities": []}, {"text": "We compare the proposed two-phase framework with state-of-the-art domain adaptation baselines for the relation extraction task, and we find that our method outperforms the baselines.", "labels": [], "entities": [{"text": "relation extraction task", "start_pos": 102, "end_pos": 126, "type": "TASK", "confidence": 0.889315108458201}]}], "datasetContent": [{"text": "We evaluate our algorithm on two corpora: Automatic Content Extraction (ACE).", "labels": [], "entities": [{"text": "Automatic Content Extraction", "start_pos": 42, "end_pos": 70, "type": "TASK", "confidence": 0.5746989150842031}]}, {"text": "It consists of twenty relation types such as ceo company, bornIn and isMarriedTo, and each of them is considered as a domain in this work.", "labels": [], "entities": []}, {"text": "YAGO is different from ACE 2004 in two aspects: there is less overlapping of topics, entity types and relation types between domains; and it has more relation mentions with 11 mentions per pair of entities on the average.", "labels": [], "entities": [{"text": "YAGO", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.724507212638855}]}, {"text": "We used Collins parser) to parse the sentences.", "labels": [], "entities": []}, {"text": "The constituent parse trees were then transformed into dependency parse trees, using the head of each constituent).", "labels": [], "entities": []}, {"text": "The candidate relation instances were generated by considering all pairs of entities that occur in the same sentence.", "labels": [], "entities": []}, {"text": "For the similarity matrix W in section 4.1 and the kernel K(\u00b7, \u00b7) in section 4.2, we used the composite kernel function (), which is based on structured features and entity-related features.", "labels": [], "entities": []}, {"text": "F 1 is used to measure the performance of the algorithms.", "labels": [], "entities": [{"text": "F 1", "start_pos": 0, "end_pos": 3, "type": "METRIC", "confidence": 0.9829926788806915}]}, {"text": "This is the harmonic mean of precision TP/(TP + FP) and recall TP/, where TP, FP and FN are the numbers of correct, missing and wrongly recognized relations.", "labels": [], "entities": [{"text": "precision TP/(TP + FP)", "start_pos": 29, "end_pos": 51, "type": "METRIC", "confidence": 0.8535806110927037}, {"text": "recall TP", "start_pos": 56, "end_pos": 65, "type": "METRIC", "confidence": 0.9182938039302826}, {"text": "TP", "start_pos": 74, "end_pos": 76, "type": "METRIC", "confidence": 0.943941056728363}, {"text": "FP", "start_pos": 78, "end_pos": 80, "type": "METRIC", "confidence": 0.9174678921699524}, {"text": "FN", "start_pos": 85, "end_pos": 87, "type": "METRIC", "confidence": 0.897695779800415}]}, {"text": "For ACE 2004, we used each of the six domains as the target domain and the remaining domains as source domains.", "labels": [], "entities": [{"text": "ACE 2004", "start_pos": 4, "end_pos": 12, "type": "DATASET", "confidence": 0.921705573797226}]}, {"text": "For YAGO, each relation type in YAGO was considered as a domain.", "labels": [], "entities": []}, {"text": "For each domain in YAGO, we have a binary classification task: whether the instance has the relation corresponding to the domain.", "labels": [], "entities": [{"text": "YAGO", "start_pos": 19, "end_pos": 23, "type": "DATASET", "confidence": 0.8009575009346008}]}, {"text": "Five-fold crossvalidation was used to evaluate the performance.", "labels": [], "entities": []}, {"text": "For every target domain, we divided all data into 5 subsets, and we used each subset for testing and the other four subsets for training.", "labels": [], "entities": []}, {"text": "In the training set, we randomly removed most of the positive instances of the target domain from the training set except for 10% of the labeled data.", "labels": [], "entities": []}, {"text": "This gave us the weakly-supervised setting.", "labels": [], "entities": []}, {"text": "This was repeated five times with different training and test sets.", "labels": [], "entities": []}, {"text": "We report the average performance over the five runs.", "labels": [], "entities": []}, {"text": "In our experiments, we set \u00b5 = 0.8 in Eq.", "labels": [], "entities": [{"text": "\u00b5", "start_pos": 27, "end_pos": 28, "type": "METRIC", "confidence": 0.9762925505638123}, {"text": "Eq", "start_pos": 38, "end_pos": 40, "type": "DATASET", "confidence": 0.825020968914032}]}, {"text": "1; \u03b8 = 0.18 in Eq.", "labels": [], "entities": [{"text": "\u03b8", "start_pos": 3, "end_pos": 4, "type": "METRIC", "confidence": 0.9602989554405212}]}, {"text": "2; and \u03b3 = 0.1 and \u03b2 = 0.3 in Eq.", "labels": [], "entities": []}, {"text": "3. For each target domain, we used k \u2208 {1, 3, 5} different source domains chosen randomly from the remaining domains.", "labels": [], "entities": []}, {"text": "Thus, the relevance of the source domains to the target domain varies from experiment to experiment.", "labels": [], "entities": []}, {"text": "We find that MTL, DAB and SCL are better than NT-U when the majority of source domains are relevant.", "labels": [], "entities": []}, {"text": "This shows that MTL, DAB and SCL are able to make more effective use of relevant sources than NT-U.", "labels": [], "entities": [{"text": "NT-U", "start_pos": 94, "end_pos": 98, "type": "DATASET", "confidence": 0.8906497955322266}]}, {"text": "Howevever, we find that their perfomances are not stable: for example, MTL for target UN in.", "labels": [], "entities": [{"text": "MTL", "start_pos": 71, "end_pos": 74, "type": "METRIC", "confidence": 0.6140159964561462}]}, {"text": "In contrast, we find the performance of L-SVM and DAM to be more stable.", "labels": [], "entities": []}, {"text": "The reason is their reduced vulnerability to   We analyzed histogram of the relation types to order the domains according to the imbalance of the class distributions.", "labels": [], "entities": []}, {"text": "Using this, we observe that MTL, DAB and SCL perform relatively badly when the target-domain distribution is more imbalanced.", "labels": [], "entities": []}, {"text": "In constrast, L-SVM, DAM and RDA are more robust.", "labels": [], "entities": [{"text": "RDA", "start_pos": 29, "end_pos": 32, "type": "METRIC", "confidence": 0.7064717411994934}]}, {"text": "Comparing with the baselines, RDA achieves the best performance on almost all the experiments.", "labels": [], "entities": [{"text": "RDA", "start_pos": 30, "end_pos": 33, "type": "TASK", "confidence": 0.5347648859024048}]}, {"text": "Using the two-phase framework, RDA can successfully transfer useful knowledge even in the pressence of irrelevant sources and imbalanced distributions.", "labels": [], "entities": [{"text": "RDA", "start_pos": 31, "end_pos": 34, "type": "TASK", "confidence": 0.956150233745575}]}, {"text": "For ACE 2004, the improvement in F 1 over the best baseline can be up to 4.0% and is on average 3.6%.", "labels": [], "entities": [{"text": "ACE 2004", "start_pos": 4, "end_pos": 12, "type": "DATASET", "confidence": 0.8702700734138489}, {"text": "F 1", "start_pos": 33, "end_pos": 36, "type": "METRIC", "confidence": 0.991773247718811}]}, {"text": "Similarly for YAGO, the improvement in F 1 over the best baseline can be up to 5.5% and is on average 4.3%., 4 and 6 also demonstrate that RDA improves monotonically as the number of source domains increases for both ACE 2004 and YAGO., we observe that the smallest performance gap between RDA and the in-domain settings is still high (about 12% with k = 5) on ACE 2004.", "labels": [], "entities": [{"text": "F 1", "start_pos": 39, "end_pos": 42, "type": "METRIC", "confidence": 0.9939720630645752}, {"text": "ACE 2004", "start_pos": 217, "end_pos": 225, "type": "DATASET", "confidence": 0.9171838164329529}, {"text": "ACE 2004", "start_pos": 361, "end_pos": 369, "type": "DATASET", "confidence": 0.9740409553050995}]}, {"text": "This is because we have used a lot less labeled instances in the target domains: only 10% are used.", "labels": [], "entities": []}, {"text": "However, the gaps reduces when the number of source domains increases.", "labels": [], "entities": []}, {"text": "Comparing with the in-domain results in (which is constant with k), also shows a similar trend on YAGO.", "labels": [], "entities": [{"text": "YAGO", "start_pos": 98, "end_pos": 102, "type": "METRIC", "confidence": 0.6497483849525452}]}, {"text": "By exploiting the labeled data in ten source domains in YAGO, our RDA algorithm can reduce the gap between the cross-domain and in-domain settings to 9%.", "labels": [], "entities": [{"text": "YAGO", "start_pos": 56, "end_pos": 60, "type": "DATASET", "confidence": 0.7766364812850952}]}], "tableCaptions": [{"text": " Table 1: Statistics on ACE 2004 and YAGO  Properties  ACE 2004 YAGO", "labels": [], "entities": [{"text": "ACE 2004", "start_pos": 24, "end_pos": 32, "type": "DATASET", "confidence": 0.8885462582111359}, {"text": "YAGO  Properties  ACE 2004 YAGO", "start_pos": 37, "end_pos": 68, "type": "DATASET", "confidence": 0.8653954863548279}]}, {"text": " Table 2: The F 1 of different methods on ACE 2004 with k = 1 source domain. The best performance for  each target domain is in bold.", "labels": [], "entities": [{"text": "F 1", "start_pos": 14, "end_pos": 17, "type": "METRIC", "confidence": 0.9679944515228271}, {"text": "ACE 2004", "start_pos": 42, "end_pos": 50, "type": "DATASET", "confidence": 0.9464066624641418}]}, {"text": " Table 3: The F 1 of different methods on ACE 2004 with k = 3 source domains.  Target  In-domain  NT  NT-U L-SVM MTL DAB SCL DAM RDA", "labels": [], "entities": [{"text": "ACE 2004", "start_pos": 42, "end_pos": 50, "type": "DATASET", "confidence": 0.8772495090961456}, {"text": "NT  NT-U L-SVM MTL DAB SCL DAM RDA", "start_pos": 98, "end_pos": 132, "type": "TASK", "confidence": 0.4512193910777569}]}, {"text": " Table 4: The F 1 of different methods on ACE 2004 with k = 5 source domains.  Target  In-domain  NT  NT-U L-SVM MTL DAB  SCL DAM RDA", "labels": [], "entities": [{"text": "ACE 2004", "start_pos": 42, "end_pos": 50, "type": "DATASET", "confidence": 0.8726877868175507}, {"text": "NT  NT-U L-SVM MTL DAB  SCL DAM RDA", "start_pos": 98, "end_pos": 133, "type": "TASK", "confidence": 0.45188458636403084}]}, {"text": " Table 5: The F 1 of different methods on YAGO with k = 5 source domains.  Target  In-domain  NT  NT-U L-SVM MTL DAB SCL DAM RDA", "labels": [], "entities": [{"text": "NT  NT-U L-SVM MTL DAB SCL DAM RDA", "start_pos": 94, "end_pos": 128, "type": "TASK", "confidence": 0.44482463225722313}]}, {"text": " Table 6: Average F 1 of RDA on YAGO", "labels": [], "entities": [{"text": "Average F 1", "start_pos": 10, "end_pos": 21, "type": "METRIC", "confidence": 0.8929763237635294}, {"text": "RDA", "start_pos": 25, "end_pos": 28, "type": "METRIC", "confidence": 0.7675364017486572}, {"text": "YAGO", "start_pos": 32, "end_pos": 36, "type": "DATASET", "confidence": 0.4584518074989319}]}]}