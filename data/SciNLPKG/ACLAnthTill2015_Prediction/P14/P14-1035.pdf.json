{"title": [{"text": "A Bayesian Mixed Effects Model of Literary Character", "labels": [], "entities": []}], "abstractContent": [{"text": "We consider the problem of automatically inferring latent character types in a collection of 15,099 English novels published between 1700 and 1899.", "labels": [], "entities": [{"text": "automatically inferring latent character types", "start_pos": 27, "end_pos": 73, "type": "TASK", "confidence": 0.6656566977500915}]}, {"text": "Unlike prior work in which character types are assumed responsible for probabilistically generating all text associated with a character, we introduce a model that employs multiple effects to account for the influence of extra-linguistic information (such as author).", "labels": [], "entities": []}, {"text": "In an empirical evaluation, we find that this method leads to improved agreement with the preregistered judgments of a literary scholar, complementing the results of alternative models.", "labels": [], "entities": []}], "introductionContent": [{"text": "Recent work in NLP has begun to exploit the potential of entity-centric modeling fora variety of tasks: Chambers (2013) places entities at the center of probabilistic frame induction, showing gains over a comparable event-centric model; explicitly learn character types (or \"personas\") in a dataset of Wikipedia movie plot summaries; and entity-centric models form one dominant approach in coreference resolution (.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 390, "end_pos": 412, "type": "TASK", "confidence": 0.9707606136798859}]}, {"text": "One commonality among all of these very different probabilistic approaches is that each learns statistical regularities about how entities are depicted in text (whether for the sake of learning a set of semantic roles, character types, or linking anaphora to the entities to which they refer).", "labels": [], "entities": []}, {"text": "In each case, the text we observe associated with an entity in a document is directly dependent on the class of entity-and only that class.", "labels": [], "entities": []}, {"text": "This relationship between entity and text is a theoretical assumption, with important consequences for learning: entity types learned in this way will be increasingly similar the more similar the domain, author, and other extra-linguistic effects are between them.", "labels": [], "entities": []}, {"text": "1 While in many cases the topically similar types learned under this assumption maybe desirable, we explore here the alternative, in which entity types are learned in away that controls for such effects.", "labels": [], "entities": []}, {"text": "In introducing a model based on different assumptions, we provide a method that complements past work and provides researchers with more flexible tools to infer different kinds of character types.", "labels": [], "entities": []}, {"text": "We focus hereon the literary domain, exploring a large collection of 15,099 English novels published in the 18th and 19th centuries.", "labels": [], "entities": []}, {"text": "By accounting for the influence of individual authors while inferring latent character types, we are able to learn personas that cut across different authors more effectively than if we learned types conditioned on the text alone.", "labels": [], "entities": []}, {"text": "Modeling the language used to describe a character as the joint result of that character's latent type and of other formal variables allows us to test multiple models of character and assess their value for different interpretive problems.", "labels": [], "entities": []}, {"text": "As a test case, we focus on separating character from authorial diction, but this approach can readily be generalized to produce models that provisionally distinguish character from other factors (such as period, genre, or point of view) as well.", "labels": [], "entities": []}], "datasetContent": [{"text": "While standard NLP and machine learning practice is to evaluate the performance of an algorithm on a held-out gold standard, articulating what a true \"persona\" might be fora character is inherently problematic.", "labels": [], "entities": []}, {"text": "Rather, we evaluate the performance and output of our model by preregistering a set of 29 hypotheses of varying scope and difficulty and comparing the performance of different models in either confirming, or failing to confirm, those hypotheses.", "labels": [], "entities": []}, {"text": "This kind of evaluation was previously applied to a subjective text measurement problem by.", "labels": [], "entities": []}, {"text": "All hypotheses were created by a literary scholar with specialization in the period to not only give an empirical measure of the strengths and weaknesses of different models, but also to help explore exactly what the different models may, or may not, be learning.", "labels": [], "entities": []}, {"text": "All preregistered hypotheses establish the degrees of similarity among three characters, taking the form: \"character X is more similar to character Y than either X or Y is to a distractor character Z\"; fora given model and definition of distance under that model, each hypothesis yields two yes/no decisions that we can evaluate: To tease apart the different kinds of similarities we hope to explore, we divide the hypotheses into four classes: A.", "labels": [], "entities": []}, {"text": "This class constitutes sanity checks: character X and Y are more similar to each other in every way than to character Z.", "labels": [], "entities": []}, {"text": "E.g.: Elizabeth Bennet in Pride and Prejudice resembles Elinor Dashwood in Sense and Sensibility (Jane Austen) more than either character resembles Allen Quatermain in Allen Quatermain (H. Rider Haggard).", "labels": [], "entities": [{"text": "Allen Quatermain (H. Rider Haggard)", "start_pos": 168, "end_pos": 203, "type": "DATASET", "confidence": 0.8228455100740705}]}, {"text": "(Austenian protagonists should resemble each other more than they resemble a grizzled hunter.)", "labels": [], "entities": []}, {"text": "B. This class captures our ability to identify two characters in the same author as being more similar to each other than to a closely related character in a different author.", "labels": [], "entities": []}, {"text": "E.g.: Wickham in Pride and Prejudice resembles Willoughby in Sense and Sensibility (Jane Austen) more than either character resembles Mr. Rochester in Jane Eyre (Charlotte Bront\u00eb).", "labels": [], "entities": [{"text": "Wickham in Pride and Prejudice", "start_pos": 6, "end_pos": 36, "type": "TASK", "confidence": 0.7635906338691711}]}, {"text": "C. This class captures our ability to discriminate among similar characters in the same author.", "labels": [], "entities": []}, {"text": "In these hypotheses, two characters X and Y from the same author are more similar to each other than to a third character Z from that same author.", "labels": [], "entities": []}, {"text": "E.g.: Wickham in Pride and Prejudice (Jane Austen) resembles Willoughby in Sense and Sensibility more than either character resembles Mr. Darcy in Pride and Prejudice.", "labels": [], "entities": [{"text": "Wickham in Pride and Prejudice", "start_pos": 6, "end_pos": 36, "type": "TASK", "confidence": 0.5755234599113465}]}, {"text": "D. This class constitutes more difficult, exploratory hypotheses, including differences among point of view.", "labels": [], "entities": []}, {"text": "E.g.: Montoni in Mysteries of Udolpho (Radcliffe) resembles Heathcliff in Wuthering Heights (Emily Bront\u00eb) more than either resembles Mr. Bennet in Pride and Prejudice.", "labels": [], "entities": []}, {"text": "(Testing our model's ability to discern similarities in spite of elapsed time.)", "labels": [], "entities": []}, {"text": "All 29 hypotheses can be found in a supplementary technical report).", "labels": [], "entities": []}, {"text": "We emphasize that the full set of hypotheses was locked before the model was estimated.", "labels": [], "entities": []}, {"text": "Part of the motivation of our mixed effects model is to be able to tackle hypothesis class C-by factoring out the influence of a particular author on the learning of personas, we would like to be able to discriminate between characters that all have a common authorial voice.", "labels": [], "entities": []}, {"text": "In contrast, the Persona Regression model of, which uses metadata variables (like authorship) to encourage entities with similar covariates to have similar personas, reflects an assumption that makes it likely to perform well at class B.", "labels": [], "entities": [{"text": "Persona Regression", "start_pos": 17, "end_pos": 35, "type": "TASK", "confidence": 0.6738996207714081}]}, {"text": "To judge their respective strengths on different hypothesis classes, we evaluate three models: 1.", "labels": [], "entities": []}, {"text": "The mixed-effects Author/Persona model (described above), which includes author information as a metadata effect; here, each \u03b7-vector (of length M + P + 1) contains a parameter for each of the distinct authors in our data, a parameter for each persona, and a background parameter.", "labels": [], "entities": []}, {"text": "2. A Basic persona model, which ablates author information but retains the same loglinear architecture; here, the \u03b7-vector is of size P + 1 and does not model author effects.", "labels": [], "entities": []}, {"text": "3. The Persona Regression model of.", "labels": [], "entities": []}, {"text": "All models are run with P \u2208 {10, 25, 50, 100, 250} personas; Persona Regression additionally uses K = 25 latent topics.", "labels": [], "entities": []}, {"text": "All configurations use the full dataset of 15,099 novels, and all characters with at least 25 total roles (a total of 257,298 entities).", "labels": [], "entities": []}, {"text": "All experiments are run with 50 iterations of Gibbs sampling to collect samples for the personas p, alternating with maximization steps for \u03b7.", "labels": [], "entities": []}, {"text": "The value of \u03b1 is optimized using slice sampling (with a non-informative prior) every 5 iterations.", "labels": [], "entities": []}, {"text": "The value of \u03bb is held constant at 1.", "labels": [], "entities": []}, {"text": "At the end of inference, we calculate the posterior distributions over personas for all characters as the sampling probability of the final iteration.", "labels": [], "entities": []}, {"text": "To formally evaluate \"similarity\" between two characters, we measure the Jensen-Shannon divergence between personas (calculated as the average JS distance over the cluster distributions for each role type), marginalizing over the characters' posterior distributions over personas; two characters with a lower JS divergence are judged to be more similar than two characters with a higher one.", "labels": [], "entities": []}, {"text": "As a Baseline, we also evaluate all hypotheses on a model with no latent variables whatsoever, which instead measures similarity as the average JS divergence between the empirical word distributions over each role type.", "labels": [], "entities": [{"text": "similarity", "start_pos": 118, "end_pos": 128, "type": "METRIC", "confidence": 0.9649159908294678}]}, {"text": "presents the results of this comparison; for all models with latent variables, we report the average of 5 sampling runs with different random initializations.", "labels": [], "entities": []}, {"text": "provides a syn-   Persona regression is best able to judge characters in one author to be more similar to each other than to characters in another (B), while our mixed-effects Author/Persona model outperforms other models at discriminating characters in the same author (C).", "labels": [], "entities": []}, {"text": "opsis of this table by illustrating the average accuracy across all choice of P . All models, including the baseline, perform well on the sanity checks (A).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 48, "end_pos": 56, "type": "METRIC", "confidence": 0.9979797005653381}, {"text": "sanity checks (A)", "start_pos": 138, "end_pos": 155, "type": "METRIC", "confidence": 0.9156623005867004}]}, {"text": "As expected, the Persona Regression model performs best at hypothesis class B (correctly judging two characters from the same author to be more similar to each other than to a character from a different author); this behavior is encouraged in this model by allowing an author (as an external metadata variable) to directly influence the persona choice, which has the effect of pushing characters from the same author to embody the same character type.", "labels": [], "entities": []}, {"text": "Our mixed effects Author/Persona model, in contrast, outperforms the other models at hypothesis class C (correctly discriminating different character types present in the same author).", "labels": [], "entities": []}, {"text": "By discounting author-specific lexical effects during persona inference, we are better able to detect variation among the characters of a single author that we are notable to capture otherwise.", "labels": [], "entities": []}, {"text": "While these different models complement each other in this manner, we note that there is no absolute separation among them, which maybe suggestive of the degree to which the formal and referential dimensions are fused in novels.", "labels": [], "entities": []}, {"text": "Nevertheless, the strengths of these different models on these different hypothesis classes gives us flexible alternatives to use depending on the kinds of character types we are looking to infer.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Agreement rates with preregistered hypotheses, av- eraged over 5 sampling runs with different initializations.", "labels": [], "entities": []}, {"text": " Table 2: Snapshots of three personas learned from the P = 50, Author/Persona model. Gender and time proportions are  calculated by summing and normalizing the posterior distributions over all characters with that feature. We truncate time series  at 1800 due to data sparsity before that date; the y-axis illustrates the frequency of its use in a given year, relative to its lifetime.", "labels": [], "entities": [{"text": "time proportions", "start_pos": 96, "end_pos": 112, "type": "METRIC", "confidence": 0.9142096936702728}]}]}