{"title": [{"text": "Predicting the relevance of distributional semantic similarity with contextual information", "labels": [], "entities": []}], "abstractContent": [{"text": "Using distributional analysis methods to compute semantic proximity links between words has become commonplace in NLP.", "labels": [], "entities": []}, {"text": "The resulting relations are often noisy or difficult to interpret in general.", "labels": [], "entities": []}, {"text": "This paper focuses on the issues of evaluating a distributional resource and filtering the relations it contains, but instead of considering it in abstracto, we focus on pairs of words in context.", "labels": [], "entities": []}, {"text": "Ina discourse , we are interested in knowing if the semantic link between two items is a by-product of textual coherence or is irrelevant.", "labels": [], "entities": []}, {"text": "We first setup a human annotation of semantic links with or without contex-tual information to show the importance of the textual context in evaluating the relevance of semantic similarity, and to assess the prevalence of actual semantic relations between word tokens.", "labels": [], "entities": []}, {"text": "We then built an experiment to automatically predict this relevance , evaluated on the reliable reference data set which was the outcome of the first annotation.", "labels": [], "entities": []}, {"text": "We show that in-document information greatly improve the prediction made by the similarity level alone.", "labels": [], "entities": []}], "introductionContent": [{"text": "The goal of the work presented in this paper is to improve distributional thesauri, and to help evaluate the content of such resources.", "labels": [], "entities": []}, {"text": "A distributional thesaurus is a lexical network that lists semantic neighbours, computed from a corpus and a similarity measure between lexical items, which generally captures the similarity of contexts in which the items occur.", "labels": [], "entities": []}, {"text": "This way of building a semantic network has been very popular since, even though the nature of the information it contains is hard to define, and its evaluation is far from obvious.", "labels": [], "entities": []}, {"text": "A distributional thesaurus includes a lot of \"noise\" from a semantic point of view, but also lists relevant lexical pairs that escape classical lexical relations such as synonymy or hypernymy.", "labels": [], "entities": []}, {"text": "There is a classical dichotomy when evaluating NLP components between extrinsic and intrinsic evaluations, and this applies to distributional thesauri.", "labels": [], "entities": []}, {"text": "Extrinsic evaluations measure the capacity of a system in which a resource or a component to evaluate has been used, for instance in this case information retrieval (van der or word sense disambiguation).", "labels": [], "entities": [{"text": "information retrieval (van der or word sense disambiguation)", "start_pos": 143, "end_pos": 203, "type": "TASK", "confidence": 0.5992578834295272}]}, {"text": "Intrinsic evaluations try to measure the resource itself with respect to some human standard or judgment, for instance by comparing a distributional resource with respect to an existing synonym dictionary or similarity judgment produced by human subjects.", "labels": [], "entities": []}, {"text": "The shortcomings of these methods have been underlined in (.", "labels": [], "entities": []}, {"text": "Lexical resources designed for other objectives put the spotlight on specific areas of the distributional thesaurus.", "labels": [], "entities": []}, {"text": "They are not suitable for the evaluation of the whole range of semantic relatedness that is exhibited by distributional similarities, which exceeds the limits of classical lexical relations, even though researchers have tried to collect equivalent resources manually, to be used as a gold standard).", "labels": [], "entities": []}, {"text": "One advantage of distributional similarities is to exhibit a lot of different semantic relations, not necessarily standard lexical relations.", "labels": [], "entities": []}, {"text": "Even with respect to established lexical resources, distributional approaches may improve coverage, complicating the evaluation even more.", "labels": [], "entities": []}, {"text": "The method we propose here has been designed as an intrinsic evaluation with a view to validate semantic proximity links in abroad per-spective, to cover what ( call \"non classical lexical semantic relations\".", "labels": [], "entities": []}, {"text": "For instance, agentive relations (author/publish, author/publication) or associative relations (actor/cinema) should be considered.", "labels": [], "entities": []}, {"text": "At the same time, we want to filter associations that can be considered as accidental in a semantic perspective (e.g. flag and composer are similar because they appear a lot with nationality names).", "labels": [], "entities": []}, {"text": "We do this by judging the relevance of a lexical relation in a context where both elements of a lexical pair occur.", "labels": [], "entities": []}, {"text": "We show not only that this improves the reliability of human judgments, but also that it gives a framework where this relevance can be predicted automatically.", "labels": [], "entities": [{"text": "reliability", "start_pos": 40, "end_pos": 51, "type": "METRIC", "confidence": 0.97121262550354}]}, {"text": "We hypothetize that evaluating and filtering semantic relations in texts where lexical items occur would help tasks that naturally make use of semantic similarity relations, but assessing this goes beyond the present work.", "labels": [], "entities": []}, {"text": "In the rest of this paper, we describe the resource we used as a case study, and the data we collected to evaluate its content (section 2).", "labels": [], "entities": []}, {"text": "We present the experiments we setup to automatically filter semantic relations in context, with various groups of features that take into account information from the corpus used to build the thesaurus and contextual information related to occurrences of semantic neighbours 3).", "labels": [], "entities": []}, {"text": "Finally we discuss some related work on the evaluation and improvement of distributional resources (section 4).", "labels": [], "entities": []}], "datasetContent": [{"text": "We use a distributional resource for French, built on a 200M word corpus extracted from the French Wikipedia, following principles laid out in) from a structured model (, i.e. using syntactic contexts.", "labels": [], "entities": []}, {"text": "In this approach, contexts are triples (governor,relation,dependent) derived from syntactic dependency structures.", "labels": [], "entities": []}, {"text": "Governors and dependents are verbs, adjectives and nouns.", "labels": [], "entities": []}, {"text": "Multiword units are available, but they form a very small subset of the resulting neighbours.", "labels": [], "entities": []}, {"text": "Base elements in the thesaurus are of two types: arguments (dependents' lemma) and predicates (governor+relation).", "labels": [], "entities": []}, {"text": "This is to keep the predicate/argument distinction since similarities will be computed between predicate pairs or argument pairs, and a lexical item can appear in many predicates and as an argument (e.g. interest as argument, interest for as one predicate).", "labels": [], "entities": []}, {"text": "The similarity of distributions was computed with Lin's score).", "labels": [], "entities": [{"text": "similarity", "start_pos": 4, "end_pos": 14, "type": "METRIC", "confidence": 0.9933285713195801}]}, {"text": "We will talk of lexical neighbours or distributional neighbours to label pairs of predicates or arguments, and in the rest of the paper we consider only lexical pairs with a Lin score of at least 0.1, which means about 1.4M pairs.", "labels": [], "entities": [{"text": "Lin score", "start_pos": 174, "end_pos": 183, "type": "METRIC", "confidence": 0.977724015712738}]}, {"text": "This somewhat arbitrary level is an a priori threshold to limit the resulting database, and it is conservative enough not to exclude potential interesting relations.", "labels": [], "entities": []}, {"text": "The distribution of scores is given; 97% of the selected pairs have a score between 0.1 and 0.29.", "labels": [], "entities": []}, {"text": "To ease the use of lexical neighbours in our experiments, we merged together predicates that include the same lexical unit, a posteriori.", "labels": [], "entities": []}, {"text": "Thus there is no need fora syntactic analysis of the context considered when exploiting the resource, and sparsity is less of an issue 1 .", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Inter-annotator agreements with Cohen's Kappa for contextual and non-contextual annotations.  N1, N2, N3 were annotators during the pre-test; expert annotation was made on a different dataset from  the same corpus, only with the full discourse context.", "labels": [], "entities": []}, {"text": " Table 3: Classification scores (%) on the relevant class. CI is the confidence interval on the F-score (RF  = Random Forest, NB= naive bayes).", "labels": [], "entities": [{"text": "CI", "start_pos": 59, "end_pos": 61, "type": "METRIC", "confidence": 0.9687129855155945}, {"text": "F-score", "start_pos": 96, "end_pos": 103, "type": "METRIC", "confidence": 0.9617922902107239}]}, {"text": " Table 4: Impact of each group of features on the best scores (%) : the lowest the results, the bigger the  impact of the removed group of features.", "labels": [], "entities": []}]}