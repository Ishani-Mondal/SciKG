{"title": [{"text": "Retrieving Collocations from Text: Xtract", "labels": [], "entities": [{"text": "Retrieving Collocations from Text: Xtract", "start_pos": 0, "end_pos": 41, "type": "TASK", "confidence": 0.8690361579259237}]}], "abstractContent": [{"text": "Natural languages are full of collocations, recurrent combinations of words that co-occur more often than expected by chance and that correspond to arbitrary word usages.", "labels": [], "entities": []}, {"text": "Recent work in lexicography indicates that collocations are pervasive in English; apparently, they are common in all types of writing, including both technical and nontechnical genres.", "labels": [], "entities": []}, {"text": "Several approaches have been proposed to retrieve various types of collocations from the analysis of large samples of textual data.", "labels": [], "entities": []}, {"text": "These techniques automatically produce large numbers of collocations along with statistical figures intended to reflect the relevance of the associations.", "labels": [], "entities": []}, {"text": "However, noue of these techniques provides functional information along with the collocation.", "labels": [], "entities": []}, {"text": "Also, the results produced often contained improper word associations reflecting some spurious aspect of the training corpus that did not stand for true collocations.", "labels": [], "entities": []}, {"text": "In this paper, we describe a set of techniques based on statistical methods for retrieving and identifying collocations from large textual corpora.", "labels": [], "entities": [{"text": "retrieving and identifying collocations from large textual corpora", "start_pos": 80, "end_pos": 146, "type": "TASK", "confidence": 0.6784489713609219}]}, {"text": "These techniques produce a wide range of collocations and are based on some original filtering methods that allow the production of richer and higher-precision output.", "labels": [], "entities": []}, {"text": "These techniques have been implemented and resulted in a lexicographic tool, Xtract.", "labels": [], "entities": []}, {"text": "The techniques are described and some results are presented on a 10 million-word corpus of stock market news reports.", "labels": [], "entities": []}, {"text": "A lexicographic evaluation of Xtract as a collocation retrieval tool has been made, and the estimated precision of Xtract is 80%.", "labels": [], "entities": [{"text": "precision", "start_pos": 102, "end_pos": 111, "type": "METRIC", "confidence": 0.9994543194770813}]}], "introductionContent": [], "datasetContent": [{"text": "The third stage of Xtract can thus be considered as a retrieval system that retrieves valid collocations from a set of candidates.", "labels": [], "entities": []}, {"text": "This section describes an evaluation experiment of the third stage of Xtract as a retrieval system as well as an evaluation of the overall output of Xtract.", "labels": [], "entities": []}, {"text": "Evaluation of retrieval systems is usually done with the help of two parameters: precision and recall).", "labels": [], "entities": [{"text": "precision", "start_pos": 81, "end_pos": 90, "type": "METRIC", "confidence": 0.9995744824409485}, {"text": "recall", "start_pos": 95, "end_pos": 101, "type": "METRIC", "confidence": 0.9974011182785034}]}, {"text": "Precision of a retrieval system is defined as the ratio of retrieved valid elements divided by the total number of retrieved elements.", "labels": [], "entities": [{"text": "Precision", "start_pos": 0, "end_pos": 9, "type": "METRIC", "confidence": 0.9629009366035461}]}, {"text": "It measures the quality of the retrieved material.", "labels": [], "entities": []}, {"text": "Recall is defined as the ratio of retrieved valid elements divided by the total number of valid elements.", "labels": [], "entities": [{"text": "Recall", "start_pos": 0, "end_pos": 6, "type": "METRIC", "confidence": 0.924882173538208}]}, {"text": "It measures the effectiveness of the system.", "labels": [], "entities": []}, {"text": "This section presents an evaluation of the retrieval performance of the third stage of Xtract.", "labels": [], "entities": []}, {"text": "Deciding whether a given word combination is a valid or invalid collocation is actually a difficult task that is best done by a lexicographer.", "labels": [], "entities": [{"text": "Deciding whether a given word combination", "start_pos": 0, "end_pos": 41, "type": "TASK", "confidence": 0.7840822537740072}]}, {"text": "Jeffery Triggs is a lexicographer working for the Oxford English Dictionary (OED) coordinating the North American Readers program of OED at Bell Communication Research.", "labels": [], "entities": [{"text": "Oxford English Dictionary (OED)", "start_pos": 50, "end_pos": 81, "type": "DATASET", "confidence": 0.8733919163544973}, {"text": "Bell Communication Research", "start_pos": 140, "end_pos": 167, "type": "DATASET", "confidence": 0.8249399662017822}]}, {"text": "Jeffery Triggs agreed to go over manually several thousands of collocations.", "labels": [], "entities": []}, {"text": "17 In order to have an unbiased experiment we had to be able to evaluate the performance of Xtract against a human expert.", "labels": [], "entities": []}, {"text": "We had to have the lexicographer and Xtract perform the same task.", "labels": [], "entities": []}, {"text": "To do this in an unbiased way we randomly selected a subset of about 4,000 collocations after the first two stages of Xtract.", "labels": [], "entities": []}, {"text": "This set of collocations thus contained some good collocations and some bad ones.", "labels": [], "entities": []}, {"text": "This data set was then evaluated by the lexicographer and the third stage of Xtract.", "labels": [], "entities": []}, {"text": "This allowed 17 1 am grateful to Jeffery, whose professionalism and kindness helped me understand some of the difficulty of lexicography.", "labels": [], "entities": []}, {"text": "Without him this evaluation would not have been possible.", "labels": [], "entities": []}, {"text": "us to evaluate the performances of the third stage of Xtract and the overall quality of the total output of Xtract in a single experiment.", "labels": [], "entities": []}, {"text": "The experiment was as follows: We gave the 4,000 collocations to evaluate to the lexicographer, asking him to select the ones that he would consider fora domain-specific dictionary and to cross out the others.", "labels": [], "entities": []}, {"text": "The lexicographer came up with three simple tags, YY, Y, and N.", "labels": [], "entities": []}, {"text": "Both Y and YY include good collocations, and N includes bad collocations.", "labels": [], "entities": []}, {"text": "The difference between YY and Y is that Y collocations are of better quality than YY collocations.", "labels": [], "entities": []}, {"text": "YY collocations are often too specific to be included in a dictionary, or some words are missing, etc.", "labels": [], "entities": []}, {"text": "After stage 2, about 20% of the collocations are Y, about 20% are YY, and about 60% are N.", "labels": [], "entities": []}, {"text": "This told us that the precision of Xtract at stage 2 was only about 40%.", "labels": [], "entities": [{"text": "precision", "start_pos": 22, "end_pos": 31, "type": "METRIC", "confidence": 0.9997125267982483}, {"text": "Xtract", "start_pos": 35, "end_pos": 41, "type": "TASK", "confidence": 0.8741665482521057}]}, {"text": "Although this would seem like a poor precision, one should compare it with the much lower rates currently in practice in lexicography.", "labels": [], "entities": [{"text": "precision", "start_pos": 37, "end_pos": 46, "type": "METRIC", "confidence": 0.9992972612380981}]}, {"text": "For compiling new entries for the OED, for example, the first stage roughly consists of reading numerous documents to identify new or interesting expressions.", "labels": [], "entities": [{"text": "OED", "start_pos": 34, "end_pos": 37, "type": "DATASET", "confidence": 0.8192692995071411}]}, {"text": "This task is performed by professional readers.", "labels": [], "entities": []}, {"text": "For the OED, the readers for the American program alone produce some 10,000 expressions a month.", "labels": [], "entities": [{"text": "OED", "start_pos": 8, "end_pos": 11, "type": "DATASET", "confidence": 0.8751833438873291}, {"text": "American program", "start_pos": 33, "end_pos": 49, "type": "DATASET", "confidence": 0.9271495938301086}]}, {"text": "These lists are then sent off to the dictionary and go through several rounds of careful analysis before actually being submitted to the dictionary.", "labels": [], "entities": []}, {"text": "The ratio of proposed candidates to good candidates is usually low.", "labels": [], "entities": []}, {"text": "For example, out of the 10,000 expressions proposed each month, fewer than 400 are serious candidates for the OED, which represents a current rate of 4%.", "labels": [], "entities": [{"text": "OED", "start_pos": 110, "end_pos": 113, "type": "METRIC", "confidence": 0.4080803096294403}]}, {"text": "Automatically producing lists of candidate expressions could actually be of great help to lexicographers, and even a precision of 40% would be helpful.", "labels": [], "entities": [{"text": "precision", "start_pos": 117, "end_pos": 126, "type": "METRIC", "confidence": 0.9990561604499817}]}, {"text": "Such lexicographic tools could, for example, help readers retrieve sublanguage-specific expressions by providing them with lists of candidate collocations.", "labels": [], "entities": []}, {"text": "The lexicographer then manually examines the list to remove the irrelevant data.", "labels": [], "entities": []}, {"text": "Even low precision is useful for lexicographers, as manual filtering is much faster than manual scanning of the documents).", "labels": [], "entities": [{"text": "precision", "start_pos": 9, "end_pos": 18, "type": "METRIC", "confidence": 0.9969074130058289}]}, {"text": "Such techniques are notable to replace readers, though, as they are not designed to identify low-frequency expressions, whereas a human reader immediately identifies interesting expressions with as few as one occurrence.", "labels": [], "entities": []}, {"text": "The second stage of this experiment was to use Xtract stage 3 to filter out and label the sample set of collocations.", "labels": [], "entities": []}, {"text": "As described in Section 8, there are several valid labels (VO~ VS~ NN, etc.).", "labels": [], "entities": [{"text": "VO", "start_pos": 59, "end_pos": 61, "type": "METRIC", "confidence": 0.7901182770729065}]}, {"text": "In this experiment, we grouped them under a single label: T.", "labels": [], "entities": []}, {"text": "There is only one nonvalid label: U (for unlabeled).", "labels": [], "entities": [{"text": "U", "start_pos": 34, "end_pos": 35, "type": "METRIC", "confidence": 0.9539505243301392}]}, {"text": "A T collocation is thus accepted by Xtract stage 3, and a U collocation is rejected.", "labels": [], "entities": []}, {"text": "The results of the use of stage 3 on the sample set of collocations are similar to the manual evaluation in terms of numbers: about 40% of the collocations were labeled (T) by Xtract stage 3, and about 60% were rejected (U).", "labels": [], "entities": []}, {"text": "shows the overlap of the classifications made by Xtract and the lexicographer.", "labels": [], "entities": []}, {"text": "In the figure, the first diagram on the left represents the breakdown in T and U of each of the manual categories (Y-YY and N).", "labels": [], "entities": []}, {"text": "The diagram on the right represents the breakdown in Y-YY and N of the T and U categories.", "labels": [], "entities": []}, {"text": "For example, the first column of the diagram on the left represents the application of Xtract stage 3 on the YY collocations.", "labels": [], "entities": []}, {"text": "It shows that 94% of the collocations accepted by the lexicographer were also accepted by Xtract.", "labels": [], "entities": [{"text": "Xtract", "start_pos": 90, "end_pos": 96, "type": "DATASET", "confidence": 0.779325544834137}]}, {"text": "In other words, this means that the recall of the third stage of Xtract is 94%.", "labels": [], "entities": [{"text": "recall", "start_pos": 36, "end_pos": 42, "type": "METRIC", "confidence": 0.9992941617965698}]}, {"text": "The first column of the diagram on the right represents the lexicographic evaluation of the collocations automatically accepted by Xtract.", "labels": [], "entities": []}, {"text": "It shows that about 80% of the T collocations were accepted by the lexicographer and that about 20% were rejected.", "labels": [], "entities": []}, {"text": "This shows that precision was raised from 40% to 80% with the addition of Xtract stage 3.", "labels": [], "entities": [{"text": "precision", "start_pos": 16, "end_pos": 25, "type": "METRIC", "confidence": 0.9997890591621399}]}, {"text": "In summary, these experiments allowed us to evaluate Stage 3 as a retrieval system.", "labels": [], "entities": []}, {"text": "The results are: precision = 80% and recall --94%.", "labels": [], "entities": [{"text": "precision", "start_pos": 17, "end_pos": 26, "type": "METRIC", "confidence": 0.9998798370361328}, {"text": "recall", "start_pos": 37, "end_pos": 43, "type": "METRIC", "confidence": 0.9997820258140564}]}, {"text": "-1 620 trading 3 207", "labels": [], "entities": []}], "tableCaptions": []}