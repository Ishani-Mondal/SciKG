{"title": [], "abstractContent": [{"text": "We present an algorithm for aligning texts with their translations that is based only on internal evidence.", "labels": [], "entities": []}, {"text": "The relaxation process rests on a notion of which word in one text corresponds to which word in the other text that is essentially based on the similarity of their distributions.", "labels": [], "entities": []}, {"text": "It exploits a partial alignment of the word level to induce a maximum likelihood alignment of the sentence level, which is in turn used, in the next iteration, to refine the word level estimate.", "labels": [], "entities": []}, {"text": "The algorithm appears to converge to the correct sentence alignment in only a few iterations.", "labels": [], "entities": []}], "introductionContent": [], "datasetContent": [{"text": "In this section, we show some of the results of our experiments with these algorithms, and also data produced at some of the intermediate stages.", "labels": [], "entities": []}, {"text": "We applied the methods described hereto two pairs of articles from Scientific American and their German translations in Spektrum der Wissenschaft (see references).", "labels": [], "entities": []}, {"text": "The English and German articles about human-powered flight had 214 and 162 sentences, respectively; the ones about cosmic rays contained 255 and 300 sentences, respectively.", "labels": [], "entities": []}, {"text": "The first pair was primarily used to develop the algorithm and to determine the various parameters of the program.", "labels": [], "entities": []}, {"text": "The performance of the algorithm was finally tested on the latter pair of articles.", "labels": [], "entities": []}, {"text": "We chose these journals because of a general impression that the translations were of very high quality and were sufficiently \"free\" to be a substantial challenge for the algorithm.", "labels": [], "entities": []}, {"text": "Furthermore, we expected technical translators to adhere to a narrow view of semantic accuracy in their work, and to rate the importance of this above stylistic considerations.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 86, "end_pos": 94, "type": "METRIC", "confidence": 0.9090956449508667}]}, {"text": "Later we also give results for another application of our algorithm to a larger text of 1257 sentences that was put together from two days from the French-English Hansard corpus.", "labels": [], "entities": [{"text": "French-English Hansard corpus", "start_pos": 148, "end_pos": 177, "type": "DATASET", "confidence": 0.7477237383524576}]}, {"text": "shows the first 50 entries of the WAT after pass 1 of the algorithm.", "labels": [], "entities": [{"text": "WAT", "start_pos": 34, "end_pos": 37, "type": "TASK", "confidence": 0.8219648003578186}]}, {"text": "It shows part of the first section of the WAT (lines 1-23) and the beginning of the second (lines 24-50).", "labels": [], "entities": [{"text": "WAT", "start_pos": 42, "end_pos": 45, "type": "DATASET", "confidence": 0.5052081942558289}]}, {"text": "The first segment contains words or normalized forms with more than 7 occurrences and a similarity not less than 0.8.", "labels": [], "entities": []}, {"text": "Strings shown with a following hyphen are prefixes arising from the morphological procedure; strings with an initial hyphen are suffixes.", "labels": [], "entities": []}, {"text": "Naturally, some of the word divisions are made in places that do not accurately reflect linguistic facts.", "labels": [], "entities": []}, {"text": "For example, English \"proto-\" (1) comes from \"proton\" and \"protons\"; German \"-eilchen\" (17) is the normalization for words ending in \"-teilchen\" and, in the same way, \"-eistung\" (47) comes from \"-leistung.\"", "labels": [], "entities": []}, {"text": "Of these 50 word pairs, 42 have essentially the same meanings.", "labels": [], "entities": []}, {"text": "We take it that \"erg\" and \"Joule,\" inline 4, mean the same, modulo a change in units.", "labels": [], "entities": [{"text": "erg", "start_pos": 17, "end_pos": 20, "type": "METRIC", "confidence": 0.9384191036224365}]}, {"text": "Also, it is not unreasonable to associate pairs like \"primary\"/\"sekundaren\" (26) and \"electric\"/\"Feld\" (43), on the grounds that they tend to be used together.", "labels": [], "entities": []}, {"text": "The pair \"rapid-\"/\"Pulsare-\" (49) is made because a pulsar is a rapidly spinning neutron star and some such phrase The WAT after pass 1.", "labels": [], "entities": [{"text": "rapid-\"/\"Pulsare-\" (49", "start_pos": 10, "end_pos": 32, "type": "METRIC", "confidence": 0.8923908571402231}, {"text": "WAT", "start_pos": 119, "end_pos": 122, "type": "TASK", "confidence": 0.7926838994026184}]}, {"text": "occurs with it five out of six times.", "labels": [], "entities": []}, {"text": "Notice, however, that the association \"pulsar-\" \"Pulsar-\" is also in table (6).", "labels": [], "entities": []}, {"text": "Furthermore, the German strings \"Pulsar\" and \"Pulsar-\" are both given correct associations in the next pass (lines 17 and 20 of).", "labels": [], "entities": [{"text": "Pulsar-\"", "start_pos": 46, "end_pos": 54, "type": "METRIC", "confidence": 0.7180761098861694}]}, {"text": "The table shows two interesting effects of the morphological analysis procedure.", "labels": [], "entities": [{"text": "morphological analysis", "start_pos": 47, "end_pos": 69, "type": "TASK", "confidence": 0.9167360067367554}]}, {"text": "The word \"shower\" is wrongly associated with the word \"Gammaquant\" (25) with a frequency of 6, but the prefix \"shower-\" is correctly associated with \" The SAT after pass 1.", "labels": [], "entities": [{"text": "The SAT after pass 1", "start_pos": 151, "end_pos": 171, "type": "DATASET", "confidence": 0.8164462685585022}]}], "tableCaptions": [{"text": " Table 2  The WAT after pass 3.", "labels": [], "entities": [{"text": "WAT", "start_pos": 14, "end_pos": 17, "type": "TASK", "confidence": 0.689936101436615}]}]}