{"title": [{"text": "From Grammar to Lexicon: Unsupervised Learning of Lexical Syntax", "labels": [], "entities": []}], "abstractContent": [{"text": "Imagine a language that is completely unfamiliar; the only means of studying it are an ordinary grammar book and a very large corpus of text.", "labels": [], "entities": []}, {"text": "How can easily recognized , surface grammatical facts be used to extract from a corpus as much syntactic information as possible about individual words?", "labels": [], "entities": []}, {"text": "This paper describes an approach based on two principles.", "labels": [], "entities": []}, {"text": "First, rely on local morpho-syntactic cues to structure rather than trying to parse entire sentences.", "labels": [], "entities": []}, {"text": "Second, treat these cues as probabilistic rather than absolute indicators of syntactic structure.", "labels": [], "entities": []}, {"text": "Apply inferential statistics to the data collected using the cues, rather than drawing a categorical conclusion from a single occurrence of a cue.", "labels": [], "entities": []}, {"text": "The effectiveness of this approach for inferring the syntactic frames of verbs is supported by experiments on an English corpus using a program called Lerner.", "labels": [], "entities": []}, {"text": "Lerner starts outwith no knowledge of content words-it bootstraps from", "labels": [], "entities": []}], "introductionContent": [{"text": "This paper presents a study in the automatic acquisition of lexical syntax from naturally occurring English text.", "labels": [], "entities": [{"text": "automatic acquisition of lexical syntax from naturally occurring English text", "start_pos": 35, "end_pos": 112, "type": "TASK", "confidence": 0.8480033993721008}]}, {"text": "It focuses on discovering the kinds of syntactic phrases that can be used to represent the semantic arguments of particular verbs.", "labels": [], "entities": []}, {"text": "For example, want can take an infinitive argument and hope a tensed clause argument, but not vice versa: (1) a. b. c. d. John wants Mary to be happy.", "labels": [], "entities": []}, {"text": "John hopes that Mary is happy.", "labels": [], "entities": []}, {"text": "*John wants that Mary is happy.", "labels": [], "entities": []}, {"text": "*John hopes Mary to be happy.", "labels": [], "entities": []}, {"text": "This study focuses on the ability of verbs to take arguments represented by infinitives, tensed clauses, and noun phrases serving as both direct and indirect objects.", "labels": [], "entities": []}, {"text": "These lexical properties are similar to those that Chomsky (1965) termed subcategorization frames, but to avoid confusion the properties understudy here will be referred to as syntactic frames or simply frames.", "labels": [], "entities": []}, {"text": "The general framework for the problems addressed in this paper can bethought of as follows.", "labels": [], "entities": []}, {"text": "Imagine a language that is completely unfamiliar; the only means of studying it are an ordinary grammar book and a very large corpus of text (or transcribed speech).", "labels": [], "entities": []}, {"text": "How can easily recognized, surface grammatical The effectiveness of this approach for inferring the syntactic frames of verbs is supported by experiments using an implementation called Lerner.", "labels": [], "entities": []}, {"text": "In the spirit of the problem stated above, Lerner starts outwith no knowledge of content words--it bootstraps from determiners, auxiliaries, modals, prepositions, pronouns, complementizers, coordinating conjunctions, and punctuation.", "labels": [], "entities": []}, {"text": "Lerner has two independent components corresponding to the two strategies listed above.", "labels": [], "entities": []}, {"text": "The first component identities sentences where a particular verb is likely to be exhibiting a particular syntactic frame.", "labels": [], "entities": []}, {"text": "It does this using local cues, such as the that the cue.", "labels": [], "entities": []}, {"text": "This component keeps track of the number of times each verb appears with cues for each syntactic frame as well as the total number of times each verb occurs.", "labels": [], "entities": []}, {"text": "This process can be described as collecting observations and its output as an observations table.", "labels": [], "entities": []}, {"text": "A segment of an actual observations table is shown in.", "labels": [], "entities": []}, {"text": "The observations table serves as input to the statistical modeler, which ultimately decides whether the accumulated evidence that a particular verb manifests a particular syntactic frame in the input is reliable enough to warrant a conclusion.", "labels": [], "entities": []}, {"text": "To the best of my knowledge, this is the first attempt to design a system that autonomously learns syntactic frames from naturally occurring text.", "labels": [], "entities": []}, {"text": "The goal of learning syntactic frames and the learning framework described above lead to three major differences between the approach reported here and most recent work in learning grammar from text.", "labels": [], "entities": []}, {"text": "First, this approach leverages a little a priori grammatical knowledge using statistical inference.", "labels": [], "entities": []}, {"text": "Most work on corpora of naturally occurring language either uses no a priori grammatical knowledge, or else it relies on a large and complex grammar.", "labels": [], "entities": []}, {"text": "One exception is, in which a small grammar is used to aid learning.", "labels": [], "entities": []}, {"text": "1 A second difference is that the work reported here uses inferential rather than descriptive statistics.", "labels": [], "entities": []}, {"text": "In other words, it uses statistical methods to infer facts about the language as it exists in the minds of those who produced the corpus.", "labels": [], "entities": []}, {"text": "Many other projects have used statistics in away that summarizes facts about the text but does not draw any explicit conclusions from them ().", "labels": [], "entities": []}, {"text": "On the other hand, Hindle (1991) does use inferential statistics, and recognizes the value of inference, although he does not use inferential statistics per se.", "labels": [], "entities": []}, {"text": "Finally, many other projects in machine learning of natural language use input that is annotated in someway, either with part-of-speech tags or with syntactic brackets.", "labels": [], "entities": []}, {"text": "The remainder of the paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 describes the morphosyntactic cues Lerner uses to collect observations.", "labels": [], "entities": []}, {"text": "Section 3 presents the main contribution of this paper--the statistical model and experiments supporting its effectiveness.", "labels": [], "entities": []}, {"text": "Finally, Section 4 draws conclusions and lays out a research program in machine learning of natural language.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 4  A sample of the data collected from the untagged Brown Corpus using the cues of Table 3.", "labels": [], "entities": [{"text": "Brown Corpus", "start_pos": 59, "end_pos": 71, "type": "DATASET", "confidence": 0.977353572845459}]}, {"text": " Table 7  Comparison of automatic classification to hand judgments for infinitive  complement, as a function of estimated error rate p (Brown Corpus).", "labels": [], "entities": [{"text": "automatic classification", "start_pos": 24, "end_pos": 48, "type": "TASK", "confidence": 0.6018323451280594}, {"text": "Brown Corpus)", "start_pos": 136, "end_pos": 149, "type": "DATASET", "confidence": 0.9600068926811218}]}]}