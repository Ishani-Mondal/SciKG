{"title": [{"text": "Evaluating Message Understanding Systems: An Analysis of the Third Message Understanding Conference (MUG-3)", "labels": [], "entities": [{"text": "Evaluating Message Understanding Systems", "start_pos": 0, "end_pos": 40, "type": "TASK", "confidence": 0.815359428524971}, {"text": "Third Message Understanding Conference (MUG-3)", "start_pos": 61, "end_pos": 107, "type": "TASK", "confidence": 0.6453407236507961}]}], "abstractContent": [{"text": "This paper describes and analyzes the results of the Third Message Understanding Conference (MUC-3).", "labels": [], "entities": [{"text": "Third Message Understanding Conference (MUC-3)", "start_pos": 53, "end_pos": 99, "type": "TASK", "confidence": 0.5104927037443433}]}, {"text": "It reviews the purpose, history, and methodology of the conference, summarizes the participating systems, discusses issues of measuring system effectiveness, describes the linguistic phenomena tests, and provides a critical look at the evaluation in terms of the lessons learned.", "labels": [], "entities": []}, {"text": "One of the common problems with evaluations is that the statistical significance of the results is unknown.", "labels": [], "entities": []}, {"text": "In the discussion of system performance, the statistical significance of the evaluation results is reported and the use of approximate randomization to calculate the statistical significance of the results of MUC-3 is described.", "labels": [], "entities": [{"text": "MUC-3", "start_pos": 209, "end_pos": 214, "type": "DATASET", "confidence": 0.805133044719696}]}], "introductionContent": [{"text": "The Third Message Understanding Conference (MUC-3) represented a significant step for the message processing community and for computational linguistics as a whole.", "labels": [], "entities": [{"text": "Third Message Understanding Conference (MUC-3)", "start_pos": 4, "end_pos": 50, "type": "TASK", "confidence": 0.7633072563580104}, {"text": "message processing community", "start_pos": 90, "end_pos": 118, "type": "TASK", "confidence": 0.8148352106412252}]}, {"text": "The conference brought together 15 systems that were tested on a naturally occurring corpus of newswire reports on terrorism in Latin America.", "labels": [], "entities": []}, {"text": "The systems were evaluated on their ability to extract significant information from the newswire reports in the form of \"templates\" summarizing who did what to whom.", "labels": [], "entities": []}, {"text": "We can enumerate the successes of the conference in many dimensions: the number of participating systems (15 systems, up from 8 at the previous Message Understanding Conference, MUCK-II), the scale of the application (100 times more text than the previous conference), the rigorous definition of the evaluation method (including automated and interactive scoring procedures), and the cooperative framework that enabled the participants to develop both the training data and the evaluation procedures.", "labels": [], "entities": [{"text": "MUCK-II", "start_pos": 178, "end_pos": 185, "type": "DATASET", "confidence": 0.7682241201400757}]}, {"text": "These are significant accomplishments in afield that has only recently begun to address system evaluation issues.", "labels": [], "entities": []}, {"text": "The MUC-3 conference has already been described in a conference proceedings (Proceedings of the Third Message Understanding Conference (MUC-3), 1991) and in an AI", "labels": [], "entities": [{"text": "MUC-3 conference", "start_pos": 4, "end_pos": 20, "type": "DATASET", "confidence": 0.9173319637775421}, {"text": "Third Message Understanding Conference (MUC-3), 1991)", "start_pos": 96, "end_pos": 149, "type": "TASK", "confidence": 0.5788951933383941}]}], "datasetContent": [{"text": "1.4.1 Introduction to the MUC-3 Task.", "labels": [], "entities": [{"text": "MUC-3 Task", "start_pos": 26, "end_pos": 36, "type": "DATASET", "confidence": 0.6442097425460815}]}, {"text": "The task for the MUC-3 evaluation was to extract data about terrorist incidents from newswire articles.", "labels": [], "entities": [{"text": "MUC-3 evaluation", "start_pos": 17, "end_pos": 33, "type": "TASK", "confidence": 0.6772782206535339}]}, {"text": "The extracted data were put into simulated database records defined by a template.", "labels": [], "entities": []}, {"text": "The template database slots described important aspects of those incidents, such as the type of incident, the targets, perpetrators, date, location, and effects.", "labels": [], "entities": []}, {"text": "An automated system that could perform this task would be useful in an environment where many incoming messages make it too expensive and time-consuming for personnel to do the data extraction and quality control.", "labels": [], "entities": [{"text": "data extraction", "start_pos": 177, "end_pos": 192, "type": "TASK", "confidence": 0.7519567012786865}]}, {"text": "The specific task domain for MUC-3 was restricted to terrorist acts involving nine Latin American countries.", "labels": [], "entities": [{"text": "MUC-3", "start_pos": 29, "end_pos": 34, "type": "TASK", "confidence": 0.7176246047019958}]}, {"text": "Terrorist acts were defined as violent acts perpetrated with political aims and a motive of intimidation.", "labels": [], "entities": []}, {"text": "These acts could be perpetrated by a terrorist or guerrilla group, the government or the military, or by unknown individuals.", "labels": [], "entities": []}, {"text": "The targets excluded terrorist or guerrilla groups, the military, and police; attacks  The scores discussed above provide a black-box measure of system effectiveness because only input/output pairs were examined (Palmer and Finin 1990).", "labels": [], "entities": []}, {"text": "The subsystem mechanisms used to create those outputs, were not considered as they would have been in a glass-box test because these subsystems differed widely from system to system.", "labels": [], "entities": []}, {"text": "In an attempt to gain some insight into the strengths and weaknesses of subsystems, we examined the effect of particular linguistic constructions on the ability of systems to extract data correctly.", "labels": [], "entities": []}, {"text": "The general method of testing linguistic phenomena was to find all instances of the chosen phenomenon in the test messages, to determine the slots that could only be filled correctly if a system were able to handle the phenomenon, and to configure the scoring program to score just those slot instances.", "labels": [], "entities": []}, {"text": "Three such linguistic phenomena tests were attempted during a MUC-3 dry run in February 1991.", "labels": [], "entities": [{"text": "MUC-3 dry run in February 1991", "start_pos": 62, "end_pos": 92, "type": "TASK", "confidence": 0.6597548027833303}]}, {"text": "The phenomena examined were negation, conjunction, and active versus passive verb forms.", "labels": [], "entities": [{"text": "negation, conjunction", "start_pos": 28, "end_pos": 49, "type": "TASK", "confidence": 0.7229261994361877}]}, {"text": "However, most systems were poor enough at extracting data from any linguistic construction during this test that differences caused by particular linguistic constructions were unnoticeable.", "labels": [], "entities": []}, {"text": "Those differences that were observed mirrored the differences in overall ..~cores.", "labels": [], "entities": []}, {"text": "The linguistic phenomena tests carried out as an experiment during the final MUC-3 run in May 1991 were more successful and showed that differences in handling of linguistic structures could be discerned through black-box testing.", "labels": [], "entities": [{"text": "MUC-3 run", "start_pos": 77, "end_pos": 86, "type": "DATASET", "confidence": 0.8137036263942719}]}, {"text": "This was not only because the preliminary tests, taught us to use a relatively frequent linguistic phenomenon but also because many sites had improved system performance in the interim, allowing meaningful scores on subsets of the data to be measured.", "labels": [], "entities": []}, {"text": "All sentences from the test messages containing appositions were extracted and analyzed according to the appositions' effect on slot fills, their position (appositive preposed or postposed), and their complexity (simple or complex).", "labels": [], "entities": []}, {"text": "Configuration files were composed that specified which slots in which templates were to be scored for appositioned noun phrases, simple appositive constructions, complex appositive constructions, preposed appositives, and postposed appositives.", "labels": [], "entities": []}, {"text": "A set of test messages with simple sentences substituted for the appositive constructions was generated from the official test messages.", "labels": [], "entities": []}, {"text": "The configuration files and modified messages were sent to the sites as part of the MUC-3 test package.", "labels": [], "entities": [{"text": "MUC-3 test package", "start_pos": 84, "end_pos": 102, "type": "DATASET", "confidence": 0.8797106146812439}]}, {"text": "The sites were required to automatically rescore their templates using their official history file with each of the configuration files.", "labels": [], "entities": []}, {"text": "It took two weeks to develop the test package for the linguistic phenomena experiment and it took the sites on the order of two hours to automatically rescore their systems.", "labels": [], "entities": []}, {"text": "Sites voluntarily chose to participate in the test that compared their performance on the 'minimal pairs' of appositive constructions and simple sentences.", "labels": [], "entities": []}, {"text": "This test required them to run their systems on the modified test messages and to rescore using the apposition configuration file for the new templates.", "labels": [], "entities": []}, {"text": "This part of the experiment was voluntary because the process was more time consuming than those tests that only required automatic rescoring.", "labels": [], "entities": []}, {"text": "The recall and precision scores on the apposition test are shown in the scatter plot in.", "labels": [], "entities": [{"text": "recall", "start_pos": 4, "end_pos": 10, "type": "METRIC", "confidence": 0.9995773434638977}, {"text": "precision", "start_pos": 15, "end_pos": 24, "type": "METRIC", "confidence": 0.9983605742454529}]}, {"text": "These results are quite different from the overall results for MUC-3 in.", "labels": [], "entities": [{"text": "MUC-3", "start_pos": 63, "end_pos": 68, "type": "DATASET", "confidence": 0.5994381904602051}]}, {"text": "These results indicate that the appositive constructions could be isolated by the test procedure at current levels of performance, although the systems' overall performance on the subset of involved slots may have played a role in these results.", "labels": [], "entities": []}, {"text": "shows the combined results of recall multiplied by precision for the simple and complex appositive constructions.", "labels": [], "entities": [{"text": "recall", "start_pos": 30, "end_pos": 36, "type": "METRIC", "confidence": 0.9986855387687683}, {"text": "precision", "start_pos": 51, "end_pos": 60, "type": "METRIC", "confidence": 0.9976031184196472}]}, {"text": "The systems scored higher on the simpler The scatterplot of the recall versus preci.sion scores for appositioned noun phrases shows that the systems scored differently on the appositive constructions than on the overall test.", "labels": [], "entities": [{"text": "recall", "start_pos": 64, "end_pos": 70, "type": "METRIC", "confidence": 0.9981840252876282}]}, {"text": "The plot of the product of recall and precision scores for the simple and the complex appositive constructions shows that the systems scored higher for the simpler appositive constructions as predicted.", "labels": [], "entities": [{"text": "recall", "start_pos": 27, "end_pos": 33, "type": "METRIC", "confidence": 0.9992603659629822}, {"text": "precision", "start_pos": 38, "end_pos": 47, "type": "METRIC", "confidence": 0.9990326166152954}]}, {"text": "appositive constructions than they did on the more complex appositive constructions.", "labels": [], "entities": []}, {"text": "The results indicate strongly that the tests were isolating the linguistic phenomenon.", "labels": [], "entities": []}, {"text": "\u2022 POST R X P [ n---PRE RXP SITE The plot of the product of recall and precision scores for the postposed and preposed appositives show that there is no clear trend in the scores.", "labels": [], "entities": [{"text": "POST R X P [ n---PRE RXP SITE", "start_pos": 2, "end_pos": 31, "type": "METRIC", "confidence": 0.7954444348812103}, {"text": "recall", "start_pos": 59, "end_pos": 65, "type": "METRIC", "confidence": 0.9970974922180176}, {"text": "precision", "start_pos": 70, "end_pos": 79, "type": "METRIC", "confidence": 0.9959386587142944}]}, {"text": "Figure 16  The linguistic phenomena test experiment gives several strong indications that linguistic phenomena can be isolated by scoring the affected slots in the system responses.", "labels": [], "entities": []}, {"text": "The development of a range of linguistic phenomena tests spanning the levels of linguistic structure from morphology to discourse would focus attention on the generality of the underlying linguistic mechanisms.", "labels": [], "entities": []}, {"text": "Perhaps the thing that we learned the most about was evaluation itself: the process, the costs, the payoffs, and the pitfalls.", "labels": [], "entities": []}, {"text": "On the whole, the participants--the system developers, the people responsible for the evaluation process, and the observers--all felt strongly that this evaluation was successful and that it was worth the (very large) amount of time and effort.", "labels": [], "entities": []}, {"text": "The format of the conference required that participants describe their system in detail and provide an analysis of what did and did notwork.", "labels": [], "entities": []}, {"text": "This enabled all participants to learn from each other's experiences, which greatly increased the value of the exercise.", "labels": [], "entities": []}, {"text": "The fact that the participants were involved in the planning of the conference and defining the methods used for evaluation also contributed to its success.", "labels": [], "entities": []}, {"text": "Overall, our conclusions are that evaluation is costly; it requires the investment of substantial resources, both to create the evaluation infrastructure and to port the systems to the chosen application.", "labels": [], "entities": []}, {"text": "This kind of evaluation can only be successful if system developers feel that they benefit from their participation by gaining new insights into their own systems in relation to alternatives represented by other systems.", "labels": [], "entities": []}, {"text": "Another lesson we learned is that black-box evaluation is good forgetting a snapshot of the field, but it is not necessarily a good predictor of future system performance.", "labels": [], "entities": []}, {"text": "Several MUC-3 developers showed interesting statistics indicating that their performance was increasing steadily for each week of continued development, with no significant fall-off as MUC-3 approached.", "labels": [], "entities": [{"text": "MUC-3", "start_pos": 185, "end_pos": 190, "type": "DATASET", "confidence": 0.8445796370506287}]}, {"text": "This is strong evidence that these systems will show improved performance if given more time for development.", "labels": [], "entities": []}, {"text": "Other systems suffered from slow start-up, limited resources, or missing components that prevented them from achieving peak performance.", "labels": [], "entities": []}, {"text": "Successive black-box evaluations maybe required to show whether a system has \"topped out\" or whether routine bug fixes, new modules, and additional knowledge produce further performance improvements.", "labels": [], "entities": []}, {"text": "This observation has led to anew proposal to measure system \"convergence\" (Hirschman 1991a).", "labels": [], "entities": []}, {"text": "The proposal is to perform an initial evaluation using two test sets, $1 and $2.", "labels": [], "entities": []}, {"text": "Following this, each site would be allowed to use test set $1 for development fora short period of time (perhaps a few days), but would not be allowed to look attest set $2.", "labels": [], "entities": []}, {"text": "At the end of this period, the system would again be scored on both test sets.", "labels": [], "entities": []}, {"text": "The improvement on test set $2 relative to the improvement on test set $1 would provide some measure of how well the system was convergingmwhether changes made to fix problems in one test set actually helped in another test set.", "labels": [], "entities": []}, {"text": "Another lesson was that black-box evaluation is not effective for determining which techniques are responsible for good performance across systems.", "labels": [], "entities": []}, {"text": "Performance trade-offs are very system-specific, and insights depend on a careful analysis of how the particular system failed.", "labels": [], "entities": []}, {"text": "SRI provided such an analysis of errors fora subset of the test messages, and this gave some interesting insights into that particular system.", "labels": [], "entities": [{"text": "SRI", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.9741368293762207}]}, {"text": "However, it is difficult to draw any cross-system comparisons.", "labels": [], "entities": []}, {"text": "If we wish to have more consistent insights into the strengths and weaknesses of components within individual systems, we will have to incorporate glass-box measures or rely on more sophisticated tests such as the linguistic phenomena tests described in Section 6.", "labels": [], "entities": []}, {"text": "In addition, we need effectiveness measures that go beyond recall and precision to take into account the structured nature of the information being extracted.", "labels": [], "entities": [{"text": "recall", "start_pos": 59, "end_pos": 65, "type": "METRIC", "confidence": 0.998928964138031}, {"text": "precision", "start_pos": 70, "end_pos": 79, "type": "METRIC", "confidence": 0.9984643459320068}]}, {"text": "Such measures might require the use of a structured database to evaluate the effectiveness of the retrieval of certain kinds of information.", "labels": [], "entities": []}], "tableCaptions": []}