{"title": [{"text": "TOWARDS THE AUTOMATIC IDENTIFICATION OF ADJECTIVAL SCALES: CLUSTERING ADJECTIVES ACCORDING TO MEANING", "labels": [], "entities": []}], "abstractContent": [{"text": "In this paper we present a method to group adjectives according to their meaning, as a first step towards the automatic identification of adjectival scales.", "labels": [], "entities": []}, {"text": "We discuss the properties of adjectival scales and of groups of semantically related adjectives and how they imply sources of linguistic knowledge in text corpora.", "labels": [], "entities": []}, {"text": "We describe how our system exploits this linguistic knowledge to compute a measure of similarity between two adjectives, using statistical techniques and without having access to any semantic information about the adjectives.", "labels": [], "entities": []}, {"text": "We also show how a clustering algorithm can use these similarities to produce the groups of adjectives, and we present results produced by our system fora sample set of adjectives.", "labels": [], "entities": []}, {"text": "We conclude by presenting evaluation methods for the task at hand, and analyzing the significance of the results obtained.", "labels": [], "entities": []}], "introductionContent": [{"text": "As natural language processing systems become more oriented towards solving real-world problems like machine translation or spoken language understanding in a limited domain, their need for access to vast amounts of knowledge increases.", "labels": [], "entities": [{"text": "machine translation or spoken language understanding", "start_pos": 101, "end_pos": 153, "type": "TASK", "confidence": 0.6594453056653341}]}, {"text": "While a model of the general rules of the language at various levels (morphological, syntactic, etc.) can be hand-encoded, knowledge which pertains to each specific word is harder to encode manually, if only because of the size of the lexicon.", "labels": [], "entities": []}, {"text": "Most systems currently rely on human linguists or lexicographers who compile lexicon entries by hand.", "labels": [], "entities": []}, {"text": "This approach requires significant amounts of time and effort for expanding the system's lexicon.", "labels": [], "entities": []}, {"text": "Furthermore, if the compiled information depends in anyway on the domain of the application, the acquisition of lexical knowledge must be repeated whenever the system is transported to another domain.", "labels": [], "entities": []}, {"text": "For systems which need access to large lexicons, some form of at least partial automation of the lexical knowledge acquisition phase is needed.", "labels": [], "entities": [{"text": "lexical knowledge acquisition phase", "start_pos": 97, "end_pos": 132, "type": "TASK", "confidence": 0.7114180475473404}]}, {"text": "One type of lexical knowledge which is useful for many natural language (NL) tasks is the semantic relatedness between words of the same or different syntactic categories.", "labels": [], "entities": []}, {"text": "Semantic relatedness subsumes hyponymy, synonymy, and antonymyincompatibility.", "labels": [], "entities": []}, {"text": "Special forms of relatedness are represented in the lexical entries of the WordNet lexical database).", "labels": [], "entities": [{"text": "WordNet lexical database", "start_pos": 75, "end_pos": 99, "type": "DATASET", "confidence": 0.9657948613166809}]}, {"text": "Paradigmatic semantic relations in WordNet have been used for diverse NL problems, including disambiguation of syntactic structure and semiautomatic construction of a large-scale ontology for machine translation.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 192, "end_pos": 211, "type": "TASK", "confidence": 0.7460865080356598}]}, {"text": "In this paper, we focus on a particular case of semantic relatedness: relatedness between adjectives which describe the same property.", "labels": [], "entities": []}, {"text": "We describe a technique for automatically grouping adjectives according to their meaning based on a given text corpus, so that all adjectives placed in one group describe different values of the same property.", "labels": [], "entities": []}, {"text": "Our method is based on statistical techniques, augmented with linguistic information derived from the corpus, and is completely domain independent.", "labels": [], "entities": []}, {"text": "It demonstrates how high-level semantic knowledge can be computed from large amounts of low-level knowledge (essentially plain text, part-of-speech rules, and optionally syntactic relations).", "labels": [], "entities": []}, {"text": "The problem of identifying semantically related words has received considerable attention, both in computational linguistics (e.g. in connection with thesaurus or dictionary construction) and in psychology.", "labels": [], "entities": [{"text": "identifying semantically related words", "start_pos": 15, "end_pos": 53, "type": "TASK", "confidence": 0.8408960700035095}, {"text": "dictionary construction)", "start_pos": 163, "end_pos": 187, "type": "TASK", "confidence": 0.7906134724617004}]}, {"text": "However, only recently has work been done on the automatic computation of such relationships from text, quantifying similarity between words and clustering them,).", "labels": [], "entities": []}, {"text": "In comparison, our work emphasizes the use of shallow linguistic knowledge in addition to a statistical model and is original in the use of negative knowledge to constrain the search space.", "labels": [], "entities": []}, {"text": "Furthermore, we use a flexible architecture which will allow us to easily incorporate additional knowledge sources for computing similarity.", "labels": [], "entities": []}, {"text": "While our current system does not distinguish between scalar and non-scalar adjectives, it is a first step in the automatic identification of adjectival scales, since the scales can be subsequently ordered and the non-scalar adjectives filtered on the basis of independent tests, done in part automatically and in part by hand in a post-editing phase.", "labels": [], "entities": []}, {"text": "The result is a semi-automated system for the compilation of adjectival scales.", "labels": [], "entities": [{"text": "compilation of adjectival scales", "start_pos": 46, "end_pos": 78, "type": "TASK", "confidence": 0.8342197835445404}]}, {"text": "In the following sections, we first provide background on scales, then describe our algorithm in detail, present the results obtained, and finally provide a formal evaluation of the results.", "labels": [], "entities": []}], "datasetContent": [{"text": "To evaluate the performance of our system we compared its output to a model solution for the problem designed by humans.", "labels": [], "entities": []}, {"text": "Nine human judges were presented with the set of adjectives to be partitioned, a description of the domain, and a simple example.", "labels": [], "entities": []}, {"text": "They were told that clusters should not overlap but they could select any number of clusters (the judges used from 6 to 11 clusters, with an average of 8.565 and a sample standard deviation of 1.74).", "labels": [], "entities": []}, {"text": "Note that this evaluation method differs significantly from the alternative method of asking the humans to directly estimate the goodness of the system's results (e.g.).", "labels": [], "entities": []}, {"text": "It requires an explicit construction of a model from the human judge and places the burden of the comparison between the model and the system's output on the system instead of the judge.", "labels": [], "entities": []}, {"text": "It has been repeatedly demonstrated that in complex evaluation tasks humans can easily find arguments to support observed data, leading to biased results and to an inflation of the evaluation scores.", "labels": [], "entities": []}, {"text": "To score our results, we converted the comparison of two partitions to a series of yes-no questions, each of which has a correct answer (as dictated by the model) and an answer assigned by the system.", "labels": [], "entities": []}, {"text": "For each pair of adjectives, we asked if they fell in the same cluster (\"yes\") or not (\"no\").", "labels": [], "entities": []}, {"text": "Since human judges did not always agree, we used fractional values for the correctness of each answer instead of 0 (\"incorrect\") and 1 (\"correct\").", "labels": [], "entities": []}, {"text": "We defined the correctness of each answer as the relative frequency of the association between the two adjectives among the human models and the incorrectness of each answer as 1 -correctness; in this way, associations receive a correctness value proportional to their popularity among the human judges.", "labels": [], "entities": []}, {"text": "For example, in the sample set of adjectives discussed in the previous section, the association (foreign, international) received a correctness value of 1, since all the humans placed these two adjectives in the same group, while the association (legal, severe) received a correctness value of 0.", "labels": [], "entities": [{"text": "correctness", "start_pos": 132, "end_pos": 143, "type": "METRIC", "confidence": 0.9699420928955078}]}, {"text": "The pair (economic, political) on the other hand received a correctness value of 0.67, since two thirds of the judges placed the two adjectives in the same group.", "labels": [], "entities": [{"text": "correctness", "start_pos": 60, "end_pos": 71, "type": "METRIC", "confidence": 0.9976014494895935}]}, {"text": "Once correctness and incorrectness values have been defined, we can generalize measures such as \"the number of correct associations retrieved by the system\" by using summation of those values instead of counting.", "labels": [], "entities": []}, {"text": "Then the contingency table model, widely used in Information Retrieval and Psychology, is applicable.", "labels": [], "entities": [{"text": "Information Retrieval", "start_pos": 49, "end_pos": 70, "type": "TASK", "confidence": 0.8218027949333191}]}, {"text": "Referring to the classification of the yes-no answers in, the following measures are defined : In other words, recall is the percentage of correct \"yes\" answers that the system found among the model \"yes\" answers, precision is the percentage of correct \"yes\" answers among the total of \"yes\" answers that the system reported, and fallout is the percentage of incorrect \"yes\" answers relative to the total number of \"no\" answers 6.", "labels": [], "entities": [{"text": "recall", "start_pos": 111, "end_pos": 117, "type": "METRIC", "confidence": 0.9996408224105835}, {"text": "precision", "start_pos": 214, "end_pos": 223, "type": "METRIC", "confidence": 0.9995393753051758}]}, {"text": "Note that in our generalized contingency table model, the symbols a, b, c, and d do not represent numbers of observed associations but rather sums of correctness or incorrectness values.", "labels": [], "entities": []}, {"text": "These sums use correctness values for the quantities in the first column of and incorrectness values for the quantities in the second column of.", "labels": [], "entities": [{"text": "correctness", "start_pos": 15, "end_pos": 26, "type": "METRIC", "confidence": 0.9850316047668457}]}, {"text": "Furthermore, the summation is performed overall pairs reported or not reported by the system for quantities in the first or second row of respectively.", "labels": [], "entities": []}, {"text": "Consequently, the information theoretic measures represent the generalized counterparts of their original definitions.", "labels": [], "entities": []}, {"text": "In the case of perfect agreement between the models, or of only one model, the generalized measures reduce to their original definitions.", "labels": [], "entities": []}, {"text": "We also compute a combined measure for recall and precision, the F-measure), which always takes a value between the values of recall and precision, and is higher when recall and precision are closer; it is defined as   where 13 is the weight of recall relative to precision; we use 13=1.0, which corresponds to equal weighting of the two measures.", "labels": [], "entities": [{"text": "recall", "start_pos": 39, "end_pos": 45, "type": "METRIC", "confidence": 0.9930738210678101}, {"text": "precision", "start_pos": 50, "end_pos": 59, "type": "METRIC", "confidence": 0.9819638729095459}, {"text": "F-measure", "start_pos": 65, "end_pos": 74, "type": "METRIC", "confidence": 0.9872463941574097}, {"text": "recall", "start_pos": 126, "end_pos": 132, "type": "METRIC", "confidence": 0.9923679232597351}, {"text": "precision", "start_pos": 137, "end_pos": 146, "type": "METRIC", "confidence": 0.981401264667511}, {"text": "recall", "start_pos": 167, "end_pos": 173, "type": "METRIC", "confidence": 0.9616449475288391}, {"text": "precision", "start_pos": 178, "end_pos": 187, "type": "METRIC", "confidence": 0.9107115864753723}, {"text": "recall", "start_pos": 245, "end_pos": 251, "type": "METRIC", "confidence": 0.9289625287055969}, {"text": "precision", "start_pos": 264, "end_pos": 273, "type": "METRIC", "confidence": 0.9872232675552368}]}, {"text": "The results of applying our evaluation method to the system output () are shown in, which also includes the scores obtained for several other sub-optimal choices of the number of clusters.", "labels": [], "entities": []}, {"text": "We have made these observations related to the evaluation mechanism: 1.", "labels": [], "entities": []}, {"text": "Recall is inversely related to fallout and precision.", "labels": [], "entities": [{"text": "Recall", "start_pos": 0, "end_pos": 6, "type": "METRIC", "confidence": 0.9891949892044067}, {"text": "precision", "start_pos": 43, "end_pos": 52, "type": "METRIC", "confidence": 0.99940025806427}]}, {"text": "Decreasing the number of clusters generally increases the recall and fallout and simultaneously decreases precision.", "labels": [], "entities": [{"text": "recall", "start_pos": 58, "end_pos": 64, "type": "METRIC", "confidence": 0.9995394945144653}, {"text": "precision", "start_pos": 106, "end_pos": 115, "type": "METRIC", "confidence": 0.9989010095596313}]}, {"text": "2. We have found fallout to be a better measure overall than precision, since, in addition to its decision-theoretic advantages), it appears to be more consistent across evaluations of partitions with different numbers of clusters.", "labels": [], "entities": [{"text": "precision", "start_pos": 61, "end_pos": 70, "type": "METRIC", "confidence": 0.999527096748352}]}, {"text": "This has also been reported by other researchers in different evaluation problems ().", "labels": [], "entities": []}, {"text": "3. The problem of assessing the meaning of the evaluation scores in an absolute sense is a non-trivial one.", "labels": [], "entities": []}, {"text": "For example, there has been increasing concern that the scoring methods used for evaluating the goodness of parsers are producing values which seem extremely good (in the >90% range), while in fact the parse trees produced are not so satisfactory; the blame for this inflation of the scores can be assigned to an inadequate comparison technique, which essentially considers a tree fragment correct when it is apart of (although not exactly matching) the corresponding fragment in the model.", "labels": [], "entities": []}, {"text": "For other tasks, such as part-of-speech assignment to free text, the comparison techniques are sound, but very high levels of performance (e.g, 90%) can be obtained by a zeroparameter model which operates at random; clearly this makes the assessment of the significance of an improvement over the baseline of the random algorithm much harder.", "labels": [], "entities": [{"text": "part-of-speech assignment to free text", "start_pos": 25, "end_pos": 63, "type": "TASK", "confidence": 0.8130157291889191}]}, {"text": "As a consequence of point (3) made above, we need to understand the significance of the scores produced by our evaluation methods (for example, the limits of their ranges) before trying to interpret them.", "labels": [], "entities": []}, {"text": "There are theoretical principles which indicate that the evaluation metrics will produce lower values much more easily than higher ones.", "labels": [], "entities": []}, {"text": "Because of the multiple models used, perfect scores are not attainable.", "labels": [], "entities": [{"text": "perfect scores", "start_pos": 37, "end_pos": 51, "type": "METRIC", "confidence": 0.9827145338058472}]}, {"text": "Also, because each pair of adjectives in a cluster is considered an observed association, the relationship between the number of associations produced by a cluster and the number of adjectives in the cluster is not linear (a cluster with k adjectives will produce (k) =O (k 2) associations).", "labels": [], "entities": []}, {"text": "This leads to lower values of recall, since moving a single adjective out of a cluster with k elements in the model will cause the system to miss k-1 associations.", "labels": [], "entities": [{"text": "recall", "start_pos": 30, "end_pos": 36, "type": "METRIC", "confidence": 0.9996253252029419}]}, {"text": "As an example of this phenomenon, consider the hypothetical (single) model and partition of; while the partition differs from the model only in that the first cluster has been split into two, the recall score abruptly falls to 50%.", "labels": [], "entities": [{"text": "recall score", "start_pos": 196, "end_pos": 208, "type": "METRIC", "confidence": 0.9879879355430603}]}, {"text": "In order to provide empirical evidence in addition to the theoretical discussion above, and be able to estimate an upper bound on the values of the evaluation metrics, we evaluated each human model against all the other human models, using the same evaluation method which was used for the system; the results ranged from 38 to 72% for recall, 1 to 12% for fallout, 38 to 81% for precision, and, covering a Model:: Comparison of the system's performance (9 clusters) with and without the negative knowledge module.", "labels": [], "entities": [{"text": "recall", "start_pos": 336, "end_pos": 342, "type": "METRIC", "confidence": 0.9976206421852112}, {"text": "precision", "start_pos": 380, "end_pos": 389, "type": "METRIC", "confidence": 0.9994538426399231}]}, {"text": "remarkably short range, 49 to 59% for F-measure 7, indicating that the performance of the system is not far behind human performance.", "labels": [], "entities": []}, {"text": "In order to provide a lower bound for the evaluation metrics and thus show that the system's scores are not close to the scores of the human judges simply by chance, we performed a Monte Carlo analysis for the evaluation metrics, by repeatedly creating random partitions of the sample adjectives and evaluating the results.", "labels": [], "entities": []}, {"text": "Then we estimated a smoothed probability density function for each metric from the resulting histograms; the results obtained are shown in for F-measure and fallout using 9 clusters.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 143, "end_pos": 152, "type": "METRIC", "confidence": 0.7492654919624329}]}, {"text": "We observed that the system's performance (indicated by a square in the diagrams) was significantly better than what we would expect under the null hypothesis of random performance; the probability of getting a better partition than the system's is extremely small for all metrics (no occurrence in 20,000 trials) except for fallout, for which a random system maybe better 4.9% of the time.", "labels": [], "entities": []}, {"text": "The estimated density functions also show that the metrics are severely constrained by the structure imposed by the clustering as they tend to peak at some point and then fall rapidly.", "labels": [], "entities": []}, {"text": "Finally, we performed another study to quantify the impact of using negative knowledge obtained from adjective-adjective pairs.", "labels": [], "entities": []}, {"text": "We ran our system in a mode where the suggestions of the adjectiveadjective module were ignored (i.e. stage three simply passed to the output the similarities computed by the adjective-noun module, after converting them to dissimilarities), and evaluated the results produced.", "labels": [], "entities": []}, {"text": "The values of the metrics for the partition with 9 clusters appear in, alongside the corresponding values produced when the system uses both modules.", "labels": [], "entities": []}, {"text": "When both modules are used, we can see a significant improvement of about 15 points, which is a 43% to 50% improvement for all metrics (except for fallout where the improvement is about 17%).", "labels": [], "entities": []}, {"text": "This represents a definite improvement even though for our test set of 21 adjectives) we observed in our corpus only 41 distinct adjectiveadjective pairs, out of a possible (221)=210 pairs.", "labels": [], "entities": []}, {"text": "AI7Thus indicating that human models which fared well on the precision metric tended to perform badly on recall, and vice versa; remember that the values of the metrics are related to the number of clusters used, and that the human judges were allowed to select the number of clusters they considered most appropriate; consequently, the models with high recall/low precision are the ones with a small number of clusters, while the opposite pattern of scores characterizes the models with a large number of clusters.", "labels": [], "entities": [{"text": "precision", "start_pos": 61, "end_pos": 70, "type": "METRIC", "confidence": 0.9983559250831604}, {"text": "recall", "start_pos": 105, "end_pos": 111, "type": "METRIC", "confidence": 0.9984294772148132}, {"text": "recall/low precision", "start_pos": 354, "end_pos": 374, "type": "METRIC", "confidence": 0.6853141486644745}]}, {"text": "though the observed pairs represent only 19.52% of the possible pairs, their importance is considerable.", "labels": [], "entities": []}, {"text": "Note that the sparsity of the adjective-adjective pairs does not allow us to perform a comparable study for the partition produced using the adjectiveadjective module alone, since such a partition would be largely determined by chance.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 4: Comparison of the system's performance (9 clusters) with and without the negative knowledge module.", "labels": [], "entities": []}]}