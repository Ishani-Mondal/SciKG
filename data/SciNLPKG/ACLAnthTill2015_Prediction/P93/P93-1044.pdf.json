{"title": [{"text": "Guiding an HPSG Parser using Semantic and Pragmatic Expectations", "labels": [], "entities": [{"text": "HPSG Parser", "start_pos": 11, "end_pos": 22, "type": "DATASET", "confidence": 0.877671629190445}]}], "abstractContent": [{"text": "1 Efficient natural language generation has been successfully demonstrated using highly compiled knowledge about speech acts and their related social actions.", "labels": [], "entities": [{"text": "natural language generation", "start_pos": 12, "end_pos": 39, "type": "TASK", "confidence": 0.6896366079648336}]}, {"text": "A design and prototype implementation of a parser which utilizes this same pragmatic knowledge to efficiently guide parsing is presented.", "labels": [], "entities": []}, {"text": "Such guidance is shown to prune the search space and thus avoid needless processing of pragmatically unlikely constituent structures.", "labels": [], "entities": []}, {"text": "INTRODUCTION The use of purely syntactic knowledge during the parse phase of natural language understanding yields considerable local ambiguity (consideration of impossible subeonstituents) as well global ambiguity (construction of syntactically valid parses not applicable to the socio-pragmatic context).", "labels": [], "entities": []}, {"text": "This research investigates bringing socio-pragmatic knowledge to bear during the parse, while maintaining a domain independent grammar and parser.", "labels": [], "entities": []}, {"text": "The particular technique explored uses knowledge about the pragmatic context to order the consideration of proposed parse constituents, thus guiding the parser to consider the best (wrt the expectations)", "labels": [], "entities": []}], "introductionContent": [{"text": "The use of purely syntactic knowledge during the parse phase of natural language understanding yields considerable local ambiguity (consideration of impossible subeonstituents) as well global ambiguity (construction of syntactically valid parses not applicable to the socio-pragmatic context).", "labels": [], "entities": []}, {"text": "This research investigates bringing socio-pragmatic knowledge to bear during the parse, while maintaining a domain independent grammar and parser.", "labels": [], "entities": []}, {"text": "The particular technique explored uses knowledge about the pragmatic context to order the consideration of proposed parse constituents, thus guiding the parser to consider the best (wrt the expectations) solutions first.", "labels": [], "entities": []}, {"text": "Such a search maybe classified as a bestfirst search.", "labels": [], "entities": []}, {"text": "The theoretical models used to represent the pragmatic knowledge in this study are based on Halliday's Systemic Grammar and a model of the pragmatics of conversation.", "labels": [], "entities": []}, {"text": "The model used to represent the syntax and domain independent semantic knowledge is HPSG -Head-driven Phrase Structure Grammar.", "labels": [], "entities": [{"text": "HPSG -Head-driven Phrase Structure Grammar", "start_pos": 84, "end_pos": 126, "type": "DATASET", "confidence": 0.8125700950622559}]}], "datasetContent": [{"text": "The heuristic evaluation function is based on three specific types of tests: I.", "labels": [], "entities": []}, {"text": "Role match -does a constituent match a role's set of expected features?", "labels": [], "entities": []}, {"text": "Role path match -is a constituent role path compatible with the roles of its children?", "labels": [], "entities": []}, {"text": "Clausal completeness -are all clausal roles expected for this constituent present?", "labels": [], "entities": [{"text": "Clausal completeness", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.9737736880779266}]}, {"text": "Tests II and III above require that constituents under consideration have roles already assigned to them.", "labels": [], "entities": []}, {"text": "For example, in the case of II, the test requires roles for both the new constituent and the proposed daughters of the constituent.", "labels": [], "entities": []}, {"text": "But since the parse strategy employeed is bottom-up, role paths cannot be anchored to a root, and thus fully known, until parse completion.", "labels": [], "entities": []}, {"text": "The solution to this dilemma is to hypothesise a constituent's role using a process similar to abduction.", "labels": [], "entities": [{"text": "hypothesise a constituent's role", "start_pos": 35, "end_pos": 67, "type": "TASK", "confidence": 0.8304869413375855}]}, {"text": "Two types of knowledge are exploited in this process.", "labels": [], "entities": []}, {"text": "First, roles with features which subsume or are consistant with a proposed constituent are considered good candidate roles.", "labels": [], "entities": []}, {"text": "Also, roles may also be inferred by projecting up from the roles already hypothesized for the children.", "labels": [], "entities": []}, {"text": "By intersecting these two sources of role evidence, the list of hypothesized roles can be refined (by ruling out roles without both types of evidence).", "labels": [], "entities": []}, {"text": "In this manner the hypothesized roles of later constituents can be refined from descendant constituents.", "labels": [], "entities": []}, {"text": "In the case of roles projected from daughters, clausal boundary knowledge must be applied to correctly infer the parent role.", "labels": [], "entities": []}, {"text": "The techniques described here have been used successfully to guide the parsing of several sentences taken from real conversations.", "labels": [], "entities": [{"text": "parsing of several sentences taken from real conversations", "start_pos": 71, "end_pos": 129, "type": "TASK", "confidence": 0.7284309342503548}]}, {"text": "The pragmatic and semantic knowledge already existed from Patten's research to generate these sentences.", "labels": [], "entities": []}, {"text": "A subset of this knowledge, judged to represent the partial knowledge available to a listener, was used to generate expectations in the form described above.", "labels": [], "entities": []}, {"text": "The parser used in this study by default produced all possible parses.", "labels": [], "entities": []}, {"text": "The modified version attempts to converge on the \"expected\" parse first, and terminate.", "labels": [], "entities": []}, {"text": "For each sentence tested the parser converges on the correct parse first.", "labels": [], "entities": []}, {"text": "When the expectations are modified to expect a different parse, a different (and correct) parse is found first.", "labels": [], "entities": []}, {"text": "The results in terms of speedup vary considerably depending on the level of ambiguity present in the sentence.", "labels": [], "entities": []}, {"text": "The most complex sentence parsed thus far exhibits considerable speedup.", "labels": [], "entities": []}, {"text": "When unguided, the parser produces 24 parses, and considers a total of 252 distinct constituents.", "labels": [], "entities": []}, {"text": "In the guided case, the parser only considers 39 constituents, and converges on the one \"correct\" parse first.", "labels": [], "entities": []}, {"text": "Within the current testing environment, this guidence results in a greater then ten-fold speedup in terms of CPU time.", "labels": [], "entities": []}], "tableCaptions": []}