{"title": [], "abstractContent": [{"text": "In this talk, we will, show how techniques for planning text and discourse can be generalized to plan the structure and content of multimodal communications , that integrate natural language, pointing, graphics, and animations.", "labels": [], "entities": []}, {"text": "The central claim of this talk is that the generation of multimodal discourse can be considered as an incremental planning process that aims to achieve a given communicative goal.", "labels": [], "entities": []}, {"text": "One of the surprises from our research is that it is actually possible to extend and adapt many of the fundamental concepts developed to date in computatational linguistics in such away that they become useful for multimodal discourse as well.", "labels": [], "entities": []}, {"text": "This means that an interesting methodologi-cal transfer from the area of natural language processing to a much broader computational model of multimodal communication is possible.", "labels": [], "entities": []}, {"text": "In particular , semantic and pragmatic concepts like speech acts, coherence, focus, communicative act, discourse model, reference, implicature, anaphora, rhetorical relations and scope ambiguity take an extended meaning in the context of multimodal discourse.", "labels": [], "entities": []}, {"text": "It is an important goal of this research not simply to merge the verbalization and visualiza-tion results of mode-specific generators, but to carefully coordinate them in such away that they generate a multiplieative improvement in communication capabilities.", "labels": [], "entities": []}, {"text": "Allowing all of the modalities to refer to and depend upon each other is a key to the richness of multimodal communication.", "labels": [], "entities": []}, {"text": "A basic principle underlying our model is that the various constituents of a multimodal communication should be generated from a common representation of what is to be conveyed.", "labels": [], "entities": []}, {"text": "This raises the question of how to decompose a given communicative goal into subgoals to be realized by the mode-specific generators, so that they complement each other.", "labels": [], "entities": []}, {"text": "To address this problem, we explore computational models of the cognitive de-eision process, coping with questions such as what should go into text, what should go into graphics, and which kinds of links between the verbal and non-verbal fragments are necessary.", "labels": [], "entities": []}, {"text": "In addition, we deal with layout as a rhetorical force, influencing the intentional and attentional state of the discourse participants.", "labels": [], "entities": []}, {"text": "We have been engaged in work in the area of multimodal communication for several years now, starting with the HAM-ANS (Wahlster et al.", "labels": [], "entities": [{"text": "multimodal communication", "start_pos": 44, "end_pos": 68, "type": "TASK", "confidence": 0.6938264071941376}, {"text": "HAM-ANS", "start_pos": 110, "end_pos": 117, "type": "DATASET", "confidence": 0.797601044178009}]}, {"text": "1983) and VITRA systems (Wahlster 1989), which automatically create natural language descriptions of pictures and image sequences shown on the screen.", "labels": [], "entities": []}, {"text": "These projects resulted in a better understanding of how perception interacts with language production.", "labels": [], "entities": []}, {"text": "Since then, we have been investigating ways of integrating tactile pointing and graphics with natural language understanding and generation in the XTRA (Wahlster 1991) and WIP projects (Wahlster et al. 1991).", "labels": [], "entities": [{"text": "natural language understanding and generation", "start_pos": 94, "end_pos": 139, "type": "TASK", "confidence": 0.7180938959121704}]}, {"text": "The task of the knowledge-based presentation system WIP is the context-sensitive generation of a variety of multimodal communications from an input including a presentation goal (Wahlster et al. 1993a).", "labels": [], "entities": []}, {"text": "The presentation goal is a formal representation of the communicative intent specified by a back-end application system.", "labels": [], "entities": []}, {"text": "WIP is currently able to generate simple multimodal explanations in German and English on using an espresso machine , assembling a lawnmower , or installing a modem, demonstrating our claim of language and application independence.", "labels": [], "entities": [{"text": "WIP", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.9353487491607666}]}, {"text": "WIP is a highly adap-tive multimodal presentation system, since all of its output is generated on the fly and customized for the intended discourse situation.", "labels": [], "entities": [{"text": "WIP", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.8203378319740295}]}, {"text": "The quest for adaptation is based on the fact that it is impossible to anticipate the needs and requirements of each potential dialog partner in an infinite number of discourse situations.", "labels": [], "entities": []}, {"text": "Thus all presentation decisions are postponed until runtime.", "labels": [], "entities": []}, {"text": "In contrast to hypermedia-based approaches, WIP does not use any preplanned texts or graphics.", "labels": [], "entities": [{"text": "WIP", "start_pos": 44, "end_pos": 47, "type": "TASK", "confidence": 0.799501359462738}]}, {"text": "That is, each presentation is designed from scratch by reasoning 95", "labels": [], "entities": []}], "introductionContent": [], "datasetContent": [], "tableCaptions": []}