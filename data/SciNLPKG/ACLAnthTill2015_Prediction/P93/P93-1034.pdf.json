{"title": [], "abstractContent": [{"text": "This paper presents a method for inducing the parts of speech of a language and part-of-speech labels for individual words from a large text corpus.", "labels": [], "entities": []}, {"text": "Vector representations for the part-of-speech of a word are formed from entries of its near lexical neighbors.", "labels": [], "entities": []}, {"text": "A dimen-sionality reduction creates a space representing the syntactic categories of unambiguous words.", "labels": [], "entities": []}, {"text": "A neural net trained on these spatial representations classifies individual contexts of occurrence of ambiguous words.", "labels": [], "entities": []}, {"text": "The method classifies both ambiguous and unam-biguous words correctly with high accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 80, "end_pos": 88, "type": "METRIC", "confidence": 0.9973575472831726}]}], "introductionContent": [{"text": "Part-of-speech information about individual words is necessary for any kind of syntactic and higher level processing of natural language.", "labels": [], "entities": []}, {"text": "While it is easy to obtain lists with part of speech labels for frequent English words, such information is not available for less common languages.", "labels": [], "entities": []}, {"text": "Even for English, a categorization of words that is tailored to a particular genre maybe desired.", "labels": [], "entities": []}, {"text": "Finally, there are rare words that need to be categorized even if frequent words are covered by an available electronic dictionary.", "labels": [], "entities": []}, {"text": "This paper presents a method for inducing the parts of speech of a language and part-of-speech labels for individual words from a large text corpus.", "labels": [], "entities": []}, {"text": "Little, if any, language-specific knowledge is used, so that it is applicable to any language in principle.", "labels": [], "entities": []}, {"text": "Since the part-of-speech representations are derived from the corpus, the resulting categorization is highly text specific and doesn't contain categories that are inappropriate for the genre in question.", "labels": [], "entities": []}, {"text": "The method is efficient enough for vocabularies of tens of thousands of words thus addressing the problem of coverage.", "labels": [], "entities": [{"text": "coverage", "start_pos": 109, "end_pos": 117, "type": "TASK", "confidence": 0.952511191368103}]}, {"text": "The problem of how syntactic categories can be induced is also of theoretical interest in language acquisition and learnability.", "labels": [], "entities": [{"text": "language acquisition", "start_pos": 90, "end_pos": 110, "type": "TASK", "confidence": 0.7024032175540924}]}, {"text": "Syntactic category information is part of the basic knowledge about language that children must learn before they can acquire more complicated structures.", "labels": [], "entities": [{"text": "Syntactic category information", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.8881461421648661}]}, {"text": "It has been claimed that \"the properties that the child can detect in the input -such as the serial positions and adjacency and co-occurrence relations among words -are in general linguistically irrelevant.\")", "labels": [], "entities": []}, {"text": "It will be shown here that relative position of words with respect to each other is sufficient for learning the major syntactic categories.", "labels": [], "entities": []}, {"text": "In the first part of the derivation, two iterations of a massive linear approximation of cooccurrence counts categorize unambiguous words.", "labels": [], "entities": []}, {"text": "Then a neural net trained on these words classifies individual contexts of occurrence of ambiguous words.", "labels": [], "entities": []}, {"text": "An evaluation suggests that the method classifies both ambiguous and unambiguous words correctly.", "labels": [], "entities": []}, {"text": "It differs from previous work in its efficiency and applicability to large vocabularies; and in that linguistic knowledge is only used in the very last step so that theoretical assumptions that don't hold fora language or sublanguage have minimal influence on the classification.", "labels": [], "entities": []}, {"text": "The next two sections describe the linear approximation and a birecurrent neural network for the classification of ambiguous words.", "labels": [], "entities": [{"text": "classification of ambiguous words", "start_pos": 97, "end_pos": 130, "type": "TASK", "confidence": 0.8826026320457458}]}, {"text": "The last section discusses the results.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": []}