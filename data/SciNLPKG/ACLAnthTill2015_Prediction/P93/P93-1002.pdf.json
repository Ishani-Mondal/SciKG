{"title": [{"text": "ALIGNING SENTENCES IN BILINGUAL CORPORA USING LEXICAL INFORMATION", "labels": [], "entities": [{"text": "BILINGUAL CORPORA USING LEXICAL INFORMATION", "start_pos": 22, "end_pos": 65, "type": "METRIC", "confidence": 0.7879754185676575}]}], "abstractContent": [{"text": "In this paper, we describe a fast algorithm for aligning sentences with their translations in a bilingual corpus.", "labels": [], "entities": []}, {"text": "Existing efficient algorithms ignore word identities and only consider sentence length (Brown el al., 1991b; Gale and Church, 1991).", "labels": [], "entities": []}, {"text": "Our algorithm constructs a simple statistical word-to-word translation model on the fly during alignment.", "labels": [], "entities": [{"text": "statistical word-to-word translation", "start_pos": 34, "end_pos": 70, "type": "TASK", "confidence": 0.6488159199555715}]}, {"text": "We find the alignment that maximizes the probability of generating the corpus with this translation model.", "labels": [], "entities": []}, {"text": "We have achieved an error rate of approximately 0.4% on Canadian Hansard data, which is a significant improvement over previous results.", "labels": [], "entities": [{"text": "error rate", "start_pos": 20, "end_pos": 30, "type": "METRIC", "confidence": 0.9934110045433044}, {"text": "Canadian Hansard data", "start_pos": 56, "end_pos": 77, "type": "DATASET", "confidence": 0.836304783821106}]}, {"text": "The algorithm is language independent .", "labels": [], "entities": []}], "introductionContent": [{"text": "In this paper, we describe an algorithm for aligning sentences with their translations in a bilingual corpus.", "labels": [], "entities": []}, {"text": "Aligned bilingual corpora have proved useful in many tasks, including machine translation, sense disambiguation; Dagan el at.,, and bilingual lexicography ().", "labels": [], "entities": [{"text": "machine translation", "start_pos": 70, "end_pos": 89, "type": "TASK", "confidence": 0.824635773897171}, {"text": "sense disambiguation", "start_pos": 91, "end_pos": 111, "type": "TASK", "confidence": 0.6645450592041016}]}, {"text": "The task is difficult because sentences frequently do not align one-to-one.", "labels": [], "entities": []}, {"text": "Sometimes sentences align many-to-one, and often there are deletions in *The author wishes to thank Peter Brown, Stephen DellaPietra, Vincent DellaPietra, and Robert Mercer for their suggestions, support, and relentless taunting.", "labels": [], "entities": []}, {"text": "The author also wishes to thank Jan Hajic and Meredith Goldsmith as well as the aforementioned for checking the aligmnents produced by the implementation.", "labels": [], "entities": []}, {"text": "one of the supposedly parallel corpora of a bilingual corpus.", "labels": [], "entities": []}, {"text": "These deletions can be substantial; in the Canadian Hansard corpus, there are many deletions of several thousand sentences and one deletion of over 90,000 sentences.", "labels": [], "entities": [{"text": "Canadian Hansard corpus", "start_pos": 43, "end_pos": 66, "type": "DATASET", "confidence": 0.8439235885938009}]}, {"text": "Previous work includes and (.", "labels": [], "entities": []}, {"text": "In Brown, alignment is based solely on the number of words in each sentence; the actual identities of words are ignored.", "labels": [], "entities": []}, {"text": "The general idea is that the closer in length two sentences are, the more likely they align.", "labels": [], "entities": []}, {"text": "To perform the search for the best alignment, dynamic programming is used.", "labels": [], "entities": []}, {"text": "Because dynamic programming requires time quadratic in the length of the text aligned, it is not practical to align a large corpus as a single unit.", "labels": [], "entities": []}, {"text": "The computation required is drastically reduced if the bilingual corpus can be subdivided into smaller chunks.", "labels": [], "entities": []}, {"text": "Brown uses anchors to perform this subdivision.", "labels": [], "entities": []}, {"text": "An anchor is apiece of text likely to be present at the same location in both of the parallel corpora of a bilingual corpus.", "labels": [], "entities": []}, {"text": "Dynamic programming is used to align anchors, and then dynamic programming is used again to align the text between anchors.", "labels": [], "entities": []}, {"text": "The Gale algorithm is similar to the Brown algorithm except that instead of basing alignment on the number of words in sentences, alignment is based on the number of characters in sentences.", "labels": [], "entities": [{"text": "basing alignment", "start_pos": 76, "end_pos": 92, "type": "TASK", "confidence": 0.863445520401001}]}, {"text": "Dynamic programming is also used to search for the best alignment.", "labels": [], "entities": []}, {"text": "Large corpora are assumed to be already subdivided into smaller chunks.", "labels": [], "entities": []}, {"text": "While these algorithms have achieved remarkably good performance, there is definite room for improvement.", "labels": [], "entities": []}, {"text": "These algorithms are not robust with respect to non-literal translations and small deletions; they can easily misalign small passages Oui.", "labels": [], "entities": []}, {"text": ":: A Bilingual Corpus Fragment because they ignore word identities.", "labels": [], "entities": [{"text": "Bilingual Corpus Fragment", "start_pos": 5, "end_pos": 30, "type": "TASK", "confidence": 0.5955429077148438}]}, {"text": "For example, the type of passage depicted in occurs in the Hansard corpus.", "labels": [], "entities": [{"text": "Hansard corpus", "start_pos": 59, "end_pos": 73, "type": "DATASET", "confidence": 0.9883854687213898}]}, {"text": "With length-based alignment algorithms, these passages may well be misaligned by an even number of sentences if one of the corpora contains a deletion.", "labels": [], "entities": []}, {"text": "In addition, with lengthbased algorithms it is difficult to automatically recover from large deletions.", "labels": [], "entities": []}, {"text": "In Brown, anchors are used to deal with this issue, but the selection of anchors requires manual inspection of the corpus to be aligned.", "labels": [], "entities": []}, {"text": "Gale does not discuss this issue.", "labels": [], "entities": []}, {"text": "Alignment algorithms that use lexical information offer a potential for higher accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 79, "end_pos": 87, "type": "METRIC", "confidence": 0.988864541053772}]}, {"text": "However, to date lexically-based algorithms have not proved efficient enough to be suitable for large corpora.", "labels": [], "entities": []}, {"text": "In this paper, we describe a fast algorithm for sentence alignment that uses lexical information.", "labels": [], "entities": [{"text": "sentence alignment", "start_pos": 48, "end_pos": 66, "type": "TASK", "confidence": 0.7609448730945587}]}, {"text": "The algorithm constructs a simple statistical word-to-word translation model on the fly during sentence alignment.", "labels": [], "entities": [{"text": "statistical word-to-word translation", "start_pos": 34, "end_pos": 70, "type": "TASK", "confidence": 0.6722715099652609}, {"text": "sentence alignment", "start_pos": 95, "end_pos": 113, "type": "TASK", "confidence": 0.7079666703939438}]}, {"text": "We find the alignment that maximizes the probability of generating the corpus with this translation model.", "labels": [], "entities": []}, {"text": "The search strategy used is dynamic programming with thresholding.", "labels": [], "entities": []}, {"text": "Because of thresholding, the search is linear in the length of the corpus so that a corpus need not be subdivided into smaller chunks.", "labels": [], "entities": []}, {"text": "The search strategy is robust with respect to large deletions; lexical information allows us to confidently identify the beginning and end of deletions.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": []}