{"title": [{"text": "Exploring Word Embedding for Drug Name Recognition", "labels": [], "entities": [{"text": "Drug Name Recognition", "start_pos": 29, "end_pos": 50, "type": "TASK", "confidence": 0.6619706650575002}]}], "abstractContent": [{"text": "This paper describes a machine learning-based approach that uses word embedding features to recognize drug names from biomedical texts.", "labels": [], "entities": []}, {"text": "As a starting point, we developed a baseline system based on Conditional Random Field (CRF) trained with standard features used in current Named Entity Recognition (NER) systems.", "labels": [], "entities": [{"text": "Named Entity Recognition (NER)", "start_pos": 139, "end_pos": 169, "type": "TASK", "confidence": 0.8222542107105255}]}, {"text": "Then, the system was extended to incorporate new features, such as word vectors and word clusters generated by the Word2Vec tool and a lexicon feature from the DINTO ontology.", "labels": [], "entities": [{"text": "Word2Vec", "start_pos": 115, "end_pos": 123, "type": "DATASET", "confidence": 0.9357538819313049}]}, {"text": "We trained the Word2vec tool over two different corpus: Wikipedia and MedLine.", "labels": [], "entities": [{"text": "Wikipedia", "start_pos": 56, "end_pos": 65, "type": "DATASET", "confidence": 0.9717817902565002}, {"text": "MedLine", "start_pos": 70, "end_pos": 77, "type": "DATASET", "confidence": 0.8990458250045776}]}, {"text": "Our main goal is to study the effectiveness of using word embeddings as features to improve performance on our baseline system, as well as to analyze whether the DINTO ontology could be a valuable complementary data source integrated in a machine learning NER system.", "labels": [], "entities": []}, {"text": "To evaluate our approach and compare it with previous work, we conducted a series of experiments on the dataset of SemEval-2013 Task 9.1 Drug Name Recognition.", "labels": [], "entities": [{"text": "SemEval-2013 Task 9.1 Drug Name Recognition", "start_pos": 115, "end_pos": 158, "type": "TASK", "confidence": 0.8257129291693369}]}], "introductionContent": [{"text": "The automatic recognition of biomedical entities from scientific texts can markedly reduce the time that experts spend populating biomedical knowledge bases and annotating papers and patents.", "labels": [], "entities": [{"text": "automatic recognition of biomedical entities from scientific texts", "start_pos": 4, "end_pos": 70, "type": "TASK", "confidence": 0.7401061467826366}]}, {"text": "Furthermore, Named Entity Recognition (NER) is a crucial component for many Natural Language Processing (NLP) systems such as relation extraction, text classification or sentiment analysis systems, among many others.", "labels": [], "entities": [{"text": "Named Entity Recognition (NER)", "start_pos": 13, "end_pos": 43, "type": "TASK", "confidence": 0.7976672848065695}, {"text": "relation extraction", "start_pos": 126, "end_pos": 145, "type": "TASK", "confidence": 0.8781532943248749}, {"text": "text classification or sentiment analysis", "start_pos": 147, "end_pos": 188, "type": "TASK", "confidence": 0.7077903687953949}]}, {"text": "Conditional Random Fields (CRF) often show best results in the recognition of drugs and chemical names (.", "labels": [], "entities": [{"text": "recognition of drugs and chemical names", "start_pos": 63, "end_pos": 102, "type": "TASK", "confidence": 0.8127060929934183}]}, {"text": "So far the most popular features for CRF-based NER systems concern syntactic and semantic properties of words (such as tokens, part-of-speech (POS) tags, lemmas, orthographic and lexicon features, among others).", "labels": [], "entities": []}, {"text": "In this work, we develop a system based on a CRF to recognize drug mentions occurring in the DDI corpus 1 . It consists of two different datasets: DDI-DrugBank (792 texts selected from the DrugBank database) and DDI-MedLine (233 MedLine abstracts on the subject of DDIs).", "labels": [], "entities": [{"text": "DrugBank database", "start_pos": 189, "end_pos": 206, "type": "DATASET", "confidence": 0.9427921772003174}]}, {"text": "This corpus will allow us to compare our system to the participating systems in the SemEval-2013 Task 9.1 DrugNER Task.", "labels": [], "entities": [{"text": "SemEval-2013 Task 9.1 DrugNER Task", "start_pos": 84, "end_pos": 118, "type": "TASK", "confidence": 0.6231121897697449}]}, {"text": "One of the goals of this paper is to study whether the DINTO ontology 2 (Herrero Zazo, 2015) can provide valuable information for this task.", "labels": [], "entities": [{"text": "DINTO ontology 2 (Herrero Zazo, 2015)", "start_pos": 55, "end_pos": 92, "type": "DATASET", "confidence": 0.7171197003788419}]}, {"text": "As far as we know, DINTO is the first ontology providing a comprehensive and accurate representation of drug-drug interactions (DDI) knowledge.", "labels": [], "entities": [{"text": "representation of drug-drug interactions (DDI) knowledge", "start_pos": 86, "end_pos": 142, "type": "TASK", "confidence": 0.7398419827222824}]}, {"text": "The DINTO ontology contains a total of 25,809 classes, in particular 8,786 drugs and 11,555 DDIs.", "labels": [], "entities": [{"text": "DINTO ontology", "start_pos": 4, "end_pos": 18, "type": "TASK", "confidence": 0.6036537289619446}]}, {"text": "Several domain resources such as the CheBI ontology, the DrugBank database () or the OAE ontology () have been reused to create DINTO.", "labels": [], "entities": [{"text": "CheBI ontology", "start_pos": 37, "end_pos": 51, "type": "DATASET", "confidence": 0.9320653080940247}, {"text": "DrugBank database", "start_pos": 57, "end_pos": 74, "type": "DATASET", "confidence": 0.9673174917697906}, {"text": "OAE ontology", "start_pos": 85, "end_pos": 97, "type": "DATASET", "confidence": 0.8354673087596893}]}, {"text": "Furthermore, it was designed to be used by the computer science community working on the DDI domain.", "labels": [], "entities": [{"text": "DDI domain", "start_pos": 89, "end_pos": 99, "type": "DATASET", "confidence": 0.9063830673694611}]}, {"text": "A detailed description of the DINTO ontology can be found in HerreroZazo's PhD thesis.", "labels": [], "entities": []}, {"text": "As the main contribution, this work explores the effectiveness of new features for the Drug NER task, in particular, word clusters and word vectors generated using the Word2Vec tool (, a word embedding model based on a neural network (NN).", "labels": [], "entities": [{"text": "Drug NER task", "start_pos": 87, "end_pos": 100, "type": "TASK", "confidence": 0.62924857934316}]}, {"text": "We hypothesize that the use of word embedding features would allow us to accurately detect even those drugs that are not in the training set or in the DINTO ontology.", "labels": [], "entities": [{"text": "DINTO ontology", "start_pos": 151, "end_pos": 165, "type": "DATASET", "confidence": 0.8482382893562317}]}, {"text": "A word embedding is a function to map words to highdimensional vectors.", "labels": [], "entities": []}, {"text": "At present, NN is one of the most used learning techniques for generating word embeddings ().", "labels": [], "entities": []}, {"text": "The essential assumption of word embedding is that semantically close words will have similar vectors.", "labels": [], "entities": []}, {"text": "Word embeddings have shown promising results in NLP tasks, such as named entity recognition, sentiment analysis or parsing).", "labels": [], "entities": [{"text": "named entity recognition", "start_pos": 67, "end_pos": 91, "type": "TASK", "confidence": 0.617166539033254}, {"text": "sentiment analysis or parsing", "start_pos": 93, "end_pos": 122, "type": "TASK", "confidence": 0.7122015580534935}]}, {"text": "However, to the best of our knowledge, this technique has hardly ever been exploited in drug name recognition (.", "labels": [], "entities": [{"text": "drug name recognition", "start_pos": 88, "end_pos": 109, "type": "TASK", "confidence": 0.6063017050425211}]}, {"text": "In fact, our work is the first to explore the word embedding potential using the whole word2vec vector for drug name recognition.", "labels": [], "entities": [{"text": "drug name recognition", "start_pos": 107, "end_pos": 128, "type": "TASK", "confidence": 0.6289795239766439}]}, {"text": "In contrast to (, we also train the word embedding features (word clusters and word vectors) using the latest wikipedia dump 3 , which contains more than 3 billion words, as well as the 2013 release of MedLine 4 , which they used for genereting their word representations.", "labels": [], "entities": []}, {"text": "This release contains approximately one million words, being thus much smaller than the Wikipedia collection.", "labels": [], "entities": [{"text": "Wikipedia collection", "start_pos": 88, "end_pos": 108, "type": "DATASET", "confidence": 0.9147848188877106}]}, {"text": "While MedLine is a biomedical literature database, Wikipedia covers many different domains of knowledge.", "labels": [], "entities": []}, {"text": "However, we believe that the larger the dataset used for training the Word2Vec models, the better word embeddings should be obtained.", "labels": [], "entities": []}, {"text": "Thus, we would like to compare the effectiveness of word embeddings features trained on a specific domain corpus, such as MedLine, to those trained on a larger collection, such as Wikipedia.", "labels": [], "entities": []}, {"text": "Another key difference of our work with () is that while they only gave results for the whole DDI corpus, we analyze and discuss the effect of the DINTO and word2vec features on each one of the datasets: DDI-DrugBank and DDI-MedLine.", "labels": [], "entities": [{"text": "DDI corpus", "start_pos": 94, "end_pos": 104, "type": "DATASET", "confidence": 0.7940950691699982}]}, {"text": "This analysis is necessary in order to know what features are more efficient on each dataset.", "labels": [], "entities": []}, {"text": "MedLine abstracts are very different from DrugBank texts.", "labels": [], "entities": [{"text": "MedLine abstracts", "start_pos": 0, "end_pos": 17, "type": "DATASET", "confidence": 0.8435966372489929}, {"text": "DrugBank texts", "start_pos": 42, "end_pos": 56, "type": "DATASET", "confidence": 0.9659810066223145}]}, {"text": "While abstracts are mainly addressed to scientists in life sciences, texts from DDI-DrugBank are written in a language understandable to patients.", "labels": [], "entities": []}, {"text": "The paper is organized as follows.", "labels": [], "entities": []}, {"text": "In the next section, we introduce the two main shared tasks for drug name recognition task organized so far: the BioCreative IV ChemdNER task and the drugNER subtask of the SemEval-2013 DDIExtraction challenge.", "labels": [], "entities": [{"text": "drug name recognition task", "start_pos": 64, "end_pos": 90, "type": "TASK", "confidence": 0.7221155092120171}, {"text": "SemEval-2013 DDIExtraction challenge", "start_pos": 173, "end_pos": 209, "type": "TASK", "confidence": 0.5363336205482483}]}, {"text": "Section 3 describes the datasets used and the experiments performed.", "labels": [], "entities": []}, {"text": "The experimental results are presented and discussed in Section 4.", "labels": [], "entities": []}, {"text": "We conclude in Section 5 with a summary of our findings and some directions for future work.", "labels": [], "entities": []}, {"text": "2 State of the art 2.1 CHEMDNER task The BioCreative IV CHEMDNER (Chemical compound and drug name recognition) task was devoted to NER focusing on detecting chemical entity mentions.", "labels": [], "entities": [{"text": "CHEMDNER", "start_pos": 23, "end_pos": 31, "type": "METRIC", "confidence": 0.9594945907592773}, {"text": "BioCreative IV CHEMDNER", "start_pos": 41, "end_pos": 64, "type": "METRIC", "confidence": 0.8365452885627747}, {"text": "Chemical compound and drug name recognition)", "start_pos": 66, "end_pos": 110, "type": "TASK", "confidence": 0.6274756278310504}, {"text": "NER", "start_pos": 131, "end_pos": 134, "type": "TASK", "confidence": 0.9944228529930115}, {"text": "detecting chemical entity mentions", "start_pos": 147, "end_pos": 181, "type": "TASK", "confidence": 0.8406423479318619}]}, {"text": "Twenty-six teams participated in this task and as a result a corpus containing 10,000 PubMed abstracts annotated with 84,355 chemistry and chemical entity mentions was generated ().", "labels": [], "entities": []}, {"text": "An overview of the task as well as of the main relevant characteristics of participating systems is given in ().", "labels": [], "entities": []}, {"text": "Participating systems used three approaches to recognize chemical entity mentions: (a) supervised machine learning techniques (used by 17 systems).", "labels": [], "entities": [{"text": "recognize chemical entity mentions", "start_pos": 47, "end_pos": 81, "type": "TASK", "confidence": 0.7609064728021622}]}, {"text": "CRF was the most used technique followed by Support Vector Machines (SVM) and logistic regression.", "labels": [], "entities": []}, {"text": "Only three systems tried a hybrid approach combining machine learning and rule-based strategies.", "labels": [], "entities": []}, {"text": "Analyzing the runs submitted by participating teams, it is important to highlight that the top ranked system () (87,39% of F-score) implemented a hybrid approach that combines a CRF model, a set of patterns to identify special types of mentions and gazetteers.", "labels": [], "entities": [{"text": "F-score", "start_pos": 123, "end_pos": 130, "type": "METRIC", "confidence": 0.9892560243606567}]}, {"text": "This score is very close to the inter human annotator agreement (IAA) in this task (91%).", "labels": [], "entities": [{"text": "inter human annotator agreement (IAA)", "start_pos": 32, "end_pos": 69, "type": "METRIC", "confidence": 0.7171584240027836}]}], "datasetContent": [{"text": "The major contribution of DDIExtraction was to provide a benchmark corpus, the DDI corpus.", "labels": [], "entities": [{"text": "DDI corpus", "start_pos": 79, "end_pos": 89, "type": "DATASET", "confidence": 0.9238274395465851}]}, {"text": "The corpus was manually annotated with a total of 18,502 pharmacological substances and 5,028 DDIs.", "labels": [], "entities": []}, {"text": "It consists of two different datasets: DDIDrugBank (792 texts selected from the DrugBank database) and DDI-MedLine (233 MedLine abstracts on the subject of DDIs).", "labels": [], "entities": [{"text": "DDIDrugBank", "start_pos": 39, "end_pos": 50, "type": "DATASET", "confidence": 0.8890198469161987}, {"text": "DrugBank database", "start_pos": 80, "end_pos": 97, "type": "DATASET", "confidence": 0.9399727880954742}]}, {"text": "A detailed description of the DDI corpus can be found in).", "labels": [], "entities": [{"text": "DDI corpus", "start_pos": 30, "end_pos": 40, "type": "DATASET", "confidence": 0.9025253653526306}]}, {"text": "The corpus was split in order to build the datasets for the training and evaluation of the different participating systems.", "labels": [], "entities": []}, {"text": "Approximately 77% of the DDI corpus documents were randomly selected for the training dataset and the remaining was used for the test dataset.", "labels": [], "entities": [{"text": "DDI corpus documents", "start_pos": 25, "end_pos": 45, "type": "DATASET", "confidence": 0.9104286233584086}]}, {"text": "The training dataset is the same for both subtasks since it contains entity and DDI annotations.", "labels": [], "entities": []}, {"text": "The test dataset for the DrugNER task was formed by discarding documents which contained DDI annotations.", "labels": [], "entities": [{"text": "DrugNER", "start_pos": 25, "end_pos": 32, "type": "DATASET", "confidence": 0.7205626368522644}]}, {"text": "Entity annotations were removed from this dataset to be used by participants.", "labels": [], "entities": []}, {"text": "The remaining docu-ments (that is, those containing some interactions) were used to create the test dataset for the DDI task.", "labels": [], "entities": []}, {"text": "Since entity annotations are not removed from these documents, the test dataset for the DDI task can also be used as additional training data for the DrugNER task.", "labels": [], "entities": [{"text": "DrugNER", "start_pos": 150, "end_pos": 157, "type": "DATASET", "confidence": 0.8425495624542236}]}, {"text": "Table1 shows the basic statistics on the training and test datasets for the DrugNER task.", "labels": [], "entities": [{"text": "DrugNER task", "start_pos": 76, "end_pos": 88, "type": "TASK", "confidence": 0.7212745249271393}]}, {"text": "As it stated in the previous section, most successful approaches for drug name recognition have used machine learning algorithms such as CRFs trained with linguistic features (tokens, lemmas or POS tags, among others) and semantic features from domain resources such as ontologies or dictionaries.", "labels": [], "entities": [{"text": "drug name recognition", "start_pos": 69, "end_pos": 90, "type": "TASK", "confidence": 0.7143658796946207}]}, {"text": "Encouraged by the good results of the CRF-based methods, we propose a system based on CRF and also explore word embedding features provided by the Word2vec tool.", "labels": [], "entities": [{"text": "Word2vec", "start_pos": 147, "end_pos": 155, "type": "DATASET", "confidence": 0.9330487847328186}]}, {"text": "In particular, we used a python binding 8 to CRFsuite.", "labels": [], "entities": [{"text": "CRFsuite", "start_pos": 45, "end_pos": 53, "type": "DATASET", "confidence": 0.8765987157821655}]}, {"text": "CRF performs the NER task as a classification task on each token, determining whether it is an entity or not.", "labels": [], "entities": [{"text": "CRF", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.8609658479690552}, {"text": "NER task", "start_pos": 17, "end_pos": 25, "type": "TASK", "confidence": 0.8680820465087891}]}, {"text": "To represent the class of each token, we used the BIO tagging scheme.", "labels": [], "entities": [{"text": "BIO tagging", "start_pos": 50, "end_pos": 61, "type": "TASK", "confidence": 0.6069646030664444}]}, {"text": "According to this scheme, each token is tagged as either beginning entity token (B), inside entity token (I) or outside token (O).", "labels": [], "entities": []}, {"text": "For the detection subtask (exact criterion), we only considered three classes: B-ENTITY, I-ENTITY and O. However, since we had to classify four different types (drug, brand, group and drug-n), we used nine different classes for the classification task.", "labels": [], "entities": [{"text": "I-ENTITY", "start_pos": 89, "end_pos": 97, "type": "METRIC", "confidence": 0.9730721712112427}, {"text": "O.", "start_pos": 102, "end_pos": 104, "type": "METRIC", "confidence": 0.9619781374931335}]}, {"text": "As a first stage, we developed a baseline system using a CRF algorithm in which each token is represented with the following features: \u2022 The context window of three tokens to its right and to its left in the sentence.", "labels": [], "entities": []}, {"text": "The context window also includes the current token.", "labels": [], "entities": []}, {"text": "\u2022 POS tags and lemmas in the context window are also considered.", "labels": [], "entities": []}, {"text": "\u2022 An orthography feature which can take the following values: upperInitial (the token begins with an uppercase letter and the rest are lowercase), allCaps (all its letters are uppercase), lowerCase (all its letters are lowercase) and mixedCaps (the token contains any mixture of upper and lowercase letters).", "labels": [], "entities": []}, {"text": "8 http://python-crfsuite.readthedocs.org/en/latest/ \u2022 A feature representing the type of token: word, number, symbol or punctuation.", "labels": [], "entities": []}, {"text": "As one of our goals is to study the contribution of DINTO in the task, in a second stage, we also considered a binary feature that indicated whether the current token was found in the DINTO ontology.", "labels": [], "entities": []}, {"text": "shows a pipeline of GATE components used to process the texts and to obtain the feature set used to train the CRF model.", "labels": [], "entities": []}, {"text": "There are five main processing modules: sentence splitter, tokenizer, POS tagger, morphological analyzer and the Gate onto root gazetteer, which links text to the DINTO ontology.", "labels": [], "entities": [{"text": "sentence splitter", "start_pos": 40, "end_pos": 57, "type": "TASK", "confidence": 0.7581070065498352}, {"text": "POS tagger", "start_pos": 70, "end_pos": 80, "type": "TASK", "confidence": 0.6892421841621399}]}, {"text": "The ontology is processed to produce a flexible gazetteer taking into account alternative morphological forms of the instances of the ontology.", "labels": [], "entities": []}, {"text": "The main hypothesis of this work is that the incorporating of word embeddings as features into a CRF model could help to recognize unseen or very rare drug mentions in the training set.", "labels": [], "entities": []}, {"text": "Thus, we train word embeddings using the Word2vec tool.", "labels": [], "entities": [{"text": "Word2vec", "start_pos": 41, "end_pos": 49, "type": "DATASET", "confidence": 0.9392442107200623}]}, {"text": "Word2vec only requires a large corpus of sentences as input dataset in order to generate word vectors by training a NN language model.", "labels": [], "entities": [{"text": "Word2vec", "start_pos": 0, "end_pos": 8, "type": "DATASET", "confidence": 0.9216996431350708}]}, {"text": "The NN model is able to learn from the different contexts in which a word appears and then to compute its representation as a vector.", "labels": [], "entities": []}, {"text": "In this study, Word2Vec tool was trained on two different corpora.", "labels": [], "entities": []}, {"text": "As first option, we used the latest wikipedia dump , which contains more than 3 billion words.", "labels": [], "entities": []}, {"text": "Then, we used the Word2Vec model trained on Wikipedia to obtain the word vectors for all tokens in the DDI corpus.", "labels": [], "entities": [{"text": "Word2Vec", "start_pos": 18, "end_pos": 26, "type": "DATASET", "confidence": 0.9203861355781555}, {"text": "DDI corpus", "start_pos": 103, "end_pos": 113, "type": "DATASET", "confidence": 0.9030875563621521}]}, {"text": "Based on distributional hypothesis, similar words will have similar vectors because they occur in similar contexts.", "labels": [], "entities": []}, {"text": "The word vector for the current token was considered as anew feature into an our CRF system.", "labels": [], "entities": []}, {"text": "We tried with different dimensions of vectors (50, 100 and 200) (see).", "labels": [], "entities": []}, {"text": "It should be noted that these word representations could be very valuable input, not only for named entity recognition, but also in many other NLP tasks (POS tagging, word name disambiguation, lexical simplification, etc).", "labels": [], "entities": [{"text": "named entity recognition", "start_pos": 94, "end_pos": 118, "type": "TASK", "confidence": 0.6311362584431967}, {"text": "POS tagging", "start_pos": 154, "end_pos": 165, "type": "TASK", "confidence": 0.8491563200950623}, {"text": "word name disambiguation", "start_pos": 167, "end_pos": 191, "type": "TASK", "confidence": 0.6679398119449615}]}, {"text": "Another important advantage of the Word2vec tool is that contains a utility to compute word clusters using a k-means clustering algorithm.", "labels": [], "entities": []}, {"text": "Thus, we also used word cluster as anew feature to represent the current token in our CRF-based system.: Statistics on the training and test dataset for the DrugNER task.", "labels": [], "entities": []}, {"text": "Word clusters represent words at a higher level abstraction that may help to recognize even those drug mentions that are not observed in the training set.", "labels": [], "entities": []}, {"text": "We performed experiments for different values of kin the k-means (50, 150 and 500).", "labels": [], "entities": []}, {"text": "All experiments are summarized in. shows the results for the different settings studied for the detection subtask (exact criterion) and for the classification subtask (strict criterion).", "labels": [], "entities": []}, {"text": "The scores correspond to the micro-average values, which were calculated with regarding all classes (B-and I-) of each corresponding subtask.", "labels": [], "entities": [{"text": "B-and I-)", "start_pos": 101, "end_pos": 110, "type": "METRIC", "confidence": 0.9214625954627991}]}, {"text": "The following subsections present and discuss the results for each dataset: DDI-DrugBank and DDI-MedLine.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Statistics on the training and test dataset for the DrugNER task.", "labels": [], "entities": [{"text": "DrugNER task", "start_pos": 62, "end_pos": 74, "type": "TASK", "confidence": 0.8205677270889282}]}]}