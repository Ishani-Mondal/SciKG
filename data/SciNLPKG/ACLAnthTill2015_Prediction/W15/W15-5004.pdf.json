{"title": [], "abstractContent": [{"text": "Translation systems of our NICT team at the 2nd Workshop on Asian Translation (WAT 2015) are described in this paper.", "labels": [], "entities": [{"text": "Translation", "start_pos": 0, "end_pos": 11, "type": "TASK", "confidence": 0.9420652985572815}, {"text": "NICT team at the 2nd Workshop on Asian Translation (WAT 2015)", "start_pos": 27, "end_pos": 88, "type": "TASK", "confidence": 0.7910673801715558}]}, {"text": "We participated in two translation tasks: Japanese-to-English (JE) and Korean-to-Japanese (KJ).", "labels": [], "entities": [{"text": "translation tasks", "start_pos": 23, "end_pos": 40, "type": "TASK", "confidence": 0.8844403624534607}]}, {"text": "A baseline phrased-based (PB) statistical machine translation (SMT) system in Moses was used.", "labels": [], "entities": [{"text": "phrased-based (PB) statistical machine translation (SMT)", "start_pos": 11, "end_pos": 67, "type": "TASK", "confidence": 0.6941852539777755}]}, {"text": "On JE translation , two pre-reordering approaches were applied: a simple reverse preordering and a dependency-based approach.", "labels": [], "entities": [{"text": "JE translation", "start_pos": 3, "end_pos": 17, "type": "TASK", "confidence": 0.9031307995319366}]}, {"text": "On KJ translation, the processing was purely conducted on character-level.", "labels": [], "entities": [{"text": "KJ translation", "start_pos": 3, "end_pos": 17, "type": "TASK", "confidence": 0.8081522285938263}]}, {"text": "Evaluation results show that even simple approaches can improve JE and KJ PB SMT significantly.", "labels": [], "entities": [{"text": "JE", "start_pos": 64, "end_pos": 66, "type": "TASK", "confidence": 0.8576968312263489}, {"text": "KJ PB SMT", "start_pos": 71, "end_pos": 80, "type": "TASK", "confidence": 0.5718689560890198}]}, {"text": "These techniques can be easily applied in practice because of the simplicity.", "labels": [], "entities": []}], "introductionContent": [{"text": "Statistical machine translation (SMT) techniques have been well developed and widely applied in practice.", "labels": [], "entities": [{"text": "Statistical machine translation (SMT)", "start_pos": 0, "end_pos": 37, "type": "TASK", "confidence": 0.8485134243965149}]}, {"text": "Linguistic knowledge-free SMT frameworks, such as phrase-based (PB) SMT ( and hierarchical phrase-based SMT (HIERO), handle many translation tasks efficiently as long as sufficient training data prepared.", "labels": [], "entities": [{"text": "Linguistic knowledge-free SMT", "start_pos": 0, "end_pos": 29, "type": "TASK", "confidence": 0.44420817494392395}, {"text": "phrase-based (PB) SMT", "start_pos": 50, "end_pos": 71, "type": "TASK", "confidence": 0.562378978729248}, {"text": "phrase-based SMT", "start_pos": 91, "end_pos": 107, "type": "TASK", "confidence": 0.5735151618719101}]}, {"text": "Further, sophisticated syntacticallydriven approaches give better performance than PB SMT and HIERO on difficult translation tasks.", "labels": [], "entities": [{"text": "PB SMT", "start_pos": 83, "end_pos": 89, "type": "TASK", "confidence": 0.6681848168373108}]}, {"text": "At the 2nd Workshop on Asian Translation (WAT 2015) (, our intention is to test the efficiency of several simple techniques for Japanese-to-English (JE) and Korean-to-Japanese (KJ) translation, specifically, pre-reordering approaches for JE translation and character-based processing for KJ translation.", "labels": [], "entities": [{"text": "Asian Translation (WAT 2015)", "start_pos": 23, "end_pos": 51, "type": "TASK", "confidence": 0.8322353859742483}, {"text": "Korean-to-Japanese (KJ) translation", "start_pos": 157, "end_pos": 192, "type": "TASK", "confidence": 0.6796600103378296}, {"text": "JE translation", "start_pos": 238, "end_pos": 252, "type": "TASK", "confidence": 0.9574008882045746}, {"text": "KJ translation", "start_pos": 288, "end_pos": 302, "type": "TASK", "confidence": 0.7956621646881104}]}, {"text": "On JE translation, we found the simple reverse preordering approach proposed by performed as well as a welldesigned dependency-based approach, in improving a PB SMT baseline.", "labels": [], "entities": [{"text": "JE translation", "start_pos": 3, "end_pos": 17, "type": "TASK", "confidence": 0.8450442850589752}, {"text": "PB SMT", "start_pos": 158, "end_pos": 164, "type": "TASK", "confidence": 0.49725259840488434}]}, {"text": "Considering the simplicity of the reverse preordering, we think the approach should be used more widely for JE translation.", "labels": [], "entities": [{"text": "JE translation", "start_pos": 108, "end_pos": 122, "type": "TASK", "confidence": 0.9695754051208496}]}, {"text": "On KJ translation, we found even a pure character-based approach outperformed the organizer's baseline a lot, due to the similarity of the two languages on their vocabularies and syntaxes.", "labels": [], "entities": [{"text": "KJ translation", "start_pos": 3, "end_pos": 17, "type": "TASK", "confidence": 0.8010520040988922}]}, {"text": "We give descriptions of the approaches in the following sections.", "labels": [], "entities": []}], "datasetContent": [{"text": "We used the PB SMT system in Moses 12 () for JE and KJ translation tasks.", "labels": [], "entities": [{"text": "PB SMT", "start_pos": 12, "end_pos": 18, "type": "TASK", "confidence": 0.5031269192695618}, {"text": "JE and KJ translation tasks", "start_pos": 45, "end_pos": 72, "type": "TASK", "confidence": 0.6916154801845551}]}, {"text": "Basically, we used identical settings as the organizer used in the baseline.", "labels": [], "entities": []}, {"text": "However, there were several differences as follows.", "labels": [], "entities": []}, {"text": "\u2022 We used SRILM 13) for lan-4 otherwise the reordering will become excessive.", "labels": [], "entities": [{"text": "SRILM 13", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.812566339969635}]}, {"text": "i.e., the ordinary comma.", "labels": [], "entities": []}, {"text": "6 \"fullwidth comma\", the Chinese comma.", "labels": [], "entities": []}, {"text": "7 \"ideographic comma\", the Japanese t\u00af oten.", "labels": [], "entities": []}, {"text": "8 \"ideographic full stop\", the Japanese kuten.", "labels": [], "entities": []}, {"text": "Because the DEP-REO is totally based on the IPA system, we also used the system for REV-REO.", "labels": [], "entities": [{"text": "DEP-REO", "start_pos": 12, "end_pos": 19, "type": "DATASET", "confidence": 0.7645898461341858}]}, {"text": "Actually 100% of the surface form wa were tagged as joshi, kakarijoshi by MeCab in our experiments.", "labels": [], "entities": [{"text": "MeCab", "start_pos": 74, "end_pos": 79, "type": "DATASET", "confidence": 0.9773081541061401}]}, {"text": "We only introduce the minimum rewriting to replace the \"|\", \"\" to full-width characters for Moses' decoder.", "labels": [], "entities": []}, {"text": "The spaces mainly appeared on the Korean side due to its orthography.", "labels": [], "entities": []}, {"text": "Those occasional spaces on the Japanese side were also replaced with tags.", "labels": [], "entities": []}, {"text": "guage model training (interpolated modified Kneser-Ney discounting; 5-gram on English for JE translation and 9-gram on Japanese for KJ translation).", "labels": [], "entities": [{"text": "JE translation", "start_pos": 90, "end_pos": 104, "type": "TASK", "confidence": 0.8267102241516113}, {"text": "KJ translation", "start_pos": 132, "end_pos": 146, "type": "TASK", "confidence": 0.7790052592754364}]}, {"text": "\u2022 We used MeCab (IPA) and CaboCha to process Japanese sentences in JE translation.", "labels": [], "entities": [{"text": "JE translation", "start_pos": 67, "end_pos": 81, "type": "TASK", "confidence": 0.6636996418237686}]}, {"text": "\u2022 We used no tools for Korean and Japanese morphological analysis in KJ translation, instead, the max-phrase-length were set to 9 in translation model training.", "labels": [], "entities": [{"text": "Korean and Japanese morphological analysis", "start_pos": 23, "end_pos": 65, "type": "TASK", "confidence": 0.5750115275382995}, {"text": "KJ translation", "start_pos": 69, "end_pos": 83, "type": "TASK", "confidence": 0.831959068775177}]}, {"text": "We selected the optimal distortion limit (DL) in PB SMT decoding by indoor experiments and used the selected setting in the final submissions.", "labels": [], "entities": [{"text": "distortion limit (DL)", "start_pos": 24, "end_pos": 45, "type": "METRIC", "confidence": 0.9447409510612488}, {"text": "PB SMT decoding", "start_pos": 49, "end_pos": 64, "type": "TASK", "confidence": 0.6974997520446777}]}, {"text": "shows the experimental results of DEP-REO and REV-REO on JE devtest set.", "labels": [], "entities": [{"text": "DEP-REO", "start_pos": 34, "end_pos": 41, "type": "METRIC", "confidence": 0.4886997938156128}, {"text": "REV-REO", "start_pos": 46, "end_pos": 53, "type": "METRIC", "confidence": 0.9570181965827942}, {"text": "JE devtest set", "start_pos": 57, "end_pos": 71, "type": "DATASET", "confidence": 0.8997640808423361}]}, {"text": "The excellent performance of REV-REO is impressive.", "labels": [], "entities": [{"text": "REV-REO", "start_pos": 29, "end_pos": 36, "type": "METRIC", "confidence": 0.4542248547077179}]}, {"text": "However, REV-REO needs a proper DL to reach its best performance, while DEP-REO has a more   stable performance across different DLs.", "labels": [], "entities": []}, {"text": "The phenomenon is in agree to. shows the experimental results on KJ translation results.", "labels": [], "entities": [{"text": "KJ translation", "start_pos": 65, "end_pos": 79, "type": "TASK", "confidence": 0.80978062748909}]}, {"text": "We tested different DLs of 0, 3, and 6 with the lexicalized orientation reordering model (+Lex.-Reo.).", "labels": [], "entities": []}, {"text": "The performance has only quite slight changes under different DLs.", "labels": [], "entities": []}, {"text": "We also tested the monotone translation (DL = 0) without reordering model (\u2212Lex.-Reo.).", "labels": [], "entities": [{"text": "DL", "start_pos": 41, "end_pos": 43, "type": "METRIC", "confidence": 0.9783993363380432}]}, {"text": "The change on performance is still insignificant.", "labels": [], "entities": []}, {"text": "So a pure monotone translation is enough for KJ and a reordering model helps little.", "labels": [], "entities": []}, {"text": "The phenomenon is in agree to.", "labels": [], "entities": []}, {"text": "We have observed there are many brackets in the data of KJ translation task.", "labels": [], "entities": [{"text": "KJ translation task", "start_pos": 56, "end_pos": 75, "type": "TASK", "confidence": 0.8812262415885925}]}, {"text": "The translations of brackets are not consistent in training data and PB SMT cannot handle bracket pairs well in decoding.", "labels": [], "entities": [{"text": "PB SMT", "start_pos": 69, "end_pos": 75, "type": "TASK", "confidence": 0.6811265647411346}]}, {"text": "We used a simple post-processing for bracket balancing according to the following steps.", "labels": [], "entities": [{"text": "bracket balancing", "start_pos": 37, "end_pos": 54, "type": "TASK", "confidence": 0.9207772016525269}]}, {"text": "1. Getting 1, 000-best list for each output 15 ; 2.", "labels": [], "entities": []}, {"text": "Selecting the m-th candidate, where m is min(arg min n |#L n \u2212#R n |); #L n and #R n are counts of \"(\" and \")\" in the n-th candidate; 3.", "labels": [], "entities": []}, {"text": "Inserting untranslated source-side \")\" to the selected candidate after the translated parts of its preceding character , when (a) its paired \"(\" on source side is translated to a \"(\" on target side; (b) it has no paired \"(\" on source side but follows numbers / alphabets.", "labels": [], "entities": []}, {"text": "The described brackets balancing brought again about +0.2 BLEU scores on devtest set, which is larger than the effect of DL and reordering models.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 58, "end_pos": 62, "type": "METRIC", "confidence": 0.9988476037979126}]}, {"text": "We consider specific post-processing will improve KJ translation more.", "labels": [], "entities": [{"text": "KJ translation", "start_pos": 50, "end_pos": 64, "type": "TASK", "confidence": 0.9698864817619324}]}, {"text": "The evaluation results of our submission are listed in.", "labels": [], "entities": []}, {"text": "Our local evaluation on automatic measures had slight but not significant differences compared with the organizer's in cases.", "labels": [], "entities": []}, {"text": "On JE translation, our baseline was a little lower than the organizer's baseline, as the experimental settings were not totally identical to the organizer's ones, we think the difference is acceptable.", "labels": [], "entities": [{"text": "JE translation", "start_pos": 3, "end_pos": 17, "type": "TASK", "confidence": 0.5458663403987885}]}, {"text": "Both REV-REO and DEP-REO improved the baseline (ours) approximately one point on BLEU score, but REV-REO gave a larger improvement on RIBES.", "labels": [], "entities": [{"text": "REV-REO", "start_pos": 5, "end_pos": 12, "type": "METRIC", "confidence": 0.9891014695167542}, {"text": "DEP-REO", "start_pos": 17, "end_pos": 24, "type": "METRIC", "confidence": 0.7999213337898254}, {"text": "BLEU score", "start_pos": 81, "end_pos": 91, "type": "METRIC", "confidence": 0.9781156182289124}, {"text": "REV-REO", "start_pos": 97, "end_pos": 104, "type": "METRIC", "confidence": 0.8821962475776672}, {"text": "RIBES", "start_pos": 134, "end_pos": 139, "type": "METRIC", "confidence": 0.48352035880088806}]}, {"text": "On KJ translation, the listed scores are all based on the MeCab's analysis.", "labels": [], "entities": [{"text": "KJ translation", "start_pos": 3, "end_pos": 17, "type": "DATASET", "confidence": 0.7959547936916351}, {"text": "MeCab's analysis", "start_pos": 58, "end_pos": 74, "type": "DATASET", "confidence": 0.9516468445460001}]}, {"text": "Our baseline, i.e., a character-based one, outperformed the organizer's baseline more than one BLEU score and the bracket balancing still gave a further improvement around +0.2 BLEU scores.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 95, "end_pos": 99, "type": "METRIC", "confidence": 0.9981347322463989}, {"text": "BLEU", "start_pos": 177, "end_pos": 181, "type": "METRIC", "confidence": 0.971744179725647}]}, {"text": "As to the human evaluations, our approaches still have stable improvement.", "labels": [], "entities": []}, {"text": "On JE translation, the DEP-REO has a more obvious improvement than REV-REO, although the BLEU scores of the two approaches are nearly the same.", "labels": [], "entities": [{"text": "JE translation", "start_pos": 3, "end_pos": 17, "type": "TASK", "confidence": 0.8771590292453766}, {"text": "DEP-REO", "start_pos": 23, "end_pos": 30, "type": "METRIC", "confidence": 0.8232608437538147}, {"text": "REV-REO", "start_pos": 67, "end_pos": 74, "type": "METRIC", "confidence": 0.9652532935142517}, {"text": "BLEU", "start_pos": 89, "end_pos": 93, "type": "METRIC", "confidence": 0.9994271993637085}]}, {"text": "We consider the using of specific syntactic information in DEP-REO brings benefits inhuman evaluation.", "labels": [], "entities": [{"text": "DEP-REO", "start_pos": 59, "end_pos": 66, "type": "DATASET", "confidence": 0.7494097948074341}]}, {"text": "On KJ translation, the automatic and human evaluations have consistent results, that our character-based baseline performs better than organizer's baseline and post-processing gives further improvement.", "labels": [], "entities": [{"text": "KJ translation", "start_pos": 3, "end_pos": 17, "type": "TASK", "confidence": 0.8528141379356384}]}], "tableCaptions": [{"text": " Table 1: Devtest set BLEU score and RIBES on  JE translation.", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 22, "end_pos": 32, "type": "METRIC", "confidence": 0.9741236865520477}, {"text": "RIBES", "start_pos": 37, "end_pos": 42, "type": "METRIC", "confidence": 0.9975529313087463}, {"text": "JE translation", "start_pos": 47, "end_pos": 61, "type": "TASK", "confidence": 0.5533363521099091}]}, {"text": " Table 2: Devtest set BLEU score and RIBES on  KJ translation (morpheme level, by MeCab).", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 22, "end_pos": 32, "type": "METRIC", "confidence": 0.9818823039531708}, {"text": "RIBES", "start_pos": 37, "end_pos": 42, "type": "METRIC", "confidence": 0.9978492259979248}, {"text": "KJ translation", "start_pos": 47, "end_pos": 61, "type": "TASK", "confidence": 0.594247579574585}]}, {"text": " Table 3: Evaluation of our submission on JE translation compared with the organizer's PB SMT baseline.", "labels": [], "entities": [{"text": "JE translation", "start_pos": 42, "end_pos": 56, "type": "TASK", "confidence": 0.8921918570995331}, {"text": "PB SMT baseline", "start_pos": 87, "end_pos": 102, "type": "DATASET", "confidence": 0.6304945747057596}]}, {"text": " Table 4: Evaluation of our submission on KJ translation compared with the organizer's PB SMT baseline.", "labels": [], "entities": [{"text": "KJ translation", "start_pos": 42, "end_pos": 56, "type": "TASK", "confidence": 0.7856819331645966}, {"text": "PB SMT baseline", "start_pos": 87, "end_pos": 102, "type": "DATASET", "confidence": 0.6345063149929047}]}]}