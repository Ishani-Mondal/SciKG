{"title": [{"text": "From Argumentation Mining to Stance Classification", "labels": [], "entities": [{"text": "Stance Classification", "start_pos": 29, "end_pos": 50, "type": "TASK", "confidence": 0.9612241089344025}]}], "abstractContent": [{"text": "Argumentation mining and stance classification were recently introduced as interesting tasks in text mining.", "labels": [], "entities": [{"text": "Argumentation mining", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.8637273013591766}, {"text": "stance classification", "start_pos": 25, "end_pos": 46, "type": "TASK", "confidence": 0.9603750109672546}, {"text": "text mining", "start_pos": 96, "end_pos": 107, "type": "TASK", "confidence": 0.8659135103225708}]}, {"text": "In this paper, a novel framework for argument tagging based on topic modeling is proposed.", "labels": [], "entities": [{"text": "argument tagging", "start_pos": 37, "end_pos": 53, "type": "TASK", "confidence": 0.7776132822036743}]}, {"text": "Unlike other machine learning approaches for argument tagging which often require large set of labeled data, the proposed model is minimally supervised and merely a one-to-one mapping between the pre-defined argument set and the extracted topics is required.", "labels": [], "entities": [{"text": "argument tagging", "start_pos": 45, "end_pos": 61, "type": "TASK", "confidence": 0.7632840573787689}]}, {"text": "These extracted arguments are subsequently exploited for stance classification.", "labels": [], "entities": [{"text": "stance classification", "start_pos": 57, "end_pos": 78, "type": "TASK", "confidence": 0.9831264019012451}]}, {"text": "Additionally, a manually-annotated corpus for stance classification and argument tagging of online news comments is introduced and made available.", "labels": [], "entities": [{"text": "stance classification", "start_pos": 46, "end_pos": 67, "type": "TASK", "confidence": 0.9705944955348969}, {"text": "argument tagging of online news comments", "start_pos": 72, "end_pos": 112, "type": "TASK", "confidence": 0.8522230883439382}]}, {"text": "Experiments on our collected corpus demonstrate the benefits of using topic-modeling for argument tagging.", "labels": [], "entities": [{"text": "argument tagging", "start_pos": 89, "end_pos": 105, "type": "TASK", "confidence": 0.7600316405296326}]}, {"text": "We show that using Non-Negative Matrix Factorization instead of Latent Dirich-let Allocation achieves better results for argument classification, close to the results of a supervised classifier.", "labels": [], "entities": [{"text": "argument classification", "start_pos": 121, "end_pos": 144, "type": "TASK", "confidence": 0.8017464280128479}]}, {"text": "Furthermore, the statistical model that leverages automatically-extracted arguments as features for stance classification shows promising results.", "labels": [], "entities": [{"text": "stance classification", "start_pos": 100, "end_pos": 121, "type": "TASK", "confidence": 0.96993488073349}]}], "introductionContent": [{"text": "In the past, people were only the consumers of information on the web.", "labels": [], "entities": []}, {"text": "With the advent of Web 2.0, new tools for producing User Generated Content (UGC) were provided.", "labels": [], "entities": [{"text": "User Generated Content (UGC)", "start_pos": 52, "end_pos": 80, "type": "TASK", "confidence": 0.5643798758586248}]}, {"text": "Consequently, huge amounts of text data is generate everyday on the web.", "labels": [], "entities": []}, {"text": "As the volume of this unstructured data increases, the request for automatically processing UGC grows significantly.", "labels": [], "entities": []}, {"text": "Moreover, this new source of information and opinions contains valuable feedback about products, services, policies, and news and can play an important role in decision making for marketers, politicians, policy makers and even for ordinary people.", "labels": [], "entities": []}, {"text": "So far, there has been a great effort toward subjectivity analysis of sentiment and opinion mining of reviews on concrete entities such as product or movies (), (,); however, this line of research does not fit online discussions opinion mining where comments not only contain the sentiment/stance of the commenter toward the target, but also convey personal beliefs about what is true or what action should betaken.", "labels": [], "entities": [{"text": "opinion mining of reviews on concrete entities such as product or movies", "start_pos": 84, "end_pos": 156, "type": "TASK", "confidence": 0.8367745379606882}]}, {"text": "This kind of subjectivity is called argumentation.", "labels": [], "entities": []}, {"text": "Argumentation analysis is more focused on the reason for author's overall position.", "labels": [], "entities": []}, {"text": "Stance has been defined as the overall position toward an idea, objector proposition.", "labels": [], "entities": []}, {"text": "There has been growing interest instance classification particularly for online debates (,.", "labels": [], "entities": []}, {"text": "To the best of our knowledge, our paper is the first work for stance classification of the news comments considering particular news as target to investigate the overall position toward it.", "labels": [], "entities": [{"text": "stance classification", "start_pos": 62, "end_pos": 83, "type": "TASK", "confidence": 0.937418669462204}]}, {"text": "Argument tagging was first introduced as a task in) in which the arguments were identified from a domain-dependent predefined list of arguments.", "labels": [], "entities": [{"text": "Argument tagging", "start_pos": 0, "end_pos": 16, "type": "TASK", "confidence": 0.887557864189148}]}, {"text": "An argument tag is a controversial aspect in the domain that is abstracted by a representative phrase/sentence (.", "labels": [], "entities": []}, {"text": "In our paper, anew framework for argument tag-ging at document-level based on topic modeling, mainly Non-Negative Matrix Factorization, is proposed.", "labels": [], "entities": []}, {"text": "The main advantage of this framework is that it is minimally supervised and no labeled data is required.", "labels": [], "entities": []}, {"text": "The correlation between stance labels and argument tags has been addressed in different studies)).", "labels": [], "entities": []}, {"text": "In our research, a statistical model for stance classification based on the extracted arguments is suggested, while in previous research stance labels were exploited for argument tagging.", "labels": [], "entities": [{"text": "stance classification", "start_pos": 41, "end_pos": 62, "type": "TASK", "confidence": 0.9507251083850861}, {"text": "argument tagging", "start_pos": 170, "end_pos": 186, "type": "TASK", "confidence": 0.7339217662811279}]}, {"text": "Nowadays, several popular news websites like CNN and BBC allow their readers to express their opinion by commenting; these kinds of commentspheres can be considered as type of social media.", "labels": [], "entities": []}, {"text": "Consequently, visualizing and summarizing the content of these data can play a significant role in public opinion mining and decision making.", "labels": [], "entities": [{"text": "public opinion mining", "start_pos": 99, "end_pos": 120, "type": "TASK", "confidence": 0.6330162982145945}, {"text": "decision making", "start_pos": 125, "end_pos": 140, "type": "TASK", "confidence": 0.8517166376113892}]}, {"text": "Considering the huge volume of the news comments that are generated everyday, manual analysis of these data maybe unfeasible.", "labels": [], "entities": []}, {"text": "In our research, a corpus of news comments is collected and annotated and is made available to be deployed as a benchmark in this field 1 . Hence, it provides opportunities to further investigate automatic analysis of such types of UGC.", "labels": [], "entities": []}], "datasetContent": [{"text": "Important results of health-related studies, reported in the scientific medical journals, are often popularized and broadcasted by media.", "labels": [], "entities": []}, {"text": "Such media stories are often followed by online discussions in the social media.", "labels": [], "entities": []}, {"text": "For our research, we chose to focus on a controversial study published in the British Medical Journal (BMJ) in February 2014, about breast cancer screening).", "labels": [], "entities": [{"text": "British Medical Journal (BMJ) in February 2014", "start_pos": 78, "end_pos": 124, "type": "DATASET", "confidence": 0.9610918627844917}, {"text": "breast cancer screening", "start_pos": 132, "end_pos": 155, "type": "TASK", "confidence": 0.5968326727549235}]}, {"text": "Subsequently, a set of news articles that broadcasted or discussed about this study was selected and their corresponding comments were collected.", "labels": [], "entities": []}, {"text": "There are two Yahoo news articles 2 , three CNN 3 and three New York Times articles 4 . Comments were harvested from news websites or their corresponding social media.", "labels": [], "entities": []}, {"text": "CNN commentsphere is provided by DISQUS 5 . Only root comments were kept and the rest (reply to the other comments) was discarded since they mostly contain user interactions and their opinion targets are not the study in which we are interested in for this research.", "labels": [], "entities": [{"text": "CNN commentsphere", "start_pos": 0, "end_pos": 17, "type": "DATASET", "confidence": 0.9374864399433136}, {"text": "DISQUS 5", "start_pos": 33, "end_pos": 41, "type": "DATASET", "confidence": 0.8866621553897858}]}, {"text": "A total number of 1063 posts were collected from all the sources and cleaned by removing HTML tags and links.", "labels": [], "entities": []}, {"text": "In this section, first, the experimental setting is reviewed and the evaluation process and metrics are described.", "labels": [], "entities": []}, {"text": "Subsequently, the results of applying our proposed framework on our corpus are presented for both argument tagging and stance classification.", "labels": [], "entities": [{"text": "argument tagging", "start_pos": 98, "end_pos": 114, "type": "TASK", "confidence": 0.8450123369693756}, {"text": "stance classification", "start_pos": 119, "end_pos": 140, "type": "TASK", "confidence": 0.9019130766391754}]}, {"text": "After removing those arguments which did not have sufficient representatives, eight argument tags remained.", "labels": [], "entities": []}, {"text": "We treated argument tagging as a multiclass multi-label classification problem.", "labels": [], "entities": [{"text": "argument tagging", "start_pos": 11, "end_pos": 27, "type": "TASK", "confidence": 0.7859538197517395}, {"text": "multiclass multi-label classification", "start_pos": 33, "end_pos": 70, "type": "TASK", "confidence": 0.6455825765927633}]}, {"text": "Each post can have one or more of those eight labels or none of them.", "labels": [], "entities": []}, {"text": "Each post was represented by using the Term Frequency-Inverse Document Frequency (TF-IDF) weighting scheme over its bag of words.", "labels": [], "entities": []}, {"text": "Standard English stopwords were removed.", "labels": [], "entities": []}, {"text": "Additionally, we removed corpus specific stopwords by discarding   terms that have been appeared in more than twenty percent of the documents.", "labels": [], "entities": []}, {"text": "For evaluation, separate test and training data were deployed.", "labels": [], "entities": []}, {"text": "Data was randomly divided into test and training sets.", "labels": [], "entities": []}, {"text": "Seventy percent of the data was used for training and the rest was used for testing.", "labels": [], "entities": []}, {"text": "As mentioned earlier, for our proposed framework, the labels of training are not leveraged and topic models are applied on unlabeled training data.", "labels": [], "entities": []}, {"text": "Like similar researches in text classification, precision, recall and f1-score are used as evaluation metrics.", "labels": [], "entities": [{"text": "text classification", "start_pos": 27, "end_pos": 46, "type": "TASK", "confidence": 0.7927342653274536}, {"text": "precision", "start_pos": 48, "end_pos": 57, "type": "METRIC", "confidence": 0.9995741248130798}, {"text": "recall", "start_pos": 59, "end_pos": 65, "type": "METRIC", "confidence": 0.9991195797920227}, {"text": "f1-score", "start_pos": 70, "end_pos": 78, "type": "METRIC", "confidence": 0.913533091545105}]}], "tableCaptions": [{"text": " Table 2: Distribution of stance labels in the corpus", "labels": [], "entities": []}, {"text": " Table 3: Distribution of argument tags for different stance labels in our corpus", "labels": [], "entities": []}, {"text": " Table 5: Results of argument tagging on our corpus", "labels": [], "entities": [{"text": "argument tagging", "start_pos": 21, "end_pos": 37, "type": "TASK", "confidence": 0.7656172215938568}]}, {"text": " Table 6: Results of stance classification in the case of 4- classes (the strength and the overall stance)", "labels": [], "entities": [{"text": "stance classification", "start_pos": 21, "end_pos": 42, "type": "TASK", "confidence": 0.8772167265415192}]}, {"text": " Table 7: Results of stance classification in the case of 2- classes", "labels": [], "entities": [{"text": "stance classification", "start_pos": 21, "end_pos": 42, "type": "TASK", "confidence": 0.9562482535839081}]}, {"text": " Table 8: The summary of the performance of proposed  framework for each argument (the class numbers match  argument tag numbers in table 4)", "labels": [], "entities": []}]}