{"title": [{"text": "Named Entity Recognition for Arabic Social Media", "labels": [], "entities": [{"text": "Entity Recognition", "start_pos": 6, "end_pos": 24, "type": "TASK", "confidence": 0.7078801095485687}, {"text": "Arabic Social Media", "start_pos": 29, "end_pos": 48, "type": "TASK", "confidence": 0.5022240479787191}]}], "abstractContent": [{"text": "The majority of research on Arabic Named Entity Recognition (NER) addresses the the task for newswire genre, where the language used is Modern Standard Ara-bic (MSA), however, the need to study this task in social media is becoming more vital.", "labels": [], "entities": [{"text": "Arabic Named Entity Recognition (NER)", "start_pos": 28, "end_pos": 65, "type": "TASK", "confidence": 0.7147741445473262}]}, {"text": "Social media is characterized by the use of both MSA and Dialectal Ara-bic (DA), with often code switching between the two language varieties.", "labels": [], "entities": []}, {"text": "Despite some common characteristics between MSA and DA, there are significant differences between which result in poor performance when MSA targeting systems are applied for NER in DA.", "labels": [], "entities": [{"text": "NER", "start_pos": 174, "end_pos": 177, "type": "TASK", "confidence": 0.9843065738677979}]}, {"text": "Additionally , most NER systems rely primarily on gazetteers, which can be more challenging in asocial media processing context due to an inherent low coverage.", "labels": [], "entities": [{"text": "NER", "start_pos": 20, "end_pos": 23, "type": "TASK", "confidence": 0.9551234841346741}]}, {"text": "In this paper, we present a gazetteers-free NER system for Dialectal data that yields an F1 score of 72.68% which is an absolute improvement of \u2248 2 \u2212 3% over a comparable state-of-the-art gazetteer based DA-NER system.", "labels": [], "entities": [{"text": "F1 score", "start_pos": 89, "end_pos": 97, "type": "METRIC", "confidence": 0.98770871758461}]}], "introductionContent": [{"text": "Named Entity Recognition (NER) is the task of tagging names with a predefined set of named entity types (e.g. in opendomain text (.", "labels": [], "entities": [{"text": "Named Entity Recognition (NER)", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.8009965966145197}]}, {"text": "NER has been shown to improve Information Retrieval performance and Question Answering (QA) performance where ( shows that, on average, questions contain \u2248 85% Named Entities.", "labels": [], "entities": [{"text": "NER", "start_pos": 0, "end_pos": 3, "type": "TASK", "confidence": 0.7942425012588501}, {"text": "Information Retrieval", "start_pos": 30, "end_pos": 51, "type": "TASK", "confidence": 0.8116792738437653}, {"text": "Question Answering (QA)", "start_pos": 68, "end_pos": 91, "type": "TASK", "confidence": 0.6551683127880097}]}, {"text": "In the current world of ubiquitous social media presence, processing informal genre is becoming evermore crucial.", "labels": [], "entities": []}, {"text": "One of the prevalent genre in social media in need for text mining is microblog data such as Twitter.", "labels": [], "entities": [{"text": "text mining", "start_pos": 55, "end_pos": 66, "type": "TASK", "confidence": 0.8324854075908661}]}, {"text": "Twitter data is characterized by being massive.", "labels": [], "entities": [{"text": "Twitter data", "start_pos": 0, "end_pos": 12, "type": "DATASET", "confidence": 0.853145182132721}]}, {"text": "Off the shelf NER systems trained on formal genre such as newswire fail to process such data, thereby current research in information extraction has been specifically targeting this genre ().", "labels": [], "entities": [{"text": "information extraction", "start_pos": 122, "end_pos": 144, "type": "TASK", "confidence": 0.7790385186672211}]}, {"text": "This problem is quite significant in English and is evermore pronounced in lower resourced languages such as Arabic.", "labels": [], "entities": []}, {"text": "Arabic has gained more attention recently due to the increased availability of annotated datasets.", "labels": [], "entities": []}, {"text": "Arabic NER systems, as other languages, are domain dependent and mainly trained on news corpora or other well structured data that uses the Modern Standard Arabic (MSA) variety of the language ( and).", "labels": [], "entities": [{"text": "Modern Standard Arabic (MSA) variety", "start_pos": 140, "end_pos": 176, "type": "DATASET", "confidence": 0.82097818170275}]}, {"text": "Arabic, in general, poses additional challenges to Natural Language Processing (NLP) tasks, as opposed to other languages, due its rich morphology and highly inflected nature.", "labels": [], "entities": []}, {"text": "Moreover, Arabic is also one of those languages that exists in a state of diglossia where multiple forms of the language exist in the same context, the standard formal form, MSA, used informal settings (education, formal speeches, etc.) and the spoken vernaculars that differ significantly from MSA, known as Dialectal Arabic (DA) that are used pervasively in informal settings such as in social media.", "labels": [], "entities": []}, {"text": "Since MSA and DA co-exist, we note that people very often code switch between the two varieties within the same utterance which is reflected in microblog data.", "labels": [], "entities": []}, {"text": "Hence NLP systems targeting the Twitter genre needs to account for this phenomenon.", "labels": [], "entities": []}, {"text": "Compared to English NER, here are some example challenges posed for Arabic NER): \u2022 Lack of capitalization: Capitalization in Latin languages is a strong indicator of Named Entity (NE).", "labels": [], "entities": []}, {"text": "However, in Arabic, proper nouns are not capitalized, which renders the identification of NEs more complicated; \u2022 Nominal Confusability: Some words can be proper nouns, nouns, or adjectives.", "labels": [], "entities": [{"text": "identification of NEs", "start_pos": 72, "end_pos": 93, "type": "TASK", "confidence": 0.8807186881701151}]}, {"text": "For instance, jamiyolap 1 which means 'beautiful' can be a proper noun or an adjective.", "labels": [], "entities": []}, {"text": "Another example, jamAl, which means 'beauty', is a noun but can be a common noun or a proper name; \u2022 Agglutination: Since Arabic exhibits concatenative morphology, we note the pervasive presence of affixes agglutinating to proper nouns as prefixes and suffixes.", "labels": [], "entities": [{"text": "jamAl", "start_pos": 17, "end_pos": 22, "type": "METRIC", "confidence": 0.7980972528457642}, {"text": "Agglutination", "start_pos": 101, "end_pos": 114, "type": "METRIC", "confidence": 0.9809091091156006}]}, {"text": "Examples of ambiguity are: mSr, maybe miSor as in 'Egypt' or muSir as in 'insistent'; qTr maybe the name of the country 'Qatar' if vowelized/diacritized as qaTar, qaTor for 'sugar syrup', quTor for 'diameter'.", "labels": [], "entities": []}, {"text": "For a reference listing please see http://www.qamus.org/transliteration.htm since by definition such media has a ubiquitous presence of highly productive names exemplified by the usage of nick names, hence the PERSON class in social media NER will always have a coverage problem; \u2022 Applying NLP tools designed for MSA to DA results in considerably lower performance, thus the need to build resources and tools that specifically target DA ().", "labels": [], "entities": []}, {"text": "The majority of existing NER systems rely on the use of gazetteers to improve the system accuracy (, however, large external resources are correlated with higher performance cost.", "labels": [], "entities": [{"text": "NER", "start_pos": 25, "end_pos": 28, "type": "TASK", "confidence": 0.97903972864151}, {"text": "accuracy", "start_pos": 89, "end_pos": 97, "type": "METRIC", "confidence": 0.997658371925354}]}, {"text": "In this paper, we study the impact of word representation and embedding features on Arabic NER performance for Twitter and Dialectal Arabic, and demonstrate that our proposed features show comparable and superior results to other NER systems that use large gazetteers.", "labels": [], "entities": []}, {"text": "Our contributions are as follows: \u2022 Show the impact of using word representations and embedding on NER performance; \u2022 Propose a set of features that does not include the use of external resources; \u2022 Produce comparable NER performance to other systems that use large gazetteers.", "labels": [], "entities": [{"text": "NER", "start_pos": 99, "end_pos": 102, "type": "TASK", "confidence": 0.9529187679290771}]}], "datasetContent": [{"text": "We use Microblogs and Dialectal weblogs datasets for our experiments: \u2022 Twitter dataset: We use the training and test data split proposed in, where the training dataset contains 3,646 tweets which were randomly selected from tweets that were authored in the period of May 3-12, 2012.", "labels": [], "entities": [{"text": "Twitter dataset", "start_pos": 72, "end_pos": 87, "type": "DATASET", "confidence": 0.7939094603061676}]}, {"text": "The tweets were scraped from Twitter using the query lang:ar.", "labels": [], "entities": []}, {"text": "The testing data contains 1,423 tweets that were randomly selected from tweets authored between November 23, 2011 and November 27, 2011.", "labels": [], "entities": []}, {"text": "This dataset has also been used in) for testing.", "labels": [], "entities": []}, {"text": "Both datasets are annotated using the Linguistics Data Consortium ACE tagging guidelines; \u2022 Dialectal Arabic dataset (DA-EGY): The annotated data was chosen from a set of web blogs that are manually identified by LDC as Egyptian dialect and contains nearly 40k tokens.", "labels": [], "entities": [{"text": "Linguistics Data Consortium ACE tagging", "start_pos": 38, "end_pos": 77, "type": "DATASET", "confidence": 0.7948772311210632}]}, {"text": "The data was annotated by one native Arabic speaker annotator who followed the Linguistics Data Consortium guidelines for tagging.", "labels": [], "entities": []}, {"text": "We use the same 80/20 train/test 5-fold cross validation split proposed in (Zirikly and Diab, 2014) shows dataset statistics, namely number of tokens, and the named entity types: PER, LOC, and ORG.", "labels": [], "entities": [{"text": "PER", "start_pos": 179, "end_pos": 182, "type": "METRIC", "confidence": 0.9297623634338379}, {"text": "LOC", "start_pos": 184, "end_pos": 187, "type": "METRIC", "confidence": 0.7747735977172852}, {"text": "ORG", "start_pos": 193, "end_pos": 196, "type": "METRIC", "confidence": 0.9739876389503479}]}, {"text": "We choose precision (PREC), recall (REC), and harmonic F-measure (F1) metrics to evaluate the performance of our NER system over accuracy.", "labels": [], "entities": [{"text": "precision (PREC)", "start_pos": 10, "end_pos": 26, "type": "METRIC", "confidence": 0.8760083764791489}, {"text": "recall (REC)", "start_pos": 28, "end_pos": 40, "type": "METRIC", "confidence": 0.9513324201107025}, {"text": "harmonic F-measure (F1)", "start_pos": 46, "end_pos": 69, "type": "METRIC", "confidence": 0.8197219252586365}, {"text": "accuracy", "start_pos": 129, "end_pos": 137, "type": "METRIC", "confidence": 0.9977235198020935}]}, {"text": "This decision is based on the observation that the baseline accuracy is always high as the majority of the words in free text are not named entities.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 60, "end_pos": 68, "type": "METRIC", "confidence": 0.9589672088623047}]}], "tableCaptions": [{"text": " Table 3: Twitter NER Results", "labels": [], "entities": [{"text": "Twitter NER", "start_pos": 10, "end_pos": 21, "type": "DATASET", "confidence": 0.7613560557365417}]}, {"text": " Table 4: DA-EGY NER Results", "labels": [], "entities": [{"text": "DA-EGY NER", "start_pos": 10, "end_pos": 20, "type": "TASK", "confidence": 0.5463254153728485}]}]}