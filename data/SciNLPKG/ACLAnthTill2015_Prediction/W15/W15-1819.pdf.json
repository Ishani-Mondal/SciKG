{"title": [{"text": "Topic Models: Accounting Component Structure of Bigrams", "labels": [], "entities": []}], "abstractContent": [{"text": "The paper describes the results of an empirical study of integrating bigram col-locations and similarities between them and unigrams into topic models.", "labels": [], "entities": []}, {"text": "First of all, we propose a novel algorithm PLSA-SIM that is a modification of the original algorithm PLSA.", "labels": [], "entities": []}, {"text": "It incorporates bigrams and maintains relationships between uni-grams and bigrams based on their component structure.", "labels": [], "entities": []}, {"text": "Then we analyze a variety of word association measures in order to integrate top-ranked bigrams into topic models.", "labels": [], "entities": []}, {"text": "All experiments were conducted on four text collections of different domains and languages.", "labels": [], "entities": []}, {"text": "The experiments distinguish a subgroup of tested measures that produce top-ranked bigrams, which demonstrate significant improvement of topic models quality for all collections, when integrated into PLSA-SIM algorithm .", "labels": [], "entities": []}], "introductionContent": [{"text": "Topic modeling is one of the latest applications of machine learning techniques to the natural language processing.", "labels": [], "entities": [{"text": "Topic modeling", "start_pos": 0, "end_pos": 14, "type": "TASK", "confidence": 0.8489779233932495}]}, {"text": "Topic models identify which topics relate to each document and which words form each topic.", "labels": [], "entities": []}, {"text": "Each topic is defined as a multinomial distribution over terms and each document is defined as multinomial distribution over topics ().", "labels": [], "entities": []}, {"text": "Topic models have achieved noticeable success in various areas such as information retrieval), including such applications as multi-document summarization ( ), text clustering and categorization (, and other natural language processing tasks such as word sense disambiguation, machine translation ().", "labels": [], "entities": [{"text": "information retrieval", "start_pos": 71, "end_pos": 92, "type": "TASK", "confidence": 0.7827106416225433}, {"text": "multi-document summarization", "start_pos": 126, "end_pos": 154, "type": "TASK", "confidence": 0.7035296261310577}, {"text": "text clustering", "start_pos": 160, "end_pos": 175, "type": "TASK", "confidence": 0.7667263448238373}, {"text": "word sense disambiguation", "start_pos": 250, "end_pos": 275, "type": "TASK", "confidence": 0.6940447688102722}, {"text": "machine translation", "start_pos": 277, "end_pos": 296, "type": "TASK", "confidence": 0.7851718068122864}]}, {"text": "Among most well-known models are Latent Dirichlet Allocation (LDA) (, which is based on Dirichlet prior distribution, and Probabilistic Latent Semantic Analysis (PLSA)), which is not connected with any parametric prior distribution.", "labels": [], "entities": [{"text": "Probabilistic Latent Semantic Analysis (PLSA))", "start_pos": 122, "end_pos": 168, "type": "TASK", "confidence": 0.7207497443471637}]}, {"text": "One of the main drawback of the topic models is that they utilize \"bag-of-words\" model that discards word order and is based on the word independence assumption.", "labels": [], "entities": []}, {"text": "There are numerous studies, where the integration of collocations, n-grams, idioms and multi-word terms into topic models is investigated.", "labels": [], "entities": []}, {"text": "However, it often leads to a decrease in the model quality due to increasing size of a vocabulary or to a serious complication of the model.", "labels": [], "entities": []}, {"text": "The paper proposes a novel approach taking into account bigram collocations and relationship between them and unigrams in topic models (such as citizen -citizen of country -citizen of union -European citizen -state citizen; categorization -document categorization -term categorization -text categorization).", "labels": [], "entities": []}, {"text": "This allows us to create a novel method of integrating bigram collocations into topic models that does not consider bigrams being as \"black boxes\", but maintains the relationship between unigrams and bigrams based on their component structure.", "labels": [], "entities": []}, {"text": "The proposed algorithm leads to significant improvement of topic models quality measured in perplexity and topic coherence) without complications of the model.", "labels": [], "entities": []}, {"text": "All experiments were carried out using PLSA algorithm and its modifications on four corpora of different domains and languages: the English part of Europarl parallel corpus, the English part of JRC-Acquis parallel corpus, ACL Anthology Reference corpus, and Russian banking magazines.", "labels": [], "entities": [{"text": "Europarl parallel corpus", "start_pos": 148, "end_pos": 172, "type": "DATASET", "confidence": 0.9388209382692972}, {"text": "JRC-Acquis parallel corpus", "start_pos": 194, "end_pos": 220, "type": "DATASET", "confidence": 0.8853334585825602}, {"text": "ACL Anthology Reference corpus", "start_pos": 222, "end_pos": 252, "type": "DATASET", "confidence": 0.9314057379961014}, {"text": "Russian banking magazines", "start_pos": 258, "end_pos": 283, "type": "DATASET", "confidence": 0.7823781569798788}]}, {"text": "The rest of the paper is organized as follows.", "labels": [], "entities": []}, {"text": "In the section 2 we focus on related work.", "labels": [], "entities": []}, {"text": "Section 3 proposes a novel algorithm PLSA-SIM that incorporates bigrams and similarities between them and unigrams into topic models.", "labels": [], "entities": []}, {"text": "Section 4 describes the datasets used in experiments, all preprocessing steps and metrics used to evaluate the quality.", "labels": [], "entities": []}, {"text": "In the section 5 we perform an extensive analysis of a variety of measures for integrating top-ranked bigrams into topic models.", "labels": [], "entities": []}, {"text": "And in the last section we draw conclusions.", "labels": [], "entities": []}], "datasetContent": [{"text": "In our experiments we used English and Russian text collections obtained from different sources: \u2022 For the English part of our study we took three different collections: \u2022 For the Russian part of our study we took 10422 Russian articles from several economics-oriented magazines such as Auditor, RBC, Banking Magazine, etc.", "labels": [], "entities": []}, {"text": "These documents contain almost 18.5 mln. words.", "labels": [], "entities": []}, {"text": "At the preprocessing step documents were processed by morphological analyzers.", "labels": [], "entities": []}, {"text": "For the English corpus we used Stanford CoreNLP tools (http://nlp.stanford.edu/software/ corenlp.shtml), while for the Russian corpus we used our own morphological analyzer.", "labels": [], "entities": []}, {"text": "We consider only Adjectives, Nouns, Verbs and Adverbs since function words do not play significant role in forming topics.", "labels": [], "entities": []}, {"text": "Besides, we excluded words occurring less than five times per the whole text collection.", "labels": [], "entities": []}, {"text": "In addition, we extracted all bigrams in forms of Noun + Noun, Adjective + Noun and Noun + of + Noun for all English collections, and Noun + Noun in Genitive and Adjective + Noun for the Russian collection.", "labels": [], "entities": [{"text": "Russian collection", "start_pos": 187, "end_pos": 205, "type": "DATASET", "confidence": 0.8121142387390137}]}, {"text": "We consider only such bigrams since topics are mainly identified by nouns and noun groups ().", "labels": [], "entities": []}, {"text": "As for the inferred topics quality, we consider four different intrinsic measures.", "labels": [], "entities": []}, {"text": "The first measure is Perplexity since it is the standard criterion of topic models quality (: where n is the number of all considered words in the collection, Dis the set of documents in the collection, n dw is the number of occurrences of the word win the document d, p(w|d) is the probability of appearing the word win the document d.", "labels": [], "entities": [{"text": "Perplexity", "start_pos": 21, "end_pos": 31, "type": "METRIC", "confidence": 0.9866227507591248}]}, {"text": "The less the value of perplexity is the better the model predicts words win documents D.", "labels": [], "entities": []}, {"text": "Although there were numerous studies arguing that perplexity is not suited to topic model evaluation (, it is still commonly used for comparing different topic models.", "labels": [], "entities": [{"text": "topic model evaluation", "start_pos": 78, "end_pos": 100, "type": "TASK", "confidence": 0.7262405157089233}]}, {"text": "Since it is well-known that perplexity computed on the same training collection is susceptible to over-fitting and can give optimistically low values () we use the standard method of computing hold-out perplexity described in.", "labels": [], "entities": []}, {"text": "In our experiments we split the collections randomly into the training sets D, on which models are trained, and the validation sets D \ud97b\udf59 , on which hold-out perplexity is computed.", "labels": [], "entities": []}, {"text": "Another method of evaluating topic model quality is using expert opinions.", "labels": [], "entities": []}, {"text": "We provided annotators with inferred topics from the same text collections and instructed them to decide whether the topic was to some extent coherent, meaningful and interpretable.", "labels": [], "entities": []}, {"text": "The indicator of topic usefulness is the ease by which one could think of a short label to describe a topic ().", "labels": [], "entities": []}, {"text": "In the we present incoherent topic that cannot be given any label and coherent one with label given by experts.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Results of integrating top-1000 bigrams  ranked by MI into topic models", "labels": [], "entities": []}, {"text": " Table 3: Results of integrating top-1000 bigrams  ranked by TF into topic models", "labels": [], "entities": []}, {"text": " Table 4: Results of expert markup of topics", "labels": [], "entities": []}]}