{"title": [{"text": "Enhancing FreeLing Rule-Based Dependency Grammars with Subcategorization Frames", "labels": [], "entities": []}], "abstractContent": [{"text": "Despite the recent advances in parsing, significant efforts are needed to improve the current parsers performance, such as the enhancement of the argument/adjunct recognition.", "labels": [], "entities": [{"text": "parsing", "start_pos": 31, "end_pos": 38, "type": "TASK", "confidence": 0.9784168004989624}, {"text": "argument/adjunct recognition", "start_pos": 146, "end_pos": 174, "type": "TASK", "confidence": 0.6322138831019402}]}, {"text": "There is evidence that verb subcategorization frames can contribute to parser accuracy, but a number of issues remain open.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 78, "end_pos": 86, "type": "METRIC", "confidence": 0.7835431098937988}]}, {"text": "The main aim of this paper is to show how subcategorization frames acquired from a syntactically annotated corpus and organized into fine-grained classes can improve the performance of two rule-based dependency grammars.", "labels": [], "entities": []}], "introductionContent": [{"text": "Statistical parsers and rule-based parsers have advanced over recent years.", "labels": [], "entities": [{"text": "Statistical parsers", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.7109129726886749}, {"text": "rule-based parsers", "start_pos": 24, "end_pos": 42, "type": "TASK", "confidence": 0.5976749062538147}]}, {"text": "However, significant efforts are required to increase the performance of current parsers;).", "labels": [], "entities": []}, {"text": "One of the linguistic phenomena which parsers often fail to handle correctly is the argument/adjunct distinction).", "labels": [], "entities": []}, {"text": "For this reason, the main goal of this paper is to test empirically the accuracy of rule-based dependency grammars working exclusively with syntactic rules or adding subcategorization frames to the rules.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 72, "end_pos": 80, "type": "METRIC", "confidence": 0.9986072182655334}]}, {"text": "A number of studies shows that subcategorization frames can contribute to improve parser performance (.", "labels": [], "entities": []}, {"text": "Particularly, these studies are mainly concerned with the integration of subcategorization information into statistical parsers.", "labels": [], "entities": []}, {"text": "The list of studies about rule-based parsers integrating subcategorization information is also extensive).", "labels": [], "entities": []}, {"text": "However, they do not explicitly relate the improvements in parser performance to the addition of subcategorization.", "labels": [], "entities": []}, {"text": "This paper analyses in detail how subcategorization frames acquired from an annotated corpus and distributed among fine-grained classes increase accuracy in rule-based dependency grammars.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 145, "end_pos": 153, "type": "METRIC", "confidence": 0.9974930286407471}]}, {"text": "The framework used is that of the FreeLing Dependency Grammars (FDGs) for Spanish and Catalan, using enriched lexical-syntactic information about the argument structure of the verb.) is an open-source library of multilingual Natural Language Processing (NLP) tools that provide linguistic analysis for written texts.", "labels": [], "entities": []}, {"text": "The FDGs are the core of the FreeLing dependency parser, the Txala Parser ().", "labels": [], "entities": [{"text": "Txala Parser", "start_pos": 61, "end_pos": 73, "type": "DATASET", "confidence": 0.8662824630737305}]}, {"text": "The remainder of this paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 contains an overview of previous work related to this research.", "labels": [], "entities": []}, {"text": "Section 3 presents the rule-based dependency parser used and the Spanish and Catalan grammars.", "labels": [], "entities": [{"text": "dependency parser", "start_pos": 34, "end_pos": 51, "type": "TASK", "confidence": 0.6303908973932266}]}, {"text": "Section 4 describes the strategy followed initially to integrate subcategorization into the grammars and how this information has been redesigned.", "labels": [], "entities": []}, {"text": "Section 5 focuses on the evaluation and the analysis of several experiments testing versions of the grammars including or discarding subcategorization frames.", "labels": [], "entities": []}, {"text": "Finally, the main conclusions and the further research goals arisen from the results of the experiments are exposed in Section 6.", "labels": [], "entities": [{"text": "Section 6", "start_pos": 119, "end_pos": 128, "type": "DATASET", "confidence": 0.8948497772216797}]}], "datasetContent": [{"text": "An evaluation task has been carried out to test empirically how the FDGs performance changes when subcategorization information is added or subtracted.", "labels": [], "entities": []}, {"text": "Several versions of the grammars have been tested using a controlled annotated linguistic data set.", "labels": [], "entities": []}, {"text": "This evaluation specifically focuses on analysing the results of the experiments qualitatively.", "labels": [], "entities": []}, {"text": "This kind of analysis makes it possible to track the decisions that the parser has made, so that it is possible to provide an explanation about the accuracy of the FDGs running with different linguistic information.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 148, "end_pos": 156, "type": "METRIC", "confidence": 0.996039867401123}]}, {"text": "Four versions of both Spanish and Catalan grammars are tested in order to assess the differences of the performance depending on the linguistic information added.", "labels": [], "entities": []}, {"text": "A version of the FDGs running without subcategorization frames.", "labels": [], "entities": [{"text": "FDGs", "start_pos": 17, "end_pos": 21, "type": "DATASET", "confidence": 0.8980157971382141}]}, {"text": "A version of the FDGs running with the old CompLex-VS lexicon.", "labels": [], "entities": [{"text": "FDGs", "start_pos": 17, "end_pos": 21, "type": "DATASET", "confidence": 0.8197591304779053}]}, {"text": "A version of the FDGs running with the CompLex-SynF lexicon.: Comparison of the labelling tags distribution in SenSem and ParTes (%) \u2022 SynF+Cat FDG.", "labels": [], "entities": [{"text": "SynF+Cat FDG", "start_pos": 135, "end_pos": 147, "type": "DATASET", "confidence": 0.49346236884593964}]}, {"text": "A version of the FDGs running with the CompLex-Synf+Cat lexicon.", "labels": [], "entities": [{"text": "FDGs", "start_pos": 17, "end_pos": 21, "type": "DATASET", "confidence": 0.842910647392273}, {"text": "CompLex-Synf+Cat lexicon", "start_pos": 39, "end_pos": 63, "type": "DATASET", "confidence": 0.8354212939739227}]}, {"text": "Since this research is focused on the implementation of subcategorization information for argument/adjunct recognition, only the labelling rules are discussed in this paper.", "labels": [], "entities": [{"text": "argument/adjunct recognition", "start_pos": 90, "end_pos": 118, "type": "TASK", "confidence": 0.6492820307612419}]}, {"text": "However, metrics related to linking rules are also mentioned to provide a general description of the FDGs.", "labels": [], "entities": [{"text": "FDGs", "start_pos": 101, "end_pos": 105, "type": "DATASET", "confidence": 0.7891002893447876}]}, {"text": "To perform a qualitative evaluation, the ParTes test suite has been used ().", "labels": [], "entities": [{"text": "ParTes test suite", "start_pos": 41, "end_pos": 58, "type": "DATASET", "confidence": 0.8789801597595215}]}, {"text": "This resource is a multilingual hierarchical test suite of a representative and controlled set of syntactic phenomena which has been developed for evaluating the parsing performance as regards syntactic structure and word order.", "labels": [], "entities": []}, {"text": "It contains 161 syntactic phenomena in Spanish (99 referring to structure and 62 to word order) and 147 syntactic phenomena in Catalan (101 corresponding to structure phenomena and 46 to word order).", "labels": [], "entities": []}, {"text": "The current version of ParTes is distributed with an annotated data set in the CoNLL format.", "labels": [], "entities": [{"text": "CoNLL format", "start_pos": 79, "end_pos": 91, "type": "DATASET", "confidence": 0.909137487411499}]}, {"text": "Although this data set is not initially developed for evaluating the argument/adjunct recognition, the number of arguments and adjuncts contained in ParTes is proportional to the number of arguments and adjuncts of the SenSem Corpus.", "labels": [], "entities": [{"text": "argument/adjunct recognition", "start_pos": 69, "end_pos": 97, "type": "TASK", "confidence": 0.7211306691169739}, {"text": "SenSem Corpus", "start_pos": 219, "end_pos": 232, "type": "DATASET", "confidence": 0.8469960987567902}]}, {"text": "Therefore, the ParTes data set is a reduced sample of the linguistic phenomena that occur in a larger corpus, which makes ParTes an appropriate resource for this task.", "labels": [], "entities": [{"text": "ParTes data set", "start_pos": 15, "end_pos": 30, "type": "DATASET", "confidence": 0.9142043391863505}]}, {"text": "The metrics have been computed using the CoNLL-X Shared Task 2007 script (.", "labels": [], "entities": [{"text": "CoNLL-X Shared Task 2007 script", "start_pos": 41, "end_pos": 72, "type": "DATASET", "confidence": 0.8728196501731873}]}, {"text": "The output of the FDGs (system output) has been compared to the ParTes annotated data set (gold standard).", "labels": [], "entities": [{"text": "FDGs", "start_pos": 18, "end_pos": 22, "type": "METRIC", "confidence": 0.6879395842552185}, {"text": "ParTes annotated data set", "start_pos": 64, "end_pos": 89, "type": "DATASET", "confidence": 0.9043729603290558}]}, {"text": "Both quantitative and qualitative analysis detailed in Section 5.4 pay special attention to the metric LAS2, which informs about the number of heads with the correct syntactic function tag.", "labels": [], "entities": []}, {"text": "Precision and recall metrics of the labelling rules provide information about how the addition of verbal subcategorization information contributes to the grammar performance.", "labels": [], "entities": [{"text": "Precision", "start_pos": 0, "end_pos": 9, "type": "METRIC", "confidence": 0.9786696434020996}, {"text": "recall", "start_pos": 14, "end_pos": 20, "type": "METRIC", "confidence": 0.9867745637893677}]}, {"text": "For this reason, in the qualitative analysis, only labelling syntactic function tags directly related to verbal subcategorization are considered.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Sizes of the FDGs", "labels": [], "entities": [{"text": "Sizes", "start_pos": 10, "end_pos": 15, "type": "TASK", "confidence": 0.9775978922843933}, {"text": "FDGs", "start_pos": 23, "end_pos": 27, "type": "DATASET", "confidence": 0.6306641697883606}]}, {"text": " Table 3: Labelling rules in the evaluated grammars", "labels": [], "entities": []}, {"text": " Table 4: Comparison of the labelling tags distribu- tion in SenSem and ParTes (%)", "labels": [], "entities": []}, {"text": " Table 6: Accuracy scores (%) in Spanish", "labels": [], "entities": [{"text": "Accuracy scores", "start_pos": 10, "end_pos": 25, "type": "METRIC", "confidence": 0.9767694473266602}]}, {"text": " Table 7: Accuracy scores (%) in Catalan", "labels": [], "entities": [{"text": "Accuracy scores", "start_pos": 10, "end_pos": 25, "type": "METRIC", "confidence": 0.9760157763957977}, {"text": "Catalan", "start_pos": 33, "end_pos": 40, "type": "DATASET", "confidence": 0.7817509174346924}]}, {"text": " Table 8: Labelling precision scores (%) in Spanish", "labels": [], "entities": [{"text": "Labelling precision scores", "start_pos": 10, "end_pos": 36, "type": "METRIC", "confidence": 0.7550303936004639}]}, {"text": " Table 9: Labelling precision scores (%) in Catalan", "labels": [], "entities": [{"text": "precision scores", "start_pos": 20, "end_pos": 36, "type": "METRIC", "confidence": 0.8569156527519226}]}, {"text": " Table 10: Labelling recall scores (%) in Spanish", "labels": [], "entities": [{"text": "recall scores", "start_pos": 21, "end_pos": 34, "type": "METRIC", "confidence": 0.9488721787929535}]}, {"text": " Table 11: Labelling recall scores (%) in Catalan", "labels": [], "entities": [{"text": "recall scores", "start_pos": 21, "end_pos": 34, "type": "METRIC", "confidence": 0.9518450200557709}]}]}