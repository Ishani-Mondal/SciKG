{"title": [{"text": "Evaluation of the domain adaptation of MT systems in ACCURAT", "labels": [], "entities": [{"text": "MT", "start_pos": 39, "end_pos": 41, "type": "TASK", "confidence": 0.9772412776947021}, {"text": "ACCURAT", "start_pos": 53, "end_pos": 60, "type": "DATASET", "confidence": 0.6098702549934387}]}], "abstractContent": [{"text": "1 The contribution reports on an evaluation of efforts to improve MT quality by domain adaptation, for both rule-based and statistical MT, as done in the ACCURAT project (Skadi\u0146a et al. 2012).", "labels": [], "entities": [{"text": "MT", "start_pos": 66, "end_pos": 68, "type": "TASK", "confidence": 0.9961387515068054}, {"text": "domain adaptation", "start_pos": 80, "end_pos": 97, "type": "TASK", "confidence": 0.7126595079898834}, {"text": "MT", "start_pos": 135, "end_pos": 137, "type": "TASK", "confidence": 0.9471897482872009}, {"text": "ACCURAT project", "start_pos": 154, "end_pos": 169, "type": "DATASET", "confidence": 0.8277852833271027}]}, {"text": "Comparative evaluation shows an increase of about 5% for both MT paradigms after system adaptation; absolute evaluation shows an increase inadequacy and fluency for SMT.", "labels": [], "entities": [{"text": "MT paradigms", "start_pos": 62, "end_pos": 74, "type": "TASK", "confidence": 0.9283332526683807}, {"text": "SMT", "start_pos": 165, "end_pos": 168, "type": "TASK", "confidence": 0.9910508394241333}]}, {"text": "While the RMT solution is superior in quality in both comparative and absolute evaluation, the gain by domain adaptation is higher for the SMT paradigm.", "labels": [], "entities": [{"text": "RMT", "start_pos": 10, "end_pos": 13, "type": "TASK", "confidence": 0.8808870315551758}, {"text": "SMT", "start_pos": 139, "end_pos": 142, "type": "TASK", "confidence": 0.9926896691322327}]}], "introductionContent": [{"text": "The objective of this contribution is to evaluate improvements achieved by adapting Machine Translation systems to narrow domains, using data from comparable corpora.", "labels": [], "entities": [{"text": "Machine Translation", "start_pos": 84, "end_pos": 103, "type": "TASK", "confidence": 0.7996531128883362}]}, {"text": "Language direction chosen was German to English; the automotive domain, subdomain of transmission / gearbox technology, was selected as an example fora narrow domain.", "labels": [], "entities": []}, {"text": "In order to assess the effect of domain adaptation on MT systems with different architecture, both a data driven (SMT) and a knowledge-driven (RMT) system were evaluated.", "labels": [], "entities": [{"text": "domain adaptation", "start_pos": 33, "end_pos": 50, "type": "TASK", "confidence": 0.7217917144298553}, {"text": "MT", "start_pos": 54, "end_pos": 56, "type": "TASK", "confidence": 0.9854459762573242}]}], "datasetContent": [{"text": "The evaluation object are two versions of an MT system: A baseline version, without domain tuning, and an adapted version, with domain tuning.", "labels": [], "entities": [{"text": "MT", "start_pos": 45, "end_pos": 47, "type": "TASK", "confidence": 0.975989818572998}]}, {"text": "Their comparison shows to which extent the domain adaptation can improve MT quality.", "labels": [], "entities": [{"text": "domain adaptation", "start_pos": 43, "end_pos": 60, "type": "TASK", "confidence": 0.7095301598310471}, {"text": "MT", "start_pos": 73, "end_pos": 75, "type": "TASK", "confidence": 0.9953203797340393}]}, {"text": "The evaluation objects were created as follows: For the baseline systems, on the RMT side, an out-of-the-box system of Linguatec's 'Personal Translator' PT (V.14) was used, which is a rulebased MT system, based on the IBM slot-filler grammar technology) and a bilingual lexicon of about 200K transfers.", "labels": [], "entities": [{"text": "RMT", "start_pos": 81, "end_pos": 84, "type": "DATASET", "confidence": 0.8526182174682617}, {"text": "Linguatec's 'Personal Translator' PT (V.14)", "start_pos": 119, "end_pos": 162, "type": "DATASET", "confidence": 0.7603468596935272}]}, {"text": "On the SMT side, a baseline Moses system was trained with standard parallel data (Europarl, JRC etc.), plus some initial comparable corpus data as collected in the first phase of ACCURAT.", "labels": [], "entities": [{"text": "SMT", "start_pos": 7, "end_pos": 10, "type": "TASK", "confidence": 0.9734163284301758}, {"text": "Europarl", "start_pos": 82, "end_pos": 90, "type": "DATASET", "confidence": 0.9678834080696106}, {"text": "ACCURAT", "start_pos": 179, "end_pos": 186, "type": "DATASET", "confidence": 0.7601452469825745}]}, {"text": "For the adaptation of the baseline systems, data were collected from the automotive domain.", "labels": [], "entities": []}, {"text": "These data were obtained by crawling sites of automotive companies being active in the transmission field (like ZF, BASF, Volkswagen and others), using the focused crawler described in ().", "labels": [], "entities": [{"text": "BASF", "start_pos": 116, "end_pos": 120, "type": "DATASET", "confidence": 0.6360875368118286}]}, {"text": "They were then aligned and cleaned manually.", "labels": [], "entities": []}, {"text": "Some sentence pairs were set aside for testing, the rest was given to the two systems as development and test sets.", "labels": [], "entities": []}, {"text": "The resulting narrow-domain automotive corpus has about 42.000 sentences for German-toEnglish.", "labels": [], "entities": []}, {"text": "For the SMT system, domain adaptation was done by adding these sentences to the training and development sets, and building anew SMT system.", "labels": [], "entities": [{"text": "SMT", "start_pos": 8, "end_pos": 11, "type": "TASK", "confidence": 0.9937519431114197}, {"text": "domain adaptation", "start_pos": 20, "end_pos": 37, "type": "TASK", "confidence": 0.8068752288818359}, {"text": "SMT", "start_pos": 129, "end_pos": 132, "type": "TASK", "confidence": 0.9734991192817688}]}, {"text": "In case of rule-based technology, domain adaptation involves terminology creation, as the main means of adaptation.", "labels": [], "entities": [{"text": "domain adaptation", "start_pos": 34, "end_pos": 51, "type": "TASK", "confidence": 0.7354784160852432}, {"text": "terminology creation", "start_pos": 61, "end_pos": 81, "type": "TASK", "confidence": 0.8279136419296265}]}, {"text": "This procedure is described in detail in.", "labels": [], "entities": []}, {"text": "Result of these efforts were four test systems, for German-to-English, and tuned for automotive domain with the same adaptation data: SMT-base: Moses with just baseline data SMT-adapted:Moses baseline plus in-domain data RMT-base: PT-baseline out-of-the-box RMT-adapted: PT with an automotive dictionary.", "labels": [], "entities": []}, {"text": "In total about 1500 sentences were taken from the collected strongly comparable automotive corpora for tests, with one reference translation each.", "labels": [], "entities": []}, {"text": "The sentences represent 'real-life' data; they were not cleaned or corrected..", "labels": [], "entities": []}, {"text": "In the ACCURAT narrow domain task, the following evaluation methods were used: Automatic evaluation of the four systems (SMT and RMT, baseline and adapted) using BLEU.", "labels": [], "entities": [{"text": "ACCURAT narrow domain task", "start_pos": 7, "end_pos": 33, "type": "TASK", "confidence": 0.5151668712496758}, {"text": "RMT", "start_pos": 129, "end_pos": 132, "type": "METRIC", "confidence": 0.6762583255767822}, {"text": "BLEU", "start_pos": 162, "end_pos": 166, "type": "METRIC", "confidence": 0.9968461394309998}]}, {"text": "Comparative evaluation of the pairs SMTbaseline vs. SMT-adapted, and RMT-baseline vs. RMT-adapted; this produces the core information how much the systems can improve.", "labels": [], "entities": [{"text": "SMTbaseline", "start_pos": 36, "end_pos": 47, "type": "TASK", "confidence": 0.9123181104660034}]}, {"text": "Absolute evaluation of the systems SMTadapted and RMT-adapted, to gain insight into translation quality, and consequently the acceptance of such systems for real-world use.", "labels": [], "entities": [{"text": "SMTadapted", "start_pos": 35, "end_pos": 45, "type": "TASK", "confidence": 0.8160811066627502}]}, {"text": "Other forms of evaluation were not included, esp.", "labels": [], "entities": []}, {"text": "postediting evaluation was done in other tasks in the ACCURAT project (cf.).", "labels": [], "entities": [{"text": "ACCURAT project", "start_pos": 54, "end_pos": 69, "type": "DATASET", "confidence": 0.8621069490909576}]}, {"text": "But to have a complete picture, other ABS and COMP directions were evaluated, but with 1 tester only.", "labels": [], "entities": [{"text": "ABS", "start_pos": 38, "end_pos": 41, "type": "METRIC", "confidence": 0.9836249351501465}]}, {"text": "For the evaluation, a special tool was created called 'Sisyphus II', to be used offline by freelancers, randomly proposing evaluation data, and creating an XML file for later evaluation.", "labels": [], "entities": []}, {"text": "The automatic evaluation for the four test systems was done using BLEU scores.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 66, "end_pos": 70, "type": "METRIC", "confidence": 0.9972020387649536}]}, {"text": "The results are shown in.", "labels": [], "entities": []}, {"text": "For both system types there is an increase in BLEU; more moderate for the RMT than for the SMT system.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 46, "end_pos": 50, "type": "METRIC", "confidence": 0.9997572302818298}, {"text": "SMT", "start_pos": 91, "end_pos": 94, "type": "TASK", "confidence": 0.977367103099823}]}, {"text": "Also, the SMT system performs better in this evaluation method.", "labels": [], "entities": [{"text": "SMT", "start_pos": 10, "end_pos": 13, "type": "TASK", "confidence": 0.9882456064224243}]}, {"text": "However it is known that BLEU is biased towards SMT systems (.: BLEU scores for SMT and RMT  Three testers were used, all of them good speakers of English with translation background.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 25, "end_pos": 29, "type": "METRIC", "confidence": 0.9973090887069702}, {"text": "SMT", "start_pos": 48, "end_pos": 51, "type": "TASK", "confidence": 0.9836806058883667}, {"text": "BLEU", "start_pos": 64, "end_pos": 68, "type": "METRIC", "confidence": 0.999030590057373}, {"text": "SMT", "start_pos": 80, "end_pos": 83, "type": "TASK", "confidence": 0.9412461519241333}]}, {"text": "They inspected randomly selected subsets of the 1500 test sentences.", "labels": [], "entities": []}, {"text": "Results are given in Tab.", "labels": [], "entities": [{"text": "Tab.", "start_pos": 21, "end_pos": 25, "type": "DATASET", "confidence": 0.9443926513195038}]}, {"text": "2. Both types of systems show an improvement of about 5% after domain adaptation.", "labels": [], "entities": [{"text": "domain adaptation", "start_pos": 63, "end_pos": 80, "type": "TASK", "confidence": 0.6920372843742371}]}, {"text": "It is a bit more for the SMT than for the RMT, due to a strong RMT baseline system.", "labels": [], "entities": [{"text": "SMT", "start_pos": 25, "end_pos": 28, "type": "TASK", "confidence": 0.954760730266571}, {"text": "RMT", "start_pos": 42, "end_pos": 45, "type": "DATASET", "confidence": 0.7259106040000916}]}, {"text": "The result is consistent among the testers: All of them see a higher improvement for the SMT than for the RMT.", "labels": [], "entities": [{"text": "SMT", "start_pos": 89, "end_pos": 92, "type": "TASK", "confidence": 0.9863021373748779}]}, {"text": "It maybe worthwhile noticing that in the RMT evaluation, a large proportion of the test sentences (nearly 60%) came out identical in both versions.", "labels": [], "entities": [{"text": "RMT", "start_pos": 41, "end_pos": 44, "type": "TASK", "confidence": 0.9348761439323425}]}, {"text": "In the SMT system, nearly no sentence came out unchanged; this fact increases the postediting effort for consecutive versions of SMT output.", "labels": [], "entities": [{"text": "SMT", "start_pos": 7, "end_pos": 10, "type": "TASK", "confidence": 0.9832628965377808}, {"text": "SMT output", "start_pos": 129, "end_pos": 139, "type": "TASK", "confidence": 0.925627201795578}]}, {"text": "Ina sideline evaluation, a comparison was made between the RMT and SMT systems, for both baseline and adaptations, cf. Tab.", "labels": [], "entities": [{"text": "SMT", "start_pos": 67, "end_pos": 70, "type": "TASK", "confidence": 0.8939505219459534}]}, {"text": "3. RMT, for baseline and adapted The result shows that the RMT quality is considered significantly better than the SMT quality.", "labels": [], "entities": [{"text": "RMT", "start_pos": 3, "end_pos": 6, "type": "METRIC", "confidence": 0.7474411725997925}, {"text": "RMT", "start_pos": 59, "end_pos": 62, "type": "METRIC", "confidence": 0.8115494251251221}, {"text": "SMT", "start_pos": 115, "end_pos": 118, "type": "TASK", "confidence": 0.9543871879577637}]}, {"text": "The main reason for this seems to be that the SMT German-English frequently eliminates verbs in sentences, which makes the output much less understandable.", "labels": [], "entities": [{"text": "SMT German-English", "start_pos": 46, "end_pos": 64, "type": "TASK", "confidence": 0.7534129023551941}]}, {"text": "It should be noted, however, that the distance between the system types is smaller in the adapted than in the baseline versions (by 3%).", "labels": [], "entities": []}, {"text": "Absolute evaluation assesses how usable the resulting translation would be after the system was adapted.", "labels": [], "entities": []}, {"text": "A total of 1100 sentences, randomly selected from the 1500 sentence test base, were inspected by three testers for adequacy and fluency.", "labels": [], "entities": []}, {"text": "It can be seen that testers evaluate the SMT somewhat between 'mostly' and 'partially' fluent / comprehensible, and the RMT close to 'mostly' fluent / comprehensible.", "labels": [], "entities": [{"text": "SMT", "start_pos": 41, "end_pos": 44, "type": "TASK", "confidence": 0.9892578721046448}, {"text": "RMT", "start_pos": 120, "end_pos": 123, "type": "METRIC", "confidence": 0.8786356449127197}]}, {"text": "If the percentage of level 1/2 evaluations is taken, both adequacy and fluency rates are significantly higher for RMT output.", "labels": [], "entities": [{"text": "RMT", "start_pos": 114, "end_pos": 117, "type": "TASK", "confidence": 0.9128897786140442}]}, {"text": "All testers agree in this evaluation, with similar average results.", "labels": [], "entities": []}, {"text": "It could be worthwhile to mention that the opinion often heard that the SMT produces more fluent output that the RMT cannot be corroborated with the evaluation data here: The RMT output is clearly considered to be more fluent than the SMT output (1.80 vs. 2.34).", "labels": [], "entities": [{"text": "SMT", "start_pos": 72, "end_pos": 75, "type": "TASK", "confidence": 0.9684506058692932}]}, {"text": "As far as the interrater agreement is concerned, the test setup made it difficult to compute it: All testers used the same test set but tested only a random subset of it.", "labels": [], "entities": []}, {"text": "So there are only few data points common to all testers (only 20 in many cases).", "labels": [], "entities": []}, {"text": "For those, only weak agreement could be found (with values below 0.4 in Cohen's kappa).", "labels": [], "entities": [{"text": "agreement", "start_pos": 21, "end_pos": 30, "type": "METRIC", "confidence": 0.9703867435455322}]}, {"text": "However, all testers show consistent behaviour in the evaluation, and came to similar conclusions overall, as has been explained above.", "labels": [], "entities": []}, {"text": "All evaluation methods indicate an improvement of the adapted versions over the baseline versions.", "labels": [], "entities": []}, {"text": "Absolute evaluation: For SMT, adequacy improved from 2.86 to 2.62, fluency slightly from 2.35 to 2.34; for RMT, adequacy improved from 2.05 to 2.02, fluency decreased from 1.48 to 1.8.", "labels": [], "entities": [{"text": "SMT", "start_pos": 25, "end_pos": 28, "type": "TASK", "confidence": 0.9898198246955872}, {"text": "RMT", "start_pos": 107, "end_pos": 110, "type": "TASK", "confidence": 0.7719805240631104}]}, {"text": "The improvement is more significant for the SMT system than for the RMT; this maybe due to the fact that the RMT baseline system was stronger than the SMT baseline.", "labels": [], "entities": [{"text": "SMT", "start_pos": 44, "end_pos": 47, "type": "TASK", "confidence": 0.9737834930419922}, {"text": "RMT", "start_pos": 68, "end_pos": 71, "type": "DATASET", "confidence": 0.6963411569595337}]}, {"text": "For SMT improvement, () report improvements between 8.6 and 16.8 BLEU (relative) for domain adaptation; results here are inline with these findings.", "labels": [], "entities": [{"text": "SMT", "start_pos": 4, "end_pos": 7, "type": "TASK", "confidence": 0.9950965046882629}, {"text": "BLEU", "start_pos": 65, "end_pos": 69, "type": "METRIC", "confidence": 0.9967054724693298}, {"text": "domain adaptation", "start_pos": 85, "end_pos": 102, "type": "TASK", "confidence": 0.7682557702064514}]}, {"text": "Comparing the evaluation methods, the findings corroborate statements (cf.) that the 'human-based' methods (COMP and ABS) differ from the automatic ones (BLEU) if different types of MT systems are to be compared.", "labels": [], "entities": [{"text": "ABS", "start_pos": 117, "end_pos": 120, "type": "METRIC", "confidence": 0.9261316657066345}, {"text": "BLEU", "start_pos": 154, "end_pos": 158, "type": "METRIC", "confidence": 0.9897691011428833}, {"text": "MT", "start_pos": 182, "end_pos": 184, "type": "TASK", "confidence": 0.9748926162719727}]}, {"text": "Overall, the 'human-based' evaluation methods (COMP, ABS) have shown that a trained RMT system still outperforms a trained SMT system; however the SMT system profits more from adaptation.", "labels": [], "entities": [{"text": "ABS", "start_pos": 53, "end_pos": 56, "type": "METRIC", "confidence": 0.8851844668388367}, {"text": "SMT", "start_pos": 123, "end_pos": 126, "type": "TASK", "confidence": 0.980444073677063}, {"text": "SMT", "start_pos": 147, "end_pos": 150, "type": "TASK", "confidence": 0.9772829413414001}]}], "tableCaptions": []}