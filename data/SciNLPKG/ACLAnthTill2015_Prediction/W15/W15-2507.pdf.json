{"title": [{"text": "A Proposal fora Coherence Corpus in Machine Translation", "labels": [], "entities": [{"text": "Machine Translation", "start_pos": 36, "end_pos": 55, "type": "TASK", "confidence": 0.7463884353637695}]}], "abstractContent": [{"text": "Coherence in Machine Translation (MT) has received little attention to date.", "labels": [], "entities": [{"text": "Coherence in Machine Translation (MT)", "start_pos": 0, "end_pos": 37, "type": "TASK", "confidence": 0.842994042805263}]}, {"text": "One of the main issues we face in work in this area is the lack of labelled data.", "labels": [], "entities": []}, {"text": "While coherent (human authored) texts are abundant and incoherent texts could betaken from MT output, the latter also contains other errors which are not specifically related to coherence.", "labels": [], "entities": [{"text": "MT", "start_pos": 91, "end_pos": 93, "type": "TASK", "confidence": 0.9217730760574341}]}, {"text": "This makes it difficult to identify and quantify issues of coherence in those texts.", "labels": [], "entities": []}, {"text": "We introduce an initiative to create a corpus consisting of data artificially manipulated to contain errors of coherence common in MT output.", "labels": [], "entities": [{"text": "MT output", "start_pos": 131, "end_pos": 140, "type": "TASK", "confidence": 0.9056587815284729}]}, {"text": "Such a corpus could then be used as a benchmark for coherence models in MT, and potentially as training data for coherence models in supervised settings.", "labels": [], "entities": [{"text": "MT", "start_pos": 72, "end_pos": 74, "type": "TASK", "confidence": 0.9683263301849365}]}], "introductionContent": [{"text": "Discourse information has only recently started to attract attention in MT, particularly in Statistical Machine Translation (SMT), the focus of this paper.", "labels": [], "entities": [{"text": "MT", "start_pos": 72, "end_pos": 74, "type": "TASK", "confidence": 0.9945652484893799}, {"text": "Statistical Machine Translation (SMT)", "start_pos": 92, "end_pos": 129, "type": "TASK", "confidence": 0.8287394841512045}]}, {"text": "Most decoders work on a sentence by sentence basis, isolated from context, due to both modelling and computational complexity.", "labels": [], "entities": []}, {"text": "An exception are approaches to multi-pass decoding, such as Docent ().", "labels": [], "entities": []}, {"text": "Our work focuses on an issue which has not yet been much explored in MT, that of coherence.", "labels": [], "entities": [{"text": "MT", "start_pos": 69, "end_pos": 71, "type": "TASK", "confidence": 0.9479379057884216}]}, {"text": "Coherence is undeniably a cognitive process, and we will limit our remit to the extent that this process is guided by linguistic elements discernible in the discourse.", "labels": [], "entities": []}, {"text": "While it does include cohesion, it is wider in terms of describing how a text becomes semantically meaningful overall, and additionally spans the entire document.", "labels": [], "entities": []}, {"text": "We are interested in capturing aspects of coherence as defined by, based on the attentional state, intentional structure and linguistic structure of discourse.", "labels": [], "entities": []}, {"text": "As a result, we believe that a coherent discourse should have a context and a focus, be characterised by appropriate coherence relations, and structured in a logical manner.", "labels": [], "entities": []}, {"text": "Previous computational models for assessing coherence in a monolingual context have covered entity transitions (, syntactic patterns (, discourse relations (), distributed sentence representations () and lexical chains).", "labels": [], "entities": []}, {"text": "For evaluation, these studies in coherence have typically used automatically summarized texts, or texts with sentences artificially shuffled as their 'incoherent' data.", "labels": [], "entities": []}, {"text": "The latter is an example of artificially created labelled data, distorting the ordered logic of the text and thus affecting some aspects of coherence.", "labels": [], "entities": []}, {"text": "However, it is inadequate for our task, as MT preserves the sentence ordering, but suffers from other aspects of incoherence.", "labels": [], "entities": [{"text": "MT", "start_pos": 43, "end_pos": 45, "type": "TASK", "confidence": 0.9835996627807617}]}, {"text": "Moreover, while the MT output can potentially be considered 'incoherent', it contains a multitude of problems, which are not all due to lack of coherence.", "labels": [], "entities": [{"text": "MT", "start_pos": 20, "end_pos": 22, "type": "TASK", "confidence": 0.962801456451416}]}, {"text": "For the evaluation of coherence models in the MT context, as well as for supervised learning of coherence models it is necessary to have data annotated with issues of incoherence.", "labels": [], "entities": [{"text": "MT context", "start_pos": 46, "end_pos": 56, "type": "TASK", "confidence": 0.8766717314720154}]}, {"text": "In particular, we are interested in coherence issues which are deemed to occur specifically in MT output.", "labels": [], "entities": [{"text": "MT output", "start_pos": 95, "end_pos": 104, "type": "TASK", "confidence": 0.8983926177024841}]}, {"text": "The purpose of this initiative is to ensure that we can assess coherence models by isolating other issues that are not related to coherence.", "labels": [], "entities": []}, {"text": "In the remainder of this paper, we start by presenting previous work (Section 2).", "labels": [], "entities": []}, {"text": "We then describe how problems related to lack of coherence are manifested in MT output (Section 3).", "labels": [], "entities": [{"text": "MT", "start_pos": 77, "end_pos": 79, "type": "TASK", "confidence": 0.958389937877655}]}, {"text": "In Section 4 we detail how we plan to manipulate the data in systematic ways to create a corpus of artificially generated incoherent data.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": []}