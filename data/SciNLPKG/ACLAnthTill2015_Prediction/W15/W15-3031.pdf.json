{"title": [{"text": "Results of the WMT15 Metrics Shared Task", "labels": [], "entities": [{"text": "WMT15 Metrics Shared", "start_pos": 15, "end_pos": 35, "type": "TASK", "confidence": 0.6045461694399515}]}], "abstractContent": [{"text": "This paper presents the results of the WMT15 Metrics Shared Task.", "labels": [], "entities": [{"text": "WMT15 Metrics Shared Task", "start_pos": 39, "end_pos": 64, "type": "TASK", "confidence": 0.6694209724664688}]}, {"text": "We asked participants of this task to score the outputs of the MT systems involved in the WMT15 Shared Translation Task.", "labels": [], "entities": [{"text": "MT", "start_pos": 63, "end_pos": 65, "type": "TASK", "confidence": 0.9248127341270447}, {"text": "WMT15 Shared Translation Task", "start_pos": 90, "end_pos": 119, "type": "TASK", "confidence": 0.7477867007255554}]}, {"text": "We collected scores of 46 metrics from 11 research groups.", "labels": [], "entities": []}, {"text": "In addition to that, we computed scores of 7 standard metrics (BLEU, SentBLEU, NIST, WER, PER, TER and CDER) as baselines.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 63, "end_pos": 67, "type": "METRIC", "confidence": 0.9987298846244812}, {"text": "NIST", "start_pos": 79, "end_pos": 83, "type": "METRIC", "confidence": 0.4956520199775696}, {"text": "WER", "start_pos": 85, "end_pos": 88, "type": "METRIC", "confidence": 0.9439495801925659}, {"text": "PER", "start_pos": 90, "end_pos": 93, "type": "METRIC", "confidence": 0.8898788094520569}, {"text": "TER", "start_pos": 95, "end_pos": 98, "type": "METRIC", "confidence": 0.9236747622489929}]}, {"text": "The collected scores were evaluated in terms of system level correlation (how well each metric's scores correlate with WMT15 official manual ranking of systems) and in terms of segment level correlation (how often a metric agrees with humans in comparing two translations of a particular sentence).", "labels": [], "entities": [{"text": "WMT15 official manual ranking", "start_pos": 119, "end_pos": 148, "type": "DATASET", "confidence": 0.8369509875774384}, {"text": "segment level correlation", "start_pos": 177, "end_pos": 202, "type": "METRIC", "confidence": 0.63816170891126}]}], "introductionContent": [{"text": "Automatic machine translation metrics play a very important role in the development of MT systems and their evaluation.", "labels": [], "entities": [{"text": "machine translation metrics", "start_pos": 10, "end_pos": 37, "type": "TASK", "confidence": 0.7516123255093893}, {"text": "MT", "start_pos": 87, "end_pos": 89, "type": "TASK", "confidence": 0.9973209500312805}]}, {"text": "There are many different metrics of diverse nature and one would like to assess their quality.", "labels": [], "entities": []}, {"text": "For this reason, the Metrics Shared Task is held annually at the Workshop of Statistical Machine Translation 1 , starting with and following up to.", "labels": [], "entities": [{"text": "Metrics Shared Task", "start_pos": 21, "end_pos": 40, "type": "TASK", "confidence": 0.857369065284729}, {"text": "Statistical Machine Translation 1", "start_pos": 77, "end_pos": 110, "type": "TASK", "confidence": 0.8379443287849426}]}, {"text": "The systems' outputs, human judgements and evaluated metrics are described in Section 2.", "labels": [], "entities": []}, {"text": "The quality of the metrics in terms of system level correlation is reported in Section 3.", "labels": [], "entities": []}, {"text": "Section 4 is devoted to segment level correlation.", "labels": [], "entities": [{"text": "segment level correlation", "start_pos": 24, "end_pos": 49, "type": "TASK", "confidence": 0.759057343006134}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 6: Kendall's \u03c4 scores for two metrics across  years.", "labels": [], "entities": [{"text": "Kendall's \u03c4 scores", "start_pos": 10, "end_pos": 28, "type": "METRIC", "confidence": 0.5398799479007721}]}]}