{"title": [{"text": "Learning Domain-Independent Dialogue Policies via Ontology Parameterisation", "labels": [], "entities": [{"text": "Parameterisation", "start_pos": 59, "end_pos": 75, "type": "TASK", "confidence": 0.5224652290344238}]}], "abstractContent": [{"text": "This paper introduces a novel approach to eliminate the domain dependence of dialogue state and action representations, such that dialogue policies trained based on the proposed representation can be transferred across different domains.", "labels": [], "entities": []}, {"text": "The experimental results show that the policy optimised in a restaurant search domain using our domain-independent representations can be deployed to a laptop sale domain , achieving a task success rate very close (96.4% relative) to that of the policy optimised on in-domain dialogues.", "labels": [], "entities": []}], "introductionContent": [{"text": "Statistical approaches to Spoken Dialogue Systems (SDS), particularly, Partially Observable Markov Decision Processes (POMDPs) (), have demonstrated great success in improving the robustness of dialogue policies to error-prone Automatic Speech Recognition (ASR).", "labels": [], "entities": [{"text": "Spoken Dialogue Systems (SDS)", "start_pos": 26, "end_pos": 55, "type": "TASK", "confidence": 0.8205128808816274}, {"text": "Automatic Speech Recognition (ASR)", "start_pos": 227, "end_pos": 261, "type": "TASK", "confidence": 0.800395131111145}]}, {"text": "However, building statistical SDS (SSDS) for different application domains is time consuming.", "labels": [], "entities": [{"text": "statistical SDS (SSDS)", "start_pos": 18, "end_pos": 40, "type": "TASK", "confidence": 0.7984185338020324}]}, {"text": "Traditionally, each component of such SSDS needs to be trained based on domain-specific data, which are not always easy to obtain.", "labels": [], "entities": [{"text": "SSDS", "start_pos": 38, "end_pos": 42, "type": "TASK", "confidence": 0.9629929065704346}]}, {"text": "Moreover, in many cases, one will need a basic (e.g. rulebased) working SDS to be built before starting the data collection procedure, where developing the initial system fora new domain requires a significant amount of human expertise.", "labels": [], "entities": [{"text": "data collection", "start_pos": 108, "end_pos": 123, "type": "TASK", "confidence": 0.6930762529373169}]}, {"text": "In this paper, we introduce a simple but effective approach to eliminate domain dependence of dialogue policies, by exploring the nature and commonness of the underlying tasks of SDS in different domains, and parameterising different slots defined in the domain ontologies into a common * ZW's present address is Baidu Inc., feature space according to their relations and potential contributions to the underlying tasks.", "labels": [], "entities": [{"text": "Baidu Inc.", "start_pos": 313, "end_pos": 323, "type": "DATASET", "confidence": 0.9525017440319061}]}, {"text": "After the parameterisation, the resulting policy can be applied to different domains that realise a same abstract task (see \u00a73.3 for examples).", "labels": [], "entities": []}, {"text": "Existing works on domain-extension/transfer for SDS include domain-independent intermediate semantic extractors for Spoken Language Understanding (SLU) (), domain-general rules ( and delexicalised deep classifiers) for dialogue state tracking, and domain-extensible/transferable statistical dialogue policies (.", "labels": [], "entities": [{"text": "Spoken Language Understanding (SLU)", "start_pos": 116, "end_pos": 151, "type": "TASK", "confidence": 0.6798565983772278}, {"text": "dialogue state tracking", "start_pos": 219, "end_pos": 242, "type": "TASK", "confidence": 0.6624814867973328}]}, {"text": "When compared to the closely related methods by Ga\u0161i\u00b4Ga\u0161i\u00b4c et al. and Lemon et al. that manually tie slots in different domains, our approach provides a more flexible way to parametrically measure the similarity between different domain ontologies and directly addresses the nature of the underlying tasks.", "labels": [], "entities": []}, {"text": "For the ease of access to the proposed technique ( \u00a73), we start from a brief review of POMDP-SDS in \u00a72.", "labels": [], "entities": []}, {"text": "Promising experimental results are achieved based on both simulated users and human subjects as shown in \u00a74, followed by conclusions ( \u00a75).", "labels": [], "entities": []}], "datasetContent": [{"text": "In the following experiments, the proposed domain-independent parameterisation (DIP) method were integrated with a generic dialogue state tracker ( to yield an overall domain-independent dialogue manager.", "labels": [], "entities": []}, {"text": "Firstly, we trained DIP dialogue policies in the restaurant search domain using GP-SARSA based on a state-of-the-art agenda-based user simulator 3 (, in comparison with the GP-SARSA learning process for the well-known BUDS system (where full beliefs are used), as shown in.", "labels": [], "entities": [{"text": "DIP dialogue", "start_pos": 20, "end_pos": 32, "type": "TASK", "confidence": 0.8364550173282623}, {"text": "GP-SARSA", "start_pos": 80, "end_pos": 88, "type": "DATASET", "confidence": 0.9392907023429871}, {"text": "BUDS system", "start_pos": 218, "end_pos": 229, "type": "DATASET", "confidence": 0.8593591749668121}]}, {"text": "It can be found that the proposed method results in faster convergence and can even achieve slightly better performance than the conventional approach.", "labels": [], "entities": []}, {"text": "After this, we directly deployed the DIP poli-# of dialogues 0 1,000 2,000 3,000 4,000 5,000 6,000 7,000 8,000 9,000 10,000 cies trained in the restaurant search domain to the laptop sale domain, and compared its performance with an in-domain policy trained using the simulator (configured to the laptop sale domain).", "labels": [], "entities": []}, {"text": "shows that the performance of the transferred policy is almost identical to the in-domain policy.", "labels": [], "entities": []}, {"text": "Finally, we chose the best in-domain and transferred DIP policies and deployed them into endto-end laptop sale SDSs, for human subject experiments based on MTurk.", "labels": [], "entities": [{"text": "MTurk", "start_pos": 156, "end_pos": 161, "type": "DATASET", "confidence": 0.9416128993034363}]}, {"text": "After each dialogue, the user was also asked to provide a subjective score for the naturalness of the interaction, ranging from 1 (very unnatural) to 6 (very natural).", "labels": [], "entities": []}, {"text": "The results are summarised in, where the success rate difference (3%) between the in-domain policy and the transferred policy is statistically insignificant, and surprisingly, the users on average regard the transferred policy as slightly more natural than the in-domain policy.", "labels": [], "entities": [{"text": "success rate difference", "start_pos": 41, "end_pos": 64, "type": "METRIC", "confidence": 0.8860487937927246}]}], "tableCaptions": [{"text": " Table 1: Policy evaluations in the laptop sale do- main based on simulated dialogues.", "labels": [], "entities": [{"text": "laptop sale do- main", "start_pos": 36, "end_pos": 56, "type": "DATASET", "confidence": 0.8390168666839599}]}, {"text": " Table 2: Policy evaluations using human subjects.", "labels": [], "entities": []}]}