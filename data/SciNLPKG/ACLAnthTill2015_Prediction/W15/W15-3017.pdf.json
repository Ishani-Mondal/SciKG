{"title": [{"text": "UdS-Sant: English-German Hybrid Machine Translation System", "labels": [], "entities": [{"text": "UdS-Sant", "start_pos": 0, "end_pos": 8, "type": "DATASET", "confidence": 0.8549848794937134}, {"text": "English-German Hybrid Machine Translation", "start_pos": 10, "end_pos": 51, "type": "TASK", "confidence": 0.4839838370680809}]}], "abstractContent": [{"text": "This paper describes the UdS-Sant English-German Hybrid Machine Translation (MT) system submitted to the Translation Task organized in the Workshop on Statistical Machine Translation (WMT) 2015.", "labels": [], "entities": [{"text": "UdS-Sant English-German Hybrid Machine Translation (MT)", "start_pos": 25, "end_pos": 80, "type": "TASK", "confidence": 0.739476203918457}, {"text": "Translation Task organized in the Workshop on Statistical Machine Translation (WMT) 2015", "start_pos": 105, "end_pos": 193, "type": "TASK", "confidence": 0.8641028021063123}]}, {"text": "Our proposed hybrid system brings improvements over the baseline system by incorporating additional knowledge such as extracted bilingual named entities and bilingual phrase pairs induced from example-based methods.", "labels": [], "entities": []}, {"text": "The reported final submission is the result of a hybrid system obtained from confusion network based system combination that combines the best performance of each individual system in a multi-engine pipeline.", "labels": [], "entities": []}], "introductionContent": [{"text": "In this paper, we present Universit\u00e4t des Saarlandes (UdS) submission (named UdS-Sant) to WMT 2015 using a Hybrid MT framework.", "labels": [], "entities": [{"text": "UdS-Sant) to WMT 2015", "start_pos": 77, "end_pos": 98, "type": "DATASET", "confidence": 0.8256284832954407}]}, {"text": "We participated in the generic translation shared task for the English-German (EN-DE) language pair.", "labels": [], "entities": [{"text": "generic translation shared task", "start_pos": 23, "end_pos": 54, "type": "TASK", "confidence": 0.8514929264783859}]}, {"text": "Corpus-based MT (CBMT) has delivered progressively improved quality translations since its inception.", "labels": [], "entities": [{"text": "Corpus-based MT (CBMT", "start_pos": 0, "end_pos": 21, "type": "TASK", "confidence": 0.48344576358795166}]}, {"text": "There are two main approaches to corpus-based MT -Example Based Machine Translation (EBMT) and Statistical Machine Translation (SMT).", "labels": [], "entities": [{"text": "MT", "start_pos": 46, "end_pos": 48, "type": "TASK", "confidence": 0.8957785964012146}, {"text": "Example Based Machine Translation", "start_pos": 50, "end_pos": 83, "type": "TASK", "confidence": 0.7514352798461914}, {"text": "Statistical Machine Translation (SMT)", "start_pos": 95, "end_pos": 132, "type": "TASK", "confidence": 0.8166133562723795}]}, {"text": "Out of these two, in terms of large-scale evaluations, SMT is the most successful MT paradigm.", "labels": [], "entities": [{"text": "SMT", "start_pos": 55, "end_pos": 58, "type": "TASK", "confidence": 0.9936965107917786}, {"text": "MT", "start_pos": 82, "end_pos": 84, "type": "TASK", "confidence": 0.9948384165763855}]}, {"text": "However, each approach has its own advantages and disadvantages along with its own methods of applying and acquiring translation knowledge from the bilingual parallel training data.", "labels": [], "entities": []}, {"text": "EBMT phrases tend to be more linguistically motivated compared to SMT phrases which essentially operate on n-grams.", "labels": [], "entities": [{"text": "SMT phrases", "start_pos": 66, "end_pos": 77, "type": "TASK", "confidence": 0.9305754005908966}]}, {"text": "The knowledge extraction as well as representation process, in both EBMT and SMT, uses very different techniques in order to extract resources.", "labels": [], "entities": [{"text": "knowledge extraction", "start_pos": 4, "end_pos": 24, "type": "TASK", "confidence": 0.7878189384937286}, {"text": "SMT", "start_pos": 77, "end_pos": 80, "type": "TASK", "confidence": 0.9717971086502075}]}, {"text": "Even though, SMT is the most popular MT paradigm, it sometimes fails to deliver sufficient quality in translation output for some languages, since each language has its own difficulties.", "labels": [], "entities": [{"text": "SMT", "start_pos": 13, "end_pos": 16, "type": "TASK", "confidence": 0.9896016716957092}, {"text": "MT paradigm", "start_pos": 37, "end_pos": 48, "type": "TASK", "confidence": 0.9214847087860107}]}, {"text": "Multiword Expressions (MWEs) and Named Entities (NEs) offer challenges within a language.", "labels": [], "entities": []}, {"text": "MWEs are defined as idiosyncratic interpretations that crossword boundaries ().", "labels": [], "entities": []}, {"text": "Named entities on the other hand often consist of more than one word, so that they can be considered as a specific type of MWEs such as noun compounds.", "labels": [], "entities": []}, {"text": "Traditional approaches to word alignment such as IBM Models () are unable to tackle NEs and MWEs properly due to their inability to handle many-to-many alignments.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 26, "end_pos": 40, "type": "TASK", "confidence": 0.7906268239021301}, {"text": "NEs and MWEs", "start_pos": 84, "end_pos": 96, "type": "TASK", "confidence": 0.720726211865743}]}, {"text": "In another wellknown word alignment approach, Hidden Markov Model (HMM: (), the alignment probabilities depend on the alignment position of the previous word.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 21, "end_pos": 35, "type": "TASK", "confidence": 0.7427719831466675}]}, {"text": "It does not explicitly consider many-to-many alignment either.", "labels": [], "entities": []}, {"text": "We address this alignment problem indirectly.", "labels": [], "entities": []}, {"text": "The objective of the present work is threefold.", "labels": [], "entities": []}, {"text": "Firstly, we would like to determine how treatment of MWEs as a single unit affects the overall MT quality ().", "labels": [], "entities": [{"text": "MT", "start_pos": 95, "end_pos": 97, "type": "TASK", "confidence": 0.9772771596908569}]}, {"text": "Secondly, whether a prior automatic NE aligned parallel corpus as well as example based parallel phrases can bring about any further improvement on top of that.", "labels": [], "entities": []}, {"text": "And finally, whether system combination can provide any additional advantage in terms of translation quality and performance.", "labels": [], "entities": [{"text": "translation", "start_pos": 89, "end_pos": 100, "type": "TASK", "confidence": 0.9607391953468323}]}, {"text": "The remainder of the paper is organised as follows.", "labels": [], "entities": []}, {"text": "Section 2 details the components of our system, in particular named entity extraction, translation memory, and EBMT, followed by description of 3 types of Hybrid systems and the system combination module.", "labels": [], "entities": [{"text": "entity extraction", "start_pos": 68, "end_pos": 85, "type": "TASK", "confidence": 0.7403794229030609}, {"text": "translation memory", "start_pos": 87, "end_pos": 105, "type": "TASK", "confidence": 0.8888732492923737}, {"text": "EBMT", "start_pos": 111, "end_pos": 115, "type": "METRIC", "confidence": 0.8441965579986572}]}, {"text": "In Section 3, we outline the complete experimental setup for the shared task and provide results and analysis on the performance on the test set in Section 4.", "labels": [], "entities": []}, {"text": "Section 5 concludes the proposed research.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": []}