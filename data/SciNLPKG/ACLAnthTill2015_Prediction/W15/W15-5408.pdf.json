{"title": [{"text": "Discriminating similar languages with token-based backoff", "labels": [], "entities": []}], "abstractContent": [{"text": "In this paper we describe the language identification system built within the Finno-Ugric Languages and the Internet project for the Discriminating between Similar Languages (DSL) shared task in LT4VarDial workshop at RANLP-2015.", "labels": [], "entities": [{"text": "language identification", "start_pos": 30, "end_pos": 53, "type": "TASK", "confidence": 0.7147505879402161}, {"text": "Discriminating between Similar Languages (DSL) shared task", "start_pos": 133, "end_pos": 191, "type": "TASK", "confidence": 0.7006031970183054}, {"text": "RANLP-2015", "start_pos": 218, "end_pos": 228, "type": "DATASET", "confidence": 0.5461806058883667}]}, {"text": "The system reached fourth place in normal closed submissions (94.7% accuracy) and second place in closed submissions with the named entities blinded (93.0% accuracy).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 68, "end_pos": 76, "type": "METRIC", "confidence": 0.9961696267127991}, {"text": "accuracy", "start_pos": 156, "end_pos": 164, "type": "METRIC", "confidence": 0.9960589408874512}]}], "introductionContent": [{"text": "In the Finno-Ugric Languages and the Internet project 1 , our aim is to harvest texts written in small Uralic languages from the internet.", "labels": [], "entities": [{"text": "Finno-Ugric Languages and the Internet project 1", "start_pos": 7, "end_pos": 55, "type": "DATASET", "confidence": 0.7651358927999224}]}, {"text": "The project is funded by the Kone Foundation from its language program, which is especially targeted to support the research of Uralic languages).", "labels": [], "entities": []}, {"text": "We are particularly interested in gathering material written in the smaller languages, instead of the three largest Uralic languages: Hungarian, Finnish and Estonian.", "labels": [], "entities": []}, {"text": "As part of the project, we are developing methods for language identification which are needed to find the relevant texts among the billions of files we are downloading.", "labels": [], "entities": [{"text": "language identification", "start_pos": 54, "end_pos": 77, "type": "TASK", "confidence": 0.7201897352933884}]}, {"text": "At the moment, we have a list of 38 relevant languages based on the ISO 639-3 division of the Uralic languages.", "labels": [], "entities": [{"text": "ISO 639-3 division of the Uralic languages", "start_pos": 68, "end_pos": 110, "type": "DATASET", "confidence": 0.7607413487774985}]}, {"text": "Some of the relevant languages, such as LivviKarelian and Ludic, two Finnic languages used in the north-western Russia, are very close to each other.", "labels": [], "entities": []}, {"text": "However, the closeness between relevant languages is not as great a problem as the closeness between relevant and irrelevant languages.", "labels": [], "entities": []}, {"text": "For example there are many dialectal variations of Finnish which are written differently from the 1 http://suki.ling.helsinki.fi standard Finnish and are actually closer in orthography to some of the very close languages, such as Tornedalen Finnish, than the standard written Finnish.", "labels": [], "entities": []}, {"text": "This has led us to introduce separate language models for some of the Finnish dialects.", "labels": [], "entities": []}, {"text": "An even greater problem for us is the large number of pages we have found which are written in a language not known to our language identifier (which at the moment has models for 395 languages and variants) or which consist mostly of lists of model abbreviations.", "labels": [], "entities": []}, {"text": "Some of the character combinations used in the abbreviations tend to be quite common in some of the relevant languages and are therefore identified as such when the language identifier is forced to choose between languages it knows.", "labels": [], "entities": []}, {"text": "Therefore, the opportunity given by the second version of the DSL shared task () to research unknown language detection has been very welcome.", "labels": [], "entities": [{"text": "unknown language detection", "start_pos": 93, "end_pos": 119, "type": "TASK", "confidence": 0.6604744096597036}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 3: The average number of tokens per excerpt in the  training and the development sets for each language.", "labels": [], "entities": []}, {"text": " Table 4: The average accuracies for known languages using  different unit combinations on the development set.", "labels": [], "entities": [{"text": "accuracies", "start_pos": 22, "end_pos": 32, "type": "METRIC", "confidence": 0.9654526114463806}]}, {"text": " Table 6.  R l is the cut-off ratio and C l is the cut-off score.  The cut-off ratio for Slovak stayed as high as it  did because the Slovak development set included  some sentences where all the accents were omitted  from the characters. We could have coped with  this problem by creating separate language models  for these languages with de-accented characters,  but we did not have time to move further with this  idea.", "labels": [], "entities": [{"text": "Slovak development set", "start_pos": 134, "end_pos": 156, "type": "DATASET", "confidence": 0.6549723843733469}]}, {"text": " Table 10. It is clear that our sys- tem has a special problem with the group A, where  our results are almost 6% lower than the best re- sults of the 2014 shared task.", "labels": [], "entities": []}, {"text": " Table 10: The accuracies within the language groups for the  third run on normal test set.", "labels": [], "entities": [{"text": "normal test set", "start_pos": 75, "end_pos": 90, "type": "DATASET", "confidence": 0.8002042373021444}]}, {"text": " Table 9: The confusion table for the third run on the test set with the named entities blinded.", "labels": [], "entities": [{"text": "confusion", "start_pos": 14, "end_pos": 23, "type": "METRIC", "confidence": 0.9867727160453796}]}]}