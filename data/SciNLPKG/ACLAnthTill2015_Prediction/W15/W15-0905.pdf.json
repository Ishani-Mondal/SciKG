{"title": [{"text": "Modeling the Statistical Idiosyncrasy of Multiword Expressions", "labels": [], "entities": [{"text": "Statistical Idiosyncrasy of Multiword Expressions", "start_pos": 13, "end_pos": 62, "type": "TASK", "confidence": 0.8176538109779358}]}], "abstractContent": [{"text": "The focus of this work is statistical idiosyncrasy (or collocational weight) as a discrimi-nant property of multiword expressions.", "labels": [], "entities": []}, {"text": "We formalize and model this property, compile a 2-class data set of MWE and non-MWE examples , and evaluate our models on this data set.", "labels": [], "entities": []}, {"text": "We present a possible empirical implementation of collocational weight and study its effects on identification and extraction of MWEs.", "labels": [], "entities": [{"text": "identification and extraction of MWEs", "start_pos": 96, "end_pos": 133, "type": "TASK", "confidence": 0.7362302541732788}]}, {"text": "Our models prove to be more effective than baselines in identifying noun-noun MWEs.", "labels": [], "entities": [{"text": "identifying noun-noun MWEs", "start_pos": 56, "end_pos": 82, "type": "TASK", "confidence": 0.7471070090929667}]}], "introductionContent": [{"text": "Multiword Expressions (MWEs) are sequences of words that show some level of idiosyncrasy.", "labels": [], "entities": [{"text": "Multiword Expressions (MWEs)", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.7401323914527893}]}, {"text": "For instance they can be semantically idiosyncratic (i.e., their meaning cannot be readily inferred from the meaning of their components, e.g., flea market), syntactically idiosyncratic (their syntax cannot be extracted from the syntax of their components, e.g., at large), statistically idiosyncratic (their components tend to co-occur more often than expected by chance, e.g., drug dealer), or have other forms of idiosyncrasy.", "labels": [], "entities": []}, {"text": "MWEs comprise several types and sub-types.", "labels": [], "entities": []}, {"text": "Although it is not always clear whereto draw the line between various types of MWEs, the two broadest categories are lexicalized MWEs and institutionalized MWEs ().", "labels": [], "entities": []}, {"text": "The main property of lexicalized MWEs is syntactic or semantic idiosyncrasy and the main property of institutionalized MWEs is statistical idiosyncrasy.", "labels": [], "entities": []}, {"text": "Semantic idiosyncrasy is closely related to the concept of non-compositionality.", "labels": [], "entities": []}, {"text": "It is important to note that a MWE is often idiosyncratic in more than one way (.", "labels": [], "entities": [{"text": "MWE", "start_pos": 31, "end_pos": 34, "type": "TASK", "confidence": 0.8829917311668396}]}, {"text": "This means lexicalized MWEs can be statistically idiosyncratic, and institutionalized MWEs can be semantically idiosyncratic.", "labels": [], "entities": []}, {"text": "Institutionalized MWEs are closely related to collocations.", "labels": [], "entities": [{"text": "Institutionalized MWEs", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.5493604093790054}]}, {"text": "1 They can be compositional (seat belt) or non-compositional (hard drive), but statistically they co-occur more often than expected by chance.", "labels": [], "entities": []}, {"text": "Efficient extraction and identification of MWEs can positively influence some important Natural Language Processing (NLP) tasks such as parsing () and Statistical Machine Translation ().", "labels": [], "entities": [{"text": "identification of MWEs", "start_pos": 25, "end_pos": 47, "type": "TASK", "confidence": 0.6858656207720438}, {"text": "parsing", "start_pos": 136, "end_pos": 143, "type": "TASK", "confidence": 0.981342077255249}, {"text": "Statistical Machine Translation", "start_pos": 151, "end_pos": 182, "type": "TASK", "confidence": 0.7748862703641256}]}, {"text": "Identification and extraction of MWEs are therefore important research questions in the area of NLP.", "labels": [], "entities": [{"text": "Identification and extraction of MWEs", "start_pos": 0, "end_pos": 37, "type": "TASK", "confidence": 0.7610287129878998}]}, {"text": "In this work we refer to statistical idiosyncrasy as collocational weight and present a method of modeling this property for noun-noun compounds.", "labels": [], "entities": []}, {"text": "Comparative evaluation reveals better performance of proposed models compared to that of the baselines.", "labels": [], "entities": []}, {"text": "In previous work, it has often been suggested that collocations can be identified by their nonsubstitutability.", "labels": [], "entities": []}, {"text": "This means we cannot replace a collocation's components with their near synonyms).", "labels": [], "entities": []}, {"text": "For instance we cannot say brief film instead of short film.", "labels": [], "entities": []}, {"text": "Pearce (2001) defines collocations as pairs of words where \"one of the words significantly prefers a particular lexical re-alization of the concept the other represents.\"", "labels": [], "entities": []}, {"text": "To the best of our knowledge, however, non-substitutability (with near synonyms) or in other words collocational weight has never been explicitly and empirically tested.", "labels": [], "entities": []}, {"text": "In this work, we present two models that partially, and fully, model collocational weight, and investigate its effects on extraction of MWEs.", "labels": [], "entities": []}], "datasetContent": [{"text": "In order to test our hypotheses, we implement the two models described above and two baselines, and run a comparative evaluation.", "labels": [], "entities": []}, {"text": "We divide our data into two subsets: development and test sets.", "labels": [], "entities": []}, {"text": "The evaluation is carried out in two phases.", "labels": [], "entities": []}, {"text": "In the first phase we perform model selection and find the optimal parameters for various models on the development set.", "labels": [], "entities": [{"text": "model selection", "start_pos": 30, "end_pos": 45, "type": "TASK", "confidence": 0.7291452884674072}]}, {"text": "In the second phase we evaluate the selected models with optimal parameters on the test set, which remains unseen by the models up to this phase.", "labels": [], "entities": []}, {"text": "We implement the following two baselines: (1) Multinomial likelihood, which calculates the probability of the observed contingency table fora given pair under the null hypothesis of independence.", "labels": [], "entities": [{"text": "Multinomial likelihood", "start_pos": 46, "end_pos": 68, "type": "METRIC", "confidence": 0.7148509323596954}]}, {"text": "(2) Mutual information, which calculates the mutual depen-dency of words of a co-occurrence, and has been proved efficient in identification and extraction of MWEs.", "labels": [], "entities": [{"text": "identification and extraction of MWEs", "start_pos": 126, "end_pos": 163, "type": "TASK", "confidence": 0.6875951290130615}]}, {"text": "With respect to the range of scores, we set and alter a threshold for multinomial likelihood (M.N.L hereafter) and mutual information (M.I. hereafter).", "labels": [], "entities": []}, {"text": "Pairs that obtain a score above the threshold are considered MWE, and pairs that obtain a score below the threshold are considered non-MWE.", "labels": [], "entities": [{"text": "MWE", "start_pos": 61, "end_pos": 64, "type": "METRIC", "confidence": 0.48761484026908875}]}, {"text": "illustrates the precisionrecall curve for our models and the baselines on the development set.", "labels": [], "entities": [{"text": "precisionrecall curve", "start_pos": 16, "end_pos": 37, "type": "METRIC", "confidence": 0.9767552018165588}]}, {"text": "The two baseline models i.e., M.N.L. and M.I. reach a high precision only at the cost of a dramatic loss in recall.", "labels": [], "entities": [{"text": "M.N.L.", "start_pos": 30, "end_pos": 36, "type": "DATASET", "confidence": 0.7874854803085327}, {"text": "precision", "start_pos": 59, "end_pos": 68, "type": "METRIC", "confidence": 0.9988918900489807}, {"text": "recall", "start_pos": 108, "end_pos": 114, "type": "METRIC", "confidence": 0.9986951947212219}]}, {"text": "They behave similarly, however, M.I. in general performs better.", "labels": [], "entities": []}, {"text": "M 2 clearly performs better compare to all other models.", "labels": [], "entities": []}, {"text": "It reaches a high precision and recall, however, its precision declines rather quickly when recall increases.", "labels": [], "entities": [{"text": "precision", "start_pos": 18, "end_pos": 27, "type": "METRIC", "confidence": 0.9995037317276001}, {"text": "recall", "start_pos": 32, "end_pos": 38, "type": "METRIC", "confidence": 0.9996193647384644}, {"text": "precision", "start_pos": 53, "end_pos": 62, "type": "METRIC", "confidence": 0.9995914101600647}, {"text": "recall", "start_pos": 92, "end_pos": 98, "type": "METRIC", "confidence": 0.9992026686668396}]}, {"text": "M 1 shows a more steady behaviour in the sense that reaching a higher recall doesn't significantly impact its precision.", "labels": [], "entities": [{"text": "recall", "start_pos": 70, "end_pos": 76, "type": "METRIC", "confidence": 0.9991353154182434}, {"text": "precision", "start_pos": 110, "end_pos": 119, "type": "METRIC", "confidence": 0.9985446929931641}]}, {"text": "shows how F 1 score changes for various models when changing parameters in order to go from high precision to high recall.", "labels": [], "entities": [{"text": "F 1 score", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9728450775146484}, {"text": "precision", "start_pos": 97, "end_pos": 106, "type": "METRIC", "confidence": 0.9928943514823914}, {"text": "recall", "start_pos": 115, "end_pos": 121, "type": "METRIC", "confidence": 0.9951007962226868}]}, {"text": "M 1 and M 2 constantly have a higher F 1 score, where M.I. and M.N.L. start off with a low score and reach a score which is comparable with that of the other models.", "labels": [], "entities": [{"text": "F 1 score", "start_pos": 37, "end_pos": 46, "type": "METRIC", "confidence": 0.9911983609199524}]}, {"text": "Out of the four tested models, with respect to F 1 scores, we select M 1 , M 2 , and M.I. for further experiments.", "labels": [], "entities": [{"text": "F 1 scores", "start_pos": 47, "end_pos": 57, "type": "METRIC", "confidence": 0.9622358083724976}]}, {"text": "We set the relevant parameters to optimal values 2 (obtained by looking at the highest F 1 scores) and run the next experiments on the test set, which has remained unseen by the models up to this  point.", "labels": [], "entities": [{"text": "F 1 scores", "start_pos": 87, "end_pos": 97, "type": "METRIC", "confidence": 0.9415971636772156}]}, {"text": "shows the result of these experiments.", "labels": [], "entities": []}, {"text": "The performance of all three models on the test set is consistent with their performance on the development set.", "labels": [], "entities": []}, {"text": "M 2 reaches the highest precision and F 1 score.", "labels": [], "entities": [{"text": "precision", "start_pos": 24, "end_pos": 33, "type": "METRIC", "confidence": 0.9995371103286743}, {"text": "F 1 score", "start_pos": 38, "end_pos": 47, "type": "METRIC", "confidence": 0.9849703311920166}]}, {"text": "M.I. has the highest recall but a low precision, and M 1 has a high recall and a reasonable but not very high precision.: Evaluation results in terms of precision, recall and F 1 score for the three selected models.", "labels": [], "entities": [{"text": "M.I.", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.9461264610290527}, {"text": "recall", "start_pos": 21, "end_pos": 27, "type": "METRIC", "confidence": 0.999233603477478}, {"text": "precision", "start_pos": 38, "end_pos": 47, "type": "METRIC", "confidence": 0.9981381893157959}, {"text": "recall", "start_pos": 68, "end_pos": 74, "type": "METRIC", "confidence": 0.9987082481384277}, {"text": "precision.", "start_pos": 110, "end_pos": 120, "type": "METRIC", "confidence": 0.9973583817481995}, {"text": "precision", "start_pos": 153, "end_pos": 162, "type": "METRIC", "confidence": 0.999444305896759}, {"text": "recall", "start_pos": 164, "end_pos": 170, "type": "METRIC", "confidence": 0.9995077848434448}, {"text": "F 1 score", "start_pos": 175, "end_pos": 184, "type": "METRIC", "confidence": 0.9885436097780863}]}], "tableCaptions": [{"text": " Table 2: Evaluation results in terms of precision, recall  and F 1 score for the three selected models.", "labels": [], "entities": [{"text": "precision", "start_pos": 41, "end_pos": 50, "type": "METRIC", "confidence": 0.999772846698761}, {"text": "recall", "start_pos": 52, "end_pos": 58, "type": "METRIC", "confidence": 0.9998076558113098}, {"text": "F 1 score", "start_pos": 64, "end_pos": 73, "type": "METRIC", "confidence": 0.9916962186495463}]}]}