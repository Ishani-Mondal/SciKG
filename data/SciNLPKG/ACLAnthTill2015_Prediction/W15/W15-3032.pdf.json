{"title": [{"text": "Results of the WMT15 Tuning Shared Task", "labels": [], "entities": [{"text": "WMT15 Tuning Shared Task", "start_pos": 15, "end_pos": 39, "type": "TASK", "confidence": 0.7074415534734726}]}], "abstractContent": [{"text": "This paper presents the results of the WMT15 Tuning Shared Task.", "labels": [], "entities": [{"text": "WMT15 Tuning Shared Task", "start_pos": 39, "end_pos": 63, "type": "TASK", "confidence": 0.7874326407909393}]}, {"text": "We provided the participants of this task with a complete machine translation system and asked them to tune its internal parameters (feature weights).", "labels": [], "entities": [{"text": "machine translation", "start_pos": 58, "end_pos": 77, "type": "TASK", "confidence": 0.722204864025116}]}, {"text": "The tuned systems were used to translate the test set and the outputs were manually ranked for translation quality.", "labels": [], "entities": []}, {"text": "We received 4 submissions in the English-Czech and 6 in the Czech-English translation direction.", "labels": [], "entities": []}, {"text": "In addition, we ran 3 baseline setups, tuning the parameters with standard optimizers for BLEU score.", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 90, "end_pos": 100, "type": "METRIC", "confidence": 0.9699185192584991}]}], "introductionContent": [{"text": "Almost all modern statistical machine translation (SMT) systems internally consider translation candidates from several aspects.", "labels": [], "entities": [{"text": "statistical machine translation (SMT)", "start_pos": 18, "end_pos": 55, "type": "TASK", "confidence": 0.7857579787572225}]}, {"text": "Some of these aspects can be very simple and one parameter is sufficient to capture them, such as the word penalty incurred for every word produced or the phrase penalty controlling whether the sentence should be translated in fewer or more independent phrases, leading to more or less word-for-word translation.", "labels": [], "entities": [{"text": "word penalty incurred", "start_pos": 102, "end_pos": 123, "type": "METRIC", "confidence": 0.9050591190656027}, {"text": "word-for-word translation", "start_pos": 286, "end_pos": 311, "type": "TASK", "confidence": 0.7381189465522766}]}, {"text": "Other aspects try to assess e.g. the fidelity of the translation, the fluency of the output or the amount of reordering.", "labels": [], "entities": []}, {"text": "These are far more complex and formally captured in a model such as the translation model or language model.", "labels": [], "entities": []}, {"text": "Both the simple penalties as well as the scores from the more complex models are called features and need to be combined to a single score to allow for ranking of translation candidates.", "labels": [], "entities": []}, {"text": "This is usually done using a linear combination of the scores: where e and fare the candidate translation and the source, respectively, and h m (\u00b7, \u00b7) is one of the M penalties or models.", "labels": [], "entities": []}, {"text": "The tuned parameters are \u03bb m \u2208 R, called feature weights.", "labels": [], "entities": []}, {"text": "Feature weights have a tremendous effect on the final translation quality.", "labels": [], "entities": []}, {"text": "For instance the system can produce extremely long outputs, fabulating words just in order to satisfy a negativelyweighted word penalty, i.e. a bonus for each word produced.", "labels": [], "entities": []}, {"text": "An inherent part of the preparation of MT systems is thus some optimization of the weight settings.", "labels": [], "entities": [{"text": "MT", "start_pos": 39, "end_pos": 41, "type": "TASK", "confidence": 0.9917553663253784}]}, {"text": "If we had to set the weights manually, we would have to try a few configurations and pick one that leads to reasonable outputs.", "labels": [], "entities": []}, {"text": "The common practice is to use an optimization algorithm that examines many settings, evaluating the produced translations automatically against reference translations using some evaluation measure (traditionally called \"metric\" in the MT field).", "labels": [], "entities": []}, {"text": "In short, the optimizer tunes model weights so that the final combined model score correlates with the metric score.", "labels": [], "entities": []}, {"text": "The metric score, in turn, is designed to correlate well with human judgements of translation quality, see Stanojevi\u00b4c  and the previous papers summarizing WMT metrics tasks.", "labels": [], "entities": [{"text": "WMT metrics", "start_pos": 156, "end_pos": 167, "type": "TASK", "confidence": 0.8830961287021637}]}, {"text": "However, a metric that correlates well with humans on final output quality may not be usable in weight optimization for various technical reasons.", "labels": [], "entities": [{"text": "weight optimization", "start_pos": 96, "end_pos": 115, "type": "TASK", "confidence": 0.7463528215885162}]}, {"text": "BLEU () was shown to be very hard to surpass and this is also confirmed by the results of the invitation-only WMT11 Tunable Metrics Task 1 . Note however, that some metrics have been successfully used for system tuning ().", "labels": [], "entities": [{"text": "BLEU", "start_pos": 0, "end_pos": 4, "type": "METRIC", "confidence": 0.9894042015075684}, {"text": "WMT11 Tunable Metrics Task 1", "start_pos": 110, "end_pos": 138, "type": "DATASET", "confidence": 0.6736991763114929}, {"text": "system tuning", "start_pos": 205, "end_pos": 218, "type": "TASK", "confidence": 0.7881320416927338}]}, {"text": "The aim of the WMT15 Tuning Task 2 is to attract attention to the exploration of all the three: Out of vocabulary word counts aspects of model optimization: (1) the set of features in the model, (2) optimization algorithm, and (3) MT quality metric used in optimization.", "labels": [], "entities": [{"text": "WMT15 Tuning Task", "start_pos": 15, "end_pos": 32, "type": "TASK", "confidence": 0.6609988609949747}, {"text": "model optimization", "start_pos": 137, "end_pos": 155, "type": "TASK", "confidence": 0.7576009631156921}, {"text": "MT", "start_pos": 231, "end_pos": 233, "type": "TASK", "confidence": 0.8146491050720215}]}, {"text": "For, we provide a fixed set of \"dense\" features and also allow participants to add additional \"sparse\" features.", "labels": [], "entities": []}, {"text": "For (2), the optimization algorithm, task participants are free to use one of the available algorithms for direct loss optimization, which are usually capable of optimizing only a dozen of features, or one of the optimizers handling also very large sets of features, or a custom algorithm.", "labels": [], "entities": [{"text": "direct loss optimization", "start_pos": 107, "end_pos": 131, "type": "TASK", "confidence": 0.6888018449147543}]}, {"text": "And finally for (3), participants can use any established evaluation metric or a custom one.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 4: Results on Czech-English tuning", "labels": [], "entities": [{"text": "Czech-English tuning", "start_pos": 21, "end_pos": 41, "type": "DATASET", "confidence": 0.8954291939735413}]}, {"text": " Table 5: Results on English-Czech tuning", "labels": [], "entities": [{"text": "English-Czech tuning", "start_pos": 21, "end_pos": 41, "type": "DATASET", "confidence": 0.8454732000827789}]}, {"text": " Table 6: Detailed scores and weights of Czech- to-English (left) and English-to-Czech (right) sys- tems.", "labels": [], "entities": [{"text": "Detailed", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9365043044090271}]}, {"text": " Table 7: Loadings (correlations) of each compo- nent with each feature function for English-Czech", "labels": [], "entities": []}]}