{"title": [{"text": "Rhetorical Figure Detection: the Case of Chiasmus", "labels": [], "entities": [{"text": "Rhetorical Figure Detection", "start_pos": 0, "end_pos": 27, "type": "TASK", "confidence": 0.8069108724594116}, {"text": "Chiasmus", "start_pos": 41, "end_pos": 49, "type": "TASK", "confidence": 0.2992144525051117}]}], "abstractContent": [{"text": "We propose an approach to detecting the rhetorical figure called chiasmus, which involves the repetition of a pair of words in reverse order, as in \"all for one, one for all\".", "labels": [], "entities": [{"text": "detecting the rhetorical figure", "start_pos": 26, "end_pos": 57, "type": "TASK", "confidence": 0.8076571971178055}]}, {"text": "Although repetitions of words are common in natural language, true instances of chiasmus are rare, and the question is therefore whether a computer can effectively distinguish a chias-mus from a random criss-cross pattern.", "labels": [], "entities": []}, {"text": "We argue that chiasmus should be treated as a graded phenomenon, which leads to the design of an engine that extracts all criss-cross patterns and ranks them on a scale from pro-totypical chiasmi to less and less likely instances.", "labels": [], "entities": []}, {"text": "Using an evaluation inspired by information retrieval, we demonstrate that our system achieves an average precision of 61%.", "labels": [], "entities": [{"text": "precision", "start_pos": 106, "end_pos": 115, "type": "METRIC", "confidence": 0.9980410933494568}]}, {"text": "As a by-product of the evaluation we also construct the first annotated corpus of chiasmi.", "labels": [], "entities": []}], "introductionContent": [{"text": "Natural language processing (NLP) automates different tasks: translation, information retrieval, genre classification.", "labels": [], "entities": [{"text": "Natural language processing (NLP", "start_pos": 0, "end_pos": 32, "type": "TASK", "confidence": 0.7044826567173004}, {"text": "translation", "start_pos": 61, "end_pos": 72, "type": "TASK", "confidence": 0.9718877673149109}, {"text": "information retrieval", "start_pos": 74, "end_pos": 95, "type": "TASK", "confidence": 0.7699936330318451}, {"text": "genre classification", "start_pos": 97, "end_pos": 117, "type": "TASK", "confidence": 0.7903502285480499}]}, {"text": "Today, these technologies definitely provide valuable assistance for humans even if they are not perfect.", "labels": [], "entities": []}, {"text": "But the automatic tools become inappropriate to use when we need to generate, translate or evaluate texts with stylistic quality, such as great political discourse, novels, or pleadings.", "labels": [], "entities": []}, {"text": "Indeed, one is reluctant to trust computer assistance when it comes to judging the rhetoric of a text.", "labels": [], "entities": [{"text": "judging the rhetoric of a text", "start_pos": 71, "end_pos": 101, "type": "TASK", "confidence": 0.9254749019940695}]}, {"text": "As expressed by: Too much attention has been placed on semantics at the expense of rhetoric (including stylistics, pragmatics, and sentiment).", "labels": [], "entities": []}, {"text": "While computational approaches to language have occasionally deployed the word 'rhetoric', even in quite central ways (such as), the deep resources of the millenia-long research tradition of rhetoric have only been tapped to a vanishingly small degree.", "labels": [], "entities": []}, {"text": "Even though the situation has improved slightly during the last years (see Section 2), the gap underlined by Harris and DiMarco in the treatment of traditional rhetoric is still important.", "labels": [], "entities": []}, {"text": "This study is a contribution aimed at filling this gap.", "labels": [], "entities": []}, {"text": "We will focus on the task of automatically identifying a rhetorical device already studied in the first century before Christ by Quintilian (Greene, 2012, art.", "labels": [], "entities": [{"text": "automatically identifying a rhetorical device", "start_pos": 29, "end_pos": 74, "type": "TASK", "confidence": 0.654058039188385}]}, {"text": "antimetabole), but rarely studied in computational linguistics: the chiasmus.", "labels": [], "entities": []}, {"text": "Chiasmi area family of figures that consist in repeating linguistic elements in reverse order.", "labels": [], "entities": []}, {"text": "It is named by the classics after the Greek letter \u03c7 because of the cross this letter symbolises (see.", "labels": [], "entities": []}, {"text": "If the name 'chiasmus' seems specific to rhetorical studies, the figure in itself is known to everybody through proverbs like (1) or quotations like (2).", "labels": [], "entities": []}, {"text": "(1) Live not to eat, but eat to live.", "labels": [], "entities": []}, {"text": "(2) Ask not what your country can do for you; ask what you can do for your country.", "labels": [], "entities": []}, {"text": "One can talk about chiasmus of letters, sounds, concepts or even syntactic structures as in (3).", "labels": [], "entities": []}, {"text": "(3) Each throat was parched, and glazed each eye.", "labels": [], "entities": []}, {"text": "Strictly speaking, we will only be concerned with one type of chiasmus: the chiasmus of identical words (also called antimetabole) or of identical lemmas, as exemplified in and, respectively.", "labels": [], "entities": []}, {"text": "(4) A comedian does funny things, a good comedian does things funny.", "labels": [], "entities": []}, {"text": "(5) A wit with dunces and a dunce with wits From now on, for the sake of simplicity, we will restrict the term 'chiasmus' to exclusively chiasmus of words that share identity of lemma.", "labels": [], "entities": [{"text": "simplicity", "start_pos": 73, "end_pos": 83, "type": "METRIC", "confidence": 0.9757732152938843}]}, {"text": "We see different reasons why NLP should pay attention to chiasmi.", "labels": [], "entities": [{"text": "NLP", "start_pos": 29, "end_pos": 32, "type": "DATASET", "confidence": 0.8247836232185364}]}, {"text": "First, it maybe useful fora literary analysis: tools for supporting studies of literature exist but mostly belong to textometry.", "labels": [], "entities": [{"text": "literary analysis", "start_pos": 28, "end_pos": 45, "type": "TASK", "confidence": 0.7533144056797028}]}, {"text": "Thus, they mainly identify word frequency and some syntactic patterns, not figures of speech.", "labels": [], "entities": []}, {"text": "Second, the chiasmus has interesting linguistic properties: it expresses semantic inversion thanks to syntax inversion, as in (2) above.", "labels": [], "entities": []}, {"text": "points out that chiasmus can be used to emphasize antagonism as in (6) as well as reciprocity as in (7).", "labels": [], "entities": []}], "datasetContent": [{"text": "In order to evaluate our features we perform four experiments.", "labels": [], "entities": []}, {"text": "We start with only the basic features.", "labels": [], "entities": []}, {"text": "Then, for each new experiment, we add the next group of features in the same order as in (size, similarity and lexical clues).", "labels": [], "entities": []}, {"text": "Thus the fourth and last experiment (called '+Lexical clues') accumulates all the features.", "labels": [], "entities": []}, {"text": "Each time we run an experiment on the test set, we manually annotate as True or False the top 200 hits given by the machine.", "labels": [], "entities": [{"text": "True", "start_pos": 72, "end_pos": 76, "type": "METRIC", "confidence": 0.9594386219978333}, {"text": "False", "start_pos": 80, "end_pos": 85, "type": "METRIC", "confidence": 0.824592649936676}]}, {"text": "Thanks to this manual annotation, we present the evaluation in a precision-recall graph).", "labels": [], "entities": [{"text": "precision-recall", "start_pos": 65, "end_pos": 81, "type": "METRIC", "confidence": 0.9950577020645142}]}, {"text": "In, recall is based on 19 true positives.", "labels": [], "entities": [{"text": "recall", "start_pos": 4, "end_pos": 10, "type": "METRIC", "confidence": 0.9991311430931091}]}, {"text": "They were found through the annotation of the 200 top hits of our 4 different experiments.", "labels": [], "entities": []}, {"text": "On this graph the curves end when the position 200 is reach.", "labels": [], "entities": []}, {"text": "For instance, the curve of '+Size' experiment stops at 7% precision because at candidates number 200 only 14 chiasmi were found.", "labels": [], "entities": [{"text": "precision", "start_pos": 58, "end_pos": 67, "type": "METRIC", "confidence": 0.9993866682052612}]}, {"text": "The 'basic' experiment is not present because of too low precision.", "labels": [], "entities": [{"text": "precision", "start_pos": 57, "end_pos": 66, "type": "METRIC", "confidence": 0.9975855350494385}]}, {"text": "Indeed, 16 out of the 19 true positives were ranked by the 'basic' features as first but within a tie of 1180 other criss-cross patterns (less than 2% precision).", "labels": [], "entities": [{"text": "precision", "start_pos": 151, "end_pos": 160, "type": "METRIC", "confidence": 0.9980644583702087}]}, {"text": "When we add size features, the algorithm outputs the majority of the chiasmi within 200 hits (14 out of 19, or a recall of 74%), but the average precision is below 35%).", "labels": [], "entities": [{"text": "recall", "start_pos": 113, "end_pos": 119, "type": "METRIC", "confidence": 0.9993677735328674}, {"text": "precision", "start_pos": 145, "end_pos": 154, "type": "METRIC", "confidence": 0.9985988736152649}]}, {"text": "The recall can get significantly better.", "labels": [], "entities": [{"text": "recall", "start_pos": 4, "end_pos": 10, "type": "METRIC", "confidence": 0.9994639754295349}]}, {"text": "We notice, indeed, a significant progression of the number of chiasmi if we use N -gram similarity features (17 out of 19 chiasmi).", "labels": [], "entities": []}, {"text": "Finally the lexical clues do not permit us to find more chiasmi (the maximum recall is still 90% for both the third and the fourth experiment) but the precision improves slightly (plus 9% for '+Lexical clues' experiment).", "labels": [], "entities": [{"text": "recall", "start_pos": 77, "end_pos": 83, "type": "METRIC", "confidence": 0.995591938495636}, {"text": "precision", "start_pos": 151, "end_pos": 160, "type": "METRIC", "confidence": 0.9995412826538086}]}, {"text": "We never reach 100% recall.", "labels": [], "entities": [{"text": "recall", "start_pos": 20, "end_pos": 26, "type": "METRIC", "confidence": 0.9288730621337891}]}, {"text": "This means that 2 of the 19 chiasmi we found were not identifiable by the best algorithm ('+Lexical clues').", "labels": [], "entities": []}, {"text": "They are ranked more highly by the non-optimal algorithms.", "labels": [], "entities": []}, {"text": "It can be that our features are too shallow, but it can be as well that the current weights are not optimal.", "labels": [], "entities": []}, {"text": "Since our tuning is manual, we have not tried every combination of weights possible.", "labels": [], "entities": []}, {"text": "Chiasmus is a graded phenomenon, our manual annotation ranks three levels of chiasmi: true, bordeline, and false cases.", "labels": [], "entities": []}, {"text": "Borderline cases are by definition controversial, thus we do not count them in our table of results.", "labels": [], "entities": []}, {"text": "Duplicates are not counted either.", "labels": [], "entities": []}, {"text": "Comparing our model to previous research is not straightforward.", "labels": [], "entities": []}, {"text": "Our output is ranked, unlike and.", "labels": [], "entities": []}, {"text": "We know already that Gawryjolek (2009) extracts every crisscross pattern with no exception and thus obtains 100% recall but fora precision close to 0% (see Section 2).", "labels": [], "entities": [{"text": "recall", "start_pos": 113, "end_pos": 119, "type": "METRIC", "confidence": 0.9978082776069641}, {"text": "precision", "start_pos": 129, "end_pos": 138, "type": "METRIC", "confidence": 0.998301088809967}]}, {"text": "We run the experiment of Hromada (2011) on our test set.", "labels": [], "entities": [{"text": "Hromada (2011)", "start_pos": 25, "end_pos": 39, "type": "DATASET", "confidence": 0.7074194252490997}]}, {"text": "6 It outputs 6 true positives fora total of only 9 candidates.", "labels": [], "entities": []}, {"text": "In order to give a fair comparison with Hromada (2011), the 3 systems will be compared only for the nine first candidates We invite our reader to read them in Appendix B and at http://stp.lingfil.uu.se/~marie/chiasme.htm For example, if the machine extracts both: \"All for one, one for all\", \"All for one, one for all\" we take into account only the second case even if both extracts belong to a chiasmus.", "labels": [], "entities": [{"text": "Appendix", "start_pos": 159, "end_pos": 167, "type": "METRIC", "confidence": 0.9049338102340698}]}, {"text": "Program furnished by D. Hromada in the email of the 10th of February.", "labels": [], "entities": [{"text": "D. Hromada in the email of the 10th of February", "start_pos": 21, "end_pos": 68, "type": "DATASET", "confidence": 0.7477790117263794}]}, {"text": "We provide this regex at http://stp.lingfil.uu.se/~marie/chiasme.htm.", "labels": [], "entities": []}, {"text": "Finally, the efficiency: our algorithm takes less than three minutes and a half for one million words (214 seconds).", "labels": [], "entities": []}, {"text": "It is three times more than Hromada (2011) (78 seconds per million words) but still reasonable.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: The four groups of features used to rank chiasmus candidates", "labels": [], "entities": []}, {"text": " Table 2: Average precision, and precision at a given top  rank, for each experiment.", "labels": [], "entities": [{"text": "Average", "start_pos": 10, "end_pos": 17, "type": "METRIC", "confidence": 0.973124086856842}, {"text": "precision", "start_pos": 18, "end_pos": 27, "type": "METRIC", "confidence": 0.8866407871246338}, {"text": "precision", "start_pos": 33, "end_pos": 42, "type": "METRIC", "confidence": 0.9995073080062866}]}, {"text": " Table 3: Precision, recall, and F-measure at candidate  number 9. Comparison with previous works.", "labels": [], "entities": [{"text": "Precision", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9954723119735718}, {"text": "recall", "start_pos": 21, "end_pos": 27, "type": "METRIC", "confidence": 0.9973917007446289}, {"text": "F-measure", "start_pos": 33, "end_pos": 42, "type": "METRIC", "confidence": 0.9966773986816406}]}]}