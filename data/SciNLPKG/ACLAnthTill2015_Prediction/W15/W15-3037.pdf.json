{"title": [{"text": "QUality Estimation from ScraTCH (QUETCH): Deep Learning for Word-level Translation Quality Estimation", "labels": [], "entities": [{"text": "Word-level Translation Quality Estimation", "start_pos": 60, "end_pos": 101, "type": "TASK", "confidence": 0.7242769747972488}]}], "abstractContent": [{"text": "This paper describes the system submitted by the University of Heidelberg to the Shared Task on Word-level Quality Estimation at the 2015 Workshop on Statistical Machine Translation.", "labels": [], "entities": [{"text": "Shared Task on Word-level Quality Estimation at the 2015 Workshop on Statistical Machine Translation", "start_pos": 81, "end_pos": 181, "type": "TASK", "confidence": 0.7583888726575034}]}, {"text": "The submitted system combines a continuous space deep neural network, that learns a bilingual feature representation from scratch, with a linear combination of the manually defined baseline features provided by the task organizers.", "labels": [], "entities": []}, {"text": "A combination of these orthogonal information sources shows significant improvements over the combined systems, and produces very competitive F 1-scores for predicting word-level translation quality.", "labels": [], "entities": [{"text": "F 1-scores", "start_pos": 142, "end_pos": 152, "type": "METRIC", "confidence": 0.965636670589447}, {"text": "predicting word-level translation quality", "start_pos": 157, "end_pos": 198, "type": "TASK", "confidence": 0.8120027035474777}]}], "introductionContent": [{"text": "This paper describes the University of Heidelberg submission to the Shared Task on Wordlevel Quality Estimation (QE Task 2) at the 2015 Workshop on Statistical Machine Translation (WMT15).", "labels": [], "entities": [{"text": "Shared Task on Wordlevel Quality Estimation (QE Task 2) at the 2015 Workshop on Statistical Machine Translation (WMT15)", "start_pos": 68, "end_pos": 187, "type": "TASK", "confidence": 0.7718009163032878}]}, {"text": "The task consists of predicting the word-level quality level (\"OK\"/\"BAD\") of English-to-Spanish machine translations, without the use of human references, and without insight into the translation derivations, that is, by treating the Machine Translation (MT) system that produced the translations as a black box.", "labels": [], "entities": [{"text": "word-level quality level (\"OK\"/\"BAD\")", "start_pos": 36, "end_pos": 73, "type": "METRIC", "confidence": 0.7552704587578773}, {"text": "Machine Translation (MT)", "start_pos": 234, "end_pos": 258, "type": "TASK", "confidence": 0.8333872795104981}]}, {"text": "The task organizers provided training and development data comprising tokenized MT outputs that were automatically annotated for errors as edit operations (replacements, insertions, or deletions) with respect to human post-edits ().", "labels": [], "entities": [{"text": "MT outputs", "start_pos": 80, "end_pos": 90, "type": "TASK", "confidence": 0.8694639801979065}]}, {"text": "Furthermore, a set of 25 baseline features that operate on source and target translation, but do not use features of the SMT pipeline that produced the translations, was provided.", "labels": [], "entities": [{"text": "SMT pipeline", "start_pos": 121, "end_pos": 133, "type": "TASK", "confidence": 0.848977267742157}]}, {"text": "Even though the distribution of binary labels is skewed towards \"OK\" labels, even more so than in the previous QE task at WMT14 1 , the most common approach is to treat the problem as a supervised classification task.", "labels": [], "entities": [{"text": "WMT14 1", "start_pos": 122, "end_pos": 129, "type": "DATASET", "confidence": 0.7439493238925934}]}, {"text": "Furthermore, most approaches rely on manually designed features, including source and target contexts, alignments, and generalizations by linguistic categories (POS, syntactic dependency links, WordNet senses) as reported by, similar to the 25 feature templates provided by the organizers.", "labels": [], "entities": []}, {"text": "We apply the framework of to learn bilingual correspondences \"from scratch\", i.e. from raw input words.", "labels": [], "entities": []}, {"text": "To this aim, a continuous space deep neural network is pre-trained by initializing the lookup-table with distributed word representations (, and fine-tuned for the QE classification task by back-propagating word-level prediction errors using stochastic gradient descent.", "labels": [], "entities": [{"text": "QE classification task", "start_pos": 164, "end_pos": 186, "type": "TASK", "confidence": 0.8602570096651713}]}, {"text": "Moreover, we train a linear combination of the manually defined baseline features provided by the task organizers.", "labels": [], "entities": []}, {"text": "A combination of the orthogonal information based on the continuous space features and the manually chosen baseline features shows significant improvements over the combined systems, and produces very competitive F 1 scores for predicting word-level translation quality.", "labels": [], "entities": [{"text": "F 1 scores", "start_pos": 213, "end_pos": 223, "type": "METRIC", "confidence": 0.9770222902297974}, {"text": "predicting word-level translation quality", "start_pos": 228, "end_pos": 269, "type": "TASK", "confidence": 0.8055535554885864}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: QUETCH results on WMT14 task 2 test data un- der different configurations: (v)anilla system, (p)retraining  of word embeddings, (a)lignments from an SMT system.", "labels": [], "entities": [{"text": "QUETCH", "start_pos": 10, "end_pos": 16, "type": "METRIC", "confidence": 0.6786966919898987}, {"text": "WMT14 task 2 test data", "start_pos": 28, "end_pos": 50, "type": "DATASET", "confidence": 0.8105838418006897}, {"text": "SMT", "start_pos": 159, "end_pos": 162, "type": "TASK", "confidence": 0.9634425044059753}]}, {"text": " Table 2: Winning submissions of the WMT14 Quality Esti- mation Task 2 (Bojar et al., 2014).", "labels": [], "entities": [{"text": "WMT14 Quality Esti- mation Task 2", "start_pos": 37, "end_pos": 70, "type": "DATASET", "confidence": 0.5915550674710955}]}, {"text": " Table 4: Official test results on WMT15 task 2 for word level  translation quality. The All F1-score is the weighted aver- age of BAD F1 and OK F1, where the weights are deter- mined by the frequency of the classes in the test data. The  UAlacant/OnLine-SBI-Baseline and the QUETCH+ predic- tions show no significant difference at p=0.05 and are both  announced official winners.", "labels": [], "entities": [{"text": "WMT15 task 2", "start_pos": 35, "end_pos": 47, "type": "TASK", "confidence": 0.5774330298105875}, {"text": "word level  translation quality", "start_pos": 52, "end_pos": 83, "type": "TASK", "confidence": 0.7271910607814789}, {"text": "All F1-score", "start_pos": 89, "end_pos": 101, "type": "METRIC", "confidence": 0.85430708527565}, {"text": "aver- age", "start_pos": 118, "end_pos": 127, "type": "METRIC", "confidence": 0.8657246232032776}, {"text": "BAD F1", "start_pos": 131, "end_pos": 137, "type": "METRIC", "confidence": 0.9746484756469727}, {"text": "OK F1", "start_pos": 142, "end_pos": 147, "type": "METRIC", "confidence": 0.7998757064342499}]}]}