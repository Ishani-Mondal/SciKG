{"title": [{"text": "Toshiba MT System Description for the WAT2015 Workshop", "labels": [], "entities": [{"text": "Toshiba MT System Description", "start_pos": 0, "end_pos": 29, "type": "DATASET", "confidence": 0.7239760383963585}, {"text": "WAT2015", "start_pos": 38, "end_pos": 45, "type": "TASK", "confidence": 0.6170563101768494}]}], "abstractContent": [{"text": "This paper provides the system description of Toshiba Machine Translation System for the 2nd Workshop on Asian Translation (WAT2015).", "labels": [], "entities": [{"text": "Toshiba Machine Translation", "start_pos": 46, "end_pos": 73, "type": "TASK", "confidence": 0.7536332607269287}, {"text": "2nd Workshop on Asian Translation (WAT2015)", "start_pos": 89, "end_pos": 132, "type": "TASK", "confidence": 0.6664010658860207}]}, {"text": "We participated in all tasks that consist of \"sci-entific papers subtask\" and \"patents subtask\".", "labels": [], "entities": []}, {"text": "We submitted statistically post edited translation (SPE) results based on our rule based translation system and SMT for each language pair.", "labels": [], "entities": [{"text": "statistically post edited translation (SPE)", "start_pos": 13, "end_pos": 56, "type": "TASK", "confidence": 0.7655266863959176}, {"text": "SMT", "start_pos": 112, "end_pos": 115, "type": "TASK", "confidence": 0.8582184314727783}]}, {"text": "In addition, we submitted system combination results between SPE and SMT with a recurrent neural language model (RNNLM).", "labels": [], "entities": [{"text": "SPE", "start_pos": 61, "end_pos": 64, "type": "TASK", "confidence": 0.8264173269271851}, {"text": "SMT", "start_pos": 69, "end_pos": 72, "type": "TASK", "confidence": 0.9496724605560303}]}, {"text": "In experimental results, the system combination achieved higher BLEU scores than single system with reranking.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 64, "end_pos": 68, "type": "METRIC", "confidence": 0.9995275735855103}]}, {"text": "We also obtained improvements in Chinese translation in crowdsourcing evaluations .", "labels": [], "entities": [{"text": "Chinese translation", "start_pos": 33, "end_pos": 52, "type": "TASK", "confidence": 0.620175838470459}]}], "introductionContent": [{"text": "Recently, statistical machine translation (SMT) has been broadly developed and successfully used in the portion of practicable systems.", "labels": [], "entities": [{"text": "statistical machine translation (SMT)", "start_pos": 10, "end_pos": 47, "type": "TASK", "confidence": 0.8526014884312948}]}, {"text": "However, it is costly to make a large volume of parallel corpora in a wide range of domains for commercial use.", "labels": [], "entities": []}, {"text": "For this reason, we have developed rule based machine translation (RBMT) system using a monolingual corpus in the target language.", "labels": [], "entities": [{"text": "rule based machine translation (RBMT)", "start_pos": 35, "end_pos": 72, "type": "TASK", "confidence": 0.7580389763627734}]}, {"text": "For example, target word selection is possible based on co-occurrence relationship extracted from a monolingual corpus ().", "labels": [], "entities": [{"text": "target word selection", "start_pos": 13, "end_pos": 34, "type": "TASK", "confidence": 0.6223559180895487}]}, {"text": "Furthermore, we have developed a word sense disambiguation based on a monolingual corpus in the target domain, and it has been applied to Japanese-Korean and KoreanJapanese translation systems ().", "labels": [], "entities": [{"text": "word sense disambiguation", "start_pos": 33, "end_pos": 58, "type": "TASK", "confidence": 0.6936109960079193}]}, {"text": "On the other hand, open Asian parallel corpora including ASPEC 1 , NTCIR PatentMT 2 and JPO Patent Corpus 3 are available for the research of machine translation systems.", "labels": [], "entities": [{"text": "NTCIR PatentMT", "start_pos": 67, "end_pos": 81, "type": "DATASET", "confidence": 0.8158967792987823}, {"text": "JPO Patent Corpus 3", "start_pos": 88, "end_pos": 107, "type": "DATASET", "confidence": 0.9217899441719055}, {"text": "machine translation", "start_pos": 142, "end_pos": 161, "type": "TASK", "confidence": 0.8117580711841583}]}, {"text": "By using the parallel corpora, we have confirmed advantages which apply statistical post editing (SPE) to RBMT in domain adaptation.", "labels": [], "entities": [{"text": "domain adaptation", "start_pos": 114, "end_pos": 131, "type": "TASK", "confidence": 0.7843890190124512}]}, {"text": "In the last workshop (), we participated in Japanese-English and Japanese-Chinese tasks with SPE approach and obtained higher evaluation results than RBMT.", "labels": [], "entities": [{"text": "SPE", "start_pos": 93, "end_pos": 96, "type": "METRIC", "confidence": 0.7328652739524841}, {"text": "RBMT", "start_pos": 150, "end_pos": 154, "type": "DATASET", "confidence": 0.7081434726715088}]}, {"text": "Meanwhile, RBMT showed better performance than SPE in the direct and relative comparison . In this workshop (WAT2015), we participated in all tasks including Japanese-English (ja-en), English-Japanese (en-ja), Japanese-Chinese (ja-zh) and ChineseJapanese (zh-ja) for \"scientific paper subtask\", and Chinese-Japanese (JPCzh-ja) and KoreanJapanese (JPCko-ja) for \"patents subtask\".", "labels": [], "entities": [{"text": "RBMT", "start_pos": 11, "end_pos": 15, "type": "METRIC", "confidence": 0.4078308343887329}, {"text": "WAT2015", "start_pos": 109, "end_pos": 116, "type": "DATASET", "confidence": 0.8466464877128601}]}, {"text": "Patents subtask is newly added, and its parallel corpus has 4 sections (Chemistry, Electricity, Mechanical Engineering and Physics).", "labels": [], "entities": []}, {"text": "In all the tasks, we submitted SPE translation results based on our RBMT and SMT.", "labels": [], "entities": [{"text": "SPE translation", "start_pos": 31, "end_pos": 46, "type": "TASK", "confidence": 0.916671484708786}, {"text": "RBMT", "start_pos": 68, "end_pos": 72, "type": "DATASET", "confidence": 0.43492892384529114}, {"text": "SMT", "start_pos": 77, "end_pos": 80, "type": "TASK", "confidence": 0.8634992837905884}]}, {"text": "In addition, we submitted system combination results between SPE and SMT with recurrent neural language model (RNNLM;.", "labels": [], "entities": [{"text": "SPE", "start_pos": 61, "end_pos": 64, "type": "TASK", "confidence": 0.723968505859375}, {"text": "SMT", "start_pos": 69, "end_pos": 72, "type": "TASK", "confidence": 0.939670741558075}]}, {"text": "Section 2 and 3 describe the overview of our systems and some pre/post processing.", "labels": [], "entities": []}, {"text": "The experimental results and official results are shown in Section 4 and 5.", "labels": [], "entities": []}, {"text": "The analysis for the official results is discussed in Section 6 and finally, Section 7 concludes this paper.", "labels": [], "entities": []}, {"text": "As fora contextaware translation, the description was omitted because our baseline system is the same as the last workshop (see ).", "labels": [], "entities": [{"text": "contextaware translation", "start_pos": 8, "end_pos": 32, "type": "TASK", "confidence": 0.7040680944919586}]}], "datasetContent": [{"text": "This section shows experimental results of our translation systems.", "labels": [], "entities": []}, {"text": "show the overall BLEU and RIBES scores for \"scientific papers subtask\" and \"patents subtask\", respectively.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 17, "end_pos": 21, "type": "METRIC", "confidence": 0.9993517994880676}, {"text": "RIBES", "start_pos": 26, "end_pos": 31, "type": "METRIC", "confidence": 0.9924290776252747}]}, {"text": "COMB means results of the system combination and Rerank means results of reranking using RNNLM (100-best for SMT and SPE, 200-best for COMB).", "labels": [], "entities": [{"text": "COMB", "start_pos": 0, "end_pos": 4, "type": "METRIC", "confidence": 0.8398556709289551}, {"text": "Rerank", "start_pos": 49, "end_pos": 55, "type": "METRIC", "confidence": 0.9881518483161926}, {"text": "RNNLM", "start_pos": 89, "end_pos": 94, "type": "DATASET", "confidence": 0.693354606628418}, {"text": "SMT", "start_pos": 109, "end_pos": 112, "type": "TASK", "confidence": 0.9234182834625244}]}, {"text": "In all tasks, SPE improves translation results of RBMT on the BLEU and RIBES.", "labels": [], "entities": [{"text": "SPE", "start_pos": 14, "end_pos": 17, "type": "TASK", "confidence": 0.5034371018409729}, {"text": "RBMT", "start_pos": 50, "end_pos": 54, "type": "TASK", "confidence": 0.6222522258758545}, {"text": "BLEU", "start_pos": 62, "end_pos": 66, "type": "METRIC", "confidence": 0.9903844594955444}, {"text": "RIBES", "start_pos": 71, "end_pos": 76, "type": "DATASET", "confidence": 0.5513004660606384}]}, {"text": "In tasks except JPOko-ja, SPE achieves performance equal to or better than phrase-based SMT.", "labels": [], "entities": [{"text": "SPE", "start_pos": 26, "end_pos": 29, "type": "TASK", "confidence": 0.9076953530311584}, {"text": "SMT", "start_pos": 88, "end_pos": 91, "type": "TASK", "confidence": 0.7125949859619141}]}, {"text": "Moreover, inmost tasks, Rerank improves about 0.3-0.5 BLEU score, and COMB shows better performance than other systems.", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 54, "end_pos": 64, "type": "METRIC", "confidence": 0.9775457978248596}, {"text": "COMB", "start_pos": 70, "end_pos": 74, "type": "METRIC", "confidence": 0.6479713320732117}]}, {"text": "In JPOko-ja, SMT, SPE and COMB show very high performances which are close to 70 BLEU, and SMT with reranking achieves the highest BLEU and RIBES scores.", "labels": [], "entities": [{"text": "JPOko-ja", "start_pos": 3, "end_pos": 11, "type": "DATASET", "confidence": 0.9065905213356018}, {"text": "SMT", "start_pos": 13, "end_pos": 16, "type": "TASK", "confidence": 0.9324594140052795}, {"text": "SPE", "start_pos": 18, "end_pos": 21, "type": "METRIC", "confidence": 0.832514762878418}, {"text": "COMB", "start_pos": 26, "end_pos": 30, "type": "METRIC", "confidence": 0.849063515663147}, {"text": "BLEU", "start_pos": 81, "end_pos": 85, "type": "METRIC", "confidence": 0.9993763566017151}, {"text": "BLEU", "start_pos": 131, "end_pos": 135, "type": "METRIC", "confidence": 0.9993745684623718}, {"text": "RIBES", "start_pos": 140, "end_pos": 145, "type": "METRIC", "confidence": 0.9424607753753662}]}, {"text": "In ja-en, en-ja, ja-zh and zh-ja, more than half of translations selected from SPE and the others selected from SMT.", "labels": [], "entities": [{"text": "SPE", "start_pos": 79, "end_pos": 82, "type": "DATASET", "confidence": 0.6623415350914001}, {"text": "SMT", "start_pos": 112, "end_pos": 115, "type": "DATASET", "confidence": 0.7100125551223755}]}, {"text": "In particular SPE accounted for about 80% translations in ja-en, en-ja and zh-ja.", "labels": [], "entities": [{"text": "SPE", "start_pos": 14, "end_pos": 17, "type": "TASK", "confidence": 0.5272825956344604}]}, {"text": "On the other hand, more than half of translations selected from SMT in JPOzh-ja and JPOko-ja. shows the translation examples that COMB achieves better results than SPE with reranking in sentence-level BLEU.", "labels": [], "entities": [{"text": "SMT", "start_pos": 64, "end_pos": 67, "type": "TASK", "confidence": 0.8558750152587891}, {"text": "JPOzh-ja", "start_pos": 71, "end_pos": 79, "type": "DATASET", "confidence": 0.929682731628418}, {"text": "JPOko-ja.", "start_pos": 84, "end_pos": 93, "type": "DATASET", "confidence": 0.8992725014686584}, {"text": "BLEU", "start_pos": 201, "end_pos": 205, "type": "METRIC", "confidence": 0.9779284000396729}]}, {"text": "Finally, we compared between phrase-based model and hierarchical phrase-based model.", "labels": [], "entities": []}, {"text": "shows comparison in ja-zh task.", "labels": [], "entities": []}, {"text": "In all systems including SPE, hierarchical phrase-based model improves about 0.4 BLEU.", "labels": [], "entities": [{"text": "SPE", "start_pos": 25, "end_pos": 28, "type": "TASK", "confidence": 0.8550997376441956}, {"text": "BLEU", "start_pos": 81, "end_pos": 85, "type": "METRIC", "confidence": 0.9982966780662537}]}, {"text": "We applied hierarchical phrase-based model to ja-zh only, because significant improvements were not confirmed in other language pairs.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Overall BLEU and RIBES scores for \"scientific papers subtask\".", "labels": [], "entities": [{"text": "BLEU", "start_pos": 18, "end_pos": 22, "type": "METRIC", "confidence": 0.9964029788970947}, {"text": "RIBES", "start_pos": 27, "end_pos": 32, "type": "METRIC", "confidence": 0.9923844337463379}]}, {"text": " Table 2: Overall BLEU and RIBES scores for \"patents subtask\".", "labels": [], "entities": [{"text": "BLEU", "start_pos": 18, "end_pos": 22, "type": "METRIC", "confidence": 0.9971338510513306}, {"text": "RIBES", "start_pos": 27, "end_pos": 32, "type": "METRIC", "confidence": 0.992500364780426}]}, {"text": " Table 4: A Comparison of Phrase-based Model.", "labels": [], "entities": []}, {"text": " Table 7: The relationship between automatic  evaluations and human evaluations.", "labels": [], "entities": []}, {"text": " Table 5: Overall official results for \"scientific papers subtask\". B, R and H mean BLEU, RIBES,  HUMAN, respectively. HUMAN was evaluated by 5 evaluators using crowdsorcing.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 84, "end_pos": 88, "type": "METRIC", "confidence": 0.9994935989379883}, {"text": "RIBES", "start_pos": 90, "end_pos": 95, "type": "METRIC", "confidence": 0.9926095604896545}, {"text": "HUMAN", "start_pos": 98, "end_pos": 103, "type": "METRIC", "confidence": 0.9729102253913879}]}, {"text": " Table 6: Overall official results for \"patents subtask\".", "labels": [], "entities": []}]}