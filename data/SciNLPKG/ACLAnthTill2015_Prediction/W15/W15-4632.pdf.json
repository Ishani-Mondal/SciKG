{"title": [], "abstractContent": [{"text": "The problem of extractive text summa-rization fora collection of documents is defined as the problem of selecting a small subset of sentences so that the contents and meaning of the original document set are preserved in the best possible way.", "labels": [], "entities": [{"text": "extractive text summa-rization", "start_pos": 15, "end_pos": 45, "type": "TASK", "confidence": 0.5963345368703207}]}, {"text": "In this paper we describe the linear programming-based global optimization model to rank and extract the most relevant sentences to a summary.", "labels": [], "entities": []}, {"text": "We introduce three different objective functions being optimized.", "labels": [], "entities": []}, {"text": "These functions define a relevance of a sentence that is being maximized , in different manners, such as: coverage of meaningful words of a document, coverage of its bigrams, or coverage of frequent sequences of words.", "labels": [], "entities": []}, {"text": "We supply here an overview of our system's participation in the MultiLing contest of SIGDial 2015.", "labels": [], "entities": [{"text": "MultiLing contest of SIGDial 2015", "start_pos": 64, "end_pos": 97, "type": "TASK", "confidence": 0.5257250666618347}]}], "introductionContent": [{"text": "Automated text summarization is an active field of research in various communities, including Information Retrieval, Natural Language Processing, and Text Mining.", "labels": [], "entities": [{"text": "Automated text summarization", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.773270845413208}, {"text": "Information Retrieval", "start_pos": 94, "end_pos": 115, "type": "TASK", "confidence": 0.8062085807323456}, {"text": "Text Mining", "start_pos": 150, "end_pos": 161, "type": "TASK", "confidence": 0.8069183230400085}]}, {"text": "Some authors reduce summarization to the maximum coverage problem) which, despite positive results, is known as NPhard ().", "labels": [], "entities": [{"text": "summarization", "start_pos": 20, "end_pos": 33, "type": "TASK", "confidence": 0.9854748249053955}, {"text": "coverage", "start_pos": 49, "end_pos": 57, "type": "METRIC", "confidence": 0.7824594974517822}]}, {"text": "Because linear programming (LP) helps to find an accurate approximated solution to this problem it has recently become very popular in the summarization field.", "labels": [], "entities": [{"text": "summarization", "start_pos": 139, "end_pos": 152, "type": "TASK", "confidence": 0.9900485277175903}]}, {"text": "Trying to solve a trade-off between summary quality and time complexity, we propose a summarization model solving the approximated maximum coverage problem by linear programming in polynomial time.", "labels": [], "entities": [{"text": "summarization", "start_pos": 86, "end_pos": 99, "type": "TASK", "confidence": 0.9615491628646851}]}, {"text": "We measure information coverage by an objective function and strive to obtain a summary that preserves its optimal value as much as possible.", "labels": [], "entities": []}, {"text": "Three objective functions considering different metrics of information are introduced and evaluated.", "labels": [], "entities": []}, {"text": "The main achievement of our method is a text representation model expanding a classic vector space model () to hyperplane and half-spaces and making it possible to represent an exponential number of extracts without computing them explicitly.", "labels": [], "entities": []}, {"text": "This model also enables us to find the optimal extract by simple optimizing an objective function in polynomial time, using linear programming over rationals.", "labels": [], "entities": []}, {"text": "For the first time, the frequent sequence mining was integrated with the maximal coverage approach in order to obtain a summary that best describes the summarized document.", "labels": [], "entities": [{"text": "frequent sequence mining", "start_pos": 24, "end_pos": 48, "type": "TASK", "confidence": 0.6173540949821472}]}, {"text": "One of the introduced objective functions implements this idea.", "labels": [], "entities": []}, {"text": "Our method ranks and extracts significant sentences into a summary, without any need in morphological text analysis.", "labels": [], "entities": []}, {"text": "It was applied for both single-document (MSS) and multi-document (MMS) MultiLing 2015 summarization tasks, in three languages-English, Hebrew, and Arabic.", "labels": [], "entities": [{"text": "MultiLing 2015 summarization tasks", "start_pos": 71, "end_pos": 105, "type": "TASK", "confidence": 0.6377005577087402}]}, {"text": "In this paper we present experimental results in comparison with other systems that participated in the same tasks, using the same languages.", "labels": [], "entities": []}], "datasetContent": [{"text": "Tables 4, 4, and 1 contain the summarized results of automated evaluations for MultiLing 2015, single-document summarization (MSS) task for English, Hebrew, and Arabic corpora, respectively.", "labels": [], "entities": [{"text": "single-document summarization (MSS) task", "start_pos": 95, "end_pos": 135, "type": "TASK", "confidence": 0.8071824312210083}]}, {"text": "The quality of the summaries is measured by ROUGE-1 (Recall, Precision, and Fmeasure).)", "labels": [], "entities": [{"text": "ROUGE-1", "start_pos": 44, "end_pos": 51, "type": "METRIC", "confidence": 0.9982370138168335}, {"text": "Recall", "start_pos": 53, "end_pos": 59, "type": "METRIC", "confidence": 0.9801888465881348}, {"text": "Precision", "start_pos": 61, "end_pos": 70, "type": "METRIC", "confidence": 0.8813425898551941}, {"text": "Fmeasure", "start_pos": 76, "end_pos": 84, "type": "METRIC", "confidence": 0.9907433390617371}]}, {"text": "We also demonstrate the absolute ranks of each submission-P-Rank, R-Rank, and F-Rank-when their scores are sorted by Precision, Recall, and F-measure, respectively.", "labels": [], "entities": [{"text": "F-Rank-when", "start_pos": 78, "end_pos": 89, "type": "METRIC", "confidence": 0.9618929624557495}, {"text": "Precision", "start_pos": 117, "end_pos": 126, "type": "METRIC", "confidence": 0.9963429570198059}, {"text": "Recall", "start_pos": 128, "end_pos": 134, "type": "METRIC", "confidence": 0.861927330493927}, {"text": "F-measure", "start_pos": 140, "end_pos": 149, "type": "METRIC", "confidence": 0.9864495396614075}]}, {"text": "Only the best submissions (in terms of F-measure) for each participated system are presented and sorted in descending order of their F-measure scores.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 39, "end_pos": 48, "type": "METRIC", "confidence": 0.9872018098831177}]}, {"text": "Two systems-Oracles and Lead-were used as topline and baseline summarizers, respectively.", "labels": [], "entities": []}, {"text": "Oracles compute summaries for each article using the combinatorial covering algorithm in ()-sentences were selected from a text to maximally cover the tokens in the human summary, using as few sentences as possible until its size exceeded the human summary, at which point it was truncated.", "labels": [], "entities": []}, {"text": "Because Oracles can actually \"see\" the human summaries, it is considered as the optimal algorithm and its scores are the best scores that extractive approaches can achieve.", "labels": [], "entities": []}, {"text": "Lead simply extracts the leading substring of the body text of the articles having the same length as the human summary of the article.", "labels": [], "entities": []}, {"text": "Below we summarize the comparative results for our summarizer (denoted in the following tables by Poly) in both tasks, in terms of Rouge-1, F-measure.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 140, "end_pos": 149, "type": "METRIC", "confidence": 0.9436479806900024}]}, {"text": "For comparisons, we consider the best result out of 3 functions: coverage of frequent sequences for English and coverage of meaningful words for Hebrew and Arabic.", "labels": [], "entities": []}, {"text": "English: 4 th places out of 9 participants in both MSS and MMS tasks.", "labels": [], "entities": [{"text": "MSS", "start_pos": 51, "end_pos": 54, "type": "TASK", "confidence": 0.8871476054191589}, {"text": "MMS tasks", "start_pos": 59, "end_pos": 68, "type": "TASK", "confidence": 0.711021900177002}]}, {"text": "Hebrew: 3 rd place out of 7 and out of 9 partici-  pants in MSS and MMS tasks, respectively; and the highest recall score in MMS task.", "labels": [], "entities": [{"text": "MMS tasks", "start_pos": 68, "end_pos": 77, "type": "TASK", "confidence": 0.780304342508316}, {"text": "recall score", "start_pos": 109, "end_pos": 121, "type": "METRIC", "confidence": 0.9853576123714447}, {"text": "MMS task", "start_pos": 125, "end_pos": 133, "type": "TASK", "confidence": 0.8277412056922913}]}, {"text": "Arabic: 5 th place out of 7 systems in MSS task, and 4 th place out of 9 participants and the highest recall score in MMS task.", "labels": [], "entities": [{"text": "MSS task", "start_pos": 39, "end_pos": 47, "type": "TASK", "confidence": 0.8555905520915985}, {"text": "recall score", "start_pos": 102, "end_pos": 114, "type": "METRIC", "confidence": 0.982611745595932}, {"text": "MMS task", "start_pos": 118, "end_pos": 126, "type": "TASK", "confidence": 0.8434866070747375}]}, {"text": "As can be seen, the best performance for our summarizer has been achieved on the dataset of Hebrew documents.", "labels": [], "entities": []}, {"text": "For example, only the top-line Oracles and the supervised MUSE summarizers outperformed our system in MSS task.", "labels": [], "entities": [{"text": "MUSE summarizers", "start_pos": 58, "end_pos": 74, "type": "TASK", "confidence": 0.6441706866025925}, {"text": "MSS task", "start_pos": 102, "end_pos": 110, "type": "TASK", "confidence": 0.8558646738529205}]}, {"text": "Poly also outperformed Gillick (2009) model using ILP.", "labels": [], "entities": []}, {"text": "The average running time for Poly is 500 ms per document.", "labels": [], "entities": [{"text": "Poly", "start_pos": 29, "end_pos": 33, "type": "DATASET", "confidence": 0.9382007718086243}]}], "tableCaptions": [{"text": " Table 1: MSS task. Rouge-1. English, Hebrew,  and Arabic, top-down.", "labels": [], "entities": [{"text": "MSS task", "start_pos": 10, "end_pos": 18, "type": "TASK", "confidence": 0.7650226354598999}]}]}