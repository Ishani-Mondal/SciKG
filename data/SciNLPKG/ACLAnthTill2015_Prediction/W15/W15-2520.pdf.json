{"title": [{"text": "Novel Document Level Features for Statistical Machine Translation", "labels": [], "entities": [{"text": "Statistical Machine Translation", "start_pos": 34, "end_pos": 65, "type": "TASK", "confidence": 0.8449784318606058}]}], "abstractContent": [{"text": "In this paper, we introduce document level features that capture necessary information to help MT system perform better word sense disambiguation in the translation process.", "labels": [], "entities": [{"text": "MT", "start_pos": 95, "end_pos": 97, "type": "TASK", "confidence": 0.9852396249771118}, {"text": "word sense disambiguation", "start_pos": 120, "end_pos": 145, "type": "TASK", "confidence": 0.664305845896403}]}, {"text": "We describe enhancements to a Maximum Entropy based translation model, utilizing long distance contextual features identified from the span of entire document and from both source and target sides, to improve the likelihood of the correct translation for words with multiple meanings, and to improve the consistency of the translation output in a document setting.", "labels": [], "entities": [{"text": "consistency", "start_pos": 304, "end_pos": 315, "type": "METRIC", "confidence": 0.9585561752319336}]}, {"text": "The proposed features have been observed to achieve substantial improvement of MT performance on a variety of standard test sets in terms of TER/BLEU score.", "labels": [], "entities": [{"text": "MT", "start_pos": 79, "end_pos": 81, "type": "TASK", "confidence": 0.9833545088768005}, {"text": "TER", "start_pos": 141, "end_pos": 144, "type": "METRIC", "confidence": 0.9990552067756653}, {"text": "BLEU score", "start_pos": 145, "end_pos": 155, "type": "METRIC", "confidence": 0.8903668522834778}]}], "introductionContent": [{"text": "Most statistical machine translation (MT) systems use sentence as the processing unit for both training and decoding.", "labels": [], "entities": [{"text": "statistical machine translation (MT)", "start_pos": 5, "end_pos": 41, "type": "TASK", "confidence": 0.782756452759107}]}, {"text": "This strategy, mainly the result of pursuing efficiency, assumes that each sentence is independent, and therefore suffers the loss of missing many kinds of \"global\" information, such as domain, topic and inter-sentence dependency, which are particularly important for word sense disambiguation ( and need be learned from the span of entire document.", "labels": [], "entities": [{"text": "word sense disambiguation", "start_pos": 268, "end_pos": 293, "type": "TASK", "confidence": 0.6691255966822306}]}, {"text": "shows the MT output of our sentence level Arabic-to-English translation engine on two sentences excerpted from a news article discussing middle-east politics.", "labels": [], "entities": [{"text": "MT", "start_pos": 10, "end_pos": 12, "type": "TASK", "confidence": 0.8593494892120361}]}, {"text": "The Arabic sentences are displayed in Romanized form.", "labels": [], "entities": []}, {"text": "The Arabic word mrsy denotes the name of the former Egyptian president Morsi in both sentences.", "labels": [], "entities": []}, {"text": "In the first sentence it is translated together with prior word mHmd(Mohamed) as a phrase and mapped to the name correctly.", "labels": [], "entities": []}, {"text": "In the second sentence, where no relevant local context is present, it is incorrectly translated into the word thank, which is the most frequent English word aligned to mrsy in our training data.", "labels": [], "entities": [{"text": "thank", "start_pos": 111, "end_pos": 116, "type": "METRIC", "confidence": 0.9400875568389893}]}, {"text": "This example shows that for ambiguous words like mrsy, utilizing only local features is insufficient to find them the correct translation hypotheses.", "labels": [], "entities": []}, {"text": "This example also illustrates another weakness of sentence level MT.", "labels": [], "entities": [{"text": "sentence level MT", "start_pos": 50, "end_pos": 67, "type": "TASK", "confidence": 0.49776514371236164}]}, {"text": "It has been observed that a word tends to keep same meaning within one document (.", "labels": [], "entities": []}, {"text": "However, such consistency can't be maintained by MT system working on isolated sentences since all decisions are made locally.", "labels": [], "entities": [{"text": "consistency", "start_pos": 14, "end_pos": 25, "type": "METRIC", "confidence": 0.9690240621566772}, {"text": "MT", "start_pos": 49, "end_pos": 51, "type": "TASK", "confidence": 0.746221661567688}]}], "datasetContent": [{"text": "Our system is primarily built for an Arabic dialect to English MT task.) to minimize the score of (TER-BLEU).", "labels": [], "entities": [{"text": "MT task.", "start_pos": 63, "end_pos": 71, "type": "TASK", "confidence": 0.8575514853000641}, {"text": "TER-BLEU", "start_pos": 99, "end_pos": 107, "type": "METRIC", "confidence": 0.9991674423217773}]}, {"text": "We select NIST Arabic MT03-MT09 as the test sets.", "labels": [], "entities": [{"text": "NIST Arabic MT03-MT09", "start_pos": 10, "end_pos": 31, "type": "DATASET", "confidence": 0.8943895896275839}]}, {"text": "The two numbers in each score column are TER followed by BLEU.", "labels": [], "entities": [{"text": "TER", "start_pos": 41, "end_pos": 44, "type": "METRIC", "confidence": 0.9996533393859863}, {"text": "BLEU", "start_pos": 57, "end_pos": 61, "type": "METRIC", "confidence": 0.9992762207984924}]}, {"text": "The best performance is illustrated in bold.", "labels": [], "entities": []}, {"text": "The result of MT system using only sentence level features is listed as the baseline.", "labels": [], "entities": [{"text": "MT", "start_pos": 14, "end_pos": 16, "type": "TASK", "confidence": 0.9651626348495483}]}, {"text": "The integrations of the three document features are denoted as +LDC, +tLDC and +QT, respectively.", "labels": [], "entities": []}, {"text": "shows that substantial improvements of translation quality, measured by both TER and BLEU, are achieved for most of the test sets.", "labels": [], "entities": [{"text": "translation", "start_pos": 39, "end_pos": 50, "type": "TASK", "confidence": 0.9395353198051453}, {"text": "TER", "start_pos": 77, "end_pos": 80, "type": "METRIC", "confidence": 0.9969793558120728}, {"text": "BLEU", "start_pos": 85, "end_pos": 89, "type": "METRIC", "confidence": 0.9966409206390381}]}, {"text": "To understand the effectiveness of document features on different type of data, we further split MT09 set into newswire and weblog, and conduct test on them.", "labels": [], "entities": [{"text": "MT09 set", "start_pos": 97, "end_pos": 105, "type": "DATASET", "confidence": 0.8728890120983124}]}, {"text": "shows that long distance context features, \u03c6 LDC and \u03c6 tLDC , perform better on newswire than on weblog respecting to the relative improvement of TER and BLEU.", "labels": [], "entities": [{"text": "TER", "start_pos": 146, "end_pos": 149, "type": "METRIC", "confidence": 0.997404158115387}, {"text": "BLEU", "start_pos": 154, "end_pos": 158, "type": "METRIC", "confidence": 0.9944700002670288}]}, {"text": "One reason to explain this is that the rate of content word repetition is different on the two types of data.", "labels": [], "entities": [{"text": "content word repetition", "start_pos": 47, "end_pos": 70, "type": "TASK", "confidence": 0.6539038221041361}]}, {"text": "According to our calculation, about 19% content words in newswire repeat themselves while the ratio on weblog is about 13%.: MT performance on MT09 newswire and weblog in terms of TER and BLEU.", "labels": [], "entities": [{"text": "MT", "start_pos": 125, "end_pos": 127, "type": "METRIC", "confidence": 0.679388165473938}, {"text": "MT09 newswire", "start_pos": 143, "end_pos": 156, "type": "DATASET", "confidence": 0.9247344136238098}, {"text": "TER", "start_pos": 180, "end_pos": 183, "type": "METRIC", "confidence": 0.9989192485809326}, {"text": "BLEU", "start_pos": 188, "end_pos": 192, "type": "METRIC", "confidence": 0.9985224604606628}]}, {"text": "shows the new MT output of the two example sentences.", "labels": [], "entities": [{"text": "MT", "start_pos": 14, "end_pos": 16, "type": "TASK", "confidence": 0.8767575025558472}]}, {"text": "Three LDC features are fired for mrsy in the 2nd sentence: mrsy,AlmSry,Morsi, mrsy,mHmd,Morsi and mrsy,ySf,Morsi where the 3rd one is a false alarm.", "labels": [], "entities": []}, {"text": "Items in the triplets correspond to source word, context word and hypothesized word, respectively.", "labels": [], "entities": []}, {"text": "Three tLDC features are also fired including mrsy,Egyptian,Morsi, mrsy,Mohamed,Morsi and mrsy,describes,Morsi where the 3rd one is also a false alarm.", "labels": [], "entities": []}, {"text": "To our surprise, word Alr}ys and its translation president aren't fired as context feature.", "labels": [], "entities": []}, {"text": "Analysis found that this is due to the fact that our LDC training data was collected before Dr. Morsi was elected as president in 2012.", "labels": [], "entities": [{"text": "LDC training data", "start_pos": 53, "end_pos": 70, "type": "DATASET", "confidence": 0.6713443100452423}]}, {"text": "Therefore no relevant feature is learned into MaxEnt model.", "labels": [], "entities": []}, {"text": "AR: Alr}ys AlmSry AlmEzwl mHmd mrsy ysf nfsh bnh r}ys Aljmhwryp MT: The deposed Egyptian president Mohamed Morsi describes himself as the president of the republic AR: mrsy ytHdY AlqADy fy mHAkmth bthmp Alhrwb mn Alsjn MT: Morsi defies the judge in his trial on charges of escaping from prison: New MT results using document level features", "labels": [], "entities": [{"text": "MT", "start_pos": 219, "end_pos": 221, "type": "TASK", "confidence": 0.9430068731307983}, {"text": "MT", "start_pos": 299, "end_pos": 301, "type": "TASK", "confidence": 0.9789754748344421}]}], "tableCaptions": [{"text": " Table 2: MT performance on MT03-MT09 in terms of TER and BLEU.", "labels": [], "entities": [{"text": "MT", "start_pos": 10, "end_pos": 12, "type": "TASK", "confidence": 0.966171145439148}, {"text": "MT03-MT09", "start_pos": 28, "end_pos": 37, "type": "DATASET", "confidence": 0.8946622014045715}, {"text": "TER", "start_pos": 50, "end_pos": 53, "type": "METRIC", "confidence": 0.9989655017852783}, {"text": "BLEU", "start_pos": 58, "end_pos": 62, "type": "METRIC", "confidence": 0.9980056881904602}]}, {"text": " Table 3: MT performance on MT09 newswire and  weblog in terms of TER and BLEU.", "labels": [], "entities": [{"text": "MT", "start_pos": 10, "end_pos": 12, "type": "TASK", "confidence": 0.9691958427429199}, {"text": "MT09 newswire", "start_pos": 28, "end_pos": 41, "type": "DATASET", "confidence": 0.9062317311763763}, {"text": "TER", "start_pos": 66, "end_pos": 69, "type": "METRIC", "confidence": 0.9987612962722778}, {"text": "BLEU", "start_pos": 74, "end_pos": 78, "type": "METRIC", "confidence": 0.997383177280426}]}]}