{"title": [{"text": "The AFRL-MITLL WMT15 System: There's More than One Way to Decode It!", "labels": [], "entities": [{"text": "AFRL-MITLL WMT15 System", "start_pos": 4, "end_pos": 27, "type": "DATASET", "confidence": 0.7445307374000549}]}], "abstractContent": [{"text": "This paper describes the AFRL-MITLL statistical MT systems and the improvements that were developed during the WMT15 evaluation campaign.", "labels": [], "entities": [{"text": "AFRL-MITLL statistical MT", "start_pos": 25, "end_pos": 50, "type": "TASK", "confidence": 0.6184078852335612}, {"text": "WMT15 evaluation", "start_pos": 111, "end_pos": 127, "type": "TASK", "confidence": 0.5686588734388351}]}, {"text": "As part of these efforts we experimented with a number of extensions to the standard phrase-based model that improve performance on the Russian to English translation task creating three submission systems with different decoding strategies.", "labels": [], "entities": [{"text": "Russian to English translation task", "start_pos": 136, "end_pos": 171, "type": "TASK", "confidence": 0.6526995897293091}]}, {"text": "Out of vocabulary words were addressed with named entity postprocessing.", "labels": [], "entities": []}], "introductionContent": [], "datasetContent": [], "tableCaptions": [{"text": " Table 1: NNJM Rescoring on newstest2015,  optimizing on newstest2014, case-insensitive  BLEU.", "labels": [], "entities": [{"text": "NNJM", "start_pos": 10, "end_pos": 14, "type": "DATASET", "confidence": 0.7838764786720276}, {"text": "Rescoring", "start_pos": 15, "end_pos": 24, "type": "METRIC", "confidence": 0.958766520023346}, {"text": "BLEU", "start_pos": 89, "end_pos": 93, "type": "METRIC", "confidence": 0.9821266531944275}]}, {"text": " Table 2: NE post-processing improvement measured in uncased BLEU", "labels": [], "entities": [{"text": "BLEU", "start_pos": 61, "end_pos": 65, "type": "METRIC", "confidence": 0.9895890951156616}]}, {"text": " Table 3: MT Submission Systems decoding  newstest2015", "labels": [], "entities": [{"text": "MT Submission", "start_pos": 10, "end_pos": 23, "type": "TASK", "confidence": 0.8837363123893738}, {"text": "newstest2015", "start_pos": 42, "end_pos": 54, "type": "DATASET", "confidence": 0.5677257776260376}]}, {"text": " Table 4: Submission system similarity measured  in uncased BLEU", "labels": [], "entities": [{"text": "Submission system", "start_pos": 10, "end_pos": 27, "type": "TASK", "confidence": 0.8810521960258484}, {"text": "BLEU", "start_pos": 60, "end_pos": 64, "type": "METRIC", "confidence": 0.9911666512489319}]}]}