{"title": [{"text": "How much does word sense disambiguation help in sentiment analysis of micropost data?", "labels": [], "entities": [{"text": "word sense disambiguation", "start_pos": 14, "end_pos": 39, "type": "TASK", "confidence": 0.7067036628723145}, {"text": "sentiment analysis", "start_pos": 48, "end_pos": 66, "type": "TASK", "confidence": 0.980062872171402}]}], "abstractContent": [{"text": "This short paper describes a sentiment analysis system for micro-post data that includes analysis of tweets from Twitter and Short Messaging Service (SMS) text messages.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 29, "end_pos": 47, "type": "TASK", "confidence": 0.9077860116958618}]}, {"text": "We discuss our system that makes use of Word Sense Disambigua-tion techniques in sentiment analysis at the message level, where the entire tweet or SMS text was analysed to determine its dominant sentiment.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 81, "end_pos": 99, "type": "TASK", "confidence": 0.8604331910610199}]}, {"text": "Previous work done in the area of Word Sense Disambigua-tion does not throw light on its influence on the analysis of social-media text and micropost data, which is what our work aims to achieve.", "labels": [], "entities": [{"text": "Word Sense Disambigua-tion", "start_pos": 34, "end_pos": 60, "type": "TASK", "confidence": 0.6066036919752756}]}, {"text": "Our experiments show that the use of Word Sense Disambigua-tion alone has resulted in an improved sentiment analysis system that outperforms systems built without incorporating Word Sense Disambiguation.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 98, "end_pos": 116, "type": "TASK", "confidence": 0.9385639727115631}]}], "introductionContent": [{"text": "Twitter is an online social networking and microblogging service that enables users to send and read short 140-character messages called \"tweets\".", "labels": [], "entities": []}, {"text": "As of the first quarter of 2015, the microblogging service averaged at 236 million monthly active users.", "labels": [], "entities": []}, {"text": "Worldwide over 350 billion SMS text messages are exchanged across the world's mobile networks every month, with over 15 percent of these messages being classified as commercial or marketing messages.", "labels": [], "entities": []}, {"text": "The process of sentiment analysis involves text analytics, linguistics and accepted language processing to determine and dig subjective information from source materials.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 15, "end_pos": 33, "type": "TASK", "confidence": 0.9687648117542267}]}, {"text": "Sentiment analysis finds applications in various domains such as marketing, business and commerce, healthcare, tourism and travel (, and disaster management.", "labels": [], "entities": [{"text": "Sentiment analysis", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.9507721960544586}, {"text": "disaster management", "start_pos": 137, "end_pos": 156, "type": "TASK", "confidence": 0.7375473529100418}]}, {"text": "One of the first problems that is encountered by any natural language processing system is that of lexical ambiguity, be it syntactic or semantic (.", "labels": [], "entities": []}, {"text": "The resolution of a word's syntactic ambiguity has largely been solved in language processing by part-of-speech taggers which predict the syntactic category of words in text with high levels of accuracy.", "labels": [], "entities": [{"text": "resolution of a word's syntactic ambiguity", "start_pos": 4, "end_pos": 46, "type": "TASK", "confidence": 0.8578212431498936}, {"text": "accuracy", "start_pos": 194, "end_pos": 202, "type": "METRIC", "confidence": 0.9932603240013123}]}, {"text": "The problem is that words often have more than one meaning, sometimes fairly similar and sometimes completely different.", "labels": [], "entities": []}, {"text": "The meaning of a word in a particular usage can only be determined by examining its context.", "labels": [], "entities": []}, {"text": "Word Sense Disambiguation (WSD) is the process of identifying the sense of a polysemic word . Different approaches to WSD include knowledge-based systems such as Lesk algorithm and adapted), unsupervised corpus-based systems, and supervised corpusbased systems).", "labels": [], "entities": [{"text": "Word Sense Disambiguation (WSD)", "start_pos": 0, "end_pos": 31, "type": "TASK", "confidence": 0.7654449294010798}]}, {"text": "Subjectivity Word Sense Disambiguation (SWSD) was shown to improve contextual opinion analysis by.", "labels": [], "entities": [{"text": "Subjectivity Word Sense Disambiguation (SWSD", "start_pos": 0, "end_pos": 44, "type": "TASK", "confidence": 0.711159403125445}, {"text": "contextual opinion analysis", "start_pos": 67, "end_pos": 94, "type": "TASK", "confidence": 0.6137134432792664}]}, {"text": "The authors state that SWSD is midway between pure dictionary classification and pure contextual interpretation.", "labels": [], "entities": [{"text": "SWSD", "start_pos": 23, "end_pos": 27, "type": "TASK", "confidence": 0.9378731846809387}, {"text": "dictionary classification", "start_pos": 51, "end_pos": 76, "type": "TASK", "confidence": 0.7209799736738205}, {"text": "contextual interpretation", "start_pos": 86, "end_pos": 111, "type": "TASK", "confidence": 0.7559036314487457}]}, {"text": "For SWSD, the context of the word is considered in order to perform the task, but the subjectivity is determined solely by the dictionary.", "labels": [], "entities": [{"text": "SWSD", "start_pos": 4, "end_pos": 8, "type": "TASK", "confidence": 0.9552913308143616}]}, {"text": "A supervised learning approach was used, in which a different classifier was trained for each lexicon entry for which training data was present.", "labels": [], "entities": []}, {"text": "Thus, they described their work as similar to targeted WSD, with two labels Subjective (S) and Objective (O).", "labels": [], "entities": []}, {"text": "By applying SWSD to contextual polarity classification (positive/negative/neutral), they observed an accuracy improvement of 3 percentage points over the original classifier) calculated on the SenMPQA dataset.", "labels": [], "entities": [{"text": "contextual polarity classification", "start_pos": 20, "end_pos": 54, "type": "TASK", "confidence": 0.6399788359800974}, {"text": "accuracy", "start_pos": 101, "end_pos": 109, "type": "METRIC", "confidence": 0.9993301630020142}, {"text": "SenMPQA dataset", "start_pos": 193, "end_pos": 208, "type": "DATASET", "confidence": 0.9089279770851135}]}, {"text": "Additionally, showed that WSD is valuable in polarity classification of sentences containing figurative expressions.", "labels": [], "entities": [{"text": "WSD", "start_pos": 26, "end_pos": 29, "type": "TASK", "confidence": 0.8756434321403503}, {"text": "polarity classification of sentences containing figurative expressions", "start_pos": 45, "end_pos": 115, "type": "TASK", "confidence": 0.8037536314555577}]}, {"text": "It should be noted that the above work did not focus on using WSD for social-media or micropost data, which is the primary focus area of our work.", "labels": [], "entities": []}, {"text": "Babelfy () 2 is a unified, multilingual, graph-based approach to Entity Linking and Word Sense Disambiguation based on a loose identification of candidate meanings coupled with a densest sub-graph heuristic which selects highcoherence semantic interpretations.", "labels": [], "entities": [{"text": "Entity Linking and Word Sense Disambiguation", "start_pos": 65, "end_pos": 109, "type": "TASK", "confidence": 0.7007164259751638}]}, {"text": "We have used Babelfy for WSD in our work.", "labels": [], "entities": [{"text": "WSD", "start_pos": 25, "end_pos": 28, "type": "TASK", "confidence": 0.9301192760467529}]}, {"text": "Babelfy is based on the BabelNet 3.0 multilingual semantic network, and jointly performs WSD and entity linking in three steps: \u2022 It associates with each vertex of the BabelNet semantic network, i.e., either concept or named entity, a semantic signature, that is, a set of related vertices.", "labels": [], "entities": [{"text": "WSD and entity linking", "start_pos": 89, "end_pos": 111, "type": "TASK", "confidence": 0.6562162637710571}]}, {"text": "This is a preliminary step which needs to be performed only once, independently of the input text.", "labels": [], "entities": []}, {"text": "\u2022 Given an input text, it extracts all the linkable fragments from this text and, for each of them, lists the possible meanings according to the semantic network.", "labels": [], "entities": []}, {"text": "\u2022 It creates a graph-based semantic interpretation of the whole text by linking the candidate meanings of the extracted fragments using the previously-computed semantic signatures.", "labels": [], "entities": []}, {"text": "It then extracts a dense sub-graph of this representation and selects the best candidate meaning for each fragment.", "labels": [], "entities": []}, {"text": "BabelNet 3.0, on which Babelfy is based, is obtained from the automatic integration of WordNet 3.0, Open Multilingual WordNet, Wikipedia, OmegaWiki, Wiktionary and Wikidata.", "labels": [], "entities": []}, {"text": "We chose to use Babelfy for WSD as experiments on six gold-standard datasets show the state-of-the-art performance of Babelfy, as well as its robustness across languages.", "labels": [], "entities": [{"text": "WSD", "start_pos": 28, "end_pos": 31, "type": "TASK", "confidence": 0.909688413143158}]}, {"text": "Its evaluation also demonstrates that Babelfy fares well both on long texts, such as those of the WSD tasks, and short and highly-ambiguous sentences, such as the ones in KORE50.", "labels": [], "entities": [{"text": "WSD tasks", "start_pos": 98, "end_pos": 107, "type": "TASK", "confidence": 0.6771753132343292}, {"text": "KORE50", "start_pos": 171, "end_pos": 177, "type": "DATASET", "confidence": 0.9236259460449219}]}], "datasetContent": [{"text": "Tweets also shows baseline results (Baseline 1) obtained by a majority classifier that always predicts the most frequent class as output.", "labels": [], "entities": []}, {"text": "Since the final Average F-score is based only on the F-scores of positive and negative classes and not on neutral, the majority baseline shown, chose the most frequent class among positive and negative, which in this case was the positive class.", "labels": [], "entities": [{"text": "Average", "start_pos": 16, "end_pos": 23, "type": "METRIC", "confidence": 0.8672430515289307}, {"text": "F-score", "start_pos": 24, "end_pos": 31, "type": "METRIC", "confidence": 0.5175091028213501}, {"text": "F-scores", "start_pos": 53, "end_pos": 61, "type": "METRIC", "confidence": 0.972000777721405}]}, {"text": "The results shown in Baseline 2 are obtained for an similar system as ours, but in this case, we do not disambiguate word senses, and instead the reported SentiWordNet scores of first sense of the word for the right part-of-speech are chosen.", "labels": [], "entities": []}, {"text": "It should be noted that we have only used three numeric-feature vectors to represent the data for training our system and no additional features such as unigram or n-grams, punctuation, token-clusters, upper-case words, elongated words, negation detection, emoticons or n-gram lexicons have been used.", "labels": [], "entities": [{"text": "negation detection", "start_pos": 237, "end_pos": 255, "type": "TASK", "confidence": 0.9271848797798157}]}, {"text": "Using so few features has also helped determine that the considerable improvement in performance reported below can be primarily attributed only to WSD and the P, N and O scores that are determined from the SentiWordNet lexicon as a result of disambiguating the text, which then form the only three features in the vector used to represent the message.", "labels": [], "entities": [{"text": "WSD", "start_pos": 148, "end_pos": 151, "type": "METRIC", "confidence": 0.7935490012168884}, {"text": "P, N and O scores", "start_pos": 160, "end_pos": 177, "type": "METRIC", "confidence": 0.7039213875929514}]}, {"text": "There are no other features used in our system that can claim to have contributed to the improved performance.", "labels": [], "entities": []}, {"text": "Therefore, we report an improvement of 11.14 percentage points for tweets and 10.31 percentage points for SMS text messages, over the allunigram-features score of the NRC-Canada bestscoring system, when evaluated for the test dataset provided, despite our system not utilizing several other unigram features that were discussed above, but focussing only on the three WSD features instead.", "labels": [], "entities": [{"text": "NRC-Canada bestscoring system", "start_pos": 167, "end_pos": 196, "type": "DATASET", "confidence": 0.9154694477717081}]}], "tableCaptions": [{"text": " Table 1: Dataset Class Distribution.", "labels": [], "entities": [{"text": "Dataset Class Distribution", "start_pos": 10, "end_pos": 36, "type": "TASK", "confidence": 0.7133718729019165}]}, {"text": " Table 2: Accuracies reported for 10-fold cross val- idation of training data.", "labels": [], "entities": [{"text": "Accuracies", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.9991356730461121}]}, {"text": " Table 4: Results for SMS test data, for each class.", "labels": [], "entities": []}, {"text": " Table 5: Comparison of Average F-scores for pos- itive/negative classes. All scores reported are for  the test datasets", "labels": [], "entities": [{"text": "F-scores", "start_pos": 32, "end_pos": 40, "type": "METRIC", "confidence": 0.8077704310417175}]}]}