{"title": [{"text": "USZEGED: Correction Type-sensitive Normalization of English Tweets Using Efficiently Indexed n-gram Statistics", "labels": [], "entities": [{"text": "USZEGED", "start_pos": 0, "end_pos": 7, "type": "DATASET", "confidence": 0.8816514611244202}]}], "abstractContent": [{"text": "This paper describes the framework applied by team USZEGED at the \"Lexical Normalisation for English Tweets\" shared task.", "labels": [], "entities": [{"text": "USZEGED", "start_pos": 51, "end_pos": 58, "type": "DATASET", "confidence": 0.9116654992103577}, {"text": "Lexical Normalisation for English Tweets\" shared task", "start_pos": 67, "end_pos": 120, "type": "TASK", "confidence": 0.8903402835130692}]}, {"text": "Our approach first employs a CRF-based sequence labeling framework to decide the kind of corrections the individual tokens require, then performs the necessary modifications relying on external lexicons and a massive collection of efficiently indexed n-gram statistics from En-glish tweets.", "labels": [], "entities": [{"text": "CRF-based sequence labeling", "start_pos": 29, "end_pos": 56, "type": "TASK", "confidence": 0.561076283454895}]}, {"text": "Our solution is based on the assumption that from the context of the OOV words, it is possible to reconstruct its IV equivalent, as there are users who use the standard English form of the OOV word within the same context.", "labels": [], "entities": []}, {"text": "Our approach achieved an F-score of 0.8052, being the second best one among the un-constrained submissions, the category our submission also belongs to.", "labels": [], "entities": [{"text": "F-score", "start_pos": 25, "end_pos": 32, "type": "METRIC", "confidence": 0.9996777772903442}]}], "introductionContent": [{"text": "Social media is a rich source of information which has been proven to be useful to a variety of applications, such as event extraction ( or trend detection, including the tracking of epidemics (.", "labels": [], "entities": [{"text": "event extraction", "start_pos": 118, "end_pos": 134, "type": "TASK", "confidence": 0.7746913433074951}, {"text": "trend detection", "start_pos": 140, "end_pos": 155, "type": "TASK", "confidence": 0.7352331280708313}, {"text": "tracking of epidemics", "start_pos": 171, "end_pos": 192, "type": "TASK", "confidence": 0.8506304224332174}]}, {"text": "Analyzing tweets in general, however, can pose several difficulties.", "labels": [], "entities": []}, {"text": "From an engineering point of view, the streaming nature of tweets requires that special attention is paid to the scalability of the algorithms applied and from an NLP point of view, the often substandard characteristics of social media utterances has to be addressed.", "labels": [], "entities": []}, {"text": "The fact that tweets are often written on mobile devices and are informal makes the misspelling and abbreviations of words and expressions, as well as the use of creative informal language prevalent, giving rise to a higher number of out-of-vocabulary (OOV) words than in other genres.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Distribution of the correction types in the  training and test sets", "labels": [], "entities": []}, {"text": " Table 2: Results of predicting the correction types  for tokens on the training set", "labels": [], "entities": []}, {"text": " Table 3: Results of predicting the correction types  for tokens on the test set", "labels": [], "entities": []}, {"text": " Table 4: Detailed performance on the different  correction types on the training dataset", "labels": [], "entities": []}, {"text": " Table 5: Detailed performance on the different  correction types on the test dataset", "labels": [], "entities": []}]}