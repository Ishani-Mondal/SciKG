{"title": [{"text": "The Effect of Author Set Size in Authorship Attribution for Lithuanian", "labels": [], "entities": [{"text": "Authorship Attribution", "start_pos": 33, "end_pos": 55, "type": "TASK", "confidence": 0.6360137611627579}, {"text": "Lithuanian", "start_pos": 60, "end_pos": 70, "type": "TASK", "confidence": 0.39799967408180237}]}], "abstractContent": [{"text": "This paper reports the first authorship at-tribution results based on the effect of the author set size using automatic computational methods for the Lithuanian language.", "labels": [], "entities": []}, {"text": "The aim is to determine how fast authorship attribution results are deteriorating while the number of candidate authors is gradually increasing: i.e. starting from 3, going up to 5, 10, 20, 50, and 100.", "labels": [], "entities": [{"text": "authorship attribution", "start_pos": 33, "end_pos": 55, "type": "TASK", "confidence": 0.8163214921951294}]}, {"text": "Using supervised machine learning techniques we also investigated the influence of different features (lexical, character , morphological, etc.) and language types (normative parliamentary speeches and non-normative forum posts).", "labels": [], "entities": []}, {"text": "The experiments revealed that the effectiveness of the method and feature types depends more on the language type rather than on the number of candidate authors.", "labels": [], "entities": []}, {"text": "The content features based on word lem-mas are the most useful type for the nor-mative texts, due to the fact that Lithua-nian is a highly inflective, morphologically and vocabulary rich language.", "labels": [], "entities": []}, {"text": "The character features are the most accurate type for forum posts, where texts are too complicated to be effectively processed with external morphological tools.", "labels": [], "entities": []}], "introductionContent": [{"text": "Authorship Attribution (AA) is the task of identifying who, from a set of candidate authors, is an actual author of a given anonymous text document.", "labels": [], "entities": [{"text": "Authorship Attribution (AA) is the task of identifying who, from a set of candidate authors, is an actual author of a given anonymous text document", "start_pos": 0, "end_pos": 147, "type": "Description", "confidence": 0.7582194959295208}]}, {"text": "This prediction is based on a human \"stylometric fingerprint\" notion: i.e. a specific, individual, persistent, and uncontrolled habit to express thoughts with a unique set of linguistic means.", "labels": [], "entities": []}, {"text": "Van Halteren (2005) has gone so far as to name this phenomenon a \"human stylome\" in the deliberate analogy to the DNA \"genome\".", "labels": [], "entities": []}, {"text": "However, argues that such strict implications may not be absolutely correct, because the \"genome\" is stable, but the human style tends to evolve overtime.", "labels": [], "entities": []}, {"text": "Nevertheless a \"stylome\" can still be added to human biometrics, next to voice, gait, keystroke dynamics, handwriting, etc.", "labels": [], "entities": []}, {"text": "Starting from Mendenhall (1887) AA is one of the oldest computational linguistics problems, which is especially highly topical nowadays.", "labels": [], "entities": [{"text": "AA", "start_pos": 32, "end_pos": 34, "type": "TASK", "confidence": 0.6839367747306824}]}, {"text": "For along time in the past the main AA applications were restricted to the literary texts only.", "labels": [], "entities": [{"text": "AA applications", "start_pos": 36, "end_pos": 51, "type": "TASK", "confidence": 0.8218987584114075}]}, {"text": "But the constant influx of anonymous electronic text documents, especially on the Internet, and the popularity of automatic methods opened the gate to a number of new applications in forensic analysis and electronic commerce.", "labels": [], "entities": [{"text": "forensic analysis", "start_pos": 183, "end_pos": 200, "type": "TASK", "confidence": 0.8253897428512573}]}, {"text": "In addition to literary research the practical problems from the plagiarism detection, the identification of harassment and threatening ( to tracking authors of malicious source code () gained even greater prominence.", "labels": [], "entities": [{"text": "plagiarism detection", "start_pos": 65, "end_pos": 85, "type": "TASK", "confidence": 0.8281832337379456}]}, {"text": "This led to experiments with different datasets, such as e-mails (de, web forum messages), online chats (), Internet blogs) or tweets, which, in turn, contributed to a progress of the development of computational linguistic methods that are able to cope with the emerged problems.", "labels": [], "entities": []}, {"text": "Despite that many computational linguistic tasks can be solved accurately only relying on efforts of domain-experts, it is very time consuming, expensive, and perhaps the most limiting way for AA, moreover, which provides no explicit measure how attributions are made.", "labels": [], "entities": [{"text": "AA", "start_pos": 193, "end_pos": 195, "type": "TASK", "confidence": 0.9262505173683167}]}, {"text": "The alternative way is a manually composed set of rules capable to take attribution decisions automatically.", "labels": [], "entities": []}, {"text": "Unfor-tunately, rule-based systems usually are very complex, unwieldy, and thus not robust to any changes in the domain, language or author characteristics, therefore it is rather difficult to make any updates.", "labels": [], "entities": []}, {"text": "Moreover, when dealing with hundreds (e.g. in,) or thousands of candidate authors (e.g. in 10,000 authors; in -100,000) the possibility to create an effective rule set goes far beyond human potential limits.", "labels": [], "entities": []}, {"text": "Ultimately, AA task can be solved using the machine learning: i.e. by training the classifiers and later using them to predict the authorship of unseen texts.", "labels": [], "entities": [{"text": "AA task", "start_pos": 12, "end_pos": 19, "type": "TASK", "confidence": 0.8761552572250366}, {"text": "predict the authorship of unseen texts", "start_pos": 119, "end_pos": 157, "type": "TASK", "confidence": 0.6969788571198782}]}, {"text": "Moreover, it can be easily adjusted to new applications or domains and even generalized well to drifts in the author characteristics.", "labels": [], "entities": []}, {"text": "Due to all these advantages, the machine learning paradigm became dominant and remained the most popular till nowadays.", "labels": [], "entities": [{"text": "machine learning", "start_pos": 33, "end_pos": 49, "type": "TASK", "confidence": 0.7412919700145721}]}, {"text": "Therefore our focus in this paper is also on the machine learning methods.", "labels": [], "entities": []}], "datasetContent": [{"text": "All our experiments were carried out on 2 datasets to make sure that findings generalize over different domains and language types: \u2022 ParlTranscr 1 (see) contains unedited transcripts of parliamentary speeches and debates, thus representing formal spoken but normative Lithuanian language.", "labels": [], "entities": []}, {"text": "All transcripts are from regular parliamentary sessions and cover the period of 7 parliamentary terms starting on March 10, 1990 and ending on December 23, 2013.", "labels": [], "entities": []}, {"text": "Very long (>1,000 words) and very short (<100 words) texts were removed from the dataset to avoid speeches written by non-parliamentarians, but by someone else and to avoid less informative text samples, respectively.", "labels": [], "entities": []}, {"text": "Afterwards we selected 100 authors with the largest number of texts, but making sure that the selected candidates are distributed over different parliamentary terms (to avoid topic classification) and party groups (to avoid ideologybased classification).", "labels": [], "entities": [{"text": "topic classification)", "start_pos": 175, "end_pos": 196, "type": "TASK", "confidence": 0.7756417195002238}]}, {"text": "\u2022 LRytas 2 (see) contains forum data full of informal words, foreign language insertions, word shortenings, emoticons, and diacritic eliminations, thus represents the informal non-normative Lithuanian language.", "labels": [], "entities": [{"text": "foreign language insertions", "start_pos": 61, "end_pos": 88, "type": "TASK", "confidence": 0.6659258802731832}]}, {"text": "The forum has 11 general topics (such as \"Business\", \"Politics\", \"Sports\", etc.).", "labels": [], "entities": []}, {"text": "Very short texts (<10 words) were not included into the dataset.", "labels": [], "entities": []}, {"text": "Afterwards we selected 100 authors having the largest number of texts, but making sure that selected candidates would be distributed over different topics (to avoid topic classification).", "labels": [], "entities": [{"text": "topic classification", "start_pos": 165, "end_pos": 185, "type": "TASK", "confidence": 0.7307829707860947}]}, {"text": "Our aim is to explore different classification methods (see Section 3.2), feature types (see Section 3.3) and to answer the main questions: \u2022 How the author set size affects results, when having 3, 5, 10, 20, 50, and 100 candidate authors?", "labels": [], "entities": []}, {"text": "The candidate author selection is done depending on the number of their texts: the authors with the most texts are selected first.", "labels": [], "entities": []}, {"text": "\u2022 How the language type influences results, when ParlTranscr contains texts of normative, but LRytas of non-normative language?", "labels": [], "entities": []}, {"text": "All experiments were carried outwith the stratified 10-fold cross-validation and evaluated using accuracy and micro/macro average F-score metrics.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 97, "end_pos": 105, "type": "METRIC", "confidence": 0.9993420243263245}, {"text": "F-score", "start_pos": 130, "end_pos": 137, "type": "METRIC", "confidence": 0.9276370406150818}]}, {"text": "Since F-scores showed the same accuracy trend in all our experiments, we do not present them in the following figures and tables.", "labels": [], "entities": [{"text": "F-scores", "start_pos": 6, "end_pos": 14, "type": "METRIC", "confidence": 0.9737987518310547}, {"text": "accuracy", "start_pos": 31, "end_pos": 39, "type": "METRIC", "confidence": 0.9987996816635132}]}, {"text": "For each dataset random (\u2211 P 2 (c j )) and majority (max P(c j )) baselines (where P(c j ) is the probability of class c j ) were calculated, but only the higher values were presented in the following figures.", "labels": [], "entities": []}, {"text": "In order to determine whether the differences between obtained values are statistically significant we performed test with one degree of freedom.", "labels": [], "entities": []}, {"text": "In our experiments we used chi-squared feature extraction method, SMO polynomial kernel (because it gave the highest accuracy in our preliminary control experiments) with SVM and NBM implementations in the WEKA machine learning toolkit, version 3.6.", "labels": [], "entities": [{"text": "feature extraction", "start_pos": 39, "end_pos": 57, "type": "TASK", "confidence": 0.730850487947464}, {"text": "accuracy", "start_pos": 117, "end_pos": 125, "type": "METRIC", "confidence": 0.9934060573577881}, {"text": "WEKA machine learning toolkit", "start_pos": 206, "end_pos": 235, "type": "DATASET", "confidence": 0.7977214306592941}]}, {"text": "All remaining parameters were set to their default values.", "labels": [], "entities": []}, {"text": "For the effect of used method see and feature type see.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Composition of ParlTranscr: the upper value in each cell represents a balanced dataset (200  instances in each class), the lower -imbalanced (full). The set of authors is identical in the both datasets.", "labels": [], "entities": []}, {"text": " Table 2: Composition of LRytas: the upper value in each cell represents a balanced dataset (10 instances  in each class), the lower -imbalanced (full). The set of authors is identical in the both datasets.", "labels": [], "entities": []}, {"text": " Table 3: Accuracy values with SVM and various feature types for ParlTrascr dataset. Only the best  results in terms of N of each feature type are reported. The best results for different author set sizes (in  columns) are in bold; results that do not statistically significant differ from the best result are underlined.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9895310401916504}, {"text": "ParlTrascr dataset", "start_pos": 65, "end_pos": 83, "type": "DATASET", "confidence": 0.9238130152225494}]}, {"text": " Table 4: Accuracy values with SVM and various feature types for LRytas dataset. For other notations  see the caption of", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9957981705665588}, {"text": "LRytas dataset", "start_pos": 65, "end_pos": 79, "type": "DATASET", "confidence": 0.9283304810523987}]}]}