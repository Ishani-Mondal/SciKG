{"title": [{"text": "Clustering-based Approach to Multiword Expression Extraction and Ranking", "labels": [], "entities": [{"text": "Multiword Expression Extraction", "start_pos": 29, "end_pos": 60, "type": "TASK", "confidence": 0.8771143555641174}, {"text": "Ranking", "start_pos": 65, "end_pos": 72, "type": "TASK", "confidence": 0.6266561150550842}]}], "abstractContent": [{"text": "We present a domain-independent clustering-based approach for automatic extraction of multiword expressions (MWEs).", "labels": [], "entities": [{"text": "automatic extraction of multiword expressions (MWEs)", "start_pos": 62, "end_pos": 114, "type": "TASK", "confidence": 0.8376728817820549}]}, {"text": "The method combines statistical information from a general-purpose corpus and texts from Wikipedia articles.", "labels": [], "entities": []}, {"text": "We incorporate association measures via dimensions of data points to cluster MWEs and then compute the ranking score for each MWE based on the closest exemplar assigned to a cluster.", "labels": [], "entities": []}, {"text": "Evaluation results, achieved for two languages, show that a combination of association measures gives an improvement in the ranking of MWEs compared with simple counts of co-occurrence frequencies and purely statistical measures.", "labels": [], "entities": []}], "introductionContent": [{"text": "Extraction of multiword expressions (MWEs) is a challenging and well-known task, aimed at identifying lexical items with idiosyncratic interpretations that can be decomposed into single words ().", "labels": [], "entities": [{"text": "Extraction of multiword expressions (MWEs)", "start_pos": 0, "end_pos": 42, "type": "TASK", "confidence": 0.8868916971342904}]}, {"text": "In this study, we primarily focus on the extraction of two-word expressions in Russian.", "labels": [], "entities": [{"text": "extraction of two-word expressions", "start_pos": 41, "end_pos": 75, "type": "TASK", "confidence": 0.8200859278440475}]}, {"text": "A number of lexical association measures and their combinations have been employed in previous studies about extraction of general-purpose collocations and domain-specific terms).", "labels": [], "entities": []}, {"text": "Ranked collocations with higher association scores are selected into the n-best list.", "labels": [], "entities": [{"text": "association scores", "start_pos": 32, "end_pos": 50, "type": "METRIC", "confidence": 0.9473437964916229}]}, {"text": "These simple approaches are limited by the size of corpora and the effect of low frequency on ranking).", "labels": [], "entities": []}, {"text": "Most studies regard MWE as a classification task and based on supervised methods to predict the class (collocations or non-collocations) to which an MWE candidate relates (.", "labels": [], "entities": [{"text": "MWE", "start_pos": 20, "end_pos": 23, "type": "TASK", "confidence": 0.9683594107627869}]}, {"text": "There is no labeled training set in Russian for these approaches, and data annotation is time-consuming.", "labels": [], "entities": []}, {"text": "The task could be seen as a ranking task: ranking model group comparable entities into queries by criteria and constructing a ranking model using training data with exemplars to predict a ranking score.", "labels": [], "entities": []}, {"text": "However, there are no formal principles on how to detect comparable MWEs from general-purpose corpora for Russian.", "labels": [], "entities": []}, {"text": "Therefore, in this study we focus on clustering semantically similar MWE candidates using association measures, calculated on a general-purpose corpora and Wikipedia.", "labels": [], "entities": [{"text": "clustering semantically similar MWE candidates", "start_pos": 37, "end_pos": 83, "type": "TASK", "confidence": 0.8227055788040161}]}, {"text": "A particular general-purpose corpus, such as the Russian National Corpus or the British National Corpus, provides only a partial coverage of the modern language.", "labels": [], "entities": [{"text": "Russian National Corpus", "start_pos": 49, "end_pos": 72, "type": "DATASET", "confidence": 0.7632885773976644}, {"text": "British National Corpus", "start_pos": 80, "end_pos": 103, "type": "DATASET", "confidence": 0.9617947538693746}]}, {"text": "Although association measures have been widely applied, they have a limitation: the computed probabilities maybe small in the particular corpus, which gives a lower rank for MWE in the n-best list.", "labels": [], "entities": []}, {"text": "To avoid this situation, we incorporate the standard statistical measure, computed from the generalpurpose corpus, with Wikipedia, that contains avast amount of knowledge (e.g., named entities, domainspecific terms, and disambiguation of word senses).", "labels": [], "entities": []}, {"text": "Given a small number of most representative MWEs as exemplars, our primary goal is to identify MWE noun candidates, considering similarity between a candidate and the exemplars, based on association scores in both resources.", "labels": [], "entities": []}, {"text": "Our method consists of three steps: (i) extracting bigrams that serve as MWE candidates, adopting Wikipedia arti-cles, and using predefined morphosyntactic patterns; (ii) grouping the candidates using clustering techniques; and (iii) ranking MWE candidates by a score, which is computed based on the distance between the candidate and the closest exemplar multiplied by the percent of exemplars in the cluster.", "labels": [], "entities": []}, {"text": "The third step relies on the intuition that MWEs are highly ranked in clusters with a higher number of exemplars due to strong similarity between these expressions.", "labels": [], "entities": []}, {"text": "We demonstrate that combining association measures from two resources is effective, and improvement according to precision-recall curves can be achieved by a small number of measures combined.", "labels": [], "entities": [{"text": "precision-recall", "start_pos": 113, "end_pos": 129, "type": "METRIC", "confidence": 0.995561957359314}]}], "datasetContent": [{"text": "We use the Russian National Corpus (RNC) and the British National Corpus (BNC) as the generalpurpose corpus of the Russian language and the English language, respectively.", "labels": [], "entities": [{"text": "Russian National Corpus (RNC)", "start_pos": 11, "end_pos": 40, "type": "DATASET", "confidence": 0.8269960780938467}, {"text": "British National Corpus (BNC)", "start_pos": 49, "end_pos": 78, "type": "DATASET", "confidence": 0.9743525485197703}]}, {"text": "For corpora in Russian, we generated frequency lists of bigrams in singular and plural forms.", "labels": [], "entities": []}, {"text": "We adopt n-gram data of English Wikipedia and the BNC, extracted by and.", "labels": [], "entities": [{"text": "English Wikipedia", "start_pos": 24, "end_pos": 41, "type": "DATASET", "confidence": 0.9000296592712402}, {"text": "BNC", "start_pos": 50, "end_pos": 53, "type": "DATASET", "confidence": 0.8880517482757568}]}, {"text": "We suppose that all MWE candidates occur at least once in corpora due to frequency thresholds in the lists.", "labels": [], "entities": [{"text": "MWE", "start_pos": 20, "end_pos": 23, "type": "TASK", "confidence": 0.9670354723930359}]}, {"text": "shows MWEs that are top-ranked by our approach.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Summary of the list of MWE candidates.", "labels": [], "entities": [{"text": "Summary", "start_pos": 10, "end_pos": 17, "type": "METRIC", "confidence": 0.6336387395858765}, {"text": "MWE", "start_pos": 33, "end_pos": 36, "type": "TASK", "confidence": 0.8282429575920105}]}, {"text": " Table 3: Evaluation results with a varied number of clus- ters, n equals to 3,500 (for Russian).", "labels": [], "entities": []}]}