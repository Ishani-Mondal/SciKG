{"title": [], "abstractContent": [{"text": "We present our state of the art multilingual text summarizer capable of single as well as multi-document text summa-rization.", "labels": [], "entities": [{"text": "multilingual text summarizer", "start_pos": 32, "end_pos": 60, "type": "TASK", "confidence": 0.5560932457447052}]}, {"text": "The algorithm is based on repeated application of TextRank on a sentence similarity graph, a bag of words model for sentence similarity and a number of linguistic pre-and post-processing steps using standard NLP tools.", "labels": [], "entities": [{"text": "sentence similarity", "start_pos": 116, "end_pos": 135, "type": "TASK", "confidence": 0.7071215361356735}]}, {"text": "We submitted this algorithm for two different tasks of the MultiLing 2015 summa-rization challenge: Multilingual Single-document Summarization and Multilingual Multi-document Summarization.", "labels": [], "entities": [{"text": "MultiLing 2015 summa-rization challenge", "start_pos": 59, "end_pos": 98, "type": "TASK", "confidence": 0.625950500369072}, {"text": "Multilingual Single-document Summarization", "start_pos": 100, "end_pos": 142, "type": "TASK", "confidence": 0.5882572531700134}, {"text": "Multilingual Multi-document Summarization", "start_pos": 147, "end_pos": 188, "type": "TASK", "confidence": 0.595696876446406}]}], "introductionContent": [{"text": "The amount of textual content that is produced and consumed each day allover the world, through news websites, social media, and other information sources, is constantly growing.", "labels": [], "entities": []}, {"text": "This makes the process of selecting the right content to read and quickly recognizing basic facts and topics in texts a core task for making content accessible to the users.", "labels": [], "entities": []}, {"text": "Automatic summarization strives to provide a means to this end.", "labels": [], "entities": [{"text": "summarization", "start_pos": 10, "end_pos": 23, "type": "TASK", "confidence": 0.8640432357788086}]}, {"text": "This paper describes our automatic summarization system, and its participation in the MultiLing 2015 summarization challenge.", "labels": [], "entities": [{"text": "summarization", "start_pos": 35, "end_pos": 48, "type": "TASK", "confidence": 0.9271599650382996}, {"text": "MultiLing 2015 summarization challenge", "start_pos": 86, "end_pos": 124, "type": "TASK", "confidence": 0.7184656113386154}]}, {"text": "Our focus has been on producing a largely language-independent solution for the MultiLing 2015 challenge that, in contrast to most attempts in this field, requires a strict minimum of languagespecific components and uses no language-specific materials for the core innovative elements.", "labels": [], "entities": [{"text": "MultiLing 2015 challenge", "start_pos": 80, "end_pos": 104, "type": "TASK", "confidence": 0.8136924107869467}]}, {"text": "Our motivation comes in part from, who compares a number of single language summarization systems on the same standardized data set and shows that many complex, language-specific, highly optimized and trained methods do not significantly out-perform simplistic algorithms that date back to the first summarization competitions in 2004.", "labels": [], "entities": [{"text": "summarization competitions in 2004", "start_pos": 300, "end_pos": 334, "type": "TASK", "confidence": 0.9178456217050552}]}, {"text": "Language-independent text summarization is generally based on sentence extractive methods: A subset of sentences in a text are identified and combined to form a summary, rather than performing more complex operations, and the primary task of summarization algorithms is to identify the set of sentences that form the best summary.", "labels": [], "entities": [{"text": "Language-independent text summarization", "start_pos": 0, "end_pos": 39, "type": "TASK", "confidence": 0.5571703811486562}, {"text": "summarization", "start_pos": 242, "end_pos": 255, "type": "TASK", "confidence": 0.9786717891693115}]}, {"text": "In this case, algorithms differ mostly in how sentences are selected.", "labels": [], "entities": []}, {"text": "One textual feature that has proven useful in identifying good summary sentences is the relative prominence of specific words in texts when contrasted to a reference distribution (like frequency in a large general corpus).", "labels": [], "entities": []}, {"text": "For example, the \"keyness\" metric in, singular value decomposition on a term-vector matrix and neural network-derived transformations of term vectors) have all produced significant results.", "labels": [], "entities": []}, {"text": "There are also a number of rule-based approaches like.", "labels": [], "entities": []}, {"text": "provides an overview of various current approaches, ranging from simple baseline algorithms to complex systems with many machine learning and rule-based components of various kinds.", "labels": [], "entities": []}, {"text": "One promising recent approach is graph theorybased schemes which construct sentence similarity graphs and use various graph techniques to determine the importance of specific sentences as a heuristic to identify good summary sentences.", "labels": [], "entities": []}, {"text": "In this paper, we describe ExB's graphbased summarization approach and its results in two MultiLing 2015 tasks: Multilingual Singledocument Summarization and Multilingual Multidocument Summarization.", "labels": [], "entities": [{"text": "Multilingual Singledocument Summarization", "start_pos": 112, "end_pos": 153, "type": "TASK", "confidence": 0.5960850417613983}, {"text": "Multilingual Multidocument Summarization", "start_pos": 158, "end_pos": 198, "type": "TASK", "confidence": 0.5927177369594574}]}, {"text": "ExB's submissions covered all languages in each task.", "labels": [], "entities": [{"text": "ExB", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.9082111716270447}]}, {"text": "Furthermore, we summarize and discuss some unexpected negative experimental results, particularly in light of the problems posed by summarization tasks and their evaluation using ROUGE).", "labels": [], "entities": [{"text": "summarization tasks", "start_pos": 132, "end_pos": 151, "type": "TASK", "confidence": 0.9112978875637054}, {"text": "ROUGE", "start_pos": 179, "end_pos": 184, "type": "METRIC", "confidence": 0.8877615332603455}]}], "datasetContent": [{"text": "When experimenting with the challenge data we made several observations: 1.", "labels": [], "entities": []}, {"text": "Since the dataset of MMS is composed of news articles, just selecting the headlines and first sentences will produce a strong baseline with very high ROUGE scores.", "labels": [], "entities": [{"text": "MMS", "start_pos": 21, "end_pos": 24, "type": "TASK", "confidence": 0.8605437278747559}, {"text": "ROUGE", "start_pos": 150, "end_pos": 155, "type": "METRIC", "confidence": 0.9972714781761169}]}, {"text": "It is difficult to beat this baseline using sentence extraction techniques.", "labels": [], "entities": [{"text": "sentence extraction", "start_pos": 44, "end_pos": 63, "type": "TASK", "confidence": 0.7285425215959549}]}, {"text": "2. The quality of the summaries varies a great deal between languages.", "labels": [], "entities": []}, {"text": "Instead of producing fine-tuned configurations for each lan-   guage that optimize ROUGE scores, we focused on increasing the performance in English -a language we can read and in which we can qualitatively evaluate the produced summaries.", "labels": [], "entities": [{"text": "ROUGE scores", "start_pos": 83, "end_pos": 95, "type": "METRIC", "confidence": 0.9547838270664215}]}, {"text": "3. All the results hereof the time information processing are at document-level.", "labels": [], "entities": []}, {"text": "We also tried to apply the time grouping algorithms per sentence, but we noticed a drop of about 3% ROUGE-2 score on average.", "labels": [], "entities": [{"text": "time grouping", "start_pos": 27, "end_pos": 40, "type": "TASK", "confidence": 0.6266297250986099}, {"text": "ROUGE-2 score", "start_pos": 100, "end_pos": 113, "type": "METRIC", "confidence": 0.9830466210842133}]}, {"text": "The most important finding is that using temporal expressions and chronological information does improve the performance of the summary system, and that the iterative FairTextRank algorithm shows a solid performance even for multiple documents.", "labels": [], "entities": []}, {"text": "As can be seen in, our system gets ranked in middle position in the official scores of the challenge using the NPowER, MeMoG and AutoSummENG measures as described in and.", "labels": [], "entities": [{"text": "NPowER", "start_pos": 111, "end_pos": 117, "type": "DATASET", "confidence": 0.799686074256897}, {"text": "MeMoG", "start_pos": 119, "end_pos": 124, "type": "DATASET", "confidence": 0.794833779335022}]}, {"text": "We also note that our system out-performs all other participants in Chinese, a language for which we had no training data.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Number of covered languages and average rank for each system in MSS competition for  ROUGE-(1,2,3,4,4-SU) measures. In bold, competitors in all available languages. Lead and Oracles  are two reference systems created by the organizers.", "labels": [], "entities": [{"text": "ROUGE-(1,2,3,4,4-SU)", "start_pos": 95, "end_pos": 115, "type": "METRIC", "confidence": 0.9239733517169952}]}, {"text": " Table 2: ROUGE-2 recall results for different  grouping algorithms in MMS-2011 dataset.", "labels": [], "entities": [{"text": "ROUGE-2", "start_pos": 10, "end_pos": 17, "type": "METRIC", "confidence": 0.9427144527435303}, {"text": "recall", "start_pos": 18, "end_pos": 24, "type": "METRIC", "confidence": 0.8399803042411804}, {"text": "MMS-2011 dataset", "start_pos": 71, "end_pos": 87, "type": "DATASET", "confidence": 0.9139115512371063}]}, {"text": " Table 3: Average per-language Score ranked  against the best run of each system in MMS com- petition for MeMoG measure.", "labels": [], "entities": [{"text": "MMS com- petition", "start_pos": 84, "end_pos": 101, "type": "DATASET", "confidence": 0.8321057111024857}, {"text": "MeMoG measure", "start_pos": 106, "end_pos": 119, "type": "DATASET", "confidence": 0.831098198890686}]}]}