{"title": [{"text": "Learning Embeddings for Transitive Verb Disambiguation by Implicit Tensor Factorization", "labels": [], "entities": [{"text": "Transitive Verb Disambiguation", "start_pos": 24, "end_pos": 54, "type": "TASK", "confidence": 0.6936101714769999}]}], "abstractContent": [{"text": "We present an implicit tensor factorization method for learning the embeddings of transitive verb phrases.", "labels": [], "entities": []}, {"text": "Unlike the implicit matrix factorization methods recently proposed for learning word embeddings, our method directly models the interaction between predicates and their two arguments, and learns verb phrase embeddings.", "labels": [], "entities": []}, {"text": "By representing transitive verbs as matrices, our method captures multiple meanings of transitive verbs and disambiguates them taking their arguments into account.", "labels": [], "entities": []}, {"text": "We evaluate our method on a widely-used verb disambiguation task and three phrase similarity tasks.", "labels": [], "entities": [{"text": "verb disambiguation", "start_pos": 40, "end_pos": 59, "type": "TASK", "confidence": 0.7168826311826706}, {"text": "phrase similarity", "start_pos": 75, "end_pos": 92, "type": "TASK", "confidence": 0.7054738253355026}]}, {"text": "On the disambiguation task, our method outperforms previous state-of-the-art methods.", "labels": [], "entities": []}, {"text": "Our experimental results also show that adjuncts provide useful information in learning the meanings of verb phrases.", "labels": [], "entities": [{"text": "learning the meanings of verb phrases", "start_pos": 79, "end_pos": 116, "type": "TASK", "confidence": 0.7163451413313547}]}], "introductionContent": [{"text": "There is a growing interest in learning vectorspace representations of words and phrases using large training corpora in the field of Natural Language Processing (NLP) (.", "labels": [], "entities": []}, {"text": "The phrase representations are usually computed by composition models that combine the meanings of words into the meanings of phrases.", "labels": [], "entities": []}, {"text": "While some studies focus on representing entire phrases or sentences using syntactic structures (), others focus on representing the meaning of transitive verb phrases.", "labels": [], "entities": []}, {"text": "In this paper, we investigate vector-space representations of transitive verb phrases.", "labels": [], "entities": []}, {"text": "The meaning of a transitive verb is often ambiguous and disambiguated by its arguments, i.e., subjects and objects.", "labels": [], "entities": []}, {"text": "Investigation of transitive verb phrases should therefore provide insights into how composition models can capture such semantic interactions between words.", "labels": [], "entities": []}, {"text": "Moreover, in practice, capturing the meanings of transitive verb phrases should be useful in many real-world NLP applications such as semantic retrieval () and question answering (Who did What to Whom?)).", "labels": [], "entities": [{"text": "capturing the meanings of transitive verb phrases", "start_pos": 23, "end_pos": 72, "type": "TASK", "confidence": 0.7843008892876762}, {"text": "semantic retrieval", "start_pos": 134, "end_pos": 152, "type": "TASK", "confidence": 0.7716187536716461}, {"text": "question answering (Who did What to Whom?))", "start_pos": 160, "end_pos": 203, "type": "TASK", "confidence": 0.8581341505050659}]}, {"text": "There are several approaches to representing transitive verb phrases in a vector space using large unannotated corpora.", "labels": [], "entities": []}, {"text": "One is based on tensor calculus (; Van de Cruys et al., 2013) and another is based on neural networks ().", "labels": [], "entities": []}, {"text": "In the tensor-based methods, transitive verbs are represented as matrices, and they are constructed by using the pre-trained word embeddings of their subjects and objects.", "labels": [], "entities": []}, {"text": "One limitation of this approach is that the embeddings of subjectverb-object phrases are computed statically, i.e., the composition process and the embedding (or matrix) construction process are conducted separately.", "labels": [], "entities": []}, {"text": "In the neural network-based methods, the embeddings of words and phrases can be learned jointly ().", "labels": [], "entities": []}, {"text": "However, the strong interaction between verbs and their arguments is not fully captured in their method because it relies on shallow neural networks using diagonal weight matrices which are designed to work on large training corpora.", "labels": [], "entities": []}, {"text": "To bridge the gap between the two approaches, we present an implicit tensor factorization method 1 for learning the embeddings of transitive verb phrases.", "labels": [], "entities": []}, {"text": "We assume a three-mode tensor in which the value of each element represents the level of plausibility of a tuple of a predicate and its two arguments (Van de).", "labels": [], "entities": []}, {"text": "We then implicitly factorize the tensor into three latent factors, namely one predicate tensor and two argument matrices.", "labels": [], "entities": []}, {"text": "This is motivated by the recently proposed implicit matrix factorization methods for learning word embeddings (.", "labels": [], "entities": []}, {"text": "Our method trains matrices representing predicates and embeddings of their arguments so that they maximize the accuracy of predicting the plausibility of the predicateargument tuples in the training corpus.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 111, "end_pos": 119, "type": "METRIC", "confidence": 0.9992270469665527}]}, {"text": "The transitive verb matrices and the embeddings of their subject and object are thus jointly learned.", "labels": [], "entities": []}, {"text": "Furthermore, this method allows us to exploit the role of prepositional adjuncts when learning the meaning of verb phrases by modeling the relationship between prepositions and verb phrases.", "labels": [], "entities": []}, {"text": "Our experimental results show that our method enables predicates and their arguments to strongly interact with each other and that adjuncts are useful in learning the meaning of verb phrases.", "labels": [], "entities": [{"text": "learning the meaning of verb phrases", "start_pos": 154, "end_pos": 190, "type": "TASK", "confidence": 0.7228286266326904}]}, {"text": "We evaluate our method using a widely-used verb disambiguation task and three phrase similarity tasks.", "labels": [], "entities": [{"text": "verb disambiguation", "start_pos": 43, "end_pos": 62, "type": "TASK", "confidence": 0.7127895355224609}, {"text": "phrase similarity", "start_pos": 78, "end_pos": 95, "type": "TASK", "confidence": 0.6853125840425491}]}, {"text": "On the disambiguation dataset provided by, we have achieved a Spearman's rank correlation score of 0.614, which is significantly higher than the state of the art (0.456).", "labels": [], "entities": [{"text": "Spearman's rank correlation score", "start_pos": 62, "end_pos": 95, "type": "METRIC", "confidence": 0.9483537197113037}]}, {"text": "This result demonstrates that the direct interaction between verbs and their arguments is important in tackling verb disambiguation tasks.", "labels": [], "entities": [{"text": "tackling verb disambiguation tasks", "start_pos": 103, "end_pos": 137, "type": "TASK", "confidence": 0.8822766989469528}]}, {"text": "Qualitative evaluation further shows that the meanings of ambiguous verbs can be disambiguated according to their arguments and the learned verb matrices capture multiple meanings of transitive verbs.", "labels": [], "entities": []}], "datasetContent": [{"text": "We evaluated the learned embeddings of transitive verbs using a transitive verb disambiguation task and three tasks for measuring the semantic similarity between transitive verb phrases.", "labels": [], "entities": [{"text": "transitive verb disambiguation", "start_pos": 64, "end_pos": 94, "type": "TASK", "confidence": 0.7127829194068909}]}, {"text": "Each phrase 0.456 n/a n/a 0.732 0.422 0.669 0.612 0.770 0.35 n/a 0.58 n/a: Results for the transitive verb tasks using the BNC data.", "labels": [], "entities": [{"text": "BNC data", "start_pos": 123, "end_pos": 131, "type": "DATASET", "confidence": 0.9494071900844574}]}, {"text": "pair in the four datasets is paired with multiple human ratings: the higher the rating is, the more semantically similar the phrases are.", "labels": [], "entities": []}, {"text": "To evaluate the learned verb phrase embeddings on each dataset, we used the Spearman's rank correlation between the human ratings and the cosine similarity between the phrase embeddings.", "labels": [], "entities": [{"text": "Spearman's rank correlation", "start_pos": 76, "end_pos": 103, "type": "METRIC", "confidence": 0.715374305844307}]}, {"text": "We calculated the correlation scores using averaged human ratings.", "labels": [], "entities": [{"text": "correlation", "start_pos": 18, "end_pos": 29, "type": "METRIC", "confidence": 0.9748147130012512}]}, {"text": "Each phrase pair in the datasets was annotated by more than two annotators and we took the average of the multiple human ratings for each phrase pair.", "labels": [], "entities": []}, {"text": "The first dataset GS'11 is provided by.", "labels": [], "entities": [{"text": "GS'11", "start_pos": 18, "end_pos": 23, "type": "DATASET", "confidence": 0.8164551258087158}]}, {"text": "GS'11 consists of pairs of transitive verbs and each verb pair takes the same subject and object.", "labels": [], "entities": [{"text": "GS'11", "start_pos": 0, "end_pos": 5, "type": "DATASET", "confidence": 0.8521711826324463}]}, {"text": "As discussed in previous work), GS'11 has an aspect of a verb sense disambiguation task.", "labels": [], "entities": [{"text": "verb sense disambiguation task", "start_pos": 57, "end_pos": 87, "type": "TASK", "confidence": 0.7301515191793442}]}, {"text": "For example, the transitive verb \"run\" is known as a polysemous word and this task requires one to identify the meanings of \"run\" and \"operate\" are similar to each other when taking \"people\" as their subject and \"company\" as their object.", "labels": [], "entities": []}, {"text": "In the same setting, however, the meanings of \"run\" and \"move\" are not similar to each other.", "labels": [], "entities": []}, {"text": "The task is suitable for evaluating our method since our method allows verbs and their subjects and objects to multiplicatively interact with each other.", "labels": [], "entities": []}, {"text": "0.35 n/a 0.58 n/a: Results for the transitive verb tasks using the enWiki data.", "labels": [], "entities": [{"text": "enWiki data", "start_pos": 67, "end_pos": 78, "type": "DATASET", "confidence": 0.9429200291633606}]}, {"text": "The other datasets are ML'10 provided by Mitchell and Lapata (2010), KS'13 provided by, and KS'14 provided by.", "labels": [], "entities": []}, {"text": "ML'10 consists of pairs of verb-object phrases and KS'13 complements ML'10 by incorporating an appropriate subject for each verb-object phrase.", "labels": [], "entities": [{"text": "ML'10", "start_pos": 0, "end_pos": 5, "type": "DATASET", "confidence": 0.8700370788574219}]}, {"text": "KS'14 is the reannotated version of KS'13 using a cloud sourcing service.", "labels": [], "entities": [{"text": "KS'14", "start_pos": 0, "end_pos": 5, "type": "DATASET", "confidence": 0.9357616305351257}]}, {"text": "Unlike GS'11, these three datasets require one to capture the topical similarity rather than the disambiguation aspect (). and 5 show the evaluation results using BNC and enWiki, respectively.", "labels": [], "entities": [{"text": "GS'11", "start_pos": 7, "end_pos": 12, "type": "DATASET", "confidence": 0.8750584721565247}, {"text": "BNC", "start_pos": 163, "end_pos": 166, "type": "DATASET", "confidence": 0.6680554151535034}]}, {"text": "The results are shown for each method, datatype, and embedding dimensionality.", "labels": [], "entities": []}, {"text": "These tables also show the results from other work () on the same tasks while the training settings, such as the corpus and information used in the training, are different from those in this work.", "labels": [], "entities": []}, {"text": "However, the evaluation settings are the same with those in the previous work.", "labels": [], "entities": []}, {"text": "That is, in the previous work, averaged human ratings were used to evaluate the Spearman's rank correlation scores, similarity scores between subject-verb-object phrases were used for GS, and similarity scores between verb-object phrases were used for ML'10.", "labels": [], "entities": [{"text": "Spearman's rank correlation scores", "start_pos": 80, "end_pos": 114, "type": "METRIC", "confidence": 0.615108597278595}, {"text": "ML'10", "start_pos": 252, "end_pos": 257, "type": "TASK", "confidence": 0.5266674160957336}]}, {"text": "Finally, we inspect the learned verb matrices using the SVO data of enWiki with d = 50.", "labels": [], "entities": [{"text": "SVO data of enWiki", "start_pos": 56, "end_pos": 74, "type": "DATASET", "confidence": 0.7934550493955612}]}, {"text": "Compared with the word embeddings, the verb matrices have two-dimensional structure.", "labels": [], "entities": []}, {"text": "(3), each row vector and each column vector in a verb matrix are updated to capture the information about what subject-object pairs are relevant (or irrelevant) to the verb.", "labels": [], "entities": []}, {"text": "shows the nearest neighbor verbs using the cosine similarity between row (or column) vectors in the verb matrices.", "labels": [], "entities": []}, {"text": "For reference, we also show the results using the vectorized representation of the verb matrices (denoted as \"all\" in the table).", "labels": [], "entities": []}, {"text": "While the entire matrices capture the general similarity between verbs as with word embeddings, some specific rows (or columns) capture the multiple meanings of usages of the verbs.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 3: Evaluation results on the plausibility  judgment task on the SVO development data.", "labels": [], "entities": [{"text": "SVO development data", "start_pos": 71, "end_pos": 91, "type": "DATASET", "confidence": 0.875552773475647}]}, {"text": " Table 4: Results for the transitive verb tasks using  the BNC data.", "labels": [], "entities": [{"text": "BNC data", "start_pos": 59, "end_pos": 67, "type": "DATASET", "confidence": 0.9390726387500763}]}, {"text": " Table 5: Results for the transitive verb tasks using  the enWiki data.", "labels": [], "entities": [{"text": "enWiki data", "start_pos": 59, "end_pos": 70, "type": "DATASET", "confidence": 0.9642481207847595}]}]}