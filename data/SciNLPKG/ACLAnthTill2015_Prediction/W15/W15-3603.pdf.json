{"title": [{"text": "Counting What Counts: Decompounding for Keyphrase Extraction", "labels": [], "entities": [{"text": "Counting", "start_pos": 0, "end_pos": 8, "type": "TASK", "confidence": 0.9271512627601624}, {"text": "Decompounding for Keyphrase Extraction", "start_pos": 22, "end_pos": 60, "type": "TASK", "confidence": 0.6585612446069717}]}], "abstractContent": [{"text": "A core assumption of keyphrase extraction is that a concept is more important if it is mentioned more often in a document.", "labels": [], "entities": [{"text": "keyphrase extraction", "start_pos": 21, "end_pos": 41, "type": "TASK", "confidence": 0.8274812400341034}]}, {"text": "Especially in languages like German that form large noun compounds, frequency counts might be misleading as concepts \"hidden\" in compounds are not counted.", "labels": [], "entities": []}, {"text": "We hypothesize that using decompound-ing before counting term frequencies may lead to better keyphrase extraction.", "labels": [], "entities": [{"text": "keyphrase extraction", "start_pos": 93, "end_pos": 113, "type": "TASK", "confidence": 0.8048348724842072}]}, {"text": "We identified two effects of decompounding: (i) enhanced frequency counts, and (ii) more keyphrase candidates.", "labels": [], "entities": []}, {"text": "We created two German evaluation datasets to test our hypothesis and analyzed the effect of additional decompounding for keyphrase extraction .", "labels": [], "entities": [{"text": "German evaluation datasets", "start_pos": 15, "end_pos": 41, "type": "DATASET", "confidence": 0.6905816992123922}, {"text": "keyphrase extraction", "start_pos": 121, "end_pos": 141, "type": "TASK", "confidence": 0.8470714688301086}]}], "introductionContent": [{"text": "Most approaches for automatic extraction of keyphrases are based on the assumption that the more frequent a term or phrase is mentioned, the more important it is.", "labels": [], "entities": [{"text": "automatic extraction of keyphrases", "start_pos": 20, "end_pos": 54, "type": "TASK", "confidence": 0.8183697536587715}]}, {"text": "Consequently, most extraction algorithms apply some kind of normalization, e.g. lemmatization or noun chunking, in order to arrive with accurate counts.", "labels": [], "entities": [{"text": "noun chunking", "start_pos": 97, "end_pos": 110, "type": "TASK", "confidence": 0.7964284718036652}]}, {"text": "However, especially in Germanic languages the frequent use of noun compounds has an adverse effect on the reliability of frequency counts.", "labels": [], "entities": [{"text": "reliability", "start_pos": 106, "end_pos": 117, "type": "METRIC", "confidence": 0.978904664516449}]}, {"text": "Consider for example a German document that talks about Lehrer (Engl.: teacher) without ever mentioning the word \"Lehrer\" at all, because it is always part of compounds like Deutschlehrer (Engl.: German teacher) or Gymnasiallehrer (Engl.: grammar school teacher).", "labels": [], "entities": []}, {"text": "Thus, we argue that the problem can be solved by splitting noun compounds in meaningful parts, i.e. by performing decompounding.", "labels": [], "entities": []}, {"text": "give an example for decompounding Deutschlehrer Deutsch Lehrer: Decompounding of German term Deutschlehrer (Engl.: German teacher).", "labels": [], "entities": []}, {"text": "The compound Deutschlehrer consists of the parts Deutsch (Engl.: German) and Lehrer (Engl.: teacher).", "labels": [], "entities": []}, {"text": "In this paper, we propose a comprehensive decompounding architecture and analyze the performance of four state-of-the-art algorithms.", "labels": [], "entities": []}, {"text": "We then perform experiments on three German datasets, of which two have been created particularly for these experiments, in order to analyze the impact of decompounding on standard keyphrase extraction approaches.", "labels": [], "entities": [{"text": "German datasets", "start_pos": 37, "end_pos": 52, "type": "DATASET", "confidence": 0.8121325075626373}, {"text": "keyphrase extraction", "start_pos": 181, "end_pos": 201, "type": "TASK", "confidence": 0.7645478546619415}]}, {"text": "Decompounding has previously been successfully used in other applications, e.g. in machine translation (, information retrieval (), speech recognition, and word prediction ().", "labels": [], "entities": [{"text": "machine translation", "start_pos": 83, "end_pos": 102, "type": "TASK", "confidence": 0.8328257203102112}, {"text": "information retrieval", "start_pos": 106, "end_pos": 127, "type": "TASK", "confidence": 0.7849420011043549}, {"text": "speech recognition", "start_pos": 132, "end_pos": 150, "type": "TASK", "confidence": 0.8102560937404633}, {"text": "word prediction", "start_pos": 156, "end_pos": 171, "type": "TASK", "confidence": 0.8339669108390808}]}, {"text": "have shown that infrequency errors area major cause for lower keyphrase extraction results . To the best of our knowledge, we are the first to examine the influence of decompounding on keyphrase extraction.", "labels": [], "entities": [{"text": "keyphrase extraction", "start_pos": 62, "end_pos": 82, "type": "TASK", "confidence": 0.7434654533863068}, {"text": "keyphrase extraction", "start_pos": 185, "end_pos": 205, "type": "TASK", "confidence": 0.8222093284130096}]}], "datasetContent": [{"text": "For evaluation, we use the corpus created by as a gold standard to evaluate the performance of the decompounding methods.", "labels": [], "entities": []}, {"text": "This corpus contains a list of 158,653 compounds, stating how each compound should be decompounded.", "labels": [], "entities": []}, {"text": "The compounds were obtained from the issues 01/2000 to 13/2004 of the German computer magazine c't 5 in a semi-automatic approach.", "labels": [], "entities": [{"text": "01/2000 to 13/2004 of the German computer magazine c't 5", "start_pos": 44, "end_pos": 100, "type": "DATASET", "confidence": 0.6990647693475087}]}, {"text": "Human annotators reviewed the list to identify and correct possible errors.", "labels": [], "entities": []}, {"text": "For calculating the required frequencies, we use the Web1T corpus ().", "labels": [], "entities": [{"text": "Web1T corpus", "start_pos": 53, "end_pos": 65, "type": "DATASET", "confidence": 0.9759271442890167}]}, {"text": "use a modified version of precision and recall for evaluating decompounding performance.", "labels": [], "entities": [{"text": "precision", "start_pos": 26, "end_pos": 35, "type": "METRIC", "confidence": 0.9996646642684937}, {"text": "recall", "start_pos": 40, "end_pos": 46, "type": "METRIC", "confidence": 0.9963492155075073}]}, {"text": "Following, we decided to apply these metrics for measuring the splitting algorithms, and ranking the functions' performance.", "labels": [], "entities": []}, {"text": "The following counts were used for evaluating the experiments on the compound level: correct split (cs), a split fragment which was correctly identified and wrong split (ws), a split fragment which was wrongly identified.", "labels": [], "entities": [{"text": "correct split (cs)", "start_pos": 85, "end_pos": 103, "type": "METRIC", "confidence": 0.9659711241722106}, {"text": "wrong split (ws)", "start_pos": 157, "end_pos": 173, "type": "METRIC", "confidence": 0.8319584965705872}]}, {"text": "P comp and R comp evaluate decompounding on the level of compounds, and we propose to use P split = cs cs + ws to evaluate on the level of splits.", "labels": [], "entities": []}, {"text": "As we focus in this work on the influence of decompounding on improving the accuracy of fre-  quency counts, P split is the best metric in our case.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 76, "end_pos": 84, "type": "METRIC", "confidence": 0.9987724423408508}, {"text": "fre-  quency counts", "start_pos": 88, "end_pos": 107, "type": "METRIC", "confidence": 0.8653186410665512}, {"text": "P split", "start_pos": 109, "end_pos": 116, "type": "METRIC", "confidence": 0.9588581919670105}]}, {"text": "We can see in that the ASV Toolbox splitting algorithm is the best performing system in respect to P split . Thus, we select it as the decompounding algorithm in our keyphrase extraction experiments described in the next section.", "labels": [], "entities": [{"text": "ASV Toolbox splitting", "start_pos": 23, "end_pos": 44, "type": "TASK", "confidence": 0.7822615504264832}, {"text": "keyphrase extraction", "start_pos": 166, "end_pos": 186, "type": "TASK", "confidence": 0.8483306169509888}]}, {"text": "For our evaluation, we could not rely on English datasets, as there is only very little compounding and thus the expected effect of decompounding is small.", "labels": [], "entities": []}, {"text": "German is a good choice, as it is infamous for its heavy compounding, e.g. the well-known Donaudampfschifffahrtskapit\u00e4n (Engl.: captain of a steamship on the river Danube).", "labels": [], "entities": []}, {"text": "For German keyphrase extraction, we can use the peDOCS datasets described in and we created two additional datasets consisting of summaries of lesson transcripts (Pythagoras) and posts from a medical forum (MedForum).", "labels": [], "entities": [{"text": "German keyphrase extraction", "start_pos": 4, "end_pos": 31, "type": "TASK", "confidence": 0.6398817499478658}, {"text": "peDOCS datasets", "start_pos": 48, "end_pos": 63, "type": "DATASET", "confidence": 0.7372389286756516}]}, {"text": "peDOCS consists of peer-reviewed articles, dissertations, and books from the educational domain published by researchers.", "labels": [], "entities": []}, {"text": "The gold standard for this dataset was compiled by professional indexers and should thus be of high quality.", "labels": [], "entities": []}, {"text": "We present two novel keyphrase datasets consisting of German texts.", "labels": [], "entities": []}, {"text": "MedForum is composed of posts from a medical forum.", "labels": [], "entities": [{"text": "MedForum", "start_pos": 0, "end_pos": 8, "type": "DATASET", "confidence": 0.9393583536148071}]}, {"text": "To our knowledge, it is the first dataset with keyphrase annotations from user-generated data in German.", "labels": [], "entities": []}, {"text": "Two German annotators with university degrees identified a set of keyphrases for every document and following, the union of both sets are the final gold keyphrases.", "labels": [], "entities": []}, {"text": "The Pythagoras dataset contains summaries of lesson transcripts compiled in the Pythagoras project.", "labels": [], "entities": [{"text": "Pythagoras dataset", "start_pos": 4, "end_pos": 22, "type": "DATASET", "confidence": 0.9283945560455322}]}, {"text": "8 Two annotators iden-tified keyphrases after a training phase with discussion of three documents.", "labels": [], "entities": []}, {"text": "As in the MedForum dataset, the gold standard consists of the union of lemmatized keyphrases by both annotators.", "labels": [], "entities": [{"text": "MedForum dataset", "start_pos": 10, "end_pos": 26, "type": "DATASET", "confidence": 0.9343541264533997}]}, {"text": "All datasets contain a unranked list of keyphrases.", "labels": [], "entities": []}, {"text": "The peDOCS dataset is by far the largest of the sets, since it has been created over the course of several years.", "labels": [], "entities": [{"text": "peDOCS dataset", "start_pos": 4, "end_pos": 18, "type": "DATASET", "confidence": 0.8360903263092041}]}, {"text": "MedForum and Pythagoras contain fewer documents but each document is annotated by a fixed pair of human annotators.", "labels": [], "entities": [{"text": "MedForum", "start_pos": 0, "end_pos": 8, "type": "DATASET", "confidence": 0.9701083898544312}]}, {"text": "The average number of keyphrases is highest for peDOCS and lowest for MedForum.", "labels": [], "entities": [{"text": "MedForum", "start_pos": 70, "end_pos": 78, "type": "DATASET", "confidence": 0.9569499492645264}]}, {"text": "The length of the document also influences the number of keyphrases as short documents have fewer keyphrase candidates.", "labels": [], "entities": []}, {"text": "Keyphrases in all three datasets are on average very short.", "labels": [], "entities": []}, {"text": "The example in gives an example of a rather specific keyphrase which, however, consists of only one token.", "labels": [], "entities": []}, {"text": "We believe that keyphrase extraction approaches benefit from decompounding more in cases of short documents.", "labels": [], "entities": [{"text": "keyphrase extraction", "start_pos": 16, "end_pos": 36, "type": "TASK", "confidence": 0.8779194951057434}]}, {"text": "Longer documents provide more statistical data which reduces the need for additional statistical data obtained with decompounding.", "labels": [], "entities": []}, {"text": "For preprocessing, we rely on components from the DKPro Core framework) and on DKPro Lab (de Castilho and Gurevych, 2011) for building experimental pipelines.", "labels": [], "entities": [{"text": "DKPro Core framework", "start_pos": 50, "end_pos": 70, "type": "DATASET", "confidence": 0.9429023861885071}, {"text": "DKPro Lab (de Castilho and Gurevych, 2011)", "start_pos": 79, "end_pos": 121, "type": "DATASET", "confidence": 0.937369441986084}]}, {"text": "We use the Stanford Segmenter 9 for tokenization, TreeTagger for lemmatization and partof-speech tagging.", "labels": [], "entities": [{"text": "Stanford Segmenter 9", "start_pos": 11, "end_pos": 31, "type": "DATASET", "confidence": 0.8892585237820944}, {"text": "tokenization", "start_pos": 36, "end_pos": 48, "type": "TASK", "confidence": 0.9717052578926086}, {"text": "partof-speech tagging", "start_pos": 83, "end_pos": 104, "type": "TASK", "confidence": 0.8201621770858765}]}, {"text": "Finally, we perform stopword removal and decompounding as described in Section 2.", "labels": [], "entities": [{"text": "stopword removal", "start_pos": 20, "end_pos": 36, "type": "TASK", "confidence": 0.7963250577449799}]}, {"text": "It should be noted that inmost preprocessing pipelines, decompounding should be the last step, as it heavily influences POS-tagging.", "labels": [], "entities": []}, {"text": "We extract all lemmas in the document as keyphrase candidates and rank them according to basic ranking approaches based on frequency counts and the position in the document.", "labels": [], "entities": []}, {"text": "We do not use more sophisticated extraction approaches, as we want to examine the influence of decompounding as directly as possible.", "labels": [], "entities": []}, {"text": "However, it has been shown that frequency-based heuristics area very strong baseline (, and even supervised keyphrase extraction methods such as KEA () use term frequency and position as the most important features and will be heavily influenced by decompounding.", "labels": [], "entities": [{"text": "keyphrase extraction", "start_pos": 108, "end_pos": 128, "type": "TASK", "confidence": 0.7326310127973557}]}, {"text": "We evaluate the following ranking methods: tfidf constant ranks candidates according to their term frequency f (t, d) in the document.", "labels": [], "entities": []}, {"text": "tf-idf decreases the impact of words that occur inmost documents.", "labels": [], "entities": []}, {"text": "The term frequency count is normalized with the inverse document frequency in the test collection.", "labels": [], "entities": []}, {"text": "In this formula |D| is the number of documents and |d \u2208 D : t \u2208 d| is the number of documents mentioning term t.", "labels": [], "entities": []}, {"text": "As some document collections maybe too small to allow computing reliable frequency estimates, we also evaluated tf-idf web . Again, the document frequency is approximated by the frequency counts from the Web1T corpus.", "labels": [], "entities": [{"text": "Web1T corpus", "start_pos": 204, "end_pos": 216, "type": "DATASET", "confidence": 0.918976217508316}]}, {"text": "We take the position of a candidate as a baseline.", "labels": [], "entities": []}, {"text": "The closer the keyword is to the beginning of the text, the higher it is ranked.", "labels": [], "entities": []}, {"text": "This is not dependent on frequency counts, but decompounding can also have an influence if a compound that appears early in the document is split into parts that are now also possible keyphrase candidates.", "labels": [], "entities": []}, {"text": "We test each of the ranking methods with (w) and without (w/o) decompounding.", "labels": [], "entities": []}, {"text": "For the keyphrase experiments, we compare results in terms of precision and recall of the top-5 keyphrases (P@5), Mean Average Precision (MAP), and R-precision (R-p).", "labels": [], "entities": [{"text": "precision", "start_pos": 62, "end_pos": 71, "type": "METRIC", "confidence": 0.9991484880447388}, {"text": "recall", "start_pos": 76, "end_pos": 82, "type": "METRIC", "confidence": 0.9985015392303467}, {"text": "Mean Average Precision (MAP)", "start_pos": 114, "end_pos": 142, "type": "METRIC", "confidence": 0.9668918450673422}, {"text": "R-precision", "start_pos": 148, "end_pos": 159, "type": "METRIC", "confidence": 0.9583059549331665}]}, {"text": "10 MAP is the average precision of extracted keyphrases from 1 to the number of extracted keyphrases, which can be much higher than ten.", "labels": [], "entities": [{"text": "MAP", "start_pos": 3, "end_pos": 6, "type": "METRIC", "confidence": 0.9871438145637512}, {"text": "precision", "start_pos": 22, "end_pos": 31, "type": "METRIC", "confidence": 0.9966012239456177}]}, {"text": "R-precision 11 is the ratio of true positives in the set of extracted keyphrases when as many keyphrases as there are gold keyphrases are extracted.", "labels": [], "entities": [{"text": "R-precision 11", "start_pos": 0, "end_pos": 14, "type": "METRIC", "confidence": 0.8757402300834656}]}], "tableCaptions": [{"text": " Table 2: Corpus statistics of datasets.", "labels": [], "entities": []}, {"text": " Table 3: Difference of results with decompound- ing on the MedForum dataset.", "labels": [], "entities": [{"text": "Difference", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.8552747964859009}, {"text": "MedForum dataset", "start_pos": 60, "end_pos": 76, "type": "DATASET", "confidence": 0.9864498972892761}]}, {"text": " Table 4: Maximum recall for keyphrase extraction  with and without decompounding for the datasets.", "labels": [], "entities": [{"text": "recall", "start_pos": 18, "end_pos": 24, "type": "METRIC", "confidence": 0.9920896291732788}, {"text": "keyphrase extraction", "start_pos": 29, "end_pos": 49, "type": "TASK", "confidence": 0.8454041481018066}]}, {"text": " Table 5: Results for keyphrase extraction approaches without (w/o) and with (w/) decompounding.", "labels": [], "entities": [{"text": "keyphrase extraction", "start_pos": 22, "end_pos": 42, "type": "TASK", "confidence": 0.8587611615657806}]}]}