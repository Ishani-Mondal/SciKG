{"title": [{"text": "Evaluation Algorithms for Event Nugget Detection : A Pilot Study", "labels": [], "entities": [{"text": "Event Nugget Detection", "start_pos": 26, "end_pos": 48, "type": "TASK", "confidence": 0.75309290488561}]}], "abstractContent": [{"text": "Event Mention detection is the first step in tex-tual event understanding.", "labels": [], "entities": [{"text": "Event Mention detection", "start_pos": 0, "end_pos": 23, "type": "TASK", "confidence": 0.8299020131429037}, {"text": "tex-tual event understanding", "start_pos": 45, "end_pos": 73, "type": "TASK", "confidence": 0.8098207712173462}]}, {"text": "Proper evaluation is important for modern natural language processing tasks.", "labels": [], "entities": [{"text": "Proper evaluation", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.6640471816062927}, {"text": "natural language processing tasks", "start_pos": 42, "end_pos": 75, "type": "TASK", "confidence": 0.7063423916697502}]}, {"text": "In this paper, we present our evaluation algorithm and results during the Event Mention Evaluation pilot study.", "labels": [], "entities": [{"text": "Event Mention Evaluation", "start_pos": 74, "end_pos": 98, "type": "TASK", "confidence": 0.7384602725505829}]}, {"text": "We analyze the problems of evaluating multiple event mention attributes and discontinuous event mention spans.", "labels": [], "entities": []}, {"text": "In addition, we identify a few limitations in the evaluation algorithm used for the pilot task and propose some potential improvements .", "labels": [], "entities": []}], "introductionContent": [{"text": "Textual event understanding has attracted a lot of attention in the community.", "labels": [], "entities": [{"text": "Textual event understanding", "start_pos": 0, "end_pos": 27, "type": "TASK", "confidence": 0.8296577334403992}]}, {"text": "Recent work has covered several areas about events, such as event mention detection() , event coreference (, and script understanding.", "labels": [], "entities": [{"text": "event mention detection", "start_pos": 60, "end_pos": 83, "type": "TASK", "confidence": 0.7298929889996847}, {"text": "event coreference", "start_pos": 88, "end_pos": 105, "type": "TASK", "confidence": 0.7657338976860046}, {"text": "script understanding", "start_pos": 113, "end_pos": 133, "type": "TASK", "confidence": 0.848232626914978}]}, {"text": "Event Mention detection is the fundamental preprocessing step for these tasks.", "labels": [], "entities": [{"text": "Event Mention detection", "start_pos": 0, "end_pos": 23, "type": "TASK", "confidence": 0.8393299579620361}]}, {"text": "However, downstream event researches often make minimal effort for event mention detection.", "labels": [], "entities": [{"text": "event mention detection", "start_pos": 67, "end_pos": 90, "type": "TASK", "confidence": 0.8304306070009867}]}, {"text": "For example, in event coreference work, do not make clear distinction between event and entity mentions. and use oracle event mentions from human annotations.", "labels": [], "entities": []}, {"text": "Building robust event mention detection system can help promote research in these areas and enable researchers to produce end-to-end systems.", "labels": [], "entities": [{"text": "event mention detection", "start_pos": 16, "end_pos": 39, "type": "TASK", "confidence": 0.8077698151270548}]}, {"text": "In this paper, we discuss our recent effort in providing a proper evaluation metric for event mention detection.", "labels": [], "entities": [{"text": "event mention detection", "start_pos": 88, "end_pos": 111, "type": "TASK", "confidence": 0.8333422740300497}]}], "datasetContent": [{"text": "The Automatic Content Extraction 2005 evaluation task involves event extraction.", "labels": [], "entities": [{"text": "Automatic Content Extraction 2005 evaluation task", "start_pos": 4, "end_pos": 53, "type": "TASK", "confidence": 0.7193025598923365}, {"text": "event extraction", "start_pos": 63, "end_pos": 79, "type": "TASK", "confidence": 0.7835347652435303}]}, {"text": "The Event Detection and Recognition (VDR) task in the Automatic Content Extraction 2005 evaluation) evaluate the accuracy of event arguments and multiple other event attributes.", "labels": [], "entities": [{"text": "Event Detection and Recognition (VDR)", "start_pos": 4, "end_pos": 41, "type": "TASK", "confidence": 0.8101399796349662}, {"text": "Automatic Content Extraction 2005 evaluation", "start_pos": 54, "end_pos": 98, "type": "TASK", "confidence": 0.5909893035888671}, {"text": "accuracy", "start_pos": 113, "end_pos": 121, "type": "METRIC", "confidence": 0.9971871972084045}]}, {"text": "However, event mention recognition is not directly evaluated ( \u00a73.2).) evaluate event trigger detection using a mention-wise F-1 score.", "labels": [], "entities": [{"text": "event mention recognition", "start_pos": 9, "end_pos": 34, "type": "TASK", "confidence": 0.7876710295677185}, {"text": "event trigger detection", "start_pos": 80, "end_pos": 103, "type": "TASK", "confidence": 0.7539335886637369}, {"text": "F-1", "start_pos": 125, "end_pos": 128, "type": "METRIC", "confidence": 0.9190486073493958}]}, {"text": "An event trigger is considered correct only when the span and event type are matched exactly.", "labels": [], "entities": []}, {"text": "Errors from different sources are not separately presented.", "labels": [], "entities": []}, {"text": "In addition, most previous evaluations on event mention evaluation do not give partial credits to partial matches.", "labels": [], "entities": [{"text": "event mention evaluation", "start_pos": 42, "end_pos": 66, "type": "TASK", "confidence": 0.5421784818172455}]}, {"text": "Partial scoring is more important in the current setting because of the mention span detection task is difficult with discontinuous event nuggets.", "labels": [], "entities": [{"text": "Partial scoring", "start_pos": 0, "end_pos": 15, "type": "TASK", "confidence": 0.8757050335407257}, {"text": "mention span detection task", "start_pos": 72, "end_pos": 99, "type": "TASK", "confidence": 0.7090695947408676}]}, {"text": "In this section, we describe our mention detection algorithms 3 . We will use the terms Event Nugget and Event Mention interchangeably.", "labels": [], "entities": [{"text": "mention detection", "start_pos": 33, "end_pos": 50, "type": "TASK", "confidence": 0.7042139321565628}]}, {"text": "We conduct evaluation on the 15 pilot study submissions using the LDC2015E3 dataset, which contains 200 documents with 6921 annotated event mentions.", "labels": [], "entities": [{"text": "LDC2015E3 dataset", "start_pos": 66, "end_pos": 83, "type": "DATASET", "confidence": 0.9840164482593536}]}, {"text": "The results we show in this section are all micro average across these mentions.", "labels": [], "entities": []}], "tableCaptions": []}