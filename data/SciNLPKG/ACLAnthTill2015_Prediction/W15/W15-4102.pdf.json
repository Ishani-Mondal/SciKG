{"title": [{"text": "Multi-system machine translation using online APIs for English-Latvian", "labels": [], "entities": [{"text": "Multi-system machine translation", "start_pos": 0, "end_pos": 32, "type": "TASK", "confidence": 0.6047141551971436}]}], "abstractContent": [{"text": "This paper describes a hybrid machine translation (HMT) system that employs several online MT system application program interfaces (APIs) forming a Multi-System Machine Translation (MSMT) approach.", "labels": [], "entities": [{"text": "machine translation (HMT)", "start_pos": 30, "end_pos": 55, "type": "TASK", "confidence": 0.8636474609375}, {"text": "MT system application program", "start_pos": 91, "end_pos": 120, "type": "TASK", "confidence": 0.8658143430948257}, {"text": "Multi-System Machine Translation (MSMT)", "start_pos": 149, "end_pos": 188, "type": "TASK", "confidence": 0.8004717926184336}]}, {"text": "The goal is to improve the automated translation of English-Latvian texts over each of the individual MT APIs.", "labels": [], "entities": [{"text": "automated translation of English-Latvian texts", "start_pos": 27, "end_pos": 73, "type": "TASK", "confidence": 0.7231907606124878}, {"text": "MT APIs", "start_pos": 102, "end_pos": 109, "type": "TASK", "confidence": 0.8839878439903259}]}, {"text": "The selection of the best hypothesis translation is done by calculating the perplexity for each hypothesis.", "labels": [], "entities": [{"text": "hypothesis translation", "start_pos": 26, "end_pos": 48, "type": "TASK", "confidence": 0.8012624680995941}]}, {"text": "Experiment results show a slight improvement of BLEU score and WER (word error rate).", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 48, "end_pos": 58, "type": "METRIC", "confidence": 0.9822026193141937}, {"text": "WER", "start_pos": 63, "end_pos": 66, "type": "METRIC", "confidence": 0.9983055591583252}, {"text": "word error rate", "start_pos": 68, "end_pos": 83, "type": "METRIC", "confidence": 0.7763516505559286}]}], "introductionContent": [{"text": "MSMT is a subset of HMT where multiple MT systems are combined in a single system to complement each other's weaknesses in order to boost the accuracy level of the translations.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 142, "end_pos": 150, "type": "METRIC", "confidence": 0.9989058971405029}]}, {"text": "Other types of HMT include modifying statistical MT (SMT) systems with rule-based MT (RBMT) generated output and generating rules for RBMT systems with the help of SMT.", "labels": [], "entities": [{"text": "modifying statistical MT (SMT)", "start_pos": 27, "end_pos": 57, "type": "TASK", "confidence": 0.6706143468618393}, {"text": "SMT", "start_pos": 164, "end_pos": 167, "type": "TASK", "confidence": 0.9215264320373535}]}, {"text": "MSMT involves usage of multiple MT systems in parallel and combining their output with the aim to produce better result as for each of the individual systems.", "labels": [], "entities": [{"text": "MT", "start_pos": 32, "end_pos": 34, "type": "TASK", "confidence": 0.9595346450805664}]}, {"text": "It is a relatively new branch of MT and interest from researchers has emerged more widely during the last 10 years.", "labels": [], "entities": [{"text": "MT", "start_pos": 33, "end_pos": 35, "type": "TASK", "confidence": 0.9881837964057922}]}, {"text": "And even now such systems mostly live as experiments in lab environments instead of real, live, functional MT systems.", "labels": [], "entities": [{"text": "MT", "start_pos": 107, "end_pos": 109, "type": "TASK", "confidence": 0.9591676592826843}]}, {"text": "Since no single system can be perfect and different systems have different advantages over others, a good combination must lead towards better overall translations.", "labels": [], "entities": []}, {"text": "There are several recent experiments that use MSMT.", "labels": [], "entities": []}, {"text": "Ahsan and Kolachina describe away of combining SMT and RBMT systems in multiple setups where each one had input from the SMT system added in a different phase of the RBMT system.", "labels": [], "entities": [{"text": "SMT and RBMT", "start_pos": 47, "end_pos": 59, "type": "TASK", "confidence": 0.6305208802223206}]}, {"text": "Barrault describes a MT system combination method where he combines confusion networks of the best hypotheses from several MT systems into one lattice and uses a language model for decoding the lattice to generate the best hypothesis.", "labels": [], "entities": [{"text": "MT system combination", "start_pos": 21, "end_pos": 42, "type": "TASK", "confidence": 0.9203926920890808}]}, {"text": "Mellebeek et al. introduce a hybrid MT system that utilised online MT engines for MSMT.", "labels": [], "entities": [{"text": "MT", "start_pos": 36, "end_pos": 38, "type": "TASK", "confidence": 0.9765824675559998}, {"text": "MSMT", "start_pos": 82, "end_pos": 86, "type": "TASK", "confidence": 0.8427326679229736}]}, {"text": "They introduce a system that at first attempts to split sentences into smaller parts for easier translation by the means of syntactic analysis, then translate each part with each individual MT system while also providing some context, and finally create the output from the best scored translations of each part (they use three heuristics for selecting the best translation).", "labels": [], "entities": []}, {"text": "Most of the research is done English -Hindi, Arabic -English and English -Spanish language pairs in their experiments.", "labels": [], "entities": []}, {"text": "Where it concerns English -Latvian machine translation, no such experiments have been conducted.", "labels": [], "entities": [{"text": "English -Latvian machine translation", "start_pos": 18, "end_pos": 54, "type": "TASK", "confidence": 0.5890091598033905}]}, {"text": "This paper presents a first attempt in using an MSMT approach for the under-resourced EnglishLatvian language pair.", "labels": [], "entities": []}, {"text": "Furthermore the first results of this hybrid system are analysed and compared with human evaluation.", "labels": [], "entities": []}, {"text": "The experiments described use multiple combinations of outputs from two MT systems and one experiment uses three different MT systems.", "labels": [], "entities": []}], "datasetContent": [{"text": "The first experiments were conducted on the English -Latvian part of the JRC Acquis corpus version 2.2 from which both the language model and the test data were retrieved.", "labels": [], "entities": [{"text": "JRC Acquis corpus version 2.2", "start_pos": 73, "end_pos": 102, "type": "DATASET", "confidence": 0.9406793355941773}]}, {"text": "The test data contained 1581 randomly selected sentences.", "labels": [], "entities": []}, {"text": "The language model was created using KenLM with order 5.", "labels": [], "entities": []}, {"text": "Translations were obtained from each API individually, combining each two APIs and lastly combining all three APIs.", "labels": [], "entities": []}, {"text": "Thereby forming 7 different variants of translations.", "labels": [], "entities": []}, {"text": "Google Translate and Bing Translator APIs were used with the default configuration and the LetsMT API used the configuration of TB2013 EN-LV v03 . Evaluation on each of the seven outputs was done with three scoring methods -BLEU, TER (translation edit rate) and WER.", "labels": [], "entities": [{"text": "TB2013 EN-LV v03", "start_pos": 128, "end_pos": 144, "type": "DATASET", "confidence": 0.9134788115819296}, {"text": "BLEU", "start_pos": 224, "end_pos": 228, "type": "METRIC", "confidence": 0.9986978769302368}, {"text": "TER (translation edit rate)", "start_pos": 230, "end_pos": 257, "type": "METRIC", "confidence": 0.7824178040027618}, {"text": "WER", "start_pos": 262, "end_pos": 265, "type": "METRIC", "confidence": 0.9885615706443787}]}, {"text": "The resulting translations were inspected with a modified iBLEU tool that allowed to determine which system from the hybrid setups was chosen to get the specific translation for each sentence.", "labels": [], "entities": []}, {"text": "The results of the first translation experiment are summarized in.", "labels": [], "entities": [{"text": "translation", "start_pos": 25, "end_pos": 36, "type": "TASK", "confidence": 0.9646576642990112}]}, {"text": "Surprisingly all hybrid systems that include the LetsMT API produce lower results than the baseline LetsMT system.", "labels": [], "entities": []}, {"text": "However the combination of Google Translate and Bing Translator shows improvements in BLEU score and WER compared to each of the baseline systems.", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 86, "end_pos": 96, "type": "METRIC", "confidence": 0.9776350259780884}, {"text": "WER", "start_pos": 101, "end_pos": 104, "type": "METRIC", "confidence": 0.9964836835861206}]}, {"text": "The table also shows the percentage of translations from each API for the hybrid systems.", "labels": [], "entities": []}, {"text": "Although according to scores the LetsMT system was by far better than the other two, it seems that the language model was reluctant to favor its translations.", "labels": [], "entities": []}, {"text": "Since the systems themselves are more of a general domain and the first test was conducted on a legal domain corpus, a second experiment was conducted on a smaller data set containing 512 sentences of a general domain.", "labels": [], "entities": []}, {"text": "In this experiment only the BLEU score was calculated as it is shown in.", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 28, "end_pos": 38, "type": "METRIC", "confidence": 0.9849300682544708}]}, {"text": "A random 2% (32 sentences) of the translations from the first experiment were given to five native Latvian speakers with an instruction to choose the best translation (just like the hybrid system should).", "labels": [], "entities": []}, {"text": "The results are shown in.", "labels": [], "entities": []}, {"text": "Comparing the evaluation results to the BLEU scores and the selections made by the hybrid MT a tendency towards the LetsMT translation can be observed among the user ratings and BLEU score that is not visible from the selection of the hybrid method.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 40, "end_pos": 44, "type": "METRIC", "confidence": 0.9986985921859741}, {"text": "BLEU", "start_pos": 178, "end_pos": 182, "type": "METRIC", "confidence": 0.9986346364021301}]}], "tableCaptions": [{"text": " Table 2. Surprisingly all hybrid  systems that include the LetsMT API produce  lower results than the baseline LetsMT system.  However the combination of Google Translate", "labels": [], "entities": []}, {"text": " Table 3: Native speaker evaluation results", "labels": [], "entities": [{"text": "Native speaker evaluation", "start_pos": 10, "end_pos": 35, "type": "TASK", "confidence": 0.777478039264679}]}]}