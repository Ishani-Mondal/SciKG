{"title": [{"text": "Cross-Lingual Dependency Parsing with Universal Dependencies and Predicted PoS Labels", "labels": [], "entities": [{"text": "Cross-Lingual Dependency Parsing", "start_pos": 0, "end_pos": 32, "type": "TASK", "confidence": 0.5342611769835154}]}], "abstractContent": [{"text": "This paper presents cross-lingual models for dependency parsing using the first release of the universal dependencies data set.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 45, "end_pos": 63, "type": "TASK", "confidence": 0.8950537741184235}, {"text": "universal dependencies data set", "start_pos": 95, "end_pos": 126, "type": "DATASET", "confidence": 0.7144483625888824}]}, {"text": "We systematically compare annotation projection with monolingual baseline models and study the effect of predicted PoS labels in evaluation.", "labels": [], "entities": []}, {"text": "Our results reveal the strong impact of tagging accuracy especially with models trained on noisy projected data sets.", "labels": [], "entities": [{"text": "tagging", "start_pos": 40, "end_pos": 47, "type": "TASK", "confidence": 0.9743117690086365}, {"text": "accuracy", "start_pos": 48, "end_pos": 56, "type": "METRIC", "confidence": 0.9101707935333252}]}, {"text": "This paper quantifies the differences that can be observed when replacing gold standard labels and our results should influence application developers that rely on cross-lingual models that are not tested in realistic scenarios.", "labels": [], "entities": []}], "introductionContent": [{"text": "Cross-lingual parsing has received considerable attention in recent years.", "labels": [], "entities": [{"text": "Cross-lingual parsing", "start_pos": 0, "end_pos": 21, "type": "TASK", "confidence": 0.8455935716629028}]}, {"text": "The demand for robust NLP tools in many languages makes it necessary to port existing tools and resources to new languages in order to support low-resource languages without starting their development from scratch.", "labels": [], "entities": []}, {"text": "Dependency parsing is one of the popular tasks in the NLP community) that also found its way into commercial products and applications.", "labels": [], "entities": [{"text": "Dependency parsing", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.8806009590625763}]}, {"text": "Statistical parsing relies on annotated data sets, so-called treebanks.", "labels": [], "entities": [{"text": "Statistical parsing", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.8502909541130066}]}, {"text": "Several freely available data sets exist but still they only cover a small fraction of the linguistic variety in the world (.", "labels": [], "entities": []}, {"text": "Transferring linguistic information across languages is one approach to add support for new languages.", "labels": [], "entities": [{"text": "Transferring linguistic information", "start_pos": 0, "end_pos": 35, "type": "TASK", "confidence": 0.9041099150975546}]}, {"text": "There are basically two types of transfer that have been proposed in the literature: data transfer approaches and model transfer approaches.", "labels": [], "entities": [{"text": "data transfer", "start_pos": 85, "end_pos": 98, "type": "TASK", "confidence": 0.8336944878101349}, {"text": "model transfer", "start_pos": 114, "end_pos": 128, "type": "TASK", "confidence": 0.7286430299282074}]}, {"text": "The former emphasizes the projection of data sets to new languages and it usually relies on parallel data sets and word alignment (.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 115, "end_pos": 129, "type": "TASK", "confidence": 0.743212103843689}]}, {"text": "Recently, machine translation was also introduced as yet another alternative to data transfer).", "labels": [], "entities": [{"text": "machine translation", "start_pos": 10, "end_pos": 29, "type": "TASK", "confidence": 0.8417004942893982}, {"text": "data transfer", "start_pos": 80, "end_pos": 93, "type": "TASK", "confidence": 0.8333007395267487}]}, {"text": "In model transfer, one tries to port existing parsers to new languages by (i) relying on universal features) and (ii) by adapting model parameters to the target language.", "labels": [], "entities": [{"text": "model transfer", "start_pos": 3, "end_pos": 17, "type": "TASK", "confidence": 0.8338968455791473}]}, {"text": "Universal features may refer to coarse part-of-speech sets that represent common word classes ( and may also include language-set-specific features such as cross-lingual word clusters) or bilingual word embeddings.", "labels": [], "entities": []}, {"text": "Target language adaptation can be done using external linguistic resources such as prior knowledge about language families or lexical databases or any other existing tool for the target language.", "labels": [], "entities": [{"text": "Target language adaptation", "start_pos": 0, "end_pos": 26, "type": "TASK", "confidence": 0.7603349288304647}]}, {"text": "This paper is focused on data transfer methods and especially annotation projection techniques that have been proposed in the related literature.", "labels": [], "entities": [{"text": "data transfer", "start_pos": 25, "end_pos": 38, "type": "TASK", "confidence": 0.843457967042923}, {"text": "annotation projection", "start_pos": 62, "end_pos": 83, "type": "TASK", "confidence": 0.7280543148517609}]}, {"text": "There is an on-going effort on harmonized dependency annotations that makes it possible to transfer syntactic information across languages and to compare projected annotation and cross-lingual models even including labeled structures.", "labels": [], "entities": []}, {"text": "The contributions of this paper include the presentation of monolingual and cross-lingual baseline models for the recently published universal dependencies data sets (UD; release 1.0) 1 and a detailed discussion of the impact of PoS labels.", "labels": [], "entities": []}, {"text": "We systematically compare results on standard test sets with gold labels with corresponding experiments that rely on predicted labels, which reflects the typical real-world scenario.", "labels": [], "entities": []}, {"text": "Let us first look at baseline models before starting our discussion of cross-lingual approaches.", "labels": [], "entities": []}, {"text": "In all our experiments, we apply the Mate tools) for train-ing dependency parsers and we use standard settings throughout the paper.", "labels": [], "entities": [{"text": "train-ing dependency parsers", "start_pos": 53, "end_pos": 81, "type": "TASK", "confidence": 0.6060269971688589}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Baseline models for all languages included  in release 1.0 of the universal dependencies data  set. Results on the given test sets in labeled accu- racy (LAS), unlabeled accuracy (UAS) and label  accuracy (LACC).", "labels": [], "entities": [{"text": "universal dependencies data  set", "start_pos": 76, "end_pos": 108, "type": "DATASET", "confidence": 0.6915115043520927}, {"text": "labeled accu- racy (LAS)", "start_pos": 144, "end_pos": 168, "type": "METRIC", "confidence": 0.8296329208782741}, {"text": "accuracy (UAS)", "start_pos": 180, "end_pos": 194, "type": "METRIC", "confidence": 0.9073659926652908}, {"text": "label  accuracy (LACC)", "start_pos": 199, "end_pos": 221, "type": "METRIC", "confidence": 0.841621732711792}]}, {"text": " Table 2: The impact of morphology and PoS labels: Comparing gold labels with predicted labels.", "labels": [], "entities": []}, {"text": " Table 3: Delexicalized models tested with gold PoS labels across languages.", "labels": [], "entities": []}, {"text": " Table 5: Cross-lingual parsing with projected annotation (dependency relations and coarse PoS tags).  Evaluation with gold PoS labels.", "labels": [], "entities": [{"text": "Cross-lingual parsing", "start_pos": 10, "end_pos": 31, "type": "TASK", "confidence": 0.7482589781284332}]}, {"text": " Table 7: Coarse PoS tagger accuracy on test sets  from the universal dependencies data set with mod- els trained on projected bitexts.", "labels": [], "entities": [{"text": "Coarse PoS tagger", "start_pos": 10, "end_pos": 27, "type": "TASK", "confidence": 0.67546413342158}, {"text": "accuracy", "start_pos": 28, "end_pos": 36, "type": "METRIC", "confidence": 0.9838908314704895}, {"text": "universal dependencies data set", "start_pos": 60, "end_pos": 91, "type": "DATASET", "confidence": 0.7174056172370911}]}, {"text": " Table 8: Cross-lingual parsing with translated treebanks; evaluated with gold PoS labels.", "labels": [], "entities": [{"text": "Cross-lingual parsing", "start_pos": 10, "end_pos": 31, "type": "TASK", "confidence": 0.7398028373718262}]}, {"text": " Table 10: Coarse PoS tagger accuracy on test sets  from the universal dependencies data set with mod- els trained on translated treebanks.", "labels": [], "entities": [{"text": "PoS tagger", "start_pos": 18, "end_pos": 28, "type": "TASK", "confidence": 0.7253189980983734}, {"text": "accuracy", "start_pos": 29, "end_pos": 37, "type": "METRIC", "confidence": 0.9815465807914734}, {"text": "universal dependencies data set", "start_pos": 61, "end_pos": 92, "type": "DATASET", "confidence": 0.7137449979782104}]}]}