{"title": [{"text": "Extracting Time Expressions from Clinical Text", "labels": [], "entities": [{"text": "Extracting Time Expressions from Clinical Text", "start_pos": 0, "end_pos": 46, "type": "TASK", "confidence": 0.9024081528186798}]}], "abstractContent": [{"text": "Temporal information extraction is important to understanding text in clinical documents.", "labels": [], "entities": [{"text": "Temporal information extraction", "start_pos": 0, "end_pos": 31, "type": "TASK", "confidence": 0.9057837327321371}]}, {"text": "Temporal expression extraction provides explicit grounding of events in a narrative.", "labels": [], "entities": [{"text": "Temporal expression extraction", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.9310593008995056}]}, {"text": "In this work we provide a direct comparison of various ways of extracting temporal expressions , using similar features as much as possible to explore the advantages of the methods themselves.", "labels": [], "entities": []}, {"text": "We evaluate these systems on both the THYME (Temporal History of Your Medical Events) and i2b2 Challenge corpora.", "labels": [], "entities": [{"text": "THYME", "start_pos": 38, "end_pos": 43, "type": "METRIC", "confidence": 0.9335178136825562}, {"text": "i2b2 Challenge corpora", "start_pos": 90, "end_pos": 112, "type": "DATASET", "confidence": 0.6878431936105093}]}, {"text": "Our main findings are that simple sequence taggers outperform conditional random fields on the new data, and higher-level syntactic features do not seem to improve performance.", "labels": [], "entities": [{"text": "sequence taggers", "start_pos": 34, "end_pos": 50, "type": "TASK", "confidence": 0.7214487791061401}]}], "introductionContent": [{"text": "Temporal information is ubiquitous in clinical narratives, and accurately extracting temporal information has recently been the focus of a great deal of work in clinical natural language processing (NLP) (.", "labels": [], "entities": [{"text": "clinical natural language processing (NLP)", "start_pos": 161, "end_pos": 203, "type": "TASK", "confidence": 0.7882048657962254}]}, {"text": "Relevant temporal information includes events, time expressions, and temporal relations between pairs of events and/or times.", "labels": [], "entities": []}, {"text": "The accurate extraction of temporal information would be enabling technology for sophisticated downstream processing that requires temporal awareness of patient status.", "labels": [], "entities": []}, {"text": "One promising application is question answering, where a physician can directly ask questions about a patient's medical record.", "labels": [], "entities": [{"text": "question answering", "start_pos": 29, "end_pos": 47, "type": "TASK", "confidence": 0.9005049765110016}]}, {"text": "Many question types of interest are explicitly temporal (When was the patient's last colonoscopy?", "labels": [], "entities": []}, {"text": "), but almost all are implicitly temporal in the sense that every question needs to be understood relative  to sometime frame (What drugs is the patient on?", "labels": [], "entities": []}, {"text": "cannot simply return all drugs in the record but has to understand the question itself is anchored in the present).", "labels": [], "entities": []}, {"text": "This work focuses on the automatic identification of time expressions in clinical text.", "labels": [], "entities": [{"text": "automatic identification of time expressions in clinical text", "start_pos": 25, "end_pos": 86, "type": "TASK", "confidence": 0.7859675250947475}]}, {"text": "Time expressions are words and phrases that correspond to points or spans on a timeline, such as dates or times.", "labels": [], "entities": [{"text": "Time expressions are words and phrases that correspond to points or spans on a timeline, such as dates or times", "start_pos": 0, "end_pos": 111, "type": "Description", "confidence": 0.6544032040096465}]}, {"text": "Other temporal expression types include Durations, Quantifiers, Sets, and Prepostexps.", "labels": [], "entities": []}, {"text": "shows the time expression classes used in this work, with examples given of each class.", "labels": [], "entities": []}, {"text": "The significant deviation from general domain methods is the Prepostexp type, which is specific to the clinical domain.", "labels": [], "entities": [{"text": "Prepostexp", "start_pos": 61, "end_pos": 71, "type": "METRIC", "confidence": 0.9705513119697571}]}, {"text": "Exemplified by terms like postoperatively, this type represents time spans relative to some event, often an operation.", "labels": [], "entities": []}, {"text": "Temporal information extraction has been a topic of a great deal of work both in the clinical and general NLP domains.", "labels": [], "entities": [{"text": "Temporal information extraction", "start_pos": 0, "end_pos": 31, "type": "TASK", "confidence": 0.9420225620269775}]}, {"text": "In the general NLP domain, the TimeBank () spurred much of the early research by providing a manually annotated corpus of events, times and temporal relations.", "labels": [], "entities": []}, {"text": "Shared tasks such as TERN 1 , which focused on time expressions, and, which included events and temporal relations as well, helped build a com-munity around temporal information extraction.", "labels": [], "entities": [{"text": "temporal information extraction", "start_pos": 157, "end_pos": 188, "type": "TASK", "confidence": 0.660668134689331}]}, {"text": "The community explored a wide variety of approaches, the best of which used either manually engineered databases of regular expression rules) or a supervised learning word classification paradigm, and achieved precisions and recalls above 80% in the shared tasks.", "labels": [], "entities": [{"text": "supervised learning word classification", "start_pos": 147, "end_pos": 186, "type": "TASK", "confidence": 0.6902326866984367}, {"text": "precisions", "start_pos": 210, "end_pos": 220, "type": "METRIC", "confidence": 0.9990859031677246}, {"text": "recalls", "start_pos": 225, "end_pos": 232, "type": "METRIC", "confidence": 0.9207355380058289}]}, {"text": "In the clinical domain, temporal information extraction has seen a great deal of recent interest, with the i2b2 (Informatics for Integrating Biology and the Bedside) shared task on temporal information extraction ( and the recent release of the THYME (Temporal History of Your Medical Events) corpus of clinical annotations).", "labels": [], "entities": [{"text": "temporal information extraction", "start_pos": 24, "end_pos": 55, "type": "TASK", "confidence": 0.6378045678138733}, {"text": "temporal information extraction", "start_pos": 181, "end_pos": 212, "type": "TASK", "confidence": 0.6682568987210592}, {"text": "THYME (Temporal History of Your Medical Events) corpus", "start_pos": 245, "end_pos": 299, "type": "DATASET", "confidence": 0.4863924622535706}]}, {"text": "The i2b2 shared task contained a track explicitly focusing on extraction of temporal expressions.", "labels": [], "entities": []}, {"text": "In that task, a variety of approaches were used for time expression extraction.", "labels": [], "entities": [{"text": "time expression extraction", "start_pos": 52, "end_pos": 78, "type": "TASK", "confidence": 0.6543516119321188}]}, {"text": "The best performing system () used machine learning, with a conditional random field classifier (CRF) for finding spans and a support vector machine classifier for classifying attributes.", "labels": [], "entities": []}, {"text": "Other top approaches used adapted regular expressions () on top of the off the shelf Heideltime system (a general-domain NLP system for parsing time expressions)).", "labels": [], "entities": [{"text": "parsing time expressions", "start_pos": 136, "end_pos": 160, "type": "TASK", "confidence": 0.8562621474266052}]}, {"text": "Another approach used a hybrid system where the output from a CRF-based system was combined with the output of a rule-based system.", "labels": [], "entities": []}, {"text": "In this work, we develop and evaluate several machine learning methods for extracting time expressions from clinical text.", "labels": [], "entities": [{"text": "extracting time expressions from clinical text", "start_pos": 75, "end_pos": 121, "type": "TASK", "confidence": 0.7581108808517456}]}, {"text": "These methods include simple sequential classifiers, a sequential model (conditional random field), a constituency parser-based method, and an ensemble sequence method that attempts to leverage the differing performance of all the other models.", "labels": [], "entities": []}, {"text": "The contributions of this work are the comparison and analysis of a large number of different machine learning models for this task, the first use of deep syntactic features for this task, and an evaluation on two different corpora, including the first evaluation of these methods on the THYME corpus.", "labels": [], "entities": [{"text": "THYME corpus", "start_pos": 288, "end_pos": 300, "type": "DATASET", "confidence": 0.9516246914863586}]}, {"text": "THYME n/a Frequency n/a 249: Descriptive statistics of THYME and i2b2 corpora.", "labels": [], "entities": []}, {"text": "Frequency in i2b2 is roughly the union of set and quantifier in THYME.", "labels": [], "entities": [{"text": "Frequency", "start_pos": 0, "end_pos": 9, "type": "METRIC", "confidence": 0.9318621158599854}, {"text": "THYME", "start_pos": 64, "end_pos": 69, "type": "DATASET", "confidence": 0.9212799668312073}]}], "datasetContent": [{"text": "Our evaluation looks at three variables -different machine learning methods, the usefulness of automatic parses at deriving syntactic features, and the domain of the data.", "labels": [], "entities": []}, {"text": "For scoring the evaluation, we primarily use a simple scorer built into ClearTK that requires exact span matching.", "labels": [], "entities": [{"text": "ClearTK", "start_pos": 72, "end_pos": 79, "type": "DATASET", "confidence": 0.9645748138427734}]}, {"text": "We also track partially overlapping spans and count them as correct for overlapping span matching.", "labels": [], "entities": [{"text": "overlapping span matching", "start_pos": 72, "end_pos": 97, "type": "TASK", "confidence": 0.6849984725316366}]}, {"text": "For comparability, we also use the 2012 i2b2 Challenge scoring tool for i2b2 data, which allows both exact and overlapping matching.", "labels": [], "entities": [{"text": "2012 i2b2 Challenge scoring", "start_pos": 35, "end_pos": 62, "type": "DATASET", "confidence": 0.7994617074728012}]}, {"text": "We use exact span matching as our primary scoring method to conservatively estimate performance, in part because the output of these systems will typically be passed to a time normalization system, which may not be able to handle the variations in input.", "labels": [], "entities": [{"text": "exact span matching", "start_pos": 7, "end_pos": 26, "type": "TASK", "confidence": 0.5733982821305593}]}, {"text": "The metrics we use are precision #correcttimespans #predictedtimespans , recall #correcttimespans #goldtimespans , and F1 2 * p * r p+r . We look first at multiple methods on two different corpora.", "labels": [], "entities": [{"text": "precision", "start_pos": 23, "end_pos": 32, "type": "METRIC", "confidence": 0.9991139769554138}, {"text": "recall", "start_pos": 73, "end_pos": 79, "type": "METRIC", "confidence": 0.99880051612854}, {"text": "F1", "start_pos": 119, "end_pos": 121, "type": "METRIC", "confidence": 0.9966714382171631}]}, {"text": "In this experiment we are looking to see whether there is any method which is clearly superior to the others, especially across corpora.", "labels": [], "entities": []}, {"text": "This experiment is important because methods like the CRF and the CRF-based ensemble have some nice theoretical properties (finding the globally optimal sequence), but as a result have slower run time, and to understand this tradeoff we need to measure performance differences.", "labels": [], "entities": []}, {"text": "For the first four systems (the non-ensemble systems), we simply train each method on the combined training and development sets for each corpus, and test on the test set for that corpus.", "labels": [], "entities": []}, {"text": "For the ensemble system, we note that since it is trained on the outputs of other systems, we must do an internal cross-validation of the component systems before performing the tests, to ensure that the labels provided to the ensemble method are representative of what it  will see on test data.", "labels": [], "entities": []}, {"text": "We first perform a 5-fold cross validation on the training set, for each fold training the component on four folds and running the trained component on the fifth.", "labels": [], "entities": []}, {"text": "The output on that fifth fold forms the training data that the ensemble method will see.", "labels": [], "entities": []}, {"text": "By repeating that for each fold, the ensemble method obtains proper system-generated labels from the component system for the entire training set to use as its training data.", "labels": [], "entities": []}, {"text": "The second experiment looks at the importance of accurate syntactic parsing for generating features.", "labels": [], "entities": [{"text": "syntactic parsing", "start_pos": 58, "end_pos": 75, "type": "TASK", "confidence": 0.7181389331817627}]}, {"text": "For the syntax-focused experiments, we use only the THYME corpus, since it has a layer of gold standard treebank annotations.", "labels": [], "entities": [{"text": "THYME corpus", "start_pos": 52, "end_pos": 64, "type": "DATASET", "confidence": 0.9244480133056641}]}, {"text": "The tagger we evaluate is the best performing system on the first experiment, the Backwards BIO tagger.", "labels": [], "entities": [{"text": "Backwards BIO tagger", "start_pos": 82, "end_pos": 102, "type": "TASK", "confidence": 0.4289604922135671}]}, {"text": "In this case we examine three different conditions: First, using gold standard treebank for feature extraction; second, using automatic parses from a THYMEtrained parser; and finally, without any syntactic features at all.", "labels": [], "entities": [{"text": "feature extraction", "start_pos": 92, "end_pos": 110, "type": "TASK", "confidence": 0.7048939168453217}]}, {"text": "The final experiment examines the domainspecificity of the systems and corpora.", "labels": [], "entities": []}, {"text": "In this experiment we train the best performing system (Backwards BIO tagger) on THYME data and then test on i2b2 data, and vice versa.", "labels": [], "entities": []}, {"text": "shows the results of the primary experiment -performance of the various systems on both THYME and i2b2 corpora.", "labels": [], "entities": [{"text": "THYME", "start_pos": 88, "end_pos": 93, "type": "DATASET", "confidence": 0.8733727335929871}]}, {"text": "In most conditions, the Backwards BIO Tagger obtains the highest or tied for the highest F-score, while the regular BIO tagger and ensemble method: Precision (P), recall (R), and F1-Score (F) for different syntactic configurations of the Backwards BIO tagger system.", "labels": [], "entities": [{"text": "F-score", "start_pos": 89, "end_pos": 96, "type": "METRIC", "confidence": 0.9957039952278137}, {"text": "Precision (P)", "start_pos": 148, "end_pos": 161, "type": "METRIC", "confidence": 0.9489690810441971}, {"text": "recall (R)", "start_pos": 163, "end_pos": 173, "type": "METRIC", "confidence": 0.950716495513916}, {"text": "F1-Score (F)", "start_pos": 179, "end_pos": 191, "type": "METRIC", "confidence": 0.9618528038263321}]}, {"text": "GoldManually annotated trees from Treebank used for features.", "labels": [], "entities": [{"text": "GoldManually annotated trees from Treebank", "start_pos": 0, "end_pos": 42, "type": "DATASET", "confidence": 0.945375382900238}]}, {"text": "Automatic -parser trained on clinical text from THYME Treebank, italicized to denote that it is copied from above.", "labels": [], "entities": [{"text": "THYME Treebank", "start_pos": 48, "end_pos": 62, "type": "DATASET", "confidence": 0.9743562936782837}]}, {"text": "No Syntax -Backwards BIO tagger system with no syntactic features.", "labels": [], "entities": [{"text": "Backwards BIO tagger", "start_pos": 11, "end_pos": 31, "type": "TASK", "confidence": 0.6430653830369314}]}], "tableCaptions": [{"text": " Table 1: Time expression classes and two ex- amples of each class.", "labels": [], "entities": []}, {"text": " Table 4: Precision (P), Recall (R), and F1-Score (F) for different systems and corpora. The  highest score in each column is in bold. BIO=Begin-Inside-Outside tagger, Backwards=Reverse  BIO tagger,CRF=Conditional Random Field tagger,Constituency=Constituency parser-based  classifier, Ensemble=CRF-based ensemble classifier. Italicized results from Xu et al. indicated  reported, not replicated, results.", "labels": [], "entities": [{"text": "Precision", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9907005429267883}, {"text": "Recall (R)", "start_pos": 25, "end_pos": 35, "type": "METRIC", "confidence": 0.9229350239038467}, {"text": "F1-Score (F)", "start_pos": 41, "end_pos": 53, "type": "METRIC", "confidence": 0.95276840031147}, {"text": "BIO", "start_pos": 135, "end_pos": 138, "type": "METRIC", "confidence": 0.9972572922706604}, {"text": "Conditional Random Field tagger,Constituency=Constituency parser-based  classifier", "start_pos": 202, "end_pos": 284, "type": "TASK", "confidence": 0.6580227166414261}]}, {"text": " Table 5: Precision (P), recall (R), and F1- Score (F) for different syntactic configurations  of the Backwards BIO tagger system. Gold - Manually annotated trees from Treebank used  for features. Automatic -parser trained on  clinical text from THYME Treebank, itali- cized to denote that it is copied from", "labels": [], "entities": [{"text": "Precision (P)", "start_pos": 10, "end_pos": 23, "type": "METRIC", "confidence": 0.9248489886522293}, {"text": "recall (R)", "start_pos": 25, "end_pos": 35, "type": "METRIC", "confidence": 0.9417694807052612}, {"text": "F1- Score (F)", "start_pos": 41, "end_pos": 54, "type": "METRIC", "confidence": 0.9841392536958059}, {"text": "THYME Treebank", "start_pos": 246, "end_pos": 260, "type": "DATASET", "confidence": 0.9613586366176605}]}, {"text": " Table 6: Precision (P), recall (R), and F1-Score (F) for cross-domain experiments. We use  the best-performing system for each experiment (Backwards BIO), with automatic parse fea- tures from a THYME-trained parser. Italicized rows are copied from", "labels": [], "entities": [{"text": "Precision (P)", "start_pos": 10, "end_pos": 23, "type": "METRIC", "confidence": 0.9347027838230133}, {"text": "recall (R)", "start_pos": 25, "end_pos": 35, "type": "METRIC", "confidence": 0.9460953623056412}, {"text": "F1-Score (F)", "start_pos": 41, "end_pos": 53, "type": "METRIC", "confidence": 0.9707617163658142}, {"text": "Backwards BIO)", "start_pos": 140, "end_pos": 154, "type": "METRIC", "confidence": 0.814454178015391}]}]}