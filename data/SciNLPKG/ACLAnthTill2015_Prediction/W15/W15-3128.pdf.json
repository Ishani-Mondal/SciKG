{"title": [{"text": "NEUDM: A System for Topic-Based Message Polarity Classification", "labels": [], "entities": [{"text": "NEUDM", "start_pos": 0, "end_pos": 5, "type": "DATASET", "confidence": 0.8087088465690613}, {"text": "Topic-Based Message Polarity Classification", "start_pos": 20, "end_pos": 63, "type": "TASK", "confidence": 0.7547680661082268}]}], "abstractContent": [{"text": "In this paper, we describe our system for the topic-based Chinese message polarity classification in SIGHAN 8 Task 2.", "labels": [], "entities": [{"text": "topic-based Chinese message polarity classification", "start_pos": 46, "end_pos": 97, "type": "TASK", "confidence": 0.6045397341251373}, {"text": "SIGHAN 8 Task 2", "start_pos": 101, "end_pos": 116, "type": "DATASET", "confidence": 0.6229012310504913}]}, {"text": "Our system integrates two SVM classifiers which consist of LinearSVC and LibSVM to train the classification model and predict the results of Chinese message polarity in the restricted resource and the unrestricted resource, respectively.", "labels": [], "entities": []}, {"text": "In order to assure our feature engineering effort on the task, we use some feature selection methods, such as LDA, word2vec, and sentiment lexicons including DLUT emotion ontology and NTUSD.", "labels": [], "entities": [{"text": "DLUT emotion ontology", "start_pos": 158, "end_pos": 179, "type": "TASK", "confidence": 0.607051283121109}]}, {"text": "Our system achieves the overall F1 score of 74.88% in the restricted evaluation and 74.43% in the unrestricted evaluation.", "labels": [], "entities": [{"text": "F1 score", "start_pos": 32, "end_pos": 40, "type": "METRIC", "confidence": 0.9819717705249786}]}], "introductionContent": [{"text": "With the development of social network, more and more people are actively sharing information with others and expressing their opinions and feelings on Chinese Weibo platform.", "labels": [], "entities": [{"text": "Chinese Weibo platform", "start_pos": 152, "end_pos": 174, "type": "DATASET", "confidence": 0.9207795858383179}]}, {"text": "Weibo has aggregated huge number of tweets that containing people's opinion about commercial products, celebrities, social event and soon.", "labels": [], "entities": [{"text": "Weibo", "start_pos": 0, "end_pos": 5, "type": "DATASET", "confidence": 0.9659522175788879}]}, {"text": "Therefore, mining people's sentiments expressed in tweets has attracted more and more attention for both research and industrial communities.", "labels": [], "entities": []}, {"text": "For the Chinese microblog, our task is to classify people's sentiments fora given topic as positive, negative, and neutral.", "labels": [], "entities": [{"text": "Chinese microblog", "start_pos": 8, "end_pos": 25, "type": "DATASET", "confidence": 0.9085623323917389}]}, {"text": "Among the varieties of topics, people could express neutral, positive, and negative sentiments for them, respectively.", "labels": [], "entities": []}, {"text": "If the topic information is ignored, it is difficult to obtain the correct sentiment fora specified target.", "labels": [], "entities": []}, {"text": "The traditional learning-based methods for solving sentiment classification problem, such as (, basically followed (), who utilized machine learning based classifiers for the sentiment classification of text.", "labels": [], "entities": [{"text": "sentiment classification", "start_pos": 51, "end_pos": 75, "type": "TASK", "confidence": 0.7799895703792572}, {"text": "sentiment classification of text", "start_pos": 175, "end_pos": 207, "type": "TASK", "confidence": 0.8565996736288071}]}, {"text": "They worked in a topic-independent way: all the features have no relation with the topic.", "labels": [], "entities": []}, {"text": "That is to say: the sentiment is decided no matter what the target is. combined the target-independent features (content and lexicon) and target-dependent features (rules based on the dependency parsing results) together for tweet subjectivity and polarity classification.", "labels": [], "entities": [{"text": "polarity classification", "start_pos": 248, "end_pos": 271, "type": "TASK", "confidence": 0.7344406247138977}]}, {"text": "The microblog usually has a length limitation, such as 140 characters.", "labels": [], "entities": []}, {"text": "Therefore, the vectors formed by microblog data are extremely sparse, which sets obstacles for further classification algorithms.", "labels": [], "entities": []}, {"text": "To tackle these challenges, in this paper we first leverage the generative model LDA (Andrew) to extract the top ranked topic words as topic-related features.", "labels": [], "entities": []}, {"text": "Secondly, we count the number of positive and negative sentiment words through sentiment lexicon in the sentence and get the adjective word which only occur in the polarity sentences.", "labels": [], "entities": []}, {"text": "Finally, we utilize the well-known deep learning word embedding tool word2vec 1 to find the top-k semantically similar words in the topic document to expand the feature representation.", "labels": [], "entities": []}, {"text": "The used words in the word embedding tool word2vec both appear in a sentiment lexicon and the topic document.", "labels": [], "entities": []}, {"text": "The component of feature vector can be described as follows.", "labels": [], "entities": []}, {"text": "In, the topic, sentiment and expanded features attempt to handle the topic-based sentiment analysis problem.", "labels": [], "entities": [{"text": "topic-based sentiment analysis", "start_pos": 69, "end_pos": 99, "type": "TASK", "confidence": 0.6553711990515391}]}, {"text": "The expanded features based on word2vec try to enrich the feature space and alleviate the sparse vector problem.", "labels": [], "entities": []}, {"text": "Based on the feature vector, we can utilize off-the-shelf machine learning algorithms to train the topicbased sentiment classification model.", "labels": [], "entities": [{"text": "topicbased sentiment classification", "start_pos": 99, "end_pos": 134, "type": "TASK", "confidence": 0.7442314823468527}]}], "datasetContent": [{"text": "In this section, we explain details of the data and the general settings for the different experiments we conducted.", "labels": [], "entities": []}, {"text": "We train and evaluate our classifier for restricted resource and unrestricted resource respectively, training and testing datasets provided by SIGHAN 8 Task 2.", "labels": [], "entities": [{"text": "SIGHAN 8 Task 2", "start_pos": 143, "end_pos": 158, "type": "DATASET", "confidence": 0.7015543431043625}]}, {"text": "The train dataset is composed of five different topics and includes 4,905 Chinese microblogs.", "labels": [], "entities": []}, {"text": "The test dataset is composed of twenty different topics and includes 19,469 Chinese microblogs.", "labels": [], "entities": []}, {"text": "Each topic contains approximately 1,000 Chinese microblogs.", "labels": [], "entities": []}, {"text": "But the ratio of subjective class to objective class is four to one and the ratio of positive class to negative class is one to one in the subjective class.", "labels": [], "entities": []}, {"text": "The serious imbalanced data set has an adverse effect on classification results.", "labels": [], "entities": [{"text": "classification", "start_pos": 57, "end_pos": 71, "type": "TASK", "confidence": 0.9722762703895569}]}, {"text": "So in order to keep the train data set balanced, we adopt the sampling strategy.", "labels": [], "entities": []}, {"text": "We do not change the neutral class data and the sum of the positive class and the negative class is resampled to bean equal number of the neutral class.", "labels": [], "entities": []}, {"text": "In SIGHAN 8 task 2, we evaluate the experimental results with Precision, Recall and F1 measure.", "labels": [], "entities": [{"text": "SIGHAN 8 task", "start_pos": 3, "end_pos": 16, "type": "TASK", "confidence": 0.6988706191380819}, {"text": "Precision", "start_pos": 62, "end_pos": 71, "type": "METRIC", "confidence": 0.9987094402313232}, {"text": "Recall", "start_pos": 73, "end_pos": 79, "type": "METRIC", "confidence": 0.9882584810256958}, {"text": "F1", "start_pos": 84, "end_pos": 86, "type": "METRIC", "confidence": 0.9986847043037415}]}, {"text": "These three classic values are utilized to measure the performance of positive, negative, neutral class respectively.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: the results of our system", "labels": [], "entities": []}, {"text": " Table 3: the compare of competition results", "labels": [], "entities": []}]}