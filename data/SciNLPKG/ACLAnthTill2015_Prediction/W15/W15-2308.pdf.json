{"title": [{"text": "General Perspective on Distributionally Learnable Classes", "labels": [], "entities": []}], "abstractContent": [{"text": "Several algorithms have been proposed to learn different subclasses of context-free grammars based on the idea generically called distributional learning.", "labels": [], "entities": []}, {"text": "Those techniques have been applied to many formalisms richer than context-free grammars like multiple context-free grammars, simple context-free tree grammars and others.", "labels": [], "entities": []}, {"text": "The learning algorithms for those different formalisms are actually quite similar to each other.", "labels": [], "entities": []}, {"text": "We in this paper give a uniform view on those algorithms .", "labels": [], "entities": []}], "introductionContent": [{"text": "Approaches based on the idea generically called distributional learning have been making great success in the algorithmic learning of various subclasses of context-free grammars (CFGs)).", "labels": [], "entities": []}, {"text": "Those techniques are applied to richer formalisms as well.", "labels": [], "entities": []}, {"text": "The formalisms studied so far include multiple CFGs, simple context-free tree grammars (CFTGs) (), second-order abstract categorial grammars (), parallel multiple, conjunctive grammars and others.", "labels": [], "entities": []}, {"text": "The goal of this paper is to present a uniform view on those algorithms.", "labels": [], "entities": []}, {"text": "Every grammar formalism for which distributional learning techniques have been proposed so far generate their languages through context-free derivation trees, whose nodes are labeled by production rules.", "labels": [], "entities": []}, {"text": "The formalism and grammar rules determine how a context-free derivation tree \u03c4 is mapped to a derived object\u02dc\u03c4object\u02dc object\u02dc\u03c4 = d.", "labels": [], "entities": []}, {"text": "A context-free derivation tree \u03c4 can be decomposed into a subtree \u03c3 and a tree-context \u03c7 so that \u03c4 = \u03c7.", "labels": [], "entities": []}, {"text": "The subtree determines a substructure s = \u02dc \u03c3 of d and the tree-context determines a contextual structure c = \u02dc \u03c7 in which the substructure is plugged to form the derived object d = c \u2299 s, where we represent the plugging operation by \u2299.", "labels": [], "entities": []}, {"text": "In the CFG case, c is a string pair \u27e8l, r\u27e9 and sis a string u and \u27e8l, r\u27e9 \u2299 u = lur, which may correspond to a derivation I * \u21d2 lXr * \u21d2 lur where I is the initial symbol and X is a nonterminal symbol.", "labels": [], "entities": [{"text": "CFG", "start_pos": 7, "end_pos": 10, "type": "DATASET", "confidence": 0.9016796350479126}]}, {"text": "In richer formalisms those substructures and contexts may have richer structures, like tuples of strings or \u03bb-terms.", "labels": [], "entities": []}, {"text": "A learner does not know how a given exampled is derived by a hidden grammar behind the observed examples.", "labels": [], "entities": []}, {"text": "A learner based on distributional learning simply tries all the possible decompositions of a positive example into arbitrary two parts c \u2032 and s \u2032 such that d = c \u2032 \u2299 s \u2032 where some grammar may derive d thorough a derivation tree \u03c4 \u2032 = \u03c7 \u2032 [\u03c3 \u2032 ] with\u02dc\u03c7with\u02dc with\u02dc\u03c7 \u2032 = c \u2032 and\u02dc\u03c3and\u02dc and\u02dc\u03c3 \u2032 = s \u2032 . Based on observation on the relation between substructures and contexts collected from given examples, a hypothesis grammar is computed.", "labels": [], "entities": []}, {"text": "We call properties on grammars with which distributional learning approaches work distributional properties.", "labels": [], "entities": []}, {"text": "This paper first formally defines grammar formalisms based on context-free derivation trees.", "labels": [], "entities": []}, {"text": "We then show that grammars with different distributional properties are learnable by standard distributional learning techniques if the formalism satisfies some conditions, which include polynomialtime decomposability of objects into contexts and substructures.", "labels": [], "entities": []}, {"text": "In addition, we discuss cases where we cannot enumerate all of the possible contexts and substructures.", "labels": [], "entities": []}, {"text": "F \u2286 F is a finite set of function names, and P is a finite set of production rules, which are elements of N \u00d7 F \u00d7 N * . Each production rule is denoted as X 0 \u2190 f \u27e8X 1 , . .", "labels": [], "entities": []}, {"text": ", X n \u27e9 where X 0 , . .", "labels": [], "entities": []}, {"text": ", X n \u2208 N and f \u2208 F O 0 ,O 1 ,...,On for \u03c3(X i ) = O i . For each O \u2208 \u2126, N O = \u03c3 \u22121 (O) \u2286 N is the set of O-nonterminals which are assigned the sort O.", "labels": [], "entities": []}, {"text": "By G(\u03a3) we denote the class of \u03a3-grammars.", "labels": [], "entities": []}, {"text": "A \u03a3-grammar defines its language via derivation trees, which are recursively defined as follows.", "labels": [], "entities": []}, {"text": "\u2022 If \u03c4 i are X i -derivation trees for i = 1, . .", "labels": [], "entities": []}, {"text": ", n and \u03c1 is a rule of the form X 0 \u2190 f \u27e8X 1 , . .", "labels": [], "entities": []}, {"text": ", X n \u27e9, then the term \u03c4 0 = \u03c1[\u03c4 1 , . .", "labels": [], "entities": []}, {"text": ", \u03c4 n ] is an X 0 -derivation tree.", "labels": [], "entities": []}, {"text": "Its yield\u02dc\u03c4yield\u02dc yield\u02dc\u03c4 0 is\u02dcfis\u02dc is\u02dcf (\u02dc \u03c4 1 , . .", "labels": [], "entities": []}, {"text": ", \u02dc \u03c4 n ) \u2208 O \u03c3(X 0 ) where\u02dc\u03c4where\u02dc where\u02dc\u03c4 i is the yield of \u03c4 i . The case where n = 0 gives the base of this recursive definition.", "labels": [], "entities": []}, {"text": "An X-derivation tree is complete if X \u2208 I.", "labels": [], "entities": []}, {"text": "The yield of any X-derivation tree is called an X-substructure.", "labels": [], "entities": []}, {"text": "By S(G, X) we denote the set of X-substructures.", "labels": [], "entities": []}, {"text": "The language of , which we calla \u03a3-language.", "labels": [], "entities": []}, {"text": "In other words, L(G) is the set of the yields of complete derivation trees.", "labels": [], "entities": []}, {"text": "The class of \u03a3-languages is denoted by L(\u03a3).", "labels": [], "entities": []}, {"text": "Distributional learning is concerned with what Xderivation contexts represent.", "labels": [], "entities": [{"text": "Distributional learning", "start_pos": 0, "end_pos": 23, "type": "TASK", "confidence": 0.8005044460296631}]}, {"text": "An X-derivation context is obtained by replacing an occurrence of an X-derivation tree in a complete derivation tree by a special symbol \u25a1 \u03c3(X) . Accordingly the yield\u02dc\u03c7yield\u02dc yield\u02dc\u03c7 of an X-derivation context \u03c7 should be a finite representation of a function that gives \u03c7[\u03c4 ] when applied t\u00f5 \u03c4 for any X-derivation tree \u03c4 . We assume to have a set E O of representations of functions from O O to O * for O \u2208 \u2126 to which the yields of derivation contexts belong.", "labels": [], "entities": []}, {"text": "\u2022 \u25a1 X is an X-derivation context for all X \u2208 I and its yield \u25a1 O * \u2208 E O * represents the identity function on O * , \u2022 For an X-derivation context \u03c7 0 , a rule \u03c1 = X \u2190 f \u27e8X 1 , . .", "labels": [], "entities": []}, {"text": ", X n \u27e9 and X i -derivation trees \u03c4 i for i \u2208 {1, . .", "labels": [], "entities": []}, {"text": ", n} \u2212 {j}, the term \u03c7 obtained by replacing is denoted as\u02dc\u03c7 where \u03d5 0 is the function represented by\u02dc\u03c7by\u02dc by\u02dc\u03c7 0 . The yield of any X-derivation context is called an X-context.", "labels": [], "entities": []}, {"text": "By C(G, X) we denote the set of Xcontexts.", "labels": [], "entities": []}, {"text": "For c \u2208 C(G, X) and s \u2208 S(G, X), c \u2299 sis the result of the application of the function represented by c to s.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": []}