{"title": [{"text": "Location Name Disambiguation Exploiting Spatial Proximity and Temporal Consistency", "labels": [], "entities": [{"text": "Location Name Disambiguation Exploiting Spatial Proximity", "start_pos": 0, "end_pos": 57, "type": "TASK", "confidence": 0.5888664970795313}]}], "abstractContent": [{"text": "As the volume of documents on the Web increases , technologies to extract useful information from them become increasingly essential.", "labels": [], "entities": []}, {"text": "For instance, information extracted from social network services such as Twitter and Facebook is useful because it contains a lot of location-specific information.", "labels": [], "entities": []}, {"text": "To extract such information, it is necessary to identify the location of each location-relevant expression within a document.", "labels": [], "entities": []}, {"text": "Previous studies on location disambiguation have tackled this problem on the basis of word sense disambigua-tion, and did not make use of location-specific clues.", "labels": [], "entities": [{"text": "location disambiguation", "start_pos": 20, "end_pos": 43, "type": "TASK", "confidence": 0.7257838845252991}]}, {"text": "In this paper, we propose a method for location disambiguation that takes advantage of the following two clues: spatial proximity and temporal consistency.", "labels": [], "entities": [{"text": "location disambiguation", "start_pos": 39, "end_pos": 62, "type": "TASK", "confidence": 0.7203294038772583}]}, {"text": "We confirm the effectiveness of these clues through experiments on Twitter tweets with GPS information.", "labels": [], "entities": []}], "introductionContent": [{"text": "As the volume of documents on the Web increases, technologies to extract useful information from them become increasingly essential.", "labels": [], "entities": []}, {"text": "For instance, information extracted from social network services (SNS) such as Twitter and Facebook is useful because it contains a lot of location-specific information.", "labels": [], "entities": []}, {"text": "To extract such information, it is necessary to identify the location of each location-relevant expression within a document.", "labels": [], "entities": []}, {"text": "However, many previous studies on SNS rely only on geo-tagged documents (e.g.,), which include GPS information, but these represent only a small proportion of the total.", "labels": [], "entities": [{"text": "SNS", "start_pos": 34, "end_pos": 37, "type": "TASK", "confidence": 0.9509232044219971}]}, {"text": "To extract as much location information as possible, it is important to develop a method that can estimate locations from numerous documents without GPS information.", "labels": [], "entities": []}, {"text": "Previous studies on location disambiguation made use of methods for word sense disambiguation and are based only on textual information, i.e., the bagof-words in a document.", "labels": [], "entities": [{"text": "location disambiguation", "start_pos": 20, "end_pos": 43, "type": "TASK", "confidence": 0.7603451907634735}, {"text": "word sense disambiguation", "start_pos": 68, "end_pos": 93, "type": "TASK", "confidence": 0.6978306869665781}]}, {"text": "It is, however, difficult to solve this problem using only textual information in a relatively short SNS document.", "labels": [], "entities": []}, {"text": "For example, it is difficult to identify the location of \"Prefectural Office Ave.\" from the following document based only on word information.", "labels": [], "entities": [{"text": "Prefectural Office Ave.\"", "start_pos": 58, "end_pos": 82, "type": "DATASET", "confidence": 0.902205303311348}]}, {"text": "\"I arrived at Prefectural Office Ave. from Shuri Station!\"", "labels": [], "entities": [{"text": "Prefectural Office Ave. from Shuri Station", "start_pos": 14, "end_pos": 56, "type": "DATASET", "confidence": 0.8691934744517008}]}, {"text": "In this paper, we propose a method that identifies the locations of location expressions in Twitter tweets on the basis of the following two clues: (1) spatial proximity, and (2) temporal consistency.", "labels": [], "entities": [{"text": "consistency", "start_pos": 188, "end_pos": 199, "type": "METRIC", "confidence": 0.6012309193611145}]}, {"text": "Spatial proximity assumes that all locations mentioned in a tweet are close to one another.", "labels": [], "entities": [{"text": "Spatial proximity", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.8298354744911194}]}, {"text": "In the above document, for example, we would assume that \"Prefectural Office Ave.\" is \"Prefectural Office Ave.", "labels": [], "entities": [{"text": "Prefectural Office Ave.", "start_pos": 58, "end_pos": 81, "type": "DATASET", "confidence": 0.8651681145032247}]}, {"text": "(Okinawa)\" using the proximity between \"Shuri Station\" and \"Prefectural Office Ave.", "labels": [], "entities": [{"text": "Prefectural Office Ave", "start_pos": 60, "end_pos": 82, "type": "DATASET", "confidence": 0.8562005956967672}]}, {"text": "(Okinawa)\" The other clue is temporal consistency, Semiocast reported that GPS information is assigned to only 0.77% of all public tweets.", "labels": [], "entities": [{"text": "consistency", "start_pos": 38, "end_pos": 49, "type": "METRIC", "confidence": 0.8533423542976379}]}, {"text": "Although it is possible to learn a clue from \"Shuri Station,\" which is located in Okinawa Prefecture, it would require a large amount of training data to learn such lexical clues for each target location expression.", "labels": [], "entities": []}, {"text": "1 which assumes that the locations in a series of tweets are near to each other.", "labels": [], "entities": []}, {"text": "In our experiments, we learn a location classifier for each ambiguous location expression in Japanese.", "labels": [], "entities": []}, {"text": "Hereafter, we call an ambiguous location expression, such as \"Prefectural Office Ave.,\" a Location EXpression (LEX), and a location to which a LEX points, such as <Prefectural Office Ave.", "labels": [], "entities": [{"text": "Location EXpression (LEX)", "start_pos": 90, "end_pos": 115, "type": "METRIC", "confidence": 0.7734945297241211}]}, {"text": "(Okinawa)>, a Location Entity (LE), which is linked to its GIS information.", "labels": [], "entities": [{"text": "GIS information", "start_pos": 59, "end_pos": 74, "type": "DATASET", "confidence": 0.8458405435085297}]}, {"text": "We calla LEX linked to multiple LEs an ambiguous LEX, which is the target of our location name disambiguation system.", "labels": [], "entities": [{"text": "location name disambiguation", "start_pos": 81, "end_pos": 109, "type": "TASK", "confidence": 0.6753716468811035}]}, {"text": "That is unambiguous LEXs are not our target, such as \"Tokyo Tower,\" which points the LE <Tokyo Tower>.", "labels": [], "entities": [{"text": "Tokyo Tower", "start_pos": 54, "end_pos": 65, "type": "DATASET", "confidence": 0.9770951867103577}, {"text": "Tokyo Tower>", "start_pos": 89, "end_pos": 101, "type": "DATASET", "confidence": 0.9088108936945597}]}, {"text": "We define a set of LEXs and LEs on the basis of Japanese Wikipedia.", "labels": [], "entities": [{"text": "Japanese Wikipedia", "start_pos": 48, "end_pos": 66, "type": "DATASET", "confidence": 0.9348395466804504}]}, {"text": "Training data for the location classifiers are created from tweets containing GPS information.", "labels": [], "entities": []}, {"text": "The resulting location classifiers can be applied to LEXs in any tweets or documents without GPS information.", "labels": [], "entities": [{"text": "LEXs", "start_pos": 53, "end_pos": 57, "type": "METRIC", "confidence": 0.904983401298523}]}, {"text": "Our novel contributions can be summarized as follows: \u2022 two novel clues for location disambiguation are proposed, \u2022 training data is automatically created from tweets with GPS information, and \u2022 our method can identify LEs of LEXs in any documents without GPS information.", "labels": [], "entities": [{"text": "location disambiguation", "start_pos": 76, "end_pos": 99, "type": "TASK", "confidence": 0.7252428531646729}]}, {"text": "The remainder of this paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 introduces related work, while Section 3 describes the resources used in this paper.", "labels": [], "entities": []}, {"text": "Section 4 details our proposed method and Section 5 reports the experimental results.", "labels": [], "entities": []}, {"text": "Section 6 concludes the paper.", "labels": [], "entities": []}], "datasetContent": [{"text": "We create an SVM classifier for each LEX to solve location name disambiguation with the features described in Section 4.", "labels": [], "entities": [{"text": "location name disambiguation", "start_pos": 50, "end_pos": 78, "type": "TASK", "confidence": 0.6964358488718668}]}, {"text": "This classifier identifies the LE for an ambiguous LEX included in a tweet.", "labels": [], "entities": [{"text": "LE", "start_pos": 31, "end_pos": 33, "type": "METRIC", "confidence": 0.9901761412620544}]}, {"text": "Since location name disambiguation is a multi-class identification problem, we use the one-versus-therest method for the SVM classifier.", "labels": [], "entities": [{"text": "location name disambiguation", "start_pos": 6, "end_pos": 34, "type": "TASK", "confidence": 0.6515038510163625}]}, {"text": "For the goldstandard data, we used 70,184 tweets including the LEXs that are associated with tenor more tweets from the corpus described in Section 3.2.", "labels": [], "entities": [{"text": "goldstandard data", "start_pos": 8, "end_pos": 25, "type": "DATASET", "confidence": 0.7240287512540817}, {"text": "LEXs", "start_pos": 63, "end_pos": 67, "type": "METRIC", "confidence": 0.9733487963676453}]}, {"text": "We conducted 5-fold cross-validation using this data.", "labels": [], "entities": []}, {"text": "We adopted TinySVM, an SVM package with a quadratic polynomial kernel.", "labels": [], "entities": [{"text": "TinySVM", "start_pos": 11, "end_pos": 18, "type": "DATASET", "confidence": 0.9487467408180237}]}, {"text": "For the segmentation of Japanese words, we used the Japanese morphological analyzer JUMAN.", "labels": [], "entities": [{"text": "segmentation of Japanese words", "start_pos": 8, "end_pos": 38, "type": "TASK", "confidence": 0.8611437380313873}, {"text": "Japanese morphological analyzer JUMAN", "start_pos": 52, "end_pos": 89, "type": "TASK", "confidence": 0.4905057027935982}]}, {"text": "The accuracy s c is calculated from the system output and the correct LEs, where sis the number of tweets whose output had the correct LE and c is the total number of tweets considered.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.9987228512763977}, {"text": "LEs", "start_pos": 70, "end_pos": 73, "type": "METRIC", "confidence": 0.8073004484176636}]}, {"text": "Moreover, the accuracy is calculated separately for each number of tweets per LEX (10\u223c100: rare LEX, 100\u223c1,000: intermediate LEX, 1,000\u223c: common LEX, 10\u223c: all).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 14, "end_pos": 22, "type": "METRIC", "confidence": 0.9996508359909058}]}, {"text": "The results for all methods are compared in with the following proximity and consistency features: \u2022 0\u223c10, 10\u223c100, 100\u223c500 km The Majority Baseline (MB) is a baseline method that outputs the most frequent LE for each LEX.", "labels": [], "entities": [{"text": "consistency", "start_pos": 77, "end_pos": 88, "type": "METRIC", "confidence": 0.9608998894691467}, {"text": "LE", "start_pos": 205, "end_pos": 207, "type": "METRIC", "confidence": 0.8878064751625061}]}, {"text": "lists the accuracy of the estimated LEs considering spatial proximity and temporal consistency.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9994029998779297}]}, {"text": "In particular, considering the proximity improves the accuracy, regardless of the number of tweets for each LEX.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 54, "end_pos": 62, "type": "METRIC", "confidence": 0.9994539618492126}]}, {"text": "Although the consideration of \" \u2020\" means the superiority to B estimated at the 5% significance level and \" \u2021\" means that at the 1% level.", "labels": [], "entities": [{"text": "B", "start_pos": 60, "end_pos": 61, "type": "METRIC", "confidence": 0.9913753867149353}, {"text": "\u2021\"", "start_pos": 107, "end_pos": 109, "type": "METRIC", "confidence": 0.9598179459571838}]}, {"text": "temporal consistency also improves accuracy forrare LEXs.", "labels": [], "entities": [{"text": "consistency", "start_pos": 9, "end_pos": 20, "type": "METRIC", "confidence": 0.6649855375289917}, {"text": "accuracy", "start_pos": 35, "end_pos": 43, "type": "METRIC", "confidence": 0.9993151426315308}]}, {"text": "the accuracy is below the baseline for common LEXs.The accuracy considering both features outperforms the baseline by 7.13% for rare LEXs.In addition, a sign-test was adopted to demonstrate the significance of the results.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.9994115829467773}, {"text": "accuracy", "start_pos": 55, "end_pos": 63, "type": "METRIC", "confidence": 0.9789125323295593}]}, {"text": "This test was performed using R.", "labels": [], "entities": []}, {"text": "6 \" \u2020\" means the superiority to B estimated at a significance level of 5%, and \" \u2021\" means that at the 1% level.", "labels": [], "entities": [{"text": "\u2020\"", "start_pos": 4, "end_pos": 6, "type": "METRIC", "confidence": 0.9767417907714844}, {"text": "B", "start_pos": 32, "end_pos": 33, "type": "METRIC", "confidence": 0.9462165236473083}, {"text": "\u2021\"", "start_pos": 81, "end_pos": 83, "type": "METRIC", "confidence": 0.9585305452346802}]}, {"text": "This test shows the significance of the proposed method, particularly for rare LEXs.Moreover, the accuracy with all tweets verifies the significance of the proposed method compared to the baseline.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 98, "end_pos": 106, "type": "METRIC", "confidence": 0.9990342855453491}]}, {"text": "The accuracy did not improve for common LEXsbecause of an imbalance in the tweet data.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.9996540546417236}]}, {"text": "This study only uses tweet data that include LEXs and GIS information.", "labels": [], "entities": [{"text": "LEXs", "start_pos": 45, "end_pos": 49, "type": "METRIC", "confidence": 0.924170732498169}]}, {"text": "Therefore, the LEs of the tweets are imbalanced for each LEX.", "labels": [], "entities": [{"text": "LEs", "start_pos": 15, "end_pos": 18, "type": "METRIC", "confidence": 0.9878748059272766}]}, {"text": "The high accuracy of MB suggests this imbalance depends on the number of tweets for each LEX.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 9, "end_pos": 17, "type": "METRIC", "confidence": 0.9994113445281982}, {"text": "MB", "start_pos": 21, "end_pos": 23, "type": "METRIC", "confidence": 0.9809954762458801}]}, {"text": "Moreover, most tweets with GIS information are generated automatically by companies such as Foursquare.", "labels": [], "entities": [{"text": "Foursquare", "start_pos": 92, "end_pos": 102, "type": "DATASET", "confidence": 0.9725200533866882}]}, {"text": "As a result, high accuracy is obtained in many cases without considering the proximity or consistency.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 18, "end_pos": 26, "type": "METRIC", "confidence": 0.9994106292724609}, {"text": "consistency", "start_pos": 90, "end_pos": 101, "type": "METRIC", "confidence": 0.9844954609870911}]}, {"text": "Although this study used only tweets with GIS information, the accuracy could clearly be improved using tweets with-6 http://cran.r-project.org/.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 63, "end_pos": 71, "type": "METRIC", "confidence": 0.9994630217552185}]}, {"text": "As shown in Table 5, the accuracy of location name disambiguation with rare LEXs improves with the addition of the 500\u223c1000 km bin.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 25, "end_pos": 33, "type": "METRIC", "confidence": 0.9994935989379883}, {"text": "location name disambiguation", "start_pos": 37, "end_pos": 65, "type": "TASK", "confidence": 0.5880791246891022}]}, {"text": "However, when many tweets are considered, the accuracy improves with the addition of 10\u223c50 and 50\u223c100 km bins.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 46, "end_pos": 54, "type": "METRIC", "confidence": 0.9995421171188354}]}, {"text": "This implies that the LE estimation requires additional information when there are few tweets, and less information when many tweets are available.", "labels": [], "entities": [{"text": "LE estimation", "start_pos": 22, "end_pos": 35, "type": "METRIC", "confidence": 0.8923332393169403}]}, {"text": "A comparison of the results for different degrees of temporal consistency is shown in.", "labels": [], "entities": []}, {"text": "Although there were few remarkable results, it is clear that the accuracy does not improve significantly when older tweets are considered.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 65, "end_pos": 73, "type": "METRIC", "confidence": 0.9995508790016174}]}, {"text": "In particular, the poorest accuracy was achieved when specific terms are not defined.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 27, "end_pos": 35, "type": "METRIC", "confidence": 0.9993994235992432}]}, {"text": "This shows the validity of considering specific terms.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: LEs for the LEX \"Prefectural Office Ave.\"", "labels": [], "entities": [{"text": "LEX \"Prefectural Office Ave.\"", "start_pos": 22, "end_pos": 51, "type": "DATASET", "confidence": 0.8559816139084953}]}, {"text": " Table 2: Statistics of LEX database", "labels": [], "entities": [{"text": "LEX", "start_pos": 24, "end_pos": 27, "type": "DATASET", "confidence": 0.600191056728363}]}, {"text": " Table 5: Comparison of SP features", "labels": [], "entities": [{"text": "SP", "start_pos": 24, "end_pos": 26, "type": "TASK", "confidence": 0.7283343076705933}]}, {"text": " Table 6. Al- though there were few remarkable results, it is clear  that the accuracy does not improve significantly  when older tweets are considered. In particular, the  poorest accuracy was achieved when specific terms", "labels": [], "entities": [{"text": "Al", "start_pos": 10, "end_pos": 12, "type": "METRIC", "confidence": 0.9633664488792419}, {"text": "accuracy", "start_pos": 78, "end_pos": 86, "type": "METRIC", "confidence": 0.9994940757751465}, {"text": "accuracy", "start_pos": 181, "end_pos": 189, "type": "METRIC", "confidence": 0.9973324537277222}]}]}