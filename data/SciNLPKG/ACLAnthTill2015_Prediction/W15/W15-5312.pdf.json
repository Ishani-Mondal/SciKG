{"title": [], "abstractContent": [{"text": "Elliptical constructions can help to avoid repetition of identical constituents during natural-language generation.", "labels": [], "entities": []}, {"text": "From grammar books, it is not easy to extract exe-cutable rules for ellipsis-in our casein Russian.", "labels": [], "entities": []}, {"text": "Therefore we follow a different strategy.", "labels": [], "entities": []}, {"text": "We test the accuracy of a rule set that has been evaluated for the two Germanic languages, Dutch and German, and the two Finno-Ugric languages, Esto-nian and Hungarian.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 12, "end_pos": 20, "type": "METRIC", "confidence": 0.9995564818382263}]}, {"text": "For a Russian test corpus of about 100 syntactically annotated coordinated sentences that systematically vary the conditions of rule application , our Java program can automatically produce all elliptical variants.", "labels": [], "entities": []}, {"text": "Over-and undergeneration in the resulting lists have been tested in two experiments with native speakers.", "labels": [], "entities": []}, {"text": "Basically, the rules work very well for Russian.", "labels": [], "entities": []}, {"text": "Within the four target languages, Russian works best with the Estonian amendments.", "labels": [], "entities": [{"text": "Estonian amendments", "start_pos": 62, "end_pos": 81, "type": "DATASET", "confidence": 0.7247672528028488}]}, {"text": "Here we report two slight deviations partially known from the linguistic literature.", "labels": [], "entities": []}], "introductionContent": [{"text": "In natural-language generation, ellipsis can help to avoid repetition of identical constituents.", "labels": [], "entities": [{"text": "natural-language generation", "start_pos": 3, "end_pos": 30, "type": "TASK", "confidence": 0.7538730204105377}]}, {"text": "For instance, the conceptual structure 'eat(Peter, apples) & eat(Mary, apples)' where 'eat' and 'apples' occur two times can be formulated as Peter eats apples and Mary too, a case of Stripping.", "labels": [], "entities": []}, {"text": "However, many other paraphrases can be produced such as the aggregation into one sentence with NPcoordination (Peter and Mary eat apples)-a case of reduction we do not address in the following as it works on the conceptual structure whereas we only deal with syntactic structures as input.", "labels": [], "entities": []}, {"text": "Ellipsis occurs frequently in written and spoken language.", "labels": [], "entities": []}, {"text": "In the following, we study four types of clausal coordinate ellipsis (CCE): (1) Gapping (including Long Distance Gapping (LDG), Subgapping and Stripping), (2) Forward Conjunction Reduction (FCR), (3) Backward Conjunction Reduction (BCR), and (4) Subject Gap with Finite/Fronted Verb (SGF).", "labels": [], "entities": []}, {"text": "In German written text, clausal coordination, i.e., the two conjuncts comprise verbal constructions (not necessarily finite), occurs in 14 and ellipsis in at least one of the two conjuncts in 7 percent of the investigated corpus (cf..", "labels": [], "entities": []}, {"text": "All these types of clausal coordinate ellipsis also emerge in spontaneous speech in German (cf.).", "labels": [], "entities": []}, {"text": "This observation is inline with English corpus studies (see, e.g.,) and Dutch).", "labels": [], "entities": []}, {"text": "For recent theoretical treatments of CCE in various linguistic frameworks see, e.g.,.", "labels": [], "entities": []}, {"text": "For Russian as target language, see, e.g.,.", "labels": [], "entities": []}, {"text": "Parsing elliptical constructions is a difficult problem partially due to the fact that both conjuncts maybe grammatically incorrect when viewed in isolation (see, e.g.,.", "labels": [], "entities": [{"text": "Parsing elliptical constructions", "start_pos": 0, "end_pos": 32, "type": "TASK", "confidence": 0.9225388964017233}]}, {"text": "Ina natural-language generation-system, CCE is only one realization option (cf. Shaw 1998) out of many (e.g., Pronominalization also avoids repeating the same NP).", "labels": [], "entities": []}, {"text": "The implemented CCEgeneration component ELLEIPO, which embodies the CCE rule set we present below, can serve as a post-editing component for NLG systems that provide a syntactic structure annotated with co-referentiality tags (cf..", "labels": [], "entities": [{"text": "ELLEIPO", "start_pos": 40, "end_pos": 47, "type": "METRIC", "confidence": 0.6694114804267883}, {"text": "CCE rule set", "start_pos": 68, "end_pos": 80, "type": "DATASET", "confidence": 0.8272349635759989}]}, {"text": "ELLEIPO takes these non-elliptical (redundant) structures as input and provides all reduced to CCE options as output.", "labels": [], "entities": [{"text": "ELLEIPO", "start_pos": 0, "end_pos": 7, "type": "DATASET", "confidence": 0.8800452351570129}]}, {"text": "ELLEIPO was originally developed for), but the implemented set of CCE rules was designed in a languageindependent manner.", "labels": [], "entities": [{"text": "ELLEIPO", "start_pos": 0, "end_pos": 7, "type": "DATASET", "confidence": 0.541155993938446}]}, {"text": "This makes it possible to discover CCE rules in anew target language.", "labels": [], "entities": []}, {"text": "For the Finno-Ugric language Estonian, Harbusch, report high accuracy of the rule set, which suggests that the entire process is language independent.", "labels": [], "entities": [{"text": "Finno-Ugric language Estonian", "start_pos": 8, "end_pos": 37, "type": "TASK", "confidence": 0.5257872541745504}, {"text": "accuracy", "start_pos": 61, "end_pos": 69, "type": "METRIC", "confidence": 0.9995829463005066}]}, {"text": "However, Estonian is suspected to be strongly influenced by language contact with Germanic languages.", "labels": [], "entities": []}, {"text": "Nevertheless, Hungarian, another Finno-Ugric language, yields equally good results (cf..", "labels": [], "entities": []}, {"text": "In the present paper, we aim to further verify our claim that CCE can be generated by language-independent rules by testing ELLEIPO's rules for Russian.", "labels": [], "entities": []}, {"text": "To this purpose, we built a test corpus of about 100 Russian syntactic structures of (unreduced) coordinated sentences in Russian varying the conditions for CCE-rule application.", "labels": [], "entities": [{"text": "CCE-rule application", "start_pos": 157, "end_pos": 177, "type": "TASK", "confidence": 0.5911591202020645}]}, {"text": "RUSSIAN-ELLEIPO produces all CCE reductions for the test corpus.", "labels": [], "entities": [{"text": "RUSSIAN-ELLEIPO", "start_pos": 0, "end_pos": 15, "type": "METRIC", "confidence": 0.44849705696105957}, {"text": "CCE reductions", "start_pos": 29, "end_pos": 43, "type": "METRIC", "confidence": 0.7787796556949615}]}, {"text": "In the first experiment, we let native speakers of Russian judge the quality of the output (overgeneration of the CCE rules).", "labels": [], "entities": []}, {"text": "In the second, native speakers generated all reductions (inclusive Pronominalization etc.) for unreduced coordinated sentences in order to spot CCE realizations that ELLEIPO does not generate (undergeneration).", "labels": [], "entities": []}, {"text": "In general, we observed a very high level of accuracy of the CCE rules.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 45, "end_pos": 53, "type": "METRIC", "confidence": 0.9994956254959106}, {"text": "CCE rules", "start_pos": 61, "end_pos": 70, "type": "DATASET", "confidence": 0.8840258419513702}]}, {"text": "The paper is organized as follows.", "labels": [], "entities": []}, {"text": "In Section 2, we define the CCE phenomena ELLEIPO is able to generate.", "labels": [], "entities": [{"text": "CCE phenomena ELLEIPO", "start_pos": 28, "end_pos": 49, "type": "DATASET", "confidence": 0.7538800438245138}]}, {"text": "In Section 3, we describe the test corpus, and elaborate on ELLEIPO's output and on the user studies.", "labels": [], "entities": [{"text": "ELLEIPO's output", "start_pos": 60, "end_pos": 76, "type": "DATASET", "confidence": 0.8521456122398376}]}, {"text": "In Section 4, we outline our results.", "labels": [], "entities": []}, {"text": "In the final Section, we draw some conclusions and address future work.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 2: Phenomena in the Russian test corpus.", "labels": [], "entities": [{"text": "Russian test corpus", "start_pos": 27, "end_pos": 46, "type": "DATASET", "confidence": 0.8689695000648499}]}]}