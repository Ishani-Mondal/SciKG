{"title": [{"text": "Distributed Representations of Words and Documents for Discriminating Similar Languages", "labels": [], "entities": [{"text": "Distributed Representations of Words and Documents for Discriminating Similar Languages", "start_pos": 0, "end_pos": 87, "type": "TASK", "confidence": 0.8472467422485351}]}], "abstractContent": [{"text": "Discriminating between similar languages or language varieties aims to detect lexical and semantic variations in order to classify these varieties of languages.", "labels": [], "entities": []}, {"text": "In this work we describe the system built by the Pattern Recognition and Human Language Technology (PRHLT) research center-Univer-sitat Polit\u00e8cnica deVa\u00ec encia and Autoritas Consulting for the Discriminating between similar languages (DSL) 2015 shared task.", "labels": [], "entities": [{"text": "Pattern Recognition and Human Language Technology (PRHLT)", "start_pos": 49, "end_pos": 106, "type": "TASK", "confidence": 0.82410443160269}, {"text": "Discriminating between similar languages (DSL) 2015 shared task", "start_pos": 193, "end_pos": 256, "type": "TASK", "confidence": 0.7103738784790039}]}, {"text": "In order to determine the language group of similar languages, we first employ a simple approach based on distances with language prototypes with 99.8% accuracy in the test sets.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 152, "end_pos": 160, "type": "METRIC", "confidence": 0.9981669187545776}]}, {"text": "For classifying intra-group languages we focus on the use of distributed representations of words and documents using the continuous Skip-gram model.", "labels": [], "entities": []}, {"text": "Experimental results of classification of languages in 14 categories yielded accuracies of 92.7% and 90.8% when classifying unmodified texts and text with hidden named entities, respectively.", "labels": [], "entities": [{"text": "accuracies", "start_pos": 77, "end_pos": 87, "type": "METRIC", "confidence": 0.9970424771308899}]}], "introductionContent": [{"text": "Automatic language identification is considered a solved problem in a regular scenario.", "labels": [], "entities": [{"text": "Automatic language identification", "start_pos": 0, "end_pos": 33, "type": "TASK", "confidence": 0.6233720084031423}]}, {"text": "demonstrated how even the most simple of the methods, based on language prototypes of term frequencies, is able to achieve almost 100% accuracy of classification.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 135, "end_pos": 143, "type": "METRIC", "confidence": 0.9992144107818604}]}, {"text": "However, it is far to be solved if we consider the classification of short text, mixed content and when discriminating between language varieties and similar languages.", "labels": [], "entities": []}, {"text": "investigated the language identification of short and noisy text of several European languages using Twitter data, and justified the difficulty of classification in this domain.", "labels": [], "entities": [{"text": "language identification of short and noisy text of several European languages", "start_pos": 17, "end_pos": 94, "type": "TASK", "confidence": 0.8566810488700867}]}, {"text": "Gottron and Lipka (2010) studied the identification of European languages in news headlines and single unambiguous words.", "labels": [], "entities": [{"text": "identification of European languages in news headlines and single unambiguous words", "start_pos": 37, "end_pos": 120, "type": "TASK", "confidence": 0.7999785271557894}]}, {"text": "They demonstrated the impact of the length in the accuracy of classification.", "labels": [], "entities": [{"text": "length", "start_pos": 36, "end_pos": 42, "type": "METRIC", "confidence": 0.9708889722824097}, {"text": "accuracy", "start_pos": 50, "end_pos": 58, "type": "METRIC", "confidence": 0.9969795942306519}, {"text": "classification", "start_pos": 62, "end_pos": 76, "type": "TASK", "confidence": 0.9187513589859009}]}, {"text": "The identification of varieties of the same language has been related to author profiling (, which aims to identify the linguistic profile of an author on the basis of his writing style, and to determine author's traits such as gender, age and personality.", "labels": [], "entities": [{"text": "author profiling", "start_pos": 73, "end_pos": 89, "type": "TASK", "confidence": 0.7233583927154541}]}, {"text": "Variety identification differs from the aforementioned language identification works in terms of difficulty due to the high syntactic and semantic similarities.", "labels": [], "entities": [{"text": "Variety identification", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.8697733879089355}, {"text": "language identification", "start_pos": 55, "end_pos": 78, "type": "TASK", "confidence": 0.7796009182929993}]}, {"text": "Accuracy of classification is reduced from 90-100% to values closer to 80%.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 0, "end_pos": 8, "type": "METRIC", "confidence": 0.9964093565940857}, {"text": "classification", "start_pos": 12, "end_pos": 26, "type": "TASK", "confidence": 0.7983269691467285}]}, {"text": "In () the authors investigated varieties of Portuguese applying different features such as word and character n-grams.", "labels": [], "entities": []}, {"text": "Similarly, in) the authors differentiate between six different varieties of Arabic in blogs and forums using character n-grams.", "labels": [], "entities": []}, {"text": "Concerning Spanish language varieties, in) the authors employed meta-learning to classify tweets from Argentina, Chile, Colombia, Mexico and Spain.", "labels": [], "entities": []}, {"text": "overviews the results of the shared task of tweet language identification organized at SEPLN'2014.", "labels": [], "entities": [{"text": "tweet language identification", "start_pos": 44, "end_pos": 73, "type": "TASK", "confidence": 0.787239670753479}, {"text": "SEPLN'2014", "start_pos": 87, "end_pos": 97, "type": "DATASET", "confidence": 0.7311873435974121}]}, {"text": "A more recent work (, explored the use of techniques based on embeddings to model semantics and evaluated using the HispaBlogs 1 dataset, anew collection of Spanish blogs from five different countries: Argentina, Chile, Mexico, Peru and Spain.", "labels": [], "entities": [{"text": "HispaBlogs 1 dataset", "start_pos": 116, "end_pos": 136, "type": "DATASET", "confidence": 0.9362149437268575}]}, {"text": "The proposed approach demonstrated to achieve remarkable performance and to be less sensitive to over-fitting than the compared state-of-the-art approaches.", "labels": [], "entities": []}, {"text": "In order to illustrate that language identification is not a solved problem, the Discrimi-nating between similar languages (DSL) shared task () is organized.", "labels": [], "entities": [{"text": "language identification", "start_pos": 28, "end_pos": 51, "type": "TASK", "confidence": 0.7310176640748978}, {"text": "Discrimi-nating between similar languages (DSL) shared task", "start_pos": 81, "end_pos": 140, "type": "TASK", "confidence": 0.6365318530135684}]}, {"text": "This task encourages participants to submit systems in order to identify the language of short texts of several groups of similar and varieties of languages ( ).", "labels": [], "entities": []}, {"text": "achieved the best results of the 2014 edition with a combination of different kernels using Support Vector Machines (SVM) (Chang and Lin, 2011) and word and character n-gram features.", "labels": [], "entities": []}, {"text": "This year, the task aims to identify the language of six groups of texts containing similar and varieties of languages (see) and a group containing texts written in a set of other languages.", "labels": [], "entities": []}, {"text": "In this work we evaluate the 2015 shared task by adapting the approach presented in).", "labels": [], "entities": []}, {"text": "We first use an approach based on distances with language prototypes to determine the language group, and next we classify the language using the continuous Skip-gram model to generate distributed representations of words, i.e., n-dimensional vectors -applying further refinements in order to be able to use them in documents.", "labels": [], "entities": []}, {"text": "In addition, we use the Sentence Vector variation to directly generate representations of documents.", "labels": [], "entities": []}, {"text": "Motivations behind evaluating this approach in the DSL shared task are: i) analyse the performance when classifying not only varieties of languages but also similar ones; and ii) determine the validity of the approach to work with considerably shorter texts (sentences) compared to the blogs with 10 post per user that were used as single instance in the past.", "labels": [], "entities": []}, {"text": "The rest of the paper is structured as follows.", "labels": [], "entities": []}, {"text": "Section 2 presents the approach we adapted for the shared task, Section 3 details our evaluation, and in Section 4 we provide our conclusions and future works.", "labels": [], "entities": []}, {"text": "Additional analysis and comparison with the other submitted systems are available in the 2015 shared task overview ().", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section we evaluate our systems for the DSL 2015 shared task.", "labels": [], "entities": [{"text": "DSL 2015 shared task", "start_pos": 48, "end_pos": 68, "type": "TASK", "confidence": 0.6125543415546417}]}, {"text": "Given a labelled collection of training sentences T r belonging to a set of L languages, and a collection of test sentences Te, the task is to classify each sentence t \u2208 Te into one of the languages l \u2208 L using the labelled sentences of T r.", "labels": [], "entities": []}, {"text": "We evaluated our system with the DSL Corpus Collection ( ) of this edition (DSLCC v. 2.0).", "labels": [], "entities": [{"text": "DSL Corpus Collection", "start_pos": 33, "end_pos": 54, "type": "DATASET", "confidence": 0.9840340614318848}, {"text": "DSLCC v. 2.0)", "start_pos": 76, "end_pos": 89, "type": "DATASET", "confidence": 0.9205652922391891}]}, {"text": "This dataset contains sentences in Bulgarian, Macedonian, Serbian, Croatian, Bosnian, Czech, Slovak, Argentinian Spanish, Peninsular Spanish, Brazilian Portuguese, European Portuguese, Malay, Indonesian and a group containing texts written in a set of other languages.", "labels": [], "entities": []}, {"text": "In we can see how they are grouped according to their similarities.", "labels": [], "entities": []}, {"text": "Groups A, C and F contain similar languages and groups B, D and E include language varieties.", "labels": [], "entities": []}, {"text": "There are 18,000 training, 2,000 development and 1,000 test instances/sentences per language.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Accuracy results in discrimination between similar languages using test set A and B.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9956018924713135}]}]}