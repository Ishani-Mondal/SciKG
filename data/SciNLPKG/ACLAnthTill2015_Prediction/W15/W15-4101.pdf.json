{"title": [{"text": "Bootstrapping a hybrid deep MT system", "labels": [], "entities": [{"text": "MT", "start_pos": 28, "end_pos": 30, "type": "TASK", "confidence": 0.9223940968513489}]}], "abstractContent": [{"text": "We present a Portuguese\u2194English hybrid deep MT system based on an analysis-transfer-synthesis architecture, with transfer being done at the level of deep syntax, a level that already includes a great deal of semantic information.", "labels": [], "entities": [{"text": "MT", "start_pos": 44, "end_pos": 46, "type": "TASK", "confidence": 0.7542247772216797}]}, {"text": "The system received a few months of development, but its performance is already similar to that of baseline phrase-based MT, when evaluated using BLEU, and surpasses the base-line under human qualitative assessment.", "labels": [], "entities": [{"text": "MT", "start_pos": 121, "end_pos": 123, "type": "TASK", "confidence": 0.776969313621521}, {"text": "BLEU", "start_pos": 146, "end_pos": 150, "type": "METRIC", "confidence": 0.9925147891044617}]}], "introductionContent": [{"text": "Data-driven phrase-based MT has been, for many years, the technique that has achieved the best results in MT, much due to the availability of huge parallel data sets.", "labels": [], "entities": [{"text": "Data-driven phrase-based MT", "start_pos": 0, "end_pos": 27, "type": "TASK", "confidence": 0.44762800137201947}, {"text": "MT", "start_pos": 106, "end_pos": 108, "type": "TASK", "confidence": 0.9950284361839294}]}, {"text": "Requiring such large amounts of training data is a hindrance for languages with fewer resources.", "labels": [], "entities": []}, {"text": "Statistical MT (SMT) as an approach, however, may have intrinsic limitations that go beyond that of data availability.", "labels": [], "entities": [{"text": "Statistical MT (SMT)", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.8038474321365356}]}, {"text": "The main weakness of current SMT methods ultimately stems from the limited linguistic abstraction that is employed, which leads to difficulties in correctly handling the translation of certain phenomena, such as getting the correct word order when translating between languages with different typology and in maintaining the semantic cohesion of the translated text.", "labels": [], "entities": [{"text": "SMT", "start_pos": 29, "end_pos": 32, "type": "TASK", "confidence": 0.9936269521713257}]}, {"text": "SMT has attempted to tackle these issues by making use of richer linguistic structure, such as hierarchical methods and tree-to-tree mappings, but these methods have been unable to clearly improve on the phrase-based state-of-the-art.", "labels": [], "entities": [{"text": "SMT", "start_pos": 0, "end_pos": 3, "type": "TASK", "confidence": 0.9654731154441833}]}, {"text": "There is a growing opinion that the previous approaches to SMT maybe reaching a performance ceiling and that pushing beyond it will require approaches that are more linguistically informed and that are able to bring semantics into the process.", "labels": [], "entities": [{"text": "SMT", "start_pos": 59, "end_pos": 62, "type": "TASK", "confidence": 0.9960489869117737}]}, {"text": "The classic analysis-transfer-synthesis architecture (the Vauquois triangle) provides a promising foundation onto which such approaches can be built.", "labels": [], "entities": []}, {"text": "Underlying this architecture is the rationale that, the deeper the level of representation, the easier transfer becomes since deeper representations abstract away from surface aspects that are specific to a language.", "labels": [], "entities": []}, {"text": "At the limit, the representation of the meaning of a sentence, and of all its paraphrases, would be shared among all languages.", "labels": [], "entities": []}, {"text": "This paper reports on our work of building a deep MT system, which translates between Portuguese and English, where transfer is performed at the level of a deep syntactic representation.", "labels": [], "entities": [{"text": "MT", "start_pos": 50, "end_pos": 52, "type": "TASK", "confidence": 0.9739383459091187}]}, {"text": "Portuguese is a widespread language, with an estimated 220 million speakers, and is the fifth most used language on the Web.", "labels": [], "entities": []}, {"text": "Despite this, it is relatively less-resourced in terms of available NLP tools and resources.", "labels": [], "entities": []}, {"text": "In this respect, the current work also allowed us to determine a minimal set of NLP tools required to get a deep MT system running, which helps to assess the feasibility of building such a system for underresourced languages.", "labels": [], "entities": [{"text": "MT", "start_pos": 113, "end_pos": 115, "type": "TASK", "confidence": 0.9458271265029907}]}, {"text": "This paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 presents the translation pipeline.", "labels": [], "entities": [{"text": "translation pipeline", "start_pos": 23, "end_pos": 43, "type": "TASK", "confidence": 0.9385863542556763}]}, {"text": "Section 3 evaluates the system intrinsically by comparing it with a state-of-the-art phrase-based SMT approach, and extrinsically by human assessment in the context of a cross-lingual information retrieval task.", "labels": [], "entities": [{"text": "SMT", "start_pos": 98, "end_pos": 101, "type": "TASK", "confidence": 0.8166433572769165}, {"text": "cross-lingual information retrieval task", "start_pos": 170, "end_pos": 210, "type": "TASK", "confidence": 0.6890619844198227}]}, {"text": "Section 4 concludes with some final remarks.", "labels": [], "entities": []}], "datasetContent": [{"text": "This Section reports on both an intrinsic and an extrinsic evaluation, the latter made possible by embedding the system into a helpdesk application that provides technical support through an online chat interface.", "labels": [], "entities": []}, {"text": "In this regard, the application can be seen as a Question Answering (QA) system.", "labels": [], "entities": [{"text": "Question Answering (QA)", "start_pos": 49, "end_pos": 72, "type": "TASK", "confidence": 0.8212039530277252}]}, {"text": "Since most user questions address issues that have been dealt with previously, they are matched against a database of prior questions-answer pairs.", "labels": [], "entities": []}, {"text": "If a matching question is found, the pre-existing answer is returned, thus avoiding the need for the intervention of a human operator.", "labels": [], "entities": []}, {"text": "The questions and the answers in the database are stored in English (see for an example).", "labels": [], "entities": []}, {"text": "An MT component enables cross-lingual usage by automatically translating non-English queries into English prior to searching the database, and by automatically translating the answer from English into the language of the user of the application.", "labels": [], "entities": [{"text": "MT", "start_pos": 3, "end_pos": 5, "type": "TASK", "confidence": 0.9473226070404053}]}, {"text": "The MT component may then impact the QA application in two ways: (i) when translating the question (PT\u2192EN), and consequently affect the ability of the QA system to retrieve the correct answer; and (ii) when translating the retrieved answer (EN\u2192PT), and consequently affect properties of the translated retrieved answer such as its grammaticality, readability and fluency.", "labels": [], "entities": [{"text": "MT", "start_pos": 4, "end_pos": 6, "type": "TASK", "confidence": 0.9608417749404907}]}, {"text": "Given the workings of this QA application, we are concerned with evaluating translation in the PT\u2192EN direction, for questions, and in the EN\u2192PT direction, for answers.", "labels": [], "entities": []}, {"text": "The  The intrinsic evaluation is itself broken down into an automatic and a manual evaluation.", "labels": [], "entities": []}, {"text": "In the automatic evaluation, the standard BLEU metric is used to compare the Treex pipeline against a system built with Moses () that represents the state-of-the-art SMT phrase-based approach.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 42, "end_pos": 46, "type": "METRIC", "confidence": 0.9977442026138306}, {"text": "SMT phrase-based", "start_pos": 166, "end_pos": 182, "type": "TASK", "confidence": 0.8873628973960876}]}, {"text": "Like the transfer module in the translation pipeline, the SMT model is trained over 1.9 million sentences from Europarl.", "labels": [], "entities": [{"text": "translation pipeline", "start_pos": 32, "end_pos": 52, "type": "TASK", "confidence": 0.8993048667907715}, {"text": "SMT", "start_pos": 58, "end_pos": 61, "type": "TASK", "confidence": 0.9895256757736206}, {"text": "Europarl", "start_pos": 111, "end_pos": 119, "type": "DATASET", "confidence": 0.9927345514297485}]}, {"text": "The test set consists of 1, 000 question-answer pairs.", "labels": [], "entities": []}, {"text": "The results of the automatic intrinsic evaluation are summarized in BLEU scores are low, though we note that the domain of the test corpus (technical support) is very different from the domain of Europarl.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 68, "end_pos": 72, "type": "METRIC", "confidence": 0.9986206293106079}, {"text": "Europarl", "start_pos": 196, "end_pos": 204, "type": "DATASET", "confidence": 0.9900960922241211}]}, {"text": "For questions, the BLEU score of the Treex pipeline is fairly worse than the score of Moses.", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 19, "end_pos": 29, "type": "METRIC", "confidence": 0.9808058738708496}, {"text": "Treex pipeline", "start_pos": 37, "end_pos": 51, "type": "DATASET", "confidence": 0.9637560248374939}]}, {"text": "Given the application we envisage, this is to be expected.", "labels": [], "entities": []}, {"text": "The translated question is meant to be used as database query, and not for human eyes.", "labels": [], "entities": []}, {"text": "As such, we have so far placed relatively little effort in improving the synthesis rules for English, since issues like word order errors, agreement mismatches and missing functional words often do not prevent the query from being successful.", "labels": [], "entities": []}, {"text": "BLEU does not necessarily correlate with human judgments.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 0, "end_pos": 4, "type": "METRIC", "confidence": 0.9850198030471802}]}, {"text": "This points us towards manual evaluation as a better way to measure translation quality.", "labels": [], "entities": [{"text": "translation", "start_pos": 68, "end_pos": 79, "type": "TASK", "confidence": 0.908454418182373}]}, {"text": "Recall that the translation of the retrieved answer, unlike the translation of questions, is meant to be read by humans.", "labels": [], "entities": []}, {"text": "As such, the manual evaluation that follows is done only for answers (EN\u2192PT).", "labels": [], "entities": [{"text": "PT", "start_pos": 73, "end_pos": 75, "type": "METRIC", "confidence": 0.6621003150939941}]}, {"text": "The intrinsic manual evaluation consists of a detailed manual diagnosis of the types of translation errors found.", "labels": [], "entities": []}, {"text": "Translation errors are classified in a hierarchy of issues, following the Multidimensional Quality Metrics (MQM) framework, with the help of the open-source editor translate5.", "labels": [], "entities": [{"text": "Translation errors", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.8839605748653412}]}, {"text": "The classification is done by two annotators.", "labels": [], "entities": [{"text": "classification", "start_pos": 4, "end_pos": 18, "type": "TASK", "confidence": 0.9742279052734375}]}, {"text": "Each annotator analyzed the same 100 answers.", "labels": [], "entities": []}, {"text": "The extrinsic evaluation consists of comparing two variants of the cross-lingual QA application, one using the baseline SMT for translation and another using the Treex translation pipeline.", "labels": [], "entities": []}, {"text": "For a given query, the QA system returns a list of answers, each associated with a confidence score.", "labels": [], "entities": []}, {"text": "For each variant, we measure if the correct answer is the first result (top-1) or among the top-2 or top-3 returned results.", "labels": [], "entities": []}, {"text": "The summary in shows that there is little difference between the variants.", "labels": [], "entities": []}, {"text": "The Treex pipeline has a lower BLEU for questions, but this does not negatively impact answer retrieval.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 31, "end_pos": 35, "type": "METRIC", "confidence": 0.9995424747467041}]}, {"text": "While retrieval using the translated question is working well, the quality and usefulness of the helpdesk application ultimately hinges on the quality of the answer that is presented to the user and whether it is correct and clear enough to help the user solve their technical problem.", "labels": [], "entities": []}, {"text": "To evaluate this, a total of six human evaluators were asked to assess the quality of the translated answer.", "labels": [], "entities": []}, {"text": "Their task was, given a reference question-answer pair, to compare both translated answers (anonymized and in random order) with the reference answer and pick the best translation, allowing for ties.", "labels": [], "entities": []}, {"text": "While inmost cases there is not a clearly better variant, the output of the Treex pipeline is better than the output of the SMT system in 30.8% of better variant Treex pipeline 30.8% SMT (Moses) 13.0% (no difference) 56.2%: Variant ranking the cases and worse in only 13.0% of the cases, as shown in.", "labels": [], "entities": [{"text": "SMT", "start_pos": 124, "end_pos": 127, "type": "TASK", "confidence": 0.9697616696357727}]}, {"text": "Inter-annotator agreement, as a ratio of matched annotations, was 0.628.", "labels": [], "entities": [{"text": "agreement", "start_pos": 16, "end_pos": 25, "type": "METRIC", "confidence": 0.6625238656997681}]}], "tableCaptions": [{"text": " Table 1: Comparison of BLEU scores", "labels": [], "entities": [{"text": "BLEU", "start_pos": 24, "end_pos": 28, "type": "METRIC", "confidence": 0.9950218200683594}]}]}