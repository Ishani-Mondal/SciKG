{"title": [{"text": "Analysing Inconsistencies and Errors in PoS Tagging in two Icelandic Gold Standards", "labels": [], "entities": [{"text": "PoS Tagging", "start_pos": 40, "end_pos": 51, "type": "TASK", "confidence": 0.8758823573589325}, {"text": "Icelandic Gold Standards", "start_pos": 59, "end_pos": 83, "type": "DATASET", "confidence": 0.9237006902694702}]}], "abstractContent": [{"text": "This paper describes work in progress.", "labels": [], "entities": []}, {"text": "We experiment with training a state-of-the-art tagger, Stagger, on anew gold standard, MIM-GOLD, for the PoS tagging of Ice-landic.", "labels": [], "entities": [{"text": "MIM-GOLD", "start_pos": 87, "end_pos": 95, "type": "METRIC", "confidence": 0.9650496244430542}, {"text": "PoS tagging", "start_pos": 105, "end_pos": 116, "type": "TASK", "confidence": 0.8543569147586823}]}, {"text": "We compare the results to results obtained using a previous gold standard, IFD.", "labels": [], "entities": [{"text": "IFD", "start_pos": 75, "end_pos": 78, "type": "DATASET", "confidence": 0.7974652051925659}]}, {"text": "Using MIM-GOLD, tagging accuracy is considerably lower, 92.76% compared to 93.67% accuracy for IFD.", "labels": [], "entities": [{"text": "tagging", "start_pos": 16, "end_pos": 23, "type": "TASK", "confidence": 0.9518661499023438}, {"text": "accuracy", "start_pos": 24, "end_pos": 32, "type": "METRIC", "confidence": 0.9893714189529419}, {"text": "accuracy", "start_pos": 82, "end_pos": 90, "type": "METRIC", "confidence": 0.9989431500434875}]}, {"text": "We analyze and classify the errors made by the tagger in order to explain this difference.", "labels": [], "entities": []}, {"text": "We find that inconsistencies and incorrect tags in MIM-GOLD may account for this difference.", "labels": [], "entities": [{"text": "MIM-GOLD", "start_pos": 51, "end_pos": 59, "type": "DATASET", "confidence": 0.7041346430778503}]}], "introductionContent": [{"text": "For some years anew gold standard, MIM-GOLD, for training PoS taggers has been underdevelopment (.", "labels": [], "entities": [{"text": "MIM-GOLD", "start_pos": 35, "end_pos": 43, "type": "METRIC", "confidence": 0.9321098923683167}, {"text": "PoS taggers", "start_pos": 58, "end_pos": 69, "type": "TASK", "confidence": 0.895181804895401}]}, {"text": "This corpus contains approximately one million tokens of text from various sources from the period.", "labels": [], "entities": []}, {"text": "State-of-the-art PoS tagging accuracy for Icelandic, 92.82%, was achieved by, using the Averaged Perceptron Tagger Stagger without an external lexicon.", "labels": [], "entities": [{"text": "PoS tagging", "start_pos": 17, "end_pos": 28, "type": "TASK", "confidence": 0.847144603729248}, {"text": "accuracy", "start_pos": 29, "end_pos": 37, "type": "METRIC", "confidence": 0.9774377346038818}]}, {"text": "All PoS taggers tested so far for Icelandic have been developed or trained and tested on the Icelandic Frequency Dictionary (IFD) (.", "labels": [], "entities": [{"text": "PoS taggers", "start_pos": 4, "end_pos": 15, "type": "TASK", "confidence": 0.8273848593235016}, {"text": "Icelandic Frequency Dictionary (IFD)", "start_pos": 93, "end_pos": 129, "type": "DATASET", "confidence": 0.8129330277442932}]}, {"text": "In this paper we describe the training and testing of Stagger on MIM-GOLD.", "labels": [], "entities": [{"text": "MIM-GOLD", "start_pos": 65, "end_pos": 73, "type": "DATASET", "confidence": 0.5906471014022827}]}, {"text": "Results are compared to the results for training and tagging IFD reported by.", "labels": [], "entities": [{"text": "tagging IFD", "start_pos": 53, "end_pos": 64, "type": "TASK", "confidence": 0.8337761163711548}]}, {"text": "Tagging errors made by Stagger, when tagging the two gold standards, are examined and classified to explain the difference in tagging accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 134, "end_pos": 142, "type": "METRIC", "confidence": 0.9653021693229675}]}, {"text": "In Section 2 we describe the two corpora used for training and tagging.", "labels": [], "entities": [{"text": "tagging", "start_pos": 63, "end_pos": 70, "type": "TASK", "confidence": 0.9350091218948364}]}, {"text": "In Section 3 we describe training and tagging of MIM-GOLD with Stagger.", "labels": [], "entities": [{"text": "tagging", "start_pos": 38, "end_pos": 45, "type": "TASK", "confidence": 0.960294246673584}, {"text": "MIM-GOLD", "start_pos": 49, "end_pos": 57, "type": "TASK", "confidence": 0.7559677362442017}]}, {"text": "In Section 4 we discuss the results.", "labels": [], "entities": []}, {"text": "In Section 5 we report on the analysis of errors made by Stagger when tagging the two corpora, and in Section 6 we conclude.", "labels": [], "entities": []}], "datasetContent": [{"text": "The experiment with training and testing Stagger on IFD reported by was repeated for MIM-GOLD.", "labels": [], "entities": [{"text": "MIM-GOLD", "start_pos": 85, "end_pos": 93, "type": "DATASET", "confidence": 0.6937125325202942}]}, {"text": "We evaluated the version of Stagger using linguistic features (LF) and the unknown word guesser IceMorphy (Loftsson, 2008) and added an extended lexicon based on B\u00cdN.", "labels": [], "entities": [{"text": "word guesser IceMorphy (Loftsson, 2008)", "start_pos": 83, "end_pos": 122, "type": "TASK", "confidence": 0.5818438865244389}, {"text": "B\u00cdN", "start_pos": 162, "end_pos": 165, "type": "METRIC", "confidence": 0.7569750547409058}]}, {"text": "We did not add word embeddings (WE) as was done in the original experiment.", "labels": [], "entities": []}, {"text": "Average unknown word ratio for the IFD corpus when using B\u00cdN is 0.97% and for the MIM-GOLD corpus 3.43%.", "labels": [], "entities": [{"text": "unknown word ratio", "start_pos": 8, "end_pos": 26, "type": "METRIC", "confidence": 0.6023287077744802}, {"text": "IFD corpus", "start_pos": 35, "end_pos": 45, "type": "DATASET", "confidence": 0.9261436760425568}, {"text": "B\u00cdN", "start_pos": 57, "end_pos": 60, "type": "METRIC", "confidence": 0.8340829014778137}, {"text": "MIM-GOLD corpus", "start_pos": 82, "end_pos": 97, "type": "DATASET", "confidence": 0.8321882486343384}]}], "tableCaptions": [{"text": " Table 1: Tagging accuracy when tagging IFD and  MIM-GOLD using 10-fold cross-validation.", "labels": [], "entities": [{"text": "Tagging", "start_pos": 10, "end_pos": 17, "type": "TASK", "confidence": 0.9462853074073792}, {"text": "accuracy", "start_pos": 18, "end_pos": 26, "type": "METRIC", "confidence": 0.990410327911377}, {"text": "tagging IFD", "start_pos": 32, "end_pos": 43, "type": "TASK", "confidence": 0.7309830784797668}, {"text": "MIM-GOLD", "start_pos": 49, "end_pos": 57, "type": "DATASET", "confidence": 0.6584175229072571}]}, {"text": " Table 3: Tagging categorization in the corpora.", "labels": [], "entities": [{"text": "Tagging categorization", "start_pos": 10, "end_pos": 32, "type": "TASK", "confidence": 0.9075410664081573}]}]}