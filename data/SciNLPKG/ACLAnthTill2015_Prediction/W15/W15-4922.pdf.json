{"title": [{"text": "Integrating a Large, Monolingual Corpus as Translation Memory into Statistical Machine Translation", "labels": [], "entities": [{"text": "Statistical Machine Translation", "start_pos": 67, "end_pos": 98, "type": "TASK", "confidence": 0.6471877992153168}]}], "abstractContent": [{"text": "Translation memories (TM) are widely used in the localization industry to improve consistency and speed of human translation.", "labels": [], "entities": [{"text": "Translation memories (TM)", "start_pos": 0, "end_pos": 25, "type": "TASK", "confidence": 0.8995962023735047}, {"text": "consistency", "start_pos": 82, "end_pos": 93, "type": "METRIC", "confidence": 0.9835763573646545}, {"text": "human translation", "start_pos": 107, "end_pos": 124, "type": "TASK", "confidence": 0.6676574647426605}]}, {"text": "Several approaches have been presented to integrate the bilingual translation units of TMs into statistical machine translation (SMT).", "labels": [], "entities": [{"text": "statistical machine translation (SMT)", "start_pos": 96, "end_pos": 133, "type": "TASK", "confidence": 0.7602410813172659}]}, {"text": "We present an extension of these approaches to the integration of partial matches found in a large, monolingual corpus in the target language, using cross-language information retrieval (CLIR) techniques.", "labels": [], "entities": [{"text": "cross-language information retrieval (CLIR)", "start_pos": 149, "end_pos": 192, "type": "TASK", "confidence": 0.7375464886426926}]}, {"text": "We use locality-sensitive hashing (LSH) for efficient coarse-grained retrieval of match candidates, which are then filtered by fine-grained fuzzy matching, and finally used to re-rank the n-best SMT output.", "labels": [], "entities": [{"text": "SMT", "start_pos": 195, "end_pos": 198, "type": "TASK", "confidence": 0.9787859916687012}]}, {"text": "We show consistent and significant improvements over a state-of-the-art SMT system, across different domains and language pairs on tens of millions of sentences.", "labels": [], "entities": [{"text": "SMT", "start_pos": 72, "end_pos": 75, "type": "TASK", "confidence": 0.992598295211792}]}], "introductionContent": [{"text": "A translation memory (TM) is a computational tool used by professional translators to speedup translation of repetitive texts.", "labels": [], "entities": [{"text": "translation memory (TM)", "start_pos": 2, "end_pos": 25, "type": "TASK", "confidence": 0.8926089644432068}, {"text": "translation of repetitive texts", "start_pos": 94, "end_pos": 125, "type": "TASK", "confidence": 0.791416585445404}]}, {"text": "At its core is a database, in which source and target of previously translated segments of text are stored.", "labels": [], "entities": []}, {"text": "TMs are capable of retrieving not only exact, but also partial matches, where only a certain percentage of source words overlap with the query, called fuzzy matches.", "labels": [], "entities": []}, {"text": "A computer-assisted translation (CAT) tool presents possible matches found in the database to a user, if the match is considered similar enough to the current source sentence.", "labels": [], "entities": [{"text": "computer-assisted translation (CAT)", "start_pos": 2, "end_pos": 37, "type": "TASK", "confidence": 0.8326326012611389}]}, {"text": "Even if the presented target sentence is not a perfect translation, a fuzzy match can be a good starting point for the translation of the current sentence and reduce translation time and effort.", "labels": [], "entities": []}, {"text": "Furthermore, the approach can help with translation consistency and terminology control.", "labels": [], "entities": [{"text": "translation consistency", "start_pos": 40, "end_pos": 63, "type": "TASK", "confidence": 0.8981123864650726}, {"text": "terminology control", "start_pos": 68, "end_pos": 87, "type": "TASK", "confidence": 0.9408911764621735}]}, {"text": "In contrast to statistical machine translation (SMT), TM tools are widely used in the translation industry, since the results presented to the translator are fluent translations.", "labels": [], "entities": [{"text": "statistical machine translation (SMT)", "start_pos": 15, "end_pos": 52, "type": "TASK", "confidence": 0.7832465271155039}]}, {"text": "They are especially successful for translation of texts from repetitive domains, e.g. technical documents such as IT manuals, that are the predominant use casein the localization industry.", "labels": [], "entities": [{"text": "translation of texts from repetitive domains", "start_pos": 35, "end_pos": 79, "type": "TASK", "confidence": 0.8720947802066803}]}, {"text": "The idea of combining the strengths of TM and SMT tools has been successfully explored in recent years.", "labels": [], "entities": [{"text": "SMT", "start_pos": 46, "end_pos": 49, "type": "TASK", "confidence": 0.9503222703933716}]}, {"text": "In this paper, we extend these approaches to the integration of a large, monolingual corpus in the target language as a TM into an SMT system using cross-language information retrieval (CLIR).", "labels": [], "entities": [{"text": "SMT", "start_pos": 131, "end_pos": 134, "type": "TASK", "confidence": 0.9850856065750122}, {"text": "cross-language information retrieval (CLIR)", "start_pos": 148, "end_pos": 191, "type": "TASK", "confidence": 0.7226298848787943}]}, {"text": "Our approach utilizes locality-sensitive hashing (LSH) as an efficient coarse retrieval technique to select candidate translations.", "labels": [], "entities": []}, {"text": "Ina next step, search is performed at a finer-grained level using distance metrics customary in CAT.", "labels": [], "entities": []}, {"text": "Given a match, our model re-ranks the n-best list output by an SMT decoder using features modeling the closeness of the hypothesis and the target of the TM match.", "labels": [], "entities": [{"text": "SMT decoder", "start_pos": 63, "end_pos": 74, "type": "TASK", "confidence": 0.8926138877868652}]}, {"text": "Since our approach does not rely on an alignment between source and target side of the TM match, we are able to search for potential matches in large, monolingual corpora that might only be available in the target language.", "labels": [], "entities": []}, {"text": "We show consistent and significant improvements on different domains (IT, legal, patents) for different language pairs (including Chinese, Japanese, English, French, and German), achieving results compara-ble to or better than using a target-language reference of source-side matches.", "labels": [], "entities": []}], "datasetContent": [{"text": "Since translation memories are most effective on text that has a certain amount of repetition, we evaluate our approach on typical localization data, from the IT, legal and intellectual property domains 3).", "labels": [], "entities": [{"text": "translation memories", "start_pos": 6, "end_pos": 26, "type": "TASK", "confidence": 0.8922194242477417}, {"text": "repetition", "start_pos": 83, "end_pos": 93, "type": "METRIC", "confidence": 0.9560288190841675}]}, {"text": "All corpora are freely available for research purposes.", "labels": [], "entities": []}, {"text": "We report repetition rate () and average sentence length in and show the number of matches for each fuzzy match interval in.", "labels": [], "entities": [{"text": "repetition rate", "start_pos": 10, "end_pos": 25, "type": "METRIC", "confidence": 0.9913522601127625}]}, {"text": "Among the freely available corpora, only the JRC-Acquis corpus has been used previously in combinations of TM and SMT ().", "labels": [], "entities": [{"text": "JRC-Acquis corpus", "start_pos": 45, "end_pos": 62, "type": "DATASET", "confidence": 0.932085245847702}]}, {"text": "Most works in this area report results on TM data from industrial partners that are not publicly available.", "labels": [], "entities": [{"text": "TM", "start_pos": 42, "end_pos": 44, "type": "TASK", "confidence": 0.9612363576889038}]}, {"text": "Usually, these datasets feature a large proportion of fuzzy matches in high ranges, e.g. between 80% and 100%, which makes it possible for the combined systems to achieve a large boost in score.", "labels": [], "entities": []}, {"text": "Our reported results are in a smaller range, but achieved on data with much less highpercentage matches.", "labels": [], "entities": []}, {"text": "We manage to gain improvements in performance from matches with an associated fuzzy match score between 10% and 80%.", "labels": [], "entities": []}, {"text": "We prepared an English-Chinese corpus of IT manuals from the OPUS 4 corpus, the OpenOffice 3 (OO3) data.", "labels": [], "entities": [{"text": "OPUS 4 corpus", "start_pos": 61, "end_pos": 74, "type": "DATASET", "confidence": 0.9270324309666952}, {"text": "OpenOffice 3 (OO3) data", "start_pos": 80, "end_pos": 103, "type": "DATASET", "confidence": 0.7455531458059946}]}, {"text": "We only kept pairs that contained at least one Chinese character . The Chinese side was segmented using the Stanford Word Segmenter () with the Penn Treebank standard.", "labels": [], "entities": [{"text": "Stanford Word Segmenter", "start_pos": 108, "end_pos": 131, "type": "DATASET", "confidence": 0.8555344343185425}, {"text": "Penn Treebank standard", "start_pos": 144, "end_pos": 166, "type": "DATASET", "confidence": 0.9921953479448954}]}, {"text": "Development and test sets were created by randomly sampling 1,000 sentence pairs each and remaining pairs used for training.", "labels": [], "entities": []}, {"text": "We used English-French legal data from the JRC-Acquis corpus) and sampled dev, devtest and test set from documents published in 2000.", "labels": [], "entities": [{"text": "JRC-Acquis corpus", "start_pos": 43, "end_pos": 60, "type": "DATASET", "confidence": 0.9560200273990631}]}, {"text": "The remaining years were used for training.", "labels": [], "entities": []}, {"text": "We evaluated our approach on two patent data sets; English-German data from the PatTR 7 corpus and Japanese-English data from the NTCIR 8 challenge (.", "labels": [], "entities": [{"text": "PatTR 7 corpus", "start_pos": 80, "end_pos": 94, "type": "DATASET", "confidence": 0.9398763577143351}, {"text": "NTCIR 8 challenge", "start_pos": 130, "end_pos": 147, "type": "DATASET", "confidence": 0.9080419540405273}]}, {"text": "We used NTCIR-10 dev, test: Data for domain adaptation scenario.", "labels": [], "entities": [{"text": "NTCIR-10 dev", "start_pos": 8, "end_pos": 20, "type": "DATASET", "confidence": 0.9341987073421478}, {"text": "domain adaptation", "start_pos": 37, "end_pos": 54, "type": "TASK", "confidence": 0.7612797617912292}]}, {"text": "trained with SRILM) on the target side of the training data.", "labels": [], "entities": [{"text": "SRILM", "start_pos": 13, "end_pos": 18, "type": "METRIC", "confidence": 0.8997968435287476}]}, {"text": "The weights of the loglinear model were optimized with MIRA (Watanabe et al., 2007) on a held-out development set reserved for this purpose (dev).", "labels": [], "entities": [{"text": "MIRA", "start_pos": 55, "end_pos": 59, "type": "METRIC", "confidence": 0.9921405911445618}]}, {"text": "We employed the baseline model to produce query translations and hypergraphs for the cross-lingual retrieval of target matches as well as to produce 500-best lists, which we re-ranked according to our model given the best match found after fine-grained retrieval.", "labels": [], "entities": []}, {"text": "Retrieval and re-ranking parameters were optimized on an additional held-out (devtest) set.", "labels": [], "entities": []}, {"text": "All presented results were obtained on a third (test) data set.", "labels": [], "entities": []}, {"text": "To compare source and different target retrieval methods in a fair setting, we used the bilingual data from training the SMT model as translation memory, restricted to the target side for target retrieval.", "labels": [], "entities": [{"text": "SMT", "start_pos": 121, "end_pos": 124, "type": "TASK", "confidence": 0.9592127203941345}]}, {"text": "To evaluate our target retrieval approach in more a realistic setting, we furthermore setup an experiment for the English-German patent task, where SMT training data and monolingual TM deviate.", "labels": [], "entities": [{"text": "SMT training", "start_pos": 148, "end_pos": 160, "type": "TASK", "confidence": 0.8746499419212341}]}, {"text": "We assume that we have parallel data from patent claims and the task is to translate text from a different genre, patent descriptions, for which only data in the target language available as well as a small amount of bitext to tune parameters on -a typical domain adaptation scenario.", "labels": [], "entities": []}, {"text": "The available monolingual data is used to extend both the language model as well as the target-language TM.", "labels": [], "entities": []}, {"text": "We report BLEU () and TER () evaluation scores.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9995226860046387}, {"text": "TER () evaluation", "start_pos": 22, "end_pos": 39, "type": "METRIC", "confidence": 0.9449172218640646}]}, {"text": "Statistical significance of all results was assessed following the method described in using the source code provided by the authors 10 .", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Statistics for experimental data.", "labels": [], "entities": []}, {"text": " Table 2: Test set repetition rates (RR) and average  sentence length (SL) in tokens.", "labels": [], "entities": [{"text": "Test set repetition rates (RR)", "start_pos": 10, "end_pos": 40, "type": "METRIC", "confidence": 0.7724512049130031}, {"text": "average  sentence length (SL)", "start_pos": 45, "end_pos": 74, "type": "METRIC", "confidence": 0.897277424732844}]}, {"text": " Table 3: Number of test sentences with source  side fuzzy match score in a certain range.", "labels": [], "entities": []}, {"text": " Table 5: BLEU and TER difference to baseline for TM integration on by source-side matching and  re-ranking (+src-rr) and variants of target-side matching and re-ranking (+tgt-*-rr). All improvements,  except marked with  *  , are significant w.r.t the baseline at p < 0.05. Best results in bold face.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9988124370574951}, {"text": "TER", "start_pos": 19, "end_pos": 22, "type": "METRIC", "confidence": 0.9943913817405701}, {"text": "TM integration", "start_pos": 50, "end_pos": 64, "type": "TASK", "confidence": 0.8885675370693207}]}]}