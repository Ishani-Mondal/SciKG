{"title": [{"text": "Shared Tasks of the 2015 Workshop on Noisy User-generated Text: Twitter Lexical Normalization and Named Entity Recognition", "labels": [], "entities": [{"text": "Lexical Normalization", "start_pos": 72, "end_pos": 93, "type": "TASK", "confidence": 0.7000897526741028}, {"text": "Named Entity Recognition", "start_pos": 98, "end_pos": 122, "type": "TASK", "confidence": 0.6075005531311035}]}], "abstractContent": [{"text": "This paper presents the results of the two shared tasks associated with W-NUT 2015: (1) a text normalization task with 10 participants; and (2) a named entity tagging task with 8 participants.", "labels": [], "entities": [{"text": "W-NUT 2015", "start_pos": 72, "end_pos": 82, "type": "DATASET", "confidence": 0.7804199457168579}, {"text": "text normalization task", "start_pos": 90, "end_pos": 113, "type": "TASK", "confidence": 0.8293902476628622}, {"text": "named entity tagging task", "start_pos": 146, "end_pos": 171, "type": "TASK", "confidence": 0.7267614006996155}]}, {"text": "We outline the task, annotation process and dataset statistics, and provide a high-level overview of the participating systems for each shared task.", "labels": [], "entities": []}], "introductionContent": [{"text": "As part of the 2015 ACL-IJCNLP Workshop on Noisy User-generated Text (W-NUT), we organized two shared tasks: (1) a text normalization task (Section 2); and (2) a named entity tagging task (Section 3).", "labels": [], "entities": [{"text": "2015 ACL-IJCNLP Workshop on Noisy User-generated Text (W-NUT)", "start_pos": 15, "end_pos": 76, "type": "TASK", "confidence": 0.5127142459154129}, {"text": "text normalization task", "start_pos": 115, "end_pos": 138, "type": "TASK", "confidence": 0.7918310562769572}, {"text": "named entity tagging task", "start_pos": 162, "end_pos": 187, "type": "TASK", "confidence": 0.7304260432720184}]}, {"text": "In the text normalization task, participants were asked to convert non-standard words to their standard forms for English tweets.", "labels": [], "entities": [{"text": "text normalization task", "start_pos": 7, "end_pos": 30, "type": "TASK", "confidence": 0.8110531369845072}]}, {"text": "Participating systems were classified by their use of resources, into a constrained and an unconstrained category: constrained systems were permitted to use only the provided training data and off-the-shelf tools; unconstrained systems, on the other hand, were free to use any public tools and resources.", "labels": [], "entities": []}, {"text": "There were 6 official submissions in the constrained category, and 5 official submissions in the unconstrained category.", "labels": [], "entities": []}, {"text": "Overall, deep learning methods and methods based on lexicon-augmented conditional random fields (CRFs) achieved the best results.", "labels": [], "entities": []}, {"text": "The winning team achieved a precision of 0.9061 precision, recall of 0.7865, and F1 of 0.8421.", "labels": [], "entities": [{"text": "precision", "start_pos": 28, "end_pos": 37, "type": "METRIC", "confidence": 0.9995751976966858}, {"text": "precision", "start_pos": 48, "end_pos": 57, "type": "METRIC", "confidence": 0.994933545589447}, {"text": "recall", "start_pos": 59, "end_pos": 65, "type": "METRIC", "confidence": 0.9998487234115601}, {"text": "F1", "start_pos": 81, "end_pos": 83, "type": "METRIC", "confidence": 0.9998579025268555}]}, {"text": "The named entity recognition task attracted 8 participants.", "labels": [], "entities": [{"text": "named entity recognition task", "start_pos": 4, "end_pos": 33, "type": "TASK", "confidence": 0.7558745741844177}]}, {"text": "The majority of teams built their systems using linear-chain conditional random fields (), and many teams also used brown clusters and word embedding features (.", "labels": [], "entities": []}, {"text": "Notable new techniques for named entity recognition in Twitter include a semi-Markov MIRA trained tagger (nrc), an end-to-end neural network using no handengineered features (multimedialab), an approach that weights training data to compensate for concept drift (USFD), and a differential evolution approach to feature selection (iitp).", "labels": [], "entities": [{"text": "named entity recognition", "start_pos": 27, "end_pos": 51, "type": "TASK", "confidence": 0.6404209236303965}]}, {"text": "The submission from the winning team (ousia) achieved suprisingly good performance on this difficult task, near the level of inter-rater agreement.", "labels": [], "entities": []}], "datasetContent": [{"text": "The dataset was randomly split 60:40, into 2,950 tweets for the training data and 1,967 tweets for the test data.", "labels": [], "entities": []}, {"text": "Training ratio 0.587 0.597 0.500 0.589: Numbers of non-standard words in the training and test datasets for the lexical normalization task, broken down into 1:1, 1:N and N :1 mappings from non-standard words to standard words.", "labels": [], "entities": [{"text": "Training ratio 0.587", "start_pos": 0, "end_pos": 20, "type": "METRIC", "confidence": 0.9098626176516215}, {"text": "lexical normalization task", "start_pos": 112, "end_pos": 138, "type": "TASK", "confidence": 0.7764997283617655}]}, {"text": "\"Training ratio\" represents the number of non-standard words in the training data divided by the overall non-standard words in that category.: Top-10 most frequent non-standard words in each partition of the lexical normalization dataset.", "labels": [], "entities": [{"text": "Training ratio\"", "start_pos": 1, "end_pos": 16, "type": "METRIC", "confidence": 0.9581178228060404}]}], "tableCaptions": [{"text": " Table 1: Numbers of non-standard words in the  training and test datasets for the lexical normal- ization task, broken down into 1:1, 1:N and N :1  mappings from non-standard words to standard  words. \"Training ratio\" represents the number of  non-standard words in the training data divided by  the overall non-standard words in that category.", "labels": [], "entities": [{"text": "Training ratio\"", "start_pos": 203, "end_pos": 218, "type": "METRIC", "confidence": 0.8904555638631185}]}, {"text": " Table 2: Top-10 most frequent non-standard words  in each partition of the lexical normalization  dataset.", "labels": [], "entities": []}, {"text": " Table 3: Results of the constrained systems for the lexical normalization shared task", "labels": [], "entities": []}, {"text": " Table 4: Results of the unconstrained systems for the lexical normalization shared task", "labels": [], "entities": []}, {"text": " Table 7: Features and machine learning approach taken by each team.", "labels": [], "entities": []}, {"text": " Table 8: Results segmenting and categorizing en- tities into 10 types.", "labels": [], "entities": []}]}