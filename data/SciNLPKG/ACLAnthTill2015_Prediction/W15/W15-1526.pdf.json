{"title": [{"text": "Unsupervised Topic Modeling for Short Texts Using Distributed Representations of Words", "labels": [], "entities": [{"text": "Unsupervised Topic Modeling", "start_pos": 0, "end_pos": 27, "type": "TASK", "confidence": 0.6500851611296335}]}], "abstractContent": [{"text": "We present an unsupervised topic model for short texts that performs soft clustering over distributed representations of words.", "labels": [], "entities": []}, {"text": "We model the low-dimensional semantic vector space represented by the dense distributed representations of words using Gaussian mixture models (GMMs) whose components capture the notion of latent topics.", "labels": [], "entities": []}, {"text": "While conventional topic model-ing schemes such as probabilistic latent semantic analysis (pLSA) and latent Dirich-let allocation (LDA) need aggregation of short messages to avoid data sparsity in short documents, our framework works on large amounts of raw short texts (billions of words).", "labels": [], "entities": []}, {"text": "In contrast with other topic modeling frameworks that use word co-occurrence statistics, our framework uses a vector space model that overcomes the issue of sparse word co-occurrence patterns.", "labels": [], "entities": []}, {"text": "We demonstrate that our framework outperforms LDA on short texts through both subjective and objective evaluation.", "labels": [], "entities": []}, {"text": "We also show the utility of our framework in learning topics and classifying short texts on Twitter data for English, Spanish, French, Portuguese and Russian.", "labels": [], "entities": []}], "introductionContent": [{"text": "A popular way to infer semantics in an unsupervised manner is to model a document as a mixture of latent topics.", "labels": [], "entities": []}, {"text": "Several schemes such as latent semantic analysis, probabilistic latent semantic analysis (pLSA)) and latent Dirichlet allocation (LDA) ( have been used to good success in inferring the high level meaning of documents through a set of representative words (topics).", "labels": [], "entities": [{"text": "latent semantic analysis", "start_pos": 24, "end_pos": 48, "type": "TASK", "confidence": 0.658670703570048}]}, {"text": "However, the notion of a document has changed immensely over the last decade.", "labels": [], "entities": []}, {"text": "Users have embraced new communication and information medium such as short messaging service (SMS), chats, Twitter, Facebook posts, Instagram and user comments on news pages/blogs in place of emails and conventional news websites.", "labels": [], "entities": []}, {"text": "Document sizes have been reduced from a few hundred words to few hundred characters 1 while the amount of data has increased exponentially.", "labels": [], "entities": []}, {"text": "Conventional topic models such as pLSA and LDA learn latent topics in a corpus by exploiting document-level word co-ocurrences.", "labels": [], "entities": []}, {"text": "Hence, these models typically suffer from data sparsity (estimating reliable word co-occurrence statistics) when applied to short documents.", "labels": [], "entities": []}, {"text": "A popular strategy to overcome this bottleneck is to aggregate short texts into longer documents based on user information, title category, etc.", "labels": [], "entities": []}, {"text": "(. However, these schemes are heuristic and highly dependent on the data.", "labels": [], "entities": []}, {"text": "Furthermore, such metadata may not be available for short texts such as news titles, advertisements or image captions.", "labels": [], "entities": []}, {"text": "In this work, we present an unsupervised topic model that uses soft clustering over distributed representations of words.", "labels": [], "entities": []}, {"text": "The distributed word representations are obtained by using a log-linear model and we model the low-dimensional semantic vector space represented by the dense word vectors using Gaussian mixture models (GMMs).", "labels": [], "entities": []}, {"text": "The K components of the Gaussian mixture model can be considered as the latent topics that are captured by the model.", "labels": [], "entities": []}, {"text": "Unlike long documents, these short messages do not have long distance syntactic or semantic dependencies and we find that the distributed representations learned over limited context windows is sufficient in capturing the distributional similarity of words within a message.", "labels": [], "entities": []}, {"text": "In comparison with previous approaches to topic modeling, we completely ignore the distribution over documents and consider the entire corpus, thereby eliminating the need for aggregation over short messages.", "labels": [], "entities": [{"text": "topic modeling", "start_pos": 42, "end_pos": 56, "type": "TASK", "confidence": 0.7890545725822449}]}, {"text": "The framework presented here is unsupervised, language agnostic and scalable.", "labels": [], "entities": []}], "datasetContent": [{"text": "First, we randomly replaced low frequency words (less than 4 occurrences) with an UNK token to keep the vocabulary open and subsequently used the stop word list to filter the training data.", "labels": [], "entities": [{"text": "UNK token", "start_pos": 82, "end_pos": 91, "type": "DATASET", "confidence": 0.8529407382011414}]}, {"text": "Distributed representations using the continuousbag-of-words log-linear model was used to obtain w i \u2192 d i , \u2200i \u2208 V in each language.", "labels": [], "entities": []}, {"text": "We experimented with different dimensions of distributed representations as well as mixture components.", "labels": [], "entities": []}, {"text": "shows some topics learned by the model and the terms that comprise the topics fora model learned with D=100 and K=200 on English Twitter data.", "labels": [], "entities": [{"text": "D", "start_pos": 102, "end_pos": 103, "type": "METRIC", "confidence": 0.979520320892334}, {"text": "English Twitter data", "start_pos": 121, "end_pos": 141, "type": "DATASET", "confidence": 0.8884422580401102}]}, {"text": "The terms are ranked by probability.", "labels": [], "entities": []}, {"text": "Unsupervised topic modeling schemes are inherently difficult to evaluate quantitatively.", "labels": [], "entities": [{"text": "topic modeling", "start_pos": 13, "end_pos": 27, "type": "TASK", "confidence": 0.6974336057901382}]}, {"text": "Perplexity of trained models on a held-out set is typically used to objectively evaluate topic models (.", "labels": [], "entities": []}, {"text": "However, our scheme does not model the generation process of short text documents.", "labels": [], "entities": []}, {"text": "Hence, we use a variety of subjective and 4 http://en.wiktionary.org/wiki/Wiktionary:Frequency lists objective topic coherence measures to evaluate our framework.", "labels": [], "entities": []}, {"text": "We also present a comparison with a state-of-the-art technique for modeling short texts, namely, biterm topic model (BTM) (.", "labels": [], "entities": []}, {"text": "We perform unsupervised topic modeling experiments on the phrasified English Twitter corpus using three schemes.", "labels": [], "entities": [{"text": "English Twitter corpus", "start_pos": 69, "end_pos": 91, "type": "DATASET", "confidence": 0.6951333781083425}]}, {"text": "We use LDA as a baseline and treat each tweet as an independent document without any aggregation.", "labels": [], "entities": []}, {"text": "We also use the BTM topic model that has been proven to be a suitable fit for short texts.", "labels": [], "entities": [{"text": "BTM topic", "start_pos": 16, "end_pos": 25, "type": "TASK", "confidence": 0.5209468454122543}]}, {"text": "For LDA, we used the open-source implementation GibbsLDA++ and for BTM, we used the implementation associated with (.", "labels": [], "entities": [{"text": "GibbsLDA++", "start_pos": 48, "end_pos": 58, "type": "DATASET", "confidence": 0.9242458641529083}, {"text": "BTM", "start_pos": 67, "end_pos": 70, "type": "DATASET", "confidence": 0.8141593933105469}]}, {"text": "All three schemes used identical data.", "labels": [], "entities": []}, {"text": "We set the parameters \u03b1 = 0.05 and \u03b2 = 0.01 for LDA and \u03b1 = 50 K and \u03b2 = 0.01 for BTM.", "labels": [], "entities": [{"text": "BTM", "start_pos": 82, "end_pos": 85, "type": "DATASET", "confidence": 0.8737567067146301}]}, {"text": "The parameters for LDA and BTM were optimized on held-out set with line search using topic coherence metric described in Eq 4.", "labels": [], "entities": []}, {"text": "We performed training using our framework for varying window lengths (wlen), vector space dimension (D) and number of clusters (K).", "labels": [], "entities": []}, {"text": "Specifically, we trained GMMs with the following parameters,.", "labels": [], "entities": []}, {"text": "First, we manually inspected the topics obtained by our unsupervised distributed representation framework.", "labels": [], "entities": []}, {"text": "A sample of the topics is shown in.", "labels": [], "entities": []}, {"text": "Manual inspection of many of the topic clusters (top ranked words in each cluster) indicated promising results . As a subsequent step, we asked three professional speech transcribers (also NLP annotators) to subjectively rate the utility of each topic (by displaying the top 50 words) on a 1-3 Likert scale.", "labels": [], "entities": []}, {"text": "A rating of 1 indicates completely useless topic cluster while 3 indicates useful topic cluster.", "labels": [], "entities": []}, {"text": "Useful was defined as a collection: Terms with the highest probability for sample latent topics over the entire English Twitter corpus.", "labels": [], "entities": [{"text": "English Twitter corpus", "start_pos": 112, "end_pos": 134, "type": "DATASET", "confidence": 0.8728295564651489}]}, {"text": "The topics were obtained by using wlen = 15, D=100 and K=200.  of terms that indicated some meaningful semantic property (e.g., movie names, politics, headlines, superlatives, sad emoticons/words, etc.) that could be used fora categorization task.", "labels": [], "entities": [{"text": "D", "start_pos": 45, "end_pos": 46, "type": "METRIC", "confidence": 0.9737256169319153}]}, {"text": "In cases of ambiguity, we asked the labelers to confer a rating of 2.", "labels": [], "entities": []}, {"text": "We computed the inter annotator agreement between the three labelers using Fleiss' kappa metric.", "labels": [], "entities": []}, {"text": "The results are presented in Table 2.", "labels": [], "entities": []}, {"text": "The inter-annotator agreement is quite high for the topic clusters induced with context windows wlen of 11 and 15 words.", "labels": [], "entities": []}, {"text": "The agreement is lower for model trained with longer context window perhaps indicating that a window of length 11 or 15 words is sufficient for tweets.", "labels": [], "entities": [{"text": "agreement", "start_pos": 4, "end_pos": 13, "type": "METRIC", "confidence": 0.9981020092964172}]}, {"text": "The mean ratings are mostly higher than 2 and the median rating for wlen = 15, K = {50, 100} are above 2.", "labels": [], "entities": []}, {"text": "The subjective ratings are significantly better than LDA and BTM.", "labels": [], "entities": [{"text": "LDA", "start_pos": 53, "end_pos": 56, "type": "METRIC", "confidence": 0.6797967553138733}, {"text": "BTM", "start_pos": 61, "end_pos": 64, "type": "DATASET", "confidence": 0.60654217004776}]}, {"text": "Hence, subjective evaluation of topics learned using our framework are of consistently high quality.", "labels": [], "entities": []}, {"text": "In order to objectively measure the quality of topics, we also used coherence score).", "labels": [], "entities": []}, {"text": "shows the average topic coherence score over top N words across varying wlen by fixing D = 50 and K = 50.", "labels": [], "entities": []}, {"text": "The topic clusters are more coherent for wlen = 11 at lower values of N but for higher values of N , the model with wlen = 13 performs better.", "labels": [], "entities": []}, {"text": "Since our vector space GMM model learns topic distributions across the entire corpus, many 197 clusters have a large number of terms with high likelihoods.", "labels": [], "entities": []}, {"text": "As a result, it is more appropriate to choose a model with high topic coherence for large values of N . Next, we analyze the effect of dimension of the vector space model on the topic modeling framework.", "labels": [], "entities": []}, {"text": "plots the average topic coherence for varying D.", "labels": [], "entities": []}, {"text": "We find that for D = 100, the model with lower K achieves better topic coherence.", "labels": [], "entities": []}, {"text": "In contrast, for D = 50, the model with K = 200 is objectively better than the models with K = {50, 100}.", "labels": [], "entities": []}, {"text": "In the former case, the number of topics is smaller and hence a higher dimension is separating the vectors in a better fashion while in the latter case, the increased number of topics achieves better separation even with smaller dimension vectors.", "labels": [], "entities": []}, {"text": "One can balance the choice of K and D based on the size of data and desired clusters to be learned.", "labels": [], "entities": []}, {"text": "Topic Coherence for top N words using our approach wlen=15,D=50,K=50 wlen=15,D=50,K=100 wlen=15,D=50,K=200 wlen=15,D=100,K=50 wlen=15,D=100,K=100, we plot the topic coherence score for different cluster sizes.", "labels": [], "entities": []}, {"text": "The plot shows that fora given N , the best coherence score is obtained for Topic Coherence for top N words using our approach wlen=11,D=50,K=50 wlen=11,D=50,K=100 wlen=11,D=50,K=200 wlen=15,D=50,K=50 wlen=15,D=50,K=100 wlen=15,D=50,K=200 wlen=17,D=50,K=50 wlen=17,D=50,K=100 wlen=17,D=50,K=200 were consistently lower than that of the above presented results.", "labels": [], "entities": []}, {"text": "It may again be due to the balance needed in the separation of topics due to vector space dimension versus the total number of GMM components.", "labels": [], "entities": []}, {"text": "Finally, plots the topic coherence score for our approach, BTM and LDA.", "labels": [], "entities": [{"text": "BTM", "start_pos": 59, "end_pos": 62, "type": "DATASET", "confidence": 0.504960298538208}]}, {"text": "The results clearly indicate that our framework performs extremely well on short texts.", "labels": [], "entities": []}, {"text": "While previous results using the BTM approach was only performed on a few million tweets, our experiments are performed on 178M tweets for English.", "labels": [], "entities": []}, {"text": "The performance of LDA and BTM are very similar while our approach achieves significantly higher topic coherence scores.", "labels": [], "entities": []}, {"text": "Finally, shows the topic coherence for Spanish, French, Portuguese and Russian.", "labels": [], "entities": []}, {"text": "Our proposed scheme clearly outperforms LDA on large collections of short texts across languages.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Statistics of the data used to induce distributed representation in each language. en: English,  es: Spanish, fr: French, pt: Portuguese. #voc stands for the vocabulary and #sents denotes number of  sentences.", "labels": [], "entities": []}, {"text": " Table 2: Subjective evaluation of topic coherence across three annotators (D = 50)", "labels": [], "entities": [{"text": "D", "start_pos": 76, "end_pos": 77, "type": "METRIC", "confidence": 0.9943331480026245}]}]}