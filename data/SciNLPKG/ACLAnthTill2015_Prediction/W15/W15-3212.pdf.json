{"title": [{"text": "Joint Arabic Segmentation and Part-Of-Speech Tagging", "labels": [], "entities": [{"text": "Joint Arabic Segmentation", "start_pos": 0, "end_pos": 25, "type": "TASK", "confidence": 0.5346009135246277}, {"text": "Part-Of-Speech Tagging", "start_pos": 30, "end_pos": 52, "type": "TASK", "confidence": 0.6856033354997635}]}], "abstractContent": [{"text": "Arabic has a very comp lex morphological system, though a very structured one.", "labels": [], "entities": []}, {"text": "Character patterns are often indicative of word class and word segmentation.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 58, "end_pos": 75, "type": "TASK", "confidence": 0.7273588627576828}]}, {"text": "In this paper, wee x-plore a novel approach to Arabic word seg-mentation and part-of-speech tagging relying on character information.", "labels": [], "entities": [{"text": "part-of-speech tagging", "start_pos": 77, "end_pos": 99, "type": "TASK", "confidence": 0.7306216955184937}]}, {"text": "The approach is lexicon-free and does not require any morphological analysis, eliminat ing the factor of dictionary coverage.", "labels": [], "entities": []}, {"text": "Using character-based analysis, the developed system yielded state-of-the-art accuracy comparing favourably with other taggers that involve external resources .", "labels": [], "entities": [{"text": "accuracy", "start_pos": 78, "end_pos": 86, "type": "METRIC", "confidence": 0.9984641075134277}]}], "introductionContent": [], "datasetContent": [], "tableCaptions": [{"text": " Table 4: Corpus ATB parts", "labels": [], "entities": [{"text": "Corpus ATB", "start_pos": 10, "end_pos": 20, "type": "DATASET", "confidence": 0.7648823857307434}]}, {"text": " Table 5: Corpus ambiguity analysis", "labels": [], "entities": [{"text": "Corpus ambiguity analysis", "start_pos": 10, "end_pos": 35, "type": "TASK", "confidence": 0.8568122188250223}]}, {"text": " Table 6: Standard split (Diab et al. 2013)", "labels": [], "entities": []}, {"text": " Table 8. The model  trained on the whole training set is tested on the  test set of each part. Then a single model is built  from each training set of each part and tested on  the test set of the given part. The highest scores  are in bold showing the best tagging was  achieved on ATB1 and best segmentation on  ATB2.", "labels": [], "entities": [{"text": "ATB1", "start_pos": 283, "end_pos": 287, "type": "DATASET", "confidence": 0.9829299449920654}, {"text": "segmentation", "start_pos": 297, "end_pos": 309, "type": "TASK", "confidence": 0.9596830606460571}, {"text": "ATB2", "start_pos": 314, "end_pos": 318, "type": "DATASET", "confidence": 0.9911851286888123}]}, {"text": " Table 8: Testing results per part", "labels": [], "entities": []}, {"text": " Table 9: Most errorneous classes -SEGC", "labels": [], "entities": [{"text": "SEGC", "start_pos": 35, "end_pos": 39, "type": "TASK", "confidence": 0.4877275824546814}]}, {"text": " Table 10: Most errorneous classes -UNSC", "labels": [], "entities": [{"text": "UNSC", "start_pos": 36, "end_pos": 40, "type": "DATASET", "confidence": 0.856834352016449}]}, {"text": " Table 11: Most erroneous tokens -SEGC", "labels": [], "entities": [{"text": "SEGC", "start_pos": 34, "end_pos": 38, "type": "TASK", "confidence": 0.42617329955101013}]}, {"text": " Table 12: Most erroneous tokens -UNSC", "labels": [], "entities": [{"text": "UNSC", "start_pos": 34, "end_pos": 38, "type": "DATASET", "confidence": 0.8453243374824524}]}]}