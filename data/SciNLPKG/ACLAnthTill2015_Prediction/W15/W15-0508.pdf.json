{"title": [], "abstractContent": [{"text": "Argument extraction is the task of identifying arguments, along with their components in text.", "labels": [], "entities": [{"text": "Argument extraction", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.7812722027301788}]}, {"text": "Arguments can be usually decomposed into a claim and one or more premises justifying it.", "labels": [], "entities": []}, {"text": "The proposed approach tries to identify segments that represent argument elements (claims and premises) on social Web texts (mainly news and blogs) in the Greek language, fora small set of thematic domains, including articles on politics , economics, culture, various social issues, and sports.", "labels": [], "entities": []}, {"text": "The proposed approach exploits distributed representations of words, extracted from a large non-annotated corpus.", "labels": [], "entities": []}, {"text": "Among the novel aspects of this work is the thematic domain itself which relates to social Web, in contrast to traditional research in the area, which concentrates mainly on law documents and scientific publications.", "labels": [], "entities": []}, {"text": "The huge increase of social web communities, along with their user tendency to debate, makes the identification of arguments in these texts a necessity.", "labels": [], "entities": []}, {"text": "In addition, anew manually annotated corpus has been constructed that can be used freely for research purposes.", "labels": [], "entities": []}, {"text": "Evaluation results are quite promising, suggesting that distributed representations can contribute positively to the task of argument extraction .", "labels": [], "entities": [{"text": "argument extraction", "start_pos": 125, "end_pos": 144, "type": "TASK", "confidence": 0.7741692960262299}]}], "introductionContent": [{"text": "Argumentation is a branch of philosophy that studies the actor process of forming reasons and of drawing conclusions in the context of a discussion, dialogue, or conversation.", "labels": [], "entities": [{"text": "Argumentation is a branch of philosophy that studies the actor process of forming reasons and of drawing conclusions in the context of a discussion, dialogue, or conversation", "start_pos": 0, "end_pos": 174, "type": "Description", "confidence": 0.7969120679230526}]}, {"text": "Being an important element of human communication, its use is very frequent in texts, as a means to convey meaning to the reader.", "labels": [], "entities": []}, {"text": "As a result, argumentation has attracted significant research focus from many disciplines, ranging from philosophy to artificial intelligence.", "labels": [], "entities": [{"text": "argumentation", "start_pos": 13, "end_pos": 26, "type": "TASK", "confidence": 0.9700102806091309}]}, {"text": "Central to argumentation is the notion of argument, which according to is a set of assumptions (i.e. information from which conclusions can be drawn), together with a conclusion that can be obtained by one or more reasoning steps (i.e. steps of deduction).", "labels": [], "entities": []}, {"text": "The conclusion of the argument is often called the claim, or equivalently the consequent or the conclusion of the argument, while the assumptions are called the support, or equivalently the premises of the argument, which provide the reason (or equivalently the justification) for the claim of the argument.", "labels": [], "entities": []}, {"text": "The process of extracting conclusions/claims along with their supporting premises, both of which compose an argument, is known as argument extraction and constitutes an emerging research field.", "labels": [], "entities": [{"text": "argument extraction", "start_pos": 130, "end_pos": 149, "type": "TASK", "confidence": 0.7959249019622803}]}, {"text": "Nowadays, people have the ability to express their opinion with many different ways, using services of the social Web, such as comments on news, fora, blogs, micro-blogs and social networks.", "labels": [], "entities": []}, {"text": "Social Web is a domain that contains a massive volume of information on every possible subject, from religion to health and products, and it is a prosperous place for exchanging opinions.", "labels": [], "entities": []}, {"text": "Its nature is based on debating, so there already is plenty of useful information that waits to be identified and extracted.", "labels": [], "entities": []}, {"text": "Consequently, there is a large amount of data that can be further explored.", "labels": [], "entities": []}, {"text": "A common form for mining useful information from these texts, is by applying sentiment analysis techniques.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 77, "end_pos": 95, "type": "TASK", "confidence": 0.9527416229248047}]}, {"text": "Sentiment analysis can be proven as a quick way to capture sentiment polarity of people about a specific topic.", "labels": [], "entities": [{"text": "Sentiment analysis", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.9573659598827362}]}, {"text": "Two of the domains where capturing public opinion is of great importance, are e-Government and policy making.", "labels": [], "entities": [{"text": "policy making", "start_pos": 95, "end_pos": 108, "type": "TASK", "confidence": 0.7676813900470734}]}, {"text": "In this way, politicians and policy makers can refine their plans, laws and public consultations prior to their publication or implementation.", "labels": [], "entities": []}, {"text": "Additionally, it could help the voters in deciding which policies and political parties suit them better.", "labels": [], "entities": []}, {"text": "However, a more fine-grained analysis is required in order to detect in which specific aspects of a policy, a citizen is in favour or against.", "labels": [], "entities": []}, {"text": "Such analysis can be achieved through argument extraction: once a document that relates to a policy is located, it is examined in order to identify segments that contain argument elements, such as premises that are against or in support of a claim or an entity (such as nuclear energy or renewable energy sources).", "labels": [], "entities": [{"text": "argument extraction", "start_pos": 38, "end_pos": 57, "type": "TASK", "confidence": 0.7544327974319458}]}, {"text": "The main idea behind this filtering of public opinion as found on the social Web, is that citizens that try to justify their opinion with arguments maybe more important or influential than the less justified ones.", "labels": [], "entities": []}, {"text": "Motivated by this need, in this paper we propose a supervised approach for argument extraction from relevant media, based on Conditional Random Fields.", "labels": [], "entities": [{"text": "argument extraction from relevant media", "start_pos": 75, "end_pos": 114, "type": "TASK", "confidence": 0.8407715559005737}]}, {"text": "Following the state of the art (i.e. [), our approach studies the applicability of existing approaches on the domain of social Web, mainly news and blogs, although the evaluation focuses only on news, due to copyright issues 1 . Assuming that we know whether a sentence contains an argument element or not (i.e. by applying an approach similar to the one described in), our approach tries to detect the exact segments that represent these elements (i.e. claims and premises) through the use of a CRF classifier.", "labels": [], "entities": []}, {"text": "Targeting a set of thematic domains and languages as wide as possible, we have tried to minimise the use of domain and language depended resources.", "labels": [], "entities": []}, {"text": "Thus our approach exploits features such as words, part-of-speech tags, small lists of language-dependent cue words, and distributed representations of words, that can be easily extracted from unannotated large corpora.", "labels": [], "entities": []}, {"text": "Our approach has been evaluated on manually annotated news in the Greek language, containing news from various thematic domains, including sports, politics, economics, culture, and various so-cial problems, while the evaluation results are quite promising, suggesting that distributed representations can contribute positively to this task.", "labels": [], "entities": []}, {"text": "The rest of the paper is organized as follows: Section 2 refers to the related work on argument extraction, section 3 describes the proposed methodology and the corresponding features used for our approach.", "labels": [], "entities": [{"text": "argument extraction", "start_pos": 87, "end_pos": 106, "type": "TASK", "confidence": 0.7868320345878601}]}, {"text": "Section 4 presents the experimental results and the tools we utilized and finally, section 5 concludes the paper and proposes some future directions.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section the performance of the proposed approach will be examined.", "labels": [], "entities": []}, {"text": "The performance metrics that will be used in order to evaluate our approach is accuracy, precision, recall and F1-measure.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 79, "end_pos": 87, "type": "METRIC", "confidence": 0.9996365308761597}, {"text": "precision", "start_pos": 89, "end_pos": 98, "type": "METRIC", "confidence": 0.9995378255844116}, {"text": "recall", "start_pos": 100, "end_pos": 106, "type": "METRIC", "confidence": 0.9996179342269897}, {"text": "F1-measure", "start_pos": 111, "end_pos": 121, "type": "METRIC", "confidence": 0.9987491369247437}]}, {"text": "The empirical evaluation involves two experiments: The first experiment concerns that use of the \"word2vec\" tool, in order to obtain a suitable model for Greek, while the second experiment involves the evaluation of our approach for argument extraction on a manually annotated corpus.", "labels": [], "entities": [{"text": "argument extraction", "start_pos": 233, "end_pos": 252, "type": "TASK", "confidence": 0.7307108491659164}]}, {"text": "Unfortunately, the corpus used in was not available due to licensing limitations.", "labels": [], "entities": []}, {"text": "As a result, we had to create anew manually annotated corpus in order to evaluate our approach.", "labels": [], "entities": []}, {"text": "We collected 300 news articles written in Greek from  the Greek newspaper \"\u0391\u03c5\u03b3\u03ae\" 5 . According to their site, articles can be used without restriction for noncommercial purposes.", "labels": [], "entities": [{"text": "Greek newspaper \"\u0391\u03c5\u03b3\u03ae\" 5", "start_pos": 58, "end_pos": 82, "type": "DATASET", "confidence": 0.7486642102400461}]}, {"text": "The thematic domain of the articles varies from politics and economics to culture, various social issues and sports.", "labels": [], "entities": []}, {"text": "The documents were manually annotated by two post-graduate students with moderate experience on the annotation process.", "labels": [], "entities": []}, {"text": "Prior to the beginning of the annotation task, the annotators were supplied with guidelines describing the identification of arguments, while a QA session was carried out afterwards.", "labels": [], "entities": []}, {"text": "The guidelines contained text examples of premises in favor or against the central claim stated by the articles' author.", "labels": [], "entities": []}, {"text": "In these terms, the annotators were initially called to identify the central claims stated from the author of each article.", "labels": [], "entities": []}, {"text": "Subsequently, they looked for text segments attacking or supporting every claim respectively.", "labels": [], "entities": []}, {"text": "These segments may sometimes start with cue words such as \"\u03b4\u03b9\u03cc\u03c4\u03b9\" (\"because\"), \"\u03b3\u03b9\u03b1 \u03bd\u03b1\" (\"in order to\"), \"\u03b1\u03bb\u03bb\u03ac\" (\"but\"), or may just follow the usual sentence structure.", "labels": [], "entities": []}, {"text": "Each annotator annotated 150 documents with argument components (premises and claims).", "labels": [], "entities": []}, {"text": "Once each annotator has annotated half of the corpus, pre-annotation has been applied, as a proven way to obtain significant gains in both annotation time and quality of annotation.", "labels": [], "entities": []}, {"text": "Since we were targeting errors of omission (segments missed by the annotators), an \"overly-general\" CRF model was trained on all 300 documents, and applied on the corpus.", "labels": [], "entities": []}, {"text": "The CRF model is characterised as \"overly-general\", as it was derived only from sentences that contained claims and premises.", "labels": [], "entities": []}, {"text": "Sentences not containing argument elements were omitted from training.", "labels": [], "entities": []}, {"text": "The CRF model detected 4524 segments, significantly more than the 1172 segments annotated by the two annotators.", "labels": [], "entities": []}, {"text": "A second round of annotation was performed, where both layers of annotations were visible (both the manual and the segments obtained through machine learning), and each annotator was asked to revise his own http://www.avgi.gr annotations, having two goals: a) examine whether any of the segments detected by the CRF model is either a claim or a premise, and b) exploit their experience from annotating 150 documents, to revise their annotations, especially the ones done during the early stages of annotation.", "labels": [], "entities": []}, {"text": "During this second annotation step, a small number of errors was corrected and 19 new segments were added as argument elements, producing the \"final\" version of the manually annotated corpus , which has been used for evaluating our approach.", "labels": [], "entities": []}, {"text": "The final version of the corpus contains 1191 segments annotated as argument elements.", "labels": [], "entities": []}, {"text": "Although the production of the corpus is still an ongoing process, we measured the inter-annotation agreement between of the two annotators over a fraction of the entire corpus.", "labels": [], "entities": []}, {"text": "For this reason, we asked each annotator to annotate eighty articles already annotated by the other annotator, leading to 170 documents (out of 300) annotated by both annotators.", "labels": [], "entities": []}, {"text": "Annotator A has annotated 918 argument elements, while annotator B has annotated 735 argument elements, out of which 624 were common between the two annotators, leading to a precision of 84.90%, a recall of 67.97%, with an F1 measure of 75.50%.", "labels": [], "entities": [{"text": "precision", "start_pos": 174, "end_pos": 183, "type": "METRIC", "confidence": 0.9992226362228394}, {"text": "recall", "start_pos": 197, "end_pos": 203, "type": "METRIC", "confidence": 0.9971401691436768}, {"text": "F1 measure", "start_pos": 223, "end_pos": 233, "type": "METRIC", "confidence": 0.9915998578071594}]}, {"text": "The manually annotated corpus containing 300 documents was used in order to evaluate our approach.", "labels": [], "entities": []}, {"text": "For all evaluations, 10-fold cross validation was used, along with precision, recall, and F1 measure as the evaluation metrics.", "labels": [], "entities": [{"text": "precision", "start_pos": 67, "end_pos": 76, "type": "METRIC", "confidence": 0.9997252821922302}, {"text": "recall", "start_pos": 78, "end_pos": 84, "type": "METRIC", "confidence": 0.999136745929718}, {"text": "F1 measure", "start_pos": 90, "end_pos": 100, "type": "METRIC", "confidence": 0.9874317944049835}]}, {"text": "In order to measure the increase in performance, we have used abase case.", "labels": [], "entities": []}, {"text": "Our base case was a CRF model, using as features the words and pos tags.", "labels": [], "entities": []}, {"text": "Our approach for argument extraction seeks to detect the boundaries of a text fragment that encloses a claim or a premise of an argument.", "labels": [], "entities": [{"text": "argument extraction", "start_pos": 17, "end_pos": 36, "type": "TASK", "confidence": 0.7712239027023315}]}, {"text": "One way to achieve this task, is to classify each word (token) of a sentence as a \"boundary\" token, i.e. as a token that \"starts\" or \"ends\" an argumentative segment.", "labels": [], "entities": []}, {"text": "Using such a representation, the task can be converted into a classification task on each token.", "labels": [], "entities": []}, {"text": "The \"BILOU\" representation seeks to classify each token with a single tag, which can be any tag from the following set: a) B: This tag represents the start/begin of a segment.", "labels": [], "entities": [{"text": "BILOU", "start_pos": 5, "end_pos": 10, "type": "METRIC", "confidence": 0.990919828414917}]}, {"text": "It must be applied on the first token of a segment.", "labels": [], "entities": []}, {"text": "b) I: This tag marks a token as being inside a segment.", "labels": [], "entities": []}, {"text": "It must be applied on any token inside a segment, except the first and last ones.", "labels": [], "entities": []}, {"text": "c) L: This tag represents the end of a segment.", "labels": [], "entities": []}, {"text": "It must be applied on the last token of a segment.", "labels": [], "entities": []}, {"text": "d) O: This tag marks a token as being outside a segment.", "labels": [], "entities": [{"text": "O", "start_pos": 3, "end_pos": 4, "type": "METRIC", "confidence": 0.9929041266441345}]}, {"text": "It must be applied on any token that is not contained inside a segment.", "labels": [], "entities": []}, {"text": "e) U: This tag correspond to \"unit\" segments, which are segments that contain a single token.", "labels": [], "entities": []}, {"text": "It is a special case that marks a token that is the beginning and end of a segment simultaneously.", "labels": [], "entities": []}, {"text": "For example the BILOU representation of the sentence \"Wind turbines generate noise in the summer\" is presented in  Since the documents in our corpus were divided in four large categories (according to their source of origin), we started with the creation of four different \"word2vec\" models.", "labels": [], "entities": [{"text": "BILOU", "start_pos": 16, "end_pos": 21, "type": "METRIC", "confidence": 0.9948115348815918}]}, {"text": "Evaluation of the acquired models showed that news and blogs provide more finegrained models in comparison to the models obtained from Facebook and Twitter.", "labels": [], "entities": []}, {"text": "This happens because the Facebook and Twitter postings are usually less formal, many words are used with different senses than in news/blogs, postings may not have proper syntax or spelling and often contain abbreviations.", "labels": [], "entities": []}, {"text": "As a result, a lot of noise has been inserted in the corresponding output models.", "labels": [], "entities": []}, {"text": "The authors of have made available to us the cue word and entity lists they have used in their experiments, which concern the thematic domain of renewable energy sources.", "labels": [], "entities": []}, {"text": "Their list of cue words was manually extracted from their corpus by the researches, while the list of entities was provided by domain experts and policy makers.", "labels": [], "entities": []}, {"text": "Trying to expand these lists, we randomly selected twenty cue words and twenty entities from these, as a seed.", "labels": [], "entities": []}, {"text": "For each seed word, the five more similar words were examined.", "labels": [], "entities": []}, {"text": "Evaluation results suggest that there was a large variation on the similarities drawn for the same words from the news/blogs corpora and the Facebook/Twitter corpora.", "labels": [], "entities": []}, {"text": "As it was expected, the models produced from the Facebook and Twitter corpora were worse than the others.", "labels": [], "entities": []}, {"text": "shows sample results for the word \"\u03bb\u03b9\u03b3\u03bd\u03af\u03c4\u03b7\u03c2\" (\"lignite\"), from the \"word2vec\" models of the news and blogs corpora.", "labels": [], "entities": []}, {"text": "As we can see, the obtained similar words both for news and blogs corpora belong to the same domain, thus they can all be used to expand our word feature space and gazetteers for this specific domain.", "labels": [], "entities": []}, {"text": "On the other hand, as shown in, the results from Facebook and Twitter for the same word (\"\u03bb\u03b9\u03b3\u03bd\u03af\u03c4\u03b7\u03c2\") are completely irrelevant.", "labels": [], "entities": []}, {"text": "After examining the results, we observed that the sense of many words varies between news/blogs and facebook/twitter corpora.", "labels": [], "entities": []}, {"text": "For example, the word \"attractive\", in Twitter and Facebook is used inmost cases as \"handsome\" (i.e. attractive person), while in news and blogs is usually referred as \"interesting\" (i.e. attractive investment).", "labels": [], "entities": []}, {"text": "One reason for this, is clearly the irrelevance of the topics discussed in social media and the use of language used in these discussion.", "labels": [], "entities": []}, {"text": "In addition, the vocabulary normally used in social media is not as specialized as in news sites.", "labels": [], "entities": []}, {"text": "This means that the similarity results from social media are not expected to be efficient for using in domain independent models.", "labels": [], "entities": []}, {"text": "A noted fact that supports the above findings is the frequency of appearance of the word \"\u03bb\u03b9\u03b3\u03bd\u03af\u03c4\u03b7\u03c2\" (\"lignite\") in the corpora.", "labels": [], "entities": [{"text": "frequency", "start_pos": 53, "end_pos": 62, "type": "METRIC", "confidence": 0.9731906056404114}]}, {"text": "Specifically, the word \"\u03bb\u03b9\u03b3\u03bd\u03af\u03c4\u03b7\u03c2\", appeared 5087 times in the news/blogs corpora, unlike the Facebook/Twitter corpora that appeared 1615 times.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: \"Word2vec\" sample output (most similar words to  the Greek word \"\u03bf\u03c1\u03b5\u03b9\u03b2\u03b1\u03c3\u03af\u03b1\" (\"climbing\")).", "labels": [], "entities": []}, {"text": " Table 2: \"Word2vec\" sample output (40 most similar words to the Greek word \"\u03bb\u03b9\u03b3\u03bd\u03af\u03c4\u03b7\u03c2\" (\"lignite\")). Model extracted  from documents originating from news and Blogs.", "labels": [], "entities": []}, {"text": " Table 3: Corpus Properties (in millions of documents).", "labels": [], "entities": []}, {"text": " Table 6: Evaluation Results: Accuracy of 5 most similar words.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 30, "end_pos": 38, "type": "METRIC", "confidence": 0.9985783100128174}]}, {"text": " Table 8: CRF base case evaluation: words + pos tags.", "labels": [], "entities": []}, {"text": " Table 9: CRF base case evaluation: words + pos tags +  context 2/5.", "labels": [], "entities": []}, {"text": " Table 10: CRF base case evaluation: words + pos tags +  context 2/5.", "labels": [], "entities": []}]}