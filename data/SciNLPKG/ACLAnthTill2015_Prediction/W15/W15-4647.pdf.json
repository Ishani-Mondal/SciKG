{"title": [{"text": "Automatic Detection of Miscommunication in Spoken Dialogue Systems", "labels": [], "entities": [{"text": "Automatic Detection of Miscommunication", "start_pos": 0, "end_pos": 39, "type": "TASK", "confidence": 0.8239200413227081}]}], "abstractContent": [{"text": "In this paper, we present a data-driven approach for detecting instances of mis-communication in dialogue system interactions.", "labels": [], "entities": [{"text": "detecting instances of mis-communication in dialogue system interactions", "start_pos": 53, "end_pos": 125, "type": "TASK", "confidence": 0.6843806430697441}]}, {"text": "A range of generic features that are both automatically extractable and manually annotated were used to train two models for online detection and one for offline analysis.", "labels": [], "entities": [{"text": "online detection", "start_pos": 125, "end_pos": 141, "type": "TASK", "confidence": 0.6786799430847168}]}, {"text": "Online detection could be used to raise the error awareness of the system, whereas offline detection could be used by a system designer to identify potential flaws in the dialogue design.", "labels": [], "entities": [{"text": "Online detection", "start_pos": 0, "end_pos": 16, "type": "TASK", "confidence": 0.7061239629983902}, {"text": "error awareness", "start_pos": 44, "end_pos": 59, "type": "METRIC", "confidence": 0.9284945130348206}]}, {"text": "In experimental evaluations on system logs from three different dialogue systems that vary in their dialogue strategy , the proposed models performed substantially better than the majority class baseline models.", "labels": [], "entities": []}], "introductionContent": [{"text": "Miscommunication is a frequent phenomenon in both human-human and human-machine interactions.", "labels": [], "entities": [{"text": "Miscommunication", "start_pos": 0, "end_pos": 16, "type": "TASK", "confidence": 0.9417489171028137}]}, {"text": "However, while human conversational partners are skilled at detecting and resolving problems, state-of-the-art dialogue systems often have problems with this.", "labels": [], "entities": []}, {"text": "Various works have been reported on detection of errors in humanmachine dialogues.", "labels": [], "entities": []}, {"text": "While the common theme among these works is to use error detection for making online adaption of dialogue strategies (e.g., implicit vs. explicit confirmations), they differ in what they model as error.", "labels": [], "entities": []}, {"text": "For example, model dialogue successor failure as error, refers to lack of confidence in understanding user intentions as error, use the notion of interaction quality in a dialogue as an estimate of errors at arbitrary point in a dialogue, and model misunderstandings on the system's part as errors.", "labels": [], "entities": []}, {"text": "Awareness about errors in dialogues, however, has relevance not only for making online decisions, but also for dialogue system designers.", "labels": [], "entities": []}, {"text": "Access to information about in which states the dialogue fails or runs into trouble could enable system designers to identify potential flaws in the dialogue design.", "labels": [], "entities": []}, {"text": "Unfortunately, this type of error analysis is typically done manually, which is laborious and time consuming.", "labels": [], "entities": [{"text": "error analysis", "start_pos": 28, "end_pos": 42, "type": "TASK", "confidence": 0.6860197484493256}]}, {"text": "Automation of this task has high relevance for dialogue system developers, particularly for interactive voice response (IVR) systems.", "labels": [], "entities": [{"text": "interactive voice response (IVR)", "start_pos": 92, "end_pos": 124, "type": "TASK", "confidence": 0.7407230834166209}]}, {"text": "In this paper, we present a data-driven approach for detection of miscommunication in dialogue system interactions through automatic analysis of system logs.", "labels": [], "entities": []}, {"text": "This analysis is based on the assumption that the onus of miscommunication is on the system.", "labels": [], "entities": []}, {"text": "Thus, instances of nonunderstandings, implicit and explicit confirmations based on false assumptions, and confusing prompts are treated as problematic system actions that we want to detect in order to avoid them.", "labels": [], "entities": []}, {"text": "Since our main goal is to integrate the approach in a toolkit for offline analysis of interaction logs we focus here largely on models for offline detection.", "labels": [], "entities": [{"text": "offline detection", "start_pos": 139, "end_pos": 156, "type": "TASK", "confidence": 0.7192289978265762}]}, {"text": "For this analysis, we have the full dialogue context (backward and forward) at our disposal, and use features that are both automatically extractable from the system logs and manually annotated.", "labels": [], "entities": []}, {"text": "However, we also report the performances of these models using only online features and limited dialogue context, and demonstrate our models' suitability for online use in detection of potential problems in system actions.", "labels": [], "entities": []}, {"text": "We evaluate our approach on datasets from three different dialogue systems that vary in their dialogue modeling, dialogue strategy, language, user types.", "labels": [], "entities": []}, {"text": "We also report findings from an experimental work on cross-corpus analysis: using a model trained on logs from one system for analysis of interaction logs from another system.", "labels": [], "entities": [{"text": "cross-corpus analysis", "start_pos": 53, "end_pos": 74, "type": "TASK", "confidence": 0.8163007199764252}]}, {"text": "Thus the novelty of work reported here lies in our models' relevance for offline as well as online detection of miscommunications, and the applicability and generalizability of features across dialogue systems and domains.", "labels": [], "entities": []}, {"text": "The paper is structured as follows: we report the relevant literature in Section 2 and establish the ground for our work.", "labels": [], "entities": []}, {"text": "In Section 3 we describe the three datasets used.", "labels": [], "entities": []}, {"text": "The annotation scheme is discussed in Section 4.", "labels": [], "entities": []}, {"text": "The complete set of features explored in this work is presented in Section 5.", "labels": [], "entities": []}, {"text": "The experimental method is described in Section 6 and results are reported in Section 7.", "labels": [], "entities": []}, {"text": "We conclude and outline our future work in Section 8.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 4: Distribution of the three annotation catego- ries across the three datasets", "labels": [], "entities": []}, {"text": " Table 6: Cross-corpus performances of offline model  (JRIP learner and feature set BoC+ DrW+DrC)", "labels": [], "entities": [{"text": "JRIP learner and feature set BoC+ DrW+DrC", "start_pos": 55, "end_pos": 96, "type": "DATASET", "confidence": 0.879980844259262}]}, {"text": " Table 7: Offline error detection on a CamInfo interaction. Text within [] is the top ASR hypothesis.", "labels": [], "entities": [{"text": "Offline error detection", "start_pos": 10, "end_pos": 33, "type": "TASK", "confidence": 0.6196373005708059}, {"text": "ASR", "start_pos": 86, "end_pos": 89, "type": "TASK", "confidence": 0.9614516496658325}]}]}