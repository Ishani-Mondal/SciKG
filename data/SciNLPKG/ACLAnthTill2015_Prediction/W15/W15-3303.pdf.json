{"title": [{"text": "An HPSG-based Shared-Grammar for the Chinese Languages: ZHONG [|]", "labels": [], "entities": []}], "abstractContent": [{"text": "This paper introduces our attempts to model the Chinese language using HPSG and MRS.", "labels": [], "entities": [{"text": "HPSG", "start_pos": 71, "end_pos": 75, "type": "DATASET", "confidence": 0.9324142336845398}, {"text": "MRS", "start_pos": 80, "end_pos": 83, "type": "DATASET", "confidence": 0.5088643431663513}]}, {"text": "Chinese refers to a family of various languages including Mandarin Chinese, Cantonese, Min, etc.", "labels": [], "entities": []}, {"text": "These languages share a large amount of structure , though they may differ in orthogra-phy, lexicon, and syntax.", "labels": [], "entities": []}, {"text": "To model these, we are building a family of grammars: ZHONG [ ].", "labels": [], "entities": [{"text": "ZHONG", "start_pos": 54, "end_pos": 59, "type": "DATASET", "confidence": 0.9247934222221375}]}, {"text": "This grammar contains in-stantiations of various Chinese languages, sharing descriptions where possible.", "labels": [], "entities": []}, {"text": "Currently we have prototype grammars for Cantonese and Mandarin in both simplified and traditional script, all based on a common core.", "labels": [], "entities": []}, {"text": "The grammars also have facilities for robust parsing, sentence generation , and unknown word handling.", "labels": [], "entities": [{"text": "sentence generation", "start_pos": 54, "end_pos": 73, "type": "TASK", "confidence": 0.7949616014957428}, {"text": "unknown word handling", "start_pos": 80, "end_pos": 101, "type": "TASK", "confidence": 0.6125682493050894}]}], "introductionContent": [{"text": "Chinese is a group of related but sometimes mutually unintelligible languages that originated in China, including Mandarin Chinese, Cantonese, Min, etc.", "labels": [], "entities": []}, {"text": "These languages have many grammatical similarities, though their orthography, vocabulary and syntax all differ from language to language.", "labels": [], "entities": []}, {"text": "Thus, it is advantageous to implement a Chinese resource capable of covering both the common parts of the grammars and the linguistic diversity across the languages.", "labels": [], "entities": []}, {"text": "Building an integrated grammar reduces the cost for resource construction and also helps the system reflect the genuine nature of the Chinese languages reliably.", "labels": [], "entities": []}, {"text": "This paper reports on our on-going project of building up an integrated computational grammar for these languages within the HPSG and MRS frameworks).", "labels": [], "entities": [{"text": "HPSG and MRS frameworks", "start_pos": 125, "end_pos": 148, "type": "DATASET", "confidence": 0.709164448082447}]}, {"text": "The grammar is implemented using the collection of language processing tools offered by the DELPH-IN (DEep Linguistic Processing with HPSG -INitiative, http: //www.delph-in.net) consortium.", "labels": [], "entities": []}, {"text": "This grammar combines a shared core for all the Chinese languages, as well as language specific descriptions.", "labels": [], "entities": []}, {"text": "Currently we only have grammars for Mandarin Chinese (with simplified and traditional characters) and Cantonese, although we hope to add Min soon.", "labels": [], "entities": []}, {"text": "This paper describes how the grammar has been constructed and reports on its current capacity for parsing and generation.", "labels": [], "entities": [{"text": "parsing and generation", "start_pos": 98, "end_pos": 120, "type": "TASK", "confidence": 0.6812043090661367}]}, {"text": "The paper is structured as follows: Section 2 offers background knowledge of the current work.", "labels": [], "entities": []}, {"text": "Section 3 presents how the resource grammar works for the different Chinese languages.", "labels": [], "entities": []}, {"text": "After discussing the specification of the grammar in Section 4, Section 5 conducts an evaluation to see coverage.", "labels": [], "entities": [{"text": "coverage", "start_pos": 104, "end_pos": 112, "type": "METRIC", "confidence": 0.990587592124939}]}, {"text": "Section 6 concludes this paper with an outlook for future work.", "labels": [], "entities": []}], "datasetContent": [{"text": "We measured the coverage of the current grammar focusing on simplified Mandarin Chinese (abbreviated to zhs).", "labels": [], "entities": [{"text": "coverage", "start_pos": 16, "end_pos": 24, "type": "METRIC", "confidence": 0.9661260843276978}]}, {"text": "We have two groups of test suites.", "labels": [], "entities": []}, {"text": "First, we use three linguistic phenomena-based testsuites: the testsuite constructed at Free University of Berlin (fu-berlin,), the testsuite of the Mandarin Chinese Grammar (mcg-wxl, Zhang et al.), and the JEC basic sentences (jec,).", "labels": [], "entities": [{"text": "JEC", "start_pos": 207, "end_pos": 210, "type": "DATASET", "confidence": 0.8312249183654785}]}, {"text": "Second, we use naturally occurring texts in order to check the computational feasibility of the current implementation.", "labels": [], "entities": []}, {"text": "The corpora we used include the NTU-MC (ntumc,), the Penn Chinese Treebank (pctb,), and the Sinica Treebank (sinica,).", "labels": [], "entities": [{"text": "NTU-MC", "start_pos": 32, "end_pos": 38, "type": "DATASET", "confidence": 0.9520558714866638}, {"text": "Penn Chinese Treebank (pctb", "start_pos": 53, "end_pos": 80, "type": "DATASET", "confidence": 0.9401679277420044}, {"text": "Sinica Treebank", "start_pos": 92, "end_pos": 107, "type": "DATASET", "confidence": 0.755825400352478}]}, {"text": "We used the entire NTU-MC (7,460 sentences) and extracted the first 5,000 sentences from the other two corpora.", "labels": [], "entities": [{"text": "NTU-MC", "start_pos": 19, "end_pos": 25, "type": "DATASET", "confidence": 0.956544816493988}]}, {"text": "The tools for running tests are pyDelphin (https: //github.com/goodmami/pydelphin) and gTest (https://github.com/goodmami/gtest).", "labels": [], "entities": []}, {"text": "The result of coverage testing is provided in.", "labels": [], "entities": []}, {"text": "The numbers in parenthesis stand for the coverage of ungrammatical sentences.", "labels": [], "entities": []}, {"text": "Note that only the first two include ungrammatical items.", "labels": [], "entities": []}, {"text": "Since ungrammatical sentences had better be rejected, the smaller number means the better performance for those items.", "labels": [], "entities": []}, {"text": "All the numbers in parenthesis are smaller than 5%, which shows that our grammar does not overgenerate very much.", "labels": [], "entities": []}, {"text": "When unknown word handling (unk) is facilitated, our current grammar provides relatively satisfactory results, as indicated in the third column.", "labels": [], "entities": [{"text": "word handling (unk)", "start_pos": 13, "end_pos": 32, "type": "TASK", "confidence": 0.8052927196025849}]}, {"text": "However, the parsing coverage is still low when a running text is chosen for testing.", "labels": [], "entities": [{"text": "parsing coverage", "start_pos": 13, "end_pos": 29, "type": "TASK", "confidence": 0.7369281351566315}]}, {"text": "Particularly, when it comes to the pctb testsuite, the coverage is only about 7%.", "labels": [], "entities": [{"text": "coverage", "start_pos": 55, "end_pos": 63, "type": "METRIC", "confidence": 0.9971103072166443}]}, {"text": "There are two main reasons.", "labels": [], "entities": []}, {"text": "First, the sentences in the pctb testsuite are much longer than those in the other testsuites.", "labels": [], "entities": []}, {"text": "Second, our current grammar has not fully modeled relative clauses and serial verbs in Chinese, but the pctb testsuite includes many sentences containing such constructions.", "labels": [], "entities": []}, {"text": "Thus, our immediate goal in grammar construction is to implement the constructions (see).", "labels": [], "entities": [{"text": "grammar construction", "start_pos": 28, "end_pos": 48, "type": "TASK", "confidence": 0.7444342076778412}]}, {"text": "When the sinica testsuite is used, the coverage is relatively high (40.36%).", "labels": [], "entities": [{"text": "coverage", "start_pos": 39, "end_pos": 47, "type": "METRIC", "confidence": 0.9986692667007446}]}, {"text": "This is mainly because our lexical acquisition is mostly based on the corpus.", "labels": [], "entities": []}, {"text": "Using bridging rules (br) aims to facilitate robust parsing, which serves to minimize additional parsing costs (time and space) and maximize compatibility with existing platforms and tools.", "labels": [], "entities": [{"text": "parsing", "start_pos": 52, "end_pos": 59, "type": "TASK", "confidence": 0.9624599814414978}]}, {"text": "Since a set of bridging rules allows any two signs to combine into a phrase, the combination of unknown word handling and bridging rules (unk+br) provides the highest coverage, as indicated in the fifth column of.", "labels": [], "entities": [{"text": "coverage", "start_pos": 167, "end_pos": 175, "type": "METRIC", "confidence": 0.9658007025718689}]}, {"text": "This implies that the unk+br mode enables our grammar to be used for training of statistical models and run-time applications in future work.", "labels": [], "entities": []}, {"text": "The generation coverage (gen) is calculated as follows: If a sentence is parsed, the MRS representation of the parse result is chosen as the input source for generation.", "labels": [], "entities": [{"text": "generation coverage (gen)", "start_pos": 4, "end_pos": 29, "type": "METRIC", "confidence": 0.7230771124362946}]}, {"text": "Because the generation does notwork with unknown word handling within the present infrastructure, the input source comes from the parse result of plain.", "labels": [], "entities": []}, {"text": "If the generation process successfully produces one or more surface forms at the end, the generation coverage grows up.", "labels": [], "entities": []}, {"text": "Notice that the generation coverage is not necessarily 100%, because the memory space for generation is limited (2GB in the current evaluation).", "labels": [], "entities": []}, {"text": "The held-out testsuites result in more than 90% generation coverage, and the testsuites consisting of naturally occurring texts result in more than 70% except the pctb testsuite.", "labels": [], "entities": [{"text": "coverage", "start_pos": 59, "end_pos": 67, "type": "METRIC", "confidence": 0.6539170742034912}]}, {"text": "We believe that these measures are good for such a young grammar, although several challenging points remain.", "labels": [], "entities": []}, {"text": "Finally, the end-to-end-success coverage from parsing to generation is measured by multiplying the values in the second column (plain) and the sixth column (gen).", "labels": [], "entities": [{"text": "parsing", "start_pos": 46, "end_pos": 53, "type": "TASK", "confidence": 0.9801055788993835}]}], "tableCaptions": [{"text": " Table 1. ManGO, which ZHONG [", "labels": [], "entities": [{"text": "ManGO", "start_pos": 10, "end_pos": 15, "type": "DATASET", "confidence": 0.7298718690872192}, {"text": "ZHONG", "start_pos": 23, "end_pos": 28, "type": "METRIC", "confidence": 0.6703215837478638}]}, {"text": " Table 1: Size of grammar", "labels": [], "entities": []}, {"text": " Table 3: Coverage of simplified Mandarin (%)", "labels": [], "entities": []}]}