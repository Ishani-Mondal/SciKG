{"title": [{"text": "Grammatical Error Correction Considering Multi-word Expressions", "labels": [], "entities": [{"text": "Grammatical Error Correction", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.8106780846913656}]}], "abstractContent": [{"text": "Multi-word expressions (MWEs) have been recognized as important linguistic information and much research has been conducted especially on their extraction and interpretation.", "labels": [], "entities": [{"text": "Multi-word expressions (MWEs)", "start_pos": 0, "end_pos": 29, "type": "TASK", "confidence": 0.6703632354736329}]}, {"text": "On the other hand, they have hardly been used in real application areas.", "labels": [], "entities": []}, {"text": "While those who are learning English as a second language (ESL) use MWEs in their writings just like native speakers, MWEs haven't been taken into consideration in grammatical error correction tasks.", "labels": [], "entities": [{"text": "grammatical error correction tasks", "start_pos": 164, "end_pos": 198, "type": "TASK", "confidence": 0.7127919644117355}]}, {"text": "In this paper, we investigate the grammatical error correction method using MWEs.", "labels": [], "entities": [{"text": "grammatical error correction", "start_pos": 34, "end_pos": 62, "type": "TASK", "confidence": 0.5419135987758636}]}, {"text": "Our method proposes a straightforward application of MWEs to grammatical error correction , but experimental results show that MWEs have a beneficial effect on grammatical error correction.", "labels": [], "entities": [{"text": "grammatical error correction", "start_pos": 61, "end_pos": 89, "type": "TASK", "confidence": 0.7134601473808289}, {"text": "grammatical error correction", "start_pos": 160, "end_pos": 188, "type": "TASK", "confidence": 0.6968110402425131}]}], "introductionContent": [{"text": "Publicly usable services on the Web for assisting second language learning are growing recently.", "labels": [], "entities": []}, {"text": "For example, there are language learning social networking services such as Lang-8 and English grammar checkers such as Ginger 2 . Research on assistance of second language learning also has received much attention, especially on grammatical error correction of essays written by learners of English as a second language (ESL) . In the past, three competitions for grammatical error correction have been held: Helping Our Own () and CoNLL Shared Task ().", "labels": [], "entities": [{"text": "Lang-8", "start_pos": 76, "end_pos": 82, "type": "DATASET", "confidence": 0.9404852390289307}, {"text": "grammatical error correction of essays written by learners of English as a second language (ESL)", "start_pos": 230, "end_pos": 326, "type": "TASK", "confidence": 0.8644684553146362}, {"text": "grammatical error correction", "start_pos": 365, "end_pos": 393, "type": "TASK", "confidence": 0.6134339074293772}]}, {"text": "Most previous research on ESL learners' grammatical error correction is targeted on one or few restricted types of learners' errors.", "labels": [], "entities": [{"text": "ESL learners' grammatical error correction", "start_pos": 26, "end_pos": 68, "type": "TASK", "confidence": 0.8776524901390076}]}, {"text": "ESL learners make various kinds of grammatical errors).", "labels": [], "entities": []}, {"text": "For dealing with any types of errors, grammatical error correction methods using phrase-based statistical machine translation (SMT) are proposed ().", "labels": [], "entities": [{"text": "grammatical error correction", "start_pos": 38, "end_pos": 66, "type": "TASK", "confidence": 0.6512846450010935}, {"text": "phrase-based statistical machine translation (SMT)", "start_pos": 81, "end_pos": 131, "type": "TASK", "confidence": 0.7100001914160592}]}, {"text": "Phrase-based SMT carries out translation with phrases which area sequence of words as translation units.", "labels": [], "entities": [{"text": "Phrase-based SMT", "start_pos": 0, "end_pos": 16, "type": "TASK", "confidence": 0.6201568990945816}]}, {"text": "However, since phrases are extracted in an unsupervised manner, an MWE like \"a lot of\" may not be treated as one phrase.", "labels": [], "entities": []}, {"text": "In machine translation fields, phrase-based SMT considering MWEs achieved higher performance.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 3, "end_pos": 22, "type": "TASK", "confidence": 0.7675653100013733}, {"text": "SMT", "start_pos": 44, "end_pos": 47, "type": "TASK", "confidence": 0.675759494304657}]}, {"text": "In this paper, we propose a grammatical error correction method considering MWEs.", "labels": [], "entities": [{"text": "grammatical error correction", "start_pos": 28, "end_pos": 56, "type": "TASK", "confidence": 0.5810916324456533}]}, {"text": "To be precise, we apply machine translation methods considering MWEs to grammatical error correction.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 24, "end_pos": 43, "type": "TASK", "confidence": 0.6949343234300613}, {"text": "grammatical error correction", "start_pos": 72, "end_pos": 100, "type": "TASK", "confidence": 0.6482017437616984}]}, {"text": "They turn MWEs into single units in the source side sentences (English).", "labels": [], "entities": []}, {"text": "Unlike typical machine translation that translates between two languages, in the grammatical error correction task, source side sentences contain errors.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 15, "end_pos": 34, "type": "TASK", "confidence": 0.7575602233409882}, {"text": "grammatical error correction", "start_pos": 81, "end_pos": 109, "type": "TASK", "confidence": 0.6201382577419281}]}, {"text": "Thus, we propose two methods; one is that MWEs are treated as one word in both source and target side sentences, the other is that MWEs are treated as one word in only the target side sentences.", "labels": [], "entities": []}], "datasetContent": [{"text": "correction using multi-word expressions  We used cicada 0.3.0 6 for the machine translation tool.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 72, "end_pos": 91, "type": "TASK", "confidence": 0.7324225455522537}]}, {"text": "This includes a decoder and a word aligner.", "labels": [], "entities": []}, {"text": "As the language modeling tool we used expgram 0.2.0 7 . We used ZMERT 8 as the parameter tuning tool.", "labels": [], "entities": []}, {"text": "For automatic identifying MWEs, we use AMALGr 1.0 9 ().", "labels": [], "entities": [{"text": "automatic identifying MWEs", "start_pos": 4, "end_pos": 30, "type": "TASK", "confidence": 0.6232239107290903}, {"text": "AMALGr 1.0 9", "start_pos": 39, "end_pos": 51, "type": "DATASET", "confidence": 0.7684650421142578}]}, {"text": "The MWE identification tool is re-trained using the MWE data set tagged by) on the Penn Treebank sections of OntoNotes Release 4.0.", "labels": [], "entities": [{"text": "MWE identification", "start_pos": 4, "end_pos": 22, "type": "TASK", "confidence": 0.8634430766105652}, {"text": "MWE data set tagged", "start_pos": 52, "end_pos": 71, "type": "DATASET", "confidence": 0.9559879750013351}, {"text": "Penn Treebank sections of OntoNotes Release 4.0", "start_pos": 83, "end_pos": 130, "type": "DATASET", "confidence": 0.93301408631461}]}, {"text": "This is because their annotation was more convenient for our purpose.", "labels": [], "entities": []}, {"text": "The translation model was trained on the Lang-8 Learner Corpora v2.0.", "labels": [], "entities": [{"text": "translation", "start_pos": 4, "end_pos": 15, "type": "TASK", "confidence": 0.9701359868049622}, {"text": "Lang-8 Learner Corpora v2.0", "start_pos": 41, "end_pos": 68, "type": "DATASET", "confidence": 0.9443332105875015}]}, {"text": "We extracted English essays which were written by ESL learners whose native language is Japanese from the corpora and cleaned the noise with the method proposed in.", "labels": [], "entities": []}, {"text": "As the results, we got 629,787 sentence pairs.", "labels": [], "entities": []}, {"text": "We used a 5-gram  As evaluation metrics, we use precision, recall and F-score.", "labels": [], "entities": [{"text": "precision", "start_pos": 48, "end_pos": 57, "type": "METRIC", "confidence": 0.9997274279594421}, {"text": "recall", "start_pos": 59, "end_pos": 65, "type": "METRIC", "confidence": 0.9994004964828491}, {"text": "F-score", "start_pos": 70, "end_pos": 77, "type": "METRIC", "confidence": 0.9980364441871643}]}, {"text": "We compare phrase-based SMT without using MWEs (baseline) with the two methods explained in 4.2.", "labels": [], "entities": [{"text": "SMT", "start_pos": 24, "end_pos": 27, "type": "TASK", "confidence": 0.7701662182807922}]}, {"text": "In addition, we varied the number of MWEs used for training the translation model and the language model.", "labels": [], "entities": []}, {"text": "This is because MWEs that appear few times may introduce noises.", "labels": [], "entities": []}, {"text": "We use top 70 (50%), 120 (80%) and 170 (90%) MWEs described in 3.1.", "labels": [], "entities": []}, {"text": "The methods considering MWEs achieved higher Fscore than baseline except for the case that uses All MWEs.", "labels": [], "entities": [{"text": "Fscore", "start_pos": 45, "end_pos": 51, "type": "METRIC", "confidence": 0.9996863603591919}]}, {"text": "In addition, using more MWEs increases the F-score.", "labels": [], "entities": [{"text": "F-score", "start_pos": 43, "end_pos": 50, "type": "METRIC", "confidence": 0.9986039996147156}]}], "tableCaptions": [{"text": " Table 1 shows the rate of overlap of multi- word expressions from Penn Treebank section of  OntoNotes and Lang-8 Learner Corpora in taking  top N. Although they are in different domains,  MWEs used by learners overlap about 60% with  those used by native speakers.", "labels": [], "entities": [{"text": "Penn Treebank section", "start_pos": 67, "end_pos": 88, "type": "DATASET", "confidence": 0.9895272056261698}, {"text": "OntoNotes", "start_pos": 93, "end_pos": 102, "type": "DATASET", "confidence": 0.5030989050865173}]}, {"text": " Table 2: Results of grammatical error correction", "labels": [], "entities": [{"text": "grammatical error correction", "start_pos": 21, "end_pos": 49, "type": "TASK", "confidence": 0.6529672642548879}]}]}