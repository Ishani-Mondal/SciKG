{"title": [{"text": "Analyzing English-Spanish Named-Entity enhanced Machine Translation", "labels": [], "entities": [{"text": "Analyzing English-Spanish Named-Entity", "start_pos": 0, "end_pos": 38, "type": "TASK", "confidence": 0.876604437828064}, {"text": "Machine Translation", "start_pos": 48, "end_pos": 67, "type": "TASK", "confidence": 0.6916923671960831}]}], "abstractContent": [{"text": "Translation of named-entities (NEs) is an issue in SMT.", "labels": [], "entities": [{"text": "Translation of named-entities (NEs)", "start_pos": 0, "end_pos": 35, "type": "TASK", "confidence": 0.9079187413056692}, {"text": "SMT", "start_pos": 51, "end_pos": 54, "type": "TASK", "confidence": 0.9906339645385742}]}, {"text": "In this paper we analyze the errors when translating NEs with a SMT system from English to Spanish.", "labels": [], "entities": [{"text": "translating NEs", "start_pos": 41, "end_pos": 56, "type": "TASK", "confidence": 0.689521849155426}, {"text": "SMT", "start_pos": 64, "end_pos": 67, "type": "TASK", "confidence": 0.9609141945838928}]}, {"text": "We train on Europarl and test on News Commentary, fo-cusing on entities correctly recognized by an automatic NE recognition system.", "labels": [], "entities": [{"text": "Europarl", "start_pos": 12, "end_pos": 20, "type": "DATASET", "confidence": 0.9931307435035706}, {"text": "NE recognition", "start_pos": 109, "end_pos": 123, "type": "TASK", "confidence": 0.806229293346405}]}, {"text": "The automatic systems translate around 85% NEs correctly , leaving a small margin for improving performance.", "labels": [], "entities": [{"text": "NEs", "start_pos": 43, "end_pos": 46, "type": "METRIC", "confidence": 0.979075014591217}]}, {"text": "In addition, we implement a purpose-build NE translator and integrate it in the SMT system, yielding a small but significant improvement in BLEU score.", "labels": [], "entities": [{"text": "NE translator", "start_pos": 42, "end_pos": 55, "type": "TASK", "confidence": 0.7130801975727081}, {"text": "SMT", "start_pos": 80, "end_pos": 83, "type": "TASK", "confidence": 0.9648898839950562}, {"text": "BLEU score", "start_pos": 140, "end_pos": 150, "type": "METRIC", "confidence": 0.9812771677970886}]}, {"text": "Our analysis shows that, contrary to similar systems translating from Chinese to English, there was no improvement in NE translation, prompting further work.", "labels": [], "entities": [{"text": "NE translation", "start_pos": 118, "end_pos": 132, "type": "TASK", "confidence": 0.9464148283004761}]}], "introductionContent": [{"text": "Name-Aware SMT focuses on improving namedentity (NE) translation.", "labels": [], "entities": [{"text": "Name-Aware SMT", "start_pos": 0, "end_pos": 14, "type": "TASK", "confidence": 0.467338889837265}, {"text": "namedentity (NE) translation", "start_pos": 36, "end_pos": 64, "type": "TASK", "confidence": 0.5431443691253662}]}, {"text": "The most basic approach is to add a devoted named-entity translation lexicon to the training data.", "labels": [], "entities": []}, {"text": "report good results using this method.", "labels": [], "entities": []}, {"text": "Another common solution is to replace NEs with special tags and translate them in a postedition step.", "labels": [], "entities": []}, {"text": "For instance, propose substituting source names with high frequency names before applying SMT.", "labels": [], "entities": [{"text": "SMT", "start_pos": 90, "end_pos": 93, "type": "TASK", "confidence": 0.9818182587623596}]}, {"text": "Ina more sophisticated setting, use hierarchical SMT (HSMT) to integrate a specialized NE translation system, showing relevant improvements in overall translation quality and, particularly, in NE translation when translating from Chinese to English.", "labels": [], "entities": [{"text": "NE translation", "start_pos": 87, "end_pos": 101, "type": "TASK", "confidence": 0.872352659702301}, {"text": "NE translation", "start_pos": 193, "end_pos": 207, "type": "TASK", "confidence": 0.9033913314342499}]}, {"text": "In this paper we replicate their system and analyze how NEs are translated when translating from English to Spanish.", "labels": [], "entities": []}, {"text": "There is also related work on including transliteration modules ().", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Distribution of NEs in the development set", "labels": [], "entities": []}, {"text": " Table 2: NE translation accuracy in the development set for the baseline HSMT system.", "labels": [], "entities": [{"text": "NE translation", "start_pos": 10, "end_pos": 24, "type": "TASK", "confidence": 0.876192182302475}, {"text": "accuracy", "start_pos": 25, "end_pos": 33, "type": "METRIC", "confidence": 0.9499584436416626}]}, {"text": " Table 3: NE translation accuracy and BLEU score in the test set", "labels": [], "entities": [{"text": "NE translation", "start_pos": 10, "end_pos": 24, "type": "TASK", "confidence": 0.5778471976518631}, {"text": "accuracy", "start_pos": 25, "end_pos": 33, "type": "METRIC", "confidence": 0.9145435094833374}, {"text": "BLEU score", "start_pos": 38, "end_pos": 48, "type": "METRIC", "confidence": 0.9794080555438995}]}]}