{"title": [{"text": "Alignment-based sense selection in METEOR and the RATATOUILLE recipe", "labels": [], "entities": [{"text": "Alignment-based sense selection", "start_pos": 0, "end_pos": 31, "type": "TASK", "confidence": 0.864422341187795}, {"text": "METEOR", "start_pos": 35, "end_pos": 41, "type": "METRIC", "confidence": 0.6326075196266174}, {"text": "RATATOUILLE", "start_pos": 50, "end_pos": 61, "type": "DATASET", "confidence": 0.6339967250823975}]}], "abstractContent": [{"text": "This paper describes Meteor-WSD and RATATOUILLE, the LIMSI submissions to the WMT15 metrics shared task.", "labels": [], "entities": [{"text": "RATATOUILLE", "start_pos": 36, "end_pos": 47, "type": "METRIC", "confidence": 0.8608059883117676}, {"text": "WMT15 metrics shared task", "start_pos": 78, "end_pos": 103, "type": "TASK", "confidence": 0.6396838426589966}]}, {"text": "Meteor-WSD extends synonym mapping to languages other than English based on alignments and gives credit to semantically adequate translations in context.", "labels": [], "entities": [{"text": "synonym mapping", "start_pos": 19, "end_pos": 34, "type": "TASK", "confidence": 0.8899215459823608}]}, {"text": "We show that context-sensitive synonym selection increases the correlation of the Meteor metric with human judgments of translation quality on the WMT14 data.", "labels": [], "entities": [{"text": "context-sensitive synonym selection", "start_pos": 13, "end_pos": 48, "type": "TASK", "confidence": 0.6559272805849711}, {"text": "Meteor metric", "start_pos": 82, "end_pos": 95, "type": "DATASET", "confidence": 0.8593060970306396}, {"text": "WMT14 data", "start_pos": 147, "end_pos": 157, "type": "DATASET", "confidence": 0.9780958294868469}]}, {"text": "RATATOUILLE combines Meteor-WSD with nine other metrics for evaluation and outperforms the best metric (BEER) involved in its computation.", "labels": [], "entities": [{"text": "RATATOUILLE", "start_pos": 0, "end_pos": 11, "type": "TASK", "confidence": 0.3805229961872101}, {"text": "BEER)", "start_pos": 104, "end_pos": 109, "type": "METRIC", "confidence": 0.9785750806331635}]}], "introductionContent": [{"text": "The Meteor metric evaluates translation hypotheses by aligning them to reference translations and calculating sentence-level similarity scores (.", "labels": [], "entities": []}, {"text": "The space of possible alignments fora hypothesis-reference pair is constructed by identifying all possible matches between the sentences according to different matchers mapping words with identical surface forms or having the same stem, WordNet synonyms and paraphrases.", "labels": [], "entities": []}, {"text": "These modules add flexibility to the metric and improve its correlation with human judgments of translation quality but they fail to account for important semantics-related aspects.", "labels": [], "entities": []}, {"text": "For example, Meteor and Meteor-NEXT treat all the variants available fora particular text fragment in WordNet) or a pivot paraphrase database () as semantically equivalent.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 102, "end_pos": 109, "type": "DATASET", "confidence": 0.9389135837554932}]}, {"text": "Consequently, erroneous matches can be made by mapping synonyms found in different WordNet synsets and describing different senses.", "labels": [], "entities": []}, {"text": "Similarly, pivot paraphrase sets merge sense boundaries in cases of polysemous words (), which means that paraphrases of different senses are considered as equivalent and can be mapped during evaluation.", "labels": [], "entities": []}, {"text": "To avoid erroneous matches between text segments, it is thus important to restrict the available word and phrase variants to the ones that are correct in a specific context.", "labels": [], "entities": []}, {"text": "Context-based synonym selection is the main idea behind the Meteor-WSD metric submitted to the WMT15 Metrics Shared Task.", "labels": [], "entities": [{"text": "Context-based synonym selection", "start_pos": 0, "end_pos": 31, "type": "TASK", "confidence": 0.7448370059331259}, {"text": "WMT15 Metrics Shared Task", "start_pos": 95, "end_pos": 120, "type": "TASK", "confidence": 0.6767617762088776}]}, {"text": "The mechanism used for sense selection is described in detail in the next section where we also present the results obtained by the Meteor-WSD metric on the WMT14 evaluation dataset.", "labels": [], "entities": [{"text": "sense selection", "start_pos": 23, "end_pos": 38, "type": "TASK", "confidence": 0.8590894639492035}, {"text": "WMT14 evaluation dataset", "start_pos": 157, "end_pos": 181, "type": "DATASET", "confidence": 0.9433523416519165}]}, {"text": "Section 3 presents the RATATOUILLE metric which integrates Meteor-WSD together with nine other evaluation metrics.", "labels": [], "entities": [{"text": "RATATOUILLE metric", "start_pos": 23, "end_pos": 41, "type": "METRIC", "confidence": 0.8912042677402496}, {"text": "Meteor-WSD", "start_pos": 59, "end_pos": 69, "type": "DATASET", "confidence": 0.8713083267211914}]}, {"text": "We report results in all language pairs and directions of the WMT14 dataset, except for hi-en.", "labels": [], "entities": [{"text": "WMT14 dataset", "start_pos": 62, "end_pos": 75, "type": "DATASET", "confidence": 0.9662489891052246}]}, {"text": "2 Meteor-WSD 2.1 Context-dependent sense selection A first attempt to integrate context-based sense selection in Meteor is described in.", "labels": [], "entities": [{"text": "Meteor-WSD 2.1 Context-dependent sense selection", "start_pos": 2, "end_pos": 50, "type": "TASK", "confidence": 0.5075833439826966}]}, {"text": "Word sense disambiguation (WSD) was performed using the Babelfy tool () which relies on the multilingual resource BabelNet (.", "labels": [], "entities": [{"text": "Word sense disambiguation (WSD)", "start_pos": 0, "end_pos": 31, "type": "TASK", "confidence": 0.8076716810464859}]}, {"text": "BabelNet is a wide coverage semantic network where senses are described by synsets (synonym and paraphrase sets) containing lexicographic and encyclopedic knowledge extracted from various sources in many languages and are linked between them by different types of relations.", "labels": [], "entities": []}, {"text": "Depending on the language, the lexical and phrase variants available in the synsets come from different sources such as WordNet, Wikipedia, Wiktionary, OmegaWiki as well as Machine Translation output.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 120, "end_pos": 127, "type": "DATASET", "confidence": 0.9298905730247498}, {"text": "Machine Translation", "start_pos": 173, "end_pos": 192, "type": "TASK", "confidence": 0.7807035446166992}]}, {"text": "The Babelfy tool jointly performs WSD and Entity Linking by exploiting BabelNet's graph structure and se-lects multilingual BabelNet synsets that correctly describe the semantics of words in context.", "labels": [], "entities": [{"text": "WSD", "start_pos": 34, "end_pos": 37, "type": "TASK", "confidence": 0.9171745777130127}, {"text": "Entity Linking", "start_pos": 42, "end_pos": 56, "type": "TASK", "confidence": 0.7040975838899612}]}, {"text": "In, Babelfy assigned BabelNet synsets to words in the English references of the WMT14 dataset.", "labels": [], "entities": [{"text": "WMT14 dataset", "start_pos": 80, "end_pos": 93, "type": "DATASET", "confidence": 0.9807527959346771}]}, {"text": "The WordNet literals found in the synset selected for an English word served to filter the WordNet synonym set used by the basic Meteor configuration in order to keep only variants that were good in this specific context and discard the ones corresponding to other senses.", "labels": [], "entities": [{"text": "WordNet synonym set", "start_pos": 91, "end_pos": 110, "type": "DATASET", "confidence": 0.8624163468678793}]}, {"text": "The reported MT evaluation results showed the beneficial impact of disambiguation which improved the correlation of the metric to human judgments from almost all languages involved in the WMT14 evaluation into English (except for Czech-English).", "labels": [], "entities": [{"text": "MT", "start_pos": 13, "end_pos": 15, "type": "TASK", "confidence": 0.9370185732841492}, {"text": "WMT14 evaluation", "start_pos": 188, "end_pos": 204, "type": "DATASET", "confidence": 0.773686558008194}]}, {"text": "Naturally, performance strongly depends on the quality of the WSD annotations.", "labels": [], "entities": [{"text": "WSD annotations", "start_pos": 62, "end_pos": 77, "type": "TASK", "confidence": 0.5614433586597443}]}, {"text": "In this work, we use a recent version of the alignment-based WSD method proposed by Apidianaki and Gong (2015) which gives better disambiguation results than Babelfy on the WMT14 data.", "labels": [], "entities": [{"text": "WSD", "start_pos": 61, "end_pos": 64, "type": "TASK", "confidence": 0.778313398361206}, {"text": "WMT14 data", "start_pos": 173, "end_pos": 183, "type": "DATASET", "confidence": 0.9625402987003326}]}, {"text": "Disambiguation is now applied to references of all languages in the data, not only in English.", "labels": [], "entities": [{"text": "Disambiguation", "start_pos": 0, "end_pos": 14, "type": "METRIC", "confidence": 0.6783910393714905}]}, {"text": "The WSD method used in our experiments still relies on alignments but implements a mechanism that improves WSD in languages other than English compared to the previous version.", "labels": [], "entities": [{"text": "WSD", "start_pos": 4, "end_pos": 7, "type": "TASK", "confidence": 0.8645222187042236}, {"text": "WSD", "start_pos": 107, "end_pos": 110, "type": "TASK", "confidence": 0.8929311037063599}]}, {"text": "More precisely, showed that the problematic sorting performed by the default BabelNet sense ranking mechanism in languages other than English has a strong negative impact on WSD.", "labels": [], "entities": [{"text": "WSD", "start_pos": 174, "end_pos": 177, "type": "TASK", "confidence": 0.8396491408348083}]}, {"text": "In our experiments, we implement an alternative solution that eliminates the need for sense ranking.", "labels": [], "entities": [{"text": "sense ranking", "start_pos": 86, "end_pos": 99, "type": "TASK", "confidence": 0.7406832575798035}]}, {"text": "Furthermore, the currently used version integrates a multiword expression (MWE) identification step prior to disambiguation.", "labels": [], "entities": [{"text": "multiword expression (MWE) identification", "start_pos": 53, "end_pos": 94, "type": "TASK", "confidence": 0.6292401701211929}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Segment-level Kendall's \u03c4 correlations of Meteor-WSD and the official WMT14 human judg- ments.", "labels": [], "entities": [{"text": "Segment-level Kendall's \u03c4 correlations", "start_pos": 10, "end_pos": 48, "type": "METRIC", "confidence": 0.6166971087455749}, {"text": "WMT14 human judg- ments", "start_pos": 80, "end_pos": 103, "type": "DATASET", "confidence": 0.8124286532402039}]}, {"text": " Table 2: System-level Pearson's coefficient correlations of Meteor-WSD and the official WMT14 human  judgments.", "labels": [], "entities": [{"text": "Pearson's coefficient correlations", "start_pos": 23, "end_pos": 57, "type": "METRIC", "confidence": 0.7237124741077423}, {"text": "Meteor-WSD", "start_pos": 61, "end_pos": 71, "type": "DATASET", "confidence": 0.789570152759552}, {"text": "WMT14 human  judgments", "start_pos": 89, "end_pos": 111, "type": "DATASET", "confidence": 0.7778457601865133}]}, {"text": " Table 3: Segment-level Kendall's \u03c4 correlations of RATATOUILLE and the official WMT14 human judg- ments using all WMT13 human judgments (all) or only all the translation pairs containing translations  separated by at least 3 ranks (>=3).", "labels": [], "entities": [{"text": "RATATOUILLE", "start_pos": 52, "end_pos": 63, "type": "DATASET", "confidence": 0.5341012477874756}, {"text": "WMT14 human judg- ments", "start_pos": 81, "end_pos": 104, "type": "DATASET", "confidence": 0.8975152850151062}, {"text": "WMT13 human judgments", "start_pos": 115, "end_pos": 136, "type": "DATASET", "confidence": 0.8585142890612284}]}, {"text": " Table 4: Segment-level Kendall's \u03c4 correlations of RATATOUILLE and the official WMT14 human judg- ments.", "labels": [], "entities": [{"text": "Segment-level Kendall's \u03c4 correlations", "start_pos": 10, "end_pos": 48, "type": "METRIC", "confidence": 0.6057458341121673}, {"text": "RATATOUILLE", "start_pos": 52, "end_pos": 63, "type": "METRIC", "confidence": 0.623283326625824}, {"text": "WMT14 human judg- ments", "start_pos": 81, "end_pos": 104, "type": "DATASET", "confidence": 0.8739055275917054}]}, {"text": " Table 5: System-level Pearson's coefficient correlations of RATATOUILLE and the official WMT14 hu- man judgments.", "labels": [], "entities": [{"text": "Pearson's coefficient correlations", "start_pos": 23, "end_pos": 57, "type": "METRIC", "confidence": 0.7371083796024323}, {"text": "RATATOUILLE", "start_pos": 61, "end_pos": 72, "type": "METRIC", "confidence": 0.5178624987602234}, {"text": "WMT14 hu- man judgments", "start_pos": 90, "end_pos": 113, "type": "DATASET", "confidence": 0.8821753978729248}]}]}