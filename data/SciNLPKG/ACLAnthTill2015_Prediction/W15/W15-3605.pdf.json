{"title": [{"text": "Reducing Over-generation Errors for Automatic Keyphrase Extraction using Integer Linear Programming", "labels": [], "entities": [{"text": "Keyphrase Extraction", "start_pos": 46, "end_pos": 66, "type": "TASK", "confidence": 0.7029923647642136}]}], "abstractContent": [{"text": "We introduce a global inference model for keyphrase extraction that reduces over-generation errors by weighting sets of keyphrase candidates according to their component words.", "labels": [], "entities": [{"text": "keyphrase extraction", "start_pos": 42, "end_pos": 62, "type": "TASK", "confidence": 0.8584436178207397}]}, {"text": "Our model can be applied on top of any supervised or unsuper-vised word weighting function.", "labels": [], "entities": []}, {"text": "Experimental results show a substantial improvement over commonly used word-based ranking approaches.", "labels": [], "entities": []}], "introductionContent": [{"text": "Keyphrases are words or phrases that capture the main topics discussed in a document.", "labels": [], "entities": []}, {"text": "Automatically extracted keyphrases have been found to be useful for many natural language processing and information retrieval tasks, such as summarization (, opinion mining or text categorization ().", "labels": [], "entities": [{"text": "natural language processing and information retrieval", "start_pos": 73, "end_pos": 126, "type": "TASK", "confidence": 0.6283294856548309}, {"text": "summarization", "start_pos": 142, "end_pos": 155, "type": "TASK", "confidence": 0.9903035759925842}, {"text": "opinion mining", "start_pos": 159, "end_pos": 173, "type": "TASK", "confidence": 0.7766611576080322}, {"text": "text categorization", "start_pos": 177, "end_pos": 196, "type": "TASK", "confidence": 0.7619486153125763}]}, {"text": "Despite considerable research effort, the automatic extraction of keyphrases that match those of human experts remains challenging.", "labels": [], "entities": [{"text": "automatic extraction of keyphrases", "start_pos": 42, "end_pos": 76, "type": "TASK", "confidence": 0.7665794268250465}]}, {"text": "Recent work has shown that most errors made by state-of-the-art keyphrase extraction systems are due to over-generation.", "labels": [], "entities": [{"text": "keyphrase extraction", "start_pos": 64, "end_pos": 84, "type": "TASK", "confidence": 0.804363876581192}]}, {"text": "Over-generation errors occur when a system correctly outputs a keyphrase because it contains an important word, but at the same time erroneously predicts other keyphrase candidates as keyphrases because they contain the same word.", "labels": [], "entities": []}, {"text": "One reason these errors are frequent is that many unsupervised systems rank candidates according to the weights of their component words, e.g. (;, and many supervised systems use unigrams as features, e.g..", "labels": [], "entities": []}, {"text": "While weighting words instead of phrases may seem rather blunt, it offers several advantages.", "labels": [], "entities": []}, {"text": "In practice, words are usually much easier to extract, match and weight, especially for short documents where many phrases may not be statistically frequent ().", "labels": [], "entities": []}, {"text": "Selecting keyphrase candidates according to their component words may also turnout to be useful for reducing over-generation errors if one can ensure that the importance of each word is counted only once in the set of extracted keyphrases.", "labels": [], "entities": []}, {"text": "To do so, keyphrases should be extracted as a set rather than independently.", "labels": [], "entities": []}, {"text": "Finding the optimal set of keyphrases is a combinatorial optimisation problem, and can be formulated as an integer linear program (ILP) which can be solved exactly using off-the-shelf solvers.", "labels": [], "entities": []}, {"text": "In this work, we propose an ILP formulation for keyphrase extraction that can be applied on top of any word weighting scheme.", "labels": [], "entities": [{"text": "keyphrase extraction", "start_pos": 48, "end_pos": 68, "type": "TASK", "confidence": 0.8357684910297394}]}, {"text": "Through experiments carried out on the SemEval dataset (, we show that our model increases the performance of both supervised and unsupervised word weighting keyphrase extraction methods.", "labels": [], "entities": [{"text": "SemEval dataset", "start_pos": 39, "end_pos": 54, "type": "DATASET", "confidence": 0.7284888625144958}, {"text": "word weighting keyphrase extraction", "start_pos": 143, "end_pos": 178, "type": "TASK", "confidence": 0.8299754410982132}]}, {"text": "The rest of this paper is organized as follows.", "labels": [], "entities": []}, {"text": "In Section 2, we describe our ILP model for keyphrase extraction.", "labels": [], "entities": [{"text": "keyphrase extraction", "start_pos": 44, "end_pos": 64, "type": "TASK", "confidence": 0.8670659959316254}]}, {"text": "Our experiments are presented in Section 3.", "labels": [], "entities": []}, {"text": "In Section 4, we briefly review the previous work, and we conclude in Section 5.", "labels": [], "entities": []}], "datasetContent": [{"text": "We carryout our experiments on the SemEval dataset (, which is composed of scientific articles collected from the ACM Digital Library.", "labels": [], "entities": [{"text": "SemEval dataset", "start_pos": 35, "end_pos": 50, "type": "DATASET", "confidence": 0.7826876044273376}, {"text": "ACM Digital Library", "start_pos": 114, "end_pos": 133, "type": "DATASET", "confidence": 0.9621337652206421}]}, {"text": "The dataset is divided into training (144 documents) and test (100 documents) sets.", "labels": [], "entities": []}, {"text": "We use the set of combined author-and reader-assigned keyphrases as reference keyphrases.", "labels": [], "entities": []}, {"text": "We follow the common practice ( and evaluate the performance of our method in terms of precision (P), recall (R) and f-measure (F) at the top N keyphrases 9 . Extracted and reference keyphrases are stemmed to reduce the number of mismatches.", "labels": [], "entities": [{"text": "precision (P)", "start_pos": 87, "end_pos": 100, "type": "METRIC", "confidence": 0.9365031570196152}, {"text": "recall (R)", "start_pos": 102, "end_pos": 112, "type": "METRIC", "confidence": 0.9534174054861069}, {"text": "f-measure (F)", "start_pos": 117, "end_pos": 130, "type": "METRIC", "confidence": 0.9092437475919724}]}, {"text": "For each word weighting function, namely TF\u00d7IDF, TextRank and Logistic regression, we compare the performance of our ILP model (hereafter ilp) with that of two word-based weighting baselines.", "labels": [], "entities": []}, {"text": "The first baseline (hereafter sum) simply ranks keyphrase candidates according to the sum of the weights of their component words as in).", "labels": [], "entities": []}, {"text": "The second baseline (hereafter norm) consists in scoring keyphrase candidates by computing the sum of the weights of their component words normalized by their length as in.", "labels": [], "entities": []}, {"text": "As a post-processing step, we remove redundant keyphrases from the ranked lists generated by both baselines.", "labels": [], "entities": []}, {"text": "A keyphrase is considered redundant if it is included in another keyphrase that is ranked higher in the list.", "labels": [], "entities": []}, {"text": "IDF weights are computed on the training set.", "labels": [], "entities": []}, {"text": "The regularization parameter \u03bb is set, for all the experiments, to the value that achieves the best performance on the training set, that is 0.3 for TF\u00d7IDF, 0.4 for TextRank and 1.2 for Logistic regression.", "labels": [], "entities": [{"text": "TextRank", "start_pos": 165, "end_pos": 173, "type": "DATASET", "confidence": 0.8666479587554932}]}], "tableCaptions": [{"text": " Table 1: Comparison of TF\u00d7IDF, TextRank and Logistic regression for different ranking strategies when  extracting a maximum of 5 and 10 keyphrases. Results are expressed as a percentage of precision (P),  recall (R) and f-measure (F).  \u2020 indicates significance at the 0.05 level using Student's t-test.", "labels": [], "entities": [{"text": "precision (P)", "start_pos": 190, "end_pos": 203, "type": "METRIC", "confidence": 0.9540938287973404}, {"text": "recall (R)", "start_pos": 206, "end_pos": 216, "type": "METRIC", "confidence": 0.9508097618818283}, {"text": "f-measure (F)", "start_pos": 221, "end_pos": 234, "type": "METRIC", "confidence": 0.8602953255176544}]}]}