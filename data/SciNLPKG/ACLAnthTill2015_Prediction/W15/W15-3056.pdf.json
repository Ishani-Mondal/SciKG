{"title": [{"text": "Improving evaluation and optimization of MT systems against MEANT", "labels": [], "entities": [{"text": "Improving evaluation", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.8770430684089661}, {"text": "MT", "start_pos": 41, "end_pos": 43, "type": "TASK", "confidence": 0.9793563485145569}, {"text": "MEANT", "start_pos": 60, "end_pos": 65, "type": "TASK", "confidence": 0.7273834943771362}]}], "abstractContent": [{"text": "We show that, consistent with MEANT-tuned systems that translate into Chinese, MEANT-tuned MT systems that translate into English also outperforms BLEU-tuned systems across commonly used MT evaluation metrics, even in BLEU.", "labels": [], "entities": [{"text": "MT", "start_pos": 91, "end_pos": 93, "type": "TASK", "confidence": 0.8519829511642456}, {"text": "BLEU-tuned", "start_pos": 147, "end_pos": 157, "type": "METRIC", "confidence": 0.9913290739059448}, {"text": "MT evaluation", "start_pos": 187, "end_pos": 200, "type": "TASK", "confidence": 0.9055047631263733}, {"text": "BLEU", "start_pos": 218, "end_pos": 222, "type": "METRIC", "confidence": 0.8716509938240051}]}, {"text": "The result is achieved by significantly improving MEANT's sentence-level ranking correlation with human preferences through incorporating a more accurate distribu-tional semantic model for lexical similarity and a novel backoff algorithm for evaluating MT output which automatic semantic parser fails to parse.", "labels": [], "entities": [{"text": "MT output", "start_pos": 253, "end_pos": 262, "type": "TASK", "confidence": 0.8947047889232635}]}, {"text": "The surprising result of MEANT-tuned systems having a higher BLEU score than BLEU-tuned systems suggests that MEANT is a more accurate objective function guiding the development of MT systems towards producing more adequate translation.", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 61, "end_pos": 71, "type": "METRIC", "confidence": 0.9858136475086212}, {"text": "BLEU-tuned", "start_pos": 77, "end_pos": 87, "type": "METRIC", "confidence": 0.9920209050178528}, {"text": "MEANT", "start_pos": 110, "end_pos": 115, "type": "METRIC", "confidence": 0.9503579139709473}, {"text": "MT", "start_pos": 181, "end_pos": 183, "type": "TASK", "confidence": 0.9931557774543762}]}], "introductionContent": [{"text": "showed that MEANT-tuned system for translating into Chinese outperforms BLEU-tuned system across commonly used MT evaluation metrics, even in BLEU.", "labels": [], "entities": [{"text": "MEANT-tuned", "start_pos": 12, "end_pos": 23, "type": "METRIC", "confidence": 0.9738796949386597}, {"text": "translating into Chinese", "start_pos": 35, "end_pos": 59, "type": "TASK", "confidence": 0.8664863705635071}, {"text": "BLEU-tuned", "start_pos": 72, "end_pos": 82, "type": "METRIC", "confidence": 0.9937040209770203}, {"text": "MT evaluation", "start_pos": 111, "end_pos": 124, "type": "TASK", "confidence": 0.8979312479496002}, {"text": "BLEU", "start_pos": 142, "end_pos": 146, "type": "METRIC", "confidence": 0.9078737497329712}]}, {"text": "However, such phenomena are not observed in MEANT-tuned system for translating into English.", "labels": [], "entities": [{"text": "MEANT-tuned", "start_pos": 44, "end_pos": 55, "type": "METRIC", "confidence": 0.44748908281326294}, {"text": "translating into English", "start_pos": 67, "end_pos": 91, "type": "TASK", "confidence": 0.8691582282384237}]}, {"text": "In this paper, for the first time, we present MT systems for translating into English, which is tuned to a improved version of MEANT, also outperforms BLEU-tuned system across commonly used MT evaluation metrics, even in BLEU.", "labels": [], "entities": [{"text": "MT", "start_pos": 46, "end_pos": 48, "type": "TASK", "confidence": 0.9883536100387573}, {"text": "translating into English", "start_pos": 61, "end_pos": 85, "type": "TASK", "confidence": 0.8784239093462626}, {"text": "MEANT", "start_pos": 127, "end_pos": 132, "type": "METRIC", "confidence": 0.9543448090553284}, {"text": "BLEU-tuned", "start_pos": 151, "end_pos": 161, "type": "METRIC", "confidence": 0.9970152378082275}, {"text": "MT evaluation", "start_pos": 190, "end_pos": 203, "type": "TASK", "confidence": 0.8999497890472412}, {"text": "BLEU", "start_pos": 221, "end_pos": 225, "type": "METRIC", "confidence": 0.9650322198867798}]}, {"text": "The improvements in MEANT include incorporating more accurate distributional semantic model for lexical similarity and a novel backoff algorithm for evaluating MT output which the automatic semantic parser failed to parse.", "labels": [], "entities": [{"text": "MEANT", "start_pos": 20, "end_pos": 25, "type": "METRIC", "confidence": 0.7058713436126709}, {"text": "MT output", "start_pos": 160, "end_pos": 169, "type": "TASK", "confidence": 0.8726324737071991}]}, {"text": "Empirical results show that * This work was completed at HKUST.", "labels": [], "entities": [{"text": "HKUST", "start_pos": 57, "end_pos": 62, "type": "DATASET", "confidence": 0.981145977973938}]}, {"text": "the new version of MEANT is significantly improved in terms of sentence-level ranking correlation with human preferences.", "labels": [], "entities": [{"text": "MEANT", "start_pos": 19, "end_pos": 24, "type": "METRIC", "confidence": 0.8121544122695923}]}, {"text": "The accuracy of MEANT relies heavily on the accuracy of the model that determines the lexical similarities of the semantic role fillers.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.9985753297805786}, {"text": "MEANT", "start_pos": 16, "end_pos": 21, "type": "METRIC", "confidence": 0.5686624050140381}, {"text": "accuracy", "start_pos": 44, "end_pos": 52, "type": "METRIC", "confidence": 0.9986171722412109}]}, {"text": "However, the discrete context vector model based on the raw co-occurrence counts used in the original proposal of MEANT does notwork well in predicting the similarity of the lexicons used in the reference and machine translations.", "labels": [], "entities": [{"text": "MEANT", "start_pos": 114, "end_pos": 119, "type": "DATASET", "confidence": 0.4957456886768341}]}, {"text": "Recent work by shows that word embeddings trained by predict models outperforms the count based models in various lexical semantic tasks.", "labels": [], "entities": []}, {"text": "argues that predict models such as word2vec outperform count based models on a wide range of lexical semantic tasks.", "labels": [], "entities": []}, {"text": "It is also common knowledge that raw co-occurrence counts do notwork very well and performance can be improved when transformed by reweighing the counts for context informativeness and dimensionality reduction.", "labels": [], "entities": []}, {"text": "In contrast to conventional word vector models, prediction based word vector models estimate the vectors directly as a supervised task, where the weights in a word vector are set to maximize the probability of the contexts in which the word is observed in the corpus (.", "labels": [], "entities": []}, {"text": "In this paper, we show that MEANT's correlation with human adequacy judgments can be further improved by incorporating the word embeddings trained by the predict models.", "labels": [], "entities": [{"text": "MEANT", "start_pos": 28, "end_pos": 33, "type": "METRIC", "confidence": 0.8595957159996033}]}, {"text": "Subsequently, tuning MT system against the improved version of MEANT produce more adequate translations than tuning against BLEU.", "labels": [], "entities": [{"text": "MT", "start_pos": 21, "end_pos": 23, "type": "TASK", "confidence": 0.890302300453186}, {"text": "MEANT", "start_pos": 63, "end_pos": 68, "type": "METRIC", "confidence": 0.835790753364563}, {"text": "BLEU", "start_pos": 124, "end_pos": 128, "type": "METRIC", "confidence": 0.9878296852111816}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: System-level Pearson's score correlation with human preferences of MEANT on WMT2014  metrics track test set", "labels": [], "entities": [{"text": "Pearson's score correlation", "start_pos": 23, "end_pos": 50, "type": "METRIC", "confidence": 0.8500989973545074}, {"text": "MEANT", "start_pos": 77, "end_pos": 82, "type": "METRIC", "confidence": 0.9122641086578369}, {"text": "WMT2014  metrics track test set", "start_pos": 86, "end_pos": 117, "type": "DATASET", "confidence": 0.9308131456375122}]}, {"text": " Table 2: Sentence-level Kendall's rank correlation with human preferences of MEANT on WMT2014  metrics track test set", "labels": [], "entities": [{"text": "Sentence-level Kendall's rank correlation", "start_pos": 10, "end_pos": 51, "type": "METRIC", "confidence": 0.6866186082363128}, {"text": "MEANT", "start_pos": 78, "end_pos": 83, "type": "METRIC", "confidence": 0.8674284219741821}, {"text": "WMT2014  metrics track test set", "start_pos": 87, "end_pos": 118, "type": "DATASET", "confidence": 0.9293376684188843}]}, {"text": " Table 3: Translation quality of MT system tuned against MEANT and BLEU on WMT15 tuning task  dev set. MEANT reported here is the version using Google pretrained word embeddings with \u03b1=1 and  backoff algorithm.", "labels": [], "entities": [{"text": "Translation", "start_pos": 10, "end_pos": 21, "type": "TASK", "confidence": 0.9576378464698792}, {"text": "MT", "start_pos": 33, "end_pos": 35, "type": "TASK", "confidence": 0.9707068800926208}, {"text": "MEANT", "start_pos": 57, "end_pos": 62, "type": "METRIC", "confidence": 0.9895724654197693}, {"text": "BLEU", "start_pos": 67, "end_pos": 71, "type": "METRIC", "confidence": 0.9984716773033142}, {"text": "WMT15 tuning task  dev set", "start_pos": 75, "end_pos": 101, "type": "DATASET", "confidence": 0.8752274870872497}, {"text": "MEANT", "start_pos": 103, "end_pos": 108, "type": "DATASET", "confidence": 0.4966360032558441}]}, {"text": " Table 4: Translation quality of MT system tuned against MEANT and BLEU on WMT15 tuning task  test set. MEANT reported here is the version using Google pretrained word embeddings with \u03b1=1 and  backoff algorithm.", "labels": [], "entities": [{"text": "Translation", "start_pos": 10, "end_pos": 21, "type": "TASK", "confidence": 0.9595131278038025}, {"text": "MT", "start_pos": 33, "end_pos": 35, "type": "TASK", "confidence": 0.9772629141807556}, {"text": "MEANT", "start_pos": 57, "end_pos": 62, "type": "METRIC", "confidence": 0.9901760220527649}, {"text": "BLEU", "start_pos": 67, "end_pos": 71, "type": "METRIC", "confidence": 0.9984667897224426}, {"text": "WMT15 tuning task  test set", "start_pos": 75, "end_pos": 102, "type": "DATASET", "confidence": 0.895393705368042}, {"text": "MEANT", "start_pos": 104, "end_pos": 109, "type": "DATASET", "confidence": 0.47965967655181885}]}]}