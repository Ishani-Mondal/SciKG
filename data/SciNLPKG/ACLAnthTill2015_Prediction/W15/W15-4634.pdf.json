{"title": [{"text": "AllSummarizer system at MultiLing 2015: Multilingual single and multi-document summarization", "labels": [], "entities": [{"text": "summarization", "start_pos": 79, "end_pos": 92, "type": "TASK", "confidence": 0.7024298310279846}]}], "abstractContent": [{"text": "In this paper, we evaluate our automatic text summarization system in multilingual context.", "labels": [], "entities": [{"text": "text summarization", "start_pos": 41, "end_pos": 59, "type": "TASK", "confidence": 0.6242351830005646}]}, {"text": "We participated in both single document and multi-document sum-marization tasks of MultiLing 2015 workshop.", "labels": [], "entities": []}, {"text": "Our method involves clustering the document sentences into topics using a fuzzy clustering algorithm.", "labels": [], "entities": []}, {"text": "Then each sentence is scored according to how well it covers the various topics.", "labels": [], "entities": []}, {"text": "This is done using statistical features such as TF, sentence length, etc.", "labels": [], "entities": [{"text": "TF", "start_pos": 48, "end_pos": 50, "type": "METRIC", "confidence": 0.9646340012550354}]}, {"text": "Finally, the summary is constructed from the highest scoring sentences , while avoiding overlap between the summary sentences.", "labels": [], "entities": []}, {"text": "This makes it language-independent, but we have to afford preprocessed data first (tokenization, stemming, etc.).", "labels": [], "entities": []}], "introductionContent": [{"text": "A document summary can be regarded as domainspecific or general-purpose, using the specificity as classification criterion.", "labels": [], "entities": []}, {"text": "We can, also, look at this criterion from language angle: language-specific or language-independent summarization.", "labels": [], "entities": []}, {"text": "Language-independent systems can handle more than one language.", "labels": [], "entities": []}, {"text": "They can be partially language-independent, which means they use language-related resources, and therefore you can't add anew language so easily.", "labels": [], "entities": []}, {"text": "Inversely, they can be fully language-independent.", "labels": [], "entities": []}, {"text": "Recently, multilingual summarization has received the attention of the summarization community, such as Text Analysis Conference (TAC).", "labels": [], "entities": [{"text": "summarization", "start_pos": 23, "end_pos": 36, "type": "TASK", "confidence": 0.6520256400108337}, {"text": "summarization", "start_pos": 71, "end_pos": 84, "type": "TASK", "confidence": 0.9675254225730896}, {"text": "Text Analysis Conference (TAC)", "start_pos": 104, "end_pos": 134, "type": "TASK", "confidence": 0.8555247286955515}]}, {"text": "The TAC 2011 workshop included a task called \"MultiLing task\", which aims to evaluate languageindependent summarization algorithms on a variety of languages ( ).", "labels": [], "entities": [{"text": "TAC 2011 workshop", "start_pos": 4, "end_pos": 21, "type": "DATASET", "confidence": 0.8914101918538412}, {"text": "languageindependent summarization", "start_pos": 86, "end_pos": 119, "type": "TASK", "confidence": 0.5042343586683273}]}, {"text": "In the task's pilot, there were seven languages covering news texts: Arabic, Czech, English, French, Greek, Hebrew and Hindi, where each system has to participate for at least two languages.", "labels": [], "entities": []}, {"text": "MultiLing 2013 workshop is a community-driven initiative for testing and promoting multilingual summarization methods.", "labels": [], "entities": [{"text": "MultiLing 2013 workshop", "start_pos": 0, "end_pos": 23, "type": "DATASET", "confidence": 0.6851610442002615}]}, {"text": "It aims to evaluate the application of (partially or fully) language-independent summarization algorithms on a variety of languages.", "labels": [], "entities": []}, {"text": "There were three tasks: \"Multi-document multilingual summarization\", \"Multilingual single document summarization\" () and \"Multilingual summary evaluation\".", "labels": [], "entities": [{"text": "Multi-document multilingual summarization", "start_pos": 25, "end_pos": 66, "type": "TASK", "confidence": 0.6410306493441263}, {"text": "Multilingual single document summarization", "start_pos": 70, "end_pos": 112, "type": "TASK", "confidence": 0.6216907575726509}, {"text": "Multilingual summary evaluation", "start_pos": 122, "end_pos": 153, "type": "TASK", "confidence": 0.6843135952949524}]}, {"text": "The multi-document task uses the 7 past languages along with three new languages: Chinese, Romanian and Spanish.", "labels": [], "entities": []}, {"text": "The single document task introduces 40 languages.", "labels": [], "entities": []}, {"text": "This paper contains a description of our method () which uses sentences' clustering to define topics, and then trains on these topics to score each sentence.", "labels": [], "entities": []}, {"text": "We will explain each task in the system (AllSummarizer), especially the preprocessing task which is languagedependent.", "labels": [], "entities": []}, {"text": "Then, we will discuss how we fixed the summarization's hyper-parameters (threshold and features) for each language.", "labels": [], "entities": []}, {"text": "The next section (Section 5) is reserved to discuss the experiments conducted in the MultiLing workshop.", "labels": [], "entities": []}, {"text": "Finally, we will conclude by discussing possible improvements.", "labels": [], "entities": []}], "datasetContent": [{"text": "We participated in all workshop's languages, either in single document or multi-document tasks.", "labels": [], "entities": []}, {"text": "To compare our system to others participated systems, we followed these steps (for every evaluation metric): \u2022 For each system, calculate the average scores of all used languages.", "labels": [], "entities": []}, {"text": "\u2022 For our system, calculate the average scores of used languages by others.", "labels": [], "entities": []}, {"text": "For example, BGU-SCE-M team uses Arabic, English and Hebrew; We calculate the average of scores of these languages for this system and ours.", "labels": [], "entities": [{"text": "BGU-SCE-M", "start_pos": 13, "end_pos": 22, "type": "DATASET", "confidence": 0.4825754463672638}]}, {"text": "\u2022 Then, we calculate the relative improvement using the averages oursystem\u2212othersystem othersystem .  In \"Single document summarization\" task, ROUGE (Recall-Oriented Understudy for Gisting Evaluation)) is used to evaluate the participated systems.", "labels": [], "entities": [{"text": "ROUGE", "start_pos": 143, "end_pos": 148, "type": "METRIC", "confidence": 0.9956018924713135}]}, {"text": "It allows us to evaluate automatic text summaries against human made abstracts.", "labels": [], "entities": [{"text": "text summaries", "start_pos": 35, "end_pos": 49, "type": "TASK", "confidence": 0.6206012666225433}]}, {"text": "The principle of this method is to compare N-grams of two summaries based on the number of matches between these two based on the recall measure.", "labels": [], "entities": [{"text": "recall measure", "start_pos": 130, "end_pos": 144, "type": "METRIC", "confidence": 0.974072128534317}]}, {"text": "Five metrics are used: ROUGE-1, ROUGE-2, ROUGE-3, ROUGE-4 and ROUGE-SU4.", "labels": [], "entities": [{"text": "ROUGE-1", "start_pos": 23, "end_pos": 30, "type": "METRIC", "confidence": 0.9865929484367371}, {"text": "ROUGE-2", "start_pos": 32, "end_pos": 39, "type": "METRIC", "confidence": 0.9570490717887878}, {"text": "ROUGE-3", "start_pos": 41, "end_pos": 48, "type": "METRIC", "confidence": 0.9577747583389282}, {"text": "ROUGE-4", "start_pos": 50, "end_pos": 57, "type": "METRIC", "confidence": 0.965386688709259}, {"text": "ROUGE-SU4", "start_pos": 62, "end_pos": 71, "type": "METRIC", "confidence": 0.8316253423690796}]}, {"text": "In \"Multi-document summarization\" task, Three metrics are officially used: AutoSummENG,) and NPowER (.", "labels": [], "entities": [{"text": "Multi-document summarization\" task", "start_pos": 4, "end_pos": 38, "type": "TASK", "confidence": 0.778442770242691}, {"text": "NPowER", "start_pos": 93, "end_pos": 99, "type": "DATASET", "confidence": 0.6124240159988403}]}], "tableCaptions": []}