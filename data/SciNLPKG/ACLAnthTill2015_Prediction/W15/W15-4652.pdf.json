{"title": [{"text": "Incremental Coordination: Attention-Centric Speech Production in a Physically Situated Conversational Agent", "labels": [], "entities": [{"text": "Incremental Coordination", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.8322615921497345}]}], "abstractContent": [{"text": "Inspired by studies of human-human conversations , we present methods for incre-mentally coordinating speech production with listeners' visual foci of attention.", "labels": [], "entities": []}, {"text": "We introduce a model that considers the demands and availability of listeners' attention at the onset and throughout the production of system utterances, and that in-crementally coordinates speech synthesis with the listener's gaze.", "labels": [], "entities": [{"text": "speech synthesis", "start_pos": 190, "end_pos": 206, "type": "TASK", "confidence": 0.7595255374908447}]}, {"text": "We present an implementation and deployment of the model in a physically situated dialog system and discuss lessons learned.", "labels": [], "entities": []}], "introductionContent": [{"text": "Participants in a conversation coordinate with one another on producing turns, and often co-produce language by using verbal and non-verbal signals, including gaze, gestures, prosody and grammatical structures.", "labels": [], "entities": []}, {"text": "Among these signals, patterns of attention play an important role.", "labels": [], "entities": []}, {"text": "highlights a variety of coordination mechanisms that speakers use to achieve mutual orientation at the beginning and throughout turns, such as pausing, adding phrasal breaks, lengthening spoken units, and even changing the structure of the sentence on the fly to secure the listener's attention.", "labels": [], "entities": []}, {"text": "His work suggests that, beyond a simple errors-in-production view, \"disfluencies\" help to coordinate on turns, and generally facilitate co-production among speakers and listeners.", "labels": [], "entities": []}, {"text": "presents sample snippets of conversations recorded in the wild, annotated to show when the gaze of a listener turns to meet Research conducted during an internship at Microsoft Research the gaze of the speaker (marked with *) and when mutual gaze is maintained (marked with an underline).", "labels": [], "entities": []}, {"text": "We investigate this direction and introduce a model that incrementally coordinates language production and speech synthesis with the listeners' foci of attention.", "labels": [], "entities": [{"text": "speech synthesis", "start_pos": 107, "end_pos": 123, "type": "TASK", "confidence": 0.7457819581031799}]}, {"text": "The model centers on computing whether the listener's attention matches a set of attentional demands for the utterance at hand.", "labels": [], "entities": []}, {"text": "When attentional demands are not met, the model triggers a sequence of linguistic devices in an attempt to recover the listener's attention and to coordinate the system's speech with it.", "labels": [], "entities": []}, {"text": "We introduce and demonstrate the promise of incremental coordination of language production with attention in situated systems.", "labels": [], "entities": []}, {"text": "Following a brief review of related work, we describe the proposed approach in more detail in Section 3.", "labels": [], "entities": []}, {"text": "In Section 4, we discuss lessons learned from an in-the-wild deployment of this approach in a directions-giving robot.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": []}