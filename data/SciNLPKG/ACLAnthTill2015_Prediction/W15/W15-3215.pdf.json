{"title": [{"text": "CUFE@QALB-2015 Shared Task: Arabic Error Correction System", "labels": [], "entities": []}], "abstractContent": [{"text": "In this paper we describe the implementation of an Arabic error correction system developed for the WANLP-2015 shared task on automatic error correction for Arabic text.", "labels": [], "entities": [{"text": "Arabic error correction", "start_pos": 51, "end_pos": 74, "type": "TASK", "confidence": 0.5489625533421835}, {"text": "WANLP-2015 shared task on automatic error correction for Arabic text", "start_pos": 100, "end_pos": 168, "type": "TASK", "confidence": 0.6608832657337189}]}, {"text": "We proposed improvements to a previous statistical rule based system, where we use the words patterns to improve the error correction , also we have used a statistical system the syntactic error correction rules.", "labels": [], "entities": [{"text": "syntactic error correction", "start_pos": 179, "end_pos": 205, "type": "TASK", "confidence": 0.6111730535825094}]}, {"text": "The system achieves an F-score of 0.7287 on the Alj-test-2015 dataset, and an F-score of 0.3569 on the L2-test-2015 dataset.", "labels": [], "entities": [{"text": "F-score", "start_pos": 23, "end_pos": 30, "type": "METRIC", "confidence": 0.9995131492614746}, {"text": "Alj-test-2015 dataset", "start_pos": 48, "end_pos": 69, "type": "DATASET", "confidence": 0.9892555773258209}, {"text": "F-score", "start_pos": 78, "end_pos": 85, "type": "METRIC", "confidence": 0.999308705329895}, {"text": "L2-test-2015 dataset", "start_pos": 103, "end_pos": 123, "type": "DATASET", "confidence": 0.8393940925598145}]}], "introductionContent": [{"text": "This paper presents improvements to a previously developed rule-based probabilistic system).", "labels": [], "entities": []}, {"text": "We first make use of a unique Arabic feature, which is the word pattern to extract more rules for the system.", "labels": [], "entities": []}, {"text": "Also, we have proposed a probabilistic Arabic grammar analyzer instead of a simple rule-based one proposed in the previous work.", "labels": [], "entities": [{"text": "Arabic grammar analyzer", "start_pos": 39, "end_pos": 62, "type": "TASK", "confidence": 0.5795585612456003}]}, {"text": "This shared task was on automatic Arabic text correction.", "labels": [], "entities": [{"text": "automatic Arabic text correction", "start_pos": 24, "end_pos": 56, "type": "TASK", "confidence": 0.5344753190875053}]}, {"text": "For this task, the Qatar Arabic Language Bank (QALB) corpus ) was provided.", "labels": [], "entities": [{"text": "Qatar Arabic Language Bank (QALB) corpus", "start_pos": 19, "end_pos": 59, "type": "DATASET", "confidence": 0.9171206951141357}]}, {"text": "It is an extension of the first QALB shared task ) that took place last year.", "labels": [], "entities": [{"text": "QALB shared task", "start_pos": 32, "end_pos": 48, "type": "TASK", "confidence": 0.5711637934048971}]}, {"text": "QALB-2014 addressed errors in comments written to Aljazeera articles by native Arabic speakers ( ).", "labels": [], "entities": [{"text": "QALB-2014", "start_pos": 0, "end_pos": 9, "type": "DATASET", "confidence": 0.9156782627105713}]}, {"text": "This year's competition includes two tracks, and, in addition to errors produced by native speakers, also includes correction of texts written by learners of Arabic as a foreign language (L2)).", "labels": [], "entities": []}, {"text": "The native track includes texts from QALB-2014.", "labels": [], "entities": [{"text": "QALB-2014", "start_pos": 37, "end_pos": 46, "type": "DATASET", "confidence": 0.9378969073295593}]}, {"text": "This data was released for the development of the systems.", "labels": [], "entities": []}, {"text": "The systems were scored on blind test sets.", "labels": [], "entities": []}, {"text": "The proposed framework could be described as a probabilistic rule-based framework.", "labels": [], "entities": []}, {"text": "During the training of this framework, we extracted error correction rules and compute a probability to each rule as shown later in section 3.", "labels": [], "entities": []}, {"text": "The extracted rules are then sorted based on their probabilities.", "labels": [], "entities": []}, {"text": "And during the test, we apply the rules from the highest probability to the lowest probability one by one, on the entire test data till a stopping criteria is satisfied.", "labels": [], "entities": []}, {"text": "During the algorithm we have some kind of heuristic to estimate the F-score after each rule is apply.", "labels": [], "entities": [{"text": "F-score", "start_pos": 68, "end_pos": 75, "type": "METRIC", "confidence": 0.9968230724334717}]}, {"text": "The stopping criteria for the algorithm is that the estimated Fscore start to decrease.", "labels": [], "entities": [{"text": "stopping", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.9542272686958313}, {"text": "Fscore", "start_pos": 62, "end_pos": 68, "type": "METRIC", "confidence": 0.997253954410553}]}, {"text": "This paper is organized as follow, in section 2, an overview of the related work in the field of error correction is discussed.", "labels": [], "entities": [{"text": "error correction", "start_pos": 97, "end_pos": 113, "type": "TASK", "confidence": 0.820390522480011}]}, {"text": "In section 3, the proposed system and its main components are explained.", "labels": [], "entities": []}, {"text": "The improvements in the correction rules are discussed in section 4.", "labels": [], "entities": [{"text": "correction", "start_pos": 24, "end_pos": 34, "type": "TASK", "confidence": 0.7794890403747559}]}, {"text": "The evaluation process is presented in section 5.", "labels": [], "entities": []}, {"text": "Finally, concluding remarks and future work are presented in section 6.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Examples of Correction Rules Precisions", "labels": [], "entities": [{"text": "Precisions", "start_pos": 39, "end_pos": 49, "type": "TASK", "confidence": 0.44109824299812317}]}]}