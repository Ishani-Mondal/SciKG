{"title": [{"text": "Improving Event Detection with Abstract Meaning Representation", "labels": [], "entities": [{"text": "Improving Event Detection", "start_pos": 0, "end_pos": 25, "type": "TASK", "confidence": 0.9048447211583456}, {"text": "Abstract Meaning Representation", "start_pos": 31, "end_pos": 62, "type": "TASK", "confidence": 0.767472525437673}]}], "abstractContent": [{"text": "Event Detection (ED) aims to identify instances of specified types of events in text, which is a crucial component in the overall task of event extraction.", "labels": [], "entities": [{"text": "Event Detection (ED)", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.8310717523097992}, {"text": "event extraction", "start_pos": 138, "end_pos": 154, "type": "TASK", "confidence": 0.7193012088537216}]}, {"text": "The commonly used features consist of lexical, syntactic, and entity information, but the knowledge encoded in the Abstract Meaning Representation (AMR) has not been utilized in this task.", "labels": [], "entities": [{"text": "Abstract Meaning Representation (AMR)", "start_pos": 115, "end_pos": 152, "type": "TASK", "confidence": 0.7965105175971985}]}, {"text": "AMR is a semantic formalism in which the meaning of a sentence is encoded as a rooted, directed, acyclic graph.", "labels": [], "entities": []}, {"text": "In this paper, we demonstrate the effectiveness of AMR to capture and represent the deeper semantic contexts of the trigger words in this task.", "labels": [], "entities": []}, {"text": "Experimental results further show that adding AMR features on top of the traditional features can achieve 67.8% (with 2.1% absolute improvement) F-measure (F 1), which is comparable to the state-of-the-art approaches.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 145, "end_pos": 154, "type": "METRIC", "confidence": 0.9366325736045837}, {"text": "F 1)", "start_pos": 156, "end_pos": 160, "type": "METRIC", "confidence": 0.944702128569285}]}], "introductionContent": [{"text": "The problem of event detection (ED) is identifying instances of specified types of events in text.", "labels": [], "entities": [{"text": "event detection (ED)", "start_pos": 15, "end_pos": 35, "type": "TASK", "confidence": 0.892057454586029}]}, {"text": "Associated with each event mention, the event trigger (most often a single verb or nominalization) evokes that event.", "labels": [], "entities": []}, {"text": "Our task, more precisely stated, involves identifying event triggers and classifying them into specific types.", "labels": [], "entities": []}, {"text": "In this paper, we focus on the event detection task defined in Automatic Content Extraction (ACE) evaluation . The task defines 8 event types and 33 subtypes such as Die and End-Position.", "labels": [], "entities": [{"text": "event detection task", "start_pos": 31, "end_pos": 51, "type": "TASK", "confidence": 0.7946107983589172}, {"text": "Automatic Content Extraction (ACE) evaluation", "start_pos": 63, "end_pos": 108, "type": "TASK", "confidence": 0.7418778879301888}]}, {"text": "For instance, according to the ACE 2005 annotation guideline, in the sentence \"A bomb exploded in central Baghdad yesterday\", an event detection system should be able to recognize the word \"exploded\" as a trigger for the event Attack.", "labels": [], "entities": [{"text": "ACE 2005 annotation guideline", "start_pos": 31, "end_pos": 60, "type": "DATASET", "confidence": 0.9552304446697235}, {"text": "event detection", "start_pos": 129, "end_pos": 144, "type": "TASK", "confidence": 0.7121910750865936}]}, {"text": "ED is a crucial component in the overall http://projects.ldc.upenn.edu/ace/ task of event extraction, which also involves event argument discovery 2 . This task is quite challenging, as the same event might appear with various trigger expressions, and an expression might also represent different events in different contexts.", "labels": [], "entities": [{"text": "event extraction", "start_pos": 84, "end_pos": 100, "type": "TASK", "confidence": 0.7246815413236618}, {"text": "event argument discovery", "start_pos": 122, "end_pos": 146, "type": "TASK", "confidence": 0.6540147562821707}]}, {"text": "Abstract Meaning Representation (AMR)) ( \u00a72) is a semantic formalism in which the meaning of a sentence is encoded as a rooted, directed, acyclic graph.", "labels": [], "entities": [{"text": "Abstract Meaning Representation (AMR))", "start_pos": 0, "end_pos": 38, "type": "TASK", "confidence": 0.855897068977356}]}, {"text": "Nodes represent concepts, and labeled directed edges represent the relationships between them.", "labels": [], "entities": []}, {"text": "The knowledge incorporated in the AMR ( \u00a73) can benefit the ED task by abstracting the semantic representation from the sentences with the same meaning but possibly in different syntactic forms.", "labels": [], "entities": [{"text": "ED task", "start_pos": 60, "end_pos": 67, "type": "TASK", "confidence": 0.8584046363830566}]}, {"text": "The results demonstrate that some characteristics are not completely captured by traditional features (e.g., dependency parse features), but maybe revealed in the AMR, complementing other features to help boost the performance to 67.8% (with 2.1% absolute improvement) in F 1 ( \u00a74).", "labels": [], "entities": [{"text": "dependency parse", "start_pos": 109, "end_pos": 125, "type": "TASK", "confidence": 0.7116541862487793}, {"text": "AMR", "start_pos": 163, "end_pos": 166, "type": "DATASET", "confidence": 0.6577454209327698}, {"text": "F 1", "start_pos": 272, "end_pos": 275, "type": "METRIC", "confidence": 0.7438229620456696}]}], "datasetContent": [{"text": "In this section, we will compare our MaxEnt classifiers using both baseline features and additional proposed AMR features with the state-of-the-art systems on the blind test set, and then discuss the results in more detail.", "labels": [], "entities": []}, {"text": "We evaluate our system with above presented features over the ACE 2005 corpus.", "labels": [], "entities": [{"text": "ACE 2005 corpus", "start_pos": 62, "end_pos": 77, "type": "DATASET", "confidence": 0.9795197248458862}]}, {"text": "For comparison purposes, we utilize the same test set with 40 newswire articles (672 sentences), the same development set with 30 other documents (836 sentences) and the same training set with the remaining 529 documents (14, 849 sentences) as the previous studies on this dataset (.", "labels": [], "entities": []}, {"text": "Following the previous work), a trigger candidate is counted as correct if its event subtype and offsets match those of a reference trigger.", "labels": [], "entities": []}, {"text": "The ACE 2005 corpus has 33 event subtypes that, along with one class \"Other\" for the non-trigger tokens, constitutes a 34-class classification problem in this work.", "labels": [], "entities": [{"text": "ACE 2005 corpus", "start_pos": 4, "end_pos": 19, "type": "DATASET", "confidence": 0.9627351959546407}]}, {"text": "This is remarkable since our MaxEnt classifier does not require any global features 5 or sophisticated machine learning framework with a much larger hypothesis space, e.g., structured perceptron with beam search (.", "labels": [], "entities": []}, {"text": "From the detailed result analysis, we can see that the event trigger detection of most event types are significantly (p < 0.05) improved over the baseline setting.", "labels": [], "entities": [{"text": "event trigger detection", "start_pos": 55, "end_pos": 78, "type": "TASK", "confidence": 0.619563082853953}]}, {"text": "Many types gain substantially in both precision and recall, while only 4 out of 33 event types decrease slightly in performance.", "labels": [], "entities": [{"text": "precision", "start_pos": 38, "end_pos": 47, "type": "METRIC", "confidence": 0.9996522665023804}, {"text": "recall", "start_pos": 52, "end_pos": 58, "type": "METRIC", "confidence": 0.9995404481887817}]}, {"text": "Table 3 presents the performance comparison fora subset of event types between the baseline and the Entity mentions and types may get used to introduce more features into the systems.", "labels": [], "entities": []}, {"text": "Global features are the features generated from several event trigger candidates, such as bigrams of trigger types which occur in the same sentence or the same clause, binary feature indicating whether synonyms in the same sentence have the same trigger label, context and dependency paths between two triggers conjuncted with their types, etc.", "labels": [], "entities": []}, {"text": "classifier with both baseline and AMR features . For instance, in the test sentence \".", "labels": [], "entities": [{"text": "AMR", "start_pos": 34, "end_pos": 37, "type": "METRIC", "confidence": 0.726893961429596}]}, {"text": "have Scud missiles capable of reaching Israel . .", "labels": [], "entities": []}, {"text": "\", the trigger candidate \"reach\" can be a Conflict:Attack event (as in this case) but also a Contact:PhoneWrite event (e.g., \"they tried to reach their loved ones\").", "labels": [], "entities": []}, {"text": "If the subject (ARG0) is a weapon (as in this example), it should bean Attack event.", "labels": [], "entities": []}, {"text": "This pattern can be learned from a sentence such as \"The missiles . .", "labels": [], "entities": []}, {"text": "The AMR parser is able to look through \"capable of \" and recognizes that \"missiles\" is the subject (:ARG0 m2/missile) of \"reach\" in this example.", "labels": [], "entities": []}, {"text": "Thus AMR features are able to help predict the correct event type in this case.", "labels": [], "entities": []}, {"text": "AMR can also analyze and learn from different forms of the same word.", "labels": [], "entities": [{"text": "AMR", "start_pos": 0, "end_pos": 3, "type": "TASK", "confidence": 0.6681666374206543}]}, {"text": "For example, there are two examples in the ACE corpus involving \"repay\", one using the verb (\"repaying\") and the other one using the noun (\"repayment\"), and both are classified as Transaction:Transfer-money event.", "labels": [], "entities": [{"text": "ACE corpus", "start_pos": 43, "end_pos": 53, "type": "DATASET", "confidence": 0.8703896701335907}]}, {"text": "AMR could learn from the \"repaying\" example about the correct event type and then precisely apply it to the \"repayment\" example.", "labels": [], "entities": [{"text": "AMR", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.7376373410224915}, {"text": "repaying\"", "start_pos": 26, "end_pos": 35, "type": "TASK", "confidence": 0.8986869752407074}, {"text": "repayment\"", "start_pos": 109, "end_pos": 119, "type": "TASK", "confidence": 0.8926043808460236}]}, {"text": "The gains from adding AMR features show that the features and knowledge encoded in the AMR parse graphs can complement the information incorporated in the dependency parse trees and other traditional features.: Comparison between the performance (%) of baseline and AMR on a subset of event types.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Features extracted from the AMR graph and example features for candidate \"acquisition\".", "labels": [], "entities": [{"text": "AMR graph", "start_pos": 38, "end_pos": 47, "type": "DATASET", "confidence": 0.8056648373603821}]}, {"text": " Table 2: Performance (%) comparison with the state-of-the-art systems.  \u2020 beyond sentence level.", "labels": [], "entities": []}, {"text": " Table 3: Comparison between the performance (%) of baseline and AMR on a subset of event types.", "labels": [], "entities": [{"text": "AMR", "start_pos": 65, "end_pos": 68, "type": "METRIC", "confidence": 0.5774579644203186}]}]}