{"title": [{"text": "VERTa: a Linguistically-motivated Metric at the WMT15 Metrics Task", "labels": [], "entities": [{"text": "VERTa", "start_pos": 0, "end_pos": 5, "type": "DATASET", "confidence": 0.6154428124427795}, {"text": "WMT15 Metrics Task", "start_pos": 48, "end_pos": 66, "type": "DATASET", "confidence": 0.9662229418754578}]}], "abstractContent": [{"text": "This paper describes VERTa's submission to the 2015 EMNLP Workshop on Statistical Machine Translation.", "labels": [], "entities": [{"text": "EMNLP Workshop on Statistical Machine Translation", "start_pos": 52, "end_pos": 101, "type": "TASK", "confidence": 0.6701563696066538}]}, {"text": "VERTa is a linguistically-motivated metric that combines linguistic features at different levels.", "labels": [], "entities": [{"text": "VERTa", "start_pos": 0, "end_pos": 5, "type": "DATASET", "confidence": 0.6836923360824585}]}, {"text": "In this paper, VERTa is described briefly, as well as the three versions submitted to the workshop: VERTa-70Adeq30Flu, VERTa-EQ and VERTa-W.", "labels": [], "entities": [{"text": "VERTa", "start_pos": 15, "end_pos": 20, "type": "METRIC", "confidence": 0.6302152872085571}, {"text": "VERTa-70Adeq30Flu", "start_pos": 100, "end_pos": 117, "type": "METRIC", "confidence": 0.5194467306137085}, {"text": "VERTa-EQ", "start_pos": 119, "end_pos": 127, "type": "METRIC", "confidence": 0.5497905015945435}, {"text": "VERTa-W", "start_pos": 132, "end_pos": 139, "type": "DATASET", "confidence": 0.5593538880348206}]}, {"text": "Finally, the experiments conducted with the WMT14 data are reported and some conclusions are drawn.", "labels": [], "entities": [{"text": "WMT14 data", "start_pos": 44, "end_pos": 54, "type": "DATASET", "confidence": 0.938055545091629}]}], "introductionContent": [{"text": "In the last decade Automatic Machine Translation (MT) Evaluation has become a key field in Natural Language Processing due to the amount of texts that are translated over the world and the need fora quick, reliable and inexpensive way to evaluate the quality of the output text.", "labels": [], "entities": [{"text": "Automatic Machine Translation (MT) Evaluation", "start_pos": 19, "end_pos": 64, "type": "TASK", "confidence": 0.8334860971995762}]}, {"text": "Therefore, a large number of metrics have been developed, which range from very simple metrics to more complex ones.", "labels": [], "entities": []}, {"text": "Within simple metrics there are those that do not use any type of linguistic information, such as BLEU () which is one of the most well-known and widely used, since it is fast and easy to use.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 98, "end_pos": 102, "type": "METRIC", "confidence": 0.9979987740516663}]}, {"text": "Other metrics though, rely on linguistic information used at lexical level such as METEOR; at syntactic level, using either constituent analysis () or dependency analysis; while others use more complex information such as semantic roles ().", "labels": [], "entities": [{"text": "METEOR", "start_pos": 83, "end_pos": 89, "type": "METRIC", "confidence": 0.7131649851799011}]}, {"text": "However, all these metrics focus on partial aspects of language which might lead to a biased evaluation.", "labels": [], "entities": []}, {"text": "As a consequence, in the last years researchers have been exploring different ways to combine a wide variety of linguistic features, either using machine-learning techniques ( or in a more simple and straightforward way).", "labels": [], "entities": []}, {"text": "Nevertheless, little research has been carried out in order to explore the suitability of the linguistic features used and how they should be combined, from a linguistic point of view.", "labels": [], "entities": []}, {"text": "Therefore, this paper proposes anew version of VERTa, a linguisticallymotivated metric which uses a wide variety of linguistic features at different levels and which aims at moving away from a biased evaluation and providing a more holistic approach to MT evaluation.", "labels": [], "entities": [{"text": "VERTa", "start_pos": 47, "end_pos": 52, "type": "METRIC", "confidence": 0.7769246697425842}, {"text": "MT evaluation", "start_pos": 253, "end_pos": 266, "type": "TASK", "confidence": 0.9717044830322266}]}, {"text": "Last year VERTa participated in the WMT15 and achieved promising results at system level, this year we would like to improve the metric's performance at segment level.", "labels": [], "entities": [{"text": "VERTa", "start_pos": 10, "end_pos": 15, "type": "DATASET", "confidence": 0.7497088313102722}, {"text": "WMT15", "start_pos": 36, "end_pos": 41, "type": "DATASET", "confidence": 0.5179960131645203}]}, {"text": "To this aim, a Language Model Module has been added, as well as a NERC component.", "labels": [], "entities": []}, {"text": "In this paper we provide a brief description of the different modules in VERTa and how they are combined, section 3 present the three versions submitted to the WMT15 and reports the experiments performed with WMT14 data into English, and finally in section 4 some conclusions are drawn.", "labels": [], "entities": [{"text": "VERTa", "start_pos": 73, "end_pos": 78, "type": "DATASET", "confidence": 0.9386706948280334}, {"text": "WMT15", "start_pos": 160, "end_pos": 165, "type": "DATASET", "confidence": 0.931669294834137}, {"text": "WMT14 data", "start_pos": 209, "end_pos": 219, "type": "DATASET", "confidence": 0.9158351719379425}]}], "datasetContent": [{"text": "The experiments reported in this section were carried out on the data released in WMT14, all languages into English.", "labels": [], "entities": [{"text": "WMT14", "start_pos": 82, "end_pos": 87, "type": "DATASET", "confidence": 0.9423016905784607}]}, {"text": "Language \"all\" includes Czech (cs), French (fr), German (de), Hindi (hi) and Russian (ru).", "labels": [], "entities": []}, {"text": "All experiments were carried out at segment level and the evaluation sets provided by WMT organizers were used to calculate segment-level correlations.", "labels": [], "entities": [{"text": "WMT organizers", "start_pos": 86, "end_pos": 100, "type": "DATASET", "confidence": 0.872893363237381}]}, {"text": "Our goal in these experiments was two-fold: first, we wanted to test if the combination of Adequacy and Fluency features reported in Comelles (2015) was suitable for the ranking of sentences; and second, we wanted to study if the best weights for each module varied depending on the language pair.", "labels": [], "entities": [{"text": "Fluency", "start_pos": 104, "end_pos": 111, "type": "METRIC", "confidence": 0.5635150671005249}]}], "tableCaptions": [{"text": " Table 4. Modules combination for Adequacy  and Fluency", "labels": [], "entities": [{"text": "Fluency", "start_pos": 48, "end_pos": 55, "type": "METRIC", "confidence": 0.9714310169219971}]}, {"text": " Table 5. Kendall's Correlation for the  Adequacy-Fluency Combination", "labels": [], "entities": []}, {"text": " Table 6. Kendall's Correlation for language- dependent weight combinations", "labels": [], "entities": []}, {"text": " Table 7. Comparison between VERTa's submission to WMT14 and WMT15", "labels": [], "entities": [{"text": "VERTa's submission to WMT14", "start_pos": 29, "end_pos": 56, "type": "DATASET", "confidence": 0.8309550166130066}, {"text": "WMT15", "start_pos": 61, "end_pos": 66, "type": "DATASET", "confidence": 0.8301164507865906}]}]}