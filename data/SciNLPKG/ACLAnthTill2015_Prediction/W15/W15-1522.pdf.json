{"title": [{"text": "Distributed Word Representations Improve NER for e-Commerce", "labels": [], "entities": [{"text": "Distributed Word Representations Improve NER", "start_pos": 0, "end_pos": 44, "type": "TASK", "confidence": 0.8249879360198975}]}], "abstractContent": [{"text": "This paper presents a case study of using distributed word representations, word2vec in particular, for improving performance of Named Entity Recognition for the e-Commerce domain.", "labels": [], "entities": [{"text": "Named Entity Recognition", "start_pos": 129, "end_pos": 153, "type": "TASK", "confidence": 0.6502364277839661}]}, {"text": "We also demonstrate that distributed word representations trained on a smaller amount of in-domain data are more effective than word vectors trained on very large amount of out-of-domain data, and that their combination gives the best results.", "labels": [], "entities": []}], "introductionContent": [{"text": "On-line commerce has gained a lot of popularity over the past decade.", "labels": [], "entities": [{"text": "On-line commerce", "start_pos": 0, "end_pos": 16, "type": "TASK", "confidence": 0.7361800372600555}]}, {"text": "Large on-line C2C marketplaces like eBay, Alibaba, and Amazon feature a very large and long-tail inventory with millions of items (product offers) entered into the marketplace everyday by a large variety of sellers.", "labels": [], "entities": []}, {"text": "To manage items effectively and provide the best user experience, it is critical for these marketplaces to structure their inventory into descriptive namevalue pairs (called properties) and ensure that items of the same kind (digital cameras, for instance) are described using a unique set of properties (brand name, model number, zoom, resolution, etc.).", "labels": [], "entities": [{"text": "resolution", "start_pos": 337, "end_pos": 347, "type": "METRIC", "confidence": 0.9859588742256165}]}, {"text": "This is important for recommendations in merchandising, providing faceted navigation, and assisting business intelligence applications.", "labels": [], "entities": [{"text": "faceted navigation", "start_pos": 66, "end_pos": 84, "type": "TASK", "confidence": 0.6819482445716858}]}, {"text": "While some sellers (generally large, professional retailers) provide rich, structured descriptions of their products (using schemas or global trade item numbers), the vast majority of sellers only provide unstructured natural language descriptions.", "labels": [], "entities": []}, {"text": "In the latter case, one solution to the problem of structuring e-commerce inventory is to use techniques such as Named-Entity Recognition (NER) to extract properties from the textual description of the items.", "labels": [], "entities": [{"text": "Named-Entity Recognition (NER)", "start_pos": 113, "end_pos": 143, "type": "TASK", "confidence": 0.7573229670524597}]}, {"text": "The scale at which on-line marketplaces operate makes it impractical to solve this problem manually.", "labels": [], "entities": []}, {"text": "This paper focuses on NER, generally defined as the task of classifying elements of text into predefined categories (often referred to as entity types or entities).", "labels": [], "entities": [{"text": "NER", "start_pos": 22, "end_pos": 25, "type": "TASK", "confidence": 0.9771777987480164}]}, {"text": "Entities usually include names of persons, organizations, locations, times, and quantities, as well as nationalities or religious groups, products (vehicles, weapons, foods, etc.), and titles of books or songs (Ontonotes 5.0 dataset).", "labels": [], "entities": [{"text": "Entities usually include names of persons, organizations, locations, times, and quantities, as well as nationalities or religious groups, products (vehicles, weapons, foods, etc.), and titles of books or songs", "start_pos": 0, "end_pos": 209, "type": "Description", "confidence": 0.8349118072812151}, {"text": "Ontonotes 5.0 dataset", "start_pos": 211, "end_pos": 232, "type": "DATASET", "confidence": 0.8751897017161051}]}, {"text": "In the e-commerce domain, these entities are item properties such as brand name, color, material, clothing size, golf club type, makeup shade code, sun protection factor, etc.", "labels": [], "entities": []}, {"text": "Another important specificity of the e-commerce domain with respect to NER is that the sentences are usually much shorter than in other applications and don't exhibit the grammatical structure of natural language.", "labels": [], "entities": []}, {"text": "This paper investigates whether distributed word vectors benefit NER in the e-commerce domain.", "labels": [], "entities": [{"text": "NER", "start_pos": 65, "end_pos": 68, "type": "TASK", "confidence": 0.9567105174064636}]}, {"text": "Distributed word representations based on neural networks from unlabeled text data have proven useful for many natural language tasks, including NER.", "labels": [], "entities": []}, {"text": "In fact, reported results compa-rable to state-of-the-art for the CoNLL 2003 NER task using such representations.", "labels": [], "entities": [{"text": "CoNLL 2003 NER task", "start_pos": 66, "end_pos": 85, "type": "DATASET", "confidence": 0.7960376292467117}]}, {"text": "In this paper, we evaluate distributed word vectors with a focus on using in-domain data for their training.", "labels": [], "entities": []}, {"text": "In the remainder of this paper, we first explain the specificity of NER in the e-commerce domain and describe the approach we use for performing the task.", "labels": [], "entities": [{"text": "NER", "start_pos": 68, "end_pos": 71, "type": "TASK", "confidence": 0.9771565794944763}]}, {"text": "In Section 3, we describe our datasets.", "labels": [], "entities": []}, {"text": "In Section 4, we describe the setting of the experiments we have conducted and discuss the results in Section 5.", "labels": [], "entities": []}, {"text": "Finally, we review related works in Section 6.", "labels": [], "entities": []}], "datasetContent": [{"text": "We now present our experimental results for NER on e-commerce item titles.", "labels": [], "entities": [{"text": "NER", "start_pos": 44, "end_pos": 47, "type": "TASK", "confidence": 0.9775750637054443}]}, {"text": "The goal of our work is not necessarily to present the best possible results for this task.", "labels": [], "entities": []}, {"text": "Instead, our experiments are driven by the following two questions: (1) Are distributed word representations created from highly unstructured data (namely, e-commerce item titles) beneficial for the task of named entity recognition on the same kind of unstructured data?", "labels": [], "entities": [{"text": "named entity recognition", "start_pos": 207, "end_pos": 231, "type": "TASK", "confidence": 0.6686336696147919}]}, {"text": "(2) How do distributed word vector representations created from out-of-domain (namely, non e-commerce data) compare with those created from in-domain data?", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Approximate statistics for the in-domain titles  (B: billion, M: million, K: thousand). The vocabulary  size is based on a minimum count of 50.", "labels": [], "entities": [{"text": "Approximate", "start_pos": 10, "end_pos": 21, "type": "METRIC", "confidence": 0.9917978048324585}]}, {"text": " Table 3: Training / test data splits (titles, token count,  vocabulary size) for each category.", "labels": [], "entities": []}, {"text": " Table 7: A small sample of errors made by our various models on the CELLPH category. The first column shows the  models being compared (\">\" stands for \"better than\"). The predictions of the models differ for the underlined tokens.  In parentheses, the prediction from the correct model is shown first, followed by the prediction of the incorrect model.", "labels": [], "entities": [{"text": "CELLPH category", "start_pos": 69, "end_pos": 84, "type": "DATASET", "confidence": 0.9025454521179199}]}]}