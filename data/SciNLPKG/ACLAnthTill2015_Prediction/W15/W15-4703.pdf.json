{"title": [{"text": "A Domain Agnostic Approach to Verbalizing n-ary Events without Parallel Corpora", "labels": [], "entities": []}], "abstractContent": [{"text": "We present a method for automatically generating descriptions of biological events encoded in the KB BIO 101 Knowledge base.", "labels": [], "entities": [{"text": "KB BIO 101 Knowledge base", "start_pos": 98, "end_pos": 123, "type": "DATASET", "confidence": 0.9407309889793396}]}, {"text": "We evaluate our approach on a corpus of 336 event descriptions, provide a qualitative and quantitative analysis of the results obtained and discuss possible directions for further work.", "labels": [], "entities": []}], "introductionContent": [{"text": "While earlier work on data-to-text generation heavily relied on handcrafted linguistic resources, more recent data-driven approaches have focused on learning a generation system from parallel corpora of data and text.", "labels": [], "entities": [{"text": "data-to-text generation", "start_pos": 22, "end_pos": 45, "type": "TASK", "confidence": 0.7774713635444641}]}, {"text": "Thus, () trained and developed data-to-text generators on datasets from various domains including the air travel domain (, weather forecasts ( and sportscasting).", "labels": [], "entities": []}, {"text": "In both cases, considerable time and expertise must be spent on developing the required linguistic resources.", "labels": [], "entities": []}, {"text": "In the handcrafted, symbolic approach, appropriate grammars and lexicons must be specified while in the parallel corpus based learning approach, an aligned data-text corpus must be built for each new domain.", "labels": [], "entities": []}, {"text": "Here, we explore an alternative approach using non-parallel corpora for surface realisation from knowledge bases that can be used for any knowledge base for which there exists large textual corpora.", "labels": [], "entities": []}, {"text": "A more specific, linguistic issue which has received relatively little attention is the unsupervised verbalisation of n-ary relations and the task of appropriately mapping KB roles to syntactic functions.", "labels": [], "entities": []}, {"text": "In recent work on verbalising RDF triples, relations are restricted to binary relations (called \"property\" in the RDF language) and the issue is therefore intrinsically simpler.", "labels": [], "entities": []}, {"text": "In symbolic approaches dealing with n-ary relations, the mapping between syntactic and semantic arguments is determined by the lexicon and must be manually specified.", "labels": [], "entities": []}, {"text": "In data-driven approaches, the mapping is learned from the alignment between text and data and is restricted by cases seen in the training data.", "labels": [], "entities": []}, {"text": "Instead, we learn a probabilistic model designed to select the most probable mapping.", "labels": [], "entities": []}, {"text": "In this way, we provide a domain independent, fully automatic, means of verbalising n-ary relations.", "labels": [], "entities": []}, {"text": "The paper is structured as follows.", "labels": [], "entities": []}, {"text": "In Section 2, we discuss related work.", "labels": [], "entities": []}, {"text": "In Section 3, we present the method used to verbalise KB events and their participants.", "labels": [], "entities": [{"text": "verbalise KB events", "start_pos": 44, "end_pos": 63, "type": "TASK", "confidence": 0.842615564664205}]}, {"text": "In Section 4, we evaluate our approach on a corpus of 336 test cases, provide a qualitative and quantitative analysis of the results obtained and discuss possible directions for further work.", "labels": [], "entities": []}], "datasetContent": [{"text": "Taking a sample of 264 inputs from the KBGEN + dataset, we evaluate the mappings of roles to syntax in the output.", "labels": [], "entities": [{"text": "KBGEN + dataset", "start_pos": 39, "end_pos": 54, "type": "DATASET", "confidence": 0.9358817140261332}]}, {"text": "The sample contains inputs with 1 to 2 roles (40%), 3 roles (30%) and more than 3 roles (30%).", "labels": [], "entities": []}, {"text": "For each sampled input, we consider the 5 best outputs and manually grade the output as follows: 1.", "labels": [], "entities": []}, {"text": "Correct: both the syntax/semantic linking of the arguments and the lexicalisation of the event and of its arguments is correct.", "labels": [], "entities": []}, {"text": "2. Almost Corrrect: the lexicalisation of the event and of its arguments is correct and the linking of core semantic arguments is correct.", "labels": [], "entities": []}, {"text": "The core arguments are the most frequent ones in the test data namely AGENT, BASE, OB-JECT.", "labels": [], "entities": [{"text": "AGENT", "start_pos": 70, "end_pos": 75, "type": "METRIC", "confidence": 0.9930629134178162}, {"text": "BASE", "start_pos": 77, "end_pos": 81, "type": "METRIC", "confidence": 0.998454213142395}, {"text": "OB-JECT", "start_pos": 83, "end_pos": 90, "type": "METRIC", "confidence": 0.9732257127761841}]}, {"text": "3. Incorrect: all other cases.", "labels": [], "entities": [{"text": "Incorrect", "start_pos": 3, "end_pos": 12, "type": "TASK", "confidence": 0.7767996191978455}]}, {"text": "Three judges independently graded 264 inputs using the above criteria.", "labels": [], "entities": []}, {"text": "The inter-annotator agreement, as measured with the Fleiss Kappa in a preliminary experiment in these conditions, was \u03ba = 0.76 which is considered as \"good agreement\" in the literature.", "labels": [], "entities": []}, {"text": "29% of the ouput were found to be correct, 20% to be almost correct and 51% to be incorrect.", "labels": [], "entities": []}, {"text": "One main factor negatively affecting results is the number of roles contained in an event description.", "labels": [], "entities": []}, {"text": "Unsurprisingly, the greater the number of roles the lower the accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 62, "end_pos": 70, "type": "METRIC", "confidence": 0.9988935589790344}]}, {"text": "That is, for event descriptions with 3 or less roles, the scores are higher (40%, 23%, 37% respectively for correct, almost correct and incorrect) as there are less possibilities to be considered.", "labels": [], "entities": []}, {"text": "Another, related issue, is data sparsity.", "labels": [], "entities": []}, {"text": "Unsurprisingly, roles that are less frequent often score lower (i.e., are more often incorrectly mapped to syntax) than roles which occur more frequently.", "labels": [], "entities": []}, {"text": "Thus, the three most frequent roles (AGENT,OBJECT, BASE) have a 5-best role mapping accuracy that ranges from 43% to 77%, while most other roles have much lower accuracy.", "labels": [], "entities": [{"text": "AGENT,OBJECT", "start_pos": 37, "end_pos": 49, "type": "METRIC", "confidence": 0.8644724488258362}, {"text": "BASE", "start_pos": 51, "end_pos": 55, "type": "METRIC", "confidence": 0.9863507151603699}, {"text": "role mapping", "start_pos": 71, "end_pos": 83, "type": "TASK", "confidence": 0.6756080090999603}, {"text": "accuracy", "start_pos": 84, "end_pos": 92, "type": "METRIC", "confidence": 0.9601231217384338}, {"text": "accuracy", "start_pos": 161, "end_pos": 169, "type": "METRIC", "confidence": 0.9950237274169922}]}, {"text": "These of our model's outputs; this is the only threshold value that we have tried, and we have not tuned this threshold at all two issues suggest that results could be improved by using either more data or a more sophisticated smoothing or learning strategy.", "labels": [], "entities": []}, {"text": "However linguistic factors are also at play here.", "labels": [], "entities": []}, {"text": "First, some semantic roles are often verbalised as verbs rather than thematic roles.", "labels": [], "entities": []}, {"text": "For instance, in Sentence (2), the event (INTRACELLULAR-DIGESTION) is verbalised as a nominalisation and the OBJECT role as a verb (produces).", "labels": [], "entities": [{"text": "Sentence (2)", "start_pos": 17, "end_pos": 29, "type": "TASK", "confidence": 0.872920036315918}, {"text": "INTRACELLULAR-DIGESTION", "start_pos": 42, "end_pos": 65, "type": "METRIC", "confidence": 0.9718899726867676}, {"text": "OBJECT", "start_pos": 109, "end_pos": 115, "type": "METRIC", "confidence": 0.8921381235122681}]}, {"text": "More generally, a role in the KB is not necessarily realised by a thematic role.", "labels": [], "entities": []}, {"text": "(2) Intracellular digestion of polymers and solid substances in the lysosome produces monomers.", "labels": [], "entities": []}, {"text": "Second, in some cases, entities which are arguments of the event in the input are verbalised as prepositional modifiers of an argument of the verb verbalising the event rather than as an argument of the verb itself.", "labels": [], "entities": []}, {"text": "This is frequently the case for the BASE relation.", "labels": [], "entities": [{"text": "BASE relation", "start_pos": 36, "end_pos": 49, "type": "TASK", "confidence": 0.6402246356010437}]}, {"text": "For instance, Example (3) shows the gold sentence for an input containing EUKARYOTIC-CELL as a BASE argument.", "labels": [], "entities": [{"text": "EUKARYOTIC-CELL", "start_pos": 74, "end_pos": 89, "type": "DATASET", "confidence": 0.9097167253494263}, {"text": "BASE", "start_pos": 95, "end_pos": 99, "type": "METRIC", "confidence": 0.9806168079376221}]}, {"text": "As can be seen, in this case, the EUKARYOTIC-CELL entity is verbalised by a prepositional phrase modifying an NP rather than by an argument of the verb.", "labels": [], "entities": [{"text": "EUKARYOTIC-CELL", "start_pos": 34, "end_pos": 49, "type": "DATASET", "confidence": 0.8171095848083496}]}, {"text": "(3) Lysosomal enzymes digest nucleic acids and proteins in the lysosome of eukaryotic cells.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 3: Lexical Entries and Number of KBGEN +  event and entities for which one or more entry was  found (Intersecting Entries)", "labels": [], "entities": []}, {"text": " Table 4: Proportion of Event and Entity Names for which a Lexical Entry was found. Min, max and  average number of lexical items associated with event and entities", "labels": [], "entities": [{"text": "Min", "start_pos": 84, "end_pos": 87, "type": "METRIC", "confidence": 0.9802339673042297}, {"text": "max", "start_pos": 89, "end_pos": 92, "type": "METRIC", "confidence": 0.9012290835380554}]}]}