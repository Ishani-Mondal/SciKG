{"title": [{"text": "Translation Model Adaptation Using Genre-Revealing Text Features", "labels": [], "entities": [{"text": "Translation Model Adaptation", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.9156170686086019}]}], "abstractContent": [{"text": "Research in domain adaptation for statistical machine translation (SMT) has resulted in various approaches that adapt system components to specific translation tasks.", "labels": [], "entities": [{"text": "domain adaptation", "start_pos": 12, "end_pos": 29, "type": "TASK", "confidence": 0.7109226733446121}, {"text": "statistical machine translation (SMT)", "start_pos": 34, "end_pos": 71, "type": "TASK", "confidence": 0.8082424948612849}]}, {"text": "The concept of a domain, however , is not precisely defined, and most approaches rely on provenance information or manual subcorpus labels, while genre differences have not been addressed explicitly.", "labels": [], "entities": []}, {"text": "Motivated by the large translation quality gap that is commonly observed between different genres in a test corpus, we explore the use of document-level genre-revealing text features for the task of translation model adaptation.", "labels": [], "entities": [{"text": "translation model adaptation", "start_pos": 199, "end_pos": 227, "type": "TASK", "confidence": 0.9118000666300455}]}, {"text": "Results show that automatic indicators of genre can replace manual subcorpus labels, yielding significant improvements across two test sets of up to 0.9 BLEU.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 153, "end_pos": 157, "type": "METRIC", "confidence": 0.9974034428596497}]}, {"text": "In addition, we find that our genre-adapted translation models encourage document-level translation consistency .", "labels": [], "entities": [{"text": "document-level translation consistency", "start_pos": 73, "end_pos": 111, "type": "TASK", "confidence": 0.5968161225318909}]}], "introductionContent": [{"text": "Statistical machine translation (SMT) systems use large bilingual corpora to train translation models, which can be used to translate unseen test sentences.", "labels": [], "entities": [{"text": "Statistical machine translation (SMT)", "start_pos": 0, "end_pos": 37, "type": "TASK", "confidence": 0.8021986136833826}, {"text": "translate unseen test sentences", "start_pos": 124, "end_pos": 155, "type": "TASK", "confidence": 0.7903618067502975}]}, {"text": "Training corpora are typically collected from a wide variety of sources and therefore have varying textual characteristics such as writing style and vocabulary.", "labels": [], "entities": []}, {"text": "The test set, on the other hand, is much smaller and usually more homogeneous.", "labels": [], "entities": []}, {"text": "As a result, there is often a mismatch between the test data and the majority of the training data.", "labels": [], "entities": []}, {"text": "In such situations, it is beneficial to adapt the translation system to the translation task at hand, which is exactly the challenge of domain adaptation in SMT.", "labels": [], "entities": [{"text": "SMT", "start_pos": 157, "end_pos": 160, "type": "TASK", "confidence": 0.9736480712890625}]}, {"text": "The concept of a domain, however, is not precisely defined across existing domain adaptation methods.", "labels": [], "entities": []}, {"text": "Different domains typically correspond to different subcorpora, in which documents exhibit a particular combination of genre and topic, and optionally other textual characteristics such as dialect and register.", "labels": [], "entities": []}, {"text": "This definition, however, has two major shortcomings.", "labels": [], "entities": []}, {"text": "First, subcorpusbased domains depend on provenance information, which might not be available, or on manual grouping of documents into subcorpora, which is labor intensive and often carried out according to arbitrary criteria.", "labels": [], "entities": []}, {"text": "Second, the commonly used notion of a domain neglects the fact that topic and genre are two distinct properties of text).", "labels": [], "entities": []}, {"text": "While this distinction has long been acknowledged in text classification literature), most work on domain adaptation in SMT uses in-domain and out-of-domain data that differs on both the topic and the genre level (e.g., Europarl political proceedings () versus EMEA medical text), making it unclear whether the proposed solutions address topic or genre differences.", "labels": [], "entities": [{"text": "text classification", "start_pos": 53, "end_pos": 72, "type": "TASK", "confidence": 0.7363876700401306}, {"text": "domain adaptation", "start_pos": 99, "end_pos": 116, "type": "TASK", "confidence": 0.7386890947818756}, {"text": "SMT", "start_pos": 120, "end_pos": 123, "type": "TASK", "confidence": 0.7582393288612366}, {"text": "Europarl political proceedings", "start_pos": 220, "end_pos": 250, "type": "DATASET", "confidence": 0.9462107022603353}]}, {"text": "In this work, we follow text classification literature for definitions of the concepts topic and genre.", "labels": [], "entities": [{"text": "text classification", "start_pos": 24, "end_pos": 43, "type": "TASK", "confidence": 0.6957693099975586}]}, {"text": "While topic refers to the general subject (e.g., sports, politics or science) of a document, genre is harder to define since existing definitions vary., for example, refers to genre as a class of communicative events with a shared set of communicative purposes, and calls it a grouping of documents that are stylistically consistent.", "labels": [], "entities": []}, {"text": "Based on previous definitions, concludes that the term genre is pri-marily used as a concept complementary to topic, covering the non-topical text properties function, style, and text type.", "labels": [], "entities": []}, {"text": "Examples of genres include editorials, newswire, or user-generated (UG) text, i.e., content written by lay-persons that has not undergone any editorial control.", "labels": [], "entities": []}, {"text": "Within the latter we can distinguish more fine-grained subclasses, such as dialog-oriented content (e.g., SMS or chat messages), weblogs, or commentaries to news articles, all of which pose different challenges to SMT (van der).", "labels": [], "entities": [{"text": "SMT", "start_pos": 214, "end_pos": 217, "type": "TASK", "confidence": 0.9938105940818787}]}, {"text": "Recently, we studied the impact of topic and genre differences on SMT quality using the Gen&Topic benchmark set, an Arabic-English evaluation set with controlled topic distributions over two genres; newswire and UG comments (van der).", "labels": [], "entities": [{"text": "SMT", "start_pos": 66, "end_pos": 69, "type": "TASK", "confidence": 0.9969111084938049}, {"text": "Gen&Topic benchmark set", "start_pos": 88, "end_pos": 111, "type": "DATASET", "confidence": 0.807009482383728}]}, {"text": "Motivated by the observation that translation quality varies more between the two genres than across topics, we explore in this paper the task of genre adaptation.", "labels": [], "entities": [{"text": "translation", "start_pos": 34, "end_pos": 45, "type": "TASK", "confidence": 0.969993531703949}, {"text": "genre adaptation", "start_pos": 146, "end_pos": 162, "type": "TASK", "confidence": 0.7828280031681061}]}, {"text": "Concretely, we incorporate genre-revealing features, inspired by previous findings in genre classification literature, into a competitive translation model adaptation approach with the aim of improving translation quality across two test sets; the first containing newswire and UG comments, and the second containing newswire and UG weblogs.", "labels": [], "entities": [{"text": "genre classification literature", "start_pos": 86, "end_pos": 117, "type": "TASK", "confidence": 0.7707504133383433}, {"text": "translation model adaptation", "start_pos": 138, "end_pos": 166, "type": "TASK", "confidence": 0.8474847078323364}]}, {"text": "Ina series of translation experiments we show that automatic indicators of genre can replace manual subcorpus labels, yielding improvements of up to 0.9 BLEU over a strong unadapted baseline.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 153, "end_pos": 157, "type": "METRIC", "confidence": 0.9983804225921631}]}, {"text": "In addition, we observe small but mostly significant improvements when using the automatic genre indicators on top of manual subcorpus labels.", "labels": [], "entities": []}, {"text": "We also find that our genre-revealing feature values can be computed on either side of the training bitext, indicating that the proposed features are to a large extent language independent.", "labels": [], "entities": []}, {"text": "Finally, we notice that our genre-adapted translation models encourage document-level translation consistency with respect to the unadapted baseline.", "labels": [], "entities": []}], "datasetContent": [{"text": "We evaluate the methods described in Section 3 on two Arabic-to-English translation tasks, both comprising the NW and UG.", "labels": [], "entities": [{"text": "Arabic-to-English translation", "start_pos": 54, "end_pos": 83, "type": "TASK", "confidence": 0.5836521983146667}]}, {"text": "The first evaluation set is the Gen&Topic benchmark (van der Wees et al., 2015b), which consists of manually translated web-crawled news articles and their respective manually translated user comments, both covering five different topics.", "labels": [], "entities": [{"text": "Gen&Topic benchmark", "start_pos": 32, "end_pos": 51, "type": "DATASET", "confidence": 0.6678807884454727}]}, {"text": "Since this evaluation set has controlled topic distributions per genre, differences in translation quality between genres can be entirely attributed to actual genre differences.", "labels": [], "entities": []}, {"text": "We perform our experiments using an inhouse phrase-based SMT system similar to Moses ( ).", "labels": [], "entities": [{"text": "SMT", "start_pos": 57, "end_pos": 60, "type": "TASK", "confidence": 0.9260432124137878}]}, {"text": "All runs use lexicalized reordering, distinguishing between monotone, swap, and discontinuous reordering, with respect to the previous and next phrase (   Other features include linear distortion with limit 5, lexical weighting (, and a 5-gram target language model trained with KneserNey smoothing).", "labels": [], "entities": []}, {"text": "The feature weights are tuned using pairwise ranking optimization (PRO) (Hopkins and May, 2011).", "labels": [], "entities": [{"text": "pairwise ranking optimization (PRO)", "start_pos": 36, "end_pos": 71, "type": "TASK", "confidence": 0.6756178587675095}]}, {"text": "For all experiments, tuning is done separately for the two genre-specific development sets.", "labels": [], "entities": []}, {"text": "All runs use parallel corpora made available for NIST OpenMT 2012, excluding the UN data.", "labels": [], "entities": [{"text": "NIST OpenMT 2012", "start_pos": 49, "end_pos": 65, "type": "DATASET", "confidence": 0.855152428150177}, {"text": "UN data", "start_pos": 81, "end_pos": 88, "type": "DATASET", "confidence": 0.8146689236164093}]}, {"text": "While LDC-distributed data sets contain substantial portions of documents within the NW genre, they only contain small portions of UG documents.", "labels": [], "entities": [{"text": "LDC-distributed data sets", "start_pos": 6, "end_pos": 31, "type": "DATASET", "confidence": 0.7851028541723887}]}, {"text": "To alleviate this imbalance we augment our LDC-distributed training data with a variety of web-crawled manually translated documents, containing user comments that are of a similar nature as the UG documents in the Gen&Topic, set as well as a number of other genres.", "labels": [], "entities": [{"text": "Gen&Topic, set", "start_pos": 215, "end_pos": 229, "type": "DATASET", "confidence": 0.8289143443107605}]}, {"text": "lists the corpus statistics of the training data, split by manual subcorpus labels as used for the subcorpus VSM variant (see Section 3.2).", "labels": [], "entities": []}, {"text": "While our manually grouped subcorpora approximate those used by, exact agreement was impossible to obtain, illustrating that it is not trivial to manually generate optimal subcorpus labels.", "labels": [], "entities": []}, {"text": "We tokenize all Arabic data using MADA), ATB scheme.", "labels": [], "entities": [{"text": "ATB", "start_pos": 41, "end_pos": 44, "type": "METRIC", "confidence": 0.9757020473480225}]}, {"text": "Word alignment was performed by running GIZA++ in both directions and generating the symmetric alignments using the 'grow-diag-final-and' heuristics.", "labels": [], "entities": [{"text": "Word alignment", "start_pos": 0, "end_pos": 14, "type": "TASK", "confidence": 0.6586725562810898}]}, {"text": "We use an adapted language model which", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Corpus statistics of the evaluation sets.  Numbers of tokens are counted on the Arabic  side. Note that Gen&Topic contains one reference  translation per sentence, while NIST has four sets  of reference translations.", "labels": [], "entities": [{"text": "NIST", "start_pos": 180, "end_pos": 184, "type": "DATASET", "confidence": 0.9332594275474548}]}, {"text": " Table 4: BLEU scores of the baseline system and all VSM variants using automatic indicators of genre.  Significance is tested against the baseline, and the best performing VSM variant per test set is bold-faced.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9992300271987915}]}, {"text": " Table 5: BLEU scores of VSM with manual subcorpus labels in comparison to the best performing VSM  with automatic indicators of genre per test corpus (see bold-faced results in", "labels": [], "entities": [{"text": "BLEU", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9988828301429749}]}]}