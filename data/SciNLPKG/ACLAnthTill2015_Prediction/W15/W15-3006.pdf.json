{"title": [{"text": "CUNI in WMT15: Chimera Strikes Again", "labels": [], "entities": [{"text": "CUNI in WMT15", "start_pos": 0, "end_pos": 13, "type": "DATASET", "confidence": 0.8666886488596598}, {"text": "Chimera Strikes", "start_pos": 15, "end_pos": 30, "type": "TASK", "confidence": 0.511266827583313}]}], "abstractContent": [{"text": "This paper describes our WMT15 system submission for the translation task, a hybrid system for English-to-Czech translation.", "labels": [], "entities": [{"text": "WMT15 system submission", "start_pos": 25, "end_pos": 48, "type": "DATASET", "confidence": 0.7465034127235413}, {"text": "translation task", "start_pos": 57, "end_pos": 73, "type": "TASK", "confidence": 0.942459762096405}, {"text": "English-to-Czech translation", "start_pos": 95, "end_pos": 123, "type": "TASK", "confidence": 0.6874006390571594}]}, {"text": "We repeat the successful setup from the previous two years.", "labels": [], "entities": []}], "introductionContent": [{"text": "CHIMERA () is our English-to-Czech MT system designed as a combination of three very different components: \u2022 TectoMT (Popel and\u017dabokrtsk\u00b4yand\u02c7and\u017dabokrtsk\u00b4and\u017dabokrtsk\u00b4y, 2010), a deep-syntactic transfer-based system, \u2022 Moses (, where we use a factored phrase-based setup with large language models, \u2022 Depfix (, an automatic postediting system, aimed at correcting mainly errors in morphological agreement but successful also in semantic corrections, esp.", "labels": [], "entities": [{"text": "MT", "start_pos": 35, "end_pos": 37, "type": "TASK", "confidence": 0.9370046257972717}, {"text": "Popel and\u017dabokrtsk\u00b4yand\u02c7and\u017dabokrtsk\u00b4and\u017dabokrtsk\u00b4y, 2010)", "start_pos": 118, "end_pos": 176, "type": "DATASET", "confidence": 0.9198330283164978}, {"text": "semantic corrections", "start_pos": 429, "end_pos": 449, "type": "TASK", "confidence": 0.700692281126976}]}, {"text": "The overall setup as well as the details on each of the components have been described in the past.", "labels": [], "entities": []}, {"text": "We nevertheless briefly review it here, to make the paper self-contained.", "labels": [], "entities": []}, {"text": "This year, our submission mainly differed in the additional data we were able to collect.", "labels": [], "entities": []}, {"text": "We thus evaluate how much do the additional data help in contrast with an identical setup using WMT15 training data only.", "labels": [], "entities": [{"text": "WMT15 training data", "start_pos": 96, "end_pos": 115, "type": "DATASET", "confidence": 0.8719083070755005}]}, {"text": "For the manual evaluation in WMT15, we submitted the non-constrained system, and even the \"constrained\" setup might not qualify as such, since it is a system combination and both TectoMT and Depfix rely on handcrafted rules to some extent.", "labels": [], "entities": [{"text": "WMT15", "start_pos": 29, "end_pos": 34, "type": "DATASET", "confidence": 0.8286026120185852}]}, {"text": "In the following, we provide various details of the setup.", "labels": [], "entities": []}, {"text": "We leave Depfix aside, since we simply applied it as a post-processing step and the relevant analysis of its rules was published previously ().", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Summary of parallel data used in our constrained and full setup.", "labels": [], "entities": [{"text": "Summary", "start_pos": 10, "end_pos": 17, "type": "METRIC", "confidence": 0.8461124300956726}]}, {"text": " Table 3: Complementary effect of adding Tec- toMT and language models.", "labels": [], "entities": []}, {"text": " Table 4: BLEU scores on WMT newstest2014 of  the first two components of Chimera.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9994434714317322}, {"text": "WMT newstest2014", "start_pos": 25, "end_pos": 41, "type": "DATASET", "confidence": 0.9557051360607147}]}, {"text": " Table 5: Automatic scores and results of man- ual ranking in WMT 2015 (preliminary re- sults). BLEU (cased) and TER from matrix.  statmt.org. The top other system JHU-SMT  and GOOGLE TRANSLATE are reported for refer- ence.", "labels": [], "entities": [{"text": "WMT 2015", "start_pos": 62, "end_pos": 70, "type": "DATASET", "confidence": 0.7335255742073059}, {"text": "BLEU", "start_pos": 96, "end_pos": 100, "type": "METRIC", "confidence": 0.9992813467979431}, {"text": "TER", "start_pos": 113, "end_pos": 116, "type": "METRIC", "confidence": 0.9985122084617615}, {"text": "JHU-SMT", "start_pos": 164, "end_pos": 171, "type": "DATASET", "confidence": 0.9367417097091675}, {"text": "GOOGLE", "start_pos": 177, "end_pos": 183, "type": "METRIC", "confidence": 0.9054219722747803}, {"text": "TRANSLATE", "start_pos": 184, "end_pos": 193, "type": "METRIC", "confidence": 0.6907969117164612}, {"text": "refer- ence", "start_pos": 211, "end_pos": 222, "type": "METRIC", "confidence": 0.8822800715764364}]}]}