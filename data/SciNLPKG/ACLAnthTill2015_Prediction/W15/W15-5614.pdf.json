{"title": [{"text": "An Annotated Corpus for Sentiment Analysis in Political News", "labels": [], "entities": [{"text": "Sentiment Analysis in Political News", "start_pos": 24, "end_pos": 60, "type": "TASK", "confidence": 0.8381800293922425}]}], "abstractContent": [{"text": "This article describes a corpus of news texts in Brazilian Portuguese.", "labels": [], "entities": []}, {"text": "News were collected from four big newswire outlets, segmented in paragraphs, and marked up by a group of four annotators, who had to classify each paragraph according to two dimensions: target entity (that is the person which is the main subject of the news contained in the paragraph), and the paragraph's polarity with respect to the target entity.", "labels": [], "entities": []}, {"text": "The corpus comprises 131 news, segmented in 1,447 paragraphs, with 65,675 words in total.", "labels": [], "entities": []}, {"text": "Along with the corpus, we have also built a gold standard, where paragraphs are classified according to the opinion of the majority of annotators.", "labels": [], "entities": []}, {"text": "This gold standard and annotated corpus are available to the community under a Creative Commons licence.", "labels": [], "entities": []}], "introductionContent": [{"text": "In recent years, sentiment analysis has drawn researchers' attention due to the vast amount of information available through the internet, along with the development of machine learning techniques applied to natural language processing [Pang and.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 17, "end_pos": 35, "type": "TASK", "confidence": 0.9684980809688568}]}, {"text": "With this kind of analysis, it is possible to gather information of great commercial interest, such as what costumers are saying about some product, film or person, for example.", "labels": [], "entities": []}, {"text": "In this sense, one of the first domains to serve as a testing field for sentiment analysis was that of customer reviews (e.g.), where products are classified as recommended or not by customers (e.g.).", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 72, "end_pos": 90, "type": "TASK", "confidence": 0.9574539959430695}]}, {"text": "Alternatively, a number of \"stars\" maybe attributed to some product or information which, in turn, are used to classify the reviews according to their valence (i.e. positive, neutral or negative, e.g.).", "labels": [], "entities": []}, {"text": "Differently from customer reviews, however, the newswire domain usually comes with no such hint on customers' (i.e. readers') opinion about the product (i.e. the news itself), or even on the content of the news.", "labels": [], "entities": []}, {"text": "As such, researchers have no inbuilt hint that can help them figure out the valence of the sentiment associated with that news, be it the sentiment expressed along with the news, or the sentiment it elicits in customers.", "labels": [], "entities": []}, {"text": "In order to allow for sentiment analysis techniques to be used and evaluated, it is necessary then to manually annotate a set of news.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 22, "end_pos": 40, "type": "TASK", "confidence": 0.9666745662689209}]}, {"text": "As a matter of fact, such annotated corpora can already be found in some languages, such as Arabian [Abdul-, Portuguese [Rocha and and English [Curran and, for example.", "labels": [], "entities": []}, {"text": "These, however, are designed for general use, not focusing on a specific subject, such as political news, for instance.", "labels": [], "entities": []}, {"text": "On this account, only the German language seems to have a corpus dedicated to this kind of news (cf. [).", "labels": [], "entities": []}, {"text": "The focus on politics, in turn, is justifiable given its usually polarised nature, whereby one always have a situation and an opposition.", "labels": [], "entities": []}, {"text": "Such a polarisation can be a fertile ground for research on bias (in its different forms), economical situation forecasting, or even political action prediction, which could be inferred from some tendency detected in this kind of news.", "labels": [], "entities": [{"text": "economical situation forecasting", "start_pos": 91, "end_pos": 123, "type": "TASK", "confidence": 0.6301953295866648}, {"text": "political action prediction", "start_pos": 133, "end_pos": 160, "type": "TASK", "confidence": 0.6471051275730133}]}, {"text": "To help reduce this lack of resources, specifically in Brazilian Portuguese, in this article we present a corpus of political news texts, annotated with sentiment information according to two dimensions: the entity referred to by the news, and the valence of that reference.", "labels": [], "entities": []}, {"text": "From resulting annotations, we have also built a gold standard, which can be used both to evaluate different sentiment analysis techniques, thereby providing a common ground for future comparisons, and to allow for machine learning techniques to be applied.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 109, "end_pos": 127, "type": "TASK", "confidence": 0.9213968813419342}]}, {"text": "Both corpus and gold standard are publicly available under a Creative Commons licence at http://www.each.usp.br/norton/ viesnoticias/index_ing.html.", "labels": [], "entities": []}, {"text": "The rest of this article is organised as follows.", "labels": [], "entities": []}, {"text": "Section 2 provides an overview of current related research on news corpora annotation.", "labels": [], "entities": []}, {"text": "Section 3, in turn, describes the process of data gathering, along with the methodology followed to annotate these data.", "labels": [], "entities": [{"text": "data gathering", "start_pos": 45, "end_pos": 59, "type": "TASK", "confidence": 0.792260468006134}]}, {"text": "Section 4 presents the annotation results, in terms of inter-annotator agreement, along with the steps taken to build our gold standard and label distribution within it.", "labels": [], "entities": []}, {"text": "These results are then discussed further in this Section.", "labels": [], "entities": []}, {"text": "Finally, Section 5 presents our conclusions and directions for future research.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1. Selected Twitter Profiles", "labels": [], "entities": []}, {"text": " Table 3. Inter-annotator agreement for polarity and target entity", "labels": [], "entities": []}, {"text": " Table 4. As an example to help  the reader understand these figures, in this table, \u03b1's value between annotators 1 and 2 is  0.64, whereas its value for annotators 3 and 4 is 0.71, and so on. Mean value amongst all  pairs is then 0.68.", "labels": [], "entities": [{"text": "Mean", "start_pos": 193, "end_pos": 197, "type": "METRIC", "confidence": 0.9948217868804932}]}, {"text": " Table 4. Pairwise inter-annotator agreement for the target entity dimension", "labels": [], "entities": []}, {"text": " Table 5. Pairwise inter-annotator agreement for the Polarity 2 dimension", "labels": [], "entities": []}, {"text": " Table 6. Polarity distribution in the gold standard", "labels": [], "entities": []}]}