{"title": [{"text": "Automated Lossless Hyper-Minimization for Morphological Analyzers", "labels": [], "entities": []}], "abstractContent": [{"text": "This paper presents a fully automated loss-less hyper-minimization method for finite-state morphological analyzers in Xerox lexc formalism.", "labels": [], "entities": []}, {"text": "The method utilizes flag diacritics to preserve the structure of the original lexc description in the finite-state analyzer, which results in reduced size of the analyzer.", "labels": [], "entities": []}, {"text": "We compare our method against an earlier solution by Drobac et al.", "labels": [], "entities": []}, {"text": "(2014) which requires manual selection of flag diacritics and results in slow lookup.", "labels": [], "entities": []}, {"text": "We show that our method gives similar size reductions while maintaining fast lookup without requiring any manual input.", "labels": [], "entities": []}], "introductionContent": [{"text": "Morphological analyzers are commonly implemented as finite state machines (FSM) because finite-state technology enables both fast processing of large amounts of input and manipulation of the analyzer using finite-state algebra.", "labels": [], "entities": [{"text": "Morphological analyzers", "start_pos": 0, "end_pos": 23, "type": "TASK", "confidence": 0.8372304141521454}]}, {"text": "Sometimes finite-state analyzers may, however, become quite large.", "labels": [], "entities": []}, {"text": "This can be a problem e.g. when analyzers are used on mobile devices where a moderate memory footprint is required.", "labels": [], "entities": []}, {"text": "The usual way to reduce the size of FSMs is to use a minimization algorithm.", "labels": [], "entities": [{"text": "FSMs", "start_pos": 36, "end_pos": 40, "type": "TASK", "confidence": 0.831781268119812}]}, {"text": "Minimization can have a substantial effect on the size of the FSM but, as it is only able to combine suffix-equivalent states, there may still be residual redundancy in the state space of the machine.", "labels": [], "entities": [{"text": "FSM", "start_pos": 62, "end_pos": 65, "type": "TASK", "confidence": 0.6586659550666809}]}, {"text": "Further size reduction can be accomplished by introducing a limited form of context-free structure into the finite-state graph using special symbols called flag diacritics.", "labels": [], "entities": []}, {"text": "Using flag diacritics, it is possible to combine sub-graphs which are equivalent, i.e. accept the same strings, but which are not necessarily suffix-equivalent.", "labels": [], "entities": []}, {"text": "Flag diacritics are used to couple entrance points of the sub-graphs with appropriate exit points.", "labels": [], "entities": []}, {"text": "During lookup, paths whose flag diacritics do not match are filtered out.", "labels": [], "entities": []}, {"text": "Thus, the original language of the machine is preserved.", "labels": [], "entities": []}, {"text": "Traditionally, the lexicon writer manually inserts flag diacritics into the lexicon of the morphological analyzer.", "labels": [], "entities": []}, {"text": "There are two major problems with this approach: (1) In practice, manually inserted flag diacritics often do not result in great size reduction because many lexicon writers have poor understanding of the structure of the finite-state networks built from lexicographicalmorphological descriptions; (2) The addition of flag diacritics to these descriptions makes them unreadable and unmanageable since the amount of non-linguistic data in the linguistic description increases.", "labels": [], "entities": []}, {"text": "This paper introduces an automated method for inducing flag diacritics into finite-state morphological analyzers based on the Xerox lexc formalism.", "labels": [], "entities": []}, {"text": "We refine an earlier approach by, which requires manual selection of flag diacritics, to obtain substantial size reduction.", "labels": [], "entities": []}, {"text": "We show that our approach achieves similar reductions in size, but with a fully automated process.", "labels": [], "entities": []}, {"text": "Moreover, the approach presented in this paper is conceptually simpler and faster because, unlike, we do not need additional processing after applying phonological rules.", "labels": [], "entities": []}, {"text": "Additionally, our approach results in substantially improved lookup speed compared to due to an operation which we call path condensation.", "labels": [], "entities": []}, {"text": "We apply our approach to morphological analyzers for three morphologically complex languages: Greenlandic, North Saami, and Finnish.", "labels": [], "entities": [{"text": "morphological analyzers", "start_pos": 25, "end_pos": 48, "type": "TASK", "confidence": 0.7239139378070831}]}, {"text": "Compared to, our approach results in near equal size reduction for these languages without requiring any manual intervention.", "labels": [], "entities": []}, {"text": "Furthermore, due to path condensation introduced in Section 3.3, lookup time is reduced for all three languages and because of the new lexc approach, compilation time is reduced for all languages.", "labels": [], "entities": []}], "datasetContent": [{"text": "We performed experiments using three full scale open-source morphological analyzers distributed by the Giellatekno project 2 . We used the analyzers for Finnish (fin), Greenlandic (kal) and Northern Sami (sme) available from the Giellatakno repos-itory 3 . For compilation we use the Helsinki Finite State Transducer (HFST) library and tools).", "labels": [], "entities": []}, {"text": "We compile the morphological analyzers in three different ways \u2022 Basic compilation without joiner symbols.", "labels": [], "entities": []}, {"text": "\u2022 Compilation using hyper-minimization and path condensation.", "labels": [], "entities": []}, {"text": "For each compilation method, we report results on \u2022 Compilation time.", "labels": [], "entities": []}, {"text": "\u2022 Size of the final morphological analyzer.", "labels": [], "entities": [{"text": "morphological analyzer", "start_pos": 20, "end_pos": 42, "type": "TASK", "confidence": 0.624711349606514}]}, {"text": "\u2022 Lookup speed of the final morphological an- alyzer.", "labels": [], "entities": [{"text": "Lookup speed", "start_pos": 2, "end_pos": 14, "type": "METRIC", "confidence": 0.8859991431236267}]}, {"text": "Lookup speed is tested using continuous text spanning tens of thousands of words for each language.", "labels": [], "entities": []}, {"text": "All experiments were performed on an Intel Core i5-4300U laptop with a dual core 1.90 GHz processor and 16 GB of RAM.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Results of experiments. The columns de- note (1) compilation without hyper-minimization  (None), (2) with hyper-minimization (H-M) and  (3) hyper-minimization together with path con- densation (H-M + PC). The rows denote (1) com- pilation time, (2) fst binary size, (3) fst lookup  speed (as thousands of words per second) and", "labels": [], "entities": [{"text": "fst lookup  speed", "start_pos": 280, "end_pos": 297, "type": "METRIC", "confidence": 0.6908258100350698}]}]}