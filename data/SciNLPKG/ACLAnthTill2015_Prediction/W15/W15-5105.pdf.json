{"title": [{"text": "Synthesizing and Evaluating Animations of American Sign Language Verbs Modeled from Motion-Capture Data", "labels": [], "entities": [{"text": "Synthesizing and Evaluating Animations of American Sign Language Verbs Modeled from Motion-Capture", "start_pos": 0, "end_pos": 98, "type": "TASK", "confidence": 0.823877714574337}]}], "abstractContent": [{"text": "Animations of American Sign Language (ASL) can make information accessible for many signers with lower levels of English literacy.", "labels": [], "entities": [{"text": "Animations of American Sign Language (ASL)", "start_pos": 0, "end_pos": 42, "type": "TASK", "confidence": 0.5629376657307148}]}, {"text": "Automatically synthesizing such animations is challenging because the movements of ASL signs often depend on the context in which they appear, e.g., many ASL verb movements depend on locations in the signing space the signer has associated with the verb's subject and object.", "labels": [], "entities": []}, {"text": "This paper presents several techniques for automatically synthesizing novel instances of ASL verbs whose motion-path and hand-orientation must accurately reflect the subject and object locations in 3D space, including enhancements to to prior state-of-the-art models.", "labels": [], "entities": []}, {"text": "Using these models, animation generation software could produce an infinite variety of indicating verb instances.", "labels": [], "entities": [{"text": "animation generation", "start_pos": 20, "end_pos": 40, "type": "TASK", "confidence": 0.7762323319911957}]}, {"text": "Using a corpus of motion-capture recordings of multiple performances of eight ASL indicating verbs, we modeled the signer's hand locations and orientations during each verb, dependent upon the location in the signing space where the subject and object were positioned.", "labels": [], "entities": []}, {"text": "Ina user study, ASL signers watched animations that included verbs synthesized from these models, and we found that they had similar quality to those produced by a human animator.", "labels": [], "entities": []}], "introductionContent": [{"text": "This paper describes technologies for automating the creation of animations of American Sign Language (ASL), which is a natural language that consists of movements of the hands, body, head, and face.", "labels": [], "entities": [{"text": "American Sign Language (ASL)", "start_pos": 79, "end_pos": 107, "type": "TASK", "confidence": 0.5403516888618469}]}, {"text": "ASL is the primary means of communication for over 500,000 people in the United States.", "labels": [], "entities": [{"text": "ASL", "start_pos": 0, "end_pos": 3, "type": "TASK", "confidence": 0.9701653122901917}]}, {"text": "ASL is a natural language, and the grammar, word-order, and vocabulary of the language is distinct from English.", "labels": [], "entities": [{"text": "ASL", "start_pos": 0, "end_pos": 3, "type": "TASK", "confidence": 0.9016432762145996}]}, {"text": "For various language-exposure and educational reasons, many deaf adults have lower literacy levels.", "labels": [], "entities": []}, {"text": "In fact, standardized testing suggests that the majority of deaf high school graduates in the U.S. (typically students age 18) have a fourth-grade reading level or below (typically students age 10).", "labels": [], "entities": []}, {"text": "Given these literacy trends, when English text is presented online, the text may sometimes be too difficult for many of these users.", "labels": [], "entities": []}, {"text": "Conveying information content through videos or animations of ASL could make information more accessible.", "labels": [], "entities": []}, {"text": "As discussed in, because a human signer must be refilmed, videos are ill-suited to contexts where the information: is often modified, might require later corrections, is generated automatically in response to a query, or is produced by automatic translation technologies.", "labels": [], "entities": []}, {"text": "Animations of sign language that are produced automatically from an easy-toupdate script can overcome these limitations and make it easier to incorporate ASL content on websites or other media.", "labels": [], "entities": []}, {"text": "A challenge is that ASL signs must be \"customized\" so that they are performed in a specific manner that matches how the signer has setup locations around their body to represent entities under discussion.", "labels": [], "entities": [{"text": "ASL signs", "start_pos": 20, "end_pos": 29, "type": "TASK", "confidence": 0.925302267074585}]}, {"text": "This paper focuses on a ubiquitous class of ASL verbs, called \"indicating verbs,\" and it describes research on technologies to automatically produce understandable animations of these verbs for use in ASL animations, with an ultimate goal of increasing information accessibility for users who are deaf.", "labels": [], "entities": [{"text": "ASL animations", "start_pos": 201, "end_pos": 215, "type": "TASK", "confidence": 0.936453640460968}]}], "datasetContent": [{"text": "A user study was conducted to evaluate animations synthesized by our point-based model and by our vector-based model, trained on the recorded data of the eight ASL verbs.", "labels": [], "entities": []}, {"text": "The overall methodology of this study, including the recruiting practices, format of comprehension questions, and other details follows the general approach used in prior ASL evaluation research, e.g.,.", "labels": [], "entities": [{"text": "ASL evaluation", "start_pos": 171, "end_pos": 185, "type": "TASK", "confidence": 0.9423249661922455}]}, {"text": "Of the 24 participants, 13 had used ASL since infancy, 6 participants had learned ASL before age 8, and 2 participants began using ASL at a school with primary instruction in ASL since age 10.", "labels": [], "entities": []}, {"text": "The remaining 3 participants identified as deaf, attended schools and university with instruction in ASL, and had spouses or partners with whom they used ASL on a daily basis.", "labels": [], "entities": [{"text": "ASL", "start_pos": 101, "end_pos": 104, "type": "TASK", "confidence": 0.9609568119049072}]}, {"text": "There were 17 men and 7 women of ages 24-58 (median age 33).", "labels": [], "entities": []}, {"text": "The experiment consisted of two phases: In phase 1 of the study, we used a set of 12 ASL stories and comprehension questions that we designed and produced as stimuli.", "labels": [], "entities": [{"text": "ASL stories and comprehension questions", "start_pos": 85, "end_pos": 124, "type": "TASK", "confidence": 0.8472827315330506}]}, {"text": "The stories and questions were adapted from those used in for use in this current study; the stories were edited so that they included the eight ASL verbs listed in.", "labels": [], "entities": []}, {"text": "The animations consisted of a single onscreen virtual human character, who tells a story about 3-4 characters, who are associated with different arc-positions in the signing space surrounding the virtual signer.", "labels": [], "entities": []}, {"text": "The 12 stories and their questions were designed so that the questions related to information conveyed by a specific verb in the story.", "labels": [], "entities": []}, {"text": "The comprehension questions were difficult to answer because of the stories' complexity, because participants saw the story before seeing the questions, and because they could only view the story onetime.", "labels": [], "entities": []}, {"text": "Each story was produced in four different versions, based on the form of the verb used in the animation: \u2022 PointModel: inflected verb using our point-based model \u2022 VectorModel: inflected verb using vector-based model \u2022 Animator: inflected verb produced by a human animator \u2022 Uninflected: uninflected citation-form of the verb It is important to note that all of the animations presented were grammatical, including the Uninflected stimuli.", "labels": [], "entities": []}, {"text": "As described in section 1.1, verbs in ASL do not require spatial inflection during sentences, so long as the identity of the subject and object is otherwise indicated in the sentence.", "labels": [], "entities": [{"text": "ASL", "start_pos": 38, "end_pos": 41, "type": "TASK", "confidence": 0.9495155215263367}]}, {"text": "The animations presented in this study included in this information in the form of noun phrases or pointing pronouns in each sentence, identifying the subject and object.", "labels": [], "entities": []}, {"text": "So, there were no nongrammatical sentences shown to participants in the study.", "labels": [], "entities": []}, {"text": "Section 3.2 mentions how the orientation model of the vectorbased model is identical to the orientation model of the pointbased model, so, the hand orientations in these two types of animation are identical -only the locations of the hands differ.", "labels": [], "entities": []}, {"text": "In this within-subjects study design: \u2022 No participant saw the same story twice.", "labels": [], "entities": []}, {"text": "\u2022 The order of presentation of each story was randomized.", "labels": [], "entities": []}, {"text": "\u2022 Each participant saw 3 animations of each version.", "labels": [], "entities": []}, {"text": "(a) (b): Example of ASL verb COPY produced by the vector model, as it appears in the study shows example images for the verb COPY, produced by the vector model, as it appeared in a story during the study.", "labels": [], "entities": [{"text": "ASL verb COPY produced", "start_pos": 20, "end_pos": 42, "type": "TASK", "confidence": 0.8560109734535217}]}, {"text": "In this example, the animated signer described a story in which several students (set up at locations in the signing space) were working on homework, and one student copied another student's homework.", "labels": [], "entities": []}, {"text": "One of the comprehension questions for this story asked which of the students copied the homework.", "labels": [], "entities": []}, {"text": "Animation examples from this study maybe accessed here: http://latlab.ist.rit.edu/slpat2015/: Verbs collected in the training data set and which appear in the stimuli in study in section 4.", "labels": [], "entities": []}, {"text": "After watching each story once, participants answered 4 multiple-choice comprehension questions that focused on information conveyed by the indicating verbs.", "labels": [], "entities": []}, {"text": "This study followed the methodological details of prior ASL animation research studies, as described in. shows the comprehension question accuracy scores.", "labels": [], "entities": [{"text": "ASL animation", "start_pos": 56, "end_pos": 69, "type": "TASK", "confidence": 0.9742718040943146}, {"text": "accuracy", "start_pos": 138, "end_pos": 146, "type": "METRIC", "confidence": 0.6700962781906128}]}, {"text": "A Kruskal-Wallis test (alpha=0.05) was run to check for significant differences between comprehension scores for each version of the animations.", "labels": [], "entities": []}, {"text": "Only one pair of values had a significant difference (marked with a star in the.", "labels": [], "entities": []}, {"text": "In phase 2, participants viewed four animations of the same sentence side-by-side; e.g., \"John point_to_arc_position_0.9 ASK Mary point_to_arc_position_-0.6.\"", "labels": [], "entities": []}, {"text": "(Arc position 0.9 is on the signer's far right side, and arc position -0.6 is on the signer's left side.)", "labels": [], "entities": [{"text": "Arc position 0.9", "start_pos": 1, "end_pos": 17, "type": "METRIC", "confidence": 0.9285435676574707}, {"text": "arc position -0.6", "start_pos": 57, "end_pos": 74, "type": "METRIC", "confidence": 0.959957480430603}]}, {"text": "The only difference between the four versions that were displayed on the screen was whether the verb in the sentence was: (a) synthesized from our point-based model, (b) synthesized from our vector-based model, (c) created by a human animator, or (d) an uninflected version of the verb.", "labels": [], "entities": []}, {"text": "Participants could re-play the animations multiple times, and a variety of arc-positions were used in the animations (the four versions shown atone time all used the same arc-positions).", "labels": [], "entities": []}, {"text": "Participants answered 1-to-10 Likertscale questions about the quality of the verb in each of the 3 versions of the sentence.", "labels": [], "entities": [{"text": "Likertscale", "start_pos": 30, "end_pos": 41, "type": "METRIC", "confidence": 0.9141705632209778}]}, {"text": "To check for significant differences between Likert-scale scores for each version, a Kruskal-Wallis test (alpha=0.05) was performed; significant pairwise differences are marked with a star.", "labels": [], "entities": []}], "tableCaptions": []}