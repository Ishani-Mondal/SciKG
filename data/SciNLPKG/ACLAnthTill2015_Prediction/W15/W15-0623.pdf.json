{"title": [{"text": "Judging the Quality of Automatically Generated Gap-fill Question using Active Learning", "labels": [], "entities": []}], "abstractContent": [{"text": "In this paper, we propose to use active learning for training classifiers to judge the quality of gap-fill questions.", "labels": [], "entities": []}, {"text": "Gap-fill questions are widely used for assessments in education contexts because they can be graded automatically while offering reliable assessment of learners' knowledge level if appropriately calibrated.", "labels": [], "entities": []}, {"text": "Active learning is a machine learning framework which is typically used when unlabeled data is abundant but manual annotation is slow and expensive.", "labels": [], "entities": [{"text": "Active learning", "start_pos": 0, "end_pos": 15, "type": "TASK", "confidence": 0.7486826181411743}]}, {"text": "This is the casein many Natural Language Processing tasks, including automated question generation, which is our focus.", "labels": [], "entities": [{"text": "question generation", "start_pos": 79, "end_pos": 98, "type": "TASK", "confidence": 0.7405653148889542}]}, {"text": "A key task in automated question generation is judging the quality of the generated questions.", "labels": [], "entities": [{"text": "automated question generation", "start_pos": 14, "end_pos": 43, "type": "TASK", "confidence": 0.5947247246901194}]}, {"text": "Classifiers can be built to address this task which typically are trained on human labeled data.", "labels": [], "entities": []}, {"text": "Our evaluation results suggest that the use of active learning leads to accurate classifiers for judging the quality of gap-fill questions while keeping the annotation costs in check.", "labels": [], "entities": []}, {"text": "We are not aware of any previous effort that uses active learning for question evaluation .", "labels": [], "entities": [{"text": "question evaluation", "start_pos": 70, "end_pos": 89, "type": "TASK", "confidence": 0.8183853924274445}]}], "introductionContent": [{"text": "Recent explosion of massive open online courses (MOOCs) such as Coursera and Udacity 2 and the success of Intelligent Tutoring Systems (ITSs), e.g. AutoTutor () and DeepTutor (, at inducing learning gains comparable to human tutors indicate great opportunities for 1 http://www.coursera.org 2 http://www.udacity.com online education platforms.", "labels": [], "entities": [{"text": "Coursera", "start_pos": 64, "end_pos": 72, "type": "DATASET", "confidence": 0.9694275856018066}]}, {"text": "These systems typically deliver knowledge to learners via video streaming or direct interaction with the system, e.g. dialogue based interaction.", "labels": [], "entities": []}, {"text": "If adaptive to individual learners, such online platforms for learning must assess learners' knowledge before, during, and after students' interaction with the platform.", "labels": [], "entities": []}, {"text": "For instance, in order to identify knowledge deficits before and/or after a session a pre-and/or post-test can be used.", "labels": [], "entities": []}, {"text": "The knowledge deficits discovered based on the pre-test can guide the online platform to select appropriate instructional tasks for the learner.", "labels": [], "entities": []}, {"text": "Furthermore, the pre-and post-test can be used to measure the learning gains with the online platform, e.g. by subtractic the pre-test score from the post-test score.", "labels": [], "entities": []}, {"text": "The bottom line is that assessment is critical for adaptive instruction.", "labels": [], "entities": []}, {"text": "Various kinds of questions are used to assess students' knowledge levels varying from True/False questions to multiple choice questions to open answer questions.", "labels": [], "entities": []}, {"text": "Indeed, a main challenge in online learning platforms such as MOOCs and ITSs is test construction (assessment question generation).", "labels": [], "entities": [{"text": "test construction", "start_pos": 80, "end_pos": 97, "type": "TASK", "confidence": 0.7688203752040863}, {"text": "assessment question generation", "start_pos": 99, "end_pos": 129, "type": "TASK", "confidence": 0.6739121278127035}]}, {"text": "Automated test construction is a demanding task requiring significant resources.", "labels": [], "entities": [{"text": "Automated test construction", "start_pos": 0, "end_pos": 27, "type": "TASK", "confidence": 0.7567675312360128}]}, {"text": "Any level of automation in question generation would therefore be very useful for this expensive and time-consuming process.", "labels": [], "entities": []}, {"text": "In fact, it has been proven that computer-assisted test construction can dramatically reduce costs associated with test construction activities ().", "labels": [], "entities": []}, {"text": "Besides test construction, automatic question generation are very useful in several other applications such as reading comprehension), vocabulary assessment (), and academic writing(.", "labels": [], "entities": [{"text": "test construction", "start_pos": 8, "end_pos": 25, "type": "TASK", "confidence": 0.7863336205482483}, {"text": "question generation", "start_pos": 37, "end_pos": 56, "type": "TASK", "confidence": 0.7185825854539871}, {"text": "vocabulary assessment", "start_pos": 135, "end_pos": 156, "type": "TASK", "confidence": 0.8885689079761505}]}, {"text": "Consequently, particular attention has been paid by Natural Language Processing (NLP) and educational researchers to automatically generating several types of questions.", "labels": [], "entities": []}, {"text": "Some examples include multiple choice questions (), gap-fill questions and free-response questions (.", "labels": [], "entities": []}, {"text": "The more general problem of question generation has been systematically addressed via shared tasks (.", "labels": [], "entities": [{"text": "question generation", "start_pos": 28, "end_pos": 47, "type": "TASK", "confidence": 0.8011172711849213}]}, {"text": "reported that automatic question construction followed by manual correction is more time-efficient than manual construction of the questions alone.", "labels": [], "entities": [{"text": "question construction", "start_pos": 24, "end_pos": 45, "type": "TASK", "confidence": 0.6894256621599197}]}, {"text": "Automated method for judging the question quality would therefore make the question generation process much more efficient.", "labels": [], "entities": [{"text": "question generation", "start_pos": 75, "end_pos": 94, "type": "TASK", "confidence": 0.7920686900615692}]}, {"text": "To this end, we present in this paper an efficient method to rank gap-fill questions, a key step in generating the questions.", "labels": [], "entities": []}, {"text": "We formulate the problem next.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section we describe our experiments in detail.", "labels": [], "entities": []}], "tableCaptions": []}