{"title": [{"text": "AUT Document Alignment Framework for BUCC Workshop Shared Task", "labels": [], "entities": [{"text": "AUT Document Alignment", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.7987772822380066}, {"text": "BUCC Workshop Shared Task", "start_pos": 37, "end_pos": 62, "type": "DATASET", "confidence": 0.8180763125419617}]}], "abstractContent": [{"text": "This paper presents a framework for aligning comparable documents collection.", "labels": [], "entities": []}, {"text": "Our feature based model is able to consider different characteristics of documents for evaluating their similarities.", "labels": [], "entities": []}, {"text": "The model uses the content of documents while no link, special tag or Metadata are available.", "labels": [], "entities": []}, {"text": "And also we apply a filtering mechanism which made our model to be properly applicable fora large collection of data.", "labels": [], "entities": []}, {"text": "According to the results, our model is able to recognize related documents in the target language with recall of 45.67% for the 1-best and 62% for the 5-best.", "labels": [], "entities": [{"text": "recall", "start_pos": 103, "end_pos": 109, "type": "METRIC", "confidence": 0.999582827091217}]}], "introductionContent": [{"text": "Comparable corpora (CC) are collections of similar documents with different levels of comparability ().", "labels": [], "entities": []}, {"text": "There are useful resources for most of the Natural Language Processing (NLP) or Information Retrieval (IR) tasks such as cross-lingual text mining), bilingual lexicon extraction (, cross-lingual information retrieval) and machine translation ( etc.", "labels": [], "entities": [{"text": "Natural Language Processing (NLP) or Information Retrieval (IR)", "start_pos": 43, "end_pos": 106, "type": "TASK", "confidence": 0.6998764077822367}, {"text": "cross-lingual text mining", "start_pos": 121, "end_pos": 146, "type": "TASK", "confidence": 0.6291856467723846}, {"text": "bilingual lexicon extraction", "start_pos": 149, "end_pos": 177, "type": "TASK", "confidence": 0.6974854071935018}, {"text": "cross-lingual information retrieval", "start_pos": 181, "end_pos": 216, "type": "TASK", "confidence": 0.6342402398586273}, {"text": "machine translation", "start_pos": 222, "end_pos": 241, "type": "TASK", "confidence": 0.8273150324821472}]}, {"text": "The sub-fields of NLP are related to solving human language tasks that are mostly hard problems such as Language Understanding), Machine Translation etc.", "labels": [], "entities": [{"text": "Language Understanding", "start_pos": 104, "end_pos": 126, "type": "TASK", "confidence": 0.7060990631580353}, {"text": "Machine Translation", "start_pos": 129, "end_pos": 148, "type": "TASK", "confidence": 0.8960369229316711}]}, {"text": "The modern algorithms of NLP sub-fields are based on machine learning and statistical approaches.", "labels": [], "entities": []}, {"text": "Most of the developed systems of these fields require large amounts of parallel corpora, as a result the limitation in success of such tasks is the lack of parallel corpora.", "labels": [], "entities": []}, {"text": "In recent researches, it is proven that Comparable Corpora can be a valuable alternative to rare parallel corpora.", "labels": [], "entities": []}, {"text": "Information Retrieval (IR) is \"the act of finding materials, usually documents of an unstructured form that satisfies an information need within large collections stored in computers\").", "labels": [], "entities": [{"text": "Information Retrieval (IR)", "start_pos": 0, "end_pos": 26, "type": "TASK", "confidence": 0.8559787333011627}]}, {"text": "IR is not limited to monolingual documents if the task is related to mapping bilingual or multilingual documents; anew area of IR will be introduced: Cross/Multilingual IR.", "labels": [], "entities": [{"text": "IR", "start_pos": 0, "end_pos": 2, "type": "TASK", "confidence": 0.9679690003395081}]}, {"text": "The idea of Cross-Lingual IR (CLIR) is to retrieve documents in a language different from the language of input text).", "labels": [], "entities": [{"text": "Cross-Lingual IR (CLIR)", "start_pos": 12, "end_pos": 35, "type": "TASK", "confidence": 0.8253661870956421}]}, {"text": "The input text maybe either a query or a document which categorizes the field to document based or query based approaches.", "labels": [], "entities": []}, {"text": "CLIR is away of expanding input queries to other languages.", "labels": [], "entities": []}, {"text": "This is a useful approach in search engines that enables users to formulate queries in their preferred languages and retrieve relevant documents in whatever language they are written.", "labels": [], "entities": []}, {"text": "For this purpose instead of parallel corpora for translating input queries, using comparable corpora might be helpful.", "labels": [], "entities": [{"text": "translating input queries", "start_pos": 49, "end_pos": 74, "type": "TASK", "confidence": 0.8585848808288574}]}, {"text": "However, document based CLIR can be used for producing comparable corpora.", "labels": [], "entities": []}, {"text": "The related works will be reviewed in section 2.", "labels": [], "entities": []}, {"text": "Our Model is a framework consists of different modules.", "labels": [], "entities": []}, {"text": "Each module considers disparate features for matching each source document with the target documents, so we called this a featurebased model.", "labels": [], "entities": []}, {"text": "The pipeline of the modules in our model is shown in.", "labels": [], "entities": []}, {"text": "We assume two similar documents contain same sets of names which occur in the same order.", "labels": [], "entities": []}, {"text": "Name Module of our model is responsible for checking this structure.", "labels": [], "entities": []}, {"text": "In addition, translation of similar texts in the source and target languages must be similar, so we use SMT system as another module in the model.", "labels": [], "entities": [{"text": "SMT", "start_pos": 104, "end_pos": 107, "type": "TASK", "confidence": 0.9681710004806519}]}, {"text": "We also assume similar documents converted to vector representations using neural networks will have shorter Euclidean distance between each other.", "labels": [], "entities": []}, {"text": "This characteristic of similar documents is considered.", "labels": [], "entities": []}, {"text": "The structure of the pipeline model.", "labels": [], "entities": []}, {"text": "To recognize similar conceptual structures in documents we use bilingual topic models.", "labels": [], "entities": []}, {"text": "The problem is aligning source documents to target documents, but because of the amount of data, in addition to similarity concerns, our model is faced to the very large corpora problem.", "labels": [], "entities": []}, {"text": "It is not possible to evaluate each pair of documents in this big space, so we used some of our modules as a filter for decreasing the target space.", "labels": [], "entities": []}, {"text": "From the framework's modules, we choose ones with higher Recall to be sure that our filter is able to recognize and remove wrong samples.", "labels": [], "entities": [{"text": "Recall", "start_pos": 57, "end_pos": 63, "type": "METRIC", "confidence": 0.9979812502861023}]}, {"text": "Another factor for selecting the filtering modules is the execution speed.", "labels": [], "entities": []}, {"text": "Low speed modules are not proper in the model's pipeline.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this phase, we align the documents of test.de set with a proper en document from the collection of English documents.", "labels": [], "entities": []}, {"text": "In the two filtering steps of the model pipeline, we reduce the size of the target space from 313(K) documents to 5(K) documents for each de document.", "labels": [], "entities": []}, {"text": "The first filter is the Doc2Vec module, which is the fastest module in our model.", "labels": [], "entities": []}, {"text": "This filter reduces the target space to 12(K) English documents that are the nearest documents to the de one with 87.6% of accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 123, "end_pos": 131, "type": "METRIC", "confidence": 0.9973646998405457}]}, {"text": "Each de document in the test set is evaluated with the filtered en documents (5K documents).", "labels": [], "entities": []}, {"text": "Then the vector of the similarity scores for each pair is produced and the score of the system combination module is computed for each pair of documents.", "labels": [], "entities": []}, {"text": "The result is a matrix of similarity values.", "labels": [], "entities": []}, {"text": "Finally, for each row of this matrix the 5-best results are extracted.", "labels": [], "entities": []}, {"text": "The precision, recall and F-measure for the 1-best output of the system combination module and the 5-best results list are shown in.", "labels": [], "entities": [{"text": "precision", "start_pos": 4, "end_pos": 13, "type": "METRIC", "confidence": 0.9996092915534973}, {"text": "recall", "start_pos": 15, "end_pos": 21, "type": "METRIC", "confidence": 0.9996824264526367}, {"text": "F-measure", "start_pos": 26, "end_pos": 35, "type": "METRIC", "confidence": 0.9994138479232788}]}, {"text": "Results of our model; Precision, Recall and F-measure for 1-best System Combination and 5-best results list.", "labels": [], "entities": [{"text": "Precision", "start_pos": 22, "end_pos": 31, "type": "METRIC", "confidence": 0.9987114667892456}, {"text": "Recall", "start_pos": 33, "end_pos": 39, "type": "METRIC", "confidence": 0.997178316116333}, {"text": "F-measure", "start_pos": 44, "end_pos": 53, "type": "METRIC", "confidence": 0.9985851049423218}]}, {"text": "The final precision of our model is about 12%, this is because of the variation of the modules votes.", "labels": [], "entities": [{"text": "precision", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9644982814788818}]}, {"text": "Each module considers the en documents from a different view so the 5-best list of the final results contains the most similar en documents to the de input.", "labels": [], "entities": []}, {"text": "But from this list just one of them is the exact translation.", "labels": [], "entities": []}, {"text": "Although each Wikipedia page has a specific equivalent page in the target language but, it is probable that a set of pages are highly similar to it, especially for pages with related topics.", "labels": [], "entities": []}, {"text": "So, because of this characteristic of Wikipedia pages, deciding the exact translation just with the content information is a vague task.", "labels": [], "entities": []}, {"text": "Also aligning the de document to a proper en one from a large collection of en samples increases this ambiguity.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1. Statistical information of data.", "labels": [], "entities": []}, {"text": " Table 2. Results of our model; Precision, Recall  and F-measure for 1-best System Combination  and 5-best results list.", "labels": [], "entities": [{"text": "Precision", "start_pos": 32, "end_pos": 41, "type": "METRIC", "confidence": 0.9992202520370483}, {"text": "Recall", "start_pos": 43, "end_pos": 49, "type": "METRIC", "confidence": 0.9977721571922302}, {"text": "F-measure", "start_pos": 55, "end_pos": 64, "type": "METRIC", "confidence": 0.998885452747345}]}]}