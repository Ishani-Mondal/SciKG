{"title": [{"text": "A Discursive Grid Approach to Model Local Coherence in Multi-document Summaries", "labels": [], "entities": [{"text": "Model Local Coherence in Multi-document Summaries", "start_pos": 30, "end_pos": 79, "type": "TASK", "confidence": 0.669194092353185}]}], "abstractContent": [{"text": "Multi-document summarization is a very important area of Natural Language Processing (NLP) nowadays because of the huge amount of data in the web.", "labels": [], "entities": [{"text": "Multi-document summarization", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.8005836308002472}, {"text": "Natural Language Processing (NLP)", "start_pos": 57, "end_pos": 90, "type": "TASK", "confidence": 0.7189637919267019}]}, {"text": "People want more and more information and this information must be coherently organized and summarized.", "labels": [], "entities": []}, {"text": "The main focus of this paper is to deal with the coherence of multi-document summaries.", "labels": [], "entities": []}, {"text": "Therefore, a model that uses discursive information to automatically evaluate local coherence in multi-document summaries has been developed.", "labels": [], "entities": []}, {"text": "This model obtains 92.69% of accuracy in distinguishing coherent from incoherent summaries, outperforming the state of the art in the area.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 29, "end_pos": 37, "type": "METRIC", "confidence": 0.9996395111083984}]}], "introductionContent": [{"text": "In text generation systems (as summarizers, question-answering systems, etc.), coherence is an essential characteristic in order to produce comprehensible texts.", "labels": [], "entities": [{"text": "text generation", "start_pos": 3, "end_pos": 18, "type": "TASK", "confidence": 0.7194780111312866}]}, {"text": "As such, studies and theories on coherence,) have supported applications that involve text generation (,), ().", "labels": [], "entities": [{"text": "text generation", "start_pos": 86, "end_pos": 101, "type": "TASK", "confidence": 0.7607933580875397}]}, {"text": "According to, Multi-document Summarization (MDS) is the task of automatically producing a unique summary from a set of source texts on the same topic.", "labels": [], "entities": [{"text": "Multi-document Summarization (MDS)", "start_pos": 14, "end_pos": 48, "type": "TASK", "confidence": 0.8676328659057617}]}, {"text": "In MDS, local coherence is as important as informativity.", "labels": [], "entities": []}, {"text": "A summary must contain relevant information but also present it in a coherent, readable and understandable way.", "labels": [], "entities": []}, {"text": "Coherence is the possibility of establishing a meaning for the text ().", "labels": [], "entities": []}, {"text": "Coherence supposes that there are relationships among the elements of the text for it to make sense.", "labels": [], "entities": []}, {"text": "It also involves aspects that are out of the text, for example, the shared knowledge between the producer (writer) and the receiver (reader/listener) of the text, inferences, intertextuality, intentionality and acceptability, among others (.", "labels": [], "entities": []}, {"text": "Textual coherence occurs in local and global levels.", "labels": [], "entities": []}, {"text": "Local level coherence is presented by the local relationship among the parts of a text, for instance, sentences and shorter sequences.", "labels": [], "entities": []}, {"text": "On the other hand, a text presents global coherence when this text links all its elements as a whole.", "labels": [], "entities": []}, {"text": "Psycholinguistics consider that local coherence is essential in order to achieve global coherence.", "labels": [], "entities": []}, {"text": "The main phenomena that affect coherence in multi-document summaries are redundant, complementary and contradictory information.", "labels": [], "entities": []}, {"text": "These phenomena may occur because the information contained in the summaries possibly come from different sources that narrate the same topic.", "labels": [], "entities": []}, {"text": "Thus, a good multidocument summary should a) not contain redundant information, b) properly link and order complementary information, and c) avoid or treat contradictory information.", "labels": [], "entities": []}, {"text": "In this context, we present, in this paper, a discourse-based model for capturing the above properties and distinguishing coherent from incoherent (or less coherent) multi-document summaries.", "labels": [], "entities": []}, {"text": "Cross-document Structure Theory (CST)) and Rhetorical Structure Theory (RST) () relations are used to create the discursive model.", "labels": [], "entities": [{"text": "Rhetorical Structure Theory (RST)", "start_pos": 43, "end_pos": 76, "type": "TASK", "confidence": 0.6945267071326574}]}, {"text": "RST considers that each text presents an underlying rhetorical structure that allows the recovery of the writer\"s communicative intention.", "labels": [], "entities": [{"text": "RST", "start_pos": 0, "end_pos": 3, "type": "TASK", "confidence": 0.8838297128677368}]}, {"text": "RST relations are structured in the form of a tree, where Elementary Discourse Units (EDUs) are located in the leaves of this tree.", "labels": [], "entities": [{"text": "RST relations", "start_pos": 0, "end_pos": 13, "type": "TASK", "confidence": 0.912327229976654}]}, {"text": "CST, in turn, organizes multiple texts on the same topic and establishes relations among different textual segments.", "labels": [], "entities": [{"text": "CST", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.8326734304428101}]}, {"text": "In particular, this work is based on the following assumptions: (i) there are transition patterns of discursive relations (CST and RST) in locally coherent summaries; (ii) and coherent summaries show certain distinct intra-and interdiscursive relation organization (),,).", "labels": [], "entities": []}, {"text": "The model we propose aims at incorporating such issues, learning summary discourse organization preferences from corpus.", "labels": [], "entities": []}, {"text": "This paper is organized as follows: in Section 2, it is presented an overview of the most relevant researches related to local coherence; Section 3 details the proposed approach in this paper; Section 4 shows the experimental setup and the obtained results; finally, Section 5 presents some final remarks.", "labels": [], "entities": []}, {"text": "used Latent Semantic Analysis (LSA)) to compute a coherence value for texts.", "labels": [], "entities": []}, {"text": "LSA produces a vector for each word or sentence, so that the similarity between two words or two sentences maybe measured by their cosine.", "labels": [], "entities": []}, {"text": "The coherence value of a text maybe obtained by the cosine measures for all pairs of adjacent sentences.", "labels": [], "entities": []}, {"text": "With this statistical approach, the authors obtained 81% and 87.3% of accuracy applied to the earthquakes and accidents corpus from North American News Corpus 1 , respectively.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 70, "end_pos": 78, "type": "METRIC", "confidence": 0.9997151494026184}, {"text": "earthquakes and accidents corpus from North American News Corpus 1", "start_pos": 94, "end_pos": 160, "type": "DATASET", "confidence": 0.7845010071992874}]}, {"text": "proposed to deal with local coherence with an Entity Grid Model.", "labels": [], "entities": []}, {"text": "This model is based on Centering Theory (, whose assumption is that locally coherent texts present certain regularities concerning entity distribution.", "labels": [], "entities": []}, {"text": "These regularities are calculated over an Entity Grid, i.e., a matrix in which the rows represent the sentences of the text and the columns the text entities.", "labels": [], "entities": []}, {"text": "For example, shows part of the Entity Grid for the text in.", "labels": [], "entities": [{"text": "Entity Grid", "start_pos": 31, "end_pos": 42, "type": "DATASET", "confidence": 0.8163568675518036}]}, {"text": "For instance, the \"Depart.\"", "labels": [], "entities": []}, {"text": "(Department) column in the grid shows that the entity \"Department\" only happens in the first sentence in the Subject (S) position.", "labels": [], "entities": []}, {"text": "Analogously, the marks O and X indicate the syntactical functions \"Object\" and \"other syntactical functions\" that are neither subject nor object, respectively.", "labels": [], "entities": []}, {"text": "The hyphen (\"-\") indicates that the entity did not happen in the corresponding sentence.", "labels": [], "entities": []}], "datasetContent": [{"text": "The text-ordering task from was used to evaluate the performance of the proposed model and to compare it with other methods in literature.", "labels": [], "entities": []}, {"text": "The corpus used was the CSTNews 2 from.", "labels": [], "entities": [{"text": "CSTNews 2", "start_pos": 24, "end_pos": 33, "type": "DATASET", "confidence": 0.9354430437088013}]}, {"text": "This corpus has been created for multi-document summarization.", "labels": [], "entities": [{"text": "multi-document summarization", "start_pos": 33, "end_pos": 61, "type": "TASK", "confidence": 0.6151878535747528}]}, {"text": "It is composed of 140 texts distributed in 50 sets of news texts written in Brazilian Portuguese from various domains.", "labels": [], "entities": []}, {"text": "Each set has 2 or 3 texts from different sources that address the same topic.", "labels": [], "entities": []}, {"text": "Besides the original texts, the corpus has several annotation layers: (i) CST and RST manual annotations; (ii) the identification of temporal expressions; (iii) automatic syntactical analyses; (iv) noun and verb senses; (v) text-summary alignments; and (vi) the semantic annotation of informative aspects in summaries; among others.", "labels": [], "entities": [{"text": "identification of temporal expressions", "start_pos": 115, "end_pos": 153, "type": "TASK", "confidence": 0.8115113228559494}, {"text": "text-summary alignments", "start_pos": 224, "end_pos": 247, "type": "TASK", "confidence": 0.6682692021131516}]}, {"text": "For this work, the CST and RST annotations have been used.", "labels": [], "entities": [{"text": "CST", "start_pos": 19, "end_pos": 22, "type": "DATASET", "confidence": 0.9023034572601318}]}, {"text": "Originally, the CSTNews corpus had one extractive multi-document summary for each set of texts.", "labels": [], "entities": [{"text": "CSTNews corpus", "start_pos": 16, "end_pos": 30, "type": "DATASET", "confidence": 0.8655916154384613}]}, {"text": "However, Dias et al (2014a) produced 5 more extractive multi-document summaries for each set of texts.", "labels": [], "entities": []}, {"text": "Now, the corpus has 6 reference extractive multi-document summaries for each set of texts.", "labels": [], "entities": []}, {"text": "In this work, 251 reference multidocument extracts (with average size of 6.5 sentences) and 20 permutations for each one (totalizing 5020 summaries) were used in the experiments.", "labels": [], "entities": []}, {"text": "Besides the proposed model, some other methods from the literature have also been reimplemented in order to compare our results to the current state of the art.", "labels": [], "entities": []}, {"text": "The following methods were chosen based on their importance and on the techniques used to evaluate local coher-ence: the LSA method of, the Entity Grid Model of, the Graph Model of, the Shallow RST Model of, the RST Model of and the Entity-based Model with CST bool of Castro.", "labels": [], "entities": []}, {"text": "The LSA method, Entity Grid, Graph and Shallow RST Models were adapted to Brazilian Portuguese, using the appropriate available tools and resources for this language, as the PALAVRAS parser) that was used to identify the summary entities, which are all nouns and proper nouns.", "labels": [], "entities": []}, {"text": "The implementation of these methods carefully followed each step of the original ones.", "labels": [], "entities": []}, {"text": "Barzilay and Lapata\"s method has been implemented without coreference information, since, to the best of our knowledge, there is no robust coreference resolution system available for Brazilian Portuguese, and the CSTNews corpus still does not have referential information in its annotation layers.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 139, "end_pos": 161, "type": "TASK", "confidence": 0.7252819538116455}, {"text": "CSTNews corpus", "start_pos": 213, "end_pos": 227, "type": "DATASET", "confidence": 0.9086032509803772}]}, {"text": "Furthermore, the implementation of Barzilay and Lapata\"s approach produced 4 models: with syntax and salience information (referred by Syntactic+Salience+), with syntax but without salience information (Syntactic+Salience-), with salience information but without syntax (Syntactic-Salience+), and without syntax and salience information (Syntactic-Salience-), in which salience distinguishes entities with frequency higher or equal to 2.", "labels": [], "entities": []}, {"text": "The Full RST Approach is similar to, and then it was not used in these experiments.", "labels": [], "entities": [{"text": "RST Approach", "start_pos": 9, "end_pos": 21, "type": "TASK", "confidence": 0.47313593327999115}]}, {"text": "Lin et al.\"s model (2011) was not used in the experiments, since the CSTNews corpus does not have the PDTB-style discursive relations annotated.", "labels": [], "entities": [{"text": "CSTNews corpus", "start_pos": 69, "end_pos": 83, "type": "DATASET", "confidence": 0.9390721619129181}]}, {"text": "However, according to, the PDTB-style discursive relations encode only very shallow discursive structures, i.e., the relations are mostly local, e.g., within a single sentence or between two adjacent sentences.", "labels": [], "entities": []}, {"text": "Due to this, the Shallow RST Model from, which behaves as, was used in these experiments.", "labels": [], "entities": []}, {"text": "shows the accuracy of our approach compared to the other methods, ordered by accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9996849298477173}, {"text": "accuracy", "start_pos": 77, "end_pos": 85, "type": "METRIC", "confidence": 0.9993581175804138}]}], "tableCaptions": []}