{"title": [], "abstractContent": [{"text": "Understanding contextual information is key to detecting metaphors in discourse.", "labels": [], "entities": []}, {"text": "Most current work aims at detecting metaphors given a single sentence, thus focusing mostly on local contextual cues within a short text.", "labels": [], "entities": [{"text": "detecting metaphors", "start_pos": 26, "end_pos": 45, "type": "TASK", "confidence": 0.8554218709468842}]}, {"text": "In this paper, we present a novel approach that explicitly leverages global context of a discourse to detect metaphors.", "labels": [], "entities": []}, {"text": "In addition, we show that syntactic information such as dependency structures can help better describe local contextual information, thus improving detection results when combined.", "labels": [], "entities": []}, {"text": "We apply our methods on a newly annotated online discussion forum, and show that our approach outperforms the state-of-the-art baselines in previous literature.", "labels": [], "entities": []}], "introductionContent": [{"text": "Detecting metaphors in text is an active line of research which has attracted attention in recent years.", "labels": [], "entities": [{"text": "Detecting metaphors in text", "start_pos": 0, "end_pos": 27, "type": "TASK", "confidence": 0.9377338588237762}]}, {"text": "To date, most of the previous literature has looked at lexical semantic features such as selectional restriction violations) or contrast in lexical concreteness and abstractness.", "labels": [], "entities": []}, {"text": "While these approaches have been shown to be successful in detecting metaphors given a single sentence, metaphor detection in discourse brings anew dimension to the task.", "labels": [], "entities": [{"text": "metaphor detection", "start_pos": 104, "end_pos": 122, "type": "TASK", "confidence": 0.7653117775917053}]}, {"text": "Consider the following excerpt from an online Breast Cancer discussion forum as an example: welcome, glad for the company ....", "labels": [], "entities": [{"text": "Breast Cancer discussion forum", "start_pos": 46, "end_pos": 76, "type": "TASK", "confidence": 0.49476176500320435}]}, {"text": "just sad to see that there are so many of us.", "labels": [], "entities": []}, {"text": "Here is a thought that I have been thinking since I was diagnosed.", "labels": [], "entities": []}, {"text": "This disease should be called the \"Hurry up and Wait\" illness.", "labels": [], "entities": [{"text": "Hurry up and Wait\"", "start_pos": 35, "end_pos": 53, "type": "TASK", "confidence": 0.5170945525169373}]}, {"text": "Since the day I heard the dreaded words \"you need to have a biopsy\", I feel like I am on a speeding train.", "labels": [], "entities": []}, {"text": "It rushes into every station where you have to make instant decisions, while this ominous clock is ticking.", "labels": [], "entities": []}, {"text": "Wait for test results, wait for appointments, wait for healing.", "labels": [], "entities": []}, {"text": "In the example above, it is difficult to identify \"rushes into every station\" as a metaphorical expression using the previous approaches, because it does not violate selectional restrictions or have any notable contrast in lexical concreteness and abstractness.", "labels": [], "entities": []}, {"text": "The reason for this is clear: the action of rushing into stations itself makes perfect sense literally when it is viewed locally as an isolated phrase, while the contextual cues for this metaphor are embedded globally throughout the discourse (e.g. diagonsed, disease, biopsy are semantically contrasted with train, rushes, and station).", "labels": [], "entities": []}, {"text": "This clearly demonstrates the need fora new set of computational tools to represent context beyond a single sentence, in order to better detect metaphorical expressions that have contextual connections outside the sentence in which they are used.", "labels": [], "entities": []}, {"text": "Metaphor is a semantic phenomenon that describes objects often with a view borrowed from a different domain.", "labels": [], "entities": []}, {"text": "As such, it is natural that metaphors inherently break the lexical coherence of a sentence or a discourse., for example, showed in their study that words related to the topic of discussion are less likely to be metaphorical than other words in text, implying that contextual incoherence might serve as a cue for detecting metaphors.", "labels": [], "entities": []}, {"text": "Based on this observation, the idea of leveraging textual context to detect metaphors has been recently proposed by some researchers ().", "labels": [], "entities": []}, {"text": "We extend the previous approaches for detecting metaphors by explicitly addressing the global discourse context, as well as by representing the local context of a sentence in a more robust way.", "labels": [], "entities": [{"text": "detecting metaphors", "start_pos": 38, "end_pos": 57, "type": "TASK", "confidence": 0.9078889489173889}]}, {"text": "Our contribution is thus twofold: first, we propose several textual descriptors that can capture global contextual shifts among a discourse, such as semantic word category distribution obtained from a framesemantic parser, homogeneity in topic distributions, and lexical chains.", "labels": [], "entities": []}, {"text": "Second, we show that global and local contextual information are complimentary in detecting metaphors, and that leveraging syntactic features is crucial in better describing lexico-semantic information in a local context.", "labels": [], "entities": []}, {"text": "Our method achieves higher performance on a metaphor disambiguation task than state-ofthe-art systems from prior work () on our newly created dataset from an online discussion forum.", "labels": [], "entities": [{"text": "metaphor disambiguation task", "start_pos": 44, "end_pos": 72, "type": "TASK", "confidence": 0.8619773586591085}]}, {"text": "The rest of the paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 relates our work to prior work.", "labels": [], "entities": []}, {"text": "Section 3 explains our method in detail, specifically in regards to how we use global context and local context for metaphor detection.", "labels": [], "entities": [{"text": "metaphor detection", "start_pos": 116, "end_pos": 134, "type": "TASK", "confidence": 0.9585635960102081}]}, {"text": "Section 4 describes the Breast Cancer dataset annotated and used for our experiment.", "labels": [], "entities": [{"text": "Breast Cancer dataset annotated", "start_pos": 24, "end_pos": 55, "type": "DATASET", "confidence": 0.7586316168308258}]}, {"text": "In Section 5, we present our experimental results and show the effectiveness of our method with the task of metaphor disambiguation.", "labels": [], "entities": [{"text": "metaphor disambiguation", "start_pos": 108, "end_pos": 131, "type": "TASK", "confidence": 0.8707692623138428}]}, {"text": "Section 6 analyzes the results and identifies potential areas of improvement, and we give our concluding remarks in Section 7.", "labels": [], "entities": []}], "datasetContent": [{"text": "We evaluate our method on a metaphor disambiguation task detailed in Section 5.1.", "labels": [], "entities": [{"text": "metaphor disambiguation", "start_pos": 28, "end_pos": 51, "type": "TASK", "confidence": 0.8138995170593262}]}, {"text": "Section 5.2 lists the metrics we used for the evaluation on this test set.", "labels": [], "entities": []}, {"text": "Section 5.3 describes the baselines we compare our method against on these metrics.", "labels": [], "entities": []}, {"text": "We detail our classification settings in Section 5.4 and report our results in Section 5.5.", "labels": [], "entities": []}, {"text": "We report four evaluation metrics: accuracy, precision, recall, and F-score.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 35, "end_pos": 43, "type": "METRIC", "confidence": 0.9995982050895691}, {"text": "precision", "start_pos": 45, "end_pos": 54, "type": "METRIC", "confidence": 0.9985604882240295}, {"text": "recall", "start_pos": 56, "end_pos": 62, "type": "METRIC", "confidence": 0.9983775615692139}, {"text": "F-score", "start_pos": 68, "end_pos": 75, "type": "METRIC", "confidence": 0.998296320438385}]}, {"text": "Accuracy: Accuracy is the percentage of correctly classified instances among all instances.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 0, "end_pos": 8, "type": "METRIC", "confidence": 0.9938316345214844}, {"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9984437823295593}]}, {"text": "Precision: Precision is the percentage of correctly classified instances among instances assigned to a particular class (metaphor or literal) by the model.", "labels": [], "entities": [{"text": "Precision", "start_pos": 0, "end_pos": 9, "type": "METRIC", "confidence": 0.907228946685791}]}, {"text": "Recall: Recall is the percentage of correctly classified instances among all nonliteral or literal instances.", "labels": [], "entities": [{"text": "Recall", "start_pos": 0, "end_pos": 6, "type": "METRIC", "confidence": 0.9471015334129333}, {"text": "Recall", "start_pos": 8, "end_pos": 14, "type": "METRIC", "confidence": 0.9733073711395264}]}, {"text": "Precision and recall are recorded for both metaphorical and literal labels.", "labels": [], "entities": [{"text": "Precision", "start_pos": 0, "end_pos": 9, "type": "METRIC", "confidence": 0.9463974833488464}, {"text": "recall", "start_pos": 14, "end_pos": 20, "type": "METRIC", "confidence": 0.9954547882080078}]}, {"text": "F-score: F-score is the harmonic mean of precision and recall.", "labels": [], "entities": [{"text": "F-score", "start_pos": 0, "end_pos": 7, "type": "METRIC", "confidence": 0.9610888361930847}, {"text": "F-score", "start_pos": 9, "end_pos": 16, "type": "METRIC", "confidence": 0.9859234094619751}, {"text": "precision", "start_pos": 41, "end_pos": 50, "type": "METRIC", "confidence": 0.9985356330871582}, {"text": "recall", "start_pos": 55, "end_pos": 61, "type": "METRIC", "confidence": 0.9955517649650574}]}], "tableCaptions": [{"text": " Table 1: Metaphor use statistics of data used for  MTurk (* indicates metaphor candidates for which  the literal usage is more common than the non- literal one, N: nonliteral use L: literal use).", "labels": [], "entities": [{"text": "MTurk", "start_pos": 52, "end_pos": 57, "type": "TASK", "confidence": 0.7538884878158569}]}, {"text": " Table 3: Performance on metaphor disambiguation task per target word with the best setting ALL-LC.  Note that the performance results on target words candle and spice are not reported because of their small  number of instances.", "labels": [], "entities": [{"text": "metaphor disambiguation task", "start_pos": 25, "end_pos": 53, "type": "TASK", "confidence": 0.8032442132631937}]}]}