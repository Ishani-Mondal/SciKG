{"title": [{"text": "Trimming a consistent OWL knowledge base, relying on linguistic evidence", "labels": [], "entities": [{"text": "OWL knowledge base", "start_pos": 22, "end_pos": 40, "type": "DATASET", "confidence": 0.8304130434989929}]}], "abstractContent": [{"text": "Intuitively absurd but logically consistent sets of statements are common in publicly available OWL datasets.", "labels": [], "entities": [{"text": "OWL datasets", "start_pos": 96, "end_pos": 108, "type": "DATASET", "confidence": 0.9232378602027893}]}, {"text": "This article proposes an original and fully automated method to point at erroneous axioms in a consistent OWL knowledge base, by weakening it in order to improve its compliance with linguistic evidence gathered from natural language texts.", "labels": [], "entities": [{"text": "OWL knowledge base", "start_pos": 106, "end_pos": 124, "type": "DATASET", "confidence": 0.862795372804006}]}, {"text": "A score for evaluating the compliance of subbases of the input knowledge base is proposed, as well as a trimming algorithm to discard potentially erroneous axioms.", "labels": [], "entities": [{"text": "trimming", "start_pos": 104, "end_pos": 112, "type": "TASK", "confidence": 0.9396989345550537}]}, {"text": "The whole approach is evaluated on two real datasets, with automatically retrieved web pages as a linguistic input.", "labels": [], "entities": []}], "introductionContent": [{"text": "As they grow in size, knowledge bases (KBs) tend to contain statements which may make sense individually but, when taken together, violate commonsense intuitions.", "labels": [], "entities": []}, {"text": "As an illustration, consider the following set \u2126 of Description Logics (DL) formulas, issued from DBpedia ( : . \u2126 = { (1) owningCompany(Smithsonian Networks, Smithsonian Institution), (2) doctoralAdvisor(Thaddeus S.C.", "labels": [], "entities": [{"text": "DBpedia", "start_pos": 98, "end_pos": 105, "type": "DATASET", "confidence": 0.9510182738304138}, {"text": "owningCompany(Smithsonian Networks, Smithsonian Institution)", "start_pos": 122, "end_pos": 182, "type": "DATASET", "confidence": 0.8999584317207336}, {"text": "doctoralAdvisor", "start_pos": 188, "end_pos": 203, "type": "DATASET", "confidence": 0.925794243812561}]}, {"text": "Lowe, Smithsonian Institution), (3) doctoralAdvisor(Nick Katz, Bernard Dwork), (4) \u2200doctoralAdvisor.Person, (5) \u2200owningCompany.Company } From (1), (2), (4) and (5), the individual Smithsonian Institution must bean instance of both Company and Person, which may seem counterintuitive, and indeed does not correspond to the overall understanding of these two concepts within DBpedia.", "labels": [], "entities": []}, {"text": "This kind of issue is common among OWL datasets, which should not be a surprise.", "labels": [], "entities": [{"text": "OWL datasets", "start_pos": 35, "end_pos": 47, "type": "DATASET", "confidence": 0.8873996734619141}]}, {"text": "The most conventional way of spotting this kind of errors in OWL is by checking consistency or coherence 1 of the input KB, but negation (or cardinality restriction) is underused in practice.", "labels": [], "entities": [{"text": "consistency", "start_pos": 80, "end_pos": 91, "type": "METRIC", "confidence": 0.9736236333847046}]}, {"text": "As an illustration, according to the LODstats survey tool, which provides statistics about a sample of the Linked Open Data (LOD) cloud, the two most standard OWL constructs expressing negation, namely owl:disjointWith and owl:complementOf, have been observed 333 times and twice respectively, against more that 89 000 occurrences for owl:subClassOf.", "labels": [], "entities": [{"text": "Linked Open Data (LOD) cloud", "start_pos": 107, "end_pos": 135, "type": "DATASET", "confidence": 0.6961617640086583}]}, {"text": "Let us assume that \u2126 is part of a larger KB K, for instance a subset of DBpedia extracted fora specific application, or a set of OWL statements aggregated from multiple sources.", "labels": [], "entities": []}, {"text": "Assume also that there are several other instances of Person and Company according to K and, to keep the example simple, that Smithsonian Institution, Bernard Dwork, doctoralAdvisor, and owningCompany do not appear in K \\\u2126.", "labels": [], "entities": [{"text": "doctoralAdvisor", "start_pos": 166, "end_pos": 181, "type": "DATASET", "confidence": 0.9408670663833618}, {"text": "owningCompany", "start_pos": 187, "end_pos": 200, "type": "DATASET", "confidence": 0.9110783338546753}]}, {"text": "If most instances of Person and Company according to K are respectively human beings and companies, one can expect the term \"the Smithsonian Institution\" to appear with linguistic contexts which tend to characterize terms denoting other instances of Company according to K (e.g. the context \"X was established\"), but not other instances of Person (like \"X was born in\").", "labels": [], "entities": []}, {"text": "Similarly, \"Bernard Dwork\" should appear with contexts which are characteristic of terms denoting other instances of Person according to K.", "labels": [], "entities": []}, {"text": "In other words, by checking the overall compliance of K with some linguistic input, it should be possible to identify some undesirable (Person(Smithsonian Institution)) and desirable (Company(Smithsonian Institution), Person(Bernard Dwork)) consequences of it.", "labels": [], "entities": []}, {"text": "The next problem consists in determining how K can be weakened in order to discard the former, but keep the latter.", "labels": [], "entities": []}, {"text": "Even if one focuses here (for readability) on weakening \u2126 only, there are several options available.", "labels": [], "entities": []}, {"text": "The view adopted here, which is also the most common in the knowledge base debugging literature, is that some axiom(s) of \u2126 should be discarded, but none of them unnecessarily.", "labels": [], "entities": []}, {"text": "Then the only solution in this example consists in discarding (2).", "labels": [], "entities": []}, {"text": "The article investigates the applicability of such a trimming mechanism to moderately large input KBs (up to a few thousand statements), using automatically gathered web pages or snippets as linguistic input.", "labels": [], "entities": []}, {"text": "To our knowledge, this is the first attempt to use linguistic evidence in order to automatically weaken an existing KB instead of extending it.", "labels": [], "entities": []}, {"text": "Section 1 reviews existing works in two closely related fields, KB extraction from texts and KB debugging, whereas section 2 introduces some conventions.", "labels": [], "entities": [{"text": "KB extraction from texts", "start_pos": 64, "end_pos": 88, "type": "TASK", "confidence": 0.9135170727968216}, {"text": "KB debugging", "start_pos": 93, "end_pos": 105, "type": "TASK", "confidence": 0.7503481209278107}]}, {"text": "Section 3 defines a score which evaluates the compliance with the linguistic data of any subbase of the input KB.", "labels": [], "entities": []}, {"text": "Section 4 proposes an algorithm to trim the input KB based on this score.", "labels": [], "entities": []}, {"text": "Section 5 evaluates the approach with two datasets.", "labels": [], "entities": []}], "datasetContent": [{"text": "Both approaches were evaluated with 2 consistent datasets, using a distinct evaluation protocol for each dataset.", "labels": [], "entities": []}, {"text": "The first dataset is an automatically retrieved subset of DBpedia, thematically focused on tourism.", "labels": [], "entities": [{"text": "DBpedia", "start_pos": 58, "end_pos": 65, "type": "DATASET", "confidence": 0.9683108925819397}]}, {"text": "It counts 5721 logical axioms, and 1095 DL named individuals, with relatively simple formulas (the least expressive underlying DL is AL ).", "labels": [], "entities": []}, {"text": "This is an example of a lightweight KB, with a large predominance of ABox axioms (5336 over 5721).", "labels": [], "entities": [{"text": "ABox axioms", "start_pos": 69, "end_pos": 80, "type": "METRIC", "confidence": 0.8713468611240387}]}, {"text": "Additionally, it is a fragment of a large dataset (DBpedia) mainly built out of semi-structured data (Wikipedia infoboxes), but also partly issued from a collaborative effort (the DBpedia ontology), and therefore it is likely to contain nonsensical sets of statements.", "labels": [], "entities": []}, {"text": "The procedure applied to obtain this KB is described in.", "labels": [], "entities": []}, {"text": "In particular, individuals with potential homonyms (like JFK) have been discarded based on the existence of a Wikipedia disambiguation page, of other named individuals sharing their label in DBpedia, or simply if the number of matched web pages for (one of) the label(s) of the individual was too high.", "labels": [], "entities": [{"text": "JFK", "start_pos": 57, "end_pos": 60, "type": "DATASET", "confidence": 0.909511148929596}, {"text": "DBpedia", "start_pos": 191, "end_pos": 198, "type": "DATASET", "confidence": 0.9122942686080933}]}, {"text": "The corpus for this dataset was composed of approximately 60000 web pages retrieved with a search engine, using named individual labels as queries.", "labels": [], "entities": []}, {"text": "The evaluation consisted in manually verifying whether a discarded axiom \u03c6 was actually erroneous, i.e. whether the understanding of some element of the signature of \u03c6 (named individual, atomic concept or role) was incompatible with its overall understanding within K.", "labels": [], "entities": []}, {"text": "The results of this first evaluation are presented in table 1.", "labels": [], "entities": []}, {"text": "Columns \"5\", \"10\" and \"20\" give the number (\"val.\") and proportion (\"prec.\", for precision) of axioms manually identified as actually erroneous among the 5, 10 and 20 first discarded ones.", "labels": [], "entities": [{"text": "proportion", "start_pos": 56, "end_pos": 66, "type": "METRIC", "confidence": 0.9859748482704163}, {"text": "precision", "start_pos": 81, "end_pos": 90, "type": "METRIC", "confidence": 0.9993670582771301}]}, {"text": "Column \"Ordering\" specifies the method applied to select the discarded axiom \u03c6 at each iteration of the loop in algorithm 1 : \"sc(\u0393 \\ {\u03c6})\" if \u03c6 = argmax \u03c6\u2208\u0393 sc(\u0393 \\ {\u03c6}), and \" l \" if \u03c6 is obtained with the alternative approach (the lexicographic order) presented in section 4.", "labels": [], "entities": []}, {"text": "The values obtained are encouraging, in that one can reasonably expect the proportion of erroneous within the whole KB to be much lower than the precision scores obtained here.", "labels": [], "entities": [{"text": "precision", "start_pos": 145, "end_pos": 154, "type": "METRIC", "confidence": 0.9989861845970154}]}, {"text": "A more thorough examination of the linguistic contexts responsible for these good results is still required though.: Random axioms among the first 5, 10 and 20 discarded ones for the fragment of the fisheries ontology The second dataset is a small randomly extracted fragment of the fisheries KB built for the NEON project, 4 which contains 169 logical axioms, involving only 20 named individuals (mostly geographical or administrative entities), with a more complex TBox (the least expressive underlying DL is SI).", "labels": [], "entities": [{"text": "TBox", "start_pos": 467, "end_pos": 471, "type": "METRIC", "confidence": 0.9360730051994324}]}, {"text": "This KB is arguably more reliable too, which allowed the experimentation of a more objective form of evaluation.", "labels": [], "entities": []}, {"text": "It consists in artificially extending K with randomly generated axioms, before trying to discard them by application of the trimming algorithm.", "labels": [], "entities": []}, {"text": "The assumption is that a randomly generated axiom is usually less reliable than a manually crafted one.", "labels": [], "entities": []}, {"text": "The axiom generation procedure randomly selects an axiom \u03c6 \u2208 K, and yields an axiom \u03c6 with the same syntactic structure, but in which all individuals, atomic concepts and roles have been randomly replaced by individuals, atomic concepts and roles appearing in K.", "labels": [], "entities": [{"text": "axiom generation", "start_pos": 4, "end_pos": 20, "type": "TASK", "confidence": 0.7308794260025024}]}, {"text": "For instance, if \u03c6 = A \u2200r.\u00acB, then \u03c6 = C \u2200s.\u00acD, with C and D (resp. s) randomly chosen among atomic concepts (resp. roles) of the signature of K.", "labels": [], "entities": []}, {"text": "20 axioms in total were added to K.", "labels": [], "entities": []}, {"text": "The corpus consisted of approximately 4500 web pages, retrieved in the same way as for the first dataset.", "labels": [], "entities": []}, {"text": "Results are presented in table 2.", "labels": [], "entities": []}, {"text": "This time, the values are the number and proportion of randomly generated axioms among the first 5, 10 and 20 discarded ones.", "labels": [], "entities": []}, {"text": "Because the numbers of generated and trimmed axioms are identical, column \"prec./rec.\" estimates both precision and recall.", "labels": [], "entities": [{"text": "precision", "start_pos": 102, "end_pos": 111, "type": "METRIC", "confidence": 0.9994945526123047}, {"text": "recall", "start_pos": 116, "end_pos": 122, "type": "METRIC", "confidence": 0.9982232451438904}]}, {"text": "Precision was high for the first discarded axioms when sc(\u0393 \\ {\u03c6}) was used to order immediate subbases of \u0393.", "labels": [], "entities": []}, {"text": "But in both cases, the number of randomly generated axioms among the 20 first discarded ones was not significant.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Actually erroneous axioms among the first 5, 10 and 20 discarded ones for the DBpedia subset", "labels": [], "entities": [{"text": "DBpedia", "start_pos": 88, "end_pos": 95, "type": "DATASET", "confidence": 0.9512168169021606}]}, {"text": " Table 2: Random axioms among the first 5, 10 and 20 discarded ones for the fragment of the fisheries  ontology", "labels": [], "entities": []}]}