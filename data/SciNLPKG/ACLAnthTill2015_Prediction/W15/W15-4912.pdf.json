{"title": [{"text": "Dynamic Terminology Integration Methods in Statistical Machine Translation", "labels": [], "entities": [{"text": "Dynamic Terminology Integration", "start_pos": 0, "end_pos": 31, "type": "TASK", "confidence": 0.8667992750803629}, {"text": "Statistical Machine Translation", "start_pos": 43, "end_pos": 74, "type": "TASK", "confidence": 0.8261068860689799}]}], "abstractContent": [{"text": "In this paper the author presents methods for dynamic terminology integration in statistical machine translation systems using a source text pre-processing work-flow.", "labels": [], "entities": [{"text": "dynamic terminology integration", "start_pos": 46, "end_pos": 77, "type": "TASK", "confidence": 0.6324682335058848}, {"text": "statistical machine translation", "start_pos": 81, "end_pos": 112, "type": "TASK", "confidence": 0.621256152788798}]}, {"text": "The workflow consists of exchange-able components for term identification, inflected form generation for terms, and term translation candidate ranking.", "labels": [], "entities": [{"text": "term identification", "start_pos": 54, "end_pos": 73, "type": "TASK", "confidence": 0.7488462030887604}, {"text": "term translation candidate ranking", "start_pos": 116, "end_pos": 150, "type": "TASK", "confidence": 0.8367048650979996}]}, {"text": "Automatic evaluation for three language pairs shows a translation quality improvement from 0.9 to 3.41 BLEU points over the baseline.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 103, "end_pos": 107, "type": "METRIC", "confidence": 0.9991821646690369}]}, {"text": "Manual evaluation for seven language pairs confirms the positive results; the proportion of correctly translated terms increases from 1.6% to 52.6% over the baseline.", "labels": [], "entities": []}], "introductionContent": [{"text": "In professional translation services, correct and consistent handling of terminology is an important indicator of translation quality.", "labels": [], "entities": [{"text": "translation", "start_pos": 114, "end_pos": 125, "type": "TASK", "confidence": 0.960871696472168}]}, {"text": "However, pure statistical machine translation (SMT) systems, such as, Moses ( ) in a general scenario cannot ensure correct and consistent handling of terminology, because statistics of large amounts of data are difficult to control if not constrained by means of, e.g., bilingual term collections or translation model or language model adaptation techniques.", "labels": [], "entities": [{"text": "statistical machine translation (SMT)", "start_pos": 14, "end_pos": 51, "type": "TASK", "confidence": 0.8103382488091787}, {"text": "translation model or language model adaptation", "start_pos": 301, "end_pos": 347, "type": "TASK", "confidence": 0.6652985562880834}]}, {"text": "In cases where the context is too ambiguous (e.g., if an SMT system receives just a short translation segment or the SMT system's models are limited in the possibilities to analyse larger context) or when external knowledge is re- quired, it can be impossible for an SMT system to guess the correct translation.", "labels": [], "entities": [{"text": "SMT system receives just a short translation segment", "start_pos": 57, "end_pos": 109, "type": "TASK", "confidence": 0.7425195425748825}, {"text": "SMT", "start_pos": 267, "end_pos": 270, "type": "TASK", "confidence": 0.9780222177505493}]}, {"text": "In the localisation industry customers often provide their own term collections that have to be strictly used during translation to ensure correct and consistent usage of terminology.", "labels": [], "entities": []}, {"text": "Obviously, such collections may contain term translations that are rated as unlikely (in certain contexts) by an SMT system's models or they may even be missing in the models at all if custom adaptation of the models using the customers' provided data is not performed.", "labels": [], "entities": [{"text": "SMT", "start_pos": 113, "end_pos": 116, "type": "TASK", "confidence": 0.9752858281135559}]}, {"text": "If such SMT systems would be integrated in localisation service workflows, it would not be possible to ensure high terminology translation quality in the SMT suggestions.", "labels": [], "entities": [{"text": "SMT", "start_pos": 8, "end_pos": 11, "type": "TASK", "confidence": 0.9830904006958008}, {"text": "terminology translation", "start_pos": 115, "end_pos": 138, "type": "TASK", "confidence": 0.7612407207489014}, {"text": "SMT", "start_pos": 154, "end_pos": 157, "type": "TASK", "confidence": 0.9753764271736145}]}, {"text": "Therefore, effective methods that can benefit from custom term collections are necessary.", "labels": [], "entities": []}, {"text": "Researchers have tried to address the terminology integration challenge directly by using indomain term collections and indirectly by tackling the broader challenge of domain adaptation.", "labels": [], "entities": [{"text": "terminology integration", "start_pos": 38, "end_pos": 61, "type": "TASK", "confidence": 0.9155242741107941}, {"text": "domain adaptation", "start_pos": 168, "end_pos": 185, "type": "TASK", "confidence": 0.7161124646663666}]}, {"text": "Significant research efforts have been focussed on using in-domain parallel and monolingual corpora (that contain in-domain terminology) to perform SMT system translation and language model adaptation to specific domains (to name but a few,,,, and many others).", "labels": [], "entities": [{"text": "SMT system translation", "start_pos": 148, "end_pos": 170, "type": "TASK", "confidence": 0.9184117714564005}, {"text": "language model adaptation", "start_pos": 175, "end_pos": 200, "type": "TASK", "confidence": 0.6082517405351003}]}, {"text": "Terminology integration has been also indirectly addressed by research on multi-word unit integration in SMT.", "labels": [], "entities": [{"text": "Terminology integration", "start_pos": 0, "end_pos": 23, "type": "TASK", "confidence": 0.9528601169586182}, {"text": "multi-word unit integration", "start_pos": 74, "end_pos": 101, "type": "TASK", "confidence": 0.6428268849849701}, {"text": "SMT", "start_pos": 105, "end_pos": 108, "type": "TASK", "confidence": 0.8774318099021912}]}, {"text": "E.g., showed that for French-English it is enough to simply add multi-word unit pairs to the parallel corpus; however, they observed a limited gain of +0.3 BLEU () points.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 156, "end_pos": 160, "type": "METRIC", "confidence": 0.9986095428466797}]}, {"text": "In terms of direct terminology integration,  have shown that the addition of terms to the parallel corpus and the introduction of a bilingual termi-nology identifying feature in the translation model can significantly improve translation quality of an out-of-domain system (up to +2.13 BLEU points).", "labels": [], "entities": [{"text": "BLEU", "start_pos": 286, "end_pos": 290, "type": "METRIC", "confidence": 0.9986923336982727}]}, {"text": "Their method specifically addressed morphologically rich languages by identifying terms in different inflected forms using stemming tools.", "labels": [], "entities": []}, {"text": "Similar work that shows significant quality improvements has been recently performed by for the English-Italian language pair.", "labels": [], "entities": []}, {"text": "They use a term collection to create a \" fill-up\" translation model that consists of a pre-trained SMT system's phrase table merged with a phrase table created from the bilingual terminology.", "labels": [], "entities": [{"text": "SMT", "start_pos": 99, "end_pos": 102, "type": "TASK", "confidence": 0.9741394519805908}]}, {"text": "However, all these methods require to re-train the whole SMT system (or at least re-tune the SMT system) if new in-domain data becomes available.", "labels": [], "entities": [{"text": "SMT", "start_pos": 57, "end_pos": 60, "type": "TASK", "confidence": 0.9754176139831543}, {"text": "SMT", "start_pos": 93, "end_pos": 96, "type": "TASK", "confidence": 0.9172613024711609}]}, {"text": "For many translation tasks such a scenario is not economically justifiable.", "labels": [], "entities": [{"text": "translation tasks", "start_pos": 9, "end_pos": 26, "type": "TASK", "confidence": 0.9237560927867889}]}, {"text": "Furthermore, if we have already trained a relatively good SMT system (let it be a general domain system or a close-domain system to the domain that is needed), we should be able to tailor it to the required domain with the help of just the right bilingual terminology.", "labels": [], "entities": [{"text": "SMT", "start_pos": 58, "end_pos": 61, "type": "TASK", "confidence": 0.9927022457122803}]}, {"text": "Consequently, considerable research efforts have been focussed also on dynamic integration methods for term collections in SMT that do not require re-training of SMT systems.", "labels": [], "entities": [{"text": "SMT", "start_pos": 123, "end_pos": 126, "type": "TASK", "confidence": 0.819277822971344}, {"text": "SMT", "start_pos": 162, "end_pos": 165, "type": "TASK", "confidence": 0.9728848338127136}]}, {"text": "For instance, the Moses SMT system supports input data (in the Moses XML format) that is enriched with externally generated translation candidates.", "labels": [], "entities": [{"text": "SMT", "start_pos": 24, "end_pos": 27, "type": "TASK", "confidence": 0.5737147331237793}]}, {"text": "Using this methodology, used term dictionaries to pre-process source text and achieved an increase in translation quality for the English-French language pair.", "labels": [], "entities": []}, {"text": "Similarly, identify exactly matched terms and provide translation equivalents from the Wiki Machine 1 by performing context-based disambiguation if there are multiple translation equivalents fora single term for English-Italian.", "labels": [], "entities": [{"text": "Wiki Machine 1", "start_pos": 87, "end_pos": 101, "type": "DATASET", "confidence": 0.9216154217720032}]}, {"text": "showed that inclusion of certain named entities in \"do-not-translate\" lists allowed to increase translation quality for the English-Russian language pair.", "labels": [], "entities": []}, {"text": "Recently dynamic translation and language models) have been investigated for integration of terminology into SMT (Arcan et al., 2014b) for English-Italian.", "labels": [], "entities": [{"text": "SMT", "start_pos": 109, "end_pos": 112, "type": "TASK", "confidence": 0.9734162092208862}]}, {"text": "It is evident that most of the related research has, however, mostly focused on languages with simple morphology or translation of phrases that are rarely The Wiki Machine is available online at: https://bitbucket.org/fbk/thewikimachine translated or even left untranslated.", "labels": [], "entities": []}, {"text": "A study in the FP7 project TTC showed that for EnglishLatvian such simplified methods do not yield positive results.", "labels": [], "entities": [{"text": "FP7 project TTC", "start_pos": 15, "end_pos": 30, "type": "DATASET", "confidence": 0.9160773555437723}, {"text": "EnglishLatvian", "start_pos": 47, "end_pos": 61, "type": "DATASET", "confidence": 0.9256179332733154}]}, {"text": "came to the same conclusion in their work on English-Czech named entity translation.", "labels": [], "entities": [{"text": "English-Czech named entity translation", "start_pos": 45, "end_pos": 83, "type": "TASK", "confidence": 0.529924750328064}]}, {"text": "This means that for morphologically rich languages more linguistically rich methods are necessary.", "labels": [], "entities": []}, {"text": "In this paper, the author proposes a workflow for dynamic terminology integration in SMT systems that allows to: 1) identify terms in source text (i.e., translation segments or even large documents with Moses XML tags) that is sent to the SMT system for translation, 2) generate inflected forms of terms using corpus-based and morphological synthesisbased methods, and 3) rank term translation candidates.", "labels": [], "entities": [{"text": "dynamic terminology integration", "start_pos": 50, "end_pos": 81, "type": "TASK", "confidence": 0.6779385606447855}, {"text": "SMT", "start_pos": 85, "end_pos": 88, "type": "TASK", "confidence": 0.9734187126159668}, {"text": "rank term translation", "start_pos": 372, "end_pos": 393, "type": "TASK", "confidence": 0.6784911354382833}]}, {"text": "The methods proposed have been evaluated in two different scenarios using automated SMT quality metrics for three language pairs and by performing manual comparative evaluation for seven language pairs (from English into Estonian, French, German, Italian, Latvian, Lithuanian, and Spanish).", "labels": [], "entities": [{"text": "SMT", "start_pos": 84, "end_pos": 87, "type": "TASK", "confidence": 0.991592288017273}]}, {"text": "The results will show that the proposed methods are able to improve terminology translation quality and the overall sentence translation quality for morphologically rich languages.", "labels": [], "entities": [{"text": "terminology translation quality", "start_pos": 68, "end_pos": 99, "type": "TASK", "confidence": 0.8004500468571981}, {"text": "sentence translation", "start_pos": 116, "end_pos": 136, "type": "TASK", "confidence": 0.7369877249002457}]}, {"text": "For evaluation purposes, the author uses the LetsMT SMT platform, which is based on the Moses SMT system.", "labels": [], "entities": [{"text": "LetsMT SMT platform", "start_pos": 45, "end_pos": 64, "type": "DATASET", "confidence": 0.6655588348706564}, {"text": "Moses SMT system", "start_pos": 88, "end_pos": 104, "type": "DATASET", "confidence": 0.7387973566850027}]}, {"text": "The paper is further structured as follows: section 2 describes the dynamic terminology integration workflow and the different modules for source text pre-processing, section 3 describes our automatic and manual evaluation efforts, and section 4 concludes the paper.", "labels": [], "entities": []}], "datasetContent": [{"text": "To evaluate the dynamic terminology integration methods, two evaluation tasks were carried out: 1) automatic evaluation that identifies the combination of the different methods that allows achieving the highest results, and 2) manual evaluation that focusses on term translation qualitative analysis using production SMT systems and an authoritative term collection.", "labels": [], "entities": [{"text": "dynamic terminology integration", "start_pos": 16, "end_pos": 47, "type": "TASK", "confidence": 0.6129883825778961}, {"text": "term translation qualitative analysis", "start_pos": 262, "end_pos": 299, "type": "TASK", "confidence": 0.8489348739385605}, {"text": "SMT", "start_pos": 317, "end_pos": 320, "type": "TASK", "confidence": 0.9188555479049683}]}, {"text": "The following subsections describe both evaluation efforts.", "labels": [], "entities": []}, {"text": "The automatic evaluation was performed for three language pairs (English-German, Latvian, and Lithuanian) using general domain SMT systems that were trained in the LetsMT platform using the DGT-TM parallel corpus (Steinberger et al., 2012) (the releases of).", "labels": [], "entities": [{"text": "SMT", "start_pos": 127, "end_pos": 130, "type": "TASK", "confidence": 0.8597280383110046}, {"text": "DGT-TM parallel corpus (Steinberger et al., 2012)", "start_pos": 190, "end_pos": 239, "type": "DATASET", "confidence": 0.8525593280792236}]}, {"text": "For evaluation, the author uses a proprietary parallel corpus of 872 sentence pairs in the automotive domain (technical documentation from car service manuals).", "labels": [], "entities": []}, {"text": "The original data set was available for English-Latvian, therefore, the remaining two data sets for German and Lithuanian were prepared by professional translators.", "labels": [], "entities": []}, {"text": "For English-Latvian an in-domain tuning set of 1,745 sentence pairs was available; for the remaining systems held-out sets of 2,000 sentence pairs from the training data were used for SMT system tuning.", "labels": [], "entities": [{"text": "SMT system tuning", "start_pos": 184, "end_pos": 201, "type": "TASK", "confidence": 0.924963116645813}]}, {"text": "The results of the baseline systems are given in: Baseline system performance (\"(a)\" -automotive domain evaluation sets; \"(g)\" -SMT system in-domain evaluation sets from the DGT-TM corpus) dent that the results for English-Latvian are significantly higher (although still relatively low) than for the other language pairs.", "labels": [], "entities": [{"text": "SMT", "start_pos": 128, "end_pos": 131, "type": "TASK", "confidence": 0.9807306528091431}, {"text": "DGT-TM corpus", "start_pos": 174, "end_pos": 187, "type": "DATASET", "confidence": 0.9451256394386292}]}, {"text": "This is mainly due to the fact that an automotive domain tuning set was available for the English-Latvian experiments.", "labels": [], "entities": []}, {"text": "As the results for the other language pairs are very low, includes also automatic evaluation results using 1000 held-out sentence pairs from the DGT-TM corpus to show that the systems on indomain data perform relatively well.", "labels": [], "entities": [{"text": "DGT-TM corpus", "start_pos": 145, "end_pos": 158, "type": "DATASET", "confidence": 0.9682164788246155}]}, {"text": "This shows just how different the writing styles and the language complexity between different domains can be.", "labels": [], "entities": []}, {"text": "Next, the author analysed, which pre-processing configuration allows achieving better results (see).", "labels": [], "entities": []}, {"text": "This analysis was performed for English-Latvian using a term collection that was created by a professional translator from the tuning-data.", "labels": [], "entities": []}, {"text": "The term collection consists of 644 term pairs (terms were included only in their canonical forms).", "labels": [], "entities": []}, {"text": "The results show that all combi-: Automatic evaluation results using three different term collections for English-Latvian (BLEU scores) nations performed better than the baseline system.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 123, "end_pos": 127, "type": "METRIC", "confidence": 0.9837952852249146}]}, {"text": "It is evident that the Fast Term Identification allows achieving better results than the other term identification methods.", "labels": [], "entities": [{"text": "Fast Term Identification", "start_pos": 23, "end_pos": 47, "type": "TASK", "confidence": 0.4375108579794566}, {"text": "term identification", "start_pos": 95, "end_pos": 114, "type": "TASK", "confidence": 0.7154980301856995}]}, {"text": "The method also allows to identify more terms in the source text (1,404; compared to 1,261 for Phrase and 620 for TWSC).", "labels": [], "entities": [{"text": "TWSC", "start_pos": 114, "end_pos": 118, "type": "DATASET", "confidence": 0.7925428748130798}]}, {"text": "We see also that the Synthesis method for inflected form generation achieves lower results than the Corpus method for which there are two possible reasons: 1) data ambiguity for the SMT system by providing significantly more inflected forms is increased, and 2) the implemented ranking methods do not allow effectively estimating, which inflected form is more or less likely due to not taking the language transfer characteristics into account.", "labels": [], "entities": [{"text": "inflected form generation", "start_pos": 42, "end_pos": 67, "type": "TASK", "confidence": 0.7088212569554647}, {"text": "SMT", "start_pos": 182, "end_pos": 185, "type": "TASK", "confidence": 0.9875549674034119}]}, {"text": "Next, professional translators were asked to prepare professional term collections for EnglishGerman (692 term pairs) and English-Lithuanian (662 term pairs) and performed automatic evaluation experiments.", "labels": [], "entities": []}, {"text": "The results in are limited to the configurations with 'Corpus+Simple' that showed to achieve the best results for EnglishLatvian.", "labels": [], "entities": [{"text": "EnglishLatvian", "start_pos": 114, "end_pos": 128, "type": "DATASET", "confidence": 0.9281952381134033}]}, {"text": "The automatic evaluation showed positive results.", "labels": [], "entities": []}, {"text": "However, the SMT systems in the baseline scenario achieved relatively low scores and the term collections were relatively small (although fo-: Automatic evaluation results using different term identification methods and corpusbased inflected form generation and ranking cussed to a narrow domain).", "labels": [], "entities": [{"text": "SMT", "start_pos": 13, "end_pos": 16, "type": "TASK", "confidence": 0.9907241463661194}]}, {"text": "Therefore, the manual evaluation was performed for seven language pairs using production level in-domain SMT systems (contrary to out-of-domain systems before) in the information technology domain.", "labels": [], "entities": [{"text": "SMT", "start_pos": 105, "end_pos": 108, "type": "TASK", "confidence": 0.950893223285675}]}, {"text": "For terminology integration, the freely available Microsoft Terminology Collection 2 was used.", "labels": [], "entities": [{"text": "terminology integration", "start_pos": 4, "end_pos": 27, "type": "TASK", "confidence": 0.9510417282581329}, {"text": "Microsoft Terminology Collection 2", "start_pos": 50, "end_pos": 84, "type": "DATASET", "confidence": 0.8263965845108032}]}, {"text": "As the term collection contains many ambiguous terms that can be confused with general language words and phrases (e.g., 'AND', 'about', 'name', 'form', 'order', etc.), it is important to filter such candidates out as the dynamic integration workflow (contrary to methods that perform SMT system model adaptation) is sensitive to the level of ambiguity of the included terms.", "labels": [], "entities": [{"text": "SMT system model adaptation", "start_pos": 285, "end_pos": 312, "type": "TASK", "confidence": 0.9166532754898071}]}, {"text": "The collections for the different language pairs were filtered using a term pair specificity estimation method that is based on inverse document frequency (IDF) scores) from abroad domain corpus.", "labels": [], "entities": [{"text": "inverse document frequency (IDF) scores", "start_pos": 128, "end_pos": 167, "type": "METRIC", "confidence": 0.8824085422924587}]}, {"text": "The formula is given in (1); it was first introduced by . IDFs (ps (i)) , The baseline system performance and the term collection statistics are given in  The manual evaluation is performed by comparing the SMT system performance without (the baseline scenario) and with (the improved scenario) integrated terminology.", "labels": [], "entities": [{"text": "IDFs", "start_pos": 58, "end_pos": 62, "type": "METRIC", "confidence": 0.9946893453598022}, {"text": "SMT", "start_pos": 207, "end_pos": 210, "type": "TASK", "confidence": 0.9874835014343262}]}, {"text": "The 'Fast+Corpus+Simple' configuration was used in this experiment.", "labels": [], "entities": []}, {"text": "The evaluation data for each language pair consists of 100 in-domain sentences for which the outputs of the SMT systems in the two scenarios differed (different translations were produced in average for 56% of sentences).", "labels": [], "entities": [{"text": "SMT", "start_pos": 108, "end_pos": 111, "type": "TASK", "confidence": 0.9869656562805176}]}, {"text": "For each language pair two professional translators were involved in the evaluation.", "labels": [], "entities": []}, {"text": "For the evaluation, translators were asked to perform three ratings: \u2022 For each sentence, translators had to decide which scenario produced a better translation.", "labels": [], "entities": []}, {"text": "If both scenarios produced translations of equal quality, the translators had to decide whether both scenarios produced acceptable or not acceptable translations.", "labels": [], "entities": []}, {"text": "\u2022 Similarly to the sentence level, for each term that was identified in the source text using the 'Fast' method, translators had to decide which scenario produced a better translation.", "labels": [], "entities": []}, {"text": "\u2022 The first two are quantitative analysis measures, therefore as a third rating translators were asked to rate the term translation quality in both scenarios separately.", "labels": [], "entities": []}, {"text": "The translators had to decide whether the term is translated correctly, whether a wrong inflectional form is used, whether it is not translated, whether it is split up or its words are in a wrong order, whether a wrong lexical choice is made, whether the marked phrase is actually not a term and has been wrongly identified as a term, or whether there is another issue.", "labels": [], "entities": []}, {"text": "The sentence level evaluation summary in shows that the translations of the improved scenario were preferred more for six language pairs.", "labels": [], "entities": []}, {"text": "Because of spatial restrictions, the paper features only results from the analysis where evaluators were in full agreement.", "labels": [], "entities": []}, {"text": "It is evident that the task of comparing sentence level quality is a very challenging task for evaluators, because the Free Kappa () agreement scores are mainly in the levels of fair to moderate.", "labels": [], "entities": []}, {"text": "The term level evaluation summary is given in: Evaluation summary for term level ratings where evaluators were in agreement scores for evaluators show that the task of comparing in which system terms were translated better was fairly easy and in general well understood.", "labels": [], "entities": []}, {"text": "The summary of the term translation quality evaluation for the individual scenarios is given in.", "labels": [], "entities": []}, {"text": "The results show that the proportion of correct term translations has improved for all language pairs from +1.6% for English-Estonian to +52.6% for English-Lithuanian.", "labels": [], "entities": []}, {"text": "The minimal improvement for English-Estonian is mainly due to selection of wrong inflected forms (which is a lesser quality issue, but an issue nonetheless) rather than wrong term lexical choices (which is a greater quality issue).", "labels": [], "entities": []}, {"text": "The author believes that the relatively low performance for English-Estonian is caused by the under-performance of the word stemming component for Estonian that is used for inflectional form acquisition for terms (however, deeper investigation is necessary).", "labels": [], "entities": [{"text": "inflectional form acquisition", "start_pos": 173, "end_pos": 202, "type": "TASK", "confidence": 0.7874496380488077}]}, {"text": "It is evident that in terms of using the correct lexical choice, the quality has improved from +26.4% for EnglishGerman to +65.2% for English-Lithuanian.", "labels": [], "entities": []}, {"text": "This means that the method allows ensuring terminology translation consistency better than in the baseline scenario.", "labels": [], "entities": [{"text": "terminology translation", "start_pos": 43, "end_pos": 66, "type": "TASK", "confidence": 0.8917437195777893}, {"text": "consistency", "start_pos": 67, "end_pos": 78, "type": "METRIC", "confidence": 0.54961097240448}]}], "tableCaptions": [{"text": " Table 1. It is evi-", "labels": [], "entities": []}, {"text": " Table 1: Baseline system performance (\"(a)\" -au- tomotive domain evaluation sets; \"(g)\" -SMT sys- tem in-domain evaluation sets from the DGT-TM  corpus)", "labels": [], "entities": [{"text": "SMT sys", "start_pos": 90, "end_pos": 97, "type": "TASK", "confidence": 0.8699564039707184}, {"text": "DGT-TM  corpus", "start_pos": 138, "end_pos": 152, "type": "DATASET", "confidence": 0.9747463166713715}]}, {"text": " Table 2: Baseline system performance (on 1,000  held-out sentence pairs) and statistics of the term  collections before and after filtering", "labels": [], "entities": []}, {"text": " Table 3: Evaluation summary for sentence level  ratings where evaluators were in agreement", "labels": [], "entities": []}, {"text": " Table 4: Evaluation summary for term level ratings  where evaluators were in agreement", "labels": [], "entities": []}, {"text": " Table 5: Evaluation summary for term translation quality", "labels": [], "entities": [{"text": "term translation", "start_pos": 33, "end_pos": 49, "type": "TASK", "confidence": 0.7625063061714172}]}]}