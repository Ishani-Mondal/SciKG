{"title": [{"text": "Semantic Annotation of Japanese Functional Expressions and its Impact on Factuality Analysis", "labels": [], "entities": [{"text": "Semantic Annotation of Japanese Functional Expressions", "start_pos": 0, "end_pos": 54, "type": "TASK", "confidence": 0.8791237473487854}]}], "abstractContent": [{"text": "Recognizing the meaning of functional expressions is essential for natural language understanding.", "labels": [], "entities": [{"text": "Recognizing the meaning of functional expressions", "start_pos": 0, "end_pos": 49, "type": "TASK", "confidence": 0.7664433916409811}, {"text": "natural language understanding", "start_pos": 67, "end_pos": 97, "type": "TASK", "confidence": 0.6502673625946045}]}, {"text": "This is a difficult task, owing to the lack of a sufficient corpus for machine learning and evaluation.", "labels": [], "entities": []}, {"text": "In this study, we design anew annotation scheme and construct a corpus containing 2,327 Japanese sentences and 8,775 functional expressions.", "labels": [], "entities": []}, {"text": "Our scheme achieves high inter-annotator agreement with kappa score of 0.85.", "labels": [], "entities": [{"text": "agreement", "start_pos": 41, "end_pos": 50, "type": "METRIC", "confidence": 0.7380431294441223}, {"text": "kappa score", "start_pos": 56, "end_pos": 67, "type": "METRIC", "confidence": 0.9059336185455322}]}, {"text": "In the experiments, we confirmed that machine learning-based functional expression analysis contributes to fac-tuality analysis.", "labels": [], "entities": [{"text": "machine learning-based functional expression analysis", "start_pos": 38, "end_pos": 91, "type": "TASK", "confidence": 0.5953133165836334}, {"text": "fac-tuality analysis", "start_pos": 107, "end_pos": 127, "type": "TASK", "confidence": 0.7645943760871887}]}], "introductionContent": [{"text": "In natural language, many expressions are used to convey information beyond the propositional content of the sentence, such as modality and polarity.", "labels": [], "entities": []}, {"text": "Understanding such information is essential for natural language understanding.", "labels": [], "entities": [{"text": "natural language understanding", "start_pos": 48, "end_pos": 78, "type": "TASK", "confidence": 0.681805948416392}]}, {"text": "The extra-propositional aspects of meaning are often expressed by function words and their combinations.", "labels": [], "entities": []}, {"text": "For example, consider the following sentence: (1) (My computer may have been broken.)", "labels": [], "entities": []}, {"text": "Three expressions are used to add extra information to the propositional content (break): function words (means it is unintentional), (have been) and (may) mean UNIN-TENTIONAL, COMPLETION, and UNCERTAIN, respectively.", "labels": [], "entities": []}, {"text": "Some function words such as are used alone, and others are combined to express their meaning, such as and . We call the former a \"function word,\" and the latter a \"compound functional expression (CFE).\"", "labels": [], "entities": []}, {"text": "These are collectively called \"functional expressions\" (FEs) in this paper.", "labels": [], "entities": []}, {"text": "Recognizing the meaning of FEs is useful for various natural language processing tasks, such as factuality analysis, machine translation, and question answering.", "labels": [], "entities": [{"text": "Recognizing the meaning of FEs", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.7415789365768433}, {"text": "factuality analysis", "start_pos": 96, "end_pos": 115, "type": "TASK", "confidence": 0.7906526327133179}, {"text": "machine translation", "start_pos": 117, "end_pos": 136, "type": "TASK", "confidence": 0.8032641410827637}, {"text": "question answering", "start_pos": 142, "end_pos": 160, "type": "TASK", "confidence": 0.8975721597671509}]}, {"text": "However, two main issues cause difficulties in FE analysis.", "labels": [], "entities": [{"text": "FE analysis", "start_pos": 47, "end_pos": 58, "type": "TASK", "confidence": 0.9875465631484985}]}, {"text": "First, because FEs are usually expressed with multiple tokens, we must resolve the chunking problem.", "labels": [], "entities": [{"text": "FEs", "start_pos": 15, "end_pos": 18, "type": "TASK", "confidence": 0.4537273943424225}]}, {"text": "Second, FEs indicating different meanings can have the same surface form.", "labels": [], "entities": [{"text": "FEs", "start_pos": 8, "end_pos": 11, "type": "METRIC", "confidence": 0.9694753885269165}]}, {"text": "For example, is used to indicate CONTINUOUS in (now eating) and used to indicate HABIT in (always sing).", "labels": [], "entities": [{"text": "CONTINUOUS", "start_pos": 33, "end_pos": 43, "type": "METRIC", "confidence": 0.9669023752212524}, {"text": "HABIT", "start_pos": 81, "end_pos": 86, "type": "METRIC", "confidence": 0.9759247303009033}]}, {"text": "In Japanese, there is no corpus large enough for machine learning and evaluation.", "labels": [], "entities": [{"text": "machine learning", "start_pos": 49, "end_pos": 65, "type": "TASK", "confidence": 0.7099239528179169}]}, {"text": "first built a dictionary of Japanese FEs named Tsutsuji.", "labels": [], "entities": [{"text": "FEs", "start_pos": 37, "end_pos": 40, "type": "TASK", "confidence": 0.6066392064094543}, {"text": "Tsutsuji", "start_pos": 47, "end_pos": 55, "type": "METRIC", "confidence": 0.793310821056366}]}, {"text": "reported that this dictionary lacks many expressions.", "labels": [], "entities": []}, {"text": "Therefore, we designed anew scheme for annotating FE meanings, and constructed a corpus containing 2,327 sentences and 8,775 FEs.", "labels": [], "entities": [{"text": "FE meanings", "start_pos": 50, "end_pos": 61, "type": "TASK", "confidence": 0.8190349042415619}]}, {"text": "In this scheme, we reorganize a dictionary of FEs on the basis of Tsutsuji.", "labels": [], "entities": [{"text": "Tsutsuji", "start_pos": 66, "end_pos": 74, "type": "METRIC", "confidence": 0.887333869934082}]}, {"text": "Our scheme and corpus are especially compatible with factuality analysis.", "labels": [], "entities": [{"text": "factuality analysis", "start_pos": 53, "end_pos": 72, "type": "TASK", "confidence": 0.8332030773162842}]}, {"text": "We selected factuality analysis as our application, because it provides verifiable evidence to confirm the importance of FEs.", "labels": [], "entities": [{"text": "factuality analysis", "start_pos": 12, "end_pos": 31, "type": "TASK", "confidence": 0.7908119261264801}, {"text": "FEs", "start_pos": 121, "end_pos": 124, "type": "TASK", "confidence": 0.7572277784347534}]}, {"text": "Using the annotations of actual text, we investigate the problems associated with FE annotation.", "labels": [], "entities": [{"text": "FE annotation", "start_pos": 82, "end_pos": 95, "type": "TASK", "confidence": 0.49650710821151733}]}, {"text": "We also verified the effect of our corpus and FE analysis on factuality analysis.", "labels": [], "entities": [{"text": "FE", "start_pos": 46, "end_pos": 48, "type": "METRIC", "confidence": 0.7226238250732422}, {"text": "factuality analysis", "start_pos": 61, "end_pos": 80, "type": "TASK", "confidence": 0.8556201159954071}]}, {"text": "Our contributions are three fold: (1) we introduce anew annotation scheme for Japanese FEs; (2) we build a Japanese FE corpus with high inter-annotator agreement; (3) we demonstrate that improvements in FE analysis contribute to factuality analysis.", "labels": [], "entities": [{"text": "Japanese FE corpus", "start_pos": 107, "end_pos": 125, "type": "DATASET", "confidence": 0.6253339250882467}, {"text": "FE analysis", "start_pos": 203, "end_pos": 214, "type": "TASK", "confidence": 0.9494113028049469}, {"text": "factuality analysis", "start_pos": 229, "end_pos": 248, "type": "TASK", "confidence": 0.8705744743347168}]}], "datasetContent": [{"text": "The closed test experiments were performed using 10-fold cross validation on the development set; the open tests were performed using the test set, with development set as training data.", "labels": [], "entities": []}, {"text": "Features The unigram and bigram features that were used included tokens, POS, and base forms.", "labels": [], "entities": []}, {"text": "Note that POS is subdivided into four stages: we used each of them for unigrams, and only the first two stages for bigrams.", "labels": [], "entities": []}, {"text": "We used the longest match principle as a baseline when using the dictionary.", "labels": [], "entities": []}, {"text": "The baseline uses the constraints for the preceding token's POS.", "labels": [], "entities": []}, {"text": "Dictionary entries and constraints were collected from the development set.", "labels": [], "entities": []}, {"text": "Furthermore, the system outputs the most frequent label in the development set if the expression takes more than one label.", "labels": [], "entities": []}, {"text": "We employed the standard evaluation metrics of precision, recall, and F-measures.", "labels": [], "entities": [{"text": "precision", "start_pos": 47, "end_pos": 56, "type": "METRIC", "confidence": 0.9997159838676453}, {"text": "recall", "start_pos": 58, "end_pos": 64, "type": "METRIC", "confidence": 0.9989824891090393}, {"text": "F-measures", "start_pos": 70, "end_pos": 80, "type": "METRIC", "confidence": 0.9945135116577148}]}, {"text": "Each metric was calculated by considering FEs as a unit.", "labels": [], "entities": [{"text": "FEs", "start_pos": 42, "end_pos": 45, "type": "METRIC", "confidence": 0.9943875670433044}]}, {"text": "In other words, we accepted only the expressions in which a chunking labels (B and I) sequence matched correctly.", "labels": [], "entities": []}, {"text": "Furthermore, we only evaluated BI sequences, because recognizing the compounds is one of the main problems in FE analysis.", "labels": [], "entities": [{"text": "FE analysis", "start_pos": 110, "end_pos": 121, "type": "TASK", "confidence": 0.974433422088623}]}, {"text": "The entire experiment focused on only FEs, while contentives were disregarded.", "labels": [], "entities": [{"text": "FEs", "start_pos": 38, "end_pos": 41, "type": "METRIC", "confidence": 0.972695529460907}]}, {"text": "The results are shown in.", "labels": [], "entities": []}, {"text": "Every result indicates that the CRF model provides better results than the baseline.", "labels": [], "entities": []}, {"text": "The table also shows that 57 CRF achieved a high score on chunking F-measure.", "labels": [], "entities": [{"text": "chunking F-measure", "start_pos": 58, "end_pos": 76, "type": "TASK", "confidence": 0.7058380395174026}]}, {"text": "These results show that it is easier than expected to detect compounds from an FE sequence.", "labels": [], "entities": [{"text": "FE sequence", "start_pos": 79, "end_pos": 90, "type": "DATASET", "confidence": 0.5986310392618179}]}, {"text": "Conversely, the F-measure of semantic label estimation exceeded 80%.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 16, "end_pos": 25, "type": "METRIC", "confidence": 0.9962674975395203}, {"text": "semantic label estimation", "start_pos": 29, "end_pos": 54, "type": "TASK", "confidence": 0.8242597977320353}]}, {"text": "We analyzed outputs from the closed test to determine why the F-score was low.", "labels": [], "entities": [{"text": "F-score", "start_pos": 62, "end_pos": 69, "type": "METRIC", "confidence": 0.9990339279174805}]}, {"text": "In (2) and (3), RESULTATIVE was labeled incorrectly; the answer shold have been shows an example of FE correctly labeled as RESULTATIVE.", "labels": [], "entities": [{"text": "RESULTATIVE", "start_pos": 16, "end_pos": 27, "type": "METRIC", "confidence": 0.9636587500572205}, {"text": "FE", "start_pos": 100, "end_pos": 102, "type": "METRIC", "confidence": 0.9856738448143005}]}, {"text": "These examples were ambiguous, and caused lower inter-annotator agreement.", "labels": [], "entities": []}, {"text": "Therefore, we should improve our corpus to include more precise guidelines.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2. The results show that the percent- age of CFEs in the development set was 74%, and  67% in both test sets. These percentages were sig- nificantly higher than our expectations; and extract- ing CFEs correctly is a crucial problem that we must  resolve. Note that the number of FEs is much lower  than that of Tsutsuji; this is because some of the FEs  listed in Tsutsuji are infrequent and thus not found  in the corpus.", "labels": [], "entities": [{"text": "FEs", "start_pos": 286, "end_pos": 289, "type": "METRIC", "confidence": 0.8982754349708557}]}, {"text": " Table 2: Corpus Statistics. (FEs and CFEs are noted in  brackets)", "labels": [], "entities": [{"text": "Corpus Statistics", "start_pos": 10, "end_pos": 27, "type": "DATASET", "confidence": 0.9426321089267731}, {"text": "FEs", "start_pos": 30, "end_pos": 33, "type": "METRIC", "confidence": 0.9786456227302551}, {"text": "CFEs", "start_pos": 38, "end_pos": 42, "type": "METRIC", "confidence": 0.5915965437889099}]}, {"text": " Table 3: Label-specific Inter Annotator Agreement. (Precision, Recall, and F-measure assuming worker 1 produces  \"gold data\" and worker 2 produces system output. More details on each semantic label can be found in the annotation  guidelines on the web site.)", "labels": [], "entities": [{"text": "Precision", "start_pos": 53, "end_pos": 62, "type": "METRIC", "confidence": 0.9960373044013977}, {"text": "Recall", "start_pos": 64, "end_pos": 70, "type": "METRIC", "confidence": 0.9762369394302368}, {"text": "F-measure", "start_pos": 76, "end_pos": 85, "type": "METRIC", "confidence": 0.9993007183074951}]}, {"text": " Table 4: Inter-Annotator Agreement (kappa)", "labels": [], "entities": [{"text": "Inter-Annotator Agreement (kappa)", "start_pos": 10, "end_pos": 43, "type": "TASK", "confidence": 0.4495732843875885}]}, {"text": " Table 6: The distribution of factuality values", "labels": [], "entities": []}, {"text": " Table 7: Results of factuality analysis evaluation", "labels": [], "entities": [{"text": "factuality analysis", "start_pos": 21, "end_pos": 40, "type": "TASK", "confidence": 0.8575920164585114}]}, {"text": " Table 8: Error type distribution", "labels": [], "entities": [{"text": "Error", "start_pos": 10, "end_pos": 15, "type": "METRIC", "confidence": 0.9277765154838562}]}]}