{"title": [{"text": "Building a Lexicon of Formulaic Language for Language Learners", "labels": [], "entities": []}], "abstractContent": [{"text": "Though the multiword lexicon has long been of interest in computational linguistics, most relevant work is targeted at only a small portion of it.", "labels": [], "entities": []}, {"text": "Our work is motivated by the needs of learners for more comprehensive resources reflecting formulaic language that goes beyond what is likely to be codified in a dictionary.", "labels": [], "entities": []}, {"text": "Working from an initial sequential seg-mentation approach, we present two enhancements: the use of anew measure to promote the identification of lexicalized sequences, and an expansion to include sequences with gaps.", "labels": [], "entities": []}, {"text": "We evaluate using a novel method that allows us to calculate an estimate of recall without a reference lexicon, showing that good performance in the second enhancement depends crucially on the first, and that our lexicon conforms much more with human judgment of formulaic language than alternatives.", "labels": [], "entities": [{"text": "recall", "start_pos": 76, "end_pos": 82, "type": "METRIC", "confidence": 0.9916799664497375}]}], "introductionContent": [{"text": "A significant portion of a speaker's lexical knowledge consists not of atomic lexical entries, i.e. words, but rather sequences built from their combination; in fact, the working multiword lexicon of the average native speaker is almost certainly much larger than the single-word lexicon.", "labels": [], "entities": []}, {"text": "Language learners, due to lack of exposure to the new language and interference from their native language, often fail to use these larger sequences proficiently, a fact which has been demonstrated via corpus analysis using high frequency n-grams).", "labels": [], "entities": []}, {"text": "Although high frequency n-grams, known in corpus linguistics as lexical bundles, are useful for certain kinds of analysis, they are inappropriate fora fullyfeatured multiword learning system, which would ideally involve an electronic lexicon corresponding roughly to the internal lexicon of native speakers.", "labels": [], "entities": []}, {"text": "In this work, we adopt the creation of such a lexicon as our goal.", "labels": [], "entities": []}, {"text": "Though much work has been done and many resources created which focus on specific aspects of the multiword vocabulary, most notably in fields such as multiword expressions (MWEs) and keyphrase/term extraction, our pedagogical perspective leads us towards a somewhat broader theoretical foundation, the formulaic sequence theory of.", "labels": [], "entities": [{"text": "keyphrase/term extraction", "start_pos": 183, "end_pos": 208, "type": "TASK", "confidence": 0.618917316198349}]}, {"text": "We are interested in any multiword sequence that could plausibly be lexicalized, not simply those that are noncompositional (idiomatic) or that are otherwise useful for information retrieval applications.", "labels": [], "entities": [{"text": "information retrieval", "start_pos": 169, "end_pos": 190, "type": "TASK", "confidence": 0.7547281682491302}]}, {"text": "With our goal of helping advanced learners produce more fluent language, we are more interested in sequences that underpin the structure of sentences and not just terms that reflect its topic.", "labels": [], "entities": []}, {"text": "As much as possible, we do not want to limit the syntactic composition, size, or frequency of our lexical items, and we want methods that allow us to build distinct, high-coverage lexicons for varying genres.", "labels": [], "entities": []}, {"text": "Working on top of an existing pipeline for unsupervised multiword unit segmentation (, the current work presents two key improvements on that initial model that allow us to build high-coverage lexicons of formulaic language.", "labels": [], "entities": [{"text": "multiword unit segmentation", "start_pos": 56, "end_pos": 83, "type": "TASK", "confidence": 0.7471214334170023}]}, {"text": "With respect to improving the quality of the sequences, we present anew measure for distinguishing true (lexicalized) affinity from background syntactic effects, the lexical predictability ratio, and integrate it into the model to improve the quality of the out-put lexicon.", "labels": [], "entities": []}, {"text": "The second major advance expands the coverage of the lexicon beyond directly contiguous sequences, allowing for sequences with gaps.", "labels": [], "entities": []}, {"text": "Note that these are not independent, since the class imbalance between possible and actual gap phrases means that the second depends on the first.", "labels": [], "entities": []}, {"text": "Our main evaluation is novel for this space: rather than comparing with (necessarily) incomplete reference lexicons, we view our task as a n-gram (or gapped n-gram) filtering task, sampling n-grams to annotate from our full (frequency-filtered) set, which allows us to calculate a reliable precision, recall, and F-score.", "labels": [], "entities": [{"text": "precision", "start_pos": 290, "end_pos": 299, "type": "METRIC", "confidence": 0.9992672801017761}, {"text": "recall", "start_pos": 301, "end_pos": 307, "type": "METRIC", "confidence": 0.9966568946838379}, {"text": "F-score", "start_pos": 313, "end_pos": 320, "type": "METRIC", "confidence": 0.9984874725341797}]}, {"text": "We also test the relevance of our lexicon to contextual recognition of multiword expressions, using a recently released dataset.", "labels": [], "entities": [{"text": "contextual recognition of multiword expressions", "start_pos": 45, "end_pos": 92, "type": "TASK", "confidence": 0.7743783235549927}]}, {"text": "In both cases, our method outperforms a variety of alternatives, including the original segmentation approach that was our starting point; like that original approach, our lexicon creation method is highly scalable and deterministic, and has only one key parameter (minimum frequency in the corpus).", "labels": [], "entities": []}], "datasetContent": [{"text": "Evaluation of large-scale automatically-generated lexicons is notoriously problematic: comparing to a reference lexicon is usually not valid because the reference lexicon, if one exists, is not complete (if it were, why build an automatic lexicon at all?) and therefore it is impossible to accurately estimate precision.", "labels": [], "entities": [{"text": "precision", "start_pos": 310, "end_pos": 319, "type": "METRIC", "confidence": 0.9925119876861572}]}, {"text": "The output of a particular approach (i.e. the lexicon) can be judged directly, but this only measures precision, not recall, and it is a short-sighted approach with regards to evaluating future improvements.", "labels": [], "entities": [{"text": "precision", "start_pos": 102, "end_pos": 111, "type": "METRIC", "confidence": 0.9992307424545288}, {"text": "recall", "start_pos": 117, "end_pos": 123, "type": "METRIC", "confidence": 0.9982910752296448}]}, {"text": "In this work, we take advantage of the fact that we are assuming an initial n-gram frequency threshold, which greatly reduces the space of all possible n-grams (both contiguous and gap) that we are actually considering as possible formulaic sequences.", "labels": [], "entities": []}, {"text": "Although there are still many more bad n-grams than good, the imbalance is not so great as to make annotation impossible: we can sample from the set of possible n-grams, judge them as being good or bad formulaic sequences, and then compare with the output of lexicon creation processes to calculate precision, recall, and F-score.", "labels": [], "entities": [{"text": "precision", "start_pos": 299, "end_pos": 308, "type": "METRIC", "confidence": 0.9996799230575562}, {"text": "recall", "start_pos": 310, "end_pos": 316, "type": "METRIC", "confidence": 0.9995961785316467}, {"text": "F-score", "start_pos": 322, "end_pos": 329, "type": "METRIC", "confidence": 0.9988634586334229}]}, {"text": "Our annotation project involved 3 judges, a number chosen so we could use consensus for the creation of a gold standard.", "labels": [], "entities": []}, {"text": "To help them make their annotation, the judges were presented with 5 sample sentences from our corpus.", "labels": [], "entities": []}, {"text": "We annotated 1000 contiguous n-grams and 1000 gap n-grams in this fashion, with the n-grams randomly selected from sets of roughly 1.5 million ngrams in both cases.", "labels": [], "entities": []}, {"text": "For contiguous n-grams, 16.9% of the n-grams were judged to be canonical formulaic sequences, but from gap n-grams this number was much lower, only 2.9%.", "labels": [], "entities": []}, {"text": "Kappa is problematic with such a serious class imbalance), so instead we calculated an average Fscore across the 3 annotations 1 , which was found to be 0.62 for contiguous n-grams and 0.42 for gap ngrams, numbers which reflect a certain amount of subjectivity in the judgment task, but also considerable agreement.", "labels": [], "entities": [{"text": "Fscore", "start_pos": 95, "end_pos": 101, "type": "METRIC", "confidence": 0.9989369511604309}, {"text": "agreement", "start_pos": 305, "end_pos": 314, "type": "METRIC", "confidence": 0.9816053509712219}]}, {"text": "These F-scores also provide an estimate of a practical upper bound for our evaluation.", "labels": [], "entities": [{"text": "F-scores", "start_pos": 6, "end_pos": 14, "type": "METRIC", "confidence": 0.9790686368942261}]}, {"text": "To create a gold standard annotation, we used the majority judgment.", "labels": [], "entities": []}, {"text": "We also had a single judge produce separate sets for development purposes.", "labels": [], "entities": []}, {"text": "Our second evaluation uses an existing resource, a section of the English Web TreeBank () that has been annotated fora full range of MWEs ().", "labels": [], "entities": [{"text": "English Web TreeBank", "start_pos": 66, "end_pos": 86, "type": "DATASET", "confidence": 0.9455492893854777}]}, {"text": "As mentioned earlier, formulaic sequences area broader category than MWEs (as traditionally understood), and indeed a manual analysis of a portion of the corpus revealed many formulaic sequences in this set which are not annotated.", "labels": [], "entities": []}, {"text": "Nevertheless, since all MWEs are formulaic expressions, we can make use of the annotation as a secondary evaluation: for positive examples, we extracted all MWEs in the corpus (except for MWE-internal MWEs, which we ignored) above the frequency threshold (which was the vast majority of them, since the genres of the ICWSM and the Web TreeBank are similar), and as negative examples we extracted all n-grams (both contiguous and: Comparison of various automatically generated lexicons with two annotated test sets.", "labels": [], "entities": [{"text": "ICWSM", "start_pos": 317, "end_pos": 322, "type": "DATASET", "confidence": 0.9141091704368591}, {"text": "Web TreeBank", "start_pos": 331, "end_pos": 343, "type": "DATASET", "confidence": 0.713905394077301}]}, {"text": "P = Precision, R = Recall, F = F-score, ME = mutual expectation, pred decomp = prediction decomposition method of.", "labels": [], "entities": [{"text": "Precision", "start_pos": 4, "end_pos": 13, "type": "METRIC", "confidence": 0.988410234451294}, {"text": "Recall", "start_pos": 19, "end_pos": 25, "type": "METRIC", "confidence": 0.9359419345855713}, {"text": "F-score", "start_pos": 31, "end_pos": 38, "type": "METRIC", "confidence": 0.9876734614372253}, {"text": "ME", "start_pos": 40, "end_pos": 42, "type": "METRIC", "confidence": 0.9954103827476501}, {"text": "pred decomp", "start_pos": 65, "end_pos": 76, "type": "METRIC", "confidence": 0.9310125112533569}]}, {"text": "Bold is best in column.", "labels": [], "entities": []}], "tableCaptions": []}