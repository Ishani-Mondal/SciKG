{"title": [{"text": "LYSGROUP: Adapting a Spanish microtext normalization system to English", "labels": [], "entities": [{"text": "Spanish microtext normalization", "start_pos": 21, "end_pos": 52, "type": "TASK", "confidence": 0.5751638809839884}]}], "abstractContent": [{"text": "In this article we describe the microtext normalization system we have used to participate in the Normalization of Noisy Text Task of the ACL W-NUT 2015 Workshop.", "labels": [], "entities": [{"text": "microtext normalization", "start_pos": 32, "end_pos": 55, "type": "TASK", "confidence": 0.8113043010234833}, {"text": "Normalization of Noisy Text Task of the ACL W-NUT 2015 Workshop", "start_pos": 98, "end_pos": 161, "type": "TASK", "confidence": 0.725103272633119}]}, {"text": "Our normalization system was originally developed for text mining tasks on Span-ish tweets.", "labels": [], "entities": [{"text": "text mining tasks", "start_pos": 54, "end_pos": 71, "type": "TASK", "confidence": 0.84157395362854}]}, {"text": "Our main goals during its development were flexibility, scalability and maintainability, in order to test a wide variety of approximations to the problem at hand with minimum effort.", "labels": [], "entities": [{"text": "flexibility", "start_pos": 43, "end_pos": 54, "type": "METRIC", "confidence": 0.9644199013710022}]}, {"text": "We will pay special attention to the process of adapting the components of our system to deal with English tweets which, as we will show, was achieved without major modifications of its base structure.", "labels": [], "entities": []}], "introductionContent": [{"text": "The value of Twitter and other microblogging services as information sources in domains like marketing, business intelligence, journalism, etc. is obvious nowadays.", "labels": [], "entities": []}, {"text": "Nevertheless, such amount of information can only be appropriately exploited through text mining techniques.", "labels": [], "entities": [{"text": "text mining", "start_pos": 85, "end_pos": 96, "type": "TASK", "confidence": 0.7628543674945831}]}, {"text": "However, there are notable differences between \"standard\" language and the so-called texting used in those microtexts.", "labels": [], "entities": []}, {"text": "In this kind of writings, it is important to reduce the number of characters used to fit their length restrictions while maintaining the readability of the message to some extent.", "labels": [], "entities": []}, {"text": "To achieve this, most of the techniques applied rely on phonetics, thus being language-specific.", "labels": [], "entities": []}, {"text": "For example: intentionally ignoring orthographic and grammar rules, as in \"be like\" for \"am/is/are/was/were like\" in the case of English or \"asique\" for \"as\u00ed que\" in the case of Spanish; the usage of shortenings, contractions and abbreviations such as \"c u\" for \"see you\" in English or \"ksa\" for \"casa\" in Spanish; or the employment of smileys to express emotions, for instance :) to express happiness.", "labels": [], "entities": []}, {"text": "These resulting terms are called lexical variants).", "labels": [], "entities": []}, {"text": "The problem is that, in general, text mining tools are very sensitive to those phenomena, as they are designed for dealing with standard texts.", "labels": [], "entities": [{"text": "text mining", "start_pos": 33, "end_pos": 44, "type": "TASK", "confidence": 0.8576377928256989}]}, {"text": "Therefore, it is necessary to normalize these texts before their processing, that is, to transform them into standard language.", "labels": [], "entities": []}, {"text": "This way \"c u nxt week\", for example, would be transformed into \"see you next week\".", "labels": [], "entities": []}, {"text": "This is the goal of the W-NUT 2015 Normalization Task (.", "labels": [], "entities": [{"text": "W-NUT 2015 Normalization Task", "start_pos": 24, "end_pos": 53, "type": "TASK", "confidence": 0.5790937319397926}]}, {"text": "The rest of this paper is organized as follows: Section 2 describes the core architecture of our system, and how it was adapted to fit this shared task, and Section 3 presents the resources used.", "labels": [], "entities": []}, {"text": "Next, Section 4 evaluates the system and discusses the results obtained.", "labels": [], "entities": []}, {"text": "Finally, Section 5 presents our conclusions and considers some possible future improvements for our system.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this respect, tuning experiments were also made by extending our unconstrained configuration through the addition of the Web 1T 5-gram v1 English language model as a knowledge source.", "labels": [], "entities": [{"text": "Web 1T 5-gram v1 English language model", "start_pos": 124, "end_pos": 163, "type": "DATASET", "confidence": 0.8154217430523464}]}, {"text": "Only unigrams and bigrams could be used because of unsolved memory limitations.", "labels": [], "entities": []}, {"text": "However, in contrast with previous experiments performed for Spanish, the resulting performance was unsatisfactory.", "labels": [], "entities": []}, {"text": "Because of this, the use of these language models for our final submission was dismissed.", "labels": [], "entities": []}, {"text": "According to our analysis, the cause for this seems to be the great differences, at both the lexical and syntactical levels, between the texts used to build this model, which could be considered as \"regular\" texts, and those corresponding to tweets, which agrees with the observations of.", "labels": [], "entities": []}, {"text": "As illustrative examples of this type of expressions we can take \"I like them girls\" and \"Why you no do that?\", which are lexically correct but not syntactically valid, so language models built using regular texts will not recognize them.", "labels": [], "entities": []}, {"text": "In the case of our previous experiments on Spanish, this difference was not so clear.", "labels": [], "entities": []}], "tableCaptions": []}