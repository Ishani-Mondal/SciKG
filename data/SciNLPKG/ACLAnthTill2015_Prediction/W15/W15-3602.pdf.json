{"title": [{"text": "Technical Term Extraction Using Measures of Neology", "labels": [], "entities": [{"text": "Technical Term Extraction", "start_pos": 0, "end_pos": 25, "type": "TASK", "confidence": 0.6655748387177786}]}], "abstractContent": [{"text": "This study aims to show that frequency of occurrence overtime for technical terms and keyphrases differs from general language terms in the sense that technical terms and keyphrases show a strong tendency to be recent coinage, and that this difference can be exploited for the automatic identification and extraction of technical terms and keyphrases.", "labels": [], "entities": [{"text": "frequency of occurrence overtime", "start_pos": 29, "end_pos": 61, "type": "METRIC", "confidence": 0.7432191222906113}, {"text": "automatic identification and extraction of technical terms and keyphrases", "start_pos": 277, "end_pos": 350, "type": "TASK", "confidence": 0.7554036676883698}]}, {"text": "To this end, we propose two features extracted from temporally labelled datasets designed to capture surface level n-gram neology.", "labels": [], "entities": []}, {"text": "Our analysis shows that these features, calculated over consecutive bigrams, are highly indicative of technical terms and keyphrases, which suggests that both technical terms and keyphrases are strongly biased to be surface level neologisms.", "labels": [], "entities": []}, {"text": "Finally , we evaluate the proposed features on a gold-standard dataset for technical term extraction and show that the proposed features are comparable or superior to a number of features commonly used for technical term extraction.", "labels": [], "entities": [{"text": "technical term extraction", "start_pos": 75, "end_pos": 100, "type": "TASK", "confidence": 0.6915425658226013}, {"text": "technical term extraction", "start_pos": 206, "end_pos": 231, "type": "TASK", "confidence": 0.627518226703008}]}], "introductionContent": [{"text": "Keyphrases are terms assigned to documents, conventionally by its authors, that are intended chiefly as an aid in searching large collections of documents, as well as to give a brief overview of the document's contents.", "labels": [], "entities": []}, {"text": "Technical terms are words or phrases that hold a specific meaning in specific domains or communities.", "labels": [], "entities": []}, {"text": "Keyphrases are closely related to technical terms in the sense that the keyphrases assigned to a document are generally selected from the terminology of the document's domain.", "labels": [], "entities": []}, {"text": "Keyphrases and technical terms show considerable conceptual overlap, and by extension, so do keyphrase and technical term extraction.", "labels": [], "entities": [{"text": "technical term extraction", "start_pos": 107, "end_pos": 132, "type": "TASK", "confidence": 0.6811137596766154}]}, {"text": "As a consequence, these two are closely related research topics.", "labels": [], "entities": []}, {"text": "In this study we will see technical term extraction and keyphrase extraction as distinct but related.", "labels": [], "entities": [{"text": "technical term extraction", "start_pos": 26, "end_pos": 51, "type": "TASK", "confidence": 0.6340697904427847}, {"text": "keyphrase extraction", "start_pos": 56, "end_pos": 76, "type": "TASK", "confidence": 0.8279557228088379}]}, {"text": "We will take the view that the technical terms in a scientific article are likely candidates to be keyphrases for the document and consequently that technical term extraction methods might also be useful in keyphrase extraction.", "labels": [], "entities": [{"text": "technical term extraction", "start_pos": 149, "end_pos": 174, "type": "TASK", "confidence": 0.7187618811925253}, {"text": "keyphrase extraction", "start_pos": 207, "end_pos": 227, "type": "TASK", "confidence": 0.8129851818084717}]}, {"text": "We will show that features that capture the neology of term candidates can be used to extract technical terms, and that the basic assumptions that enable this extraction also hold true for keyphrases.", "labels": [], "entities": []}, {"text": "This paper is organized as follows: We first discuss how technical terms and keyphrases differ from general language terms in terms of neology.", "labels": [], "entities": []}, {"text": "We then define features that capture this difference and analyze these features statistically using the) and a gold-standard for technical term extraction derived from the same dataset.", "labels": [], "entities": [{"text": "technical term extraction", "start_pos": 129, "end_pos": 154, "type": "TASK", "confidence": 0.6129622062047323}]}, {"text": "Our analysis shows that the proposed features reliably separate positive from negative examples, both of technical terms and of keyphrases.", "labels": [], "entities": []}, {"text": "Furthermore, the histograms for the proposed features are very similar when calculated for technical terms and keyphrases, suggesting that technical terms and keyphrases have very similar neological properties.", "labels": [], "entities": []}, {"text": "Finally, we demonstrate that this statistical bias can be used to reliably extract technical terms in a gold-standard dataset, and that the proposed features are comparable or superior to other features used in technical term extraction, with an F-score of 0.509 as compared to 0.593, 0.367, 0.361, and 0.204 for affix patterns, tf-idf, word shape, and POS tags respectively.", "labels": [], "entities": [{"text": "technical term extraction", "start_pos": 211, "end_pos": 236, "type": "TASK", "confidence": 0.6393068134784698}, {"text": "F-score", "start_pos": 246, "end_pos": 253, "type": "METRIC", "confidence": 0.9989136457443237}]}, {"text": "We argue that, given the high performance of the proposed features on technical term extraction, and given that we can show that the statistical properties that enable us to use them to extract technical terms also extend to keyphrases, the proposed features should also be useful in keyphrase extraction.", "labels": [], "entities": [{"text": "technical term extraction", "start_pos": 70, "end_pos": 95, "type": "TASK", "confidence": 0.6937526861826578}, {"text": "keyphrase extraction", "start_pos": 284, "end_pos": 304, "type": "TASK", "confidence": 0.9015548825263977}]}], "datasetContent": [{"text": "In order to demonstrate that neology, as characterized by the features \u00b5 and \u03c3, can be used to automatically extract technical terms, we implement a simple technical term extractor using these as features.", "labels": [], "entities": []}, {"text": "We generally follow the approach taken by and implement a conditional random field model to BIO-tag the dataset.", "labels": [], "entities": []}, {"text": "The major difference in implementation is that we use the neology features extracted from Google Ngrams in the term extractor, and that we do not use features based on clustering.", "labels": [], "entities": []}, {"text": "For the sake of our CRF model, bigrams and unigrams are sufficient, since what we want to do is to obtain features corresponding to each node (i.e. to each unigram) and features corresponding to the links between the nodes (i.e. to each bigram).", "labels": [], "entities": []}, {"text": "We might in theory achieve better performance with higher order n-grams, but in reality the results would be severely hampered by the sparsity problems for higher order n-grams.", "labels": [], "entities": []}, {"text": "Similarly to Chaimongkol and Aizawa, we implement a CRF model using the freely available state-of-the-art CRF framework CRFSuite 2 , using five different feature sets: 1.", "labels": [], "entities": []}, {"text": "POS TAGS using the Stanford POS tagger 3 .", "labels": [], "entities": [{"text": "POS TAGS", "start_pos": 0, "end_pos": 8, "type": "DATASET", "confidence": 0.8208878338336945}, {"text": "Stanford POS tagger 3", "start_pos": 19, "end_pos": 40, "type": "DATASET", "confidence": 0.9200478494167328}]}], "tableCaptions": [{"text": " Table 2: Term extractor performance in terms of correctly labeled tokens. Here, the system is only using  a single feature class in each trial in order to compare the relative performance of each feature class.", "labels": [], "entities": [{"text": "Term extractor", "start_pos": 10, "end_pos": 24, "type": "TASK", "confidence": 0.9650634229183197}]}, {"text": " Table 3: Term extractor performance in terms of correctly labeled tokens. Here, the system is using all  but one feature class in each trial in order to compare the relative performance drop when each feature  class is removed from the classifier.", "labels": [], "entities": [{"text": "Term extractor", "start_pos": 10, "end_pos": 24, "type": "TASK", "confidence": 0.9626340270042419}]}]}