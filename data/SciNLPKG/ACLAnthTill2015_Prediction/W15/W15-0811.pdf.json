{"title": [{"text": "Identifying Various Kinds of Event Mentions in K-Parser Output", "labels": [], "entities": [{"text": "Identifying", "start_pos": 0, "end_pos": 11, "type": "TASK", "confidence": 0.9757757186889648}]}], "abstractContent": [{"text": "In this paper we show how our semantic parser (Knowledge Parser or K-Parser) identifies various kinds of event mentions in the input text.", "labels": [], "entities": []}, {"text": "The types include recursive (com-plex) and non recursive event mentions.", "labels": [], "entities": []}, {"text": "K-Parser outputs each event mention inform of an acyclic graph with root nodes as the verbs that drive those events.", "labels": [], "entities": []}, {"text": "The children nodes of the verbs represent the entities participating in the events, and their conceptual classes.", "labels": [], "entities": []}, {"text": "The on-line demo of the system is available at", "labels": [], "entities": []}], "introductionContent": [{"text": "Identifying the events mentioned in a text is an essential task for any semantic parsing system.", "labels": [], "entities": [{"text": "Identifying the events mentioned in a text", "start_pos": 0, "end_pos": 42, "type": "TASK", "confidence": 0.8852287786347526}, {"text": "semantic parsing", "start_pos": 72, "end_pos": 88, "type": "TASK", "confidence": 0.7401387691497803}]}, {"text": "Many Natural Language Understanding applications such as Question Answering) and semantics-based machine translation () use semantic parsers to translate both questions and answer sources into a desired representation.", "labels": [], "entities": [{"text": "Natural Language Understanding", "start_pos": 5, "end_pos": 35, "type": "TASK", "confidence": 0.6664842565854391}, {"text": "Question Answering", "start_pos": 57, "end_pos": 75, "type": "TASK", "confidence": 0.8498155474662781}, {"text": "semantics-based machine translation", "start_pos": 81, "end_pos": 116, "type": "TASK", "confidence": 0.7056327064832052}]}, {"text": "Several semantic parsers, both application-independent) and the ones for specific application) have been developed for the assistance.", "labels": [], "entities": []}, {"text": "However, most of them do not very effectively represent the different kinds of event mentions.", "labels": [], "entities": []}, {"text": "In this paper we demonstrate, with the help of examples, how our semantic parser (Knowledge Parser or K-Parser) is able to identify the semantics of various event types and output them inform of an acyclic graph.", "labels": [], "entities": []}, {"text": "The sections below explain, in order, the basic overview of K-Parser (along with its output), a brief explanation of various kinds of event mentions and examples demonstrating how K-Parser output is able to identify event mentions in those examples.", "labels": [], "entities": []}, {"text": "K-Parser 1 is a semantic parser which produces a graphical semantic representation of the input text.", "labels": [], "entities": []}, {"text": "The output of the parser is a mapping between the dependency parse of input text and the ontological relations from KM component library).", "labels": [], "entities": []}, {"text": "The mapping process uses Word Sense Disambiguation and a set of rules to map syntactic dependencies to appropriate semantic relations.", "labels": [], "entities": [{"text": "Word Sense Disambiguation", "start_pos": 25, "end_pos": 50, "type": "TASK", "confidence": 0.5576130449771881}]}, {"text": "Furthermore, the output of the parser contains commonsense information about the words in the text i.e. the conceptual classes.", "labels": [], "entities": []}, {"text": "For example in BarackObama 1 has superclass person.", "labels": [], "entities": [{"text": "BarackObama", "start_pos": 15, "end_pos": 26, "type": "DATASET", "confidence": 0.9329872727394104}]}, {"text": "To sum up, the output of the parser has following properties: 1.", "labels": [], "entities": []}, {"text": "An acyclic graphical representation in the form of interconnected event mentions.", "labels": [], "entities": []}, {"text": "2. A rich ontology (KM) to represent semantic relations (Event-Event relations such as causes, caused by, Event-Entity relations such as agent, and Entity-Entity relations such as related to).", "labels": [], "entities": []}, {"text": "3. Special relations (instance of and prototype of ) to represent the existential and universal quantification of entities.", "labels": [], "entities": []}, {"text": "(For example, sentences Every boxer walks. and Some boxer walks.)", "labels": [], "entities": []}, {"text": "4. Conceptual class information about words in the text.", "labels": [], "entities": []}, {"text": "5. Semantic roles of entities (For example in sentence John loves Mia.).", "labels": [], "entities": []}, {"text": "6. Tenses of the events in the input text.", "labels": [], "entities": []}, {"text": "7. Other features such as an optional Co-reference resolution.", "labels": [], "entities": [{"text": "Co-reference resolution", "start_pos": 38, "end_pos": 61, "type": "METRIC", "confidence": 0.9088485836982727}]}, {"text": "The basic algorithm of K-Parser contains five modules.", "labels": [], "entities": []}, {"text": "The first module is used to extract the syntactic dependency graph from the input text.", "labels": [], "entities": []}, {"text": "We used Stanford Dependency Parser) for the purpose.", "labels": [], "entities": [{"text": "Stanford Dependency Parser)", "start_pos": 8, "end_pos": 35, "type": "DATASET", "confidence": 0.9558513909578323}]}, {"text": "The second module is used to map the syntactic dependency relations to KM relations () and a few newly created relations (such as related to).", "labels": [], "entities": []}, {"text": "There are three techniques used for semantic mapping.", "labels": [], "entities": [{"text": "semantic mapping", "start_pos": 36, "end_pos": 52, "type": "TASK", "confidence": 0.9141530394554138}]}, {"text": "First, we used the rules to map syntactic dependencies into semantic relations.", "labels": [], "entities": []}, {"text": "For example the nominal subject dependency is mapped to agent relation.", "labels": [], "entities": []}, {"text": "Second, we developed a multi-class multilayer perceptron classifier to disambiguate different senses of prepositions and assign the semantic relations appropriately.", "labels": [], "entities": []}, {"text": "The training data for classification is taken from \"The Preposition Project\" and the sense ids for prepositions are manually mapped to the KM relations.", "labels": [], "entities": [{"text": "The Preposition Project\"", "start_pos": 52, "end_pos": 76, "type": "DATASET", "confidence": 0.6979845315217972}]}, {"text": "The third method uses the discourse connectives in the text to label the event-event relations.", "labels": [], "entities": []}, {"text": "Different connectives correspond to different labels.", "labels": [], "entities": []}, {"text": "For example, the coordinate connectives such as but, and, comma (,) and stop(.) are labeled as next event.", "labels": [], "entities": [{"text": "stop", "start_pos": 72, "end_pos": 76, "type": "METRIC", "confidence": 0.9514159560203552}]}, {"text": "Other connectives are also labeled based on their effect, such as because and so are labeled caused by and causes respectively.", "labels": [], "entities": []}, {"text": "The third module in K-Parser algorithm adds two level of classes for each node in the output of Semantic Mapping module.", "labels": [], "entities": [{"text": "Semantic Mapping", "start_pos": 96, "end_pos": 112, "type": "TASK", "confidence": 0.7448609173297882}]}, {"text": "Word Sense Disambiguation () along with the lexical senses from WordNet (Miller, 1995) are used for this task.", "labels": [], "entities": [{"text": "Word Sense Disambiguation", "start_pos": 0, "end_pos": 25, "type": "TASK", "confidence": 0.7275425593058268}, {"text": "WordNet (Miller, 1995)", "start_pos": 64, "end_pos": 86, "type": "DATASET", "confidence": 0.8683753311634064}]}, {"text": "The fourth module corrects the mappings done by the mapping function by using class information extracted by the third module.", "labels": [], "entities": []}, {"text": "For example, if there is a relation is possessed by between two nodes with their superclass as person, then the relation is corrected to related to (because a person cannot possess another person).", "labels": [], "entities": []}, {"text": "Lastly, the fifth module implements other features such as semantic roles of the entities by using Propbank Framesets ().", "labels": [], "entities": []}, {"text": "An option for co-reference resolution is also provided in the system which uses state of the art, Stanford Co-reference resolver (.", "labels": [], "entities": [{"text": "co-reference resolution", "start_pos": 14, "end_pos": 37, "type": "TASK", "confidence": 0.7128229737281799}]}, {"text": "Furthermore, many other tools are also used at various steps in the above mentioned modules, such as Named Entity Tagging, WordNet database and Weka statistical classifier library.", "labels": [], "entities": [{"text": "Named Entity Tagging", "start_pos": 101, "end_pos": 121, "type": "TASK", "confidence": 0.6224116881688436}, {"text": "WordNet database", "start_pos": 123, "end_pos": 139, "type": "DATASET", "confidence": 0.9256740212440491}, {"text": "Weka statistical classifier library", "start_pos": 144, "end_pos": 179, "type": "DATASET", "confidence": 0.7929086536169052}]}, {"text": "We used KM library for labeling the relationship edges between nodes in the output graph.", "labels": [], "entities": []}, {"text": "There are 118 total relations available in KM.", "labels": [], "entities": []}, {"text": "Out of 118, there are 24 (12 bi-directional 2 ) relations that define the relationship between events.", "labels": [], "entities": []}, {"text": "These relations are used in K-Parser to capture event-event relations.", "labels": [], "entities": []}, {"text": "We also defined four new relations to represent some of the edge labels that were not captured in KM.", "labels": [], "entities": []}, {"text": "These relations are instance of, superclass, participant and related to.", "labels": [], "entities": []}, {"text": "The first two are used to represent two levels of conceptual class information associated with nodes in the graph.", "labels": [], "entities": []}, {"text": "The other two relations represent special relations between an event node and an entity node.", "labels": [], "entities": []}, {"text": "As mentioned before, apart from recognizing event mentions, K-Parser also have other features such as conceptual classes, semantic roles and an optional co-reference resolution.", "labels": [], "entities": []}], "datasetContent": [{"text": "K-Parser is developed based on the training sentences collected from many sources such as the example sentences from stanford dependency manual and dictionary examples for sentences with conjunctions.", "labels": [], "entities": []}, {"text": "We eval-84   uated the K-Parser output based on the types of events identified.", "labels": [], "entities": []}, {"text": "This is done by manually defining gold standard representation fora corpus of 282 Winograd Schema Challenge (WSC) () sentences (there is no overlap between test and training corpus).", "labels": [], "entities": [{"text": "Winograd Schema Challenge (WSC)", "start_pos": 82, "end_pos": 113, "type": "DATASET", "confidence": 0.7198876837889353}]}, {"text": "WSC is a well accepted corpus known to demonstrate complex semantics.", "labels": [], "entities": [{"text": "WSC", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.8822386860847473}]}, {"text": "We identified some important categories to assess the accuracy of event mentions and relations between events in the output of K-Parser.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 54, "end_pos": 62, "type": "METRIC", "confidence": 0.9977134466171265}]}, {"text": "The categories are number of Events, number of Entities, number of Classes, number of Event-Event relations and number of Event-Entity relations.", "labels": [], "entities": []}, {"text": "Each of the categories are compared with the gold standard based on measures mentioned below.", "labels": [], "entities": []}, {"text": "t 1 = identified and relevant and the label is correct.", "labels": [], "entities": []}, {"text": "t 2 = identified and relevant and the label is wrong.", "labels": [], "entities": []}, {"text": "t 3 = identified, but not relevant.", "labels": [], "entities": []}, {"text": "t 4 = not identified, but relevant.", "labels": [], "entities": []}, {"text": "We defined Precision and Recall of our system based on the above terms Precision = t 1 /(t 1 + t 2 + t 3 ) Recall = t 1 /(t 1 + t 2 + t 4 ) shows the evaluation results.", "labels": [], "entities": [{"text": "Precision", "start_pos": 11, "end_pos": 20, "type": "METRIC", "confidence": 0.9767903089523315}, {"text": "Recall", "start_pos": 25, "end_pos": 31, "type": "METRIC", "confidence": 0.9964093565940857}]}, {"text": "We have also used the output of our system in solving a subsection of the Winograd Schema Challenge ().", "labels": [], "entities": [{"text": "Winograd Schema Challenge", "start_pos": 74, "end_pos": 99, "type": "DATASET", "confidence": 0.8782758712768555}]}], "tableCaptions": []}