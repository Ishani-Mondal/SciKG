{"title": [{"text": "Which distributional cues help the most? Unsupervised contexts selection for lexical category acquisition", "labels": [], "entities": [{"text": "lexical category acquisition", "start_pos": 77, "end_pos": 105, "type": "TASK", "confidence": 0.6997401913007101}]}], "abstractContent": [{"text": "Starting from the distributional bootstrap-ping hypothesis, we propose an unsuper-vised model that selects the most useful distributional information according to its salience in the input, incorporating psy-cholinguistic evidence.", "labels": [], "entities": []}, {"text": "With a supervised Parts-of-Speech tagging experiment, we provide preliminary results suggesting that the distributional contexts extracted by our model yield similar performances as compared to current approaches from the literature , with again in psychological plau-sibility.", "labels": [], "entities": [{"text": "Parts-of-Speech tagging", "start_pos": 18, "end_pos": 41, "type": "TASK", "confidence": 0.8365629315376282}]}, {"text": "We also introduce a more princi-pled way to evaluate the effectiveness of distributional contexts in helping learners to group words in syntactic categories.", "labels": [], "entities": []}], "introductionContent": [], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Evaluation of several sets of distributional cues, with baselines at the top and our models grouped  according to the information included. Column 2 shows the number of salient contexts; column 3 shows  how many of them could not be used for categorization. Column 4 provides the percentage of words  from the training set (total = 3191) that could not be categorized by the contexts. Columns 5 and 6 raw  number of hits (test set = 2600 words) and accuracy on supervised PoS tagging.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 459, "end_pos": 467, "type": "METRIC", "confidence": 0.9997461438179016}, {"text": "PoS tagging", "start_pos": 482, "end_pos": 493, "type": "TASK", "confidence": 0.8349060416221619}]}]}