{"title": [{"text": "Conditional Random Fields for Identifying Appropriate Types of Support for Propositions in Online User Comments", "labels": [], "entities": [{"text": "Identifying Appropriate Types", "start_pos": 30, "end_pos": 59, "type": "TASK", "confidence": 0.836043914159139}]}], "abstractContent": [{"text": "Park and Cardie (2014) proposed a novel task of automatically identifying appropriate types of support for propositions comprising online user comments, as an essential step toward automated analysis of the adequacy of supporting information.", "labels": [], "entities": []}, {"text": "While multiclass Support Vector Machines (SVMs) proved to work reasonably well, they do not exploit the sequential nature of the problem: For instance, verifiable experiential propositions tend to appear together, because a personal narrative typically spans multiple propositions.", "labels": [], "entities": []}, {"text": "According to our experiments, however, Conditional Random Fields (CRFs) degrade the overall performance, and we discuss potential fixes to this problem.", "labels": [], "entities": []}, {"text": "Nonetheless, we observe that the F 1 score with respect to the unver-ifiable proposition class is increased.", "labels": [], "entities": [{"text": "F 1 score", "start_pos": 33, "end_pos": 42, "type": "METRIC", "confidence": 0.9858666062355042}]}, {"text": "Also, semi-supervised CRFs with posterior regular-ization trained on 75% labeled training data can closely match the performance of a supervised CRF trained on the same training data with the remaining 25% labeled as well.", "labels": [], "entities": []}], "introductionContent": [{"text": "The primary domain for argumentation mining has been professionally written text, such as parliamentary records, legal documents and news articles, which contain well-formed arguments consisting of explicitly stated premises and conclusions ().", "labels": [], "entities": [{"text": "argumentation mining", "start_pos": 23, "end_pos": 43, "type": "TASK", "confidence": 0.9428851902484894}]}, {"text": "In contrast, online user comments are often comprised of implicit arguments, which are conclusions with no explicitly stated premises . For instance, in the following user comment, neither of the two propositions are supported with a reason or evidence.", "labels": [], "entities": []}, {"text": "In other words, each of the two propositions is the conclusion of its own argument, with no explicit support provided (thus called implicit arguments): All airfare costs should include the passenger's right to check at least one standard piece of baggage.", "labels": [], "entities": []}, {"text": "A All fees should be fully disclosed at the time of airfare purchase, regardless of nature.", "labels": [], "entities": []}, {"text": "B When the goal is to extract well-formed arguments from a given text, one may simply disregard such implicit arguments.).", "labels": [], "entities": []}, {"text": "However, with the accumulation of a large amount of text consisting of implicit arguments, a means of assessing the adequacy of support in arguments has become increasingly desirable.", "labels": [], "entities": []}, {"text": "It is not only beneficial for analyzing the strength of arguments, but also for helping commenters to construct better arguments by suggesting the appropriate types of support to be provided.", "labels": [], "entities": []}, {"text": "As an initial step toward automatically assessing the adequacy of support in arguments, proposed a novel task of classifying each proposition based on the appropriate type of support: unverifiable (UNVERIF), verifiable nonexperiential (VERIF N ON ), or verifiable experiential (VERIF EXP ) 2 . They show that multiclass Support Vector Machines (SVMs) can perform reasonably well on this task.", "labels": [], "entities": [{"text": "verifiable nonexperiential (VERIF N ON )", "start_pos": 208, "end_pos": 248, "type": "METRIC", "confidence": 0.6913593113422394}]}, {"text": "SVMs, however, do not leverage on the sequential nature of the propositions: For instance, when a commenter writes about his past experience, it typically spans multiple propositions.", "labels": [], "entities": []}, {"text": "(In our dataset, VERIF EXP is followed by VERIF EXP with 57% probability, when VERIF EXP constitutes less than 15% of the entire dataset.)", "labels": [], "entities": [{"text": "VERIF EXP", "start_pos": 17, "end_pos": 26, "type": "METRIC", "confidence": 0.8454053699970245}, {"text": "VERIF EXP", "start_pos": 42, "end_pos": 51, "type": "METRIC", "confidence": 0.8958476483821869}]}, {"text": "Thus, we expect that the probability of a proposition being a verifiable experiential proposition significantly increases when the previous proposition is a verifiable experiential proposition.", "labels": [], "entities": []}, {"text": "In this paper, we test our intuition by employing Conditional Random Field (CRF), a popular approach for building probabilistic models to classify sequence data, for this task ().", "labels": [], "entities": [{"text": "Conditional Random Field (CRF)", "start_pos": 50, "end_pos": 80, "type": "METRIC", "confidence": 0.7292399207750956}]}, {"text": "In addition, we experiment with various ways to train CRFs in a semi-supervised fashion.", "labels": [], "entities": []}, {"text": "Unlike our intuition, we find that a CRF performs worse than a multiclass SVM overall.", "labels": [], "entities": []}, {"text": "Still, the F 1 score with respect to the UNVERIF class is improved.", "labels": [], "entities": [{"text": "F 1 score", "start_pos": 11, "end_pos": 20, "type": "METRIC", "confidence": 0.9916019837061564}, {"text": "UNVERIF class", "start_pos": 41, "end_pos": 54, "type": "DATASET", "confidence": 0.7283663749694824}]}, {"text": "Also, we show that semi-supervised CRFs with posterior regularization trained on 75% labeled training data can closely match the performance of a supervised CRF trained on the same training data with the remaining 25% labeled as well.", "labels": [], "entities": []}], "datasetContent": [{"text": "The experiments were conducted on the dataset from, which consists of user comments collected from RegulationRoom.org, an experimental eRulemaking site.", "labels": [], "entities": []}, {"text": "The dataset consists of user comments about rules proposed by government agencies, such as the Department of Transportation.", "labels": [], "entities": []}, {"text": "For comparison purposes, we used the same train/test split (See).", "labels": [], "entities": []}, {"text": "On average, roughly 8 propositions constitute a comment in both sets.", "labels": [], "entities": []}, {"text": "The goal of the experiments is two-fold: 1) comparing the overall performance of CRF-based approaches to the prior results from using multiclass SVMs and 2) analyzing how the semi-supervised CRFs perform with different percentages of the training data labeled, under different conditions.", "labels": [], "entities": []}, {"text": "To achieve this, a set of repeated experiments were conducted, where gradually increasing portions of the training set were used as labeled data with the remaining portion used as unlabeled data.", "labels": [], "entities": []}, {"text": "For evaluation, we use the macro-averaged F1 score computed over the three classes.", "labels": [], "entities": [{"text": "F1 score", "start_pos": 42, "end_pos": 50, "type": "METRIC", "confidence": 0.9649023413658142}]}, {"text": "Macro-F1 is used in the prior work, as well, to prevent the performance on the majority class, the multiclass SVM classifier performs better overall.", "labels": [], "entities": []}, {"text": "But at the same time, a clear trend can be observed: With CRF, the precision makes a significant gain at the cost of the recall for both VERIF N ON and VERIF EXP . And the opposite is the case for VERIF.", "labels": [], "entities": [{"text": "precision", "start_pos": 67, "end_pos": 76, "type": "METRIC", "confidence": 0.9994909763336182}, {"text": "recall", "start_pos": 121, "end_pos": 127, "type": "METRIC", "confidence": 0.9991564750671387}, {"text": "VERIF N ON", "start_pos": 137, "end_pos": 147, "type": "METRIC", "confidence": 0.8842863241831461}, {"text": "VERIF EXP", "start_pos": 152, "end_pos": 161, "type": "METRIC", "confidence": 0.4584864377975464}, {"text": "VERIF", "start_pos": 197, "end_pos": 202, "type": "DATASET", "confidence": 0.8226137757301331}]}, {"text": "One cause for this is the heavy skew in the dataset that can be better handled in SVMs; As mentioned before, the majority class (UNVERIF) comprises about 70% of the dataset.", "labels": [], "entities": []}, {"text": "When training the multiclass SVM, it is relatively straightforward to balance the class distribution in the training set, as each proposition is assumed to be independent of others.", "labels": [], "entities": []}, {"text": "Thus, Park and Cardie randomly oversample the instances of non-majority classes to construct a balanced trained set.", "labels": [], "entities": []}, {"text": "The situation is different for CRF, since the entire sequence of propositions comprising a comment is classified together.", "labels": [], "entities": []}, {"text": "Further investigation in resolving this issue is desirable.", "labels": [], "entities": []}, {"text": "Semi-supervised CRF reports the average performance of CRFs trained on 25%, 50%, 75% and 100% labeled training data (the same dataset), using various supervised and semi-supervised approaches over 5 rounds.", "labels": [], "entities": []}, {"text": "Though, the amount is small, incorporating semi-supervised approaches consistently boosts the performance for the most part.", "labels": [], "entities": []}, {"text": "The limited gain in performance is due to the small set of accurate constraints.", "labels": [], "entities": [{"text": "accurate", "start_pos": 59, "end_pos": 67, "type": "METRIC", "confidence": 0.9870411157608032}]}, {"text": "As discussed in Section 2.2, one crucial component of training CRFs with Posterior Regularization is designing constraints on features.", "labels": [], "entities": []}, {"text": "For a given feature, a respective constraint defines a probability distribution over the possible classes.", "labels": [], "entities": []}, {"text": "For the best performance, the distribution needs to be accurate, and the constrained features occur in the unlabeled training set frequently.", "labels": [], "entities": []}, {"text": "Super-CRF = supervised approach only using the labeled data, CRF-PR H = CRF with posterior regularization using constraints that are manually selected, CRF-PR H+IG = CRF with posterior regularization using constraints that are manually written and automatically generated using information gain.", "labels": [], "entities": []}, {"text": "*Precision, recall, and F 1 scores are computed with respect to each one-vs-all classification problem for evaluation purposes, though a single model is built for the multi-class classification problem.", "labels": [], "entities": [{"text": "Precision", "start_pos": 1, "end_pos": 10, "type": "METRIC", "confidence": 0.9993937015533447}, {"text": "recall", "start_pos": 12, "end_pos": 18, "type": "METRIC", "confidence": 0.9975443482398987}, {"text": "F 1 scores", "start_pos": 24, "end_pos": 34, "type": "METRIC", "confidence": 0.9879279136657715}, {"text": "multi-class classification", "start_pos": 167, "end_pos": 193, "type": "TASK", "confidence": 0.689615398645401}]}, {"text": "Our manual approach resulted in a small set of about 10 constraints on features that are tightly coupled with a class.", "labels": [], "entities": []}, {"text": "Examples include the word \"should\", large number of strong subjective expressions, and imperatives, which are all highly correlated with the UNVERIF.", "labels": [], "entities": [{"text": "UNVERIF", "start_pos": 141, "end_pos": 148, "type": "DATASET", "confidence": 0.8569396734237671}]}, {"text": "While the constraints are accurate, the coverage is too small to boost the performance.", "labels": [], "entities": [{"text": "coverage", "start_pos": 40, "end_pos": 48, "type": "METRIC", "confidence": 0.985047459602356}]}, {"text": "However, it is quite difficult to generate a large set of constraints, because there are not that many features that are indicative of a single class.", "labels": [], "entities": []}, {"text": "Also, given that UNVERIF comprises a large percentage of the dataset, and the nature of verifiability 6 , it is even more difficult to identify features tightly coupled with VERIF N ON and VERIF EXP class.", "labels": [], "entities": [{"text": "VERIF N ON", "start_pos": 174, "end_pos": 184, "type": "METRIC", "confidence": 0.918240467707316}]}, {"text": "One issue with automatically generated constraints, based on information gain, is that they tend to be inaccurate.", "labels": [], "entities": []}, {"text": "Verifiability does not have many characterizing features, but the lack of any of the characteristics of unverifiability, such as sentiment bearing words, is indicative of verifiability.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: # of Propositions in Training and Test Set", "labels": [], "entities": []}, {"text": " Table 2: Multi-SVM vs Supervised CRF Classification Results", "labels": [], "entities": []}, {"text": " Table 3: Supervised vs Semi-Supervised CRF Classification Results", "labels": [], "entities": [{"text": "Supervised vs Semi-Supervised CRF Classification", "start_pos": 10, "end_pos": 58, "type": "TASK", "confidence": 0.5235127568244934}]}]}