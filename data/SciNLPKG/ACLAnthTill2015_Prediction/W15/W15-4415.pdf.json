{"title": [{"text": "Chinese Grammatical Error Diagnosis Using Ensemble Learning", "labels": [], "entities": [{"text": "Chinese Grammatical Error Diagnosis", "start_pos": 0, "end_pos": 35, "type": "TASK", "confidence": 0.812029279768467}]}], "abstractContent": [{"text": "Automatic grammatical error detection for Chinese has been a big challenge for NLP researchers fora longtime, mostly due to the flexible and irregular ways in the expressing of this language.", "labels": [], "entities": [{"text": "grammatical error detection", "start_pos": 10, "end_pos": 37, "type": "TASK", "confidence": 0.5860413014888763}]}, {"text": "Strictly speaking, there is no evidence of a series of formal and strict grammar rules for Chinese, especially for the spoken Chi-nese, making it hard for foreigners to master this language.", "labels": [], "entities": []}, {"text": "The CFL shared task provides a platform for the researchers to develop automatic engines to detect grammatical errors based on a number of manually annotated Chinese spoken sentences.", "labels": [], "entities": []}, {"text": "This paper introduces HITSZ's system for this year's Chinese grammatical error diagnosis (CGED) task.", "labels": [], "entities": [{"text": "Chinese grammatical error diagnosis (CGED) task", "start_pos": 53, "end_pos": 100, "type": "TASK", "confidence": 0.8142930120229721}]}, {"text": "Similar to the last year's task, we put our emphasis mostly on the error detection level and error type identification level but did little for the position level.", "labels": [], "entities": [{"text": "error detection", "start_pos": 67, "end_pos": 82, "type": "TASK", "confidence": 0.755296140909195}, {"text": "error type identification", "start_pos": 93, "end_pos": 118, "type": "TASK", "confidence": 0.6098708311716715}]}, {"text": "For all our models, we simply use supervised machine learning methods constrained to the given training corpus, with neither any heuristic rules nor any other refer-enced materials (except for the last years' data).", "labels": [], "entities": []}, {"text": "Among the three runs of results we submitted, the one using the ensemble classifier Random Feature Subspace (HITSZ_Run1) gained the best performance , with an optimal F1 of 0.6648 for the detection level and 0.2675 for the identification level.", "labels": [], "entities": [{"text": "F1", "start_pos": 167, "end_pos": 169, "type": "METRIC", "confidence": 0.9975524544715881}]}], "introductionContent": [{"text": "Automatic grammatical error detection for Chinese has been a big challenge for NLP researchers fora longtime, mostly due to the flexible and irregular ways in the expressing of this language.", "labels": [], "entities": [{"text": "grammatical error detection", "start_pos": 10, "end_pos": 37, "type": "TASK", "confidence": 0.5860415399074554}]}, {"text": "Different from English which follows grammatical rules strictly (i.e. subject-verb agreement, or strict tenses and modals), the Chinese language has no verb tenses or numbers and endures heavily for the incompleteness of grammatical elements in a sentence (i.e. the zero subject or verb or object).", "labels": [], "entities": []}, {"text": "Some examples are shown below in.", "labels": [], "entities": []}], "datasetContent": [{"text": "In the experiment, we use the training data from this year's and last year's shared tasks.", "labels": [], "entities": []}, {"text": "lists the number of sentences for each type in the training data.", "labels": [], "entities": []}, {"text": "Since the scale of this year's data is really small, we add last year's corpus into the training data and do cross validations in the training steps.", "labels": [], "entities": []}, {"text": "lists the number of sentences for each error type in these two years' dataset.", "labels": [], "entities": []}, {"text": "Our experiments cover training data construction, feature selection and supervised learning.", "labels": [], "entities": [{"text": "training data construction", "start_pos": 22, "end_pos": 48, "type": "TASK", "confidence": 0.6878204147020975}, {"text": "feature selection", "start_pos": 50, "end_pos": 67, "type": "TASK", "confidence": 0.8103280365467072}]}, {"text": "We tried several groups of training data, different combinations of features and a variety of classifiers in the training phase.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 3. CV results based on POS Tri-gram features", "labels": [], "entities": [{"text": "POS Tri-gram", "start_pos": 30, "end_pos": 42, "type": "DATASET", "confidence": 0.8473781049251556}]}, {"text": " Table 4. CV results based on POS Tri-gram and probability features", "labels": [], "entities": [{"text": "probability", "start_pos": 47, "end_pos": 58, "type": "METRIC", "confidence": 0.9490846395492554}]}, {"text": " Table 2. Error type distribution for the two  years' shared tasks.", "labels": [], "entities": [{"text": "Error type distribution", "start_pos": 10, "end_pos": 33, "type": "METRIC", "confidence": 0.9012563228607178}]}, {"text": " Table 5. The final results", "labels": [], "entities": []}]}