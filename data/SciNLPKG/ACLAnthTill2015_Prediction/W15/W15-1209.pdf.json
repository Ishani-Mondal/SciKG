{"title": [{"text": "Proceedings of the 2nd Workshop on Computational Linguistics and Clinical Psychology: From Linguistic Signal Recursive Neural Networks for Coding Therapist and Patient Behavior in Motivational Interviewing", "labels": [], "entities": []}], "abstractContent": [{"text": "Motivational Interviewing (MI) is an effica-cious treatment for substance use disorders and other problem behaviors (Lundahl and Burke, 2009).", "labels": [], "entities": [{"text": "Motivational Interviewing (MI)", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.7915267765522003}]}, {"text": "However, little is known about the specific mechanisms that drive therapeutic change.", "labels": [], "entities": []}, {"text": "A growing body of research has focused on coding within-session language to better understand how therapist and patient language mutually influence each other and predict successful (or unsuccessful) treatment outcomes.", "labels": [], "entities": []}, {"text": "These studies typically use human raters, requiring considerable financial, time, and training costs for conducting such research.", "labels": [], "entities": []}, {"text": "This paper describes the development and testing of a recursive neural network (RNN) model for rating 78,977 therapist and patient talk turns across 356 MI sessions.", "labels": [], "entities": []}, {"text": "We assessed the accuracy of RNNs in predicting human ratings for client speech and compared them to standard n-gram models.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 16, "end_pos": 24, "type": "METRIC", "confidence": 0.9979023933410645}, {"text": "predicting human ratings", "start_pos": 36, "end_pos": 60, "type": "TASK", "confidence": 0.8486310243606567}]}, {"text": "The RNN model showed improvement over ngram models for some codes, but overall, all of the models performed well below human reliability, demonstrating the difficulty of the task.", "labels": [], "entities": []}], "introductionContent": [], "datasetContent": [{"text": "To evaluate the performance of the RNN and n-gram models we compared precision (i.e., proportion of model-derived codes that matched human raters), recall (i.e., proportion of human-rated codes that were correctly identified by the model), and F1 scores (i.e., the harmonic mean of precision and recall) for each model.", "labels": [], "entities": [{"text": "precision", "start_pos": 69, "end_pos": 78, "type": "METRIC", "confidence": 0.9994051456451416}, {"text": "recall", "start_pos": 148, "end_pos": 154, "type": "METRIC", "confidence": 0.999362051486969}, {"text": "F1 scores", "start_pos": 244, "end_pos": 253, "type": "METRIC", "confidence": 0.9880579710006714}, {"text": "precision", "start_pos": 282, "end_pos": 291, "type": "METRIC", "confidence": 0.9893180727958679}, {"text": "recall", "start_pos": 296, "end_pos": 302, "type": "METRIC", "confidence": 0.99504554271698}]}, {"text": "The current results are an early stage in the process toward developing a final model.", "labels": [], "entities": []}, {"text": "As such, all models were evaluated using 5 fold cross validation on the section of the dataset that is designated as training data (which is two thirds of the total dataset).", "labels": [], "entities": []}, {"text": "The cross validation subsets were divided by session (so each session could only occur in one or the other subsets).", "labels": [], "entities": []}, {"text": "The testing section of the data will be used at a later date when the modeling process is complete.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Cross Validation Results: Change Talk", "labels": [], "entities": [{"text": "Cross Validation", "start_pos": 10, "end_pos": 26, "type": "TASK", "confidence": 0.7890721261501312}]}, {"text": " Table 2: Cross Validation Results: Sustain Talk", "labels": [], "entities": [{"text": "Cross Validation", "start_pos": 10, "end_pos": 26, "type": "TASK", "confidence": 0.7864664494991302}, {"text": "Sustain", "start_pos": 36, "end_pos": 43, "type": "TASK", "confidence": 0.8931294083595276}]}]}