{"title": [{"text": "A Language Detection System for Short Chats in Mobile Games", "labels": [], "entities": [{"text": "Language Detection", "start_pos": 2, "end_pos": 20, "type": "TASK", "confidence": 0.7171677052974701}]}], "abstractContent": [{"text": "Machine Translation system accuracies are often brought down due to inaccurate Language Detection (LD) of input phrases.", "labels": [], "entities": [{"text": "Machine Translation system", "start_pos": 0, "end_pos": 26, "type": "TASK", "confidence": 0.8377130230267843}, {"text": "accuracies", "start_pos": 27, "end_pos": 37, "type": "METRIC", "confidence": 0.6160872578620911}, {"text": "Language Detection (LD) of input phrases", "start_pos": 79, "end_pos": 119, "type": "TASK", "confidence": 0.7694618478417397}]}, {"text": "The Language detection accuracy is further affected when the inputs are short and contain ungram-matical phrases, especially in a multilingual mobile game setting.", "labels": [], "entities": [{"text": "Language detection", "start_pos": 4, "end_pos": 22, "type": "TASK", "confidence": 0.706342950463295}, {"text": "accuracy", "start_pos": 23, "end_pos": 31, "type": "METRIC", "confidence": 0.9010812044143677}]}, {"text": "Chat messages in mobile games are often short as they are typed on mobile devices and contain slang as a common communication preference.", "labels": [], "entities": []}, {"text": "Previous work has shown that LD systems have a drop inaccuracy when the inputs are short messages instead of long ones.", "labels": [], "entities": []}, {"text": "This paper targets LD for short chat messages in mobile games.", "labels": [], "entities": []}, {"text": "We propose a novel LD system which integrates text-based and user-based methods to achieve significantly better performance over current state-of-the-art LD systems.", "labels": [], "entities": []}], "introductionContent": [{"text": "With the growth of social media, a huge amount of social media texts have become ubiquitous, e.g., Twitter messages, Facebook updates, game chat messages, etc.", "labels": [], "entities": []}, {"text": "Due to their importance, Natural Language Processing (NLP) applications have been applied to social media texts, e.g., and recognized named entities in Twitter messages, and investigated Part-Of-Speech tagging and parsing of Twitter messages.", "labels": [], "entities": [{"text": "Part-Of-Speech tagging and parsing of Twitter messages", "start_pos": 187, "end_pos": 241, "type": "TASK", "confidence": 0.7459870960031237}]}, {"text": "As the phenomenon is prevelant across the globe, social media texts are usually multilingual, while most of the NLP applications are language-specific.", "labels": [], "entities": []}, {"text": "We usually have to know the language of a given message, in order to process the message using appropriate NLP applications.", "labels": [], "entities": []}, {"text": "Accuracy of Language Detection (LD) is thus highly critical for subsequent NLP applications.", "labels": [], "entities": [{"text": "Accuracy of Language Detection (LD)", "start_pos": 0, "end_pos": 35, "type": "TASK", "confidence": 0.8060316443443298}]}, {"text": "LD on long messages is widely considered a solved problem as its accuracy is often found to be high with latest methods (.", "labels": [], "entities": [{"text": "LD", "start_pos": 0, "end_pos": 2, "type": "TASK", "confidence": 0.9619689583778381}, {"text": "accuracy", "start_pos": 65, "end_pos": 73, "type": "METRIC", "confidence": 0.9991907477378845}]}, {"text": "However, more and more researchers have recently noted that LD on short messages is very difficult.", "labels": [], "entities": [{"text": "LD", "start_pos": 60, "end_pos": 62, "type": "TASK", "confidence": 0.9852212071418762}]}, {"text": "E.g, found LD became increasingly difficult as we reduced the length of documents, and increased the number of languages.", "labels": [], "entities": [{"text": "LD", "start_pos": 11, "end_pos": 13, "type": "TASK", "confidence": 0.9531103372573853}]}, {"text": "found LD of microblogs was challenging for state-of-the-art LD methods.", "labels": [], "entities": [{"text": "LD", "start_pos": 6, "end_pos": 8, "type": "TASK", "confidence": 0.9727666974067688}]}, {"text": "Moreover, LD studies mostly focus on Twitter messages, as Twitter provides an API for researchers to crawl public Twitter messages, while no research is done on game chat messages, which in itself contains language that has quite a bit more slang than Twitter messages.", "labels": [], "entities": []}, {"text": "In this paper, we propose a novel LD system for chat messages in a mobile game which has a builtin chat translation system.", "labels": [], "entities": []}, {"text": "The translation system helps players speaking different languages chat with each other.", "labels": [], "entities": [{"text": "translation", "start_pos": 4, "end_pos": 15, "type": "TASK", "confidence": 0.9648641347885132}]}, {"text": "The LD system is used to detect language of chat messages such that the chat translation system could know which language a message should be translated from.", "labels": [], "entities": []}, {"text": "Chat messages in mobile games are different from other social media texts, because it is inconvenient to type on mobile devices leading to an increased misspelling rate, and game chats tend to be much shorter than Twitter messages (see Section 3).", "labels": [], "entities": []}, {"text": "Our work is furthermore challenging, as we are detecting 27 languages.", "labels": [], "entities": []}], "datasetContent": [{"text": "As far as we know, most previous LD work on short messages () focused on Twitter messages, and no previous work explored LD for game chat messages.", "labels": [], "entities": []}, {"text": "We thus create a LD data set containing multilingual chat messages sent in mobile games with the method described in Section 4.1.", "labels": [], "entities": []}, {"text": "We first create a data set containing chat messages  in 27 languages supported by the game, then splitting the messages for each language into a training set (named TRAIN) and a test set (named FULL).", "labels": [], "entities": [{"text": "TRAIN", "start_pos": 165, "end_pos": 170, "type": "METRIC", "confidence": 0.9905067682266235}, {"text": "FULL", "start_pos": 194, "end_pos": 198, "type": "METRIC", "confidence": 0.9944918155670166}]}, {"text": "As our focus is on short messages, we also generate four other test sets based on FULL.", "labels": [], "entities": [{"text": "FULL", "start_pos": 82, "end_pos": 86, "type": "METRIC", "confidence": 0.8759918212890625}]}, {"text": "We have truncated each message in FULL to retain the first n tokens 5 , thus generating 4 new test sets named as LENn where n \u2208 {1, 2, 3, 4}.", "labels": [], "entities": [{"text": "FULL", "start_pos": 34, "end_pos": 38, "type": "DATASET", "confidence": 0.6190778017044067}, {"text": "LENn", "start_pos": 113, "end_pos": 117, "type": "METRIC", "confidence": 0.991969645023346}]}, {"text": "In LENn, only unique messages are retained based on only texts, e.g., if we have (text=\"thx tom\", userid=\"123\", lang=\"en\") and (text=\"thx boss\", userid=\"456\", lang=\"en\") in FULL, we only keep one message (text=\"thx\", userid=\"123\", lang=\"en\") generated from the two messages in the data set LEN1.", "labels": [], "entities": [{"text": "FULL", "start_pos": 173, "end_pos": 177, "type": "DATASET", "confidence": 0.7520216107368469}]}, {"text": "The statistics of the resulted data sets are shown in.", "labels": [], "entities": []}, {"text": "Following, we also use accuracy, i.e., the percentage of messages whose language is detected correctly, to evaluate the effect of LD.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 23, "end_pos": 31, "type": "METRIC", "confidence": 0.9993427395820618}]}, {"text": "The experimental results on data set LEN1 are shown in, from which we can see that for extremely short messages containing only 1 token, LANGID performs poorly with an average accuracy of 34.88%.", "labels": [], "entities": [{"text": "LANGID", "start_pos": 137, "end_pos": 143, "type": "METRIC", "confidence": 0.9242016673088074}, {"text": "accuracy", "start_pos": 176, "end_pos": 184, "type": "METRIC", "confidence": 0.9989359974861145}]}, {"text": "DICT works better than LANGID on the 10 languages supported by DICT, which shows that dictionary-based methods are very useful in LD for short messages, though detecting 10 languages is much easier than detecting 27 languages.", "labels": [], "entities": [{"text": "DICT", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.6323011517524719}, {"text": "LANGID", "start_pos": 23, "end_pos": 29, "type": "METRIC", "confidence": 0.8146100044250488}]}, {"text": "Moreover, PROFILE achieves very amazing accuracies on 1-token messages, which confirms the critical importance of user language profiles in LD of very short messages.", "labels": [], "entities": []}, {"text": "At last, COMB successfully combines the three systems above and the alphabetbased LD method, achieving a relatively high accuracy of 73.69% on 1-token messages, which outperforms PROFILE by 11.48% accuracy.", "labels": [], "entities": [{"text": "COMB", "start_pos": 9, "end_pos": 13, "type": "DATASET", "confidence": 0.5999467968940735}, {"text": "accuracy", "start_pos": 121, "end_pos": 129, "type": "METRIC", "confidence": 0.9989049434661865}, {"text": "accuracy", "start_pos": 197, "end_pos": 205, "type": "METRIC", "confidence": 0.9959309697151184}]}, {"text": "Note that the AVERAGE is macro-average., 4 and 5 respectively present the results on data set LEN2, LEN3 and LEN4.", "labels": [], "entities": [{"text": "AVERAGE", "start_pos": 14, "end_pos": 21, "type": "METRIC", "confidence": 0.99892657995224}]}, {"text": "LANGID's accuracy increases as the message length increases, as expected.", "labels": [], "entities": [{"text": "LANGID", "start_pos": 0, "end_pos": 6, "type": "METRIC", "confidence": 0.7806604504585266}, {"text": "accuracy", "start_pos": 9, "end_pos": 17, "type": "METRIC", "confidence": 0.9926199316978455}]}, {"text": "Because more text is available.", "labels": [], "entities": []}, {"text": "PRO-FILE maintains a stable accuracy at about 63.5% on all the 3 data sets, since it only depends on the user who sends the message, and is independent on texts.", "labels": [], "entities": [{"text": "PRO-FILE", "start_pos": 0, "end_pos": 8, "type": "DATASET", "confidence": 0.6263606548309326}, {"text": "accuracy", "start_pos": 28, "end_pos": 36, "type": "METRIC", "confidence": 0.9989263415336609}]}, {"text": "COMB again performs best among the 4 systems.", "labels": [], "entities": [{"text": "COMB", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.9331375360488892}]}, {"text": "The experimental results on data set FULL are shown in.", "labels": [], "entities": [{"text": "FULL", "start_pos": 37, "end_pos": 41, "type": "METRIC", "confidence": 0.7605833411216736}]}, {"text": "LANGID works much better on full-length messages than on shorter messages.", "labels": [], "entities": [{"text": "LANGID", "start_pos": 0, "end_pos": 6, "type": "METRIC", "confidence": 0.7702441215515137}]}, {"text": "PROFILE still keeps a stable accuracy at 63.57%.", "labels": [], "entities": [{"text": "PROFILE", "start_pos": 0, "end_pos": 7, "type": "DATASET", "confidence": 0.7933300137519836}, {"text": "accuracy", "start_pos": 29, "end_pos": 37, "type": "METRIC", "confidence": 0.999363124370575}]}, {"text": "COMB performs best with an average accuracy of 84.61% on the 27 languages.", "labels": [], "entities": [{"text": "COMB", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.9348369836807251}, {"text": "accuracy", "start_pos": 35, "end_pos": 43, "type": "METRIC", "confidence": 0.998738706111908}]}, {"text": "As a summary, the average accuracy of LANGID varies from 34.88% to 74.53% on the 5 test sets of messages of different lengths, which shows that the traditional LD methods relying on text-based features perform poorly on short messages.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 26, "end_pos": 34, "type": "METRIC", "confidence": 0.9993876218795776}, {"text": "LANGID", "start_pos": 38, "end_pos": 44, "type": "METRIC", "confidence": 0.7839735746383667}]}, {"text": "PROFILE works consistently well on the test sets with an accuracy at about 63%.", "labels": [], "entities": [{"text": "PROFILE", "start_pos": 0, "end_pos": 7, "type": "DATASET", "confidence": 0.7379572987556458}, {"text": "accuracy", "start_pos": 57, "end_pos": 65, "type": "METRIC", "confidence": 0.9996964931488037}]}, {"text": "Our proposed system COMB can effectively integrate LANGID, DICT, and PROFILE    together, consistently outperforming all the baselines on test sets of messages of different lengths.", "labels": [], "entities": [{"text": "COMB", "start_pos": 20, "end_pos": 24, "type": "DATASET", "confidence": 0.7160090804100037}, {"text": "LANGID", "start_pos": 51, "end_pos": 57, "type": "METRIC", "confidence": 0.8752042055130005}, {"text": "DICT", "start_pos": 59, "end_pos": 63, "type": "METRIC", "confidence": 0.8179755210876465}]}, {"text": "COMB achieves a relatively consistent and high accuracy on messages of varied lengths from 73.69% to 84.61%.", "labels": [], "entities": [{"text": "COMB", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.8078988790512085}, {"text": "accuracy", "start_pos": 47, "end_pos": 55, "type": "METRIC", "confidence": 0.9990549683570862}]}, {"text": "These results confirm the potential of the proposed system.", "labels": [], "entities": []}, {"text": "We also found both LANGID and COMB perform poorly on Malay and Catalan, which maybe due to the fact that Malay is very similar to Indonesian, and that Catalan is similar to French and Spanish.", "labels": [], "entities": [{"text": "LANGID", "start_pos": 19, "end_pos": 25, "type": "METRIC", "confidence": 0.9121828675270081}, {"text": "COMB", "start_pos": 30, "end_pos": 34, "type": "DATASET", "confidence": 0.5234641432762146}]}], "tableCaptions": [{"text": " Table 1: Statistics of the LD data sets created from game chat messages.", "labels": [], "entities": [{"text": "LD data sets", "start_pos": 28, "end_pos": 40, "type": "DATASET", "confidence": 0.8224136829376221}]}, {"text": " Table 2: Accuracies (%) of LD methods on LEN1.", "labels": [], "entities": [{"text": "Accuracies", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.998773992061615}]}, {"text": " Table 3: Accuracies (%) of LD methods on LEN2.", "labels": [], "entities": [{"text": "Accuracies", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.9987375140190125}]}]}