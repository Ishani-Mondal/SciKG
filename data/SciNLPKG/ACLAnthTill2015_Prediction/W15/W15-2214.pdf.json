{"title": [], "abstractContent": [{"text": "This article proposes a syntactic parsing strategy based on a dependency grammar containing both formal rules and a compression technique that reduces the complexity of those rules.", "labels": [], "entities": [{"text": "syntactic parsing", "start_pos": 24, "end_pos": 41, "type": "TASK", "confidence": 0.7133511304855347}]}, {"text": "Compression parsing is mainly driven by the single-head constraint of Dependency Grammar, and can be seen as an alternative method to the well-known constructive strategy.", "labels": [], "entities": [{"text": "Compression parsing", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.8926643133163452}]}, {"text": "The compression algorithm simplifies the input sentence by progressively removing from it the dependent tokens as soon as binary syntactic dependencies are recognized.", "labels": [], "entities": []}, {"text": "The performance of our system was compared to a deterministic parser based on supervised learning: MaltParser.", "labels": [], "entities": []}, {"text": "Both systems were applied on several test sets of sentences in Spanish and Portuguese, from a variety of different domains and genres.", "labels": [], "entities": []}, {"text": "Results showed that our parsing method keeps a similar performance through related languages and different domains, while MaltParser, as most supervised methods, turns out to be very dependent on the text domain used to train the system.", "labels": [], "entities": [{"text": "parsing", "start_pos": 24, "end_pos": 31, "type": "TASK", "confidence": 0.9687281847000122}]}], "introductionContent": [{"text": "For large scale applications in Information Extraction (IE), syntactic parsing should be robust, fast, and relatively accurate.", "labels": [], "entities": [{"text": "Information Extraction (IE)", "start_pos": 32, "end_pos": 59, "type": "TASK", "confidence": 0.8651965379714965}, {"text": "syntactic parsing", "start_pos": 61, "end_pos": 78, "type": "TASK", "confidence": 0.7639424502849579}]}, {"text": "Moreover, for specific IE applications such as semantic relation extraction, the output of parsing should be simple, easy to handle by the IE systems, and close to the semantic relationships to be extracted.", "labels": [], "entities": [{"text": "semantic relation extraction", "start_pos": 47, "end_pos": 75, "type": "TASK", "confidence": 0.6566269397735596}]}, {"text": "For multilingual purposes, it is important to develop parsing techniques easily adapted to several languages.", "labels": [], "entities": [{"text": "parsing", "start_pos": 54, "end_pos": 61, "type": "TASK", "confidence": 0.9705665707588196}]}, {"text": "And finally, in order to be easily integrated in several NLP applications and tasks, the parsers should be applied on different text domains and genres with similar accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 165, "end_pos": 173, "type": "METRIC", "confidence": 0.9927640557289124}]}, {"text": "There are two well known approaches that could be considered as good approximations to the ideal system filling all these parsing properties: both deterministic dependency parsing) and partial parsing using rule-based finitestate techniques.", "labels": [], "entities": [{"text": "deterministic dependency parsing", "start_pos": 147, "end_pos": 179, "type": "TASK", "confidence": 0.7399712800979614}, {"text": "partial parsing", "start_pos": 185, "end_pos": 200, "type": "TASK", "confidence": 0.6536984145641327}]}, {"text": "However, these two parsing approaches have still some problems.", "labels": [], "entities": [{"text": "parsing", "start_pos": 19, "end_pos": 26, "type": "TASK", "confidence": 0.9767516851425171}]}, {"text": "Recent work on deterministic dependency parsing (called 'transition based') relies on supervised techniques requiring fully analyzed training corpora.", "labels": [], "entities": [{"text": "deterministic dependency parsing", "start_pos": 15, "end_pos": 47, "type": "TASK", "confidence": 0.6278980175654093}]}, {"text": "Given that supervised techniques tend to have loss of precision when applied on texts of domains and genres different to those used for training (, they need too much manual effort to create, adapt, or modify the training corpus to the target domain.", "labels": [], "entities": [{"text": "precision", "start_pos": 54, "end_pos": 63, "type": "METRIC", "confidence": 0.996541440486908}]}, {"text": "Speed is not actually a problem for finite-state techniques, which can parse large text corpora in a very efficient way.", "labels": [], "entities": [{"text": "Speed", "start_pos": 0, "end_pos": 5, "type": "METRIC", "confidence": 0.9842398166656494}]}, {"text": "However, as they rely on complex rule-based notations, their main drawback is the difficulty to adapt such a rule system to different languages.", "labels": [], "entities": []}, {"text": "Moreover, as most finite-state parsers are based on constituency grammars, their syntactic output cannot be easily integrated into IE applications.", "labels": [], "entities": []}, {"text": "Unlike phrase constituents, dependencies are seen as simple and flat syntactic representations, very close to semantic relations which are the extraction target of many IE systems.", "labels": [], "entities": []}, {"text": "Many finite-state parsers are based on the constructive strategy).", "labels": [], "entities": []}, {"text": "In constructive parsing, an input sentence is manipulated by transducers that progressively transform the input with additional symbols encoding syntactic constituents or dependency relations.", "labels": [], "entities": [{"text": "constructive parsing", "start_pos": 3, "end_pos": 23, "type": "TASK", "confidence": 0.6387782543897629}]}, {"text": "These transducers are pattern rules arranged in cascades: the output of a transducer is the input of the next one, which contains new rules adapted to the symbols added to the input.", "labels": [], "entities": []}, {"text": "So, parsing consists in transforming a basic input string into a more complex one by incrementally adding new symbols, bracket delimiters, labels, or special markers.", "labels": [], "entities": [{"text": "parsing", "start_pos": 4, "end_pos": 11, "type": "TASK", "confidence": 0.9661155939102173}]}, {"text": "This strategy incrementally constructs the linguistic representation within the input string, by making use of rules organized at different levels of complexity.", "labels": [], "entities": []}, {"text": "In this article, we propose anew (rule-based) finite-state parsing strategy based on dependencies, which minimizes the complexity of rules by using a technique we call compression.", "labels": [], "entities": [{"text": "finite-state parsing", "start_pos": 46, "end_pos": 66, "type": "TASK", "confidence": 0.5829575657844543}]}, {"text": "Compression parsing is driven by the \"single-head\" constraint of Dependency Grammar, and can be seen as an alternative method to the constructive strategy.", "labels": [], "entities": [{"text": "Compression parsing", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.8511373996734619}, {"text": "Dependency Grammar", "start_pos": 65, "end_pos": 83, "type": "TASK", "confidence": 0.5746452808380127}]}, {"text": "It simplifies the input string by progressively removing the dependent tokens as binary syntactic dependencies are recognized.", "labels": [], "entities": []}, {"text": "At the end of the compression process, if all the dependencies in the sentence were recognized, the input string should contain just one token representing the main head (i.e., the root) of the sentence.", "labels": [], "entities": []}, {"text": "This strategy was inspired by the Right and Left Reduce transitions used in deterministic dependency parsing.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 90, "end_pos": 108, "type": "TASK", "confidence": 0.6806348711252213}]}, {"text": "The input sentence is assumed to be tagged and disambiguated with a Part-Of-Speech (PoS) tagger.", "labels": [], "entities": []}, {"text": "Moreover, the cost of manually creating rules can also be reduced by providing a suitable rule notation for linguists.", "labels": [], "entities": []}, {"text": "As in Ait-, we hold that the ordering of rules/transducers is in itself a genuine linguistic task, which must preserve the basic principle of doing the easiest task first.", "labels": [], "entities": []}, {"text": "If rules (and so the grammar) are written following this principle, it is possible to use finite-state automata to deal with embedding structures and long-distance dependencies.", "labels": [], "entities": []}, {"text": "Note that this is a deterministic parsing strategy, since it cannot produce ambiguous structures.", "labels": [], "entities": []}, {"text": "The use of grammars in recent dependency parsers is almost non-existent.", "labels": [], "entities": []}, {"text": "Our work propose to incorporate more linguistic knowledge into the parsing systems via light-weight grammars.", "labels": [], "entities": []}, {"text": "Finally, a system based on the compression strategy was implemented and released under General Public License.", "labels": [], "entities": []}, {"text": "In addition, we defined a high level grammar language to define dependency-based rules and developed a grammar compiler to generate compression parsers in several languages ().", "labels": [], "entities": []}, {"text": "The performance of this system was compared to), a deterministic parser based on supervised learning.", "labels": [], "entities": []}, {"text": "Both systems were applied on several test sets of sentences of different domains and genres, in Spanish and Portuguese.", "labels": [], "entities": []}, {"text": "One of the main motivations of the evaluation is to test whether the two systems are reliable to parse sentences of different domains and genres.", "labels": [], "entities": []}, {"text": "It is generally accepted that supervised classifiers require some type of domain adaptation when both the training and test data sets belong to different domains.", "labels": [], "entities": []}, {"text": "In particular, the accuracy of statistical parsers degrades when they are applied to different genres and domains (.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 19, "end_pos": 27, "type": "METRIC", "confidence": 0.9990874528884888}]}, {"text": "Results showed that our system keeps a similar performance through related languages and different domains, while MaltParser, as most supervised methods, is very dependent on the text domain used to train the system.", "labels": [], "entities": []}, {"text": "The remainder of this article is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 introduces different approaches on both dependency and FST parsing.", "labels": [], "entities": [{"text": "FST parsing", "start_pos": 65, "end_pos": 76, "type": "TASK", "confidence": 0.9495473504066467}]}, {"text": "Then, Section 3 is focused on the description of our compression strategy.", "labels": [], "entities": []}, {"text": "Next, Section 4 provides a general view of the implemented system.", "labels": [], "entities": []}, {"text": "Then Section 5 reports the diverse experiments performed over the Portuguese and Spanish data sets.", "labels": [], "entities": [{"text": "Portuguese and Spanish data sets", "start_pos": 66, "end_pos": 98, "type": "DATASET", "confidence": 0.7162303626537323}]}, {"text": "And finally, some conclusions are addressed in Section 6.", "labels": [], "entities": []}], "datasetContent": [{"text": "Our objective is to compare the performance of our FST-based strategy with that of a transitionbased system.", "labels": [], "entities": [{"text": "FST-based", "start_pos": 51, "end_pos": 60, "type": "TASK", "confidence": 0.7813090085983276}]}, {"text": "For this purpose, we compare DepPattern with MaltParser), one of the top performing systems in the CoNLL shared tasks on multilingual dependency parsing in).", "labels": [], "entities": [{"text": "multilingual dependency parsing", "start_pos": 121, "end_pos": 152, "type": "TASK", "confidence": 0.576739231745402}]}, {"text": "Experiments were performed on two languages: Portuguese and Spanish.", "labels": [], "entities": []}, {"text": "The reason of making experiments on only two languages is the very high cost required to adapt the outputs of our system to the test data set.", "labels": [], "entities": []}, {"text": "To evaluate the performance of the two systems, it is necessary to take into account that DepPattern produces partial parses.", "labels": [], "entities": []}, {"text": "This system assigns the dependency relation '0' (or Root) to all unattached tokens.", "labels": [], "entities": []}, {"text": "So, it is relevant to make use of precision and recall, instead of accuracy, to measure the performance of the DepPattern parsers.", "labels": [], "entities": [{"text": "precision", "start_pos": 34, "end_pos": 43, "type": "METRIC", "confidence": 0.999396562576294}, {"text": "recall", "start_pos": 48, "end_pos": 54, "type": "METRIC", "confidence": 0.9986396431922913}, {"text": "accuracy", "start_pos": 67, "end_pos": 75, "type": "METRIC", "confidence": 0.9993398785591125}]}, {"text": "For MaltParser, precision and recall are the same: these values correspond to the unlabeled attachment score (UAS).", "labels": [], "entities": [{"text": "precision", "start_pos": 16, "end_pos": 25, "type": "METRIC", "confidence": 0.9996132254600525}, {"text": "recall", "start_pos": 30, "end_pos": 36, "type": "METRIC", "confidence": 0.9995563626289368}, {"text": "unlabeled attachment score (UAS)", "start_pos": 82, "end_pos": 114, "type": "METRIC", "confidence": 0.803668017188708}]}, {"text": "Furthermore, as the dependency labels of DepPattern are very different from those found in the two treebanks, the evaluation was restricted to unlabeled dependencies.", "labels": [], "entities": []}, {"text": "Parser evaluation is conducted by comparing the dependencies guessed by the system with manually revised dependencies.", "labels": [], "entities": [{"text": "Parser evaluation", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.8021408915519714}]}, {"text": "Given these two data sets, precision and recall are defined as in.", "labels": [], "entities": [{"text": "precision", "start_pos": 27, "end_pos": 36, "type": "METRIC", "confidence": 0.9997355341911316}, {"text": "recall", "start_pos": 41, "end_pos": 47, "type": "METRIC", "confidence": 0.9996703863143921}]}, {"text": "As '0' values, associated to unattached tokens, are considered as not found dependencies, they are relevant to measure recall in DepPattern.", "labels": [], "entities": [{"text": "recall", "start_pos": 119, "end_pos": 125, "type": "METRIC", "confidence": 0.997713565826416}, {"text": "DepPattern", "start_pos": 129, "end_pos": 139, "type": "DATASET", "confidence": 0.8654815554618835}]}, {"text": "Punctuation marks are ignored in our evaluation.", "labels": [], "entities": [{"text": "Punctuation marks", "start_pos": 0, "end_pos": 17, "type": "METRIC", "confidence": 0.9321359097957611}]}, {"text": "show the results obtained with DepPattern and MaltParser, respectively, when applied on the different testing sets.", "labels": [], "entities": [{"text": "DepPattern", "start_pos": 31, "end_pos": 41, "type": "DATASET", "confidence": 0.8366262316703796}]}, {"text": "The results obtained by MaltParser represent in fact the UAS  of the system, since precision and recall are the same.", "labels": [], "entities": [{"text": "MaltParser", "start_pos": 24, "end_pos": 34, "type": "DATASET", "confidence": 0.9120784401893616}, {"text": "UAS", "start_pos": 57, "end_pos": 60, "type": "METRIC", "confidence": 0.9872180819511414}, {"text": "precision", "start_pos": 83, "end_pos": 92, "type": "METRIC", "confidence": 0.9994332194328308}, {"text": "recall", "start_pos": 97, "end_pos": 103, "type": "METRIC", "confidence": 0.9991311430931091}]}, {"text": "MaltParser outperforms DepPattern on both bosque-test and ancora-test.", "labels": [], "entities": []}, {"text": "The scores we obtained using MaltParser follow the same tendency (even if they are not identical) of those obtained at the CoNLL 2006 shared task, where the system achieved 91% accuracy on Portuguese and 85 on Spanish (for unlabeled attachment scores).", "labels": [], "entities": [{"text": "CoNLL 2006 shared task", "start_pos": 123, "end_pos": 145, "type": "DATASET", "confidence": 0.8823000937700272}, {"text": "accuracy", "start_pos": 177, "end_pos": 185, "type": "METRIC", "confidence": 0.9989481568336487}]}, {"text": "In our experiments, MaltParser obtained 88.2% and 85, respectively.", "labels": [], "entities": []}, {"text": "The differences between the Portuguese scores at CoNLL and those obtained in our experiment could derive from small changes in the optimization procedure, and from the size of the training corpus.", "labels": [], "entities": [{"text": "CoNLL", "start_pos": 49, "end_pos": 54, "type": "DATASET", "confidence": 0.8317192196846008}]}, {"text": "Notice that the performance of MaltParser is quite different across our three data sets: 88.2% (bosque) 85 (ancora), and.", "labels": [], "entities": []}, {"text": "By contrast, DepPattern achieves similar results in all the tests.", "labels": [], "entities": []}, {"text": "In the content-open test, we observe that whereas MaltParser gets down from 88.2 accuracy to 81.3, DepPattern keeps a similar score in the three datasets.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 81, "end_pos": 89, "type": "METRIC", "confidence": 0.9563257098197937}]}, {"text": "It seems that the change of domain affects the performance of the data-driven system.", "labels": [], "entities": []}, {"text": "By contrast, the grammar-based parser keeps a similar performance across domains and genres.", "labels": [], "entities": []}, {"text": "It seems to be also most stable across different languages: it achieves similar results in Spanish and Portuguese because, on the one hand, these languages are very close and, on the other, DepPattern only use those grammar rules shared by the two languages.", "labels": [], "entities": []}, {"text": "However, it is not easy to explain why MaltParser behaves in a very different way on two languages which are very similar in terms of grammar.", "labels": [], "entities": []}, {"text": "Finally, we also verified whether the two systems are complementary.", "labels": [], "entities": []}, {"text": "This was made by measuring the statistical correlation between the results obtained by the two types of parsers.", "labels": [], "entities": []}, {"text": "For this purpose, we analysed the Pearson correlation between the parses resulting from both DepPatter and MaltParser, in order to verify if they tend to make the same correct decisions.", "labels": [], "entities": [{"text": "Pearson correlation", "start_pos": 34, "end_pos": 53, "type": "METRIC", "confidence": 0.9601183831691742}, {"text": "DepPatter", "start_pos": 93, "end_pos": 102, "type": "DATASET", "confidence": 0.9146074056625366}]}, {"text": "The Pearson coefficient obtained was low, namely 0.14, with only 69% of shared correct decisions.", "labels": [], "entities": [{"text": "Pearson coefficient", "start_pos": 4, "end_pos": 23, "type": "METRIC", "confidence": 0.9839761555194855}]}, {"text": "This means that the two systems are complementary since many of the correct dependencies they guess are not the same.", "labels": [], "entities": []}, {"text": "In sum, they are good in different ways.", "labels": [], "entities": []}, {"text": "This insight essentially encourages to the pursuit of hybrid approaches and parser combinations, since both strategies seem to be complementary and should work together to produce more efficient results.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Evaluation of DepPattern (unlabeled de- pendencies)", "labels": [], "entities": []}, {"text": " Table 2: Evaluation of MaltParser (unlabeled de- pendencies)", "labels": [], "entities": [{"text": "MaltParser", "start_pos": 24, "end_pos": 34, "type": "DATASET", "confidence": 0.9082865118980408}]}]}