{"title": [{"text": "USAAR-SAPE: An English-Spanish Statistical Automatic Post-Editing System", "labels": [], "entities": [{"text": "USAAR-SAPE", "start_pos": 0, "end_pos": 10, "type": "DATASET", "confidence": 0.9707109332084656}]}], "abstractContent": [{"text": "We describe the USAAR-SAPE English-Spanish Automatic Post-Editing (APE) system submitted to the APE Task organized in the Workshop on Statistical Machine Translation (WMT) in 2015.", "labels": [], "entities": [{"text": "USAAR-SAPE English-Spanish Automatic Post-Editing (APE)", "start_pos": 16, "end_pos": 71, "type": "TASK", "confidence": 0.5890017407281058}, {"text": "APE Task organized in the Workshop on Statistical Machine Translation (WMT) in 2015", "start_pos": 96, "end_pos": 179, "type": "TASK", "confidence": 0.8190695126851399}]}, {"text": "Our system was able to improve upon the baseline MT system output by incorporating Phrase-Based Statistical MT (PBSMT) technique into the monolingual Statistical APE task (SAPE).", "labels": [], "entities": [{"text": "MT", "start_pos": 49, "end_pos": 51, "type": "TASK", "confidence": 0.9848459959030151}]}, {"text": "The reported final submission crucially involves hybrid word alignment.", "labels": [], "entities": [{"text": "hybrid word alignment", "start_pos": 49, "end_pos": 70, "type": "TASK", "confidence": 0.6070235768953959}]}, {"text": "The SAPE system takes raw Spanish Machine Translation (MT) output provided by the shared task organizers and produces post-edited Spanish text.", "labels": [], "entities": [{"text": "Spanish Machine Translation (MT) output", "start_pos": 26, "end_pos": 65, "type": "TASK", "confidence": 0.7836587684495109}]}, {"text": "The parallel data consist of English Text, raw machine translated Spanish output, and their corresponding manually post-edited versions.", "labels": [], "entities": []}, {"text": "The major goal of the task is to reduce the post-editing effort by improving the quality of the MT output in terms of fluency and adequacy.", "labels": [], "entities": [{"text": "MT", "start_pos": 96, "end_pos": 98, "type": "TASK", "confidence": 0.9744060635566711}]}], "introductionContent": [{"text": "In this paper, we present the submission of Saarland University (USAAR) to the WMT2015 APE task.", "labels": [], "entities": [{"text": "Saarland University (USAAR)", "start_pos": 44, "end_pos": 71, "type": "DATASET", "confidence": 0.7082593142986298}, {"text": "WMT2015 APE task", "start_pos": 79, "end_pos": 95, "type": "TASK", "confidence": 0.8038500746091207}]}, {"text": "The system combines a hybrid word alignment system implementation with a monolingual PBSMT for the language pair English-Spanish (EN-ES), translating from English into Spanish.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 29, "end_pos": 43, "type": "TASK", "confidence": 0.708698496222496}]}, {"text": "In order to achieve the desired translation quality, translations provided by MT systems need to be corrected by human translators.", "labels": [], "entities": [{"text": "MT", "start_pos": 78, "end_pos": 80, "type": "TASK", "confidence": 0.9346968531608582}]}, {"text": "Automatic MT post-editing (APE) is the method of improving raw MT output, before performing human post-editing on it.", "labels": [], "entities": [{"text": "MT post-editing (APE)", "start_pos": 10, "end_pos": 31, "type": "TASK", "confidence": 0.9130210041999817}, {"text": "MT output", "start_pos": 63, "end_pos": 72, "type": "TASK", "confidence": 0.9156059920787811}]}, {"text": "The objective is to decreases the amount of errors produced by the MT systems, achieving in the end a productivity increase in the translation process.", "labels": [], "entities": [{"text": "MT", "start_pos": 67, "end_pos": 69, "type": "TASK", "confidence": 0.97356116771698}]}, {"text": "Usually APE tasks focus on fluency errors produced by the MT system.", "labels": [], "entities": [{"text": "APE tasks", "start_pos": 8, "end_pos": 17, "type": "TASK", "confidence": 0.8804534375667572}, {"text": "MT", "start_pos": 58, "end_pos": 60, "type": "TASK", "confidence": 0.9407751560211182}]}, {"text": "The most frequent ones are incorrect lexical choices, incorrect word ordering, the insertion of a word, the deletion of a word.", "labels": [], "entities": [{"text": "word ordering", "start_pos": 64, "end_pos": 77, "type": "TASK", "confidence": 0.672632172703743}]}, {"text": "For the WMT2015 APE task, we adapted our system in order to automatically post-edit lexical choice errors, word insertions and deletions.", "labels": [], "entities": [{"text": "WMT2015 APE task", "start_pos": 8, "end_pos": 24, "type": "TASK", "confidence": 0.6864622235298157}, {"text": "word insertions and deletions", "start_pos": 107, "end_pos": 136, "type": "TASK", "confidence": 0.7765047326683998}]}, {"text": "The method is also able to correct to some extent word ordering.", "labels": [], "entities": [{"text": "word ordering", "start_pos": 50, "end_pos": 63, "type": "TASK", "confidence": 0.7778241336345673}]}, {"text": "The remainder of the paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 gives an overview of the related work, Section 3 describes the various components of our system, in particular the corpus preprocessing module, the hybrid word alignment module and the PBSMT model.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 165, "end_pos": 179, "type": "TASK", "confidence": 0.7018663287162781}]}, {"text": "In Section 4, we outline the complete experimental setup.", "labels": [], "entities": []}, {"text": "Section 5 presents the results of the automatic and human evaluation, followed by conclusion in Section 6.", "labels": [], "entities": []}], "datasetContent": [{"text": "We performed experiments on the development set provided by the organizers of the APE task in the WMT2015.", "labels": [], "entities": [{"text": "APE task in the WMT2015", "start_pos": 82, "end_pos": 105, "type": "DATASET", "confidence": 0.6780988335609436}]}, {"text": "The effectiveness of the present work is demonstrated by using the standard log-linear PBSMT model.", "labels": [], "entities": []}, {"text": "For building our SAPE system, we experimented with various maximum phrase lengths for the translation model and n-gram settings for the language model.", "labels": [], "entities": []}, {"text": "We found that using a maximum phrase length of 7 for the translation model and a 5-gram language model produces the best results in terms of BLEU () scores for our SAPE model.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 141, "end_pos": 145, "type": "METRIC", "confidence": 0.9993022680282593}]}, {"text": "The other experimental settings were concerned with hybrid word alignment training algorithms (described in Section 3) and the phraseextraction ().", "labels": [], "entities": [{"text": "word alignment training", "start_pos": 59, "end_pos": 82, "type": "TASK", "confidence": 0.8057311574618021}]}, {"text": "The reordering model was trained with the hierarchical, monotone, swap, left to right bidirectional (hier-mslrbidirectional) () method and conditioned on both source and target language.", "labels": [], "entities": []}, {"text": "The 5-gram target language model was trained using KenLM.", "labels": [], "entities": [{"text": "KenLM", "start_pos": 51, "end_pos": 56, "type": "METRIC", "confidence": 0.5577716827392578}]}, {"text": "Phrase pairs that occur only once in the training data are assigned an unduly high probability mass (i.e. 1).", "labels": [], "entities": []}, {"text": "To alleviate this shortcoming, we performed smoothing of the phrase table using the GoodTuring smoothing technique ().", "labels": [], "entities": []}, {"text": "System tuning was carried out using Minimum Error Rate Training (MERT) optimised with k-best MIRA (Cherry and Foster, 2012) on a held out development set.", "labels": [], "entities": [{"text": "Minimum Error Rate Training (MERT)", "start_pos": 36, "end_pos": 70, "type": "METRIC", "confidence": 0.8865045053618295}, {"text": "MIRA", "start_pos": 93, "end_pos": 97, "type": "METRIC", "confidence": 0.9152549505233765}]}, {"text": "After the parameters were tuned, decoding was carried out on the held out test set.", "labels": [], "entities": []}, {"text": "The evaluation of our SAPE system was performed on the 1817 Spanish sentences.", "labels": [], "entities": [{"text": "1817 Spanish sentences", "start_pos": 55, "end_pos": 77, "type": "DATASET", "confidence": 0.9085710446039835}]}, {"text": "The baseline consisted of two systems, an MT baseline system and the APE the system of ().", "labels": [], "entities": [{"text": "APE", "start_pos": 69, "end_pos": 72, "type": "METRIC", "confidence": 0.8882208466529846}]}, {"text": "The evaluation was carried out using HTER (TER with human targeted references) score.", "labels": [], "entities": [{"text": "HTER", "start_pos": 37, "end_pos": 41, "type": "METRIC", "confidence": 0.9120746850967407}]}, {"text": "In this year's WMT seven groups made a submission to the APE task.", "labels": [], "entities": [{"text": "WMT", "start_pos": 15, "end_pos": 18, "type": "DATASET", "confidence": 0.6808371543884277}, {"text": "APE task", "start_pos": 57, "end_pos": 65, "type": "TASK", "confidence": 0.764082670211792}]}, {"text": "From the seven systems, our system was ranked on the third place, achieving a HTER score of 23.426 for case sensitive evaluation and 22.710 for the case insensitive evaluation, outperforming the baseline APE system scoring 23.839 for the case sensitive evaluation and 23.130 for the case insensitive evaluation.", "labels": [], "entities": [{"text": "HTER score", "start_pos": 78, "end_pos": 88, "type": "METRIC", "confidence": 0.98542320728302}, {"text": "APE", "start_pos": 204, "end_pos": 207, "type": "METRIC", "confidence": 0.8440780639648438}]}], "tableCaptions": [{"text": " Table 1 presents the statistics of the training, de- velopment and test sets released for the English- Spanish SAPE Task organized in WMT'2015.  These data sets did not require any preprocessing  in terms of encoding or alignment.", "labels": [], "entities": [{"text": "English- Spanish SAPE Task organized in WMT'2015", "start_pos": 95, "end_pos": 143, "type": "DATASET", "confidence": 0.6655782051384449}]}]}