{"title": [], "abstractContent": [{"text": "Different names maybe popular in different countries.", "labels": [], "entities": []}, {"text": "Hence, person names may give a clue to a per-son's country of origin.", "labels": [], "entities": []}, {"text": "Along with other features, mapping names to countries can be helpful in a variety of applications such as country tagging twitter users.", "labels": [], "entities": [{"text": "country tagging twitter", "start_pos": 106, "end_pos": 129, "type": "TASK", "confidence": 0.7729307015736898}]}, {"text": "This paper describes the collection of Ara-bic Twitter user names that are either written in Ara-bic or transliterated into Latin characters along with their stated geographical locations.", "labels": [], "entities": []}, {"text": "To classify previously unseen names, we trained naive Bayes and Support Vector Machine (SVM) multi-class classi-fiers using primarily bag-of-words features.", "labels": [], "entities": []}, {"text": "We are able to map Arabic user names to specific Arab countries with 79% accuracy and to specific regions (Gulf, Egypt, Levant, Maghreb, and others) with 94% accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 73, "end_pos": 81, "type": "METRIC", "confidence": 0.9987951517105103}, {"text": "accuracy", "start_pos": 158, "end_pos": 166, "type": "METRIC", "confidence": 0.9983696341514587}]}, {"text": "As for transliterated Arabic names, the accuracy per country and per region was 67% and 83% respectively.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 40, "end_pos": 48, "type": "METRIC", "confidence": 0.9996728897094727}]}, {"text": "The approach is generic and language independent, and can be used to collect and classify names to other countries or regions, and considering language-dependent name features (like the compound names, and person titles) yields to better results.", "labels": [], "entities": []}], "introductionContent": [{"text": "Geo-locating tweets and tweeps (Twitter users) has captured significant attention in recent years.", "labels": [], "entities": []}, {"text": "Geographical information is important for many applications such as transliteration, social studies, directed advertisement, dialect identification, and Automatic Speech Recognition (ASR) among others.", "labels": [], "entities": [{"text": "dialect identification", "start_pos": 125, "end_pos": 147, "type": "TASK", "confidence": 0.7807760238647461}, {"text": "Automatic Speech Recognition (ASR)", "start_pos": 153, "end_pos": 187, "type": "TASK", "confidence": 0.780019223690033}]}, {"text": "In social studies, researchers maybe interested in studying the views and opinions of tweeps for specific geographical locations.", "labels": [], "entities": []}, {"text": "Similarly, tweets can offer a tool for linguists to study different linguistic phenomena.", "labels": [], "entities": []}, {"text": "For ASR, training language models using dialectal Arabic tweets that are associated with different regions of the Arab world was shown to reduce recognition error rate for dialectal Egyptian Arabic by 25%).", "labels": [], "entities": [{"text": "ASR", "start_pos": 4, "end_pos": 7, "type": "TASK", "confidence": 0.9921987652778625}, {"text": "recognition error rate", "start_pos": 145, "end_pos": 167, "type": "METRIC", "confidence": 0.6735203961531321}]}, {"text": "Previous work has looked at a variety of features that may geo-locate tweets and tweeps such as the dialect of tweet(s), words appearing in tweets, a tweep's social network, etc.", "labels": [], "entities": []}, {"text": "In this work we examine the predictive power of tweep names in predicting a tweep's location or region of origin.", "labels": [], "entities": []}, {"text": "We define geographic units at two different levels, namely: country level and region level.", "labels": [], "entities": []}, {"text": "The country level geographic units are defined based on political boundaries regardless of the size and proximity of different geographic entities.", "labels": [], "entities": []}, {"text": "Thus, Qatar and Bahrain as well as Lebanon and Syria are considered as different units.", "labels": [], "entities": []}, {"text": "At the region level, we conflate nearby countries into regions.", "labels": [], "entities": []}, {"text": "Conflation was guided by previous work on dialects, where dialects were categorized into five regional language groups, namely: Egyptian (EGY), Maghrebi (MGR), Gulf (Arabian Peninsula) (GLF), Iraqi (IRQ), and Levantine (LEV) ().", "labels": [], "entities": []}, {"text": "Sometimes, the Iraqi dialect is considered to be one of the Gulf dialects (.", "labels": [], "entities": []}, {"text": "In this paper we consider Iraq as apart of the Gulf region.", "labels": [], "entities": []}, {"text": "Thus the goal of this work is to build a classifier that can predict a tweep's country/region of residence/origin.", "labels": [], "entities": []}, {"text": "To build the classifier we obtained tweep names and their self-declared locations from Twitter.", "labels": [], "entities": []}, {"text": "Many tweeps use pseudonyms, such as \"white knight\", and fake or irregular, such as \"in phantasmagoria\" or \"Eastern Province\".", "labels": [], "entities": [{"text": "Eastern Province", "start_pos": 107, "end_pos": 123, "type": "DATASET", "confidence": 0.9328008890151978}]}, {"text": "Hence, identifying fake tweep names maybe necessary, and 1 locations need to be mapped to countries.", "labels": [], "entities": []}, {"text": "We built multiple classifiers using either a naive Bayes or a Support Vector Machine (SVM) classifier using bagof-words features, namely word unigrams.", "labels": [], "entities": []}, {"text": "We also considered improvements that entailed using character n-gram features and word position weighting.", "labels": [], "entities": [{"text": "word position weighting", "start_pos": 82, "end_pos": 105, "type": "TASK", "confidence": 0.6738482614358267}]}, {"text": "For our work, we tried to collect tweets for all 22 Arab countries, but we did not find Arabic tweets from Mauritania, Somalia, Djibouti and Comoros.", "labels": [], "entities": []}, {"text": "The contributions of this paper are: 1.", "labels": [], "entities": []}, {"text": "We show that we can use Twitter as a source for collecting person names for different Arab countries by mapping user location to one of the Arab countries.", "labels": [], "entities": []}, {"text": "2. We show that we can build a classifier of Arabic names at the county level or region level with reasonable accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 110, "end_pos": 118, "type": "METRIC", "confidence": 0.9969402551651001}]}, {"text": "3. we show the characteristics of Arabic names and how they differ among different countries or regions.", "labels": [], "entities": []}, {"text": "The paper is organized as follows: Section 2 surveys previous work on person name classification; Section 3 describes some features of Arabic names including dialectal variation in transliteration; section 4 describes how names are collected from Twitter, cleaned and classified; section 5 shows results of name classification experiments; and Section 6 contains conclusion and future work.", "labels": [], "entities": [{"text": "person name classification", "start_pos": 70, "end_pos": 96, "type": "TASK", "confidence": 0.6972620685895284}, {"text": "name classification", "start_pos": 307, "end_pos": 326, "type": "TASK", "confidence": 0.755346029996872}]}], "datasetContent": [{"text": "Given the 170K Names arb and 182K Names trans that we collected, we randomly split the set into 80/20 training and testing splits.", "labels": [], "entities": [{"text": "182K Names trans", "start_pos": 29, "end_pos": 45, "type": "DATASET", "confidence": 0.8453908165295919}]}, {"text": "We used word unigrams as features.", "labels": [], "entities": []}, {"text": "We also examined giving first and last names different weights and character trigrams as a back-off for unseen words.", "labels": [], "entities": []}, {"text": "Further, we trained two classifiers namely a Naive Bayes classifier and an SVM classifier.", "labels": [], "entities": []}, {"text": "When using a Naive Bayes classifier and a name was not observed during training in general or fora class, we used KenLM language modeling toolkit to compute the smoothing probability of it.", "labels": [], "entities": [{"text": "KenLM language modeling", "start_pos": 114, "end_pos": 137, "type": "TASK", "confidence": 0.564428041378657}]}, {"text": "Our baseline involved tagging all test items with the tag of the majority class, which means that every tweep would assigned to SA at country level and the Gulf at region level.", "labels": [], "entities": []}, {"text": "shows the baseline re- show the results for Names arb per country and per region respectively using word unigrams only.", "labels": [], "entities": []}, {"text": "Similarly, show the results for Names trans per country and per region respectively using word unigrams only.", "labels": [], "entities": []}, {"text": "Micro and Macro averages refer to computing metrics per test example or taking the average of per country results respectively.", "labels": [], "entities": []}, {"text": "As can be seen, the naive Bayes classifier performed better than SVM classifier for the vast majority of countries and in overall accuracy and F-measure.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 130, "end_pos": 138, "type": "METRIC", "confidence": 0.9997707009315491}, {"text": "F-measure", "start_pos": 143, "end_pos": 152, "type": "METRIC", "confidence": 0.9947393536567688}]}, {"text": "Mostly the SVM classifier had higher precision with less recall.", "labels": [], "entities": [{"text": "precision", "start_pos": 37, "end_pos": 46, "type": "METRIC", "confidence": 0.9992027878761292}, {"text": "recall", "start_pos": 57, "end_pos": 63, "type": "METRIC", "confidence": 0.99906986951828}]}, {"text": "In further experiments, we exclusively used the naive Bayes classifier.", "labels": [], "entities": []}, {"text": "We tried two modifications of the classifier.", "labels": [], "entities": []}, {"text": "The first involved giving different weights to different single names in the full name, such that a person's last name would get a higher weight than his/her first name.", "labels": [], "entities": []}, {"text": "The intuition is that different countries may have different common family names that may indicate their place of origin, family, or tribe.", "labels": [], "entities": []}, {"text": "The weight of the word based on its position is determined using the following formula: weight i = 1 no of single names\u2212i+1 Where i ranged between 1 and number of single names in the full name.", "labels": [], "entities": []}, {"text": "Thus the last single name would get a weight of 1 and all previous single names would get a weight of 1/2, 1/3, etc.", "labels": [], "entities": []}, {"text": "(from end to beginning).", "labels": [], "entities": []}, {"text": "The second entailed using a character trigram model as a back-off for out of vocabulary words, which were not seen during training.", "labels": [], "entities": []}, {"text": "We used KenLM to train a trigram character model using all the names in the training set (Heafield, 2011).", "labels": [], "entities": [{"text": "KenLM", "start_pos": 8, "end_pos": 13, "type": "DATASET", "confidence": 0.7997734546661377}]}, {"text": "compare the plain Bayesian classifier with using the classifier with single name weighting and character trigram back-off for Names arb at country and region level respectively.", "labels": [], "entities": []}, {"text": "compare the same for Names trans . As the results show, both methods improved overall accuracy with consistent improvements in precision and improvements in recall most of the time.", "labels": [], "entities": [{"text": "Names trans", "start_pos": 21, "end_pos": 32, "type": "TASK", "confidence": 0.6493431031703949}, {"text": "accuracy", "start_pos": 86, "end_pos": 94, "type": "METRIC", "confidence": 0.9993730187416077}, {"text": "precision", "start_pos": 127, "end_pos": 136, "type": "METRIC", "confidence": 0.9994275569915771}, {"text": "recall", "start_pos": 157, "end_pos": 163, "type": "METRIC", "confidence": 0.9990406632423401}]}, {"text": "Using single name weighting had a greater effect on precision.", "labels": [], "entities": [{"text": "precision", "start_pos": 52, "end_pos": 61, "type": "METRIC", "confidence": 0.9963657855987549}]}], "tableCaptions": [{"text": " Table 5: Names arb Results per country", "labels": [], "entities": []}, {"text": " Table 6: Names arb Results per region", "labels": [], "entities": []}, {"text": " Table 8: Names arb Results per region", "labels": [], "entities": []}, {"text": " Table 9: Names arb Results by country for plain Naive  Bayes, position weighting, and char n-gram back-off", "labels": [], "entities": [{"text": "position weighting", "start_pos": 63, "end_pos": 81, "type": "TASK", "confidence": 0.6601079702377319}]}, {"text": " Table 10: Names arb Results by country for plain Naive  Bayes, position weighting, and char n-gram back-off", "labels": [], "entities": [{"text": "position weighting", "start_pos": 64, "end_pos": 82, "type": "TASK", "confidence": 0.6509728133678436}]}, {"text": " Table 11: Names trans Results by country for plain Naive  Bayes, position weighting, and char n-gram back-off", "labels": [], "entities": [{"text": "position weighting", "start_pos": 66, "end_pos": 84, "type": "TASK", "confidence": 0.6508305966854095}]}]}