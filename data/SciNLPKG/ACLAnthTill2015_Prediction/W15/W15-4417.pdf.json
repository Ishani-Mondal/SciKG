{"title": [{"text": "Improving Chinese Grammatical Error Correction using Corpus Augmentation and Hierarchical Phrase-based Statistical Machine Translation", "labels": [], "entities": [{"text": "Improving Chinese Grammatical Error Correction", "start_pos": 0, "end_pos": 46, "type": "TASK", "confidence": 0.9232401251792908}, {"text": "Corpus Augmentation", "start_pos": 53, "end_pos": 72, "type": "TASK", "confidence": 0.7219075113534927}, {"text": "Statistical Machine Translation", "start_pos": 103, "end_pos": 134, "type": "TASK", "confidence": 0.6184688409169515}]}], "abstractContent": [{"text": "In this study, we describe our system submitted to the 2nd Workshop on Natural Language Processing Techniques for Educational Applications (NLP-TEA-2) shared task on Chinese grammatical error diagnosis (CGED).", "labels": [], "entities": [{"text": "Chinese grammatical error diagnosis (CGED)", "start_pos": 166, "end_pos": 208, "type": "TASK", "confidence": 0.7828523346355983}]}, {"text": "We use a statistical machine translation method already applied to several similar tasks (Brockett et al., 2006; Chiu et al., 2013; Zhao et al., 2014).", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 9, "end_pos": 40, "type": "TASK", "confidence": 0.6125224232673645}]}, {"text": "In this research, we examine corpus augmentation and explore alternative translation models including syntax-based and hierarchical phrase-based models.", "labels": [], "entities": []}, {"text": "Finally, we show variations using different combinations of these factors .", "labels": [], "entities": []}], "introductionContent": [{"text": "The concept of \"translating\" an error sentence into a correct one was first researched by.", "labels": [], "entities": []}, {"text": "They proposed a statistical machine translation (SMT) system with noisy channel model to correct automatically erroneous sentences for learners of English as a Second Language (ESL).", "labels": [], "entities": [{"text": "statistical machine translation (SMT)", "start_pos": 16, "end_pos": 53, "type": "TASK", "confidence": 0.7742156187693278}]}, {"text": "It seems that a statistical machine translation toolkit has become increasingly popular for grammatical error correction.", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 16, "end_pos": 47, "type": "TASK", "confidence": 0.6310986578464508}, {"text": "grammatical error correction", "start_pos": 92, "end_pos": 120, "type": "TASK", "confidence": 0.7575075229008993}]}, {"text": "In the CoNLL-2014 shared task on English grammatical error correction (), four teams of 13 participants each used a phrase-based SMT system.", "labels": [], "entities": [{"text": "CoNLL-2014 shared task on English grammatical error correction", "start_pos": 7, "end_pos": 69, "type": "TASK", "confidence": 0.6581100262701511}]}, {"text": "Grammatical error correction using a phrasebased SMT system can be improved by tuning using evaluation metrics such as F 0.5 () or even a combination of different tuning algorithms).", "labels": [], "entities": [{"text": "Grammatical error correction", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.8131143848101298}, {"text": "SMT", "start_pos": 49, "end_pos": 52, "type": "TASK", "confidence": 0.7282643914222717}, {"text": "F 0.5", "start_pos": 119, "end_pos": 124, "type": "METRIC", "confidence": 0.953474760055542}]}, {"text": "In addition, SMT can be merged with other methods.", "labels": [], "entities": [{"text": "SMT", "start_pos": 13, "end_pos": 16, "type": "TASK", "confidence": 0.991621732711792}]}, {"text": "For example, the language modelbased and rule-based methods can be integrated into a single sophisticated but effective system).", "labels": [], "entities": []}, {"text": "For Chinese, SMT has also been used to correct spelling errors (.", "labels": [], "entities": [{"text": "SMT", "start_pos": 13, "end_pos": 16, "type": "TASK", "confidence": 0.9841457009315491}]}, {"text": "Furthermore, as is shown in NLP-TEA-1, an SMT system can be applied to Chinese grammatical error correction if we can employ a large-scale learner corpus (.", "labels": [], "entities": [{"text": "SMT", "start_pos": 42, "end_pos": 45, "type": "TASK", "confidence": 0.9908332228660583}, {"text": "Chinese grammatical error correction", "start_pos": 71, "end_pos": 107, "type": "TASK", "confidence": 0.6793290823698044}]}, {"text": "In this study, we extend our previous system () to the NLP-TEA-2 shared task on Chinese grammatical error diagnosis, which is based on SMT.", "labels": [], "entities": [{"text": "Chinese grammatical error diagnosis", "start_pos": 80, "end_pos": 115, "type": "TASK", "confidence": 0.6341289505362511}, {"text": "SMT", "start_pos": 135, "end_pos": 138, "type": "TASK", "confidence": 0.9440492987632751}]}, {"text": "The main contribution of this study is as follows: \uf0b7 We investigate the hierarchical phrasebased model () and determine that it yields higher recall and thus F score than does the phrase-based model, but is less accurate.", "labels": [], "entities": [{"text": "recall", "start_pos": 142, "end_pos": 148, "type": "METRIC", "confidence": 0.9987900853157043}, {"text": "F score", "start_pos": 158, "end_pos": 165, "type": "METRIC", "confidence": 0.9916149973869324}]}, {"text": "\uf0b7 We increase our Chinese learner corpus by web scraping () and show that the greater the size of the learner corpus, the better the performance.", "labels": [], "entities": [{"text": "Chinese learner corpus", "start_pos": 18, "end_pos": 40, "type": "DATASET", "confidence": 0.7623103062311808}]}, {"text": "\uf0b7 We perform minimum error-rate training) using several evaluation metrics and demonstrate that tuning improves the final F score.", "labels": [], "entities": [{"text": "F score", "start_pos": 122, "end_pos": 129, "type": "METRIC", "confidence": 0.9782954454421997}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Three RUNs submitted by TMU  (Tokyo Metropolitan University) team.", "labels": [], "entities": [{"text": "RUNs", "start_pos": 16, "end_pos": 20, "type": "TASK", "confidence": 0.5538055300712585}, {"text": "TMU  (Tokyo Metropolitan University) team", "start_pos": 34, "end_pos": 75, "type": "DATASET", "confidence": 0.8612587111336845}]}, {"text": " Table 2: Final test result of TMU RUNs at position  level.", "labels": [], "entities": [{"text": "TMU RUNs", "start_pos": 31, "end_pos": 39, "type": "TASK", "confidence": 0.4181652069091797}]}, {"text": " Table 3: F1 score of SMT-based grammatical error  correction system on NLP-TEA-1 dataset, with and  without tuning.", "labels": [], "entities": [{"text": "F1 score", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9752839207649231}, {"text": "SMT-based grammatical error  correction", "start_pos": 22, "end_pos": 61, "type": "TASK", "confidence": 0.8900675028562546}, {"text": "NLP-TEA-1 dataset", "start_pos": 72, "end_pos": 89, "type": "DATASET", "confidence": 0.9616944789886475}]}, {"text": " Table 4: Tuning result suitable to an evalua- tion score but unacceptable for its low precision  and recall.", "labels": [], "entities": [{"text": "Tuning", "start_pos": 10, "end_pos": 16, "type": "TASK", "confidence": 0.9604116678237915}, {"text": "precision", "start_pos": 87, "end_pos": 96, "type": "METRIC", "confidence": 0.9993302822113037}, {"text": "recall", "start_pos": 102, "end_pos": 108, "type": "METRIC", "confidence": 0.9995397329330444}]}]}