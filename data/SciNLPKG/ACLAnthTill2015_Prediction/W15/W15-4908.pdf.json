{"title": [{"text": "Document-Level Machine Translation with Word Vector Models", "labels": [], "entities": [{"text": "Document-Level Machine Translation", "start_pos": 0, "end_pos": 34, "type": "TASK", "confidence": 0.642259438832601}]}], "abstractContent": [{"text": "In this paper we apply distributional semantic information to document-level machine translation.", "labels": [], "entities": [{"text": "document-level machine translation", "start_pos": 62, "end_pos": 96, "type": "TASK", "confidence": 0.6279950042565664}]}, {"text": "We train monolingual and bilingual word vector models on large corpora and we evaluate them first in a cross-lingual lexical substitution task and then on the final translation task.", "labels": [], "entities": [{"text": "cross-lingual lexical substitution task", "start_pos": 103, "end_pos": 142, "type": "TASK", "confidence": 0.7075151205062866}]}, {"text": "For translation , we incorporate the semantic information in a statistical document-level de-coder (Docent), by enforcing translation choices that are semantically similar to the context.", "labels": [], "entities": [{"text": "translation", "start_pos": 4, "end_pos": 15, "type": "TASK", "confidence": 0.9841495156288147}]}, {"text": "As expected, the bilingual word vector models are more appropriate for the purpose of translation.", "labels": [], "entities": [{"text": "translation", "start_pos": 86, "end_pos": 97, "type": "TASK", "confidence": 0.964218258857727}]}, {"text": "The final document-level translator incorporating the semantic model outperforms the basic Docent (without semantics) and also performs slightly over a standard sentence-level SMT system in terms of ULC (the average of a set of standard automatic evaluation metrics for MT).", "labels": [], "entities": [{"text": "SMT", "start_pos": 176, "end_pos": 179, "type": "TASK", "confidence": 0.8759148716926575}, {"text": "ULC", "start_pos": 199, "end_pos": 202, "type": "METRIC", "confidence": 0.9911626577377319}, {"text": "MT", "start_pos": 270, "end_pos": 272, "type": "TASK", "confidence": 0.9822966456413269}]}, {"text": "Finally, we also present some manual analysis of the translations of some concrete documents.", "labels": [], "entities": []}], "introductionContent": [{"text": "Document-level information is usually lost during the translation process when using Statistical Machine Translation (SMT) sentence-based systems).", "labels": [], "entities": [{"text": "Statistical Machine Translation (SMT) sentence-based", "start_pos": 85, "end_pos": 137, "type": "TASK", "confidence": 0.7837933940546853}]}, {"text": "Cross-sentence dependencies are totally ignored, as they translate sentence by sentence without taking into account any document context when choosing the best translation.", "labels": [], "entities": []}, {"text": "Some simple phenomena like c \ufffd 2015 The authors.", "labels": [], "entities": []}, {"text": "This article is licensed under a Creative Commons 3.0 licence, no derivative works, attribution, CC-BY-ND.", "labels": [], "entities": []}, {"text": "coreferent pronouns outside a sentence cannot be properly translated in this way, which is already important because the correct translation of pronouns in a document confers a high level of coherence to the final translation.", "labels": [], "entities": []}, {"text": "Also, discourse connectives are valuable because they mark the flow of the discourse in a text.", "labels": [], "entities": []}, {"text": "It is desirable to transfer them to the output translation in order to maintain the characteristics of the discourse.", "labels": [], "entities": []}, {"text": "The evolution of the topic through a text is also an important feature to preserve.", "labels": [], "entities": []}, {"text": "All these aspects can be used to improve the translation quality by trying to assure coherence throughout a document.", "labels": [], "entities": []}, {"text": "Several recent works goon that direction.", "labels": [], "entities": []}, {"text": "Some of them present postprocessing approaches making changes into a first translation according to document-level information).", "labels": [], "entities": []}, {"text": "Others introduce the information within the decoder, by, for instance, implementing a topicbased cache approach.", "labels": [], "entities": []}, {"text": "The decoding methodology itself can be changed.", "labels": [], "entities": []}, {"text": "This is the case of a document-oriented decoder,, which implements a search in the space of translations of a whole document.", "labels": [], "entities": []}, {"text": "This framework allows us to consider features that apply at document level.", "labels": [], "entities": []}, {"text": "One of the main goals of this paper is to take advantage of this capability to include semantic information at decoding time.", "labels": [], "entities": []}, {"text": "We present here the usage of a semantic representation based on word embeddings as a language model within a document-oriented decoder.", "labels": [], "entities": []}, {"text": "To do this, we trained a word vector model (WVM) using neural networks.", "labels": [], "entities": []}, {"text": "As a first approach, a monolingual model is used in analogy with the standard monolingual language models based on n-grams of words instead of vectors.", "labels": [], "entities": []}, {"text": "However, to better approach translation, bilingual models are built.", "labels": [], "entities": [{"text": "translation", "start_pos": 28, "end_pos": 39, "type": "TASK", "confidence": 0.9715380072593689}]}, {"text": "These models are avaluated in isolation outside the decoder by means of a cross-lingual evaluation task that resembles a translation environment.", "labels": [], "entities": []}, {"text": "Finally, we use these models in a translation task and we observe how the semantic information enclosed in them help to improve translation quality.", "labels": [], "entities": [{"text": "translation task", "start_pos": 34, "end_pos": 50, "type": "TASK", "confidence": 0.9253341257572174}]}, {"text": "The paper is organized as follows.", "labels": [], "entities": []}, {"text": "A brief revision of the related work is done in Section 2.", "labels": [], "entities": []}, {"text": "In Section 3, we describe our approach of using a bilingual word vector model as a language model.", "labels": [], "entities": []}, {"text": "The model is compared to monolingual models and evaluated.", "labels": [], "entities": []}, {"text": "We show and discuss the results of our experiments on the full translation task in Section 5.", "labels": [], "entities": [{"text": "full translation task", "start_pos": 58, "end_pos": 79, "type": "TASK", "confidence": 0.6770877242088318}]}, {"text": "Finally, we draw the conclusions and define several lines of future work in Section 6.", "labels": [], "entities": []}], "datasetContent": [{"text": "Our SMT baseline system is based on Moses.", "labels": [], "entities": [{"text": "SMT", "start_pos": 4, "end_pos": 7, "type": "TASK", "confidence": 0.980144739151001}]}, {"text": "The translation system has been trained with the Europarl corpus in its version 7 for the SpanishEnglish language pair.", "labels": [], "entities": [{"text": "Europarl corpus", "start_pos": 49, "end_pos": 64, "type": "DATASET", "confidence": 0.9923809766769409}, {"text": "SpanishEnglish language pair", "start_pos": 90, "end_pos": 118, "type": "DATASET", "confidence": 0.8708095550537109}]}, {"text": "We used the GIZA++ software to do the word alignments.", "labels": [], "entities": [{"text": "word alignments", "start_pos": 38, "end_pos": 53, "type": "TASK", "confidence": 0.7622700035572052}]}, {"text": "The language model is an interpolation of several 5-gram language models obtained using SRILM) with interpolated Kneser-Ney discounting on the target side of the Europarl corpus v7; United Nations;; AFP, APW and Xinhua corpora as given by The optimization of the weights is done with MERT against the BLEU measure on the NewsCommentary corpus of 2009.", "labels": [], "entities": [{"text": "Europarl corpus v7", "start_pos": 162, "end_pos": 180, "type": "DATASET", "confidence": 0.980782131354014}, {"text": "United Nations", "start_pos": 182, "end_pos": 196, "type": "DATASET", "confidence": 0.8541948199272156}, {"text": "AFP", "start_pos": 199, "end_pos": 202, "type": "DATASET", "confidence": 0.9543870687484741}, {"text": "APW", "start_pos": 204, "end_pos": 207, "type": "DATASET", "confidence": 0.7491355538368225}, {"text": "MERT", "start_pos": 284, "end_pos": 288, "type": "METRIC", "confidence": 0.9968916773796082}, {"text": "BLEU", "start_pos": 301, "end_pos": 305, "type": "METRIC", "confidence": 0.9984265565872192}, {"text": "NewsCommentary corpus of 2009", "start_pos": 321, "end_pos": 350, "type": "DATASET", "confidence": 0.9718578904867172}]}, {"text": "As in the previous section, our experiments are carried out over the NewsCommentary-2011 test set.", "labels": [], "entities": [{"text": "NewsCommentary-2011 test set", "start_pos": 69, "end_pos": 97, "type": "DATASET", "confidence": 0.9922600189844767}]}, {"text": "We chose the newswire documents as test set because typically they are documents with high consistency and coherence.", "labels": [], "entities": [{"text": "consistency", "start_pos": 91, "end_pos": 102, "type": "METRIC", "confidence": 0.9749094247817993}]}, {"text": "Regarding the document-level decoder, we use Docent.", "labels": [], "entities": []}, {"text": "The first step in the Docent translation process is the output of our Moses baseline system.", "labels": [], "entities": [{"text": "Docent translation", "start_pos": 22, "end_pos": 40, "type": "TASK", "confidence": 0.9397836923599243}]}, {"text": "We set the initial Docent weights to be the same as the ones obtained with MERT for the Moses baseline.", "labels": [], "entities": [{"text": "MERT", "start_pos": 75, "end_pos": 79, "type": "METRIC", "confidence": 0.9098236560821533}, {"text": "Moses baseline", "start_pos": 88, "end_pos": 102, "type": "DATASET", "confidence": 0.8898861706256866}]}, {"text": "Finally, the word vector models used in the experiments of this section are the ones that we describe and evaluate in Section 3 using the CBOW algorithm.", "labels": [], "entities": []}, {"text": "shows the automatic evaluation obtained with the Asiya toolkit () for several lexical metrics (BLEU, NIST, TER, ME-TEOR and ROUGE), a syntactic metric based on the overlap of PoS elements (SP-Op), and an average of a set of 21 lexical and syntactic metrics (ULC), including all the previous measures and many more.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 95, "end_pos": 99, "type": "METRIC", "confidence": 0.9983541965484619}, {"text": "TER", "start_pos": 107, "end_pos": 110, "type": "METRIC", "confidence": 0.9895239472389221}, {"text": "ME-TEOR", "start_pos": 112, "end_pos": 119, "type": "METRIC", "confidence": 0.905698835849762}, {"text": "ROUGE", "start_pos": 124, "end_pos": 129, "type": "METRIC", "confidence": 0.9883254766464233}]}, {"text": "The first row shows the results for the Moses baseline system.", "labels": [], "entities": [{"text": "Moses baseline system", "start_pos": 40, "end_pos": 61, "type": "DATASET", "confidence": 0.9183850089708964}]}, {"text": "The second row shows the evaluation of the Docent baseline system working with the baseline Moses output as first step.", "labels": [], "entities": []}, {"text": "This Docent system uses only the default features that are equivalent to the ones in the Moses system but without lexical reordering.", "labels": [], "entities": []}, {"text": "The last two rows show the evaluation of our extensions for the Docent decoder using both, monolingual vector models as semantic space language models (Docent + monoSSM) and the bilingual ones (Docent + biSSM).", "labels": [], "entities": []}, {"text": "The results show only slight differences among the systems.", "labels": [], "entities": []}, {"text": "However, these differences reflect the impact of our word embeddings in the translation process and are consistent across metrics.", "labels": [], "entities": []}, {"text": "The differences are statistically signifi-   cant at the 90% confidence level, but not at higher level, between Moses and all Docent systems and, also, between the Docent baseline and both extended Docent systems.", "labels": [], "entities": [{"text": "Docent baseline", "start_pos": 164, "end_pos": 179, "type": "DATASET", "confidence": 0.8305643200874329}]}, {"text": "We observed that by using boostrap-resampling over BLEU and NIST metrics as described in).", "labels": [], "entities": [{"text": "BLEU", "start_pos": 51, "end_pos": 55, "type": "METRIC", "confidence": 0.9950556755065918}, {"text": "NIST", "start_pos": 60, "end_pos": 64, "type": "DATASET", "confidence": 0.8218415379524231}]}, {"text": "We observe that Docent systems have a positive trend in their performance as long as we introduce models with more information (from only monolingual to bilingual).", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Figures on the corpora used for training, development and test.", "labels": [], "entities": []}, {"text": " Table 2: Evaluation of the word2vec vector mod- els. Top 1 and Top 5 accuracies of the monolingual  (mono rows) in Spanish and the bilingual (bi rows)  English-Spanish models trained using CBOW or  Skipgram.", "labels": [], "entities": []}, {"text": " Table 3: Automatic evaluation of the systems. See text for the system and metrics definition.", "labels": [], "entities": []}, {"text": " Table 4: Evaluation of the different systems using BLEU metric on some individual newswire documents  extracted from the NewsCommentary-2011 test set.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 52, "end_pos": 56, "type": "METRIC", "confidence": 0.9983174800872803}, {"text": "NewsCommentary-2011 test set", "start_pos": 122, "end_pos": 150, "type": "DATASET", "confidence": 0.9771381815274557}]}]}