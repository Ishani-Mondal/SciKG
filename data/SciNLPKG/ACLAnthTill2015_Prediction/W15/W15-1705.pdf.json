{"title": [{"text": "A Deep Learning and Knowledge Transfer Based Architecture for Social Media User Characteristic Determination", "labels": [], "entities": [{"text": "Social Media User Characteristic Determination", "start_pos": 62, "end_pos": 108, "type": "TASK", "confidence": 0.6465983033180237}]}], "abstractContent": [{"text": "Determining explicit user characteristics based on interactions on Social Media is a crucial task in developing recommendation and social polling solutions.", "labels": [], "entities": []}, {"text": "For this purpose, rule based and N-gram based techniques have been proposed to develop user profiles, but they are only fit for detecting user attributes that can be classified by a relatively simple logic or rely on the presence of a large amount of training data.", "labels": [], "entities": []}, {"text": "In this paper, we propose a general purpose, end-to-end architecture for text analytics, and demonstrate its effectiveness for analytics based on tweets with a relatively small training set.", "labels": [], "entities": [{"text": "text analytics", "start_pos": 73, "end_pos": 87, "type": "TASK", "confidence": 0.776760995388031}]}, {"text": "By performing unsupervised feature learning and deep learning over labeled and unlabeled tweets, we are able to learn in a more generalizable way than N-gram techniques.", "labels": [], "entities": []}, {"text": "Our proposed hidden layer sharing approach makes it possible to efficiently transfer knowledge between related NLP tasks.", "labels": [], "entities": []}, {"text": "This approach is extensible, and can learn even more from metadata available about Social Media users.", "labels": [], "entities": []}, {"text": "For the task of user age prediction over a relatively small corpus, we demonstrate 38.3% error reduction over single task baselines, a total of 44.7% error reduction with the incorporation of two related tasks, and achieve 90.1% accuracy when useful metadata is present.", "labels": [], "entities": [{"text": "user age prediction", "start_pos": 16, "end_pos": 35, "type": "TASK", "confidence": 0.6235796908537546}, {"text": "error reduction", "start_pos": 89, "end_pos": 104, "type": "METRIC", "confidence": 0.9748790264129639}, {"text": "error reduction", "start_pos": 150, "end_pos": 165, "type": "METRIC", "confidence": 0.9540378451347351}, {"text": "accuracy", "start_pos": 229, "end_pos": 237, "type": "METRIC", "confidence": 0.9993688464164734}]}], "introductionContent": [{"text": "Two major Social Media Analytics use cases that are driving business value for businesses today are social recommendation systems and social polling applications.", "labels": [], "entities": []}, {"text": "Social recommendation systems analyze attributes of Social Media users and historical trends to recommend personalized products and advertisements to users.", "labels": [], "entities": []}, {"text": "The accuracy and robustness of these systems has a direct impact on user satisfaction and ROI, making improvement of these systems a very worthwhile area of study.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.9989917874336243}, {"text": "ROI", "start_pos": 90, "end_pos": 93, "type": "METRIC", "confidence": 0.9590029716491699}]}, {"text": "Social polling refers to effectively carrying out massive surveys over Social Media.", "labels": [], "entities": [{"text": "Social polling", "start_pos": 0, "end_pos": 14, "type": "TASK", "confidence": 0.6967771202325821}]}, {"text": "Organizations find applications with these capabilities useful for brand management, campaign management, and understanding key social trends.", "labels": [], "entities": [{"text": "brand management", "start_pos": 67, "end_pos": 83, "type": "TASK", "confidence": 0.8604551255702972}, {"text": "campaign management", "start_pos": 85, "end_pos": 104, "type": "TASK", "confidence": 0.7734745740890503}]}, {"text": "State of the art social polling systems include a capability of measuring trending topics and sentiment.", "labels": [], "entities": []}, {"text": "These systems also include a capability to analyze the user characteristic level dependencies of these trends.", "labels": [], "entities": []}, {"text": "For this use case, informative characteristics for businesses to analyze may include a user's age range, gender, ethnicity, income range, location, hobbies, political leanings, and brand affinities.", "labels": [], "entities": []}, {"text": "Additionally, both high precision and high recall for all features is paramount to the success of these systems.", "labels": [], "entities": [{"text": "precision", "start_pos": 24, "end_pos": 33, "type": "METRIC", "confidence": 0.9994211196899414}, {"text": "recall", "start_pos": 43, "end_pos": 49, "type": "METRIC", "confidence": 0.9993908405303955}]}, {"text": "Low precision or low recall for user attributes skew trends seen over aggregate data, and defeat the purpose of using these solutions to discover statistically founded business insights.", "labels": [], "entities": [{"text": "precision", "start_pos": 4, "end_pos": 13, "type": "METRIC", "confidence": 0.9984102249145508}, {"text": "recall", "start_pos": 21, "end_pos": 27, "type": "METRIC", "confidence": 0.998246431350708}]}, {"text": "Social Media organizations, generally with strong inherent privacy restrictions, like Facebook have access to many user level characteristics that have been directly inputted to the website.", "labels": [], "entities": []}, {"text": "However, there is great interest in analyzing these same kinds of qualities on more public platforms like Twitter and Blogs, where comments are more rea-dily accessible to organizations interested in Social Media analytics.", "labels": [], "entities": [{"text": "Blogs", "start_pos": 118, "end_pos": 123, "type": "DATASET", "confidence": 0.9253862500190735}]}, {"text": "In this situation, text analytics techniques are commonly used to infer qualities about these users that are not explicitly provided to organizations analyzing this content.", "labels": [], "entities": []}, {"text": "The difficulty of extracting a characteristic about a user based on tweets alone varies greatly by the type of characteristic.", "labels": [], "entities": []}, {"text": "NLP rule based approaches () have been commonly used as a means to perform microsegment analysis of Social Media users.", "labels": [], "entities": [{"text": "microsegment analysis of Social Media users", "start_pos": 75, "end_pos": 118, "type": "TASK", "confidence": 0.8102325697739919}]}, {"text": "These techniques have been very effective at creating extractors for user attributes like \"fan of\" relationships, and gender determination with the presence of very little training data.", "labels": [], "entities": [{"text": "gender determination", "start_pos": 118, "end_pos": 138, "type": "TASK", "confidence": 0.7290149480104446}]}, {"text": "For example, by knowing the key characters, actors, and plot details of a TV show, the logic is intuitive for making an individual rule based extractor that monitors expressed interest by a Social Media user in that show.", "labels": [], "entities": []}, {"text": "Moreover, a gender prediction system can be made pretty reliable simply by extracting profile first names, and matching to large lists of female and male names.", "labels": [], "entities": [{"text": "gender prediction", "start_pos": 12, "end_pos": 29, "type": "TASK", "confidence": 0.818636029958725}]}, {"text": "However, rule based techniques are not good solutions for analyzing more subtle relationships in social posts like those needed for predicting a user's age range, income range, or political leanings.", "labels": [], "entities": []}, {"text": "Additionally, as social trends change and users age, it is very desirable for classifiers focused on these tasks to be adaptive and have the ability to efficiently relearn from scratch.", "labels": [], "entities": []}, {"text": "As such, Machine Learning techniques make sense as a means for creating classifiers of more complex user characteristics.", "labels": [], "entities": []}, {"text": "N-gram based techniques have commonly been applied to social media analytics problems (,).", "labels": [], "entities": [{"text": "social media analytics", "start_pos": 54, "end_pos": 76, "type": "TASK", "confidence": 0.6241114636262258}]}, {"text": "However, we have found that these techniques are not effective without a substantial amount of supervised training data or an extremely reliable semisupervised method of creating a stand-in corpus.", "labels": [], "entities": []}, {"text": "In this paper, we propose an end-to-end architecture to address the key problems exhibited with common NLP techniques in analyzing subtly expressed social media user characteristics.", "labels": [], "entities": []}, {"text": "We will demonstrate our architecture's effectiveness at predicting user age based on a modest 1266 user training set compiled by a team of four researchers in a few hours of work for each person manually annotating data.", "labels": [], "entities": []}, {"text": "Our end-to-end method improves on N-gram machine learning techniques by: 1.", "labels": [], "entities": []}, {"text": "Building unsupervised text representations that naturally pickup semantic and syntactic synonymy relationships.", "labels": [], "entities": []}, {"text": "2. Effectively utilizing knowledge acquired from unlabelled data.", "labels": [], "entities": []}, {"text": "3. Taking advantage of powerful deep neural networks to increase prediction accuracy.", "labels": [], "entities": [{"text": "prediction", "start_pos": 65, "end_pos": 75, "type": "TASK", "confidence": 0.9595767259597778}, {"text": "accuracy", "start_pos": 76, "end_pos": 84, "type": "METRIC", "confidence": 0.9102997779846191}]}, {"text": "4. Leveraging a practical framework for transferring knowledge between related user characteristic classifiers for increased performance without increasing the number of free parameters.", "labels": [], "entities": []}, {"text": "5. Establishing a methodology for efficient knowledge transfer from structured metadata related to a user.", "labels": [], "entities": [{"text": "knowledge transfer", "start_pos": 44, "end_pos": 62, "type": "TASK", "confidence": 0.7480282485485077}]}, {"text": "Although our main intent is to show the effectiveness of our architecture for Social Media analytics use cases, there is little about our system that has virtues specific to the social media domain.", "labels": [], "entities": []}, {"text": "Considering the collection of a user's historical tweets as equivalent to a text document, our approach can serve as a general purpose text analytics architecture, especially for use cases with limited training data.", "labels": [], "entities": []}, {"text": "In fact, tweets are generally regarded as more challenging to analyze than other text because of the noisy language and ambiguous content.", "labels": [], "entities": []}, {"text": "The rest of the paper is organized as follows: In Section 2, we describe our data set and go over our experimental methodology.", "labels": [], "entities": []}, {"text": "Section 3 gives an overview of the benefits we see by exploring unsupervised text vector techniques.", "labels": [], "entities": []}, {"text": "In Section 4 we explain the benefit of building deep learning models on top of unsupervised features.", "labels": [], "entities": []}, {"text": "We proceed to explain popular multitask deep learning techniques and their failures for our problem statement in Section 5.", "labels": [], "entities": []}, {"text": "Section 6 is an overview of our hidden layer sharing approach, which we validate in Section 7.", "labels": [], "entities": []}, {"text": "Section 8 explains how our model is extensible for the incorporation of structured metadata.", "labels": [], "entities": []}, {"text": "Finally, Section 9 concludes the paper.", "labels": [], "entities": []}], "datasetContent": [{"text": "Without access to any reliable user provided age information, we had to rely on human judgment to create gold standard annotations for the ages of users on Twitter.", "labels": [], "entities": []}, {"text": "We randomly generated Twitter usernames and had a team of four people manually go to Twitter.com and look at their profile.", "labels": [], "entities": []}, {"text": "The instructions were to look at the user's Twitter pro-file including pictures and their tweets to judge their age range and discard any users for whom the age range was not clear.", "labels": [], "entities": []}, {"text": "The annotators looked through the user's recent tweets to validate their age and also annotated with gender and ethnicity where possible.", "labels": [], "entities": []}, {"text": "Each user in our dataset was analyzed by two different annotators, and only those in which there was agreement for all characteristics were kept.", "labels": [], "entities": []}, {"text": "Ultimately, we compiled a dataset of 1808 annotated Twitter profiles, and retrieved historical tweets from their accounts.", "labels": [], "entities": []}, {"text": "Depending on individual usage patterns, we retrieved a very variable number of tweets.", "labels": [], "entities": []}, {"text": "The minimum was 5, the maximum was 7115, the average was 226.6, the median was 96, and the standard deviation was 326.", "labels": [], "entities": [{"text": "median", "start_pos": 68, "end_pos": 74, "type": "METRIC", "confidence": 0.9615744352340698}, {"text": "standard deviation", "start_pos": 91, "end_pos": 109, "type": "METRIC", "confidence": 0.9253566861152649}]}, {"text": "For our first attempt to create an age prediction system, we attempted to use rules.", "labels": [], "entities": [{"text": "age prediction", "start_pos": 35, "end_pos": 49, "type": "TASK", "confidence": 0.7469204664230347}]}, {"text": "However, we quickly found that even things like usage of currently trending slang were not reliable in predicting age groups.", "labels": [], "entities": []}, {"text": "Moreover, rule based systems did not seem to have the potential to achieve even modest recall.", "labels": [], "entities": [{"text": "recall", "start_pos": 87, "end_pos": 93, "type": "METRIC", "confidence": 0.997563362121582}]}, {"text": "Clearly, age prediction could not be accurately performed deterministically based on tweets, and a technique that used a complex evidence based model would be needed.", "labels": [], "entities": [{"text": "age prediction", "start_pos": 9, "end_pos": 23, "type": "TASK", "confidence": 0.6929740905761719}]}, {"text": "Our second attempt at age prediction then was to use popular machine learning text analytics models based on N-grams.", "labels": [], "entities": [{"text": "age prediction", "start_pos": 22, "end_pos": 36, "type": "TASK", "confidence": 0.7177507281303406}]}, {"text": "We deployed these models using classifiers in the NLTK python package ().", "labels": [], "entities": [{"text": "NLTK python package", "start_pos": 50, "end_pos": 69, "type": "DATASET", "confidence": 0.8868327935536703}]}, {"text": "We tried Na\u00efve Bayes, and Maximum Entropy models for unigrams, bigrams, and trigrams.", "labels": [], "entities": []}, {"text": "We found that it was optimal to require a minimum of 3 training corpus occurrences for an N-gram to be included in our feature space.", "labels": [], "entities": []}, {"text": "depicts the test set results from our Maximum Entropy and Na\u00efve Bayes analysis.", "labels": [], "entities": [{"text": "Na\u00efve Bayes analysis", "start_pos": 58, "end_pos": 78, "type": "DATASET", "confidence": 0.8149527907371521}]}, {"text": "Increasing the our granularity to include bigrams and trigrams resulted in an better training set performance for Maximum Entropy and Na\u00efve Bayes, but those increases did not generalize to the test set.", "labels": [], "entities": []}, {"text": "Maximum Entropy models saw degradation inaccuracy with higher level N-grams.", "labels": [], "entities": []}, {"text": "For Na\u00efve Bayes, there was a slight improvement based on an increase in performance at predicting the oldest age range.", "labels": [], "entities": []}, {"text": "Regardless, these results would not be suitable fora deployed system to make confident judgments.", "labels": [], "entities": []}, {"text": "As we began exploring other techniques which we will describe in more detail in subsequent sections, we use Paragraph Vector as provided by the original developers (.", "labels": [], "entities": []}, {"text": "Additionally, we used the theano-hf python package (Boulanger-) as the beginning building block for our deep learning based approaches.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Total counts of the annotated Twitter users in  our training set and test set by age range.", "labels": [], "entities": []}]}