{"title": [{"text": "Discriminating between Similar Languages Using PPM", "labels": [], "entities": []}], "abstractContent": [{"text": "The paper presents the results of participation of Bobicev team in DSL (Discriminating Similar Languages) shared task 2015.", "labels": [], "entities": [{"text": "DSL (Discriminating Similar Languages) shared task 2015", "start_pos": 67, "end_pos": 122, "type": "DATASET", "confidence": 0.6997189455562167}]}, {"text": "It describes the use of PPM (Prediction by Partial Matching) for language discrimination.", "labels": [], "entities": [{"text": "language discrimination", "start_pos": 65, "end_pos": 88, "type": "TASK", "confidence": 0.7622064054012299}]}, {"text": "The accuracy of the presented system was equal to 94.14% for the first set and 92.22% for the second set.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.9997448325157166}]}, {"text": "The results were scored as the 4th for the first task and 5th for the second task, the best results being 95.54% and 94.01% respectively .", "labels": [], "entities": []}], "introductionContent": [{"text": "The task of language identification is the problem of detection what language a document is written in.", "labels": [], "entities": [{"text": "language identification", "start_pos": 12, "end_pos": 35, "type": "TASK", "confidence": 0.7238649874925613}]}, {"text": "The task seems to be relatively easy and many statistical methods achieve relatively high accuracy (more than 95%) for language detection.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 90, "end_pos": 98, "type": "METRIC", "confidence": 0.9987448453903198}, {"text": "language detection", "start_pos": 119, "end_pos": 137, "type": "TASK", "confidence": 0.8050294816493988}]}, {"text": "However, the good results obtained in the laboratory simplified conditions become worse in the real word circumstances.", "labels": [], "entities": []}, {"text": "Very short documents (such as tweets), fragments of various languages in one text, documents written in similar languages -here are just some difficulties encountered by the language detection systems.", "labels": [], "entities": []}, {"text": "The present paper describes use of PPM (prediction by Partial Matching) statistical method for language discrimination task.", "labels": [], "entities": [{"text": "language discrimination task", "start_pos": 95, "end_pos": 123, "type": "TASK", "confidence": 0.8474147518475851}]}, {"text": "The accuracy of the presented system for the DSL 2015 1 (Discriminating Similar Languages) shared task () was equal to 94.14% for the first set; 92.22% for the second set respectively.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.9996097683906555}, {"text": "DSL 2015 1 (Discriminating Similar Languages) shared task", "start_pos": 45, "end_pos": 102, "type": "DATASET", "confidence": 0.8155067026615143}]}, {"text": "The results were scored as the 4 th for the first task and 5 th for the second task, the best results being 95.54% and 94.01% respectively.", "labels": [], "entities": []}, {"text": "The advantage of the proposed method is its relative simplicity.", "labels": [], "entities": []}, {"text": "The method operates with sequences of characters or even bytes, thus it 1 http://ttg.uni-saarland.de/lt4vardial2015/dsl.html does not need to tokenize or preprocess the analyzed text in anyway.", "labels": [], "entities": []}, {"text": "This also makes it relatively fast in training and text processing.", "labels": [], "entities": [{"text": "text processing", "start_pos": 51, "end_pos": 66, "type": "TASK", "confidence": 0.8342234790325165}]}, {"text": "The paper is organized as follows: the next part gives a short overview of the related work; section 3 contains the system description and explanations how it was used for the task at hand; section 4 includes task (4.2) and data presentation (4.1), experiments and the obtained results (4.3, 4.4).", "labels": [], "entities": []}, {"text": "Finally, a discussion concludes the paper.", "labels": [], "entities": []}], "datasetContent": [{"text": "The experiments were carried out during the DSL 2015 shared task event.", "labels": [], "entities": [{"text": "DSL 2015 shared task event", "start_pos": 44, "end_pos": 70, "type": "DATASET", "confidence": 0.7949747443199158}]}, {"text": "The first set of the experiments was performed on the base of training data released by the organisers in May 2015.", "labels": [], "entities": [{"text": "training data released by the organisers in May 2015", "start_pos": 62, "end_pos": 114, "type": "DATASET", "confidence": 0.7725693583488464}]}, {"text": "The second set consisted of evaluation runs on test data released in June and the results for these experiments were provided by the organizers.", "labels": [], "entities": []}, {"text": "In order to evaluate the PPM method for the task we used 10-fold cross-validation on the all provided training data.", "labels": [], "entities": []}, {"text": "Initially, we excluded the instances marked as xx with the unknown languages to see how the method performed on the known sets.", "labels": [], "entities": []}, {"text": "Thus, for each step we used 1800 instances of each language for training and 200 instances of each language for test.", "labels": [], "entities": []}, {"text": "We used character-based PPM5 in the first set of the experiments.", "labels": [], "entities": []}, {"text": "The first experiment was performed using only letters for training, all other characters were ignored.", "labels": [], "entities": []}, {"text": "In the second experiment we used all characters from the texts; all letters were converted in lowercase.", "labels": [], "entities": []}, {"text": "The results for the first and the second experiments are presented in table 1.", "labels": [], "entities": []}, {"text": "Thus, we obtained slightly better results in case when all characters from the texts were used.", "labels": [], "entities": []}, {"text": "The next experiment was performed using wordbased PPM1 described in the previous section.", "labels": [], "entities": []}, {"text": "Its results were worse than for character based PPM5.", "labels": [], "entities": []}, {"text": "Next, we experimented with the unknown languages marked as xx.", "labels": [], "entities": []}, {"text": "There were several languages and thus, they did not present one uniform class of texts.", "labels": [], "entities": []}, {"text": "While the entropy for the texts written in the same language was in average 2 \u00b1 0.5 bit/symbol, for the different languages the average entropy varied from 4 to even 12 bit/symbol.", "labels": [], "entities": []}, {"text": "We considered two options of the unknown languages classification: -A threshold for these languages was used.", "labels": [], "entities": []}, {"text": "If the smallest entropy of a test text on the base of all models is bigger than a threshold we considered that text as not written in any of 13 known languages and hence, as unknown one and marked as xx.", "labels": [], "entities": []}, {"text": "In this case we created models only on 13 known classes of languages.", "labels": [], "entities": []}, {"text": "-All text marked with xx were treated as one more class.", "labels": [], "entities": []}, {"text": "In this case, 14 models were created, including a model for xx class and the standard procedure was applied.", "labels": [], "entities": []}, {"text": "Each test document was attributed to the class for which it has the lowest entropy.", "labels": [], "entities": []}, {"text": "The obtained results are presented in table 2.", "labels": [], "entities": []}, {"text": "Thus, the second option when all the documents written in the unknown languages were treated as the one class was better.", "labels": [], "entities": []}, {"text": "More than that, this result was even better than the pure classification of 13 known languages.", "labels": [], "entities": []}, {"text": "This indicates that xx class was distinguished fairly well.", "labels": [], "entities": []}, {"text": "The second set of the experiments was performed on the base of the test data released by the organizers of DSL shared task in June 2015.", "labels": [], "entities": [{"text": "DSL shared task in June 2015", "start_pos": 107, "end_pos": 135, "type": "DATASET", "confidence": 0.8952727218468984}]}, {"text": "These DSL Test Sets are part of the DSLCC v2.0, they comprise news data from various corpora to emulate the diverse news content across different languages and varieties.", "labels": [], "entities": [{"text": "DSL Test Sets", "start_pos": 6, "end_pos": 19, "type": "DATASET", "confidence": 0.8308873573939005}]}, {"text": "Two types of test data were released: \u2022The first test set that contained 14,000 unchanged sentences for 13 anguages/varieties and others (bg, bs, cz, es-AR, es-ES, hr, id, mk, my, pt-BR, pt-PT, sk, sr, xx).", "labels": [], "entities": []}, {"text": "\u2022The second test that contained 14,000 sentences with that had blinded Named Entities.", "labels": [], "entities": []}, {"text": "In these texts, the Named Entities (NEs) have been replaced by placeholders; a #NE# instead of a named entity.", "labels": [], "entities": []}, {"text": "An example of such sentence is: The initial sentence: La cinta, que hoy se estrena en nuestro pa\u00eds, competir\u00e1 contra Hors la Loi, de Argelia, Dogtooth, de Grecia, Incendies, de Canad\u00e1, Life above all , de Sud\u00e1frica, y con la ganadora del Globo de Oro, In A Better World, de Dinamarca.", "labels": [], "entities": [{"text": "Argelia", "start_pos": 133, "end_pos": 140, "type": "METRIC", "confidence": 0.9179680943489075}, {"text": "Dinamarca", "start_pos": 274, "end_pos": 283, "type": "DATASET", "confidence": 0.9151127338409424}]}, {"text": "We submitted only one run for each test set using PPM5 character based method using all characters from the text as this option demonstrated the best results in the first set of experiments.", "labels": [], "entities": []}, {"text": "While experimenting with the second test set with blinded NE we simply removed #NE# fragments and worked with the rest of the text.", "labels": [], "entities": []}, {"text": "The accuracy for the first task was equal to 94.14; for the second set it was 92.22.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.9998019337654114}]}, {"text": "The results were scored as the 4 th for the first task and 5 th for the second task, the best results being 95.54 and 94.01 respectively.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: The results for the first and the second expe- riments using letter and character based PPM5", "labels": [], "entities": []}, {"text": " Table 2: The results for the first and the second expe- riments with the unknown texts marked as xx", "labels": [], "entities": []}, {"text": " Table 3: Confusion table for Bulgarian and Macedo- nian", "labels": [], "entities": [{"text": "Confusion", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.8178887367248535}]}, {"text": " Table 4: Confusion table for Bosnian, Croatian and  Serbian", "labels": [], "entities": [{"text": "Confusion", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.8737205266952515}]}, {"text": " Table 6: Confusion table for Brazilian Portuguese and  European Portuguese", "labels": [], "entities": []}, {"text": " Table 7: Confusion table for Indonesian and Malay", "labels": [], "entities": []}]}