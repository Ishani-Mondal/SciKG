{"title": [{"text": "Rapid FrameNet annotation of spoken conversation transcripts", "labels": [], "entities": []}], "abstractContent": [{"text": "This paper presents the semantic annotation process of a corpus of spoken conversation transcriptions recorded in the Paris transport authority call-centre.", "labels": [], "entities": [{"text": "Paris transport authority call-centre", "start_pos": 118, "end_pos": 155, "type": "DATASET", "confidence": 0.8292852938175201}]}, {"text": "The semantic model used is a FrameNet model developed for the French language.", "labels": [], "entities": []}, {"text": "The methodology proposed for the rapid annotation of this corpus is a semi-supervised process where syntactic dependency annotations are used in conjunction with a semantic lexicon in order to generate frame candidates for each turn of a conversation.", "labels": [], "entities": []}, {"text": "This first hypotheses generation is followed by a rule-based decision module in charge of filtering and removing ambiguities in the frames generated.", "labels": [], "entities": []}, {"text": "These rules are very specific, they don't need to generalize to other examples as the final goal of this study is limited to the annotation of this given corpus, on which a statistical frame parser will finally be trained.", "labels": [], "entities": []}, {"text": "This paper describes this methodology and give examples of annotations obtained.", "labels": [], "entities": []}, {"text": "A first evaluation of the quality of the corpus obtained is also given on a small gold corpus manually labeled.", "labels": [], "entities": []}], "introductionContent": [{"text": "Parsing human-human conversations consists in enriching text transcription with structural and semantic information.", "labels": [], "entities": [{"text": "Parsing human-human conversations", "start_pos": 0, "end_pos": 33, "type": "TASK", "confidence": 0.8693159222602844}, {"text": "text transcription", "start_pos": 56, "end_pos": 74, "type": "TASK", "confidence": 0.7796680927276611}]}, {"text": "Such information include sentence boundaries, syntactic and semantic parse of each sentence, para-semantic traits related to several paralinguistic dimensions (emotion, polarity, behavioral patterns) and finally discourse structure features in order to take into account the interactive nature of a conversation.", "labels": [], "entities": []}, {"text": "The applicative context of this work is the automatic processing of human-human spoken conversations recorded in customer service telephone call centers.", "labels": [], "entities": [{"text": "automatic processing of human-human spoken conversations recorded in customer service telephone call centers", "start_pos": 44, "end_pos": 152, "type": "TASK", "confidence": 0.6909416478413802}]}, {"text": "The goal of processing such data is to take advantage of cues in order to automatically obtain relevant summaries and reports of such conversations for speech mining applications.", "labels": [], "entities": [{"text": "speech mining", "start_pos": 152, "end_pos": 165, "type": "TASK", "confidence": 0.7078863829374313}]}, {"text": "These processes are needed because coarse-grained analyses, such as keyword search, are unable to capture relevant meaning and are therefore unable to understand human dialogs.", "labels": [], "entities": [{"text": "keyword search", "start_pos": 68, "end_pos": 82, "type": "TASK", "confidence": 0.7418879270553589}]}, {"text": "Performing semantic parsing on spoken transcriptions is a challenging task.", "labels": [], "entities": [{"text": "semantic parsing on spoken transcriptions", "start_pos": 11, "end_pos": 52, "type": "TASK", "confidence": 0.7610347986221313}]}, {"text": "Spoken conversation transcriptions have characteristics that make them very different to process from written text Tur and De Mori (2011).", "labels": [], "entities": [{"text": "Spoken conversation transcriptions", "start_pos": 0, "end_pos": 34, "type": "TASK", "confidence": 0.8061478932698568}]}, {"text": "The general process of parsing conversations can be divided into three levels: conversational data pre-processing; syntactic parsing; semantic parsing.", "labels": [], "entities": [{"text": "parsing conversations", "start_pos": 23, "end_pos": 44, "type": "TASK", "confidence": 0.9200766980648041}, {"text": "syntactic parsing", "start_pos": 115, "end_pos": 132, "type": "TASK", "confidence": 0.7427732348442078}, {"text": "semantic parsing", "start_pos": 134, "end_pos": 150, "type": "TASK", "confidence": 0.7262382805347443}]}, {"text": "The pre-processing level involves the transcription (automatic or manual) of the spoken content and the segmentation into speakers' turns and sentence-like units.", "labels": [], "entities": []}, {"text": "The syntactic parsing level aims to uncover the word relationships (e.g. word order, constituents) within a sentence and support the semantic layer of the language-processing pipeline.", "labels": [], "entities": [{"text": "syntactic parsing", "start_pos": 4, "end_pos": 21, "type": "TASK", "confidence": 0.7153448909521103}]}, {"text": "Shallow syntactic processes, including part-of-speech and syntactic chunk tagging, are usually performed in a first stage.", "labels": [], "entities": [{"text": "syntactic chunk tagging", "start_pos": 58, "end_pos": 81, "type": "TASK", "confidence": 0.6169602672259012}]}, {"text": "One of the key activities described in this paper is the adaptation of a syntactic dependency parser to the processing of spontaneous speech.", "labels": [], "entities": [{"text": "syntactic dependency parser", "start_pos": 73, "end_pos": 100, "type": "TASK", "confidence": 0.7001916567484537}]}, {"text": "The syntactic parses obtained are used in the next step for semantic parsing.", "labels": [], "entities": [{"text": "semantic parsing", "start_pos": 60, "end_pos": 76, "type": "TASK", "confidence": 0.8687723577022552}]}, {"text": "The semantic parsing level is the process of producing semantic interpretations from words and other linguistic events that are automatically detected in a text conversation or a speech signal.", "labels": [], "entities": [{"text": "semantic parsing level is the process of producing semantic interpretations from words and other linguistic events that are automatically detected in a text conversation or a speech signal", "start_pos": 4, "end_pos": 192, "type": "Description", "confidence": 0.7439513749309948}]}, {"text": "Many semantic models have been proposed, ranging from formal models encoding deep semantic structures to shallow ones considering only the main topic of a document and its main concepts or entities.", "labels": [], "entities": []}, {"text": "We use in this study a FrameNet-based approach to semantics that, without needing a full semantic parse of a message, goes further than a simple flat translation of a message into basic concepts: FrameNet-based semantic parsers detect in a sentence the expression of frames and their roles.", "labels": [], "entities": [{"text": "FrameNet-based semantic parsers detect in a sentence the expression of frames", "start_pos": 196, "end_pos": 273, "type": "TASK", "confidence": 0.7319450947371396}]}, {"text": "Because frames and roles abstract away from syntactic and lexical variation, FrameNet semantic analysis gives enhanced access to the meaning of texts: of the kind who does what, and how where and when ?.", "labels": [], "entities": [{"text": "FrameNet semantic analysis", "start_pos": 77, "end_pos": 103, "type": "TASK", "confidence": 0.6242641508579254}]}, {"text": "We describe in this paper the rapid semantic annotation of a corpus of human-human conversations recorded in the Paris public authority call-centre, the RATP-DECODA corpus presented in.", "labels": [], "entities": [{"text": "Paris public authority call-centre", "start_pos": 113, "end_pos": 147, "type": "DATASET", "confidence": 0.87518011033535}, {"text": "RATP-DECODA corpus", "start_pos": 153, "end_pos": 171, "type": "DATASET", "confidence": 0.9397921562194824}]}, {"text": "This corpus is presented in section 2.", "labels": [], "entities": []}, {"text": "The methodology followed is a semi-supervised process where syntactic dependency annotations are used in conjunction with a semantic lexicon in order to generate frame candidates for each turn of a conversation.", "labels": [], "entities": []}, {"text": "This first hypotheses generation is followed by a rule-based decision module in charge of filtering and removing ambiguities in the frames generated.", "labels": [], "entities": []}, {"text": "Section 3 describes the adaptation of syntactic parsing models to the processing of spontaneous speech.", "labels": [], "entities": [{"text": "syntactic parsing", "start_pos": 38, "end_pos": 55, "type": "TASK", "confidence": 0.7154515385627747}]}, {"text": "Section 4 presents the FrameNet semantic model derived for annotating these call-centre conversations, and finally section 5 reports some evaluation results on a small gold corpus manually annotated.", "labels": [], "entities": []}], "datasetContent": [{"text": "A small gold corpus was manually defined and annotated.", "labels": [], "entities": []}, {"text": "The automatic rule-based Frame selection process is evaluated on this corpus, as presented in.", "labels": [], "entities": [{"text": "Frame selection", "start_pos": 25, "end_pos": 40, "type": "TASK", "confidence": 0.8117282092571259}]}, {"text": "Our gold corpus is a set on 21 conversations from the RATP-DECODA corpus.", "labels": [], "entities": [{"text": "gold corpus", "start_pos": 4, "end_pos": 15, "type": "DATASET", "confidence": 0.7968379557132721}, {"text": "RATP-DECODA corpus", "start_pos": 54, "end_pos": 72, "type": "DATASET", "confidence": 0.936582088470459}]}, {"text": "These conversations were fully manually annotated by one annotator.", "labels": [], "entities": []}, {"text": "The tables below give a representation of the distribution of the frames on this subcorpus, comparing manual annotation and automatic annotation.", "labels": [], "entities": []}, {"text": "show us that on average there is at least one trigger per speaker turn.", "labels": [], "entities": []}, {"text": "Moreover, we can already tell that the automatic annotation predicts more triggers than the human annotator, and get more variability in the frame chosen.", "labels": [], "entities": []}, {"text": "In we find our main domain on the RATP-DECODA corpus through the frames.", "labels": [], "entities": [{"text": "RATP-DECODA corpus", "start_pos": 34, "end_pos": 52, "type": "DATASET", "confidence": 0.885109931230545}]}, {"text": "In fact \"Hello\" and \"Judgment direct address\" represent the structure of the call (opening and closing), while \"Request\", \"Losing\", \"Motion\" and \"Commerce buy\" can easily represent the reason of the call.", "labels": [], "entities": [{"text": "Motion", "start_pos": 133, "end_pos": 139, "type": "METRIC", "confidence": 0.9074435830116272}]}, {"text": "The quality of the automatic prediction, with respect to the gold corpus, is presented in.", "labels": [], "entities": [{"text": "gold corpus", "start_pos": 61, "end_pos": 72, "type": "DATASET", "confidence": 0.8698154389858246}]}, {"text": "There are different levels of evaluation (trigger selection, frame level, frame element level, span, . .", "labels": [], "entities": [{"text": "span", "start_pos": 95, "end_pos": 99, "type": "METRIC", "confidence": 0.952198326587677}]}, {"text": "). We chose to evaluate our annotation at the frame level.", "labels": [], "entities": []}, {"text": "In other words, we evaluate if a trigger produced the correct frame.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 3: Frames distribution on the gold corpus.", "labels": [], "entities": [{"text": "Frames distribution", "start_pos": 10, "end_pos": 29, "type": "TASK", "confidence": 0.6649045795202255}, {"text": "gold corpus", "start_pos": 37, "end_pos": 48, "type": "DATASET", "confidence": 0.9325900375843048}]}, {"text": " Table 4: Top 10 used frames on the gold corpus.", "labels": [], "entities": [{"text": "gold corpus", "start_pos": 36, "end_pos": 47, "type": "DATASET", "confidence": 0.9408319592475891}]}, {"text": " Table 5.  There are different levels of evaluation (trigger selection, frame level, frame element level, span, . . . ).  We chose to evaluate our annotation at the frame level. In other words, we evaluate if a trigger produced  the correct frame.", "labels": [], "entities": [{"text": "span", "start_pos": 106, "end_pos": 110, "type": "METRIC", "confidence": 0.9579251408576965}]}]}