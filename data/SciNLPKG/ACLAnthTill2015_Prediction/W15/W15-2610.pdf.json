{"title": [{"text": "Parser Adaptation to the Biomedical Domain without Re-Training", "labels": [], "entities": [{"text": "Parser Adaptation", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.8029450476169586}]}], "abstractContent": [{"text": "We present a distributional approach to the problem of inducing parameters for unseen words in probabilistic parsers.", "labels": [], "entities": []}, {"text": "Our KNN-based algorithm uses distributional similarity over an unlabelled corpus to match unseen words to the most similar seen words, and can induce parameters for those unseen words without retraining the parser.", "labels": [], "entities": []}, {"text": "We apply this to domain adaptation for three different parsers that employ fine-grained syntactic categories, which allows us to focus on modifying the lexicon, while leaving the structure of the parser itself intact.", "labels": [], "entities": [{"text": "domain adaptation", "start_pos": 17, "end_pos": 34, "type": "TASK", "confidence": 0.7170752435922623}]}, {"text": "We demonstrate uplifts for dependency recovery of 2%-6% on novel vocabulary in biomedical text.", "labels": [], "entities": []}], "introductionContent": [{"text": "Parsing is an important component in many NLP applications.", "labels": [], "entities": [{"text": "Parsing", "start_pos": 0, "end_pos": 7, "type": "TASK", "confidence": 0.8879038095474243}]}, {"text": "Shallower analyses may allow the discovery of local relations, but to handle the full complexity of speech and text requires knowledge of the hierarchical structures that parsers are designed to uncover.", "labels": [], "entities": []}, {"text": "This is particularly true of long range dependencies such as that between activities and decreased in the specific synthetic activities of electrophoretically purified myosin heavy chain decreased.", "labels": [], "entities": []}, {"text": "Such dependencies have proven to be useful features in many text mining and knowledge extraction applications, for example identifying biomarkers in the biomedical literature or extracting family history from clinical text ().", "labels": [], "entities": [{"text": "text mining and knowledge extraction", "start_pos": 60, "end_pos": 96, "type": "TASK", "confidence": 0.6826415419578552}, {"text": "extracting family history from clinical text", "start_pos": 178, "end_pos": 222, "type": "TASK", "confidence": 0.8489182690779368}]}, {"text": "Correctly identifying the dependencies within a string of words is generally based on finding the most probable structure over them, and this in turn requires knowing what sort of relations each word is likely to enter into.", "labels": [], "entities": []}, {"text": "Unfortunately, gold standard training data, annotated with these syntactic relations, is generally in short supply.", "labels": [], "entities": []}, {"text": "The vocabulary for which we have explicitly seen examples of the type of dependencies each word supports is therefore typically small and performance on real data is often degraded in handling out-of-vocabulary items.", "labels": [], "entities": []}, {"text": "Although the Penn Treebank has been a vital tool in the development and evaluation of parsing technology, providing a standard dataset for comparison of parsers, practical application of these techniques usually requires adaptation to new domains., for example, examine the adaptation of a WSJ-trained CCG parser to the biomedical domain.", "labels": [], "entities": [{"text": "Penn Treebank", "start_pos": 13, "end_pos": 26, "type": "DATASET", "confidence": 0.9955155551433563}, {"text": "parsing", "start_pos": 86, "end_pos": 93, "type": "TASK", "confidence": 0.96640944480896}, {"text": "WSJ-trained CCG", "start_pos": 290, "end_pos": 305, "type": "DATASET", "confidence": 0.9071691930294037}]}, {"text": "The divergence between these two domains, news and biology, is manifest in terms of both vocabulary and also stylistic differences in the prevalence of various syntactic structures.", "labels": [], "entities": []}, {"text": "For example, biomedical writing eschews personal pronouns and tolerates long sequences of noun modifiers, whereas the style of news articles tends to reverse these preferences.", "labels": [], "entities": []}, {"text": "approach to adapting to these differences is based on retraining elements of the model using biomedical texts which have been hand-tagged with gold-standard tags.", "labels": [], "entities": []}, {"text": "While this is undoubtedly effective, achieving an overall improvement of F-score of over 5%, it requires a considerable commitment of skilled resources to manually annotate a substantial corpus with the linguistically correct tags.", "labels": [], "entities": [{"text": "F-score", "start_pos": 73, "end_pos": 80, "type": "METRIC", "confidence": 0.9989299178123474}]}, {"text": "Here, we consider a distributional approach to domain adaptation using the information about syntactic structure that is implicit in raw text.", "labels": [], "entities": [{"text": "domain adaptation", "start_pos": 47, "end_pos": 64, "type": "TASK", "confidence": 0.7480147778987885}]}, {"text": "We estimate parameters for unseen words using a KNN approach that matches them to the nearest seen words and averages over their parameters.", "labels": [], "entities": []}, {"text": "We explore a number of different approaches to measuring distributional similarity and find that vectors based on counts of occurrence within ngram contexts give the best results.", "labels": [], "entities": []}, {"text": "Bag-of-word approaches and neural embeddings, which have worked well for semantic tasks, do not appear to capture the information about syntactic similarity that this task requires.", "labels": [], "entities": []}, {"text": "Our use of ngram contexts is inspired by psycholinguistic research into the acquisition of syntactic categories., for example, consider how children might use a word's distribution across a range of templates, such as the XXX is good, to infer its syntactic properties.", "labels": [], "entities": []}, {"text": "They show, in simulations, that such distributional information can be used to infer syntactic categories from child-directed speech.", "labels": [], "entities": []}, {"text": "analyses distributions over a simpler type of template, which he calls a frequent frame, consisting of a pair of common lexical items flanking a word of interest, e.g. you XXX it or the XXX is.", "labels": [], "entities": []}, {"text": "In addition to showing how such distributional information can be used to induce categories, he also discusses the evidence that adults and children are sensitive to these frames.", "labels": [], "entities": []}, {"text": "consider even simpler contexts, based simply on bigram colocations, e.g. the XXX.", "labels": [], "entities": []}, {"text": "Pinker, on the other hand, has long contested the possibility of using such distributional information to acquire valid grammatical categories, and proposes instead that grammatical categories are bootstrapped using semantic knowledge.", "labels": [], "entities": []}, {"text": "While the patterns and templates described above can be used to characterise a word's behaviour in terms of concrete occurrences in specific contexts, neural networks have recently become popular as a means to create more abstract representations.", "labels": [], "entities": []}, {"text": "In this case, as the network adapts to the data, representations are learned that embed discrete inputs in a continuous space defined by its internal states.", "labels": [], "entities": []}, {"text": "Researchers have been interested in the nature of such internal representations for sometime (e.g.,).", "labels": [], "entities": []}, {"text": "However, it has now become practical to induce such embeddings from large quantities of text and employ them in linguistic applications.", "labels": [], "entities": []}, {"text": "For example, and apply neural representations to POS tagging, and this suggests that at least some useful information about the syntax of unseen words might be gained from this source.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 49, "end_pos": 60, "type": "TASK", "confidence": 0.8026283383369446}]}, {"text": "While POS tags can provide a coarse-grained description of words' syntactic behaviour, accurate parsing typically requires finer-grained detail.", "labels": [], "entities": []}, {"text": "We can distinguish between two approaches, which maybe combined, to specifying this additional level of detail.", "labels": [], "entities": []}, {"text": "The first approach simply makes use of finer-grained syntactic categories, either instead of or in addition to POS tags).", "labels": [], "entities": []}, {"text": "These categories can then determine the missing information about the dependencies a word will take part in, such as whether a verb is intransitive or whether it takes prepositional arguments.", "labels": [], "entities": []}, {"text": "The second approach instead increases the granularity of the production rules, by conditioning the probabilities on the heads of the phrases involved.", "labels": [], "entities": []}, {"text": "In this way, words are associated with probabilities for the structure of phrases that they head, determining, for example, the types of object that a verb phrase expands into.", "labels": [], "entities": []}, {"text": "Although the two approaches are compatible, a significant difference makes the former more conducive to our purposes.", "labels": [], "entities": []}, {"text": "Enhancing the granularity of the syntactic categories results in a much richer lexicon containing more information about how words behave syntactically.", "labels": [], "entities": []}, {"text": "In principle, this should lead to an enlargement of the lexicon having a greater impact on performance by itself.", "labels": [], "entities": []}, {"text": "In the latter approach, of lexicalising the production rules, expanding the vocabulary of the parser maybe much more complicated, requiring modifications throughout the model.", "labels": [], "entities": []}, {"text": "In contrast our approach simply adds new entries to the lexicon without the need to retrain the parser.", "labels": [], "entities": []}, {"text": "In fact, our approach does not even require full sentences and can be applied to an unlabelled corpus of ngram counts.", "labels": [], "entities": []}, {"text": "Our KNN approach and the three parsers we modify are described in Sections 2 and 3 respectively.", "labels": [], "entities": []}, {"text": "We then use a biomedical dependency recovery task, specified in Section 4, to evaluate the performance of the modified parsers, as reported in Section 5.", "labels": [], "entities": [{"text": "biomedical dependency recovery", "start_pos": 14, "end_pos": 44, "type": "TASK", "confidence": 0.633518636226654}]}], "datasetContent": [{"text": "We measure the performance of our parsers in terms of the ability to recover dependencies from biomedical text.", "labels": [], "entities": []}, {"text": "Dependency recovery is not only a useful component in processing both clinical text () and biomedical literature, it also provides an evaluation metric that is independent of the particular syntactic formalism employed in the parser.", "labels": [], "entities": [{"text": "Dependency recovery", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.7394880056381226}]}, {"text": "BioInfer () is a corpus of about 35,000 words from PUBMED abstracts, annotated with grammatical relations using a slight modification of the Stanford dependencies scheme (de).", "labels": [], "entities": []}, {"text": "Our models were tuned on a development set of 600 sentences and then evaluated on the remaining 500 sentence test set, using the same split as and.", "labels": [], "entities": []}, {"text": "The vocabulary in these sentences diverges considerably from that found in the WSJ, with about 27% of the tokens being unseen.", "labels": [], "entities": [{"text": "WSJ", "start_pos": 79, "end_pos": 82, "type": "DATASET", "confidence": 0.8562304377555847}]}, {"text": "Of the \u2248 3, 000 unseen word types found in BioInfer, 92% occur in the unlabelled Medline corpus that we use to induce distributional representations, and over 80% are assigned parameters by the KNN method.", "labels": [], "entities": [{"text": "Medline corpus", "start_pos": 81, "end_pos": 95, "type": "DATASET", "confidence": 0.9095580577850342}]}, {"text": "In contrast, only about 700 of those unseen words are present in the SENNA vocabulary, all of which are assigned parameters.", "labels": [], "entities": [{"text": "SENNA vocabulary", "start_pos": 69, "end_pos": 85, "type": "DATASET", "confidence": 0.7745324969291687}]}, {"text": "compares the performance of the Berkeley, C&C and EasyCCG parsers on the BioInfer development set, after KNN adaptation using various forms of distributional similarity.", "labels": [], "entities": [{"text": "BioInfer development set", "start_pos": 73, "end_pos": 97, "type": "DATASET", "confidence": 0.9129219651222229}]}, {"text": "The results for each parser are grouped together with the first line in each of these groups giving the baseline F-score achieved on the BioInfer development set before expanding the vocabulary.", "labels": [], "entities": [{"text": "F-score", "start_pos": 113, "end_pos": 120, "type": "METRIC", "confidence": 0.977393627166748}, {"text": "BioInfer development set", "start_pos": 137, "end_pos": 161, "type": "DATASET", "confidence": 0.828588863213857}]}, {"text": "Each subsequent line then corresponds to the best model found for each type of representation, with columns containing D, the number of dimensions in the distributional vectors, k, the number of nearest neighbours, and lastly the F-Score.", "labels": [], "entities": [{"text": "F-Score", "start_pos": 230, "end_pos": 237, "type": "METRIC", "confidence": 0.9728200435638428}]}], "tableCaptions": [{"text": " Table 1: F-scores for recovery of dependencies on  the BioInfer development set for the best perform- ing D and k for each type of KNN model.", "labels": [], "entities": [{"text": "F-scores", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9957994818687439}, {"text": "BioInfer development set", "start_pos": 56, "end_pos": 80, "type": "DATASET", "confidence": 0.8554349939028422}]}, {"text": " Table 2: F-scores for recovery of dependencies for  the original models and the best performing KNN  enhanced models on the BioInfer test set.", "labels": [], "entities": [{"text": "F-scores", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9981166124343872}, {"text": "BioInfer test set", "start_pos": 125, "end_pos": 142, "type": "DATASET", "confidence": 0.9592904845873514}]}]}