{"title": [{"text": "POS-tagging of Tunisian Dialect Using Standard Arabic Resources and Tools", "labels": [], "entities": [{"text": "POS-tagging of Tunisian Dialect", "start_pos": 0, "end_pos": 31, "type": "TASK", "confidence": 0.4294509291648865}]}], "abstractContent": [{"text": "Developing natural language processing tools usually requires a large number of resources (lexica, annotated corpora, etc.), which often do not exist for less-resourced languages.", "labels": [], "entities": []}, {"text": "One way to overcome the problem of lack of resources is to devote substantial efforts to build new ones from scratch.", "labels": [], "entities": []}, {"text": "Another approach is to exploit existing resources of closely related languages.", "labels": [], "entities": []}, {"text": "In this paper, we focus on developing a part-of-speech tagger for the Tunisian Arabic dialect (TUN), a low-resource language, by exploiting its close-ness to Modern Standard Arabic (MSA), which has many state-of-the-art resources and tools.", "labels": [], "entities": []}, {"text": "Our system achieved an accuracy of 89% (\u223c20% absolute improvement over an MSA tagger baseline).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 23, "end_pos": 31, "type": "METRIC", "confidence": 0.999599039554596}, {"text": "MSA tagger", "start_pos": 74, "end_pos": 84, "type": "TASK", "confidence": 0.6137709319591522}]}], "introductionContent": [{"text": "The Arabic language is characterized by diglossia : two linguistic variants live side by side: a standard written form and a large variety of spoken dialects.", "labels": [], "entities": []}, {"text": "While dialects differ from one region to another, the written variety, called Modern Standard Arabic (MSA), is generally the same.", "labels": [], "entities": [{"text": "Modern Standard Arabic (MSA)", "start_pos": 78, "end_pos": 106, "type": "DATASET", "confidence": 0.822246640920639}]}, {"text": "MSA, the official language for Arabic countries, is used for written communication as well as informal spoken communications.", "labels": [], "entities": [{"text": "MSA", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.8587727546691895}]}, {"text": "Spoken varieties, generally used in informal daily discussions, are increasingly being used for informal written communication on the web.", "labels": [], "entities": []}, {"text": "Such unstandardized varieties differ from MSA with respect to phonology, morphology, syntax and the lexicon.", "labels": [], "entities": []}, {"text": "Unlike MSA which has an important number of NLP resources and tools, Arabic dialects are less-resourced.", "labels": [], "entities": []}, {"text": "In this paper, we focus on the Tunisian Arabic dialect.", "labels": [], "entities": []}, {"text": "It is the spoken language of twelve million speakers living mainly in Tunisia.", "labels": [], "entities": []}, {"text": "TUN is the result of interactions and influences of a number of languages including Arabic, Berber and French (.", "labels": [], "entities": [{"text": "TUN", "start_pos": 0, "end_pos": 3, "type": "TASK", "confidence": 0.5806072950363159}]}, {"text": "In this paper, we focus on the development of a part-of-speech (POS) tagger for TUN.", "labels": [], "entities": []}, {"text": "There are two main options when developing such a tool for TUN.", "labels": [], "entities": []}, {"text": "The first one is to build a corpus of TUN, which involves recording, transcribing and manually POS tagging.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 95, "end_pos": 106, "type": "TASK", "confidence": 0.6610936671495438}]}, {"text": "In order to have a state-of-theart POS tagger one also needs to develop a lexicon.", "labels": [], "entities": []}, {"text": "The second option is to convert TUN into an approximate form of MSA, that we will call pseudo MSA, and use an existing MSA POS tagger.", "labels": [], "entities": []}, {"text": "We intentionally do not use the verb translate to describe the process of transforming a TUN text into a pseudo MSA text.", "labels": [], "entities": []}, {"text": "The reason being that we are not translating between two natural languages: pseudo MSA is not meant to be read by humans.", "labels": [], "entities": []}, {"text": "Its only purpose is to be close enough to MSA so that running it through NLP tools would give good results.", "labels": [], "entities": [{"text": "MSA", "start_pos": 42, "end_pos": 45, "type": "DATASET", "confidence": 0.8388745784759521}]}, {"text": "The annotation produced is then projected back on the TUN text.", "labels": [], "entities": [{"text": "TUN text", "start_pos": 54, "end_pos": 62, "type": "DATASET", "confidence": 0.9617983102798462}]}, {"text": "More technically, the conversion process focuses on morphological and lexical aspects; it is based on morphological analyzers and generators for TUN and MSA as well as a TUN-MSA dictionaries which are themselves partly automatically produced using the morphological analyzers and generators.", "labels": [], "entities": []}, {"text": "Besides producing a POS tagger for TUN, we aim at proposing a general methodology for developing NLP tools for dialects of Arabic.", "labels": [], "entities": []}, {"text": "The rest of the paper is organized as follows: we present, in section 2, phonological, lexical and morphosyntactic variations between TUN and MSA.", "labels": [], "entities": []}, {"text": "We then discuss related works and existing POS taggers of Arabic dialects in section 3.", "labels": [], "entities": []}, {"text": "Section 4 reviews the tools and resources used in this work.", "labels": [], "entities": []}, {"text": "In section 5, we describe in detail our approach to tag TUN texts.", "labels": [], "entities": [{"text": "tag TUN texts", "start_pos": 52, "end_pos": 65, "type": "TASK", "confidence": 0.5703568557898203}]}, {"text": "Finally, Section 6 presents results evaluating our approach under several conditions.", "labels": [], "entities": []}], "datasetContent": [{"text": "Our system consists of three step: conversion, disambiguation and POS tagging.", "labels": [], "entities": [{"text": "conversion", "start_pos": 35, "end_pos": 45, "type": "TASK", "confidence": 0.9638625979423523}, {"text": "POS tagging", "start_pos": 66, "end_pos": 77, "type": "TASK", "confidence": 0.776549220085144}]}, {"text": "The TUN input sentence t 1 t 2 t 3 . .", "labels": [], "entities": []}, {"text": "tn , is converted to a MSA lattice.", "labels": [], "entities": []}, {"text": "The lattice is then disambiguated to produce a pseudo MSA target sentence m 1 m 2 m 3 . .", "labels": [], "entities": []}, {"text": "m n . Next, a MSA tagger assign to each target word its POS tag.", "labels": [], "entities": [{"text": "MSA tagger", "start_pos": 14, "end_pos": 24, "type": "TASK", "confidence": 0.8145810961723328}]}, {"text": "The disambiguation step is optional, the MSA lattice can be sent directly to the POS tagger which tags the lattice and produces the most likely tag sequence.", "labels": [], "entities": []}, {"text": "Taking as an example the TUN sentence tijbar bA\u0161 yuq\u03c2ud 'he was obliged to stay', which correspond to the sequence of POS tags verb-pass 5 -part -verb.", "labels": [], "entities": [{"text": "TUN sentence tijbar bA\u0161 yuq\u03c2ud", "start_pos": 25, "end_pos": 55, "type": "TASK", "confidence": 0.47927998304367064}]}, {"text": "This sentence translates into MSA as Ai\u00f0Tar\u223ca \u02c7 Aila\u00fd AlbaqA'.", "labels": [], "entities": [{"text": "MSA as Ai\u00f0Tar\u223ca \u02c7 Aila\u00fd AlbaqA", "start_pos": 30, "end_pos": 60, "type": "DATASET", "confidence": 0.5355521738529205}]}, {"text": "Our system produces for this sentence, after conversion and disambiguation, the sentence Au\u00f0Tur\u223ca sawfa yajlisu 'he was obliged will sit-down' which receives the correct POS tags sequence verb-pass -partverb, although the MSA translation is suboptimal.", "labels": [], "entities": [{"text": "MSA", "start_pos": 222, "end_pos": 225, "type": "DATASET", "confidence": 0.8314010500907898}]}, {"text": "In the remainder of this section, we describe in detail each step of the whole process.", "labels": [], "entities": []}, {"text": "In order to evaluate our method, we used a transcribed and annotated corpus of 805 sentences containing 10, 746 tokens and 2, 455 types.", "labels": [], "entities": []}, {"text": "These sentences were obtained from several sources: TV series and political debates, a transcribed theater play and a transcribed corpus made of conversations between a customer and a railways officer.", "labels": [], "entities": []}, {"text": "This selection aims to include different TUN spoken varieties.", "labels": [], "entities": []}, {"text": "After transcribing, we have assigned to each token its lemma, lmm and POS tag using the same conventions as the corpus used to train the tagger.", "labels": [], "entities": [{"text": "POS tag", "start_pos": 70, "end_pos": 77, "type": "METRIC", "confidence": 0.948654055595398}]}, {"text": "Our baseline experiment consists of running the MSA POS tagger directly on TUN texts without any processing.", "labels": [], "entities": [{"text": "MSA POS tagger", "start_pos": 48, "end_pos": 62, "type": "TASK", "confidence": 0.6049622098604838}]}, {"text": "This baseline will allow us to measure the contribution of converting TUN to pseudo MSA prior to POS tagging with the MSA tagger.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 97, "end_pos": 108, "type": "TASK", "confidence": 0.7189722061157227}]}, {"text": "The accuracy of tagging and the number of out-of-vocabulary words are given in.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.9996566772460938}]}, {"text": "The lemmas and lmms used for the experiment are gold lemmas and lmms, presented again for comparative reasons.", "labels": [], "entities": []}, {"text": "Our official baseline is with forms.", "labels": [], "entities": []}, {"text": "For our main experiment we convert TUN texts to pseudo MSA before POS tagging.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 66, "end_pos": 77, "type": "TASK", "confidence": 0.6685431599617004}]}, {"text": "The conversion step produces three lattices (forms, lemmas, lmms).", "labels": [], "entities": []}, {"text": "The form lattice is disambiguated by the language models providing a scored lattice and the first best path.", "labels": [], "entities": []}, {"text": "We ran the POS tagging of pseudo-MSA forms in three modes: on the best form path, on the scored lattice and the unscored lattice produced by the conversion.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 11, "end_pos": 22, "type": "TASK", "confidence": 0.7105047106742859}]}, {"text": "The final output is the sequence of POS tags for the words in the original sentence.", "labels": [], "entities": []}, {"text": "Results are shown in).", "labels": [], "entities": []}, {"text": "Disambiguation based on the POS tagger gives better accuracy (\u223c82.5% on forms) than the language model (77.2%).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 52, "end_pos": 60, "type": "METRIC", "confidence": 0.9993181228637695}]}, {"text": "Our convertion process allows to produce, MSA lemmas and lmms rather then forms by leaving the morphological generation of MSA forms.", "labels": [], "entities": []}, {"text": "The POS tagger was ran thus on the lattices of lemmas and lmms.", "labels": [], "entities": []}, {"text": "In, we give results of POS tagging such inputs.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 23, "end_pos": 34, "type": "TASK", "confidence": 0.7526119649410248}]}, {"text": "We give again results on forms to compare these final results with the basline results.", "labels": [], "entities": [{"text": "basline", "start_pos": 71, "end_pos": 78, "type": "METRIC", "confidence": 0.6491483449935913}]}, {"text": "predicted predicted forms lemmas lmms accuracy 82.5% 86.9% 89.1% OOVs 13.5% 6.2% 4.9%: Accuracy of POS tagging of pseudo MSA lemmas and lmms As shown in, POS tagging of lemmas and lmms outperforms POS tagging of forms.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 38, "end_pos": 46, "type": "METRIC", "confidence": 0.9881654977798462}, {"text": "OOVs", "start_pos": 65, "end_pos": 69, "type": "METRIC", "confidence": 0.9487340450286865}, {"text": "Accuracy", "start_pos": 87, "end_pos": 95, "type": "METRIC", "confidence": 0.9942881464958191}, {"text": "POS tagging", "start_pos": 99, "end_pos": 110, "type": "TASK", "confidence": 0.7818610370159149}, {"text": "POS tagging", "start_pos": 154, "end_pos": 165, "type": "TASK", "confidence": 0.8731469810009003}, {"text": "POS tagging", "start_pos": 197, "end_pos": 208, "type": "TASK", "confidence": 0.8320673704147339}]}, {"text": "Our best accuracy, with lmms, jumps to 89.1%: a 20% absolute increase of the baseline of using the MSA POS tagger directly on the TUN sentences.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 9, "end_pos": 17, "type": "METRIC", "confidence": 0.9996219873428345}]}, {"text": "An error analysis of the first 100 errors shows that 34 of them are due to bad conversion and 49 to bad disambiguation.", "labels": [], "entities": []}, {"text": "Only, 17 of the errors came from POS tagging.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 33, "end_pos": 44, "type": "TASK", "confidence": 0.6651987731456757}]}], "tableCaptions": [{"text": " Table 4: Accuracy of POS tagging of MSA corpus", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9955511093139648}, {"text": "POS tagging", "start_pos": 22, "end_pos": 33, "type": "TASK", "confidence": 0.8118410706520081}]}, {"text": " Table 5: Baseline Accuracy of POS tagging TUN  using MSA POS tagger", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 19, "end_pos": 27, "type": "METRIC", "confidence": 0.9303094744682312}, {"text": "POS tagging TUN", "start_pos": 31, "end_pos": 46, "type": "TASK", "confidence": 0.7779574195543925}]}, {"text": " Table 6: Accuracy of POS tagging of pseudo MSA", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9950733780860901}, {"text": "POS tagging", "start_pos": 22, "end_pos": 33, "type": "TASK", "confidence": 0.7945483326911926}]}]}