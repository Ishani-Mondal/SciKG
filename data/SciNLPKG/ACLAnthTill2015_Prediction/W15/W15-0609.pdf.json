{"title": [{"text": "Towards Automatic Description of Knowledge Components", "labels": [], "entities": [{"text": "Automatic Description of Knowledge Components", "start_pos": 8, "end_pos": 53, "type": "TASK", "confidence": 0.7699802160263062}]}], "abstractContent": [{"text": "A key aspect of cognitive diagnostic models is the specification of the Q-matrix associating the items and some underlying student attributes.", "labels": [], "entities": []}, {"text": "In many data-driven approaches, test items are mapped to the underlying, latent knowledge components (KC) based on observed student performance, and with little or no input from human experts.", "labels": [], "entities": []}, {"text": "As a result, these latent skills typically focus on model-ing the data accurately, but maybe hard to describe and interpret.", "labels": [], "entities": []}, {"text": "In this paper, we focus on the problem of describing these knowledge components.", "labels": [], "entities": []}, {"text": "Using a simple probabilis-tic model, we extract, from the text of the test items, some keywords that are most relevant to each KC.", "labels": [], "entities": []}, {"text": "On a small dataset from the PSLC datashop, we show that this is surprisingly effective, retrieving unknown skill labels in close to 50% of cases.", "labels": [], "entities": [{"text": "PSLC datashop", "start_pos": 28, "end_pos": 41, "type": "DATASET", "confidence": 0.8415092527866364}]}, {"text": "We also show that our method clearly outperforms typical base-lines in specificity and diversity.", "labels": [], "entities": []}], "introductionContent": [{"text": "Recent years have seen significant advances in automatically identifying latent attributes useful for cognitive diagnostic assessment.", "labels": [], "entities": [{"text": "cognitive diagnostic assessment", "start_pos": 102, "end_pos": 133, "type": "TASK", "confidence": 0.7944452166557312}]}, {"text": "For example, the Qmatrix associates test items with skills of students taking the test.", "labels": [], "entities": []}, {"text": "Data-driven methods were introduced to automatically identify latent knowledge components (KCs) and map them to test items, based on observed student performance, cf. and Section 2 below.", "labels": [], "entities": []}, {"text": "A crucial issue with these automatic methods is that latent skills optimize some well defined objective function, but maybe hard to describe and interpret.", "labels": [], "entities": []}, {"text": "Even for manually-designed Q-matrices, knowledge components may not be described in detail by the designer.", "labels": [], "entities": []}, {"text": "In that situation, a datagenerated description can provide useful information.", "labels": [], "entities": []}, {"text": "In this short paper, we show how to extract keywords relevant to each KC, from the textual content corresponding to each item.", "labels": [], "entities": []}, {"text": "We build a simple probabilistic model, with which we score possible keywords.", "labels": [], "entities": []}, {"text": "This proves surprisingly effective on a small dataset obtained from the PSLC datashop.", "labels": [], "entities": [{"text": "PSLC datashop", "start_pos": 72, "end_pos": 85, "type": "DATASET", "confidence": 0.8672959208488464}]}, {"text": "After a quick overview of the automatic extraction of latent attributes in Section 2, we describe our keyword extraction procedure in Section 3.", "labels": [], "entities": [{"text": "keyword extraction", "start_pos": 102, "end_pos": 120, "type": "TASK", "confidence": 0.769537627696991}]}, {"text": "The data is introduced in Section 4, and we present our experimental results and analysis in Section 5.", "labels": [], "entities": []}], "datasetContent": [{"text": "From the preprocessed data, we estimate all KC profiles using Eq.", "labels": [], "entities": []}, {"text": "(1), on different data sources: 1.", "labels": [], "entities": []}, {"text": "Only the body of the question (\"body\"), 2.", "labels": [], "entities": []}, {"text": "Body plus hints (\"b+h\"), 3.", "labels": [], "entities": []}, {"text": "Body, hints and responses (\"all\").", "labels": [], "entities": []}, {"text": "For each KC, we extract the top 10 keywords according to s c (w) (Eq. 3).", "labels": [], "entities": []}, {"text": "shows the top keywords extracted from the body text fora sample of knowledge components.", "labels": [], "entities": []}, {"text": "Even for knowledge components with very few items, the extracted keywords are clearly related to the topic suggested by the label.", "labels": [], "entities": []}, {"text": "Although the label itself is not available when estimating the model, words from the label often appear in the keywords (sometimes with slight morphological differences).", "labels": [], "entities": []}, {"text": "Our first metric evaluates the quality of the extraction by the number of times words from the (unknown) label appear in the keywords.", "labels": [], "entities": []}, {"text": "For the model in, this occurs in 44 KCs out of the 108 in the model (41%).", "labels": [], "entities": []}, {"text": "These KCs are associated with 280 items (34%), suggesting that labels are more commonly found within keywords for small KCs.", "labels": [], "entities": []}, {"text": "This may also be due to vague labels for large KCs (e.g. identify, sr in), although the overall keyword description is quite clear (phishing, email, scam).", "labels": [], "entities": []}, {"text": "We now focus on two ways to evaluate keyword quality: diversity (number of distinct keywords) and specificity (how many KC a keyword describes).", "labels": [], "entities": []}, {"text": "Desirable keywords are specific to one or few KCs.", "labels": [], "entities": []}, {"text": "A side effect is that there should be many different keywords.", "labels": [], "entities": []}, {"text": "We therefore compute 1) how many distinct keywords there are overall, 2) how many keywords appear in a single KC, and 3) the maximum number of KCs sharing the same keyword.", "labels": [], "entities": []}, {"text": "As a baseline, we compare against the simple strategy that consists in simply picking as keywords the tokens with maximum probability in the KC profile (1).", "labels": [], "entities": []}, {"text": "This baseline is common practice when describing probabilistic topic models (.", "labels": [], "entities": []}, {"text": "compares KL score (\"KL-*\" rows) and maximum probability baseline (\"MP-*\" rows) for the two KC models.", "labels": [], "entities": [{"text": "KL score", "start_pos": 9, "end_pos": 17, "type": "METRIC", "confidence": 0.9407124817371368}, {"text": "maximum probability baseline (\"MP-*\" rows)", "start_pos": 36, "end_pos": 78, "type": "METRIC", "confidence": 0.8451099246740341}]}, {"text": "The total number of keywords is fairly stable as we extract up to 10 keywords per KC in all cases (some KCs have a single item and not enough text).", "labels": [], "entities": []}, {"text": "The KL rows clearly show that our KL-based method generates many more different keywords than MP, implying that MP extracts the same keywords for many more KCs.", "labels": [], "entities": []}, {"text": "\u2022 With KL, we have up to 727 distinct keywords (out of 995) for noSA and 372 out of 440 for C75, i.e. an average 1.18 to 1.37 (median 1) KC per keyword.", "labels": [], "entities": []}, {"text": "With MP the keywords describe on average 3.1 KC of noSA, and 2.97 of C75.", "labels": [], "entities": [{"text": "noSA", "start_pos": 51, "end_pos": 55, "type": "METRIC", "confidence": 0.9077214598655701}]}, {"text": "\u2022 With KL, as many as 577 (i.e. more than half) keywords appear in a single noSA KC.", "labels": [], "entities": []}, {"text": "By contrast, only as few as 221 MP keywords have a unique KC.", "labels": [], "entities": []}, {"text": "For C75, the numbers are 316 (72%) vs, 88 to 131.", "labels": [], "entities": [{"text": "C75", "start_pos": 4, "end_pos": 7, "type": "DATASET", "confidence": 0.8526562452316284}, {"text": "316", "start_pos": 25, "end_pos": 28, "type": "METRIC", "confidence": 0.9654351472854614}]}, {"text": "\u2022 With KL, no keyword is used to describe more than 9 to 19 noSA KCs and 6 to 12 C75 KCs.", "labels": [], "entities": [{"text": "noSA", "start_pos": 60, "end_pos": 64, "type": "DATASET", "confidence": 0.616023063659668}]}, {"text": "With MP, some keywords appear in as many as 87 noSA KCs and all 44 C75 KCs.", "labels": [], "entities": [{"text": "noSA KCs", "start_pos": 47, "end_pos": 55, "type": "DATASET", "confidence": 0.7224697470664978}]}, {"text": "This shows that they are much less specific at describing the content of a KC.", "labels": [], "entities": []}, {"text": "These results all point to the fact that the KL-based method provides better diversity as well as specificity in naming the different KCs.", "labels": [], "entities": []}, {"text": "Source of textual content: Somewhat surprisingly, using less textual content, i.e. body only, consistently produces better diversity (more distinct keywords) and better specificity (fewer KC per keyword).", "labels": [], "entities": []}, {"text": "The hint text yields little change and the response text seriously degrades both diversity and specificity, despite nearly doubling the amount of textual data available.", "labels": [], "entities": []}, {"text": "This is because responses are very similar across items.", "labels": [], "entities": []}, {"text": "They add textual information but tend to smooth out profiles.", "labels": [], "entities": []}, {"text": "This is shown in the comparison between \"KL-body\" and \"MP-all\" in.", "labels": [], "entities": []}, {"text": "The latter extracts \"correct\" and \"incorrect\" as keywords for most KCs in both models, because these words frequently appear in the response feedback.", "labels": [], "entities": []}, {"text": "KL-based naming discards these words because they are almost equally frequent in all KCs and are not specific enough.", "labels": [], "entities": [{"text": "KL-based naming discards", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.7585844993591309}]}, {"text": "extracted for all 44 KCs.", "labels": [], "entities": []}, {"text": "Results on noSA are similar and not included for brievity.", "labels": [], "entities": [{"text": "noSA", "start_pos": 11, "end_pos": 15, "type": "TASK", "confidence": 0.5854364633560181}]}], "tableCaptions": [{"text": " Table 1: Dataset statistics, (# tokens).", "labels": [], "entities": []}, {"text": " Table 3: Statistics on various keyword extraction meth- ods. KL (Kullback-Leibler score) and MP (maximum  probability) are tested on body only, body+hints (b+h)  or all text. We report the total number of keywords ex- tracted (Total), the number of different keywords (diff.),  keywords with unique KC (unique) and maximum num- ber of KC per keyword (max). \"+sw\" indicates stopwords  are included (not filtered).", "labels": [], "entities": [{"text": "KL", "start_pos": 62, "end_pos": 64, "type": "METRIC", "confidence": 0.8862112164497375}, {"text": "MP (maximum  probability)", "start_pos": 94, "end_pos": 119, "type": "METRIC", "confidence": 0.8829501748085022}]}, {"text": " Table 4. The latter extracts \"correct\" and \"incor- rect\" as keywords for most KCs in both models, be- cause these words frequently appear in the response  feedback", "labels": [], "entities": [{"text": "correct", "start_pos": 31, "end_pos": 38, "type": "METRIC", "confidence": 0.9687268733978271}]}]}