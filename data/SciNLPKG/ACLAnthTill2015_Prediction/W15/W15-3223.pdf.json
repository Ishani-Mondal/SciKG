{"title": [{"text": "Answer Selection in Arabic Community Question Answering: A Feature-Rich Approach", "labels": [], "entities": [{"text": "Answer Selection in Arabic Community Question Answering", "start_pos": 0, "end_pos": 55, "type": "TASK", "confidence": 0.7512721930231366}]}], "abstractContent": [{"text": "The task of answer selection in community question answering consists of identifying pertinent answers from a pool of user-generated comments related to a question.", "labels": [], "entities": [{"text": "answer selection in community question answering", "start_pos": 12, "end_pos": 60, "type": "TASK", "confidence": 0.6700561741987864}]}, {"text": "The recent SemEval-2015 introduced a shared task on community question answering, providing a corpus and evaluation scheme.", "labels": [], "entities": [{"text": "community question answering", "start_pos": 52, "end_pos": 80, "type": "TASK", "confidence": 0.6245851218700409}]}, {"text": "In this paper we address the problem of answer selection in Arabic.", "labels": [], "entities": [{"text": "answer selection", "start_pos": 40, "end_pos": 56, "type": "TASK", "confidence": 0.9558050334453583}]}, {"text": "Our proposed model includes a manifold of features including lexical and semantic similarities, vector representations , and rankings.", "labels": [], "entities": []}, {"text": "We investigate the contribution of each set of features in a supervised setting.", "labels": [], "entities": []}, {"text": "We show that employing a feature combination by means of a linear support vector machine achieves a better performance than that of the competition winner (F 1 of 79.25 compared to 78.55).", "labels": [], "entities": [{"text": "F 1", "start_pos": 156, "end_pos": 159, "type": "METRIC", "confidence": 0.9960545599460602}]}], "introductionContent": [{"text": "Community Question Answering (cQA) platforms have become an important resource of punctual information for users on the Web.", "labels": [], "entities": [{"text": "Community Question Answering (cQA)", "start_pos": 0, "end_pos": 34, "type": "TASK", "confidence": 0.7195178965727488}]}, {"text": "A person posts a question on a specific topic and other users post their answers with little, if not null, restrictions.", "labels": [], "entities": []}, {"text": "The liberty to post questions and answers at will is one of the ingredients that make this kind of fora attractive and allows questions to be answered in a very short time.", "labels": [], "entities": []}, {"text": "Nevertheless, this same anarchy could cause a question to receive as many answers as to make manual inspection difficult while a given comment might not even address the question (e.g., because the topic gets diverted, or the user aims to make fun of the topic).", "labels": [], "entities": []}, {"text": "Our task is defined as follows.", "labels": [], "entities": []}, {"text": "Given a question q and its set of derived comments C, identify whether each c \u2208 C represents a DIRECT , RELATED , or IRRELEVANT answer to q.", "labels": [], "entities": [{"text": "RELATED", "start_pos": 104, "end_pos": 111, "type": "METRIC", "confidence": 0.9462317228317261}, {"text": "IRRELEVANT", "start_pos": 117, "end_pos": 127, "type": "METRIC", "confidence": 0.9391514658927917}]}, {"text": "In order to do that, we take advantage of the framework provided by the SemEval-2015 Task 3 on \"Answer Selection in Community Question Answering\"  and focus on the Arabic language.", "labels": [], "entities": [{"text": "Answer Selection in Community Question Answering", "start_pos": 96, "end_pos": 144, "type": "TASK", "confidence": 0.8607664406299591}]}, {"text": "Our approach is treating each questioncomment as an instance in a supervised learning scenario.", "labels": [], "entities": []}, {"text": "We build a support vector machine (SVM) classifier that is using different kinds of features, including vector representations, similarity measures, and rankings.", "labels": [], "entities": []}, {"text": "Our extensive feature set allows us to achieve better results than those of the winner of the competition: 79.25 F 1 compared to 78.55, obtained by.", "labels": [], "entities": [{"text": "79.25 F 1", "start_pos": 107, "end_pos": 116, "type": "METRIC", "confidence": 0.7809241612752279}]}, {"text": "The rest of the paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 describes the experimental framework -composed of the Fatwa corpus and the evaluation metrics-and overviews the different models proposed at competition time.", "labels": [], "entities": [{"text": "Fatwa corpus", "start_pos": 64, "end_pos": 76, "type": "DATASET", "confidence": 0.9783499538898468}]}, {"text": "Section 3 describes our model.", "labels": [], "entities": []}, {"text": "Experiments and results are discussed in Section 4.", "labels": [], "entities": []}, {"text": "Related work is discussed in Section 5.", "labels": [], "entities": []}, {"text": "We summarize our contributions in Section 6, and include an error analysis in Appendix A.", "labels": [], "entities": [{"text": "error analysis", "start_pos": 60, "end_pos": 74, "type": "METRIC", "confidence": 0.9542875289916992}, {"text": "Appendix", "start_pos": 78, "end_pos": 86, "type": "METRIC", "confidence": 0.49803945422172546}]}], "datasetContent": [{"text": "The aim of our experiments is to explore each set of features both isolated and combined.", "labels": [], "entities": []}, {"text": "Thus we isolate rule-based features from similarity features and from vector-based features.", "labels": [], "entities": []}, {"text": "In our experiments we combined vector-based and statistical ranking features, following our previous work.", "labels": [], "entities": []}, {"text": "Note that the rulebased ranking system (Section 3.4) does not produce any features.", "labels": [], "entities": []}, {"text": "Instead, we binarize its output to produce the features to be combined with the rest.", "labels": [], "entities": []}, {"text": "We train and tune all the models on the training and development sets and perform a final evaluation on the test set.", "labels": [], "entities": []}, {"text": "This experimental design mimics the competition setting, making the figures directly comparable.", "labels": [], "entities": []}, {"text": "It is worth noting that the performance of the different feature sets is already competitive with respect to the top models at competition time.", "labels": [], "entities": []}, {"text": "On the development set, we found it useful to run an SVM ranker on the entire set of features and convert its ranking to predictions as follows: the top scoring comment is DIRECT , next best is RELATED , and all others are IRRELEVANT . This heuristic (marked with \"#\" in the table) produced the best results on the development set, but was not as successful on the test set.", "labels": [], "entities": [{"text": "DIRECT", "start_pos": 172, "end_pos": 178, "type": "METRIC", "confidence": 0.993026614189148}, {"text": "RELATED", "start_pos": 194, "end_pos": 201, "type": "METRIC", "confidence": 0.9970530271530151}, {"text": "IRRELEVANT", "start_pos": 223, "end_pos": 233, "type": "METRIC", "confidence": 0.9923539161682129}]}, {"text": "Instead, we observe that the best performing system is obtained by combining vectors and rule-based ranking, achieving 79.25 F 1 and outperforming the best result from the SemEval 2015 task.", "labels": [], "entities": [{"text": "79.25 F 1", "start_pos": 119, "end_pos": 128, "type": "METRIC", "confidence": 0.8177661498387655}, {"text": "SemEval 2015 task", "start_pos": 172, "end_pos": 189, "type": "TASK", "confidence": 0.6965444087982178}]}], "tableCaptions": [{"text": " Table 1: Statistics of the Fatwa corpus", "labels": [], "entities": [{"text": "Fatwa", "start_pos": 28, "end_pos": 33, "type": "DATASET", "confidence": 0.49004098773002625}]}, {"text": " Table 3: Results on the development and test sets. Top-performing (primary) submissions at competition  time are included for comparison.", "labels": [], "entities": []}]}