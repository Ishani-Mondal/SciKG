{"title": [{"text": "Opportunities and Obligations to Take Turns in Collaborative Multi-Party Human-Robot Interaction", "labels": [], "entities": []}], "abstractContent": [{"text": "In this paper we present a data-driven model for detecting opportunities and obligations fora robot to take turns in multi-party discussions about objects.", "labels": [], "entities": []}, {"text": "The data used for the model was collected in a public setting, where the robot head Furhat played a collabo-rative card sorting game together with two users.", "labels": [], "entities": []}, {"text": "The model makes a combined detection of addressee and turn-yielding cues, using multi-modal data from voice activity, syntax, prosody, head pose, movement of cards, and dialogue context.", "labels": [], "entities": []}, {"text": "The best result fora binary decision is achieved when several modalities are combined, giving a weighted F 1 score of 0.876 on data from a previously unseen interaction, using only automatically extractable features.", "labels": [], "entities": [{"text": "F 1 score", "start_pos": 105, "end_pos": 114, "type": "METRIC", "confidence": 0.9873530069986979}]}], "introductionContent": [{"text": "Robots of the future are envisioned to help people perform tasks, not only as mere tools, but as autonomous agents interacting and solving problems together with humans.", "labels": [], "entities": []}, {"text": "Such interaction will be characterised by two important features that need to betaken into account when modelling the spoken interaction.", "labels": [], "entities": []}, {"text": "Firstly, the robot should be able to solve problems together with several humans (and possibly other robots) at the same time, which means that we need to model multiparty interaction.", "labels": [], "entities": []}, {"text": "Secondly, joint problem solving is in many cases situated, which means that the spoken discourse will involve references to, and manipulation of, objects in the shared physical space.", "labels": [], "entities": [{"text": "joint problem solving", "start_pos": 10, "end_pos": 31, "type": "TASK", "confidence": 0.6437582770983378}]}, {"text": "When speaking about objects, humans typically pay attention to these objects and gaze at them.", "labels": [], "entities": []}, {"text": "Also, placing or moving an object can be regarded as a communicative act in itself).", "labels": [], "entities": []}, {"text": "To solve the task efficiently, interlocutors need to coordinate their attention, resulting in so-called joint attention.", "labels": [], "entities": []}, {"text": "These characteristics of human-robot interaction pose many challenges for spoken dialogue systems.", "labels": [], "entities": []}, {"text": "In this paper, we address the problem of turn-taking, which is a central problem for all spoken dialogue systems, but which is especially challenging when several interlocutors are involved.", "labels": [], "entities": []}, {"text": "In multi-party interaction, the system does not only have to determine when a speaker yields the turn, but also whether it is yielded to the system or to someone else.", "labels": [], "entities": []}, {"text": "This becomes even more problematic when the discussion involves objects in a shared physical space.", "labels": [], "entities": []}, {"text": "For example, an obvious signal that humans use for yielding the turn in a face-to-face setting is to gaze at the next speaker ().", "labels": [], "entities": []}, {"text": "However, in situated interaction, where the gaze is also used to pay attention to the objects which are under discussion, it is not obvious how this shared resource is used.", "labels": [], "entities": []}, {"text": "While modelling all these aspects of the interaction is indeed challenging, the multi-modal nature of human-robot interaction also has the promise of offering redundant information that the system can utilize, thereby possibly increasing the robustness of the system (.", "labels": [], "entities": []}, {"text": "The aim of this study is to develop a datadriven model that can be used by the system to decide when to take the turn and not.", "labels": [], "entities": []}, {"text": "While there are many previous studies that have built such models based on human-human () or human-machine interaction), we are not aware of any previous studies that investigate multi-party human-robot discussions about objects.", "labels": [], "entities": []}, {"text": "The system that we build the model for, and use data from, is a collaborative game that was exhibited at the Swedish National Museum of Science and Technology in.", "labels": [], "entities": [{"text": "Swedish National Museum of Science and Technology", "start_pos": 109, "end_pos": 158, "type": "DATASET", "confidence": 0.810039758682251}]}, {"text": "As can be seen in, two visitors at a time could play a collaborative game together with the robot head Furhat).", "labels": [], "entities": [{"text": "Furhat", "start_pos": 103, "end_pos": 109, "type": "DATASET", "confidence": 0.7444287538528442}]}, {"text": "On the touch table between the players, a set of cards are shown.", "labels": [], "entities": []}, {"text": "The two visitors and Furhat are given the task of sorting the cards according to some criterion.", "labels": [], "entities": [{"text": "Furhat", "start_pos": 21, "end_pos": 27, "type": "METRIC", "confidence": 0.797944188117981}]}, {"text": "For example, the task could be to sorta set of inventions in the order they were invented, or a set of animals based on how fast they can run.", "labels": [], "entities": [{"text": "sorta set of inventions", "start_pos": 34, "end_pos": 57, "type": "TASK", "confidence": 0.8537739813327789}]}, {"text": "This is a collaborative game, which means that the visitors have to discuss the solution together with Furhat.", "labels": [], "entities": [{"text": "Furhat", "start_pos": 103, "end_pos": 109, "type": "DATASET", "confidence": 0.8608176112174988}]}, {"text": "As we have discussed in previous work, we think that the symmetry of the interaction is especially interesting from a turntaking perspective.", "labels": [], "entities": []}, {"text": "The setting also provides a wide range of multi-modal features that can be exploited: voice activity, syntax, prosody, head pose, movement of cards, and dialogue context 1 . The paper is organized as follows: In Section 2 we present and discuss related work, in Section 3 we describe the system and data annotation in more detail, in Section 4 we present the performance of the different machine learning algorithms and features sets, and in Section 5 we end with conclusions and a discussion of the results.", "labels": [], "entities": []}], "datasetContent": [{"text": "We finally evaluated the best performing models built from the initial 9 dialogues on a separate test set of 43 decision points from a tenth dialogue, annotated both by the original annotator and a second annotator.", "labels": [], "entities": []}, {"text": "For the binary decision, we selected the MLP classifier with features from head pose, POS, card movements, prosody and the system's dialogue act.", "labels": [], "entities": []}, {"text": "When evaluated on the test set annotated by the original annotator and the new annotator, the weighted F 1 score was 0.876 and 0.814 for 29 and 32 instances respectively.", "labels": [], "entities": [{"text": "F 1 score", "start_pos": 103, "end_pos": 112, "type": "METRIC", "confidence": 0.9840763807296753}]}, {"text": "These are promising results, given the classifier's performance of 0.851 in the training set crossvalidation and that the test set was from a previously unseen interaction.", "labels": [], "entities": []}, {"text": "The regression model was evaluated using the Gaussian Processes classifier with features from head pose, VAD and card movement.", "labels": [], "entities": [{"text": "VAD", "start_pos": 105, "end_pos": 108, "type": "METRIC", "confidence": 0.7758799195289612}]}, {"text": "The correlation coefficients for the original annotator and the new annotator were 0.5959 and 0.5647 over 43 instances each, compared to 0.677 in the training set cross-validation.", "labels": [], "entities": [{"text": "correlation", "start_pos": 4, "end_pos": 15, "type": "METRIC", "confidence": 0.9581746459007263}]}, {"text": "The lower values could be due to a different distribution of annotations in the test set and the relatively small data set.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Weighted F 1 score of the feature categories  used in isolation. Results significantly better than  baseline are marked with *.", "labels": [], "entities": [{"text": "F 1 score", "start_pos": 19, "end_pos": 28, "type": "METRIC", "confidence": 0.9378297726313273}]}, {"text": " Table 2: Weighted F 1 score for different feature set  combinations using RIPPER (JRIP), Support Vector  Machine (SVM) and Multilayer Perceptron (MLP)  classifiers", "labels": [], "entities": [{"text": "Weighted F 1 score", "start_pos": 10, "end_pos": 28, "type": "METRIC", "confidence": 0.8522216528654099}]}, {"text": " Table 3: Correlation coefficient for different feature  set combinations using Gaussian Processes (GP) and  Linear Regression (LR) classifiers", "labels": [], "entities": []}]}