{"title": [{"text": "An Exploration of Discourse-Based Sentence Spaces for Compositional Distributional Semantics", "labels": [], "entities": []}], "abstractContent": [{"text": "This paper investigates whether the wider context in which a sentence is located can contribute to a distributional representation of sentence meaning.", "labels": [], "entities": []}, {"text": "We compare a vector space for sentences in which the features are words occurring within the sentence, with two new vector spaces that only make use of surrounding context.", "labels": [], "entities": []}, {"text": "Experiments on simple subject-verb-object similarity tasks show that all sentence spaces produce results that are comparable with previous work.", "labels": [], "entities": []}, {"text": "However, qualitative analysis and user experiments indicate that extra-sentential contexts capture more diverse, yet topically coherent information.", "labels": [], "entities": []}], "introductionContent": [{"text": "Distributional word representations have proven useful fora wide variety of tasks, including lexical similarity, sentiment analysis, and machine translation.", "labels": [], "entities": [{"text": "Distributional word representations", "start_pos": 0, "end_pos": 35, "type": "TASK", "confidence": 0.6727681557337443}, {"text": "sentiment analysis", "start_pos": 113, "end_pos": 131, "type": "TASK", "confidence": 0.9625240564346313}, {"text": "machine translation", "start_pos": 137, "end_pos": 156, "type": "TASK", "confidence": 0.8246607184410095}]}, {"text": "By far the most typical method of building distributional word vectors is based on co-occurrences in a small context window around the word.", "labels": [], "entities": []}, {"text": "In contrast, there has been little investigation of different distributional representations for sentences, though the current hypothesis is that the wider discourse in which the sentence is situated may provide relevant information (.", "labels": [], "entities": []}, {"text": "If word representations could be composed into sentence vectors that reflect typical discourse contexts, this might be of great use in sentencelevel tasks such as sentence similarity, automatic summarisation, and textual entailment.", "labels": [], "entities": [{"text": "sentence similarity", "start_pos": 163, "end_pos": 182, "type": "TASK", "confidence": 0.7260836511850357}, {"text": "summarisation", "start_pos": 194, "end_pos": 207, "type": "TASK", "confidence": 0.7980749607086182}, {"text": "textual entailment", "start_pos": 213, "end_pos": 231, "type": "TASK", "confidence": 0.6709942370653152}]}, {"text": "Previous work in compositional distributional semantics largely defines the sentence vector space to be the same as the noun space (, and produces sentence vectors in that space by a sequence of operations on word representations.", "labels": [], "entities": [{"text": "compositional distributional semantics", "start_pos": 17, "end_pos": 55, "type": "TASK", "confidence": 0.706396738688151}]}, {"text": "However, embedding a sentence into a vector space whose dimensions are based on lexical semantics may fail to capture important aspects of sentential meaning.", "labels": [], "entities": []}, {"text": "We believe there are two reasons behind the rather surprising lack of attention to sentence spaces.", "labels": [], "entities": []}, {"text": "The first is doubt as to whether the distributional hypothesis applies to sentences, i.e. whether sentence meaning is contextual.", "labels": [], "entities": []}, {"text": "The second is a question of data sparsity in obtaining contextual sentence representations.", "labels": [], "entities": []}, {"text": "In this paper we explore the idea that contextual sentence representations are viable, and that the surrounding discourse, in the form of adjacent sentences, provides useful information for modelling sentence meaning.", "labels": [], "entities": []}, {"text": "We introduce two sentence spaces based on extra-sentential context, one consisting of a variety of context words and the other only of the surrounding verbs, and compare them with an intra-sentential contextual sentence space similar to that proposed in . We situate our work within the Categorial framework () where nouns and sentences are considered atomic types, represented as vectors, and other words as functions, represented as tensors.", "labels": [], "entities": []}, {"text": "This framework provides a natural setting in which the sentence space can differ from the spaces of sentence constituents, since argument-taking words such as verbs are maps from argument space into sentence space.", "labels": [], "entities": []}, {"text": "Following and we focus on simplified sentences consisting of a subject, transitive verb, and object (SVO).", "labels": [], "entities": []}, {"text": "We train transitive verb tensors using a single-step multilinear regression algorithm.", "labels": [], "entities": []}, {"text": "We evaluate our composed representations on two standard SVO sentence similarity tasks.", "labels": [], "entities": [{"text": "SVO sentence similarity", "start_pos": 57, "end_pos": 80, "type": "TASK", "confidence": 0.6587726374467214}]}, {"text": "The results show that the discourse-based sentence spaces perform competitively, both with the intra-1 sentential contextual space and with previous work on SVO composition, although not beating the state of the art on these tasks.", "labels": [], "entities": [{"text": "SVO composition", "start_pos": 157, "end_pos": 172, "type": "TASK", "confidence": 0.8344870507717133}]}, {"text": "We then provide a qualitative analysis of the topics resulting from Singular Value Decomposition in each sentence space, showing that both intra-and extrasentential spaces contain highly coherent topics, but that the extra-sentential spaces are able to group together SVO triples with greater lexical diversity.", "labels": [], "entities": []}, {"text": "We evaluate topic coherence with a novel SVO triple intrusion task.", "labels": [], "entities": []}], "datasetContent": [{"text": "We perform two experiments using composed sentence vectors.", "labels": [], "entities": []}, {"text": "The first involves disambiguation of a polysemous verb in the context of its subject and object, and the second involves measurement of sentence similarity, without disambiguation.", "labels": [], "entities": []}, {"text": "We make use of two existing SVO datasets.", "labels": [], "entities": [{"text": "SVO datasets", "start_pos": 28, "end_pos": 40, "type": "DATASET", "confidence": 0.9491196274757385}]}], "tableCaptions": [{"text": " Table 1: Spearman-\u03c1 results for the GS11 dataset (left) and KS14 dataset (right).", "labels": [], "entities": [{"text": "GS11 dataset", "start_pos": 37, "end_pos": 49, "type": "DATASET", "confidence": 0.9899566173553467}, {"text": "KS14 dataset", "start_pos": 61, "end_pos": 73, "type": "DATASET", "confidence": 0.9433943331241608}]}, {"text": " Table 3: Triple intrusion task: model accuracy  average over two (amalgamated) annotators and  Fleiss' \u03ba.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 39, "end_pos": 47, "type": "METRIC", "confidence": 0.9633011817932129}]}]}