{"title": [], "abstractContent": [{"text": "This paper introduces NEMWEL, a system that performs Never-Ending Mul-tiWord Expressions Learning.", "labels": [], "entities": [{"text": "Never-Ending Mul-tiWord Expressions Learning", "start_pos": 53, "end_pos": 97, "type": "TASK", "confidence": 0.5248743966221809}]}, {"text": "Instead of using a static corpus and classifier, NEMWEL applies supervised learning on automatically crawled news texts.", "labels": [], "entities": []}, {"text": "Moreover , it uses its own results to periodically retrain the classifier, bootstrapping on its own results.", "labels": [], "entities": []}, {"text": "In addition to a detailed description of the system's architecture and its modules, we report the results of a manual evaluation.", "labels": [], "entities": []}, {"text": "It shows that NEMWEL is capable of learning new expressions overtime with improved precision.", "labels": [], "entities": [{"text": "precision", "start_pos": 83, "end_pos": 92, "type": "METRIC", "confidence": 0.9968229532241821}]}], "introductionContent": [{"text": "Multiword expressions (MWEs) are combinations of two or more lexemes which present some lexical, syntactic, semantic, pragmatic or statistical idiosyncrasies with respect to regular combinations (.", "labels": [], "entities": [{"text": "Multiword expressions (MWEs)", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.6840166926383973}]}, {"text": "Examples include idioms (saw logs as to snore), phrasal verbs (pull over, give up), noun compounds (machine learning, support vector machine) and complex function words (as well as, with respect to).", "labels": [], "entities": []}, {"text": "In human languages, such constructions are very frequent, as native speakers rarely realize how often they employ them (; Jackendoff, 1997b).", "labels": [], "entities": []}, {"text": "However, they are not frequent in NLP resources such as lexicons and grammars, and this represents a bottleneck for building robust and accurate NLP applications.", "labels": [], "entities": []}, {"text": "Since the construction of such resources is onerous and demands highly qualified linguistic expertise, automatic MWE lexicon extraction is an attractive alternative which has been one of the most active topics in the MWE research community.", "labels": [], "entities": [{"text": "MWE lexicon extraction", "start_pos": 113, "end_pos": 135, "type": "TASK", "confidence": 0.9189973672231039}, {"text": "MWE research", "start_pos": 217, "end_pos": 229, "type": "TASK", "confidence": 0.9108743369579315}]}, {"text": "Proposed methods are often based on supervised and unsupervised learning of MWE lists from textual corpora.", "labels": [], "entities": [{"text": "MWE lists from textual corpora", "start_pos": 76, "end_pos": 106, "type": "TASK", "confidence": 0.8327846884727478}]}, {"text": "In spite of the availability of very large corpora like the Gigaword or WaC (), these methods are still limited by the coverage of the texts in the source corpus.", "labels": [], "entities": []}, {"text": "This paper presents NEMWEL, a machine learning system able to learn MWEs following the never-ending approach (.", "labels": [], "entities": []}, {"text": "NEMWEL automatically extracts MWE candidates from a corpus periodically crawled from a Brazilian online news portal.", "labels": [], "entities": [{"text": "MWE candidates", "start_pos": 30, "end_pos": 44, "type": "TASK", "confidence": 0.8550680875778198}]}, {"text": "Then, based on supervised training, NEMWEL classifies the candidates and promotes some of them to the status of \"true MWEs\", which are used to retrain the classifier.", "labels": [], "entities": []}, {"text": "This process is repeated endlessly, taking into consideration the true MWEs learned in previous steps.", "labels": [], "entities": []}, {"text": "By doing so, NEMWEL tries to resemble the way human beings learn.", "labels": [], "entities": [{"text": "NEMWEL", "start_pos": 13, "end_pos": 19, "type": "TASK", "confidence": 0.5891678929328918}]}, {"text": "We have developed a prototype that implements this idea.", "labels": [], "entities": []}, {"text": "To the best of our knowledge, this is the first attempt to build MWE lexicons using a never-ending learning approach.", "labels": [], "entities": [{"text": "MWE lexicons", "start_pos": 65, "end_pos": 77, "type": "TASK", "confidence": 0.8419948518276215}]}, {"text": "We have manually evaluated the extracted MWEs and we show that the precision of the learner seems to increase with time.", "labels": [], "entities": [{"text": "precision", "start_pos": 67, "end_pos": 76, "type": "METRIC", "confidence": 0.9995494484901428}]}, {"text": "The remainder of this paper is structured as follows: we discuss related work on MWE extraction (Section 2) and never-ending learning methods (Section 3).", "labels": [], "entities": [{"text": "MWE extraction", "start_pos": 81, "end_pos": 95, "type": "TASK", "confidence": 0.9748767912387848}]}, {"text": "Then, we present the architecture and detail the modules in NEMWEL (Section 4).", "labels": [], "entities": [{"text": "NEMWEL", "start_pos": 60, "end_pos": 66, "type": "DATASET", "confidence": 0.9318563342094421}]}, {"text": "Finaly, we present the results of automatic and manual evaluation in Brazilian Portuguese (Section 5) and ideas for future work (Section 6).", "labels": [], "entities": []}], "datasetContent": [{"text": "An initial training corpus was generated from texts of the G1 news portal.", "labels": [], "entities": [{"text": "G1 news portal", "start_pos": 59, "end_pos": 73, "type": "DATASET", "confidence": 0.9527193307876587}]}, {"text": "From this corpus, NEMWEL extracted 1,100 candidate MWEs which were manually annotated by two native speakers of Brazilian Portuguese: 600 candidates for each one with an intersection of 100 candidates.", "labels": [], "entities": []}, {"text": "The annotation interface showed the candidate and the sentences from the G1 corpus from which the candidate was extracted (see).", "labels": [], "entities": [{"text": "G1 corpus", "start_pos": 73, "end_pos": 82, "type": "DATASET", "confidence": 0.8896883130073547}]}, {"text": "The annotators had to perform a binary choice as to whether the candidate was a true MWE (\"Sim\") or not (\"N\u00e3o\").", "labels": [], "entities": []}, {"text": "Each annotator cross-checked the other one's items.", "labels": [], "entities": []}, {"text": "This last cross-checking step was crucial because, even though some guidelines were provided, some cases were hard to decide and required discussion.", "labels": [], "entities": []}, {"text": "From this first annotation, 19% of the candidates were evaluated as true MWEs.", "labels": [], "entities": []}, {"text": "The kappa agreement) was 0.85, which indicates a very good agreement.", "labels": [], "entities": [{"text": "kappa agreement)", "start_pos": 4, "end_pos": 20, "type": "METRIC", "confidence": 0.9396909475326538}]}, {"text": "The annotated set was used to train our Promoter-0 as explained in section 4.4.", "labels": [], "entities": []}, {"text": "NEMWEL, then, run for 15 iterations and, at each 5 iterations (a generation), anew Promoter was trained using the beliefs and false MWEs classified in the previous iterations.", "labels": [], "entities": [{"text": "NEMWEL", "start_pos": 0, "end_pos": 6, "type": "DATASET", "confidence": 0.951231837272644}]}, {"text": "candidates was manually evaluated by the two native speakers, but with no overlap between the annotators.", "labels": [], "entities": []}, {"text": "To allow the analysis of the learning curve overtime, this sample contained 400 candidates extracted in each generation, from which each annotator judged half, that is, 600 candidates per annotator, 200 for each generation.", "labels": [], "entities": []}, {"text": "From the 1,200 candidates, 15.6% were classified as true MWE.", "labels": [], "entities": []}, {"text": "The results are shown in in terms of precision, recall, F-measure and accuracy calculated regarding true positives (TP), false positives (FP), true negatives (TN) and false negatives (FN): As we can notice from, the precision rises 10 percentage points from the first to the last iteration, indicating that NEMWEL is capable of improving its learning performance, as expected fora never-ending learning system.", "labels": [], "entities": [{"text": "precision", "start_pos": 37, "end_pos": 46, "type": "METRIC", "confidence": 0.9994955062866211}, {"text": "recall", "start_pos": 48, "end_pos": 54, "type": "METRIC", "confidence": 0.9993769526481628}, {"text": "F-measure", "start_pos": 56, "end_pos": 65, "type": "METRIC", "confidence": 0.9990757703781128}, {"text": "accuracy", "start_pos": 70, "end_pos": 78, "type": "METRIC", "confidence": 0.999491810798645}, {"text": "true positives (TP), false positives (FP), true negatives (TN) and false negatives (FN)", "start_pos": 100, "end_pos": 187, "type": "METRIC", "confidence": 0.6917804013127866}, {"text": "precision", "start_pos": 216, "end_pos": 225, "type": "METRIC", "confidence": 0.9975417852401733}, {"text": "NEMWEL", "start_pos": 307, "end_pos": 313, "type": "DATASET", "confidence": 0.7800788879394531}]}, {"text": "The decay in recall from 65.5% to 52.3% from the second to the third generation seems to be related to overfitting.", "labels": [], "entities": [{"text": "recall", "start_pos": 13, "end_pos": 19, "type": "METRIC", "confidence": 0.9988917708396912}]}, {"text": "Another possible explanation for this decay is that only the candidate MWEs annotated as true by both annotators were taking into account.", "labels": [], "entities": []}, {"text": "Furthermore, since the dataset is unbalanced, the classifier may tend to classify new candidates always as non MWEs.", "labels": [], "entities": []}, {"text": "New experiments will be carried out to investigate this decay.", "labels": [], "entities": []}, {"text": "shows some examples of MWE candidates extracted by NEMWEL.", "labels": [], "entities": [{"text": "MWE", "start_pos": 23, "end_pos": 26, "type": "TASK", "confidence": 0.9466190934181213}, {"text": "NEMWEL", "start_pos": 51, "end_pos": 57, "type": "DATASET", "confidence": 0.9539424180984497}]}], "tableCaptions": [{"text": " Table 1: Results of NEMWEL's evaluation after 15  iterations and 3 generations of new Promoters.", "labels": [], "entities": [{"text": "NEMWEL", "start_pos": 21, "end_pos": 27, "type": "TASK", "confidence": 0.6113762855529785}]}]}