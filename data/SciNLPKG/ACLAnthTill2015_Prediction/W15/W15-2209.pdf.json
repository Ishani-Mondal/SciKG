{"title": [{"text": "MSTParser Model Interpolation for Multi-source Delexicalized Transfer", "labels": [], "entities": [{"text": "MSTParser Model Interpolation", "start_pos": 0, "end_pos": 29, "type": "TASK", "confidence": 0.6555062532424927}, {"text": "Multi-source Delexicalized Transfer", "start_pos": 34, "end_pos": 69, "type": "TASK", "confidence": 0.6139036218325297}]}], "abstractContent": [{"text": "We introduce interpolation of trained MSTParser models as a resource combination method for multi-source delexical-ized parser transfer.", "labels": [], "entities": [{"text": "multi-source delexical-ized parser transfer", "start_pos": 92, "end_pos": 135, "type": "TASK", "confidence": 0.5766792744398117}]}, {"text": "We present both an unweighted method, as well as a variant in which each source model is weighted by the similarity of the source language to the target language.", "labels": [], "entities": []}, {"text": "Evaluation on the HamleDT treebank collection shows that the weighted model interpolation performs comparably to weighted parse tree combination method, while being computation-ally much less demanding.", "labels": [], "entities": [{"text": "HamleDT treebank collection", "start_pos": 18, "end_pos": 45, "type": "DATASET", "confidence": 0.9842906792958578}]}], "introductionContent": [{"text": "The task of delexicalized dependency parser transfer (or delex transfer for short) is to train a parser on a treebank fora source language (src), using only non-lexical features, most notably partof-speech (POS) tags, and to apply that parser to POS-tagged sentences of a target language (tgt) to obtain dependency parse trees.", "labels": [], "entities": [{"text": "dependency parser transfer (or delex transfer", "start_pos": 26, "end_pos": 71, "type": "TASK", "confidence": 0.702228524855205}]}, {"text": "Delex transfer yields worse results than a supervised lexicalized parser trained on the tgt language treebank.", "labels": [], "entities": []}, {"text": "However, for languages with no treebanks available, it maybe useful to obtain at least a lower-quality parse tree for tasks such as information retrieval.", "labels": [], "entities": [{"text": "information retrieval", "start_pos": 132, "end_pos": 153, "type": "TASK", "confidence": 0.8175168335437775}]}, {"text": "Usually, multiple src treebanks are available, and it is non-trivial to select the best one fora given tgt language.", "labels": [], "entities": []}, {"text": "Therefore, information from some or all src treebanks is usually combined together.", "labels": [], "entities": []}, {"text": "The standard ways are to train a parser on the concatenation of all src treebanks, or to train a separate parser on each src treebank and to combine the parse trees produced by the parsers using a maximum spanning tree algorithm.", "labels": [], "entities": []}, {"text": "The tree combination method typically performs better; it can also be easily extended by weighting the src parser predictions by similarity of the src language to the tgt language, which can further improve its results.", "labels": [], "entities": []}, {"text": "In this work, we present a novel method for src information combination, based on interpolation of trained parser models.", "labels": [], "entities": [{"text": "src information combination", "start_pos": 44, "end_pos": 71, "type": "TASK", "confidence": 0.8628914952278137}]}, {"text": "Our approach was motivated by an intuition that the more fine-grained information provided by the src edge scores could be of benefit, probably serving as src parser confidence.", "labels": [], "entities": [{"text": "src parser", "start_pos": 155, "end_pos": 165, "type": "TASK", "confidence": 0.718904972076416}]}, {"text": "Moreover, model interpolation is significantly less computationally demanding at inference than the parse tree combination method, as instead of running a set of separate src parsers, only one parser is run.", "labels": [], "entities": [{"text": "model interpolation", "start_pos": 10, "end_pos": 29, "type": "TASK", "confidence": 0.7059628665447235}]}], "datasetContent": [{"text": "We carryout all experiments using HamleDT 2.0 (), a collection of 30 treebanks converted into Universal Stanford Dependencies ().", "labels": [], "entities": [{"text": "HamleDT 2.0", "start_pos": 34, "end_pos": 45, "type": "DATASET", "confidence": 0.8686147332191467}]}, {"text": "We use goldstandard UPOS tags in all experiments; while this is not fully realistic in the setting of underresourced languages, there exist high-performance semi-supervised taggers that could be used instead of gold tags (, which we plan to evaluate in future.", "labels": [], "entities": []}, {"text": "We use the treebank training sections for parser training and KL \u22124 cpos 3 computation, and the test sections for evaluation.", "labels": [], "entities": []}, {"text": "We used 12 of the treebanks as a development set to select the model normalization method to avoid overfitting it to the dataset.", "labels": [], "entities": []}, {"text": "contains the results of our model interpolation methods, as well as the baseline methods.", "labels": [], "entities": []}, {"text": "For each tgt language, all remaining 29 src treebanks were used for parser training.", "labels": [], "entities": []}, {"text": "We base our evaluation on comparing absolute differences in UAS on the whole set of 30 languages as targets.", "labels": [], "entities": [{"text": "UAS", "start_pos": 60, "end_pos": 63, "type": "TASK", "confidence": 0.4744386076927185}]}, {"text": "The performance of the weighted model interpolation is comparable to the weighted tree combination -the difference in average UAS of the methods is lower than 0.1%, with model interpolation achieving a higher UAS than the tree combination for 16 of the 30 tgt languages.", "labels": [], "entities": [{"text": "UAS", "start_pos": 126, "end_pos": 129, "type": "METRIC", "confidence": 0.994696855545044}, {"text": "UAS", "start_pos": 209, "end_pos": 212, "type": "METRIC", "confidence": 0.9965682029724121}]}, {"text": "This shows  In the unweighted setting, the situation is quite different, with model interpolation scoring much lower than tree combination (-2.4%), and only slightly higher than treebank concatenation (+0.4%) on average.", "labels": [], "entities": []}, {"text": "This suggests that, contrary to our original intuition, edge scores assigned by the src models are not a good proxy for parser confidence, not even when appropriately normalized.", "labels": [], "entities": []}, {"text": "Furthermore, the weighted methods generally out-perform the unweighted ones (by +4.0% for tree combination and by +6.4% for model interpolation on average), which suggests, among other, that the src-tgt language similarity is much more important than the exact values of src edge scores for resource combination in delex transfer.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: UAS on test tgt treebanks (upper part of  table) and development tgt treebanks (lower part).", "labels": [], "entities": [{"text": "UAS", "start_pos": 10, "end_pos": 13, "type": "DATASET", "confidence": 0.6567606925964355}]}]}