{"title": [{"text": "A Joint Model for Chinese Microblog Sentiment Analysis", "labels": [], "entities": [{"text": "Chinese Microblog Sentiment Analysis", "start_pos": 18, "end_pos": 54, "type": "TASK", "confidence": 0.7220922112464905}]}], "abstractContent": [{"text": "Topic-based sentiment analysis for Chi-nese microblog aims to identify the user attitude on specified topics.", "labels": [], "entities": [{"text": "Topic-based sentiment analysis", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.7694587111473083}]}, {"text": "In this paper, we propose a joint model by incorporating Support Vector Machines (SVM) and deep neural network to improve the performance of sentiment analysis.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 141, "end_pos": 159, "type": "TASK", "confidence": 0.9362310469150543}]}, {"text": "Firstly, a SVM Clas-sifier is constructed using N-gram, N-POS and sentiment lexicons features.", "labels": [], "entities": []}, {"text": "Meanwhile, a convolutional neural network is applied to learn paragraph representation features as the input of another SVM classifier.", "labels": [], "entities": []}, {"text": "The classification results outputted by these two classi-fiers are merged as the final classification results.", "labels": [], "entities": []}, {"text": "The evaluations on the SIGHAN-8 Topic-based Chinese mi-croblog sentiment analysis task show that our proposed approach achieves the second rank on micro average F1 and the fourth rank on macro average F1 among a total of 13 submitted systems .", "labels": [], "entities": [{"text": "SIGHAN-8 Topic-based Chinese mi-croblog sentiment analysis task", "start_pos": 23, "end_pos": 86, "type": "TASK", "confidence": 0.6921486343656268}, {"text": "F1", "start_pos": 161, "end_pos": 163, "type": "METRIC", "confidence": 0.6633190512657166}, {"text": "F1", "start_pos": 201, "end_pos": 203, "type": "METRIC", "confidence": 0.7196304202079773}]}], "introductionContent": [{"text": "With the development of the Internet, microblog has become a popular user-generated content platform where users share the newest events or their personal feelings with each other.", "labels": [], "entities": []}, {"text": "Topic-based microblogs are the most common interactive way for users to share their opinions towards a specified topic.", "labels": [], "entities": []}, {"text": "To identify the opinions of users, sentiment analysis techniques are investigated to classify texts into different categorizations according to their sentiment polarities.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 35, "end_pos": 53, "type": "TASK", "confidence": 0.89813432097435}]}, {"text": "Most existing sentiment classification techniques are based on machine learning algorithms, such as Support Vector Machine, Na\u00efve Bayes and Maximum Entropy.", "labels": [], "entities": [{"text": "sentiment classification", "start_pos": 14, "end_pos": 38, "type": "TASK", "confidence": 0.9409069120883942}]}, {"text": "The machine learning based approach uses feature vectors as the input of classification to predict the classification results.", "labels": [], "entities": []}, {"text": "Thus, feature engineering, a method for extracting effective features from texts, plays an important role.", "labels": [], "entities": [{"text": "feature engineering", "start_pos": 6, "end_pos": 25, "type": "TASK", "confidence": 0.9041920006275177}]}, {"text": "Some commonly used features in sentiment classification are unigram, bigram and sentiment words.", "labels": [], "entities": [{"text": "sentiment classification", "start_pos": 31, "end_pos": 55, "type": "TASK", "confidence": 0.9719111621379852}]}, {"text": "However, these features cannot work well for cross-domain sentiment classification because of the lack of domain knowledge.", "labels": [], "entities": [{"text": "cross-domain sentiment classification", "start_pos": 45, "end_pos": 82, "type": "TASK", "confidence": 0.8332401315371195}]}, {"text": "Danushka used multiple sources to construct a sentiment sensitive thesaurus to overcome the lack of domain knowledge.", "labels": [], "entities": []}, {"text": "New sentiment words expansion is another kind of approach to improve the performance of sentiment analysis.", "labels": [], "entities": [{"text": "New sentiment words expansion", "start_pos": 0, "end_pos": 29, "type": "TASK", "confidence": 0.6061859801411629}, {"text": "sentiment analysis", "start_pos": 88, "end_pos": 106, "type": "TASK", "confidence": 0.91107577085495}]}, {"text": "Strfano constructed SentiWordNet by extending WordNet with sentiment information.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 46, "end_pos": 53, "type": "DATASET", "confidence": 0.9407464861869812}]}, {"text": "It is now widely used in sentiment classification for English.", "labels": [], "entities": [{"text": "sentiment classification", "start_pos": 25, "end_pos": 49, "type": "TASK", "confidence": 0.9748575687408447}]}, {"text": "As for Chinese sentiment analysis, Minlie proposed anew word detection method by mining the frequent sentiment word patterns.", "labels": [], "entities": [{"text": "Chinese sentiment analysis", "start_pos": 7, "end_pos": 33, "type": "TASK", "confidence": 0.7667550047238668}, {"text": "word detection", "start_pos": 56, "end_pos": 70, "type": "TASK", "confidence": 0.7369844317436218}]}, {"text": "This method may discover new sentiment words from a large scale of unlabeled texts.", "labels": [], "entities": []}, {"text": "With the rapid development of pre-trained word embedding and deep neural networks, anew way to represent texts and features is devloped.", "labels": [], "entities": []}, {"text": "showed that word embedding represents words with meaningful syntactic and semantic information effectively.", "labels": [], "entities": []}, {"text": "Recursive neural network proposed by is shown efficient to construct sentence representations based on the word embedding.", "labels": [], "entities": []}, {"text": "Convolutional neural networks (CNN), another deep learn model which achieved success in image recognition field, was applied to nature language processing with word embed-dings.", "labels": [], "entities": [{"text": "image recognition", "start_pos": 88, "end_pos": 105, "type": "TASK", "confidence": 0.7795311510562897}, {"text": "nature language processing", "start_pos": 128, "end_pos": 154, "type": "TASK", "confidence": 0.6243416865666708}]}, {"text": "Yoon used CNN with pretrained word embedding to achieve state-ofthe-art performances on some sentence classification tasks, including sentiment classification.", "labels": [], "entities": [{"text": "sentence classification", "start_pos": 93, "end_pos": 116, "type": "TASK", "confidence": 0.7430980801582336}, {"text": "sentiment classification", "start_pos": 134, "end_pos": 158, "type": "TASK", "confidence": 0.9577584266662598}]}, {"text": "Siwei incorporated global information in a recurrent convolutional neural network.", "labels": [], "entities": []}, {"text": "It obtained further improvements comparing to other deep learning models.", "labels": [], "entities": []}, {"text": "In this paper, we propose a joint model which incorporates traditional machine learning based method (SVM) and deep learning model.", "labels": [], "entities": []}, {"text": "Two different classifiers are developed.", "labels": [], "entities": []}, {"text": "One is a word feature based SVM classifier which uses word unigram, bigram and sentiment words as features.", "labels": [], "entities": [{"text": "SVM classifier", "start_pos": 28, "end_pos": 42, "type": "TASK", "confidence": 0.7394866347312927}]}, {"text": "Another one is a CNN-based SVM classifier which takes paragraph representations features learned by CNN as input features.", "labels": [], "entities": []}, {"text": "The classification results of these two classifiers are integrated to generate the final classification results.", "labels": [], "entities": []}, {"text": "The evaluations on the SIGHAN-8 Topic-based Chinese microblog sentiment analysis task show that our proposed approach achieves the second rank on micro average F1 and the fourth rank on macro average F1 among a total of 13 submitted systems.", "labels": [], "entities": [{"text": "SIGHAN-8 Topic-based Chinese microblog sentiment analysis task", "start_pos": 23, "end_pos": 85, "type": "TASK", "confidence": 0.7169031841414315}, {"text": "F1", "start_pos": 160, "end_pos": 162, "type": "METRIC", "confidence": 0.7334368228912354}, {"text": "F1", "start_pos": 200, "end_pos": 202, "type": "METRIC", "confidence": 0.6917814612388611}]}, {"text": "Furthermore, the joint classifier strategy brings further performance improvement on individual classifiers.", "labels": [], "entities": []}, {"text": "The rest of this paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 presents the design and implementation of our proposed joint model.", "labels": [], "entities": []}, {"text": "Section 3 gives the evaluation results and discussions.", "labels": [], "entities": []}, {"text": "Finally, Section 4 gives the conclusion and future research directions.", "labels": [], "entities": []}], "datasetContent": [{"text": "There are two subtasks in SIGHAN-8 topicbased Chinese microblog polarity classification: Performances by different classifiers in unrestricted resource subtask.", "labels": [], "entities": [{"text": "SIGHAN-8 topicbased Chinese microblog polarity classification", "start_pos": 26, "end_pos": 87, "type": "TASK", "confidence": 0.7785482108592987}]}, {"text": "task: restricted resource and unrestricted resource subtasks.", "labels": [], "entities": []}, {"text": "gives the performances in restricted resource subtask.", "labels": [], "entities": []}, {"text": "The first column lists the name of participants who achieves higher macro average F1 values while out system is named as HLT_HITSZ.", "labels": [], "entities": [{"text": "F1", "start_pos": 82, "end_pos": 84, "type": "METRIC", "confidence": 0.8504490256309509}, {"text": "HLT_HITSZ", "start_pos": 121, "end_pos": 130, "type": "METRIC", "confidence": 0.8333680828412374}]}, {"text": "It is observed that our proposed approach achieves better performance on negative and positive categories, but obviously lower performance on neutral category.", "labels": [], "entities": []}, {"text": "The good performance on the recall of minority classes showed the effectiveness of our consideration on imbalanced dataset training.", "labels": [], "entities": [{"text": "recall", "start_pos": 28, "end_pos": 34, "type": "METRIC", "confidence": 0.9870405793190002}]}, {"text": "The achieved performances in the unrestricted resource subtask are listed in.", "labels": [], "entities": []}, {"text": "Our system achieves about 3% of performance improvement on each category, respectively.", "labels": [], "entities": []}, {"text": "It shows the contributions of extra training corpus and merging rules.", "labels": [], "entities": []}, {"text": "In order to validate the effectiveness of merging rules, the performances of Classifier 1 and Classifier 2 are evaluated, individually.", "labels": [], "entities": []}, {"text": "The achieved performances are given in Table 6.", "labels": [], "entities": []}, {"text": "It is observed that generally speaking, Classifier 1 achieves a higher classification precision because many features are coming from manually compiled sentiment-related lexicons.", "labels": [], "entities": [{"text": "precision", "start_pos": 86, "end_pos": 95, "type": "METRIC", "confidence": 0.9760938286781311}]}, {"text": "However, these features are limited to training data so that Classifier 1 achieved a lower recall.", "labels": [], "entities": [{"text": "recall", "start_pos": 91, "end_pos": 97, "type": "METRIC", "confidence": 0.9991394281387329}]}, {"text": "On the contrary, Classifier 2 may learn the representation features automatically from training data which is better for generalization.", "labels": [], "entities": []}, {"text": "Thus, a good recall is achieved.", "labels": [], "entities": [{"text": "recall", "start_pos": 13, "end_pos": 19, "type": "METRIC", "confidence": 0.9995213747024536}]}, {"text": "Meanwhile, the achieved performances show that our joint model obtains better performances compared to two individual classifiers which indicate the effectiveness of our proposed joint classification strategy.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 4: Performances in restricted resource subtask.", "labels": [], "entities": []}, {"text": " Table 5: Performances in unrestricted resource subtask.", "labels": [], "entities": []}, {"text": " Table 6: Performances by different classifiers in unrestricted resource subtask.", "labels": [], "entities": []}]}