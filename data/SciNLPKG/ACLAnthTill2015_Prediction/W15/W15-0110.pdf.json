{"title": [], "abstractContent": [{"text": "Following earlier work in multimodal distributional semantics, we present the first results of our efforts to build a perceptually grounded semantic model.", "labels": [], "entities": []}, {"text": "Rather than using images, our models are built on sound data collected from freesound.org.", "labels": [], "entities": []}, {"text": "We compare three models: one bag-of-words model based on user-provided tags, a model based on audio features, using a 'bag-of-audio-words' approach and a model that combines the two.", "labels": [], "entities": []}, {"text": "Our results show that the models are able to capture semantic relatedness, with the tag-based model scoring higher than the sound-based model and the combined model.", "labels": [], "entities": []}, {"text": "However, capturing semantic relatedness is biased towards language-based models.", "labels": [], "entities": [{"text": "capturing semantic relatedness", "start_pos": 9, "end_pos": 39, "type": "TASK", "confidence": 0.7467880845069885}]}, {"text": "Future work will focus on improving the sound-based model, finding ways to combine linguistic and acoustic information, and creating more reliable evaluation data.", "labels": [], "entities": []}], "introductionContent": [{"text": "This paper explores the possibility of creating distributional semantic models () from a large dataset of tagged sounds.", "labels": [], "entities": []}, {"text": "Traditionally, distributional models have solely relied on word cooccurrences in large corpora.", "labels": [], "entities": []}, {"text": "Recently, have started to combine visual features with textual ones, resulting in a performance increase for tasks focusing on the use of color terms.", "labels": [], "entities": []}, {"text": "Sound has received relatively little attention in the distributional semantics literature, but we believe that it maybe a useful source of information, especially for the representation of actions or events like talking, shattering, or barking.", "labels": [], "entities": [{"text": "distributional semantics", "start_pos": 54, "end_pos": 78, "type": "TASK", "confidence": 0.7781484127044678}, {"text": "representation of actions or events like talking, shattering, or barking", "start_pos": 171, "end_pos": 243, "type": "TASK", "confidence": 0.6744145378470421}]}, {"text": "We propose three models: a tag-based model, a model based on bags-of-auditory words, and a model combining both kinds of information.", "labels": [], "entities": []}, {"text": "We evaluate these models against human similarity and relatedness judgments, and show that while the tag-based model performs better than the others, the sound-based model and the combined model still correlate well with the judgment data.", "labels": [], "entities": []}, {"text": "Based on our results, we suggest a number of future improvements.", "labels": [], "entities": []}, {"text": "All of our code is available on GitHub.", "labels": [], "entities": []}], "datasetContent": [{"text": "We evaluated our models on the MEN Test Collection () and on SimLex-999 ().", "labels": [], "entities": [{"text": "MEN Test Collection", "start_pos": 31, "end_pos": 50, "type": "DATASET", "confidence": 0.9737215042114258}, {"text": "SimLex-999", "start_pos": 61, "end_pos": 71, "type": "DATASET", "confidence": 0.9439324736595154}]}, {"text": "The former provides a test of semantic relatedness, i.e. how strongly two words are associated.", "labels": [], "entities": []}, {"text": "The latter tests semantic similarity, which is a measure of how alike two concepts are.", "labels": [], "entities": []}, {"text": "show that similarity ratings are more difficult to predict on the basis of text corpus data.", "labels": [], "entities": []}, {"text": "To evaluate our models, we took the tag pairs from both benchmarks, and we compared the similarity/relatedness ratings with the cosine similarity between the tags in each model.", "labels": [], "entities": [{"text": "similarity", "start_pos": 88, "end_pos": 98, "type": "METRIC", "confidence": 0.9692211151123047}]}, {"text": "The correlation between the cosine similarity values and the actual ratings are reported in the next section.", "labels": [], "entities": [{"text": "cosine similarity values", "start_pos": 28, "end_pos": 52, "type": "METRIC", "confidence": 0.8426680167516073}]}, {"text": "Our expectations for the performance of our models are as follows: 1.", "labels": [], "entities": []}, {"text": "We expect the tag-based model (SoundFX-tags) to perform better on MEN than on SimLex-999, because (i) tag co-occurrence can only tell us something about which actions and entities typically occur together in a given event.", "labels": [], "entities": []}, {"text": "But that does not tell us how alike the tags are; and (ii) languagebased models typically perform better on measures of relatedness.", "labels": [], "entities": []}, {"text": "2. We expect the sound-based model (SoundFX-BoAW) to perform worse than SoundFX-tags on both tasks.", "labels": [], "entities": []}, {"text": "This would parallel Bruni et al.'s results with bag-of-visual-words models.", "labels": [], "entities": []}, {"text": "3. We expect SoundFX-BoAW to perform better on SimLex-999 than on MEN, because the model clusters sounds (and thus tags) by their likeness.", "labels": [], "entities": []}, {"text": "4. We expect the combined model (SoundFX-combined) to perform better on both tasks than SoundFXBoAW, because it is enriched with information from SoundFX-tags (which we expect to be a better approximator of human semantic judgment, see expectation 1).", "labels": [], "entities": []}, {"text": "In addition, we also created a tag-based model using the full Freesound database (Freesound-tags) because we were curious to seethe effects of quantity versus quality (i.e. homogeneity) of tags.", "labels": [], "entities": [{"text": "Freesound database", "start_pos": 62, "end_pos": 80, "type": "DATASET", "confidence": 0.9486346244812012}]}, {"text": "We were hoping that the two would balance each other out, yielding a performance on par with SoundFX-tags.", "labels": [], "entities": [{"text": "SoundFX-tags", "start_pos": 93, "end_pos": 105, "type": "DATASET", "confidence": 0.9472312331199646}]}, {"text": "In future work, we hope to be able to provide a better benchmark for sound-based distributional models.", "labels": [], "entities": []}, {"text": "For example, MEN is based on tags from an image dataset.", "labels": [], "entities": []}, {"text": "Clearly this is not ideal for models of sound domain, and a more balanced test collection is needed.", "labels": [], "entities": []}, {"text": "shows the results for our models.", "labels": [], "entities": []}, {"text": "Each row shows the correlation scores on MEN and SimLex-999 for our models.", "labels": [], "entities": [{"text": "correlation", "start_pos": 19, "end_pos": 30, "type": "METRIC", "confidence": 0.9704955220222473}, {"text": "MEN", "start_pos": 41, "end_pos": 44, "type": "DATASET", "confidence": 0.9553285241127014}, {"text": "SimLex-999", "start_pos": 49, "end_pos": 59, "type": "DATASET", "confidence": 0.8944780230522156}]}, {"text": "We have selected the models with the optimal number of dimensions, which is why we report two models for SoundFX-tags: with 100 dimensions it produces the best score on SimLex, while with 400 dimensions it produces the best score on MEN.", "labels": [], "entities": [{"text": "MEN", "start_pos": 233, "end_pos": 236, "type": "DATASET", "confidence": 0.9543665647506714}]}, {"text": "Our other models did not differ as much in their 'high-scores' for MEN and SimLex, which is why we do not report different versions of these.", "labels": [], "entities": [{"text": "MEN", "start_pos": 67, "end_pos": 70, "type": "DATASET", "confidence": 0.9247221946716309}]}, {"text": "The results confirm our first two expectations, while the latter two expectations are not borne out.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Spearman correlations between our models and the MEN and Simlex-999 datasets.", "labels": [], "entities": [{"text": "MEN", "start_pos": 59, "end_pos": 62, "type": "DATASET", "confidence": 0.9511620402336121}, {"text": "Simlex-999 datasets", "start_pos": 67, "end_pos": 86, "type": "DATASET", "confidence": 0.7944490909576416}]}, {"text": " Table 3: Spearman correlations between different concatenation models and the MEN and Simlex-999 datasets.", "labels": [], "entities": [{"text": "MEN", "start_pos": 79, "end_pos": 82, "type": "DATASET", "confidence": 0.9531876444816589}, {"text": "Simlex-999 datasets", "start_pos": 87, "end_pos": 106, "type": "DATASET", "confidence": 0.8044089078903198}]}]}