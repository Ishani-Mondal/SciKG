{"title": [{"text": "Evaluating Features for Identifying Japanese-Chinese Bilingual Synonymous Technical Terms from Patent Families", "labels": [], "entities": [{"text": "Identifying Japanese-Chinese Bilingual Synonymous Technical Terms from Patent Families", "start_pos": 24, "end_pos": 110, "type": "TASK", "confidence": 0.8898018532329135}]}], "abstractContent": [{"text": "In the process of translating patent documents , a bilingual lexicon of technical terms is inevitable knowledge source.", "labels": [], "entities": [{"text": "translating patent documents", "start_pos": 18, "end_pos": 46, "type": "TASK", "confidence": 0.8719762762387594}]}, {"text": "It is important to develop techniques of acquiring technical term translation equivalent pairs automatically from parallel patent documents.", "labels": [], "entities": [{"text": "acquiring technical term translation equivalent pairs", "start_pos": 41, "end_pos": 94, "type": "TASK", "confidence": 0.6880465497573217}]}, {"text": "We take an approach of utilizing the phrase table of a state-of-the-art phrase-based statistical machine translation model.", "labels": [], "entities": [{"text": "phrase-based statistical machine translation", "start_pos": 72, "end_pos": 116, "type": "TASK", "confidence": 0.6092117205262184}]}, {"text": "First, we collect candidates of synonymous translation equivalent pairs from parallel patent sentences.", "labels": [], "entities": []}, {"text": "Then, we apply the Support Vector Machines (SVMs) to the task of identifying bilingual synonymous technical terms.", "labels": [], "entities": [{"text": "identifying bilingual synonymous technical terms", "start_pos": 65, "end_pos": 113, "type": "TASK", "confidence": 0.7637787699699402}]}, {"text": "This paper especially focuses on the issue of examining the effectiveness of each feature and identifies the minimum number of features that perform as comparatively well as the optimal set of features.", "labels": [], "entities": []}, {"text": "Finally, we achieve the performance of over 90% precision with the condition of more than or equal to 25% recall.", "labels": [], "entities": [{"text": "precision", "start_pos": 48, "end_pos": 57, "type": "METRIC", "confidence": 0.9995710253715515}, {"text": "recall", "start_pos": 106, "end_pos": 112, "type": "METRIC", "confidence": 0.9989711046218872}]}], "introductionContent": [{"text": "For both high quality machine and human translation, a large scale and high quality bilingual lexicon is the most important key resource.", "labels": [], "entities": [{"text": "human translation", "start_pos": 34, "end_pos": 51, "type": "TASK", "confidence": 0.7312031686306}]}, {"text": "Since manual compilation of bilingual lexicon requires plenty of time and huge manual labor, in the research area of knowledge acquisition from natural language text, automatic bilingual lexicon compilation have been studied.", "labels": [], "entities": [{"text": "manual compilation of bilingual lexicon", "start_pos": 6, "end_pos": 45, "type": "TASK", "confidence": 0.7994372606277466}, {"text": "knowledge acquisition from natural language text", "start_pos": 117, "end_pos": 165, "type": "TASK", "confidence": 0.8277958830197653}, {"text": "automatic bilingual lexicon compilation", "start_pos": 167, "end_pos": 206, "type": "TASK", "confidence": 0.6498259752988815}]}, {"text": "Techniques invented so far include translation term pair acquisition based on statistical co-occurrence measure from parallel sentences), compositional translation generation based on an existing bilingual lexicon for human use), translation term pair acquisition by collecting partially bilingual texts through the search engine (), and translation term pair acquisition from comparable corpora).", "labels": [], "entities": [{"text": "translation term pair acquisition", "start_pos": 35, "end_pos": 68, "type": "TASK", "confidence": 0.8533339947462082}, {"text": "compositional translation generation", "start_pos": 138, "end_pos": 174, "type": "TASK", "confidence": 0.7525727649529775}, {"text": "translation term pair acquisition", "start_pos": 230, "end_pos": 263, "type": "TASK", "confidence": 0.8559050261974335}, {"text": "translation term pair acquisition", "start_pos": 338, "end_pos": 371, "type": "TASK", "confidence": 0.8351848274469376}]}, {"text": "Among those efforts of acquiring bilingual lexicon from text, studied to acquire Japanese-English technical term translation lexicon from phrase tables, which are trained by a phrase-based SMT model with parallel sentences automatically extracted from parallel patent documents.", "labels": [], "entities": [{"text": "Japanese-English technical term translation lexicon", "start_pos": 81, "end_pos": 132, "type": "TASK", "confidence": 0.6730719029903411}, {"text": "SMT", "start_pos": 189, "end_pos": 192, "type": "TASK", "confidence": 0.8647854924201965}]}, {"text": "Furthermore, based on the achievement above,) studied the issue of identifying Japanese-English synonymous translation equivalent pairs in the task of acquiring Japanese-English technical term translation equivalent pairs.", "labels": [], "entities": [{"text": "acquiring Japanese-English technical term translation equivalent pairs", "start_pos": 151, "end_pos": 221, "type": "TASK", "confidence": 0.6661936129842486}]}, {"text": "Based on the technique and the results of identifying Japanese-English synonymous translation equivalent pairs in, next studied how to identify Japanese-Chinese synonymous translation equivalent pairs from Japanese-Chinese patent families.", "labels": [], "entities": []}, {"text": "In the task of identifying Japanese-Chinese synonymous translation equivalent pairs from Japanese-Chinese patent families) studied in, this paper modifies some of the features studied in and further focuses on the issue of examining the effectiveness of each feature.", "labels": [], "entities": []}, {"text": "This paper especially identifies the minimum number of features that perform as comparatively well as the optimal set of features, where the most effective feature is discovered to be the rate of intersection in translation by the phrase table.", "labels": [], "entities": []}, {"text": "Based on the evaluation results, we finally achieve the performance of over 90% precision with the condition of more than or equal to 25% recall.", "labels": [], "entities": [{"text": "precision", "start_pos": 80, "end_pos": 89, "type": "METRIC", "confidence": 0.9995648264884949}, {"text": "recall", "start_pos": 138, "end_pos": 144, "type": "METRIC", "confidence": 0.9988486766815186}]}, {"text": "From them, we extract 312,492 patent families, and the method of is applied 1 to the text of those patent families, and Japanese and Chinese sentences are aligned.", "labels": [], "entities": []}, {"text": "In this paper, we use 3.6M parallel patent sentences with the highest scores of sentence alignment 2 . We used a Japanese-Chinese translation lexicon consisting of about 170,000 Chinese head words.", "labels": [], "entities": []}, {"text": "The maximum score of the method of Utiyama and Isahara (2007) is set to be 1.0, while the lower bound of its score is about 0.152 with the 3.6M parallel patent sentences.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Number of Bilingual Technical Terms: Candidates and Reference of Synonyms", "labels": [], "entities": []}, {"text": " Table 4: Pairs of Features having No Significant  Difference (5% Significance Level) with Maxi- mum Precision Features and their Evaluation Re- sults (%)", "labels": [], "entities": [{"text": "Evaluation Re- sults", "start_pos": 130, "end_pos": 150, "type": "METRIC", "confidence": 0.9306943714618683}]}, {"text": " Table 3: Evaluation Results (%)", "labels": [], "entities": [{"text": "Evaluation", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.8700454831123352}]}, {"text": " Table 5: Features for Identifying Bilingual Synonymous Technical Terms by Tsunakawa and Tsu- jii (2008)", "labels": [], "entities": [{"text": "Identifying Bilingual Synonymous Technical Terms", "start_pos": 23, "end_pos": 71, "type": "TASK", "confidence": 0.8279785633087158}]}]}