{"title": [{"text": "The Ubuntu Dialogue Corpus: A Large Dataset for Research in Unstructured Multi-Turn Dialogue Systems", "labels": [], "entities": [{"text": "Ubuntu Dialogue Corpus", "start_pos": 4, "end_pos": 26, "type": "DATASET", "confidence": 0.9053040742874146}]}], "abstractContent": [{"text": "This paper introduces the Ubuntu Dialogue Corpus, a dataset containing almost 1 million multi-turn dialogues, with a total of over 7 million utterances and 100 million words.", "labels": [], "entities": [{"text": "Ubuntu Dialogue Corpus", "start_pos": 26, "end_pos": 48, "type": "DATASET", "confidence": 0.8586169083913168}]}, {"text": "This provides a unique resource for research into building dialogue managers based on neural language models that can make use of large amounts of unlabeled data.", "labels": [], "entities": []}, {"text": "The dataset has both the multi-turn property of conversations in the Dialog State Tracking Challenge datasets, and the unstructured nature of interactions from microblog services such as Twitter.", "labels": [], "entities": [{"text": "Dialog State Tracking Challenge datasets", "start_pos": 69, "end_pos": 109, "type": "DATASET", "confidence": 0.6781252980232239}]}, {"text": "We also describe two neural learning architectures suitable for analyzing this dataset, and provide benchmark performance on the task of selecting the best next response.", "labels": [], "entities": []}], "introductionContent": [{"text": "The ability fora computer to converse in a natural and coherent manner with a human has long been held as one of the primary objectives of artificial intelligence (AI).", "labels": [], "entities": []}, {"text": "In this paper we consider the problem of building dialogue agents that have the ability to interact in one-on-one multi-turn conversations on a diverse set of topics.", "labels": [], "entities": []}, {"text": "We primarily target unstructured dialogues, where there is no a priori logical representation for the information exchanged during the conversation.", "labels": [], "entities": []}, {"text": "This is in contrast to recent systems which focus on structured dialogue tasks, using a slot-filling representation.", "labels": [], "entities": []}, {"text": "We observe that in several subfields of AIcomputer vision, speech recognition, machine translation-fundamental break-throughs were achieved in recent years using machine learning * The first two authors contributed equally.", "labels": [], "entities": [{"text": "AIcomputer vision", "start_pos": 40, "end_pos": 57, "type": "TASK", "confidence": 0.8118446469306946}, {"text": "speech recognition", "start_pos": 59, "end_pos": 77, "type": "TASK", "confidence": 0.7813318371772766}, {"text": "machine translation-fundamental break-throughs", "start_pos": 79, "end_pos": 125, "type": "TASK", "confidence": 0.8270359834035238}]}, {"text": "methods, more specifically with neural architectures; however, it is worth noting that many of the most successful approaches, in particular convolutional and recurrent neural networks, were known for many years prior.", "labels": [], "entities": []}, {"text": "It is therefore reasonable to attribute this progress to three major factors: 1) the public distribution of very large rich datasets, 2) the availability of substantial computing power, and 3) the development of new training methods for neural architectures, in particular leveraging unlabeled data.", "labels": [], "entities": []}, {"text": "Similar progress has not yet been observed in the development of dialogue systems.", "labels": [], "entities": []}, {"text": "We hypothesize that this is due to the lack of sufficiently large datasets, and aim to overcome this barrier by providing anew large corpus for research in multi-turn conversation.", "labels": [], "entities": []}, {"text": "The new Ubuntu Dialogue Corpus consists of almost one million two-person conversations extracted from the Ubuntu chat logs 1 , used to receive technical support for various Ubuntu-related problems.", "labels": [], "entities": [{"text": "Ubuntu Dialogue Corpus", "start_pos": 8, "end_pos": 30, "type": "DATASET", "confidence": 0.8717010219891866}, {"text": "Ubuntu chat logs 1", "start_pos": 106, "end_pos": 124, "type": "DATASET", "confidence": 0.8932183235883713}]}, {"text": "The conversations have an average of 8 turns each, with a minimum of 3 turns.", "labels": [], "entities": []}, {"text": "All conversations are carried out in text form (not audio).", "labels": [], "entities": []}, {"text": "The dataset is orders of magnitude larger than structured corpuses such as those of the Dialogue State Tracking Challenge.", "labels": [], "entities": [{"text": "Dialogue State Tracking Challenge", "start_pos": 88, "end_pos": 121, "type": "TASK", "confidence": 0.6806006282567978}]}, {"text": "It is on the same scale as recent datasets for solving problems such as question answering and analysis of microblog services, such as Twitter, but each conversation in our dataset includes several more turns, as well as longer utterances.", "labels": [], "entities": [{"text": "question answering", "start_pos": 72, "end_pos": 90, "type": "TASK", "confidence": 0.8499869108200073}]}, {"text": "Furthermore, because it targets a specific domain, namely technical support, it can be used as a case study for the development of AI agents in targeted applications, in contrast to chatbox agents that often lack a welldefined goal.", "labels": [], "entities": []}, {"text": "In addition to the corpus, we present learning architectures suitable for analyzing this dataset, ranging from the simple frequency-inverse docu-ment frequency (TF-IDF) approach, to more sophisticated neural models including a Recurrent Neural Network (RNN) and a Long Short-Term Memory (LSTM) architecture.", "labels": [], "entities": []}, {"text": "We provide benchmark performance of these algorithms, trained with our new corpus, on the task of selecting the best next response, which can be achieved without requiring any human labeling.", "labels": [], "entities": []}, {"text": "The dataset is ready for public release 2 . The code developed for the empirical results is also available 3 .", "labels": [], "entities": []}], "datasetContent": [{"text": "The Switchboard dataset, and the Dialogue State Tracking Challenge (DSTC) datasets have been used to train and validate dialogue management systems for interactive information retrieval.", "labels": [], "entities": [{"text": "Switchboard dataset", "start_pos": 4, "end_pos": 23, "type": "DATASET", "confidence": 0.7930608987808228}, {"text": "Dialogue State Tracking Challenge (DSTC)", "start_pos": 33, "end_pos": 73, "type": "TASK", "confidence": 0.768575519323349}, {"text": "interactive information retrieval", "start_pos": 152, "end_pos": 185, "type": "TASK", "confidence": 0.6500844260056814}]}, {"text": "The problem is typically formalized as a slot filling task, where agents attempt to predict the goal of a user during the conversation.", "labels": [], "entities": [{"text": "slot filling task", "start_pos": 41, "end_pos": 58, "type": "TASK", "confidence": 0.8211861451466879}]}, {"text": "These datasets have been significant resources for structured dialogues, and have allowed major progress in this field, though they are quite small compared to datasets currently used for training neural architectures.", "labels": [], "entities": []}, {"text": "Recently, a few datasets have been used containing unstructured dialogues extracted from Twitter . [21] collected 1.3 million conversations; this was extended in to take advantage of longer contexts by using A-B-A triples.", "labels": [], "entities": []}, {"text": "Shang et al. used data from a similar Chinese website called Weibo 5 . However to our knowledge, these datasets have not been made public, and furthermore, the post-reply format of such microblogging services is perhaps not as representative of natural dialogue between humans as the continuous stream of messages in a chatroom.", "labels": [], "entities": [{"text": "Weibo 5", "start_pos": 61, "end_pos": 68, "type": "DATASET", "confidence": 0.9595561325550079}]}, {"text": "In fact, Ritter et al. estimate that only 37% of posts on Twitter are 'conversational in nature', and 69% of their collected data contained exchanges of only length 2.", "labels": [], "entities": []}, {"text": "We hypothesize that chat-room style messaging is more closely correlated to human-tohuman dialogue than micro-blogging websites, or forum-based sites such as Reddit.", "labels": [], "entities": []}, {"text": "Part of the Ubuntu chat logs have previously been aggregated into a dataset, called the Ubuntu Chat Corpus.", "labels": [], "entities": [{"text": "Ubuntu Chat Corpus", "start_pos": 88, "end_pos": 106, "type": "DATASET", "confidence": 0.9348220626513163}]}, {"text": "However that resource preserves the multi-participant structure and thus is less amenable to the investigation of more traditional two-party conversations.", "labels": [], "entities": []}, {"text": "Also weakly related to our contribution is the problem of question-answer systems.", "labels": [], "entities": []}, {"text": "Several datasets of question-answer pairs are available, however these interactions are much shorter than what we seek to study.", "labels": [], "entities": []}, {"text": "In order to create the Ubuntu Dialogue Corpus, first a method had to be devised to extract dyadic dialogues from the chatroom multi-party conversations.", "labels": [], "entities": [{"text": "Ubuntu Dialogue Corpus", "start_pos": 23, "end_pos": 45, "type": "DATASET", "confidence": 0.7698610027631124}]}, {"text": "The first step was to separate every message into 4-tuples of (time, sender, recipient, utterance).", "labels": [], "entities": []}, {"text": "Given these 4-tuples, it is straightforward to group all tuples where there is a matching sender and recipient.", "labels": [], "entities": []}, {"text": "Although it is easy to separate the time and the sender from the rest, finding the in-tended recipient of the message is not always trivial.", "labels": [], "entities": []}, {"text": "We consider the task of best response selection.", "labels": [], "entities": [{"text": "best response selection", "start_pos": 24, "end_pos": 47, "type": "TASK", "confidence": 0.6508260269959768}]}, {"text": "This can be achieved by processing the data as described in Section 3.4, without requiring any human labels.", "labels": [], "entities": []}, {"text": "This classification task is an adaptation of the recall and precision metrics previously applied to dialogue datasets.", "labels": [], "entities": [{"text": "recall", "start_pos": 49, "end_pos": 55, "type": "METRIC", "confidence": 0.999041736125946}, {"text": "precision", "start_pos": 60, "end_pos": 69, "type": "METRIC", "confidence": 0.97093665599823}]}, {"text": "A family of metrics often used in language tasks is Recall@k (denoted R@1 R@2, R@5 below).", "labels": [], "entities": []}, {"text": "Here the agent is asked to select the k most likely responses, and it is correct if the true response is among these k candidates.", "labels": [], "entities": []}, {"text": "Only the R@1 metric is relevant in the case of binary classification (as in the.", "labels": [], "entities": [{"text": "binary classification", "start_pos": 47, "end_pos": 68, "type": "TASK", "confidence": 0.7035912573337555}]}, {"text": "Although a language model that performs well on response classification is not a gauge of good performance on next utterance generation, we hypothesize that improvements on a model with regards to the classification task will eventually lead to improvements for the generation task.", "labels": [], "entities": [{"text": "response classification", "start_pos": 48, "end_pos": 71, "type": "TASK", "confidence": 0.784223347902298}, {"text": "next utterance generation", "start_pos": 110, "end_pos": 135, "type": "TASK", "confidence": 0.6537681221961975}]}, {"text": "See Section 6 for further discussion of this point.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: A selection of structured and unstructured large-scale datasets applicable to dialogue systems.  Faded datasets are not publicly available. The last entry is our contribution.", "labels": [], "entities": []}, {"text": " Table 2: Properties of Ubuntu Dialogue Corpus.", "labels": [], "entities": [{"text": "Ubuntu Dialogue Corpus", "start_pos": 24, "end_pos": 46, "type": "DATASET", "confidence": 0.8857366840044657}]}]}