{"title": [{"text": "SHEF-NN: Translation Quality Estimation with Neural Networks", "labels": [], "entities": [{"text": "Translation Quality Estimation", "start_pos": 9, "end_pos": 39, "type": "TASK", "confidence": 0.8587129712104797}]}], "abstractContent": [{"text": "We describe our systems for Tasks 1 and 2 of the WMT15 Shared Task on Quality Estimation.", "labels": [], "entities": [{"text": "WMT15 Shared Task on Quality Estimation", "start_pos": 49, "end_pos": 88, "type": "TASK", "confidence": 0.7544600566228231}]}, {"text": "Our submissions use (i) a continuous space language model to extract additional features for Task 1 (SHEF-GP, SHEF-SVM), (ii) a continuous bag-of-words model to produce word embed-dings as features for Task 2 (SHEF-W2V) and (iii) a combination of features produced by QuEst++ and a feature produced with word embedding models (SHEF-QuEst++).", "labels": [], "entities": []}, {"text": "Our systems outperform the baseline as well as many other submissions.", "labels": [], "entities": []}, {"text": "The results are especially encouraging for Task 2, where our best performing system (SHEF-W2V) only uses features learned in an unsupervised fashion.", "labels": [], "entities": [{"text": "SHEF-W2V", "start_pos": 85, "end_pos": 93, "type": "DATASET", "confidence": 0.7350850701332092}]}], "introductionContent": [{"text": "Quality Estimation (QE) aims at measuring the quality of the Machine Translation (MT) output without reference translations.", "labels": [], "entities": [{"text": "Quality Estimation (QE)", "start_pos": 0, "end_pos": 23, "type": "TASK", "confidence": 0.7068248987197876}, {"text": "Machine Translation (MT)", "start_pos": 61, "end_pos": 85, "type": "TASK", "confidence": 0.8367209076881409}]}, {"text": "Generally, QE is addressed with various features indicating fluency, adequacy and complexity of the source-translation text pair.", "labels": [], "entities": []}, {"text": "Such features are then used along with Machine Learning methods in order for models to be learned.", "labels": [], "entities": []}, {"text": "Features play a key role in QE.", "labels": [], "entities": [{"text": "QE", "start_pos": 28, "end_pos": 30, "type": "TASK", "confidence": 0.9566489458084106}]}, {"text": "A wide range of features from the source segments and their translations, often processed using external resources and tools, have been proposed.", "labels": [], "entities": []}, {"text": "These go from simple, language-independent features, to advanced, linguistically motivated features.", "labels": [], "entities": []}, {"text": "They include features that rely on information from the MT system that generated the translations, and features that are oblivious to the way translations were produced.", "labels": [], "entities": []}, {"text": "This leads to a potential bottleneck: feature engineering can be time consuming, particularly because the impact of features vary across datasets and language pairs.", "labels": [], "entities": [{"text": "feature engineering", "start_pos": 38, "end_pos": 57, "type": "TASK", "confidence": 0.7917558550834656}]}, {"text": "Also, most features in the literature are extracted from segment pairs in isolation, ignoring contextual clues from other segments in the text.", "labels": [], "entities": []}, {"text": "The focus of our contributions this year is to introduce anew set of features which are language-independent, require minimal resources, and can be extracted in unsupervised ways with the use of neural networks.", "labels": [], "entities": []}, {"text": "Word embeddings have shown their potential in modelling long distance dependencies in data, including syntactic and semantic information.", "labels": [], "entities": []}, {"text": "For instance, neural network language models () have been successfully explored in many problems including Automatic Speech Recognition ( and Machine Translation.", "labels": [], "entities": [{"text": "Automatic Speech Recognition", "start_pos": 107, "end_pos": 135, "type": "TASK", "confidence": 0.7014391918977102}, {"text": "Machine Translation", "start_pos": 142, "end_pos": 161, "type": "TASK", "confidence": 0.8489161729812622}]}, {"text": "While neural network language models predict the next word given a preceding context, () proposed a neural network framework to predict the word given the left and right contexts, or to predict the word's left and right contexts in a given sentence.", "labels": [], "entities": []}, {"text": "Recently, it has been shown that these distributed vector representations (or word embeddings) can be exploited across languages to predict translations ().", "labels": [], "entities": [{"text": "predict translations", "start_pos": 132, "end_pos": 152, "type": "TASK", "confidence": 0.6781067848205566}]}, {"text": "The word representations are learned from large monolingual data independently for source and target languages.", "labels": [], "entities": []}, {"text": "A small seed dictionary is used to learn mapping from the source into the target space.", "labels": [], "entities": []}, {"text": "In this paper, we investigate the use of such resources in both sentence-level (Task 1) and word-level QE (Task 2).", "labels": [], "entities": []}, {"text": "As we describe in what follows, we extract features from such resources and use them to learn prediction models.", "labels": [], "entities": []}], "datasetContent": [{"text": "We present experiments on the WMT15 QE Tasks 1 and 2, with CSLM features for Task 1, and word embedding features for Task 2.", "labels": [], "entities": [{"text": "WMT15 QE Tasks 1", "start_pos": 30, "end_pos": 46, "type": "DATASET", "confidence": 0.8847433030605316}]}, {"text": "Task 1's English-Spanish dataset consists respectively of a training set and development set with 11, 271 and 1, 000 source segments, their machine translations, the post-editions of the latter, and edit distance scores between between the MT and its post-edited version (HTER).", "labels": [], "entities": [{"text": "edit distance scores", "start_pos": 199, "end_pos": 219, "type": "METRIC", "confidence": 0.9333515365918478}]}, {"text": "The test set consists of 1, 817 English-Spanish source-MT pairs.", "labels": [], "entities": []}, {"text": "Translations are produced by a single online statistical MT system.", "labels": [], "entities": [{"text": "Translations", "start_pos": 0, "end_pos": 12, "type": "TASK", "confidence": 0.9619755744934082}, {"text": "MT", "start_pos": 57, "end_pos": 59, "type": "TASK", "confidence": 0.9348971843719482}]}, {"text": "Each of the translations was post-edited by crowdsourced translators, and HTER labels were computed using the TER tool (settings: tokenised, case insensitive, exact matching only, with scores capped to 1).", "labels": [], "entities": [{"text": "HTER labels", "start_pos": 74, "end_pos": 85, "type": "METRIC", "confidence": 0.9655675888061523}, {"text": "TER", "start_pos": 110, "end_pos": 113, "type": "METRIC", "confidence": 0.9763159155845642}]}, {"text": "The data for this is the same as the one provided in Task 1.", "labels": [], "entities": []}, {"text": "All segments have been automatically annotated for errors with binary word-level labels (\"GOOD\" and \"BAD\") by using the alignments provided by the TER tool (settings: tokenised, case insensitive, exact matching only, disabling shifts by using the '-d 0' option) between machine translations and their post-edited versions.", "labels": [], "entities": [{"text": "GOOD", "start_pos": 90, "end_pos": 94, "type": "METRIC", "confidence": 0.9502756595611572}, {"text": "BAD", "start_pos": 101, "end_pos": 104, "type": "METRIC", "confidence": 0.8598319888114929}, {"text": "TER", "start_pos": 147, "end_pos": 150, "type": "METRIC", "confidence": 0.8602967262268066}]}, {"text": "The edit operations considered as errors (\"BAD\") are replacements and insertions.", "labels": [], "entities": [{"text": "BAD", "start_pos": 43, "end_pos": 46, "type": "METRIC", "confidence": 0.9737963676452637}]}], "tableCaptions": [{"text": " Table 1: Training and dev datasets size (in number  of tokens) and models perplexity (px).", "labels": [], "entities": []}, {"text": " Table 2: Results on development set of Task 1.", "labels": [], "entities": []}, {"text": " Table 3: Official results on test set of Task 1.", "labels": [], "entities": []}, {"text": " Table 5: Official results on test set of Task 2.", "labels": [], "entities": []}]}