{"title": [{"text": "From a Distance: Using Cross-lingual Word Alignments for Noun Compound Bracketing", "labels": [], "entities": [{"text": "Cross-lingual Word Alignments", "start_pos": 23, "end_pos": 52, "type": "TASK", "confidence": 0.6056199669837952}]}], "abstractContent": [{"text": "We present a cross-lingual method for determining NP structures.", "labels": [], "entities": []}, {"text": "More specifically, we try to determine whether the semantics of tripartite noun compounds in context requires a left or right branching interpretation.", "labels": [], "entities": []}, {"text": "The system exploits the difference in word position between languages as found in parallel corpora.", "labels": [], "entities": []}, {"text": "We achieve a bracketing accuracy of 94.6%, significantly outperforming all systems in comparison and comparable to human performance.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 24, "end_pos": 32, "type": "METRIC", "confidence": 0.9643969535827637}]}, {"text": "Our system generates large amounts of high-quality bracketed NPs in a multilingual context that can be used to train supervised learners.", "labels": [], "entities": []}], "introductionContent": [{"text": "k-partite noun compounds, i.e., compositions of k bare common nouns that function as one unit, (kNCs), such as air traffic control system, usually have an implicit structure that reflects semantics.", "labels": [], "entities": []}, {"text": "While a LEFTbranching [world banana] market is very unlikely, for luxury cattle truck, both structures make sense and context is necessary for disambiguation: [luxury cattle] truck is a truck for luxury cattle whereas luxury [cattle truck] is a luxury truck for (any) cattle.", "labels": [], "entities": []}, {"text": "Therefore, a proper structural analysis is a crucial part of noun compound interpretation and of fundamental importance for many tasks in natural language processing such as machine translation.", "labels": [], "entities": [{"text": "noun compound interpretation", "start_pos": 61, "end_pos": 89, "type": "TASK", "confidence": 0.8053163687388102}, {"text": "machine translation", "start_pos": 174, "end_pos": 193, "type": "TASK", "confidence": 0.799754410982132}]}, {"text": "The correct French translation of luxury cattle truck depends on the internal structure.", "labels": [], "entities": []}, {"text": "While [luxury cattle] truck is translated as camion pour b\u00e9tail deluxe, the preferred translation for luxury [cattle truck] is camion deluxe pour b\u00e9tail.", "labels": [], "entities": []}, {"text": "Previous work on noun compound bracketing has shown that supervised beats unsupervised.", "labels": [], "entities": [{"text": "noun compound bracketing", "start_pos": 17, "end_pos": 41, "type": "TASK", "confidence": 0.7814732591311137}]}, {"text": "The latter approaches use N-gram statistics or lexical patterns, web counts () or semantic relations and evaluate on carefully selected evaluation data from encyclopedia) or from general newspaper text.", "labels": [], "entities": []}, {"text": "manually annotated the Penn Treebank and showed that they improve over unsupervised results by a large margin.", "labels": [], "entities": [{"text": "Penn Treebank", "start_pos": 23, "end_pos": 36, "type": "DATASET", "confidence": 0.9916132390499115}]}, {"text": "used the data from Vadas and Curran (2007a) fora parser applicable on base noun phrases (NPs) of any length including coordinations.", "labels": [], "entities": []}, {"text": "Barker (1998) presents a bracketing method for k-partite NPs that reduces the task to three-word bracketings within a sliding window.", "labels": [], "entities": []}, {"text": "One advantage of supervised approaches for this task is that kNCs are labeled in context so contextual features can be used in the learning framework.", "labels": [], "entities": []}, {"text": "These are especially useful when dealing with ambiguous kNCs.", "labels": [], "entities": []}, {"text": "The need for annotated data is a drawback of supervised approaches.", "labels": [], "entities": []}, {"text": "Manual annotations are costly and time-consuming.", "labels": [], "entities": []}, {"text": "To circumvent this need for annotated data, previous work has used cross-lingual supervision based on parallel corpora.", "labels": [], "entities": []}, {"text": "made use of small amounts of annotated data on the target side and complement this with bilingual features from unlabeled bitext in a co-trained classifier for coordination disambiguation in complex NPs.", "labels": [], "entities": []}, {"text": "Previous work on using cross-lingual data for the analysis of multi-word expressions (MWEs) of different types include;;;;.", "labels": [], "entities": [{"text": "analysis of multi-word expressions (MWEs)", "start_pos": 50, "end_pos": 91, "type": "TASK", "confidence": 0.6477140273366656}]}, {"text": "Ziering and Van der Plas (2014) propose an approach that refrains from using any human annotation.", "labels": [], "entities": []}, {"text": "They use the fact, that languages differ in their preference for open or closed compounding (i.e., multiword vs. one-word compounds), for inducing the English bracketing of 3NCs.", "labels": [], "entities": []}, {"text": "English open 3NCs like human rights abuses can be translated to partially closed phrases as in German Verletzungen der Menschenrechte, (abuses of human rights), from which we can induce the LEFT-branching structure.", "labels": [], "entities": [{"text": "LEFT-branching", "start_pos": 190, "end_pos": 204, "type": "METRIC", "confidence": 0.7996935844421387}]}, {"text": "Although this approach achieves a solid accuracy, a crucial limitation is coverage, because restricting to six paraphrasing patterns ignores many other predictive cases.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 40, "end_pos": 48, "type": "METRIC", "confidence": 0.998416543006897}, {"text": "coverage", "start_pos": 74, "end_pos": 82, "type": "METRIC", "confidence": 0.9961689114570618}]}, {"text": "Moreover, the system needs part of speech (PoS) tags and splitting information for determining 2NCs and is therefore rather language-dependent.", "labels": [], "entities": []}, {"text": "In this paper, we present a precise, high-coverage and knowledge-lean method for bracketing kNCs (for k \u2265 3) occurring in parallel data.", "labels": [], "entities": [{"text": "bracketing kNCs", "start_pos": 81, "end_pos": 96, "type": "TASK", "confidence": 0.8391028046607971}]}, {"text": "Our method uses the distances of words that are aligned to kNC components in parallel languages.", "labels": [], "entities": []}, {"text": "For example, the 3NC human rights violations can be bracketed using the positions of aligned words in the Italian fragment . .", "labels": [], "entities": [{"text": "3NC human rights violations", "start_pos": 17, "end_pos": 44, "type": "DATASET", "confidence": 0.9010669738054276}, {"text": "Italian fragment", "start_pos": 106, "end_pos": 122, "type": "DATASET", "confidence": 0.8649596571922302}]}, {"text": "che le violazioni gravi e sistematiche dei diritti umani . .", "labels": [], "entities": []}, {"text": "The fact, that the alignment of the third noun, violations (violazioni), is separated from the rest, points us in the direction of LEFT-branching.", "labels": [], "entities": [{"text": "LEFT-branching", "start_pos": 131, "end_pos": 145, "type": "METRIC", "confidence": 0.9003880023956299}]}, {"text": "Using less restricted forms of cross-lingual supervision, we achieve a much higher coverage than Ziering and Van der Plas (2014).", "labels": [], "entities": [{"text": "coverage", "start_pos": 83, "end_pos": 91, "type": "METRIC", "confidence": 0.9909337759017944}]}, {"text": "Furthermore, our results are more accurate.", "labels": [], "entities": []}, {"text": "In contrast to previous unsupervised methods, our system is applicable in both token-and type-based modes.", "labels": [], "entities": []}, {"text": "Token-based bracketing is context-dependent and allows fora better treatment of structural ambiguity (as in luxury cattle truck).", "labels": [], "entities": [{"text": "Token-based bracketing", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.8882191181182861}]}, {"text": "We generate large amounts of high-quality bracketed kNCs in a multilingual context that can be used to train supervised learners.", "labels": [], "entities": []}], "datasetContent": [{"text": "While AWDB is designed for bracketing NPs of any length, we first experiment with bracketing 3NCs, the largest class of 3 + NCs (93.8% on the basic dataset of Ziering and Van der Plas (2014)), for which bracketing is a binary classification (i.e., LEFT or RIGHT).", "labels": [], "entities": [{"text": "AWDB", "start_pos": 6, "end_pos": 10, "type": "DATASET", "confidence": 0.7297223806381226}, {"text": "LEFT", "start_pos": 248, "end_pos": 252, "type": "METRIC", "confidence": 0.9934831261634827}, {"text": "RIGHT", "start_pos": 256, "end_pos": 261, "type": "METRIC", "confidence": 0.9147078394889832}]}, {"text": "For bracketing longer NCs we often have to make do with partial information from a language, instead of a full structure.", "labels": [], "entities": [{"text": "bracketing longer NCs", "start_pos": 4, "end_pos": 25, "type": "TASK", "confidence": 0.8650749325752258}]}, {"text": "In future work, we plan to investigate methods to combine these partial results.", "labels": [], "entities": []}, {"text": "Moreover, in contrast to previous work (e.g.,), we take only common nouns as components into account rather than named entities.", "labels": [], "entities": []}, {"text": "We consider the task of bracketing 3NCs composed of common nouns more ambitious, because named entities often form a single concept that is easy to spot, e.g., Apple II owners.", "labels": [], "entities": [{"text": "bracketing 3NCs composed of common nouns", "start_pos": 24, "end_pos": 64, "type": "TASK", "confidence": 0.8415405054887136}]}, {"text": "Although AWDB can also process compounds including adjectives (e.g., active inclusion policy aligned to the Dutch beleid voor actieve insluiting (policy for active inclusion)), fora direct comparison with the system of Ziering and Van der Plas (2014), that analyses 3NCs, we restrict ourselves to noun sequences.", "labels": [], "entities": []}, {"text": "We use the Europarl 2 compound database 3 developed by Ziering and Van der Plas (2014).", "labels": [], "entities": [{"text": "Europarl 2 compound database", "start_pos": 11, "end_pos": 39, "type": "DATASET", "confidence": 0.9466505646705627}]}, {"text": "This database has been compiled from the OPUS 4 corpus (Tiedemann, 2012) and comprises ten languages: Danish, Dutch, English, French, German, Greek, Italian, Portuguese, Spanish and Swedish.", "labels": [], "entities": [{"text": "OPUS 4 corpus (Tiedemann, 2012)", "start_pos": 41, "end_pos": 72, "type": "DATASET", "confidence": 0.9083417803049088}]}, {"text": "We use the initial version (basic dataset), that contains English word sequences that conform PoS chunks and their alignments.", "labels": [], "entities": []}, {"text": "We select English word sequences whose PoS pattern conforms three nouns.", "labels": [], "entities": []}, {"text": "Extraction errors area problem, since many adjectives have been tagged as nouns and some 3NCs occur as incomplete fragments.", "labels": [], "entities": []}, {"text": "For increasing the effectiveness of human annotation, we developed a high-confidence noun filter P noun (word) = P (noun | word).", "labels": [], "entities": []}, {"text": "It is trained on the English Wikipedia 5 tagged by TreeTagger (.", "labels": [], "entities": [{"text": "English Wikipedia 5 tagged by TreeTagger", "start_pos": 21, "end_pos": 61, "type": "DATASET", "confidence": 0.8851325313250223}]}, {"text": "We inspect all 3NCs in the context of one token to the left and right, w 0 {N 1 N 2 N 3 }w 4 . If P noun (N i ) < \u03b8 or P noun (w j ) \u2265 \u03b8, we remove the 3NC from our dataset.", "labels": [], "entities": []}, {"text": "We inspected a subset of all 3NCs in the database and estimated the best filter quality to be with \u03b8 = 0.04.", "labels": [], "entities": []}, {"text": "This threshold discards increasing land abandonment but keeps human rights abuse.", "labels": [], "entities": []}, {"text": "Our final dataset contains 14,941 tokens and 8824 types.", "labels": [], "entities": []}, {"text": "We compare AWDB with the bracketing approach of Ziering and Van der Plas (2014).", "labels": [], "entities": [{"text": "AWDB", "start_pos": 11, "end_pos": 15, "type": "METRIC", "confidence": 0.49422550201416016}]}, {"text": "For both systems, we use the majority vote across all nine aligned languages, in a token-and type-based version.", "labels": [], "entities": []}, {"text": "We implemented an unsupervised method based on statistics on bi-grams extracted from the English part of the Europarl corpus.", "labels": [], "entities": [{"text": "English part of the Europarl corpus", "start_pos": 89, "end_pos": 124, "type": "DATASET", "confidence": 0.7149789035320282}]}, {"text": "As scorer, we use the Chi squared (\u03c7 2 ) measure, which worked best in previous work).", "labels": [], "entities": [{"text": "Chi squared (\u03c7 2 ) measure", "start_pos": 22, "end_pos": 48, "type": "METRIC", "confidence": 0.7454402574471065}]}, {"text": "We consider both the adjacency (i.e., (N 1 , N 2 ) vs.,) and the dependency (i.e., (N 1 , N 2 ) vs.,) model.", "labels": [], "entities": []}, {"text": "We created a back-off model for the bracketing system of Ziering and Van der Plas (2014) and for AWDB that falls back to using \u03c7 2 if no bracketing structure can be derived (system \u2192 \u03c7 2 ).", "labels": [], "entities": [{"text": "AWDB", "start_pos": 97, "end_pos": 101, "type": "DATASET", "confidence": 0.9452041983604431}]}, {"text": "Finally, we compare with a baseline, that always predicts the majority class: LEFT.", "labels": [], "entities": [{"text": "LEFT", "start_pos": 78, "end_pos": 82, "type": "METRIC", "confidence": 0.998035728931427}]}, {"text": "We observed that there is only a very small overlap between test sets of previous work on NP bracketing and the Europarl database.", "labels": [], "entities": [{"text": "NP bracketing", "start_pos": 90, "end_pos": 103, "type": "TASK", "confidence": 0.7751138210296631}, {"text": "Europarl database", "start_pos": 112, "end_pos": 129, "type": "DATASET", "confidence": 0.9927779138088226}]}, {"text": "The test set used by Ziering and Van der Plas is very small and the labeling is less fine-grained.", "labels": [], "entities": []}, {"text": "Thus, we decided to create our own test set.", "labels": [], "entities": []}, {"text": "statmt.org/europarl 3 ims.uni-stuttgart.de/data/NCDatabase.html 4 opus.lingfil.uu.se 5 en.wikipedia.org For a fair comparison, we leave systems that have access to external knowledge, such as web search engines, aside.", "labels": [], "entities": [{"text": "europarl 3 ims.uni-stuttgart.de/data/NCDatabase.html", "start_pos": 11, "end_pos": 63, "type": "DATASET", "confidence": 0.755422226020268}]}], "tableCaptions": [{"text": " Table 1: Evaluation results on coverage", "labels": [], "entities": []}, {"text": " Table 2: Direct comparison on common test sets;  \u2020 = significantly better than the systems in comparison", "labels": [], "entities": []}, {"text": " Table 3: Evaluation of language families for AWDB type", "labels": [], "entities": []}]}