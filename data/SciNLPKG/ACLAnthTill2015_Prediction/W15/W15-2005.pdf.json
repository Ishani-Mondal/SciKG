{"title": [{"text": "Coarse-Grained Sense Annotation of Danish across Textual Domains", "labels": [], "entities": [{"text": "Coarse-Grained Sense Annotation of Danish", "start_pos": 0, "end_pos": 41, "type": "TASK", "confidence": 0.6164770007133484}]}], "abstractContent": [{"text": "We present the results of a coarse-grained sense annotation task on verbs, nouns and adjectives across six textual domains in Danish.", "labels": [], "entities": []}, {"text": "We present the domain-wise differences in intercoder agreement and discuss how the applicability and validity of the sense inventory vary depending on domain.", "labels": [], "entities": [{"text": "validity", "start_pos": 101, "end_pos": 109, "type": "METRIC", "confidence": 0.9830348491668701}]}, {"text": "We find that domain-wise agreement is not higher in very canonical or edited text.", "labels": [], "entities": [{"text": "agreement", "start_pos": 25, "end_pos": 34, "type": "METRIC", "confidence": 0.9228179454803467}]}, {"text": "In fact, newswire text and parliament speeches have lower agreement than blogs and chats, probably because the language of these text types is more complex and uses more abstract concepts.", "labels": [], "entities": [{"text": "agreement", "start_pos": 58, "end_pos": 67, "type": "METRIC", "confidence": 0.9869449734687805}]}, {"text": "We further observe that domains differ in their sense distribution.", "labels": [], "entities": []}, {"text": "For instance, newswire and magazines standout as having a high focus on persons, and discussion fora typically include a restricted number of senses dependent on specialized topics.", "labels": [], "entities": []}, {"text": "We anticipate that these findings can be exploited in automatic sense tagging when dealing with domain shift.", "labels": [], "entities": [{"text": "automatic sense tagging", "start_pos": 54, "end_pos": 77, "type": "TASK", "confidence": 0.6125906010468801}]}], "introductionContent": [{"text": "It is commonly observed that word meanings vary substantially across textual domains, so that an appropriate sense inventory for one domain maybe inappropriate or insufficient for another (.", "labels": [], "entities": []}, {"text": "This essential quality of the lexicon poses a huge challenge to natural language processing and underlines the need for developing systems that are generally less sensitive to domain shifts.", "labels": [], "entities": [{"text": "natural language processing", "start_pos": 64, "end_pos": 91, "type": "TASK", "confidence": 0.7050201495488485}]}, {"text": "The present work is framed within a project that deals with sense inventories of different granularity and across textual domains.", "labels": [], "entities": []}, {"text": "The overall goal is to discover what sense inventories and algorithms are manageable for annotation purposes and useful for automatic sense tagging.", "labels": [], "entities": [{"text": "automatic sense tagging", "start_pos": 124, "end_pos": 147, "type": "TASK", "confidence": 0.5937451322873434}]}, {"text": "In this paper we experiment with coarsegrained annotations, and we analyze how reliable the annotations are and how much they vary over textual domains.", "labels": [], "entities": []}, {"text": "In Section 2 we present the backbone of our scalable sense inventory based on a monolingual dictionary of Danish.", "labels": [], "entities": []}, {"text": "In Sections 3 and 4 we present the data, describing the different corpora, as well as the coarse-grained sense inventory.", "labels": [], "entities": []}, {"text": "In Section 5 we present the differences in inter-coder agreement across the textual domains and discuss how the applicability and validity of the sense inventory vary depending on the kind of textual domain.", "labels": [], "entities": [{"text": "validity", "start_pos": 130, "end_pos": 138, "type": "METRIC", "confidence": 0.9579330086708069}]}, {"text": "Section 6 is devoted to comparisons of the relative frequency of selected supersenses across the six domains, and Section 7 describes the relation between specific senses via pointwise mutual information.", "labels": [], "entities": []}, {"text": "Section 8 provides the conclusion for the article.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 2: Language characteristics of the textual  domains.", "labels": [], "entities": []}, {"text": " Table 3: The standard supersense inventory with the added senses/satellite types in bold.", "labels": [], "entities": []}, {"text": " Table 4: Inter-annotator agreement \u03ba across do- mains together with the percentage of double an- notated files.", "labels": [], "entities": []}, {"text": " Table 6: Mutual information for supersenses.", "labels": [], "entities": []}]}