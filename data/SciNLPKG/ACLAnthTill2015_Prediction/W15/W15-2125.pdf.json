{"title": [{"text": "Evaluation of Two-level Dependency Representations of Argument Structure in Long-Distance Dependencies", "labels": [], "entities": [{"text": "Two-level Dependency Representations of Argument Structure", "start_pos": 14, "end_pos": 72, "type": "TASK", "confidence": 0.671395073334376}]}], "abstractContent": [{"text": "Full recovery of argument structure information for question answering or information extraction requires that parsers can analyse long-distance dependencies.", "labels": [], "entities": [{"text": "question answering", "start_pos": 52, "end_pos": 70, "type": "TASK", "confidence": 0.8304468393325806}, {"text": "information extraction", "start_pos": 74, "end_pos": 96, "type": "TASK", "confidence": 0.7484741508960724}]}, {"text": "Previous work on statistical dependency parsing has used post-processing or additional training data to tackle this complex problem.", "labels": [], "entities": [{"text": "statistical dependency parsing", "start_pos": 17, "end_pos": 47, "type": "TASK", "confidence": 0.7771928509076437}]}, {"text": "We evaluate an alternative approach to recovering long-distance dependencies.", "labels": [], "entities": []}, {"text": "This approach uses a two-level parsing model to recover both grammatical dependencies , such as subject and object, and full argument structure.", "labels": [], "entities": []}, {"text": "We show that this two-level approach is competitive, while also providing useful semantic role information .", "labels": [], "entities": []}], "introductionContent": [{"text": "One of the main motivations for adopting dependency representations in the parsing and computational linguistics community is their direct expression of the lexical-semantic properties of words and their relations.", "labels": [], "entities": [{"text": "parsing and computational linguistics", "start_pos": 75, "end_pos": 112, "type": "TASK", "confidence": 0.8205984383821487}]}, {"text": "Argument structure is the representation of the argument taking properties of a predicate.", "labels": [], "entities": []}, {"text": "It represents those semantic properties of a predicate that are expressed grammatically.", "labels": [], "entities": []}, {"text": "It is usually defined as the specification of the arity of the predicate, its grammatical functions and the substantive labels of the arguments in the structure, what are usually called thematic or semantic roles.", "labels": [], "entities": []}, {"text": "For example the argument structure of the verb hit comprises the specification that hit is a transitive verb and that it takes an AGENT subject and a THEME object.", "labels": [], "entities": [{"text": "AGENT", "start_pos": 130, "end_pos": 135, "type": "METRIC", "confidence": 0.9615444540977478}]}, {"text": "Constructions involving long-distance dependencies (LDDs) -such as questions, or relative clauses -are the stress test of the ability to represent argument structure, because in these constructions argument structure information is not directly reflected in the surface order of the sentence.", "labels": [], "entities": []}, {"text": "Despite the complexity of their representation, report that these constructions cover roughly ten percent of the data in a corpus such as the PennTreebank, and therefore cannot be ignored.", "labels": [], "entities": [{"text": "PennTreebank", "start_pos": 142, "end_pos": 154, "type": "DATASET", "confidence": 0.9867109656333923}]}, {"text": "LDDs are illustrated in Figure 1.", "labels": [], "entities": []}, {"text": "Representing argument structure in longdistance dependency constructions, thus, requires special mechanisms to deal with the divergence between the argument taking properties of the verb and the surface order of the sentence.", "labels": [], "entities": []}, {"text": "The most frequently used ways to encode long-distance dependencies is either by a copy mechanism, shown in, or by turning the tree into a directed graph, shown in.", "labels": [], "entities": []}, {"text": "Many current statistical dependency parsers fail to represent many long-distance dependencies and their related argument structure directly, often because the relevant information, such as traces, has been stripped from the training data.", "labels": [], "entities": [{"text": "statistical dependency parsers", "start_pos": 13, "end_pos": 43, "type": "TASK", "confidence": 0.6472362279891968}]}, {"text": "For example, most current statistical parsers do not represent directly the links drawn below the sentences in.", "labels": [], "entities": []}, {"text": "Moreover, there is no attempt in these representations, to encode the full argument structure directly, as the semantic role labels are usually inferred from their correlation with the grammatical function labels, but not explicitly represented.", "labels": [], "entities": []}, {"text": "The argument structure of the verb spread in the first sentence in comprises a THEME subject in the intransitive form of the verb.", "labels": [], "entities": [{"text": "THEME", "start_pos": 79, "end_pos": 84, "type": "METRIC", "confidence": 0.9643253087997437}]}, {"text": "This argument structure must be inferred indirectly from the graph: first the long-distance nsubj relation must be inferred from a sequence of links typical of subject extraction from an embedded clause.", "labels": [], "entities": []}, {"text": "Moreover, the notion that verbs like spread take THEME subjects in some, but not all cases, is not represented, and therefore the argument structure cannot be, strictly speaking, fully recovered.", "labels": [], "entities": [{"text": "THEME", "start_pos": 49, "end_pos": 54, "type": "METRIC", "confidence": 0.8206313252449036}]}, {"text": "These parsers can recover the long-distance dependency only through a post-processing step, which recovers the information about predicateargument relation and the grammatical function.", "labels": [], "entities": []}, {"text": "The semantic role label is usually not recovered even in post-processing.", "labels": [], "entities": []}, {"text": "We investigate here, then, the hypothesis whether current two-level syntactic-semantic parsers can fill in for the missing information, and recover the long-distance and argument structure information during parsing without need for postprocessing and without loss in performance.", "labels": [], "entities": []}, {"text": "If this were possible, we would be able to produce longdistance dependencies with more direct and perspicuous representations, and also fill in some of the semantic information currently missing from argument structure representations.", "labels": [], "entities": []}, {"text": "It is important to recall that the reason why predicate-argument structure is considered central for NLP applications hinges on the assumption that what needs recovering is the lexical semantics content.", "labels": [], "entities": [{"text": "predicate-argument structure", "start_pos": 46, "end_pos": 74, "type": "TASK", "confidence": 0.7438557147979736}]}, {"text": "For example, it is likely that for information extraction, it is more useful to know which are the manner, temporal and location arguments than to know an underspecified adverbial modifier label.", "labels": [], "entities": [{"text": "information extraction", "start_pos": 35, "end_pos": 57, "type": "TASK", "confidence": 0.8035496771335602}]}, {"text": "In the rest of the paper, then, we will first contrast the one-level representation of long-distance dependencies to a two-level representation, where grammatical functions and argument structure are both explicitly represented.", "labels": [], "entities": []}, {"text": "We will then briefly recall a recently proposed two-level parsing model, and then present the main contribution of the paper: the evaluation of parsing models that parse these twolevel syntactic-semantic dependencies on longdistance dependencies.", "labels": [], "entities": []}, {"text": "We also compare the results to other statistical dependency parsers, investigate the usefulness and informativeness of the extracted information, discuss and conclude.", "labels": [], "entities": [{"text": "statistical dependency parsers", "start_pos": 37, "end_pos": 67, "type": "TASK", "confidence": 0.6105080346266428}]}], "datasetContent": [{"text": "In this section we assess how well the two-level parser performs on constructions involving longdistance dependencies.", "labels": [], "entities": []}, {"text": "In so doing, we verify that these two-level models of syntactic and argument structure representations can be learnt even in difficult cases, while also producing an output that is richer than what statistical parsers usually produce.", "labels": [], "entities": []}, {"text": "To confirm this statement, we expect to see that the syntactic dependency parsing performance is not degraded, compared to more standard statistical parsing architectures on long-distance dependencies, while also producing semantic role labels on these difficult constructions.", "labels": [], "entities": [{"text": "syntactic dependency parsing", "start_pos": 53, "end_pos": 81, "type": "TASK", "confidence": 0.6061946054299673}]}, {"text": "Like in previous papers (, we evaluate the parser on its ability to recover LDDs.", "labels": [], "entities": []}, {"text": "The first one was semi-automatic, performed with a modified version of the evaluation script developed in.", "labels": [], "entities": []}, {"text": "An independent manual evaluation was also performed.", "labels": [], "entities": []}, {"text": "A dependency is considered correctly recovered if a dependency in the gold data is found in the output.", "labels": [], "entities": []}, {"text": "A dependency is a triple comprising three items: the nodes connected by the arc in the graph and the label of the arc.", "labels": [], "entities": []}, {"text": "In principle, a dependency is considered correct if all three elements of the triple are correct.", "labels": [], "entities": []}, {"text": "However, in this evaluation the representations vary across models and exact matches would not allow a fair assessment.", "labels": [], "entities": []}, {"text": "Both previous evaluation exercises ( suggest some avenues to relax the matching conditions, and define equivalence classes of representations.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Our percent recall results, construction by construction, automatic and manual (A/M), compared  to some of the results reported in Rimell et al. (2009) and Nivre et al. (2010). Abbreviations are explained  in subsection 4.1. Right node raising was evaluated only manually.", "labels": [], "entities": [{"text": "recall", "start_pos": 22, "end_pos": 28, "type": "METRIC", "confidence": 0.972633957862854}, {"text": "Abbreviations", "start_pos": 187, "end_pos": 200, "type": "METRIC", "confidence": 0.9761198163032532}, {"text": "Right node raising", "start_pos": 235, "end_pos": 253, "type": "TASK", "confidence": 0.6152720848719279}]}, {"text": " Table 3: Distribution of error types in the develop- ment sets. (G= Global; S= Sem; SA= Sem+Arg;  L= Link; Dep= number of dependencies).", "labels": [], "entities": []}, {"text": " Table 4: Comparison of the three dependency  parsers based on the total number of errors in each  development set.", "labels": [], "entities": []}]}