{"title": [{"text": "Improving Twitter Named Entity Recognition using Word Representations", "labels": [], "entities": [{"text": "Improving Twitter Named Entity Recognition", "start_pos": 0, "end_pos": 42, "type": "TASK", "confidence": 0.8803467273712158}]}], "abstractContent": [{"text": "This paper describes our system used in the ACL 2015 Workshop on Noisy User-generated Text Shared Task for Named Entity Recognition (NER) in Twitter.", "labels": [], "entities": [{"text": "ACL 2015 Workshop on Noisy User-generated Text Shared Task for Named Entity Recognition (NER) in Twitter", "start_pos": 44, "end_pos": 148, "type": "TASK", "confidence": 0.6335384448369344}]}, {"text": "Our system uses Conditional Random Fields to train two separate classifiers for the two evaluations: predicting 10 fine-grained types, and segmenting named entities.", "labels": [], "entities": [{"text": "predicting 10 fine-grained types", "start_pos": 101, "end_pos": 133, "type": "TASK", "confidence": 0.835521787405014}]}, {"text": "We focus our efforts on generating word representations from large amount of unla-beled newswire data and tweets.", "labels": [], "entities": []}, {"text": "Our experiment results show that cluster features derived from word representations significantly improve Twitter NER performances.", "labels": [], "entities": [{"text": "Twitter NER", "start_pos": 106, "end_pos": 117, "type": "TASK", "confidence": 0.5049595683813095}]}, {"text": "Our system is ranked 2nd for both evaluations.", "labels": [], "entities": []}], "introductionContent": [{"text": "Named Entity Recognition (NER) is the task of identifying and categorizing the various mentions of people, organizations and other named entities within the text.", "labels": [], "entities": [{"text": "Named Entity Recognition (NER)", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.7776608715454737}]}, {"text": "NER has been an essential analysis component in many Natural Language Processing (NLP) systems, especially information extraction and question answering.", "labels": [], "entities": [{"text": "NER", "start_pos": 0, "end_pos": 3, "type": "TASK", "confidence": 0.8799541592597961}, {"text": "information extraction", "start_pos": 107, "end_pos": 129, "type": "TASK", "confidence": 0.8194380104541779}, {"text": "question answering", "start_pos": 134, "end_pos": 152, "type": "TASK", "confidence": 0.8864050805568695}]}, {"text": "Traditionally, the NER system is trained and applied on long and formal text such as the newswire.", "labels": [], "entities": []}, {"text": "From the beginning of the new millennium, user-generated content from the social media websites such as Twitter and Weibo presents a huge compilation of informative but noisy and informal text.", "labels": [], "entities": []}, {"text": "This rapidly growing text collection becomes more and more important for NLP tasks such as sentiment analysis and emerging topic detection.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 91, "end_pos": 109, "type": "TASK", "confidence": 0.9738415777683258}, {"text": "emerging topic detection", "start_pos": 114, "end_pos": 138, "type": "TASK", "confidence": 0.6329691310723623}]}, {"text": "However, standard NER system trained on formal text does notwork well on this new and challenging style of text.", "labels": [], "entities": []}, {"text": "Therefore, adapting the NER system to the new and challenging Twitter domain has attracted increasing attention of researchers.", "labels": [], "entities": []}, {"text": "The ACL 2015 Workshop on Noisy User-generated Text (W-NUT) Shared Task for NER in Twitter is organized in response to these new changes.", "labels": [], "entities": [{"text": "ACL 2015 Workshop on Noisy User-generated Text (W-NUT) Shared Task", "start_pos": 4, "end_pos": 70, "type": "TASK", "confidence": 0.5631371115644773}]}, {"text": "We participated in the above Shared Task, which consists of two separate evaluations: one where the task is to predict 10 fine-grained types (10types) and the other in which only named entity segments are predicted (notypes).", "labels": [], "entities": []}, {"text": "For both evaluations, we model the problem as a sequential labeling task, using Conditional Random Fields (CRF) as the training algorithm.", "labels": [], "entities": []}, {"text": "An additional postprocessing step is applied to further refine the system output.", "labels": [], "entities": []}, {"text": "The remainder of this paper is structured as follows.", "labels": [], "entities": []}, {"text": "In Section 2, we report on the external resources used by our system and how they are obtained and processed.", "labels": [], "entities": []}, {"text": "In Section 3, the features used are described in details.", "labels": [], "entities": []}, {"text": "In Section 4, the experiment and official results are presented.", "labels": [], "entities": []}, {"text": "Finally, Section 5 summarizes our work.", "labels": [], "entities": []}], "datasetContent": [{"text": "Our system is trained using the CRF++ tool 8 . We trained separate classifiers for the two different evaluations (10types and notypes).", "labels": [], "entities": [{"text": "CRF++ tool 8", "start_pos": 32, "end_pos": 44, "type": "DATASET", "confidence": 0.8983942568302155}]}, {"text": "To select the optimum settings, we make use of all available training data (train, dev, dev_2015) and conduct 5-fold cross validation experiments.", "labels": [], "entities": []}, {"text": "For easier comparisons with other systems, the 5 folds are split such that dev is the test set for Fold 1, while dev_2015 is the test set for Fold 5.", "labels": [], "entities": [{"text": "Fold", "start_pos": 99, "end_pos": 103, "type": "DATASET", "confidence": 0.8195723295211792}]}, {"text": "shows the 5-fold cross validation performances after adding each feature group for the 10types and notypes evaluations respectively.", "labels": [], "entities": []}, {"text": "The use of word clusters significantly improves the performances for both evaluations.", "labels": [], "entities": []}, {"text": "There is an overall improvement of 13% and 9% for the 10types and notypes evaluation respectively when word cluster features are added.", "labels": [], "entities": []}, {"text": "This demonstrates the usefulness of word vectors in improving the accuracy of a Twitter NER system.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 66, "end_pos": 74, "type": "METRIC", "confidence": 0.9989257454872131}]}], "tableCaptions": [{"text": " Table 1: 5-fold cross-validation F1 performances for the 10types evaluation. Each row uses all features  added in the previous rows.", "labels": [], "entities": [{"text": "F1", "start_pos": 34, "end_pos": 36, "type": "METRIC", "confidence": 0.9725502729415894}]}, {"text": " Table 2: 5-fold cross-validation F1 performances for the notypes evaluation. Each row uses all features  added in the previous rows.", "labels": [], "entities": [{"text": "F1", "start_pos": 34, "end_pos": 36, "type": "METRIC", "confidence": 0.9747781157493591}]}, {"text": " Table 3: Comparison of our system (NLANGP) with the top three participating systems and official  baselines for the 10types and notypes evaluations.", "labels": [], "entities": []}, {"text": " Table 4: System performances on the test data when word cluster features are not used.", "labels": [], "entities": []}, {"text": " Table 5: Performance of each fine-grained type of  our system.", "labels": [], "entities": []}]}