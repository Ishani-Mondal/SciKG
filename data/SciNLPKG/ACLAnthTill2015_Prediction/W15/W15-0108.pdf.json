{"title": [{"text": "Obtaining a Better Understanding of Distributional Models of German Derivational Morphology", "labels": [], "entities": [{"text": "Obtaining", "start_pos": 0, "end_pos": 9, "type": "TASK", "confidence": 0.8602744340896606}]}], "abstractContent": [{"text": "Predicting the (distributional) meaning of derivationally related words (read / read+er) from one another has recently been recognized as an instance of distributional compositional meaning construction.", "labels": [], "entities": [{"text": "Predicting the (distributional) meaning of derivationally related words (read / read", "start_pos": 0, "end_pos": 84, "type": "TASK", "confidence": 0.7202501211847577}, {"text": "distributional compositional meaning construction", "start_pos": 153, "end_pos": 202, "type": "TASK", "confidence": 0.7060999572277069}]}, {"text": "However, the properties of this task are not yet well understood.", "labels": [], "entities": []}, {"text": "In this paper, we present an analysis of two such composition models on a set of German derivation patterns (e.g.,-in, durch-).", "labels": [], "entities": []}, {"text": "We begin by introducing a rank-based evaluation metric, which reveals the task to be challenging due to specific properties of German (compounding, capitalization).", "labels": [], "entities": []}, {"text": "We also find that performance varies greatly between patterns and even among base-derived term pairs of the same pattern.", "labels": [], "entities": []}, {"text": "A regression analysis shows that semantic coherence of the base and derived terms within a pattern, as well as coherence of the semantic shifts from base to derived terms, all significantly impact prediction quality.", "labels": [], "entities": []}], "introductionContent": [{"text": "Derivation is a major morphological process of word formation (e.g., read \u2192 read+er), which is typically associated with a fairly specific semantic shift (+er: agentivization).", "labels": [], "entities": [{"text": "word formation", "start_pos": 47, "end_pos": 61, "type": "TASK", "confidence": 0.7118518948554993}]}, {"text": "It may therefore be surprising that the semantics of derivation is a relatively understudied phenomenon in distributional semantics.", "labels": [], "entities": []}, {"text": "Recently, proposed to consider the semantics of a derived term like read+er as the result of a compositional process that combines the meanings of the base term read and the affix +er.", "labels": [], "entities": []}, {"text": "This puts derivation into the purview of compositional distributional semantic models (CDSMs).", "labels": [], "entities": []}, {"text": "CDSMs are normally used to compute the meaning of phrases and sentences by combining distributional representations of the individual words.", "labels": [], "entities": []}, {"text": "A first generation of CDSMs represented all words as vectors and modeled composition as vector combination.", "labels": [], "entities": []}, {"text": "A second generation represents the meaning of predicates as higher-order algebraic objects such as matrices and tensors, which are combined using various composition operations.", "labels": [], "entities": []}, {"text": "Lazaridou et al. predict vectors for derived terms and evaluate their approach on a set of English derivation patterns.", "labels": [], "entities": []}, {"text": "Building on and extending their analysis, we turn to German derivation patterns and offer both qualitative and quantitative analyses of two composition models on a state-of-the-art vector space, with the aim of better understanding where these models work well and where they fail.", "labels": [], "entities": []}, {"text": "Our contributions are as follows.", "labels": [], "entities": []}, {"text": "First, we perform all analyses in parallel for six derivation patterns (two each for nouns, adjectives, and verbs).", "labels": [], "entities": []}, {"text": "This provides new insights, as we can cross-reference results from individual analyses.", "labels": [], "entities": []}, {"text": "Secondly, we evaluate using a rank-based metric, allowing for better assessment of the practical utility of these models.", "labels": [], "entities": []}, {"text": "Thirdly, we construct a regression model that is able to explain performance differences among patterns and word pairs in terms of differences in semantic coherence.", "labels": [], "entities": []}], "datasetContent": [{"text": "We build a vector space from the SdeWaC corpus, part-of-speech tagged and lemmatized using TreeTagger.", "labels": [], "entities": [{"text": "SdeWaC corpus", "start_pos": 33, "end_pos": 46, "type": "DATASET", "confidence": 0.8362449109554291}]}, {"text": "To alleviate sparsity arising from TreeTagger's lexicon-driven lemmatization, we back off for unrecognized words to the MATE Tools, which have higher recall but lower precision than TreeTagger.", "labels": [], "entities": [{"text": "MATE Tools", "start_pos": 120, "end_pos": 130, "type": "DATASET", "confidence": 0.7879749834537506}, {"text": "recall", "start_pos": 150, "end_pos": 156, "type": "METRIC", "confidence": 0.9947212934494019}, {"text": "precision", "start_pos": 167, "end_pos": 176, "type": "METRIC", "confidence": 0.9958190321922302}]}, {"text": "We also reconstruct lemmas for separated prefix verbs based on the MATE dependency analysis.", "labels": [], "entities": [{"text": "MATE dependency", "start_pos": 67, "end_pos": 82, "type": "TASK", "confidence": 0.4645174741744995}]}, {"text": "Finally, we get a word list with 289,946 types (content words only).", "labels": [], "entities": []}, {"text": "From the corpus, we extract lemmatized sentences and train a state-of-the art predictive model, namely CBOW ( . This model builds distributed word vectors by learning to predict the current word based on a context.", "labels": [], "entities": []}, {"text": "We use lemma-POS pairs as both target and context elements, 300 dimensions, negative sampling set to 15, and no hierarchical softmax.", "labels": [], "entities": []}, {"text": "Selected patterns and word pairs.", "labels": [], "entities": []}, {"text": "We investigate six derivation patterns in German and the word pairs associated with them in DErivBase (see).", "labels": [], "entities": [{"text": "DErivBase", "start_pos": 92, "end_pos": 101, "type": "DATASET", "confidence": 0.9313353300094604}]}, {"text": "We consider only patterns where base and derived terms have the same POS, and we prefer patterns encoding straightforward semantic shifts.", "labels": [], "entities": [{"text": "POS", "start_pos": 69, "end_pos": 72, "type": "METRIC", "confidence": 0.9697321653366089}]}, {"text": "Such patterns tend to encode meaning shifts without corresponding argument structure changes; thus they are represented appropriately in composition models based on purely lexical vector spaces.", "labels": [], "entities": []}, {"text": "Per pattern, we randomly select 80 word pairs for which both base and derived lemmas appear at least 20 times in SdeWaC.: Derivation patterns, representative examples (and translations), and prediction performance in terms of R oof percentages and mean similarity between derived and gold vectors, 10-fold cross-validation.", "labels": [], "entities": []}], "tableCaptions": []}