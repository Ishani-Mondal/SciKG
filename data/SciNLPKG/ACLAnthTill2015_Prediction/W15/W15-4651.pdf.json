{"title": [{"text": "User Adaptive Restoration for Incorrectly Segmented Utterances in Spoken Dialogue Systems", "labels": [], "entities": [{"text": "User Adaptive Restoration", "start_pos": 0, "end_pos": 25, "type": "TASK", "confidence": 0.6788984934488932}, {"text": "Incorrectly Segmented Utterances", "start_pos": 30, "end_pos": 62, "type": "TASK", "confidence": 0.6403656204541525}]}], "abstractContent": [{"text": "Ideally, the users of spoken dialogue systems should be able to speak at their own tempo.", "labels": [], "entities": []}, {"text": "The systems thus need to correctly interpret utterances from various users, even when these utterances contain disflu-ency.", "labels": [], "entities": []}, {"text": "In response to this issue, we propose an approach based on a posteriori restoration for incorrectly segmented utterances.", "labels": [], "entities": []}, {"text": "A crucial part of this approach is to classify whether restoration is required or not.", "labels": [], "entities": []}, {"text": "We improve the accuracy by adapting the classifier to each user.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 15, "end_pos": 23, "type": "METRIC", "confidence": 0.9993764758110046}]}, {"text": "We focus on the dialogue tempo of each user, which can be obtained during dialogues, and determine the correlation between each user's tempo and the appropriate thresholds for the classification.", "labels": [], "entities": []}, {"text": "A linear regression function used to convert the tempos into thresholds is also derived.", "labels": [], "entities": []}, {"text": "Experimental results showed that the proposed user adaptation for two classifiers, thresholding and decision tree, improved the classification accuracies by 3.0% and 7.4%, respectively, in tenfold cross validation.", "labels": [], "entities": [{"text": "accuracies", "start_pos": 143, "end_pos": 153, "type": "METRIC", "confidence": 0.7980466485023499}]}], "introductionContent": [{"text": "To make spoken dialogue systems more userfriendly, users need to be able to speak at their own tempo.", "labels": [], "entities": []}, {"text": "Even though not all users speak fluently, i.e., some speak slowly and with disfluency, conventional systems basically assume that a user says one utterance with no pause.", "labels": [], "entities": []}, {"text": "Systems need to handle utterances by both novice users who speak slowly and experienced users who want the systems to reply quickly.", "labels": [], "entities": []}, {"text": "We propose a method for spoken dialogue systems to interpret user utterances adaptively in terms of utterance units.", "labels": [], "entities": []}, {"text": "We adopt an approach based on our a posteriori restoration for incorrectly segmented utterances ( ).", "labels": [], "entities": []}, {"text": "The proposed system responds quickly while also interpreting utterance fragments by concatenating them when a user speaks with disfluency or speaks slowly with pauses.", "labels": [], "entities": [{"text": "interpreting utterance fragments", "start_pos": 48, "end_pos": 80, "type": "TASK", "confidence": 0.8403703769048055}]}, {"text": "Another approach for this issue is to adaptively change the parameters of voice activity detection (VAD) for each user during dialogues, but automatic speech recognition (ASR) engines with such adaptive control are uncommon, and implementing an online-adaptive VAD module is difficult.", "labels": [], "entities": [{"text": "voice activity detection (VAD)", "start_pos": 74, "end_pos": 104, "type": "TASK", "confidence": 0.7795085112253824}, {"text": "automatic speech recognition (ASR)", "start_pos": 141, "end_pos": 175, "type": "TASK", "confidence": 0.8102758924166361}]}, {"text": "Our a posteriori restoration approach does not require changing ASR engines, and the system can restore interpretation of user utterances after ASR results are obtained.", "labels": [], "entities": [{"text": "ASR", "start_pos": 64, "end_pos": 67, "type": "TASK", "confidence": 0.9472241997718811}]}, {"text": "Our a posteriori restoration approach needs to classify whether two utterance fragments close in time need to be interpreted together or not, i.e., whether these are two different utterances or a single utterance incorrectly segmented by VAD.", "labels": [], "entities": [{"text": "a posteriori restoration", "start_pos": 4, "end_pos": 28, "type": "TASK", "confidence": 0.6944554448127747}, {"text": "VAD", "start_pos": 238, "end_pos": 241, "type": "METRIC", "confidence": 0.7620773911476135}]}, {"text": "If these need to be interpreted separately, the system normally responds to the two fragments on the basis of their ASR results.", "labels": [], "entities": [{"text": "ASR", "start_pos": 116, "end_pos": 119, "type": "TASK", "confidence": 0.7999892234802246}]}, {"text": "If they need to be interpreted together, the system immediately stops its response to the first fragment, concatenates the two segments, and then interprets it.", "labels": [], "entities": []}, {"text": "Misclassification causes erroneous system responses.", "labels": [], "entities": []}, {"text": "If the system incorrectly classifies the restoration as not being required, its response often becomes erroneous because the original user utterance is interrupted in its middle.", "labels": [], "entities": []}, {"text": "If the system classifies the restoration as being required even though it is actually not, the system takes an unnecessarily longtime before it starts responding, and its response tends to be erroneous because an unnecessary part is attached to the actual utterance.", "labels": [], "entities": []}, {"text": "We adapt the classification to each user and show through experiments that the adaptation improves classification accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 114, "end_pos": 122, "type": "METRIC", "confidence": 0.9240109920501709}]}, {"text": "We focus on the tempo of each user and use it to adapt the classifier.", "labels": [], "entities": []}, {"text": "Since the temporal interval between two utterance fragments is an important parameter in the classifier ( ), we adapt its threshold to user behaviors obtained during the dialogue.", "labels": [], "entities": []}], "datasetContent": [{"text": "We investigated whether the user adaptation contributes to improving the classification accuracy.", "labels": [], "entities": [{"text": "classification", "start_pos": 73, "end_pos": 87, "type": "TASK", "confidence": 0.9579373002052307}, {"text": "accuracy", "start_pos": 88, "end_pos": 96, "type": "METRIC", "confidence": 0.9492920637130737}]}, {"text": "We also experimentally checked the upper limit and convergence speed of the proposed adaptation by comparing the accuracy with its batch version, in which all utterance data from a target user is assumed to be always available.", "labels": [], "entities": [{"text": "convergence", "start_pos": 51, "end_pos": 62, "type": "METRIC", "confidence": 0.9560406804084778}, {"text": "accuracy", "start_pos": 113, "end_pos": 121, "type": "METRIC", "confidence": 0.9996434450149536}]}], "tableCaptions": [{"text": " Table 1: Deviation of parameters in linear regres- sion function.  a  b  Avg.  0.883 \u22120.431  Std. dev. 0.034  0.057", "labels": [], "entities": []}]}