{"title": [{"text": "Clinical Abbreviation Disambiguation Using Neural Word Embeddings", "labels": [], "entities": [{"text": "Clinical Abbreviation Disambiguation", "start_pos": 0, "end_pos": 36, "type": "TASK", "confidence": 0.48878129323323566}]}], "abstractContent": [{"text": "This study examined the use of neural word embeddings for clinical abbreviation disambiguation, a special case of word sense disambiguation (WSD).", "labels": [], "entities": [{"text": "clinical abbreviation disambiguation", "start_pos": 58, "end_pos": 94, "type": "TASK", "confidence": 0.611634224653244}, {"text": "word sense disambiguation (WSD)", "start_pos": 114, "end_pos": 145, "type": "TASK", "confidence": 0.7639793207248052}]}, {"text": "We investigated three different methods for deriving word embeddings from a large unlabeled clinical corpus: one existing method called Surrounding based embedding feature (SBE), and two newly developed methods: Left-Right surrounding based embedding feature (LR_SBE) and MAX surrounding based embedding feature (MAX_SBE).", "labels": [], "entities": []}, {"text": "We then added these word embeddings as additional features to a Support Vector Machines (SVM) based WSD system.", "labels": [], "entities": []}, {"text": "Evaluation using the clinical abbreviation datasets from both the Vanderbilt University and the University of Minnesota showed that neural word embedding features improved the performance of the SVM-based clinical abbreviation disambigua-tion system.", "labels": [], "entities": [{"text": "SVM-based clinical abbreviation disambigua-tion", "start_pos": 195, "end_pos": 242, "type": "TASK", "confidence": 0.6511400416493416}]}, {"text": "More specifically, the new MAX_SBE method outperformed the other two methods and achieved the state-of-the-art performance on both clinical abbreviation datasets.", "labels": [], "entities": [{"text": "MAX_SBE", "start_pos": 27, "end_pos": 34, "type": "TASK", "confidence": 0.4075119694073995}]}], "introductionContent": [{"text": "Abbreviations are frequently used in clinical notes and often represent important clinical concepts such as diseases and procedures.", "labels": [], "entities": [{"text": "Abbreviations", "start_pos": 0, "end_pos": 13, "type": "METRIC", "confidence": 0.9527072310447693}]}, {"text": "However, it is still challenging to handle clinical abbreviations.", "labels": [], "entities": []}, {"text": "Ina previous study (), we examined three widely used clinical Natural Language Processing (NLP) systems and found that all of them have limited capability to accurately identify clinical abbreviations, especially for ambiguous abbreviations (abbreviations with multiple senses, e.g., \"pt\" can represent \"patient\" or \"physical therapy\").", "labels": [], "entities": []}, {"text": "The prevalence of ambiguous clinical abbreviations is very high.", "labels": [], "entities": [{"text": "prevalence", "start_pos": 4, "end_pos": 14, "type": "METRIC", "confidence": 0.9705943465232849}]}, {"text": "A study () examining the abbreviations in the Unified Medical Language System (UMLS) reported that 33.1% of them have more than one sense.", "labels": [], "entities": [{"text": "Unified Medical Language System (UMLS)", "start_pos": 46, "end_pos": 84, "type": "DATASET", "confidence": 0.6228864022663662}]}, {"text": "In reality, the ambiguity problem of clinical abbreviations could be even higher, as existing knowledge bases (e.g., the UMLS) have low coverage of abbreviations' senses (around 38% to 50%) (.", "labels": [], "entities": [{"text": "UMLS", "start_pos": 121, "end_pos": 125, "type": "DATASET", "confidence": 0.9528014659881592}]}, {"text": "Clinical abbreviation disambiguation is a particular case of the Word Sense Disambiguation (WSD), which is to \"computationally determine which sense of a word is activated by its context\".", "labels": [], "entities": [{"text": "Clinical abbreviation disambiguation", "start_pos": 0, "end_pos": 36, "type": "TASK", "confidence": 0.5764520863691965}, {"text": "Word Sense Disambiguation (WSD)", "start_pos": 65, "end_pos": 96, "type": "TASK", "confidence": 0.7212936381498972}]}, {"text": "WSD has been extensively studied in the field of NLP ().", "labels": [], "entities": [{"text": "WSD", "start_pos": 0, "end_pos": 3, "type": "TASK", "confidence": 0.7576756477355957}]}, {"text": "Researchers have developed different WSD methods including knowledge-based methods, supervised machine learning methods ( and unsupervised machine learning based methods ( for general English text.", "labels": [], "entities": [{"text": "WSD", "start_pos": 37, "end_pos": 40, "type": "TASK", "confidence": 0.979536771774292}]}, {"text": "As the intrinsic linguistic essentials shared in between, researchers have applied similar methods to biomedical literature and clinical text ().", "labels": [], "entities": []}, {"text": "For example, researchers have conducted studies to disambiguate important entities in biomedical literature, such as gene names.)", "labels": [], "entities": []}, {"text": "Much work has been done for disambiguation of abbreviations in clinical text (.", "labels": [], "entities": [{"text": "disambiguation of abbreviations in clinical text", "start_pos": 28, "end_pos": 76, "type": "TASK", "confidence": 0.8071448902289072}]}, {"text": "Various types of WSD approaches have been proposed for clinical abbreviations, including traditional supervised machine learning based approaches with optimized features (), vector space model based methods, algorithms based on hyper-dimensional computing, as well as recent unsupervised methods based on topic-modeling-based approaches).", "labels": [], "entities": [{"text": "WSD", "start_pos": 17, "end_pos": 20, "type": "TASK", "confidence": 0.9250651001930237}]}, {"text": "Furthermore, there is also a study to recognize and disambiguate abbreviations in real-time when physicians are authorizing the notes.", "labels": [], "entities": []}, {"text": "Among all these methods, supervised machine learning methods often show good performances, when annotated corpora are available (.", "labels": [], "entities": []}, {"text": "A few studies have proposed methods to automatically generate \"pseudo\" training corpus from biomedical/clinical text, by replacing the expanded long forms by their corresponding abbreviations ()).", "labels": [], "entities": []}, {"text": "In the recent 2013 Share/CLEF challenge on clinical abbreviation normalization), a hybrid system developed by our group, which combines the supervised machine learning method, the profile-based method, as well as existing knowledge bases achieved the best performance.", "labels": [], "entities": [{"text": "Share/CLEF challenge on clinical abbreviation normalization", "start_pos": 19, "end_pos": 78, "type": "TASK", "confidence": 0.5680862590670586}]}, {"text": "Over the last few years, there has been increasing interest in training word embeddings from large unlabeled corpora using deep neural networks.", "labels": [], "entities": []}, {"text": "Word embedding is typically represented as a dense real-valued low dimensional matrix M of size V\u00d7D, where V is the vocabulary size and Dis the predefined embedding dimension.", "labels": [], "entities": []}, {"text": "Each row of the matrix is associated with a word in the vocabulary, and each column of the matrix represents a latent feature.", "labels": [], "entities": []}, {"text": "Several neural network based training algorithms have been proposed.", "labels": [], "entities": []}, {"text": "Bengio () and Mikolov ( proposed algorithms to train word embeddings by maximizing the probability of a word given by the previous word.) proposed a neural network to train word embeddings using ranking lost criteria with negative sampling.", "labels": [], "entities": []}, {"text": "The experimental results showed that the ranking based word embeddings derived from the entire English Wikipedia corpus greatly improved a number of NLP tasks in the general English text.", "labels": [], "entities": [{"text": "English Wikipedia corpus", "start_pos": 95, "end_pos": 119, "type": "DATASET", "confidence": 0.7106185058752695}]}, {"text": "Previous studies have found that the neural word embeddings could represent abundant semantic meanings in the real-valued matrix, which could be useful features for different NLP tasks including WSD.", "labels": [], "entities": [{"text": "WSD", "start_pos": 195, "end_pos": 198, "type": "TASK", "confidence": 0.7636170387268066}]}, {"text": "In 2014,) proposed two methods to derive word embedding features for WSD, including the \"TF-IDF based Embedding\" (TBE) feature, and the \"Surrounding Based Embedding\" (SBE) feature.", "labels": [], "entities": []}, {"text": "The experimental results on the MSH collection data and the WISE collection data showed that the SBE method achieved better performance.", "labels": [], "entities": [{"text": "MSH collection data", "start_pos": 32, "end_pos": 51, "type": "DATASET", "confidence": 0.9323315223058065}, {"text": "WISE collection data", "start_pos": 60, "end_pos": 80, "type": "DATASET", "confidence": 0.9814332127571106}, {"text": "SBE", "start_pos": 97, "end_pos": 100, "type": "TASK", "confidence": 0.8915328979492188}]}, {"text": "In the biomedical domain,) used the popular word2vec package to generate word embeddings and showed that the word embedding features improved the F1-score of a baseline NER system by 0.49% (from 70.0% to 70.49%).", "labels": [], "entities": [{"text": "F1-score", "start_pos": 146, "end_pos": 154, "type": "METRIC", "confidence": 0.998620867729187}]}, {"text": "Nevertheless, there is no study that investigates the use of neural word embeddings for WSD in the medical domain, i.e., clinical abbreviation disambiguation.", "labels": [], "entities": [{"text": "WSD", "start_pos": 88, "end_pos": 91, "type": "TASK", "confidence": 0.94793301820755}, {"text": "clinical abbreviation disambiguation", "start_pos": 121, "end_pos": 157, "type": "TASK", "confidence": 0.5956381956736246}]}, {"text": "In this study, we developed two new word embeddings methods to generate WSD features from a large unlabeled clinical corpus.", "labels": [], "entities": [{"text": "WSD", "start_pos": 72, "end_pos": 75, "type": "TASK", "confidence": 0.9271304607391357}]}, {"text": "We compared them with the existing SBE method proposed by Li et al. for disambiguation of clinical abbreviations in two datasets from Vanderbilt University and the University of Minnesota.", "labels": [], "entities": []}, {"text": "Our results showed that clinical abbreviation disambiguation could benefit from a much larger unlabeled corpus and our newly developed embedding features outperformed the SBE.", "labels": [], "entities": [{"text": "clinical abbreviation disambiguation", "start_pos": 24, "end_pos": 60, "type": "TASK", "confidence": 0.6774498124917349}]}, {"text": "To the best of our knowledge, this is the first study using the word embeddings trained from a large unlabeled clinical corpus to improve the performance of clinical abbreviation disambiguation methods.", "labels": [], "entities": [{"text": "clinical abbreviation disambiguation", "start_pos": 157, "end_pos": 193, "type": "TASK", "confidence": 0.6223629713058472}]}], "datasetContent": [{"text": "This study used the annotated abbreviation datasets from the Vanderbilt University Hospital's (VUH) admission notes, as well as the clinical notes from the University of Minnesota-affiliated (UMN) Fairview Health Services in the Twin Cities.", "labels": [], "entities": [{"text": "Vanderbilt University Hospital's (VUH) admission notes", "start_pos": 61, "end_pos": 115, "type": "DATASET", "confidence": 0.9126148356331719}]}, {"text": "The VUH dataset contains 25 abbreviations.", "labels": [], "entities": [{"text": "VUH dataset", "start_pos": 4, "end_pos": 15, "type": "DATASET", "confidence": 0.9882876574993134}]}, {"text": "For each abbreviation, up to 200 sentences containing the abbreviation were randomly selected and manually annotated by domain experts.", "labels": [], "entities": []}, {"text": "The UMN dataset contains 75 abbreviations and 500 sentences were randomly selected and annotated for each abbreviation.", "labels": [], "entities": [{"text": "UMN dataset", "start_pos": 4, "end_pos": 15, "type": "DATASET", "confidence": 0.9651035368442535}]}, {"text": "Detailed information for the two datasets can be found in) We used the implementation of SVMs in the libsvm package a . The details of the SVMbased WSD system can be found in our previous study (Wu, Denny, et al., 2013).", "labels": [], "entities": []}, {"text": "We implemented the neural network based word embedding algorithm from) and trained the word embedding matrix on the unlabeled MIMIC II corpus.", "labels": [], "entities": [{"text": "MIMIC II corpus", "start_pos": 126, "end_pos": 141, "type": "DATASET", "confidence": 0.9220728874206543}]}, {"text": "We used the suggested parameters to train the neural network with a hidden layer size of 300, a fixed learning rate of 0.01, and an embedding dimension of 50.", "labels": [], "entities": [{"text": "learning rate", "start_pos": 102, "end_pos": 115, "type": "METRIC", "confidence": 0.9229355752468109}]}, {"text": "For each abbreviation in a dataset, we trained an SVMs model using the conventional features as the baseline, where the model parameters and the window size were optimized by 10-fold cross validation.", "labels": [], "entities": []}, {"text": "To reduce the parameter tuning effort, we select a set of unified model parameters for all the abbreviations.", "labels": [], "entities": [{"text": "parameter tuning", "start_pos": 14, "end_pos": 30, "type": "TASK", "confidence": 0.7018818110227585}]}, {"text": "To assess the effect of word embedding features, we added each type of word embedding features (SBE, LR_SBE, or MAX_SBE) to the conventional features and then re-trained the SVM classifier using the optimized parameters.", "labels": [], "entities": []}, {"text": "We then reported the (Macro) average accuracy across all abbreviations in either the VUH dataset or the UMN dataset based on the results from 10-fold cross validation..", "labels": [], "entities": [{"text": "accuracy", "start_pos": 37, "end_pos": 45, "type": "METRIC", "confidence": 0.9498609900474548}, {"text": "VUH dataset", "start_pos": 85, "end_pos": 96, "type": "DATASET", "confidence": 0.9891127049922943}, {"text": "UMN dataset", "start_pos": 104, "end_pos": 115, "type": "DATASET", "confidence": 0.974047064781189}]}, {"text": "Average accuracy of the WSD systems using different word embedding features on both VUH and UMN datasets According to 10-fold cross validation, we set the optimized window size of 3 for both datasets.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 8, "end_pos": 16, "type": "METRIC", "confidence": 0.9995853304862976}, {"text": "VUH", "start_pos": 84, "end_pos": 87, "type": "DATASET", "confidence": 0.9401089549064636}, {"text": "UMN datasets", "start_pos": 92, "end_pos": 104, "type": "DATASET", "confidence": 0.7882043719291687}]}, {"text": "shows the macro average accuracy of using different embedding features on the VUH and the UMN abbreviation datasets.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 24, "end_pos": 32, "type": "METRIC", "confidence": 0.9441421627998352}, {"text": "VUH", "start_pos": 78, "end_pos": 81, "type": "DATASET", "confidence": 0.9748275876045227}, {"text": "UMN abbreviation datasets", "start_pos": 90, "end_pos": 115, "type": "DATASET", "confidence": 0.9112735390663147}]}, {"text": "The baseline system (SVMs classifier using conventional features) achieved an accuracy of 92.19% and an accuracy of 94.97% on the VUH and the UMN dataset, respectively.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 78, "end_pos": 86, "type": "METRIC", "confidence": 0.9994997978210449}, {"text": "accuracy", "start_pos": 104, "end_pos": 112, "type": "METRIC", "confidence": 0.9993427395820618}, {"text": "VUH", "start_pos": 130, "end_pos": 133, "type": "DATASET", "confidence": 0.9719263911247253}, {"text": "UMN dataset", "start_pos": 142, "end_pos": 153, "type": "DATASET", "confidence": 0.9592134654521942}]}, {"text": "The baseline performance on the VUH dataset is lower than that in the UMN dataset.", "labels": [], "entities": [{"text": "VUH dataset", "start_pos": 32, "end_pos": 43, "type": "DATASET", "confidence": 0.9595283567905426}, {"text": "UMN dataset", "start_pos": 70, "end_pos": 81, "type": "DATASET", "confidence": 0.9395014941692352}]}, {"text": "All three types of embedding features (SBE, LR_SBE, and MAX_SBE) improved the average accuracy when compared with the baseline system, with improvements of 0.51%, 0.67, 0.82% for the VUH dataset and 0.39%, 0.49% and 0.82% for the UMN dataset, for SBE, LR_SBE, and MAX_SBE, respectively.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 86, "end_pos": 94, "type": "METRIC", "confidence": 0.99275803565979}, {"text": "VUH dataset", "start_pos": 183, "end_pos": 194, "type": "DATASET", "confidence": 0.9712915420532227}, {"text": "UMN dataset", "start_pos": 230, "end_pos": 241, "type": "DATASET", "confidence": 0.9568721652030945}]}, {"text": "We used Wilcoxon test to compare the embedding features.", "labels": [], "entities": [{"text": "Wilcoxon test", "start_pos": 8, "end_pos": 21, "type": "DATASET", "confidence": 0.8275835812091827}]}, {"text": "The test results show that the best embedding features in this study (MAX_SBE) outperformed the SBE feature with a significant pvalue of 0.004 on the VUH dataset and 7.05e-05 on the UMN dataset.", "labels": [], "entities": [{"text": "VUH dataset", "start_pos": 150, "end_pos": 161, "type": "DATASET", "confidence": 0.9904087483882904}, {"text": "UMN dataset", "start_pos": 182, "end_pos": 193, "type": "DATASET", "confidence": 0.9823392331600189}]}], "tableCaptions": [{"text": " Table 1. Statistics of the two abbreviation da- tasets and the unlabeled clinical corpus", "labels": [], "entities": []}, {"text": " Table 2. Average accuracy of the WSD sys- tems using different word embedding features on  both VUH and UMN datasets", "labels": [], "entities": [{"text": "accuracy", "start_pos": 18, "end_pos": 26, "type": "METRIC", "confidence": 0.9642640352249146}, {"text": "VUH and UMN datasets", "start_pos": 97, "end_pos": 117, "type": "DATASET", "confidence": 0.746763065457344}]}]}