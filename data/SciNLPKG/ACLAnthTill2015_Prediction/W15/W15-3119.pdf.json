{"title": [{"text": "Chinese Semantic Role Labeling using High-quality Syntactic Knowledge", "labels": [], "entities": [{"text": "Semantic Role Labeling", "start_pos": 8, "end_pos": 30, "type": "TASK", "confidence": 0.6157934168974558}]}], "abstractContent": [{"text": "This paper presents an application of Chi-nese syntactic knowledge for semantic role labeling (SRL).", "labels": [], "entities": [{"text": "semantic role labeling (SRL)", "start_pos": 71, "end_pos": 99, "type": "TASK", "confidence": 0.8022740185260773}]}, {"text": "Besides basic morphological information, syntactic structures are crucial in SRL.", "labels": [], "entities": [{"text": "SRL", "start_pos": 77, "end_pos": 80, "type": "TASK", "confidence": 0.9917254447937012}]}, {"text": "However, it is difficult to learn such information from limited, small-scale, manually annotated training data.", "labels": [], "entities": []}, {"text": "Instead of manually increasing the size of annotated data, we use a large amount of automatically extracted syntactic knowledge to improve the performance of SRL.", "labels": [], "entities": [{"text": "SRL", "start_pos": 158, "end_pos": 161, "type": "TASK", "confidence": 0.9516586065292358}]}], "introductionContent": [{"text": "Semantic role labeling (SRL) is regarded as a task that is intermediate between syntactic parsing and semantic analysis in natural language processing (NLP).", "labels": [], "entities": [{"text": "Semantic role labeling (SRL)", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.8422271807988485}, {"text": "syntactic parsing", "start_pos": 80, "end_pos": 97, "type": "TASK", "confidence": 0.7708729803562164}, {"text": "semantic analysis in natural language processing (NLP)", "start_pos": 102, "end_pos": 156, "type": "TASK", "confidence": 0.6907777322663201}]}, {"text": "The main goal of SRL is to extract a proposition from a sentence about who does what to whom, when, where and why.", "labels": [], "entities": [{"text": "SRL", "start_pos": 17, "end_pos": 20, "type": "TASK", "confidence": 0.9855512380599976}]}, {"text": "By using semantic roles, the complex expression of a sentence is then interpreted as an event and its participants (i.e., predicates and arguments such as agent, patient, locative, temporal and manner).", "labels": [], "entities": []}, {"text": "Unlike syntactic level surface cases (i.e., dependency labels such as subject and object), semantic roles can be regarded as a deep case representation for predicates.", "labels": [], "entities": []}, {"text": "Because of its ability to abstract the meaning of a sentence, SRL has been applied to many NLP applications, including information extraction, question answering ( and machine translation (.", "labels": [], "entities": [{"text": "SRL", "start_pos": 62, "end_pos": 65, "type": "TASK", "confidence": 0.9680087566375732}, {"text": "information extraction", "start_pos": 119, "end_pos": 141, "type": "TASK", "confidence": 0.8380789458751678}, {"text": "question answering", "start_pos": 143, "end_pos": 161, "type": "TASK", "confidence": 0.9011159539222717}, {"text": "machine translation", "start_pos": 168, "end_pos": 187, "type": "TASK", "confidence": 0.7641550302505493}]}, {"text": "Semantically annotated corpora, such as FrameNet () and PropBank (, make this type of automatic semantic structure analysis feasible by using supervised machine learning methods.", "labels": [], "entities": [{"text": "PropBank", "start_pos": 56, "end_pos": 64, "type": "DATASET", "confidence": 0.8781253695487976}, {"text": "semantic structure analysis", "start_pos": 96, "end_pos": 123, "type": "TASK", "confidence": 0.6807445685068766}]}, {"text": "Automatic SRL processing has two major drawbacks: firstly, the scale of the training data is quite limited and although manually annotated data such as PropBank is available as training data for learning semantic role prediction models, it is still hard to learn lexical preferences due its limited size.", "labels": [], "entities": [{"text": "SRL processing", "start_pos": 10, "end_pos": 24, "type": "TASK", "confidence": 0.9746887683868408}, {"text": "PropBank", "start_pos": 152, "end_pos": 160, "type": "DATASET", "confidence": 0.9355663657188416}, {"text": "learning semantic role prediction models", "start_pos": 195, "end_pos": 235, "type": "TASK", "confidence": 0.6300082325935363}]}, {"text": "Increasing the size and coverage of this resource for improving the quality of learned models is a time consuming task.", "labels": [], "entities": []}, {"text": "Secondly, similar to syntactic analysis such as syntactic dependency parsing, whose performance is highly dependent on preceding analysis such as POS tagging, automatic SRL systems are based on syntactic structures along with lower level information including POS tags and lexical information.", "labels": [], "entities": [{"text": "syntactic dependency parsing", "start_pos": 48, "end_pos": 76, "type": "TASK", "confidence": 0.6621010402838389}, {"text": "POS tagging", "start_pos": 146, "end_pos": 157, "type": "TASK", "confidence": 0.6094359159469604}, {"text": "SRL", "start_pos": 169, "end_pos": 172, "type": "TASK", "confidence": 0.9337178468704224}]}, {"text": "As a result, SRL suffers from error propagation from the lower levels of the whole framework.", "labels": [], "entities": [{"text": "SRL", "start_pos": 13, "end_pos": 16, "type": "TASK", "confidence": 0.9487438201904297}]}, {"text": "Although some studies use automatic analysis of unlabeled data to enrich the training data to solve the first problem, accumulated errors in such automatic analysis inevitably causes negative effects.", "labels": [], "entities": []}, {"text": "Especially, for some hard-to-analyze languages such as Chinese, which is difficult to analyze morphologically, the performance of SRL is always limited due to the above two problems.", "labels": [], "entities": [{"text": "SRL", "start_pos": 130, "end_pos": 133, "type": "TASK", "confidence": 0.973663866519928}]}, {"text": "In this paper, we focus on Chinese SRL and address the problems mentioned above by using high-quality knowledge automatically extracted from a large-scale corpus.", "labels": [], "entities": [{"text": "Chinese SRL", "start_pos": 27, "end_pos": 38, "type": "TASK", "confidence": 0.5403841435909271}]}, {"text": "Instead of using high level automatic analyses such as semantic roles, we use lower level syntactic knowledge because lower level analyses are less erroneous compared to higher level analyses.", "labels": [], "entities": []}, {"text": "The additional knowledge can provide not only a rich lexicon but also syntactic information, both of which play crucial roles in SRL.", "labels": [], "entities": [{"text": "SRL", "start_pos": 129, "end_pos": 132, "type": "TASK", "confidence": 0.9938198924064636}]}, {"text": "In order to show that automatically extracted syntactic knowledge is beneficial, we use predicate-argument structures and case frames (which will be introduced in later sections) in our experiments to validate our claim.", "labels": [], "entities": []}, {"text": "The rest of this paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 contains related work.", "labels": [], "entities": []}, {"text": "Section 3 describes the high-quality dependency selection process.", "labels": [], "entities": []}, {"text": "Section 4.1 presents a detailed description of our approach, conducted on three languages, along with the results followed by a discussion in Section 4.2.", "labels": [], "entities": []}, {"text": "Finally, Section 5 contains our conclusions and future work.", "labels": [], "entities": []}], "datasetContent": [{"text": "For large-scale syntactic knowledge acquisition, 30 million sentences from Chinese Gigaword 5.0 (LDC2011T13) 2 were used.", "labels": [], "entities": [{"text": "syntactic knowledge acquisition", "start_pos": 16, "end_pos": 47, "type": "TASK", "confidence": 0.7343388597170512}, {"text": "Chinese Gigaword 5.0 (LDC2011T13) 2", "start_pos": 75, "end_pos": 110, "type": "DATASET", "confidence": 0.9007945486477443}]}, {"text": "For the high-quality dependency selection approach in the knowledge construction pipeline, the Stanford parser was used to apply syntactic dependency parsing on the raw texts from Chinese Gigaword.", "labels": [], "entities": [{"text": "knowledge construction pipeline", "start_pos": 58, "end_pos": 89, "type": "TASK", "confidence": 0.7766523957252502}, {"text": "syntactic dependency parsing", "start_pos": 129, "end_pos": 157, "type": "TASK", "confidence": 0.7341957092285156}, {"text": "Chinese Gigaword", "start_pos": 180, "end_pos": 196, "type": "DATASET", "confidence": 0.8230792880058289}]}, {"text": "The training section of Chinese Treebank 7.0 was used to train the dependency parser and the official development section was used to train a classifier for high-quality dependency selection.", "labels": [], "entities": [{"text": "Chinese Treebank 7.0", "start_pos": 24, "end_pos": 44, "type": "DATASET", "confidence": 0.9814683596293131}, {"text": "dependency parser", "start_pos": 67, "end_pos": 84, "type": "TASK", "confidence": 0.8260654509067535}]}, {"text": "Judging whether the automatic dependencies are reliable can be regarded as a binary classification problem, for which we utilized support vector machines (SVMs).", "labels": [], "entities": []}, {"text": "Specifically, we employed SVMLight 3 with a linear kernel to select high-quality dependencies from large-scale automatic dependency parses on the Chinese Gigaword for syntactic knowledge construction.", "labels": [], "entities": [{"text": "syntactic knowledge construction", "start_pos": 167, "end_pos": 199, "type": "TASK", "confidence": 0.6835171580314636}]}, {"text": "Using official evalution section of CTB 7.0, we evaluated the quality of thoses selected dependencies using unlabeled attachment score (UAS), which calculates the percentage of correctly indentified dependency heads.", "labels": [], "entities": [{"text": "CTB 7.0", "start_pos": 36, "end_pos": 43, "type": "DATASET", "confidence": 0.948707103729248}, {"text": "unlabeled attachment score (UAS)", "start_pos": 108, "end_pos": 140, "type": "METRIC", "confidence": 0.7885410537322363}]}, {"text": "For SRL, we used the Chinese section of CoNLL-2009 shared task data for experiments.", "labels": [], "entities": [{"text": "SRL", "start_pos": 4, "end_pos": 7, "type": "TASK", "confidence": 0.9164420366287231}, {"text": "Chinese section of CoNLL-2009 shared task data", "start_pos": 21, "end_pos": 67, "type": "DATASET", "confidence": 0.8836243322917393}]}, {"text": "Automatically obtained morphological and syntactic information (the columns begin with \"P\") was used.", "labels": [], "entities": []}, {"text": "PD and AI, AC step are regarded as multi-class classification problems.", "labels": [], "entities": [{"text": "AI", "start_pos": 7, "end_pos": 9, "type": "METRIC", "confidence": 0.9597672820091248}]}, {"text": "We employed OPAL 4 to solve this problem.", "labels": [], "entities": []}, {"text": "We set the options as follows: polynomial kernel with degree 2; passive aggressive I learner; 20 iterations.", "labels": [], "entities": []}, {"text": "The SRL system without using additional syntactic knowledge was used as a baseline.", "labels": [], "entities": [{"text": "SRL", "start_pos": 4, "end_pos": 7, "type": "TASK", "confidence": 0.7473433017730713}]}, {"text": "To examine the effect of different quality of syntactic knowledge, we used different set of PAS which was extracted under different dependency selection thresholds (20%, 50%, w/o selection).", "labels": [], "entities": [{"text": "PAS", "start_pos": 92, "end_pos": 95, "type": "METRIC", "confidence": 0.9351092576980591}]}, {"text": "The official script provided on the CoNLL-2009 shared task website was used for evaluation.", "labels": [], "entities": [{"text": "CoNLL-2009 shared task website", "start_pos": 36, "end_pos": 66, "type": "DATASET", "confidence": 0.8273112326860428}]}, {"text": "Tabel 4 shows the quality of selected dependencies using different selection criteria.", "labels": [], "entities": []}, {"text": "The precision of automatic syntactic depdencies increases when we lower the recall.", "labels": [], "entities": [{"text": "precision", "start_pos": 4, "end_pos": 13, "type": "METRIC", "confidence": 0.9996140599250793}, {"text": "recall", "start_pos": 76, "end_pos": 82, "type": "METRIC", "confidence": 0.9990413784980774}]}, {"text": "shows our experimental results using the syntactic knowledge-based features.", "labels": [], "entities": []}, {"text": "Syntactic knowledge (x%) indicates that the top x% (according to the classifier) of the automatically extracted syntactic knowledge was used.", "labels": [], "entities": []}, {"text": "'100%' means that dependency selection step was not performed.", "labels": [], "entities": [{"text": "dependency selection", "start_pos": 18, "end_pos": 38, "type": "TASK", "confidence": 0.8566273748874664}]}, {"text": "Our baseline system outperforms as well as the best system in CoNLL-2009 shared task.", "labels": [], "entities": [{"text": "CoNLL-2009 shared task", "start_pos": 62, "end_pos": 84, "type": "DATASET", "confidence": 0.7922524015108744}]}, {"text": "As we can see from the result, using large-scale syntactic knowledge can help improve the performance of SRL.", "labels": [], "entities": [{"text": "SRL", "start_pos": 105, "end_pos": 108, "type": "TASK", "confidence": 0.9871572852134705}]}, {"text": "Syntactic knowledge extracted from automatic parses without any selection (100%) contains a lot of noise and hence is not beneficial at all.", "labels": [], "entities": []}, {"text": "However, filtering noisy syntactic knowledge leads to an significant improvement in Chinese SRL task.", "labels": [], "entities": [{"text": "SRL", "start_pos": 92, "end_pos": 95, "type": "TASK", "confidence": 0.6670902371406555}]}, {"text": "This shows that selecting hiqhquality dependencies is an important aspect of high-quality SRL.", "labels": [], "entities": [{"text": "SRL", "start_pos": 90, "end_pos": 93, "type": "TASK", "confidence": 0.9707150459289551}]}], "tableCaptions": [{"text": " Table 4: Precision of selected dependencies under different criteria", "labels": [], "entities": [{"text": "Precision", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.6552424430847168}]}, {"text": " Table 5: Evaluation results of Chinese SRL. The ** mark and * mark mean that the result is regarded as  significant (with a p value < 0.01 and a p value < 0.05 respectively) using McNemar's test.", "labels": [], "entities": [{"text": "Chinese SRL", "start_pos": 32, "end_pos": 43, "type": "TASK", "confidence": 0.6456827819347382}, {"text": "McNemar's test", "start_pos": 181, "end_pos": 195, "type": "DATASET", "confidence": 0.921596348285675}]}]}