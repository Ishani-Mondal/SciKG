{"title": [{"text": "LINA: Identifying Comparable Documents from Wikipedia", "labels": [], "entities": [{"text": "LINA", "start_pos": 0, "end_pos": 4, "type": "METRIC", "confidence": 0.8321320414543152}, {"text": "Identifying Comparable Documents from Wikipedia", "start_pos": 6, "end_pos": 53, "type": "TASK", "confidence": 0.7279529809951782}]}], "abstractContent": [{"text": "This paper describes the LINA system for the BUCC 2015 shared track.", "labels": [], "entities": [{"text": "LINA", "start_pos": 25, "end_pos": 29, "type": "METRIC", "confidence": 0.8634989261627197}, {"text": "BUCC 2015 shared track", "start_pos": 45, "end_pos": 67, "type": "DATASET", "confidence": 0.9361877292394638}]}, {"text": "Following (Enright and Kondrak, 2007), our system identify comparable documents by collecting counts of hapax words.", "labels": [], "entities": []}, {"text": "We extend this method by filtering out document pairs sharing target documents using pigeonhole reasoning and cross-lingual information .", "labels": [], "entities": []}], "introductionContent": [{"text": "Parallel corpora, that is, collections of documents that are mutual translations, are used in many natural language processing applications, particularly for statistical machine translation.", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 158, "end_pos": 189, "type": "TASK", "confidence": 0.7122872273127238}]}, {"text": "Building such resources is however exceedingly expensive, requiring highly skilled annotators or professional translators.", "labels": [], "entities": []}, {"text": "Comparable corpora, that are sets of texts in two or more languages without being translations of each other, are often considered as a solution for the lack of parallel corpora, and many techniques have been proposed to extract parallel sentences (, or mine word translations.", "labels": [], "entities": []}, {"text": "Identifying comparable resources in a large amount of multilingual data remains a very challenging task.", "labels": [], "entities": []}, {"text": "The purpose of the Building and Using Comparable Corpora (BUCC) 2015 shared task 1 is to provide the first evaluation of existing approaches for identifying comparable resources.", "labels": [], "entities": [{"text": "Building and Using Comparable Corpora (BUCC) 2015 shared task", "start_pos": 19, "end_pos": 80, "type": "TASK", "confidence": 0.5647306740283966}]}, {"text": "More precisely, given a large collection of Wikipedia pages in several languages, the task is to identify the most similar pages across languages.", "labels": [], "entities": []}, {"text": "1 https://comparable.limsi.fr/bucc2015/ In this paper, we describe the system that we developed for the BUCC 2015 shared track and show that a language agnostic approach can achieve promising results.", "labels": [], "entities": [{"text": "BUCC 2015 shared track", "start_pos": 104, "end_pos": 126, "type": "DATASET", "confidence": 0.9475422650575638}]}], "datasetContent": [{"text": "The BUCC 2015 shared task consists in returning for each Wikipedia page in a source language, up to five ranked suggestions to its linked page in English.", "labels": [], "entities": [{"text": "BUCC 2015 shared task", "start_pos": 4, "end_pos": 25, "type": "DATASET", "confidence": 0.9149414598941803}]}, {"text": "Inter-language links, that is, links from a page in one language to an equivalent page in another language, are used to evaluate the effectiveness of the systems.", "labels": [], "entities": []}, {"text": "Here, we only focus on the French-English and German-English pairs.", "labels": [], "entities": []}, {"text": "Following the task guidelines, we use the following evaluation measures investigate the effectiveness of our method: \u2022 Mean Average Precision (MAP).", "labels": [], "entities": [{"text": "Mean Average Precision (MAP)", "start_pos": 119, "end_pos": 147, "type": "METRIC", "confidence": 0.9526989758014679}]}, {"text": "Average of precisions computed at the point of each correctly paired document in the ranked list of paired documents.", "labels": [], "entities": [{"text": "precisions", "start_pos": 11, "end_pos": 21, "type": "METRIC", "confidence": 0.9991822838783264}]}, {"text": "\u2022 Success (Succ.).", "labels": [], "entities": [{"text": "Success", "start_pos": 2, "end_pos": 9, "type": "METRIC", "confidence": 0.9950135350227356}, {"text": "Succ.", "start_pos": 11, "end_pos": 16, "type": "METRIC", "confidence": 0.9759268760681152}]}, {"text": "Precision computed on the first returned paired document.", "labels": [], "entities": []}, {"text": "\u2022 Precision at 5 (P@5).", "labels": [], "entities": [{"text": "Precision", "start_pos": 2, "end_pos": 11, "type": "METRIC", "confidence": 0.9895094633102417}]}, {"text": "Precision computed on the 5 topmost paired documents.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Percentage of English articles that are  paired with multiple French or German articles on  the training data.", "labels": [], "entities": []}, {"text": " Table 3: Performance in terms of MAP, success (Succ.) and precision at 5 (P@5) of our model.", "labels": [], "entities": [{"text": "MAP", "start_pos": 34, "end_pos": 37, "type": "METRIC", "confidence": 0.9439128041267395}, {"text": "success", "start_pos": 39, "end_pos": 46, "type": "METRIC", "confidence": 0.9738656282424927}, {"text": "Succ.", "start_pos": 48, "end_pos": 53, "type": "METRIC", "confidence": 0.848227858543396}, {"text": "precision", "start_pos": 59, "end_pos": 68, "type": "METRIC", "confidence": 0.998988687992096}]}]}