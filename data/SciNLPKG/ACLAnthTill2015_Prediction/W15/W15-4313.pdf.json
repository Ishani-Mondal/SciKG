{"title": [{"text": "NCSU-SAS-Ning: Candidate Generation and Feature Engineering for Supervised Lexical Normalization", "labels": [], "entities": [{"text": "NCSU-SAS-Ning", "start_pos": 0, "end_pos": 13, "type": "DATASET", "confidence": 0.9690467119216919}, {"text": "Candidate Generation", "start_pos": 15, "end_pos": 35, "type": "TASK", "confidence": 0.679032951593399}, {"text": "Lexical Normalization", "start_pos": 75, "end_pos": 96, "type": "TASK", "confidence": 0.7239874005317688}]}], "abstractContent": [{"text": "User generated content often contains non-standard words that hinder effective automatic text processing.", "labels": [], "entities": []}, {"text": "In this paper, we present a system we developed to perform lexical normalization for English Twitter text.", "labels": [], "entities": []}, {"text": "It first generates candidates based on past knowledge and a novel string similarity measurement and then selects a candidate using features learned from training data.", "labels": [], "entities": []}, {"text": "The system has a constrained mode and an unconstrained mode.", "labels": [], "entities": []}, {"text": "The constrained mode participated in the W-NUT noisy English text normal-ization competition (Baldwin et al., 2015) and achieved the best F1 score.", "labels": [], "entities": [{"text": "F1", "start_pos": 138, "end_pos": 140, "type": "METRIC", "confidence": 0.9992019534111023}]}], "introductionContent": [{"text": "User generated content, such as customer reviews, forum discussions, text messages and Twitter text, is of great value in applications like understanding users, trend discovery and crowdsourcing.", "labels": [], "entities": [{"text": "trend discovery", "start_pos": 161, "end_pos": 176, "type": "TASK", "confidence": 0.7156424522399902}]}, {"text": "For example, by reading the Twitter text posted by a user, a company can learn the user's preferences and connections and use the information for targeted advertising.", "labels": [], "entities": []}, {"text": "For another example, by reading Amazon customer reviews about a certain product, a shopper can collect a lot of product information that is not available from manufacturers and retailers.", "labels": [], "entities": []}, {"text": "Unfortunately, user generated content often contains ungrammatical sentence structures and nonstandard words, which hinders automated text processing.", "labels": [], "entities": []}, {"text": "In this paper, we present a solution that attempts to perform lexical normalization) for English Twitter text based on training text with human annotation (.", "labels": [], "entities": []}, {"text": "The solution has a constrained mode and an unconstrained mode.", "labels": [], "entities": []}, {"text": "Both modes have the same architecture and components.", "labels": [], "entities": []}, {"text": "Both use the annotated training data and CMU's ark POS tagger (.", "labels": [], "entities": [{"text": "CMU", "start_pos": 41, "end_pos": 44, "type": "DATASET", "confidence": 0.9569964408874512}]}, {"text": "The difference between them is parameter settings and the usage of a canonical lexicon dictionary by the unconstrained mode.", "labels": [], "entities": []}, {"text": "This paper is organized as follows: Section 2 describes the architecture and components shared by the constrained and unconstrained modes.", "labels": [], "entities": []}, {"text": "Section 3 lists what resources are used by each system.", "labels": [], "entities": []}, {"text": "In Section 4, we describe the different settings of the constrained and unconstrained modes and compare their performance.", "labels": [], "entities": []}, {"text": "Section 5 concludes the paper and discusses future work.", "labels": [], "entities": []}], "datasetContent": [{"text": "Given a tweet T, one of its token ti and one of the token's candidate c, we train a binary classifier that predicts whether c is the correct canonical form oft i in the tweet T and outputs a confidence score for the prediction.", "labels": [], "entities": []}, {"text": "Among the candidates that the classifier predicts to be the correct canonical forms, we select the one with the highest confidence score as the canonical form oft i . In our implementation of the system, we used a random forest classifier) mainly because its training speed is faster and its performance is relatively insensitive to parameter values, but other binary classification algorithm should also work.", "labels": [], "entities": []}, {"text": "This step is mostly feature engineering and we used the following features: \u2022 Support and confidence We calculate the support of token ti (number of times ti appears) and confidence of token ti being normalized to candidate c (percentage of times ti is normalized to c) according to training data and use them as features for classification.", "labels": [], "entities": [{"text": "Support", "start_pos": 78, "end_pos": 85, "type": "METRIC", "confidence": 0.9488507509231567}]}, {"text": "For example, in the training data shown above, the support of token \"ur\" is 3 and the confidence of normalizing \"ur\" to \"you are\" is 2/3 = 0.67.", "labels": [], "entities": []}, {"text": "The confidence of normalizing \"ur\" to \"your\" is 1/3 = 0.33.", "labels": [], "entities": []}, {"text": "If the token ti is absent in the training data, e.g. \"looove\", then the support and confidence are both zero.", "labels": [], "entities": [{"text": "support", "start_pos": 72, "end_pos": 79, "type": "METRIC", "confidence": 0.968511700630188}, {"text": "confidence", "start_pos": 84, "end_pos": 94, "type": "METRIC", "confidence": 0.935418963432312}]}, {"text": "If the token ti is present but the normalization from ti to c is absent in training data, then only the confidence is zero.", "labels": [], "entities": [{"text": "confidence", "start_pos": 104, "end_pos": 114, "type": "METRIC", "confidence": 0.9663349986076355}]}, {"text": "These features are context free and the intuition is that the higher the support and confidence are (high support is necessary in case of small sample), the more likely that c is the correct canonical form oft i . \u2022 String information We calculate the string similarity score (Jaccard Index of feature sets) between token ti and candidate c and use it as a feature for classification.", "labels": [], "entities": [{"text": "string similarity score (Jaccard Index of feature sets)", "start_pos": 252, "end_pos": 307, "type": "METRIC", "confidence": 0.7306881308555603}]}, {"text": "String similarity score is a good feature for difference between token and its canonical form caused by misspelling (for example, \"seperate\" \u00e0\uf0e0 \"separate\"), but it is not a good feature for difference caused by abbreviation (for example, \"lol\" \u00e0\uf0e0 \"laughing out loud\").", "labels": [], "entities": [{"text": "String similarity score", "start_pos": 0, "end_pos": 23, "type": "METRIC", "confidence": 0.5725641349951426}]}, {"text": "Therefore, we also add string length and difference in string length between ti and c so that classifier can choose to ignore string similarity score when necessary.", "labels": [], "entities": [{"text": "string similarity score", "start_pos": 126, "end_pos": 149, "type": "METRIC", "confidence": 0.602786531051}]}, {"text": "All string information features are context free.", "labels": [], "entities": []}, {"text": "\u2022 POS tagging information One of the motivations of text normalization is to facilitate subsequent tasks, such as partof-speech tagging and named entity recognition.", "labels": [], "entities": [{"text": "POS tagging information", "start_pos": 2, "end_pos": 25, "type": "TASK", "confidence": 0.7787600954373678}, {"text": "text normalization", "start_pos": 52, "end_pos": 70, "type": "TASK", "confidence": 0.7867066860198975}, {"text": "partof-speech tagging", "start_pos": 114, "end_pos": 135, "type": "TASK", "confidence": 0.8177504539489746}, {"text": "named entity recognition", "start_pos": 140, "end_pos": 164, "type": "TASK", "confidence": 0.6502391000588735}]}, {"text": "Therefore, good text normalization should make the subsequent tasks easier.", "labels": [], "entities": [{"text": "text normalization", "start_pos": 16, "end_pos": 34, "type": "TASK", "confidence": 0.7502694129943848}]}, {"text": "We observed that in the training data, in 90% of the cases where a token is normalized to another token, the canonical form has higher POS tagging confidence, based on the ark POS tagger (Gimpel et al., 2011), than the original.", "labels": [], "entities": []}, {"text": "Therefore we use change in POS tagging confidence at position i in tweet T before and after normalizing ti to c as a feature for classification.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 27, "end_pos": 38, "type": "TASK", "confidence": 0.6954829692840576}]}, {"text": "We also include change in mean POS tagging confidence in tweet T because changing one token can affect the confidence of tagging other tokens.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 31, "end_pos": 42, "type": "TASK", "confidence": 0.6615364253520966}]}, {"text": "In addition to change in POS tagging confidence, we use POS tags of tokens t i-1 and ti as features (tag is empty if ti is the first token) because there can be patterns of consecutive POS tags and some patterns are much more frequent than others.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 25, "end_pos": 36, "type": "TASK", "confidence": 0.9138138890266418}]}, {"text": "All POS tagging features use context information.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 4, "end_pos": 15, "type": "TASK", "confidence": 0.7114602476358414}]}, {"text": "The importance of these classification features are evaluated in Section 4.", "labels": [], "entities": []}, {"text": "To train the classifier, we generate candidates for each token in training data and label each pair according to human annotation.", "labels": [], "entities": []}, {"text": "If the candidate is the correct canonical form of the token in the tweet, then the pair is labeled as class 1; otherwise the pair is labeled as class 0.", "labels": [], "entities": []}, {"text": "Feature vectors with features described above are calculated for each pair.", "labels": [], "entities": []}, {"text": "Then a random forest binary classifier is learned.", "labels": [], "entities": []}, {"text": "When the classifier is learned, the class (label) weights are adjusted inversely proportional to class frequencies in the data because the data is imbalanced and majority of the observations are in class 0.", "labels": [], "entities": []}, {"text": "For both the constrained and unconstrained modes, we use only bigrams and 1-skip-bigrams as similarity features.", "labels": [], "entities": []}, {"text": "The differences between the two modes are listed below.", "labels": [], "entities": []}, {"text": "For the constrained mode: \u2022 It uses best-scoring canonical forms from the similarity index as candidates.", "labels": [], "entities": []}, {"text": "\u2022 It uses similarity index for candidate generation only when the token contains repetitive characters (same character occupying consecutive positions).", "labels": [], "entities": [{"text": "similarity index", "start_pos": 10, "end_pos": 26, "type": "METRIC", "confidence": 0.9226128458976746}, {"text": "candidate generation", "start_pos": 31, "end_pos": 51, "type": "TASK", "confidence": 0.8008825480937958}]}, {"text": "4 \u2022 It builds a similarity index based on all canonical forms present in the training data.", "labels": [], "entities": []}, {"text": "\u2022 Dictionary and feature learning and classifier training are based on the same data set.", "labels": [], "entities": []}, {"text": "For the Unconstrained mode: \u2022 It uses top-3 best-scoring canonical forms from the similarity index as candidates.", "labels": [], "entities": []}, {"text": "\u2022 It builds a similarity index based on all canonical forms in the training data and all lexicons in the dictionary scowl.american.70.", "labels": [], "entities": []}, {"text": "\u2022 It always uses the similarity index for candidate generation.", "labels": [], "entities": [{"text": "similarity index", "start_pos": 21, "end_pos": 37, "type": "METRIC", "confidence": 0.9693536460399628}]}, {"text": "\u2022 Dictionary and feature learning and classifier training are based on different data sets.", "labels": [], "entities": []}, {"text": "For the constrained mode, dictionaries (including static mapping dictionary and similarity index), classification feature calculation and classifier training are based on the same data set.", "labels": [], "entities": [{"text": "classification feature calculation", "start_pos": 99, "end_pos": 133, "type": "TASK", "confidence": 0.9346198439598083}]}, {"text": "It causes overfitting because the dictionaries and the support and confidence features leak label information.", "labels": [], "entities": []}, {"text": "However, our cross-validation results show that learning dictionaries, support and confidence features, and classifier on the same data set generates better generalization as well.", "labels": [], "entities": []}, {"text": "It leads to better F1 score than splitting the data set into two parts and learning dictionaries and features on one part and learning the classifier on the other part.", "labels": [], "entities": [{"text": "F1 score", "start_pos": 19, "end_pos": 27, "type": "METRIC", "confidence": 0.9724303483963013}]}, {"text": "This is because having large dictionaries is crucial for candidate generation and the correct canonical form cannot be found if it is not among the candidates.", "labels": [], "entities": [{"text": "candidate generation", "start_pos": 57, "end_pos": 77, "type": "TASK", "confidence": 0.7647634148597717}]}, {"text": "Using all the available data instead of splitting it allows the system to learn larger dictionaries and more than makes up for the overfitting problem.", "labels": [], "entities": []}, {"text": "For the unconstrained mode, dictionaries and features are learned on 67% of the available data and the classifier is learned on 33% of the available data (random split).", "labels": [], "entities": []}, {"text": "This is different from constrained mode because the unconstrained mode already has a very large canonical form dictionary in scowl.american.70 and the accuracy of selecting the correct canonical form becomes the bottleneck.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 151, "end_pos": 159, "type": "METRIC", "confidence": 0.9968219995498657}]}, {"text": "We used the data sets provided by the WNUT 2015 lexical normalization competition (described in () for evaluation.", "labels": [], "entities": [{"text": "WNUT 2015 lexical normalization competition", "start_pos": 38, "end_pos": 81, "type": "TASK", "confidence": 0.7311810374259948}]}, {"text": "During our development of the systems, only the training data file train_data_20150430.json was used for any parameter selection and design decisions.", "labels": [], "entities": []}, {"text": "We used cross-validation to estimate system performance.", "labels": [], "entities": []}, {"text": "The constrained and unconstrained modes have separate classifier training.", "labels": [], "entities": []}, {"text": "shows the performance of the constrained mode with different sets of classification features based on the test data file test_truth.json concealed from development.", "labels": [], "entities": []}, {"text": "It can be seen that the support and confidence features are the most important for achieving high F1 score.", "labels": [], "entities": [{"text": "support", "start_pos": 24, "end_pos": 31, "type": "METRIC", "confidence": 0.9544975161552429}, {"text": "F1 score", "start_pos": 98, "end_pos": 106, "type": "METRIC", "confidence": 0.9687468111515045}]}, {"text": "Without the support and confidence features, the F1 score of the constrained mode decreases by 0.0521.", "labels": [], "entities": [{"text": "confidence", "start_pos": 24, "end_pos": 34, "type": "METRIC", "confidence": 0.9626920819282532}, {"text": "F1 score", "start_pos": 49, "end_pos": 57, "type": "METRIC", "confidence": 0.9869662821292877}]}, {"text": "The POS tagging features constitute the second most important feature set.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 4, "end_pos": 15, "type": "TASK", "confidence": 0.7038133144378662}]}, {"text": "Without POS tagging features, the F1 score goes down by 0.0129.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 8, "end_pos": 19, "type": "TASK", "confidence": 0.584205687046051}, {"text": "F1 score", "start_pos": 34, "end_pos": 42, "type": "METRIC", "confidence": 0.9756899178028107}]}, {"text": "The string features are the least important set of features as they lead to very marginal improvement in F1 score.", "labels": [], "entities": [{"text": "F1 score", "start_pos": 105, "end_pos": 113, "type": "METRIC", "confidence": 0.9650800228118896}]}, {"text": "It can be seen that our normalization system has the best F1 score in both constrained mode and unconstrained mode.", "labels": [], "entities": [{"text": "F1 score", "start_pos": 58, "end_pos": 66, "type": "METRIC", "confidence": 0.985209584236145}]}, {"text": "In fact, our constrained mode has the best F1 score overall, better than our unconstrained mode, which seems counterintuitive.", "labels": [], "entities": [{"text": "F1 score", "start_pos": 43, "end_pos": 51, "type": "METRIC", "confidence": 0.9857142269611359}]}, {"text": "Besides, the unconstrained mode is expected to achieve higher recall than the constrained mode because of its much larger dictionary, but the evaluation results show that the unconstrained mode has lower recall and higher precision than the constrained mode.", "labels": [], "entities": [{"text": "recall", "start_pos": 62, "end_pos": 68, "type": "METRIC", "confidence": 0.9984499216079712}, {"text": "recall", "start_pos": 204, "end_pos": 210, "type": "METRIC", "confidence": 0.9983879327774048}, {"text": "precision", "start_pos": 222, "end_pos": 231, "type": "METRIC", "confidence": 0.9976824522018433}]}, {"text": "The following three factors lead to the inferior F1 score and recall by our unconstrained mode:", "labels": [], "entities": [{"text": "F1 score", "start_pos": 49, "end_pos": 57, "type": "METRIC", "confidence": 0.9855626821517944}, {"text": "recall", "start_pos": 62, "end_pos": 68, "type": "METRIC", "confidence": 0.9984508752822876}]}], "tableCaptions": [{"text": " Table 3: Importance of Classification Features", "labels": [], "entities": [{"text": "Importance", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.968772292137146}]}, {"text": " Table 4: Competition Evaluation Results", "labels": [], "entities": []}]}