{"title": [{"text": "Balancing the Existing and the New in the Context of Annotating Non-Canonical Language", "labels": [], "entities": [{"text": "Balancing the Existing and the New in the Context of Annotating Non-Canonical Language", "start_pos": 0, "end_pos": 86, "type": "Description", "confidence": 0.6695506801972022}]}], "abstractContent": [{"text": "The importance of balancing linguistic considerations , annotation practicalities, and end user needs in developing language annotation guidelines is discussed.", "labels": [], "entities": []}, {"text": "Maintaining a clear view of the various goals and fostering collaboration and feedback across levels of annotation and between corpus creators and corpus users is helpful in determining this balance.", "labels": [], "entities": []}, {"text": "Annotating non-canonical language brings additional challenges that serve to highlight the necessity of keeping these goals in mind when creating corpora.", "labels": [], "entities": []}], "introductionContent": [{"text": "Context is important -both the linguistic context of a specific annotation and also the external context of the project as a whole affect what type of annotation scheme can be developed, what kind of annotation can be done, and what the balance of existing and new will need to be in an annotation scheme.", "labels": [], "entities": []}, {"text": "Non-canonical language can make the usual linguistic and situational context considerations for annotation even more relevant: how broad the context is (word, sentence, document, conversation, world knowledge), how much that context affects the feature that is being annotated, and whether it is possible for an annotator to take that context into account.", "labels": [], "entities": []}, {"text": "In addition, particularly when developing large corpora as part of projects with a short timeline and restricted funding, which is often the case at the Linguistic Data Consortium (LDC), a necessary part of choosing or designing an annotation scheme is considering who the end users of the annotated data will be, what the annotations will be used for, what level of detail is important for the project, and what level of accuracy or consistency is desired.", "labels": [], "entities": [{"text": "Linguistic Data Consortium (LDC)", "start_pos": 153, "end_pos": 185, "type": "DATASET", "confidence": 0.7837557395299276}, {"text": "accuracy", "start_pos": 422, "end_pos": 430, "type": "METRIC", "confidence": 0.9977772831916809}, {"text": "consistency", "start_pos": 434, "end_pos": 445, "type": "METRIC", "confidence": 0.5886887311935425}]}, {"text": "What are the factors that lead to the adoption of a totally new annotation scheme rather than using an existing annotation scheme?", "labels": [], "entities": []}, {"text": "Since the development of entirely new annotation guidelines is a time-consuming endeavor, it is worth considering whether totally new development is necessary.", "labels": [], "entities": []}, {"text": "It maybe necessary, if the annotation task is entirely new, or if the goals for using the annotation are entirely new, and neither can take advantage of existing resources.", "labels": [], "entities": []}, {"text": "When LDC began a project to create English treebank annotations on web text data, we chose to use the existing Penn Treebank guidelines (), but to make additions and adaptations to account for the non-canonical language that appears in internet communication.", "labels": [], "entities": [{"text": "Penn Treebank guidelines", "start_pos": 111, "end_pos": 135, "type": "DATASET", "confidence": 0.9882142345110575}]}, {"text": "The existing guidelines addressed most of the syntactic structures that were likely to come up, and the existing annotation tool could handle most of them as well.", "labels": [], "entities": []}, {"text": "However, the novel constructions that were present in the data required new guidelines, and some new features also had to be added to the annotation tool.", "labels": [], "entities": []}, {"text": "In this case, developing entirely new annotation guidelines and tools would have been prohibitively expensive in both time and effort, and the combination of existing and new worked well for the project (.", "labels": [], "entities": []}, {"text": "Similarly, LDC developed Entities, Relations, and Events (ERE) annotation to support requirements in the DEFT program, including informal genres, and based that development on adapting existing ACE guidelines ().", "labels": [], "entities": []}, {"text": "LDC first defined Light ERE as a simplified form of ACE annotation, with the goal of being able to rapidly produce consistently labeled data in multiple languages), taking advantage of the taxonomy and distinctions developed for ACE.", "labels": [], "entities": [{"text": "LDC", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.899955153465271}]}, {"text": "Ina second phase of development, Rich ERE expanded entity, relation and event ontologies and also expanded the notion of what is taggable, to provide better support for evaluation tasks in the program.", "labels": [], "entities": []}, {"text": "Rich ERE also introduced expanded event coreference with the notion of event hoppers, particularly with respect to event mention and event argument granularity variation (.", "labels": [], "entities": [{"text": "Rich ERE", "start_pos": 0, "end_pos": 8, "type": "DATASET", "confidence": 0.9392032325267792}, {"text": "event coreference", "start_pos": 34, "end_pos": 51, "type": "TASK", "confidence": 0.7063463479280472}]}, {"text": "Treebank and ERE guidelines that have been completed for English have been later adapted for other languages as well -for example, Modern Standard Arabic and also dialectal Arabic treebanks (, as well as Chinese and Spanish ERE ().", "labels": [], "entities": []}, {"text": "Clearly, new guidelines are necessary to account for language-specific constructions for each language and annotation task, but developing them based on existing guidelines for another language is a considerable head start.", "labels": [], "entities": []}, {"text": "How do you decide on the granularity of the distinctions you choose to annotate?", "labels": [], "entities": []}, {"text": "We aim fora level of granularity in annotation distinctions that is \uf0b7 Consistent with goals of the annotation task and the guidelines \uf0b7 Useful for downstream users of the data or additional downstream annotation \uf0b7 Possible for annotators to distinguish reliably For example, in part-of-speech tagging English web and SMS/Chat text, we make a distinction between emoticons and other decorative uses of punctuation.", "labels": [], "entities": [{"text": "part-of-speech tagging English web and SMS/Chat text", "start_pos": 278, "end_pos": 330, "type": "TASK", "confidence": 0.8597715894381205}]}, {"text": "End users of the data have suggested that the distinction could be useful, since there could be a semantic difference between the two uses, and annotators are able to make the distinction reliably.", "labels": [], "entities": []}, {"text": "Ina more structural example from the same data, the syntactic annotation of internet initialisms (such as lol, icymi, rofl, etc.) requires a decision about how much internal structure to give them.", "labels": [], "entities": []}, {"text": "Since not every word of the spelled out version is necessarily part of the initials, and since in any case there is often disagreement about what the full spelled out version should be, we do not spell out internet initialisms as part of the annotation.", "labels": [], "entities": []}, {"text": "They are left as written and annotated by function in the tree, even if the spelled out version could have internal structure.", "labels": [], "entities": []}, {"text": "For example, \"atm\" for at the moment is annotated simply as a one-word temporal adverbial phrase (although the fully spelled out at the moment would be a more complex prepositional phrase that includes a noun phrase complement): (ADVP-TMP atm) However, if an initialism takes additional arguments, such as clausal arguments of \"idk\" for I don't know, the argument structure is shown in the tree, so that it is as consistent as possible with other similar structures.", "labels": [], "entities": []}, {"text": "It more closely matches annotator intuitions, and it gives end users a more complete picture of the annotated events and their participants.", "labels": [], "entities": []}, {"text": "For building new resources for NCLs, is it still worthwhile to invest a huge amount of time and human labour for manual annotation, considering that the annotators spend most of their time making arbitrary decisions, and that the aim of building 'high-quality resources' for NCLs might not be realistic?", "labels": [], "entities": []}, {"text": "Manually annotated resources provide information that may not be possible to determine using automated systems only.", "labels": [], "entities": []}, {"text": "High-quality manual annotation of non-canonical language is possible to achieve, given clear annotation guidelines and careful training of annotators.", "labels": [], "entities": []}, {"text": "The premise of the question -that annotators must spend most of their time making arbitrary decisions -seems incorrect tome.", "labels": [], "entities": []}, {"text": "It is possible to eliminate or minimize arbitrary decisions in the development of annotation guidelines when that is a priority.", "labels": [], "entities": []}, {"text": "It is also important to keep in mind, however, that different projects and different users may have different requirements regarding quality.", "labels": [], "entities": []}, {"text": "\"High quality\" will not mean the same thing to everybody, and an annotated corpus is valuable if it helps the end users do what they want to do with it.", "labels": [], "entities": []}, {"text": "Not all end users require high annotator consistency, and not all end users require a notion of a single right answer.", "labels": [], "entities": []}, {"text": "In addition, not all annotation \"improvements\" have the same cost, or the same benefit.", "labels": [], "entities": []}, {"text": "Some annotation updates maybe quite simple or fast but are high value in terms of system performance.", "labels": [], "entities": []}, {"text": "Other updates might be difficult or slow and end up not bearing much fruit for the end users.", "labels": [], "entities": []}, {"text": "A close feedback loop between corpus creators and corpus users is helpful in terms of selecting what kinds of updates are worthwhile given limited resources.", "labels": [], "entities": []}, {"text": "This type of beneficial feedback loop was in place during the development of the Arabic Treebank and Arabic morphological analyzers and parsers).", "labels": [], "entities": [{"text": "Arabic Treebank", "start_pos": 81, "end_pos": 96, "type": "DATASET", "confidence": 0.9527675807476044}]}], "datasetContent": [], "tableCaptions": []}