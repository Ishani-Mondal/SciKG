{"title": [{"text": "Tuning Phrase-Based Segmented Translation fora Morphologically Complex Target Language", "labels": [], "entities": [{"text": "Tuning Phrase-Based Segmented Translation", "start_pos": 0, "end_pos": 41, "type": "TASK", "confidence": 0.8148492127656937}]}], "abstractContent": [{"text": "This article describes the Aalto University entry to the English-to-Finnish shared translation task in WMT 2015.", "labels": [], "entities": [{"text": "English-to-Finnish shared translation task in WMT 2015", "start_pos": 57, "end_pos": 111, "type": "TASK", "confidence": 0.7230860931532723}]}, {"text": "The system participates in the constrained condition, but in addition we impose some further constraints, using no language-specific resources beyond those provided in the task.", "labels": [], "entities": []}, {"text": "We use a morphological segmenter, Morfessor FlatCat, but train and tune it in an un-supervised manner.", "labels": [], "entities": [{"text": "Morfessor FlatCat", "start_pos": 34, "end_pos": 51, "type": "DATASET", "confidence": 0.8303947448730469}]}, {"text": "The system could thus be used for another language pair with a morphologically complex target language, without needing modification or additional resources.", "labels": [], "entities": []}], "introductionContent": [{"text": "In isolating languages, such as English, suitable smallest units of translation are easy to find using whitespace and punctuation characters as delimiters.", "labels": [], "entities": []}, {"text": "This approach of using words as the smallest unit of translation is problematic for synthetic languages with rich inflection, derivation or compounding.", "labels": [], "entities": []}, {"text": "Such languages have very large vocabularies, leading to sparse statistics and many out-of-vocabulary words.", "labels": [], "entities": []}, {"text": "A synthetic language uses fewer words than an isolating language to express the same sentence, by combining several grammatical markers into each word and using compound words.", "labels": [], "entities": []}, {"text": "This difference in granularity is problematic in alignment, when a word in the isolating language properly aligns with only apart of a word in the synthetic language.", "labels": [], "entities": [{"text": "alignment", "start_pos": 49, "end_pos": 58, "type": "TASK", "confidence": 0.960317075252533}]}, {"text": "In order to balance the number of tokens between target and source, it is often possible to segment the morphologically richer side.", "labels": [], "entities": []}, {"text": "Oversegmentation is detrimental, however, as longer windows of history need to be used, and useful phrases become more difficult to extract.", "labels": [], "entities": []}, {"text": "It is therefore important to find a balance in the amount of segmentation.", "labels": [], "entities": []}, {"text": "A linguistically accurate segmentation maybe oversegmented for the task of translation, if some of the distinctions are either unmarked or marked in a similar way in the other language.", "labels": [], "entities": [{"text": "translation", "start_pos": 75, "end_pos": 86, "type": "TASK", "confidence": 0.9767191410064697}]}, {"text": "An increase in the number of tokens means that the distance spanned by dependencies becomes longer.", "labels": [], "entities": []}, {"text": "Recurrent Neural Network (RNN) based language models have been shown to perform well for English).", "labels": [], "entities": []}, {"text": "Their strength lies in being theoretically capable of modeling arbitrarily long dependencies.", "labels": [], "entities": []}, {"text": "Moreover, a huge vocabulary is particularly detrimental for neural language models due to their computationally heavy training and need to marginalize over the whole vocabulary during prediction.", "labels": [], "entities": []}, {"text": "As morphological segmentation can reduce the vocabulary size considerably, using RNN language models seems even more suitable for this approach.", "labels": [], "entities": []}, {"text": "Our system is designed for translation in the direction from a morphologically less complex to a more complex language.", "labels": [], "entities": [{"text": "translation", "start_pos": 27, "end_pos": 38, "type": "TASK", "confidence": 0.977741539478302}]}, {"text": "The opposite direction -simplifying morphology -has received more attention, especially with English as the target language.", "labels": [], "entities": []}, {"text": "Of the target languages in this year's task, Finnish is the most difficult to translate into, shown by and reconfirmed by the evaluations of this shared task.", "labels": [], "entities": []}, {"text": "Even though the use of supervised linguistic tools (such as taggers, parsers, or morphological analyzers) was allowed in the constrained condition, our method does not use them.", "labels": [], "entities": []}, {"text": "It is therefore applicable to other morphologically complex target languages.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 2: The data sets used for different purposes. \"en-fi\" signifies that parallel data was used,  \"fi\" signifies monolingual data, or using only the Finnish side of parallel data.", "labels": [], "entities": []}, {"text": " Table 3: Results of evaluation.", "labels": [], "entities": []}]}