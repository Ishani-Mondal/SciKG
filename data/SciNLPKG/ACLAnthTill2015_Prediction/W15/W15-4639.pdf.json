{"title": [{"text": "Stochastic Language Generation in Dialogue using Recurrent Neural Networks with Convolutional Sentence Reranking", "labels": [], "entities": [{"text": "Stochastic Language Generation", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.7491490443547567}]}], "abstractContent": [{"text": "The natural language generation (NLG) component of a spoken dialogue system (SDS) usually needs a substantial amount of handcrafting or a well-labeled dataset to be trained on.", "labels": [], "entities": [{"text": "natural language generation (NLG)", "start_pos": 4, "end_pos": 37, "type": "TASK", "confidence": 0.8182035386562347}, {"text": "spoken dialogue system (SDS)", "start_pos": 53, "end_pos": 81, "type": "TASK", "confidence": 0.6822149654229482}]}, {"text": "These limitations add significantly to development costs and make cross-domain, multilingual dialogue systems intractable.", "labels": [], "entities": []}, {"text": "Moreover, human languages are context-aware.", "labels": [], "entities": []}, {"text": "The most natural response should be directly learned from data rather than depending on pre-defined syntaxes or rules.", "labels": [], "entities": []}, {"text": "This paper presents a statistical language generator based on a joint recurrent and convolu-tional neural network structure which can be trained on dialogue act-utterance pairs without any semantic alignments or pre-defined grammar trees.", "labels": [], "entities": []}, {"text": "Objective metrics suggest that this new model outperforms previous methods under the same experimental conditions.", "labels": [], "entities": []}, {"text": "Results of an evaluation by human judges indicate that it produces not only high quality but linguistically varied utterances which are preferred compared to n-gram and rule-based systems .", "labels": [], "entities": []}], "introductionContent": [{"text": "Conventional spoken dialogue systems (SDS) are expensive to build because many of the processing components require a substantial amount of handcrafting ().", "labels": [], "entities": [{"text": "spoken dialogue systems (SDS)", "start_pos": 13, "end_pos": 42, "type": "TASK", "confidence": 0.7163289686044058}]}, {"text": "In the past decade, significant progress has been made in applying statistical methods to automate the speech understanding and dialogue management components of an SDS, including making them more easily extensible to other application domains ().", "labels": [], "entities": [{"text": "speech understanding and dialogue management", "start_pos": 103, "end_pos": 147, "type": "TASK", "confidence": 0.671515840291977}]}, {"text": "However, due to the difficulty of collecting semantically-annotated corpora, the use of data-driven NLG for SDS remains relatively unexplored and rule-based generation remains the norm for most systems.", "labels": [], "entities": [{"text": "SDS", "start_pos": 108, "end_pos": 111, "type": "TASK", "confidence": 0.9611724019050598}]}, {"text": "The goal of the NLG component of an SDS is to map an abstract dialogue act consisting of an act type and a set of attribute-value pairs into an appropriate surface text (see below for some examples).", "labels": [], "entities": []}, {"text": "An early example of a statistical NLG system is HALOGEN by which uses an n-gram language model (LM) to rerank a set of candidates generated by a handcrafted generator.", "labels": [], "entities": []}, {"text": "In order to reduce the amount of handcrafting and make the approach more useful in SDS, replaced the handcrafted generator with a set of word-based n-gram LM-based generators, one for each dialogue type and then reranked the generator outputs using a set of rules to produce the final response.", "labels": [], "entities": [{"text": "SDS", "start_pos": 83, "end_pos": 86, "type": "TASK", "confidence": 0.9787729978561401}]}, {"text": "Although's approach limits the amount of handcrafting to a small set of post-processing rules, their system incurs a large computational cost in the over-generation phase and it is difficult to ensure that all of the required semantics are covered by the selected output.", "labels": [], "entities": []}, {"text": "More recently, a phrase-based NLG system called BAGEL trained from utterances aligned with coarse-grained semantic concepts has been described (.", "labels": [], "entities": [{"text": "BAGEL", "start_pos": 48, "end_pos": 53, "type": "METRIC", "confidence": 0.8544458746910095}]}, {"text": "By implicitly modelling paraphrases, Bagel can generate linguistically varied utterances.", "labels": [], "entities": []}, {"text": "However, collecting semantically-aligned corpora is expensive and time consuming, which limits Bagel's scalability to new domains.", "labels": [], "entities": []}, {"text": "This paper presents a neural network based NLG system that can be fully trained from dia-log act-utterance pairs without any semantic alignments between the two.", "labels": [], "entities": []}, {"text": "We start in Section 3 by presenting a generator based on a recurrent neural network language model (RNNLM) () which is trained on a delexicalised corpus ( ) whereby each value has been replaced by a symbol representing its corresponding slot.", "labels": [], "entities": []}, {"text": "Ina final postprocessing phase, these slot symbols are converted back to the corresponding slot values.", "labels": [], "entities": []}, {"text": "While generating, the RNN generator is conditioned on an auxiliary dialogue act feature and a controlling gate to over-generate candidate utterances for subsequent reranking.", "labels": [], "entities": []}, {"text": "In order to account for arbitrary slot-value pairs that cannot be routinely delexicalized in our corpus, Section 3.1 describes a convolutional neural network (CNN)) sentence model which is used to validate the semantic consistency of candidate utterances during reranking.", "labels": [], "entities": []}, {"text": "Finally, by adding a backward RNNLM reranker into the model in Section 3.2, output fluency is further improved.", "labels": [], "entities": []}, {"text": "Training and decoding details of the proposed system are described in Section 3.3 and 3.4.", "labels": [], "entities": []}, {"text": "Section 4 presents an evaluation of the proposed system in the context of an application providing information about restaurants in the San Francisco area.", "labels": [], "entities": []}, {"text": "In Section 4.2, we first show that new generator outperforms's utterance class LM approach using objective metrics, whilst at the same time being more computationally efficient.", "labels": [], "entities": []}, {"text": "In order to assess the subjective performance of our system, pairwise preference tests are presented in Section 4.3.", "labels": [], "entities": []}, {"text": "The results show that our approach can produce high quality utterances that are considered to be more natural than a rule-based generator.", "labels": [], "entities": []}, {"text": "Moreover, by sampling utterances from the top reranked output, our system can also generate linguistically varied utterances.", "labels": [], "entities": []}, {"text": "Section 4.4 provides a more detailed analysis of the contribution of each component of the system to the final performance.", "labels": [], "entities": []}, {"text": "We conclude with a brief summary and future work in Section 5.", "labels": [], "entities": []}], "datasetContent": [{"text": "The target application area for our generation system is a spoken dialogue system providing information about restaurants in San Francisco.", "labels": [], "entities": []}, {"text": "There are 8 system dialogue act types such as inform to present information about restaurants, confirm to check that a slot value has been recognised correctly, and reject to advise that the user's constraints cannot be met gives the full list with examples); and there are 12 attributes (slots): name, count, food, near, price, pricerange, postcode, phone, address, area, goodformeal, and kidsallowed, in which all slots are categorical except kidsallowed which is binary.", "labels": [], "entities": []}, {"text": "To form a training corpus, dialogues from a set of 3577 dialogues collected in a user trial of a statistical dialogue manager proposed by were randomly sampled and shown to workers recruited via the Amazon Mechanical Turk service.", "labels": [], "entities": []}, {"text": "Workers were shown each dialogue turn by turn and asked to enter an appropriate system response in natural English corresponding to each system dialogue act.", "labels": [], "entities": []}, {"text": "The resulting corpus contains 5193 hand-crafted system utterances from 1006 randomly sampled dialogues.", "labels": [], "entities": []}, {"text": "Each categorical value was replaced by a token representing its slot, and slots that appeared multiple times in a dialogue act were merged into one.", "labels": [], "entities": []}, {"text": "This resulted in 228 distinct dialogue acts.", "labels": [], "entities": []}, {"text": "The system was implemented using the Theano library ().", "labels": [], "entities": [{"text": "Theano library", "start_pos": 37, "end_pos": 51, "type": "DATASET", "confidence": 0.9852882623672485}]}, {"text": "The system was trained by partitioning the 5193 utterances into a training set, validation set, and testing set in the ratio 3:1:1, respectively.", "labels": [], "entities": []}, {"text": "The frequency of each action type and slot-value pair differs quite markedly across the corpus, hence up-sampling was used to make the corpus more uniform.", "labels": [], "entities": []}, {"text": "Since our generator works stochastically and the trained networks can differ depending on the initialisation, all the results shown below were averaged over 10 randomly initialised networks.", "labels": [], "entities": []}, {"text": "The BLEU-4 metric was used for the objective evaluation ().", "labels": [], "entities": [{"text": "BLEU-4", "start_pos": 4, "end_pos": 10, "type": "METRIC", "confidence": 0.9983079433441162}]}, {"text": "To do this, about 60 judges were recruited using Amazon Mechanical Turk and system responses were generated for the remaining 2571 unseen dialogues mentioned in Section 4.1.", "labels": [], "entities": [{"text": "Amazon Mechanical Turk", "start_pos": 49, "end_pos": 71, "type": "DATASET", "confidence": 0.9268292387326559}]}, {"text": "Each judge was then shown a randomly selected dialogue, turn by turn.", "labels": [], "entities": []}, {"text": "At each turn, two utterances were generated from two different systems and presented to the judge who was asked to score each utterance in terms of informativeness and naturalness (rating out of 5), and also asked to state a preference between the two taking account of the given dialogue act and the dialogue context.", "labels": [], "entities": []}, {"text": "Here informativeness is defined as whether the utterance contains all the information specified in the dialogue act, and naturalness is defined as whether the utterance could have been produced by a human.", "labels": [], "entities": []}, {"text": "The trial was run pairwise across four systems: the RNN system using 1-best utterance RNN 1 , the RNN system sampling from the top 5 utterances RNN 5 , the O&R approach sampling from top 5 utterances O&R 5 , and a handcrafted baseline.", "labels": [], "entities": []}, {"text": "The result is shown in.", "labels": [], "entities": []}, {"text": "As can be seen, the human judges preferred both RNN 1 and RNN 5 compared to the rule-based generator and the preference is statistically significant.", "labels": [], "entities": []}, {"text": "Furthermore, the RNN systems scored higher in both informativeness and naturalness metrics, though the difference for informativeness is not statistically significant.", "labels": [], "entities": []}, {"text": "When comparing RNN 1 with RNN 5 , RNN 1 was judged to produce higher quality utterances but overall the diversity of output offered by RNN 5 made it the preferred system.", "labels": [], "entities": []}, {"text": "Even though the preference is not statistically significant, it echoes previous findings) that showed that language variability by paraphrasing in dialogue systems is generally beneficial.", "labels": [], "entities": []}, {"text": "Lastly, RNN 5 was thought to be significantly better than O&R in terms of informativeness.", "labels": [], "entities": [{"text": "RNN 5", "start_pos": 8, "end_pos": 13, "type": "DATASET", "confidence": 0.6340932846069336}, {"text": "O&R", "start_pos": 58, "end_pos": 61, "type": "TASK", "confidence": 0.49660754203796387}]}, {"text": "This result verified our findings in Section 4.2 that O&R suffers from high slot error rates compared to the RNN system.", "labels": [], "entities": [{"text": "O&R", "start_pos": 54, "end_pos": 57, "type": "TASK", "confidence": 0.6096973220507304}, {"text": "slot error rates", "start_pos": 76, "end_pos": 92, "type": "METRIC", "confidence": 0.7113093733787537}]}], "tableCaptions": [{"text": " Table 2: Comparison of top-1 utterance between  the RNN-based system and three baselines. A  two-tailed Wilcoxon rank sum test was applied to  compare the RNN model with the best O&R sys- tem (the 3-slot, 5g configuration) over 10 random  seeds. (*=p<.005)", "labels": [], "entities": []}, {"text": " Table 3: Pairwise comparison between four systems. Two quality evaluations (rating out of 5) and one  preference test were performed in each case. Statistical significance was computed using a two-tailed  Wilcoxon rank sum test and a two-tailed binomial test (*=p<.05, **=p<.005).", "labels": [], "entities": [{"text": "Statistical significance", "start_pos": 148, "end_pos": 172, "type": "METRIC", "confidence": 0.7482716143131256}]}, {"text": " Table 3. As can be  seen, the human judges preferred both RNN 1 and  RNN 5 compared to the rule-based generator and  the preference is statistically significant. Further- more, the RNN systems scored higher in both in- formativeness and naturalness metrics, though the  difference for informativeness is not statistically", "labels": [], "entities": []}]}