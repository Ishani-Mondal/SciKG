{"title": [{"text": "The RWTH Aachen German-English Machine Translation System for WMT 2015", "labels": [], "entities": [{"text": "RWTH Aachen German-English Machine Translation", "start_pos": 4, "end_pos": 50, "type": "TASK", "confidence": 0.8028949856758117}, {"text": "WMT", "start_pos": 62, "end_pos": 65, "type": "TASK", "confidence": 0.8597719073295593}]}], "abstractContent": [{"text": "This paper describes the statistical machine translation system developed at RWTH Aachen University for the German\u2192English translation task of the EMNLP 2015 Tenth Workshop on Statistical Machine Translation (WMT 2015).", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 25, "end_pos": 56, "type": "TASK", "confidence": 0.6922669013341268}, {"text": "German\u2192English translation task of the EMNLP 2015 Tenth Workshop on Statistical Machine Translation (WMT 2015)", "start_pos": 108, "end_pos": 218, "type": "TASK", "confidence": 0.766672504575629}]}, {"text": "A phrase-based machine translation system was applied and augmented with hierarchical phrase reordering and word class language models.", "labels": [], "entities": [{"text": "phrase-based machine translation", "start_pos": 2, "end_pos": 34, "type": "TASK", "confidence": 0.6471686959266663}]}, {"text": "Further, we ran discriminative maximum expected BLEU training for our system.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 48, "end_pos": 52, "type": "METRIC", "confidence": 0.9947798252105713}]}, {"text": "In addition, we utilized multiple feed-forward neural network language and translation models and a recurrent neural network language model for reranking.", "labels": [], "entities": []}], "introductionContent": [{"text": "For the WMT 2015 shared translation task 1 , RWTH utilized a state-of-the-art phrase-based translation system.", "labels": [], "entities": [{"text": "WMT 2015 shared translation task 1", "start_pos": 8, "end_pos": 42, "type": "TASK", "confidence": 0.7698009113470713}, {"text": "RWTH", "start_pos": 45, "end_pos": 49, "type": "DATASET", "confidence": 0.8005975484848022}, {"text": "phrase-based translation", "start_pos": 78, "end_pos": 102, "type": "TASK", "confidence": 0.6812335848808289}]}, {"text": "We participated in the German\u2192English translation task.", "labels": [], "entities": [{"text": "German\u2192English translation task", "start_pos": 23, "end_pos": 54, "type": "TASK", "confidence": 0.6053828239440918}]}, {"text": "The system included a hierarchical reordering model, a word class (cluster) language model, and discriminative maximum expected BLEU training.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 128, "end_pos": 132, "type": "METRIC", "confidence": 0.9456409811973572}]}, {"text": "Further, we reranked the nbest lists produced by our system with three feed-forward neural network models and a recurrent neural language model.", "labels": [], "entities": []}, {"text": "This paper is structured as follows: First, we briefly describe our preprocessing pipeline for the language pair German\u2192English in Section 2, which is based on our 2014 pipeline.", "labels": [], "entities": []}, {"text": "Next, morpho-syntactic analysis for preprocessing the data is described in Section 2.3.", "labels": [], "entities": []}, {"text": "Different alignment methods are discussed in Section 3.", "labels": [], "entities": [{"text": "alignment", "start_pos": 10, "end_pos": 19, "type": "TASK", "confidence": 0.9479886889457703}]}, {"text": "In Section 4, we present a summary of all methods used in our submission.", "labels": [], "entities": []}, {"text": "More details are given about the language models, maximum expected BLEU training (Section 4.4), the hierarchical reordering model (Section 4.5), feed-forward neural network training (Section 4.6), and recurrent neural network language model (Section 4.7).", "labels": [], "entities": [{"text": "BLEU", "start_pos": 67, "end_pos": 71, "type": "METRIC", "confidence": 0.9965266585350037}]}, {"text": "Experimental results are discussed in Section 5.", "labels": [], "entities": []}, {"text": "We conclude the paper in Section 6.", "labels": [], "entities": []}], "datasetContent": [{"text": "All setups were evaluated with).", "labels": [], "entities": []}, {"text": "To evaluate our models, we used the average of three MERT optimization runs for case sensitive BLEU () and case insensitive TER).", "labels": [], "entities": [{"text": "MERT", "start_pos": 53, "end_pos": 57, "type": "METRIC", "confidence": 0.9471685886383057}, {"text": "BLEU", "start_pos": 95, "end_pos": 99, "type": "METRIC", "confidence": 0.9713342785835266}, {"text": "TER", "start_pos": 124, "end_pos": 127, "type": "METRIC", "confidence": 0.8108320236206055}]}, {"text": "The results of the phrase-based system are summarized in.", "labels": [], "entities": []}, {"text": "It was tuned on the concatenation of newstest2011 and newstest2012.", "labels": [], "entities": [{"text": "newstest2011", "start_pos": 37, "end_pos": 49, "type": "DATASET", "confidence": 0.9599959850311279}, {"text": "newstest2012", "start_pos": 54, "end_pos": 66, "type": "DATASET", "confidence": 0.9268366694450378}]}, {"text": "The phrase-based baseline system, which included the hierarchical reordering model) and a word class language model (wcLM), reached a performance of 25.9% BLEU on newstest2014.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 155, "end_pos": 159, "type": "METRIC", "confidence": 0.9993909597396851}]}, {"text": "Maximum expected BLEU training selected on newstest2013 improved the results on newstest2014 by 0.3% BLEU absolute.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 17, "end_pos": 21, "type": "METRIC", "confidence": 0.9992203712463379}, {"text": "newstest2013", "start_pos": 43, "end_pos": 55, "type": "DATASET", "confidence": 0.9357913732528687}, {"text": "BLEU", "start_pos": 101, "end_pos": 105, "type": "METRIC", "confidence": 0.9996067881584167}]}, {"text": "There was improvement of 0.1% in BLEU on newstest2014 by replacing the old language models from WMT 2014 with an updated general 4-gram LM and word class LM.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 33, "end_pos": 37, "type": "METRIC", "confidence": 0.9979789853096008}, {"text": "WMT 2014", "start_pos": 96, "end_pos": 104, "type": "DATASET", "confidence": 0.9133749604225159}]}, {"text": "Further-more, adding an extra unpruned language model trained on the concatenation of the monolingual data improved the results on newstest2014 by 0.3% BLEU.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 152, "end_pos": 156, "type": "METRIC", "confidence": 0.9994921684265137}]}, {"text": "Adding three feed-forward neural network models yielded an improvement of 0.5% BLEU on newstest2013 and newstest2014.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 79, "end_pos": 83, "type": "METRIC", "confidence": 0.9996700286865234}, {"text": "newstest2014", "start_pos": 104, "end_pos": 116, "type": "DATASET", "confidence": 0.9182431101799011}]}, {"text": "Adding the LSTM language model improved the TER by an additional 0.1% on newstest2014 and by 0.2% on newstest2013.", "labels": [], "entities": [{"text": "TER", "start_pos": 44, "end_pos": 47, "type": "METRIC", "confidence": 0.9939466118812561}, {"text": "newstest2013", "start_pos": 101, "end_pos": 113, "type": "DATASET", "confidence": 0.9551584124565125}]}, {"text": "The submission system used all models and we chose the best optimization run on the development data.", "labels": [], "entities": []}, {"text": "This optimization run by itself was 0.5% BLEU stronger on newstest2014 compared to the average across three optimization runs which included this run.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 41, "end_pos": 45, "type": "METRIC", "confidence": 0.9998495578765869}, {"text": "newstest2014", "start_pos": 58, "end_pos": 70, "type": "DATASET", "confidence": 0.9561694264411926}]}], "tableCaptions": [{"text": " Table 1: Comparison of a simple GIZA++ alignment vs. merging multiple alignments. Even though the  multiple alignment approach did not improve the GIZA++ alignment for the baseline system, it improved  translation quality in combination with a neural network joint model (NNJM). BLEU and TER are given  in percentage.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 280, "end_pos": 284, "type": "METRIC", "confidence": 0.9989966750144958}, {"text": "TER", "start_pos": 289, "end_pos": 292, "type": "METRIC", "confidence": 0.9978989362716675}]}, {"text": " Table 2: Results for the German\u2192English translation task. The results are the average of three optimiza- tion runs. newstest2011 and newstest2012 were used as development data. The submission  system used all models and the best optimization run on the development data. BLEU and TER are given  in percentage.", "labels": [], "entities": [{"text": "German\u2192English translation task", "start_pos": 26, "end_pos": 57, "type": "TASK", "confidence": 0.624355411529541}, {"text": "BLEU", "start_pos": 272, "end_pos": 276, "type": "METRIC", "confidence": 0.9986627101898193}, {"text": "TER", "start_pos": 281, "end_pos": 284, "type": "METRIC", "confidence": 0.9965433478355408}]}]}