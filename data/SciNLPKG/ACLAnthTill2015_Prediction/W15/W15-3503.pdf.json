{"title": [{"text": "Integrating Case Frame into Japanese to Chinese Hierarchical Phrase-based Translation Model", "labels": [], "entities": [{"text": "Integrating Case Frame", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.6698037485281626}, {"text": "Hierarchical Phrase-based Translation", "start_pos": 48, "end_pos": 85, "type": "TASK", "confidence": 0.5588621993859609}]}], "abstractContent": [{"text": "This paper presents a novel approach to enhance hierarchical phrase-based (HP-B) machine translation systems with case frame (CF).we integrate the Japanese shallow CF into both rule extraction and decoding.", "labels": [], "entities": [{"text": "phrase-based (HP-B) machine translation", "start_pos": 61, "end_pos": 100, "type": "TASK", "confidence": 0.6565821667512258}, {"text": "rule extraction", "start_pos": 177, "end_pos": 192, "type": "TASK", "confidence": 0.795994758605957}]}, {"text": "All of these rules are then employed to decode new sentences in Japanese with source language case frame.", "labels": [], "entities": []}, {"text": "The results of experiments carried out on Japanese-Chinese test sets.", "labels": [], "entities": []}, {"text": "It shows that our approach maintains the advantages of HPB translation systems while at the same time naturally incorporates CF constraints.", "labels": [], "entities": [{"text": "HPB translation", "start_pos": 55, "end_pos": 70, "type": "TASK", "confidence": 0.6822839379310608}]}, {"text": "The case frame rules can complement Hiero-style rules.", "labels": [], "entities": []}, {"text": "Our approach is especially effective for language pairs with large word order differences, such as Japanese-to-Chinese.", "labels": [], "entities": []}], "introductionContent": [{"text": "In the Japanese-Chinese machine translation task, reordering is the main problem due to substantial differences in sentence structures between these two languages.", "labels": [], "entities": [{"text": "Japanese-Chinese machine translation task", "start_pos": 7, "end_pos": 48, "type": "TASK", "confidence": 0.6745500192046165}]}, {"text": "For example, Japanese has a subject-object-verb (SOV) structure, while, Chinese has a subject-verb-object (SVO) structure.", "labels": [], "entities": []}, {"text": "The pre-ordering technology is one way to handle this problem), but it needs to train a pre-ordering model.", "labels": [], "entities": []}, {"text": "An hierarchical phrase-based (HPB) model) is a powerful method to cover any format of translation pairs by using synchronous context free grammar.", "labels": [], "entities": []}, {"text": "Hiero grammars can capture complex nested translation relationships to handle reordering.", "labels": [], "entities": []}, {"text": "However, due to its compromise on the efficiency of rule extraction and decoding, (a) a source language span limit is applied with 10, (b) the number of non-terminals in one rule is set to 2, (c) there is a prohibition of consecutive nonterminals on the source language side of a rule and With a traditional approach, the typical H-PB model fails to capture complex reordering information as shown in.", "labels": [], "entities": [{"text": "rule extraction", "start_pos": 52, "end_pos": 67, "type": "TASK", "confidence": 0.7738176882266998}]}, {"text": "By contrast, has proposed case grammar, which is effectively proved and originally used in rule-based machine translation (RBMT) system.) defines the Japanese shallow CF that is widely and successfully used in Japanese dependency tasks provided by. shows the CF's ability to capture reordering information.", "labels": [], "entities": [{"text": "rule-based machine translation (RBMT)", "start_pos": 91, "end_pos": 128, "type": "TASK", "confidence": 0.7983462313810984}]}, {"text": "In this paper, we describe effective approaches to introducing source language Japanese CF in the Japanese-Chinese translation task.", "labels": [], "entities": [{"text": "Japanese-Chinese translation task", "start_pos": 98, "end_pos": 131, "type": "TASK", "confidence": 0.718514084815979}]}, {"text": "Unlike previous work, we are the first to use Japanese CF information on the HPB model, and to transform CF information into SCFG style rules, which is suitable and useful in the original HPB decoder.", "labels": [], "entities": [{"text": "HPB model", "start_pos": 77, "end_pos": 86, "type": "DATASET", "confidence": 0.9734288454055786}]}, {"text": "By importing CF into the HPB model, we expand search space and introduce fine-grained rules.", "labels": [], "entities": []}, {"text": "The remainder of this paper is organized as follows.", "labels": [], "entities": []}, {"text": "After introducing Japanese CF,the proposed approach is introduced in Section 3; the experimental results and associate analysis are given", "labels": [], "entities": [{"text": "Japanese CF,the", "start_pos": 18, "end_pos": 33, "type": "DATASET", "confidence": 0.7586082220077515}]}], "datasetContent": [{"text": "We report results for this Japanese-Chinese task.", "labels": [], "entities": []}, {"text": "We use two data sets, where one uses news from the 7th China Workshop on Machine Translation (CWMT) including 280 thousand sentence pairs for training, 500 sentence pairs for parameter optimization and 900 sentence pairs for testing, the other, from Asian Scientific Paper Excerpt Corpus-Japanese to Chinese (ASPEC-JC) includes 680 thousand pairs for training, 2090 sentence pairs for parameter optimization and 1800 sentence pairs for testing.", "labels": [], "entities": [{"text": "China Workshop on Machine Translation (CWMT)", "start_pos": 55, "end_pos": 99, "type": "TASK", "confidence": 0.724102221429348}, {"text": "Asian Scientific Paper Excerpt Corpus-Japanese to Chinese (ASPEC-JC)", "start_pos": 250, "end_pos": 318, "type": "DATASET", "confidence": 0.7796490758657455}]}, {"text": "The source side sentences are parsed by KNP ( into chunk dependency structures whose nodes are at chunk-level.", "labels": [], "entities": []}, {"text": "Also we achieve corresponding case frame analysis from byproduct of KNP.", "labels": [], "entities": []}, {"text": "The word alignment is obtained by running GIZA++) on the corpus in both direction and applying \"grow-diag-and\"refinement (.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 4, "end_pos": 18, "type": "TASK", "confidence": 0.6999283879995346}]}, {"text": "We apply SRI Language Modeling Toolkit) to train a 5-gram language model for target side sentences.", "labels": [], "entities": [{"text": "SRI Language Modeling", "start_pos": 9, "end_pos": 30, "type": "TASK", "confidence": 0.5686821639537811}]}], "tableCaptions": []}