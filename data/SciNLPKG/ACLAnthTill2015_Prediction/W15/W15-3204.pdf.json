{"title": [{"text": "The Second QALB Shared Task on Automatic Text Correction for Arabic", "labels": [], "entities": []}], "abstractContent": [{"text": "We present a summary of QALB-2015, the second shared task on automatic text correction of Arabic texts.", "labels": [], "entities": [{"text": "automatic text correction of Arabic texts", "start_pos": 61, "end_pos": 102, "type": "TASK", "confidence": 0.7579943885405859}]}, {"text": "The shared task extends QALB-2014, which focused on correcting errors in Arabic texts produced by native speakers of Arabic.", "labels": [], "entities": [{"text": "QALB-2014", "start_pos": 24, "end_pos": 33, "type": "DATASET", "confidence": 0.4977184236049652}, {"text": "correcting errors in Arabic texts produced by native speakers of Arabic", "start_pos": 52, "end_pos": 123, "type": "TASK", "confidence": 0.8813353451815519}]}, {"text": "The competition this year, in addition to native data, includes texts produced by learners of Arabic as a foreign language.", "labels": [], "entities": []}, {"text": "The report includes an overview of the QALB corpus, which is the dataset used for training and evaluation, an overview of participating systems, results of the competition and an analysis of the results and systems.", "labels": [], "entities": [{"text": "QALB corpus", "start_pos": 39, "end_pos": 50, "type": "DATASET", "confidence": 0.901393324136734}]}], "introductionContent": [{"text": "The task of text correction has recently been attracting a lot of attention in the Natural Language Processing (NLP) community, but most of the effort in this area concentrated on English, especially on errors made by learners of English as a Second Language.", "labels": [], "entities": [{"text": "text correction", "start_pos": 12, "end_pos": 27, "type": "TASK", "confidence": 0.8247953951358795}]}, {"text": "Four competitions devoted to error correction for non-native English writers took place recently: HOO) and CoNLL ().", "labels": [], "entities": [{"text": "error correction for non-native English writers", "start_pos": 29, "end_pos": 76, "type": "TASK", "confidence": 0.7082136819760004}, {"text": "HOO", "start_pos": 98, "end_pos": 101, "type": "METRIC", "confidence": 0.749602735042572}, {"text": "CoNLL", "start_pos": 107, "end_pos": 112, "type": "DATASET", "confidence": 0.6635072231292725}]}, {"text": "Shared tasks of this kind are extremely important, as they bring together researchers and promote the development of relevant techniques and dissemination of key resources, such as benchmark data sets.", "labels": [], "entities": []}, {"text": "In the area of Arabic text correction, there has been a significant body of work, as well ().", "labels": [], "entities": [{"text": "text correction", "start_pos": 22, "end_pos": 37, "type": "TASK", "confidence": 0.6914757937192917}]}, {"text": "However, due to the lack of a common benchmark data set, making progress on this task has been difficult.", "labels": [], "entities": []}, {"text": "The QALB shared task on automatic text correction of Arabic, organized within the framework of the Qatar Arabic Language Bank (QALB) project, 1 is the first effort aimed at constructing a benchmark data set, which will allow for development and evaluation of automatic correction systems for Arabic.", "labels": [], "entities": [{"text": "text correction of Arabic", "start_pos": 34, "end_pos": 59, "type": "TASK", "confidence": 0.8062111362814903}, {"text": "Qatar Arabic Language Bank (QALB) project,", "start_pos": 99, "end_pos": 141, "type": "DATASET", "confidence": 0.8534063431951735}]}, {"text": "In this paper, we present a summary of the second edition of the QALB competition.", "labels": [], "entities": [{"text": "QALB competition", "start_pos": 65, "end_pos": 81, "type": "DATASET", "confidence": 0.6776716709136963}]}, {"text": "The first one -QALB-2014 ( ) -took place in conjunction with the Arabic NLP workshop at EMNLP-2014 and focused on errors found in online commentaries produced by native speakers of Arabic.", "labels": [], "entities": [{"text": "Arabic NLP workshop at EMNLP-2014", "start_pos": 65, "end_pos": 98, "type": "DATASET", "confidence": 0.5763765037059784}]}, {"text": "QALB-2014 attracted a lot of attention and resulted in nine systems being submitted with a variety of approaches that included rule-based frameworks, machine-learning classifiers, and statistical machine translation methods.", "labels": [], "entities": [{"text": "QALB-2014", "start_pos": 0, "end_pos": 9, "type": "DATASET", "confidence": 0.9078745245933533}, {"text": "statistical machine translation", "start_pos": 184, "end_pos": 215, "type": "TASK", "confidence": 0.6569986840089163}]}, {"text": "This year's competition extends the first edition by adding another track that focuses on errors found in essays written by learners of Arabic.", "labels": [], "entities": []}, {"text": "Eight teams participated in the competition this year, including several participants from last year who submitted improved systems for the native track.", "labels": [], "entities": []}, {"text": "The non-native (L2) track also allowed the participants to determine to what extent their approaches need to be modified to adapt to anew set of errors.", "labels": [], "entities": []}, {"text": "Overall, QALB-2015 generated a diverse set of approaches for automatic text correction of Arabic.", "labels": [], "entities": [{"text": "automatic text correction of Arabic", "start_pos": 61, "end_pos": 96, "type": "TASK", "confidence": 0.7292297124862671}]}, {"text": "The rest of the paper is organized as follows.", "labels": [], "entities": []}, {"text": "In Section 2, we present the shared task framework.", "labels": [], "entities": []}, {"text": "This is followed by an overview of the QALB corpus (Section 3).", "labels": [], "entities": [{"text": "QALB corpus", "start_pos": 39, "end_pos": 50, "type": "DATASET", "confidence": 0.9185341000556946}]}, {"text": "Section 4 describes the shared task data, and Section 5 presents the approaches adopted by the participating teams.", "labels": [], "entities": []}, {"text": "Section 6 discusses the results of the competition.", "labels": [], "entities": []}, {"text": "Section 7 concludes the paper.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 5: Distribution of annotations by type in the shared task data. Error types denotes the action  required in order to correct the error.", "labels": [], "entities": [{"text": "Error", "start_pos": 71, "end_pos": 76, "type": "METRIC", "confidence": 0.9911457896232605}]}, {"text": " Table 4: Statistics on the shared task data.", "labels": [], "entities": []}, {"text": " Table 8: Official results on the test set (Alj-test- 2015). Column 1 shows the system rank ac- cording to the F 1 score. MADAMIRA refers to  the baseline of applying corrections proposed by  MADAMIRA.", "labels": [], "entities": [{"text": "Alj-test- 2015)", "start_pos": 44, "end_pos": 59, "type": "DATASET", "confidence": 0.9393051266670227}, {"text": "F 1 score", "start_pos": 111, "end_pos": 120, "type": "METRIC", "confidence": 0.9601415395736694}]}, {"text": " Table 9: Official results on the test set (L2-test- 2015). Column 1 shows the system rank according  to the F 1 score. Column 1 shows the system rank  according to the F 1 score. MADAMIRA refers to  the baseline of applying corrections proposed by  MADAMIRA.", "labels": [], "entities": [{"text": "F 1 score", "start_pos": 109, "end_pos": 118, "type": "METRIC", "confidence": 0.9701296091079712}, {"text": "F 1 score", "start_pos": 169, "end_pos": 178, "type": "METRIC", "confidence": 0.9586243828137716}]}, {"text": " Table 10: Alj-test-2015: Results on the test set in different settings: with punctuation errors removed  from evaluation; normalization errors removed; and when both punctuation and normalization errors are  removed. Only the best output from each team is shown.", "labels": [], "entities": [{"text": "Alj-test-2015", "start_pos": 11, "end_pos": 24, "type": "DATASET", "confidence": 0.9054130911827087}]}, {"text": " Table 11: L2-test-2015: Results on the test set in different settings: with punctuation errors removed  from evaluation; normalization errors removed; and when both punctuation and normalization errors are  removed. Only the best output from each team is shown.", "labels": [], "entities": []}]}