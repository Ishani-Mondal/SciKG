{"title": [{"text": "Detecting Document-level Context Triggers to Resolve Translation Ambiguity", "labels": [], "entities": [{"text": "Detecting Document-level Context Triggers", "start_pos": 0, "end_pos": 41, "type": "TASK", "confidence": 0.8342669904232025}, {"text": "Resolve Translation Ambiguity", "start_pos": 45, "end_pos": 74, "type": "TASK", "confidence": 0.8513511617978414}]}], "abstractContent": [{"text": "Most current machine translation systems translate each sentence independently, ignoring the context from previous sentences.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 13, "end_pos": 32, "type": "TASK", "confidence": 0.7236064076423645}]}, {"text": "This discourse unawareness can lead to incorrect translation of words or phrases that are ambiguous in the sentence.", "labels": [], "entities": []}, {"text": "For example, the German term Typen in the phrase diese Typen can be translated either into English types or guys.", "labels": [], "entities": []}, {"text": "However, knowing that it co-refers to the compound K\u00f6rpertypen (\"body types\") in the previous sentence helps to disam-biguate the term and translate it into types.", "labels": [], "entities": []}, {"text": "We propose a method of automatically detecting document-level trigger words (like K\u00f6rpertypen), whose presence helps to disambiguate translations of ambiguous terms.", "labels": [], "entities": []}, {"text": "In this preliminary study we analyze the method and its limitations, and outline future work directions.", "labels": [], "entities": []}], "introductionContent": [{"text": "Words with ambiguous senses and translations pose a core challenge for machine translation.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 71, "end_pos": 90, "type": "TASK", "confidence": 0.8119271695613861}]}, {"text": "For example, the English noun face is translated into German Gesicht (\"front of head\") or Wand (\"wall\") when talking about mountaineering.", "labels": [], "entities": []}, {"text": "Phrase-based Statistical Machine Translation (SMT) systems benefit from using the local context inside the phrases for disambiguation; on the other hand, global sentence-level and documentlevel context remains largely unmodelled.", "labels": [], "entities": [{"text": "Phrase-based Statistical Machine Translation (SMT)", "start_pos": 0, "end_pos": 50, "type": "TASK", "confidence": 0.7407614929335458}]}, {"text": "We focus on cases where the source of disambiguation lies in the sentences preceding the ambiguous term, for example: ...on the unclimbed East face of the Central Tower...", "labels": [], "entities": [{"text": "East face of the Central Tower", "start_pos": 138, "end_pos": 168, "type": "DATASET", "confidence": 0.7833983302116394}]}, {"text": "...we were swept from the face by a fiveday storm... and tackle the issue illustrated in the previous example, and show improvements in correctness, based on the one-translation-per-discourse hypothesis.", "labels": [], "entities": []}, {"text": "Specifically, their method uses the translation of the head of the compound (e.g. Wand in East face) for the term (e.g. face) that co-refers back to it in a later sentence.", "labels": [], "entities": []}, {"text": "Bridging Noun Phrases (NPs) area similar phenomenon that crosses sentence boundaries: The company wrote out anew job.", "labels": [], "entities": [{"text": "Bridging Noun Phrases (NPs)", "start_pos": 0, "end_pos": 27, "type": "TASK", "confidence": 0.8270437320073446}]}, {"text": "Here the bridging NP two applicants is ambiguous on its own, as applicants can be translated into Spanish as candidatos or solicitantes.", "labels": [], "entities": []}, {"text": "However, in the context of the antecedent of the bridging NP, anew job, applicants is more appropriately translated into candidatos.", "labels": [], "entities": []}, {"text": "In this work we generalize over both these problems (i.e. co-referent compounds and bridging NPs) and disambiguate translations using \"trigger words\": words whose presence in the preceding sentences indicates a certain context for the ambiguous term in the current sentence.", "labels": [], "entities": []}, {"text": "We focus on automatically detecting such trigger words universally without focusing on a single phenomenon like compound co-references or bridging, and analyze the results.", "labels": [], "entities": []}, {"text": "tions in P (\u00b7|driver) will reflect the frequency of usage and not the particular contexts.", "labels": [], "entities": []}, {"text": "We focus on trigger words that appear in the context of a particular word sense.", "labels": [], "entities": []}, {"text": "Identifying them helps to disambiguate the sense of an ambiguous word and translate it correctly.", "labels": [], "entities": []}, {"text": "We try to detect trigger words from the preceding context and use them as conditional variables in the translation distributions.", "labels": [], "entities": []}, {"text": "This means, for example, that p(tgt = \"pilote\"|src = \"driver\", trig = \"road\") should below, while p(tgt = \"pilote\"|src = \"driver\", trig = \"device\") should be much higher (where src is the source word, tgt -its translation hypothesis and trigthe trigger word).", "labels": [], "entities": []}, {"text": "To identify those trigger words we consider a simplistic method based on translation distribution similarity.", "labels": [], "entities": []}, {"text": "The core idea is that the translation distribution of an ambiguous word changes with the presence and absence of a trigger word.", "labels": [], "entities": []}, {"text": "That is, non-trigger words (e.g. function words and general vocabulary) lead to similar distributions (i.e. their presence and absence has little effect on the translation choice), whereas relevant triggers result in these two distributions being highly different.", "labels": [], "entities": []}, {"text": "To measure this distribution difference we compute the KL-divergence between them.", "labels": [], "entities": []}, {"text": "In other words, for each ambiguous term A we are searching for such a trigger word W from the preceding sentences that maximizes where \u2212W means the absence of the trigger word W from the preceding sentences.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this preliminary evaluation of our method we focus on the specific case of co-references to compounds, where the co-reference is an ambiguous word with several translations.", "labels": [], "entities": []}, {"text": "The co-reference is disambiguated using a trigger word from the preceding context (i.e. the compound that the word co-refers to).", "labels": [], "entities": []}, {"text": "The idea is that knowing which these compounds are we assess whether our method is able to detect them as relevant triggers.", "labels": [], "entities": []}, {"text": "The data comes from the German-English part of the WIT3 corpus (, which is a collection of TED talks in multiple languages.", "labels": [], "entities": [{"text": "WIT3 corpus", "start_pos": 51, "end_pos": 62, "type": "DATASET", "confidence": 0.9560486972332001}]}, {"text": "The corpus consists of 194'533 sentences and 3.6 million tokens split into 1'596 talks (i.e. documents).", "labels": [], "entities": []}, {"text": "The test set is also a collection of TED talks, consisting of 6'047 sentences and about 100'000 tokens.", "labels": [], "entities": []}, {"text": "The talks differ greatly in terms of the covered topics, and therefore, have a high potential for ambiguous translations between them.", "labels": [], "entities": []}, {"text": "This topic variety is so high that it is not feasible to tune SMT systems separately to each topic.", "labels": [], "entities": [{"text": "SMT", "start_pos": 62, "end_pos": 65, "type": "TASK", "confidence": 0.9856802225112915}]}, {"text": "However, it makes the corpus a feasible target for dynamic adaptation like our method.", "labels": [], "entities": []}, {"text": "For our experiments we first manually select four ambiguous words, and we then obtain the co-referenced compounds by applying the detection method described in ().", "labels": [], "entities": []}, {"text": "Next, we check whether our method detects these compounds as triggers.", "labels": [], "entities": []}, {"text": "The four selected words Bild, Land, Typ and Fl\u00e4che are presented in", "labels": [], "entities": [{"text": "Typ", "start_pos": 36, "end_pos": 39, "type": "METRIC", "confidence": 0.5172126889228821}, {"text": "Fl\u00e4che", "start_pos": 44, "end_pos": 50, "type": "METRIC", "confidence": 0.9607425332069397}]}], "tableCaptions": [{"text": " Table 1: The four ambiguous words selected for our experiments from the WIT3 corpus. The table shows  how the translation distribution of each word differ from document to document. Some translations are  noise due to wrong word alignments.", "labels": [], "entities": [{"text": "WIT3 corpus", "start_pos": 73, "end_pos": 84, "type": "DATASET", "confidence": 0.9539677202701569}]}, {"text": " Table 2: Comparison of the lemmas with the highest and lowest KL divergence score in the context of  Land considering the 4 preceding sentences. The Freq. column shows the total number of times the  lemma appears in the context of Land over the total occurrences of that lemma in the corpus.", "labels": [], "entities": [{"text": "KL divergence score", "start_pos": 63, "end_pos": 82, "type": "METRIC", "confidence": 0.8138633171717325}, {"text": "Freq.", "start_pos": 150, "end_pos": 155, "type": "DATASET", "confidence": 0.703332930803299}]}, {"text": " Table 3: Comparison of the resulting KL divergence ranking obtained considering the context of the pre- vious sentences up to 4. The table shows the ranking position of the compounds co-referenced by Land  in the corpus, and the difference between their distance score and the word with the highest distance.", "labels": [], "entities": [{"text": "KL divergence ranking", "start_pos": 38, "end_pos": 59, "type": "METRIC", "confidence": 0.6975178321202596}]}]}