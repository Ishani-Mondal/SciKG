{"title": [{"text": "DeepNL: a Deep Learning NLP pipeline", "labels": [], "entities": []}], "abstractContent": [{"text": "We present the architecture of a deep learning pipeline for natural language processing.", "labels": [], "entities": []}, {"text": "Based on this architecture we built a set of tools both for creating distributional vector representations and for performing specific NLP tasks.", "labels": [], "entities": []}, {"text": "Three methods are available for creating embeddings: feed-forward neural network, sentiment specific embeddings and embeddings based on counts and Hellinger PCA.", "labels": [], "entities": []}, {"text": "Two methods are provided for training a network to perform sequence tagging, a window approach and a convolutional approach.", "labels": [], "entities": [{"text": "sequence tagging", "start_pos": 59, "end_pos": 75, "type": "TASK", "confidence": 0.6819964200258255}]}, {"text": "The window approach is used for implementing a POS tagger and a NER tagger, the convolutional network is used for Semantic Role Labeling.", "labels": [], "entities": [{"text": "Semantic Role Labeling", "start_pos": 114, "end_pos": 136, "type": "TASK", "confidence": 0.8356210390726725}]}, {"text": "The library is implemented in Python with core numerical processing written in C++ using parallel linear algebra library for efficiency and scalability.", "labels": [], "entities": []}], "introductionContent": [{"text": "Distributional Semantic Models (DSM) that represent words as vectors of weights over a high dimensional feature space (, have proved very effective in representing semantic or syntactic aspects of lexicon.", "labels": [], "entities": []}, {"text": "Incorporating such representations has allowed improving many natural language tasks.", "labels": [], "entities": []}, {"text": "They also reduce the burden of feature selection since these models can be learned through unsupervised techniques from text.", "labels": [], "entities": []}, {"text": "Deep learning algorithms for NLP tasks exploit distributional representation of words.", "labels": [], "entities": []}, {"text": "In tagging applications such as POS tagging, NER tagging and Semantic Role Labeling (SRL), this has proved quite effective in reaching state of art accuracy and reducing reliance on manually engineered feature selection ().", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 32, "end_pos": 43, "type": "TASK", "confidence": 0.76934814453125}, {"text": "NER tagging", "start_pos": 45, "end_pos": 56, "type": "TASK", "confidence": 0.8539211750030518}, {"text": "Semantic Role Labeling (SRL)", "start_pos": 61, "end_pos": 89, "type": "TASK", "confidence": 0.7888734638690948}, {"text": "accuracy", "start_pos": 148, "end_pos": 156, "type": "METRIC", "confidence": 0.9981984496116638}]}, {"text": "Word embeddings have been exploited also in constituency parsing and dependency parsing.", "labels": [], "entities": [{"text": "constituency parsing", "start_pos": 44, "end_pos": 64, "type": "TASK", "confidence": 0.8939226567745209}, {"text": "dependency parsing", "start_pos": 69, "end_pos": 87, "type": "TASK", "confidence": 0.865879476070404}]}, {"text": "A further benefit of a deep learning approach is to allow performing multiple tasks jointly, and therefore reducing error propagation as well as improving efficiency.", "labels": [], "entities": [{"text": "error propagation", "start_pos": 116, "end_pos": 133, "type": "TASK", "confidence": 0.6730261445045471}]}, {"text": "This paper presents DeepNL, an NLP pipeline based on a common Deep Learning architecture: it consists of tools for creating embeddings, and tools that exploit word embeddings as features.", "labels": [], "entities": []}, {"text": "The current release includes a POS tagger, a NER, an SRL tagger and a dependency parser.", "labels": [], "entities": []}, {"text": "Two methods are supported for creating embeddings: an approach that uses neural network and one using Hellinger PCA ().", "labels": [], "entities": []}], "datasetContent": [{"text": "We tested the DeepNL sequence tagger on the CoNLL 2003 challenge 13 , a NER benchmark based on Reuters data.", "labels": [], "entities": [{"text": "DeepNL sequence tagger", "start_pos": 14, "end_pos": 36, "type": "DATASET", "confidence": 0.8508205413818359}, {"text": "CoNLL 2003 challenge 13", "start_pos": 44, "end_pos": 67, "type": "DATASET", "confidence": 0.9364011436700821}, {"text": "Reuters data", "start_pos": 95, "end_pos": 107, "type": "DATASET", "confidence": 0.9177800416946411}]}, {"text": "The tagger was trained with three types of features: the word embeddings from SENNA, a \"caps\" feature telling whether a word is in lowercase, uppercase, title case, or had at least one non-initial capital letter, and a gazetteer feature, based on the list provided by the organizers.", "labels": [], "entities": [{"text": "SENNA", "start_pos": 78, "end_pos": 83, "type": "DATASET", "confidence": 0.7320591807365417}]}, {"text": "The window size was set to 5, 300 hidden variables were used and training was iterated for 40 epochs.", "labels": [], "entities": []}, {"text": "In the following The slight difference with SENNA might be explained by the use of different gazetteers.", "labels": [], "entities": [{"text": "SENNA", "start_pos": 44, "end_pos": 49, "type": "DATASET", "confidence": 0.5385793447494507}]}, {"text": "The same sequence tagger can be used for POS tagging.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 41, "end_pos": 52, "type": "TASK", "confidence": 0.772530734539032}]}, {"text": "In this case the discrete features used are the same capitalization feature as for the NER and a suffix feature, which denotes whether a token ends with one of the 455 most frequent suffixes of length one or two characters in the training corpus.", "labels": [], "entities": [{"text": "NER", "start_pos": 87, "end_pos": 90, "type": "DATASET", "confidence": 0.9172284007072449}]}, {"text": "presents the results achieved by the POS tagger trained on the Penn Treebank, compared with the results of the reference system by, which uses rich features, and with the original SENNA implementation.", "labels": [], "entities": [{"text": "Penn Treebank", "start_pos": 63, "end_pos": 76, "type": "DATASET", "confidence": 0.9946745038032532}]}, {"text": "Both these experiments confirm that word embeddings can replace the use of complex manually engineered features for typical natural language processing tasks.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1. Performance on the NER task, using the  CoNLL 2003 benchmark.", "labels": [], "entities": [{"text": "NER task", "start_pos": 29, "end_pos": 37, "type": "TASK", "confidence": 0.9021879732608795}, {"text": "CoNLL 2003 benchmark", "start_pos": 50, "end_pos": 70, "type": "DATASET", "confidence": 0.96146027247111}]}, {"text": " Table 2. Performance on the POS task, using the Penn  Treebank, sections 0-18 for training, sections 22-24  for testing.", "labels": [], "entities": [{"text": "POS task", "start_pos": 29, "end_pos": 37, "type": "TASK", "confidence": 0.7073514461517334}, {"text": "Penn  Treebank", "start_pos": 49, "end_pos": 63, "type": "DATASET", "confidence": 0.9970374405384064}]}]}