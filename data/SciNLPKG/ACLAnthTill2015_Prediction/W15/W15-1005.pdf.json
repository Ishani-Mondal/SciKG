{"title": [{"text": "Unsupervised False Friend Disambiguation Using Contextual Word Clusters and Parallel Word Alignments", "labels": [], "entities": [{"text": "Unsupervised False Friend Disambiguation", "start_pos": 0, "end_pos": 40, "type": "TASK", "confidence": 0.542792059481144}, {"text": "Parallel Word Alignments", "start_pos": 76, "end_pos": 100, "type": "TASK", "confidence": 0.6353991130987803}]}], "abstractContent": [{"text": "Lexical false friends (FF) are the phenomena where words that look the same, do not have the same meaning or lexical usage.", "labels": [], "entities": [{"text": "Lexical false friends (FF)", "start_pos": 0, "end_pos": 26, "type": "TASK", "confidence": 0.8345262706279755}]}, {"text": "FF impose several challenges to statistical machine translation.", "labels": [], "entities": [{"text": "FF", "start_pos": 0, "end_pos": 2, "type": "TASK", "confidence": 0.8986067175865173}, {"text": "statistical machine translation", "start_pos": 32, "end_pos": 63, "type": "TASK", "confidence": 0.7004685004552206}]}, {"text": "We present a methodology which exploits word context modeling as well as information provided byword alignments for identifying false friends and choosing the right sense for them in the context.", "labels": [], "entities": [{"text": "word context modeling", "start_pos": 40, "end_pos": 61, "type": "TASK", "confidence": 0.7301710645357767}]}, {"text": "We show that our approach enhances SMT lexical choice for false friends across language variants.", "labels": [], "entities": [{"text": "SMT lexical choice", "start_pos": 35, "end_pos": 53, "type": "TASK", "confidence": 0.9511264165242513}]}, {"text": "We demonstrate that our approach reduces word error rate (WER) and position independent error rate (PER) for Egyptian-English SMT by 0.6% and 0.1% compared to the baseline.", "labels": [], "entities": [{"text": "word error rate (WER)", "start_pos": 41, "end_pos": 62, "type": "METRIC", "confidence": 0.8757335692644119}, {"text": "position independent error rate (PER)", "start_pos": 67, "end_pos": 104, "type": "METRIC", "confidence": 0.9043659397533962}, {"text": "SMT", "start_pos": 126, "end_pos": 129, "type": "TASK", "confidence": 0.7856122851371765}]}], "introductionContent": [{"text": "False friends (FF), aka faux amis, are words in two or more language variants that are orthographically and/or phonetically similar but do not convey the same meaning.", "labels": [], "entities": [{"text": "False friends (FF), aka faux amis", "start_pos": 0, "end_pos": 33, "type": "TASK", "confidence": 0.7252368165387048}]}, {"text": "FF sense divergence is one of the main sources of performance degradation in statistical machine translation (SMT) systems.", "labels": [], "entities": [{"text": "FF sense divergence", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.7819112141927084}, {"text": "statistical machine translation (SMT)", "start_pos": 77, "end_pos": 114, "type": "TASK", "confidence": 0.7804824113845825}]}, {"text": "These words are frequently observed when the underlying distribution of the test set is different from that of the train data.", "labels": [], "entities": []}, {"text": "In other words, the sense of a particular word in the input sentence varies from all observed senses of that word in the train data.", "labels": [], "entities": []}, {"text": "Thus, SMT may choose the target language translation which is considered inappropriate based on the context.", "labels": [], "entities": [{"text": "SMT", "start_pos": 6, "end_pos": 9, "type": "TASK", "confidence": 0.9937030673027039}]}, {"text": "Standard form of a language has different informal spoken varieties which are known as dialects.", "labels": [], "entities": []}, {"text": "For instance, standard form of Arabic has different dialects.", "labels": [], "entities": []}, {"text": "These dialects typically share a set of cognates that could bear the same meaning in both varieties or only be shared homographs but serve as false friend.", "labels": [], "entities": []}, {"text": "The usage of dialects in textual social media and communication channels is rapidly increasing.", "labels": [], "entities": []}, {"text": "On the other hand, usually there is not enough dialectal parallel data to train the translation model and build standalone machine translation systems for dialects.", "labels": [], "entities": []}, {"text": "However, the standard official forms of language usually have a wealth of resources and tools that can be adapted to dialects of that language.", "labels": [], "entities": []}, {"text": "The main goal of this paper is to enhance dialectal SMT performance without any in-domain training data.", "labels": [], "entities": [{"text": "dialectal SMT", "start_pos": 42, "end_pos": 55, "type": "TASK", "confidence": 0.7518429756164551}]}, {"text": "We move towards this goal by performing a pre-processing phase which includes, 1) identifying false friends in the input sentence and, 2) replacing them with an appropriate equivalent from standard language which bears the same meaning.", "labels": [], "entities": []}, {"text": "By doing this, we benefit from availability of standard parallel data to choose a more accurate target translation for the false friends.", "labels": [], "entities": []}, {"text": "We aim to identify false friends without any labeled training data.", "labels": [], "entities": []}, {"text": "We then try to choose equivalents from the standard language for the identified false friends.", "labels": [], "entities": []}, {"text": "We exploit a classifier for identifying false friends and designing a word sense disambiguator for finding the best equivalent from the standard language.", "labels": [], "entities": []}, {"text": "We employ unsupervised word alignment from parallel text and a taxonomy-based semantic similarity measure ( to automatically acquire training data for the FF identifier.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 23, "end_pos": 37, "type": "TASK", "confidence": 0.7223195433616638}]}, {"text": "Our word sense disambiguator benefits from unsupervised word clusters to model the context.", "labels": [], "entities": [{"text": "word sense disambiguator", "start_pos": 4, "end_pos": 28, "type": "TASK", "confidence": 0.6712091763814291}]}, {"text": "We obtain word clusters from a large monolingual text in the standard language.", "labels": [], "entities": []}, {"text": "Training the model only involves counting the coocurrences of each word with word clusters for different context definitions.", "labels": [], "entities": []}, {"text": "During decoding (disambiguation), fora word in a sentence, we estimate the likelihood for each equivalent of that word given word clusters in its surrounding context.", "labels": [], "entities": []}, {"text": "We evaluate our method on Egyptian (EGY) to English (EN) SMT using a translation model trained on Modern Standard Arabic (MSA).", "labels": [], "entities": [{"text": "Egyptian (EGY) to English (EN) SMT", "start_pos": 26, "end_pos": 60, "type": "TASK", "confidence": 0.5632247775793076}, {"text": "Modern Standard Arabic (MSA)", "start_pos": 98, "end_pos": 126, "type": "DATASET", "confidence": 0.7661336759726206}]}, {"text": "We show that our approach improves EGY-to-EN SMT lexical choice and reachs 0.6% and 0.1% reduction in word error rate (WER) and position-independent error (PER) () over the baseline respectively.", "labels": [], "entities": [{"text": "EGY-to-EN SMT lexical choice", "start_pos": 35, "end_pos": 63, "type": "TASK", "confidence": 0.7653803825378418}, {"text": "word error rate (WER)", "start_pos": 102, "end_pos": 123, "type": "METRIC", "confidence": 0.9099110960960388}, {"text": "position-independent error (PER)", "start_pos": 128, "end_pos": 160, "type": "METRIC", "confidence": 0.8647547364234924}]}, {"text": "In summary, the main contributions of this paper are: 1) designing a FF identifier with a supervised classifier trained on automatically acquired labeled data, 2) designing a disambiguator for replacing FF with their equivalent standard form and 3) improving the SMT lexical choice on dialectal data without using any in-domain parallel data to train SMT model.", "labels": [], "entities": [{"text": "SMT lexical choice", "start_pos": 263, "end_pos": 281, "type": "TASK", "confidence": 0.9098103841145834}, {"text": "SMT", "start_pos": 351, "end_pos": 354, "type": "TASK", "confidence": 0.9723950624465942}]}, {"text": "The remainder of this paper is organized as follows: We give a literature overview in \u00a72.", "labels": [], "entities": []}, {"text": "We then detail our approach in \u00a73 . We present t experiments in \u00a74 and discuss the results in \u00a75.", "labels": [], "entities": []}, {"text": "We finally make conclusions in \u00a76.", "labels": [], "entities": []}], "datasetContent": [{"text": "Tools We use GIZA++ (Och and Ney, 2003) for word alignment.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 44, "end_pos": 58, "type": "TASK", "confidence": 0.8067198395729065}]}, {"text": "We obtain word clusters from word2vec () K-means word clustering tool.", "labels": [], "entities": [{"text": "word clustering", "start_pos": 49, "end_pos": 64, "type": "TASK", "confidence": 0.6788555681705475}]}, {"text": "We use the continuous bag of word model to build word vectors of size 200 using a word window of size 8 for both left and right.", "labels": [], "entities": []}, {"text": "The number of negative samples for logistic regression is set to 25 and threshold used for sub-sampling of frequent words is set to 10 \u22125 in the model with 15 iterations.", "labels": [], "entities": []}, {"text": "We also use full softmax to obtain the probability distribution.", "labels": [], "entities": []}, {"text": "We use AIDA (Elfardy and Diab, 2013) as the dialect identification tool.", "labels": [], "entities": [{"text": "dialect identification", "start_pos": 44, "end_pos": 66, "type": "TASK", "confidence": 0.7654272317886353}]}, {"text": "AIDA also provides a list of MSA equivalents for identified DA words in context.", "labels": [], "entities": [{"text": "AIDA", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.9217009544372559}]}], "tableCaptions": [{"text": " Table 1: Evaluation results (BLEU, METEOR (Banerjee and Lavie, 2005), TER (Snover et al., 2006),  WER, PER) on the Bolt-arz test set compared to the baselines.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 30, "end_pos": 34, "type": "METRIC", "confidence": 0.9988662004470825}, {"text": "METEOR", "start_pos": 36, "end_pos": 42, "type": "METRIC", "confidence": 0.9853310585021973}, {"text": "TER", "start_pos": 71, "end_pos": 74, "type": "METRIC", "confidence": 0.9988933205604553}, {"text": "WER", "start_pos": 99, "end_pos": 102, "type": "METRIC", "confidence": 0.9957020878791809}, {"text": "PER", "start_pos": 104, "end_pos": 107, "type": "METRIC", "confidence": 0.7694026231765747}, {"text": "Bolt-arz test set", "start_pos": 116, "end_pos": 133, "type": "DATASET", "confidence": 0.8595916430155436}]}, {"text": " Table 3: Percentage of BLEU-enhanced sen- tences/percentage of BLEU-degraded sentences for  different replacement approaches compared to each  baseline separately.", "labels": [], "entities": [{"text": "Percentage", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.9608808755874634}, {"text": "BLEU-enhanced sen- tences", "start_pos": 24, "end_pos": 49, "type": "METRIC", "confidence": 0.9105143696069717}, {"text": "BLEU-degraded", "start_pos": 64, "end_pos": 77, "type": "METRIC", "confidence": 0.9608907699584961}]}]}