{"title": [{"text": "Five Shades of Noise: Analyzing Machine Translation Errors in User-Generated Text", "labels": [], "entities": [{"text": "Analyzing Machine Translation Errors", "start_pos": 22, "end_pos": 58, "type": "TASK", "confidence": 0.691867008805275}]}], "abstractContent": [{"text": "It is widely accepted that translating user-generated (UG) text is a difficult task for modern statistical machine translation (SMT) systems.", "labels": [], "entities": [{"text": "translating user-generated (UG) text", "start_pos": 27, "end_pos": 63, "type": "TASK", "confidence": 0.7986473540465037}, {"text": "statistical machine translation (SMT)", "start_pos": 95, "end_pos": 132, "type": "TASK", "confidence": 0.7790307253599167}]}, {"text": "The translation quality metrics typically used in the SMT literature reflect the overall quality of the system output but provide little insight into what exactly makes UG text translation difficult.", "labels": [], "entities": [{"text": "SMT", "start_pos": 54, "end_pos": 57, "type": "TASK", "confidence": 0.9903518557548523}, {"text": "UG text translation", "start_pos": 169, "end_pos": 188, "type": "TASK", "confidence": 0.9041778643925985}]}, {"text": "This paper analyzes in detail the behavior of a state-of-the-art SMT system on five different types of informal text.", "labels": [], "entities": [{"text": "SMT", "start_pos": 65, "end_pos": 68, "type": "TASK", "confidence": 0.9914777874946594}]}, {"text": "The results help to demystify the poor SMT performance experienced by researchers who use SMT as an intermediate step of their UG-NLP pipeline, and to identify translation modeling aspects that the SMT community should more urgently address to improve translation of UG data.", "labels": [], "entities": [{"text": "SMT", "start_pos": 39, "end_pos": 42, "type": "TASK", "confidence": 0.9937868118286133}, {"text": "SMT", "start_pos": 90, "end_pos": 93, "type": "TASK", "confidence": 0.9633150100708008}, {"text": "translation modeling", "start_pos": 160, "end_pos": 180, "type": "TASK", "confidence": 0.9416946172714233}, {"text": "SMT community", "start_pos": 198, "end_pos": 211, "type": "TASK", "confidence": 0.9032177627086639}]}], "introductionContent": [{"text": "User-generated (UG) text such as found on social media and web forums poses different challenges to statistical machine translation (SMT) than formal text.", "labels": [], "entities": [{"text": "statistical machine translation (SMT)", "start_pos": 100, "end_pos": 137, "type": "TASK", "confidence": 0.8111505806446075}]}, {"text": "This is reflected by poor translation quality for informal genres (see for example), which is typically measured with automatic quality metrics such as BLEU (), METEOR (Banerjee and), or TER ().", "labels": [], "entities": [{"text": "BLEU", "start_pos": 152, "end_pos": 156, "type": "METRIC", "confidence": 0.9983000159263611}, {"text": "METEOR", "start_pos": 161, "end_pos": 167, "type": "METRIC", "confidence": 0.972515344619751}, {"text": "TER", "start_pos": 187, "end_pos": 190, "type": "METRIC", "confidence": 0.9684640765190125}]}, {"text": "These scores alone, however, only reflect the overall translation quality, and do not provide any insight in what exactly makes translating UG text hard.", "labels": [], "entities": [{"text": "translating UG text", "start_pos": 128, "end_pos": 147, "type": "TASK", "confidence": 0.8633347551027933}]}, {"text": "While such knowledge is crucial for improving SMT of UG text, surprisingly little work on error analysis for SMT of usergenerated text has been reported.", "labels": [], "entities": [{"text": "SMT", "start_pos": 46, "end_pos": 49, "type": "TASK", "confidence": 0.9971325397491455}, {"text": "SMT", "start_pos": 109, "end_pos": 112, "type": "TASK", "confidence": 0.994025468826294}]}, {"text": "Moreover, the notion of user-generated content  only partially specifies the exact nature of documents.", "labels": [], "entities": []}, {"text": "What all documents that can be classified as being UG have in common is the fact that they have been written by a lay-person, as opposed to a journalist or professional author, and that they have not undergone any editorial control.", "labels": [], "entities": []}, {"text": "UG text also tends to express the writer's opinion to a larger degree than news articles which generally strive for balance and nuance.", "labels": [], "entities": [{"text": "UG text", "start_pos": 0, "end_pos": 7, "type": "TASK", "confidence": 0.6613094508647919}]}, {"text": "Within UG text, we can distinguish several subclasses, including (i) message and dialog-oriented content such as short message service (SMS) texts, Internet chat messages, and transcripts of conversational speech, (ii) commentaries to news articles, often expressing an opinion about the corresponding articles and relating the content to the reader's situation, and (iii) weblogs, which can bear some resemblance to editorial pieces published by news organizations.", "labels": [], "entities": []}, {"text": "While UG text processing tasks are becoming more and more common, the research in SMT is still mostly driven by formal translation tasks 1 , and existing error analysis approaches are only partially useful for UG.", "labels": [], "entities": [{"text": "UG text processing tasks", "start_pos": 6, "end_pos": 30, "type": "TASK", "confidence": 0.8795641213655472}, {"text": "SMT", "start_pos": 82, "end_pos": 85, "type": "TASK", "confidence": 0.9952087998390198}]}, {"text": "In this work, we conduct a series of analyses on five different UG benchmark sets for two language pairs, Arabic-English and Chinese-English, with the goals of (i) explaining the typically poor SMT performance observed for UG texts, and (ii) identifying translation modeling aspects that should be addressed to improve translation of UG data.", "labels": [], "entities": [{"text": "SMT", "start_pos": 194, "end_pos": 197, "type": "TASK", "confidence": 0.9894903302192688}, {"text": "translation modeling", "start_pos": 254, "end_pos": 274, "type": "TASK", "confidence": 0.9429351389408112}, {"text": "translation of UG", "start_pos": 319, "end_pos": 336, "type": "TASK", "confidence": 0.8416264057159424}]}, {"text": "We not only contrast our observations with two news data sets, but we also show that SMT quality can vary significantly across different types of UG content, and that different UG types exhibit dissimilar error distributions.", "labels": [], "entities": [{"text": "SMT", "start_pos": 85, "end_pos": 88, "type": "TASK", "confidence": 0.9924001693725586}]}, {"text": "Specifically, we summarize our main findings as follows: \u2022 The SMS and chat benchmarks are the most distant from formal text at all the analyzed levels.", "labels": [], "entities": []}, {"text": "Errors in other types of UG are often more similar to news errors than to those in SMS and chat messages.", "labels": [], "entities": [{"text": "Errors", "start_pos": 0, "end_pos": 6, "type": "METRIC", "confidence": 0.9837694764137268}]}, {"text": "\u2022 SMT model coverage dramatically deteriorates for phrases of length 3 or longer inmost of the UG benchmarks.", "labels": [], "entities": [{"text": "SMT", "start_pos": 2, "end_pos": 5, "type": "TASK", "confidence": 0.9852560758590698}, {"text": "coverage", "start_pos": 12, "end_pos": 20, "type": "METRIC", "confidence": 0.6665235757827759}, {"text": "UG benchmarks", "start_pos": 95, "end_pos": 108, "type": "DATASET", "confidence": 0.7102320492267609}]}, {"text": "\u2022 Errors due to out-of-vocabulary (OOV) words in the source text substantially increase in number for UG data sets, but are considerably less common than errors due to source-target OOVs, i.e., phrase pairs that are not covered by the SMT models.", "labels": [], "entities": [{"text": "Errors", "start_pos": 2, "end_pos": 8, "type": "METRIC", "confidence": 0.9741136431694031}, {"text": "UG data sets", "start_pos": 102, "end_pos": 114, "type": "DATASET", "confidence": 0.8615108728408813}, {"text": "SMT", "start_pos": 235, "end_pos": 238, "type": "TASK", "confidence": 0.9740126729011536}]}], "datasetContent": [{"text": "We perform our error analysis on two language pairs, Arabic-English and Chinese-English.", "labels": [], "entities": []}, {"text": "For both language pairs we use evaluation sets for five types of user-generated text: SMS messages, chat messages, manual transcripts of phone conversations (called Conversational Telephone   Speech (CTS)), weblogs, and readers' comments to news articles.", "labels": [], "entities": []}, {"text": "The first four data sets originate from BOLT and NIST OpenMT, and are distributed by the Linguistic Data Consortium (LDC), while the last data set is crawled from the web.", "labels": [], "entities": [{"text": "BOLT", "start_pos": 40, "end_pos": 44, "type": "DATASET", "confidence": 0.8396937847137451}, {"text": "NIST OpenMT", "start_pos": 49, "end_pos": 60, "type": "DATASET", "confidence": 0.849782794713974}]}, {"text": "All UG experiments are contrasted with two news data sets; the news portions of NIST evaluation sets, and web-crawled news articles.", "labels": [], "entities": [{"text": "NIST evaluation sets", "start_pos": 80, "end_pos": 100, "type": "DATASET", "confidence": 0.867067813873291}]}, {"text": "For Arabic-English, the web-crawled news articles and comments originate from the Gen&Topic data set (van der, in which both genres cover the same distributions over various topics.", "labels": [], "entities": [{"text": "Gen&Topic data set", "start_pos": 82, "end_pos": 100, "type": "DATASET", "confidence": 0.8423548579216004}]}, {"text": "Consequently, any observed differences between the news and UG portions of this data set can be entirely attributed to genre differences and not to potential topical variation.", "labels": [], "entities": []}, {"text": "We have created similar-sized benchmark sets as much as possible, however sometimes limited by availability.", "labels": [], "entities": []}, {"text": "show the data specifications of the Arabic-English and ChineseEnglish evaluation sets, respectively.", "labels": [], "entities": [{"text": "ChineseEnglish evaluation sets", "start_pos": 55, "end_pos": 85, "type": "DATASET", "confidence": 0.826928714911143}]}, {"text": "Next, to gain a more fine-grained insight in why our SMT system makes its translation choices, we reimplement an evaluation approach proposed by, which analyzes SMT error types at the word alignment level.", "labels": [], "entities": [{"text": "SMT", "start_pos": 53, "end_pos": 56, "type": "TASK", "confidence": 0.9838459491729736}, {"text": "SMT error types", "start_pos": 161, "end_pos": 176, "type": "TASK", "confidence": 0.8766457239786783}, {"text": "word alignment", "start_pos": 184, "end_pos": 198, "type": "TASK", "confidence": 0.6739880591630936}]}, {"text": "The analysis exploits automatic word alignments between (i) a given source sentence and its reference translation, and (ii) the same source sentence and its automatic translation.", "labels": [], "entities": []}, {"text": "Each aligned source-reference word pair is examined for whether the alignment link is matched by the decoder.", "labels": [], "entities": []}, {"text": "Formally, f i is a foreign  word, e j is a reference word aligned to f i , a i,j is the alignment link between f i and e j , and H i is the set of output words that are aligned to f i by the decoder.", "labels": [], "entities": []}, {"text": "If e j \u2208 H i , the alignment link a i,j is marked as correct.", "labels": [], "entities": []}, {"text": "Otherwise, a i,j is categorized with one of the following error types:  In addition to the listed error types, Irvine et al. define SEARCH errors as errors due to pruning in beam search, and refer to the complete set of errors as the S 4 taxonomy.", "labels": [], "entities": [{"text": "SEARCH errors", "start_pos": 132, "end_pos": 145, "type": "METRIC", "confidence": 0.9684037864208221}]}, {"text": "For this analysis, however, SEARCH errors are indistinguishable from SCORE errors, and are therefore never assigned.", "labels": [], "entities": [{"text": "SEARCH errors", "start_pos": 28, "end_pos": 41, "type": "METRIC", "confidence": 0.9792128801345825}]}, {"text": "A final category that can be considered are freebies: OOVs that are copied over verbatim to the output sentence and accidentally match the reference translation (e.g., urls, proper nouns, etc.).", "labels": [], "entities": []}, {"text": "For the language pairs that we study, they are very rare; at most 0.35% for Arabic-English (in CTS) and 0.63% for Chinese-English (in SMS).", "labels": [], "entities": []}, {"text": "Manual inspection reveals that nearly all freebies are English words in the foreign source text.", "labels": [], "entities": []}, {"text": "Since they are so rare, we omit freebies from our results.", "labels": [], "entities": []}, {"text": "As WADE errors are assigned at the finegrained level of individual words, this analysis allows for (i) sentence-level visualization of errors, and (ii) collecting aggregate statistics of each error type for an entire evaluation set.", "labels": [], "entities": [{"text": "WADE", "start_pos": 3, "end_pos": 7, "type": "TASK", "confidence": 0.9496545195579529}]}, {"text": "By assembling the latter for various benchmarks, we can quantify global differences between genres or data sets.", "labels": [], "entities": []}, {"text": "At the same time, by examining (i) we can gain insight in the nature of the different 'errors', which might be real mistakes, or, for instance, different lexical choices.", "labels": [], "entities": []}, {"text": "The aggregate error statistics for each data set are shown in.", "labels": [], "entities": []}, {"text": "To put our results into perspective, we recall the findings of.", "labels": [], "entities": []}, {"text": "They find that for formal domains using a French-English system, 50-60% of the alignment links are correct, and SCORE errors are more common than SENSE errors, which in turn are more common than SEEN errors.", "labels": [], "entities": []}, {"text": "While we observe a similar distribution for our ArabicEnglish news benchmarks, these numbers do not generalize to the Arabic-English UG benchmarks nor to any of the Chinese-English data sets.", "labels": [], "entities": [{"text": "ArabicEnglish news benchmarks", "start_pos": 48, "end_pos": 77, "type": "DATASET", "confidence": 0.8879366914431254}, {"text": "Chinese-English data sets", "start_pos": 165, "end_pos": 190, "type": "DATASET", "confidence": 0.8181740641593933}]}, {"text": "First, the portion of SEEN errors increases dramatically for the Arabic-English UG translation tasks.", "labels": [], "entities": [{"text": "SEEN errors", "start_pos": 22, "end_pos": 33, "type": "METRIC", "confidence": 0.7645178735256195}, {"text": "UG translation tasks", "start_pos": 80, "end_pos": 100, "type": "TASK", "confidence": 0.796893040339152}]}, {"text": "For Chinese-English this trend is less pronounced yet also clearly observable.", "labels": [], "entities": []}, {"text": "Next, SENSE errors also increase substantially for most of the UG data, making up the majority of the errors for Chinese-English SMS and chat.", "labels": [], "entities": [{"text": "SENSE errors", "start_pos": 6, "end_pos": 18, "type": "METRIC", "confidence": 0.8798444867134094}, {"text": "UG data", "start_pos": 63, "end_pos": 70, "type": "DATASET", "confidence": 0.8351598680019379}]}, {"text": "This indicates that a promising strategy for adapting SMT systems to translating UG data involves generating new target-side translation candidates that match the source phrases in the input sentences.", "labels": [], "entities": [{"text": "SMT", "start_pos": 54, "end_pos": 57, "type": "TASK", "confidence": 0.9940424561500549}]}, {"text": "Finally, we evaluate the fraction of SCORE errors.", "labels": [], "entities": [{"text": "SCORE errors", "start_pos": 37, "end_pos": 49, "type": "METRIC", "confidence": 0.8591399490833282}]}, {"text": "While this is the most commonly observed error type inmost of the data sets, there seems to be very little correspondance with the genre or BLEU scores of the benchmarks.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 140, "end_pos": 144, "type": "METRIC", "confidence": 0.9912949204444885}]}, {"text": "This is an interesting finding since most work in system adaptation for SMT focuses on better scoring of existing translation candidates (, among others).", "labels": [], "entities": [{"text": "system adaptation", "start_pos": 50, "end_pos": 67, "type": "TASK", "confidence": 0.7728858590126038}, {"text": "SMT", "start_pos": 72, "end_pos": 75, "type": "TASK", "confidence": 0.9770734906196594}]}, {"text": "However, for UG translation tasks this does not appear as the most profitable approach.", "labels": [], "entities": [{"text": "UG translation tasks", "start_pos": 13, "end_pos": 33, "type": "TASK", "confidence": 0.9496776660283407}]}, {"text": "The generated sentencelevel error annotations allow us to examine the various error types in detail.", "labels": [], "entities": []}, {"text": "The first phenomenon that we repeatedly observe in the UG data are SEEN errors due to misspellings or, in the case of Arabic, dialectal forms.", "labels": [], "entities": [{"text": "UG data", "start_pos": 55, "end_pos": 62, "type": "DATASET", "confidence": 0.8116296231746674}, {"text": "SEEN errors", "start_pos": 67, "end_pos": 78, "type": "METRIC", "confidence": 0.968473881483078}]}, {"text": "Two such examples are shown in Figures 6A and 6B: In the first, the SMT system does not recognize the dialectal form of verb negation 'mtzEl$', which is a morphologically complex word containing both a prefix and a suffix.", "labels": [], "entities": [{"text": "SMT", "start_pos": 68, "end_pos": 71, "type": "TASK", "confidence": 0.9921374917030334}]}, {"text": "In the second, the input word 'AlmwbAyl' ('mobile') is wrongly spelled 'AlmwyAyl'.", "labels": [], "entities": []}, {"text": "It is interesting to note that 'b' and 'y' are very similar in the Arabic script.", "labels": [], "entities": []}, {"text": "This type of errors is particularly frequent in chat and SMS, which can partly explain the different distribution of errors across the Arabic-English data sets ().", "labels": [], "entities": [{"text": "Arabic-English data sets", "start_pos": 135, "end_pos": 159, "type": "DATASET", "confidence": 0.8124561905860901}]}, {"text": "Also frequently observed in the UG data are SMT lexical choices that are more formal than the reference translations.", "labels": [], "entities": [{"text": "UG data", "start_pos": 32, "end_pos": 39, "type": "DATASET", "confidence": 0.7897081077098846}, {"text": "SMT lexical", "start_pos": 44, "end_pos": 55, "type": "TASK", "confidence": 0.9262265861034393}]}, {"text": "This is not surprising given the large amount of formal data in the SMT models, but it does illustrate the need for adaptation to UG data.", "labels": [], "entities": [{"text": "SMT", "start_pos": 68, "end_pos": 71, "type": "TASK", "confidence": 0.9884809255599976}]}, {"text": "Often, the optimal lexical choice is simply absent from the SMT models, resulting in SENSE errors.", "labels": [], "entities": [{"text": "SMT", "start_pos": 60, "end_pos": 63, "type": "TASK", "confidence": 0.9756729602813721}]}, {"text": "This can be observed in, where 'sons' is output instead 'kids', and in, where 'i understand' is output instead of the colloquial 'i got it'.", "labels": [], "entities": []}, {"text": "In other situations, the annotated SCORE errors indicate that the correct choice was available to the SMT system without being selected for translation.", "labels": [], "entities": [{"text": "SMT", "start_pos": 102, "end_pos": 105, "type": "TASK", "confidence": 0.986415684223175}]}, {"text": "For example in, the output 'my parents' is preferred to the more colloquial 'mom and dad' in the reference.", "labels": [], "entities": []}, {"text": "Another phenomenon, particularly common for Chinese-English UG translations, is that idioms are translated in small chunks, thereby losing their meaning as a phrase.", "labels": [], "entities": [{"text": "UG translations", "start_pos": 60, "end_pos": 75, "type": "TASK", "confidence": 0.8265004456043243}]}, {"text": "In, the characters '\u8bf4', '\u2f00', and '\u58f0' mean 'to say', 'one', and 'sound', respectively.", "labels": [], "entities": []}, {"text": "The phrase '\u8bf4\u2f00\u58f0' as a whole means 'talk a bit about something' but is not covered by the SMT models.", "labels": [], "entities": [{"text": "SMT", "start_pos": 89, "end_pos": 92, "type": "TASK", "confidence": 0.9273698329925537}]}, {"text": "Similarly, ' \u4f60\u8def\u4e0a\u6162\u70b9 ' in literally means 'you on the road slow a bit', which, if covered by the models, could have been translated into 'be careful on", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Statistics of the Arabic-English UG (top)  and contrastive news (bottom) evaluation sets. To- kens are counted on the Arabic side.", "labels": [], "entities": []}, {"text": " Table 2: Statistics of the Chinese-English UG  (top) and contrastive news (bottom) evaluation  sets. Tokens are counted on the Chinese side.", "labels": [], "entities": []}, {"text": " Table 3: Target language model perplexity and translation model coverage of Arabic-English bench- marks. Phrase pair recall values are broken down by source phrase length. Intensities of the cell colors  indicate relative recall values with respect to the best scoring benchmark (measured in BLEU).", "labels": [], "entities": [{"text": "recall", "start_pos": 223, "end_pos": 229, "type": "METRIC", "confidence": 0.9433716535568237}, {"text": "BLEU", "start_pos": 293, "end_pos": 297, "type": "METRIC", "confidence": 0.9987478256225586}]}, {"text": " Table 4: Target language model perplexity and translation model coverage of Chinese-English bench- marks. See", "labels": [], "entities": []}]}