{"title": [{"text": "Individuality-Preserving Spectrum Modification for Articulation Disorders Using Phone Selective Synthesis", "labels": [], "entities": [{"text": "Individuality-Preserving Spectrum Modification", "start_pos": 0, "end_pos": 46, "type": "TASK", "confidence": 0.6159739394982656}]}], "abstractContent": [{"text": "This paper presents a speech synthesis method for people with articulation disorders resulting from athetoid cerebral palsy.", "labels": [], "entities": [{"text": "speech synthesis", "start_pos": 22, "end_pos": 38, "type": "TASK", "confidence": 0.7179996818304062}]}, {"text": "For people with articulation disorders, there are duration, pitch and spectral problems that cause their speech to be less intelligible and make communication difficult.", "labels": [], "entities": [{"text": "duration", "start_pos": 50, "end_pos": 58, "type": "METRIC", "confidence": 0.9977201819419861}]}, {"text": "In order to deal with these problems, this paper describes a Hidden Markov Model (HMM)-based text-to-speech synthesis approach that preserves the voice individuality of those with articulation disorders and aids them in their communication.", "labels": [], "entities": [{"text": "text-to-speech synthesis", "start_pos": 93, "end_pos": 117, "type": "TASK", "confidence": 0.7484550178050995}]}, {"text": "For the unstable pitch problem , we use the F0 patterns of a physically unimpaired person, with the average F0 being converted to the target F0 in advance.", "labels": [], "entities": [{"text": "F0", "start_pos": 44, "end_pos": 46, "type": "METRIC", "confidence": 0.9559609293937683}, {"text": "F0", "start_pos": 108, "end_pos": 110, "type": "METRIC", "confidence": 0.9862615466117859}]}, {"text": "Because the spectrum of people with articulation disorders is often unstable and unclear, we modify generated spectral parameters from the HMM synthesis system by using a physically unimpaired person's spectral model while preserving the individuality of the person with an articulation disorder.", "labels": [], "entities": []}, {"text": "Through experimental evaluations, we have confirmed that the proposed method successfully synthesizes intelligible speech while maintaining the target speaker's individuality.", "labels": [], "entities": []}], "introductionContent": [{"text": "In this study, we focus on a person with an articulation disorder resulting from the athetoid type of cerebral palsy.", "labels": [], "entities": []}, {"text": "About two babies in 1,000 are born with cerebral palsy.", "labels": [], "entities": []}, {"text": "Cerebral palsy results from damage to the central nervous system, and the damage causes movement disorders.", "labels": [], "entities": []}, {"text": "It is classified into the following types: 1) spastic, 2) athetoid, 3) ataxic, 4) atonic, 5) rigid, and a mixture of these types.", "labels": [], "entities": [{"text": "spastic", "start_pos": 46, "end_pos": 53, "type": "METRIC", "confidence": 0.9589976072311401}]}, {"text": "Athetoid symptoms develop in about 10-15% of cerebral palsy sufferers.", "labels": [], "entities": [{"text": "Athetoid", "start_pos": 0, "end_pos": 8, "type": "METRIC", "confidence": 0.9726064205169678}]}, {"text": "In the case of persons with articulation disorders resulting from the athetoid type of cerebral palsy, his/her movements are sometimes more unstable than usual.", "labels": [], "entities": []}, {"text": "That means their utterances (especially their consonants) are often unstable or unclear due to their athetoid symptoms, and there is a great need for voice systems that can assist them in their communication.", "labels": [], "entities": []}, {"text": "An HMM-based speech synthesis system is a text-tospeech (TTS) system that can generate signals from input text data.", "labels": [], "entities": [{"text": "HMM-based speech synthesis", "start_pos": 3, "end_pos": 29, "type": "TASK", "confidence": 0.6024529337882996}]}, {"text": "A TTS system maybe useful for those with articulation disorders because they have difficulty moving their lips.", "labels": [], "entities": [{"text": "TTS", "start_pos": 2, "end_pos": 5, "type": "TASK", "confidence": 0.5787732005119324}]}, {"text": "In an HMM-based speech synthesis system, the spectrum, F0 and duration are modeled simultaneously in a unified framework.", "labels": [], "entities": [{"text": "F0", "start_pos": 55, "end_pos": 57, "type": "METRIC", "confidence": 0.9953258037567139}, {"text": "duration", "start_pos": 62, "end_pos": 70, "type": "METRIC", "confidence": 0.9843062162399292}]}, {"text": "Melcepstral coefficients are used as spectral features, which are modeled by continuous density HMMs.", "labels": [], "entities": []}, {"text": "F0 patterns are modeled by a hidden Markov model based on multi-space probabil-: HMM-based sound synthesis system ity distribution (MSD-HMM), and state duration densities are modeled by single Gaussian distributions.", "labels": [], "entities": []}, {"text": "In the field of assistive technology, used HMM-based speech synthesis to reconstruct the voice of individuals with degenerative speech disorders resulting from Amyotrophic Lateral Sclerosis (ALS).", "labels": [], "entities": [{"text": "Amyotrophic Lateral Sclerosis (ALS)", "start_pos": 160, "end_pos": 195, "type": "TASK", "confidence": 0.6699469089508057}]}, {"text": "They have proposed a reconstruction method for degenerative speech disorders using an HMM sound synthesis system.", "labels": [], "entities": []}, {"text": "In this method, the subject's utterances are used to adapt an average voice model pre-trained on many speakers.", "labels": [], "entities": []}, {"text": "Creer et al. also adapt the average voice model of multiple speakers to the severe dysarthria data.", "labels": [], "entities": []}, {"text": "And Khan et al. uses such adaption method to the laryngectomy patient's data.", "labels": [], "entities": []}, {"text": "proposed a project called \"Voice Banking and Reconstruction\".", "labels": [], "entities": [{"text": "Voice Banking and Reconstruction", "start_pos": 27, "end_pos": 59, "type": "TASK", "confidence": 0.806339681148529}]}, {"text": "In that project, various types of voices were collected, and they proposed TTS for ALS using that database.", "labels": [], "entities": [{"text": "TTS", "start_pos": 75, "end_pos": 78, "type": "TASK", "confidence": 0.8013111352920532}]}, {"text": "Also, Rudzicz proposed a speech adjustment method for people with articulation disorders based on observations from the database.", "labels": [], "entities": [{"text": "speech adjustment", "start_pos": 25, "end_pos": 42, "type": "TASK", "confidence": 0.6986176669597626}]}, {"text": "In this paper, we propose an HMM-based speech synthesis method for articulation disorders because there are several problems in the recorded voice of persons with articulation disorders, and this causes the output synthesized signals to be unintelligible.", "labels": [], "entities": [{"text": "HMM-based speech synthesis", "start_pos": 29, "end_pos": 55, "type": "TASK", "confidence": 0.6997911930084229}]}, {"text": "To deal with these problems, it is necessary to develop a speech synthesis system in which the output signals become more intelligible and include the subject's individuality.", "labels": [], "entities": [{"text": "speech synthesis", "start_pos": 58, "end_pos": 74, "type": "TASK", "confidence": 0.7312372028827667}]}, {"text": "To generate an intelligible voice while preserving the speaker's individuality, we train the speech synthesis system using training data from both a person with an articulation disorder and a physically unimpaired person.", "labels": [], "entities": [{"text": "speech synthesis", "start_pos": 93, "end_pos": 109, "type": "TASK", "confidence": 0.7481559813022614}]}, {"text": "Because the utterance rate of persons with articulation disorders differs from that of a 118  physically unimpaired person, we utilize the duration model of a physically unimpaired person only in our method.", "labels": [], "entities": [{"text": "duration", "start_pos": 139, "end_pos": 147, "type": "METRIC", "confidence": 0.9903959631919861}]}, {"text": "In addition to the utterance rate problem, the F0 patterns of persons with articulation disorders are often unstable compared to those of physically unimpaired persons.", "labels": [], "entities": [{"text": "F0", "start_pos": 47, "end_pos": 49, "type": "METRIC", "confidence": 0.9794759154319763}]}, {"text": "In our method, the F0 model is trained from a physically unimpaired person's F0 patterns, and the average F0 is used as the F0 pattern for the person with an articulation disorder.", "labels": [], "entities": [{"text": "F0", "start_pos": 19, "end_pos": 21, "type": "METRIC", "confidence": 0.9499974846839905}, {"text": "F0", "start_pos": 106, "end_pos": 108, "type": "METRIC", "confidence": 0.9854199290275574}, {"text": "F0", "start_pos": 124, "end_pos": 126, "type": "METRIC", "confidence": 0.957874059677124}]}, {"text": "As for the spectral problem associated with persons with articulation disorders, the consonant parts of their speech are often unstable or unclear, which causes their voice to be unintelligible.", "labels": [], "entities": []}, {"text": "To resolve this consonant problem, we conduct different operations on the consonant and vowel parts.", "labels": [], "entities": []}, {"text": "For the consonants parts, we basically generate the output spectrum from the spectral model of a physically unimpaired person.", "labels": [], "entities": []}, {"text": "For the vowel parts, we generate the output spectrum from the spectral model of a person with an articulation disorder in order to preserve the person's individuality.", "labels": [], "entities": []}], "datasetContent": [{"text": "We prepared the training data for two men.", "labels": [], "entities": []}, {"text": "One is a physically unimpaired person, and the other is a person with an articula- tion disorder.", "labels": [], "entities": []}, {"text": "We used 513 sentences from the ATR Japanese database fora physically unimpaired person, and recorded 429 sentences in the same database uttered by a person with an articulation disorder.", "labels": [], "entities": [{"text": "ATR Japanese database", "start_pos": 31, "end_pos": 52, "type": "DATASET", "confidence": 0.9437262614568075}]}, {"text": "The speech signals were sampled at 48 kHz and the frame shift was 5 ms.", "labels": [], "entities": [{"text": "frame shift", "start_pos": 50, "end_pos": 61, "type": "METRIC", "confidence": 0.9561457633972168}]}, {"text": "Acoustic and prosodic features were extracted by using STRAIGHT.", "labels": [], "entities": [{"text": "STRAIGHT", "start_pos": 55, "end_pos": 63, "type": "METRIC", "confidence": 0.9348182082176208}]}, {"text": "As spectral parameters, mel-cepstrum coefficients, their dynamic, acceleration coefficients were used.", "labels": [], "entities": []}, {"text": "As excitation parameters, log-F0 and 5 band-filtered aperiodicity measures were used and their dynamic and acceleration coefficients were also used.", "labels": [], "entities": []}, {"text": "Contextdependent phoneme HMMs with five states were used in the speech synthesis system.", "labels": [], "entities": [{"text": "speech synthesis", "start_pos": 64, "end_pos": 80, "type": "TASK", "confidence": 0.7888574302196503}]}, {"text": "In order to confirm the effectiveness of our method, we evaluated both the aspect of listening intelligibility and the aspect of speaker similarity by listening to voices synthesized under the five conditions shown in.", "labels": [], "entities": []}, {"text": "Ten sentences included in the ATR Japanese database were synthesized under those five conditions.", "labels": [], "entities": [{"text": "ATR Japanese database", "start_pos": 30, "end_pos": 51, "type": "DATASET", "confidence": 0.9320117831230164}]}, {"text": "A total of 8 Japanese speakers took part in the listening test using headphones.", "labels": [], "entities": []}, {"text": "For speaker similarity, we performed a MOS (Mean Opinion Score) test.", "labels": [], "entities": [{"text": "speaker similarity", "start_pos": 4, "end_pos": 22, "type": "TASK", "confidence": 0.7003937363624573}, {"text": "MOS (Mean Opinion Score) test", "start_pos": 39, "end_pos": 68, "type": "METRIC", "confidence": 0.8678218509469714}]}, {"text": "In the MOS test, the opinion score was set to a 5-point scale (5: Identical, 4: Very Similar, 3: Quite Similar, 2: Dissimilar, 1: Very Dissimilar).", "labels": [], "entities": [{"text": "MOS", "start_pos": 7, "end_pos": 10, "type": "TASK", "confidence": 0.8328847885131836}]}, {"text": "For the listening intelligibility, a paired comparison test was carried out, where each subject listened to pairs of speech converted by the two methods, and then selected which sample was more intelligible.", "labels": [], "entities": []}, {"text": "In the proposed method, we generated the modified spectral parameters by mixing both ADM and PUM spectral parameters.", "labels": [], "entities": []}, {"text": "shows the generated spectrum from the ADM spectral model and shows the generated spectrum from the PUM spectral model.", "labels": [], "entities": [{"text": "ADM spectral model", "start_pos": 38, "end_pos": 56, "type": "DATASET", "confidence": 0.9019713600476583}, {"text": "PUM spectral model", "start_pos": 99, "end_pos": 117, "type": "DATASET", "confidence": 0.8614698648452759}]}, {"text": "Both spectral parameters are generated from the same text and the same PUM duration model so that they have the same number of frames and dimensions.", "labels": [], "entities": [{"text": "PUM duration", "start_pos": 71, "end_pos": 83, "type": "METRIC", "confidence": 0.7560733258724213}]}, {"text": "As shown in, the high-frequency component is weaker compared to, which means that the consonant parts of ADM spectral parameters are weak.", "labels": [], "entities": []}, {"text": "This causes the output synthesized signals to be less intelligible.", "labels": [], "entities": []}, {"text": "shows the modified spectrum created from both ADM and PUM spectral parameters by using Eq.", "labels": [], "entities": []}, {"text": "As shown in, the consonant parts are complemented by the high-frequency parameters of PUM while preserving ADM's low-frequency components.", "labels": [], "entities": []}, {"text": "shows the results of the MOS test on speaker similarity, where the error bar shows a 95% confidence score.", "labels": [], "entities": [{"text": "MOS", "start_pos": 25, "end_pos": 28, "type": "METRIC", "confidence": 0.39426517486572266}]}, {"text": "As shown in, the ADM score was the highest score of all.", "labels": [], "entities": [{"text": "ADM score", "start_pos": 17, "end_pos": 26, "type": "METRIC", "confidence": 0.9644286036491394}]}, {"text": "This is because the signal from ADM is synthesized only from the feature parameters of a person with an articulation disorder.", "labels": [], "entities": []}, {"text": "The Prop score is slightly less than those of Ref1 and Ref2 because of the modification of the spectral parameters.", "labels": [], "entities": [{"text": "Prop score", "start_pos": 4, "end_pos": 14, "type": "METRIC", "confidence": 0.982012152671814}]}, {"text": "shows the preference score for the listening intelligibility, where the error bar shows a 95% confidence score.", "labels": [], "entities": [{"text": "error bar", "start_pos": 72, "end_pos": 81, "type": "METRIC", "confidence": 0.9548006355762482}]}, {"text": "As shown in, our method obtained a higher score than Ref1 and ADM.", "labels": [], "entities": [{"text": "Ref1", "start_pos": 53, "end_pos": 57, "type": "METRIC", "confidence": 0.9910496473312378}, {"text": "ADM", "start_pos": 62, "end_pos": 65, "type": "DATASET", "confidence": 0.8490539193153381}]}, {"text": "These results show that the proposed method is effective.", "labels": [], "entities": []}, {"text": "By replacing the physically unimpaired person's duration model and converting his F0 patterns to those of the person with an articulation disorder improves intelligibility.", "labels": [], "entities": [{"text": "duration", "start_pos": 48, "end_pos": 56, "type": "METRIC", "confidence": 0.960412859916687}, {"text": "F0", "start_pos": 82, "end_pos": 84, "type": "METRIC", "confidence": 0.9810375571250916}]}, {"text": "Our method also obtained a higher score than Ref2.", "labels": [], "entities": [{"text": "Ref2", "start_pos": 45, "end_pos": 49, "type": "DATASET", "confidence": 0.5288591980934143}]}, {"text": "This result shows that modifying the output spectral parameters is quite effective in improving intelligibility.", "labels": [], "entities": []}, {"text": "Therefore, considering from Figs. 6 and 7, it is confirmed that our proposed method implements the synthesized signals which is intelligible and includes individuality of a person with an articulation disorder.", "labels": [], "entities": [{"text": "Figs. 6", "start_pos": 28, "end_pos": 35, "type": "DATASET", "confidence": 0.9530403912067413}]}], "tableCaptions": [{"text": " Table 2: Average duration per mora in 50 sentences", "labels": [], "entities": [{"text": "Average duration", "start_pos": 10, "end_pos": 26, "type": "METRIC", "confidence": 0.7953332364559174}]}]}