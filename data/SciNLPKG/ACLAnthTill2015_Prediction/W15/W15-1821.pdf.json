{"title": [], "abstractContent": [{"text": "There has been substantial recent interest in annotation schemes that can be applied consistently to many languages.", "labels": [], "entities": []}, {"text": "Building on several recent efforts to unify morphological and syntactic annotation, the Universal Dependencies (UD) project seeks to introduce a cross-linguistically applicable part-of-speech tagset, feature inventory , and set of dependency relations as well as a large number of uniformly annotated treebanks.", "labels": [], "entities": []}, {"text": "We present Universal Dependencies for Finnish, one of the ten languages in the recent first release of UD project treebank data.", "labels": [], "entities": [{"text": "UD project treebank data", "start_pos": 103, "end_pos": 127, "type": "DATASET", "confidence": 0.8893031477928162}]}, {"text": "We detail the mapping of previously introduced annotation to the UD standard, describing specific challenges and their resolution.", "labels": [], "entities": [{"text": "UD standard", "start_pos": 65, "end_pos": 76, "type": "DATASET", "confidence": 0.9283657968044281}]}, {"text": "We additionally present parsing experiments comparing the performance of a state-of-the-art parser trained on a language-specific annotation schema to performance on the corresponding UD annotation.", "labels": [], "entities": []}, {"text": "The results show improvement compared to the source annotation, indicating that the conversion is accurate and supporting the feasibility of UD as a parsing target.", "labels": [], "entities": []}, {"text": "The introduced tools and resources are available under open licenses from", "labels": [], "entities": []}], "introductionContent": [{"text": "The Universal Dependencies (UD) initiative seeks to develop cross-linguistically consistent annotation guidelines and apply them to many languages to create treebank annotations that are uniform in e.g. their theoretical basis, label sets, and structural aspects.", "labels": [], "entities": []}, {"text": "Such resources could substantially advance cross-lingual learning, improve comparability of evaluation results, and facilitate new approaches to automatic syntactic analysis.", "labels": [], "entities": [{"text": "automatic syntactic analysis", "start_pos": 145, "end_pos": 173, "type": "TASK", "confidence": 0.6425154705842336}]}, {"text": "UD builds on the Google Universal part-ofspeech (POS) tagset (, the Interset interlingua of morphosyntactic features, and Stanford Dependencies ().", "labels": [], "entities": [{"text": "Stanford Dependencies", "start_pos": 122, "end_pos": 143, "type": "DATASET", "confidence": 0.9043087959289551}]}, {"text": "In addition to the abstract annotation scheme, UD defines also a treebank storage format, CoNLL-U.", "labels": [], "entities": []}, {"text": "A first version of UD treebank data, building on the Google Universal Dependency) and many other previously released resources (), was recently released 1 (.", "labels": [], "entities": [{"text": "UD treebank data", "start_pos": 19, "end_pos": 35, "type": "DATASET", "confidence": 0.8067573805650076}, {"text": "Google Universal Dependency)", "start_pos": 53, "end_pos": 81, "type": "DATASET", "confidence": 0.8476435542106628}]}, {"text": "In this paper, we present the adaptation of the UD guidelines to Finnish and the creation of the UD Finnish treebank by conversion of the previously introduced Turku Dependency Treebank (TDT)).", "labels": [], "entities": [{"text": "UD Finnish treebank", "start_pos": 97, "end_pos": 116, "type": "DATASET", "confidence": 0.7745402455329895}, {"text": "Turku Dependency Treebank (TDT))", "start_pos": 160, "end_pos": 192, "type": "DATASET", "confidence": 0.819307858745257}]}, {"text": "We also provide a first set of experiments comparing the parsing scores of language-specific treebank annotation to that of a UD treebank, providing an evaluation of both the conversion quality and the feasibility of UD annotation as a parsing target.", "labels": [], "entities": [{"text": "parsing", "start_pos": 57, "end_pos": 64, "type": "TASK", "confidence": 0.9580538272857666}, {"text": "UD treebank", "start_pos": 126, "end_pos": 137, "type": "DATASET", "confidence": 0.6975471675395966}]}, {"text": "Ina related but separate effort within the UD initiative, the FinnTreeBank 1 2 (ftb-1) (Voutilainen, 2011) is also being converted into the UD format.", "labels": [], "entities": [{"text": "FinnTreeBank 1 2 (ftb-1) (Voutilainen, 2011)", "start_pos": 62, "end_pos": 106, "type": "DATASET", "confidence": 0.9218211011453108}]}, {"text": "The ftb-1 is a treebank based on all grammatical examples from the VISK 3 Finnish grammar reference), and will thus complement the TDT-based UD Finnish treebank in the set of UD treebanks.", "labels": [], "entities": [{"text": "VISK 3 Finnish grammar reference", "start_pos": 67, "end_pos": 99, "type": "DATASET", "confidence": 0.7554264068603516}, {"text": "TDT-based UD Finnish treebank", "start_pos": 131, "end_pos": 160, "type": "DATASET", "confidence": 0.8386414051055908}, {"text": "UD treebanks", "start_pos": 175, "end_pos": 187, "type": "DATASET", "confidence": 0.801285982131958}]}], "datasetContent": [{"text": "As discussed by in the context of the Universal Stanford Dependencies which formed the basis on which UD was built, parsing accuracy has not been a major consideration in the definition of the scheme.", "labels": [], "entities": [{"text": "Universal Stanford Dependencies", "start_pos": 38, "end_pos": 69, "type": "DATASET", "confidence": 0.748317817846934}, {"text": "parsing", "start_pos": 116, "end_pos": 123, "type": "TASK", "confidence": 0.9691493511199951}, {"text": "accuracy", "start_pos": 124, "end_pos": 132, "type": "METRIC", "confidence": 0.9433428049087524}]}, {"text": "In fact, a number of the design choices taken, such as the attachment of auxiliaries and prepositions as dependents rather than governors of their semantic head is known to result in a numerically worse parsing accuracy.", "labels": [], "entities": [{"text": "parsing", "start_pos": 203, "end_pos": 210, "type": "TASK", "confidence": 0.9405474066734314}, {"text": "accuracy", "start_pos": 211, "end_pos": 219, "type": "METRIC", "confidence": 0.8440176844596863}]}, {"text": "Additionally, as the conversion is an automatic process, the resulting noise may have a detrimental effect on parsing accuracy as well.", "labels": [], "entities": [{"text": "parsing", "start_pos": 110, "end_pos": 117, "type": "TASK", "confidence": 0.9761700630187988}, {"text": "accuracy", "start_pos": 118, "end_pos": 126, "type": "METRIC", "confidence": 0.9490230083465576}]}, {"text": "To quantify these effects, we carryout several parsing experiments, comparing the Stanford Dependencies annotation in TDT with its conversion to the UD format.", "labels": [], "entities": [{"text": "Stanford Dependencies annotation", "start_pos": 82, "end_pos": 114, "type": "DATASET", "confidence": 0.8980207244555155}, {"text": "TDT", "start_pos": 118, "end_pos": 121, "type": "DATASET", "confidence": 0.5303040146827698}]}, {"text": "Further, since TDT now contains also fully manually annotated morphology, we will pay extra attention to morphological processing in the evaluation.", "labels": [], "entities": [{"text": "TDT", "start_pos": 15, "end_pos": 18, "type": "DATASET", "confidence": 0.7426176071166992}]}, {"text": "We base the experiments on the publicly available Finnish parsing pipeline.", "labels": [], "entities": [{"text": "Finnish parsing", "start_pos": 50, "end_pos": 65, "type": "TASK", "confidence": 0.5998490452766418}]}, {"text": "The pipeline uses the CRF-based tagger, in conjunction with the two-level morphological analyzer OMorFi).", "labels": [], "entities": []}, {"text": "The morphological analyzer is used to provide the set of possible morphological readings (lemma, POS, and features) of every recognized word, which are subsequently given as features to the Marmot tagger.", "labels": [], "entities": [{"text": "POS", "start_pos": 97, "end_pos": 100, "type": "METRIC", "confidence": 0.9815991520881653}, {"text": "Marmot tagger", "start_pos": 190, "end_pos": 203, "type": "DATASET", "confidence": 0.9075577557086945}]}, {"text": "We initially apply a hard constraint approach, where the output of the tagger is used to select one of these readings (the reading with the highest overlap of tags and a priority for readings matching the main POS), effectively disambiguating OMorFi output.", "labels": [], "entities": []}, {"text": "For words not recognized by OMorFi, the reading produced by Marmot is used as-is, and the wordform itself is used in place of the lemma.", "labels": [], "entities": [{"text": "OMorFi", "start_pos": 28, "end_pos": 34, "type": "DATASET", "confidence": 0.8994437456130981}]}, {"text": "This has so far been the strategy taken when learning to parse).", "labels": [], "entities": [{"text": "parse", "start_pos": 57, "end_pos": 62, "type": "TASK", "confidence": 0.7642467617988586}]}, {"text": "The tagged text is then parsed with the Mate tools graph-based dependency parser.", "labels": [], "entities": [{"text": "Mate tools graph-based dependency parser", "start_pos": 40, "end_pos": 80, "type": "TASK", "confidence": 0.5793353199958802}]}, {"text": "As baseline, we consider the most recent Finnish dependency parser trained and evaluated on the original distribution of TDT.", "labels": [], "entities": [{"text": "TDT", "start_pos": 121, "end_pos": 124, "type": "DATASET", "confidence": 0.833512544631958}]}, {"text": "Note that the test sets differ: the baseline is evaluated on a test set matching the data it was trained on, which differs from the new test set in several aspects such as the treatment of named entities.", "labels": [], "entities": []}, {"text": "The results are thus broadly comparable, but not directly so.: Results of the parsing experiments.", "labels": [], "entities": [{"text": "parsing", "start_pos": 78, "end_pos": 85, "type": "TASK", "confidence": 0.9766516089439392}]}, {"text": "SD refers to the morphological tagset and dependency relations as defined in TDT, UD to the universal tagset and relations, and pure UD to UD relations with no language-specific extensions.", "labels": [], "entities": [{"text": "TDT", "start_pos": 77, "end_pos": 80, "type": "DATASET", "confidence": 0.8682712316513062}]}, {"text": "POS is the POS tagging accuracy, PM the accuracy of POS and all features, FM the accuracy of full morphology (including the lemma), and LAS and UAS are the standard labeled and unlabeled attachment score metrics.: Results of the UD parsing experiments with the soft and hard-pos morphological tagging strategies.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 11, "end_pos": 22, "type": "TASK", "confidence": 0.5546812117099762}, {"text": "accuracy", "start_pos": 23, "end_pos": 31, "type": "METRIC", "confidence": 0.5749140381813049}, {"text": "PM", "start_pos": 33, "end_pos": 35, "type": "METRIC", "confidence": 0.9959278702735901}, {"text": "accuracy", "start_pos": 40, "end_pos": 48, "type": "METRIC", "confidence": 0.9983822107315063}, {"text": "FM", "start_pos": 74, "end_pos": 76, "type": "METRIC", "confidence": 0.9939127564430237}, {"text": "accuracy", "start_pos": 81, "end_pos": 89, "type": "METRIC", "confidence": 0.9975079298019409}, {"text": "LAS", "start_pos": 136, "end_pos": 139, "type": "METRIC", "confidence": 0.9926129579544067}, {"text": "UAS", "start_pos": 144, "end_pos": 147, "type": "METRIC", "confidence": 0.967719554901123}, {"text": "UD parsing", "start_pos": 229, "end_pos": 239, "type": "TASK", "confidence": 0.9239152371883392}]}], "tableCaptions": [{"text": " Table 5: Results of the parsing experiments. SD refers to the morphological tagset and dependency  relations as defined in TDT, UD to the universal tagset and relations, and pure UD to UD relations with  no language-specific extensions. POS is the POS tagging accuracy, PM the accuracy of POS and all  features, FM the accuracy of full morphology (including the lemma), and LAS and UAS are the standard  labeled and unlabeled attachment score metrics.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 261, "end_pos": 269, "type": "METRIC", "confidence": 0.680440366268158}, {"text": "PM", "start_pos": 271, "end_pos": 273, "type": "METRIC", "confidence": 0.9633896946907043}, {"text": "accuracy", "start_pos": 278, "end_pos": 286, "type": "METRIC", "confidence": 0.9959010481834412}, {"text": "FM", "start_pos": 313, "end_pos": 315, "type": "METRIC", "confidence": 0.9674387574195862}, {"text": "accuracy", "start_pos": 320, "end_pos": 328, "type": "METRIC", "confidence": 0.9975336790084839}, {"text": "LAS", "start_pos": 375, "end_pos": 378, "type": "METRIC", "confidence": 0.9845412969589233}, {"text": "UAS", "start_pos": 383, "end_pos": 386, "type": "METRIC", "confidence": 0.8594900369644165}]}, {"text": " Table 6: Results of the UD parsing experiments with the soft and hard-pos morphological tagging strate- gies.", "labels": [], "entities": [{"text": "UD parsing", "start_pos": 25, "end_pos": 35, "type": "TASK", "confidence": 0.9494481086730957}]}]}