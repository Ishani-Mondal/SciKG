{"title": [{"text": "On Statistical Machine Translation and Translation Theory", "labels": [], "entities": [{"text": "Statistical Machine Translation", "start_pos": 3, "end_pos": 34, "type": "TASK", "confidence": 0.8103524049123129}, {"text": "Translation Theory", "start_pos": 39, "end_pos": 57, "type": "TASK", "confidence": 0.9056864678859711}]}], "abstractContent": [{"text": "The translation process in statistical machine translation (SMT) is shaped by technical constraints and engineering considerations.", "labels": [], "entities": [{"text": "translation process", "start_pos": 4, "end_pos": 23, "type": "TASK", "confidence": 0.891062468290329}, {"text": "statistical machine translation (SMT)", "start_pos": 27, "end_pos": 64, "type": "TASK", "confidence": 0.7847802688678106}]}, {"text": "SMT explicitly models translation as search fora target-language equivalent of the input text.", "labels": [], "entities": [{"text": "SMT", "start_pos": 0, "end_pos": 3, "type": "TASK", "confidence": 0.9681192636489868}, {"text": "translation", "start_pos": 22, "end_pos": 33, "type": "TASK", "confidence": 0.9641014337539673}]}, {"text": "This perspective on translation had wide currency in mid-20th century translation studies, but has since been superseded by approaches arguing fora more complex relation between source and target text.", "labels": [], "entities": []}, {"text": "In this paper, we show how traditional assumptions of translational equivalence are embodied in SMT through the concepts of word alignment and domain and discuss some limitations arising from the word-level/corpus-level dichotomy inherent in these concepts.", "labels": [], "entities": [{"text": "SMT", "start_pos": 96, "end_pos": 99, "type": "TASK", "confidence": 0.9911075234413147}, {"text": "word alignment", "start_pos": 124, "end_pos": 138, "type": "TASK", "confidence": 0.7298033535480499}]}], "introductionContent": [{"text": "The methods used in present-day statistical machine translation (SMT) have their foundation in specific assumptions about the nature of the translation process.", "labels": [], "entities": [{"text": "statistical machine translation (SMT)", "start_pos": 32, "end_pos": 69, "type": "TASK", "confidence": 0.7917483995358149}]}, {"text": "These assumptions are seldom discussed or even made explicit in the SMT literature, but they have a strong influence on the way SMT models implement translation.", "labels": [], "entities": [{"text": "SMT", "start_pos": 68, "end_pos": 71, "type": "TASK", "confidence": 0.9887720942497253}, {"text": "SMT", "start_pos": 128, "end_pos": 131, "type": "TASK", "confidence": 0.9895439147949219}]}, {"text": "This paper studies the relation between current approaches to SMT and major developments in translation studies.", "labels": [], "entities": [{"text": "SMT", "start_pos": 62, "end_pos": 65, "type": "TASK", "confidence": 0.9957398176193237}, {"text": "translation studies", "start_pos": 92, "end_pos": 111, "type": "TASK", "confidence": 0.9251706898212433}]}, {"text": "We begin with a brief overview of the most important milestones in translation theory and show that the concept of word alignment embodies a view of translation that is strongly related to notions of translational equivalence popular among translation theorists of the 1960s and 1970s.", "labels": [], "entities": [{"text": "translation theory", "start_pos": 67, "end_pos": 85, "type": "TASK", "confidence": 0.9803646802902222}, {"text": "word alignment", "start_pos": 115, "end_pos": 129, "type": "TASK", "confidence": 0.720928743481636}]}, {"text": "Defined in terms of an equivalence relation, translation is seen as an essentially \"transparent\" operation that recodes a text in a different linguistic representation without adding anything of its own, a view that ignores much of the complexity of the decision making processes involved in translation.", "labels": [], "entities": [{"text": "translation", "start_pos": 45, "end_pos": 56, "type": "TASK", "confidence": 0.9686334729194641}]}, {"text": "We show how SMT works around this problem by using the concept of domain as a corpus-level catch-all variable and discuss why this approximation may not always be sufficient.", "labels": [], "entities": [{"text": "SMT", "start_pos": 12, "end_pos": 15, "type": "TASK", "confidence": 0.9938378930091858}]}], "datasetContent": [], "tableCaptions": []}