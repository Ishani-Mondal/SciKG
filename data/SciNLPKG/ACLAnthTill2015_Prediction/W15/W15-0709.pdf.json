{"title": [{"text": "Towards a better understanding of Burrows's Delta in literary authorship attribution", "labels": [], "entities": [{"text": "Burrows's", "start_pos": 34, "end_pos": 43, "type": "DATASET", "confidence": 0.9102871119976044}]}], "abstractContent": [{"text": "Burrows's Delta is the most established measure for stylometric difference in literary authorship attribution.", "labels": [], "entities": [{"text": "Burrows's Delta", "start_pos": 0, "end_pos": 15, "type": "METRIC", "confidence": 0.8286409179369608}, {"text": "literary authorship attribution", "start_pos": 78, "end_pos": 109, "type": "TASK", "confidence": 0.593319962422053}]}, {"text": "Several improvements on the original Delta have been proposed.", "labels": [], "entities": []}, {"text": "However , a recent empirical study showed that none of the proposed variants constitute a major improvement in terms of authorship attri-bution performance.", "labels": [], "entities": []}, {"text": "With this paper, we try to improve our understanding of how and why these text distance measures work for authorship attribution.", "labels": [], "entities": [{"text": "authorship attribution", "start_pos": 106, "end_pos": 128, "type": "TASK", "confidence": 0.7926749289035797}]}, {"text": "We evaluate the effects of standardization and vector normalization on the statistical distributions of features and the resulting text clustering quality.", "labels": [], "entities": []}, {"text": "Furthermore, we explore supervised selection of discrimi-nant words as a procedure for further improving authorship attribution.", "labels": [], "entities": [{"text": "authorship attribution", "start_pos": 105, "end_pos": 127, "type": "TASK", "confidence": 0.8261597454547882}]}], "introductionContent": [{"text": "Authorship Attribution is a research area in quantitative text analysis concerned with attributing texts of unknown or disputed authorship to their actual author based on quantitatively measured linguistic evidence.", "labels": [], "entities": [{"text": "Authorship Attribution", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.7063266634941101}, {"text": "quantitative text analysis", "start_pos": 45, "end_pos": 71, "type": "TASK", "confidence": 0.6412098904450735}]}, {"text": "Authorship attribution has applications e.g. in literary studies, history, and forensics, and uses methods from Natural Language Processing, Text Mining, and Corpus Stylistics.", "labels": [], "entities": [{"text": "Authorship attribution", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.7717981934547424}, {"text": "literary studies", "start_pos": 48, "end_pos": 64, "type": "TASK", "confidence": 0.7466800212860107}, {"text": "Text Mining", "start_pos": 141, "end_pos": 152, "type": "TASK", "confidence": 0.7377924919128418}]}, {"text": "The fundamental assumption in authorship attribution is that individuals have idiosyncratic habits of language use, leading to a stylistic similarity of texts written by the same person.", "labels": [], "entities": [{"text": "authorship attribution", "start_pos": 30, "end_pos": 52, "type": "TASK", "confidence": 0.7136842906475067}]}, {"text": "Many of these stylistic habits can be measured by assessing the relative frequencies of function words or parts of speech, vocabulary richness, and other linguistic features.", "labels": [], "entities": []}, {"text": "This, in turn, allows using the relative similarity of the texts to each other in clustering or classification tasks and to attribute a text of unknown authorship to the most similar of a (usually closed) set of candidate authors.", "labels": [], "entities": [{"text": "clustering or classification", "start_pos": 82, "end_pos": 110, "type": "TASK", "confidence": 0.6845580836137136}]}, {"text": "One of the most crucial elements in quantitative authorship attribution methods is the distance measure used to quantify the degree of similarity between texts.", "labels": [], "entities": [{"text": "quantitative authorship attribution", "start_pos": 36, "end_pos": 71, "type": "TASK", "confidence": 0.5985087752342224}]}, {"text": "A major advance in this area has been Delta, as proposed by, which has proven to be a very robust measure in different genres and languages.", "labels": [], "entities": [{"text": "Delta", "start_pos": 38, "end_pos": 43, "type": "METRIC", "confidence": 0.754330039024353}]}, {"text": "Since 2002, a number of variants of Burrows's Delta have been proposed.", "labels": [], "entities": [{"text": "Burrows's Delta", "start_pos": 36, "end_pos": 51, "type": "DATASET", "confidence": 0.9711180528004965}]}, {"text": "Ina recent publication, empirical tests of authorship attribution performance for Delta as well as 13 precursors and/or variants of it have been reported.", "labels": [], "entities": []}, {"text": "That study, using three test corpora in English, German and French, has shown that Burrows's Delta remains a strong contender, but is outperformed quite clearly by Cosine Delta as proposed by.", "labels": [], "entities": [{"text": "Burrows's Delta", "start_pos": 83, "end_pos": 98, "type": "DATASET", "confidence": 0.8943121631940206}]}, {"text": "The study has also shown that some of the theoretical arguments by do not find empirical confirmation.", "labels": [], "entities": []}, {"text": "This means that, intriguingly, there is still no clear theoretical model which is able to explain why these various distance measures yield varying performance; we don't have a clear understanding why Burrows's Delta and Cosine Delta are so robust and reliable.", "labels": [], "entities": []}, {"text": "In the absence of compelling theoretical arguments, systematic empirical testing becomes paramount, and this paper proposes to continue such investigations.", "labels": [], "entities": []}, {"text": "Previous work has focused on feature selection either in the sense of deciding what type of feature (e.g. character, word or part-of-speech ngrams) has the best discriminatory power for authorship attribution), or in the sense of deciding which part of the list of most frequent words yields the best results ().", "labels": [], "entities": [{"text": "feature selection", "start_pos": 29, "end_pos": 46, "type": "TASK", "confidence": 0.7104651927947998}]}, {"text": "Other publications explored strategies of deliberately picking a very small numbers of particularly disciminative features.", "labels": [], "entities": []}, {"text": "Our strategy builds on such approaches but differs from them in that we focus on word unigrams only and examine how the treatment of the input feature vector (i.e., the list of word tokens used and their frequencies) interacts with the performance of distance measures.", "labels": [], "entities": []}, {"text": "Each distance measure implements a specific combination of standardization and/or normalization of the feature vector.", "labels": [], "entities": []}, {"text": "In addition, the feature vector can be preprocessed in several ways before submitting it to the distance measure.", "labels": [], "entities": []}, {"text": "In the following, we report on a series of experiments which assess the effects of standardization and normalization, as well as of feature vector manipulation, on the performance of distance measures for authorship attribution.", "labels": [], "entities": [{"text": "authorship attribution", "start_pos": 205, "end_pos": 227, "type": "TASK", "confidence": 0.8393052518367767}]}, {"text": "Although we use attribution success as our performance indicator, our ultimate goal is not so much to optimize the results, but rather to gain a deeper understanding of the mechanisms behind distance measures.", "labels": [], "entities": []}, {"text": "We hope that a deeper theoretical understanding will help choose the right parameters in authorship attribution cases.", "labels": [], "entities": [{"text": "authorship attribution", "start_pos": 89, "end_pos": 111, "type": "TASK", "confidence": 0.8249655365943909}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 2: Evaluation results for the selected features on the second additional test set compared to all features (for  Cosine Delta clustering, 2 000 mfw are used in this case)", "labels": [], "entities": [{"text": "Cosine Delta clustering", "start_pos": 120, "end_pos": 143, "type": "TASK", "confidence": 0.6150456865628561}]}]}