{"title": [{"text": "Recursive Neural Networks Can Learn Logical Semantics", "labels": [], "entities": [{"text": "Recursive Neural Networks", "start_pos": 0, "end_pos": 25, "type": "TASK", "confidence": 0.8471649487813314}]}], "abstractContent": [{"text": "Tree-structured recursive neural networks (TreeRNNs) for sentence meaning have been successful for many applications, but it remains an open question whether the fixed-length representations that they learn can support tasks as demanding as logical deduction.", "labels": [], "entities": [{"text": "sentence meaning", "start_pos": 57, "end_pos": 73, "type": "TASK", "confidence": 0.7370693385601044}]}, {"text": "We pursue this question by evaluating whether two such models-plain TreeRNNs and tree-structured neural tensor networks (TreeRNTNs)-can correctly learn to identify logical relationships such as entailment and contradiction using these representations.", "labels": [], "entities": []}, {"text": "In our first set of experiments, we generate artificial data from a logical grammar and use it to evaluate the models' ability to learn to handle basic relational reasoning, recursive structures , and quantification.", "labels": [], "entities": []}, {"text": "We then evaluate the models on the more natural SICK challenge data.", "labels": [], "entities": [{"text": "SICK challenge data", "start_pos": 48, "end_pos": 67, "type": "DATASET", "confidence": 0.8340849081675211}]}, {"text": "Both models perform competitively on the SICK data and generalize well in all three experiments on simulated data, suggesting that they can learn suitable representations for logical inference in natural language.", "labels": [], "entities": [{"text": "SICK data", "start_pos": 41, "end_pos": 50, "type": "DATASET", "confidence": 0.799875944852829}]}], "introductionContent": [{"text": "Tree-structured recursive neural network models (TreeRNNs;) for sentence meaning have been successful in an array of sophisticated language tasks, including sentiment analysis (, image description ( , and paraphrase detection).", "labels": [], "entities": [{"text": "sentence meaning", "start_pos": 64, "end_pos": 80, "type": "TASK", "confidence": 0.7402649521827698}, {"text": "sentiment analysis", "start_pos": 157, "end_pos": 175, "type": "TASK", "confidence": 0.9323701858520508}, {"text": "image description", "start_pos": 179, "end_pos": 196, "type": "TASK", "confidence": 0.7407128810882568}, {"text": "paraphrase detection", "start_pos": 205, "end_pos": 225, "type": "TASK", "confidence": 0.8898429870605469}]}, {"text": "These results are encouraging for the ability of these models to learn to produce and use strong semantic representations for sentences.", "labels": [], "entities": []}, {"text": "However, it remains an open question whether any such fully learned model can achieve the kind of high-fidelity distributed representations proposed in recent algebraic work on vector space modeling, and whether any such model can match the performance of grammars based in logical forms in their ability to model core semantic phenomena like quantification, entailment, and contradiction (.", "labels": [], "entities": [{"text": "vector space modeling", "start_pos": 177, "end_pos": 198, "type": "TASK", "confidence": 0.6765272617340088}]}, {"text": "Recent work on the algebraic approach of Coecke et al.", "labels": [], "entities": []}, {"text": "(2011) has yielded rich frameworks for computing the meanings of fragments of natural language compositionally from vector or tensor representations, but has not yet yielded effective methods for learning these representations from data in typical machine learning settings.", "labels": [], "entities": [{"text": "computing the meanings of fragments of natural language compositionally from vector or tensor representations", "start_pos": 39, "end_pos": 148, "type": "TASK", "confidence": 0.7379552594252995}]}, {"text": "Past experimental work on reasoning with distributed representations have been largely confined to short phrases ().", "labels": [], "entities": []}, {"text": "However, for robust natural language understanding, it is essential to model these phenomena in their full generality on complex linguistic structures.", "labels": [], "entities": [{"text": "natural language understanding", "start_pos": 20, "end_pos": 50, "type": "TASK", "confidence": 0.7671294013659159}]}, {"text": "This paper describes four machine learning experiments that directly evaluate the abilities of these models to learn representations that support specific semantic behaviors.", "labels": [], "entities": []}, {"text": "These tasks follow the format of natural language inference (also known as recognizing textual entailment;), in which the goal is to determine the core inferential relationship between two sentences.", "labels": [], "entities": [{"text": "recognizing textual entailment", "start_pos": 75, "end_pos": 105, "type": "TASK", "confidence": 0.6436361074447632}]}, {"text": "We introduce a novel NN architecture for natural language inference which independently computes vector representations for each of two sentences using standard) models, and produces a judgment for the pair using only those representations.", "labels": [], "entities": []}, {"text": "This allows us to gauge the abilities of these two models to represent all of the necessary semantic information in the sentence vectors.", "labels": [], "entities": []}, {"text": "Much of the theoretical work on natural language inference (and some successful implemented models;) involves natural logics, which are formal systems that define rules of inference between natural language words, phrases, and sentences without the need of intermediate representations in an artificial logical language.", "labels": [], "entities": [{"text": "natural language inference", "start_pos": 32, "end_pos": 58, "type": "TASK", "confidence": 0.6708558003107706}]}, {"text": "In our first three experiments, we test our models' ability to learn the foundations of natural language inference by training them to reproduce the behavior of the natural logic of on artificial data.", "labels": [], "entities": []}, {"text": "This logic defines seven mutually-exclusive relations of synonymy, entailment, contradiction, and mutual consistency, as summarized in, and it provides rules of semantic combination for projecting these relations from the lexicon up to complex phrases.", "labels": [], "entities": []}, {"text": "The formal properties of this system are now well-understood).", "labels": [], "entities": []}, {"text": "The first experiment using this logic covers reasoning with the bare logical relations ( \u00a73), the second extends this to reasoning with statements constructed compositionally from recursive functions ( \u00a74), and the third covers the additional complexity that results from quantification ( \u00a75).", "labels": [], "entities": []}, {"text": "Though the performance of the plain TreeRNN model is somewhat poor in our first experiment, we find that the stronger TreeRNTN model generalizes well in every case, suggesting that it has learned to simulate our target logical concepts.", "labels": [], "entities": []}, {"text": "The experiments with simulated data provide a convincing demonstration of the ability of neural networks to learn to build and use semantic representations for complex natural language sentences from reasonably-sized training sets.", "labels": [], "entities": []}, {"text": "However, we are also interested in the more practical question of whether they can learn these representations from naturalistic text.", "labels": [], "entities": []}, {"text": "To address this question, we apply our models to the SICK entailment challenge data in \u00a76.", "labels": [], "entities": [{"text": "SICK entailment challenge data in \u00a76", "start_pos": 53, "end_pos": 89, "type": "DATASET", "confidence": 0.8316911714417594}]}, {"text": "The small size of this corpus puts datahungry NN models like ours at a disadvantage, but we are nonetheless able to achieve competitive performance on it, surpassing several submitted models with significant hand-engineered taskspecific features and our own NN baseline.", "labels": [], "entities": []}, {"text": "This suggests that the representational abilities that we observe in the previous sections are not limited to carefully circumscribed tasks.", "labels": [], "entities": []}, {"text": "We conclude that TreeRNTN models are adequate for typical cases of natural language inference, and that there is not yet any clear level of inferential complexity for which other approaches work and NN models fail.", "labels": [], "entities": [{"text": "natural language inference", "start_pos": 67, "end_pos": 93, "type": "TASK", "confidence": 0.642404039700826}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 6: Examples of each category used in error analysis from the SICK test data.", "labels": [], "entities": [{"text": "SICK test data", "start_pos": 68, "end_pos": 82, "type": "DATASET", "confidence": 0.8335212667783102}]}, {"text": " Table 7: Classification accuracy, including a cat- egory breakdown for SICK test data. Categories  are shown with their frequencies.", "labels": [], "entities": [{"text": "Classification", "start_pos": 10, "end_pos": 24, "type": "TASK", "confidence": 0.9264382123947144}, {"text": "accuracy", "start_pos": 25, "end_pos": 33, "type": "METRIC", "confidence": 0.9655431509017944}, {"text": "SICK test data", "start_pos": 72, "end_pos": 86, "type": "DATASET", "confidence": 0.773312489191691}]}]}