{"title": [{"text": "A Multi-classifier Approach to support Coreference Resolution in a Vector Space Model", "labels": [], "entities": [{"text": "Coreference Resolution", "start_pos": 39, "end_pos": 61, "type": "TASK", "confidence": 0.9841993451118469}]}], "abstractContent": [{"text": "In this paper a different machine learning approach is presented to deal with the coref-erence resolution task.", "labels": [], "entities": [{"text": "coref-erence resolution task", "start_pos": 82, "end_pos": 110, "type": "TASK", "confidence": 0.8486868143081665}]}, {"text": "This approach consists of a multi-classifier system that classifies mention-pairs in a reduced dimensional vector space.", "labels": [], "entities": []}, {"text": "The vector representation for mention-pairs is generated using a rich set of linguistic features.", "labels": [], "entities": []}, {"text": "The SVD technique is used to generate the reduced dimensional vector space.", "labels": [], "entities": []}, {"text": "The approach is applied to the OntoNotes v4.0 Release Corpus for the column-format files used in CONLL-2011 coreference resolution shared task.", "labels": [], "entities": [{"text": "OntoNotes v4.0 Release Corpus", "start_pos": 31, "end_pos": 60, "type": "DATASET", "confidence": 0.8550663441419601}, {"text": "coreference resolution shared task", "start_pos": 108, "end_pos": 142, "type": "TASK", "confidence": 0.7807666957378387}]}, {"text": "The results obtained show that the reduced dimensional representation obtained by SVD is very adequate to appropriately classify mention-pair vectors.", "labels": [], "entities": []}, {"text": "Moreover, we can state that the multi-classifier plays an important role in improving the results.", "labels": [], "entities": []}], "introductionContent": [{"text": "Coreference resolution deals with the problem of finding all expressions that refer to the same entity in a text.", "labels": [], "entities": [{"text": "Coreference resolution", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.9337328374385834}]}, {"text": "It is an important subtask in Natural Language Processing that require natural language understanding, and hence, it is considered to be difficult.", "labels": [], "entities": []}, {"text": "A coreference resolution system has to automatically identify the mentions of entities in text and link the corefering mentions (the ones that refer to the same entity) to form coreference chains.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 2, "end_pos": 24, "type": "TASK", "confidence": 0.9287815690040588}]}, {"text": "Systems are expected to perform both, mention detection and coreference resolution.", "labels": [], "entities": [{"text": "mention detection", "start_pos": 38, "end_pos": 55, "type": "TASK", "confidence": 0.7875939905643463}, {"text": "coreference resolution", "start_pos": 60, "end_pos": 82, "type": "TASK", "confidence": 0.9638814628124237}]}, {"text": "Preliminary researches proposed heuristic approaches to the task, but thanks to the annotated coreference corpora made available in the last years and the progress achieved in statistical NLP methods, machine learning approaches to the coreference resolution task are being proposed.", "labels": [], "entities": [{"text": "coreference resolution task", "start_pos": 236, "end_pos": 263, "type": "TASK", "confidence": 0.9288445115089417}]}, {"text": "presents an interesting survey of the progress in coreference resolution.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 50, "end_pos": 72, "type": "TASK", "confidence": 0.9762896299362183}]}, {"text": "In this paper we present a different machine learning approach to deal with the coreference resolution task.", "labels": [], "entities": [{"text": "coreference resolution task", "start_pos": 80, "end_pos": 107, "type": "TASK", "confidence": 0.9411195913950602}]}, {"text": "Given a corpus with annotated mentions, the multi-classifier system we present classifies mention-pairs in a reduced dimensional vector space.", "labels": [], "entities": []}, {"text": "We use the typical mention-pair model, where each pair of mentions is represented by a rich set of linguistic features; positive instances correspond to mention-pairs that corefer.", "labels": [], "entities": []}, {"text": "Coreference resolution is tackled as a binary classification problem () in this paper; the subsequent linking of mentions into coreference chains is not considered.", "labels": [], "entities": [{"text": "Coreference resolution", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.9361631870269775}]}, {"text": "In fact, the aim of our experiment is to measure to what extent working with feature vectors in a reduced dimensional vector space and applying a multi-classifier system helps to determine the coreference of mention-pairs.", "labels": [], "entities": []}, {"text": "To the best of our knowledge, there are no approaches to the coreference resolution task which make use of multi-classifier systems to classify mention-pairs in a reduced dimensional vector space.", "labels": [], "entities": [{"text": "coreference resolution task", "start_pos": 61, "end_pos": 88, "type": "TASK", "confidence": 0.9343299865722656}]}, {"text": "This paper gives a brief description of our approach to deal with the problem of identifying whether two mentions corefer and shows the results obtained.", "labels": [], "entities": []}, {"text": "Section 2 presents related work.", "labels": [], "entities": []}, {"text": "In Section 3 our approach is presented.", "labels": [], "entities": []}, {"text": "Section 4 presents the case study, where details about the dataset used in the experiments and the preprocessing applied are given.", "labels": [], "entities": []}, {"text": "In Section 5 the experimental setup is briefly introduced.", "labels": [], "entities": []}, {"text": "The experimental results are presented and discussed in Section 6, and finally, Section 7 contains some conclusions and comments on future work.", "labels": [], "entities": []}], "datasetContent": [{"text": "The approach presented in this paper is a binary classification system where the final prediction c j maybe positive (mentions tested corefer) or negative (mentions do not corefer).", "labels": [], "entities": []}, {"text": "There are many metrics that can be used to measure the performance of a classifier.", "labels": [], "entities": []}, {"text": "In binary classification problems precision and recall are very widely used.", "labels": [], "entities": [{"text": "binary classification", "start_pos": 3, "end_pos": 24, "type": "TASK", "confidence": 0.7568502426147461}, {"text": "precision", "start_pos": 34, "end_pos": 43, "type": "METRIC", "confidence": 0.9990565180778503}, {"text": "recall", "start_pos": 48, "end_pos": 54, "type": "METRIC", "confidence": 0.9992480874061584}]}, {"text": "Precision (Prec) is the number of correct positive results divided by the number of all positive results, and recall (Rec) is the number of correct positive results divided by the number of positive results that should have been returned.", "labels": [], "entities": [{"text": "Precision (Prec)", "start_pos": 0, "end_pos": 16, "type": "METRIC", "confidence": 0.9417145550251007}, {"text": "recall (Rec)", "start_pos": 110, "end_pos": 122, "type": "METRIC", "confidence": 0.9733027368783951}]}, {"text": "In general, there is a trade-off between precision and recall.", "labels": [], "entities": [{"text": "precision", "start_pos": 41, "end_pos": 50, "type": "METRIC", "confidence": 0.9994152784347534}, {"text": "recall", "start_pos": 55, "end_pos": 61, "type": "METRIC", "confidence": 0.997552216053009}]}, {"text": "Thus, a classifier is usually evaluated by means of a measure which combines them.", "labels": [], "entities": []}, {"text": "The F 1 -score can be interpreted as a weighted average of precision and recall; it reaches its best value at 1 and worst score at 0.", "labels": [], "entities": [{"text": "F 1 -score", "start_pos": 4, "end_pos": 14, "type": "METRIC", "confidence": 0.9746099263429642}, {"text": "precision", "start_pos": 59, "end_pos": 68, "type": "METRIC", "confidence": 0.9994292855262756}, {"text": "recall", "start_pos": 73, "end_pos": 79, "type": "METRIC", "confidence": 0.9986485838890076}]}, {"text": "Accuracy is also used as a statistical measure of performance in binary classification tasks.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 0, "end_pos": 8, "type": "METRIC", "confidence": 0.9915627241134644}, {"text": "binary classification tasks", "start_pos": 65, "end_pos": 92, "type": "TASK", "confidence": 0.7557280759016672}]}, {"text": "Accuracy is the proportion of true results (both true positives and true negatives) among the total number of cases tested.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 0, "end_pos": 8, "type": "METRIC", "confidence": 0.9932835102081299}]}, {"text": "The OntoNotes v4.0 Release Corpus is used in the experiments 2 . It provides a large-scale multi-genre corpus with multiple layers of annotation (syntactic, semantic and discourse information) which also include coreference tags.", "labels": [], "entities": [{"text": "OntoNotes v4.0 Release Corpus", "start_pos": 4, "end_pos": 33, "type": "DATASET", "confidence": 0.7440008074045181}]}, {"text": "A nice description of the coreference annotation in OntoNotes can be found in (Pradhan et al., 2007a) and ( The English language portion of the OntoNotes v4.0 Release Corpus was used in the CONLL-2011 coreference resolution Shared task 3 . The task was to automatically identify mentions of entities and events in text and to link the corefering mentions together to form mention chains.", "labels": [], "entities": [{"text": "OntoNotes v4.0 Release Corpus", "start_pos": 144, "end_pos": 173, "type": "DATASET", "confidence": 0.6732762902975082}, {"text": "CONLL-2011 coreference resolution Shared task 3", "start_pos": 190, "end_pos": 237, "type": "TASK", "confidence": 0.6730878154436747}]}, {"text": "Since OntoNotes coreference data spans multiple genre, the task organizers created a test set spanning all the genres.", "labels": [], "entities": []}, {"text": "The training, development and test files were downloaded from the CONLL-2011 website, and the * conll files were generated from each corresponding * skel files using the scripts made available by the organizers.", "labels": [], "entities": [{"text": "CONLL-2011 website", "start_pos": 66, "end_pos": 84, "type": "DATASET", "confidence": 0.9496466815471649}]}, {"text": "The * conll files contain information in a tabular structure where the last column contains coreference chain information.", "labels": [], "entities": []}, {"text": "Two types of * conll files maybe generated, depending on how the annotation was generated; *gold conll files were handannotated and adjudicated quality, whereas annotations in *auto conll files were produced using a combination of automatic tools.", "labels": [], "entities": []}, {"text": "*gold conll files are used in the experiments presented in this paper.", "labels": [], "entities": []}, {"text": "To optimize the behaviour of the multi-classifier system, the number of TD i training datasets is adjusted in a parameter tuning phase.", "labels": [], "entities": []}, {"text": "This optimization process is performed in an independent way for each of the genres because the five genres correspond to texts coming from different sources and may have very different characteristics ( ).", "labels": [], "entities": []}, {"text": "Therefore, we treat them as five different classification problems.", "labels": [], "entities": []}, {"text": "The five development corpora are used to adjust parameter i (the amount of TD i training datasets).", "labels": [], "entities": []}, {"text": "We experimented with the following values for i: 5, 10, 20, 30, 40, 50, 60, 70, 80.", "labels": [], "entities": []}, {"text": "Two different dimensional representations are experimented for mention-pair vectors.", "labels": [], "entities": []}, {"text": "On the one hand, we consider mention-pair vectors represented in the original 127 dimensions.", "labels": [], "entities": []}, {"text": "On the other hand, the SVD-computed dimensional vector representation is being experimented.", "labels": [], "entities": []}, {"text": "shows the number of singular values (dimensions) computed by SVD for each of the genres.", "labels": [], "entities": []}, {"text": "Three experiments were carried out in the test phase using the optimal values for parameter i and the two different representations for mention-pair vectors.", "labels": [], "entities": []}, {"text": "shows the results obtained for each of the experiments: accuracy values in a first row (Acc.) and F 1 -scores in a second (F 1 ).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 56, "end_pos": 64, "type": "METRIC", "confidence": 0.9996013045310974}, {"text": "Acc.", "start_pos": 88, "end_pos": 92, "type": "METRIC", "confidence": 0.9940807223320007}, {"text": "F 1 -scores", "start_pos": 98, "end_pos": 109, "type": "METRIC", "confidence": 0.9823951125144958}, {"text": "F 1 )", "start_pos": 123, "end_pos": 128, "type": "METRIC", "confidence": 0.9075300494829813}]}, {"text": "Ina first experiment (Exp.1), the Weka 3-NN classifier is applied to classify testing cases represented in the original 127 dimensional space.", "labels": [], "entities": [{"text": "Weka 3-NN classifier", "start_pos": 34, "end_pos": 54, "type": "DATASET", "confidence": 0.872184177239736}]}, {"text": "The same 3-NN classifier is applied in a second experiment (Exp.2), but training and testing cases are represented using the dimensions computed by SVD (see Singular Values in).", "labels": [], "entities": [{"text": "Exp.2", "start_pos": 60, "end_pos": 65, "type": "DATASET", "confidence": 0.9197342991828918}]}, {"text": "Ina last experiment (Exp.3), our approach is applied and a multi-classifier system classifies testing vectors in the same SVD-dimensional vector space as in the previous experiment.", "labels": [], "entities": []}, {"text": "The multi-classifier is generated according to the optimal values for parameter i in each genre.", "labels": [], "entities": []}, {"text": "The results shown in bold in the first part of Table 4 are the best for each genre.", "labels": [], "entities": []}, {"text": "Note that the two performance measures computed (accuracy and F 1 -score) are very correlated in the five cases.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 49, "end_pos": 57, "type": "METRIC", "confidence": 0.999626874923706}, {"text": "F 1 -score)", "start_pos": 62, "end_pos": 73, "type": "METRIC", "confidence": 0.9823767185211182}]}, {"text": "Taking into account that the proportion of positive and negative examples varies from genre to genre, this correlation gives consistency to the interpretation of the results obtained.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Size of corpora used in the experiments.", "labels": [], "entities": []}, {"text": " Table 1. gives detailed information about the  number of positive and negative mention-pairs in  the training, development and test corpora used in  the experiments. A matrix is constructed for each  of the training corpus. Feature values that appear  at least once in the corpus are selected as terms.  Even though theoretically we could have a maxi- mum number of 254 different terms in each train- ing corpus (127 \u00d7 2, because the 127 features are  binary), the real value is between 227 and 230. The", "labels": [], "entities": []}, {"text": " Table 2: Size of term-document matrices M .", "labels": [], "entities": []}, {"text": " Table 3: Optimal values for the number of T D i datasets.  Number of singular values computed by SVD", "labels": [], "entities": [{"text": "SVD", "start_pos": 98, "end_pos": 101, "type": "TASK", "confidence": 0.4633089005947113}]}, {"text": " Table 4: Accuracy and F 1 -score for the test corpora.  Exp.1: 3-NN and 127 dimensions. Exp.2: 3-NN and  SVD dimensions. Exp.3: multi-classifier and SVD di- mensions. Last column: mean values", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9994480013847351}, {"text": "F 1 -score", "start_pos": 23, "end_pos": 33, "type": "METRIC", "confidence": 0.9896072000265121}]}]}