{"title": [{"text": "Multilingual Reliability and \"Semantic\" Structure of Continuous Word Spaces", "labels": [], "entities": []}], "abstractContent": [{"text": "While continuous word vector representations enjoy increasing popularity, it is still poorly understood (i) how reliable they are for other languages than English, and (ii) to what extent they encode deep semantic relatedness such as paradigmatic relations.", "labels": [], "entities": []}, {"text": "This study presents experiments with continuous word vectors for English and German, a morphologically rich language.", "labels": [], "entities": []}, {"text": "For evaluation , we use both published and newly created datasets of morpho-syntactic and semantic relations.", "labels": [], "entities": []}, {"text": "Our results show that (i) morphological complexity causes a drop inaccuracy, and (ii) continuous representations lack the ability to solve analogies of paradigmatic relations.", "labels": [], "entities": []}], "introductionContent": [{"text": "Until recently, the majority of research on semantic spaces concentrated on vector spaces relying on context counts (count vector spaces).", "labels": [], "entities": []}, {"text": "However, increasing attention is being devoted to low-dimensional continuous word vector representations.", "labels": [], "entities": []}, {"text": "Unlike count vectors, these continuous vectors are the result of supervised training of context-predicting models (predict vector spaces).", "labels": [], "entities": []}, {"text": "Mikolov et al. reported that a predict vector space trained with a simplified neural language model (cf.) seemingly encodes syntactic and semantic properties, which can be recovered directly from the space through linear translations, to solve analogies such as \u2212 \u2212 \u2192 king \u2212 \u2212 \u2212 \u2192 man = \u2212 \u2212\u2212 \u2192 queen \u2212 \u2212 \u2212\u2212\u2212 \u2192 woman.", "labels": [], "entities": []}, {"text": "presented experiments where predict vectors outperform count vectors on several semantic benchmarks involving semantic relatedness, word clustering, and selectional preferences.", "labels": [], "entities": [{"text": "word clustering", "start_pos": 132, "end_pos": 147, "type": "TASK", "confidence": 0.7591370046138763}]}, {"text": "Several open questions regarding predict vectors remain.", "labels": [], "entities": [{"text": "predict vectors", "start_pos": 33, "end_pos": 48, "type": "TASK", "confidence": 0.9763683080673218}]}, {"text": "In this paper, we focus on two shortcomings of previous analyses.", "labels": [], "entities": []}, {"text": "First, the analogies in the \"syntactic\" and \"semantic\" benchmark datasets by  in fact cover mostly morpho-syntactic relations -even in the semantic category.", "labels": [], "entities": []}, {"text": "Consequently, it is still unknown to what extent predict vector spaces encode deep semantic relatedness, such as paradigmatic relations.", "labels": [], "entities": []}, {"text": "offered some insight by testing hypernymy relations through similarity; investigated synonymy, hypernymy, and co-hyponymy relations.", "labels": [], "entities": []}, {"text": "However, no systematic evaluation of deep semantic analogies has been performed so far.", "labels": [], "entities": []}, {"text": "Second, it remains unclear whether comparable performance can be achieved fora wider range of relations in morphologically rich languages, as most previous work on predict vectors worked with English data.", "labels": [], "entities": []}, {"text": "A notable exception is Zuanovi\u00b4c, who achieved strong performance for superlative and country-capital analogies in Croatian.", "labels": [], "entities": []}, {"text": "learned mappings of predict vectors between English, Hebrew, and Arabic, but provided no deeper insight into the model's capabilities on a direct evaluation of semantic relations.", "labels": [], "entities": []}, {"text": "trained predict vectors using two languages, but evaluated only in English.", "labels": [], "entities": []}, {"text": "We present a systematic exploration of morpho-syntactic and semantic relatedness in English and the morphologically richer language German.", "labels": [], "entities": []}, {"text": "We show detailed results of the continuous bag-of-words model (CBOW) by , which we apply to equivalent morpho-syntactic tasks for both The terminology follows.", "labels": [], "entities": []}], "datasetContent": [{"text": "Our setups vary model type (two predict models and one count model), language (English and German), and word forms vs. lemmas in the training data -leading to a total of 3\u00d72\u00d72 models.", "labels": [], "entities": []}, {"text": "Our predict models are the standard CBOW and SKIP-gram models, trained with the word2vec toolkit ( ).", "labels": [], "entities": [{"text": "CBOW", "start_pos": 36, "end_pos": 40, "type": "DATASET", "confidence": 0.8409250378608704}]}, {"text": "We use negative sampling with 15 negative samples, 400 dimensions, asymmetrical window of size 2, subsampling with p = 10 \u22125 , and a frequency threshold of 50 to filter out rare words.", "labels": [], "entities": []}, {"text": "Our count model is a standard bag-of-words model with positive point-wise mutual information weighting and dimensionality reduction through singular value decomposition.", "labels": [], "entities": []}, {"text": "The dimensionality and the window size were set identical to the predict vectors.", "labels": [], "entities": []}, {"text": "We solve analogy tasks with the 3COSMUL method (, and similarity tasks with cosine similarity.", "labels": [], "entities": []}, {"text": "For the Google, TOEFL, and Sem-Para tasks, we report accuracy; for RG and WordSim we report Spearman's rank-order correlation coefficient \u03c1.", "labels": [], "entities": [{"text": "TOEFL", "start_pos": 16, "end_pos": 21, "type": "DATASET", "confidence": 0.7913200259208679}, {"text": "accuracy", "start_pos": 53, "end_pos": 61, "type": "METRIC", "confidence": 0.9991925358772278}, {"text": "WordSim", "start_pos": 74, "end_pos": 81, "type": "DATASET", "confidence": 0.911772608757019}, {"text": "rank-order correlation coefficient \u03c1", "start_pos": 103, "end_pos": 139, "type": "METRIC", "confidence": 0.7855204790830612}]}], "tableCaptions": [{"text": " Table 1: Results (\u03c1 for Sem-Gen, accuracy for others) by task category across models.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 34, "end_pos": 42, "type": "METRIC", "confidence": 0.9991558790206909}]}, {"text": " Table 2: Results by task for the English and German CBOW models.", "labels": [], "entities": [{"text": "English and German CBOW models", "start_pos": 34, "end_pos": 64, "type": "DATASET", "confidence": 0.6908382594585418}]}, {"text": " Table 3: Sem-Para results across models, for recall at ten.", "labels": [], "entities": [{"text": "recall", "start_pos": 46, "end_pos": 52, "type": "METRIC", "confidence": 0.9992424249649048}]}]}