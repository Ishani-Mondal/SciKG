{"title": [{"text": "Integrating Query Performance Prediction in Term Scoring for Diachronic Thesaurus", "labels": [], "entities": []}], "abstractContent": [{"text": "A diachronic thesaurus is a lexical resource that aims to map between modern terms and their semantically related terms in earlier periods.", "labels": [], "entities": []}, {"text": "In this paper, we investigate the task of collecting a list of relevant modern target terms fora domain-specific diachronic thesaurus.", "labels": [], "entities": []}, {"text": "We propose a supervised learning scheme, which integrates features from two closely related fields: Terminology Extraction and Query Performance Prediction (QPP).", "labels": [], "entities": [{"text": "Query Performance Prediction (QPP)", "start_pos": 127, "end_pos": 161, "type": "TASK", "confidence": 0.6046387056509653}]}, {"text": "Our method further expands modern candidate terms with ancient related terms, before assessing their corpus relevancy with QPP measures.", "labels": [], "entities": []}, {"text": "We evaluate the empirical benefit of our method fora thesaurus fora diachronic Jewish corpus.", "labels": [], "entities": []}], "introductionContent": [{"text": "In recent years, there has been growing interest in diachronic lexical resources, which comprise terms from different language periods.", "labels": [], "entities": []}, {"text": "These resources are mainly used for studying language change and supporting searches in historical domains, bridging the lexical gap between modern and ancient language.", "labels": [], "entities": []}, {"text": "In particular, we are interested in this paper in a certain type of diachronic thesaurus.", "labels": [], "entities": []}, {"text": "It contains entries for modern terms, denoted as target terms.", "labels": [], "entities": []}, {"text": "Each entry includes a list of ancient related terms.", "labels": [], "entities": []}, {"text": "Beyond being a historical linguistic resource, such thesaurus is useful for supporting searches in a diachronic corpus, composed of both modern and ancient documents.", "labels": [], "entities": []}, {"text": "For example, in our historical Jewish corpus, the modern Hebrew term for terminal patient 1 has only few verbatim occurrences, in modern documents, but this topic has been widely discussed in ancient periods.", "labels": [], "entities": []}, {"text": "A domain searcher needs the diachronic thesaurus to enrich the search with ancient synonyms or related terms, such as dying and living for the moment.", "labels": [], "entities": []}, {"text": "Prior work on diachronic thesauri addressed the problem of collecting relevant related terms forgiven thesaurus entries.", "labels": [], "entities": []}, {"text": "In this paper we focus on the complementary preceding task of collecting a relevant list of modern target terms fora diachronic thesaurus in a certain domain.", "labels": [], "entities": []}, {"text": "As a starting point, we assume that a list of meaningful terms in the modern language is given, such as titles of Wikipedia articles.", "labels": [], "entities": []}, {"text": "Then, our task is to automatically decide which of these candidate terms are likely to be relevant for the corpus domain and should be included in the thesaurus.", "labels": [], "entities": []}, {"text": "In other words, we need to decide which of the candidate modern terms corresponds to a concept that has been discussed significantly in the diachronic domain corpus.", "labels": [], "entities": []}, {"text": "Our task is closely related to term scoring in the known Terminology Extraction (TE) task in NLP.", "labels": [], "entities": [{"text": "Terminology Extraction (TE) task", "start_pos": 57, "end_pos": 89, "type": "TASK", "confidence": 0.7247883876164755}]}, {"text": "The goal of corpus-based TE is to automatically extract prominent terms from a given corpus and score them for domain relevancy.", "labels": [], "entities": [{"text": "TE", "start_pos": 25, "end_pos": 27, "type": "TASK", "confidence": 0.8634170889854431}]}, {"text": "In our setting, since all the target terms are modern, we avoid extracting them from the diachronic corpus of modern and ancient language.", "labels": [], "entities": []}, {"text": "Instead, we use a given candidate list and apply only the term scoring phase.", "labels": [], "entities": []}, {"text": "As a starting point, we adopt a rich set of state-of-the-art TE scoring measures and integrate them as features in a common supervised classification approach.", "labels": [], "entities": [{"text": "TE scoring", "start_pos": 61, "end_pos": 71, "type": "TASK", "confidence": 0.8554078340530396}]}, {"text": "Given our Information Retrieval (IR) motivation, we notice a closely related task to TE, namely Query Performance Prediction (QPP).", "labels": [], "entities": [{"text": "Information Retrieval (IR)", "start_pos": 10, "end_pos": 36, "type": "TASK", "confidence": 0.8071664452552796}, {"text": "TE", "start_pos": 85, "end_pos": 87, "type": "TASK", "confidence": 0.6854022741317749}, {"text": "Query Performance Prediction (QPP)", "start_pos": 96, "end_pos": 130, "type": "TASK", "confidence": 0.5749360471963882}]}, {"text": "QPP methods are designed to estimate the retrieval quality of search queries, by assessing their relevance to the text collection.", "labels": [], "entities": []}, {"text": "Therefore, QPP scoring measures seem to be potentially suitable also for our terminology scoring task, by considering the candidate term as a search query.", "labels": [], "entities": [{"text": "QPP scoring", "start_pos": 11, "end_pos": 22, "type": "TASK", "confidence": 0.6587002277374268}, {"text": "terminology scoring task", "start_pos": 77, "end_pos": 101, "type": "TASK", "confidence": 0.8957563440004984}]}, {"text": "Some of the QPP measures are indeed similar in nature to the TE methods, analyzing the distribution of the query terms within the collection.", "labels": [], "entities": []}, {"text": "However, some of the QPP methods have different IR-biased characteristics and may provide a marginal contribution.", "labels": [], "entities": []}, {"text": "Therefore, we adopted them as additional features for our classifier and indeed observed a performance increase.", "labels": [], "entities": []}, {"text": "Most of the QPP methods prioritize query terms with high frequency in the corpus.", "labels": [], "entities": []}, {"text": "However, in a diachronic corpus, such criterion may sometimes be problematic.", "labels": [], "entities": []}, {"text": "A modern target term might appear only in few modern documents, while being referred to, via ancient terminology, also in ancient documents.", "labels": [], "entities": []}, {"text": "Therefore, we would like our prediction measure to be aware of these ancient documents as well.", "labels": [], "entities": [{"text": "prediction", "start_pos": 29, "end_pos": 39, "type": "TASK", "confidence": 0.8949967622756958}]}, {"text": "Following a particular QPP measure ( , we address this problem through Query Expansion (QE).", "labels": [], "entities": [{"text": "Query Expansion (QE)", "start_pos": 71, "end_pos": 91, "type": "METRIC", "confidence": 0.6644221484661103}]}, {"text": "Accordingly, our method first expands the query containing the modern candidate term, then calculates the QPP scores of the expanded query and then utilizes them as scoring features.", "labels": [], "entities": [{"text": "QPP", "start_pos": 106, "end_pos": 109, "type": "METRIC", "confidence": 0.8245161771774292}]}, {"text": "Combining the baseline features with our expansion-based QPP features yields additional improvement in the classification results.", "labels": [], "entities": []}], "datasetContent": [{"text": "We applied our method to the diachronic corpus is the Responsa project Hebrew corpus . The Responsa corpus includes rabbinic case-law rulings which represent the historical-sociological milieu of real-life situations, collected over more than a thousand years, from the 11 th century until today.", "labels": [], "entities": [{"text": "Responsa project Hebrew corpus", "start_pos": 54, "end_pos": 84, "type": "DATASET", "confidence": 0.5969061031937599}]}, {"text": "The corpus consists of 81,993 documents, and was used for previous NLP and IR research (.", "labels": [], "entities": []}, {"text": "The candidate target terms for our classification task were taken from the publicly available keylist of Hebrew Wikipedia entries 6 . Since many of these tens of thousands entries, such as person names and place names, were not suitable as target terms, we first filtered them by Hebrew Named Entity Recognition 7 and manually.", "labels": [], "entities": [{"text": "Hebrew Named Entity Recognition", "start_pos": 280, "end_pos": 311, "type": "TASK", "confidence": 0.5616283789277077}]}, {"text": "Then, a list of approximately 5000 candidate target terms was manually annotated by two domain experts.", "labels": [], "entities": []}, {"text": "The experts decided which of the candidates corresponds to a concept that has been discussed significantly in our diachronic domain corpus.", "labels": [], "entities": []}, {"text": "Only candidates that the annotators agreed on their annotation were retained, and then balanced for equal number of positive and negative examples.", "labels": [], "entities": []}, {"text": "Consequently, the balanced training and test sets contain 500 and 200 candidates, respectively.", "labels": [], "entities": []}, {"text": "For classification, Weka's 8 Support Vector Machine supervised classifier with polynomial kernel was used.", "labels": [], "entities": [{"text": "classification", "start_pos": 4, "end_pos": 18, "type": "TASK", "confidence": 0.9751967191696167}]}, {"text": "We train the classifier with our training set and measure the accuracy on the test set.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 62, "end_pos": 70, "type": "METRIC", "confidence": 0.9995280504226685}]}, {"text": "compares the classification performance of our baseline (TE) and integrated systems, (TE-QPP T erm ) and (TE-QPP QE ), proposed in Section 3.", "labels": [], "entities": [{"text": "TE-QPP T erm )", "start_pos": 86, "end_pos": 100, "type": "METRIC", "confidence": 0.9061444848775864}]}], "tableCaptions": []}