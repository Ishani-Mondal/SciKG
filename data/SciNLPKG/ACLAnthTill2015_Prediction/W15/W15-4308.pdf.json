{"title": [{"text": "IITP: Multiobjective Differential Evolution based Twitter Named Entity Recognition", "labels": [], "entities": [{"text": "IITP", "start_pos": 0, "end_pos": 4, "type": "TASK", "confidence": 0.8716893196105957}, {"text": "Multiobjective Differential Evolution based Twitter Named Entity Recognition", "start_pos": 6, "end_pos": 82, "type": "TASK", "confidence": 0.6025179997086525}]}], "abstractContent": [{"text": "In this paper we propose a differential evolution (DE) based named entity recognition (NER) system in twitter data.", "labels": [], "entities": [{"text": "differential evolution (DE) based named entity recognition (NER)", "start_pos": 27, "end_pos": 91, "type": "TASK", "confidence": 0.6798087408145269}]}, {"text": "In the first step, we develop various NER systems using different combinations of the features.", "labels": [], "entities": []}, {"text": "We implemented these features without using any domain-specific features and/or resources.", "labels": [], "entities": []}, {"text": "As abase clas-sifier we use Conditional Random Field (CRF).", "labels": [], "entities": [{"text": "Conditional Random Field (CRF)", "start_pos": 28, "end_pos": 58, "type": "METRIC", "confidence": 0.7719182421763738}]}, {"text": "In the second step, we propose a DE based feature selection approach to determine the most relevant set of features and its context information.", "labels": [], "entities": []}, {"text": "The optimized feature set applied to the training set yields the precision, recall and F-measure values of 60.68%, 29.65% and 39.84%, respectively for the fine-grained named entity (NE) types.", "labels": [], "entities": [{"text": "precision", "start_pos": 65, "end_pos": 74, "type": "METRIC", "confidence": 0.9997183680534363}, {"text": "recall", "start_pos": 76, "end_pos": 82, "type": "METRIC", "confidence": 0.9965059757232666}, {"text": "F-measure", "start_pos": 87, "end_pos": 96, "type": "METRIC", "confidence": 0.996485710144043}]}, {"text": "When we consider only the coarse-grained NE types, it shows the precision, recall and F-measure values of 63.43%, 51.44% and 56.81%, respectively .", "labels": [], "entities": [{"text": "precision", "start_pos": 64, "end_pos": 73, "type": "METRIC", "confidence": 0.9997594952583313}, {"text": "recall", "start_pos": 75, "end_pos": 81, "type": "METRIC", "confidence": 0.9975451827049255}, {"text": "F-measure", "start_pos": 86, "end_pos": 95, "type": "METRIC", "confidence": 0.9983528852462769}]}], "introductionContent": [{"text": "During the last few years there has been a phenomenal growth in the number of users that make use of different social networking platforms to share their opinions and views.", "labels": [], "entities": []}, {"text": "Twitter now has upto over 500 million users with approx 302 million active users . One can easily imagine that amount of tweets generated per day would be enormous i.e. almost 500 million tweets per day 2 . These information are usually unstructured and noisy in nature.", "labels": [], "entities": []}, {"text": "The reason behind its unstructured nature is that tweets are rather short messages (constitute upto 140 characters only), contains several grammatical & spelling mistakes etc.", "labels": [], "entities": []}, {"text": "The size limitation bounds a user to invent several short forms (e.g. 2mrw, tmrw for tomorrow) of a valid word which a human mind can interpret easily but, on the other hand, becomes very difficult to come up with an accurate system for solving any problem related to natural language processing (NLP).", "labels": [], "entities": []}, {"text": "Also in order to show their emotions, users sometime put extra emphasis by elongating a valid word (e.g. yeeesssss!! for yes).", "labels": [], "entities": []}, {"text": "Named entity recognition (NER) can be seen as one of the important and foremost tasks for many natural language processing (NLP) tasks such as machine translation, information extraction, question-answering etc.", "labels": [], "entities": [{"text": "Named entity recognition (NER)", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.8145456314086914}, {"text": "machine translation", "start_pos": 143, "end_pos": 162, "type": "TASK", "confidence": 0.7787452042102814}, {"text": "information extraction", "start_pos": 164, "end_pos": 186, "type": "TASK", "confidence": 0.7736584544181824}]}, {"text": "The task of NER can bethought of as a two-step process that involves identifying proper names from the text and classifying them into some predefined categories such as person, organization, location etc.", "labels": [], "entities": [{"text": "NER", "start_pos": 12, "end_pos": 15, "type": "TASK", "confidence": 0.9710057377815247}]}, {"text": "Although the techniques () for recognizing named entities (NEs) in newswire and other well-formatted traditional corpus has already matured but it is still a challenging task to perform in unstructured and noisy twitter data.", "labels": [], "entities": [{"text": "recognizing named entities (NEs)", "start_pos": 31, "end_pos": 63, "type": "TASK", "confidence": 0.8037764728069305}]}, {"text": "The concept of NER in twitter has recently drawn the attention of researchers worldwide.", "labels": [], "entities": [{"text": "NER", "start_pos": 15, "end_pos": 18, "type": "TASK", "confidence": 0.9849157333374023}]}, {"text": "Very few authors have reported their works ( for NER in twitter.", "labels": [], "entities": []}, {"text": "A semi-supervised model for NER has been reported in () where K-nearest neighbour classifier is combined with CRF.", "labels": [], "entities": [{"text": "NER", "start_pos": 28, "end_pos": 31, "type": "TASK", "confidence": 0.9896490573883057}]}, {"text": "Application of LabeledLDA () in supervised environment can be found in ().", "labels": [], "entities": []}, {"text": "Their method classifies NEs into fine-grained types of 10 classes (as in our case).", "labels": [], "entities": []}, {"text": "In another work (), authors have used random walk model to build an unsupervised approach to NER.", "labels": [], "entities": [{"text": "NER", "start_pos": 93, "end_pos": 96, "type": "TASK", "confidence": 0.9528474807739258}]}, {"text": "They modelled their system on local(tweets) and global (www) context without employing any of the linguistic features.", "labels": [], "entities": []}, {"text": "Few more related works can be found in and.", "labels": [], "entities": []}, {"text": "Due to several challenges it pose, recently there has been a huge interest to identify NE in twitter data.", "labels": [], "entities": []}, {"text": "In compliance with this a shared task \"ACL2015 W-NUT: Named Entity Recognition in Twitter\" 3 was organized.", "labels": [], "entities": [{"text": "Named Entity Recognition in Twitter\"", "start_pos": 54, "end_pos": 90, "type": "TASK", "confidence": 0.7342485934495926}]}, {"text": "The work that we report here is apart of this shared task.", "labels": [], "entities": []}, {"text": "The main objective of the shared task was to efficiently identify various coarse-grained and finegrained named entities.", "labels": [], "entities": []}, {"text": "Fine-grained NE types include 10 different categories namely, person, product, company, geo-loc, movie, musicartist, tvshow, facility, sportsteam and other.", "labels": [], "entities": []}, {"text": "We have used a rich feature set based on lexical and syntactic properties of a tweet as discussed in Section 3.9.", "labels": [], "entities": []}, {"text": "Our proposed work uses Conditional Random Field (CRF) () as learning algorithm, which is very efficient as a sequence learner.", "labels": [], "entities": []}, {"text": "Subsequently we have applied Differential Evolution (DE), a stochastic, population based optimization algorithm, introduced by Storn and Prince in 1996, to obtain the optimal feature set for NER in twitter data.", "labels": [], "entities": [{"text": "Differential Evolution (DE)", "start_pos": 29, "end_pos": 56, "type": "TASK", "confidence": 0.7892813801765441}, {"text": "NER", "start_pos": 191, "end_pos": 194, "type": "TASK", "confidence": 0.9643650054931641}]}, {"text": "The organization of the paper is as follows.", "labels": [], "entities": []}, {"text": "Section 2 provides a very brief theoretical discussion of DE.", "labels": [], "entities": [{"text": "DE", "start_pos": 58, "end_pos": 60, "type": "TASK", "confidence": 0.954339861869812}]}, {"text": "Feature set and methodology used in the proposed work are discussed in Section 3.", "labels": [], "entities": []}, {"text": "Experimental result and analysis can be found in Section 4.", "labels": [], "entities": []}, {"text": "We conclude the paper in Section 5.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section we firstly describe the datasets and then report the evaluation results.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2 for the coarse-grained NE tagged and fine- grained NE tagged datasets, respectively. Gold  standard test datasets comprise of 1,000 tweets.", "labels": [], "entities": [{"text": "Gold  standard test datasets", "start_pos": 94, "end_pos": 122, "type": "DATASET", "confidence": 0.559761181473732}]}, {"text": " Table 2: Statistics of the fine-grained dataset.", "labels": [], "entities": [{"text": "fine-grained dataset", "start_pos": 28, "end_pos": 48, "type": "DATASET", "confidence": 0.7485051453113556}]}, {"text": " Table 4: Results of various systems on different dataset. All values are in %.", "labels": [], "entities": []}]}