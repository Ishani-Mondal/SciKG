{"title": [{"text": "Concept Extensions as the Basis for Vector-Space Semantics: Combining Distributional and Ontological Information about Entities", "labels": [], "entities": []}], "abstractContent": [{"text": "We propose to base the development of vector-space models of semantics on concept extensions, which defines concepts to be sets of entities.", "labels": [], "entities": []}, {"text": "We investigate two sources of knowledge about entities that could be relevant: distributional information provided byword or phrase embed-dings, and ontological information derived from a knowledge base.", "labels": [], "entities": []}, {"text": "We develop a feedforward neural network architecture to learn entity representations that are used to predict their concept memberships, and show that the two sources of information are actually complementary.", "labels": [], "entities": [{"text": "predict their concept memberships", "start_pos": 102, "end_pos": 135, "type": "TASK", "confidence": 0.6221299692988396}]}, {"text": "In an entity ranking experiment, the combination approach that uses both types of information outperforms models that only rely on one of the two.", "labels": [], "entities": []}, {"text": "We also perform an analysis of the output using fuzzy logic techniques to demonstrate the potential of learning concept extensions for supporting inference involving classical semantic operations.", "labels": [], "entities": []}], "introductionContent": [{"text": "The extensional definition, or denotation, of a concept is the set of entities in the world to which that concept applies.", "labels": [], "entities": []}, {"text": "For example, the definition of Celebrity would be the set of entities in the world, including Will Smith, Paris Hilton, etc.", "labels": [], "entities": []}, {"text": "In formal semantics and pragmatics, this conception of meaning has played an important role in the accounts of a wide range of compositional constructions, including definite and indefinite articles, quantifiers, presuppositions, and intersective adjectives.", "labels": [], "entities": []}, {"text": "For example, the extension of a noun phrase such as \"red apple\" that is composed of a noun and a modifying adjective is derived by taking the set intersection of the extensions of \"red\" and \"apple\".", "labels": [], "entities": []}, {"text": "In an applied setting, explicitly enumerating the members of these extensions seems to bean impossible task, as there are large numbers of entities and relations, not to mention infinitely many possible contexts and domains.", "labels": [], "entities": []}, {"text": "Thus, the direct application of this view of semantics would seem to be confined to limited domains.", "labels": [], "entities": []}, {"text": "Distributional semantics is a potential solution to this problem.", "labels": [], "entities": [{"text": "Distributional semantics", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.8533999025821686}]}, {"text": "The long-touted advantages of distributional approaches are that they can be easily trained from a large corpus, and they enable a graded notion of similarity.", "labels": [], "entities": []}, {"text": "Typically, such models are trained to optimize distributional criteria based on similarity correlations or predicting a word in context.", "labels": [], "entities": []}, {"text": "However, it is not enough to rely solely on these criteria.", "labels": [], "entities": []}, {"text": "Similarity only supports relative reasoning about relations between concepts, and it is difficult to adapt such measures to make absolute inferences about the truth value of a proposition.", "labels": [], "entities": [{"text": "relative reasoning about relations between concepts", "start_pos": 25, "end_pos": 76, "type": "TASK", "confidence": 0.7906726896762848}]}, {"text": "The applications of distributional semantics (DS) to date have reflected this bias.", "labels": [], "entities": [{"text": "distributional semantics (DS)", "start_pos": 20, "end_pos": 49, "type": "TASK", "confidence": 0.7413378596305847}]}, {"text": "The most common approach to evaluate DS models has been to correlate predicted similarity judgments against judgments gathered from humans ().", "labels": [], "entities": []}, {"text": "More recent applications in paraphrase detection), textual entailment () and analogical reasoning () are also primarily concerned with the relationships between phrases.", "labels": [], "entities": [{"text": "paraphrase detection", "start_pos": 28, "end_pos": 48, "type": "TASK", "confidence": 0.9202247858047485}, {"text": "textual entailment", "start_pos": 51, "end_pos": 69, "type": "TASK", "confidence": 0.6909815669059753}, {"text": "analogical reasoning", "start_pos": 77, "end_pos": 97, "type": "TASK", "confidence": 0.7681443691253662}]}, {"text": "A more serious issue is that distributional semantics alone seems to be insufficient for handling rarely occurring events and entities, if we treat them as just another target phrase in the corpus.", "labels": [], "entities": []}, {"text": "Consider the following passage: (1) He is an American actor, producer, and rapper.", "labels": [], "entities": []}, {"text": "As of 2014, 17 of the 21 films in which he has had leading roles have accumulated worldwide gross earnings of over $100 million each.", "labels": [], "entities": []}, {"text": "Given just this short description of the entity, we are able to make several inferences about its properties.", "labels": [], "entities": []}, {"text": "For example, we are able to infer that this entity is a male human, working in the entertainment industry.", "labels": [], "entities": []}, {"text": "He can most likely vote in American elections, obtain a passport, and he is likely a wealthy celebrity, given the success of the movies he has acted in.", "labels": [], "entities": []}, {"text": "We might even be able to guess the identity of this person (Will Smith) . While it maybe possible to learn these characteristics from the contexts of the bigram \"Will Smith\" in a large training corpus, this is less plausible fora rarely occurring, or perhaps an entirely invented entity.", "labels": [], "entities": []}, {"text": "Clearly, these inferences are enabled by extracting the concept and relational information present in the local context, then relating them to other concepts of interest based on our knowledge of the world.", "labels": [], "entities": []}, {"text": "In this paper, we propose to use concept extension predictions as the overall training objective of a vector-space model of semantics.", "labels": [], "entities": [{"text": "concept extension predictions", "start_pos": 33, "end_pos": 62, "type": "TASK", "confidence": 0.800703763961792}]}, {"text": "While distributional information will still be a crucial component of our model, what distinguishes our approach is that it optimizes directly for an objective which is well justified by compositional theories of semantics, rather than an objective that is internal to considerations within distributional semantics such as similarity measurements.", "labels": [], "entities": []}, {"text": "To predict these concept extensions, we train a model that learns a representation of an input entity using features derived from distributional semantics and ontological information derived from a knowledge base.", "labels": [], "entities": []}, {"text": "Our model, which we call Ontological Distributional Semantics, employs a simple feedforward neural network architecture to learn interactions between these two sources of information.", "labels": [], "entities": []}, {"text": "We conduct experiments on Freebase (, taking Freebase types to be concepts, and the entity set that the Freebase type contains to be that concept's extension.", "labels": [], "entities": [{"text": "Freebase", "start_pos": 26, "end_pos": 34, "type": "DATASET", "confidence": 0.9518448710441589}]}, {"text": "The results of an entity ranking experiment show that Ontological Distributed Semantics outperforms either distributed representations or ontological information alone across three entity classes.", "labels": [], "entities": []}, {"text": "Because a large, complete knowledge base may not always be available, we further test our model under conditions in which there is incomplete ontological knowledge about an entity, and we analyze the relative contributions of the distributional and ontological components of our model.", "labels": [], "entities": []}, {"text": "Finally, to illustrate how our approach can take advantage of insights from classical approaches to semantics, we develop a method to extract semantic relations between concepts from the output predictions of our model without further training using fuzzy set logic operations.", "labels": [], "entities": []}, {"text": "These results argue for the importance of learning concept extensions not just to develop a better model of entities, but also as a potential method to better integrate distributional semantics with formal, compositional approaches to semantics.", "labels": [], "entities": []}], "datasetContent": [{"text": "Our experiments were conducted on the collaborative knowledge base, Freebase.", "labels": [], "entities": [{"text": "Freebase", "start_pos": 68, "end_pos": 76, "type": "DATASET", "confidence": 0.9257485866546631}]}, {"text": "We extracted three classes of entities from the June 9, 2014 dump of Freebase by taking instances of top-level concepts (i.e., Freebase types) corresponding to People, Organizations, and Locations, as shown in.", "labels": [], "entities": [{"text": "June 9, 2014 dump of Freebase", "start_pos": 48, "end_pos": 77, "type": "DATASET", "confidence": 0.7568276865141732}]}, {"text": "We chose these classes because they are the entity classes most often modelled by other work in NLP, such as by NER taggers ().", "labels": [], "entities": [{"text": "NER taggers", "start_pos": 112, "end_pos": 123, "type": "TASK", "confidence": 0.6109226942062378}]}, {"text": "These classes also tend to be apart of many different scenarios, thus there should be rich ontological structures to learn.", "labels": [], "entities": []}, {"text": "In addition to the entities, we extracted all of the concepts that these entities are tagged with, in order to construct the ontological vector component of our model.", "labels": [], "entities": []}, {"text": "We then filtered the entities and concepts according to several frequency and quality criteria.", "labels": [], "entities": []}, {"text": "For entities, we required the following characteristics: (1) there must be a word2vec vector available for that entity, as determined by a string match to the entity's name or one of its aliases; (2) the entity must belong to a minimum of five concepts; (3) the entity must satisfy a minimum frequency threshold, as follows.", "labels": [], "entities": []}, {"text": "We estimate the frequency of an entity by taking the frequency of the name of the entity in the Gigaword corpus.", "labels": [], "entities": [{"text": "Gigaword corpus", "start_pos": 96, "end_pos": 111, "type": "DATASET", "confidence": 0.9546336531639099}]}, {"text": "Where the name consists of multiple words, the minimum of these is taken.", "labels": [], "entities": []}, {"text": "We used a frequency threshold of 150, which is actually quite low given the size of the Gigaword corpus.", "labels": [], "entities": [{"text": "Gigaword corpus", "start_pos": 88, "end_pos": 103, "type": "DATASET", "confidence": 0.9644477665424347}]}, {"text": "We chose to filter on frequency so that the distributional component would have seen the entity often enough to learn something useful about it.", "labels": [], "entities": []}, {"text": "Of the roughly one million entities in Freebase in these three categories, 84,286 entities passed the above filters.", "labels": [], "entities": [{"text": "Freebase", "start_pos": 39, "end_pos": 47, "type": "DATASET", "confidence": 0.9605156779289246}]}, {"text": "For the concepts, we required the following characteristics: (1) the concept must contain a minimum often entity instances; (2) the concept must not be a /user or /m type.", "labels": [], "entities": []}, {"text": "The second criterion removes many concepts that are overly specific and only of interest to a particular user, containing for example lists of landmarks that a user would like to visit.", "labels": [], "entities": []}, {"text": "In addition, we removed the concept used to construct an entity category, and the concept /common/topic, because all of the entities in an entity class would be instances of these concepts.", "labels": [], "entities": []}, {"text": "1,262 concepts of the original 5,024 were retained after filtering.", "labels": [], "entities": []}, {"text": "Following filtering, the remaining entities are randomly assigned to training, development, and test sets in a 60%-20%-20% split.", "labels": [], "entities": []}, {"text": "provides a summary of several statistics about the data sets that we extracted.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Basic statistics concerning the subsets of Freebase that we extracted for our experiments. Free- base ID refers to the top-level concept used to define the entity classes that we extract. N represents the  count of unique entities or concepts.", "labels": [], "entities": []}, {"text": " Table 2: Entity ranking results by input feature set  in terms of the mean average precision measure  (%). All differences are statistically significant by  a randomized bootstrap test at p < 0.0001.", "labels": [], "entities": [{"text": "Entity ranking", "start_pos": 10, "end_pos": 24, "type": "TASK", "confidence": 0.8629417419433594}, {"text": "mean average precision measure", "start_pos": 71, "end_pos": 101, "type": "METRIC", "confidence": 0.6929488182067871}]}, {"text": " Table 3: Entity ranking results in the partial on- tological information experiment, by MAP (%).", "labels": [], "entities": [{"text": "MAP", "start_pos": 89, "end_pos": 92, "type": "METRIC", "confidence": 0.9985709190368652}]}, {"text": " Table 4: Average maximum Jaccard similarity for  the top 50 concepts in each entity class", "labels": [], "entities": [{"text": "Jaccard similarity", "start_pos": 26, "end_pos": 44, "type": "METRIC", "confidence": 0.8062510788440704}]}]}