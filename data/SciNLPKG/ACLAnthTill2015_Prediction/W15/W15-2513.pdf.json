{"title": [{"text": "Pronoun Translation and Prediction with or without Coreference Links", "labels": [], "entities": [{"text": "Pronoun Translation", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.8292086720466614}]}], "abstractContent": [{"text": "The Idiap NLP Group has participated in both DiscoMT 2015 sub-tasks: pronoun-focused translation and pronoun prediction.", "labels": [], "entities": [{"text": "Idiap NLP Group", "start_pos": 4, "end_pos": 19, "type": "DATASET", "confidence": 0.8776591817537943}, {"text": "DiscoMT 2015", "start_pos": 45, "end_pos": 57, "type": "TASK", "confidence": 0.6650340855121613}, {"text": "pronoun-focused translation", "start_pos": 69, "end_pos": 96, "type": "TASK", "confidence": 0.7327700853347778}, {"text": "pronoun prediction", "start_pos": 101, "end_pos": 119, "type": "TASK", "confidence": 0.8333565592765808}]}, {"text": "The system for the first sub-task combines two knowledge sources: grammatical constraints from the hypothesized coreference links, and candidate translations from an SMT decoder.", "labels": [], "entities": []}, {"text": "The system for the second sub-task avoids hypothesizing a coreference link, and uses instead a large set of source-side and target-side features from the noun phrases surrounding the pronoun to train a pronoun predictor.", "labels": [], "entities": []}], "introductionContent": [{"text": "The NLP Group of the Idiap Research Institute participated in both sub-tasks of the DiscoMT 2015 Shared Task: pronoun-focused translation and pronoun prediction.", "labels": [], "entities": [{"text": "Idiap Research Institute", "start_pos": 21, "end_pos": 45, "type": "DATASET", "confidence": 0.9187191327412924}, {"text": "DiscoMT 2015 Shared Task", "start_pos": 84, "end_pos": 108, "type": "TASK", "confidence": 0.5612383708357811}, {"text": "pronoun-focused translation", "start_pos": 110, "end_pos": 137, "type": "TASK", "confidence": 0.6912479102611542}, {"text": "pronoun prediction", "start_pos": 142, "end_pos": 160, "type": "TASK", "confidence": 0.8050873875617981}]}, {"text": "The first task aimed at evaluating the quality of pronoun translation in the output of a full-fledged machine translation (MT) system, while the second task aimed at restoring hidden pronouns in a high-quality reference translation.", "labels": [], "entities": [{"text": "pronoun translation", "start_pos": 50, "end_pos": 69, "type": "TASK", "confidence": 0.7565709352493286}, {"text": "machine translation (MT)", "start_pos": 102, "end_pos": 126, "type": "TASK", "confidence": 0.8396045446395874}]}, {"text": "In our view, both sub-tasks raise the same question: given the limitations of current anaphora resolution systems, to what extent is it possible to correctly translate pronouns with unreliable knowledge of their antecedents?", "labels": [], "entities": [{"text": "anaphora resolution", "start_pos": 86, "end_pos": 105, "type": "TASK", "confidence": 0.8045880794525146}]}, {"text": "Although the answer depends on the translation divergencies from the source language to the target one, we explore here two different approaches to answer this question, within the DiscoMT 2015 Shared Task: one using imperfect knowledge of the antecedents of pronouns, and the other one replacing it with a large set of morphological features.", "labels": [], "entities": [{"text": "DiscoMT 2015 Shared Task", "start_pos": 181, "end_pos": 205, "type": "DATASET", "confidence": 0.8992556482553482}]}, {"text": "The SMT system we submitted to the pronounfocused translation sub-task (Section 3) combines * Work performed while at the Idiap Research Institute.", "labels": [], "entities": [{"text": "SMT", "start_pos": 4, "end_pos": 7, "type": "TASK", "confidence": 0.9877168536186218}, {"text": "pronounfocused translation", "start_pos": 35, "end_pos": 61, "type": "TASK", "confidence": 0.6657605767250061}, {"text": "Idiap Research Institute", "start_pos": 122, "end_pos": 146, "type": "DATASET", "confidence": 0.9289023081461588}]}, {"text": "two probabilistic knowledge sources to decide the translation of the English pronouns it and they into French, namely a probability distribution obtained from an anaphora resolution system and one obtained from the SMT decoder.", "labels": [], "entities": []}, {"text": "The classifier for the pronoun prediction sub-task (Section 4), uses morphological and positional features of sourceside and target-side noun phrases surrounding the pronoun to be restored, without any hypothesis on its antecedents.", "labels": [], "entities": [{"text": "pronoun prediction", "start_pos": 23, "end_pos": 41, "type": "TASK", "confidence": 0.7179408073425293}]}, {"text": "System configurations are shown in Section 5, and results in Section 6.", "labels": [], "entities": []}], "datasetContent": [{"text": "The challenge in this task is to build classifiers to predict the hidden pronouns in translations, knowing the source.", "labels": [], "entities": []}, {"text": "Four data sets of different domains were provided for development: Europarl, News Commentary (NCv9), IWSLT 2014 and TED(dev) talks.", "labels": [], "entities": [{"text": "Europarl", "start_pos": 67, "end_pos": 75, "type": "DATASET", "confidence": 0.9840741157531738}, {"text": "News Commentary (NCv9)", "start_pos": 77, "end_pos": 99, "type": "DATASET", "confidence": 0.8143526554107666}, {"text": "IWSLT 2014", "start_pos": 101, "end_pos": 111, "type": "DATASET", "confidence": 0.6942198276519775}]}, {"text": "Each data set includes a series of five-element tuples: source sentence, target sentence (with pronouns substituted by placeholders), alignment information, actual pronouns and gold-standard ones (last two not given in the test data).", "labels": [], "entities": []}, {"text": "We first extract features for all occurrences of \"it\" and \"they\", and then train classifiers over the feature set with various machine learning methods.", "labels": [], "entities": []}, {"text": "In fact, to ensure an acceptable training time, we exploit entirely only the smaller data sets, and partially the larger ones: we use for constructing predictors all the occurrences of \"it\" and \"they\" of TED(dev), 10% of those of NCv9, 10% of those of IWSLT and about 1% of those of Europarl.", "labels": [], "entities": [{"text": "NCv9", "start_pos": 230, "end_pos": 234, "type": "DATASET", "confidence": 0.9699759483337402}, {"text": "IWSLT", "start_pos": 252, "end_pos": 257, "type": "DATASET", "confidence": 0.9025688767433167}, {"text": "Europarl", "start_pos": 283, "end_pos": 291, "type": "DATASET", "confidence": 0.994205892086029}]}, {"text": "The sizes, total numbers of \"it\" and \"they\" occurrences, and the actual number exploited are shown in.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Size, number of occurrences of \"it\" and  \"they\", and instances actually used for training.", "labels": [], "entities": []}, {"text": " Table 2: Cross-validation results (macro-averaged  F-scores) over 4 data sets and 4 types of classifiers.", "labels": [], "entities": [{"text": "F-scores", "start_pos": 52, "end_pos": 60, "type": "METRIC", "confidence": 0.901369035243988}]}]}