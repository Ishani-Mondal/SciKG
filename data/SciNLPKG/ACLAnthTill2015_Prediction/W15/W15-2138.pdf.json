{"title": [{"text": "Exploring Confidence-based Self-training for Multilingual Dependency Parsing in an Under-Resourced Language Scenario", "labels": [], "entities": [{"text": "Multilingual Dependency Parsing", "start_pos": 45, "end_pos": 76, "type": "TASK", "confidence": 0.6246841549873352}]}], "abstractContent": [{"text": "This paper presents a novel self-training approach that we use to explore a scenario which is typical for under-resourced languages.", "labels": [], "entities": []}, {"text": "We apply self-training on small multilingual dependency corpora of nine languages.", "labels": [], "entities": []}, {"text": "Our approach employs a confidence-based method to gain additional training data from large unlabeled datasets.", "labels": [], "entities": []}, {"text": "The method has been shown effective for five languages out of the nine languages of the SPMRL Shared Task 2014 datasets.", "labels": [], "entities": [{"text": "SPMRL Shared Task 2014 datasets", "start_pos": 88, "end_pos": 119, "type": "DATASET", "confidence": 0.6460238873958588}]}, {"text": "We obtained the largest absolute improvement of two percentage points on Korean data.", "labels": [], "entities": [{"text": "Korean data", "start_pos": 73, "end_pos": 84, "type": "DATASET", "confidence": 0.9042068123817444}]}, {"text": "Our self-training experiments show improvements upon the best state-of-the-art systems of the SPMRL shared task that employs one parser only.", "labels": [], "entities": [{"text": "SPMRL shared task", "start_pos": 94, "end_pos": 111, "type": "TASK", "confidence": 0.8916091521581014}]}], "introductionContent": [{"text": "The availability of the manually annotated treebanks and state-of-the-art dependency parsers) leads to high accuracy on some languages such as English,) and Chinese () that have large manually annotated datasets.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 108, "end_pos": 116, "type": "METRIC", "confidence": 0.998782217502594}]}, {"text": "In contrast to resource-rich languages, languages that have less training data show a lower accuracy ().", "labels": [], "entities": [{"text": "accuracy", "start_pos": 92, "end_pos": 100, "type": "METRIC", "confidence": 0.9992666840553284}]}, {"text": "Semi-supervised techniques gain popularity as they are able to improve parsing accuracy by exploiting unlabeled data which avoids the cost of labeling new data.", "labels": [], "entities": [{"text": "parsing", "start_pos": 71, "end_pos": 78, "type": "TASK", "confidence": 0.9807224869728088}, {"text": "accuracy", "start_pos": 79, "end_pos": 87, "type": "METRIC", "confidence": 0.8374111652374268}]}, {"text": "Self-training is one of these appealing techniques that have been successfully used for instance in constituency parsing for English texts while for dependency parsing this approach was only effective in a few cases, in contrast to co-training which works for dependency parsing well too.", "labels": [], "entities": [{"text": "constituency parsing for English texts", "start_pos": 100, "end_pos": 138, "type": "TASK", "confidence": 0.8948580622673035}, {"text": "dependency parsing", "start_pos": 149, "end_pos": 167, "type": "TASK", "confidence": 0.8494669198989868}, {"text": "dependency parsing", "start_pos": 260, "end_pos": 278, "type": "TASK", "confidence": 0.7722140252590179}]}, {"text": "Ina co-training approach, at least another parser is employed to label additional training data.", "labels": [], "entities": []}, {"text": "used self-training for English constituency parsing.", "labels": [], "entities": [{"text": "English constituency parsing", "start_pos": 23, "end_pos": 51, "type": "TASK", "confidence": 0.6536329587300619}]}, {"text": "In their approaches, self-training was most effective when the parser is retrained on the combination of the initial training set and the large unlabeled dataset generated by both the generative parser and reranker.", "labels": [], "entities": []}, {"text": "This leads to many subsequent applications on English texts via self-training for constituency parsing, cf. (. In contrast to English constituency parsing, selftraining usually has proved to be less effective or has even shown negative results when applied to dependency parsing, cf. ().", "labels": [], "entities": [{"text": "constituency parsing", "start_pos": 82, "end_pos": 102, "type": "TASK", "confidence": 0.8920537531375885}, {"text": "constituency parsing", "start_pos": 134, "end_pos": 154, "type": "TASK", "confidence": 0.6641745120286942}, {"text": "dependency parsing", "start_pos": 260, "end_pos": 278, "type": "TASK", "confidence": 0.8409233391284943}]}, {"text": "This paper makes the following contributions: 1.", "labels": [], "entities": []}, {"text": "We present an effective confidence-based self-training approach.", "labels": [], "entities": []}, {"text": "2. We evaluate our approach on nine languages in a resource-poor parsing scenario.", "labels": [], "entities": []}, {"text": "3. We successfully improved the parsing performances on five languages which are Basque, German, Hungarian, Korean and Swedish.", "labels": [], "entities": [{"text": "parsing", "start_pos": 32, "end_pos": 39, "type": "TASK", "confidence": 0.974075973033905}]}, {"text": "The remainder of this paper is structured as follows: In Section 2, we discuss related work.", "labels": [], "entities": []}, {"text": "In Section 3, we introduce our confidence-based approach to self-training and Section 4 describes the experimental set-up.", "labels": [], "entities": []}, {"text": "Section 5 presents the results and contains a discussion of the results.", "labels": [], "entities": []}, {"text": "Section 6 presents our conclusions.", "labels": [], "entities": []}], "datasetContent": [{"text": "We evaluate our approach on nine languages available from 2014 Shared Task at the Workshop on Statistical Parsing of Morphologically Rich Languages (SPMRL), cf. ().", "labels": [], "entities": [{"text": "Statistical Parsing of Morphologically Rich Languages (SPMRL)", "start_pos": 94, "end_pos": 155, "type": "TASK", "confidence": 0.8555449313587613}]}, {"text": "We have chosen the datasets as they provide smaller data sets of 5k sentences for each language of the SPMRL shared task which area good basis for our exploration for improving parsing accuracy of under-resourced languages and the shared task provides competitive results for these languages from the participants of the shared task that provides us strong accuracy scores against which we can compare our results.", "labels": [], "entities": [{"text": "SPMRL shared task", "start_pos": 103, "end_pos": 120, "type": "TASK", "confidence": 0.7567726373672485}, {"text": "parsing", "start_pos": 177, "end_pos": 184, "type": "TASK", "confidence": 0.966873288154602}, {"text": "accuracy", "start_pos": 185, "end_pos": 193, "type": "METRIC", "confidence": 0.6932789087295532}, {"text": "accuracy", "start_pos": 357, "end_pos": 365, "type": "METRIC", "confidence": 0.9976089000701904}]}, {"text": "Further, the organizers of the SPMRL shared task provided sufficient unlabeled data that are required for self-training.", "labels": [], "entities": [{"text": "SPMRL shared task", "start_pos": 31, "end_pos": 48, "type": "TASK", "confidence": 0.8712824781735738}]}, {"text": "More precisely, for all language, we use as our initial training set the 5k datasets, we test on test sets available from the shared task and use a 100k SPMRL unlabeled data for each of the languages.", "labels": [], "entities": []}, {"text": "We use the German development set (5,000 sentences) when tuning the fixed value d that was mentioned in Section 3.", "labels": [], "entities": [{"text": "German development set", "start_pos": 11, "end_pos": 33, "type": "DATASET", "confidence": 0.7590754628181458}]}, {"text": "Table 1 shows statistics about the corpora that we use in our experiments.", "labels": [], "entities": []}, {"text": "As previously noted, the Mate transition-based dependency parser with default settings is used in our experiments, cf..", "labels": [], "entities": [{"text": "Mate transition-based dependency parser", "start_pos": 25, "end_pos": 64, "type": "TASK", "confidence": 0.6830384880304337}]}, {"text": "We use the parser's internal tagger to supply the part-ofspeech for both unlabeled data and test data.", "labels": [], "entities": []}, {"text": "The baselines are generated by training the parser on initial training data and testing the parser on the described test sets.", "labels": [], "entities": []}, {"text": "For the evaluation of the parser's accuracy, we report labeled attachment scores (LAS).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 35, "end_pos": 43, "type": "METRIC", "confidence": 0.9985975623130798}, {"text": "labeled attachment scores (LAS)", "start_pos": 55, "end_pos": 86, "type": "METRIC", "confidence": 0.8388485213120779}]}, {"text": "In line with the SPMRL shared task evaluation, we include all punctuation marks in the evaluation.", "labels": [], "entities": [{"text": "SPMRL shared task evaluation", "start_pos": 17, "end_pos": 45, "type": "TASK", "confidence": 0.7309876978397369}]}, {"text": "For significance testing, we take Dan Bikel's randomized parsing evaluation comparator that was used by the CoNLL 2007 shared task with the default settings of 10,000 iterations ().", "labels": [], "entities": [{"text": "significance testing", "start_pos": 4, "end_pos": 24, "type": "TASK", "confidence": 0.9417205154895782}, {"text": "CoNLL 2007 shared task", "start_pos": 108, "end_pos": 130, "type": "DATASET", "confidence": 0.8509338051080704}]}, {"text": "The statistically significant results are marked due to their p-values (*) p-value<0.05, (**) p-value<0.01.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Statistics about the corpora that we used in our experiments for the training set, test set and the  unlabeled datasets for our multilingual evaluations, cf. (Seddah et al., 2014).", "labels": [], "entities": []}, {"text": " Table 2: The table shows the results obtained for the languages of the SPMRL Shared Task 2014. The  first column (Baseline)", "labels": [], "entities": [{"text": "SPMRL Shared Task 2014", "start_pos": 72, "end_pos": 94, "type": "TASK", "confidence": 0.7432238012552261}]}]}