{"title": [{"text": "Can Translation Memories afford not to use paraphrasing?", "labels": [], "entities": [{"text": "Translation Memories", "start_pos": 4, "end_pos": 24, "type": "TASK", "confidence": 0.9737858772277832}]}], "abstractContent": [{"text": "This paper investigates to what extent the use of paraphrasing in translation memory (TM) matching and retrieval is useful for human translators.", "labels": [], "entities": [{"text": "translation memory (TM) matching and retrieval", "start_pos": 66, "end_pos": 112, "type": "TASK", "confidence": 0.7833962552249432}]}, {"text": "Current translation memories lack semantic knowledge like paraphrasing in matching and retrieval.", "labels": [], "entities": []}, {"text": "Due to this, paraphrased segments are often not retrieved.", "labels": [], "entities": []}, {"text": "Lack of semantic knowledge also results in inappropriate ranking of the retrieved segments.", "labels": [], "entities": []}, {"text": "Gupta and Or\u02d8 asan (2014) proposed an improved matching algorithm which incorporates paraphrasing.", "labels": [], "entities": []}, {"text": "Its automatic evaluation suggested that it could be beneficial to translators.", "labels": [], "entities": [{"text": "translators", "start_pos": 66, "end_pos": 77, "type": "TASK", "confidence": 0.972754180431366}]}, {"text": "In this paper we perform an extensive human evaluation of the use of paraphrasing in the TM matching and retrieval process.", "labels": [], "entities": [{"text": "TM matching and retrieval process", "start_pos": 89, "end_pos": 122, "type": "TASK", "confidence": 0.8163423776626587}]}, {"text": "We measure post-editing time, keystrokes, two subjective evaluations , and HTER and HMETEOR to assess the impact on human performance.", "labels": [], "entities": [{"text": "HTER", "start_pos": 75, "end_pos": 79, "type": "METRIC", "confidence": 0.9942396879196167}, {"text": "HMETEOR", "start_pos": 84, "end_pos": 91, "type": "METRIC", "confidence": 0.9890901446342468}]}, {"text": "Our results show that paraphrasing improves TM matching and retrieval, resulting in translation performance increases when translators use paraphrase enhanced TMs.", "labels": [], "entities": [{"text": "TM matching", "start_pos": 44, "end_pos": 55, "type": "TASK", "confidence": 0.9629325866699219}]}], "introductionContent": [{"text": "One of the core features of a TM system is the retrieval of previously translated similar segments for post-editing in order to avoid translation from scratch when an exact match is not available.", "labels": [], "entities": [{"text": "TM", "start_pos": 30, "end_pos": 32, "type": "TASK", "confidence": 0.9684301614761353}]}, {"text": "However, this retrieval process is still limited to editdistance based measures operating on surface form (or sometimes stem) matching.", "labels": [], "entities": [{"text": "stem) matching", "start_pos": 120, "end_pos": 134, "type": "TASK", "confidence": 0.6736436486244202}]}, {"text": "Most of the commercial systems use edit distance or some variation of it, e.g. the open-source TM OmegaT 1 uses word-based edit distance with some extra preprocessing.", "labels": [], "entities": [{"text": "TM OmegaT 1", "start_pos": 95, "end_pos": 106, "type": "DATASET", "confidence": 0.6078862249851227}]}, {"text": "Although these measures provide a strong baseline, they are not sufficient to capture semantic similarity between the segments as judged by humans.", "labels": [], "entities": []}, {"text": "proposed an edit distance measure which incorporates paraphrasing in the process.", "labels": [], "entities": []}, {"text": "In the present paper, we perform a human-centred evaluation to investigate the use of paraphrasing in translation memory matching and retrieval.", "labels": [], "entities": [{"text": "translation memory matching", "start_pos": 102, "end_pos": 129, "type": "TASK", "confidence": 0.8839885195096334}]}, {"text": "We use the same system as Gupta and Or\u02d8 asan and investigate the following questions: (1) how much of an improvement can paraphrasing provide in terms of retrieval?", "labels": [], "entities": []}, {"text": "What is the quality of the retrieved segments and its impact on the work of human translators?", "labels": [], "entities": []}, {"text": "These questions are answered using human centred evaluations.", "labels": [], "entities": []}, {"text": "To the best of our knowledge, this paper presents the first work on assessing the quality of any type of semantically informed TM fuzzy matches based on post-editing time or keystrokes.", "labels": [], "entities": []}], "datasetContent": [{"text": "We have used the approach presented in Gupta and Or\u02d8 asan (2014) to include paraphrasing in the TM matching and retrieval process.", "labels": [], "entities": [{"text": "TM matching", "start_pos": 96, "end_pos": 107, "type": "TASK", "confidence": 0.9716736376285553}]}, {"text": "The approach classifies paraphrases into different types for efficient implementation based on the matching of the words between the source and corresponding paraphrase.", "labels": [], "entities": []}, {"text": "Using this approach, the fuzzy match score between segments can be calculated in polynomial time despite the inclusion of paraphrases.", "labels": [], "entities": []}, {"text": "The method uses dynamic programming along with greedy approximation.", "labels": [], "entities": []}, {"text": "The method calculates fuzzy match score as if the appropriate paraphrases are applied.", "labels": [], "entities": []}, {"text": "For example, if the translation memory used has a segment \"What is the actual aim of this practice ?\" and the paraphrase database has paraphrases \"the actual\" \u21d2 \"the real\" and \"aim of this\" \u21d2\"goal of this\", for the input sentence \"What is the real goal of this mission ?\", the approach will give a 89.89% fuzzy match score (only one word, \"practice\", needs substitution with \"mission\") rather than 66.66% using simple wordbased edit distance.", "labels": [], "entities": []}, {"text": "In TM, the performance of retrieval can be measured by counting the number of segments or words retrieved.", "labels": [], "entities": [{"text": "TM", "start_pos": 3, "end_pos": 5, "type": "TASK", "confidence": 0.9345609545707703}]}, {"text": "However, NLP techniques are not 100% accurate and most of the time, there is a tradeoff between the precision and recall of this retrieval process.", "labels": [], "entities": [{"text": "precision", "start_pos": 100, "end_pos": 109, "type": "METRIC", "confidence": 0.9995803236961365}, {"text": "recall", "start_pos": 114, "end_pos": 120, "type": "METRIC", "confidence": 0.9979918003082275}]}, {"text": "This is also one of the reasons that TM developers shy away from using semantic matching.", "labels": [], "entities": [{"text": "semantic matching", "start_pos": 71, "end_pos": 88, "type": "TASK", "confidence": 0.7339296936988831}]}, {"text": "One cannot measure the gain unless retrieval benefits the translator.", "labels": [], "entities": []}, {"text": "When we use paraphrasing in the matching and retrieval process, the fuzzy match score of a paraphrased segment is increased, which results in the retrieval of more segments at a particular threshold.", "labels": [], "entities": []}, {"text": "This increment in retrieval can be classified in two types: without changing the top rank; and by changing the top rank.", "labels": [], "entities": []}, {"text": "For example, fora particular input segment, we have two segments A and B in the TM.", "labels": [], "entities": []}, {"text": "Using simple edit-distance, A has a 65% and B has a 60% fuzzy score; the fuzzy score of A is better than that of B.", "labels": [], "entities": []}, {"text": "As a result of using paraphrasing we notice two types of score changes: 1.", "labels": [], "entities": []}, {"text": "the score of A is still better than or equal to that of B, for example, A has 85% and B has 70% fuzzy score; 2.", "labels": [], "entities": []}, {"text": "the score of A is less than that of B, for example, A has 75% and B has 80% fuzzy score.", "labels": [], "entities": []}, {"text": "In the first case, paraphrasing does not supersede the existing model and just facilitates it by improving the fuzzy score so that the top segment ranked using edit distance gets retrieved.", "labels": [], "entities": []}, {"text": "However, in the second case paraphrasing changes the ranking and now the top ranked segment is different.", "labels": [], "entities": []}, {"text": "In this case, the paraphrasing model supersedes the existing simple edit distance model.", "labels": [], "entities": []}, {"text": "This second case also gives a different reference to compare with.", "labels": [], "entities": []}, {"text": "We take the top segment retrieved using simple edit distance as a reference against the top segment retrieved using paraphrasing and compare to see which is better fora human translator to work with.", "labels": [], "entities": []}, {"text": "To evaluate the influence of paraphrasing on matching and retrieval, we have carried out four different experiments.", "labels": [], "entities": [{"text": "matching and retrieval", "start_pos": 45, "end_pos": 67, "type": "TASK", "confidence": 0.585004061460495}]}, {"text": "Section 3.1 describes the settings and measures used for post-editing evaluation, and Sections 3.2 and 3.3 describe the settings for the subjective evaluations.", "labels": [], "entities": []}, {"text": "In this evaluation, we carried out subjective evaluation with two options (SE2).", "labels": [], "entities": [{"text": "SE2", "start_pos": 75, "end_pos": 78, "type": "METRIC", "confidence": 0.9742189645767212}]}, {"text": "We presented fuzzy matches retrieved using both paraphrasing (PP) and simple edit distance (ED) to the translators.", "labels": [], "entities": [{"text": "simple edit distance (ED)", "start_pos": 70, "end_pos": 95, "type": "METRIC", "confidence": 0.8965745468934377}]}, {"text": "The translators were unaware of the details (ED or PP) of how the fuzzy matches were obtained.", "labels": [], "entities": [{"text": "ED or PP)", "start_pos": 45, "end_pos": 54, "type": "METRIC", "confidence": 0.8483091592788696}]}, {"text": "To neutralise any bias, half of the ED matches were tagged as A and the other half as B, with the same applied to PP matches.", "labels": [], "entities": []}, {"text": "The translator has to choose between two options: A is better; or B is better.", "labels": [], "entities": []}, {"text": "17 translators participated in this experiment.", "labels": [], "entities": []}, {"text": "Finally, the decision of whether 'ED is better' or 'PP is better' is made on the basis of how many translators choose one over the other.", "labels": [], "entities": [{"text": "ED", "start_pos": 34, "end_pos": 36, "type": "METRIC", "confidence": 0.9418178796768188}]}, {"text": "This evaluation is similar to Evaluation SE2 except that we provided one more option to translators.", "labels": [], "entities": []}, {"text": "Translators can choose among three options: A is better; B is better; or both are equal.", "labels": [], "entities": []}, {"text": "7 translators participated in this experiment.", "labels": [], "entities": []}, {"text": "The subjective evaluations also show significant improvements.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 3: Test Sets for Human Experiments", "labels": [], "entities": []}, {"text": " Table 4: Results of Human Evaluation on Set1 (1-14) and Set2 (15-30)", "labels": [], "entities": []}, {"text": " Table 5: Results using human targeted references", "labels": [], "entities": []}]}