{"title": [{"text": "Miscommunication Recovery in Physically Situated Dialogue", "labels": [], "entities": [{"text": "Miscommunication Recovery in Physically Situated Dialogue", "start_pos": 0, "end_pos": 57, "type": "TASK", "confidence": 0.7579994350671768}]}], "abstractContent": [{"text": "We describe an empirical study that crowdsourced human-authored recovery strategies for various problems encountered in physically situated dialogue.", "labels": [], "entities": [{"text": "crowdsourced human-authored recovery", "start_pos": 36, "end_pos": 72, "type": "TASK", "confidence": 0.6812185148398081}]}, {"text": "The purpose was to investigate the strategies that people use in response to requests that are referentially ambiguous or impossible to execute.", "labels": [], "entities": []}, {"text": "Results suggest a general preference for including specific kinds of visual information when disambiguat-ing referents, and for volunteering alternative plans when the original instruction was not possible to carryout.", "labels": [], "entities": []}], "introductionContent": [{"text": "Physically situated dialogue differs from traditional human-computer dialogue in that interactions will make use of reference to a dialogue agent's surroundings.", "labels": [], "entities": []}, {"text": "Tasks may fail due to dependencies on specific environment configurations, such as when a robot's path to a goal is blocked.", "labels": [], "entities": []}, {"text": "People will often help; in navigation dialogues they tend to ask proactive, task-related questions instead of simply signaling communication failure ().", "labels": [], "entities": [{"text": "navigation dialogues", "start_pos": 27, "end_pos": 47, "type": "TASK", "confidence": 0.944260835647583}]}, {"text": "They supplement the agent's representation of the environment and allow it to complete tasks.", "labels": [], "entities": []}, {"text": "The current study establishes an empirical basis for grounding in physically situated contexts.", "labels": [], "entities": []}, {"text": "We had people provide recovery strategies fora robot in various situations.", "labels": [], "entities": []}, {"text": "The focus of this work is on recovery from situated grounding problems, a type of miscommunication that occurs when an agent fails to uniquely map a person's instructions to its surroundings.", "labels": [], "entities": [{"text": "recovery from situated grounding problems, a type of miscommunication that occurs when an agent fails to uniquely map a person's instructions to its surroundings", "start_pos": 29, "end_pos": 190, "type": "Description", "confidence": 0.8357484684540675}]}, {"text": "A referential ambiguity is where an instruction resolves to more than one possibility (e.g., \"Search the room on the left\" when there are multiple rooms on the agent's left); an impossible-to-execute problem fails to resolve to any action (e.g., same instruction but there are no rooms on the agent's left).", "labels": [], "entities": []}, {"text": "A common strategy evidenced in human-human corpora is for people to ask questions to recover from situated grounding problems (.", "labels": [], "entities": []}, {"text": "Dialogue divides into two levels: that of managing the actual dialogue-determining who has the floor, that an utterance was recognized, etc.-and the dialogue that serves the main joint activities that dialogue partners are carrying out, like a human-robot team exploring anew area.", "labels": [], "entities": []}, {"text": "Most approaches to grounding in dialogue systems are managing the dialogue itself, making use of spoken language input as an indicator of understanding (e.g.,).", "labels": [], "entities": []}, {"text": "Situated grounding problems are associated with the main joint activities; to resolve them we believe that the recovery model must be extended to include planning and environment information.", "labels": [], "entities": []}, {"text": "Flexible recovery strategies make this possible by enabling dialogue partners to coordinate their joint activities and accomplish tasks.", "labels": [], "entities": []}, {"text": "We cast the problem space as one where the agent aims to select the most efficient recovery strategy that would resolve a user's intended referent.", "labels": [], "entities": []}, {"text": "We expect that this efficiency is tied to the cognitive load it takes to produce clarifications.", "labels": [], "entities": []}, {"text": "suggest a similar prediction in their study comparing human and automatically generated referring expressions of objects and their properties.", "labels": [], "entities": []}, {"text": "We sought to answer the following questions in this work: \u2022 How good are people at detecting situated grounding problems?", "labels": [], "entities": [{"text": "detecting situated grounding", "start_pos": 83, "end_pos": 111, "type": "TASK", "confidence": 0.8446368972460429}]}, {"text": "\u2022 How do people organize recovery strategies?", "labels": [], "entities": [{"text": "organize recovery", "start_pos": 16, "end_pos": 33, "type": "TASK", "confidence": 0.7506904602050781}]}, {"text": "\u2022 When resolving ambiguity, which properties do people use to differentiate referents?", "labels": [], "entities": []}, {"text": "\u2022 When resolving impossible-to-execute instructions, do people use active or passive ways to get the conversation back on track?", "labels": [], "entities": []}, {"text": "We determined the most common recovery strategies for referential ambiguity and impossible-toexecute problems.", "labels": [], "entities": [{"text": "referential ambiguity", "start_pos": 54, "end_pos": 75, "type": "TASK", "confidence": 0.8804634511470795}]}, {"text": "Several patterns emerged that suggest ways that people expect agents to recover.", "labels": [], "entities": []}, {"text": "Ultimately we intend for dialogue systems to use such strategies in physically situated contexts.", "labels": [], "entities": []}], "datasetContent": [{"text": "After instructions and a practice trial, participants viewed scenes in one of 10 different environments (see).", "labels": [], "entities": []}, {"text": "They would first watch a flyover video of the robot's environment, then view a screen showing labels for all possible referable objects in the scene.", "labels": [], "entities": []}, {"text": "The participant would then watch the robot enter the first scene.", "labels": [], "entities": []}, {"text": "The practice trial and instructions did not provide any examples of questions.", "labels": [], "entities": []}, {"text": "The robot would stop and a spoken instruction from the operator would be heard.", "labels": [], "entities": []}, {"text": "The participant was free to replay the instruction multiple times.", "labels": [], "entities": []}, {"text": "They would then enter a response (say an acknowledgment or a question).", "labels": [], "entities": []}, {"text": "Upon completion of the trial, the robot would move to a different scene, where the process was repeated.", "labels": [], "entities": []}, {"text": "Only self-contained questions that would allow the operator to answer without follow-up were allowed.", "labels": [], "entities": []}, {"text": "Thus generic questions like \"which one?\" would not allow the operator to give the robot enough useful information to proceed.", "labels": [], "entities": []}, {"text": "In the instructions, we suggested that participants include some detail about the environment in their ques- tions.", "labels": [], "entities": []}, {"text": "Participants used a web form 1 to view situations and provide responses.", "labels": [], "entities": []}, {"text": "We recorded demographic information (gender, age, native language, native country) and time on task.", "labels": [], "entities": []}, {"text": "The instructions had several attention checks to ensure that participants were focusing on the task.", "labels": [], "entities": [{"text": "attention checks", "start_pos": 29, "end_pos": 45, "type": "METRIC", "confidence": 0.9781060516834259}]}, {"text": "We created fifty trials across ten environments.", "labels": [], "entities": []}, {"text": "Each environment had five trials that represented waypoints the robot was to reach.", "labels": [], "entities": []}, {"text": "Participants viewed five different environments (totaling twenty-five trials).", "labels": [], "entities": []}, {"text": "Each command from the remote operator to the robot was a route instruction in the robot navigation domain.", "labels": [], "entities": [{"text": "robot navigation domain", "start_pos": 82, "end_pos": 105, "type": "TASK", "confidence": 0.7748769521713257}]}, {"text": "Trials were assembled in two groups and participants were assigned randomly to one (see).", "labels": [], "entities": []}, {"text": "Trial order was randomized according to a Latin Square.", "labels": [], "entities": [{"text": "Latin Square", "start_pos": 42, "end_pos": 54, "type": "DATASET", "confidence": 0.9127700924873352}]}], "tableCaptions": [{"text": " Table 1: Distribution of stimulus types across the two trial  groups of participants (PARTIC). Trials either had referen- tial ambiguity (AMB), were impossible-to-execute (IMP), or  executable (EXE).", "labels": [], "entities": [{"text": "PARTIC", "start_pos": 87, "end_pos": 93, "type": "METRIC", "confidence": 0.9414141178131104}, {"text": "referen- tial ambiguity (AMB)", "start_pos": 114, "end_pos": 143, "type": "METRIC", "confidence": 0.7748842239379883}]}, {"text": " Table 4: Projected belief annotations for the 175 correct de- tections of impossible-to-execute stimuli.", "labels": [], "entities": []}]}