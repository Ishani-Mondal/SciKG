{"title": [{"text": "Accessing Linked Open Data via A Common Ontology *", "labels": [], "entities": []}], "abstractContent": [{"text": "In the paper we present the construction of the FactForge service.", "labels": [], "entities": [{"text": "FactForge service", "start_pos": 48, "end_pos": 65, "type": "DATASET", "confidence": 0.9268077909946442}]}, {"text": "FactForge represents a reasonable view over several Linked Open Data (LOD) datasets including DBPedia, Freebase and Geonames.", "labels": [], "entities": [{"text": "FactForge", "start_pos": 0, "end_pos": 9, "type": "DATASET", "confidence": 0.8924495577812195}, {"text": "DBPedia", "start_pos": 94, "end_pos": 101, "type": "DATASET", "confidence": 0.6507765054702759}]}, {"text": "It enables users to easily identify resources in the LOD cloud by providing a general unified method for querying a group of datasets.", "labels": [], "entities": []}, {"text": "FactForge is designed also as a use case for large-scale reasoning and data integration.", "labels": [], "entities": [{"text": "FactForge", "start_pos": 0, "end_pos": 9, "type": "DATASET", "confidence": 0.8627702593803406}, {"text": "data integration", "start_pos": 71, "end_pos": 87, "type": "TASK", "confidence": 0.7329950928688049}]}, {"text": "We describe the datasets, ontologies, inference rules, and manipulations done over the data.", "labels": [], "entities": []}, {"text": "The datasets are unified via a common ontology-PROTON, whose concepts are mapped to the concepts of the involved LOD datasets.", "labels": [], "entities": [{"text": "LOD datasets", "start_pos": 113, "end_pos": 125, "type": "DATASET", "confidence": 0.769224613904953}]}, {"text": "Each of the mapping rules relates a PROTON class or a PROTON property to the corresponding class or property of the other ontologies.", "labels": [], "entities": []}, {"text": "This mechanism of constructing a reasonable view over selected LOD datasets ensures that the redundant instance representations are cleaned as much as possible.", "labels": [], "entities": [{"text": "LOD datasets", "start_pos": 63, "end_pos": 75, "type": "DATASET", "confidence": 0.7462671101093292}]}, {"text": "The instances are grouped in equivalent classes of instances.", "labels": [], "entities": []}], "introductionContent": [{"text": "Linked Open Data \uf020 (LOD)) facilitates the emergence of a web of linked data by publishing and interlinking open data on the web in RDF (.", "labels": [], "entities": []}, {"text": "The current datasets in LOD cover a wide spectrum of subject domains -biomedical, science, geographic, generic knowledge, entertainment, government (LOD Cloud 2011).", "labels": [], "entities": [{"text": "LOD Cloud 2011)", "start_pos": 149, "end_pos": 164, "type": "DATASET", "confidence": 0.9009538292884827}]}, {"text": "As they constantly grow, we face the problem of conveniently accessing, manipulating and further developing them.", "labels": [], "entities": []}, {"text": "It is believed that this large set of interconnected data will enable new classes of applications, making use of more sophisticated querying, knowledge discovery and reasoning.", "labels": [], "entities": [{"text": "knowledge discovery", "start_pos": 142, "end_pos": 161, "type": "TASK", "confidence": 0.7302766740322113}]}, {"text": "However, LOD is characterized by heterogeneity and inconsistency of the datasets, which makes their automated use via algorithms difficult.", "labels": [], "entities": []}, {"text": "A lot of research effort nowadays has been focused on \uf020 * The research reported here is done within Ontotext AD detecting methods to cope with and preserve the diversity of LOD, which can scale and manage their increasing growth rates.", "labels": [], "entities": [{"text": "Ontotext AD detecting", "start_pos": 100, "end_pos": 121, "type": "TASK", "confidence": 0.8050429224967957}]}, {"text": "These methods bring experimental results, which show that the state of the art is still far from the performance necessary for real life applications.", "labels": [], "entities": []}, {"text": "Highly heterogeneous contexts such as LOD and the Web need mechanisms to ensure consistency based on a set of data agreed upon or commonly acceptable, shared by various datasets, and make them interconnected.", "labels": [], "entities": []}, {"text": "In order to provide such a mechanism we use a reference layer, consisting of one or more ontologies with different degrees of generality built on top of LOD and interlinked with their schemata and instances.", "labels": [], "entities": []}, {"text": "This is a viable and optimal solution for handling LOD heterogeneity.", "labels": [], "entities": []}, {"text": "In the Semantic Web, the idea of having an integrated global ontology which extracts information from the local ontologies and provides a unified view through which users can query the local ontologies is unrealistic, since it is practically impossible to maintain this global ontology in a highly dynamic environment.", "labels": [], "entities": []}, {"text": "The idea of building reference structures at the schema level has been advocated previously ().", "labels": [], "entities": []}, {"text": "They state that it would be valuable to have a schema describing the subject domain of the datasets in LOD.", "labels": [], "entities": []}, {"text": "Besides the reference layer, we think that the actual datasets in LOD needs to be tuned to fit the reference layer.", "labels": [], "entities": []}, {"text": "Such a tuning includes: unification of modelling principles for the various datasets and cleaning the instance data that do not fit the conceptualization.", "labels": [], "entities": []}, {"text": "In the paper we present the preparation of datasets for one LOD service including these two components: a reference layer and cleaning of the involved datasets, based on the detected conceptual mismatches between the common ontology and conceptualization of each involved dataset.", "labels": [], "entities": []}, {"text": "LOD are valuable source of information of NLP like extraction of vobularies, names, features.", "labels": [], "entities": []}, {"text": "In this paper we do not discuss any concrete NLP task or application, but for each of them we need a reliable LOD dataset -the topic of the paper.", "labels": [], "entities": [{"text": "LOD dataset", "start_pos": 110, "end_pos": 121, "type": "DATASET", "confidence": 0.7477195262908936}]}, {"text": "The structure of the paper is as follows: Section 2 gives the background of our idea.", "labels": [], "entities": []}, {"text": "Section 3 focuses on the conctruction of FactForge.", "labels": [], "entities": [{"text": "FactForge", "start_pos": 41, "end_pos": 50, "type": "DATASET", "confidence": 0.8156301975250244}]}, {"text": "Section 4 concludes the paper.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section we present two of the most popular LOD datasets -DBPedia and Freebase with respect to discrepancies between their conceptualization and ontology in the reference layer.", "labels": [], "entities": [{"text": "LOD datasets", "start_pos": 51, "end_pos": 63, "type": "DATASET", "confidence": 0.7026428282260895}, {"text": "DBPedia", "start_pos": 65, "end_pos": 72, "type": "DATASET", "confidence": 0.5091812014579773}, {"text": "Freebase", "start_pos": 77, "end_pos": 85, "type": "DATASET", "confidence": 0.8840036988258362}]}, {"text": "The DBPedia dataset is created by extracting structured information from Wikipedia and presenting it in an RDF form (http://dbpedia.org/About).", "labels": [], "entities": [{"text": "DBPedia dataset", "start_pos": 4, "end_pos": 19, "type": "DATASET", "confidence": 0.9660714566707611}]}, {"text": "The conceptualization of the DBPedia dataset is based on the categories that are designed and implemented in Wikipedia, i.e. the data in the   The main difference is that in PROTON the class pext:Architect is defined as a profession and asocial function, in order for someone (or something) to have this profession.", "labels": [], "entities": [{"text": "DBPedia dataset", "start_pos": 29, "end_pos": 44, "type": "DATASET", "confidence": 0.921815812587738}]}, {"text": "This means that not only persons can perform it.", "labels": [], "entities": []}, {"text": "While in DBPedia the definition follows the logic that all architects described in Wikipedia are, in fact, persons.", "labels": [], "entities": [{"text": "DBPedia", "start_pos": 9, "end_pos": 16, "type": "DATASET", "confidence": 0.9494642615318298}]}, {"text": "It is relatively easy to overcome such conceptual differences by an appropriate mapping between the two ontologies: The difference is that in DBPedia, Sport is a specific activity and its characteristics such as game rules, number of participants, etc. are not defined in the class dbp-ont:Sport.", "labels": [], "entities": [{"text": "DBPedia", "start_pos": 142, "end_pos": 149, "type": "DATASET", "confidence": 0.933373212814331}]}, {"text": "In PROTON the characteristics of the sport game are defined in the class pext:Sport as asocial abstraction.", "labels": [], "entities": []}, {"text": "The actual realization of the definition as a sport event is an instance of activity.", "labels": [], "entities": []}, {"text": "Unfortunately, any mapping between the two ontologies cannot solve this conceptual difference.", "labels": [], "entities": []}, {"text": "The following mappings:  automatically make all instances of the class dbp-ont:Sport in PROTON to be simultaneously instances of the classes ptop:Happening and ptop:Abstract, which are mutually disjoint.", "labels": [], "entities": []}, {"text": "In FactForge such conceptualization differences between the two ontologies are solved by not loading the DBPedia ontology into the FactForge repository.", "labels": [], "entities": [{"text": "FactForge repository", "start_pos": 131, "end_pos": 151, "type": "DATASET", "confidence": 0.9349617063999176}]}, {"text": "In this way, we make use of the richness of the DBPedia instances but impose the conceptualization of PROTON ontology over it.", "labels": [], "entities": []}, {"text": "Another reason for not loading the DBPedia ontology is that the definitions in the DBPedia ontology also contain mappings to other ontologies.", "labels": [], "entities": [{"text": "DBPedia ontology", "start_pos": 35, "end_pos": 51, "type": "DATASET", "confidence": 0.9328123331069946}, {"text": "DBPedia ontology", "start_pos": 83, "end_pos": 99, "type": "DATASET", "confidence": 0.9524101912975311}]}, {"text": "However, we believe that including ontology statements referring to classes (properties, etc) of other ontologies is not a good practice.", "labels": [], "entities": []}, {"text": "First, presenting the necessary conceptualization requires importing the other ontology.", "labels": [], "entities": []}, {"text": "And second, this can introduce some contradictions in the ontology that uses these statements.", "labels": [], "entities": []}, {"text": "For example, the DBPedia ontology contains some statements from the Schema ontology (http://schema.org).", "labels": [], "entities": [{"text": "DBPedia ontology", "start_pos": 17, "end_pos": 33, "type": "DATASET", "confidence": 0.9337111413478851}]}, {"text": "However, because DBPedia is not an extension of the Schema ontology, therefore it is better to store these statements separately.", "labels": [], "entities": []}, {"text": "If they are included in the definitions of the DBPedia classes, this can lead to some contradictions as illustrated in the examples below for University and College: Using owl:equivalentClass makes these two classes -dbp-ont:University and dbpont:College -the same.", "labels": [], "entities": [{"text": "DBPedia classes", "start_pos": 47, "end_pos": 62, "type": "DATASET", "confidence": 0.9381240010261536}]}, {"text": "Such equivalent statements are difficult to be noticed in the DBPedia ontology as it is full of them but it is also not very easy to use DBPedia without such statements.", "labels": [], "entities": [{"text": "DBPedia ontology", "start_pos": 62, "end_pos": 78, "type": "DATASET", "confidence": 0.9323194622993469}, {"text": "DBPedia", "start_pos": 137, "end_pos": 144, "type": "DATASET", "confidence": 0.944904088973999}]}, {"text": "The instance data also contains statements that result from inferences from the DBPedia ontology.", "labels": [], "entities": [{"text": "DBPedia ontology", "start_pos": 80, "end_pos": 96, "type": "DATASET", "confidence": 0.9495725929737091}]}, {"text": "In order to avoid all conceptualizations that follow from the DBPedia ontology we have to clean the DBPedia instance data from such inferences.", "labels": [], "entities": [{"text": "DBPedia ontology", "start_pos": 62, "end_pos": 78, "type": "DATASET", "confidence": 0.9259705543518066}, {"text": "DBPedia instance data", "start_pos": 100, "end_pos": 121, "type": "DATASET", "confidence": 0.8934212923049927}]}, {"text": "Here are some examples: Subclass -Superclass inference.", "labels": [], "entities": []}, {"text": "In the DBPedia instance data, each instance of sport is classified as sport but also as an activity.", "labels": [], "entities": [{"text": "DBPedia instance data", "start_pos": 7, "end_pos": 28, "type": "DATASET", "confidence": 0.9403833349545797}]}, {"text": "Therefore, even if we do not load the DBPedia ontology into the FactForge repository, this inference is present in the instance data.", "labels": [], "entities": [{"text": "FactForge repository", "start_pos": 64, "end_pos": 84, "type": "DATASET", "confidence": 0.9503103196620941}]}, {"text": "Thus, the classification of the DBPedia sport instances will also be wrong in PROTON when mapping PROTON to DBPedia.", "labels": [], "entities": [{"text": "DBPedia sport instances", "start_pos": 32, "end_pos": 55, "type": "DATASET", "confidence": 0.9357289473215739}, {"text": "PROTON", "start_pos": 78, "end_pos": 84, "type": "DATASET", "confidence": 0.8279078006744385}, {"text": "DBPedia", "start_pos": 108, "end_pos": 115, "type": "DATASET", "confidence": 0.9661706686019897}]}, {"text": "To clean this instance data statement we have created a deletion statement of the following type:  Apart from the deleted statements discussed earlier, we have deleted all instance data described by statements using classes that are not from the DBPedia ontology.", "labels": [], "entities": [{"text": "DBPedia ontology", "start_pos": 246, "end_pos": 262, "type": "DATASET", "confidence": 0.9339450299739838}]}, {"text": "In this way, the DBPedia instance data has a clean interpretation in terms of the PROTON conceptualization.", "labels": [], "entities": [{"text": "DBPedia instance data", "start_pos": 17, "end_pos": 38, "type": "DATASET", "confidence": 0.8961209654808044}]}, {"text": "Freebase7 is a communitycurated database of well-known people, places, and things.", "labels": [], "entities": [{"text": "Freebase7", "start_pos": 0, "end_pos": 9, "type": "DATASET", "confidence": 0.9571162462234497}]}, {"text": "In Freebase, real-world entities are represented as topics.", "labels": [], "entities": []}, {"text": "There are topics for movie stars, countries, cities, etc.", "labels": [], "entities": []}, {"text": "The information for each topic is structured in three levels as defined in the Freebase schema.", "labels": [], "entities": [{"text": "Freebase schema", "start_pos": 79, "end_pos": 94, "type": "DATASET", "confidence": 0.9485057890415192}]}, {"text": "The first layer comprises several domains.", "labels": [], "entities": []}, {"text": "Each domain is defined by type (second layer) and each type has properties (third layer).", "labels": [], "entities": []}, {"text": "The types are connected via the special relation inclusion of type.", "labels": [], "entities": []}, {"text": "This relation connects more specific types with more general types: the type fb:base/litcentral/named_person includes the type: fb:people/person.", "labels": [], "entities": []}, {"text": "It is not possible to interpret this relation as superclass-tosubclass relation, because it is not strict in the sense that each instance of the subclass inherits the properties of the instance of the super class.", "labels": [], "entities": []}, {"text": "For example, the type fb:film/actor also includes the type fb:people/person.", "labels": [], "entities": []}, {"text": "But its definition is: \"The Film Actor type includes people (and credited animals) who have appeared in any film http://www.freebase.com/ ...\".", "labels": [], "entities": []}, {"text": "Therefore, inmost cases, the instances of the type fb:film/actor are people but there are also cases where they are not.", "labels": [], "entities": []}, {"text": "Thus, the interpretation of the type inclusion relation is not strict with respect to inheritance of the properties from the included type.", "labels": [], "entities": []}, {"text": "In the example above, if the film actor is a person, then he or she inherits all properties from the type for persons.", "labels": [], "entities": []}, {"text": "But if it is not a person, then it does not inherit any of these properties.", "labels": [], "entities": []}, {"text": "Instead, it inherits properties from some other type(s).", "labels": [], "entities": []}, {"text": "These peculiarities of the Freebase schema impose some restrictions over the mapping to the PROTON ontology.", "labels": [], "entities": []}, {"text": "Mapping so many types and properties requires more extensive work.", "labels": [], "entities": [{"text": "Mapping", "start_pos": 0, "end_pos": 7, "type": "TASK", "confidence": 0.9615262746810913}]}, {"text": "Therefore, for our purposes, we have mapped only the types with more than 500 instances in the Freebase dataset to the PROTON concepts.", "labels": [], "entities": [{"text": "Freebase dataset", "start_pos": 95, "end_pos": 111, "type": "DATASET", "confidence": 0.9893942177295685}]}, {"text": "Another criterion is that the mapping does not produce any misclassification of some instances.", "labels": [], "entities": []}, {"text": "For many types the mapping is straightforward:  Some of the types are mediators between a type and a grouping of several other types.", "labels": [], "entities": []}, {"text": "This is mainly used to represents event information.", "labels": [], "entities": []}, {"text": "For example, the type Website ownership describes an event of owning a website by an agent for some period.", "labels": [], "entities": []}, {"text": "A website can be owned by different agents in different periods, thus it is important that these 'owning' events are represented as different instances in the dataset.", "labels": [], "entities": []}, {"text": "At present, we have not yet mapped the mediator types to PROTON.", "labels": [], "entities": [{"text": "PROTON", "start_pos": 57, "end_pos": 63, "type": "DATASET", "confidence": 0.8127018213272095}]}, {"text": "For this type of mapping it is necessary to use an appropriate subclass of the class ptop:Happening.", "labels": [], "entities": []}, {"text": "For example, the type Website ownership can be mapped to a subclass of the class ptop:Situation, where the start and end date of the ownership are stated, the owner and the address of the website are specified, etc.", "labels": [], "entities": []}, {"text": "As this requires huge extension of PROTON, it is not featured in the current version.", "labels": [], "entities": [{"text": "PROTON", "start_pos": 35, "end_pos": 41, "type": "DATASET", "confidence": 0.6655536890029907}]}, {"text": "In the original dataset, there are also several errors in the instance classification.", "labels": [], "entities": []}, {"text": "For example, organisation and location are very often represented by the same instance.", "labels": [], "entities": []}, {"text": "More specifically, the types fb:organization.organization and fb:location.location have 42763 instances in common.", "labels": [], "entities": []}, {"text": "We believe that such cases result from the linguistic intuition of the users who created the data in question.", "labels": [], "entities": []}, {"text": "In many cases, the same word denotes both the meaning of an institution and a location.", "labels": [], "entities": []}, {"text": "We do not consider this a good practice for the semantic representation in LOD and we think that it should be avoided.", "labels": [], "entities": []}, {"text": "The different classes (types in Freebase) have different properties.", "labels": [], "entities": [{"text": "Freebase", "start_pos": 32, "end_pos": 40, "type": "DATASET", "confidence": 0.942814826965332}]}, {"text": "Although the Freebase types are not strict in inheriting properties, some types are still not mutually compatible (intuitively).", "labels": [], "entities": []}, {"text": "For example, due to this misclassification, the instance of the United States of America (https://www.freebase.com/m/09c7w0) is not only an instance of the types Country, Location but also of Food.", "labels": [], "entities": []}, {"text": "We believe that such knowledge has to be represented in a different way.", "labels": [], "entities": []}, {"text": "It is important to note that correcting such cases of instances classification to many disjoint types (classes) is outside the scope of the current version of FactForge.", "labels": [], "entities": [{"text": "FactForge", "start_pos": 159, "end_pos": 168, "type": "DATASET", "confidence": 0.8992814421653748}]}, {"text": "In future, we envisage to introduce new instances for each disjoint class and to keep relations between them where necessary via appropriate properties.", "labels": [], "entities": []}, {"text": "Although we could perform such an extension of Freebase, in our view, it is better this to be done in the original dataset.", "labels": [], "entities": [{"text": "Freebase", "start_pos": 47, "end_pos": 55, "type": "DATASET", "confidence": 0.9761354327201843}]}, {"text": "We consider these mismatches as a result from crowdsourcing where some of the providers of knowledge where influenced by the semantics of natural language.", "labels": [], "entities": []}], "tableCaptions": []}