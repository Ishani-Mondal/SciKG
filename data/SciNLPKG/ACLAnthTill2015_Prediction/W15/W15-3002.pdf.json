{"title": [{"text": "Statistical Machine Translation with Automatic Identification of Translationese", "labels": [], "entities": [{"text": "Statistical Machine Translation", "start_pos": 0, "end_pos": 31, "type": "TASK", "confidence": 0.7009690801302592}, {"text": "Automatic Identification of Translationese", "start_pos": 37, "end_pos": 79, "type": "TASK", "confidence": 0.5723229125142097}]}], "abstractContent": [{"text": "Translated texts (in any language) are so markedly different from original ones that text classification techniques can be used to tease them apart.", "labels": [], "entities": [{"text": "text classification", "start_pos": 85, "end_pos": 104, "type": "TASK", "confidence": 0.753351479768753}]}, {"text": "Previous work has shown that awareness to these differences can significantly improve statistical machine translation.", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 86, "end_pos": 117, "type": "TASK", "confidence": 0.7673653960227966}]}, {"text": "These results, however , required meta-information on the ontological status of texts (original or translated) which is typically unavailable.", "labels": [], "entities": []}, {"text": "In this work we show that the predictions of translationese classifiers are as good as meta-information.", "labels": [], "entities": [{"text": "translationese classifiers", "start_pos": 45, "end_pos": 71, "type": "TASK", "confidence": 0.9054650962352753}]}, {"text": "First, when a monolin-gual corpus in the target language is given, to be used for constructing a language model, predicting the translated portions of the corpus, and using only them for the language model, is as good as using the entire corpus.", "labels": [], "entities": []}, {"text": "Second, identifying the portions of a parallel corpus that are translated in the direction of the translation task, and using only them for the translation model, is as good as using the entire corpus.", "labels": [], "entities": []}, {"text": "We present results from several language pairs and various data sets, indicating that these results are robust and general.", "labels": [], "entities": []}], "introductionContent": [{"text": "Research in Translation Studies suggests that translated texts are considerably different from original texts, constituting a sublanguage known as Translationese.", "labels": [], "entities": [{"text": "Translation Studies", "start_pos": 12, "end_pos": 31, "type": "TASK", "confidence": 0.9325518012046814}]}, {"text": "Awareness to translationese can significantly improve statistical machine translation (SMT).", "labels": [], "entities": [{"text": "translationese", "start_pos": 13, "end_pos": 27, "type": "TASK", "confidence": 0.9690206050872803}, {"text": "statistical machine translation (SMT)", "start_pos": 54, "end_pos": 91, "type": "TASK", "confidence": 0.7809049735466639}]}, {"text": "showed that French-to-English SMT systems whose translation models were constructed from human translations from French to English yielded better translation quality than ones created from translations in the other direction.", "labels": [], "entities": [{"text": "SMT", "start_pos": 30, "end_pos": 33, "type": "TASK", "confidence": 0.9175517559051514}]}, {"text": "These results were corroborated by, who showed that translation models can be adapted to translationese, thereby improving the quality of SMT even further.", "labels": [], "entities": [{"text": "SMT", "start_pos": 138, "end_pos": 141, "type": "TASK", "confidence": 0.9932083487510681}]}, {"text": "Awareness to translationese also benefits the language models used in SMT: showed that language models complied from translated texts better fit the reference sets in term of perplexity, and SMT systems constructed from such language models perform much better than those constructed from original texts.", "labels": [], "entities": [{"text": "SMT", "start_pos": 70, "end_pos": 73, "type": "TASK", "confidence": 0.9935685396194458}, {"text": "SMT", "start_pos": 191, "end_pos": 194, "type": "TASK", "confidence": 0.9902426600456238}]}, {"text": "To benefit from these results, however, one has to know whether the texts used for training SMT systems are original or translated, and previous work indeed used such meta-information.", "labels": [], "entities": [{"text": "SMT", "start_pos": 92, "end_pos": 95, "type": "TASK", "confidence": 0.921675980091095}]}, {"text": "Unfortunately, annotation reflecting the status of texts, or the direction of translation, is typically unavailable.", "labels": [], "entities": []}, {"text": "The research question we investigate in this work is whether the predictions of translationese classifiers can replace manual annotation.", "labels": [], "entities": [{"text": "translationese classifiers", "start_pos": 80, "end_pos": 106, "type": "TASK", "confidence": 0.9049985110759735}]}, {"text": "Ina variety of evaluation scenarios, we demonstrate that this is indeed the case.", "labels": [], "entities": []}, {"text": "When a monolingual corpus in the target language is given for constructing a language model for SMT, we show that automatically identifying the translated portions of the corpus, and using only them for the language model, is as good as using the entire corpus.", "labels": [], "entities": [{"text": "SMT", "start_pos": 96, "end_pos": 99, "type": "TASK", "confidence": 0.9922261238098145}]}, {"text": "Similarly, when a parallel corpus is given, we show that automatically identifying the portions of the corpus that are translated in the direction of the translation task, and using only them for training the translation model, is again as good as using the entire corpus.", "labels": [], "entities": []}, {"text": "We present results from several language pairs and various data sets, indicating that the approach we advocate is general and robust.", "labels": [], "entities": []}, {"text": "The main contribution of this work is a general approach that, provided labeled data for training classifiers, can be applied to any corpus before it is used for constructing SMT systems, resulting in systems that are as good as (or better than) those that use the entire corpus, but that rely on significantly smaller language and translation models.", "labels": [], "entities": [{"text": "SMT", "start_pos": 175, "end_pos": 178, "type": "TASK", "confidence": 0.9732053875923157}]}, {"text": "We briefly review related work in Section 2.", "labels": [], "entities": []}, {"text": "Section 3 describes our methodology and experimental setup.", "labels": [], "entities": []}, {"text": "Section 4 details the experiments and their results.", "labels": [], "entities": []}, {"text": "We conclude with an analysis of the results and suggestions for future research.", "labels": [], "entities": []}], "datasetContent": [{"text": "The experiments we describe in Section 4 consist of three parts: 1.", "labels": [], "entities": []}, {"text": "Training classifiers to tease apart original from translated texts.", "labels": [], "entities": []}, {"text": "2. Constructing SMT systems with language models compiled from the predicted translations, comparing them with similar SMT systems whose language models consist of the entire monolingual corpora.", "labels": [], "entities": [{"text": "SMT", "start_pos": 16, "end_pos": 19, "type": "TASK", "confidence": 0.9916623830795288}]}, {"text": "3. Constructing SMT systems with translation models compiled from bitexts that are predicted as translated in the same direction as the direction of the SMT task, comparing them with similar SMT systems whose translation models consist of the entire parallel corpora.", "labels": [], "entities": [{"text": "SMT", "start_pos": 16, "end_pos": 19, "type": "TASK", "confidence": 0.993380069732666}, {"text": "SMT task", "start_pos": 153, "end_pos": 161, "type": "TASK", "confidence": 0.9003012776374817}, {"text": "SMT", "start_pos": 191, "end_pos": 194, "type": "TASK", "confidence": 0.9640814065933228}]}, {"text": "In this section we describe the language resources and tools required for performing these experiments.", "labels": [], "entities": []}, {"text": "Our main experiments focus on French translated to English (FR\u2192EN), and we define a classifier that can identify English translationese.", "labels": [], "entities": [{"text": "identify English translationese", "start_pos": 104, "end_pos": 135, "type": "TASK", "confidence": 0.6467650930086771}]}, {"text": "However, to further establish the robustness of our approach, we also experiment with German translated to English (DE\u2192EN) and with English translated to French (EN\u2192FR).", "labels": [], "entities": [{"text": "FR", "start_pos": 165, "end_pos": 167, "type": "METRIC", "confidence": 0.8171002864837646}]}, {"text": "We also conduct cross-corpus experiments in which we train translationese classifier on one corpus (Europarl) and test its contribution to SMT on another (Hansard, News).", "labels": [], "entities": [{"text": "translationese classifier", "start_pos": 59, "end_pos": 84, "type": "TASK", "confidence": 0.9073269665241241}, {"text": "Europarl", "start_pos": 100, "end_pos": 108, "type": "DATASET", "confidence": 0.9743359684944153}, {"text": "SMT", "start_pos": 139, "end_pos": 142, "type": "TASK", "confidence": 0.9891830682754517}, {"text": "Hansard, News)", "start_pos": 155, "end_pos": 169, "type": "DATASET", "confidence": 0.8895806521177292}]}, {"text": "These experiments are crucial for evaluating the robustness of our approach, in light of the findings that translationese classification is much less accurate outside the training domain.", "labels": [], "entities": [{"text": "translationese classification", "start_pos": 107, "end_pos": 136, "type": "TASK", "confidence": 0.982930988073349}]}, {"text": "From the Europarl corpus we use several portions, collected over the In all experiments, the split of the monolingual corpora to translated vs. original texts is balanced (in terms of chunks).", "labels": [], "entities": [{"text": "Europarl corpus", "start_pos": 9, "end_pos": 24, "type": "DATASET", "confidence": 0.9915033280849457}]}, {"text": "The parallel corpora are divided to two sections according to the direction of the translation (when it is known).", "labels": [], "entities": []}, {"text": "For example, for the French-to-English translation task, we divide the Europarl corpus to a Frenchoriginal section (FR\u2192EN) and an English-original section.", "labels": [], "entities": [{"text": "French-to-English translation", "start_pos": 21, "end_pos": 50, "type": "TASK", "confidence": 0.619534432888031}, {"text": "Europarl corpus", "start_pos": 71, "end_pos": 86, "type": "DATASET", "confidence": 0.9865379333496094}, {"text": "FR\u2192EN)", "start_pos": 116, "end_pos": 122, "type": "METRIC", "confidence": 0.8491325080394745}]}, {"text": "We also use portions of Europarl to define reference sets for evaluating the perplexity of LMs.", "labels": [], "entities": [{"text": "Europarl", "start_pos": 24, "end_pos": 32, "type": "DATASET", "confidence": 0.9901727437973022}]}, {"text": "For this task we only use translated texts.", "labels": [], "entities": []}, {"text": "For constructing translation models we use parallel corpora.", "labels": [], "entities": []}, {"text": "For the FR\u2192EN and EN\u2192FR tasks we use original French text, aligned with its translation to English (FR\u2192EN).", "labels": [], "entities": [{"text": "FR\u2192EN", "start_pos": 8, "end_pos": 13, "type": "TASK", "confidence": 0.4892691969871521}]}, {"text": "For the DE\u2192EN translation task we use original German text, aligned with its translation to English (DE\u2192EN).", "labels": [], "entities": [{"text": "DE\u2192EN translation", "start_pos": 8, "end_pos": 25, "type": "TASK", "confidence": 0.5584924593567848}]}, {"text": "The parallel portions we use are disjoint from those used for the language model and are evenly balanced between the original text and the aligned translated text.", "labels": [], "entities": []}, {"text": "From Europarl we use portions from the period of January to September 2000.", "labels": [], "entities": [{"text": "Europarl", "start_pos": 5, "end_pos": 13, "type": "DATASET", "confidence": 0.9857037663459778}]}, {"text": "To tune and evaluate SMT systems we use reference sets that are extracted from a parallel, aligned corpus.", "labels": [], "entities": [{"text": "SMT", "start_pos": 21, "end_pos": 24, "type": "TASK", "confidence": 0.9922707080841064}]}, {"text": "These include 1000 sentence pairs for tuning and 1000 (different) sentence pairs for evaluation.", "labels": [], "entities": []}, {"text": "The sentences are randomly extracted from another portion of the Europarl corpus, collected over the period of October to December 2000, and another portion of Hansard.", "labels": [], "entities": [{"text": "Europarl corpus", "start_pos": 65, "end_pos": 80, "type": "DATASET", "confidence": 0.9940998554229736}, {"text": "Hansard", "start_pos": 160, "end_pos": 167, "type": "DATASET", "confidence": 0.9931609630584717}]}, {"text": "All tuning and references sets are disjoint from the training materials.", "labels": [], "entities": []}, {"text": "We now move to experiments that address the translation model.", "labels": [], "entities": [{"text": "translation", "start_pos": 44, "end_pos": 55, "type": "TASK", "confidence": 0.9736107587814331}]}, {"text": "We build SMT systems that use a fixed language model but differ in their translation model training data.", "labels": [], "entities": [{"text": "SMT", "start_pos": 9, "end_pos": 12, "type": "TASK", "confidence": 0.9918351173400879}]}, {"text": "For all systems we use fixed tuning and evaluation sets.", "labels": [], "entities": []}, {"text": "We build several SMT systems that use the same translation model, but differ in their language models.", "labels": [], "entities": [{"text": "SMT", "start_pos": 17, "end_pos": 20, "type": "TASK", "confidence": 0.9893566966056824}]}, {"text": "This involves three tasks detailed below.", "labels": [], "entities": []}, {"text": "The above results are not very surprising given the high accuracy of the translationese classifier.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 57, "end_pos": 65, "type": "METRIC", "confidence": 0.9994233846664429}, {"text": "translationese classifier", "start_pos": 73, "end_pos": 98, "type": "TASK", "confidence": 0.8957242667675018}]}, {"text": "The question we investigate in this section is whether a classifier trained on texts in one domain is useful for predicting translationese in a different domain.", "labels": [], "entities": [{"text": "predicting translationese", "start_pos": 113, "end_pos": 138, "type": "TASK", "confidence": 0.8681860268115997}]}, {"text": "We train an (English) translationese classifier on the Europarl training data, but use the Hansard corpus for the translation model.", "labels": [], "entities": [{"text": "translationese classifier", "start_pos": 22, "end_pos": 47, "type": "TASK", "confidence": 0.8939298689365387}, {"text": "Europarl training data", "start_pos": 55, "end_pos": 77, "type": "DATASET", "confidence": 0.9735703070958456}, {"text": "Hansard corpus", "start_pos": 91, "end_pos": 105, "type": "DATASET", "confidence": 0.9857778549194336}]}, {"text": "We apply the classifier to the English side of the Hansard corpus, and based on its predictions, define a partition of the Hansard training corpus to use for the translation model.", "labels": [], "entities": [{"text": "Hansard corpus", "start_pos": 51, "end_pos": 65, "type": "DATASET", "confidence": 0.9652210175991058}, {"text": "Hansard training corpus", "start_pos": 123, "end_pos": 146, "type": "DATASET", "confidence": 0.9080479939778646}, {"text": "translation", "start_pos": 162, "end_pos": 173, "type": "TASK", "confidence": 0.9759976267814636}]}, {"text": "As in the in-domain experiment, we construct a single, fixed language model from a portion of the (Hansard) corpus.", "labels": [], "entities": [{"text": "Hansard) corpus", "start_pos": 99, "end_pos": 114, "type": "DATASET", "confidence": 0.871864895025889}]}, {"text": "We then train a French-to-English SMT system with the (predicted) translation model, comparing it to systems that use the entire Hansard training corpus, the (actual) S \u2192 T texts and the actual T \u2192 S texts.", "labels": [], "entities": [{"text": "SMT", "start_pos": 34, "end_pos": 37, "type": "TASK", "confidence": 0.9039224982261658}, {"text": "Hansard training corpus", "start_pos": 129, "end_pos": 152, "type": "DATASET", "confidence": 0.9315615296363831}]}, {"text": "The best-performing systems use either actual S \u2192 T texts or the entire corpus (BLEU score of 37.3).", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 80, "end_pos": 90, "type": "METRIC", "confidence": 0.9745491147041321}]}, {"text": "The classifier performs worse, at 36.3, but still much better than the system that is based on T \u2192 S texts.", "labels": [], "entities": []}, {"text": "This should be attributed to the very small number of chunks predicted by the classifier as S \u2192 T .", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Classification of translationese, and fitness to the reference set of FR\u2192EN language models  compiled from texts predicted as translated", "labels": [], "entities": []}, {"text": " Table 2: Accuracy of the classification, and fitness of language models compiled from texts predicted as  translated to the reference set, DE\u2192EN and EN\u2192FR", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.995964527130127}]}, {"text": " Table 3: Evaluation of the FR\u2192EN SMT system built from LMs compiled from predicted translationese", "labels": [], "entities": [{"text": "FR\u2192EN SMT", "start_pos": 28, "end_pos": 37, "type": "TASK", "confidence": 0.5790464654564857}]}, {"text": " Table 4: Evaluation of the DE\u2192EN and EN\u2192FR SMT systems built from LMs compiled from predicted  translationese", "labels": [], "entities": [{"text": "EN\u2192FR SMT", "start_pos": 38, "end_pos": 47, "type": "TASK", "confidence": 0.5256771296262741}]}, {"text": " Table 5: Cross-corpus evaluation: Hansard-based SMT system, Europarl-based classification", "labels": [], "entities": [{"text": "SMT", "start_pos": 49, "end_pos": 52, "type": "TASK", "confidence": 0.569251298904419}, {"text": "Europarl-based classification", "start_pos": 61, "end_pos": 90, "type": "DATASET", "confidence": 0.8620493710041046}]}, {"text": " Table 6: Cross-corpus evaluation: News Commentary corpus", "labels": [], "entities": []}, {"text": " Table 7: Accuracy of the classification and evaluation of SMT systems built from translation models  compiled from predicted translationese", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9936450719833374}, {"text": "SMT", "start_pos": 59, "end_pos": 62, "type": "TASK", "confidence": 0.9831601977348328}]}, {"text": " Table 8: Cross-corpus evaluation: Hansard-based SMT system, Europarl-based classification", "labels": [], "entities": [{"text": "SMT", "start_pos": 49, "end_pos": 52, "type": "TASK", "confidence": 0.5688377618789673}, {"text": "Europarl-based classification", "start_pos": 61, "end_pos": 90, "type": "DATASET", "confidence": 0.8624511063098907}]}]}