{"title": [{"text": "Describing Spatial Relationships between Objects in Images in English and French", "labels": [], "entities": [{"text": "Describing Spatial Relationships between Objects in Images", "start_pos": 0, "end_pos": 58, "type": "TASK", "confidence": 0.7967548327786582}]}], "abstractContent": [{"text": "The context for the work we report here is the automatic description of spatial relationships between pairs of objects in images.", "labels": [], "entities": []}, {"text": "We investigate the task of selecting prepositions for such spatial relationships.", "labels": [], "entities": []}, {"text": "We describe the two datasets of object pairs and prepositions we have created for English and French, and report results for predicting prepositions for object pairs in both of these languages, using two methods: (a) an existing approach which manually fixes the mapping from geometrical features to prepositions, and (b) a Naive Bayes classifier trained on the English and French datasets.", "labels": [], "entities": []}, {"text": "For the latter we use features based on object class labels and geometrical measurements of object bounding boxes.", "labels": [], "entities": []}, {"text": "We evaluate the automatically generated prepositions on unseen data in terms of accuracy against the human-selected prepositions.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 80, "end_pos": 88, "type": "METRIC", "confidence": 0.9992313385009766}]}], "introductionContent": [{"text": "Automatic image description is important not just for assistive technology, but also for applications such as text-based querying of image databases.", "labels": [], "entities": [{"text": "Automatic image description", "start_pos": 0, "end_pos": 27, "type": "TASK", "confidence": 0.6812580724557241}]}, {"text": "A good image description will, among other things, refer to the main objects in the image and the relationships between them.", "labels": [], "entities": []}, {"text": "Two of the most important types of relationships for image description are activities (e.g. a child riding a bike), and spatial relationships (e.g. a dog in a car).", "labels": [], "entities": [{"text": "image description", "start_pos": 53, "end_pos": 70, "type": "TASK", "confidence": 0.7444639503955841}]}, {"text": "The task we investigate is predicting the prepositions that can be used to describe spatial relationships between pairs of objects in images.", "labels": [], "entities": []}, {"text": "This is an important subtask in image description, but it is rarely addressed as a subtask in its own right.", "labels": [], "entities": [{"text": "image description", "start_pos": 32, "end_pos": 49, "type": "TASK", "confidence": 0.8502671122550964}]}, {"text": "If an image description method produces spatial prepositions it tends to be as a side-effect of the overall method (, or else relationships are not between objects, but e.g. between objects and the 'scene').", "labels": [], "entities": []}, {"text": "An example of preposition selection as a separate subtask is where the mapping is rule-based.", "labels": [], "entities": [{"text": "preposition selection", "start_pos": 14, "end_pos": 35, "type": "TASK", "confidence": 0.8725531697273254}]}, {"text": "Spatial relations also play a role in referring expression generation) where the problem is, however, often framed as a content selection problem from known abstract representations of the objects and scene, and the aim is to enable unique identification of the object referred to.", "labels": [], "entities": [{"text": "referring expression generation", "start_pos": 38, "end_pos": 69, "type": "TASK", "confidence": 0.823115070660909}]}, {"text": "Our main data source is a corpus of images) in which objects have been annotated with rectangular bounding boxes and object class labels.", "labels": [], "entities": []}, {"text": "For a subset of 1,000 of the images we also have five human-created descriptions of the whole image (.", "labels": [], "entities": []}, {"text": "We collected additional annotations for the images listing, for each object pair, a set of prepositions that have been selected by human annotators as correctly describing the spatial relationship between the given object pair (Section 2.3).", "labels": [], "entities": []}, {"text": "We did this in separate experiments for both English and French.", "labels": [], "entities": []}, {"text": "The overall aim is to create models for the mapping from image, bounding boxes and labels to spatial prepositions as indicated in.", "labels": [], "entities": []}, {"text": "We compare two approaches to modelling the mapping.", "labels": [], "entities": []}, {"text": "One is taken from previous work and defines manually constructed rules to implement the mapping from image ge- in front of(dog(Obj 3 ), person(Obj 1 )) Examples of all six types of annotation can be seen in.", "labels": [], "entities": []}], "datasetContent": [{"text": "We use two methods (Acc A and Acc B ) of calculating accuracy (the percentage of instances for: English Acc B results: Acc B (1..n), n \u2264 4; Acc Syn B (1); and Acc Syn B (1..4) for v NB and v RB models.", "labels": [], "entities": [{"text": "Acc A", "start_pos": 20, "end_pos": 25, "type": "METRIC", "confidence": 0.9303853809833527}, {"text": "Acc", "start_pos": 30, "end_pos": 33, "type": "METRIC", "confidence": 0.8715116381645203}, {"text": "accuracy", "start_pos": 53, "end_pos": 61, "type": "METRIC", "confidence": 0.9945791959762573}, {"text": "Acc B", "start_pos": 119, "end_pos": 124, "type": "METRIC", "confidence": 0.9741170108318329}, {"text": "Acc Syn B (1)", "start_pos": 140, "end_pos": 153, "type": "METRIC", "confidence": 0.9065848588943481}, {"text": "Acc Syn B", "start_pos": 159, "end_pos": 168, "type": "METRIC", "confidence": 0.8717997670173645}]}, {"text": "Shown: all prepositions of frequency 20 and above, in order of frequency.", "labels": [], "entities": []}, {"text": "Also included are less frequent words if they are in the set of eight prepositions produced by the v RB method.", "labels": [], "entities": []}, {"text": "which a correct output is returned).", "labels": [], "entities": []}, {"text": "The notation Acc A (1..n) or Acc B (1..n) is used to indicate that in this version of the evaluation method at least one of the top n most likely outputs (prepositions) returned by the model needs to match one of the human-selected reference prepositions for the model output to count as correct.", "labels": [], "entities": [{"text": "Acc A", "start_pos": 13, "end_pos": 18, "type": "METRIC", "confidence": 0.9803505837917328}, {"text": "Acc B (1..n)", "start_pos": 29, "end_pos": 41, "type": "METRIC", "confidence": 0.9223424111093793}]}, {"text": "Furthermore, we use the notation Acc Syn A (1..n) or Acc Syn B (1..n) to indicate that in this version, at least one of the top n most likely outputs (prepositions) returned by the model, or one of its near synonyms, needs to match one of the humanselected reference prepositions for the model output to count as correct.", "labels": [], "entities": [{"text": "Acc Syn A", "start_pos": 33, "end_pos": 42, "type": "METRIC", "confidence": 0.9096130728721619}, {"text": "Acc Syn B (1..n)", "start_pos": 53, "end_pos": 69, "type": "METRIC", "confidence": 0.8875431939959526}]}, {"text": "The near synonym sets used for English are: {above, over}, {along, alongside}, {atop, upon, on, on top of}, {below, beneath}, {beside, by, next to}, {beyond, past}, {close to, near}, {in, inside, inside of, within} {outside, outside of}, {toward, towards}, {under, underneath}, plus 11 singleton sets.", "labels": [], "entities": []}, {"text": "For French we used: {a l'interieur de, dans}, {au dessus de, en haut de}, {en dessous de, sous}, plus 15 singleton sets.", "labels": [], "entities": []}, {"text": "This gives us 18 sets for French, and 22 for English.", "labels": [], "entities": []}, {"text": "For the rule-based selection method we do not have the ranked outputs needed to compute Acc A and Acc B . Interpreting the output set P directly as ranked would mean preserving the order in which prepositions are selected by rules which is likely to be unfair to this method.", "labels": [], "entities": [{"text": "Acc A", "start_pos": 88, "end_pos": 93, "type": "METRIC", "confidence": 0.9670899212360382}, {"text": "Acc B", "start_pos": 98, "end_pos": 103, "type": "METRIC", "confidence": 0.8923201560974121}]}, {"text": "Instead we randomly shuffle P and then interpret it as ranked, with the first in this shuffled list giving the highest ranked output v RB . To be on the safe side we average all results over 10 different random shuffles.", "labels": [], "entities": []}, {"text": "Note that from n = 4 upwards, it makes no difference whether the outputs are truly ranked or not.: French Acc B results: Acc B (1..n), n \u2264 4; Acc Syn B (1); and Acc Syn B (1..4) for v NB and v RB models.", "labels": [], "entities": [{"text": "French", "start_pos": 99, "end_pos": 105, "type": "DATASET", "confidence": 0.7645279765129089}, {"text": "Acc B", "start_pos": 106, "end_pos": 111, "type": "METRIC", "confidence": 0.9380600154399872}, {"text": "Acc B", "start_pos": 121, "end_pos": 126, "type": "METRIC", "confidence": 0.9771497845649719}, {"text": "Acc Syn B", "start_pos": 142, "end_pos": 151, "type": "METRIC", "confidence": 0.894867738087972}, {"text": "Acc Syn B", "start_pos": 161, "end_pos": 170, "type": "METRIC", "confidence": 0.8900509277979533}]}, {"text": "Shown: all prepositions of frequency 10 and above, in order of frequency.", "labels": [], "entities": []}, {"text": "Also included are less frequent words if they are in the set of eight prepositions produced by the v RB method.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Object class label frequencies.", "labels": [], "entities": []}, {"text": " Table 3: Accuracy A results for English and French.", "labels": [], "entities": [{"text": "Accuracy A", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.7739710211753845}]}, {"text": " Table 4: English Acc B results: Acc B (1..n), n \u2264 4; Acc Syn  B (1); and Acc Syn  B (1..4) for v N B and v RB  models. Shown: all prepositions of frequency 20 and above, in order of frequency. Also included are  less frequent words if they are in the set of eight prepositions produced by the v RB method.", "labels": [], "entities": [{"text": "Acc B", "start_pos": 18, "end_pos": 23, "type": "METRIC", "confidence": 0.9400756359100342}, {"text": "Acc B", "start_pos": 33, "end_pos": 38, "type": "METRIC", "confidence": 0.9853378236293793}, {"text": "Acc Syn  B (1)", "start_pos": 54, "end_pos": 68, "type": "METRIC", "confidence": 0.9398831327756246}, {"text": "Acc Syn  B", "start_pos": 74, "end_pos": 84, "type": "METRIC", "confidence": 0.9095107714335123}]}]}