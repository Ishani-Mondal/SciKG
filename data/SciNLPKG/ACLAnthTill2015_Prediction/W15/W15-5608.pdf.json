{"title": [{"text": "Integrating support verb constructions into a parser", "labels": [], "entities": [{"text": "Integrating support verb constructions", "start_pos": 0, "end_pos": 38, "type": "TASK", "confidence": 0.9100131690502167}]}], "abstractContent": [{"text": "This paper describes the process of integrating into a rule-based parser a set of approximately 1,000 nominal predicates forming support verb constructions (SVC) with the verb dar 'give' in Brazilian Portuguese.", "labels": [], "entities": []}, {"text": "The system was evaluated on a sample of 580 sentences containing verb-noun combinations candidates to SVC, manually and independently annotated.", "labels": [], "entities": [{"text": "SVC", "start_pos": 102, "end_pos": 105, "type": "DATASET", "confidence": 0.7536536455154419}]}, {"text": "Best results yield 85% precision, 79% recall, 76% accuracy and 82% F-measure.", "labels": [], "entities": [{"text": "precision", "start_pos": 23, "end_pos": 32, "type": "METRIC", "confidence": 0.9997184872627258}, {"text": "recall", "start_pos": 38, "end_pos": 44, "type": "METRIC", "confidence": 0.9995778203010559}, {"text": "accuracy", "start_pos": 50, "end_pos": 58, "type": "METRIC", "confidence": 0.9995951056480408}, {"text": "F-measure", "start_pos": 67, "end_pos": 76, "type": "METRIC", "confidence": 0.99825519323349}]}], "introductionContent": [{"text": "Support verb constructions (SVC)] pose a challenge to Natural Language Processing (NLP) because they are superficially alike verbal predicates (cp.", "labels": [], "entities": [{"text": "Support verb constructions (SVC)]", "start_pos": 0, "end_pos": 33, "type": "TASK", "confidence": 0.7024056116739908}]}, {"text": "John gave a kiss to Mary vs. John gave a book to Mary), but semantically they present a special configuration since the predicate is actually expressed by the predicative noun (kiss) instead of the verb (give).", "labels": [], "entities": []}, {"text": "This entails a set of SVC-specific properties that distinguish them from ordinary (distributional) verbal constructions (e.g. John gave my *kiss/book to Mary, John's kiss/*book to Mary).", "labels": [], "entities": []}, {"text": "From the perspective of identifying the meaning units of texts, SVC area combination of verb and noun corresponding to a single semantic unit, although syntactically analysable.", "labels": [], "entities": []}, {"text": "In this sense, they do not form a compound word, but a special type of collocation, where the verb functions as an auxiliary of the noun, conveying the grammatical values of person-number and tense.", "labels": [], "entities": []}], "datasetContent": [{"text": "In order to evaluate the overall performance of the system, a reference corpus containing 2,646 sentences with SVC in (Brazilian) Portuguese was produced, constituting a golden standard for SVC processing.", "labels": [], "entities": [{"text": "SVC processing", "start_pos": 190, "end_pos": 204, "type": "TASK", "confidence": 0.9369645714759827}]}, {"text": "These constructions have been manually and independently annotated by 5 annotators, all Portuguese native speakers, professional linguists, and experts in SVC.", "labels": [], "entities": [{"text": "SVC", "start_pos": 155, "end_pos": 158, "type": "DATASET", "confidence": 0.9424024820327759}]}, {"text": "The average agreement between annotators was 80.8% and Cohen's Kappa was 0.604, which can be considered in the range between \"moderate\" and \"substantial\".", "labels": [], "entities": [{"text": "agreement", "start_pos": 12, "end_pos": 21, "type": "METRIC", "confidence": 0.968511700630188}, {"text": "Kappa", "start_pos": 63, "end_pos": 68, "type": "METRIC", "confidence": 0.45006227493286133}]}, {"text": "The reference subcorpus for this paper consists of a sample containing 580 sentences with the verb dar give' and 8 stylistic or aspectual variants 2 . The evaluation of the new module of the Portuguese grammar for XIP parser in STRING was carried out in two stages: (i) a preliminary evaluation took as reference the 580 manually annotated sentences, considering the majority agreement among the annotators; (ii) the second evaluation was carried outwith the same sample of sentences but after error analysis was performed.", "labels": [], "entities": [{"text": "XIP parser in STRING", "start_pos": 214, "end_pos": 234, "type": "TASK", "confidence": 0.4833564758300781}]}, {"text": "This analysis made possible to spot some inconsistencies in the annotation as well as some few errors in the Lexicon-Grammar.", "labels": [], "entities": []}, {"text": "For example, some diminutive forms of -da '-ed' ending nouns (e.g. arrumadinha 'little tidy-ed up') had not been adequately analyzed by STRING and hence were not associated with its lemma (arrumada 'tidy-ed up').", "labels": [], "entities": [{"text": "STRING", "start_pos": 136, "end_pos": 142, "type": "TASK", "confidence": 0.4804600775241852}]}, {"text": "This enabled us to improve the STRING lexicon.", "labels": [], "entities": [{"text": "STRING lexicon", "start_pos": 31, "end_pos": 45, "type": "TASK", "confidence": 0.8428422808647156}]}, {"text": "On the other hand, the inconsistent annotation of some SVC as idioms or some linking operator verbs as support verbs led us to refine the criteria fora more precise distinction between those categories.", "labels": [], "entities": []}, {"text": "For lack of space, a fully detailed error analysis cannot be presented here.", "labels": [], "entities": []}, {"text": "The new (corrected) reference was then compared with STRING's new results in a second evaluation run.", "labels": [], "entities": [{"text": "STRING", "start_pos": 53, "end_pos": 59, "type": "METRIC", "confidence": 0.825167179107666}]}, {"text": "Results from both runs are compared in  Comparing the first and second evaluation runs, one can see that the system's overall performance shows a small improvement.", "labels": [], "entities": []}, {"text": "The most important change is the number of true-negative cases (TN), due mostly to a more precise definition and reclassification of idioms (e.g. dar nome 'give name to', dar a volta por cima 'turn things around') or the verb ter 'have' as a linking Vop (e.g. Eu tenho uma informa\u00e7informa\u00e7\u02dcinforma\u00e7\u00e3o para (dar para) voc\u00ea 'I have an information to (give to) you').", "labels": [], "entities": [{"text": "true-negative cases (TN)", "start_pos": 43, "end_pos": 67, "type": "TASK", "confidence": 0.6327641487121582}]}, {"text": "Some errors derive from previous modules of the processing chain, for example errors in POS-tagging and disambiguation, in the chunking or in the syntactic parsing.", "labels": [], "entities": [{"text": "syntactic parsing", "start_pos": 146, "end_pos": 163, "type": "TASK", "confidence": 0.6848745346069336}]}, {"text": "Other errors came from the ambiguity between standard and converse constructions, especially when involving the verb ter 'have'].", "labels": [], "entities": []}], "tableCaptions": []}