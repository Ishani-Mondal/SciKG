{"title": [{"text": "Part of Speech Annotation of Intermediate Versions in the Keystroke Logged Translation Corpus", "labels": [], "entities": []}], "abstractContent": [{"text": "Translation process data contains non-canonical features such as incomplete word tokens, non-sequential string modifications and syntactically deficient structures.", "labels": [], "entities": [{"text": "Translation process", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.8794327080249786}]}, {"text": "While these features are often removed for the final translation product, they are present in the unfolding text (i.e. intermediate translation versions).", "labels": [], "entities": []}, {"text": "This paper describes tools developed to semi-automatically process intermediate versions of translation data to facilitate quantitative analysis of linguistic means employed in translation strategies.", "labels": [], "entities": []}, {"text": "We examine the data from a translation experiment with the help of these tools.", "labels": [], "entities": [{"text": "translation", "start_pos": 27, "end_pos": 38, "type": "TASK", "confidence": 0.9698992371559143}]}], "introductionContent": [{"text": "Within the area of translation studies, there is a growing interest in the investigation of the processrelated aspects of translation (see e.g. for an overview).", "labels": [], "entities": [{"text": "translation studies", "start_pos": 19, "end_pos": 38, "type": "TASK", "confidence": 0.9813500642776489}]}, {"text": "Insights into the ongoing translation process can be gained by conducting psycholinguistic experiments, often characterized through a combination of eye-tracking and keystroke logging methods (e.g.).", "labels": [], "entities": [{"text": "translation process", "start_pos": 26, "end_pos": 45, "type": "TASK", "confidence": 0.9002029895782471}]}, {"text": "The resulting process data is typically analyzed in terms of behavioral measures, such as pauses during text production and gaze patterns within the texts, linked to the more abstract level of cognitive processing during a translation task.", "labels": [], "entities": []}, {"text": "We adopt a corpus perspective on the keystroke logs (, which contain rich information on key presses and mouse clicks during a translation session.", "labels": [], "entities": []}, {"text": "This perspective entails that the data present in the logs can be queried, enabling us to perform quantitative, linguistically informed analyses of the translations.", "labels": [], "entities": []}, {"text": "We take into account not only originals and the corresponding final versions of translated texts -which are also present in the traditional parallel corpora used in translation studies and contrastive linguistics, e.g. the CroCo corpus) -but also the intermediate versions of translations.", "labels": [], "entities": [{"text": "CroCo corpus", "start_pos": 223, "end_pos": 235, "type": "DATASET", "confidence": 0.9100527167320251}]}, {"text": "We define the intermediate versions as variants of the unfolding texts produced at certain points in time during the translation process.", "labels": [], "entities": []}, {"text": "The explicit linguistic annotation of text versions proposed here is not found in existing data collections containing keystroke logs: for instance, the TPR database involves part of speech (POS) annotation of source and target language tokens but does not analyze the intermediate versions.", "labels": [], "entities": [{"text": "part of speech (POS) annotation of source and target language tokens", "start_pos": 175, "end_pos": 243, "type": "TASK", "confidence": 0.6696791098668025}]}, {"text": "Investigation of these text versions allows us to identify potential translation problems and strategies, contributing to our understanding of cognitive processing, and also to provide best practice solutions for problems encountered in machine translation.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 237, "end_pos": 256, "type": "TASK", "confidence": 0.7420523166656494}]}, {"text": "However, in order to study specific research questions from the field of translation studies with the help of such a corpus, we first need a transformation of sequences of production, deletion and separation keystrokes (see section 3.1) into word tokens, their annotation with linguistic information and also alignment between originals and the corresponding translations.", "labels": [], "entities": []}, {"text": "The present paper concentrates on completed work involving the tokenization and (semi-)automatic POS annotation of the intermediate versions identified in the unfolding translations.", "labels": [], "entities": [{"text": "tokenization", "start_pos": 63, "end_pos": 75, "type": "TASK", "confidence": 0.9689455032348633}, {"text": "POS annotation", "start_pos": 97, "end_pos": 111, "type": "TASK", "confidence": 0.548381119966507}]}, {"text": "The corpus presents a type of non-canonical language, which is to some extent comparable to spoken data, as it also contains online repairs of the ongoing text production (cf.).", "labels": [], "entities": []}, {"text": "Online repair can take place when a word or a grammatical structure present in one of the intermediate versions is replaced by another variant, either immediately before the participant moves to the translation of the subsequent parts or at a later stage of the translation process.", "labels": [], "entities": [{"text": "Online repair", "start_pos": 0, "end_pos": 13, "type": "TASK", "confidence": 0.7485929429531097}]}, {"text": "This can be shown using Example 1 taken from the keystroke logged translation corpus (KLTC).", "labels": [], "entities": [{"text": "keystroke logged translation corpus (KLTC)", "start_pos": 49, "end_pos": 91, "type": "DATASET", "confidence": 0.7291072819914136}]}, {"text": "It contains the source text (ST), two intermediate versions of the unfolding translation (IT1 and IT2) and the target text (TT).", "labels": [], "entities": []}, {"text": "ST Crumpling a sheet of paper seems IT1 Ein Blatt Papier zu kn\u00fcllen scheint 'a leaf paper to crumple seems' IT2 Ein Blatt Papier zu kn\u00fcllen 'a leaf paper to crumple' TT Ein Blatt Papier zu kn\u00fcllen erscheint 'a leaf paper to crumple appears' Example 1.", "labels": [], "entities": []}, {"text": "From the intermediate versions of the text we know that the translator typed scheint 'seems', deleted it, and at a later point typed erscheint 'appears'.", "labels": [], "entities": []}, {"text": "In other words, this experiment participant replaced one verb with another nearly synonymous one, filling the same slot in the produced sentence.", "labels": [], "entities": []}, {"text": "Apart from such cases, the corpus also contains several versions of the same word tokens along with incomplete tokens and structures.", "labels": [], "entities": []}, {"text": "Taking into account these non-canonical features, traditional NLP tools have to be modified to some extent, in order to make the automatic processing of the process data feasible.", "labels": [], "entities": []}, {"text": "The type of data included in the current version of the keystroke logged translation corpus is described in section 2.", "labels": [], "entities": []}, {"text": "Section 3 presents how our Tokenizer processes the intermediate translation versions and discusses alternative methods of POS annotation.", "labels": [], "entities": [{"text": "POS annotation", "start_pos": 122, "end_pos": 136, "type": "TASK", "confidence": 0.6918960213661194}]}, {"text": "In section 4 we show how these preand post-processing steps can help us in the analysis of translation studies phenomena.", "labels": [], "entities": [{"text": "translation studies", "start_pos": 91, "end_pos": 110, "type": "TASK", "confidence": 0.8028702735900879}]}, {"text": "Finally, section 5 provides an outlook on the next steps.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": []}