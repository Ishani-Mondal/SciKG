{"title": [{"text": "Ranking Relevant Verb Phrases Extracted from Historical Text", "labels": [], "entities": [{"text": "Ranking Relevant Verb Phrases Extracted from Historical Text", "start_pos": 0, "end_pos": 60, "type": "TASK", "confidence": 0.7109927907586098}]}], "abstractContent": [{"text": "In this paper, we present three approaches to automatic ranking of relevant verb phrases extracted from historical text.", "labels": [], "entities": [{"text": "automatic ranking of relevant verb phrases extracted from historical text", "start_pos": 46, "end_pos": 119, "type": "TASK", "confidence": 0.7889540135860443}]}, {"text": "These approaches are based on conditional probability, log likelihood ratio, and bag-of-words classification respectively.", "labels": [], "entities": [{"text": "log likelihood ratio", "start_pos": 55, "end_pos": 75, "type": "METRIC", "confidence": 0.7854598561922709}]}, {"text": "The aim of the ranking in our study is to present verb phrases that have a high probability of describing work at the top of the results list, but the methods are likely to be applicable to other information needs as well.", "labels": [], "entities": []}, {"text": "The results are evaluated by use of three different evaluation metrics: precision at k, R-precision, and average precision.", "labels": [], "entities": [{"text": "precision", "start_pos": 72, "end_pos": 81, "type": "METRIC", "confidence": 0.9993281364440918}, {"text": "R-precision", "start_pos": 88, "end_pos": 99, "type": "METRIC", "confidence": 0.9745371341705322}, {"text": "average precision", "start_pos": 105, "end_pos": 122, "type": "METRIC", "confidence": 0.7341877818107605}]}, {"text": "In the best setting, 91 out of the top-100 instances in the list are true posi-tives.", "labels": [], "entities": []}], "introductionContent": [{"text": "Automatic analysis of historical text is of great interest not only to the language engineering community, but also to historians and other researchers in humanities, for which historical texts contain information relevant to their research.", "labels": [], "entities": [{"text": "Automatic analysis of historical text", "start_pos": 0, "end_pos": 37, "type": "TASK", "confidence": 0.7996100068092347}]}, {"text": "This information is however not easily accessed.", "labels": [], "entities": []}, {"text": "Even in cases where the text has been digitized, contemporary tools for linguistic analysis and information extraction are often not sufficient, since historical text differs in many aspects from modern text, with longer sentences, a different vocabulary, varying word order, and inconsistencies in both spelling and syntax.", "labels": [], "entities": [{"text": "information extraction", "start_pos": 96, "end_pos": 118, "type": "TASK", "confidence": 0.7873799204826355}]}, {"text": "In this paper we address the problem of information extraction from historical text, more specifically automatic extraction and ranking of verb phrases describing work.", "labels": [], "entities": [{"text": "information extraction from historical text", "start_pos": 40, "end_pos": 83, "type": "TASK", "confidence": 0.8357596933841706}, {"text": "automatic extraction and ranking of verb phrases describing work", "start_pos": 103, "end_pos": 167, "type": "TASK", "confidence": 0.7200659049881829}]}, {"text": "This particular information need has arisen within the Gender and Work project, where historians are storing information in a database on what men and women did fora living in the Early Modern Swedish society (i.e. approximately 1550-1800).", "labels": [], "entities": []}, {"text": "During this work they have found that working activities in their source material are most often expressed in the form of verb phrases, such as to fish herring or to sell clothes).", "labels": [], "entities": []}, {"text": "Our approach to information extraction from historical text, and ranking of the extracted results, is however likely to be applicable to other information needs as well.", "labels": [], "entities": [{"text": "information extraction from historical text", "start_pos": 16, "end_pos": 59, "type": "TASK", "confidence": 0.858279013633728}]}, {"text": "Furthermore, the methods presented in this paper are not dependent on semantically annotated data, since the only information required is a goldstandard containing positive and negative phrases.", "labels": [], "entities": []}, {"text": "In the ideal case, we would like to extract all verb phrases from a historical text, correctly classify each instance as either describing work or not, and finally present all phrases denoting work, and no other phrases, to the end user.", "labels": [], "entities": []}, {"text": "In reality, this is however a tricky task.", "labels": [], "entities": []}, {"text": "Even though we have access to a database of phrases previously extracted by the historians as describing work, this does not guarantee that we know how to categorise similar phrases occurring in other texts.", "labels": [], "entities": []}, {"text": "For example, the verb k\u00f6pa ('to buy') is sometimes a working activity related to trade, whereas in other contexts, people buy things for non-commercial reasons.", "labels": [], "entities": []}, {"text": "In previously unseen texts, there will also most certainly be previously unseen word forms present, which a classifier would not know how to handle.", "labels": [], "entities": []}, {"text": "This problem is further aggravated by the high degree of spelling variation in historical text, and inconsistently extracted phrases in the goldstandard (see further Section 3).", "labels": [], "entities": []}, {"text": "Instead of doing a binary classification into phrases denoting work versus phrases not denoting work, we therefore try a ranking approach aiming to present those verb phrases that most probably describe work at the top of the results list, whereas phrases that are less likely to describe work will be presented further down in the list.", "labels": [], "entities": []}, {"text": "In this paper we present three different approaches to verb phrase ranking, based on 1) conditional probability, 2) log likelihood ratio, and 3) bag-of-words classification.", "labels": [], "entities": [{"text": "verb phrase ranking", "start_pos": 55, "end_pos": 74, "type": "TASK", "confidence": 0.6769108970959982}, {"text": "log likelihood ratio", "start_pos": 116, "end_pos": 136, "type": "METRIC", "confidence": 0.7891696294148763}, {"text": "bag-of-words classification", "start_pos": 145, "end_pos": 172, "type": "TASK", "confidence": 0.7125610709190369}]}, {"text": "The outline of the paper is as follows.", "labels": [], "entities": []}, {"text": "Related work is given in Section 2.", "labels": [], "entities": []}, {"text": "In Section 3 we describe the corpus data used in our study.", "labels": [], "entities": []}, {"text": "The verb phrase extraction method is presented in Section 4, whereas the ranking methods are described in detail in Section 5.", "labels": [], "entities": [{"text": "verb phrase extraction", "start_pos": 4, "end_pos": 26, "type": "TASK", "confidence": 0.6489037871360779}]}, {"text": "In Section 6, the metrics used for evaluating the ranking approaches are introduced.", "labels": [], "entities": []}, {"text": "Finally, the results are presented in Section 7, and conclusions are drawn in Section 8.", "labels": [], "entities": []}], "datasetContent": [{"text": "Three different evaluation metrics are applied to the verb phrase ranking results: precision at k, Rprecision, and average precision.", "labels": [], "entities": [{"text": "precision", "start_pos": 83, "end_pos": 92, "type": "METRIC", "confidence": 0.9992928504943848}, {"text": "Rprecision", "start_pos": 99, "end_pos": 109, "type": "METRIC", "confidence": 0.9977365732192993}, {"text": "average precision", "start_pos": 115, "end_pos": 132, "type": "METRIC", "confidence": 0.7982825040817261}]}, {"text": "In accordance with the arguments given in Section 3, an extracted verb phrase is here judged as describing work as long as there is at least one verb in common between the automatically extracted phrase and a manual excerpt from the same case.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Datasets used in our experiments.", "labels": [], "entities": []}, {"text": " Table 2: Results for verb phrase ranking based on conditional  probability. p10 = precision at 10, p50 = precision at 50,  p100 = precision at 100, R-pre = R-precision, AVP = average  precision, baseline = results for the unranked list, tok = token- based model, lem = lemma-based model, avg = probability  score based on average value, max = probability score based  on maximum value.", "labels": [], "entities": [{"text": "verb phrase ranking", "start_pos": 22, "end_pos": 41, "type": "TASK", "confidence": 0.6355535387992859}, {"text": "precision", "start_pos": 83, "end_pos": 92, "type": "METRIC", "confidence": 0.9983512163162231}, {"text": "precision", "start_pos": 106, "end_pos": 115, "type": "METRIC", "confidence": 0.9955026507377625}, {"text": "precision", "start_pos": 131, "end_pos": 140, "type": "METRIC", "confidence": 0.9935715198516846}, {"text": "AVP = average  precision", "start_pos": 170, "end_pos": 194, "type": "METRIC", "confidence": 0.7118935510516167}]}, {"text": " Table 3: Results for verb phrase ranking based on the log  likelihood ratio. p10 = precision at 10, p50 = precision at 50,  p100 = precision at 100, R-pre = R-precision, AVP = average  precision, baseline = results for the unranked list, tok = token- based model, lem = lemma-based model. See Section 5.2 for  a description of the other abbreviations used in the table.", "labels": [], "entities": [{"text": "verb phrase ranking", "start_pos": 22, "end_pos": 41, "type": "TASK", "confidence": 0.6699115037918091}, {"text": "precision", "start_pos": 84, "end_pos": 93, "type": "METRIC", "confidence": 0.9984436631202698}, {"text": "precision", "start_pos": 107, "end_pos": 116, "type": "METRIC", "confidence": 0.9952636957168579}, {"text": "precision", "start_pos": 132, "end_pos": 141, "type": "METRIC", "confidence": 0.9956621527671814}, {"text": "AVP = average  precision", "start_pos": 171, "end_pos": 195, "type": "METRIC", "confidence": 0.7843874245882034}]}, {"text": " Table 4: Results for verb phrase ranking based on machine  learning. p10 = precision at 10, p50 = precision at 50, p100  = precision at 100, R-pre = R-precision, AVP = average pre- cision, baseline = results for the unranked list, words = bag  of words, lemmas = bag of lemmas, vb = bag of verbs, vbnn  = bag of verbs and nouns, tok = token-based model, lem =  lemma-based model.", "labels": [], "entities": [{"text": "verb phrase ranking", "start_pos": 22, "end_pos": 41, "type": "TASK", "confidence": 0.6227126518885294}, {"text": "precision", "start_pos": 76, "end_pos": 85, "type": "METRIC", "confidence": 0.9984128475189209}, {"text": "precision", "start_pos": 99, "end_pos": 108, "type": "METRIC", "confidence": 0.9927861094474792}, {"text": "precision", "start_pos": 124, "end_pos": 133, "type": "METRIC", "confidence": 0.9960118532180786}, {"text": "AVP", "start_pos": 163, "end_pos": 166, "type": "METRIC", "confidence": 0.9913042783737183}]}, {"text": " Table 5: Summary of the results for verb phrase ranking. p10  = precision at 10, p50 = precision at 50, p100 = precision at  100, R-pre = R-precision, AVP = average precision, baseline  = results for the unranked list, cond prob = conditional proba- bility, llr = log likelihood, bow = bag-of-words classification.", "labels": [], "entities": [{"text": "verb phrase ranking", "start_pos": 37, "end_pos": 56, "type": "TASK", "confidence": 0.6591415206591288}, {"text": "precision", "start_pos": 65, "end_pos": 74, "type": "METRIC", "confidence": 0.9985694885253906}, {"text": "precision", "start_pos": 88, "end_pos": 97, "type": "METRIC", "confidence": 0.9969357252120972}, {"text": "precision", "start_pos": 112, "end_pos": 121, "type": "METRIC", "confidence": 0.9961144924163818}, {"text": "AVP = average precision", "start_pos": 152, "end_pos": 175, "type": "METRIC", "confidence": 0.7513142675161362}]}]}