{"title": [], "abstractContent": [], "introductionContent": [{"text": "The idea of statistical analysis of language is an old idea, but modern NLP started with a focus on methods based on pure symbolic analysis of language.", "labels": [], "entities": [{"text": "statistical analysis of language", "start_pos": 12, "end_pos": 44, "type": "TASK", "confidence": 0.8436227291822433}]}, {"text": "Statistical methods were introduced to NLP in its current form in the 1980s/1990s, allowing \"soft\" reasoning about language, and made NLP more data-driven.", "labels": [], "entities": []}, {"text": "Over the last decade another step has been taken in this direction -it was proposed to represent and analyze language in vector spaces.", "labels": [], "entities": []}, {"text": "Now-a-days, context, symbolic and high-dimensional representations are often augmented with relatively low-dimensional vector-space representations.", "labels": [], "entities": []}, {"text": "Vector space representations have been successfully used in different areas of NLP such as syntax and semantics.", "labels": [], "entities": []}, {"text": "This workshop is an opportunity to explore state of the art in the use of vector spaces in order to computationally analyze natural language.", "labels": [], "entities": []}, {"text": "The focus of the workshop is on the use of vector spaces to learn latent representations.", "labels": [], "entities": []}, {"text": "The goal of the workshop is to bring together researchers from areas such as deep learning and representation learning, spectral learning, distributional compositional semantics and others, in order to see their relevance to each other, and learn about the state of the art in these areas.", "labels": [], "entities": []}, {"text": "This is the first time that this workshop is held.", "labels": [], "entities": []}, {"text": "There were other similar workshops in the past, such as the Workshop on Continuous Vector Space Models and their Compositionality.", "labels": [], "entities": []}, {"text": "The program this year includes 27 papers that cover different areas under the realm of vector space modeling in NLP, all of which are presented in two poster sessions.", "labels": [], "entities": [{"text": "vector space modeling", "start_pos": 87, "end_pos": 108, "type": "TASK", "confidence": 0.6825541456540426}]}, {"text": "There are also 3 invited speakers, Marco Baroni, Chris Manning and Xavier Carreras, with each of their talks covering a different aspect of vector space modeling in NLP.", "labels": [], "entities": [{"text": "vector space modeling", "start_pos": 140, "end_pos": 161, "type": "TASK", "confidence": 0.6318284074465433}]}, {"text": "We would like to thank the Program Committee members who reviewed the papers this year.", "labels": [], "entities": []}, {"text": "We would also like to thank the workshop participants.", "labels": [], "entities": []}, {"text": "Last, a word of thanks also goes to our two sponsors: Google Deepmind and Textkernel.", "labels": [], "entities": [{"text": "Textkernel", "start_pos": 74, "end_pos": 84, "type": "DATASET", "confidence": 0.9283217787742615}]}], "datasetContent": [], "tableCaptions": []}