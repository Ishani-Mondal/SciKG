{"title": [{"text": "A Hybrid Transliteration Model for Chinese/English Named Entities -BJTU-NLP Report for the 5th Named Entities Workshop", "labels": [], "entities": [{"text": "BJTU-NLP Report for the 5th Named Entities Workshop", "start_pos": 67, "end_pos": 118, "type": "DATASET", "confidence": 0.7566519379615784}]}], "abstractContent": [{"text": "This paper presents our system (BJTU-NLP system) for the NEWS2015 evaluation task of Chinese-to-English and English-to-Chinese named entity transliteration.", "labels": [], "entities": [{"text": "BJTU-NLP", "start_pos": 32, "end_pos": 40, "type": "DATASET", "confidence": 0.6266083717346191}, {"text": "NEWS2015 evaluation task", "start_pos": 57, "end_pos": 81, "type": "TASK", "confidence": 0.4810231725374858}]}, {"text": "Our system adopts a hybrid machine transliteration approach, which combines several features.", "labels": [], "entities": []}, {"text": "To further improve the result, we adopt external data extracted from wikipeda to expand the training set.", "labels": [], "entities": []}, {"text": "In addition, pre-processing and post-processing rules are utilized to further improve the performance.", "labels": [], "entities": []}, {"text": "The final performance on the test corpus shows that our system achieves comparable results with other state-of-the-art systems.", "labels": [], "entities": []}], "introductionContent": [{"text": "Machine transliteration transforms the script of a word from a source language to a target language automatically.", "labels": [], "entities": [{"text": "Machine transliteration", "start_pos": 0, "end_pos": 23, "type": "TASK", "confidence": 0.7294212877750397}]}, {"text": "proposes a phoneme-based approach to solve the transliteration between English names and Japanese katakana.", "labels": [], "entities": []}, {"text": "The phoneme-based approach needs a pronunciation dictionary for one or two languages.", "labels": [], "entities": []}, {"text": "These dictionaries usually do not exist or can't coverall the names.", "labels": [], "entities": []}, {"text": "views machine transliteration as a special example of machine translation and uses the phrase-based machine translation model to solve it.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 54, "end_pos": 73, "type": "TASK", "confidence": 0.7865241169929504}, {"text": "phrase-based machine translation", "start_pos": 87, "end_pos": 119, "type": "TASK", "confidence": 0.6450734635194143}]}, {"text": "However, using the English letters and Chinese characters as basic mapping units will make ambiguity in the alignment and translation step.", "labels": [], "entities": [{"text": "alignment", "start_pos": 108, "end_pos": 117, "type": "TASK", "confidence": 0.9564204812049866}, {"text": "translation", "start_pos": 122, "end_pos": 133, "type": "TASK", "confidence": 0.8726769685745239}]}, {"text": "Huang(2011) proposes a novel nonparametric Bayesian using synchronous adaptor grammars to model the grapheme-based transliteration.", "labels": [], "entities": []}, {"text": "This paper describes a machine transliteration system and data measures for participating NEWS2015 evaluation, which is abbreviated as BJTU-NLP.", "labels": [], "entities": [{"text": "NEWS2015 evaluation", "start_pos": 90, "end_pos": 109, "type": "TASK", "confidence": 0.5661736726760864}, {"text": "BJTU-NLP", "start_pos": 135, "end_pos": 143, "type": "DATASET", "confidence": 0.9107710123062134}]}, {"text": "We participated in two transliteration masks: Chinese-to-English and English-to-Chinese named entity transliteration task.", "labels": [], "entities": []}, {"text": "This report briefly introduces the implementation framework of our machine transliteration system, and analyzes the experimental results over the evaluation data.", "labels": [], "entities": []}, {"text": "The following parts are organized as follows: Section 2 briefly introduces the implementation framework of the transliteration system.", "labels": [], "entities": []}, {"text": "Section 3 introduces the details of the experiment and data processing in brief.", "labels": [], "entities": [{"text": "data processing", "start_pos": 55, "end_pos": 70, "type": "TASK", "confidence": 0.7397395372390747}]}, {"text": "In Section 4, experimental results are given and the results of the experiment are analyzed.", "labels": [], "entities": []}, {"text": "Section 5 is our conclusion and future work.", "labels": [], "entities": []}], "datasetContent": [{"text": "Our transliteration systems' outputs have following format problems: 1.", "labels": [], "entities": []}, {"text": "English-to-Chinese outputs: the Chinese output words are still separated by spaces 2.", "labels": [], "entities": []}, {"text": "Chinese-to-English outputs: English output words are still divided by syllable To solve these problems, we make the following amendments to the outputs: 1.", "labels": [], "entities": []}, {"text": "Remove the spaces between character and character, syllable and syllable 2.", "labels": [], "entities": []}, {"text": "The English results are expressed as: initial capital letters, other letter lowercase We adopt Niutrans () to realize our log-linear model to combining several features.", "labels": [], "entities": []}, {"text": "By comparing the experiment, we found that segmentation by syllable of English words is more effective and segmentation by Pinyin and syllable of Chinese words performs better.", "labels": [], "entities": []}, {"text": "We adopt the above standard and non-standard training set to evaluate the official test set, and use official development set to adjust parameters.", "labels": [], "entities": []}, {"text": "The evaluation results of the standard and non-standard training set and corresponding analysis are shown as follows.", "labels": [], "entities": []}, {"text": "We evaluated the four official test sets respectively.", "labels": [], "entities": []}, {"text": "We calculated the four parameter values, ACC, F-score, MRR and MAP_ref, according to the four official evaluation standards.", "labels": [], "entities": [{"text": "ACC", "start_pos": 41, "end_pos": 44, "type": "METRIC", "confidence": 0.9979487061500549}, {"text": "F-score", "start_pos": 46, "end_pos": 53, "type": "METRIC", "confidence": 0.9946804642677307}, {"text": "MRR", "start_pos": 55, "end_pos": 58, "type": "METRIC", "confidence": 0.9938616752624512}, {"text": "MAP_ref", "start_pos": 63, "end_pos": 70, "type": "METRIC", "confidence": 0.9629295070966085}]}, {"text": "The experimental results are shown in.", "labels": [], "entities": []}, {"text": "Standard training set evaluation results In, we found that the effect of English-Chinese transliteration is better than the Chinese-English transliteration.", "labels": [], "entities": []}, {"text": "The effect of English-Chinese transliteration is better than the Chinese-English transliteration, which shows that segmentation of syllable is more reasonable for preprocessing when the source language is English, and preprocessing method of Chinese needs to be improved.", "labels": [], "entities": []}, {"text": "We added the English-Chinese and ChineseEnglish named entities drawn from the Wikipedia to the training set, and evaluate the official test sets by the expanded training set as non-Standard training set.", "labels": [], "entities": []}, {"text": "We calculated the four official parameter values likewise and experimental results are shown in. that the results of the evaluation on the non-Standard training set have promotion over that on the Standard training set.", "labels": [], "entities": [{"text": "Standard training set", "start_pos": 197, "end_pos": 218, "type": "DATASET", "confidence": 0.8771788279215494}]}, {"text": "This suggests that increasing the training set has a positive influence on improving the evaluating results.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 3 Standard training set evaluation results", "labels": [], "entities": []}]}