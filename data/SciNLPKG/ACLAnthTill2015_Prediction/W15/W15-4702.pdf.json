{"title": [{"text": "Input Seed Features for Guiding the Generation Process: A Statistical Approach for Spanish", "labels": [], "entities": [{"text": "Guiding the Generation Process", "start_pos": 24, "end_pos": 54, "type": "TASK", "confidence": 0.8355357646942139}]}], "abstractContent": [{"text": "In this paper we analyse a statistical approach for generating Spanish sentences focused on the surface realisation stage guided by an input seed feature.", "labels": [], "entities": []}, {"text": "This seed feature can be anything such as a word, a phoneme, a sentiment, etc.", "labels": [], "entities": []}, {"text": "Our approach attempts to maximise the appearance of words with that seed feature along the sentence.", "labels": [], "entities": []}, {"text": "It follows three steps: first we train a language model over a corpus; then we obtain a bag of words having that concrete seed feature; and finally a sentence is generated based on both, the language model and the bag of words.", "labels": [], "entities": []}, {"text": "Depending on the selected seed feature, this kind of sentences can be useful fora wide range of applications.", "labels": [], "entities": []}, {"text": "In particular, we have fo-cused our experiments on generating sentences in order to reinforce the phoneme pronunciation for dyslalia disorder.", "labels": [], "entities": []}, {"text": "Automatic generated sentences have been evaluated manually obtaining good results in newly generated meaningful sentences.", "labels": [], "entities": []}], "introductionContent": [{"text": "The task of Natural Language Generation (NLG) comprises a wide range of subtasks which extend from an action planning until its execution.", "labels": [], "entities": [{"text": "Natural Language Generation (NLG)", "start_pos": 12, "end_pos": 45, "type": "TASK", "confidence": 0.8073237438996633}]}, {"text": "This subtasks are commonly viewed as a pipeline of three stages: document planning, microplanning and surface realisation).", "labels": [], "entities": []}, {"text": "The NLG can be applied to several fields, not only to the task of reporting, such as text simplification (, recommendation generation (), text summarisation ( or text that attempts to help people having any kind of disorders in therapies).", "labels": [], "entities": [{"text": "text simplification", "start_pos": 85, "end_pos": 104, "type": "TASK", "confidence": 0.7447009086608887}, {"text": "recommendation generation", "start_pos": 108, "end_pos": 133, "type": "TASK", "confidence": 0.7151538282632828}, {"text": "text summarisation", "start_pos": 138, "end_pos": 156, "type": "TASK", "confidence": 0.78384068608284}]}, {"text": "Despite the applicability of NLG, this is not a trivial task.", "labels": [], "entities": [{"text": "NLG", "start_pos": 29, "end_pos": 32, "type": "DATASET", "confidence": 0.771629273891449}]}, {"text": "There is still a lot of room for improvement, and small steps in this task would be useful for being integrated or applied in larger NLG or NLP systems.", "labels": [], "entities": []}, {"text": "Therefore, the main goal of this paper is to present and evaluate a statistical NLG approach for Spanish based on N-grams language models.", "labels": [], "entities": []}, {"text": "Our approach is focused on the surface realisation stage, and it is initially designed and tested for Spanish, but it can be extrapolated to other languages as it is statistical-based.", "labels": [], "entities": []}, {"text": "The novelty of this approach lies in its input data, which can be a concrete seed feature or aspect (communicative goal) that we will be used to guide the generation of the new sentence (i.e., for guiding the generation process).", "labels": [], "entities": []}, {"text": "This seed feature could be a word, a phoneme, a sentiment, etc.", "labels": [], "entities": []}, {"text": "This type of generated sentences can be useful in many different ways such as helping in therapies as has been outlined above.", "labels": [], "entities": []}, {"text": "Specifically, we have chosen stories generation as our experimental scenario, so that a person with dyslalia, a speech disorder that implies the inability of pronounce certain phonemes, can reinforce the pronunciation of several problematic phonemes through reading and repeating words.", "labels": [], "entities": [{"text": "stories generation", "start_pos": 29, "end_pos": 47, "type": "TASK", "confidence": 0.7176704406738281}]}, {"text": "So the aim of these sentences for dyslalia would be to contain a huge number of words with a concrete phoneme.", "labels": [], "entities": []}, {"text": "At this stage we are not exhaustively evaluating how syntactically and semantically correct a sentence is, but just whether to what extent a sentence fulfilling a communicative goal can be generated from a functional point of view.", "labels": [], "entities": []}, {"text": "We consider that the communicative goal of our experimental scenario is to teach how a phoneme should be pronounced, so, by repeating the desired phoneme along a sentence this goal can be reached.", "labels": [], "entities": []}, {"text": "Therefore, we will evaluate and analyse the output from our approach based on the seed feature appearance along the sentence and the sentence correctness.", "labels": [], "entities": []}, {"text": "The remainder of this paper is as follows.", "labels": [], "entities": []}, {"text": "Section 2 discusses some related work concerned with surface realisation statistical systems.", "labels": [], "entities": [{"text": "surface realisation statistical", "start_pos": 53, "end_pos": 84, "type": "TASK", "confidence": 0.8437995115915934}]}, {"text": "Section 3 presents our statistical approach for NLG based on seed features.", "labels": [], "entities": []}, {"text": "Section 4 shows the experimentation carried out over the approach.", "labels": [], "entities": []}, {"text": "In Section 5 the evaluation and the results obtained is discussed.", "labels": [], "entities": []}, {"text": "Section 6 presents the potentials and limitations of our approach.", "labels": [], "entities": []}, {"text": "Finally, section 7 draws some conclusions and outlines ideas for future work.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section we are going to discuss both the scenario, resources and tests performed to the approach.", "labels": [], "entities": []}, {"text": "We have performed several experiments dividing them in two groups that will be explained in more detail in the following paragraphs: \u2022 Preliminary experiments \u2022 Overgeneration experiments To determine the length of the sentences to be generated, the average sentence length of the corpus was computed (16 words), using also this value for our experiments.", "labels": [], "entities": []}, {"text": "This type of experiments were conducted in order to check if it was worthy to carry on with this statistical-based approach, employing bigrams and trigrams LM, and to what extent the approach's behavior could be affected by the inclusion (or not) of stopwords.", "labels": [], "entities": []}, {"text": "In addition, these experiments were carried outwith the default configuration of the approach and testing all the Spanish phonemes.", "labels": [], "entities": []}, {"text": "In this sense, we performed three types of experiments: \u2022 First experiment: we removed the stopwords from the generation approach but we did not remove them from the training corpus.", "labels": [], "entities": []}, {"text": "\u2022 Second experiment: we trained both LMs without stopwords, and consequently the generation was made without stopwords.", "labels": [], "entities": []}, {"text": "\u2022 Third experiment: we trained both LMs with stopwords and we also removed the words repetitions on the final sentence.", "labels": [], "entities": []}, {"text": "Furthermore, the stopwords were included in the final sentence.", "labels": [], "entities": []}, {"text": "This experiment was performed after checking the results from the preliminary experiments.", "labels": [], "entities": []}, {"text": "The main objective of this experiment was to test the overgeneration configuration of the approach with all the Spanish phonemes, and, check if it generates some meaningful sentences, as well as the most common types of errors.", "labels": [], "entities": []}, {"text": "In this section we report the results from our two types of experiments: preliminary and overgeneration experiments.", "labels": [], "entities": []}, {"text": "Furthermore, for the resulting generated sentences we made a manual analysis and evaluation.", "labels": [], "entities": []}, {"text": "With this evaluation we needed to check if there was any meaningful sentence, ensuring that the sentence contained at least one word with the concrete phoneme.", "labels": [], "entities": []}, {"text": "As previously explained in section 4.3.1, within these preliminary experiments we performed three types of tests regarding the approach behavior and the utilisation or not of stopwords.", "labels": [], "entities": []}, {"text": "Some sentences obtained from this test can be seen in the.", "labels": [], "entities": []}, {"text": "Concerning our first experiment, in many cases the approach did not find the next word and the generation ended before reaching the limit length of the sentence using both LMs, bigram and trigram.", "labels": [], "entities": []}, {"text": "This was due to the fact that there are verbs or words that only appears next to stopwords.", "labels": [], "entities": []}, {"text": "We also tested in this experiment that, when a stopword was found, the next function word returned the stopword accompanied with its next word, but the stopword was not included in the final sentence and it was only used for the next word prediction.", "labels": [], "entities": []}, {"text": "Yet still, most generated sentence were meaningless and presented quite a lot repetition.", "labels": [], "entities": [{"text": "repetition", "start_pos": 78, "end_pos": 88, "type": "METRIC", "confidence": 0.9507153034210205}]}, {"text": "As a result of our second experiment, the generated sentences tend to be a sequence of nouns, verbs and adjectives without any relation between them.", "labels": [], "entities": []}, {"text": "Finally, in our third experiment we observed that the generated sentences with trigrams ended with the special token end of sentence (</s>), containing at least one word with the phoneme, and some of them where meaningful sentences.", "labels": [], "entities": []}, {"text": "Regarding the bigrams generated ones, most of them contained a huge number of words with the phoneme but the words itself did not have any connection with each other.", "labels": [], "entities": []}, {"text": "Thanks to these results we found that our approach worked well in some cases and because of that we decided to try the overgeneration configuration of the approach.", "labels": [], "entities": []}, {"text": "In this case, the approach generated 208 sentences, which 119 of them contains the special token end of sentence (</s>).", "labels": [], "entities": []}, {"text": "All these sentences were generated from the bigram and trigram LMs, so it can occur that the same sentence could be generated by both LMs.", "labels": [], "entities": []}, {"text": "These sentences ended with the token (</s>) are important because they can be comparable to a complete sentence.", "labels": [], "entities": []}, {"text": "Of the 119 sentences generated containing the token (</s>), 95 of them are different.", "labels": [], "entities": []}, {"text": "This can be seen on.", "labels": [], "entities": []}, {"text": "We then focused the evaluation and analysis of our results on the sentences ending with the token (</s>).", "labels": [], "entities": []}, {"text": "This is because we consider these sentences as complete sentences being this token comparable to a full stop.", "labels": [], "entities": []}, {"text": "The statistics of were calculated according to the total number of different generated sentences ended with the token (</s>), 95 sentences.", "labels": [], "entities": []}, {"text": "In this Table we also include the comparative percentage regarding the total number of generated sentences, that is 208 sentences.", "labels": [], "entities": []}, {"text": "As we can see in this Table, the statistics of meaningful sentences are really encouraging.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Statistics of the generated sentences ended with (</s>)", "labels": [], "entities": []}, {"text": " Table 1: Statistics of the generated sentences from  the overgeneration configuration", "labels": [], "entities": []}, {"text": " Table 3: Common types of generated sentences errors", "labels": [], "entities": []}]}