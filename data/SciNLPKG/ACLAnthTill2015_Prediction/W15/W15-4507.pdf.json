{"title": [{"text": "Storylines for structuring massive streams of news", "labels": [], "entities": []}], "abstractContent": [{"text": "Stories are the most natural ways for people to deal with information about the changing world.", "labels": [], "entities": []}, {"text": "They provide an efficient schematic structure to order and relate events according to some explanation.", "labels": [], "entities": []}, {"text": "We describe (1) a formal model for representing storylines to handle streams of news and (2) a first implementation of a system that automatically extracts the ingredients of a storyline from news articles according to the model.", "labels": [], "entities": []}, {"text": "Our model mimics the basic notions from narratology by adding bridging relations to timelines of events in relation to a climax point.", "labels": [], "entities": []}, {"text": "We provide a method for defining the climax score of each event and the bridging relations between them.", "labels": [], "entities": [{"text": "climax score", "start_pos": 37, "end_pos": 49, "type": "METRIC", "confidence": 0.9626310467720032}]}, {"text": "We generate a JSON structure for any set of news articles to represent the different stories they contain and visualize these stories on a timeline with climax and bridging relations.", "labels": [], "entities": []}, {"text": "This visual-ization helps inspecting the validity of the generated structures.", "labels": [], "entities": []}], "introductionContent": [{"text": "News is published as a continuous stream of information in which people reflect on the changes in the world.", "labels": [], "entities": []}, {"text": "The information that comes in is often partial, repetitive and, sometimes, contradictory.", "labels": [], "entities": []}, {"text": "Human readers of the news trace information on a day today basis to buildup a story overtime.", "labels": [], "entities": []}, {"text": "When creating this story, they integrate the incoming information with the known, remove duplication, resolve conflicts and order relevant events in time.", "labels": [], "entities": []}, {"text": "People also create an explanatory and causal scheme for what happened and relate the actors involved to these schemes.", "labels": [], "entities": []}, {"text": "Obviously, humans are limited in the amount of news that they can digest and integrate in their minds.", "labels": [], "entities": []}, {"text": "Even though they may remember very well the main structure of the story, they cannot remember all the details nor the sources from which they obtained the story.", "labels": [], "entities": []}, {"text": "Estimates are that on a single working day, millions of news articles are published.", "labels": [], "entities": []}, {"text": "Besides the fact that the data is massive, the information is also complex and dynamic.", "labels": [], "entities": []}, {"text": "Current search-based solutions and also topic tracking systems (Google trends, Twitter trends, EMM Newsbrief 1 , Yahoo news) can point the reader/user to important news but they cannot organize the news as a story as humans tend to do: deduplicating, aggregating, ordering in time, resolving conflicts and providing an explanatory scheme.", "labels": [], "entities": [{"text": "EMM Newsbrief 1", "start_pos": 95, "end_pos": 110, "type": "DATASET", "confidence": 0.9348939657211304}]}, {"text": "In this paper, we present a formal model for representing time series of events as storylines and an implementation to extract data for this model from massive streams of news.", "labels": [], "entities": []}, {"text": "Our formal model represents events and participants as instances with pointers to the mentions in the different sources.", "labels": [], "entities": []}, {"text": "Furthermore, events are anchored in time and relative to each other, resulting in timelines of events.", "labels": [], "entities": []}, {"text": "However, not every timeline is a storyline.", "labels": [], "entities": []}, {"text": "We therefore use event relations (bridging relations) and event salience to approximate the fabula, or plot structure, where the most salient event (the climax of the storyline) is preceded and followed by events that explain it.", "labels": [], "entities": []}, {"text": "Our implementation of the storyline extraction module is built on top of an NLP pipeline for processing text that results in a basic timeline structure.", "labels": [], "entities": [{"text": "storyline extraction", "start_pos": 26, "end_pos": 46, "type": "TASK", "confidence": 0.8497658669948578}]}, {"text": "The remainder of this paper is structured as follows.", "labels": [], "entities": []}, {"text": "In Section 2, we present the theoretical background based on narratology frameworks which inspired our model described in Section 3.", "labels": [], "entities": []}, {"text": "Section 4, then, explains our system for extracting storyline data from news streams according to the model.", "labels": [], "entities": [{"text": "extracting storyline data from news streams", "start_pos": 41, "end_pos": 84, "type": "TASK", "confidence": 0.8241397539774576}]}, {"text": "In Section 5, we report related works and highlight differences and similarities with respect to our system.", "labels": [], "entities": []}, {"text": "Finally, we discuss the status of our work, possible evaluation options and future work in Section 6.", "labels": [], "entities": [{"text": "Section 6", "start_pos": 91, "end_pos": 100, "type": "DATASET", "confidence": 0.8006570041179657}]}], "datasetContent": [{"text": "In this section we describe a first implementation of our model and its steps for the storyline generation: a.) timeline extraction; b.) climax event identification; c.) rising and falling actions identification.", "labels": [], "entities": [{"text": "storyline generation", "start_pos": 86, "end_pos": 106, "type": "TASK", "confidence": 0.7676871418952942}, {"text": "timeline extraction", "start_pos": 112, "end_pos": 131, "type": "TASK", "confidence": 0.7052582800388336}, {"text": "climax event identification", "start_pos": 137, "end_pos": 164, "type": "TASK", "confidence": 0.6280880471070608}, {"text": "rising and falling actions identification", "start_pos": 170, "end_pos": 211, "type": "TASK", "confidence": 0.7949131488800049}]}, {"text": "In this phase we are not yet able to provide an extensive evaluation of the system.", "labels": [], "entities": []}, {"text": "Evaluation methods for storylines are not trivial.", "labels": [], "entities": []}, {"text": "Most importantly, they cannot be evaluated with respect to standard measures such as Precision and Recall.", "labels": [], "entities": [{"text": "Precision", "start_pos": 85, "end_pos": 94, "type": "METRIC", "confidence": 0.9819095134735107}, {"text": "Recall", "start_pos": 99, "end_pos": 105, "type": "METRIC", "confidence": 0.9112666845321655}]}, {"text": "In this section, we describe and propose a set of evaluation methods to be used as a standard reference method for this kind of tasks.", "labels": [], "entities": []}, {"text": "The evaluation of a storyline must be based, at least, on two aspects: informativeness and interest.", "labels": [], "entities": []}, {"text": "A good storyline is a storyline which interest the user, provides all relevant and necessary information with respect to a target entity, and it is coherent.", "labels": [], "entities": []}, {"text": "We envisage two types of evaluation: direct and indirect.", "labels": [], "entities": []}, {"text": "Direct evaluation necessarily needs human interaction.", "labels": [], "entities": [{"text": "Direct evaluation", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.7015560865402222}]}, {"text": "This can be achieved in two methods: using experts and using crowdsourcing techniques.", "labels": [], "entities": []}, {"text": "Experts can evaluate the data provided with the storylines with respect to a set of reference documents and check the informativeness and coherence parameters.", "labels": [], "entities": []}, {"text": "Following (), two types of questions can be addressed at the microlevel and at the macro-level of knowledge.", "labels": [], "entities": []}, {"text": "Both evaluation types address the quality of the generated storylines.", "labels": [], "entities": []}, {"text": "The former addresses the efficiency of the storylines in retrieving the information while the latter addresses the quality of the storylines with respect to a certain topic (e.g. the commercial \"war\" between Boeing and Airbus).", "labels": [], "entities": []}, {"text": "Concerning metrics, micro-knowledge can be measured by the time the users need to gather the information, while the macro-knowledge can be measured as the text proportion, i.e. how many sentences of the source documents composing the storyline are used to write a short summary.", "labels": [], "entities": []}, {"text": "Crowdsourcing can be used to evaluate the storylines by means of simplified tasks.", "labels": [], "entities": []}, {"text": "One task can ask the crowd to identify salient events in a corpus and then validate if the identified events correlate with the climax events of the storylines.", "labels": [], "entities": []}, {"text": "Indirect evaluation can be based on a crossdocument Summarization tasks.", "labels": [], "entities": []}, {"text": "The ideal situation is the one in which the storyline contains the most salient and related events.", "labels": [], "entities": []}, {"text": "These sets of data can be used either to recover the sentences in a collection of documents and generate an extractive summary (story) or used to produce an abstractive summary.", "labels": [], "entities": []}, {"text": "Summarization measures such as ROUGE can then be used to evaluate the quality of summaries and, indirectly, of the storylines ().", "labels": [], "entities": [{"text": "ROUGE", "start_pos": 31, "end_pos": 36, "type": "METRIC", "confidence": 0.9974498152732849}]}], "tableCaptions": []}