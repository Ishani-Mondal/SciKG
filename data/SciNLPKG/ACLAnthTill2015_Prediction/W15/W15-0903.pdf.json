{"title": [{"text": "How to Account for Idiomatic German Support Verb Constructions in Statistical Machine Translation", "labels": [], "entities": [{"text": "Idiomatic German Support Verb Constructions", "start_pos": 19, "end_pos": 62, "type": "TASK", "confidence": 0.5286879599094391}, {"text": "Statistical Machine Translation", "start_pos": 66, "end_pos": 97, "type": "TASK", "confidence": 0.7299466927846273}]}], "abstractContent": [{"text": "Support-verb constructions (i.e., multiword expressions combining a semantically light verb with a predicative noun) are problematic for standard statistical machine translation systems, because SMT systems cannot distinguish between literal and idiomatic uses of the verb.", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 146, "end_pos": 177, "type": "TASK", "confidence": 0.6296047667662302}, {"text": "SMT", "start_pos": 195, "end_pos": 198, "type": "TASK", "confidence": 0.9882688522338867}]}, {"text": "We work on the German to English translation direction, for which the identification of support-verb constructions is challenging due to the relatively free word order of German.", "labels": [], "entities": []}, {"text": "We show that we achieve improved translation quality for verb-object support-verb constructions by marking the verbs when occuring in such constructions.", "labels": [], "entities": []}, {"text": "Additional evaluations revealed that our systems produce more correct verb translations than a con-trastive baseline system without verb markup.", "labels": [], "entities": []}], "introductionContent": [{"text": "It is widely acknowledged in the NLP community that multiword expressions (MWEs) area challenge for many NLP applications (), due to their idiosyncratic behaviour at different levels of linguistic description.", "labels": [], "entities": []}, {"text": "In this paper we address German support verb constructions (SVCs) in statistical machine translation.", "labels": [], "entities": [{"text": "German support verb constructions (SVCs)", "start_pos": 25, "end_pos": 65, "type": "TASK", "confidence": 0.6645377491201673}, {"text": "statistical machine translation", "start_pos": 69, "end_pos": 100, "type": "TASK", "confidence": 0.6809861660003662}]}, {"text": "Support-verb constructions, also known as lightverb constructions, 2 are multiword expressions combining a verb and a predicative noun.", "labels": [], "entities": []}, {"text": "The verb neither contributes its full meaning to the construction, nor is the meaning completely void (Butt, The work presented in this paper is part of the Master's Thesis of Manju Nirmal, cf..", "labels": [], "entities": []}], "datasetContent": [{"text": "Based on the ranked list of verbobject pairs by a word association measure, we decided to investigate different thresholds to the loglikelihood scores in order to identify idiomatic SVCs among the set of verb-object pairs and thus approximate different degrees of idiomaticity.", "labels": [], "entities": []}, {"text": "We set these thresholds at log-likelihood scores of 1,000, 500,  350 and 250.", "labels": [], "entities": []}, {"text": "Note that the degree of idiomaticity decreases with the loglikelihood score, while the amount of noise inform of literal verb-object pairs being erroneosly taken for SVCs increases.", "labels": [], "entities": []}, {"text": "Nevertheless, we performed no manual cleaning of these lists.", "labels": [], "entities": []}, {"text": "According to the various thresholds, we obtained different sets of presumably idiomatic verbobject pairs to be marked for the SMT system, and all pairs occurring in the sets are considered SVCs.", "labels": [], "entities": [{"text": "SMT", "start_pos": 126, "end_pos": 129, "type": "TASK", "confidence": 0.9871466159820557}]}, {"text": "shows the number of all extracted verbobject pairs from the German part of the parallel data, and the number of pairs with a freqency \u2265 5.", "labels": [], "entities": [{"text": "freqency", "start_pos": 125, "end_pos": 133, "type": "METRIC", "confidence": 0.9963290095329285}]}, {"text": "Note that we discarded verb-object pairs with a frequency < 5 as we consider these to be too sparse to be translated adequately by an SMT system.", "labels": [], "entities": [{"text": "SMT", "start_pos": 134, "end_pos": 137, "type": "TASK", "confidence": 0.9832642674446106}]}, {"text": "also shows the sizes of the resulting sets of SVCs, both for the training data and the test data.", "labels": [], "entities": []}, {"text": "In order to assess the impact of our SVC verb markup, we trained one baseline SMT system without markup and 4 different systems with our markup (one for each idiomaticity threshold, cf.).", "labels": [], "entities": [{"text": "SMT", "start_pos": 78, "end_pos": 81, "type": "TASK", "confidence": 0.9664840698242188}]}, {"text": "Each of our SMT experiments consists of the following steps: 1.", "labels": [], "entities": [{"text": "SMT", "start_pos": 12, "end_pos": 15, "type": "TASK", "confidence": 0.9931145310401917}]}, {"text": "add SVC verb markup to the parallel training data (as described in Section 4) 2.", "labels": [], "entities": []}, {"text": "train the SMT system, including word alignment, construction of a phrase-table and a reordering table 3.", "labels": [], "entities": [{"text": "SMT", "start_pos": 10, "end_pos": 13, "type": "TASK", "confidence": 0.9862349629402161}, {"text": "word alignment", "start_pos": 32, "end_pos": 46, "type": "TASK", "confidence": 0.7835391461849213}]}, {"text": "tune translation parameters using minimun error rate training 4.", "labels": [], "entities": []}, {"text": "translate the test set and evaluate the output against one human reference translation In the following we give details on the data sets we used and some further technical details on our SMT systems.", "labels": [], "entities": [{"text": "SMT", "start_pos": 187, "end_pos": 190, "type": "TASK", "confidence": 0.9896565675735474}]}, {"text": "Apart from differing SVC verb markup, all systems are trained identically.", "labels": [], "entities": [{"text": "SVC verb markup", "start_pos": 21, "end_pos": 36, "type": "TASK", "confidence": 0.7044711709022522}]}, {"text": "In order to evaluate the translation quality of our systems in comparison to each other and also to a baseline without any markup, we performed a standard MT evaluation using the BLEU metric.", "labels": [], "entities": [{"text": "MT", "start_pos": 155, "end_pos": 157, "type": "TASK", "confidence": 0.9715828895568848}, {"text": "BLEU", "start_pos": 179, "end_pos": 183, "type": "METRIC", "confidence": 0.9925099611282349}]}, {"text": "In addition, we also performed a semi-automatic evaluation with a focus on verb translations.", "labels": [], "entities": [{"text": "verb translations", "start_pos": 75, "end_pos": 92, "type": "TASK", "confidence": 0.7108880579471588}]}, {"text": "It is common practise to evaluate the performance of an SMT system by comparing its output to one (or more) human reference translations.", "labels": [], "entities": [{"text": "SMT", "start_pos": 56, "end_pos": 59, "type": "TASK", "confidence": 0.9928207993507385}]}, {"text": "We follow this line and calculate BLEU scores () for each of our systems.", "labels": [], "entities": [{"text": "BLEU scores", "start_pos": 34, "end_pos": 45, "type": "METRIC", "confidence": 0.9793610572814941}]}, {"text": "Our testset is taken from the 2014 shared task on statistical machine translation (\u223c 3,000 words).", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 50, "end_pos": 81, "type": "TASK", "confidence": 0.689065416653951}]}, {"text": "We tested all BLEU scores for statistical significance using pairwise bootstrap resampling with sample size 1,000 and a p-value of 0.05 . Results are givenin.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 14, "end_pos": 18, "type": "METRIC", "confidence": 0.9971645474433899}]}, {"text": "Compared to the baseline, we found that all of our systems containing verb markup for SVC verbs lead to a significant improvement in terms of BLEU.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 142, "end_pos": 146, "type": "METRIC", "confidence": 0.9984295964241028}]}, {"text": "The fact that all investigated sets of automatically identified SVCs improve the translation quality in the same magnitude shows that no manual filtering Code to be obtained from www.ark.cs.smu.edu/MT System # sentences with at least one full verb 2,411: Number of sentences produced by the systems, which contain at least one full verb. of the SVC sets is required to improve translation quality.", "labels": [], "entities": []}, {"text": "Even though the sets certainly contain literal verb-object pairs, their markup does not seem to decrease translation quality.", "labels": [], "entities": []}, {"text": "In future experiemnts, we will investigate the effect of manual filtering the SVC lists on translation quality.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 5: Number of SVCs in the training data and test set  when applying different log-likelihood (LL) thresholds.", "labels": [], "entities": [{"text": "log-likelihood (LL) thresholds", "start_pos": 84, "end_pos": 114, "type": "METRIC", "confidence": 0.7328604578971862}]}, {"text": " Table 7: BLEU scores on the 2014 testset.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.997340977191925}, {"text": "2014 testset", "start_pos": 29, "end_pos": 41, "type": "DATASET", "confidence": 0.9287071526050568}]}, {"text": " Table 9.  It can be seen that, compared to the baseline, our  system yields more verbs that match the reference  translation on lemma level (3,648 vs. 3,505", "labels": [], "entities": []}, {"text": " Table 9: Overview of verb counts. 'X' indicates a verb  matching the reference verb on lemma-level.", "labels": [], "entities": []}]}