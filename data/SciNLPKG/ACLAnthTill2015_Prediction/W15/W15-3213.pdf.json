{"title": [{"text": "Multi-Reference Evaluation for Dialectal Speech Recognition System: A Study for Egyptian ASR", "labels": [], "entities": [{"text": "Dialectal Speech Recognition", "start_pos": 31, "end_pos": 59, "type": "TASK", "confidence": 0.6090716123580933}, {"text": "ASR", "start_pos": 89, "end_pos": 92, "type": "TASK", "confidence": 0.7336342930793762}]}], "abstractContent": [{"text": "Dialectal Arabic has no standard ortho-graphic representation.", "labels": [], "entities": []}, {"text": "This creates a challenge when evaluating an Automatic Speech Recognition (ASR) system for dialect.", "labels": [], "entities": [{"text": "Automatic Speech Recognition (ASR)", "start_pos": 44, "end_pos": 78, "type": "TASK", "confidence": 0.7391478916009268}]}, {"text": "Since the reference transcription text can vary widely from one user to another , we propose an innovative approach for evaluating dialectal speech recognition using Multi-References.", "labels": [], "entities": [{"text": "dialectal speech recognition", "start_pos": 131, "end_pos": 159, "type": "TASK", "confidence": 0.6831998030344645}]}, {"text": "For each recognized speech segments, we ask five different users to transcribe the speech.", "labels": [], "entities": []}, {"text": "We combine the alignment for the multiple references, and use the combined alignment to report a modified version of Word Error Rate (WER).", "labels": [], "entities": [{"text": "Word Error Rate (WER)", "start_pos": 117, "end_pos": 138, "type": "METRIC", "confidence": 0.8355970730384191}]}, {"text": "This approach is in favor of accepting a recognized word if any of the references typed it in the same form.", "labels": [], "entities": []}, {"text": "Our method proved to be more effective in capturing many correctly recognized words that have multiple acceptable spellings.", "labels": [], "entities": []}, {"text": "The initial WER according to each of the five references individually ranged between 76.4% to 80.9%.", "labels": [], "entities": [{"text": "initial", "start_pos": 4, "end_pos": 11, "type": "METRIC", "confidence": 0.9834262132644653}, {"text": "WER", "start_pos": 12, "end_pos": 15, "type": "METRIC", "confidence": 0.8565019965171814}]}, {"text": "When considering all references combined, the Multi-References MR-WER was found to be 53%.", "labels": [], "entities": [{"text": "MR-WER", "start_pos": 63, "end_pos": 69, "type": "METRIC", "confidence": 0.6323904395103455}]}], "introductionContent": [{"text": "Arabic Automatic Speech Recognition (ASR) is a challenging task because of the lexical variety and data sparseness of the language.", "labels": [], "entities": [{"text": "Arabic Automatic Speech Recognition (ASR)", "start_pos": 0, "end_pos": 41, "type": "TASK", "confidence": 0.6884691502366748}]}, {"text": "Arabic can be considered one of the most morphologically complex languages).", "labels": [], "entities": []}, {"text": "With more than 300 million people speaking Arabic as a mother tongue, it is counted as the fifth most widely spoken language.", "labels": [], "entities": []}, {"text": "Modern Standard Arabic (MSA) is the official language amongst Arabic native speakers.", "labels": [], "entities": [{"text": "Modern Standard Arabic (MSA)", "start_pos": 0, "end_pos": 28, "type": "DATASET", "confidence": 0.8511400123437246}]}, {"text": "In fact, MSA is used informal events, such as newspapers, formal speech, and broadcast news.", "labels": [], "entities": []}, {"text": "Nevertheless, MSA is rarely used in day-today communication.", "labels": [], "entities": []}, {"text": "The vast majority of Arabic speakers use Dialectal Arabic (DA) in everyday communication).", "labels": [], "entities": []}, {"text": "DA has many differences from MSA in morphology, phonology and the lexicon.", "labels": [], "entities": []}, {"text": "A significant challenge in dialectal speech recognition is diglossia, in which the written language differs considerably from the spoken vernaculars ().", "labels": [], "entities": [{"text": "dialectal speech recognition", "start_pos": 27, "end_pos": 55, "type": "TASK", "confidence": 0.712305466334025}]}, {"text": "Variance among different Arabic dialects such as Egyptian, Levantine or Gulf has been considered similar to the variance among Romance languages).", "labels": [], "entities": []}, {"text": "There are many varieties of dialectal Arabic distributed over the 22 Arabic countries, often several variants of the Arabic language within the same country.", "labels": [], "entities": []}, {"text": "In natural language processing (NLP), researchers have aggregated dialectal Arabic into four regional language groups: Egyptian, Maghrebi, Gulf (Arabian Peninsula), and Levantine (.", "labels": [], "entities": [{"text": "natural language processing (NLP)", "start_pos": 3, "end_pos": 36, "type": "TASK", "confidence": 0.8373028934001923}]}, {"text": "Most ASR systems are trained and tuned by minimizing WER, which counts word errors at the surface level.", "labels": [], "entities": [{"text": "ASR", "start_pos": 5, "end_pos": 8, "type": "TASK", "confidence": 0.9906378984451294}, {"text": "WER", "start_pos": 53, "end_pos": 56, "type": "METRIC", "confidence": 0.9800806045532227}]}, {"text": "It does not consider the contextual and syntactic roles of a word, which are often critical for tasks like Machine Translation (MT), particularly in the end-to-end Speech Translation (ST) scenarios.", "labels": [], "entities": [{"text": "Machine Translation (MT)", "start_pos": 107, "end_pos": 131, "type": "TASK", "confidence": 0.8541577935218811}, {"text": "end-to-end Speech Translation (ST)", "start_pos": 153, "end_pos": 187, "type": "TASK", "confidence": 0.8063362787167231}]}, {"text": "Ina study by) , they showed that WER is not the optimal metric fora speech recognizer trained fora speech translation task.", "labels": [], "entities": [{"text": "WER", "start_pos": 33, "end_pos": 36, "type": "METRIC", "confidence": 0.9897128343582153}, {"text": "speech translation task", "start_pos": 99, "end_pos": 122, "type": "TASK", "confidence": 0.8048815727233887}]}, {"text": "They developed a BLEU-optimized approach for training the scale parameters of a log-linear based speech translation system.", "labels": [], "entities": [{"text": "BLEU-optimized", "start_pos": 17, "end_pos": 31, "type": "METRIC", "confidence": 0.9962508082389832}, {"text": "speech translation", "start_pos": 97, "end_pos": 115, "type": "TASK", "confidence": 0.7623616755008698}]}, {"text": "In their study, they got better results using the new measure, although WER were found to be higher in the intermediate step of the speech recognition.", "labels": [], "entities": [{"text": "WER", "start_pos": 72, "end_pos": 75, "type": "METRIC", "confidence": 0.9994889497756958}, {"text": "speech recognition", "start_pos": 132, "end_pos": 150, "type": "TASK", "confidence": 0.8059764802455902}]}, {"text": "Dialectal Arabic can be viewed as an example of a language with no orthographic rules, since there is no academies in DA nor enough amount of language resources, such as no standard lexicon or clear rules for writing.", "labels": [], "entities": [{"text": "DA", "start_pos": 118, "end_pos": 120, "type": "DATASET", "confidence": 0.8286049365997314}]}, {"text": "Ina study by) in which they presented Conventional Orthography for Dialectal Arabic CODA, they explain the design principles of CODA and provide description of CODA, and use the Egyptian dialect as an example, which has been presented mainly for the purpose of developing DA computational models.", "labels": [], "entities": []}, {"text": "Ina similar study by), they studied the best practices for writing Egyptian orthography.", "labels": [], "entities": []}, {"text": "They conducted experiments on both Acoustic Model (AM), Language Model (LM), and guidelines for transcribing Egyptian speech.", "labels": [], "entities": [{"text": "transcribing Egyptian speech", "start_pos": 96, "end_pos": 124, "type": "TASK", "confidence": 0.8744639952977499}]}, {"text": "They released guidelines for transcribing Egyptian speech for what is called augmented Conventional Orthography for Dialectal Arabic augmented-CODA.", "labels": [], "entities": []}, {"text": "They also reported gain in Egyptian speech recognition when augmented-CODA is followed in transcribing Egyptian speech data.", "labels": [], "entities": [{"text": "Egyptian speech recognition", "start_pos": 27, "end_pos": 54, "type": "TASK", "confidence": 0.6593715647856394}]}, {"text": "Unlike previous work by), where they studied the best practices for writing DA, in this paper, we propose an evaluation method that accepts the variations in transcribing dialectal Arabic.", "labels": [], "entities": [{"text": "writing DA", "start_pos": 68, "end_pos": 78, "type": "TASK", "confidence": 0.6917916238307953}]}, {"text": "We use multiple references, up to five different transcriptions per utterance, to evaluate the performance of the speech recognition engine.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 114, "end_pos": 132, "type": "TASK", "confidence": 0.7987845242023468}]}, {"text": "The main idea is to learn from the crowd and use multi-references to vote for each word in the recognized output.", "labels": [], "entities": []}, {"text": "This is, in away, similar to BLUE score used in MT, where multiple translation could be accepted for one source sentence.", "labels": [], "entities": [{"text": "BLUE score", "start_pos": 29, "end_pos": 39, "type": "METRIC", "confidence": 0.9854165613651276}, {"text": "MT", "start_pos": 48, "end_pos": 50, "type": "TASK", "confidence": 0.9163616299629211}]}, {"text": "Here, we submit our speech data on a crowdsourcing platform, and ask for five different transcriptions for each speech segment.", "labels": [], "entities": []}, {"text": "These five transcriptions typically capture the different acceptable variations of the Arabic dialect, where we then use them as our multiple references to calculate multi-reference WER (MR-WER).", "labels": [], "entities": [{"text": "WER", "start_pos": 182, "end_pos": 185, "type": "METRIC", "confidence": 0.6856695413589478}, {"text": "MR-WER", "start_pos": 187, "end_pos": 193, "type": "METRIC", "confidence": 0.757510781288147}]}, {"text": "The rest of the paper is organized as follows: In section 2, we describe dialectal speech recognition; section 3, we discuss the details of the multireference WER, and the proposed method evaluate dialectal ASR; section 4, we elaborate the data used in this experiment; section 5, we discuss the experiment and the results; and section 6 is for conclusion and future work.", "labels": [], "entities": [{"text": "dialectal speech recognition", "start_pos": 73, "end_pos": 101, "type": "TASK", "confidence": 0.7364899516105652}, {"text": "WER", "start_pos": 159, "end_pos": 162, "type": "METRIC", "confidence": 0.7299670577049255}]}], "datasetContent": [{"text": "One of the tasks that uses multi-reference evaluation is Machine Translation (MT).", "labels": [], "entities": [{"text": "Machine Translation (MT)", "start_pos": 57, "end_pos": 81, "type": "TASK", "confidence": 0.864730703830719}]}, {"text": "The main reason here is that many translations in the target language are fully valid fora given sentence in the source language.", "labels": [], "entities": []}, {"text": "Thus, the MT research community found it more appropriate when evaluating an MT system to compare the automatic translation to more than one possible manual reference translations, typically translated by different language experts, to have a less biased evaluation to one translation.", "labels": [], "entities": [{"text": "MT", "start_pos": 10, "end_pos": 12, "type": "TASK", "confidence": 0.971676230430603}, {"text": "MT", "start_pos": 77, "end_pos": 79, "type": "TASK", "confidence": 0.9313431978225708}]}, {"text": "Therefore, most of the MT evaluation scores are designed to accept multiple references ().", "labels": [], "entities": [{"text": "MT evaluation", "start_pos": 23, "end_pos": 36, "type": "TASK", "confidence": 0.8932061791419983}]}, {"text": "ASR is treated differently, since the speech recognition is seen to have a single exact match to a specific string, and one reference should be sufficient to transcribe or judge what is spoken in the speech segment.", "labels": [], "entities": [{"text": "ASR", "start_pos": 0, "end_pos": 3, "type": "TASK", "confidence": 0.9729431867599487}]}, {"text": "This assumption is valid inmost of the spoken languages.", "labels": [], "entities": []}, {"text": "However, for languages with no standard orthographic representation such as Dialectal Arabic, there are many different ways to write a given spoken word.", "labels": [], "entities": []}, {"text": "shows an example for an Egyptian speech segment, which presents the transcription of one soundtrack from four different transcribers.", "labels": [], "entities": []}, {"text": "As shown, many of the words presented has various spellings among the four transcribers.", "labels": [], "entities": []}, {"text": "In addition, there are some words that are written by some transcribers but neglected by the others, such as the word \" \"(Ah) and \" \"(yEny), that could be seen by some people as noise or filler and not worthy of writing.", "labels": [], "entities": []}, {"text": "The variations in spelling the same words are clear in the shown example, such as {\" \"(dh),\"\"(dA)} and {\" \"(AHnA),\" \"(nHn), \" \"(AHnA)}.", "labels": [], "entities": []}, {"text": "presents some additional samples of Arabic dialect words that have multiple acceptable spellings.", "labels": [], "entities": []}, {"text": "These examples illustrate the problem of comparing an ASR output to only one reference that picks one of many possible spellings of a dialect Arabic word.", "labels": [], "entities": [{"text": "ASR", "start_pos": 54, "end_pos": 57, "type": "TASK", "confidence": 0.9595544338226318}]}, {"text": "Accordingly, we propose introducing a multireference evaluation methodology for ASR tasks that targets languages with no standardized orthography.", "labels": [], "entities": [{"text": "ASR tasks", "start_pos": 80, "end_pos": 89, "type": "TASK", "confidence": 0.9409412741661072}]}, {"text": "Similar to BLEU score in MT, multireference increases the likelihood of accepting an automatic translation (speech recognition), if any of the manual translations (transcriptions) agreed with it in some portions.", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 11, "end_pos": 21, "type": "METRIC", "confidence": 0.9795184135437012}, {"text": "MT", "start_pos": 25, "end_pos": 27, "type": "TASK", "confidence": 0.9630337953567505}, {"text": "accepting an automatic translation (speech recognition)", "start_pos": 72, "end_pos": 127, "type": "TASK", "confidence": 0.6531294025480747}]}, {"text": "Our experiments are designed to address the following research questions: 1.", "labels": [], "entities": []}, {"text": "How many references should be used in the multi reference 2.", "labels": [], "entities": []}, {"text": "What is the inter-reference agreement?", "labels": [], "entities": []}, {"text": "How good is the crowdsource data?", "labels": [], "entities": []}, {"text": "Do we need to filter bad transcription for the MR-WER evaluation?", "labels": [], "entities": [{"text": "MR-WER", "start_pos": 47, "end_pos": 53, "type": "METRIC", "confidence": 0.5726032853126526}]}, {"text": "3. How many times do we need to see correct word to count it correct?", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Sample of phrases with multiple valid  spellings", "labels": [], "entities": [{"text": "Sample of phrases", "start_pos": 10, "end_pos": 27, "type": "TASK", "confidence": 0.8752915660540262}]}, {"text": " Table 5: Number of utterances per file after re- moving outlier transcriptions.", "labels": [], "entities": []}, {"text": " Table 6: MR-WER for counting correct once or  more.", "labels": [], "entities": [{"text": "MR-WER", "start_pos": 10, "end_pos": 16, "type": "METRIC", "confidence": 0.9976645708084106}, {"text": "counting correct once", "start_pos": 21, "end_pos": 42, "type": "METRIC", "confidence": 0.7161120076974233}]}]}