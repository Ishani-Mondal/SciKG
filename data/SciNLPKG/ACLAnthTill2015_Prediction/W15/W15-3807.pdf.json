{"title": [{"text": "Stacked Generalization for Medical Concept Extraction from Clinical Notes", "labels": [], "entities": [{"text": "Medical Concept Extraction", "start_pos": 27, "end_pos": 53, "type": "TASK", "confidence": 0.6654168963432312}]}], "abstractContent": [{"text": "The goal of our research is to extract medical concepts from clinical notes containing patient information.", "labels": [], "entities": []}, {"text": "Our research explores stacked generalization as a meta-learning technique to exploit a diverse set of concept extraction models.", "labels": [], "entities": [{"text": "stacked generalization", "start_pos": 22, "end_pos": 44, "type": "TASK", "confidence": 0.7892426252365112}, {"text": "concept extraction", "start_pos": 102, "end_pos": 120, "type": "TASK", "confidence": 0.7800416350364685}]}, {"text": "First, we create multiple models for concept extraction using a variety of information extraction techniques, including knowledge-based, rule-based, and machine learning models.", "labels": [], "entities": [{"text": "concept extraction", "start_pos": 37, "end_pos": 55, "type": "TASK", "confidence": 0.7539765536785126}, {"text": "information extraction", "start_pos": 75, "end_pos": 97, "type": "TASK", "confidence": 0.7441946566104889}]}, {"text": "Next, we train a meta-classifier using stacked generalization with a feature set generated from the outputs of the individual classifiers.", "labels": [], "entities": []}, {"text": "The meta-classifier learns to predict concepts based on information about the predictions of the component classifiers.", "labels": [], "entities": []}, {"text": "Our results show that the stacked generalization learner performs better than the individual models and achieves state-of-the-art performance on the 2010 i2b2 data set.", "labels": [], "entities": [{"text": "2010 i2b2 data set", "start_pos": 149, "end_pos": 167, "type": "DATASET", "confidence": 0.8643369227647781}]}], "introductionContent": [{"text": "Clinical notes (or electronic medical records) contain important medical information related to patient care management.", "labels": [], "entities": [{"text": "patient care management", "start_pos": 96, "end_pos": 119, "type": "TASK", "confidence": 0.6956511537233988}]}, {"text": "Health care professionals enter a patient's medical history and information about their care at a healthcare provider.", "labels": [], "entities": []}, {"text": "A patient's diseases, symptoms, treatments, and test results are often encoded in these notes in an unstructured manner.", "labels": [], "entities": []}, {"text": "In the last two decades, Natural Language Processing (NLP) techniques have been applied to clinical notes for medical concept extraction.", "labels": [], "entities": [{"text": "medical concept extraction", "start_pos": 110, "end_pos": 136, "type": "TASK", "confidence": 0.674875388542811}]}, {"text": "Medical concept extraction typically consists of two main steps: detection of the phrases that refer to medical entities, and classification of the semantic category for each detected medical entity.", "labels": [], "entities": [{"text": "Medical concept extraction", "start_pos": 0, "end_pos": 26, "type": "TASK", "confidence": 0.6456790467103323}]}, {"text": "Medical domain knowledge and sophisticated information extraction methods are required to achieve high levels of performance.", "labels": [], "entities": [{"text": "information extraction", "start_pos": 43, "end_pos": 65, "type": "TASK", "confidence": 0.7570765316486359}]}, {"text": "Medical concept extraction is a fundamental problem that can also serve as the steppingstone for higher level tasks, such as recognizing different types of relationships between pairs of medical concepts.", "labels": [], "entities": [{"text": "Medical concept extraction", "start_pos": 0, "end_pos": 26, "type": "TASK", "confidence": 0.6731915871302286}, {"text": "recognizing different types of relationships between pairs of medical concepts", "start_pos": 125, "end_pos": 203, "type": "TASK", "confidence": 0.6391537994146347}]}, {"text": "The main goal of our research is to explore the use of stacked generalization learning for the medical concept extraction task.", "labels": [], "entities": [{"text": "stacked generalization learning", "start_pos": 55, "end_pos": 86, "type": "TASK", "confidence": 0.6801117062568665}, {"text": "medical concept extraction task", "start_pos": 95, "end_pos": 126, "type": "TASK", "confidence": 0.7357971668243408}]}, {"text": "Stacked learning) is a meta-learning ensemblebased method that regulates the biases of multiple learners and integrates their diversities.", "labels": [], "entities": []}, {"text": "An ensemble of individual classifiers is created and then another classifier (the meta-classifier) sits on top of the ensemble and trains on the predictions of the component classifiers.", "labels": [], "entities": []}, {"text": "A key advantage of stacked generalization is that the meta-classifier learns how to weight and combine the predictions of the individual classifiers, allowing fora fully automated ensemble system.", "labels": [], "entities": []}, {"text": "New component classifiers can be easily added without the need for manual intervention.", "labels": [], "entities": []}, {"text": "Voting-based ensembles are another strategy for combing multiple classification models, and they often perform well.", "labels": [], "entities": []}, {"text": "But they can require manual adjustment of the voting threshold when new components are added, and they do not automatically learn how to weight different components.", "labels": [], "entities": []}, {"text": "Stacked generalization provides a more easily extensible and adaptable framework.", "labels": [], "entities": []}, {"text": "In the next sections, we discuss related work, describe our individual classifiers for medical concept extraction, and present the stacked generalization learning framework.", "labels": [], "entities": [{"text": "medical concept extraction", "start_pos": 87, "end_pos": 113, "type": "TASK", "confidence": 0.6096069912115732}]}, {"text": "Finally, we present experimental results on the 2010 i2b2 data set and compare our results with state-of-the-art systems.", "labels": [], "entities": [{"text": "2010 i2b2 data set", "start_pos": 48, "end_pos": 66, "type": "DATASET", "confidence": 0.8130145817995071}]}], "datasetContent": [{"text": "We present experimental results for each of our concept extraction components individually, as well as for each of the two ensemble methods: voting and stacked generalization learning.", "labels": [], "entities": [{"text": "concept extraction", "start_pos": 48, "end_pos": 66, "type": "TASK", "confidence": 0.7703602015972137}]}], "tableCaptions": [{"text": " Table 3: Recall (Rec), Precision (Pr), and F 1 score  (F) of each method on the 2010 i2b2 Challenge  test data.", "labels": [], "entities": [{"text": "Recall (Rec)", "start_pos": 10, "end_pos": 22, "type": "METRIC", "confidence": 0.9089962244033813}, {"text": "Precision (Pr)", "start_pos": 24, "end_pos": 38, "type": "METRIC", "confidence": 0.9671727418899536}, {"text": "F 1 score  (F)", "start_pos": 44, "end_pos": 58, "type": "METRIC", "confidence": 0.9599426587422689}, {"text": "2010 i2b2 Challenge  test data", "start_pos": 81, "end_pos": 111, "type": "DATASET", "confidence": 0.8543566823005676}]}, {"text": " Table 4: The ablation tests of Voting and Stacked Generalization Ensembles", "labels": [], "entities": [{"text": "ablation", "start_pos": 14, "end_pos": 22, "type": "METRIC", "confidence": 0.9479623436927795}, {"text": "Stacked Generalization Ensembles", "start_pos": 43, "end_pos": 75, "type": "TASK", "confidence": 0.6225275297959646}]}, {"text": " Table 5: Recall (Rec), Precision (Pr), and F 1  score (F) of other state-of-the-art systems and our  Stacked Ensemble.", "labels": [], "entities": [{"text": "Recall (Rec)", "start_pos": 10, "end_pos": 22, "type": "METRIC", "confidence": 0.9267942160367966}, {"text": "Precision (Pr)", "start_pos": 24, "end_pos": 38, "type": "METRIC", "confidence": 0.9674647599458694}, {"text": "F 1  score (F)", "start_pos": 44, "end_pos": 58, "type": "METRIC", "confidence": 0.9735371172428131}]}]}