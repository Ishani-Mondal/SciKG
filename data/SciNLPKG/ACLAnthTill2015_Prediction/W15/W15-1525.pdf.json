{"title": [{"text": "Vector Space and Language Models for Scientific Document Summarization", "labels": [], "entities": [{"text": "Scientific Document Summarization", "start_pos": 37, "end_pos": 70, "type": "TASK", "confidence": 0.7721602320671082}]}], "abstractContent": [{"text": "In this paper we compare the performance of three approaches for estimating the latent weights of terms for scientific document sum-marization, given the document and a set of citing documents.", "labels": [], "entities": []}, {"text": "The first approach is a term-frequency (TF) vector space method utilizing a nonnegative matrix factorization (NNMF) for dimensionality reduction.", "labels": [], "entities": []}, {"text": "The other two are language modeling approaches for predicting the term distributions of human-generated summaries.", "labels": [], "entities": [{"text": "predicting the term distributions of human-generated summaries", "start_pos": 51, "end_pos": 113, "type": "TASK", "confidence": 0.8048628057752337}]}, {"text": "The language model we build exploits the key sections of the document and a set of citing sentences derived from auxiliary documents that cite the document of interest.", "labels": [], "entities": []}, {"text": "The parameters of the model maybe set via a minimization of the Jensen-Shannon (JS) divergence.", "labels": [], "entities": []}, {"text": "We use the OCCAMS algorithm (Optimal Combinatorial Covering Algorithm for Multi-document Summarization) to select a set of sentences that maximizes the term-coverage score while minimizing redundancy.", "labels": [], "entities": [{"text": "Multi-document Summarization)", "start_pos": 74, "end_pos": 103, "type": "TASK", "confidence": 0.7784970800081888}]}, {"text": "The results are evaluated with standard ROUGE metrics, and the performance of the resulting methods achieve ROUGE scores exceeding those of the average human summa-rizer.", "labels": [], "entities": [{"text": "ROUGE", "start_pos": 108, "end_pos": 113, "type": "METRIC", "confidence": 0.9972660541534424}]}], "introductionContent": [{"text": "The volume of the scientific literature is vast and increasing.", "labels": [], "entities": []}, {"text": "It is commonly impossible for researchers to read all the papers published even in their own specialty, thus it is natural to apply text summarization methods to scientific literature.", "labels": [], "entities": [{"text": "text summarization", "start_pos": 132, "end_pos": 150, "type": "TASK", "confidence": 0.620048463344574}]}, {"text": "The problem we consider is to summarize a scientific paper that has been cited multiple times, given the paper (reference paper) and a set of citing papers.", "labels": [], "entities": []}, {"text": "Note that the citing papers give additional insights into the impact of the results presented in the original paper and also how the paper is perceived by colleagues.", "labels": [], "entities": []}, {"text": "Following the approach of, we use the citing papers to help inform the summary, but also build a language model to cover the major sections of the paper such as the abstract and the results sections.", "labels": [], "entities": []}, {"text": "Thus, we form a summary pooling information from the paper and how other authors citing the paper view the contributions of the paper.", "labels": [], "entities": []}, {"text": "The summarization system we consider for this task consists of the following components:", "labels": [], "entities": [{"text": "summarization", "start_pos": 4, "end_pos": 17, "type": "TASK", "confidence": 0.9586990475654602}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Vector Space Model based on TF and NNMF", "labels": [], "entities": [{"text": "NNMF", "start_pos": 45, "end_pos": 49, "type": "DATASET", "confidence": 0.6532170176506042}]}]}