{"title": [{"text": "Report of NEWS 2015 Machine Transliteration Shared Task", "labels": [], "entities": [{"text": "NEWS 2015 Machine Transliteration Shared Task", "start_pos": 10, "end_pos": 55, "type": "TASK", "confidence": 0.7711934546629587}]}], "abstractContent": [{"text": "This report presents the results from the Machine Transliteration Shared Task conducted as part of The Fifth Named Entities Workshop (NEWS 2015) held at ACL 2015 in Beijing, China.", "labels": [], "entities": [{"text": "Machine Transliteration Shared Task", "start_pos": 42, "end_pos": 77, "type": "TASK", "confidence": 0.8486943393945694}, {"text": "Fifth Named Entities Workshop (NEWS 2015) held at ACL 2015 in Beijing", "start_pos": 103, "end_pos": 172, "type": "TASK", "confidence": 0.5979100295475551}]}, {"text": "Similar to previous editions of NEWS Workshop, the Shared Task featured machine transliteration of proper names over 14 different language pairs, including 12 different languages and two different Japanese scripts.", "labels": [], "entities": [{"text": "machine transliteration of proper names", "start_pos": 72, "end_pos": 111, "type": "TASK", "confidence": 0.81409832239151}]}, {"text": "A total of 6 teams participated in the evaluation, submitting 194 standard and 12 non-standard runs, involving a diverse variety of translitera-tion methodologies.", "labels": [], "entities": []}, {"text": "Four performance metrics were used to report the evaluation results.", "labels": [], "entities": []}, {"text": "Once again, the NEWS shared task on machine transliteration has successfully achieved its objectives by providing a common ground for the research community to conduct comparative evaluations of state-of-the-art technologies that will benefit the future research and development in this area.", "labels": [], "entities": [{"text": "NEWS shared task", "start_pos": 16, "end_pos": 32, "type": "TASK", "confidence": 0.5483595530192057}, {"text": "machine transliteration", "start_pos": 36, "end_pos": 59, "type": "TASK", "confidence": 0.5974963158369064}]}], "introductionContent": [{"text": "Names play an important role in the performance of most Natural Language Processing (NLP) and Information Retrieval (IR) applications.", "labels": [], "entities": [{"text": "Information Retrieval (IR)", "start_pos": 94, "end_pos": 120, "type": "TASK", "confidence": 0.822630774974823}]}, {"text": "They are also critical in cross-lingual applications such as Machine Translation (MT) and Cross-language Information Retrieval (CLIR), as it has been shown that system performance correlates positively with the quality of name conversion across languages).", "labels": [], "entities": [{"text": "Machine Translation (MT)", "start_pos": 61, "end_pos": 85, "type": "TASK", "confidence": 0.8676328539848328}, {"text": "Cross-language Information Retrieval (CLIR)", "start_pos": 90, "end_pos": 133, "type": "TASK", "confidence": 0.7720605929692587}, {"text": "name conversion", "start_pos": 222, "end_pos": 237, "type": "TASK", "confidence": 0.7064500749111176}]}, {"text": "Bilingual dictionaries constitute the traditional source of information for name conversion across languages, however they offer very limited support due to the fact that, inmost languages, names are continuously emerging and evolving.", "labels": [], "entities": [{"text": "name conversion", "start_pos": 76, "end_pos": 91, "type": "TASK", "confidence": 0.7808976471424103}]}, {"text": "All of the above points to the critical need for robust Machine Transliteration methods and systems.", "labels": [], "entities": []}, {"text": "During the last decade, significant efforts has been conducted by the research community to address the problem of machine transliteration).", "labels": [], "entities": [{"text": "machine transliteration", "start_pos": 115, "end_pos": 138, "type": "TASK", "confidence": 0.7484261691570282}]}, {"text": "These previous works fall into three main categories: grapheme-based, phoneme-based and hybrid methods.", "labels": [], "entities": []}, {"text": "Grapheme based methods () treat transliteration as a direct orthographic mapping and only uses orthography-related features while phoneme-based methods make use of phonetic correspondences to generate the transliteration.", "labels": [], "entities": []}, {"text": "The hybrid approach refers to the combination of several different models or knowledge sources to support the transliteration generation process.", "labels": [], "entities": [{"text": "transliteration generation", "start_pos": 110, "end_pos": 136, "type": "TASK", "confidence": 0.8675634562969208}]}, {"text": "The first machine transliteration shared task () was organized and conducted as part of NEWS 2009 at ACL-IJCNLP 2009.", "labels": [], "entities": [{"text": "machine transliteration shared task", "start_pos": 10, "end_pos": 45, "type": "TASK", "confidence": 0.7798252552747726}, {"text": "NEWS 2009 at ACL-IJCNLP 2009", "start_pos": 88, "end_pos": 116, "type": "DATASET", "confidence": 0.741490113735199}]}, {"text": "It was the first time that common benchmarking data in diverse language pairs was provided for evaluating state-of-the-art machine transliteration.", "labels": [], "entities": []}, {"text": "While the focus of the 2009 shared task was on establishing the quality metrics and on setting up a baseline for transliteration quality based on those metrics, the 2010 shared task () focused on expanding the scope of the transliteration generation task to about a dozen languages and on exploring the quality of the task depending on the direction of transliteration.", "labels": [], "entities": [{"text": "transliteration generation task", "start_pos": 223, "end_pos": 254, "type": "TASK", "confidence": 0.8257994850476583}]}, {"text": "In NEWS 2011 (), the focus was on significantly increasing the hand-crafted parallel corpora of named entities to include 14 different language pairs from 11 language families, and on making them available as the common dataset for the shared task.", "labels": [], "entities": [{"text": "NEWS 2011", "start_pos": 3, "end_pos": 12, "type": "DATASET", "confidence": 0.9405198097229004}]}, {"text": "The NEWS 2015 Shared Task on Transliteration has been a continued effort for evaluating machine transliteration performance over such a common dataset following the NEWS 2012 () and 2011 shared tasks.", "labels": [], "entities": [{"text": "NEWS 2015 Shared Task on Transliteration", "start_pos": 4, "end_pos": 44, "type": "DATASET", "confidence": 0.8240361710389456}, {"text": "NEWS 2012", "start_pos": 165, "end_pos": 174, "type": "DATASET", "confidence": 0.9192938506603241}]}, {"text": "In this paper, we present in full detail the results of the NEWS 2015 Machine Transliteration Shared Task.", "labels": [], "entities": [{"text": "NEWS 2015 Machine Transliteration Shared Task", "start_pos": 60, "end_pos": 105, "type": "TASK", "confidence": 0.7070621947447459}]}, {"text": "The rest of the paper is structured as follows.", "labels": [], "entities": []}, {"text": "Section 2 provides as short review of the main characteristics of the machine transliteration task and the corpora used for it.", "labels": [], "entities": []}, {"text": "Section 3 reviews the four metrics used for the evaluations.", "labels": [], "entities": []}, {"text": "Section 4 reports specific details about participation in the 2015 edition of the shared task, and section 5 presents and discusses the evaluation results.", "labels": [], "entities": []}, {"text": "Finally, section 6 presents our main conclusions and future plans.", "labels": [], "entities": []}], "datasetContent": [{"text": "The participants have been asked to submit standard and, optionally, non-standard runs.", "labels": [], "entities": []}, {"text": "One of the standard runs must be named as the primary submission, which was the one used for the performance summary.", "labels": [], "entities": []}, {"text": "Each run must contain a ranked list of up to ten candidate transliterations for each source name.", "labels": [], "entities": []}, {"text": "The submitted results are compared to the ground truth (reference transliterations) using four evaluation metrics capturing different aspects of transliteration performance.", "labels": [], "entities": []}, {"text": "The four considered evaluation metrics are: \u2022 Word Accuracy in Top-1 (ACC), \u2022 Fuzziness in Top-1 (Mean F-score), \u2022 Mean Reciprocal Rank (MRR), and \u2022 Mean Average Precision (MAP ref ).", "labels": [], "entities": [{"text": "Word Accuracy in Top-1 (ACC)", "start_pos": 46, "end_pos": 74, "type": "METRIC", "confidence": 0.7367535148348127}, {"text": "Fuzziness in Top-1 (Mean F-score)", "start_pos": 78, "end_pos": 111, "type": "METRIC", "confidence": 0.7563697951180595}, {"text": "Mean Reciprocal Rank (MRR)", "start_pos": 115, "end_pos": 141, "type": "METRIC", "confidence": 0.9520292182763418}, {"text": "Mean Average Precision (MAP ref )", "start_pos": 149, "end_pos": 182, "type": "METRIC", "confidence": 0.9667903866086688}]}, {"text": "In the next subsections, we present a brief description of the four considered evaluation metrics.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Number of standard (Std) and non- standard (Non) runs submitted, and teams par- ticipating in each task.", "labels": [], "entities": [{"text": "par", "start_pos": 85, "end_pos": 88, "type": "METRIC", "confidence": 0.9706451892852783}]}]}