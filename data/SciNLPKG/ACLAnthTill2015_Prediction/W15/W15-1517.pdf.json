{"title": [{"text": "Word Embeddings vs Word Types for Sequence Labeling: the Curious Case of CV Parsing", "labels": [], "entities": [{"text": "Sequence Labeling", "start_pos": 34, "end_pos": 51, "type": "TASK", "confidence": 0.9159716069698334}, {"text": "CV Parsing", "start_pos": 73, "end_pos": 83, "type": "TASK", "confidence": 0.625357523560524}]}], "abstractContent": [{"text": "We explore new methods of improving Curriculum Vitae (CV) parsing for German documents by applying recent research on the application of word embeddings in Natural Language Processing (NLP).", "labels": [], "entities": [{"text": "Curriculum Vitae (CV) parsing for German documents", "start_pos": 36, "end_pos": 86, "type": "TASK", "confidence": 0.7135147518581815}]}, {"text": "Our approach integrates the word embeddings as input features fora probabilistic sequence labeling model that relies on the Conditional Random Field (CRF) framework.", "labels": [], "entities": []}, {"text": "Best-performing word em-beddings are generated from a large sample of German CVs.", "labels": [], "entities": []}, {"text": "The best results on the extraction task are obtained by the model which integrates the word embeddings together with a number of hand-crafted features.", "labels": [], "entities": []}, {"text": "The improvements are consistent throughout different sections of the target documents.", "labels": [], "entities": []}, {"text": "The effect of the word embeddings is strongest on semi-structured, out-of-sample data.", "labels": [], "entities": []}], "introductionContent": [{"text": "Curriculum Vitae (CV) parsing refers to the task of processing and transforming the relevant information contained in a given CV.", "labels": [], "entities": [{"text": "Curriculum Vitae (CV) parsing", "start_pos": 0, "end_pos": 29, "type": "TASK", "confidence": 0.5185598085323969}]}, {"text": "The goal is to produce structured output detailing the information presented in the document, including personal information, education items, work experience, or further skills.", "labels": [], "entities": []}, {"text": "CV Parsing is used in multiple real world scenarios.", "labels": [], "entities": [{"text": "CV Parsing", "start_pos": 0, "end_pos": 10, "type": "TASK", "confidence": 0.6655356585979462}]}, {"text": "Nowadays, job seekers are frequently presented with the option of simply uploading the required documents into an application system, which then automatically processes the data and directly uploads the candidate information into the corresponding databases.", "labels": [], "entities": []}, {"text": "Given structured information on the candidate, recruiters are able to quickly search for potential matches, and systems are enabled to generate personalized recommendations that meet the candidate's specific skill set.", "labels": [], "entities": []}, {"text": "CV Parsing poses an interesting challenge to modern Natural Language Processing (NLP) techniques, because the documents consist of a mixture of semi-structured and free form text with a high degree of variance in the data.", "labels": [], "entities": [{"text": "CV Parsing", "start_pos": 0, "end_pos": 10, "type": "TASK", "confidence": 0.663422018289566}]}, {"text": "The semi-structured text often takes the shape of attribute-value pairs.", "labels": [], "entities": []}, {"text": "Typical examples with regard to personal information would be Name: John Doe, or Phone: 212 / 123-5678.", "labels": [], "entities": [{"text": "Name: John Doe", "start_pos": 62, "end_pos": 76, "type": "DATASET", "confidence": 0.6739005148410797}, {"text": "Phone: 212 / 123-5678", "start_pos": 81, "end_pos": 102, "type": "DATASET", "confidence": 0.7719683051109314}]}, {"text": "A considerable portion of CVs contain personal information without any left context, e.g.", "labels": [], "entities": []}], "datasetContent": [{"text": "We start by describing our data sets in Section 5.1.", "labels": [], "entities": []}, {"text": "Section 5.2 details the feature set implemented in the models.", "labels": [], "entities": []}, {"text": "Section 5.3 provides details on the generating of the word embeddings, and Section 5.4 specifies the model evaluation.", "labels": [], "entities": []}, {"text": "We evaluate five models based on three different groups of features (cf.).", "labels": [], "entities": []}, {"text": "The first baseline model uses only the hand-crafted features.", "labels": [], "entities": []}, {"text": "We compare this baseline to two models which incorporate either a feature vector for the word types, or a feature vector for the word embeddings, respectively.", "labels": [], "entities": []}, {"text": "Finally, we combine the hand-crafted features with word types or word embeddings for two additional models.", "labels": [], "entities": []}, {"text": "Character-based overlap scores are computed for averaged precision, recall, and F1 scores to evaluate the performance of the models on personal and experience sections.", "labels": [], "entities": [{"text": "precision", "start_pos": 57, "end_pos": 66, "type": "METRIC", "confidence": 0.9706653952598572}, {"text": "recall", "start_pos": 68, "end_pos": 74, "type": "METRIC", "confidence": 0.9986445307731628}, {"text": "F1 scores", "start_pos": 80, "end_pos": 89, "type": "METRIC", "confidence": 0.9813293218612671}]}, {"text": "We use character-based overlap instead of token-based overlap scores to penalize the incorrect labeling of longer tokens.", "labels": [], "entities": []}, {"text": "Recall that our labeling always spans entire tokens.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Distribution of documents and personal  and experience entities over main set and  out-of-sample (OOS) dataset.", "labels": [], "entities": []}, {"text": " Table 2: Macro-averaged precision, recall, and F1 scores of the phrase models on the main test partition.", "labels": [], "entities": [{"text": "precision", "start_pos": 25, "end_pos": 34, "type": "METRIC", "confidence": 0.9782105088233948}, {"text": "recall", "start_pos": 36, "end_pos": 42, "type": "METRIC", "confidence": 0.9980541467666626}, {"text": "F1", "start_pos": 48, "end_pos": 50, "type": "METRIC", "confidence": 0.9997739195823669}]}, {"text": " Table 3: Experience phrase model performance on test partition and out-of-sample dataset.", "labels": [], "entities": []}]}