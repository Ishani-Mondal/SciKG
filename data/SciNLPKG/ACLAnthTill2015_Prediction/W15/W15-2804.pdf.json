{"title": [{"text": "Lingusitic Analysis of multi-modal Recurrent Neural Networks\u00b4Akos", "labels": [], "entities": []}], "abstractContent": [], "introductionContent": [{"text": "Recurrent neural networks (RNN) have gained a reputation for beating state-of-the-art results on many NLP benchmarks and for learning representations of words and larger linguistic units that encode complex syntactic and semantic structures.", "labels": [], "entities": [{"text": "Recurrent neural networks (RNN", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.701631498336792}]}, {"text": "However, it is not straight-forward to understand how exactly these models make their decisions.", "labels": [], "entities": []}, {"text": "Recently developed methods to provide linguistically motivated analysis for RNNs trained for sentiment analysis.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 93, "end_pos": 111, "type": "TASK", "confidence": 0.9605741500854492}]}, {"text": "Here we focus on the analysis of a multi-modal Gated Recurrent Neural Network (GRU) architecture trained to predict image-vectors -extracted from images using a CNN trained on ImageNet -from their corresponding descriptions.", "labels": [], "entities": []}, {"text": "We propose two methods to explore the importance of grammatical categories with respect to the model and the task.", "labels": [], "entities": []}, {"text": "We observe that the model pays most attention to head-words, noun subjects and adjectival modifiers and least to determiners and coordinations.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": []}