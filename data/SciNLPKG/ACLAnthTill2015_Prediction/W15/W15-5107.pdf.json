{"title": [{"text": "Qualitative investigation of the display of speech recognition results for communication with deaf people", "labels": [], "entities": [{"text": "display of speech recognition", "start_pos": 33, "end_pos": 62, "type": "TASK", "confidence": 0.667031541466713}]}], "abstractContent": [{"text": "Speech technologies provide ways of helping people with hearing loss by improving their autonomy.", "labels": [], "entities": []}, {"text": "This study focuses on an application in French language which is developed in the collaborative project RAPSODIE in order to improve communication between a hearing person and a deaf or hard-of-hearing person.", "labels": [], "entities": []}, {"text": "Our goal is to investigate different ways of displaying the speech recognition results which takes also into account the reliability of the recognized items.", "labels": [], "entities": [{"text": "displaying the speech recognition", "start_pos": 45, "end_pos": 78, "type": "TASK", "confidence": 0.6452939808368683}]}, {"text": "In this qualitative study, 10 persons have been interviewed to find the best way of displaying the speech transcription results.", "labels": [], "entities": [{"text": "speech transcription", "start_pos": 99, "end_pos": 119, "type": "TASK", "confidence": 0.6497732996940613}]}, {"text": "All the participants are deaf with different levels of hearing loss and various modes of communication.", "labels": [], "entities": []}], "introductionContent": [{"text": "In the world, there are millions of people with hearing loss (http://www.who.int/pbd/deafness/news/Millionslivewithheari ngloss.pdf; http://wfdeaf.org).", "labels": [], "entities": []}, {"text": "In France over 11% of people suffer from hearing loss which causes several other limitations that are persistent.", "labels": [], "entities": []}, {"text": "The sensory problems involve both perceptual, speech, cognitive and social difficulties.", "labels": [], "entities": []}, {"text": "The unemployment rate thus varies from 15 to 50% depending on the type of hearing loss.", "labels": [], "entities": [{"text": "unemployment rate", "start_pos": 4, "end_pos": 21, "type": "METRIC", "confidence": 0.9685349464416504}]}, {"text": "Deaf adults still have difficulties mastering French language, which is not considered, for some of them, as their native language.", "labels": [], "entities": []}, {"text": "Sign language may also not be considered as their native language and has no written modality.", "labels": [], "entities": []}, {"text": "The lack of oral interaction is repeated in many situations, even for those adults for whom hearing aids provide correction.", "labels": [], "entities": []}, {"text": "In working situations with hearing persons, deaf adults often have to be supported by others.", "labels": [], "entities": []}, {"text": "The long term goals of the Rapsodie project (http://erocca.com/rapsodie) are to facilitate the integration of deaf or hard-of-hearing people within a professional context thus aiding their independence, providing them ways of comprehension and communication with automatic speech transcription help.", "labels": [], "entities": []}, {"text": "Our research relates to an embedded system, used in a professional context which could help deaf or hard-of-hearing persons, employees, to interact with a speaking person, customer, without the help of an interpreter.", "labels": [], "entities": []}, {"text": "The speech recognition of the customer's utterance is displayed on the screen of the embedded terminal.", "labels": [], "entities": [{"text": "speech recognition of the customer's utterance", "start_pos": 4, "end_pos": 50, "type": "TASK", "confidence": 0.7908490129879543}]}, {"text": "The difficulty comes from the fact that speech transcription results contain recognition errors, especially if it is areal time process on a device with limited resources (CPU and memory) and in a noisy environment.", "labels": [], "entities": [{"text": "speech transcription", "start_pos": 40, "end_pos": 60, "type": "TASK", "confidence": 0.7316257357597351}]}, {"text": "As in many realwork conditions, the speech signal is overlapped with parasitic noise, undesired extra speech, or music.", "labels": [], "entities": []}, {"text": "These difficulties may impact the understanding processes.", "labels": [], "entities": [{"text": "understanding", "start_pos": 34, "end_pos": 47, "type": "TASK", "confidence": 0.9684240221977234}]}, {"text": "There has been many attempts to develop speech recognition appliances but to our knowledge, there is no suitable, validated and currently available screen display of the output of automatic speech recognizer for deaf or hard-of-hearing persons, in terms of size, colors and choice of the written symbols.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 40, "end_pos": 58, "type": "TASK", "confidence": 0.7225950360298157}]}, {"text": "It is the goal of this first qualitative study, taking account of the previously described technical constraints.", "labels": [], "entities": []}, {"text": "We interviewed deaf adults at working age, with different levels of hearing loss and various modalities of communication.", "labels": [], "entities": []}, {"text": "Our aim were both to study the feasibility of the project with deaf people of varying profiles, to investigate the more suitable display and to examine which factors the participants consider as being helpful fora better understanding of the speech transcription.", "labels": [], "entities": [{"text": "speech transcription", "start_pos": 242, "end_pos": 262, "type": "TASK", "confidence": 0.7126253843307495}]}, {"text": "In the following sections, the speech recognition system is described and then the different modalities chosen for displaying the recognition output.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 31, "end_pos": 49, "type": "TASK", "confidence": 0.7391062676906586}]}, {"text": "Afterwards, we focus on the experimental protocol results conducted with 10 deaf people, discussing how they can be accommodated in order to find the best display of the automatic speech transcription results.", "labels": [], "entities": [{"text": "automatic speech transcription", "start_pos": 170, "end_pos": 200, "type": "TASK", "confidence": 0.6870224475860596}]}], "datasetContent": [], "tableCaptions": []}