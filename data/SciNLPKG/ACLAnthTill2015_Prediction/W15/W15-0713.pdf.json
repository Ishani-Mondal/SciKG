{"title": [{"text": "Automated translation of a literary work: a pilot study", "labels": [], "entities": [{"text": "Automated translation of a literary work", "start_pos": 0, "end_pos": 40, "type": "TASK", "confidence": 0.9005625148614248}]}], "abstractContent": [{"text": "Current machine translation (MT) techniques are continuously improving.", "labels": [], "entities": [{"text": "machine translation (MT)", "start_pos": 8, "end_pos": 32, "type": "TASK", "confidence": 0.8695625066757202}]}, {"text": "In specific areas , post-editing (PE) can enable the production of high-quality translations relatively quickly.", "labels": [], "entities": []}, {"text": "But is it feasible to translate a literary work (fiction, short story, etc) using such an MT+PE pipeline?", "labels": [], "entities": [{"text": "translate a literary work (fiction, short story", "start_pos": 22, "end_pos": 69, "type": "TASK", "confidence": 0.8158649139934115}, {"text": "PE", "start_pos": 93, "end_pos": 95, "type": "METRIC", "confidence": 0.648618221282959}]}, {"text": "This paper offers an initial response to this question.", "labels": [], "entities": []}, {"text": "An essay by the American writer Richard Powers, currently not available in French, is automatically translated and post-edited and then revised by non-professional translators.", "labels": [], "entities": []}, {"text": "In addition to presenting experimental evaluation results of the MT+PE pipeline (MT system used, automatic evaluation), we also discuss the quality of the translation output from the perspective of a panel of readers (who read the translated short story in French, and answered a survey afterwards).", "labels": [], "entities": [{"text": "MT+PE", "start_pos": 65, "end_pos": 70, "type": "TASK", "confidence": 0.5387734274069468}]}, {"text": "Finally, some remarks of the official French translator of R.", "labels": [], "entities": [{"text": "French translator of R", "start_pos": 38, "end_pos": 60, "type": "DATASET", "confidence": 0.770339623093605}]}, {"text": "Powers, requested on this occasion, are given at the end of this article.", "labels": [], "entities": []}], "introductionContent": [{"text": "The task of post-editing consists of editing some text (generally produced by a machine, such as a machine translation, optical character recognition, or automatic transcription system) in order to improve it.", "labels": [], "entities": [{"text": "machine translation, optical character recognition", "start_pos": 99, "end_pos": 149, "type": "TASK", "confidence": 0.691598022977511}]}, {"text": "When using machine translation in the field of document translation, the following process is generally used: the MT system produces raw translations, which are manually post-edited by trained professional translators (post-editors) who correct translation errors.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 11, "end_pos": 30, "type": "TASK", "confidence": 0.7516439259052277}, {"text": "document translation", "start_pos": 47, "end_pos": 67, "type": "TASK", "confidence": 0.6968306452035904}, {"text": "MT", "start_pos": 114, "end_pos": 116, "type": "TASK", "confidence": 0.9182006120681763}]}, {"text": "Several studies have shown the benefits of the combined use of machine translation and manual post-editing (MT+PE) fora document translation task.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 63, "end_pos": 82, "type": "TASK", "confidence": 0.7164031565189362}, {"text": "document translation task", "start_pos": 120, "end_pos": 145, "type": "TASK", "confidence": 0.8055439392725626}]}, {"text": "For example, showed that even though post-editing raw translations does not always lead to significant increases in productivity, this process can result in higher quality translations (when compared to translating from scratch).", "labels": [], "entities": []}, {"text": "Autodesk also carried out an experiment to test whether the use of MT would improve the productivity of translators.", "labels": [], "entities": [{"text": "Autodesk", "start_pos": 0, "end_pos": 8, "type": "DATASET", "confidence": 0.9663835167884827}, {"text": "MT", "start_pos": 67, "end_pos": 69, "type": "TASK", "confidence": 0.9174141883850098}]}, {"text": "Results from that experiment show that post-editing machine translation output significantly increases productivity when compared to translating a document from scratch.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 52, "end_pos": 71, "type": "TASK", "confidence": 0.6776560097932816}]}, {"text": "This result held regardless of the language pair, the experience level of the translator, and the translator's stated preference for post-editing or translating from scratch.", "labels": [], "entities": []}, {"text": "These results from academia (Garcia, 2011) and industry regarding translation in specialized areas lead us to ask the following questions: \u2022 What would be the value of such a process (MT + PE) applied to the translation of a literary work?", "labels": [], "entities": [{"text": "translation of a literary work", "start_pos": 208, "end_pos": 238, "type": "TASK", "confidence": 0.7928426742553711}]}, {"text": "\u2022 How long does it take to translate a literary document often thousand words?", "labels": [], "entities": [{"text": "translate a literary document often thousand words", "start_pos": 27, "end_pos": 77, "type": "TASK", "confidence": 0.838923522404262}]}, {"text": "\u2022 Is the resulting translation acceptable to readers?", "labels": [], "entities": []}, {"text": "\u2022 What would the official translator (of the considered author) think of it?", "labels": [], "entities": []}, {"text": "\u2022 Is \"low cost\" translation produced by communities of fans (as is the case for TV series) feasible for novels or short stories?", "labels": [], "entities": []}, {"text": "This work attempts to provide preliminary answers to these questions.", "labels": [], "entities": []}, {"text": "In addition to our experimental results, we also present anew transla-tion (into French) of an English-language essay.", "labels": [], "entities": []}, {"text": "This paper is organized as follows.", "labels": [], "entities": []}, {"text": "We begin in \u00a72 by surveying related work in machine translation in the literary domain.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 44, "end_pos": 63, "type": "TASK", "confidence": 0.7434861958026886}]}, {"text": "In \u00a73, we present our experimental methodology, including the choice of literary work to be translated and the machine translation, domain adaptation, and post-editing frameworks used.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 111, "end_pos": 130, "type": "TASK", "confidence": 0.7139501124620438}, {"text": "domain adaptation", "start_pos": 132, "end_pos": 149, "type": "TASK", "confidence": 0.7043436020612717}]}, {"text": "In \u00a74, we present our experimental results, 2 including an assessment of translation quality using automated machine translation metrics.", "labels": [], "entities": [{"text": "translation", "start_pos": 73, "end_pos": 84, "type": "TASK", "confidence": 0.9632024168968201}]}, {"text": "In \u00a75, we attempt to assess machine translation quality beyond automated metrics, through a human assessment of the final translation; this assessment was performed by a panel of readers and by the official French translator of Richard Powers.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 28, "end_pos": 47, "type": "TASK", "confidence": 0.7281311452388763}, {"text": "French translator of Richard Powers", "start_pos": 207, "end_pos": 242, "type": "DATASET", "confidence": 0.6657820582389832}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Number of words in each block of the English source corpus, French machine translation (MT), and French  post-edited machine translation (PE).", "labels": [], "entities": [{"text": "English source corpus", "start_pos": 47, "end_pos": 68, "type": "DATASET", "confidence": 0.6924551427364349}, {"text": "French machine translation (MT)", "start_pos": 70, "end_pos": 101, "type": "TASK", "confidence": 0.7179678281148275}, {"text": "French  post-edited machine translation (PE)", "start_pos": 107, "end_pos": 151, "type": "TASK", "confidence": 0.6564408157552991}]}, {"text": " Table  3. It is interesting to see that while the revision takes  40% of the total time, the revised text remains very  similar to the post-edited text. This can be observed  by computing BLEU between the post-edited text  before and after revising; the result is a BLEU score", "labels": [], "entities": [{"text": "BLEU", "start_pos": 189, "end_pos": 193, "type": "METRIC", "confidence": 0.9989493489265442}, {"text": "BLEU", "start_pos": 267, "end_pos": 271, "type": "METRIC", "confidence": 0.9995604157447815}]}, {"text": " Table 2: BLEU after tokenization and case removal on full corpus, and time measurements for each iteration", "labels": [], "entities": [{"text": "BLEU", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9993300437927246}, {"text": "tokenization", "start_pos": 21, "end_pos": 33, "type": "TASK", "confidence": 0.9736353158950806}, {"text": "case removal", "start_pos": 38, "end_pos": 50, "type": "TASK", "confidence": 0.7045862972736359}]}, {"text": " Table 3: Automatic Evaluation (BLEU) on full corpus between unedited machine translation (MT), post-edited ma- chine translation (PE), and revised post-edited machine translation (REV).", "labels": [], "entities": [{"text": "Automatic Evaluation (BLEU)", "start_pos": 10, "end_pos": 37, "type": "METRIC", "confidence": 0.887726628780365}, {"text": "unedited machine translation (MT)", "start_pos": 61, "end_pos": 94, "type": "TASK", "confidence": 0.7990382611751556}, {"text": "post-edited ma- chine translation (PE)", "start_pos": 96, "end_pos": 134, "type": "TASK", "confidence": 0.7412410974502563}, {"text": "revised post-edited machine translation (REV)", "start_pos": 140, "end_pos": 185, "type": "TASK", "confidence": 0.7536725316728864}]}]}