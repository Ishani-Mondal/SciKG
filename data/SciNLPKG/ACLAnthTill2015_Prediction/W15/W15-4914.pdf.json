{"title": [{"text": "Poor man's lemmatisation for automatic error classification", "labels": [], "entities": []}], "abstractContent": [{"text": "This paper demonstrates the possibility to make an existing automatic error classi-fier for machine translations independent from the requirement of lemmatisation.", "labels": [], "entities": [{"text": "machine translations", "start_pos": 92, "end_pos": 112, "type": "TASK", "confidence": 0.6518785059452057}]}, {"text": "This makes it usable also for smaller and under-resourced languages and in situations where there is no lemmatiser at hand.", "labels": [], "entities": []}, {"text": "It is shown that cutting all words into the first four letters is the best method even for highly inflective languages, preserving both the detected distribution of error types within a translation output as well as over various translation outputs.", "labels": [], "entities": []}, {"text": "The main cost of not using a lemmatiser is the lower accuracy of detecting the in-flectional error class due to its confusion with mistranslations.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 53, "end_pos": 61, "type": "METRIC", "confidence": 0.9993519186973572}]}, {"text": "For shorter words, actual inflectional errors will be tagged as mistranslations, for longer words the other way round.", "labels": [], "entities": []}, {"text": "Keeping all that in mind, it is possible to use the error classifier without target language lemmatisation and to extrapolate inflectional and lexical error rates according to the average word length in the analysed text.", "labels": [], "entities": []}], "introductionContent": [{"text": "Future improvement of machine translation (MT) systems requires reliable automatic evaluation and error classification tools in order to minimise efforts of time and money consuming human classification.", "labels": [], "entities": [{"text": "machine translation (MT)", "start_pos": 22, "end_pos": 46, "type": "TASK", "confidence": 0.8545314848423005}, {"text": "error classification", "start_pos": 98, "end_pos": 118, "type": "TASK", "confidence": 0.6844003945589066}]}, {"text": "Therefore automatic error classification tools have been developed in recent years (Zeman et al., 2011; Popovi\u00b4cPopovi\u00b4c, 2011) and are being used to facilitate the error analysis.", "labels": [], "entities": [{"text": "error classification", "start_pos": 20, "end_pos": 40, "type": "TASK", "confidence": 0.7089046388864517}]}, {"text": "Although these tools are completely language independent, for obtaining a precise error distribution over classes a lemmatiser for the target language is required.", "labels": [], "entities": []}, {"text": "For the languages strongly supported in language resources and tools this does not pose a problem.", "labels": [], "entities": []}, {"text": "However, fora number of languages a lemmatiser might not beat hand, or it does not exist at all.", "labels": [], "entities": []}, {"text": "This paper investigates possibilities for obtaining reasonable error classification results without lemmatisation.", "labels": [], "entities": [{"text": "obtaining reasonable error classification", "start_pos": 42, "end_pos": 83, "type": "TASK", "confidence": 0.6212588548660278}]}, {"text": "To the best of our knowledge, this issue has not been investigated so far.", "labels": [], "entities": []}], "datasetContent": [{"text": "The two main objectives of automatic error classifier are: \u2022 to estimate the error distribution within a translation output \u2022 to compare different translation outputs in terms of error categories Therefore we tested the described methods for both these aspects by comparing the results with those obtained when using lemmatised words, i.e. we used the error rates obtained with lemmas as the \"reference\" error rates.", "labels": [], "entities": []}, {"text": "The best way for the assessment would be, of course, a comparison with human error classification.", "labels": [], "entities": [{"text": "human error classification", "start_pos": 71, "end_pos": 97, "type": "TASK", "confidence": 0.5613374511400858}]}, {"text": "Nevertheless, this has not been done for two reasons: first, the original method using lemmas is already thoroughly tested in previous work) and is shown to correlate well with human judgements.", "labels": [], "entities": []}, {"text": "Second, human evaluation is resource and timeconsuming.", "labels": [], "entities": []}, {"text": "The explored target languages in this work are English, Spanish, German, Slovenian and Czech originating from news, technical texts, client data of Language Service Providers, pharmaceutical domain, Europarl, as well as the OpenSubtitles 1 spoken language corpus.", "labels": [], "entities": [{"text": "Europarl", "start_pos": 199, "end_pos": 207, "type": "DATASET", "confidence": 0.9803471565246582}, {"text": "OpenSubtitles 1 spoken language corpus", "start_pos": 224, "end_pos": 262, "type": "DATASET", "confidence": 0.7577691316604614}]}, {"text": "In addition, one Basque translation output from technical domain has been available as well.", "labels": [], "entities": [{"text": "Basque translation", "start_pos": 17, "end_pos": 35, "type": "TASK", "confidence": 0.6593341380357742}]}, {"text": "The publicly available texts are described in), (Specia, 2011) and.", "labels": [], "entities": []}, {"text": "The majority of translation outputs has been created by statistical systems but a number of translations has been produced by rule-based systems.", "labels": [], "entities": [{"text": "translation outputs", "start_pos": 16, "end_pos": 35, "type": "TASK", "confidence": 0.9128192365169525}]}, {"text": "It should be noted that not all target languages were available for all domains, however the total amount of texts and the diversity of languages and domains are sufficient to obtain reliable results -about 36000 sentences with average number of words ranging from 8 (subtitles) through 15 (domain-specific corpora) up to 25 (Europarl and news) have been analysed.", "labels": [], "entities": [{"text": "Europarl", "start_pos": 326, "end_pos": 334, "type": "DATASET", "confidence": 0.9584805369377136}]}, {"text": "Lemmas for English, Spanish and German texts are generated using TreeTagger, 2 Slovenian lemmas are produced by the Obeliks tagger (, and Czech texts are lemmatised using the COMPOST tagger.", "labels": [], "entities": []}, {"text": "It should be noted that all the reported results are calculated using WER of lemmas (or corresponding substitutions) since no changes related to lemma substitution techniques were observed in comparison with the use of the standard full word WER.", "labels": [], "entities": [{"text": "WER", "start_pos": 70, "end_pos": 73, "type": "METRIC", "confidence": 0.9467037916183472}]}], "tableCaptions": [{"text": " Table 2: Comparison of error rates obtained by each of the described word reduction methods with the  reference lemma error rates for three translation outputs: English (above), Spanish (middle) and Czech  (below). Error rates using full words as lemma replacement are shown as well, illustrating why this  method is not recommended.", "labels": [], "entities": [{"text": "word reduction", "start_pos": 70, "end_pos": 84, "type": "TASK", "confidence": 0.7381522059440613}, {"text": "Error", "start_pos": 216, "end_pos": 221, "type": "METRIC", "confidence": 0.9639633893966675}]}, {"text": " Table 4: Accuracies and confusions between reference lemma error categories and those obtained by the  4let method; for all texts (Overall), separately for post-editions and for references, separately for each  target language, and separately for written and spoken language.", "labels": [], "entities": [{"text": "Accuracies", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.9875836968421936}]}, {"text": " Table 6: Comparison of overall 4let and stem accuracies and confusions.", "labels": [], "entities": []}]}