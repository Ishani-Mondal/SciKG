{"title": [{"text": "Hierarchical Statistical Semantic Realization for Minimal Recursion Semantics", "labels": [], "entities": [{"text": "Hierarchical Statistical Semantic Realization", "start_pos": 0, "end_pos": 45, "type": "TASK", "confidence": 0.5692012086510658}]}], "abstractContent": [{"text": "We introduce a robust statistical approach to realization from Minimal Recursion Semantics representations.", "labels": [], "entities": []}, {"text": "The approach treats realization as a translation problem, transforming the Dependency MRS graph representation to a surface string.", "labels": [], "entities": [{"text": "Dependency MRS graph representation", "start_pos": 75, "end_pos": 110, "type": "DATASET", "confidence": 0.5944562032818794}]}, {"text": "Translation is based on a Synchronous Context-Free Grammar that is automatically extracted from a large corpus of parsed sentences.", "labels": [], "entities": [{"text": "Translation", "start_pos": 0, "end_pos": 11, "type": "TASK", "confidence": 0.9599380493164062}]}, {"text": "We have evaluated the new approach on the Wikiwoods corpus, where it shows promising results.", "labels": [], "entities": [{"text": "Wikiwoods corpus", "start_pos": 42, "end_pos": 58, "type": "DATASET", "confidence": 0.9511032104492188}]}], "introductionContent": [{"text": "Realization from Minimal Recursion Semantics (MRS) representations has traditionally used a chartbased approach governed by a resource grammar.", "labels": [], "entities": [{"text": "Realization from Minimal Recursion Semantics (MRS) representations", "start_pos": 0, "end_pos": 66, "type": "TASK", "confidence": 0.8415106336275736}]}, {"text": "Introduced by and, the chart-based approach is lexically-driven and is able to produce a large number of candidate surface strings which maybe ranked using an N-gram language model or using discriminative machine learning.", "labels": [], "entities": []}, {"text": "As the chart-based realization relies on a resource grammar, it tends to perform well when realizing from MRS representations that were created by a parser using the same resource grammar.", "labels": [], "entities": []}, {"text": "However, the chart-based approach may fail to produce any output when the MRS representation has missing or incorrect parts.", "labels": [], "entities": [{"text": "MRS representation", "start_pos": 74, "end_pos": 92, "type": "TASK", "confidence": 0.7325848937034607}]}, {"text": "This is a significant issue for the MRS representations produced as a result of semantic transfer in semantic transfer translation systems such as LOGON) due to the difficulty of the translation problem.", "labels": [], "entities": [{"text": "MRS representations", "start_pos": 36, "end_pos": 55, "type": "TASK", "confidence": 0.8843468129634857}]}, {"text": "Consequently, the realization component is unable to produce any output and, in turn, translation fails.", "labels": [], "entities": []}, {"text": "In this paper we describe a first attempt at statistical realization from MRS representations.", "labels": [], "entities": [{"text": "statistical realization", "start_pos": 45, "end_pos": 68, "type": "TASK", "confidence": 0.830299973487854}, {"text": "MRS representations", "start_pos": 74, "end_pos": 93, "type": "TASK", "confidence": 0.8217041194438934}]}, {"text": "The approach treats realization as a translation problem, transforming the Dependency MRS graph representation to a surface string.", "labels": [], "entities": [{"text": "Dependency MRS graph representation", "start_pos": 75, "end_pos": 110, "type": "DATASET", "confidence": 0.5944562032818794}]}, {"text": "The approach draws inspiration from Statistical Machine Translation, namely the hierarchical phrase-based approach to translation introduced by.", "labels": [], "entities": [{"text": "Statistical Machine Translation", "start_pos": 36, "end_pos": 67, "type": "TASK", "confidence": 0.7812336484591166}]}, {"text": "We will refer to the new approach as Hierarchical Statistical Semantic Realization or HSSR.", "labels": [], "entities": [{"text": "Statistical Semantic Realization", "start_pos": 50, "end_pos": 82, "type": "TASK", "confidence": 0.6707924405733744}]}, {"text": "As part of the HSSR system, we present an approach for the automatic extraction of salient hierarchical rules for realization.", "labels": [], "entities": []}, {"text": "The approach creates rules by considering DMRS subgraphs and corresponding surface substrings.", "labels": [], "entities": []}, {"text": "The rules are created in two stages, first creating terminal rules, followed by nonterminal rules.", "labels": [], "entities": []}, {"text": "The latter are created by 'subtracting' terminal rules from each other.", "labels": [], "entities": []}, {"text": "The realization rules are extracted from a large parsed corpus to form a Synchronous Context-Free Grammar (SCFG).", "labels": [], "entities": []}, {"text": "We build on the ideas behind HiFST, a hierarchical phrase-based decoder introduced by, to create a realization decoder.", "labels": [], "entities": []}, {"text": "The decoder represents realization rules as Weighted Finite State Acceptors (WFSA).", "labels": [], "entities": [{"text": "Weighted Finite State Acceptors (WFSA", "start_pos": 44, "end_pos": 81, "type": "METRIC", "confidence": 0.6287300537029902}]}, {"text": "It uses WFSA operations to create a lattice encoding all possible realizations under a given SCFG.", "labels": [], "entities": []}, {"text": "An N-gram language model is applied to the lattice to encourage fluency in surface realizations.", "labels": [], "entities": []}, {"text": "The best realization is selected by finding the shortest path through the lattice.", "labels": [], "entities": []}, {"text": "The long term goal of the HSSR system is to provide a robust alternative to chart-based realization that would be especially useful for realization in semantic transfer-based translation systems.", "labels": [], "entities": [{"text": "semantic transfer-based translation", "start_pos": 151, "end_pos": 186, "type": "TASK", "confidence": 0.6111976901690165}]}, {"text": "However, in this paper we focus on presenting the main ideas behind HSSR and not on providing a direct alternative to the traditional approach.", "labels": [], "entities": [{"text": "HSSR", "start_pos": 68, "end_pos": 72, "type": "TASK", "confidence": 0.8963419795036316}]}, {"text": "The system in its current stage of development lacks maturity and efficiency required by its potential applications.", "labels": [], "entities": []}, {"text": "Consequently, we make some simplifying assumptions during evaluation, which we discuss in the relevant parts of the paper.", "labels": [], "entities": []}, {"text": "The HSSR approach is suitable for realization in any language, provided that there is a resource grammar of the language available.", "labels": [], "entities": []}, {"text": "We evaluated its performance on the Wikiwoods corpus, a large deep parsed corpus of English Wikipedia which provides a large collection of MRS representations aligned with surface realizations that are suitable for learning the realization grammar.", "labels": [], "entities": [{"text": "Wikiwoods corpus, a large deep parsed corpus of English Wikipedia", "start_pos": 36, "end_pos": 101, "type": "DATASET", "confidence": 0.7557691877538507}]}, {"text": "We measure the performance of the HSSR system using BLEU and discuss its strengths and weakness using example output.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 52, "end_pos": 56, "type": "METRIC", "confidence": 0.9982068538665771}]}, {"text": "The system shows promising results, with the main issues stemming from the lack of efficiency.", "labels": [], "entities": []}], "datasetContent": [{"text": "We evaluated the HSSR approach by realizing a set of parsed MRS representations and comparing the realized surface strings against the original sentences.", "labels": [], "entities": []}, {"text": "We use the BLEU metric for comparison of surface strings.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 11, "end_pos": 15, "type": "METRIC", "confidence": 0.9984605312347412}]}, {"text": "have investigated the use of various automatic evaluation metrics to measure the quality of realization output.", "labels": [], "entities": []}, {"text": "They have found that several standard Statistical Machine Translation evaluation metrics, including BLEU, correlate moderately well with human judgment of adequacy and fluency for the string realization task.", "labels": [], "entities": [{"text": "Statistical Machine Translation evaluation", "start_pos": 38, "end_pos": 80, "type": "TASK", "confidence": 0.7505739107728004}, {"text": "BLEU", "start_pos": 100, "end_pos": 104, "type": "METRIC", "confidence": 0.9972150325775146}, {"text": "string realization task", "start_pos": 184, "end_pos": 207, "type": "TASK", "confidence": 0.7890223463376363}]}, {"text": "The authors conclude that these metrics are useful for measuring incremental progress of a realization system, but advise caution when comparing different realization systems.", "labels": [], "entities": []}, {"text": "We trained and evaluated the HSSR system on a subset of the Wikiwoods corpus.", "labels": [], "entities": [{"text": "Wikiwoods corpus", "start_pos": 60, "end_pos": 76, "type": "DATASET", "confidence": 0.9528267681598663}]}, {"text": "The Wikiwoods corpus, introduced by, contains close to 1.3 million deep-parsed content articles, extracted from a snapshot of English Wikipedia in July 2008.", "labels": [], "entities": [{"text": "Wikiwoods corpus", "start_pos": 4, "end_pos": 20, "type": "DATASET", "confidence": 0.9401266872882843}, {"text": "English Wikipedia in July 2008", "start_pos": 126, "end_pos": 156, "type": "DATASET", "confidence": 0.8875458359718322}]}, {"text": "We randomly sampled chunks of the corpus to create our training, tuning, and test sets.", "labels": [], "entities": []}, {"text": "The training set consists of around 1 million DMRS-sentence pairs.", "labels": [], "entities": []}, {"text": "Tuning and test sets consist of 500 and 1000 DMRS-sentence pairs respectively.", "labels": [], "entities": []}, {"text": "Due to efficiency reasons, we selected input pairs of up to 20 tokens in the training set, and up to 15 DMRS graph nodes in the tuning and test sets.", "labels": [], "entities": []}, {"text": "In future, we plan to address the efficiency of rule extraction and decoding with regards to input size by introducing an input graph splitting strategy, a graph equivalent to the standard practices of sentence splitting in SMT.", "labels": [], "entities": [{"text": "rule extraction", "start_pos": 48, "end_pos": 63, "type": "TASK", "confidence": 0.7631816565990448}, {"text": "input graph splitting", "start_pos": 122, "end_pos": 143, "type": "TASK", "confidence": 0.7733781933784485}, {"text": "sentence splitting", "start_pos": 202, "end_pos": 220, "type": "TASK", "confidence": 0.7582569420337677}, {"text": "SMT", "start_pos": 224, "end_pos": 227, "type": "TASK", "confidence": 0.660616934299469}]}, {"text": "In the preprocessing stage, we performed general predicate node filtering from DMRS graphs to remove nodes that would introduce unnecessary complexity in rule extraction and decoding.", "labels": [], "entities": [{"text": "rule extraction", "start_pos": 154, "end_pos": 169, "type": "TASK", "confidence": 0.755283385515213}]}, {"text": "On the other hand, we augmented the DMRS representations with explicit punctuation nodes and links, as the graphs otherwise do not contain information regarding punctuation.", "labels": [], "entities": []}, {"text": "We evaluated the system using 2-gram, 3-gram, and 4-gram language models.", "labels": [], "entities": []}, {"text": "We estimated the language models on the entire Wikiwoods corpus, consisting of 800 million words (excluding tuning and training sets).", "labels": [], "entities": [{"text": "Wikiwoods corpus", "start_pos": 47, "end_pos": 63, "type": "DATASET", "confidence": 0.9344191253185272}]}, {"text": "The language models were estimated using KenLM toolkit) with interpolated modified Kneser-Ney smoothing.", "labels": [], "entities": []}, {"text": "Rule extraction on the training set of 1 million DMRS graph-surface string pairs produced 7.3 million realization rules.", "labels": [], "entities": [{"text": "Rule extraction", "start_pos": 0, "end_pos": 15, "type": "TASK", "confidence": 0.7407422363758087}]}, {"text": "Practical limitations mentioned above apply: we extracted rules with at most 2 nonterminals, and the size of source side is at most five nodes.", "labels": [], "entities": []}, {"text": "We tuned the log-linear model weights using simple grid search over several iterations against the BLEU evaluation metric ().", "labels": [], "entities": [{"text": "BLEU evaluation metric", "start_pos": 99, "end_pos": 121, "type": "METRIC", "confidence": 0.9163680871327718}]}, {"text": "A mature system could instead be optimized using standard tuning approaches from SMT, for example MERT and LMERT ().", "labels": [], "entities": [{"text": "SMT", "start_pos": 81, "end_pos": 84, "type": "TASK", "confidence": 0.9575197100639343}, {"text": "MERT", "start_pos": 98, "end_pos": 102, "type": "METRIC", "confidence": 0.5362939238548279}, {"text": "LMERT", "start_pos": 107, "end_pos": 112, "type": "METRIC", "confidence": 0.7195574045181274}]}, {"text": "The decoding times of the current system implementation can be relatively long.", "labels": [], "entities": []}, {"text": "We enforced reasonable computation time by terminating decoding of a DMRS graph after 300 seconds.", "labels": [], "entities": []}, {"text": "This occurred for 96/1000 examples in the test set.", "labels": [], "entities": []}, {"text": "As BLEU significantly penalizes short or omitted output using the brevity penalty, we computed the BLEU scores only on decoded examples.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 3, "end_pos": 7, "type": "METRIC", "confidence": 0.9806365370750427}, {"text": "BLEU", "start_pos": 99, "end_pos": 103, "type": "METRIC", "confidence": 0.9988565444946289}]}, {"text": "The final evaluation example set is the same between all systems in order to keep the scores comparable between them.", "labels": [], "entities": []}], "tableCaptions": []}