{"title": [{"text": "Sequential Annotation and Chunking of Chinese Discourse Structure", "labels": [], "entities": [{"text": "Sequential Annotation", "start_pos": 0, "end_pos": 21, "type": "TASK", "confidence": 0.8668786883354187}]}], "abstractContent": [{"text": "We propose a linguistically driven approach to represent discourse relations in Chinese text as sequences.", "labels": [], "entities": []}, {"text": "We observe that certain surface characteristics of Chi-nese texts, such as the order of clauses, are overt markers of discourse structures, yet existing annotation proposals adapted from formalism constructed for English do not fully incorporate these characteristics.", "labels": [], "entities": []}, {"text": "We present an annotated resource consisting of 325 articles in the Chinese Tree-bank.", "labels": [], "entities": [{"text": "Chinese Tree-bank", "start_pos": 67, "end_pos": 84, "type": "DATASET", "confidence": 0.9843586087226868}]}, {"text": "In addition, using this annotation, we introduce a discourse chunker based on a cascade of classifiers and report 70% top-level discourse sense accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 144, "end_pos": 152, "type": "METRIC", "confidence": 0.9842610359191895}]}], "introductionContent": [{"text": "Discourse relations refer to the relations between units of text at document level.", "labels": [], "entities": []}, {"text": "As a key for language processing, they are used in tasks such as automatic summerization, sentiment analysis and text coherence assessment ().", "labels": [], "entities": [{"text": "language processing", "start_pos": 13, "end_pos": 32, "type": "TASK", "confidence": 0.7422075271606445}, {"text": "sentiment analysis", "start_pos": 90, "end_pos": 108, "type": "TASK", "confidence": 0.9667603671550751}, {"text": "text coherence assessment", "start_pos": 113, "end_pos": 138, "type": "TASK", "confidence": 0.6753726800282797}]}, {"text": "While discourse-annotated English resources are available, resources in other languages are limited.", "labels": [], "entities": []}, {"text": "In this work, we present the linguistic motivation behind the Chinese discourse annotated corpus we constructed, and preliminary experiments on discourse chunking of Chinese.", "labels": [], "entities": [{"text": "discourse chunking of Chinese", "start_pos": 144, "end_pos": 173, "type": "TASK", "confidence": 0.8080196678638458}]}], "datasetContent": [{"text": "We run the classifiers from Steps 1-5.", "labels": [], "entities": []}, {"text": "After Step 1, identified non-discourse-unit segments are joined as one argument and features are updated.", "labels": [], "entities": []}, {"text": "The discourse context features are also updated after each step based on last classifier's output.", "labels": [], "entities": []}, {"text": "The tag of a fw-linking DC is switched to the next segment, as a relation connecting the next segment to the current one.", "labels": [], "entities": []}, {"text": "The current segment is thus passed to the implicit classifier, given that there is not any bw-linking DCs.", "labels": [], "entities": []}, {"text": "For applications that need discourse, it may not be necessary to distinguish between explicit and implicit relations.", "labels": [], "entities": []}, {"text": "Thus, we combine the outputs of the explicit and implicit classifiers when evaluating the end-to-end outputs.", "labels": [], "entities": []}, {"text": "Specifically, the pipeline outputs one of the 4 discourse senses or 'non-discourse-unit' across a segment boundary, while the reference can be more than one, since duplicated annotation is allowed.", "labels": [], "entities": []}, {"text": "The system prediction is considered correct if it is included in the gold tag set.", "labels": [], "entities": []}, {"text": "The combined outputs are evaluated in terms of accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 47, "end_pos": 55, "type": "METRIC", "confidence": 0.9988195300102234}]}, {"text": "shows the classification accuracies evaluated by the above principle under different error propagation settings.", "labels": [], "entities": []}, {"text": "For example, given gold identification of non-discourse segments (Step 1) and explicit DC classifier (Step 2), classification of the 4 main explicit sense reaches accuracy of 0.854, but is dropped to 0.800 if step 1 and step 2 are automatic . It is observed that errors are generally propagated along the pipeline.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 163, "end_pos": 171, "type": "METRIC", "confidence": 0.9992570281028748}]}, {"text": "Similar to the finding in English (), the discourse context as predicted by earlier classifiers does not affect the later steps -the results are the same based on gold or automatic outputs.", "labels": [], "entities": []}, {"text": "The end-to-end accuracy of the proposed pipeline is 65.7% and the baseline (classify all as 'expansion') is 50.0%.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 15, "end_pos": 23, "type": "METRIC", "confidence": 0.9686596393585205}, {"text": "baseline", "start_pos": 66, "end_pos": 74, "type": "METRIC", "confidence": 0.9485666155815125}]}, {"text": "Accuracies non-disexp/impexplicitnon-disimplicit over or not /non-dis senses types senses -all Step 2-way 3-way 4-way 3-way 4-way.", "labels": [], "entities": [{"text": "Accuracies", "start_pos": 0, "end_pos": 10, "type": "METRIC", "confidence": 0.9905133247375488}]}, {"text": "The best result (70.1% accuracy), is obtained by classifying implicit DCs and non-discourse units in one step.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 23, "end_pos": 31, "type": "METRIC", "confidence": 0.9993348717689514}]}, {"text": "reports an accuracy of 88.28% on 4-way classification of inter-sentential discourse senses, and reports an accuracy of 81.63% on 2-way classification of intra-sentential contingency vs comparison senses.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 11, "end_pos": 19, "type": "METRIC", "confidence": 0.9994308352470398}, {"text": "accuracy", "start_pos": 107, "end_pos": 115, "type": "METRIC", "confidence": 0.9991781115531921}]}, {"text": "Note that the result is much degraded if we train one 5-way classifier to classify all relations.", "labels": [], "entities": []}, {"text": "This shows that explicit and implicit DCs ought to be treated separately, even though we do not concern about distinguishing them in the final output.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Distribution of various tags in the an- notated corpus (4 senses: CONtingency, COM- parison, TEMporal, EXPansion; 3 types of non- discourse-unit segments: ATTRibution, OPTional  punctuation, and non-discourse ADVerbial)", "labels": [], "entities": [{"text": "TEMporal", "start_pos": 103, "end_pos": 111, "type": "METRIC", "confidence": 0.9864779710769653}]}, {"text": " Table 2: Accuracies of individual classifiers on  'gold' test samples. F1 is the average of the F1  for each class.", "labels": [], "entities": [{"text": "Accuracies", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.9889993071556091}, {"text": "F1", "start_pos": 72, "end_pos": 74, "type": "METRIC", "confidence": 0.9991461038589478}, {"text": "F1", "start_pos": 97, "end_pos": 99, "type": "METRIC", "confidence": 0.9889827370643616}]}, {"text": " Table 3: Accuracies at each stage under different  error propagation settings.", "labels": [], "entities": [{"text": "Accuracies", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.9946466088294983}]}]}