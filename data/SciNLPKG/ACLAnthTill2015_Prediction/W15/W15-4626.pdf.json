{"title": [{"text": "Memory-Based Acquisition of Argument Structures and its Application to Implicit Role Detection", "labels": [], "entities": [{"text": "Implicit Role Detection", "start_pos": 71, "end_pos": 94, "type": "TASK", "confidence": 0.6182342271010081}]}], "abstractContent": [{"text": "We propose a generic, memory-based approach for the detection of implicit semantic roles.", "labels": [], "entities": [{"text": "detection of implicit semantic roles", "start_pos": 52, "end_pos": 88, "type": "TASK", "confidence": 0.7540232419967652}]}, {"text": "While state-of-the-art methods for this task combine hand-crafted rules with specialized and costly lexical resources, our models use large corpora with automated annotations for explicit semantic roles only to capture the distribution of predicates and their associated roles.", "labels": [], "entities": []}, {"text": "We show that memory-based learning can increase the recognition rate of implicit roles beyond the state-of-the-art.", "labels": [], "entities": []}], "introductionContent": [{"text": "Automated implicit semantic role labeling (iSRL) has emerged as a novel area of interest in the recent years.", "labels": [], "entities": [{"text": "Automated implicit semantic role labeling (iSRL)", "start_pos": 0, "end_pos": 48, "type": "TASK", "confidence": 0.7020872980356216}]}, {"text": "In contrast to traditional SRL, which aims to detect events (e.g., verbal or nominal predicates) together with their associated semantic roles (agent, theme, recipient, etc.) as overtly realized in the current sentence, iSRL extends this analysis with locally unexpressed linguistic items.", "labels": [], "entities": [{"text": "SRL", "start_pos": 27, "end_pos": 30, "type": "TASK", "confidence": 0.958246648311615}]}, {"text": "Hence, iSRL requires to broaden the scope beyond isolated sentences to the surrounding discourse.", "labels": [], "entities": []}, {"text": "As an illustration, consider the following example from: El Salvador is now the only Latin American country which still has troops in.", "labels": [], "entities": []}, {"text": "Nicaragua, Honduras and the Dominican Republic have withdrawn their troops.", "labels": [], "entities": []}, {"text": "In the second sentence, a standard SRL parser would ideally identify withdraw as the main verbal predicate.", "labels": [], "entities": [{"text": "SRL parser", "start_pos": 35, "end_pos": 45, "type": "TASK", "confidence": 0.8868127167224884}]}, {"text": "In its thematic relation to the other words within the same sentence, all countries serve as the overtly expressed (explicit) agents, and are thus labeled as arguments A0.", "labels": [], "entities": []}, {"text": "Semantically, they are the action performers, whereas troops would carry the patient role A1 as the entity which undergoes the action of being withdrawn.", "labels": [], "entities": []}, {"text": "However, given these explicit role annotations for A0 and A1 in the second sentence, the standard system would definitely fail to infer the underlying, linguistically unexpressed, i.e., non-overt realization of an implicit argument of withdraw (denoted by) about source information.", "labels": [], "entities": [{"text": "A0", "start_pos": 51, "end_pos": 53, "type": "METRIC", "confidence": 0.9204016923904419}, {"text": "A1", "start_pos": 58, "end_pos": 60, "type": "METRIC", "confidence": 0.804572343826294}]}, {"text": "Its corresponding realization is associated with Iraq in the preceding sentence, which is outside of the scope of any standard SRL parser.", "labels": [], "entities": []}, {"text": "The resulting implicit role has the label A2.", "labels": [], "entities": [{"text": "A2", "start_pos": 42, "end_pos": 44, "type": "METRIC", "confidence": 0.9545218348503113}]}, {"text": "Many role realizations are suppressed on the surface level.", "labels": [], "entities": [{"text": "role realizations", "start_pos": 5, "end_pos": 22, "type": "TASK", "confidence": 0.7185784578323364}]}, {"text": "The automated detection of such implicit roles and their fillers, which are also called null instantiations (NIs)), is a challenging task.", "labels": [], "entities": []}, {"text": "Yet, if uncovered, NIs provide highly beneficial 'supplementary' information which in turn can be incorporated into practical, downstream NLU applications, like automated text summarization, recognizing textual entailment or question answering.", "labels": [], "entities": [{"text": "text summarization", "start_pos": 171, "end_pos": 189, "type": "TASK", "confidence": 0.6542698293924332}, {"text": "recognizing textual entailment", "start_pos": 191, "end_pos": 221, "type": "TASK", "confidence": 0.8384109536806742}, {"text": "question answering", "start_pos": 225, "end_pos": 243, "type": "TASK", "confidence": 0.8434834778308868}]}, {"text": "Current issues in iSRL Corpus data with manually annotated implicit roles is extremely sparse and hard to obtain, and annotation efforts have emerged only recently; cf.,, and also for an attempt to enlarge the number of annotation instances by combination of scarce resources.", "labels": [], "entities": [{"text": "iSRL Corpus data", "start_pos": 18, "end_pos": 34, "type": "DATASET", "confidence": 0.8853247960408529}]}, {"text": "As a result, most state-ofthe-art iSRL systems cannot be trained in a supervised setting and thus integrate custom, rule-based components to detect NIs (we elaborate on related work in Section 2).", "labels": [], "entities": []}, {"text": "To this end, a predicate's overt roles are matched against a predefined predicatespecific template.", "labels": [], "entities": []}, {"text": "Informally, all roles found in the template but not in the text are regarded as null instantiations.", "labels": [], "entities": []}, {"text": "Such pattern-based methods perform satisfactorily, yet there are drawbacks: (1) They are inflexible and absolute according to their type, in that they assume that all candidate NIs are equally likely to be missing, which is unrealistic given the variety of different linguistic contexts in which predicates co-occur with their semantic roles.", "labels": [], "entities": []}, {"text": "(2) They are expensive in that they require handcrafted, idiosyncratic rules) and rich background knowledge in the form of language-specific lexical resources, such as FrameNet (),) or NomBank ().", "labels": [], "entities": []}, {"text": "Dictionaries providing information about each predicate and status of the individual roles (e.g., whether they can serve as implicit elements or not) are costly, and for most other languages not available to the same extent as for English.", "labels": [], "entities": []}, {"text": "(3) Most earlier studies heuristically restrict implicit arguments to core roles 2 only, but this is problematic as it ignores the fact that implicit non-core roles also provide valid and valuable information.", "labels": [], "entities": []}, {"text": "Our approach remains agnostic regarding the role inventory, and can address both core and non-core arguments.", "labels": [], "entities": []}, {"text": "Yet, in accordance with the limited evaluation data and inline with earlier literature, we had to restrict ourselves to evaluate NI predictions for core arguments only.", "labels": [], "entities": []}, {"text": "Our contribution We propose a novel, generic approach to infer information about implicit roles which does not rely on the availability of manually annotated gold data.", "labels": [], "entities": []}, {"text": "Our focus is exclusively on NI role identification, i.e., per-predicate detection of the missing implicit semantic role(s) given their overtly expressed explicit role(s) (without finding filler elements) as we believe that it serves as a crucial preprocessing step and still bears great potential for improvement.", "labels": [], "entities": [{"text": "NI role identification", "start_pos": 28, "end_pos": 50, "type": "TASK", "confidence": 0.829265832901001}]}, {"text": "We treat NI identification separately from the resolution of their fillers, also because not all NIs are resolvable from the context.", "labels": [], "entities": [{"text": "NI identification", "start_pos": 9, "end_pos": 26, "type": "TASK", "confidence": 0.8494042754173279}]}, {"text": "In order to facilitate a more flexible mechanism, we propose to condition on the presence of other roles, and primarily argue that NI detection should be probabilistic instead of rulebased.", "labels": [], "entities": [{"text": "NI detection", "start_pos": 131, "end_pos": 143, "type": "TASK", "confidence": 0.8788480758666992}]}, {"text": "More specifically, we predict implicit arguments using large corpora from which we build a background knowledge base of predicates, cooccurring (explicit) roles and their probabilities.", "labels": [], "entities": []}, {"text": "With such a memory-based approach, we gener-alize overlarge quantities of explicit roles to find evidence for implicit information in a mildly supervised manner.", "labels": [], "entities": []}, {"text": "Our proposed models are largely domain independent, include a sense distinction for predicates, and are not bound to a specific release of a hand-maintained dictionary.", "labels": [], "entities": []}, {"text": "Our approach is portable across languages in that training data can be created using projected SRL annotations.", "labels": [], "entities": []}, {"text": "Unlike most earlier approaches, we employ a generic role set which is based on PropBank/NomBank rather than FrameNet: The PropBank format comprises a relatively small role inventory which is better suited to obtain statistical generalizations than the great variety of highly specific FrameNet roles.", "labels": [], "entities": []}, {"text": "While FrameNet roles seem to be more fine-grained, their greater number arises mostly from predicate-specific semantic roles, whose specific semantics can be recovered from PropBank annotations by pairing semantic roles with the predicate.", "labels": [], "entities": []}, {"text": "Yet another motivation of our work is related to the recent development of AMR parsing (Banarescu et al., 2013, Abstract Meaning Representation) which aims at modeling the semantic representation of a sentence while abstracting from syntactic idiosyncrasies.", "labels": [], "entities": [{"text": "AMR parsing", "start_pos": 75, "end_pos": 86, "type": "TASK", "confidence": 0.9213102459907532}, {"text": "Abstract Meaning Representation)", "start_pos": 112, "end_pos": 144, "type": "TASK", "confidence": 0.6564906090497971}]}, {"text": "This particular appraoch makes extensive use of the PropBank-style framesets, as well, and would greatly benefit from the integration of information on implicit roles.", "labels": [], "entities": [{"text": "PropBank-style framesets", "start_pos": 52, "end_pos": 76, "type": "DATASET", "confidence": 0.9647155404090881}]}, {"text": "The paper is structured as follows: Section 2 outlines related work in which we exclusively focus on how previous research has handled the sole identification of NIs.", "labels": [], "entities": [{"text": "identification of NIs", "start_pos": 144, "end_pos": 165, "type": "TASK", "confidence": 0.7920438845952352}]}, {"text": "3 describes our approach to probabilistic NI detection; Sect.", "labels": [], "entities": [{"text": "NI detection", "start_pos": 42, "end_pos": 54, "type": "TASK", "confidence": 0.9062015414237976}]}, {"text": "4 presents two experiments and their evaluation; Sect.", "labels": [], "entities": []}], "datasetContent": [{"text": "To evaluate the general usefulness of our memorybased approach to detect implicit roles, we setup a simplified framework for predicates with exactly one overt argument and one NI annotated in the SemEval data (for all verbs and all nouns and from both the train and test files to obtain a reasonably large sample; no differentiation of DNIs and INIs).", "labels": [], "entities": [{"text": "SemEval data", "start_pos": 196, "end_pos": 208, "type": "DATASET", "confidence": 0.7344432473182678}]}, {"text": "This pattern accounts for 189 instances-roughly 9% of the data samples in the SemEval set.", "labels": [], "entities": [{"text": "SemEval set", "start_pos": 78, "end_pos": 89, "type": "DATASET", "confidence": 0.8126460313796997}]}, {"text": "We divided the instances into two subsets based on the predicate's part of speech.", "labels": [], "entities": []}, {"text": "The label distributions over overt and null instantiated roles for both verbal and nominal predicates are given in.", "labels": [], "entities": []}, {"text": "Concerning our parameter-based classifiers, the main observations are: First, the overall performance (F 1 score) increases from C 0 to C 4 (yet not significantly).", "labels": [], "entities": [{"text": "F 1 score)", "start_pos": 103, "end_pos": 113, "type": "METRIC", "confidence": 0.983306959271431}]}, {"text": "Secondly, with more parameters, recall decreases while precision increases.", "labels": [], "entities": [{"text": "recall", "start_pos": 32, "end_pos": 38, "type": "METRIC", "confidence": 0.9997634291648865}, {"text": "precision", "start_pos": 55, "end_pos": 64, "type": "METRIC", "confidence": 0.9996888637542725}]}, {"text": "We can observe, however, that improvements from C 2 to C 4 are marginal, at best, due to the sparsity of predicates with two or more overt arguments.", "labels": [], "entities": []}, {"text": "Similar problems related to data sparsity have been reported in.", "labels": [], "entities": []}, {"text": "Results for C 3 and C 4 are identical, as no predicate with more than three overt arguments occurred in the test data.", "labels": [], "entities": []}, {"text": "Encoding the distinction between verbal and nominal predicates into the classifier again slightly increases the performance.", "labels": [], "entities": []}, {"text": "A combination of the high-precision supervised classifiers and the best performing mildly supervised algorithm yields a significant boost in performance (Tab. 4, last two columns).", "labels": [], "entities": []}, {"text": "The optimal parameter values for all classifiers C 4n,v estimated on the train section of the SemEval data set are given in  In, we report the performance of our best classifier C 4 n,v,B2 with detailed label scores.", "labels": [], "entities": [{"text": "SemEval data set", "start_pos": 94, "end_pos": 110, "type": "DATASET", "confidence": 0.8729132612546285}]}, {"text": "Its overall NI recognition rate of 0.81 (recall) outperforms the state-of-the-art in implicit role identification: cf. L&P (0.66), SEMAFOR (0.63), S&F (0.58), T&D (0.54), VENSES++ (0.08).", "labels": [], "entities": [{"text": "NI recognition rate", "start_pos": 12, "end_pos": 31, "type": "METRIC", "confidence": 0.6917018890380859}, {"text": "recall", "start_pos": 41, "end_pos": 47, "type": "METRIC", "confidence": 0.9990371465682983}, {"text": "role identification", "start_pos": 94, "end_pos": 113, "type": "TASK", "confidence": 0.6957736164331436}, {"text": "SEMAFOR", "start_pos": 131, "end_pos": 138, "type": "METRIC", "confidence": 0.6109887361526489}, {"text": "VENSES", "start_pos": 171, "end_pos": 177, "type": "METRIC", "confidence": 0.8492361903190613}]}, {"text": "Summarizing our results, Exp.", "labels": [], "entities": []}, {"text": "2 has shown that combining supervised and mildly supervised strategies to NI detection achieves the best results on the SemEval test set.", "labels": [], "entities": [{"text": "NI detection", "start_pos": 74, "end_pos": 86, "type": "TASK", "confidence": 0.8247005641460419}, {"text": "SemEval test set", "start_pos": 120, "end_pos": 136, "type": "DATASET", "confidence": 0.8592728773752848}]}, {"text": "Concerning the mildly supervised, parameter-based classifiers, it Note that only an indirect comparison of these scores is possible due to the aforementioned difference between data formats and also because none of the other systems report precision scores for their pattern-based NI detection systems.  has proven beneficial to incorporate a maximum of available information on overtly expressed arguments in order to determine implicit roles.", "labels": [], "entities": [{"text": "precision scores", "start_pos": 240, "end_pos": 256, "type": "METRIC", "confidence": 0.9629659950733185}, {"text": "NI detection", "start_pos": 281, "end_pos": 293, "type": "TASK", "confidence": 0.7578393220901489}]}, {"text": "Our best-performing classifier achieves NI recognition rate beyond state-of-the-art.", "labels": [], "entities": [{"text": "NI", "start_pos": 40, "end_pos": 42, "type": "METRIC", "confidence": 0.6782388687133789}, {"text": "recognition", "start_pos": 43, "end_pos": 54, "type": "METRIC", "confidence": 0.42480209469795227}]}, {"text": "Interestingly, memory-based learning offers the capability to detect both DNIs (resolvable from context), as well as INIs (not resolvable from context), simply by learning patterns from local explicit role realizations.", "labels": [], "entities": []}, {"text": "Subsequent experiments should extend this approach to distinguish between the two types, as well, which we have treated equivalently in our settings.", "labels": [], "entities": []}, {"text": "First promising experiments in this direction are being conducted in.", "labels": [], "entities": []}, {"text": "The setup from the previous experiment is by far too simplistic compared to areal linguistic scenario.", "labels": [], "entities": []}, {"text": "Usually, a predicate can have an arbitrary number of overt arguments, and similarly the number of missing NIs varies.", "labels": [], "entities": []}, {"text": "To tackle this problem, we take the original train and test split (744 vs. 929 unrestricted frame instances of the form: any combination of overt roles vs. any combination of NI roles per predicate).", "labels": [], "entities": []}, {"text": "Again, we do not draw a distinction between DNIs and INIs, but treat them generally as NIs.", "labels": [], "entities": []}, {"text": "shows the distribution of the different NI role patterns in the test data.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Label distribution of the SemEval 2010 data set for", "labels": [], "entities": [{"text": "SemEval 2010 data set", "start_pos": 36, "end_pos": 57, "type": "DATASET", "confidence": 0.8301456272602081}]}, {"text": " Table 2: Label distributions of all roles in both data sets", "labels": [], "entities": []}, {"text": " Table 4: Precision, recall and F1 scores for all classifiers introduced in Experiment 2. Scores are compared row-wise to the", "labels": [], "entities": [{"text": "Precision", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9991590976715088}, {"text": "recall", "start_pos": 21, "end_pos": 27, "type": "METRIC", "confidence": 0.9979296922683716}, {"text": "F1 scores", "start_pos": 32, "end_pos": 41, "type": "METRIC", "confidence": 0.9777779877185822}]}, {"text": " Table 5: Optimal parameter values for the thresholds in", "labels": [], "entities": []}, {"text": " Table 6: Evaluation of C4 n,v,B2 for all 252 implicit roles.", "labels": [], "entities": []}]}