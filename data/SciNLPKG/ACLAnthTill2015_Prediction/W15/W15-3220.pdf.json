{"title": [{"text": "TECHLIMED@QALB-Shared Task 2015: a hybrid Arabic Error Correction System", "labels": [], "entities": [{"text": "TECHLIMED@QALB-Shared Task 2015", "start_pos": 0, "end_pos": 31, "type": "DATASET", "confidence": 0.5339442968368531}]}], "abstractContent": [{"text": "This paper reports on the participation of Techlimed in the Second Shared Task on Automatic Arabic Error Correction organized by the Arabic Natural Language Processing Workshop.", "labels": [], "entities": [{"text": "Automatic Arabic Error Correction organized by the Arabic Natural Language Processing Workshop", "start_pos": 82, "end_pos": 176, "type": "TASK", "confidence": 0.5984307875235876}]}, {"text": "This year's competition includes two tracks, and, in addition to errors produced by native speakers (L1), also includes correction of texts written by learners of Arabic as a foreign language (L2).", "labels": [], "entities": []}, {"text": "Techlimed participated in the L1 track.", "labels": [], "entities": []}, {"text": "For our participation in the L1 evaluation task, we developed two systems.", "labels": [], "entities": [{"text": "L1 evaluation task", "start_pos": 29, "end_pos": 47, "type": "TASK", "confidence": 0.7575029333432516}]}, {"text": "The first one is based on the spell-checker Hunspell with specific dictionaries.", "labels": [], "entities": [{"text": "Hunspell", "start_pos": 44, "end_pos": 52, "type": "DATASET", "confidence": 0.793788731098175}]}, {"text": "The second one is a hybrid system based on rules, morphology analysis and statistical machine translation.", "labels": [], "entities": [{"text": "morphology analysis", "start_pos": 50, "end_pos": 69, "type": "TASK", "confidence": 0.6993429064750671}, {"text": "statistical machine translation", "start_pos": 74, "end_pos": 105, "type": "TASK", "confidence": 0.6403553287188212}]}, {"text": "Our results on the test set show that the hybrid system outperforms the lexicon driven approach with a precision of 71.2%, a recall of 64.94% and an F-measure of 67.93%.", "labels": [], "entities": [{"text": "precision", "start_pos": 103, "end_pos": 112, "type": "METRIC", "confidence": 0.9990457892417908}, {"text": "recall", "start_pos": 125, "end_pos": 131, "type": "METRIC", "confidence": 0.999005138874054}, {"text": "F-measure", "start_pos": 149, "end_pos": 158, "type": "METRIC", "confidence": 0.999574601650238}]}], "introductionContent": [{"text": "Spell checking is an important task in Natural Language Processing (NLP).", "labels": [], "entities": [{"text": "Spell checking", "start_pos": 0, "end_pos": 14, "type": "TASK", "confidence": 0.9665994942188263}, {"text": "Natural Language Processing (NLP)", "start_pos": 39, "end_pos": 72, "type": "TASK", "confidence": 0.7159081697463989}]}, {"text": "It can be used in a wide range of applications such as word processing tools, machine translation, information retrieval, optical character recognition etc.", "labels": [], "entities": [{"text": "word processing", "start_pos": 55, "end_pos": 70, "type": "TASK", "confidence": 0.8377351462841034}, {"text": "machine translation", "start_pos": 78, "end_pos": 97, "type": "TASK", "confidence": 0.8223924934864044}, {"text": "information retrieval", "start_pos": 99, "end_pos": 120, "type": "TASK", "confidence": 0.8167847692966461}, {"text": "optical character recognition", "start_pos": 122, "end_pos": 151, "type": "TASK", "confidence": 0.708668053150177}]}, {"text": "Automatic error correction tools on Arabic are underperforming in comparison with other languages like English or French.", "labels": [], "entities": [{"text": "error correction", "start_pos": 10, "end_pos": 26, "type": "TASK", "confidence": 0.6920354217290878}]}, {"text": "The lack of appropriate resources (e.g. publicly available corpora and tools) and the complexity of the Arabic language can explain this difference.", "labels": [], "entities": []}, {"text": "Arabic is a challenging language for any NLP tool for many reasons.", "labels": [], "entities": []}, {"text": "Arabic has a rich and complex morphology compared to other languages.", "labels": [], "entities": []}, {"text": "Short vowels are missing in the texts but are mandatory from a grammatical point of view.", "labels": [], "entities": []}, {"text": "Moreover, they are needed to disambiguate between several possibilities of words.", "labels": [], "entities": []}, {"text": "Arabic is a rich language.", "labels": [], "entities": []}, {"text": "It is characterised by its great number of synonyms and is a highly agglutinative, inflectional and derivational language that uses clitics (proclitics and enclitics).", "labels": [], "entities": []}, {"text": "Modern Standard Arabic represents the variety of the news and formal speech.", "labels": [], "entities": []}, {"text": "Classical Arabic refers to religious and classical texts.", "labels": [], "entities": []}, {"text": "Dialectal Arabic has no standard rules for orthography and is based on the pronunciation.", "labels": [], "entities": []}, {"text": "Therefore, a same word can be written using many different surface forms depending on the dialectal origin of the writer.", "labels": [], "entities": []}, {"text": "Another very popular way of writing Arabic on the Internet and the social media like Facebook or Tweeter is to use \"Arabizi\", a Latinized form of writing Arabic using Latin letters and digits).", "labels": [], "entities": []}, {"text": "For our participation in this second QALB Shared Task, we tried to improve the systems we have developed for the first edition).", "labels": [], "entities": [{"text": "QALB Shared Task", "start_pos": 37, "end_pos": 53, "type": "TASK", "confidence": 0.5143754581610361}]}, {"text": "The first approach is a lexicon driven spellchecker using Hunspell).", "labels": [], "entities": []}, {"text": "The second approach is a hybrid system based on correction rules, morphological analysis and statistical machine translation.", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 93, "end_pos": 124, "type": "TASK", "confidence": 0.6225871940453848}]}, {"text": "The paper is organized as follows: section 2 gives an overview of the automatic error correction evaluation task and resources provided by the organizers; section 3 describes the systems we have developed for the evaluations; and finally in section 4 we discuss the results and draw some conclusion.", "labels": [], "entities": [{"text": "automatic error correction evaluation task", "start_pos": 70, "end_pos": 112, "type": "TASK", "confidence": 0.7257801413536071}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 1 Example of Hunspell dictionary", "labels": [], "entities": [{"text": "Hunspell", "start_pos": 20, "end_pos": 28, "type": "DATASET", "confidence": 0.6401525139808655}]}, {"text": " Table 4 and Table 5.", "labels": [], "entities": []}, {"text": " Table 4 Results on the development data (Alj- test-2014)", "labels": [], "entities": [{"text": "Alj- test-2014)", "start_pos": 42, "end_pos": 57, "type": "DATASET", "confidence": 0.9292722344398499}]}, {"text": " Table 5 Results on the evaluation data (Alj-Test- 2015)", "labels": [], "entities": [{"text": "Alj-Test- 2015)", "start_pos": 41, "end_pos": 56, "type": "DATASET", "confidence": 0.9447511583566666}]}, {"text": " Table 6 Performance of TECH-2 on the evalua- tion data (Alj-Test-2015) by component.", "labels": [], "entities": [{"text": "TECH-2", "start_pos": 24, "end_pos": 30, "type": "METRIC", "confidence": 0.7945871949195862}, {"text": "Alj-Test-2015", "start_pos": 57, "end_pos": 70, "type": "DATASET", "confidence": 0.8492850065231323}]}]}