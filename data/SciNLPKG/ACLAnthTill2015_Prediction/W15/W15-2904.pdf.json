{"title": [{"text": "Enhanced Twitter Sentiment Classification Using Contextual Information", "labels": [], "entities": [{"text": "Enhanced Twitter Sentiment Classification", "start_pos": 0, "end_pos": 41, "type": "TASK", "confidence": 0.7481242269277573}]}], "abstractContent": [{"text": "The rise in popularity and ubiquity of Twitter has made sentiment analysis of tweets an important and well-covered area of research.", "labels": [], "entities": [{"text": "sentiment analysis of tweets", "start_pos": 56, "end_pos": 84, "type": "TASK", "confidence": 0.9095586985349655}]}, {"text": "However, the 140 character limit imposed on tweets makes it hard to use standard linguistic methods for sentiment classification.", "labels": [], "entities": [{"text": "sentiment classification", "start_pos": 104, "end_pos": 128, "type": "TASK", "confidence": 0.9571952819824219}]}, {"text": "On the other hand, what tweets lack in structure they makeup with sheer volume and rich metadata.", "labels": [], "entities": []}, {"text": "This metadata includes geolocation, temporal and author information.", "labels": [], "entities": []}, {"text": "We hypothesize that sentiment is dependent on all these contextual factors.", "labels": [], "entities": []}, {"text": "Different locations, times and authors have different emotional valences.", "labels": [], "entities": []}, {"text": "In this paper, we explored this hypothesis by utilizing distant supervision to collect millions of labelled tweets from different locations, times and authors.", "labels": [], "entities": []}, {"text": "We used this data to analyse the variation of tweet sentiments across different authors, times and locations.", "labels": [], "entities": []}, {"text": "Once we explored and understood the relationship between these variables and sentiment, we used a Bayesian approach to combine these variables with more standard linguistic features such as n-grams to create a Twit-ter sentiment classifier.", "labels": [], "entities": []}, {"text": "This combined classifier outperforms the purely linguistic classifier, showing that integrating the rich contextual information available on Twitter into sentiment classification is a promising direction of research.", "labels": [], "entities": [{"text": "sentiment classification", "start_pos": 154, "end_pos": 178, "type": "TASK", "confidence": 0.9405480921268463}]}], "introductionContent": [{"text": "Twitter is a micro-blogging platform and asocial network where users can publish and exchange short messages of up to 140 characters long (also known as tweets).", "labels": [], "entities": []}, {"text": "Twitter has seen a great rise in popularity in recent years because of its availability and ease-of-use.", "labels": [], "entities": []}, {"text": "This rise in popularity and the public nature of Twitter (less than 10% of Twitter accounts are private) have made it an important tool for studying the behaviour and attitude of people.", "labels": [], "entities": []}, {"text": "One area of research that has attracted great attention in the last few years is that of tweet sentiment classification.", "labels": [], "entities": [{"text": "tweet sentiment classification", "start_pos": 89, "end_pos": 119, "type": "TASK", "confidence": 0.8841020862261454}]}, {"text": "Through sentiment classification and analysis, one can get a picture of people's attitudes about particular topics on Twitter.", "labels": [], "entities": [{"text": "sentiment classification", "start_pos": 8, "end_pos": 32, "type": "TASK", "confidence": 0.8823125958442688}]}, {"text": "This can be used for measuring people's attitudes towards brands, political candidates, and social issues.", "labels": [], "entities": []}, {"text": "There have been several works that do sentiment classification on Twitter using standard sentiment classification techniques, with variations of n-gram and bag of words being the most common.", "labels": [], "entities": [{"text": "sentiment classification", "start_pos": 38, "end_pos": 62, "type": "TASK", "confidence": 0.9590629041194916}, {"text": "sentiment classification", "start_pos": 89, "end_pos": 113, "type": "TASK", "confidence": 0.8303906619548798}]}, {"text": "There have been attempts at using more advanced syntactic features as is done in sentiment classification for other domains), however the 140 character limit imposed on tweets makes this hard to do as each article in the Twitter training set consists of sentences of no more than several words, many of them with irregular form ().", "labels": [], "entities": [{"text": "sentiment classification", "start_pos": 81, "end_pos": 105, "type": "TASK", "confidence": 0.9163842499256134}]}, {"text": "On the other hand, what tweets lack in structure they makeup with sheer volume and rich metadata.", "labels": [], "entities": []}, {"text": "This metadata includes geolocation, temporal and author information.", "labels": [], "entities": []}, {"text": "We hypothesize that sentiment is dependent on all these contextual factors.", "labels": [], "entities": []}, {"text": "Different locations, times and authors have different emotional valences.", "labels": [], "entities": []}, {"text": "For instance, people are generally happier on weekends and certain hours of the day, more depressed at the end of summer holidays, and happier in certain states in the United States.", "labels": [], "entities": []}, {"text": "Moreover, people have different baseline emotional valences from one another.", "labels": [], "entities": []}, {"text": "These claims are supported for example by the annual Gallup poll that ranks states from most happy to least happy (), or the work by) that showed reported happiness varies significantly by day of week and time of day.", "labels": [], "entities": [{"text": "Gallup poll", "start_pos": 53, "end_pos": 64, "type": "DATASET", "confidence": 0.8851957619190216}]}, {"text": "We believe these factors manifest themselves in sentiments expressed in tweets and that by accounting for these factors, we can improve sentiment classification on Twitter.", "labels": [], "entities": [{"text": "sentiment classification", "start_pos": 136, "end_pos": 160, "type": "TASK", "confidence": 0.845601350069046}]}, {"text": "In this work, we explored this hypothesis by utilizing distant supervision () to collect millions of labelled tweets from different locations (within the USA), times of day, days of the week, months and authors.", "labels": [], "entities": []}, {"text": "We used this data to analyse the variation of tweet sentiments across the aforementioned categories.", "labels": [], "entities": []}, {"text": "We then used a Bayesian approach to incorporate the relationship between these factors and tweet sentiments into standard n-gram based Twitter sentiment classification.", "labels": [], "entities": [{"text": "n-gram based Twitter sentiment classification", "start_pos": 122, "end_pos": 167, "type": "TASK", "confidence": 0.6190388858318329}]}, {"text": "This paper is structured as follows.", "labels": [], "entities": []}, {"text": "In the next sections we will review related work on sentiment classification, followed by a detailed explanation of our approach and our data collection, annotation and processing efforts.", "labels": [], "entities": [{"text": "sentiment classification", "start_pos": 52, "end_pos": 76, "type": "TASK", "confidence": 0.9659307599067688}]}, {"text": "After that, we describe our baseline n-gram sentiment classifier model, followed by the explanation of how the baseline model is extended to incorporate contextual information.", "labels": [], "entities": []}, {"text": "Next, we describe our analysis of the variation of sentiment within each of the contextual categories.", "labels": [], "entities": []}, {"text": "We then evaluate our models and finally summarize our findings and contributions and discuss possible paths for future work.", "labels": [], "entities": []}], "datasetContent": [{"text": "We collected two datasets, one massive and labelled through distant supervision, the other small and labelled by humans.", "labels": [], "entities": []}, {"text": "The massive dataset was used to calculate the prior probabilities for each of our contextual categories.", "labels": [], "entities": []}, {"text": "Both datasets were used to train and test our sentiment classifier.", "labels": [], "entities": [{"text": "sentiment classifier", "start_pos": 46, "end_pos": 66, "type": "TASK", "confidence": 0.8805260956287384}]}, {"text": "The human-labelled dataset was used as a sanity check to make sure the dataset labelled using the emoticons classifier was not too noisy and that the human and emoticon labels matched fora majority of tweets.", "labels": [], "entities": []}, {"text": "We collected a total of 18 million, geo-tagged, English-language tweets over three years, from January 1st, 2012 to January 1st, 2015, evenly divided across all 36 months, using Historical PowerTrack for Twitter 2 provided by GNIP 3 . We created geolocation bounding boxes 4 for each of the 50 states which were used to collect our dataset.", "labels": [], "entities": []}, {"text": "All 18 million tweets originated from one of the 50 states and are tagged as such.", "labels": [], "entities": []}, {"text": "Moreover, all tweets contained one of the six emoticons in Table 1 and were labelled as either positive or negative based on the emoticon.", "labels": [], "entities": []}, {"text": "Out of the 18 million tweets, 11.2 million (62%) were labelled as positive and 6.8 million (38%) were labelled as negative.", "labels": [], "entities": []}, {"text": "The 18 million tweets came from 7, 657, 158 distinct users.", "labels": [], "entities": []}, {"text": "We randomly selected 3000 tweets from our large dataset and had all their emoticons stripped.", "labels": [], "entities": []}, {"text": "We then had these tweets labelled as positive or negative by three human annotators.", "labels": [], "entities": []}, {"text": "We measured the inter-annotator agreement using Fleiss' kappa, which calculates the degree of agreement in classification over that which would be expected by chance.", "labels": [], "entities": [{"text": "Fleiss' kappa", "start_pos": 48, "end_pos": 61, "type": "DATASET", "confidence": 0.8123085498809814}]}, {"text": "The kappa score for the three annotators was 0.82, which means that there were disagreements in sentiment fora small portion of the tweets.", "labels": [], "entities": [{"text": "kappa score", "start_pos": 4, "end_pos": 15, "type": "METRIC", "confidence": 0.9225052297115326}]}, {"text": "However, the number of tweets that were labelled the same by at least two of the three human annotator was 2908 out of of the 3000 tweets (96%).", "labels": [], "entities": []}, {"text": "Of these 2908 tweets, 60% were labelled as positive and 40% as negative.", "labels": [], "entities": []}, {"text": "We then measured the agreement between the human labels and emoticon-based labels, using only tweets that were labelled the same by at least two of the three human annotators (the majority label was used as the label for the tweet).", "labels": [], "entities": []}, {"text": "shows the confusion matrix between human and emoticon-based annotations.", "labels": [], "entities": []}, {"text": "As you can see, 85% of all labels matched ( 1597+822 1597+882+281+148 = .85).", "labels": [], "entities": []}, {"text": "These results are very promising and show that using emoticon-based distant supervision to label the sentiment of tweets is an acceptable method.", "labels": [], "entities": [{"text": "label the sentiment of tweets", "start_pos": 91, "end_pos": 120, "type": "TASK", "confidence": 0.7657342791557312}]}, {"text": "Though there is some noise introduced to the dataset (as evidenced by the 15% of tweets whose human labels did not match their emoticon labels), the sheer volume of labelled data that this method makes accessible, far outweighs the relatively small amount of noise introduced.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 3: Classifier accuracy, sorted from worst to  best.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 21, "end_pos": 29, "type": "METRIC", "confidence": 0.9898970127105713}]}]}