{"title": [], "abstractContent": [{"text": "We propose to use Graph Rewriting for parsing syntactic dependencies.", "labels": [], "entities": [{"text": "Graph Rewriting", "start_pos": 18, "end_pos": 33, "type": "TASK", "confidence": 0.7000191658735275}, {"text": "parsing syntactic dependencies", "start_pos": 38, "end_pos": 68, "type": "TASK", "confidence": 0.8830638726552328}]}, {"text": "We present a system of rewriting rules dedicated to French and we evaluate it by parsing the SEQUOIA corpus.", "labels": [], "entities": [{"text": "SEQUOIA corpus", "start_pos": 93, "end_pos": 107, "type": "DATASET", "confidence": 0.8688134551048279}]}], "introductionContent": [{"text": "The most popular frameworks (TAG, CG, LFG, HPSG) for symbolic parsing are based on the notion of grammar.", "labels": [], "entities": [{"text": "symbolic parsing", "start_pos": 53, "end_pos": 69, "type": "TASK", "confidence": 0.7187172472476959}]}, {"text": "They defined a set of initial structures (often strongly linked to a lexicon) and a set of rules to express how initial structures can combine into larger ones.", "labels": [], "entities": []}, {"text": "In this setting, parsing consists in searching fora syntactic structure predicted by the grammar for an input sentence.", "labels": [], "entities": [{"text": "parsing", "start_pos": 17, "end_pos": 24, "type": "TASK", "confidence": 0.9661413431167603}]}, {"text": "Among drawbacks of these methods, there is the fact that they maybe inefficient when large-coverage grammar are considered (the search space grows very quickly for large sentences) and that they are not easy to use in contexts where robust parsing is needed (grammars describe set of correct sentences but do not give structures to sentences that are not completely covered by the grammar).", "labels": [], "entities": []}, {"text": "Another problem with grammar-based parsing is that it is a difficult task to maintain the global consistency of the grammar.", "labels": [], "entities": []}, {"text": "Moreover, development of large coverage grammar is known to be a time-consuming task.", "labels": [], "entities": []}, {"text": "On the other side, statistical methods build language models with learning algorithm applied to large annotated corpora.", "labels": [], "entities": []}, {"text": "With respect to symbolic methods, it is easier to build robust parser with these methods and it is also easier to adapt a method to anew kind of corpus or to anew natural language.", "labels": [], "entities": []}, {"text": "The main drawbacks are that good results are obtained only if large and wellannotated corpora are available.", "labels": [], "entities": []}, {"text": "It is also difficult to improve a system: learning provides a language model which is essentially a black box which cannot be read by a human; external mechanism must be used if someone want to include linguistic knowledge in the system.", "labels": [], "entities": []}, {"text": "In this paper we propose a symbolic method which is defined in a Graph Rewriting (GR) framework.", "labels": [], "entities": [{"text": "Graph Rewriting (GR)", "start_pos": 65, "end_pos": 85, "type": "TASK", "confidence": 0.7450754046440125}]}, {"text": "The output format is dependency syntax of natural language sentences.", "labels": [], "entities": []}, {"text": "We propose to describe the parsing process as a sequence of atomic transformations starting from a list of lexical units (a tokenized sentence) to a dependency tree 1 built on the same lexical units.", "labels": [], "entities": []}, {"text": "Each atomic transformation is described by a handcrafted rule.", "labels": [], "entities": []}, {"text": "Then, instead of defining a grammar that describes the set of well-formed structures, we define rules which describe linguistic contexts in which a dependency relation can appear.", "labels": [], "entities": []}, {"text": "The rule system input is made of lemmatized and POS-tagged sentences.", "labels": [], "entities": []}, {"text": "For the experiments in this paper, we use the SEQUOIA corpus) (version 6.0 2 ) as the gold standard.", "labels": [], "entities": [{"text": "SEQUOIA corpus)", "start_pos": 46, "end_pos": 61, "type": "DATASET", "confidence": 0.8180237313111623}]}, {"text": "We experiment our system in two settings: on gold POS-tagged text (taken from SEQUOIA data) and on POS-tagging given by the MElt tagger.", "labels": [], "entities": [{"text": "SEQUOIA data", "start_pos": 78, "end_pos": 90, "type": "DATASET", "confidence": 0.8633141815662384}]}, {"text": "We use the general framework of GR where each transformation is given by two parts: first, the conditions that control when the transformation may apply (the pattern) and second, a description of the way the structure should be modified.", "labels": [], "entities": []}, {"text": "In the system we proposed, the input format is a tokenized sentence where each lexical unit is given a lemma and a POS-tag; the output format is a dependency structure; hence, both input and output structure can be represented as trees.", "labels": [], "entities": []}, {"text": "Nevertheless, we use GR to describe our rules.", "labels": [], "entities": []}, {"text": "At a first sight, it maybe surprising to use such a formalism to manipulate only trees.", "labels": [], "entities": []}, {"text": "But, the first thing to notice is that matching algorithms used in GR are direct generalization of matching algorithm that can The output may a partial dependency trees.", "labels": [], "entities": []}, {"text": "2 https://gforge.inria.fr/projects/sequoiabank/ 30 be used in tree transformation: it means that, if all structures and patterns happen to be trees, the pattern matching in the GR setting will be as efficient as the pattern matching in the tree rewriting setting.", "labels": [], "entities": [{"text": "tree transformation", "start_pos": 62, "end_pos": 81, "type": "TASK", "confidence": 0.7824337482452393}]}, {"text": "A second benefit of GR is that it becomes possible to express more information in the intermediate structures.", "labels": [], "entities": [{"text": "GR", "start_pos": 20, "end_pos": 22, "type": "TASK", "confidence": 0.8753540515899658}]}, {"text": "In the rule system, we use two kinds of relation to express linear order between lexical entities: the relation SUC links the heads of two partial dependency structures; the relation INIT_SUC links two successive lexical unit of the sentence, even if they have also been integrated in partial dependency structures.", "labels": [], "entities": []}, {"text": "Structures with these two kinds of relations are graphs and cannot be represented as trees.", "labels": [], "entities": []}, {"text": "Ina comparison with other works from the literature, we left out data-driven approaches which are far from our proposal.", "labels": [], "entities": []}, {"text": "In (), (), weighted rules are used to described valid dependency structures and the parsing is expressed as a constraints resolution problem. and propose rule-based processes to produce dependency structures but they are presented as kind of shift-reduce algorithm where word are treated one by one following the reading order, rules describing how each word can be link to the current state.", "labels": [], "entities": []}, {"text": "Each rule only tells that a dependency from a word to another word is acceptable.", "labels": [], "entities": []}, {"text": "More close to our work is the proposal of which defines a set of rules that are used iteratively until a fixpoint is reached and the rules application do not necessarily follow the reading order of the sentence.", "labels": [], "entities": []}, {"text": "However, in rules are encoded as regular expressions and are less flexible than a GR rule can be.", "labels": [], "entities": []}, {"text": "To our knowledge, our proposal is the first use of the Graph Rewriting framework for symbolic dependency parsing.", "labels": [], "entities": [{"text": "Graph Rewriting", "start_pos": 55, "end_pos": 70, "type": "TASK", "confidence": 0.6653560400009155}, {"text": "symbolic dependency parsing", "start_pos": 85, "end_pos": 112, "type": "TASK", "confidence": 0.6671635409196218}]}, {"text": "In Section 2, we describe more precisely the GR framework used in the paper.", "labels": [], "entities": []}, {"text": "In Section 3, the GR system considered is detailed.", "labels": [], "entities": [{"text": "GR", "start_pos": 18, "end_pos": 20, "type": "TASK", "confidence": 0.8426088094711304}]}, {"text": "We finally give experimental results in Section 4.", "labels": [], "entities": []}], "datasetContent": [{"text": "The gold standard data used for evaluation is SE-QUOIA version 6.0, which contains 3,099 French sentences taken from various sources (newspaper, medical texts, Europarl and Wikipedia).", "labels": [], "entities": [{"text": "SE-QUOIA version 6.0", "start_pos": 46, "end_pos": 66, "type": "DATASET", "confidence": 0.7159984707832336}, {"text": "Europarl", "start_pos": 160, "end_pos": 168, "type": "DATASET", "confidence": 0.9757497310638428}]}, {"text": "The full corpus was divided in two homogeneous subcorpora (DEV-SEQUOIA and TEST-SEQUOIA) of the same size.", "labels": [], "entities": [{"text": "TEST-SEQUOIA", "start_pos": 75, "end_pos": 87, "type": "METRIC", "confidence": 0.9761381149291992}]}, {"text": "We used the DEV-SEQUOIA corpus to develop and to improve the rule system; the final evaluation reported below being done on the other part TEST-SEQUOIA.", "labels": [], "entities": [{"text": "DEV-SEQUOIA corpus", "start_pos": 12, "end_pos": 30, "type": "DATASET", "confidence": 0.9645094871520996}, {"text": "TEST-SEQUOIA", "start_pos": 139, "end_pos": 151, "type": "DATASET", "confidence": 0.6578468084335327}]}, {"text": "The input of our rule-based system FRDEP-PARSE are sentences which are tokenized, lemmatized and tagged with the refined system of 28 pos labels defined in).", "labels": [], "entities": [{"text": "FRDEP-PARSE", "start_pos": 35, "end_pos": 46, "type": "DATASET", "confidence": 0.7046904563903809}]}, {"text": "In order to evaluate the FRDEP-PARSE rule system alone, we have made a first experiment (called GOLD-POS) where the input data are taken from the gold corpus: we consider the tokenization, lemmatization and enriched POS of SEQUOIA version 6.0 as input.", "labels": [], "entities": [{"text": "FRDEP-PARSE", "start_pos": 25, "end_pos": 36, "type": "DATASET", "confidence": 0.550659716129303}, {"text": "GOLD-POS", "start_pos": 96, "end_pos": 104, "type": "METRIC", "confidence": 0.7870487570762634}, {"text": "SEQUOIA version 6.0", "start_pos": 223, "end_pos": 242, "type": "DATASET", "confidence": 0.7697052756945292}]}, {"text": "The second experiment tries to evaluate our proposal in a more realistic setting where no gold tagging is available.", "labels": [], "entities": [{"text": "gold tagging", "start_pos": 90, "end_pos": 102, "type": "TASK", "confidence": 0.7273154854774475}]}, {"text": "In this second case, we first use a French tagger to build the input of out system from the raw test.", "labels": [], "entities": []}, {"text": "Our tests are based on MElt (Denis and Sagot, 2012), so we call this sec-ond experiment MELT-POS.", "labels": [], "entities": [{"text": "MElt", "start_pos": 23, "end_pos": 27, "type": "METRIC", "confidence": 0.8767619132995605}, {"text": "MELT-POS", "start_pos": 88, "end_pos": 96, "type": "METRIC", "confidence": 0.8281155824661255}]}, {"text": "In SEQUOIA, there is no clear rules in the annotation guide which explain how punctuation sign should be linked to the rest of the sentence; hence, the punctuation is not annotated in a consistent way.", "labels": [], "entities": [{"text": "SEQUOIA", "start_pos": 3, "end_pos": 10, "type": "DATASET", "confidence": 0.6099345684051514}]}, {"text": "Here, we report scores on the Corpus TEST-SEQUOIA without taking into account the relation punctuation; nevertheless, comma used as a coordination in enumeration are annotated with relation coord and dep.coord and so there are included in the evaluation.", "labels": [], "entities": []}, {"text": "In this context, the LAS (Labelled Attachment Score) corresponds to what is usually called the recall (i.e. the proportion of relations in the reference corpus which are correctly predicted by the system).", "labels": [], "entities": [{"text": "LAS (Labelled Attachment Score)", "start_pos": 21, "end_pos": 52, "type": "METRIC", "confidence": 0.8292613923549652}, {"text": "recall", "start_pos": 95, "end_pos": 101, "type": "METRIC", "confidence": 0.994260311126709}]}, {"text": "The objective of FRDEP-PARSE is not to build complete dependency parse and when it is not sensible to compute a relation with a deterministic rewrite rule, only partial dependency structures are returned and some lexical units are left unattached.", "labels": [], "entities": [{"text": "FRDEP-PARSE", "start_pos": 17, "end_pos": 28, "type": "DATASET", "confidence": 0.7601971626281738}]}, {"text": "This explain why the precision (i.e. the proportion of relations predicted by the system which are correct) is much higher than the recall.", "labels": [], "entities": [{"text": "precision", "start_pos": 21, "end_pos": 30, "type": "METRIC", "confidence": 0.9995269775390625}, {"text": "recall", "start_pos": 132, "end_pos": 138, "type": "METRIC", "confidence": 0.9985045194625854}]}, {"text": "The TEST-SEQUOIA corpus contains 1,550 sentences and 33,662 lexical units.", "labels": [], "entities": [{"text": "TEST-SEQUOIA corpus", "start_pos": 4, "end_pos": 23, "type": "DATASET", "confidence": 0.8198550939559937}]}, {"text": "This corpus is parsed in 51.9 seconds (with a 2.4GHz Intel Core i7) and 32,035 relations are produced; this corresponds to a mean of 617 relations produced per second.", "labels": [], "entities": []}], "tableCaptions": []}