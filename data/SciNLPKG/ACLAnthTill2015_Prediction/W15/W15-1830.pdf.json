{"title": [{"text": "Adapting word2vec to Named Entity Recognition", "labels": [], "entities": [{"text": "Adapting word2vec", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.8142168521881104}, {"text": "Named Entity Recognition", "start_pos": 21, "end_pos": 45, "type": "TASK", "confidence": 0.5977609654267629}]}], "abstractContent": [{"text": "In this paper we explore how word vectors built using word2vec can be used to improve the performance of a classifier during Named Entity Recognition.", "labels": [], "entities": [{"text": "Named Entity Recognition", "start_pos": 125, "end_pos": 149, "type": "TASK", "confidence": 0.7197181781133016}]}, {"text": "Thereby, we discuss the best integration of word embeddings into the classification problem and consider the effect of the size of the unlabelled dataset on performance, reaching the unexpected result that for this particular task increasing the amount of unlabelled data does not necessarily increase the performance of the classifier.", "labels": [], "entities": []}], "introductionContent": [{"text": "Supervised NLP systems suffer from a fundamental data bottleneck problem: though unprecedented amounts of data and the computational power necessary for its processing have become available, supervised training requires data that has been annotated fora specific task.", "labels": [], "entities": []}, {"text": "The process of annotation in turn requires human time and is thereby inherently connected to high costs, both in terms of time and money.", "labels": [], "entities": []}, {"text": "Enhancing supervised methods with unsupervised word representations can ameliorate this problem.", "labels": [], "entities": []}, {"text": "Word representations can be trained on large unannotated corpora and can learn implicit semantic and/or syntactic information.", "labels": [], "entities": []}, {"text": "This information can then be used to augment a small amount of annotated data, thereby reducing the amount of annotated data necessary or improving the accuracy of a classifier with a given amount of annotated data.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 152, "end_pos": 160, "type": "METRIC", "confidence": 0.9987664222717285}]}, {"text": "Different word representations have been shown to successfully improve various NLP tasks.", "labels": [], "entities": []}, {"text": "For example, use word clusters during named entity recognition (henceforth NER) and use continuous word representations as features for dependency parsing (for a larger overview cf.).", "labels": [], "entities": [{"text": "named entity recognition", "start_pos": 38, "end_pos": 62, "type": "TASK", "confidence": 0.6792711019515991}, {"text": "dependency parsing", "start_pos": 136, "end_pos": 154, "type": "TASK", "confidence": 0.8294470012187958}]}, {"text": "Naturally, the main goal of using word representations is adding further information to a classification task.", "labels": [], "entities": []}, {"text": "How to make this information maximally relevant depends on the task given.", "labels": [], "entities": []}, {"text": "Thus, whether we want two words to be considered similar depends on the task in which they are being classified (cf.).", "labels": [], "entities": []}, {"text": "For example, train their word representations on dependency context instead of raw linear context.", "labels": [], "entities": []}, {"text": "In the following we will apply word vectors to the task of NER.", "labels": [], "entities": [{"text": "NER", "start_pos": 59, "end_pos": 62, "type": "TASK", "confidence": 0.9536314010620117}]}, {"text": "Vector based word representations have a successful history of use in information retrieval and computational semantics as an implementation of the long-standing linguistic hypothesis that words that occur in similar contexts tend to have similar meanings.", "labels": [], "entities": [{"text": "Vector based word representations", "start_pos": 0, "end_pos": 33, "type": "TASK", "confidence": 0.6916394084692001}, {"text": "information retrieval", "start_pos": 70, "end_pos": 91, "type": "TASK", "confidence": 0.7281772494316101}]}, {"text": "More recently, word vectors have also been shown to be able to capture linguistic regularities of both semantic ('king' to 'man' is like 'queen' to 'woman') and syntactic nature ('ran' to 'run' is like 'laughed' to 'laugh' ) ().", "labels": [], "entities": []}, {"text": "We first discuss our method of extracting word vectors and adding them to the classification task before describing the task of NER and our more experiments more concretely.", "labels": [], "entities": [{"text": "NER", "start_pos": 128, "end_pos": 131, "type": "TASK", "confidence": 0.8708369731903076}]}, {"text": "In the final discussion we primarily explore engineering options related to the incorporation of the word embeddings and the size of the unlabelled data set.", "labels": [], "entities": []}], "datasetContent": [{"text": "All of our experiments were based on the RCV1 corpus which contains one year of Reuters English newswire from August 1996 to August 1997 ().", "labels": [], "entities": [{"text": "RCV1 corpus which contains one year of Reuters English newswire from August 1996", "start_pos": 41, "end_pos": 121, "type": "DATASET", "confidence": 0.8235760583327367}]}, {"text": "Preprocessing of the RCV1 corpus involved the extraction of text from the news files as well as sentence and word tokenization, both of which we did using the NLTK toolkit.", "labels": [], "entities": [{"text": "RCV1 corpus", "start_pos": 21, "end_pos": 32, "type": "DATASET", "confidence": 0.9497763514518738}, {"text": "sentence and word tokenization", "start_pos": 96, "end_pos": 126, "type": "TASK", "confidence": 0.6162914037704468}]}, {"text": "In order to evaluate the effect of the size of the non-labelled corpus on performance we trained word embeddings on different subsets of RCV1.", "labels": [], "entities": []}, {"text": "The smallest subset was the CoNLL03 corpus.", "labels": [], "entities": [{"text": "CoNLL03 corpus", "start_pos": 28, "end_pos": 42, "type": "DATASET", "confidence": 0.967029482126236}]}, {"text": "Furthermore, we trained word2vec models on a quarter, half and three quarters of RCV1.", "labels": [], "entities": [{"text": "RCV1", "start_pos": 81, "end_pos": 85, "type": "DATASET", "confidence": 0.9726531505584717}]}, {"text": "In Table 1 below we give a rough estimate of the number of documents used for training each model (where a document contains between a few hundred and several thousand words) as well as the number of words represented with word vectors in the word2vec model.", "labels": [], "entities": []}, {"text": "As could be expected given the Zipf distribution of words, the number of unique types does not grow linearly with the number of tokens in a model but begins to stagnate at a large number of documents.", "labels": [], "entities": []}, {"text": "This effect is fortified by necessary design choices: While training the CoNLL03 corpus we set the word2vec 'min count' variable to one (which means that all tokens will be considered) whereas for the larger data sets it was set to the default value of five (only words occurring at least five times are represented) to reduce processing costs.", "labels": [], "entities": [{"text": "CoNLL03 corpus", "start_pos": 73, "end_pos": 87, "type": "DATASET", "confidence": 0.9589195847511292}]}, {"text": "word2vec was reimplemented for use in Python by.", "labels": [], "entities": [{"text": "word2vec", "start_pos": 0, "end_pos": 8, "type": "DATASET", "confidence": 0.9082966446876526}]}, {"text": "We use this implementation to build our models, using the default setting for vector dimensionality (100), as well as for the other parameters such as the number of training iterations and the size of the window.", "labels": [], "entities": []}, {"text": "The classification itself is a greedy implementation of the Linear Support Vector Classification algorithm as implemented in the scikit-learn software, using the default values.", "labels": [], "entities": [{"text": "Linear Support Vector Classification", "start_pos": 60, "end_pos": 96, "type": "TASK", "confidence": 0.5951607450842857}]}, {"text": "Linear SVC was shown by to perform comparably to more computationally complex and costly search algorithms such as beamsearch or Viterbi.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Data set statistics.", "labels": [], "entities": []}]}