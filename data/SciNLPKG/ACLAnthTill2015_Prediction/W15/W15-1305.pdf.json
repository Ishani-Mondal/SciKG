{"title": [{"text": "Extending NegEx with Kernel Methods for Negation Detection in Clinical Text", "labels": [], "entities": [{"text": "Negation Detection", "start_pos": 40, "end_pos": 58, "type": "TASK", "confidence": 0.8968266248703003}]}], "abstractContent": [{"text": "NegEx is a popular rule-based system used to identify negated concepts in clinical notes.", "labels": [], "entities": [{"text": "NegEx", "start_pos": 0, "end_pos": 5, "type": "DATASET", "confidence": 0.858426570892334}]}, {"text": "This system has been reported to perform very well by numerous studies in the past.", "labels": [], "entities": []}, {"text": "In this paper, we demonstrate the use of kernel methods to extend the performance of NegEx.", "labels": [], "entities": []}, {"text": "A kernel leveraging the rules of NegEx and its output as features, performs as well as the rule-based system.", "labels": [], "entities": []}, {"text": "An improvement in performance is achieved if this kernel is coupled with a bag of words kernel.", "labels": [], "entities": []}, {"text": "Our experiments show that kernel methods outperform the rule-based system, when evaluated within and across two different open datasets.", "labels": [], "entities": []}, {"text": "We also present the results of a semi-supervised approach to the problem, which improves performance on the data.", "labels": [], "entities": []}], "introductionContent": [{"text": "Clinical narratives consisting of free-text documents are an important part of the electronic medical record (EMR).", "labels": [], "entities": []}, {"text": "Medical professionals often need to search the EMR for notes corresponding to specific medical events fora particular patient.", "labels": [], "entities": []}, {"text": "Recruitment of subjects in research studies such as clinical trials involves searching through the EMR of multiple patients to find a cohort of relevant candidates.", "labels": [], "entities": [{"text": "Recruitment", "start_pos": 0, "end_pos": 11, "type": "TASK", "confidence": 0.9745278358459473}]}, {"text": "Most information retrieval approaches determine a document to be relevant to a concept based on the presence of that concept in the document.", "labels": [], "entities": [{"text": "information retrieval", "start_pos": 5, "end_pos": 26, "type": "TASK", "confidence": 0.7388304769992828}]}, {"text": "However, these approaches fall short if these concepts are negated, leading to a number of false positives.", "labels": [], "entities": []}, {"text": "This is an important problem especially in the clinical domain.", "labels": [], "entities": []}, {"text": "For example, the sentence: \"The scan showed no signs of malignancy\" has the concept 'malignancy' which was looked for in the patient, but was not observed to be present.", "labels": [], "entities": []}, {"text": "The task of negation detection is to identify whether a given concept is negated or affirmed in a sentence.) is a rule-based system developed to detect negated concepts in the clinical domain and has been extensively used in the literature.", "labels": [], "entities": [{"text": "negation detection", "start_pos": 12, "end_pos": 30, "type": "TASK", "confidence": 0.9811652600765228}]}, {"text": "In this paper, we show that a kernel-based approach can map this rule-based system into a machine learning system and extends its performance.", "labels": [], "entities": []}, {"text": "We validate the generalization capabilities of our approach by evaluating it across datasets.", "labels": [], "entities": []}, {"text": "Finally, we demonstrate that a semi-supervised approach can also achieve an improvement over the baseline rulebased system, a valuable finding in the clinical domain where annotated data is expensive to generate.", "labels": [], "entities": []}], "datasetContent": [{"text": "A test set of de-identified sentences, extracted from clinical notes at the University of Pittsburgh Medical Center, is also available with the NegEx source code.", "labels": [], "entities": [{"text": "NegEx source code", "start_pos": 144, "end_pos": 161, "type": "DATASET", "confidence": 0.9339219331741333}]}, {"text": "In each sentence, a concept of interest has been annotated by physicians with respect to being negated or affirmed in the sentence.", "labels": [], "entities": []}, {"text": "The concepts are non numeric clinical conditions (such as symptoms, findings and diseases) extracted from six types of clinical notes (e.g., discharge summaries, operative notes, echo-cardiograms).", "labels": [], "entities": []}, {"text": "The 2010 i2b2 challenge (Uzuner et al., 2011) on relation extraction had assertion classification as a subtask.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 49, "end_pos": 68, "type": "TASK", "confidence": 0.9143643081188202}]}, {"text": "The corpus for this task along with the annotations is freely available for download.", "labels": [], "entities": []}, {"text": "Based on a given target concept, participants had to classify assertions as either present, absent, or possible in the patient, conditionally present in the patient under certain circumstances, hypothetically present in the patient at some future point, and mentioned in the patient report but associated with someone other than the patient.", "labels": [], "entities": []}, {"text": "Since we focus on negation detection, we selected only assertions corresponding to the positive and negative classes from the five assertion classes in the corpus, which simulates the type of data found in the NegEx Corpus.", "labels": [], "entities": [{"text": "negation detection", "start_pos": 18, "end_pos": 36, "type": "TASK", "confidence": 0.9396981000900269}, {"text": "NegEx Corpus", "start_pos": 210, "end_pos": 222, "type": "DATASET", "confidence": 0.9239985346794128}]}, {"text": "The i2b2 corpus has training data, partitioned into discharge summaries from Partners Healthcare (PH) and the Beth Israel Deaconess (BID) Medical Center.", "labels": [], "entities": []}, {"text": "This gave us datasets from two more medical institutions.", "labels": [], "entities": []}, {"text": "The corpus also has a test set, but does not have a split corresponding to these institutions.", "labels": [], "entities": []}, {"text": "Using the above corpora we constructed five datasets: 1) The dataset available with the NegEx rule-based system, henceforth referred to as the NegCorp dataset; 2) We adapted the training set of the i2b2 assertion classification task for negation detection, the i2b2Train mod dataset; 3) The training subset of i2b2Train mod from Partners Health-  We implemented the kernels outlined in Section 3 and evaluated them within different datasets using precision, recall and F1 on ten-fold cross validation.", "labels": [], "entities": [{"text": "NegCorp dataset", "start_pos": 143, "end_pos": 158, "type": "DATASET", "confidence": 0.9133552014827728}, {"text": "negation detection", "start_pos": 237, "end_pos": 255, "type": "TASK", "confidence": 0.9628756940364838}, {"text": "precision", "start_pos": 447, "end_pos": 456, "type": "METRIC", "confidence": 0.9994919300079346}, {"text": "recall", "start_pos": 458, "end_pos": 464, "type": "METRIC", "confidence": 0.9988192915916443}, {"text": "F1", "start_pos": 469, "end_pos": 471, "type": "METRIC", "confidence": 0.9995694756507874}]}, {"text": "We compared the performance of each model against the NegEx rule-based system as baseline.", "labels": [], "entities": []}, {"text": "As can be seen in, the NegEx Features Kernel performed similarly to the baseline (the improvement is not significant).", "labels": [], "entities": [{"text": "NegEx Features Kernel", "start_pos": 23, "end_pos": 44, "type": "DATASET", "confidence": 0.6652954816818237}]}, {"text": "However, the ABoW kernel significantly outperformed the baseline (p<0.05, McNemar's test).", "labels": [], "entities": []}, {"text": "showed that given two kernels K1 and K2, the composite kernel K(x, y) = K1(x, y) + K2(x, y) is also a kernel.", "labels": [], "entities": []}, {"text": "We constructed a composite kernel adding the kernel matrices for the ABoW and NF kernels, which resulted in a further (but not significant) improvement.", "labels": [], "entities": [{"text": "ABoW", "start_pos": 69, "end_pos": 73, "type": "METRIC", "confidence": 0.84425950050354}]}, {"text": "In order to test the generalizability of our approach, we evaluated the performance of the ABoW kernel against the baseline.", "labels": [], "entities": []}, {"text": "We trained the ABoW kernel on different datasets and tested them on the i2b2Test mod dataset.", "labels": [], "entities": [{"text": "ABoW kernel", "start_pos": 15, "end_pos": 26, "type": "DATASET", "confidence": 0.801924854516983}, {"text": "i2b2Test mod dataset", "start_pos": 72, "end_pos": 92, "type": "DATASET", "confidence": 0.6853549977143606}]}, {"text": "We found that the ABoW kernel significantly outperformed the baseline when trained on datasets that were generated from the same corpus, namely PH and BID.", "labels": [], "entities": [{"text": "BID", "start_pos": 151, "end_pos": 154, "type": "METRIC", "confidence": 0.9353206157684326}]}, {"text": "A kernel trained on i2b2Train mod , i.e., combining the PH and BID datasets performs better than the individually trained datasets.", "labels": [], "entities": [{"text": "BID", "start_pos": 63, "end_pos": 66, "type": "METRIC", "confidence": 0.9442068934440613}]}, {"text": "These experiments also tested the effect of training data size (PH < BID < i2b2Train mod ) on the kernel performance.", "labels": [], "entities": [{"text": "PH", "start_pos": 64, "end_pos": 66, "type": "METRIC", "confidence": 0.9506104588508606}, {"text": "BID", "start_pos": 69, "end_pos": 72, "type": "METRIC", "confidence": 0.8795908689498901}]}, {"text": "We observed that the performance of the kernel increases as the size of the training data increases, though not significantly.", "labels": [], "entities": []}, {"text": "The kernel trained on a dataset from a different corpus (NegCorp) performs as well as the baseline.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Number of affirmed and negated concepts in  each dataset.", "labels": [], "entities": []}, {"text": " Table 2: Within dataset performance of kernels based on  F1-score using 10-fold cross validation. Bold results indi- cate significant improvements over the baseline (p<0.05,  McNemar's test).", "labels": [], "entities": [{"text": "F1-score", "start_pos": 58, "end_pos": 66, "type": "METRIC", "confidence": 0.9978862404823303}, {"text": "McNemar's test", "start_pos": 176, "end_pos": 190, "type": "DATASET", "confidence": 0.6798922618230184}]}, {"text": " Table 3: Cross dataset performance on the i2b2Test mod  dataset given different training datasets.", "labels": [], "entities": [{"text": "i2b2Test mod  dataset", "start_pos": 43, "end_pos": 64, "type": "DATASET", "confidence": 0.6215948164463043}]}, {"text": " Table 4: Semi-supervised models on the i2b2Test mod  dataset.", "labels": [], "entities": [{"text": "i2b2Test mod  dataset", "start_pos": 40, "end_pos": 61, "type": "DATASET", "confidence": 0.6660529573758444}]}]}