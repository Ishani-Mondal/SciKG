{"title": [{"text": "Post-Editing Evaluations: Trade-offs between Novice and Profes- sional Participants", "labels": [], "entities": []}], "abstractContent": [{"text": "The increasing use of post-editing in localisation workflows has led to a great deal of research and development in the area, much of it requiring user evaluation.", "labels": [], "entities": []}, {"text": "This paper compares some results from a post-editing user interface study carried out using novice and expert translator groups.", "labels": [], "entities": []}, {"text": "By comparing rates of productivity, edit distance, engagement with the research, and qualitative findings regarding each group\"s attitude to post-editing, we find that there are trade-offs to be considered when selecting participants for evaluation tasks.", "labels": [], "entities": []}, {"text": "Novices may generally be more positive and enthusiastic and will engage considerably with the research while professionals will be more efficient , but their routines and attitudes may prevent full engagement with research objectives.", "labels": [], "entities": []}], "introductionContent": [{"text": "The use of machine translation (MT) in commercial translation and localisation workflows has grown exponentially in recent years.", "labels": [], "entities": [{"text": "machine translation (MT)", "start_pos": 11, "end_pos": 35, "type": "TASK", "confidence": 0.8577463388442993}]}, {"text": "Relatively recent breakthroughs in the quality of statistical machine translation (SMT) output has led to the use of MT for assimilation (gisting) and MT for dissemination (post-edited \uf020 \u00a9 2015 The authors.", "labels": [], "entities": [{"text": "statistical machine translation (SMT) output", "start_pos": 50, "end_pos": 94, "type": "TASK", "confidence": 0.8065640415464129}]}, {"text": "This article is licensed under a Creative Commons 3.0 licence, no derivative works, attribution, CC-BY-ND.", "labels": [], "entities": []}, {"text": "This research is supported by the Science Foundation Ireland (Grant 12/CE/I2267) as part of the CNGL (www.cngl.ie) at Dublin City University and by the FALCON Project (falcon-project.eu), funded by the European Commission through the Seventh Framework Programme (FP7) Grant Agreement No. 610879. MT).", "labels": [], "entities": [{"text": "Ireland (Grant 12/CE/I2267)", "start_pos": 53, "end_pos": 80, "type": "DATASET", "confidence": 0.7338063915570577}, {"text": "CNGL (www.cngl.ie) at Dublin City University", "start_pos": 96, "end_pos": 140, "type": "DATASET", "confidence": 0.914084181189537}, {"text": "FP7) Grant Agreement No. 610879. MT", "start_pos": 263, "end_pos": 298, "type": "DATASET", "confidence": 0.7736612728663853}]}, {"text": "The growth in the amount of content to be translated and a push for cost-cutting from translation clients has meant that post-editing of MT has grown in popularity -a survey of almost 1000 language service providers (LSPs) in 2013 found that over 44% offer a post-editing (PE) service to customers.", "labels": [], "entities": [{"text": "MT", "start_pos": 137, "end_pos": 139, "type": "TASK", "confidence": 0.9383888840675354}]}, {"text": "This has led to a requirement for user testing, as industry and researchers attempt to learn how translators work with MT, through the task of post-editing, and most usually within a translation memory tool.", "labels": [], "entities": [{"text": "MT", "start_pos": 119, "end_pos": 121, "type": "TASK", "confidence": 0.9185503721237183}]}, {"text": "User dissatisfaction with postediting has been widely reported) and translators tend to associate translation automation negatively with \"regimentation, dependence, exploitation or impotence\".", "labels": [], "entities": [{"text": "translation automation", "start_pos": 98, "end_pos": 120, "type": "TASK", "confidence": 0.8856657147407532}]}, {"text": "Any new features intended to make the task more palatable to translators will naturally need to be tested for effectiveness.", "labels": [], "entities": []}, {"text": "Automatic evaluation metrics (AEMs -such as BLEU) are typically used to measure quality improvements in MT and quality improvements, in turn, are expected to lead to higher levels of satisfaction among post-editors.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 44, "end_pos": 48, "type": "METRIC", "confidence": 0.9827917218208313}, {"text": "MT", "start_pos": 104, "end_pos": 106, "type": "TASK", "confidence": 0.9544380903244019}]}, {"text": "However, some AEMs have been shown not to correlate well with human evaluation of quality, and although automatic metrics measuring edit distance such as Humanmediated Translation Edit Rate (HTER)) have better correlations with human judgements, evaluations with real users are often necessary to gain a deeper understanding of the human/machine interaction and relationship.", "labels": [], "entities": [{"text": "Humanmediated Translation Edit Rate (HTER))", "start_pos": 154, "end_pos": 197, "type": "METRIC", "confidence": 0.7180283452783313}]}, {"text": "User evaluation also offers the possibility of eliciting valuable qualitative data, which can give insights into barriers for adoption and acceptance.", "labels": [], "entities": [{"text": "adoption and acceptance", "start_pos": 126, "end_pos": 149, "type": "TASK", "confidence": 0.6505995492140452}]}, {"text": "Many translation user studies are carried out using translation students, often out of necessity (Morado) or convenience).", "labels": [], "entities": []}, {"text": "On the other hand, the common orthodoxy is that, where possible, it is best to evaluate using experts -professional translators -because they are more representative of the target user group for MT.", "labels": [], "entities": [{"text": "MT", "start_pos": 195, "end_pos": 197, "type": "TASK", "confidence": 0.9897387623786926}]}, {"text": "In this paper we focus on the ramifications of using one user type over another for post-editing research.", "labels": [], "entities": []}, {"text": "We do this by comparing the results of a post-editing user evaluation study using two sets of participants, one novice group (translation students) and one expert group (professional translators and post-editors).", "labels": [], "entities": []}, {"text": "We have chosen translation students rather than lay or untrained volunteer translators as our novice group, as students are more likely to be participants in research.", "labels": [], "entities": []}, {"text": "The purpose of the user evaluation was to test smart post-editing features that had been programmed into a beta post-editing environment in order to test their effectiveness, although we do not report results from that test here.", "labels": [], "entities": []}, {"text": "Instead, we focus explicitly on differences between the two user groups and on their suitability as research participants.", "labels": [], "entities": []}, {"text": "Such differences are sometimes acknowledged but sidestepped when reporting research results.", "labels": [], "entities": []}, {"text": "The measurements collected during the evaluations were speed (measured in source text words per second), edit distance (measured using the Translation Edit Rate (TER) metric), attitudes to post-editing (collected via a survey), and user engagement (we measure the number of clicks on experimental features in the translation interface as a proxy for user engagement).", "labels": [], "entities": [{"text": "speed", "start_pos": 55, "end_pos": 60, "type": "METRIC", "confidence": 0.9957555532455444}, {"text": "edit distance", "start_pos": 105, "end_pos": 118, "type": "METRIC", "confidence": 0.7931651175022125}, {"text": "Translation Edit Rate (TER) metric", "start_pos": 139, "end_pos": 173, "type": "METRIC", "confidence": 0.8207698294094631}]}, {"text": "Yamada (2012) compared novice and professional translators and found productivity increases in both groups using post-editing, although the student group tended to make fewer edits.", "labels": [], "entities": []}, {"text": "found that his students preferred post-editing to human translation, which might make them a more favourable group for user testing.", "labels": [], "entities": [{"text": "human translation", "start_pos": 50, "end_pos": 67, "type": "TASK", "confidence": 0.6613197326660156}]}, {"text": "J\u00e4\u00e4skel\u00e4inen notes that not all professional translators can be considered expert, as they may not produce good quality translations or may fall into an automatic routine when they work.", "labels": [], "entities": []}, {"text": "Moreover, a translator maybe an expert in a specific domain, and not at all expert in another.", "labels": [], "entities": []}, {"text": "In addition, she suggests that experts may underperform for reasons such as \"inflexibility, over-confidence, or bias\".", "labels": [], "entities": []}, {"text": "More generally, professional users have been found to exhibit resistance when faced with change due to a bias toward the status quo, or if they feel they have not been involved in the decision to change.", "labels": [], "entities": []}, {"text": "This outline of previous work suggests that the use of professional translators in post-editing research needs careful consideration because not all professional translators are equal.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1. Group 1 -Experts: Productivity  (Words per Second)", "labels": [], "entities": []}, {"text": " Table 3. Group 1 post-edit example", "labels": [], "entities": []}, {"text": " Table 6. Engagement with PE features", "labels": [], "entities": []}]}