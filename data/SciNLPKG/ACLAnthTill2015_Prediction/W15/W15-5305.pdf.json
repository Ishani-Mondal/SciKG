{"title": [{"text": "Open Relation Extraction for Polish: Preliminary Experiments", "labels": [], "entities": [{"text": "Open Relation Extraction", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.865299920241038}]}], "abstractContent": [{"text": "This paper presents preliminary experiments on Open Relation Extraction for Polish.", "labels": [], "entities": [{"text": "Open Relation Extraction", "start_pos": 47, "end_pos": 71, "type": "TASK", "confidence": 0.8837817112604777}]}, {"text": "In particular, a variant of a prior-art algorithm for open relation extraction for English has been adapted and tested on a set of articles from Polish on-line news.", "labels": [], "entities": [{"text": "open relation extraction", "start_pos": 54, "end_pos": 78, "type": "TASK", "confidence": 0.6427421867847443}]}, {"text": "The paper provides initial evaluation results , which constitute the point of departure for in-depth research in this area.", "labels": [], "entities": []}], "introductionContent": [{"text": "While traditional Information Extraction (IE) systems are tailored to the extraction of predefined set of target relations, an Open Information Extraction (OIE) system focuses on the extraction of non predefined, domain-independent relations from texts.", "labels": [], "entities": [{"text": "Information Extraction (IE)", "start_pos": 18, "end_pos": 45, "type": "TASK", "confidence": 0.8096868395805359}]}, {"text": "The main drive behind the emergence of the OIE paradigm comes from the need to scale IE methods to the size and diversity of the Web (.", "labels": [], "entities": []}, {"text": "Analogously to traditional IE, OIE systems deploy either machine-learned extraction patterns, hand-crafted heuristics or a combination of both of them.", "labels": [], "entities": [{"text": "IE", "start_pos": 27, "end_pos": 29, "type": "TASK", "confidence": 0.9489991664886475}]}, {"text": "TEXTRUNNER ( was the first OIE system based on a ML approach, where the OIE paradigm was introduced.", "labels": [], "entities": [{"text": "TEXTRUNNER", "start_pos": 0, "end_pos": 10, "type": "METRIC", "confidence": 0.6147907972335815}]}, {"text": "WOE () is an extension of TEXTRUNNER, where the Wikipedia corpus was exploited as training data to boost the coverage.", "labels": [], "entities": [{"text": "WOE", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.7726163864135742}, {"text": "TEXTRUNNER", "start_pos": 26, "end_pos": 36, "type": "METRIC", "confidence": 0.5979822278022766}, {"text": "Wikipedia corpus", "start_pos": 48, "end_pos": 64, "type": "DATASET", "confidence": 0.9288568794727325}]}, {"text": "( ) introduced REVERB, the first linguistically-lightweight OIE system based on heuristics, which initially identifies verb phrases and light verb constructions that express relations, and subsequently extracts the relations' arguments in the left/right context thereof.", "labels": [], "entities": [{"text": "REVERB", "start_pos": 15, "end_pos": 21, "type": "METRIC", "confidence": 0.9718661308288574}]}, {"text": "( and are examples of hybrid systems that deploy dependency parsing.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 49, "end_pos": 67, "type": "TASK", "confidence": 0.8368710875511169}]}, {"text": "Relatively little work has been reported on OIE for non-English languages, e.g., () presents an approach based on dependency parsing and provides evaluation figures for non-English languages.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 114, "end_pos": 132, "type": "TASK", "confidence": 0.6746044307947159}]}, {"text": "An extensive overview of research and open problems in OIE is provided in.", "labels": [], "entities": [{"text": "OIE", "start_pos": 55, "end_pos": 58, "type": "DATASET", "confidence": 0.6835436820983887}]}, {"text": "This paper reports on preliminary experiments on developing a scalable linguistically lightweight OIE approach to extraction of arbitrary binary relations from Polish texts.", "labels": [], "entities": [{"text": "extraction of arbitrary binary relations from Polish texts", "start_pos": 114, "end_pos": 172, "type": "TASK", "confidence": 0.8707309886813164}]}, {"text": "We are particularly interested in extraction of relations from online news.", "labels": [], "entities": [{"text": "extraction of relations from online news", "start_pos": 34, "end_pos": 74, "type": "TASK", "confidence": 0.9025242030620575}]}, {"text": "Although the recently reported OIE techniques for extracting binary relations from English texts are advancing rapidly, they might not be directly applicable to languages such as Polish with various phenomena that complicate both IE and OIE tasks, e.g., relatively free word order, rich morphology (including complex proper noun declension paradigm), syncretism of forms (i.e., single form may fulfill different grammatical functions: subject/object), zero anaphora and existence of pro-drop pronouns.", "labels": [], "entities": [{"text": "extracting binary relations from English texts", "start_pos": 50, "end_pos": 96, "type": "TASK", "confidence": 0.8063220381736755}, {"text": "IE", "start_pos": 230, "end_pos": 232, "type": "TASK", "confidence": 0.7996261715888977}]}, {"text": "To our best knowledge, the only work on OIE for Polish has been reported in, where a dependency parsing-based approach to binary relation extraction has been introduced.", "labels": [], "entities": [{"text": "dependency parsing-based", "start_pos": 85, "end_pos": 109, "type": "TASK", "confidence": 0.7089753746986389}, {"text": "binary relation extraction", "start_pos": 122, "end_pos": 148, "type": "TASK", "confidence": 0.6518303453922272}]}, {"text": "The main difference of the aforementioned work vs. ours is that the former focuses solely on the extraction of relations that hold between named entities of certain type, whereas in the presented work we do not introduce such limitations.", "labels": [], "entities": []}, {"text": "Secondly, we deliberately intend to approach the OIE problem in an incremental manner, i.e., start explorations with as linguisticallypoor methods as possible and identify the phenomena/issues that complicate the task at hand most before elaborating more sophisticated solutions, whereas the work described in) deploys relatively linguistically sophisticated chain of NLP modules, including a dependency parser, which might prohibit applying it on Web-scale corpora.", "labels": [], "entities": []}, {"text": "Finally, although the evaluation results reported in) are promising, they only refer to a limited number of preselected relation types (e.g., 'born in), thus making a direct comparison difficult.", "labels": [], "entities": []}], "datasetContent": [{"text": "Four instances of the algorithm sketched in 2 have been evaluated: SREP (the algorithm without Step 5), SREP-PAT (the algorithm with Step 5), SREP-OV (the algorithm without Step 5, where the text fragments from which relation triples are extracted may overlap, e.g., two relations are extracted from the same text fragment), and SREP-PAT-OV (the algorithm with Step 5, where the text fragments from which relations are extracted may overlap).", "labels": [], "entities": []}, {"text": "The rationale of including 'OV' variants was to estimate the number of potentially missed extractions by the base versions of the algorithm.", "labels": [], "entities": []}, {"text": "In order to have a more in-depth picture of the error types we have computed precision-recall curves for the subtask of exact relation extraction task, namely, the relation phrase extraction task, which are depicted in.", "labels": [], "entities": [{"text": "precision-recall", "start_pos": 77, "end_pos": 93, "type": "METRIC", "confidence": 0.9879365563392639}, {"text": "relation extraction task", "start_pos": 126, "end_pos": 150, "type": "TASK", "confidence": 0.7744302749633789}, {"text": "relation phrase extraction task", "start_pos": 164, "end_pos": 195, "type": "TASK", "confidence": 0.7739999890327454}]}, {"text": "One can observe significant improvement as regards both precision and recall vs. extracting entire relations, in particular for SREP and SREP-PAT configurations, for which the figures still lag behind the ones reported for relation phrase extraction for English ) but are getting closer.", "labels": [], "entities": [{"text": "precision", "start_pos": 56, "end_pos": 65, "type": "METRIC", "confidence": 0.9991248250007629}, {"text": "recall", "start_pos": 70, "end_pos": 76, "type": "METRIC", "confidence": 0.9979093670845032}, {"text": "relation phrase extraction", "start_pos": 223, "end_pos": 249, "type": "TASK", "confidence": 0.6269544263680776}]}, {"text": "One corresponding to 'being better' and one to 'winning a match' relation.", "labels": [], "entities": []}, {"text": "Relation phrase and both arguments have to be identical with the corresponding annotation in the test corpus.", "labels": [], "entities": []}, {"text": "One can also conclude from that a significant number of errors stems from non correct extraction of the arguments of a relation.", "labels": [], "entities": []}, {"text": "To study the problem more thoroughly we also computed the precision-recall curves for the fuzzy relation extraction task, in which an extracted triple (X,rel,Y) is considered to be correct if rel is identical with the corresponding value in the test corpus, whereas X and Y are similar to the corresponding values in the test corpus, i.e., the string distance between the extracted values and the correct ones in the test corpus is relatively small.", "labels": [], "entities": [{"text": "precision-recall", "start_pos": 58, "end_pos": 74, "type": "METRIC", "confidence": 0.9949796795845032}, {"text": "fuzzy relation extraction task", "start_pos": 90, "end_pos": 120, "type": "TASK", "confidence": 0.6994687616825104}]}, {"text": "For the purpose of computing string distance we used the longest common substrings distance metric).", "labels": [], "entities": []}, {"text": "presents the precision-recall curves for the fuzzy extraction task, where SREP-PAT-FUZZY-2 curve corresponds to a variant of fuzzy matching, in which relation phrase may also slightly differ from the relation phrase in the test corpus.", "labels": [], "entities": [{"text": "precision-recall", "start_pos": 13, "end_pos": 29, "type": "METRIC", "confidence": 0.9934266805648804}, {"text": "fuzzy extraction task", "start_pos": 45, "end_pos": 66, "type": "TASK", "confidence": 0.8285706837972006}, {"text": "SREP-PAT-FUZZY-2", "start_pos": 74, "end_pos": 90, "type": "METRIC", "confidence": 0.9930996894836426}]}, {"text": "Although both precision and recall figures are higher vs. figures for exact relation matching, there is an indication (cf. that there is still a fraction of extracted relations for which the extraction of at least one of the arguments entirely failed, i.e., the error is not related to mismatching left/right boundary of the NP representing the argument.", "labels": [], "entities": [{"text": "precision", "start_pos": 14, "end_pos": 23, "type": "METRIC", "confidence": 0.9994292855262756}, {"text": "recall", "start_pos": 28, "end_pos": 34, "type": "METRIC", "confidence": 0.9981845021247864}, {"text": "relation matching", "start_pos": 76, "end_pos": 93, "type": "TASK", "confidence": 0.6920411735773087}]}, {"text": "The main cause of missed relations was due to, i.a.,: (a) relation phrase not being present in the text between arguments (36.7%); (b) noncontiguous relation phrase structure (28.3%) 8 ; (c) non-matching of POS-based patterns for detection of relation phrases (10.4%); and (d) non handling of constructions, in which arguments of the relations are \"embraced\" in verbs (8.9%) 9 .", "labels": [], "entities": []}], "tableCaptions": []}