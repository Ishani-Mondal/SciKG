{"title": [{"text": "METEOR-WSD: Improved Sense Matching in MT Evaluation", "labels": [], "entities": [{"text": "METEOR-WSD", "start_pos": 0, "end_pos": 10, "type": "METRIC", "confidence": 0.774553656578064}, {"text": "Improved Sense Matching", "start_pos": 12, "end_pos": 35, "type": "TASK", "confidence": 0.7433841029802958}, {"text": "MT Evaluation", "start_pos": 39, "end_pos": 52, "type": "TASK", "confidence": 0.9603111147880554}]}], "abstractContent": [{"text": "We present an initial experiment in integrating a disambiguation step in MT evaluation.", "labels": [], "entities": [{"text": "MT evaluation", "start_pos": 73, "end_pos": 86, "type": "TASK", "confidence": 0.9511792063713074}]}, {"text": "We show that accounting for sense distinctions helps METEOR establish better sense correspondences and improves its correlation with human judgments of translation quality.", "labels": [], "entities": []}], "introductionContent": [{"text": "Synonym and paraphrase support are useful means for capturing lexical variation in Machine Translation evaluation.", "labels": [], "entities": [{"text": "Machine Translation evaluation", "start_pos": 83, "end_pos": 113, "type": "TASK", "confidence": 0.9097769260406494}]}, {"text": "In the METEOR metric, some level of abstraction from the surface forms of words is achieved through the \"stem\" and \"synonymy\" modules which map words with the same stem or belonging to the same WordNet synset.", "labels": [], "entities": []}, {"text": "METEOR-NEXT) extends semantic mapping to languages other than English and to longer text segments, using the paraphrase tables constructed by the pivot method ().", "labels": [], "entities": []}, {"text": "Although both metrics yield improvements regarding correlation with human judgments of translation quality compared to the standard METEOR configuration for English, they integrate semantic information in a rather simplistic way: matching is performed without disambiguation, which means that all the variants available fora particular text fragment are treated as semantically equivalent.", "labels": [], "entities": []}, {"text": "This is however not always the case, as synonyms found in different WordNet synsets correspond to different senses.", "labels": [], "entities": []}, {"text": "Similarly, paraphrase sets obtained by the pivot method often group phrases describing different senses).", "labels": [], "entities": []}, {"text": "In these cases, a word sense disambiguation (WSD) step would help to identify the correct synset or subset of paraphrases fora word or phrase in context and avoid erroneous matchings between text segments carrying different senses.", "labels": [], "entities": [{"text": "word sense disambiguation (WSD)", "start_pos": 18, "end_pos": 49, "type": "TASK", "confidence": 0.7968661338090897}]}, {"text": "We present an initial experiment on the integration of a disambiguation step in the METEOR metric and show how it helps increase correlation with human judgments of translation quality.", "labels": [], "entities": [{"text": "METEOR metric", "start_pos": 84, "end_pos": 97, "type": "DATASET", "confidence": 0.6542767882347107}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Segment-level Kendall's \u03c4 correlations be- tween METEOR and the official human judgments of the  WMT14 metrics shared task.", "labels": [], "entities": [{"text": "METEOR", "start_pos": 59, "end_pos": 65, "type": "METRIC", "confidence": 0.9912155866622925}, {"text": "WMT14 metrics shared task", "start_pos": 107, "end_pos": 132, "type": "DATASET", "confidence": 0.90565425157547}]}]}