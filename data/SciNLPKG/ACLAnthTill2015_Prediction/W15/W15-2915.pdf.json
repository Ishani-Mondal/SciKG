{"title": [{"text": "A Linguistically Informed Convolutional Neural Network", "labels": [], "entities": []}], "abstractContent": [{"text": "Sentiment lexicons and other linguistic knowledge proved to be beneficial in polarity classification.", "labels": [], "entities": [{"text": "polarity classification", "start_pos": 77, "end_pos": 100, "type": "TASK", "confidence": 0.9057974219322205}]}, {"text": "This paper introduces a linguistically informed Convolu-tional Neural Network (lingCNN), which incorporates this valuable kind of information into the model.", "labels": [], "entities": []}, {"text": "We present two intuitive and simple methods: The first one integrates word-level features, the second sentence-level features.", "labels": [], "entities": []}, {"text": "By combining both types of features our model achieves results that are comparable to state-of-the-art systems.", "labels": [], "entities": []}], "introductionContent": [{"text": "This paper explores the use of Convolutional Neural Networks (CNN) for sentiment analysis.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 71, "end_pos": 89, "type": "TASK", "confidence": 0.9653598666191101}]}, {"text": "CNNs reach state-of-the-art results in several polarity classification tasks ().", "labels": [], "entities": [{"text": "polarity classification", "start_pos": 47, "end_pos": 70, "type": "TASK", "confidence": 0.7297784686088562}]}, {"text": "Reasons are their ability to deal with arbitrary input sentence lengths and to preserve word order.", "labels": [], "entities": []}, {"text": "Moreover, they learn to find the most important polarity indicators and ignore the rest of the sentence.", "labels": [], "entities": []}, {"text": "That is beneficial, since most of the words in a text do not convey sentiment information.", "labels": [], "entities": []}, {"text": "Finally, CNNs can make use of powerful pretrained word representations (e.g.,).", "labels": [], "entities": []}, {"text": "However, training such a model requires a large amount of labeled training data.", "labels": [], "entities": []}, {"text": "One approach to address this issue is to enlarge training data in a semi-supervised fashion.", "labels": [], "entities": []}, {"text": "Instead, we propose to make use of already available linguistically motivated resources.", "labels": [], "entities": []}, {"text": "Especially sentiment lexicons are important cues for polarity classification (cf. ). We introduce two intuitive and simple methods of incorporating linguistic features into a CNN.", "labels": [], "entities": [{"text": "polarity classification", "start_pos": 53, "end_pos": 76, "type": "TASK", "confidence": 0.7473002672195435}]}, {"text": "The resulting architecture is called linguistically informed CNN (lingCNN).", "labels": [], "entities": []}, {"text": "The first method is to add features to every word in a sentence.", "labels": [], "entities": []}, {"text": "That enables the model to learn interactions between words and between individual word embeddings and linguistic features.", "labels": [], "entities": []}, {"text": "The second method is to add feature vectors that are computed based on the entire sentence.", "labels": [], "entities": []}, {"text": "The results show that word-level features can improve the classification and are more beneficial than sentence-level features.", "labels": [], "entities": []}, {"text": "However, the combination of both methods reaches the best performance and yields results that are comparable to state-of-the-art on the SemEval Twitter polarity data set.", "labels": [], "entities": [{"text": "SemEval Twitter polarity data set", "start_pos": 136, "end_pos": 169, "type": "DATASET", "confidence": 0.8302838206291199}]}, {"text": "We use the following terminology.", "labels": [], "entities": []}, {"text": "LT \u2208 R d\u00d7|V | denotes a lookup table that assigns each word in the vocabulary Va d-dimensional vector.", "labels": [], "entities": []}, {"text": "Given a sequence of n tokens t 1 tot n the model concatenates all n word representations to the input of the lingCNN:", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Data set sizes.", "labels": [], "entities": []}, {"text": " Table 2: Results of baselines (upper half) and  lingCNN (lower half).", "labels": [], "entities": []}, {"text": " Table 3: Different training set sizes.", "labels": [], "entities": []}]}