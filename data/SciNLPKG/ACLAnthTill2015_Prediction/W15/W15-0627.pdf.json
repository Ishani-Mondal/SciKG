{"title": [{"text": "Using Learner Data to Improve Error Correction in Adjective-Noun Combinations", "labels": [], "entities": []}], "abstractContent": [{"text": "This paper presents a novel approach to error correction in content words in learner writing focussing on adjective-noun (AN) combinations.", "labels": [], "entities": [{"text": "error correction in content words", "start_pos": 40, "end_pos": 73, "type": "TASK", "confidence": 0.7971273779869079}]}, {"text": "We show how error patterns can be used to improve the performance of the error correction system, and demonstrate that our approach is capable of suggesting an appropriate correction within the top two alternatives in half of the cases and within top 10 alternatives in 71% of the cases, performing with an M RR of 0.5061.", "labels": [], "entities": [{"text": "error correction", "start_pos": 73, "end_pos": 89, "type": "TASK", "confidence": 0.6913875043392181}, {"text": "M RR", "start_pos": 307, "end_pos": 311, "type": "METRIC", "confidence": 0.8967272937297821}]}, {"text": "We then integrate our error correction system with a state-of-the-art content word error detection system and discuss the results.", "labels": [], "entities": [{"text": "error correction", "start_pos": 22, "end_pos": 38, "type": "TASK", "confidence": 0.7387383580207825}, {"text": "word error detection", "start_pos": 78, "end_pos": 98, "type": "TASK", "confidence": 0.7249066432317098}]}], "introductionContent": [{"text": "The task of error detection and correction (EDC) on non-native texts, as well as research on learner language in general, has attracted much attention recently ().", "labels": [], "entities": [{"text": "error detection and correction (EDC)", "start_pos": 12, "end_pos": 48, "type": "TASK", "confidence": 0.8482428874288287}]}, {"text": "The field has been dominated by EDC for grammatical errors and errors in the use of articles and prepositions ().", "labels": [], "entities": [{"text": "EDC", "start_pos": 32, "end_pos": 35, "type": "METRIC", "confidence": 0.7056317925453186}]}, {"text": "More recently, however, the need to address other error types has been recognised ().", "labels": [], "entities": []}, {"text": "Among these, errors in content words are the third most frequent error type after errors in articles and prepositions).", "labels": [], "entities": []}, {"text": "The correct use of content words is notoriously hard for language learners to master, while importance of the correct word choice for successful writing has long been recognised (.", "labels": [], "entities": []}, {"text": "The major difficulty is that correct word choice is not governed by any strictly defined rules: native speakers know that powerful computer is preferred over strong computer, while strong tea is preferred over powerful tea (), but language learners often find themselves unsure of how to choose an appropriate word.", "labels": [], "entities": []}, {"text": "As a result, they often confuse words that are similar in meaning or spelling, overuse words with general meaning, or select words based on their L1s ().", "labels": [], "entities": []}, {"text": "Previous work on EDC for content words has also demonstrated that since these error types are substantially different from errors with function words, they require different approaches.", "labels": [], "entities": []}, {"text": "The most widely adopted approach to EDC for function words relies on availability of finite confusion sets.", "labels": [], "entities": [{"text": "EDC", "start_pos": 36, "end_pos": 39, "type": "TASK", "confidence": 0.9379206895828247}]}, {"text": "The task can then be cast as multi-class classification with the number of classes equal to the number of possible alternatives.", "labels": [], "entities": []}, {"text": "Detection and correction can be done simultaneously: if the alternative chosen by the classifier is different from the original word, this is flagged as an error.", "labels": [], "entities": [{"text": "Detection", "start_pos": 0, "end_pos": 9, "type": "METRIC", "confidence": 0.6929238438606262}]}, {"text": "However, content word errors cannot be defined in terms of a general and finite set of confusion pairs, and the set of alternatives in each case depends on the choice of original word.", "labels": [], "entities": []}, {"text": "Moreover, it has been argued that error detection for content words should be performed independently from error correction.", "labels": [], "entities": [{"text": "error detection", "start_pos": 34, "end_pos": 49, "type": "TASK", "confidence": 0.6653220355510712}]}, {"text": "In this work, we focus on error correction in content words and, in particular, investigate error correction in adjective-noun (AN) combinations using several publicly-available learner error datasets for this type of construction.", "labels": [], "entities": [{"text": "error correction in content words", "start_pos": 26, "end_pos": 59, "type": "TASK", "confidence": 0.7607661128044129}, {"text": "error correction in adjective-noun (AN) combinations", "start_pos": 92, "end_pos": 144, "type": "TASK", "confidence": 0.6861287876963615}]}, {"text": "At the same time, we believe that a similar approach can be applied to other types of content word combinations.", "labels": [], "entities": []}, {"text": "Specifically, we make the following contributions: 1.", "labels": [], "entities": []}, {"text": "We explore different ways to construct the correction sets and to rank the alternatives with respect to their appropriateness.", "labels": [], "entities": []}, {"text": "We report the coverage of different resources and assess the ranked lists of suggestions.", "labels": [], "entities": []}, {"text": "2. We show that learner text is a useful source of possible corrections for content words.", "labels": [], "entities": []}, {"text": "In addition, we demonstrate how error patterns extracted from learner text can be used to improve the ranking of the alternatives.", "labels": [], "entities": []}, {"text": "3. We present an EDC system for AN combinations which compares favourably to the previous published approaches of which we are aware.", "labels": [], "entities": [{"text": "EDC", "start_pos": 17, "end_pos": 20, "type": "METRIC", "confidence": 0.9178882241249084}, {"text": "AN combinations", "start_pos": 32, "end_pos": 47, "type": "TASK", "confidence": 0.9090668857097626}]}, {"text": "4. We explore the usefulness of self-propagating for an error correction system.", "labels": [], "entities": [{"text": "error correction", "start_pos": 56, "end_pos": 72, "type": "TASK", "confidence": 0.6824855506420135}]}, {"text": "note that the usual approach to EDC in content words relies on the idea of comparing the writer's choice to possible alternatives, so that if any of the alternatives score higher than the original combination then the original combination is flagged as a possible error and one or more alternatives are suggested as possible corrections.", "labels": [], "entities": [{"text": "EDC", "start_pos": 32, "end_pos": 35, "type": "TASK", "confidence": 0.9579874873161316}]}, {"text": "The performance of an EDC algorithm that uses this approach depends on:", "labels": [], "entities": []}], "datasetContent": [{"text": "We use the dataset of AN combinations released by.", "labels": [], "entities": []}, {"text": "This dataset presents typical learner errors in the use of 61 adjectives that are most problematic for language learners.", "labels": [], "entities": []}, {"text": "The examples are annotated with respect to the types of errors committed in the use of adjectives and nouns, and corrections are provided.", "labels": [], "entities": []}, {"text": "Kochmar and Briscoe note that learners often confuse semantically related words (e.g., synonyms, near-synonyms, hypo-/hypernyms).", "labels": [], "entities": []}, {"text": "Examples and from illustrate the confusion between the adjective big and semantically similar adjectives large and great: In addition, in we note that the adjectives with quite general meaning like big, large and great are often overused by language learners instead of more specific ones, as is illustrated by examples (3) to (6): Words that seem to be similar inform (either related morphologically or through similar pronunciation) are also often confused by learners.", "labels": [], "entities": []}, {"text": "Examples and illustrate this type of confusions: The dataset contains 798 annotated AN combinations, with 340 unique errors.", "labels": [], "entities": []}, {"text": "presents the statistics on the error types detected in this dataset.", "labels": [], "entities": []}, {"text": "The majority of the errors Error type Distribution S 56.18% F 25.88% N 17.94% involve semantically related words (type S).", "labels": [], "entities": [{"text": "errors", "start_pos": 20, "end_pos": 26, "type": "METRIC", "confidence": 0.9671961069107056}, {"text": "Error type Distribution S", "start_pos": 27, "end_pos": 52, "type": "METRIC", "confidence": 0.9118814021348953}, {"text": "F", "start_pos": 60, "end_pos": 61, "type": "METRIC", "confidence": 0.8763335943222046}]}, {"text": "Formrelated confusions occur in 25.88% of the cases (type F); while 17.94% are annotated as errors committed due to other reasons (type N), possibly related to learners' L1s.", "labels": [], "entities": []}, {"text": "The CLC-FCE AN dataset is extracted from the publicly-available CLC-FCE subset of the CLC released by.", "labels": [], "entities": [{"text": "CLC-FCE AN dataset", "start_pos": 4, "end_pos": 22, "type": "DATASET", "confidence": 0.792140781879425}]}, {"text": "The CLC error coding has been used to extract the correctly used ANs and those that are annotated as errors due to inappropriate choice of an adjective or/and noun, but the error subtypes for the AN errors are not further specified.", "labels": [], "entities": []}, {"text": "We have extracted 456 combinations that have adjective-noun combinations as corrections.", "labels": [], "entities": []}, {"text": "We have also used the training and development sets from the CoNLL-2014 Shared Task on Grammatical Error Correction () to extract the incorrect AN combinations.", "labels": [], "entities": [{"text": "CoNLL-2014 Shared Task on Grammatical Error Correction", "start_pos": 61, "end_pos": 115, "type": "TASK", "confidence": 0.7406980650765556}]}, {"text": "The data for the shared task has been extracted from the NUCLE corpus, the NUS Corpus of Learner English (.", "labels": [], "entities": [{"text": "NUCLE corpus", "start_pos": 57, "end_pos": 69, "type": "DATASET", "confidence": 0.9894402325153351}, {"text": "NUS Corpus of Learner English", "start_pos": 75, "end_pos": 104, "type": "DATASET", "confidence": 0.9686765670776367}]}, {"text": "Unlike the other two datasets it represents a smaller range of L1s, and similarly to the CLC-FCE dataset the errors are not further annotated with respect to their subtypes.", "labels": [], "entities": [{"text": "CLC-FCE dataset", "start_pos": 89, "end_pos": 104, "type": "DATASET", "confidence": 0.9699915945529938}]}, {"text": "We have preprocessed the data using the RASP parser (), and used the error annotation provided to extract the AN combinations that contain errors in the choice of either one or both words.", "labels": [], "entities": [{"text": "RASP", "start_pos": 40, "end_pos": 44, "type": "DATASET", "confidence": 0.7216442227363586}]}, {"text": "Additionally, we have also checked that the suggested corrections are represented by AN combinations.", "labels": [], "entities": []}, {"text": "The extracted dataset contains 369 ANs.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Distribution of error types in the annotated  dataset.", "labels": [], "entities": []}, {"text": " Table 3: Coverage of different sets of alternatives.", "labels": [], "entities": [{"text": "Coverage", "start_pos": 10, "end_pos": 18, "type": "TASK", "confidence": 0.9425296187400818}]}, {"text": " Table 4: MRR for the alternatives ranking.", "labels": [], "entities": [{"text": "MRR", "start_pos": 10, "end_pos": 13, "type": "METRIC", "confidence": 0.9624749422073364}]}, {"text": " Table 5: CLC confusion pairs", "labels": [], "entities": []}, {"text": " Table 6: Results breakdown: % of errors covered.", "labels": [], "entities": [{"text": "errors", "start_pos": 34, "end_pos": 40, "type": "METRIC", "confidence": 0.936290979385376}]}, {"text": " Table 7: Subtype error analysis for the annotated dataset.", "labels": [], "entities": [{"text": "Subtype error analysis", "start_pos": 10, "end_pos": 32, "type": "TASK", "confidence": 0.7022885084152222}]}, {"text": " Table 8: Average MRR on the sets of ANs with the errors  in the choice of adjectives and nouns.", "labels": [], "entities": [{"text": "MRR", "start_pos": 18, "end_pos": 21, "type": "METRIC", "confidence": 0.9089658856391907}]}, {"text": " Table 9: Augmented sets of alternatives.", "labels": [], "entities": []}]}