{"title": [{"text": "An extended dependency graph for relation extraction in biomedical texts", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 33, "end_pos": 52, "type": "TASK", "confidence": 0.8281255960464478}]}], "abstractContent": [{"text": "Kernel-based methods are widely used for relation extraction task and obtain good results by leveraging lexical and syntactic information.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 41, "end_pos": 60, "type": "TASK", "confidence": 0.9309587180614471}]}, {"text": "However, in biomedi-cal domain these methods are limited by the size of dataset and have difficulty in coping with variations in text.", "labels": [], "entities": []}, {"text": "To address this problem, we propose Extended Dependency Graph (EDG) by incorporating a few simple linguistic ideas and include information beyond syntax.", "labels": [], "entities": []}, {"text": "We believe the use of EDG will enable machine learning methods to generalize more easily.", "labels": [], "entities": []}, {"text": "Experiments confirm that EDG provides up to 10% f-value improvement over dependency graph using mainstream kernel methods over five corpora.", "labels": [], "entities": []}, {"text": "We conducted additional experiments to provide a more detailed analysis of the contributions of individual modules in EDG construction .", "labels": [], "entities": [{"text": "EDG construction", "start_pos": 118, "end_pos": 134, "type": "TASK", "confidence": 0.8391912877559662}]}], "introductionContent": [{"text": "With growing amount of biomedical information available in textual form, there has been considerable interest in applying NLP techniques and machine-learning (ML) methods to biomedical literature.", "labels": [], "entities": []}, {"text": "Some of these projects involve extracting relations such as protein-protein interaction (.", "labels": [], "entities": []}, {"text": "In biomedical domain, most relation extraction work is currently applied on the abstracts of articles.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 27, "end_pos": 46, "type": "TASK", "confidence": 0.8821511566638947}]}, {"text": "These abstracts by nature are dense with information and often use constructions such as appositives and relative clauses.", "labels": [], "entities": []}, {"text": "The abundance of textual variations can thus be problematic for ML systems, especially with small training corpora.", "labels": [], "entities": [{"text": "ML", "start_pos": 64, "end_pos": 66, "type": "TASK", "confidence": 0.9837915897369385}]}, {"text": "One solution to this issue is to find a suitable level of abstraction in the text representation so that ML methods become easier to generalize.", "labels": [], "entities": []}, {"text": "Use of syntax and parse information provides one such abstraction.", "labels": [], "entities": []}, {"text": "Using syntactic dependency information has become prevalent in biomedical relation extraction.", "labels": [], "entities": [{"text": "biomedical relation extraction", "start_pos": 63, "end_pos": 93, "type": "TASK", "confidence": 0.7636944850285848}]}, {"text": "It has been suggested dependency links are close to the semantic relationship needed for the next stage of interpretation).", "labels": [], "entities": []}, {"text": "There have been significant advances in the development of advanced machine learning and kernel methods and the use of sophisticated parameter tuning in the biomedical domain.", "labels": [], "entities": [{"text": "parameter tuning", "start_pos": 133, "end_pos": 149, "type": "TASK", "confidence": 0.7656022906303406}]}, {"text": "In this work, we focus on the representation of the text used in learning rather than the machine learning technique, with the hope that advances in both directions will be improve the performance of the relation extraction systems.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 204, "end_pos": 223, "type": "TASK", "confidence": 0.7850454747676849}]}, {"text": "In this paper we propose Extended Dependency Graph (EDG), which includes information about text that goes beyond syntax.", "labels": [], "entities": [{"text": "Extended Dependency Graph (EDG)", "start_pos": 25, "end_pos": 56, "type": "TASK", "confidence": 0.563646117846171}]}, {"text": "We will define EDG and discuss how we construct it from a given sentence by using some simple linguistic notions.", "labels": [], "entities": []}, {"text": "The hypothesis we test here is that EDG allows ML techniques to generalize more easily.", "labels": [], "entities": [{"text": "EDG", "start_pos": 36, "end_pos": 39, "type": "METRIC", "confidence": 0.6136302947998047}, {"text": "ML", "start_pos": 47, "end_pos": 49, "type": "TASK", "confidence": 0.9668391942977905}]}, {"text": "To determine the effect of EDG, we conducted experiments on protein-protein interaction (PPI) extraction.", "labels": [], "entities": [{"text": "protein-protein interaction (PPI) extraction", "start_pos": 60, "end_pos": 104, "type": "TASK", "confidence": 0.6373192469278971}]}, {"text": "For this purpose, we used two kernels: a simple kernel based on edit distance () and a more elaborate kernel that is one of the top performing kernels on the PPI task ( . We compared the performance of both kernels using dependency graph and EDG on 5 corpora.", "labels": [], "entities": []}, {"text": "Our results suggest EDG provides up to 10% f-value improvement over dependency graph.", "labels": [], "entities": []}, {"text": "On 3 out of 5 corpora the results are better than the overall best system in the study of, as well as an ensemble method that builds on them ().", "labels": [], "entities": []}, {"text": "We also evaluate the contributions of the individual components included in EDG.", "labels": [], "entities": [{"text": "EDG", "start_pos": 76, "end_pos": 79, "type": "DATASET", "confidence": 0.8238419890403748}]}], "datasetContent": [{"text": "We evaluated our method on protein-protein interaction (PPI) extraction task, where the system identifies whether a given protein pair in a sentence has PPI relationship or not.", "labels": [], "entities": [{"text": "protein-protein interaction (PPI) extraction task", "start_pos": 27, "end_pos": 76, "type": "TASK", "confidence": 0.6995134311062949}]}, {"text": "We used SDG or EDG as input representation of the sentences, which includes the named protein entities.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Basic statistics of the corpora.", "labels": [], "entities": []}, {"text": " Table 2: Evaluation results. Performance is reported in terms of Recall/Precision/F-value.", "labels": [], "entities": [{"text": "Recall", "start_pos": 66, "end_pos": 72, "type": "METRIC", "confidence": 0.9973652958869934}, {"text": "Precision", "start_pos": 73, "end_pos": 82, "type": "METRIC", "confidence": 0.7262905240058899}, {"text": "F-value", "start_pos": 83, "end_pos": 90, "type": "METRIC", "confidence": 0.8293696641921997}]}, {"text": " Table 2. On the LLL corpus,  as components were successively added, we no- ticed a drop in F-value when referential linking  was added. So similarly by turning off is-a detec- tion and including all other EDG edges enabled us", "labels": [], "entities": [{"text": "LLL corpus", "start_pos": 17, "end_pos": 27, "type": "DATASET", "confidence": 0.7049286514520645}, {"text": "F-value", "start_pos": 92, "end_pos": 99, "type": "METRIC", "confidence": 0.963930606842041}]}, {"text": " Table 3: Contributions of different part in SDG and EDG using edit kernel. Performance is reported in  terms of Recall/Precision/F-value.", "labels": [], "entities": [{"text": "EDG", "start_pos": 53, "end_pos": 56, "type": "DATASET", "confidence": 0.8596062064170837}, {"text": "Recall", "start_pos": 113, "end_pos": 119, "type": "METRIC", "confidence": 0.9938753247261047}, {"text": "Precision", "start_pos": 120, "end_pos": 129, "type": "METRIC", "confidence": 0.7608491778373718}, {"text": "F-value", "start_pos": 130, "end_pos": 137, "type": "METRIC", "confidence": 0.8706358671188354}]}]}