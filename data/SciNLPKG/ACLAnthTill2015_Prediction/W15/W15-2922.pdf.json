{"title": [{"text": "Synthetic Text Generation for Sentiment Analysis", "labels": [], "entities": [{"text": "Synthetic Text Generation", "start_pos": 0, "end_pos": 25, "type": "TASK", "confidence": 0.9110045433044434}, {"text": "Sentiment Analysis", "start_pos": 30, "end_pos": 48, "type": "TASK", "confidence": 0.9633277058601379}]}], "abstractContent": [{"text": "Natural language is a common type of input for data processing systems.", "labels": [], "entities": []}, {"text": "Therefore , it is often required to have a large testing data set of this type.", "labels": [], "entities": []}, {"text": "In this context, the task to automatically generate natural language texts, which maintain the properties of real texts is desirable.", "labels": [], "entities": []}, {"text": "However, current synthetic data generators do not capture natural language text data sufficiently.", "labels": [], "entities": []}, {"text": "In this paper, we present a preliminary study on different generative models for text generation, which maintain specific properties of natural language text, i.e., the sentiment of a review text.", "labels": [], "entities": [{"text": "text generation", "start_pos": 81, "end_pos": 96, "type": "TASK", "confidence": 0.7220721691846848}]}, {"text": "Ina series of experiments using different data sets and sentiment analysis methods, we show that generative models can generate texts with a specific sentiment and that hidden Markov model based text generation achieves less accuracy than Markov chain based text generation, but can generate a higher number of distinct texts.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 225, "end_pos": 233, "type": "METRIC", "confidence": 0.9941733479499817}, {"text": "Markov chain based text generation", "start_pos": 239, "end_pos": 273, "type": "TASK", "confidence": 0.5855327844619751}]}], "introductionContent": [{"text": "Text generation is the task of automatically generating texts, which maintain specific properties of real texts.", "labels": [], "entities": [{"text": "Text generation", "start_pos": 0, "end_pos": 15, "type": "TASK", "confidence": 0.7905350625514984}]}, {"text": "In the context of synthetic text generation, generative models are used to generate test data for benchmarking big data systems).", "labels": [], "entities": [{"text": "synthetic text generation", "start_pos": 18, "end_pos": 43, "type": "TASK", "confidence": 0.7172180414199829}]}, {"text": "BDGS () is a text generator that applies latent dirichlet allocation ( as the text data generation model and BigBench () is a benchmark that provides a text generator based on Markov chain model.", "labels": [], "entities": [{"text": "BDGS", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.7076361775398254}]}, {"text": "Sentiment analysis (SA) is a method of processing opinions and subjectivity of a text.", "labels": [], "entities": [{"text": "Sentiment analysis (SA)", "start_pos": 0, "end_pos": 23, "type": "TASK", "confidence": 0.923005199432373}]}, {"text": "The task is to find and extract the sentiment polarity expressed in a text.", "labels": [], "entities": []}, {"text": "The goal of the paper is to demonstrate the ability of different generative models, i.e., latent dirichlet allocation (LDA), Markov chains (MC), and hidden Markov model (HMM), to generate text with a specific sentiment.", "labels": [], "entities": []}, {"text": "This is an important problem because the sentiment of a text maybe crucial in several applications like extracting the customers reviews about books, movies, or food and classifying them along their sentiment.", "labels": [], "entities": [{"text": "extracting the customers reviews about books, movies, or food", "start_pos": 104, "end_pos": 165, "type": "TASK", "confidence": 0.7216726053844799}]}, {"text": "The contributions of this paper are as follows.", "labels": [], "entities": []}, {"text": "We present a primary study on three different generative models for text generation.", "labels": [], "entities": [{"text": "text generation", "start_pos": 68, "end_pos": 83, "type": "TASK", "confidence": 0.7932285666465759}]}, {"text": "LDA and MC are used for text generation in previous work).", "labels": [], "entities": [{"text": "LDA", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.6799547672271729}, {"text": "text generation", "start_pos": 24, "end_pos": 39, "type": "TASK", "confidence": 0.7937873601913452}]}, {"text": "We introduce the well known HMM to use it for text generation and compare it with LDA and MC.", "labels": [], "entities": [{"text": "text generation", "start_pos": 46, "end_pos": 61, "type": "TASK", "confidence": 0.814522385597229}]}, {"text": "Ina series of experiments, we analyze the scalability, cardinality, and the ability to generate text with a sentiment.", "labels": [], "entities": []}, {"text": "For sentiment analysis, we use stateof-the-art methods.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 4, "end_pos": 22, "type": "TASK", "confidence": 0.9837065637111664}]}, {"text": "The evaluation indicates that the models can generate texts with a specific sentiment.", "labels": [], "entities": []}, {"text": "The hidden Markov model achieves a lower accuracy than Markov chains, but can generate more distinct texts.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 41, "end_pos": 49, "type": "METRIC", "confidence": 0.9976740479469299}]}, {"text": "The remainder of the paper is organized as follows.", "labels": [], "entities": []}, {"text": "Sections 2 and 3 provide an overview on generative models and sentiment analysis approaches.", "labels": [], "entities": [{"text": "generative models", "start_pos": 40, "end_pos": 57, "type": "TASK", "confidence": 0.9558526873588562}, {"text": "sentiment analysis", "start_pos": 62, "end_pos": 80, "type": "TASK", "confidence": 0.9524312615394592}]}, {"text": "In Section 4 the results of the preliminary experiments are presented.", "labels": [], "entities": []}, {"text": "Finally, Section 5 presents a summary and discusses directions for future work.", "labels": [], "entities": []}], "datasetContent": [{"text": "Ina series of experiments we analyzed the scalability, cardinality and the ability to generate text with a sentiment.", "labels": [], "entities": []}, {"text": "In this experiment the scalability of the presented models are measured on data sets of different sizes.", "labels": [], "entities": []}, {"text": "We use the food reviews data set used in) and construct seven sub data sets with 10K, 50K, 100K, 200K, 300K and 500K food reviews respectively.", "labels": [], "entities": [{"text": "food reviews data set", "start_pos": 11, "end_pos": 32, "type": "DATASET", "confidence": 0.7048040851950645}]}, {"text": "We measure the execution time of the learning algorithms of the models on each of these sub data sets.", "labels": [], "entities": []}, {"text": "shows for each sub data set the execution time of the learning phase.", "labels": [], "entities": []}, {"text": "As we can see, MC outperforms the other methods in terms of scalability because it only builds n-grams.", "labels": [], "entities": []}, {"text": "HMM has a higher execution time because the data sets have to be tagged using a part-of-speech tagger.", "labels": [], "entities": [{"text": "HMM", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.797989547252655}]}, {"text": "LDA performs the worst due to the extensive learning phase.", "labels": [], "entities": [{"text": "LDA", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.5762781500816345}]}, {"text": "In this experiment the cardinality of the synthetic data sets are measured.", "labels": [], "entities": []}, {"text": "The cardinality is defined as the amount of distinct text elements in the generated data set.", "labels": [], "entities": []}, {"text": "Two text elements are the same if they have the exact same string.", "labels": [], "entities": []}, {"text": "A text element can bean arbitrary type of text, i.e. a sentence or a document.", "labels": [], "entities": []}, {"text": "This will show the upscaling behavior in terms of the ability to generate distinct texts.", "labels": [], "entities": []}, {"text": "We use a data set of 10,662 movie reviews used in (Pang and, which contains an equal number of positive and negative reviews, and divide it into two data sets along their sentiment polarity.", "labels": [], "entities": [{"text": "Pang and", "start_pos": 51, "end_pos": 59, "type": "DATASET", "confidence": 0.9460922181606293}]}, {"text": "On both data sets we build the presented models, which we utilize to scale up by factors of 1, 2, 10, 100 and 1000.", "labels": [], "entities": []}, {"text": "shows that the LDA and HMM models performs best in generating distinct text elements, where almost all text elements are distinct.", "labels": [], "entities": []}, {"text": "The MC model generates the smallest amount of distinct text elements, e.g. only 62% distinct text elements using scale up factor 1000.", "labels": [], "entities": []}, {"text": "The next word in LDA and HMM only depend on the latent vari- able and not on the previous words, wherein LDA it depends on the latent topics and in HMM on the part-of-speech tags.", "labels": [], "entities": []}, {"text": "Therefore, more combinations of words are possible.", "labels": [], "entities": []}, {"text": "In this experiment it is demonstrated that the models learn high-quality language presented models and are able to generate text with a sentiment.", "labels": [], "entities": []}, {"text": "We use the same data set as in the previous experiment and divide it into two data sets along their sentiment polarity.", "labels": [], "entities": []}, {"text": "To build an SVM based classifier we split each data set into a training and test data set.", "labels": [], "entities": []}, {"text": "On both data sets we learn the presented models, which we utilize to scale up by factors of 1, 2 and 10.", "labels": [], "entities": []}, {"text": "We use (a) SentiWordNet (, (b) SVM, and (c) the Stanford sentiment analysis library) to assess whether the generated reviews have the appropriate sentiment.", "labels": [], "entities": [{"text": "Stanford sentiment analysis library", "start_pos": 48, "end_pos": 83, "type": "DATASET", "confidence": 0.6754894703626633}]}, {"text": "shows the main experimental results.", "labels": [], "entities": []}, {"text": "We see that the HMM is more accurately than LDA but less accurately than the MC.", "labels": [], "entities": []}, {"text": "The method (c) outperforms the other methods and achieves an F-measure of 79% for the positive and 79% for the negative class.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 61, "end_pos": 70, "type": "METRIC", "confidence": 0.9991937279701233}]}, {"text": "The basic methods (a) and (b) reveal only a modest difference between the original and synthetic data set, while the advanced method (c) illustrates a significant decrease of the F-measure in the synthetic data sets.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 179, "end_pos": 188, "type": "METRIC", "confidence": 0.9967492818832397}]}, {"text": "One reason why the F-measure have declined is that ba-: This table shows the F-measures of the original and synthetic data sets for the positive and negative class separately.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 19, "end_pos": 28, "type": "METRIC", "confidence": 0.9804695248603821}]}, {"text": "The synthetic data sets are generated by scale up factors of 1, 2 and 10.", "labels": [], "entities": []}, {"text": "The sentiments analysis methods are SentiWordNet (a) SVM (b), and Stanford library (c).", "labels": [], "entities": [{"text": "Stanford library", "start_pos": 66, "end_pos": 82, "type": "DATASET", "confidence": 0.9124411344528198}]}, {"text": "The HMM achieves a lower F-measure than MC but a higher than LDA on each scale up factor.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 25, "end_pos": 34, "type": "METRIC", "confidence": 0.9990750551223755}, {"text": "MC", "start_pos": 40, "end_pos": 42, "type": "METRIC", "confidence": 0.858022153377533}, {"text": "LDA", "start_pos": 61, "end_pos": 64, "type": "METRIC", "confidence": 0.9862684607505798}]}, {"text": "sic methods work by assessing words in isolation.", "labels": [], "entities": []}, {"text": "They give positive scores for positive words and negative scores for negative words and then aggregate these scores.", "labels": [], "entities": []}, {"text": "Therefore, the order of words is ignored.", "labels": [], "entities": []}, {"text": "In contrast, the advanced method builds a representation of the whole sentence based on the sentence structure using the parse tree.", "labels": [], "entities": []}, {"text": "Consequently, MC and HMM perform better than LDA because of their ability to capture the order of words.", "labels": [], "entities": []}, {"text": "The F-measures of all models and sentiment analysis methods are almost constant on each scale up factor, which indicates a robust upscaling behavior of these models.", "labels": [], "entities": [{"text": "F-measures", "start_pos": 4, "end_pos": 14, "type": "METRIC", "confidence": 0.9919764399528503}, {"text": "sentiment analysis", "start_pos": 33, "end_pos": 51, "type": "TASK", "confidence": 0.9367456436157227}]}, {"text": "The HMM achieves a lower F-measure than MC, but can generate a higher number of distinct text elements than MC.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 25, "end_pos": 34, "type": "METRIC", "confidence": 0.9985313415527344}]}, {"text": "shows the sentiment polarity of the original data set and synthetic data sets.", "labels": [], "entities": []}, {"text": "The first column is the original data set tagged by the Stanford library and is classified about 40% as positive, 49% as negative and 11% as neutral.", "labels": [], "entities": [{"text": "original data set tagged by the Stanford library", "start_pos": 24, "end_pos": 72, "type": "DATASET", "confidence": 0.7292072251439095}]}, {"text": "As we can see, the sentiment polarity of the synthetic data set using MC is most similar to the original one, with about 36% tagged as positive, 43% as negative and 21% as neutral.", "labels": [], "entities": []}, {"text": "The experiments indicate that the presented models can generate texts with a specific sentiment.", "labels": [], "entities": []}, {"text": "For sentiment analysis the Stanford library is used.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 4, "end_pos": 22, "type": "TASK", "confidence": 0.9838869571685791}, {"text": "Stanford library", "start_pos": 27, "end_pos": 43, "type": "DATASET", "confidence": 0.9654591679573059}]}, {"text": "The sentiment polarity of the synthetic data set using MC is most similar to the original one.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: This table shows the F-measures of the  original and synthetic data sets for the positive and  negative class separately. The synthetic data sets  are generated by scale up factors of 1, 2 and 10.  The sentiments analysis methods are SentiWord- Net (a) SVM (b), and Stanford library (c). The  HMM achieves a lower F-measure than MC but a  higher than LDA on each scale up factor.", "labels": [], "entities": [{"text": "Stanford library", "start_pos": 276, "end_pos": 292, "type": "DATASET", "confidence": 0.8424805700778961}, {"text": "F-measure", "start_pos": 324, "end_pos": 333, "type": "METRIC", "confidence": 0.9859327673912048}, {"text": "LDA", "start_pos": 361, "end_pos": 364, "type": "METRIC", "confidence": 0.9791324734687805}]}]}