{"title": [{"text": "Japanese Word Reordering Executed Concurrently with Dependency Parsing and Its Evaluation", "labels": [], "entities": [{"text": "Japanese Word Reordering", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.5931721528371176}]}], "abstractContent": [{"text": "This paper proposes a method for reordering words in a Japanese sentence based on concurrent execution with dependency parsing so that the sentence becomes more readable.", "labels": [], "entities": []}, {"text": "Our contributions are summarized as follows: (1) we extend a probablistic model used in the previous work which concurrently performs word reordering and dependency parsing; (2) we conducted an evaluation experiment using our semi-automatically constructed evaluation data so that sentences in the data are more likely to be spontaneously written by natives than the automatically constructed evaluation data in the previous work.", "labels": [], "entities": [{"text": "word reordering", "start_pos": 134, "end_pos": 149, "type": "TASK", "confidence": 0.7068554162979126}, {"text": "dependency parsing", "start_pos": 154, "end_pos": 172, "type": "TASK", "confidence": 0.736424058675766}]}], "introductionContent": [{"text": "Although Japanese has relatively free word order, Japanese word order is not completely arbitrary and has some sort of preference.", "labels": [], "entities": []}, {"text": "Since such preference is incompletely understood, even Japanese natives often write Japanese sentences which are grammatically well-formed but not easy to read.", "labels": [], "entities": []}, {"text": "For example, in, the word order of S1 is less readable than that of S2 because the distance between the bunsetsu \"Suzuki-san-ga (Mr. Suzuki)\" and its modified bunsetsu \"toi-te-shimatta (solved)\" is large and thus the loads on working memory become large) There have been some conventional researches for reordering words in a sentence so that the sentence becomes easier to read;).", "labels": [], "entities": []}, {"text": "Most of the conventional researches used syntactic information by assuming that an input sentence for word reordering  There is a problem that the errors of dependency parsing increase when an input sentence is less-readable, and the parsing errors cause negative effects on word reordering.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 157, "end_pos": 175, "type": "TASK", "confidence": 0.7106349021196365}]}, {"text": "To solve the problem, we previously proposed a method for concurrently performing word reordering and dependency parsing and confirmed the effectiveness of their proposed method using evaluation data created by randomly changing the word order in newspaper article sentences).", "labels": [], "entities": [{"text": "word reordering", "start_pos": 82, "end_pos": 97, "type": "TASK", "confidence": 0.7446987330913544}, {"text": "dependency parsing", "start_pos": 102, "end_pos": 120, "type": "TASK", "confidence": 0.7003232389688492}]}, {"text": "However, since some of the just automatically created sentences are unlikely to be spontaneously written by a native, the evaluation is thought to be not enough.", "labels": [], "entities": []}, {"text": "In addition, the probablistic model has room for improvement in targeting at sentences which a native is likely to spontaneously write.", "labels": [], "entities": []}, {"text": "This paper proposes anew method on Japanese word reordering based on concurrent execution with dependency parsing by extending the probablistic model proposed by, and describes an evaluation experiment using our evaluation data semi-automatically constructed by adding human judgement after automatically changing word order in newspaper article sentences.", "labels": [], "entities": [{"text": "Japanese word reordering", "start_pos": 35, "end_pos": 59, "type": "TASK", "confidence": 0.6078541378180186}, {"text": "dependency parsing", "start_pos": 95, "end_pos": 113, "type": "TASK", "confidence": 0.7549430131912231}]}, {"text": "The experimental results showed the effectiveness of our method.", "labels": [], "entities": []}], "datasetContent": [{"text": "To evaluate the effectiveness of our method, we applied our method to less-readable sentences artificially created by changing the word order of Japanese newspaper article sentences, and evaluated how much our method could reproduce the word order of the original sentences.", "labels": [], "entities": []}, {"text": "From a viewpoint of utilizing our method for support revision, it is desirable to use less-readable sentences spontaneously written by Japanese natives in the experiment.", "labels": [], "entities": [{"text": "support revision", "start_pos": 45, "end_pos": 61, "type": "TASK", "confidence": 0.729434072971344}]}, {"text": "However, it is not easy to collect a large amount of pairs composed of such a sentence and the corresponding sentence which was modified by hand so that the word order becomes readable, and also, such data is unavailable.", "labels": [], "entities": []}, {"text": "In addition, since spontaneously written sentences have many factors other than word order which decrease the readability, it is difficult to conduct the evaluation with a focus solely on word order.", "labels": [], "entities": []}, {"text": "Therefore, our previous work () artificially generated sentences which were not easy to read, by just automatically changing the word order of newspaper article sentences in Kyoto Text Corpus 3 based on the dependency structure.", "labels": [], "entities": [{"text": "Kyoto Text Corpus 3", "start_pos": 174, "end_pos": 193, "type": "DATASET", "confidence": 0.9560882598161697}]}, {"text": "However, just automatically changing the word order may create sentences which are unlikely to be written by a native.", "labels": [], "entities": []}, {"text": "To solve the problem, we semi-automatically constructed the evaluation data by adding human judgement.", "labels": [], "entities": []}, {"text": "That is, if a subject judges that a sentence generated by automatically changing the word order in the same way as the previous work () may have spontaneously written by a native.", "labels": [], "entities": []}, {"text": "Our constructed data has 552 sentences including 4,906 bunsetsus.", "labels": [], "entities": []}, {"text": "Since our method needs to decide the weight \u03b1 in Formula (2) in advance, we conducted 5-fold cross validation using the evaluation data constructed in Section 4.1.", "labels": [], "entities": []}, {"text": "Concretely, we divided 552 sentences into 5 sets, and then, we repeated an experiment 5 times, in which we used one set from among 5 sets as the test data and the others as the held-out data to decide \u03b1.", "labels": [], "entities": []}, {"text": "As the training data to estimate each probability in Formula (2), we used 7,976 sentences in Kyoto Text Corpus, which were different from the 552 sentences.", "labels": [], "entities": [{"text": "Kyoto Text Corpus", "start_pos": 93, "end_pos": 110, "type": "DATASET", "confidence": 0.984843115011851}]}, {"text": "Here, we used the Maximum Entropy Modeling Toolkit for Python and C++ 4 with the default options except \"-i (iteration) 1000.\"", "labels": [], "entities": []}, {"text": "In the evaluation of word reordering, we obtained the complete agreement (the percentage of the sentences in which all words' order completely agrees with that of the original sentence) and pair agreement (the percentage of the pairs of bunsetsus whose word order agrees with that in the original sentence), which are defined by.", "labels": [], "entities": [{"text": "word reordering", "start_pos": 21, "end_pos": 36, "type": "TASK", "confidence": 0.6968526989221573}, {"text": "pair agreement", "start_pos": 190, "end_pos": 204, "type": "METRIC", "confidence": 0.8757842481136322}]}, {"text": "Here, when deciding \u03b1 using the held-out data, we calculate the \u03b1 to two places of decimals which maximizes the pair agreement.", "labels": [], "entities": []}, {"text": "In the evaluation of dependency parsing, we obtained the dependency accuracy (the percentage of correctly analyzed dependencies out of all dependencies) and sentency accuracy (the percentage of the sentences in which all the dependencies are analyzed correctly), which were defined by.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 21, "end_pos": 39, "type": "TASK", "confidence": 0.8045392036437988}, {"text": "accuracy", "start_pos": 68, "end_pos": 76, "type": "METRIC", "confidence": 0.864798367023468}, {"text": "sentency accuracy", "start_pos": 157, "end_pos": 174, "type": "METRIC", "confidence": 0.7891886532306671}]}, {"text": "We compared our method to Yoshida's method () and two conventional sequential methods.", "labels": [], "entities": []}, {"text": "Both the sequential methods execute the dependency parsing primarily, and then, perform the word reordering by using the conventional word reordering method ().", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 40, "end_pos": 58, "type": "TASK", "confidence": 0.7406394183635712}]}, {"text": "The difference between the two is the method of dependency parsing.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 48, "end_pos": 66, "type": "TASK", "confidence": 0.8463447093963623}]}, {"text": "The sequential methods 1 and 2 use the dependency parsing method proposed by and the dependency parsing tool CaboCha 5 , respectively.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 39, "end_pos": 57, "type": "TASK", "confidence": 0.8109901547431946}, {"text": "dependency parsing", "start_pos": 85, "end_pos": 103, "type": "TASK", "confidence": 0.7677698135375977}]}, {"text": "All of the methods used the same training features as those described in. shows the experimental results on word reordering of each method.", "labels": [], "entities": [{"text": "word reordering", "start_pos": 108, "end_pos": 123, "type": "TASK", "confidence": 0.7002728432416916}]}, {"text": "Here, the last row shows the agreements measured by comparing the input word order with the correct word order.", "labels": [], "entities": []}, {"text": "The agreements mean the values which can be achieved with no reordering.", "labels": [], "entities": []}, {"text": "The both agreements of our method are micro averages for the agreements of each of the 5 sets.", "labels": [], "entities": []}, {"text": "As the result of decision of \u03b1 by using the held-out data, the \u03b1 for 3 sets was 0.66, and the \u03b1 for the other two sets was 0.75.", "labels": [], "entities": []}, {"text": "The both agreements of our method were highest among all.", "labels": [], "entities": []}, {"text": "We can confirm the effectiveness of our method.", "labels": [], "entities": []}, {"text": "Although the purpose of our method is reordering to improve readability, our method generates a dependency structure as a by-product.", "labels": [], "entities": []}, {"text": "Here, for reference, we show the experimental results on dependency parsing in.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 57, "end_pos": 75, "type": "TASK", "confidence": 0.8175353705883026}]}, {"text": "The dependency accuracy of our method was significantly lower than that of the two sequential methods, and was higher than that of Yoshida's method although there was no significant difference.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 15, "end_pos": 23, "type": "METRIC", "confidence": 0.9726365208625793}]}, {"text": "On the other hand, the sentence accuracy of our method was highest among all the methods although there were no significant differences in them.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 32, "end_pos": 40, "type": "METRIC", "confidence": 0.9892033934593201}]}, {"text": "As a result of analysis, especially, our method and Yoshida's method tended to improve the sentence accuracy very well in case of short sentences.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 100, "end_pos": 108, "type": "METRIC", "confidence": 0.9732820391654968}]}, {"text": "On the other hand, CaboCha, which is a dependency parser in sequential 2, tended not to depend very well on the length of sentences.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Experimental results (word reordering)", "labels": [], "entities": [{"text": "word reordering", "start_pos": 32, "end_pos": 47, "type": "TASK", "confidence": 0.7829396426677704}]}, {"text": " Table 2: Experimental results (dep. parsing)", "labels": [], "entities": []}]}