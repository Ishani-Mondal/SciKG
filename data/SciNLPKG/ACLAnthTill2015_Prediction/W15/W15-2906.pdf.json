{"title": [], "abstractContent": [{"text": "Agile social media analysis involves building bespoke, one-off classification pipelines tailored to the analysis of specific datasets.", "labels": [], "entities": [{"text": "social media analysis", "start_pos": 6, "end_pos": 27, "type": "TASK", "confidence": 0.8014944593111674}]}, {"text": "In this study we investigate how the DUALIST architecture can be op-timised for agile social media analysis.", "labels": [], "entities": []}, {"text": "We evaluate several semi-supervised learning algorithms in conjunction with a Na\u00a8\u0131veNa\u00a8\u0131ve Bayes model, and show how these modifications can improve the performance of bespoke classifiers fora variety of tasks on a large range of datasets.", "labels": [], "entities": []}], "introductionContent": [{"text": "Natural Language Processing (NLP) on large social media datasets has emerged as a popular theme in the academic NLP community with publications ranging from predicting elections, e.g. (, to forecasting box-office revenues for movies, e.g. ( and anticipating the stock market, e.g..", "labels": [], "entities": [{"text": "Natural Language Processing (NLP)", "start_pos": 0, "end_pos": 33, "type": "TASK", "confidence": 0.6790934155384699}]}, {"text": "More recently, Opinion Mining and Sentiment Analysis on large social media datasets have received an increasing amount of attention outside academia, where a growing number of businesses and public institutions seek to gain insight into public opinion.", "labels": [], "entities": [{"text": "Opinion Mining", "start_pos": 15, "end_pos": 29, "type": "TASK", "confidence": 0.7378018796443939}, {"text": "Sentiment Analysis", "start_pos": 34, "end_pos": 52, "type": "TASK", "confidence": 0.9180127382278442}]}, {"text": "For example, companies are primarily interested in what is being said about their brand and products, while public organisations are more concerned with analysing reactions to recent events, or with capturing the general political and societal Zeitgeist.", "labels": [], "entities": []}, {"text": "The social network Twitter has been a popular target for such analyses as the vast majority of tweets are publicly available, and easily obtainable via the Twitter API 1 , which conveniently enables the harnessing of a large number of realtime responses to any user-defined keyword query.", "labels": [], "entities": []}, {"text": "In this paper we are concerned with what we call agile social media analysis, which is best illustrated with an example.", "labels": [], "entities": [{"text": "agile social media analysis", "start_pos": 49, "end_pos": 76, "type": "TASK", "confidence": 0.7185917496681213}]}, {"text": "Imagine that apolitical scientist wants to investigate reactions on Twitter to a speech given by British Prime Minister David Cameron the previous night.", "labels": [], "entities": [{"text": "investigate reactions on Twitter to a speech given by British Prime Minister David Cameron the previous night", "start_pos": 43, "end_pos": 152, "type": "TASK", "confidence": 0.6588062591412488}]}, {"text": "She uses an application which allows her to query the Twitter API in order to gather a dataset, and to interactively design classifiers, tailored to specific tasks.", "labels": [], "entities": []}, {"text": "For her analysis, she starts searching for \"Cameron\", which inevitably will retrieve a large number of irrelevant tweets, e.g. those referring to Cameron Diaz.", "labels": [], "entities": []}, {"text": "Her first goal therefore is to filter out all of those unrelated tweets, for which she requires a bespoke classifier that will only be used for this single task.", "labels": [], "entities": []}, {"text": "In order to create such a classifier, she first needs to annotate a gold standard evaluation set which is randomly sampled from the initially retrieved tweets.", "labels": [], "entities": []}, {"text": "While labelling the first few tweets for the evaluation set, she starts to build a picture of the range of topics being discussed on Twitter that night.", "labels": [], "entities": []}, {"text": "She notices that a considerable proportion of tweets appears to be talking about David Cameron's personality.", "labels": [], "entities": []}, {"text": "Many of the others appear to be about two specific topics mentioned in the speech: tax policy and the EU referendum.", "labels": [], "entities": []}, {"text": "After training a classifier to perform relevancy classification, she therefore decides to create another one-off classifier to divide the relevant tweets into the three categories, \"personality\", \"tax policy\" and \"EU referendum\".", "labels": [], "entities": [{"text": "relevancy classification", "start_pos": 39, "end_pos": 63, "type": "TASK", "confidence": 0.7894930243492126}]}, {"text": "To conclude her analysis, she creates three more bespoke classifiers to perform Sentiment Analysis on each of the three subsets separately.", "labels": [], "entities": [{"text": "Sentiment Analysis", "start_pos": 80, "end_pos": 98, "type": "TASK", "confidence": 0.9309366941452026}]}, {"text": "A crucial aspect of performing agile social media analysis is the direct interaction with the data, through which the analyst gains a sense of what the discourse is about.", "labels": [], "entities": []}, {"text": "It furthermore enables her to better tailor her analysis to the collected data.", "labels": [], "entities": []}, {"text": "DUALIST introduced the framework which enables non-technical analysts to design bespoke classifiers by labelling documents and features through active learning, with only a few minutes of annotation effort. and showed that the DUALIST architecture can successfully be used for performing ad-hoc analyses in an agile manner.", "labels": [], "entities": [{"text": "DUALIST", "start_pos": 0, "end_pos": 7, "type": "DATASET", "confidence": 0.9498084187507629}]}, {"text": "The remainder of this paper is organised as follows: in Section 2 we more generally introduce agile social media analysis, followed by the description of the datasets we use in our empirical evaluation in Section 3.", "labels": [], "entities": []}, {"text": "Section 4 describes our approach alongside related work and Section 5 presents our experiments and discusses our findings.", "labels": [], "entities": []}, {"text": "In Section 6 we give an overview of future work and we conclude this paper in Section 7.", "labels": [], "entities": []}], "datasetContent": [{"text": "We evaluate our experiments on 24 Twitter datasets that have been collected by social scientists fora number of real-world analyses ().", "labels": [], "entities": []}, {"text": "The Twitter datasets represent a diverse range of possible applications of agile social media analysis.", "labels": [], "entities": [{"text": "Twitter datasets", "start_pos": 4, "end_pos": 20, "type": "DATASET", "confidence": 0.7304265946149826}, {"text": "agile social media analysis", "start_pos": 75, "end_pos": 102, "type": "TASK", "confidence": 0.6650609821081161}]}, {"text": "Some are focused on \"Twitcidents\" 2 during political debates or speeches (boocheer, cameron 1-3, clacton, clegg, debate 1-2, farage, immigr, miliband 1-2, salmond).", "labels": [], "entities": []}, {"text": "Three datasets are concerned with reactions to the inquest following the death of Mark Duggan in London 2013 (duggan 1-3), and the remaining ones investigate topics such as the winter floods in many coastal regions in the South of England, throughout late 2013 and early 2014 (flood 1-2), misogyny (misogyny, rape), extremism (isis 1-3) and oil drillings in the arctic (shell).", "labels": [], "entities": [{"text": "Duggan in London 2013 (duggan 1-3", "start_pos": 87, "end_pos": 120, "type": "DATASET", "confidence": 0.7219892186777932}]}, {"text": "The Twitter datasets are drawn from different stages of the processing pipeline, which means that some datasets consist of the unprocessed tweets matching an initial keyword query while others have already been processed by one or more preceding steps in the pipeline.", "labels": [], "entities": []}, {"text": "For example, the shell and flood-1 datasets are the result of querying the Twitter API, whereas the duggan-1 dataset has already been cleared of irrelevant tweets, and tweets only containing news links, in two separate preceeding stages of the processing pipeline.", "labels": [], "entities": []}, {"text": "We furthermore evaluate our implementations on 2 commonly used NLP benchmark datasets, 20 Newsgroups, henceforth \"20news\", as an example Topic Classification dataset, and Movie Reviews (Maas et al., 2011), henceforth \"reviews\", as an example Sentiment Analysis dataset.", "labels": [], "entities": [{"text": "NLP benchmark datasets", "start_pos": 63, "end_pos": 85, "type": "DATASET", "confidence": 0.6384885907173157}, {"text": "Sentiment Analysis", "start_pos": 242, "end_pos": 260, "type": "TASK", "confidence": 0.805433064699173}]}, {"text": "highlights the extreme imbalance between labelled and unlabelled data and the corresponding differences in vocabulary size.", "labels": [], "entities": []}, {"text": "In the Twitter datasets, |V L | is usually one order of magnitude smaller than |V L\u222a U |.", "labels": [], "entities": [{"text": "Twitter datasets", "start_pos": 7, "end_pos": 23, "type": "DATASET", "confidence": 0.8572600483894348}]}, {"text": "In comparison, the disparity in vocabulary size between labelled and unlabelled data in the reviews corpus is less than a factor of two.", "labels": [], "entities": []}, {"text": "The difference is more extreme when looking at the actual amounts of labelled and unlabelled data, where the Twitter datasets often contain two orders of magnitude more unlabelled data than labelled data.", "labels": [], "entities": [{"text": "Twitter datasets", "start_pos": 109, "end_pos": 125, "type": "DATASET", "confidence": 0.7434450089931488}]}, {"text": "Furthermore, the disparity in number of labelled documents between the Twitter datasets and the NLP benchmark corpora usually is one to two orders of magnitude.", "labels": [], "entities": [{"text": "Twitter datasets", "start_pos": 71, "end_pos": 87, "type": "DATASET", "confidence": 0.7722138464450836}, {"text": "NLP benchmark corpora", "start_pos": 96, "end_pos": 117, "type": "DATASET", "confidence": 0.857274611790975}]}, {"text": "Where the 20news dataset contains more than 10k labelled documents and the reviews dataset even 25k labelled instances, the Twitter datasets rarely contain more than a few hundred labelled tweets.", "labels": [], "entities": [{"text": "20news dataset", "start_pos": 10, "end_pos": 24, "type": "DATASET", "confidence": 0.9169686734676361}, {"text": "Twitter datasets", "start_pos": 124, "end_pos": 140, "type": "DATASET", "confidence": 0.7940919101238251}]}, {"text": "All datasets we use have pre-defined training/testing splits.", "labels": [], "entities": []}, {"text": "We tokenise the documents, but do not perform any other pre-processing such as stemming, URL normalisation or stopword removal.", "labels": [], "entities": [{"text": "URL normalisation", "start_pos": 89, "end_pos": 106, "type": "TASK", "confidence": 0.7754006683826447}, {"text": "stopword removal", "start_pos": 110, "end_pos": 126, "type": "TASK", "confidence": 0.7395207285881042}]}, {"text": "All documents are represented as simple bag-of-words vectors.", "labels": [], "entities": []}, {"text": "We report micro-averaged F1-Scores for all experiments.", "labels": [], "entities": [{"text": "F1-Scores", "start_pos": 25, "end_pos": 34, "type": "METRIC", "confidence": 0.9452082514762878}]}, {"text": "When investigating the effect of unlabelled data, we randomly sample 1k, 5k, 10k, 25k, 50k, 100k unlabelled tweets, or use all available unlabelled data.", "labels": [], "entities": []}, {"text": "As baseline we use EM-CWF -MNB add-1, which reflects the text classifier and semi-supervised learning algorithm used in DUALIST, with the difference that we use the labelled documents instead of the labelled features for initialising EM.", "labels": [], "entities": []}, {"text": "This is to isolate the effects of Na\u00a8\u0131veNa\u00a8\u0131ve Bayes and EM, and to factor out the contributions of active learning.", "labels": [], "entities": [{"text": "EM", "start_pos": 57, "end_pos": 59, "type": "METRIC", "confidence": 0.6311903595924377}]}, {"text": "We compare our results in terms of absolute F1-Score gain/loss in comparison to our baseline, or present F1-Score performance trajectories.", "labels": [], "entities": [{"text": "F1-Score gain/loss", "start_pos": 44, "end_pos": 62, "type": "METRIC", "confidence": 0.9462739378213882}, {"text": "F1-Score", "start_pos": 105, "end_pos": 113, "type": "METRIC", "confidence": 0.9958701729774475}]}], "tableCaptions": [{"text": " Table 1: Datasets: T =Task, where TC=Topic Classification; SA=Sentiment Analysis; |C| = number of labels; L=Labelled data, |L|=amount of Labelled data; U =Unlabelled data,  |U |=amount of Unlabelled data; |V L |=Vocabulary size of the labelled data; |V L\u222a U |=Vocabulary size of the labelled and unlabelled data", "labels": [], "entities": []}, {"text": " Table 2: Micro averaged F1-Score for all methods across all datasets. EM-M=EM-PWF -binary MNB LT; EM-B=EM-PWF -BNB LT; SFE-M=SFE -binary MNB LT; SFE-B=SFE - BNB LT; FM=FM -binary MNB LT; MNB=supervised binary MNB LT; EM-C=EM-CWF -MNB add-1; Boldfaced numbers mean top performance on the dataset.", "labels": [], "entities": [{"text": "F1-Score", "start_pos": 25, "end_pos": 33, "type": "METRIC", "confidence": 0.5394518375396729}]}]}