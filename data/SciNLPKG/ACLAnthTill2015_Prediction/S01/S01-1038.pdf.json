{"title": [{"text": "Word Translation Based on Machine Learning Models Using Translation Memory and Corpora", "labels": [], "entities": [{"text": "Word Translation", "start_pos": 0, "end_pos": 16, "type": "TASK", "confidence": 0.7659096419811249}]}], "abstractContent": [{"text": "SENSEVAL-2 was held in Spring, 2001.", "labels": [], "entities": [{"text": "SENSEVAL-2", "start_pos": 0, "end_pos": 10, "type": "DATASET", "confidence": 0.6207985877990723}]}, {"text": "It consisted of several tasks in various languages.", "labels": [], "entities": []}, {"text": "In this paper, we describe our system used for one of these tasks: the Japanese translation task.", "labels": [], "entities": [{"text": "Japanese translation task", "start_pos": 71, "end_pos": 96, "type": "TASK", "confidence": 0.805102010567983}]}, {"text": "With an accuracy of 63.4%, our system was the third best system in the contest among nine systems developed by seven groups.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 8, "end_pos": 16, "type": "METRIC", "confidence": 0.9996687173843384}]}], "introductionContent": [{"text": "In the Japanese translation task, the senses of a word were defined in terms of the word's translations.", "labels": [], "entities": [{"text": "Japanese translation task", "start_pos": 7, "end_pos": 32, "type": "TASK", "confidence": 0.7063131034374237}]}, {"text": "Given an input sentence and a target word in the sentence, our system first estimates the similarity between the input sentence and parallel example sets called \"Translation Memory\".", "labels": [], "entities": [{"text": "Translation Memory", "start_pos": 162, "end_pos": 180, "type": "TASK", "confidence": 0.8933805823326111}]}, {"text": "It then selects an appropriate translation of the target word by using the example set with the highest similarity.", "labels": [], "entities": []}, {"text": "The similarity is calculated using dynamic programming and a machine learning model, which assesses the similarity based on the similarity of a string, words to the left and to the right of the target word in the input sentence, content words in the input sentence and their translations, and co-occurrence of content words in bilingual and monolingual corpora in English and Japanese.", "labels": [], "entities": []}], "datasetContent": [{"text": "The input and evaluation of the systems followed those of the Japanese translation task in SENSEVAL-2.", "labels": [], "entities": [{"text": "Japanese translation", "start_pos": 62, "end_pos": 82, "type": "TASK", "confidence": 0.5729282945394516}]}, {"text": "ATM for 320 headwords was given to each participant in the middle of.", "labels": [], "entities": [{"text": "ATM", "start_pos": 0, "end_pos": 3, "type": "METRIC", "confidence": 0.966759979724884}]}, {"text": "The average number of examples prepared for each headword was approximately 20.", "labels": [], "entities": []}, {"text": "For the formal test, 40 target words (20 nouns and 20 verbs) were selected from the headwords.", "labels": [], "entities": []}, {"text": "For each target word, 30 texts including the target words were prepared.", "labels": [], "entities": []}, {"text": "The total number of the target words was 1,200.", "labels": [], "entities": []}, {"text": "As a bilingual dictionary, we used \"EI-JIRO\" available at the website of NIFTY ' a network provider.", "labels": [], "entities": []}, {"text": "As monolingual corpora, we used MAINICHI newspapers from 1991 to, which include English newspaper articles for several years published by the Wall Street Journal the Associated Press Writer, and the New York Times.", "labels": [], "entities": []}, {"text": "In the formal test, the threshold of similarity used in Method 1 was 1.", "labels": [], "entities": [{"text": "similarity", "start_pos": 37, "end_pos": 47, "type": "METRIC", "confidence": 0.8157510757446289}]}, {"text": "JUMAN (), a Japanese morphological analyzer, was used for morphological analysis in Method 2.", "labels": [], "entities": [{"text": "JUMAN", "start_pos": 0, "end_pos": 5, "type": "DATASET", "confidence": 0.7890968322753906}, {"text": "morphological analysis", "start_pos": 58, "end_pos": 80, "type": "TASK", "confidence": 0.9432969689369202}]}, {"text": "As sentences similar to a certain example in Method 2, sentences that included a string obtained by stemming Japanese examples were extracted for Japanese examples, and sentences that included English headwords were extracted for English examples.", "labels": [], "entities": []}, {"text": "As for the rnachine learning models, we could not select the most appropriate set of models by cross validation because not all learning processes could be finished by the deadline for submission.", "labels": [], "entities": []}, {"text": "The models finally selected for the formal test were as follows: \u2022 SVM : 23 words (12 nouns and 11 verbs) \u2022 DL : 12 words (8 nouns and 4 verbs) \u2022 SB : 5 words (5 verbs)  The accuracy obtained by our system in the formal test was 63.4% (761/1,200).", "labels": [], "entities": [{"text": "DL", "start_pos": 108, "end_pos": 110, "type": "METRIC", "confidence": 0.9335253834724426}, {"text": "accuracy", "start_pos": 174, "end_pos": 182, "type": "METRIC", "confidence": 0.9995367527008057}]}, {"text": "The accuracy obtained by Method 1 and 2 were 91.0% (91/100) and 60.9% (670/1,100), respectively.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.9997547268867493}]}, {"text": "Based on our results, we can draw the following conclusions:", "labels": [], "entities": []}], "tableCaptions": []}