{"title": [{"text": "Improving WSD with Multi-Level View of Context Monitored by Similarity Measure", "labels": [], "entities": [{"text": "WSD", "start_pos": 10, "end_pos": 13, "type": "TASK", "confidence": 0.73298180103302}]}], "abstractContent": [{"text": "The approach presented in this paper for Word Sense Disambiguation (WSD) is based on a combination of different views of the context.", "labels": [], "entities": [{"text": "Word Sense Disambiguation (WSD)", "start_pos": 41, "end_pos": 72, "type": "TASK", "confidence": 0.8269164313872656}]}, {"text": "Semantic Classification Trees (SCT) are employed over a short and a multi-level view of context, including rough semantic features, while a similarity measure is used in some particular cases to rely on a larger view of the context.", "labels": [], "entities": [{"text": "Semantic Classification Trees (SCT)", "start_pos": 0, "end_pos": 35, "type": "TASK", "confidence": 0.7622391631205877}]}, {"text": "We also describe our two-step approach based on HMM for the all-word task.", "labels": [], "entities": []}], "introductionContent": [{"text": "In the tracks of SENSEV AL-l), the second edition of the word sense disambiguation evaluation campaign offers anew set of words to test improvements in the domain of WSD.", "labels": [], "entities": [{"text": "word sense disambiguation evaluation", "start_pos": 57, "end_pos": 93, "type": "TASK", "confidence": 0.7346025034785271}, {"text": "WSD", "start_pos": 166, "end_pos": 169, "type": "TASK", "confidence": 0.8500334024429321}]}, {"text": "It also includes anew task, aimed at disambiguating each word of a text.", "labels": [], "entities": [{"text": "disambiguating each word of a text", "start_pos": 37, "end_pos": 71, "type": "TASK", "confidence": 0.7670109371344248}]}, {"text": "Our approach for the lexical sample task is based on three different views of the context, which allows us to consider more information for sense tagging.", "labels": [], "entities": [{"text": "sense tagging", "start_pos": 140, "end_pos": 153, "type": "TASK", "confidence": 0.74923175573349}]}, {"text": "In order to deal with shortrange view of the context, we have chosen to use Semantic Classification Trees (SCT), which are binary decision trees.", "labels": [], "entities": []}, {"text": "Moreover, based on our experience, we will show, that using rough semantic features as a higher-level view of the context yields substantial increases in perfom1ance.", "labels": [], "entities": []}, {"text": "Finally, a similarity distance is employed in order to capture longer-range context information.", "labels": [], "entities": [{"text": "similarity distance", "start_pos": 11, "end_pos": 30, "type": "METRIC", "confidence": 0.9402256011962891}]}, {"text": "The paper is organized as follows: in the first part (Section I), the work we have done on the lexical sample task is presented.", "labels": [], "entities": []}, {"text": "This part includes a brief overview of the SCT approach (Section 1. 1) and we show how the coverage it yields could be increased while using more or less rough semantic features thanks to a multi-level view of the context (Section 1.2).", "labels": [], "entities": [{"text": "SCT", "start_pos": 43, "end_pos": 46, "type": "TASK", "confidence": 0.9767016172409058}]}, {"text": "In (2) Sinequa 51-59 rue Ledru Rollin F-94200 lvry-sur-Seine { crestan, loupy} @sinequa.com Section 1.3, we propose to use a similarity measure like those used in document retrieval in order to select a sense among those proposed by the SCT systems.", "labels": [], "entities": [{"text": "Sinequa 51-59 rue Ledru Rollin F-94200 lvry-sur-Seine { crestan", "start_pos": 7, "end_pos": 70, "type": "DATASET", "confidence": 0.8900489078627692}]}, {"text": "The second part (Section 2) is dedicated to the all-words task.", "labels": [], "entities": []}, {"text": "A two-step approach based on a trisem-bisem model is presented (Section 2.1 ).", "labels": [], "entities": []}, {"text": "Then, we propose to apply a special process on the most frequent words in the task (Section 2.2).", "labels": [], "entities": []}, {"text": "In conclusion, the results for both tasks are presented.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Results for fine and coarse-grained senses", "labels": [], "entities": []}]}