{"title": [{"text": "Combination of contextual features for word sense disambiguation: LIU-WSD", "labels": [], "entities": [{"text": "word sense disambiguation", "start_pos": 39, "end_pos": 64, "type": "TASK", "confidence": 0.7313114702701569}]}], "abstractContent": [{"text": "This paper describes a system for word sense disambiguation that participated in the Swedish Lexical Sample task of SENSEVAL-2.", "labels": [], "entities": [{"text": "word sense disambiguation", "start_pos": 34, "end_pos": 59, "type": "TASK", "confidence": 0.75566166639328}, {"text": "Swedish Lexical Sample task of SENSEVAL-2", "start_pos": 85, "end_pos": 126, "type": "TASK", "confidence": 0.6242675632238388}]}, {"text": "The system LIU-WSD is based on letting different contextual features cast votes on preferred senses according to a ranking scheme.", "labels": [], "entities": []}], "introductionContent": [{"text": "The addition of new languages to the SENSEV AL-2 workshop, among these languages also Swedish, presented an opportunity to learn more about WSD applied to Swedish by participation in the event.", "labels": [], "entities": [{"text": "SENSEV AL-2 workshop", "start_pos": 37, "end_pos": 57, "type": "DATASET", "confidence": 0.6372621953487396}, {"text": "WSD", "start_pos": 140, "end_pos": 143, "type": "TASK", "confidence": 0.9375767707824707}]}, {"text": "Previously, we had had no experience of building word sense disambiguation software, but the Swedish Lexical Sample task seemed like a suitable occasion for trying another field of NLP (in recent years our focus has been on word alignment and parallel corpora).", "labels": [], "entities": [{"text": "word sense disambiguation", "start_pos": 49, "end_pos": 74, "type": "TASK", "confidence": 0.7434589465459188}, {"text": "Swedish Lexical Sample task", "start_pos": 93, "end_pos": 120, "type": "TASK", "confidence": 0.6218453943729401}, {"text": "word alignment", "start_pos": 224, "end_pos": 238, "type": "TASK", "confidence": 0.765055924654007}]}, {"text": "Due to time constraints our initial plans of implementing some kind of version of decision lists were abandoned in the end and we decided to go fora slightly simpler approach based on a general algorithm and voting strategies for contextual features on different levels.", "labels": [], "entities": []}, {"text": "The contextual features that were being considered were unigrams and bigrams, both in fixed and variable positions, together with possibilities to include parts-of-speech, lemmas and graph words (inflected words).", "labels": [], "entities": []}], "datasetContent": [{"text": "As the results were slightly worse than we had hoped for, it is interesting to point out further details from the scores and on the strategies that were actually used by the system.", "labels": [], "entities": []}, {"text": "illustrates what part of the algorithm that was used for selecting a particular sense and how well each strategy worked.", "labels": [], "entities": []}, {"text": "It is notable that more than 50 percent of the selections were made by the heuristics to select a \"sure sense\" based on the relative frequency.", "labels": [], "entities": []}, {"text": "This is also the most successful in terms of precision of all the strategies.", "labels": [], "entities": [{"text": "precision", "start_pos": 45, "end_pos": 54, "type": "METRIC", "confidence": 0.9994613528251648}]}, {"text": "The voting strategies performed far worse, 49% for selection based on senses that were ranked first, and only 24% when a tie for first place was found and the second positions were considered.", "labels": [], "entities": []}, {"text": "The strategies to select a shared common main sense, a most frequent main sense or most frequent sub sense when the other criteria failed were clearly not very successful, as indicated by precision rates varying from 18 to 25 percent.", "labels": [], "entities": [{"text": "precision", "start_pos": 188, "end_pos": 197, "type": "METRIC", "confidence": 0.9987769722938538}]}, {"text": "It is also worth pointing out that there were always some significant features for each instance of the test corpus, which meant that step 1 of the algorithm never triggered.", "labels": [], "entities": []}, {"text": "The same is true for the last step.", "labels": [], "entities": []}, {"text": "If we breakdown the results into different parts-of-speech, we can seethe following: As has been noted elsewhere, nouns are easier than verbs and adjectives when it comes to word sense disambiguation ( cf. Yarowsky 2000).", "labels": [], "entities": [{"text": "word sense disambiguation", "start_pos": 174, "end_pos": 199, "type": "TASK", "confidence": 0.6568844318389893}]}, {"text": "This is clearly the case here, and a contributing factor to this is that the number of senses for nouns is significantly smaller than for the other word classes.", "labels": [], "entities": []}, {"text": "However, the system does in general perform better than the standard baseline (Most Frequent Sense of the trammg corpus).", "labels": [], "entities": [{"text": "trammg corpus", "start_pos": 106, "end_pos": 119, "type": "DATASET", "confidence": 0.719914585351944}]}, {"text": "For nouns, all 20 test instances are better than the baseline.", "labels": [], "entities": []}, {"text": "There is however work to be done to improve the performance for verbs and adjectives.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2. Overview of sense selecting criteria for the LIU-WSD system in SENSEV AL-2", "labels": [], "entities": [{"text": "SENSEV AL-2", "start_pos": 73, "end_pos": 84, "type": "DATASET", "confidence": 0.6788080632686615}]}]}