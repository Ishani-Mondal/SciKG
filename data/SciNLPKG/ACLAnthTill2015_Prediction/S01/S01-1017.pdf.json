{"title": [{"text": "Using Lazy Boosting for Word Sense Disambiguation", "labels": [], "entities": [{"text": "Word Sense Disambiguation", "start_pos": 24, "end_pos": 49, "type": "TASK", "confidence": 0.715399444103241}]}], "abstractContent": [{"text": "This paper describes the architecture and results of the TALP system presented at the SENSEVAL-2 exercise for the English lexical-sample task.", "labels": [], "entities": []}, {"text": "This system is based on the LazyBoosting algorithm for Word Sense Disambiguation (Escudero et al., 2000), and incorporates some improvements and adaptations to this task.", "labels": [], "entities": [{"text": "Word Sense Disambiguation", "start_pos": 55, "end_pos": 80, "type": "TASK", "confidence": 0.6433865229288737}]}, {"text": "The evaluation reported here includes an analysis of the contribution of each component to the overall system performance.", "labels": [], "entities": []}], "introductionContent": [], "datasetContent": [{"text": "The official results achieved by the TALP system are presented in table 1.", "labels": [], "entities": [{"text": "TALP", "start_pos": 37, "end_pos": 41, "type": "TASK", "confidence": 0.6166656613349915}]}, {"text": "The evaluation setting corresponding to these results contains all the modifications explained in the previous sections, including the hierarchical approach to all words.", "labels": [], "entities": []}, {"text": "Accuracy fine-grained 59.4% coarse-grained 67.1%: Official results After the SENSEVAL-2 event, we added a very simple Named-entity Recognizer to the part-ofspeech tagger that was not finished at the time of the event, but the system continues ignoring the 'U' label.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 0, "end_pos": 8, "type": "METRIC", "confidence": 0.9918408393859863}, {"text": "SENSEVAL-2 event", "start_pos": 77, "end_pos": 93, "type": "TASK", "confidence": 0.5611841678619385}]}, {"text": "We also have evaluated which parts of the system contributed most to the improvement in performance.", "labels": [], "entities": []}, {"text": "shows the accuracy results of the four combinations resulting from using (or not) domain-label features and hierarchical decomposition.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9996054768562317}]}, {"text": "These results have been calculated over the test set of SENSEVAL-2.", "labels": [], "entities": [{"text": "SENSEVAL-2", "start_pos": 56, "end_pos": 66, "type": "DATASET", "confidence": 0.5174651145935059}]}, {"text": "On the one hand, it becomes clear that enriching the feature set with domain labels systematically improves the results in all cases, and that this difference is specially noticeable in the case of nouns (over 3 points of improvement).", "labels": [], "entities": []}, {"text": "On the other hand, the use of the hierarchies is unexpectedly useless in all cases.", "labels": [], "entities": []}, {"text": "Although it is productive in some particular words: Fine/coarse-grained evaluation for different settings and part-of-speech overall performance is significantly lower.", "labels": [], "entities": [{"text": "Fine", "start_pos": 52, "end_pos": 56, "type": "METRIC", "confidence": 0.9608122706413269}]}, {"text": "A fact that can explain this situation is that the first-level classifiers do not succeed on classifying semanticfile labels with high precision (the average accuracy of first-level classifiers is only slightly over 71%) and that this important error is dramatically propagated to the second-level, not allowing the greedy sequential application of classifiers.", "labels": [], "entities": [{"text": "precision", "start_pos": 135, "end_pos": 144, "type": "METRIC", "confidence": 0.9885308742523193}, {"text": "accuracy", "start_pos": 158, "end_pos": 166, "type": "METRIC", "confidence": 0.9949328303337097}]}, {"text": "A possible explanation of this fact is the way semantic classes are defined in WordNet.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 79, "end_pos": 86, "type": "DATASET", "confidence": 0.9550297856330872}]}, {"text": "Consider for instance work#1 (activity) and work#2 (production), they seem quite close but a system trying to differentiate among semantic files needs to distinguish among these two senses.", "labels": [], "entities": []}, {"text": "On the other extreme, such a classifier should collapse house#2 (legislature) with house#4 (family), which are quite different.", "labels": [], "entities": []}, {"text": "Of course, joining both situations makes a pretty hard task.", "labels": [], "entities": []}, {"text": "Regarding multiword preprocessing (not included in table 2), we have seen that is slightly useful in all cases.", "labels": [], "entities": [{"text": "multiword preprocessing", "start_pos": 10, "end_pos": 33, "type": "TASK", "confidence": 0.8388420939445496}]}, {"text": "It improves the non-hierarchical scheme with domain information by almost 1 point inaccuracy.", "labels": [], "entities": []}, {"text": "By part-of-speech, the improvement is about 1 point for nouns, 0.1 for verbs and about 2 points for adjectives.", "labels": [], "entities": []}, {"text": "In conclusion, the best results obtained by our system on this test set correspond to the application of multiword preprocessing and domain-labels for all words, but no hierarchical decomposition at all, achieving a fine-grained accuracy of 61.51% and a coarse-grained accuracy of 69.00%.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 229, "end_pos": 237, "type": "METRIC", "confidence": 0.6580566167831421}, {"text": "coarse-grained", "start_pos": 254, "end_pos": 268, "type": "METRIC", "confidence": 0.9171772003173828}, {"text": "accuracy", "start_pos": 269, "end_pos": 277, "type": "METRIC", "confidence": 0.5369935631752014}]}, {"text": "We know that it is not fair to consider these results for comparison, since the system is tuned over the test set.", "labels": [], "entities": []}, {"text": "Our aim is simply to fully inspect the TALP system to know which parts are useful fora real Word Sense Disambiguation system.", "labels": [], "entities": [{"text": "Word Sense Disambiguation", "start_pos": 92, "end_pos": 117, "type": "TASK", "confidence": 0.7342731555302938}]}], "tableCaptions": [{"text": " Table 2: Fine/coarse-grained evaluation for differ- ent settings and part-of-speech", "labels": [], "entities": []}]}