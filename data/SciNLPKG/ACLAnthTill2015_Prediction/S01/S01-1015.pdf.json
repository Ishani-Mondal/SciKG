{"title": [{"text": "Probabilistic Network Models for Word Sense Disambiguation", "labels": [], "entities": [{"text": "Word Sense Disambiguation", "start_pos": 33, "end_pos": 58, "type": "TASK", "confidence": 0.7352164089679718}]}], "abstractContent": [{"text": "We present the techniques used in the word sense disambiguation (WSD) system that was submitted to the SENSEVAL-2 workshop.", "labels": [], "entities": [{"text": "word sense disambiguation (WSD)", "start_pos": 38, "end_pos": 69, "type": "TASK", "confidence": 0.7851343750953674}]}, {"text": "The system builds a probabilistic network per sentence to model the dependencies between the words within the sentence, and the sense tagging for the entire sentence is computed by performing a query over the network.", "labels": [], "entities": []}, {"text": "The salient context used for disambiguation is based on sentential structure and not positional information.", "labels": [], "entities": []}, {"text": "The parameters are established automatically and smoothed via training data, which was compiled from the SemCor corpus and the WordNet glosses.", "labels": [], "entities": [{"text": "SemCor corpus", "start_pos": 105, "end_pos": 118, "type": "DATASET", "confidence": 0.8994731903076172}, {"text": "WordNet glosses", "start_pos": 127, "end_pos": 142, "type": "DATASET", "confidence": 0.9578966498374939}]}, {"text": "Lastly, the One-sense-per-discourse (OSPD) hypothesis is incorporated to test its effectiveness.", "labels": [], "entities": []}, {"text": "The results from two parameterization techniques and the effects of the OSPD hypothesis are presented.", "labels": [], "entities": []}, {"text": "1 Problem Formulation WSD is treated in this system as a classification task, where the ith sense (W #i) of a word (W) is classified as the correct sense tag (M;), given the word W and usually some surrounding context.", "labels": [], "entities": [{"text": "Problem Formulation WSD", "start_pos": 2, "end_pos": 25, "type": "TASK", "confidence": 0.792664368947347}]}, {"text": "In the SENSEVAL-2 English all-words task, all ambiguous content words (nouns, verbs, adjectives, and adverbs) are to be classified with a sense tag from the WordNet 1.7 lexical database (Miller, 1990).", "labels": [], "entities": [{"text": "SENSEVAL-2 English all-words task", "start_pos": 7, "end_pos": 40, "type": "TASK", "confidence": 0.8525936901569366}, {"text": "WordNet 1.7 lexical database", "start_pos": 157, "end_pos": 185, "type": "DATASET", "confidence": 0.9191206395626068}]}, {"text": "For example, the words \"great\", \"devastated\", and \"re-gion\" in the sentence \"The great hurricane devastated the region\" are classified with the correct sense tags 2, 2, and 2, respectively.", "labels": [], "entities": [{"text": "re-gion", "start_pos": 51, "end_pos": 58, "type": "METRIC", "confidence": 0.9710753560066223}]}, {"text": "We will refer to this task using the following notation: M = Mbest(S) = arg maxP(MIS), (1) where S is the input sentence, and M is the semantic tag assigned to each word.", "labels": [], "entities": [{"text": "arg maxP(MIS)", "start_pos": 72, "end_pos": 85, "type": "METRIC", "confidence": 0.9353632092475891}]}, {"text": "While a context larger than the sentence Scan be and is used in our model, we will refer to the context asS.", "labels": [], "entities": []}, {"text": "In this formulation , each word W; in the sentence is treated as a random variable M; taking on the values {1 ..", "labels": [], "entities": []}, {"text": "Ni}, where N; is the number of senses for the word W;.", "labels": [], "entities": []}, {"text": "Therefore, we wish to find instantiations of M such that P(MIS) is maximized.", "labels": [], "entities": [{"text": "MIS)", "start_pos": 59, "end_pos": 63, "type": "METRIC", "confidence": 0.8515728712081909}]}], "introductionContent": [], "datasetContent": [{"text": "For SENSEVAL-2, we submitted three models for comparison, which differ by their methods of parameter estimation.", "labels": [], "entities": [{"text": "SENSEVAL-2", "start_pos": 4, "end_pos": 14, "type": "TASK", "confidence": 0.806846022605896}]}, {"text": "Model 2 uses the training data from SemCor and Hierarchical networks to smooth the parameters from Internet search engines.", "labels": [], "entities": []}, {"text": "Model 3 incorporates additional training data gathered automatically from the WordNet glosses.", "labels": [], "entities": [{"text": "WordNet glosses", "start_pos": 78, "end_pos": 93, "type": "DATASET", "confidence": 0.9724238216876984}]}, {"text": "Lastly, model 1 combines all training data, as well as the OSPD hypothesis.", "labels": [], "entities": []}, {"text": "One can see that the model that uses all of the available data achieved best accuracy (model 1) but unfortunately also had the lowest recall due to the added complexity.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 77, "end_pos": 85, "type": "METRIC", "confidence": 0.9995301961898804}, {"text": "recall", "start_pos": 134, "end_pos": 140, "type": "METRIC", "confidence": 0.9995118379592896}]}, {"text": "Some highly polysemous words were omitted due to time and memory constraints.", "labels": [], "entities": []}, {"text": "Between the 2 training sets, it was unfortunate that the addition of the automatically generated training set reduced the accuracy slightly, mainly due to the noisy data produced by our experimental system.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 122, "end_pos": 130, "type": "METRIC", "confidence": 0.9995669722557068}]}], "tableCaptions": [{"text": " Table 1: Precision/recall results of the three models  submitted to SENSEVAL-2.", "labels": [], "entities": [{"text": "Precision", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9950592517852783}, {"text": "recall", "start_pos": 20, "end_pos": 26, "type": "METRIC", "confidence": 0.9161688685417175}]}]}