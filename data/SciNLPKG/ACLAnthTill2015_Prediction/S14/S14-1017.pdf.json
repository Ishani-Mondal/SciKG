{"title": [{"text": "Using Text Segmentation Algorithms for the Automatic Generation of E-Learning Courses", "labels": [], "entities": [{"text": "Automatic Generation of E-Learning Courses", "start_pos": 43, "end_pos": 85, "type": "TASK", "confidence": 0.7363972663879395}]}], "abstractContent": [{"text": "With the advent of e-learning, there is a strong demand for tools that help to create e-learning courses in an automatic or semi-automatic way.", "labels": [], "entities": []}, {"text": "While resources for new courses are often freely available, they are generally not properly structured into easy to handle units.", "labels": [], "entities": []}, {"text": "In this paper, we investigate how state of the art text segmentation algorithms can be applied to automatically transform unstructured text into coherent pieces appropriate for e-learning courses.", "labels": [], "entities": [{"text": "text segmentation", "start_pos": 51, "end_pos": 68, "type": "TASK", "confidence": 0.7551231682300568}]}, {"text": "The feasibility to course generation is validated on a test corpus specifically tailored to this scenario.", "labels": [], "entities": [{"text": "course generation", "start_pos": 19, "end_pos": 36, "type": "TASK", "confidence": 0.8618796169757843}]}, {"text": "We also introduce a more generic training and testing method for text seg-mentation algorithms based on a Latent Dirichlet Allocation (LDA) topic model.", "labels": [], "entities": []}, {"text": "In addition we introduce a scalable random text segmentation algorithm, in order to establish lower and upper bounds to be able to evaluate segmentation results on a common basis.", "labels": [], "entities": [{"text": "random text segmentation", "start_pos": 36, "end_pos": 60, "type": "TASK", "confidence": 0.7590291698773702}]}], "introductionContent": [{"text": "The creation of e-learning courses is generally a time consuming effort.", "labels": [], "entities": []}, {"text": "However, separating text into topically cohesive segments can help to reduce this effort whenever textual content is already available but not properly structured according to e-learning standards.", "labels": [], "entities": []}, {"text": "Since these segments textually describe the content of learning units, automatic pedagogical annotation algorithms could be applied to categorize them into introductions, descriptions, explanations, examples and other pedagogical meaningful concepts (K..", "labels": [], "entities": []}, {"text": "Course designers generally assume that learning content is composed of small inseparable learning objects at the micro level which in turn are wrapped into Concept Containers (CCs) at the macro level.", "labels": [], "entities": []}, {"text": "This approach is followed, e.g., in the Web-Didactic approach by where CCs correspond to chapters in a book and Knowledge Objects (KOs) correspond to course pages.", "labels": [], "entities": []}, {"text": "To automate the partition of an unstructured text source into appropriate segments for the macro and micro level we applied different text segmentation algorithms (segmenters) on each level.", "labels": [], "entities": []}, {"text": "To evaluate the segmenters in the described scenario, we created a test corpus based on featured Wikipedia articles.", "labels": [], "entities": []}, {"text": "For the macro level we exploit sections from different articles and the corresponding micro structure consists of subsequent paragraphs from these sections.", "labels": [], "entities": []}, {"text": "On the macro level the segmenter TopicTiling (TT) by is used.", "labels": [], "entities": []}, {"text": "It is based on a LDA topic model which we train based on the articles from Wikipedia to extract a predefined number of different topics.", "labels": [], "entities": []}, {"text": "On the micro level, the segmenter BayesSeg (BS) is applied.", "labels": [], "entities": [{"text": "BayesSeg (BS)", "start_pos": 34, "end_pos": 47, "type": "METRIC", "confidence": 0.5729254335165024}]}, {"text": "We achieved overall good results measured in three different metrics over a baseline approach, i.e., a scalable random segmenter, that indicate text segmentation algorithms are ready to be applied to facilitate the creation of e-learning courses.", "labels": [], "entities": [{"text": "text segmentation", "start_pos": 144, "end_pos": 161, "type": "TASK", "confidence": 0.7130604386329651}]}, {"text": "This paper is organized as follows: Section 2 gives an overview of related work on automatic course generation as well as text segmentation applications.", "labels": [], "entities": [{"text": "automatic course generation", "start_pos": 83, "end_pos": 110, "type": "TASK", "confidence": 0.6667814254760742}, {"text": "text segmentation", "start_pos": 122, "end_pos": 139, "type": "TASK", "confidence": 0.7743313610553741}]}, {"text": "In the main sections 3 and 4 we describe our approach and evaluation results on our corpus.", "labels": [], "entities": []}, {"text": "In the last section we summarize the presented findings and give an outlook on further research needed for the automatic generation of e-learning courses.", "labels": [], "entities": []}], "datasetContent": [{"text": "We evaluated TT on the macro dataset without providing the number of boundaries.", "labels": [], "entities": [{"text": "TT", "start_pos": 13, "end_pos": 15, "type": "TASK", "confidence": 0.8118937611579895}, {"text": "macro dataset", "start_pos": 23, "end_pos": 36, "type": "DATASET", "confidence": 0.6887254267930984}]}, {"text": "On the micro dataset we evaluated BS with the expected number of boundaries provided.", "labels": [], "entities": [{"text": "BS", "start_pos": 34, "end_pos": 36, "type": "METRIC", "confidence": 0.9206939935684204}]}, {"text": "We also implemented a scalable random segmenter (RS) to compare TT and BS against some algorithm with interpretable performance.", "labels": [], "entities": []}, {"text": "The interpretation of the values in any metric even with respect to different metrics is very difficult without comparison to another segmenter.", "labels": [], "entities": []}, {"text": "For every true boundary in a document, RS predicts a boundary drawn from a normally distributed set around the true boundary with scalable standard deviation \u03c3.", "labels": [], "entities": [{"text": "RS", "start_pos": 39, "end_pos": 41, "type": "TASK", "confidence": 0.785824179649353}]}, {"text": "Thus smaller values for \u03c3 result in better segmentations because the probability of selecting the true boundary increases, e.g., for \u03c3 = 2, more than 68% of all predicted boundaries are at most 2 sentences away from the true boundary and more than 99% of all predicted boundaries are located within a range of 6 sentences from it.", "labels": [], "entities": []}, {"text": "But whether 6 sentences is a large or small distance should depend on the average topic size.", "labels": [], "entities": []}, {"text": "We therefore relate the performance of RS to the mean number of sentence per topic by defining \u03c3 in percentages of that number as shown in the table below.", "labels": [], "entities": []}, {"text": "Distance from True Boundary:  For the LDA topic model training we used the following default parameters: alpha=0.5, beta=0.1,ntopics=100,niters=1000, twords=20,savestep=100, for details we refer to).", "labels": [], "entities": []}, {"text": "To compare TT's performance for different folds of the macro dataset we optimized the window parameter which has to beset for TT, it specifies the number of sentences to the left and to the right of the current position p between two sentences that are used to calculate the coherence score between these sentences).", "labels": [], "entities": []}, {"text": "The performance for TT has been best with window sizes between 9 and 11 for all metrics as shown in.", "labels": [], "entities": [{"text": "TT", "start_pos": 20, "end_pos": 22, "type": "TASK", "confidence": 0.8729618191719055}]}, {"text": "As expected, higher folds increase TT's overall performance especially with respect to metric b).", "labels": [], "entities": [{"text": "TT", "start_pos": 35, "end_pos": 37, "type": "TASK", "confidence": 0.9108035564422607}]}, {"text": "This is due to the larger training set sizes of the LDA topic model.", "labels": [], "entities": []}, {"text": "In general smaller window sizes increase the number of predicted boundaries.", "labels": [], "entities": []}, {"text": "The optimal window size is between 9 and 11 and we would expect the measures for 5 and 15 to be similar ().", "labels": [], "entities": []}, {"text": "This is only the case for metric b, the metrics wd and pk seem to penalize false positives more than false negatives.", "labels": [], "entities": []}, {"text": "This would be a contradiction to the findings of since they actually found the opposite to be true.", "labels": [], "entities": []}, {"text": "This behaviour is explained by the nonlinear relation between the window parameter and number of predicted boundaries by TT as shown in.", "labels": [], "entities": [{"text": "TT", "start_pos": 121, "end_pos": 123, "type": "METRIC", "confidence": 0.5653831958770752}]}, {"text": "Another important finding is the stability of TT's performance over different window sizes (from 9 to 11).", "labels": [], "entities": [{"text": "TT", "start_pos": 46, "end_pos": 48, "type": "TASK", "confidence": 0.8275449275970459}]}, {"text": "This is important since a very sensitive behaviour would be very difficult to handle for course creators because they would have to estimate this parameter in advance.", "labels": [], "entities": []}, {"text": "For the following detailed evaluation TT window size is set to 9 because of the best overall results with respect to metric band 30-fold cross validation.", "labels": [], "entities": [{"text": "TT window size", "start_pos": 38, "end_pos": 52, "type": "METRIC", "confidence": 0.6681632697582245}]}, {"text": "The detailed performance with respect to metric wd, pk and b of TT compared to RS with different standard deviations \u03c3 is shown in, ii) and iii). i. TT measured with metric b.", "labels": [], "entities": [{"text": "TT", "start_pos": 149, "end_pos": 151, "type": "TASK", "confidence": 0.7460533380508423}]}, {"text": "TT measured with metric wd. iii.", "labels": [], "entities": [{"text": "TT", "start_pos": 0, "end_pos": 2, "type": "DATASET", "confidence": 0.4880637228488922}]}, {"text": "TT measured with metric pk.", "labels": [], "entities": [{"text": "TT", "start_pos": 0, "end_pos": 2, "type": "METRIC", "confidence": 0.5639670491218567}]}, {"text": "First of all we want to point out that the graphs of RS for different values of \u03c3 are ordered as expected by all metrics.", "labels": [], "entities": []}, {"text": "Lower percentages indicate better results.", "labels": [], "entities": []}, {"text": "And with respect to metric wd and pk the performance for each \u03c3 is nearly constant overall subsets, which indicates that the metrics correctly consider the relative distance of a predicted boundary from the true boundary by using the mean number of sentences per topic.", "labels": [], "entities": []}, {"text": "In metric b only the RS with \u03c3=30%, 15% and 5% are constant.", "labels": [], "entities": [{"text": "RS", "start_pos": 21, "end_pos": 23, "type": "METRIC", "confidence": 0.9913358688354492}]}, {"text": "For \u03c3=5% there is a strong decrease in performance for subsets with more sentences per topic.", "labels": [], "entities": []}, {"text": "The overall performance of TT is between that of RS for \u03c3=1% and \u03c3=15%, except for subset 7_6 with respect to metric wd.", "labels": [], "entities": [{"text": "TT", "start_pos": 27, "end_pos": 29, "type": "TASK", "confidence": 0.7627617120742798}]}, {"text": "With respect to metric b TT even predicts very close boundaries.", "labels": [], "entities": []}, {"text": "In all metrics TT has the worst results on subset 7_6, which has the largest number of sentences per topic (see).", "labels": [], "entities": [{"text": "TT", "start_pos": 15, "end_pos": 17, "type": "TASK", "confidence": 0.8649998903274536}]}, {"text": "This is due to TT's window parameter which influences the number of predicted boundaries as shown in.", "labels": [], "entities": [{"text": "TT", "start_pos": 15, "end_pos": 17, "type": "METRIC", "confidence": 0.45831209421157837}]}, {"text": "BS does not need any training or parameter fitting, since it is provided with the number of expected segments.", "labels": [], "entities": [{"text": "BS", "start_pos": 0, "end_pos": 2, "type": "TASK", "confidence": 0.8535671830177307}, {"text": "parameter fitting", "start_pos": 33, "end_pos": 50, "type": "TASK", "confidence": 0.7317975461483002}]}, {"text": "We therefore used the default parameter settings.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Macro dataset and its subsets each with  200 samples.", "labels": [], "entities": [{"text": "Macro dataset", "start_pos": 10, "end_pos": 23, "type": "DATASET", "confidence": 0.6484384536743164}]}, {"text": " Table 2: Micro dataset and its subsets.", "labels": [], "entities": [{"text": "Micro dataset", "start_pos": 10, "end_pos": 23, "type": "DATASET", "confidence": 0.8629579842090607}]}, {"text": " Table 3: Mean size and standard deviation of  truly disjunctive LDA training and respective TT  testing set.", "labels": [], "entities": [{"text": "Mean size", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9488008320331573}]}]}