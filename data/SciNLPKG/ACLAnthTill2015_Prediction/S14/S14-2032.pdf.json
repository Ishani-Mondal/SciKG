{"title": [{"text": "COMMIT-P1WP3: A Co-occurrence Based Approach to Aspect-Level Sentiment Analysis", "labels": [], "entities": [{"text": "COMMIT-P1WP3", "start_pos": 0, "end_pos": 12, "type": "DATASET", "confidence": 0.8932294249534607}, {"text": "Aspect-Level Sentiment Analysis", "start_pos": 48, "end_pos": 79, "type": "TASK", "confidence": 0.677329828341802}]}], "abstractContent": [{"text": "In this paper, the crucial ingredients for our submission to SemEval-2014 Task 4 \"Aspect Level Sentiment Analysis\" are discussed.", "labels": [], "entities": [{"text": "SemEval-2014 Task 4", "start_pos": 61, "end_pos": 80, "type": "TASK", "confidence": 0.7929873069127401}, {"text": "Aspect Level Sentiment Analysis", "start_pos": 82, "end_pos": 113, "type": "TASK", "confidence": 0.7151457890868187}]}, {"text": "We present a simple aspect detection algorithm, a co-occurrence based method for category detection and a dictionary based sentiment classification algorithm.", "labels": [], "entities": [{"text": "aspect detection", "start_pos": 20, "end_pos": 36, "type": "TASK", "confidence": 0.8728474378585815}, {"text": "category detection", "start_pos": 81, "end_pos": 99, "type": "TASK", "confidence": 0.8385185301303864}, {"text": "sentiment classification", "start_pos": 123, "end_pos": 147, "type": "TASK", "confidence": 0.7559177279472351}]}, {"text": "The dictionary for the latter is based on co-occurrences as well.", "labels": [], "entities": []}, {"text": "The failure analysis and related work section focus mainly on the category detection method as it is most distinctive for our work.", "labels": [], "entities": [{"text": "failure analysis", "start_pos": 4, "end_pos": 20, "type": "TASK", "confidence": 0.7203497141599655}, {"text": "category detection", "start_pos": 66, "end_pos": 84, "type": "TASK", "confidence": 0.8570608496665955}]}], "introductionContent": [{"text": "In recent years, sentiment analysis has taken flight and is now actively used, on the Web and beyond (.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 17, "end_pos": 35, "type": "TASK", "confidence": 0.9751479029655457}]}, {"text": "To provide users of sentiment tools with more detailed and useful information, a number of innovations have been introduced, and among others a switch from document-level sentiment analysis towards fine-grained, aspect-level sentiment analysis can be seen.", "labels": [], "entities": [{"text": "document-level sentiment analysis", "start_pos": 156, "end_pos": 189, "type": "TASK", "confidence": 0.6240657567977905}, {"text": "aspect-level sentiment analysis", "start_pos": 212, "end_pos": 243, "type": "TASK", "confidence": 0.6480071743329366}]}, {"text": "In line with the many challenges associated with this, SemEval-2014 Task 4 \"Aspect Level Sentiment Analysis\" () is split into four sub-tasks: Aspect Detection, Aspect Sentiment Classification, Category Detection, and Category Sentiment Classification.", "labels": [], "entities": [{"text": "Aspect Level Sentiment Analysis", "start_pos": 76, "end_pos": 107, "type": "TASK", "confidence": 0.5773454308509827}, {"text": "Aspect Sentiment Classification", "start_pos": 160, "end_pos": 191, "type": "TASK", "confidence": 0.5610903799533844}, {"text": "Category Detection", "start_pos": 193, "end_pos": 211, "type": "TASK", "confidence": 0.661522850394249}, {"text": "Category Sentiment Classification", "start_pos": 217, "end_pos": 250, "type": "TASK", "confidence": 0.6645490229129791}]}, {"text": "The main focus of this paper is on the category detection algorithm we developed, but a method for aspect detection and a sentiment classification algorithm (both for aspects and categories) are also included.", "labels": [], "entities": [{"text": "category detection", "start_pos": 39, "end_pos": 57, "type": "TASK", "confidence": 0.8064777851104736}, {"text": "aspect detection", "start_pos": 99, "end_pos": 115, "type": "TASK", "confidence": 0.8591835796833038}, {"text": "sentiment classification", "start_pos": 122, "end_pos": 146, "type": "TASK", "confidence": 0.7731128036975861}]}, {"text": "The aspect detection algorithm will be presented first, followed by the category detection algorithm and the sentiment classification method.", "labels": [], "entities": [{"text": "aspect detection", "start_pos": 4, "end_pos": 20, "type": "TASK", "confidence": 0.8795296251773834}, {"text": "category detection", "start_pos": 72, "end_pos": 90, "type": "TASK", "confidence": 0.8089080452919006}, {"text": "sentiment classification", "start_pos": 109, "end_pos": 133, "type": "TASK", "confidence": 0.9219033122062683}]}, {"text": "Next, the benchmark results for all algorithms are presented, plus a discussion and failure analysis of the category detection method.", "labels": [], "entities": [{"text": "category detection", "start_pos": 108, "end_pos": 126, "type": "TASK", "confidence": 0.717345267534256}]}, {"text": "Finally, conclusions are drawn and some suggestions for future work are presented.", "labels": [], "entities": []}], "datasetContent": [{"text": "All three algorithms presented above were evaluated through a submission in the SemEval-2014 Task 4 \"Aspect Level Sentiment Analysis\".", "labels": [], "entities": [{"text": "SemEval-2014 Task 4 \"Aspect Level Sentiment Analysis", "start_pos": 80, "end_pos": 132, "type": "TASK", "confidence": 0.735790841281414}]}, {"text": "Two data sets have been used, one consisting of sentences from restaurant reviews, the other consisting of sentences from laptop reviews.", "labels": [], "entities": []}, {"text": "Both sets have been annotated with aspects and aspect sentiment, but only the restaurant set is also annotated with aspect categories and their associated sentiment class.", "labels": [], "entities": []}, {"text": "Both data sets are split into a training set of roughly 3000 sentences and a test set of 800 sentences.", "labels": [], "entities": []}, {"text": "All sentences in the data set have been preprocessed by a tokenizer, a Part-of-Speech tagger, and a lemmatizer.", "labels": [], "entities": []}, {"text": "These tasks were performed by . Furthermore, the OpenNLP 2 chunker was used to provide basic phrase chunking in order to retrieve noun phrases for instance.", "labels": [], "entities": [{"text": "OpenNLP 2 chunker", "start_pos": 49, "end_pos": 66, "type": "DATASET", "confidence": 0.8451236883799235}, {"text": "phrase chunking", "start_pos": 93, "end_pos": 108, "type": "TASK", "confidence": 0.7237896919250488}]}, {"text": "The official scores, as computed by the task organizers are shown in.", "labels": [], "entities": []}, {"text": "Note that the sentiment classification algorithm is used for subtasks 2 and 4, so two scores are reported, and that subtasks 3 and 4 can only be performed with the restaurant data set.", "labels": [], "entities": [{"text": "sentiment classification", "start_pos": 14, "end_pos": 38, "type": "TASK", "confidence": 0.9395139217376709}, {"text": "restaurant data set", "start_pos": 164, "end_pos": 183, "type": "DATASET", "confidence": 0.7775998910268148}]}, {"text": "As the performance of the category detection method was lower than anticipated, a failure analysis has been performed.", "labels": [], "entities": [{"text": "category detection", "start_pos": 26, "end_pos": 44, "type": "TASK", "confidence": 0.8880459666252136}]}, {"text": "This led to the observation that overfitting is one of major factors in explaining the lower performance . This is shown in, in which one can easily notice the great difference in in-sample performance, and the performance on unseen data.", "labels": [], "entities": []}, {"text": "Notice that by using 10-fold cross-validation, better results are achieved than on the official test set.", "labels": [], "entities": []}, {"text": "This indicates that there are factors other than overfitting that influence the performance.", "labels": [], "entities": []}, {"text": "Interestingly, especially recall is influenced by the overfitting problem: precision is almost the same for the 10-fold cross-validation and even with the in-sample performance it increases only a little bit.", "labels": [], "entities": [{"text": "recall", "start_pos": 26, "end_pos": 32, "type": "METRIC", "confidence": 0.998471200466156}, {"text": "precision", "start_pos": 75, "end_pos": 84, "type": "METRIC", "confidence": 0.9996621608734131}]}, {"text": "To gain more insight into the difference in recall, a graph showing the relative contribution to false negatives of the five categories is shown in.", "labels": [], "entities": [{"text": "recall", "start_pos": 44, "end_pos": 50, "type": "METRIC", "confidence": 0.9979910850524902}]}, {"text": "For completeness, the same graph but for false positives is also shown, together with the frequency distribution of the categories in both training and test set.", "labels": [], "entities": []}, {"text": "Immediately visible is the effect of defaulting to the 'anecdotes/miscellaneous' when no category is assigned to that sentence: many false positives are generated by this rule, but there are almost no false negatives for this category.", "labels": [], "entities": []}, {"text": "Note that without this default, F 1 -measure would drop by roughly 3 percentage points.", "labels": [], "entities": [{"text": "F 1 -measure", "start_pos": 32, "end_pos": 44, "type": "METRIC", "confidence": 0.97551229596138}]}, {"text": "Also notable is the difference between the insample bar and the official results bar: two categories, namely 'anecdotes/miscellaneous' and 'food' show large differences in contribution to false positives and false negatives.", "labels": [], "entities": []}, {"text": "The algorithm finds fewer 'food' categories in the test set, than in the training set, while for 'anecdotes/miscellaneous', the reverse is the case.", "labels": [], "entities": []}, {"text": "This can at least be partly explained by the change in data statistics: in the training set, 33% of the annotated categories are 'food' and 30% are 'anecdotes/miscellaneous', whereas in the test set, these numbers are 40% and 22%, respectively.", "labels": [], "entities": []}, {"text": "With much more sentences having the 'food' category, false positives will be lower but false negatives will be higher.", "labels": [], "entities": []}, {"text": "For 'anecdotes/miscellaneous', the reverse is true: with less sentences in the test set having this category, false positives will by higher, but false negatives will be lower, a change reinforced by 'anecdotes/miscellaneous' being the default.", "labels": [], "entities": []}, {"text": "Two factors remain that might have negatively impacted the performance of the algorithm.", "labels": [], "entities": []}, {"text": "The first is that in the restaurant set, many words appear only once (e.g., dishes, ingredients), and when words do not appear in the training set, no co-occurrence with any category can be recorded.", "labels": [], "entities": []}, {"text": "The second is that the category thresholds, while working well on the training set, do not seem to generalize well to the test set.", "labels": [], "entities": []}, {"text": "Testing the algorithm with one threshold for all five categories, while showing a sharply decreased in-sample performance, yields an out-ofsample F 1 -measure that is only slightly lower than F 1 -measure with different thresholds.", "labels": [], "entities": [{"text": "F 1 -measure", "start_pos": 146, "end_pos": 158, "type": "METRIC", "confidence": 0.8247784376144409}, {"text": "F 1 -measure", "start_pos": 192, "end_pos": 204, "type": "METRIC", "confidence": 0.9364439845085144}]}], "tableCaptions": [{"text": " Table 1: Official results for both algorithms.  aspect detection (subtask 1)  precision recall  F 1  laptop  0.836  0.148  0.252  restaurant  0.909  0.388  0.544  category detection (subtask 3)  precision recall  F 1  restaurant  0.633  0.558  0.593  aspect sentiment classification (subtask 2)  laptop  accuracy 0.570  restaurant accuracy 0.660  category sentiment classification (subtask 4)  restaurant accuracy 0.677", "labels": [], "entities": [{"text": "precision recall", "start_pos": 79, "end_pos": 95, "type": "METRIC", "confidence": 0.9400323033332825}, {"text": "precision recall", "start_pos": 196, "end_pos": 212, "type": "METRIC", "confidence": 0.9353311955928802}, {"text": "accuracy 0.570  restaurant accuracy", "start_pos": 305, "end_pos": 340, "type": "METRIC", "confidence": 0.7927397042512894}, {"text": "restaurant accuracy 0.677", "start_pos": 395, "end_pos": 420, "type": "METRIC", "confidence": 0.6269257863362631}]}]}