{"title": [{"text": "Turku: Broad-Coverage Semantic Parsing with Rich Features", "labels": [], "entities": [{"text": "Broad-Coverage Semantic Parsing", "start_pos": 7, "end_pos": 38, "type": "TASK", "confidence": 0.6911506851514181}]}], "abstractContent": [{"text": "In this paper we introduce our system capable of producing semantic parses of sentences using three different annotation formats.", "labels": [], "entities": []}, {"text": "The system was used to participate in the SemEval-2014 Shared Task on broad-coverage semantic dependency parsing and it was ranked third with an overall F 1-score of 80.49%.", "labels": [], "entities": [{"text": "SemEval-2014 Shared Task", "start_pos": 42, "end_pos": 66, "type": "TASK", "confidence": 0.7591759959856669}, {"text": "broad-coverage semantic dependency parsing", "start_pos": 70, "end_pos": 112, "type": "TASK", "confidence": 0.735871709883213}, {"text": "F 1-score", "start_pos": 153, "end_pos": 162, "type": "METRIC", "confidence": 0.9881037771701813}]}, {"text": "The system has a pipeline architecture, consisting of three separate supervised classification steps.", "labels": [], "entities": []}], "introductionContent": [{"text": "In the SemEval-2014 Task 8 on semantic parsing, the objective is to extract for each sentence a rich set of typed semantic dependencies in three different formats: DM, PAS and PCEDT.", "labels": [], "entities": [{"text": "SemEval-2014 Task 8 on semantic parsing", "start_pos": 7, "end_pos": 46, "type": "TASK", "confidence": 0.7202724715073904}, {"text": "PAS", "start_pos": 168, "end_pos": 171, "type": "METRIC", "confidence": 0.9360038638114929}]}, {"text": "These formats differ substantially both in the assignment of semantic heads as well as in the lexicon of semantic dependency types.", "labels": [], "entities": []}, {"text": "In the open track of the shared task, participants were encouraged to use all resources and tools also beyond the provided training data.", "labels": [], "entities": []}, {"text": "To improve the comparability of the systems, the organizers provided ready-to-use dependency parses produced using the state-of-theart parser of.", "labels": [], "entities": []}, {"text": "In this paper we describe our entry in the open track of the shared task.", "labels": [], "entities": []}, {"text": "Our system is a pipeline of three support vector machine classifiers trained separately for detecting semantic dependencies, assigning their roles, and selecting the top nodes of semantic graphs.", "labels": [], "entities": []}, {"text": "In this, we loosely follow the architecture of e.g. the TEES () and EventMine () systems, which were found to be effective in the structurally * These authors contributed equally.", "labels": [], "entities": []}, {"text": "This work is licenced under a Creative Commons Attribution 4.0 International License.", "labels": [], "entities": []}, {"text": "Page numbers and proceedings footer are added by the organizers.", "labels": [], "entities": []}, {"text": "License details: http: //creativecommons.org/licenses/by/4.0/ related task of biomedical event extraction.", "labels": [], "entities": [{"text": "biomedical event extraction", "start_pos": 78, "end_pos": 105, "type": "TASK", "confidence": 0.6906540989875793}]}, {"text": "Similar classification approach is shown to be effective also in semantic parsing by e.g., the winner of the CoNLL'09 Shared Task on Syntactic and Semantic Dependencies in Multiple Languages (SRL-only subtask), where semantic parsing is approached as a word-pair classification problem and semantic arguments and their roles are predicted simultaneously.", "labels": [], "entities": [{"text": "semantic parsing", "start_pos": 65, "end_pos": 81, "type": "TASK", "confidence": 0.7299839407205582}, {"text": "CoNLL'09 Shared Task on Syntactic and Semantic Dependencies in Multiple Languages (SRL-only subtask)", "start_pos": 109, "end_pos": 209, "type": "TASK", "confidence": 0.697273071606954}, {"text": "semantic parsing", "start_pos": 217, "end_pos": 233, "type": "TASK", "confidence": 0.7611828446388245}, {"text": "word-pair classification", "start_pos": 253, "end_pos": 277, "type": "TASK", "confidence": 0.7178237289190292}]}, {"text": "In preliminary experiments, we also developed a joint approach to simultaneously identify semantic dependencies and assign their roles, but found that the performance of the joint prediction was substantially worse than for the current pipeline approach.", "labels": [], "entities": []}, {"text": "As the source of features, we rely heavily on the syntactic parses as well as other external resources such as vector space representations of words and large-scale syntactic n-gram statistics.", "labels": [], "entities": []}, {"text": "In the following sections, we describe the three individual classification steps of our semantic parsing pipeline.", "labels": [], "entities": [{"text": "semantic parsing pipeline", "start_pos": 88, "end_pos": 113, "type": "TASK", "confidence": 0.7761466304461161}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 2: Overall scores of whole task as well as  separately for each annotation format in terms of  labeled precision (LP), recall (LR) and F 1 -score  (LF) as well as unlabeled F 1 -score (UF).", "labels": [], "entities": [{"text": "labeled precision (LP)", "start_pos": 102, "end_pos": 124, "type": "METRIC", "confidence": 0.8518017768859864}, {"text": "recall (LR)", "start_pos": 126, "end_pos": 137, "type": "METRIC", "confidence": 0.9552924484014511}, {"text": "F 1 -score  (LF)", "start_pos": 142, "end_pos": 158, "type": "METRIC", "confidence": 0.9636533686092922}, {"text": "F 1 -score (UF)", "start_pos": 180, "end_pos": 195, "type": "METRIC", "confidence": 0.9621464099202838}]}]}