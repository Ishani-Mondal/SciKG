{"title": [{"text": "UKPDIPF: A Lexical Semantic Approach to Sentiment Polarity Prediction in Twitter Data", "labels": [], "entities": [{"text": "UKPDIPF", "start_pos": 0, "end_pos": 7, "type": "DATASET", "confidence": 0.9712058305740356}, {"text": "Sentiment Polarity Prediction", "start_pos": 40, "end_pos": 69, "type": "TASK", "confidence": 0.9239230354626974}]}], "abstractContent": [{"text": "We present a sentiment classification system that participated in the SemEval 2014 shared task on sentiment analysis in Twit-ter.", "labels": [], "entities": [{"text": "sentiment classification", "start_pos": 13, "end_pos": 37, "type": "TASK", "confidence": 0.8894089460372925}, {"text": "SemEval 2014 shared task on sentiment analysis", "start_pos": 70, "end_pos": 116, "type": "TASK", "confidence": 0.6714580569948468}, {"text": "Twit-ter", "start_pos": 120, "end_pos": 128, "type": "DATASET", "confidence": 0.7221652865409851}]}, {"text": "Our system expands tokens in a tweet with semantically similar expressions using a large novel distributional thesaurus and calculates the semantic relatedness of the expanded tweets to word lists representing positive and negative sentiment.", "labels": [], "entities": []}, {"text": "This approach helps to assess the polarity of tweets that do not directly contain polarity cues.", "labels": [], "entities": []}, {"text": "Moreover, we incorporate syntactic , lexical and surface sentiment features.", "labels": [], "entities": []}, {"text": "On the message level, our system achieved the 8th place in terms of macro-averaged F-score among 50 systems, with particularly good performance on the Life-Journal corpus (F 1 =71.92) and the Twitter sarcasm (F 1 =54.59) dataset.", "labels": [], "entities": [{"text": "F-score", "start_pos": 83, "end_pos": 90, "type": "METRIC", "confidence": 0.9315182566642761}, {"text": "Life-Journal corpus", "start_pos": 151, "end_pos": 170, "type": "DATASET", "confidence": 0.9386127889156342}, {"text": "F 1 =71.92)", "start_pos": 172, "end_pos": 183, "type": "METRIC", "confidence": 0.8572221159934997}, {"text": "Twitter sarcasm (F 1 =", "start_pos": 192, "end_pos": 214, "type": "METRIC", "confidence": 0.6131871392329534}]}, {"text": "On the expression level, our system ranked 14 out of 27 systems, based on macro-averaged F-score.", "labels": [], "entities": [{"text": "F-score", "start_pos": 89, "end_pos": 96, "type": "METRIC", "confidence": 0.9502676129341125}]}], "introductionContent": [{"text": "Microblogging sites, such as Twitter, have become an important source of information about current events.", "labels": [], "entities": []}, {"text": "The fact that users write about their experiences, often directly during or shortly after an event, contributes to the high level of emotions in many such messages.", "labels": [], "entities": []}, {"text": "Being able to automatically and reliably evaluate these emotions in context of a specific event or a product would be highly beneficial not only in marketing) or public relations, but also in political sciences, disaster manageThis work is licensed under a Creative Commons Attribution 4.0 International Licence.", "labels": [], "entities": []}, {"text": "Page numbers and proceedings footer are added by the organisers.", "labels": [], "entities": []}, {"text": "Licence details: http://creativecommons.org/licenses/by/4.0/ ment, stock market analysis or the health sector.", "labels": [], "entities": []}, {"text": "Due to its large number of applications, sentiment analysis on Twitter is a very popular task.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 41, "end_pos": 59, "type": "TASK", "confidence": 0.9671048223972321}]}, {"text": "Challenges arise both from the character of the task and from the language specifics of Twitter messages.", "labels": [], "entities": []}, {"text": "Messages are normally very short and informal, frequently using slang, alternative spelling, neologism and links, and mostly ignoring the punctuation.", "labels": [], "entities": []}, {"text": "Our experiments have been carried out as part of the SemEval 2014 Task 9 -Sentiment Analysis on Twitter (), a rerun of a).", "labels": [], "entities": [{"text": "SemEval 2014 Task 9 -Sentiment Analysis", "start_pos": 53, "end_pos": 92, "type": "TASK", "confidence": 0.7745731728417533}]}, {"text": "The datasets are thus described in detail in the overview papers.", "labels": [], "entities": []}, {"text": "The rerun uses the same training and development data, but new test data from Twitter and a \"surprise domain\".", "labels": [], "entities": []}, {"text": "The task consists of two subtasks: an expression-level subtask (Subtask A) and a message-level subtask (Subtask B).", "labels": [], "entities": []}, {"text": "In subtask A, each tweet in a corpus contained a marked instance of a word or phrase.", "labels": [], "entities": []}, {"text": "The goal is to determine whether that instance is positive, negative or neutral in that context.", "labels": [], "entities": []}, {"text": "In subtask B, the goal is to classify whether the entire message is of positive, negative, or neutral sentiment.", "labels": [], "entities": []}, {"text": "For messages conveying both a positive and negative sentiment, the stronger one should be chosen.", "labels": [], "entities": []}, {"text": "The key components of our system are the sentiment polarity lexicons.", "labels": [], "entities": [{"text": "sentiment polarity lexicons", "start_pos": 41, "end_pos": 68, "type": "TASK", "confidence": 0.789419949054718}]}, {"text": "In contrast to previous approaches, we do not only count exact lexicon hits, but also calculate explicit semantic relatedness ( between the tweet and the sentiment list, benefiting from resources such as Wiktionary and WordNet.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 219, "end_pos": 226, "type": "DATASET", "confidence": 0.9452064633369446}]}, {"text": "On top of that, we expand content words (adjectives, adverbs, nouns and verbs) in the tweet with similar words, which we derive from a novel corpus of more than 80 million English Tweets gathered by the Language Technology group 1 at TU Darm-stadt.", "labels": [], "entities": [{"text": "TU Darm-stadt", "start_pos": 234, "end_pos": 247, "type": "DATASET", "confidence": 0.7262624204158783}]}], "datasetContent": [{"text": "Our experimental setup is based on an open-source text classification framework DKPro TC 2, which allows to combine NLP pipelines into a configurable and modular system for preprocessing, feature extraction and classification.", "labels": [], "entities": [{"text": "DKPro TC 2", "start_pos": 80, "end_pos": 90, "type": "DATASET", "confidence": 0.7304781675338745}, {"text": "feature extraction", "start_pos": 188, "end_pos": 206, "type": "TASK", "confidence": 0.7267719805240631}]}, {"text": "We use the unit classification mode of DKPro TC for Subtask A and the document classification mode for Subtask B.", "labels": [], "entities": [{"text": "DKPro TC", "start_pos": 39, "end_pos": 47, "type": "DATASET", "confidence": 0.8935551643371582}, {"text": "document classification", "start_pos": 70, "end_pos": 93, "type": "TASK", "confidence": 0.6313778609037399}]}], "tableCaptions": [{"text": " Table 1: Unsupervised expansion of 'awesome'", "labels": [], "entities": []}, {"text": " Table 3: Performance increase where feature  added to the full setup", "labels": [], "entities": []}]}