{"title": [{"text": "V3: Unsupervised Generation of Domain Aspect Terms for Aspect Based Sentiment Analysis", "labels": [], "entities": [{"text": "Aspect Based Sentiment Analysis", "start_pos": 55, "end_pos": 86, "type": "TASK", "confidence": 0.6424359753727913}]}], "abstractContent": [{"text": "This paper presents V3, an unsupervised system for aspect-based Sentiment Analysis when evaluated on the SemEval 2014 Task 4.", "labels": [], "entities": [{"text": "Sentiment Analysis", "start_pos": 64, "end_pos": 82, "type": "TASK", "confidence": 0.874961793422699}, {"text": "SemEval 2014 Task 4", "start_pos": 105, "end_pos": 124, "type": "TASK", "confidence": 0.6634960398077965}]}, {"text": "V3 focuses on generating a list of aspect terms fora new domain using a collection of raw texts from the domain.", "labels": [], "entities": [{"text": "V3", "start_pos": 0, "end_pos": 2, "type": "DATASET", "confidence": 0.8678586483001709}]}, {"text": "We also implement a very basic approach to classify the aspect terms into categories and assign polarities to them.", "labels": [], "entities": []}], "introductionContent": [{"text": "The automatic analysis of opinions, within the framework of opinion mining or sentiment analysis, has gained a huge importance during the last decade due to the amount of review web sites, blogs and social networks producing everyday a massive amount of new content).", "labels": [], "entities": [{"text": "automatic analysis of opinions", "start_pos": 4, "end_pos": 34, "type": "TASK", "confidence": 0.7450576573610306}, {"text": "opinion mining or sentiment analysis", "start_pos": 60, "end_pos": 96, "type": "TASK", "confidence": 0.7199181139469146}]}, {"text": "This content usually contains opinions about different entities, products or services.", "labels": [], "entities": []}, {"text": "Trying to cope with this large amounts of textual data is unfeasible without the help of automatic Opinion Mining tools which try to detect, identify, classify, aggregate and summarize the opinions expressed about different topics () () () (.", "labels": [], "entities": []}, {"text": "In this framework, aspect based opinion mining systems aim to detect the sentiment at \"aspect\" level (i.e. the precise feature being opinionated in a clause or sentence).", "labels": [], "entities": [{"text": "aspect based opinion mining", "start_pos": 19, "end_pos": 46, "type": "TASK", "confidence": 0.6093848347663879}]}, {"text": "In this paper we describe our system presented in the SemEval 2014 task 4 1 Aspect Based Sentiment Analysis (, which focuses on detecting opinionated aspect terms (e.g. wine list and menu in restaurant domain, and hard disk and battery life in laptop domain), their categories and polarities in customer review sentences.", "labels": [], "entities": [{"text": "SemEval 2014 task 4 1 Aspect Based Sentiment Analysis", "start_pos": 54, "end_pos": 107, "type": "TASK", "confidence": 0.670718080467648}]}, {"text": "The task provides two training datasets, one of restaurant reviews and other of laptop reviews.", "labels": [], "entities": []}, {"text": "The restaurant review dataset consists of over 3,000 English sentences from restaurant reviews borrowed from ().", "labels": [], "entities": [{"text": "restaurant review dataset", "start_pos": 4, "end_pos": 29, "type": "DATASET", "confidence": 0.6099853416283926}]}, {"text": "The laptop review dataset consists of over 3,000 English sentences extracted from customer reviews.", "labels": [], "entities": [{"text": "laptop review dataset", "start_pos": 4, "end_pos": 25, "type": "DATASET", "confidence": 0.7615574995676676}]}, {"text": "The task is divided in four different subtasks: subtask 1 aspect term extraction, subtask 2 aspect term polarity detection, subtask 3 aspect category detection, subtask 4 aspect category polarity detection.", "labels": [], "entities": [{"text": "aspect term extraction", "start_pos": 58, "end_pos": 80, "type": "TASK", "confidence": 0.6478013197580973}, {"text": "aspect term polarity detection", "start_pos": 92, "end_pos": 122, "type": "TASK", "confidence": 0.6312751173973083}, {"text": "aspect category detection", "start_pos": 134, "end_pos": 159, "type": "TASK", "confidence": 0.697118212779363}, {"text": "aspect category polarity detection", "start_pos": 171, "end_pos": 205, "type": "TASK", "confidence": 0.702616423368454}]}, {"text": "Our system mainly focused on subtask 1, but we have also participated in the other subtasks.", "labels": [], "entities": []}, {"text": "The paper is organized as follows: section 2 presents our approach, section 3 details the improvement methods used for the aspects term selection and section 4 focus on category and polarity tagging.", "labels": [], "entities": [{"text": "term selection", "start_pos": 131, "end_pos": 145, "type": "TASK", "confidence": 0.7370336651802063}, {"text": "category and polarity tagging", "start_pos": 169, "end_pos": 198, "type": "TASK", "confidence": 0.645305223762989}]}, {"text": "Finally section 5 presents the results obtained and section 6 draws the conclusions and future work.", "labels": [], "entities": []}], "datasetContent": [{"text": "The run submitted to the SemEval task 4 competition was based on 25k unlabelled sentences extracted from domain related reviews (for restaurants and laptops) obtained by scraping different websites.", "labels": [], "entities": [{"text": "SemEval task 4 competition", "start_pos": 25, "end_pos": 51, "type": "TASK", "confidence": 0.904609352350235}]}, {"text": "We used these unlabelled sentences to execute our unsupervised system to generate and   rank the aspect term lists.", "labels": [], "entities": []}, {"text": "Then we used those aspect term lists to annotate the sentences using a simple lemma matching approach between the words.", "labels": [], "entities": []}, {"text": "The generated aspect term lists were limited to the first ranked 550 items after some initial experiments with the SemEval training sets.", "labels": [], "entities": [{"text": "SemEval training sets", "start_pos": 115, "end_pos": 136, "type": "DATASET", "confidence": 0.8144819736480713}]}, {"text": "The SemEval test datasets (restaurants and laptops) contain about 800 sentences each.", "labels": [], "entities": [{"text": "SemEval test datasets", "start_pos": 4, "end_pos": 25, "type": "DATASET", "confidence": 0.8030896385510763}]}, {"text": "The restaurant dataset contains 1,134 labelled gold aspect term spans, and the laptop dataset contains 634 labelled gold aspect term spans.", "labels": [], "entities": [{"text": "restaurant dataset", "start_pos": 4, "end_pos": 22, "type": "DATASET", "confidence": 0.7276104688644409}, {"text": "laptop dataset", "start_pos": 79, "end_pos": 93, "type": "DATASET", "confidence": 0.9757552146911621}]}, {"text": "We compare the results against the SemEval baseline which is calculated using the scripts provided by the SemEval organizers.", "labels": [], "entities": [{"text": "SemEval baseline", "start_pos": 35, "end_pos": 51, "type": "DATASET", "confidence": 0.7895574569702148}]}, {"text": "This baseline splits the dataset into train and test subsets, and uses all the labelled aspect terms in the train subset to build a dictionary of aspect terms.", "labels": [], "entities": []}, {"text": "Then it simply uses that dictionary to label the test subset for evaluation.", "labels": [], "entities": []}, {"text": "show the performance of our system with respect to the baselines in both datasets.", "labels": [], "entities": []}, {"text": "\"V3 (S)\" stands for our system only using the SemEval test data (as our approach is unsupervised it learns from the available texts for the task).", "labels": [], "entities": [{"text": "SemEval test data", "start_pos": 46, "end_pos": 63, "type": "DATASET", "confidence": 0.7705500821272532}]}, {"text": "(W) refers to the results using our own dataset scraped from the Web.", "labels": [], "entities": []}, {"text": "Finally (W+S) refers to the results using both SemEval and our Web dataset mixed together.", "labels": [], "entities": []}, {"text": "The best results are highlighted in bold.", "labels": [], "entities": []}, {"text": "For subtask 1, although our system outperforms the baseline in terms of F-score in both datasets, in the competition our system obtained quite modest results ranking 24th and 26th out of 29 participants: Results for the polarity classification subtasks (subtasks 2 and 4).", "labels": [], "entities": [{"text": "F-score", "start_pos": 72, "end_pos": 79, "type": "METRIC", "confidence": 0.9983170032501221}]}, {"text": "for restaurants and laptops respectively.", "labels": [], "entities": []}, {"text": "One of the most important source of errors are the multiword aspect term detection.", "labels": [], "entities": [{"text": "multiword aspect term detection", "start_pos": 51, "end_pos": 82, "type": "TASK", "confidence": 0.7244222313165665}]}, {"text": "In the SemEval datasets, about the 25% of the gold aspect terms are multiword terms.", "labels": [], "entities": [{"text": "SemEval datasets", "start_pos": 7, "end_pos": 23, "type": "DATASET", "confidence": 0.7862496674060822}]}, {"text": "In both datasets we find a large number of names of recipes and meals, composed by two, three or even more words, which cannot appear in our aspect term lists because we limit the multiword length up to two words.", "labels": [], "entities": []}, {"text": "As mentioned in the introduction our approach focuses mainly in the aspects so the approach for detecting categories and polarities needs more attention.", "labels": [], "entities": [{"text": "detecting categories and polarities", "start_pos": 96, "end_pos": 131, "type": "TASK", "confidence": 0.8377551734447479}]}, {"text": "presents our results on category detection and table 5 our results on polarities.", "labels": [], "entities": [{"text": "category detection", "start_pos": 24, "end_pos": 42, "type": "TASK", "confidence": 0.8424392342567444}]}, {"text": "The results are quite poor so we do not comment on them here.", "labels": [], "entities": []}, {"text": "We will address these subtasks in future work.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Results on the restaurant review test set.", "labels": [], "entities": [{"text": "restaurant review test set", "start_pos": 25, "end_pos": 51, "type": "DATASET", "confidence": 0.671667218208313}]}, {"text": " Table 3: Results on the laptop review test set.", "labels": [], "entities": [{"text": "laptop review test set", "start_pos": 25, "end_pos": 47, "type": "DATASET", "confidence": 0.8487125039100647}]}, {"text": " Table 4: Results on restaurant category detection  using the test set.", "labels": [], "entities": [{"text": "restaurant category detection", "start_pos": 21, "end_pos": 50, "type": "TASK", "confidence": 0.645576149225235}]}, {"text": " Table 5: Results for the polarity classification sub- tasks (subtasks 2 and 4).", "labels": [], "entities": [{"text": "polarity classification", "start_pos": 26, "end_pos": 49, "type": "TASK", "confidence": 0.7536753714084625}]}]}