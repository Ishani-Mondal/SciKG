{"title": [{"text": "GPLSI: Supervised Sentiment Analysis in Twitter using Skipgrams", "labels": [], "entities": [{"text": "GPLSI", "start_pos": 0, "end_pos": 5, "type": "DATASET", "confidence": 0.880204975605011}, {"text": "Supervised Sentiment Analysis", "start_pos": 7, "end_pos": 36, "type": "TASK", "confidence": 0.7078377604484558}, {"text": "Skipgrams", "start_pos": 54, "end_pos": 63, "type": "DATASET", "confidence": 0.9145971536636353}]}], "abstractContent": [{"text": "In this paper we describe the system submitted for the SemEval 2014 Task 9 (Sen-timent Analysis in Twitter) Subtask B. Our contribution consists of a supervised approach using machine learning techniques, which uses the terms in the dataset as features.", "labels": [], "entities": [{"text": "SemEval 2014 Task 9", "start_pos": 55, "end_pos": 74, "type": "TASK", "confidence": 0.7890637516975403}, {"text": "Sen-timent Analysis in Twitter) Subtask", "start_pos": 76, "end_pos": 115, "type": "TASK", "confidence": 0.7392599582672119}]}, {"text": "In this work we do not employ any external knowledge and resources.", "labels": [], "entities": []}, {"text": "The novelty of our approach lies in the use of words, ngrams and skipgrams (not-adjacent ngrams) as features, and how they are weighted.", "labels": [], "entities": []}], "introductionContent": [{"text": "The Web 2.0 has become one of the most important sources of data to extract useful and heterogeneous knowledge from.", "labels": [], "entities": []}, {"text": "Texts can provide factual information, such as descriptions and lists of features, and opinion-based information, which would include reviews, emotions, or feelings.", "labels": [], "entities": []}, {"text": "This subjective information can be expressed through different textual genres, such as blogs, forums, social networks and microblogs.", "labels": [], "entities": []}, {"text": "An example of microblogging social network is Twitter 1 , which has gained much popularity in the last years.", "labels": [], "entities": []}, {"text": "This website enables its users to send and read text-based messages of up to 140 characters, known as tweets.", "labels": [], "entities": []}, {"text": "This site can be avast source of subjective information in real time; millions of users share opinions on different aspects of their everyday life.", "labels": [], "entities": []}, {"text": "Extracting this subjective information has a great value for both general and expert users.", "labels": [], "entities": [{"text": "Extracting", "start_pos": 0, "end_pos": 10, "type": "TASK", "confidence": 0.9564632177352905}]}, {"text": "However, it is difficult to exploit it accordingly, mainly because of the short length of the tweets, the informality, and the lack of context.", "labels": [], "entities": []}, {"text": "Sentiment Analysis (SA) systems must be adapted to face the challenges of this new textual genre.", "labels": [], "entities": [{"text": "Sentiment Analysis (SA)", "start_pos": 0, "end_pos": 23, "type": "TASK", "confidence": 0.8678474068641663}]}, {"text": "International competitions related to the assessment of SA systems in Twitter have taken place.", "labels": [], "entities": []}, {"text": "Some of them include the TASS workshop in the SEPLN conference, the RepLab workshop in the CLEF conference, and the Sentiment Analysis in Twitter task (Task 2) in the last SemEval workshop (.", "labels": [], "entities": [{"text": "Sentiment Analysis in Twitter task", "start_pos": 116, "end_pos": 150, "type": "TASK", "confidence": 0.9134981036186218}]}, {"text": "In this paper we describe the system submitted for the SemEval 2014 Sentiment Analysis in Twitter task (Task 9 Subtask B) 2 ().", "labels": [], "entities": [{"text": "SemEval 2014 Sentiment Analysis in Twitter task", "start_pos": 55, "end_pos": 102, "type": "TASK", "confidence": 0.8955369421413967}]}, {"text": "This task consists of performing an automatic sentiment analysis to determine whether a message expresses a positive, negative, or neutral sentiment.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 46, "end_pos": 64, "type": "TASK", "confidence": 0.7434880435466766}]}, {"text": "The organisers of this task provide three datasets: training, development training, and development test.", "labels": [], "entities": []}, {"text": "The participants can use the training and development training datasets to train and validate their models, but the development test dataset can only be used for validation.", "labels": [], "entities": []}, {"text": "The size and distribution of polarities of these datasets is shown in.", "labels": [], "entities": []}, {"text": "Once their systems are ready, the participants must classify each text in the official test corpus and send the results to the organisers, who will perform the official evaluation.", "labels": [], "entities": []}], "datasetContent": [{"text": "We performed a series of experiments employing both the training corpus and the development training corpus to create our model, and the development test corpus to validate it.", "labels": [], "entities": []}, {"text": "We used as baseline the system presented to the, which also uses skipgrams and scores them depending on their density but, instead of using the skipgrams as features of a machine learning model, the polarity of each text is determined by a combination of the scores of its skipgrams.", "labels": [], "entities": []}, {"text": "The results of our experiments are shown in show the weighted precision (P), the weighted recall (R), the weighted F-score (F1) and the score obtained using the scorer tool provided by the workshop organisers (Score).", "labels": [], "entities": [{"text": "precision (P)", "start_pos": 62, "end_pos": 75, "type": "METRIC", "confidence": 0.8989442139863968}, {"text": "recall (R)", "start_pos": 90, "end_pos": 100, "type": "METRIC", "confidence": 0.9571346044540405}, {"text": "F-score (F1)", "start_pos": 115, "end_pos": 127, "type": "METRIC", "confidence": 0.9363986551761627}]}, {"text": "The notation n = max indicates there was no limit with the number of terms, and k = max indicates there was no restriction with the number of skips.", "labels": [], "entities": []}, {"text": "As we can see, the presented approach outperforms the baseline proposed and the best results are obtained using skipgrams, specifically when n = 2 and k = max.", "labels": [], "entities": [{"text": "skipgrams", "start_pos": 112, "end_pos": 121, "type": "METRIC", "confidence": 0.9611585140228271}]}, {"text": "These are the parameters of the system submitted to the competition.", "labels": [], "entities": []}, {"text": "Our main observation is that incrementing the number of terms increases the precision of the system.", "labels": [], "entities": [{"text": "precision", "start_pos": 76, "end_pos": 85, "type": "METRIC", "confidence": 0.9994943141937256}]}, {"text": "A possible explanation for this might be that ngrams/skipgrams with a greater number of words are more specific and representative of a given polarity.", "labels": [], "entities": []}, {"text": "In addition, using skipgrams insted of ngrams also improves the precision.", "labels": [], "entities": [{"text": "precision", "start_pos": 64, "end_pos": 73, "type": "METRIC", "confidence": 0.9990966320037842}]}, {"text": "However, no significant differences were found between experiments with a different number of skips.", "labels": [], "entities": []}, {"text": "In we can seethe official results obtained in the SemEval 2014 competition.", "labels": [], "entities": [{"text": "SemEval 2014 competition", "start_pos": 50, "end_pos": 74, "type": "TASK", "confidence": 0.6786629358927408}]}, {"text": "The best rank was obtained in the experiments with the Twitter 2014 Sarcasm dataset.", "labels": [], "entities": [{"text": "Twitter 2014 Sarcasm dataset", "start_pos": 55, "end_pos": 83, "type": "DATASET", "confidence": 0.8490924388170242}]}], "tableCaptions": [{"text": " Table 1. Once their systems are ready,  the participants must classify each text in the offi- cial test corpus and send the results to the organis- ers, who will perform the official evaluation.", "labels": [], "entities": []}, {"text": " Table 1: Dataset distribution in number of tweets.", "labels": [], "entities": []}, {"text": " Table 2: Experiments performed and scores obtained.", "labels": [], "entities": []}, {"text": " Table 3: Official SemEval 2014 Subtask B results.", "labels": [], "entities": [{"text": "Official SemEval 2014 Subtask B results", "start_pos": 10, "end_pos": 49, "type": "DATASET", "confidence": 0.6508430937925974}]}]}