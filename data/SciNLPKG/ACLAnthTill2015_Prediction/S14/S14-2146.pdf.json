{"title": [{"text": "UWM: Applying an Existing Trainable Semantic Parser to Parse Robotic Spatial Commands", "labels": [], "entities": [{"text": "UWM", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.8051948547363281}]}], "abstractContent": [{"text": "This paper describes Team UWM's system for the Task 6 of SemEval 2014 for doing supervised semantic parsing of robotic spatial commands.", "labels": [], "entities": [{"text": "SemEval 2014", "start_pos": 57, "end_pos": 69, "type": "TASK", "confidence": 0.826251745223999}, {"text": "supervised semantic parsing of robotic spatial commands", "start_pos": 80, "end_pos": 135, "type": "TASK", "confidence": 0.8288982255118233}]}, {"text": "An existing semantic parser, KRISP, was trained using the provided training data of natural language robotic spatial commands paired with their meaning representations in the formal robot command language.", "labels": [], "entities": []}, {"text": "The entire process required very little manual effort.", "labels": [], "entities": []}, {"text": "Without using the additional annotations of word-aligned semantic trees, the trained parser was able to exactly parse new commands into their meaning representations with 51.18% best F-measure at 72.67% precision and 39.49% recall.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 183, "end_pos": 192, "type": "METRIC", "confidence": 0.9925634264945984}, {"text": "precision", "start_pos": 203, "end_pos": 212, "type": "METRIC", "confidence": 0.9928975105285645}, {"text": "recall", "start_pos": 224, "end_pos": 230, "type": "METRIC", "confidence": 0.9987945556640625}]}, {"text": "Results show that the parser was particularly accurate for short sentences.", "labels": [], "entities": []}], "introductionContent": [{"text": "Semantic parsing is the task of converting natural language utterances into their complete formal meaning representations which are executable for some application.", "labels": [], "entities": [{"text": "Semantic parsing", "start_pos": 0, "end_pos": 16, "type": "TASK", "confidence": 0.8288902938365936}]}, {"text": "Example applications of semantic parsing include giving natural language commands to robots and querying databases in natural language.", "labels": [], "entities": [{"text": "semantic parsing", "start_pos": 24, "end_pos": 40, "type": "TASK", "confidence": 0.7256380021572113}]}, {"text": "Some old semantic parsers were developed manually to work for specific applications.", "labels": [], "entities": []}, {"text": "However, such semantic parsers were generally brittle and building them required a lot of manual effort.", "labels": [], "entities": []}, {"text": "In addition, these parsers could not be ported to any other application without again putting significant manual effort.", "labels": [], "entities": []}, {"text": "More recently, several semantic parsers have been developed using machine learning (Zelle and;;).", "labels": [], "entities": []}, {"text": "In this approach, training data is first created for the domain of interest.", "labels": [], "entities": []}, {"text": "Then using one of the many machine learning methods and semantic parsing frameworks, a semantic parser is automatically learned from the training data.", "labels": [], "entities": [{"text": "semantic parsing", "start_pos": 56, "end_pos": 72, "type": "TASK", "confidence": 0.760162889957428}]}, {"text": "The trained semantic parser is then capable of parsing new natural language utterances into their meaning representations.", "labels": [], "entities": [{"text": "parsing new natural language utterances", "start_pos": 47, "end_pos": 86, "type": "TASK", "confidence": 0.8264951109886169}]}, {"text": "Semantic parsers built using machine learning tend to be more robust and can be easily ported to other application domains with appropriate domain-specific training data.", "labels": [], "entities": []}, {"text": "The Task 6 of SemEval 2014 provided anew application domain for semantic parsing along with training and test data.", "labels": [], "entities": [{"text": "SemEval 2014", "start_pos": 14, "end_pos": 26, "type": "TASK", "confidence": 0.8693735003471375}, {"text": "semantic parsing", "start_pos": 64, "end_pos": 80, "type": "TASK", "confidence": 0.7476394176483154}]}, {"text": "The domain involved giving natural language commands to a robotic arm which would then move blocks on aboard.", "labels": [], "entities": []}, {"text": "The domain was inspired from the classic AI system SHRDLU.", "labels": [], "entities": []}, {"text": "The training data contained 2500 examples of sentences paired with their meaning representations in the Robot Command Language (RCL) which was designed for this domain.", "labels": [], "entities": []}, {"text": "The test data contained 909 such example pairs.", "labels": [], "entities": []}, {"text": "We trained an existing and freely available 1 semantic parser KRISP () using the training data for this domain.", "labels": [], "entities": []}, {"text": "Besides changing the format of the data for running KRISP and writing a context-free grammar for the meaning representation language RCL, the entire process required minimal manual effort.", "labels": [], "entities": [{"text": "meaning representation language RCL", "start_pos": 101, "end_pos": 136, "type": "TASK", "confidence": 0.7374370396137238}]}, {"text": "The author spent less than a week's time for participating in the Task 6, and most of it was spent in running the experiments.", "labels": [], "entities": []}, {"text": "This demonstrates that trainable semantic parsers like KRISP can be rapidly adopted to new domains.", "labels": [], "entities": []}, {"text": "In the Results section we show different precisions and recalls it ob-tained at different confidence levels in the form of a precision-recall curve.", "labels": [], "entities": [{"text": "precisions", "start_pos": 41, "end_pos": 51, "type": "METRIC", "confidence": 0.9991416931152344}, {"text": "precision-recall", "start_pos": 125, "end_pos": 141, "type": "METRIC", "confidence": 0.9860028028488159}]}, {"text": "The results also show that the parser was particularly accurate on shorter sentences.", "labels": [], "entities": []}, {"text": "Two major reasons that prevented KRISP from performing better on this domain were -its high computational demand for memory which prevented it from being trained beyond 1500 training examples, and some variability in the meaning representation language RCL that negatively affected training as well as evaluation.", "labels": [], "entities": [{"text": "meaning representation language RCL", "start_pos": 221, "end_pos": 256, "type": "TASK", "confidence": 0.6909181773662567}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 2: Accuracy of semantic parsing across test  sentences of varying lengths.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9893431663513184}, {"text": "semantic parsing", "start_pos": 22, "end_pos": 38, "type": "TASK", "confidence": 0.6967369616031647}]}]}