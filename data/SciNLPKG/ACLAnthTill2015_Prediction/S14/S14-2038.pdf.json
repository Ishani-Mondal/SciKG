{"title": [{"text": "DLIREC: Aspect Term Extraction and Term Polarity Classification System", "labels": [], "entities": [{"text": "Aspect Term Extraction and Term Polarity Classification", "start_pos": 8, "end_pos": 63, "type": "TASK", "confidence": 0.6347156507628304}]}], "abstractContent": [{"text": "This paper describes our system used in the Aspect Based Sentiment Analysis Task 4 at the SemEval-2014.", "labels": [], "entities": [{"text": "Aspect Based Sentiment Analysis Task 4 at the SemEval-2014", "start_pos": 44, "end_pos": 102, "type": "TASK", "confidence": 0.7690931061903635}]}, {"text": "Our system consists of two components to address two of the subtasks respectively: a Conditional Random Field (CRF) based classifier for Aspect Term Extraction (ATE) and a linear classifier for Aspect Term Polarity Classification (ATP).", "labels": [], "entities": [{"text": "Aspect Term Extraction (ATE)", "start_pos": 137, "end_pos": 165, "type": "TASK", "confidence": 0.7035015722115835}, {"text": "Aspect Term Polarity Classification (ATP)", "start_pos": 194, "end_pos": 235, "type": "TASK", "confidence": 0.7631679092134748}]}, {"text": "For the ATE subtask, we implement a variety of lexicon, syntactic and semantic features, as well as cluster features induced from unlabeled data.", "labels": [], "entities": []}, {"text": "Our system achieves state-of-the-art performances in ATE, ranking 1st (among 28 submissions) and 2rd (among 27 submissions) for the restaurant and laptop domain respectively.", "labels": [], "entities": [{"text": "ATE", "start_pos": 53, "end_pos": 56, "type": "DATASET", "confidence": 0.5602485537528992}]}], "introductionContent": [{"text": "Sentiment analysis on document and sentence level no longer fulfills user's needs of getting more accurate and precise information.", "labels": [], "entities": [{"text": "Sentiment analysis", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.9455608129501343}]}, {"text": "By performing sentiment analysis at the aspect level, we can help users gain more insights on the sentiments of the various aspects of the target entity.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 14, "end_pos": 32, "type": "TASK", "confidence": 0.8478914499282837}]}, {"text": "Task 4 of SemEval-2014 provides a good platform for (1) aspect term extraction and (2) aspect term polarity classification.", "labels": [], "entities": [{"text": "aspect term extraction", "start_pos": 56, "end_pos": 78, "type": "TASK", "confidence": 0.6879930297533671}, {"text": "aspect term polarity classification", "start_pos": 87, "end_pos": 122, "type": "TASK", "confidence": 0.7417197078466415}]}, {"text": "For the first subtask, we follow the approach of by modeling term extraction as a sequential labeling task.", "labels": [], "entities": [{"text": "term extraction", "start_pos": 61, "end_pos": 76, "type": "TASK", "confidence": 0.7215374559164047}]}, {"text": "Specifically, we leverage on semantic and syntactic resources to extract a variety of features and use CRF as the learning algorithm.", "labels": [], "entities": []}, {"text": "For the second subtask, we simply treat it as a multi-class classification problem where a linear classifier is learned to predict the polarity class.", "labels": [], "entities": []}, {"text": "Our system achieves good performances for the first subtask in both domains, ranking 1st for the restaurant domain, and 2nd for the laptop domain.", "labels": [], "entities": []}, {"text": "The remainder of this paper is structured as follows: In Section 2, we describe our ATE system in detail, including experiments and result analysis.", "labels": [], "entities": [{"text": "ATE", "start_pos": 84, "end_pos": 87, "type": "TASK", "confidence": 0.7639797329902649}, {"text": "result analysis", "start_pos": 132, "end_pos": 147, "type": "TASK", "confidence": 0.6799284219741821}]}, {"text": "Section 3 describes the general approach of our ATP system.", "labels": [], "entities": []}, {"text": "Finally, Section 4 summarizes our work.", "labels": [], "entities": []}], "datasetContent": [{"text": "We use the CRFsuite tool to train our CRF model.", "labels": [], "entities": []}, {"text": "We use the default settings, except for the negative state features (-p feature.possible states=1).: 5-fold cross-validation performances on the laptop domain.", "labels": [], "entities": []}, {"text": "Each row uses all features added in the previous rows.", "labels": [], "entities": []}, {"text": "show the 5-fold crossvalidation performances after adding each feature group for the laptop and restaurant domain respectively.", "labels": [], "entities": []}, {"text": "Most features are included in the optimum feature set for both domains, except for WordNet Taxonomy feature (only used in the restaurant domain) and Dependency Relation feature (only used in the laptop domain).", "labels": [], "entities": [{"text": "Dependency Relation", "start_pos": 149, "end_pos": 168, "type": "TASK", "confidence": 0.7009258568286896}]}, {"text": "For each domain, we make submissions in both constrained and unconstrained settings.", "labels": [], "entities": []}, {"text": "The constrained submission only uses the Word and Name List features, while all features listed in and are used in the unconstrained submission for the respective domain.", "labels": [], "entities": []}, {"text": "We use LIBLINEAR 12 to train our logistic regression classifier using default settings.: Accuracy of the Aspect Term Polarity subtask.", "labels": [], "entities": [{"text": "LIBLINEAR", "start_pos": 7, "end_pos": 16, "type": "METRIC", "confidence": 0.8986406326293945}, {"text": "Accuracy", "start_pos": 89, "end_pos": 97, "type": "METRIC", "confidence": 0.9981535077095032}]}, {"text": "shows the classification accuracy of our baseline system on the training and test set for each domain.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 25, "end_pos": 33, "type": "METRIC", "confidence": 0.9804274439811707}]}, {"text": "The performance drops a lot in the test set as we use very simple approaches to generate the lexicons.", "labels": [], "entities": []}, {"text": "This may cause overfitting on the training set.", "labels": [], "entities": []}, {"text": "We also observe that in the test set of both domains, more than half of the instances are positive.", "labels": [], "entities": []}, {"text": "In the future, we can explore on using more sophisticated ways to build more effective features and to better model data skewness.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: 5-fold cross-validation performances on  the laptop domain. Each row uses all features  added in the previous rows.", "labels": [], "entities": []}, {"text": " Table 3: Results of the Aspect Term Extraction subtask. We also indicate whether the system is con- strained (C) or unconstrained (U).", "labels": [], "entities": [{"text": "Aspect Term Extraction", "start_pos": 25, "end_pos": 47, "type": "TASK", "confidence": 0.6904022097587585}]}, {"text": " Table 2: 5-fold cross-validation performances on  the restaurant domain. Each row uses all features  added in the previous rows.", "labels": [], "entities": []}, {"text": " Table 4: Feature ablation study on the test set. The  quantity is the F1 loss resulted from the removal of  a single feature group. The last row indicates the  F1 loss when all features are used.", "labels": [], "entities": [{"text": "F1 loss", "start_pos": 71, "end_pos": 78, "type": "METRIC", "confidence": 0.9861319661140442}, {"text": "F1 loss", "start_pos": 161, "end_pos": 168, "type": "METRIC", "confidence": 0.9764276742935181}]}, {"text": " Table 5: Accuracy of the Aspect Term Polarity  subtask.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9984481334686279}, {"text": "Aspect Term Polarity", "start_pos": 26, "end_pos": 46, "type": "METRIC", "confidence": 0.6666823029518127}]}]}