{"title": [{"text": "IITP: A Supervised Approach for Disorder Mention Detection and Disambiguation", "labels": [], "entities": [{"text": "Disorder Mention Detection and Disambiguation", "start_pos": 32, "end_pos": 77, "type": "TASK", "confidence": 0.8181516885757446}]}], "abstractContent": [{"text": "In this paper we briefly describe our supervised machine learning approach for disorder mention detection system that we submitted as part of our participation in the SemEval-2014 Shared task.", "labels": [], "entities": [{"text": "disorder mention detection", "start_pos": 79, "end_pos": 105, "type": "TASK", "confidence": 0.7711757918198904}, {"text": "SemEval-2014 Shared task", "start_pos": 167, "end_pos": 191, "type": "TASK", "confidence": 0.7832425038019816}]}, {"text": "The main goal of this task is to build a system that automatically identifies mentions of clinical conditions from the clinical texts.", "labels": [], "entities": []}, {"text": "The main challenge lies due in the fact that the same mention of concept maybe represented in many surface forms.", "labels": [], "entities": []}, {"text": "We develop the system based on the supervised machine learning algorithms, namely Conditional Random Field and Support Vector Machine.", "labels": [], "entities": []}, {"text": "One appealing characteristics of our system is that most of the features for learning are extracted automatically from the given training or test datasets without using deep domain specific resources and/or tools.", "labels": [], "entities": []}, {"text": "We submitted three runs, and best performing system is based on Conditional Random Field.", "labels": [], "entities": []}, {"text": "For task A, it shows the precision, recall and F-measure values of 50.00%, 47.90% and 48.90%, respectively under the strict matching criterion.", "labels": [], "entities": [{"text": "precision", "start_pos": 25, "end_pos": 34, "type": "METRIC", "confidence": 0.999735414981842}, {"text": "recall", "start_pos": 36, "end_pos": 42, "type": "METRIC", "confidence": 0.997409999370575}, {"text": "F-measure", "start_pos": 47, "end_pos": 56, "type": "METRIC", "confidence": 0.9955841898918152}]}, {"text": "When the matching criterion is relaxed, it shows the precision, recall and F-measure of 81.50%, 79.70% and 80.60%, respectively.", "labels": [], "entities": [{"text": "precision", "start_pos": 53, "end_pos": 62, "type": "METRIC", "confidence": 0.9997554421424866}, {"text": "recall", "start_pos": 64, "end_pos": 70, "type": "METRIC", "confidence": 0.9985748529434204}, {"text": "F-measure", "start_pos": 75, "end_pos": 84, "type": "METRIC", "confidence": 0.9995332956314087}]}, {"text": "For task B, we obtain the accuracies of 33.30% and 69.60% for the relaxed and strict matches, respectively.", "labels": [], "entities": [{"text": "accuracies", "start_pos": 26, "end_pos": 36, "type": "METRIC", "confidence": 0.9986652135848999}]}], "introductionContent": [{"text": "The SemEval-2014 Shared Task 7 is concerned with the analysis of clinical texts, particularly for disorder mention detection and disambiguation.", "labels": [], "entities": [{"text": "disorder mention detection and disambiguation", "start_pos": 98, "end_pos": 143, "type": "TASK", "confidence": 0.6572469532489776}]}, {"text": "To classify each mention with respect to the Unified Medical Language System (UMLS) Concept Unique Identifier (CUI).", "labels": [], "entities": [{"text": "Unified Medical Language System (UMLS) Concept Unique Identifier (CUI)", "start_pos": 45, "end_pos": 115, "type": "TASK", "confidence": 0.5683947136768928}]}, {"text": "The task is challenging in the sense that the same mention of concept maybe represented in many surface forms and mention may appear in the different parts of texts.", "labels": [], "entities": []}, {"text": "Some systems) are available for disorder mention detection.", "labels": [], "entities": [{"text": "disorder mention detection", "start_pos": 32, "end_pos": 58, "type": "TASK", "confidence": 0.876963198184967}]}, {"text": "Looking at the challenges and resources available at our hand we planned to adapt our existing system () for disorder mention detection.", "labels": [], "entities": [{"text": "disorder mention detection", "start_pos": 109, "end_pos": 135, "type": "TASK", "confidence": 0.8681723872820536}]}, {"text": "The original architecture was conceptualized as part of our participation in the BioCreative-IV Track-2 Shared Task on Chemical Compound and Drug Name Recognition.", "labels": [], "entities": [{"text": "BioCreative-IV Track-2 Shared Task on Chemical Compound and Drug Name Recognition", "start_pos": 81, "end_pos": 162, "type": "TASK", "confidence": 0.525203981182792}]}, {"text": "Although our submitted system for SemEval-14 shared task is inline with BioCreative-IV 1 , it has many different features and characteristics.", "labels": [], "entities": [{"text": "SemEval-14 shared task", "start_pos": 34, "end_pos": 56, "type": "TASK", "confidence": 0.8767066796620687}]}, {"text": "We develop three systems (e.g. Model-1: sikdar.run-0, Model-2: sikdar.run-1 and Model-3: sikdar.run-2) based on the popular supervised machine learning algorithms, namely Conditional Random Field (CRF) () and Support Vector Machine (SVM)).", "labels": [], "entities": []}, {"text": "The models were developed by varying the features and feature templates.", "labels": [], "entities": []}, {"text": "A baseline model is constructed by using the UMLS MetaMap 2 tool.", "labels": [], "entities": []}, {"text": "During testing we merge the development set with the training set.", "labels": [], "entities": []}, {"text": "Evaluation results on test data with the benchmark setup show the F-measure values of 48.90%, 46.50% and 46.50%, respectively under the strict criterion.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 66, "end_pos": 75, "type": "METRIC", "confidence": 0.9986439347267151}]}, {"text": "Under relaxed matching criterion the models show the F-measure values of 80.60%, 78.20% and 79.60%, respectively.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 53, "end_pos": 62, "type": "METRIC", "confidence": 0.9985587000846863}]}, {"text": "Our submission for Task-B is simple in nature where we consider only those mentions that are also predicted in the baseline model, i.e. only the common CUIs are considered.", "labels": [], "entities": []}, {"text": "It shows the accuracies of 33.30%, 31.90% and 33.20%, respectively under strict matching criterion; and 69.60%, 69.60% and 69.10%, respectively under the relaxed matching criterion.", "labels": [], "entities": [{"text": "accuracies", "start_pos": 13, "end_pos": 23, "type": "METRIC", "confidence": 0.9982624650001526}]}], "datasetContent": [{"text": "In SemEval-2014 Shared task 7, three types of data were provided-training, development and test.", "labels": [], "entities": [{"text": "SemEval-2014 Shared task 7", "start_pos": 3, "end_pos": 29, "type": "TASK", "confidence": 0.6620862632989883}]}, {"text": "Training data contains four different types of notes-discharge, ecg, echo and radiology.", "labels": [], "entities": [{"text": "echo", "start_pos": 69, "end_pos": 73, "type": "METRIC", "confidence": 0.9910739064216614}]}, {"text": "Development data consists of notes of three different domains, viz.", "labels": [], "entities": []}, {"text": "discharge, echo and radiology.", "labels": [], "entities": [{"text": "echo", "start_pos": 11, "end_pos": 15, "type": "TASK", "confidence": 0.914508581161499}]}, {"text": "But the test set contains only the discharge notes.", "labels": [], "entities": []}, {"text": "For a given document, the start and end indices are mentioned for the disorder mentions.", "labels": [], "entities": [{"text": "start and end indices", "start_pos": 26, "end_pos": 47, "type": "METRIC", "confidence": 0.7040977329015732}]}, {"text": "There are 199, 99 and 133 documents in the training, development and test set, respectively.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Results on development set for Task A.", "labels": [], "entities": []}, {"text": " Table 3: Results on development set for Task B.", "labels": [], "entities": []}, {"text": " Table 3. Please  note that although our system performs better than  the baseline in terms of strict matching, it does not  show better accuracy under relaxed matching cri- terion. This is because our system for Task-B is  developed by considering only those mentions that  lie in the intersection of baseline and CRF models.  As a result many mentions are missed. During fi- nal submissions we merged development sets with  the respective training sets, and perform evalua- tion on the test sets. We report our results on the  test sets in", "labels": [], "entities": [{"text": "accuracy", "start_pos": 137, "end_pos": 145, "type": "METRIC", "confidence": 0.9989905953407288}]}, {"text": " Table 4: Evaluation results on test set for Task A.", "labels": [], "entities": []}]}