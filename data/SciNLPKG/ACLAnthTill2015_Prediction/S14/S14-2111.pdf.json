{"title": [{"text": "TeamX: A Sentiment Analyzer with Enhanced Lexicon Mapping and Weighting Scheme for Unbalanced Data", "labels": [], "entities": [{"text": "TeamX", "start_pos": 0, "end_pos": 5, "type": "DATASET", "confidence": 0.8187885284423828}]}], "abstractContent": [{"text": "This paper describes the system that has been used by TeamX in SemEval-2014 Task 9 Subtask B. The system is a sentiment analyzer based on a supervised text categorization approach designed with following two concepts.", "labels": [], "entities": [{"text": "SemEval-2014 Task 9 Subtask", "start_pos": 63, "end_pos": 90, "type": "TASK", "confidence": 0.6599810421466827}, {"text": "sentiment analyzer", "start_pos": 110, "end_pos": 128, "type": "TASK", "confidence": 0.8878772556781769}]}, {"text": "Firstly, since lexicon features were shown to be effective in SemEval-2013 Task 2, various lexicons and pre-processors for them are introduced to enhance lexical information.", "labels": [], "entities": [{"text": "SemEval-2013 Task 2", "start_pos": 62, "end_pos": 81, "type": "TASK", "confidence": 0.740645706653595}]}, {"text": "Secondly, since a distribution of sentiment on tweets is known to be unbalanced, an weighting scheme is introduced to bias an output of a machine learner.", "labels": [], "entities": []}, {"text": "For the test run, the system was tuned towards Twitter texts and successfully achieved high scoring results on Twitter data, average F 1 70.96 on Twit-ter2014 and average F 1 56.50 on Twit-ter2014Sarcasm.", "labels": [], "entities": [{"text": "Twitter data", "start_pos": 111, "end_pos": 123, "type": "DATASET", "confidence": 0.855615109205246}, {"text": "F 1 70.96", "start_pos": 133, "end_pos": 142, "type": "METRIC", "confidence": 0.9735184113184611}, {"text": "Twit-ter2014", "start_pos": 146, "end_pos": 158, "type": "DATASET", "confidence": 0.9640112519264221}, {"text": "F 1", "start_pos": 171, "end_pos": 174, "type": "METRIC", "confidence": 0.9706115424633026}, {"text": "Twit-ter2014Sarcasm", "start_pos": 184, "end_pos": 203, "type": "DATASET", "confidence": 0.9595000743865967}]}], "introductionContent": [{"text": "The growth of social media has brought a rising interest to make natural language technologies that work with informal texts.", "labels": [], "entities": []}, {"text": "Sentiment analysis is one such technology, and several workshops such as,, and TASS 2013) have recently targeted tweets or cellphone messages as analysis text.", "labels": [], "entities": [{"text": "Sentiment analysis", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.932640939950943}, {"text": "TASS 2013", "start_pos": 79, "end_pos": 88, "type": "DATASET", "confidence": 0.7803260087966919}]}, {"text": "This paper describes a system that has submitted a sentiment analysis result to Subtask B of).", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 51, "end_pos": 69, "type": "TASK", "confidence": 0.9072386622428894}]}, {"text": "SemEval-2014 Task9 is a rerun of SemEval-2013 Task 2 with different test data, and Subtask B is a task of message polarity classification.", "labels": [], "entities": [{"text": "SemEval-2014 Task9", "start_pos": 0, "end_pos": 18, "type": "DATASET", "confidence": 0.8546723425388336}, {"text": "message polarity classification", "start_pos": 106, "end_pos": 137, "type": "TASK", "confidence": 0.8494078516960144}]}, {"text": "The system we prepared is a sentiment analyzer based on a supervised text categorization approach.", "labels": [], "entities": [{"text": "sentiment analyzer", "start_pos": 28, "end_pos": 46, "type": "TASK", "confidence": 0.940721869468689}]}, {"text": "Various features and their extraction methods are integrated in the system following the works presented in SemEval-2013 Task 2.", "labels": [], "entities": [{"text": "SemEval-2013 Task 2", "start_pos": 108, "end_pos": 127, "type": "TASK", "confidence": 0.7016272147496542}]}, {"text": "Additionally to these features, we assembled following notable functionalities to the system: 1.", "labels": [], "entities": []}, {"text": "Processes to enhance word-to-lemma mapping.", "labels": [], "entities": [{"text": "word-to-lemma mapping", "start_pos": 21, "end_pos": 42, "type": "TASK", "confidence": 0.7493748664855957}]}, {"text": "(a) A spelling corrector to normalize out-ofvocabulary words.", "labels": [], "entities": [{"text": "spelling corrector", "start_pos": 6, "end_pos": 24, "type": "TASK", "confidence": 0.8768517673015594}]}, {"text": "(b) Two Part-of-Speech (POS) taggers to realize word-to-lemma mapping in two perspectives.", "labels": [], "entities": []}, {"text": "(c) A word sense disambiguator to obtain word senses and their confidence scores.", "labels": [], "entities": [{"text": "word sense disambiguator", "start_pos": 6, "end_pos": 30, "type": "TASK", "confidence": 0.7245706617832184}]}, {"text": "2. An weighting scheme to bias an output of a machine learner.", "labels": [], "entities": []}, {"text": "Functionalities 1a to 1c are introduced to enhance information based on lexical knowledge, since features based on lexicons are shown to be effective in.", "labels": [], "entities": []}, {"text": "Functionality 2 is introduced to make the system adjustable to polarity unbalancedness known to exists in Twitter data (.", "labels": [], "entities": [{"text": "Functionality", "start_pos": 0, "end_pos": 13, "type": "METRIC", "confidence": 0.8843468427658081}, {"text": "Twitter data", "start_pos": 106, "end_pos": 118, "type": "DATASET", "confidence": 0.8898614943027496}]}, {"text": "The accompanying sections of this papers are organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 describes resources such as labeled texts and lexicons used in our system.", "labels": [], "entities": []}, {"text": "Section 3 explains the details of the system.", "labels": [], "entities": []}, {"text": "Section 4 discusses the submission test run and some extra test runs that we performed after the test data release.", "labels": [], "entities": []}, {"text": "Finally, section 5 concludes the paper.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: The numbers of messages for each type.  'train', 'dev', and 'dev-test' denote training, devel- opment, and development-test respectively. #Used  is the number of messages that we were able to  obtain, and #Full is the maximum number of mes- sages that were provided.", "labels": [], "entities": []}, {"text": " Table 3: The scores for each source in the test runs. The run with asterisk (*) denotes the submission  run. The values in the 'Sources' columns represent scores in SemEval-2014 Task 9 metric (the average  of positive F 1 and negative F 1 ).", "labels": [], "entities": [{"text": "SemEval-2014 Task 9 metric", "start_pos": 166, "end_pos": 192, "type": "DATASET", "confidence": 0.5763163566589355}, {"text": "F 1", "start_pos": 219, "end_pos": 222, "type": "METRIC", "confidence": 0.9682089686393738}, {"text": "F 1", "start_pos": 236, "end_pos": 239, "type": "METRIC", "confidence": 0.882567822933197}]}]}