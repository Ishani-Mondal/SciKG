{"title": [{"text": "SAIL: Sentiment Analysis using Semantic Similarity and Contrast Features", "labels": [], "entities": [{"text": "Sentiment Analysis", "start_pos": 6, "end_pos": 24, "type": "TASK", "confidence": 0.973747968673706}]}], "abstractContent": [{"text": "This paper describes our submission to Se-mEval2014 Task 9: Sentiment Analysis in Twitter.", "labels": [], "entities": [{"text": "Sentiment Analysis in Twitter", "start_pos": 60, "end_pos": 89, "type": "TASK", "confidence": 0.8737303614616394}]}, {"text": "Our model is primarily a lexicon based one, augmented by some pre-processing, including detection of Multi-Word Expressions, negation propagation and hashtag expansion and by the use of pairwise semantic similarity at the tweet level.", "labels": [], "entities": [{"text": "negation propagation", "start_pos": 125, "end_pos": 145, "type": "TASK", "confidence": 0.9547902643680573}, {"text": "hashtag expansion", "start_pos": 150, "end_pos": 167, "type": "TASK", "confidence": 0.732540026307106}]}, {"text": "Feature extraction is repeated for sub-strings and contrasting sub-string features are used to better capture complex phenomena like sarcasm.", "labels": [], "entities": [{"text": "Feature extraction", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.7359589040279388}]}, {"text": "The resulting supervised system, using a Naive Bayes model, achieved high performance in classifying entire tweets, ranking 7th on the main set and 2nd when applied to sarcastic tweets.", "labels": [], "entities": []}], "introductionContent": [{"text": "The analysis of the emotional content of text is relevant to numerous natural language processing (NLP), web and multi-modal dialogue applications.", "labels": [], "entities": [{"text": "analysis of the emotional content of text", "start_pos": 4, "end_pos": 45, "type": "TASK", "confidence": 0.7508500984736851}]}, {"text": "In recent years the increased popularity of social media and increased availability of relevant data has led to a focus of scientific efforts on the emotion expressed through social media, with Twitter being the most common subject.", "labels": [], "entities": []}, {"text": "Sentiment analysis in Twitter is usually performed by combining techniques used for related tasks, like word-level () and sentencelevel () emotion extraction.", "labels": [], "entities": [{"text": "Sentiment analysis", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.9485345184803009}, {"text": "emotion extraction", "start_pos": 139, "end_pos": 157, "type": "TASK", "confidence": 0.7928613424301147}]}, {"text": "Twitter however does present specific challenges: the breadth of possible content is virtually unlimited, the writing style is informal, the use of orthography and This work is licensed under a Creative Commons Attribution 4.0 International Licence.", "labels": [], "entities": []}, {"text": "Page numbers and proceedings footer are added by the organisers.", "labels": [], "entities": []}, {"text": "Licence details: http://creativecommons.org/licenses/by/4.0/ grammar can be \"unconventional\" and there are unique artifacts like hashtags.", "labels": [], "entities": []}, {"text": "Computation systems, like those submitted to) mostly use bag-of-words models with specific features added to model emotion indicators like hashtags and emoticons.", "labels": [], "entities": []}, {"text": "This paper describes our submissions to SemEval 2014 task 9 (), which deals with sentiment analysis in twitter.", "labels": [], "entities": [{"text": "SemEval 2014 task 9", "start_pos": 40, "end_pos": 59, "type": "TASK", "confidence": 0.8995323479175568}, {"text": "sentiment analysis", "start_pos": 81, "end_pos": 99, "type": "TASK", "confidence": 0.9476751387119293}]}, {"text": "The system is an expansion of our submission to the same task in, which used only token rating statistics as features.", "labels": [], "entities": []}, {"text": "We expanded the system by using multiple lexica and more statistics, added steps to the pre-processing stage (including negation and multi-word expression handling), incorporated pairwise tweet-level semantic similarities as features and finally performed feature extraction on substrings and used the partial features as indicators of irony, sarcasm or humor.", "labels": [], "entities": [{"text": "multi-word expression handling", "start_pos": 133, "end_pos": 163, "type": "TASK", "confidence": 0.7290414174397787}, {"text": "feature extraction", "start_pos": 256, "end_pos": 274, "type": "TASK", "confidence": 0.719155952334404}]}, {"text": "2 Model Description 2.1 Preprocessing POS-tagging / Tokenization was performed using the ARK NLP tweeter tagger (), a Twitter-specific tagger.", "labels": [], "entities": [{"text": "ARK NLP tweeter tagger", "start_pos": 89, "end_pos": 111, "type": "DATASET", "confidence": 0.8134271800518036}]}, {"text": "Negations were detected using the list from Christopher Potts' tutorial.", "labels": [], "entities": [{"text": "Christopher Potts' tutorial", "start_pos": 44, "end_pos": 71, "type": "DATASET", "confidence": 0.8653694987297058}]}, {"text": "All tokens up to the next punctuation were marked as negated.", "labels": [], "entities": []}, {"text": "Hashtag expansion into word strings was performed using a combination of a word insertion Finite State Machine and a language model.", "labels": [], "entities": [{"text": "Hashtag expansion", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.9583602845668793}]}, {"text": "A normalized perplexity threshold was used to detect if the output was a \"proper\" English string and expansion was not performed if it was not.", "labels": [], "entities": []}, {"text": "Multi-word Expressions (MWEs) were detected using the MIT jMWE library ().", "labels": [], "entities": [{"text": "Multi-word Expressions (MWEs)", "start_pos": 0, "end_pos": 29, "type": "TASK", "confidence": 0.691618412733078}, {"text": "MIT jMWE library", "start_pos": 54, "end_pos": 70, "type": "DATASET", "confidence": 0.7695989608764648}]}, {"text": "MWEs are non-compositional expressions (), which should be handled as a single token instead of attempting to reconstruct their meaning from their parts.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Performance and rank achieved by our  submission for all datasets of subtasks A and B.", "labels": [], "entities": [{"text": "rank", "start_pos": 26, "end_pos": 30, "type": "METRIC", "confidence": 0.9651704430580139}]}, {"text": " Table 2: Selected features for subtask B.", "labels": [], "entities": []}, {"text": " Table 3: Performance on all data sets of subtask B after removing 1 set of features. Performance differ- ence with the complete system listed if greater than 1%.", "labels": [], "entities": []}]}