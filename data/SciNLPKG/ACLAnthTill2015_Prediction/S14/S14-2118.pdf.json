{"title": [{"text": "TMUNSW: Disorder Concept Recognition and Normalization in Clinical Notes for SemEval-2014 Task 7", "labels": [], "entities": [{"text": "TMUNSW", "start_pos": 0, "end_pos": 6, "type": "DATASET", "confidence": 0.7738238573074341}, {"text": "Disorder Concept Recognition", "start_pos": 8, "end_pos": 36, "type": "TASK", "confidence": 0.7468413909276327}, {"text": "SemEval-2014 Task 7", "start_pos": 77, "end_pos": 96, "type": "TASK", "confidence": 0.8669045170148214}]}], "abstractContent": [{"text": "We present our participation in Task 7 of SemEval shared task 2014.", "labels": [], "entities": [{"text": "SemEval shared task 2014", "start_pos": 42, "end_pos": 66, "type": "TASK", "confidence": 0.8615349531173706}]}, {"text": "The goal of this particular task includes the identification of disorder named entities and the mapping of each disorder to a unique Unified Medical Language System concept identifier, which were referred to as Task A and Task B respectively.", "labels": [], "entities": [{"text": "identification of disorder named entities", "start_pos": 46, "end_pos": 87, "type": "TASK", "confidence": 0.7930572628974915}]}, {"text": "We participated in both of these subtasks and used YTEX as a baseline system.", "labels": [], "entities": [{"text": "YTEX", "start_pos": 51, "end_pos": 55, "type": "DATASET", "confidence": 0.7677003741264343}]}, {"text": "We further developed a supervised linear chain Conditional Random Field model based on sets of features to predict disorder mentions.", "labels": [], "entities": []}, {"text": "To take benefit of results from both systems we merged these results.", "labels": [], "entities": []}, {"text": "Under strict condition our best run evaluated at 0.549 F-measure for Task A and an accuracy of 0.489 for Task B on test dataset.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 55, "end_pos": 64, "type": "METRIC", "confidence": 0.998898983001709}, {"text": "accuracy", "start_pos": 83, "end_pos": 91, "type": "METRIC", "confidence": 0.9993001222610474}]}, {"text": "Based on our error analysis we conclude that recall of our system can be significantly increased by adding more features to the Conditional Random Field model and by using another type of tag representation or frame matching algorithm to deal with the disjoint entity mentions.", "labels": [], "entities": [{"text": "recall", "start_pos": 45, "end_pos": 51, "type": "METRIC", "confidence": 0.9986005425453186}]}], "introductionContent": [{"text": "Clinical notes are rich sources of valuable patient's information.", "labels": [], "entities": []}, {"text": "These clinical notes are often plain text records containing important entity mentions such as clinical findings, procedures and disease mentions (.", "labels": [], "entities": []}, {"text": "Using automated tools to extract the aforementioned information can undoubtedly help researchers and clinicians with better decision making.", "labels": [], "entities": [{"text": "decision making", "start_pos": 124, "end_pos": 139, "type": "TASK", "confidence": 0.7222871780395508}]}, {"text": "An important subtask of information extraction called named entity recognition (NER) can recognize the boundary of named entity mention and classify it into a certain semantic group.", "labels": [], "entities": [{"text": "information extraction", "start_pos": 24, "end_pos": 46, "type": "TASK", "confidence": 0.7300282269716263}, {"text": "named entity recognition (NER", "start_pos": 54, "end_pos": 83, "type": "TASK", "confidence": 0.7585217595100403}]}, {"text": "The focus of the SemEval-2104 task 7 is recognition and normalization of disorder entities mentioned in clinical notes.", "labels": [], "entities": [{"text": "SemEval-2104 task 7", "start_pos": 17, "end_pos": 36, "type": "TASK", "confidence": 0.855534295241038}]}, {"text": "As such, this task was further divided into two parts: first, task A which includes recognition of mention of concepts that belong to UMLS (Unified Medical Language System) semantic group disorders).", "labels": [], "entities": [{"text": "recognition of mention of concepts that belong to UMLS (Unified Medical Language System) semantic group disorders", "start_pos": 84, "end_pos": 197, "type": "TASK", "confidence": 0.6096984859969881}]}, {"text": "The concepts considered in Task A include the following eleven UMLS semantic types: Congenital Abnormality; Acquired Abnormality; Injury or Poisoning; Pathologic Function; Disease or Syndrome; Mental or Behavioral Dysfunction; Cell or Molecular Dysfunction; Experimental Model of Disease; Anatomical Abnormality; Neoplastic Process; and Signs and Symptoms.", "labels": [], "entities": []}, {"text": "Second, task B referred to as task of normalization involves the mapping of each disorder mention to a UMLS concept unique identifier (CUI).The mapping was limited to UMLS CUI of SNOMED clinical term codes).", "labels": [], "entities": []}, {"text": "We participated in both tasks and devel-oped a disorder concept recognition/normalization system based on several openly available tools and machine learning algorithms.", "labels": [], "entities": [{"text": "disorder concept recognition/normalization", "start_pos": 47, "end_pos": 89, "type": "TASK", "confidence": 0.7678617238998413}]}], "datasetContent": [{"text": "For Task A and Task B, the training and development datasets provided by the SemEval task 7 organizers were used.", "labels": [], "entities": [{"text": "SemEval task 7 organizers", "start_pos": 77, "end_pos": 102, "type": "DATASET", "confidence": 0.6520513147115707}]}, {"text": "Both were derived from ShARe corpus containing de-identified plain text clinical notes from MIMIC II database).", "labels": [], "entities": [{"text": "ShARe corpus containing de-identified plain text clinical notes from MIMIC II database", "start_pos": 23, "end_pos": 109, "type": "DATASET", "confidence": 0.7763446519772211}]}, {"text": "These clinical notes were manually annotated for disorder mention and normalized to an UMLS CUI when possible.", "labels": [], "entities": [{"text": "UMLS CUI", "start_pos": 87, "end_pos": 95, "type": "DATASET", "confidence": 0.9289454519748688}]}, {"text": "The corpus consisted of four types of clinical notes: discharge summaries, electrocardiogram, echocardiogram, and radiology reports.", "labels": [], "entities": [{"text": "echocardiogram", "start_pos": 94, "end_pos": 108, "type": "METRIC", "confidence": 0.8827597498893738}]}, {"text": "As the dataset, we included different types of clinical notes, further we trained a CRF model for each type and evaluated its performance on the corresponding development data.", "labels": [], "entities": []}, {"text": "However, test set from task organizers contained discharge summaries only.", "labels": [], "entities": []}, {"text": "Hence, the model developed for discharge summary was selected for evaluation on the test set.", "labels": [], "entities": [{"text": "discharge summary", "start_pos": 31, "end_pos": 48, "type": "TASK", "confidence": 0.8753325343132019}]}, {"text": "The official evaluation script provided by organizers of the shared task was used to evaluate our system ability to correct an identify spans of text that belongs to semantic group disorders and to normalize them to the corresponding CUIs.", "labels": [], "entities": []}, {"text": "We calculated the evaluation measures under two settings-strict and relaxed.", "labels": [], "entities": []}, {"text": "The strict setting matches exact boundaries with the gold standard, while relaxed setting matches overlapping boundaries in the gold standard.", "labels": [], "entities": [{"text": "gold standard", "start_pos": 128, "end_pos": 141, "type": "DATASET", "confidence": 0.8958384394645691}]}, {"text": "The evaluation measures were calculated using the commonly used evaluation measures including recall (R), precision (P), and F-measure (F) (Powers, 2007).", "labels": [], "entities": [{"text": "recall (R)", "start_pos": 94, "end_pos": 104, "type": "METRIC", "confidence": 0.9573618024587631}, {"text": "precision (P)", "start_pos": 106, "end_pos": 119, "type": "METRIC", "confidence": 0.9548158198595047}, {"text": "F-measure (F)", "start_pos": 125, "end_pos": 138, "type": "METRIC", "confidence": 0.9638503342866898}]}], "tableCaptions": [{"text": " Table 1. Summary of Training Set Evaluation Re- sults.", "labels": [], "entities": [{"text": "Training Set Evaluation Re- sults", "start_pos": 21, "end_pos": 54, "type": "METRIC", "confidence": 0.5585729032754898}]}, {"text": " Table 2. Summary of Test Set Evaluation Results.", "labels": [], "entities": [{"text": "Summary of Test Set Evaluation", "start_pos": 10, "end_pos": 40, "type": "TASK", "confidence": 0.5473012924194336}]}]}