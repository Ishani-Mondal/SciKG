{"title": [{"text": "UMCC DLSI: Sentiment Analysis in Twitter using Polirity Lexicons and Tweet Similarity", "labels": [], "entities": [{"text": "UMCC DLSI", "start_pos": 0, "end_pos": 9, "type": "DATASET", "confidence": 0.8940552473068237}, {"text": "Sentiment Analysis", "start_pos": 11, "end_pos": 29, "type": "TASK", "confidence": 0.9499522149562836}]}], "abstractContent": [{"text": "This paper describes a system submitted to SemEval-2014 Task 4B: Sentiment Analysis in Twitter, by the team UMCC DLSI Sem integrated by researchers of the University of Matanzas, Cuba and the University of Alicante, Spain.", "labels": [], "entities": [{"text": "Sentiment Analysis in Twitter", "start_pos": 65, "end_pos": 94, "type": "TASK", "confidence": 0.8781944066286087}, {"text": "UMCC DLSI Sem", "start_pos": 108, "end_pos": 121, "type": "DATASET", "confidence": 0.8767003417015076}]}, {"text": "The system adopts a cascade classification process that uses two classi-fiers, K-NN using the lexical Levenshtein metric and a Dagging model trained over attributes extracted from annotated corpora and sentiment lexicons.", "labels": [], "entities": []}, {"text": "Phrases that fit the distance thresholds were automatically classified by the KNN model, the others, were evaluated with the Dagging model.", "labels": [], "entities": [{"text": "Dagging", "start_pos": 125, "end_pos": 132, "type": "DATASET", "confidence": 0.7959322929382324}]}, {"text": "This system achieved over 52.4% of correctly classified instances in the Twitter message-level subtask.", "labels": [], "entities": []}], "introductionContent": [{"text": "Nowadays, one of the most important sources of data to extract useful and heterogeneous knowledge is Textual Information.", "labels": [], "entities": []}, {"text": "Daily, millions of Tweets, SMS and blog comments increase the huge volume of information available for researchers.", "labels": [], "entities": []}, {"text": "Texts can provide factual information, such as: descriptions, lists of characteristics, or even instructions to opinion-based information, which would include reviews, emotions, or feelings ( . These facts have motivated that dealing with the identification and extraction of opinions and sentiments in texts requires special attention.", "labels": [], "entities": [{"text": "identification and extraction of opinions and sentiments in texts", "start_pos": 243, "end_pos": 308, "type": "TASK", "confidence": 0.8707685934172736}]}, {"text": "Applications of Sentiment Analysis are now more common than ever in fields like politics and business.", "labels": [], "entities": [{"text": "Sentiment Analysis", "start_pos": 16, "end_pos": 34, "type": "TASK", "confidence": 0.9636782109737396}]}, {"text": "More than 50 This work is licensed under a Creative Commons Attribution 4.0 International Licence.", "labels": [], "entities": []}, {"text": "Page numbers and proceedings footer are added by the organisers.", "labels": [], "entities": []}, {"text": "Licence details: http://creativecommons.org/licenses/by/4.0/ systems participating in this task, clearly indicate the increase of interest in the scientific community.", "labels": [], "entities": []}, {"text": "Twitter messages can be found among of the most used corpora nowadays for Sentiment Analysis (SA).", "labels": [], "entities": [{"text": "Sentiment Analysis (SA)", "start_pos": 74, "end_pos": 97, "type": "TASK", "confidence": 0.8495434641838073}]}, {"text": "This kind of messages involves an evident informality which has been addressed in different ways.", "labels": [], "entities": []}, {"text": "For example, there are some works like ( ) that apply normalisation textual tools to reduce the informality of the twitter messages.", "labels": [], "entities": []}, {"text": "Authors such as (, , ) and others are focused on the application of preprocessing processes and feature reduction to be able to standardise twitter messages and reduce different types of elements like hashtags, user nicks, urls, etc.", "labels": [], "entities": [{"text": "feature reduction", "start_pos": 96, "end_pos": 113, "type": "TASK", "confidence": 0.7057442665100098}]}, {"text": "In terms of those techniques that can be used for SA, we can cite () who built a lexicon with associated polarity value, starting with a set of classified seed adjectives and using conjunctions (and) disjunctions (or, but) to deduce the orientation of new words in a corpus.", "labels": [], "entities": [{"text": "SA", "start_pos": 50, "end_pos": 52, "type": "TASK", "confidence": 0.9723901152610779}]}, {"text": "This research was based on machine learning techniques to address Sentiment Classification.", "labels": [], "entities": [{"text": "Sentiment Classification", "start_pos": 66, "end_pos": 90, "type": "TASK", "confidence": 0.9413787722587585}]}, {"text": "Other interesting research is, which classifies words according to their polarity based on the idea that terms with similar orientation tend to co-occur in documents.", "labels": [], "entities": []}, {"text": "There area large quantity of approaches to deal with SA, and basically most of them are based on word bags and/or annotated corpora as knowledge base.", "labels": [], "entities": [{"text": "SA", "start_pos": 53, "end_pos": 55, "type": "TASK", "confidence": 0.7148240804672241}]}, {"text": "Based on this information the SA systems are able to apply different types of evaluation techniques such as machine learning or statistic formulas to predict the correct classification.", "labels": [], "entities": []}, {"text": "As part of machine learning approaches we would like to mention those works such as (,  and others that were based on feature vectors and which cover a wide range settings of SA.", "labels": [], "entities": []}, {"text": "As a starting point, we based this work on the ( ) approach, adding new features extracted from the sentiment repositories Sentiment 140 1 and NRC-Hashtag Sentiment.", "labels": [], "entities": [{"text": "NRC-Hashtag Sentiment", "start_pos": 143, "end_pos": 164, "type": "DATASET", "confidence": 0.8817407190799713}]}, {"text": "The remainder of this paper is structured as follows: section 2 describes in detail the approach presented.", "labels": [], "entities": []}, {"text": "In section 3 we explain the experiments we carried out.", "labels": [], "entities": []}, {"text": "Finally in section 4 conclusions and future works are expounded.", "labels": [], "entities": []}], "datasetContent": [{"text": "The experiments were evaluated over the training dataset provided by    The first stage of the system was applied to compute the number of instances which have at least one instance with a similarity value greater than T . We computed the percent of instances correctly classified (%CCI).", "labels": [], "entities": []}, {"text": "shows the behaviour of the system when T changes.", "labels": [], "entities": []}, {"text": "This metric counts the quantity of matched symbols (words in this case) between two sentences.", "labels": [], "entities": []}, {"text": "Furthermore, we repeated this experiment using the Matching Coefficient similarity metric to better tunning the algorithm and to evaluate if the results behave in a similar way when T changes.", "labels": [], "entities": [{"text": "Matching Coefficient similarity metric", "start_pos": 51, "end_pos": 89, "type": "METRIC", "confidence": 0.7953096777200699}]}, {"text": "In both cases, we use the implementation provided in the SimMetrics library.", "labels": [], "entities": [{"text": "SimMetrics library", "start_pos": 57, "end_pos": 75, "type": "DATASET", "confidence": 0.9011207818984985}]}, {"text": "As those results shows, when T decrease the accuracy decrease too.", "labels": [], "entities": [{"text": "T", "start_pos": 29, "end_pos": 30, "type": "METRIC", "confidence": 0.9705101251602173}, {"text": "accuracy", "start_pos": 44, "end_pos": 52, "type": "METRIC", "confidence": 0.9997653365135193}]}, {"text": "In practice, for the values of T lower than 0.6 the results are worse than 61.4% using the Dagging classifier in the 10 fold crossvalidation.", "labels": [], "entities": [{"text": "T", "start_pos": 31, "end_pos": 32, "type": "METRIC", "confidence": 0.9916600584983826}, {"text": "Dagging classifier", "start_pos": 91, "end_pos": 109, "type": "DATASET", "confidence": 0.8437482118606567}]}, {"text": "For that reason, as was mentioned in 2, we only tried to apply the first stage for values of T \u2265 0.6 . We evaluated our system in the challenge Task 4B: Sentiment Analysis in Twitter, using the provided training and test data of this challenge.", "labels": [], "entities": [{"text": "T", "start_pos": 93, "end_pos": 94, "type": "METRIC", "confidence": 0.9483639001846313}, {"text": "Sentiment Analysis", "start_pos": 153, "end_pos": 171, "type": "TASK", "confidence": 0.9364863336086273}]}, {"text": "Based on the classifier obtained in the training process we tested our system over the test dataset achieving values of %CCI up to 55.4.", "labels": [], "entities": [{"text": "CCI", "start_pos": 121, "end_pos": 124, "type": "METRIC", "confidence": 0.9085479974746704}]}, {"text": "show detailed results for each of the 5 different sources.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Results of the K-NN classifier using Lev- enshtein metric.", "labels": [], "entities": []}, {"text": " Table 2: Results of the K-NN classifier using  Matching Coefficient metric.", "labels": [], "entities": []}, {"text": " Table 3: Results in the SemEval-2014 Task 4B.", "labels": [], "entities": [{"text": "SemEval-2014 Task 4B", "start_pos": 25, "end_pos": 45, "type": "TASK", "confidence": 0.814850370089213}]}]}