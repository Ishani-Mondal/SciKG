{"title": [{"text": "University of Warwick: SENTIADAPTRON -A Domain Adaptable Sentiment Analyser for Tweets -Meets SemEval", "labels": [], "entities": [{"text": "SENTIADAPTRON", "start_pos": 23, "end_pos": 36, "type": "METRIC", "confidence": 0.946717381477356}, {"text": "SemEval", "start_pos": 94, "end_pos": 101, "type": "TASK", "confidence": 0.574306309223175}]}], "abstractContent": [{"text": "We give a brief overview of our system, SentiAdaptron, a domain-sensitive and domain adaptable system for twitter analysis in tweets, and discuss performance on SemEval (in both the constrained and un-constrained scenarios), as well as implications arising from comparing the intra-and inter-domain performance on our twitter corpus.", "labels": [], "entities": [{"text": "twitter analysis", "start_pos": 106, "end_pos": 122, "type": "TASK", "confidence": 0.6793790757656097}]}], "introductionContent": [{"text": "A domain is broadly defined as a set of documents demonstrating a similar distribution of words and linguistic patterns.", "labels": [], "entities": []}, {"text": "Task 9 of SemEval treats Twitter as a single domain with respect to sentiment analysis.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 68, "end_pos": 86, "type": "TASK", "confidence": 0.9361258745193481}]}, {"text": "However previous research has argued for the topic-specific treatment of sentiment given domain-specific nuances and the over-generality of current sentiment analysis systems with respect to applications in the social sciences).", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 148, "end_pos": 166, "type": "TASK", "confidence": 0.7515386641025543}]}, {"text": "Thelwal's method -manually extending a sentiment lexicon fora particular topic or domain -highlights that expression of sentiment varies from one domain to another.", "labels": [], "entities": []}, {"text": "Rather than relying on the manual extension of lexica, we developed an approach to Twitter sentiment classification that is domain sensitive.", "labels": [], "entities": [{"text": "Twitter sentiment classification", "start_pos": 83, "end_pos": 115, "type": "TASK", "confidence": 0.6259458263715109}]}, {"text": "To this effect we gathered tweets from three primary domainsfinancial news, political opinion, technology companies and their products -and trained our system on one domain while adapting to the other.", "labels": [], "entities": []}, {"text": "Using this methodology we obtained both intrinsic as well as extrinsic evaluation of the system on real world applications with promising results.", "labels": [], "entities": []}, {"text": "As our approach to sentiment analysis has been influenced by the task description of: The distribution of sentiment classes between SemEval and our corpus at word and tweet level.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 19, "end_pos": 37, "type": "TASK", "confidence": 0.9613699316978455}]}, {"text": "decided to also evaluate the system on SemEval's data, since it provides a well established benchmark.", "labels": [], "entities": [{"text": "SemEval's data", "start_pos": 39, "end_pos": 53, "type": "DATASET", "confidence": 0.7846898039182028}]}, {"text": "In the following we briefly describe our system and corpus and discuss our approach for the SemEval submission.", "labels": [], "entities": [{"text": "SemEval submission", "start_pos": 92, "end_pos": 110, "type": "TASK", "confidence": 0.8487862646579742}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 2: Classifier metrics obtained from 4-fold intra-domain cross-validation (using reference annota- tions) and results for subtasks A and B of SemEval task 9 (computed using reference scorer).", "labels": [], "entities": [{"text": "SemEval task 9", "start_pos": 148, "end_pos": 162, "type": "TASK", "confidence": 0.8822649518648783}]}, {"text": " Table 3: F1-scores achieved for each domain on  our corpus (naive Bayes, 10-fold cross valida- tion) using reference annotations with and without  subjective (positive, negative, neutral) proportions  (SP).", "labels": [], "entities": [{"text": "F1-scores", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9989483952522278}]}, {"text": " Table 4: Binary class metrics with structural correspondence learning on our own corpus.", "labels": [], "entities": []}, {"text": " Table 5: Classifier metrics from training and testing on different domains, with and without proportions  of positive, negative and neutral phrases from the source domain (Subjective Proportions SP).", "labels": [], "entities": []}]}