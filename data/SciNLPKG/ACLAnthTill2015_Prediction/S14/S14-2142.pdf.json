{"title": [{"text": "UTH_CCB: A Report for SemEval 2014 -Task 7 Analysis of Clinical Text", "labels": [], "entities": [{"text": "UTH_CCB", "start_pos": 0, "end_pos": 7, "type": "DATASET", "confidence": 0.7394361893335978}, {"text": "SemEval 2014 -Task 7 Analysis of Clinical Text", "start_pos": 22, "end_pos": 68, "type": "TASK", "confidence": 0.8211357129944695}]}], "abstractContent": [{"text": "This work describes the participation of the University of Texas Health Science Center at Houston (UTHealth) team on the SemEval 2014-Task 7 analysis of clinical text challenge.", "labels": [], "entities": [{"text": "SemEval 2014-Task 7 analysis of clinical text challenge", "start_pos": 121, "end_pos": 176, "type": "TASK", "confidence": 0.9149433523416519}]}, {"text": "The task consisted of two subtasks: (1) disorder entity recognition, recognizing mentions of disorder concepts; (2) disorder entity encoding, mapping each mention to a unique Concept Unique Identifier (CUI) defined in Unified Medical Language System (UMLS).", "labels": [], "entities": [{"text": "disorder entity recognition", "start_pos": 40, "end_pos": 67, "type": "TASK", "confidence": 0.640936960776647}, {"text": "disorder entity encoding", "start_pos": 116, "end_pos": 140, "type": "TASK", "confidence": 0.6550633211930593}]}, {"text": "We developed three ensemble learning approaches for recognizing disorder entities and a Vector Space Model based method for encoding.", "labels": [], "entities": []}, {"text": "Our approaches achieved top rank in both subtasks, with the best F measure of 0.813 for entity recognition and the best accuracy of 74.1% for encoding, indicating the proposed approaches are promising.", "labels": [], "entities": [{"text": "F measure", "start_pos": 65, "end_pos": 74, "type": "METRIC", "confidence": 0.9946439862251282}, {"text": "entity recognition", "start_pos": 88, "end_pos": 106, "type": "TASK", "confidence": 0.8359063863754272}, {"text": "accuracy", "start_pos": 120, "end_pos": 128, "type": "METRIC", "confidence": 0.9965589642524719}]}], "introductionContent": [{"text": "In recent years, clinical natural language processing (NLP) has received great attention for its critical role in unlocking information embedded in clinical documents.", "labels": [], "entities": [{"text": "clinical natural language processing (NLP)", "start_pos": 17, "end_pos": 59, "type": "TASK", "confidence": 0.7630192083971841}, {"text": "unlocking information embedded in clinical documents", "start_pos": 114, "end_pos": 166, "type": "TASK", "confidence": 0.8031431039174398}]}, {"text": "Leveraging such information can facilitate the secondary  Clinical entity recognition, which recognizes mentions of clinically relevant concepts (e.g., disorders, procedures, drugs etc.) in narratives, and clinical entity encoding, which maps the recognized entities to concepts in standard vocabularies (e.g., UMLS CUI), are among the fundamental tasks in clinical NLP research.", "labels": [], "entities": [{"text": "Clinical entity recognition", "start_pos": 58, "end_pos": 85, "type": "TASK", "confidence": 0.5941066841284434}, {"text": "clinical entity encoding", "start_pos": 206, "end_pos": 230, "type": "TASK", "confidence": 0.62678462266922}, {"text": "UMLS CUI", "start_pos": 311, "end_pos": 319, "type": "DATASET", "confidence": 0.8772442638874054}]}, {"text": "Many systems have been developed to extract clinical concepts from various types of clinical notes in last two decades, ranging from early symbolic NLP systems heavily dependent on domain knowledge to machine learning algorithm based systems driven by increasingly available annotated clinical corpora.", "labels": [], "entities": []}, {"text": "The representative systems include MedLEE (,,), cTAKES (, etc.", "labels": [], "entities": [{"text": "MedLEE", "start_pos": 35, "end_pos": 41, "type": "DATASET", "confidence": 0.7553694844245911}]}, {"text": "Clinical NLP challenges organized by the Center for Informatics for Integrating Biology & the Beside (i2b2) have promoted research using machine learning algorithms to recognize clinical entities (.", "labels": [], "entities": []}, {"text": "Unlike the previous i2b2 challenges, the ShARe/CLEF challenge of clinical disorder extraction and encoding held in 2013 took the initiative to recognize disjoint entities, in addition to entities made up of consecutive words.", "labels": [], "entities": [{"text": "ShARe/CLEF challenge of clinical disorder extraction and encoding", "start_pos": 41, "end_pos": 106, "type": "TASK", "confidence": 0.5845248430967331}]}, {"text": "ShARe/CLEF challenge also required encoding of the disorder entities to Systematized Nomenclature Of Medicine Clinical Terms (SNOMED-CT) (using UMLS CUIs).", "labels": [], "entities": [{"text": "ShARe/CLEF challenge", "start_pos": 0, "end_pos": 20, "type": "DATASET", "confidence": 0.7208638787269592}]}, {"text": "In this paper, we describe our system for Task 7 of SemEval 2014, which followed the requirements of 2013 ShARe/CLEF challenge.", "labels": [], "entities": [{"text": "SemEval 2014", "start_pos": 52, "end_pos": 64, "type": "TASK", "confidence": 0.773456335067749}, {"text": "ShARe/CLEF challenge", "start_pos": 106, "end_pos": 126, "type": "TASK", "confidence": 0.4674653932452202}]}, {"text": "Our system employed ensemble learning based approaches for disorder entity recognition and a Vector Space Model (VSM) based method for mapping extracted entities to CUIs of SNOMED-CT concepts.", "labels": [], "entities": [{"text": "disorder entity recognition", "start_pos": 59, "end_pos": 86, "type": "TASK", "confidence": 0.6647004087766012}]}, {"text": "Our system was top-ranked among all participating teams according to evaluation by the organizer.", "labels": [], "entities": []}], "datasetContent": [{"text": "The training and test sets of 2013 ShARe/CLEF challenge were used as the training and development sets respectively for system development in SemEval 2014 Task 7.", "labels": [], "entities": [{"text": "2013 ShARe/CLEF challenge", "start_pos": 30, "end_pos": 55, "type": "DATASET", "confidence": 0.7232883930206299}, {"text": "SemEval 2014 Task 7", "start_pos": 142, "end_pos": 161, "type": "TASK", "confidence": 0.8109759986400604}]}, {"text": "The training set consists of 199 notes and the development set has 99 notes, both of which were collected from four types of clinical notes including discharge summaries (DIS), radiology reports (RAD), and ECG/ECHO reports.", "labels": [], "entities": [{"text": "discharge summaries (DIS), radiology reports (RAD)", "start_pos": 150, "end_pos": 200, "type": "TASK", "confidence": 0.6491046710447832}, {"text": "ECG/ECHO reports", "start_pos": 206, "end_pos": 222, "type": "DATASET", "confidence": 0.7909813523292542}]}, {"text": "Based on a pre-defined guideline, disorder entities were annotated for each note and then mapped to UMLS CUIs of SNOMED-CT concepts.", "labels": [], "entities": []}, {"text": "Disorder entities not found in SNOMED-CT were marked as \"CUI-less\".", "labels": [], "entities": []}, {"text": "The training set contained 5811 disorder entities which were mapped to 1007 unique CUIs or CUI-less.", "labels": [], "entities": []}, {"text": "The development set contained 5340 disorder entities mapped to 795 CUIs or CUI-less.", "labels": [], "entities": []}, {"text": "The test set contained 133 notes, all of which were discharge summaries.", "labels": [], "entities": []}, {"text": "As the gold-standard annotation of the test set is not released by the organizer, the detailed annotation information of the test set is not available..", "labels": [], "entities": []}, {"text": "Our system was developed and trained using the enlarged training set by merging the 199 notes in the training set and the 99 notes in the development set.", "labels": [], "entities": []}, {"text": "All parameters of CRF, SSVM and Liblinear were optimized by 10-fold crossvalidation on the enlarged training dataset.", "labels": [], "entities": [{"text": "CRF", "start_pos": 18, "end_pos": 21, "type": "DATASET", "confidence": 0.7881461977958679}]}, {"text": "The performance of disorder entity recognition was evaluated by precision, recall and F-measure, which were measured in both \"strict\" and \"relaxed\" modes.", "labels": [], "entities": [{"text": "disorder entity recognition", "start_pos": 19, "end_pos": 46, "type": "TASK", "confidence": 0.6199661294619242}, {"text": "precision", "start_pos": 64, "end_pos": 73, "type": "METRIC", "confidence": 0.9997019171714783}, {"text": "recall", "start_pos": 75, "end_pos": 81, "type": "METRIC", "confidence": 0.9995100498199463}, {"text": "F-measure", "start_pos": 86, "end_pos": 95, "type": "METRIC", "confidence": 0.9992786049842834}]}, {"text": "The \"strict\" mode was defined as follows: a concept is correctly recognized if and only if it can be matched exactly to a disorder mention in the gold standard, and the \"relaxed\" mode means that a disorder mention is correctly recognized if it overlaps with any disorder mention in the gold standard.", "labels": [], "entities": []}, {"text": "For entity encoding, all participating systems were evaluated using accuracy, in \"strict\" and \"relaxed\" modes, as defined in).", "labels": [], "entities": [{"text": "entity encoding", "start_pos": 4, "end_pos": 19, "type": "TASK", "confidence": 0.8155162036418915}, {"text": "accuracy", "start_pos": 68, "end_pos": 76, "type": "METRIC", "confidence": 0.9990818500518799}]}, {"text": "show the best performance of our systems in the SemEval 2014 Task 7 as reported by the organizers, where \"P\", \"R\", \"F\" denote precision, recall and F-measure respectively.", "labels": [], "entities": [{"text": "SemEval 2014 Task 7", "start_pos": 48, "end_pos": 67, "type": "TASK", "confidence": 0.8026088923215866}, {"text": "F", "start_pos": 116, "end_pos": 117, "type": "METRIC", "confidence": 0.7134358882904053}, {"text": "precision", "start_pos": 126, "end_pos": 135, "type": "METRIC", "confidence": 0.9924197793006897}, {"text": "recall", "start_pos": 137, "end_pos": 143, "type": "METRIC", "confidence": 0.9971247315406799}, {"text": "F-measure", "start_pos": 148, "end_pos": 157, "type": "METRIC", "confidence": 0.9880620241165161}]}, {"text": "For disorder entity recognition, the ensemble ML based system outperformed the other two ensemble approaches, achieving the best Fmeasure of 0.813 under \"strict\" criterion and was ranked first in the challenge.", "labels": [], "entities": [{"text": "disorder entity recognition", "start_pos": 4, "end_pos": 31, "type": "TASK", "confidence": 0.6129737893740336}, {"text": "Fmeasure", "start_pos": 129, "end_pos": 137, "type": "METRIC", "confidence": 0.9990449547767639}]}, {"text": "For encoding, our system achieved an accuracy of 0.741 by ensemble DM under \"strict\" criterion and was again ranked first in the challenge..", "labels": [], "entities": [{"text": "encoding", "start_pos": 4, "end_pos": 12, "type": "TASK", "confidence": 0.961682915687561}, {"text": "accuracy", "start_pos": 37, "end_pos": 45, "type": "METRIC", "confidence": 0.9994146823883057}]}, {"text": "The SNOMED encoding performance of our system for the SemEval 2014 task 7.", "labels": [], "entities": [{"text": "SNOMED encoding", "start_pos": 4, "end_pos": 19, "type": "TASK", "confidence": 0.7478389739990234}, {"text": "SemEval 2014 task", "start_pos": 54, "end_pos": 71, "type": "TASK", "confidence": 0.771586537361145}]}], "tableCaptions": [{"text": " Table 1. Statistics of the dataset.", "labels": [], "entities": []}, {"text": " Table 2. The disorder recognition performance  of our system for the SemEval 2014 task 7 (%).", "labels": [], "entities": [{"text": "disorder recognition", "start_pos": 14, "end_pos": 34, "type": "TASK", "confidence": 0.7111091166734695}, {"text": "SemEval 2014 task", "start_pos": 70, "end_pos": 87, "type": "TASK", "confidence": 0.754675547281901}]}]}