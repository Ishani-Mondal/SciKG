{"title": [{"text": "UniPi: Recognition of Mentions of Disorders in Clinical Text", "labels": [], "entities": [{"text": "Recognition of Mentions of Disorders in Clinical Text", "start_pos": 7, "end_pos": 60, "type": "TASK", "confidence": 0.806202158331871}]}], "abstractContent": [{"text": "The paper describes our experiments addressing the SemEval 2014 task on the Analysis of Clinical text.", "labels": [], "entities": [{"text": "SemEval 2014 task", "start_pos": 51, "end_pos": 68, "type": "TASK", "confidence": 0.8867700298627218}, {"text": "Analysis of Clinical text", "start_pos": 76, "end_pos": 101, "type": "TASK", "confidence": 0.8809792399406433}]}, {"text": "Our approach consists in extending the techniques of NE recognition, based on sequence labelling , to address the special issues of this task, i.e. the presence of overlapping and discontiguous mentions and the requirement to map the mentions to unique iden-tifiers.", "labels": [], "entities": [{"text": "NE recognition", "start_pos": 53, "end_pos": 67, "type": "TASK", "confidence": 0.9517149031162262}]}, {"text": "We explored using supervised methods in combination with word em-beddings generated from unannotated data .", "labels": [], "entities": []}], "introductionContent": [{"text": "Clinical records provide detailed information on examination and findings of a patient consultation expressed in a narrative style.", "labels": [], "entities": []}, {"text": "Such records abound in mentions of clinical conditions, anatomical sites, medications, and procedures, whose accurate identification is crucial for any further activity of text mining.", "labels": [], "entities": [{"text": "text mining", "start_pos": 172, "end_pos": 183, "type": "TASK", "confidence": 0.8176291584968567}]}, {"text": "Many different surface forms are used to represent the same concept and the mentions are interleaved with modifiers, e.g. adjectives, verb or adverbs, or are abbreviated involving implicit terms.", "labels": [], "entities": []}, {"text": "For example, in Abdomen is soft, nontender, nondistended, negative bruits the mention occurrences are \"Abdomen nontender\" and \"Abdomen bruits\", which refer to the disorders: \"nontender abdomen\" and \"abdomininal bruit\", with only the second having a corresponding UMLS Concept Unique Identifier (CUI).", "labels": [], "entities": []}, {"text": "In this case the two mentions overlap and both are interleaved with other terms, not part of the mentions.", "labels": [], "entities": []}, {"text": "Secondly, mentions can be nested, as in this example: left pleural and parenchymal calcifications where the mention calcifications is nested within pleural calcifications.", "labels": [], "entities": []}, {"text": "Mentions of this kind area considerable departure from those dealt in typical Named Entity recognition, which are contiguous and nonoverlapping, and therefore they represents anew challenge for text analysis.", "labels": [], "entities": [{"text": "Named Entity recognition", "start_pos": 78, "end_pos": 102, "type": "TASK", "confidence": 0.6639941533406576}, {"text": "text analysis", "start_pos": 194, "end_pos": 207, "type": "TASK", "confidence": 0.812005490064621}]}, {"text": "The analysis of clinical records poses additional difficulties with respect to other biomedical NER tasks, which use corpora from the medical literature.", "labels": [], "entities": [{"text": "NER", "start_pos": 96, "end_pos": 99, "type": "TASK", "confidence": 0.7339679002761841}]}, {"text": "Clinical records are entered by medical personnel on the fly and so they contain misspellings and inconsistent use of capitalization.", "labels": [], "entities": []}, {"text": "The task 7 at SemEval 2014, Analysis of Clinical Text, addresses the problem of recognition of mentions of disorders and is divided in two parts: A. recognition of mentions of bio-medical concepts that belong to the UMLS semantic group disorders; B. mapping of each disorder mention to a unique UMLS CUI (Concept Unique Identifiers).", "labels": [], "entities": [{"text": "recognition of mentions of disorders", "start_pos": 80, "end_pos": 116, "type": "TASK", "confidence": 0.8455493569374084}]}, {"text": "The challenge organizers provided the following resources: \uf0b7 A training corpus of clinical notes from MIMIC II database manually annotated for disorder mentions and normalized to an UMLS CUI, consisting of 9432 sentences, with 5816 annotations.", "labels": [], "entities": [{"text": "MIMIC II database", "start_pos": 102, "end_pos": 119, "type": "DATASET", "confidence": 0.8754979173342387}, {"text": "UMLS CUI", "start_pos": 182, "end_pos": 190, "type": "DATASET", "confidence": 0.8290893137454987}]}, {"text": "\uf0b7 A collection of unannotated notes, consisting of 1,611,080 sentences.", "labels": [], "entities": []}, {"text": "We also had access to the UMLS ontology).", "labels": [], "entities": [{"text": "UMLS ontology", "start_pos": 26, "end_pos": 39, "type": "DATASET", "confidence": 0.8688821196556091}]}, {"text": "Our approach to portion A of the task was to adapt a sequence labeller, which provides good accuracy in Named Entity recognition in the newswire domain, to handle the peculiarities of the clinical domain.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 92, "end_pos": 100, "type": "METRIC", "confidence": 0.9987422823905945}, {"text": "Named Entity recognition", "start_pos": 104, "end_pos": 128, "type": "TASK", "confidence": 0.7840130726496378}]}, {"text": "We performed mention recognition in two steps: 1.", "labels": [], "entities": [{"text": "mention recognition", "start_pos": 13, "end_pos": 32, "type": "TASK", "confidence": 0.9777570068836212}]}, {"text": "identifying contiguous portions of a mention; 2.", "labels": [], "entities": []}, {"text": "combining separated portions of mentions into a full mention.", "labels": [], "entities": []}, {"text": "In order to use a traditional sequence tagger for the first step, we had to convert the input data into a suitable format, in particular, we dealt with nested mentions by transforming them into nonoverlapping sequences, through replication.", "labels": [], "entities": []}, {"text": "For recombining discontiguous mentions, we employed a classifier, trained to recognize whether pairs of mentions belong to the same entity.", "labels": [], "entities": []}, {"text": "The classifier was trained using also features extracted from the dependency tree of a sentence, in particular the distance of terms along the tree path.", "labels": [], "entities": []}, {"text": "Terms related by a dependency have distance 1 and terms having a common head have distance 2.", "labels": [], "entities": []}, {"text": "By limiting the pairs 1 to be considered for combination to those within distance 3, we both ensure that only plausible combinations are performed and reduce the cost of the algorithm.", "labels": [], "entities": []}, {"text": "For dealing with portion B of the task, we apply fuzzy matching) between the extracted mentions and the textual description of entities present in selected sections of UMLS disorders.", "labels": [], "entities": []}, {"text": "The CUI from the match with highest score is chosen.", "labels": [], "entities": []}, {"text": "In the following sections, we describe how we carried out the experiments, starting with the preprocessing of the data, then with the training of several versions of NE recognizer, the training of the classifier for mention combination.", "labels": [], "entities": [{"text": "NE recognizer", "start_pos": 166, "end_pos": 179, "type": "TASK", "confidence": 0.7015765309333801}]}, {"text": "We then report on the results and discuss some error analysis on the results.", "labels": [], "entities": []}], "datasetContent": [{"text": "The training corpus for the submission consisted of the merge of the train and development sets.", "labels": [], "entities": []}, {"text": "We submitted three runs, using different or differently configured NE tagger.", "labels": [], "entities": []}, {"text": "Two runs were submitted using the Tanl tagger using the features listed in, where DISEASE and CLUSTER meaning is explained earlier.", "labels": [], "entities": [{"text": "DISEASE", "start_pos": 82, "end_pos": 89, "type": "METRIC", "confidence": 0.9936320185661316}, {"text": "CLUSTER", "start_pos": 94, "end_pos": 101, "type": "METRIC", "confidence": 0.9739521741867065}]}, {"text": "Since the clustering produced few large clusters, the inclusion of this feature did not affect substantially the results.", "labels": [], "entities": []}, {"text": "After the submission, we changed the algorithm for merging mentions, in order to avoid nested spans, retaining only the larger one.", "labels": [], "entities": []}, {"text": "Tests on the development set show that this change leads to a small improvement in the strict evaluation:", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2. Word Embedding Parameters.", "labels": [], "entities": []}, {"text": " Table 3. Accuracy of various NE taggers on the  development set.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.995276689529419}]}, {"text": " Table 4. CUI identifications on the devel set.", "labels": [], "entities": [{"text": "CUI identifications", "start_pos": 10, "end_pos": 29, "type": "TASK", "confidence": 0.6200920194387436}]}, {"text": " Table 6. UniPI Task A results, compared to the  best submission.", "labels": [], "entities": []}, {"text": " Table 7. UniPI Task B results, compared to the  best submission.", "labels": [], "entities": []}, {"text": " Table 8. UniPI Task A post submission results.", "labels": [], "entities": []}]}