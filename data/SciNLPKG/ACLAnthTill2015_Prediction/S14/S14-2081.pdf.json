{"title": [{"text": "Potsdam: Semantic Dependency Parsing by Bidirectional Graph-Tree Transformations and Syntactic Parsing\u017deljko", "labels": [], "entities": []}], "abstractContent": [{"text": "We present the Potsdam systems that participated in the semantic dependency parsing shared task of SemEval 2014.", "labels": [], "entities": [{"text": "semantic dependency parsing shared task of SemEval 2014", "start_pos": 56, "end_pos": 111, "type": "TASK", "confidence": 0.6994633376598358}]}, {"text": "They are based on linguistically motivated bidi-rectional transformations between graphs and trees and on utilization of syntactic dependency parsing.", "labels": [], "entities": [{"text": "syntactic dependency parsing", "start_pos": 121, "end_pos": 149, "type": "TASK", "confidence": 0.6663481990496317}]}, {"text": "They were entered in both the closed track and the open track of the challenge, recording a peak average labeled F 1 score of 78.60.", "labels": [], "entities": [{"text": "F 1 score", "start_pos": 113, "end_pos": 122, "type": "METRIC", "confidence": 0.9506494800249735}]}], "introductionContent": [{"text": "In the semantic dependency parsing (SDP) task of SemEval 2014, the meaning of a sentence is represented in terms of binary head-argument relations between the lexical units -bi-lexical dependencies).", "labels": [], "entities": [{"text": "semantic dependency parsing (SDP) task of SemEval 2014", "start_pos": 7, "end_pos": 61, "type": "TASK", "confidence": 0.8023702323436737}]}, {"text": "Since words can be semantic dependents of multiple other words, this framework results in graph representations of sentence meaning.", "labels": [], "entities": []}, {"text": "For the SDP task, three such annotation layers are provided on top of the WSJ text of the Penn Treebank (PTB) -DM: the reduction of DeepBank HPSG annotation ( ) into bi-lexical dependencies following), -PAS: the predicate-argument structures derived from the training set of the Enju HPSG parser () and -PCEDT: a subset of the tectogrammatical annotation layer from the English side of the Prague Czech-English Dependency).", "labels": [], "entities": [{"text": "SDP task", "start_pos": 8, "end_pos": 16, "type": "TASK", "confidence": 0.930247038602829}, {"text": "WSJ text", "start_pos": 74, "end_pos": 82, "type": "DATASET", "confidence": 0.9197404086589813}, {"text": "Penn Treebank (PTB", "start_pos": 90, "end_pos": 108, "type": "DATASET", "confidence": 0.9534173458814621}, {"text": "English side of the Prague Czech-English Dependency", "start_pos": 370, "end_pos": 421, "type": "DATASET", "confidence": 0.7174763466630664}]}, {"text": "The three annotation schemes provide three directed graph representations for each PTB sen- tence, with word forms as nodes and labeled dependency relations as edges pointing from functors to arguments.", "labels": [], "entities": []}, {"text": "The SDP-annotated PTB text is split into training (sections 00-19), development (sec. 20) and testing sets (sec. 21).", "labels": [], "entities": [{"text": "SDP-annotated PTB text", "start_pos": 4, "end_pos": 26, "type": "DATASET", "confidence": 0.624031533797582}]}, {"text": "This in turn makes the SDP parsing task a problem of datadriven graph parsing, in which systems are to be trained for producing dependency graph representations of sentences respecting the three underlying schemes.", "labels": [], "entities": [{"text": "SDP parsing", "start_pos": 23, "end_pos": 34, "type": "TASK", "confidence": 0.9614754021167755}, {"text": "datadriven graph parsing", "start_pos": 53, "end_pos": 77, "type": "TASK", "confidence": 0.6406412521998087}]}, {"text": "While a number of theoretical and preliminary contributions to data-driven graph parsing exist, our goal here is to investigate the simplest approach that can achieve competitive performance.", "labels": [], "entities": [{"text": "data-driven graph parsing", "start_pos": 63, "end_pos": 88, "type": "TASK", "confidence": 0.7310336232185364}]}, {"text": "Our starting point is the observation that the SDP graphs are relatively tree-like.", "labels": [], "entities": []}, {"text": "On it, we build a system for data-driven graph parsing by (1) transforming dependency graphs into dependency trees in preprocessing, (2) training and using syntactic dependency parsers over these trees and (3) transforming their output back into graphs in postprocessing.", "labels": [], "entities": [{"text": "data-driven graph parsing", "start_pos": 29, "end_pos": 54, "type": "TASK", "confidence": 0.7440690199534098}]}, {"text": "This way, we inherit the accuracy and speed of syntactic dependency parsers.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 25, "end_pos": 33, "type": "METRIC", "confidence": 0.9995771050453186}, {"text": "speed", "start_pos": 38, "end_pos": 43, "type": "METRIC", "confidence": 0.9733009338378906}]}, {"text": "The secondary benefit is insight into the structure of the semantic representations, as graph-tree transformations can make the phenomena that require non-tree-like structures more explicit.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Basic statistics for the training sets.", "labels": [], "entities": []}, {"text": " Table 2: Upper bound LF scores on the develop- ment set for LOCAL and DFS conversion compared  to the baseline. This score indicates the quality of  graph-tree transformation as no parsing is done.", "labels": [], "entities": [{"text": "DFS conversion", "start_pos": 71, "end_pos": 85, "type": "TASK", "confidence": 0.7184935510158539}]}, {"text": " Table 3: Top node detection accuracy with CRFs  on the development set for the three annotations.  Precision (P), recall (R) and the F 1 scores relate to  marking tokens with the binary top node flag.", "labels": [], "entities": [{"text": "Top node detection", "start_pos": 10, "end_pos": 28, "type": "TASK", "confidence": 0.6102943221728007}, {"text": "accuracy", "start_pos": 29, "end_pos": 37, "type": "METRIC", "confidence": 0.9748134613037109}, {"text": "Precision (P)", "start_pos": 100, "end_pos": 113, "type": "METRIC", "confidence": 0.9624015837907791}, {"text": "recall (R)", "start_pos": 115, "end_pos": 125, "type": "METRIC", "confidence": 0.9581511169672012}, {"text": "F 1 scores", "start_pos": 134, "end_pos": 144, "type": "METRIC", "confidence": 0.9652905861536661}]}, {"text": " Table 4: Syntactic dependency parsing accuracy  of our systems before the tree-to-graph transfor- mations, given as a set of labeled (LAS) and un- labeled (UAS) attachment scores. The scores are  given for the development set.", "labels": [], "entities": [{"text": "Syntactic dependency parsing", "start_pos": 10, "end_pos": 38, "type": "TASK", "confidence": 0.7033963998158773}, {"text": "accuracy", "start_pos": 39, "end_pos": 47, "type": "METRIC", "confidence": 0.9295955300331116}]}, {"text": " Table 4. The scores correlate with the label  set sizes, with a notable difference between the la- beled (LAS) and unlabeled (UAS) attachment score  for PCEDT. The LOCAL approach tends to out- perform DFS for PCEDT, while DFS parsers also  significantly outperform LOCAL for DM and PAS.  The open track parsers tend to perform a little bet- ter as they make use of the additional features.", "labels": [], "entities": [{"text": "UAS) attachment score", "start_pos": 127, "end_pos": 148, "type": "METRIC", "confidence": 0.776124432682991}]}, {"text": " Table 6: Breakdown of the scores for our LOCAL and DFS systems on the test sets. We provide labeled  and unlabeled precision (LP, UP), recall (LR, UR), F 1 scores (LF, UF) and exact matches (LM, UM) for  all three annotations in both the closed and the open evaluation track.", "labels": [], "entities": [{"text": "precision (LP, UP)", "start_pos": 116, "end_pos": 134, "type": "METRIC", "confidence": 0.8532947699228922}, {"text": "recall", "start_pos": 136, "end_pos": 142, "type": "METRIC", "confidence": 0.9964184761047363}, {"text": "F 1 scores", "start_pos": 153, "end_pos": 163, "type": "METRIC", "confidence": 0.9750805695851644}, {"text": "exact matches", "start_pos": 177, "end_pos": 190, "type": "METRIC", "confidence": 0.9520131349563599}]}]}