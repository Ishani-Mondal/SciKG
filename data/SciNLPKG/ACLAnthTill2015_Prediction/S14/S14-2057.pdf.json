{"title": [{"text": "Indian Institute of Technology-Patna: Sentiment Analysis in Twitter", "labels": [], "entities": [{"text": "Indian Institute of Technology-Patna", "start_pos": 0, "end_pos": 36, "type": "DATASET", "confidence": 0.7892326712608337}, {"text": "Sentiment Analysis", "start_pos": 38, "end_pos": 56, "type": "TASK", "confidence": 0.8495990931987762}]}], "abstractContent": [{"text": "This paper is an overview of the system submitted to the SemEval-2014 shared task on sentiment analysis in twitter.", "labels": [], "entities": [{"text": "SemEval-2014 shared task", "start_pos": 57, "end_pos": 81, "type": "TASK", "confidence": 0.5723215341567993}, {"text": "sentiment analysis in twitter", "start_pos": 85, "end_pos": 114, "type": "TASK", "confidence": 0.811369314789772}]}, {"text": "For the very first time we participated in both the tasks, viz contextual polarity disam-biguation and message polarity classification.", "labels": [], "entities": [{"text": "contextual polarity disam-biguation", "start_pos": 63, "end_pos": 98, "type": "TASK", "confidence": 0.6073617935180664}, {"text": "message polarity classification", "start_pos": 103, "end_pos": 134, "type": "TASK", "confidence": 0.8177629907925924}]}, {"text": "Our approach is supervised in nature and we use sequential minimal optimization classifier.", "labels": [], "entities": []}, {"text": "We implement the features for sentiment analysis without using deep domain-specific resources and/or tools.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 30, "end_pos": 48, "type": "TASK", "confidence": 0.9745601415634155}]}, {"text": "Experiments within the benchmark setup of SemEval-14 shows the F-scores of 77.99%, 75.99%, 76.54 %, 76.43% and 71.", "labels": [], "entities": [{"text": "F-scores", "start_pos": 63, "end_pos": 71, "type": "METRIC", "confidence": 0.9993141889572144}]}], "introductionContent": [{"text": "In current era microblogging is an efficient way of communication where people can communicate without physical presence of receiver(s).", "labels": [], "entities": []}, {"text": "Twitter is the medium where people post real time messages to discuss on the different topics, and express their sentiments.", "labels": [], "entities": []}, {"text": "The texts used in twitter are generally informal and unstructured in nature.", "labels": [], "entities": []}, {"text": "Tweets and SMS messages are very short in length, usually a sentence or a headline rather than a document.", "labels": [], "entities": []}, {"text": "These texts are very informal in nature and contains creative spellings and punctuation symbols.", "labels": [], "entities": []}, {"text": "Text also contains lots of misspellings, slang, out-of-vocabulary words, URLs, and genre-specific terminology and abbreviations, e.g., RT for re-Tweet and #hashtags.", "labels": [], "entities": []}, {"text": "Such kinds of structures introduce difficulties in building various lexical and syntactic resources and/or tools, which are required for efficient processing of texts.", "labels": [], "entities": []}, {"text": "Finding relevant information from these posts poses big challenges to the researchers compared to the traditional text genres such as newswire.", "labels": [], "entities": []}, {"text": "In recent times, there has been a huge interest to mine and understand the opinions and sentiments that people are communicating in social media ().", "labels": [], "entities": []}, {"text": "There is a tremendous interest in sentiment analysis of Tweets across a variety of domains such as commerce (), health) and disaster management.) used tree kernel decision tree that made use of the features such as Partof-Speech (PoS) information, lexicon-based features and several other features.", "labels": [], "entities": [{"text": "sentiment analysis of Tweets", "start_pos": 34, "end_pos": 62, "type": "TASK", "confidence": 0.8877640813589096}]}, {"text": "They acquired 11,875 manually annotated Twitter data (Tweets) from a commercial source, and reported an accuracy of 75.39%.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 104, "end_pos": 112, "type": "METRIC", "confidence": 0.9994142055511475}]}, {"text": "Semantics has also been used as the feature to improve the performance of sentiment analysis).", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 74, "end_pos": 92, "type": "TASK", "confidence": 0.9477437138557434}]}, {"text": "For each extracted entity (e.g. iPhone) from Tweets, they added its semantic concept (e.g. Apple product) as an additional feature.", "labels": [], "entities": []}, {"text": "Thereafter they devised a method to measure the correlation of the representative concept with negative/positive sentiment, and applied this approach to predict sentiment for three different Twitter datasets.", "labels": [], "entities": []}, {"text": "They showed that semantic features produce better recall and F-score when classifying negative sentiment, and better precision with lower recall and F-score in positive sentiment classification.", "labels": [], "entities": [{"text": "recall", "start_pos": 50, "end_pos": 56, "type": "METRIC", "confidence": 0.9993618130683899}, {"text": "F-score", "start_pos": 61, "end_pos": 68, "type": "METRIC", "confidence": 0.997569739818573}, {"text": "classifying negative sentiment", "start_pos": 74, "end_pos": 104, "type": "TASK", "confidence": 0.8469657301902771}, {"text": "precision", "start_pos": 117, "end_pos": 126, "type": "METRIC", "confidence": 0.9991087317466736}, {"text": "recall", "start_pos": 138, "end_pos": 144, "type": "METRIC", "confidence": 0.9986472725868225}, {"text": "F-score", "start_pos": 149, "end_pos": 156, "type": "METRIC", "confidence": 0.9885997772216797}, {"text": "positive sentiment classification", "start_pos": 160, "end_pos": 193, "type": "TASK", "confidence": 0.6954526305198669}]}, {"text": "The benchmark corpus were made available with the SemEval-2013 shared task () on sentiment analysis in twitter.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 81, "end_pos": 99, "type": "TASK", "confidence": 0.9458930790424347}]}, {"text": "The datasets used are from the domains of Tweets and SMS messages.", "labels": [], "entities": []}, {"text": "The datasets were labelled with contextual phraselevel polarity and overall message-level polarity.", "labels": [], "entities": []}, {"text": "Among the 44 submissions, the support vector machine based system proposed in) achieved the highest F-scores of 69.02% for Task A, i.e. the message-level polarity and and 88.93% for Task B, i.e. term-level polarity.", "labels": [], "entities": [{"text": "F-scores", "start_pos": 100, "end_pos": 108, "type": "METRIC", "confidence": 0.9987190961837769}]}, {"text": "The issues addressed in SemEval-13 are further extended in SemEval-14 shared task 1 . The same two tasks, viz.", "labels": [], "entities": []}, {"text": "Subtask A and Subtask B denoting contextual polarity disambiguation and message polarity classification.", "labels": [], "entities": [{"text": "message polarity classification", "start_pos": 72, "end_pos": 103, "type": "TASK", "confidence": 0.7523047924041748}]}, {"text": "The goal of Subtask A is to determine, fora given message containing a marked instance of a word or phrase, whether that instance is positive, negative or neutral in that context.", "labels": [], "entities": [{"text": "Subtask A", "start_pos": 12, "end_pos": 21, "type": "TASK", "confidence": 0.8741548359394073}]}, {"text": "Given a message, the task is to classify it with its entirety whether it is positive, negative, or neutral sentiment.", "labels": [], "entities": []}, {"text": "For messages that convey both positive and negative sentiments, the stronger one should be chosen.", "labels": [], "entities": []}, {"text": "In this paper we report on our submitted systems for both the tasks.", "labels": [], "entities": []}, {"text": "Our evaluation for the first task shows the F-scores of 77.99%, 75.99%, 76.54%, 76.43% and 71.43% for LiveJournal2014, SMS2013, Twitter2013, Twitter2014 and Twitter2014Sarcasm, respectively for Subtask A. For Subtask B we obtain the F-scores of 60.39%, 51.96%, 52.58%, 57.25%, 41.33% for five different test sets, respectively.", "labels": [], "entities": [{"text": "F-scores", "start_pos": 44, "end_pos": 52, "type": "METRIC", "confidence": 0.9981690645217896}, {"text": "Twitter2014", "start_pos": 141, "end_pos": 152, "type": "DATASET", "confidence": 0.9030587077140808}, {"text": "F-scores", "start_pos": 233, "end_pos": 241, "type": "METRIC", "confidence": 0.9949713945388794}]}], "datasetContent": [{"text": "SemEval-2014 shared task is a continuation of the SemEval-2013 shared task.", "labels": [], "entities": [{"text": "SemEval-2014", "start_pos": 0, "end_pos": 12, "type": "DATASET", "confidence": 0.8059983849525452}]}, {"text": "In 2014 shared task, datasets from different domains were incorporated with a wide range of topics, including a mixture of entities, products and events.", "labels": [], "entities": []}, {"text": "Messages relevant to the topics are selected based on the keywords and twitter hashtags.", "labels": [], "entities": []}, {"text": "The training set of Task-A has 4,914 positive, 2,592 negative and 384 neutral class instances.", "labels": [], "entities": []}, {"text": "The Task-B training set contains 3,057 positive, 1,200 negative and 3,941 neutral sentiments.", "labels": [], "entities": [{"text": "Task-B training set", "start_pos": 4, "end_pos": 23, "type": "DATASET", "confidence": 0.6364725331465403}]}, {"text": "Developments sets contain 555, 45 and 365 positive, negative and neutral sentiments, respectively for the first task; and 493, 288 and 632 positive, negative and neutral sentiments, respectively for the second task.", "labels": [], "entities": []}, {"text": "The selected test sets were taken mainly from the following domains: LiveJournal2014: 2000 sentences from LiveJournal blogs; SMS2013: SMS test from last year-used as a progress test for comparison; Twitter2013: Twitter test data from last year-used as a progress test for comparison;: Results for Task-A on development set(in %).", "labels": [], "entities": [{"text": "Twitter2013: Twitter test data", "start_pos": 198, "end_pos": 228, "type": "DATASET", "confidence": 0.6681446373462677}]}], "tableCaptions": [{"text": " Table 1: Results for Task-A on development set(in  %).", "labels": [], "entities": []}, {"text": " Table 2: Result on test sets for Task-A and Task-B.", "labels": [], "entities": []}]}