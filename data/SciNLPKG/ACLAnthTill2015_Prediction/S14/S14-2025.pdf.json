{"title": [{"text": "CISUC-KIS: Tackling Message Polarity Classification with a Large and Diverse set of Features", "labels": [], "entities": [{"text": "CISUC-KIS", "start_pos": 0, "end_pos": 9, "type": "DATASET", "confidence": 0.9241642355918884}, {"text": "Tackling Message Polarity Classification", "start_pos": 11, "end_pos": 51, "type": "TASK", "confidence": 0.9228420555591583}]}], "abstractContent": [{"text": "This paper presents the approach of the CISUC-KIS team to the SemEval 2014 task on Sentiment Analysis in Twitter, more precisely subtask B-Message Polarity Classification.", "labels": [], "entities": [{"text": "CISUC-KIS", "start_pos": 40, "end_pos": 49, "type": "DATASET", "confidence": 0.9065020680427551}, {"text": "SemEval 2014 task", "start_pos": 62, "end_pos": 79, "type": "TASK", "confidence": 0.8380259474118551}, {"text": "Sentiment Analysis in Twitter", "start_pos": 83, "end_pos": 112, "type": "TASK", "confidence": 0.8794664293527603}, {"text": "subtask B-Message Polarity Classification", "start_pos": 129, "end_pos": 170, "type": "TASK", "confidence": 0.6553770899772644}]}, {"text": "We followed a machine learning approach where a SVM classifier was trained from a large and diverse set of features that included lexical, syntactic , sentiment and semantic-based aspects.", "labels": [], "entities": []}, {"text": "This led to very interesting results which, in different datasets, put us always in the top-7 scores, including second position in the LiveJournal2014 dataset.", "labels": [], "entities": [{"text": "LiveJournal2014 dataset", "start_pos": 135, "end_pos": 158, "type": "DATASET", "confidence": 0.9889803528785706}]}], "introductionContent": [{"text": "Everyday people transmit their opinion in social networks and microblogging services.", "labels": [], "entities": []}, {"text": "Identifying the sentiment transmitted in all those shared messages is of great utility for recognizing trends and supporting decision making, key in areas such as social marketing.", "labels": [], "entities": []}, {"text": "Sentiment Analysis deals with the computational treatment of sentiments in natural language text, often normalized to positive or negative polarities.", "labels": [], "entities": [{"text": "Sentiment Analysis", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.9286603331565857}, {"text": "computational treatment of sentiments in natural language text", "start_pos": 34, "end_pos": 96, "type": "TASK", "confidence": 0.7530359700322151}]}, {"text": "It is a very challenging task, not only for machines, but also for humans.", "labels": [], "entities": []}, {"text": "SemEval 2014 is a semantic evaluation of Natural Language Processing (NLP) that comprises several tasks.", "labels": [], "entities": [{"text": "semantic evaluation of Natural Language Processing (NLP)", "start_pos": 18, "end_pos": 74, "type": "TASK", "confidence": 0.6597568028502994}]}, {"text": "This paper describes our approach to the Sentiment Analysis in Twitter task, which comprises two subtasks: (A) Contextual Polarity Disambiguation; and (B) Message Polarity Classification.", "labels": [], "entities": [{"text": "Sentiment Analysis in Twitter task", "start_pos": 41, "end_pos": 75, "type": "TASK", "confidence": 0.932388436794281}, {"text": "Contextual Polarity Disambiguation", "start_pos": 111, "end_pos": 145, "type": "TASK", "confidence": 0.5769110918045044}, {"text": "Message Polarity Classification", "start_pos": 155, "end_pos": 186, "type": "TASK", "confidence": 0.7494587699572245}]}, {"text": "We ended up addressing only task B, which is more sentence oriented, as it targets the polarity of the full messages and not individual words in those messages.", "labels": [], "entities": []}, {"text": "We tackled this task with a machine learningbased approach, in which we first collect several features from the analysis of the given text at several levels.", "labels": [], "entities": []}, {"text": "The collected features are then used to learn a sentiment classification model, which can be done with different algorithms.", "labels": [], "entities": [{"text": "sentiment classification", "start_pos": 48, "end_pos": 72, "type": "TASK", "confidence": 0.9338587522506714}]}, {"text": "Features were collected from several different resources, including: sentiment lexicons, dictionaries and available APIs for this task.", "labels": [], "entities": []}, {"text": "Moreover, since microblogging text has particular characteristics that increase the difficulty of NLP, we gave special focus on text pre-processing.", "labels": [], "entities": []}, {"text": "Regarding the tested features, they went from low-level ones, such as punctuation and emoticons, to more high-level, including topics extracted using topic modelling techniques, as well features from sentiment lexicons, some structured on plain words and others based on WordNet, and thus structured on word senses.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 271, "end_pos": 278, "type": "DATASET", "confidence": 0.9259932637214661}]}, {"text": "Using the latter, we even explored word sense disambiguation.", "labels": [], "entities": [{"text": "word sense disambiguation", "start_pos": 35, "end_pos": 60, "type": "TASK", "confidence": 0.7528238892555237}]}, {"text": "We tested several learning algorithms with all these features, but Support Vector Machines (SVM) led to the best results, so it was used for the final evaluation.", "labels": [], "entities": []}, {"text": "In all our runs, a model was learned from tweets, and no SMS were used for training.", "labels": [], "entities": []}, {"text": "The model's performance was assessed with the FScore of positive and negative classes, with 10-fold cross validation.", "labels": [], "entities": [{"text": "FScore", "start_pos": 46, "end_pos": 52, "type": "METRIC", "confidence": 0.9983072280883789}]}, {"text": "In the official evaluation, we achieved very interesting scores, namely: 74.46% for the LiveJournal2014 (2nd place), 65.9% for the SMS2013 (7th), 67.56% for the Twitter2013 (7th), 67.95% for the Twitter2014 (4th) and 55.49% for the Twitter2014Sarcasm (4th) datasets, which ranked us always among the top-7 participations.", "labels": [], "entities": [{"text": "SMS2013", "start_pos": 131, "end_pos": 138, "type": "DATASET", "confidence": 0.9007964134216309}, {"text": "Twitter2013", "start_pos": 161, "end_pos": 172, "type": "DATASET", "confidence": 0.956121027469635}, {"text": "Twitter2014", "start_pos": 195, "end_pos": 206, "type": "DATASET", "confidence": 0.9631950259208679}, {"text": "Twitter2014Sarcasm (4th) datasets", "start_pos": 232, "end_pos": 265, "type": "DATASET", "confidence": 0.7207942366600036}]}, {"text": "The next section describes the external resources exploited.", "labels": [], "entities": []}, {"text": "Section 3 presents our approach with more detail, and is followed by section 4, where the experimental results are described.", "labels": [], "entities": []}, {"text": "Section 5 concludes with a brief balance and the main lessons learned from our participation.", "labels": [], "entities": []}], "datasetContent": [{"text": "For training the SVM classifier, we used a set of 9,634 tweets with a known polarity and also 1,281 tweets as development test to grid search the best parameters.", "labels": [], "entities": [{"text": "SVM classifier", "start_pos": 17, "end_pos": 31, "type": "TASK", "confidence": 0.7651265859603882}]}, {"text": "No SMS messages were used as training or as development test.", "labels": [], "entities": []}, {"text": "For the scorer function, we used a macro-averaged F-Score of positive and negative classes -the one made available and used by the task organizers.", "labels": [], "entities": [{"text": "F-Score", "start_pos": 50, "end_pos": 57, "type": "METRIC", "confidence": 0.9294165372848511}]}], "tableCaptions": []}