{"title": [{"text": "haLF: Comparing a Pure CDSM Approach with a Standard Machine Learning System for RTE", "labels": [], "entities": [{"text": "haLF", "start_pos": 0, "end_pos": 4, "type": "METRIC", "confidence": 0.6238430142402649}, {"text": "RTE", "start_pos": 81, "end_pos": 84, "type": "TASK", "confidence": 0.5282270312309265}]}], "abstractContent": [{"text": "In this paper, we describe our submission to the Shared Task #1.", "labels": [], "entities": [{"text": "Shared Task #1", "start_pos": 49, "end_pos": 63, "type": "TASK", "confidence": 0.7605428546667099}]}, {"text": "We tried to follow the underlying idea of the task, that is, evaluating the gap of full-fledged recognizing textual en-tailment systems with respect to com-positional distributional semantic models (CDSMs) applied to this task.", "labels": [], "entities": []}, {"text": "We thus submitted two runs: 1) a system obtained with a machine learning approach based on the feature spaces of rules with variables and 2) a system completely based on a CDSM that mixes structural and syntactic information by using distributed tree kernels.", "labels": [], "entities": []}, {"text": "Our analysis shows that, under the same conditions, the fully CDSM system is still far from being competitive with more complex methods.", "labels": [], "entities": []}], "introductionContent": [{"text": "Recognizing Textual Entailment is a largely explored problem ().", "labels": [], "entities": [{"text": "Recognizing Textual Entailment", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.898187001546224}]}, {"text": "Past challenges (;) explored methods and models applied in complex and natural texts.", "labels": [], "entities": []}, {"text": "In this context, machine learning solutions show interesting results.", "labels": [], "entities": []}, {"text": "The Shared Task #1 of SemEval instead wants to explore systems in a more controlled textual environment where the phenomena to model are clearer.", "labels": [], "entities": []}, {"text": "The aim of the Shared Task is to study how RTE systems built upon compositional distributional semantic models behave with respect to the above tradition.", "labels": [], "entities": [{"text": "RTE", "start_pos": 43, "end_pos": 46, "type": "TASK", "confidence": 0.9497436285018921}]}, {"text": "We tried to capture this underlying idea of the task.", "labels": [], "entities": []}, {"text": "In this paper, we describe our submission to the Shared Task #1.", "labels": [], "entities": [{"text": "Shared Task #1", "start_pos": 49, "end_pos": 63, "type": "TASK", "confidence": 0.7605428546667099}]}, {"text": "We tried to follow the underlying idea of the task, that is, evaluating the gap of full-fledged recognizing textual entailment systems with respect to compositional distributional semantic models (CDSMs) applied to this task.", "labels": [], "entities": []}, {"text": "We thus submitted two runs: 1) a system obtained with a machine learning approach based on the feature spaces of rules with variables () and 2) a system completely based on a CDSM that mixes structural and syntactic information by using distributed tree kernels ().", "labels": [], "entities": []}, {"text": "Our analysis shows that, under the same conditions, the fully CDSM system is still far from being competitive with more complete methods.", "labels": [], "entities": []}, {"text": "The rest of the paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 describes the full-fledged recognizing textual entailment system that is used for comparison.", "labels": [], "entities": []}, {"text": "Section 3 introduces a novel compositional distributional semantic model, namely, the distributed smoothed tree kernels, and the way this model is applied to the task of RTE.", "labels": [], "entities": [{"text": "RTE", "start_pos": 170, "end_pos": 173, "type": "TASK", "confidence": 0.8430313467979431}]}, {"text": "Section 4 describes the results in the challenge and it draws some preliminary conclusions.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Accuracies of the two systems on the  test set, together with the maximum, mini- mum and average score for the challenge.", "labels": [], "entities": [{"text": "Accuracies", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.9979832172393799}, {"text": "mini- mum and average score", "start_pos": 85, "end_pos": 112, "type": "METRIC", "confidence": 0.6399514973163605}]}]}