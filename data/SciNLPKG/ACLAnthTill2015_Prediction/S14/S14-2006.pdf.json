{"title": [{"text": "SemEval-2014 Task 6: Supervised Semantic Parsing of Robotic Spatial Commands", "labels": [], "entities": [{"text": "Supervised Semantic Parsing of Robotic Spatial Commands", "start_pos": 21, "end_pos": 76, "type": "TASK", "confidence": 0.7200031110218593}]}], "abstractContent": [{"text": "SemEval-2014 Task 6 aims to advance semantic parsing research by providing a high-quality annotated dataset to compare and evaluate approaches.", "labels": [], "entities": [{"text": "semantic parsing research", "start_pos": 36, "end_pos": 61, "type": "TASK", "confidence": 0.8524053692817688}]}, {"text": "The task focuses on contextual parsing of robotic commands, in which the additional context of spatial scenes can be used to guide a parser to control a robot arm.", "labels": [], "entities": [{"text": "contextual parsing of robotic commands", "start_pos": 20, "end_pos": 58, "type": "TASK", "confidence": 0.7389081478118896}]}, {"text": "Six teams submitted systems using both rule-based and statistical methods.", "labels": [], "entities": []}, {"text": "The best performing (hybrid) system scored 92.5% and 90.5% for parsing with and without spatial context.", "labels": [], "entities": [{"text": "parsing", "start_pos": 63, "end_pos": 70, "type": "TASK", "confidence": 0.9749661684036255}]}, {"text": "However, the best performing statistical system scored 87.35% and 60.84% respectively, indicating that generalized understanding of commands given to a robot remains challenging, despite the fixed domain used for the task.", "labels": [], "entities": [{"text": "generalized understanding of commands given", "start_pos": 103, "end_pos": 146, "type": "TASK", "confidence": 0.7473176717758179}]}], "introductionContent": [{"text": "Semantic parsers analyze sentences to produce formal meaning representations that are used for the computational understanding of natural language.", "labels": [], "entities": []}, {"text": "Recently, state-of-the-art semantic parsing methods have used fora variety of applications, including question answering, dialog systems (, entity relation extraction and robotic control.", "labels": [], "entities": [{"text": "semantic parsing", "start_pos": 27, "end_pos": 43, "type": "TASK", "confidence": 0.770896852016449}, {"text": "question answering", "start_pos": 102, "end_pos": 120, "type": "TASK", "confidence": 0.9184392094612122}, {"text": "entity relation extraction", "start_pos": 140, "end_pos": 166, "type": "TASK", "confidence": 0.6574193437894186}]}, {"text": "Different parsers can be distinguished by the level of supervision they require during training.", "labels": [], "entities": []}, {"text": "Fully supervised training typically requires an annotated dataset that maps natural language (NL) to a formal meaning representation such as logical form.", "labels": [], "entities": []}, {"text": "However, because annotated data is often not available, a recent trend in semantic parsing research has been to eschew supervised training in favour of either unsupervised or weakly-supervised methods that utilize additional information.", "labels": [], "entities": [{"text": "semantic parsing", "start_pos": 74, "end_pos": 90, "type": "TASK", "confidence": 0.8190549910068512}]}, {"text": "For example, Berant and Liang (2014) use a dataset of 5,810 questionanswer pairs without annotated logical forms to induce a parser fora question-answering system.", "labels": [], "entities": []}, {"text": "In comparison, Poon (2013) converts NL questions into formal queries via indirect supervision through database interaction.", "labels": [], "entities": []}, {"text": "In contrast to previous work, the shared task described in this paper uses the Robot Commands Treebank), anew dataset made available for supervised semantic parsing.", "labels": [], "entities": [{"text": "Robot Commands Treebank", "start_pos": 79, "end_pos": 102, "type": "DATASET", "confidence": 0.5568916300932566}, {"text": "supervised semantic parsing", "start_pos": 137, "end_pos": 164, "type": "TASK", "confidence": 0.6802770594755808}]}, {"text": "The chosen domain is robotic control, in which NL commands are given to a robot arm used to manipulate shapes on an 8 x 8 game board.", "labels": [], "entities": []}, {"text": "Despite the fixed domain, the task is challenging as correctly parsing commands requires understanding spatial context.", "labels": [], "entities": []}, {"text": "For example, the command in may have several plausible interpretations, given different board configurations.", "labels": [], "entities": []}, {"text": "'Move the pyramid on the blue cube on the gray one.'", "labels": [], "entities": []}, {"text": "The task is inspired by the classic AI system SHRLDU, which responded to NL commands to control a robot fora similar game board), although that system is reported to not have generalized well).", "labels": [], "entities": []}, {"text": "More recent research in command understanding has focused on parsing jointly with grounding, the process of mapping NL descriptions of entities within an environment to a semantic representation.", "labels": [], "entities": [{"text": "command understanding", "start_pos": 24, "end_pos": 45, "type": "TASK", "confidence": 0.7417415380477905}, {"text": "parsing", "start_pos": 61, "end_pos": 68, "type": "TASK", "confidence": 0.9673287272453308}]}, {"text": "Previous work includes, who develop a small corpus of commands fora simulated forklift robot, with grounding performed using a factor graph.", "labels": [], "entities": []}, {"text": "Similarly, perform joint parsing and grounding using a corpus of navigation commands.", "labels": [], "entities": [{"text": "joint parsing", "start_pos": 19, "end_pos": 32, "type": "TASK", "confidence": 0.5391068607568741}]}, {"text": "In contrast, this paper focuses on parsing using additional situational context for disambiguation and by using a larger NL dataset, in comparison to previous robotics research.", "labels": [], "entities": [{"text": "parsing", "start_pos": 35, "end_pos": 42, "type": "TASK", "confidence": 0.9769336581230164}, {"text": "NL dataset", "start_pos": 121, "end_pos": 131, "type": "DATASET", "confidence": 0.657603994011879}]}, {"text": "In the remainder of this paper, we describe the task, the dataset and the metrics used for evaluation.", "labels": [], "entities": []}, {"text": "We then compare the approaches used by participant systems and conclude with suggested improvements for future work.", "labels": [], "entities": []}], "datasetContent": [{"text": "Out of the 3,400 sentences annotated for the task, 2,500 sentences were provided to participants for system training.", "labels": [], "entities": []}, {"text": "During evaluation, trained systems were presented with 909 previously unseen sentences and asked to generate corresponding RCL statements, with access to the spatial planner for additional context.", "labels": [], "entities": []}, {"text": "To keep the evaluation process as simple as possible, each parser's output fora sentence was scored as correct if it exactly matched the expected RCL statement in the treebank.", "labels": [], "entities": []}, {"text": "Participants were asked to calculate two metrics, P and NP, which are the proportion of exact matches with and without using the spatial planner respectively:: System results for supervised semantic parsing of the Robot Commands Treebank (P = parsing with integrated spatial planning, NP = parsing without integrated spatial planning, NP -P = drop in performance without integrated spatial planning, N/A = performance not available).", "labels": [], "entities": [{"text": "supervised semantic parsing", "start_pos": 179, "end_pos": 206, "type": "TASK", "confidence": 0.6863592465718588}, {"text": "Robot Commands Treebank", "start_pos": 214, "end_pos": 237, "type": "DATASET", "confidence": 0.5755052963892618}]}, {"text": "These metrics contrast with measures for partially correct parsed structures, such as Parseval ( or the leaf-ancestor metric).", "labels": [], "entities": [{"text": "Parseval", "start_pos": 86, "end_pos": 94, "type": "METRIC", "confidence": 0.8546735644340515}]}, {"text": "The rationale for using a strict match is that in the integrated system, a command will only be executed if it is completely understood, as both the spatial planner and the simulator require well-formed RCL.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 3: System results for supervised semantic parsing of the Robot Commands Treebank  (P = parsing with integrated spatial planning, NP = parsing without integrated spatial planning,  NP -P = drop in performance without integrated spatial planning, N/A = performance not available).", "labels": [], "entities": [{"text": "supervised semantic parsing", "start_pos": 29, "end_pos": 56, "type": "TASK", "confidence": 0.6817094683647156}, {"text": "Robot Commands Treebank", "start_pos": 64, "end_pos": 87, "type": "DATASET", "confidence": 0.5627604524294535}]}]}