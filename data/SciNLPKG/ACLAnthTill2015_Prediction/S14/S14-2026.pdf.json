{"title": [{"text": "Citius: A Naive-Bayes Strategy for Sentiment Analysis on English Tweets *", "labels": [], "entities": [{"text": "Sentiment Analysis on English Tweets", "start_pos": 35, "end_pos": 71, "type": "TASK", "confidence": 0.858559000492096}]}], "abstractContent": [{"text": "This article describes a strategy based on a naive-bayes classifier for detecting the polarity of English tweets.", "labels": [], "entities": [{"text": "detecting the polarity of English tweets", "start_pos": 72, "end_pos": 112, "type": "TASK", "confidence": 0.756727268298467}]}, {"text": "The experiments have shown that the best performance is achieved by using a binary classifier between just two sharp polarity categories: positive and negative.", "labels": [], "entities": []}, {"text": "In addition, in order to detect tweets with and without polarity , the system makes use of a very basic rule that searchs for polarity words within the analysed tweets/texts.", "labels": [], "entities": []}, {"text": "When the clas-sifier is provided with a polarity lexicon and multiwords it achieves 63% F-score.", "labels": [], "entities": [{"text": "F-score", "start_pos": 88, "end_pos": 95, "type": "METRIC", "confidence": 0.9988640546798706}]}], "introductionContent": [{"text": "Sentiment Analysis consists in finding the opinion (e.g. positive, negative, or neutral) from text documents such as movie reviews or product reviews.", "labels": [], "entities": [{"text": "Sentiment Analysis", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.9446910321712494}]}, {"text": "Opinions about movies, products, etc.", "labels": [], "entities": []}, {"text": "can be found in web blogs, social networks, discussion forums, and soon.", "labels": [], "entities": []}, {"text": "Companies can improve their products and services on the basis of the reviews and comments of their costumers.", "labels": [], "entities": []}, {"text": "Recently, many works have stressed the microblogging service Twitter.", "labels": [], "entities": []}, {"text": "As Twitter can be seen as a large source of short texts (tweets) containing user opinions, most of these works make sentiment analysis by identifying user attitudes and opinions toward a particular topic or product ().", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 116, "end_pos": 134, "type": "TASK", "confidence": 0.8767674565315247}]}, {"text": "The task of making sentiment analysis from tweets is a hard challenge.", "labels": [], "entities": [{"text": "making sentiment analysis from tweets", "start_pos": 12, "end_pos": 49, "type": "TASK", "confidence": 0.7790753841400146}]}, {"text": "On the one hand, as in any sentiment analysis framework, we have to deal with human subjectivity.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 27, "end_pos": 45, "type": "TASK", "confidence": 0.9511137008666992}]}, {"text": "Even humans often disagree on * This work has been supported by the projects: HPC-PLN: Ref:EM13/041 (Program Emergentes, Xunta de Galicia), Celtic: Ref:2012-CE138 and Plastic: Ref:2013-CE298 This work is licensed under a Creative Commons Attribution 4.0 International Licence.", "labels": [], "entities": [{"text": "HPC-PLN", "start_pos": 78, "end_pos": 85, "type": "DATASET", "confidence": 0.9539564251899719}, {"text": "EM13/041 (Program Emergentes, Xunta de Galicia)", "start_pos": 91, "end_pos": 138, "type": "DATASET", "confidence": 0.7286911823532798}, {"text": "Celtic", "start_pos": 140, "end_pos": 146, "type": "DATASET", "confidence": 0.9307489991188049}]}, {"text": "Page numbers and proceedings footer are added by the organisers.", "labels": [], "entities": []}, {"text": "Licence details: http://creativecommons.org/licenses/by/4.0/ the categorization of the positive or negative sentiment that is supposed to be expressed on a given text).", "labels": [], "entities": []}, {"text": "On the other hand, tweets are too short text to be linguistically analyzed, and it makes the task of finding relevant information (e.g. opinions) much harder.", "labels": [], "entities": []}, {"text": "The SemEval-2014 task \"Sentiment Analysis in Twitter\" is an evaluation competition that includes a specific task directly related to sentiment analyisis.", "labels": [], "entities": [{"text": "SemEval-2014 task \"Sentiment Analysis in Twitter", "start_pos": 4, "end_pos": 52, "type": "TASK", "confidence": 0.756328535931451}, {"text": "sentiment analyisis", "start_pos": 133, "end_pos": 152, "type": "TASK", "confidence": 0.8351786434650421}]}, {"text": "In particular, subtask B, called \"Message Polarity Classification\", consists in classifying whether a given message is of positive, negative, or neutral sentiment.", "labels": [], "entities": [{"text": "Message Polarity Classification", "start_pos": 34, "end_pos": 65, "type": "TASK", "confidence": 0.680759052435557}]}, {"text": "For messages conveying both a positive and negative sentiment, the stronger sentiment should be chosen.", "labels": [], "entities": []}, {"text": "The results of our system in this task are situated in the average out of 51 evaluated systems.", "labels": [], "entities": []}, {"text": "In this article, we describe the learning strategies we developed so as to perform this task, all of them based on bayesian classification.", "labels": [], "entities": []}], "datasetContent": [{"text": "To evaluate the classification performance of these classifiers, we used as test corpus another dataset provided by the organization: tweeti-b.devel.tsv.", "labels": [], "entities": []}, {"text": "The results show that there is an improvement in performance when the classifiers are implemented with the Binary strategy, when they use a polarity lexicon, and when multiwords are considered as features.", "labels": [], "entities": []}, {"text": "The two systems submmited to Semeval competition were those obtained the best scores: CONSTR-BIN-LEX-MW and UNCONSTR-BIN-LEX-MW.", "labels": [], "entities": [{"text": "CONSTR-BIN-LEX-MW", "start_pos": 86, "end_pos": 103, "type": "DATASET", "confidence": 0.6903496980667114}, {"text": "UNCONSTR-BIN-LEX-MW", "start_pos": 108, "end_pos": 127, "type": "DATASET", "confidence": 0.9288889765739441}]}, {"text": "The scores obtained by these two systems in the competition are very similar to those obtained in the experiments depicted in.", "labels": [], "entities": []}, {"text": "More precisely, in the Tweets2014 test corpus, the constrained system reached 0.62 F-score while the unconstrained version achieved 0.63.", "labels": [], "entities": [{"text": "Tweets2014 test corpus", "start_pos": 23, "end_pos": 45, "type": "DATASET", "confidence": 0.9459933241208395}, {"text": "F-score", "start_pos": 83, "end_pos": 90, "type": "METRIC", "confidence": 0.9967889785766602}]}, {"text": "Our best system was ranked as 26th from 53 systems.", "labels": [], "entities": []}, {"text": "A Spanish version of this system () also participated in the, where it was ranked as the 3th best system out of 13 participants.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Results of our six systems", "labels": [], "entities": []}]}