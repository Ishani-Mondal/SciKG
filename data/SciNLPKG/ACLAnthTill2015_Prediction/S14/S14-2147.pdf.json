{"title": [{"text": "UWM: Disorder Mention Extraction from Clinical Text Using CRFs and Normalization Using Learned Edit Distance Patterns", "labels": [], "entities": [{"text": "UWM", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.9381023645401001}, {"text": "Disorder Mention Extraction from Clinical Text", "start_pos": 5, "end_pos": 51, "type": "TASK", "confidence": 0.9242399831612905}]}], "abstractContent": [{"text": "This paper describes Team UWM's system for the Task 7 of SemEval 2014 that does disorder mention extraction and nor-malization from clinical text.", "labels": [], "entities": [{"text": "SemEval 2014", "start_pos": 57, "end_pos": 69, "type": "TASK", "confidence": 0.8272242844104767}]}, {"text": "For the disorder mention extraction (Task A), the system was trained using Conditional Random Fields with features based on words, their POS tags and semantic types, as well as features based on MetaMap matches.", "labels": [], "entities": [{"text": "disorder mention extraction", "start_pos": 8, "end_pos": 35, "type": "TASK", "confidence": 0.6154892941315969}]}, {"text": "For the disorder mention normalization (Task B), variations of disorder mentions were considered whenever exact matches were not found in the training data or in the UMLS.", "labels": [], "entities": [{"text": "UMLS", "start_pos": 166, "end_pos": 170, "type": "DATASET", "confidence": 0.963602602481842}]}, {"text": "Suitable types of variations for disorder mentions were automatically learned using anew method based on edit distance patterns.", "labels": [], "entities": []}, {"text": "Among nineteen participating teams, UWM ranked third in Task A with 0.755 strict F-measure and second in Task B with 0.66 strict accuracy.", "labels": [], "entities": [{"text": "UWM", "start_pos": 36, "end_pos": 39, "type": "DATASET", "confidence": 0.8256591558456421}, {"text": "F-measure", "start_pos": 81, "end_pos": 90, "type": "METRIC", "confidence": 0.8510352969169617}, {"text": "accuracy", "start_pos": 129, "end_pos": 137, "type": "METRIC", "confidence": 0.8466325402259827}]}], "introductionContent": [{"text": "Entity mention extraction is an important task in processing natural language clinical text.", "labels": [], "entities": [{"text": "Entity mention extraction", "start_pos": 0, "end_pos": 25, "type": "TASK", "confidence": 0.7962807019551595}, {"text": "processing natural language clinical text", "start_pos": 50, "end_pos": 91, "type": "TASK", "confidence": 0.6970422565937042}]}, {"text": "Disorders, medications, anatomical sites, clinical procedures etc. are among the entity types that predominantly occur in clinical text.", "labels": [], "entities": []}, {"text": "Out of these, the Task 7 of SemEval 2014 concentrated on extracting (Task A) and normalizing (Task B) disorder mentions.", "labels": [], "entities": [{"text": "SemEval 2014", "start_pos": 28, "end_pos": 40, "type": "TASK", "confidence": 0.860990583896637}]}, {"text": "Disorder mention extraction is particularly challenging because disorders are frequently found as discontinuous phrases in clinical sentences.", "labels": [], "entities": [{"text": "Disorder mention extraction", "start_pos": 0, "end_pos": 27, "type": "TASK", "confidence": 0.8663832942644755}]}, {"text": "The extracted mentions were then to be normalized by mapping them to their UMLS CUIs if they were in the SNOMED-CT part of UMLS This work is licensed under a Creative Commons Attribution 4.0 International Licence.", "labels": [], "entities": []}, {"text": "Page numbers and proceedings footer are added by the organisers.", "labels": [], "entities": []}, {"text": "Licence details: http://creativecommons.org/licenses/by/4.0/ and belonged to the \"disorder\" UMLS semantic group, otherwise they were to be declared as \"CUI-less\".", "labels": [], "entities": []}, {"text": "This normalization task is challenging because disorder names are frequently mentioned in modified forms which prevents their exact matching with concept descriptions in UMLS.", "labels": [], "entities": [{"text": "UMLS", "start_pos": 170, "end_pos": 174, "type": "DATASET", "confidence": 0.8723731637001038}]}, {"text": "Our team, UWM, participated in both Task A and Task B. We modelled disorder mention extraction as a standard sequence labeling task.", "labels": [], "entities": [{"text": "UWM", "start_pos": 10, "end_pos": 13, "type": "DATASET", "confidence": 0.9520326256752014}, {"text": "disorder mention extraction", "start_pos": 67, "end_pos": 94, "type": "TASK", "confidence": 0.6494651436805725}]}, {"text": "The model was trained using Conditional Random Fields () with various types of lexical and semantic features that included MetaMap) matches.", "labels": [], "entities": []}, {"text": "The model was also inherently capable of extracting discontinuous disorder mentions.", "labels": [], "entities": [{"text": "extracting discontinuous disorder mentions", "start_pos": 41, "end_pos": 83, "type": "TASK", "confidence": 0.81260846555233}]}, {"text": "To normalize disorder mentions, our system first looked for exact matches with disorder mentions in the training data and in the UMLS.", "labels": [], "entities": [{"text": "normalize disorder mentions", "start_pos": 3, "end_pos": 30, "type": "TASK", "confidence": 0.8668458064397176}, {"text": "UMLS", "start_pos": 129, "end_pos": 133, "type": "DATASET", "confidence": 0.9671754837036133}]}, {"text": "If no exact match was found, then suitable variations of the disorder mentions were generated based on the commonly used variations of disorder mentions learned from the training data as well as from the UMLS synonyms.", "labels": [], "entities": [{"text": "UMLS", "start_pos": 204, "end_pos": 208, "type": "DATASET", "confidence": 0.9103640913963318}]}, {"text": "We developed a novel method to automatically learn such variations based on edit distances which is described in the next section.", "labels": [], "entities": []}, {"text": "Our Team ranked third on Task A and second on Task B in the official SemEval 2014 Task 7 evaluation (considering only the best run for each team).", "labels": [], "entities": [{"text": "SemEval 2014 Task 7 evaluation", "start_pos": 69, "end_pos": 99, "type": "DATASET", "confidence": 0.6439701914787292}]}, {"text": "We also present results of ablation studies we did on the development data in order to determine the contributions of various features and components of our system.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 2: A few illustrative edit distance patterns that were automatically learned from UMLS and the training data.", "labels": [], "entities": [{"text": "UMLS", "start_pos": 89, "end_pos": 93, "type": "DATASET", "confidence": 0.8609482645988464}]}, {"text": " Table 3: SemEval 2014 Task 7 evaluation results for our system. Precision (P), recall (R) and F-measure (F) were measured", "labels": [], "entities": [{"text": "SemEval 2014 Task 7", "start_pos": 10, "end_pos": 29, "type": "TASK", "confidence": 0.8453125506639481}, {"text": "Precision (P)", "start_pos": 65, "end_pos": 78, "type": "METRIC", "confidence": 0.9510086178779602}, {"text": "recall (R)", "start_pos": 80, "end_pos": 90, "type": "METRIC", "confidence": 0.9516967087984085}, {"text": "F-measure (F)", "start_pos": 95, "end_pos": 108, "type": "METRIC", "confidence": 0.9585632532835007}]}, {"text": " Table 4: Ablation study results for Task A showing how the", "labels": [], "entities": [{"text": "Ablation", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9968738555908203}]}, {"text": " Table 5: Performance on Task B obtained by combinations", "labels": [], "entities": []}]}