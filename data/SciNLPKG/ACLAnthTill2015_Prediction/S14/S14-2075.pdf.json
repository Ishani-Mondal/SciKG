{"title": [{"text": "NILC USP: Aspect Extraction using Semantic Labels", "labels": [], "entities": [{"text": "NILC USP", "start_pos": 0, "end_pos": 8, "type": "DATASET", "confidence": 0.7618331611156464}, {"text": "Aspect Extraction", "start_pos": 10, "end_pos": 27, "type": "TASK", "confidence": 0.9417535364627838}]}], "abstractContent": [{"text": "This paper details the system NILC USP that participated in the Semeval 2014: Aspect Based Sentiment Analysis task.", "labels": [], "entities": [{"text": "NILC USP", "start_pos": 30, "end_pos": 38, "type": "DATASET", "confidence": 0.8400423228740692}, {"text": "Semeval 2014: Aspect Based Sentiment Analysis task", "start_pos": 64, "end_pos": 114, "type": "TASK", "confidence": 0.8865868449211121}]}, {"text": "This system uses a Conditional Random Field (CRF) algorithm for extracting the aspects mentioned in the text.", "labels": [], "entities": []}, {"text": "Our work added semantic labels into a basic feature set for measuring the efficiency of those for aspect extraction.", "labels": [], "entities": [{"text": "aspect extraction", "start_pos": 98, "end_pos": 115, "type": "TASK", "confidence": 0.8122283816337585}]}, {"text": "We used the semantic roles and the highest verb frame as features for the machine learning.", "labels": [], "entities": []}, {"text": "Overall, our results demonstrated that the system could not improve with the use of this semantic information, but its precision was increased.", "labels": [], "entities": [{"text": "precision", "start_pos": 119, "end_pos": 128, "type": "METRIC", "confidence": 0.9996167421340942}]}], "introductionContent": [{"text": "Sentiment analysis, or opinion mining, has gained lots of attention lately.", "labels": [], "entities": [{"text": "Sentiment analysis", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.9810542166233063}, {"text": "opinion mining", "start_pos": 23, "end_pos": 37, "type": "TASK", "confidence": 0.7558058202266693}]}, {"text": "The importance of this field of study is linked with the grown of information in the internet and the commercial attention it brought.", "labels": [], "entities": []}, {"text": "According to, there are two kinds of information available in the internet: facts and opinions.", "labels": [], "entities": []}, {"text": "Facts are objective statements about entities and events in the world.", "labels": [], "entities": []}, {"text": "Opinions are subjective statements that reflect people's sentiments or perceptions about the entities and events.", "labels": [], "entities": []}, {"text": "According to Liu, by that time, there was a lot of attention on the processing of facts but little work had been done on the processing of opinions.", "labels": [], "entities": []}, {"text": "Three levels of analysis for sentiment analysis are known (Liu, 2012): document level, sentence level and aspect level.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 29, "end_pos": 47, "type": "TASK", "confidence": 0.9674165546894073}]}, {"text": "The aspect-based sentiment analysis is the name of the research topic that aims to extract the sentiments about the aspects present in the text.", "labels": [], "entities": [{"text": "aspect-based sentiment analysis", "start_pos": 4, "end_pos": 35, "type": "TASK", "confidence": 0.6803153256575266}]}, {"text": "This work presents a system evaluated in the SemEval Task4: Aspect Based Sentiment Analysis shared task ().", "labels": [], "entities": [{"text": "SemEval Task4: Aspect Based Sentiment Analysis shared task", "start_pos": 45, "end_pos": 103, "type": "TASK", "confidence": 0.7573446300294664}]}, {"text": "Our system participated only in subtask 1: Aspect Term Extraction.", "labels": [], "entities": [{"text": "Aspect Term Extraction", "start_pos": 43, "end_pos": 65, "type": "TASK", "confidence": 0.7639628748099009}]}, {"text": "In this subtask, given a text, the system should extract all aspects that are present.", "labels": [], "entities": []}, {"text": "There were two different domains for this task: restaurants and laptops.", "labels": [], "entities": []}, {"text": "The goal of our system was to verify how semantic labels used in machine learning classification would improve the aspect extraction task.", "labels": [], "entities": [{"text": "machine learning classification", "start_pos": 65, "end_pos": 96, "type": "TASK", "confidence": 0.6670507788658142}, {"text": "aspect extraction", "start_pos": 115, "end_pos": 132, "type": "TASK", "confidence": 0.814325213432312}]}, {"text": "For this goal, we used two kinds of semantic labels: the semantic roles () and the semantic frames (.", "labels": [], "entities": []}, {"text": "categorizes the works for aspect extraction in four types, regarding the approach they follow, using: frequent terms, infrequent terms, machine learning, and topic modeling.", "labels": [], "entities": [{"text": "aspect extraction", "start_pos": 26, "end_pos": 43, "type": "TASK", "confidence": 0.8042729794979095}, {"text": "topic modeling", "start_pos": 158, "end_pos": 172, "type": "TASK", "confidence": 0.693193182349205}]}, {"text": "This work uses a machine learning approach that consists in training a sequential labeling algorithm for aspect detection and extraction.", "labels": [], "entities": [{"text": "aspect detection and extraction", "start_pos": 105, "end_pos": 136, "type": "TASK", "confidence": 0.7699809223413467}]}, {"text": "In what follows, we present some related work in Section 2.", "labels": [], "entities": []}, {"text": "Section 3 and 4 introduce our system and report the achieved results.", "labels": [], "entities": []}, {"text": "Some conclusions are presented in Section 5.", "labels": [], "entities": []}, {"text": "a Conditional Random Field for aspect extraction.", "labels": [], "entities": [{"text": "aspect extraction", "start_pos": 31, "end_pos": 48, "type": "TASK", "confidence": 0.8659011125564575}]}, {"text": "In this work, the authors report the results fora single domain and across domain experiment.", "labels": [], "entities": []}, {"text": "They show that even in other domains the method could be good.", "labels": [], "entities": []}, {"text": "explored the semantic structure of a sentence, anchored to an opinion bearing verb or adjective.", "labels": [], "entities": []}, {"text": "Their method uses semantic role labeling as an intermediate step to label an opinion holder and topic using data from FrameNet.", "labels": [], "entities": [{"text": "semantic role labeling", "start_pos": 18, "end_pos": 40, "type": "TASK", "confidence": 0.6574452817440033}, {"text": "FrameNet", "start_pos": 118, "end_pos": 126, "type": "DATASET", "confidence": 0.930702805519104}]}, {"text": "Houen (2011) presented a system for opinion mining with semantic analysis.", "labels": [], "entities": [{"text": "opinion mining", "start_pos": 36, "end_pos": 50, "type": "TASK", "confidence": 0.8570786416530609}]}, {"text": "The author explores the use of the semantic frame-based analyzer FrameNet () for modeling features in a machine learning approach.", "labels": [], "entities": []}, {"text": "The author found that the FrameNet information was not helpful in this classifier.", "labels": [], "entities": [{"text": "FrameNet information", "start_pos": 26, "end_pos": 46, "type": "DATASET", "confidence": 0.8596045076847076}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Results for restaurants domain  System  Precision Recall F1-mesaure  Baseline  52.54  42.76  47.15  Word + POS  83.76  68.69  75.48  + Chunk  83.38  68.16  75.01  + NE  83.45  68.07  74.98  + SRL  82.79  67.46  74.34  + Frame  87.72  34.03  49.04", "labels": [], "entities": [{"text": "Precision Recall F1-mesaure  Baseline", "start_pos": 50, "end_pos": 87, "type": "METRIC", "confidence": 0.7941879779100418}, {"text": "Word + POS  83.76  68.69  75.48  + Chunk  83.38  68.16  75.01  + NE  83.45  68.07", "start_pos": 110, "end_pos": 191, "type": "DATASET", "confidence": 0.7336671690146128}, {"text": "SRL", "start_pos": 202, "end_pos": 205, "type": "DATASET", "confidence": 0.5424919724464417}]}, {"text": " Table 2: Results for laptops domain  System  Precision Recall F1-mesaure  Baseline  44.31  29.81  35.64  Word + POS  80.87  39.44  53.03  + Chunk  78.83  39.29  52.44  + NE  79.93  39.60  52.96  + SRL  78.22  38.99  52.04  + Frame  83.62  14.83  25.19", "labels": [], "entities": [{"text": "Precision Recall F1-mesaure  Baseline", "start_pos": 46, "end_pos": 83, "type": "METRIC", "confidence": 0.7920826524496078}, {"text": "NE", "start_pos": 171, "end_pos": 173, "type": "DATASET", "confidence": 0.9233097434043884}, {"text": "SRL  78.22", "start_pos": 198, "end_pos": 208, "type": "DATASET", "confidence": 0.7784763276576996}]}]}