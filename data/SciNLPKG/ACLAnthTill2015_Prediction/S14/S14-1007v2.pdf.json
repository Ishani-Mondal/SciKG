{"title": [{"text": "Identifying semantic relations in a specialized corpus through distributional analysis of a cooccurrence tensor", "labels": [], "entities": [{"text": "Identifying semantic relations", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.9269999066988627}]}], "abstractContent": [{"text": "We describe a method of encoding cooc-currence information in a three-way tensor from which HAL-style word space models can be derived.", "labels": [], "entities": []}, {"text": "We use these models to identify semantic relations in a specialized corpus.", "labels": [], "entities": []}, {"text": "Results suggest that the tensor-based methods we propose are more robust than the basic HAL model in some respects.", "labels": [], "entities": []}], "introductionContent": [{"text": "Word space models such as LSA) and HAL () have been shown to identify semantic relations from corpus data quite effectively.", "labels": [], "entities": []}, {"text": "However, the performance of such models depends on the parameters used to construct the word space.", "labels": [], "entities": []}, {"text": "In the case of HAL, parameters such as the size of the context window can have a significant impact on the ability of the model to identify semantic relations and on the types of relations (e.g. paradigmatic or syntagmatic) captured.", "labels": [], "entities": []}, {"text": "In this paper, we describe a method of encoding cooccurrence information which employs a threeway tensor instead of a matrix.", "labels": [], "entities": []}, {"text": "Because the tensor explicitly encodes the distance between a target word and the context words that co-occur with it, it allows us to extract matrices corresponding to HAL models with different context windows without repeatedly processing the whole corpus, but it also allows us to experiment with different kinds of word spaces.", "labels": [], "entities": []}, {"text": "We describe one method whereby features are selected in different slices of the tensor corresponding to different distances between the target and context words, and another which uses SVD for dimensionality reduction.", "labels": [], "entities": []}, {"text": "Models are evaluated and compared on reference data extracted from a specialized dictionary of the environment domain, as our target application is the identification of lexico-semantic relations in specialized corpora.", "labels": [], "entities": []}, {"text": "Preliminary results suggest the tensor-based methods are more robust than the basic HAL model in some respects.", "labels": [], "entities": []}], "datasetContent": [{"text": "Models were evaluated using reference data extracted from DiCoEnviro 4 , a specialized dictionary of the environment.", "labels": [], "entities": []}, {"text": "This dictionary describes the meaning and behaviour of terms of the environment domain as well as the lexicosemantic relations between these terms.", "labels": [], "entities": []}, {"text": "Of the various relations encoded in the dictionary, we focused on a subset of three paradigmatic relations: near-synonyms (terms that have similar meanings), antonyms (opposite meanings), and hyponyms (kinds of).", "labels": [], "entities": []}, {"text": "446 pairs containing a headword and a related term were extracted from the dictionary.", "labels": [], "entities": []}, {"text": "We then filtered out the pairs that contained at least one OOV term, and were left with 374 pairs containing two paradigmatically-related, single-word terms.", "labels": [], "entities": []}, {"text": "About two thirds (246) of these examples were used for parameter selection, and the rest were set aside fora final comparison of the highest-scoring models.", "labels": [], "entities": [{"text": "parameter selection", "start_pos": 55, "end_pos": 74, "type": "TASK", "confidence": 0.7238895893096924}]}, {"text": "Each model was automatically evaluated on the reference data as follows.", "labels": [], "entities": []}, {"text": "For each <headword, related term> pair in the training set, we computed the cosine similarity between the headword and all other words in the vocabulary, then observed the rank of the related term in the sorted list of neighbours.", "labels": [], "entities": []}, {"text": "The score used to compare models is recall at k (R@k), which is the percentage of cases where the related term is among the k nearest neighbours of the headword.", "labels": [], "entities": [{"text": "recall", "start_pos": 36, "end_pos": 42, "type": "METRIC", "confidence": 0.9992200136184692}]}, {"text": "It should be noted that a score of 100% is not always possible in this setting (depending on the value of k), as some headwords have more than 1 related term in the reference data.", "labels": [], "entities": []}, {"text": "Nonetheless, since most (\u223c70%) have 1 or 2 related terms, R@k for some small value of k (we use k = 10) should be a good indicator of accuracy.", "labels": [], "entities": [{"text": "R", "start_pos": 58, "end_pos": 59, "type": "METRIC", "confidence": 0.9469296932220459}, {"text": "accuracy", "start_pos": 134, "end_pos": 142, "type": "METRIC", "confidence": 0.996822714805603}]}, {"text": "A measure that explicitly accounts for the fact that different terms have different numbers of related terms (e.g. R-precision) would be a good alternative.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: A 3 \u00d7 3 \u00d7 2 cooccurrence tensor.", "labels": [], "entities": []}, {"text": " Table 3: R@10 (%) of best models.", "labels": [], "entities": [{"text": "R", "start_pos": 10, "end_pos": 11, "type": "METRIC", "confidence": 0.997432291507721}]}]}