{"title": [{"text": "IUCL: Combining Information Sources for SemEval Task 5", "labels": [], "entities": [{"text": "SemEval Task", "start_pos": 40, "end_pos": 52, "type": "TASK", "confidence": 0.9210518002510071}]}], "abstractContent": [{"text": "We describe the Indiana University system for SemEval Task 5, the L2 writing assistant task, as well as some extensions to the system that were completed after the main evaluation.", "labels": [], "entities": [{"text": "Indiana University system", "start_pos": 16, "end_pos": 41, "type": "DATASET", "confidence": 0.9191662470499674}, {"text": "SemEval Task 5", "start_pos": 46, "end_pos": 60, "type": "TASK", "confidence": 0.8931776682535807}]}, {"text": "Our team submitted translations for all four language pairs in the evaluation, yielding the top scores for English-German.", "labels": [], "entities": []}, {"text": "The system is based on combining several information sources to arrive at a final L2 translation fora given L1 text fragment, incorporating phrase tables extracted from bitexts, an L2 language model, a multilingual dictionary, and dependency-based collocational models derived from large samples of target-language text.", "labels": [], "entities": []}], "introductionContent": [{"text": "In the L2 writing assistant task, we must translate an L1 fragment in the midst of an existing, nearly complete, L2 sentence.", "labels": [], "entities": []}, {"text": "With the presence of this rich target-language context, the task is rather different from a standard machine translation setting, and our goal with our design was to make effective use of the L2 context, exploiting collocational relationships between tokens anywhere in the L2 context and the proposed fragment translations.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 101, "end_pos": 120, "type": "TASK", "confidence": 0.7555868029594421}]}, {"text": "Our system proceeds in several stages: (1) looking up or constructing candidate translations for the L1 fragment, (2) scoring candidate translations via a language model of the L2, (3) scoring candidate translations with a dependency-driven word similarity measure) (which we call SIM), and (4) combining the previous scores in a log-linear model to arrive at a final n-best list.", "labels": [], "entities": []}, {"text": "Step 1 models transfer knowledge between This work is licenced under a Creative Commons Attribution 4.0 International License.", "labels": [], "entities": []}, {"text": "Page numbers and proceedings footer are added by the organizers.", "labels": [], "entities": []}, {"text": "License details: http: //creativecommons.org/licenses/by/4.0/ the L1 and L2; step 2 models facts about the L2 syntax, i.e., which translations fit well into the local context; step 3 models collocational and semantic tendencies of the L2; and step 4 gives different weights to each of the three sources of information.", "labels": [], "entities": []}, {"text": "Although we did not finish step 3 in time for the official results, we discuss it here, as it represents the most novel aspect of the systemnamely, steps towards the exploitation of the rich L2 context.", "labels": [], "entities": []}, {"text": "In general, our approach is languageindependent, with accuracy varying due to the size of data sources and quality of input technology (e.g., syntactic parse accuracy).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 54, "end_pos": 62, "type": "METRIC", "confidence": 0.9981200098991394}, {"text": "syntactic parse", "start_pos": 142, "end_pos": 157, "type": "TASK", "confidence": 0.684627041220665}, {"text": "accuracy", "start_pos": 158, "end_pos": 166, "type": "METRIC", "confidence": 0.4754541516304016}]}, {"text": "More features could easily be added to the log-linear model, and further explorations of ways to make use of targetlanguage knowledge could be promising.", "labels": [], "entities": []}], "datasetContent": [{"text": "In figures 1-4, we show the scores on this year's test set for running the two variations of our system: run2, the version without the SIM extensions, which we submitted for the evaluation, and SIM, with the extensions enabled.", "labels": [], "entities": []}, {"text": "For comparison, we also include the best (or for EnglishGerman, next-best) submitted system.", "labels": [], "entities": [{"text": "EnglishGerman", "start_pos": 49, "end_pos": 62, "type": "DATASET", "confidence": 0.9608075618743896}]}, {"text": "We see here that the use of the SIM features did not improve the performance of the base system, and in the case of English-Spanish caused significant degradation, which is as of yet unexplained, though we suspect difficulties parsing the Spanish test set, as for all of the other language pairs, the effects of adding SIM features were small.", "labels": [], "entities": []}], "tableCaptions": []}