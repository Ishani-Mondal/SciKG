{"title": [{"text": "Text Summarization through Entailment-based Minimum Vertex Cover", "labels": [], "entities": [{"text": "Text Summarization", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.5694294273853302}]}], "abstractContent": [{"text": "Sentence Connectivity is a textual characteristic that maybe incorporated intelligently for the selection of sentences of a well meaning summary.", "labels": [], "entities": [{"text": "Sentence Connectivity", "start_pos": 0, "end_pos": 21, "type": "TASK", "confidence": 0.8892800807952881}]}, {"text": "However, the existing summarization methods do not utilize its potential fully.", "labels": [], "entities": [{"text": "summarization", "start_pos": 22, "end_pos": 35, "type": "TASK", "confidence": 0.9707536101341248}]}, {"text": "The present paper introduces a novel method for single-document text summarization.", "labels": [], "entities": [{"text": "single-document text summarization", "start_pos": 48, "end_pos": 82, "type": "TASK", "confidence": 0.6303673684597015}]}, {"text": "It poses the text summarization task as an optimization problem, and attempts to solve it using Weighted Minimum Vertex Cover (WMVC), a graph-based algorithm.", "labels": [], "entities": [{"text": "text summarization task", "start_pos": 13, "end_pos": 36, "type": "TASK", "confidence": 0.8067823449770609}]}, {"text": "Tex-tual entailment, an established indicator of semantic relationships between text units, is used to measure sentence connectivity and construct the graph on which WMVC operates.", "labels": [], "entities": []}, {"text": "Experiments on a standard sum-marization dataset show that the suggested algorithm outperforms related methods.", "labels": [], "entities": []}], "introductionContent": [{"text": "In the present age of digital revolution with proliferating numbers of internet-connected devices, we are facing an exponential rise in the volume of available information.", "labels": [], "entities": []}, {"text": "Users are constantly facing the problem of deciding what to read and what to skip.", "labels": [], "entities": []}, {"text": "Text summarization provides a practical solution to this problem, causing a resurgence in research in this field.", "labels": [], "entities": [{"text": "Text summarization", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.7047390937805176}]}, {"text": "Given a topic of interest, a standard search often yields a large number of documents.", "labels": [], "entities": []}, {"text": "Many of them are not of the user's interest.", "labels": [], "entities": []}, {"text": "Rather than going through the entire result-set, the reader may read a gist of a document, produced via summarization tools, and then decide whether to fully read the document or not, thus saving a substantial amount of time.", "labels": [], "entities": []}, {"text": "According to, a summary can be defined as \"a reductive transformation of source text to summary text through content reduction by selection and/or generalization on what is important in the source\".", "labels": [], "entities": []}, {"text": "Summarization based on content reduction by selection is referred to as extraction (identifying and including the important sentences in the final summary), whereas a summary involving content reduction by generalization is called abstraction (reproducing the most informative content in anew way).", "labels": [], "entities": []}, {"text": "The present paper focuses on extraction-based single-document summarization.", "labels": [], "entities": [{"text": "extraction-based single-document summarization", "start_pos": 29, "end_pos": 75, "type": "TASK", "confidence": 0.5238404671351115}]}, {"text": "We formulate the task as a graph-based optimization problem, where vertices represent the sentences and edges the connections between sentences.", "labels": [], "entities": []}, {"text": "Textual entailment () is employed to estimate the degree of connectivity between sentences, and subsequently to assign a weight to each vertex of the graph.", "labels": [], "entities": []}, {"text": "Then, the Weighted Minimum Vertex Cover, a classical graph algorithm, is used to find the minimal set of vertices (that is -sentences) that forms a cover.", "labels": [], "entities": []}, {"text": "The idea is that such cover of well-connected vertices would correspond to a cover of the salient content of the document.", "labels": [], "entities": []}, {"text": "The rest of the paper is organized as follows: In Section 2, we discuss related work and describe the WMVC algorithm.", "labels": [], "entities": [{"text": "WMVC algorithm", "start_pos": 102, "end_pos": 116, "type": "TASK", "confidence": 0.6883332133293152}]}, {"text": "In Section 3, we propose a novel summarization method, and in Section 4, experiments and results are presented.", "labels": [], "entities": [{"text": "summarization", "start_pos": 33, "end_pos": 46, "type": "TASK", "confidence": 0.9808128476142883}]}, {"text": "Finally, in Section 5, we conclude and outline future research directions.", "labels": [], "entities": []}], "datasetContent": [{"text": "We have conducted experiments on the singledocument summarization task of the DUC 2002 dataset 2 , using a random sample that contains 60 news articles picked from each of the 60 clusters available in the dataset.", "labels": [], "entities": [{"text": "singledocument summarization task", "start_pos": 37, "end_pos": 70, "type": "TASK", "confidence": 0.6083968579769135}, {"text": "DUC 2002 dataset 2", "start_pos": 78, "end_pos": 96, "type": "DATASET", "confidence": 0.982339471578598}]}, {"text": "The target summary length limit has been set to 100 words.", "labels": [], "entities": [{"text": "summary length limit", "start_pos": 11, "end_pos": 31, "type": "METRIC", "confidence": 0.8000447551409403}]}, {"text": "We used version 2.1.1 of BIUTEE (), a transformation-based TE system to compute textual entailment score between pairs of sentences.", "labels": [], "entities": [{"text": "BIUTEE", "start_pos": 25, "end_pos": 31, "type": "METRIC", "confidence": 0.9792096614837646}]}, {"text": "3 BIUTEE was trained with 600 texthypothesis pairs of the RTE-5 dataset ().", "labels": [], "entities": [{"text": "BIUTEE", "start_pos": 2, "end_pos": 8, "type": "METRIC", "confidence": 0.9954327344894409}, {"text": "RTE-5 dataset", "start_pos": 58, "end_pos": 71, "type": "DATASET", "confidence": 0.9540959000587463}]}, {"text": "We have evaluated the method's performance using ROUGE   quality of an automatically-generated summary by comparing it to a \"gold-standard\", typically a human generated summary.", "labels": [], "entities": [{"text": "ROUGE   quality", "start_pos": 49, "end_pos": 64, "type": "METRIC", "confidence": 0.9298776388168335}]}, {"text": "ROUGE-n measures ngram precision and recall of a candidate summary with respect to a set of reference summaries.", "labels": [], "entities": [{"text": "ROUGE-n", "start_pos": 0, "end_pos": 7, "type": "METRIC", "confidence": 0.9764352440834045}, {"text": "precision", "start_pos": 23, "end_pos": 32, "type": "METRIC", "confidence": 0.9432879686355591}, {"text": "recall", "start_pos": 37, "end_pos": 43, "type": "METRIC", "confidence": 0.9989860653877258}]}, {"text": "We compare the system-generated summary with two reference summaries for each article in the dataset, and show the results for ROUGE-1, ROUGE-2 and ROUGE-SU4 that allows skips within n-grams.", "labels": [], "entities": [{"text": "ROUGE-1", "start_pos": 127, "end_pos": 134, "type": "METRIC", "confidence": 0.6590563654899597}]}, {"text": "These metrics were shown to perform well for single document text summarization, especially for short summaries.", "labels": [], "entities": [{"text": "single document text summarization", "start_pos": 45, "end_pos": 79, "type": "TASK", "confidence": 0.584765262901783}]}, {"text": "Specifically, showed that ROUGE-1 achieves high correlation with human judgments.", "labels": [], "entities": [{"text": "ROUGE-1", "start_pos": 26, "end_pos": 33, "type": "METRIC", "confidence": 0.9579674601554871}]}], "tableCaptions": [{"text": " Table 1: The sentence array of article AP881113-0007 of cluster do106 in the DUC'02 dataset.", "labels": [], "entities": [{"text": "DUC'02 dataset", "start_pos": 78, "end_pos": 92, "type": "DATASET", "confidence": 0.9855549335479736}]}, {"text": " Table 2: The sentence entailment matrix of the ex- ample article.", "labels": [], "entities": []}, {"text": " Table 3: Connectivity Scores of the sentences of  article AP881113-0007.", "labels": [], "entities": [{"text": "article AP881113-0007", "start_pos": 51, "end_pos": 72, "type": "DATASET", "confidence": 0.7890925407409668}]}]}