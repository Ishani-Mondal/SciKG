{"title": [{"text": "SimCompass: Using Deep Learning Word Embeddings to Assess Cross-level Similarity", "labels": [], "entities": [{"text": "Similarity", "start_pos": 70, "end_pos": 80, "type": "TASK", "confidence": 0.7201331853866577}]}], "abstractContent": [{"text": "This article presents our team's participating system at SemEval-2014 Task 3.", "labels": [], "entities": [{"text": "SemEval-2014 Task 3", "start_pos": 57, "end_pos": 76, "type": "TASK", "confidence": 0.7580788135528564}]}, {"text": "Using a meta-learning framework, we experiment with traditional knowledge-based metrics, as well as novel corpus-based measures based on deep learning paradigms, paired with varying degrees of context expansion.", "labels": [], "entities": []}, {"text": "The framework enabled us to reach the highest overall performance among all competing systems.", "labels": [], "entities": []}], "introductionContent": [{"text": "Semantic textual similarity is one of the key components behind a multitude of natural language processing applications, such as information retrieval, relevance feedback and text classification, word sense disambiguation), summarization (, automatic evaluation of machine translation), plagiarism detection, and more.", "labels": [], "entities": [{"text": "Semantic textual similarity", "start_pos": 0, "end_pos": 27, "type": "TASK", "confidence": 0.751576821009318}, {"text": "information retrieval", "start_pos": 129, "end_pos": 150, "type": "TASK", "confidence": 0.7993027865886688}, {"text": "text classification", "start_pos": 175, "end_pos": 194, "type": "TASK", "confidence": 0.6948343217372894}, {"text": "word sense disambiguation", "start_pos": 196, "end_pos": 221, "type": "TASK", "confidence": 0.6726149320602417}, {"text": "summarization", "start_pos": 224, "end_pos": 237, "type": "TASK", "confidence": 0.9920305013656616}, {"text": "automatic evaluation of machine translation)", "start_pos": 241, "end_pos": 285, "type": "TASK", "confidence": 0.659529502193133}, {"text": "plagiarism detection", "start_pos": 287, "end_pos": 307, "type": "TASK", "confidence": 0.7352990210056305}]}, {"text": "To date, semantic similarity research has primarily focused on comparing text snippets of similar length (see the semantic textual similarity tasks organized during *Sem and).", "labels": [], "entities": [{"text": "semantic similarity", "start_pos": 9, "end_pos": 28, "type": "TASK", "confidence": 0.7747836410999298}]}, {"text": "Yet, as new challenges emerge, such as augmenting a knowledge-base with textual evidence, assessing similarity across different context granularities is gaining traction.", "labels": [], "entities": []}, {"text": "The SemEval Cross-level semantic similarity task is aimed at this latter scenario, and is described in more details in the task paper", "labels": [], "entities": [{"text": "SemEval Cross-level semantic similarity task", "start_pos": 4, "end_pos": 48, "type": "TASK", "confidence": 0.8633340954780578}]}], "datasetContent": [{"text": "Our system participated in all cross-level subtasks under the name SimCompass, competing with 37 other systems developed by 20 teams.", "labels": [], "entities": []}, {"text": "highlights the Pearson correlations at the four lexical levels between the gold standard and each similarity measure introduced in Section 3, as well as the predictions ensuing as a result of meta-learning.", "labels": [], "entities": [{"text": "Pearson correlations", "start_pos": 15, "end_pos": 35, "type": "METRIC", "confidence": 0.9501242637634277}]}, {"text": "The left and right histograms in each subfigure present the scores obtained on the train and test data, respectively.", "labels": [], "entities": []}, {"text": "In the case of word2sense train data, we notice that expanding the context provides additional information and improves the correlation results.", "labels": [], "entities": [{"text": "correlation", "start_pos": 124, "end_pos": 135, "type": "METRIC", "confidence": 0.9680061936378479}]}, {"text": "For corpus-based measures, the correlations are stronger when the expansion involves only the right side of the tuple, namely the sense.", "labels": [], "entities": []}, {"text": "We notice an increase of 0.04 correlation points for WTV1 and 0.09 for WTV2.", "labels": [], "entities": [{"text": "correlation", "start_pos": 30, "end_pos": 41, "type": "METRIC", "confidence": 0.9828197956085205}, {"text": "WTV1", "start_pos": 53, "end_pos": 57, "type": "DATASET", "confidence": 0.9791085124015808}, {"text": "WTV2", "start_pos": 71, "end_pos": 75, "type": "DATASET", "confidence": 0.9815346002578735}]}, {"text": "As soon as the word is expanded as well, the context incorporates too much noise, and the correlation levels drop.", "labels": [], "entities": [{"text": "correlation", "start_pos": 90, "end_pos": 101, "type": "METRIC", "confidence": 0.96478670835495}]}, {"text": "In the case of knowledge-based measures, expanding the context does not seem to impact the results.", "labels": [], "entities": []}, {"text": "However, these trends do not carryout to the test data, where the corpus-based features without expansion reach a correlation higher than 0.3, while the knowledge-based features score significantly lower (by 0.16).", "labels": [], "entities": []}, {"text": "Once all these measures are used as features in a meta learner (All) using Gaussian processes regression (GP), the correlation increases over the level attained by the best performing individual feature, reaching 0.45 on the train data and 0.36 on the test data.", "labels": [], "entities": [{"text": "correlation", "start_pos": 115, "end_pos": 126, "type": "METRIC", "confidence": 0.9588809609413147}]}, {"text": "SimCompass ranks second in this subtask's evaluations, falling short of the leading system by 0.025 correlation points.", "labels": [], "entities": [{"text": "SimCompass", "start_pos": 0, "end_pos": 10, "type": "DATASET", "confidence": 0.8843181133270264}, {"text": "correlation", "start_pos": 100, "end_pos": 111, "type": "METRIC", "confidence": 0.9667065739631653}]}, {"text": "Turning now to the phrase2word subfigure, we notice that the context already carries sufficient information, and expanding it causes the performance to drop (the more extensive the expansion, the steeper the drop).", "labels": [], "entities": []}, {"text": "Unlike the scenario encountered for word2sense, the trend observed hereon the training data also gets mirrored in the test data.", "labels": [], "entities": []}, {"text": "Same as before, knowledge-based measures have a significantly lower performance, but deep learning-based features based on word2vec (WTV) only show a correlation variation by at most 0.05, proving their robustness.", "labels": [], "entities": []}, {"text": "Leveraging all the features in a meta-learning framework enables the system to predict stronger scores for both the train and the test data (0.48 and 0.42, respectively).", "labels": [], "entities": []}, {"text": "Actually, for this variation, SimCompass No expansion Expansion R Expansion L&R All obtains the highest score among all competing systems, surpassing the second best by 0.10.", "labels": [], "entities": []}, {"text": "Noticing that expansion is not helpful when sufficient context is available, for the next variations we use the original tuples.", "labels": [], "entities": []}, {"text": "Also, due to the reduced impact of knowledge-based features on the training outcome, we only focus on deep learning features (WTV1, WTV2, WTV3, WTV4).", "labels": [], "entities": [{"text": "WTV1", "start_pos": 126, "end_pos": 130, "type": "DATASET", "confidence": 0.9838142395019531}, {"text": "WTV2", "start_pos": 132, "end_pos": 136, "type": "DATASET", "confidence": 0.8648266196250916}, {"text": "WTV3", "start_pos": 138, "end_pos": 142, "type": "DATASET", "confidence": 0.9040936827659607}, {"text": "WTV4", "start_pos": 144, "end_pos": 148, "type": "DATASET", "confidence": 0.9172146916389465}]}, {"text": "Shifting to sentence2phrase, WTV2 (constructed using VectorSum) is the top performing feature, surpassing the baseline by 0.19, and attaining 0.69 and 0.73 on the train and test sets, respectively.", "labels": [], "entities": [{"text": "WTV2", "start_pos": 29, "end_pos": 33, "type": "DATASET", "confidence": 0.9411670565605164}]}, {"text": "Despite also considering a lower performing feature (WTV1), the metalearner maintains high scores, surpassing the correlation achieved on the train data by 0.04 (from 0.70 to 0.74).", "labels": [], "entities": [{"text": "WTV1", "start_pos": 53, "end_pos": 57, "type": "DATASET", "confidence": 0.9597230553627014}, {"text": "correlation", "start_pos": 114, "end_pos": 125, "type": "METRIC", "confidence": 0.9823580384254456}]}, {"text": "In this variation, our system ranks fifth, at 0.035 from the top system.", "labels": [], "entities": []}, {"text": "For the paragraph2sentence variation, due to the availability of longer contexts, we introduce WTV3 and WTV4 that are based on clustering the left and the right sides of the tuple, respectively.", "labels": [], "entities": [{"text": "WTV3", "start_pos": 95, "end_pos": 99, "type": "DATASET", "confidence": 0.9729442000389099}, {"text": "WTV4", "start_pos": 104, "end_pos": 108, "type": "DATASET", "confidence": 0.9479004144668579}]}, {"text": "WTV2 fares slightly better than WTV3 and WTV4.", "labels": [], "entities": [{"text": "WTV2", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.9584179520606995}, {"text": "WTV3", "start_pos": 32, "end_pos": 36, "type": "DATASET", "confidence": 0.9684054851531982}, {"text": "WTV4", "start_pos": 41, "end_pos": 45, "type": "DATASET", "confidence": 0.9601993560791016}]}, {"text": "WTV1 surpasses the baseline this time, leaving its mark on the decision process.", "labels": [], "entities": [{"text": "WTV1", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.9544762969017029}]}, {"text": "When training the GP learner on all features, we obtain 0.78 correlation on the train data, and 0.81 on test data, 0.10 higher than those attained by the individual features alone.", "labels": [], "entities": [{"text": "correlation", "start_pos": 61, "end_pos": 72, "type": "METRIC", "confidence": 0.9758461713790894}]}, {"text": "SimCompass ranks seventh in performance on this subtask, at 0.026 from the first.", "labels": [], "entities": []}, {"text": "Considering the overall system performance, SimCompass is remarkably versatile, ranking among the top at each lexical level, and taking the first place in the SemEval Task 3 overall evaluation with respect to both Pearson (0.58 average correlation) and Spearman correlations.", "labels": [], "entities": [{"text": "SemEval Task 3", "start_pos": 159, "end_pos": 173, "type": "TASK", "confidence": 0.8559534748395284}, {"text": "Pearson (0.58 average correlation)", "start_pos": 214, "end_pos": 248, "type": "METRIC", "confidence": 0.9287420610586802}]}], "tableCaptions": []}