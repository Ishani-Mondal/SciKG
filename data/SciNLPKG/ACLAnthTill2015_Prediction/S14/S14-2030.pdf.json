{"title": [{"text": "CNRC-TMT: Second Language Writing Assistant System Description", "labels": [], "entities": [{"text": "Second Language Writing Assistant System Description", "start_pos": 10, "end_pos": 62, "type": "TASK", "confidence": 0.7310396631558737}]}], "abstractContent": [{"text": "We describe the system entered by the National Research Council Canada in the SemEval-2014 L2 writing assistant task.", "labels": [], "entities": [{"text": "National Research Council Canada", "start_pos": 38, "end_pos": 70, "type": "DATASET", "confidence": 0.929147943854332}, {"text": "SemEval-2014 L2 writing assistant task", "start_pos": 78, "end_pos": 116, "type": "TASK", "confidence": 0.7128640532493591}]}, {"text": "Our system relies on a standard Phrase-Based Statistical Machine Translation trained on generic, publicly available data.", "labels": [], "entities": [{"text": "Phrase-Based Statistical Machine Translation", "start_pos": 32, "end_pos": 76, "type": "TASK", "confidence": 0.6290296092629433}]}, {"text": "Translations are produced by taking the already translated part of the sentence as fixed context.", "labels": [], "entities": []}, {"text": "We show that translation systems can address the L2 writing assistant task, reaching out-of-five word-based accuracy above 80 percent for 3 out of 4 language pairs.", "labels": [], "entities": [{"text": "translation", "start_pos": 13, "end_pos": 24, "type": "TASK", "confidence": 0.96708083152771}, {"text": "L2 writing assistant task", "start_pos": 49, "end_pos": 74, "type": "TASK", "confidence": 0.6724298894405365}, {"text": "accuracy", "start_pos": 108, "end_pos": 116, "type": "METRIC", "confidence": 0.8754853010177612}]}, {"text": "We also present a brief analysis of remaining errors.", "labels": [], "entities": []}], "introductionContent": [{"text": "The Semeval L2 writing assistant task simulates the situation of an L2 language learner trying to translate a L1 fragment in a L2 context.", "labels": [], "entities": [{"text": "Semeval L2 writing assistant task", "start_pos": 4, "end_pos": 37, "type": "TASK", "confidence": 0.7929403066635132}]}, {"text": "This is clearly motivated by a L2 language learning scenario.", "labels": [], "entities": []}, {"text": "However, a very similar scenario can be encountered in Computer-Aided Translation.", "labels": [], "entities": [{"text": "Computer-Aided Translation", "start_pos": 55, "end_pos": 81, "type": "TASK", "confidence": 0.6391840428113937}]}, {"text": "Translation memories retrieve from a large corpus of already translated documents the source segments that best match anew sentence to be translated.", "labels": [], "entities": [{"text": "Translation memories", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.892103761434555}]}, {"text": "If an exact source match is found, the corresponding target translation can be expected to be suitable with little or no post-editing.", "labels": [], "entities": []}, {"text": "However, when only approximate matches are found, post-editing will typically be required to adapt the target side of the partially matching source segment to the source sentence under consideration.", "labels": [], "entities": []}, {"text": "It is possible to automate this process: standard string matching algorithms and word alignment techniques can be used to locate the parts of the source segment that do not match the sentence to translate, and from c 2014, The Crown in there the parts of the target segment that need to be modified.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 81, "end_pos": 95, "type": "TASK", "confidence": 0.7631365060806274}, {"text": "The Crown", "start_pos": 223, "end_pos": 232, "type": "DATASET", "confidence": 0.8057723641395569}]}, {"text": "The task of translating a L1 fragment in L2 context therefore has much broader application than language learning.", "labels": [], "entities": [{"text": "translating a L1 fragment", "start_pos": 12, "end_pos": 37, "type": "TASK", "confidence": 0.8465314358472824}]}, {"text": "This motivation also provides a clear link of this task to the Machine Translation setting.", "labels": [], "entities": [{"text": "Machine Translation", "start_pos": 63, "end_pos": 82, "type": "TASK", "confidence": 0.871520608663559}]}, {"text": "There are also connections to the codeswitching and mixed language translation problems ().", "labels": [], "entities": [{"text": "mixed language translation", "start_pos": 52, "end_pos": 78, "type": "TASK", "confidence": 0.6648217439651489}]}, {"text": "In our work, we therefore investigate the use of a standard Phrase-Based Statistical Machine Translation (SMT) system to translate L1 fragments in L2 context.", "labels": [], "entities": [{"text": "Phrase-Based Statistical Machine Translation (SMT)", "start_pos": 60, "end_pos": 110, "type": "TASK", "confidence": 0.7090801554066795}]}, {"text": "In the next section, we describe the SMT system that we used in our submission.", "labels": [], "entities": [{"text": "SMT", "start_pos": 37, "end_pos": 40, "type": "TASK", "confidence": 0.9942210912704468}]}, {"text": "We then describe the corpora used to train the SMT engine (Section 3), and our results on the trial and test data, as well as a short error analysis.", "labels": [], "entities": [{"text": "SMT", "start_pos": 47, "end_pos": 50, "type": "TASK", "confidence": 0.9908592104911804}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Number of training segments for each  language pair.", "labels": [], "entities": []}, {"text": " Table 2: Trial data performance, from official eval- uation script: (W)ord and (F)ragment accuracy at  (1) and (5)-best and BLEU score gain.", "labels": [], "entities": [{"text": "ragment", "start_pos": 83, "end_pos": 90, "type": "METRIC", "confidence": 0.7608129382133484}, {"text": "accuracy", "start_pos": 91, "end_pos": 99, "type": "METRIC", "confidence": 0.5997984409332275}, {"text": "BLEU score gain", "start_pos": 125, "end_pos": 140, "type": "METRIC", "confidence": 0.9801761905352274}]}, {"text": " Table 3: News data performance (cf Tab. 2).", "labels": [], "entities": []}, {"text": " Table 4: Test data performance, from official eval- uation results (cf. Table 2).", "labels": [], "entities": []}, {"text": " Table 5: Test data error analysis: OOV's is the  proportion of all test fragments containing out-of- vocabulary tokens; failed align is the proportion of  fragments which our system cannot align to any of  the reference translations by forced decoding.", "labels": [], "entities": [{"text": "OOV", "start_pos": 36, "end_pos": 39, "type": "METRIC", "confidence": 0.9950597882270813}]}]}