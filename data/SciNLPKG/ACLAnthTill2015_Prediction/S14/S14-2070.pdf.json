{"title": [{"text": "LT3: Sentiment Classification in User-Generated Content Using a Rich Feature Set", "labels": [], "entities": [{"text": "LT3", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.7858449220657349}, {"text": "Sentiment Classification", "start_pos": 5, "end_pos": 29, "type": "TASK", "confidence": 0.9611859619617462}]}], "abstractContent": [{"text": "This paper describes our contribution to the SemEval-2014 Task 9 on sentiment analysis in Twitter.", "labels": [], "entities": [{"text": "SemEval-2014 Task 9 on sentiment analysis", "start_pos": 45, "end_pos": 86, "type": "TASK", "confidence": 0.7572040110826492}]}, {"text": "We participated in both strands of the task, viz.", "labels": [], "entities": []}, {"text": "classification at message-level (subtask B), and polarity disambiguation of particular text spans within a message (subtask A).", "labels": [], "entities": []}, {"text": "Our experiments with a variety of lexical and syntactic features show that our systems benefit from rich feature sets for sentiment analysis on user-generated content.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 122, "end_pos": 140, "type": "TASK", "confidence": 0.9426359534263611}]}, {"text": "Our systems ranked ninth among 27 and sixteenth among 50 submissions for task A and B respectively.", "labels": [], "entities": []}], "introductionContent": [{"text": "Over the past few years, Web 2.0 applications such as microblogging services, social networking sites, and short messaging services have considerably increased the amount of user-generated content produced online.", "labels": [], "entities": []}, {"text": "Millions of people rely on these services to send messages, share their views or gather information about others.", "labels": [], "entities": []}, {"text": "Simultaneously, companies, marketeers and politicians are anxious to detect sentiment in UGC since these messages might contain valuable information about the public opinion.", "labels": [], "entities": []}, {"text": "This explains why sentiment analysis has been a research area of great interest in the last few years ().", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 18, "end_pos": 36, "type": "TASK", "confidence": 0.9685900509357452}]}, {"text": "Though first studies focussed more on product or movie reviews, we see that analyzing sentiment in UGC is currently becoming increasingly popular.", "labels": [], "entities": [{"text": "analyzing sentiment in UGC", "start_pos": 76, "end_pos": 102, "type": "TASK", "confidence": 0.7143961191177368}]}, {"text": "The main difference between these two sources of information is that the former is rather long and contains quite formal language whereas the latter one is generally very brief and noisy and thus represents some different challenges (.", "labels": [], "entities": []}, {"text": "In this paper, we describe our contribution to the, which was a rerun of) and consisted of two subtasks: \u2022 Subtask A -Contextual Polarity Disambiguation: Given a message containing a marked instance of a word or phrase, determine whether that instance is positive, negative or neutral in that context.", "labels": [], "entities": [{"text": "Contextual Polarity Disambiguation", "start_pos": 118, "end_pos": 152, "type": "TASK", "confidence": 0.5793818533420563}]}, {"text": "\u2022 Subtask B -Message Polarity Classification: Given a message, classify whether the message is of positive, negative, or neutral sentiment.", "labels": [], "entities": []}, {"text": "For messages conveying both a positive and negative sentiment, whichever is the stronger sentiment should be chosen.", "labels": [], "entities": []}, {"text": "The datasets for training, development and testing were provided by the task organizers.", "labels": [], "entities": []}, {"text": "The training datasets consisted of Twitter messages on a variety of topics.", "labels": [], "entities": []}, {"text": "The test sets contained regular tweets (Twitter2013, Twitter2014), tweets labeled as sarcastic (TwitterSarcasm), SMS messages (SMS2013), and blog posts (LiveJournal2014).", "labels": [], "entities": []}, {"text": "For both subtasks, the possible polarity labels were positive, negative, neutral, and objective.", "labels": [], "entities": []}, {"text": "The datasets for subtask B contained an additional label, i.e. objective-OR-neutral.", "labels": [], "entities": []}, {"text": "Table 1 presents an overview of all provided datasets.", "labels": [], "entities": []}, {"text": "For each task and test dataset, two runs could be submitted: a constrained run using the provided training data only, and an unconstrained one using additional training data.", "labels": [], "entities": []}, {"text": "For both tasks, we created a constrained model based on supervised learning, relying on additional lexicons and using the test datasets of SemEval-2013 as development data.", "labels": [], "entities": []}, {"text": "Evaluation was based on averaged Fmeasure, considering averaged F-positive and Fnegative.", "labels": [], "entities": [{"text": "Fmeasure", "start_pos": 33, "end_pos": 41, "type": "METRIC", "confidence": 0.9949864149093628}, {"text": "F-positive", "start_pos": 64, "end_pos": 74, "type": "METRIC", "confidence": 0.9907360672950745}, {"text": "Fnegative", "start_pos": 79, "end_pos": 88, "type": "METRIC", "confidence": 0.98527991771698}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Number of labeled instances contained  by the training, development (test data SemEval- 2013), and SemEval-2014 test sets.", "labels": [], "entities": [{"text": "SemEval-2014 test sets", "start_pos": 109, "end_pos": 131, "type": "DATASET", "confidence": 0.843383272488912}]}, {"text": " Table 2: F-scores obtained after adding other fea- tures for the Twitter and SMS development data  (test data SemEval-2013) -subtask A.", "labels": [], "entities": [{"text": "F-scores", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9973592162132263}, {"text": "SMS development data", "start_pos": 78, "end_pos": 98, "type": "DATASET", "confidence": 0.7192561427752177}]}, {"text": " Table 3: F-scores obtained after adding other fea- tures for the Twitter and SMS development data  (test data SemEval-2013) -subtask B.", "labels": [], "entities": [{"text": "F-scores", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9974125027656555}, {"text": "SMS development data", "start_pos": 78, "end_pos": 98, "type": "DATASET", "confidence": 0.7173701127370199}]}]}