{"title": [{"text": "An Iterative 'Sudoku Style' Approach to Subgraph-based Word Sense Disambiguation", "labels": [], "entities": [{"text": "Subgraph-based Word Sense Disambiguation", "start_pos": 40, "end_pos": 80, "type": "TASK", "confidence": 0.7622724547982216}]}], "abstractContent": [{"text": "We introduce an iterative approach to subgraph-based Word Sense Disambigua-tion (WSD).", "labels": [], "entities": [{"text": "subgraph-based Word Sense Disambigua-tion (WSD)", "start_pos": 38, "end_pos": 85, "type": "TASK", "confidence": 0.6941576940672738}]}, {"text": "Inspired by the Sudoku puzzle , it significantly improves the precision and recall of disambiguation.", "labels": [], "entities": [{"text": "precision", "start_pos": 62, "end_pos": 71, "type": "METRIC", "confidence": 0.9994744658470154}, {"text": "recall", "start_pos": 76, "end_pos": 82, "type": "METRIC", "confidence": 0.9979392886161804}]}, {"text": "We describe how conventional subgraph-based WSD treats the two steps of (1) subgraph construction and (2) disambiguation via graph centrality measures as ordered and atomic.", "labels": [], "entities": [{"text": "WSD", "start_pos": 44, "end_pos": 47, "type": "TASK", "confidence": 0.7879667282104492}, {"text": "subgraph construction", "start_pos": 76, "end_pos": 97, "type": "TASK", "confidence": 0.7026967406272888}]}, {"text": "Consequently, researchers tend to focus on improving either of these two steps individually , overlooking the fact that these steps can complement each other if they are allowed to interact in an iterative manner.", "labels": [], "entities": []}, {"text": "We tested our iterative approach against the conventional approach fora range of well-known graph centrality measures and subgraph types, at the sentence and document level.", "labels": [], "entities": []}, {"text": "The results demonstrated that an average performing WSD system which embraces the iterative approach , can easily compete with state-of-the-art.", "labels": [], "entities": [{"text": "WSD", "start_pos": 52, "end_pos": 55, "type": "TASK", "confidence": 0.9759149551391602}]}, {"text": "This alone warrants further investigation .", "labels": [], "entities": []}], "introductionContent": [{"text": "Explicit WSD is a two-step process of analysing a word's contextual use then deducing its intended sense.", "labels": [], "entities": []}, {"text": "When established SEN-SEVAL, the collaborative framework and forum to evaluate WSD, unsupervised systems performed poorly in comparison to their supervised counterparts (.", "labels": [], "entities": []}, {"text": "A review of the literature shows there has been a healthy rivalry between the two, in which proponents of unsupervised WSD have long sought to vindicate its potential since two decades ago to even more recent times.", "labels": [], "entities": [{"text": "WSD", "start_pos": 119, "end_pos": 122, "type": "TASK", "confidence": 0.9500299692153931}]}, {"text": "As Pedersen (2007) rightly states, supervised systems are bound by their training data, and therefore are limited in portability and flexibility in the face of new domains, changing applications, or different languages.", "labels": [], "entities": []}, {"text": "This knowledge acquisition bottleneck, coined by, can be alleviated by unsupervised systems that exploit the portability and flexibility of Lexical Knowledge Bases (LKBs).", "labels": [], "entities": []}, {"text": "As of 2007, SENSEVAL became SEMEVAL, offering a more diverse range of semantic tasks.", "labels": [], "entities": []}, {"text": "Unsupervised knowledge-based WSD has since had its performance evaluated in terms of granularity ( ), domain (, and cross/multi-linguality (.", "labels": [], "entities": [{"text": "WSD", "start_pos": 29, "end_pos": 32, "type": "TASK", "confidence": 0.8470475077629089}]}, {"text": "Results from these tasks have demonstrated unsupervised systems are now a competitive and robust alternative to supervised systems, especially given the ever changing task-orientated settings WSD is evaluated in.", "labels": [], "entities": []}, {"text": "One such class of unsupervised knowledgebased WSD systems that we seek to improve in this paper constructs semantic subgraphs from LKBs, and then runs graph-based centrality measures such as PageRank () over them to finally select the senses (as nodes) ranked as the most relevant.", "labels": [], "entities": []}, {"text": "This class is known as subgraph-based WSD, characterised over the last decade by performing the two key steps of (1) subgraph construction and (2) disambiguation via graph centrality measures, in an ordered atomic sequence.", "labels": [], "entities": [{"text": "subgraph construction", "start_pos": 117, "end_pos": 138, "type": "TASK", "confidence": 0.7096966952085495}]}, {"text": "We refer to this characteristic as the conventional approach to subgraph-based WSD.", "labels": [], "entities": [{"text": "subgraph-based WSD", "start_pos": 64, "end_pos": 82, "type": "TASK", "confidence": 0.585029125213623}]}, {"text": "We propose an iterative approach to subgraphbased WSD that allows for interaction between the two major steps in an incremental manner and demonstrate its effectiveness across a range of graph-based centrality measures and subgraph construction methods at the sentence and document levels of disambiguation.", "labels": [], "entities": [{"text": "subgraph construction", "start_pos": 223, "end_pos": 244, "type": "TASK", "confidence": 0.7256440818309784}]}], "datasetContent": [{"text": "In our evaluations we set out to understand a number of aspects.", "labels": [], "entities": []}, {"text": "The first evaluation is a proof of concept, to understand whether an iterative approach to subgraph WSD can in fact achieve better performance than the conventional approach.", "labels": [], "entities": []}, {"text": "The second set of experiments seeks to understand how the iterative approach works and the performance benefits and penalties of implementing the iterative approach.", "labels": [], "entities": []}, {"text": "Finally the third experiment is an elementary attempt at optimising the iterative approach to defeat the MFS baseline.", "labels": [], "entities": [{"text": "MFS baseline", "start_pos": 105, "end_pos": 117, "type": "DATASET", "confidence": 0.702018529176712}]}, {"text": "For an evaluation, we have chosen the multilingual LKB known as BabelNet (.", "labels": [], "entities": []}, {"text": "It weaves together several other LKBs, most notably WordNet and Wikipedia.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 52, "end_pos": 59, "type": "DATASET", "confidence": 0.958844780921936}, {"text": "Wikipedia", "start_pos": 64, "end_pos": 73, "type": "DATASET", "confidence": 0.8504133820533752}]}, {"text": "It also can be easily accessed with the BabelNet API, of which we have built our code base around.", "labels": [], "entities": []}, {"text": "All experiments are conducted on the most recent SemEval WSD dataset, of which is the SemEval 2013 Task 12 Multilingual WSD (English) data set.", "labels": [], "entities": [{"text": "SemEval WSD dataset", "start_pos": 49, "end_pos": 68, "type": "DATASET", "confidence": 0.7641834616661072}, {"text": "SemEval 2013 Task 12 Multilingual WSD (English) data set", "start_pos": 86, "end_pos": 142, "type": "DATASET", "confidence": 0.6030039055780931}]}, {"text": "For this experiment we simply set out to see how the iterative approach performed compared to the conventional approach in a range of experimental conditions.", "labels": [], "entities": []}, {"text": "Directed and unweighted subgraphs were used, namely subtree paths and shortest paths subgraphs with L = 2.: Improvements of using the Iterative Approach at the Sentence Level senses anchored to the same lemma assisting each other's \u03c6 score (as discussed in Section 3.1), the SENSE_SHIFTS filter that is provided by the BabelNet API was also applied.", "labels": [], "entities": [{"text": "SENSE_SHIFTS filter", "start_pos": 275, "end_pos": 294, "type": "METRIC", "confidence": 0.8007490485906601}]}, {"text": "This filter removes any path P a\u2192b such that s a , s b \u2208 R( i ).", "labels": [], "entities": []}, {"text": "Disambiguation was attempted at the document and sentence level, making use of the eight well-known graph centrality measures listed in section 4.2.", "labels": [], "entities": [{"text": "Disambiguation", "start_pos": 0, "end_pos": 14, "type": "TASK", "confidence": 0.92908775806427}]}, {"text": "For this experiment no means of optimisation were applied.", "labels": [], "entities": []}, {"text": "Therefore Personalised PageRank was not used, and traditional PageRank took on a uniform random surfing vector.", "labels": [], "entities": [{"text": "PageRank", "start_pos": 62, "end_pos": 70, "type": "DATASET", "confidence": 0.9306133389472961}]}, {"text": "Default values of 0.85 and 30 for damping factor and maximum iterations were set respectively.", "labels": [], "entities": []}, {"text": "First and foremost, it is clear from that the iterative approach outperforms the conventional approach, regardless of the subgraph used, level of disambiguation, or the graph centrality measure employed.", "labels": [], "entities": []}, {"text": "Since no graph centrality measure or subgraph were optimised, let this experiment prove that the iterative approach has the potential to improve any WSD system that implements it.", "labels": [], "entities": []}, {"text": "At the document level for both subgraphs the FScores were very close to the Most Frequent Sense (MFS) baseline for this task of 66.50.", "labels": [], "entities": [{"text": "FScores", "start_pos": 45, "end_pos": 52, "type": "METRIC", "confidence": 0.6651578545570374}, {"text": "Most Frequent Sense (MFS) baseline", "start_pos": 76, "end_pos": 110, "type": "METRIC", "confidence": 0.7916211017540523}]}, {"text": "It is notoriously hard to beat and only one team () managed to beat it for this task.", "labels": [], "entities": []}, {"text": "For all subtree subgraphs, we observe that In-Degree is clearly the best choice of centrality measure, while HITS (hub) enjoys the most improvement.", "labels": [], "entities": []}, {"text": "We also observe that applying the iterative approach to Betweenness Centrality on shortest paths is a great combination at both the document and sentence level, most probably due to the measure being based on shortest paths.", "labels": [], "entities": []}, {"text": "Furthermore it is worth noting, the results at the sentence level for all graph centrality measures on shortest path subgraphs are quite poor, but highly improved, this is likely to our restriction of L = 2 causing the subgraphs to be much sparser and broken up into many components.", "labels": [], "entities": []}, {"text": "We also provide here an example from the data set in which the incorrect disambiguation of the lemma cup via the conventional approach was corrected by the iterative approach.", "labels": [], "entities": []}, {"text": "This example is the seventh sentence in the eleventh document (d011.s007).", "labels": [], "entities": []}, {"text": "Each word's degree of polysemy is denoted in square brackets.", "labels": [], "entities": []}, {"text": "The potential graph constructed from this sentence is illustrated in as a shortest paths subgraph.", "labels": [], "entities": []}, {"text": "The darker edges portray the subgraph iteratively constructed up to a polysemy \u03c1 \u2264 8 (in order to disambiguate cup), whereas the lighter edges portray the greater subgraph constructed if the conventional approach is employed.", "labels": [], "entities": []}, {"text": "Note that although the lemma cup has eight senses, only three are shown due to the application of the previously mentioned SENSE_SHIFTS filter.", "labels": [], "entities": [{"text": "SENSE", "start_pos": 123, "end_pos": 128, "type": "METRIC", "confidence": 0.7594937682151794}]}, {"text": "The remaining five senses of cup were filtered out since they were notable to link to a sense up to L = 2 hops away that is anchored to an alterative lemma.", "labels": [], "entities": []}, {"text": "\u2022 cup#1 -A small open container usually used for drinking; usually has a handle.", "labels": [], "entities": []}, {"text": "\u2022 cup#7 -The hole (or metal container in the hole) on a golf green.", "labels": [], "entities": []}, {"text": "\u2022 cup#8 -A large metal vessel with two handles that is awarded as atrophy to the winner of a competition.", "labels": [], "entities": []}, {"text": "Given the context, the eighth sense of cup is the correct sense, the type we know as atrophy.", "labels": [], "entities": []}, {"text": "For the conventional approach, if \u03c6 is a centrality measure of Out-Degree then the eighth sense of cup is easily chosen by having one extra outgoing edge than the other two senses for cup.", "labels": [], "entities": [{"text": "Out-Degree", "start_pos": 63, "end_pos": 73, "type": "METRIC", "confidence": 0.9587342143058777}]}, {"text": "Yet if \u03c6 is a centrality measure of In-Degree or Betweenness Centrality, all three senses of cup now have the same score, zero.", "labels": [], "entities": []}, {"text": "Therefore in our results the first sense is chosen which is incorrect.", "labels": [], "entities": []}, {"text": "On the other hand, if  The shortest paths cup#1\u2192handle#1\u2192golf_club#2 and cup#7\u2192golf#1\u2192golf_club#2 only exist because the sense golf_club#2 (anchored to the more polysemous lemma club) is present, if it was not then the SENSE_SHIFTS filter would have removed these alternative senses.", "labels": [], "entities": [{"text": "SENSE", "start_pos": 219, "end_pos": 224, "type": "METRIC", "confidence": 0.805769681930542}]}, {"text": "This demonstrates that if the senses of more polysemous lemmas are introduced into the subgraph too soon, they can interfere rather than help with disambiguation.", "labels": [], "entities": []}, {"text": "Secondly with each disambiguation at lower levels of polysemy, a more stable context is constructed to perform the disambiguation of much more polysemous lemmas later.", "labels": [], "entities": []}, {"text": "Therefore in an iteratively constructed subgraph with cup already disambiguated, would mean the other two senses of cup would no longer be present.", "labels": [], "entities": []}, {"text": "This ensures that club#2 (the correct answer) would have a much stronger chance of being selected than golf_club#2, which would have only one incoming edge from handle#1.", "labels": [], "entities": [{"text": "golf", "start_pos": 103, "end_pos": 107, "type": "DATASET", "confidence": 0.8306779861450195}]}, {"text": "Note the conventional approach would lend golf_club#2 one extra incoming edge than club#2 has, which could be problematic if \u03c6 is a centrality measure of In-Degree.", "labels": [], "entities": []}, {"text": "An obvious caveat of the iterative approach is that it requires the construction of several subgraphs as \u03c1 increases, which of course will require extra computation and time which is a penalty for the improved precision and recall.", "labels": [], "entities": [{"text": "precision", "start_pos": 210, "end_pos": 219, "type": "METRIC", "confidence": 0.999200165271759}, {"text": "recall", "start_pos": 224, "end_pos": 230, "type": "METRIC", "confidence": 0.9982615113258362}]}, {"text": "We decided to investigate the extent to which this happens.", "labels": [], "entities": []}, {"text": "We selected Betweenness Centrality and PageRank from Experiment 1, in which both use shortest path subgraphs at the document level.", "labels": [], "entities": []}, {"text": "This is because a) they acquired good results at the document level and b) with only 13 documents there are less data points on the plots making it easier to read as opposed to the hundreds of sentences.", "labels": [], "entities": []}, {"text": "Firstly from Figures 6(a) and (b) we see that there is a substantial improvement in F-Score for almost all documents, except for two for \u03c6 = Betweenness Centrality and one for \u03c6 = PageRank.", "labels": [], "entities": [{"text": "F-Score", "start_pos": 84, "end_pos": 91, "type": "METRIC", "confidence": 0.9954934120178223}, {"text": "PageRank", "start_pos": 180, "end_pos": 188, "type": "DATASET", "confidence": 0.9385640025138855}]}, {"text": "With some exceptions, for most documents the increased amount of time to disambiguate is not unreasonable.", "labels": [], "entities": []}, {"text": "For this experiment, applying the iterative approach to Betweenness Centrality resulted in a mean 231% increase in processing time, from 3.54 to 11.73 seconds to acquire a mean F-Score improvement of +8.85.", "labels": [], "entities": [{"text": "F-Score", "start_pos": 177, "end_pos": 184, "type": "METRIC", "confidence": 0.9942638278007507}]}, {"text": "Again for PageRank, a mean increase of 343% in processing time, from 1.95 to 8.64 seconds to acquire a F-Score improvement of +7.16 was observed.", "labels": [], "entities": [{"text": "PageRank", "start_pos": 10, "end_pos": 18, "type": "DATASET", "confidence": 0.9088900685310364}, {"text": "F-Score", "start_pos": 103, "end_pos": 110, "type": "METRIC", "confidence": 0.9993268251419067}]}, {"text": "We wanted to investigate why in some cases, the iterative approach can produce poorer results than the conventional approach.", "labels": [], "entities": []}, {"text": "We looked at aspects of the subgraphs such as order, size, density, and number of components.", "labels": [], "entities": []}, {"text": "Eventually we came to the conclusion that, just like in a Sudoku puzzle, if there are not enough hints to start with, the possibility of finishing the puzzle becomes slim.", "labels": [], "entities": []}, {"text": "Therefore we suspected that if there were not enough monosemous lemmas, to construct the initial G L , then the effectiveness of the iterative approach could be negated.", "labels": [], "entities": []}, {"text": "It turns out, as observed in and (b) on the following page that this does effect the outcome.", "labels": [], "entities": []}, {"text": "On the horizontal axis, document monosemy represents the percentage of lemmas in a document, not counting duplicates, that are monosemous.", "labels": [], "entities": []}, {"text": "The vertical axis on the other hand represents the difference in F-Score between the conventional and iterative approach.", "labels": [], "entities": [{"text": "F-Score", "start_pos": 65, "end_pos": 72, "type": "METRIC", "confidence": 0.9962653517723083}]}, {"text": "Through a simple linear regression of the scatter plot, we observe an increased effectiveness of the iterative approach.", "labels": [], "entities": []}, {"text": "This observation is important, because a WSD system may decide on which approach to use based on a document's monosemy.", "labels": [], "entities": [{"text": "WSD", "start_pos": 41, "end_pos": 44, "type": "TASK", "confidence": 0.9119293093681335}]}, {"text": "With m representing document monosemy, and \u2206F representing the change in F-Score induced by the iterative approach, the slopes observed in  Briefly, we made an effort into optimising the iterative approach with subtree subgraphs, and compared these results with systems from) in  Firstly, we were able to marginally improve our original result as team DAEBAK!, by applying the iterative approach to our Peripheral Diversity centrality measure (It-PD).", "labels": [], "entities": []}, {"text": "Next we tried Personalised PageRank (It-PPR) with a surfing vector biased towards only Monosemous senses.", "labels": [], "entities": []}, {"text": "We also included regular PageRank (It-/PR) with a Uniform surfing vector as a reference point.", "labels": [], "entities": []}, {"text": "It-PPR almost defeated the MFS baseline of 66.50, but lacked recall.", "labels": [], "entities": [{"text": "MFS baseline", "start_pos": 27, "end_pos": 39, "type": "DATASET", "confidence": 0.7309246957302094}, {"text": "recall", "start_pos": 61, "end_pos": 67, "type": "METRIC", "confidence": 0.9991355538368225}]}, {"text": "To rectify this, the MFS baseline was used as a back-off strategy (It-PPR[M] + ) , which then led Note that plus + implies the use of a back-off strategy.", "labels": [], "entities": [{"text": "MFS baseline", "start_pos": 21, "end_pos": 33, "type": "DATASET", "confidence": 0.8415960669517517}]}, {"text": "to us beating the MFS baseline.", "labels": [], "entities": [{"text": "MFS baseline", "start_pos": 18, "end_pos": 30, "type": "DATASET", "confidence": 0.7311480939388275}]}, {"text": "As for the other teams, GETALP () made use of an Ant Colony algorithm, while UMCC-DLSI () also made use of PPR, except they based the surfing vector on SemCor () sense frequencies, set L = 5 for shortest paths subgraphs, and disambiguated using resources external to BabelNet.", "labels": [], "entities": [{"text": "GETALP", "start_pos": 24, "end_pos": 30, "type": "DATASET", "confidence": 0.8373969197273254}, {"text": "UMCC-DLSI", "start_pos": 77, "end_pos": 86, "type": "DATASET", "confidence": 0.9146521687507629}]}, {"text": "Since their implementation of PPR beats ours, it would be interesting to see how effective the iterative approach could be on their results.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Improvements of using the Iterative Approach at the Document Level", "labels": [], "entities": []}, {"text": " Table 2: Improvements of using the Iterative Approach at the Sentence Level", "labels": [], "entities": []}, {"text": " Table 3: Comparison to SemEval 2013 Task 12", "labels": [], "entities": [{"text": "SemEval 2013 Task", "start_pos": 24, "end_pos": 41, "type": "TASK", "confidence": 0.8330375750859579}]}]}