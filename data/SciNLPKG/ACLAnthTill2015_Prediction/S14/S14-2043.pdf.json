{"title": [{"text": "ECNU: Leveraging on Ensemble of Heterogeneous Features and Information Enrichment for Cross Level Semantic Similarity Estimation", "labels": [], "entities": [{"text": "ECNU", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.9399411082267761}, {"text": "Cross Level Semantic Similarity Estimation", "start_pos": 86, "end_pos": 128, "type": "TASK", "confidence": 0.6521356403827667}]}], "abstractContent": [{"text": "This paper reports our submissions to the Cross Level Semantic Similarity (CLSS) task in SemEval 2014.", "labels": [], "entities": [{"text": "Cross Level Semantic Similarity (CLSS) task in SemEval 2014", "start_pos": 42, "end_pos": 101, "type": "TASK", "confidence": 0.7638606374913995}]}, {"text": "We submitted one Random Forest regression system on each cross level text pair, i.e., Paragraph to Sentence (P-S), Sentence to Phrase (S-Ph), Phrase to Word (Ph-W) and Word to Sense (W-Se).", "labels": [], "entities": []}, {"text": "For text pairs on P-S level and S-Ph level, we consider them as sentences and extract heterogeneous types of similarity features, i.e., string features, knowledge based features, corpus based features, syntactic features, machine translation based features, multi-level text features , etc.", "labels": [], "entities": []}, {"text": "For text pairs on Ph-W level and W-Se level, due to lack of information , most of these features are not applicable or available.", "labels": [], "entities": []}, {"text": "To overcome this problem, we propose several information enrichment methods using WordNet synonym and definition.", "labels": [], "entities": [{"text": "information enrichment", "start_pos": 45, "end_pos": 67, "type": "TASK", "confidence": 0.7678999900817871}]}, {"text": "Our systems rank the 2nd out of 18 teams both on Pearson correlation (official rank) and Spearman rank correlation.", "labels": [], "entities": [{"text": "Pearson correlation (official rank)", "start_pos": 49, "end_pos": 84, "type": "METRIC", "confidence": 0.8002788921197256}, {"text": "Spearman rank correlation", "start_pos": 89, "end_pos": 114, "type": "METRIC", "confidence": 0.7387837370236715}]}, {"text": "Specifically, our systems take the second place on P-S level, S-Ph level and Ph-W level and the 4th place on W-Se level in terms of Pearson correlation.", "labels": [], "entities": [{"text": "Pearson correlation", "start_pos": 132, "end_pos": 151, "type": "METRIC", "confidence": 0.8898451924324036}]}], "introductionContent": [{"text": "Semantic similarity is an essential component of many applications in Natural Language Processing (NLP).", "labels": [], "entities": [{"text": "Semantic similarity", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.8188066482543945}]}, {"text": "Previous works often focus on text semantic similarity on the same level, i.e., paragraph to paragraph or sentence to sentence, and many effective text semantic measurements have been proposed,).", "labels": [], "entities": []}, {"text": "However, in many real world cases, the two texts may not always be on the same level.", "labels": [], "entities": []}, {"text": "The Cross Level Semantic Similarity (CLSS) task in SemEval 2014 provides a universal platform to measure the degree of semantic equivalence between two texts across different levels.", "labels": [], "entities": [{"text": "Cross Level Semantic Similarity (CLSS) task in SemEval 2014", "start_pos": 4, "end_pos": 63, "type": "TASK", "confidence": 0.7651690353046764}]}, {"text": "For each text pair on four cross levels, i.e., Paragraph to Sentence (P-S), Sentence to Phrase (S-Ph), Phrase to Word (Ph-W) and Word to Sense (W-Se), participants are required to return a similarity score which ranges from 0 (no relation) to 4 (semantic equivalence).", "labels": [], "entities": []}, {"text": "We participate in all the four cross levels and take the second place out of all 18 teams both on Pearson correlation (official) and Spearman correlation ranks.", "labels": [], "entities": [{"text": "Pearson correlation", "start_pos": 98, "end_pos": 117, "type": "METRIC", "confidence": 0.8616976737976074}, {"text": "Spearman correlation", "start_pos": 133, "end_pos": 153, "type": "METRIC", "confidence": 0.7247169315814972}]}, {"text": "In this work, we present a supervised regression system for each cross level separately.", "labels": [], "entities": []}, {"text": "For P-S level and S-Ph level, we regard the paragraph of P-S as along sentence, and the phrase of SPh as a short sentence.", "labels": [], "entities": []}, {"text": "Then we use various types of text similarity features including string features, knowledge based features, corpus based features, syntactic features, machine translation based features, multi-level text features and soon, to capture the semantic similarity between two texts.", "labels": [], "entities": []}, {"text": "Some of these features are borrowed from our previous system in the Semantic Textual Similarity (STS) task in * SEM Shared Task 2013 (Zhu and Lan, 2013).", "labels": [], "entities": [{"text": "Semantic Textual Similarity (STS) task", "start_pos": 68, "end_pos": 106, "type": "TASK", "confidence": 0.7688304100717817}, {"text": "SEM Shared Task 2013", "start_pos": 112, "end_pos": 132, "type": "TASK", "confidence": 0.7527037262916565}]}, {"text": "Others followed the previous work in and).", "labels": [], "entities": []}, {"text": "For Ph-W level and W-Se level, since the text pairs lack contextual information, for example, word or sense alone no longer shares the property of sentence, most features used in P-S level and S-Ph level are not applicable or available.", "labels": [], "entities": []}, {"text": "To overcome the problem of insufficient information in word and sense level, we propose several information enrichment methods to extend information with the aid of WordNet, which significantly improved the system performance.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 165, "end_pos": 172, "type": "DATASET", "confidence": 0.9469401836395264}]}, {"text": "The rest of this paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 describes the similarity features used on four cross levels in detail.", "labels": [], "entities": []}, {"text": "Section 3 presents experiments and the results of four cross levels on training data and test data.", "labels": [], "entities": []}, {"text": "Conclusions and future work are given in Section 4.", "labels": [], "entities": []}], "datasetContent": [{"text": "We adopt supervised regression model for each cross level.", "labels": [], "entities": []}, {"text": "In order to compare the performance of different regression algorithms, we perform 5-fold cross validation on training data for each cross level.", "labels": [], "entities": []}, {"text": "We used several regression algorithms including Support Vector Regression (SVR) with 3 different kernels (i.e., linear, polynomial and rbf), Random Forest, Stochastic Gradient Descent (SGD) and Decision Tree implemented in the scikit-learn toolkit (Pedregosa et al., 2011).", "labels": [], "entities": []}, {"text": "The system performance is evaluated in Pearson correlation (r) (official measure) and Spearman's rank correlation (\u03c1).", "labels": [], "entities": [{"text": "Pearson correlation (r)", "start_pos": 39, "end_pos": 62, "type": "METRIC", "confidence": 0.9711380720138549}, {"text": "Spearman's rank correlation (\u03c1)", "start_pos": 86, "end_pos": 117, "type": "METRIC", "confidence": 0.819935313292912}]}, {"text": "show the averaged performance of different regression algorithms in terms of Pearson correlation (r) and Spearman's rank correlation (\u03c1) on the training data of P-S level and S-Ph level using 5-fold cross validation, where the standard deviation is given in brackets.", "labels": [], "entities": [{"text": "Pearson correlation (r)", "start_pos": 77, "end_pos": 100, "type": "METRIC", "confidence": 0.9711051344871521}, {"text": "Spearman's rank correlation (\u03c1)", "start_pos": 105, "end_pos": 136, "type": "METRIC", "confidence": 0.811192831822804}]}, {"text": "The results show that Random Forest performs the best both on P-S level and S-Ph level whether in (r) or (\u03c1).", "labels": [], "entities": []}, {"text": "We also find that the results of P-S level are better than that of S-Ph level, and the reason maybe that paragraph and sentence pair contain more information than the sentence and phrase pair.: Results of different algorithms using 5-fold cross validation on training data of S-Ph level shows the results of different regression algorithms and different feature sets in terms of rand \u03c1 on the training data of Ph-W level using 5-fold cross validation, where the basic features are denoted as Feature Set A and their combination with word definition expansion features are denoted as Feature Set B. The results show that almost all algorithms performance have been improved by using word definition expansion feature except Decision Tree.", "labels": [], "entities": []}, {"text": "This proves the effectiveness of the information enrichment method we proposed in this level.", "labels": [], "entities": [{"text": "information enrichment", "start_pos": 37, "end_pos": 59, "type": "TASK", "confidence": 0.7849431931972504}]}, {"text": "Besides, Random Forest achieves the best performance again with r=44% and \u03c1=41%.", "labels": [], "entities": []}, {"text": "However, in comparison with P-S level and S-Ph level, all scores in drop a lot even with information enrichment method.", "labels": [], "entities": []}, {"text": "The possible reason maybe two: the reduction of information on Ph-W level and our information enrichment method brings in a certain noise as well.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 3: Results of different algorithms using 5-fold cross validation on training data of Ph-W level", "labels": [], "entities": [{"text": "Ph-W", "start_pos": 92, "end_pos": 96, "type": "DATASET", "confidence": 0.9043666124343872}]}, {"text": " Table 6: Pearson Correlation (official) on test data", "labels": [], "entities": [{"text": "Pearson Correlation", "start_pos": 10, "end_pos": 29, "type": "METRIC", "confidence": 0.8620996475219727}]}, {"text": " Table 7: Spearman Correlation on test data", "labels": [], "entities": [{"text": "Spearman Correlation", "start_pos": 10, "end_pos": 30, "type": "TASK", "confidence": 0.8954488635063171}]}]}