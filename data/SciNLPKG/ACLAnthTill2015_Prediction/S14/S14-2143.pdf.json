{"title": [{"text": "UTU: Disease Mention Recognition and Normalization with CRFs and Vector Space Representations", "labels": [], "entities": [{"text": "UTU", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.8960446715354919}, {"text": "Disease Mention Recognition", "start_pos": 5, "end_pos": 32, "type": "TASK", "confidence": 0.805644303560257}]}], "abstractContent": [{"text": "In this paper we present our system participating in the SemEval-2014 Task 7 in both subtasks A and B, aiming at recognizing and normalizing disease and symptom mentions from electronic medical records respectively.", "labels": [], "entities": [{"text": "SemEval-2014 Task 7", "start_pos": 57, "end_pos": 76, "type": "TASK", "confidence": 0.8059197862943014}, {"text": "recognizing and normalizing disease and symptom mentions from electronic medical records", "start_pos": 113, "end_pos": 201, "type": "TASK", "confidence": 0.7504615485668182}]}, {"text": "In subtask A, we used an existing NER system, NERsuite, with our own feature set tailored for this task.", "labels": [], "entities": [{"text": "NERsuite", "start_pos": 46, "end_pos": 54, "type": "DATASET", "confidence": 0.8915929198265076}]}, {"text": "For subtask B, we combined word vector representations and supervised machine learning to map the recognized mentions to the corresponding UMLS concepts.", "labels": [], "entities": []}, {"text": "Our system was placed 2nd and 5th out of 21 participants on subtasks A and B respectively showing competitive performance .", "labels": [], "entities": []}], "introductionContent": [{"text": "The SemEval 2014 task 7 aims to advance the development of tools for analyzing clinical text.", "labels": [], "entities": [{"text": "SemEval 2014 task 7", "start_pos": 4, "end_pos": 23, "type": "TASK", "confidence": 0.758247897028923}, {"text": "analyzing clinical text", "start_pos": 69, "end_pos": 92, "type": "TASK", "confidence": 0.8091091314951578}]}, {"text": "The task is organized by providing the researchers annotated clinical records to develop systems that can detect the mentions of diseases and symptoms in medical records.", "labels": [], "entities": []}, {"text": "In particular, the SemEval task 7 comprises two subtasks, recognizing the mentions of diseases and symptoms (task A) and mapping the mentions to unique concept identifiers that belong to the semantic group of disorders in the Unified Medical Language System (UMLS).", "labels": [], "entities": [{"text": "SemEval task 7", "start_pos": 19, "end_pos": 33, "type": "TASK", "confidence": 0.8830957412719727}]}, {"text": "Our team participated in both of these subtasks.", "labels": [], "entities": []}, {"text": "In subtask A, we used an existing named entity recognition (NER) system, NERsuite, supplemented with UMLS dictionary and normalization similarity features.", "labels": [], "entities": [{"text": "named entity recognition (NER)", "start_pos": 34, "end_pos": 64, "type": "TASK", "confidence": 0.8082478940486908}]}, {"text": "In subtask B, we combined compositional word vector representations * These authors contributed equally.", "labels": [], "entities": []}, {"text": "This work is licensed under a Creative Commons Attribution 4.0 International Licence.", "labels": [], "entities": []}, {"text": "Page numbers and proceedings footer are added by the organisers.", "labels": [], "entities": []}, {"text": "Licence details: http://creativecommons.org/licenses/by/4.0/ with supervised machine learning to map the recognized mentions from task A to the UMLS concepts.", "labels": [], "entities": []}, {"text": "Our best systems, evaluated on strict matching criteria, achieved F-score of 76.6% for the subtask A and accuracy of 60.1% for the subtask B, showing competitive performance in both tasks.", "labels": [], "entities": [{"text": "F-score", "start_pos": 66, "end_pos": 73, "type": "METRIC", "confidence": 0.9996546506881714}, {"text": "accuracy", "start_pos": 105, "end_pos": 113, "type": "METRIC", "confidence": 0.9995688796043396}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: The results of our different NERsuite  models, announced by the organizers.", "labels": [], "entities": []}, {"text": " Table 2: Evaluation of the different approaches  to detect CUI-less entities on the official develop- ment set compared to a baseline without CUI-less  detection and an oracle method with perfect de- tection. This evaluation was done with the entities  recognized by our NER system instead of the gold  standard entities. B = baseline without CUI-less  detection, T = similarity threshold, L = Lexicon- based method, C = classifier, O = Oracle.", "labels": [], "entities": [{"text": "NER system", "start_pos": 272, "end_pos": 282, "type": "DATASET", "confidence": 0.8721525073051453}]}, {"text": " Table 3: Official evaluation results for the top 5  teams in the normalization task.", "labels": [], "entities": [{"text": "normalization task", "start_pos": 66, "end_pos": 84, "type": "TASK", "confidence": 0.9285871386528015}]}]}