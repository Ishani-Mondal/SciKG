{"title": [{"text": "Link\u00f6ping: Cubic-Time Graph Parsing with a Simple Scoring Scheme", "labels": [], "entities": [{"text": "Cubic-Time Graph Parsing", "start_pos": 11, "end_pos": 35, "type": "TASK", "confidence": 0.6741066873073578}]}], "abstractContent": [{"text": "We turn the Eisner algorithm for parsing to projective dependency trees into a cubic-time algorithm for parsing to a restricted class of directed graphs.", "labels": [], "entities": [{"text": "parsing to projective dependency trees", "start_pos": 33, "end_pos": 71, "type": "TASK", "confidence": 0.8638786673545837}, {"text": "parsing", "start_pos": 104, "end_pos": 111, "type": "TASK", "confidence": 0.9666607975959778}]}, {"text": "To extend the algorithm into a data-driven parser, we combine it with an edge-factored feature model and online learning.", "labels": [], "entities": []}, {"text": "We report and discuss results on the SemEval-2014 Task 8 data sets (Oepen et al., 2014).", "labels": [], "entities": [{"text": "SemEval-2014 Task 8 data sets", "start_pos": 37, "end_pos": 66, "type": "DATASET", "confidence": 0.7420663893222809}]}], "introductionContent": [{"text": "This paper describes the system that we submitted to the closed track of the SemEval-2014 Task on Broad-Coverage Semantic Dependency Parsing ().", "labels": [], "entities": [{"text": "SemEval-2014 Task on Broad-Coverage Semantic Dependency Parsing", "start_pos": 77, "end_pos": 140, "type": "TASK", "confidence": 0.7578128746577671}]}, {"text": "1 However, the main contribution of the paper is not the system as such (which had the lowest score among all systems submitted to the task), but the general approach for which it is a proof of concept.", "labels": [], "entities": []}, {"text": "Graphs support natural representations of linguistic structure.", "labels": [], "entities": []}, {"text": "For this reason, algorithms that can learn, process and transform graphs are of central importance to language technology.", "labels": [], "entities": []}, {"text": "Yet, most of the algorithms that are used in natural language processing today focus on the restricted case of trees, and do so fora reason: Computation on general graphs is hard or even intractable, and efficient processing is possible only for restricted classes (cf.).", "labels": [], "entities": [{"text": "natural language processing", "start_pos": 45, "end_pos": 72, "type": "TASK", "confidence": 0.6722650130589803}]}, {"text": "The task then is to identify classes of graphs that are both expressive enough to cover the linguistic data, and restricted enough to facilitate efficient processing.", "labels": [], "entities": []}, {"text": "This paper shows that there are graphs that satisfy both of these desiderata.", "labels": [], "entities": []}, {"text": "Our system is based on anew algorithm for parsing to a restricted class of directed graphs (Section 2).", "labels": [], "entities": []}, {"text": "This class is restricted in so far as our algorithm runs in cubic time with respect to the length of the sentence; it thus has the same asymptotic complexity as parsing with context-free phrase structure grammars.", "labels": [], "entities": []}, {"text": "The class of graphs defined by our algorithm is also expressive, in so far that it covers more than 98% of the SemEval data.", "labels": [], "entities": [{"text": "SemEval data", "start_pos": 111, "end_pos": 123, "type": "DATASET", "confidence": 0.8083032667636871}]}, {"text": "To demonstrate that our parsing algorithm can be turned into a practical system, we combine it with two techniques taken straight from the literature on data-driven syntactic dependency parsing: an edge-factored scoring model, as it has been used as the core of practical parsers since the seminal work of, and online learning using the structured perceptron, in the style of.", "labels": [], "entities": [{"text": "parsing algorithm", "start_pos": 24, "end_pos": 41, "type": "TASK", "confidence": 0.9032340943813324}, {"text": "syntactic dependency parsing", "start_pos": 165, "end_pos": 193, "type": "TASK", "confidence": 0.6984224120775858}]}, {"text": "State-of-the-art parsers use considerably more advanced (and computationally more demanding) techniques, and therefore our system cannot be expected to deliver competitive results.", "labels": [], "entities": []}, {"text": "(Its results on the SemEval data are reported in Section 4.)", "labels": [], "entities": [{"text": "SemEval data", "start_pos": 20, "end_pos": 32, "type": "DATASET", "confidence": 0.8452136516571045}]}, {"text": "Instead, the main point of our contribution to the SemEval Task is to provide evidence that research on classes of graphs that balance linguistic coverage and parsing efficiency holds a lot of potential.", "labels": [], "entities": [{"text": "SemEval Task", "start_pos": 51, "end_pos": 63, "type": "TASK", "confidence": 0.9208083748817444}]}], "datasetContent": [{"text": "We report experimental results on the SemEval data sets (closed track).", "labels": [], "entities": [{"text": "SemEval data sets", "start_pos": 38, "end_pos": 55, "type": "DATASET", "confidence": 0.832153856754303}]}, {"text": "We trained one parser for each representation (DM, PAS, PCEDT).", "labels": [], "entities": [{"text": "PAS", "start_pos": 51, "end_pos": 54, "type": "METRIC", "confidence": 0.9213353395462036}]}, {"text": "Averaged perceptron training can be parametrized by the number N of iterations over the training data; to determine the value of this parameter, for each representation type and each 1 \u00c4 N \u00c4 10 we trained a development system using the recommended development train/dev-split and selected that value of N which gave the highest accuracy on the held-out data.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 328, "end_pos": 336, "type": "METRIC", "confidence": 0.9991256594657898}]}, {"text": "The selected values and the number of (binary) features in the resulting systems are reported in.", "labels": [], "entities": []}, {"text": "Training took around 8 minutes per iteration on an iMac computer (Late 2013, 3,4 GHz Intel Core i5) with a 6 GB Java heap size.", "labels": [], "entities": []}, {"text": "reports the labelled precision (LP) and labelled recall (LR) of our system on the final test data.", "labels": [], "entities": [{"text": "labelled precision (LP)", "start_pos": 12, "end_pos": 35, "type": "METRIC", "confidence": 0.8795966386795044}, {"text": "labelled recall (LR)", "start_pos": 40, "end_pos": 60, "type": "METRIC", "confidence": 0.862914788722992}]}, {"text": "Compared to the tree-based baseline, our system has substantially lower precision (between 4.66 and 14.16 points) but substantially higher recall (between 2.27 and 39.81 points).", "labels": [], "entities": [{"text": "precision", "start_pos": 72, "end_pos": 81, "type": "METRIC", "confidence": 0.9993415474891663}, {"text": "recall", "start_pos": 139, "end_pos": 145, "type": "METRIC", "confidence": 0.9996013045310974}]}, {"text": "Compared to the top-scoring system, our system is way behind in terms of both scores (11.11-16.19 points).", "labels": [], "entities": []}, {"text": "The scores of our system are also substantially below the task average, which resulted in it being ranked last of all six systems participating in the closed track.", "labels": [], "entities": []}, {"text": "Given these results, we have refrained from doing a detailed error analysis.", "labels": [], "entities": []}, {"text": "It maybe interesting to note, however, that our system is the only one in the task for which labelled F1 is higher on the DM data than on the PAS data.: Characteristics of the trained models.", "labels": [], "entities": [{"text": "F1", "start_pos": 102, "end_pos": 104, "type": "METRIC", "confidence": 0.9351529479026794}, {"text": "DM data", "start_pos": 122, "end_pos": 129, "type": "DATASET", "confidence": 0.8735198676586151}, {"text": "PAS data.", "start_pos": 142, "end_pos": 151, "type": "DATASET", "confidence": 0.8057729601860046}]}], "tableCaptions": [{"text": " Table 1: Upper bounds for recall (LR/LM) on the  test data for two different sets of operations.", "labels": [], "entities": [{"text": "recall (LR/LM)", "start_pos": 27, "end_pos": 41, "type": "METRIC", "confidence": 0.91224471728007}]}, {"text": " Table 2: Labelled precision (LP), labelled recall (LR), and labelled F1 (LF) scores of our own system  (Link\u00f6ping) and three points of comparison on the SemEval-2014 Task 8 test data: baseline, task average,  and the best-performing system from Peking University (", "labels": [], "entities": [{"text": "Labelled precision (LP)", "start_pos": 10, "end_pos": 33, "type": "METRIC", "confidence": 0.8288987874984741}, {"text": "recall (LR)", "start_pos": 44, "end_pos": 55, "type": "METRIC", "confidence": 0.924118384718895}, {"text": "F1 (LF) scores", "start_pos": 70, "end_pos": 84, "type": "METRIC", "confidence": 0.9349220514297485}, {"text": "Link\u00f6ping)", "start_pos": 105, "end_pos": 115, "type": "DATASET", "confidence": 0.9326672554016113}, {"text": "SemEval-2014 Task 8 test data", "start_pos": 154, "end_pos": 183, "type": "DATASET", "confidence": 0.6717251360416412}]}, {"text": " Table 3: Characteristics of the trained models.", "labels": [], "entities": []}]}