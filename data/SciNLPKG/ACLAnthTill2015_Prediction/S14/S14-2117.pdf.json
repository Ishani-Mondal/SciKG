{"title": [{"text": "TJP: Identifying the Polarity of Tweets from Context", "labels": [], "entities": [{"text": "Identifying the Polarity of Tweets from Context", "start_pos": 5, "end_pos": 52, "type": "TASK", "confidence": 0.8447740929467338}]}], "abstractContent": [{"text": "The TJP system is presented, which participated in SemEval 2014 Task 9, Part A: Contextual Polarity Disambiguation.", "labels": [], "entities": [{"text": "SemEval 2014 Task 9", "start_pos": 51, "end_pos": 70, "type": "TASK", "confidence": 0.8422055840492249}, {"text": "Contextual Polarity Disambiguation", "start_pos": 80, "end_pos": 114, "type": "TASK", "confidence": 0.6900979280471802}]}, {"text": "Our system is 'constrained', using only data provided by the organizers.", "labels": [], "entities": []}, {"text": "The goal of this task is to identify whether marking contexts are positive, negative or neutral.", "labels": [], "entities": []}, {"text": "Our system uses a support vector machine, with extensive pre-processing and achieved an overall F-score of 81.96%.", "labels": [], "entities": [{"text": "F-score", "start_pos": 96, "end_pos": 103, "type": "METRIC", "confidence": 0.9997007846832275}]}], "introductionContent": [{"text": "The aim of sentiment analysis is to identify whether the subject of a text is intended to be viewed positively of negatively by a reader.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 11, "end_pos": 29, "type": "TASK", "confidence": 0.9398425817489624}]}, {"text": "Such emotions are sometimes hidden in long sentences and are difficult to identify.", "labels": [], "entities": []}, {"text": "Consequently sentiment analysis is an active research area in natural language processing.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 13, "end_pos": 31, "type": "TASK", "confidence": 0.9631608426570892}, {"text": "natural language processing", "start_pos": 62, "end_pos": 89, "type": "TASK", "confidence": 0.6621104578177134}]}, {"text": "* Sentiment is currently conceived terms of polarity.", "labels": [], "entities": []}, {"text": "This has numerous interesting applications.", "labels": [], "entities": []}, {"text": "For example, used sentiment analysis to classify customers' reviews of hotels by using a star rating to categorize the * This work is licensed under a Creative Commons Attribution 4.0 International Licence.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 18, "end_pos": 36, "type": "TASK", "confidence": 0.9208711385726929}]}, {"text": "Page numbers and proceedings footer are added by the organisers.", "labels": [], "entities": []}, {"text": "Licence details: http://creativecommons.org/licenses/by/4.0/ reviews as bad, neutral and good.", "labels": [], "entities": []}, {"text": "Similarly, tried to predict the outcome of the German federal election through the analysis more than 100,000 tweets posted in the lead up.", "labels": [], "entities": []}, {"text": "Sentiment analysis has also used to classify whether dreams are positive or negative ().", "labels": [], "entities": [{"text": "Sentiment analysis", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.9360781908035278}]}, {"text": "This paper presents the TJP system which was submitted to SemEval 2014 Task 9, Part A: Contextual Polarity Disambiguation ().", "labels": [], "entities": [{"text": "SemEval 2014 Task 9", "start_pos": 58, "end_pos": 77, "type": "TASK", "confidence": 0.7526823878288269}, {"text": "Contextual Polarity Disambiguation", "start_pos": 87, "end_pos": 121, "type": "TASK", "confidence": 0.6500620543956757}]}, {"text": "TJP focused on the 'Constrained' task.", "labels": [], "entities": [{"text": "TJP", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.9222069978713989}]}, {"text": "The 'Constrained' task only uses data provided by the organizers.", "labels": [], "entities": []}, {"text": "That is, external resources such as sentiment inventories (e.g. Sentiwordnet) are excluded.", "labels": [], "entities": []}, {"text": "The objective of the TJP system was to use the results for comparison with our previous experiment.", "labels": [], "entities": []}, {"text": "More details of these can be found in section 5.", "labels": [], "entities": []}, {"text": "The TJP system was implemented using a support vector machine (SVM, e.g.) with the addition of extensive preprocessing such as stopword removal, negation, slang, contraction, and emoticon expansions.", "labels": [], "entities": [{"text": "stopword removal", "start_pos": 127, "end_pos": 143, "type": "TASK", "confidence": 0.7479845285415649}]}, {"text": "The remainder of this paper is constructed as follows: firstly, related work is discussed in section 2; the methodology, the experiment and results are presented in sections 3 and 4, respectively.", "labels": [], "entities": []}, {"text": "Finally a discussion and future work are given in section 5.", "labels": [], "entities": []}], "datasetContent": [{"text": "In our experiment, we used the datasets and evaluated the system using the F-score measurement.", "labels": [], "entities": [{"text": "F-score measurement", "start_pos": 75, "end_pos": 94, "type": "METRIC", "confidence": 0.9744411408901215}]}, {"text": "During pre-processing features were extracted from both datasets.", "labels": [], "entities": []}, {"text": "First, we used a frequency of word as a featured weight by calculating the frequency of word in the dataset and, during pre-processing, we labelled the emotions in both datasets.", "labels": [], "entities": []}, {"text": "The results revealed a lower than average F-score at 34.80%.", "labels": [], "entities": [{"text": "F-score", "start_pos": 42, "end_pos": 49, "type": "METRIC", "confidence": 0.999687671661377}]}, {"text": "As this was quite low we disregarded further use of term frequency as a feature weight.", "labels": [], "entities": []}, {"text": "We moved onto use Tf-Idf as the feature weight and, again, emoticons in both datasets were labelled.", "labels": [], "entities": []}, {"text": "The score of 78.10% was achieved.", "labels": [], "entities": []}, {"text": "Then, we kept the prepossessing of the training set stable by combining the features to extract from the testing data.", "labels": [], "entities": []}, {"text": "These results are presented in The highest score of 81.96% was recorded when all the features were combined and extracted from both datasets.", "labels": [], "entities": []}, {"text": "The lowest score of 36.48% was recorded when emoticons were extracted from testing data and all features were extracted from training datasets.", "labels": [], "entities": []}, {"text": "The results of the highest scoring experiment were submitted to the task organizers.", "labels": [], "entities": []}, {"text": "Following solution submissions, the task organizers announced the scores by separating the data into the following five groups: LiveJournal2014; SMS2013; Twitter2013; Twitter2014; and Twitter2014 Sarcasm.", "labels": [], "entities": [{"text": "Twitter2014", "start_pos": 167, "end_pos": 178, "type": "DATASET", "confidence": 0.8740506172180176}, {"text": "Twitter2014 Sarcasm", "start_pos": 184, "end_pos": 203, "type": "DATASET", "confidence": 0.803642064332962}]}, {"text": "This would allow the identification of any domain dependent effects.", "labels": [], "entities": []}, {"text": "However, the results showed that we achieved above average in all the datasets, as illustrated in.", "labels": [], "entities": []}, {"text": "\u00a7 Based on SVMLight ** The results in the table are from the test set 2014 in task 2A.", "labels": [], "entities": []}], "tableCaptions": []}