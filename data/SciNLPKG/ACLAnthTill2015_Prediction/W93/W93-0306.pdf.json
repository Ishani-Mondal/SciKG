{"title": [{"text": "NPtool~ a detector of English noun phrases *", "labels": [], "entities": []}], "abstractContent": [{"text": "NPtool is a fast and accurate system for extracting noun phrases from English texts for the purposes of e.g. information retrieval , translation unit discovery, and corpus studies.", "labels": [], "entities": [{"text": "NPtool", "start_pos": 0, "end_pos": 6, "type": "DATASET", "confidence": 0.8967613577842712}, {"text": "information retrieval", "start_pos": 109, "end_pos": 130, "type": "TASK", "confidence": 0.7698560655117035}, {"text": "translation unit discovery", "start_pos": 133, "end_pos": 159, "type": "TASK", "confidence": 0.8877206246058146}]}, {"text": "After a general introduction, the system architecture is presented in outline.", "labels": [], "entities": []}, {"text": "Then follows an examination of a recently written Constraint Syntax.", "labels": [], "entities": []}, {"text": "Section 6 reports on the performance of the system.", "labels": [], "entities": []}], "introductionContent": [{"text": "This paper outlines NPiool, a noun phrase detector.", "labels": [], "entities": [{"text": "noun phrase detector", "start_pos": 30, "end_pos": 50, "type": "TASK", "confidence": 0.790078858534495}]}, {"text": "At the heart of this modular system is reductionistic word-oriented morphosyntactic analysis that expresses head-modifier dependencies.", "labels": [], "entities": [{"text": "reductionistic word-oriented morphosyntactic analysis", "start_pos": 39, "end_pos": 92, "type": "TASK", "confidence": 0.5929163247346878}]}, {"text": "Previous work on this approach, largely based on Karlsson's original proposal, is documented in.", "labels": [], "entities": []}, {"text": "Let us summarise a few key features of this style of analysis.", "labels": [], "entities": []}, {"text": "\u2022 As most parsing frameworks, also the present style of analysis employs a lexicon and a grammar.", "labels": [], "entities": []}, {"text": "What may distinguish the present approach from most other frameworks is the considerable degree of attention we pay to the morphological and lexical description: morphological analysis is based on an extensive and detailed description that employs inflectional and central derivational categories as well as other morphosyntactic features that can be useful for stating syntactic generalisations.", "labels": [], "entities": [{"text": "stating syntactic generalisations", "start_pos": 362, "end_pos": 395, "type": "TASK", "confidence": 0.7216397523880005}]}, {"text": "In this way \"This paper is based on a longer manuscript with the same title.", "labels": [], "entities": []}, {"text": "The development of ENGCG wLs supported by TEKES, the Finnish Technological Development Center, \u2022nd apart of the work on Finite-state syntax hu been supported by the Academy of Finland.", "labels": [], "entities": [{"text": "TEKES", "start_pos": 42, "end_pos": 47, "type": "METRIC", "confidence": 0.7916289567947388}]}, {"text": "a carefully built and informative lexicon facilitates the construction of accurate, wide-coverage parsing grammars.", "labels": [], "entities": []}, {"text": "\u2022 We use tags to encode morphological distinctions, part of speech, and also syntactic information; for instance: In this type of analysis, each word is provided with tags indicating e.g. part of speech, inflection, derivation, and syntactic function.", "labels": [], "entities": []}, {"text": "\u2022 Morphological and syntactic descriptions are based on hand-coded linguistic rules rather than on corpus-based statistical models.", "labels": [], "entities": [{"text": "Morphological and syntactic descriptions", "start_pos": 2, "end_pos": 42, "type": "TASK", "confidence": 0.7424190044403076}]}, {"text": "They employ structural categories that can be found in descriptive grammars, e.g..", "labels": [], "entities": []}, {"text": "Regarding the at times heated methodological debate on whether statistical or rule-based information is to he preferred in grammatical analysis of running text (cf. e.g.), we do not object to probabilistic methods in principle; nevertheless, it seems to us that rule-based descriptions are preferable bemuse they can provide for more accurate and reliable analyses than current probabilistic systems, e.g. part-of-speech taggers; Voutilainen, forthcoming a].", "labels": [], "entities": [{"text": "part-of-speech taggers", "start_pos": 406, "end_pos": 428, "type": "TASK", "confidence": 0.7284532785415649}]}, {"text": "I ProbaIConsider for instance the question posed in whether lexical probabilities contribute more to morphological or parLor-speech disambiguation than context does.", "labels": [], "entities": [{"text": "I ProbaIConsider", "start_pos": 0, "end_pos": 16, "type": "DATASET", "confidence": 0.805276095867157}]}, {"text": "The ENGCG morphological disambiguator, which is entirely based on context rules, uniquely bilistic or heuristic techniques may still be a useful add-on to linguistic information, if potentially remaining ambiguities must be resolved -though with a higher risk of error.", "labels": [], "entities": [{"text": "ENGCG morphological disambiguator", "start_pos": 4, "end_pos": 37, "type": "TASK", "confidence": 0.6134923497835795}]}, {"text": "\u2022 In the design of our grammar schemes, we have paid considerable attention to the question on the resolvability of grammatical distinctions.", "labels": [], "entities": []}, {"text": "In the design of accurate parsers of running text, this question is very important: if the description abounds with distinctions that can be dependably resolved only with extrasyntactic knowledge ~, then either the ambiguities due to these distinctions remain to burden the structure-based parser (as well as the potential application based on the analysis), or a guess, i.e. a misprediction, has to be hazarded.", "labels": [], "entities": []}, {"text": "This descriptive policy brings with it a certain degree of shallowness; in terms of information content, a tag-based syntactic analysis is somewhere between morphological (e.g. part-of-speech) analysis and a conventional syntactic analysis, e.g. a phrase structure tree or a feature-based analysis.", "labels": [], "entities": []}, {"text": "What we hope to achieve with this compromise in information content is the higher reliability of the proposed analyses.", "labels": [], "entities": [{"text": "reliability", "start_pos": 82, "end_pos": 93, "type": "METRIC", "confidence": 0.9973573088645935}]}, {"text": "A superior accuracy could be considered as an argument for postulating anew, 'intermediary' level of computational syntactic description.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 11, "end_pos": 19, "type": "METRIC", "confidence": 0.9989181756973267}]}, {"text": "For more details, see e.g..", "labels": [], "entities": []}, {"text": "\u2022 Our grammar schemes are also learnable: according to double-blind experiments on manually assigning morphological descriptions, a 100% interjudge agreement is typical [Voutilainen, forthcoming a].", "labels": [], "entities": []}, {"text": "3 \u2022 The ability to parse running text is of a high priority.", "labels": [], "entities": [{"text": "parse running text", "start_pos": 19, "end_pos": 37, "type": "TASK", "confidence": 0.8720188736915588}]}, {"text": "Not only a structurally motivated description is important; in the construction of the parsing grammars and lexica, attention should also be paid to corpus evidence.", "labels": [], "entities": [{"text": "parsing grammars", "start_pos": 87, "end_pos": 103, "type": "TASK", "confidence": 0.8991627991199493}]}, {"text": "Often a grammar rule, as we expr~s it in our parsing grammars, is formed as a generalisation 'inspired' by corpus observations; in this sense the parsing grammar is corpus-based.", "labels": [], "entities": []}, {"text": "However, the description need not be restricted to the corpus observation: the linguist is likely to generalise over past experience, and this is not necessarily harmful -as long as the generalisations can also and correctly identifies more than 97% of all appropriate descriptions, and this is considerably more than the near-90% success rate achieved with lexical probabilities alone.", "labels": [], "entities": []}, {"text": "Moreover, note that in all, the ENGCG disaanbiguator identifies more than 99.5% of all appropriate descriptions; only, some 2-3% of all anMyses remain ambiguous and thus do not become uniquely identified.", "labels": [], "entities": []}, {"text": "For more details, see.", "labels": [], "entities": []}, {"text": "2Witness, for instance, ambiguities due to adverbial attachment or modifier scope.", "labels": [], "entities": []}, {"text": "3The 95% interjudge agreement rate reported in probably indicates that in the case of debatable constructions, explicit descriptive conventions have not been consistently established.", "labels": [], "entities": []}, {"text": "Only a carefully defined grammar scheme makes the evaluation of the accuracy of the parsing system a meaningful enterprise (see also).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 68, "end_pos": 76, "type": "METRIC", "confidence": 0.9962981343269348}]}, {"text": "be validated against representative test corpora.", "labels": [], "entities": []}, {"text": "* At least in a practical application, a parsing grammar should assign the best available analysis to its input rather than leave many of the input utterances unrecognised e.g. as ill-formed.", "labels": [], "entities": [{"text": "parsing grammar", "start_pos": 41, "end_pos": 56, "type": "TASK", "confidence": 0.9303825199604034}]}, {"text": "This does not mean that the concept of well-formedness is irrelevant for the present approach.", "labels": [], "entities": []}, {"text": "Our point is simply: although we may consider some text utterance as deviant in one respect or another, we may still be interested in extracting as much information as possible from it, rather than ignore it altogether.", "labels": [], "entities": []}, {"text": "To achieve this effect, the grammar rules should be used in such a manner 4 that no input becomes entirely rejected, although the rules as such may express categorical restrictions on what is possible or well-formed in the language.", "labels": [], "entities": []}, {"text": "\u2022 In our approach, parsing consists of two main kinds of operation: i.", "labels": [], "entities": [{"text": "parsing", "start_pos": 19, "end_pos": 26, "type": "TASK", "confidence": 0.9774067401885986}]}, {"text": "Context-insensitive lookup of (alternative) descriptions for input words 2.", "labels": [], "entities": []}, {"text": "Elimination of unacceptable or contextually illegitimate alternatives.", "labels": [], "entities": []}, {"text": "Morphological analysis typically corresponds to the lookup module: it produces the desired morphosyntactic analysis of the sentence, along with a number of inappropriate ones, by providing each word in the sentence with all conventional analyses as a list of alternatives.", "labels": [], "entities": [{"text": "Morphological analysis", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.9248684644699097}]}, {"text": "The grammar itself exerts the restrictions on permitted sequences of words and descriptors.", "labels": [], "entities": []}, {"text": "In other words, syntactic analysis proceeds byway of ambiguity resolution or dlsambiguation: the parser eliminates ill-formed readings, and what 'survives' the grammar is the (syntactic) analysis of the input utterance.", "labels": [], "entities": [{"text": "syntactic analysis", "start_pos": 16, "end_pos": 34, "type": "TASK", "confidence": 0.7754632532596588}]}, {"text": "Since the input contains the desired analysis, no new structure will be built dtvdng syntactic analysis itself.", "labels": [], "entities": []}, {"text": "\u2022 Our grammars consist of constraints -partim distributional definitions of morphosyntactic categories, such as parts of speech or syntactic functions.", "labels": [], "entities": []}, {"text": "Each constraint expresses a piecemeal linearprecedence generalisation about the language, and they are independent of each other.", "labels": [], "entities": []}, {"text": "That is, the constraints can be applied in any order: a true grammar will produce the same analysis, whatever the order.", "labels": [], "entities": []}, {"text": "The grammarian is relatively free to select the level of abstraction at which (s)he is willing to express the distributional generalisation.", "labels": [], "entities": []}, {"text": "In particular, also reference to very low-level categories is possible, and this makes for the accuracy of the parser: while the grammar will contain more or less abstract, feature-oriented rules, often it is also expedient to state further, more particular restrictions on more particular distributional classes, even at the word-form level.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 95, "end_pos": 103, "type": "METRIC", "confidence": 0.9993520379066467}]}, {"text": "These 'smaller' rules do not contradict the more general rules; often it is sim4e.g. by ranking the graanmar rules in terms of compromisability ply the case that further restrictions can be imposed on smaller lexical classes s This flexibility in the grammar formalism greatly contributes to the accuracy of the parser [Voutilainen, forthcoming a;.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 296, "end_pos": 304, "type": "METRIC", "confidence": 0.9993762373924255}]}], "datasetContent": [{"text": "The present syntax has been applied to large amounts of journalistic and technical text (newspapers, abstracts on electrical engineering, manuals on car maintenance, etc.), and the analysis of some 20,000-30,000 words has been proofread to get an estimate of the accuracy of the parser.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 263, "end_pos": 271, "type": "METRIC", "confidence": 0.9989351630210876}]}, {"text": "After the application of the NPtool syntax, some 93-96% of all words become syntactically unambiguous, with an error rate of less than i% 14 . To find out how much ambiguity remains at the sentence level, I also applied a 'NP-neutral' version 15 of the finite-state parser on a 25,500 word text from The Grolier Electronic Encyclopaedia.", "labels": [], "entities": [{"text": "error rate", "start_pos": 111, "end_pos": 121, "type": "METRIC", "confidence": 0.9349421858787537}, {"text": "The Grolier Electronic Encyclopaedia", "start_pos": 300, "end_pos": 336, "type": "DATASET", "confidence": 0.7241817638278008}]}, {"text": "The results are given in.", "labels": [], "entities": []}, {"text": "Some 64% (960) of the 1,495 sentences became syntactically unambiguous, while only some 2% of all sentences analyses contain more than ten readings, the worst ambiguity being due to 72 analyses.", "labels": [], "entities": []}, {"text": "This compares favourably with the ENGCG performance: after ENGCG parsing, 23.5% of all sentences remained ambiguous due to a number of sentence readings greater than the worst casein NPtool syntax.", "labels": [], "entities": [{"text": "ENGCG", "start_pos": 34, "end_pos": 39, "type": "DATASET", "confidence": 0.6846924424171448}, {"text": "ENGCG parsing", "start_pos": 59, "end_pos": 72, "type": "TASK", "confidence": 0.7811410129070282}]}], "tableCaptions": []}