{"title": [], "abstractContent": [], "introductionContent": [{"text": "The design of word-sense taxonornies is acknowledged as one of the most difficult (and frustrating) tasks in NLP systems.", "labels": [], "entities": []}, {"text": "The decision to assign a word to a category is far from being straightforward) and often the lexicon builders do not use consistent classification pfincipia.", "labels": [], "entities": []}, {"text": "Automatic approaches to the acquisition of word taxonomies have generally made use of machine readable dictionaries (MRD), for the typical definitory nature of MRD texts.", "labels": [], "entities": [{"text": "acquisition of word taxonomies", "start_pos": 28, "end_pos": 58, "type": "TASK", "confidence": 0.7979696840047836}]}, {"text": "For example, in and other similar studies the category of a word is acquired from the first few words of a dictionary definition.", "labels": [], "entities": []}, {"text": "Besides the well known problems of inconsistency and circularity of definitions, an inherent difficulty with this approach is that verbs can hardly be defined in terms of genus and differentiae.", "labels": [], "entities": []}, {"text": "Verb semantics resides in the nature of the event they describe, that is better expressed by the roles played by its arguments in a sentence.", "labels": [], "entities": [{"text": "Verb semantics", "start_pos": 0, "end_pos": 14, "type": "TASK", "confidence": 0.7491425573825836}]}, {"text": "Psycholinguistie studies on verb semantics outline the relevance of thematic roles, especially in eategorisation activities, and indicate the argument structure of verbs as playing a central role in language acquisition.", "labels": [], "entities": [{"text": "language acquisition", "start_pos": 199, "end_pos": 219, "type": "TASK", "confidence": 0.707602858543396}]}, {"text": "In NLP, representing verb semantics with their thematic roles is a consolidated practice, even though theoretical researches) propose more rich and formal representation frameworks.", "labels": [], "entities": []}, {"text": "More recent papers, proposed to cluster nouns on the basis of a metric derived from the distribution of subject, verb and object in the texts.", "labels": [], "entities": []}, {"text": "Both papers use as a source of information large corpora, but differ in the type of statistical approach used to determine word similarity.", "labels": [], "entities": []}, {"text": "These studies, though valuable, leave several open problems: 1) A metric of conceptual closeness based on mere syntactic similarity is questionable, particularly if applied to verbs.", "labels": [], "entities": []}, {"text": "In fact, the argument structure of verbs is variegated and poorly overlapping.", "labels": [], "entities": []}, {"text": "Furthermore, subject and object relations do not fully characterize many verbs.", "labels": [], "entities": []}, {"text": "2) Many events accumulate statistical evidence only in very large corpora, even though in Pereira and Tishby (1992) the adopted notion of distributional similarity in part avoids this problem.", "labels": [], "entities": []}, {"text": "3) The description of a word is an \"agglomerate\" of its occurrences in the corpus, and it is not possible to discriminate different senses.", "labels": [], "entities": []}, {"text": "4) None of the aforementioned studies provide a method to describe and evaluate the derived categories.", "labels": [], "entities": []}, {"text": "As a result, the acquired classifications seem of little use fora large-scale NLP system, and even fora linguist that is in charge of deriving the taxonomy.", "labels": [], "entities": []}, {"text": "Our research is an attempt to overcome in part the aforementioned limitations.", "labels": [], "entities": []}, {"text": "We present a corpus-driven unsupervised learning algorithm based on a modified version of COBWEB Fisher (1987),.", "labels": [], "entities": [{"text": "COBWEB Fisher (1987)", "start_pos": 90, "end_pos": 110, "type": "DATASET", "confidence": 0.9444936394691468}]}, {"text": "The algorithm learns verb classifications through the systematic observation of verb usages in sentences.", "labels": [], "entities": [{"text": "verb classifications", "start_pos": 21, "end_pos": 41, "type": "TASK", "confidence": 0.7327021360397339}]}, {"text": "The algorithm has been tested on two domains with very different linguistic styles, a commercial and a legal corpus of about 500,000 words each.", "labels": [], "entities": []}, {"text": "In section 2 we highlight the advantages that concept formation algorithms, like COBWEB, have over \"agglomerate\" statistical approaches.", "labels": [], "entities": [{"text": "concept formation", "start_pos": 46, "end_pos": 63, "type": "TASK", "confidence": 0.7609386444091797}]}, {"text": "However, using a Machine Learning methodology fora Natural Language Processing problem required adjustments on both sides.", "labels": [], "entities": []}, {"text": "Raw texts representing instances of verb usages have been processed to fit the feature-vector like representation needed for concept formation algorithms.", "labels": [], "entities": [{"text": "concept formation", "start_pos": 125, "end_pos": 142, "type": "TASK", "confidence": 0.7352063953876495}]}, {"text": "The NL processor used for this task is briefly summarized in section2.", "labels": [], "entities": []}, {"text": "a) Incrementality, since whenever new data are available, the system updates its classification; b) A formal description of the acquired clusters; c) The notion of category utility, used to select among competing classifications.", "labels": [], "entities": []}, {"text": "b) and e) are particularly relevant to our linguistic problem, as remarked in the Introduction.", "labels": [], "entities": []}, {"text": "On the other side, applying COBWEB to verb classification is not straightforward.", "labels": [], "entities": [{"text": "verb classification", "start_pos": 38, "end_pos": 57, "type": "TASK", "confidence": 0.7614640295505524}]}, {"text": "First, there is a knowledge representation problem, that is common to most Machine Learning algorithms: Input instances must be pre-coded (manually) using a feature-I Ciaula stands for Concept formation Algorithm Used for Language Acquisition, and has been inspired by the tale \"Ciaula scopre la luna\" by Luigi Pirandello.", "labels": [], "entities": [{"text": "knowledge representation", "start_pos": 18, "end_pos": 42, "type": "TASK", "confidence": 0.7126548588275909}, {"text": "Concept formation Algorithm Used for Language Acquisition", "start_pos": 185, "end_pos": 242, "type": "TASK", "confidence": 0.7056712465626853}]}, {"text": "This limited the use of such algorithms in many real world problems.", "labels": [], "entities": []}, {"text": "In the specific case we are analyzing, a manual codification of verb instances is not realistic on a large scale.", "labels": [], "entities": []}, {"text": "Second, the algorithm does not distinguish multiple usages of the same verb, nor different verbs that are found with the same pattern of use, since different instances with the same feature vector are taken as identical.", "labels": [], "entities": []}, {"text": "The motivation is that concept formation algorithms as COBWEB assume the input information as being stable, unambiguous, and complete.", "labels": [], "entities": [{"text": "concept formation", "start_pos": 23, "end_pos": 40, "type": "TASK", "confidence": 0.7692759037017822}]}, {"text": "At the opposite, our data do not exhibit a stable behaviour, they are ambiguous, incomplete, and possibly misleading, since errors in codification of verb instances may well be possible.", "labels": [], "entities": []}, {"text": "In the following sections we will discuss the methods by which we attempted to overcome these obstacles.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": []}