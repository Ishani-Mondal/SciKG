{"title": [{"text": "Word Sense Disambiguation by Human Subjects: Computational and Psycholinguistic Applications", "labels": [], "entities": [{"text": "Word Sense Disambiguation by Human Subjects", "start_pos": 0, "end_pos": 43, "type": "TASK", "confidence": 0.7932539880275726}]}], "abstractContent": [{"text": "Although automated word sense disambiguation has become a popular activity within computational lexicology, evaluation of the accuracy of disambiguation systems is still mostly limited to manual checking by the developer.", "labels": [], "entities": [{"text": "word sense disambiguation", "start_pos": 19, "end_pos": 44, "type": "TASK", "confidence": 0.6751290361086527}, {"text": "accuracy", "start_pos": 126, "end_pos": 134, "type": "METRIC", "confidence": 0.9956596493721008}]}, {"text": "This paper describes our work in collecting data on the disambiguation behavior of human subjects, with the intention of providing (I) a norm against which dictionary-based systems (and perhaps others) can be evaluated, and (2) a source of psycholinguistic information about previously unobserved aspects of human disambiguation, for the use of both psycholinguists and computational researchers.", "labels": [], "entities": []}, {"text": "We also describe two of our most important tools: a questionnaire of ambiguous test words in various contexts, and a hypertext user interface for efficient and powerful collection of data from human subjects.", "labels": [], "entities": []}], "introductionContent": [], "datasetContent": [{"text": "Many previous studies of human disambiguation have been from a psycholinguistic point of view.", "labels": [], "entities": [{"text": "human disambiguation", "start_pos": 25, "end_pos": 45, "type": "TASK", "confidence": 0.6892502903938293}]}, {"text": "Simpson and Burgess, surveying some of these studies, identify three basic models of ambiguity processing: (1) restriction by context, (2) ordered access, and (3) multiple access.", "labels": [], "entities": []}, {"text": "Prather and Swinney consider whether the lexical component of human language processing is modular, i.e., acts independently of other components, or whether it interacts with other components.", "labels": [], "entities": []}, {"text": "Computationally oriented evaluations of human disambiguation began as incidental adjuncts to computational projects.", "labels": [], "entities": []}, {"text": "Amsler and White, with the help of assistants, manually (i.e., by human judgment) disambiguated the nouns and verbs used in definitions in the Merriam-Webster Pocket Dictionary.", "labels": [], "entities": [{"text": "Merriam-Webster Pocket Dictionary", "start_pos": 143, "end_pos": 176, "type": "DATASET", "confidence": 0.8928518891334534}]}, {"text": "In an informal study, they found that their disambiguators' self-consistency on repeat performance was high (84%) but their consistency with respect to each other was lower.", "labels": [], "entities": []}, {"text": "The need for some means of evaluating automatic disambiguation methods, more rigorous than the experimenter's personal judgment, has become more obvious with the recent growing interest in the topic., for instance, have followed the approach of estimating upper and lower bounds on the performance of a system.", "labels": [], "entities": []}, {"text": "The project described in this paper began when one of us (Ahlswede) wrote disambiguation programs based on those of and Ide and Veronis for application in dictionary and corpus research.", "labels": [], "entities": [{"text": "dictionary and corpus research", "start_pos": 155, "end_pos": 185, "type": "TASK", "confidence": 0.6702847480773926}]}, {"text": "Lesk claimed 50-70% accuracy on short samples of literary and journalistic input.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 20, "end_pos": 28, "type": "METRIC", "confidence": 0.9994480013847351}]}, {"text": "Ide and Veronis claimed a 90% accuracy rate for their program, although they explained that they had tested it against strongly distinct definitionsmainly homographs rather than senses.", "labels": [], "entities": [{"text": "accuracy rate", "start_pos": 30, "end_pos": 43, "type": "METRIC", "confidence": 0.9914369881153107}]}, {"text": "After running the programs on test data containing ambiguities at both homograph and sense level, and evaluating the results, Ahlswede doubted whether, given this subtler mix of ambiguities, even a single human judge would achieve 90% consistency on successive evaluations of the same output; moreover, the consistency among multiple judges might well be much lower.", "labels": [], "entities": [{"text": "consistency", "start_pos": 235, "end_pos": 246, "type": "METRIC", "confidence": 0.9653884768486023}, {"text": "consistency", "start_pos": 307, "end_pos": 318, "type": "METRIC", "confidence": 0.95534747838974}]}, {"text": "Ahlswede recruited seven colleagues and friends to evaluate the test data, then compared their disambiguations of the test data against each other.", "labels": [], "entities": []}, {"text": "The level of agreement averaged only 66% among the various human informants, ranging from 31% to 88% between pairs of informants.", "labels": [], "entities": [{"text": "agreement", "start_pos": 13, "end_pos": 22, "type": "METRIC", "confidence": 0.8367740511894226}]}, {"text": "This figure was based on a simple pairwise comparison strategy.", "labels": [], "entities": []}, {"text": "The informants rated each sense definition of a test word with a \"1\" indicating that it correctly represented the meaning of the word as used in the test text; \"-1\" if the definition did not correctly represent the meaning; and \"0\" if for any reason the informant could not decide one way or the other.", "labels": [], "entities": []}, {"text": "Pairs of informants were then compared by matching their ratings of the sense definitions of each word.", "labels": [], "entities": []}, {"text": "The pair were considered to agree on a test word if at least one sense received a \"1\" from both informants and if no sense receiving a \"1\" from either informant was given a \"-1\" by the other.", "labels": [], "entities": []}, {"text": "This scoring method had the advantage of simplicity, but it did not reflect the agreement implicit in the rejection as well as the selection of senses by both informants.", "labels": [], "entities": []}, {"text": "But the relative weight of common rejections and common selections among the senses of a given test word depends on the total number of senses, which varies widely.", "labels": [], "entities": []}, {"text": "No discrete-valued scoring mechanism seems able to solve this problem.", "labels": [], "entities": []}, {"text": "A pairwise scoring procedure that gives much more plausible results is the coefficient of correlation, applied to the parallel evaluations by the informants being compared.", "labels": [], "entities": [{"text": "correlation", "start_pos": 90, "end_pos": 101, "type": "METRIC", "confidence": 0.5898312926292419}]}, {"text": "It clearly distinguishes the relatively high agreement expected from human subjects from the relatively low agreement predicted for primitive automatic disambiguation systems, and from the more or less random behavior of a control series of random \"disambiguations.\"", "labels": [], "entities": []}, {"text": "hl through h7 are human informants; h6 took the test twice.", "labels": [], "entities": []}, {"text": "ml and mla are implementations of Lesk's algorithm.", "labels": [], "entities": []}, {"text": "In mla, the test texts were previously disambiguated for part of speech; senses of inappropriate parts of speech were assumed incorrect, and left out of the test data.", "labels": [], "entities": [{"text": "mla", "start_pos": 3, "end_pos": 6, "type": "DATASET", "confidence": 0.9073174595832825}]}, {"text": "3. m2 is a spreading activation algorithm related to the Ide-Veronis algorithm.", "labels": [], "entities": []}, {"text": "4. al is a control in which all senses of all test words received a \"1\".", "labels": [], "entities": []}, {"text": "In our first scoring strategy, al achieved absurdly high scores.", "labels": [], "entities": []}, {"text": "5. rand is a control created by randomly scrambling the sequence of answers in one of the human samples.", "labels": [], "entities": []}, {"text": "These results suggested that a very high accuracy rate is not so much unrealistic as meaningless: which of the human informants should the computer agree with, if the humans cannot agree among themselves?", "labels": [], "entities": [{"text": "accuracy rate", "start_pos": 41, "end_pos": 54, "type": "METRIC", "confidence": 0.9900805652141571}]}, {"text": "For this reason, the informal experiment has led to the development of a larger and more formal test of human disambiguation performance.", "labels": [], "entities": []}, {"text": "The main areas of innovation are (1) a much more systematically designed questionnaire, to be administered to hundreds of subjects rather than only seven, and (2) a user interface to facilitate both the completion of the questionnaire by this large number of human subjects, and our analysis of their performance.", "labels": [], "entities": []}, {"text": "The biggest advantage of a computerized interface is that we can study the timing of subjects' responses: valuable information that could not be recorded in the original written test.", "labels": [], "entities": []}, {"text": "Combined with the user interface, the questionnaire is adapted for administration to human informants, but it can be adapted with little effort for use with dictionarybased disambiguation programs, as was done with its written (but also machine-readable) predecessor.", "labels": [], "entities": []}], "tableCaptions": []}