{"title": [{"text": "Corpus-based Adaptation Mechanisms for Chinese Homophone Disambiguation", "labels": [], "entities": [{"text": "Chinese Homophone Disambiguation", "start_pos": 39, "end_pos": 71, "type": "TASK", "confidence": 0.5481656591097513}]}], "abstractContent": [{"text": "Based on the concepts of bzd~rectwnal converswn and automahc evaluatzon, we propose two user.", "labels": [], "entities": []}, {"text": "adaptation mechanzsms, character-preference learn.", "labels": [], "entities": []}, {"text": "in9 and pseudo-word learning, for resolving Chinese homophone ambiguities in syllable-to.character conversion.", "labels": [], "entities": [{"text": "pseudo-word learning", "start_pos": 8, "end_pos": 28, "type": "TASK", "confidence": 0.7512558698654175}, {"text": "syllable-to.character conversion", "start_pos": 77, "end_pos": 109, "type": "TASK", "confidence": 0.748914897441864}]}, {"text": "The 1991 Umted Daily corpus of approximately 10 million Chinese characters ts used for extraction of 10 reporter-specific article databases and .[or computat,on of word frequencies and character hi-grams.", "labels": [], "entities": [{"text": "1991 Umted Daily corpus", "start_pos": 4, "end_pos": 27, "type": "DATASET", "confidence": 0.7989061996340752}]}, {"text": "Ezpemments show that ~0.5 percent (testing sets) to 71.8 percent (trammg sets) of conversion er. rots can be eliminated through the proposed mechanisms.", "labels": [], "entities": []}, {"text": "These concepts are thus very useful tn ap-phcattons such as Chinese znput methods and speech recognition systems.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 86, "end_pos": 104, "type": "TASK", "confidence": 0.7553986012935638}]}], "introductionContent": [{"text": "Corpus-based Chinese NLP research has been very active in the recent years as more and more computer readable Chinese corpora are available.", "labels": [], "entities": []}, {"text": "Reported corpus-based NLP applications include machine translation, word segmentation, character recognition, text classification, lexicography, and spelling checker.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 47, "end_pos": 66, "type": "TASK", "confidence": 0.8055900037288666}, {"text": "word segmentation", "start_pos": 68, "end_pos": 85, "type": "TASK", "confidence": 0.7908684313297272}, {"text": "character recognition", "start_pos": 87, "end_pos": 108, "type": "TASK", "confidence": 0.9211505949497223}, {"text": "text classification", "start_pos": 110, "end_pos": 129, "type": "TASK", "confidence": 0.7901241481304169}, {"text": "spelling checker", "start_pos": 149, "end_pos": 165, "type": "TASK", "confidence": 0.8579782247543335}]}, {"text": "In this paper, we will describe our work on adaptive Chinese homophone disambiguation (also known as phonetic-input-to-character conversion or phonetic decoding) using part of the 1991 United Daily (UD) corpus of approximately 10 million Chinese characters (Hanzi).", "labels": [], "entities": [{"text": "adaptive Chinese homophone disambiguation", "start_pos": 44, "end_pos": 85, "type": "TASK", "confidence": 0.5974267274141312}, {"text": "phonetic-input-to-character conversion or phonetic decoding)", "start_pos": 101, "end_pos": 161, "type": "TASK", "confidence": 0.6869295537471771}, {"text": "United Daily (UD) corpus of", "start_pos": 185, "end_pos": 212, "type": "DATASET", "confidence": 0.9242668407303947}]}, {"text": "It requires a coding method, structural or phonetic, to input Chinese characters into a computer, since there are more than I0,000 of them in common use.", "labels": [], "entities": []}, {"text": "In the literature, there are several hundred different coding methods for this purpose.", "labels": [], "entities": []}, {"text": "For most users, phonetic coding (Pinyin or Bopomofo) is the choice.", "labels": [], "entities": [{"text": "phonetic coding", "start_pos": 16, "end_pos": 31, "type": "TASK", "confidence": 0.7182592153549194}, {"text": "Bopomofo", "start_pos": 43, "end_pos": 51, "type": "DATASET", "confidence": 0.6961468458175659}]}, {"text": "To input a Chinese character, the user simply keys in its corresponding phonetic code.", "labels": [], "entities": []}, {"text": "It is easy to learn, but suffers from the homophone problem, i.e., a phonetic code corresponding to several different characters.", "labels": [], "entities": []}, {"text": "Therefore, the user needs to choose the desired character from a (usually long) list of candidate characters.", "labels": [], "entities": []}, {"text": "It is inefficient and annoying.", "labels": [], "entities": []}, {"text": "So, automatic homophone disambiguation is highly desirable.", "labels": [], "entities": [{"text": "homophone disambiguation", "start_pos": 14, "end_pos": 38, "type": "TASK", "confidence": 0.6422305405139923}]}, {"text": "Several disambiguation approaches have been reported in the literature.", "labels": [], "entities": []}, {"text": "Some of them have even been realized in commercial input methods, e.g., ttanin, WangXing, Going.", "labels": [], "entities": []}, {"text": "However, the accuracies of these disambiguators are not satisfactory.", "labels": [], "entities": []}, {"text": "In this paper, we propose a corpus-based adaptation method for improving the accuracy of homophone disambiguation.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 77, "end_pos": 85, "type": "METRIC", "confidence": 0.9982662796974182}, {"text": "homophone disambiguation", "start_pos": 89, "end_pos": 113, "type": "TASK", "confidence": 0.7069232165813446}]}, {"text": "For homophone disambiguation, what we need as input is syllable (phonetic code) corpora instead of text corpora.", "labels": [], "entities": [{"text": "homophone disambiguation", "start_pos": 4, "end_pos": 28, "type": "TASK", "confidence": 0.7690806090831757}]}, {"text": "For adaptation, what we need is personal corpora instead of general corpora (such as the UD corpus).", "labels": [], "entities": [{"text": "UD corpus", "start_pos": 89, "end_pos": 98, "type": "DATASET", "confidence": 0.7412127256393433}]}, {"text": "Thus, we first design a selection procedure to extract articles by individual reporters.", "labels": [], "entities": []}, {"text": "Ten personal corpora were setup in this way.", "labels": [], "entities": []}, {"text": "An additional domain-specific corpus, translated AP news, was built up similarly.", "labels": [], "entities": [{"text": "AP news", "start_pos": 49, "end_pos": 56, "type": "DATASET", "confidence": 0.6258576661348343}]}, {"text": "Then, we design a highly-reliable (99.7% correct) character-tosyllable converter to transfer the text corpora into syllable corpora.", "labels": [], "entities": []}, {"text": "Our baseline disambiguator is rather conventional, composed of a word-lattice searching module, a path scorer, and a lexicon-driven word hypothesizer.", "labels": [], "entities": []}, {"text": "Using the original text corpora and the corresponding syllable corpora, we propose a user-adaptation method, applying the concept of bidirectional conversion and automatic evaluation.", "labels": [], "entities": []}, {"text": "The adaptation method includes two parts: character-preference learning and pseudo word learning.", "labels": [], "entities": [{"text": "character-preference learning", "start_pos": 42, "end_pos": 71, "type": "TASK", "confidence": 0.7943865954875946}, {"text": "pseudo word learning", "start_pos": 76, "end_pos": 96, "type": "TASK", "confidence": 0.6067068179448446}]}, {"text": "Given a personal corpus (i.e., sample text), the adaptation pro-cedure is able to produce a user-specific characterpreference model and a pseudo word lexicon automatically.", "labels": [], "entities": []}, {"text": "Then the system can use the user-specific parameters in the two models for improving the conversion accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 100, "end_pos": 108, "type": "METRIC", "confidence": 0.9735620617866516}]}, {"text": "Extensive experiments have been conducted for (1) ten sets of local-news articles (one set per reporter) and (2) translated international news from AP News.", "labels": [], "entities": [{"text": "AP News", "start_pos": 148, "end_pos": 155, "type": "DATASET", "confidence": 0.9480145573616028}]}, {"text": "Each set is divided into two subsets: one for training, the other for testing.", "labels": [], "entities": []}, {"text": "The character accuracy of the b&seline version is 93.46% on average.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 14, "end_pos": 22, "type": "METRIC", "confidence": 0.9899356961250305}]}, {"text": "With the proposed adaptation method, the augmented version increases the accuracy to 98.16~ for the training sets and to 94.80% for the test sets.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 73, "end_pos": 81, "type": "METRIC", "confidence": 0.9995594620704651}]}, {"text": "In other words, 71.8% and 20.5% of the errors have been eliminated, respectively.", "labels": [], "entities": [{"text": "errors", "start_pos": 39, "end_pos": 45, "type": "METRIC", "confidence": 0.9930720925331116}]}, {"text": "The results are encouragiug for us to further pursue corpus-based adaptive learning methods for Chinese phonetic input and language modeling for speech recognition.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 145, "end_pos": 163, "type": "TASK", "confidence": 0.7640716433525085}]}], "datasetContent": [{"text": "Here, we will only briefly review the concepts of bidirectional conversion and automatic evaluation.", "labels": [], "entities": []}, {"text": "For more details, seethe cited papers.", "labels": [], "entities": []}, {"text": "Homophone disambiguation can be considered as a process of syllable-to-character ($2C) conversion, Its reverse process, character-to-syllable (C2S) conversion, is also nontrivial.", "labels": [], "entities": [{"text": "Homophone disambiguation", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.8249012231826782}, {"text": "character-to-syllable (C2S) conversion", "start_pos": 120, "end_pos": 158, "type": "TASK", "confidence": 0.6712574481964111}]}, {"text": "There are more than 1000 characters, so-called Poyinzi (homographs), with multiple pronunciations.", "labels": [], "entities": []}, {"text": "However, a high-accuracy C2S converter is achievable.", "labels": [], "entities": []}, {"text": "Using an n-gram lookahead scheme, we have designed such a converter with 99.71c~ accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 81, "end_pos": 89, "type": "METRIC", "confidence": 0.9968737363815308}]}, {"text": "Because of the high accuracy, the C2S converter can be used to convert a text corpus to a syllable corpus automatically.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 20, "end_pos": 28, "type": "METRIC", "confidence": 0.9990608096122742}]}, {"text": "The two processes together form a bidirectional conversion model.", "labels": [], "entities": []}, {"text": "The i~oint is: If we ignore the 0.29% error (could be reduced ifa better C2S system is used), many applications of the model appear.", "labels": [], "entities": []}, {"text": "We have applied the bidirectional model to automatic evaluation of language models for speech recognition.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 87, "end_pos": 105, "type": "TASK", "confidence": 0.7541047632694244}]}, {"text": "A more straightforward application is automatic evaluation of the $2C converter.", "labels": [], "entities": []}, {"text": "A text is converted into a syllable sequence, which then is converted back to an output text.", "labels": [], "entities": []}, {"text": "Comparing the input text with the output, we can compute the accuracy of the $2C converter automatically.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 61, "end_pos": 69, "type": "METRIC", "confidence": 0.9997005462646484}]}], "tableCaptions": [{"text": " Table 1: The Article Databases", "labels": [], "entities": [{"text": "The Article Databases", "start_pos": 10, "end_pos": 31, "type": "DATASET", "confidence": 0.7187236746152242}]}, {"text": " Table 2: Accuracy Rates for Training Sets", "labels": [], "entities": [{"text": "Accuracy Rates", "start_pos": 10, "end_pos": 24, "type": "METRIC", "confidence": 0.9866158664226532}]}, {"text": " Table 3: Accuracy Rates for Testing Sets", "labels": [], "entities": [{"text": "Accuracy Rates", "start_pos": 10, "end_pos": 24, "type": "METRIC", "confidence": 0.9865062534809113}]}]}