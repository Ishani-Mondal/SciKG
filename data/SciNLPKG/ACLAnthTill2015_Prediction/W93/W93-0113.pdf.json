{"title": [{"text": "Evaluation Techniques for Automatic Semantic Extraction: Comparing Syntactic and Window Based Approaches", "labels": [], "entities": [{"text": "Automatic Semantic Extraction", "start_pos": 26, "end_pos": 55, "type": "TASK", "confidence": 0.6074199875195821}]}], "abstractContent": [{"text": "As large on-line corpora become more prevalent, a number of attempts have been made to automatically extract thesaurus-like relations directly from text using knowledge poor methods.", "labels": [], "entities": []}, {"text": "In the absence of any specific application, comparing the results of these attempts is difficult.", "labels": [], "entities": []}, {"text": "Here we propose an evaluation method using gold standards , i.e., pre-existing hand-compiled resources, as a means of comparing extraction techniques.", "labels": [], "entities": []}, {"text": "Using this evaluation method, we compare two semantic extraction techniques which produce similar word lists, one using syntactic context of words , and the other using windows of heuristically tagged words.", "labels": [], "entities": [{"text": "semantic extraction", "start_pos": 45, "end_pos": 64, "type": "TASK", "confidence": 0.7300698906183243}]}, {"text": "The two techniques are very similar except that in one case selective natural language processing, a partial syntactic analysis, is performed.", "labels": [], "entities": []}, {"text": "On a 4 megabyte corpus, syntactic contexts produce significantly better results against the gold standards for the most characteristk: words in the corpus, while windows produce better results for rare words.", "labels": [], "entities": []}], "introductionContent": [{"text": "As more text becomes available electronically, it is tempting to imagine the development of automatic filters able to screen these tremendous flows of text extracting usefill bits of information.", "labels": [], "entities": [{"text": "text extracting usefill bits of information", "start_pos": 151, "end_pos": 194, "type": "TASK", "confidence": 0.8095511297384897}]}, {"text": "In order to properly filter, it is useful to know when two words are similar in a corpus.", "labels": [], "entities": []}, {"text": "Knowing this would allcviate part of the term variability problem of natural language discussed in . Individuals will choose a variety of words to name the same objector operation, with little overlap between people's choices.", "labels": [], "entities": []}, {"text": "This variability in naming was cited as the principal reason for large numbers of missed citations in a large-scale evaluation of an information retrieval system.", "labels": [], "entities": []}, {"text": "A proper filter must be able to access information in the text using any word of a set of similar words.", "labels": [], "entities": []}, {"text": "A number of knowledge-rich and knowledge-poor methods have been proposed for recognizing when words are similar.", "labels": [], "entities": []}, {"text": "The knowledge-rich approaches require either a conceptual dependency representation, or semantic tagging of the words, while the knowledge-poor approaches require no previously encoded semantic information, and depend on frequency of co-occurrence of word contexts to determine similarity.", "labels": [], "entities": []}, {"text": "Evaluations of results produced by the above systems are often been limited to visual verification by a human subject or left to the human reader.", "labels": [], "entities": []}, {"text": "In this paper, we propose gold standard evaluation techniques, allowing us to objectively evaluate and to compare two knowledge-poor approaches for extracting word similarity relations from large text corpora.", "labels": [], "entities": [{"text": "extracting word similarity relations from large text corpora", "start_pos": 148, "end_pos": 208, "type": "TASK", "confidence": 0.8600396439433098}]}, {"text": "In order to evaluate the relations extracted, we measure the overlap of the results of each technique against existing hand-created repositories of semantic information such as thesauri and dictionaries.", "labels": [], "entities": []}, {"text": "We describe below }low such resources can be used as evaluation tools, and apply them to two knowledge-poor approaches.", "labels": [], "entities": []}, {"text": "One of the tested semantic extraction approaches uses selective natural language processing, in this case the lexical-syntactic relations that can be extracted for each word in a corpus by robust parsers.", "labels": [], "entities": [{"text": "semantic extraction", "start_pos": 18, "end_pos": 37, "type": "TASK", "confidence": 0.7854987382888794}]}, {"text": "The other approach uses a variation on a classic windowing technique around each word such as was used in.", "labels": [], "entities": []}, {"text": "Both techniques are applied to the same 4 megabyte corpus.", "labels": [], "entities": []}, {"text": "We evaluate the results of both techniques using our gold standard evaluations over thesauri and dictionaries and compare the results obtained by the syntactic based method to those obtained by the windowing method.", "labels": [], "entities": []}, {"text": "The syntax-based method provides a better overlap with the manually defined thesaurus classes for the 600 most frequently appearing words in the corpus, while for rare words the windowing method performs slightly better for rare words.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": []}