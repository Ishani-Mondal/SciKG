{"title": [{"text": "The Automatic Acquisition of Frequencies of Verb Subcategorization Frames from Tagged Corpora", "labels": [], "entities": []}], "abstractContent": [{"text": "We describe a mechanism for automatically acquiring verb subcategorization frames and their frequencies in a large corpus.", "labels": [], "entities": []}, {"text": "A tagged corpus is first partially parsed to identify noun phrases and then a finear grammar is used to estimate the appropriate subcategorization frame for each verb token in the corpus.", "labels": [], "entities": []}, {"text": "In an experiment involving the identification of six fixed subcategorization frames, our current system showed more than 80% accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 125, "end_pos": 133, "type": "METRIC", "confidence": 0.9989954829216003}]}, {"text": "In addition, anew statistical approach substantially improves the accuracy of the frequency estimation.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 66, "end_pos": 74, "type": "METRIC", "confidence": 0.999578058719635}]}], "introductionContent": [{"text": "When we construct a grammar, there is always a trade-off between the coverage of the grammar and the ambiguity of the grammar.", "labels": [], "entities": []}, {"text": "If we hope to develop an efficient highcoverage parser for unrestricted texts, we must have some means of dealing with the combinatorial explosion of syntactic ambiguities.", "labels": [], "entities": [{"text": "highcoverage parser", "start_pos": 35, "end_pos": 54, "type": "TASK", "confidence": 0.6750631183385849}]}, {"text": "While a general probabilistic optimization technique such as the Inside-Outside algorithm (,,,) can be used to reduce ambiguity by providing estimates on the applicability of the context-free rules in a grammar (for example), the algorithm does not take advantage of lexical information, including such information as verb subcategorization frame preferences.", "labels": [], "entities": []}, {"text": "Discovering or acquiring lexically-sensitive linguistic structures from large corpora may offer an essential complementary approach.", "labels": [], "entities": []}, {"text": "Verb subcategorization (verb-subcat) frames represent one of the most important elements of grammatical/lexical knowledge for efficient and reliable parsing.", "labels": [], "entities": []}, {"text": "At this stage in the computational-linguistic exploration of corpora, dictionaries are still probably more reliable than automatic acquisition systems as a source of subcategorization (subcat) frames for verbs.", "labels": [], "entities": []}, {"text": "The Oxford Advanced Learners Dictionary (OALD), for example, uses 32 verb patterns to describe a usage of each verb for each meaning of the verb.", "labels": [], "entities": [{"text": "Oxford Advanced Learners Dictionary (OALD)", "start_pos": 4, "end_pos": 46, "type": "DATASET", "confidence": 0.9131054111889431}]}, {"text": "However, dictionaries do not provide quantitative information such as how often each verb is used with each of the possible subcat frames.", "labels": [], "entities": []}, {"text": "Since dictionaries are repositories, primarily, of what is possible, not what is most likely, they tend to contain information about rare usage [.", "labels": [], "entities": []}, {"text": "But without information about the frequencies of the subcat frames we find in dictionaries, we face the prospect of having to treat each frame as equiprobable in parsing.", "labels": [], "entities": []}, {"text": "This can lead to serious inefficiency.", "labels": [], "entities": []}, {"text": "We also know that the frequency of subcat frames can vary by domain; frames that are very rare in one domain can be quite common in another.", "labels": [], "entities": []}, {"text": "If we could automatically determine the frequencies of subcat frames for domains, we would be able to tailor parsing with domain-specific heuristics.", "labels": [], "entities": []}, {"text": "Indeed, it would be desirable to have a subcat dictionary for each possible domain.", "labels": [], "entities": []}, {"text": "This paper describes a mechanism for automatically acquiring subcat frames and their frequencies based on a tagged corpus.", "labels": [], "entities": []}, {"text": "The method utilizes a tagged corpus because (i) we don't have to deal with a lexical ambiguity (ii) tagged corpora in various domains are becoming readily available and (iii) simple and robust tagging techniques using such corpora recently have been developed (,).", "labels": [], "entities": []}, {"text": "Brent reports a method for automatically acquiring subcat frames but without frequency measurements (,).", "labels": [], "entities": []}, {"text": "His approach is to count occurrences of those unambiguous verb phrases that contain no noun phrases other than pronouns or proper nouns.", "labels": [], "entities": []}, {"text": "By thus restricting the \"features\" that trigger identification of a verb phrase, he avoids possible errors due to syntactic ambiguity.", "labels": [], "entities": []}, {"text": "Although the rate of false positives is very low in his system, his syntactic features are so selective that most verb tokens fail to satisfy them.", "labels": [], "entities": []}, {"text": "(For example, verbs that occurred fewer than 20 times in the corpus tend to have no co-occurrences with the features.)", "labels": [], "entities": []}, {"text": "Therefore his approach is not useful in determining verb-subcat frame frequencies.", "labels": [], "entities": []}, {"text": "To measure frequencies, we need, ideally, to identify a subcat frame for each verb token in the corpus.", "labels": [], "entities": []}, {"text": "This, in turn, requires a full parse of the corpus.", "labels": [], "entities": []}, {"text": "Since manually parsed corpora are rare and typically small, and since automatically parsed corpora contain many errors (given current parsing technologies), an alternative source of useful linguistic structure is needed.", "labels": [], "entities": []}, {"text": "We have elected to use partially parsed sentences automatically derived from a lexically-tagged corpus.", "labels": [], "entities": []}, {"text": "The partial parse contains information about minimal noun phrases (without PP attachment or clausal complements).", "labels": [], "entities": []}, {"text": "While such derived information about linguistic structure is less accurate and complete than that available in certified, hand-parsed corpora, the approach promises to generalize and to yield large sample sizes.", "labels": [], "entities": []}, {"text": "In particular, we can use partially parsed corpora to measure verb-subcat frame frequencies.", "labels": [], "entities": []}], "datasetContent": [{"text": "We used the above method in experiments involving a tagged corpus of Wall Street Journal (WSJ) articles, provided by the Penn Treebank project.", "labels": [], "entities": [{"text": "Wall Street Journal (WSJ) articles", "start_pos": 69, "end_pos": 103, "type": "DATASET", "confidence": 0.9189571993691581}, {"text": "Penn Treebank project", "start_pos": 121, "end_pos": 142, "type": "DATASET", "confidence": 0.9854923884073893}]}, {"text": "Our experiment was limited in two senses.", "labels": [], "entities": []}, {"text": "First, we treated all prepositional phrases as adjuncts.", "labels": [], "entities": []}, {"text": "(It is generally difficult to distinguish complement and adjunct PPs.)", "labels": [], "entities": []}, {"text": "Second, we measured the frequencies of only six fixed subcat frames for verbs in non-participle form.", "labels": [], "entities": []}, {"text": "(This does not represent an essential shortcoming in the method; we only need to have additional subcat frame extraction rules to accommodate participles.)", "labels": [], "entities": []}, {"text": "We extracted two sets of tagged sentences from the WSJ corpus, each representing 3-MBytes and approximately 300,000 words of text.", "labels": [], "entities": [{"text": "WSJ corpus", "start_pos": 51, "end_pos": 61, "type": "DATASET", "confidence": 0.9711855351924896}]}, {"text": "One set was used as a training corpus, the other as a test corpus.", "labels": [], "entities": []}, {"text": "gives the list of verb-subcat frame extraction rules obtained (via examination) for four verbs \"expect\", \"reflect\", \"tell\", and \"give\", as they occurred in the training corpus.", "labels": [], "entities": [{"text": "verb-subcat frame extraction", "start_pos": 18, "end_pos": 46, "type": "TASK", "confidence": 0.6555566787719727}]}, {"text": "Sample sentences that can be captured by each set of rules are attached to the list.", "labels": [], "entities": []}, {"text": "shows the result of the hand comparison of the automat!cally identified verb-subcat frames for \"give\" and \"expect\" in the test corpus.", "labels": [], "entities": []}, {"text": "The tabular columns give actual frequencies for each verb-subcat frame based on manual review and the tabular rowsgive the frequencies as determined automatically by the system.", "labels": [], "entities": []}, {"text": "The count of each cell () gives the number of occurrences of the verb that are assigned the i-th subcat frame by the system and assigned the j-th frame by manual review.", "labels": [], "entities": []}, {"text": "The frame/column labeled \"REST\" represents all other subcat frames, encompassing such subcat frames as those involving wh-clauses, verb-particle combinations (such as \"give up\"), and no complements.", "labels": [], "entities": [{"text": "REST", "start_pos": 26, "end_pos": 30, "type": "METRIC", "confidence": 0.9608412384986877}]}, {"text": "Despite the simplicity of the rules, the frequencies for subcat frames determined under automatic processing are very close to the real distributions.", "labels": [], "entities": []}, {"text": "Most of the errors are attributable to errors in the noun phrase parser.", "labels": [], "entities": [{"text": "noun phrase parser", "start_pos": 53, "end_pos": 71, "type": "TASK", "confidence": 0.6461488207181295}]}, {"text": "For example, 10 out of the 13 errors in the [NP,NP+NP] cell under \"give\" are due to noun phrase parsing errors such as the misidentification of a N-N sequence (e.g., *\"give [NP government officials rights] against the press\" vs. \"give [NP government officials] [NP rights] against the press\").", "labels": [], "entities": [{"text": "noun phrase parsing", "start_pos": 84, "end_pos": 103, "type": "TASK", "confidence": 0.6258017818133036}]}], "tableCaptions": [{"text": " Table 3: Subcategorization Frame Frequencies", "labels": [], "entities": []}, {"text": " Table 5: Statistical Estimation (Unit = %) for the Verb \"Need\"", "labels": [], "entities": [{"text": "Statistical Estimation", "start_pos": 10, "end_pos": 32, "type": "METRIC", "confidence": 0.7674666345119476}, {"text": "Unit", "start_pos": 34, "end_pos": 38, "type": "METRIC", "confidence": 0.899523138999939}]}]}