{"title": [], "abstractContent": [{"text": "Translated texts are distinctively different from original ones, to the extent that supervised text classification methods can distinguish between them with high accuracy.", "labels": [], "entities": [{"text": "text classification", "start_pos": 95, "end_pos": 114, "type": "TASK", "confidence": 0.8048351109027863}, {"text": "accuracy", "start_pos": 162, "end_pos": 170, "type": "METRIC", "confidence": 0.9879392385482788}]}, {"text": "These differences were proven useful for statistical machine translation.", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 41, "end_pos": 72, "type": "TASK", "confidence": 0.7503153284390768}]}, {"text": "However, it has been suggested that the accuracy of translation detection deteriorates when the classifier is evaluated outside the domain it was trained on.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 40, "end_pos": 48, "type": "METRIC", "confidence": 0.998646080493927}, {"text": "translation detection", "start_pos": 52, "end_pos": 73, "type": "TASK", "confidence": 0.9785790741443634}]}, {"text": "We show that this is indeed the case, in a variety of evaluation scenarios.", "labels": [], "entities": []}, {"text": "We then show that unsupervised classification is highly accurate on this task.", "labels": [], "entities": [{"text": "unsupervised classification", "start_pos": 18, "end_pos": 45, "type": "TASK", "confidence": 0.5209095478057861}]}, {"text": "We suggest a method for determining the correct labels of the clustering outcomes, and then use the labels for voting, improving the accuracy even further.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 133, "end_pos": 141, "type": "METRIC", "confidence": 0.999336302280426}]}, {"text": "Moreover , we suggest a simple method for clustering in the challenging case of mixed-domain datasets, in spite of the dominance of domain-related features over translation-related ones.", "labels": [], "entities": []}, {"text": "The result is an effective, fully-unsupervised method for distinguishing between original and translated texts that can be applied to new domains with reasonable accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 162, "end_pos": 170, "type": "METRIC", "confidence": 0.9851008057594299}]}], "introductionContent": [{"text": "Human-translated texts (in any language) have distinct features that distinguish them from original, non-translated texts.", "labels": [], "entities": []}, {"text": "These differences stem either from the effect of the translation process on the translated outcomes, or from \"fingerprints\" of the source language on the target language product.", "labels": [], "entities": []}, {"text": "The term translationese was coined to indicate the unique properties of translations.", "labels": [], "entities": []}, {"text": "Awareness to translationese can improve statistical machine translation (SMT).", "labels": [], "entities": [{"text": "translationese", "start_pos": 13, "end_pos": 27, "type": "TASK", "confidence": 0.9677736759185791}, {"text": "statistical machine translation (SMT)", "start_pos": 40, "end_pos": 77, "type": "TASK", "confidence": 0.7915624976158142}]}, {"text": "First, for training translation models, parallel texts that were translated in the direction of the SMT task are preferable to texts translated in the opposite direction; second, for training language models, monolingual corpora of translated texts are better than original texts.", "labels": [], "entities": [{"text": "SMT task", "start_pos": 100, "end_pos": 108, "type": "TASK", "confidence": 0.9323039650917053}]}, {"text": "It is possible to automatically distinguish between original (O) and translated (T) texts, with very high accuracy, by employing text classification methods.", "labels": [], "entities": [{"text": "distinguish between original (O) and translated (T) texts", "start_pos": 32, "end_pos": 89, "type": "TASK", "confidence": 0.650188980003198}, {"text": "accuracy", "start_pos": 106, "end_pos": 114, "type": "METRIC", "confidence": 0.9973515272140503}, {"text": "text classification", "start_pos": 129, "end_pos": 148, "type": "TASK", "confidence": 0.7053163647651672}]}, {"text": "Existing approaches, however, only employ supervised machine-learning; they therefore suffer from two main drawbacks: (i) they inherently depend on data annotated with the translation direction, and (ii) they may not be generalized to unseen (related or unrelated) domains.", "labels": [], "entities": []}, {"text": "These shortcomings undermine the usability of supervised methods for translationese identification in atypical real-life scenario, where no labelled in-domain data are available.", "labels": [], "entities": [{"text": "translationese identification", "start_pos": 69, "end_pos": 98, "type": "TASK", "confidence": 0.9804372787475586}]}, {"text": "In this work we explore unsupervised techniques for reliable discrimination of original and translated texts.", "labels": [], "entities": [{"text": "reliable discrimination of original and translated texts", "start_pos": 52, "end_pos": 108, "type": "TASK", "confidence": 0.7150667267186301}]}, {"text": "More precisely, we apply dimension reduction and centroid-based clustering methods (enhanced by internal clustering evaluation), for telling O from T in an unsupervised scenario.", "labels": [], "entities": []}, {"text": "Furthermore, we introduce a robust methodology for labelling the obtained clusters, i.e., annotating them as \"original\" or \"translated\", by inspecting similarities between the clustering outcomes and O and T prototypical examples.", "labels": [], "entities": []}, {"text": "Rigorous experiments with four diverse corpora demonstrate that clustering of in-domain texts using lexical, content-independent features systematically yields very high accuracy, only 10 percent points lower than the performance of supervised classification on the same data (in most cases).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 170, "end_pos": 178, "type": "METRIC", "confidence": 0.9983851909637451}]}, {"text": "Ac-curacy can be improved even further by clustering consensus techniques.", "labels": [], "entities": [{"text": "Ac-curacy", "start_pos": 0, "end_pos": 9, "type": "METRIC", "confidence": 0.705375075340271}]}, {"text": "We further scrutinize the tension between domain-related and translationese-based text properties.", "labels": [], "entities": []}, {"text": "Using a series of experiments in a mixeddomain setup, we show that clustering (in particular, relying on content-independent features) perfectly groups the data into domains, rather than into the (desirable) cross-domain O and T; that is, domainrelated properties clearly dominate and overshadow the translationese-based characteristics of the underlying texts.", "labels": [], "entities": []}, {"text": "We address the challenge of discriminating O from T in a mixed-domain setup by proposing two simple methodologies (flat and two-phase) and empirically demonstrate their soundness.", "labels": [], "entities": []}, {"text": "The clustering experiments throughout the paper were conducted in a setup similar to that of supervised classification, determining the status (O vs. T) of logical units (chunks) of 2,000 tokens.", "labels": [], "entities": []}, {"text": "We also show that clustering accuracy remains stable even when the number of available chunks decreases dramatically and remains satisfactory when the chunk size is reduced.", "labels": [], "entities": [{"text": "clustering", "start_pos": 18, "end_pos": 28, "type": "TASK", "confidence": 0.9402474164962769}, {"text": "accuracy", "start_pos": 29, "end_pos": 37, "type": "METRIC", "confidence": 0.9660822153091431}]}, {"text": "The main contribution of this work is therefore two-fold: (i) we establish a robust approach for reliable unsupervised identification of translated texts, thereby eliminating the need for in-domain labeled data; (ii) we provide an extensive empirical foundation for the dominance of domain-based properties over translationese-related characteristics of a text, and propose a methodology for identification of translationese in a mixed-domain scenario.", "labels": [], "entities": [{"text": "identification of translationese", "start_pos": 392, "end_pos": 424, "type": "TASK", "confidence": 0.8068882425626119}]}, {"text": "The remainder of the paper is structured as following: after reviewing related work in Section 2, we detail our datasets, features and tools in Section 3.", "labels": [], "entities": []}, {"text": "In Section 4 we reproduce and extend supervised classification results, and demonstrate the poor cross-domain classification accuracy of supervised methods.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 125, "end_pos": 133, "type": "METRIC", "confidence": 0.9397622346878052}]}, {"text": "Our clustering methodology and experiments are described in Section 5; mixed-domain classification is discussed in Section 6.", "labels": [], "entities": [{"text": "mixed-domain classification", "start_pos": 71, "end_pos": 98, "type": "TASK", "confidence": 0.6935245543718338}]}, {"text": "We conclude with a discussion and suggestions for future research.", "labels": [], "entities": []}], "datasetContent": [{"text": "Our main dataset 2 consists of texts originally written in English and texts translated to English from French.", "labels": [], "entities": []}, {"text": "We use various corpora: (i) Europarl, the proceedings of the European Parliament, between the years 2001-2006; (ii) the Canadian Hansard, transcripts of the Canadian Parliament, spanning years 2001-2009; (iii) literary classics written (or translated) mainly in the 19th century; and (iv) transcripts of TED and TEDx talks.", "labels": [], "entities": [{"text": "Europarl", "start_pos": 28, "end_pos": 36, "type": "DATASET", "confidence": 0.929847776889801}, {"text": "Canadian Hansard", "start_pos": 120, "end_pos": 136, "type": "DATASET", "confidence": 0.884247362613678}]}, {"text": "This collection suggests diversity in genre, register, modality (written vs. spoken) and era.", "labels": [], "entities": []}, {"text": "details some statistical data on the corpora (after tokenization).", "labels": [], "entities": [{"text": "tokenization", "start_pos": 52, "end_pos": 64, "type": "TASK", "confidence": 0.9722919464111328}]}, {"text": "We now briefly describe each dataset.", "labels": [], "entities": []}, {"text": "Europarl is probably the most popular parallel corpus in natural language processing, and it was indeed used for many of the translationese tasks surveyed in Section 2.", "labels": [], "entities": [{"text": "Europarl", "start_pos": 0, "end_pos": 8, "type": "DATASET", "confidence": 0.967613697052002}, {"text": "natural language processing", "start_pos": 57, "end_pos": 84, "type": "TASK", "confidence": 0.6359454194704691}]}, {"text": "This corpus has been used extensively in SMT (, and was even adapted specifically for research in translation studies: compiled a customized version of Europarl, where the direction of translation is indicated.", "labels": [], "entities": [{"text": "SMT", "start_pos": 41, "end_pos": 44, "type": "TASK", "confidence": 0.992468535900116}, {"text": "Europarl", "start_pos": 152, "end_pos": 160, "type": "DATASET", "confidence": 0.9803686738014221}]}, {"text": "We use aversion of Europarl (Rabinovich and Wintner, Forthcoming) that aims to further increase the confidence in the direction of translation, through a comprehensive cross-lingual validation of the original language of the speakers.", "labels": [], "entities": [{"text": "Europarl", "start_pos": 19, "end_pos": 27, "type": "DATASET", "confidence": 0.9804532527923584}, {"text": "translation", "start_pos": 131, "end_pos": 142, "type": "TASK", "confidence": 0.9720069766044617}]}, {"text": "The Hansard is a parallel corpus consisting of transcriptions of the Canadian parliament in.", "labels": [], "entities": [{"text": "Hansard", "start_pos": 4, "end_pos": 11, "type": "DATASET", "confidence": 0.8841557502746582}]}, {"text": "This is the largest available source of English-French sentence pairs.", "labels": [], "entities": []}, {"text": "We use aversion that is annotated with the original language of each parallel sentence.", "labels": [], "entities": []}, {"text": "Relying on metadata available in the corpus, we filtered out all segments not referring to speech, i.e., retaining only sentences annotated as Content ParaText.", "labels": [], "entities": []}, {"text": "The Literature corpus consists of literary classics written (and translated) in the 18th-20th centuries by English and French authors; the raw material is available from the Gutenberg project.", "labels": [], "entities": [{"text": "Literature corpus", "start_pos": 4, "end_pos": 21, "type": "DATASET", "confidence": 0.9250529408454895}]}, {"text": "We use subsets that were manually or automatically paragraphaligned.", "labels": [], "entities": []}, {"text": "Note that classifying literary texts is considered a more challenging task than classifying more \"technical\" translations, such as parliament proceedings, since translators of literature typically enjoy more literary freedom, thereby rendering the translation product more similar to original writing (Lynch and Vogel, 2012; Avner et al., Forthcoming).", "labels": [], "entities": [{"text": "Forthcoming", "start_pos": 339, "end_pos": 350, "type": "DATASET", "confidence": 0.9017893671989441}]}], "tableCaptions": [{"text": " Table 2: In-domain (cross-validation) classification accu- racy using various feature sets", "labels": [], "entities": []}, {"text": " Table 3: Pairwise cross-domain classification using func- tion words", "labels": [], "entities": [{"text": "Pairwise cross-domain classification", "start_pos": 10, "end_pos": 46, "type": "TASK", "confidence": 0.6957431534926096}]}, {"text": " Table 5. The reported numbers reflect the average  accuracy over 30 experiments (the only difference  being a random choice of the initial conditions). 6", "labels": [], "entities": [{"text": "accuracy", "start_pos": 52, "end_pos": 60, "type": "METRIC", "confidence": 0.9990160465240479}]}, {"text": " Table 5: Clustering results using various feature sets", "labels": [], "entities": []}, {"text": " Table 6: Clustering consensus by voting; statistically sig- nificant improvements, compared to using FW only, are  marked with '*'", "labels": [], "entities": [{"text": "FW", "start_pos": 102, "end_pos": 104, "type": "DATASET", "confidence": 0.7409345507621765}]}, {"text": " Table 7: Clustering a chunk-level mix of Europarl, Hansard and Literature using function words; accuracy by transla- tion status (O vs. T) is reported where applicable (i.e., the outcome constitutes two clusters)", "labels": [], "entities": [{"text": "Europarl", "start_pos": 42, "end_pos": 50, "type": "DATASET", "confidence": 0.9857211112976074}, {"text": "Hansard and Literature", "start_pos": 52, "end_pos": 74, "type": "DATASET", "confidence": 0.7798630396525065}, {"text": "accuracy", "start_pos": 97, "end_pos": 105, "type": "METRIC", "confidence": 0.9993062019348145}, {"text": "transla- tion status (O vs. T)", "start_pos": 109, "end_pos": 139, "type": "METRIC", "confidence": 0.6676087578137716}]}, {"text": " Table 8: Flat and two-phase clustering of domain-mix using function words", "labels": [], "entities": []}]}