{"title": [{"text": "One Vector is Not Enough: Entity-Augmented Distributed Semantics for Discourse Relations", "labels": [], "entities": []}], "abstractContent": [{"text": "Discourse relations bind smaller linguistic units into coherent texts.", "labels": [], "entities": []}, {"text": "Automatically identifying discourse relations is difficult, because it requires understanding the semantics of the linked arguments.", "labels": [], "entities": []}, {"text": "A more subtle challenge is that it is not enough to represent the meaning of each argument of a discourse relation, because the relation may depend on links between lower-level components, such as entity mentions.", "labels": [], "entities": []}, {"text": "Our solution computes distributed meaning representations for each discourse argument by composition up the syntactic parse tree.", "labels": [], "entities": []}, {"text": "We also perform a downward compositional pass to capture the meaning of coreferent entity mentions.", "labels": [], "entities": []}, {"text": "Implicit discourse relations are then predicted from these two representations, obtaining substantial improvements on the Penn Discourse Treebank.", "labels": [], "entities": [{"text": "Penn Discourse Treebank", "start_pos": 122, "end_pos": 145, "type": "DATASET", "confidence": 0.9857925971349081}]}], "introductionContent": [{"text": "The high-level organization of text can be characterized in terms of discourse relations between adjacent spans of text).", "labels": [], "entities": []}, {"text": "Identifying these relations has been shown to be relevant to tasks such as summarization (), sentiment analysis (, coherence evaluation ( ), and question answering).", "labels": [], "entities": [{"text": "summarization", "start_pos": 75, "end_pos": 88, "type": "TASK", "confidence": 0.9900771379470825}, {"text": "sentiment analysis", "start_pos": 93, "end_pos": 111, "type": "TASK", "confidence": 0.9735565185546875}, {"text": "question answering", "start_pos": 145, "end_pos": 163, "type": "TASK", "confidence": 0.878135472536087}]}, {"text": "While the Penn Discourse Treebank (PDTB) now provides a large dataset annotated for discourse relations (, the automatic identification of implicit relations is a difficult task, with state-of-the-art performance at roughly 40% (.", "labels": [], "entities": [{"text": "Penn Discourse Treebank (PDTB)", "start_pos": 10, "end_pos": 40, "type": "DATASET", "confidence": 0.9497202038764954}]}, {"text": "One reason for this poor performance is that discourse relations are rooted in semantics (Forbes-), which can be difficult to recover from surface level features.", "labels": [], "entities": []}, {"text": "Consider the implicit discourse relation between the following two sentences (also shown in): (1) Bob gave Tina the burger.", "labels": [], "entities": []}, {"text": "While a connector like because seems appropriate here, there is little surface information to signal this relationship, unless the model has managed to learn a bilexical relationship between burger and hungry.", "labels": [], "entities": []}, {"text": "Learning all such relationships from annotated data -including the relationship of hungry to knish, pierogie, pupusa etc -would require far more data than can possibly be annotated.", "labels": [], "entities": []}, {"text": "We address this issue by applying a discriminatively-trained model of compositional distributed semantics to discourse relation classification).", "labels": [], "entities": [{"text": "discourse relation classification", "start_pos": 109, "end_pos": 142, "type": "TASK", "confidence": 0.6456243495146433}]}, {"text": "The meaning of each discourse argument is represented as a vector, which is computed through a series of bottom-up compositional operations over the syntactic parse tree.", "labels": [], "entities": []}, {"text": "The discourse relation can then be predicted as a bilinear combination of these vector representations.", "labels": [], "entities": []}, {"text": "Both the prediction matrix and the compositional operator are trained in a supervised large-margin framework, ensuring that the learned compositional operation produces semantic representations that are useful for discourse.", "labels": [], "entities": []}, {"text": "We show that when combined with a small number of surface features, this approach outperforms prior work on the classification of implicit discourse relations in the PDTB.", "labels": [], "entities": [{"text": "PDTB", "start_pos": 166, "end_pos": 170, "type": "DATASET", "confidence": 0.8817890882492065}]}, {"text": "Despite these positive results, we argue that bottom-up vector-based representations of discourse arguments are insufficient to capture their relations.", "labels": [], "entities": []}, {"text": "To see why, consider what happens if we make a tiny change to example (1): (2) Bob gave Tina the burger.", "labels": [], "entities": []}, {"text": "After changing the subject of the second sentence to Bob, the connective \"because\" no longer seems appropriate; a contrastive connector like although is preferred.", "labels": [], "entities": []}, {"text": "But despite the radical difference in meaning, the bottom-up distributed representation of the second sentence will be almost unchanged: the syntactic structure remains identical, and the words he and she have very similar word representations (see.", "labels": [], "entities": []}, {"text": "If we reduce each discourse argument span to a single vector, built from the elements in the argument itself, we cannot possibly capture the ways that discourse relations are signaled by entities and their roles ().", "labels": [], "entities": []}, {"text": "As Mooney (2014) puts it, \"you can't cram the meaning of a whole %&!$# sentence into a single $&!#* vector!\"", "labels": [], "entities": []}, {"text": "We address this issue by computing vector representations not only for each discourse argument, but also for each coreferent entity mention.", "labels": [], "entities": []}, {"text": "These representations are meant to capture the role played by the entity in the text, and so they must take the entire span of text into account.", "labels": [], "entities": []}, {"text": "We compute entity-role representations using a feed-forward compositional model, which combines \"upward\" and \"downward\" passes through the syntactic structure, shown in.", "labels": [], "entities": []}, {"text": "In the example, the downward representations for Tina and she are computed from a combination of the parent and sibling nodes in the binarized parse tree.", "labels": [], "entities": []}, {"text": "Representations for these coreferent mentions are then combined in a bilinear product, and help to predict the implicit discourse relation.", "labels": [], "entities": []}, {"text": "In example (2), we resolve he to Bob, and combine their vector representations instead, yielding a different prediction about the discourse relation.", "labels": [], "entities": []}, {"text": "Our overall approach combines surface features, distributed representations of discourse arguments, and distributed representations of entity mentions.", "labels": [], "entities": []}, {"text": "It achieves a 4% improvement inaccuracy over the best previous work () on multiclass discourse relation classification, and also outperforms more recent work on binary classification.", "labels": [], "entities": [{"text": "multiclass discourse relation classification", "start_pos": 74, "end_pos": 118, "type": "TASK", "confidence": 0.6928731352090836}, {"text": "binary classification", "start_pos": 161, "end_pos": 182, "type": "TASK", "confidence": 0.7252858132123947}]}, {"text": "The novel entity-augmented distributed representation improves accuracy over the \"upward\" compositional model, showing the importance of representing the meaning of coreferent entity mentions.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 63, "end_pos": 71, "type": "METRIC", "confidence": 0.9985005855560303}]}], "datasetContent": [{"text": "We evaluate our approach on the Penn Discourse Treebank (PDTB;, which provides a discourse level annotation over the Wall Street Journal corpus.", "labels": [], "entities": [{"text": "Penn Discourse Treebank (PDTB", "start_pos": 32, "end_pos": 61, "type": "DATASET", "confidence": 0.9312127351760864}, {"text": "Wall Street Journal corpus", "start_pos": 117, "end_pos": 143, "type": "DATASET", "confidence": 0.9688013345003128}]}, {"text": "In the PDTB, each discourse relation is annotated between two argument spans.", "labels": [], "entities": []}, {"text": "Identifying the argument spans of discourse relations is a challenging task (), which we do not attempt here; instead, we use gold argument spans, as inmost of the relevant prior work.", "labels": [], "entities": [{"text": "Identifying the argument spans of discourse relations", "start_pos": 0, "end_pos": 53, "type": "TASK", "confidence": 0.7891648156302316}]}, {"text": "PDTB relations maybe explicit, meaning that they are signaled by discourse connectives (e.g., because); alternatively, they maybe implicit, meaning that the connective is absent.", "labels": [], "entities": []}, {"text": "show that most explicit connectives are unambiguous, so we focus on the problem of classifying implicit discourse relations.", "labels": [], "entities": []}, {"text": "The PDTB provides a three-level hierarchy of discourse relations.", "labels": [], "entities": []}, {"text": "The first level consists of four major relation classes: TEMPORAL, CON-TINGENCY, COMPARISON and EXPANSION.", "labels": [], "entities": [{"text": "TEMPORAL", "start_pos": 57, "end_pos": 65, "type": "METRIC", "confidence": 0.9817833304405212}]}, {"text": "For each class, a second level of types is defined to provide finer semantic or pragmatic distinctions; there are sixteen such relation types.", "labels": [], "entities": []}, {"text": "A third level of subtypes is defined for only some types, specifying the semantic contribution of each argument.", "labels": [], "entities": []}, {"text": "There are two main approaches to evaluating implicit discourse relation classification.", "labels": [], "entities": [{"text": "implicit discourse relation classification", "start_pos": 44, "end_pos": 86, "type": "TASK", "confidence": 0.6273624897003174}]}, {"text": "Multiclass classification requires identifying the discourse relation from all possible choices.", "labels": [], "entities": [{"text": "Multiclass classification", "start_pos": 0, "end_pos": 25, "type": "TASK", "confidence": 0.8415444791316986}]}, {"text": "This task was explored by, who focus on second-level discourse relations.", "labels": [], "entities": []}, {"text": "More recent work has emphasized binary classification, where the goal is to build and evaluate separate \"one-versus-all\" classifiers for each discourse relation (.", "labels": [], "entities": [{"text": "binary classification", "start_pos": 32, "end_pos": 53, "type": "TASK", "confidence": 0.7418983578681946}]}, {"text": "We primarily focus on multiclass classification, because it is more relevant for the ultimate goal of building a PDTB parser; however, to compare with recent prior work, we also evaluate on binary relation classification.", "labels": [], "entities": [{"text": "multiclass classification", "start_pos": 22, "end_pos": 47, "type": "TASK", "confidence": 0.7959345281124115}, {"text": "binary relation classification", "start_pos": 190, "end_pos": 220, "type": "TASK", "confidence": 0.7056070367495219}]}], "tableCaptions": [{"text": " Table 2: Proportion of relations with coreferent  entities, according to automatic coreference reso- lution and gold coreference annotation.", "labels": [], "entities": []}, {"text": " Table 3: Experimental results on multiclass classification of level-2 discourse relations. The results of  Lin et al. (2009) are shown in line 3. We reimplemented this system and added the Brown cluster features  of Rutherford and Xue (2014), with results shown in line 4.", "labels": [], "entities": [{"text": "multiclass classification of level-2 discourse relations", "start_pos": 34, "end_pos": 90, "type": "TASK", "confidence": 0.798394779364268}]}, {"text": " Table 3.  As before, all parameters are tuned on a devel- opment set. In this evaluation, we obtain larger  improvements from our approach: our full model  (with entity semantics) gives 47.27% accuracy, as  compared to 44.96% without entity semantics; the  result for the surface feature baseline is 41.48%.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 194, "end_pos": 202, "type": "METRIC", "confidence": 0.9995038509368896}]}, {"text": " Table 4: Evaluation on the first-level discourse relation identification. The results of the competitive  systems are reprinted.", "labels": [], "entities": [{"text": "discourse relation identification", "start_pos": 40, "end_pos": 73, "type": "TASK", "confidence": 0.6294879416624705}]}]}