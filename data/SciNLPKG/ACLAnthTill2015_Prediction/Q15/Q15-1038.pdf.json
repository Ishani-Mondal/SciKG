{"title": [{"text": "Large-Scale Information Extraction from Textual Definitions through Deep Syntactic and Semantic Analysis", "labels": [], "entities": [{"text": "Large-Scale Information Extraction from Textual Definitions", "start_pos": 0, "end_pos": 59, "type": "TASK", "confidence": 0.7402311364809672}, {"text": "Semantic Analysis", "start_pos": 87, "end_pos": 104, "type": "TASK", "confidence": 0.7159843742847443}]}], "abstractContent": [{"text": "We present DEFIE, an approach to large-scale Information Extraction (IE) based on a syntactic-semantic analysis of textual definitions.", "labels": [], "entities": [{"text": "Information Extraction (IE)", "start_pos": 45, "end_pos": 72, "type": "TASK", "confidence": 0.8495552062988281}]}, {"text": "Given a large corpus of definitions we leverage syntactic dependencies to reduce data sparsity, then disambiguate the arguments and content words of the relation strings, and finally exploit the resulting information to organize the acquired relations hierarchically.", "labels": [], "entities": []}, {"text": "The output of DEFIE is a high-quality knowledge base consisting of several million automatically acquired semantic relations.", "labels": [], "entities": [{"text": "DEFIE", "start_pos": 14, "end_pos": 19, "type": "DATASET", "confidence": 0.6848748922348022}]}], "introductionContent": [{"text": "The problem of knowledge acquisition lies at the core of Natural Language Processing.", "labels": [], "entities": [{"text": "knowledge acquisition", "start_pos": 15, "end_pos": 36, "type": "TASK", "confidence": 0.8035890460014343}, {"text": "Natural Language Processing", "start_pos": 57, "end_pos": 84, "type": "TASK", "confidence": 0.6446771919727325}]}, {"text": "Recent years have witnessed the massive exploitation of collaborative, semi-structured information as the ideal middle ground between high-quality, fully-structured resources and the larger amount of cheaper (but noisy) unstructured text (.", "labels": [], "entities": []}, {"text": "Collaborative projects, like Freebase ( and Wikidata, have been being developed for many years and are continuously being improved.", "labels": [], "entities": [{"text": "Freebase", "start_pos": 29, "end_pos": 37, "type": "DATASET", "confidence": 0.9699202179908752}, {"text": "Wikidata", "start_pos": 44, "end_pos": 52, "type": "DATASET", "confidence": 0.906463086605072}]}, {"text": "A great deal of research also focuses on enriching available semi-structured resources, most notably Wikipedia, thereby creating taxonomies (), ontologies () and semantic networks.", "labels": [], "entities": []}, {"text": "These solutions, however, are inherently constrained to small and often prespecified sets of relations.", "labels": [], "entities": []}, {"text": "A more radical approach is adopted in systems like TEXTRUNNER () and REVERB), which developed from the Open Information Extraction (OIE) paradigm) and focused on the unconstrained extraction of a large number of relations from massive unstructured corpora.", "labels": [], "entities": [{"text": "REVERB", "start_pos": 69, "end_pos": 75, "type": "METRIC", "confidence": 0.9814132452011108}]}, {"text": "Ultimately, all these endeavors were geared towards addressing the knowledge acquisition problem and tackling long-standing challenges in the field, such as Machine Reading (.", "labels": [], "entities": [{"text": "knowledge acquisition", "start_pos": 67, "end_pos": 88, "type": "TASK", "confidence": 0.8721711039543152}, {"text": "Machine Reading", "start_pos": 157, "end_pos": 172, "type": "TASK", "confidence": 0.9156627953052521}]}, {"text": "While earlier OIE approaches relied mostly on dependencies at the level of surface text), more recent work has focused on deeper language understanding at the level of both syntax and semantics and tackled challenging linguistic phenomena like synonymy and polysemy.", "labels": [], "entities": []}, {"text": "However, these issues have not yet been addressed in their entirety.", "labels": [], "entities": []}, {"text": "Relation strings are still bound to surface text, lacking actual semantic content.", "labels": [], "entities": []}, {"text": "Furthermore, most OIE systems do not have a clear and unified ontological structure and require additional processing steps, such as statistical inference mappings (), graphbased alignments of relational phrases), or knowledge base unification procedures, in order for their potential to be exploitable in real applications.", "labels": [], "entities": [{"text": "knowledge base unification", "start_pos": 217, "end_pos": 243, "type": "TASK", "confidence": 0.6303812662760416}]}, {"text": "In DEFIE the key idea is to leverage the linguistic analysis of recent semantically-enhanced OIE techniques while moving from open text to smaller corpora of dense prescriptive knowledge.", "labels": [], "entities": [{"text": "DEFIE", "start_pos": 3, "end_pos": 8, "type": "DATASET", "confidence": 0.6752481460571289}]}, {"text": "The aim is then to extract as much information as possible by unifying syntactic analysis and state-of-the-art disambiguation and entity linking.", "labels": [], "entities": [{"text": "entity linking", "start_pos": 130, "end_pos": 144, "type": "TASK", "confidence": 0.7067375779151917}]}, {"text": "Using this strategy, from an input corpus of textual definitions (short and concise descriptions of a given concept or entity) we are able to harvest fully disambiguated relation instances on a large scale, and integrate them automatically into a high-quality taxonomy of semantic relations.", "labels": [], "entities": []}, {"text": "As a result a large knowledge base is produced that shows competitive accuracy and coverage against state-of-the-art OIE systems based on much larger corpora.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 70, "end_pos": 78, "type": "METRIC", "confidence": 0.9990717172622681}, {"text": "coverage", "start_pos": 83, "end_pos": 91, "type": "METRIC", "confidence": 0.9884184002876282}]}, {"text": "Our contributions can be summarized as follows: \u2022 We propose an approach to IE that ties together syntactic dependencies and unified entity linking/word sense disambiguation, designed to discover semantic relations from a relatively small corpus of textual definitions; \u2022 We create a large knowledge base of fully disambiguated relation instances, ranging over named entities and concepts from available resources like WordNet and Wikipedia; \u2022 We exploit our semantified relation patterns to automatically build a rich, high-quality relation taxonomy, showing competitive results against state-of-the-art approaches.", "labels": [], "entities": [{"text": "IE", "start_pos": 76, "end_pos": 78, "type": "TASK", "confidence": 0.9864446520805359}, {"text": "unified entity linking/word sense disambiguation", "start_pos": 125, "end_pos": 173, "type": "TASK", "confidence": 0.6341593904154641}]}, {"text": "Our approach comprises three stages.", "labels": [], "entities": []}, {"text": "First, we extract from our input corpus an initial set of semantic relations (Section 2); each relation is then scored and augmented with semantic type signatures (Section 3); finally, the augmented relations are used to build a relation taxonomy (Section 4).", "labels": [], "entities": []}], "datasetContent": [{"text": "The input corpus used for the relation extraction procedure is the full set of English textual definitions in BabelNet 2.5 (.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 30, "end_pos": 49, "type": "TASK", "confidence": 0.8793757855892181}]}, {"text": "In fact, any set of textual definitions can be provided as input to DEFIE, ranging from existing dictionaries (like WordNet or Wiktionary) to the set of first sentences of Wikipedia articles.", "labels": [], "entities": [{"text": "DEFIE", "start_pos": 68, "end_pos": 73, "type": "DATASET", "confidence": 0.7244938015937805}, {"text": "WordNet", "start_pos": 116, "end_pos": 123, "type": "DATASET", "confidence": 0.9412832260131836}]}, {"text": "As it is a merger for various different resources of this kind, BabelNet provides a large heterogeneous set comprising definitions from WordNet, Wikipedia, Wiktionary, Wikidata and OmegaWiki.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 136, "end_pos": 143, "type": "DATASET", "confidence": 0.957631528377533}]}, {"text": "To the best of our knowledge, this set constitutes the largest available corpus of definitional knowledge.", "labels": [], "entities": [{"text": "definitional knowledge", "start_pos": 83, "end_pos": 105, "type": "TASK", "confidence": 0.905665785074234}]}, {"text": "We therefore worked on a total of 4,357,327 textual definitions from the English synsets of BabelNet's knowledge base.", "labels": [], "entities": []}, {"text": "We then used the same version of BabelNet as the underlying semantic network structure for disambiguating with Babelfy.", "labels": [], "entities": []}, {"text": "Comparative statistics are shown in.", "labels": [], "entities": []}, {"text": "DEFIE extracts 20,352,903 relation instances, out of which 13,753,133 feature a fully disambiguated pattern, yielding an average of 3.15 disambiguated relation instances extracted from each definition.", "labels": [], "entities": []}, {"text": "After the extraction process, our knowledge base comprises 255,881 distinct semantic relations, 94% of which also have disambiguated content words in their patterns.", "labels": [], "entities": []}, {"text": "DEFIE extracts a considerably larger amount of relation instances compared to similar approaches, despite the much smaller amount of text used.", "labels": [], "entities": []}, {"text": "For example, we managed to harvest over 5 million relation instances more than PATTY, using a much smaller corpus (sin-gle sentences as opposed to full Wikipedia articles) and generating a number of distinct relations that was six times less than PATTY's.", "labels": [], "entities": [{"text": "PATTY", "start_pos": 79, "end_pos": 84, "type": "DATASET", "confidence": 0.801882803440094}]}, {"text": "As a result, we obtained an average number of extractions that was substantially higher than those of our OIE competitors.", "labels": [], "entities": [{"text": "OIE", "start_pos": 106, "end_pos": 109, "type": "DATASET", "confidence": 0.8553486466407776}]}, {"text": "This suggests that DEFIE is able to exploit the nature of textual definitions effectively and generalize over relation patterns.", "labels": [], "entities": []}, {"text": "Furthermore, our semantic analysis captured 2,398,982 distinct arguments (either concept or named entities), outperforming almost all open-text systems examined.", "labels": [], "entities": []}, {"text": "All the evaluations carried out in Section 6 were based on manual assessment by two human judges, with an inter-annotator agreement, as measured by Cohen's kappa coefficient, above 70% in all cases.", "labels": [], "entities": []}, {"text": "In these evaluations we compared DE-FIE with the following OIE approaches: \u2022 NELL () with knowledge base beliefs updated to November 2014; \u2022 PATTY (Nakashole et al., 2012) with Freebase types and pattern synsets from the English Wikipedia dump of June 2011; \u2022 REVERB (Fader et al., 2011), using the set of normalized relation instances from the ClueWeb09 dataset; \u2022 WISENET (Moro and Navigli, 2012; Moro and Navigli, 2013) with relational phrases from the English Wikipedia dump of December 2012.", "labels": [], "entities": [{"text": "NELL", "start_pos": 77, "end_pos": 81, "type": "METRIC", "confidence": 0.9107092022895813}, {"text": "PATTY", "start_pos": 141, "end_pos": 146, "type": "METRIC", "confidence": 0.9901622533798218}, {"text": "English Wikipedia dump of June 2011", "start_pos": 221, "end_pos": 256, "type": "DATASET", "confidence": 0.8875267406304678}, {"text": "REVERB", "start_pos": 260, "end_pos": 266, "type": "METRIC", "confidence": 0.9938870072364807}, {"text": "ClueWeb09 dataset", "start_pos": 345, "end_pos": 362, "type": "DATASET", "confidence": 0.860884964466095}, {"text": "English Wikipedia dump of December 2012", "start_pos": 456, "end_pos": 495, "type": "DATASET", "confidence": 0.8568936586380005}]}, {"text": "In addition, we also compared our knowledge base with up-to-date human-contributed resources, namely Freebase ( and DBpedia (), both from the dumps of April/May 2014.: Novelty of the extracted information", "labels": [], "entities": [{"text": "Freebase", "start_pos": 101, "end_pos": 109, "type": "DATASET", "confidence": 0.9281288981437683}, {"text": "DBpedia", "start_pos": 116, "end_pos": 123, "type": "DATASET", "confidence": 0.8577522039413452}]}], "tableCaptions": [{"text": " Table 1: Examples of relation scores", "labels": [], "entities": []}, {"text": " Table 2: Comparative statistics on the relation extraction process", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 40, "end_pos": 59, "type": "TASK", "confidence": 0.8635233044624329}]}, {"text": " Table 2. DEFIE extracts 20,352,903 relation in- stances, out of which 13,753,133 feature a fully dis- ambiguated pattern, yielding an average of 3.15 dis- ambiguated relation instances extracted from each  definition. After the extraction process, our knowl- edge base comprises 255,881 distinct semantic re- lations, 94% of which also have disambiguated  content words in their patterns. DEFIE extracts  a considerably larger amount of relation instances  compared to similar approaches, despite the much  smaller amount of text used. For example, we man- aged to harvest over 5 million relation instances  more than PATTY, using a much smaller corpus (sin-gle sentences as opposed to full Wikipedia articles)  and generating a number of distinct relations that  was six times less than PATTY's. As a result, we  obtained an average number of extractions that was  substantially higher than those of our OIE competi- tors. This suggests that DEFIE is able to exploit the  nature of textual definitions effectively and general- ize over relation patterns. Furthermore, our semantic  analysis captured 2,398,982 distinct arguments (ei- ther concept or named entities), outperforming al- most all open-text systems examined.", "labels": [], "entities": []}, {"text": " Table 3: Precision of relation patterns", "labels": [], "entities": [{"text": "Precision of relation patterns", "start_pos": 10, "end_pos": 40, "type": "TASK", "confidence": 0.7717525660991669}]}, {"text": " Table 4: Novelty of the extracted information", "labels": [], "entities": [{"text": "Novelty", "start_pos": 10, "end_pos": 17, "type": "METRIC", "confidence": 0.8266762495040894}]}, {"text": " Table 5: Coverage of semantic relations", "labels": [], "entities": [{"text": "Coverage of semantic relations", "start_pos": 10, "end_pos": 40, "type": "TASK", "confidence": 0.8658080995082855}]}, {"text": " Table 6: Coverage of manually curated resources", "labels": [], "entities": []}, {"text": " Table 7: Coverage of individual relation instances", "labels": [], "entities": [{"text": "Coverage of individual relation", "start_pos": 10, "end_pos": 41, "type": "TASK", "confidence": 0.8429012149572372}]}, {"text": " Table 8: Precision and coverage of the relation taxonomy", "labels": [], "entities": [{"text": "Precision", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9649056792259216}, {"text": "coverage", "start_pos": 24, "end_pos": 32, "type": "METRIC", "confidence": 0.9370015859603882}]}, {"text": " Table 9: Coverage for different disambiguation systems", "labels": [], "entities": []}, {"text": " Table 10: Precision for different disambiguation systems", "labels": [], "entities": [{"text": "Precision", "start_pos": 11, "end_pos": 20, "type": "METRIC", "confidence": 0.7228564620018005}]}, {"text": " Table 11: Composition of the input corpus by source", "labels": [], "entities": []}, {"text": " Table 12: Impact of each source on the extraction step", "labels": [], "entities": []}, {"text": " Table 13: Extraction results over non-definitional text", "labels": [], "entities": [{"text": "Extraction", "start_pos": 11, "end_pos": 21, "type": "TASK", "confidence": 0.96555495262146}]}, {"text": " Table 14: Performance of PATTY on definitional data", "labels": [], "entities": [{"text": "PATTY", "start_pos": 26, "end_pos": 31, "type": "METRIC", "confidence": 0.5541623830795288}]}, {"text": " Table 16: Concept pairs and associated edges in BabelNet", "labels": [], "entities": []}]}