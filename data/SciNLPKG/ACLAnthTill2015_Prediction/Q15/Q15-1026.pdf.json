{"title": [{"text": "A Graph-based Lattice Dependency Parser for Joint Morphological Segmentation and Syntactic Analysis", "labels": [], "entities": [{"text": "Joint Morphological Segmentation", "start_pos": 44, "end_pos": 76, "type": "TASK", "confidence": 0.6762571434179941}, {"text": "Syntactic Analysis", "start_pos": 81, "end_pos": 99, "type": "TASK", "confidence": 0.8136685490608215}]}], "abstractContent": [{"text": "Space-delimited words in Turkish and He-brew text can be further segmented into meaningful units, but syntactic and semantic context is necessary to predict segmentation.", "labels": [], "entities": []}, {"text": "At the same time, predicting correct syntactic structures relies on correct segmentation.", "labels": [], "entities": [{"text": "predicting correct syntactic structures", "start_pos": 18, "end_pos": 57, "type": "TASK", "confidence": 0.8953389078378677}]}, {"text": "We present a graph-based lattice dependency parser that operates on morphological lattices to represent different segmentations and morphological analyses fora given input sentence.", "labels": [], "entities": []}, {"text": "The lattice parser predicts a dependency tree over a path in the lattice and thus solves the joint task of segmentation, morphological analysis, and syntactic parsing.", "labels": [], "entities": [{"text": "morphological analysis", "start_pos": 121, "end_pos": 143, "type": "TASK", "confidence": 0.7048296481370926}, {"text": "syntactic parsing", "start_pos": 149, "end_pos": 166, "type": "TASK", "confidence": 0.7344527840614319}]}, {"text": "We conduct experiments on the Turkish and the Hebrew treebank and show that the joint model outper-forms three state-of-the-art pipeline systems on both data sets.", "labels": [], "entities": [{"text": "Turkish and the Hebrew treebank", "start_pos": 30, "end_pos": 61, "type": "DATASET", "confidence": 0.6750509858131408}]}, {"text": "Our work corroborates findings from constituency lattice parsing for He-brew and presents the first results for full lattice parsing on Turkish.", "labels": [], "entities": [{"text": "constituency lattice parsing", "start_pos": 36, "end_pos": 64, "type": "TASK", "confidence": 0.6634484231472015}]}], "introductionContent": [{"text": "Linguistic theory has provided examples from many different languages in which grammatical information is expressed via case marking, morphological agreement, or clitics.", "labels": [], "entities": [{"text": "Linguistic theory", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.7697734534740448}]}, {"text": "In these languages, configurational information is less important than in English since the words are overtly marked for their syntactic relations to each other.", "labels": [], "entities": []}, {"text": "Such morphologically rich languages pose many new challenges to today's natural language processing technology, which has often been developed for English.", "labels": [], "entities": []}, {"text": "One of the first challenges is the question on how to represent morphologically rich languages and what are the basic units of analysis ().", "labels": [], "entities": []}, {"text": "The Turkish treebank, for example, represents words as sequences of inflectional groups, semantically coherent groups of morphemes separated by derivational boundaries.", "labels": [], "entities": [{"text": "Turkish treebank", "start_pos": 4, "end_pos": 20, "type": "DATASET", "confidence": 0.9353280067443848}]}, {"text": "The treebank for Modern Hebrew) chooses morphemes as the basic unit of representation.", "labels": [], "entities": []}, {"text": "A space-delimited word in the treebank can consist of several morphemes that may belong to independent syntactic contexts.", "labels": [], "entities": []}, {"text": "Both Turkish and Hebrew show high amounts of ambiguity when it comes to the correct segmentation of words into inflectional groups and morphemes, respectively.", "labels": [], "entities": []}, {"text": "Within a sentence, however, these ambiguities can often be resolved by the syntactic and semantic context in which these words appear.", "labels": [], "entities": []}, {"text": "A standard (dependency) parsing system decides segmentation, morphological analysis (including POS), and syntax one after the other in a pipeline setup.", "labels": [], "entities": []}, {"text": "While pipelines are fast and efficient, they cannot model interaction between these different levels of analysis, however.", "labels": [], "entities": []}, {"text": "It has therefore been argued that joint modeling of these three tasks is more suitable to the problem).", "labels": [], "entities": []}, {"text": "In previous research, several transition-based parsers have been proposed to model POS/morphological tagging and parsing jointly.", "labels": [], "entities": [{"text": "POS/morphological tagging", "start_pos": 83, "end_pos": 108, "type": "TASK", "confidence": 0.8464375734329224}]}, {"text": "Such parsing systems have been further extended to also solve the segmentation problem in Chinese).", "labels": [], "entities": [{"text": "parsing", "start_pos": 5, "end_pos": 12, "type": "TASK", "confidence": 0.9691389799118042}, {"text": "segmentation problem", "start_pos": 66, "end_pos": 86, "type": "TASK", "confidence": 0.922329306602478}]}, {"text": "Transition-based parsers are attractive since they do not rely on global optimization and thus deal well with the increased model complexity that comes with joint modeling.", "labels": [], "entities": []}, {"text": "Nonetheless, graphbased models have been proposed as well, e.g. by for joint POS tagging and dependency parsing.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 77, "end_pos": 88, "type": "TASK", "confidence": 0.8094222545623779}, {"text": "dependency parsing", "start_pos": 93, "end_pos": 111, "type": "TASK", "confidence": 0.8454720675945282}]}, {"text": "Their parsers model the joint problem directly at the cost of increased model complexity.", "labels": [], "entities": []}, {"text": "In this paper, we present a graph-based dependency parser for lattice parsing that handles the increased complexity by applying dual decomposition.", "labels": [], "entities": [{"text": "lattice parsing", "start_pos": 62, "end_pos": 77, "type": "TASK", "confidence": 0.7081865072250366}]}, {"text": "The parser operates on morphological lattices and predicts word segmentation, morphological analysis, and dependency syntax jointly.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 59, "end_pos": 76, "type": "TASK", "confidence": 0.6978092789649963}, {"text": "morphological analysis", "start_pos": 78, "end_pos": 100, "type": "TASK", "confidence": 0.7102033644914627}]}, {"text": "It decomposes the problem into several subproblems and uses dual decomposition to find a common solution ().", "labels": [], "entities": []}, {"text": "The subproblems are defined such that they can be solved efficiently and agreement is found in an iterative fashion.", "labels": [], "entities": []}, {"text": "Decomposing the problem thus keeps the complexity of the joint parser on a tractable level.", "labels": [], "entities": []}, {"text": "We test the parser on the Turkish and the Hebrew treebank.", "labels": [], "entities": [{"text": "Turkish and the Hebrew treebank", "start_pos": 26, "end_pos": 57, "type": "DATASET", "confidence": 0.7977035880088806}]}, {"text": "The segmentation problem in these languages can be tackled with the same approach even though their underlying linguistic motivation is quite different.", "labels": [], "entities": []}, {"text": "In our experiments, the lattice dependency parser outperforms three state-of-the-art pipeline systems.", "labels": [], "entities": []}, {"text": "Lattice parsing for Hebrew has been thoroughly investigated in constituency parsing, demonstrating the viability of joint modeling.", "labels": [], "entities": [{"text": "Lattice parsing", "start_pos": 0, "end_pos": 15, "type": "TASK", "confidence": 0.6137295812368393}, {"text": "constituency parsing", "start_pos": 63, "end_pos": 83, "type": "TASK", "confidence": 0.8970783650875092}]}, {"text": "To the best of our knowledge, our work is the first to apply full lattice parsing to the Turkish treebank.", "labels": [], "entities": [{"text": "lattice parsing", "start_pos": 66, "end_pos": 81, "type": "TASK", "confidence": 0.5925697386264801}, {"text": "Turkish treebank", "start_pos": 89, "end_pos": 105, "type": "DATASET", "confidence": 0.967484176158905}]}, {"text": "We introduce the segmentation problem in Turkish and Hebrew in Section 2 and present the lattice parser in Section 3.", "labels": [], "entities": [{"text": "segmentation", "start_pos": 17, "end_pos": 29, "type": "TASK", "confidence": 0.9734015464782715}]}, {"text": "Sections 4 and 5 describe the experiments and their results and we discuss related work in Section 6.", "labels": [], "entities": []}, {"text": "We conclude with Section 7.", "labels": [], "entities": []}], "datasetContent": [{"text": "Standard labeled and unlabeled attachment scores are not applicable when parsing with uncertain segmentation since the number of tokens in the output of the parser may not coincide with the number of tokens in the gold standard.", "labels": [], "entities": [{"text": "parsing", "start_pos": 73, "end_pos": 80, "type": "TASK", "confidence": 0.9735928177833557}]}, {"text": "Previous work therefore suggests alternative methods for evaluation, e.g. by means of precision, recall, and f-score over tokens, see e.g. or.", "labels": [], "entities": [{"text": "precision", "start_pos": 86, "end_pos": 95, "type": "METRIC", "confidence": 0.9992771744728088}, {"text": "recall", "start_pos": 97, "end_pos": 103, "type": "METRIC", "confidence": 0.9939100742340088}]}, {"text": "The uncertainty of segmentation furthermore makes it very hard to evaluate the other levels of analysis independently of the segmentation.", "labels": [], "entities": [{"text": "segmentation", "start_pos": 19, "end_pos": 31, "type": "TASK", "confidence": 0.9804547429084778}]}, {"text": "In order to decide whether the morphological analysis of a token (or its syntactic attachment) is correct, one always needs to find out first to which token in the gold standard it corresponds.", "labels": [], "entities": []}, {"text": "By establishing this correspondence, the segmentation is already being evaluated.", "labels": [], "entities": [{"text": "segmentation", "start_pos": 41, "end_pos": 53, "type": "TASK", "confidence": 0.9783527851104736}]}, {"text": "Evaluating syntax isolated from the other levels of analysis is therefore not possible in general.", "labels": [], "entities": []}, {"text": "(2012) count a dependency relation correct only when both the head and the dependent have the correct morphological analysis (here POS) and segmentation.", "labels": [], "entities": []}, {"text": "Goldberg (2011, page 53) proposes a similar approach, but only requires surface forms to match between gold standard and prediction.", "labels": [], "entities": []}, {"text": "These metrics compute precision and recall over tokens. and Eryi\u02d8 git (2012) define an accuracy (IGeval) for Turkish parsing by taking advantage of the annotation scheme in the Turkish treebank: A non-final IG in the Turkish treebank always has its head immediately to the right, always with the same label, which makes it possible to ignore the inner dependency relations, i.e. the segmentation, of a dependent word.", "labels": [], "entities": [{"text": "precision", "start_pos": 22, "end_pos": 31, "type": "METRIC", "confidence": 0.9959617257118225}, {"text": "recall", "start_pos": 36, "end_pos": 42, "type": "METRIC", "confidence": 0.9931509494781494}, {"text": "accuracy", "start_pos": 87, "end_pos": 95, "type": "METRIC", "confidence": 0.997689962387085}, {"text": "Turkish parsing", "start_pos": 109, "end_pos": 124, "type": "TASK", "confidence": 0.6375956237316132}, {"text": "Turkish treebank", "start_pos": 177, "end_pos": 193, "type": "DATASET", "confidence": 0.853937178850174}]}, {"text": "The metric therefore only needs to check for each word whether the head of the last IG is attached to the correct IG in another word.", "labels": [], "entities": []}, {"text": "The metric includes a back-off strategy in case the head word's segmentation is wrong.", "labels": [], "entities": []}, {"text": "A dependency arc is then counted as correct if it attaches to an IG in the correct word and the POS tag of the head IG is the same as in the gold standard.", "labels": [], "entities": [{"text": "POS tag", "start_pos": 96, "end_pos": 103, "type": "METRIC", "confidence": 0.9642889201641083}]}, {"text": "We follow and use a strict definition of precision and recall (PREC, REC, F1) over tokens to evaluate the full task.", "labels": [], "entities": [{"text": "precision", "start_pos": 41, "end_pos": 50, "type": "METRIC", "confidence": 0.9990956783294678}, {"text": "recall", "start_pos": 55, "end_pos": 61, "type": "METRIC", "confidence": 0.9924200177192688}, {"text": "REC", "start_pos": 69, "end_pos": 72, "type": "METRIC", "confidence": 0.8331131339073181}, {"text": "F1)", "start_pos": 74, "end_pos": 77, "type": "METRIC", "confidence": 0.89400315284729}]}, {"text": "We first align the tokens of a word in the parser output with the tokens of the corresponding word in the gold standard using the NeedlemanWunsch algorithm, which we modify so it does not allow for mismatches.", "labels": [], "entities": []}, {"text": "A token in the parser output that is not in the gold standard is thus paired with a gap and vice versa.", "labels": [], "entities": []}, {"text": "Two tokens must have the same morphological analysis in order to match.", "labels": [], "entities": []}, {"text": "A true positive is defined as a pair of matching tokens whose heads are also aligned and match.", "labels": [], "entities": []}, {"text": "For labeled scores, the dependency relations must match as well.", "labels": [], "entities": []}, {"text": "Precision is defined as the number of true positives over the number of tokens in the prediction, recall is defined as the number of true positives over the number of tokens in the gold standard.", "labels": [], "entities": [{"text": "Precision", "start_pos": 0, "end_pos": 9, "type": "METRIC", "confidence": 0.992452085018158}, {"text": "recall", "start_pos": 98, "end_pos": 104, "type": "METRIC", "confidence": 0.999433696269989}]}, {"text": "F-score is the harmonic mean of precision and recall.", "labels": [], "entities": [{"text": "F-score", "start_pos": 0, "end_pos": 7, "type": "METRIC", "confidence": 0.9758203029632568}, {"text": "precision", "start_pos": 32, "end_pos": 41, "type": "METRIC", "confidence": 0.9994860887527466}, {"text": "recall", "start_pos": 46, "end_pos": 52, "type": "METRIC", "confidence": 0.9967036843299866}]}, {"text": "This metric is very strict and requires all levels of analysis to be correct.", "labels": [], "entities": []}, {"text": "In order to evaluate the syntax as independently as possible, we furthermore report IGeval for Turkish, with and without the aforementioned backoff strategy (IGeval and IGeval STRICT).", "labels": [], "entities": []}, {"text": "For Hebrew, we report on aversion of precision and recall as defined above that only requires the surface forms of the tokens to match.", "labels": [], "entities": [{"text": "aversion", "start_pos": 25, "end_pos": 33, "type": "METRIC", "confidence": 0.9864033460617065}, {"text": "precision", "start_pos": 37, "end_pos": 46, "type": "METRIC", "confidence": 0.9612134695053101}, {"text": "recall", "start_pos": 51, "end_pos": 57, "type": "METRIC", "confidence": 0.9984366297721863}]}, {"text": "This metric is almost the one proposed in Goldberg (2011).", "labels": [], "entities": []}, {"text": "All reported evaluation metrics ignore punctuation.", "labels": [], "entities": []}, {"text": "We do not use TedEval as defined in even though it has been used previously to evaluate dependency parsing with uncertain segmentation).", "labels": [], "entities": [{"text": "TedEval", "start_pos": 14, "end_pos": 21, "type": "METRIC", "confidence": 0.743933916091919}, {"text": "dependency parsing", "start_pos": 88, "end_pos": 106, "type": "TASK", "confidence": 0.8261351585388184}]}, {"text": "The reason is that it is not an inherently dependency-based framework and the conversion from constituency structures to dependency structures interferes with the metric.", "labels": [], "entities": []}, {"text": "The metric The method does not create cross, many-to-one, or one-tomany alignments, which can be important because in very rare cases the same token occurs twice in one word.", "labels": [], "entities": []}, {"text": "The metric would notwork for Turkish, as the surface forms of non-final IGs are all represented as underscores.", "labels": [], "entities": []}, {"text": "As an experiment, we took a Turkish treebank tree and created artificial parses by attaching one token to a different head each time.", "labels": [], "entities": [{"text": "Turkish treebank tree", "start_pos": 28, "end_pos": 49, "type": "DATASET", "confidence": 0.9184714158376058}]}, {"text": "All other tokens remained attached to their correct head, and segmentation is kept gold.", "labels": [], "entities": [{"text": "segmentation", "start_pos": 62, "end_pos": 74, "type": "TASK", "confidence": 0.950312077999115}]}, {"text": "This gave us 11 parses that contained exactly one attachment error and one parse identical with the gold standard.", "labels": [], "entities": []}, {"text": "Running TedEval on each of the proposed in Goldberg (2011) implements the same ideas without edit distance and is defined directly for dependencies.", "labels": [], "entities": [{"text": "TedEval", "start_pos": 8, "end_pos": 15, "type": "DATASET", "confidence": 0.9076724648475647}]}, {"text": "We use the same token-based precision and recall to measure the quality of segmentation and morphological analysis without syntax.", "labels": [], "entities": [{"text": "precision", "start_pos": 28, "end_pos": 37, "type": "METRIC", "confidence": 0.9930382370948792}, {"text": "recall", "start_pos": 42, "end_pos": 48, "type": "METRIC", "confidence": 0.9990304708480835}]}, {"text": "For a token to be correct, it has to have the same morphological analysis as the token in the gold standard to which it is aligned.", "labels": [], "entities": []}, {"text": "We furthermore report word accuracy (ACC w ), which is the percentage of words that received the correct segmentation.", "labels": [], "entities": [{"text": "accuracy (ACC w )", "start_pos": 27, "end_pos": 44, "type": "METRIC", "confidence": 0.8699483871459961}]}], "tableCaptions": [{"text": " Table 1: Path selection quality.", "labels": [], "entities": [{"text": "Path selection", "start_pos": 10, "end_pos": 24, "type": "TASK", "confidence": 0.8461474776268005}]}, {"text": " Table 2: Parsing results for Turkish. Statistically significant differences between the joint system and the pipeline  system are marked with  \u2020 (p < 0.01) and  *  (p < 0.05). Significance testing was performed using the Wilcoxon Signed  Rank Test (not for F1).", "labels": [], "entities": [{"text": "Wilcoxon Signed  Rank Test", "start_pos": 222, "end_pos": 248, "type": "METRIC", "confidence": 0.5564810857176781}, {"text": "F1", "start_pos": 258, "end_pos": 260, "type": "METRIC", "confidence": 0.9967451095581055}]}, {"text": " Table 3: Statistically significant differences between the  joint system and the pipeline system are marked with  \u2020  (p < 0.01) and  *  (p < 0.05). Significance testing was  performed using the Wilcoxon Signed Rank Test (not for  F1).", "labels": [], "entities": [{"text": "Wilcoxon Signed Rank Test", "start_pos": 195, "end_pos": 220, "type": "DATASET", "confidence": 0.5907378196716309}, {"text": "F1", "start_pos": 231, "end_pos": 233, "type": "METRIC", "confidence": 0.9974077343940735}]}]}