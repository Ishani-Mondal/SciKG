{"title": [{"text": "Reasoning about Quantities in Natural Language", "labels": [], "entities": [{"text": "Reasoning about Quantities in Natural Language", "start_pos": 0, "end_pos": 46, "type": "TASK", "confidence": 0.8868890901406606}]}], "abstractContent": [{"text": "Little work from the Natural Language Processing community has targeted the role of quantities in Natural Language Understanding.", "labels": [], "entities": [{"text": "Natural Language Understanding", "start_pos": 98, "end_pos": 128, "type": "TASK", "confidence": 0.647710531949997}]}, {"text": "This paper takes some key steps towards facilitating reasoning about quantities expressed in natural language.", "labels": [], "entities": [{"text": "reasoning about quantities expressed in natural language", "start_pos": 53, "end_pos": 109, "type": "TASK", "confidence": 0.7895157848085675}]}, {"text": "We investigate two different tasks of numerical reasoning.", "labels": [], "entities": [{"text": "numerical reasoning", "start_pos": 38, "end_pos": 57, "type": "TASK", "confidence": 0.8137719929218292}]}, {"text": "First, we consider Quantity Entailment, anew task formulated to understand the role of quantities in general textual inference tasks.", "labels": [], "entities": [{"text": "Quantity Entailment", "start_pos": 19, "end_pos": 38, "type": "TASK", "confidence": 0.8384712040424347}]}, {"text": "Second, we consider the problem of automatically understanding and solving elementary school math word problems.", "labels": [], "entities": [{"text": "automatically understanding and solving elementary school math word problems", "start_pos": 35, "end_pos": 111, "type": "TASK", "confidence": 0.7704424891206954}]}, {"text": "In order to address these quantitative reasoning problems we first develop a computational approach which we show to successfully recognize and normalize textual expressions of quantities.", "labels": [], "entities": []}, {"text": "We then use these capabilities to further develop algorithms to assist reasoning in the context of the aforementioned tasks.", "labels": [], "entities": []}], "introductionContent": [{"text": "Every day, newspaper articles report statistics to present an objective assessment of the situations they describe.", "labels": [], "entities": []}, {"text": "From election results, number of casualties in accidents, to changes in stock prices, textual representations of quantities are extremely important in communicating accurate information.", "labels": [], "entities": []}, {"text": "However, relatively little work in Natural Language Processing has analyzed the use of quantities in text.", "labels": [], "entities": []}, {"text": "Even in areas where we have relatively mature solutions, like search, we fail to deal with quantities; for example, one cannot search the financial media for \"transactions in the 1-2 million pounds range.\"", "labels": [], "entities": []}, {"text": "Language understanding often requires the ability to reason with respect to quantities.", "labels": [], "entities": [{"text": "Language understanding", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.6837880164384842}]}, {"text": "Consider, for example, the following textual inference, which we present as Textual Entailment query.", "labels": [], "entities": []}, {"text": "Recognizing Textual Entailment (RTE) ( has become a common way to formulate textual inference and we follow this trend.", "labels": [], "entities": [{"text": "Recognizing Textual Entailment (RTE)", "start_pos": 0, "end_pos": 36, "type": "TASK", "confidence": 0.8209287226200104}, {"text": "formulate textual inference", "start_pos": 66, "end_pos": 93, "type": "TASK", "confidence": 0.8518518209457397}]}, {"text": "RTE is the task of determining whether the meaning of a given text passage T entails that of a hypothesis H.", "labels": [], "entities": [{"text": "RTE", "start_pos": 0, "end_pos": 3, "type": "TASK", "confidence": 0.8344252705574036}]}, {"text": "Here, we need to identify the quantities \"five Americans\" and \"four Israelis\", as well as use the fact that \"Americans\" and \"Israelis\" are \"people\".", "labels": [], "entities": []}, {"text": "A different flavour of numeric reasoning is required in math word problems.", "labels": [], "entities": []}, {"text": "For example, in Example 2 Ryan has 72 marbles and 17 blocks.", "labels": [], "entities": []}, {"text": "If he shares the marbles among 9 friends, how many marbles does each friend get?", "labels": [], "entities": []}, {"text": "one has to determine the relevant quantities in the question.", "labels": [], "entities": []}, {"text": "Here, the number of blocks in Ryan's possession has no bearing on the answer.", "labels": [], "entities": []}, {"text": "The second challenge is to determine the relevant mathematical operation from the context.", "labels": [], "entities": []}, {"text": "In this paper, we describe some key steps necessary to facilitate reasoning about quantities in natural language text.", "labels": [], "entities": [{"text": "reasoning about quantities in natural language text", "start_pos": 66, "end_pos": 117, "type": "TASK", "confidence": 0.7492737599781581}]}, {"text": "We first describe a system developed to recognize quantities in free form text, infer units associated with them and convert them to 1 a standardized form.", "labels": [], "entities": []}, {"text": "For example, in we would like to extract the number 6.5, the corresponding unit, \"hour\", and also determine that the quantity describes an approximate figure, not an exact one.", "labels": [], "entities": []}, {"text": "One of the difficulties is that any noun or noun phrase can be a unit, and inferring them requires analyzing contextual cues and local sentence structure.", "labels": [], "entities": []}, {"text": "As we show, in some cases deeper NLP techniques are required to support that.", "labels": [], "entities": []}, {"text": "We then develop a reasoning framework for quantities that we believe can play an important role in general purpose textual inference.", "labels": [], "entities": [{"text": "general purpose textual inference", "start_pos": 99, "end_pos": 132, "type": "TASK", "confidence": 0.7223523855209351}]}, {"text": "Isolating the quantity reasoning component of the RTE task, we define Quantity Entailment (QE) -the task of determining whether a given quantity can be inferred from a given text snippet, and then describe our approach towards solving it.", "labels": [], "entities": [{"text": "quantity reasoning", "start_pos": 14, "end_pos": 32, "type": "TASK", "confidence": 0.7179388999938965}, {"text": "RTE task", "start_pos": 50, "end_pos": 58, "type": "TASK", "confidence": 0.9322118759155273}, {"text": "Quantity Entailment (QE)", "start_pos": 70, "end_pos": 94, "type": "TASK", "confidence": 0.5834352135658264}]}, {"text": "This allows us to support the inference presented in Example 1.", "labels": [], "entities": []}, {"text": "As an additional evaluation, we also show the effectiveness of our system on an application of QE, a search for ranges of currency values.", "labels": [], "entities": []}, {"text": "Given a query range, say from 1 million USD to 3 million USD, we want to find all mentions of money with values in this range.", "labels": [], "entities": []}, {"text": "Using standard search engine technology to query all values in the range, in the various forms they could be expressed, is not feasible.", "labels": [], "entities": []}, {"text": "Instead, we use our proposed approach to extract monetary mentions from text and normalize them, and then we use QE to verify them against the query.", "labels": [], "entities": [{"text": "QE", "start_pos": 113, "end_pos": 115, "type": "METRIC", "confidence": 0.947597086429596}]}, {"text": "We next develop a reasoning framework for elementary school math word problems.", "labels": [], "entities": [{"text": "elementary school math word problems", "start_pos": 42, "end_pos": 78, "type": "TASK", "confidence": 0.626814204454422}]}, {"text": "Our reasoner makes use of several classifiers to detect different properties of a word problem, and finally combines the decisions of individual classifiers to obtain the correct answer.", "labels": [], "entities": []}, {"text": "We develop and annotate datasets 1 for evaluation, and show that our approach can handle the aforementioned reasoning tasks quite well.", "labels": [], "entities": []}, {"text": "The next section presents some related work on quantities and reasoning.", "labels": [], "entities": []}, {"text": "We then formally define a quantity and describe our knowledge  representation.", "labels": [], "entities": []}, {"text": "The following sections describe quantities extraction and standardization.", "labels": [], "entities": [{"text": "quantities extraction", "start_pos": 32, "end_pos": 53, "type": "TASK", "confidence": 0.7639223635196686}, {"text": "standardization", "start_pos": 58, "end_pos": 73, "type": "TASK", "confidence": 0.8951817154884338}]}, {"text": "We next present the formulation of Quantity Entailment, and describe our reasoning framework for it.", "labels": [], "entities": [{"text": "Quantity Entailment", "start_pos": 35, "end_pos": 54, "type": "TASK", "confidence": 0.9187357425689697}]}, {"text": "We then describe our approach towards understanding elementary school math problems, and conclude with experimental evaluation.", "labels": [], "entities": [{"text": "understanding elementary school math problems", "start_pos": 38, "end_pos": 83, "type": "TASK", "confidence": 0.8049534916877746}]}], "datasetContent": [{"text": "In this section, we seek to validate our proposed modeling.", "labels": [], "entities": []}, {"text": "We evaluate our system's performance on four tasks: Quantity Segmentation, Quantity Entailment, Currency Range Search, and Answering Math Word Problems.", "labels": [], "entities": [{"text": "Quantity Segmentation", "start_pos": 52, "end_pos": 73, "type": "TASK", "confidence": 0.8749386370182037}, {"text": "Quantity Entailment", "start_pos": 75, "end_pos": 94, "type": "TASK", "confidence": 0.8009057343006134}, {"text": "Currency Range Search", "start_pos": 96, "end_pos": 117, "type": "TASK", "confidence": 0.6574485898017883}, {"text": "Answering Math Word Problems", "start_pos": 123, "end_pos": 151, "type": "TASK", "confidence": 0.9230259209871292}]}, {"text": "We do not directly evaluate our system's ability to map raw text segments into our representation, but instead evaluate this capability extrinsically, in the context of the aforementioned tasks, since good Standardization is necessary to perform quantitative inference.", "labels": [], "entities": []}, {"text": "QE: Due to lack of related work, an adequately annotated corpus does not exist.", "labels": [], "entities": [{"text": "QE", "start_pos": 0, "end_pos": 2, "type": "DATASET", "confidence": 0.5274447798728943}]}, {"text": "Thus, in order to evaluate our system, we used two collections: 1.", "labels": [], "entities": []}, {"text": "Sub-corpus of the RTE) We choose text-hypothesis pairs from RTE2-RTE4 datasets, which have quantity mentions in the hypothesis.", "labels": [], "entities": [{"text": "RTE", "start_pos": 18, "end_pos": 21, "type": "DATASET", "confidence": 0.792622447013855}, {"text": "RTE2-RTE4 datasets", "start_pos": 60, "end_pos": 78, "type": "DATASET", "confidence": 0.9599522948265076}]}, {"text": "Overall, we selected 384 text-hypothesis pairs with quantities in the hypothesis.", "labels": [], "entities": []}, {"text": "2. Newswire Text 600 sentences of newswire text were selected, all containing quantity mentions.", "labels": [], "entities": [{"text": "Newswire Text 600 sentences of newswire text", "start_pos": 3, "end_pos": 47, "type": "DATASET", "confidence": 0.8967793243271964}]}, {"text": "Both these datasets were manually annotated with the phrase boundaries of quantity mentions and had an inter-annotator agreement of 0.91.", "labels": [], "entities": []}, {"text": "We restricted annotation to contiguous segments of text.", "labels": [], "entities": []}, {"text": "No instances of implicit quantities were annotated.", "labels": [], "entities": []}, {"text": "We also did not annotate these mentions with QVRs.", "labels": [], "entities": [{"text": "QVRs", "start_pos": 45, "end_pos": 49, "type": "DATASET", "confidence": 0.9009097218513489}]}, {"text": "Limiting the annotations to contiguous spans of text results in a few instances of quantities which contain missing information, such as missing or ambiguous units, and several range and ratio relationships which were not annotated (e.g., we do not annotate the range expressed in \"from in to in\", but do so in \"[from 5 million to 6 million]\").", "labels": [], "entities": []}, {"text": "In the RTE sub-corpus we also annotated entailment pairs with information about which quantities entail, in addition to the boundary information.", "labels": [], "entities": [{"text": "RTE sub-corpus", "start_pos": 7, "end_pos": 21, "type": "DATASET", "confidence": 0.879362016916275}]}, {"text": "For each quantity in the hypothesis we labeled it as either \"entails\", \"no relation\", or \"contradicts\", with an inter-annotator agreement of 0.95.", "labels": [], "entities": []}, {"text": "There were 309 entailing quantities, 71 contradicting quantities and 56 quantities which were unrelated to the corresponding text.", "labels": [], "entities": []}, {"text": "We also maintained the information about general entailment, that is, whether the hypothesis can be explained by the text.", "labels": [], "entities": [{"text": "general entailment", "start_pos": 41, "end_pos": 59, "type": "TASK", "confidence": 0.8409672379493713}]}, {"text": "An example of an annotated RTE example is shown below.", "labels": [], "entities": []}, {"text": "\"nine people\" : entails \"five Americans\" : entails Global entailment decision : entails Although we limit our scope to infer the entailment decision for individual quantities mentioned in hypothesis, we hope to see future approaches use these individual decisions and combine them appropriately to obtain the global entailment decision.", "labels": [], "entities": [{"text": "Global entailment decision", "start_pos": 51, "end_pos": 77, "type": "TASK", "confidence": 0.7066311140855154}]}, {"text": "Currency Search We developed anew dataset for evaluating currency search.", "labels": [], "entities": [{"text": "currency search", "start_pos": 57, "end_pos": 72, "type": "TASK", "confidence": 0.6678623557090759}]}, {"text": "Queries of various amounts of money like \"1000$\", \"USD 2 million\", etc. were made on a search engine, and paragraphs containing monetary mentions were taken from the top search results.", "labels": [], "entities": []}, {"text": "We collected 100 paragraphs containing various mentions of monetary values, and labeled them with the amount mentioned in them.", "labels": [], "entities": []}, {"text": "We restricted the denominations to US dollars.", "labels": [], "entities": []}, {"text": "The inter-annotator agreement was 0.98.", "labels": [], "entities": []}, {"text": "Math Word Problems We created anew dataset with elementary math word problems.", "labels": [], "entities": []}, {"text": "The problems were collected from http://www.k5learning.com/ and http://www.dadsworksheets.com/.", "labels": [], "entities": []}, {"text": "The list was further pruned to keep problems with the properties listed in section 6.", "labels": [], "entities": []}, {"text": "We also manually removed problems requiring background knowledge, for example, \"Roger reads 2 books each day.", "labels": [], "entities": []}, {"text": "How many books will he read in 3 weeks ?\", which requires knowing that a week comprises 7 days.", "labels": [], "entities": []}, {"text": "Problems with rounding issues were also excluded.", "labels": [], "entities": [{"text": "rounding", "start_pos": 14, "end_pos": 22, "type": "TASK", "confidence": 0.9727259874343872}]}, {"text": "For example, \"Each basket can hold 9 apples.", "labels": [], "entities": []}, {"text": "How many baskets are required to hold 10 apples ?\".", "labels": [], "entities": []}, {"text": "Each problem was annotated with the operation required to solve the problem, and the final answer.", "labels": [], "entities": []}, {"text": "shows some statistics of our dataset.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Statistics of math word problems dataset", "labels": [], "entities": []}, {"text": " Table 2: 10-fold cross-validation results of segmentation", "labels": [], "entities": [{"text": "segmentation", "start_pos": 46, "end_pos": 58, "type": "TASK", "confidence": 0.9502707123756409}]}, {"text": " Table 3. Note that  exact match only supports 43.3% of the entailment  decisions. It is also evident that the deeper semantic  analysis using SRL and Coreference improves the  quantitative inference.", "labels": [], "entities": [{"text": "SRL", "start_pos": 143, "end_pos": 146, "type": "DATASET", "confidence": 0.7770448327064514}]}, {"text": " Table 3: Results of QE; Adding Semantics(+SEM)", "labels": [], "entities": [{"text": "QE", "start_pos": 21, "end_pos": 23, "type": "METRIC", "confidence": 0.43734094500541687}]}, {"text": " Table 4: Micro-averaged accuracy in detecting monetary", "labels": [], "entities": [{"text": "Micro-averaged", "start_pos": 10, "end_pos": 24, "type": "METRIC", "confidence": 0.9410418272018433}, {"text": "accuracy", "start_pos": 25, "end_pos": 33, "type": "METRIC", "confidence": 0.9271078109741211}, {"text": "detecting", "start_pos": 37, "end_pos": 46, "type": "TASK", "confidence": 0.9802300930023193}]}, {"text": " Table 5: 2-fold cross-validation results of math word problem", "labels": [], "entities": []}]}