{"title": [{"text": "A Bayesian Model of Grounded Color Semantics", "labels": [], "entities": []}], "abstractContent": [{"text": "Natural language meanings allow speakers to encode important real-world distinctions, but corpora of grounded language use also reveal that speakers categorize the world in different ways and describe situations with different terminology.", "labels": [], "entities": []}, {"text": "To learn meanings from data, we therefore need to link underlying representations of meaning to models of speaker judgment and speaker choice.", "labels": [], "entities": []}, {"text": "This paper describes anew approach to this problem: we model variability through uncertainty in categorization boundaries and distributions over preferred vocabulary.", "labels": [], "entities": []}, {"text": "We apply the approach to a large data set of color descriptions , where statistical evaluation documents its accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 109, "end_pos": 117, "type": "METRIC", "confidence": 0.9973551034927368}]}, {"text": "The results are available as a Lexicon of Uncertain Color Standards (LUX), which supports future efforts in grounded language understanding and generation by prob-abilistically mapping 829 English color descriptions to potentially context-sensitive regions in HSV color space.", "labels": [], "entities": [{"text": "grounded language understanding and generation", "start_pos": 108, "end_pos": 154, "type": "TASK", "confidence": 0.6568493008613586}]}], "introductionContent": [{"text": "To ground natural language semantics in real-world data at large scale requires researchers to confront the vocabulary problem (.", "labels": [], "entities": []}, {"text": "Much of what people say falls in along tail of increasingly infrequent and specialized items.", "labels": [], "entities": []}, {"text": "Moreover, the choice of how to categorize and describe realworld data varies across people.", "labels": [], "entities": []}, {"text": "We can't account for this complexity by deriving one definitive mapping between words and the world.", "labels": [], "entities": []}, {"text": "We see this complexity already in free text descriptions of color patches.", "labels": [], "entities": []}, {"text": "English has fewer than a dozen basic color words, but people's descriptions of colors are much more variable than this would suggest.", "labels": [], "entities": []}, {"text": "Measured on the corpus described in Section 4.1, there's an average of 3.845 bits of information in a color description given the color it describes-comparable to rolling a 14-sided die.", "labels": [], "entities": []}, {"text": "summarizes the data and plots the entropy of descriptions encountered within small bins of color space.", "labels": [], "entities": []}, {"text": "The bins are aggregated over the Saturation and Value dimensions and indexed on the xaxis by the Hue dimension.", "labels": [], "entities": []}, {"text": "There's little reason to think that this variability conceals consistent meanings.", "labels": [], "entities": []}, {"text": "In formal semantics, one of the hallmarks of vague language is that speakers can make it more precise in alternative, incompatible ways.", "labels": [], "entities": []}, {"text": "We see this in practice as well, for example with the image of, where subjects com- from the data set of, whose subjects describe these dogs as a brown dog and a tan one or a tan dog and a white one.", "labels": [], "entities": []}, {"text": "prehensibly describe either of two dogs as the tan one.", "labels": [], "entities": []}, {"text": "Systems that robustly understand or generate descriptions of colors in situated dialogue need models of meaning that capture this variability.", "labels": [], "entities": []}, {"text": "This paper makes two key contributions towards this challenge.", "labels": [], "entities": []}, {"text": "First, we present a methodology to infer a corpus-based model of meaning that accounts for possible differences in word usage across different speakers.", "labels": [], "entities": []}, {"text": "As we explain in Section 2, our approach differs from the typical perspective in grounded semantics (, where a meaning is reduced to a single classifier that collapses patterns of variation.", "labels": [], "entities": []}, {"text": "Instead, our model allows for variability in meaning by positing uncertainty in classification boundaries that can get resolved when a speaker chooses to use a word on a specific occasion.", "labels": [], "entities": []}, {"text": "We explain the model and its theoretical rationale in Section 3.", "labels": [], "entities": []}, {"text": "Second, we develop and release a Lexicon of Uncertain Color Standards (LUX) by applying our methodology to color descriptions.", "labels": [], "entities": []}, {"text": "LUX is an interpretation of 829 distinct English color descriptions as distributions over regions of the Hue-SaturationValue color space that describe their possible meanings.", "labels": [], "entities": []}, {"text": "As we describe in Section 4, the model is trained by machine learning methods from a subset of Randall Munroe's 2010 publicly-available corpus of 3.4 million crowdsourced free-text descriptions of color patches.", "labels": [], "entities": []}, {"text": "Data, models and visualization software are available at http: //mcmahan.io/lux/.", "labels": [], "entities": []}, {"text": "Statistical evaluation of our model against two alternative approaches documents its effectiveness.", "labels": [], "entities": []}, {"text": "The model makes better quantitative predictions than a brute-force memorization model; it seems to generalize to unseen data in more meaningful ways.", "labels": [], "entities": []}, {"text": "At the same time, our meanings work as well as special-purpose models to explain speaker choice, even though our model supports diverse other reasoning.", "labels": [], "entities": []}, {"text": "We see color as the first of many applications of our methodology, and are optimistic about learning vague meanings for other continuous domains as quantity, space, and time.", "labels": [], "entities": []}, {"text": "At the same time, the methodology opens up new prospects for research on negotiating meaning interactively) with principled representations and with broad coverage.", "labels": [], "entities": []}, {"text": "In fact, many practical situated dialogue systems already identify unfamiliar objects by color.", "labels": [], "entities": []}, {"text": "We expect that LUX will provide a broadly useful resource to extend the range of descriptions such systems can generate and understand.", "labels": [], "entities": []}], "datasetContent": [{"text": "We worked with Randall Munroe's crowdsourced corpus of color judgments, and fit the model using the Metropolis-Hastings Markov Chain Monte Carlo, a Gaussian random walk optimization method.", "labels": [], "entities": []}, {"text": "This form of approximate Bayesian inference is described in Section 4.2.", "labels": [], "entities": []}, {"text": "LUX explains Munroe's data via speakers' rational use of probabilistic meanings, represented as simple \"blurry boxes\".", "labels": [], "entities": [{"text": "LUX", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.9273980259895325}]}, {"text": "In this section, we assess the effectiveness of this explanation.", "labels": [], "entities": []}, {"text": "We anticipate two arguments against our model: first, that the representation is too simple; second, that factoring speakers' choices through a model of meaning is too cumbersome.", "labels": [], "entities": []}, {"text": "We rebut these arguments by providing metrics and results that suggest that LUX escapes these objections and captures almost all of the structure in subjects' responses.", "labels": [], "entities": []}, {"text": "We evaluate the models using two classes of metrics on a held-out test set consisting of 25% of the corpus.", "labels": [], "entities": []}, {"text": "The first type is based upon the posterior distribution over labels and the ranked position of subjects' actual labels of color values.", "labels": [], "entities": []}, {"text": "The second type is based upon the log likelihood of the models, which quantifies model fit.", "labels": [], "entities": []}, {"text": "Our analysis of patterns of error in LUX suggests that LUX would best improved by more faithful models of linguistic meaning, rather than more elaborate models of subjects' choices or more powerful learning methods.", "labels": [], "entities": []}, {"text": "For one thing, neither LUX nor the simple prototype model captures ambiguity, which sometimes arises in Munroe's data.", "labels": [], "entities": []}, {"text": "An example is the color label melon, which has a multimodal distribution in the reddish-orange and green areas of color space shown in-most likely corresponding to people thinking about the distinct colors of the flesh of watermelon, cantaloupe and honeydew.", "labels": [], "entities": []}, {"text": "Interestingly, our model captures the more common usage.", "labels": [], "entities": []}, {"text": "A different modeling challenge is illustrated by the behavior of greenish in.", "labels": [], "entities": []}, {"text": "Greenish seems to bean exception to the general assumption that color terms label convex categories.", "labels": [], "entities": []}, {"text": "Actually, greenish seems to fit the boundary of green-the areas that are not definitely green but not definitely not green.", "labels": [], "entities": []}, {"text": "(Linguists often appeal to such concepts in the literature on vagueness.)", "labels": [], "entities": []}, {"text": "This is not a convex area so, not surprisingly, our model finds a poor match.", "labels": [], "entities": []}, {"text": "Additional research is needed to understand when it's appropriate to give meanings more complex representations and how they can be learned.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Decision-based results. The percentage of cor- rect responses of 544,764 test-set data points are shown.", "labels": [], "entities": []}, {"text": " Table 2: Likelihood-based evaluation results: negative  log likelihood of the data, negative log likelihood of  labels given points, number of parameters, Akaike In- formation Criterion and perplexity of labels given color  values. Parameter counts for AIC are 15751 for LUX,  315669 for HM and 5803 for GM.", "labels": [], "entities": [{"text": "Akaike In- formation Criterion", "start_pos": 156, "end_pos": 186, "type": "METRIC", "confidence": 0.932337486743927}, {"text": "Parameter counts", "start_pos": 233, "end_pos": 249, "type": "METRIC", "confidence": 0.9730020761489868}, {"text": "GM", "start_pos": 305, "end_pos": 307, "type": "DATASET", "confidence": 0.9684903025627136}]}]}