{"title": [{"text": "Exploiting Parallel News Streams for Unsupervised Event Extraction", "labels": [], "entities": [{"text": "Unsupervised Event Extraction", "start_pos": 37, "end_pos": 66, "type": "TASK", "confidence": 0.6960273782412211}]}], "abstractContent": [{"text": "Most approaches to relation extraction, the task of extracting ground facts from natural language text, are based on machine learning and thus starved by scarce training data.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 19, "end_pos": 38, "type": "TASK", "confidence": 0.9797077476978302}]}, {"text": "Manual annotation is too expensive to scale to a comprehensive set of relations.", "labels": [], "entities": []}, {"text": "Distant supervision , which automatically creates training data, only works with relations that already populate a knowledge base (KB).", "labels": [], "entities": []}, {"text": "Unfortunately , KBs such as FreeBase rarely cover event relations (e.g. \"person travels to loca-tion\").", "labels": [], "entities": []}, {"text": "Thus, the problem of extracting a wide range of events-e.g., from news streams-is an important, open challenge.", "labels": [], "entities": [{"text": "extracting a wide range of events-e.g., from news streams-is", "start_pos": 21, "end_pos": 81, "type": "TASK", "confidence": 0.7272009193897248}]}, {"text": "This paper introduces NEWSSPIKE-RE, a novel, unsupervised algorithm that discovers event relations and then learns to extract them.", "labels": [], "entities": []}, {"text": "NEWSSPIKE-RE uses a novel probabilistic graphical model to cluster sentences describing similar events from parallel news streams.", "labels": [], "entities": [{"text": "NEWSSPIKE-RE", "start_pos": 0, "end_pos": 12, "type": "DATASET", "confidence": 0.9554674029350281}]}, {"text": "These clusters then comprise training data for the extractor.", "labels": [], "entities": []}, {"text": "Our evaluation shows that NEWSSPIKE-RE generates high quality training sentences and learns extractors that perform much better than rival approaches, more than doubling the area under a precision-recall curve compared to Universal Schemas.", "labels": [], "entities": [{"text": "precision-recall", "start_pos": 187, "end_pos": 203, "type": "METRIC", "confidence": 0.9838786125183105}]}], "introductionContent": [{"text": "Relation extraction, the process of extracting structured information from natural language text, grows increasingly important for Web search and question answering.", "labels": [], "entities": [{"text": "Relation extraction", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.9138005673885345}, {"text": "Web search", "start_pos": 131, "end_pos": 141, "type": "TASK", "confidence": 0.7788328230381012}, {"text": "question answering", "start_pos": 146, "end_pos": 164, "type": "TASK", "confidence": 0.9184486865997314}]}, {"text": "Traditional supervised approaches, which can achieve high precision and recall, are limited by the cost of labeling training data and are unlikely to scale to the thousands of relations on the Web.", "labels": [], "entities": [{"text": "precision", "start_pos": 58, "end_pos": 67, "type": "METRIC", "confidence": 0.9972196817398071}, {"text": "recall", "start_pos": 72, "end_pos": 78, "type": "METRIC", "confidence": 0.9986465573310852}]}, {"text": "Another approach, distant supervision, creates its own training data by matching the ground instances of a Knowledge base (KB) (e.g. Freebase) to the unlabeled text.", "labels": [], "entities": []}, {"text": "Unfortunately, while distant supervision can work well in some situations, the method is limited to relatively static facts (e.g., born-in(person, location) or capital-of(location,location)) where there is a corresponding knowledge base.", "labels": [], "entities": []}, {"text": "But what about dynamic event relations (also known as fluents), such as travel-to(person, location) or fire(organization, person)?", "labels": [], "entities": []}, {"text": "Since these time-dependent facts are ephemeral, they are rarely stored in a pre-existing KB.", "labels": [], "entities": []}, {"text": "At the same time, knowledge of real-time events is crucial for making informed decisions in fields like finance and politics.", "labels": [], "entities": []}, {"text": "Indeed, news stories report events almost exclusively, so learning to extract events is an important open problem.", "labels": [], "entities": []}, {"text": "This paper develops anew unsupervised technique, NEWSSPIKE-RE, to both discover event relations and extract them with high precision.", "labels": [], "entities": [{"text": "NEWSSPIKE-RE", "start_pos": 49, "end_pos": 61, "type": "DATASET", "confidence": 0.49087730050086975}, {"text": "precision", "start_pos": 123, "end_pos": 132, "type": "METRIC", "confidence": 0.9777793884277344}]}, {"text": "The intuition underlying NEWSSPIKE-RE is that the text of articles from two different news sources are not independent, since they are each conditioned on the same real-world events.", "labels": [], "entities": [{"text": "NEWSSPIKE-RE", "start_pos": 25, "end_pos": 37, "type": "DATASET", "confidence": 0.7437163591384888}]}, {"text": "By looking for rarely described entities that suddenly \"spike\" in popularity on a given date, one can identify paraphrases.", "labels": [], "entities": []}, {"text": "Such temporal correspondence allow one to cluster diverse sentences, and the resulting clusters maybe used to form training data in order to learn event extractors.", "labels": [], "entities": [{"text": "event extractors", "start_pos": 147, "end_pos": 163, "type": "TASK", "confidence": 0.6694825738668442}]}, {"text": "Furthermore, one can also exploit parallel news to obtain direct negative evidence.", "labels": [], "entities": []}, {"text": "To see this, suppose one day the news includes the following: (a) \"Snowden travels to Hong Kong, off southeastern China.\"", "labels": [], "entities": []}, {"text": "(b) \"Snowden cannot stay in Hong Kong as Chinese officials will not allow ...\"", "labels": [], "entities": []}, {"text": "Since news stories are usually coherent, it is highly unlikely that travel to and stay in (which is negated) are synonymous.", "labels": [], "entities": []}, {"text": "By leveraging such direct negative phrases, we can learn extractors capable of distinguishing heavily co-occurring but semantically different phrases, thereby avoiding many extraction errors.", "labels": [], "entities": []}, {"text": "Our NEWSSPIKE-RE system encapuslates these intuitions in a novel graphical model making the following contributions: \u2022 We develop a method to discover a set of distinct, salient event relations from news streams.", "labels": [], "entities": []}, {"text": "\u2022 We describe an algorithm to exploit parallel news streams to cluster sentences that belong to the same event relations.", "labels": [], "entities": []}, {"text": "In particular, we propose the temporal negation heuristic to avoid conflating co-occurring but nonsynonymous phrases.", "labels": [], "entities": []}, {"text": "\u2022 We introduce a probabilistic graphical model to generate training fora sentential event extractor without requiring any human annotations.", "labels": [], "entities": [{"text": "sentential event extractor", "start_pos": 73, "end_pos": 99, "type": "TASK", "confidence": 0.6133328080177307}]}, {"text": "\u2022 We present detailed experiments demonstrating that the event extractors, learned from the generated training data, significantly outperform several competitive baselines, e.g. our system more than doubles the area under the micro-averaged, PR curve (0.80 vs. 0.30) compared to Riedel's Universal Schema ().", "labels": [], "entities": [{"text": "event extractors", "start_pos": 57, "end_pos": 73, "type": "TASK", "confidence": 0.6971542239189148}, {"text": "PR curve", "start_pos": 242, "end_pos": 250, "type": "METRIC", "confidence": 0.912816733121872}]}], "datasetContent": [{"text": "Our evaluation addresses two questions.", "labels": [], "entities": []}, {"text": "Section 7.2 considers whether our training generation algorithm identifies accurate and diverse sentences.", "labels": [], "entities": []}, {"text": "Then, Section 7.3 investigates whether the event extractor, learned from the training sentences, outperforms other extraction approaches.", "labels": [], "entities": [{"text": "event extractor", "start_pos": 43, "end_pos": 58, "type": "TASK", "confidence": 0.6638949662446976}]}, {"text": "We follow the procedure described in to collect parallel news streams and generate the NewsSpikes: first, we get news seeds and query the Bing newswire search engine to gather additional, time-stamped, news articles on a similar topic; next, we extract OpenIE tuples from the news articles and group the sentences that share the same arguments and date into NewsSpikes.", "labels": [], "entities": []}, {"text": "We collected the news stream corpus from March 1st 2013 to July 1st 2014.", "labels": [], "entities": [{"text": "news stream corpus from March 1st 2013", "start_pos": 17, "end_pos": 55, "type": "DATASET", "confidence": 0.914524393422263}]}, {"text": "We split the dataset into two parts: in the training phrase, we use the news streams in 2013 (named NS13) to generate the training sentences.", "labels": [], "entities": [{"text": "news streams in 2013 (named NS13)", "start_pos": 72, "end_pos": 105, "type": "DATASET", "confidence": 0.760683573782444}]}, {"text": "NS13 has 33k NewsSpikes containing 173k sentences.", "labels": [], "entities": [{"text": "NS13", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.9790441393852234}]}, {"text": "We evaluated the extraction performance on news articles collected in 2014 (named NS14).", "labels": [], "entities": [{"text": "NS14", "start_pos": 82, "end_pos": 86, "type": "DATASET", "confidence": 0.9219368100166321}]}, {"text": "In this way, we make sure the test sentences are unseen during training.", "labels": [], "entities": []}, {"text": "There are 15 million sentences in NS14.", "labels": [], "entities": [{"text": "NS14", "start_pos": 34, "end_pos": 38, "type": "DATASET", "confidence": 0.977715790271759}]}, {"text": "We randomly sample 100k unique sentences having two different arguments recognized by the name entity recognition system.", "labels": [], "entities": [{"text": "name entity recognition", "start_pos": 90, "end_pos": 113, "type": "TASK", "confidence": 0.6252878208955129}]}, {"text": "For our event discovery algorithm, we set the number of event relations to be 30 and ran the algorithm on NS13.", "labels": [], "entities": [{"text": "event discovery", "start_pos": 8, "end_pos": 23, "type": "TASK", "confidence": 0.8695822656154633}, {"text": "NS13", "start_pos": 106, "end_pos": 110, "type": "DATASET", "confidence": 0.9870882034301758}]}, {"text": "The algorithm takes 6 seconds to run on a 2.3GHz CPU.", "labels": [], "entities": []}, {"text": "Note that most previous unsupervised relation discovery algorithms require additional manual post-processing to assign names to the output clusters.", "labels": [], "entities": [{"text": "relation discovery", "start_pos": 37, "end_pos": 55, "type": "TASK", "confidence": 0.7553080916404724}]}, {"text": "In contrast, NEWSSPIKE-RE discovers the event relations fully automatically and the output is self-explanatory.", "labels": [], "entities": []}, {"text": "We list them together with the by-event extraction performance in.", "labels": [], "entities": [{"text": "by-event extraction", "start_pos": 31, "end_pos": 50, "type": "TASK", "confidence": 0.6497181206941605}]}, {"text": "From the table, we can see that most of the discovered event relations are salient with little overlap between relations.", "labels": [], "entities": []}, {"text": "While we arbitrarily set K to 30 in our experiments, there is no inherent limit to the number of relation phrases as long as the news corpus provides sufficient support to learn an extractor for each relation.", "labels": [], "entities": []}, {"text": "In future, we plan to explore much larger sets of event relations to see if the extraction accuracy is maintained.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 91, "end_pos": 99, "type": "METRIC", "confidence": 0.9834317564964294}]}, {"text": "The joint cluster model that identifies training sentences for each event relation E = e(t 1 , t 2 ) uses cosine similarity between the event phrase p of a sentence and the canonical phrases of each relation as features in the phrase factors in.", "labels": [], "entities": []}, {"text": "It also includes the cosine similarity between p and a set of \"anti-phrases\" for the event relation which are recognized by the temporal negation heuristic.", "labels": [], "entities": []}, {"text": "For the in-spike factor, we measure whether the fine-grained argument types of the sentence returned from the FIGER system matches the required ti respectively.", "labels": [], "entities": [{"text": "FIGER system", "start_pos": 110, "end_pos": 122, "type": "DATASET", "confidence": 0.6621599346399307}]}, {"text": "In addition, we implement the features from) to measure whether the sentence is describing the event of the NewsSpike.", "labels": [], "entities": [{"text": "NewsSpike", "start_pos": 108, "end_pos": 117, "type": "DATASET", "confidence": 0.9607767462730408}]}, {"text": "For the cross-spike factors, we use textual similarity features between the two sets of parallel sentences to measure the distance between the pair of NewsSpikes.", "labels": [], "entities": [{"text": "NewsSpikes", "start_pos": 151, "end_pos": 161, "type": "DATASET", "confidence": 0.944112241268158}]}], "tableCaptions": [{"text": " Table 1: Quality of the generated training sentences  (count, micro-and macro-accuracy), where \"all\" in- cludes sentences with all event phrases and \"diverse\" are  those with distinct event phrases.", "labels": [], "entities": [{"text": "count", "start_pos": 56, "end_pos": 61, "type": "METRIC", "confidence": 0.9852054715156555}]}, {"text": " Table 2: Performance of extractors by event relation, reporting both precision and the area under the PR curve. The  # column shows the number of true extractions in the pool of sampled output. NEWSSPIKE-RE (labeled N-RE)  outperforms two implementations of Riedel's Universal Schemas (See Section 7.3 for details). The advantage of  NEWSSPIKE-RE over Universal Schemas is greatest on a diverse test set where each sentence has a distinct event  phrase.", "labels": [], "entities": [{"text": "precision", "start_pos": 70, "end_pos": 79, "type": "METRIC", "confidence": 0.9992734789848328}]}]}