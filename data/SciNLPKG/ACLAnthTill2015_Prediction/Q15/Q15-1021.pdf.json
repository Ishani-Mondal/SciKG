{"title": [{"text": "Problems in Current Text Simplification Research: New Data Can Help", "labels": [], "entities": [{"text": "Current Text Simplification Research", "start_pos": 12, "end_pos": 48, "type": "TASK", "confidence": 0.7625141441822052}]}], "abstractContent": [{"text": "Simple Wikipedia has dominated simplification research in the past 5 years.", "labels": [], "entities": []}, {"text": "In this opinion paper, we argue that focusing on Wikipedia limits simplification research.", "labels": [], "entities": []}, {"text": "We backup our arguments with corpus analysis and by highlighting statements that other researchers have made in the simplification literature.", "labels": [], "entities": []}, {"text": "We introduce anew simplification dataset that is a significant improvement over Simple Wikipedia, and present a novel quantitative-comparative approach to study the quality of simplification data resources.", "labels": [], "entities": []}], "introductionContent": [{"text": "The goal of text simplification is to rewrite complex text into simpler language that is easier to understand.", "labels": [], "entities": [{"text": "text simplification", "start_pos": 12, "end_pos": 31, "type": "TASK", "confidence": 0.7550333738327026}]}, {"text": "Research into this topic has many potential practical applications.", "labels": [], "entities": []}, {"text": "For instance, it can provide reading aids for people with disabilities, low-literacy (, non-native backgrounds) or non-expert knowledge.", "labels": [], "entities": []}, {"text": "Text simplification may also help improve the performance of many natural language processing (NLP) tasks, such as parsing), summarization, semantic role labeling, information extraction ( and machine translation (, by transforming long, complex sentences into ones that are more easily processed.", "labels": [], "entities": [{"text": "parsing", "start_pos": 115, "end_pos": 122, "type": "TASK", "confidence": 0.979876697063446}, {"text": "summarization", "start_pos": 125, "end_pos": 138, "type": "TASK", "confidence": 0.9923452734947205}, {"text": "semantic role labeling", "start_pos": 140, "end_pos": 162, "type": "TASK", "confidence": 0.6380782624085745}, {"text": "information extraction", "start_pos": 164, "end_pos": 186, "type": "TASK", "confidence": 0.8736995160579681}, {"text": "machine translation", "start_pos": 193, "end_pos": 212, "type": "TASK", "confidence": 0.7816378474235535}]}, {"text": "The Parallel Wikipedia Simplification (PWKP) corpus prepared by, has become the benchmark dataset for training and evaluating automatic text simplification systems.", "labels": [], "entities": [{"text": "Parallel Wikipedia Simplification (PWKP)", "start_pos": 4, "end_pos": 44, "type": "TASK", "confidence": 0.7354119420051575}]}, {"text": "An associated test set of 100 sentences from Wikipedia has been used for comparing the state-of-the-art approaches.", "labels": [], "entities": []}, {"text": "The collection of simple-complex parallel sentences sparked a major advance for machine translationbased approaches to simplification.", "labels": [], "entities": [{"text": "machine translationbased", "start_pos": 80, "end_pos": 104, "type": "TASK", "confidence": 0.6819700598716736}]}, {"text": "However, we will show that this dataset is deficient and should be considered obsolete.", "labels": [], "entities": []}, {"text": "In this opinion paper, we argue that Wikipedia as a simplification data resource is suboptimal for several reasons: 1) It is prone to automatic sentence alignment errors; 2) It contains a large proportion of inadequate simplifications; 3) It generalizes poorly to other text genres.", "labels": [], "entities": [{"text": "sentence alignment", "start_pos": 144, "end_pos": 162, "type": "TASK", "confidence": 0.7136895209550858}]}, {"text": "These problems are largely due to the fact that Simple Wikipedia is an encyclopedia spontaneously and collaboratively created for \"children and adults who are learning English language\" without more specific guidelines.", "labels": [], "entities": []}, {"text": "We quantitatively illustrate the seriousness of these problems through manual inspection and statistical analysis.", "labels": [], "entities": []}, {"text": "Our manual inspection reveals that about 50% of the sentence pairs in the PWKP corpus are not simplifications.", "labels": [], "entities": [{"text": "PWKP corpus", "start_pos": 74, "end_pos": 85, "type": "DATASET", "confidence": 0.9528429806232452}]}, {"text": "We also introduce anew comparative approach to simplification corpus analysis.", "labels": [], "entities": [{"text": "simplification corpus analysis", "start_pos": 47, "end_pos": 77, "type": "TASK", "confidence": 0.8713188568751017}]}, {"text": "In particular, we assemble anew simplification corpus of news articles, 1 re-written by professional editors to meet the readability standards for children at multi-Not Aligned (17%) [NORM] The soprano ranges are also written from middle C to A an octave higher, but sound one octave higher than written.", "labels": [], "entities": [{"text": "NORM", "start_pos": 184, "end_pos": 188, "type": "METRIC", "confidence": 0.7367953062057495}]}, {"text": "[SIMP] The xylophone is usually played so that the music sounds an octave higher than written.", "labels": [], "entities": []}], "datasetContent": [{"text": "With the popularity of parallel Wikipedia data in simplification research, most state-of-the-art systems evaluate on simplifying sentences from Wikipedia.", "labels": [], "entities": []}, {"text": "All simplification systems published in the ACL, NAACL, EACL, COLING and EMNLP main conferences since Zhu's 2010 work compared solely on the same test set that consists of only 100 sentences from Wikipedia, except one paper that additionally experimented with 5 short news summaries.", "labels": [], "entities": [{"text": "NAACL", "start_pos": 49, "end_pos": 54, "type": "DATASET", "confidence": 0.7939072251319885}, {"text": "EACL", "start_pos": 56, "end_pos": 60, "type": "METRIC", "confidence": 0.5198211669921875}]}, {"text": "The most widely practiced evaluation methodology is to have human judges rate on grammaticality (or fluency), simplicity, and adequacy (or meaning preservation) on a 5-point Likert scale.", "labels": [], "entities": [{"text": "simplicity", "start_pos": 110, "end_pos": 120, "type": "METRIC", "confidence": 0.9985679388046265}, {"text": "meaning preservation", "start_pos": 139, "end_pos": 159, "type": "TASK", "confidence": 0.6366278976202011}]}, {"text": "Such evaluation is insufficient to measure 1) the practical value of a system to a specific target reader population and 2) the performance of individual simplification components: sentence splitting, deletion and paraphrasing.", "labels": [], "entities": [{"text": "sentence splitting", "start_pos": 181, "end_pos": 199, "type": "TASK", "confidence": 0.7630896866321564}]}, {"text": "Although the inadequacy of text simplification evaluations has been discussed before, we focus on these two common deficiencies and suggest two future directions.", "labels": [], "entities": [{"text": "text simplification evaluations", "start_pos": 27, "end_pos": 58, "type": "TASK", "confidence": 0.8174346884091696}]}], "tableCaptions": [{"text": " Table 2:  The vocabulary size of the Parallel  Wikipedia Simplification (PWKP) corpus and the  vocabulary difference between its normal and sim- ple sides (as a 2\u00d72 matrix). Only words consisting  of the 26 English letters are counted.", "labels": [], "entities": [{"text": "Parallel  Wikipedia Simplification (PWKP)", "start_pos": 38, "end_pos": 79, "type": "TASK", "confidence": 0.6813168972730637}]}, {"text": " Table 3: Example of sentences written at multiple levels of text complexity from the Newsela data set. The  Lexile readability score and grade level apply to the whole article rather than individual sentences, so the  same sentences may receive different scores, e.g. the above sentences for the 6th and 7th grades. The bold  font highlights the parts of sentence that are different from the adjacent version(s).", "labels": [], "entities": [{"text": "Newsela data set", "start_pos": 86, "end_pos": 102, "type": "DATASET", "confidence": 0.9928368926048279}]}, {"text": " Table 5: This table shows the vocabulary changes between different levels of simplification in the Newsela  corpus (as a 5\u00d75 matrix). Each cell shows the number of unique word types that appear in the corpus listed  in the column but do not appear in the corpus listed in the row. We also list the average frequency of those  vocabulary items. For example, in the cell marked *, the Simp-4 version contains 583 unique words that  do not appear in the Original version. By comparing the cells marked **, we see about half of the words  (19,197 out of 39,046) in the Original version are not in the Simp-4 version. Most of the vocabulary that is  removed consists of low-frequency words (with an average frequency of 2.6 in the Original).", "labels": [], "entities": [{"text": "Newsela  corpus", "start_pos": 100, "end_pos": 115, "type": "DATASET", "confidence": 0.9629007279872894}]}, {"text": " Table 7: Top 50 tokens associated with the simplified text.", "labels": [], "entities": []}, {"text": " Table 8: Frequency of example words from Table 6. These complex words are reduced at a much greater  rate in the simplified Newsela than they are in the Simple English Wikipedia. A smaller odds ratio indicates  greater reduction.", "labels": [], "entities": [{"text": "Frequency", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9513428211212158}, {"text": "Newsela", "start_pos": 125, "end_pos": 132, "type": "DATASET", "confidence": 0.7678112983703613}, {"text": "Simple English Wikipedia", "start_pos": 154, "end_pos": 178, "type": "DATASET", "confidence": 0.7856068015098572}]}]}