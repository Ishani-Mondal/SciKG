{"title": [{"text": "An Empirical Study of Semi-supervised Structured Conditional Models for Dependency Parsing", "labels": [], "entities": [{"text": "Dependency Parsing", "start_pos": 72, "end_pos": 90, "type": "TASK", "confidence": 0.6762974411249161}]}], "abstractContent": [{"text": "This paper describes an empirical study of high-performance dependency parsers based on a semi-supervised learning approach.", "labels": [], "entities": []}, {"text": "We describe an extension of semi-supervised structured conditional models (SS-SCMs) to the dependency parsing problem, whose framework is originally proposed in (Suzuki and Isozaki, 2008).", "labels": [], "entities": [{"text": "dependency parsing problem", "start_pos": 91, "end_pos": 117, "type": "TASK", "confidence": 0.8539427916208903}]}, {"text": "Moreover, we introduce two extensions related to dependency parsing: The first extension is to combine SS-SCMs with another semi-supervised approach, described in (Koo et al., 2008).", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 49, "end_pos": 67, "type": "TASK", "confidence": 0.8380679786205292}]}, {"text": "The second extension is to apply the approach to second-order parsing models, such as those described in (Carreras, 2007), using a two-stage semi-supervised learning approach.", "labels": [], "entities": []}, {"text": "We demonstrate the effectiveness of our proposed methods on dependency parsing experiments using two widely used test collections: the Penn Treebank for En-glish, and the Prague Dependency Tree-bank for Czech.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 60, "end_pos": 78, "type": "TASK", "confidence": 0.8357709050178528}, {"text": "Penn Treebank", "start_pos": 135, "end_pos": 148, "type": "DATASET", "confidence": 0.9928244054317474}, {"text": "Prague Dependency Tree-bank", "start_pos": 171, "end_pos": 198, "type": "DATASET", "confidence": 0.9341349601745605}]}, {"text": "Our best results on test data in the above datasets achieve 93.79% parent-prediction accuracy for En-glish, and 88.05% for Czech.", "labels": [], "entities": [{"text": "parent-prediction", "start_pos": 67, "end_pos": 84, "type": "METRIC", "confidence": 0.9720227718353271}, {"text": "accuracy", "start_pos": 85, "end_pos": 93, "type": "METRIC", "confidence": 0.7363169193267822}]}], "introductionContent": [{"text": "Recent work has successfully developed dependency parsing models for many languages using supervised learning algorithms.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 39, "end_pos": 57, "type": "TASK", "confidence": 0.8326538801193237}]}, {"text": "Semi-supervised learning methods, which make use of unlabeled data in addition to labeled examples, have the potential to give improved performance over purely supervised methods for dependency parsing.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 183, "end_pos": 201, "type": "TASK", "confidence": 0.8353841006755829}]}, {"text": "It is often straightforward to obtain large amounts of unlabeled data, making semi-supervised approaches appealing; previous work on semisupervised methods for dependency parsing includes ().", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 160, "end_pos": 178, "type": "TASK", "confidence": 0.8099840879440308}]}, {"text": "In particular, describe a semi-supervised approach that makes use of cluster features induced from unlabeled data, and gives state-of-the-art results on the widely used dependency parsing test collections: the Penn Treebank (PTB) for English and the Prague Dependency Treebank (PDT) for Czech.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 169, "end_pos": 187, "type": "TASK", "confidence": 0.7534463405609131}, {"text": "Penn Treebank (PTB)", "start_pos": 210, "end_pos": 229, "type": "DATASET", "confidence": 0.9627484560012818}, {"text": "Prague Dependency Treebank (PDT)", "start_pos": 250, "end_pos": 282, "type": "DATASET", "confidence": 0.8913415173689524}]}, {"text": "This is a very simple approach, but provided significant performance improvements comparing with the stateof-the-art supervised dependency parsers such as ).", "labels": [], "entities": []}, {"text": "This paper introduces an alternative method for semi-supervised learning for dependency parsing.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 77, "end_pos": 95, "type": "TASK", "confidence": 0.84733846783638}]}, {"text": "Our approach basically follows a framework proposed in.", "labels": [], "entities": []}, {"text": "We extend it for dependency parsing, which we will refer to as a Semi-supervised Structured Conditional Model (SS-SCM).", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 17, "end_pos": 35, "type": "TASK", "confidence": 0.8688565194606781}]}, {"text": "In this framework, a structured conditional model is constructed by incorporating a series of generative models, whose parameters are estimated from unlabeled data.", "labels": [], "entities": []}, {"text": "This paper describes a basic method for learning within this approach, and in addition describes two extensions.", "labels": [], "entities": []}, {"text": "The first extension is to combine our method with the cluster-based semi-supervised method of (.", "labels": [], "entities": []}, {"text": "The second extension is to apply the approach to second-order parsing models, more specifically the model of, using a two-stage semi-supervised learning approach.", "labels": [], "entities": []}, {"text": "We conduct experiments on dependency parsing of English (on Penn Treebank data) and Czech (on the Prague Dependency Treebank).", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 26, "end_pos": 44, "type": "TASK", "confidence": 0.7735658288002014}, {"text": "Penn Treebank data", "start_pos": 60, "end_pos": 78, "type": "DATASET", "confidence": 0.9956915974617004}, {"text": "Prague Dependency Treebank)", "start_pos": 98, "end_pos": 125, "type": "DATASET", "confidence": 0.9600556939840317}]}, {"text": "Our experiments investigate the effectiveness of: 1) the basic SS-SCM for dependency parsing; 2) a combination of the SS-SCM with's semisupervised approach (even in the case we used the same unlabeled data for both methods); 3) the twostage semi-supervised learning approach that in-corporates a second-order parsing model.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 74, "end_pos": 92, "type": "TASK", "confidence": 0.8161558210849762}]}, {"text": "In addition, we evaluate the SS-SCM for English dependency parsing with large amounts (up to 3.72 billion tokens) of unlabeled data .", "labels": [], "entities": [{"text": "English dependency parsing", "start_pos": 40, "end_pos": 66, "type": "TASK", "confidence": 0.5755769908428192}]}], "datasetContent": [{"text": "We now describe experiments investigating the effectiveness of the SS-SCM approach for dependency parsing.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 87, "end_pos": 105, "type": "TASK", "confidence": 0.8732421696186066}]}, {"text": "The experiments test basic, firstorder parsing models, as well as the extensions to cluster-based features and second-order parsing models described in the previous section.", "labels": [], "entities": []}, {"text": "All results presented in our experiments are given in terms of parent-prediction accuracy on unla-beled dependency parsing.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 81, "end_pos": 89, "type": "METRIC", "confidence": 0.7923084497451782}, {"text": "dependency parsing", "start_pos": 104, "end_pos": 122, "type": "TASK", "confidence": 0.6878770291805267}]}, {"text": "We ignore the parentpredictions of punctuation tokens for English, while we retain all the punctuation tokens for Czech.", "labels": [], "entities": [{"text": "parentpredictions", "start_pos": 14, "end_pos": 31, "type": "METRIC", "confidence": 0.9395034313201904}]}, {"text": "These settings match the evaluation setting in previous work such as.", "labels": [], "entities": []}, {"text": "We used the method proposed by for our second-order parsing model.", "labels": [], "entities": []}, {"text": "Since this method only considers projective dependency structures, we \"projectivized\" the PDT training data in the same way as (.", "labels": [], "entities": [{"text": "PDT training data", "start_pos": 90, "end_pos": 107, "type": "DATASET", "confidence": 0.6394829352696737}]}, {"text": "We used a non-projective model, trained using an application of the matrix-tree theorem () for the first-order Czech models, and projective parsers for all other models.", "labels": [], "entities": []}, {"text": "As shown in Section 2, SS-SCMs with 1st-order parsing models have two tunable parameters, C and \u03b7, corresponding to the regularization constant, and the Dirichlet prior for the generative models.", "labels": [], "entities": []}, {"text": "We selected a fixed value \u03b7 = 2, which was found to work well in preliminary experiments.", "labels": [], "entities": []}, {"text": "The value of C was chosen to optimize performance on development data.", "labels": [], "entities": []}, {"text": "Note that C for supervised SCMs were also tuned on development data.", "labels": [], "entities": [{"text": "SCMs", "start_pos": 27, "end_pos": 31, "type": "TASK", "confidence": 0.9074050784111023}]}, {"text": "For the two-stage SS-SCM for incorporating second-order parsing model, we have additional one tunable parameter B shown in Eq.", "labels": [], "entities": []}, {"text": "8. This was also chosen by the value that provided the best performance on development data.", "labels": [], "entities": []}, {"text": "In addition to providing results for models trained on the full training sets, we also performed experiments with smaller labeled training sets.", "labels": [], "entities": []}, {"text": "These training sets were either created through random sampling or by using a predefined subset of document IDs from the labeled training data.", "labels": [], "entities": []}, {"text": "gives results for the SS-SCM method under various configurations: for first and secondorder parsing models, with and without the cluster features of (, and for varying amounts of labeled data.", "labels": [], "entities": []}, {"text": "The remainder of this section discusses these results in more detail.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Details of training, development, test data  (labeled data sets) and unlabeled data used in our  experiments", "labels": [], "entities": []}, {"text": " Table 3: Dependency parsing results for the SS-SCM method with different amounts of labeled training  data. Supervised SCM (1od) and Supervised MIRA (2od) are the baseline first and second-order ap- proaches; SS-SCM (1od) and 2-stage SS-SCM(+MIRA) (2od) are the first and second-order approaches  described in this paper. \"Baseline\" refers to models without cluster-based features, \"CL\" refers to models  which make use of cluster-based features.", "labels": [], "entities": [{"text": "Dependency parsing", "start_pos": 10, "end_pos": 28, "type": "TASK", "confidence": 0.8365749716758728}, {"text": "MIRA", "start_pos": 145, "end_pos": 149, "type": "METRIC", "confidence": 0.8431441187858582}]}, {"text": " Table 4: Parent-prediction accuracies on develop- ment data with 3.72G tokens unlabeled data for  English dependency parsing.", "labels": [], "entities": [{"text": "English dependency parsing", "start_pos": 99, "end_pos": 125, "type": "TASK", "confidence": 0.5563160677750906}]}, {"text": " Table 5: Parent-prediction accuracies on test data  using the best setting in terms of development data  performances in each condition.", "labels": [], "entities": []}, {"text": " Table 6: Comparisons with the previous top sys- tems: (1od, 2od: 1st-and 2nd-order parsing  model, ULD: unlabeled data).", "labels": [], "entities": []}]}