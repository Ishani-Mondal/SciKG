{"title": [{"text": "Effective Use of Linguistic and Contextual Information for Statistical Machine Translation", "labels": [], "entities": [{"text": "Statistical Machine Translation", "start_pos": 59, "end_pos": 90, "type": "TASK", "confidence": 0.874035656452179}]}], "abstractContent": [{"text": "Current methods of using lexical features in machine translation have difficulty in scaling up to realistic MT tasks due to a prohibitively large number of parameters involved.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 45, "end_pos": 64, "type": "TASK", "confidence": 0.7612667083740234}, {"text": "MT tasks", "start_pos": 108, "end_pos": 116, "type": "TASK", "confidence": 0.9249802529811859}]}, {"text": "In this paper, we propose methods of using new linguistic and con-textual features that do not suffer from this problem and apply them in a state-of-the-art hierarchical MT system.", "labels": [], "entities": [{"text": "MT", "start_pos": 170, "end_pos": 172, "type": "TASK", "confidence": 0.9722736477851868}]}, {"text": "The features used in this work are non-terminal labels, non-terminal length distribution, source string context and source dependency LM scores.", "labels": [], "entities": []}, {"text": "The effectiveness of our techniques is demonstrated by significant improvements over a strong base-line.", "labels": [], "entities": []}, {"text": "On Arabic-to-English translation, improvements in lower-cased BLEU are 2.0 on NIST MT06 and 1.7 on MT08 newswire data on decoding output.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 62, "end_pos": 66, "type": "METRIC", "confidence": 0.9971877932548523}, {"text": "NIST", "start_pos": 78, "end_pos": 82, "type": "DATASET", "confidence": 0.9515562653541565}, {"text": "MT06", "start_pos": 83, "end_pos": 87, "type": "DATASET", "confidence": 0.556962251663208}, {"text": "MT08 newswire data", "start_pos": 99, "end_pos": 117, "type": "DATASET", "confidence": 0.9283439119656881}]}, {"text": "On Chinese-to-English translation, the improvements are 1.0 on MT06 and 0.8 on MT08 newswire data.", "labels": [], "entities": [{"text": "Chinese-to-English translation", "start_pos": 3, "end_pos": 33, "type": "TASK", "confidence": 0.5642878860235214}, {"text": "MT06", "start_pos": 63, "end_pos": 67, "type": "DATASET", "confidence": 0.9645707011222839}, {"text": "MT08 newswire data", "start_pos": 79, "end_pos": 97, "type": "DATASET", "confidence": 0.9718372424443563}]}], "introductionContent": [{"text": "Linguistic and context features, especially sparse lexical features, have been widely used in recent machine translation (MT) research.", "labels": [], "entities": [{"text": "machine translation (MT)", "start_pos": 101, "end_pos": 125, "type": "TASK", "confidence": 0.8420305371284484}]}, {"text": "Unfortunately, existing methods of using such features are not ideal for large-scale, practical translation tasks.", "labels": [], "entities": [{"text": "translation tasks", "start_pos": 96, "end_pos": 113, "type": "TASK", "confidence": 0.9015878438949585}]}, {"text": "In this paper, we will propose several probabilistic models to effectively exploit linguistic and contextual information for MT decoding, and these new features do not suffer from the scalability problem.", "labels": [], "entities": [{"text": "MT decoding", "start_pos": 125, "end_pos": 136, "type": "TASK", "confidence": 0.96668541431427}]}, {"text": "Our new models are tested on NIST MT06 and MT08 data, and they provide significant improvement over a strong baseline system.", "labels": [], "entities": [{"text": "NIST", "start_pos": 29, "end_pos": 33, "type": "DATASET", "confidence": 0.9698696136474609}, {"text": "MT06", "start_pos": 34, "end_pos": 38, "type": "DATASET", "confidence": 0.5847823619842529}, {"text": "MT08 data", "start_pos": 43, "end_pos": 52, "type": "DATASET", "confidence": 0.944057285785675}]}], "datasetContent": [{"text": "Setup We take BBN's HierDec, a string-to-dependency decoder as described in), as our baseline for the following two reasons: \u2022 It provides a strong baseline, which ensures the validity of the improvement we would obtain.", "labels": [], "entities": [{"text": "BBN's HierDec", "start_pos": 14, "end_pos": 27, "type": "DATASET", "confidence": 0.8778229753176371}, {"text": "validity", "start_pos": 176, "end_pos": 184, "type": "METRIC", "confidence": 0.9831425547599792}]}, {"text": "The baseline model used in this paper showed state-of-the-art performance at NIST 2008 MT evaluation.", "labels": [], "entities": [{"text": "NIST 2008 MT evaluation", "start_pos": 77, "end_pos": 100, "type": "DATASET", "confidence": 0.8751868158578873}]}, {"text": "\u2022 The baseline algorithm can be easily extended to incorporate the features proposed in this paper.", "labels": [], "entities": []}, {"text": "The use of source dependency structures is a natural extension of the stringto-tree model to a tree-to-tree model.", "labels": [], "entities": []}, {"text": "To ensure the generality of our results, we tested the features on two rather different language pairs, Arabic-to-English and Chinese-to-English, using two metrics, IBM BLEU () and TER ().", "labels": [], "entities": [{"text": "IBM", "start_pos": 165, "end_pos": 168, "type": "METRIC", "confidence": 0.7068948149681091}, {"text": "BLEU", "start_pos": 169, "end_pos": 173, "type": "METRIC", "confidence": 0.8413161635398865}, {"text": "TER", "start_pos": 181, "end_pos": 184, "type": "METRIC", "confidence": 0.9896500110626221}]}, {"text": "Our experiments show that each of the first three features: nonterminal labels, length distribution and source side context, improves MT performance.", "labels": [], "entities": [{"text": "MT", "start_pos": 134, "end_pos": 136, "type": "TASK", "confidence": 0.9950500130653381}]}, {"text": "Surprisingly, the source dependency feature does not produce an improvement.", "labels": [], "entities": []}, {"text": "We designed our experiments to show the impact of each feature separately as well as their cumulative impact: \u2022 BASE: baseline string-to-dependency system on n-best translations, but evaluated on both IBM BLEU and TER.", "labels": [], "entities": [{"text": "BASE", "start_pos": 112, "end_pos": 116, "type": "METRIC", "confidence": 0.9978417158126831}, {"text": "IBM", "start_pos": 201, "end_pos": 204, "type": "DATASET", "confidence": 0.6728328466415405}, {"text": "BLEU", "start_pos": 205, "end_pos": 209, "type": "METRIC", "confidence": 0.963552713394165}, {"text": "TER", "start_pos": 214, "end_pos": 217, "type": "METRIC", "confidence": 0.6843470335006714}]}, {"text": "The motivation is to detect if an improvement is artificial, i.e., specific to the tuning metric.", "labels": [], "entities": []}, {"text": "For both Arabic-to-English and Chinese-toEnglish MT, we tuned on NIST MT02-05 and tested on MT06 and MT08 newswire sets.", "labels": [], "entities": [{"text": "MT", "start_pos": 49, "end_pos": 51, "type": "TASK", "confidence": 0.8459711074829102}, {"text": "NIST", "start_pos": 65, "end_pos": 69, "type": "DATASET", "confidence": 0.9793140292167664}, {"text": "MT02-05", "start_pos": 70, "end_pos": 77, "type": "DATASET", "confidence": 0.5267757177352905}, {"text": "MT06", "start_pos": 92, "end_pos": 96, "type": "DATASET", "confidence": 0.9527660608291626}, {"text": "MT08 newswire sets", "start_pos": 101, "end_pos": 119, "type": "DATASET", "confidence": 0.9341639876365662}]}, {"text": "The training data are different from what was usd at MT06 or MT08.", "labels": [], "entities": [{"text": "MT06", "start_pos": 53, "end_pos": 57, "type": "DATASET", "confidence": 0.9747134447097778}, {"text": "MT08", "start_pos": 61, "end_pos": 65, "type": "DATASET", "confidence": 0.9426154494285583}]}, {"text": "Our Arabic-to-English data contain 29M Arabic words and 38M English words from 11 corpora: LDC2004T17, LDC2004T18, LDC2005E46, LDC2006E25, LDC2006G05, LDC2005E85, LDC2006E36, LDC2006E82, LDC2006E95, Sakhr-A2E and Sakhr-E2A.", "labels": [], "entities": []}, {"text": "The Chinese-to-English data contain 107M Chinese words and 132M English words from eight corpora: LDC2002E18, LDC2005T06, LDC2005T10, LDC2006E26, LDC2006G05, LDC2002L27, LDC2005T34 and LDC2003E07.", "labels": [], "entities": []}, {"text": "They are available under the DARPA GALE program.", "labels": [], "entities": [{"text": "DARPA GALE", "start_pos": 29, "end_pos": 39, "type": "TASK", "confidence": 0.5742735266685486}]}, {"text": "Traditional 3-gram and 5-gram string LMs were trained on the English side of the parallel data plus the English Gigaword corpus V3.0 in away described in (.", "labels": [], "entities": [{"text": "English Gigaword corpus V3.0", "start_pos": 104, "end_pos": 132, "type": "DATASET", "confidence": 0.7628532648086548}]}, {"text": "The target dependency LMs were trained on the English side of the parallel training data.", "labels": [], "entities": []}, {"text": "For that purpose, we parsed the English side of the parallel data.", "labels": [], "entities": [{"text": "parsed", "start_pos": 21, "end_pos": 27, "type": "TASK", "confidence": 0.9685497879981995}]}, {"text": "Two separate models were trained: one for Arabic from the Arabic training data and the other for Chinese from the Chinese training data.", "labels": [], "entities": []}, {"text": "To compute the source dependency LM for Chinese-to-English MT, we parsed the Chinese side of the Chinese-to-English parallel data.", "labels": [], "entities": [{"text": "MT", "start_pos": 59, "end_pos": 61, "type": "TASK", "confidence": 0.8065941333770752}]}, {"text": "Due to the lack of a good Arabic parser compatible with the Sakhr tokenization that we used on the source side, we did not test the source dependency LM for Arabic-to-English MT.", "labels": [], "entities": [{"text": "MT", "start_pos": 175, "end_pos": 177, "type": "TASK", "confidence": 0.8892685174942017}]}, {"text": "When extracting rules with source dependency structures, we applied the same well-formedness constraint on the source side as we did on the target side, using a procedure described by other hand, one string-to-dependency rule may split into several dependency-to-dependency rules due to different source dependency structures.", "labels": [], "entities": []}, {"text": "The size of the dependency-to-dependency rule set is slightly smaller than the size of the string-todependency rule set.", "labels": [], "entities": []}, {"text": "show the BLEU and TER percentage scores on MT06 and MT08 for Arabicto-English and Chinese-to-English translation respectively.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 9, "end_pos": 13, "type": "METRIC", "confidence": 0.9995778203010559}, {"text": "TER percentage", "start_pos": 18, "end_pos": 32, "type": "METRIC", "confidence": 0.9799322783946991}, {"text": "MT06", "start_pos": 43, "end_pos": 47, "type": "DATASET", "confidence": 0.9626651406288147}, {"text": "MT08", "start_pos": 52, "end_pos": 56, "type": "DATASET", "confidence": 0.9545758962631226}]}, {"text": "The context LM feature, the length feature and the syntax label feature all produce a small improvement for most of the conditions.", "labels": [], "entities": []}, {"text": "When we combined the three features, we observed significant improvements over the baseline.", "labels": [], "entities": []}, {"text": "For Arabic-to-English MT, the LBL+LEN+CLM system improved lower-cased BLEU by 2.0 on MT06 and 1.7 on MT08 on decoding output.", "labels": [], "entities": [{"text": "MT", "start_pos": 22, "end_pos": 24, "type": "TASK", "confidence": 0.8458759188652039}, {"text": "LBL+LEN+CLM", "start_pos": 30, "end_pos": 41, "type": "METRIC", "confidence": 0.8146235466003418}, {"text": "BLEU", "start_pos": 70, "end_pos": 74, "type": "METRIC", "confidence": 0.9983301758766174}, {"text": "MT06", "start_pos": 85, "end_pos": 89, "type": "DATASET", "confidence": 0.8977352380752563}, {"text": "MT08", "start_pos": 101, "end_pos": 105, "type": "DATASET", "confidence": 0.8756900429725647}]}, {"text": "For Chinese-to-English MT, the improvements in lower-cased BLEU were 1.0 on MT06 and 0.8 on MT08.", "labels": [], "entities": [{"text": "MT", "start_pos": 23, "end_pos": 25, "type": "TASK", "confidence": 0.7871778607368469}, {"text": "BLEU", "start_pos": 59, "end_pos": 63, "type": "METRIC", "confidence": 0.9952078461647034}, {"text": "MT06", "start_pos": 76, "end_pos": 80, "type": "DATASET", "confidence": 0.9204815626144409}, {"text": "MT08", "start_pos": 92, "end_pos": 96, "type": "DATASET", "confidence": 0.9282997846603394}]}, {"text": "After re-scoring, the improvements became smaller, but still noticeable, ranging from 0.7 to 1.4.", "labels": [], "entities": []}, {"text": "TER scores were also improved noticeably for all conditions, suggesting there was no metric specific over-tuning.", "labels": [], "entities": [{"text": "TER", "start_pos": 0, "end_pos": 3, "type": "METRIC", "confidence": 0.9856806993484497}]}, {"text": "Surprisingly, source dependency LM did not provide any improvement over the baseline.", "labels": [], "entities": []}, {"text": "There are two possible reasons for this.", "labels": [], "entities": []}, {"text": "One is that the source and target parse trees were generated by two stand-alone parsers, which may cause incompatible structures on the source and target sides.", "labels": [], "entities": []}, {"text": "By applying the well-formed constraints on both sides, a lot of useful transfer rules are discarded.", "labels": [], "entities": []}, {"text": "A bi-lingual parser, trained on parallel treebanks recently made available to the NLP community, may overcome this problem.", "labels": [], "entities": []}, {"text": "The other is that the search space of dependency-todependency decoding is much larger, since we need to add source dependency information into the chart parsing states.", "labels": [], "entities": []}, {"text": "We will explore techniques to address these problems in the future.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: BLEU and TER percentage scores on MT06 and MT08 Arabic-to-English newswire sets.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9993255138397217}, {"text": "TER percentage", "start_pos": 19, "end_pos": 33, "type": "METRIC", "confidence": 0.9670949876308441}, {"text": "MT06", "start_pos": 44, "end_pos": 48, "type": "DATASET", "confidence": 0.9648005366325378}, {"text": "MT08 Arabic-to-English newswire sets", "start_pos": 53, "end_pos": 89, "type": "DATASET", "confidence": 0.9014323055744171}]}, {"text": " Table 2: BLEU and TER percentage scores on MT06 and MT08 Chinese-to-English newswire sets.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9993282556533813}, {"text": "TER percentage", "start_pos": 19, "end_pos": 33, "type": "METRIC", "confidence": 0.969099760055542}, {"text": "MT06", "start_pos": 44, "end_pos": 48, "type": "DATASET", "confidence": 0.9753134846687317}, {"text": "MT08 Chinese-to-English newswire sets", "start_pos": 53, "end_pos": 90, "type": "DATASET", "confidence": 0.9184465557336807}]}]}