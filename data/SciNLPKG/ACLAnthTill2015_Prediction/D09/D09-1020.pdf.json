{"title": [], "abstractContent": [{"text": "This paper investigates anew task, subjec-tivity word sense disambiguation (SWSD), which is to automatically determine which word instances in a corpus are being used with subjective senses, and which are being used with objective senses.", "labels": [], "entities": [{"text": "subjec-tivity word sense disambiguation (SWSD)", "start_pos": 35, "end_pos": 81, "type": "TASK", "confidence": 0.7261826481137957}]}, {"text": "We provide empirical evidence that SWSD is more feasible than full word sense dis-ambiguation, and that it can be exploited to improve the performance of contextual subjectivity and sentiment analysis systems .", "labels": [], "entities": [{"text": "SWSD", "start_pos": 35, "end_pos": 39, "type": "TASK", "confidence": 0.9670356512069702}, {"text": "full word sense dis-ambiguation", "start_pos": 62, "end_pos": 93, "type": "TASK", "confidence": 0.6367184296250343}, {"text": "sentiment analysis", "start_pos": 182, "end_pos": 200, "type": "TASK", "confidence": 0.9061961770057678}]}], "introductionContent": [{"text": "The automatic extraction of opinions, emotions, and sentiments in text (subjectivity analysis) to support applications such as product review mining, summarization, question answering, and information extraction is an active area of research in NLP.", "labels": [], "entities": [{"text": "automatic extraction of opinions, emotions, and sentiments in text", "start_pos": 4, "end_pos": 70, "type": "TASK", "confidence": 0.853754617951133}, {"text": "product review mining", "start_pos": 127, "end_pos": 148, "type": "TASK", "confidence": 0.7071172793706259}, {"text": "summarization", "start_pos": 150, "end_pos": 163, "type": "TASK", "confidence": 0.9861327409744263}, {"text": "question answering", "start_pos": 165, "end_pos": 183, "type": "TASK", "confidence": 0.8763337731361389}, {"text": "information extraction", "start_pos": 189, "end_pos": 211, "type": "TASK", "confidence": 0.848015695810318}]}, {"text": "Many approaches to opinion, sentiment, and subjectivity analysis rely on lexicons of words that maybe used to express subjectivity.", "labels": [], "entities": [{"text": "opinion, sentiment, and subjectivity analysis", "start_pos": 19, "end_pos": 64, "type": "TASK", "confidence": 0.7125790928091321}]}, {"text": "Examples of such words are the following (in bold): He is a disease to every team he has gone to.", "labels": [], "entities": []}, {"text": "Converting to SMF is a headache.", "labels": [], "entities": [{"text": "SMF", "start_pos": 14, "end_pos": 17, "type": "TASK", "confidence": 0.8848806023597717}]}, {"text": "The concert left me cold.", "labels": [], "entities": []}, {"text": "That guy is such a pain.", "labels": [], "entities": []}, {"text": "Knowing the meaning (and thus subjectivity) of these words would help a system recognize the negative sentiments in these sentences.", "labels": [], "entities": []}, {"text": "Most subjectivity lexicons are compiled as lists of keywords, rather than word meanings (senses).", "labels": [], "entities": []}, {"text": "However, many keywords have both subjective and objective senses.", "labels": [], "entities": []}, {"text": "False hits -subjectivity clues used with objective senses -are a significant source of error in subjectivity and sentiment analysis.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 113, "end_pos": 131, "type": "TASK", "confidence": 0.8932617902755737}]}, {"text": "For example, even though the following sentence contains all of the negative keywords above, it is nevertheless objective, as they are all false hits: Early symptoms of the disease include severe headaches, red eyes, fevers and cold chills, body pain, and vomiting.", "labels": [], "entities": []}, {"text": "To tackle this source of error, we define anew task, subjectivity word sense disambiguation (SWSD), which is to automatically determine which word instances in a corpus are being used with subjective senses, and which are being used with objective senses.", "labels": [], "entities": [{"text": "subjectivity word sense disambiguation (SWSD)", "start_pos": 53, "end_pos": 98, "type": "TASK", "confidence": 0.7353928514889309}]}, {"text": "We hypothesize that SWSD is more feasible than full word sense disambiguation, because it is more coarse grained -often, the exact sense need not be pinpointed.", "labels": [], "entities": [{"text": "SWSD", "start_pos": 20, "end_pos": 24, "type": "TASK", "confidence": 0.9502052664756775}, {"text": "full word sense disambiguation", "start_pos": 47, "end_pos": 77, "type": "TASK", "confidence": 0.6144802868366241}]}, {"text": "We also hypothesize that SWSD can be exploited to improve the performance of contextual subjectivity analysis systems via sense-aware classification.", "labels": [], "entities": [{"text": "SWSD", "start_pos": 25, "end_pos": 29, "type": "TASK", "confidence": 0.8446792960166931}]}, {"text": "The paper consists of two parts.", "labels": [], "entities": []}, {"text": "In the first part, we build and evaluate a targeted supervised SWSD system that aims to disambiguate members of a subjectivity lexicon.", "labels": [], "entities": [{"text": "SWSD", "start_pos": 63, "end_pos": 67, "type": "TASK", "confidence": 0.9393723011016846}]}, {"text": "It labels clue instances as having a subjective sense or an objective sense in context.", "labels": [], "entities": []}, {"text": "The system relies on common machine learning features for word sense disambiguation (WSD).", "labels": [], "entities": [{"text": "word sense disambiguation (WSD)", "start_pos": 58, "end_pos": 89, "type": "TASK", "confidence": 0.8116265634695689}]}, {"text": "The performance is substantially above both baseline and the performance of full WSD on the same data, suggesting that the task is feasible, and that subjectivity provides a natural coarsegrained grouping of senses.", "labels": [], "entities": []}, {"text": "The second part demonstrates the promise of SWSD for contextual subjectivity analysis.", "labels": [], "entities": [{"text": "SWSD", "start_pos": 44, "end_pos": 48, "type": "TASK", "confidence": 0.8756954669952393}, {"text": "contextual subjectivity analysis", "start_pos": 53, "end_pos": 85, "type": "TASK", "confidence": 0.6708739995956421}]}, {"text": "First, we show that subjectivity sense ambiguity is highly prevalent in the MPQA opinion-annotated corpus (, thus establishing the potential benefit of performing SWSD.", "labels": [], "entities": [{"text": "MPQA opinion-annotated corpus", "start_pos": 76, "end_pos": 105, "type": "DATASET", "confidence": 0.902199923992157}, {"text": "SWSD", "start_pos": 163, "end_pos": 167, "type": "TASK", "confidence": 0.9607447981834412}]}, {"text": "Then, we exploit SWSD to improve performance on several subjectivity analysis tasks, from subjective/objective sentence-level classification to positive/negative/neutral expressionlevel classification.", "labels": [], "entities": [{"text": "positive/negative/neutral expressionlevel classification", "start_pos": 144, "end_pos": 200, "type": "TASK", "confidence": 0.7382466495037079}]}, {"text": "To our knowledge, this is the first attempt to explicitly use sense-level subjectivity tags in contextual subjectivity and sentiment analysis.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 123, "end_pos": 141, "type": "TASK", "confidence": 0.8900537490844727}]}], "datasetContent": [{"text": "In this section, we evaluate our SWSD system, and compare its performance to an WSD system on the same data.", "labels": [], "entities": [{"text": "SWSD", "start_pos": 33, "end_pos": 37, "type": "TASK", "confidence": 0.8016934990882874}]}, {"text": "Note that, although generally in the SENSEVAL datasets, training and test data are provided separately, a few target words from SENSEVAL1 do not have both training and testing data.", "labels": [], "entities": [{"text": "SENSEVAL datasets", "start_pos": 37, "end_pos": 54, "type": "DATASET", "confidence": 0.8789772093296051}]}, {"text": "Thus, we opted to combine the training and test data into one dataset, and then perform 10-fold cross validation experiments.", "labels": [], "entities": []}, {"text": "For our classifier, we use the SVM classifier from the Weka package) with its default settings.", "labels": [], "entities": [{"text": "Weka package", "start_pos": 55, "end_pos": 67, "type": "DATASET", "confidence": 0.8050726652145386}]}, {"text": "We were interested in how well the system would perform on more and less ambiguous words.", "labels": [], "entities": []}, {"text": "Thus, we split the words into three subsets according to their majority-class baselines, and report separate results: S1 (9 words), S2 (18 words), and S3 (12 words) have majority-class baselines in the intervals [50%,70%) , [70%,90%), and [90%,100%), respectively.", "labels": [], "entities": []}, {"text": "contains the results, giving the overall results (micro averages), as well as results for the subsets S1, S2, and S3.", "labels": [], "entities": []}, {"text": "The improvement for SWSD over baseline is especially high for the less skewed set, S1.", "labels": [], "entities": [{"text": "SWSD", "start_pos": 20, "end_pos": 24, "type": "TASK", "confidence": 0.7189396023750305}]}, {"text": "This is very encouraging because these words are the more ambiguous words, and thus are the ones that most need SWSD (assuming the SENSEVAL priors are similar to the priors in the corpus).", "labels": [], "entities": [{"text": "SWSD", "start_pos": 112, "end_pos": 116, "type": "METRIC", "confidence": 0.6430830955505371}]}, {"text": "The average error reduction over baseline for S1 words is 54.2%.", "labels": [], "entities": [{"text": "error reduction", "start_pos": 12, "end_pos": 27, "type": "METRIC", "confidence": 0.9829984903335571}]}, {"text": "Even for the more skewed sets S2 and S3, reductions are 32.8% and 28.0%, respectively, with an overall reduction of 41.8%.", "labels": [], "entities": []}, {"text": "To compare SWSD with WSD, we re-ran the 10-fold cross validation experiments, but this time using the original sense labels, rather than Sand O. The (micro-averaged) accuracy is 67.9%, much lower than the overall accuracy for SWSD (88.3%).", "labels": [], "entities": [{"text": "SWSD", "start_pos": 11, "end_pos": 15, "type": "TASK", "confidence": 0.8325430750846863}, {"text": "accuracy", "start_pos": 166, "end_pos": 174, "type": "METRIC", "confidence": 0.913574755191803}, {"text": "accuracy", "start_pos": 213, "end_pos": 221, "type": "METRIC", "confidence": 0.9986591339111328}]}, {"text": "The positive results provide evidence that SWSD is a feasible variant of WSD, and that the S/O sense groupings are natural ones, since the system is able to learn to distinguish between them with high accuracy.", "labels": [], "entities": [{"text": "WSD", "start_pos": 73, "end_pos": 76, "type": "TASK", "confidence": 0.841991662979126}, {"text": "accuracy", "start_pos": 201, "end_pos": 209, "type": "METRIC", "confidence": 0.9880344271659851}]}, {"text": "There is also potential for improvement by using a richer feature set, including subjectivity features.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Overall SWSD results (micro averages). Base is majority-class baseline; Acc is accuracy; SP,  SR, and SF are subjective precision, recall and F-measure; similarly for OP, OR, and OF. IB is absolute  improvement in Acc over Base; EB is percent error reduction in Acc.", "labels": [], "entities": [{"text": "SWSD", "start_pos": 18, "end_pos": 22, "type": "TASK", "confidence": 0.9480462670326233}, {"text": "Acc", "start_pos": 82, "end_pos": 85, "type": "METRIC", "confidence": 0.9873977899551392}, {"text": "accuracy", "start_pos": 89, "end_pos": 97, "type": "METRIC", "confidence": 0.9979438185691833}, {"text": "SF", "start_pos": 112, "end_pos": 114, "type": "METRIC", "confidence": 0.8154134750366211}, {"text": "precision", "start_pos": 130, "end_pos": 139, "type": "METRIC", "confidence": 0.8743532299995422}, {"text": "recall", "start_pos": 141, "end_pos": 147, "type": "METRIC", "confidence": 0.9981958270072937}, {"text": "F-measure", "start_pos": 152, "end_pos": 161, "type": "METRIC", "confidence": 0.9802086353302002}, {"text": "OF", "start_pos": 189, "end_pos": 191, "type": "METRIC", "confidence": 0.9323407411575317}, {"text": "IB", "start_pos": 193, "end_pos": 195, "type": "METRIC", "confidence": 0.99257892370224}, {"text": "Acc", "start_pos": 224, "end_pos": 227, "type": "METRIC", "confidence": 0.9885845184326172}, {"text": "EB", "start_pos": 239, "end_pos": 241, "type": "METRIC", "confidence": 0.9970487952232361}, {"text": "error reduction", "start_pos": 253, "end_pos": 268, "type": "METRIC", "confidence": 0.9244320392608643}, {"text": "Acc", "start_pos": 272, "end_pos": 275, "type": "METRIC", "confidence": 0.9521167874336243}]}, {"text": " Table 2: Effect of SWSD on the rule-based classi- fiers.", "labels": [], "entities": [{"text": "SWSD", "start_pos": 20, "end_pos": 24, "type": "TASK", "confidence": 0.8182305097579956}]}, {"text": " Table 3: Effect of SWSD on the subjec- tive/objective classifier", "labels": [], "entities": [{"text": "SWSD", "start_pos": 20, "end_pos": 24, "type": "TASK", "confidence": 0.867741584777832}]}, {"text": " Table 5: Effect of SWSD on the contextual polarity classifier", "labels": [], "entities": [{"text": "SWSD", "start_pos": 20, "end_pos": 24, "type": "TASK", "confidence": 0.8947885036468506}, {"text": "contextual polarity classifier", "start_pos": 32, "end_pos": 62, "type": "TASK", "confidence": 0.6414056022961935}]}, {"text": " Table 4: Effect of SWSD on the neutral/polar clas- sifier", "labels": [], "entities": []}]}