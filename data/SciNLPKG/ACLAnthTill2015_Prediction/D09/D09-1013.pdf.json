{"title": [{"text": "A Rich Feature Vector for Protein-Protein Interaction Extraction from Multiple Corpora", "labels": [], "entities": [{"text": "Protein-Protein Interaction Extraction", "start_pos": 26, "end_pos": 64, "type": "TASK", "confidence": 0.7904064853986105}]}], "abstractContent": [{"text": "Because of the importance of protein-protein interaction (PPI) extraction from text, many corpora have been proposed with slightly differing definitions of proteins and PPI.", "labels": [], "entities": [{"text": "protein-protein interaction (PPI) extraction from text", "start_pos": 29, "end_pos": 83, "type": "TASK", "confidence": 0.7908628061413765}]}, {"text": "Since no single corpus is large enough to saturate a machine learning system, it is necessary to learn from multiple different corpora.", "labels": [], "entities": []}, {"text": "In this paper, we propose a solution to this challenge.", "labels": [], "entities": []}, {"text": "We designed a rich feature vector, and we applied a support vector machine modified for corpus weighting (SVM-CW) to complete the task of multiple corpora PPI extraction.", "labels": [], "entities": [{"text": "multiple corpora PPI extraction", "start_pos": 138, "end_pos": 169, "type": "TASK", "confidence": 0.593110479414463}]}, {"text": "The rich feature vector, made from multiple useful kernels, is used to express the important information for PPI extraction, and the system with our feature vector was shown to be both faster and more accurate than the original kernel-based system, even when using just a single corpus.", "labels": [], "entities": [{"text": "PPI extraction", "start_pos": 109, "end_pos": 123, "type": "TASK", "confidence": 0.9403262734413147}]}, {"text": "SVM-CW learns from one corpus , while using other corpora for support.", "labels": [], "entities": []}, {"text": "SVM-CW is simple, but it is more effective than other methods that have been successfully applied to other NLP tasks earlier.", "labels": [], "entities": []}, {"text": "With the feature vector and SVM-CW, our system achieved the best performance among all state-of-the-art PPI extraction systems reported so far.", "labels": [], "entities": [{"text": "PPI extraction", "start_pos": 104, "end_pos": 118, "type": "TASK", "confidence": 0.8977856934070587}]}], "introductionContent": [{"text": "The performance of an information extraction program is highly dependent on various factors, including text types (abstracts, complete articles, reports, etc.), exact definitions of the information to be extracted, shared sub-topics of the text collections from which information is to be extracted.", "labels": [], "entities": [{"text": "information extraction", "start_pos": 22, "end_pos": 44, "type": "TASK", "confidence": 0.7359443157911301}]}, {"text": "Even if two corpora are annotated in terms of the same type of information by two groups, the performance of a program trained by one corpus is unlikely to be reproduced in the other corpus.", "labels": [], "entities": []}, {"text": "On the other hand, from a practical point of view, it is worthwhile to effectively use multiple existing annotated corpora together, because it is very costly to make new annotations.", "labels": [], "entities": []}, {"text": "One problem with several different corpora is protein-protein interaction (PPI) extraction from text.", "labels": [], "entities": [{"text": "protein-protein interaction (PPI) extraction from text", "start_pos": 46, "end_pos": 100, "type": "TASK", "confidence": 0.7149214781820774}]}, {"text": "While PPIs play a critical role in understanding the working of cells in diverse biological contexts, the manual construction of PPI databases such as BIND, DIP, HPRD, IntAct, and MINT () is known to be very time-consuming and labor-intensive.", "labels": [], "entities": [{"text": "BIND", "start_pos": 151, "end_pos": 155, "type": "METRIC", "confidence": 0.8955236077308655}]}, {"text": "The automatic extraction of PPI from published papers has therefore been a major research topic in Natural Language Processing for Biology (BioNLP).", "labels": [], "entities": [{"text": "automatic extraction of PPI from published papers", "start_pos": 4, "end_pos": 53, "type": "TASK", "confidence": 0.8278655878135136}]}, {"text": "Among several PPI extraction task settings, the most common is sentence-based, pair-wise PPI extraction.", "labels": [], "entities": [{"text": "PPI extraction task", "start_pos": 14, "end_pos": 33, "type": "TASK", "confidence": 0.9323964317639669}, {"text": "PPI extraction", "start_pos": 89, "end_pos": 103, "type": "TASK", "confidence": 0.7782065868377686}]}, {"text": "At least four annotated corpora have been provided for this setting: AIMed ( ), HPRD50 (), IEPA (), and LLL).", "labels": [], "entities": [{"text": "HPRD50", "start_pos": 80, "end_pos": 86, "type": "DATASET", "confidence": 0.8934904932975769}, {"text": "IEPA", "start_pos": 91, "end_pos": 95, "type": "METRIC", "confidence": 0.7938209772109985}]}, {"text": "Each of these corpora have been used as the standard corpus for training and testing PPI programs.", "labels": [], "entities": []}, {"text": "Moreover, several corpora are annotated for more types of events than just for PPI.", "labels": [], "entities": []}, {"text": "Such examples include BioInfer (, and GENIA (), and they can be reorganized into PPI corpora.", "labels": [], "entities": [{"text": "BioInfer", "start_pos": 22, "end_pos": 30, "type": "DATASET", "confidence": 0.6733567118644714}, {"text": "GENIA", "start_pos": 38, "end_pos": 43, "type": "DATASET", "confidence": 0.9059931039810181}]}, {"text": "Even though all of these corpora were made for PPI extraction, they were constructed based on different definitions of proteins and PPI, which reflect different biological research interests ( . Research on PPI extraction so far has revealed that the performance on each of the corpora could benefit from additional examples ( . Learning from multiple annotated corpora could lead to better PPI extraction performance.", "labels": [], "entities": [{"text": "PPI extraction", "start_pos": 47, "end_pos": 61, "type": "TASK", "confidence": 0.9264892637729645}, {"text": "PPI extraction", "start_pos": 207, "end_pos": 221, "type": "TASK", "confidence": 0.830083578824997}, {"text": "PPI extraction", "start_pos": 391, "end_pos": 405, "type": "TASK", "confidence": 0.8668728470802307}]}, {"text": "Various research paradigms such as inductive transfer learning (ITL) and domain adaptation (DA) have mainly focused on how to effectively use corpora annotated by other groups, by reducing the incompatibilities.", "labels": [], "entities": [{"text": "inductive transfer learning (ITL)", "start_pos": 35, "end_pos": 68, "type": "TASK", "confidence": 0.757543126742045}, {"text": "domain adaptation (DA)", "start_pos": 73, "end_pos": 95, "type": "TASK", "confidence": 0.8168898820877075}]}, {"text": "In this paper, we propose the extraction of PPIs from multiple different corpora.", "labels": [], "entities": []}, {"text": "We design a rich feature vector, and as an ITL method, we apply a support vector machine (SVM) modified for corpus weighting (SVM-CW) (, in order to evaluate the use of multiple corpora for the PPI extraction task.", "labels": [], "entities": [{"text": "PPI extraction task", "start_pos": 194, "end_pos": 213, "type": "TASK", "confidence": 0.9044406016667684}]}, {"text": "Our rich feature vector is made from multiple useful kernels, each of which is based on multiple parser inputs, proposed by.", "labels": [], "entities": []}, {"text": "The system with our feature vector was better than or at least comparable to the state-of-the-art PPI extraction systems on every corpus.", "labels": [], "entities": [{"text": "PPI extraction", "start_pos": 98, "end_pos": 112, "type": "TASK", "confidence": 0.8013496398925781}]}, {"text": "The system is a good starting point to use the multiple corpora.", "labels": [], "entities": []}, {"text": "Using one of the corpora as the target corpus, SVM-CW weights the remaining corpora (we call them the source corpora) with \"goodness\" for training on the target corpus.", "labels": [], "entities": []}, {"text": "While SVM-CW is simple, we show that SVM-CW can improve the performance of the system more effectively and more efficiently than other methods proven to be successful in other NLP tasks earlier.", "labels": [], "entities": []}, {"text": "As a result, SVM-CW with our feature vector is comprised of a PPI system with five different models, of which each model is superior to the best model in the original PPI extraction task, which used only the single corpus.", "labels": [], "entities": [{"text": "PPI extraction task", "start_pos": 167, "end_pos": 186, "type": "TASK", "confidence": 0.8509407043457031}]}], "datasetContent": [{"text": "We used five corpora for evaluation: AIMed, BioInfer, HPRD50, IEPA, and LLL.", "labels": [], "entities": [{"text": "HPRD50", "start_pos": 54, "end_pos": 60, "type": "DATASET", "confidence": 0.9002869129180908}, {"text": "IEPA", "start_pos": 62, "end_pos": 66, "type": "METRIC", "confidence": 0.9371589422225952}]}, {"text": "For the comparison with other methods, we report the Fscore (%), and the area under the receiver operating characteristic (ROC) curve (AUC) (%) using (abstract-wise) a 10-fold CV and a oneanswer-per-occurrence criterion.", "labels": [], "entities": [{"text": "Fscore", "start_pos": 53, "end_pos": 59, "type": "METRIC", "confidence": 0.9994779229164124}, {"text": "receiver operating characteristic (ROC) curve (AUC)", "start_pos": 88, "end_pos": 139, "type": "METRIC", "confidence": 0.8720792025327683}]}, {"text": "These measures are commonly used for the PPI extraction tasks.", "labels": [], "entities": [{"text": "PPI extraction tasks", "start_pos": 41, "end_pos": 61, "type": "TASK", "confidence": 0.9238075415293375}]}, {"text": "The F-score is a harmonic mean of Precision and Recall.", "labels": [], "entities": [{"text": "F-score", "start_pos": 4, "end_pos": 11, "type": "METRIC", "confidence": 0.9943848848342896}, {"text": "Precision", "start_pos": 34, "end_pos": 43, "type": "METRIC", "confidence": 0.9969466328620911}, {"text": "Recall", "start_pos": 48, "end_pos": 54, "type": "METRIC", "confidence": 0.9859043955802917}]}, {"text": "The ROC curve is a plot of a true positive rate (TPR) vs a false positive rate (FPR) for different thresholds.", "labels": [], "entities": [{"text": "ROC curve", "start_pos": 4, "end_pos": 13, "type": "METRIC", "confidence": 0.9473628997802734}, {"text": "true positive rate (TPR)", "start_pos": 29, "end_pos": 53, "type": "METRIC", "confidence": 0.7698036034901937}, {"text": "false positive rate (FPR)", "start_pos": 59, "end_pos": 84, "type": "METRIC", "confidence": 0.7567656089862188}]}, {"text": "We tuned the regularization parameters of all classifiers by performing a 10-fold CV on the training data using a random split.", "labels": [], "entities": []}, {"text": "The other parameters were fixed, and we report the highest of the macro-averaged F-scores as our final F-score.", "labels": [], "entities": [{"text": "F-scores", "start_pos": 81, "end_pos": 89, "type": "METRIC", "confidence": 0.9584658145904541}, {"text": "F-score", "start_pos": 103, "end_pos": 110, "type": "METRIC", "confidence": 0.9493242502212524}]}, {"text": "For 10-fold CV, we split the corpora as recommended by .  In this section, we first apply each model from a source corpus to a target corpus, to show how different the corpora are.", "labels": [], "entities": []}, {"text": "We then evaluate SVM-CW by comparing it with three other methods (see Section 2) with limited features, and apply it to every corpus.", "labels": [], "entities": []}, {"text": "Figure 8: F-score on a target corpus using a model on a source corpus.", "labels": [], "entities": [{"text": "F-score", "start_pos": 10, "end_pos": 17, "type": "METRIC", "confidence": 0.9964249730110168}]}, {"text": "For the comparison, we show the 10-fold CV result on each target corpus and co-occurrences.", "labels": [], "entities": []}, {"text": "The regularization parameter was fixed to 1.", "labels": [], "entities": []}, {"text": "First, we apply the model from a source corpus to a target corpus.", "labels": [], "entities": []}, {"text": "shows how the model from a source corpus performs on the target corpus.", "labels": [], "entities": []}, {"text": "Interestingly, the model from IEPA performs better on LLL than the model from LLL itself.", "labels": [], "entities": [{"text": "IEPA", "start_pos": 30, "end_pos": 34, "type": "DATASET", "confidence": 0.7933838963508606}]}, {"text": "All the results showed that using different corpora (except IEPA) is worse than just using the same corpora.", "labels": [], "entities": [{"text": "IEPA", "start_pos": 60, "end_pos": 64, "type": "METRIC", "confidence": 0.9794206023216248}]}, {"text": "However, the cross-corpora scores are still better than the co-occurrences base-line, which indicates that the corpora share some information, even though they are not fully compatible.", "labels": [], "entities": []}, {"text": "Next, we compare SVM-CW with three other methods: aSVM, SVD-ASO, and TrAdaBoost.", "labels": [], "entities": [{"text": "aSVM", "start_pos": 50, "end_pos": 54, "type": "METRIC", "confidence": 0.7088530659675598}, {"text": "TrAdaBoost", "start_pos": 69, "end_pos": 79, "type": "METRIC", "confidence": 0.6124329566955566}]}, {"text": "For this comparison, we used our feature vector without including the graph features, because SVD-ASO and TrAdaBoost require large computational resources.", "labels": [], "entities": []}, {"text": "We applied SVD-ASO and TrAdaBoost in the following way.", "labels": [], "entities": [{"text": "SVD-ASO", "start_pos": 11, "end_pos": 18, "type": "DATASET", "confidence": 0.7673913836479187}, {"text": "TrAdaBoost", "start_pos": 23, "end_pos": 33, "type": "METRIC", "confidence": 0.6949790120124817}]}, {"text": "As for SVD-ASO, we made 400 auxiliary problems from the labels of each corpus by splitting features randomly, and extracted 50 additional features each for 4 feature groups.", "labels": [], "entities": []}, {"text": "In total, we made new 200 additional features from 2,000 auxiliary problems.", "labels": [], "entities": []}, {"text": "As recommended by, we removed negative weights, performed SVD to each feature group, and iterated ASO once.", "labels": [], "entities": [{"text": "ASO", "start_pos": 98, "end_pos": 101, "type": "METRIC", "confidence": 0.9355006217956543}]}, {"text": "Since AdaBoost easily overfitted with our rich feature vector, we applied soft margins () to TrAdaBoost.", "labels": [], "entities": [{"text": "AdaBoost", "start_pos": 6, "end_pos": 14, "type": "DATASET", "confidence": 0.9218078255653381}]}, {"text": "The update parameter for source examples was calculated using the update parameter on the training data in AdaBoost and the original parameter in TrAdaBoost.", "labels": [], "entities": [{"text": "AdaBoost", "start_pos": 107, "end_pos": 115, "type": "DATASET", "confidence": 0.9391579031944275}, {"text": "TrAdaBoost", "start_pos": 146, "end_pos": 156, "type": "DATASET", "confidence": 0.9134768843650818}]}, {"text": "This ensures that the parameter would be the same as the original parameter, when the C value in the soft margin approaches infinity.: F-score and AUC by SVM-CW.", "labels": [], "entities": [{"text": "F-score", "start_pos": 135, "end_pos": 142, "type": "METRIC", "confidence": 0.994273841381073}, {"text": "AUC", "start_pos": 147, "end_pos": 150, "type": "METRIC", "confidence": 0.9986147880554199}, {"text": "SVM-CW", "start_pos": 154, "end_pos": 160, "type": "DATASET", "confidence": 0.8877869844436646}]}, {"text": "Rows correspond to a target corpus, and columns a source corpus.", "labels": [], "entities": []}, {"text": "A:AIMed, B:BioInfer, H:HPRD50, I:IEPA, and L:LLL corpora.", "labels": [], "entities": [{"text": "AIMed", "start_pos": 2, "end_pos": 7, "type": "DATASET", "confidence": 0.8425605893135071}, {"text": "HPRD50", "start_pos": 23, "end_pos": 29, "type": "DATASET", "confidence": 0.9439020752906799}, {"text": "IEPA", "start_pos": 33, "end_pos": 37, "type": "METRIC", "confidence": 0.7911554574966431}]}, {"text": "\"all\" signifies that all source corpora are used as one source corpus, ignoring the differences among the corpora.", "labels": [], "entities": []}, {"text": "For the comparison, we show the 10-fold CV result on each target corpus.", "labels": [], "entities": []}, {"text": "In, we demonstrate the results of the comparison.", "labels": [], "entities": []}, {"text": "SVM-CW improved the classification performance at least as much as all the other methods.", "labels": [], "entities": [{"text": "SVM-CW", "start_pos": 0, "end_pos": 6, "type": "DATASET", "confidence": 0.8485052585601807}, {"text": "classification", "start_pos": 20, "end_pos": 34, "type": "TASK", "confidence": 0.96542888879776}]}, {"text": "The improvement is mainly attributed to the aggressive use of source examples while learning the model.", "labels": [], "entities": []}, {"text": "Some source examples can be used as training data, as indicated in.", "labels": [], "entities": []}, {"text": "SVM-CW does not set the restriction between C sand Ct in Equation, so it can use source examples aggressively while learning the model.", "labels": [], "entities": [{"text": "SVM-CW", "start_pos": 0, "end_pos": 6, "type": "DATASET", "confidence": 0.8638821244239807}]}, {"text": "Since aSVM transfers a model, and SVD-ASO transfers an additional feature space, aSVM and SVD-ASO do not use the source examples while learning the model.", "labels": [], "entities": []}, {"text": "In addition to the difference in the data usage, the settings of aSVM and SVD-ASO do not match the current task.", "labels": [], "entities": []}, {"text": "As for aSVM, the DA assumption (that the labels are the same) does not match the task.", "labels": [], "entities": []}, {"text": "In SVD-ASO, the numbers of both source examples and auxiliary problems are much smaller than those reported by.", "labels": [], "entities": []}, {"text": "TrAdaBoost uses the source examples while learning the model, but never increases the weight of the examples, and it attempts to reduce their effects.", "labels": [], "entities": [{"text": "TrAdaBoost", "start_pos": 0, "end_pos": 10, "type": "DATASET", "confidence": 0.888218879699707}]}, {"text": "Finally, we apply SVM-CW to all corpora using all features.", "labels": [], "entities": []}, {"text": "summarizes the F-score and AUC by SVM-CW with all features.", "labels": [], "entities": [{"text": "F-score", "start_pos": 15, "end_pos": 22, "type": "METRIC", "confidence": 0.9976012110710144}, {"text": "AUC", "start_pos": 27, "end_pos": 30, "type": "METRIC", "confidence": 0.9968520998954773}, {"text": "SVM-CW", "start_pos": 34, "end_pos": 40, "type": "DATASET", "confidence": 0.9548260569572449}]}, {"text": "SVM-CW is especially effective for small corpora, showing that SVM-CW can adapt source corpora to a small annotated target corpus.", "labels": [], "entities": []}, {"text": "The improvement on AIMed is small compared to the improvement on BioInfer, even though these corpora are similar in size.", "labels": [], "entities": [{"text": "BioInfer", "start_pos": 65, "end_pos": 73, "type": "DATASET", "confidence": 0.7310988306999207}]}, {"text": "One of the reasons for this is that whole abstracts are annotated in AIMed, therefore making the examples biased.", "labels": [], "entities": []}, {"text": "The difference between L2-SVM and SVM-CW + IEPA on AIMed is small, but statistically, it is significant (McNemar test, P = 0.0081).", "labels": [], "entities": []}, {"text": "In the cases of HPRD50 + IEPA, LLL + IEPA, and two folds in BioInfer + IEPA, C sis larger than Ct in Equation (2).", "labels": [], "entities": []}, {"text": "This is worth noting, because the source corpus is more weighted than the target corpus, and the prediction performance on the target corpus is improved.", "labels": [], "entities": []}, {"text": "Most methods put more trust in the target corpus than in the source corpus, and our results show that this setting is not always effective for mixing corpora.", "labels": [], "entities": []}, {"text": "The results also indicate that IEPA contains more useful information for extracting PPI than other corpora, and that using source examples aggressively is important for these combinations.", "labels": [], "entities": [{"text": "extracting PPI", "start_pos": 73, "end_pos": 87, "type": "TASK", "confidence": 0.7954883277416229}]}, {"text": "We compared the results of L2-SVM and SVM-CW + IEPA on AIMed, and found that 38 pairs were described as \"interaction\" or \"binding\" in the sentences among 61  newly found pairs.", "labels": [], "entities": []}, {"text": "This analysis is evidence that IEPA contains instances to help find such interactions, and that SVM-CW helps to collect gold pairs that lack enough supporting instances in a single corpus, by adding instances from other corpora.", "labels": [], "entities": []}, {"text": "SVM-CW missed coreferential relations that were also missed by L2-SVM.", "labels": [], "entities": []}, {"text": "This can be attributed to the fact that the coreferential information is not stored in our current feature vector; so we need an even more expressive feature space.", "labels": [], "entities": []}, {"text": "This is left as future work.", "labels": [], "entities": []}, {"text": "SVM-CW is effective on most corpus combinations, and all the models from single corpora can be improved by adding other source corpora.", "labels": [], "entities": []}, {"text": "This result is impressive, because the baselines by L2-SVM on just single corpora are already better than or at least comparable to other state-of-the-art PPI extraction systems, and also because the variety of the differences among different corpora is quite wide depending on various factors including annotation policies of the corpora ( . The results suggest that SVM-CW is useful as an ITL method.", "labels": [], "entities": [{"text": "PPI extraction", "start_pos": 155, "end_pos": 169, "type": "TASK", "confidence": 0.7780902683734894}]}], "tableCaptions": [{"text": " Table 1: The sizes of used PPI corpora. A:AIMed,  B:BioInfer, H:HPRD50, I:IEPA, and L:LLL.", "labels": [], "entities": [{"text": "BioInfer", "start_pos": 53, "end_pos": 61, "type": "METRIC", "confidence": 0.8294530510902405}, {"text": "HPRD50", "start_pos": 65, "end_pos": 71, "type": "DATASET", "confidence": 0.9372819662094116}, {"text": "IEPA", "start_pos": 75, "end_pos": 79, "type": "METRIC", "confidence": 0.777787983417511}]}, {"text": " Table 2: Classification performance on AIMed us- ing five different linear classifiers. The F-score (F)  and Area Under the ROC curve (AUC) are shown.  L2 is L2-SVM, L1 is L1-SVM, LR is logistic re- gression, AP is averaged perceptron, and CW is  confidence weighted linear classification.", "labels": [], "entities": [{"text": "F-score (F)", "start_pos": 93, "end_pos": 104, "type": "METRIC", "confidence": 0.9526080191135406}, {"text": "Area", "start_pos": 110, "end_pos": 114, "type": "METRIC", "confidence": 0.9899652600288391}, {"text": "ROC curve (AUC)", "start_pos": 125, "end_pos": 140, "type": "METRIC", "confidence": 0.9362348556518555}, {"text": "AP", "start_pos": 210, "end_pos": 212, "type": "METRIC", "confidence": 0.9810097813606262}]}, {"text": " Table 3: Comparison of methods on multiple corpora. Our feature vector without graph features is used.  The source corpora with the best F-scores are reported for aSVM, TrAdaBoost, and SVM-CW.", "labels": [], "entities": [{"text": "aSVM", "start_pos": 164, "end_pos": 168, "type": "DATASET", "confidence": 0.8501390218734741}, {"text": "TrAdaBoost", "start_pos": 170, "end_pos": 180, "type": "DATASET", "confidence": 0.5315991044044495}]}, {"text": " Table 4: F-score and AUC by SVM-CW. Rows correspond to a target corpus, and columns a source  corpus. A:AIMed, B:BioInfer, H:HPRD50, I:IEPA, and L:LLL corpora. \"all\" signifies that all source  corpora are used as one source corpus, ignoring the differences among the corpora. For the comparison,  we show the 10-fold CV result on each target corpus.", "labels": [], "entities": [{"text": "F-score", "start_pos": 10, "end_pos": 17, "type": "METRIC", "confidence": 0.9778398871421814}, {"text": "AUC", "start_pos": 22, "end_pos": 25, "type": "METRIC", "confidence": 0.9930532574653625}, {"text": "HPRD50", "start_pos": 126, "end_pos": 132, "type": "DATASET", "confidence": 0.9072737693786621}, {"text": "IEPA", "start_pos": 136, "end_pos": 140, "type": "METRIC", "confidence": 0.8452157378196716}]}, {"text": " Table 6: Comparison with the results by Airola  et al. (2008). A:AIMed, B:BioInfer, H:HPRD50,  I:IEPA, and L:LLL corpora. The results with the  highest F-score from Table 4 are reported as the  results for SVM-CW.", "labels": [], "entities": [{"text": "IEPA", "start_pos": 98, "end_pos": 102, "type": "METRIC", "confidence": 0.8848472833633423}, {"text": "F-score", "start_pos": 153, "end_pos": 160, "type": "METRIC", "confidence": 0.996099591255188}, {"text": "SVM-CW", "start_pos": 207, "end_pos": 213, "type": "DATASET", "confidence": 0.8520839214324951}]}, {"text": " Table 5: Comparison with previous PPI extraction results on the AIMed corpus. The numbers of positive  and all examples, precision (P), recall (R), F-score (F), and AUC are shown. The result with the highest  F-score from", "labels": [], "entities": [{"text": "AIMed corpus", "start_pos": 65, "end_pos": 77, "type": "DATASET", "confidence": 0.9113454222679138}, {"text": "precision (P)", "start_pos": 122, "end_pos": 135, "type": "METRIC", "confidence": 0.9506312161684036}, {"text": "recall (R)", "start_pos": 137, "end_pos": 147, "type": "METRIC", "confidence": 0.9591250419616699}, {"text": "F-score (F)", "start_pos": 149, "end_pos": 160, "type": "METRIC", "confidence": 0.9445832967758179}, {"text": "AUC", "start_pos": 166, "end_pos": 169, "type": "METRIC", "confidence": 0.9977943897247314}, {"text": "F-score", "start_pos": 210, "end_pos": 217, "type": "METRIC", "confidence": 0.9834342002868652}]}]}