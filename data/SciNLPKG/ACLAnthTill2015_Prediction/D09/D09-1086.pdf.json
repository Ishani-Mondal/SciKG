{"title": [{"text": "Parser Adaptation and Projection with Quasi-Synchronous Grammar Features *", "labels": [], "entities": []}], "abstractContent": [{"text": "We connect two scenarios in structured learning: adapting a parser trained on one corpus to another annotation style, and projecting syntactic annotations from one language to another.", "labels": [], "entities": []}, {"text": "We propose quasi-synchronous grammar (QG) features for these structured learning tasks.", "labels": [], "entities": []}, {"text": "That is, we score a aligned pair of source and target trees based on local features of the trees and the alignment.", "labels": [], "entities": []}, {"text": "Our quasi-synchronous model assigns positive probability to any alignment of any trees, in contrast to asynchronous grammar, which would insist on some form of structural parallelism.", "labels": [], "entities": []}, {"text": "In monolingual dependency parser adaptation , we achieve high accuracy in translating among multiple annotation styles for the same sentence.", "labels": [], "entities": [{"text": "monolingual dependency parser adaptation", "start_pos": 3, "end_pos": 43, "type": "TASK", "confidence": 0.7295501157641411}, {"text": "accuracy", "start_pos": 62, "end_pos": 70, "type": "METRIC", "confidence": 0.9985225796699524}]}, {"text": "On the more difficult problem of cross-lingual parser projection, we learn a dependency parser fora target language by using bilingual text, an English parser, and automatic word alignments.", "labels": [], "entities": [{"text": "cross-lingual parser projection", "start_pos": 33, "end_pos": 64, "type": "TASK", "confidence": 0.7943014105161031}]}, {"text": "Our experiments show that unsupervised QG projection improves on parses trained using only high-precision projected annotations and far outperforms, by more than 35% absolute dependency accuracy, learning an unsu-pervised parser from raw target-language text alone.", "labels": [], "entities": [{"text": "QG projection", "start_pos": 39, "end_pos": 52, "type": "TASK", "confidence": 0.8002959787845612}, {"text": "accuracy", "start_pos": 186, "end_pos": 194, "type": "METRIC", "confidence": 0.5212168097496033}]}, {"text": "When a few target-language parse trees are available, projection gives a boost equivalent to doubling the number of target-language trees.", "labels": [], "entities": []}, {"text": "* The first author would like to thank the Center for Intelligent Information Retrieval at UMass Amherst.", "labels": [], "entities": [{"text": "Intelligent Information Retrieval", "start_pos": 54, "end_pos": 87, "type": "TASK", "confidence": 0.6496289869149526}, {"text": "UMass Amherst", "start_pos": 91, "end_pos": 104, "type": "DATASET", "confidence": 0.7909001410007477}]}, {"text": "We would also like to thank Noah Smith and Rebecca Hwa for helpful discussions and the anonymous reviewers for their suggestions for improving the paper.", "labels": [], "entities": [{"text": "Noah Smith and Rebecca Hwa", "start_pos": 28, "end_pos": 54, "type": "DATASET", "confidence": 0.786460018157959}]}], "introductionContent": [], "datasetContent": [{"text": "Our experiments compare learning on target language text to learning on parallel text.", "labels": [], "entities": []}, {"text": "In the latter case, we compare learning from high-precision one-to-one alignments alone, to learning from all alignments using a QG.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Adapting a parser to a new annotation style. We learn to parse in a \"target\" style (wide column label) given some  number (narrow column label) of supervised target-style training sentences. As a font of additional features, all training and  test sentences have already been augmented with parses in some \"source\" style (row label): either gold-standard parses (an  oracle experiment) or else the output of a parser trained on 18k source trees (more realistic). If we have 0 training sentences, we  simply output the source-style parse. But with 10 or 100 target-style training sentences, each off-diagonal block learns to adapt,  mostly closing the gap with the diagonal block in the same column. In the diagonal blocks, source and target styles match, and  the QG parser degrades performance when acting as a \"stacked\" parser.", "labels": [], "entities": []}, {"text": " Table 2: Precision and recall of direct dependency projection  via one-to-one links alone.", "labels": [], "entities": [{"text": "Precision", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9635207056999207}, {"text": "recall", "start_pos": 24, "end_pos": 30, "type": "METRIC", "confidence": 0.989227294921875}, {"text": "dependency projection", "start_pos": 41, "end_pos": 62, "type": "TASK", "confidence": 0.63213250041008}]}, {"text": " Table 3: Test accuracy with unsupervised training methods", "labels": [], "entities": [{"text": "accuracy", "start_pos": 15, "end_pos": 23, "type": "METRIC", "confidence": 0.9911606907844543}]}]}