{"title": [{"text": "Convolution Kernels on Constituent, Dependency and Sequential Structures for Relation Extraction", "labels": [], "entities": [{"text": "Relation Extraction", "start_pos": 77, "end_pos": 96, "type": "TASK", "confidence": 0.8878168761730194}]}], "abstractContent": [{"text": "This paper explores the use of innovative kernels based on syntactic and semantic structures fora target relation extraction task.", "labels": [], "entities": [{"text": "target relation extraction task", "start_pos": 98, "end_pos": 129, "type": "TASK", "confidence": 0.6978642866015434}]}, {"text": "Syntax is derived from constituent and dependency parse trees whereas semantics concerns to entity types and lexical sequences.", "labels": [], "entities": []}, {"text": "We investigate the effectiveness of such representations in the automated relation extraction from texts.", "labels": [], "entities": [{"text": "relation extraction from texts", "start_pos": 74, "end_pos": 104, "type": "TASK", "confidence": 0.8109724149107933}]}, {"text": "We process the above data by means of Support Vector Machines along with the syntactic tree, the partial tree and the word sequence kernels.", "labels": [], "entities": []}, {"text": "Our study on the ACE 2004 corpus illustrates that the combination of the above kernels achieves high effectiveness and significantly improves the current state-of-the-art.", "labels": [], "entities": [{"text": "ACE 2004 corpus", "start_pos": 17, "end_pos": 32, "type": "DATASET", "confidence": 0.9779378970464071}]}], "introductionContent": [{"text": "Relation Extraction (RE) is defined in ACE as the task of finding relevant semantic relations between pairs of entities in texts.", "labels": [], "entities": [{"text": "Relation Extraction (RE)", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.8837174057960511}]}, {"text": "shows part of a document from ACE 2004 corpus, a collection of news articles.", "labels": [], "entities": [{"text": "ACE 2004 corpus", "start_pos": 30, "end_pos": 45, "type": "DATASET", "confidence": 0.9370035529136658}]}, {"text": "In the text, the relation between president and NBC's entertainment division describes the relationship between the first entity (person) and the second (organization) where the person holds a managerial position.", "labels": [], "entities": []}, {"text": "Several approaches have been proposed for automatically learning semantic relations from texts.", "labels": [], "entities": [{"text": "automatically learning semantic relations from texts", "start_pos": 42, "end_pos": 94, "type": "TASK", "confidence": 0.7510903924703598}]}, {"text": "Among others, there has been increased interest in the application of kernel methods (.", "labels": [], "entities": []}, {"text": "Their main property is the ability of exploiting a huge amount of This work has been partially funded by the LiveMemories project (http://www.livememories.org/) and Expert System (http://www.expertsystem.net/) research grant.", "labels": [], "entities": []}, {"text": "Jeff Zucker, the longtime executive producer of NBC's \"Today\" program, will be named Friday as the new president of NBC's entertainment division, replacing Garth Ancier, NBC executives said.", "labels": [], "entities": []}, {"text": "features without an explicit feature representation.", "labels": [], "entities": []}, {"text": "This can be done by computing a kernel function between a pair of linguistic objects, where such function is a kind of similarity measure satisfying certain properties.", "labels": [], "entities": []}, {"text": "An example is the sequence kernel (), where the objects are strings of characters and the kernel function computes the number of common subsequences of characters in the two strings.", "labels": [], "entities": []}, {"text": "Such substrings are then weighted according to a decaying factor penalizing longer ones.", "labels": [], "entities": []}, {"text": "In the same line, Tree Kernels count the number of subtree shared by two input trees.", "labels": [], "entities": []}, {"text": "An example is that of syntactic (or subset) tree kernel (SST), where trees encode grammatical derivations.", "labels": [], "entities": [{"text": "syntactic (or subset) tree kernel (SST)", "start_pos": 22, "end_pos": 61, "type": "TASK", "confidence": 0.6780952036380767}]}, {"text": "Previous work on the use of kernels for RE has exploited some similarity measures over diverse features () or subsequence kernels over dependency graphs (.", "labels": [], "entities": [{"text": "RE", "start_pos": 40, "end_pos": 42, "type": "TASK", "confidence": 0.9650729298591614}]}, {"text": "More specifically, () use kernels over dependency trees, which showed much lower accuracy than feature-based methods (.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 81, "end_pos": 89, "type": "METRIC", "confidence": 0.9977502226829529}]}, {"text": "One problem of the dependency kernels above is that they do not exploit the overall structural aspects of dependency trees.", "labels": [], "entities": []}, {"text": "A more effective solution is the application of convolution kernels to constituent parse trees () but this is not satisfactory from a general per-spective since dependency structures offer some unique advantages, which should be exploited by an appropriate kernel.", "labels": [], "entities": []}, {"text": "Therefore, studying convolution tree kernels for dependency trees is worthwhile also considering that, to the best of our knowledge, these models have not been previously used for relation extraction 1 task.", "labels": [], "entities": [{"text": "relation extraction 1 task", "start_pos": 180, "end_pos": 206, "type": "TASK", "confidence": 0.9105316698551178}]}, {"text": "Additionally, sequence kernels should be included in such global study since some of their forms have not been applied to RE.", "labels": [], "entities": []}, {"text": "In this paper, we study and evaluate diverse convolution and sequence kernels for the RE problem by providing several kernel combinations on constituent and dependency trees and sequential structures.", "labels": [], "entities": [{"text": "RE problem", "start_pos": 86, "end_pos": 96, "type": "TASK", "confidence": 0.9385996460914612}]}, {"text": "To fully exploit the potential of dependency trees, in addition to the SST kernel, we applied the partial tree (PT) kernel proposed in), which is a general convolution tree kernel adaptable for dependency structures.", "labels": [], "entities": []}, {"text": "We also investigate various sequence kernels (e.g. the word sequence kernel (WSK) () by incorporating dependency structures into word sequences.", "labels": [], "entities": []}, {"text": "These are also enriched by including information from constituent parse trees.", "labels": [], "entities": []}, {"text": "We conduct experiments on the standard ACE 2004 newswire and broadcast news domain.", "labels": [], "entities": [{"text": "ACE 2004 newswire and broadcast news domain", "start_pos": 39, "end_pos": 82, "type": "DATASET", "confidence": 0.8160352749483926}]}, {"text": "The results show that although some kernels are less effective than others, they exhibit properties that are complementary to each other.", "labels": [], "entities": []}, {"text": "In particular, we found that relation extraction can benefit from increasing the feature space by combining kernels (with a simple summation) exploiting the two different parsing paradigms.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 29, "end_pos": 48, "type": "TASK", "confidence": 0.942629486322403}]}, {"text": "Our experiments on RE show that the current composite kernel, which is constituent-based is more effective than those based on dependency trees and individual sequence kernel but at the same time their combinations, i.e. dependency plus constituent trees, improve the state-of-the-art in RE.", "labels": [], "entities": [{"text": "RE", "start_pos": 19, "end_pos": 21, "type": "TASK", "confidence": 0.8967597484588623}]}, {"text": "More interestingly, also the combinations of various sequence kernels gain significant better performance than the current state-of-the-art ( ).", "labels": [], "entities": []}, {"text": "Overall, these results are interesting for the computational linguistics research since they show that the above two parsing paradigms provide different and important information fora semantic task such as RE.", "labels": [], "entities": []}, {"text": "Regarding sequence-based kernels, the WSK gains better performance than previous sequence and dependency models for RE.", "labels": [], "entities": []}, {"text": "A review of previous work on RE is described in Section 2.", "labels": [], "entities": [{"text": "RE", "start_pos": 29, "end_pos": 31, "type": "TASK", "confidence": 0.9542723298072815}]}, {"text": "Section 3 introduces support vector machines and kernel methods whereas our specific kernels for RE are described is Section 4.", "labels": [], "entities": []}, {"text": "The experiments and conclusions are presented in sections 5 and 6, respectively.", "labels": [], "entities": []}], "datasetContent": [{"text": "Our experiments aim at investigating the effectiveness of convolution kernels adapted to syntactic parse trees and various sequence kernels for the RE task.", "labels": [], "entities": [{"text": "RE task", "start_pos": 148, "end_pos": 155, "type": "TASK", "confidence": 0.9284110069274902}]}, {"text": "For this purpose, we use the subset and partial tree kernel over different kinds of trees, namely constituent and dependency syntactic parse trees.", "labels": [], "entities": []}, {"text": "Diverse sequences are applied individually and in combination together.", "labels": [], "entities": []}, {"text": "We consider our task of relation extraction as a classification problem where categories are relation types.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 24, "end_pos": 43, "type": "TASK", "confidence": 0.8862617313861847}]}, {"text": "All pairs of entity mentions in the same sentence are taken to generate potential relations, which will be processed as positive and negative examples.", "labels": [], "entities": []}, {"text": "We use the newswire and broadcast news domain in the English portion of the ACE 2004 corpus provided by LDC.", "labels": [], "entities": [{"text": "ACE 2004 corpus provided by LDC", "start_pos": 76, "end_pos": 107, "type": "DATASET", "confidence": 0.8598006765047709}]}, {"text": "This data portion includes 348 documents and 4400 relation instances.", "labels": [], "entities": []}, {"text": "It defines seven entity types and seven relation types.", "labels": [], "entities": []}, {"text": "Every relation is assigned one of the seven types: Physical, Person/Social, Employment/Membership/-Subsidiary, Agent-Artifact, PER/ORG Affiliation, GPE Affiliation, and Discourse.", "labels": [], "entities": [{"text": "PER/ORG Affiliation", "start_pos": 127, "end_pos": 146, "type": "METRIC", "confidence": 0.6764908358454704}, {"text": "GPE Affiliation", "start_pos": 148, "end_pos": 163, "type": "METRIC", "confidence": 0.7504481375217438}]}, {"text": "For sake of space, we do not explain these relationships here, nevertheless, they are explicitly described in the ACE document guidelines.", "labels": [], "entities": [{"text": "ACE document guidelines", "start_pos": 114, "end_pos": 137, "type": "DATASET", "confidence": 0.9519169330596924}]}, {"text": "There are 4400 positive and 38,696 negative examples when generating pairs of entity mentions as potential relations.", "labels": [], "entities": []}, {"text": "Documents are parsed using Stanford Parser ( to produce parse trees.", "labels": [], "entities": [{"text": "Stanford Parser", "start_pos": 27, "end_pos": 42, "type": "DATASET", "confidence": 0.8829576373100281}]}, {"text": "Potential relations are generated by iterating all pairs of entity mentions in the same sentence.", "labels": [], "entities": []}, {"text": "Entity information, namely entity type, is integrated into parse trees.", "labels": [], "entities": []}, {"text": "To train and test our binary relation classifier, we used SVMs.", "labels": [], "entities": []}, {"text": "Here, relation detection is formulated as a multiclass classification problem.", "labels": [], "entities": [{"text": "relation detection", "start_pos": 6, "end_pos": 24, "type": "TASK", "confidence": 0.9667907953262329}, {"text": "multiclass classification", "start_pos": 44, "end_pos": 69, "type": "TASK", "confidence": 0.7046774178743362}]}, {"text": "The one vs. rest strategy is employed by selecting the instance with largest margin as the final answer.", "labels": [], "entities": []}, {"text": "For experimentation, we use 5-fold cross-validation with the Tree Kernel Tools) (available at http://disi.unitn.it/\u02dcmoschitt/Tree-Kernel.htm).", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Results on the ACE 2004 evaluation test  set. Six structures were experimented over the  constituent and dependency trees.", "labels": [], "entities": [{"text": "ACE 2004 evaluation test  set", "start_pos": 25, "end_pos": 54, "type": "DATASET", "confidence": 0.9291608929634094}]}, {"text": " Table 2: Performance comparison on the ACE  2004 data with different kernel setups.", "labels": [], "entities": [{"text": "ACE  2004 data", "start_pos": 40, "end_pos": 54, "type": "DATASET", "confidence": 0.9789635936419169}]}]}