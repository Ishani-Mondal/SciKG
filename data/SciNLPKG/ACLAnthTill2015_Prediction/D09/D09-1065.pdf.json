{"title": [{"text": "EEG responds to conceptual stimuli and corpus semantics", "labels": [], "entities": []}], "abstractContent": [{"text": "(2008) demonstrated that corpus-extracted models of semantic knowledge can predict neural activation patterns recorded using fMRI.", "labels": [], "entities": []}, {"text": "This could be a very powerful technique for evaluating conceptual models extracted from corpora; however, fMRI is expensive and imposes strong constraints on data collection.", "labels": [], "entities": []}, {"text": "Following on experiments that demonstrated that EEG activation patterns encode enough information to discriminate broad conceptual categories, we show that corpus-based semantic representations can predict EEG activation patterns with significant accuracy, and we evaluate the relative performance of different corpus-models on this task.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 247, "end_pos": 255, "type": "METRIC", "confidence": 0.9823472499847412}]}], "introductionContent": [{"text": "Models of semantic relatedness induced from corpus data have proven effective in a number of empirical tasks) and there is increasing interest in whether distributional information extracted from corpora correlates with aspects of speakers' semantic knowledge: see,,,,, among many others.", "labels": [], "entities": []}, {"text": "For this purpose, corpus models have been tested on datasets that are based on semantic judgements (metalinguistic or meta-cognitive intuitions about synonymy, semantic distance, category-membership) or behavioural experiments (semantic priming, property generation, free association).", "labels": [], "entities": [{"text": "property generation", "start_pos": 246, "end_pos": 265, "type": "TASK", "confidence": 0.7294538170099258}]}, {"text": "While all these data are valuable, they are indirect reflections of semantic knowledge, and when the predictions they make diverge from those of corpora, interpretation is problematic: is the corpus model missing essential aspects of semantics, or are nonsemantic factors biasing the data elicited from informants?", "labels": [], "entities": []}, {"text": "Reading semantic processes and representations directly from the brain would bean ideal way to get around these limitations.", "labels": [], "entities": []}, {"text": "Until recently, analysis of linguistic quantities using neural data collected with EEG (measurement at the scalp of voltages induced by neuronal firing) or fMRI (measurement of changes of oxygen concentrations in the brain tied to cognitive processes) had neither the advantages of corpora (scale) nor of informants (finer grained judgements).", "labels": [], "entities": []}, {"text": "However, some clear patterns of differential activity have been found for broad semantic classes.", "labels": [], "entities": []}, {"text": "Viewing images of natural (typically animals and plants) and non-natural (typically artefacts like tools or vehicles) objects elicits different loci of activity in fMRI) and EEG, that persist across participants.", "labels": [], "entities": [{"text": "EEG", "start_pos": 174, "end_pos": 177, "type": "METRIC", "confidence": 0.8310325741767883}]}, {"text": "Differences have also been found in response to auditorily or visually presented words of different lexical classes, such as abstract/concrete, and verb/noun.", "labels": [], "entities": []}, {"text": "But interpretation of such group results remains somewhat difficult, as they maybe consistent with more than one distinction: the natural/artefactual division just mentioned, may rather be between living/nonliving entities, dynamic/static entities, or be based on embodied experience (e.g. manipulable or not).", "labels": [], "entities": []}, {"text": "More recently, however, machine learning and other numerical techniques have been successfully applied to extract semantic information from neural data in a more discriminative fashion, down to the level of individual concepts.", "labels": [], "entities": []}, {"text": "The work presented here builds on two strands of previous work: use EEG data to perform semantic categorisation on single stimuli; and introduce an fMRIbased method that detects word level distinctions by learning associations between features of neural activity and semantic features derived from a corpus.", "labels": [], "entities": []}, {"text": "We combine these innovations by introducing a method that extracts featural representations from the EEG signal, and uses corpusbased models to predict word level distinctions in patterns of EEG activity.", "labels": [], "entities": []}, {"text": "The proposed method achieves a performance level significantly above chance (also when distinguishing between concepts from the same semantic category, e.g., dog and cat), and approaching that achieved with fMRI.", "labels": [], "entities": []}, {"text": "The paper proceeds as follows.", "labels": [], "entities": []}, {"text": "The next section describes a simple behavioural experiment where Italian-speaking participants had to name photographic images of mammals and tools while their EEG activity was being recorded, and continues to detail how the rich and multidimensional signals collected were reduced to a small set of optimally informative features using anew method.", "labels": [], "entities": []}, {"text": "Section 3 describes a series of corpus-based semantic models derived from both a raw-text web corpus, and from various parsings of a conventional corpus.", "labels": [], "entities": []}, {"text": "In Section 4 we describe the training of a series of linear models, that each learn the associations between a set of corpus semantic features and an individual EEG activity feature.", "labels": [], "entities": []}, {"text": "By combining these models it is possible to predict the EEG activity pattern fora single unseen word, and compare this to the observed pattern for the corresponding concept.", "labels": [], "entities": []}, {"text": "Results (Section 5) show that these predictions succeed at a level significantly above chance, both for coarser distinctions between words in different superordinate categories (e.g., differentiating between drill and gorilla), and, at least for the model based on the larger web corpus, for those within the same category (e.g., drill vs spanner, koala vs gorilla).", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 4: Accuracy levels for individual participant  sessions, yahoo-mitchell web corpus", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9971670508384705}, {"text": "yahoo-mitchell web corpus", "start_pos": 64, "end_pos": 89, "type": "DATASET", "confidence": 0.9413996338844299}]}, {"text": " Table 5: Accuracy levels for individual participant  sessions, repubblica-window-svd", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9982181191444397}]}, {"text": " Table 3: Comparison across corpus models, with percentage concept coverage, mean cross-subject per- centage prediction accuracy and standard deviation;  * p < 0.05,  *   *  p < 0.01", "labels": [], "entities": [{"text": "mean cross-subject per- centage prediction accuracy", "start_pos": 77, "end_pos": 128, "type": "METRIC", "confidence": 0.6426216534205845}]}]}