{"title": [{"text": "Towards Discipline-Independent Argumentative Zoning: Evidence from Chemistry and Computational Linguistics", "labels": [], "entities": [{"text": "Discipline-Independent Argumentative Zoning", "start_pos": 8, "end_pos": 51, "type": "TASK", "confidence": 0.6458313564459482}]}], "abstractContent": [{"text": "Argumentative Zoning (AZ) is an analysis of the argumentative and rhetorical structure of a scientific paper.", "labels": [], "entities": [{"text": "Argumentative Zoning (AZ) is an analysis of the argumentative and rhetorical structure of a scientific paper", "start_pos": 0, "end_pos": 108, "type": "TASK", "confidence": 0.6194728132751253}]}, {"text": "It has been shown to be reliably used by independent human coders, and has proven useful for various information access tasks.", "labels": [], "entities": [{"text": "information access tasks", "start_pos": 101, "end_pos": 125, "type": "TASK", "confidence": 0.8261783123016357}]}, {"text": "Annotation experiments have however so far been restricted to one discipline, computational linguistics (CL).", "labels": [], "entities": [{"text": "computational linguistics (CL)", "start_pos": 78, "end_pos": 108, "type": "TASK", "confidence": 0.7849992394447327}]}, {"text": "Here, we present a more informative AZ scheme with 15 categories in place of the original 7, and show that it can be applied to the life sciences as well as to CL.", "labels": [], "entities": [{"text": "AZ", "start_pos": 36, "end_pos": 38, "type": "METRIC", "confidence": 0.7044222354888916}]}, {"text": "We use a domain expert to encode basic knowledge about the subject (such as terminology and domain specific rules for individual categories) as part of the annotation guidelines.", "labels": [], "entities": []}, {"text": "Our results show that non-expert human coders can then use these guidelines to reliably annotate this scheme in two domains, chemistry and computational linguistics.", "labels": [], "entities": []}], "introductionContent": [{"text": "define the task of Argumentative Zoning (AZ) as a sentence-by-sentence classification with mutually exclusive categories from the annotation scheme given in.", "labels": [], "entities": [{"text": "Argumentative Zoning (AZ)", "start_pos": 19, "end_pos": 44, "type": "TASK", "confidence": 0.8242727518081665}]}, {"text": "The reasoning behind the categories is inspired by the notion of a knowledge claim: the act of writing a paper corresponds to an attempt of claiming ownership fora new piece of knowledge, which is to be integrated into the repository of scientific knowledge in the authors' field by the process of peer review and publication.", "labels": [], "entities": []}, {"text": "In the cause of this process, the authors have to convince the reviewers that the knowledge claim of the paper is valid.", "labels": [], "entities": []}, {"text": "What AZ aims to model, then, are some of the relevant stages in this argument.", "labels": [], "entities": []}, {"text": "We divide the paper into zones, OTHER, OWN and BACKGROUND.", "labels": [], "entities": [{"text": "OTHER", "start_pos": 32, "end_pos": 37, "type": "METRIC", "confidence": 0.996669352054596}, {"text": "OWN", "start_pos": 39, "end_pos": 42, "type": "METRIC", "confidence": 0.9526140689849854}, {"text": "BACKGROUND", "start_pos": 47, "end_pos": 57, "type": "METRIC", "confidence": 0.8959525227546692}]}, {"text": "These are defined on the basis of who owns the knowledge claim in the corresponding segment.", "labels": [], "entities": []}, {"text": "There are also two categories which are defined by their relationship to existing work, BASIS and CONTRAST.", "labels": [], "entities": [{"text": "BASIS", "start_pos": 88, "end_pos": 93, "type": "METRIC", "confidence": 0.9786576628684998}, {"text": "CONTRAST", "start_pos": 98, "end_pos": 106, "type": "METRIC", "confidence": 0.7339557409286499}]}, {"text": "That means that parts of the AZ scheme are similar to citation function classification schemes from the area of citation content analysis, and to automatic citation function classification).", "labels": [], "entities": [{"text": "citation function classification", "start_pos": 54, "end_pos": 86, "type": "TASK", "confidence": 0.648130069176356}, {"text": "citation content analysis", "start_pos": 112, "end_pos": 137, "type": "TASK", "confidence": 0.6486546595891317}, {"text": "citation function classification", "start_pos": 156, "end_pos": 188, "type": "TASK", "confidence": 0.6292583545049032}]}, {"text": "The remaining categories, AIM and TEXTUAL, fulfil different rhetorical functions for the presentation of the paper.", "labels": [], "entities": [{"text": "AIM", "start_pos": 26, "end_pos": 29, "type": "METRIC", "confidence": 0.692967414855957}, {"text": "TEXTUAL", "start_pos": 34, "end_pos": 41, "type": "METRIC", "confidence": 0.9537531733512878}]}, {"text": "AIM points out the paper's main knowledge claim, a rhetorical move which maybe repeated in the conclusion and the introduction.", "labels": [], "entities": [{"text": "AIM", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.962826132774353}]}, {"text": "TEXTUAL explains the physical location of information, e.g., by giving a section overview or presenting a summary of a subsection.", "labels": [], "entities": []}, {"text": "On the basis of human-annotated training material, AZ can be automatically classified using supervised machine learning.", "labels": [], "entities": []}, {"text": "Figure 1: AZ Annotation Scheme ().", "labels": [], "entities": [{"text": "AZ Annotation Scheme", "start_pos": 10, "end_pos": 30, "type": "DATASET", "confidence": 0.9199092388153076}]}], "datasetContent": [{"text": "The annotators were the co-developers of the annotation scheme and the authors of this paper.", "labels": [], "entities": []}, {"text": "Whereas all three annotators have good background knowledge in CL, the largest difference between them concerns their expertise in chemistry: Annotator A is a PhD-level chemist, Annotator B has two years' of undergraduate training in chemistry and can therefore be considered a chemical semi-expert, and Annotator C has no specialised chemistry knowledge.", "labels": [], "entities": []}, {"text": "As agreement measure we choose the Kappa coefficient \u03ba, the agreement measure predominantly used in natural language processing research.", "labels": [], "entities": [{"text": "natural language processing research", "start_pos": 100, "end_pos": 136, "type": "TASK", "confidence": 0.6886120215058327}]}, {"text": "\u03ba corrects raw agreement P (A) for agreement by chance P (E): No matter how many items or annotators, or how the categories are distributed, \u03ba = 0 when there is no agreement other than what would be expected by chance, and \u03ba = 1 when agreement is perfect.", "labels": [], "entities": []}, {"text": "If two annotators agree less than expected by chance, \u03ba can also be negative.", "labels": [], "entities": []}, {"text": "Chance agreement P (E) is defined as the level of agreement which would be reached by random annotation using the same distribution of categories as the real annotators.", "labels": [], "entities": []}, {"text": "All work done here is reported in terms of Fleiss' \u03ba.", "labels": [], "entities": [{"text": "Fleiss' \u03ba", "start_pos": 43, "end_pos": 52, "type": "METRIC", "confidence": 0.9560211896896362}]}, {"text": "1 \u03ba is also designed to abstract over the number of annotators as its formula relies on the proportion of expected vs. observed pairwise agreements possible in a pool.", "labels": [], "entities": []}, {"text": "That is, \u03ba fork annotators will bean average of the values of \u03ba taking all possible m-tuples of annotators from the annotator pool (with m < k).", "labels": [], "entities": []}, {"text": "As aside effect of its definition of random agreement, \u03ba treats agreement in a rare category as more surprising, and rewards such agreement more than an agreement in a frequent category.", "labels": [], "entities": []}, {"text": "This is a desirable property, because we are more interested in the performance of the rare rhetorical categories than we are in the performance of the more frequent zone categories.", "labels": [], "entities": []}], "tableCaptions": []}