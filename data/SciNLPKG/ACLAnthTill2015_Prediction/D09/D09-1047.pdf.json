{"title": [{"text": "Joint Learning of Preposition Senses and Semantic Roles of Prepositional Phrases", "labels": [], "entities": []}], "abstractContent": [{"text": "The sense of a preposition is related to the semantics of its dominating prepositional phrase.", "labels": [], "entities": []}, {"text": "Knowing the sense of a preposition could help to correctly classify the semantic role of the dominating preposi-tional phrase and vice versa.", "labels": [], "entities": []}, {"text": "In this paper , we propose a joint probabilistic model for word sense disambiguation of prepositions and semantic role labeling of prepo-sitional phrases.", "labels": [], "entities": [{"text": "word sense disambiguation", "start_pos": 59, "end_pos": 84, "type": "TASK", "confidence": 0.6894740164279938}, {"text": "semantic role labeling of prepo-sitional phrases", "start_pos": 105, "end_pos": 153, "type": "TASK", "confidence": 0.764541874329249}]}, {"text": "Our experiments on the PropBank corpus show that jointly learning the word sense and the semantic role leads to an improvement over state-of-the-art individual classifier models on the two tasks.", "labels": [], "entities": [{"text": "PropBank corpus", "start_pos": 23, "end_pos": 38, "type": "DATASET", "confidence": 0.9434299468994141}]}], "introductionContent": [{"text": "Word sense disambiguation (WSD) and semantic role labeling (SRL) are two key components in natural language processing to find a semantic representation fora sentence.", "labels": [], "entities": [{"text": "Word sense disambiguation (WSD)", "start_pos": 0, "end_pos": 31, "type": "TASK", "confidence": 0.7725295225779215}, {"text": "semantic role labeling (SRL)", "start_pos": 36, "end_pos": 64, "type": "TASK", "confidence": 0.7868773440519968}]}, {"text": "Semantic role labeling is the task of determining the constituents of a sentence that represent semantic arguments with respect to a predicate and labeling each with a semantic role.", "labels": [], "entities": [{"text": "Semantic role labeling", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.7493244608243307}]}, {"text": "Word sense disambiguation tries to determine the correct meaning of a word in a given context.", "labels": [], "entities": [{"text": "Word sense disambiguation", "start_pos": 0, "end_pos": 25, "type": "TASK", "confidence": 0.7234500348567963}]}, {"text": "Ambiguous words occur frequently in normal English text.", "labels": [], "entities": []}, {"text": "One word class which is both frequent and highly ambiguous is preposition.", "labels": [], "entities": []}, {"text": "The different senses of a preposition express different relations between the preposition complement and the rest of the sentence.", "labels": [], "entities": []}, {"text": "Semantic roles and word senses offer two different inventories of \"meaning\" for prepositional phrases (PP): semantic roles distinguish between different verb complements while word senses intend to fully capture the preposition semantics at a more fine-grained level.", "labels": [], "entities": []}, {"text": "In this paper, we use the semantic roles from the PropBank corpus and the preposition senses from the Preposition Project (TPP).", "labels": [], "entities": [{"text": "PropBank corpus", "start_pos": 50, "end_pos": 65, "type": "DATASET", "confidence": 0.9663867354393005}]}, {"text": "Both corpora are explained in more detail in the following section.", "labels": [], "entities": []}, {"text": "The relationship between the two inventories (PropBank semantic roles and TPP preposition senses) is not a simple one-to-one mapping, as we can see from the following examples: \u2022 She now lives with relatives [in sense1 Alabama.]", "labels": [], "entities": []}, {"text": "ARGM-LOC \u2022 The envelope arrives [in sense1 the mail.]", "labels": [], "entities": [{"text": "ARGM-LOC", "start_pos": 0, "end_pos": 8, "type": "METRIC", "confidence": 0.7674664855003357}]}, {"text": "ARG4 \u2022 [In sense5 separate statements] ARGM-LOC the two sides said they want to have \"further discussions.\"", "labels": [], "entities": [{"text": "ARG4", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.9558731317520142}, {"text": "ARGM-LOC", "start_pos": 39, "end_pos": 47, "type": "DATASET", "confidence": 0.8249948620796204}]}, {"text": "In the first two examples, the sense of the preposition in is annotated as sense 1 (\"surrounded by or enclosed in\"), following the definitions of the TPP, but the semantic roles are different.", "labels": [], "entities": []}, {"text": "In the first example the semantic role is a locative adjunctive argument (ARGM-LOC), while in the second example it is ARG4 which denotes the \"end point or destination\" of the arriving action 1 . In the first and third example, the semantic roles are the same, but the preposition senses are different, i.e., sense 1 and sense 5 (\"inclusion or involvement\").", "labels": [], "entities": [{"text": "ARGM-LOC", "start_pos": 74, "end_pos": 82, "type": "METRIC", "confidence": 0.818035364151001}, {"text": "ARG4", "start_pos": 119, "end_pos": 123, "type": "METRIC", "confidence": 0.5735962986946106}]}, {"text": "Preposition senses and semantic roles provide two different views on the semantics of PPs.", "labels": [], "entities": []}, {"text": "Knowing the semantic role of the PP could be helpful to successfully disambiguate the sense of the preposition.", "labels": [], "entities": []}, {"text": "Likewise, the preposition sense could provide valuable information to classify the semantic role of the PP.", "labels": [], "entities": []}, {"text": "This is especially so for the semantic roles ARGM-LOC and ARGM-TMP, where we expect a strong correlation with spatial and temporal preposition senses respectively.", "labels": [], "entities": [{"text": "ARGM-LOC", "start_pos": 45, "end_pos": 53, "type": "DATASET", "confidence": 0.6030477285385132}, {"text": "ARGM-TMP", "start_pos": 58, "end_pos": 66, "type": "DATASET", "confidence": 0.6108444929122925}]}, {"text": "In this paper, we propose a probabilistic model for joint inference on preposition senses and semantic roles.", "labels": [], "entities": []}, {"text": "For each prepositional phrase that has been identified as an argument of the predicate, we jointly infer its semantic role and the sense of the preposition that is the lexical head of the prepositional phrase.", "labels": [], "entities": []}, {"text": "That is, our model maximizes the joint probability of the semantic role and the preposition sense.", "labels": [], "entities": []}, {"text": "Previous research has shown the benefit of jointly learning semantic roles of multiple constituents ().", "labels": [], "entities": []}, {"text": "In contrast, our joint model makes predictions fora single constituent, but multiple tasks (WSD and SRL) . Our experiments show that adding the SRL information leads to statistically significant improvements over an independent, state-of-the-art WSD classifier.", "labels": [], "entities": []}, {"text": "For the SRL task, we show statistically significant improvements of our joint model over an independent, state-of-the-art SRL classifier for locative and temporal adjunctive arguments, even though the overall improvement overall semantic roles is small.", "labels": [], "entities": [{"text": "SRL task", "start_pos": 8, "end_pos": 16, "type": "TASK", "confidence": 0.9388852715492249}]}, {"text": "To the best of our knowledge, no previous research has attempted to perform preposition WSD and SRL of prepositional phrases in a joint learning approach.", "labels": [], "entities": [{"text": "preposition WSD", "start_pos": 76, "end_pos": 91, "type": "TASK", "confidence": 0.5074902474880219}]}, {"text": "The remainder of this paper is structured as follows: First, we give an introduction to the WSD and SRL task.", "labels": [], "entities": [{"text": "WSD", "start_pos": 92, "end_pos": 95, "type": "TASK", "confidence": 0.8935286998748779}, {"text": "SRL task", "start_pos": 100, "end_pos": 108, "type": "TASK", "confidence": 0.8598460853099823}]}, {"text": "Then, in Section 3, we describe the individual and joint classifier models.", "labels": [], "entities": []}, {"text": "The details of the data set used in our experiments are given in Section 4.", "labels": [], "entities": []}, {"text": "In Section 5, we present experiments and results.", "labels": [], "entities": []}, {"text": "Section 6 summarizes related work, before we conclude in the final section.", "labels": [], "entities": []}], "datasetContent": [{"text": "We evaluate the performance of the joint model on the annotated prepositional phrases in test section 23 and compare the results with the performance of the baseline models and the pipeline models.", "labels": [], "entities": []}, {"text": "shows the classification accuracy of the WSD models for each of the seven prepositions in the test section.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 25, "end_pos": 33, "type": "METRIC", "confidence": 0.9602179527282715}, {"text": "WSD", "start_pos": 41, "end_pos": 44, "type": "TASK", "confidence": 0.5033177137374878}]}, {"text": "The results show that the pipeline model and the joint model perform almost equally, with the joint model performing marginally better in the overall score.", "labels": [], "entities": []}, {"text": "The detailed scores are given in.", "labels": [], "entities": []}, {"text": "Both models outperform the baseline classifier for three of the seven prepositions: at, for, and to.", "labels": [], "entities": []}, {"text": "For the prepositions in, of, and on, the SRL feature did not affect the WSD classification accuracy significantly.", "labels": [], "entities": [{"text": "SRL", "start_pos": 41, "end_pos": 44, "type": "METRIC", "confidence": 0.8938013315200806}, {"text": "WSD classification", "start_pos": 72, "end_pos": 90, "type": "TASK", "confidence": 0.9120132625102997}, {"text": "accuracy", "start_pos": 91, "end_pos": 99, "type": "METRIC", "confidence": 0.9544910788536072}]}, {"text": "For the preposition with, the classification accuracy even dropped by about 6%.", "labels": [], "entities": [{"text": "classification", "start_pos": 30, "end_pos": 44, "type": "TASK", "confidence": 0.6026501059532166}, {"text": "accuracy", "start_pos": 45, "end_pos": 53, "type": "METRIC", "confidence": 0.8600468635559082}]}, {"text": "Performing the student's t-test, we found that the improvement for the prepositions at, for, and to is statistical significant (p < 0.05), as is the overall improvement.", "labels": [], "entities": []}, {"text": "This confirms our hypothesis that the semantic role of the prepositional phrase is a strong hint for the preposition sense.", "labels": [], "entities": []}, {"text": "However, our results also show that it is the SRL feature that brings the improvement, not the joint model, because the pipeline and joint model achieve about the same performance.", "labels": [], "entities": []}, {"text": "For the SRL task, we report the classification accuracy overall annotated prepositional phrases in the test section and the F 1 measure for the semantic roles ARGM-LOC and ARGM-TMP.", "labels": [], "entities": [{"text": "SRL task", "start_pos": 8, "end_pos": 16, "type": "TASK", "confidence": 0.9207702577114105}, {"text": "F 1 measure", "start_pos": 124, "end_pos": 135, "type": "METRIC", "confidence": 0.9791368246078491}]}, {"text": "Our SRL experiments show that a pipeline model degrades the performance.", "labels": [], "entities": [{"text": "SRL", "start_pos": 4, "end_pos": 7, "type": "TASK", "confidence": 0.7006354928016663}]}, {"text": "The reason is the relatively high degree of noise in the WSD classification and that the pipeline model does not discriminate whether the previous classifier predicts the extra feature with high or low confidence.", "labels": [], "entities": [{"text": "WSD classification", "start_pos": 57, "end_pos": 75, "type": "DATASET", "confidence": 0.6879225969314575}]}, {"text": "Instead, the model only passes on the 1-best WSD prediction, which can cause the next classifier to make a wrong classification based on the erroneous prediction of the previous step.", "labels": [], "entities": [{"text": "1-best WSD prediction", "start_pos": 38, "end_pos": 59, "type": "METRIC", "confidence": 0.6683411300182343}]}, {"text": "In principle, this problem can be mitigated by training the pipeline model on automatically predicted labels using cross-validation, but in our case we found that automatically predicted WSD labels decreased the performance of the pipeline model even more.", "labels": [], "entities": []}, {"text": "In contrast, the joint model computes the full probability distribution over the semantic roles and preposition senses.", "labels": [], "entities": []}, {"text": "If the noise level in the first classification step is low, the joint model and the pipeline model perform almost identically, as we have seen in the previous WSD experiments.", "labels": [], "entities": []}, {"text": "But if the noise level is high, the joint model can still improve while the pipeline model drops in performance.", "labels": [], "entities": []}, {"text": "Our experiments show that the joint model is more robust in the presence of noisy features than the pipeline model.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Number of annotated prepositional  phrases for each semantic role", "labels": [], "entities": []}, {"text": " Table 3: Number of annotated prepositional  phrases for each preposition", "labels": [], "entities": []}, {"text": " Table 5: F 1 measure and accuracy of the baseline,  pipeline, and joint model on the SRL task in test  section 23, statistically significant improvements  over the baseline are marked with an (*)", "labels": [], "entities": [{"text": "F", "start_pos": 10, "end_pos": 11, "type": "METRIC", "confidence": 0.9619130492210388}, {"text": "accuracy", "start_pos": 26, "end_pos": 34, "type": "METRIC", "confidence": 0.9996471405029297}, {"text": "SRL task", "start_pos": 86, "end_pos": 94, "type": "TASK", "confidence": 0.8783985674381256}]}]}