{"title": [], "abstractContent": [{"text": "In this paper, we propose a linear model-based general framework to combine k-best parse outputs from multiple parsers.", "labels": [], "entities": []}, {"text": "The proposed framework leverages on the strengths of previous system combination and re-ranking techniques in parsing by integrating them into a linear model.", "labels": [], "entities": [{"text": "parsing", "start_pos": 110, "end_pos": 117, "type": "TASK", "confidence": 0.967284083366394}]}, {"text": "As a result, it is able to fully utilize both the logarithm of the probability of each k-best parse tree from each individual parser and any additional useful features.", "labels": [], "entities": []}, {"text": "For feature weight tuning, we compare the simulated -annealing algorithm and the perceptron algorithm.", "labels": [], "entities": [{"text": "feature weight tuning", "start_pos": 4, "end_pos": 25, "type": "TASK", "confidence": 0.6862724125385284}]}, {"text": "Our experiments are carried out on both the Chinese and English Penn Treebank syntactic parsing task by combining two state-of-the-art parsing models, a head-driven lexi-calized model and a latent-annotation-based un-lexicalized model.", "labels": [], "entities": [{"text": "English Penn Treebank", "start_pos": 56, "end_pos": 77, "type": "DATASET", "confidence": 0.8196178674697876}, {"text": "syntactic parsing task", "start_pos": 78, "end_pos": 100, "type": "TASK", "confidence": 0.764245887597402}]}, {"text": "Experimental results show that our F-Scores of 85.45 on Chinese and 92.62 on English outperform the previously best-reported systems by 1.21 and 0.52, respectively.", "labels": [], "entities": [{"text": "F-Scores", "start_pos": 35, "end_pos": 43, "type": "METRIC", "confidence": 0.997075080871582}]}], "introductionContent": [{"text": "Statistical models have achieved great success in language parsing and obtained the state-of-theart results in a variety of languages.", "labels": [], "entities": [{"text": "language parsing", "start_pos": 50, "end_pos": 66, "type": "TASK", "confidence": 0.6815888285636902}]}, {"text": "In general, they can be divided into two major categories, namely lexicalized models) and un-lexicalized models (.", "labels": [], "entities": []}, {"text": "In lexicalized models, word information play a key role in modeling grammar rule generation, while un-lexicalized models usually utilize latent information derived from the parse structure diversity.", "labels": [], "entities": [{"text": "grammar rule generation", "start_pos": 68, "end_pos": 91, "type": "TASK", "confidence": 0.6735398173332214}]}, {"text": "Although the two models are different from each other in essence, both have achieved stateof-the-art results in a variety of languages and are complementary to each other (this will be empirically verified later in this paper).", "labels": [], "entities": []}, {"text": "Therefore, it is natural to combine the two models for better parsing performance.", "labels": [], "entities": [{"text": "parsing", "start_pos": 62, "end_pos": 69, "type": "TASK", "confidence": 0.9708499908447266}]}, {"text": "Besides individual parsing models, many system combination methods for parsing have been proposed) and promising performance improvements have been reported.", "labels": [], "entities": [{"text": "parsing", "start_pos": 19, "end_pos": 26, "type": "TASK", "confidence": 0.9553794264793396}, {"text": "parsing", "start_pos": 71, "end_pos": 78, "type": "TASK", "confidence": 0.9774603843688965}]}, {"text": "In addition, parsing re-ranking (Collins 2000;) has also been shown to be another effective technique to improve parsing performance.", "labels": [], "entities": [{"text": "parsing re-ranking", "start_pos": 13, "end_pos": 31, "type": "TASK", "confidence": 0.9633144438266754}, {"text": "Collins 2000;)", "start_pos": 33, "end_pos": 47, "type": "DATASET", "confidence": 0.9560840924580892}, {"text": "parsing", "start_pos": 113, "end_pos": 120, "type": "TASK", "confidence": 0.9780640602111816}]}, {"text": "This technique utilizes a bunch of linguistic features to re-rank the k-best (Huang and Chiang 2005) output on the forest level or tree level.", "labels": [], "entities": []}, {"text": "In prior work, system combination was applied on multiple parsers while re-ranking was applied on the k-best outputs of individual parsers.", "labels": [], "entities": []}, {"text": "In this paper, we propose a linear model-based general framework for multiple parsers combination.", "labels": [], "entities": []}, {"text": "The proposed framework leverages on the strengths of previous system combination and reranking methods and is open to any type of features.", "labels": [], "entities": []}, {"text": "In particular, it is capable of utilizing the logarithm of the parse tree probability from each individual parser while previous combination methods are unable to use this feature since the probabilities from different parsers are not comparable.", "labels": [], "entities": []}, {"text": "In addition, we experiment on k-best combination while previous methods are only verified on 1-best combination.", "labels": [], "entities": []}, {"text": "Finally, we apply our method in combining outputs from both the lexicalized and un-lexicalized parsers while previous methods only carryout experiments on multiple lexicalized parsers.", "labels": [], "entities": []}, {"text": "We also compare two learning algorithms in tuning the feature weights for the linear model.", "labels": [], "entities": []}, {"text": "We perform extensive experiments on the Chinese and English Penn Treebank corpus.", "labels": [], "entities": [{"text": "Chinese and English Penn Treebank corpus", "start_pos": 40, "end_pos": 80, "type": "DATASET", "confidence": 0.807165672381719}]}, {"text": "Experimental results show that our final results, an F-Score of 92.62 on English and 85.45 on Chinese, outperform the previously best-reported systems by 0.52 point and 1.21 point, respectively.", "labels": [], "entities": [{"text": "F-Score", "start_pos": 53, "end_pos": 60, "type": "METRIC", "confidence": 0.9994238615036011}]}, {"text": "This convincingly demonstrates the effectiveness of our proposed framework.", "labels": [], "entities": []}, {"text": "Our study also shows that the simulated-annealing algorithm () is more effective than the perceptron algorithm) for feature weight tuning.", "labels": [], "entities": [{"text": "feature weight tuning", "start_pos": 116, "end_pos": 137, "type": "TASK", "confidence": 0.6834361553192139}]}, {"text": "The rest of this paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 briefly reviews related work.", "labels": [], "entities": []}, {"text": "Section 3 discusses our method while section 4 presents the feature weight tuning algorithm.", "labels": [], "entities": [{"text": "feature weight tuning", "start_pos": 60, "end_pos": 81, "type": "TASK", "confidence": 0.6045571366945902}]}, {"text": "In Section 5, we report our experimental results and then conclude in Section 6.", "labels": [], "entities": []}], "datasetContent": [{"text": "We evaluate our method on both Chinese and English syntactic parsing task with the standard division on Chinese Penn Treebank Version 5.0 and WSJ English Treebank 3.0 () as shown in.", "labels": [], "entities": [{"text": "syntactic parsing", "start_pos": 51, "end_pos": 68, "type": "TASK", "confidence": 0.646376222372055}, {"text": "Chinese Penn Treebank Version 5.0", "start_pos": 104, "end_pos": 137, "type": "DATASET", "confidence": 0.836347508430481}, {"text": "WSJ English Treebank 3.0", "start_pos": 142, "end_pos": 166, "type": "DATASET", "confidence": 0.9211925119161606}]}, {"text": "We use Satoshi Sekine and Michael Collins' EVALB script modified by David Ellis for accuracy evaluation.", "labels": [], "entities": [{"text": "Collins' EVALB script", "start_pos": 34, "end_pos": 55, "type": "DATASET", "confidence": 0.6740094820658366}, {"text": "accuracy", "start_pos": 84, "end_pos": 92, "type": "METRIC", "confidence": 0.9965547323226929}]}, {"text": "We use Charniak's parser as the two individual parsers, where Charniak's parser represents the best performance of the lexicalized model and the Berkeley's parser represents the best performance of the un-lexicalized model.", "labels": [], "entities": []}, {"text": "We retrain both of them according to the division in 1.", "labels": [], "entities": []}, {"text": "The number of EM iteration process for Berkeley's parser is set to 5 on English and 6 on Chinese.", "labels": [], "entities": []}, {"text": "Both the Charniak's parser and Berkeley's parser provide function to evaluate an input parse tree's probability and output the logarithm of the probability.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2 and Table 3.  \"P\" means precision, \"R\" means recall and \"F\" is  the F1-measure (all is in % percentage metrics);  \"Charniak\" represents the parser of (Charniak  2000), \"Berkeley\" represents the parser of", "labels": [], "entities": [{"text": "precision", "start_pos": 33, "end_pos": 42, "type": "METRIC", "confidence": 0.9989381432533264}, {"text": "recall", "start_pos": 54, "end_pos": 60, "type": "METRIC", "confidence": 0.9980992674827576}, {"text": "F", "start_pos": 66, "end_pos": 67, "type": "METRIC", "confidence": 0.9297625422477722}, {"text": "F1-measure", "start_pos": 77, "end_pos": 87, "type": "METRIC", "confidence": 0.9973617196083069}]}, {"text": " Table 2. Results on Chinese", "labels": [], "entities": [{"text": "Chinese", "start_pos": 21, "end_pos": 28, "type": "DATASET", "confidence": 0.9293988347053528}]}, {"text": " Table 3. Results on English", "labels": [], "entities": [{"text": "English", "start_pos": 21, "end_pos": 28, "type": "DATASET", "confidence": 0.9180980920791626}]}, {"text": " Table 4. The statistics on the 50-best out- put for Chinese and English test set.  The small redundant rate clearly suggests that  the two parsing models are quite different and  are complementary to each other.", "labels": [], "entities": [{"text": "Chinese and English test set", "start_pos": 53, "end_pos": 81, "type": "DATASET", "confidence": 0.6631844878196717}]}, {"text": " Table 5. The oracle over 50-best output for in- dividual parser and our method", "labels": [], "entities": []}, {"text": " Table 6. F1 score on 50-best combination with  different feature configuration. \"I\" means the  constituent count, \"B\" means Berkeley parser  confidence score and \"C\" means Charniak parser  confidence score.", "labels": [], "entities": [{"text": "F1 score", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9725141525268555}]}, {"text": " Table 7. Precision and Recall score on 50-best  combination by the two parameter estimation  algorithms with significant test; \"SA.\" is simu- lated annealing, \"AP.\" is averaged perceptron,  \"P-value\" is the significant test p-value.", "labels": [], "entities": [{"text": "Precision", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9977553486824036}, {"text": "Recall", "start_pos": 24, "end_pos": 30, "type": "METRIC", "confidence": 0.9990929365158081}, {"text": "AP.", "start_pos": 161, "end_pos": 164, "type": "METRIC", "confidence": 0.9726390242576599}]}, {"text": " Table 9. Performance with Charniak parser  enhanced by re-ranking; \"baseline\" is the per- formance of the combination of", "labels": [], "entities": []}, {"text": " Table 10. Performance with Charniak parser  enhanced by re-ranking plus self-training", "labels": [], "entities": []}, {"text": " Table 11. Accuracy comparison on Chinese System  F1-Measure", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 11, "end_pos": 19, "type": "METRIC", "confidence": 0.9974105954170227}, {"text": "Chinese System  F1-Measure", "start_pos": 34, "end_pos": 60, "type": "DATASET", "confidence": 0.9492965936660767}]}, {"text": " Table 12. Accuracy comparison on English.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 11, "end_pos": 19, "type": "METRIC", "confidence": 0.9609034061431885}]}]}