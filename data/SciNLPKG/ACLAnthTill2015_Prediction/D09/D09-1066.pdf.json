{"title": [{"text": "A Comparison of Windowless and Window-Based Computational Association Measures as Predictors of Syntagmatic Human Associations", "labels": [], "entities": []}], "abstractContent": [{"text": "Distance-based (windowless) word asso-cation measures have only very recently appeared in the NLP literature and their performance compared to existing win-dowed or frequency-based measures is largely unknown.", "labels": [], "entities": []}, {"text": "We conduct a large-scale empirical comparison of a variety of distance-based and frequency-based measures for the reproduction of syntagmatic human assocation norms.", "labels": [], "entities": []}, {"text": "Overall, our results show an improvement in the pre-dictive power of windowless over win-dowed measures.", "labels": [], "entities": []}, {"text": "This provides support to some of the previously published theoretical advantages and makes window-less approaches a promising avenue to explore further.", "labels": [], "entities": []}, {"text": "This study also serves as a first comparison of windowed methods across numerous human association datasets.", "labels": [], "entities": []}, {"text": "During this comparison we also introduce some novel variations of window-based measures which perform as well as or better in the human association norm task than established measures.", "labels": [], "entities": []}], "introductionContent": [{"text": "Automatic discovery of semantically associated words has attracted a large amount of attention in the last decades and a host of computational association measures have been proposed to deal with this task (see Section 2).", "labels": [], "entities": [{"text": "Automatic discovery of semantically associated words", "start_pos": 0, "end_pos": 52, "type": "TASK", "confidence": 0.7434795598189036}]}, {"text": "These measures traditionally rely on the co-ocurrence frequency of two words in a corpus to estimate a relatedness score.", "labels": [], "entities": []}, {"text": "There has been a recent emergence of distancebased language modelling techiques in NLP) in which the number of tokens separating words is the essential quantity.", "labels": [], "entities": []}, {"text": "While some of this work has considered distance-based alternatives to conventional association measures, there has been no principled empirical evaluation of these measures as predictors of human association.", "labels": [], "entities": []}, {"text": "We remedy this by conducting a thorough comparison of a wide variety of frequency-based and distance-based measures as predictors of human association scores as elicited in several different free word association tasks.", "labels": [], "entities": []}, {"text": "In this work we focus on first-order association measures as predictors of syntagmatic associations.", "labels": [], "entities": []}, {"text": "This is in contrast to second and higher-order measures which are better predictors of paradigmatic associations, or word similarity.", "labels": [], "entities": []}, {"text": "The distinction between syntagmatic and paradigmatic relationship types is neither exact nor mutually exclusive, and many paradigmatic relationships can be observed syntagmatically in the text.", "labels": [], "entities": []}, {"text": "Roughly in keeping with), we hereby regard paradigmatic assocations as those based largely on word similarity (i.e. including those typically classed as synonyms, antonyms, hypernyms, hyponyms etc), whereas syntagmatic associations are all those words which strongly invoke one another yet which cannot readily be said to be similar.", "labels": [], "entities": []}, {"text": "Typically these will have an identifiable semantic or grammatical relationship (meronym/holonym: stem -flower, verb/object: eat -food etc), or may have harder-to-classify topical or idiomatic relationships (family -Christmas, rock -roll).", "labels": [], "entities": []}, {"text": "We will show in Section 3.2 that syntagmatic relations by themselves constitute a substantial 25-40% of the strongest human responses to cue words.", "labels": [], "entities": []}, {"text": "Although the automatic detection of these assocations in text has received less attention than that of paradigmatic associations, they are nonetheless important in applications such as the resolution of bridging anaphora).", "labels": [], "entities": [{"text": "resolution", "start_pos": 189, "end_pos": 199, "type": "TASK", "confidence": 0.9672628045082092}]}, {"text": "1 Furthermore, first-order associations are often the basis of higher-order vector wordspace models used for predicting paradigmatic relationships: i.e. through the observation of words which share similar sets of syntagmatic associations.", "labels": [], "entities": []}, {"text": "Therefore improvements made at the level we are concerned with may reasonably be expected to carry through to applications which hinge on the identification of paradigmatic relationships.", "labels": [], "entities": []}, {"text": "After a discussion of previous work in Section 2, we formulate the exact association measures and parameter settings which we compare in Section 3, where we also introduce the corpora and human association sets used.", "labels": [], "entities": []}, {"text": "Then, by using evaluations similar to those described in ( and by, we show that the best distance-based measures correlate better overall with human association scores than do the best window based configurations (see Section 4), and that they also serve as better predictors of the strongest human associations (see Section 5).", "labels": [], "entities": []}], "datasetContent": [{"text": "For evaluating agreement between corpus-derived associations and human associations, we use Spearman's Rank correlation.", "labels": [], "entities": []}, {"text": "This is appropriate because we are primarily interested in the relative ranking of word pair associations (in order to predict particularly strong responses, for example).", "labels": [], "entities": []}, {"text": "Although some studies have used Pearson's correlation, the various association measures explored here are not linear within each another and it would be inappropriate to evaluate them under the assumption of a linear relationship with the human norms.", "labels": [], "entities": [{"text": "Pearson's correlation", "start_pos": 32, "end_pos": 53, "type": "METRIC", "confidence": 0.7792683641115824}]}, {"text": "Two of the human datasets, Kent and Minnesota, though collected independently, are based on the same set of 100 cue words established by.", "labels": [], "entities": [{"text": "Kent", "start_pos": 27, "end_pos": 31, "type": "DATASET", "confidence": 0.8585307002067566}]}, {"text": "Therefore by performing a rank correlation of these two datasets with one another, (each of which was produced by pooling the responses of some 1000 people) we can get a useful upper-bound for correlations: if a computer-based system were to exceed this upper-bound in correlations with either dataset, then we would need to suspect it of over-fitting.", "labels": [], "entities": []}, {"text": "As a baseline, we use the corpus frequency of the response word.", "labels": [], "entities": []}, {"text": "The simple assumption is that the more frequent a word is, the more likely it is to appear as a human response independent of the cue given.", "labels": [], "entities": []}, {"text": "This is also the simplest formulation which does not assign equal scores to the various possible responses, and which is therefore capable of producing a rank-list of predictions.", "labels": [], "entities": []}, {"text": "shows the Spearman's rank correlation co-efficients across all paramaterisations of all association measures (frequency-based on the left, and distance-based on the right), with each human dataset, for the 10 million word corpus.", "labels": [], "entities": [{"text": "Spearman's rank correlation", "start_pos": 10, "end_pos": 37, "type": "METRIC", "confidence": 0.521560475230217}]}, {"text": "Emboldened are the best performing windowed and windowless configurations for each dataset.", "labels": [], "entities": []}, {"text": "The difference of these figures over the baseline is highly significant (p < 0.0001 inmost cases).", "labels": [], "entities": []}, {"text": "The panels to the right show summary statistics for these figures, and for the 1 million word corpus (for which full figures are not included owing to space limitations).", "labels": [], "entities": []}, {"text": "These statistics include the performance of the baseline, where relevant the estimated upperbound (see Section 4.1), and the difference in performance of the distance-based method over the window-based.", "labels": [], "entities": []}, {"text": "The accuracy and error figures are based on the co-efficients of determination (r 2 ) and are expressed both as a relative improvement inaccuracy (how much closer (r 2 ) is to 1 under the distance-based approach) and reduction in error (how much further r 2 is from zero).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.9994481205940247}, {"text": "error", "start_pos": 17, "end_pos": 22, "type": "METRIC", "confidence": 0.9553583264350891}, {"text": "error", "start_pos": 230, "end_pos": 235, "type": "METRIC", "confidence": 0.9768307209014893}]}, {"text": "Also the significance of the difference in the r values is given.", "labels": [], "entities": [{"text": "significance", "start_pos": 9, "end_pos": 21, "type": "METRIC", "confidence": 0.9781749248504639}]}, {"text": "For the strongest human response to each cue in the human datasets, its rank was calculated amongst all 33, 000 possible responses to that cue, according to each association measure and parameterisation.", "labels": [], "entities": []}, {"text": "Where there were tied scores for various responses, a median rank was assigned.", "labels": [], "entities": []}, {"text": "As a rough upper bound, we would be impressed by a computer system which was able to predict the most popular human response as often as a randomly selected individual in the human experiments happened to chose the most popular response.", "labels": [], "entities": []}, {"text": "illustrates the range of computational association scores attributed to only the strongest human responses.", "labels": [], "entities": []}, {"text": "The position of the strongest human response to each cue word, within the computationally-ranked lists of all possible responses, is plotted on the y-axis.", "labels": [], "entities": []}, {"text": "For each association measure the points are ordered from best to worst along the x-axis.", "labels": [], "entities": []}, {"text": "In the ideal case therefore, the most popular human response for every cue word would appear at rank 1 amongst the computer-generated responses, resulting in a horizonal line at y=1.", "labels": [], "entities": []}, {"text": "Generally speaking therefore, the smaller the area above a line the better the performance of a measure.", "labels": [], "entities": []}, {"text": "Three summary statistics can be derived from 1) The number of most popular human responses that are correctly predicted by a measure is indicated by the x-position at which its line departs from y=1.", "labels": [], "entities": []}, {"text": "This can be seen to be around 11% for CWCD sig and is zero for the two best PMI parameterizations, with other illustrated measures performing intermediately.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Human association datasets", "labels": [], "entities": []}]}