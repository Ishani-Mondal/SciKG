{"title": [{"text": "Re-Ranking Models Based-on Small Training Data for Spoken Language Understanding", "labels": [], "entities": [{"text": "Spoken Language Understanding", "start_pos": 51, "end_pos": 80, "type": "TASK", "confidence": 0.8718142509460449}]}], "abstractContent": [{"text": "The design of practical language applications by means of statistical approaches requires annotated data, which is one of the most critical constraint.", "labels": [], "entities": []}, {"text": "This is particularly true for Spoken Dialog Systems since considerably domain-specific conceptual annotation is needed to obtain accurate Language Understanding models.", "labels": [], "entities": [{"text": "Spoken Dialog", "start_pos": 30, "end_pos": 43, "type": "TASK", "confidence": 0.8014557063579559}]}, {"text": "Since data annotation is usually costly, methods to reduce the amount of data are needed.", "labels": [], "entities": [{"text": "data annotation", "start_pos": 6, "end_pos": 21, "type": "TASK", "confidence": 0.7717964351177216}]}, {"text": "In this paper, we show that better feature representations serve the above purpose and that structure kernels provide the needed improved representation.", "labels": [], "entities": []}, {"text": "Given the relatively high computational cost of kernel methods, we apply them to just re-rank the list of hypotheses provided by a fast generative model.", "labels": [], "entities": []}, {"text": "Experiments with Support Vector Machines and different kernels on two different dialog corpora show that our re-ranking models can achieve better results than state-of-the-art approaches when small data is available.", "labels": [], "entities": []}], "introductionContent": [{"text": "Spoken Dialog Systems carryout automatic speech recognition and shallow natural language understanding by heavily relying on statistical models.", "labels": [], "entities": [{"text": "Spoken Dialog", "start_pos": 0, "end_pos": 13, "type": "TASK", "confidence": 0.5992833971977234}, {"text": "automatic speech recognition", "start_pos": 31, "end_pos": 59, "type": "TASK", "confidence": 0.6502632598082224}, {"text": "natural language understanding", "start_pos": 72, "end_pos": 102, "type": "TASK", "confidence": 0.8167598644892374}]}, {"text": "These in turn need annotated data describing the application domain.", "labels": [], "entities": []}, {"text": "Such annotation is far the most expensive part of the system design.", "labels": [], "entities": []}, {"text": "Therefore, methods reducing the amount of labeled data can speedup and lower the overall amount of work.", "labels": [], "entities": []}, {"text": "Among others, Spoken Language Understanding (SLU) is an important component of the systems above, which requires training data to translate a spoken sentence into its meaning representation based on semantic constituents.", "labels": [], "entities": [{"text": "Spoken Language Understanding (SLU)", "start_pos": 14, "end_pos": 49, "type": "TASK", "confidence": 0.8579970002174377}]}, {"text": "These are conceptual units instantiated by sequences of words.", "labels": [], "entities": []}, {"text": "In the last decade two major approaches have been proposed to automatically map words in concepts: (i) generative models, whose parameters refer to the joint probability of concepts and constituents; and (ii) discriminative models, which learn a classification function based on conditional probabilities of concepts given words.", "labels": [], "entities": []}, {"text": "A simple but effective generative model is the one based on Finite State Transducers.", "labels": [], "entities": [{"text": "generative", "start_pos": 23, "end_pos": 33, "type": "TASK", "confidence": 0.9640196561813354}]}, {"text": "It performs SLU as a translation process from words to concepts using Finite State Transducers (FST).", "labels": [], "entities": [{"text": "SLU", "start_pos": 12, "end_pos": 15, "type": "TASK", "confidence": 0.9609061479568481}]}, {"text": "An example of discriminative model used for SLU is the one based on Support Vector Machines (SVMs), as shown in.", "labels": [], "entities": [{"text": "SLU", "start_pos": 44, "end_pos": 47, "type": "TASK", "confidence": 0.9531075358390808}]}, {"text": "In this approach, data is mapped into a vector space and SLU is performed as a classification problem using Maximal Margin Classifiers.", "labels": [], "entities": [{"text": "Maximal Margin Classifiers", "start_pos": 108, "end_pos": 134, "type": "TASK", "confidence": 0.6041513582070669}]}, {"text": "A relatively more recent approach for SLU is based on Conditional Random Fields (CRF) ().", "labels": [], "entities": [{"text": "SLU", "start_pos": 38, "end_pos": 41, "type": "TASK", "confidence": 0.9842494130134583}]}, {"text": "CRFs are undirected graphical and discriminative models.", "labels": [], "entities": []}, {"text": "They use conditional probabilities to account for many feature dependencies without the need of explicitly representing such dependencies.", "labels": [], "entities": []}, {"text": "Generative models have the advantage to be more robust to overfitting on training data, while discriminative models are more robust to irrelevant features.", "labels": [], "entities": []}, {"text": "Both approaches, used separately, have shown good accuracy), but they have very different characteristics and the way they encode prior knowledge is very different, thus designing models that take into account characteristics of both approaches are particularly promising.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 50, "end_pos": 58, "type": "METRIC", "confidence": 0.9993083477020264}]}, {"text": "In this paper, we propose a method for SLU based on generative and discriminative models: the former uses FSTs to generate a list of SLU hypotheses, which are re-ranked by SVMs.", "labels": [], "entities": [{"text": "SLU", "start_pos": 39, "end_pos": 42, "type": "TASK", "confidence": 0.9660927057266235}]}, {"text": "To effectively design our re-ranker, we use all pos-sible word/concept subsequences with gaps of the spoken sentence as features (i.e. all possible ngrams).", "labels": [], "entities": []}, {"text": "Gaps allow for encoding long distance dependencies between words in relatively small sequences.", "labels": [], "entities": [{"text": "encoding long distance dependencies between words", "start_pos": 15, "end_pos": 64, "type": "TASK", "confidence": 0.791109303633372}]}, {"text": "Since the space of such features is huge, we adopted kernel methods, i.e. sequence kernels) and tree kernels ( to implicitly encode them along with other structural information in SVMs.", "labels": [], "entities": []}, {"text": "We experimented with different approaches for training the discriminative models and two different corpora: the french MEDIA corpus () and a corpus made available by the European project LUNA 1 ().", "labels": [], "entities": [{"text": "french MEDIA corpus", "start_pos": 112, "end_pos": 131, "type": "DATASET", "confidence": 0.6903145710627238}]}, {"text": "In particular, the new contents with respect to our previous work) are: \u2022 We designed anew sequential structure (SK2) and two new hierarchical tree structures (MULTILEVEL and FEATURES) for re-ranking models (see Section 4.2).", "labels": [], "entities": [{"text": "MULTILEVEL", "start_pos": 160, "end_pos": 170, "type": "METRIC", "confidence": 0.8694278001785278}, {"text": "FEATURES", "start_pos": 175, "end_pos": 183, "type": "METRIC", "confidence": 0.9771100282669067}]}, {"text": "The latter combined with two different tree kernels originate four new different models.", "labels": [], "entities": []}, {"text": "\u2022 We experimented with automatic speech transcriptions thus assessing the robustness to noise of our models.", "labels": [], "entities": [{"text": "automatic speech transcriptions", "start_pos": 23, "end_pos": 54, "type": "TASK", "confidence": 0.6629270613193512}]}, {"text": "\u2022 We compare our models against Conditional Random Field (CRF) approaches described in (, which are the current state-of-the-art in SLU.", "labels": [], "entities": []}, {"text": "Learning curves clearly show that our models improve CRF, especially when small data sets are used.", "labels": [], "entities": [{"text": "CRF", "start_pos": 53, "end_pos": 56, "type": "TASK", "confidence": 0.9298985004425049}]}, {"text": "The remainder of the paper is organized as follows: Section 2 introduces kernel methods for structured data, Section 3 describes the generative model producing the initial hypotheses whereas Section 4 presents the discriminative models for re-ranking them.", "labels": [], "entities": []}, {"text": "The experiments and results are reported in Section 5 and the conclusions are drawn in Section 6.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section, we describe the corpora, parameters, models and results of our experiments on reranking for SLU.", "labels": [], "entities": [{"text": "SLU", "start_pos": 109, "end_pos": 112, "type": "TASK", "confidence": 0.6413708329200745}]}, {"text": "Our baseline is constituted by the error rate of systems solely based on either FST or SVMs.", "labels": [], "entities": []}, {"text": "The re-ranking models are built on the FST output, which in turn is applied to both manual or automatic transcriptions.", "labels": [], "entities": [{"text": "FST output", "start_pos": 39, "end_pos": 49, "type": "DATASET", "confidence": 0.6150806993246078}]}, {"text": "Given the small size of LUNA corpus, we did not carried out any parameterization thus we used default or a priori parameters.", "labels": [], "entities": [{"text": "LUNA corpus", "start_pos": 24, "end_pos": 35, "type": "DATASET", "confidence": 0.8891901969909668}]}, {"text": "We experimented with LUNA and three different re-rankers obtained with the combination of SVMs with STK, PTK and SK, described in Section 4.", "labels": [], "entities": [{"text": "LUNA", "start_pos": 21, "end_pos": 25, "type": "METRIC", "confidence": 0.6349362134933472}, {"text": "PTK", "start_pos": 105, "end_pos": 108, "type": "METRIC", "confidence": 0.8669154644012451}, {"text": "SK", "start_pos": 113, "end_pos": 115, "type": "METRIC", "confidence": 0.9767190217971802}]}, {"text": "The initial annotation to be re-ranked is the list of the ten best hypotheses output by an FST model.", "labels": [], "entities": []}, {"text": "We point out that, on the large Media dataset the processing time is considerably high 2 so we could not run all the models.", "labels": [], "entities": [{"text": "Media dataset", "start_pos": 32, "end_pos": 45, "type": "DATASET", "confidence": 0.9884568452835083}]}, {"text": "We trained all the SCLMs used in our experiments with the SRILM toolkit and we used an interpolated model for probability estimation with the Kneser-Ney discount).", "labels": [], "entities": [{"text": "SRILM toolkit", "start_pos": 58, "end_pos": 71, "type": "DATASET", "confidence": 0.8890181481838226}]}, {"text": "We then converted the model in an FST again with SRILM toolkit.", "labels": [], "entities": [{"text": "FST", "start_pos": 34, "end_pos": 37, "type": "TASK", "confidence": 0.5430288314819336}, {"text": "SRILM toolkit", "start_pos": 49, "end_pos": 62, "type": "DATASET", "confidence": 0.7610651552677155}]}, {"text": "The model used to obtain the SVM baseline for concept classification was trained using YamCHA ().", "labels": [], "entities": [{"text": "concept classification", "start_pos": 46, "end_pos": 68, "type": "TASK", "confidence": 0.6827101707458496}]}, {"text": "As re-ranking models based on structure kernels and SVMs, we used the SVM-Light-TK toolkit (available at disi.unitn.it/moschitti).", "labels": [], "entities": []}, {"text": "For \u03bb (see Section 3), costfactor and trade-off parameters, we used, 0.4, 1 and 1, respectively (i.e. the default parameters).", "labels": [], "entities": []}, {"text": "The number m of hypotheses was always set to 10.", "labels": [], "entities": []}, {"text": "The CRF model we compare with was trained with the CRF++ tool, available at http://crfpp.sourceforge.net/.", "labels": [], "entities": []}, {"text": "The model is equivalent to the one described in (. As features, we used word and morpho-syntactic categories in a window of with respect to the current token, plus bigrams of concept tags (see) and the CRF++ website for more details).", "labels": [], "entities": [{"text": "CRF++ website", "start_pos": 202, "end_pos": 215, "type": "DATASET", "confidence": 0.9428754448890686}]}, {"text": "Such model is very effective for SLU.", "labels": [], "entities": [{"text": "SLU", "start_pos": 33, "end_pos": 36, "type": "TASK", "confidence": 0.9237735271453857}]}, {"text": "In (, it is compared with other four models (Stochastic Finite State Transducers, Support Vector Machines, Machine Translation, PositionalBased Log-linear model) and it is by far the best on MEDIA.", "labels": [], "entities": [{"text": "Machine Translation", "start_pos": 107, "end_pos": 126, "type": "TASK", "confidence": 0.8001421689987183}, {"text": "MEDIA", "start_pos": 191, "end_pos": 196, "type": "DATASET", "confidence": 0.8641449809074402}]}, {"text": "Additionally, in, a similar CRF model was compared with FST and SVMs on ATIS and on a different The number of parameters of the models and the number of training approaches make the exhaustive experimentation very expensive in terms of processing time, which would be roughly between 2 and 3 months of atypical workstation.", "labels": [], "entities": [{"text": "ATIS", "start_pos": 72, "end_pos": 76, "type": "DATASET", "confidence": 0.9535133242607117}]}, {"text": "We ran SLU experiments on manual and automatic transcriptions.", "labels": [], "entities": []}, {"text": "The latter are produced by a speech recognizer with a WER of 41.0% and 31.4% on the LUNA and the MEDIA test sets, respectively.", "labels": [], "entities": [{"text": "speech recognizer", "start_pos": 29, "end_pos": 46, "type": "TASK", "confidence": 0.6661783307790756}, {"text": "WER", "start_pos": 54, "end_pos": 57, "type": "METRIC", "confidence": 0.9995750784873962}, {"text": "LUNA", "start_pos": 84, "end_pos": 88, "type": "DATASET", "confidence": 0.7780914902687073}, {"text": "MEDIA test sets", "start_pos": 97, "end_pos": 112, "type": "DATASET", "confidence": 0.8989824056625366}]}], "tableCaptions": [{"text": " Table 1: Statistics on the LUNA corpus", "labels": [], "entities": []}, {"text": " Table 2: Statistics on the MEDIA corpus", "labels": [], "entities": [{"text": "MEDIA", "start_pos": 28, "end_pos": 33, "type": "DATASET", "confidence": 0.7397417426109314}]}, {"text": " Table 3: CER of SVMs using STK, PTK and SK  on LUNA (manual transcriptions). The Baselines,  FST and SVMs alone, show a CER of 23.2% and  26.3%, respectively.", "labels": [], "entities": [{"text": "CER", "start_pos": 10, "end_pos": 13, "type": "METRIC", "confidence": 0.9891356229782104}, {"text": "FST", "start_pos": 94, "end_pos": 97, "type": "DATASET", "confidence": 0.6288577914237976}, {"text": "CER", "start_pos": 121, "end_pos": 124, "type": "METRIC", "confidence": 0.9982313513755798}]}, {"text": " Table 4: Results of SLU experiments on MEDIA  and LUNA test set (manual transcriptions).", "labels": [], "entities": [{"text": "MEDIA", "start_pos": 40, "end_pos": 45, "type": "DATASET", "confidence": 0.814596951007843}, {"text": "LUNA test set", "start_pos": 51, "end_pos": 64, "type": "DATASET", "confidence": 0.8444037636121114}]}, {"text": " Table 5: Results of SLU experiments on MEDIA  and LUNA test set (automatic transcriptions with  a WER 31.4% on MEDIA and 41% on LUNA)", "labels": [], "entities": [{"text": "LUNA test set", "start_pos": 51, "end_pos": 64, "type": "DATASET", "confidence": 0.8615750074386597}, {"text": "WER", "start_pos": 99, "end_pos": 102, "type": "METRIC", "confidence": 0.9971827268600464}]}]}