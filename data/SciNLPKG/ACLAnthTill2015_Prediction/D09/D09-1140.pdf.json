{"title": [], "abstractContent": [{"text": "In this research we aim to detect subjective sentences in multimodal conversations.", "labels": [], "entities": []}, {"text": "We introduce a novel technique wherein subjective patterns are learned from both labeled and unlabeled data, using n-gram word sequences with varying levels of lexical instantiation.", "labels": [], "entities": []}, {"text": "Applying this technique to meeting speech and email conversations, we gain significant improvement over state-of-the-art approaches.", "labels": [], "entities": []}, {"text": "Furthermore, we show that coupling the pattern-based approach with features that capture characteristics of general conversation structure yields additional improvement.", "labels": [], "entities": []}], "introductionContent": [{"text": "Conversations are rich in subjectivity.", "labels": [], "entities": []}, {"text": "Conversation participants agree and disagree with one other, argue for and against various proposals, and generally take turns expressing their private states.", "labels": [], "entities": []}, {"text": "Being able to separate these subjective utterances from more objective utterances would greatly facilitate the analysis, mining and summarization of a large number of conversations.", "labels": [], "entities": [{"text": "summarization", "start_pos": 132, "end_pos": 145, "type": "TASK", "confidence": 0.964485764503479}]}, {"text": "Two of the most prevalent conversational media are meetings and emails.", "labels": [], "entities": []}, {"text": "Face-to-face meetings enable numerous people to exchange a large amount of information and opinions in a short period of time, while emails allow for concise exchanges between potentially far-flung participants.", "labels": [], "entities": []}, {"text": "Meetings and emails can also feed into one another, with face-to-face meetings occurring at regular intervals and emails continuing the conversations in the interim.", "labels": [], "entities": []}, {"text": "This poses several interesting questions, such as whether subjective utterances are more or less likely to be found in email exchanges compared with meetings, and whether the ratios of positive and negative subjective utterances differ between the two modalities.", "labels": [], "entities": []}, {"text": "In this paper we describe a novel approach for predicting subjectivity, and test it in two sets of experiments on meetings and emails.", "labels": [], "entities": [{"text": "predicting subjectivity", "start_pos": 47, "end_pos": 70, "type": "TASK", "confidence": 0.8756160140037537}]}, {"text": "Our approach combines anew general purpose method for learning subjective patterns, with features that capture basic characteristics of conversation structure across modalities.", "labels": [], "entities": []}, {"text": "The subjective patterns are essentially n-gram sequences with varying levels of lexical instantiation, and we demonstrate how they can be learned from both labeled and unlabeled data.", "labels": [], "entities": []}, {"text": "The conversation features capture structural characteristics of multimodal conversations as well as participant information.", "labels": [], "entities": []}, {"text": "We test our approach in two sets of experiments.", "labels": [], "entities": []}, {"text": "The goal of the first set of experiments is to discriminate subjective from non-subjective utterances, comparing the novel approach to existing state-of-the-art techniques.", "labels": [], "entities": []}, {"text": "In the second set of experiments, the goal is to discriminate positivesubjective and negative-subjective utterances, establishing their polarity.", "labels": [], "entities": []}, {"text": "In both sets of experiments, we assess the impact of features relating to conversation structure.", "labels": [], "entities": []}, {"text": "have approached the problem of detecting subjectivity in meeting speech by using a variety of multimodal features such as prosodic features, word n-grams, character n-grams and phoneme n-grams.", "labels": [], "entities": []}, {"text": "For subjectivity detection, they found that a combination of all features was best, while prosodic features were less useful for discriminating between positive and negative utterances.", "labels": [], "entities": [{"text": "subjectivity detection", "start_pos": 4, "end_pos": 26, "type": "TASK", "confidence": 0.7613382339477539}]}, {"text": "They found character n-grams to be particularly useful.", "labels": [], "entities": []}, {"text": "presented a method for learning subjective extraction patterns from a large amount of data, which takes subjective and nonsubjective text as input, and outputs significant lexico-syntactic patterns.", "labels": [], "entities": [{"text": "learning subjective extraction patterns", "start_pos": 23, "end_pos": 62, "type": "TASK", "confidence": 0.7092116251587868}]}, {"text": "These patterns are based on syntactic structure output by the Sundance shal-low dependency parser ().", "labels": [], "entities": []}, {"text": "They are extracted by exhaustively applying syntactic templates such as < subj > passive-verb and active-verb < dobj > to a training corpus, with an extracted pattern for every instantiation of the syntactic template.", "labels": [], "entities": []}, {"text": "These patterns are scored according to probability of relevance given the pattern and frequency of the pattern.", "labels": [], "entities": []}, {"text": "Because these patterns are based on syntactic structure, they can represent subjective expressions that are not fixed word sequences and would therefore be missed by a simple n-gram approach.", "labels": [], "entities": []}, {"text": "explore feature subsumption for opinion detection, where a given feature may subsume another feature representationally if the strings matched by the first feature include all of the strings matched by the second feature.", "labels": [], "entities": [{"text": "opinion detection", "start_pos": 32, "end_pos": 49, "type": "TASK", "confidence": 0.7924531996250153}]}, {"text": "To give their own example, the unigram happy subsumes the bigram very happy.", "labels": [], "entities": []}, {"text": "The first feature will behaviorally subsume the second if it representationally subsumes the second and has roughly the same information gain, within an acceptable margin.", "labels": [], "entities": []}, {"text": "They show that they can improve opinion analysis results by modeling these relations and reducing the feature set.", "labels": [], "entities": [{"text": "opinion analysis", "start_pos": 32, "end_pos": 48, "type": "TASK", "confidence": 0.7827427387237549}]}], "datasetContent": [{"text": "In this section we describe the corpora used, the relevant subjectivity annotation, and the statistical classifiers employed.", "labels": [], "entities": []}, {"text": "For these experiments we use a maximum entropy classifier using the liblinear toolkit 2.", "labels": [], "entities": []}, {"text": "Feature subset selection is carried out by calculating the F-statistic for each feature, ranking the features according to the statistic, and training on increasingly smaller subsets of feature in a cross-validation procedure, ultimately choosing the feature set with the highest balanced accuracy during cross-validation.", "labels": [], "entities": [{"text": "Feature subset selection", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.6388983527819315}, {"text": "F-statistic", "start_pos": 59, "end_pos": 70, "type": "METRIC", "confidence": 0.9560450315475464}, {"text": "accuracy", "start_pos": 289, "end_pos": 297, "type": "METRIC", "confidence": 0.9928036332130432}]}, {"text": "Because the annotated portions of our corpora are fairly small (20 meetings, 40 email threads), we employ a leave-one-out method for training and testing rather than using dedicated training and test sets.", "labels": [], "entities": []}, {"text": "For the polarity labeling task applied to the BC3 corpus, we pool all of the sentences and perform 10-fold cross-validation at the sentence level.", "labels": [], "entities": [{"text": "polarity labeling", "start_pos": 8, "end_pos": 25, "type": "TASK", "confidence": 0.7061080634593964}, {"text": "BC3 corpus", "start_pos": 46, "end_pos": 56, "type": "DATASET", "confidence": 0.8942059278488159}]}, {"text": "We employ two sets of metrics for evaluating all classifiers: precision/recall/f-measure and the receiver operator characteristic (ROC) curve.", "labels": [], "entities": [{"text": "precision", "start_pos": 62, "end_pos": 71, "type": "METRIC", "confidence": 0.9990707635879517}, {"text": "recall", "start_pos": 72, "end_pos": 78, "type": "METRIC", "confidence": 0.66008460521698}, {"text": "receiver operator characteristic (ROC) curve", "start_pos": 97, "end_pos": 141, "type": "METRIC", "confidence": 0.8945581912994385}]}, {"text": "The ROC curve plots the true-positive/false-positive ratio while the posterior threshold is varied, and we report the area under the curve (AUROC) as the measure of interest.", "labels": [], "entities": [{"text": "ROC", "start_pos": 4, "end_pos": 7, "type": "METRIC", "confidence": 0.9757323265075684}, {"text": "AUROC)", "start_pos": 140, "end_pos": 146, "type": "METRIC", "confidence": 0.9827119708061218}]}, {"text": "Random performance would feature an AUROC of approximately 0.5, while perfect classification would yield an AUROC of 1.", "labels": [], "entities": [{"text": "AUROC", "start_pos": 36, "end_pos": 41, "type": "METRIC", "confidence": 0.806830644607544}, {"text": "AUROC", "start_pos": 108, "end_pos": 113, "type": "METRIC", "confidence": 0.7306594848632812}]}, {"text": "The advantage of the AUROC score compared with precision/recall/f-measure is that it evaluates a given classifier across all thresholds, indicating the classifier's overall discriminating power.", "labels": [], "entities": [{"text": "AUROC score", "start_pos": 21, "end_pos": 32, "type": "METRIC", "confidence": 0.8289655447006226}, {"text": "precision", "start_pos": 47, "end_pos": 56, "type": "METRIC", "confidence": 0.9989160299301147}, {"text": "recall", "start_pos": 57, "end_pos": 63, "type": "METRIC", "confidence": 0.7810083627700806}]}, {"text": "This metric is also known to be appropriate when class distributions are skewed, as is our case.", "labels": [], "entities": []}, {"text": "For completeness we report both AUROC and p/r/f, but our discussions focus primarily on the AUROC comparisons.", "labels": [], "entities": [{"text": "AUROC", "start_pos": 32, "end_pos": 37, "type": "DATASET", "confidence": 0.8126075863838196}, {"text": "AUROC", "start_pos": 92, "end_pos": 97, "type": "DATASET", "confidence": 0.9206246137619019}]}], "tableCaptions": [{"text": " Table 2: Example Pos. and Neg. Patterns (AMI)", "labels": [], "entities": []}, {"text": " Table 3: Example Subjective Patterns (BLOG06)", "labels": [], "entities": [{"text": "BLOG06", "start_pos": 39, "end_pos": 45, "type": "METRIC", "confidence": 0.871430516242981}]}, {"text": " Table 5: P/R/F Results, Subjectivity Task", "labels": [], "entities": []}]}