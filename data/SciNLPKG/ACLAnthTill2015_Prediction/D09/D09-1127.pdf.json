{"title": [{"text": "Bilingually-Constrained (Monolingual) Shift-Reduce Parsing", "labels": [], "entities": [{"text": "Bilingually-Constrained", "start_pos": 0, "end_pos": 23, "type": "METRIC", "confidence": 0.9186010956764221}, {"text": "Shift-Reduce Parsing", "start_pos": 38, "end_pos": 58, "type": "TASK", "confidence": 0.8603970110416412}]}], "abstractContent": [{"text": "Jointly parsing two languages has been shown to improve accuracies on either or both sides.", "labels": [], "entities": [{"text": "accuracies", "start_pos": 56, "end_pos": 66, "type": "METRIC", "confidence": 0.9913798570632935}]}, {"text": "However, its search space is much bigger than the monolingual case, forcing existing approaches to employ complicated modeling and crude approximations.", "labels": [], "entities": []}, {"text": "Here we propose a much simpler alternative, bilingually-constrained mono-lingual parsing, where a source-language parser learns to exploit reorderings as additional observation, but not bothering to build the target-side tree as well.", "labels": [], "entities": []}, {"text": "We show specifically how to enhance a shift-reduce dependency parser with alignment features to resolve shift-reduce conflicts.", "labels": [], "entities": []}, {"text": "Experiments on the bilingual portion of Chi-nese Treebank show that, with just 3 bilingual features, we can improve parsing accuracies by 0.6% (absolute) for both En-glish and Chinese over a state-of-the-art baseline, with negligible (\u223c6%) efficiency overhead, thus much faster than biparsing.", "labels": [], "entities": [{"text": "Chi-nese Treebank", "start_pos": 40, "end_pos": 57, "type": "DATASET", "confidence": 0.7012669295072556}, {"text": "parsing", "start_pos": 116, "end_pos": 123, "type": "TASK", "confidence": 0.9583373665809631}]}], "introductionContent": [{"text": "Ambiguity resolution is a central task in Natural Language Processing.", "labels": [], "entities": [{"text": "Ambiguity resolution", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.862876683473587}, {"text": "Natural Language Processing", "start_pos": 42, "end_pos": 69, "type": "TASK", "confidence": 0.6362710893154144}]}, {"text": "Interestingly, not all languages are ambiguous in the same way.", "labels": [], "entities": []}, {"text": "For example, prepositional phrase (PP) attachment is (notoriously) ambiguous in English (and related European languages), but is strictly unambiguous in Chinese and largely unambiguous Japanese; see \"I saw Bill who had a telescope at hand.\": PP-attachment is unambiguous in Chinese, which can help English parsing.", "labels": [], "entities": [{"text": "prepositional phrase (PP) attachment", "start_pos": 13, "end_pos": 49, "type": "TASK", "confidence": 0.6244251628716787}, {"text": "English parsing", "start_pos": 298, "end_pos": 313, "type": "TASK", "confidence": 0.6393100917339325}]}, {"text": "1 It is thus intuitive to use two languages for better disambiguation, which has been applied not only to this PP-attachment problem, but also to the more fundamental problem of syntactic parsing which subsumes the former as a subproblem.", "labels": [], "entities": [{"text": "syntactic parsing", "start_pos": 178, "end_pos": 195, "type": "TASK", "confidence": 0.7576527893543243}]}, {"text": "For example, and show that joint parsing (or reranking) on a bitext improves accuracies on either or both sides by leveraging bilingual constraints, which is very promising for syntax-based machine translation which requires (good-quality) parse trees for rule extraction (.", "labels": [], "entities": [{"text": "joint parsing", "start_pos": 27, "end_pos": 40, "type": "TASK", "confidence": 0.5734162032604218}, {"text": "machine translation", "start_pos": 190, "end_pos": 209, "type": "TASK", "confidence": 0.6935609728097916}, {"text": "rule extraction", "start_pos": 256, "end_pos": 271, "type": "TASK", "confidence": 0.721430778503418}]}, {"text": "However, the search space of joint parsing is inevitably much bigger than the monolingual case, Chinese uses word-order to disambiguate the attachment (see below).", "labels": [], "entities": [{"text": "joint parsing", "start_pos": 29, "end_pos": 42, "type": "TASK", "confidence": 0.6189043670892715}]}, {"text": "By contrast, Japanese resorts to case-markers and the unambiguity is limited: it works for the \"V or N\" attachment ambiguities like in (see () but not for the \"N1 or N2\" case (Mitch Marcus, p.c.).", "labels": [], "entities": []}, {"text": "forcing existing approaches to employ complicated modeling and crude approximations.", "labels": [], "entities": []}, {"text": "Joint parsing with a simplest synchronous context-free grammar) is O(n 6 ) as opposed to the monolingual O(n 3 ) time.", "labels": [], "entities": [{"text": "O", "start_pos": 67, "end_pos": 68, "type": "METRIC", "confidence": 0.9950162768363953}]}, {"text": "To make things worse, languages are non-isomorphic, i.e., there is no 1-to-1 mapping between tree nodes, thus in practice one has to use more expressive formalisms such as synchronous tree-substitution grammars).", "labels": [], "entities": []}, {"text": "In fact, rather than joint parsing per se, resort to separate monolingual parsing and bilingual reranking over k 2 tree pairs, which covers a tiny fraction of the whole space.", "labels": [], "entities": []}, {"text": "We instead propose a much simpler alternative, bilingually-constrained monolingual parsing, where a source-language parser is extended to exploit the reorderings between languages as additional observation, but not bothering to build a tree for the target side simultaneously.", "labels": [], "entities": []}, {"text": "To illustrate the idea, suppose we are parsing the sentence Both are possible, but with a Chinese translation the choice becomes clear (see), because a Chinese PP always immediately precedes the phrase it is modifying, thus making PP-attachment strictly unambiguous.", "labels": [], "entities": []}, {"text": "We can thus use Chinese to help parse English, i.e., whenever we have a PPattachment ambiguity, we will consult the Chinese translation (from a bitext), and based on the alignment information, decide whereto attach the English PP.", "labels": [], "entities": []}, {"text": "On the other hand, English can help Chinese parsing as well, for example in deciding the scope of relative clauses which is unambiguous in English but ambiguous in Chinese.", "labels": [], "entities": [{"text": "Chinese parsing", "start_pos": 36, "end_pos": 51, "type": "TASK", "confidence": 0.6947720944881439}]}, {"text": "This method is much simpler than joint parsing because it remains monolingual in the backbone, with alignment information merely as soft evidence, rather than hard constraints since automatic word alignment is far from perfect.", "labels": [], "entities": [{"text": "joint parsing", "start_pos": 33, "end_pos": 46, "type": "TASK", "confidence": 0.6886108815670013}, {"text": "word alignment", "start_pos": 192, "end_pos": 206, "type": "TASK", "confidence": 0.7167450487613678}]}, {"text": "It is thus straightforward to implement within a monolingual parsing algorithm.", "labels": [], "entities": []}, {"text": "In this work we choose shift-reduce dependency parsing for its simplicity and efficiency.", "labels": [], "entities": [{"text": "shift-reduce dependency parsing", "start_pos": 23, "end_pos": 54, "type": "TASK", "confidence": 0.5662603875001272}]}, {"text": "Specifically, we make the following contributions: \u2022 we develop a baseline shift-reduce dependency parser using the less popular, but classical, \"arc-standard\" style (Section 2), and achieve similar state-of-the-art performance with the the dominant but complicated \"arceager\" style of Nivre and Scholz (2004); \u2022 we propose bilingual features based on wordalignment information to prefer \"target-side contiguity\" in resolving shift-reduce conflicts (Section 3); \u2022 we verify empirically that shift-reduce conflicts are the major source of errors, and correct shift-reduce decisions strongly correlate with the above bilingual contiguity conditions even with automatic alignments (Section 5.3); \u2022 finally, with just three bilingual features, we improve dependency parsing accuracy by 0.6% for both English and Chinese over the state-of-the-art baseline with negligible (\u223c6%) efficiency overhead (Section 5.4).", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 751, "end_pos": 769, "type": "TASK", "confidence": 0.7218924164772034}, {"text": "accuracy", "start_pos": 770, "end_pos": 778, "type": "METRIC", "confidence": 0.7510896921157837}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 4: Baseline parser performance on standard  Penn English Treebank dependency parsing task.  The speed numbers are not exactly comparable  since they are reported on different machines.", "labels": [], "entities": [{"text": "parser", "start_pos": 19, "end_pos": 25, "type": "TASK", "confidence": 0.7469821572303772}, {"text": "Penn English Treebank", "start_pos": 51, "end_pos": 72, "type": "DATASET", "confidence": 0.9382126530011495}, {"text": "dependency parsing task", "start_pos": 73, "end_pos": 96, "type": "TASK", "confidence": 0.8080880244572958}]}, {"text": " Table 5: Training, dev, and test sets from bilingual  Chinese Treebank\u00e0Treebank`Treebank\u00e0 la Burkett and Klein (2008).", "labels": [], "entities": [{"text": "Chinese Treebank\u00e0Treebank`Treebank\u00e0 la Burkett and Klein (2008)", "start_pos": 55, "end_pos": 118, "type": "DATASET", "confidence": 0.8645448142831976}]}, {"text": " Table 8: Effects of beam size k on efficiency and  accuracy (on English dev set). Time is average  per sentence (in secs). Bilingual constraints show  more improvement with larger beams, with a frac- tional efficiency overhead over the baseline.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 52, "end_pos": 60, "type": "METRIC", "confidence": 0.9991135001182556}, {"text": "Time", "start_pos": 83, "end_pos": 87, "type": "METRIC", "confidence": 0.9532308578491211}]}, {"text": " Table 9: Final results of dependency accuracy (%)  on the test set (290 sentences, beam size k=16).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 38, "end_pos": 46, "type": "METRIC", "confidence": 0.6983165144920349}]}]}