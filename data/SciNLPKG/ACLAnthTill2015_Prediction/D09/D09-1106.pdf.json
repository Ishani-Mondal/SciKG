{"title": [{"text": "Weighted Alignment Matrices for Statistical Machine Translation", "labels": [], "entities": [{"text": "Statistical Machine Translation", "start_pos": 32, "end_pos": 63, "type": "TASK", "confidence": 0.851440966129303}]}], "abstractContent": [{"text": "Current statistical machine translation systems usually extract rules from bilingual corpora annotated with 1-best alignments.", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 8, "end_pos": 39, "type": "TASK", "confidence": 0.6164941986401876}]}, {"text": "They are prone to learn noisy rules due to alignment mistakes.", "labels": [], "entities": []}, {"text": "We propose anew structure called weighted alignment matrix to encode all possible alignments fora parallel text compactly.", "labels": [], "entities": []}, {"text": "The key idea is to assign a probability to each word pair to indicate how well they are aligned.", "labels": [], "entities": []}, {"text": "We design new algorithms for extracting phrase pairs from weighted alignment matrices and estimating their probabilities.", "labels": [], "entities": [{"text": "extracting phrase pairs from weighted alignment matrices", "start_pos": 29, "end_pos": 85, "type": "TASK", "confidence": 0.8440031409263611}]}, {"text": "Our experiments on multiple language pairs show that using weighted matrices achieves consistent improvements over using n-best lists in significant less extraction time.", "labels": [], "entities": []}], "introductionContent": [{"text": "Statistical machine translation (SMT) relies heavily on annotated bilingual corpora.", "labels": [], "entities": [{"text": "Statistical machine translation (SMT)", "start_pos": 0, "end_pos": 37, "type": "TASK", "confidence": 0.8267412632703781}]}, {"text": "Word alignment, which indicates the correspondence between the words in a parallel text, is one of the most important annotations in SMT.", "labels": [], "entities": [{"text": "Word alignment", "start_pos": 0, "end_pos": 14, "type": "TASK", "confidence": 0.6696745455265045}, {"text": "SMT", "start_pos": 133, "end_pos": 136, "type": "TASK", "confidence": 0.9937334656715393}]}, {"text": "Word-aligned corpora have been found to bean excellent source for translation-related knowledge, not only for phrase-based models (), but also for syntax-based models (e.g.,).", "labels": [], "entities": []}, {"text": "indicate that the quality of machine translation output depends directly on the quality of initial word alignment.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 29, "end_pos": 48, "type": "TASK", "confidence": 0.7102870643138885}, {"text": "word alignment", "start_pos": 99, "end_pos": 113, "type": "TASK", "confidence": 0.7650673687458038}]}, {"text": "Modern alignment methods can be divided into two major categories: generative methods and discriminative methods.", "labels": [], "entities": []}, {"text": "Generative methods treat word alignment as a hidden process and maximize the likelihood of bilingual training corpus using the expectation maximization (EM) algorithm.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 25, "end_pos": 39, "type": "TASK", "confidence": 0.8047502338886261}]}, {"text": "In contrast, discriminative methods (e.g.,;)) have the freedom to define arbitrary feature functions that describe various characteristics of an alignment.", "labels": [], "entities": []}, {"text": "They usually optimize feature weights on manually-aligned data.", "labels": [], "entities": []}, {"text": "While discriminative methods show superior alignment accuracy in benchmarks, generative methods are still widely used to produce word alignments for large sentence-aligned corpora.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 53, "end_pos": 61, "type": "METRIC", "confidence": 0.9693945050239563}, {"text": "word alignments", "start_pos": 129, "end_pos": 144, "type": "TASK", "confidence": 0.7104962766170502}]}, {"text": "However, neither generative nor discriminative alignment methods are reliable enough to yield high quality alignments for SMT, especially for distantly-related language pairs such as ChineseEnglish and Arabic-English.", "labels": [], "entities": [{"text": "SMT", "start_pos": 122, "end_pos": 125, "type": "TASK", "confidence": 0.9947910308837891}]}, {"text": "The F-measures for Chinese-English and Arabic-English are usually around 80% () and 70%, respectively.", "labels": [], "entities": [{"text": "F-measures", "start_pos": 4, "end_pos": 14, "type": "METRIC", "confidence": 0.9978873133659363}]}, {"text": "As most current SMT systems only use 1-best alignments for extracting rules, alignment errors might impair translation quality.", "labels": [], "entities": [{"text": "SMT", "start_pos": 16, "end_pos": 19, "type": "TASK", "confidence": 0.9913548827171326}]}, {"text": "Recently, several studies have shown that offering more alternatives of annotations to SMT systems will result in significant improvements, such as replacing 1-best trees with packed forests () and replacing 1-best word segmentations with word lattices.", "labels": [], "entities": [{"text": "SMT", "start_pos": 87, "end_pos": 90, "type": "TASK", "confidence": 0.9891542792320251}]}, {"text": "Similarly, use n-best alignments instead of 1-best alignments for translation rule extraction.", "labels": [], "entities": [{"text": "translation rule extraction", "start_pos": 66, "end_pos": 93, "type": "TASK", "confidence": 0.9373348156611124}]}, {"text": "While they achieve significant improvements on the IWSLT data, extracting rules from n-best alignments might be computationally expensive.", "labels": [], "entities": [{"text": "IWSLT data", "start_pos": 51, "end_pos": 61, "type": "DATASET", "confidence": 0.9104395806789398}]}, {"text": "In this paper, we propose anew structure named weighted alignment matrix to represent the alignment distribution fora sentence pair compactly.", "labels": [], "entities": []}, {"text": "Ina weighted matrix, each element that corresponds to a word pair is assigned a probability to measure the confidence of aligning the two words.", "labels": [], "entities": []}, {"text": "Therefore, a weighted matrix is capable of using a lin- ear space to encode the probabilities of exponentially many alignments.", "labels": [], "entities": []}, {"text": "We develop anew algorithm for extracting phrase pairs from weighted matrices and show how to estimate their relative frequencies and lexical weights.", "labels": [], "entities": [{"text": "extracting phrase pairs from weighted matrices", "start_pos": 30, "end_pos": 76, "type": "TASK", "confidence": 0.8423519333203634}]}, {"text": "Experimental results show that using weighted matrices achieves consistent improvements in translation quality and significant reduction in extraction time over using n-best lists.", "labels": [], "entities": [{"text": "translation", "start_pos": 91, "end_pos": 102, "type": "TASK", "confidence": 0.9489130973815918}]}, {"text": "shows an example of word alignment between a pair of Chinese and English sentences.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 20, "end_pos": 34, "type": "TASK", "confidence": 0.7336406260728836}]}, {"text": "The Chinese and English words are listed horizontally and vertically, respectively.", "labels": [], "entities": []}, {"text": "The dark points indicate the correspondence between the words in two languages.", "labels": [], "entities": []}, {"text": "For example, the first Chinese word \"zhongguo\" is aligned to the fourth English word \"China\".", "labels": [], "entities": []}, {"text": "Formally, given a source sentence f = f J 1 = f 1 , . .", "labels": [], "entities": []}, {"text": ", f j , . .", "labels": [], "entities": []}, {"text": ", f J and a target sentence e = e I 1 = e 1 , . .", "labels": [], "entities": []}, {"text": ", e i , . .", "labels": [], "entities": []}, {"text": ", e I , we define a link l = (j, i) to exist if f j and e i are translation (or part of translation) of one another.", "labels": [], "entities": []}, {"text": "Then, an alignment a is a subset of the Cartesian product of word positions:", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Some candidate target phrases of the  source phrase \"zhongguo de\" in", "labels": [], "entities": []}, {"text": " Table 2: Comparison of phrase tables learned from n-best lists and weighted matrices. We use m(10)  to represent the weighted matrices estimated from 10-best lists. \"all\" denotes the full phrase table,  \"shared\" denotes the intersection of two tables, and \"non-shared\" denotes the complement. Note that the  probabilities of \"shared\" phrase pairs are different for the two approaches.", "labels": [], "entities": []}, {"text": " Table 3: Statistics of the Europarl training data.  \"S\" denotes Spanish, \"E\" denotes English, \"F\" de- notes French, \"G\" denotes German.", "labels": [], "entities": [{"text": "Europarl training data", "start_pos": 28, "end_pos": 50, "type": "DATASET", "confidence": 0.9743224779764811}, {"text": "F\" de-", "start_pos": 96, "end_pos": 102, "type": "METRIC", "confidence": 0.8683333694934845}]}, {"text": " Table 4: BLEU scores (case-insensitive) on the  Europarl data. \"S\" denotes Spanish, \"E\" denotes  English, \"F\" denotes French, \"G\" denotes Ger- man.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9992713332176208}, {"text": "Europarl data", "start_pos": 49, "end_pos": 62, "type": "DATASET", "confidence": 0.9955260157585144}]}]}