{"title": [], "abstractContent": [{"text": "Tree Adjoining Grammars have well-known advantages, but are typically considered too difficult for practical systems.", "labels": [], "entities": [{"text": "Tree Adjoining Grammars", "start_pos": 0, "end_pos": 23, "type": "TASK", "confidence": 0.7096882263819376}]}, {"text": "We demonstrate that, when done right, adjoining improves translation quality without becoming computationally intractable.", "labels": [], "entities": []}, {"text": "Using adjoining to model optionality allows general translation patterns to be learned without the clutter of endless variations of optional material.", "labels": [], "entities": []}, {"text": "The appropriate modifiers can later be spliced in as needed.", "labels": [], "entities": []}, {"text": "In this paper, we describe a novel method for learning a type of Synchronous Tree Adjoining Grammar and associated probabilities from aligned tree/string training data.", "labels": [], "entities": []}, {"text": "We introduce a method of converting these grammars to a weakly equivalent tree transducer for decoding.", "labels": [], "entities": []}, {"text": "Finally, we show that adjoining results in an end-to-end improvement of +0.8 BLEU over a baseline statistical syntax-based MT model on a large-scale Arabic/English MT task.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 77, "end_pos": 81, "type": "METRIC", "confidence": 0.9963251948356628}, {"text": "MT", "start_pos": 123, "end_pos": 125, "type": "TASK", "confidence": 0.9251337647438049}, {"text": "Arabic/English MT task", "start_pos": 149, "end_pos": 171, "type": "TASK", "confidence": 0.5776678681373596}]}], "introductionContent": [{"text": "Statistical MT has changed a lot in recent years.", "labels": [], "entities": [{"text": "Statistical MT", "start_pos": 0, "end_pos": 14, "type": "TASK", "confidence": 0.6044724583625793}]}, {"text": "We have seen quick progress from manually crafted linguistic models to empirically learned statistical models, from word-based models to phrase-based models, and from string-based models to tree-based models.", "labels": [], "entities": []}, {"text": "Recently there is a swing back to incorporating more linguistic information again, but this time linguistic insight carefully guides the setup of empirically learned models.", "labels": [], "entities": []}, {"text": "Shieber recently argued that probabilistic Synchronous Tree Adjoining Grammars (Shieber and ) have the right combination of properties that satisfy both linguists and empirical MT practitioners.", "labels": [], "entities": [{"text": "Synchronous Tree Adjoining Grammars", "start_pos": 43, "end_pos": 78, "type": "TASK", "confidence": 0.6949476525187492}, {"text": "MT", "start_pos": 177, "end_pos": 179, "type": "TASK", "confidence": 0.975111722946167}]}, {"text": "So far, though, most work in this area has been either more linguistic than statistical () or statistically-based, but linguistically light ().", "labels": [], "entities": []}, {"text": "Current tree-based models that integrate linguistics and statistics, such as GHKM (), are notable to generalize well from a single phrase pair.", "labels": [], "entities": [{"text": "GHKM", "start_pos": 77, "end_pos": 81, "type": "DATASET", "confidence": 0.8959199786186218}]}, {"text": "For example, from the data in, GHKM can learn rule (a) to translate nouns with two pre-modifiers, but does not generalize to learn translation rules (b) -(d) without the optional adjective or noun modifiers.", "labels": [], "entities": [{"text": "GHKM", "start_pos": 31, "end_pos": 35, "type": "DATASET", "confidence": 0.8620747327804565}]}, {"text": "Likewise, none of these rules allow extra material to be introduced, e.g. \"Pakistan's national defense minister\".", "labels": [], "entities": []}, {"text": "In large enough training data sets, we see many examples of all the common patterns, but the rarer patterns have sparse statistics or poor coverage.", "labels": [], "entities": []}, {"text": "Figure 1: Rule (a) can be learned from this training example.", "labels": [], "entities": []}, {"text": "Arguably, the more general rules (b) -(d) should also be learnable.", "labels": [], "entities": []}], "datasetContent": [{"text": "All experiments are trained with a subset (171,000 sentences or 4 million words) of the ArabicEnglish training data from the constrained data track of the NIST 2008 MT Evaluation, leaving out LDC2004T18, LDC2007E07, and the UN data.", "labels": [], "entities": [{"text": "ArabicEnglish training data from the constrained data track of the NIST 2008 MT Evaluation", "start_pos": 88, "end_pos": 178, "type": "DATASET", "confidence": 0.8446231016090938}, {"text": "UN data", "start_pos": 224, "end_pos": 231, "type": "DATASET", "confidence": 0.9664571583271027}]}, {"text": "The training data is aligned using the LEAF technique.", "labels": [], "entities": [{"text": "LEAF", "start_pos": 39, "end_pos": 43, "type": "METRIC", "confidence": 0.9510363936424255}]}, {"text": "The English side of the training data is parsed with an implementation of Collins Model 2 then head-out binarized.", "labels": [], "entities": [{"text": "Collins Model 2", "start_pos": 74, "end_pos": 89, "type": "DATASET", "confidence": 0.9741472800572714}]}, {"text": "The tuning data (1,178 sentences) and devtest data (1,298 sentences) are Input: Synchronous TIG ruler with j adjoining sites, S \u2194 T , where Sand T are trees Output: a weakly equivalent xLNTs rule S \ud97b\udf59 \u2194 t 1 . .", "labels": [], "entities": []}, {"text": "tn , where S \ud97b\udf59 is a one-level tree, and 2 \u00b7 j helper rules for adjoining Run time: O(|S| + |T |) begin rules \u2190 {}, lhs-state \u2190 concat('q', get-root(S), get-root(T )) site-and-word-list-s \u2190 get-sites-and-words-in-order(S) site-and-word-list-t \u2190 get-sites-and-words-in-order(T ) if r is adjoining then lhs-state \u2190 concat(lhs-state, get-adjoin-dir(S), get-adjoin-dir(T )) lhs \u2190 construct-LHS(lhs-state, get-root(S), site-and-word-list-s) rhs \u2190 construct-RHS(add-states(id(r), site-and-word-list-t)) add: End-to-end MT results show that the best adjoining model using a log-linear combination of joint and independent models (line 6) outperforms the baseline (line 1) by +0.7 and +0.8 BLEU, a statistically significant difference at the 95% confidence level.", "labels": [], "entities": [{"text": "MT", "start_pos": 512, "end_pos": 514, "type": "TASK", "confidence": 0.9680845141410828}, {"text": "BLEU", "start_pos": 681, "end_pos": 685, "type": "METRIC", "confidence": 0.9991990923881531}]}, {"text": "made up of newswire documents drawn from the NIST MT evaluation data from.", "labels": [], "entities": [{"text": "NIST MT evaluation data", "start_pos": 45, "end_pos": 68, "type": "DATASET", "confidence": 0.9083303362131119}]}, {"text": "We use the newswire documents from the NIST part of the 2006 evaluation data (765 sentences) as a held-out test set.", "labels": [], "entities": [{"text": "newswire documents from the NIST part of the 2006 evaluation data", "start_pos": 11, "end_pos": 76, "type": "DATASET", "confidence": 0.8594438542019237}]}, {"text": "We train our feature weights using max-BLEU and decode with a CKY-based decoder that supports language model scoring directly integrated into the search.", "labels": [], "entities": []}, {"text": "In addition to P sub , P adj , and P ifadj , we use several other features in our log-linear model during decoding, including: lexical and phrase-based translation probabilities, a model similar to conditional probability on the trees (P (f tree (rule)|e tree (rule))), a probability model for generating the top tree non-terminal, a 5-gram language model 7 , and target length bonus.", "labels": [], "entities": []}, {"text": "We also have several binary features-lexical rule, rule with missing or spurious content words-and several binary indicator features for specialized rules: unknown word rules; name, number, and date translation rules; and special fail-safe monotone translation rules in case of parse failures and extremely long sentences.", "labels": [], "entities": [{"text": "name, number, and date translation", "start_pos": 176, "end_pos": 210, "type": "TASK", "confidence": 0.5904715657234192}]}, {"text": "shows the comparison between our baseline model (minimal GHKM on head-out binarized parse trees) and different models of adjoining, measured with case-insensitive, NISTtokenized BLEU (IBM definition).", "labels": [], "entities": [{"text": "GHKM", "start_pos": 57, "end_pos": 61, "type": "METRIC", "confidence": 0.9644107818603516}, {"text": "NISTtokenized", "start_pos": 164, "end_pos": 177, "type": "DATASET", "confidence": 0.7390732169151306}, {"text": "BLEU", "start_pos": 178, "end_pos": 182, "type": "METRIC", "confidence": 0.9361504316329956}]}, {"text": "The top section (lines 1-4) compares the joint adjoining probability model to the independent adjoining probability model and seen vs. unseen adjoining combinations.", "labels": [], "entities": []}, {"text": "While the joint model results in a BLEU score at the same level as our baseline (line 2), the independent model (line 4) improves BLEU by +0.5 and +0.6, which are significant differences at the 95% confidence level.", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 35, "end_pos": 45, "type": "METRIC", "confidence": 0.9788741171360016}, {"text": "BLEU", "start_pos": 130, "end_pos": 134, "type": "METRIC", "confidence": 0.9995206594467163}]}, {"text": "Since with the independent model we introduce both new adjoining patterns and a different probability model for adjoining (each site is independent), we also use the independent model with only previously seen adjoining patterns (line 3).", "labels": [], "entities": []}, {"text": "The insignificant difference in BLEU between lines 2 and 3 leads us to think that the new adjoining patterns are where the improvement comes from, rather than the independent probability model alone.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 32, "end_pos": 36, "type": "METRIC", "confidence": 0.9982045888900757}]}, {"text": "We also test several other features and combinations.", "labels": [], "entities": []}, {"text": "First, we add binary features to indicate anew adjoining combination vs. one previously seen in data.", "labels": [], "entities": []}, {"text": "We also add features to indicate the direction class of adjoining to test if there is a systematic bias toward particular directions.", "labels": [], "entities": []}, {"text": "These features cause no significant difference in score (line 5).", "labels": [], "entities": [{"text": "score", "start_pos": 50, "end_pos": 55, "type": "METRIC", "confidence": 0.9865281581878662}]}, {"text": "We also add the joint-adjoining probability as a feature, allowing it to be combined in a log-linear fashion with the independent probability (line 6).", "labels": [], "entities": []}, {"text": "This results in our best BLEU gain: +0.7 and +0.8 over our non-adjoining baseline.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 25, "end_pos": 29, "type": "METRIC", "confidence": 0.9993380904197693}]}], "tableCaptions": [{"text": " Table 1: End-to-end MT results show that the best adjoining model using a log-linear combination  of joint and independent models (line 6) outperforms the baseline (line 1) by +0.7 and +0.8 BLEU, a  statistically significant difference at the 95% confidence level.", "labels": [], "entities": [{"text": "MT", "start_pos": 21, "end_pos": 23, "type": "TASK", "confidence": 0.9826269745826721}, {"text": "BLEU", "start_pos": 191, "end_pos": 195, "type": "METRIC", "confidence": 0.9983110427856445}]}]}