{"title": [{"text": "Word Buffering Models for Improved Speech Repair Parsing *", "labels": [], "entities": [{"text": "Improved Speech Repair Parsing", "start_pos": 26, "end_pos": 56, "type": "TASK", "confidence": 0.6857704743742943}]}], "abstractContent": [{"text": "This paper describes a time-series model for parsing transcribed speech containing disfluencies.", "labels": [], "entities": [{"text": "parsing transcribed speech containing disfluencies", "start_pos": 45, "end_pos": 95, "type": "TASK", "confidence": 0.9156232595443725}]}, {"text": "This model differs from previous parsers in its explicit modeling of a buffer of recent words, which allows it to recognize repairs more easily due to the frequent overlap in words between errors and their repairs.", "labels": [], "entities": []}, {"text": "The parser implementing this model is evaluated on the standard Switchboard transcribed speech parsing task for overall parsing accuracy and edited word detection.", "labels": [], "entities": [{"text": "Switchboard transcribed speech parsing task", "start_pos": 64, "end_pos": 107, "type": "TASK", "confidence": 0.688154274225235}, {"text": "parsing", "start_pos": 120, "end_pos": 127, "type": "TASK", "confidence": 0.9439392685890198}, {"text": "accuracy", "start_pos": 128, "end_pos": 136, "type": "METRIC", "confidence": 0.9205867052078247}, {"text": "word detection", "start_pos": 148, "end_pos": 162, "type": "TASK", "confidence": 0.6841008961200714}]}], "introductionContent": [{"text": "Speech repair is a phenomenon in spontaneous speech where a speaker interrupts the flow of speech (at what's called the interruption point), backtracks some number of words (the reparandum), and continues the utterance with material meant to replace the reparandum (the alteration).", "labels": [], "entities": [{"text": "Speech repair", "start_pos": 0, "end_pos": 13, "type": "TASK", "confidence": 0.7500886023044586}]}, {"text": "The utterance can be rendered syntactically correct by excising all the words that the speaker skipped over when backtracking.", "labels": [], "entities": []}, {"text": "Speech with repair is difficult for machines to process because in addition to detecting repair, a system must know what words are meant to be excised, and parsing systems must determine how to form a grammatical structure out of the set of words comprising both the error speech and the correct speech.", "labels": [], "entities": []}, {"text": "Recent approaches to syntactic modeling of speech with repairs have shown that significant gains in parsing accuracy can be achieved by modeling the syntax of repairs ().", "labels": [], "entities": [{"text": "parsing", "start_pos": 100, "end_pos": 107, "type": "TASK", "confidence": 0.9435061812400818}, {"text": "accuracy", "start_pos": 108, "end_pos": 116, "type": "METRIC", "confidence": 0.9088013172149658}]}, {"text": "In addition, others have shown that a parser based on a time-series model that explicitly represents the incomplete * This research was supported by NSF CAREER award 0447685.", "labels": [], "entities": [{"text": "NSF CAREER award 0447685", "start_pos": 149, "end_pos": 173, "type": "DATASET", "confidence": 0.675227016210556}]}, {"text": "The views expressed are not necessarily endorsed by the sponsors . This terminology follows.", "labels": [], "entities": []}, {"text": "constituents in fluent and disfluent speech can also improve parsing accuracy.", "labels": [], "entities": [{"text": "parsing", "start_pos": 61, "end_pos": 68, "type": "TASK", "confidence": 0.9631569981575012}, {"text": "accuracy", "start_pos": 69, "end_pos": 77, "type": "METRIC", "confidence": 0.8758293986320496}]}, {"text": "However, these parsing approaches are still not as accurate at detecting reparanda as classification systems which use a variety of features to detect repairs).", "labels": [], "entities": [{"text": "parsing", "start_pos": 15, "end_pos": 22, "type": "TASK", "confidence": 0.9659667611122131}]}, {"text": "One highly salient feature which classification systems use to detect repair is the repetition of words between the error and the repair.", "labels": [], "entities": [{"text": "detect repair", "start_pos": 63, "end_pos": 76, "type": "TASK", "confidence": 0.7905436754226685}]}, {"text": "Johnson and Charniak report that 60% of words in the alterations are copies of words in reparanda in the Switchboard corpus.", "labels": [], "entities": [{"text": "Switchboard corpus", "start_pos": 105, "end_pos": 123, "type": "DATASET", "confidence": 0.765911340713501}]}, {"text": "Typically, this information is not available to a parser trained on context-free grammars.", "labels": [], "entities": []}, {"text": "Meanwhile, psycholinguistic models suggest that the human language system makes use of buffers both to keep track of recent input) and to smooth out generation.", "labels": [], "entities": []}, {"text": "These buffers are hypothesized to contain representations of recent phonological events, suggesting that there is a short window where new input might be compared to recent input.", "labels": [], "entities": []}, {"text": "This could be represented as a buffer which predicts or detects repeated input in certain constrained circumstances.", "labels": [], "entities": []}, {"text": "This paper describes a hybrid parsing system operating on transcribed speech which combines an incremental parser implemented as a probabilistic time-series model, as in Miller and Schuler, with a buffer of recent words meant to loosely model something like a phonological loop, which should better account for word repetition effects in speech repair.", "labels": [], "entities": [{"text": "speech repair", "start_pos": 338, "end_pos": 351, "type": "TASK", "confidence": 0.718586653470993}]}], "datasetContent": [{"text": "This model was evaluated on the Switchboard corpus (   tors.", "labels": [], "entities": [{"text": "Switchboard corpus", "start_pos": 32, "end_pos": 50, "type": "DATASET", "confidence": 0.8571387827396393}]}, {"text": "The input to this system is the gold standard word transcriptions, segmented into individual utterances.", "labels": [], "entities": []}, {"text": "The standard train/test breakdown was used, with sections 2 and 3 used for training, and subsections 0 and 1 of section 4 used for testing.", "labels": [], "entities": []}, {"text": "Several held-out sentences from the end of section 4 were used during development.", "labels": [], "entities": []}, {"text": "For training, the data set was first standardized by removing punctuation, empty categories, typos, all categories representing repair structure, and partial words -anything that would be difficult or impossible to obtain reliably with a speech recognizer.", "labels": [], "entities": []}, {"text": "The two metrics used here are the standard Parseval F-measure, and Edit-finding F.", "labels": [], "entities": []}, {"text": "The first takes the F-score of labeled precision and recall of the non-terminals in a hypothesized tree relative to the gold standard tree.", "labels": [], "entities": [{"text": "F-score", "start_pos": 20, "end_pos": 27, "type": "METRIC", "confidence": 0.9986218214035034}, {"text": "precision", "start_pos": 39, "end_pos": 48, "type": "METRIC", "confidence": 0.9133584499359131}, {"text": "recall", "start_pos": 53, "end_pos": 59, "type": "METRIC", "confidence": 0.9993320107460022}]}, {"text": "The second measure marks words in the gold standard as edited if they are dominated by anode labeled EDITED, and measures the F-score of the hypothesized edited words relative to the gold standard.", "labels": [], "entities": [{"text": "F-score", "start_pos": 126, "end_pos": 133, "type": "METRIC", "confidence": 0.9983959794044495}]}, {"text": "Results are shown in shows detailed results on edited word finding, with two test systems and several related approaches.", "labels": [], "entities": [{"text": "word finding", "start_pos": 54, "end_pos": 66, "type": "TASK", "confidence": 0.7216678708791733}]}, {"text": "The first two lines show results from a reimplementation of Hale et al. parsers.", "labels": [], "entities": []}, {"text": "In both those cases, gold standard part-of-speech (POS) tags were supplied to the parser.", "labels": [], "entities": []}, {"text": "The following two lines are reported results of a lexicalized parser from Hale et al. and the TAG system of Johnson and Charniak.", "labels": [], "entities": [{"text": "TAG", "start_pos": 94, "end_pos": 97, "type": "METRIC", "confidence": 0.8427741527557373}]}, {"text": "The final three lines are evaluations of HHMM systems.", "labels": [], "entities": []}, {"text": "The first is an implementation of Miller and Schuler, run without gold standard POS tags as input.", "labels": [], "entities": []}, {"text": "The second HHMM result is a system much like that described in this paper, but designed to approximate the best result that can come from simply trying to match the first word of an alteration with a recent word.", "labels": [], "entities": []}, {"text": "notes that in over 90% of repairs, the first word of the alteration is either identical or a member of the same category as the first word of the reparandum, and this clue is enough for listeners to understand what the alteration is meant to replace.", "labels": [], "entities": []}, {"text": "This implementation keeps the I variable to model repair state, but rather than a modeled buffer being part of the hidden state, it keeps an observed buffer that simply tracks the last n words seen (n = 4 in this experiment).", "labels": [], "entities": []}, {"text": "This buffer is used only to generate the first word of a repair, and only when the syntactic state allows the word.", "labels": [], "entities": []}, {"text": "Finally, the system described in Section 3 is shown on the final line.", "labels": [], "entities": []}, {"text": "shows overall parsing accuracy results, with the same set of systems, with the exception of the TAG system which did not report parsing results.", "labels": [], "entities": [{"text": "parsing", "start_pos": 14, "end_pos": 21, "type": "TASK", "confidence": 0.9755759835243225}, {"text": "accuracy", "start_pos": 22, "end_pos": 30, "type": "METRIC", "confidence": 0.9351662993431091}, {"text": "parsing", "start_pos": 128, "end_pos": 135, "type": "TASK", "confidence": 0.9443680644035339}]}], "tableCaptions": [{"text": " Table 1: Table of results of edit-finding accuracy.  Italics indicate reported, rather than reproduced,  results.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 43, "end_pos": 51, "type": "METRIC", "confidence": 0.9674851298332214}]}, {"text": " Table 2: Table of parsing results.", "labels": [], "entities": [{"text": "parsing", "start_pos": 19, "end_pos": 26, "type": "TASK", "confidence": 0.8105421662330627}]}]}