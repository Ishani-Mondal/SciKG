{"title": [{"text": "A Probabilistic Model for Associative Anaphora Resolution", "labels": [], "entities": [{"text": "Associative Anaphora", "start_pos": 26, "end_pos": 46, "type": "TASK", "confidence": 0.8986102640628815}]}], "abstractContent": [{"text": "This paper proposes a probabilistic model for associative anaphora resolution in Japanese.", "labels": [], "entities": [{"text": "associative anaphora resolution", "start_pos": 46, "end_pos": 77, "type": "TASK", "confidence": 0.7897497415542603}]}, {"text": "Associative anaphora is a type of bridging anaphora, in which the anaphor and its antecedent are not coref-erent.", "labels": [], "entities": []}, {"text": "Our model regards associative anaphora as a kind of zero anaphora and resolves it in the same manner as zero anaphora resolution using automatically acquired lexical knowledge.", "labels": [], "entities": [{"text": "zero anaphora resolution", "start_pos": 104, "end_pos": 128, "type": "TASK", "confidence": 0.7259654800097147}]}, {"text": "Experimental results show that our model resolves associative anaphora with good performance and the performance is improved by resolving it simultaneously with zero anaphora.", "labels": [], "entities": []}], "introductionContent": [{"text": "The correct interpretation of anaphora is vital for natural language understanding.", "labels": [], "entities": [{"text": "natural language understanding", "start_pos": 52, "end_pos": 82, "type": "TASK", "confidence": 0.6617768704891205}]}, {"text": "Bridging anaphora represents a special part of the general problem of anaphora resolution, which has been studied and discussed for various languages and domains.", "labels": [], "entities": [{"text": "anaphora resolution", "start_pos": 70, "end_pos": 89, "type": "TASK", "confidence": 0.8067664504051208}]}, {"text": "Usually bridging anaphora considers two types: 1 associative anaphors are noun phrases (NPs) that have an antecedent that is necessary to their interpretation but the relation between the anaphor and its antecedent is different from identity; and indirect anaphors are those that have an identity relation with their antecedents but the anaphor and its antecedent have different head The terminology that we use here is introduced by, which is also used in (). nouns.", "labels": [], "entities": []}, {"text": "In this paper, we focus on associative anaphora in Japanese.", "labels": [], "entities": []}, {"text": "Associative anaphora resolution is decomposed into two steps: acquiring lexical knowledge for associative anaphora resolution, and resolving associative anaphora using the acquired knowledge.", "labels": [], "entities": [{"text": "Associative anaphora resolution", "start_pos": 0, "end_pos": 31, "type": "TASK", "confidence": 0.8935884435971578}, {"text": "associative anaphora resolution", "start_pos": 94, "end_pos": 125, "type": "TASK", "confidence": 0.6932594180107117}]}, {"text": "Grammatical salience plays a lesser role for resolving anaphors with full lexical heads, than for pronominal anaphora).", "labels": [], "entities": []}, {"text": "Furthermore, since associative anaphors and their antecedents usually have different head nouns, string matching technique cannot be applied.", "labels": [], "entities": [{"text": "string matching", "start_pos": 97, "end_pos": 112, "type": "TASK", "confidence": 0.7660636901855469}]}, {"text": "Therefore, a large and diverse amount of lexical knowledge is essential to understand associative anaphora.", "labels": [], "entities": []}, {"text": "For example, to recognize the meronymic relation between \"a house\" and \"the roof\" in (1), such knowledge as \"a roof\" is apart of a building or vehicle is required.", "labels": [], "entities": []}, {"text": "To recognize the attributive relation between \"Prius\" and \"the price\" in (2), such knowledge as \"price\" is a price of some goods or service is required.", "labels": [], "entities": []}, {"text": "(1) There was a house.", "labels": [], "entities": []}, {"text": "(2) Toyota launched the hybrid car Prius in 1997.", "labels": [], "entities": []}, {"text": "The price was 21.5 million yen.", "labels": [], "entities": []}, {"text": "To acquire such lexical knowledge, various studies have been carried out.", "labels": [], "entities": []}, {"text": "Early studies used hand-crafted lexical knowledge such as WordNet (), but obtained poor or mediocre results.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 58, "end_pos": 65, "type": "DATASET", "confidence": 0.9617463946342468}]}, {"text": "Hence, proposed to exploit \"N h of N m \" phrases in large corpora to resolve associative anaphora in English; proposed to exploit \"N m no N h \" phrases to resolve associative anaphora in Japanese.", "labels": [], "entities": []}, {"text": "Here, the Japanese postposition \"no\" roughly corresponds to \"of,\" but it has much broader usage.", "labels": [], "entities": []}, {"text": "These studies obtained reasonable results, but the coverage of the acquired knowledge was not sufficient.", "labels": [], "entities": []}, {"text": "Recently, a number of researchers argued for using the Web as a source of lexical knowledge, and the Web has been shown to be a useful resource for anaphora resolution).", "labels": [], "entities": [{"text": "anaphora resolution", "start_pos": 148, "end_pos": 167, "type": "TASK", "confidence": 0.7771003544330597}]}, {"text": "Hence, in this study, we acquire the lexical knowledge for associative anaphora resolution from \"N m no N h \" phrases in the Web by using the method described in ().", "labels": [], "entities": [{"text": "associative anaphora resolution", "start_pos": 59, "end_pos": 90, "type": "TASK", "confidence": 0.7726642489433289}]}, {"text": "We proposed a method for acquiring such lexical knowledge, called nominal case frames (NCFs), using an ordinary language dictionary and \"N m no N h \" phrases, and constructed NCFs from newspaper corpora.", "labels": [], "entities": []}, {"text": "In this study, we aim to acquire a sufficient amount of lexical knowledge by constructing NCFs from the Web.", "labels": [], "entities": []}, {"text": "As for associative anaphora resolution itself, we propose an integrated probabilistic model for zero anaphora and associative anaphora resolution, in which associative anaphora is regarded as a kind of zero anaphora and resolved by using the same model as zero anaphora.", "labels": [], "entities": [{"text": "associative anaphora resolution", "start_pos": 7, "end_pos": 38, "type": "TASK", "confidence": 0.8288466533025106}, {"text": "associative anaphora resolution", "start_pos": 114, "end_pos": 145, "type": "TASK", "confidence": 0.6340385178724924}]}, {"text": "Our model assumes zero pronouns that represent indispensable entities of target noun phrases, which are called zero adnominal in, and conducts zero pronoun resolution.", "labels": [], "entities": []}, {"text": "Let us consider the associative anaphoric relation between \"Prius\" and \"kakaku\" (price).", "labels": [], "entities": [{"text": "Prius", "start_pos": 60, "end_pos": 65, "type": "METRIC", "confidence": 0.9590245485305786}]}, {"text": "Although \"kakaku\" itself is considered as the anaphor from a conventional point of view (3a), our model assumes a zero pronoun \u03c6 and considers it as the anaphor (3b).", "labels": [], "entities": []}, {"text": "The point of this study is three-fold: the acquisition of the lexical knowledge for associative anaphora resolution from the Web, the application of zero anaphora resolution model to associative anaphora resolution, and the integrated resolution of zero anaphora and associative anaphora.", "labels": [], "entities": [{"text": "associative anaphora resolution", "start_pos": 84, "end_pos": 115, "type": "TASK", "confidence": 0.702251156171163}, {"text": "associative anaphora resolution", "start_pos": 183, "end_pos": 214, "type": "TASK", "confidence": 0.7077832023302714}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 2: The statistics of constructed NCFs.", "labels": [], "entities": []}, {"text": " Table 3: Evaluation of constructed NCFs.  Precision  Recall  F-measure  62/70 (0.89) 62/84 (0.74)  0.81", "labels": [], "entities": [{"text": "Precision  Recall  F-measure  62/70 (0.89) 62/84 (0.74)  0.81", "start_pos": 43, "end_pos": 104, "type": "METRIC", "confidence": 0.83074551820755}]}, {"text": " Table 4: Experimental results of associative  anaphora resolution with two baseline models and  our model with/without generalized examples.  Model  Recall  Precision F-measure  Random*  0.148  0.035  0.056  (16.3/110) (16.3/467.5)", "labels": [], "entities": [{"text": "associative  anaphora resolution", "start_pos": 34, "end_pos": 66, "type": "TASK", "confidence": 0.7203718821207682}, {"text": "Recall  Precision F-measure  Random*  0.148  0.035  0.056", "start_pos": 150, "end_pos": 207, "type": "METRIC", "confidence": 0.8874377235770226}]}, {"text": " Table 5: The effects of zero anaphora resolution.  Zero anaphora Recall Precision F-measure  No resolution 0.373  0.339  0.355  (41/110) (41/121)  Automatically 0.518  0.363  0.427  resolved  (57/110) (57/157)  Manually  0.573  0.382  0.458  identified  (63/110) (63/165)", "labels": [], "entities": [{"text": "Recall Precision F-measure  No resolution 0.373  0.339  0.355", "start_pos": 66, "end_pos": 127, "type": "METRIC", "confidence": 0.8595374897122383}, {"text": "Automatically 0.518  0.363  0.427  resolved", "start_pos": 148, "end_pos": 191, "type": "METRIC", "confidence": 0.8702148914337158}]}]}