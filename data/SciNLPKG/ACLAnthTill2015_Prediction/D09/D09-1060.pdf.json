{"title": [{"text": "Improving Dependency Parsing with Subtrees from Auto-Parsed Data", "labels": [], "entities": [{"text": "Improving Dependency Parsing", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.8605720400810242}]}], "abstractContent": [{"text": "This paper presents a simple and effective approach to improve dependency parsing by using subtrees from auto-parsed data.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 63, "end_pos": 81, "type": "TASK", "confidence": 0.8337229788303375}]}, {"text": "First, we use a baseline parser to parse large-scale unannotated data.", "labels": [], "entities": [{"text": "parse large-scale unannotated", "start_pos": 35, "end_pos": 64, "type": "TASK", "confidence": 0.8646074334780375}]}, {"text": "Then we extract subtrees from dependency parse trees in the auto-parsed data.", "labels": [], "entities": []}, {"text": "Finally, we construct new subtree-based features for parsing algorithms.", "labels": [], "entities": [{"text": "parsing algorithms", "start_pos": 53, "end_pos": 71, "type": "TASK", "confidence": 0.9178784489631653}]}, {"text": "To demonstrate the effectiveness of our proposed approach, we present the experimental results on the En-glish Penn Treebank and the Chinese Penn Treebank.", "labels": [], "entities": [{"text": "En-glish Penn Treebank", "start_pos": 102, "end_pos": 124, "type": "DATASET", "confidence": 0.8140642444292704}, {"text": "Chinese Penn Treebank", "start_pos": 133, "end_pos": 154, "type": "DATASET", "confidence": 0.9732691049575806}]}, {"text": "These results show that our approach significantly outperforms baseline systems.", "labels": [], "entities": []}, {"text": "And, it achieves the best accuracy for the Chinese data and an accuracy which is competitive with the best known systems for the English data.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 26, "end_pos": 34, "type": "METRIC", "confidence": 0.9988276362419128}, {"text": "Chinese data", "start_pos": 43, "end_pos": 55, "type": "DATASET", "confidence": 0.742606520652771}, {"text": "accuracy", "start_pos": 63, "end_pos": 71, "type": "METRIC", "confidence": 0.999539852142334}]}], "introductionContent": [{"text": "Dependency parsing, which attempts to build dependency links between words in a sentence, has experienced a surge of interest in recent times, owing to its usefulness in such applications as machine translation () and question answering ().", "labels": [], "entities": [{"text": "Dependency parsing", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.8770710527896881}, {"text": "machine translation", "start_pos": 191, "end_pos": 210, "type": "TASK", "confidence": 0.8222015500068665}, {"text": "question answering", "start_pos": 218, "end_pos": 236, "type": "TASK", "confidence": 0.9001798033714294}]}, {"text": "To obtain dependency parsers with high accuracy, supervised techniques require a large amount of handannotated data.", "labels": [], "entities": [{"text": "dependency parsers", "start_pos": 10, "end_pos": 28, "type": "TASK", "confidence": 0.7414345741271973}, {"text": "accuracy", "start_pos": 39, "end_pos": 47, "type": "METRIC", "confidence": 0.9840478301048279}]}, {"text": "While hand-annotated data are very expensive, large-scale unannotated data can be obtained easily.", "labels": [], "entities": []}, {"text": "Therefore, the use of largescale unannotated data in training is an attractive idea to improve dependency parsing performance.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 95, "end_pos": 113, "type": "TASK", "confidence": 0.8194753527641296}]}, {"text": "In this paper, we present an approach that extracts subtrees from dependency trees in autoparsed data to improve dependency parsing.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 113, "end_pos": 131, "type": "TASK", "confidence": 0.8238140940666199}]}, {"text": "The auto-parsed data are generated from large-scale unannotated data by using a baseline parser.", "labels": [], "entities": []}, {"text": "Then, from dependency trees in the data, we extract different types of subtrees.", "labels": [], "entities": []}, {"text": "Finally, we represent subtree-based features on training data to train dependency parsers.", "labels": [], "entities": []}, {"text": "The use of auto-parsed data is not new.", "labels": [], "entities": []}, {"text": "However, unlike most of the previous studies) that improved the performance by using entire trees from auto-parsed data, we exploit partial information (i.e., subtrees) in auto-parsed data.", "labels": [], "entities": []}, {"text": "In their approaches, they used entire auto-parsed trees as newly labeled data to train the parsing models, while we use subtree-based features and employ the original gold-standard data to train the models.", "labels": [], "entities": []}, {"text": "The use of subtrees instead of complete trees can be justified by the fact that the accuracy of partial dependencies is much higher than that of entire dependency trees.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 84, "end_pos": 92, "type": "METRIC", "confidence": 0.9992357492446899}]}, {"text": "Previous studies show that the accuracies of complete trees are about 40% for English and about 35% for Chinese, while the accuracies of relations between two words are much higher: about 90% for English and about 85% for Chinese.", "labels": [], "entities": [{"text": "accuracies", "start_pos": 31, "end_pos": 41, "type": "METRIC", "confidence": 0.9831745028495789}, {"text": "accuracies", "start_pos": 123, "end_pos": 133, "type": "METRIC", "confidence": 0.9589482545852661}]}, {"text": "From these observations, we may conjecture that it is possible to conduct a more effective selection by using subtrees as the unit of information.", "labels": [], "entities": []}, {"text": "The use of word pairs in auto-parsed data was tried in van and.", "labels": [], "entities": []}, {"text": "However, the information on word pairs is limited.", "labels": [], "entities": []}, {"text": "To provide richer information, we consider more words besides word pairs.", "labels": [], "entities": []}, {"text": "Specifically, we use subtrees containing two or three words extracted from dependency trees in the auto-parsed data.", "labels": [], "entities": []}, {"text": "To demonstrate the effectiveness of our proposed approach, we present experimental results on En-glish and Chinese data.", "labels": [], "entities": [{"text": "Chinese data", "start_pos": 107, "end_pos": 119, "type": "DATASET", "confidence": 0.7050365656614304}]}, {"text": "We show that this simple approach greatly improves the accuracy and that the use of richer structures (i.e, word triples) indeed gives additional improvement.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 55, "end_pos": 63, "type": "METRIC", "confidence": 0.9990302324295044}]}, {"text": "We also demonstrate that our approach and other improvement techniques () are complementary and that we can achieve very high accuracies when we combine our method with other improvement techniques.", "labels": [], "entities": [{"text": "accuracies", "start_pos": 126, "end_pos": 136, "type": "METRIC", "confidence": 0.9571396112442017}]}, {"text": "Specifically, we achieve the best accuracy for the Chinese data.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 34, "end_pos": 42, "type": "METRIC", "confidence": 0.9993809461593628}, {"text": "Chinese data", "start_pos": 51, "end_pos": 63, "type": "DATASET", "confidence": 0.8650746047496796}]}, {"text": "The rest of this paper is as follows: Section 2 introduces the background of dependency parsing.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 77, "end_pos": 95, "type": "TASK", "confidence": 0.8911335170269012}]}, {"text": "Section 3 proposes an approach for extracting subtrees and represents the subtree-based features for dependency parsers.", "labels": [], "entities": []}, {"text": "Section 4 explains the experimental results and Section 5 discusses related work.", "labels": [], "entities": []}, {"text": "Finally, in section 6 we draw conclusions.", "labels": [], "entities": []}], "datasetContent": [{"text": "In order to evaluate the effectiveness of the subtree-based features, we conducted experiments on English data and Chinese Data.", "labels": [], "entities": [{"text": "English data", "start_pos": 98, "end_pos": 110, "type": "DATASET", "confidence": 0.8270242810249329}, {"text": "Chinese Data", "start_pos": 115, "end_pos": 127, "type": "DATASET", "confidence": 0.9475889801979065}]}, {"text": "For English, we used the Penn Treebank) in our experiments and the tool \"Penn2Malt\" 7 to convert the data into dependency structures using a standard set of head rules.", "labels": [], "entities": [{"text": "Penn Treebank)", "start_pos": 25, "end_pos": 39, "type": "DATASET", "confidence": 0.9909892479578654}, {"text": "Penn2Malt\" 7", "start_pos": 73, "end_pos": 85, "type": "DATASET", "confidence": 0.9075356125831604}]}, {"text": "To match previous work, we split the data into a training set (sections 2-21), a development set (Section 22), and a test set (section 23).", "labels": [], "entities": []}, {"text": "Following the work of , we used the MXPOST (Ratnaparkhi, 1996) tagger trained on training data to provide part-of-speech tags for the development and the test set, and we used 10-way jackknifing to generate tags for the training set.", "labels": [], "entities": [{"text": "MXPOST (Ratnaparkhi, 1996) tagger trained on training data", "start_pos": 36, "end_pos": 94, "type": "DATASET", "confidence": 0.8973258462819186}]}, {"text": "For the unannotated data, we used the BLLIP corpus () that contains about 43 million words of WSJ text.", "labels": [], "entities": [{"text": "BLLIP corpus", "start_pos": 38, "end_pos": 50, "type": "DATASET", "confidence": 0.8627707362174988}, {"text": "WSJ text", "start_pos": 94, "end_pos": 102, "type": "DATASET", "confidence": 0.8377821445465088}]}, {"text": "We used the MX-POST tagger trained on training data to assign part-of-speech tags and used the Basic Parser to process the sentences of the BLLIP corpus.", "labels": [], "entities": [{"text": "BLLIP corpus", "start_pos": 140, "end_pos": 152, "type": "DATASET", "confidence": 0.9322404861450195}]}, {"text": "For Chinese, we used the Chinese Treebank (CTB) version 4.0 9 in the experiments.", "labels": [], "entities": [{"text": "Chinese Treebank (CTB) version 4.0 9", "start_pos": 25, "end_pos": 61, "type": "DATASET", "confidence": 0.9647109657526016}]}, {"text": "We also used the \"Penn2Malt\" tool to convert the data and created a data split: files 1-270 and files 400-931 for training, files 271-300 for testing, and files 301-325 for development.", "labels": [], "entities": [{"text": "Penn2Malt", "start_pos": 18, "end_pos": 27, "type": "DATASET", "confidence": 0.9691134095191956}]}, {"text": "We used gold standard segmentation and part-of-speech tags in the CTB.", "labels": [], "entities": [{"text": "CTB", "start_pos": 66, "end_pos": 69, "type": "DATASET", "confidence": 0.942164421081543}]}, {"text": "The data partition and part-of-speech settings were chosen to match previous work.", "labels": [], "entities": []}, {"text": "For the unannotated data, we used the PFR corpus 10 , which has approximately 15 million words whose segmentation and POS tags are given.", "labels": [], "entities": [{"text": "PFR corpus 10", "start_pos": 38, "end_pos": 51, "type": "DATASET", "confidence": 0.9255978465080261}]}, {"text": "We used its original segmentation though there are differences in segmentation policy between CTB and this corpus.", "labels": [], "entities": [{"text": "CTB", "start_pos": 94, "end_pos": 97, "type": "DATASET", "confidence": 0.9194614291191101}]}, {"text": "As for POS tags, we discarded the original POS tags and assigned CTB style POS tags using a TNT-based tagger) trained on the training data.", "labels": [], "entities": []}, {"text": "We used the Basic Parser to process all the sentences of the PFR corpus.", "labels": [], "entities": [{"text": "PFR corpus", "start_pos": 61, "end_pos": 71, "type": "DATASET", "confidence": 0.9305366575717926}]}, {"text": "We measured the parser quality by the unlabeled attachment score (UAS), i.e., the percentage of tokens (excluding all punctuation tokens) with the correct HEAD.", "labels": [], "entities": [{"text": "unlabeled attachment score (UAS)", "start_pos": 38, "end_pos": 70, "type": "METRIC", "confidence": 0.7791400253772736}]}, {"text": "And we also evaluated on complete dependency analysis.", "labels": [], "entities": []}, {"text": "In our experiments, we used MSTParser, a freely available implementation 11 of the first-and second-order MST parsing models.", "labels": [], "entities": [{"text": "MSTParser", "start_pos": 28, "end_pos": 37, "type": "DATASET", "confidence": 0.9089910984039307}, {"text": "MST parsing", "start_pos": 106, "end_pos": 117, "type": "TASK", "confidence": 0.852760374546051}]}, {"text": "For baseline systems, we used the first-and second-order basic features, which were the same as the features used by, and we used the default settings of MSTParser throughout the paper: iters=10; training-k=1; decode-type=proj.", "labels": [], "entities": [{"text": "MSTParser", "start_pos": 154, "end_pos": 163, "type": "DATASET", "confidence": 0.9192511439323425}]}, {"text": "We implemented our systems based on the MSTParser by incorporating the subtree-based features.", "labels": [], "entities": [{"text": "MSTParser", "start_pos": 40, "end_pos": 49, "type": "DATASET", "confidence": 0.9507958292961121}]}, {"text": "The results are shown in, where Ord1/Ord2 refers to a first-/second-order MSTParser with basic features, Ord1s/Ord2s refers to a first-/second-order MSTParser with basic+subtree-based features, and the improvements by the subtree-based features over the basic features are shown in parentheses.", "labels": [], "entities": []}, {"text": "Note that we use both the bigram-and trigram-subtrees in Ord2s.", "labels": [], "entities": []}, {"text": "The parsers using the subtree-based features consistently outperformed those using the basic features.", "labels": [], "entities": []}, {"text": "For the first-order parser, we found that there is an absolute improvement of 0.81 points (UAS) by adding subtree-based features.", "labels": [], "entities": [{"text": "UAS)", "start_pos": 91, "end_pos": 95, "type": "METRIC", "confidence": 0.9852843284606934}]}, {"text": "For the second-order parser, we got an absolute improvement of 0.8 points (UAS) by including subtree-based features.", "labels": [], "entities": [{"text": "UAS)", "start_pos": 75, "end_pos": 79, "type": "METRIC", "confidence": 0.9879285395145416}]}, {"text": "The improvements of parsing with subtree-based features were significant in McNemar's Test (p < 10 \u22126 ).", "labels": [], "entities": [{"text": "parsing", "start_pos": 20, "end_pos": 27, "type": "TASK", "confidence": 0.9697374105453491}, {"text": "McNemar's Test", "start_pos": 76, "end_pos": 90, "type": "DATASET", "confidence": 0.8405598998069763}]}], "tableCaptions": [{"text": " Table 1: Dependency parsing results for English", "labels": [], "entities": [{"text": "Dependency parsing", "start_pos": 10, "end_pos": 28, "type": "TASK", "confidence": 0.8753113746643066}]}, {"text": " Table 2: Dependency parsing results for English,  for our parsers and previous work", "labels": [], "entities": [{"text": "Dependency parsing", "start_pos": 10, "end_pos": 28, "type": "TASK", "confidence": 0.9017843008041382}]}, {"text": " Table 1. As in the English  experiments, parsers with the subtree-based fea- tures outperformed parsers with the basic features,  and second-order parsers outperformed first-order  parsers. For the first-order parser, the subtree- based features provided 1.3 absolute points im- provement. For the second-order parser, the  subtree-based features achieved an absolute im- provement of 1.25 points. The improvements of  parsing with subtree-based features were signifi- cant in", "labels": [], "entities": []}, {"text": " Table 3: Dependency parsing results for Chinese.", "labels": [], "entities": [{"text": "Dependency parsing", "start_pos": 10, "end_pos": 28, "type": "TASK", "confidence": 0.8522713780403137}]}, {"text": " Table 4: Dependency parsing results for Chinese,  for our parsers and for previous work", "labels": [], "entities": [{"text": "Dependency parsing", "start_pos": 10, "end_pos": 28, "type": "TASK", "confidence": 0.904326468706131}]}]}