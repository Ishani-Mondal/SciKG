{"title": [{"text": "Descriptive and Empirical Approaches to Capturing Underlying Dependencies among Parsing Errors", "labels": [], "entities": [{"text": "Capturing Underlying Dependencies among Parsing Errors", "start_pos": 40, "end_pos": 94, "type": "TASK", "confidence": 0.8760891060034434}]}], "abstractContent": [{"text": "In this paper, we provide descriptive and empirical approaches to effectively extracting underlying dependencies among parsing errors.", "labels": [], "entities": []}, {"text": "In the descriptive approach , we define some combinations of error patterns and extract them from given errors.", "labels": [], "entities": []}, {"text": "In the empirical approach, on the other hand, we re-parse a sentence with a target error corrected and observe errors corrected together.", "labels": [], "entities": []}, {"text": "Experiments on an HPSG parser show that each of these approaches can clarify the dependencies among individual errors from each point of view.", "labels": [], "entities": [{"text": "HPSG", "start_pos": 18, "end_pos": 22, "type": "DATASET", "confidence": 0.8762874603271484}]}, {"text": "Moreover, the comparison between the results of the two approaches shows that combining these approaches can achieve a more detailed error analysis.", "labels": [], "entities": []}], "introductionContent": [{"text": "For any kind of technology, analyzing causes of errors given by a system is a very helpful process for improving its performance.", "labels": [], "entities": []}, {"text": "In recent sophisticated parsing technologies, the process has taken on more and more important roles since critical ideas for parsing performance have already been introduced and the researches are now focusing on exploring the rest of the pieces for making additional improvements.", "labels": [], "entities": [{"text": "parsing", "start_pos": 24, "end_pos": 31, "type": "TASK", "confidence": 0.9703303575515747}, {"text": "parsing performance", "start_pos": 126, "end_pos": 145, "type": "TASK", "confidence": 0.9219216704368591}]}, {"text": "In most cases for parsers' error analysis, researchers associate output errors with failures in handling certain linguistic phenomena and attempt to avoid them by adding or modifying corresponding settings of their parsers.", "labels": [], "entities": [{"text": "parsers' error analysis", "start_pos": 18, "end_pos": 41, "type": "TASK", "confidence": 0.8505042195320129}]}, {"text": "However, such an analysis cannot been done so smoothly since parsing errors sometimes depend on each other and the underlying dependencies behind superficial phenomena cannot be captured easily.", "labels": [], "entities": [{"text": "parsing", "start_pos": 61, "end_pos": 68, "type": "TASK", "confidence": 0.9716953635215759}]}, {"text": "In this paper, we propose descriptive and empirical approaches to effective extraction of dependencies among parsing errors and engage in a deeper error analysis with them.", "labels": [], "entities": [{"text": "extraction of dependencies among parsing errors", "start_pos": 76, "end_pos": 123, "type": "TASK", "confidence": 0.6952677170435587}]}, {"text": "In our descriptive approach, we define various combinations of error patterns as organized error phenomena on the basis of linguistic knowledge, and then extract such combinations from given errors.", "labels": [], "entities": []}, {"text": "In our empirical approach, on the other and, we re-parse a sentence under the condition where a target error is corrected, and errors which are additionally corrected are regarded as dependent errors.", "labels": [], "entities": []}, {"text": "By capturing dependencies among parsing errors through systematic approaches, we can effectively collect errors which are related to the same linguistic properties.", "labels": [], "entities": []}, {"text": "In the experiments, we applied both of our approaches to an HPSG parser Enju (), and then evaluated the obtained error classes.", "labels": [], "entities": [{"text": "HPSG parser Enju", "start_pos": 60, "end_pos": 76, "type": "DATASET", "confidence": 0.7597974141438802}]}, {"text": "After examining the individual approaches, we explored the combination of them.", "labels": [], "entities": []}], "datasetContent": [{"text": "A parser is a system which interprets structures of given sentences from some grammatical or in some cases semantical viewpoints, and interpreted structures are utilized as essential information for various natural language tasks such as information extraction, machine translation, and soon.", "labels": [], "entities": [{"text": "information extraction", "start_pos": 238, "end_pos": 260, "type": "TASK", "confidence": 0.8012725710868835}, {"text": "machine translation", "start_pos": 262, "end_pos": 281, "type": "TASK", "confidence": 0.8073108196258545}]}, {"text": "In most cases, an output structure of a parser is based on a certain grammatical framework such as CFG, CCG), LFG or HPSG (.", "labels": [], "entities": []}, {"text": "Since such a framework can usually produce more than one probable structure fora sentence, a parser: Descriptions for predicate types often utilizes some kind of disambiguation model for choosing the best one.", "labels": [], "entities": []}, {"text": "While various parsers take different manners in capturing linguistic phenomena based on their frameworks, they are at least required to obtain some kinds of relations between the words in sentences.", "labels": [], "entities": []}, {"text": "On the basis of the requirements, a parser is usually evaluated on how correctly it gives intended linguistic relations.", "labels": [], "entities": []}, {"text": "\"Predicate argument relation\" is one of the most common evaluation measurements fora parser since it is a very fundamental linguistic behavior and is less dependent on parser systems.", "labels": [], "entities": []}, {"text": "This measure divides linguistic structural phenomena in a sentence into minimal predicative events.", "labels": [], "entities": []}, {"text": "In one predicate argument relation, a word which represents an event (predicate) takes some words as participants (arguments).", "labels": [], "entities": []}, {"text": "Although no fixed formulation exists for the relations, there are to a large extent common conceptions for them based on linguistic knowledge among researchers.", "labels": [], "entities": []}, {"text": "shows an example of predicate argument relations given by Enju.", "labels": [], "entities": []}, {"text": "In the sentence \"John has come.\", \"has\" is a predicate of type \"aux arg12\" and takes \"John\" and \"come\" as the first and second arguments.", "labels": [], "entities": []}, {"text": "\"come\" is also a predicate of the type \"verb arg1\" and takes \"John\" as the first and the only argument.", "labels": [], "entities": []}, {"text": "In this formalism, each predicate type is represented as a combination of \"the grammatical nature of a word\" and \"the arguments which it takes,\" which are represented by the descriptions in.", "labels": [], "entities": []}, {"text": "\"aux arg12\" in indicates that it is an auxiliary word and takes two arguments \"ARG1\" and \"ARG2.\"", "labels": [], "entities": [{"text": "ARG1", "start_pos": 79, "end_pos": 83, "type": "METRIC", "confidence": 0.7891529202461243}, {"text": "ARG2", "start_pos": 90, "end_pos": 94, "type": "DATASET", "confidence": 0.868247389793396}]}, {"text": "In order to improve the performance of a parser, analyzing parsing errors is very much worth the Figure 3: Co-occurring parsing errors effort.", "labels": [], "entities": []}, {"text": "Since the errors are output according to a given evaluation measurement such as \"predicate argument relation,\" we researchers carefully explore them and infer the linguistic phenomena which cause the erroneous outputs.", "labels": [], "entities": []}, {"text": "shows an example of parsing errors for sentence \"I watched the girl on TV.\"", "labels": [], "entities": []}, {"text": "Note that the errors are based on predicate argument relations as shown above and that the predicate types are abbreviated in this figure.", "labels": [], "entities": []}, {"text": "When we focus on the error output, we can observe that \"ARG1\" of predicate \"on\" was mistaken by the parser.", "labels": [], "entities": [{"text": "ARG1", "start_pos": 56, "end_pos": 60, "type": "METRIC", "confidence": 0.8560770153999329}]}, {"text": "In this case, \"ARG1\" represents a modifiee of the preposition, and we then conclude that the ill attachment of a prepositional phrase caused this error.", "labels": [], "entities": [{"text": "ARG1", "start_pos": 15, "end_pos": 19, "type": "METRIC", "confidence": 0.810336172580719}]}, {"text": "By continuing such error analysis, weak points of the parser are revealed and can be useful clues for further improvements.", "labels": [], "entities": []}, {"text": "However, inmost researches on parsing technologies, error analysis has been limited to narrow and shallow explorations since there are various dependencies behind erroneous outputs.", "labels": [], "entities": [{"text": "parsing", "start_pos": 30, "end_pos": 37, "type": "TASK", "confidence": 0.9759281277656555}, {"text": "error analysis", "start_pos": 52, "end_pos": 66, "type": "TASK", "confidence": 0.7956356108188629}]}, {"text": "In, for example, two errors were given: wrong outputs for \"ARG1\" of \"which\" and \"ARG2\" of \"read.\"", "labels": [], "entities": [{"text": "ARG1", "start_pos": 59, "end_pos": 63, "type": "METRIC", "confidence": 0.742861807346344}]}, {"text": "Both of these two errors originated from the fact that the relative clause took a wrong antecedent \"the shelf.\"", "labels": [], "entities": []}, {"text": "In this sentence, the former Error: ARG1  We applied our approaches to parsing errors given by the HPSG parser Enju, which was trained on the Penn Treebank () section 2-21.", "labels": [], "entities": [{"text": "Error", "start_pos": 29, "end_pos": 34, "type": "METRIC", "confidence": 0.9977147579193115}, {"text": "ARG1", "start_pos": 36, "end_pos": 40, "type": "METRIC", "confidence": 0.9021875858306885}, {"text": "parsing", "start_pos": 71, "end_pos": 78, "type": "TASK", "confidence": 0.9804460406303406}, {"text": "HPSG parser Enju", "start_pos": 99, "end_pos": 115, "type": "DATASET", "confidence": 0.7880167166392008}, {"text": "Penn Treebank () section 2-21", "start_pos": 142, "end_pos": 171, "type": "DATASET", "confidence": 0.9850788593292237}]}, {"text": "We first examined each approach, and then explored the combination of the approaches.", "labels": [], "entities": []}, {"text": "We examined our descriptive approach.", "labels": [], "entities": []}, {"text": "We first parsed sentences in the Penn Treebank section 22 with Enju, and then observed the errors.", "labels": [], "entities": [{"text": "Penn Treebank section 22", "start_pos": 33, "end_pos": 57, "type": "DATASET", "confidence": 0.983647882938385}]}, {"text": "Based on the observation, we next described the patterns as shown in Section 3.", "labels": [], "entities": []}, {"text": "After that, we parsed section 0 and then applied the patterns to the errors.", "labels": [], "entities": []}, {"text": "As the table shows, with the 14 error patterns, we successfully matched 1,671 locations in error outputs and covered 2,078 of 4,709 errors, which comprised of more than 40% of the total errors.", "labels": [], "entities": []}, {"text": "This was the first step of the application of our approach, and in the future work we would like to: Frequency of each size of co-occurring error group add more patterns for capturing more phenomena.", "labels": [], "entities": [{"text": "Frequency", "start_pos": 101, "end_pos": 110, "type": "METRIC", "confidence": 0.9851745963096619}]}, {"text": "When we focused on individual patterns, we could observe that the simple error phenomena such as the attachments were dominant.", "labels": [], "entities": []}, {"text": "The first reason for this would be that such phenomena were among minimal linguistic events.", "labels": [], "entities": []}, {"text": "This would make the phenomena components of other more complex ones.", "labels": [], "entities": []}, {"text": "The second reason for the dominance would be that the patterns for these error phenomena were easy to implement only with argument inconsistencies, and only one or a few patterns could cover every probable error.", "labels": [], "entities": []}, {"text": "Among these dominant error types, the number of prepositional attachments was outstanding.", "labels": [], "entities": []}, {"text": "The error types which required matching with predicate types were fewer than the attachment errors since the limited patterns on the predicate types would narrow the possible linguistic behavior of the candidate words.", "labels": [], "entities": []}, {"text": "When we focus on more structural errors, the table shows that the rates of the participant errors to matched locations were much larger than those for simpler pattern errors.", "labels": [], "entities": []}, {"text": "Once our patterns matches, they could collect many errors at the same time.", "labels": [], "entities": []}, {"text": "Next, we applied our empirical approach in the same settings as in the previous section.", "labels": [], "entities": []}, {"text": "We first parsed sentences in section 0 and then applied our approach to the obtained errors.", "labels": [], "entities": []}, {"text": "In the experiments, some errors could not be forcibly corrected by our approach.", "labels": [], "entities": []}, {"text": "The parser \"cut off\" less probable parse substructures before giving the predicate  In this research, we ignored the errors which were subject to such \"cut off\" as \"uncorrectable\" ones, and focused only on the remaining \"correctable\" errors.", "labels": [], "entities": []}, {"text": "In our future work, we would like to consider the \"uncorrectable\" errors.", "labels": [], "entities": []}, {"text": "shows the summary of the analysis with our approach.", "labels": [], "entities": []}, {"text": "Enju gave 4,709 errors for section 0.", "labels": [], "entities": [{"text": "errors", "start_pos": 16, "end_pos": 22, "type": "METRIC", "confidence": 0.946435809135437}]}, {"text": "Among these errors, the correctable errors were 3,085, and from these errors, we successfully obtained 1,978 co-occurring error groups and 501 inductive relations.", "labels": [], "entities": []}, {"text": "shows the frequency for each size of co-occurring groups.", "labels": [], "entities": []}, {"text": "About a half of the groups contains only single errors, which would indicate that the errors could have only oneway inductive relations with other errors.", "labels": [], "entities": []}, {"text": "The rest of this section explores examples of the obtained co-occurring error groups and inductive relations.", "labels": [], "entities": []}, {"text": "shows an example of the extracted cooccurring error groups.", "labels": [], "entities": []}, {"text": "For the sentence shown at the top of the figure, Enju gave seven errors.", "labels": [], "entities": []}, {"text": "By introducing our empirical approach, these errors were definitely classified into four co-occurring error groups (a) to (d), and there were no inductive relations detected among them.", "labels": [], "entities": []}, {"text": "Group (a) contains two errors on the comma's local behavior as apposition or coordination.", "labels": [], "entities": []}, {"text": "Group (b) contains the errors on the words which gave almost the same attachment behaviors.", "labels": [], "entities": []}, {"text": "Group (c) contains the errors on whether the verb \"show\" took \"decades\": Inductive relation between obtained cooccurring error groups as its objector not.", "labels": [], "entities": []}, {"text": "Group (d) contains an error on the attachment of the adverb \"later\".", "labels": [], "entities": []}, {"text": "Regardless of the overlap of the regions in the sentence for (c) and (d), our approach successfully classified the errors into the two independent groups.", "labels": [], "entities": []}, {"text": "With our approach, it would be empirically shown that the errors in each group actually co-occurred and the group was independent.", "labels": [], "entities": []}, {"text": "This would enable us to concentrate on each of the co-occurring error groups without paying attention to the influences from the errors in other groups.", "labels": [], "entities": []}, {"text": "shows another example of the analysis with our empirical approach.", "labels": [], "entities": []}, {"text": "In this case, 8 errors fora sentence were classified into two cooccurring error groups (a) and (b), and our approach showed that correction in group (a) resulted in correcting group (b) together.", "labels": [], "entities": []}, {"text": "The errors in group (a) were on whether \"help\" behaved as an auxiliary or pure verbal role.", "labels": [], "entities": []}, {"text": "The errors in group (b) were on whether \"save\" took only one object \"her teaching certificate,\" or two objects \"her\" and \"teaching certificate.\"", "labels": [], "entities": []}, {"text": "Between group (a) and (b), no \"structural\" conflict could be found when correcting only each of the groups.", "labels": [], "entities": []}, {"text": "We could then guess that the inductive relation between these two groups was implicitly given by the disambiguation model of the parser.", "labels": [], "entities": []}, {"text": "By dividing the errors into minimum units and clarifying the effects of correcting a target error, error analysis with our empirical approach could suggest some policy for parser improvements.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 3: Errors extracted with descriptive analysis", "labels": [], "entities": [{"text": "Errors", "start_pos": 10, "end_pos": 16, "type": "METRIC", "confidence": 0.9775631427764893}]}, {"text": " Table 5: Induction relations between errors for each linguistic phenomenon and other errors", "labels": [], "entities": []}]}