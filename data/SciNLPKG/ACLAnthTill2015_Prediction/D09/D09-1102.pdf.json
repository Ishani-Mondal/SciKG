{"title": [{"text": "Global Learning of Noun Phrase Anaphoricity in Coreference Resolu- tion via Label Propagation", "labels": [], "entities": [{"text": "Global Learning of Noun Phrase Anaphoricity", "start_pos": 0, "end_pos": 43, "type": "TASK", "confidence": 0.596046601732572}, {"text": "Coreference Resolu- tion", "start_pos": 47, "end_pos": 71, "type": "TASK", "confidence": 0.7434352189302444}]}], "abstractContent": [{"text": "Knowledge of noun phrase anaphoricity might be profitably exploited in coreference resolution to bypass the resolution of non-anaphoric noun phrases.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 71, "end_pos": 93, "type": "TASK", "confidence": 0.969258189201355}]}, {"text": "However, it is surprising to notice that recent attempts to incorporate automatically acquired anaphoricity information into coreference resolution have been somewhat disappointing.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 125, "end_pos": 147, "type": "TASK", "confidence": 0.9771592319011688}]}, {"text": "This paper employs a global learning method in determining the anaphoricity of noun phrases via a label propagation algorithm to improve learning-based coreference resolution.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 152, "end_pos": 174, "type": "TASK", "confidence": 0.743475615978241}]}, {"text": "In particular, two kinds of kernels, i.e. the feature-based RBF kernel and the convolution tree kernel, are employed to compute the anaphoricity similarity between two noun phrases.", "labels": [], "entities": []}, {"text": "Experiments on the ACE 2003 corpus demonstrate the effectiveness of our method in anaphoric-ity determination of noun phrases and its application in learning-based coreference resolution .", "labels": [], "entities": [{"text": "ACE 2003 corpus", "start_pos": 19, "end_pos": 34, "type": "DATASET", "confidence": 0.9844370086987814}, {"text": "coreference resolution", "start_pos": 164, "end_pos": 186, "type": "TASK", "confidence": 0.8281371593475342}]}], "introductionContent": [{"text": "Coreference resolution, the task of determining which noun phrases (NPs) in a text refer to the same real-world entity, has long been considered an important and difficult problem in natural language processing.", "labels": [], "entities": [{"text": "Coreference resolution, the task of determining which noun phrases (NPs) in a text refer to the same real-world entity", "start_pos": 0, "end_pos": 118, "type": "Description", "confidence": 0.7051604322411797}]}, {"text": "Identifying the linguistic constraints on when two NPs can co-refer remains an active area of research in the community.", "labels": [], "entities": []}, {"text": "One significant constraint on coreference, the anaphoricity constraint, specifies that a nonanaphoric NP cannot be coreferent with any of its preceding NPs in a given text.", "labels": [], "entities": [{"text": "coreference", "start_pos": 30, "end_pos": 41, "type": "TASK", "confidence": 0.9685848355293274}]}, {"text": "Therefore, it is useful to skip over these non-anaphoric NPs rather than attempt an unnecessary search for an antecedent for them, only to end up with inaccurate outcomes.", "labels": [], "entities": []}, {"text": "Although many existing machine learning approaches to coreference resolution have performed reasonably well without explicit anaphoricity determination (e.g.,, anaphoricity determination has been studied fairly extensively in the literature, given the potential usefulness of NP anaphoricity in coreference resolution.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 54, "end_pos": 76, "type": "TASK", "confidence": 0.9708476066589355}, {"text": "anaphoricity determination", "start_pos": 160, "end_pos": 186, "type": "TASK", "confidence": 0.6955114454030991}, {"text": "coreference resolution", "start_pos": 295, "end_pos": 317, "type": "TASK", "confidence": 0.948948323726654}]}, {"text": "One common approach involves the design of heuristic rules to identify specific types of nonanaphoric NPs, such as pleonastic pronouns (e.g.) and existential definite descriptions (e.g.,.", "labels": [], "entities": []}, {"text": "More recently, the problem has been tackled using statistics-based (e.g., and learning-based (e.g. methods.", "labels": [], "entities": []}, {"text": "Although there is empirical evidence ( e.g.) that coreference resolution might be further improved with proper anaphoricity information, its contribution is still somewhat disappointing and lacks systematic evaluation.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 50, "end_pos": 72, "type": "TASK", "confidence": 0.9801340997219086}]}, {"text": "This paper employs a label propagation (LP) algorithm for global learning of NP anaphoricity.", "labels": [], "entities": [{"text": "label propagation (LP)", "start_pos": 21, "end_pos": 43, "type": "METRIC", "confidence": 0.6864329814910889}]}, {"text": "Given the labeled data and the unlabeled data, the LP algorithm first represents labeled and unlabeled instances as vertices in a connected graph, then propagates the label information from any vertex to nearby vertices through weighted edges and finally infers the labels of unlabeled instances until a global stable stage is achieved.", "labels": [], "entities": []}, {"text": "Here, the labeled data in this paper include all the NPs in the training texts with the anaphoricity labeled and the unlabeled data include all the NPs in a test text with the anaphoricity unlabeled.", "labels": [], "entities": []}, {"text": "One major advantage of LPbased anaphoricity determination is that the anaphoricity of all the NPs in a text can be determined together in a global way.", "labels": [], "entities": [{"text": "LPbased anaphoricity determination", "start_pos": 23, "end_pos": 57, "type": "TASK", "confidence": 0.6013674437999725}]}, {"text": "Compared with previous methods, the LP algorithm can effectively capture the natural clustering structure in both the labeled and unlabeled data to smooth the labeling function.", "labels": [], "entities": []}, {"text": "In particular, two kinds of kernels, i.e. the feature-based RBF kernel and the convolution tree kernel, are employed to compute the anaphoricity similarity between two NPs and weigh the edge between them.", "labels": [], "entities": []}, {"text": "Experiments on the ACE 2003 corpus show that our LP-based anaphoricity determination significantly outperforms locally-optimized one, which adopts a classifier (e.g. SVM) to determine the anaphoricity of NPs in a text individually and significantly improves the performance of learning-based coreference resolution.", "labels": [], "entities": [{"text": "ACE 2003 corpus", "start_pos": 19, "end_pos": 34, "type": "DATASET", "confidence": 0.9737751086552938}, {"text": "coreference resolution", "start_pos": 292, "end_pos": 314, "type": "TASK", "confidence": 0.8234939873218536}]}, {"text": "It also shows that, while feature-based anaphoricity determination contributes much to pronoun resolution, its contribution on definite NP resolution can be ignored.", "labels": [], "entities": [{"text": "pronoun resolution", "start_pos": 87, "end_pos": 105, "type": "TASK", "confidence": 0.786421000957489}, {"text": "NP resolution", "start_pos": 136, "end_pos": 149, "type": "TASK", "confidence": 0.7543110549449921}]}, {"text": "In comparison, it shows that tree kernel-based anaphoricity resolution contributes significantly to the resolution of both pronouns and definite NPs due to the inclusion of various kinds of syntactic structured information.", "labels": [], "entities": [{"text": "tree kernel-based anaphoricity resolution", "start_pos": 29, "end_pos": 70, "type": "TASK", "confidence": 0.6800000369548798}]}, {"text": "The rest of this paper is organized as follows.", "labels": [], "entities": []}, {"text": "In Section 2, we review related work in anaphoricity determination.", "labels": [], "entities": [{"text": "anaphoricity determination", "start_pos": 40, "end_pos": 66, "type": "TASK", "confidence": 0.8527160286903381}]}, {"text": "Then, the LP algorithm is introduced in Section 3 while Section 4 describes different similarity measurements explored in the LP algorithm.", "labels": [], "entities": []}, {"text": "Section 5 shows the experimental results.", "labels": [], "entities": []}, {"text": "Finally, we conclude our work in Section 6.", "labels": [], "entities": []}], "datasetContent": [{"text": "We have systematically evaluated the label propagation algorithm on global learning of NP anaphoricity determination on the ACE 2 003 corpus, and its application in coreference resolution.", "labels": [], "entities": [{"text": "label propagation", "start_pos": 37, "end_pos": 54, "type": "TASK", "confidence": 0.7482649981975555}, {"text": "NP anaphoricity determination", "start_pos": 87, "end_pos": 116, "type": "TASK", "confidence": 0.7018069624900818}, {"text": "ACE 2 003 corpus", "start_pos": 124, "end_pos": 140, "type": "DATASET", "confidence": 0.9692799299955368}, {"text": "coreference resolution", "start_pos": 165, "end_pos": 187, "type": "TASK", "confidence": 0.9646995663642883}]}, {"text": "The ACE 2003 corpus contains three domains: newswire (NWIRE), newspaper (NPAPER), and broadcast news (BNEWS).", "labels": [], "entities": [{"text": "ACE 2003 corpus", "start_pos": 4, "end_pos": 19, "type": "DATASET", "confidence": 0.9315537810325623}]}, {"text": "For each domain, there exist two data sets, training and devtest, which are used for training and testing respectively.", "labels": [], "entities": []}, {"text": "As a baseline coreference resolution system, a raw test text is first preprocessed automatically by a pipeline of NLP components, including sentence boundary detection, POS tagging, named entity recognition and phrase chunking, and then a training or test instance is formed by a anaphor and one of its antecedent candidates, similar to Soon e t al.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 14, "end_pos": 36, "type": "TASK", "confidence": 0.7987711429595947}, {"text": "sentence boundary detection", "start_pos": 140, "end_pos": 167, "type": "TASK", "confidence": 0.6439470847447714}, {"text": "POS tagging", "start_pos": 169, "end_pos": 180, "type": "TASK", "confidence": 0.7754993140697479}, {"text": "named entity recognition", "start_pos": 182, "end_pos": 206, "type": "TASK", "confidence": 0.6661832829316457}, {"text": "phrase chunking", "start_pos": 211, "end_pos": 226, "type": "TASK", "confidence": 0.7120034098625183}]}, {"text": "Among them, named entity recognition, part-of-speech tagging and noun phrase chunking apply the same Hidden Markov Model (HMM)-based engine with error-driven learning capability.", "labels": [], "entities": [{"text": "named entity recognition", "start_pos": 12, "end_pos": 36, "type": "TASK", "confidence": 0.644390215476354}, {"text": "part-of-speech tagging", "start_pos": 38, "end_pos": 60, "type": "TASK", "confidence": 0.7599542737007141}, {"text": "noun phrase chunking", "start_pos": 65, "end_pos": 85, "type": "TASK", "confidence": 0.7171518802642822}]}, {"text": "During training, for each anaphor encountered, a positive instance is created by pairing the anaphor and its closest antecedent while a set of negative instances is formed by pairing the anaphor with each of the noncoreferential candidates.", "labels": [], "entities": []}, {"text": "Based on the training instances, a binary classifier is generated using a particular learning algorithm.", "labels": [], "entities": []}, {"text": "In this paper, we use SVMLight developed by.", "labels": [], "entities": []}, {"text": "During resolution, an anaphor is first paired in turn with each preceding antecedent candidate to form a test instance, which is presented to a classifier.", "labels": [], "entities": [{"text": "resolution", "start_pos": 7, "end_pos": 17, "type": "TASK", "confidence": 0.9686856865882874}]}, {"text": "The classifier then returns a confidence value indicating the likelihood that the candidate is the antecedent.", "labels": [], "entities": []}, {"text": "Finally, the candidate with the highest confidence value is selected as the antecedent.", "labels": [], "entities": []}, {"text": "As a baseline, the NPs with mismatched number, person and gender agreements are filtered out.", "labels": [], "entities": []}, {"text": "On average, an anaphor has ~7 antecedent candidates.", "labels": [], "entities": []}, {"text": "In particular, the test corpus is resolved in document-level, i.e. one document by one document.", "labels": [], "entities": []}, {"text": "For anaphoricity determination, we report the performance in Acc + and Acc -, which measure the accuracies of identifying anaphoric NPs and non-anaphoric NPs, respectively.", "labels": [], "entities": [{"text": "anaphoricity determination", "start_pos": 4, "end_pos": 30, "type": "TASK", "confidence": 0.8319786190986633}, {"text": "Acc", "start_pos": 61, "end_pos": 64, "type": "METRIC", "confidence": 0.9908916354179382}, {"text": "Acc -", "start_pos": 71, "end_pos": 76, "type": "METRIC", "confidence": 0.9775700271129608}]}, {"text": "Obviously, higher Acc + means that more anaphoric NPs would be identified correctly, while higher Accmeans that more non-anaphoric NPs would be filtered out.", "labels": [], "entities": [{"text": "Acc +", "start_pos": 18, "end_pos": 23, "type": "METRIC", "confidence": 0.975574404001236}, {"text": "Accmeans", "start_pos": 98, "end_pos": 106, "type": "METRIC", "confidence": 0.9936221241950989}]}, {"text": "For coreference resolution, we report the performance in terms of recall, precision, and F 1-measure using the commonly-used model theoretic MUC scoring program ().", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 4, "end_pos": 26, "type": "TASK", "confidence": 0.9759908318519592}, {"text": "recall", "start_pos": 66, "end_pos": 72, "type": "METRIC", "confidence": 0.9994992017745972}, {"text": "precision", "start_pos": 74, "end_pos": 83, "type": "METRIC", "confidence": 0.998991072177887}, {"text": "F 1-measure", "start_pos": 89, "end_pos": 100, "type": "METRIC", "confidence": 0.9885134994983673}]}, {"text": "For separate scoring of different NP types, a recognized reference is considered correct if the reconized antecedent is in the coreferential chain of the anaphor.", "labels": [], "entities": []}, {"text": "To see whether an improvement is significant, we conduct significance testing using paired t-test.", "labels": [], "entities": []}, {"text": "In this paper, '>>>', '>>' and '>' denote p-values of an improvement smaller than 0.01, inbetween (0.01, 0,05] and bigger than 0.05, which mean significantly better, moderately better and slightly better, respectively.", "labels": [], "entities": []}, {"text": "shows the performance of LP-based anaphoricity determination using the feature-based RBF kernel.", "labels": [], "entities": []}, {"text": "It shows that our method achieves the accuracies of 74.8/84.4, 7 6.2/81.3 and 71.8/81.7 on identifying anaphoric/nonanaphoric NPs in the NWIRE, NPAPER and BNEWS domains, respectively.", "labels": [], "entities": [{"text": "accuracies", "start_pos": 38, "end_pos": 48, "type": "METRIC", "confidence": 0.9901567697525024}, {"text": "NWIRE", "start_pos": 137, "end_pos": 142, "type": "DATASET", "confidence": 0.9360999464988708}, {"text": "NPAPER", "start_pos": 144, "end_pos": 150, "type": "DATASET", "confidence": 0.6548848748207092}, {"text": "BNEWS domains", "start_pos": 155, "end_pos": 168, "type": "DATASET", "confidence": 0.8141406774520874}]}, {"text": "This suggests that our approach can effectively filter out about 82% of non-anaphoric NPs.", "labels": [], "entities": []}, {"text": "However, it can only keep about 74% of anaphoric NPs.", "labels": [], "entities": []}, {"text": "also shows the performance on different NP types.", "labels": [], "entities": []}, {"text": "Considering the effectiveness of anaphoricity determination on indefinite NPs (due to that most of anaphoric indefinite NPs are in an appositive structure and thus can be easily captured by the IsAppositive feature) and that most of errors in anaphoricity determination on proper nouns are caused by the named entity recognition module in the preprocessing), it indicates the difficulty of anaphoricity determination in filtering out non-anaphoric pronouns and identifying anaphoric definite NPs.", "labels": [], "entities": [{"text": "anaphoricity determination", "start_pos": 390, "end_pos": 416, "type": "TASK", "confidence": 0.7097084820270538}]}, {"text": "As a comparison, also shows the performance of locally-optimized anaphoricity determination using a classifier (SVM with the feature-based RBF kernel, as adopted in this paper) to determine the NPs in a text individually.", "labels": [], "entities": []}, {"text": "It shows that the LP-based method systematically outperforms (>>>) the SVM-based method.", "labels": [], "entities": []}, {"text": "This suggests the effectiveness of the LP algorithm in global modeling of the natural clustering structure in anaphoricity determination.", "labels": [], "entities": [{"text": "anaphoricity determination", "start_pos": 110, "end_pos": 136, "type": "TASK", "confidence": 0.7371539771556854}]}, {"text": "shows the performance of LP-based anaphoricity determination using the convolution tree kernel on different parse tree structures.", "labels": [], "entities": []}, {"text": "It shows that while MT performed worst due to its simple structure, DET outperforms MT(>>>), SPT(>>>) and CT(>>>) on all the three domains due to fine inclusion of necessary structural information, although inclusion of more information in both CT and SPT also improves the performance.", "labels": [], "entities": [{"text": "MT", "start_pos": 20, "end_pos": 22, "type": "TASK", "confidence": 0.9782229661941528}]}, {"text": "It again verifies that LP-based anaphoricity determination outperforms (>>>) SVM-based one, using the tree kernel.", "labels": [], "entities": []}, {"text": "further indicates that all the three kinds of structural information related with antecedent candidates, predicates and right siblings in DET contribute significantly (>>>).", "labels": [], "entities": [{"text": "DET", "start_pos": 138, "end_pos": 141, "type": "TASK", "confidence": 0.8811521530151367}]}, {"text": "In addition, shows the detailed performance of LP-based anaphoricity determination on different anaphor types using DET.", "labels": [], "entities": [{"text": "DET", "start_pos": 116, "end_pos": 119, "type": "DATASET", "confidence": 0.7723705768585205}]}, {"text": "Compared with the featurebased RBF kernel as shown in, it shows that the convolution tree kernel significantly outperforms (>>>) the feature-based RBF kernel in all the three domains, with much contribution due to performance improvement on both pronouns and definite NPs, although the tree kernel performs moderately worse than the featurebased RBF kernel due to the effectiveness of anaphoricity determination on proper nouns and indefinite NPs using the IsNameAlias and IsAppositive features respectively.: The performance of LP-based anaphoricity determination using the tree kernel on DET Finally, we evaluate the effect of LP-based anaphoricity determination on coreference resolution by including it as a preprocessing step to a baseline coreference resolution system without explicit anaphoricity determination, which employs the same set of features, as adopted in the single-candidate model of, using a SVM-based classifier and the featurebased RBF kernel.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 668, "end_pos": 690, "type": "TASK", "confidence": 0.9365443289279938}]}, {"text": "It shows that anaphoricity determination with the feature-based RBF Kernel much improves (>>>) the performance of coreference resolution with most of the contribution due to pronoun resolution while its contribution on definite NPs can be ignored.", "labels": [], "entities": [{"text": "anaphoricity determination", "start_pos": 14, "end_pos": 40, "type": "TASK", "confidence": 0.6524679362773895}, {"text": "RBF Kernel", "start_pos": 64, "end_pos": 74, "type": "DATASET", "confidence": 0.8658578991889954}, {"text": "coreference resolution", "start_pos": 114, "end_pos": 136, "type": "TASK", "confidence": 0.9625033140182495}, {"text": "pronoun resolution", "start_pos": 174, "end_pos": 192, "type": "TASK", "confidence": 0.7488243579864502}]}, {"text": "It indicates the usefulness of anaphoricity determination in filtering out non-anaphoric pronouns and the difficulty in identifying anaphoric definite NPs, using the feature-based RBF kernel.", "labels": [], "entities": [{"text": "anaphoricity determination", "start_pos": 31, "end_pos": 57, "type": "TASK", "confidence": 0.6864622235298157}]}, {"text": "It also shows that tree kernel-based anaphoricity determination cannot only improve (>>>) the performance on pronoun resolution but also improve (>>>) the performance on definite NP resolution due to the much better performance of tree kernel-based anaphoricity determination on definite NPs.", "labels": [], "entities": [{"text": "tree kernel-based anaphoricity determination", "start_pos": 19, "end_pos": 63, "type": "TASK", "confidence": 0.6141122207045555}, {"text": "pronoun resolution", "start_pos": 109, "end_pos": 127, "type": "TASK", "confidence": 0.7201585620641708}]}, {"text": "This suggests the necessity of exploring structural information in identifying anaphoric definite NPs.: Employment of anaphoricity determination in coreference resolution", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 148, "end_pos": 170, "type": "TASK", "confidence": 0.9741634428501129}]}], "tableCaptions": [{"text": " Table 1: Features in anaphoricity determination of NPs. Note: the semantic role-related features are derived from  an in-house state-of-the-art semantic role labeling system.", "labels": [], "entities": [{"text": "anaphoricity determination of NPs", "start_pos": 22, "end_pos": 55, "type": "TASK", "confidence": 0.7873857766389847}]}, {"text": " Table 2: The performance of LP-based anaphoric- ity determination using the feature-based RBF kernel", "labels": [], "entities": []}, {"text": " Table 6: Employment of anaphoricity determination in coreference resolution", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 54, "end_pos": 76, "type": "TASK", "confidence": 0.9831856787204742}]}]}