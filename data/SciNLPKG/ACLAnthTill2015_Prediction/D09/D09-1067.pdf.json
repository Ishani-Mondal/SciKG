{"title": [{"text": "Improving Verb Clustering with Automatically Acquired Selectional Preferences", "labels": [], "entities": [{"text": "Improving Verb Clustering", "start_pos": 0, "end_pos": 25, "type": "TASK", "confidence": 0.8438645402590433}]}], "abstractContent": [{"text": "In previous research in automatic verb classification, syntactic features have proved the most useful features, although manual classifications rely heavily on semantic features.", "labels": [], "entities": [{"text": "automatic verb classification", "start_pos": 24, "end_pos": 53, "type": "TASK", "confidence": 0.6354112923145294}]}, {"text": "We show, in contrast with previous work, that considerable additional improvement can be obtained by using semantic features in automatic classification: verb selectional preferences acquired from corpus data using a fully unsu-pervised method.", "labels": [], "entities": []}, {"text": "We report these promising results using anew framework for verb clustering which incorporates a recent subcategorization acquisition system, rich syntactic-semantic feature sets, and a variation of spectral clustering which performs particularly well in high dimensional feature space.", "labels": [], "entities": [{"text": "verb clustering", "start_pos": 59, "end_pos": 74, "type": "TASK", "confidence": 0.7443419694900513}]}], "introductionContent": [{"text": "Verb classifications have attracted a great deal of interest in natural language processing (NLP).", "labels": [], "entities": [{"text": "Verb classifications", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.8231724500656128}, {"text": "natural language processing (NLP)", "start_pos": 64, "end_pos": 97, "type": "TASK", "confidence": 0.8026670714219412}]}, {"text": "They have proved useful for various important NLP tasks and applications, including e.g. parsing, word sense disambiguation, semantic role labeling, information extraction, question-answering, and machine translation (.", "labels": [], "entities": [{"text": "word sense disambiguation", "start_pos": 98, "end_pos": 123, "type": "TASK", "confidence": 0.680751105149587}, {"text": "semantic role labeling", "start_pos": 125, "end_pos": 147, "type": "TASK", "confidence": 0.6657244265079498}, {"text": "information extraction", "start_pos": 149, "end_pos": 171, "type": "TASK", "confidence": 0.8286094069480896}, {"text": "machine translation", "start_pos": 197, "end_pos": 216, "type": "TASK", "confidence": 0.8197077810764313}]}, {"text": "Verb classes are useful because they offer a powerful tool for generalization and abstraction which can be beneficial when faced e.g. with the problem of data sparsity.", "labels": [], "entities": []}, {"text": "Particularly useful can be classes which capture generalizations over a range of (cross-)linguistic properties, such as the ones proposed by.", "labels": [], "entities": []}, {"text": "Being defined in terms of similar meaning and (morpho-)syntactic behaviour of words, Levin style classes generally incorporate a wider range of properties than e.g. classes defined solely on semantic grounds.", "labels": [], "entities": []}, {"text": "In recent years, a variety of approaches have been proposed for automatic induction of verb classes from corpus data (.", "labels": [], "entities": [{"text": "automatic induction of verb classes from corpus", "start_pos": 64, "end_pos": 111, "type": "TASK", "confidence": 0.7906998651368278}]}, {"text": "This work opens up the opportunity of learning and tuning classifications tailored to the application and domain in question.", "labels": [], "entities": []}, {"text": "Although manual classification may always yields higher accuracy, automatic verb classification is cost-effective and gathers statistical information as a side-effect of the acquisition process which is difficult for humans to gather but can be highly useful for NLP applications.", "labels": [], "entities": [{"text": "manual classification", "start_pos": 9, "end_pos": 30, "type": "TASK", "confidence": 0.7456327080726624}, {"text": "accuracy", "start_pos": 56, "end_pos": 64, "type": "METRIC", "confidence": 0.993285059928894}, {"text": "verb classification", "start_pos": 76, "end_pos": 95, "type": "TASK", "confidence": 0.715424433350563}]}, {"text": "To date, both supervised and unsupervised machine learning (ML) methods have been proposed for verb classification and used to classify a variety of features extracted from raw, tagged and/or parsed corpus data.", "labels": [], "entities": [{"text": "verb classification", "start_pos": 95, "end_pos": 114, "type": "TASK", "confidence": 0.7356017976999283}]}, {"text": "The best performing features on cross-domain verb classification have been syntactic in nature (e.g. syntactic slots, subcategorization frames (SCFs)).", "labels": [], "entities": [{"text": "cross-domain verb classification", "start_pos": 32, "end_pos": 64, "type": "TASK", "confidence": 0.7009346683820089}]}, {"text": "Disappointingly, semantic features have not yielded significant additional improvement, although they play a key role in manual and theoretical work on verb classification and could thus be expected to offer a considerable contribution to classification performance.", "labels": [], "entities": [{"text": "verb classification", "start_pos": 152, "end_pos": 171, "type": "TASK", "confidence": 0.7333225011825562}]}, {"text": "Since the accuracy of automatic verb classification shows room for improvement, we further investigate the potential of semantic featuresverb selectional preferences (SPs) -for the task.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9988378882408142}, {"text": "automatic verb classification", "start_pos": 22, "end_pos": 51, "type": "TASK", "confidence": 0.6749592820803324}]}, {"text": "We introduce a novel approach to verb clustering which involves the use of (i) a recent subcategorization frame (SCF) acquisition system () which produces rich lexical, SCF and syntactic data, (ii) novel syntactic-semantic feature sets extracted from this data which incorporate a variety of linguistic information, including SPs, and (iii) anew variation of spectral cluster-ing based on the MNCut algorithm) which is well-suited for dealing with the resulting, high dimensional feature space.", "labels": [], "entities": [{"text": "verb clustering", "start_pos": 33, "end_pos": 48, "type": "TASK", "confidence": 0.7297622263431549}]}, {"text": "Using this approach, we show on two wellestablished test sets that automatically acquired SPs can be highly useful for verb clustering.", "labels": [], "entities": [{"text": "verb clustering", "start_pos": 119, "end_pos": 134, "type": "TASK", "confidence": 0.7767303287982941}]}, {"text": "They yield high performance when used in combination with syntactic features.", "labels": [], "entities": []}, {"text": "We obtain our promising results using a fully unsupervised approach to SP acquisition which differs from previous approaches in that it does not exploit WordNet or other lexical resources.", "labels": [], "entities": [{"text": "SP acquisition", "start_pos": 71, "end_pos": 85, "type": "TASK", "confidence": 0.9863634705543518}]}, {"text": "It is based on clustering argument head data in the grammatical relations associated with verbs.", "labels": [], "entities": []}, {"text": "We describe our features in section 2 and the clustering methods in section 3.", "labels": [], "entities": []}, {"text": "Experimental evaluation and results are reported in sections 4 and 5, respectively.", "labels": [], "entities": []}, {"text": "Section 6 provides discussion and describes related work, and section 7 concludes.", "labels": [], "entities": []}], "datasetContent": [{"text": "To facilitate meaningful comparisons, we employ the same measures for evaluation as previously employed e.g. by ; \u00b4 O S\u00e9aghdha and Copestake.", "labels": [], "entities": [{"text": "Copestake", "start_pos": 131, "end_pos": 140, "type": "DATASET", "confidence": 0.8288701176643372}]}, {"text": "The first measure is modified purity (mPUR) -a global measure which evaluates the mean precision of clusters.", "labels": [], "entities": [{"text": "modified purity (mPUR)", "start_pos": 21, "end_pos": 43, "type": "METRIC", "confidence": 0.8838584303855896}, {"text": "precision", "start_pos": 87, "end_pos": 96, "type": "METRIC", "confidence": 0.7537254691123962}]}, {"text": "Each cluster is associated with its prevalent class.", "labels": [], "entities": []}, {"text": "The number of verbs in a cluster K that take this class is denoted by n prevalent (K).", "labels": [], "entities": []}, {"text": "Verbs that do not take it are considered as errors.", "labels": [], "entities": []}, {"text": "Clusters where n prevalent (K) = 1 are disregarded as not to introduce a bias towards singletons:  Comparing the feature sets, the simple cooccurrence based F1 performs clearly better than the random baseline.", "labels": [], "entities": [{"text": "F1", "start_pos": 157, "end_pos": 159, "type": "METRIC", "confidence": 0.9353192448616028}]}, {"text": "F2 and F3 which exploit lexical data in the argument head positions of GRs prove significantly better than F1.", "labels": [], "entities": [{"text": "F1", "start_pos": 107, "end_pos": 109, "type": "METRIC", "confidence": 0.9958471655845642}]}, {"text": "F3 yields surprisingly good results on T2: it is the second best feature set on this test set.", "labels": [], "entities": []}, {"text": "Also on T1, F3 performs better than the SCF-based feature sets F4-F7.", "labels": [], "entities": [{"text": "F3", "start_pos": 12, "end_pos": 14, "type": "METRIC", "confidence": 0.8885073661804199}]}, {"text": "This demonstrates the usefulness of lexical data when obtained from argument positions in relevant GRs.", "labels": [], "entities": []}, {"text": "Our basic SCF feature set F4 performs considerably better than the comparable feature set F8 obtained from the VALEX lexicon.", "labels": [], "entities": [{"text": "VALEX lexicon", "start_pos": 111, "end_pos": 124, "type": "DATASET", "confidence": 0.8854808509349823}]}, {"text": "The difference is 19.50 in F-measure.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 27, "end_pos": 36, "type": "METRIC", "confidence": 0.9897393584251404}]}, {"text": "As both lexicons were extracted from the same corpus data, the improvement can be attributed to improved parser and SCF acquisition performance (.", "labels": [], "entities": [{"text": "SCF acquisition", "start_pos": 116, "end_pos": 131, "type": "TASK", "confidence": 0.8291672170162201}]}, {"text": "F5-F7 refine the basic SCF feature set F4 further.", "labels": [], "entities": [{"text": "SCF feature set F4", "start_pos": 23, "end_pos": 41, "type": "DATASET", "confidence": 0.6629240810871124}]}, {"text": "F5 which combines a SCF with CO information proved the best feature set in the supervised verb classification experiment of.", "labels": [], "entities": [{"text": "supervised verb classification", "start_pos": 79, "end_pos": 109, "type": "TASK", "confidence": 0.6578885614871979}]}, {"text": "In our experiment, F5 produces substantially lower result than CO and SCF alone (i.e. F1 and F4).", "labels": [], "entities": [{"text": "F5", "start_pos": 19, "end_pos": 21, "type": "METRIC", "confidence": 0.8438012003898621}, {"text": "F1", "start_pos": 86, "end_pos": 88, "type": "METRIC", "confidence": 0.9964635968208313}]}, {"text": "However, our corpus is smaller (Li and Brew used the large Gigaword corpus), our SCFs are different, and our approach is unsupervised, making meaningful comparisons difficult.", "labels": [], "entities": [{"text": "Gigaword corpus", "start_pos": 59, "end_pos": 74, "type": "DATASET", "confidence": 0.9269776046276093}]}, {"text": "F6 combines F4 with information about verb tense.", "labels": [], "entities": [{"text": "F4", "start_pos": 12, "end_pos": 14, "type": "METRIC", "confidence": 0.8887343406677246}]}, {"text": "This was not helpful: F6 produces worse results than F4.", "labels": [], "entities": [{"text": "F6", "start_pos": 22, "end_pos": 24, "type": "METRIC", "confidence": 0.8373347520828247}]}, {"text": "F7, on the other hand, yields better results than F4 on both test sets.", "labels": [], "entities": []}, {"text": "This demonstrates what the previous research has shown: SCF perform better when parameterized for prepositions.", "labels": [], "entities": []}, {"text": "Looking at our novel feature sets F9-F17, F9-F11 combine the most accurate SCF feature set F4 with the LP-based features F2-F3.", "labels": [], "entities": []}, {"text": "Although the feature space gets more sparse, all the feature sets outperform F2-F3 on T1.", "labels": [], "entities": []}, {"text": "On T2, F3 performs exceptionally well, and thus yields a better result than F9-F11, but F9-F11 nevertheless perform clearly better than the best SCF-based feature set F4 alone.", "labels": [], "entities": []}, {"text": "The differences among F9, F10 and F11 are small on T2, but on T1 F9 yields the best performance.", "labels": [], "entities": [{"text": "F9", "start_pos": 22, "end_pos": 24, "type": "METRIC", "confidence": 0.5787975788116455}, {"text": "F10", "start_pos": 26, "end_pos": 29, "type": "METRIC", "confidence": 0.9869286417961121}, {"text": "F11", "start_pos": 34, "end_pos": 37, "type": "METRIC", "confidence": 0.989872932434082}]}, {"text": "It could be that F9 works the best for the more sparse T1 because it suffers the least from data sparsity (it uses LPs only for the subject relation).", "labels": [], "entities": [{"text": "F9", "start_pos": 17, "end_pos": 19, "type": "METRIC", "confidence": 0.4387505054473877}]}, {"text": "F12-F17 replace the LPs in F9-F11 by semantic SPs.", "labels": [], "entities": []}, {"text": "When only 20 clusters are used as SP models and acquired from the smaller sample of (200) argument heads (F12-F14), SPs do not perform better than LPs on T2.", "labels": [], "entities": []}, {"text": "A small improvement can be observed on T1, especially with F12 which uses only the subject data (yielding the best F measure on T1: 57.75%).", "labels": [], "entities": [{"text": "F12", "start_pos": 59, "end_pos": 62, "type": "METRIC", "confidence": 0.994232714176178}, {"text": "F measure", "start_pos": 115, "end_pos": 124, "type": "METRIC", "confidence": 0.9877310991287231}]}, {"text": "However, when 30 more finegrained clusters are acquired from a bigger sample of (500) argument heads (F15-F17), lower results can be seen on T1.", "labels": [], "entities": [{"text": "F15-F17", "start_pos": 102, "end_pos": 109, "type": "METRIC", "confidence": 0.9395588636398315}]}, {"text": "On T2, on the other hand, F15 yields dramatic improvement and we get the best performance for this test set: 80.35% F-measure.", "labels": [], "entities": [{"text": "F15", "start_pos": 26, "end_pos": 29, "type": "METRIC", "confidence": 0.9981811046600342}, {"text": "F-measure", "start_pos": 116, "end_pos": 125, "type": "METRIC", "confidence": 0.9994637370109558}]}, {"text": "The fact that no improvement is observed when using F16 and F17 on T2 could be explained by the fact that SPs are stronger for the subject position which also suffers less from the sparse data problem than e.g. i. object position.", "labels": [], "entities": [{"text": "F16", "start_pos": 52, "end_pos": 55, "type": "METRIC", "confidence": 0.9422470927238464}]}, {"text": "The fact that no improvement is observed on T1 is likely to be due to the fact that verbs have strong SPs only at the finer-grained level of Levin classification.", "labels": [], "entities": []}, {"text": "Recall that in T1, as many as half of the classes are coarser-grained.", "labels": [], "entities": []}, {"text": "The best performing feature sets on both T1 and T2 were thus our new SP-based feature sets.", "labels": [], "entities": [{"text": "T1 and T2", "start_pos": 41, "end_pos": 50, "type": "DATASET", "confidence": 0.7049160798390707}]}, {"text": "We conducted qualitative analysis of the best 30 SP: Cluster analysis: 20 clusters, their SP labels, and prototypical member nouns clusters in the T2 data created using SPEC to find out whether these clusters were really semantic in nature, i.e. captured semantically meaningful preferences.", "labels": [], "entities": []}, {"text": "As no gold standard specific to our verb classification task was available, we did manual cluster analysis using VerbNet (VN) as aid.", "labels": [], "entities": [{"text": "verb classification task", "start_pos": 36, "end_pos": 60, "type": "TASK", "confidence": 0.7933459579944611}, {"text": "cluster analysis", "start_pos": 90, "end_pos": 106, "type": "TASK", "confidence": 0.7706252038478851}, {"text": "VerbNet (VN)", "start_pos": 113, "end_pos": 125, "type": "DATASET", "confidence": 0.7802080810070038}]}, {"text": "In VN, Levin classes are assigned with semantic descriptions: the arguments of SCFs involved in diathesis alternations are labeled with thematic roles some of which are labeled with selectional restrictions.", "labels": [], "entities": [{"text": "VN", "start_pos": 3, "end_pos": 5, "type": "DATASET", "confidence": 0.8090481758117676}]}, {"text": "From the 30 thematic role types in VN, as many as 20 are associated with the 17 Levin classes in T2.", "labels": [], "entities": [{"text": "VN", "start_pos": 35, "end_pos": 37, "type": "DATASET", "confidence": 0.8835666179656982}]}, {"text": "The most frequent role in T2 is agent, followed by theme, location, patient, recipient, and source.", "labels": [], "entities": []}, {"text": "From the 36 possible selectional restriction types, 7 appear in T2; the most frequent ones being +animate and +organization, followed by +concrete, +location, and +communication.", "labels": [], "entities": []}, {"text": "As SP clusters capture selectional preferences rather than restrictions, we examined manually whether the 30 clusters (i) capture semantically meaningful classes, and whether they (ii) are plausible given the VN semantic descriptions/restrictions for the classes in T2.", "labels": [], "entities": []}, {"text": "The analysis revealed that all the 30 clusters had a predominant, semantically motivated SP supported by the majority of the member nouns.", "labels": [], "entities": [{"text": "SP", "start_pos": 89, "end_pos": 91, "type": "METRIC", "confidence": 0.8736998438835144}]}, {"text": "Although many clusters could be further divided into more specific SPs (and despite the fact that some nouns were clearly misclassified), we were able to assign each cluster a descriptive label characterizing the predominant SP.", "labels": [], "entities": []}, {"text": "shows 15 sam-ple clusters, the SP labels assigned to them, and a number of example nouns in these clusters.", "labels": [], "entities": []}, {"text": "When comparing each SP cluster against the VN semantic descriptions/restrictions for T2, we found that each predominant SP was plausible.", "labels": [], "entities": []}, {"text": "Also, the SPs frequent in our data were also frequent among the 17 classes according to For example, the many SP clusters labeled as arrangements, issues, ideas and other abstract concepts were also frequent in T2, e.g. among COMMUNI-CATION (37), CHARACTERISE (29.2), AMALGA-MATE (22.2) and other classes.", "labels": [], "entities": [{"text": "AMALGA-MATE", "start_pos": 268, "end_pos": 279, "type": "METRIC", "confidence": 0.7506210207939148}]}, {"text": "This analysis showed that the SP models which performed well in verb clustering were semantically meaningful for our task.", "labels": [], "entities": [{"text": "verb clustering", "start_pos": 64, "end_pos": 79, "type": "TASK", "confidence": 0.7274129241704941}]}, {"text": "An independent evaluation using one of the standard datasets available for SP acquisition research () is of course needed to determine how well the acquisition method performs in comparison with other existing methods.", "labels": [], "entities": [{"text": "SP acquisition", "start_pos": 75, "end_pos": 89, "type": "TASK", "confidence": 0.9816948473453522}]}, {"text": "Finally, we evaluated the quality of the verb clusters created using the SP-based features.", "labels": [], "entities": []}, {"text": "We found that some of the errors were similar to those seen on T2 when using syntactic features: errors due to polysemy and syntactic idiosyncracy.", "labels": [], "entities": []}, {"text": "However, anew error type clearly due to the SP-based feature was detected.", "labels": [], "entities": [{"text": "error type", "start_pos": 14, "end_pos": 24, "type": "METRIC", "confidence": 0.9126681387424469}]}, {"text": "A small number of classes got confused because of strong similar SPs in the subject (agent) position.", "labels": [], "entities": []}, {"text": "For example, some PEER (30.3) verbs (e.g. look, peer) were found in the same cluster with SAY (37.7) verbs (e.g. shout, yell) -an error which purely syntactic features do not produce.", "labels": [], "entities": [{"text": "PEER", "start_pos": 18, "end_pos": 22, "type": "METRIC", "confidence": 0.9493343830108643}]}, {"text": "Such errors were not numerous and could be addressed by developing more balanced SP models across different GRs.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Levin classes in T1 and T2", "labels": [], "entities": []}, {"text": " Table 2: (i) The total number of features and (ii)  the average per verb for all the feature sets", "labels": [], "entities": []}, {"text": " Table 3: Results on testsets T1 and T2", "labels": [], "entities": []}, {"text": " Table 5: Previous verb classification results", "labels": [], "entities": [{"text": "verb classification", "start_pos": 19, "end_pos": 38, "type": "TASK", "confidence": 0.7518412470817566}]}]}