{"title": [{"text": "Finding Short Definitions of Terms on Web Pages", "labels": [], "entities": [{"text": "Finding Short Definitions of Terms on Web Pages", "start_pos": 0, "end_pos": 47, "type": "TASK", "confidence": 0.6818652376532555}]}], "abstractContent": [{"text": "We present a system that finds short definitions of terms on Web pages.", "labels": [], "entities": []}, {"text": "It employs a Maximum Entropy classifier, but it is trained on automatically generated examples ; hence, it is in effect unsupervised.", "labels": [], "entities": []}, {"text": "We use ROUGE-W to generate training examples from encyclopedias and Web snippets , a method that outperforms an alternative centroid-based one.", "labels": [], "entities": [{"text": "ROUGE-W", "start_pos": 7, "end_pos": 14, "type": "METRIC", "confidence": 0.8457918167114258}]}, {"text": "After training, our system can be used to find definitions of terms that are not covered by encyclopedias.", "labels": [], "entities": []}, {"text": "The system outperforms a comparable publicly available system, as well as a previously published form of our system.", "labels": [], "entities": []}], "introductionContent": [{"text": "Definitions of terms are among the most common types of information users search for on the Web.", "labels": [], "entities": []}, {"text": "In the TREC 2001 QA track , where the distribution of question types reflected that of real user logs, 27% of the questions were requests for definitions (e.g., \"What is gasohol?\", \"Who was Duke Ellington?\").", "labels": [], "entities": [{"text": "TREC 2001 QA track", "start_pos": 7, "end_pos": 25, "type": "DATASET", "confidence": 0.9184190779924393}]}, {"text": "Consequently, some Web search engines provide special facilities (e.g., Google's \"define:\" query prefix) that seek definitions of user-specified terms in online encyclopedias or glossaries; to save space, we call both \"encyclopedias\".", "labels": [], "entities": []}, {"text": "There are, however, often terms that are too recent, too old, or less widely used to be included in encyclopedias.", "labels": [], "entities": []}, {"text": "Their definitions maybe present on other Web pages (e.g., newspaper articles), but they maybe provided indirectly (e.g., \"He said that gasohol, a mixture of gasoline and ethanol, has been great for his business.\") and they maybe difficult to locate with generic search engines that may return dozens of pages containing, but not defining the terms.", "labels": [], "entities": []}, {"text": "We present a system to find short definitions of user-specified terms on Web pages.", "labels": [], "entities": []}, {"text": "It can be used as an add-on to generic search engines, when no definitions can be found in on-line encyclopedias.", "labels": [], "entities": []}, {"text": "The system first invokes a search engine using the (possibly multi-word) term whose definition is sought, the target term, as the query.", "labels": [], "entities": []}, {"text": "It then scans the top pages returned by the search engine to locate 250-character snippets with the target term at their centers; we call these snippets windows.", "labels": [], "entities": []}, {"text": "The windows are candidate definitions of the target term, and they are then classified as acceptable (positive class) or unacceptable (negative class) using supervised machine learning.", "labels": [], "entities": []}, {"text": "The system reports the windows for which it is most confident that they belong in the positive class.", "labels": [], "entities": []}, {"text": "Table 1 shows examples of short definitions found by our system.", "labels": [], "entities": []}, {"text": "In our experiments, we allow the system to return up to five windows per target term, and the system's response is counted as correct if any of the returned windows contains an acceptable short definition of the target.", "labels": [], "entities": []}, {"text": "This is similar to the treatment of definition questions in TREC, but the answer is sought on the Web, not in a given document collection of a particular genre.", "labels": [], "entities": []}, {"text": "More recent TREC QA tracks required definition questions to be answered by lists of complementary text snippets, jointly providing required or optional information nuggets.", "labels": [], "entities": [{"text": "TREC QA", "start_pos": 12, "end_pos": 19, "type": "TASK", "confidence": 0.5974197685718536}]}, {"text": "In contrast, we focus on locating single snippets that include self-contained short definitions.", "labels": [], "entities": []}, {"text": "Despite its simpler nature, we believe the task we address is of practical use: a list of single-snippet definitions from Web pages accompanied by the source URLs is a good starting point for users seeking definitions of terms not covered by encyclopedias.", "labels": [], "entities": []}, {"text": "We also note that evaluating multi-snippet definitions can be problematic, because it is often difficult to agree which information nuggets should be treated as required, or even optional).", "labels": [], "entities": []}, {"text": "In contrast, earlier experimental results we have reported (Androutsopoulos and show strong inter-assessor agreement (K > 0.8) for single-snippet definitions).", "labels": [], "entities": [{"text": "inter-assessor agreement (K > 0.8", "start_pos": 92, "end_pos": 125, "type": "METRIC", "confidence": 0.6865756660699844}]}, {"text": "The task we address also differs from DUC's query focused summarization).", "labels": [], "entities": [{"text": "DUC", "start_pos": 38, "end_pos": 41, "type": "DATASET", "confidence": 0.8665838837623596}]}, {"text": "Our queries are single terms, whereas DUC queries are longer topic Target term: Babesiosis (...)", "labels": [], "entities": []}, {"text": "Babesiosis is a rare, severe and sometimes fatal tickborne disease caused by various types of Babesia, a microscopic parasite that infects red blood cells.", "labels": [], "entities": [{"text": "Babesiosis", "start_pos": 0, "end_pos": 10, "type": "TASK", "confidence": 0.9345610737800598}]}, {"text": "In New York state, the causative parasite is babesia microti.", "labels": [], "entities": []}, {"text": "Target term: anorexia nervosa (...) anorexia nervosa is an illness that usually occurs in teenage girls, but it can also occur in teenage boys, and adult women and men.", "labels": [], "entities": []}, {"text": "People with anorexia are obsessed with being thin.", "labels": [], "entities": []}, {"text": "They lose a lot of weight and are terrified of gaining weight.", "labels": [], "entities": []}, {"text": "Target term: Kinabalu (...) one hundred and thirty eight kilometers from Kota Kinabalu, the capital of the Malaysian state of Sabah, rises the majestic mount Kinabalu.", "labels": [], "entities": []}, {"text": "With its peak at 4,101 meters (and growing), mount Kinabalu is the highest mountain in south-east Asia.", "labels": [], "entities": []}, {"text": "Pythagoras of Samos about 569 BC -about 475 BC click the picture above to see eleven larger pictures Pythagoras was a Greek philosopher who made important developments in mathematics, astronomy, and the theory of music.", "labels": [], "entities": []}, {"text": "The theorem now known as (...)", "labels": [], "entities": []}, {"text": "Sacajawea was a Shoshone Indian princess.", "labels": [], "entities": []}, {"text": "The Shoshone lived from the rocky mountains to the plains.", "labels": [], "entities": []}, {"text": "They lived primarily on buffalo meat.", "labels": [], "entities": []}, {"text": "The shoshone traveled for many days searching for buffalo.", "labels": [], "entities": []}, {"text": "They hunted on horseback using the buffalo for food (...)", "labels": [], "entities": []}, {"text": "Target term: tale of Genji (...) the tale of Genji This site aims to promote a wider understanding and appreciation of the tale of Genji -the 11th century Japanese classic written by a Heian court lady known as Murasaki Shikibu.", "labels": [], "entities": [{"text": "Genji -the 11th century Japanese classic written by a Heian court lady", "start_pos": 131, "end_pos": 201, "type": "TASK", "confidence": 0.6058186980394217}]}, {"text": "It also serves as a kind of travel guide to the world (...)", "labels": [], "entities": []}, {"text": "Target term: Jacques Lacan (...) who is Jacques Lacan?", "labels": [], "entities": []}, {"text": "John Haber in New York city a primer for pre-post-structuralists Jacques Lacan is a Parisian psychoanalyst who has influenced literary criticism and feminism.", "labels": [], "entities": []}, {"text": "He began work in the 1950s, in the Freudian society there.", "labels": [], "entities": []}, {"text": "It was a (...): Definitions found by our system.", "labels": [], "entities": []}, {"text": "descriptions, often entire paragraphs; furthermore, we do not attempt to compose coherent and cohesive summaries from several snippets.", "labels": [], "entities": []}, {"text": "The system we present is based on our earlier work (, where an SVM classifier) was used to separate acceptable windows from unacceptable ones; the SVM also returned confidence scores, which were used to rank the acceptable windows.", "labels": [], "entities": []}, {"text": "On datasets from the TREC 2000 and 2001 QA tracks, our earlier system clearly outperformed the methods of and, as reported in previous work ().", "labels": [], "entities": [{"text": "TREC 2000 and 2001 QA tracks", "start_pos": 21, "end_pos": 49, "type": "DATASET", "confidence": 0.930331697066625}]}, {"text": "To train the SVM, however, thousands of training windows were required, each tagged as a positive or negative example.", "labels": [], "entities": []}, {"text": "Obtaining large numbers of training windows is easy, but manually tagging them is very timeconsuming.", "labels": [], "entities": []}, {"text": "In the TREC 2000 and 2001 datasets, it was possible to tag the training windows automatically by using training target terms and accompanying regular expression patterns provided by the TREC organizers.", "labels": [], "entities": [{"text": "TREC 2000 and 2001 datasets", "start_pos": 7, "end_pos": 34, "type": "DATASET", "confidence": 0.8908209204673767}]}, {"text": "The regular expressions covered all the known acceptable definitions of the corresponding terms that can be extracted from the datasets.", "labels": [], "entities": []}, {"text": "When the training windows, however, are obtained from the Web, it is impossible to construct manually regular expressions for all the possible phrasings of the acceptable definitions in the training windows.", "labels": [], "entities": []}, {"text": "In subsequent work (Androutsopoulos and), we developed ATTW (automatic tagging of training windows), a technique that produces arbitrarily large collections of training windows from the Web with practically no manual effort, in effect making our overall system unsupervised.", "labels": [], "entities": [{"text": "ATTW", "start_pos": 55, "end_pos": 59, "type": "METRIC", "confidence": 0.9724330306053162}, {"text": "automatic tagging of training windows)", "start_pos": 61, "end_pos": 99, "type": "TASK", "confidence": 0.6749961574872335}]}, {"text": "ATTW uses training terms for which several encyclopedia definitions are available, and compares each Web training window (each window extracted from the pages the search engine returned fora training term) to the corresponding encyclopedia definitions.", "labels": [], "entities": [{"text": "ATTW", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.9084809422492981}]}, {"text": "Web training windows that are very similar (or dissimilar) to the corresponding encyclopedia definitions are tagged as positive (or negative) examples; if the similarity is neither too high nor too low, the window is not included in the classifier's training data.", "labels": [], "entities": []}, {"text": "Previously reported experiments showed that ATTW leads to significantly better results, compared to training the classifier on all the available TREC windows, for which regular expressions are available, and then using it to classify Web windows.", "labels": [], "entities": [{"text": "ATTW", "start_pos": 44, "end_pos": 48, "type": "METRIC", "confidence": 0.6365416646003723}]}, {"text": "Note that in ATTW the encyclopedia definitions are used only during training.", "labels": [], "entities": [{"text": "ATTW", "start_pos": 13, "end_pos": 17, "type": "DATASET", "confidence": 0.864078938961029}]}, {"text": "Once the classifier has been trained, it can be used to discover definitions on arbitrary Web pages.", "labels": [], "entities": []}, {"text": "In fact, during testing we discard windows originating from on-line encyclopedias, simulating the case where we seek definitions of terms not covered by encyclopedias; we also ignore windows from on-line encyclopedias during training.", "labels": [], "entities": []}, {"text": "Also, note that the classifier is trained on Web windows, not directly on encyclopedia definitions, which allows it to avoid relying excessively on phrasings that are common in encyclopedia definitions, but uncommon in more indirect definitions of arbitrary Web pages.", "labels": [], "entities": []}, {"text": "Fur-thermore, training the classifier directly on encyclopedia definitions would not provide negative examples.", "labels": [], "entities": [{"text": "Fur-thermore", "start_pos": 0, "end_pos": 12, "type": "METRIC", "confidence": 0.7904567718505859}]}, {"text": "In our previous work with ATTW (Androutsopoulos and) we used a measure constructed by ourselves to assess the similarity between Web windows and encyclopedia definitions.", "labels": [], "entities": [{"text": "ATTW", "start_pos": 26, "end_pos": 30, "type": "DATASET", "confidence": 0.9010840654373169}]}, {"text": "Here, we use the more established ROUGE-W measure) instead.", "labels": [], "entities": [{"text": "ROUGE-W measure", "start_pos": 34, "end_pos": 49, "type": "METRIC", "confidence": 0.9792848527431488}]}, {"text": "ROUGE-W and other versions of ROUGE have been used in summarization to measure how close a machineauthored summary is to multiple human summaries of the same input.", "labels": [], "entities": [{"text": "summarization", "start_pos": 54, "end_pos": 67, "type": "TASK", "confidence": 0.9911510348320007}]}, {"text": "We use ROUGE-W in a similar setting, to measure how close a training window is to multiple encyclopedia definitions of the same term.", "labels": [], "entities": [{"text": "ROUGE-W", "start_pos": 7, "end_pos": 14, "type": "METRIC", "confidence": 0.9819939732551575}]}, {"text": "A further difference from our previous work is that we also use ROUGE-W when computing the features of the windows to be classified.", "labels": [], "entities": [{"text": "ROUGE-W", "start_pos": 64, "end_pos": 71, "type": "METRIC", "confidence": 0.988501787185669}]}, {"text": "Previously, the SVM relied, among others, on Boolean features indicating if the target term was preceded or followed in the window to be classified by a particular phrase indicating a definition (e.g., \"target, a kind of\", \"such as target\").", "labels": [], "entities": []}, {"text": "The indicative phrases are selected automatically during training, but now the corresponding features are not Boolean; their values are the ROUGE-W similarity scores between an indicative phrase and the context of the target term in the window.", "labels": [], "entities": [{"text": "ROUGE-W similarity scores", "start_pos": 140, "end_pos": 165, "type": "METRIC", "confidence": 0.9645512700080872}]}, {"text": "This allows the system to soft-match the phrases to the windows (e.g., encountering \"target, another kind of\", instead of \"target, a kind of\").", "labels": [], "entities": []}, {"text": "In our new system we also use a Maximum Entropy (MAXENT) classifier) instead of an SVM, because much faster implementations of the former are available.", "labels": [], "entities": []}, {"text": "We present experimental results showing that our new system significantly outperforms our previously published one.", "labels": [], "entities": []}, {"text": "The use of the MAXENT classifier by itself improved slightly our results, but the improvements come mostly from using ROUGE-W.", "labels": [], "entities": [{"text": "ROUGE-W", "start_pos": 118, "end_pos": 125, "type": "METRIC", "confidence": 0.9859102964401245}]}, {"text": "Apart from presenting an improved version of our system, the main contribution of this paper is a detailed experimental comparison of our new system against.", "labels": [], "entities": []}, {"text": "The latter is particularly interesting, because it is well published, it includes both an alternative, centroid-based technique to automatically tag training examples and a soft-matching classifier, and it is publicly available.", "labels": [], "entities": []}, {"text": "We show that ATTW outperforms Cui et al.'s centroid-based technique, and that our overall system is also clearly better than Cui et al.'s in the task we address.", "labels": [], "entities": []}, {"text": "Section 2 discusses ATTW with ROUGE-W, Cui et al.'s centroid-based method to tag training examples, and experiments showing that ATTW is better.", "labels": [], "entities": [{"text": "ROUGE-W", "start_pos": 30, "end_pos": 37, "type": "METRIC", "confidence": 0.9893787503242493}]}, {"text": "Section 3 describes our new overall system, the system of Cui et al., and the baselines.", "labels": [], "entities": []}, {"text": "Section 4 reports experimental results showing that our system is better than Cui et al.'s, and better than our previously published system.", "labels": [], "entities": []}, {"text": "Section 5 discusses related work; and section 6 concludes.", "labels": [], "entities": []}], "datasetContent": [{"text": "We used q training target terms in the experiments of this section, with q ranging from 50 to 1500, and 200 testing terms, with no overlap between training and testing terms, and excluding terms that had been used for other purpose.", "labels": [], "entities": []}, {"text": "We had to use testing terms for which encyclopedia definitions were also available, to judge the acceptability of the systems' responses, since many terms are highly technical.", "labels": [], "entities": []}, {"text": "We discarded, however, windows extracted from encyclopedia pages when testing, simulating the case where the target terms are not covered by encyclopedias.", "labels": [], "entities": []}, {"text": "As already mentioned, for each target term we extract r \u00b7 f = 10 \u00b7 5 windows (or fewer, if fewer are available) from the pages the search engine returns.", "labels": [], "entities": []}, {"text": "We then provide these windows to each of the systems, allowing them to return up to k = 5 windows, ordered by decreasing confidence.", "labels": [], "entities": []}, {"text": "If any of the k windows contains an acceptable short definition of the target term, as judged by a human evaluator, the system's response is counted as correct.", "labels": [], "entities": []}, {"text": "We also calculate the Mean Reciprocal Rank (MRR) of each system's responses, as in the TREC QA track: if the first acceptable definition of a response is in the j-th position (1 \u2264 j \u2264 k), the response's score is 1/j; MRR is the mean of the responses' scores, i.e., it rewards systems that return acceptable definitions higher in their responses.", "labels": [], "entities": [{"text": "Mean Reciprocal Rank (MRR)", "start_pos": 22, "end_pos": 48, "type": "METRIC", "confidence": 0.9678173263867696}, {"text": "TREC QA track", "start_pos": 87, "end_pos": 100, "type": "DATASET", "confidence": 0.8880144556363424}, {"text": "MRR", "start_pos": 217, "end_pos": 220, "type": "METRIC", "confidence": 0.9961450099945068}]}, {"text": "show the results of our experiments as percentage of correct responses and MRR, respectively; the error bars of correspond to 95% confidence intervals.", "labels": [], "entities": [{"text": "MRR", "start_pos": 75, "end_pos": 78, "type": "METRIC", "confidence": 0.9979246854782104}]}, {"text": "Our system clearly outperforms Cui et al.'s, despite the fact that the latter uses more linguistic resources (a POS tagger and a chunker).", "labels": [], "entities": []}, {"text": "Both systems outperform the baselines, of which the centroid baseline is the best, and both systems perform better as the size of the training set increases.", "labels": [], "entities": []}, {"text": "The baselines contain no learning components; hence, their curves are flat.", "labels": [], "entities": []}, {"text": "We also show the results (Base-Attrs) of our system when the features that correspond to automatically acquired patterns are excluded.", "labels": [], "entities": []}, {"text": "Clearly, these patterns help our system achieve significantly better results; however, our system outperforms Cui et al.'s even without them.", "labels": [], "entities": []}, {"text": "Without the automatic patterns, our system also shows signs of saturation as the training data increase.", "labels": [], "entities": []}, {"text": "show the performance of our new system against our previously published one (Androutsopoulos and); the new system clearly outperforms the old one.", "labels": [], "entities": []}, {"text": "Additional experiments we conducted with the old system replacing the SVM by the MAXENT classifier (without using indicate that the use of MAXENT by itself also improved slightly the results, but the differences are too minor to show; the improvement is mostly due to the use of ROUGE-W instead of our previous measure.", "labels": [], "entities": [{"text": "ROUGE-W", "start_pos": 279, "end_pos": 286, "type": "METRIC", "confidence": 0.9965337514877319}]}, {"text": "use an information extraction engine to extract linguistic features from documents relevant to the target term.", "labels": [], "entities": [{"text": "information extraction", "start_pos": 7, "end_pos": 29, "type": "TASK", "confidence": 0.7123431712388992}]}, {"text": "The features are mostly phrases, such as appositives, and phrases expressing relations.", "labels": [], "entities": []}, {"text": "The features are then ranked by their type and similarity to a centroid, and the most highly ranked ones are returned.", "labels": [], "entities": []}, {"text": "Xu et al. seem to aim at generating multi-snippet definitions, unlike the single-snippet definitions we seek.", "labels": [], "entities": []}], "tableCaptions": []}