{"title": [{"text": "Lattice-based System Combination for Statistical Machine Translation", "labels": [], "entities": [{"text": "Statistical Machine Translation", "start_pos": 37, "end_pos": 68, "type": "TASK", "confidence": 0.851705272992452}]}], "abstractContent": [{"text": "Current system combination methods usually use confusion networks to find consensus translations among different systems.", "labels": [], "entities": []}, {"text": "Requiring one-to-one mappings between the words in candidate translations, confusion networks have difficulty in handling more general situations in which several words are connected to another several words.", "labels": [], "entities": []}, {"text": "Instead, we propose a lattice-based system combination model that allows for such phrase alignments and uses lattices to encode all candidate translations.", "labels": [], "entities": [{"text": "phrase alignments", "start_pos": 82, "end_pos": 99, "type": "TASK", "confidence": 0.7332873940467834}]}, {"text": "Experiments show that our approach achieves significant improvements over the state-of-the-art baseline system on Chinese-to-English translation test sets.", "labels": [], "entities": []}], "introductionContent": [{"text": "System combination aims to find consensus translations among different machine translation systems.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 71, "end_pos": 90, "type": "TASK", "confidence": 0.7255019545555115}]}, {"text": "It has been proven that such consensus translations are usually better than the output of individual systems (.", "labels": [], "entities": []}, {"text": "In recent several years, the system combination methods based on confusion networks developed rapidly (, which show state-of-the-art performance in benchmarks.", "labels": [], "entities": []}, {"text": "A confusion network consists of a sequence of sets of candidate words.", "labels": [], "entities": []}, {"text": "Each candidate word is associated with a score.", "labels": [], "entities": []}, {"text": "The optimal consensus translation can be obtained by selecting one word from each set to maximizing the overall score.", "labels": [], "entities": [{"text": "consensus translation", "start_pos": 12, "end_pos": 33, "type": "TASK", "confidence": 0.8240362405776978}]}, {"text": "To construct a confusion network, one first need to choose one of the hypotheses (i.e., candidate translations) as the backbone (also called \"skeleton\" in the literature) and then decide the word alignments of other hypotheses to the backbone.", "labels": [], "entities": []}, {"text": "Hypothesis alignment plays a crucial role in confusionnetwork-based system combination because it has a direct effect on selecting consensus translations.", "labels": [], "entities": [{"text": "Hypothesis alignment", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.7217085361480713}, {"text": "confusionnetwork-based system combination", "start_pos": 45, "end_pos": 86, "type": "TASK", "confidence": 0.6300653517246246}]}, {"text": "However, a confusion network is restricted in such away that only 1-to-1 mappings are allowed in hypothesis alignment.", "labels": [], "entities": [{"text": "hypothesis alignment", "start_pos": 97, "end_pos": 117, "type": "TASK", "confidence": 0.7989031374454498}]}, {"text": "This is not the fact even for word alignments between the same languages.", "labels": [], "entities": [{"text": "word alignments", "start_pos": 30, "end_pos": 45, "type": "TASK", "confidence": 0.6878880858421326}]}, {"text": "It is more common that several words are connected to another several words.", "labels": [], "entities": []}, {"text": "For example, \"be capable of\" and \"be able to\" have the same meaning.", "labels": [], "entities": []}, {"text": "Although confusion-network-based approaches resort to inserting null words to alleviate this problem, they face the risk of producing degenerate translations such as \"be capable to\" and \"be able of\".", "labels": [], "entities": []}, {"text": "In this paper, we propose anew system combination method based on lattices.", "labels": [], "entities": []}, {"text": "As a more general form of confusion network, a lattice is capable of describing arbitrary mappings in hypothesis alignment.", "labels": [], "entities": [{"text": "hypothesis alignment", "start_pos": 102, "end_pos": 122, "type": "TASK", "confidence": 0.7164226025342941}]}, {"text": "Ina lattice, each edge is associated with a sequence of words rather than a single word.", "labels": [], "entities": []}, {"text": "Therefore, we select phrases instead of words in each candidate set and minimize the chance to produce unexpected translations such as \"be capable to\".", "labels": [], "entities": []}, {"text": "We compared our approach with the state-of-the-art confusion-network-based system ( and achieved a significant absolute improvement of 1.", "labels": [], "entities": []}], "datasetContent": [{"text": "The candidate systems participating in the system combination are as listed in: System A is a BTG-based system using a MaxEnt-based reordering model; System B is a hierarchical phrase-based system; System C is the Moses decoder (; System Dis a syntax-based system.", "labels": [], "entities": []}, {"text": "10-best hypotheses from each candidate system on the dev and test sets were collected as the input of the system combination.", "labels": [], "entities": []}, {"text": "In our experiments, the weights were all tuned on the NIST MT02 Chinese-to-English test set, including 878 sentences, and the test data was the NIST MT05 Chinese-to-English test set, including 1082 sentences, except the experiments in.", "labels": [], "entities": [{"text": "NIST MT02 Chinese-to-English test set", "start_pos": 54, "end_pos": 91, "type": "DATASET", "confidence": 0.8643632531166077}, {"text": "NIST MT05 Chinese-to-English test set", "start_pos": 144, "end_pos": 181, "type": "DATASET", "confidence": 0.8851270794868469}]}, {"text": "A 5-gram language model was used which was trained on the XinHua portion of Gigaword corpus.", "labels": [], "entities": [{"text": "Gigaword corpus", "start_pos": 76, "end_pos": 91, "type": "DATASET", "confidence": 0.7901616394519806}]}, {"text": "The results were all reported in case sensitive BLEU score and the weights were tuned in Powell's method to maximum BLEU score.", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 48, "end_pos": 58, "type": "METRIC", "confidence": 0.9719745814800262}, {"text": "BLEU score", "start_pos": 116, "end_pos": 126, "type": "METRIC", "confidence": 0.9838423430919647}]}, {"text": "The IHMM-based alignment module was implemented according to, and.", "labels": [], "entities": [{"text": "IHMM-based alignment", "start_pos": 4, "end_pos": 24, "type": "TASK", "confidence": 0.7280486524105072}]}, {"text": "In all experiments, the parameters for IHMM-based alignment module were set to: the smoothing factor for the surface similarity model, \u03c1 = 3; the controlling factor for the distortion model, K = 2.", "labels": [], "entities": [{"text": "IHMM-based alignment", "start_pos": 39, "end_pos": 59, "type": "TASK", "confidence": 0.6808210462331772}]}], "tableCaptions": [{"text": " Table 1: Results on the MT02 and MT05 test sets", "labels": [], "entities": [{"text": "MT02", "start_pos": 25, "end_pos": 29, "type": "DATASET", "confidence": 0.7626354098320007}, {"text": "MT05 test", "start_pos": 34, "end_pos": 43, "type": "DATASET", "confidence": 0.877717912197113}]}, {"text": " Table 2: Results on the MT06 and MT08 test sets", "labels": [], "entities": [{"text": "MT06", "start_pos": 25, "end_pos": 29, "type": "DATASET", "confidence": 0.8326423168182373}, {"text": "MT08 test", "start_pos": 34, "end_pos": 43, "type": "DATASET", "confidence": 0.8871326148509979}]}, {"text": " Table 4: Effect of dictionary scale", "labels": [], "entities": [{"text": "dictionary scale", "start_pos": 20, "end_pos": 36, "type": "METRIC", "confidence": 0.8236240446567535}]}, {"text": " Table 5: Effect of semantic alignments", "labels": [], "entities": [{"text": "semantic alignments", "start_pos": 20, "end_pos": 39, "type": "TASK", "confidence": 0.696247473359108}]}]}