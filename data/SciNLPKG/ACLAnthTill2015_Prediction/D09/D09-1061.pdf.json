{"title": [{"text": "Topic-wise, Sentiment-wise, or Otherwise? Identifying the Hidden Dimension for Unsupervised Text Classification", "labels": [], "entities": []}], "abstractContent": [{"text": "While traditional work on text clustering has largely focused on grouping documents by topic, it is conceivable that a user may want to cluster documents along other dimensions, such as the author's mood, gender, age, or sentiment.", "labels": [], "entities": [{"text": "text clustering", "start_pos": 26, "end_pos": 41, "type": "TASK", "confidence": 0.718572586774826}]}, {"text": "Without knowing the user's intention, a clustering algorithm will only group documents along the most prominent dimension, which may not be the one the user desires.", "labels": [], "entities": []}, {"text": "To address this problem, we propose a novel way of incorporating user feedback into a clustering algorithm, which allows a user to easily specify the dimension along which she wants the data points to be clustered via inspecting only a small number of words.", "labels": [], "entities": []}, {"text": "This distinguishes our method from existing ones, which typically require a large amount of effort on the part of humans in the form of document annotation or interactive construction of the feature space.", "labels": [], "entities": []}, {"text": "We demonstrate the viability of our method on several challenging sentiment datasets.", "labels": [], "entities": []}], "introductionContent": [{"text": "Text clustering is one of the most important applications in Natural Language Processing (NLP).", "labels": [], "entities": [{"text": "Text clustering", "start_pos": 0, "end_pos": 15, "type": "TASK", "confidence": 0.7723846733570099}, {"text": "Natural Language Processing (NLP)", "start_pos": 61, "end_pos": 94, "type": "TASK", "confidence": 0.6881282925605774}]}, {"text": "A common approach to this problem consists of (1) computing the similarity between each pair of documents, each of which is typically represented as a bag of words; and (2) using an unsupervised clustering algorithm to partition the documents.", "labels": [], "entities": []}, {"text": "The majority of existing work on text clustering has focused on topic-based clustering, where high accuracies can be achieved even for datasets with a large number of classes (e.g., 20 Newsgroups).", "labels": [], "entities": [{"text": "text clustering", "start_pos": 33, "end_pos": 48, "type": "TASK", "confidence": 0.7606115341186523}, {"text": "topic-based clustering", "start_pos": 64, "end_pos": 86, "type": "TASK", "confidence": 0.6382049769163132}]}, {"text": "On the other hand, there has been relatively little work on sentiment-based clustering and the related task of unsupervised polarity classification, where the goal is to cluster (or classify) a set of documents (e.g., reviews) according to the polarity (e.g., \"thumbs up\" or \"thumbs down\") expressed by the author in an unsupervised manner.", "labels": [], "entities": [{"text": "sentiment-based clustering", "start_pos": 60, "end_pos": 86, "type": "TASK", "confidence": 0.7573221921920776}, {"text": "unsupervised polarity classification", "start_pos": 111, "end_pos": 147, "type": "TASK", "confidence": 0.7033648590246836}]}, {"text": "Despite the large amount of recent work on sentiment analysis and opinion mining, much of it has focused on supervised methods (e.g.,,,).", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 43, "end_pos": 61, "type": "TASK", "confidence": 0.9773250818252563}, {"text": "opinion mining", "start_pos": 66, "end_pos": 80, "type": "TASK", "confidence": 0.8489418029785156}]}, {"text": "One weakness of these existing supervised polarity classification systems is that they are typically domain-and language-specific.", "labels": [], "entities": [{"text": "supervised polarity classification", "start_pos": 31, "end_pos": 65, "type": "TASK", "confidence": 0.7080800930658976}]}, {"text": "Hence, when given anew domain or language, one needs to go through the expensive process of collecting a large amount of annotated data in order to train a high-performance polarity classifier.", "labels": [], "entities": []}, {"text": "Some recent attempts have been made to leverage existing sentiment corpora or lexica to automatically create annotated resources for new domains or languages.", "labels": [], "entities": []}, {"text": "However, such methods require the existence of either a parallel corpus/machine translation engine for projecting/translating annotations/lexica from a resource-rich language to the target language (, or a domain that is \"similar\" enough to the target domain (.", "labels": [], "entities": [{"text": "projecting/translating annotations/lexica from a resource-rich language", "start_pos": 103, "end_pos": 174, "type": "TASK", "confidence": 0.7745384216308594}]}, {"text": "When the target domain or language fails to meet this requirement, sentiment-based clustering or unsupervised polarity classification become appealing alternatives.", "labels": [], "entities": []}, {"text": "Unfortunately, to our knowledge, these tasks are largely under-investigated in the NLP community.", "labels": [], "entities": []}, {"text": "work is perhaps one of the most notable examples of unsupervised polarity classification.", "labels": [], "entities": [{"text": "unsupervised polarity classification", "start_pos": 52, "end_pos": 88, "type": "TASK", "confidence": 0.6760526597499847}]}, {"text": "However, while his system learns the semantic orientation of the phrases in a review in an unsupervised manner, this information is used to predict the polarity of a review heuristically.", "labels": [], "entities": []}, {"text": "Despite its practical significance, sentimentbased clustering is a challenging task.", "labels": [], "entities": [{"text": "sentimentbased clustering", "start_pos": 36, "end_pos": 61, "type": "TASK", "confidence": 0.7777787744998932}]}, {"text": "To illustrate its difficulty, consider the task of clustering a set of movie reviews.", "labels": [], "entities": [{"text": "clustering a set of movie reviews", "start_pos": 51, "end_pos": 84, "type": "TASK", "confidence": 0.771031657854716}]}, {"text": "Since each review may contain a description of the plot and the author's sentiment, a clustering algorithm may cluster reviews along either the plot dimension or the sentiment dimension; and without knowing the user's intention, they will be clustered along the most prominent dimension.", "labels": [], "entities": []}, {"text": "Assuming the usual bagof-words representation, the most prominent dimension will more likely be plot, as it is not uncommon fora review to be devoted almost exclusively to the plot, with the author briefly expressing her sentiment only at the end of the review.", "labels": [], "entities": [{"text": "plot", "start_pos": 96, "end_pos": 100, "type": "METRIC", "confidence": 0.9571560025215149}]}, {"text": "Even if the reviews contain mostly subjective material, the most prominent dimension may still not be sentiment, due to the fact that many reviews are sentimentally ambiguous.", "labels": [], "entities": []}, {"text": "Specifically, a reviewer may have negative opinions on the actors but at the same time talk enthusiastically about how much she enjoyed the plot.", "labels": [], "entities": []}, {"text": "The presence of both positive and negative sentiment-bearing words in these reviews renders the sentiment dimension hidden (i.e., less prominent) as far as clustering is concerned.", "labels": [], "entities": []}, {"text": "Therefore, there is no guarantee that the clustering algorithm will automatically produce a sentiment-based clustering of the reviews.", "labels": [], "entities": []}, {"text": "Hence, it is important fora user to provide feedback on the clustering process to ensure that the reviews are clustered along the sentiment dimension, possibly in an interactive manner.", "labels": [], "entities": []}, {"text": "One way to do this would be to ask the user to annotate a small number of reviews with polarity information, possibly through an active learning procedure to minimize human intervention.", "labels": [], "entities": []}, {"text": "Another way would be to have the user explicitly identify the relevant features (in our case, the sentiment-bearing words) at the beginning of the clustering process (), or incrementally construct the set of relevant features in an interactive fashion.", "labels": [], "entities": []}, {"text": "In addition, the user may supply constraints on which pairs of documents must or must not appear in the same cluster (), or simply tell the algorithm whether two clusters should be merged or split during the clustering process (.", "labels": [], "entities": []}, {"text": "It is worth noting that many of these feedback mechanisms were developed by machine learning researchers for general clustering tasks and not for sentiment-based clustering.", "labels": [], "entities": [{"text": "sentiment-based clustering", "start_pos": 146, "end_pos": 172, "type": "TASK", "confidence": 0.7052832245826721}]}, {"text": "Our goal in this paper is to propose a novel mechanism allowing a user to cluster a set of documents along the desired dimension, which maybe a hidden dimension, with very limited user feedback.", "labels": [], "entities": []}, {"text": "In comparison to the aforementioned feedback mechanisms, ours is arguably much simpler: we only require that the user select a dimension by examining a small number of features for each dimension, as opposed to having the user generate the feature space in an interactive manner or identify clusters that need to be merged or split.", "labels": [], "entities": []}, {"text": "In particular, identifying clusters for merging or splitting in Balcan and Blum's algorithm may not be as easy as it appears: for each MERGE or SPLIT decision the user makes, she has to sample a large number of documents from the cluster(s), read through the documents, and base her decision on the extent to which the documents are (dis)similar to each other.", "labels": [], "entities": []}, {"text": "Perhaps more importantly, our human experiments involving five users indicate that all of them can easily identify the sentiment dimension based on the features, thus providing suggestive evidence that our method is viable.", "labels": [], "entities": []}, {"text": "In sum, our contributions in this paper are threefold.", "labels": [], "entities": []}, {"text": "First, we propose a novel feedback mechanism for clustering allowing a user to easily specify the dimension along which she wants data points to be clustered and apply the mechanism to the challenging, yet under-investigated problem of sentiment-based clustering.", "labels": [], "entities": [{"text": "sentiment-based clustering", "start_pos": 236, "end_pos": 262, "type": "TASK", "confidence": 0.7254533469676971}]}, {"text": "Second, spectral learning, which is the core of our method, has not been applied extensively to NLP problems, and we hope that our work can increase the awareness of this powerful machine learning technique in the NLP community.", "labels": [], "entities": [{"text": "spectral learning", "start_pos": 8, "end_pos": 25, "type": "TASK", "confidence": 0.8204255700111389}]}, {"text": "Finally, we demonstrate the viability of our method not only by evaluating its performance on sentiment datasets, but also via a set of human experiments, which is typically absent in papers that involve algorithms for incorporating user feedback.", "labels": [], "entities": []}, {"text": "The rest of the paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 presents the basics of spectral clustering, which will facilitate the discussion of our feedback mechanism in Section 3.", "labels": [], "entities": [{"text": "spectral clustering", "start_pos": 33, "end_pos": 52, "type": "TASK", "confidence": 0.736430287361145}]}, {"text": "We describe our human experiments and evaluation results on several sentiment datasets in Section 4, and present our conclusions in Section 5.", "labels": [], "entities": []}], "datasetContent": [{"text": "We use five sentiment classification datasets, including the widely-used movie review dataset () as well as four datasets containing reviews of four different types of products from Amazon [books (BOO), DVDs (DVD), electronics (ELE), and kitchen appliances (KIT)] (.", "labels": [], "entities": [{"text": "sentiment classification", "start_pos": 12, "end_pos": 36, "type": "TASK", "confidence": 0.9170539081096649}, {"text": "movie review dataset", "start_pos": 73, "end_pos": 93, "type": "DATASET", "confidence": 0.5879490176836649}, {"text": "BOO", "start_pos": 197, "end_pos": 200, "type": "METRIC", "confidence": 0.9061025977134705}]}, {"text": "Each dataset has 2000 labeled reviews (1000 positives and 1000 negatives).", "labels": [], "entities": []}, {"text": "To illustrate the difference between topic-based clustering and sentiment-based clustering, we will also show topic-based clustering results on POL, a dataset created by taking all the documents from two sections of 20 Newsgroups, namely, sci.crypt and talks.politics.", "labels": [], "entities": [{"text": "sentiment-based clustering", "start_pos": 64, "end_pos": 90, "type": "TASK", "confidence": 0.6790914237499237}]}, {"text": "To preprocess a document, we first tokenize and downcase it, and then represent it as a vector of unigrams, using frequency as presence.", "labels": [], "entities": []}, {"text": "In addition, we remove from the vector punctuation, numbers, words of length one, and words that occur in only a single review.", "labels": [], "entities": []}, {"text": "Following the common practice in the information retrieval community, we also exclude words with high document frequency, many of which are stopwords or domainspecific general-purpose words (e.g., \"movies\" in the movie domain).", "labels": [], "entities": []}, {"text": "A preliminary examination of our evaluation datasets reveals that these words typically comprise 1-2% of a vocabulary.", "labels": [], "entities": []}, {"text": "The decision of exactly how many terms to remove from each dataset is subjective: a large corpus typically requires more removals than a small corpus.", "labels": [], "entities": []}, {"text": "To be consistent, we simply sort the vocabulary by document frequency and remove the top 1.5%.", "labels": [], "entities": []}, {"text": "We employ two evaluation metrics.", "labels": [], "entities": []}, {"text": "First, we report results in terms of the accuracy achieved on the 2000 labeled reviews for each dataset.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 41, "end_pos": 49, "type": "METRIC", "confidence": 0.9993046522140503}]}, {"text": "Second, following, we evaluate the clusters produced by our approach against the gold-standard clusters using the Adjusted Rand Index (ARI).", "labels": [], "entities": [{"text": "Adjusted Rand Index (ARI)", "start_pos": 114, "end_pos": 139, "type": "METRIC", "confidence": 0.894328753153483}]}, {"text": "ARI ranges from -1 to 1; better clusterings have higher ARI values.", "labels": [], "entities": [{"text": "ARI", "start_pos": 0, "end_pos": 3, "type": "METRIC", "confidence": 0.879714846611023}, {"text": "ARI", "start_pos": 56, "end_pos": 59, "type": "METRIC", "confidence": 0.9770472049713135}]}], "tableCaptions": [{"text": " Table 1: Results in terms of accuracy and Adjusted Rand Index for the six datasets.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 30, "end_pos": 38, "type": "METRIC", "confidence": 0.9996089339256287}, {"text": "Adjusted Rand Index", "start_pos": 43, "end_pos": 62, "type": "METRIC", "confidence": 0.858614186445872}]}, {"text": " Table 1. In  comparison to the first baseline, we see improve- ments in accuracy and ARI for the three datasets  on which the first baseline performs poorly (i.e.,  BOO, DVD, and ELE), with the most drastic  improvement observed on ELE. On the other  hand, performance on the remaining two senti-ment datasets deteriorates. These results can be  attributed to the fact that for BOO, DVD, and  ELE, e 2 does not capture the sentiment dimension,  but since some other eigenvector in the ensemble  does, we see improvements. On the other hand, e 2  has already captured the sentiment dimension in  MOV and KIT; as a result, employing additional  dimensions, which may not be sentiment-related,  may only introduce noise into the computation of  the similarities between the reviews.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 73, "end_pos": 81, "type": "METRIC", "confidence": 0.9994714856147766}, {"text": "ARI", "start_pos": 86, "end_pos": 89, "type": "METRIC", "confidence": 0.9995866417884827}, {"text": "BOO", "start_pos": 166, "end_pos": 169, "type": "METRIC", "confidence": 0.9472910761833191}, {"text": "MOV", "start_pos": 596, "end_pos": 599, "type": "DATASET", "confidence": 0.7831162214279175}]}, {"text": " Table 2: Human agreement rate.", "labels": [], "entities": [{"text": "agreement rate", "start_pos": 16, "end_pos": 30, "type": "METRIC", "confidence": 0.8213136494159698}]}, {"text": " Table 3: Accuracies on unambiguous documents.", "labels": [], "entities": [{"text": "Accuracies", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.9915565252304077}]}, {"text": " Table 1. In fact, an accuracy of more than  85% was achieved on all but one dataset. This sug- gests that our method of identifying unambiguous  documents is useful.  Note that it is crucial to be able to achieve a high  accuracy on the unambiguous documents: if clus- tering accuracy is low, the features induced from", "labels": [], "entities": [{"text": "accuracy", "start_pos": 22, "end_pos": 30, "type": "METRIC", "confidence": 0.999329686164856}, {"text": "accuracy", "start_pos": 222, "end_pos": 230, "type": "METRIC", "confidence": 0.9809938669204712}, {"text": "clus- tering accuracy", "start_pos": 264, "end_pos": 285, "type": "METRIC", "confidence": 0.7534790337085724}]}, {"text": " Table 6: Top ten features induced for each dimension for the KIT and DVD domains. The shaded columns", "labels": [], "entities": [{"text": "KIT and DVD domains", "start_pos": 62, "end_pos": 81, "type": "DATASET", "confidence": 0.8045774847269058}]}, {"text": " Table 7: Transductive SVM results.", "labels": [], "entities": [{"text": "Transductive SVM", "start_pos": 10, "end_pos": 26, "type": "TASK", "confidence": 0.7191432118415833}]}]}