{"title": [{"text": "Cross-lingual Semantic Relatedness Using Encyclopedic Knowledge", "labels": [], "entities": [{"text": "Cross-lingual Semantic Relatedness", "start_pos": 0, "end_pos": 34, "type": "TASK", "confidence": 0.6759123702843984}]}], "abstractContent": [{"text": "In this paper, we address the task of cross-lingual semantic relatedness.", "labels": [], "entities": [{"text": "cross-lingual semantic relatedness", "start_pos": 38, "end_pos": 72, "type": "TASK", "confidence": 0.7565953532854716}]}, {"text": "We introduce a method that relies on the information extracted from Wikipedia, by exploiting the interlanguage links available between Wikipedia versions in multiple languages.", "labels": [], "entities": []}, {"text": "Through experiments performed on several language pairs, we show that the method performs well, with a performance comparable to monolingual measures of relatedness.", "labels": [], "entities": []}, {"text": "1 Motivation Given the accelerated growth of the number of multilingual documents on the Web and elsewhere , the need for effective multilingual and cross-lingual text processing techniques is becoming increasingly important.", "labels": [], "entities": []}, {"text": "In this paper, we address the task of cross-lingual semantic relat-edness, and introduce a method that relies on Wikipedia in order to calculate the relatedness of words across languages.", "labels": [], "entities": [{"text": "cross-lingual semantic relat-edness", "start_pos": 38, "end_pos": 73, "type": "TASK", "confidence": 0.6561659574508667}]}, {"text": "For instance, given the word factory in English and the word lavoratore in Italian (En. worker), the method can measure the relatedness of these two words despite the fact that they belong to two different languages.", "labels": [], "entities": []}, {"text": "Measures of cross-language relatedness are useful fora large number of applications, including cross-language information retrieval (Nie et al., 1999; Monz and Dorr, 2005), cross-language text classification (Gliozzo and Strapparava, 2006), lexical choice in machine translation (Och and Ney, 2000; Bangalore et al., 2007), induction of translation lexicons (Schafer and Yarowsky, 2002), cross-language annotation and resource projections to a second language (Riloff et al., 2002; Hwa et al., 2002; Mohammad et al., 2007).", "labels": [], "entities": [{"text": "cross-language information retrieval", "start_pos": 95, "end_pos": 131, "type": "TASK", "confidence": 0.7140215237935384}, {"text": "cross-language text classification", "start_pos": 173, "end_pos": 207, "type": "TASK", "confidence": 0.746433158715566}, {"text": "machine translation", "start_pos": 259, "end_pos": 278, "type": "TASK", "confidence": 0.7154954522848129}]}, {"text": "The method we propose is based on a measure of closeness between concept vectors automatically built from Wikipedia, which are mapped via the Wikipedia interlanguage links.", "labels": [], "entities": []}, {"text": "Unlike previous methods for cross-language mapping, which are typically limited by the availability of bilingual dictionaries or parallel texts, the method proposed in this paper can be used to measure the related-ness of word pairs in any of the 250 languages for which a Wikipedia version exists.", "labels": [], "entities": [{"text": "cross-language mapping", "start_pos": 28, "end_pos": 50, "type": "TASK", "confidence": 0.8086709082126617}]}, {"text": "The paper is organized as follows.", "labels": [], "entities": []}, {"text": "We first provide a brief overview of Wikipedia, followed by a description of the method to build concept vectors based on this encyclopedic resource.", "labels": [], "entities": []}, {"text": "We then show how these concept vectors can be mapped across languages fora cross-lingual measure of word relatedness.", "labels": [], "entities": []}, {"text": "Through evaluations run on six language pairs, connecting English, Spanish, Ara-bic and Romanian, we show that the method is effective at capturing the cross-lingual relatedness of words, with results comparable to the monolingual measures of relatedness.", "labels": [], "entities": []}], "introductionContent": [], "datasetContent": [{"text": "We run our experiments on four languages: English, Spanish, Romanian and Arabic.", "labels": [], "entities": []}, {"text": "For each of these languages, we use a Wikipedia download from October 2008.", "labels": [], "entities": [{"text": "Wikipedia download from October 2008", "start_pos": 38, "end_pos": 74, "type": "DATASET", "confidence": 0.9308033347129822}]}, {"text": "The articles were preprocessed using Wikipedia Miner to extract structural information such as generality, and interlanguage links.", "labels": [], "entities": [{"text": "Wikipedia Miner", "start_pos": 37, "end_pos": 52, "type": "DATASET", "confidence": 0.9580480456352234}]}, {"text": "Furthermore, articles were also processed to remove numerical content, as well as any characters not included in the given language's alphabet.", "labels": [], "entities": []}, {"text": "The content words are stemmed, and words shorter than three characters are removed (a heuristic which we use as an approximation for stopword removal).", "labels": [], "entities": []}, {"text": "shows the number of articles in each Wikipedia version and the size of their vocabularies, as obtained after the pre-processing step.", "labels": [], "entities": []}, {"text": "After pre-processing, the articles are indexed to generate the ESA concept vectors.", "labels": [], "entities": [{"text": "ESA concept vectors", "start_pos": 63, "end_pos": 82, "type": "DATASET", "confidence": 0.8911172946294149}]}, {"text": "From each Wikipedia version, we also extract other features including article titles, interlanguage links, and Wikipedia category graphs.", "labels": [], "entities": []}, {"text": "The interlanguage links are further processed to recover any missing links, as described in the previous section.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Top ten largest Wikipedias", "labels": [], "entities": [{"text": "Wikipedias", "start_pos": 26, "end_pos": 36, "type": "TASK", "confidence": 0.5512254238128662}]}, {"text": " Table 2: Top ten Wikipedia concepts for the word  \"bird\"", "labels": [], "entities": []}, {"text": " Table 3: Reflectivity and transitivity in Wikipedia", "labels": [], "entities": []}, {"text": " Table 4: Interlanguage links (initial and discov- ered) and their coverage in Wikipedia versions in  four languages.", "labels": [], "entities": []}, {"text": " Table 5: Number of articles and size of vocabulary  for the four Wikipedia versions", "labels": [], "entities": []}, {"text": " Table 7:  Pearson correlation for cross- lingual relatedness on the Miller-Charles and  WordSimilarity-353 data sets", "labels": [], "entities": [{"text": "Pearson correlation", "start_pos": 11, "end_pos": 30, "type": "METRIC", "confidence": 0.9226077198982239}, {"text": "WordSimilarity-353 data sets", "start_pos": 89, "end_pos": 117, "type": "DATASET", "confidence": 0.971624493598938}]}, {"text": " Table 8:  Spearman correlation for cross- lingual relatedness on the Miller-Charles and  WordSimilarity-353 data sets", "labels": [], "entities": [{"text": "Spearman correlation", "start_pos": 11, "end_pos": 31, "type": "METRIC", "confidence": 0.6093238592147827}, {"text": "WordSimilarity-353 data sets", "start_pos": 90, "end_pos": 118, "type": "DATASET", "confidence": 0.9737792412439982}]}]}