{"title": [{"text": "Bilingual dictionary generation for low-resourced language pairs", "labels": [], "entities": [{"text": "Bilingual dictionary generation", "start_pos": 0, "end_pos": 31, "type": "TASK", "confidence": 0.8213089108467102}]}], "abstractContent": [{"text": "Bilingual dictionaries are vital resources in many areas of natural language processing.", "labels": [], "entities": [{"text": "natural language processing", "start_pos": 60, "end_pos": 87, "type": "TASK", "confidence": 0.6606408258279165}]}, {"text": "Numerous methods of machine translation require bilingual dictionaries with large coverage , but less-frequent language pairs rarely have any digitalized resources.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 20, "end_pos": 39, "type": "TASK", "confidence": 0.7387185990810394}]}, {"text": "Since the need for these resources is increasing, but the human resources are scarce for less represented languages, efficient automatized methods are needed.", "labels": [], "entities": []}, {"text": "This paper introduces a fully automated , robust pivot language based bilingual dictionary generation method that uses the WordNet of the pivot language to build anew bilingual dictionary.", "labels": [], "entities": [{"text": "bilingual dictionary generation", "start_pos": 70, "end_pos": 101, "type": "TASK", "confidence": 0.6988087892532349}, {"text": "WordNet", "start_pos": 123, "end_pos": 130, "type": "DATASET", "confidence": 0.9546738266944885}]}, {"text": "We propose the usage of WordNet in order to increase accuracy; we also introduce a bidirectional selection method with a flexible threshold to maximize recall.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 24, "end_pos": 31, "type": "DATASET", "confidence": 0.9628891944885254}, {"text": "accuracy", "start_pos": 53, "end_pos": 61, "type": "METRIC", "confidence": 0.9986673593521118}, {"text": "recall", "start_pos": 152, "end_pos": 158, "type": "METRIC", "confidence": 0.9939761161804199}]}, {"text": "Our evaluations showed 79% accuracy and 51% weighted recall, outperforming representative pivot language based methods.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 27, "end_pos": 35, "type": "METRIC", "confidence": 0.9996132254600525}, {"text": "recall", "start_pos": 53, "end_pos": 59, "type": "METRIC", "confidence": 0.9697685837745667}]}, {"text": "A dictionary generated with this method will still need manual post-editing, but the improved recall and precision decrease the work of human correctors.", "labels": [], "entities": [{"text": "recall", "start_pos": 94, "end_pos": 100, "type": "METRIC", "confidence": 0.9992926120758057}, {"text": "precision", "start_pos": 105, "end_pos": 114, "type": "METRIC", "confidence": 0.9985235333442688}]}], "introductionContent": [{"text": "In recent decades automatic and semi-automatic machine translation systems gradually managed to takeover costly human tasks.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 47, "end_pos": 66, "type": "TASK", "confidence": 0.7212911695241928}]}, {"text": "This much welcomed change can be attributed not only to major developments in techniques regarding translation methods, but also to important translation resources, such as monolingual or bilingual dictionaries and corpora, thesauri, and soon.", "labels": [], "entities": []}, {"text": "However, while widely used language pairs can fully take advantage of state-of-the-art developments in machine translation, certain low-frequency, or less common language pairs lack some or even most of the above mentioned translation resources.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 103, "end_pos": 122, "type": "TASK", "confidence": 0.7695871591567993}]}, {"text": "In that case, the key to a highly accurate machine translation system switches from the choice and adaptation of the translation method to the problem of available translation resources between the chosen languages.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 43, "end_pos": 62, "type": "TASK", "confidence": 0.7448347210884094}]}, {"text": "One possible solution is bilingual corpus acquisition for statistical machine translation (SMT).", "labels": [], "entities": [{"text": "bilingual corpus acquisition", "start_pos": 25, "end_pos": 53, "type": "TASK", "confidence": 0.67968021829923}, {"text": "statistical machine translation (SMT)", "start_pos": 58, "end_pos": 95, "type": "TASK", "confidence": 0.8097832401593527}]}, {"text": "However, for highly accurate SMT systems large bilingual corpora are required, which are rarely available for less represented languages.", "labels": [], "entities": [{"text": "SMT", "start_pos": 29, "end_pos": 32, "type": "TASK", "confidence": 0.9885526895523071}]}, {"text": "Rule or sentence pattern based systems are an attractive alternative, for these systems the need fora bilingual dictionary is essential.", "labels": [], "entities": []}, {"text": "Our paper targets bilingual dictionary generation, a resource which can be used within the frameworks of a rule or pattern based machine translation system.", "labels": [], "entities": [{"text": "bilingual dictionary generation", "start_pos": 18, "end_pos": 49, "type": "TASK", "confidence": 0.605563094218572}]}, {"text": "Our goal is to provide a lowcost, robust and accurate dictionary generation method.", "labels": [], "entities": [{"text": "dictionary generation", "start_pos": 54, "end_pos": 75, "type": "TASK", "confidence": 0.6980524212121964}]}, {"text": "Low cost and robustness are essential in order to be re-implementable with any arbitrary language pair.", "labels": [], "entities": []}, {"text": "We also believe that besides high precision, high recall is also crucial in order to facilitate post-editing which has to be performed by human correctors.", "labels": [], "entities": [{"text": "precision", "start_pos": 34, "end_pos": 43, "type": "METRIC", "confidence": 0.9975054860115051}, {"text": "recall", "start_pos": 50, "end_pos": 56, "type": "METRIC", "confidence": 0.9984291195869446}]}, {"text": "For improved precision, we propose the usage of WordNet, while for good recall we introduce a bidirectional selection method with local thresholds.", "labels": [], "entities": [{"text": "precision", "start_pos": 13, "end_pos": 22, "type": "METRIC", "confidence": 0.9986973404884338}, {"text": "WordNet", "start_pos": 48, "end_pos": 55, "type": "DATASET", "confidence": 0.9698358774185181}, {"text": "recall", "start_pos": 72, "end_pos": 78, "type": "METRIC", "confidence": 0.9985256791114807}]}, {"text": "Our paper is structured as follows: first we overview the most significant related works, after which we analyze the problems of current dictionary generation methods.", "labels": [], "entities": [{"text": "dictionary generation", "start_pos": 137, "end_pos": 158, "type": "TASK", "confidence": 0.7404959201812744}]}, {"text": "We present the details of our proposal, exemplified with the Japanese-Hungarian language pair.", "labels": [], "entities": []}, {"text": "We evaluate the generated dictionary, performing also a comparative evaluation with two other pivotlanguage based methods.", "labels": [], "entities": []}, {"text": "Finally we present our conclusions.", "labels": [], "entities": []}], "datasetContent": [{"text": "As a pre-evaluation of the above selection methods, we randomly selected 200 1-to-1 sourcetarget entries resulted by each method.", "labels": [], "entities": []}, {"text": "The same evaluator scored the translation pairs as correct (the translation conveys the same meaning, or the meanings are slightly different, but in a certain context the translation is possible), undecided (the translation pair's semantic value is similar, but a translation based on them would be faulty) or wrong (the translation pair's two entries convey a different meaning).", "labels": [], "entities": []}, {"text": "The results showed that type A and type B selections scored higher than all order-based selections, with type C, type D and type E selections failing to deliver the desired accuracy).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 173, "end_pos": 181, "type": "METRIC", "confidence": 0.998853325843811}]}, {"text": "We performed three types of evaluation: (1) frequency-weighted recall evaluation (2) 1-to-1 entry precision evaluation (3) 1-to-multiple entry evaluation For comparative purposes we also performed each type of evaluation for two other pivot language based methods whose characteristics permit to be implementable with virtually any language pair.", "labels": [], "entities": [{"text": "recall", "start_pos": 63, "end_pos": 69, "type": "METRIC", "confidence": 0.913508415222168}]}, {"text": "In order to do so, we constructed two other Hungarian-Japanese dictionaries using the methods proposed by Tanaka & Umemura and Sj\u00f6bergh, using the same source dictionaries.", "labels": [], "entities": []}, {"text": "It is well known that one of the most challenging aspects of dictionary generation is word ambiguity.", "labels": [], "entities": [{"text": "dictionary generation", "start_pos": 61, "end_pos": 82, "type": "TASK", "confidence": 0.8584774434566498}, {"text": "word ambiguity", "start_pos": 86, "end_pos": 100, "type": "TASK", "confidence": 0.7266102433204651}]}, {"text": "It is relatively easy to automatically generate the translations of low-frequency keywords, because they tend to be less ambiguous.", "labels": [], "entities": []}, {"text": "On the contrary, the ambiguity of the high frequency words is much higher than their low-frequency counterparts, and as a result conventional methods fail to translate a considerable number of them.", "labels": [], "entities": []}, {"text": "However, this discrepancy is not reflected in the traditional recall evaluation, since each word has an equal weight, regardless of its frequency of use.", "labels": [], "entities": [{"text": "recall", "start_pos": 62, "end_pos": 68, "type": "METRIC", "confidence": 0.9670526385307312}]}, {"text": "As a result, we performed a frequency weighted recall evaluation.", "labels": [], "entities": [{"text": "recall", "start_pos": 47, "end_pos": 53, "type": "METRIC", "confidence": 0.948968768119812}]}, {"text": "We used a Japanese frequency dictionary (FD) generated from the Japanese EDR corpus to weight each Japanese entry.", "labels": [], "entities": [{"text": "Japanese frequency dictionary (FD)", "start_pos": 10, "end_pos": 44, "type": "METRIC", "confidence": 0.5335800051689148}, {"text": "Japanese EDR corpus", "start_pos": 64, "end_pos": 83, "type": "DATASET", "confidence": 0.6300398508707682}]}, {"text": "Setting the standard to the frequency dictionary (its recall value being 100), we automatically search for each entry (w) from the frequency dictionary, looking whether or not it is included in the bilingual dictionary (WD).", "labels": [], "entities": [{"text": "recall", "start_pos": 54, "end_pos": 60, "type": "METRIC", "confidence": 0.998066246509552}]}, {"text": "If it is recalled, we weight it with its frequency from the frequency dictionary.", "labels": [], "entities": []}, {"text": "The frequency weighted recall value results show that our method's dictionary (51.68) outscores every other automatically generated method's dictionary (37.03, 30.76) with a significant advantage.", "labels": [], "entities": [{"text": "recall", "start_pos": 23, "end_pos": 29, "type": "METRIC", "confidence": 0.9403268694877625}]}, {"text": "Moreover, it maintains the score of the initial translation candidates, therefore managing to maximize the recall value, owing to the bidirectional selection method with local thresholds.", "labels": [], "entities": [{"text": "recall", "start_pos": 107, "end_pos": 113, "type": "METRIC", "confidence": 0.9990947246551514}]}, {"text": "However, the recall value of a manually created Japanese-English dictionary is higher than any automatically generated dictionary's value.", "labels": [], "entities": [{"text": "recall", "start_pos": 13, "end_pos": 19, "type": "METRIC", "confidence": 0.9990068078041077}]}, {"text": "With 1-to-1 precision evaluation we determine the translation accuracy of our method, compared with the two baseline methods.", "labels": [], "entities": [{"text": "precision", "start_pos": 12, "end_pos": 21, "type": "METRIC", "confidence": 0.9852069020271301}, {"text": "translation", "start_pos": 50, "end_pos": 61, "type": "TASK", "confidence": 0.9047001004219055}, {"text": "accuracy", "start_pos": 62, "end_pos": 70, "type": "METRIC", "confidence": 0.8713942170143127}]}, {"text": "200 random pairs were selected from each of the three Hungarian-Japanese dictionaries, scoring them manually the same way as with selection type evaluation (correct, undecided, wrong) ().", "labels": [], "entities": []}, {"text": "The manual scoring was performed by one of the authors, who is a native Hungarian and fluent in Japanese.", "labels": [], "entities": []}, {"text": "Since no independent evaluator was available for these two languages, after a random identification code being assigned to each of the 600 selected translation pairs (200 from each dictionary), they were mixed.", "labels": [], "entities": []}, {"text": "Therefore the evaluator did not know the origin of the translation pairs, only after manual scoring the total score for each dictionary was available, after regrouping based on the initial identification codes.", "labels": [], "entities": []}, {"text": "The process was repeated 10 times, 2000 pairs were manually checked from each dictionary.", "labels": [], "entities": []}, {"text": "To rank the methods we only consider the correct translations.", "labels": [], "entities": []}, {"text": "Our method performed best with an average of 79.15%, outscoring Tanaka method's 62.50% and Sj\u00f6bergh method's 54.05%).", "labels": [], "entities": []}, {"text": "The maximum deviance of the correct translations during the 10 repetitions was less than 3% from the average.", "labels": [], "entities": [{"text": "repetitions", "start_pos": 63, "end_pos": 74, "type": "METRIC", "confidence": 0.948316752910614}]}, {"text": "While with 1-to-1 precision evaluation we estimated the accuracy of the translation pairs, with 1-to-multiple we calculate the true reliability of the dictionary, with the initial translation candidates set as recall benchmark.", "labels": [], "entities": [{"text": "precision", "start_pos": 18, "end_pos": 27, "type": "METRIC", "confidence": 0.9920114874839783}, {"text": "accuracy", "start_pos": 56, "end_pos": 64, "type": "METRIC", "confidence": 0.9987952709197998}, {"text": "reliability", "start_pos": 132, "end_pos": 143, "type": "METRIC", "confidence": 0.8373249173164368}, {"text": "recall", "start_pos": 210, "end_pos": 216, "type": "METRIC", "confidence": 0.9951828122138977}]}, {"text": "When looking up the meanings or translations of a certain headword, the user, whether he's a human or a machine, expects all translations to be accurate.", "labels": [], "entities": [{"text": "looking up the meanings or translations of a certain headword", "start_pos": 5, "end_pos": 66, "type": "TASK", "confidence": 0.7080254822969436}]}, {"text": "Therefore we evaluated 200 randomly selected Japanese entries from the initial translation candidates, together with all of their Hungarian translations, scoring them as correct (all translations are correct), acceptable (the good translations are predominant, but there are up to 2 erroneous translations), wrong (the number or wrong translations exceeds 2) or missing (the translation is missing) (.", "labels": [], "entities": []}, {"text": "The same type of mixed, manual evaluation was performed by the same author on samples of 200 entries from each Japanese-Hungarian dictionary.", "labels": [], "entities": []}, {"text": "This evaluation was also repeated 10 times.", "labels": [], "entities": []}, {"text": "To rank the methods, we only consider the correct translations.", "labels": [], "entities": []}, {"text": "Our method scored best with 71.45%, outperforming Sj\u00f6bergh method's 61.65% and Tanaka method's 46.95%", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Translation candidate scoring for \u8cfc\u5165: buy, purchase (above thresholds in bold)", "labels": [], "entities": []}, {"text": " Table 2: Selection type F-scores with varying thresh- olds (best threshold values in bold)", "labels": [], "entities": [{"text": "F-scores", "start_pos": 25, "end_pos": 33, "type": "METRIC", "confidence": 0.668674111366272}, {"text": "thresh- olds", "start_pos": 47, "end_pos": 59, "type": "METRIC", "confidence": 0.8325453599294027}]}, {"text": " Table 3: Selection type evaluation", "labels": [], "entities": [{"text": "Selection type evaluation", "start_pos": 10, "end_pos": 35, "type": "TASK", "confidence": 0.8994027177492777}]}, {"text": " Table 4: Recall evaluation results (* marks a manu- ally created dictionary)", "labels": [], "entities": []}, {"text": " Table 5: 1-to-1 precision evaluation examples", "labels": [], "entities": [{"text": "precision", "start_pos": 17, "end_pos": 26, "type": "METRIC", "confidence": 0.9857571721076965}]}, {"text": " Table 7: 1-to-multiple entry evaluation examples", "labels": [], "entities": []}]}