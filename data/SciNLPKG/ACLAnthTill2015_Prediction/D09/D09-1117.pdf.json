{"title": [], "abstractContent": [{"text": "This paper investigates the effect of direction in phrase-based statistial machine translation decoding.", "labels": [], "entities": [{"text": "phrase-based statistial machine translation decoding", "start_pos": 51, "end_pos": 103, "type": "TASK", "confidence": 0.6445816159248352}]}, {"text": "We compare atypical phrase-based machine translation de-coder using a left-to-right decoding strategy to a right-to-left decoder.", "labels": [], "entities": [{"text": "phrase-based machine translation de-coder", "start_pos": 20, "end_pos": 61, "type": "TASK", "confidence": 0.7064207941293716}]}, {"text": "We also investigate the effectiveness of a bidirec-tional decoding strategy that integrates both mono-directional approaches, with the aim of reducing the effects due to language specificity.", "labels": [], "entities": []}, {"text": "Our experimental evaluation was extensive, based on 272 different language pairs, and gave the surprising result that for most of the language pairs, it was better decode from right-to-left than from left-to-right.", "labels": [], "entities": []}, {"text": "As expected the relative performance of left-to-right and right-to-left strategies proved to be highly language dependent.", "labels": [], "entities": []}, {"text": "The bidirectional approach outperformed the both the left-to-right strategy and the right-to-left strategy, showing consistent improvements that appeared to be unrelated to the specific languages used for translation.", "labels": [], "entities": []}, {"text": "Bidirectional decoding gave rise to an improvement in performance over a left-to-right decoding strategy in terms of the BLEU score in 99% of our experiments.", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 121, "end_pos": 131, "type": "METRIC", "confidence": 0.9774581789970398}]}], "introductionContent": [{"text": "Human language production by its very nature is an ordered process.", "labels": [], "entities": [{"text": "Human language production", "start_pos": 0, "end_pos": 25, "type": "TASK", "confidence": 0.6149649123350779}]}, {"text": "That is to say, words are written/uttered in a sequence.", "labels": [], "entities": []}, {"text": "The current generation of phrase-based statistical machine translation (SMT) systems also generate their target word sequences according to an order.", "labels": [], "entities": [{"text": "phrase-based statistical machine translation (SMT)", "start_pos": 26, "end_pos": 76, "type": "TASK", "confidence": 0.7312918816293988}]}, {"text": "Since the generation process is symmetrical, there are two possible strategies that could be used to generate the target: from beginning to end; or from end to beginning.", "labels": [], "entities": []}, {"text": "Generating the target in the 'wrong' direction (the opposite direction to the way in which humans do) is counter intuitive, and possibly as a result of this, SMT systems typically generate the target word sequence in the same order as human language production.", "labels": [], "entities": [{"text": "SMT", "start_pos": 158, "end_pos": 161, "type": "TASK", "confidence": 0.9917997717857361}]}, {"text": "However it is not necessarily the case that this is most effective strategy for all language pairs.", "labels": [], "entities": []}, {"text": "In this paper we investigate the effect of direction in phrase-based SMT decoding.", "labels": [], "entities": [{"text": "SMT decoding", "start_pos": 69, "end_pos": 81, "type": "TASK", "confidence": 0.9127359390258789}]}, {"text": "For the purposes of this paper, we will refer to target word sequence generation that follows the same order as human language production as forward generation, and generation in the opposite direction to human language production as reverse generation.", "labels": [], "entities": [{"text": "target word sequence generation", "start_pos": 49, "end_pos": 80, "type": "TASK", "confidence": 0.656656302511692}]}, {"text": "These are often referred \"left-toright\" and \"right-to-left\" respectively in the literature, but we avoid this notation as many languages are naturally written from right-to-left.", "labels": [], "entities": []}, {"text": "In earlier work (), it was hypothesized that the optimal direction for decoding was dependent on the characteristics of the target language.", "labels": [], "entities": []}, {"text": "Their results show that for Japanese to English translation a reverse decoding strategy was the most effective, whereas for English to Japanese translation, a forward decoding strategy proved superior.", "labels": [], "entities": [{"text": "Japanese to English translation", "start_pos": 28, "end_pos": 59, "type": "TASK", "confidence": 0.5686480328440666}, {"text": "English to Japanese translation", "start_pos": 124, "end_pos": 155, "type": "TASK", "confidence": 0.6921372264623642}]}, {"text": "In addition they implemented a bidirectional decoder, but their results were mixed.", "labels": [], "entities": []}, {"text": "For English to Japanese translation, decoding bidirectionally gives higher performance, but for Japanese to English translation they were unable to improve performance by decoding bidirectionally.", "labels": [], "entities": []}, {"text": "Their experiments were performed using a decoder based on IBM Model 4 using the translation techniques developed at IBM (.", "labels": [], "entities": []}, {"text": "This work is closely related to the techniques proposed in (), but in our case we decode within the framework of a phrase-based SMT system, rather than the IBM model.", "labels": [], "entities": [{"text": "SMT", "start_pos": 128, "end_pos": 131, "type": "TASK", "confidence": 0.8462343811988831}]}, {"text": "Our intention was to explore the effect of direction in decoding within the context of a more contemporary machine translation paradigm, and to experiment with a broader range of languages.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 107, "end_pos": 126, "type": "TASK", "confidence": 0.7112319022417068}]}, {"text": "The underlying motivation for our studies however remains the same.", "labels": [], "entities": []}, {"text": "Languages have considerably different structure, and certain grammatical constructs tend to occupy particular positions within sentences of the same language, but different positions across languages.", "labels": [], "entities": []}, {"text": "These differences may make it easier to tackle the automatic translation of a sentence in a given language from a particular direction.", "labels": [], "entities": [{"text": "automatic translation of a sentence", "start_pos": 51, "end_pos": 86, "type": "TASK", "confidence": 0.8163933634757996}]}, {"text": "Our approach differs in that the decoding process of a phrased-based decoder is quite different from that used by) since decoding is done using larger units making the re-ordering process much simpler.", "labels": [], "entities": []}, {"text": "In () only one language pair is considered, for our experiments we extended this to include translation among 17 different languages including the Japanese and English pair used in ().", "labels": [], "entities": []}, {"text": "We felt that it was important to consider as many languages as possible in this study, as intuition and evidence from the original study suggests that the effect of direction in decoding is likely to be strongly language dependent.", "labels": [], "entities": []}, {"text": "The next section briefly describes the mechanisms underlying phrase-based decoding.", "labels": [], "entities": []}, {"text": "Then we explain the principles behind the forward, reverse and bidirectional decoding strategies used in our experiments.", "labels": [], "entities": []}, {"text": "Section 3 presents the experiments we performed.", "labels": [], "entities": []}, {"text": "Section 4 gives the results and some analysis.", "labels": [], "entities": []}, {"text": "Finally in Section 5, we conclude and offer possible directions for future research.", "labels": [], "entities": []}], "datasetContent": [{"text": "The experiments were conducted on all possible pairings among 17 languages.", "labels": [], "entities": []}, {"text": "A key to the acronyms used for languages together with information about their respective characteristics is given in.", "labels": [], "entities": []}, {"text": "We used all of the first ATR Basic Travel Expression Corpus (BTEC1) () for these experiments.", "labels": [], "entities": [{"text": "ATR Basic Travel Expression Corpus (BTEC1)", "start_pos": 25, "end_pos": 67, "type": "DATASET", "confidence": 0.7333844862878323}]}, {"text": "This corpus contains the kind of expressions that one might expect to find in a phrase-book for travelers.", "labels": [], "entities": []}, {"text": "The corpus is similar in character to the IWSLT06 Evaluation Campaign on Spoken Language Translation) J-E open track.", "labels": [], "entities": [{"text": "IWSLT06 Evaluation Campaign on Spoken Language Translation) J-E open track", "start_pos": 42, "end_pos": 116, "type": "DATASET", "confidence": 0.7888538891618903}]}, {"text": "The sentences are relatively short (see) with a simple structure and a fairly narrow range of vocabulary due to the limited domain.", "labels": [], "entities": []}, {"text": "The experiments were conducted on data that contained no case information, and also no punctuation (this was an arbitrary decision that we believe had no impact on the results).", "labels": [], "entities": []}, {"text": "We used a 1000 sentence development corpus for all experiments, and the corpus used for evaluation consisted of 5000 sentences with a single reference for each sentence.", "labels": [], "entities": []}, {"text": "The results presented in this paper are given in terms of the BLEU score ().", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 62, "end_pos": 72, "type": "METRIC", "confidence": 0.9723924398422241}]}, {"text": "This metric measures the geometric mean of ngram precision of n-grams drawn from the output translation and a set of reference translations for that translation.", "labels": [], "entities": [{"text": "ngram precision", "start_pos": 43, "end_pos": 58, "type": "METRIC", "confidence": 0.7166174054145813}]}, {"text": "There are large number of proposed methods for carrying out machine translation evaluation.", "labels": [], "entities": [{"text": "machine translation evaluation", "start_pos": 60, "end_pos": 90, "type": "TASK", "confidence": 0.8834394415219625}]}, {"text": "Methods differ in their focus of characteristics of the translation (for example fluency or adequacy), and moreover anomolous results can occur if a single metric is relied on.", "labels": [], "entities": []}, {"text": "Therefore, we also carried out evaluations using the NIST), METEOR (Banerjee and), WER, PER () and TER () machine translation evaluation techniques.", "labels": [], "entities": [{"text": "NIST", "start_pos": 53, "end_pos": 57, "type": "DATASET", "confidence": 0.89188551902771}, {"text": "METEOR", "start_pos": 60, "end_pos": 66, "type": "METRIC", "confidence": 0.9915594458580017}, {"text": "WER", "start_pos": 83, "end_pos": 86, "type": "METRIC", "confidence": 0.9932214021682739}, {"text": "PER", "start_pos": 88, "end_pos": 91, "type": "METRIC", "confidence": 0.904228687286377}, {"text": "TER", "start_pos": 99, "end_pos": 102, "type": "METRIC", "confidence": 0.9816899299621582}, {"text": "machine translation evaluation", "start_pos": 106, "end_pos": 136, "type": "TASK", "confidence": 0.708303322394689}]}], "tableCaptions": [{"text": " Table 1: Key to the languages, corpus statistics and word order. SVO denotes a language that predomi- nantly has subject-verb-object order, and SOV denotes a language that predominantly has subject-object- verb order", "labels": [], "entities": []}, {"text": " Table 2: Baseline BLEU scores for all systems. The figures represent the scores in BLEU percentage  points of the baseline left-to-right decoding systems. Source languages are indicated by the column  headers, the row headers denoting the target languages.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 19, "end_pos": 23, "type": "METRIC", "confidence": 0.9447619915008545}, {"text": "BLEU", "start_pos": 84, "end_pos": 88, "type": "METRIC", "confidence": 0.9970314502716064}]}, {"text": " Table 3: Gains in BLEU score from reverse decoding over a forward decoding strategy The numbers  in the cells are the differences in BLEU percentage points between the systems. Shaded cells indicate  the cases where forward decoding give a higher score. Source languages are indicated by the column  headers, the row headers denoting the target languages.", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 19, "end_pos": 29, "type": "METRIC", "confidence": 0.963799387216568}, {"text": "BLEU", "start_pos": 134, "end_pos": 138, "type": "METRIC", "confidence": 0.9958896040916443}]}, {"text": " Table 4: Summary of the results using several au- tomatic metrics for evaluation. Numbers in the ta- ble correspond to the percentage of experiments  in which the condition at the head of the column  was true (for example figure in the first row and  first column means that for 98.9 percent of the lan- guage pairs the BLEU score for the bidirectional  decoder was better than that of the forward de- coder)", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 321, "end_pos": 331, "type": "METRIC", "confidence": 0.9807138741016388}]}, {"text": " Table 5: Gains in BLEU score from decoding bidirectionally over a forward decoding strategy. The  numbers in the cells are the differences in BLEU percentage points between the systems. Shaded cells  indicate the cases where forward decoding gave a higher score. Source languages are indicated by the  column headers, the row headers denoting the target languages.", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 19, "end_pos": 29, "type": "METRIC", "confidence": 0.9615306854248047}, {"text": "BLEU", "start_pos": 143, "end_pos": 147, "type": "METRIC", "confidence": 0.9974799752235413}]}]}