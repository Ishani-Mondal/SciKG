{"title": [{"text": "Natural Language Generation with Tree Conditional Random Fields Singapore-MIT Alliance", "labels": [], "entities": [{"text": "Natural Language Generation", "start_pos": 0, "end_pos": 27, "type": "TASK", "confidence": 0.6561519702275594}]}], "abstractContent": [{"text": "This paper presents an effective method for generating natural language sentences from their underlying meaning representations.", "labels": [], "entities": []}, {"text": "The method is built on top of a hybrid tree representation that jointly encodes both the meaning representation as well as the natural language in a tree structure.", "labels": [], "entities": []}, {"text": "By using a tree conditional random field on top of the hybrid tree representation, we are able to explicitly model phrase-level dependencies amongst neighboring natural language phrases and meaning representation components in a simple and natural way.", "labels": [], "entities": []}, {"text": "We show that the additional dependencies captured by the tree conditional random field allows it to perform better than directly inverting a previously developed hybrid tree semantic parser.", "labels": [], "entities": []}, {"text": "Furthermore, we demonstrate that the model performs better than a previous state-of-the-art natural language generation model.", "labels": [], "entities": []}, {"text": "Experiments are performed on two benchmark corpora with standard automatic evaluation metrics.", "labels": [], "entities": []}], "introductionContent": [{"text": "One of the ultimate goals in the field of natural language processing (NLP) is to enable computers to converse with humans through human languages.", "labels": [], "entities": [{"text": "natural language processing (NLP)", "start_pos": 42, "end_pos": 75, "type": "TASK", "confidence": 0.8416304886341095}]}, {"text": "To achieve this goal, two important issues need to be studied.", "labels": [], "entities": []}, {"text": "First, it is important for computers to capture the meaning of a natural language sentence in a meaning representation.", "labels": [], "entities": []}, {"text": "Second, computers should be able to produce a humanunderstandable natural language sentence from its meaning representation.", "labels": [], "entities": []}, {"text": "These two tasks are referred to as semantic parsing and natural language generation (NLG), respectively.", "labels": [], "entities": [{"text": "semantic parsing", "start_pos": 35, "end_pos": 51, "type": "TASK", "confidence": 0.7164881676435471}, {"text": "natural language generation (NLG)", "start_pos": 56, "end_pos": 89, "type": "TASK", "confidence": 0.7861722409725189}]}, {"text": "In this paper, we use corpus-based statistical methods for constructing a natural language generation system.", "labels": [], "entities": []}, {"text": "Given a set of pairs, where each pair consists of a natural language (NL) sentence and its formal meaning representation (MR), a learning method induces an algorithm that can be used for performing language generation from other previously unseen meaning representations.", "labels": [], "entities": [{"text": "language generation", "start_pos": 198, "end_pos": 217, "type": "TASK", "confidence": 0.7590204775333405}]}, {"text": "A crucial question in any natural language processing system is the representation used.", "labels": [], "entities": []}, {"text": "Meaning representations can be in the form of a tree structure.", "labels": [], "entities": []}, {"text": "In, we introduced a hybrid tree framework together with a probabilistic generative model to tackle semantic parsing, where tree structured meaning representations are used.", "labels": [], "entities": [{"text": "semantic parsing", "start_pos": 99, "end_pos": 115, "type": "TASK", "confidence": 0.7674334049224854}]}, {"text": "The hybrid tree gives a natural joint tree representation of a natural language sentence and its meaning representation.", "labels": [], "entities": []}, {"text": "A joint generative model for natural language and its meaning representation, such as that used in has several advantages over various previous approaches designed for semantic parsing.", "labels": [], "entities": [{"text": "semantic parsing", "start_pos": 168, "end_pos": 184, "type": "TASK", "confidence": 0.744299590587616}]}, {"text": "First, unlike most previous approaches, the generative approach models a simultaneous generation process for both NL and MR.", "labels": [], "entities": [{"text": "generative", "start_pos": 44, "end_pos": 54, "type": "TASK", "confidence": 0.9744037985801697}]}, {"text": "One elegant property of such a joint generative model is that it allows the modeling of both semantic parsing and natural language generation within the same process.", "labels": [], "entities": [{"text": "semantic parsing", "start_pos": 93, "end_pos": 109, "type": "TASK", "confidence": 0.7336966544389725}]}, {"text": "Second, the generative process proceeds as a recursive top-down Markov process in away that takes advantage of the tree structure of the MR.", "labels": [], "entities": [{"text": "generative", "start_pos": 12, "end_pos": 22, "type": "TASK", "confidence": 0.9835161566734314}]}, {"text": "The hybrid tree generative model proposed in was shown to give stateof-the-art accuracy in semantic parsing on benchmark corpora.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 79, "end_pos": 87, "type": "METRIC", "confidence": 0.9961948394775391}, {"text": "semantic parsing", "start_pos": 91, "end_pos": 107, "type": "TASK", "confidence": 0.8003342151641846}]}, {"text": "While semantic parsing with hybrid trees has been studied in, its inverse task -NLG with hybrid trees -has not yet been explored.", "labels": [], "entities": [{"text": "semantic parsing", "start_pos": 6, "end_pos": 22, "type": "TASK", "confidence": 0.8172600567340851}]}, {"text": "We believe that the properties that make the hybrid trees effective for semantic parsing also make them effective for NLG.", "labels": [], "entities": [{"text": "semantic parsing", "start_pos": 72, "end_pos": 88, "type": "TASK", "confidence": 0.8146564960479736}]}, {"text": "In this paper, we develop systems for the generation task by building on top of the generative model introduced in (referred to as the LNLZ08 system).", "labels": [], "entities": []}, {"text": "We first present a baseline model by directly \"inverting\" the LNLZ08 system, where an NL sentence is generated word byword.", "labels": [], "entities": []}, {"text": "We call this model the direct inversion model.", "labels": [], "entities": []}, {"text": "This model is unable to model some long range global dependencies over the entire NL sentence to be generated.", "labels": [], "entities": []}, {"text": "To tackle several weaknesses exhibited by the baseline model, we next introduce an alternative, novel model that performs generation at the phrase level.", "labels": [], "entities": []}, {"text": "Motivated by conditional random fields (CRF) (), a different parameterization of the conditional probability of the hybrid tree that enables the model to encode some longer range dependencies amongst phrases and MRs is used.", "labels": [], "entities": []}, {"text": "This novel model is referred to as the tree CRF-based model.", "labels": [], "entities": []}, {"text": "Evaluation results for both models are presented, through which we demonstrate that the tree CRF-based model performs better than the direct inversion model.", "labels": [], "entities": []}, {"text": "We also compare the tree CRFbased model against the previous state-of-the-art model of.", "labels": [], "entities": []}, {"text": "Furthermore, we evaluate our model on a dataset annotated with several natural languages other than English (Japanese, Spanish, and Turkish).", "labels": [], "entities": []}, {"text": "Evaluation results show that our proposed tree CRF-based model outperforms the previous model.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section, we present the results of our systems when evaluated on two standard benchmark corpora.", "labels": [], "entities": []}, {"text": "The first corpus is GEOQUERY, which contains Prolog-based MRs that can be used to query a US geographic database (.", "labels": [], "entities": [{"text": "GEOQUERY", "start_pos": 20, "end_pos": 28, "type": "DATASET", "confidence": 0.8594500422477722}, {"text": "Prolog-based MRs", "start_pos": 45, "end_pos": 61, "type": "DATASET", "confidence": 0.7404950261116028}]}, {"text": "Our task for this domain is to generate NL sentences from the formal queries.", "labels": [], "entities": []}, {"text": "The second corpus is ROBOCUP.", "labels": [], "entities": [{"text": "ROBOCUP", "start_pos": 21, "end_pos": 28, "type": "DATASET", "confidence": 0.5064342021942139}]}, {"text": "This domain contains MRs which are instructions written in a formal language called CLANG.", "labels": [], "entities": []}, {"text": "Our task for this domain is to generate NL sentences from the coaching advice written in CLANG.", "labels": [], "entities": [{"text": "CLANG", "start_pos": 89, "end_pos": 94, "type": "DATASET", "confidence": 0.8280794620513916}]}, {"text": "GEOQUERY     The GEOQUERY domain contains 880 instances, while the ROBOCUP domain contains 300 instances.", "labels": [], "entities": [{"text": "GEOQUERY", "start_pos": 0, "end_pos": 8, "type": "DATASET", "confidence": 0.9682990312576294}, {"text": "GEOQUERY domain", "start_pos": 17, "end_pos": 32, "type": "DATASET", "confidence": 0.949444979429245}]}, {"text": "The average NL sentence length for the two corpora are 7.57 and 22.52 respectively.", "labels": [], "entities": [{"text": "NL sentence length", "start_pos": 12, "end_pos": 30, "type": "METRIC", "confidence": 0.7911529541015625}]}, {"text": "Following the evaluation methodology of, we performed 4 runs of the standard 10-fold cross validation and report the averaged performance in this section using the standard automatic evaluation metric BLEU () and NIST . The BLEU and NIST scores of the WASP \u22121 ++ system reported in this section are obtained from the published paper of.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 201, "end_pos": 205, "type": "METRIC", "confidence": 0.9882290363311768}, {"text": "NIST", "start_pos": 213, "end_pos": 217, "type": "DATASET", "confidence": 0.953051745891571}, {"text": "BLEU", "start_pos": 224, "end_pos": 228, "type": "METRIC", "confidence": 0.9975487589836121}, {"text": "NIST", "start_pos": 233, "end_pos": 237, "type": "DATASET", "confidence": 0.7644534111022949}]}, {"text": "Note that to make our experimental results directly comparable to, we used the identical training and test data splits for the 4 runs of 10-fold cross validation used by on both corpora.", "labels": [], "entities": []}, {"text": "Our system has the advantage of always producing an NL sentence given any input MR, even if there exist unseen MR productions in the input MR.", "labels": [], "entities": []}, {"text": "We can achieve this by simply skipping those unseen MR productions during the generation process.", "labels": [], "entities": []}, {"text": "However, in order to make a fair comparison against WASP \u22121 ++, which can only generate NL sentences for 97% of the input MRs, we also do not generate any NL sentence in the case of observing an unseen MR production.", "labels": [], "entities": []}, {"text": "All the evaluations discussed in this section follow this evalu-ation methodology, but we notice that empirically our system is able to achieve higher BLEU/NIST scores if we allow generation for those MRs that include unseen MR productions.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 151, "end_pos": 155, "type": "METRIC", "confidence": 0.9984758496284485}]}, {"text": "Following the work of, we also evaluated our system's performance on a subset of the GEOQUERY corpus with 250 instances, where sentences of 4 natural languages (English, Japanese, Spanish, and Turkish) are available.", "labels": [], "entities": [{"text": "GEOQUERY corpus", "start_pos": 85, "end_pos": 100, "type": "DATASET", "confidence": 0.964960128068924}]}, {"text": "The evaluation results are shown in Table 4.", "labels": [], "entities": []}, {"text": "Our tree CRF-based model achieves better performance on this task compared to WASP \u22121 ++.", "labels": [], "entities": []}, {"text": "We are again unable to conduct statistical significance tests for the same reason reported earlier.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Results of automatic evaluation of both models (bold type indicates the best performing system).", "labels": [], "entities": []}, {"text": " Table 3: Results of automatic evaluation of our tree CRF-based model and WASP \u22121 ++.", "labels": [], "entities": []}, {"text": " Table 4: Results on the GEOQUERY-250 corpus with 4 natural languages.", "labels": [], "entities": [{"text": "GEOQUERY-250 corpus", "start_pos": 25, "end_pos": 44, "type": "DATASET", "confidence": 0.9710173904895782}]}]}