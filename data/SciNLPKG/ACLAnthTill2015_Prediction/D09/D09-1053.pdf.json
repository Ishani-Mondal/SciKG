{"title": [{"text": "Model Adaptation via Model Interpolation and Boosting for Web Search Ranking", "labels": [], "entities": [{"text": "Model Adaptation", "start_pos": 0, "end_pos": 16, "type": "TASK", "confidence": 0.7482516169548035}]}], "abstractContent": [{"text": "This paper explores two classes of model adaptation methods for Web search ranking: Model Interpolation and error-driven learning approaches based on a boosting algorithm.", "labels": [], "entities": [{"text": "Web search ranking", "start_pos": 64, "end_pos": 82, "type": "TASK", "confidence": 0.7229074239730835}]}, {"text": "The results show that model interpolation, though simple, achieves the best results on all the open test sets where the test data is very different from the training data.", "labels": [], "entities": []}, {"text": "The tree-based boosting algorithm achieves the best performance on most of the closed test sets where the test data and the training data are similar , but its performance drops significantly on the open test sets due to the instability of trees.", "labels": [], "entities": []}, {"text": "Several methods are explored to improve the robustness of the algorithm, with limited success.", "labels": [], "entities": []}], "introductionContent": [{"text": "We consider the task of ranking Web search results, i.e., a set of retrieved Web documents (URLs) are ordered by relevance to a query issued by a user.", "labels": [], "entities": []}, {"text": "In this paper we assume that the task is performed using a ranking model (also called ranker for short) that is learned on labeled training data (e.g., human-judged query-document pairs).", "labels": [], "entities": []}, {"text": "The ranking model acts as a function that maps the feature vector of a query-document pair to a real-valued score of relevance.", "labels": [], "entities": []}, {"text": "Recent research shows that such a learned ranker is superior to classical retrieval models in two aspects (;).", "labels": [], "entities": []}, {"text": "First, the ranking model can use arbitrary features.", "labels": [], "entities": []}, {"text": "Both traditional criteria such as TF-IDF and BM25, and non-traditional features such as hyperlinks can be incorporated as features in the ranker.", "labels": [], "entities": [{"text": "BM25", "start_pos": 45, "end_pos": 49, "type": "DATASET", "confidence": 0.6324800848960876}]}, {"text": "Second, if large amounts of high-quality human-judged query-document pairs were available for model training, the ranker could achieve significantly better retrieval results than the traditional retrieval models that cannot benefit from training data effectively.", "labels": [], "entities": []}, {"text": "However, such training data is not always available for many search domains, such as non-English search markets or person name search.", "labels": [], "entities": [{"text": "person name search", "start_pos": 115, "end_pos": 133, "type": "TASK", "confidence": 0.6065921286741892}]}, {"text": "One of the most widely used strategies to remedy this problem is model adaptation, which attempts to adjust the parameters and/or structure of a model trained on one domain (called the background domain), for which large amounts of training data are available, to a different domain (the adaptation domain), for which only small amounts of training data are available.", "labels": [], "entities": [{"text": "model adaptation", "start_pos": 65, "end_pos": 81, "type": "TASK", "confidence": 0.7547159790992737}]}, {"text": "In Web search applications, domains can be defined by query types (e.g., person name queries), or languages, etc.", "labels": [], "entities": []}, {"text": "In this paper we investigate two classes of model adaptation methods for Web search ranking: Model Interpolation approaches and error-driven learning approaches.", "labels": [], "entities": [{"text": "Web search ranking", "start_pos": 73, "end_pos": 91, "type": "TASK", "confidence": 0.7181644638379415}]}, {"text": "In model interpolation approaches, the adaptation data is used to derive a domain-specific model (also called in-domain model), which is then combined with the background model trained on the background data.", "labels": [], "entities": []}, {"text": "This appealingly simple concept provides fertile ground for experimentation, depending on the level at which the combination is implemented.", "labels": [], "entities": []}, {"text": "In error-driven learning approaches, the background model is adjusted so as to minimize the ranking errors the model makes on the adaptation data ().", "labels": [], "entities": []}, {"text": "This is arguably more powerful than model interpolation for two reasons.", "labels": [], "entities": []}, {"text": "First, by defining a proper error function, the method can optimize more directly the measure used to assess the final quality of the Web search system, e.g., Normalized Discounted Cumulative Gain) in this study.", "labels": [], "entities": []}, {"text": "Second, in this framework, the model can be adjusted to be as fine-grained as necessary.", "labels": [], "entities": []}, {"text": "In this study we developed a set of error-driven learning methods based on a boosting algorithm where, in an incremental manner, not only each feature weight could be changed separately, but new features could be constructed.", "labels": [], "entities": []}, {"text": "We focus our experiments on the robustness of the adaptation methods.", "labels": [], "entities": []}, {"text": "A model is robust if it performs reasonably well on unseen test data that could be significantly different from training data.", "labels": [], "entities": []}, {"text": "Robustness is important in Web search applications.", "labels": [], "entities": []}, {"text": "Labeling training data takes time.", "labels": [], "entities": [{"text": "Labeling training", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.8944080770015717}]}, {"text": "As a result of the dynamic nature of Web, by the time the ranker is trained and deployed, the training data maybe more or less out of date.", "labels": [], "entities": []}, {"text": "Our results show that the model interpolation is much more robust than the boosting-based methods.", "labels": [], "entities": []}, {"text": "We then explore several methods to improve the robustness of the methods, including regularization, randomization, and using shallow trees, with limited success.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1. Data sets in the names query domain experiments,  where # qry is number of queries, and # url/qry is number  of documents per query.", "labels": [], "entities": []}, {"text": " Table 2. Data sets in the Korean domain experiments.", "labels": [], "entities": [{"text": "Korean domain experiments", "start_pos": 27, "end_pos": 52, "type": "DATASET", "confidence": 0.937716523806254}]}, {"text": " Table 3. Close test results on Names-1-Test.", "labels": [], "entities": [{"text": "Close", "start_pos": 10, "end_pos": 15, "type": "METRIC", "confidence": 0.9796502590179443}]}, {"text": " Table 4. Open test results on Names-2-Test.", "labels": [], "entities": []}, {"text": " Table 5. Close test results of baseline rankers, on Kokr-1-Test", "labels": [], "entities": [{"text": "Close", "start_pos": 10, "end_pos": 15, "type": "METRIC", "confidence": 0.9860506653785706}, {"text": "Kokr-1-Test", "start_pos": 53, "end_pos": 64, "type": "DATASET", "confidence": 0.841773271560669}]}, {"text": " Table 9. Close test results of \u03bb-Boost rankers, on Kokr-1-Test.", "labels": [], "entities": [{"text": "Kokr-1-Test", "start_pos": 52, "end_pos": 63, "type": "DATASET", "confidence": 0.9283977150917053}]}, {"text": " Table 10. Open test results of \u03bb-Boost rankers, on Kokr-2-Test.", "labels": [], "entities": [{"text": "Kokr-2-Test", "start_pos": 52, "end_pos": 63, "type": "DATASET", "confidence": 0.93208909034729}]}, {"text": " Table 11. Close test results of \u03bb-SMART rankers, on  Kokr-1-Test.  # Ranker  NDCG@1 NDCG@3 NDCG@10 AveNDCG  1 \u03bb-SMART  (En)", "labels": [], "entities": [{"text": "Kokr-1-Test", "start_pos": 54, "end_pos": 65, "type": "DATASET", "confidence": 0.9416018128395081}, {"text": "AveNDCG", "start_pos": 100, "end_pos": 107, "type": "METRIC", "confidence": 0.9408932328224182}]}, {"text": " Table 12. Open test results of \u03bb-SMART rankers, on  Kokr-2-Test.", "labels": [], "entities": [{"text": "Kokr-2-Test", "start_pos": 53, "end_pos": 64, "type": "DATASET", "confidence": 0.9473916292190552}]}]}