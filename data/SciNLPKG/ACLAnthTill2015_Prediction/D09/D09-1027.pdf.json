{"title": [{"text": "Clustering to Find Exemplar Terms for Keyphrase Extraction", "labels": [], "entities": [{"text": "Keyphrase Extraction", "start_pos": 38, "end_pos": 58, "type": "TASK", "confidence": 0.6671985387802124}]}], "abstractContent": [{"text": "Keyphrases are widely used as a brief summary of documents.", "labels": [], "entities": []}, {"text": "Since manual assignment is time-consuming, various unsupervised ranking methods based on importance scores are proposed for keyphrase extraction.", "labels": [], "entities": [{"text": "keyphrase extraction", "start_pos": 124, "end_pos": 144, "type": "TASK", "confidence": 0.8975901305675507}]}, {"text": "In practice, the keyphrases of a document should not only be statistically important in the document , but also have a good coverage of the document.", "labels": [], "entities": []}, {"text": "Based on this observation , we propose an unsupervised method for keyphrase extraction.", "labels": [], "entities": [{"text": "keyphrase extraction", "start_pos": 66, "end_pos": 86, "type": "TASK", "confidence": 0.8506813943386078}]}, {"text": "Firstly, the method finds exemplar terms by leverag-ing clustering techniques, which guarantees the document to be semantically covered by these exemplar terms.", "labels": [], "entities": []}, {"text": "Then the keyphrases are extracted from the document using the exemplar terms.", "labels": [], "entities": []}, {"text": "Our method outperforms sate-of-the-art graph-based ranking methods (TextRank) by 9.5% in F1-measure.", "labels": [], "entities": [{"text": "F1-measure", "start_pos": 89, "end_pos": 99, "type": "METRIC", "confidence": 0.9948849081993103}]}], "introductionContent": [{"text": "With the development of Internet, information on the web is emerging exponentially.", "labels": [], "entities": []}, {"text": "How to effectively seek and manage information becomes an important research issue.", "labels": [], "entities": []}, {"text": "Keyphrases, as a brief summary of a document, provide a solution to help organize, manage and retrieve documents, and are widely used in digital libraries and information retrieval.", "labels": [], "entities": [{"text": "information retrieval", "start_pos": 159, "end_pos": 180, "type": "TASK", "confidence": 0.723144069314003}]}, {"text": "Keyphrases in articles of journals and books are usually assigned by authors.", "labels": [], "entities": []}, {"text": "However, most articles on the web usually do not have human-assigned keyphrases.", "labels": [], "entities": []}, {"text": "Therefore, automatic keyphrase extraction is an important research task.", "labels": [], "entities": [{"text": "keyphrase extraction", "start_pos": 21, "end_pos": 41, "type": "TASK", "confidence": 0.8069618344306946}]}, {"text": "Existing methods can be divided into supervised and unsupervised approaches.", "labels": [], "entities": []}, {"text": "The supervised approach) regards keyphrase extraction as a classification task.", "labels": [], "entities": [{"text": "keyphrase extraction", "start_pos": 33, "end_pos": 53, "type": "TASK", "confidence": 0.9132350087165833}]}, {"text": "In this approach, a model is trained to determine whether a candidate term of the document is a keyphrase, based on statistical and linguistic features.", "labels": [], "entities": []}, {"text": "For the supervised keyphrase extraction approach, a document set with human-assigned keyphrases is required as training set.", "labels": [], "entities": [{"text": "keyphrase extraction", "start_pos": 19, "end_pos": 39, "type": "TASK", "confidence": 0.7739266455173492}]}, {"text": "However, human labelling is time-consuming.", "labels": [], "entities": []}, {"text": "Therefore, in this study we focus on unsupervised approach.", "labels": [], "entities": []}, {"text": "As an example of an unsupervised keyphrase extraction approach, the graph-based ranking) regards keyphrase extraction as a ranking task, where a document is represented by a term graph based on term relatedness, and then a graph-based ranking algorithm is used to assign importance scores to each term.", "labels": [], "entities": [{"text": "keyphrase extraction", "start_pos": 33, "end_pos": 53, "type": "TASK", "confidence": 0.7190971225500107}, {"text": "keyphrase extraction", "start_pos": 97, "end_pos": 117, "type": "TASK", "confidence": 0.8071125149726868}]}, {"text": "Existing methods usually use term cooccurrences within a specified window size in the given document as an approximation of term relatedness ().", "labels": [], "entities": []}, {"text": "As we know, none of these existing works gives an explicit definition on what are appropriate keyphrases fora document.", "labels": [], "entities": []}, {"text": "In fact, the existing methods only judge the importance of each term, and extract the most important ones as keyphrases.", "labels": [], "entities": []}, {"text": "From the observation of human-assigned keyphrases, we conclude that good keyphrases of a document should satisfy the following properties: 1.", "labels": [], "entities": []}, {"text": "The keyphrases are understandable to people.", "labels": [], "entities": []}, {"text": "This indicates the extracted keyphrases should be grammatical.", "labels": [], "entities": []}, {"text": "For example, \"machine learning\" is a grammatical phrase, but \"machine learned\" is not.", "labels": [], "entities": [{"text": "machine learning\"", "start_pos": 14, "end_pos": 31, "type": "TASK", "confidence": 0.7882689634958903}]}, {"text": "The keyphrases are semantically relevant with the document theme.", "labels": [], "entities": []}, {"text": "For example, fora document about \"machine learning\", we want the keyphrases all about this theme.", "labels": [], "entities": [{"text": "machine learning\"", "start_pos": 34, "end_pos": 51, "type": "TASK", "confidence": 0.7912896474202474}]}, {"text": "The keyphrases should cover the whole document well.", "labels": [], "entities": []}, {"text": "Suppose we have a document describing \"Beijing\" from various aspects of \"location\", \"atmosphere\" and \"culture\", the extracted keyphrases should coverall the three aspects, instead of just a partial subset of them.", "labels": [], "entities": []}, {"text": "The classification-based approach determines whether a term is a keyphrase in isolation, which could not guarantee Property 3.", "labels": [], "entities": []}, {"text": "Neither does the graph-based approach guarantee the top-ranked keyphrases could cover the whole document.", "labels": [], "entities": []}, {"text": "This may cause the resulting keyphrases to be inappropriate or badly-grouped.", "labels": [], "entities": []}, {"text": "To extract the appropriate keyphrases fora document, we suggest an unsupervised clusteringbased method.", "labels": [], "entities": []}, {"text": "Firstly the terms in a document are grouped into clusters based on semantic relatedness.", "labels": [], "entities": []}, {"text": "Each cluster is represented by an exemplar term, which is also the centroid of each cluster.", "labels": [], "entities": []}, {"text": "Then the keyphrases are extracted from the document using these exemplar terms.", "labels": [], "entities": []}, {"text": "In this method, we group terms based on semantic relatedness, which guarantees a good coverage of the document and meets Property 2 and 3.", "labels": [], "entities": []}, {"text": "Moreover, we only extract the keyphrases in accordance with noun group (chunk) patterns, which guarantees the keyphrases satisfy Property 1.", "labels": [], "entities": []}, {"text": "Experiments show that the clustering-based method outperforms the state-of-the-art graphbased approach on precision, recall and F1-measure.", "labels": [], "entities": [{"text": "precision", "start_pos": 106, "end_pos": 115, "type": "METRIC", "confidence": 0.9992191791534424}, {"text": "recall", "start_pos": 117, "end_pos": 123, "type": "METRIC", "confidence": 0.9981691837310791}, {"text": "F1-measure", "start_pos": 128, "end_pos": 138, "type": "METRIC", "confidence": 0.9954065084457397}]}, {"text": "Moreover, this method is unsupervised and language-independent, which is applicable in the web era with enormous information.", "labels": [], "entities": []}, {"text": "The rest of the paper is organized as follows.", "labels": [], "entities": []}, {"text": "In Section 2, we introduce and discuss the related work in this area.", "labels": [], "entities": []}, {"text": "In Section 3, we give an overview of our method for keyphrase extraction.", "labels": [], "entities": [{"text": "keyphrase extraction", "start_pos": 52, "end_pos": 72, "type": "TASK", "confidence": 0.8626638054847717}]}, {"text": "From Section 4 to Section 7, the algorithm is described in detail.", "labels": [], "entities": []}, {"text": "Empirical experiment results are demonstrated in Section 8, followed by our conclusions and plans for future work in Section 9.", "labels": [], "entities": []}], "datasetContent": [{"text": "The dataset used in the experiments is a collection of scientific publication abstracts from the Inspec database and the corresponding manually assigned keyphrases . The dataset is used in both  and ().", "labels": [], "entities": [{"text": "Inspec database", "start_pos": 97, "end_pos": 112, "type": "DATASET", "confidence": 0.9584248661994934}]}, {"text": "Each abstract has two kinds of keyphrases: controlled keyphrases, restricted to a given dictionary, and uncontrolled keyphrases, freely assigned by the experts.", "labels": [], "entities": []}, {"text": "We use the uncontrolled keyphrases for evaluation as proposed in  and followed by).", "labels": [], "entities": []}, {"text": "As indicated in), in uncontrolled manually assigned keyphrases, only the ones that occur in the corresponding abstracts are considered in evaluation.", "labels": [], "entities": []}, {"text": "The extracted keyphrases of various methods and manually assigned keyphrases are compared after stemming.", "labels": [], "entities": []}, {"text": "In the experiments of , for her supervised method, Hulth splits a total of 2, 000 abstracts into 1, 000 for training, 500 for validation and 500 for test.", "labels": [], "entities": []}, {"text": "In (), due to the unsupervised method, only the test set was used for comparing the performance of TextRank and Hulth's method.", "labels": [], "entities": [{"text": "TextRank", "start_pos": 99, "end_pos": 107, "type": "DATASET", "confidence": 0.9190582633018494}]}, {"text": "The package could be accessed via http://http:// nlp.stanford.edu/software/tagger.shtml.", "labels": [], "entities": []}, {"text": "Many thanks to Anette Hulth for providing us the dataset.", "labels": [], "entities": [{"text": "Hulth", "start_pos": 22, "end_pos": 27, "type": "METRIC", "confidence": 0.6104130744934082}]}, {"text": "For computing Wikipedia-based relatedness, we use a snapshot on November 11, 2005 . The frequent word list used in the postprocessing step for filtering single-word phrases is also computed from Wikipedia.", "labels": [], "entities": []}, {"text": "In the experiments of this paper, we add the words that occur more than 1, 000 times in Wikipedia into the list.", "labels": [], "entities": []}, {"text": "The clustering-based method is completely unsupervised.", "labels": [], "entities": []}, {"text": "Here, we mainly run our method on test set and investigate the influence of relatedness measurements and clustering methods with different parameters.", "labels": [], "entities": []}, {"text": "Then we compare our method with two baseline methods: Hulth's method and TextRank.", "labels": [], "entities": [{"text": "TextRank", "start_pos": 73, "end_pos": 81, "type": "DATASET", "confidence": 0.8704856038093567}]}, {"text": "Finally, we analyze and discuss the performance of the method by taking the abstract of this paper as a demonstration.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Influence of relatedness measurements  for keyphrase extraction.  Parameters Precision Recall F1-measure  Cooccurrence-based Relatedness  w = 2  0.331  0.626  0.433  w = 4  0.333  0.621  0.434  w = 6  0.331  0.630  0.434  w = 8  0.330  0.623  0.432  w = 10  0.333  0.632  0.436  Wikipedia-based Relatedness  cos  0.348  0.655  0.455  euc  0.344  0.634  0.446  pmi p  0.344  0.621  0.443  pmi t  0.344  0.619  0.442  pmi c  0.350  0.660  0.457  ngd  0.343  0.620  0.442", "labels": [], "entities": [{"text": "keyphrase extraction", "start_pos": 53, "end_pos": 73, "type": "TASK", "confidence": 0.7211751490831375}, {"text": "Parameters Precision Recall F1-measure  Cooccurrence-based", "start_pos": 76, "end_pos": 134, "type": "METRIC", "confidence": 0.6965303897857666}]}, {"text": " Table 2: Influence of clustering methods for  keyphrase extraction.  Parameters Precision Recall F1-measure  Hierarchical Clustering  m = 1  4 n  0.365  0.369  0.367  m = 1  3 n  0.365  0.369  0.367  m = 1  2 n  0.351  0.562  0.432  m = 2  3 n  0.346  0.629  0.446  m = 4  5 n  0.340  0.657  0.448  Spectral Clustering  m = 1  4 n  0.385  0.409  0.397  m = 1  3 n  0.374  0.497  0.427  m = 1  2 n  0.374  0.497  0.427  m = 2  3 n  0.350  0.660  0.457  m = 4  5 n  0.340  0.679  0.453  Affinity Propagation  p = max  0.331  0.688  0.447  p = mean  0.433  0.070  0.121  p = median  0.422  0.078  0.132  p = min  0.419  0.059  0.103", "labels": [], "entities": [{"text": "keyphrase extraction", "start_pos": 47, "end_pos": 67, "type": "TASK", "confidence": 0.7313976734876633}, {"text": "Parameters Precision Recall F1-measure", "start_pos": 70, "end_pos": 108, "type": "METRIC", "confidence": 0.6563822329044342}, {"text": "Affinity Propagation  p", "start_pos": 486, "end_pos": 509, "type": "METRIC", "confidence": 0.9147895177205404}]}, {"text": " Table 3: Comparison results of Hulth's method, TextRank and our clustering-based method.  Assigned  Correct  Method  Total  Mean Total  Mean Precision Recall F1-measure  Hulth's  7,815 15.6  1,973 3.9  0.252  0.517 0.339  TextRank  6,784 13.7  2,116 4.2  0.312  0.431 0.362  HC  7,303 14.6  2,494 5.0  0.342  0.657 0.449  SC  7,158 14.3  2,505 5.0  0.350  0.660 0.457  AP  8,013 16.0  2,648 5.3  0.330  0.697 0.448", "labels": [], "entities": [{"text": "TextRank", "start_pos": 48, "end_pos": 56, "type": "DATASET", "confidence": 0.948503315448761}, {"text": "Total  Mean Total  Mean Precision Recall F1-measure  Hulth", "start_pos": 118, "end_pos": 176, "type": "METRIC", "confidence": 0.7613026909530163}, {"text": "AP", "start_pos": 370, "end_pos": 372, "type": "METRIC", "confidence": 0.8384779691696167}]}]}