{"title": [{"text": "Semi-supervised Speech Act Recognition in Emails and Forums", "labels": [], "entities": [{"text": "Semi-supervised Speech Act Recognition in Emails and Forums", "start_pos": 0, "end_pos": 59, "type": "TASK", "confidence": 0.721110325306654}]}], "abstractContent": [{"text": "In this paper, we present a semi-supervised method for automatic speech act recognition in email and forums.", "labels": [], "entities": [{"text": "speech act recognition", "start_pos": 65, "end_pos": 87, "type": "TASK", "confidence": 0.6065076490243276}]}, {"text": "The major challenge of this task is due to lack of labeled data in these two genres.", "labels": [], "entities": []}, {"text": "Our method leverages labeled data in the Switchboard-DAMSL and the Meeting Recorder Dialog Act database and applies simple domain adaptation techniques over a large amount of unlabeled email and forum data to address this problem.", "labels": [], "entities": [{"text": "Meeting Recorder Dialog Act database", "start_pos": 67, "end_pos": 103, "type": "DATASET", "confidence": 0.8806564807891846}]}, {"text": "Our method uses automatically extracted features such as phrases and dependency trees, called sub-tree features, for semi-supervised learning.", "labels": [], "entities": []}, {"text": "Empirical results demonstrate that our model is effective in email and forum speech act recognition.", "labels": [], "entities": [{"text": "forum speech act recognition", "start_pos": 71, "end_pos": 99, "type": "TASK", "confidence": 0.6065115332603455}]}], "introductionContent": [{"text": "Email and online forums are important social media.", "labels": [], "entities": []}, {"text": "For example, thousands of emails and posts are created daily in online communities, e.g., Usenet newsgroups or the TripAdvisor travel forum 1 , in which users interact with each other using emails/posts in complicated ways in discussion threads.", "labels": [], "entities": [{"text": "TripAdvisor travel forum 1", "start_pos": 115, "end_pos": 141, "type": "DATASET", "confidence": 0.8744934946298599}]}, {"text": "To uncover the rich interactions in these email exchanges and forum discussions, we propose to apply speech act recognition to email and forum threads.", "labels": [], "entities": [{"text": "speech act recognition", "start_pos": 101, "end_pos": 123, "type": "TASK", "confidence": 0.6508654256661733}]}, {"text": "Despite extensive studies of speech act recognition in many areas, developing speech act recognition for online forms of conversation is very challenging.", "labels": [], "entities": [{"text": "speech act recognition", "start_pos": 29, "end_pos": 51, "type": "TASK", "confidence": 0.6730232437451681}, {"text": "speech act recognition", "start_pos": 78, "end_pos": 100, "type": "TASK", "confidence": 0.6261624693870544}]}, {"text": "A major challenge is that emails and forums usually have no labeled data for training statistical speech act recognizers.", "labels": [], "entities": [{"text": "statistical speech act recognizers", "start_pos": 86, "end_pos": 120, "type": "TASK", "confidence": 0.6134547665715218}]}, {"text": "Fortunately, labeled speech act data are available in other domains (i.e., telephone and meeting conversations * This work was conducted during the author's internship at Microsoft Research Asia.", "labels": [], "entities": []}, {"text": "1 http://tripadvisor.com/ in this paper) and large unlabeled data sets can be collected from the Web.", "labels": [], "entities": []}, {"text": "Thus, we focus on the problem of how to accurately recognize speech acts in emails and forums by making maximum use of data from existing resources.", "labels": [], "entities": []}, {"text": "Recently, there are increasing interests in speech act recognition of online text-based conversations.", "labels": [], "entities": [{"text": "speech act recognition", "start_pos": 44, "end_pos": 66, "type": "TASK", "confidence": 0.6850829124450684}]}, {"text": "Analysis of speech acts for online chat and instant messages and have been studied in computer-mediated communication (CMC) and distance learning (.", "labels": [], "entities": []}, {"text": "In natural language processing, and used speech acts to capture the intentional focus of emails and discussion boards.", "labels": [], "entities": []}, {"text": "However, they assume that enough labeled data are available for developing speech act recognition models.", "labels": [], "entities": [{"text": "speech act recognition", "start_pos": 75, "end_pos": 97, "type": "TASK", "confidence": 0.7699843247731527}]}, {"text": "A main contribution of this paper is that we address the problem of learning speech act recognition in a semi-supervised way.", "labels": [], "entities": [{"text": "learning speech act recognition", "start_pos": 68, "end_pos": 99, "type": "TASK", "confidence": 0.6391008049249649}]}, {"text": "To our knowledge, this is the first use of semi-supervised speech act recognition in emails and online forums.", "labels": [], "entities": [{"text": "speech act recognition in emails and online forums", "start_pos": 59, "end_pos": 109, "type": "TASK", "confidence": 0.744201835244894}]}, {"text": "To do this, we make use of labeled data from spoken conversations (.", "labels": [], "entities": []}, {"text": "A second contribution is that our model learns subtree features that constitute discriminative patterns: for example, variable length n-grams and partial dependency structures.", "labels": [], "entities": []}, {"text": "Therefore, our model can capture both local features such as n-grams and non-local dependencies.", "labels": [], "entities": []}, {"text": "In this paper, we extend subtree pattern mining to the semi-supervised learning problem.", "labels": [], "entities": [{"text": "subtree pattern mining", "start_pos": 25, "end_pos": 47, "type": "TASK", "confidence": 0.7034793297449747}]}, {"text": "This paper is structured as follows.", "labels": [], "entities": []}, {"text": "Section 2 reviews prior work on speech act recognition and Section 3 presents the problem statement and our data sets.", "labels": [], "entities": [{"text": "speech act recognition", "start_pos": 32, "end_pos": 54, "type": "TASK", "confidence": 0.8027828534444174}]}, {"text": "Section 4 describes a supervised method of learning subtree features that shows the effectiveness of subtree features on labeled data sets.", "labels": [], "entities": []}, {"text": "Section 5 proposes semi-supervised learning techniques for speech act recognition and Section 6 demonstrates our method applied to email and on-line forum thread data.", "labels": [], "entities": [{"text": "speech act recognition", "start_pos": 59, "end_pos": 81, "type": "TASK", "confidence": 0.7985376119613647}]}, {"text": "Section 7 concludes this paper with future work.", "labels": [], "entities": []}], "datasetContent": [{"text": "We verified the effectiveness of using subtree features on the SWBD and MRDA data sets.", "labels": [], "entities": [{"text": "SWBD and MRDA data sets", "start_pos": 63, "end_pos": 86, "type": "DATASET", "confidence": 0.760260009765625}]}, {"text": "For boosting learning, one typically assumes \u03b1 i = 1.", "labels": [], "entities": []}, {"text": "In addition, the number of iterations, which relates to the number of patterns, was determined by a development set.", "labels": [], "entities": []}, {"text": "We also used a one-vs.-all strategy for the multi-class problem.", "labels": [], "entities": []}, {"text": "Precision and recall were computed and combined into micro-and macro-averaged F 1 scores.", "labels": [], "entities": [{"text": "Precision", "start_pos": 0, "end_pos": 9, "type": "METRIC", "confidence": 0.9930156469345093}, {"text": "recall", "start_pos": 14, "end_pos": 20, "type": "METRIC", "confidence": 0.9991087317466736}, {"text": "F 1", "start_pos": 78, "end_pos": 81, "type": "METRIC", "confidence": 0.9153829216957092}]}, {"text": "The significance of our results was evaluated using the McNemar paired test, which is based on individual labeling decisions to compare the correctness of two models.", "labels": [], "entities": [{"text": "McNemar paired test", "start_pos": 56, "end_pos": 75, "type": "METRIC", "confidence": 0.6081271171569824}]}, {"text": "All experiments were implemented in C++ and executed in Windows XP on a PC with a Dual 2.1 GHz Intel Core2 processor and 2.0 Gbyte of main memory.", "labels": [], "entities": []}, {"text": "We show that use of subtree features is effective to solve the supervised speech act recognition problem.", "labels": [], "entities": [{"text": "supervised speech act recognition", "start_pos": 63, "end_pos": 96, "type": "TASK", "confidence": 0.5930873453617096}]}, {"text": "We also compared our model with the state-of-the-art maximum entropy classifier (MAXENT).", "labels": [], "entities": []}, {"text": "We used bag-of-words, bigram and trigram features for MAXENT, which modeled 702k (SWBD) and 460k (MRDA) parameters (i.e., patterns), and produced micro-averaged F 1 scores of 92.76 (macro-averaged F 1 = 63.54) for SWBD and 82.48 (macro-averaged F 1 = 57.19) for MRDA.", "labels": [], "entities": [{"text": "F 1 scores", "start_pos": 161, "end_pos": 171, "type": "METRIC", "confidence": 0.9060218731562296}, {"text": "MRDA", "start_pos": 262, "end_pos": 266, "type": "TASK", "confidence": 0.7004384398460388}]}, {"text": "In contrast, our method generated approximately 4k to 5k patterns on average with similar or greater F 1 scores; hence, compared to MAXENT, our model requires fewer calculations and is just as accurate.", "labels": [], "entities": [{"text": "F 1 scores", "start_pos": 101, "end_pos": 111, "type": "METRIC", "confidence": 0.9710899988810221}]}, {"text": "The n-gram model (NGRAM) performed significantly better than the bag-of-words model (McNemar test; p < 0.001).", "labels": [], "entities": []}, {"text": "Unlike MAX-ENT, NGRAM automatically selects a relevant set of variable length n-gram features (i.e., phrase features).", "labels": [], "entities": []}, {"text": "To this set, we separately added two syntax type features, part-of-speech tag n-gram (POSTAG) and dependency parse tree (DEPTREE) automatically parsed by Minipar 8 , and one discourse type feature, speaker n-gram (SPEAKER).", "labels": [], "entities": [{"text": "dependency parse tree (DEPTREE)", "start_pos": 98, "end_pos": 129, "type": "METRIC", "confidence": 0.721763034661611}]}, {"text": "Although some micro-averaged F 1 are not statistically significant between the original NGRAM and the models that include POSTAG, DEPTREE or SPEAKER, macro-averaged F 1 values indicate that minor classes can take advantage of other structures.", "labels": [], "entities": [{"text": "micro-averaged F 1", "start_pos": 14, "end_pos": 32, "type": "METRIC", "confidence": 0.6740676760673523}, {"text": "NGRAM", "start_pos": 88, "end_pos": 93, "type": "DATASET", "confidence": 0.9268872737884521}, {"text": "DEPTREE", "start_pos": 130, "end_pos": 137, "type": "METRIC", "confidence": 0.7699524164199829}]}, {"text": "For example, in the result of SWBD, DEPTREE and SPEAKER models help to predict uncertain responses (U), whereas NGRAM and POSTAG cannot do this.", "labels": [], "entities": [{"text": "DEPTREE", "start_pos": 36, "end_pos": 43, "type": "METRIC", "confidence": 0.9286870360374451}]}], "tableCaptions": [{"text": " Table 2: Number of sentences in labeled and unlabeled data  Set  SWBD MRDA  Training  96,553 50,865  Development 12,299  8,366  Evaluation  24,264 10,492", "labels": [], "entities": [{"text": "SWBD MRDA  Training  96,553", "start_pos": 66, "end_pos": 93, "type": "DATASET", "confidence": 0.8029186427593231}]}]}