{"title": [{"text": "Review Sentiment Scoring via a Parse-and-Paraphrase Paradigm", "labels": [], "entities": [{"text": "Sentiment Scoring", "start_pos": 7, "end_pos": 24, "type": "TASK", "confidence": 0.9495330154895782}]}], "abstractContent": [{"text": "This paper presents a parse-and-paraphrase paradigm to assess the degrees of sentiment for product reviews.", "labels": [], "entities": []}, {"text": "Sentiment identification has been well studied; however, most previous work provides binary polarities only (positive and negative), and the polarity of sentiment is simply reversed when a negation is detected.", "labels": [], "entities": [{"text": "Sentiment identification", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.9784390926361084}]}, {"text": "The extraction of lexical features such as uni-gram/bigram also complicates the sentiment classification task, as linguistic structure such as implicit long-distance dependency is often disregarded.", "labels": [], "entities": [{"text": "sentiment classification", "start_pos": 80, "end_pos": 104, "type": "TASK", "confidence": 0.9643438458442688}]}, {"text": "In this paper, we propose an approach to extracting adverb-adjective-noun phrases based on clause structure obtained by parsing sentences into a hierarchical representation.", "labels": [], "entities": []}, {"text": "We also propose a robust general solution for modeling the contribution of adver-bials and negation to the score for degree of sentiment.", "labels": [], "entities": []}, {"text": "In an application involving extracting aspect-based pros and cons from restaurant reviews, we obtained a 45% relative improvement in recall through the use of parsing methods , while also improving precision.", "labels": [], "entities": [{"text": "extracting aspect-based pros and cons from restaurant reviews", "start_pos": 28, "end_pos": 89, "type": "TASK", "confidence": 0.7346450053155422}, {"text": "recall", "start_pos": 133, "end_pos": 139, "type": "METRIC", "confidence": 0.9993233680725098}, {"text": "precision", "start_pos": 198, "end_pos": 207, "type": "METRIC", "confidence": 0.9985935091972351}]}], "introductionContent": [{"text": "Online product reviews have provided an extensive collection of free-style texts as well as product ratings prepared by general users, which in return provide grassroots contributions to users interested in a particular product or service as assistance.", "labels": [], "entities": []}, {"text": "Yet, valuable as they are, free-style reviews contain much noisy data and are tedious to read through in order to reach an overall conclusion.", "labels": [], "entities": []}, {"text": "Thus, we conducted this study to automatically process and evaluate product reviews in order to generate both numerical evaluation and textual summaries of users' opinions, with the ultimate goal of adding value to real systems such as a restaurant-guide dialogue system.", "labels": [], "entities": []}, {"text": "Sentiment summarization has been well studied in the past decade;.", "labels": [], "entities": [{"text": "Sentiment summarization", "start_pos": 0, "end_pos": 23, "type": "TASK", "confidence": 0.9494627714157104}]}, {"text": "The polarity of users' sentiments in each segment of review texts is extracted, and the polarities of individual sentiments are aggregated among all the sentences/segments of texts to give a numerical scaling on sentiment orientation.", "labels": [], "entities": []}, {"text": "Most of the work done for sentiment analysis so far has employed shallow parsing features such as part-of-speech tagging.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 26, "end_pos": 44, "type": "TASK", "confidence": 0.9782359302043915}, {"text": "part-of-speech tagging", "start_pos": 98, "end_pos": 120, "type": "TASK", "confidence": 0.7044628262519836}]}, {"text": "Frequent adjectives and nouns/noun phrases are extracted as opinion words and representative product features.", "labels": [], "entities": []}, {"text": "However, the linguistic structure of the sentence is usually not taken into consideration.", "labels": [], "entities": []}, {"text": "High level linguistic features, if well utilized and accurately extracted, can provide much insight into the semantic meaning of user opinions and contribute to the task of sentiment identification.", "labels": [], "entities": [{"text": "sentiment identification", "start_pos": 173, "end_pos": 197, "type": "TASK", "confidence": 0.9631824791431427}]}, {"text": "Furthermore, in addition to adjectives and nouns, adverbials and negation also play an important role in determining the degree of the orientation level.", "labels": [], "entities": []}, {"text": "For example, \"very good\" and \"good\" certainly express different degrees of positive sentiment.", "labels": [], "entities": []}, {"text": "Also, in previous studies, when negative expressions are identified, the polarity of sentiment in the associated segment of text is simply reversed.", "labels": [], "entities": []}, {"text": "However, semantic expressions are quite different from the absolute opposite values in mathematics.", "labels": [], "entities": []}, {"text": "For example, \"not bad\" does not express the opposite meaning of \"bad\", which would be highly positive.", "labels": [], "entities": []}, {"text": "Simply reversing the polarity of sentiment on the appearance of negations may result in inaccurate interpretation of sentiment expressions.", "labels": [], "entities": []}, {"text": "Thus, a system which attempts to quantify sentiment while ignoring adverbials is missing a significant component of the sentiment score, especially if the adverbial is a negative word.", "labels": [], "entities": []}, {"text": "Another challenging aspect of negation is proper scoping of the negative reference over the right constituent, which we argue, can be handled quite well with careful linguistic analysis.", "labels": [], "entities": [{"text": "negation", "start_pos": 30, "end_pos": 38, "type": "TASK", "confidence": 0.9833926558494568}]}, {"text": "Take the sentence \"I don't think the place is very clean\" as example.", "labels": [], "entities": []}, {"text": "A linguistic approach associating long-distance elements with semantic relations can identify that the negation \"not\" scopes over the complement clause, thus extracting \"not very clean\" instead of \"very clean\".", "labels": [], "entities": []}, {"text": "Our goal in modeling adverbials is to investigate whether a simple linear correction model can capture the polarity contribution of all adverbials.", "labels": [], "entities": []}, {"text": "Furthermore, is it also appropriate to adjust for multiple adverbs, including negation, via a linear additive model?", "labels": [], "entities": []}, {"text": "I.e., can \"not very good\" be modeled as not(very(good))?", "labels": [], "entities": []}, {"text": "The fact that \"not very good\" seems to be less negative than \"not good\" suggests that such an algorithm might work well.", "labels": [], "entities": []}, {"text": "From these derivations we have developed a model which treats negations in the exact same way as modifying adverbs, via an accumulative linear offset model.", "labels": [], "entities": []}, {"text": "This yields a very generic and straightforward solution to modeling the strength of sentiment expression.", "labels": [], "entities": [{"text": "sentiment expression", "start_pos": 84, "end_pos": 104, "type": "TASK", "confidence": 0.7892221510410309}]}, {"text": "In this paper we utilize a parse-and-paraphrase paradigm to identify semantically related phrases in review texts, taking quantifiers (e.g., modifying adverbs) and qualifiers (e.g., negations) into special consideration.", "labels": [], "entities": []}, {"text": "The approach makes use of a lexicalized probabilistic syntactic grammar to identify and extract sets of adverb-adjectivenoun phrases that match review-related patterns.", "labels": [], "entities": []}, {"text": "Such patterns are constructed based on wellformed linguistic structure; thus, relevant phrases can be extracted reliably.", "labels": [], "entities": []}, {"text": "We also propose a cumulative linear offset model to calculate the degree of sentiment for joint adjectives and quantifiers/qualifiers.", "labels": [], "entities": []}, {"text": "The proposed sentiment prediction model takes modifying adverbs and negations as universal scales on strength of sentiment, and conducts cumulative calculation on the degree of sentiment for the associated adjective.", "labels": [], "entities": [{"text": "sentiment prediction", "start_pos": 13, "end_pos": 33, "type": "TASK", "confidence": 0.8916814625263214}]}, {"text": "With this model, we can provide not only qualitative textual summarization such as \"good food\" and \"bad service\", but also a numerical scoring of sentiment, i.e., \"how good the food is\" and \"how bad the service is.\"", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section we present a systematic evaluation of the proposed approaches conducted on real data.", "labels": [], "entities": []}, {"text": "We crawled a data collection of 137,569 reviews on 24,043 restaurants in 9 cities in the U.S. from an online restaurant evaluation website . Most of the reviews have both pros/cons and free-style text.", "labels": [], "entities": []}, {"text": "For the purpose of evaluation, we take those reviews containing pros/cons as the experimental set, which is 72.7% (99,147 reviews) of the original set.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2. Experimental results of topic extraction by  the NB baseline, the proposed LING approach and  a combined system (COMB).  No Clustering  NB  LING  COMB  Recall  39.6%  44.2%  48.1%  Precision  60.2%  60.0%  59.8%  With Clustering  NB  LING  COMB  Recall  44.4%  57.0%  61.9%  Precision  56.8%  61.1%  60.8%", "labels": [], "entities": [{"text": "topic extraction", "start_pos": 34, "end_pos": 50, "type": "TASK", "confidence": 0.7554151713848114}, {"text": "NB baseline", "start_pos": 59, "end_pos": 70, "type": "DATASET", "confidence": 0.8730676770210266}]}, {"text": " Table 3. Sentiment scoring for selected adjectives.  Adjective  Rating  Adjective  Rating  Excellent  5.0  Awesome  4.8  Easy  4.1  Great  4.4  Good  3.9  Limited  3.4  Inattentive  2.75  Overpriced  2.3  Rude  1.69  Horrible  1.3", "labels": [], "entities": []}, {"text": " Table 4. Strength scoring for selected adverbs.  Adverb  Rating  Adverb  Rating  Super  0.58  Fairly  0.13  Extremely  0.54  Pretty  0.07  Incredibly  0.49  A little  -0.65  Very  0.44  A bit  -0.83  Really  0.39  Not  -3.10", "labels": [], "entities": []}, {"text": " Table 5. Comparison of sentiment scoring between  the proposed approach and two annotation sets.  Annotation 1 Annotation 2  Mean distance  0.46  0.43  Kappa agreement  0.55  0.60", "labels": [], "entities": [{"text": "Mean distance  0.46  0.43  Kappa agreement  0.55  0.60", "start_pos": 126, "end_pos": 180, "type": "METRIC", "confidence": 0.8979280889034271}]}, {"text": " Table 6. Experimental results of topic extraction  based on sentiment polarity matching.  No Clustering  NB  LING  COMB  Recall  34.5%  38.9%  42.2%  Precision  53.8%  54.0%  53.3%  With Clustering  NB  LING  COMB  Recall  37.4%  49.7%  54.1%  Precision  48.5%  52.9%  51.4%", "labels": [], "entities": [{"text": "topic extraction", "start_pos": 34, "end_pos": 50, "type": "TASK", "confidence": 0.8163400888442993}, {"text": "sentiment polarity matching", "start_pos": 61, "end_pos": 88, "type": "TASK", "confidence": 0.7340302368005117}]}]}