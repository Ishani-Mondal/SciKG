{"title": [{"text": "Web-Scale Distributional Similarity and Entity Set Expansion", "labels": [], "entities": []}], "abstractContent": [{"text": "Computing the pairwise semantic similarity between all words on the Web is a compu-tationally challenging task.", "labels": [], "entities": []}, {"text": "Parallelization and optimizations are necessary.", "labels": [], "entities": []}, {"text": "We propose a highly scalable implementation based on distributional similarity, implemented in the MapReduce framework and deployed over a 200 billion word crawl of the Web.", "labels": [], "entities": []}, {"text": "The pairwise similarity between 500 million terms is computed in 50 hours using 200 quad-core nodes.", "labels": [], "entities": []}, {"text": "We apply the learned similarity matrix to the task of automatic set expansion and present a large empirical study to quantify the effect on expansion performance of corpus size, corpus quality, seed composition and seed size.", "labels": [], "entities": [{"text": "automatic set expansion", "start_pos": 54, "end_pos": 77, "type": "TASK", "confidence": 0.6694292426109314}]}, {"text": "We make publican experimental testbed for set expansion analysis that includes a large collection of diverse entity sets extracted from Wikipedia.", "labels": [], "entities": [{"text": "set expansion analysis", "start_pos": 42, "end_pos": 64, "type": "TASK", "confidence": 0.807292511065801}]}], "introductionContent": [{"text": "Computing the semantic similarity between terms has many applications in NLP including word classification (, word sense disambiguation, contextspelling correction, fact extraction (), semantic role labeling, and applications in IR such as query expansion) and textual advertising ().", "labels": [], "entities": [{"text": "word classification", "start_pos": 87, "end_pos": 106, "type": "TASK", "confidence": 0.7990474104881287}, {"text": "word sense disambiguation", "start_pos": 110, "end_pos": 135, "type": "TASK", "confidence": 0.6400942305723826}, {"text": "contextspelling correction", "start_pos": 137, "end_pos": 163, "type": "TASK", "confidence": 0.7070009559392929}, {"text": "fact extraction", "start_pos": 165, "end_pos": 180, "type": "TASK", "confidence": 0.7068427056074142}, {"text": "semantic role labeling", "start_pos": 185, "end_pos": 207, "type": "TASK", "confidence": 0.7064993580182394}, {"text": "IR", "start_pos": 229, "end_pos": 231, "type": "TASK", "confidence": 0.9467418193817139}, {"text": "query expansion", "start_pos": 240, "end_pos": 255, "type": "TASK", "confidence": 0.6511524766683578}]}, {"text": "For commercial engines such as Yahoo! and Google, creating lists of named entities found on the Web is critical for query analysis, document categorization, and ad matching.", "labels": [], "entities": [{"text": "query analysis", "start_pos": 116, "end_pos": 130, "type": "TASK", "confidence": 0.7983883321285248}, {"text": "ad matching", "start_pos": 161, "end_pos": 172, "type": "TASK", "confidence": 0.7227205783128738}]}, {"text": "Computing term similarity is typically done by comparing cooccurrence vectors between all pairs of terms (.", "labels": [], "entities": [{"text": "Computing term similarity", "start_pos": 0, "end_pos": 25, "type": "TASK", "confidence": 0.6172923942406973}]}, {"text": "Scaling this task to the Web requires parallelization and optimizations.", "labels": [], "entities": []}, {"text": "In this paper, we propose a large-scale term similarity algorithm, based on distributional similarity, implemented in the MapReduce framework and deployed over a 200 billion word crawl of the Web.", "labels": [], "entities": []}, {"text": "The resulting similarity matrix between 500 million terms is applied to the task of expanding lists of named entities (automatic set expansion).", "labels": [], "entities": []}, {"text": "We provide a detailed empirical analysis of the discovered named entities and quantify the effect on expansion accuracy of corpus size, corpus quality, seed composition, and seed set size.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 111, "end_pos": 119, "type": "METRIC", "confidence": 0.9891229271888733}]}], "datasetContent": [{"text": "In this section, we describe our methodology for evaluating Web-scale set expansion.", "labels": [], "entities": [{"text": "Web-scale set expansion", "start_pos": 60, "end_pos": 83, "type": "TASK", "confidence": 0.6664113203684489}]}, {"text": "Our goal is to study the performance gains onset expansion using our Web-scale term similarity algorithm from Section 3.", "labels": [], "entities": []}, {"text": "We present a large empirical study quantifying the importance of corpus and seeds on expansion accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 95, "end_pos": 103, "type": "METRIC", "confidence": 0.9733933806419373}]}, {"text": "We extracted statistics to build our model from Section 3 using four different corpora, outlined in.", "labels": [], "entities": []}, {"text": "The Wikipedia corpus consists of a snapshot of the English articles in December 2008 . The Web100 corpus consists of an extraction from a large crawl of the Web, from Yahoo!, of over 600 million English webpages.", "labels": [], "entities": [{"text": "Wikipedia corpus", "start_pos": 4, "end_pos": 20, "type": "DATASET", "confidence": 0.9517285227775574}, {"text": "Web100 corpus", "start_pos": 91, "end_pos": 104, "type": "DATASET", "confidence": 0.8766748011112213}]}, {"text": "For each crawled document, we removed paragraphs containing fewer than 50 tokens (as a rough approximation of the narrative part of a webpage) and then removed all duplicate sentences.", "labels": [], "entities": []}, {"text": "The resulting corpus consists of over 200 billion words.", "labels": [], "entities": []}, {"text": "The Web020 corpus is a random sample of 1/5 th of the sentences in Web100 whereas Web004 is a random sample of 1/25 th of Web100.", "labels": [], "entities": [{"text": "Web020 corpus", "start_pos": 4, "end_pos": 17, "type": "DATASET", "confidence": 0.9611570835113525}, {"text": "Web004", "start_pos": 82, "end_pos": 88, "type": "DATASET", "confidence": 0.9207836389541626}]}, {"text": "For each corpus, we tagged and chunked each sentence as described in Section 3.", "labels": [], "entities": []}, {"text": "We then computed the similarity between all noun phrase chunks using the model of Section 3.1.", "labels": [], "entities": [{"text": "similarity", "start_pos": 21, "end_pos": 31, "type": "METRIC", "confidence": 0.9681376814842224}]}], "tableCaptions": [{"text": " Table 1. Definitions for f 0 , f 1 , f 2 , and f 3 for commonly used  similarity scores.", "labels": [], "entities": [{"text": "similarity scores", "start_pos": 71, "end_pos": 88, "type": "METRIC", "confidence": 0.9510927200317383}]}, {"text": " Table 2. Corpora used to build our expansion models.", "labels": [], "entities": []}, {"text": " Table 3. Corpora analysis: R-precision and Precision at var- ious ranks. 95% confidence bounds are all below 0.005  \u2020 .", "labels": [], "entities": [{"text": "R-precision", "start_pos": 28, "end_pos": 39, "type": "METRIC", "confidence": 0.9632259607315063}, {"text": "Precision", "start_pos": 44, "end_pos": 53, "type": "METRIC", "confidence": 0.9989639520645142}]}, {"text": " Table 3. Corpora analysis: R-precision and Precision at var- ious ranks. 95% confidence bounds are all below 0.005  \u2020 .", "labels": [], "entities": [{"text": "R-precision", "start_pos": 28, "end_pos": 39, "type": "METRIC", "confidence": 0.9632259607315063}, {"text": "Precision", "start_pos": 44, "end_pos": 53, "type": "METRIC", "confidence": 0.9989639520645142}]}]}