{"title": [{"text": "Phrase Dependency Parsing for Opinion Mining", "labels": [], "entities": [{"text": "Phrase Dependency Parsing", "start_pos": 0, "end_pos": 25, "type": "TASK", "confidence": 0.7877399722735087}]}], "abstractContent": [{"text": "In this paper, we present a novel approach for mining opinions from product reviews, where it converts opinion mining task to identify product features, expressions of opinions and relations between them.", "labels": [], "entities": [{"text": "opinion mining", "start_pos": 103, "end_pos": 117, "type": "TASK", "confidence": 0.7602347731590271}]}, {"text": "By taking advantage of the observation that a lot of product features are phrases, a concept of phrase dependency parsing is introduced , which extends traditional dependency parsing to phrase level.", "labels": [], "entities": [{"text": "phrase dependency parsing", "start_pos": 96, "end_pos": 121, "type": "TASK", "confidence": 0.729907770951589}, {"text": "dependency parsing", "start_pos": 164, "end_pos": 182, "type": "TASK", "confidence": 0.7675796151161194}]}, {"text": "This concept is then implemented for extracting relations between product features and expressions of opinions.", "labels": [], "entities": []}, {"text": "Experimental evaluations show that the mining task can benefit from phrase dependency parsing.", "labels": [], "entities": [{"text": "phrase dependency parsing", "start_pos": 68, "end_pos": 93, "type": "TASK", "confidence": 0.8154129385948181}]}], "introductionContent": [{"text": "As millions of users contribute rich information to the Internet everyday, an enormous number of product reviews are freely written in blog pages, Web forums and other consumer-generated mediums (CGMs).", "labels": [], "entities": []}, {"text": "This vast richness of content becomes increasingly important information source for collecting and tracking customer opinions.", "labels": [], "entities": [{"text": "collecting and tracking customer opinions", "start_pos": 84, "end_pos": 125, "type": "TASK", "confidence": 0.707857894897461}]}, {"text": "Retrieving this information and analyzing this content are impossible tasks if they were to be manually done.", "labels": [], "entities": []}, {"text": "However, advances in machine learning and natural language processing present us with a unique opportunity to automate the decoding of consumers' opinions from online reviews.", "labels": [], "entities": [{"text": "decoding of consumers' opinions from online reviews", "start_pos": 123, "end_pos": 174, "type": "TASK", "confidence": 0.8217994911330087}]}, {"text": "Previous works on mining opinions can be divided into two directions: sentiment classification and sentiment related information extraction.", "labels": [], "entities": [{"text": "sentiment classification", "start_pos": 70, "end_pos": 94, "type": "TASK", "confidence": 0.9171121418476105}, {"text": "sentiment related information extraction", "start_pos": 99, "end_pos": 139, "type": "TASK", "confidence": 0.7066076397895813}]}, {"text": "The former is a task of identifying positive and negative sentiments from a text which can be a passage, a sentence, a phrase and even a word).", "labels": [], "entities": []}, {"text": "The latter focuses on extracting the elements composing a sentiment text.", "labels": [], "entities": []}, {"text": "The elements include source of opinions who expresses an opinion (); target of opinions which is a receptor of an opinion (; opinion expression which delivers an opinion (.", "labels": [], "entities": []}, {"text": "Some researchers refer this information extraction task as opinion extraction or opinion mining.", "labels": [], "entities": [{"text": "information extraction task", "start_pos": 28, "end_pos": 55, "type": "TASK", "confidence": 0.8293536305427551}, {"text": "opinion extraction", "start_pos": 59, "end_pos": 77, "type": "TASK", "confidence": 0.8450569212436676}, {"text": "opinion mining", "start_pos": 81, "end_pos": 95, "type": "TASK", "confidence": 0.7847316861152649}]}, {"text": "Comparing with the former one, opinion mining usually produces richer information.", "labels": [], "entities": [{"text": "opinion mining", "start_pos": 31, "end_pos": 45, "type": "TASK", "confidence": 0.863363116979599}]}, {"text": "In this paper, we define an opinion unit as a triple consisting of a product feature, an expression of opinion, and an emotional attitude(positive or negative).", "labels": [], "entities": []}, {"text": "We use this definition as the basis for our opinion mining task.", "labels": [], "entities": [{"text": "opinion mining", "start_pos": 44, "end_pos": 58, "type": "TASK", "confidence": 0.7962557971477509}]}, {"text": "Since a product review may refer more than one product feature and express different opinions on each of them, the relation extraction is an important subtask of opinion mining.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 115, "end_pos": 134, "type": "TASK", "confidence": 0.748480349779129}, {"text": "opinion mining", "start_pos": 162, "end_pos": 176, "type": "TASK", "confidence": 0.731431856751442}]}, {"text": "Consider the following sentences: The phrases underlined are the product features, marked with square brackets are opinion expressions.", "labels": [], "entities": []}, {"text": "Product features and opinion expressions with identical superscript compose a relation.", "labels": [], "entities": []}, {"text": "For the first sentence, an opinion relation exists between \"the Canon SD500\" and \"recommend\", but not between \"picture\" and \"recommend\".", "labels": [], "entities": [{"text": "Canon SD500", "start_pos": 64, "end_pos": 75, "type": "DATASET", "confidence": 0.9268481731414795}]}, {"text": "The example shows that more than one relation may appear in a sentence, and the correct relations are not simple Cartesian product of opinion expressions and product features.", "labels": [], "entities": []}, {"text": "Simple inspection of the data reveals that product features usually contain more than one word, such as \"LCD screen\", \"image color\", \"Canon PowerShot SD500\", and soon.", "labels": [], "entities": [{"text": "Canon PowerShot SD500", "start_pos": 134, "end_pos": 155, "type": "DATASET", "confidence": 0.9262317816416422}]}, {"text": "An incomplete product feature will confuse the successive analysis.", "labels": [], "entities": []}, {"text": "For example, in passage \"Image color is dis-appointed\", the negative sentiment becomes obscure if only \"image\" or \"color\" is picked out.", "labels": [], "entities": []}, {"text": "Since a product feature could not be represented by a single word, dependency parsing might not be the best approach here unfortunately, which provides dependency relations only between words.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 67, "end_pos": 85, "type": "TASK", "confidence": 0.8585802912712097}]}, {"text": "Previous works on relation extraction usually use the headword to represent the whole phrase and extract features from the word level dependency tree.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 18, "end_pos": 37, "type": "TASK", "confidence": 0.8872050344944}]}, {"text": "This solution is problematic because the information provided by the phrase itself cannot be used by this kind of methods.", "labels": [], "entities": []}, {"text": "And, experimental results show that relation extraction task can benefit from dependencies within a phrase.", "labels": [], "entities": [{"text": "relation extraction task", "start_pos": 36, "end_pos": 60, "type": "TASK", "confidence": 0.889233668645223}]}, {"text": "To solve this issue, we introduce the concept of phrase dependency parsing and propose an approach to construct it.", "labels": [], "entities": [{"text": "phrase dependency parsing", "start_pos": 49, "end_pos": 74, "type": "TASK", "confidence": 0.755429208278656}]}, {"text": "Phrase dependency parsing segments an input sentence into \"phrases\" and links segments with directed arcs.", "labels": [], "entities": [{"text": "Phrase dependency parsing", "start_pos": 0, "end_pos": 25, "type": "TASK", "confidence": 0.8493364850680033}]}, {"text": "The parsing focuses on the \"phrases\" and the relations between them, rather than on the single words inside each phrase.", "labels": [], "entities": []}, {"text": "Because phrase dependency parsing naturally divides the dependencies into local and global, a novel tree kernel method has also been proposed.", "labels": [], "entities": [{"text": "phrase dependency parsing", "start_pos": 8, "end_pos": 33, "type": "TASK", "confidence": 0.7994821667671204}]}, {"text": "The remaining parts of this paper are organized as follows: In Section 2 we discuss our phrase dependency parsing and our approach.", "labels": [], "entities": [{"text": "phrase dependency parsing", "start_pos": 88, "end_pos": 113, "type": "TASK", "confidence": 0.7798264026641846}]}, {"text": "In Section 3, experiments are given to show the improvements.", "labels": [], "entities": []}, {"text": "In Section 4, we present related work and Section 5 concludes the paper.", "labels": [], "entities": []}, {"text": "gives the architecture overview for our approach, which performs the opinion mining task in three main steps: (1) constructing phrase dependency tree from results of chunking and dependency parsing; (2) extracting candidate product features and candidate opinion expressions; (3) extracting relations between product features and opinion expressions.", "labels": [], "entities": [{"text": "opinion mining", "start_pos": 69, "end_pos": 83, "type": "TASK", "confidence": 0.7299727946519852}, {"text": "dependency parsing", "start_pos": 179, "end_pos": 197, "type": "TASK", "confidence": 0.7657099068164825}]}], "datasetContent": [{"text": "In this section, we describe the annotated corpus and experiment configurations including baseline methods and our results on in-domain and crossdomain.", "labels": [], "entities": []}, {"text": "In order to compare with state-of-the-art results, we also evaluated the following methods.", "labels": [], "entities": []}, {"text": "1. Adjacent method extracts relations between a product feature and its nearest opinion expression, which is also used in ().", "labels": [], "entities": []}, {"text": "To compare with tree kernel based 1) The syntactic category of the tree node (e.g. NP, VP, PP, ADJP).", "labels": [], "entities": []}, {"text": "2) Whether it is an opinion expression node 3) Whether it is a product future node.", "labels": [], "entities": []}, {"text": "Features for similarity function 1) The syntactic category of the tree node (e.g. NP, VP, PP, ADJP).", "labels": [], "entities": []}, {"text": "2) POS-Tag of the headword of node's internal phrases.", "labels": [], "entities": [{"text": "POS-Tag", "start_pos": 3, "end_pos": 10, "type": "METRIC", "confidence": 0.9641152620315552}]}, {"text": "3) The type of phrase dependency edge linking to node's parent.", "labels": [], "entities": [{"text": "phrase dependency edge linking to node's parent", "start_pos": 15, "end_pos": 62, "type": "TASK", "confidence": 0.708198145031929}]}, {"text": "4) Feature 2) for the node's parent 5) Feature 3) for the node's parent approaches, we evaluated an SVM 1 result with a set of manually selected features, which are also used in (.", "labels": [], "entities": []}, {"text": "3. SVM-2 is designed to compare the effectiveness of cross-domain performances.", "labels": [], "entities": []}, {"text": "The features used are simple bag of words and POS-Tags between opinion expressions and product features.", "labels": [], "entities": []}, {"text": "4. SVM-WTree uses head words of opinion expressions and product features in the word-level dependency tree, as the previous works in information extraction.", "labels": [], "entities": [{"text": "information extraction", "start_pos": 133, "end_pos": 155, "type": "TASK", "confidence": 0.7678717970848083}]}, {"text": "Then conducts tree kernel proposed by.", "labels": [], "entities": []}, {"text": "5. SVM-PTree denotes the results of our treekernel based SVM, which is described in the Section 2.3.", "labels": [], "entities": []}, {"text": "Stanford parser () and Sundance () are used as lexical dependency parser and shallow parser.", "labels": [], "entities": []}, {"text": "The features in match function and similarity function are shown in.", "labels": [], "entities": [{"text": "similarity function", "start_pos": 35, "end_pos": 54, "type": "METRIC", "confidence": 0.9770667254924774}]}, {"text": "6. OERight is the result of SVM-PTree with correct opinion expressions.", "labels": [], "entities": [{"text": "OERight", "start_pos": 3, "end_pos": 10, "type": "METRIC", "confidence": 0.9955602884292603}]}, {"text": "7. PFRight is the result of SVM-PTree with correct product features.", "labels": [], "entities": []}, {"text": "shows the performances of different relation extraction methods with in-domain data.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 36, "end_pos": 55, "type": "TASK", "confidence": 0.7975432872772217}]}, {"text": "For each domain, we conducted 5-fold cross validation.", "labels": [], "entities": []}, {"text": "shows the performances of the extraction methods on cross-domain data.", "labels": [], "entities": []}, {"text": "We use the digital camera and cellphone domain as training set.", "labels": [], "entities": []}, {"text": "The other domains are used as testing set.", "labels": [], "entities": []}, {"text": "presents different methods' results in five domains.", "labels": [], "entities": []}, {"text": "We observe that the three learning based methods(SVM-1, SVM-WTree, SVM-PTree) perform better than the Adjacent baseline in the first three domains.", "labels": [], "entities": []}, {"text": "However, in other domains, directly adjacent method is better than the learning based methods.", "labels": [], "entities": []}, {"text": "The main difference between the first three domains and the last two domains is the size of data.", "labels": [], "entities": []}, {"text": "It implies that the simple Adjacent method is also competent when the training set is small.", "labels": [], "entities": []}, {"text": "A further inspection into the result of first 3 domains, we can also conclude that: 1) Tree kernels(SVM-WTree and SVM-PTree) are better than Adjacent, SVM-1 and SVM-2 in all domains.", "labels": [], "entities": []}, {"text": "It proofs that the dependency tree is important in the opinion relation extraction.", "labels": [], "entities": [{"text": "opinion relation extraction", "start_pos": 55, "end_pos": 82, "type": "TASK", "confidence": 0.7703153888384501}]}, {"text": "The reason for that is a connection between an opinion and its target can be discovered with various syntactic structures.", "labels": [], "entities": []}, {"text": "2) The kernel defined on phrase dependency tree (SVM-PTree) outperforms kernel defined on word level dependency tree(SVMWTree) by 4.8% in average.", "labels": [], "entities": []}, {"text": "We believe the main reason is that phrase dependency tree provides a more succinct tree structure, and the separative treatment of local dependencies and global dependencies in kernel computation can indeed improve the performance of relation extraction.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 234, "end_pos": 253, "type": "TASK", "confidence": 0.8094771206378937}]}], "tableCaptions": [{"text": " Table 1: Statistics for the annotated corpus", "labels": [], "entities": []}, {"text": " Table 2: Results for extracting product features  and opinion expressions", "labels": [], "entities": []}, {"text": " Table 5: Results of different methods", "labels": [], "entities": []}, {"text": " Table 6: Results for total performance with cross domain training data", "labels": [], "entities": []}]}