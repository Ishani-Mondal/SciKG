{"title": [{"text": "Improved Statistical Machine Translation for Resource-Poor Languages Using Related Resource-Rich Languages", "labels": [], "entities": [{"text": "Improved Statistical Machine Translation", "start_pos": 0, "end_pos": 40, "type": "TASK", "confidence": 0.8680701702833176}]}], "abstractContent": [{"text": "We propose a novel language-independent approach for improving statistical machine translation for resource-poor languages by exploiting their similarity to resource-rich ones.", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 63, "end_pos": 94, "type": "TASK", "confidence": 0.7397650281588236}]}, {"text": "More precisely, we improve the translation from a resource-poor source language X 1 into a resource-rich language Y given a bi-text containing a limited number of parallel sentences for X 1-Y and a larger bi-text for X 2-Y for some resource-rich language X 2 that is closely related to X 1.", "labels": [], "entities": []}, {"text": "The evaluation for Indonesian\u2192English (using Malay) and Spanish\u2192English (using Portuguese and pretending Spanish is resource-poor) shows an absolute gain of up to 1.35 and 3.37 Bleu points, respectively, which is an improvement over the rivaling approaches, while using much less additional data.", "labels": [], "entities": [{"text": "Bleu", "start_pos": 177, "end_pos": 181, "type": "METRIC", "confidence": 0.9902840256690979}]}], "introductionContent": [{"text": "Recent developments in statistical machine translation (SMT), e.g., the availability of efficient implementations of integrated open-source toolkits like Moses ( , have made it possible to build a prototype system with decent translation quality for any language pair in a few days or even hours.", "labels": [], "entities": [{"text": "statistical machine translation (SMT)", "start_pos": 23, "end_pos": 60, "type": "TASK", "confidence": 0.8360534061988195}]}, {"text": "In practice, doing so requires having a large set of parallel sentencealigned bi-lingual texts (a bi-text) for that language pair, which is often unavailable.", "labels": [], "entities": []}, {"text": "Large highquality bi-texts are rare; except for Arabic, Chinese, and some official languages of the European Union (EU), most of the 6,500+ world languages remain resource-poor from an SMT viewpoint.", "labels": [], "entities": [{"text": "SMT", "start_pos": 185, "end_pos": 188, "type": "TASK", "confidence": 0.9764427542686462}]}, {"text": "While manually creating a small bi-text could be relatively easy, building a large one is hard, e.g., because of copyright.", "labels": [], "entities": []}, {"text": "Most bi-texts for SMT come from parliament debates and legislation of multi-lingual countries (e.g., French-English from Canada, and Chinese-English from Hong Kong), or from international organizations like the United Nations and the European Union.", "labels": [], "entities": [{"text": "SMT", "start_pos": 18, "end_pos": 21, "type": "TASK", "confidence": 0.995179295539856}]}, {"text": "For example, the Europarl corpus of parliament proceedings consists of about 1.3M parallel sentences (up to 44M words) per language for 11 languages, and the JRC-Acquis corpus provides a comparable amount of European legislation in 22 languages ().", "labels": [], "entities": [{"text": "Europarl corpus of parliament proceedings", "start_pos": 17, "end_pos": 58, "type": "DATASET", "confidence": 0.9591173529624939}, {"text": "JRC-Acquis corpus", "start_pos": 158, "end_pos": 175, "type": "DATASET", "confidence": 0.9645524024963379}]}, {"text": "The official languages of the EU are especially lucky in that respect; while this includes such \"classic SMT languages\" like English and French, and some important international ones like Spanish and Portuguese, most of the rest have a limited number of speakers and were resource-poor until recently; this is changing quickly because of the increasing volume of EU parliament debates and the ever-growing European legislation.", "labels": [], "entities": [{"text": "SMT languages\"", "start_pos": 105, "end_pos": 119, "type": "TASK", "confidence": 0.9029054443041483}]}, {"text": "Thus, becoming an official language of the EU has turned out to bean easy recipe forgetting resource-rich in bi-texts quickly.", "labels": [], "entities": []}, {"text": "Of course, not all languages are that 'lucky', but many can still benefit.", "labels": [], "entities": []}, {"text": "In this paper, we propose using bi-texts for resource-rich language pairs to build better SMT systems for resource-poor ones by exploiting the similarity between a resource-poor language and a resource-rich one.", "labels": [], "entities": [{"text": "SMT", "start_pos": 90, "end_pos": 93, "type": "TASK", "confidence": 0.9963790774345398}]}, {"text": "The proposed method allows non-EU languages to benefit from being closely related to one or more official languages of the EU, the most obvious candidates being Norwegian (related to Swedish), Moldavian 1 (related to Romanian), and Macedonian 2 (related to Bulgarian).", "labels": [], "entities": []}, {"text": "After Croatia joins the EU, Serbian, Bosnian and Montenegrin will be able to benefit from Croatian gradually turning resource-rich (all four split from SerboCroatian after the breakup of Yugoslavia).", "labels": [], "entities": []}, {"text": "The newly-made EU-official (and thus not as resource-rich) Czech and Slovak are another possible pair of candidates.", "labels": [], "entities": []}, {"text": "As we will see below, even such resource-rich languages like Spanish and Portuguese can benefit from the proposed method.", "labels": [], "entities": []}, {"text": "Of course, many pairs of closely related languages can be also found outside of Europe, Malay and Indonesian being just one such example we will experiment with.", "labels": [], "entities": []}, {"text": "The remainder of the present paper is organized as follows: Section 2 presents our method, Section 3 describes the experiments, and Section 4 discusses the results and the general applicability of the approach.", "labels": [], "entities": []}, {"text": "Section 5 provides an overview of the related work.", "labels": [], "entities": []}, {"text": "Finally, Section 6 concludes and suggests possible directions for future work.", "labels": [], "entities": []}], "datasetContent": [{"text": "In our experiments, we used the following number of training sentence pairs (number of words shown in parentheses) for English (en), Indonesian (in), Malay (ml), Portuguese(pt), and Spanish (es): \u2022 Indonesian-English (in-en): -28,383 pairs (0.8M, 0.9M words); -monolingual English en in : 5.1M words.", "labels": [], "entities": []}, {"text": "\u2022 Malay-English (ml-en): -190,503 pairs (5.4M, 5.8M words); -monoling.", "labels": [], "entities": []}, {"text": "English en ml : 27.9M words.", "labels": [], "entities": []}, {"text": "\u2022 Spanish-English (es-en): -1,240,518 pairs (35.7M, 34.6M words); -monolingual English en es:pt : 45.3M words (the same as for pt-en).", "labels": [], "entities": []}, {"text": "\u2022 Portuguese-English (pt-en): -1,230,038 pairs (35.9M, 34.6M words).", "labels": [], "entities": []}, {"text": "-monolingual English en es:pt : 45.3M words (the same as for es-en).", "labels": [], "entities": []}, {"text": "All of the above datasets contain sentences with up to 100 tokens.", "labels": [], "entities": []}, {"text": "In addition, for each of the four language pairs, we have a development and a testing bi-text, each with 2,000 parallel sentence pairs.", "labels": [], "entities": []}, {"text": "We made sure the development and the testing bi-texts shared no sentences with the training bi-texts; we further excluded from the monolingual English data all sentences from the English sides of the training and the development bi-texts.", "labels": [], "entities": []}, {"text": "The training bi-text datasets for es-en and pt-en were built from release v.3 of the Europarl corpus, excluding the Q4/2000 portion out of which we created our testing and development datasets.", "labels": [], "entities": [{"text": "Europarl corpus", "start_pos": 85, "end_pos": 100, "type": "DATASET", "confidence": 0.9924990236759186}, {"text": "Q4/2000 portion", "start_pos": 116, "end_pos": 131, "type": "DATASET", "confidence": 0.844399631023407}]}, {"text": "We built the in-en bi-texts from texts that we downloaded from the Web.", "labels": [], "entities": []}, {"text": "We translated the Indonesian texts to English using Google Translate, and we matched 7 them against the English texts using a cosine similarity measure and heuristic constraints based on document length in words and in sentences, overlap of numbers, words in uppercase, and words in the title.", "labels": [], "entities": []}, {"text": "Next, we extracted pairs of sentences from the matched document pairs using competitive linking), and we retained the ones whose similarity was above a pre-specified threshold.", "labels": [], "entities": []}, {"text": "The ml-en was builtin a similar manner.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Cross-lingual SMT experiments (shown in bold). Columns 2-5 present the bi-texts used for  training, development and testing, and the monolingual data used to train the English language model.  The following columns show the resulting Bleu (in %s) for different numbers of training sentence pairs.", "labels": [], "entities": [{"text": "SMT", "start_pos": 24, "end_pos": 27, "type": "TASK", "confidence": 0.8676922917366028}, {"text": "Bleu (in %s)", "start_pos": 244, "end_pos": 256, "type": "METRIC", "confidence": 0.9318976302941641}]}, {"text": " Table 2: Improving Indonesian\u2192English SMT using ml-en data. Shown are the Bleu scores (in %s)  for different methods. A subscript shows the best parameter value(s) found on the development set and  used on the test set to produce the given result. Bleu scores that are statistically significantly better than  the baseline/our method are marked on the left/right side by < (for p < 0.01) or \u2264 (for p < 0.05).", "labels": [], "entities": [{"text": "Improving Indonesian\u2192English SMT", "start_pos": 10, "end_pos": 42, "type": "TASK", "confidence": 0.5786655962467193}, {"text": "Bleu", "start_pos": 75, "end_pos": 79, "type": "METRIC", "confidence": 0.968346893787384}]}, {"text": " Table 3: Improving Spanish\u2192English SMT using 160K additional pt-en sentence pairs. Column  three shows whether transliteration was used; the following columns list the Bleu scores (in %s) for  different methods. A small subscript shows the best parameter value(s) found on the development set  and used on the test set to produce the given result. Bleu scores that are statistically significantly better  than the baseline/our method are marked on the left/right side by < (for p < 0.01) or \u2264 (for p < 0.05).", "labels": [], "entities": [{"text": "Improving Spanish\u2192English SMT", "start_pos": 10, "end_pos": 39, "type": "TASK", "confidence": 0.7390344500541687}, {"text": "Bleu", "start_pos": 169, "end_pos": 173, "type": "METRIC", "confidence": 0.9086523652076721}]}, {"text": " Table 4: Comparison to the pivoting technique of Callison-Burch et al. (2006) for English\u2192Spanish.  Shown are Bleu scores (in %s) and absolute improvement over the baseline for training bi-texts with  different numbers of parallel sentences (10K, 20K, . . ., 1230K) and fixed amount of additional data:  (1) about 1.3M sentence pairs for each of eight additional languages in Callison-Burch et al. (2006)'s  pivoting, and", "labels": [], "entities": [{"text": "Bleu", "start_pos": 111, "end_pos": 115, "type": "METRIC", "confidence": 0.984451413154602}]}]}