{"title": [], "abstractContent": [{"text": "Automated mining of novel documents or sentences from chronologically ordered documents or sentences is an open challenge in text mining.", "labels": [], "entities": [{"text": "Automated mining of novel documents or sentences from chronologically ordered documents or sentences", "start_pos": 0, "end_pos": 100, "type": "TASK", "confidence": 0.8907428200428302}, {"text": "text mining", "start_pos": 125, "end_pos": 136, "type": "TASK", "confidence": 0.8419801592826843}]}, {"text": "In this paper, we describe the preprocessing techniques for detecting novel Chinese text and discuss the influence of different Part of Speech (POS) filtering rules on the detection performance.", "labels": [], "entities": [{"text": "detecting novel Chinese text", "start_pos": 60, "end_pos": 88, "type": "TASK", "confidence": 0.8569633215665817}, {"text": "Part of Speech (POS) filtering", "start_pos": 128, "end_pos": 158, "type": "TASK", "confidence": 0.5892475034509387}]}, {"text": "Experimental results on AP-WSJ and TREC 2004 Novelty Track data show that the Chinese novelty mining performance is quite different when choosing two dissimilar POS filtering rules.", "labels": [], "entities": [{"text": "AP-WSJ and TREC 2004 Novelty Track data", "start_pos": 24, "end_pos": 63, "type": "DATASET", "confidence": 0.7794719082968575}, {"text": "Chinese novelty mining", "start_pos": 78, "end_pos": 100, "type": "TASK", "confidence": 0.5503450632095337}]}, {"text": "Thus, the selection of words to represent Chinese text is of vital importance to the success of the Chinese novelty mining.", "labels": [], "entities": []}, {"text": "Moreover, we compare the Chinese novelty mining performance with that of English and investigate the impact of preprocessing stepson detecting novel Chinese text, which will be very helpful for developing a Chinese novelty mining system.", "labels": [], "entities": [{"text": "Chinese novelty mining", "start_pos": 25, "end_pos": 47, "type": "TASK", "confidence": 0.5972273747126261}, {"text": "preprocessing stepson detecting novel Chinese text", "start_pos": 111, "end_pos": 161, "type": "TASK", "confidence": 0.7408383587996165}, {"text": "Chinese novelty mining", "start_pos": 207, "end_pos": 229, "type": "TASK", "confidence": 0.5839653213818868}]}], "introductionContent": [{"text": "The bloom of information nowadays brings us rich useful information as well as tons of redundant information in news articles, social networks ( , and blogs.", "labels": [], "entities": []}, {"text": "Novelty mining (NM), or novelty detection, aims at mining novel information from a chronologically ordered list of relevant documents/sentences.", "labels": [], "entities": [{"text": "Novelty mining (NM)", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.8536722779273986}, {"text": "novelty detection", "start_pos": 24, "end_pos": 41, "type": "TASK", "confidence": 0.762790858745575}, {"text": "mining novel information from a chronologically ordered list of relevant documents/sentences", "start_pos": 51, "end_pos": 143, "type": "TASK", "confidence": 0.6483289484794323}]}, {"text": "It can facilitate users to quickly get useful information without going through a lot of redundant information, which is usually a tedious and time-consuming task.", "labels": [], "entities": []}, {"text": "The process of detecting novel text contains three main steps, (i) preprocessing, (ii) categorization, and (iii) novelty mining.", "labels": [], "entities": [{"text": "novelty mining", "start_pos": 113, "end_pos": 127, "type": "TASK", "confidence": 0.7562368214130402}]}, {"text": "The first step preprocesses the text documents/sentences by removing stop words, performing word stemming, implementing POS tagging etc.", "labels": [], "entities": [{"text": "word stemming", "start_pos": 92, "end_pos": 105, "type": "TASK", "confidence": 0.7279693782329559}, {"text": "POS tagging", "start_pos": 120, "end_pos": 131, "type": "TASK", "confidence": 0.744467556476593}]}, {"text": "Categorization classifies each incoming document/sentence into its relevant topic bin.", "labels": [], "entities": []}, {"text": "Then, within each topic bin containing a group of relevant documents/sentences, novelty mining searches through the time sequence of documents/sentences and retrieves only those with \"novel\" information.", "labels": [], "entities": [{"text": "novelty mining", "start_pos": 80, "end_pos": 94, "type": "TASK", "confidence": 0.8220100998878479}]}, {"text": "This paper focuses on applying document/sentencelevel novelty mining on Chinese.", "labels": [], "entities": [{"text": "document/sentencelevel novelty mining", "start_pos": 31, "end_pos": 68, "type": "TASK", "confidence": 0.6107812464237213}]}, {"text": "In this task, we need to identify all novel Chinese text given groups of relevant documents/sentences.", "labels": [], "entities": []}, {"text": "Novelty mining has been performed at three different levels: event level, sentence level and document level ().", "labels": [], "entities": [{"text": "Novelty mining", "start_pos": 0, "end_pos": 14, "type": "TASK", "confidence": 0.8657418787479401}]}, {"text": "Works on novelty mining at the event level originated from research on Topic Detection and Tracking (TDT), which is concerned with online new event detection/first story detection (.", "labels": [], "entities": [{"text": "novelty mining", "start_pos": 9, "end_pos": 23, "type": "TASK", "confidence": 0.8157694041728973}, {"text": "Topic Detection and Tracking (TDT)", "start_pos": 71, "end_pos": 105, "type": "TASK", "confidence": 0.8039765783718654}, {"text": "online new event detection/first story detection", "start_pos": 131, "end_pos": 179, "type": "TASK", "confidence": 0.6260307133197784}]}, {"text": "Research on document and sentence-level novelty mining aims to find relevant and novel documents/sentences given a stream of documents/sentences.", "labels": [], "entities": [{"text": "document and sentence-level novelty mining", "start_pos": 12, "end_pos": 54, "type": "TASK", "confidence": 0.5952177166938781}]}, {"text": "Previous studies on document and sentence-level novelty mining tend to apply some promising content-oriented techniques (.", "labels": [], "entities": [{"text": "document and sentence-level novelty mining", "start_pos": 20, "end_pos": 62, "type": "TASK", "confidence": 0.5990847945213318}]}, {"text": "Similarity metrics that can be used for detecting novel text are word overlap, cosine similarity (, new word count (, etc.", "labels": [], "entities": [{"text": "cosine similarity", "start_pos": 79, "end_pos": 96, "type": "METRIC", "confidence": 0.7954488694667816}]}, {"text": "Other works utilize ontological knowledge, especially taxonomy, such as WordNet (, synonym dictionary (), HowNet (), etc.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 72, "end_pos": 79, "type": "DATASET", "confidence": 0.9447476267814636}, {"text": "HowNet", "start_pos": 106, "end_pos": 112, "type": "DATASET", "confidence": 0.8548911213874817}]}, {"text": "Previous studies for novelty mining have been conducted on the English and Malay languages ( . Novelty mining studies on the Chinese language have been performed on topic de-tection and tracking, which identifies and collects relevant stories on certain topics from information stream (.", "labels": [], "entities": [{"text": "novelty mining", "start_pos": 21, "end_pos": 35, "type": "TASK", "confidence": 0.9115761816501617}]}, {"text": "Also many works have discussed the issues, such as word segmentation, POS tagging etc, between English and Chinese (.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 51, "end_pos": 68, "type": "TASK", "confidence": 0.7687611281871796}, {"text": "POS tagging", "start_pos": 70, "end_pos": 81, "type": "TASK", "confidence": 0.8455637395381927}]}, {"text": "However, to the best of our knowledge, no studies have been reported on discussing preprocessing techniques on Chinese document and sentence-level novelty mining, which is the focus of our paper.", "labels": [], "entities": [{"text": "Chinese document and sentence-level novelty mining", "start_pos": 111, "end_pos": 161, "type": "TASK", "confidence": 0.46818891167640686}]}, {"text": "The rest of this paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 gives a brief overview of related work on detecting novel documents and sentences on English and Chinese.", "labels": [], "entities": [{"text": "detecting novel documents and sentences", "start_pos": 52, "end_pos": 91, "type": "TASK", "confidence": 0.8692065119743347}]}, {"text": "Section 3 introduces the details of preprocessing steps for English and Chinese.", "labels": [], "entities": []}, {"text": "A general novelty mining algorithm is described in Section 4.", "labels": [], "entities": [{"text": "novelty mining", "start_pos": 10, "end_pos": 24, "type": "TASK", "confidence": 0.8355653584003448}]}, {"text": "Section 5 reports experimental results.", "labels": [], "entities": []}, {"text": "Section 6 summarizes the research findings and discusses issues for further research.", "labels": [], "entities": []}], "datasetContent": [{"text": "Two public datasets APWSJ (  and TREC Novelty Track 2004) are selected as our experimental datasets for the document-level and the sentence-level novelty mining respectively.", "labels": [], "entities": [{"text": "APWSJ", "start_pos": 20, "end_pos": 25, "type": "DATASET", "confidence": 0.8181906938552856}, {"text": "TREC Novelty Track 2004", "start_pos": 33, "end_pos": 56, "type": "DATASET", "confidence": 0.8838780671358109}, {"text": "sentence-level novelty mining", "start_pos": 131, "end_pos": 160, "type": "TASK", "confidence": 0.6086367666721344}]}, {"text": "APWSJ data consists of news articles from Associated Press (AP) and Wall Street Journal (WSJ).", "labels": [], "entities": [{"text": "APWSJ data", "start_pos": 0, "end_pos": 10, "type": "DATASET", "confidence": 0.9642685055732727}, {"text": "Wall Street Journal (WSJ)", "start_pos": 68, "end_pos": 93, "type": "DATASET", "confidence": 0.943510373433431}]}, {"text": "There are 50 topics from Q101 to Q150 in APWSJ and 5 topics (Q131, Q142, Q145, Q147, Q150) are excluded from the experiments because they lack non-novel documents ().", "labels": [], "entities": [{"text": "APWSJ", "start_pos": 41, "end_pos": 46, "type": "DATASET", "confidence": 0.9209317564964294}]}, {"text": "The assessors provide two degrees of judgements on non-novel documents, absolute redundant and somewhat redundant.", "labels": [], "entities": []}, {"text": "In our experiments, we adopt the strict definition used in ( ) where only absolute redundant documents are regarded as nonnovel.", "labels": [], "entities": []}, {"text": "TREC 2004 Novelty Track data is developed from AQUAINT collection.", "labels": [], "entities": [{"text": "TREC 2004 Novelty Track data", "start_pos": 0, "end_pos": 28, "type": "DATASET", "confidence": 0.9391161203384399}, {"text": "AQUAINT collection", "start_pos": 47, "end_pos": 65, "type": "DATASET", "confidence": 0.9152984321117401}]}, {"text": "Both relevant and novel sentences are selected by TREC's assessors.", "labels": [], "entities": [{"text": "TREC's assessors", "start_pos": 50, "end_pos": 66, "type": "DATASET", "confidence": 0.6417487561702728}]}, {"text": "The statistics of these two datasets are summarized in.", "labels": [], "entities": []}, {"text": "From many previous works, redundancy precision (RP ), redundancy recall (RR) and redundancy F Score (RF ) are used to evaluate the performance of document-level novelty mining ( ).", "labels": [], "entities": [{"text": "precision (RP )", "start_pos": 37, "end_pos": 52, "type": "METRIC", "confidence": 0.9308727383613586}, {"text": "recall (RR)", "start_pos": 65, "end_pos": 76, "type": "METRIC", "confidence": 0.9706707000732422}, {"text": "F Score (RF )", "start_pos": 92, "end_pos": 105, "type": "METRIC", "confidence": 0.9456113457679749}, {"text": "document-level novelty mining", "start_pos": 146, "end_pos": 175, "type": "TASK", "confidence": 0.6243207554022471}]}, {"text": "Precision (P ), recall (R) and F Score (F ) are mainly used in evaluating the performance for sentence-level novelty mining ().", "labels": [], "entities": [{"text": "Precision (P )", "start_pos": 0, "end_pos": 14, "type": "METRIC", "confidence": 0.9454032629728317}, {"text": "recall (R)", "start_pos": 16, "end_pos": 26, "type": "METRIC", "confidence": 0.950019583106041}, {"text": "F Score (F )", "start_pos": 31, "end_pos": 43, "type": "METRIC", "confidence": 0.9810340285301209}, {"text": "sentence-level novelty mining", "start_pos": 94, "end_pos": 123, "type": "TASK", "confidence": 0.6058761278788248}]}, {"text": "Therefore, we use RP , RR, RF and redundancy precision-recall (R-P R) curve to evaluate our experimental results on the document level.", "labels": [], "entities": [{"text": "RP", "start_pos": 18, "end_pos": 20, "type": "METRIC", "confidence": 0.9383545517921448}, {"text": "RR", "start_pos": 23, "end_pos": 25, "type": "METRIC", "confidence": 0.8506688475608826}, {"text": "RF", "start_pos": 27, "end_pos": 29, "type": "METRIC", "confidence": 0.9857542514801025}, {"text": "redundancy precision-recall (R-P R) curve", "start_pos": 34, "end_pos": 75, "type": "METRIC", "confidence": 0.8728259035519191}]}, {"text": "P , R, F and precision-recall (P R) curve are used to evaluate the performance on the sentence-level novelty mining.", "labels": [], "entities": [{"text": "P", "start_pos": 0, "end_pos": 1, "type": "METRIC", "confidence": 0.9143900871276855}, {"text": "F", "start_pos": 7, "end_pos": 8, "type": "METRIC", "confidence": 0.5002968311309814}, {"text": "precision-recall (P R) curve", "start_pos": 13, "end_pos": 41, "type": "METRIC", "confidence": 0.9689242740472158}, {"text": "sentence-level novelty mining", "start_pos": 86, "end_pos": 115, "type": "TASK", "confidence": 0.6136182943979899}]}, {"text": "The larger the area under the R-P R  curve/P R curve, the better the algorithm.", "labels": [], "entities": []}, {"text": "Also we drew the standard redundancy F Score/F Score contours, which indicate the F Score values when setting precision and recall from 0 to 1 with a step of 0.1.", "labels": [], "entities": [{"text": "F Score", "start_pos": 37, "end_pos": 44, "type": "METRIC", "confidence": 0.9383879005908966}, {"text": "F Score contours", "start_pos": 45, "end_pos": 61, "type": "METRIC", "confidence": 0.905672033627828}, {"text": "F Score", "start_pos": 82, "end_pos": 89, "type": "METRIC", "confidence": 0.987716794013977}, {"text": "precision", "start_pos": 110, "end_pos": 119, "type": "METRIC", "confidence": 0.9958593249320984}, {"text": "recall", "start_pos": 124, "end_pos": 130, "type": "METRIC", "confidence": 0.9983617663383484}]}, {"text": "These contours can facilitate us to compare redundancy F Scores/F Scores in R-P R curves/P R curves.", "labels": [], "entities": [{"text": "F Scores/F Scores", "start_pos": 55, "end_pos": 72, "type": "METRIC", "confidence": 0.7981870889663696}]}, {"text": "Redundancy precision, redundancy recall, precision and recall on a certain topic are defined as: where R + ,R \u2212 ,N + ,N \u2212 correspond to the number of documents/sentences that fall into each category (see).", "labels": [], "entities": [{"text": "precision", "start_pos": 11, "end_pos": 20, "type": "METRIC", "confidence": 0.9303349852561951}, {"text": "recall", "start_pos": 33, "end_pos": 39, "type": "METRIC", "confidence": 0.9760962128639221}, {"text": "precision", "start_pos": 41, "end_pos": 50, "type": "METRIC", "confidence": 0.9992978572845459}, {"text": "recall", "start_pos": 55, "end_pos": 61, "type": "METRIC", "confidence": 0.9990808963775635}]}, {"text": "Based on all the topics' RP /P and RR/R, we could get the average RP /P and average RR/R by calculating the arithmetic mean of these scores on all topics.", "labels": [], "entities": [{"text": "RR/R", "start_pos": 35, "end_pos": 39, "type": "METRIC", "confidence": 0.9099247852961222}, {"text": "RR/R", "start_pos": 84, "end_pos": 88, "type": "METRIC", "confidence": 0.9431424339612325}]}, {"text": "Then, the average redundancy F Score (RF )/F Score (F ) is obtained by the harmonic average of the average RP /P and average RR/R.", "labels": [], "entities": [{"text": "average redundancy F Score (RF )/F Score (F )", "start_pos": 10, "end_pos": 55, "type": "METRIC", "confidence": 0.8370217631260554}]}, {"text": "In this experimental study, the focus was novelty mining rather than relevant documents/sentences categorization.", "labels": [], "entities": [{"text": "novelty mining", "start_pos": 42, "end_pos": 56, "type": "TASK", "confidence": 0.778140515089035}]}, {"text": "Therefore, our experiments started with all given relevant Chinese text, from which the novel text should be identified.", "labels": [], "entities": []}, {"text": "Since the datasets that we used for documentlevel novelty mining and sentence-level novelty mining both were written in English, we first translated them into Chinese.", "labels": [], "entities": [{"text": "documentlevel novelty mining", "start_pos": 36, "end_pos": 64, "type": "TASK", "confidence": 0.6830960909525553}, {"text": "sentence-level novelty mining", "start_pos": 69, "end_pos": 98, "type": "TASK", "confidence": 0.6117126643657684}]}, {"text": "During this process, we investigated issues on machine translation vs. manually corrected translation.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 47, "end_pos": 66, "type": "TASK", "confidence": 0.8181453049182892}]}, {"text": "We compared the novelty mining performance on 107 text in TREC 2004 Novelty Track between automatically translated using Google Translate API 1 and the manually corrected translation.", "labels": [], "entities": [{"text": "novelty mining", "start_pos": 16, "end_pos": 30, "type": "TASK", "confidence": 0.7223391532897949}, {"text": "TREC 2004 Novelty Track", "start_pos": 58, "end_pos": 81, "type": "DATASET", "confidence": 0.9269255846738815}]}, {"text": "For example, here is an English sentence in Topic 51: According to a Chilean government report, a total of 4,299 political opponents died or disappeared during Pinochet's term.", "labels": [], "entities": []}, {"text": "After machine translation using Google Translator, the above sentence is translated as: 4299 Then we manually corrected the machine translation and obtained the corrected translation: 4299 After novelty mining on the machine translation sentences and the humanly corrected translation sentences individually, we found that there is a slight difference (<2%) in precision and F Score.", "labels": [], "entities": [{"text": "precision", "start_pos": 361, "end_pos": 370, "type": "METRIC", "confidence": 0.9996976852416992}, {"text": "F Score", "start_pos": 375, "end_pos": 382, "type": "METRIC", "confidence": 0.9453161358833313}]}, {"text": "Thus, we used machine translation to translate the remaining documents/sentences to Chinese.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 14, "end_pos": 33, "type": "TASK", "confidence": 0.7113666981458664}]}, {"text": "This indicates that the noise in machine translation for Chinese had little impact on our actual results.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 33, "end_pos": 52, "type": "TASK", "confidence": 0.6978465020656586}]}, {"text": "Then on English text, we applied the preprocessing steps discussed in Section 3.1, including stop word removing and word stemming.", "labels": [], "entities": [{"text": "stop word removing", "start_pos": 93, "end_pos": 111, "type": "TASK", "confidence": 0.7026803294817606}, {"text": "word stemming", "start_pos": 116, "end_pos": 129, "type": "TASK", "confidence": 0.7524392902851105}]}, {"text": "For Chinese datasets, we segmented the documents/sentences into words and then performed POS filtering to acquire the candidate words for the space vector.", "labels": [], "entities": [{"text": "POS filtering", "start_pos": 89, "end_pos": 102, "type": "TASK", "confidence": 0.7107878178358078}]}, {"text": "Based on the vectors of Chinese text, we calculated the similarities between documents/sentences and predicted the novelty for each document/sentence in the Chinese and English datasets.", "labels": [], "entities": [{"text": "novelty", "start_pos": 115, "end_pos": 122, "type": "METRIC", "confidence": 0.992281973361969}]}, {"text": "An incoming Chinese/English document will be compared with all the system delivered 10 novel documents.", "labels": [], "entities": []}, {"text": "If the novelty score is above the novelty score threshold, the document is considered to be novel.", "labels": [], "entities": [{"text": "novelty score", "start_pos": 7, "end_pos": 20, "type": "METRIC", "confidence": 0.9340541064739227}, {"text": "novelty score threshold", "start_pos": 34, "end_pos": 57, "type": "METRIC", "confidence": 0.954195479551951}]}, {"text": "Thresholds used were between 0.05 and 0.65.", "labels": [], "entities": [{"text": "Thresholds", "start_pos": 0, "end_pos": 10, "type": "METRIC", "confidence": 0.9969578981399536}]}, {"text": "We also performed Chinese/English sentence-level novelty mining.", "labels": [], "entities": [{"text": "Chinese/English sentence-level novelty mining", "start_pos": 18, "end_pos": 63, "type": "TASK", "confidence": 0.5697994331518809}]}, {"text": "Whether an incoming Chinese/English sentence is novel is predicted by comparing with the most recent system-delivered 1000 novel sentences.", "labels": [], "entities": []}, {"text": "Thresholds adopted were between 0.05 and 0.95 with an equal step of 0.10.", "labels": [], "entities": [{"text": "Thresholds", "start_pos": 0, "end_pos": 10, "type": "METRIC", "confidence": 0.9965333938598633}]}, {"text": "Then, we evaluated the Chinese/English novel text detection performance by setting a series of novelty score thresholds.", "labels": [], "entities": [{"text": "Chinese/English novel text detection", "start_pos": 23, "end_pos": 59, "type": "TASK", "confidence": 0.49605269730091095}, {"text": "novelty score thresholds", "start_pos": 95, "end_pos": 119, "type": "METRIC", "confidence": 0.9710148771603903}]}], "tableCaptions": [{"text": " Table 1: Statistics of experimental data  Dataset  Novel  Non-novel  APWSJ  10839(91.10%) 1057(8.90%)  TREC2004 3454(41.40%) 4889(58.60%)", "labels": [], "entities": [{"text": "experimental data  Dataset  Novel  Non-novel  APWSJ  10839", "start_pos": 24, "end_pos": 82, "type": "DATASET", "confidence": 0.6979676527636391}, {"text": "TREC2004 3454", "start_pos": 104, "end_pos": 117, "type": "DATASET", "confidence": 0.6602745354175568}]}]}