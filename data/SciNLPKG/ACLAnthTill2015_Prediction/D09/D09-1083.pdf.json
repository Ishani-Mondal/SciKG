{"title": [{"text": "Learning Term-weighting Functions for Similarity Measures", "labels": [], "entities": [{"text": "Similarity Measures", "start_pos": 38, "end_pos": 57, "type": "TASK", "confidence": 0.9538476765155792}]}], "abstractContent": [{"text": "Measuring the similarity between two texts is a fundamental problem in many NLP and IR applications.", "labels": [], "entities": []}, {"text": "Among the existing approaches, the cosine measure of the term vectors representing the original texts has been widely used, where the score of each term is often determined by a TFIDF formula.", "labels": [], "entities": [{"text": "TFIDF", "start_pos": 178, "end_pos": 183, "type": "METRIC", "confidence": 0.8724204301834106}]}, {"text": "Despite its simplicity , the quality of such cosine similarity measure is usually domain dependent and decided by the choice of the term-weighting function.", "labels": [], "entities": []}, {"text": "In this paper, we propose a novel framework that learns the term-weighting function.", "labels": [], "entities": []}, {"text": "Given the labeled pairs of texts as training data, the learning procedure tunes the model parameters by minimizing the specified loss function of the similarity score.", "labels": [], "entities": []}, {"text": "Compared to traditional TFIDF term-weighting schemes, our approach shows a significant improvement on tasks such as judging the quality of query suggestions and filtering irrelevant ads for online advertising.", "labels": [], "entities": []}], "introductionContent": [{"text": "Measuring the semantic similarity between two texts is an important problem that has many useful applications in both NLP and IR communities.", "labels": [], "entities": []}, {"text": "For example, Lin (1998) defined a similarity measure for automatic thesaurus creation from a corpus.", "labels": [], "entities": [{"text": "automatic thesaurus creation from a corpus", "start_pos": 57, "end_pos": 99, "type": "TASK", "confidence": 0.7821743339300156}]}, {"text": "developed several corpus-based and knowledge-based word similarity measures and applied them to a paraphrase recognition task.", "labels": [], "entities": [{"text": "paraphrase recognition task", "start_pos": 98, "end_pos": 125, "type": "TASK", "confidence": 0.8696784973144531}]}, {"text": "In the domain of web search, different methods of measuring similarity between short text segments have recently been proposed for solving problems like query suggestion and alternation;).", "labels": [], "entities": [{"text": "query suggestion and alternation", "start_pos": 153, "end_pos": 185, "type": "TASK", "confidence": 0.6830458343029022}]}, {"text": "Among these similarity measures proposed in various applications, the vector-based methods are arguably the most widely used.", "labels": [], "entities": []}, {"text": "In this approach, the text being compared with is first represented by a term vector, where each term is associated with a weight that indicates its importance.", "labels": [], "entities": []}, {"text": "The similarity function could be cosine (i.e., the inner product of two normalized unit term vectors, or equivalently a linear kernel), or other kernel functions such as the Gaussian kernel.", "labels": [], "entities": []}, {"text": "There are essentially two main factors that decide the quality of a vector-based similarity measure.", "labels": [], "entities": []}, {"text": "One is the vector operation that takes as input the term vectors and computes the final similarity score (e.g., cosine).", "labels": [], "entities": [{"text": "similarity score", "start_pos": 88, "end_pos": 104, "type": "METRIC", "confidence": 0.8871819078922272}]}, {"text": "The other is how these term vectors are constructed, including the term selection process and how the weights are determined.", "labels": [], "entities": []}, {"text": "For instance, a TFIDF scheme for measuring document similarity may follow the bag-ofwords strategy to include all the words in the document when constructing the term vectors.", "labels": [], "entities": []}, {"text": "The weight of each term is simply the product of its term frequency (i.e., the number of occurrences in the document) and inverse document frequency (i.e., the number of documents in a collection that contain this term).", "labels": [], "entities": []}, {"text": "Despite its simplicity and reasonable performance, such approach suffers from several weaknesses.", "labels": [], "entities": []}, {"text": "For instance, the similarity measure is not domain-dependent and cannot be easily adjusted to better fit the final objective, such as being a metric value used for clustering or providing better ranking results.", "labels": [], "entities": [{"text": "similarity measure", "start_pos": 18, "end_pos": 36, "type": "METRIC", "confidence": 0.9322552978992462}]}, {"text": "Researchers often need to experiment with variants of TFIDF formulas and different term selection strategies (e.g., removing stopwords or stemming) to achieve acceptable performance (.", "labels": [], "entities": []}, {"text": "In addition, when more information is available, such as the position of a term in the document or whether a term is part of an anchor text, incorporating it in the similarity measure in a principled manner may not be easy.", "labels": [], "entities": []}, {"text": "In this paper, we propose a general termweighting learning framework, TWEAK, that learns the term-weighting function for the vectorbased similarity measures.", "labels": [], "entities": [{"text": "TWEAK", "start_pos": 70, "end_pos": 75, "type": "METRIC", "confidence": 0.8177513480186462}]}, {"text": "Instead of using a fixed formula to decide the weight of each term, TWEAK uses a parametric function of features of each term, where the model parameters are learned from labeled data.", "labels": [], "entities": []}, {"text": "Although the weight of each term conceptually represents its importance with respect to the document, tuning the model parameters to optimize for such objectives may not be the best strategy due to two reasons.", "labels": [], "entities": []}, {"text": "While the label of whether a pair of texts is similar is not difficult to collect from human annotators 1 , the label of whether a term in a document is important is often very ambiguous and hard to decide.", "labels": [], "entities": []}, {"text": "Even if such annotation issue can be resolved, aligning the term weights with the true importance of each term may not necessarily lead to our real objective -deriving a better similarity measure for the target application.", "labels": [], "entities": []}, {"text": "Therefore, our learning framework, TWEAK, assumes that we are given only the labels of the pairs of texts being compared, such as whether the two texts are considered similar by human subjects.", "labels": [], "entities": [{"text": "TWEAK", "start_pos": 35, "end_pos": 40, "type": "METRIC", "confidence": 0.5482280254364014}]}, {"text": "TWEAK is flexible in choosing various loss functions that are close to the true objectives, while still maintaining the simplicity of the vectorbased similarity measures.", "labels": [], "entities": [{"text": "TWEAK", "start_pos": 0, "end_pos": 5, "type": "DATASET", "confidence": 0.7495483160018921}]}, {"text": "For example, a system that implements the TFIDF cosine measure can easily replace the original term-weighting scores with the ones output by TWEAK without changing other portions of the algorithm.", "labels": [], "entities": []}, {"text": "TWEAK is also novel compared to other existing learning methods for similarity measures.", "labels": [], "entities": [{"text": "TWEAK", "start_pos": 0, "end_pos": 5, "type": "METRIC", "confidence": 0.6013060808181763}]}, {"text": "For instance, we do not learn the scores of all the terms in the vocabulary directly, which is one of the methods proposed by.", "labels": [], "entities": []}, {"text": "Because the vocabulary size is typically large in the text domain (e.g., all possible words in English), learning directly the term-weighting scores may suffer from the data sparsity issue and cannot generalize well in practice.", "labels": [], "entities": []}, {"text": "Instead, we focus on learning the model parameters for features that each term may have, which results in a much smaller feature space.", "labels": [], "entities": []}, {"text": "TWEAK also differs from the model combination approach proposed by, where the output scores of different similarity measures are combined via a learned linear function.", "labels": [], "entities": [{"text": "TWEAK", "start_pos": 0, "end_pos": 5, "type": "METRIC", "confidence": 0.39264586567878723}]}, {"text": "In contrast, TWEAK effectively learns anew similarity measure by tuning the termweighting function and can potentially be complementary to the model combination approach.", "labels": [], "entities": []}, {"text": "As will be demonstrated in our experiments, in applications such as judging the relevance of different query suggestions and determining whether a paid-search ad is related to the user query, TWEAK can incorporate various kinds of termdocument information and learn a term-weighting function that significantly outperforms the traditional TFIDF scheme in several evaluation metrics, when using the same vector operation (i.e., cosine) and the same set of terms.", "labels": [], "entities": []}, {"text": "We organize the rest of the paper as follows.", "labels": [], "entities": []}, {"text": "2 first gives a high-level view of our termweighting learning framework.", "labels": [], "entities": []}, {"text": "We then formally define our model and present the loss functions that can be optimized for in Sec.", "labels": [], "entities": []}, {"text": "3. Experiments on target applications are presented in Sec.", "labels": [], "entities": []}, {"text": "4. Finally, we compare our approach with some related work in Sec.", "labels": [], "entities": []}, {"text": "5 and conclude the paper in Sec.", "labels": [], "entities": []}], "datasetContent": [{"text": "We demonstrate how to apply our term-weighting learning framework, TWEAK, to measuring similarity for short text segments and to judging the relevance of an ad landing page given an query.", "labels": [], "entities": [{"text": "TWEAK", "start_pos": 67, "end_pos": 72, "type": "METRIC", "confidence": 0.7116698622703552}]}, {"text": "In addition, we compare experimentally the performance of using different training settings, loss functions and features against the traditional TFIDF term-weighting scheme.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: The AUC scores, mean averaged preci- sion and precision at 3 of similarity measures us- ing different term-weighting functions. The num- bers with the  \u2020 sign are statistically significantly  better compared to the Web-kernel method.", "labels": [], "entities": [{"text": "AUC", "start_pos": 14, "end_pos": 17, "type": "METRIC", "confidence": 0.9593924283981323}, {"text": "mean averaged preci- sion", "start_pos": 26, "end_pos": 51, "type": "METRIC", "confidence": 0.8911330461502075}, {"text": "precision", "start_pos": 56, "end_pos": 65, "type": "METRIC", "confidence": 0.9987301230430603}]}, {"text": " Table 2: The AUC scores, true-positive rates at  false-positive rates 0.1 and 0.2 of the ad filter  based on different term-weighting functions. The  difference between any pair of numbers of the  same evaluation metric is statistically significant.  Method  AUC TPR fnr=0.1 TPR fnr=0.2  TFIDF  0.794  0.527  0.658  TF&DF 0.806  0.430  0.639  Plain-text 0.832  0.503  0.704  HTML  0.855  0.568  0.750", "labels": [], "entities": [{"text": "AUC", "start_pos": 14, "end_pos": 17, "type": "METRIC", "confidence": 0.5087981820106506}]}]}