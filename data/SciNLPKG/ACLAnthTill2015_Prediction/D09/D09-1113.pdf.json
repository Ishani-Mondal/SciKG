{"title": [{"text": "Empirical Exploitation of Click Data for Task Specific Ranking", "labels": [], "entities": []}], "abstractContent": [{"text": "There have been increasing needs for task specific rankings in web search such as rankings for specific query segments like long queries, time-sensitive queries, navi-gational queries, etc; or rankings for specific domains/contents like answers, blogs, news, etc.", "labels": [], "entities": []}, {"text": "In the spirit of \"divide-and-conquer\", task specific ranking may have potential advantages over generic ranking since different tasks have task-specific features , data distributions, as well as feature-grade correlations.", "labels": [], "entities": []}, {"text": "A critical problem for the task-specific ranking is training data insufficiency, which maybe solved by using the data extracted from click log.", "labels": [], "entities": []}, {"text": "This paper empirically studies how to appropriately exploit click data to improve rank function learning in task-specific ranking.", "labels": [], "entities": []}, {"text": "The main contributions are 1) the exploration on the utilities of two promising approaches for click pair extraction; 2) the analysis of the role played by the noise information which inevitably appears in click data extraction; 3) the appropriate strategy for combining training data and click data; 4) the comparison of click data which are consistent and inconsistent with baseline function.", "labels": [], "entities": [{"text": "click pair extraction", "start_pos": 95, "end_pos": 116, "type": "TASK", "confidence": 0.6591603954633077}, {"text": "click data extraction", "start_pos": 206, "end_pos": 227, "type": "TASK", "confidence": 0.6024494965871176}]}], "introductionContent": [{"text": "Learning-to-rank approaches have been widely applied in commercial search engines, in which ranking models are learned using labeled documents.", "labels": [], "entities": []}, {"text": "Significant efforts have been made in attempt to learn a generic ranking model which can appropriately rank documents for all queries . However, web users' query intentions are extremely heterogeneous, which makes it difficult fora generic ranking model to achieve best ranking results for all queries.", "labels": [], "entities": []}, {"text": "For this reason, there have been increasing needs for task specific rankings in web search such as rankings for specific query segments like long queries, time-sensitive queries, navigational queries, etc; or rankings for specific domains/contents like answers, blogs, news, etc.", "labels": [], "entities": []}, {"text": "Therefore, a specific ranking task usually correspond to a category of queries; when the search engine determines that a query is belonging to this category, it will call the ranking function dedicated to this ranking task.", "labels": [], "entities": []}, {"text": "The motivation of this divide-and-conquer strategy is that, task specific ranking may have potential advantages over generic ranking since different tasks have task-specific features, data distributions, as well as feature-grade correlations.", "labels": [], "entities": []}, {"text": "Such a dedicated ranking model can be trained using the labeled data belonging to this query category (which is called dedicated training data).", "labels": [], "entities": []}, {"text": "However, the amount of training data dedicated to a specific ranking task is usually insufficient because human labeling is expensive and timeconsuming, not to mention there are multiple ranking tasks that need to betaken care of.", "labels": [], "entities": [{"text": "human labeling", "start_pos": 106, "end_pos": 120, "type": "TASK", "confidence": 0.5957518219947815}]}, {"text": "To deal with the training data insufficiency problem for task-specific ranking, we propose to extract clickthrough data and incorporate it with dedicated training data to learn a dedicated model.", "labels": [], "entities": []}, {"text": "In order to incorporate click data to improve the ranking fora dedicate query category, it is critical to fully exploit click information.", "labels": [], "entities": []}, {"text": "We empirically explore the related approaches for the appropriate click data exploitation in task-specific rank function learning.", "labels": [], "entities": []}, {"text": "illustrates the procedures and critical components to be studied.", "labels": [], "entities": []}, {"text": "1) Click data mining: the purpose is to extract informative and reliable users' preference information from click log.", "labels": [], "entities": [{"text": "Click data mining", "start_pos": 3, "end_pos": 20, "type": "TASK", "confidence": 0.6029361585776011}]}, {"text": "We employ two promising approaches: one is heuristic rule approach, the other is sequential supervised learning approach.", "labels": [], "entities": []}, {"text": "2) Sample selection and combination: with labeled training data and unlabeled click data, how to select and combine them so that the samples have the best utility for learning?", "labels": [], "entities": [{"text": "Sample selection", "start_pos": 3, "end_pos": 19, "type": "TASK", "confidence": 0.9769402742385864}]}, {"text": "As the data distribution fora specific ranking task is different from the generic data distribution, it is natural to select those labeled training samples and unlabeled click preference pairs which belong to this query category, so that the data distributions of training set and testing set are consistent for this category.", "labels": [], "entities": []}, {"text": "On the other hand, we should keep in mind that: a) non-dedicated data, i.e, the data that does not belong the specific category, might also have similar distribution as the dedicated data.", "labels": [], "entities": []}, {"text": "Such distribution similarity makes non-dedicated data also useful for task-specific rank function learning, especially for the scenario that dedicated training samples is insufficient.", "labels": [], "entities": []}, {"text": "b) The quality of dedicated click data maybe not as reliable as human labeled training data.", "labels": [], "entities": []}, {"text": "In other words, there are some extracted click preference pairs that are inconsistent with human labeling while we regard human labeling as correct labeling.", "labels": [], "entities": []}, {"text": "3) Rank function learning algorithm: we use GBrank () algorithm for rank function learning, which has proved to be one of the most effective up-to-date learning-to-rank algorithms; furthermore, GBrank algorithm also takes preference pairs as inputs, which will be illustrated with more details in the paper.", "labels": [], "entities": [{"text": "Rank function learning", "start_pos": 3, "end_pos": 25, "type": "TASK", "confidence": 0.7608926892280579}, {"text": "rank function learning", "start_pos": 68, "end_pos": 90, "type": "TASK", "confidence": 0.6316851774851481}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 2: Skip-above pairs count vs. human judge- ments (e.g., the element in the third row and sec- ond column means we have 40 skip-above pairs  with \"excellent\" url 1 and \"perfect\" url 2 ). P: per- fect; E: excellent; G: good; F: fair; B: bad.", "labels": [], "entities": [{"text": "Skip-above", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.9625873565673828}]}, {"text": " Table 3: Skip-next pairs vs. human judgements  (e.g., the element in the third row and second col- umn means we have 10 skip-next pairs with \"ex- cellent\" url 1 and \"perfect\" url 2 ). P: perfect; E:  excellent; G: good; F: fair; B: bad.", "labels": [], "entities": [{"text": "Skip-next", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9333740472793579}]}]}