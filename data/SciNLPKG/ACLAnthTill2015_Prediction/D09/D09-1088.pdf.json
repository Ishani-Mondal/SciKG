{"title": [{"text": "An Alternative to Head-Driven Approaches for Parsing a (Relatively) Free Word-Order Language", "labels": [], "entities": []}], "abstractContent": [{"text": "Applying statistical parsers developed for English to languages with freer word-order has turned out to be harder than expected.", "labels": [], "entities": []}, {"text": "This paper investigates the adequacy of different statistical parsing models for dealing with a (relatively) free word-order language.", "labels": [], "entities": [{"text": "statistical parsing", "start_pos": 50, "end_pos": 69, "type": "TASK", "confidence": 0.6547595709562302}]}, {"text": "We show that the recently proposed Relational-Realizational (RR) model consistently outperforms state-of-the-art Head-Driven (HD) models on the Hebrew Treebank.", "labels": [], "entities": [{"text": "Hebrew Treebank", "start_pos": 144, "end_pos": 159, "type": "DATASET", "confidence": 0.9675927460193634}]}, {"text": "Our analysis reveals a weakness of HD models: their intrinsic focus on configu-rational information.", "labels": [], "entities": []}, {"text": "We conclude that the form-function separation ingrained in RR models makes them better suited for parsing nonconfigurational phenomena.", "labels": [], "entities": []}], "introductionContent": [{"text": "Parsing technology has come along way since demonstrated that a simple treebank PCFG performs better than any other parser (with F 1 75 accuracy) on parsing the WSJ Penn treebank.", "labels": [], "entities": [{"text": "F 1 75 accuracy", "start_pos": 129, "end_pos": 144, "type": "METRIC", "confidence": 0.9043153822422028}, {"text": "WSJ Penn treebank", "start_pos": 161, "end_pos": 178, "type": "DATASET", "confidence": 0.9739345709482828}]}, {"text": "Treebank Grammars () trained on large corpora nowadays present the best available means to parse natural language text.", "labels": [], "entities": [{"text": "parse natural language text", "start_pos": 91, "end_pos": 118, "type": "TASK", "confidence": 0.8341471701860428}]}, {"text": "The performance curve for parsing the WSJ was a steep one at first, as the incorporation of notions such as head, distance, subcategorization) brought about a dramatic increase in parsing accuracy to the level of F 1 88.", "labels": [], "entities": [{"text": "parsing the WSJ", "start_pos": 26, "end_pos": 41, "type": "TASK", "confidence": 0.6857166588306427}, {"text": "head", "start_pos": 108, "end_pos": 112, "type": "METRIC", "confidence": 0.9637573957443237}, {"text": "parsing", "start_pos": 180, "end_pos": 187, "type": "TASK", "confidence": 0.962389349937439}, {"text": "accuracy", "start_pos": 188, "end_pos": 196, "type": "METRIC", "confidence": 0.9730991721153259}, {"text": "F 1 88", "start_pos": 213, "end_pos": 219, "type": "METRIC", "confidence": 0.9597517649332682}]}, {"text": "Discriminative approaches, DataOriented Parsing ('all-subtrees') approaches, and self-training techniques brought further improvements, and recent results are starting to level off at around F 1 92.1 (.", "labels": [], "entities": [{"text": "F 1 92.1", "start_pos": 191, "end_pos": 199, "type": "METRIC", "confidence": 0.9558788339296976}]}, {"text": "As the interest of the NLP community grows to encompass more languages, we observe efforts towards adapting an English parser for parsing other languages (e.g., ), or towards designing a language-independent framework based on principles underlying the models for parsing English).", "labels": [], "entities": []}, {"text": "The performance curve for parsing other languages with these models looks rather different.", "labels": [], "entities": []}, {"text": "A casein point is Modern Standard Arabic.", "labels": [], "entities": [{"text": "Modern Standard Arabic", "start_pos": 18, "end_pos": 40, "type": "DATASET", "confidence": 0.9227135181427002}]}, {"text": "Since the initial effort of) to parse the Arabic treebank (), which yielded F 1 75 accuracy, four years and successive revisions have led to no more than F 1 79 (.", "labels": [], "entities": [{"text": "Arabic treebank", "start_pos": 42, "end_pos": 57, "type": "DATASET", "confidence": 0.7032207250595093}, {"text": "F 1 75", "start_pos": 76, "end_pos": 82, "type": "METRIC", "confidence": 0.9688900311787924}, {"text": "accuracy", "start_pos": 83, "end_pos": 91, "type": "METRIC", "confidence": 0.713344395160675}, {"text": "F 1 79", "start_pos": 154, "end_pos": 160, "type": "METRIC", "confidence": 0.8910337487856547}]}, {"text": "This pattern from Arabic is not peculiar.", "labels": [], "entities": []}, {"text": "The level of state-of-the-art results for other languages still lags behind those for English, even after putting considerable effort into the adaptation.", "labels": [], "entities": []}, {"text": "Given that these languages are inherently different from English and from one another, it appears that we cannot avoid a question concerning the adequacy of the models used to parse them.", "labels": [], "entities": []}, {"text": "That is, given the properties of a language, which modeling strategy would be appropriate for parsing it?", "labels": [], "entities": []}, {"text": "Until recently, there has been practically no computationally affordable alternative to the Head-Driven (HD) approach in the development of phrase-structure based statistical parsing models.", "labels": [], "entities": [{"text": "phrase-structure based statistical parsing", "start_pos": 140, "end_pos": 182, "type": "TASK", "confidence": 0.5578189119696617}]}, {"text": "Recently, we proposed the RelationalRealizational (RR) approach that rests upon different premises.", "labels": [], "entities": [{"text": "RelationalRealizational (RR)", "start_pos": 26, "end_pos": 54, "type": "TASK", "confidence": 0.6625910699367523}]}, {"text": "The question of how the RR model fares against the HD models that have so far been predominantly used has never been tackled.", "labels": [], "entities": [{"text": "RR", "start_pos": 24, "end_pos": 26, "type": "TASK", "confidence": 0.582542359828949}]}, {"text": "Yet, it is precisely such a comparison that can shed new light on the question of adequacy we posed above.", "labels": [], "entities": []}, {"text": "Empirically quantifying the effects of different modeling choices has been addressed for English by, e.g.,, and for German by, e.g.,.", "labels": [], "entities": []}, {"text": "This paper provides an empirical systematic comparison of conceptually different modeling strategies with respect to parsing Hebrew.", "labels": [], "entities": [{"text": "parsing Hebrew", "start_pos": 117, "end_pos": 131, "type": "TASK", "confidence": 0.906436026096344}]}, {"text": "This comparison is intended to provide a first answer to the question of parser adequacy in the face of word-order freedom.", "labels": [], "entities": []}, {"text": "Our two empirical results are unequivocal.", "labels": [], "entities": []}, {"text": "Firstly, RR models significantly outperform HD models (about 2 points absolute improvement in F 1 ) in parsing the Modern Hebrew treebank.", "labels": [], "entities": [{"text": "F 1", "start_pos": 94, "end_pos": 97, "type": "METRIC", "confidence": 0.9395608007907867}, {"text": "parsing", "start_pos": 103, "end_pos": 110, "type": "TASK", "confidence": 0.9758053421974182}, {"text": "Modern Hebrew treebank", "start_pos": 115, "end_pos": 137, "type": "DATASET", "confidence": 0.6977165440718333}]}, {"text": "In particular, RR models show better performance in identifying the constituents for which syntactic positions are relatively free.", "labels": [], "entities": [{"text": "RR", "start_pos": 15, "end_pos": 17, "type": "TASK", "confidence": 0.9479009509086609}]}, {"text": "Secondly, we show a novel variation of the HD model, incorporating the Relational notions of the RR model, on the hypothesis that this might bridge the gap.", "labels": [], "entities": []}, {"text": "The RR model remains superior.", "labels": [], "entities": [{"text": "RR", "start_pos": 4, "end_pos": 6, "type": "METRIC", "confidence": 0.5136669874191284}]}, {"text": "Our post-experimental analysis shows that HD modeling is inherently problematic for parsing a language with freer word-order because of the hard-wiring of notions such as left, right and distance from the head.", "labels": [], "entities": [{"text": "HD modeling", "start_pos": 42, "end_pos": 53, "type": "TASK", "confidence": 0.8937492966651917}]}, {"text": "RR models, taking a principled approach towards capturing variable formfunction correspondence patterns, are better suited for parsing nonconfigurational phenomena.", "labels": [], "entities": [{"text": "RR", "start_pos": 0, "end_pos": 2, "type": "TASK", "confidence": 0.906114399433136}]}], "datasetContent": [{"text": "Goal We set out to compare the performance of the different modeling approaches for parsing Modern Hebrew.", "labels": [], "entities": [{"text": "parsing Modern Hebrew", "start_pos": 84, "end_pos": 105, "type": "TASK", "confidence": 0.8469821612040201}]}, {"text": "Considerable effort was devoted to making the models strictly comparable, in terms of preparing the data, defining statistical events, and unifying the rules determining crosscutting linguistic notions (e.g., heads and predicates, grammatical functions and subcat sets).", "labels": [], "entities": []}, {"text": "We spell out some of the setup considerations below.", "labels": [], "entities": []}, {"text": "Data We use the Modern Hebrew treebank (MHTB)) consisting of 6501 sentences from news-wire texts, morphologically analyzed and syntactically annotated as phrase-", "labels": [], "entities": [{"text": "Modern Hebrew treebank (MHTB))", "start_pos": 16, "end_pos": 46, "type": "DATASET", "confidence": 0.7933298548062643}]}], "tableCaptions": [{"text": " Table 1: Modern Hebrew Predicative Clause- Types in 3930 Predicative Matrix Clauses in the  Training Set of the Modern Hebrew Treebank.", "labels": [], "entities": [{"text": "Modern Hebrew Treebank", "start_pos": 113, "end_pos": 135, "type": "DATASET", "confidence": 0.7084073424339294}]}, {"text": " Table 4: The Performance of Different Models  in Parsing Hebrew: Parsing Results Prec/Recall  for Sentences of Length \u2264 40.", "labels": [], "entities": []}, {"text": " Table 5: Per-Category Evaluation of Parsing  Performance for Different Models: Prec/Rec  Per Category Calculated for All Sentences.", "labels": [], "entities": [{"text": "Prec/Rec  Per Category Calculated", "start_pos": 80, "end_pos": 113, "type": "METRIC", "confidence": 0.8500044345855713}]}, {"text": " Table 6: Incorporating Distance and Grammatical Functions into Head-Driven Parsing Models  Reporting Precison/Recall (#Parameters) for Sentences Length < 40.", "labels": [], "entities": [{"text": "Reporting Precison/Recall", "start_pos": 92, "end_pos": 117, "type": "METRIC", "confidence": 0.6443202272057533}]}]}