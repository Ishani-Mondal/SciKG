{"title": [{"text": "Person Cross Document Coreference with Name Perplexity Estimates", "labels": [], "entities": [{"text": "Person Cross Document Coreference", "start_pos": 0, "end_pos": 33, "type": "TASK", "confidence": 0.5611540302634239}]}], "abstractContent": [{"text": "The Person Cross Document Coreference systems depend on the context for making decisions on the possible coreferences between person name mentions.", "labels": [], "entities": []}, {"text": "The amount of context required is a parameter that varies from corpora to corpora, which makes it difficult for usual disambiguation methods.", "labels": [], "entities": []}, {"text": "In this paper we show that the amount of context required can be dynamically controlled on the basis of the prior probabilities of coreference and we present anew statistical model for the computation of these probabilities.", "labels": [], "entities": [{"text": "coreference", "start_pos": 131, "end_pos": 142, "type": "TASK", "confidence": 0.9635802507400513}]}, {"text": "The experiment we carried on a news corpus proves that the prior probabilities of coreference are an important factor for maintaining a good balance between precision and recall for cross document coreference systems.", "labels": [], "entities": [{"text": "coreference", "start_pos": 82, "end_pos": 93, "type": "TASK", "confidence": 0.9695874452590942}, {"text": "precision", "start_pos": 157, "end_pos": 166, "type": "METRIC", "confidence": 0.9988576173782349}, {"text": "recall", "start_pos": 171, "end_pos": 177, "type": "METRIC", "confidence": 0.9959296584129333}]}], "introductionContent": [{"text": "The Person Cross Document Coreference (Grishman 1994) task, which requires that all and only the textual mentions of an entity of type Person be individuated in a large collection of text documents, is one of the challenging tasks for natural language processing systems.", "labels": [], "entities": [{"text": "Person Cross Document Coreference (Grishman 1994) task", "start_pos": 4, "end_pos": 58, "type": "TASK", "confidence": 0.7655118538273705}]}, {"text": "In the most general case the corpus itself is the only available source of information regarding the persons mentioned and we consider that this is the casein this paper.", "labels": [], "entities": []}, {"text": "A PCDC system must be able to use the information existing in the corpus in order to assign to each personal name mention (PNM) apiece of context.", "labels": [], "entities": []}, {"text": "The coreference of any two PNMs is decided mainly on the basis of the similarity of the pieces of contexts associated with them.", "labels": [], "entities": []}, {"text": "A successful PCDC must accurately extract the relevant context for coreference.", "labels": [], "entities": [{"text": "coreference", "start_pos": 67, "end_pos": 78, "type": "TASK", "confidence": 0.9795305132865906}]}, {"text": "However, the context relevance is not absolute.", "labels": [], "entities": []}, {"text": "Whether the contextual information uniquely individuates a person is a matter of probability.", "labels": [], "entities": []}, {"text": "This paper presents a statistical technique developed to provide a PCDC system with more information regarding the probability of a correct coreference.", "labels": [], "entities": []}, {"text": "The reason for developing this technique is twofold: (i) the relevant coreference context depends on the corpus itself and (ii) valid coreferences require a large amount of information, which is unavailable in the majority of cases.", "labels": [], "entities": []}, {"text": "The first reason is linked to a particularity of the CDC task that makes it more complex than other NLP tasks.", "labels": [], "entities": []}, {"text": "Unlike in other disambiguation tasks, in the CDC tasks the relevant coreference context depends on the corpus itself.", "labels": [], "entities": []}, {"text": "In word sense disambiguation, for instance, the distribution of the relevant context is mainly regulated by strong syntactic and semantic rules.", "labels": [], "entities": [{"text": "word sense disambiguation", "start_pos": 3, "end_pos": 28, "type": "TASK", "confidence": 0.7099601924419403}]}, {"text": "The existence of such rules makes it possible for the disambiguation decisions to be made considering the local context.", "labels": [], "entities": []}, {"text": "On the other hand, the distribution of the PNMs in a corpus is rather random and the relevant coreference context is a dynamic variable depending on the diversity of the corpus, that is, on how many different persons with the same name share a similar context.", "labels": [], "entities": []}, {"text": "To exemplify, consider the name \"John Smith\" and an organization, say \"U.N.\".", "labels": [], "entities": [{"text": "John Smith", "start_pos": 33, "end_pos": 43, "type": "DATASET", "confidence": 0.8828087449073792}]}, {"text": "The extent to which \"works for U.N.\" in \"John Smith works for U.N.\" is a relevant coreference context depends on the diversity of the corpus itself.", "labels": [], "entities": []}, {"text": "If in that corpus, among all the \"John Smiths\" there is only one person who works for \"U.N.\" then \"works for U.N.\" is a relevant coreference context, but if there are many \"John Smiths\" working for U.N., then \"works for U.N.\" is not a relevant coreference system; in this last case, more contextual evidence is needed in order to correctly corefer the \"John Smith\" PNMs.", "labels": [], "entities": []}, {"text": "The relevance of a context for coreference also depends on the corpus, not only on the specific relationship that exists between \"John Smith\" and \"works for U.N.\".", "labels": [], "entities": [{"text": "coreference", "start_pos": 31, "end_pos": 42, "type": "TASK", "confidence": 0.9804746508598328}, {"text": "John Smith\"", "start_pos": 130, "end_pos": 141, "type": "DATASET", "confidence": 0.9199587305386862}]}, {"text": "Thus, A PCDC system must have access to global information regarding the PNMs.", "labels": [], "entities": []}, {"text": "The second reason comes from practical considerations.", "labels": [], "entities": []}, {"text": "The amount of information required to correctly infer PNMs coreferences is not present in corpus in a computationally friendly way.", "labels": [], "entities": []}, {"text": "In many cases the relevant coreference information is embedded in semantic and ontological deep inferences, which are difficult to program In as much as 60% of the cases, two documents containing the same name, from a news corpus, lack contexts which are directly similar and big enough to correctly decide on the coreference.", "labels": [], "entities": []}, {"text": "We propose anew method to control the amount of contextual coreference required for correct coreferences.", "labels": [], "entities": []}, {"text": "Rather than having fixed rules deciding on the size of the context surrounding a PNM, we propose a probabilistic approach that requires contextual evidence for coreference differentially, by considering the prior probability of the coreference of two PNMs; the higher this probability is, the less their correct coreference depends on the context and vice versa.", "labels": [], "entities": []}, {"text": "We present a statistical model where the prior coreference probabilities are computed considering only the corpus itself, and we show how these probabilities are used by a PCDC system that dynamically revises the amount of context relevant for coreference.", "labels": [], "entities": []}, {"text": "In Section 2 we review the CDC relevant literature.", "labels": [], "entities": [{"text": "CDC relevant literature", "start_pos": 27, "end_pos": 50, "type": "DATASET", "confidence": 0.8949737747510275}]}, {"text": "In section 3 we analyze the data from annotated coreference corpora and we individuate a specific problem, setting up a working hypothesis.", "labels": [], "entities": []}, {"text": "In Section 4 we develop a statistical model for computing the prior coreference probabilities and in Section 5 we present the results obtained by applying it to a large news corpus.", "labels": [], "entities": []}, {"text": "In section 6 a direct evaluation on CDC is carried on a test corpus.", "labels": [], "entities": [{"text": "CDC", "start_pos": 36, "end_pos": 39, "type": "DATASET", "confidence": 0.9326762557029724}]}, {"text": "In Section 7 we show how the proposed techniques extends naturally to a strategy of construction relevant test corpora for CDC task.", "labels": [], "entities": []}, {"text": "The paper ends with the Conclusion and the Future Research section.", "labels": [], "entities": []}], "datasetContent": [{"text": "The (p, \u03b3) technique could be used for constructing a test corpus for the CDC task.", "labels": [], "entities": []}, {"text": "The main problem faced in the construction of the test corpus is data variation.", "labels": [], "entities": []}, {"text": "The number of different entities mentioned with the same name is a random variable with a big variance.", "labels": [], "entities": []}, {"text": "The distribution of the number of entities is very skew.", "labels": [], "entities": []}, {"text": "The average perplexity is 2.01%, but less than 18% of the total number of names have a perplexity greater than 3.", "labels": [], "entities": []}, {"text": "In we plot a modified Lorenz curve (the vertical axis is not divided in percentage, as the values are discrete).", "labels": [], "entities": []}, {"text": "The direct consequence of this situation is the fact that constructing an evaluation corpus by taking random names will result with a great probability in a very skew test corpus.", "labels": [], "entities": []}, {"text": "Indeed, the expectation is that in such corpus, the average perplexity is very low, and consequently, the great majority of cases can be coreferenced by a simple algorithm.", "labels": [], "entities": []}, {"text": "Therefore, this test corpus maybe largely ineffective in ranking the algorithms.", "labels": [], "entities": []}, {"text": "In fact, we want to construct an evaluation corpus that is able to promote the most effective algorithms.", "labels": [], "entities": []}, {"text": "The discriminative power of a test corpus is directly related to the variance of the data.", "labels": [], "entities": []}, {"text": "Moreover, if only certain names are considered fora test corpus, the variance can be very low; in particular, when the test corpus contains just one name the variance is zero.", "labels": [], "entities": []}, {"text": "It is difficult to seethe merits of different algorithms when tested on such corpora.", "labels": [], "entities": []}, {"text": "In order to make more informative statements we need to construct an evaluation corpus that is less dependent on the data variance.", "labels": [], "entities": []}, {"text": "A possible solution is to form a partition of the set of the PNMs, that is, to split the whole set of PNMs in mutual disjunctive groups.", "labels": [], "entities": []}, {"text": "This type of methodology is called stratified sampling, mainly because each group is a stratum.", "labels": [], "entities": []}, {"text": "The sampling strategy, the number of sampling elements, the variance and the sampling error can be calculated independently for each strata.", "labels": [], "entities": [{"text": "sampling error", "start_pos": 77, "end_pos": 91, "type": "METRIC", "confidence": 0.8638010025024414}]}, {"text": "The main advantages of stratified sampling are that we can concentrate on the special groups, that in general this strategy improves the accuracy of the estimation, and that the number of elements in each stratum can be conveniently chosen.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 137, "end_pos": 145, "type": "METRIC", "confidence": 0.9991523027420044}]}, {"text": "The main disadvantages are related to the difficulty in finding a suitable partition of the population.", "labels": [], "entities": []}, {"text": "The strata should be chosen prior to the sampling time, but the homogeneity inside the stratum should be guaranteed.", "labels": [], "entities": []}, {"text": "Our proposal is to use the name perplexity intervals.", "labels": [], "entities": []}, {"text": "We argue that this proposal is four-fold sustainable.", "labels": [], "entities": []}, {"text": "Firstly, the name perplexity is directly connected to the random variable whose distribution we estimate, namely the number of entities.", "labels": [], "entities": []}, {"text": "Secondly, for free names it can be computed off -line.", "labels": [], "entities": []}, {"text": "Thirdly, it gives us an independent and formally correct way to make a partition.", "labels": [], "entities": []}, {"text": "Fourthly, it easily allows a separation between the important and unimportant cases.", "labels": [], "entities": []}, {"text": "To begin with, let us suppose we have a name that has n occurrences in the Adige 500K.", "labels": [], "entities": [{"text": "Adige 500K", "start_pos": 75, "end_pos": 85, "type": "DATASET", "confidence": 0.9784851968288422}]}, {"text": "If n is relatively large, than we can be sure that there are some dominant entities that maybe represented by the majority of PNMs that have this name as value.", "labels": [], "entities": []}, {"text": "However, it is unknown whether then comes from the fact that there are indeed some dominant entities or whether the name by itself is a frequently used name.", "labels": [], "entities": []}, {"text": "In order to deal with the differences between frequency vs. perplexity, we propose to build a matrix defined by the frequency classes as rows and perplexity classes as columns.", "labels": [], "entities": []}, {"text": "In we present this matrix.", "labels": [], "entities": []}, {"text": "The number of different names in each of the cells of the matrix may differ according to the departure of the normal distribution of each stratum.", "labels": [], "entities": []}, {"text": "In general, if the real distribution is normal, then as much as ten examples are sufficient.", "labels": [], "entities": []}, {"text": "Otherwise, for not very skew distributions, which we expect most of the strata to have, an average of 30 examples should suffice.", "labels": [], "entities": []}, {"text": "In same cases, as the normal distribution can be appropriately sampled when both Np and N(1-p) are grater than five -where p is the ratio perplexity/frequency and N the sample dimension -the number of elements in the cell maybe around 200, by a maximal rough estimation.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2. Name perplexity and context", "labels": [], "entities": [{"text": "Name perplexity", "start_pos": 10, "end_pos": 25, "type": "TASK", "confidence": 0.8545697927474976}]}, {"text": " Table 5. (p, \u03b3, p inside, \u03b3 inside ) values", "labels": [], "entities": []}]}