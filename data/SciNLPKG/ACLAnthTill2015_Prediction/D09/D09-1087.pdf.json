{"title": [{"text": "Self-Training PCFG Grammars with Latent Annotations Across Languages", "labels": [], "entities": [{"text": "Self-Training PCFG Grammars", "start_pos": 0, "end_pos": 27, "type": "TASK", "confidence": 0.5041422247886658}]}], "abstractContent": [{"text": "We investigate the effectiveness of self-training PCFG grammars with latent annotations (PCFG-LA) for parsing languages with different amounts of labeled training data.", "labels": [], "entities": []}, {"text": "Compared to Charniak's lexicalized parser, the PCFG-LA parser was more effectively adapted to a language for which parsing has been less well developed (i.e., Chinese) and benefited more from self-training.", "labels": [], "entities": [{"text": "PCFG-LA", "start_pos": 47, "end_pos": 54, "type": "DATASET", "confidence": 0.9048901796340942}]}, {"text": "We show for the first time that self-training is able to significantly improve the performance of the PCFG-LA parser, a single generative parser, on both small and large amounts of labeled training data.", "labels": [], "entities": []}, {"text": "Our approach achieves state-of-the-art parsing accuracies fora single parser on both English (91.5%) and Chi-nese (85.2%).", "labels": [], "entities": []}], "introductionContent": [{"text": "There is an extensive research literature on building high quality parsers for English), however, models for parsing other languages are less well developed.", "labels": [], "entities": []}, {"text": "Take Chinese for example; there have been several attempts to develop accurate parsers for Chinese, but the state-of-the-art performance, around 83% F measure on Penn Chinese Treebank (achieved by the Berkeley parser () falls far short of performance on English (\u223c90-92%).", "labels": [], "entities": [{"text": "F measure", "start_pos": 149, "end_pos": 158, "type": "METRIC", "confidence": 0.981144905090332}, {"text": "Penn Chinese Treebank", "start_pos": 162, "end_pos": 183, "type": "DATASET", "confidence": 0.9754188060760498}]}, {"text": "As pointed out in (, there are many linguistic differences between Chinese and English, as well as structural differences between their corresponding treebanks, and some of these make it a harder task to parse Chinese.", "labels": [], "entities": []}, {"text": "Additionally, the fact that the available treebanked Chinese materials are more limited than for English also increases the challenge of building high quality Chinese parsers.", "labels": [], "entities": []}, {"text": "Many of these differences would also tend to apply to other less well investigated languages.", "labels": [], "entities": []}, {"text": "In this paper, we focus on English and Chinese because the former is a language for which extensive parsing research has been conducted while the latter is a language that has been less extensively studied.", "labels": [], "entities": []}, {"text": "We adapt and improve the Berkeley parser, which learns PCFG grammars with latent annotations, and show through comparative studies that this parser significantly outperforms Charniak's parser, which was initially developed for English and subsequently ported to Chinese.", "labels": [], "entities": []}, {"text": "We focus on answering two questions: how well does a parser perform across languages and how much does it benefit from self-training?", "labels": [], "entities": []}, {"text": "The first question is of special interest when choosing a parser that is designed for one language and adapting it to another less studied language.", "labels": [], "entities": []}, {"text": "We improve the PCFG-LA parser by adding a language-independent method for handling rare words and adapt it to another language, Chinese, by creating a method to better model Chinese unknown words.", "labels": [], "entities": [{"text": "PCFG-LA parser", "start_pos": 15, "end_pos": 29, "type": "TASK", "confidence": 0.6954105198383331}]}, {"text": "Our results show that the PCFG-LA parser performs significantly better than Charniak's parser on Chinese, and is also somewhat more accurate on English, although both parsers have high accuracy.", "labels": [], "entities": [{"text": "PCFG-LA parser", "start_pos": 26, "end_pos": 40, "type": "TASK", "confidence": 0.5924711674451828}, {"text": "accuracy", "start_pos": 185, "end_pos": 193, "type": "METRIC", "confidence": 0.9968998432159424}]}, {"text": "The second question is important because labeled training data is often quite limited, especially for less well investigated languages, while unlabeled data is ubiquitous.", "labels": [], "entities": []}, {"text": "Early investigations on self-training for parsing have had mixed results.", "labels": [], "entities": [{"text": "parsing", "start_pos": 42, "end_pos": 49, "type": "TASK", "confidence": 0.9785382151603699}]}, {"text": "reported no improvements from self-training a PCFG parser on the standard WSJ training set.", "labels": [], "entities": [{"text": "WSJ training set", "start_pos": 74, "end_pos": 90, "type": "DATASET", "confidence": 0.9171139995257059}]}, {"text": "reported some degradation using a lexicalized tree adjoining grammar parser and minor improvement using Collins lexicalized PCFG parser; however, this gain was obtained only when the parser was trained on a small labeled set.", "labels": [], "entities": []}, {"text": "obtained significant gains using Collins lexicalized parser with a different selftraining protocol, but again they only looked at small labeled sets.", "labels": [], "entities": []}, {"text": "effectively utilized unlabeled data to improve parsing accuracy on the standard WSJ training set, but they used a two-stage parser comprised of Charniak's lexicalized probabilistic parser with n-best parsing and a discriminative reranking parser), and thus it would be better categorized as \"co-training\".", "labels": [], "entities": [{"text": "parsing", "start_pos": 47, "end_pos": 54, "type": "TASK", "confidence": 0.9474267959594727}, {"text": "accuracy", "start_pos": 55, "end_pos": 63, "type": "METRIC", "confidence": 0.9383912682533264}, {"text": "WSJ training set", "start_pos": 80, "end_pos": 96, "type": "DATASET", "confidence": 0.8949922521909078}]}, {"text": "It is worth noting that their attempts at selftraining Charniak's lexicalized parser directly resulted in no improvement.", "labels": [], "entities": []}, {"text": "There are other successful semi-supervised training approaches for dependency parsing, such as (, and it would be interesting to investigate how they could be applied to constituency parsing.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 67, "end_pos": 85, "type": "TASK", "confidence": 0.843051940202713}, {"text": "constituency parsing", "start_pos": 170, "end_pos": 190, "type": "TASK", "confidence": 0.8650860488414764}]}, {"text": "We show in this paper, for the first time, that self-training is able to significantly improve the performance of the PCFG-LA parser, a single generative parser, on both small and large amounts of labeled training data, for both English and Chinese.", "labels": [], "entities": []}, {"text": "With self-training, a fraction of the WSJ or CTB6 treebank training data is sufficient to train a PCFG-LA parser that is able to achieve or even beat the accuracies obtained using a single parser trained on the entire treebank without selftraining.", "labels": [], "entities": [{"text": "WSJ", "start_pos": 38, "end_pos": 41, "type": "DATASET", "confidence": 0.9198735356330872}, {"text": "CTB6 treebank training data", "start_pos": 45, "end_pos": 72, "type": "DATASET", "confidence": 0.9212413877248764}]}, {"text": "We conjecture based on our comparison of the PCFG-LA parser to Charniak's parser that the addition of self-training data helps the former parser learn more fine-grained latent annotations without over-fitting.", "labels": [], "entities": [{"text": "PCFG-LA", "start_pos": 45, "end_pos": 52, "type": "DATASET", "confidence": 0.9098493456840515}]}, {"text": "The rest of this paper is organized as follows.", "labels": [], "entities": []}, {"text": "We describe the PCFG-LA parser and several enhancements in Section 2, and discuss self-training in Section 3.", "labels": [], "entities": [{"text": "PCFG-LA", "start_pos": 16, "end_pos": 23, "type": "DATASET", "confidence": 0.8735424280166626}]}, {"text": "We then outline the experimental setup in Section 4, describe the results in Section 5, and present a detailed analysis in Section 6.", "labels": [], "entities": []}, {"text": "The last section draws conclusions and describes future work.", "labels": [], "entities": []}], "datasetContent": [{"text": "For the English experiments, sections from the WSJ Penn Treebank are used as labeled training data: section 2-19 for training, section 22 for development, and section 23 as the test set.", "labels": [], "entities": [{"text": "WSJ Penn Treebank", "start_pos": 47, "end_pos": 64, "type": "DATASET", "confidence": 0.9221349159876505}]}, {"text": "We also used 210k 4 sentences of unlabeled news articles in the BLLIP corpus for English self-training.", "labels": [], "entities": [{"text": "BLLIP corpus", "start_pos": 64, "end_pos": 76, "type": "DATASET", "confidence": 0.9392118752002716}]}, {"text": "For the Chinese experiments, the Penn Chinese Treebank 6.0 (CTB6) () is used as labeled data.", "labels": [], "entities": [{"text": "Penn Chinese Treebank 6.0 (CTB6)", "start_pos": 33, "end_pos": 65, "type": "DATASET", "confidence": 0.9672222222600665}]}, {"text": "CTB6 includes both news articles and transcripts of broadcast news.", "labels": [], "entities": [{"text": "CTB6", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.9630451798439026}]}, {"text": "We partitioned the news articles into train/development/test sets following.", "labels": [], "entities": []}, {"text": "The broadcast news section is added to the training data because it shares many of the characteristics of newswire text (e.g., fully punctuated, contains nonverbal expressions such as numbers and symbols).", "labels": [], "entities": []}, {"text": "In addition, 210k sentences of unlabeled Chinese news articles are used for self-training.", "labels": [], "entities": []}, {"text": "Since the Chinese parsers in our experiments require wordsegmented sentences as input, the unlabeled sentences need to be word-segmented first.", "labels": [], "entities": []}, {"text": "As shown in, the accuracy of automatic word segmentation has a great impact on Chinese parsing performance.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 17, "end_pos": 25, "type": "METRIC", "confidence": 0.9989452958106995}, {"text": "automatic word segmentation", "start_pos": 29, "end_pos": 56, "type": "TASK", "confidence": 0.6242046356201172}, {"text": "Chinese parsing", "start_pos": 79, "end_pos": 94, "type": "TASK", "confidence": 0.7105739116668701}]}, {"text": "We chose to use the Stanford segmenter () in our experiments because it is consistent with the treebank segmentation and provides the best performance among the segmenters that were tested.", "labels": [], "entities": []}, {"text": "To minimize the discrepancy between the selftraining data and the treebank data, we normalize both CTB6 and the self-training data using UW Decatur () text normalization.", "labels": [], "entities": [{"text": "CTB6", "start_pos": 99, "end_pos": 103, "type": "DATASET", "confidence": 0.8442644476890564}, {"text": "UW Decatur () text", "start_pos": 137, "end_pos": 155, "type": "DATASET", "confidence": 0.9333479255437851}]}, {"text": "summarizes the data set sizes used in our experiments.", "labels": [], "entities": []}, {"text": "We used slightly modified versions of the treebanks; empty nodes and nonterminal-yield unary rules 5 , e.g., NP\u2192VP, are deleted using tsurgeon (: The number of sentences (and words in parentheses) in our experiments.", "labels": [], "entities": []}, {"text": "We trained parsers on 20%, 40%, 60%, 80%, and 100% of the treebank training data to evaluate This amount was constrained based on both CPU and memory.", "labels": [], "entities": []}, {"text": "We plan to investigate cloud computing to exploit more unlabeled data.", "labels": [], "entities": []}, {"text": "As nonterminal-yield unary rules are less likely to be posited by a statistical parser, it is common for parsers trained on the standard Chinese treebank to have substantially higher precision than recall.", "labels": [], "entities": [{"text": "Chinese treebank", "start_pos": 137, "end_pos": 153, "type": "DATASET", "confidence": 0.8109184205532074}, {"text": "precision", "start_pos": 183, "end_pos": 192, "type": "METRIC", "confidence": 0.9979034662246704}, {"text": "recall", "start_pos": 198, "end_pos": 204, "type": "METRIC", "confidence": 0.9967203736305237}]}, {"text": "This gap between bracket recall and precision is alleviated without loss of parse accuracy by deleting the nonterminal-yield unary rules.", "labels": [], "entities": [{"text": "recall", "start_pos": 25, "end_pos": 31, "type": "METRIC", "confidence": 0.9482076168060303}, {"text": "precision", "start_pos": 36, "end_pos": 45, "type": "METRIC", "confidence": 0.9991430044174194}, {"text": "accuracy", "start_pos": 82, "end_pos": 90, "type": "METRIC", "confidence": 0.8754405379295349}]}, {"text": "This modification similarly benefits both parsers we study here.", "labels": [], "entities": []}, {"text": "the effect of the amount of labeled training data on parsing performance.", "labels": [], "entities": [{"text": "parsing", "start_pos": 53, "end_pos": 60, "type": "TASK", "confidence": 0.9783841371536255}]}, {"text": "We also compare how selftraining impacts the models trained with different amounts of gold-standard training data.", "labels": [], "entities": []}, {"text": "This allows us to simulate scenarios where the language has limited human-labeled resources.", "labels": [], "entities": []}, {"text": "We compare models trained only on the gold labeled training data with those that utilize additional unlabeled data.", "labels": [], "entities": []}, {"text": "Self-training (PCFG-LA or Charniak) proceeds in two steps.", "labels": [], "entities": []}, {"text": "In the first step, the parser is first trained on the allocated labeled training data (e.g., 40%) and is then used to parse the unlabeled data.", "labels": [], "entities": []}, {"text": "In the second step, anew parser is trained on the weighted combination 6 of the allocated labeled training data and the additional automatically labeled data.", "labels": [], "entities": []}, {"text": "The development set is used in each step to select the grammar order with the best accuracy for the PCFG-LA parser and to tune the smoothing parameters for Charniak's parser.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 83, "end_pos": 91, "type": "METRIC", "confidence": 0.9985916018486023}]}], "tableCaptions": [{"text": " Table 2: Effects of rare word handling (+R) and  Chinese unknown handling (+U) on the test set.", "labels": [], "entities": []}, {"text": " Table 3: Final results on the test set.", "labels": [], "entities": []}]}