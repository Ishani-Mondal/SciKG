{"title": [{"text": "Improving Nominal SRL in Chinese Language with Verbal SRL In- formation and Automatic Predicate Recognition", "labels": [], "entities": [{"text": "Improving Nominal SRL", "start_pos": 0, "end_pos": 21, "type": "TASK", "confidence": 0.5622842609882355}, {"text": "SRL In- formation", "start_pos": 54, "end_pos": 71, "type": "TASK", "confidence": 0.6139820888638496}, {"text": "Automatic Predicate Recognition", "start_pos": 76, "end_pos": 107, "type": "TASK", "confidence": 0.6712219019730886}]}], "abstractContent": [{"text": "This paper explores Chinese semantic role labeling (SRL) for nominal predicates.", "labels": [], "entities": [{"text": "Chinese semantic role labeling (SRL)", "start_pos": 20, "end_pos": 56, "type": "TASK", "confidence": 0.7484693782670158}]}, {"text": "Besides those widely used features in verbal SRL, various nominal SRL-specific features are first included.", "labels": [], "entities": [{"text": "SRL", "start_pos": 45, "end_pos": 48, "type": "TASK", "confidence": 0.7515183091163635}]}, {"text": "Then, we improve the performance of nominal SRL by integrating useful features derived from a state-of-the-art verbal SRL system.", "labels": [], "entities": [{"text": "SRL", "start_pos": 44, "end_pos": 47, "type": "TASK", "confidence": 0.7664027810096741}]}, {"text": "Finally, we address the issue of automatic predicate recognition, which is essential fora nominal SRL system.", "labels": [], "entities": [{"text": "automatic predicate recognition", "start_pos": 33, "end_pos": 64, "type": "TASK", "confidence": 0.6118350327014923}, {"text": "SRL", "start_pos": 98, "end_pos": 101, "type": "TASK", "confidence": 0.9433622360229492}]}, {"text": "Evaluation on Chinese NomBank shows that our research in integrating various features derived from verbal SRL significantly improves the performance.", "labels": [], "entities": [{"text": "Chinese NomBank", "start_pos": 14, "end_pos": 29, "type": "DATASET", "confidence": 0.9209195673465729}]}, {"text": "It also shows that our nominal SRL system much outperforms the state-of-the-art ones.", "labels": [], "entities": [{"text": "SRL", "start_pos": 31, "end_pos": 34, "type": "TASK", "confidence": 0.9216874241828918}]}], "introductionContent": [{"text": "Semantic parsing maps a natural language sentence into a formal representation of its meaning.", "labels": [], "entities": [{"text": "Semantic parsing", "start_pos": 0, "end_pos": 16, "type": "TASK", "confidence": 0.8127036690711975}]}, {"text": "Due to the difficulty in deep semantic parsing, most of previous work focuses on shallow semantic parsing, which assigns a simple structure (such as WHO did WHAT to WHOM, WHEN, WHERE, WHY, HOW) to each predicate in a sentence.", "labels": [], "entities": [{"text": "deep semantic parsing", "start_pos": 25, "end_pos": 46, "type": "TASK", "confidence": 0.716843863328298}, {"text": "shallow semantic parsing", "start_pos": 81, "end_pos": 105, "type": "TASK", "confidence": 0.6846546034018198}, {"text": "WHOM", "start_pos": 165, "end_pos": 169, "type": "METRIC", "confidence": 0.7065482139587402}]}, {"text": "In particular, the well-defined semantic role labeling (SRL) task has been drawing more and more attention in recent years due to its importance in deep NLP applications, such as question answering), information extraction (, and co-reference resolution).", "labels": [], "entities": [{"text": "semantic role labeling (SRL) task", "start_pos": 32, "end_pos": 65, "type": "TASK", "confidence": 0.8345141410827637}, {"text": "question answering", "start_pos": 179, "end_pos": 197, "type": "TASK", "confidence": 0.9089388251304626}, {"text": "information extraction", "start_pos": 200, "end_pos": 222, "type": "TASK", "confidence": 0.898124098777771}, {"text": "co-reference resolution", "start_pos": 230, "end_pos": 253, "type": "TASK", "confidence": 0.7549537420272827}]}, {"text": "Given a sentence and a predicate (either a verb or a noun) in it, SRL recognizes and maps all the constituents in the sentence into their corresponding semantic arguments (roles) of the predicate.", "labels": [], "entities": [{"text": "SRL", "start_pos": 66, "end_pos": 69, "type": "TASK", "confidence": 0.9727010726928711}]}, {"text": "According to the predicate types, SRL could be divided into SRL for verbal predicates (verbal SRL, in short) and SRL for nominal predicates (nominal SRL, in short).", "labels": [], "entities": [{"text": "SRL", "start_pos": 34, "end_pos": 37, "type": "TASK", "confidence": 0.8861543536186218}, {"text": "SRL", "start_pos": 60, "end_pos": 63, "type": "METRIC", "confidence": 0.8760219216346741}]}, {"text": "During the past few years, verbal SRL has dominated the research on SRL with the availability of FrameNet (), PropBank ( , and the consecutive CoNLL shared tasks () in English language.", "labels": [], "entities": [{"text": "SRL", "start_pos": 34, "end_pos": 37, "type": "TASK", "confidence": 0.8038530945777893}, {"text": "SRL", "start_pos": 68, "end_pos": 71, "type": "TASK", "confidence": 0.9755149483680725}, {"text": "PropBank", "start_pos": 110, "end_pos": 118, "type": "DATASET", "confidence": 0.7764332890510559}]}, {"text": "As a complement to PropBank on verbal predicates, NomBank () annotates nominal predicates and their corresponding semantic roles using similar semantic framework as PropBank.", "labels": [], "entities": []}, {"text": "As a representative, pioneered the exploration of various nominal SRL-specific features besides the traditional verbal SRL-related features on NomBank.", "labels": [], "entities": []}, {"text": "They achieved the performance of 72.73 and 69.14 in F1-measure on golden and automatic syntactic parse trees, respectively, given golden nominal predicates.", "labels": [], "entities": [{"text": "F1-measure", "start_pos": 52, "end_pos": 62, "type": "METRIC", "confidence": 0.9989722967147827}]}, {"text": "For SRL in Chinese, Sun and Jurafsky (2004) and pioneered the research on Chinese verbal and nominal SRLs, respectively, on small private datasets.", "labels": [], "entities": [{"text": "SRL", "start_pos": 4, "end_pos": 7, "type": "TASK", "confidence": 0.9896376132965088}, {"text": "Chinese verbal and nominal SRLs", "start_pos": 74, "end_pos": 105, "type": "TASK", "confidence": 0.5896533846855163}]}, {"text": "Taking the advantage of recent release of Chinese PropBank and Chinese NomBank, Xue and his colleagues pioneered the exploration of Chinese verbal and nominal SRLs, given golden predicates.", "labels": [], "entities": [{"text": "Chinese PropBank", "start_pos": 42, "end_pos": 58, "type": "DATASET", "confidence": 0.8679941892623901}, {"text": "Chinese NomBank", "start_pos": 63, "end_pos": 78, "type": "DATASET", "confidence": 0.8127560615539551}]}, {"text": "Among them, Xue and Palmer (2005) studied Chinese verbal SRL using Chinese PropBank and achieved the performance of 91.3 and 61.3 in F1-measure on golden and automatic syntactic parse trees, respectively.", "labels": [], "entities": [{"text": "Chinese verbal SRL", "start_pos": 42, "end_pos": 60, "type": "TASK", "confidence": 0.45906006296475727}, {"text": "Chinese PropBank", "start_pos": 67, "end_pos": 83, "type": "DATASET", "confidence": 0.744985044002533}, {"text": "F1-measure", "start_pos": 133, "end_pos": 143, "type": "METRIC", "confidence": 0.9983525276184082}]}, {"text": "Xue (2006b) extended their study on Chinese nominal SRL and attempted to improve the performance of nominal SRL by simply in-cluding the Chinese PropBank training instances into the training data for nominal SRL on Chinese NomBank.", "labels": [], "entities": [{"text": "Chinese PropBank training instances", "start_pos": 137, "end_pos": 172, "type": "DATASET", "confidence": 0.7326508313417435}, {"text": "Chinese NomBank", "start_pos": 215, "end_pos": 230, "type": "DATASET", "confidence": 0.8236395716667175}]}, {"text": "However, such integration was empirically proven unsuccessful due to the different nature of certain features for verbal and nominal SRLs.", "labels": [], "entities": []}, {"text": "further improved the performance on both verbal and nominal SRLs with a better syntactic parser and new features.", "labels": [], "entities": []}, {"text": "focused on argument classification for Chinese verbal predicates with hierarchical feature selection strategy.", "labels": [], "entities": [{"text": "argument classification", "start_pos": 11, "end_pos": 34, "type": "TASK", "confidence": 0.77222540974617}]}, {"text": "They achieved the classification precision of 94.68% on golden parse trees on Chinese PropBank.", "labels": [], "entities": [{"text": "precision", "start_pos": 33, "end_pos": 42, "type": "METRIC", "confidence": 0.9478155970573425}, {"text": "Chinese PropBank", "start_pos": 78, "end_pos": 94, "type": "DATASET", "confidence": 0.9180007576942444}]}, {"text": "This paper focuses on Chinese nominal SRL.", "labels": [], "entities": [{"text": "Chinese nominal SRL", "start_pos": 22, "end_pos": 41, "type": "TASK", "confidence": 0.5876007775465647}]}, {"text": "This is done by adopting a traditional verbal SRL architecture to handle Chinese nominal predicates with additional nominal SRL-specific features.", "labels": [], "entities": []}, {"text": "Moreover, we significantly enhance the performance of nominal SRL by properly integrating various features derived from verbal SRL.", "labels": [], "entities": [{"text": "SRL", "start_pos": 62, "end_pos": 65, "type": "TASK", "confidence": 0.8044157028198242}]}, {"text": "Finally, this paper investigates the effect of automatic nominal predicate recognition on the performance of Chinese nominal SRL.", "labels": [], "entities": [{"text": "nominal predicate recognition", "start_pos": 57, "end_pos": 86, "type": "TASK", "confidence": 0.6706991394360861}, {"text": "Chinese nominal SRL", "start_pos": 109, "end_pos": 128, "type": "TASK", "confidence": 0.48459266622861225}]}, {"text": "Although previous research (e.g.) in English nominal SRL reveals the importance of automatic predicate recognition, there has no reported research on automatic predicate recognition in Chinese nominal SRL.", "labels": [], "entities": [{"text": "automatic predicate recognition", "start_pos": 83, "end_pos": 114, "type": "TASK", "confidence": 0.6039507488409678}, {"text": "automatic predicate recognition in Chinese nominal SRL", "start_pos": 150, "end_pos": 204, "type": "TASK", "confidence": 0.633182874747685}]}, {"text": "The rest of this paper is organized as follows: Section 2 introduces Chinese NomBank while the baseline nominal SRL system is described in Section 3 with traditional and nominal SRLspecific features.", "labels": [], "entities": [{"text": "Chinese NomBank", "start_pos": 69, "end_pos": 84, "type": "DATASET", "confidence": 0.8176354169845581}]}, {"text": "Then, the baseline nominal SRL system is improved by integrating useful features derived from verbal SRL (Section 4) and extended with automatic recognition of nominal predicates (Section 5).", "labels": [], "entities": [{"text": "SRL", "start_pos": 27, "end_pos": 30, "type": "TASK", "confidence": 0.8370296955108643}]}, {"text": "Section 6 gives experimental results and discussion.", "labels": [], "entities": []}, {"text": "Finally, Section 7 concludes the paper.", "labels": [], "entities": []}], "datasetContent": [{"text": "We have evaluated our Chinese nominal SRL system on Chinese NomBank with Chinese PropBank 2.0 as its counterpart.", "labels": [], "entities": [{"text": "SRL", "start_pos": 38, "end_pos": 41, "type": "TASK", "confidence": 0.620498538017273}, {"text": "Chinese NomBank", "start_pos": 52, "end_pos": 67, "type": "DATASET", "confidence": 0.8181940615177155}, {"text": "Chinese PropBank 2.0", "start_pos": 73, "end_pos": 93, "type": "DATASET", "confidence": 0.8621468742688497}]}, {"text": "This version of Chinese NomBank consists of standoff annotations on the files (chtb_001 to 1151.fid) of Chinese Penn TreeBank 5.1.", "labels": [], "entities": [{"text": "Chinese NomBank", "start_pos": 16, "end_pos": 31, "type": "DATASET", "confidence": 0.9011427760124207}, {"text": "Chinese Penn TreeBank 5.1", "start_pos": 104, "end_pos": 129, "type": "DATASET", "confidence": 0.9291962832212448}]}, {"text": "Following the experimental setting in Xue (2008), 648 files (chtb_081 to 899.fid) are selected as the training data, 72 files (chtb_001 to 040.fid and chtb_900 to 931.fid) are held out as the test data, and 40 files (chtb_041 to 080.fid) as the development data, with 8642, 1124, and 731 propositions, respectively.", "labels": [], "entities": []}, {"text": "As Chinese words are not naturally segmented in raw sentences, two Chinese automatic parsers are constructed: word-based parser (assuming golden word segmentation) and character-based parser (with automatic word segmentation).", "labels": [], "entities": [{"text": "golden word segmentation", "start_pos": 138, "end_pos": 162, "type": "TASK", "confidence": 0.7477927009264628}]}, {"text": "Here, Berkeley parser ( 1 is chosen as the Chinese automatic parser.", "labels": [], "entities": []}, {"text": "With regard to character-based parsing, we employ a Chinese word segmenter, similar to, to obtain the best automatic segmentation result fora given sentence, which is then fed into Berkeley parser for further syntactic parsing.", "labels": [], "entities": [{"text": "character-based parsing", "start_pos": 15, "end_pos": 38, "type": "TASK", "confidence": 0.6344897449016571}, {"text": "syntactic parsing", "start_pos": 209, "end_pos": 226, "type": "TASK", "confidence": 0.702176421880722}]}, {"text": "Both the word segmenter and Berkeley parser are developed with the same training and development datasets as our SRL experiments.", "labels": [], "entities": [{"text": "word segmenter", "start_pos": 9, "end_pos": 23, "type": "TASK", "confidence": 0.6958531439304352}]}, {"text": "The word segmenter achieves the performance of 96.1 in F1-measure while the Berkeley parser gives a performance of 82.5 and 85.5 in F1-measure on golden and automatic word segmentation, respectively 2 . In addition, SVMLight with the tree kernel function is selected as our classifier.", "labels": [], "entities": [{"text": "word segmenter", "start_pos": 4, "end_pos": 18, "type": "TASK", "confidence": 0.6956599056720734}, {"text": "F1-measure", "start_pos": 55, "end_pos": 65, "type": "METRIC", "confidence": 0.9966110587120056}, {"text": "F1-measure", "start_pos": 132, "end_pos": 142, "type": "METRIC", "confidence": 0.9878566265106201}, {"text": "word segmentation", "start_pos": 167, "end_pos": 184, "type": "TASK", "confidence": 0.727404996752739}]}, {"text": "In order to handle multi-classification Berkeley Parser.", "labels": [], "entities": [{"text": "Berkeley Parser", "start_pos": 40, "end_pos": 55, "type": "DATASET", "confidence": 0.8371102213859558}]}, {"text": "http://code.google.com/p/berkeleyparser/ 2 POSs are not counted in evaluating the performance of word-based syntactic parser, but they are counted in evaluating the performance of character-based parser.", "labels": [], "entities": []}, {"text": "Therefore the F1-measure for the later is higher than that for the former.", "labels": [], "entities": [{"text": "F1-measure", "start_pos": 14, "end_pos": 24, "type": "METRIC", "confidence": 0.999588668346405}]}, {"text": "problem in argument classification, we apply the one vs. others strategy, which builds K classifiers so as to separate one class from all others.", "labels": [], "entities": [{"text": "argument classification", "start_pos": 11, "end_pos": 34, "type": "TASK", "confidence": 0.8232090771198273}]}, {"text": "For argument identification and classification, we adopt the linear kernel and the training parameter C is fine-tuned to 0.220.", "labels": [], "entities": [{"text": "argument identification", "start_pos": 4, "end_pos": 27, "type": "TASK", "confidence": 0.9126031994819641}]}, {"text": "For automatic recognition of nominal predicates, the training parameter C and the decay factor \u03bb in the convolution tree kernel are fine-tuned to 2.0 and 0.2, respectively.", "labels": [], "entities": [{"text": "automatic recognition of nominal predicates", "start_pos": 4, "end_pos": 47, "type": "TASK", "confidence": 0.7616849780082703}]}], "tableCaptions": [{"text": " Table 5: The performance of nominal SRL on the  development data with golden parse trees and golden  nominal predicates", "labels": [], "entities": [{"text": "SRL", "start_pos": 37, "end_pos": 40, "type": "TASK", "confidence": 0.8778376579284668}]}, {"text": " Table 5 presents the SRL results  on the development data. It shows that nominal  SRL-specific features significantly improve the  performance from 67.78 to 72.55 (  )  in F1-measure.", "labels": [], "entities": [{"text": "SRL", "start_pos": 22, "end_pos": 25, "type": "METRIC", "confidence": 0.5508111119270325}, {"text": "F1-measure", "start_pos": 173, "end_pos": 183, "type": "METRIC", "confidence": 0.9798909425735474}]}, {"text": " Table 7: The performance of nominal SRL on the test  data with golden parse trees and golden nominal  predicates", "labels": [], "entities": [{"text": "SRL", "start_pos": 37, "end_pos": 40, "type": "TASK", "confidence": 0.8785296678543091}]}, {"text": " Table 9: The performance of automatic nominal  predicate recognition on the test data", "labels": [], "entities": [{"text": "nominal  predicate recognition", "start_pos": 39, "end_pos": 69, "type": "TASK", "confidence": 0.740354597568512}]}, {"text": " Table 9 also  shows that:  \ud97b\udf59 As a complement to local structural informa- tion, global features improve the performance  of automatic nominal predicate recognition  by 0.78 in F1-measure.  \ud97b\udf59 The word-based syntactic parser decreases  the F1-measure from 90.96 to 84.03, mostly  due to the POSTagging errors between NN  and VV, while the character-based syntactic  parser further drops the F1-measure by 0.69,  due to automatic word segmentation.", "labels": [], "entities": [{"text": "nominal predicate recognition", "start_pos": 135, "end_pos": 164, "type": "TASK", "confidence": 0.6283729076385498}, {"text": "F1-measure", "start_pos": 177, "end_pos": 187, "type": "METRIC", "confidence": 0.9946426153182983}, {"text": "F1-measure", "start_pos": 239, "end_pos": 249, "type": "METRIC", "confidence": 0.9952108263969421}, {"text": "F1-measure", "start_pos": 390, "end_pos": 400, "type": "METRIC", "confidence": 0.9949712753295898}, {"text": "word segmentation", "start_pos": 428, "end_pos": 445, "type": "TASK", "confidence": 0.7413670122623444}]}]}