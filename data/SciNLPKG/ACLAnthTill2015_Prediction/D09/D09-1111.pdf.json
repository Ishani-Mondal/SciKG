{"title": [], "abstractContent": [{"text": "We present a discriminative substring de-coder for transliteration.", "labels": [], "entities": []}, {"text": "This decoder extends recent approaches for discrimi-native character transduction by allowing fora list of known target-language words, an important resource for translit-eration.", "labels": [], "entities": [{"text": "discrimi-native character transduction", "start_pos": 43, "end_pos": 81, "type": "TASK", "confidence": 0.6891109148661295}]}, {"text": "Our approach improves upon Sherif and Kondrak's (2007b) state-of-the-art decoder, creating a 28.5% relative improvement in transliteration accuracy on a Japanese katakana-to-English task.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 139, "end_pos": 147, "type": "METRIC", "confidence": 0.9708367586135864}]}, {"text": "We also conduct a controlled comparison of two feature paradigms for discriminative training: indicators and hybrid generative features.", "labels": [], "entities": []}, {"text": "Surprisingly, the generative hybrid outperforms its purely discriminative counterpart, despite losing access to rich source-context features.", "labels": [], "entities": []}, {"text": "Finally, we show that machine transliterations have a positive impact on machine translation quality, improving human judgments by 0.5 on a 4-point scale.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 73, "end_pos": 92, "type": "TASK", "confidence": 0.7903391420841217}]}], "introductionContent": [{"text": "Transliteration occurs when a word is borrowed into a language with a different character set.", "labels": [], "entities": [{"text": "Transliteration", "start_pos": 0, "end_pos": 15, "type": "TASK", "confidence": 0.9439767599105835}]}, {"text": "The word is transcribed into the new character set in such away as to maintain rough phonetic correspondence; for example, the English word hip-hop becomes 2#7;#7, when transliterated into Japanese.", "labels": [], "entities": []}, {"text": "A task frequently of interest to the NLP community is backtransliteration, where one seeks the original word, given the borrowed form.", "labels": [], "entities": []}, {"text": "We investigate machine transliteration as a method to handle out-of-vocabulary items in a Japanese-to-English translation system.", "labels": [], "entities": []}, {"text": "More often than not, this will correspond to backtransliteration.", "labels": [], "entities": []}, {"text": "Our goal is to prevent the copying or deletion of Japanese words when they are missing from our statistical machine translation (SMT) system's translation tables.", "labels": [], "entities": [{"text": "copying or deletion of Japanese words", "start_pos": 27, "end_pos": 64, "type": "TASK", "confidence": 0.8393623729546865}, {"text": "statistical machine translation (SMT)", "start_pos": 96, "end_pos": 133, "type": "TASK", "confidence": 0.7750121355056763}]}, {"text": "This can have a substantial impact on the quality of SMT output, transforming translations of questionable usefulness, such as: Avoid using a 5JAK account. into the far more informative: Avoid using a Freemail account.", "labels": [], "entities": [{"text": "SMT output", "start_pos": 53, "end_pos": 63, "type": "TASK", "confidence": 0.9245911240577698}]}, {"text": "Though the techniques we present here are language-independent, we focus this study on the task of Japanese katakana-to-English backtransliteration.", "labels": [], "entities": []}, {"text": "Katakana is one of the four character types used in the Japanese writing system (along with hiragana, kanji and Roman alphabet), consisting of about 50 syllabic characters.", "labels": [], "entities": []}, {"text": "It is used primarily to spell foreign loanwords (e.g., !GL( [chokoreeto] -chocolate), and names (e.g., JS(S [kurinton] -Clinton).", "labels": [], "entities": []}, {"text": "Therefore, katakana is a strong indicator that a Japanese word can be back-transliterated.", "labels": [], "entities": []}, {"text": "However, katakana can also be used to spell scientific names of animals and plants (e.g., B [kamo] -duck), onomatopoeic expressions (e.g., [bashabasha] -splash) and foreign origin words that are not transliterations (e.g., ;! [hochikisu] -stapler).", "labels": [], "entities": [{"text": "B", "start_pos": 90, "end_pos": 91, "type": "METRIC", "confidence": 0.9770756959915161}]}, {"text": "These untransliterable cases constitute about 10% of the katakana words in our data.", "labels": [], "entities": []}, {"text": "We employ a discriminative substring decoder for machine transliteration.", "labels": [], "entities": [{"text": "machine transliteration", "start_pos": 49, "end_pos": 72, "type": "TASK", "confidence": 0.682643711566925}]}, {"text": "Following, the decoder operates on short source substrings, with each operation producing one or more target characters, as shown in  allows us to test novel methods for the use of target lexicons in discriminative character transduction, allowing our decoder to benefit from a list of known target words.", "labels": [], "entities": [{"text": "discriminative character transduction", "start_pos": 200, "end_pos": 237, "type": "TASK", "confidence": 0.7046579321225485}]}, {"text": "Perhaps more significantly, our framework allows us to test two competing styles of features: \u2022 sparse indicators, designed to capture the same channel and language modeling data collected by previous generative models, and \u2022 components of existing generative models, used as real-valued features in a discriminatively weighted, generative hybrid.", "labels": [], "entities": []}, {"text": "Note that generative hybrids are the norm in SMT, where translation scores are provided by a discriminative combination of generative models.", "labels": [], "entities": [{"text": "generative hybrids", "start_pos": 10, "end_pos": 28, "type": "TASK", "confidence": 0.8992469608783722}, {"text": "SMT", "start_pos": 45, "end_pos": 48, "type": "TASK", "confidence": 0.9924788475036621}]}, {"text": "Substring-based transliteration with a generative hybrid model is very similar to existing solutions for phrasal SMT (, operating on characters rather than words.", "labels": [], "entities": [{"text": "Substring-based transliteration", "start_pos": 0, "end_pos": 31, "type": "TASK", "confidence": 0.7948561608791351}, {"text": "SMT", "start_pos": 113, "end_pos": 116, "type": "TASK", "confidence": 0.7899673581123352}]}, {"text": "Unlike out-of-the-box phrasal SMT solutions, our generative hybrid benefits from a target a lexicon.", "labels": [], "entities": [{"text": "SMT", "start_pos": 30, "end_pos": 33, "type": "TASK", "confidence": 0.9307618141174316}]}, {"text": "As we will show, this is the difference between a weak baseline and a strong competitor.", "labels": [], "entities": []}, {"text": "We demonstrate that despite recent successes in discriminative character transduction using indicator features, our generative hybrid performs surprisingly well, producing our highest transliteration accuracies.", "labels": [], "entities": []}, {"text": "Researchers frequently compare against a phrasal SMT baseline when evaluating anew transduction technique; however, we are careful to vary only the features in our comparison.", "labels": [], "entities": [{"text": "SMT", "start_pos": 49, "end_pos": 52, "type": "TASK", "confidence": 0.9759345054626465}]}, {"text": "Confounding variables, such as alignment, decoder and training method, are held constant.", "labels": [], "entities": [{"text": "alignment", "start_pos": 31, "end_pos": 40, "type": "TASK", "confidence": 0.869728147983551}]}, {"text": "We also include a human evaluation of transliteration-augmented SMT output.", "labels": [], "entities": [{"text": "SMT output", "start_pos": 64, "end_pos": 74, "type": "TASK", "confidence": 0.8534125685691833}]}, {"text": "Though human evaluations are too expensive to allow a comparison between transliteration systems, we are able to show that adding our transliterations to a production-level SMT engine results in a substantial improvement in translation quality.", "labels": [], "entities": [{"text": "SMT", "start_pos": 173, "end_pos": 176, "type": "TASK", "confidence": 0.9763903617858887}]}], "datasetContent": [{"text": "In this section, we summarize development experiments, and then conduct a comparison on our two transliteration test sets.", "labels": [], "entities": []}, {"text": "We report 0-1 accuracy: a transliteration is only correct if it exactly matches the reference.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 14, "end_pos": 22, "type": "METRIC", "confidence": 0.9896278381347656}]}, {"text": "For the comparison experiments, we also report 10-best accuracy, where a system is correct if it includes the correct transliteration somewhere in its 10-best list.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 55, "end_pos": 63, "type": "METRIC", "confidence": 0.9262217879295349}]}, {"text": "The indicator system was tested using only operation indicators, with source context, transition and lexicon indicators added incrementally.", "labels": [], "entities": []}, {"text": "All feature types have a substantial impact, with the lexicon providing the boost needed to surpass the baseline.", "labels": [], "entities": []}, {"text": "Note that the inclusion of the five frequency bins is sufficient to decrease the overall feature count of the system by 600K, as much fewer mistakes are made during training.", "labels": [], "entities": []}, {"text": "Development of the hybrid generative system used the SK07 baseline as a starting point.", "labels": [], "entities": [{"text": "SK07 baseline", "start_pos": 53, "end_pos": 66, "type": "DATASET", "confidence": 0.9368294775485992}]}, {"text": "The result of combining its three components into a flat linear model, with all weights set to 1, is shown in as Linear SK07.", "labels": [], "entities": [{"text": "Linear SK07", "start_pos": 113, "end_pos": 124, "type": "DATASET", "confidence": 0.8302482962608337}]}, {"text": "This violation of conditional independence assumptions results in a drop inaccuracy.", "labels": [], "entities": []}, {"text": "However, the + perceptron line shows that setting the three weights with perceptron training results in a huge boost inaccuracy, nearly matching our indicator system.", "labels": [], "entities": []}, {"text": "Adding features inspired by SMT, such as PE (t|s), eliminates the gap between the two.", "labels": [], "entities": [{"text": "SMT", "start_pos": 28, "end_pos": 31, "type": "TASK", "confidence": 0.9778443574905396}, {"text": "PE", "start_pos": 41, "end_pos": 43, "type": "METRIC", "confidence": 0.9903203845024109}]}, {"text": "We use the MT-log translation pairs described in Section 4.2 as a sentence-level translation test set.", "labels": [], "entities": [{"text": "MT-log translation", "start_pos": 11, "end_pos": 29, "type": "TASK", "confidence": 0.8259888887405396}]}, {"text": "For each katakana word left untranslated by the baseline SMT engine, we generated 10-best transliteration candidates and added the katakanaEnglish pairs to the SMT system's translation table.", "labels": [], "entities": [{"text": "SMT", "start_pos": 57, "end_pos": 60, "type": "TASK", "confidence": 0.9792686104774475}, {"text": "SMT", "start_pos": 160, "end_pos": 163, "type": "TASK", "confidence": 0.9695871472358704}]}, {"text": "Perceptron scores were exponentiated, then normalized, to create probabilities, which were given to the SMT system as P (source|target); 9 all other translation features were set to log 1.", "labels": [], "entities": [{"text": "SMT", "start_pos": 104, "end_pos": 107, "type": "TASK", "confidence": 0.9757521748542786}]}, {"text": "We translated the test set with and without the augmented translation table.", "labels": [], "entities": []}, {"text": "120 sentences were randomly selected from the cases where the translations output by the two SMT systems differed, and were submitted for two types of human evaluation.", "labels": [], "entities": [{"text": "SMT", "start_pos": 93, "end_pos": 96, "type": "TASK", "confidence": 0.9813494086265564}]}, {"text": "In the absolute evaluation, each SMT output was assigned a score between 1 and 4 (1 = completely useless; 4 = perfect translation); in the relative evaluation, the evaluators were presented with a pair of SMT outputs, with and without the transliteration table, and were asked to judge if they preferred one translation over the other.", "labels": [], "entities": [{"text": "SMT output", "start_pos": 33, "end_pos": 43, "type": "TASK", "confidence": 0.8951631486415863}]}, {"text": "In both evaluation settings, the machine-translated sentences were evaluated by two native speakers of English who have no knowledge of Japanese, with access to a reference translation.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Development accuracy and model size", "labels": [], "entities": [{"text": "accuracy", "start_pos": 22, "end_pos": 30, "type": "METRIC", "confidence": 0.9959897398948669}]}, {"text": " Table 2: Test set comparisons", "labels": [], "entities": []}, {"text": " Table 1. Adding the word unigram model to  the indicator system results in slightly lower per- formance, and a much larger model. Adding the  frequency bins to the generative system does im- prove performance slightly, but attempts to com- pletely replace the generative system's word uni- gram model with frequency bins resulted in a sub- stantial drop in accuracy. 7", "labels": [], "entities": [{"text": "accuracy", "start_pos": 358, "end_pos": 366, "type": "METRIC", "confidence": 0.9993595480918884}]}, {"text": " Table 3: Relative translation evaluation  evaluator 1 preference  eval2pref +translit equal baseline sum  +translit  95  0  2  97  equal  19  1  2  22  baseline  1  0  0  1  sum  115  1  4  120", "labels": [], "entities": [{"text": "Relative translation", "start_pos": 10, "end_pos": 30, "type": "TASK", "confidence": 0.8586909770965576}]}]}