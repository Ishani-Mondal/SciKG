{"title": [{"text": "Adapting a Polarity Lexicon using Integer Linear Programming for Domain-Specific Sentiment Classification", "labels": [], "entities": [{"text": "Adapting", "start_pos": 0, "end_pos": 8, "type": "TASK", "confidence": 0.9586519598960876}, {"text": "Domain-Specific Sentiment Classification", "start_pos": 65, "end_pos": 105, "type": "TASK", "confidence": 0.6863341927528381}]}], "abstractContent": [{"text": "Polarity lexicons have been a valuable resource for sentiment analysis and opinion mining.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 52, "end_pos": 70, "type": "TASK", "confidence": 0.9776327013969421}, {"text": "opinion mining", "start_pos": 75, "end_pos": 89, "type": "TASK", "confidence": 0.8897776901721954}]}, {"text": "There area number of such lexical resources available, but it is often sub-optimal to use them as is, because general purpose lexical resources do not reflect domain-specific lexical usage.", "labels": [], "entities": []}, {"text": "In this paper , we propose a novel method based on integer linear programming that can adapt an existing lexicon into anew one to reflect the characteristics of the data more directly.", "labels": [], "entities": []}, {"text": "In particular, our method collectively considers the relations among words and opinion expressions to derive the most likely polarity of each lexical item (posi-tive, neutral, negative, or negator) for the given domain.", "labels": [], "entities": []}, {"text": "Experimental results show that our lexicon adaptation technique improves the performance of fine-grained polarity classification.", "labels": [], "entities": [{"text": "fine-grained polarity classification", "start_pos": 92, "end_pos": 128, "type": "TASK", "confidence": 0.6726167996724447}]}], "introductionContent": [{"text": "Polarity lexicons have been a valuable resource for sentiment analysis and opinion mining.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 52, "end_pos": 70, "type": "TASK", "confidence": 0.9776327013969421}, {"text": "opinion mining", "start_pos": 75, "end_pos": 89, "type": "TASK", "confidence": 0.8897776901721954}]}, {"text": "In particular, they have been an essential ingredient for finegrained sentiment analysis (e.g.,,, ).", "labels": [], "entities": [{"text": "finegrained sentiment analysis", "start_pos": 58, "end_pos": 88, "type": "TASK", "confidence": 0.7407547136147817}]}, {"text": "Even though the polarity lexicon plays an important role (Section 3.1), it has received relatively less attention in previous research.", "labels": [], "entities": []}, {"text": "In most cases, polarity lexicon construction is discussed only briefly as a preprocessing step fora sentiment analysis task (e.g.,,), but the effect of different alternative polarity lexicons is not explicitly investigated.", "labels": [], "entities": [{"text": "polarity lexicon construction", "start_pos": 15, "end_pos": 44, "type": "TASK", "confidence": 0.7429086565971375}, {"text": "sentiment analysis task", "start_pos": 100, "end_pos": 123, "type": "TASK", "confidence": 0.896857738494873}]}, {"text": "Conversely, research efforts that focus on constructing a general purpose polarity lexicon (e.g.,,,,) generally evaluate the lexicon in isolation from any potentially relevant NLP task, and it is unclear how the new lexicon might affect end-to-end performance of a concrete NLP application.", "labels": [], "entities": []}, {"text": "It might even be unrealistic to expect that there can be a general-purpose lexical resource that can be effective across all relevant NLP applications, as general-purpose lexicons will not reflect domain-specific lexical usage.", "labels": [], "entities": []}, {"text": "Indeed, note that the polarity of a particular word can carry opposite sentiment depending on the domain (e.g.,).", "labels": [], "entities": []}, {"text": "In this paper, we propose a novel method based on integer linear programming to adapt an existing polarity lexicon into anew one to reflect the characteristics of the data more directly.", "labels": [], "entities": []}, {"text": "In particular, our method considers the relations among words and opinion expressions collectively to derive the most likely polarity of each word for the given domain.", "labels": [], "entities": []}, {"text": "depicts the key insight of our approach using a bipartite graph.", "labels": [], "entities": []}, {"text": "On the left hand side, each node represents a word, and on the right hand side, each node represents an opinion expression.", "labels": [], "entities": []}, {"text": "There is an edge between a word w i and an opinion expression e j , if the word w i appears in the expression e j . We assume the possible polarity of each expression is one of the following three values: {positive, neutral, negative}, while the possible polarity of each word is one of: {positive, neutral, negative or negator}.", "labels": [], "entities": []}, {"text": "Strictly speaking, negator is not a value for polarity, but we include them in our lexicon, because valence shifters or negators have been shown to play an important role for sentiment analysis (e.g.,,,).", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 175, "end_pos": 193, "type": "TASK", "confidence": 0.9295256435871124}]}, {"text": "Typically, the ultimate goal of the sentiment analysis task is to determine the expression-level (or sentiment/ document-level) polarities, rather than the correct word-level polarities with respect to the domain.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 36, "end_pos": 54, "type": "TASK", "confidence": 0.9369795918464661}]}, {"text": "Therefore, word-level polarities can be considered as latent information.", "labels": [], "entities": []}, {"text": "In this paper, we show how we can improve the word-level polarities of a general-purpose polarity lexicon by utilizing the expression-level polarities, and in return, how the adapted word-level polarities can improve the expression-level polarities.", "labels": [], "entities": []}, {"text": "In, there are two types of relations we could exploit when adapting a general-purpose polarity lexicon into a domain-specific one.", "labels": [], "entities": []}, {"text": "The first are word-to-word relations within each expression.", "labels": [], "entities": []}, {"text": "That is, if we are not sure about the polarity of a certain word, we can still make a guess based on the polarities of other words within the same expression and knowledge of the polarity of the expression.", "labels": [], "entities": []}, {"text": "The second type of relations are word-to-expression relations: e.g., some words appear in expressions that take on a variety of polarities, while other words are associated with expressions of one polarity class or another.", "labels": [], "entities": []}, {"text": "In relation to previous research, analyzing word-to-word (intra-expression) relations is most related to techniques that determine expression-level polarity in context (e.g., ), while exploring word-to-expression (inter-expression) relations has connections to techniques that employ more of a global-view of corpus statistics (e.g.,).", "labels": [], "entities": []}, {"text": "While most previous research exploits only one or the other type of relation, we propose a unified method that can exploit both types of semantic relation, while adapting a general purpose polarity lexicon into a domain specific one.", "labels": [], "entities": []}, {"text": "We formulate our lexicon adaptation task using integer linear programming (ILP), which has been shown to be very effective when solving problems with complex constraints (e.g.,,).", "labels": [], "entities": [{"text": "lexicon adaptation task", "start_pos": 17, "end_pos": 40, "type": "TASK", "confidence": 0.811539868513743}]}, {"text": "And the word-to-word and word-to-expression relations discussed above can be encoded as soft and hard constraints in ILP.", "labels": [], "entities": []}, {"text": "Unfortunately, one class of constraint that we would like to encode (see Section 2) will require an exponentially many number of constraints when grounded into an actual ILP problem.", "labels": [], "entities": []}, {"text": "We therefore propose an approximation scheme to make the problem more practically solvable.", "labels": [], "entities": []}, {"text": "We evaluate the effect of the adapted lex- icon in the context of a concrete NLP task: expression-level polarity classification.", "labels": [], "entities": [{"text": "expression-level polarity classification", "start_pos": 87, "end_pos": 127, "type": "TASK", "confidence": 0.6750374237696329}]}, {"text": "Experimental results show that our lexicon adaptation technique improves the accuracy of two competitive expression-level polarity classifiers from 64.2% -70.4% to 67.0% -71.2%..", "labels": [], "entities": [{"text": "accuracy", "start_pos": 77, "end_pos": 85, "type": "METRIC", "confidence": 0.998967170715332}]}], "datasetContent": [{"text": "In the experiment section, we seek for answers for the following questions: Q1 What is the effect of a polarity lexicon on the expression-level polarity classification task?", "labels": [], "entities": [{"text": "Q1", "start_pos": 76, "end_pos": 78, "type": "METRIC", "confidence": 0.93764328956604}, {"text": "expression-level polarity classification task", "start_pos": 127, "end_pos": 172, "type": "TASK", "confidence": 0.7028323784470558}]}, {"text": "In particular, is it useful when using a machine learning technique that might be able to learn the necessary polarity information just based on the words in the training data, without consulting a dictionary?", "labels": [], "entities": []}, {"text": "(Section 3.1) Q2 What is the effect of an adapted polarity lexicon on the expression-level polarity classification task?", "labels": [], "entities": [{"text": "expression-level polarity classification task", "start_pos": 74, "end_pos": 119, "type": "TASK", "confidence": 0.6902878284454346}]}, {"text": "(Section 3.2) Notice that we include the neutral polarity in the polarity classification.", "labels": [], "entities": []}, {"text": "It makes our task much harder (e.g.,) than those that assume inputs are guaranteed to be either strongly positive or negative (e.g.,,).", "labels": [], "entities": []}, {"text": "But in practice, one cannot expect that a given input is strongly polar, as automatically extracted opinions are bound to be noisy.", "labels": [], "entities": []}, {"text": "Furthermore,  discuss that some opinion expressions do carry a neutral polarity.", "labels": [], "entities": []}, {"text": "We experiment with the Multi-Perspective Question Answering (MPQA) corpus ) for evaluation.", "labels": [], "entities": [{"text": "Multi-Perspective Question Answering (MPQA)", "start_pos": 23, "end_pos": 66, "type": "TASK", "confidence": 0.7581544319788615}]}, {"text": "It contains 535 newswire documents annotated with phrase-level subjectivity information.", "labels": [], "entities": []}, {"text": "We evaluate on all opinion expressions that are known to have high level of inter-annotator agreement.", "labels": [], "entities": []}, {"text": "That is, we include opinions with intensity marked as 'medium' or higher, and exclude those with annotation confidence marked as 'uncertain'.", "labels": [], "entities": []}, {"text": "To focus our study on the direct influence of the polarity lexicon upon the sentiment classification task, we assume the boundaries of the expressions are given.", "labels": [], "entities": [{"text": "sentiment classification", "start_pos": 76, "end_pos": 100, "type": "TASK", "confidence": 0.8900434374809265}]}, {"text": "However, our approach can be readily used in tandem with a system that extracts opinion expressions (e.g.,,).", "labels": [], "entities": []}, {"text": "Performance is reported using 10-fold cross-validation on 400 documents, and a separate 135 documents were used as a development set.", "labels": [], "entities": []}, {"text": "For the general-purpose polarity lexicon, we expand the polarity lexicon of  with General Inquirer dictionary as suggested by.", "labels": [], "entities": [{"text": "General Inquirer dictionary", "start_pos": 82, "end_pos": 109, "type": "DATASET", "confidence": 0.9239575068155924}]}, {"text": "We report the performance in two measures: accuracy for 3-way classification, and average error distance.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 43, "end_pos": 51, "type": "METRIC", "confidence": 0.9997019171714783}, {"text": "3-way classification", "start_pos": 56, "end_pos": 76, "type": "TASK", "confidence": 0.5121913105249405}, {"text": "average error distance", "start_pos": 82, "end_pos": 104, "type": "METRIC", "confidence": 0.8904091715812683}]}, {"text": "The reason why we consider average error distance is because classifying a positive class into a negative class is worse than classifying a positive class into a neutral one.", "labels": [], "entities": [{"text": "average error distance", "start_pos": 27, "end_pos": 49, "type": "METRIC", "confidence": 0.7480161090691885}]}, {"text": "We define the error distance between 'neutral' class and any other class as 1, while the error distance between 'positive' class and 'negative' class as 2.", "labels": [], "entities": [{"text": "error distance", "start_pos": 14, "end_pos": 28, "type": "METRIC", "confidence": 0.9684604704380035}, {"text": "error distance", "start_pos": 89, "end_pos": 103, "type": "METRIC", "confidence": 0.9513589143753052}]}, {"text": "If a predicted polarity is correct, then the error distance is 0.", "labels": [], "entities": [{"text": "error distance", "start_pos": 45, "end_pos": 59, "type": "METRIC", "confidence": 0.9770636558532715}]}, {"text": "We compute the error distance of each prediction and take the average overall predictions in the test data.", "labels": [], "entities": [{"text": "error distance", "start_pos": 15, "end_pos": 29, "type": "METRIC", "confidence": 0.9668784141540527}]}, {"text": "To verify the effect of a polarity lexicon on the expression-level polarity classification task, we experiment with simple classification-based machine learning technique.", "labels": [], "entities": [{"text": "expression-level polarity classification task", "start_pos": 50, "end_pos": 95, "type": "TASK", "confidence": 0.7000671476125717}]}, {"text": "We use the Mallet) implementation of Conditional Random Fields (CRFs) ().", "labels": [], "entities": []}, {"text": "To highlight the influence of a polarity lexicon, we compare the performance of CRFs with and without features derived from polarity lexicons.", "labels": [], "entities": []}, {"text": "Features: We encode basic features as words and lemmas for all content words in the given expression.", "labels": [], "entities": []}, {"text": "The performance of CRFs using only the basic features are given in the first row of the Table 2.", "labels": [], "entities": [{"text": "CRFs", "start_pos": 19, "end_pos": 23, "type": "TASK", "confidence": 0.915802001953125}]}, {"text": "Next we encode features derived from polarity lexicons as follows.", "labels": [], "entities": []}, {"text": "\u2022: Effect of a polarity lexicon on expressionlevel classification using CRFs \u2022 Number of positive, neutral, negative, and negators in the given expression.", "labels": [], "entities": [{"text": "expressionlevel classification", "start_pos": 35, "end_pos": 65, "type": "TASK", "confidence": 0.7751741409301758}]}, {"text": "\u2022 Number of positive (or negative) words in conjunction with number of negators.", "labels": [], "entities": []}, {"text": "\u2022 (boolean) Whether the number of positive words dominates negative ones.", "labels": [], "entities": []}, {"text": "\u2022 (boolean) Whether the number of negative words dominates positive ones.", "labels": [], "entities": []}, {"text": "\u2022 (boolean) None of the above two cases \u2022 Each of the above three boolean values in conjunction with the number of negators.", "labels": [], "entities": []}, {"text": "Results: shows the performance of CRFs with and without features that consult the general-purpose lexicon.", "labels": [], "entities": []}, {"text": "As expected, CRFs can perform reasonably well (accuracy = 63.9%) even without consulting the dictionary, by learning directly from the data.", "labels": [], "entities": [{"text": "CRFs", "start_pos": 13, "end_pos": 17, "type": "TASK", "confidence": 0.9218339920043945}, {"text": "accuracy", "start_pos": 47, "end_pos": 55, "type": "METRIC", "confidence": 0.9991376399993896}]}, {"text": "However, having the polarity lexicon boosts the performance significantly (accuracy = 70.4%), demonstrating that lexical resources are very helpful for fine-grained sentiment analysis.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 75, "end_pos": 83, "type": "METRIC", "confidence": 0.9988977909088135}, {"text": "fine-grained sentiment analysis", "start_pos": 152, "end_pos": 183, "type": "TASK", "confidence": 0.6526217758655548}]}, {"text": "The difference in performance is statistically significant by paired t-test for both accuracy (p < 0.01) and average error distance (p < 0.01).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 85, "end_pos": 93, "type": "METRIC", "confidence": 0.9995237588882446}, {"text": "average error distance", "start_pos": 109, "end_pos": 131, "type": "METRIC", "confidence": 0.816392183303833}]}, {"text": "In this section, we assess the quality of the adapted lexicon in the context of an expression-level polarity classification task.", "labels": [], "entities": [{"text": "expression-level polarity classification task", "start_pos": 83, "end_pos": 128, "type": "TASK", "confidence": 0.7376247048377991}]}, {"text": "In order to perform the lexicon adaptation via ILP, we need an expressionlevel polarity classification algorithm f (e l , L) as described in Section 2.", "labels": [], "entities": [{"text": "expressionlevel polarity classification", "start_pos": 63, "end_pos": 102, "type": "TASK", "confidence": 0.6639779408772787}]}, {"text": "According to, voting algorithms that recognize content-word negators achieve a competitive performance, so we will use a variant of it for simplicity.", "labels": [], "entities": []}, {"text": "Because none of the algorithms proposed by is designed to handle the neutral polarity, we invent our own version as shown in.", "labels": [], "entities": []}, {"text": "It might look a bit complex at first glance, but the intuition is simple.", "labels": [], "entities": []}, {"text": "The variable f F lipP olarity determines whether we need to flip the overall majority polarity based on the number of negators in the given expression.", "labels": [], "entities": []}, {"text": "If the positive (or negative) polarity words dominate the given expression, and if there is no need to flip the majority polarity, then we take the positive (or negative) polarity as the overall polarity.", "labels": [], "entities": []}, {"text": "If the positive (or negative) polarity words dominate the given expression, and if we need to flip the majority polarity, then we take the negative (or neutral) polarity as the overall polarity.", "labels": [], "entities": []}, {"text": "Notice that the result of flipping the negative polarity is neutral, not positive.", "labels": [], "entities": []}, {"text": "In our pilot study, we found that this strategy works better than flipping the negative polarity to positive.", "labels": [], "entities": []}, {"text": "6 Finally, if the number of positive words and the negative words tie, and there is any neutral word, then we assign the neutral polarity.", "labels": [], "entities": []}, {"text": "In this case, we don't worry if there is a negator, because flipping a neutral polarity would still result in a neutral polarity.", "labels": [], "entities": []}, {"text": "If none of above condition is met, than we default to the most prominent polarity of the data, which is the negative polarity in the MPQA corpus.", "labels": [], "entities": [{"text": "MPQA corpus", "start_pos": 133, "end_pos": 144, "type": "DATASET", "confidence": 0.9821536242961884}]}, {"text": "We name this simple algorithm as Vote & Flip algorithm.", "labels": [], "entities": []}, {"text": "The performance is shown in the first row in.", "labels": [], "entities": []}, {"text": "Next we describe the implementation part of the ILP.", "labels": [], "entities": []}, {"text": "For 10 fold-cross validation, we formulate the ILP problem using the training data (360 documents), and then test the effect of the adapted lexicon on the remaining 40 documents.", "labels": [], "entities": []}, {"text": "We include only those content words that appeared more than 3 times in the training data.", "labels": [], "entities": []}, {"text": "From the pilot test using the development set, we picked the value of w \u03b2 as 0.1.", "labels": [], "entities": []}, {"text": "We found that having the auxiliary variables \u03b1 l which allow more than one polarity per word does not necessarily help with the performance, so we omitted them.", "labels": [], "entities": []}, {"text": "We suspect it is because the polarity classifiers we experimented with is not highly capable of disambiguating different lexical usages and select the right polarity fora given context.", "labels": [], "entities": []}, {"text": "We use CPLEX integer programming solver to solve our ILP problems.", "labels": [], "entities": [{"text": "CPLEX integer programming solver", "start_pos": 7, "end_pos": 39, "type": "TASK", "confidence": 0.7629851400852203}]}, {"text": "On a machine with 4GHz CPU, it took several minutes to solve each ILP problem.", "labels": [], "entities": []}, {"text": "In order to assess the effect of the adapted lexicon using CRFs, we need to first train the CRFs model.", "labels": [], "entities": []}, {"text": "Using the same training set used for the lexicon adaptation would be suboptimal, because the features generated from the adapted lexicon will be unrealistically good in that particular data.", "labels": [], "entities": []}, {"text": "Therefore, we prepared a separate training data for CRFs using 135 documents from the development set.", "labels": [], "entities": []}, {"text": "Results: shows the comparison of the original lexicon and the adapted lexicon in terms of polarity classification performance using the Vote & Flip algorithm.", "labels": [], "entities": [{"text": "polarity classification", "start_pos": 90, "end_pos": 113, "type": "TASK", "confidence": 0.7071749418973923}]}, {"text": "The adapted lexicon improves the accuracy as well as reducing the average error distance.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 33, "end_pos": 41, "type": "METRIC", "confidence": 0.999327540397644}]}, {"text": "The difference in performance is statistically significant by paired t-test for both accuracy (p < 0.01) and average error distance (p < 0.01).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 85, "end_pos": 93, "type": "METRIC", "confidence": 0.9995237588882446}, {"text": "average error distance", "start_pos": 109, "end_pos": 131, "type": "METRIC", "confidence": 0.816392183303833}]}, {"text": "shows the comparison of the original lexicon and the adapted lexicon using CRFs.", "labels": [], "entities": []}, {"text": "The improvement is not as substantial as that of Vote & Flip algorithm but the difference in performance is also statistically significant for both accuracy (p = 0.03) and average error distance (p = 0.04).: Effect of an adapted polarity lexicon on expression-level classification using CRFs", "labels": [], "entities": [{"text": "accuracy", "start_pos": 148, "end_pos": 156, "type": "METRIC", "confidence": 0.9992623925209045}, {"text": "average error distance", "start_pos": 172, "end_pos": 194, "type": "METRIC", "confidence": 0.8678985436757406}, {"text": "expression-level classification", "start_pos": 249, "end_pos": 280, "type": "TASK", "confidence": 0.6697608828544617}]}], "tableCaptions": [{"text": " Table 2: Effect of a polarity lexicon on expression- level classification using CRFs", "labels": [], "entities": [{"text": "expression- level classification", "start_pos": 42, "end_pos": 74, "type": "TASK", "confidence": 0.6268141195178032}]}, {"text": " Table 3: Effect of an adapted polarity lexicon on  expression-level classification using the Vote &  Flip Algorithm", "labels": [], "entities": [{"text": "expression-level classification", "start_pos": 52, "end_pos": 83, "type": "TASK", "confidence": 0.7152172029018402}]}, {"text": " Table 4: Effect of an adapted polarity lexicon on  expression-level classification using CRFs", "labels": [], "entities": [{"text": "expression-level classification", "start_pos": 52, "end_pos": 83, "type": "TASK", "confidence": 0.6946122050285339}]}]}