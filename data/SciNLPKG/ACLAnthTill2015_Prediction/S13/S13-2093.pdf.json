{"title": [{"text": "BOUNCE: Sentiment Classification in Twitter using Rich Feature Sets", "labels": [], "entities": [{"text": "BOUNCE", "start_pos": 0, "end_pos": 6, "type": "METRIC", "confidence": 0.9592539668083191}, {"text": "Sentiment Classification", "start_pos": 8, "end_pos": 32, "type": "TASK", "confidence": 0.9721098840236664}]}], "abstractContent": [{"text": "The widespread use of Twitter makes it very interesting to determine the opinions and the sentiments expressed by its users.", "labels": [], "entities": []}, {"text": "The shortness of the length and the highly informal nature of tweets render it very difficult to automatically detect such information.", "labels": [], "entities": []}, {"text": "This paper reports the results to a challenge, set forth by SemEval-2013 Task 2, to determine the positive , neutral, or negative sentiments of tweets.", "labels": [], "entities": []}, {"text": "Two systems are explained: System A for determining the sentiment of a phrase within a tweet and System B for determining the sentiment of a tweet.", "labels": [], "entities": []}, {"text": "Both approaches rely on rich feature sets, which are explained in detail.", "labels": [], "entities": []}], "introductionContent": [{"text": "Twitter consists of a massive number of posts on a wide range of subjects, making it very interesting to extract information and sentiments from them.", "labels": [], "entities": []}, {"text": "For example, answering questions like 'What do Twitter users feel about the brand X?' are quite interesting.", "labels": [], "entities": []}, {"text": "The constrained length and highly informal nature of tweets presents a serious challenge for the automated extraction of such sentiments.", "labels": [], "entities": [{"text": "automated extraction", "start_pos": 97, "end_pos": 117, "type": "TASK", "confidence": 0.6986314952373505}]}, {"text": "Twitter supports special tokens (i.e. mentions and hashtags), which have been utilized to determine the sentiment of tweets.", "labels": [], "entities": []}, {"text": "In (, emoticons are used to label tweets.", "labels": [], "entities": []}, {"text": "In (, Twitter emoticons as well as hashtags are used to label tweets.", "labels": [], "entities": []}, {"text": "O' demonstrated a correlation between sentiments identified in public opinion polls and those in tweets.", "labels": [], "entities": [{"text": "O'", "start_pos": 0, "end_pos": 2, "type": "DATASET", "confidence": 0.8442198634147644}]}, {"text": "A subjectivity \u2020 These authors contributed equally to this work lexicon was used to identify the positive and negative words in a tweet.", "labels": [], "entities": []}, {"text": "In (, subjective tweets are used for sentiment classification.", "labels": [], "entities": [{"text": "sentiment classification", "start_pos": 37, "end_pos": 61, "type": "TASK", "confidence": 0.9554308354854584}]}, {"text": "They propose the use of word specific (e.g. POS tags) and tweet specific (e.g. presence of a link) features.", "labels": [], "entities": []}, {"text": "Most of these studies use their own annotated data sets for evaluation, which makes it difficult to compare the performances of their proposed approaches.", "labels": [], "entities": []}, {"text": "Sentiment Analysis in Twitter 2013 (SemEval 2013 Task 2) () presented a challenge for exploring different approaches examining sentiments conveyed in tweets: interval-level (phrase-level) sentiment classification (TaskA) and message-level sentiment classification (TaskB).", "labels": [], "entities": [{"text": "Sentiment Analysis in Twitter 2013 (SemEval 2013 Task", "start_pos": 0, "end_pos": 53, "type": "TASK", "confidence": 0.7623739971054925}, {"text": "phrase-level) sentiment classification", "start_pos": 174, "end_pos": 212, "type": "TASK", "confidence": 0.6436398029327393}, {"text": "message-level sentiment classification", "start_pos": 225, "end_pos": 263, "type": "TASK", "confidence": 0.6533767481644949}]}, {"text": "Sentiment are considered as positive, negative, or neutral.", "labels": [], "entities": []}, {"text": "For TaskA, the goal is to determine the sentiment of an interval (consecutive word sequence) within a tweet.", "labels": [], "entities": []}, {"text": "For TaskB, the goal is to determine sentiment of an entire tweet.", "labels": [], "entities": []}, {"text": "For example, let's consider a tweet like 'Can't wait until the DLC for ME3 comes out tomorrow.", "labels": [], "entities": []}, {"text": "For TaskA, the interval 0-1 (Can't wait) is 'positive' and the interval 10-10 (:-)) is 'positive'.", "labels": [], "entities": []}, {"text": "For TaskB, this tweet is 'positive'.", "labels": [], "entities": []}, {"text": "In this paper, we present two systems, one for TaskA and one for TaskB.", "labels": [], "entities": []}, {"text": "In both cases machine learning methods were utilized with rich feature sets based on the characteristics of tweets.", "labels": [], "entities": []}, {"text": "Our results suggest that our approach is promising for sentiment classification in Twitter.", "labels": [], "entities": [{"text": "sentiment classification", "start_pos": 55, "end_pos": 79, "type": "TASK", "confidence": 0.9566667973995209}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 2: Number of instances used in TaskA and TaskB", "labels": [], "entities": []}, {"text": " Table 3: Macro-averaged F-Score on the TaskA dev. set", "labels": [], "entities": [{"text": "F-Score", "start_pos": 25, "end_pos": 32, "type": "METRIC", "confidence": 0.9691417217254639}, {"text": "TaskA dev. set", "start_pos": 40, "end_pos": 54, "type": "DATASET", "confidence": 0.9666285961866379}]}, {"text": " Table 4: Macro-averaged F-Score on the TaskB dev. set", "labels": [], "entities": [{"text": "F-Score", "start_pos": 25, "end_pos": 32, "type": "METRIC", "confidence": 0.9695586562156677}, {"text": "TaskB dev. set", "start_pos": 40, "end_pos": 54, "type": "DATASET", "confidence": 0.9763937741518021}]}, {"text": " Table 5: Results on the test sets for both tasks", "labels": [], "entities": []}]}