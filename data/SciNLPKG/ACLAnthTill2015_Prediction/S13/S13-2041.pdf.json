{"title": [{"text": "GETALP: Propagation of a Lesk Measure through an Ant Colony Algorithm", "labels": [], "entities": [{"text": "GETALP", "start_pos": 0, "end_pos": 6, "type": "DATASET", "confidence": 0.4871858060359955}]}], "abstractContent": [{"text": "This article presents the GETALP system for the participation to SemEval-2013 Task 12, based on an adaptation of the Lesk measure propagated through an Ant Colony Algorithm, that yielded good results on the corpus of Se-meval 2007 Task 7 (WordNet 2.1) as well as the trial data for Task 12 SemEval 2013 (Ba-belNet 1.0).", "labels": [], "entities": [{"text": "GETALP", "start_pos": 26, "end_pos": 32, "type": "METRIC", "confidence": 0.8409693837165833}, {"text": "SemEval-2013 Task 12", "start_pos": 65, "end_pos": 85, "type": "TASK", "confidence": 0.7380133469899496}]}, {"text": "We approach the parameter estimation to our algorithm from two perspectives: edogenous estimation where we max-imised the sum the local Lesk scores; exoge-nous estimation where we maximised the F1 score on trial data.", "labels": [], "entities": [{"text": "F1 score", "start_pos": 194, "end_pos": 202, "type": "METRIC", "confidence": 0.9813725054264069}]}, {"text": "We proposed three runs of out system, exogenous estimation with Ba-belNet 1.1.1 synset id annotations, endoge-nous estimation with BabelNet 1.1.1 synset id annotations and endogenous estimation with WordNet 3.1 sense keys.", "labels": [], "entities": [{"text": "WordNet 3.1 sense keys", "start_pos": 199, "end_pos": 221, "type": "DATASET", "confidence": 0.9136836379766464}]}, {"text": "A bug in our implementation led to incorrect results and here, we present an amended version thereof.", "labels": [], "entities": []}, {"text": "Our system arrived third on this task and a more fine grained analysis of our results reveals that the algorithms performs best on general domain texts with as little named entities as possible.", "labels": [], "entities": []}, {"text": "The presence of many named entities leads the performance of the system to plummet greatly.", "labels": [], "entities": []}], "introductionContent": [{"text": "Out team is mainly interested in Word Sense Disambiguation (WSD) based on semantic similarity measures.", "labels": [], "entities": [{"text": "Out", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.9302916526794434}, {"text": "Word Sense Disambiguation (WSD)", "start_pos": 33, "end_pos": 64, "type": "TASK", "confidence": 0.7648712545633316}]}, {"text": "This approach to WSD is based on a local algorithm and a global algorithm.", "labels": [], "entities": [{"text": "WSD", "start_pos": 17, "end_pos": 20, "type": "TASK", "confidence": 0.9548169374465942}]}, {"text": "The local algorithm corresponds to a semantic similarity measure (for example (, or), while the global algorithm propagates the values resulting from these measures at the level of a text, in order to disambiguate the words that compose it.", "labels": [], "entities": []}, {"text": "For two years, now, our team has focussed on researching global algorithms.", "labels": [], "entities": []}, {"text": "The local algorithm we use, a variant of the Lesk algorithm that we have evaluated with several global algorithms (Simulated Annealing (SA), Genetic Algorithms (GA) and Ant Colony Algorithms (ACA)) (), has shown its robustness with WordNet 3.0.", "labels": [], "entities": []}, {"text": "For the present campaign, we chose to work with an ant colony based global algorithms that has proven its efficiency ().", "labels": [], "entities": []}, {"text": "Presently, for this, the objective is to disambiguate a set of target words (nouns) in a corpus of 13 texts in 5 Languages (English, French, German, Italian, Spanish) by providing, for each sense the appropriate sense labels.", "labels": [], "entities": []}, {"text": "The evaluation of the answers is performed by comparing them to a gold standard annotation of the corpus in all 5 languages using three possible sense inventories and thus sense tags: BabelNet 1.1.1 Synset ids (, Wikipedia page names and Wordnet sense keys.", "labels": [], "entities": []}, {"text": "Our ant colony algorithm is a stochastic algorithm that has several parameters that need to be selected and tuned.", "labels": [], "entities": []}, {"text": "Choosing the values of the parameters based on linguistic criteria remains an open and difficult problem, which is why we wanted to automatize the parameter search process.", "labels": [], "entities": []}, {"text": "There are two ways to go about this process: exogenous estima-tion, when the parameter values are selected so as to maximise the F-score on a small training annotated corpus and then used to disambiguate another corpus (weakly supervised); endogenous estimation, when the parameters are chosen so as to maximise the global similarity score on a text or corpus (unsupervised).", "labels": [], "entities": [{"text": "F-score", "start_pos": 129, "end_pos": 136, "type": "METRIC", "confidence": 0.9883185625076294}, {"text": "global similarity score", "start_pos": 316, "end_pos": 339, "type": "METRIC", "confidence": 0.6378677189350128}]}, {"text": "Our first experiment and system run consists in tuning the parameters on the trial corpus of the campaign and running the system with the BabelNet sense inventory.", "labels": [], "entities": []}, {"text": "Our second and third experiments consist in endogenous parameter estimation, the first using BabelNet as a sense inventory and the second using WordNet.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 144, "end_pos": 151, "type": "DATASET", "confidence": 0.9822531342506409}]}, {"text": "Unfortunately, the presence of an implementation issue prevented us from obtaining scores up to par with the potential of our system and thus we will present indicative results of the performance of the system after the implementation issue was fixed.", "labels": [], "entities": []}], "datasetContent": [{"text": "In the context of the BabelNet gold standard evaluation, we need to tag the words of the corpus with BabelNet synset ids.", "labels": [], "entities": []}, {"text": "Due to the slow speed of retrieving Babel synsets and extracting glosses, especially in the context of our extended Lesk Approach, we pre-generate a dictionary for each language that contains entries for each word of the corpus and then for each possible sense (as per BabelNet).", "labels": [], "entities": []}, {"text": "In the short time allotted for the competition, we restrict ourselves to building dictionaries only for the words of the corpus, but the process described can be applied to pre-generate a dictionary for the whole of BabelNet.", "labels": [], "entities": []}, {"text": "Each BabelNet synset fora word is considered as a possible sense in the dictionary.", "labels": [], "entities": []}, {"text": "For each synset we retrieve the Babel senses and retain the ones that are in the appropriate language.", "labels": [], "entities": []}, {"text": "Then, we retrieve the Glosses corresponding to each selected sense and combine them in as the definition corresponding to that particular BabelNet synset.", "labels": [], "entities": []}, {"text": "Furthermore, we also retrieve certain of the related synsets and repeat the same process so as to add the related definitions to the BabelNet synset being considered.", "labels": [], "entities": []}, {"text": "In our experiments on the test corpus, we determined that what worked best (i.e. English and French) was to use only relations coming from WordNet, all the while excluding the r, gdis, gmono relation added by BabelNet.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 139, "end_pos": 146, "type": "DATASET", "confidence": 0.9544206261634827}]}, {"text": "We observed a similar increase in disambiguation quality with the Degree (Navigli and Lapata, 2010) algorithm implementation that comes with BabelNet.", "labels": [], "entities": [{"text": "Degree", "start_pos": 66, "end_pos": 72, "type": "METRIC", "confidence": 0.956762969493866}]}, {"text": "The r relation correspond to the relations in BabelNet extracted from Wikipedia, whereas gdis and gmono corresponds to relation created using a disambiguation algorithm (respectively for monosemous and polysemous words).", "labels": [], "entities": []}, {"text": "In the context of the WordNet gold standard evaluation, we initially thought the purpose would be to annotate the corpus in all five languages with WordNet sense keys through alignments extracted from BabelNet.", "labels": [], "entities": [{"text": "WordNet gold standard evaluation", "start_pos": 22, "end_pos": 54, "type": "DATASET", "confidence": 0.9466894119977951}]}, {"text": "As a consequence, we exploited BabelNet as a resource, merely obtaining WordNet sense keys through the main senses expressed in BabelNet, that correspond to WordNet synsets.", "labels": [], "entities": []}, {"text": "Although we were able to produce annotations for all languages, as it turns out, the WordNet evaluation was merely aimed at evaluating monolingual systems that do not support BabelNet at all.", "labels": [], "entities": [{"text": "WordNet evaluation", "start_pos": 85, "end_pos": 103, "type": "DATASET", "confidence": 0.898295670747757}]}, {"text": "For reference, we subsequently generated a dictionary from WordNet only, to gauge the performance of our system on the evaluation as intended by the organisers.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 59, "end_pos": 66, "type": "DATASET", "confidence": 0.9703671932220459}]}], "tableCaptions": [{"text": " Table 1: Results after fixing the implementation is- sue for all three of our runs, compared to the Most  Frequent Sense baseline (MFS).", "labels": [], "entities": []}, {"text": " Table 2: Text by text F1 scores compared to the  MFS baseline for the English corpus (T.= Trans- lated, Gen.= General, Env.= Environment, Polit.=  Politics, Econ.= Economics, Web= Internet, Sport.=  Sports, Geo.= Geopolitics, Sci.= Science).", "labels": [], "entities": [{"text": "F1", "start_pos": 23, "end_pos": 25, "type": "METRIC", "confidence": 0.9901800155639648}, {"text": "MFS baseline", "start_pos": 50, "end_pos": 62, "type": "DATASET", "confidence": 0.8310292661190033}, {"text": "English corpus", "start_pos": 71, "end_pos": 85, "type": "DATASET", "confidence": 0.8360818326473236}, {"text": "T.= Trans- lated", "start_pos": 87, "end_pos": 103, "type": "METRIC", "confidence": 0.8262972474098206}]}, {"text": " Table 3: Detailed breakdown of F1 score per part  of speech category for Semeval-2007 Task 7, over  results resulting from a vote over 100 executions", "labels": [], "entities": [{"text": "F1 score", "start_pos": 32, "end_pos": 40, "type": "METRIC", "confidence": 0.9831672012805939}, {"text": "Semeval-2007 Task 7", "start_pos": 74, "end_pos": 93, "type": "TASK", "confidence": 0.8517174323399862}]}]}