{"title": [{"text": "UMBC EBIQUITY-CORE: Semantic Textual Similarity Systems", "labels": [], "entities": [{"text": "UMBC EBIQUITY-CORE", "start_pos": 0, "end_pos": 18, "type": "DATASET", "confidence": 0.7656258642673492}]}], "abstractContent": [{"text": "We describe three semantic text similarity systems developed for the *SEM 2013 STS shared task and the results of the corresponding three runs.", "labels": [], "entities": [{"text": "SEM 2013 STS shared task", "start_pos": 70, "end_pos": 94, "type": "TASK", "confidence": 0.5347326636314392}]}, {"text": "All of them shared a word similarity feature that combined LSA word similarity and WordNet knowledge.", "labels": [], "entities": [{"text": "LSA word similarity", "start_pos": 59, "end_pos": 78, "type": "TASK", "confidence": 0.5907997488975525}, {"text": "WordNet knowledge", "start_pos": 83, "end_pos": 100, "type": "DATASET", "confidence": 0.9228591918945312}]}, {"text": "The first, which achieved the best mean score of the 89 submitted runs, used a simple term alignment algorithm augmented with penalty terms.", "labels": [], "entities": [{"text": "mean score", "start_pos": 35, "end_pos": 45, "type": "METRIC", "confidence": 0.9533843994140625}, {"text": "term alignment", "start_pos": 86, "end_pos": 100, "type": "TASK", "confidence": 0.6796711832284927}]}, {"text": "The other two runs, ranked second and fourth, used support vector regression models to combine larger sets of features.", "labels": [], "entities": []}], "introductionContent": [{"text": "Measuring semantic text similarity has been a research subject in natural language processing, information retrieval and artificial intelligence for many years.", "labels": [], "entities": [{"text": "Measuring semantic text similarity", "start_pos": 0, "end_pos": 34, "type": "TASK", "confidence": 0.7213892117142677}, {"text": "natural language processing", "start_pos": 66, "end_pos": 93, "type": "TASK", "confidence": 0.6557039419809977}, {"text": "information retrieval", "start_pos": 95, "end_pos": 116, "type": "TASK", "confidence": 0.7853560149669647}]}, {"text": "Previous efforts have focused on comparing two long texts (e.g., for document classification) or a short text with along text (e.g., Web search), but there area growing number of tasks requiring computing the semantic similarity between two sentences or other short text sequences.", "labels": [], "entities": [{"text": "document classification)", "start_pos": 69, "end_pos": 93, "type": "TASK", "confidence": 0.8162431518236796}]}, {"text": "They include paraphrase recognition (), Twitter tweets search (, image retrieval by captions (), query reformulation (, automatic machine translation evaluation) and schema matching (.", "labels": [], "entities": [{"text": "paraphrase recognition", "start_pos": 13, "end_pos": 35, "type": "TASK", "confidence": 0.8912868201732635}, {"text": "query reformulation", "start_pos": 97, "end_pos": 116, "type": "TASK", "confidence": 0.7213288843631744}, {"text": "machine translation evaluation", "start_pos": 130, "end_pos": 160, "type": "TASK", "confidence": 0.7832028667132059}, {"text": "schema matching", "start_pos": 166, "end_pos": 181, "type": "TASK", "confidence": 0.788790225982666}]}, {"text": "There are three predominant approaches to computing short text similarity.", "labels": [], "entities": [{"text": "computing short text similarity", "start_pos": 42, "end_pos": 73, "type": "TASK", "confidence": 0.6733263432979584}]}, {"text": "The first uses information retrieval's vector space model in which each text is modeled as a \"bag of words\" and represented using a vector.", "labels": [], "entities": [{"text": "information retrieval", "start_pos": 15, "end_pos": 36, "type": "TASK", "confidence": 0.8231285512447357}]}, {"text": "The similarity between two texts is then computed as the cosine similarity of the vectors.", "labels": [], "entities": []}, {"text": "A variation on this approach leverages web search results (e.g., snippets) to provide context for the short texts and enrich their vectors using the words in the snippets ().", "labels": [], "entities": []}, {"text": "The second approach is based on the assumption that if two sentences or other short text sequences are semantically equivalent, we should be able to align their words or expressions.", "labels": [], "entities": []}, {"text": "The alignment quality can serve as a similarity measure.", "labels": [], "entities": [{"text": "similarity", "start_pos": 37, "end_pos": 47, "type": "METRIC", "confidence": 0.9731143712997437}]}, {"text": "This technique typically pairs words from the two texts by maximizing the summation of the word similarity of the resulting pairs ().", "labels": [], "entities": []}, {"text": "The third approach combines different measures and features using machine learning models.", "labels": [], "entities": []}, {"text": "Lexical, semantic and syntactic features are computed for the texts using a variety of resources and supplied to a classifier, which then assigns weights to the features by fitting the model to training data ().", "labels": [], "entities": []}, {"text": "For evaluating different approaches, the 2013 Semantic Textual Similarity (STS) task asked automatic systems to compute sentence similarity according to a scale definition ranging from 0 to 5, with 0 meaning unrelated and 5 semantically equivalent ().", "labels": [], "entities": [{"text": "Semantic Textual Similarity (STS) task", "start_pos": 46, "end_pos": 84, "type": "TASK", "confidence": 0.769224294594356}]}, {"text": "The example sentence pair \"The woman is playing the violin\" and \"The young lady enjoys listening to the guitar\" is scored as only 1 and the pair \"The bird is bathing in the sink\" and \"Birdie is washing itself in the water basin\" is given a score of 5.", "labels": [], "entities": []}, {"text": "The vector-space approach tends to be too shallow for the task, since solving it well requires discriminating word-level semantic differences and goes be-yond simply comparing sentence topics or contexts.", "labels": [], "entities": []}, {"text": "Our first run uses an align-and-penalize algorithm, which extends the second approach by giving penalties to the words that are poorly aligned.", "labels": [], "entities": []}, {"text": "Our other two runs use a support vector regression model to combine a large number of general and domain specific features.", "labels": [], "entities": []}, {"text": "An important and fundamental feature used by all three runs is a powerful semantic word similarity model based on a combination of Latent Semantic Analysis (LSA)) and knowledge from WordNet.", "labels": [], "entities": [{"text": "semantic word similarity", "start_pos": 74, "end_pos": 98, "type": "TASK", "confidence": 0.593019962310791}, {"text": "WordNet", "start_pos": 182, "end_pos": 189, "type": "DATASET", "confidence": 0.9316692352294922}]}, {"text": "The remainder of the paper proceeds as follows.", "labels": [], "entities": []}, {"text": "Section 2 presents the hybrid word similarity model.", "labels": [], "entities": []}, {"text": "Section 3 describes the align-and-penalize approach used for the PairingWords run.", "labels": [], "entities": []}, {"text": "In Section 4 we describe the SVM approach used for the Galactus and Saiyan runs.", "labels": [], "entities": []}, {"text": "Section 5 discusses the results and is followed by a short conclusion.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Ten examples from the LSA similarity model", "labels": [], "entities": []}, {"text": " Table 1. Examples 1 to 6 illustrate that the  metric has a good property of differentiating simi- lar words from non-similar words. Examples 7 and  8 show that the \u00b14 model can detect semantically  similar words even with different POS while the \u00b11  model yields much worse performance. Example 9  and 10 show that highly related but not substitutable  words can also have a strong similarity but the \u00b11  model has a better performance in discriminating  them. We call the \u00b11 model and the \u00b14 model  as concept similarity and relation similarity respec- tively since the \u00b11 model has a good performance  on nouns and the \u00b14 model is good at computing  similarity between relations regardless of POS of", "labels": [], "entities": []}]}