{"title": [{"text": "[LVIC-LIMSI]: Using Syntactic Features and Multi-polarity Words for Sentiment Analysis in Twitter", "labels": [], "entities": [{"text": "Sentiment Analysis", "start_pos": 68, "end_pos": 86, "type": "TASK", "confidence": 0.9020228683948517}]}], "abstractContent": [{"text": "This paper presents the contribution of our team at task 2 of SemEval 2013: Sentiment Analysis in Twitter.", "labels": [], "entities": [{"text": "SemEval 2013", "start_pos": 62, "end_pos": 74, "type": "TASK", "confidence": 0.8392858803272247}, {"text": "Sentiment Analysis", "start_pos": 76, "end_pos": 94, "type": "TASK", "confidence": 0.9213238656520844}]}, {"text": "We submitted a constrained run for each of the two subtasks.", "labels": [], "entities": []}, {"text": "In the Contextual Polarity Disambiguation subtask, we use a sentiment lexicon approach combined with polarity shift detection and tree kernel based classifiers.", "labels": [], "entities": [{"text": "Contextual Polarity Disambiguation", "start_pos": 7, "end_pos": 41, "type": "TASK", "confidence": 0.7498948574066162}, {"text": "polarity shift detection", "start_pos": 101, "end_pos": 125, "type": "TASK", "confidence": 0.682087262471517}]}, {"text": "In the Message Polarity Classification subtask, we focus on the influence of domain information on sentiment classification .", "labels": [], "entities": [{"text": "Message Polarity Classification", "start_pos": 7, "end_pos": 38, "type": "TASK", "confidence": 0.7041483024756113}, {"text": "sentiment classification", "start_pos": 99, "end_pos": 123, "type": "TASK", "confidence": 0.9416830539703369}]}], "introductionContent": [{"text": "In the past decade, new forms of communication, such as microblogging and text messaging have emerged and became ubiquitous.", "labels": [], "entities": []}, {"text": "These short messages are often used to share opinions and sentiments.", "labels": [], "entities": []}, {"text": "The Sentiment Analysis in Twitter task promotes research that will lead to a better understanding of how sentiment is conveyed in tweets and texts.", "labels": [], "entities": [{"text": "Sentiment Analysis in Twitter task", "start_pos": 4, "end_pos": 38, "type": "TASK", "confidence": 0.9242375135421753}]}, {"text": "In this paper, we describe our contribution at task 2 of SemEval 2013).", "labels": [], "entities": [{"text": "SemEval 2013", "start_pos": 57, "end_pos": 69, "type": "DATASET", "confidence": 0.6668664216995239}]}, {"text": "For the Contextual Polarity Disambiguation subtask, covered in section 2, we use a system that combines a lexicon based approach to sentiment detection with two types of supervised learning methods, one used for polarity shift identification and one for tweet segment classification in the absence of lexicon words.", "labels": [], "entities": [{"text": "Contextual Polarity Disambiguation", "start_pos": 8, "end_pos": 42, "type": "TASK", "confidence": 0.7275034586588541}, {"text": "sentiment detection", "start_pos": 132, "end_pos": 151, "type": "TASK", "confidence": 0.9614916145801544}, {"text": "polarity shift identification", "start_pos": 212, "end_pos": 241, "type": "TASK", "confidence": 0.7285121281941732}, {"text": "tweet segment classification", "start_pos": 254, "end_pos": 282, "type": "TASK", "confidence": 0.7092885375022888}]}, {"text": "The third section presents the Message Polarity Classification subtask.", "labels": [], "entities": [{"text": "Message Polarity Classification", "start_pos": 31, "end_pos": 62, "type": "TASK", "confidence": 0.723972370227178}]}, {"text": "We focus hereon the influence of domain information on sentiment classification by detecting words that change their polarity across domains.", "labels": [], "entities": [{"text": "sentiment classification", "start_pos": 55, "end_pos": 79, "type": "TASK", "confidence": 0.95958212018013}]}], "datasetContent": [{"text": "For the experiments presented in this section, we merge the training and development datasets and for the polarity shift and sentiment classification experiments we report the results using a 5-fold cross validation technique over the resulting dataset.", "labels": [], "entities": [{"text": "sentiment classification", "start_pos": 125, "end_pos": 149, "type": "TASK", "confidence": 0.7864231467247009}]}, {"text": "We tested several classifiers using the Weka toolkit ( and found that the best results were obtained with the Sequential Minimal Optimization (SMO) classifier.", "labels": [], "entities": [{"text": "Weka toolkit", "start_pos": 40, "end_pos": 52, "type": "DATASET", "confidence": 0.9605305194854736}, {"text": "Sequential Minimal Optimization (SMO) classifier", "start_pos": 110, "end_pos": 158, "type": "TASK", "confidence": 0.6809913728918348}]}, {"text": "For instance, when classifying + \u2192 \u2212 shifts, SMO correctly identified 91 out of 192 polarity shifts in contrast with 68 and 41 detected by a Random Forests and a Naive Bayes classifier, respectively.", "labels": [], "entities": [{"text": "SMO", "start_pos": 45, "end_pos": 48, "type": "TASK", "confidence": 0.9096209406852722}]}, {"text": "For the + \u2192 * classification, the SMO classifier finds 2 out of 34 shifts, for \u2212 \u2192 +, 15 out of 238 and for \u2212 \u2192 * , 2 out of 32 shifts are found.", "labels": [], "entities": [{"text": "SMO classifier", "start_pos": 34, "end_pos": 48, "type": "TASK", "confidence": 0.8578537404537201}]}, {"text": "After changing the polarity of sentiment segments as found by the 4 classifiers, we obtain an increase in F-Measure from 0.930 to 0.947 for positive segments and from 0.851 to 0.913 for negative segments.", "labels": [], "entities": [{"text": "F-Measure", "start_pos": 106, "end_pos": 115, "type": "METRIC", "confidence": 0.9958134293556213}]}, {"text": "Our choice of the Bag of Words model instead of a parse tree representation for these classifiers is justified by the poor performance of tree kernels when dealing with unbalanced data.", "labels": [], "entities": []}, {"text": "Ina series of preliminary experiments, we tested several classifiers trained on a Bag of Words model and an SVM classifier with a tree kernel.", "labels": [], "entities": []}, {"text": "We found that the parse tree representation of a tweet segment provided a higher accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 81, "end_pos": 89, "type": "METRIC", "confidence": 0.998512327671051}]}, {"text": "This shows that although small, when a segment contains more than one word, its syntactic structure becomes a relevant feature.", "labels": [], "entities": []}, {"text": "In we compare the results of 3 tree based models.", "labels": [], "entities": []}, {"text": "In the Basic Tree model, we use only the syntactic parse tree representation of a tweet segment.", "labels": [], "entities": []}, {"text": "For the Tree + Numeric model, we use the initial tree kernel together with a polynomial kernel on the binary structure features presented in section 2.1.1.", "labels": [], "entities": []}, {"text": "In the Tree + Context model, we include in the parse tree, besides the given section, k tokens (words, punctuation) from the whole tweet that surround the selected segment.", "labels": [], "entities": []}, {"text": "We performed tests with k from 1 to 5 and obtained the best results with a k value of 2.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Influence of lexicon on the F-Measure for positive  and negative segments", "labels": [], "entities": []}, {"text": " Table 2: Comparison between different models used for  segment polarity classification", "labels": [], "entities": [{"text": "segment polarity classification", "start_pos": 56, "end_pos": 87, "type": "TASK", "confidence": 0.8434786399205526}]}, {"text": " Table 3: Competition results overview on the Twitter and  SMS datasets", "labels": [], "entities": [{"text": "Twitter and  SMS datasets", "start_pos": 46, "end_pos": 71, "type": "DATASET", "confidence": 0.6469694599509239}]}]}