{"title": [{"text": "NRC: A Machine Translation Approach to Cross-Lingual Word Sense Disambiguation (SemEval-2013 Task 10)", "labels": [], "entities": [{"text": "NRC", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.8391692042350769}, {"text": "Machine Translation Approach to Cross-Lingual Word Sense Disambiguation", "start_pos": 7, "end_pos": 78, "type": "TASK", "confidence": 0.6740139275789261}]}], "abstractContent": [{"text": "This paper describes the NRC submission to the Spanish Cross-Lingual Word Sense Dis-ambiguation task at SemEval-2013.", "labels": [], "entities": [{"text": "NRC submission to the Spanish Cross-Lingual Word Sense Dis-ambiguation task at SemEval-2013", "start_pos": 25, "end_pos": 116, "type": "TASK", "confidence": 0.6063663934667906}]}, {"text": "Since this word sense disambiguation task uses Spanish translations of English words as gold annotation , it can be cast as a machine translation problem.", "labels": [], "entities": [{"text": "word sense disambiguation task", "start_pos": 11, "end_pos": 41, "type": "TASK", "confidence": 0.7450276911258698}]}, {"text": "We therefore submitted the output of a standard phrase-based system as a baseline, and investigated ways to improve its sense dis-ambiguation performance.", "labels": [], "entities": []}, {"text": "Using only local context information and no linguistic analysis beyond lemmatization, our machine translation system surprisingly yields top precision score based on the best predictions.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 90, "end_pos": 109, "type": "TASK", "confidence": 0.7531644701957703}, {"text": "precision score", "start_pos": 141, "end_pos": 156, "type": "METRIC", "confidence": 0.9737232625484467}]}, {"text": "However, its top 5 predictions are weaker than those from other systems.", "labels": [], "entities": []}], "introductionContent": [{"text": "This paper describes the systems submitted by the National Research Council Canada (NRC) for the Cross-Lingual Word Sense Disambiguation task at.", "labels": [], "entities": [{"text": "National Research Council Canada (NRC)", "start_pos": 50, "end_pos": 88, "type": "DATASET", "confidence": 0.8647716726575579}, {"text": "Cross-Lingual Word Sense Disambiguation task", "start_pos": 97, "end_pos": 141, "type": "TASK", "confidence": 0.7910073518753051}]}, {"text": "As in the previous edition, this word sense disambiguation task asks systems to disambiguate English words by providing translations in other languages.", "labels": [], "entities": [{"text": "word sense disambiguation", "start_pos": 33, "end_pos": 58, "type": "TASK", "confidence": 0.715274840593338}]}, {"text": "It is therefore closely related to machine translation.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 35, "end_pos": 54, "type": "TASK", "confidence": 0.8173092305660248}]}, {"text": "Our work aims to explore this connection between machine translation and crosslingual word sense disambiguation, by providing a machine translation baseline and investigating ways to improve the sense disambiguation performance of a standard machine translation system.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 49, "end_pos": 68, "type": "TASK", "confidence": 0.7728673219680786}, {"text": "crosslingual word sense disambiguation", "start_pos": 73, "end_pos": 111, "type": "TASK", "confidence": 0.6128912270069122}, {"text": "sense disambiguation", "start_pos": 195, "end_pos": 215, "type": "TASK", "confidence": 0.7220178991556168}]}, {"text": "Machine Translation (MT) has often been used indirectly for SemEval Word Sense Disambiguation (WSD) tasks: as a tool to automatically create training data, for instance) ; as a source of parallel data that can be used to train WSD systems); or as an application which can use the predictions of WSD systems developed for SemEval tasks.", "labels": [], "entities": [{"text": "Machine Translation (MT)", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.8665926218032837}, {"text": "SemEval Word Sense Disambiguation (WSD) tasks", "start_pos": 60, "end_pos": 105, "type": "TASK", "confidence": 0.8753169924020767}, {"text": "SemEval tasks", "start_pos": 321, "end_pos": 334, "type": "TASK", "confidence": 0.9035474061965942}]}, {"text": "This SemEval shared task gives us the opportunity to compare the performance of machine translation systems with other submissions which use very different approaches.", "labels": [], "entities": [{"text": "SemEval shared task", "start_pos": 5, "end_pos": 24, "type": "TASK", "confidence": 0.8718471129735311}, {"text": "machine translation", "start_pos": 80, "end_pos": 99, "type": "TASK", "confidence": 0.7657668590545654}]}, {"text": "Our goal is to provide machine translation output which is representative of state-of-the-art approaches, and provide a basis for comparing its strength and weaknesses with that of other systems submitted to this task.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 23, "end_pos": 42, "type": "TASK", "confidence": 0.7676830291748047}]}, {"text": "We submitted two systems to the Spanish Cross-Lingual WSD (CLWSD) task: 1.", "labels": [], "entities": [{"text": "Spanish Cross-Lingual WSD (CLWSD) task", "start_pos": 32, "end_pos": 70, "type": "TASK", "confidence": 0.5980511733463832}]}, {"text": "BASIC, a baseline machine translation system trained on the parallel corpus used to define the sense inventory; 2.", "labels": [], "entities": []}, {"text": "ADAPT, a machine translation system that has been adapted to perform better on this task.", "labels": [], "entities": [{"text": "ADAPT", "start_pos": 0, "end_pos": 5, "type": "DATASET", "confidence": 0.6673761606216431}, {"text": "machine translation", "start_pos": 9, "end_pos": 28, "type": "TASK", "confidence": 0.7188368737697601}]}, {"text": "After describing these systems in Sections 2 and 3, we give an overview of the results in Section 4.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Precision scores by target word for the BASIC and ADAPT systems", "labels": [], "entities": [{"text": "Precision", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.8854199647903442}, {"text": "ADAPT", "start_pos": 60, "end_pos": 65, "type": "DATASET", "confidence": 0.6473470330238342}]}, {"text": " Table 2: Overview of official results: comparison of  the precision scores of the ADAPT and BASIC sys- tems with the best system according to each metric  and with the official baseline", "labels": [], "entities": [{"text": "precision", "start_pos": 59, "end_pos": 68, "type": "METRIC", "confidence": 0.9989526271820068}, {"text": "ADAPT", "start_pos": 83, "end_pos": 88, "type": "DATASET", "confidence": 0.8230112791061401}]}]}