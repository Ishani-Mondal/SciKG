{"title": [{"text": "Columbia NLP: Sentiment Detection of Subjective Phrases in Social Media", "labels": [], "entities": [{"text": "Columbia NLP", "start_pos": 0, "end_pos": 12, "type": "DATASET", "confidence": 0.9534562826156616}, {"text": "Sentiment Detection of Subjective Phrases in Social Media", "start_pos": 14, "end_pos": 71, "type": "TASK", "confidence": 0.906584121286869}]}], "abstractContent": [{"text": "We present a supervised sentiment detection system that classifies the polarity of subjective phrases as positive, negative, or neutral.", "labels": [], "entities": [{"text": "sentiment detection", "start_pos": 24, "end_pos": 43, "type": "TASK", "confidence": 0.820866584777832}]}, {"text": "It is tailored towards online genres, specifically Twitter, through the inclusion of dictionaries developed to capture vocabulary used in on-line conversations (e.g., slang and emoticons) as well as stylistic features common to social media.", "labels": [], "entities": []}, {"text": "We show how to incorporate these new features within a state of the art system and evaluate it on subtask A in SemEval-2013 Task 2: Sentiment Analysis in Twitter.", "labels": [], "entities": [{"text": "Sentiment Analysis", "start_pos": 132, "end_pos": 150, "type": "TASK", "confidence": 0.9077938497066498}]}], "introductionContent": [{"text": "People use social media to write openly about their personal experiences, likes and dislikes.", "labels": [], "entities": []}, {"text": "The following sentence from Twitter is atypical example: \"Tomorrow I'm coming back from Barcelona...I don't want!", "labels": [], "entities": []}, {"text": "The ability to detect the sentiment expressed in social media can be useful for understanding what people think about the restaurants they visit, the political viewpoints of the day, and the products they buy.", "labels": [], "entities": []}, {"text": "These sentiments can be used to provided targeted advertising, automatically generate reviews, and make various predictions, such as political outcomes.", "labels": [], "entities": []}, {"text": "In this paper we develop a sentiment detection algorithm for social media that classifies the polarity of sentence phrases as positive, negative, or neutral and test its performance in Twitter through the participation in the expression level task (subtask A) of the SemEval-2013 Task 2: Sentiment Analysis in Twitter () which the authors helped organize.", "labels": [], "entities": [{"text": "sentiment detection", "start_pos": 27, "end_pos": 46, "type": "TASK", "confidence": 0.9010493457317352}, {"text": "Sentiment Analysis", "start_pos": 288, "end_pos": 306, "type": "TASK", "confidence": 0.7792215943336487}]}, {"text": "To do so, we build on previous work on sentiment detection algorithms for the more formal news genre, notably the work of, but adapt it for the language of social media, in particular Twitter.", "labels": [], "entities": [{"text": "sentiment detection", "start_pos": 39, "end_pos": 58, "type": "TASK", "confidence": 0.9020068049430847}]}, {"text": "We show that exploiting lexical-stylistic features and dictionaries geared toward social media are useful in detecting sentiment.", "labels": [], "entities": [{"text": "detecting sentiment", "start_pos": 109, "end_pos": 128, "type": "TASK", "confidence": 0.8884266316890717}]}, {"text": "In this rest of this paper, we discuss related work, including the state of the art sentiment system) our method is based on, the lexicons we used, our method, and experiments and results.", "labels": [], "entities": []}], "datasetContent": [{"text": "This task was evaluated on the Twitter dataset provided by Semeval-2013 Task 2, subtask A, which the authors helped organize.", "labels": [], "entities": [{"text": "Twitter dataset provided by Semeval-2013 Task 2", "start_pos": 31, "end_pos": 78, "type": "DATASET", "confidence": 0.776684582233429}]}, {"text": "Therefore, a large portion of time was spent on creating the dataset.", "labels": [], "entities": []}, {"text": "We ran all of our experiments in Weka () using Logistic Regression.", "labels": [], "entities": [{"text": "Weka", "start_pos": 33, "end_pos": 37, "type": "DATASET", "confidence": 0.9641775488853455}]}, {"text": "We also experimented with other learning methods but found that this worked best.", "labels": [], "entities": []}, {"text": "All results are shown using the average F-measure of the positive and negative class.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 40, "end_pos": 49, "type": "METRIC", "confidence": 0.9977619647979736}]}, {"text": "We tuned our system for Semeval-2013 Task 2, subtask A, using the provided development set and ran it on the provided Twitter and SMS test data.", "labels": [], "entities": [{"text": "Semeval-2013 Task 2", "start_pos": 24, "end_pos": 43, "type": "TASK", "confidence": 0.7489588260650635}]}, {"text": "Our results are shown in with all results being statistically significant over a majority baseline.", "labels": [], "entities": []}, {"text": "We also use the DAL as a baseline to indicate how useful lexical-stylistic features (specifically those geared towards social media) and the dictionaries are in improving the performance of sentiment detection of phrases in online genres in contrast to using just the DAL.", "labels": [], "entities": [{"text": "sentiment detection of phrases in online genres", "start_pos": 190, "end_pos": 237, "type": "TASK", "confidence": 0.8812654529299054}]}, {"text": "The results that are statistically significant (computed using the Wilcoxon's test, p \u2264 .02) shown in bold.", "labels": [], "entities": []}, {"text": "Our best results for each dataset include all features with an average Fmeasure of 77.6% and 73.3% for the Twitter and SMS test sets respectively resulting in a significant improvement of more than 5% for each test set over the DAL baseline.", "labels": [], "entities": [{"text": "Fmeasure", "start_pos": 71, "end_pos": 79, "type": "METRIC", "confidence": 0.9926873445510864}, {"text": "SMS test sets", "start_pos": 119, "end_pos": 132, "type": "DATASET", "confidence": 0.7648929953575134}, {"text": "DAL baseline", "start_pos": 228, "end_pos": 240, "type": "DATASET", "confidence": 0.8091275990009308}]}, {"text": "At the time of submission, we had not experimented with n-grams, and therefore chose the Dictionaries+Style system as our final version for the official run resulting in a rank of 12/22 (75% Fmeasure) for Twitter and 13/19 (70.2% F-measure) for SMS.", "labels": [], "entities": [{"text": "Fmeasure", "start_pos": 191, "end_pos": 199, "type": "METRIC", "confidence": 0.9900354743003845}, {"text": "F-measure", "start_pos": 230, "end_pos": 239, "type": "METRIC", "confidence": 0.9697588682174683}]}, {"text": "Our rank with the best system, which includes n-grams, would remain the same for Twitter, but bring our rank up to 10/19 for SMS.", "labels": [], "entities": []}, {"text": "We looked more closely at the impact of our new features and as one would expect, feature selection found the general and social media style features (e.g. emoticons, :(, lol, word lengthening) to be useful in Twitter and SMS data.", "labels": [], "entities": [{"text": "word lengthening)", "start_pos": 176, "end_pos": 193, "type": "TASK", "confidence": 0.7531154453754425}]}, {"text": "Using additional online dictionaries is useful in Twitter and SMS, which is understandable because they both have poor coverage in the DAL and WordNet.", "labels": [], "entities": [{"text": "DAL", "start_pos": 135, "end_pos": 138, "type": "DATASET", "confidence": 0.9138018488883972}, {"text": "WordNet", "start_pos": 143, "end_pos": 150, "type": "DATASET", "confidence": 0.8418298363685608}]}, {"text": "In all cases using n-grams was the most useful which indicates that context is most important.", "labels": [], "entities": []}, {"text": "Using Dictionaries and Style in addition to n-grams did provide a significant improvement in the Twitter test set, but not in the Twitter Dev and SMS test set.", "labels": [], "entities": [{"text": "Twitter test set", "start_pos": 97, "end_pos": 113, "type": "DATASET", "confidence": 0.8532000382741293}, {"text": "SMS test set", "start_pos": 146, "end_pos": 158, "type": "DATASET", "confidence": 0.7452179292837778}]}], "tableCaptions": [{"text": " Table 1: Coverage for each of the lexicons in the training and test corpora's.", "labels": [], "entities": []}, {"text": " Table 4: Experiments using the Twitter corpus. Results  are shown using average F-measure of the positive and  negative class. All experiments include the DAL. The  dictionaries refer to WordNet, Wiktionary, and Emoticon.  Style refers to Lexical-Stylistic features. All results ex- ceed the majority baseline significantly.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 81, "end_pos": 90, "type": "METRIC", "confidence": 0.9948712587356567}, {"text": "DAL", "start_pos": 156, "end_pos": 159, "type": "METRIC", "confidence": 0.8795030117034912}, {"text": "WordNet", "start_pos": 188, "end_pos": 195, "type": "DATASET", "confidence": 0.9518938064575195}]}]}