{"title": [{"text": "ASVUniOfLeipzig: Sentiment Analysis in Twitter using Data-driven Machine Learning Techniques", "labels": [], "entities": [{"text": "ASVUniOfLeipzig", "start_pos": 0, "end_pos": 15, "type": "DATASET", "confidence": 0.8327759504318237}, {"text": "Sentiment Analysis", "start_pos": 17, "end_pos": 35, "type": "TASK", "confidence": 0.9475193619728088}]}], "abstractContent": [{"text": "This paper describes University of Leipzig's approach to SemEval-2013 task 2B on Sentiment Analysis in Twitter: message polarity classification.", "labels": [], "entities": [{"text": "SemEval-2013 task", "start_pos": 57, "end_pos": 74, "type": "TASK", "confidence": 0.8657207787036896}, {"text": "Sentiment Analysis in Twitter: message polarity classification", "start_pos": 81, "end_pos": 143, "type": "TASK", "confidence": 0.8142732381820679}]}, {"text": "Our system is designed to function as a baseline, to see what we can accomplish with well-understood and purely data-driven lexical features, simple generalizations as well as standard machine learning techniques: We use one-against-one Support Vector Machines with asymmetric cost factors and linear \"kernels\" as classifiers, word uni-and bigrams as features and additionally model negation of word uni-and bigrams in word n-gram feature space.", "labels": [], "entities": []}, {"text": "We consider generalizations of URLs, user names, hash tags, repeated characters and expressions of laughter.", "labels": [], "entities": []}, {"text": "Our method ranks 23 out of all 48 participating systems, achieving an averaged (pos-itive, negative) F-Score of 0.5456 and an averaged (positive, negative, neutral) F-Score of 0.595, which is above median and average.", "labels": [], "entities": [{"text": "F-Score", "start_pos": 101, "end_pos": 108, "type": "METRIC", "confidence": 0.9942536950111389}, {"text": "F-Score", "start_pos": 165, "end_pos": 172, "type": "METRIC", "confidence": 0.9954462647438049}]}], "introductionContent": [{"text": "In SemEval-2013's task 2B on Sentiment Analysis in Twitter, given a Twitter message, i.e. a tweet, the goal is to classify whether this tweet is of positive, negative, or neutral polarity (, i.e. the task is a ternary polarity classification.", "labels": [], "entities": [{"text": "Sentiment Analysis", "start_pos": 29, "end_pos": 47, "type": "TASK", "confidence": 0.8815850019454956}]}, {"text": "Due to Twitter's growing popularity, the availability of large amounts of data that go along with that and the fact, that many people freely express their opinion on virtually everything using Twitter, research on sentiment analysis in Twitter has received a lot of attention lately (.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 214, "end_pos": 232, "type": "TASK", "confidence": 0.7495409250259399}]}, {"text": "Language is usually used casually in Twitter and exhibits interesting properties.", "labels": [], "entities": []}, {"text": "Therefore, some studies specifically address certain issues, e.g. a tweet's length limitation of 140 characters, some studies leverage certain language characteristics, e.g. the presence of emoticons etc.", "labels": [], "entities": []}, {"text": "identify various \"sentiment types\" defined by Twitter hash tags (e.g. #bored) and smileys (e.g. :S) using words, word n-grams, punctuation marks and patterns as features.", "labels": [], "entities": []}, {"text": "map words to more general representations, i.e. part of speech (POS) tags and the words' prior subjectivity and polarity.", "labels": [], "entities": []}, {"text": "Additionally, they count the number of re-tweets, hash tags, replies, links etc.", "labels": [], "entities": []}, {"text": "They then combine the outputs of 3 online sources of labeled but noisy and biased Twitter data into a more robust classification model.", "labels": [], "entities": []}, {"text": "also address data sparsity via word clustering methods, i.e. semantic smoothing and sentiment-topics extraction.", "labels": [], "entities": [{"text": "word clustering", "start_pos": 31, "end_pos": 46, "type": "TASK", "confidence": 0.7488689422607422}, {"text": "semantic smoothing", "start_pos": 61, "end_pos": 79, "type": "TASK", "confidence": 0.7257123738527298}, {"text": "sentiment-topics extraction", "start_pos": 84, "end_pos": 111, "type": "TASK", "confidence": 0.8217200934886932}]}, {"text": "contrast a word unigram model, a tree kernel model and a model of various features, e.g. POS tag counts, summed up prior polarity scores, presence or absence of capitalized text, all applied to binary and ternary polarity classification.", "labels": [], "entities": [{"text": "ternary polarity classification", "start_pos": 205, "end_pos": 236, "type": "TASK", "confidence": 0.6629252036412557}]}, {"text": "show that Twitter-specific feature engineering, e.g. representing the presence or absence of abbreviations and character repetitions improves model quality.", "labels": [], "entities": [{"text": "representing the presence or absence of abbreviations and character repetitions", "start_pos": 53, "end_pos": 132, "type": "TASK", "confidence": 0.5509677290916443}]}, {"text": "focus on targetdependent polarity classification regarding a given user query.", "labels": [], "entities": [{"text": "targetdependent polarity classification", "start_pos": 9, "end_pos": 48, "type": "TASK", "confidence": 0.7081348896026611}]}, {"text": "While various models and features have been proposed, word n-gram models proved to be competitive in many studies () yet are straightforward to implement.", "labels": [], "entities": []}, {"text": "Moreover, word n-gram models do not rely on hand-crafted and generally {genre, domain}-non-specific resources, e.g. prior polarity dictionaries like SentiWordNet () or Subjectivity Lexicon ().", "labels": [], "entities": []}, {"text": "In contrast, purely data-driven word ngram models are domain-specific per se: they \"let the data speak for themselves\".", "labels": [], "entities": []}, {"text": "Therefore we believe that carefully designing such a baseline using well-understood and purely data-driven lexical features, simple generalizations as well as standard machine learning techniques is a worthwhile endeavor.", "labels": [], "entities": []}, {"text": "In the next Section we describe our system.", "labels": [], "entities": []}, {"text": "In Section 3 we discuss its results in SemEval-2013 task 2B and finally conclude in Section 4.", "labels": [], "entities": [{"text": "SemEval-2013 task 2B", "start_pos": 39, "end_pos": 59, "type": "TASK", "confidence": 0.6957651376724243}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Class distribution of positive (+), negative (\u2212)  and neutral-or-objective (0) instances in training and de- velopment data after duplicate removal.", "labels": [], "entities": []}, {"text": " Table 2: Class distribution of positive (+), negative (\u2212)  and neutral-or-objective (0) instances in Twitter and SMS  testing data.", "labels": [], "entities": [{"text": "SMS  testing data", "start_pos": 114, "end_pos": 131, "type": "DATASET", "confidence": 0.677850196758906}]}, {"text": " Table 4. The ranks we achieved in the con- strained only-ranking and the full constrained and  unconstrained-ranking are shown in", "labels": [], "entities": []}, {"text": " Table 5: Ranks of University of Leipzig's approach to  SemEval-2013 task 2B on Twitter and SMS test data in  the constrained only (Constr.) and the constrained and  unconstrained setting (Un/constr.).", "labels": [], "entities": []}]}