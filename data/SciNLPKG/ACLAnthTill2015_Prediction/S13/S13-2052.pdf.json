{"title": [{"text": "SemEval-2013 Task 2: Sentiment Analysis in Twitter", "labels": [], "entities": [{"text": "Sentiment Analysis", "start_pos": 21, "end_pos": 39, "type": "TASK", "confidence": 0.9525153934955597}]}], "abstractContent": [{"text": "In recent years, sentiment analysis in social media has attracted a lot of research interest and has been used fora number of applications.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 17, "end_pos": 35, "type": "TASK", "confidence": 0.9548995196819305}]}, {"text": "Unfortunately, research has been hindered by the lack of suitable datasets, complicating the comparison between approaches.", "labels": [], "entities": []}, {"text": "To address this issue, we have proposed SemEval-2013 Task 2: Sentiment Analysis in Twitter, which included two subtasks: A, an expression-level subtask, and B, a message-level subtask.", "labels": [], "entities": [{"text": "Sentiment Analysis", "start_pos": 61, "end_pos": 79, "type": "TASK", "confidence": 0.7902858853340149}]}, {"text": "We used crowdsourcing on Amazon Mechanical Turk to label a large Twitter training dataset along with additional test sets of Twitter and SMS messages for both subtasks.", "labels": [], "entities": []}, {"text": "All datasets used in the evaluation are released to the research community.", "labels": [], "entities": []}, {"text": "The task attracted significant interest and a total of 149 submissions from 44 teams.", "labels": [], "entities": []}, {"text": "The best-performing team achieved an F1 of 88.9% and 69% for subtasks A and B, respectively.", "labels": [], "entities": [{"text": "F1", "start_pos": 37, "end_pos": 39, "type": "METRIC", "confidence": 0.9926919341087341}]}], "introductionContent": [{"text": "In the past decade, new forms of communication, such as microblogging and text messaging have emerged and become ubiquitous.", "labels": [], "entities": []}, {"text": "Twitter messages (tweets) and cellphone messages (SMS) are often used to share opinions and sentiments about the surrounding world, and the availability of social content generated on sites such as Twitter creates new opportunities to automatically study public opinion.", "labels": [], "entities": []}, {"text": "Working with these informal text genres presents new challenges for natural language processing beyond those encountered when working with more traditional text genres such as newswire.", "labels": [], "entities": [{"text": "natural language processing", "start_pos": 68, "end_pos": 95, "type": "TASK", "confidence": 0.7059403459231058}]}, {"text": "Tweets and SMS messages are short in length: a sentence or a headline rather than a document.", "labels": [], "entities": []}, {"text": "The language they use is very informal, with creative spelling and punctuation, misspellings, slang, new words, URLs, and genre-specific terminology and abbreviations, e.g., RT for re-tweet and #hashtags.", "labels": [], "entities": []}, {"text": "How to handle such challenges so as to automatically mine and understand the opinions and sentiments that people are communicating has only very recently been the subject of research (.", "labels": [], "entities": []}, {"text": "Another aspect of social media data, such as Twitter messages, is that they include rich structured information about the individuals involved in the communication.", "labels": [], "entities": []}, {"text": "For example, Twitter maintains information about who follows whom.", "labels": [], "entities": []}, {"text": "Re-tweets (reshares of a tweet) and tags inside of tweets provide discourse information.", "labels": [], "entities": []}, {"text": "Modeling such structured information is important because it provides means for empirically studying social interactions where opinion is conveyed, e.g., we can study the properties of persuasive language or those associated with influential users.", "labels": [], "entities": []}, {"text": "Several corpora with detailed opinion and sentiment annotation have been made freely available, e.g., the MPQA corpus () of newswire text.", "labels": [], "entities": [{"text": "MPQA corpus", "start_pos": 106, "end_pos": 117, "type": "DATASET", "confidence": 0.959860235452652}]}, {"text": "These corpora have proved very valuable as resources for learning about the language of sentiment in general, but they did not focus on social media.", "labels": [], "entities": [{"text": "learning about the language of sentiment", "start_pos": 57, "end_pos": 97, "type": "TASK", "confidence": 0.6353012522061666}]}, {"text": "Twitter RT @tash jade: That's really sad, Charlie RT \"Until tonight I never realised how fucked up I was\" -Charlie Sheen #sheenroast SMS Glad to hear you are coping fine in uni...", "labels": [], "entities": []}, {"text": "So, wat interview did you go to?", "labels": [], "entities": []}, {"text": "How did it go?: Examples of sentences from each corpus that contain subjective phrases.", "labels": [], "entities": []}, {"text": "While some Twitter sentiment datasets have already been created, they were either small and proprietary, such as the i-sieve corpus), or they were created only for Spanish like the TASS corpus 2), or they relied on noisy labels obtained from emoticons and hashtags.", "labels": [], "entities": [{"text": "TASS corpus 2", "start_pos": 181, "end_pos": 194, "type": "DATASET", "confidence": 0.8227821191151937}]}, {"text": "They further focused on message-level sentiment, and no Twitter or SMS corpus with expression-level sentiment annotations has been made available so far.", "labels": [], "entities": [{"text": "message-level sentiment", "start_pos": 24, "end_pos": 47, "type": "TASK", "confidence": 0.7408137023448944}]}, {"text": "Thus, the primary goal of our SemEval-2013 task 2 has been to promote research that will lead to a better understanding of how sentiment is conveyed in Tweets and SMS messages.", "labels": [], "entities": []}, {"text": "Toward that goal, we created the SemEval Tweet corpus, which contains Tweets (for both training and testing) and SMS messages (for testing only) with sentiment expressions annotated with contextual phrase-level polarity as well as an overall message-level polarity.", "labels": [], "entities": []}, {"text": "We used this corpus as a testbed for the system evaluation at In the remainder of this paper, we first describe the task, the dataset creation process, and the evaluation methodology.", "labels": [], "entities": []}, {"text": "We then summarize the characteristics of the approaches taken by the participating systems and we discuss their scores.", "labels": [], "entities": []}], "datasetContent": [{"text": "In the following sections we describe the collection and annotation of the Twitter and SMS datasets.", "labels": [], "entities": [{"text": "SMS datasets", "start_pos": 87, "end_pos": 99, "type": "DATASET", "confidence": 0.6962375491857529}]}], "tableCaptions": [{"text": " Table 2: Statistics for Subtask A.", "labels": [], "entities": [{"text": "Subtask A", "start_pos": 25, "end_pos": 34, "type": "TASK", "confidence": 0.8862961530685425}]}, {"text": " Table 3: Statistics for Subtask B.", "labels": [], "entities": [{"text": "Subtask B", "start_pos": 25, "end_pos": 34, "type": "TASK", "confidence": 0.9238578379154205}]}, {"text": " Table 4: Bounds for datasets in subtasks A and B.", "labels": [], "entities": []}, {"text": " Table 7: Results for subtask A on the Twitter dataset. The  \u2022 marks a team that includes a task coorganizer, and the  indicates a system submitted as constrained but which  used additional Tweets or additional sentiment-annotated  text to collect statistics that were then used as a feature.", "labels": [], "entities": [{"text": "Twitter dataset", "start_pos": 39, "end_pos": 54, "type": "DATASET", "confidence": 0.7998009324073792}]}, {"text": " Table 8: Results for subtask A on the SMS dataset. The  indicates a late submission, the \u2022 marks a team that  includes a task co-organizer, and the indicates a sys- tem submitted as constrained but which used additional  Tweets or additional sentiment-annotated text to collect  statistics that were then used as a feature.", "labels": [], "entities": [{"text": "SMS dataset", "start_pos": 39, "end_pos": 50, "type": "DATASET", "confidence": 0.855553150177002}]}, {"text": " Table 9: Results for subtask B on the Twitter dataset. The  indicates a system submitted as constrained but which  used additional Tweets or additional sentiment-annotated  text to collect statistics that were then used as a feature.", "labels": [], "entities": [{"text": "Twitter dataset", "start_pos": 39, "end_pos": 54, "type": "DATASET", "confidence": 0.8575553297996521}]}, {"text": " Table 10: Results for subtask B on the SMS dataset. The  indicates a system submitted as constrained but which  used additional Tweets or additional sentiment-annotated  text to collect statistics that were then used as a feature.", "labels": [], "entities": [{"text": "SMS dataset", "start_pos": 40, "end_pos": 51, "type": "DATASET", "confidence": 0.8906227946281433}]}]}