{"title": [{"text": "CLaC-CORE: Exhaustive Feature Combination for Measuring Textual Similarity", "labels": [], "entities": []}], "abstractContent": [{"text": "CLaC-CORE, an exhaustive feature combination system ranked 4th among 34 teams in the Semantic Textual Similarity shared task STS 2013.", "labels": [], "entities": [{"text": "CLaC-CORE", "start_pos": 0, "end_pos": 9, "type": "DATASET", "confidence": 0.8130456805229187}, {"text": "Semantic Textual Similarity shared task STS 2013", "start_pos": 85, "end_pos": 133, "type": "TASK", "confidence": 0.8510427560125079}]}, {"text": "Using a core set of 11 lexical features of the most basic kind, it uses a support vector regressor which uses a combination of these lexical features to train a model for predicting similarity between sentences in a two phase method, which in turn uses all combinations of the features in the feature space and trains separate models based on each combination.", "labels": [], "entities": [{"text": "predicting similarity between sentences", "start_pos": 171, "end_pos": 210, "type": "TASK", "confidence": 0.8874220550060272}]}, {"text": "Then it creates a meta-feature space and trains a final model based on that.", "labels": [], "entities": []}, {"text": "This two step process improves the results achieved by single-layer standard learning methodology over the same simple features.", "labels": [], "entities": []}, {"text": "We analyze the correlation of feature combinations with the data sets over which they are effective.", "labels": [], "entities": []}], "introductionContent": [{"text": "The Semantic Textual Similarity (STS) shared task aims to find a unified way of measuring similarity between sentences.", "labels": [], "entities": [{"text": "Semantic Textual Similarity (STS) shared task", "start_pos": 4, "end_pos": 49, "type": "TASK", "confidence": 0.7985227033495903}]}, {"text": "In fact, sentence similarity is a core element of tasks trying to establish how two pieces of text are related, such as Textual Entailment (RTE) (), and Paraphrase Recognition ().", "labels": [], "entities": [{"text": "sentence similarity", "start_pos": 9, "end_pos": 28, "type": "TASK", "confidence": 0.7081756293773651}, {"text": "Textual Entailment (RTE)", "start_pos": 120, "end_pos": 144, "type": "TASK", "confidence": 0.7477262794971467}, {"text": "Paraphrase Recognition", "start_pos": 153, "end_pos": 175, "type": "TASK", "confidence": 0.9172775149345398}]}, {"text": "The STS shared task was introduced for SemEval-2012 and was selected as its first shared task.", "labels": [], "entities": []}, {"text": "Similar in spirit, STS differs from the well-known RTE shared tasks in two important points: it defines a graded similarity scale to measure similarity of two texts, instead of RTE's binary yes/no decision and the similarity relation is considered to be symmetrical, whereas the entailment relation of RTE is inherently unidirectional.", "labels": [], "entities": [{"text": "RTE shared tasks", "start_pos": 51, "end_pos": 67, "type": "TASK", "confidence": 0.6873408158620199}]}, {"text": "The leading systems in the 2012 competition used a variety of very simple lexical features.", "labels": [], "entities": []}, {"text": "Each system combines a different set of related features.", "labels": [], "entities": []}, {"text": "CLaC Labs investigated the different combination possibilities of these simple lexical features and measured their performance on the different data sets.", "labels": [], "entities": [{"text": "CLaC Labs", "start_pos": 0, "end_pos": 9, "type": "DATASET", "confidence": 0.9491923749446869}]}, {"text": "Originally conceived to explore the space of all possible feature combinations for 'feature combination selection', a two-step method emerged that deliberately compiles and trains all feature combinations exhaustively and then trains an SVM regressor using all combination models as its input features.", "labels": [], "entities": [{"text": "feature combination selection", "start_pos": 84, "end_pos": 113, "type": "TASK", "confidence": 0.6499102016290029}]}, {"text": "It turns out that this technique is not nearly as prohibitive as imagined and achieves statistically significant improvements over the alternative of feature selection or of using anyone single combination individually.", "labels": [], "entities": [{"text": "feature selection", "start_pos": 150, "end_pos": 167, "type": "TASK", "confidence": 0.7146812975406647}]}, {"text": "We propose the method as a viable approach when the characteristics of the data are not well understood and no satisfactory training set is available.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: CLaC-CORE runs and STS baseline perfor- mance", "labels": [], "entities": [{"text": "STS baseline perfor- mance", "start_pos": 29, "end_pos": 55, "type": "METRIC", "confidence": 0.9218175530433654}]}, {"text": " Table 2: Best and worst feature combination performance  on test set", "labels": [], "entities": []}, {"text": " Table 3: Feature contribution to the three best results over  four datasets", "labels": [], "entities": [{"text": "Feature", "start_pos": 10, "end_pos": 17, "type": "METRIC", "confidence": 0.9489164352416992}]}]}