{"title": [{"text": "uOttawa: System description for SemEval 2013 Task 2 Sentiment Analysis in Twitter", "labels": [], "entities": [{"text": "SemEval 2013 Task 2 Sentiment Analysis", "start_pos": 32, "end_pos": 70, "type": "TASK", "confidence": 0.8713959554831187}]}], "abstractContent": [{"text": "We present two systems developed at the University of Ottawa for the SemEval 2013 Task 2.", "labels": [], "entities": [{"text": "SemEval 2013 Task 2", "start_pos": 69, "end_pos": 88, "type": "TASK", "confidence": 0.8062386512756348}]}, {"text": "The first system (for Task A) classifies the polarity / sentiment orientation of one target word in a Twitter message.", "labels": [], "entities": []}, {"text": "The second system (for Task B) classifies the polarity of whole Twitter messages.", "labels": [], "entities": []}, {"text": "Our two systems are very simple, based on supervised classifiers with bag-of-words feature representation, enriched with information from several sources.", "labels": [], "entities": []}, {"text": "We present a few additional results, besides results of the submitted runs.", "labels": [], "entities": []}], "introductionContent": [{"text": "The Semeval 2013 Task 2 focused on classifying Twitter messages (\"tweets\") as expressing a positive opinion, a negative opinion, a neutral opinion, or no opinion (objective).", "labels": [], "entities": [{"text": "Semeval 2013 Task 2", "start_pos": 4, "end_pos": 23, "type": "DATASET", "confidence": 0.6877736300230026}]}, {"text": "In fact, the neutral and objective were joined in one class for the requirements of the shared task.", "labels": [], "entities": []}, {"text": "Task A contained target words whose sense had to be classified in the context, while Task B was to classify each text into one of the three classes: positive, negative, and neutral/objective.", "labels": [], "entities": []}, {"text": "The training data that was made available for each task consisted in annotated Twitter message.", "labels": [], "entities": []}, {"text": "There were two test sets for each task, one composed of Twitter messages and one of SMS message (even if there was no specific training data for SMS messages).", "labels": [], "entities": []}, {"text": "See more details about the datasets in ().", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 2: Accuracy results for task A by 10-fold cross- validation on the training data", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9992169141769409}]}, {"text": " Table 3: Results for Task A for the submitted runs  (Average F-score for positive/negative class)", "labels": [], "entities": [{"text": "F-score", "start_pos": 62, "end_pos": 69, "type": "METRIC", "confidence": 0.6741094589233398}]}, {"text": " Table 4: Results for Tweet test data for Task A, for  each class.", "labels": [], "entities": []}, {"text": " Table 5: Results for SMS test data for Task A, for each  class.", "labels": [], "entities": []}, {"text": " Table 6: Accuracy results for task B by 10-fold cross- validation on the training data", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9992903470993042}]}, {"text": " Table 7: Results for Task B for the submitted runs  (Average F-score for positive/negative).", "labels": [], "entities": [{"text": "Average", "start_pos": 54, "end_pos": 61, "type": "METRIC", "confidence": 0.9612167477607727}, {"text": "F-score", "start_pos": 62, "end_pos": 69, "type": "METRIC", "confidence": 0.6268572807312012}]}, {"text": " Table 9: Results for each class for task B, for the sub- mitted system (SVM with BOW plus SentiWordNet  features) for the SMS test data.", "labels": [], "entities": [{"text": "BOW", "start_pos": 82, "end_pos": 85, "type": "METRIC", "confidence": 0.9610038995742798}, {"text": "SMS test data", "start_pos": 123, "end_pos": 136, "type": "DATASET", "confidence": 0.6723446349302927}]}]}