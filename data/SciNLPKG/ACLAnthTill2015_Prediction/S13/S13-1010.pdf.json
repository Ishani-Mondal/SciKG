{"title": [], "abstractContent": [{"text": "We describe a number of techniques for automatically deriving lists of common and proper nouns, and show that the distinction between the two can be made automatically using a vector space model learning algorithm.", "labels": [], "entities": []}, {"text": "We present a direct evaluation on the British National Corpus, and application based evaluations on Twitter messages and on automatic speech recognition (where the system could be employed to restore case).", "labels": [], "entities": [{"text": "British National Corpus", "start_pos": 38, "end_pos": 61, "type": "DATASET", "confidence": 0.9215652346611023}, {"text": "speech recognition", "start_pos": 134, "end_pos": 152, "type": "TASK", "confidence": 0.664253830909729}]}], "introductionContent": [{"text": "Some nouns are homographs (they have the same written form, but different meaning) which can be used to denote either a common or proper noun, for example the word apple in the following examples: (1) Apple designs and creates iPod (2) The Apple II series is a set of 8-bit home computers (3) The apple is the pomaceous fruit of the apple tree (4) For apple enthusiasts -tasting notes and apple identification.", "labels": [], "entities": [{"text": "apple identification", "start_pos": 389, "end_pos": 409, "type": "TASK", "confidence": 0.7557404935359955}]}, {"text": "The common and proper uses are not always as clearly distinct as in this example; for example, a specific instance of a common noun, e.g., District Court turns court into a proper noun.", "labels": [], "entities": []}, {"text": "While heuristically, proper nouns often start with a capital letter in English, capitalization can be inconsistent, incorrect or omitted, and the presence or absence of an article cannot be relied on.", "labels": [], "entities": []}, {"text": "The problem of distinguishing between common and proper usages of nouns has not received much attention within language processing, despite being an important component for many tasks including machine translation), sentiment analysis () and topic tracking.", "labels": [], "entities": [{"text": "distinguishing between common and proper usages of nouns", "start_pos": 15, "end_pos": 71, "type": "TASK", "confidence": 0.7286580875515938}, {"text": "machine translation", "start_pos": 194, "end_pos": 213, "type": "TASK", "confidence": 0.7046436220407486}, {"text": "sentiment analysis", "start_pos": 216, "end_pos": 234, "type": "TASK", "confidence": 0.9670368731021881}, {"text": "topic tracking", "start_pos": 242, "end_pos": 256, "type": "TASK", "confidence": 0.9155576229095459}]}, {"text": "Approaches to the problem also have applications to tasks such as web search), and case restoration (e.g., in automatic speech recognition output) (), but frequently involve the manual creation of a gazeteer (a list of proper nouns), which suffer not only from omissions but also often do not allow the listed words to assume their common role in text.", "labels": [], "entities": [{"text": "case restoration", "start_pos": 83, "end_pos": 99, "type": "TASK", "confidence": 0.770671546459198}, {"text": "automatic speech recognition output", "start_pos": 110, "end_pos": 145, "type": "TASK", "confidence": 0.7491925209760666}]}, {"text": "This paper presents methods for generating lists of nouns that have both common and proper usages (Section 2) and methods for identifying the type of usage (Section 3) which are evaluated using data derived automatically from the BNC (Section 4) and on two applications (Section 5).", "labels": [], "entities": [{"text": "BNC", "start_pos": 230, "end_pos": 233, "type": "DATASET", "confidence": 0.9481395483016968}]}, {"text": "It shows that it is difficult to automatically construct lists of ambiguous nouns but also that they can be distinguished effectively using standard features from Word Sense Disambiguation.", "labels": [], "entities": [{"text": "Word Sense Disambiguation", "start_pos": 163, "end_pos": 188, "type": "TASK", "confidence": 0.6805170774459839}]}], "datasetContent": [{"text": "The approaches described in the previous section are evaluated on two data sets extracted automatically from the BNC.", "labels": [], "entities": [{"text": "BNC", "start_pos": 113, "end_pos": 116, "type": "DATASET", "confidence": 0.9593614935874939}]}, {"text": "The BNC-PoS data set is created using the output from the CLAWS tagger.", "labels": [], "entities": [{"text": "BNC-PoS data set", "start_pos": 4, "end_pos": 20, "type": "DATASET", "confidence": 0.8746869762738546}, {"text": "CLAWS tagger", "start_pos": 58, "end_pos": 70, "type": "DATASET", "confidence": 0.9023438692092896}]}, {"text": "Nouns assigned the tag NP0 are treated as proper nouns and those assigned any other nominal tag as common nouns.", "labels": [], "entities": []}, {"text": "(According to the BNC manual the NP0 tag has a precision 83.99% and recall 97.76%.", "labels": [], "entities": [{"text": "BNC manual", "start_pos": 18, "end_pos": 28, "type": "DATASET", "confidence": 0.9498600661754608}, {"text": "precision", "start_pos": 47, "end_pos": 56, "type": "METRIC", "confidence": 0.9996004700660706}, {"text": "recall", "start_pos": 68, "end_pos": 74, "type": "METRIC", "confidence": 0.9996980428695679}]}, {"text": ") This data set consists of all sentences in the BNC in which the target word appears.", "labels": [], "entities": [{"text": "BNC", "start_pos": 49, "end_pos": 52, "type": "DATASET", "confidence": 0.8155506253242493}]}, {"text": "The second data set, BNC-Capital, is created using capitalisation information and consists of instances of the target noun that do not appear sentence-initially.", "labels": [], "entities": [{"text": "BNC-Capital", "start_pos": 21, "end_pos": 32, "type": "METRIC", "confidence": 0.47453922033309937}]}, {"text": "Any instances that are capitalised are treated as proper nouns and those which are non-capitalised as common nouns.", "labels": [], "entities": []}, {"text": "Experiments were carried out using capitalised and decapitalized versions of the two test corpora.", "labels": [], "entities": []}, {"text": "The decapitalised versions by lowercasing each corpus and using it for training and testing.", "labels": [], "entities": []}, {"text": "Ten fold cross validation is used for all experiments: i.e. 9/10th of the corpus were used to acquire the training data centroids and 1/10th was used for evaluation.", "labels": [], "entities": []}, {"text": "The average performance over the 10 experiments is reported.", "labels": [], "entities": []}, {"text": "The vector space model (VSM) outperforms other approaches on both corpora.", "labels": [], "entities": []}, {"text": "Performance is particularly high when capitalisation is included (VSM w caps).", "labels": [], "entities": [{"text": "VSM w caps", "start_pos": 66, "end_pos": 76, "type": "DATASET", "confidence": 0.8373703161875407}]}, {"text": "However, this approach still outperforms the baseline without case information (VSM w/o caps), demonstrating that using this simple approach is less effective than making use of local context.", "labels": [], "entities": []}, {"text": "Gold standard BNC-PoS BNC-Capital Most frequent 79% 67% n-gram w caps 80% 77% n-gram w/o caps 68% 56% VSM w caps 90% 100% VSM w/o caps 86% 80%", "labels": [], "entities": [{"text": "Gold standard BNC-PoS BNC-Capital", "start_pos": 0, "end_pos": 33, "type": "DATASET", "confidence": 0.7365016639232635}]}], "tableCaptions": [{"text": " Table 1: Pairwise comparison of lists. The nouns in each  list are compared against the BNCclaws and Gigaword  lists. Results are computed for P(recision) and R(ecall).", "labels": [], "entities": [{"text": "BNCclaws", "start_pos": 89, "end_pos": 97, "type": "DATASET", "confidence": 0.8828663229942322}]}, {"text": " Table 2: Pairwise comparison of lists with filtering", "labels": [], "entities": []}]}