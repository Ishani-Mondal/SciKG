{"title": [{"text": "CodeX: Combining an SVM Classifier and Character N-gram Language Models for Sentiment Analysis on Twitter Text", "labels": [], "entities": [{"text": "Sentiment Analysis", "start_pos": 76, "end_pos": 94, "type": "TASK", "confidence": 0.9566433727741241}]}], "abstractContent": [{"text": "This paper briefly reports our system for the SemEval-2013 Task 2: sentiment analysis in Twitter.", "labels": [], "entities": [{"text": "SemEval-2013 Task 2", "start_pos": 46, "end_pos": 65, "type": "TASK", "confidence": 0.8994386394818624}, {"text": "sentiment analysis", "start_pos": 67, "end_pos": 85, "type": "TASK", "confidence": 0.7871754169464111}]}, {"text": "We first used an SVM classifier with a wide range of features, including bag of word features (unigram, bigram), POS features , stylistic features, readability scores and other statistics of the tweet being analyzed, domain names, abbreviations, emoticons in the Twitter text.", "labels": [], "entities": []}, {"text": "Then we investigated the effectiveness of these features.", "labels": [], "entities": []}, {"text": "We also used character n-gram language models to address the problem of high lexical variation in Twit-ter text and combined the two approaches to obtain the final results.", "labels": [], "entities": []}, {"text": "Our system is robust and achieves good performance on the Twitter test data as well as the SMS test data.", "labels": [], "entities": [{"text": "Twitter test data", "start_pos": 58, "end_pos": 75, "type": "DATASET", "confidence": 0.9522804419199625}, {"text": "SMS test data", "start_pos": 91, "end_pos": 104, "type": "DATASET", "confidence": 0.8851457238197327}]}], "introductionContent": [{"text": "The challenge of the SemEval-2013 Task 2 (Task B) is the \"Message Polarity Classification\" ().", "labels": [], "entities": [{"text": "SemEval-2013 Task", "start_pos": 21, "end_pos": 38, "type": "TASK", "confidence": 0.7868357300758362}, {"text": "Message Polarity Classification", "start_pos": 58, "end_pos": 89, "type": "TASK", "confidence": 0.7277067005634308}]}, {"text": "Specifically, the task was to classify whether a given message has positive, negative or neutral sentiment; for messages conveying both positive and negative sentiment, whichever is stronger should be chosen.", "labels": [], "entities": []}, {"text": "In recent years, text messaging and microblogging such as tweeting has gained its popularity.", "labels": [], "entities": [{"text": "text messaging", "start_pos": 17, "end_pos": 31, "type": "TASK", "confidence": 0.7646151483058929}]}, {"text": "Since these short messages are often used not only to discuss facts but also to share opinions and sentiments, sentiment analysis on this type of data has lately become interesting.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 111, "end_pos": 129, "type": "TASK", "confidence": 0.970173180103302}]}, {"text": "However, some features of this type of data make natural language processing challenging.", "labels": [], "entities": [{"text": "natural language processing", "start_pos": 49, "end_pos": 76, "type": "TASK", "confidence": 0.6713919838269552}]}, {"text": "For example, the messages are usually short and the language used can be very informal, with misspellings, creative spellings, slang, URLs and special abbreviations.", "labels": [], "entities": []}, {"text": "Some research has already been done attempting to address these problems, to enable sentiment analysis on this type of data, in particular on Twitter data, and even to use the outcome of sentiment analysis to make predictions (.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 84, "end_pos": 102, "type": "TASK", "confidence": 0.9714438915252686}, {"text": "sentiment analysis", "start_pos": 187, "end_pos": 205, "type": "TASK", "confidence": 0.8582657277584076}]}, {"text": "As the research mentioned above, our system used a machine learning based approach for sentiment analysis.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 87, "end_pos": 105, "type": "TASK", "confidence": 0.9673948884010315}]}, {"text": "Our system combines results from an SVM classifier using a wide range of features as well as votes derived from character n-gram language models to do the final prediction.", "labels": [], "entities": []}, {"text": "The rest of this paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 describes the features used for the SVM classifier.", "labels": [], "entities": [{"text": "SVM classifier", "start_pos": 46, "end_pos": 60, "type": "TASK", "confidence": 0.7628212869167328}]}, {"text": "Section 3 describes how the votes from character n-gram language models were derived.", "labels": [], "entities": []}, {"text": "Section 4 describes the details of our method.", "labels": [], "entities": []}, {"text": "And finally section 5 presents the results.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Cross validation average accuracy with differ- ent feature sets. we started with all 8 feature sets and  removed feature sets one by one, where we always first  removed the feature set that resulted in the biggest drop  in accuracy.", "labels": [], "entities": [{"text": "Cross validation", "start_pos": 10, "end_pos": 26, "type": "TASK", "confidence": 0.6993759572505951}, {"text": "accuracy", "start_pos": 35, "end_pos": 43, "type": "METRIC", "confidence": 0.7611620426177979}, {"text": "accuracy", "start_pos": 233, "end_pos": 241, "type": "METRIC", "confidence": 0.9969755411148071}]}, {"text": " Table 2: Cross validation average accuracy with further  combination of feature sets.", "labels": [], "entities": [{"text": "Cross validation", "start_pos": 10, "end_pos": 26, "type": "TASK", "confidence": 0.6607972085475922}, {"text": "accuracy", "start_pos": 35, "end_pos": 43, "type": "METRIC", "confidence": 0.7177965044975281}]}, {"text": " Table 3: Overall accuracy and average F1 score for posi- tive and negative classes on Twitter test data.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 18, "end_pos": 26, "type": "METRIC", "confidence": 0.9996144771575928}, {"text": "F1 score", "start_pos": 39, "end_pos": 47, "type": "METRIC", "confidence": 0.9827724695205688}, {"text": "Twitter test data", "start_pos": 87, "end_pos": 104, "type": "DATASET", "confidence": 0.8499050537745158}]}, {"text": " Table 4: Overall accuracy and average F1 score for posi- tive and negative classes on SMS test data.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 18, "end_pos": 26, "type": "METRIC", "confidence": 0.9996008276939392}, {"text": "F1 score", "start_pos": 39, "end_pos": 47, "type": "METRIC", "confidence": 0.9808410406112671}, {"text": "SMS test data", "start_pos": 87, "end_pos": 100, "type": "DATASET", "confidence": 0.8310070435206095}]}]}