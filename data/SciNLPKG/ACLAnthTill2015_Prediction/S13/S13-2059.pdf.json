{"title": [{"text": "AMI&ERIC: How to Learn with Naive Bayes and Prior Knowledge: an Application to Sentiment Analysis", "labels": [], "entities": [{"text": "AMI", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.9111130833625793}, {"text": "Sentiment Analysis", "start_pos": 79, "end_pos": 97, "type": "TASK", "confidence": 0.9483468234539032}]}], "abstractContent": [{"text": "In this paper, we describe our system that participated in SemEval-2013, Task 2.B (senti-ment analysis in Twitter).", "labels": [], "entities": []}, {"text": "Our approach consists of adapting Naive Bayes probabilities in order to take into account prior knowledge (represented in the form of a sentiment lexicon).", "labels": [], "entities": []}, {"text": "We propose two different methods to efficiently incorporate prior knowledge.", "labels": [], "entities": []}, {"text": "We show that our approach outperforms the classical Naive Bayes method and shows competitive results with SVM while having less computational complexity.", "labels": [], "entities": []}], "introductionContent": [{"text": "With the advent of Internet microblogging, social networks, like Twitter 1 and Facebook 2 , have brought about areal revolution in our way of communicating.", "labels": [], "entities": []}, {"text": "People share their opinions of everyday life without taboos or restrictions thanks to the anonymity offered by these tools, which makes them a valuable source of information rather rich of subjective data.", "labels": [], "entities": []}, {"text": "These data can be mined using sentiment analysis as a means to understand people's feelings towards apolitical cause or what people are thinking about a product or a service.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 30, "end_pos": 48, "type": "TASK", "confidence": 0.7977610528469086}]}, {"text": "Recent works showed that Twitter sentiments can be correlated to box-office revenues or political polls.", "labels": [], "entities": []}, {"text": "Machine learning methods, like Naive Bayes (NB) and Support Vector Machines (SVM), have been widely used in sentiment analysis (Pang et al., http://www.twitter.com/ 2 http://www.facebook.com/ 2002;.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 108, "end_pos": 126, "type": "TASK", "confidence": 0.9652749598026276}]}, {"text": "One major problem with these methods, and in particular NB, is that the model is built only on the learning data which can lead to overfitting.", "labels": [], "entities": []}, {"text": "In this paper, we describe our approach that participated in SemEval-2013, Task 2.B (sentiment analysis in Twitter) (.", "labels": [], "entities": [{"text": "sentiment analysis in Twitter)", "start_pos": 85, "end_pos": 115, "type": "TASK", "confidence": 0.8874276280403137}]}, {"text": "Our approach consists of learning with both NB and prior knowledge.", "labels": [], "entities": []}, {"text": "We show that our approach outperforms the classical NB method and gives competitive results compared to SVM while having less computational complexity.", "labels": [], "entities": []}, {"text": "The remainder of this paper is organized as follows: prior works on sentiment analysis are discussed in Section 2.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 68, "end_pos": 86, "type": "TASK", "confidence": 0.9740568995475769}]}, {"text": "The proposed approach is detailed in Section 3.", "labels": [], "entities": []}, {"text": "Then, experiments and results are given in Section 4 and 5.", "labels": [], "entities": []}], "datasetContent": [{"text": "To evaluate the proposed approach, we use SemEval-2013 datasets: TW (tweets obtained by merging learn and development data) and SMS, in addition to MR (English movie reviews of).", "labels": [], "entities": [{"text": "SemEval-2013 datasets", "start_pos": 42, "end_pos": 63, "type": "DATASET", "confidence": 0.8799009919166565}, {"text": "TW", "start_pos": 65, "end_pos": 67, "type": "METRIC", "confidence": 0.8509900569915771}, {"text": "MR", "start_pos": 148, "end_pos": 150, "type": "METRIC", "confidence": 0.9607381224632263}]}, {"text": "Concerning SMS, the classification is performed using the model learned on tweets (TW) in order to assess how it generalizes on SMS data.", "labels": [], "entities": []}, {"text": "Note that our approach is adapted to binary classification but can be used for 3-way classification (which is the case of TW and SMS).", "labels": [], "entities": []}, {"text": "We do this by adapting only positive and negative probabilities, neutral ones remain unchanged.", "labels": [], "entities": []}, {"text": "Texts are preprocessed by removing stopwords, numerics, punctuation and terms that occur only once (to reduce vocabulary size and data sparseness).", "labels": [], "entities": []}, {"text": "Texts are then stemmed using Porter stemmer).", "labels": [], "entities": []}, {"text": "We also remove URLs and Twitter keywords (via, RT) from tweets.", "labels": [], "entities": []}, {"text": "Pecision  Regarding F-score of each class), our approach gave better results on the negative class (under-represented in the learning data) than NB (49.09% on TW and 47.63% on SMS).", "labels": [], "entities": [{"text": "F-score", "start_pos": 20, "end_pos": 27, "type": "METRIC", "confidence": 0.9912506341934204}, {"text": "NB", "start_pos": 145, "end_pos": 147, "type": "METRIC", "confidence": 0.6780184507369995}]}], "tableCaptions": []}