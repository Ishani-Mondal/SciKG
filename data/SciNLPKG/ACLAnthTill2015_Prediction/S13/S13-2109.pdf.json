{"title": [{"text": "LASIGE: using Conditional Random Fields and ChEBI ontology", "labels": [], "entities": []}], "abstractContent": [{"text": "For participating in the SemEval 2013 challenge of recognition and classification of drug names, we adapted our chemical entity recognition approach consisting in Conditional Random Fields for recognizing chemical terms and lexical similarity for entity resolution to the ChEBI ontology.", "labels": [], "entities": [{"text": "SemEval 2013 challenge of recognition and classification of drug names", "start_pos": 25, "end_pos": 95, "type": "TASK", "confidence": 0.8601887345314025}, {"text": "chemical entity recognition", "start_pos": 112, "end_pos": 139, "type": "TASK", "confidence": 0.7014044721921285}, {"text": "entity resolution", "start_pos": 247, "end_pos": 264, "type": "TASK", "confidence": 0.7283672392368317}, {"text": "ChEBI ontology", "start_pos": 272, "end_pos": 286, "type": "DATASET", "confidence": 0.9406329989433289}]}, {"text": "We obtained promising results, with a best F-measure of 0.81 for the partial matching task when using post-processing.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 43, "end_pos": 52, "type": "METRIC", "confidence": 0.9989497065544128}]}, {"text": "Using only Conditional Random Fields the results are slightly lower, achieving still a good result in terms of F-measure.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 111, "end_pos": 120, "type": "METRIC", "confidence": 0.9867940545082092}]}, {"text": "Using the ChEBI ontology allowed a significant improvement in precision (best precision of 0.93 in partial matching task), which indicates that taking advantage of an ontology can be extremely useful for enhancing chemical entity recognition.", "labels": [], "entities": [{"text": "precision", "start_pos": 62, "end_pos": 71, "type": "METRIC", "confidence": 0.9993135929107666}, {"text": "precision", "start_pos": 78, "end_pos": 87, "type": "METRIC", "confidence": 0.9788070917129517}, {"text": "chemical entity recognition", "start_pos": 214, "end_pos": 241, "type": "TASK", "confidence": 0.6055206557114919}]}], "introductionContent": [{"text": "Most chemical named entity recognition systems can be classified in two approaches: dictionary based and machine learning based approaches.", "labels": [], "entities": [{"text": "chemical named entity recognition", "start_pos": 5, "end_pos": 38, "type": "TASK", "confidence": 0.6578227952122688}]}, {"text": "Dictionary based approaches are usually easier to implement and maintain, but require a reference chemical term dictionary and are dependent on its completeness and quality.", "labels": [], "entities": []}, {"text": "The availability of public chemical databases has been an issue until recently, when several publicly available databases such as PubChem (),) and ChEBI ( were released.", "labels": [], "entities": [{"text": "PubChem", "start_pos": 130, "end_pos": 137, "type": "DATASET", "confidence": 0.9772754311561584}, {"text": "ChEBI", "start_pos": 147, "end_pos": 152, "type": "DATASET", "confidence": 0.8843532800674438}]}, {"text": "An example of a popular system that uses this approach is Whatizit (Rebholz-.", "labels": [], "entities": []}, {"text": "Machine learning based approaches are not limited to a terminology and are thus better suited for finding novel chemical terms that are yet to be inserted in reference databases.", "labels": [], "entities": []}, {"text": "However this approach requires training data fora classifier to be able to successfully learn and perform the chemical entity recognition task.", "labels": [], "entities": [{"text": "chemical entity recognition task", "start_pos": 110, "end_pos": 142, "type": "TASK", "confidence": 0.677339494228363}]}, {"text": "Some methods combine both approaches and thus are hybrid systems that aim to take the best out of both approaches).", "labels": [], "entities": []}, {"text": "An annotated corpus of patent documents was released by ChEBI, and using such corpus as training data we developed an chemical entity recognition system () that uses a machine learning approach based on Conditional Random Fields (CRF) ().", "labels": [], "entities": [{"text": "ChEBI", "start_pos": 56, "end_pos": 61, "type": "DATASET", "confidence": 0.9654395580291748}, {"text": "chemical entity recognition", "start_pos": 118, "end_pos": 145, "type": "TASK", "confidence": 0.6358736455440521}]}, {"text": "We furthermore expanded our method to allow resolution of recognized entities to the ChEBI ontology (.", "labels": [], "entities": [{"text": "resolution of recognized entities", "start_pos": 44, "end_pos": 77, "type": "TASK", "confidence": 0.8902924954891205}]}, {"text": "This paper describes how our system ( ) was adapted to perform the task of recognition and classification of drug names, and presents the results obtained in the task 9.1 of the 7th International Workshop on Semantic Evaluation (SemEval 2013).", "labels": [], "entities": [{"text": "recognition and classification of drug names", "start_pos": 75, "end_pos": 119, "type": "TASK", "confidence": 0.8604821562767029}, {"text": "International Workshop on Semantic Evaluation (SemEval 2013)", "start_pos": 182, "end_pos": 242, "type": "TASK", "confidence": 0.5761865940358903}]}], "datasetContent": [{"text": "The Task 9 of SemEval 2013 involved two sub-tasks: (9.1) recognition and classification of drug names, and (9.2) extraction of drug-drug interactions from Biomedical Texts.", "labels": [], "entities": [{"text": "SemEval 2013", "start_pos": 14, "end_pos": 26, "type": "TASK", "confidence": 0.7375865578651428}, {"text": "recognition and classification of drug names", "start_pos": 57, "end_pos": 101, "type": "TASK", "confidence": 0.887668381134669}, {"text": "extraction of drug-drug interactions from Biomedical Texts", "start_pos": 113, "end_pos": 171, "type": "TASK", "confidence": 0.8570605601583209}]}, {"text": "The recognition and classification of drug names (Task 9.1) comprises two steps.", "labels": [], "entities": [{"text": "recognition and classification of drug names", "start_pos": 4, "end_pos": 48, "type": "TASK", "confidence": 0.8597707202037176}]}, {"text": "First is chemical named entity recognition, that consists in finding in a sentence the offsets for the start and end of a chemical entity.", "labels": [], "entities": [{"text": "chemical named entity recognition", "start_pos": 9, "end_pos": 42, "type": "TASK", "confidence": 0.6002929508686066}]}, {"text": "An exact match is achieved by correctly identifying both the start and end offset, as curators manually provided them.", "labels": [], "entities": [{"text": "exact match", "start_pos": 3, "end_pos": 14, "type": "METRIC", "confidence": 0.7851898968219757}]}, {"text": "If there is a mismatch in the offsets but there is some overlap with a manual annotation, then it is considered a partial match, otherwise it is a recognition error.", "labels": [], "entities": []}, {"text": "The second step consists in classifying each recognized entity in one of four possible entity types: i) Drug is any pharmaceutical product approved for human use; ii) Brand is a drug that was first developed by a pharmaceutical company; iii) Group refers to a class or group of drugs; iv) Drug n is an active substance that has not been approved for human use.", "labels": [], "entities": []}, {"text": "Thus, the evaluation takes into account not only entity recognition, but also the assigned type.", "labels": [], "entities": [{"text": "entity recognition", "start_pos": 49, "end_pos": 67, "type": "TASK", "confidence": 0.7578828036785126}]}, {"text": "Type matching assessment considers the entity type evaluation from partial matching entity recognition, while strict matching considers the entity type evaluation from exact matching.", "labels": [], "entities": [{"text": "Type matching assessment", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.8908961812655131}]}, {"text": "For training, the DDI corpus dataset was provided ().", "labels": [], "entities": [{"text": "DDI corpus dataset", "start_pos": 18, "end_pos": 36, "type": "DATASET", "confidence": 0.9587145249048868}]}, {"text": "This dataset contains two sub-datasets.", "labels": [], "entities": []}, {"text": "One that consists of MedLine abstracts, and other that contains DrugBank abstracts.", "labels": [], "entities": [{"text": "DrugBank abstracts", "start_pos": 64, "end_pos": 82, "type": "DATASET", "confidence": 0.9377497732639313}]}, {"text": "An unannotated test dataset was provided for testing and evaluating the systems.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Results obtained in Task 9.1 for the different assessments. Exact and Partial matching do not consider the  entity type, while Strict and Type matching consider the entity type for Exact and Partial matching entity recognition  respectively.", "labels": [], "entities": [{"text": "Partial matching entity recognition", "start_pos": 201, "end_pos": 236, "type": "TASK", "confidence": 0.6157478988170624}]}, {"text": " Table 2: Results obtained in Task 9.1 for each entity type. In this evaluation only the entities of a specific type are  considered at a time.", "labels": [], "entities": []}, {"text": " Table 3: Macro-average measures obtained for each run.", "labels": [], "entities": []}]}