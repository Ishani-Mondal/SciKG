{"title": [{"text": "FBK-irst : A Multi-Phase Kernel Based Approach for Drug-Drug Interaction Detection and Classification that Exploits Linguistic Information", "labels": [], "entities": [{"text": "FBK-irst", "start_pos": 0, "end_pos": 8, "type": "DATASET", "confidence": 0.9024580121040344}, {"text": "Drug-Drug Interaction Detection and Classification", "start_pos": 51, "end_pos": 101, "type": "TASK", "confidence": 0.7768569827079773}]}], "abstractContent": [{"text": "This paper presents the multi-phase relation extraction (RE) approach which was used for the DDI Extraction task of SemEval 2013.", "labels": [], "entities": [{"text": "multi-phase relation extraction (RE)", "start_pos": 24, "end_pos": 60, "type": "TASK", "confidence": 0.7523771027723948}, {"text": "DDI Extraction task of SemEval 2013", "start_pos": 93, "end_pos": 128, "type": "TASK", "confidence": 0.616272916396459}]}, {"text": "As a preliminary step, the proposed approach indirectly (and automatically) exploits the scope of negation cues and the semantic roles of involved entities for reducing the skewness in the training data as well as discarding possible negative instances from the test data.", "labels": [], "entities": []}, {"text": "Then, a state-of-the-art hybrid kernel is used to train a classifier which is later applied on the instances of the test data not filtered out by the previous step.", "labels": [], "entities": []}, {"text": "The official results of the task show that our approach yields an F-score of 0.80 for DDI detection and an F-score of 0.65 for DDI detection and classification.", "labels": [], "entities": [{"text": "F-score", "start_pos": 66, "end_pos": 73, "type": "METRIC", "confidence": 0.9994277358055115}, {"text": "DDI detection", "start_pos": 86, "end_pos": 99, "type": "TASK", "confidence": 0.7819643914699554}, {"text": "F-score", "start_pos": 107, "end_pos": 114, "type": "METRIC", "confidence": 0.9988155364990234}, {"text": "DDI detection and classification", "start_pos": 127, "end_pos": 159, "type": "TASK", "confidence": 0.6954205334186554}]}, {"text": "Our system obtained significantly higher results than all the other participating teams in this shared task and has been ranked 1st.", "labels": [], "entities": []}], "introductionContent": [{"text": "Drug-drug interaction (DDI) is a condition when one drug influences the level or activity of another.", "labels": [], "entities": [{"text": "Drug-drug interaction (DDI)", "start_pos": 0, "end_pos": 27, "type": "TASK", "confidence": 0.8323794901371002}]}, {"text": "The extraction of DDIs has significant importance for public health safety.", "labels": [], "entities": []}, {"text": "It was reported that about 2.2 million people in USA, age 57 to 85, were taking potentially dangerous combinations of drugs).", "labels": [], "entities": []}, {"text": "Another report mentioned that deaths from accidental drug interactions rose by 68 percent between 1999 and 2004.", "labels": [], "entities": []}, {"text": "The DDIExtraction 2011 and DDIExtraction 2013 shared tasks underline the importance of DDI extraction.", "labels": [], "entities": [{"text": "DDI extraction", "start_pos": 87, "end_pos": 101, "type": "TASK", "confidence": 0.7982630729675293}]}, {"text": "The DDIExtraction 2013 task concerns the recognition of drugs and the extraction of drug-drug interactions from biomedical literature.", "labels": [], "entities": [{"text": "DDIExtraction 2013 task", "start_pos": 4, "end_pos": 27, "type": "DATASET", "confidence": 0.8530847827593485}, {"text": "recognition of drugs", "start_pos": 41, "end_pos": 61, "type": "TASK", "confidence": 0.8712534109751383}, {"text": "extraction of drug-drug interactions from biomedical literature", "start_pos": 70, "end_pos": 133, "type": "TASK", "confidence": 0.8128304566655841}]}, {"text": "The dataset of the shared task is composed by texts from the DrugBank database as well as MedLine abstracts in order to deal with different type of texts and language styles.", "labels": [], "entities": [{"text": "DrugBank database", "start_pos": 61, "end_pos": 78, "type": "DATASET", "confidence": 0.9765986502170563}]}, {"text": "Participants were asked to not only extract DDIs but also classify them into one of four predefined classes: advise, effect, mechanism and int.", "labels": [], "entities": []}, {"text": "A detailed description of the task settings and data can be found in Segura-.", "labels": [], "entities": [{"text": "Segura-.", "start_pos": 69, "end_pos": 77, "type": "DATASET", "confidence": 0.8426055510838827}]}, {"text": "The system that we used in this shared task combines various techniques proposed in our recent research activities for relation extraction (RE).", "labels": [], "entities": [{"text": "relation extraction (RE)", "start_pos": 119, "end_pos": 143, "type": "TASK", "confidence": 0.9114645481109619}]}], "datasetContent": [{"text": "The Charniak-Johnson reranking parser, along with a self-trained biomedical parsing model, has been used for tokenization, POS-tagging and parsing of the sentences.", "labels": [], "entities": [{"text": "tokenization", "start_pos": 109, "end_pos": 121, "type": "TASK", "confidence": 0.9698461890220642}, {"text": "parsing of the sentences", "start_pos": 139, "end_pos": 163, "type": "TASK", "confidence": 0.866267740726471}]}, {"text": "Then the parse trees are processed by the Stanford parser ( to obtain syntactic dependencies.", "labels": [], "entities": []}, {"text": "The Stanford parser often skips some syntactic dependencies in output.", "labels": [], "entities": []}, {"text": "We use the rules proposed in Chowdhury and Lavelli (2012a) to recover some of such dependencies.", "labels": [], "entities": []}, {"text": "We use the same techniques for unknown characters (if any) as described in Chowdhury and Lavelli (2011).", "labels": [], "entities": []}, {"text": "Our system uses the SVM-Light-TK toolkit 3) for computation of the hybrid kernels.", "labels": [], "entities": []}, {"text": "The ratio of negative and positive examples has been used as the value of the costratio-factor parameter.", "labels": [], "entities": []}, {"text": "The SL kernel is computed using the jSRE tool . The K HF kernel can exploit non-target entities to extract important clues.", "labels": [], "entities": []}, {"text": "So, we use a publicly available state-of-theart NER system called to automatically annotate both the training and the test data with disease mentions.", "labels": [], "entities": []}, {"text": "The DDIExtraction 2013 shared task data include two types of texts: texts taken from the DrugBank database and texts taken from MedLine abstracts.", "labels": [], "entities": [{"text": "DDIExtraction 2013 shared task data", "start_pos": 4, "end_pos": 39, "type": "DATASET", "confidence": 0.9077653169631958}, {"text": "DrugBank database", "start_pos": 89, "end_pos": 106, "type": "DATASET", "confidence": 0.9688757359981537}]}, {"text": "During training we used both types together.", "labels": [], "entities": []}, {"text": "shows the results of 5-fold cross validation for DDI detection on the training data.", "labels": [], "entities": [{"text": "DDI detection", "start_pos": 49, "end_pos": 62, "type": "TASK", "confidence": 0.9002600908279419}]}, {"text": "As we can see, the usage of the LIS and LII filtering techniques improves both precision and recall.", "labels": [], "entities": [{"text": "precision", "start_pos": 79, "end_pos": 88, "type": "METRIC", "confidence": 0.9994252920150757}, {"text": "recall", "start_pos": 93, "end_pos": 99, "type": "METRIC", "confidence": 0.9988623857498169}]}, {"text": "We submitted three runs for the DDIExtraction 2013 shared task.", "labels": [], "entities": [{"text": "DDIExtraction 2013 shared task", "start_pos": 32, "end_pos": 62, "type": "DATASET", "confidence": 0.8798416703939438}]}, {"text": "The only difference between the three runs concerns the default class label (i.e. the class chosen when none of the separate models assigns a class label to a predicted DDI).", "labels": [], "entities": []}, {"text": "Such default class label is \"int\", \"effect\" and \"mechanism\" for run 1, 2 and 3 respectively.", "labels": [], "entities": []}, {"text": "According to the official results provided by the task organisers, our best result was obtained by run 2 (shown in).", "labels": [], "entities": []}, {"text": "According to the official results, the performance for \"advise\" is very low (F 1 0.29) in MedLine texts, while the performance for \"int\" is comparatively much higher (F 1 0.57) with respect to the one of the other DDI types.", "labels": [], "entities": [{"text": "F 1 0.29)", "start_pos": 77, "end_pos": 86, "type": "METRIC", "confidence": 0.9662184864282608}, {"text": "MedLine texts", "start_pos": 90, "end_pos": 103, "type": "DATASET", "confidence": 0.9406737685203552}, {"text": "F 1 0.57", "start_pos": 167, "end_pos": 175, "type": "METRIC", "confidence": 0.9482458432515463}]}, {"text": "In comparison, the performance for \"int\" is much lower (F 1 0.55) in DrugBank texts with respect to the one of the other DDI types.", "labels": [], "entities": [{"text": "F 1 0.55", "start_pos": 56, "end_pos": 64, "type": "METRIC", "confidence": 0.9702174464861552}, {"text": "DrugBank texts", "start_pos": 69, "end_pos": 83, "type": "DATASET", "confidence": 0.9610857367515564}]}, {"text": "In MedLine test data, the number of \"effect\" (62) and \"mechanism\" (24) DDIs is much higher than that of \"advise\" (7) and \"int\" (2: Official results of the best run (run 2) of our system in the DDIExtraction 2013 shared task.", "labels": [], "entities": [{"text": "MedLine test data", "start_pos": 3, "end_pos": 20, "type": "DATASET", "confidence": 0.9290843605995178}, {"text": "DDIExtraction 2013 shared task", "start_pos": 193, "end_pos": 223, "type": "DATASET", "confidence": 0.8001587092876434}]}, {"text": "hand, in DrugBank test data, the different DDIs are more evenly distributed -\"effect\" (298), \"mechanism\" (278), \"advise\" (214) and \"int\" (94).", "labels": [], "entities": [{"text": "DrugBank test data", "start_pos": 9, "end_pos": 27, "type": "DATASET", "confidence": 0.961632510026296}]}, {"text": "Initially, it was not clear to us why our system (as well as other participants) achieves so much higher results on the DrugBank sentences in comparison to MedLine sentences.", "labels": [], "entities": [{"text": "DrugBank sentences", "start_pos": 120, "end_pos": 138, "type": "DATASET", "confidence": 0.9402742683887482}]}, {"text": "Statistics of the average number of words show that the length of the two types of training sentences are substantially similar (DrugBank : 21.2, MedLine : 22.3).", "labels": [], "entities": [{"text": "DrugBank : 21.2", "start_pos": 129, "end_pos": 144, "type": "DATASET", "confidence": 0.905196487903595}]}, {"text": "It is true that the number of the training sentences for the former is almost 5.3 times higher than the latter.", "labels": [], "entities": []}, {"text": "But it could not be the main reason for such high discrepancies.", "labels": [], "entities": []}, {"text": "So, we turned our attention to the presence of the cue words.", "labels": [], "entities": []}, {"text": "In the 4,683 sentences of the DrugBank training set (which have at least one drug mention), we found that the words \"increase\" and \"decrease\" are present in 721 and 319 sentences respectively.", "labels": [], "entities": [{"text": "DrugBank training set", "start_pos": 30, "end_pos": 51, "type": "DATASET", "confidence": 0.9715479016304016}]}, {"text": "While in the 877 sentences of the MedLine training set (which have at least one drug mention), we found that the same words are present in only 67 and 40 sentences respectively.", "labels": [], "entities": [{"text": "MedLine training set", "start_pos": 34, "end_pos": 54, "type": "DATASET", "confidence": 0.9220278660456339}]}, {"text": "In other words, the presence of these two important cue words in the DrugBank sentences is twice more likely than that in the MedLine sentences.", "labels": [], "entities": [{"text": "DrugBank sentences", "start_pos": 69, "end_pos": 87, "type": "DATASET", "confidence": 0.9480645656585693}, {"text": "MedLine sentences", "start_pos": 126, "end_pos": 143, "type": "DATASET", "confidence": 0.8737823069095612}]}, {"text": "We assume similar observations might be also possible for other cue words.", "labels": [], "entities": []}, {"text": "Hence, this is probably the main reason why the results are so much better on the DrugBank sentences.", "labels": [], "entities": [{"text": "DrugBank sentences", "start_pos": 82, "end_pos": 100, "type": "DATASET", "confidence": 0.9792008101940155}]}], "tableCaptions": [{"text": " Table 1: Comparison of results for DDI detection on the  training data using 5-fold cross validation. Parameter tun- ing is not done during these experiments.", "labels": [], "entities": [{"text": "DDI detection", "start_pos": 36, "end_pos": 49, "type": "TASK", "confidence": 0.9367377460002899}, {"text": "Parameter tun- ing", "start_pos": 103, "end_pos": 121, "type": "METRIC", "confidence": 0.9249167442321777}]}, {"text": " Table 2: Official results of the best run (run 2) of our  system in the DDIExtraction 2013 shared task.", "labels": [], "entities": [{"text": "DDIExtraction 2013 shared task", "start_pos": 73, "end_pos": 103, "type": "DATASET", "confidence": 0.9058479070663452}]}]}