{"title": [{"text": "UTTime: Temporal Relation Classification using Deep Syntactic Features", "labels": [], "entities": [{"text": "UTTime", "start_pos": 0, "end_pos": 6, "type": "DATASET", "confidence": 0.49234405159950256}, {"text": "Temporal Relation Classification", "start_pos": 8, "end_pos": 40, "type": "TASK", "confidence": 0.9629365007082621}]}], "abstractContent": [{"text": "In this paper, we present a system, UTTime, which we submitted to TempEval-3 for Task C: Annotating temporal relations.", "labels": [], "entities": [{"text": "Annotating temporal relations", "start_pos": 89, "end_pos": 118, "type": "TASK", "confidence": 0.8416602412859598}]}, {"text": "The system uses logistic regression classifiers and exploits features extracted from a deep syntactic parser, including paths between event words in phrase structure trees and their path lengths, and paths between event words in predicate-argument structures and their subgraphs.", "labels": [], "entities": []}, {"text": "UT-Time achieved an F1 score of 34.9 based on the graphed-based evaluation for Task C (ranked 2 nd) and 56.45 for Task C-relation-only (ranked 1 st) in the TempEval-3 evaluation .", "labels": [], "entities": [{"text": "UT-Time", "start_pos": 0, "end_pos": 7, "type": "DATASET", "confidence": 0.9612686634063721}, {"text": "F1 score", "start_pos": 20, "end_pos": 28, "type": "METRIC", "confidence": 0.9816794395446777}]}], "introductionContent": [{"text": "Temporal annotation is the task of identifying temporal relationships between pairs of temporal entities, namely temporal expressions and events, within apiece of text.", "labels": [], "entities": [{"text": "Temporal annotation is the task of identifying temporal relationships between pairs of temporal entities, namely temporal expressions and events, within apiece of text", "start_pos": 0, "end_pos": 167, "type": "Description", "confidence": 0.7202704322338104}]}, {"text": "The temporal relationships are important to support other NLP applications such as textual entailment, document summarization, and question answering.", "labels": [], "entities": [{"text": "textual entailment", "start_pos": 83, "end_pos": 101, "type": "TASK", "confidence": 0.7057700157165527}, {"text": "document summarization", "start_pos": 103, "end_pos": 125, "type": "TASK", "confidence": 0.7275316715240479}, {"text": "question answering", "start_pos": 131, "end_pos": 149, "type": "TASK", "confidence": 0.9031075239181519}]}, {"text": "The temporal annotation task consists of several subtasks, including temporal expression extraction, event extraction, and temporal link identification and relation classification.", "labels": [], "entities": [{"text": "temporal expression extraction", "start_pos": 69, "end_pos": 99, "type": "TASK", "confidence": 0.6307251453399658}, {"text": "event extraction", "start_pos": 101, "end_pos": 117, "type": "TASK", "confidence": 0.7368153184652328}, {"text": "temporal link identification and relation classification", "start_pos": 123, "end_pos": 179, "type": "TASK", "confidence": 0.6095537344614664}]}, {"text": "In TempEval-3, there are three subtasks of the temporal annotation process offered, i.e., Task A: Temporal expression extraction and normalization, Task B: Event extraction, and Task C: Annotating temporal relations.", "labels": [], "entities": [{"text": "Temporal expression extraction", "start_pos": 98, "end_pos": 128, "type": "TASK", "confidence": 0.6890727678934733}, {"text": "Event extraction", "start_pos": 156, "end_pos": 172, "type": "TASK", "confidence": 0.7495178282260895}]}, {"text": "This paper presents a system to handle Task C. Based on the annotated data provided, this subtask requires identifying pairs of temporal entities and classifying the pairs into one of the 14 relation types according to The motivation behind our work is to utilize syntactic and semantic relationships between a pair of temporal entities in the temporal relation classification task, since we believe that these relationships convey the temporal relation.", "labels": [], "entities": [{"text": "temporal relation classification", "start_pos": 344, "end_pos": 376, "type": "TASK", "confidence": 0.6838538646697998}]}, {"text": "In addition to general features, which are easily extracted from sentences (e.g., part of speech tags, lemmas, synnonyms), we use features extracted using a deep syntactic parser.", "labels": [], "entities": []}, {"text": "The features from the deep parser can be divided into two groups: features from phrase structure trees and features from predicate-argument structures.", "labels": [], "entities": []}, {"text": "These features are only applicable in the case that the temporal entities appear in the same sentence, so we use only the general features for inter-sentence relations.", "labels": [], "entities": []}, {"text": "Predicate-argument structure expresses semantic relations between words.", "labels": [], "entities": []}, {"text": "This information can be extracted from a deep syntactic parser.", "labels": [], "entities": []}, {"text": "Features from predicate-argument structures can capture important temporal information (e.g., prepositions of time) from sentences effectively.", "labels": [], "entities": []}, {"text": "The remaining part of this paper is organized as follows.", "labels": [], "entities": []}, {"text": "We explain our approach in detail in Section 2 and then show the evaluation and results in Section 3.", "labels": [], "entities": []}, {"text": "Finally, we conclude with directions for future work in Section 4.", "labels": [], "entities": []}], "datasetContent": [{"text": "The scores are calculated by the graph-based evaluation metric proposed by.", "labels": [], "entities": []}, {"text": "We trained the models with TimeBank and AQUAINT corpora.", "labels": [], "entities": [{"text": "TimeBank", "start_pos": 27, "end_pos": 35, "type": "DATASET", "confidence": 0.9341651797294617}, {"text": "AQUAINT", "start_pos": 40, "end_pos": 47, "type": "METRIC", "confidence": 0.7397580146789551}]}, {"text": "We also trained our models on the training set with inverse relations.", "labels": [], "entities": []}, {"text": "The performance analysis is based on 10-fold cross validation on the development data.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Result of Task C. (rule: rule-based approach,  hyb.: hybrid approach, gen.: general features, ph.:phrase  structure tree features, pas.:predicate-argument structure  features, and inv.: Inverse relations are used for training.)", "labels": [], "entities": []}, {"text": " Table 2: Result of Task C-relation-only.  (gen.:  general features, ph.:phrase structure tree features,  pas.:predicate-argument structure features, and inv.: In- verse relations are used for training.)", "labels": [], "entities": []}, {"text": " Table 3: Result of Tack C on test data. (rule: rule-based  approach, hyb.: hybrid approach, and inv.: Inverse rela- tions are used for training.)", "labels": [], "entities": []}, {"text": " Table 4: Result of Task C-relation-only on test data.  (gen.: general features, ph.:phrase structure tree features,  pas.:predicate-argument structure features, and inv.: In- verse relations are used for training.)", "labels": [], "entities": []}]}