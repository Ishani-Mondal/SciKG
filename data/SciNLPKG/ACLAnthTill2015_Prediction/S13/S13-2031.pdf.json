{"title": [{"text": "HLTDI: CL-WSD Using Markov Random Fields for SemEval-2013 Task 10", "labels": [], "entities": [{"text": "HLTDI", "start_pos": 0, "end_pos": 5, "type": "DATASET", "confidence": 0.763878583908081}, {"text": "SemEval-2013 Task 10", "start_pos": 45, "end_pos": 65, "type": "TASK", "confidence": 0.8683197498321533}]}], "abstractContent": [{"text": "We present our entries for the SemEval-2013 cross-language word-sense disambigua-tion task (Lefever and Hoste, 2013).", "labels": [], "entities": [{"text": "SemEval-2013 cross-language word-sense disambigua-tion task", "start_pos": 31, "end_pos": 90, "type": "TASK", "confidence": 0.8076067924499511}]}, {"text": "We submitted three systems based on classifiers trained on local context features, with some elaborations.", "labels": [], "entities": []}, {"text": "Our three systems, in increasing order of complexity, were: maximum entropy classifiers trained to predict the desired target-language phrase using only monolingual features (we called this system L1); similar clas-sifiers, but with the desired target-language phrase for the other four languages as features (L2); and lastly, networks of five classifiers, over which we do loopy belief propagation to solve the classification tasks jointly (MRF).", "labels": [], "entities": [{"text": "loopy belief propagation", "start_pos": 374, "end_pos": 398, "type": "TASK", "confidence": 0.696250836054484}]}], "introductionContent": [{"text": "In the cross-language word-sense disambiguation (CL-WSD) task, given an instance of an ambiguous word used in a context, we want to predict the appropriate translation into some target language.", "labels": [], "entities": [{"text": "cross-language word-sense disambiguation (CL-WSD) task", "start_pos": 7, "end_pos": 61, "type": "TASK", "confidence": 0.7788866843496051}]}, {"text": "This setting for WSD has an immediate application in machine translation, since many words have multiple possible translations.", "labels": [], "entities": [{"text": "WSD", "start_pos": 17, "end_pos": 20, "type": "TASK", "confidence": 0.9265956878662109}, {"text": "machine translation", "start_pos": 53, "end_pos": 72, "type": "TASK", "confidence": 0.8184444010257721}]}, {"text": "Framing the resolution of lexical ambiguities as an explicit classification task has along history, and was considered in early SMT work at IBM (.", "labels": [], "entities": [{"text": "resolution of lexical ambiguities", "start_pos": 12, "end_pos": 45, "type": "TASK", "confidence": 0.8659471720457077}, {"text": "SMT", "start_pos": 128, "end_pos": 131, "type": "TASK", "confidence": 0.9931620359420776}]}, {"text": "More recently, Carpuat and Wu have shown how to use CL-WSD techniques to improve modern phrase-based SMT systems, even though the language model and phrase-tables of these systems mitigate the problem of lexical ambiguities somewhat.", "labels": [], "entities": [{"text": "SMT", "start_pos": 101, "end_pos": 104, "type": "TASK", "confidence": 0.8184064626693726}]}, {"text": "In the SemEval-2013 CL-WSD shared task (, entrants are asked to build a system that can provide translations for twenty ambiguous English nouns, given appropriate contexts -here the particular usage of the ambiguous noun is called the target word.", "labels": [], "entities": [{"text": "SemEval-2013 CL-WSD shared task", "start_pos": 7, "end_pos": 38, "type": "TASK", "confidence": 0.5731150954961777}]}, {"text": "The five target languages of the shared task are Spanish, Dutch, German, Italian and French.", "labels": [], "entities": []}, {"text": "In the evaluation, for each of the twenty ambiguous nouns, systems are to provide translations for the target word in each of fifty sentences or short passages.", "labels": [], "entities": []}, {"text": "The translations of each English word maybe single words or short phrases in the target language, but in either case, they should be lemmatized.", "labels": [], "entities": []}, {"text": "Following the work of Lefever and Hoste (2011), we wanted to make use of multiple bitext corpora for the CL-WSD task.", "labels": [], "entities": []}, {"text": "ParaSense, the system of Lefever and Hoste, takes into account evidence from all of the available parallel corpora.", "labels": [], "entities": [{"text": "ParaSense", "start_pos": 0, "end_pos": 9, "type": "DATASET", "confidence": 0.8271287083625793}]}, {"text": "Let S be the set of five target languages and t be the particular target language of interest at the moment; ParaSense creates bag-of-words features from the translations of the target sentence into the languages S\u2212{t}.", "labels": [], "entities": []}, {"text": "Given corpora that are parallel over many languages, this is straightforward at training time.", "labels": [], "entities": []}, {"text": "However, at testing time it requires a complete MT system for each of the four other languages, which is computationally prohibitive.", "labels": [], "entities": [{"text": "MT", "start_pos": 48, "end_pos": 50, "type": "TASK", "confidence": 0.9540181159973145}]}, {"text": "Thus in our work, we learn from several parallel corpora but require neither a locally running MT system nor access to an online translation API.", "labels": [], "entities": []}, {"text": "We presented three systems in this shared task, all of which were variations on the theme of a maximum entropy classifier for each ambiguous noun, trained on local context features similar to those used in previous work and familiar from the WSD literature.", "labels": [], "entities": [{"text": "WSD literature", "start_pos": 242, "end_pos": 256, "type": "DATASET", "confidence": 0.8192369937896729}]}, {"text": "The first system, L1 (\"layer one\"), uses maximum entropy classifiers trained on local con-text features.", "labels": [], "entities": []}, {"text": "The second system, L2 (\"layer two\"), is the same as the L1 system, with the addition of the correct translations into the other target languages as features, which at testing time are predicted with L1 classifiers.", "labels": [], "entities": []}, {"text": "The third system, MRF (\"Markov random field\") uses a network of interacting classifiers to solve the classification problem for all five target languages jointly.", "labels": [], "entities": [{"text": "MRF", "start_pos": 18, "end_pos": 21, "type": "METRIC", "confidence": 0.7891688942909241}]}, {"text": "Our three systems are all trained from the same data, which we extracted from the Europarl Intersection corpus provided by the shared task organizers.", "labels": [], "entities": [{"text": "Europarl Intersection corpus", "start_pos": 82, "end_pos": 110, "type": "DATASET", "confidence": 0.9531519015630087}]}, {"text": "At the time of the evaluation, our simplest system had the top results in the shared task for the out-of-five evaluation for three languages.", "labels": [], "entities": []}, {"text": "However, after the evaluation deadline, we fixed a simple bug in our MRF code, and the MRF system then achieved even better results for the oof evaluation.", "labels": [], "entities": [{"text": "MRF code", "start_pos": 69, "end_pos": 77, "type": "DATASET", "confidence": 0.785677433013916}]}, {"text": "For the best evaluation, our two more sophisticated systems posted better results than the L1 version.", "labels": [], "entities": []}, {"text": "All of our systems beat the \"most-frequent sense\" baseline in every case.", "labels": [], "entities": []}, {"text": "In the following sections, we will describe our three systems 1 , our training data extraction process, the results on the shared task, and conclusions and future work.", "labels": [], "entities": [{"text": "training data extraction", "start_pos": 70, "end_pos": 94, "type": "TASK", "confidence": 0.6600037614504496}]}], "datasetContent": [], "tableCaptions": []}