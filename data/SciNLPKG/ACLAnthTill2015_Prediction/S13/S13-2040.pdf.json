{"title": [{"text": "SemEval-2013 Task 12: Multilingual Word Sense Disambiguation", "labels": [], "entities": [{"text": "SemEval-2013 Task 12", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.8735634883244833}, {"text": "Multilingual Word Sense Disambiguation", "start_pos": 22, "end_pos": 60, "type": "TASK", "confidence": 0.728797011077404}]}], "abstractContent": [{"text": "This paper presents the SemEval-2013 task on multilingual Word Sense Disambiguation.", "labels": [], "entities": [{"text": "SemEval-2013 task", "start_pos": 24, "end_pos": 41, "type": "TASK", "confidence": 0.8717297315597534}, {"text": "multilingual Word Sense Disambiguation", "start_pos": 45, "end_pos": 83, "type": "TASK", "confidence": 0.6284311711788177}]}, {"text": "We describe our experience in producing a multilingual sense-annotated corpus for the task.", "labels": [], "entities": []}, {"text": "The corpus is tagged with BabelNet 1.1.1, a freely-available multilingual encyclopedic dictionary and, as a byproduct, WordNet 3.0 and the Wikipedia sense inventory.", "labels": [], "entities": [{"text": "Wikipedia sense inventory", "start_pos": 139, "end_pos": 164, "type": "DATASET", "confidence": 0.846116284529368}]}, {"text": "We present and analyze the results of participating systems , and discuss future directions.", "labels": [], "entities": []}], "introductionContent": [{"text": "Word Sense Disambiguation (WSD), the task of automatically assigning predefined meanings to words occurring in context, is a fundamental task in computational lexical semantics.", "labels": [], "entities": [{"text": "Word Sense Disambiguation (WSD)", "start_pos": 0, "end_pos": 31, "type": "TASK", "confidence": 0.789491871992747}, {"text": "automatically assigning predefined meanings to words occurring in context", "start_pos": 45, "end_pos": 118, "type": "TASK", "confidence": 0.5486125349998474}, {"text": "computational lexical semantics", "start_pos": 145, "end_pos": 176, "type": "TASK", "confidence": 0.6940677165985107}]}, {"text": "Several Senseval and SemEval tasks have been organized in the past to study the performance and limits of disambiguation systems and, even more importantly, disambiguation settings.", "labels": [], "entities": []}, {"text": "While an ad-hoc sense inventory was originally chosen for the first Senseval edition), later tasks () focused on WordNet () as a sense inventory.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 113, "end_pos": 120, "type": "DATASET", "confidence": 0.9525724053382874}]}, {"text": "In 2007 the issue of the fine sense granularity of WordNet was addressed in two different SemEval disambiguation tasks, leading to the beneficial creation of coarsergrained sense inventories from WordNet itself) and from OntoNotes (.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 51, "end_pos": 58, "type": "DATASET", "confidence": 0.9487482309341431}, {"text": "SemEval disambiguation", "start_pos": 90, "end_pos": 112, "type": "TASK", "confidence": 0.8475738167762756}, {"text": "OntoNotes", "start_pos": 221, "end_pos": 230, "type": "DATASET", "confidence": 0.8645239472389221}]}, {"text": "In recent years, with the exponential growth of the Web and, consequently, the increase of nonEnglish speaking surfers, we have witnessed an upsurge of interest in multilinguality.", "labels": [], "entities": []}, {"text": "SemEval-2010 tasks on cross-lingual Word Sense Disambiguation ( and cross-lingual lexical substitution ( were organized.", "labels": [], "entities": [{"text": "cross-lingual Word Sense Disambiguation", "start_pos": 22, "end_pos": 61, "type": "TASK", "confidence": 0.6406111270189285}, {"text": "cross-lingual lexical substitution", "start_pos": 68, "end_pos": 102, "type": "TASK", "confidence": 0.7080267469088236}]}, {"text": "While these tasks addressed the multilingual aspect of sense-level text understanding, they departed from the traditional WSD paradigm, i.e., the automatic assignment of senses from an existing inventory, and instead focused on lexical substitution).", "labels": [], "entities": [{"text": "sense-level text understanding", "start_pos": 55, "end_pos": 85, "type": "TASK", "confidence": 0.6251238683859507}, {"text": "WSD", "start_pos": 122, "end_pos": 125, "type": "TASK", "confidence": 0.8756234049797058}]}, {"text": "The main factor hampering traditional WSD from going multilingual was the lack of a freely-available large-scale multilingual dictionary.", "labels": [], "entities": [{"text": "WSD", "start_pos": 38, "end_pos": 41, "type": "TASK", "confidence": 0.9347186088562012}]}, {"text": "The recent availability of huge collaborativelybuilt repositories of knowledge such as Wikipedia has enabled the automated creation of large-scale lexical knowledge resources (.", "labels": [], "entities": []}, {"text": "Over the past few years, a wide-coverage multilingual \"encyclopedic\" dictionary, called BabelNet, has been developed (.", "labels": [], "entities": []}, {"text": "BabelNet 1 brings together WordNet and Wikipedia and provides a multilingual sense inventory that currently covers 6 languages.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 27, "end_pos": 34, "type": "DATASET", "confidence": 0.9201231598854065}]}, {"text": "We therefore decided to put the BabelNet 1.1.1 sense inventory to the test and organize a traditional Word Sense Disambiguation task on a given English test set translated into 4 other languages (namely, French, German, Spanish and Italian).", "labels": [], "entities": [{"text": "Word Sense Disambiguation task", "start_pos": 102, "end_pos": 132, "type": "TASK", "confidence": 0.6804938241839409}]}, {"text": "Not only does BabelNet enable multilinguality, but it also provides coverage for both lexicographic (e.g., apple as fruit) and encyclopedic meanings (e.g., Apple Inc. as company).", "labels": [], "entities": []}, {"text": "In this paper we describe our task and disambiguation dataset and report on the system results.", "labels": [], "entities": []}], "datasetContent": [{"text": "Task 12 uses the standard definitions of precision and recall for WSD evaluation (see, e.g.,).", "labels": [], "entities": [{"text": "precision", "start_pos": 41, "end_pos": 50, "type": "METRIC", "confidence": 0.9994334578514099}, {"text": "recall", "start_pos": 55, "end_pos": 61, "type": "METRIC", "confidence": 0.9977743029594421}, {"text": "WSD evaluation", "start_pos": 66, "end_pos": 80, "type": "TASK", "confidence": 0.9558032751083374}]}, {"text": "Precision measures the percentage of the sense assignments provided by the system that are identical to the gold standard; Recall measures the percentage of instances that are correctly labeled by the system.", "labels": [], "entities": [{"text": "Precision", "start_pos": 0, "end_pos": 9, "type": "METRIC", "confidence": 0.9851688146591187}, {"text": "Recall", "start_pos": 123, "end_pos": 129, "type": "METRIC", "confidence": 0.9530855417251587}]}, {"text": "When a system provides sense labels for all instances, precision and recall are equivalent.", "labels": [], "entities": [{"text": "precision", "start_pos": 55, "end_pos": 64, "type": "METRIC", "confidence": 0.9995824694633484}, {"text": "recall", "start_pos": 69, "end_pos": 75, "type": "METRIC", "confidence": 0.9995927214622498}]}, {"text": "Systems using BabelNet and WordNet senses are compared against the Most Frequent Sense (MFS) baseline obtained by using the WordNet most frequent sense.", "labels": [], "entities": [{"text": "Most Frequent Sense (MFS) baseline", "start_pos": 67, "end_pos": 101, "type": "METRIC", "confidence": 0.8042864969798497}]}, {"text": "For the Wikipedia sense inventory, we constructed a pseudo-MFS baseline by selecting (1) the Wikipedia page associated with the highest ranking WordNet sense, as ranked by SemCor frequency, or (2) when no synset fora lemma was associated with a WordNet sense, the first Wikipedia page sorted using BabelNet's ordering criteria, i.e., lexicographic sorting.", "labels": [], "entities": []}, {"text": "We note that, in the second case, this procedure frequently selected the page with the same name as the lemma itself.", "labels": [], "entities": []}, {"text": "For instance, the first sense of Dragon Ball is the cartoon with title DRAGON BALL, followed by two films and DRAGON BALL EVOLU-TION).", "labels": [], "entities": [{"text": "DRAGON BALL", "start_pos": 71, "end_pos": 82, "type": "METRIC", "confidence": 0.7490775883197784}, {"text": "DRAGON BALL EVOLU-TION", "start_pos": 110, "end_pos": 132, "type": "METRIC", "confidence": 0.7399327754974365}]}, {"text": "Systems were scored separately for each sense inventory.", "labels": [], "entities": []}, {"text": "We note that because the instances in each test set are filtered to include only those that can be labeled with the respective inventory, both the Wikipedia and WordNet test sets are subsets of the instances in the BabelNet test set.", "labels": [], "entities": [{"text": "WordNet test sets", "start_pos": 161, "end_pos": 178, "type": "DATASET", "confidence": 0.9148006637891134}, {"text": "BabelNet test set", "start_pos": 215, "end_pos": 232, "type": "DATASET", "confidence": 0.7621749937534332}]}], "tableCaptions": [{"text": " Table 1: Statistics for the sense annotations of the test set.", "labels": [], "entities": []}, {"text": " Table 2: Statistics when using the English sense an- notations to project the correct sense of a lemma in  another language of the sentence-aligned test data.", "labels": [], "entities": []}, {"text": " Table 3: System performance, reported as F1, for all five languages in the test set when using BabelNet  senses. Top performing systems are marked in bold.", "labels": [], "entities": [{"text": "F1", "start_pos": 42, "end_pos": 44, "type": "METRIC", "confidence": 0.9987132549285889}]}, {"text": " Table 4: The F1 measure for each system across all five languages in the test set when using Wikipedia-based  senses.", "labels": [], "entities": [{"text": "F1 measure", "start_pos": 14, "end_pos": 24, "type": "METRIC", "confidence": 0.9823622703552246}]}, {"text": " Table 5: System performance when using WordNet senses. Top performing systems are marked in bold.", "labels": [], "entities": []}, {"text": " Table 6: System F1 per instance type, averaged across all submitted languages, with the highest system  scores in bold.", "labels": [], "entities": [{"text": "F1", "start_pos": 17, "end_pos": 19, "type": "METRIC", "confidence": 0.87043696641922}]}, {"text": " Table 7: System performance when the system's annotations are restricted to only those senses that it also  uses in the aligned sentences of at least two other languages.", "labels": [], "entities": []}]}