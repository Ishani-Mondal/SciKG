{"title": [{"text": "SOFTCARDINALITY: Hierarchical Text Overlap for Student Response Analysis", "labels": [], "entities": [{"text": "Student Response Analysis", "start_pos": 47, "end_pos": 72, "type": "TASK", "confidence": 0.7996886173884074}]}], "abstractContent": [{"text": "In this paper we describe our system used to participate in the Student-Response-Analysis task-7 at SemEval 2013.", "labels": [], "entities": [{"text": "Student-Response-Analysis task-7 at SemEval 2013", "start_pos": 64, "end_pos": 112, "type": "DATASET", "confidence": 0.4803702712059021}]}, {"text": "This system is based on text overlap through the soft cardinality and anew mechanism for weight propagation.", "labels": [], "entities": [{"text": "text overlap", "start_pos": 24, "end_pos": 36, "type": "TASK", "confidence": 0.7017907500267029}, {"text": "weight propagation", "start_pos": 89, "end_pos": 107, "type": "TASK", "confidence": 0.7518158555030823}]}, {"text": "Although there are several official performance measures, taking into account the overall accuracy throughout the two availabe data sets (Beetle and SciEntsBank), our system ranked first in the 2 way classification task and second in the others.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 90, "end_pos": 98, "type": "METRIC", "confidence": 0.9990453124046326}, {"text": "availabe data sets", "start_pos": 118, "end_pos": 136, "type": "DATASET", "confidence": 0.9059126377105713}, {"text": "Beetle", "start_pos": 138, "end_pos": 144, "type": "DATASET", "confidence": 0.6473734974861145}, {"text": "2 way classification task", "start_pos": 194, "end_pos": 219, "type": "TASK", "confidence": 0.6433573067188263}]}, {"text": "Furthermore, our system performs particularly well with \"unseen-domains\" instances, which was the more challenging test set.", "labels": [], "entities": []}, {"text": "This paper also describes another system that integrates this method with the lexical-overlap baseline provided by the task organizers obtaining better results than the best official results.", "labels": [], "entities": []}, {"text": "We concluded that the soft cardinality method is a very competitive baseline for the automatic evaluation of student responses.", "labels": [], "entities": []}], "introductionContent": [{"text": "The Student-Response-Analysis (SRA) task consist in provide assessments of the correctness of student answers (A), considering their corresponding questions (Q) and reference answers (RA) ().", "labels": [], "entities": [{"text": "Student-Response-Analysis (SRA) task", "start_pos": 4, "end_pos": 40, "type": "TASK", "confidence": 0.6945915579795837}, {"text": "reference answers (RA)", "start_pos": 165, "end_pos": 187, "type": "METRIC", "confidence": 0.6397798180580139}]}, {"text": "SRA is the task-7 in the SemEval 2013 evaluation campaign (.", "labels": [], "entities": [{"text": "SRA", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.8271355628967285}, {"text": "SemEval 2013 evaluation", "start_pos": 25, "end_pos": 48, "type": "TASK", "confidence": 0.6175782084465027}]}, {"text": "The method used in our participation was basically text overlap based on the soft cardinality () plus a machine learning classifier.", "labels": [], "entities": [{"text": "text overlap", "start_pos": 51, "end_pos": 63, "type": "TASK", "confidence": 0.7318499684333801}]}, {"text": "This method did not use any information external to the data sets except fora stemmer and a list of stop words.", "labels": [], "entities": []}, {"text": "The soft cardinality is a general model for object comparison that has been tested at text applications.", "labels": [], "entities": [{"text": "object comparison", "start_pos": 44, "end_pos": 61, "type": "TASK", "confidence": 0.7229498624801636}]}, {"text": "Particularly, this text overlap approach has provided strong baselines for several applications, i.e. entity resolution (, semantic textual similarity (), cross-lingual textual entailment (), information retrieval, textual entailment and paraphrase detection ( . A brief description of the soft cardinality is presented in the next section.", "labels": [], "entities": [{"text": "text overlap", "start_pos": 19, "end_pos": 31, "type": "TASK", "confidence": 0.7145231813192368}, {"text": "entity resolution", "start_pos": 102, "end_pos": 119, "type": "TASK", "confidence": 0.7742155194282532}, {"text": "cross-lingual textual entailment", "start_pos": 155, "end_pos": 187, "type": "TASK", "confidence": 0.6606676081816355}, {"text": "information retrieval", "start_pos": 192, "end_pos": 213, "type": "TASK", "confidence": 0.8283296525478363}, {"text": "textual entailment", "start_pos": 215, "end_pos": 233, "type": "TASK", "confidence": 0.7421664595603943}, {"text": "paraphrase detection", "start_pos": 238, "end_pos": 258, "type": "TASK", "confidence": 0.9461769759654999}]}, {"text": "The data for SRA consist of two data sets Beetle (5,199 instances) and SciEntsBank (10,804 instances) divided into training and test sets (76%-24% for Beetle and 46%-54% SciEntsBank).", "labels": [], "entities": [{"text": "SRA", "start_pos": 13, "end_pos": 16, "type": "TASK", "confidence": 0.9443087577819824}, {"text": "Beetle", "start_pos": 42, "end_pos": 48, "type": "DATASET", "confidence": 0.9494063258171082}]}, {"text": "In addition, the test part of Beetle data set was divided into two test sets: \"unseen answers\" (35%) and \"unseen questions\" (65%).", "labels": [], "entities": [{"text": "Beetle data set", "start_pos": 30, "end_pos": 45, "type": "DATASET", "confidence": 0.9796687960624695}]}, {"text": "Similarity, SciEntsBank test part is divided into \"unseen answers\" (9%), \"unseen questions\" (13%) and \"unseen domains\" (78%).", "labels": [], "entities": [{"text": "SciEntsBank test part", "start_pos": 12, "end_pos": 33, "type": "DATASET", "confidence": 0.7578962842623392}]}, {"text": "All texts are in English.", "labels": [], "entities": []}, {"text": "The challenge consists in predicting for each instance triple (Q, A, RA) an assessment of correctness for the student's answer.", "labels": [], "entities": [{"text": "RA", "start_pos": 69, "end_pos": 71, "type": "METRIC", "confidence": 0.8919568657875061}]}, {"text": "Three levels of detail are considered for this assessment: 2 way (correct and incorrect), 3 way (correct, contradictory and incorrect) and 5 way (correct, incomplete, contradictory, irrelevant and non-in-the-domain).", "labels": [], "entities": [{"text": "detail", "start_pos": 16, "end_pos": 22, "type": "METRIC", "confidence": 0.9849898815155029}]}, {"text": "Section 3 presents the method used for the extraction of features from texts using the soft cardinality to provide a vector representation.", "labels": [], "entities": []}, {"text": "In Section 4, the details of the system used to produce our predic-tions are presented.", "labels": [], "entities": []}, {"text": "Besides, in that section a system that integrates our system with the lexical-overlap baseline proposed by the task organizers is also presented.", "labels": [], "entities": []}, {"text": "This combined system was motivated by the observation that our system performed well in the SciEntsBank data set but poorly in Beetle in comparison with the lexical-overlap baseline.", "labels": [], "entities": [{"text": "SciEntsBank data set", "start_pos": 92, "end_pos": 112, "type": "DATASET", "confidence": 0.8560372392336527}, {"text": "Beetle", "start_pos": 127, "end_pos": 133, "type": "DATASET", "confidence": 0.982671856880188}]}, {"text": "The results obtained by both systems are also presented in that section.", "labels": [], "entities": []}, {"text": "Finally in Section 5 the conclusions of our participation in this evaluation campaign are presented.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 3: Official results for the top-3 performing systems (among 15), the lexical overlap baseline in the SRA task  SemEval 2013 and unofficial results of the soft cardinality system combined with the lexical overlap (in italics).  Performance measure used: overall accuracy.", "labels": [], "entities": [{"text": "SRA task  SemEval 2013", "start_pos": 108, "end_pos": 130, "type": "TASK", "confidence": 0.7108918279409409}, {"text": "accuracy", "start_pos": 268, "end_pos": 276, "type": "METRIC", "confidence": 0.9911748170852661}]}]}