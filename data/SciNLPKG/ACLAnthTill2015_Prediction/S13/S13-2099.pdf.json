{"title": [{"text": "Celi: EDITS and Generic Text Pair Classification", "labels": [], "entities": [{"text": "EDITS", "start_pos": 6, "end_pos": 11, "type": "DATASET", "confidence": 0.6264979243278503}]}], "abstractContent": [{"text": "This paper presents CELI's participation in the SemEval The Joint Student Response Analysis and 8th Recognizing Textual Entailment Challenge (Task7) and Cross-lingual Textual Entailment for Content Synchronization task (Task 8).", "labels": [], "entities": [{"text": "SemEval", "start_pos": 48, "end_pos": 55, "type": "TASK", "confidence": 0.9016443490982056}, {"text": "8th", "start_pos": 96, "end_pos": 99, "type": "METRIC", "confidence": 0.9543268084526062}, {"text": "Cross-lingual Textual Entailment for Content Synchronization task", "start_pos": 153, "end_pos": 218, "type": "TASK", "confidence": 0.7529432858739581}]}], "introductionContent": [{"text": "Recognizing an existing relation between two text fragments received a significant interest as NLP task in the recent years.", "labels": [], "entities": [{"text": "Recognizing an existing relation between two text fragments", "start_pos": 0, "end_pos": 59, "type": "TASK", "confidence": 0.8473059237003326}]}, {"text": "A lot of the approaches were focused in the filed of Textual Entailment(TE).", "labels": [], "entities": [{"text": "filed of Textual Entailment(TE)", "start_pos": 44, "end_pos": 75, "type": "TASK", "confidence": 0.7665782528264182}]}, {"text": "TE has been proposed as as a comprehensive framework for applied semantics (, where the need for an explicit mapping between linguistic objects can be, at least partially, bypassed through the definition of semantic inferences at the textual level.", "labels": [], "entities": []}, {"text": "In the TE framework, a text (T ) is said to entail the hypothesis (H) if the meaning of H can be derived from the meaning of T . Initially defined as binary relation between texts (YES/NO there is an entailment or there is not) the TE evolved in the third RTE3 () challenge into a set of three relations between texts: ENTAILMENT, CONTRADICTION and UNKNOWN.", "labels": [], "entities": [{"text": "YES", "start_pos": 181, "end_pos": 184, "type": "METRIC", "confidence": 0.9911556243896484}, {"text": "RTE3", "start_pos": 256, "end_pos": 260, "type": "DATASET", "confidence": 0.8086633682250977}, {"text": "ENTAILMENT", "start_pos": 319, "end_pos": 329, "type": "METRIC", "confidence": 0.9476653933525085}, {"text": "CONTRADICTION", "start_pos": 331, "end_pos": 344, "type": "METRIC", "confidence": 0.8606685996055603}]}, {"text": "These relations are interpreted as follows: \u2022 ENTAILMENT -The T entails the H.", "labels": [], "entities": [{"text": "ENTAILMENT", "start_pos": 46, "end_pos": 56, "type": "METRIC", "confidence": 0.9957500696182251}, {"text": "T", "start_pos": 62, "end_pos": 63, "type": "METRIC", "confidence": 0.9324542284011841}]}, {"text": "\u2022 CONTRADICTION -The H contradicts the T \u2022 UNKNOWN -There is no semantic connection between T and H.", "labels": [], "entities": [{"text": "CONTRADICTION", "start_pos": 2, "end_pos": 15, "type": "METRIC", "confidence": 0.968241810798645}, {"text": "UNKNOWN", "start_pos": 43, "end_pos": 50, "type": "METRIC", "confidence": 0.9062170386314392}]}, {"text": "With more and more applications available for recognizing textual entailment the researches focused their efforts in finding practical applications for the developed systems.", "labels": [], "entities": [{"text": "recognizing textual entailment", "start_pos": 46, "end_pos": 76, "type": "TASK", "confidence": 0.8201583822568258}]}, {"text": "Thus the Cross-Lingual Textual Entailment task (CLTE) was created using textual entailment (TE) to define cross-lingual content synchronization scenario proposed in ), ).", "labels": [], "entities": [{"text": "Cross-Lingual Textual Entailment task (CLTE)", "start_pos": 9, "end_pos": 53, "type": "TASK", "confidence": 0.7606771503176007}]}, {"text": "The task is defined by the organizers as follows: Given a pair of topically related text fragments (T1 and T2) in different languages, the CLTE task consists of automatically annotating it with one of the following entailment judgments: \u2022 Bidirectional: the two fragments entail each other (semantic equivalence) \u2022 Forward: unidirectional entailment from T1 to T2 \u2022 Backward: unidirectional entailment from T2 to T1 \u2022 No Entailment: there is no entailment between T1 and T2 The textual entailment competition also evolved.", "labels": [], "entities": []}, {"text": "In this year SEMEVAL The Joint Student Response Analysis and 8th Recognizing Textual Entailment Challenge -JRSA-RTE8 (Task7) the textual entailment was defined in three subtasks: 5-way task , where the system is required to classify the student answer according to one of the following judgments: \u2022 Correct, if the student answer is a complete and correct paraphrase of the reference answer; \u2022 Partially correct incomplete, if the student answer is a partially correct answer containing some but not all information from the reference answer; \u2022 Contradictory, if the student answer explicitly contradicts the reference answer; \u2022 Irrelevant, if the student answer is \"irrelevant\", talking about domain content but not providing the necessary information; \u2022 Non domain, if the student answer expresses a request for help, frustration or lack of domain knowledge -e.g., \"I don't know\", \"as the book says\", \"you are stupid\".", "labels": [], "entities": [{"text": "Recognizing Textual Entailment Challenge -JRSA-RTE8", "start_pos": 65, "end_pos": 116, "type": "TASK", "confidence": 0.5542897979418436}]}, {"text": "3-way task , where the system is required to classify the student answer according to one of the following judgments: \u2022 correct \u2022 contradictory \u2022 incorrect, conflating the categories of partially correct incomplete, irrelevant or non domain in the 5-way classification 2-way task , where the system is required to classify the student answer according to one of the following judgments: \u2022 correct \u2022 incorrect, conflating the categories of contradictory and incorrect in the 3-way classification.", "labels": [], "entities": []}, {"text": "Following the overall trend, we have decided to convert our system for recognizing textual entailment EDITS from a simple YES/NO recognition system into a generic system capable of recognizing multiple semantic relationships between two texts.", "labels": [], "entities": [{"text": "recognizing textual entailment EDITS", "start_pos": 71, "end_pos": 107, "type": "TASK", "confidence": 0.7446452230215073}, {"text": "YES/NO recognition", "start_pos": 122, "end_pos": 140, "type": "TASK", "confidence": 0.7106667459011078}]}, {"text": "EDITS ( and ) is an open source package for recognizing textual entailment, which offers a modular, flexible, and adaptable working environment to experiment with the RTE task over different datasets.", "labels": [], "entities": [{"text": "EDITS", "start_pos": 0, "end_pos": 5, "type": "DATASET", "confidence": 0.8098779320716858}, {"text": "recognizing textual entailment", "start_pos": 44, "end_pos": 74, "type": "TASK", "confidence": 0.8058757185935974}, {"text": "RTE task", "start_pos": 167, "end_pos": 175, "type": "TASK", "confidence": 0.9005634188652039}]}, {"text": "The package allows to: i) create an entailment engine by defining its basic components ii) train such entailment engine over an annotated RTE corpus to learn a model; and iii) use the entailment engine and the model to assign an entailment judgments and a confidence score to each pair of an unannotated test corpus.", "labels": [], "entities": [{"text": "RTE corpus", "start_pos": 138, "end_pos": 148, "type": "DATASET", "confidence": 0.8164098560810089}]}, {"text": "We define the recognition of semantic relations between two texts as a classification task.", "labels": [], "entities": [{"text": "recognition of semantic relations between two texts", "start_pos": 14, "end_pos": 65, "type": "TASK", "confidence": 0.8493608917508807}]}, {"text": "In this task the system takes as an input two texts and classifies them in one of a set of predefined relations.", "labels": [], "entities": []}, {"text": "We have modified EDITS in order to handle the so defined task.", "labels": [], "entities": [{"text": "EDITS", "start_pos": 17, "end_pos": 22, "type": "DATASET", "confidence": 0.5719054937362671}]}, {"text": "Having this in mind we have participated in JRSA-RTE8 (task 7) and CLTE2 (task 8) with the same approach.", "labels": [], "entities": [{"text": "JRSA-RTE8", "start_pos": 44, "end_pos": 53, "type": "DATASET", "confidence": 0.6598948240280151}, {"text": "CLTE2", "start_pos": 67, "end_pos": 72, "type": "DATASET", "confidence": 0.8021889925003052}]}, {"text": "We have merged EDITS with some features from the TLike system described in our last participation in CLTE ).", "labels": [], "entities": [{"text": "CLTE", "start_pos": 101, "end_pos": 105, "type": "DATASET", "confidence": 0.8742496371269226}]}, {"text": "For each of the tasks we have created a specialized components that are integrated in EDITS as one of the system's modules.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Task 7 Results obtained. (Accuracy)", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 36, "end_pos": 44, "type": "METRIC", "confidence": 0.9990471005439758}]}]}