{"title": [{"text": "Experiments with DBpedia, WordNet and SentiWordNet as re- sources for sentiment analysis in micro-blogging", "labels": [], "entities": [{"text": "DBpedia", "start_pos": 17, "end_pos": 24, "type": "DATASET", "confidence": 0.9105810523033142}, {"text": "WordNet", "start_pos": 26, "end_pos": 33, "type": "DATASET", "confidence": 0.945321798324585}, {"text": "sentiment analysis", "start_pos": 70, "end_pos": 88, "type": "TASK", "confidence": 0.9453519880771637}]}], "abstractContent": [{"text": "Sentiment Analysis in Twitter has become an important task due to the huge user-generated content published over such media.", "labels": [], "entities": [{"text": "Sentiment Analysis", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.9620453715324402}]}, {"text": "Such analysis could be useful for many domains such as Marketing, Finance, Politics, and Social.", "labels": [], "entities": []}, {"text": "We propose to use many features in order to improve a trained classifier of Twitter messages ; these features extend the feature vector of uni-gram model by the concepts extracted from DBpedia, the verb groups and the similar adjectives extracted from WordNet, the Senti-features extracted using SentiWordNet and some useful domain specific features.", "labels": [], "entities": [{"text": "DBpedia", "start_pos": 185, "end_pos": 192, "type": "DATASET", "confidence": 0.9444421529769897}, {"text": "WordNet", "start_pos": 252, "end_pos": 259, "type": "DATASET", "confidence": 0.9477227926254272}]}, {"text": "We also built a dictionary for emotion icons, abbreviation and slang words in tweets which is useful before extending the tweets with different features.", "labels": [], "entities": []}, {"text": "Adding these features has improved the f-measure accuracy 2% with SVM and 4% with NaiveBayes.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 49, "end_pos": 57, "type": "METRIC", "confidence": 0.965670645236969}]}], "introductionContent": [{"text": "In recent years, the explosion of social media has changed the relation between the users and the web.", "labels": [], "entities": []}, {"text": "The world has become closer and more \"realtime\" than ever.", "labels": [], "entities": []}, {"text": "People have increasingly been part of virtual society where they have created their content, shared it, interacted with others in different ways and at a very increasingly rate.", "labels": [], "entities": []}, {"text": "Twitter is one of the most important social media, with 1 billion tweets 1 posted per week and 637 million users 2 . 1http://blog.kissmetrics.com/twitter-statistics/ 2http://twopcharts.com/twitter500million.php With the availability of such content, it attracts the attention from who want to understand the opinion and interestingness of individuals.", "labels": [], "entities": []}, {"text": "Thus, it would be useful in various domains such as politics, financing, marketing and social.", "labels": [], "entities": []}, {"text": "In this context, the efficacy of sentiment analysis of twitter has been demonstrated at improving prediction of box-office revenues of movies in advance of their release.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 33, "end_pos": 51, "type": "TASK", "confidence": 0.8881384432315826}]}, {"text": "Sentiment Analysis has been used to study the impact of 13 twitter accounts of celebrated person on their followers () and for forecasting the interesting tweets which are more probably to be reposted by the followers many times.", "labels": [], "entities": [{"text": "Sentiment Analysis", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.9227829277515411}]}, {"text": "However, sentiment analysis of microblogs faces several challenges, the limited size of posts (e.g., maximum 140 characters in Twitter), the informal language of such content containing slang words and non-standard expressions (e.g. gr8 instead of great, LOL instead of laughing out loud, goooood etc.), and the high level of noise in the posts due to the absence of correctness verification by user or spelling checker tools.", "labels": [], "entities": [{"text": "sentiment analysis of microblogs", "start_pos": 9, "end_pos": 41, "type": "TASK", "confidence": 0.9151203632354736}]}, {"text": "Three different approaches can be identified in the literature of Sentiment Analysis, the first approach is the lexicon based which uses specific types of lexicons to derive the polarity of a text, this approach is suffering from the limited size of lexicon and requires human expertise to build the lexicon).", "labels": [], "entities": [{"text": "Sentiment Analysis", "start_pos": 66, "end_pos": 84, "type": "TASK", "confidence": 0.9452232122421265}]}, {"text": "The second one is machine learning approach which uses annotated texts with a given label to learn a statistical model and an early work was done on a movie review dataset (Pang, In this paper, we employ machine learning.", "labels": [], "entities": []}, {"text": "Each text is represented by a vector in which the features have to be selected carefully.", "labels": [], "entities": []}, {"text": "They can be the words of the text, their POS tags (part of speech), or any other syntactic or semantic features.", "labels": [], "entities": []}, {"text": "We propose to exploit some additional features (section 3) for sentiment analysis that extend the representation of tweets by: \u2022 the concepts extracted from DBpedia 3 , \u2022 the related adjectives and verb groups extracted from WordNet 4 , \u2022 some \"social\" features such as the number of happy and bad emotion icons, \u2022 the number of exclamation and question marks, \u2022 the existence of URL (binary feature), \u2022 if the tweet is re-tweeted (binary feature), \u2022 the number of symbols the tweet contains, \u2022 the number of uppercase words, \u2022 some other senti-features extracted from SentiWordNet 5 such as the number of positive, negative and neutral words that allow estimating a score of the negativity, positivity and objectivity of the tweets, their polarity and subjectivity.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 63, "end_pos": 81, "type": "TASK", "confidence": 0.959890753030777}]}, {"text": "We extended the unigram model with these features (section 4.2).", "labels": [], "entities": []}, {"text": "We also constructed a dictionary for the abbreviations and the slang words used in Twitter in order to overcome the ambiguity of the tweets.", "labels": [], "entities": []}, {"text": "We tested various combinations (section 4.2) of these features, and then we chose the one that gave the highest F-measure for negative and positive classes (submission for Tweet subtask B of sentiment analysis in twitter task of SemEval2013 (Wilson,).", "labels": [], "entities": [{"text": "F-measure", "start_pos": 112, "end_pos": 121, "type": "METRIC", "confidence": 0.9975650310516357}, {"text": "sentiment analysis", "start_pos": 191, "end_pos": 209, "type": "TASK", "confidence": 0.7959029376506805}]}, {"text": "We tested different machine learning models: Na\u00efve Bayes, SVM, IcsiBoost 6 but the submitted runs exploited SVM only 6 . The rest of this paper is organized as follows.", "labels": [], "entities": [{"text": "SVM", "start_pos": 58, "end_pos": 61, "type": "DATASET", "confidence": 0.8351555466651917}]}, {"text": "Section 2 outlines existing work of sentiment analysis over Twitter.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 36, "end_pos": 54, "type": "TASK", "confidence": 0.9363870322704315}]}, {"text": "Section 3 presents the features we used for training a classifier.", "labels": [], "entities": []}, {"text": "Our experiments are described in section 4 and future work is presented in section 5.", "labels": [], "entities": []}], "datasetContent": [{"text": "We have done various experiments using the features presented in Section 3 with SVM model using linear kernel and the following parameters: weighting value=1, degree=3, cost=1, nu=0.5 and seed=1.", "labels": [], "entities": []}, {"text": "We firstly constructed feature vector of tweet terms which gave 0.52% for f-measure of the negative and positive classes.", "labels": [], "entities": []}, {"text": "Then, we augmented this vector by the similar adjectives of WordNet which improves a little the f-measure, particularly for the positive class.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 60, "end_pos": 67, "type": "DATASET", "confidence": 0.9693220257759094}]}, {"text": "After that, we added the concepts of DBpedia which also improved the quality of the positive class and declined the negative one.", "labels": [], "entities": [{"text": "DBpedia", "start_pos": 37, "end_pos": 44, "type": "DATASET", "confidence": 0.7718607187271118}]}, {"text": "Finally, we added all the verb groups, sentifeatures and domain specific features which improved the f-measure for both negative and positive classes but particularly for the positive one.", "labels": [], "entities": []}, {"text": "We remark that the DBpedia concepts improved the accuracy, and just the similar adjectives and group verbs of WordNet improved it, but the other synonyms and concepts declined it.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 49, "end_pos": 57, "type": "METRIC", "confidence": 0.999553382396698}, {"text": "WordNet", "start_pos": 110, "end_pos": 117, "type": "DATASET", "confidence": 0.9680049419403076}]}, {"text": "The reason maybe linked to a perturbation added by the synonyms.", "labels": [], "entities": []}, {"text": "Moreover, the first synonym set is not necessary to be the most suitable one.", "labels": [], "entities": []}, {"text": "Many domain specific and Senti-WordNet features improved the accuracy, but others did not, such as the number of neutral words, whether the tweet is reposted or not, the number of @ and the number of #.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 61, "end_pos": 69, "type": "METRIC", "confidence": 0.9992939233779907}]}, {"text": "So we excluded the features that declined the accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 46, "end_pos": 54, "type": "METRIC", "confidence": 0.9993714690208435}]}, {"text": "We have done some experiments using NaiveBayes.", "labels": [], "entities": []}, {"text": "Na\u00efve Bayes improved the accuracy of the negative and positive classes, and the highest f-measure was obtained by adding the adjectives and the DBpedia concepts.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 25, "end_pos": 33, "type": "METRIC", "confidence": 0.999441921710968}]}, {"text": "Using such features improved the f-measure for the positive and negative classes: about 2% with SVM and 4% with NaiveBayes.", "labels": [], "entities": [{"text": "f-measure", "start_pos": 33, "end_pos": 42, "type": "METRIC", "confidence": 0.9454619288444519}, {"text": "SVM", "start_pos": 96, "end_pos": 99, "type": "DATASET", "confidence": 0.8189157247543335}]}, {"text": "The improvement given by means of the Na\u00efve Bayes model was more significant than the one obtained with SVM and needed fewer features, but the higher accuracy was obtained by SVM.", "labels": [], "entities": [{"text": "Na\u00efve Bayes model", "start_pos": 38, "end_pos": 55, "type": "DATASET", "confidence": 0.8919640382130941}, {"text": "SVM", "start_pos": 104, "end_pos": 107, "type": "DATASET", "confidence": 0.9050594568252563}, {"text": "accuracy", "start_pos": 150, "end_pos": 158, "type": "METRIC", "confidence": 0.9995328187942505}, {"text": "SVM", "start_pos": 175, "end_pos": 178, "type": "DATASET", "confidence": 0.943444013595581}]}], "tableCaptions": [{"text": " Table 1 presents the results for each kind of feature  vector.", "labels": [], "entities": []}]}