{"title": [{"text": "SZTE-NLP: Sentiment Detection on Twitter Messages", "labels": [], "entities": [{"text": "Sentiment Detection on Twitter Messages", "start_pos": 10, "end_pos": 49, "type": "TASK", "confidence": 0.8986037850379944}]}], "abstractContent": [{"text": "In this paper we introduce our contribution to the SemEval-2013 Task 2 on \"Sentiment Analysis in Twitter\".", "labels": [], "entities": [{"text": "SemEval-2013 Task 2", "start_pos": 51, "end_pos": 70, "type": "TASK", "confidence": 0.8117761214574178}, {"text": "Sentiment Analysis in Twitter", "start_pos": 75, "end_pos": 104, "type": "TASK", "confidence": 0.9083664268255234}]}, {"text": "We participated in \"task B\", where the objective was to build models which classify tweets into three classes (positive, negative or neutral) by their contents.", "labels": [], "entities": []}, {"text": "To solve this problem we basically followed the supervised learning approach and proposed several domain (i.e. microblog) specific improvements including text preprocess-ing and feature engineering.", "labels": [], "entities": [{"text": "feature engineering", "start_pos": 178, "end_pos": 197, "type": "TASK", "confidence": 0.807297945022583}]}, {"text": "Beyond the supervised setting we also introduce some early results employing a huge, automatically annotated tweet dataset.", "labels": [], "entities": []}], "introductionContent": [{"text": "In the past few years, the popularity of social media has increased.", "labels": [], "entities": []}, {"text": "Many studies have been made in the area (.", "labels": [], "entities": []}, {"text": "People post messages on a variety of topics, for example products, political issues, etc.", "labels": [], "entities": []}, {"text": "Thus a big amount of user generated data is created day-by-day.", "labels": [], "entities": []}, {"text": "The manual processing of this data is impossible, therefore automatic procedures are needed.", "labels": [], "entities": []}, {"text": "In this paper we introduce an approach which is able to assign sentiment labels to Twitter messages.", "labels": [], "entities": [{"text": "assign sentiment labels to Twitter messages", "start_pos": 56, "end_pos": 99, "type": "TASK", "confidence": 0.7612903018792471}]}, {"text": "More precisely, it classifies tweets into positive, negative or neutral polarity classes.", "labels": [], "entities": []}, {"text": "The system participated in the SemEval-2013 Task 2: Sentiment Analysis in Twitter, Task-B Message Polarity Classification ().", "labels": [], "entities": [{"text": "SemEval-2013 Task 2", "start_pos": 31, "end_pos": 50, "type": "TASK", "confidence": 0.7779811024665833}, {"text": "Sentiment Analysis", "start_pos": 52, "end_pos": 70, "type": "TASK", "confidence": 0.8723516762256622}, {"text": "Message Polarity Classification", "start_pos": 90, "end_pos": 121, "type": "TASK", "confidence": 0.65419802069664}]}, {"text": "In our approach we used a unigram based supervised model because it has been shown that it works well on short messages like tweets.", "labels": [], "entities": []}, {"text": "We reduced the size of the dictionary by normalizing the messages and by stop word filtering.", "labels": [], "entities": []}, {"text": "We also explored novel features which gave us information on the polarity of a tweet, for example we made use of the acronyms in messages.", "labels": [], "entities": []}, {"text": "In the \"constrained\" track of Task-B we used the given training and development data only.", "labels": [], "entities": []}, {"text": "For the \"unconstrained\" track we downloaded tweets using the Twitter Streaming API 1 and automatically annotated them.", "labels": [], "entities": []}, {"text": "We present some preliminary results on exploiting this huge dataset for training our classifier.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 2: Unigram-based model, Maximum Entropy  learner", "labels": [], "entities": []}, {"text": " Table 4: Normalized model, Maximum Entropy  learner", "labels": [], "entities": []}, {"text": " Table 6: Feature-based model, Maximum Entropy  learner", "labels": [], "entities": []}]}