{"title": [{"text": "iKernels-Core: Tree Kernel Learning for Textual Similarity", "labels": [], "entities": []}], "abstractContent": [{"text": "This paper describes the participation of iKer-nels system in the Semantic Textual Similarity (STS) shared task at *SEM 2013.", "labels": [], "entities": [{"text": "Semantic Textual Similarity (STS) shared task at *SEM 2013", "start_pos": 66, "end_pos": 124, "type": "TASK", "confidence": 0.7924831757942835}]}, {"text": "Different from the majority of approaches, where a large number of pairwise similarity features are used to learn a regression model, our model directly encodes the input texts into syntac-tic/semantic structures.", "labels": [], "entities": []}, {"text": "Our systems rely on tree kernels to automatically extract a rich set of syntactic patterns to learn a similarity score correlated with human judgements.", "labels": [], "entities": []}, {"text": "We experiment with different structural representations derived from constituency and dependency trees.", "labels": [], "entities": []}, {"text": "While showing large improvements over the top results from the previous year task (STS-2012), our best system ranks 21st out of total 88 participated in the STS-2013 task.", "labels": [], "entities": []}, {"text": "Nevertheless, a slight refinement to our model makes it rank 4th.", "labels": [], "entities": []}], "introductionContent": [{"text": "Comparing textual data to establish the degree of semantic similarity is of key importance in many Natural Language Processing (NLP) tasks ranging from document categorization to textual entailment and summarization.", "labels": [], "entities": [{"text": "textual entailment", "start_pos": 179, "end_pos": 197, "type": "TASK", "confidence": 0.7131726890802383}, {"text": "summarization", "start_pos": 202, "end_pos": 215, "type": "TASK", "confidence": 0.9140775203704834}]}, {"text": "The key aspect of having an accurate STS framework is the design of features that can adequately represent various aspects of the similarity between texts, e.g. using lexical, syntactic and semantic similarity metrics.", "labels": [], "entities": []}, {"text": "The majority of approaches to semantic textual similarity treat the input text pairs as feature vectors where each feature is a score corresponding to a certain type of similarity.", "labels": [], "entities": [{"text": "semantic textual similarity", "start_pos": 30, "end_pos": 57, "type": "TASK", "confidence": 0.6254219710826874}]}, {"text": "This approach is conceptually easy to implement and STS-2012 () has shown that the best systems were built following this idea, i.e. a number of features encoding similarity of an input text pair were combined in a single scoring model, such as Linear Regression or Support Vector Regression (SVR).", "labels": [], "entities": []}, {"text": "One potential limitation of using only similarity features to represent a text pair is that of low representation power.", "labels": [], "entities": []}, {"text": "The novelty of our approach is that we encode the input text pairs directly into structural objects, e.g. trees, and rely on the power of kernel learning to extract relevant structures.", "labels": [], "entities": []}, {"text": "This completely different from (, where tree kernels where used to establish syntactic similarity and then plugged as similarity features.", "labels": [], "entities": []}, {"text": "To link the documents in a pair we mark the nodes in the related structures with a special relational tag.", "labels": [], "entities": []}, {"text": "In this way effective structural relational patterns are implicitly encoded in the trees and can be automatically learned by the kernelbased machine learning methods.", "labels": [], "entities": []}, {"text": "We build our systems on top of the features used by two best systems from STS-2012 and combine them with the tree kernel models within the Support Vector Regression to derive a single scoring model.", "labels": [], "entities": []}, {"text": "Since the test data used for evaluation in) is different from the 2012 data provided for the system development, domain adaptation represents an additional challenge.", "labels": [], "entities": [{"text": "domain adaptation", "start_pos": 113, "end_pos": 130, "type": "TASK", "confidence": 0.7494099736213684}]}, {"text": "To address this problem we augment our feature vector representation with features extracted from a text pair as a whole to capture individual properties of each dataset.", "labels": [], "entities": []}, {"text": "Additionally, we experiment with a corpus type classifier and include its prediction score as additional features.", "labels": [], "entities": []}, {"text": "Finally, we use stacking to combine several structural models into the feature vector representation.", "labels": [], "entities": []}, {"text": "In the following sections we describe our approach to combine structural representations with the pairwise similarity features in a single SVR learning framework.", "labels": [], "entities": []}, {"text": "We then report results on both STS-2012 and 2013 tasks.", "labels": [], "entities": []}], "datasetContent": [{"text": "To encode TK models along with the similarity feature vectors into a single regression scoring model,: System configurations and results on STS-2012.", "labels": [], "entities": []}, {"text": "Column set base lists 3 feature sets : UKP (U), Takelab (T) and iKernels (I); corpus type features (corpus) include plain features (B), corpus classifier (O), and manually encoded dataset category (M); TK contains constituency (C) and dependency-based (D) models.", "labels": [], "entities": [{"text": "UKP", "start_pos": 39, "end_pos": 42, "type": "DATASET", "confidence": 0.9091523885726929}]}, {"text": "UKP best is the best system of STS-2012.", "labels": [], "entities": [{"text": "UKP best", "start_pos": 0, "end_pos": 8, "type": "DATASET", "confidence": 0.9217984676361084}, {"text": "STS-2012", "start_pos": 31, "end_pos": 39, "type": "DATASET", "confidence": 0.7937473654747009}]}, {"text": "First column shows configuration of our three system runs submitted to we use an SVR framework implemented in SVMLight-TK 9 . We use the following parameter settings -t 5 -F 3 -W A -C +, which specifies to use a combination of trees and feature vectors (-C +), PTK over trees (-F 3) computed in all-vs-all mode (-W A) and using polynomial kernel of degree 3 for the feature vector (active by default).", "labels": [], "entities": []}, {"text": "We report the following metrics employed in the final evaluation: Pearson correlation for individual test sets and Mean -an average score weighted by the test set size.", "labels": [], "entities": [{"text": "Pearson correlation", "start_pos": 66, "end_pos": 85, "type": "METRIC", "confidence": 0.915552407503128}, {"text": "Mean", "start_pos": 115, "end_pos": 119, "type": "METRIC", "confidence": 0.9988589286804199}]}], "tableCaptions": [{"text": " Table 1: System configurations and results on STS-2012. Column set base lists 3 feature sets : UKP (U), Takelab  (T) and iKernels (I); corpus type features (corpus) include plain features (B), corpus classifier (O), and manually  encoded dataset category (M); TK contains constituency (C) and dependency-based (D) models. UKP best is the best  system of STS-2012. First column shows configuration of our three system runs submitted to", "labels": [], "entities": [{"text": "UKP", "start_pos": 96, "end_pos": 99, "type": "DATASET", "confidence": 0.7560283541679382}]}, {"text": " Table 2: Results on STS-2013.", "labels": [], "entities": []}]}