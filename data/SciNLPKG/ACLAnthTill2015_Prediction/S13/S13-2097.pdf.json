{"title": [{"text": "EHU-ALM: Similarity-Feature Based Approach for Student Response Analysis", "labels": [], "entities": [{"text": "EHU-ALM", "start_pos": 0, "end_pos": 7, "type": "DATASET", "confidence": 0.9185104370117188}, {"text": "Student Response Analysis", "start_pos": 47, "end_pos": 72, "type": "TASK", "confidence": 0.7619241078694662}]}], "abstractContent": [{"text": "We present a 5-way supervised system based on syntactic-semantic similarity features.", "labels": [], "entities": []}, {"text": "The model deploys: Text overlap measures, WordNet-based lexical similarities, graph-based similarities, corpus-based similarities, syntactic structure overlap and predicate-argument overlap measures.", "labels": [], "entities": [{"text": "Text overlap", "start_pos": 19, "end_pos": 31, "type": "TASK", "confidence": 0.6702990978956223}]}, {"text": "These measures are applied to question, reference answer and student answer triplets.", "labels": [], "entities": []}, {"text": "We take into account the negation in the syntactic and predicate-argument overlap measures.", "labels": [], "entities": []}, {"text": "Our system uses the domain-specific data as one dataset to build a robust system.", "labels": [], "entities": []}, {"text": "The results show that our system is above the median and mean on all the evaluation scenarios of the SemEval-2013 task #7.", "labels": [], "entities": [{"text": "SemEval-2013 task #", "start_pos": 101, "end_pos": 120, "type": "TASK", "confidence": 0.7973200480143229}]}], "introductionContent": [{"text": "In this paper we describe our participation with a feature-based supervised system to the SemEval-2013 task #7: The Joint Student Response Analysis and 8th Recognizing Textual Entailment Challenge (.", "labels": [], "entities": [{"text": "SemEval-2013 task #7", "start_pos": 90, "end_pos": 110, "type": "TASK", "confidence": 0.76118203997612}, {"text": "Joint Student Response Analysis and 8th Recognizing Textual Entailment Challenge", "start_pos": 116, "end_pos": 196, "type": "TASK", "confidence": 0.6030162125825882}]}, {"text": "The goal of our participation is to build a generic system that is robust enough across domains and scenarios.", "labels": [], "entities": []}, {"text": "A domain-specific system requires new training examples when shifting to anew domain.", "labels": [], "entities": []}, {"text": "However, domain-specific data is difficult to obtain and creating new resources is expensive.", "labels": [], "entities": []}, {"text": "We seek robustness by mixing the instances from BEETLE and SCIENTSBANK.", "labels": [], "entities": [{"text": "BEETLE", "start_pos": 48, "end_pos": 54, "type": "METRIC", "confidence": 0.9701794385910034}]}, {"text": "We show our strategy is suitable to build a generic system that performs competitively on any domain in the 5-way task.", "labels": [], "entities": []}, {"text": "The paper proceeds as follows.", "labels": [], "entities": []}, {"text": "Section 2 describes the system presenting the learning features and the runs.", "labels": [], "entities": []}, {"text": "In Section 3 we show the optimization details, followed by the results (Section 4) and a preliminary error analysis (Section 5).", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: 5-way results of the runs in F1 macro-average on BEETLE and SCIENTSBANK domains across different  scenarios. Along with the runs, the LOWEST and the BEST system in each scenario are shown. The MEAN and  MEDIAN of the dataset are also presented. Finally, the OVERALL results are showed summing up both domains. Uns- answ refers to unseen answers scenario, Uns-qst stands for unseen question, Uns-dom unseen domain and All refers  to the sum of all scenarios. The run results are presented together with the ranked position in the task.", "labels": [], "entities": [{"text": "BEETLE", "start_pos": 59, "end_pos": 65, "type": "METRIC", "confidence": 0.9943444728851318}, {"text": "LOWEST", "start_pos": 144, "end_pos": 150, "type": "METRIC", "confidence": 0.9913199543952942}, {"text": "BEST", "start_pos": 159, "end_pos": 163, "type": "METRIC", "confidence": 0.9977682828903198}, {"text": "MEAN", "start_pos": 203, "end_pos": 207, "type": "METRIC", "confidence": 0.9953386783599854}, {"text": "MEDIAN", "start_pos": 213, "end_pos": 219, "type": "METRIC", "confidence": 0.9700791239738464}, {"text": "OVERALL", "start_pos": 268, "end_pos": 275, "type": "METRIC", "confidence": 0.9657530188560486}]}, {"text": " Table 2: results of the RUN2 system on a entire test set.", "labels": [], "entities": [{"text": "RUN2", "start_pos": 25, "end_pos": 29, "type": "TASK", "confidence": 0.6067416667938232}]}]}