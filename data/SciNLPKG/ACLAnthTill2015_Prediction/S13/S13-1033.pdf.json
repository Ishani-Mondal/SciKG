{"title": [{"text": "INAOE_UPV-CORE: Extracting Word Associations from Document Corpora to estimate Semantic Textual Similarity", "labels": [], "entities": [{"text": "Extracting Word Associations from Document Corpora", "start_pos": 16, "end_pos": 66, "type": "TASK", "confidence": 0.8499317864576975}]}], "abstractContent": [{"text": "This paper presents three methods to evaluate the Semantic Textual Similarity (STS).", "labels": [], "entities": [{"text": "Semantic Textual Similarity (STS)", "start_pos": 50, "end_pos": 83, "type": "TASK", "confidence": 0.7450188299020132}]}, {"text": "The first two methods do not require labeled training data; instead, they automatically extract semantic knowledge in the form of word associations from a given reference corpus.", "labels": [], "entities": []}, {"text": "Two kinds of word associations are considered: co-occurrence statistics and the similarity of word contexts.", "labels": [], "entities": []}, {"text": "The third method was done in collaboration with groups from the Universities of Paris 13, Matanzas and Alicante.", "labels": [], "entities": []}, {"text": "It uses several word similarity measures as features in order to construct an accurate prediction model for the STS.", "labels": [], "entities": []}], "introductionContent": [{"text": "Even with the current progress of the natural language processing, evaluating the semantic text similarity is an extremely challenging task.", "labels": [], "entities": []}, {"text": "Due to the existence of multiple semantic relations among words, the measuring of text similarity is a multifactorial and highly complex task).", "labels": [], "entities": [{"text": "measuring of text similarity", "start_pos": 69, "end_pos": 97, "type": "TASK", "confidence": 0.746021181344986}]}, {"text": "Despite the difficulty of this task, it remains as one of the most attractive research topics for the NLP community.", "labels": [], "entities": []}, {"text": "This is because the evaluation of text similarity is commonly used as an internal module in many different tasks, such as, information retrieval, question answering, document summarization, etc..", "labels": [], "entities": [{"text": "evaluation of text similarity", "start_pos": 20, "end_pos": 49, "type": "TASK", "confidence": 0.635510079562664}, {"text": "information retrieval", "start_pos": 123, "end_pos": 144, "type": "TASK", "confidence": 0.8114913702011108}, {"text": "question answering", "start_pos": 146, "end_pos": 164, "type": "TASK", "confidence": 0.8833776414394379}, {"text": "document summarization", "start_pos": 166, "end_pos": 188, "type": "TASK", "confidence": 0.6966906785964966}]}, {"text": "Moreover, most of these tasks require determining the \"semantic\" similarity of texts showing stylistic differences or using polysemicwords).", "labels": [], "entities": []}, {"text": "The most popular approach to evaluate the semantic similarity of words and texts consists in using the semantic knowledge expressed in ontologies; commonly, WorldNet is used for this purpose.", "labels": [], "entities": [{"text": "WorldNet", "start_pos": 157, "end_pos": 165, "type": "DATASET", "confidence": 0.9467440843582153}]}, {"text": "Unfortunately, despite the great effort that has been the creation of WordNet, it is still far to coverall existing words and senses.Therefore, the semantic similarity methods that use this resource tend to reduce their applicability to a restricted domain and to a specific language.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 70, "end_pos": 77, "type": "DATASET", "confidence": 0.9459925889968872}]}, {"text": "We recognize the necessity of having and using manually-constructed semantic-knowledge sources in order to get precise assessments of the semantic similarity of texts, but, in turn, we also consider that it is possible to obtain good estimations of these similarities using less-expensive, and perhaps broader, information sources.", "labels": [], "entities": []}, {"text": "In particular our proposal is to automatically extract the semantic knowledge from large amounts of raw data samples i.e. document corpora without labels.", "labels": [], "entities": []}, {"text": "In this paper we describe two different strategies to compute the semantic similarity of words from a reference corpus.", "labels": [], "entities": []}, {"text": "The first strategy uses word cooccurrence statistics.", "labels": [], "entities": []}, {"text": "It determines that two words are associated (in meaning) if they tend to be used together, in the same documents or contexts.", "labels": [], "entities": []}, {"text": "The second strategy measures the similarity of words by taking into consideration second order word cooccurrences.", "labels": [], "entities": []}, {"text": "It defines two words as associated if they are used in similar contexts (i.e., if they cooccur with similar words).", "labels": [], "entities": []}, {"text": "The following section describes the implementation of these two strategies for our participation at the STS-SEM 2013 task, as well as their combination with the measures designed by the groups from the Universities of Matanzas, Alicante and Paris 13.", "labels": [], "entities": []}], "datasetContent": [{"text": "The methods proposed by our group do not require to be trained, i.e., they do not require tagged data, only a reference corpus, therefore, it was possible to evaluate them on the whole training set available this year.", "labels": [], "entities": []}, {"text": "shows their results on this set..", "labels": [], "entities": []}, {"text": "Correlation values of the proposed methods and our baseline method with human judgments.", "labels": [], "entities": []}, {"text": "Results in show that the use of the cooccurrence information improves the correlation with human judgments.", "labels": [], "entities": []}, {"text": "It also shows that the use of context information further improves the results.", "labels": [], "entities": []}, {"text": "One surprising finding was the competitive performance of our baseline method; it is considerably better than the previous year's baseline result (0.31).", "labels": [], "entities": []}, {"text": "In order to evaluate the method done in collaboration with LIPN and UMCC_DLSI, we carried out several experiments using the features provided by each group independently and in conjunction with the others.", "labels": [], "entities": [{"text": "LIPN", "start_pos": 59, "end_pos": 63, "type": "DATASET", "confidence": 0.8730137348175049}, {"text": "UMCC_DLSI", "start_pos": 68, "end_pos": 77, "type": "DATASET", "confidence": 0.8768823146820068}]}, {"text": "The experiments were performed over the whole training set by means of two-fold cross-validation.", "labels": [], "entities": []}, {"text": "The individual and global results are shown in.", "labels": [], "entities": []}, {"text": "As shown in, the result corresponding to the combination of all features clearly outperformed the results obtained by using each team\u00b4s features independently.", "labels": [], "entities": []}, {"text": "Moreover, the best combination of features, containing selected features from the three teams, obtained a correlation value very close to last year's winner result.", "labels": [], "entities": [{"text": "correlation", "start_pos": 106, "end_pos": 117, "type": "METRIC", "confidence": 0.9913233518600464}]}], "tableCaptions": [{"text": " Table 1. General description of the features used by the shared me- thod. The second column indicates the source team for each group of  features; the third column indicates the number of used features from  each group; the last two columns show the information gain rank of  each group of features over the training set.", "labels": [], "entities": []}, {"text": " Table 2. Number of different stems from each of the  considered vocabularies", "labels": [], "entities": []}, {"text": " Table 4. Correlation values from our official runs over the  four sub-datasets.", "labels": [], "entities": []}]}