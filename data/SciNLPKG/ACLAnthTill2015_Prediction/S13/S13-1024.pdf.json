{"title": [{"text": "UNIBA-CORE: Combining Strategies for Semantic Textual Similarity", "labels": [], "entities": [{"text": "Semantic Textual Similarity", "start_pos": 37, "end_pos": 64, "type": "TASK", "confidence": 0.5990698933601379}]}], "abstractContent": [{"text": "This paper describes the UNIBA participation in the Semantic Textual Similarity (STS) core task 2013.", "labels": [], "entities": [{"text": "Semantic Textual Similarity (STS) core task 2013", "start_pos": 52, "end_pos": 100, "type": "TASK", "confidence": 0.8114539682865143}]}, {"text": "We exploited three different systems for computing the similarity between two texts.", "labels": [], "entities": []}, {"text": "A system is used as baseline, which represents the best model emerged from our previous participation in STS 2012.", "labels": [], "entities": [{"text": "STS 2012", "start_pos": 105, "end_pos": 113, "type": "TASK", "confidence": 0.5418015718460083}]}, {"text": "Such system is based on a distributional model of semantics capable of taking into account also syntactic structures that glue words together.", "labels": [], "entities": []}, {"text": "In addition, we investigated the use of two different learning strategies exploiting both syntactic and semantic features.", "labels": [], "entities": []}, {"text": "The former uses ensemble learning in order to combine the best machine learning techniques trained on 2012 training and test sets.", "labels": [], "entities": []}, {"text": "The latter tries to overcome the limit of working with different datasets with varying characteristics by selecting only the more suitable dataset for the training purpose.", "labels": [], "entities": []}], "introductionContent": [{"text": "Semantic Textual Similarity is the task of computing the similarity between any two given texts.", "labels": [], "entities": [{"text": "Semantic Textual Similarity", "start_pos": 0, "end_pos": 27, "type": "TASK", "confidence": 0.7005564471085867}]}, {"text": "The task, in its core formulation, aims at capturing the different kinds of similarity that emerge from texts.", "labels": [], "entities": []}, {"text": "Machine translation, paraphrasing, synonym substitution or text entailment are some fruitful methods exploited for this purpose.", "labels": [], "entities": [{"text": "Machine translation", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.8116710484027863}, {"text": "synonym substitution", "start_pos": 35, "end_pos": 55, "type": "TASK", "confidence": 0.9418473839759827}, {"text": "text entailment", "start_pos": 59, "end_pos": 74, "type": "TASK", "confidence": 0.7609787583351135}]}, {"text": "These techniques, along with other methods for estimating the text similarity, were successfully employed via machine learning approaches during the 2012 task.", "labels": [], "entities": []}, {"text": "However, the STS 2013 core task () differs from the 2012 formulation in that it provides a test set which is similar to the training, but not drawn from the same set of data.", "labels": [], "entities": [{"text": "STS 2013 core task", "start_pos": 13, "end_pos": 31, "type": "TASK", "confidence": 0.5297790914773941}]}, {"text": "Hence, in order to generalize the machine learning models trained on a group of datasets, we investigate the use of combination strategies.", "labels": [], "entities": []}, {"text": "The objective of combination strategies, known under the name of ensemble learning, is that of reducing the bias-variance decomposition through reducing the variance error.", "labels": [], "entities": []}, {"text": "Hence, this class of methods should be more robust with respect to previously unseen data.", "labels": [], "entities": []}, {"text": "Among the several ensemble learning alternatives, we exploit the stacked generalization (STACKING) algorithm.", "labels": [], "entities": []}, {"text": "Moreover, we investigate the use of a two-steps learning algorithm (2STEPSML).", "labels": [], "entities": []}, {"text": "In this method the learning algorithm is trained using only the dataset most similar to the instance to be predicted.", "labels": [], "entities": []}, {"text": "The first step aims at predicting the dataset more similar to the given pair of texts.", "labels": [], "entities": []}, {"text": "Then the second step makes use of the previously trained algorithm to predict the similarity value.", "labels": [], "entities": [{"text": "similarity", "start_pos": 82, "end_pos": 92, "type": "METRIC", "confidence": 0.9482214450836182}]}, {"text": "The baseline for the evaluation is represented by our best system (DSM PERM) resulting from our participation in the 2012 task.", "labels": [], "entities": [{"text": "DSM PERM)", "start_pos": 67, "end_pos": 76, "type": "METRIC", "confidence": 0.5980960528055826}]}, {"text": "After introducing the general models behind our systems in Section 2, Section 3 describes the evaluation setting of our systems along with the experimental results.", "labels": [], "entities": []}, {"text": "Then, some conclusions and remarks close the paper.", "labels": [], "entities": []}], "datasetContent": [{"text": "Evaluation results on the STS-2013 data are reported in.", "labels": [], "entities": [{"text": "STS-2013 data", "start_pos": 26, "end_pos": 39, "type": "DATASET", "confidence": 0.8779199719429016}]}, {"text": "Among the three systems, UNIBA-DSM PERM obtained the best performances on both individual datasets and in the overall evaluation metric (mean), which computes the Pearson's correlation considering all datasets combined in a single one.", "labels": [], "entities": [{"text": "UNIBA-DSM", "start_pos": 25, "end_pos": 34, "type": "DATASET", "confidence": 0.7248942255973816}, {"text": "PERM", "start_pos": 35, "end_pos": 39, "type": "METRIC", "confidence": 0.4584388732910156}, {"text": "evaluation metric (mean)", "start_pos": 118, "end_pos": 142, "type": "METRIC", "confidence": 0.6865172684192657}, {"text": "Pearson's correlation", "start_pos": 163, "end_pos": 184, "type": "METRIC", "confidence": 0.9290222525596619}]}, {"text": "The best system ranked 54 over a total of 90 submissions, while UNIBA-STACKING and UNIBA-2STEPSML ranked 61 and 71 respectively.", "labels": [], "entities": [{"text": "UNIBA-STACKING", "start_pos": 64, "end_pos": 78, "type": "DATASET", "confidence": 0.9354503750801086}, {"text": "UNIBA-2STEPSML", "start_pos": 83, "end_pos": 97, "type": "DATASET", "confidence": 0.8801709413528442}]}, {"text": "These results are at odds with those reported in.", "labels": [], "entities": []}, {"text": "During the test on 2012 dataset, UNIBA-STACKING gave the best result, followed by UNIBA-2STEPSML, while UNIBA-DSM PERM gave the worst performance.", "labels": [], "entities": [{"text": "2012 dataset", "start_pos": 19, "end_pos": 31, "type": "DATASET", "confidence": 0.962954580783844}, {"text": "UNIBA-STACKING", "start_pos": 33, "end_pos": 47, "type": "DATASET", "confidence": 0.9128282070159912}, {"text": "UNIBA-2STEPSML", "start_pos": 82, "end_pos": 96, "type": "DATASET", "confidence": 0.9090471267700195}]}, {"text": "The UNIBA-STACKING system corroborated our hypothesis giving also the best results on those datasets not exploited during the training phase of the system (OnWN, SMTnews).", "labels": [], "entities": [{"text": "UNIBA-STACKING system", "start_pos": 4, "end_pos": 25, "type": "DATASET", "confidence": 0.9149221479892731}, {"text": "OnWN", "start_pos": 156, "end_pos": 160, "type": "DATASET", "confidence": 0.9653434753417969}]}, {"text": "Conversely, UNIBA-2STEPSML reported a different trend showing its weakness with respect to a high variance in the data, and performing worse than UNIBA-DSM PERM on the OnWN and SMTnews datasets.", "labels": [], "entities": [{"text": "UNIBA-2STEPSML", "start_pos": 12, "end_pos": 26, "type": "DATASET", "confidence": 0.899789035320282}, {"text": "OnWN and SMTnews datasets", "start_pos": 168, "end_pos": 193, "type": "DATASET", "confidence": 0.7857072800397873}]}, {"text": "However, the evaluation results have refuted our hypothesis, even with the use of the stacking system.", "labels": [], "entities": []}, {"text": "The independence from a training set makes the UNIBA-DSM PERM system more robust than other supervised algorithms, even though it is notable to give always the best performance on individual datasets, as highlighted by results in", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: STS-2012 test results of Pearson's correlation.", "labels": [], "entities": [{"text": "Pearson's correlation", "start_pos": 35, "end_pos": 56, "type": "METRIC", "confidence": 0.6106372773647308}]}, {"text": " Table 2: Evaluation results of Pearson's correlation for individual datasets.", "labels": [], "entities": [{"text": "Pearson's correlation", "start_pos": 32, "end_pos": 53, "type": "METRIC", "confidence": 0.6945624550183614}]}]}