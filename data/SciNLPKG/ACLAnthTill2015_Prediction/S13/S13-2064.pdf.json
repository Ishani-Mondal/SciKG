{"title": [{"text": "USNA: A Dual-Classifier Approach to Contextual Sentiment Analysis", "labels": [], "entities": [{"text": "USNA", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.800042450428009}, {"text": "Contextual Sentiment Analysis", "start_pos": 36, "end_pos": 65, "type": "TASK", "confidence": 0.7456010977427164}]}], "abstractContent": [{"text": "This paper describes a dual-classifier approach to contextual sentiment analysis at the SemEval-2013 Task 2.", "labels": [], "entities": [{"text": "contextual sentiment analysis", "start_pos": 51, "end_pos": 80, "type": "TASK", "confidence": 0.7354946335156759}, {"text": "SemEval-2013 Task 2", "start_pos": 88, "end_pos": 107, "type": "TASK", "confidence": 0.6840853293736776}]}, {"text": "Contextual analysis of polarity focuses on a word or phrase, rather than the broader task of identifying the sentiment of an entire text.", "labels": [], "entities": [{"text": "Contextual analysis of polarity", "start_pos": 0, "end_pos": 31, "type": "TASK", "confidence": 0.7723365873098373}]}, {"text": "The Task 2 definition includes target word spans that range in size from a single word to entire sentences.", "labels": [], "entities": []}, {"text": "However , the context of a single word is dependent on the word's surrounding syntax, while a phrase contains most of the polarity within itself.", "labels": [], "entities": []}, {"text": "We thus describe separate treatment with two independent classifiers, outperforming the accuracy of a single classifier.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 88, "end_pos": 96, "type": "METRIC", "confidence": 0.9988237023353577}]}, {"text": "Our system ranked 6th out of 19 teams on SMS message classification, and 8th of 23 on twitter data.", "labels": [], "entities": [{"text": "SMS message classification", "start_pos": 41, "end_pos": 67, "type": "TASK", "confidence": 0.7637455860773722}, {"text": "twitter data", "start_pos": 86, "end_pos": 98, "type": "DATASET", "confidence": 0.8117670714855194}]}, {"text": "We also show a surprising result that a very small amount of word context is needed for high-performance polarity extraction.", "labels": [], "entities": [{"text": "polarity extraction", "start_pos": 105, "end_pos": 124, "type": "TASK", "confidence": 0.7631061375141144}]}], "introductionContent": [{"text": "A variety of approaches to sentiment analysis have been proposed in the literature.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 27, "end_pos": 45, "type": "TASK", "confidence": 0.9721090495586395}]}, {"text": "Early work sought to identify the general sentiment of entire documents, but a recent shift to social media has provided a large quantity of publicly available data, and private organizations are increasingly interested in how a population \"feels\" toward its products.", "labels": [], "entities": [{"text": "identify the general sentiment of entire documents", "start_pos": 21, "end_pos": 71, "type": "TASK", "confidence": 0.81641343661717}]}, {"text": "Identifying the polarity of language toward a particular topic, however, no longer requires identifying the sentiment of an entire text, but rather the contextual sentiment surrounding a target phrase.", "labels": [], "entities": []}, {"text": "Identifying the polarity of text toward a phrase is significantly different from a sentence's overall polarity, as seen in this example from the SemEval-2013 Task 2 () training set: I had a severe nosebleed last night.", "labels": [], "entities": [{"text": "SemEval-2013 Task 2 () training set", "start_pos": 145, "end_pos": 180, "type": "DATASET", "confidence": 0.6552830189466476}]}, {"text": "I think my iPad caused it as I was browsing fora few hours on it.", "labels": [], "entities": []}, {"text": "Anyhow, its stopped, which is good.", "labels": [], "entities": []}, {"text": "An ideal sentiment classifier would classify this text as overall positive (the nosebleed stopped!), but this short snippet actually contains three types of polarity (positive, negative, and neutral).", "labels": [], "entities": [{"text": "sentiment classifier", "start_pos": 9, "end_pos": 29, "type": "TASK", "confidence": 0.821364164352417}]}, {"text": "The middle sentence about the iPad is not positive, but neutral.", "labels": [], "entities": []}, {"text": "The word 'nosebleed' has a very negative polarity in this context, and the phrase 'its stopped' is positive.", "labels": [], "entities": []}, {"text": "Someone interested in specific health concerns, such as nosebleeds, needs a contextual classifier to identify the desired polarity in this context.", "labels": [], "entities": []}, {"text": "This example also illustrates how phrases of different sizes require unique handling.", "labels": [], "entities": []}, {"text": "Single token phrases, such as 'nosebleed', are highly dependent on the surrounding context for its polarity.", "labels": [], "entities": []}, {"text": "However, the polarity of the middle iPad sentence is contained within the phrase itself.", "labels": [], "entities": []}, {"text": "The surrounding context is not as important.", "labels": [], "entities": []}, {"text": "This paper thus proposes a dual-classifier that trains two separate classifiers, one for single words, and another for phrases.", "labels": [], "entities": []}, {"text": "We empirically show that unique features apply to both, and both benefit from independent training.", "labels": [], "entities": []}, {"text": "In fact, we show a surprising result that a very small window size is needed for the context of single word phrases.", "labels": [], "entities": []}, {"text": "Our system performs well on the SemEval task, placing 8th of 23 systems on twitter text.", "labels": [], "entities": [{"text": "SemEval task", "start_pos": 32, "end_pos": 44, "type": "TASK", "confidence": 0.9080815315246582}]}, {"text": "It also shows strong generalization to SMS text messages, placing 6th of 19.", "labels": [], "entities": []}], "datasetContent": [{"text": "This paper uses three polarity classes: positive, negative, and neutral.", "labels": [], "entities": []}, {"text": "We developed all algorithms on the 'Task A' corpora provided by.", "labels": [], "entities": []}, {"text": "Both training and development sets were provided, and an unseen test set was ultimately used to evaluate the final systems.", "labels": [], "entities": []}, {"text": "Initial model design and feature tuning was conducted on the SemEval-2013 Task 2 training set for training, and its dev set for evaluation.", "labels": [], "entities": [{"text": "SemEval-2013 Task 2 training set", "start_pos": 61, "end_pos": 93, "type": "DATASET", "confidence": 0.8537231922149658}]}, {"text": "We split the data into two parts: tweets with single word targets, and tweets with target phrases.", "labels": [], "entities": []}, {"text": "We trained two MaxEnt classifiers using the Stanford JavaNLP toolkit 2 . Each datum in the test set is labeled using the appropriate classifier based on the target phrase's length.", "labels": [], "entities": [{"text": "Stanford JavaNLP toolkit 2", "start_pos": 44, "end_pos": 70, "type": "DATASET", "confidence": 0.9020952731370926}]}, {"text": "The first experiments are ablation over the features described in Section 4, separately improving the single token and phrasal classifiers.", "labels": [], "entities": []}, {"text": "Results are reported in using simple accuracy on the development set.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 37, "end_pos": 45, "type": "METRIC", "confidence": 0.9946145415306091}]}, {"text": "We initially do not split off punctuation, and use only unigram features for phrases.", "labels": [], "entities": []}, {"text": "The window size is initally infinite (i.e., the entire text is used for n-grams).", "labels": [], "entities": []}, {"text": "Bigrams and trigrams hurt performance and are not shown.", "labels": [], "entities": [{"text": "trigrams", "start_pos": 12, "end_pos": 20, "type": "METRIC", "confidence": 0.9781532287597656}]}, {"text": "Reducing the window size to a single token (ignore the entire tweet) increased performance by 1.2%, and stripping punctuation off tokens by another 1.9%.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Feature ablation in order. Single token features  begin with unigrams only, holding phrasal features con- stant at unigrams only. The phrasal table picks up where  the single token table finishes. Each row uses all features  added in previous rows.", "labels": [], "entities": []}, {"text": " Table 3: Performance on Twitter and SMS Data.", "labels": [], "entities": [{"text": "SMS Data", "start_pos": 37, "end_pos": 45, "type": "DATASET", "confidence": 0.6756334602832794}]}]}