{"title": [{"text": "FBM: Combining lexicon-based ML and heuristics for Social Media Polarities", "labels": [], "entities": [{"text": "FBM", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.8092010021209717}, {"text": "Combining lexicon-based ML", "start_pos": 5, "end_pos": 31, "type": "TASK", "confidence": 0.6089356541633606}, {"text": "Social Media Polarities", "start_pos": 51, "end_pos": 74, "type": "TASK", "confidence": 0.6558171510696411}]}], "abstractContent": [{"text": "This paper describes the system implemented by Fundaci\u00f3 Barcelona Media (FBM) for classifying the polarity of opinion expressions in tweets and SMSs, and which is supported by a UIMA pipeline for rich linguistic and sentiment annotations.", "labels": [], "entities": [{"text": "Fundaci\u00f3 Barcelona Media (FBM)", "start_pos": 47, "end_pos": 77, "type": "DATASET", "confidence": 0.8266838788986206}, {"text": "classifying the polarity of opinion expressions in tweets and SMSs", "start_pos": 82, "end_pos": 148, "type": "TASK", "confidence": 0.828076434135437}]}, {"text": "FBM participated in the SEMEVAL 2013 Task 2 on polarity classification.", "labels": [], "entities": [{"text": "FBM", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.9686265587806702}, {"text": "SEMEVAL 2013 Task 2", "start_pos": 24, "end_pos": 43, "type": "TASK", "confidence": 0.6827803552150726}, {"text": "polarity classification", "start_pos": 47, "end_pos": 70, "type": "TASK", "confidence": 0.8220663666725159}]}, {"text": "It ranked 5th in Task A (constrained track) using an ensemble system combining ML algorithms with dictionary-based heuris-tics, and 7th (Task B, constrained) using an SVM classifier with features derived from the linguistic annotations and some heuristics.", "labels": [], "entities": []}], "introductionContent": [{"text": "We introduce the FBM system for classifying the polarity of short user-generated text (tweets and SMSs), which participated in the two subtasks of SEMEVAL 2013 Task 2 on Sentiment Analysis in Twitter.", "labels": [], "entities": [{"text": "FBM", "start_pos": 17, "end_pos": 20, "type": "METRIC", "confidence": 0.585031270980835}, {"text": "classifying the polarity of short user-generated text (tweets and SMSs)", "start_pos": 32, "end_pos": 103, "type": "TASK", "confidence": 0.801352987686793}, {"text": "SEMEVAL 2013 Task 2", "start_pos": 147, "end_pos": 166, "type": "TASK", "confidence": 0.7629396319389343}, {"text": "Sentiment Analysis", "start_pos": 170, "end_pos": 188, "type": "TASK", "confidence": 0.8081918060779572}]}, {"text": "These are: Task A. Contextual Polarity Disambiguation, and Task B. Message Polarity Classification.", "labels": [], "entities": [{"text": "Contextual Polarity Disambiguation", "start_pos": 19, "end_pos": 53, "type": "TASK", "confidence": 0.7557524840037028}, {"text": "Message Polarity Classification", "start_pos": 67, "end_pos": 98, "type": "TASK", "confidence": 0.806818962097168}]}, {"text": "The former aimed at classifying the polarity of already identified opinion expressions (or cues), whereas the latter consisted in classifying the polarity of the whole text ().", "labels": [], "entities": []}, {"text": "The literature agrees on two main approaches for classifying opinion expressions: using supervised learning methods and applying dictionary/rulebased knowledge (see) for an overview).", "labels": [], "entities": [{"text": "classifying opinion expressions", "start_pos": 49, "end_pos": 80, "type": "TASK", "confidence": 0.8483758568763733}]}, {"text": "Each of them on its own has been used in workable systems, and a principled combination of both of them can yield good results on noisy data, since generally one (dictionaries/rules) offers good precision while the other (ML) is able to discover unseen examples and thus enhances recall.", "labels": [], "entities": [{"text": "precision", "start_pos": 195, "end_pos": 204, "type": "METRIC", "confidence": 0.9923684000968933}, {"text": "recall", "start_pos": 280, "end_pos": 286, "type": "METRIC", "confidence": 0.9963033199310303}]}, {"text": "FBM combined both approaches in order to benefit from their respective strengths and compensating as much as possible their weaknesses.", "labels": [], "entities": [{"text": "FBM", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.9300276041030884}]}, {"text": "For Task A we used linguistic (lexical and syntactic) annotations to implement both types of approaches.", "labels": [], "entities": []}, {"text": "On the one hand, we built machine learning classifiers based on Support Vector Machines (SVMs) and Conditional Random Fields (CRFs).", "labels": [], "entities": []}, {"text": "On the other, we implemented a basic classification system mainly based on polarity dictionaries and negation information, as well as simple decision tree-like heuristics extracted from the training data.", "labels": [], "entities": []}, {"text": "For task B we trained an SVM classifier using some of the annotations from Task A. The paper first presents the process of data compilation and preprocessing (section 2), and then describes the systems for Tasks A (section 3) and B (section 4).", "labels": [], "entities": [{"text": "data compilation", "start_pos": 123, "end_pos": 139, "type": "TASK", "confidence": 0.7200005352497101}]}, {"text": "Results and conclusions are discussed in the last section.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Cue segment polarity statistics in training data  for an aggregate polarity value of -1.", "labels": [], "entities": [{"text": "Cue segment polarity", "start_pos": 10, "end_pos": 30, "type": "TASK", "confidence": 0.7425714135169983}]}, {"text": " Table 2: Twitter Task A results for different methods", "labels": [], "entities": [{"text": "Twitter Task A", "start_pos": 10, "end_pos": 24, "type": "METRIC", "confidence": 0.6840242346127828}]}, {"text": " Table 4: Results for different ensemble strategies", "labels": [], "entities": []}, {"text": " Table 7: Task A confusion matrix", "labels": [], "entities": []}]}