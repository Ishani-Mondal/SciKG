{"title": [{"text": "AVAYA: Sentiment Analysis on Twitter with Self-Training and Polarity Lexicon Expansion", "labels": [], "entities": [{"text": "Sentiment Analysis", "start_pos": 7, "end_pos": 25, "type": "TASK", "confidence": 0.9544837772846222}]}], "abstractContent": [{"text": "This paper describes the systems submitted by Avaya Labs (AVAYA) to SemEval-2013 Task 2-Sentiment Analysis in Twitter.", "labels": [], "entities": [{"text": "SemEval-2013 Task 2-Sentiment Analysis in Twitter", "start_pos": 68, "end_pos": 117, "type": "TASK", "confidence": 0.752862294514974}]}, {"text": "For the constrained conditions of both the message polarity classification and contextual polarity disambiguation subtasks, our approach centers on training high-dimensional, linear clas-sifiers with a combination of lexical and syntactic features.", "labels": [], "entities": [{"text": "message polarity classification", "start_pos": 43, "end_pos": 74, "type": "TASK", "confidence": 0.7976054350535074}]}, {"text": "The constrained message polarity model is then used to tag nearly half a million unlabeled tweets.", "labels": [], "entities": []}, {"text": "These automatically labeled data are used for two purposes: 1) to discover prior polarities of words and 2) to provide additional training examples for self-training.", "labels": [], "entities": []}, {"text": "Our systems performed competitively , placing in the top five for all subtasks and data conditions.", "labels": [], "entities": []}, {"text": "More importantly, these results show that expanding the polarity lexicon and augmenting the training data with un-labeled tweets can yield improvements in precision and recall in classifying the polarity of non-neutral messages and contexts.", "labels": [], "entities": [{"text": "precision", "start_pos": 155, "end_pos": 164, "type": "METRIC", "confidence": 0.9993565678596497}, {"text": "recall", "start_pos": 169, "end_pos": 175, "type": "METRIC", "confidence": 0.9989985823631287}]}], "introductionContent": [{"text": "The past decade has witnessed a massive expansion in communication from long-form delivery such as e-mail to short-form mechanisms such as microblogging and short messaging service (SMS) text messages.", "labels": [], "entities": []}, {"text": "Simultaneously businesses, media outlets, and investors are increasingly relying on these messages as sources of real-time information and are increasingly turning to sentiment analysis to discover product trends, identify customer preferences, and categorize users.", "labels": [], "entities": []}, {"text": "While a variety of corpora exist for developing and evaluating sentiment classifiers for long-form texts such as product reviews, there are few such resources for evaluating sentiment algorithms on microblogs and SMS texts.", "labels": [], "entities": []}, {"text": "The organizers of SemEval-2013 task 2, have begun to address this resource deficiency by coordinating a shared evaluation task for Twitter sentiment analysis.", "labels": [], "entities": [{"text": "SemEval-2013 task 2", "start_pos": 18, "end_pos": 37, "type": "TASK", "confidence": 0.8393677870432535}, {"text": "Twitter sentiment analysis", "start_pos": 131, "end_pos": 157, "type": "TASK", "confidence": 0.6491831143697103}]}, {"text": "In doing so they have assembled corpora in support of the following two subtasks:", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section we report results for the series of Sentiment Analysis in Twitter tasks at SemEval 2013.", "labels": [], "entities": [{"text": "Sentiment Analysis in Twitter tasks at SemEval 2013", "start_pos": 52, "end_pos": 103, "type": "TASK", "confidence": 0.7973315417766571}]}, {"text": "Please refer to refer to for the exact details about the corpora, evaluation conditions, and methodology.", "labels": [], "entities": []}, {"text": "We submitted polarity output for the Message Polarity Classification (task B) and the Contextual Polarity Disambiguation (task A).", "labels": [], "entities": [{"text": "Message Polarity Classification", "start_pos": 37, "end_pos": 68, "type": "TASK", "confidence": 0.6540864904721578}, {"text": "Contextual Polarity Disambiguation", "start_pos": 86, "end_pos": 120, "type": "TASK", "confidence": 0.6522977352142334}]}, {"text": "For each task we submitted system output from our constrained and unconstrained models.", "labels": [], "entities": []}, {"text": "As stated above, the constrained models made use of only the training data released for the task, whereas the unconstrained models trained on additional tweets.", "labels": [], "entities": []}, {"text": "Each subtask had two test sets one comprised of tweets and the other comprised of SMS messages.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Message Polarity Classification (Task B) Results", "labels": [], "entities": [{"text": "Message Polarity Classification", "start_pos": 10, "end_pos": 41, "type": "TASK", "confidence": 0.7678159475326538}]}, {"text": " Table 3: Contextual Polarity Disambiguation (Task A) Results", "labels": [], "entities": [{"text": "Contextual Polarity Disambiguation", "start_pos": 10, "end_pos": 44, "type": "TASK", "confidence": 0.7990567684173584}]}]}