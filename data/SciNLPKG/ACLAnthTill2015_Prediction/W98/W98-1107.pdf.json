{"title": [{"text": "Semantic Lexicon Acquisition for Learning Natural Language Interfaces", "labels": [], "entities": []}], "abstractContent": [{"text": "This paper describes a system, WOLFIE (WOrd Learning From Interpreted Examples), that acquires a semantic lexicon from a corpus of sentences paired with representations of their meaning.", "labels": [], "entities": []}, {"text": "The lexicon learned consists of words paired with meaning representations.", "labels": [], "entities": []}, {"text": "WOLFIE is part of an integrated system that learns to parse novel sentences into semantic representations, such as logical database queries.", "labels": [], "entities": [{"text": "WOLFIE", "start_pos": 0, "end_pos": 6, "type": "DATASET", "confidence": 0.8520511388778687}]}, {"text": "Experimental results are presented demonstrating WOLFIE'S ability to learn useful lexicons fora database interface in four different natural languages.", "labels": [], "entities": []}, {"text": "The lexicons learned by WOLFIE are compared to those acquired by a comparable system developed by Siskind (1996).", "labels": [], "entities": [{"text": "WOLFIE", "start_pos": 24, "end_pos": 30, "type": "DATASET", "confidence": 0.8226505517959595}]}], "introductionContent": [], "datasetContent": [{"text": "This section describes our experimental results on a database query application.", "labels": [], "entities": []}, {"text": "The corpus contains 250 questions about U.S. geography paired with logical representations.", "labels": [], "entities": []}, {"text": "This domain was chosen due to the availability of an existing hand-built natural language interface, Geobase, to a simple geography database containing about 800 facts.", "labels": [], "entities": []}, {"text": "This interface was supplied with Turbo Prolog 2.0 (, and was designed specifically for this domain.", "labels": [], "entities": [{"text": "Turbo Prolog 2.0", "start_pos": 33, "end_pos": 49, "type": "DATASET", "confidence": 0.8370080391565958}]}, {"text": "The questions were collected from uninformed undergraduates and mapped into their logical form by an exp, r.", "labels": [], "entities": []}, {"text": "Examples from the corpus were given in the previous sections.", "labels": [], "entities": []}, {"text": "To broaden the test, we had the same 250 sentences translated into Spanish, Turkish~ and Japanese.", "labels": [], "entities": []}, {"text": "The Japanese translations are in word-segmented Roman orthography.", "labels": [], "entities": []}, {"text": "Translated questions were paired with the appropriate logical queries from the English corpus.", "labels": [], "entities": []}, {"text": "To evaluate the learned lexicons, we measured their utility as background knowledge for CHILL.", "labels": [], "entities": [{"text": "CHILL", "start_pos": 88, "end_pos": 93, "type": "TASK", "confidence": 0.5821487903594971}]}, {"text": "This is performed by choosing a random set of 25 test examples and then creating lexicons and parsers using increasingly larger subsets of the remaining 225 examples.", "labels": [], "entities": []}, {"text": "The test examples are parsed using the learned parser, the resulting queries submitted to the database, the answers compared to those generated by the correct representation, and the percentage of correct answers recorded.", "labels": [], "entities": []}, {"text": "By making a comparison to the \"gold standard\" of retrieving a correct answer to the original query, we avoid measures of partial accuracy which do not give a picture of the real usefulness of the parser.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 129, "end_pos": 137, "type": "METRIC", "confidence": 0.9717532992362976}]}, {"text": "To improve the statistical significance of the results, we repeated the above steps for ten different random splits of the data into training and test sets.", "labels": [], "entities": []}, {"text": "For all significance tests we used a two-tailed, paired t-test and a significance level of p < 0.05.", "labels": [], "entities": [{"text": "significance level", "start_pos": 69, "end_pos": 87, "type": "METRIC", "confidence": 0.9758994877338409}]}, {"text": "We compared our system to that developed by.", "labels": [], "entities": []}, {"text": "Siskind's system is an on-line (incremental) learner, while ours is batch.", "labels": [], "entities": []}, {"text": "To make a closer comparison between the two, we ran his in a \"simulated\" batch mode, by repeatedly presenting the corpus 500 times, analogous to running 500 epochs to train a neural network.", "labels": [], "entities": []}, {"text": "We also made comparisons to the parsers learned by CHILL when using a hand-coded lexicon as background knowledge.", "labels": [], "entities": []}, {"text": "This lexicon was available for this domain because when CHILL was originally developed, WOLFIE had not yet been developed.", "labels": [], "entities": []}, {"text": "In this application, there are many terms, such as state and city names, whose meanings are easily extracted from the database.", "labels": [], "entities": []}, {"text": "Therefore, all tests below were run with such names given to the learner as an initial lexicon, although this is not required for learning in general.", "labels": [], "entities": []}], "tableCaptions": []}