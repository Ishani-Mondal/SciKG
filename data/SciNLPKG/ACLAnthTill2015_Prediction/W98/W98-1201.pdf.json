{"title": [{"text": "Daelemans 1 Abstraction Harmful in Language Learning Walter Daelemans (1998) Abstraction is Harmful in Language Learning", "labels": [], "entities": [{"text": "Abstraction", "start_pos": 12, "end_pos": 23, "type": "METRIC", "confidence": 0.943071186542511}, {"text": "Abstraction", "start_pos": 77, "end_pos": 88, "type": "METRIC", "confidence": 0.9477101564407349}]}], "abstractContent": [{"text": "The usual approach to learning language processing tasks such as tagging, parsing, grapheme-to-phoneme conversion, pp-attachrnent, etc., is to extract regularities from training data in the form of decision trees, rules, probabilities or other abstractions.", "labels": [], "entities": [{"text": "grapheme-to-phoneme conversion", "start_pos": 83, "end_pos": 113, "type": "TASK", "confidence": 0.7068820297718048}]}, {"text": "These representations of regularities are then used to solve new cases of the task.", "labels": [], "entities": []}, {"text": "The individual training examples on which the abstractions were based are discarded (forgotten).", "labels": [], "entities": []}, {"text": "While this approach seems to work well for other application areas of Machine Learning, I will show that there is evidence that it is not the best way to learn language processing tasks.", "labels": [], "entities": [{"text": "Machine Learning", "start_pos": 70, "end_pos": 86, "type": "TASK", "confidence": 0.8399859368801117}]}, {"text": "I will briefly review empirical work in our groups in Antwerp and Tilburg on lazy language learning.", "labels": [], "entities": [{"text": "lazy language learning", "start_pos": 77, "end_pos": 99, "type": "TASK", "confidence": 0.6839457551638285}]}, {"text": "In this approach (also called, instance-based, case-based, memory-based, and example-based learning), generalization happens at processing time by means of extrapolation from the most similar items in memory to the new item being processed.", "labels": [], "entities": []}, {"text": "Lazy Learning with a simple similarity metric based on information entropy (IB I-IG,) consistently outperforms abstracting (greedy) learning techniques such as C5.0 or backprop learning on abroad selection of natural language processing tasks ranging from phonology to semantics.", "labels": [], "entities": []}, {"text": "Our intuitive explanation for this result is that lazy learning techniques keep all training items, whereas greedy approaches lose useful information by forgetting low-frequency or exceptional instances of the task, not covered by the extracted rules or models.", "labels": [], "entities": []}, {"text": "Apart from the empirical work in Tilburg and Antwerp, a number of recent studies on statistical natural language processing (e.g. also suggest that, contrary to common wisdom, forgetting specific training items, even when they represent extremely low-frequency events, is harmful to generalization accuracy.", "labels": [], "entities": [{"text": "statistical natural language processing", "start_pos": 84, "end_pos": 123, "type": "TASK", "confidence": 0.6258311420679092}, {"text": "generalization", "start_pos": 283, "end_pos": 297, "type": "TASK", "confidence": 0.9825472235679626}, {"text": "accuracy", "start_pos": 298, "end_pos": 306, "type": "METRIC", "confidence": 0.7881681323051453}]}, {"text": "After reviewing this empirical work briefly, I will report on new results (work in progress in collaboration with van den Bosch and Zavrel), systematically comparing greedy and lazy learning techniques on a number of benehrnark natural language processing tasks: tagging, grapheme-to-phoneme conversion, and pp-attachment.", "labels": [], "entities": [{"text": "grapheme-to-phoneme conversion", "start_pos": 272, "end_pos": 302, "type": "TASK", "confidence": 0.6889054328203201}]}, {"text": "The results show that forgetting individual training items, however \"improbable' they maybe, is indeed harmful.", "labels": [], "entities": []}, {"text": "Furthermore, they show that combining lazy learning with training set editing techniques (based on typicality and other regularity criteria) also leads to worse generalization results.", "labels": [], "entities": []}, {"text": "I will conclude that forgetting, either by abstracting from the training data or by editing exceptional training items in lazy learning is ha_rm~ to generalization accuracy, and will attempt to provide an explanation for these unexpected results.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 164, "end_pos": 172, "type": "METRIC", "confidence": 0.9424997568130493}]}], "introductionContent": [], "datasetContent": [], "tableCaptions": []}