{"title": [], "abstractContent": [{"text": "Best-first probabilistic chart parsing attempts to parse efficiently by working on edges that are judged ~'best\" by some probabilistic figure of merit (FOM).", "labels": [], "entities": [{"text": "probabilistic chart parsing", "start_pos": 11, "end_pos": 38, "type": "TASK", "confidence": 0.6050393680731455}]}, {"text": "Recent work has used proba-bilistic context-free grammars (PCFGs) to assign probabilities to constituents, and to use these probabilities as the starting point for the FOM.", "labels": [], "entities": [{"text": "FOM", "start_pos": 168, "end_pos": 171, "type": "TASK", "confidence": 0.6933322548866272}]}, {"text": "This paper extends this approach to using a probabilistic FOM to judge edges (incom-plete constituents), thereby giving a much finer-grained control over parsing effort.", "labels": [], "entities": [{"text": "FOM", "start_pos": 58, "end_pos": 61, "type": "METRIC", "confidence": 0.8551366329193115}, {"text": "parsing", "start_pos": 154, "end_pos": 161, "type": "TASK", "confidence": 0.9662776589393616}]}, {"text": "We show how this can be accomplished in a particularly simple way using the common idea of binarizing the PCFG.", "labels": [], "entities": [{"text": "PCFG", "start_pos": 106, "end_pos": 110, "type": "DATASET", "confidence": 0.9623046517372131}]}, {"text": "The results obtained are about a factor of twenty improvement over the best prior results m that is, our parser achieves equivalent results using one twentieth the number of edges.", "labels": [], "entities": []}, {"text": "Furthermore we show that this improvement is obtained with parsing precision and recall levels superior to those achieved by exhaustive parsing .", "labels": [], "entities": [{"text": "parsing", "start_pos": 59, "end_pos": 66, "type": "TASK", "confidence": 0.9675310254096985}, {"text": "precision", "start_pos": 67, "end_pos": 76, "type": "METRIC", "confidence": 0.9475620985031128}, {"text": "recall", "start_pos": 81, "end_pos": 87, "type": "METRIC", "confidence": 0.999671220779419}]}], "introductionContent": [{"text": "Finding one (or all) parses fora sentence according to a context-free grammar requires search.", "labels": [], "entities": []}, {"text": "Fortunately, there are well known O(n 3) algorithms for parsing, where n is the length of the sentence.", "labels": [], "entities": [{"text": "parsing", "start_pos": 56, "end_pos": 63, "type": "TASK", "confidence": 0.9608240723609924}]}, {"text": "Unfortunately, for large grammars (such as the PCFG induced from the Penn II WSJ corpus, which contains around 1.6.", "labels": [], "entities": [{"text": "PCFG induced from the Penn II WSJ corpus", "start_pos": 47, "end_pos": 87, "type": "DATASET", "confidence": 0.8446566238999367}]}, {"text": "i04 rules) and Iongish sentences (say, 40 words and punctuation), even O(n 3) looks pretty bleak.", "labels": [], "entities": [{"text": "Iongish sentences", "start_pos": 15, "end_pos": 32, "type": "TASK", "confidence": 0.8036255836486816}, {"text": "O", "start_pos": 71, "end_pos": 72, "type": "METRIC", "confidence": 0.8433904051780701}]}, {"text": "One well-known O(n 3) parsing method is chart parsing.", "labels": [], "entities": [{"text": "O(n 3) parsing", "start_pos": 15, "end_pos": 29, "type": "TASK", "confidence": 0.5211289326349894}, {"text": "chart parsing", "start_pos": 40, "end_pos": 53, "type": "TASK", "confidence": 0.7923458218574524}]}, {"text": "In this approach one maintains an agenda of items remaining to be \" This material is based on work supported in past by NSF grants IRI-9319516 and SBR-9720368. and by ONR grant N0014-96.-1-0549.", "labels": [], "entities": [{"text": "NSF grants IRI-9319516", "start_pos": 120, "end_pos": 142, "type": "DATASET", "confidence": 0.6546225647131602}, {"text": "ONR grant N0014-96.-1-0549", "start_pos": 167, "end_pos": 193, "type": "DATASET", "confidence": 0.874966275691986}]}, {"text": "processed, one of which is processed during each iteration.", "labels": [], "entities": []}, {"text": "As each item is pulled off the agenda, it is added to the chart (unless it is already there, in which case it can be discarded) and used to extend and create additional items.", "labels": [], "entities": []}, {"text": "In \"exhaustive\" chart parsing one removes items from the agenda in some relatively simple way (last-in, first-out is common), and continues to do so until nothing remains.", "labels": [], "entities": [{"text": "exhaustive\" chart parsing", "start_pos": 4, "end_pos": 29, "type": "TASK", "confidence": 0.6233506351709366}]}, {"text": "A commonly discussed alternative is to remove the constituents from the agenda according to a figure of merit (FOM).", "labels": [], "entities": [{"text": "FOM", "start_pos": 111, "end_pos": 114, "type": "METRIC", "confidence": 0.9069952964782715}]}, {"text": "The idea is that the FOM selects \"good\" items to be processed, leaving the ~'bad\" ones--the ones that are not, in fact, part of the correct parse----sitting on the agenda.", "labels": [], "entities": []}, {"text": "When one has a completed parse, or perhaps several possible parses, one simply stops parsing, leaving items remaining on the agenda.", "labels": [], "entities": []}, {"text": "The time that would have been spent processing these remaining items is time saved, and thus time earned.", "labels": [], "entities": []}, {"text": "In our work we have found that exhaustively parsing maximum-40-word sentences from the Penn II treebank requires an average of about 1.2 million edges per sentence.", "labels": [], "entities": [{"text": "Penn II treebank", "start_pos": 87, "end_pos": 103, "type": "DATASET", "confidence": 0.9557886322339376}]}, {"text": "Numbers like this suggest that any approach that offers the possibility of reducing the workload is well worth pursuing, a fact that has been noted by several researchers.", "labels": [], "entities": []}, {"text": "Early on, suggested the use of the chart agenda for this purpose.", "labels": [], "entities": []}, {"text": "More recently, the statistical approach to language processing and the use of probabilistic context-free grammars (PCFGs) has suggested using the PCFG probabilities to create a FOM. and introduced best-first PCFG parsing, the approach taken here.", "labels": [], "entities": [{"text": "language processing", "start_pos": 43, "end_pos": 62, "type": "TASK", "confidence": 0.721540629863739}, {"text": "PCFG parsing", "start_pos": 208, "end_pos": 220, "type": "TASK", "confidence": 0.614916205406189}]}, {"text": "Subsequent work has suggested different FOMs built from PCFG probabilities.", "labels": [], "entities": [{"text": "FOMs", "start_pos": 40, "end_pos": 44, "type": "TASK", "confidence": 0.8746076822280884}]}, {"text": "Probably the most extensive comparison of possible metrics for best-first PCFG parsing is that of Caraballo and Charniak (henceforth C&C) (Forthcoming).", "labels": [], "entities": [{"text": "PCFG parsing", "start_pos": 74, "end_pos": 86, "type": "TASK", "confidence": 0.8372474610805511}]}, {"text": "They consider a large number of FOMs, and view them as approximations of some \"ideal\" (but only computable after the fact) FOM.", "labels": [], "entities": [{"text": "FOMs", "start_pos": 32, "end_pos": 36, "type": "DATASET", "confidence": 0.5192887187004089}, {"text": "FOM", "start_pos": 123, "end_pos": 126, "type": "DATASET", "confidence": 0.8542473912239075}]}, {"text": "Of these they recommend one as the best of the lot.", "labels": [], "entities": []}, {"text": "In this paper we basically adopt both their framework and their recommended FOM.", "labels": [], "entities": [{"text": "FOM", "start_pos": 76, "end_pos": 79, "type": "METRIC", "confidence": 0.9335389137268066}]}, {"text": "The next section describes their work in more detail, Besides C&C the work that is most directly comparable to ours is that of and.", "labels": [], "entities": []}, {"text": "Goodman uses an FOM that is similar to that of C&C but one that should, in general, be somewhat more accurate.", "labels": [], "entities": [{"text": "FOM", "start_pos": 16, "end_pos": 19, "type": "METRIC", "confidence": 0.6838254332542419}]}, {"text": "However, both Goodman's and Ratnaparki's work assumes that one is doing abeam search of some sort, rather than a best-first search, and their FOM are unfortunately tied to their frameworks and thus cannot be adopted here.", "labels": [], "entities": [{"text": "FOM", "start_pos": 142, "end_pos": 145, "type": "METRIC", "confidence": 0.8964015245437622}]}, {"text": "We briefly compare our results to theirs in Section 5.", "labels": [], "entities": []}, {"text": "As noted, our paper takes off from that of C&C and uses the same FOM.", "labels": [], "entities": [{"text": "C&C", "start_pos": 43, "end_pos": 46, "type": "DATASET", "confidence": 0.7959555983543396}, {"text": "FOM", "start_pos": 65, "end_pos": 68, "type": "METRIC", "confidence": 0.9943747520446777}]}, {"text": "The major difference is simply that our parser uses the FOM to rank edges (including incomplete edges), rather than simply completed constituents, as was done by C&C.", "labels": [], "entities": [{"text": "FOM", "start_pos": 56, "end_pos": 59, "type": "METRIC", "confidence": 0.9600092768669128}]}, {"text": "What is interesting about our approach is that such a seemingly simple change can produce rather dramatic results.", "labels": [], "entities": []}, {"text": "Rather than the thousands of edges required by C&C, the parser presented here requires hundreds, or even, if one is willing to pay a small price inaccuracy, tens.", "labels": [], "entities": []}], "datasetContent": [{"text": "For our experiment, we used a tree-bank grammar induced from sections 2-21 of the Penn Wall Street Journal text (, with section 22 reserved for testing.", "labels": [], "entities": [{"text": "Penn Wall Street Journal text", "start_pos": 82, "end_pos": 111, "type": "DATASET", "confidence": 0.9686033725738525}]}, {"text": "All sentences of length greater than 40 were ignored for testing purposes as done in both.", "labels": [], "entities": []}, {"text": "We applied the binarization technique described above to the grammar.", "labels": [], "entities": []}, {"text": "We chose to measure the amount of work done by the parser in terms of the average number of edges popped off the agenda before finding a parse.", "labels": [], "entities": []}, {"text": "This method has the advantage of being platform independent, as well as providing a measure of \"perfection\".", "labels": [], "entities": [{"text": "perfection", "start_pos": 96, "end_pos": 106, "type": "METRIC", "confidence": 0.9935076236724854}]}, {"text": "Here, perfection is the minimum number of edges we would need to pop off the agenda in order to create the correct parse.", "labels": [], "entities": [{"text": "perfection", "start_pos": 6, "end_pos": 16, "type": "METRIC", "confidence": 0.9807066917419434}]}, {"text": "For the binarized grammar, where each popped edge is a completed constituent, this number is simply the number of terminals plus nonterminals in the sentence---on average, 47.5.", "labels": [], "entities": []}, {"text": "Our algorithm includes some measures to reduce the number of items on the agenda, and thus (presumably) the number of popped edges.", "labels": [], "entities": []}, {"text": "Each time we add a constituent to the chart, we combine it with the constituents on either side of it, potentially creating several new edges.", "labels": [], "entities": []}, {"text": "For each of these new edges, we check to see if a matching constituent (i.e. a constituent with the same head, start, and end points) already exists in either the agenda or the chart.", "labels": [], "entities": []}, {"text": "If there is no match, we simply add the new edge to the agenda.", "labels": [], "entities": []}, {"text": "If there is a match but the old parse", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Edges vs. Sentences Parsed", "labels": [], "entities": [{"text": "Parsed", "start_pos": 30, "end_pos": 36, "type": "TASK", "confidence": 0.6482886672019958}]}]}