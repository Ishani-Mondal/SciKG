{"title": [{"text": "I mm mm m The Present Use of Statistics in the Evaluation of NLP Parsers", "labels": [], "entities": []}], "abstractContent": [{"text": "We are concerned that the quality of results produced by an NLP parser bears little, if any, relation to the percentage-results claimed by the various NLP parser-systems presently available for use.", "labels": [], "entities": []}, {"text": "To illustrate this problem, we examine one readily available NLP tagging and parsing system, the ENGCG parser; and one tagger, the Brin tagger.", "labels": [], "entities": [{"text": "NLP tagging and parsing", "start_pos": 61, "end_pos": 84, "type": "TASK", "confidence": 0.624036967754364}]}, {"text": "We note responses to both artificially generated and naturally occurring text.", "labels": [], "entities": []}, {"text": "The percentage assessments are methodologically flawed, and should betaken with a grain of salt; instead, assessment of the performance of an NLP parser should be effected by a user, and solely from a consideration of the resulting parses of exactly the input which an NLP user decides to contribute for such an assessment.", "labels": [], "entities": []}, {"text": "Careful attention to input of whatever corpus the user decides on, is presently the only suitable qualifying test of parsing ability.", "labels": [], "entities": [{"text": "parsing", "start_pos": 117, "end_pos": 124, "type": "TASK", "confidence": 0.9802523851394653}]}, {"text": "The parsers available are none of them perfectible yet, despite apparent yields now quoted at 99%+.", "labels": [], "entities": []}, {"text": "We consider the impact of Zipf's argument of 'least effort' on percentage assessment; and we open a discussion on estimating the relative complexities of corpora.", "labels": [], "entities": []}], "introductionContent": [{"text": "Statistics are frequently bandied around in NLP, and would seem to be the obvious way to compare competing systems and methodologies.", "labels": [], "entities": []}, {"text": "For example: As a rule, data-driven systems rely on statistical generalisations about short sequences of words or tags....hey tend to reach a 95-97% accuracy [and 12 parsers are referred to.]", "labels": [], "entities": [{"text": "accuracy", "start_pos": 149, "end_pos": 157, "type": "METRIC", "confidence": 0.9888429641723633}]}, {"text": "Interestingly, no significant improvement beyond the 97% \"barrier\" by means of purely data-driven systems has been reported so far...[Then there is a report of three hybrids -systems that employ linguistic rules for solving some ambiguities -with various additions; and these hybrids] seem capable of exceeding the 97% barrier ....", "labels": [], "entities": []}, {"text": "Next, anew system..uses only linguistic distributional rules.", "labels": [], "entities": []}, {"text": "Tested against a 38,000-word corpus of previously unseen text, the tagger reaches a better accuracy than previous systems (over 99%).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 91, "end_pos": 99, "type": "METRIC", "confidence": 0.9992691874504089}]}, {"text": "We are concerned about the misleading nature of such published statistics, although researchers working on NLP systems are of course well aware that the figures must be interpreted carefully.", "labels": [], "entities": []}, {"text": "To be able to show our cause for concern we must look at the statistics of a well known parser, and also at its actions.", "labels": [], "entities": []}, {"text": "Unfortunately there are relatively few systems which are freely available for consultation or examination, and for this reason we are forced to pick on some of the few systems that are.", "labels": [], "entities": []}, {"text": "The criticisms we make here are not directed against the parsers we use as examples, but against the way in which our field is treating its statistics.", "labels": [], "entities": []}, {"text": "Our main example is the ENGCG parser, in one specific form which\" has been available for several years now, and frorc h which many influential variants have been spawned,~including the one being used to tag the Bank of English (.", "labels": [], "entities": [{"text": "tag the Bank of English", "start_pos": 203, "end_pos": 226, "type": "DATASET", "confidence": 0.6538554131984711}]}, {"text": "Perhaps unfortunately for it, the ENGCG parser is very conveniently consulted on the Net, and statistics on it have been published.", "labels": [], "entities": []}, {"text": "Another good reason for our examination of this parser-group is the comment made by them, above, that \"the tagger reaches a better accuracy than previous systems (over 99%).\"", "labels": [], "entities": [{"text": "accuracy", "start_pos": 131, "end_pos": 139, "type": "METRIC", "confidence": 0.9972161054611206}]}, {"text": "And the fact is that it does seem to represent the best approach currently.,,,.", "labels": [], "entities": []}, {"text": "In this paper, we will use the name \"the ENGCG parser\" as referring to a specific combination of these components in the manner that they are reported in; in particular we are using the version which augments the underlying tagger with a finite-state parser, with heuristics switched on.", "labels": [], "entities": []}, {"text": "In considering and assessing the statistics on this parser, and also the parser itself, we record that we should not like it thought we are only trying to criticise that program.", "labels": [], "entities": []}, {"text": "So let us repeat that in our view the ENGCG parser appears to beat least as effective as any other parser presently generally consultable or available, and that it may well be the most effective member of that class today.", "labels": [], "entities": []}, {"text": "Indeed, we see that parser as defining the standards fora corpus-based parser.", "labels": [], "entities": []}, {"text": "But, as will be noted, we nonetheless think the ENGCG parser parses poorly, when it is compared with human parsers -a conclusion we have reached partly because of matters discussed in \u00a73.", "labels": [], "entities": [{"text": "ENGCG parser parses", "start_pos": 48, "end_pos": 67, "type": "TASK", "confidence": 0.6005960404872894}]}], "datasetContent": [{"text": "\"<*i>\" \"i\" <*> PRON PERS NOM SG1 SUB3 ~SUBJ \"<water>\" \"water\" N NOM SG ~NPHR \"<the>\" \"the\" DET CENTRAL ART SG/PL ~DN> \"<plants>\" \"plant\" N NOM PL @NPHR ,,<$.>\" The symbol nphr designates a \"stray NP\".", "labels": [], "entities": [{"text": "DET CENTRAL ART", "start_pos": 91, "end_pos": 106, "type": "TASK", "confidence": 0.4750887254873912}]}, {"text": "The possibility that watercould be a verb is not entertained by this parser; and a single, completely incorrect parse is the only result: noun noun determiner noun.", "labels": [], "entities": []}, {"text": "Note too: ENGCG signals an improper parse: but fails to signal the failure 1.", "labels": [], "entities": [{"text": "ENGCG", "start_pos": 10, "end_pos": 15, "type": "METRIC", "confidence": 0.6995379328727722}]}, {"text": "We tested the ENGCG parser further: with other words of a similar nature, to show that this error was not a feature of just one word, water.", "labels": [], "entities": []}, {"text": "We created a list of sentences to test starting-roles specifically: (1) The man who sails boats watches fish.", "labels": [], "entities": []}, {"text": "(2) The man who sails boats watches water.", "labels": [], "entities": []}, {"text": "l In this connection, the separate matter of permitting an \"I don't know\" response is an important feature in the correct approach to NLP but is not relevant in this paper.", "labels": [], "entities": []}, {"text": "(13) He stopped hunting rabbits.", "labels": [], "entities": []}, {"text": "He sights along the rifle.", "labels": [], "entities": []}, {"text": "The italicised word in each sentence is the testword, the word of interest.", "labels": [], "entities": []}, {"text": "The ENGCG parser is relying to some degree on limiting the starting roles of words to only the more likely ones, then it starts at that point to parsebut that restriction still allow multiplication of the parses that ENGCG offers -out to twelve, for the case of sentence (1).", "labels": [], "entities": [{"text": "ENGCG", "start_pos": 217, "end_pos": 222, "type": "DATASET", "confidence": 0.9286826848983765}]}, {"text": "This parser then attempts only to give the more likely reading(s), but it does not necessarily offer a legal parse.", "labels": [], "entities": []}, {"text": "Because of startingrole restrictions, this parsing program is not always producing an acceptable parse, which is unsatisfactory.", "labels": [], "entities": [{"text": "parsing", "start_pos": 43, "end_pos": 50, "type": "TASK", "confidence": 0.973332405090332}]}, {"text": "Indeed, we view the two clear parsing failures regarding sentences and, in the conditions we have established, as further evidence of a somewhat weak parsing action, one which fails to use all of the syntactic constraints in English, properly.", "labels": [], "entities": []}, {"text": "We ran these sentences in the more recent ENGCG-2 Tagger(Voutilainen 1995) and received parses that were improved, but the substantial point remained, although to a lesser extent: that tagger had not received the instruction to accept the verb to water as a fully equipped verb, and so a variation in sentence (3) -to (4)Let him water the plants.", "labels": [], "entities": [{"text": "ENGCG-2 Tagger(Voutilainen 1995)", "start_pos": 42, "end_pos": 74, "type": "DATASET", "confidence": 0.9095153013865153}]}, {"text": "returned water as noun only.", "labels": [], "entities": []}, {"text": "Nor did that tagger report the second parse in either of sentences (1) or (2).", "labels": [], "entities": []}, {"text": "Because the above sentences are artificially generated, the ENGCG parser has been working in a domain beyond its design; but this, the full domain of all written English, is our interest.", "labels": [], "entities": []}, {"text": "So, the aim of the ENGCG parser is not that of unequivocally parsing English, in NLP.", "labels": [], "entities": [{"text": "ENGCG parser", "start_pos": 19, "end_pos": 31, "type": "TASK", "confidence": 0.619031548500061}]}, {"text": "The limited set of roles provided by the lexicon probably arises from omission, but we note-two consequences arising from reduction of the set. of possible tags through omission of valid, but rare roles.", "labels": [], "entities": []}, {"text": "The first is obvious: if there is less disambiguation to perform, the tagger and parser will be faster.", "labels": [], "entities": []}, {"text": "The second is perhaps less obvious: if rarer roles are omitted from a parser then it is incapable of correctly resolving them.", "labels": [], "entities": []}, {"text": "It is possible to manipulate speed and error rate by judicious omission of roles.", "labels": [], "entities": [{"text": "speed", "start_pos": 29, "end_pos": 34, "type": "METRIC", "confidence": 0.9731714129447937}]}, {"text": "We learn from the above demonstration that when a word of a sentence submitted to the ENGCG parser needs a lower-probability word-role, it may not find it; in fact it returned a strange \"four nouns make a sentence\" type of parse.", "labels": [], "entities": []}, {"text": "It was not constrained by a grammar rule of English to say that water cannot be a verb -but by an arbitrary re-", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: A comparison of three NLP programs", "labels": [], "entities": []}, {"text": " Table 2: Count of different verb-forms for various extracts", "labels": [], "entities": [{"text": "Count", "start_pos": 10, "end_pos": 15, "type": "METRIC", "confidence": 0.9490839838981628}]}]}