{"title": [{"text": "The Use of WordNet in Information Retrieval", "labels": [], "entities": [{"text": "Information Retrieval", "start_pos": 22, "end_pos": 43, "type": "TASK", "confidence": 0.7124775499105453}]}], "abstractContent": [{"text": "WordNet has been used in information retrieval research by many researchers, but failed to improve the performance of their retrieval system.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 0, "end_pos": 7, "type": "DATASET", "confidence": 0.9451807737350464}, {"text": "information retrieval", "start_pos": 25, "end_pos": 46, "type": "TASK", "confidence": 0.8069123327732086}]}, {"text": "Thereby in this paper we investigate why the use of WordNet has not been successful.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 52, "end_pos": 59, "type": "DATASET", "confidence": 0.9692854285240173}]}, {"text": "Based on this analysis we propose a method of making WordNet more useful in information retrieval applications.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 53, "end_pos": 60, "type": "DATASET", "confidence": 0.9279075264930725}, {"text": "information retrieval", "start_pos": 76, "end_pos": 97, "type": "TASK", "confidence": 0.777169942855835}]}, {"text": "Experiments using several standard information retrieval test collections show that our method results in a significant improvement of information retrieval performance.", "labels": [], "entities": [{"text": "information retrieval", "start_pos": 135, "end_pos": 156, "type": "TASK", "confidence": 0.7622394263744354}]}], "introductionContent": [{"text": "Development of WordNet began in 1985 at Princeton University.", "labels": [], "entities": []}, {"text": "A team lead by Prof. George Miller aimed to create a source of lexical knowledge whose organization would reflect some of the recent findings of psycholinguistic research into the human lexicon.", "labels": [], "entities": []}, {"text": "WordNet has been used in numerous natural language processing, such as part of speech tagging, word sense disambiguation, text categorization (, information extraction, and soon with considerable success.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 0, "end_pos": 7, "type": "DATASET", "confidence": 0.9222365021705627}, {"text": "speech tagging", "start_pos": 79, "end_pos": 93, "type": "TASK", "confidence": 0.718299388885498}, {"text": "word sense disambiguation", "start_pos": 95, "end_pos": 120, "type": "TASK", "confidence": 0.6849726041158041}, {"text": "information extraction", "start_pos": 145, "end_pos": 167, "type": "TASK", "confidence": 0.842690497636795}]}, {"text": "However the usefulness of WordNet in information retrieval applications has been debatable.", "labels": [], "entities": [{"text": "information retrieval", "start_pos": 37, "end_pos": 58, "type": "TASK", "confidence": 0.7709754705429077}]}, {"text": "Information retrieval is concerned with locating documents relevant to a user's information needs from a collection of documents.", "labels": [], "entities": [{"text": "Information retrieval", "start_pos": 0, "end_pos": 21, "type": "TASK", "confidence": 0.829954981803894}]}, {"text": "The user describes his/her information needs with a query which consists of a number of words.", "labels": [], "entities": []}, {"text": "The information retrieval system compares the query with documents in the collection and returns the documents that are likely to satisfy the user's information requirements.", "labels": [], "entities": []}, {"text": "A fundamental weakness of current information retrieval methods is that the vocabulary that searchers use is often not the same as the one by which the information has been indexed.", "labels": [], "entities": [{"text": "information retrieval", "start_pos": 34, "end_pos": 55, "type": "TASK", "confidence": 0.7321912050247192}]}, {"text": "Query expansion is one method to solve this problem.", "labels": [], "entities": [{"text": "Query expansion", "start_pos": 0, "end_pos": 15, "type": "TASK", "confidence": 0.8524028956890106}]}, {"text": "The query is expanded using terms which have similar meaning or bear some relation to those in the query, increasing the chances of matching words in relevant documents.", "labels": [], "entities": []}, {"text": "Expanded terms are generally taken from a thesaurus.", "labels": [], "entities": []}, {"text": "Obviously, given a query, the information retrieval system must present all useful articles to the user.", "labels": [], "entities": []}, {"text": "This objective is measured by recall, i.e. the proportion of relevant articles retrieved by the system.", "labels": [], "entities": [{"text": "recall", "start_pos": 30, "end_pos": 36, "type": "METRIC", "confidence": 0.9994896650314331}]}, {"text": "Conversely, the information retrieval system must not present any useless article to the user.", "labels": [], "entities": []}, {"text": "This criteria is measured by precision, i.e. the proportion of retrieved articles that are relevant.", "labels": [], "entities": [{"text": "precision", "start_pos": 29, "end_pos": 38, "type": "METRIC", "confidence": 0.9995638728141785}]}, {"text": "Voorhees used WordNet as a tool for query expansion.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 14, "end_pos": 21, "type": "DATASET", "confidence": 0.9546946883201599}, {"text": "query expansion", "start_pos": 36, "end_pos": 51, "type": "TASK", "confidence": 0.824889600276947}]}, {"text": "She conducted experiments using the TREC collection) in which all terms in the queries were expanded using a combination of synonyms, hypernyms, and hyponyms.", "labels": [], "entities": [{"text": "TREC collection", "start_pos": 36, "end_pos": 51, "type": "DATASET", "confidence": 0.72682686150074}]}, {"text": "She set the weights of the words contained in the original query to 1, and used a combination of 0.1, 0.3, 0.5, 1, and 2 for the expansion terms.", "labels": [], "entities": []}, {"text": "She then used the SMART Information Retrieval System Engine to retrieve the documents.", "labels": [], "entities": [{"text": "SMART Information Retrieval", "start_pos": 18, "end_pos": 45, "type": "TASK", "confidence": 0.7630863785743713}]}, {"text": "Through this method, Voorhees only succeeded in improving the performance on short queries and a tittle with no significant improvement for long queries.", "labels": [], "entities": []}, {"text": "She further tried to use WordNet as a tool for word sense disambiguation and applied it to text retrieval, but the performance of retrieval was degraded.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 25, "end_pos": 32, "type": "DATASET", "confidence": 0.927941620349884}, {"text": "word sense disambiguation", "start_pos": 47, "end_pos": 72, "type": "TASK", "confidence": 0.7426261603832245}, {"text": "text retrieval", "start_pos": 91, "end_pos": 105, "type": "TASK", "confidence": 0.7663614153862}]}, {"text": "Stairmand) used WordNet to compute lexical cohesion according to the method suggested by, and applied this to information retrieval.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 16, "end_pos": 23, "type": "DATASET", "confidence": 0.9447609186172485}, {"text": "information retrieval", "start_pos": 110, "end_pos": 131, "type": "TASK", "confidence": 0.8156310319900513}]}, {"text": "He concluded that his method could not be applied to a fully-functional information retrieval system.", "labels": [], "entities": []}], "datasetContent": [{"text": "In order to evaluate the effectiveness of the proposed method in the previous section we conducted experiments using the WSJ, CACM, IN-SPEC, CISI, Cranfield, NPL, and LISA test collections.", "labels": [], "entities": [{"text": "WSJ", "start_pos": 121, "end_pos": 124, "type": "DATASET", "confidence": 0.9479098916053772}, {"text": "CISI", "start_pos": 141, "end_pos": 145, "type": "DATASET", "confidence": 0.8728342056274414}, {"text": "NPL", "start_pos": 158, "end_pos": 161, "type": "DATASET", "confidence": 0.6298755407333374}, {"text": "LISA test collections", "start_pos": 167, "end_pos": 188, "type": "DATASET", "confidence": 0.8902415633201599}]}, {"text": "The WSJ collection comprises part of the TREC collection.", "labels": [], "entities": [{"text": "WSJ collection", "start_pos": 4, "end_pos": 18, "type": "DATASET", "confidence": 0.9736389219760895}, {"text": "TREC collection", "start_pos": 41, "end_pos": 56, "type": "DATASET", "confidence": 0.9355162382125854}]}, {"text": "As a baseline we used SMART without expansion.", "labels": [], "entities": [{"text": "SMART", "start_pos": 22, "end_pos": 27, "type": "TASK", "confidence": 0.8498959541320801}]}, {"text": "SMART is an information retrieval engine based on the vector space model in which term weights are calculated based on term frequency, inverse document frequency and document length normalization.", "labels": [], "entities": [{"text": "information retrieval", "start_pos": 12, "end_pos": 33, "type": "TASK", "confidence": 0.7981857359409332}, {"text": "inverse document frequency", "start_pos": 135, "end_pos": 161, "type": "METRIC", "confidence": 0.7452027102311453}]}, {"text": "The results are shown in.", "labels": [], "entities": []}, {"text": "This table shows the average of 11 point uninterpolated recall-precision for each of baseline, expansion using only WordNet, expansion using only predicate-argument-based thesaurus, expansion using only cooccurrence-based thesaurus, and expansion using all of them.", "labels": [], "entities": [{"text": "recall-precision", "start_pos": 56, "end_pos": 72, "type": "METRIC", "confidence": 0.9752090573310852}, {"text": "WordNet", "start_pos": 116, "end_pos": 123, "type": "DATASET", "confidence": 0.9741346836090088}]}, {"text": "For each method we give the percentage of improvement over the baseline.", "labels": [], "entities": []}, {"text": "It is shown that the performance using the combined thesauri for query expansion is better than both SMART and using just one type of thesaurus.", "labels": [], "entities": [{"text": "query expansion", "start_pos": 65, "end_pos": 80, "type": "TASK", "confidence": 0.7667529284954071}]}], "tableCaptions": [{"text": " Table 1: Term Expansion Experiment", "labels": [], "entities": [{"text": "Term Expansion", "start_pos": 10, "end_pos": 24, "type": "TASK", "confidence": 0.7166681885719299}]}, {"text": " Table 2. This  table shows the average of 11 point uninterpo- lated recall-precision for each of baseline, expan- sion using only WordNet, expansion using only  predicate-argument-based thesaurus, expansion  using only cooccurrence-based thesaurus, and  expansion using all of them. For each method  we give the percentage of improvement over the  baseline. It is shown that the performance us- ing the combined thesauri for query expansion  is better than both SMART and using just one  type of thesaurus.", "labels": [], "entities": [{"text": "recall-precision", "start_pos": 69, "end_pos": 85, "type": "METRIC", "confidence": 0.8369668126106262}, {"text": "WordNet", "start_pos": 131, "end_pos": 138, "type": "DATASET", "confidence": 0.9611769318580627}]}]}