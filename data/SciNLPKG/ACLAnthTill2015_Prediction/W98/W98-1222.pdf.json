{"title": [{"text": "Extracting Phoneme Pronunciation Information from Corpora", "labels": [], "entities": [{"text": "Extracting Phoneme Pronunciation", "start_pos": 0, "end_pos": 32, "type": "TASK", "confidence": 0.9203598896662394}]}], "abstractContent": [{"text": "We present a procedure that determines a set of phonemes possibly intended by a speaker from a recognized or uttered phone.", "labels": [], "entities": []}, {"text": "This information will be used to allow a speech rec-ognizer to take pronunciation into account or to consider input from a noisy source during lexical access.", "labels": [], "entities": []}, {"text": "We investigate the hypothesis that different pronunciations of a phone occur within groups of sounds physically produced the same way, and use the Minimum Message Length principle to consider the effect of a phoneme's context on its pronunciation.", "labels": [], "entities": [{"text": "Minimum Message Length", "start_pos": 147, "end_pos": 169, "type": "METRIC", "confidence": 0.5018698573112488}]}], "introductionContent": [{"text": "When trying to match spoken words to dictionary entries during speech recognition, it is useful to be able to generate alternative versions of the spoken sequences of phones to account for the manner in which different speakers pronounce a phone.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 63, "end_pos": 81, "type": "TASK", "confidence": 0.7057250887155533}]}, {"text": "If we know the probabilities that the component sounds in a sequence of phones are pronounced like other sounds, then likely alternative pronunciations of that sequence of phones can be generated to match against a lexicon of known words.", "labels": [], "entities": []}, {"text": "Furthermore, if we also have some idea of how the context within which a phone was uttered affects its pronunciation, we have extra information which can be used to produce more realistic alternative pronunciations.", "labels": [], "entities": []}, {"text": "This paper considers the task of automatically extracting statistical information about how various sound sections of words (phonemes) are pronounced by speakers (as phones) by matching intended phonemes and uttered phones from a transcribed speech corpus.", "labels": [], "entities": [{"text": "extracting statistical information about how various sound sections of words (phonemes) are pronounced by speakers (as phones) by matching intended phonemes and uttered phones from a transcribed speech", "start_pos": 47, "end_pos": 248, "type": "Description", "confidence": 0.665565388277173}]}, {"text": "The same approach could be used to gather statistics about how phones recogaized (or mis-recognized) by a speech recognizer match the phonemes intended by a speaker.", "labels": [], "entities": []}, {"text": "This information extraction process is part of the training phase for the lexical access component of a speech recognition system, where the pronunciation probabilities are generated from a training corpus.", "labels": [], "entities": [{"text": "information extraction", "start_pos": 5, "end_pos": 27, "type": "TASK", "confidence": 0.7620341181755066}, {"text": "speech recognition", "start_pos": 104, "end_pos": 122, "type": "TASK", "confidence": 0.7178265452384949}]}, {"text": "The study was done on the TIMIT corpus) --a collection of American-English read sentences with correct time-aligned acousticphonetic and orthographic (word-aligned) transcriptions.", "labels": [], "entities": [{"text": "TIMIT corpus", "start_pos": 26, "end_pos": 38, "type": "DATASET", "confidence": 0.8679294288158417}]}, {"text": "1 The corpus contains 3696 sentences spoken by 462 speakers from 8 different dialect divisions across the United States.", "labels": [], "entities": []}, {"text": "Previous work by and used Classification and Regression Trees (CART) on a large number of different features of the corpus (such as genderi dialect and speaking rate) to obtain pronunciation information of intended phonemes.", "labels": [], "entities": []}, {"text": "Our system obtain~ similar results using positional information and context, and using exact matches from uttered phones to intended phonemes to guide other matches.", "labels": [], "entities": []}, {"text": "Work by on pronunciation used a couple of set sentences for multiple speakers, but did not cover a wide range of words (and thus different phone contexts).", "labels": [], "entities": []}, {"text": "Our study considers the pronunciation patterns of a wide range of different speakers using a large collection of words.", "labels": [], "entities": []}, {"text": "A tree-based system by uses an information theoretic approach for deciding alternative pronunciations based on the classification of a large context feature vector.", "labels": [], "entities": []}, {"text": "However, when building their decision tree, they do not evaluate the quality of the resulting tree, i.e., they keep testing attributes until a boundary situation is reached.", "labels": [], "entities": []}, {"text": "In contrast, our system initially uses the relative positioning of uttered phones and intended phonemes to determine the phonemes possibly intended by a speaker when uttering a particular phone.", "labels": [], "entities": []}, {"text": "The context of a phone is considered only as 1Transcriptions were made by a combination of hand transcriptions using multiple parametric representations of sentences as a guide, and automatic alignment.", "labels": [], "entities": []}, {"text": "The use of different representations is claimed as a good way of overcoming dialect biases during transcription.", "labels": [], "entities": []}, {"text": "an extra source of information to qualify these predictions.", "labels": [], "entities": []}, {"text": "Further, the method we apply for building decision trees evaluates whether context is meaningful in terms of its predictive power.", "labels": [], "entities": []}, {"text": "Riley (1991) implements a similar system using a different method for tree induction, but estimates the probability of an uttered phoneme given a phoneme context and a partial phone context, whereas we are inferring an intended phoneme from an uttered phone context.", "labels": [], "entities": [{"text": "tree induction", "start_pos": 70, "end_pos": 84, "type": "TASK", "confidence": 0.7579354345798492}]}], "datasetContent": [{"text": "As indicated in, in the majority of cases the uttered phone and the intended phoneme are the same.", "labels": [], "entities": []}, {"text": "summarizes the decision trees for situations where uttered phones are different from intended phonemes.", "labels": [], "entities": []}, {"text": "This summary shows the effect of contextual phonetic information on the intended phoneme for each possible uttered phone (one line per phone).", "labels": [], "entities": []}, {"text": "For example, for the uttered phone d, the intended phoneme wast when the next sound was\" neither a consonant nor a vowel, i.e., a word boundary, a sentence boundary or missing; this occurred in 12 of the samples.", "labels": [], "entities": []}, {"text": "Also, the intended phoneme was missing (i.e., d was uttered when no phoneme was intended) when the next sound was an obstruent; this happened in 2 of the samples.", "labels": [], "entities": []}, {"text": "In 220 samples, the uttered phone was iy with intended phoneme ax when iy was the last sound in a word, and the previous sound was a fricative.", "labels": [], "entities": []}, {"text": "Some uttered phones found in are missing from because either there were not enough samples to create a tree (the stops b, g and p, the nasal m, and the pause), or more often because the trees produced had no discriminatory power.", "labels": [], "entities": []}, {"text": "This occurred when each leaf node in a decision tree had an evenly spread mixture of intended phonemes, or when the same intended phoneme appeared throughout the tree.", "labels": [], "entities": []}, {"text": "The decision trees were evaluated using test contexts from 1344 sentences (out of 5040 sentences) spoken by 26% of the speakers.", "labels": [], "entities": []}, {"text": "No speaker was in the test and training sets.", "labels": [], "entities": []}, {"text": "Each phone and its context was classified into a leaf node using the attributes in the context.", "labels": [], "entities": []}, {"text": "A phoneme prediction was considered correct when the intended phoneme was the same as the most common phoneme in the leaf node (determined during training).", "labels": [], "entities": [{"text": "phoneme prediction", "start_pos": 2, "end_pos": 20, "type": "TASK", "confidence": 0.7332863509654999}]}, {"text": "75% of the different test samples were predicted correctly.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 3: Summary of most significant values in the decision tree for each uttered phone.", "labels": [], "entities": [{"text": "Summary", "start_pos": 10, "end_pos": 17, "type": "METRIC", "confidence": 0.8490931987762451}]}]}