{"title": [{"text": "A Comparison of Criteria for Maximum Entropy / Minimum Divergence Feature Selection", "labels": [], "entities": []}], "abstractContent": [{"text": "In this paper we study the gain, a naturally-arising statistic from the theory of MEMD modeling [2], as a figure of merit for selecting features for an MEMD language model.", "labels": [], "entities": [{"text": "MEMD modeling", "start_pos": 82, "end_pos": 95, "type": "TASK", "confidence": 0.8776580989360809}, {"text": "MEMD language model", "start_pos": 152, "end_pos": 171, "type": "TASK", "confidence": 0.8217376470565796}]}, {"text": "We compare the gain with two popular alternatives-empirical activation and mutual information-and argue that the gain is the preferred statistic, on the grounds that it directly measures a fea-ture's contribution to improving upon the base modeL", "labels": [], "entities": []}], "introductionContent": [{"text": "Maximum entropy / minimum divergence modeling is a powerful technique for building statistical models of linguistic phenomena.", "labels": [], "entities": [{"text": "Maximum entropy / minimum divergence modeling", "start_pos": 0, "end_pos": 45, "type": "TASK", "confidence": 0.6074863523244858}]}, {"text": "It has been applied to problems as diverse as machine translation, parsing, word morphology and language modeling.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 46, "end_pos": 65, "type": "TASK", "confidence": 0.8265270590782166}, {"text": "parsing", "start_pos": 67, "end_pos": 74, "type": "TASK", "confidence": 0.9221935272216797}, {"text": "word morphology", "start_pos": 76, "end_pos": 91, "type": "TASK", "confidence": 0.7563363611698151}, {"text": "language modeling", "start_pos": 96, "end_pos": 113, "type": "TASK", "confidence": 0.7394684255123138}]}, {"text": "The heart of the method is to ~ljoose a collection of informative features, each encodi'llg some linguistically significant event, and then to incorporate these features into a family of conditional models.", "labels": [], "entities": []}, {"text": "A fundamental issue in applying this technique is the criterion used to select features.", "labels": [], "entities": []}, {"text": "The work described in, for instance, incorporates every feature which either appears with above-threshold count in a training corpus, or which exhibits high mutual information.", "labels": [], "entities": []}, {"text": "In and, the authors select features based on a mutual information statistic.", "labels": [], "entities": []}, {"text": "As we argue below, both these methods have drawbacks.", "labels": [], "entities": []}, {"text": "In this paper, we examine a statistic for selecting MEMD model features, called the gain.", "labels": [], "entities": []}, {"text": "The gain was introduced in, and studied in greater detail in and.", "labels": [], "entities": []}, {"text": "We present intuition, theory and experimental results for this statistic, as a criterion for selecting features for an MEMD language model.", "labels": [], "entities": [{"text": "MEMD language", "start_pos": 119, "end_pos": 132, "type": "TASK", "confidence": 0.7733041048049927}]}, {"text": "We believe our work marks the first time it has been used in MEMD language modeling, and the first side-by-side comparison with other selection criteria.", "labels": [], "entities": [{"text": "MEMD language modeling", "start_pos": 61, "end_pos": 83, "type": "TASK", "confidence": 0.9277276595433553}]}, {"text": "Though our experimental results concern language models exclusively, we note that the gain can be used to select features for any MEMD model on a discrete space.", "labels": [], "entities": []}, {"text": "The language model we present is based on dependency grammars.", "labels": [], "entities": []}, {"text": "It is similar to, but extends upon, the work reported in.", "labels": [], "entities": []}, {"text": "Two important differences between that work and ours are that ours is a true", "labels": [], "entities": []}], "datasetContent": [{"text": "Here we describe the work in this paper.", "labels": [], "entities": []}, {"text": "computation that underlies is a schematic of the the complete computation, which divides into three phases: (1) prepare the corpus and train a parser and base model, (2) identify and rank features, and (3) select features and train an MEMD model.", "labels": [], "entities": []}, {"text": "Our experiments, which we report later, concerned phases and only.", "labels": [], "entities": []}, {"text": "We include a discussion of phase ( 1) for completeness, and to place our experiments in context.", "labels": [], "entities": []}, {"text": "In the first phase we trained a parser and base model, and parsed the corpus text.", "labels": [], "entities": []}, {"text": "By parsed we mean that for each sentence S of the corpus text T, we have its linkage f( ( S) at our disposal.", "labels": [], "entities": []}, {"text": "The parser we trained and then used was a modified version of the decision-tree parser described in.", "labels": [], "entities": []}, {"text": "Our parser training corpus consisted of 990,145 words of Tree bank Release II data, and our base model corpus consisted of 44,761,334 words of Wall Street Journal data, both prepared by the Linguistic Data Consortium.", "labels": [], "entities": [{"text": "Tree bank Release II data", "start_pos": 57, "end_pos": 82, "type": "DATASET", "confidence": 0.8926697134971618}, {"text": "Wall Street Journal data", "start_pos": 143, "end_pos": 167, "type": "DATASET", "confidence": 0.9467240869998932}]}, {"text": "This parser constructs a conventional parse tree.", "labels": [], "entities": []}, {"text": "Since we needed linkages, we used the method of headword propagation to create them from the parser output; we now explain this method.", "labels": [], "entities": [{"text": "headword propagation", "start_pos": 48, "end_pos": 68, "type": "TASK", "confidence": 0.7665698528289795}]}, {"text": "To each parse tree we apply a small collection of headword propagation rules, which operate leaves-to-root.", "labels": [], "entities": [{"text": "headword propagation", "start_pos": 50, "end_pos": 70, "type": "TASK", "confidence": 0.8161068856716156}]}, {"text": "The result is a tree labeled with a headword at each node, where each headword is selected from the headwords of a node's chilclren.", "labels": [], "entities": []}, {"text": "(At the leaves, each word is its own headword.)", "labels": [], "entities": []}, {"text": "The desired linkage is then obtained by drawing an arc from the headword of each child node to the headword ofits parent, excluding self-loops.", "labels": [], "entities": []}, {"text": "A conventional parse tree for the sentence of above, labeled with propagated headwords, appears in.", "labels": [], "entities": []}, {"text": "For the base model q 1 we chose to use a linearly interpolated trigram language model, built from the same regularized WSJ corpus as the dependency grammar model itself.", "labels": [], "entities": [{"text": "WSJ corpus", "start_pos": 119, "end_pos": 129, "type": "DATASET", "confidence": 0.9440382421016693}]}, {"text": "In the second processing phase we identified and ranked features.", "labels": [], "entities": []}, {"text": "The details of this phase, and in particular the figure of merit used for ranking 1 are the subject of Section Selection of Features.", "labels": [], "entities": []}, {"text": "Here we explain its place in the overall scheme.", "labels": [], "entities": []}, {"text": "By inspecting the parsed corpus C, we identify a set F of trigger and link candidate features.", "labels": [], "entities": []}, {"text": "These are then ranked according to the chosen statistic.", "labels": [], "entities": []}, {"text": "In this paper we advocate the use of the gain as the rank statistic.", "labels": [], "entities": []}, {"text": "The gain depends upon both the corpus and the base model, and for this reason these are shown as inputs to the box rank features in.", "labels": [], "entities": []}, {"text": "The output is the same set of candidate features, ranked according to the figure of merit.", "labels": [], "entities": []}, {"text": "It happens that the gain computation also yields initial estimates of the MEMD exponents; abbreviated exps in the figure.", "labels": [], "entities": []}, {"text": "In the final phase of processing, we inspected the ranked list of features and selected those to incorporate into the model.", "labels": [], "entities": []}, {"text": "We then used the selected features, their initial exponent estimates, the corpus 1 and the base model to train the MEMD model.", "labels": [], "entities": []}, {"text": "Different choices of features yield different models; Section Tests and Results below gives details and performance of the various models we built.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Selected Trigger and Link Features. These features are ranked according to gain, reported here  in thousandths of a bit (mbits). The third column, e\"'*, represents the approximate boost (or deflation) of  probability given to the second word of each pair, when the feature is active. The rightmost column lists  the feature's empirical activation. Note that trigger features are active far more often than link features.  The units used for column active differ by 10 4 words.", "labels": [], "entities": []}, {"text": " Table 2: Model Features, Training Characteristics, Perplexities, Gains. Models are named by the following  convention. The first part of the name gives the number of features; the letter k denotes a factor of 1 ,000.  Thus 10k is a model built of the 10,000 highest-ranking features of the candidate set F. The notation 2trig  or 2link means that we used only trigger or link features respectively. Thus 1 Ok.2link is built of the 10,000", "labels": [], "entities": []}]}