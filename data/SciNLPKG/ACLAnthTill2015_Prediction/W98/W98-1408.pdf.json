{"title": [{"text": "INTRODUCING MAXIMAL VARIATION IN TEXT PLANNING FOR SMALL DOMAINS", "labels": [], "entities": [{"text": "INTRODUCING MAXIMAL VARIATION", "start_pos": 0, "end_pos": 29, "type": "METRIC", "confidence": 0.6136338710784912}, {"text": "TEXT PLANNING FOR SMALL DOMAINS", "start_pos": 33, "end_pos": 64, "type": "METRIC", "confidence": 0.768843138217926}]}], "abstractContent": [{"text": "\u2022 This work describes a method for text planning that is suitable to small domains like train table information.", "labels": [], "entities": [{"text": "text planning", "start_pos": 35, "end_pos": 48, "type": "TASK", "confidence": 0.8764995038509369}]}, {"text": "Our aim is to introduce maximal variation in the packaging of \u2022 information and in the linear order of its presentation.", "labels": [], "entities": []}, {"text": "To this end, we regard text planning as a goal-driven process that dynamically constructs a text plan.", "labels": [], "entities": [{"text": "text planning", "start_pos": 23, "end_pos": 36, "type": "TASK", "confidence": 0.8630193769931793}]}, {"text": "The goal is a state where all information in the input is shared with the user; the means to achieve this goal are utterances.", "labels": [], "entities": []}, {"text": "The application of utterances is limited by constraints that refer to the user's current state of knowledge.", "labels": [], "entities": []}, {"text": "This approach to text planning can be conven!ently implemented as a Functional Unification Grammar.", "labels": [], "entities": [{"text": "text planning", "start_pos": 17, "end_pos": 30, "type": "TASK", "confidence": 0.8470930755138397}]}, {"text": "In addition, we show how optional or inferable information can be accountedfor, how focus can be distributed, and how the generation of anaphoric expressions can be constrained by looking at the form and content of a previous utterance.", "labels": [], "entities": []}], "introductionContent": [{"text": "This work on text planning is part of a project that is concerned with investigating Dutch prosody by implementing a concept-to-speech system.", "labels": [], "entities": [{"text": "text planning", "start_pos": 13, "end_pos": 26, "type": "TASK", "confidence": 0.8518899977207184}, {"text": "Dutch prosody", "start_pos": 85, "end_pos": 98, "type": "TASK", "confidence": 0.6222725361585617}]}, {"text": "The project focuses on the prosodic module, which predicts the pitch accents and the prosodic boundaries of an utterance on the basis \u2022of its semantic and syntactic \u2022structure and its discourse context.", "labels": [], "entities": []}, {"text": "The key idea is that a natural language generator, as opposed to a parser, generates extensive and reliable information about the liriguistic structure of an utterance, and is therefore particularly suitable to provide input to the prosodic \u2022module.", "labels": [], "entities": []}, {"text": "This approach requires at least two things from the generator.", "labels": [], "entities": []}, {"text": "First, it should generate all information that the prosodic module needs for deriving the prosodic structure of an utterance.", "labels": [], "entities": []}, {"text": "Second, it should generate as much variation as\u2022 possible, in order to put the prosodic module to the test.", "labels": [], "entities": []}, {"text": "Given a conventional architecture consisting of a text planner followed by a surface generator, these requirements affect the text planner.", "labels": [], "entities": []}, {"text": "For instance, it should keep track of the information status of concepts, because the distinction between old and new information is important for pitch accent placement.", "labels": [], "entities": [{"text": "pitch accent placement", "start_pos": 147, "end_pos": 169, "type": "TASK", "confidence": 0.6640786528587341}]}, {"text": "With respect to the second requirement, it should be able to paraphrase one and the same conceptual structure as different semantic structures, which are in turn realized as different \u2022sentences by the surface generator.", "labels": [], "entities": []}, {"text": "\u2022 This paper describes a text planner that meets these requirements.", "labels": [], "entities": []}, {"text": "It is described on the basis of an application of concept-to-speech in which train table information is taken as input to generate a spoken description, in Dutch, of how to get from one placeto another by train.", "labels": [], "entities": []}, {"text": "The approach, however, is easily adaptable to similar domains.", "labels": [], "entities": []}, {"text": "Since we are primarily interested in generating linguistically rich and maximally varied input for the prosodic module, the text planner is rather uncomplicated and ignores many other aspects of text planning like rhetorical  \u2022: Example of an input structure structuring of the text or tailoring information to the user.", "labels": [], "entities": []}, {"text": "In fact, there is no real dialogue with the user in the sense that the system is capable \u2022of reacting on feedback from the user.", "labels": [], "entities": []}, {"text": "Also, efficiency considerations (real time behaviour) have not played a role.", "labels": [], "entities": []}, {"text": "The interesting points, however, are that the text planner employs a constraint-based approach to produce variation and that its implementation is completely grammar-based within the framework of Functional Unification Grammar.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": []}