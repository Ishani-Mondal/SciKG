{"title": [{"text": "APPROACHES TO SURFACE REALIZATION WITH HPSG", "labels": [], "entities": [{"text": "APPROACHES", "start_pos": 0, "end_pos": 10, "type": "TASK", "confidence": 0.9500774145126343}, {"text": "REALIZATION WITH HPSG", "start_pos": 22, "end_pos": 43, "type": "METRIC", "confidence": 0.7168292999267578}]}], "abstractContent": [{"text": "HPSG is widely Used in theoretical and computational linguistics, but rarely in natural language generation.", "labels": [], "entities": [{"text": "HPSG", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.9128915667533875}, {"text": "natural language generation", "start_pos": 80, "end_pos": 107, "type": "TASK", "confidence": 0.6625015536944071}]}, {"text": "The paper describes some approaches to surface realization in which HPSG can be used.", "labels": [], "entities": [{"text": "surface realization", "start_pos": 39, "end_pos": 58, "type": "TASK", "confidence": 0.7429858148097992}]}, {"text": "The implementation of all the approaches combines generation algorithms in Prolog and HPSG grammars in ProFIT.", "labels": [], "entities": [{"text": "Prolog", "start_pos": 75, "end_pos": 81, "type": "DATASET", "confidence": 0.9664688110351562}, {"text": "ProFIT", "start_pos": 103, "end_pos": 109, "type": "DATASET", "confidence": 0.913303554058075}]}, {"text": "It is natural to combine a head-driven HPSG grammar with a head-driven generation algorithm.", "labels": [], "entities": []}, {"text": "We show how a simple head-driven generator can easily be adapted for use with HPSG.", "labels": [], "entities": [{"text": "HPSG", "start_pos": 78, "end_pos": 82, "type": "DATASET", "confidence": 0.9479655623435974}]}, {"text": "This works well with simplified semantics, but if we implement the full HPSG textbook semantics this approach does notwork.", "labels": [], "entities": [{"text": "HPSG textbook semantics", "start_pos": 72, "end_pos": 95, "type": "DATASET", "confidence": 0.9542512893676758}]}, {"text": "Ina second approach to head-driven generation, we implement some recent revisions of HPSG, and show that head-driven generation with HPSG \u2022 is in fact possible.", "labels": [], "entities": [{"text": "head-driven generation", "start_pos": 23, "end_pos": 45, "type": "TASK", "confidence": 0.7848549783229828}, {"text": "HPSG", "start_pos": 85, "end_pos": 89, "type": "DATASET", "confidence": 0.9529240727424622}]}, {"text": "We then switch to non-head-driven approaches.", "labels": [], "entities": []}, {"text": "We show how a bag generation algorithm, developed for use with categorial grammar and indexed QLF, can be used with HPSG and MinimalRecursion Semantics.", "labels": [], "entities": [{"text": "bag generation", "start_pos": 14, "end_pos": 28, "type": "TASK", "confidence": 0.7539747953414917}, {"text": "HPSG", "start_pos": 116, "end_pos": 120, "type": "DATASET", "confidence": 0.9447113871574402}]}, {"text": "We describe an approach to incremental generation with HPSG, noting a difficulty for highly incremental generation with HPSG and proposing a solution.", "labels": [], "entities": [{"text": "HPSG", "start_pos": 55, "end_pos": 59, "type": "DATASET", "confidence": 0.964252233505249}, {"text": "HPSG", "start_pos": 120, "end_pos": 124, "type": "DATASET", "confidence": 0.963826596736908}]}, {"text": "Finally we briefly mention a few other plausible approaches.", "labels": [], "entities": []}], "introductionContent": [{"text": "In work on natural language generation, tile most influential linguistic framework has l)robably been Systemic Functional Grammar (SFG).", "labels": [], "entities": [{"text": "natural language generation", "start_pos": 11, "end_pos": 38, "type": "TASK", "confidence": 0.6685789922873179}, {"text": "Systemic Functional Grammar (SFG)", "start_pos": 102, "end_pos": 135, "type": "TASK", "confidence": 0.7740811208883921}]}, {"text": "However, in other areas of computational linguistics the most widely used grammatical framework appears to be Head-driven Phrase Structure Grarnmar (HPSG).", "labels": [], "entities": []}, {"text": "Why is it, then, that using HPSG for generation has been almost as unpopular as using SFG for parsing?", "labels": [], "entities": []}, {"text": "Without making any claim that HPSG is better t.han SFG for generation, we will review some plausible approaches to surface realization with HPSG.", "labels": [], "entities": [{"text": "HPSG", "start_pos": 30, "end_pos": 34, "type": "DATASET", "confidence": 0.8696383237838745}]}, {"text": "We will show that there are indeed some fundamental difficulties in using HPSG for generation, but also that there are some solutions to these difficulties.", "labels": [], "entities": []}, {"text": "The first approach to mention is the radical one of converting HPSG into something else before generation, such as Tree Adjoining Grammar ()..Though this seems to support the view that HPSG is unsuitable for generation, it is in fact a valuable contribution to work on compiling HPSG grammars for efficient processing, whether for parsing or for generation.", "labels": [], "entities": []}, {"text": "However, we will not be concerned with efficiency, but with more basic problems in the relations between HPSG and generation algorithmS.", "labels": [], "entities": []}, {"text": "The question is, can existing algorithms be used with HPSG grammars at all?", "labels": [], "entities": []}, {"text": "For clarity, we use the simplest versions of the algorithms, which were originally developed for use with definite clause (DCG) grammars and categorial grammar.", "labels": [], "entities": []}, {"text": "For uniformity~ the algorithms are implemented m Prolog and the grammars are implemented in ProFIT.", "labels": [], "entities": [{"text": "Prolog", "start_pos": 49, "end_pos": 55, "type": "DATASET", "confidence": 0.9538167119026184}, {"text": "ProFIT", "start_pos": 92, "end_pos": 98, "type": "DATASET", "confidence": 0.9433290362358093}]}], "datasetContent": [], "tableCaptions": []}