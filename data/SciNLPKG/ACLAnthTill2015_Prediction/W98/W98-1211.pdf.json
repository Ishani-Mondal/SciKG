{"title": [{"text": "Linguistic Theory in Statistical Language Learning", "labels": [], "entities": [{"text": "Linguistic Theory", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.7459717094898224}, {"text": "Statistical Language Learning", "start_pos": 21, "end_pos": 50, "type": "TASK", "confidence": 0.7632657488187155}]}], "abstractContent": [{"text": "II i Hi HI mi mi mill IH i IH IH HI I I I I i I Abstract This article attempts to determine what elements of linguistic theory are used in statistical language learning, and why the extracted language models look like they do.", "labels": [], "entities": [{"text": "Abstract", "start_pos": 48, "end_pos": 56, "type": "METRIC", "confidence": 0.9761437177658081}]}, {"text": "The study indicates that some linguistic elements, such as the notion of a word, are simply too useful to be ignored.", "labels": [], "entities": []}, {"text": "The second most important factor seems to be features inherited from the original task for which the technique was used, for example using hidden Markov models for part-of-speech tagging, rather than speech recognition.", "labels": [], "entities": [{"text": "part-of-speech tagging", "start_pos": 164, "end_pos": 186, "type": "TASK", "confidence": 0.6945288628339767}, {"text": "speech recognition", "start_pos": 200, "end_pos": 218, "type": "TASK", "confidence": 0.7854190170764923}]}, {"text": "The two remaining important factors are properties of the runtime processing scheme employing the extracted language model, and the properties of the available corpus resources to which the statistical learning techniques are applied.", "labels": [], "entities": []}, {"text": "Deliberate attempts to include linguistic theory seem to end up in a fifth place.", "labels": [], "entities": []}], "introductionContent": [{"text": "What role does linguistics play in statistical language learning?", "labels": [], "entities": [{"text": "statistical language learning", "start_pos": 35, "end_pos": 64, "type": "TASK", "confidence": 0.754943867524465}]}, {"text": "\"None at all!\" might be the answer, if we ask hard-core speech-recognition professionals.", "labels": [], "entities": []}, {"text": "But even the most nonlinguistic language model, for example a statistic word bigram model, actually relies on key concepts integral to virtually all linguistic theories.", "labels": [], "entities": []}, {"text": "Words, for example, and the notion that sequences of words form utterances.", "labels": [], "entities": []}, {"text": "Statistical language learning is applied to some set of data to extract a language model of some kind.", "labels": [], "entities": []}, {"text": "This language model can serve a purely decorative purpose, but is more often than not used to process data in someway, for example to aid speech recognition.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 138, "end_pos": 156, "type": "TASK", "confidence": 0.8311777412891388}]}, {"text": "Anyone working under the pressure of producing better results, and who employs language models to this purpose, such a researchers in the field of speech recognition, will have a high incentive of incorporating useful aspects of language into his or her language models.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 147, "end_pos": 165, "type": "TASK", "confidence": 0.7246057391166687}]}, {"text": "Now, the most useful, and thus least controversial ways of describing language will, due to their usefulness, find their way into most linguistic theories and, for the very same reason, be used in models that strive to model language successfully.", "labels": [], "entities": []}, {"text": "So what do the linguistic theories underlying various statistical language models look like?", "labels": [], "entities": []}, {"text": "It maybe useful to distinguish between those aspects of linguistic theory that are incidentally in the language model, and those that are there intentionally.", "labels": [], "entities": []}, {"text": "We will start our tour of statistical language learning by inspecting language models with \"very little\" linguistic content, and then proceed to analyse increasingly more linguistic models, until we end with models that are entirely linguistic, in the sense that they are pure grammars, associated with no statistical parameters.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": []}