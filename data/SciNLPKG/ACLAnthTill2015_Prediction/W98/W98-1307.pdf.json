{"title": [{"text": "Learning Finite-State Models for Language Understanding*", "labels": [], "entities": [{"text": "Language Understanding", "start_pos": 33, "end_pos": 55, "type": "TASK", "confidence": 0.734849363565445}]}], "abstractContent": [{"text": "Language Understanding in limited domains is here approached as a problem of language tra~lation in which the target language is a ]o~nal language rather than a natural one.", "labels": [], "entities": [{"text": "Language Understanding", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.7010792046785355}]}, {"text": "Finite-state transducers are used to model the translation process.", "labels": [], "entities": []}, {"text": "Furthermore , these models are automatically learned from ironing data consisting of pairs of natural-language/formal-language sentences.", "labels": [], "entities": []}, {"text": "The need for training data is dramatically reduced by performing a two-step learning process based on !exical/phrase categoriza-tion.", "labels": [], "entities": []}, {"text": "Successful experiments are presented on a task consisting in the ~anderstanding ~ of Spanish natural-language sentences describing dates and times, where the target formal language is the one used in the popular Unix command ~at\".", "labels": [], "entities": []}], "introductionContent": [{"text": "Language Understanding (LU) has been the focus of much research work in the last twenty years.", "labels": [], "entities": [{"text": "Language Understanding (LU)", "start_pos": 0, "end_pos": 27, "type": "TASK", "confidence": 0.8270189106464386}]}, {"text": "Many classical approaches typically consider LU from a linguistically motivated, generalistic point of view.", "labels": [], "entities": []}, {"text": "Nevertheless, it is interesting to note tllat, in contrast with some general-purpose formulations of LU, many applications of interest to industry and business have limited domains; that is, lexicons are of small size and the semantic universe is limited.", "labels": [], "entities": []}, {"text": "If we restrict ourselves to these kinds of tasks, many aspects of system design can be dramatically simplified.", "labels": [], "entities": []}, {"text": "In fact, under the limited-domain framework, the ultimate goal Of a system is to driue the actions associated to the meaning conveyed by the sentences issued by the users.", "labels": [], "entities": []}, {"text": "Since actions are to be performed by machines, the understanding problem can then be simply formulated as translating the natural language sentences into .?orma/sentences of an adequate (computer) command language in which the actions to be carried out can.be specified.", "labels": [], "entities": []}, {"text": "For example, \"understanding\" natural language (spOken) queries to a database can be seen as \"translating\" these queries into appropriate computer-language code to access the database.", "labels": [], "entities": []}, {"text": "Clearly, under such an assumption, LU can be seen as a possibly simpler case of Language Translation in which the output language is forma/rather than natural Hopefully, these simplifications can lead to new systems that are more compact and faster to build thant those developed under more traditional paradigms.", "labels": [], "entities": [{"text": "Language Translation", "start_pos": 80, "end_pos": 100, "type": "TASK", "confidence": 0.7280851304531097}]}, {"text": "This would entail i) to devise simple and easily understandable models for LU, ii) to formulate LU as some kind of optimal search through an adequate structure based on these models, and iii) to develop techniques to actually learn the LU models from training data of each considered task.", "labels": [], "entities": []}, {"text": "All these requirements can be easily met through the use of Finite-State Translation Models.", "labels": [], "entities": [{"text": "Finite-State Translation", "start_pos": 60, "end_pos": 84, "type": "TASK", "confidence": 0.6659058928489685}]}, {"text": "The capabilities of Finite-State Models (FSM) have been the object of much debate in the past few years.", "labels": [], "entities": [{"text": "Finite-State Models (FSM)", "start_pos": 20, "end_pos": 45, "type": "TASK", "confidence": 0.6157410919666291}]}, {"text": "On the one hand, in the Natural Language (NL) community, FSMs have often been ruled out for many NL processing applications, including LU, even in limited domains.", "labels": [], "entities": []}, {"text": "Recently, many NL and Computational Linguistic researchers are (re-)considering the interesting features of FSMs for their use in NL processing applications.", "labels": [], "entities": []}, {"text": "Undoubtedly, the most attractive feature of FSMs consists in their simplicity: representation is just a matter of setting a network of nodes and links in memory, and parsing can be simply carried out by appropriately following the links of this network, according to the observed input data.", "labels": [], "entities": [{"text": "FSMs", "start_pos": 44, "end_pos": 48, "type": "TASK", "confidence": 0.9194015860557556}]}, {"text": "More specifically, as it is well known, using Viterbi-like techniques, computing time for parsing is linear with the length of the data sequence to be parsed and, using adequate techniques, such as beam search, it can be easily made independent on the size of the network in practice.", "labels": [], "entities": [{"text": "parsing", "start_pos": 90, "end_pos": 97, "type": "TASK", "confidence": 0.9748927354812622}, {"text": "beam search", "start_pos": 198, "end_pos": 209, "type": "TASK", "confidence": 0.8455902338027954}]}, {"text": "Simple as they are, FSMs generally need to be huge in order to be useful approximations to complex languages.", "labels": [], "entities": [{"text": "FSMs", "start_pos": 20, "end_pos": 24, "type": "TASK", "confidence": 0.9550917148590088}]}, {"text": "For instance, an adequate 3--Gram Language Model for the language of the Wall Street Journal is a FSM that may have as many as 20 million edges.", "labels": [], "entities": [{"text": "Wall Street Journal", "start_pos": 73, "end_pos": 92, "type": "DATASET", "confidence": 0.8766844471295675}, {"text": "FSM", "start_pos": 98, "end_pos": 101, "type": "DATASET", "confidence": 0.5976902842521667}]}, {"text": "Obviously, there is no point in trying to manually build such models on the base of a priori knowledge about the language to be modeled: the success lies in the possibility of automatically learning them from large enough sets of training data.", "labels": [], "entities": []}, {"text": "This is also the case for the finite-state LU models used in the work presented in this paper.", "labels": [], "entities": []}], "datasetContent": [{"text": "The chosen task in our experiments was the translation from Spanish sentences specifying times and dates into sentences of a formal semantic language.", "labels": [], "entities": [{"text": "translation from Spanish sentences specifying times and dates", "start_pos": 43, "end_pos": 104, "type": "TASK", "confidence": 0.8523161858320236}]}, {"text": "This is in fact an important subtask that is common to many real-world LU applications of much interest to industry and society.", "labels": [], "entities": []}, {"text": "Examples of this kind of applications are flight, train or hotel reservations, appointment schedules, etc..", "labels": [], "entities": [{"text": "flight, train or hotel reservations", "start_pos": 42, "end_pos": 77, "type": "TASK", "confidence": 0.585709273815155}]}, {"text": "Therefore, having an adequate solution to this subtask can significantly simplify the building of successful systems for these applications (another work on this subtask can be found in).", "labels": [], "entities": []}, {"text": "The chosen formal language has been the one used in UNIX\" command \"at\".", "labels": [], "entities": []}, {"text": "This simple language allows both absolute and relative descriptions of time.", "labels": [], "entities": []}, {"text": "From these descriptions, the \"at\" interpreter can be directly used to obtain date/time interpretations in the desired format.", "labels": [], "entities": []}, {"text": "The correct syntax of \"at\" commands is described in the standard Unix documentation (see, e.g.).", "labels": [], "entities": []}, {"text": "shows some training pairs that have been selected from the training material.", "labels": [], "entities": []}, {"text": "Starting from the given context-free-style syntax description of the \"at\" command, and knowledge-based patterns of typical ways of expressing dates and times in natural, spontaneous Spanish, a large corpus of pairs of \"natural-language\"/at-language sentences has been artificially constructed.", "labels": [], "entities": []}, {"text": "This is intended to be the first step in a bootstrapping development.", "labels": [], "entities": []}, {"text": "On-going work on this task is aimed at (semi-automatically) obtaining additional corpora produced by native speakers.", "labels": [], "entities": []}, {"text": "The corpus generation procedure incorporated certain \"category labels\", such as hour, month, day of week, etc.", "labels": [], "entities": [{"text": "corpus generation", "start_pos": 4, "end_pos": 21, "type": "TASK", "confidence": 0.7316225618124008}]}, {"text": "We have used a similar process for defining and generating subcorpora in which every input and its corresponding semantic coding belong to the different categories.", "labels": [], "entities": []}, {"text": "We finally have obtained an uncategorized version of the categorized corpus, by means of randomly instantiating the category marks in the samples.", "labels": [], "entities": []}, {"text": "The examples found on figure 2 come from this uncategorized corpus, while shows the corresponding categorized pairs.", "labels": [], "entities": []}, {"text": "II II ',\"dos minutos despuds de la usa y media\", 01 : 30 + 2 MINUTE) ft~#o minutes after one thirty) ',\"dentro de usa hora\", NOW + 1 HOUR) 'in one hour) '\"el maxtes, a la hora de!", "labels": [], "entities": [{"text": "MINUTE", "start_pos": 61, "end_pos": 67, "type": "METRIC", "confidence": 0.9971422553062439}, {"text": "HOUR", "start_pos": 133, "end_pos": 137, "type": "METRIC", "confidence": 0.8279839158058167}]}, {"text": "td, mas un minuto\", TEATIME TUE + 1 MINUTE) 'on thursday, at teatime plus one minute) i\"el catorce de octubre del afio dos nail tres, alas diecisiete horas y cinco minutos', 17 : 05 OCT 14,2003) (on october the first, year two tho.aand and three, at seventeen hours and fi~e minutes).", "labels": [], "entities": [{"text": "TEATIME TUE + 1 MINUTE", "start_pos": 20, "end_pos": 42, "type": "METRIC", "confidence": 0.832062840461731}]}, {"text": "Sample of selected training pairs for the date specification task.", "labels": [], "entities": [{"text": "date specification task", "start_pos": 42, "end_pos": 65, "type": "TASK", "confidence": 0.7094424267609915}]}, {"text": "(\"inc-number mlnutos despu& de h24 ram\", h24 :mm + inc-number IMINUTE) i(,dentro de una hora', 'NOW + 1 HOUR) ~\"el day-of-week, a t-dest, mas un minuto\", t-dest day-of-week + 1 MINUTE) (\"el day-txt de month-name del afio year-name, a h24 mm', h24 : mm month-name day-txt , year-name).", "labels": [], "entities": [{"text": "IMINUTE", "start_pos": 62, "end_pos": 69, "type": "METRIC", "confidence": 0.9957106113433838}, {"text": "NOW + 1", "start_pos": 96, "end_pos": 103, "type": "METRIC", "confidence": 0.8058206637700399}, {"text": "HOUR", "start_pos": 104, "end_pos": 108, "type": "METRIC", "confidence": 0.5056241750717163}, {"text": "MINUTE", "start_pos": 177, "end_pos": 183, "type": "METRIC", "confidence": 0.9868205189704895}]}, {"text": "Sample of categorized pairs for the date specification task.", "labels": [], "entities": [{"text": "date specification task", "start_pos": 36, "end_pos": 59, "type": "TASK", "confidence": 0.7571884989738464}]}, {"text": "We have generated a training corpus of 48353 different, uncategorized translation pairs, and a disjoint test set with 1331 translation pairs.", "labels": [], "entities": []}, {"text": "We have presented the OSTIA-DR with 8 training subsets of sizes increasing from 1817 up to 48353.", "labels": [], "entities": [{"text": "OSTIA-DR", "start_pos": 22, "end_pos": 30, "type": "DATASET", "confidence": 0.8401721119880676}]}, {"text": "We also have presented OSTIA-DR with the same, but categorized, training subsets.", "labels": [], "entities": []}, {"text": "In this case, the number of different pairs went from 1384 up to 12381.", "labels": [], "entities": []}, {"text": "shows the size of categorized corpora vs. uncategorized corpora.", "labels": [], "entities": []}, {"text": "The input language vocabulary has 108 words, and the output language has 125 semantic symbols.", "labels": [], "entities": []}, {"text": "We have used 11 different category labels.", "labels": [], "entities": []}, {"text": "In the categorized experiments, a sentence-transducer was inferred from the categorized sentences, and a (small) category-transducer for each one of the categories.", "labels": [], "entities": []}, {"text": "The final transducer, which is able to translate noncategorized sentences, was buildup by the embedding of the category-transducers into the sentence-transducers.", "labels": [], "entities": []}, {"text": "The output yielded by this final transducer includes category labels and their corresponding instances, as found in the translation process.", "labels": [], "entities": []}, {"text": "The definitive translations of the test set inputs are obtained by means of a simple filter that resolves the dependencies.", "labels": [], "entities": []}, {"text": "The sizes of the inferred transducers are shown on.", "labels": [], "entities": []}, {"text": "Performance has been measured in terms of both semantic-symbol error and fUll-sentence matching rates.", "labels": [], "entities": [{"text": "fUll-sentence matching", "start_pos": 73, "end_pos": 95, "type": "TASK", "confidence": 0.7577457427978516}]}, {"text": "The translation of the test set inputs has been computed using both the standard Viterbi algorithm and the Error Correction techniques, outlined on sections 3.1 and 3.2.", "labels": [], "entities": [{"text": "Error Correction", "start_pos": 107, "end_pos": 123, "type": "METRIC", "confidence": 0.9283586740493774}]}, {"text": "The results are shown in.", "labels": [], "entities": []}, {"text": "A big difference in performance between the uncategorized and categorize d training procedures can be observed.", "labels": [], "entities": []}, {"text": "Semantic-symbol error rates are much lower in the categorized experiments than in the uncategorized ones.", "labels": [], "entities": []}, {"text": "We can also appreciate a remarkable decrease in semantic-symbol error rates of Error Correcting with respect to Viterbi translations, specially for smaller training corpus.", "labels": [], "entities": [{"text": "semantic-symbol error rates", "start_pos": 48, "end_pos": 75, "type": "METRIC", "confidence": 0.6482633948326111}]}, {"text": "The full-sentence matching rate also exhibited a strong improve-.", "labels": [], "entities": [{"text": "full-sentence matching", "start_pos": 4, "end_pos": 26, "type": "TASK", "confidence": 0.6686404049396515}]}, {"text": "The size is expressed in number of edges: \"base\" stands for the transducer containing category labels, while \"cats\" stands for the final sentence-transducer which is calculated by embedding the (small) category-transducers into the \"base\" one; \"plain\" stands for the uncategorized sentence-transducer.", "labels": [], "entities": []}], "tableCaptions": []}