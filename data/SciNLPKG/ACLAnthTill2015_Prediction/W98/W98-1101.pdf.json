{"title": [{"text": "Bayesian Stratified Sampling to Assess Corpus Utility", "labels": [], "entities": [{"text": "Assess Corpus Utility", "start_pos": 32, "end_pos": 53, "type": "TASK", "confidence": 0.8540136019388834}]}], "abstractContent": [{"text": "This paper describes a method for asking statistical questions about a large text corpus.", "labels": [], "entities": []}, {"text": "We exemplify the method by addressing the question, \"What percent", "labels": [], "entities": []}], "introductionContent": [{"text": "The traditional task in information retrieval is to find documents from a large corpus that are relevant to a query.", "labels": [], "entities": [{"text": "information retrieval", "start_pos": 24, "end_pos": 45, "type": "TASK", "confidence": 0.7450183629989624}]}, {"text": "In this paper we address a related task: answering statistical questions about a corpus.", "labels": [], "entities": [{"text": "answering statistical questions about a corpus", "start_pos": 41, "end_pos": 87, "type": "TASK", "confidence": 0.8323441743850708}]}, {"text": "Instead of finding the documents that match a query, we quantify the percentage of documents that match it.", "labels": [], "entities": []}, {"text": "The method is designed to address statistical questions that are: \u2022 subjective: that is, informed readers may disagree about which documents match the query, and the same reader may make different judgment at different times.", "labels": [], "entities": []}, {"text": "This characteristic describes most queries of real interest to text researchers.", "labels": [], "entities": []}, {"text": "\u2022 difficult: that is, one cannot define an algorithrn to reliably assess individual documents, and thus the corpus as a whole.", "labels": [], "entities": []}, {"text": "This characteristic follows naturally from the first.", "labels": [], "entities": []}, {"text": "It maybe compounded by an insufficient understanding of a corpus, or a shortcoming in one's tools for analyzing it.", "labels": [], "entities": []}, {"text": "Statistical questions asked of small corpora can be answered exhaustively, by reading and scoring every document in the corpus.", "labels": [], "entities": []}, {"text": "Such answers will be subjective, since judgments about the individual documents are subjective.", "labels": [], "entities": []}, {"text": "For a large corpus, it is not feasible to read every document.", "labels": [], "entities": []}, {"text": "Instead, one must sample a subset of documents, then extrapolate the resuits of the sample to the corpus as a whole.", "labels": [], "entities": []}, {"text": "The conclusions that one draws from such a sampling will have two components: the estimated answer to the question, and a confidence interval around the estimate.", "labels": [], "entities": []}, {"text": "The method described in this paper combines traditional statistical sampling techniques,) with Bayesian analysis,) to reduce this sampling uncertainty.", "labels": [], "entities": []}, {"text": "The method is well-grounded in statistical theory, but its application to textual queries is novel.", "labels": [], "entities": [{"text": "statistical theory", "start_pos": 31, "end_pos": 49, "type": "TASK", "confidence": 0.9208628535270691}]}, {"text": "One begins by stratifying the data using objective tests designed to yield relatively homogeneous strata, within which most documents either match or do not match the query.", "labels": [], "entities": []}, {"text": "Then one samples randomly within each stratum, with the number of documents sampled per stratum determined through the analysis of a presampie.", "labels": [], "entities": []}, {"text": "A reader scores each selected document, and the results of the different strata are combined.", "labels": [], "entities": []}, {"text": "If the strata are well constructed, the resuiting estimate about the corpus will have a much smaller credibility interval (the Bayesian version of a confidence interval) than one based on a sample of the corpus as a whole.", "labels": [], "entities": [{"text": "credibility interval", "start_pos": 101, "end_pos": 121, "type": "METRIC", "confidence": 0.8929345309734344}]}, {"text": "The method is well suited for subjective queries because it brings a human reader's subjective judgments to bear on individual documents.", "labels": [], "entities": []}, {"text": "The Bayesian approach that we apply to this problem allows a second opportunity for the reader to influence the results of the sampling.", "labels": [], "entities": []}, {"text": "The reader can construct a probability density that summarizes his or her prior expectations about each stratum.", "labels": [], "entities": []}, {"text": "These prior expectations are combined with presampling results to determine the makeup of the final sample.", "labels": [], "entities": [{"text": "presampling", "start_pos": 43, "end_pos": 54, "type": "METRIC", "confidence": 0.9918151497840881}]}, {"text": "When the final sample is analyzed, the prior expectations are again factored in, influencing the estimated mean and the size of the credibility interval.", "labels": [], "entities": []}, {"text": "Thus different readers' prior expectations, and their judgments of individual documents, can lead to substantiially different results, which is consistent with the subjective probability paradigm.", "labels": [], "entities": []}, {"text": "In earlier work we used this method to analyze medical records, asking, \"What percentage of the patients are female?\"", "labels": [], "entities": []}, {"text": "The lack of a required gender field in the record format made this a subjective question, especially for records that did not specify the patient's gender at all, or gave conflicting clues.", "labels": [], "entities": []}, {"text": "We stratified the corpus into probable male and female records based on linguistic tests such as the number of female versus male pronouns in a record, then sampled within each stratum.", "labels": [], "entities": []}, {"text": "Stratification reduced the sampling uncertainty for the question from fourteen percentage points (based on an overall sample of 200 records) to five (based on a stratified sample of the same size).", "labels": [], "entities": [{"text": "sampling uncertainty", "start_pos": 27, "end_pos": 47, "type": "METRIC", "confidence": 0.7685602307319641}]}, {"text": "In this paper, we update the method and apply it to anew corpus, the Federal Register.", "labels": [], "entities": [{"text": "Federal Register", "start_pos": 69, "end_pos": 85, "type": "DATASET", "confidence": 0.9504123330116272}]}, {"text": "The main change from is a greater focus on numerical methods as opposed to parametric and forrnulaic calculations.", "labels": [], "entities": []}, {"text": "For example, we use a non-parametric prior density instead of a beta density, and combine posterior densities between strata using a Monte Carlo simulation rather than weighted means and variances.", "labels": [], "entities": []}, {"text": "Other differences, such as a Bayesian technique for allocating samples between strata, and anew method for determining the size of the credibility interval, are noted in the text.", "labels": [], "entities": []}, {"text": "This discovery at first appeared to be a mere nuisance.", "labels": [], "entities": []}, {"text": "We assumed that there was an easy way to separate pseudo-documents from real documents, but could not find one.", "labels": [], "entities": []}, {"text": "The harder we looked fora way to separate the two document types, the more we realized that this distinction had theoretical interest.", "labels": [], "entities": []}, {"text": "Determining the percentage of real documents would serve to evaluate the true size of the corpus, and its usefulness for TIPSTER type applications where documents relevant to topic queries are expected to be returned.", "labels": [], "entities": []}, {"text": "This query matched the two criteria set forth in the Introduction for applicability to our method.", "labels": [], "entities": []}, {"text": "As described above, there was no easy way to separate real documents from pseudo-documents.", "labels": [], "entities": []}, {"text": "The query was also subjective, since readers might disagree about the classification of particular documents.", "labels": [], "entities": []}, {"text": "For example, a document announcing classes on how to use the Federal Register could be considered areal document (since notices of all sorts appear in the Register), or a pseudo-document (since it is promulgated by the Register's office and appears at regular intervals).", "labels": [], "entities": [{"text": "Federal Register", "start_pos": 61, "end_pos": 77, "type": "DATASET", "confidence": 0.9536819159984589}]}, {"text": "As another example, readers might disagree about which erratum documents are significant enough to be considered real documents themselves.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1. This  process involved dividing the data into two  relatively homogeneous strata, one containing  mostly real documents, the other mostly  pseudo-documents, and combining sampling  results from the two strata.  This approach is advantageous because the", "labels": [], "entities": []}]}