{"title": [{"text": "Enriching Automated Essay Scoring Using Discourse Marking", "labels": [], "entities": [{"text": "Enriching Automated Essay Scoring", "start_pos": 0, "end_pos": 33, "type": "TASK", "confidence": 0.7627704739570618}, {"text": "Discourse Marking", "start_pos": 40, "end_pos": 57, "type": "TASK", "confidence": 0.7079010903835297}]}], "abstractContent": [{"text": "\u2022 Abstract Electronic Essay Rater (e-rater) is a prototype automated essay scoring system built at Educational Testing Service (ETS) that uses discourse marking, in addition to syntactic information and topical content vector analyses to automatically assign essay scores.", "labels": [], "entities": [{"text": "Educational Testing Service (ETS)", "start_pos": 99, "end_pos": 132, "type": "DATASET", "confidence": 0.700755755106608}]}, {"text": "This paper gives a general description ore-rater as a whole, but its emphasis is on the importance of discourse marking and argument partitioning for annotating the argument structure of an essay.", "labels": [], "entities": [{"text": "discourse marking", "start_pos": 102, "end_pos": 119, "type": "TASK", "confidence": 0.7117457091808319}, {"text": "argument partitioning", "start_pos": 124, "end_pos": 145, "type": "TASK", "confidence": 0.7132717221975327}]}, {"text": "We show comparisons between two content vector analysis programs used to predict scores.", "labels": [], "entities": []}, {"text": "EsscQ/'Content and ArgContent.", "labels": [], "entities": [{"text": "EsscQ", "start_pos": 0, "end_pos": 5, "type": "DATASET", "confidence": 0.8211880922317505}]}, {"text": "EsscnContent assigns scores to essays by using a standard cosine correlation that treats the essay like a \"'bag of words.\" in that it does not consider word order.", "labels": [], "entities": []}, {"text": "Ark, Content employs a novel content vector analysis approach for score assignment based on the individual arguments in an essay.", "labels": [], "entities": []}, {"text": "The average agreement between ArgContent scores and human rater scores is 82%.", "labels": [], "entities": [{"text": "ArgContent scores", "start_pos": 30, "end_pos": 47, "type": "METRIC", "confidence": 0.9547947347164154}]}, {"text": "as compared to 69% agreement between EssavContent and the human raters.", "labels": [], "entities": [{"text": "EssavContent", "start_pos": 37, "end_pos": 49, "type": "DATASET", "confidence": 0.8792654275894165}]}, {"text": "These results suggest that discourse marking enriches e-rater's scoring capability.", "labels": [], "entities": [{"text": "discourse marking", "start_pos": 27, "end_pos": 44, "type": "TASK", "confidence": 0.777408093214035}]}, {"text": "When e-rater uses its whole set of predictive features, agreement with human rater scores ranges from 87\u00b0,/o-94% across the 15 sets of essa5 responses used in this study", "labels": [], "entities": [{"text": "agreement", "start_pos": 56, "end_pos": 65, "type": "METRIC", "confidence": 0.9819964170455933}, {"text": "\u00b0,/", "start_pos": 104, "end_pos": 107, "type": "METRIC", "confidence": 0.9113073945045471}]}], "introductionContent": [{"text": "The development of Electronic Essay Rater (e-rater).", "labels": [], "entities": [{"text": "Electronic Essay Rater", "start_pos": 19, "end_pos": 41, "type": "TASK", "confidence": 0.5308322211106619}]}, {"text": "an automated prototype essay scoring system, was motivated by practical concerns of time and costs that limit the number of essay questions on current standardized tests.", "labels": [], "entities": [{"text": "essay scoring", "start_pos": 23, "end_pos": 36, "type": "TASK", "confidence": 0.7393350601196289}]}, {"text": "Literature on automated essay scoring shows that reasonably high agreement can be achieved between a machine score and a human rater score simply by doing analyses based on the number of words in an essay).", "labels": [], "entities": [{"text": "agreement", "start_pos": 65, "end_pos": 74, "type": "METRIC", "confidence": 0.9802676439285278}]}, {"text": "Scoring an essay based on the essay length is not a criterion that can be used to define competent writing.", "labels": [], "entities": []}, {"text": "In addition, from a practical standpoint.", "labels": [], "entities": []}, {"text": "essay length is a highly coachable feature.", "labels": [], "entities": [{"text": "essay length", "start_pos": 0, "end_pos": 12, "type": "TASK", "confidence": 0.4734781086444855}]}, {"text": "It doesn't take examinees long to figure out that a computer will assign a high score on an essay based on a prespecified number of words.", "labels": [], "entities": []}, {"text": "E-rater's modules extract syntactic and discourse structure information from essays, as well as information about vocabulary content in order to predict the score.", "labels": [], "entities": []}, {"text": "The 57 features included in e-rater 15 are based on writing characteristics specified at each of the six score points in the scoring guide used by human raters for manual scoring (also available at http://www.gmat.org;).", "labels": [], "entities": []}, {"text": "For example, the scoring guide indicates that an essay that stays on the topic of the test question, has a strong, coherent and wellorganized argument structure, and displays a variety of word use and syntactic structure will receive a score at the higher end of the six-point scale (5 or 6}.", "labels": [], "entities": []}, {"text": "Lower scores are assigned to essays as these characteristics diminish.", "labels": [], "entities": []}, {"text": "Included in e-rater's feature set are features derived from discourse structure, syntactic structure, and topical analysis as they relate to the human scoring guide.", "labels": [], "entities": [{"text": "topical analysis", "start_pos": 106, "end_pos": 122, "type": "TASK", "confidence": 0.6948034018278122}]}, {"text": "For each essay question, e-rater is run on a set of training data (human-scored essay responses) to extract t~.atures.", "labels": [], "entities": []}, {"text": "A stepwise linear regression analysis is performed on the features extracted from the training set to determine which ones have significant weights (the predictive features).", "labels": [], "entities": []}, {"text": "Final score prediction for cross-validation sets is performed using these predictive features identified in the training sets.", "labels": [], "entities": []}, {"text": "Accuracy is determined by measuring agreement between human rater assigned scores and machine predicted scores, which are considered to \"agree\" if there is no greater than a single point difference on the six-point scale.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 0, "end_pos": 8, "type": "METRIC", "confidence": 0.9938522577285767}, {"text": "agreement", "start_pos": 36, "end_pos": 45, "type": "METRIC", "confidence": 0.9595530033111572}]}, {"text": "This is the same criterion used to measure agreement between two human raters.", "labels": [], "entities": []}, {"text": "Among the strongest predictive features across the essay questions used in this study are the scores generated from ArgContent (a content vector analysis applied to discourse chunked text), and discourserelated surface cue word and non-lexical features.", "labels": [], "entities": [{"text": "ArgContent", "start_pos": 116, "end_pos": 126, "type": "METRIC", "confidence": 0.8799819946289062}]}, {"text": "On average, ArgContent alone has 82% agreement with the human rater score as compared to EssavContent's 69%.", "labels": [], "entities": [{"text": "ArgContent", "start_pos": 12, "end_pos": 22, "type": "METRIC", "confidence": 0.8436707258224487}, {"text": "human rater score", "start_pos": 56, "end_pos": 73, "type": "METRIC", "confidence": 0.6523938477039337}]}, {"text": "EssayContent is a content vector analysis program that treats an essay like a \"'bag of words.\"", "labels": [], "entities": [{"text": "content vector analysis", "start_pos": 18, "end_pos": 41, "type": "TASK", "confidence": 0.6844357848167419}]}, {"text": "First, the discourse markers detected by the argument annotation and partitioning program.", "labels": [], "entities": []}, {"text": "APA. are helpful for identification of relevant units of discourse in essay responses.", "labels": [], "entities": [{"text": "APA.", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.7292735576629639}]}, {"text": "the application of content vector analysis to those text units appears to increase scoring performance.", "labels": [], "entities": [{"text": "content vector analysis", "start_pos": 19, "end_pos": 42, "type": "TASK", "confidence": 0.6844281057516733}]}, {"text": "Overall, it appears that discourse marking provides feature information that is useful in e-rater's essay score predictions.", "labels": [], "entities": [{"text": "discourse marking", "start_pos": 25, "end_pos": 42, "type": "TASK", "confidence": 0.7157300561666489}]}, {"text": "A long-term goal of automated essay scoring is to be able to generate diagnostic or instructional information, along with a numeric score to a testtaker or instructor.", "labels": [], "entities": [{"text": "essay scoring", "start_pos": 30, "end_pos": 43, "type": "TASK", "confidence": 0.7178138643503189}]}, {"text": "Information about the discourse structure of essays brings us closer to being able to generate informative feedback to test-takers about the essay's cohesion.", "labels": [], "entities": []}, {"text": "We report on the overall evaluation results from crater's scoring performance on 13 sets of essay data from the Analytical Writing Assessments of the Graduate Management Admissions Test (GMAT) (see http://www.gmat.org/) and 2 sets of essay data from the Test of Written English (TWE) (see http://w.w.w.toefl.or~tstprpmt.html for sample TWE questions).", "labels": [], "entities": []}, {"text": "The paper devotes special attention to erater's discourse marking and analysis components.", "labels": [], "entities": [{"text": "erater's discourse marking", "start_pos": 39, "end_pos": 65, "type": "TASK", "confidence": 0.8974588811397552}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 3: Most Frequently Occurring Predictive  Features Across 15 Essay Questions", "labels": [], "entities": []}]}