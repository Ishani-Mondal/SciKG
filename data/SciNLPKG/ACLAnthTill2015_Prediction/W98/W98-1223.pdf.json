{"title": [{"text": "Modularity in Inductively-Learned Word Pronunciation Systems *", "labels": [], "entities": []}], "abstractContent": [{"text": "Weijt ers@tm, tue.nl Abstract In leading morpho-phonological theories and state-of-the-art text-to-speech systems it is assumed that word pronunciation cannot be learned or performed without in-between analyses at several abstraction levels (e.g., morphological , graphemic, phonemic, syllabic, and stress levels).", "labels": [], "entities": [{"text": "word pronunciation", "start_pos": 133, "end_pos": 151, "type": "TASK", "confidence": 0.765123575925827}]}, {"text": "We challenge this assumption for the case of English word pronunciation.", "labels": [], "entities": [{"text": "English word pronunciation", "start_pos": 45, "end_pos": 71, "type": "TASK", "confidence": 0.604674220085144}]}, {"text": "Using IGTR~B, an inductive-learning decision-tree algorithms, we train and test three word-pronunciation systems in which the number of abstraction levels (implemented as sequenced modules) is reduced from five, via three, to one.", "labels": [], "entities": []}, {"text": "The latter system, classifying letter strings directly as mapping to phonemes with stress markers, yields signitlcemtly better generali~tion accuracies than the two multi-module systems.", "labels": [], "entities": []}, {"text": "Analyses of empirical results indicate that positive utility etfects of sequenc-ing modules are outweighed by cascading errors passed on between modules.", "labels": [], "entities": []}], "introductionContent": [{"text": "Learning word pronunciation can be a hard task when the relation between the spelling of a language and its corresponding pronunciation is many-tomany.", "labels": [], "entities": [{"text": "Learning word pronunciation", "start_pos": 0, "end_pos": 27, "type": "TASK", "confidence": 0.7241662939389547}]}, {"text": "The English writing system and its pronunciation area notoriously complex example, mused by an apparent conflict between analog~/and inconsis~enc~/: Analogy.", "labels": [], "entities": []}, {"text": "When two words or word chunks have a similar spelling, they tend to have a slmil~r pronunciation.", "labels": [], "entities": []}, {"text": "This tendency (which generalises to other language tasks as well) is usually referred to as the analogy principle.", "labels": [], "entities": []}, {"text": "*This research was partially performed by the first and second author at the Department of Computer Science of the Universiteit Manstricht (The Netherlands), and partially in the context of the \"Induction of Linguistic Knowledge\" research programme, partially supported by the Foundation for Language Speech and Logic (TSL), funded by the Netherlands Organization for Scientific Research (NWO).", "labels": [], "entities": [{"text": "Language Speech and Logic (TSL)", "start_pos": 292, "end_pos": 323, "type": "TASK", "confidence": 0.7351982508386884}]}, {"text": "Much of the analogy in English word pronunciation is disrupted by productive and complex word morphology, word stress, and gmphematics.", "labels": [], "entities": [{"text": "English word pronunciation", "start_pos": 23, "end_pos": 49, "type": "TASK", "confidence": 0.6686490972836813}]}, {"text": "Influential pre-Chomskyan ]ingu~tic theories have been pointing at the analogy principle as the underlying principle for language learning), and at induction as the reasoning method for generalising from learned instances of language tasks to new instances through analogy.", "labels": [], "entities": [{"text": "generalising from learned instances of language tasks", "start_pos": 186, "end_pos": 239, "type": "TASK", "confidence": 0.7466939772878375}]}, {"text": "However, methods and resources (e.g., computer technology) were not available then to demonstrate how induction through analogy could be employed to learn and model language tasks.", "labels": [], "entities": []}, {"text": "Partly due to this lack of demonstrating power, Chomsky later stated \"...", "labels": [], "entities": []}, {"text": "I don't see anyway of explaining the resulting final state in terms of any proposed general developmental mecha, i~_m that has been suggested by artificial intelligence, sensorimotot mechanisms, or anything else\" (Choresky, in), p.", "labels": [], "entities": []}, {"text": "Chomsky's argument is based on the assumption that generic learning methods such as induction cannot discover autonomously essential levels of abstraction in language processing tasks.", "labels": [], "entities": []}, {"text": "Appl;ed to morpho-phonology, the argument states that generic learning methods are notable to discover morphology, graphematies, and stress patterns autonomonsly when learning word pronunciation, although this knowledge appears essential.", "labels": [], "entities": []}, {"text": "Phonological and morphological theories, influenced by Chomskyan theory across the board since the publication of spy., have generally adopted the idea of abstraction levels in various guises (e.g., levels, tapes, tiers, grids).", "labels": [], "entities": []}, {"text": "Although there is no general consensus on which levels of abstraction can be discerned in phonology and morphology, there is a rough, global agreement on the fact that words can be represented on different abstraction levels as", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Example of instances generated from the word booking, with dassificstious for all of the subtasks  investigated, viz. M, A, Q, Y, s, and Gs.", "labels": [], "entities": []}]}