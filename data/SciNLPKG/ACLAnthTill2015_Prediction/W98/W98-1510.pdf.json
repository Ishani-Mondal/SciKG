{"title": [{"text": "An Empirical Evaluation on Statistical Parsing of Japanese Sentences using Lexical Association Statistics", "labels": [], "entities": [{"text": "Statistical Parsing of Japanese Sentences", "start_pos": 27, "end_pos": 68, "type": "TASK", "confidence": 0.8947762012481689}]}], "abstractContent": [{"text": "\\Ve are proposing anew framework of statistical language modeling which integrates lexical .association statistics with syntactic preference, while maintaining the modularity of those different statistics types, facilitating both training of the model and analysis of its behavior.", "labels": [], "entities": [{"text": "statistical language modeling", "start_pos": 36, "end_pos": 65, "type": "TASK", "confidence": 0.7020219564437866}]}, {"text": "In this paper, we report the result of an empirical evaluation of our model, where the model is applied to disambiguation of dependency structures of Japanese sentences.", "labels": [], "entities": []}, {"text": "We also discussed the room remained for further improvement based on our error analysis.", "labels": [], "entities": []}], "introductionContent": [{"text": "In the statistical parsing literature) it has alread:y been established that statistics of lexical association have real potential for improvement of disambiguation performance.", "labels": [], "entities": [{"text": "statistical parsing", "start_pos": 7, "end_pos": 26, "type": "TASK", "confidence": 0.7376542091369629}]}, {"text": "The question is how lexical association statistics should be incorporated into the overall statistical parsing framework.", "labels": [], "entities": [{"text": "statistical parsing", "start_pos": 91, "end_pos": 110, "type": "TASK", "confidence": 0.6870488226413727}]}, {"text": "In exploring this issue) we consider the following four basic requirements:", "labels": [], "entities": []}], "datasetContent": [{"text": "Let us f-irst briefly describe some fundamemnl features of Japanese syntax.", "labels": [], "entities": []}, {"text": "A JapaneS(-' SPll\u00b7\u00b7 tcncc can be analyzed as a.", "labels": [], "entities": [{"text": "JapaneS", "start_pos": 2, "end_pos": 9, "type": "DATASET", "confidence": 0.8098121881484985}]}, {"text": "S(~qnence of so--called b\"unsettt.", "labels": [], "entities": []}, {"text": "phrases (BPs, hereafter) as illustratc~d in Fir$ure 1.", "labels": [], "entities": [{"text": "Fir$ure 1", "start_pos": 44, "end_pos": 53, "type": "DATASET", "confidence": 0.9250717014074326}]}, {"text": "A BP is a chunk of words consisting of a content word (noun, verb, a.djcctive, etc.) accmupari-ied by some function word(s) (postposition. auxiliary, etc.).", "labels": [], "entities": []}, {"text": "For example, the BP \"ko:nojo-gr{ (Bl\\) in consists of the noun 11 kon.ojo (she)\" followed by the postposition \"ga (:\\Oil I)\"' which functions as a slot-marker.", "labels": [], "entities": []}, {"text": "The BP 11 taheta\" ), on the other hand, consists of the verb \"tabe (eat)\" follmved by the auxiliar:v 11 f.a (PAST)\" Given a sequence of BPs) one can recognized<'-pendency relations betvveen them as illustrated in.", "labels": [], "entities": [{"text": "PAST", "start_pos": 109, "end_pos": 113, "type": "METRIC", "confidence": 0.8584213852882385}]}, {"text": "nese) if BPi precedes IJP_i, and BPi and BPj are in a. dependency relation) then BPi is always the modifier of BJJ.;, and we sa.v 11 BPi modifies BPj\u00b7:' For exa.mple 1 in 1.", "labels": [], "entities": []}, {"text": "both BP 1 and BPz modify BP3.", "labels": [], "entities": [{"text": "BP3", "start_pos": 25, "end_pos": 28, "type": "DATASET", "confidence": 0.8689176440238953}]}, {"text": "For the preliminary evaluation of our model, we restricted our focus only on the model's performance for structural disambigua.tion excluding morphological disambiguation.", "labels": [], "entities": []}, {"text": "We then developed a modification constraint matrix that describes \\vhich BP category can modify which BP category, based on examples collected from the Kyoto University text corpus.", "labels": [], "entities": [{"text": "Kyoto University text corpus", "start_pos": 152, "end_pos": 180, "type": "DATASET", "confidence": 0.9205807447433472}]}, {"text": "We finally transformed this matrix into a CFG; for instance, the constraint that a BP of category Ci can modify a BP of category CJ can be transformed into context-free rules such as (C; -+ C; C;), (C; --> C; C;), etc., where X denotes a nontermina.l symbol.", "labels": [], "entities": []}, {"text": "For the text data, we used roughly 10,000 sentences from the Kyoto University text corpus for training the syntactic model, and the \\Vhole EDR corpus Mel the R.WC POS-taggecl corpus for training the lexical model.", "labels": [], "entities": [{"text": "Kyoto University text corpus", "start_pos": 61, "end_pos": 89, "type": "DATASET", "confidence": 0.9204885959625244}, {"text": "R.WC POS-taggecl corpus", "start_pos": 158, "end_pos": 181, "type": "DATASET", "confidence": 0.6907130082448324}]}, {"text": "For testing, we used 500 sentences collected from the Kyoto University text corpus with the average sentence length being 8.7 BPs.", "labels": [], "entities": [{"text": "Kyoto University text corpus", "start_pos": 54, "end_pos": 82, "type": "DATASET", "confidence": 0.9483045488595963}]}, {"text": "The data sets used for training and testing are mutually exclusive.", "labels": [], "entities": []}, {"text": "The grammar used by our probabilistic G LR parser was a CFG automatic.ally acquired from the training sentences) consisting of 967 context-free rules containing 50 nontermina.J symbols and 43 terminal symbols (i.e. BP categories).", "labels": [], "entities": []}, {"text": "The~ baseline of the disambiguation performance was assessed byway of a naive strategy which selects the nearest possible modifiee (similarly to the right association principle in English) under the non-crossing constraint.", "labels": [], "entities": []}, {"text": "The performance of this naive strategy was 62.4% in BPhased accuracy: where BP-based accuracy is the ratio of the number of the BPs whose modifiee 84 is correctly identified to the total numbc!r of BPs (excluding the tv\u00b7.ro rightmost BPs for each S('lltence).", "labels": [], "entities": [{"text": "BPhased accuracy", "start_pos": 52, "end_pos": 68, "type": "METRIC", "confidence": 0.6167351007461548}, {"text": "accuracy", "start_pos": 85, "end_pos": 93, "type": "METRIC", "confidence": 0.770819365978241}]}, {"text": "On the other hand, the syntactic model P(R) achieved 72.1% in BP-bascd <tccun\\C)'-9.7 points above the baseline.", "labels": [], "entities": [{"text": "BP-bascd", "start_pos": 62, "end_pos": 70, "type": "METRIC", "confidence": 0.8638418912887573}]}], "tableCaptions": [{"text": " Table 1: The contribution of the lexical model", "labels": [], "entities": []}]}