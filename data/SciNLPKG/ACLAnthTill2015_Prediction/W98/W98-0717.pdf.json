{"title": [{"text": "Incorporating Knowledge in Natural Language Learning: A Case Study", "labels": [], "entities": []}], "abstractContent": [{"text": "Incorporating external information during a learning process is expected to improve its efficiency.", "labels": [], "entities": []}, {"text": "We study a method for incorporating noun-class information , in the context of learning to resolve Prepo-sitional Phrase Attachment (PPA) disambiguation.", "labels": [], "entities": [{"text": "resolve Prepo-sitional Phrase Attachment (PPA) disambiguation", "start_pos": 91, "end_pos": 152, "type": "TASK", "confidence": 0.7394372522830963}]}, {"text": "This is done within a recently introduced architecture , SNOW, a sparse network of threshold gates utilizing the Winnow learning algorithm.", "labels": [], "entities": []}, {"text": "That architecture has already been demonstrated to perform remarkably well on a number of natural language learning tasks.", "labels": [], "entities": []}, {"text": "The knowledge sources used were compiled from the WordNet database for general linguistic purposes , irrespective of the PPA problem, and are being incorporated into the learning algorithm by enriching its feature space.", "labels": [], "entities": [{"text": "WordNet database", "start_pos": 50, "end_pos": 66, "type": "DATASET", "confidence": 0.9613437652587891}]}, {"text": "We study two strategies of using enriched features and the effects of using class information at different granularities, as well as randomly-generated knowledge which serves as a control set.", "labels": [], "entities": []}, {"text": "Incorporating external knowledge sources within SNOW yields a statistically significant performance improvement.", "labels": [], "entities": [{"text": "SNOW", "start_pos": 48, "end_pos": 52, "type": "TASK", "confidence": 0.8097410798072815}]}, {"text": "In addition, we find an interesting relation between the granularity of the knowledge sources used and the magnitude of the improvement.", "labels": [], "entities": []}, {"text": "The encouraging results with noun-class data provide a motivation for carrying out more work on generating better linguistic knowledge sources.", "labels": [], "entities": []}], "introductionContent": [{"text": "A variety of inductive learning techniques have been used in recent years in natural language processing.", "labels": [], "entities": [{"text": "natural language processing", "start_pos": 77, "end_pos": 104, "type": "TASK", "confidence": 0.6644165416558584}]}, {"text": "Given a large training corpus as input and relying on statistical properties of language usage, statistics-based and machine learning algorithms are used to induce a classifier which can be used to resolve a disambiguation task.", "labels": [], "entities": []}, {"text": "Applications of this line of research include ambiguity resolution at different levels of sentence analysis: part-of speech tagging, word-sense disambiguation, word selection in machine translation, context-sensitive spelling correction, word selection in speech recognition, and identification of discourse markers.", "labels": [], "entities": [{"text": "ambiguity resolution", "start_pos": 46, "end_pos": 66, "type": "TASK", "confidence": 0.8063279986381531}, {"text": "sentence analysis", "start_pos": 90, "end_pos": 107, "type": "TASK", "confidence": 0.7437048852443695}, {"text": "part-of speech tagging", "start_pos": 109, "end_pos": 131, "type": "TASK", "confidence": 0.6036222080389658}, {"text": "word-sense disambiguation", "start_pos": 133, "end_pos": 158, "type": "TASK", "confidence": 0.76161789894104}, {"text": "word selection in machine translation", "start_pos": 160, "end_pos": 197, "type": "TASK", "confidence": 0.6701099336147308}, {"text": "context-sensitive spelling correction", "start_pos": 199, "end_pos": 236, "type": "TASK", "confidence": 0.604253739118576}, {"text": "word selection in speech recognition", "start_pos": 238, "end_pos": 274, "type": "TASK", "confidence": 0.7068396806716919}, {"text": "identification of discourse markers", "start_pos": 280, "end_pos": 315, "type": "TASK", "confidence": 0.8715984523296356}]}, {"text": "Many natural language inferences, however, seem to rely heavily on semantic and pragmatic knowledge about the world and the language, that is not explicit in the training data.", "labels": [], "entities": [{"text": "natural language inferences", "start_pos": 5, "end_pos": 32, "type": "TASK", "confidence": 0.6709684729576111}]}, {"text": "The ability to incorporate knowledge from other sources of information, be it knowledge that is acquired across modalities: prepared by a teacher or by an expert, is crucial for going beyond low level natural language inferences.", "labels": [], "entities": []}, {"text": "Within Machine Learning, the use of knowledge is often limited to that of constraining the hypothesis space (either before learning or by probabilistically biasing the search for the hypothesis) or to techniques such as EBL) which rely on explicit domain knowledge that can be used to explain (usually, prove deductively) the observed examples.", "labels": [], "entities": []}, {"text": "The knowledge needed to perform languageunderstanding related tasks, however, does not exist in any explicit form that is amenable to techniques of this sort, and many believe that it will never be available in such explicit forms.", "labels": [], "entities": []}, {"text": "An enormous amount of useful \"knowledge\" maybe available, though.", "labels": [], "entities": []}, {"text": "Pieces of information that maybe found valuable in language-understanding related tasks may include: the root form of a verb; a list of nouns that are in some relation (e.g., are all countries) and can thus appear in similar contexts; a list of verbs that can be followed by a food item; a list of items you can see through, things that are furniture, a list of dangerous things, etc.", "labels": [], "entities": []}, {"text": "This rich collection of information pieces does not form any domain theory to speak of and cannot be acquired from a single source of information.", "labels": [], "entities": []}, {"text": "This knowledge is noisy, incomplete and ambiguous.", "labels": [], "entities": []}, {"text": "While some of it maybe acquired from text, a lot if it may only be acquired from other modalities, as those used by humans.", "labels": [], "entities": []}, {"text": "We believe that integration of such knowledge is essential for NLP to attain high-level natural-language inference.", "labels": [], "entities": []}, {"text": "Contrary to this intuition, experiments in text retrieval and natural language have not shown much improvement when incorporating information of the kind humans seem to use.", "labels": [], "entities": [{"text": "text retrieval", "start_pos": 43, "end_pos": 57, "type": "TASK", "confidence": 0.8029315769672394}]}, {"text": "The lack of significant improvement in the presence of more \"knowledge\" maybe explained by the type of-knowledge used, the way it is incorporated, and the learning algorithms employed.", "labels": [], "entities": []}, {"text": "In the present paper we study an effective way of incorporating incomplete and ambiguous information sources of the abovementioned type within a specific learning approach, and focus on the knowledge sources that can be effective in doing so.", "labels": [], "entities": []}, {"text": "The long-term goal of our work is understanding what types of knowledge sources can be used for performance improvement, and at what granularity level and (2) which computational mechanisms can make the best use of these sources.", "labels": [], "entities": []}, {"text": "In particular, the effect of noun-class information on learning Prepositional Phrase Attachment (PPA, cf. Sec. 2) is studied.", "labels": [], "entities": [{"text": "learning Prepositional Phrase Attachment (PPA", "start_pos": 55, "end_pos": 100, "type": "TASK", "confidence": 0.6563481589158376}]}, {"text": "This problem is studied within SNO IF, a sparse architecture utilizing an on-line learning algorithm based on Winnow.", "labels": [], "entities": [{"text": "SNO IF", "start_pos": 31, "end_pos": 37, "type": "TASK", "confidence": 0.7749062776565552}]}, {"text": "That algorithm has been applied for natural language disambiguation tasks and related problems and perform remarkably well.", "labels": [], "entities": [{"text": "natural language disambiguation tasks", "start_pos": 36, "end_pos": 73, "type": "TASK", "confidence": 0.7140549197793007}]}, {"text": "The noun-class data was derived from the WordNet database which was compiled for general linguistic purposes, irrespective of the PPA problem.", "labels": [], "entities": [{"text": "WordNet database", "start_pos": 41, "end_pos": 57, "type": "DATASET", "confidence": 0.9723174571990967}]}, {"text": "We derived the classes at different granularities.", "labels": [], "entities": []}, {"text": "At the highest level, nouns are classified according to their synsets.", "labels": [], "entities": []}, {"text": "The lower levels are obtained by successively using the hypernym relation defined in WordNet.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 85, "end_pos": 92, "type": "DATASET", "confidence": 0.9774032235145569}]}, {"text": "In addition, we use the Corelex database.", "labels": [], "entities": [{"text": "Corelex database", "start_pos": 24, "end_pos": 40, "type": "DATASET", "confidence": 0.9516652226448059}]}, {"text": "Consisting of 126 coarse-grained semantic types covering around 40,000 nouns, Corelex defines a large number of systematic polysemous classes that are derived from an analysis of sense distributions in WordNet.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 202, "end_pos": 209, "type": "DATASET", "confidence": 0.9422244429588318}]}, {"text": "The results indicate that a statistically significant improvement in performance is achieved when the noun-class information is incorporated into the data.", "labels": [], "entities": []}, {"text": "The absolute performance achieved on the task is slightly better than other systems, although it is still significantly worse than the performance of a human subject tested on this task.", "labels": [], "entities": []}, {"text": "The granularity of the class information appears to be crucial for improving performance.", "labels": [], "entities": []}, {"text": "The addition of too many overlapping classes does not help performance, but with fewer classes -the improvement is significant.", "labels": [], "entities": []}, {"text": "In addition to semantic information, using classes carries with it some structural information.", "labels": [], "entities": []}, {"text": "A class feature maybe viewed as a disjunction of other features, thereby increasing the expressivity of the hypothesis used for prediction.", "labels": [], "entities": []}, {"text": "In order to control for the possibility that the performance improvements seen are due mainly to the structural information, we generated random classes.", "labels": [], "entities": []}, {"text": "Some of these had 122 exactly the same distribution over the original features as do the semantic classes.", "labels": [], "entities": []}, {"text": "Surprisingly, we find that a non-negligible part of the improvement is due merely to the structural information, although most of it can be attributed to the semantic content of the classes.", "labels": [], "entities": []}, {"text": "Along with promoting work on the incorporation of problem-independent incomplete knowledge into the learning process, the encouraging results with incorporating noun-class data provide a motivation for carrying out more work on generating better linguistic knowledge sources.", "labels": [], "entities": []}, {"text": "The paper is organized as follows: we start by presenting the task, PPA and the SNOW architecture and algorithm.", "labels": [], "entities": []}, {"text": "In section 4 we describe the classes and present the main experiments with the semantic and random classes.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section we present results of incorporating various semantic data and their combinations.", "labels": [], "entities": []}, {"text": "Since the classes were not compiled specifically for the PPA problem, some of the class information maybe irrelevant or even slightly misleading.", "labels": [], "entities": [{"text": "PPA problem", "start_pos": 57, "end_pos": 68, "type": "TASK", "confidence": 0.8658868372440338}]}, {"text": "The results provide an assesment of the relative relevance of each knowledge source.", "labels": [], "entities": []}, {"text": "When a noun belongs to a class, one may replace the explicit noun feature by its classes.", "labels": [], "entities": []}, {"text": "Using the classes in addition to the original nounseems, however, a better strategy.", "labels": [], "entities": []}, {"text": "Consider, for example, the feature <prep,indirect-object=n2>.", "labels": [], "entities": []}, {"text": "Suppose the noun n2 belongs to two classes cl and c2.", "labels": [], "entities": []}, {"text": "The class information will be incorporated by creating two additional features: <prep,indirect-object=c 1 > and <prep,indirect-object=c2>, thereby enhancing the feature set without losing the original information.", "labels": [], "entities": []}, {"text": "As mentioned above, giving up the original feature yielded degraded results.", "labels": [], "entities": []}, {"text": "The results of adding features from a single knowledge source, presented in, show that FF have yielded small improvements over the lena set, within the noise-level; the WN1 synset information caused a slight degradation, and the CL and other WN knowledge resulted in a significant improvement over the lemma case.", "labels": [], "entities": [{"text": "FF", "start_pos": 87, "end_pos": 89, "type": "METRIC", "confidence": 0.861351728439331}]}, {"text": "An important property of the CL class information is that each CL class defines a distinct set of nouns, as each noun belongs to one CL class.", "labels": [], "entities": []}, {"text": "The synset (WN1) distribution differs greatly from that of the CL classes; each noun may belong to a few synsets -allowing more potential conflicts.", "labels": [], "entities": []}, {"text": "That property of the synset distribution gives rise to the performance degradation.", "labels": [], "entities": []}, {"text": "Another important difference between CL and WN1 classes is their granularity.", "labels": [], "entities": []}, {"text": "There are around 60000 synsets, whereas there are only 126 CL classes.", "labels": [], "entities": []}, {"text": "The finer synset granularity means that a synset carries less information; thus, the CL classes add richer disjunctions than WN synsets do.", "labels": [], "entities": []}, {"text": "The results of CL, WNS, WN10, and WN15 improve over the FF set, these results are within the noise level (cf. Sec. 2).", "labels": [], "entities": []}, {"text": "The FF set covers relatively few nouns, hence the improvement it yields is quite small.", "labels": [], "entities": [{"text": "FF set", "start_pos": 4, "end_pos": 10, "type": "DATASET", "confidence": 0.7792424559593201}]}, {"text": "The WordNet and CL vocabularies do not include those beginning with a capital as well as numbers, therefore the WN and CL knowledge maybe augmented with the FF information without loss of consistency.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 4, "end_pos": 11, "type": "DATASET", "confidence": 0.941867470741272}]}, {"text": "Nevertheless, since each number-word (e.g., \"one\", \"two\", etc.) belongs to a different synset, augmenting WNI with a numeric class is not expected to be very effective because the words \"one\", \"two\", and \"1\" will all  The other columns present the prediction accuracy when adding each of our knowledge sources separately.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 259, "end_pos": 267, "type": "METRIC", "confidence": 0.9404311180114746}]}, {"text": "belong to different classes: synset(one), synset(two), and FF(is-number), respectively.", "labels": [], "entities": [{"text": "FF", "start_pos": 59, "end_pos": 61, "type": "METRIC", "confidence": 0.9970447421073914}]}, {"text": "As a measure of numeric class assignment, we have examined the words: \"one\", \"two\", \"three\", \"ten\", \"hundred\" and \"million\"; only CL, WN3 and subsequent WN knowledge sources assign the same hypernym to these words, therefore we have augmented these sources.", "labels": [], "entities": [{"text": "numeric class assignment", "start_pos": 16, "end_pos": 40, "type": "TASK", "confidence": 0.6583176453908285}]}, {"text": "The results are presented in, comparison with shows that augmenting with FF knowledge yielded a slight improvement only for the CL set.", "labels": [], "entities": [{"text": "FF", "start_pos": 73, "end_pos": 75, "type": "METRIC", "confidence": 0.9312532544136047}]}, {"text": "There maybe two explanations for that: (i) the CL classes are more appropriate for the PPA problem than the WN hypernyms, therefore the FF information fit with less conflicts.", "labels": [], "entities": []}, {"text": "(ii) The coverage of CL nouns is about 70% that of WN for the test data (cf.), therefore there axe more examples in which the CL and FF classes do not conflict.", "labels": [], "entities": []}, {"text": "This issue requires further study.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Sizes and coverage of the noun vocabulary and classes in the various noun-class sources.  leftmost column shows the noun vocabulary size and coverage for the train and test data.", "labels": [], "entities": []}, {"text": " Table 2: Learning results for a single knowledge source: Baseline refers to simply predicting according  to the most common attachment in the training corpus, namely (v). :temma is our basic feature set, as in Sec. 2", "labels": [], "entities": []}, {"text": " Table 3: Learning results for combinations of FF and other sources: The four leftmost columns  indicate the classes added to our basic feature set, 1emma.", "labels": [], "entities": []}]}