{"title": [{"text": "Meta-discourse markers and problem-structuring in scientific articles", "labels": [], "entities": [{"text": "Meta-discourse markers", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.8090024292469025}]}], "abstractContent": [{"text": "Knowledge about the argumentative structure of scientific articles can, amongst other things, be used to improve automatic abstracts.", "labels": [], "entities": []}, {"text": "We argue that the argumentative structure of scientific discourse can be automatically detected because reasordng about problems, research tasks and solutions follows predictable patterns.", "labels": [], "entities": []}, {"text": "Certain phrases explicitly mark the rhetorical status (communicative function) of sentences with respect to the global argumentative goal.", "labels": [], "entities": []}, {"text": "Examples for such meta-diacaurse markers are \"in this paper, we have presented...\" or \"however, their method fails to\".", "labels": [], "entities": []}, {"text": "We report on work in progress about recognizing such meta-comments automatically in research articles from two disciplines: computational linguistics and medicine (cardiology).", "labels": [], "entities": []}, {"text": "1 Motivation We are interested in a formal description of the document structure of scientific articles from different disciplines.", "labels": [], "entities": []}, {"text": "Such a description could be of practical use for many applications in document management; our specific motivation for detecting document structure is quality improvement in automatic abstracting.", "labels": [], "entities": [{"text": "document management", "start_pos": 70, "end_pos": 89, "type": "TASK", "confidence": 0.7848597466945648}]}, {"text": "Researchem in the field of automatic abstracting largely agree that it is currently not technically feasible to create automatic abstracts based on full text understanding (Sparck Jones 1994).", "labels": [], "entities": []}, {"text": "As a result, many researchers have turned to sentence extraction (Kupiec, Pedersen, & Chen 1995; Brandow, Mitze, & Rau 1995; Hovy & Lin 1997).", "labels": [], "entities": [{"text": "sentence extraction", "start_pos": 45, "end_pos": 64, "type": "TASK", "confidence": 0.8471654653549194}]}, {"text": "Sentence extraction, which does not involve any deep analysis, has the huge advantage of being robust with respect to individual writing style, discipline and text type (genre).", "labels": [], "entities": [{"text": "Sentence extraction", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.9513960778713226}]}, {"text": "Instead of producing abstract, this results produces only extracts: document surrogates consisting of a number of sentences selected verbatim from the original text.", "labels": [], "entities": []}, {"text": "We consider a concrete document retrieval (DR) scenario in which a researcher wants to select one or more scientific articles from a large scientific database (or even from the Internet) for further inspection.", "labels": [], "entities": [{"text": "concrete document retrieval (DR)", "start_pos": 14, "end_pos": 46, "type": "TASK", "confidence": 0.8284382025400797}]}, {"text": "The main task for the searcher is relevance decision for each paper: she needs to decide whether or not to spend more time on a paper (read or skim-read it), depending on how useful it presumably is to her current information needs.", "labels": [], "entities": []}, {"text": "Traditional sentence extracts can be used as rough-and-ready relevance indicators for this task, but they are not doing a great job at representing the contents of the original document: searchers often get the wrong idea about what the text is about.", "labels": [], "entities": []}, {"text": "Much of this has to do with the fact that extracts are typically incoherent texts, consisting of potentially unrelated sentences which have been taken out of their context.", "labels": [], "entities": []}, {"text": "Crucially, extracts have no handle at revealing the text's logical and semantic organisation.", "labels": [], "entities": []}, {"text": "More sophisticated, user-tailored abstracts could help the searcher make a fast, informed relevance decision by taking factors like the searcher's expertise and current information need into account.", "labels": [], "entities": []}, {"text": "If the searcher is dealing with research she knows well, her information needs might be quite concrete: during the process of writing her own paper she might want to find research which supports her own claims, find out if there are contradictory results to hers in the literature, or compare her results to those of researchers using a similar methodology.", "labels": [], "entities": []}, {"text": "A different information need arises when she wants to gain an overview of anew research area-as an only \"partially informed user\" in this field (Kircz 1991) she will need to find out about specific research goals, the names of the researchers who have contributed the main research ideas in a given time period, along with information of methodology and results in this research field.", "labels": [], "entities": []}, {"text": "There are new functions these abstracts could fulfil.", "labels": [], "entities": []}, {"text": "In order to make an informed relevance decision, the searcher needs to judge differences and similarities between papers, e.g. how a given paper relates to similar papers with respect to research goals or methodology, so that she can place the research described in a given paper in the larger picture of the field, a function we call navigation between research articles.", "labels": [], "entities": []}, {"text": "A similar operation is navigation within a paper, which supports searchers in non-linear reading and allows them to find relevant information faster, e.g. numerical results.", "labels": [], "entities": [{"text": "navigation within a paper", "start_pos": 23, "end_pos": 48, "type": "TASK", "confidence": 0.8443911969661713}]}, {"text": "We believe that a document surrogate that aims at supporting such functions should characterize research articles in terms of the problems, research tasks and 43 solutions/methodology presented in the specific paper, but it should also represent other researchers\" problems, research tasks and solutions mentioned in the paper.", "labels": [], "entities": []}, {"text": "Our long-term goal is to automatically reconstruct this problem-solution structure from unrestricted text for the searcher in the form of a problem-structured abstract.", "labels": [], "entities": []}, {"text": "But how can we find problems, research questions, research tasks and solutions in text without fully understanding the text?", "labels": [], "entities": []}, {"text": "We take sentence extraction as a starting point due to its inherent robustness.", "labels": [], "entities": [{"text": "sentence extraction", "start_pos": 8, "end_pos": 27, "type": "TASK", "confidence": 0.7845215797424316}]}, {"text": "Using additional information about each sentence, viz.", "labels": [], "entities": []}, {"text": "their rhetorical status with respect to the entire paper, we are in a better position to perform shallow, but guided information extraction, in order to find the information units we are interested in.", "labels": [], "entities": [{"text": "information extraction", "start_pos": 117, "end_pos": 139, "type": "TASK", "confidence": 0.7390808612108231}]}, {"text": "In the next section we introduce the level of document structure we are talking about, and the kind of meta-comments we employ in discovering it.", "labels": [], "entities": []}, {"text": "In the rest of the paper, we report on ongoing work on automatically filtering meta-comments from annotated and unannotated text.", "labels": [], "entities": []}, {"text": "Finding recta-comments in text is an attractive task because it would allow for the automatic adaptation of sytem s using such phrases to new domains.", "labels": [], "entities": []}, {"text": "2 Discourse structure and argumenta-tion in scientific articles Discourse linguistic theory suggests that texts serving a common purpose among a community of users eventually take on a predictable structure of presentation (Kintsch & van Dijk 1978)-and scientific articles certainly serve a well-defined communicative purpose: they \"present, retell and refer to the results of specific research\" (Salager-Meyer 1992).", "labels": [], "entities": []}, {"text": "Particularly in the life and experimental sciences, a rigid building plan for research articles has evolved over the years, where rhetorical divisions tend to be very clearly marked in section headers.", "labels": [], "entities": []}, {"text": "Prototypical rhetorical divisions include Introduction, Purpose, Experimental Design, Re-suits, Discussion, Conclusions.", "labels": [], "entities": []}, {"text": "One of the reasons for this rigidly-defined structure seems to be that the scientific community in these fields has more or less agreed on how to do research: methodologies and evaluation methods are long-lived research entities that do not change often.", "labels": [], "entities": []}, {"text": "One of the corpora we are using is a good example of such texts.", "labels": [], "entities": []}, {"text": "It consists of 129 articles in cardiology, taken from the American Heart Journa/, which have a fixed structure with respect to rhetorical divisions and section headers.", "labels": [], "entities": [{"text": "American Heart Journa", "start_pos": 58, "end_pos": 79, "type": "DATASET", "confidence": 0.9800861279169718}]}, {"text": "The other corpus, in contrast, consisting of 123 (mostly conference) articles in computational linguistics (CL), displays an heterogeneous mixture of methodologies and traditions of presentation one would expect in an interdisciplinary field.", "labels": [], "entities": [{"text": "computational linguistics (CL)", "start_pos": 81, "end_pos": 111, "type": "TASK", "confidence": 0.6982892036437989}]}, {"text": "Most of the articles cover more than one single discipline, but as a rough estimate one can say that about 45% of the articles in the collection are predominantly technical in style, describing implementations (i.e. engineering solutions); about 25% report on research in theoretical linguistics , with an argumentative tenet; the remaining 30% are empirical (psycholinguistic or psychological experiments or corpus studies).", "labels": [], "entities": []}, {"text": "Even though most of the articles have an introduction and conclusions (sometimes occurring under headers with different names), and almost all of them cite previous work, the presentation of the problem and the methodology/solution are idiosyn-cratic and depend on individual writing style.", "labels": [], "entities": []}, {"text": "Very few of the headers in the computational linguistics articles correspond to prototypical rhetorical divisions; the rest contain content specific terminology (cf. Figure 1 which compares relative frequencies of headers for the two corpora).", "labels": [], "entities": []}], "introductionContent": [], "datasetContent": [{"text": "We evaluate the quality of these automatically generated meta-comment lists by comparing them to a manually created meta-comment list used by a summarisation system, cf. (Teufel & Moens To Appear).", "labels": [], "entities": []}, {"text": "The performance of the system -with the two different metacomment lists -is measured by precision and recall values of co-selection with the target extracts defined by human annotators mentioned earlier.", "labels": [], "entities": [{"text": "precision", "start_pos": 88, "end_pos": 97, "type": "METRIC", "confidence": 0.9995222091674805}, {"text": "recall", "start_pos": 102, "end_pos": 108, "type": "METRIC", "confidence": 0.9987819790840149}]}, {"text": "The summarisation process consists of two consecutive steps, sentence extraction and rhetorical classification, and uses other heuristics like location and term frequency.", "labels": [], "entities": [{"text": "summarisation", "start_pos": 4, "end_pos": 17, "type": "TASK", "confidence": 0.9800928831100464}, {"text": "sentence extraction", "start_pos": 61, "end_pos": 80, "type": "TASK", "confidence": 0.7700810730457306}, {"text": "rhetorical classification", "start_pos": 85, "end_pos": 110, "type": "TASK", "confidence": 0.9224932193756104}]}, {"text": "The summarisation system requires a list of metacomments of arbitrary length, containing a quality score for each phrase which estimates how predictive these phrases are in pointing to extract-worthy sentences, and the most likely rhetorical label that sentences with this meta-comment will receive.", "labels": [], "entities": []}, {"text": "paper , this paper presents a in order to in this paper , we will in this paper we have unlike this paper is to in this paper , we describe paper is paper we this paper has presented , we propose a method in p~sage ( , we argue that argue that method for we show that the show how property and the number the advantages of the wall street journal the importance of however , we be used to: Extracts from automatic list of metacomments We automatically built the meta-comment list in.", "labels": [], "entities": []}, {"text": "We started from all n-grams compiled from the target sentences and took the following heuristics into account: Firstly, choose phrases with a high ratio of target frequency to corpus frequency, because these are indicative phrases.", "labels": [], "entities": []}, {"text": "Set the quality value accordingly.", "labels": [], "entities": []}, {"text": "Secondly, exclude phrases with a low overall frequency, or decrease their quality score, because including/overestimating them might construct a model that is over-fitted to the data.", "labels": [], "entities": [{"text": "quality score", "start_pos": 74, "end_pos": 87, "type": "METRIC", "confidence": 0.9270936250686646}]}, {"text": "Thirdly, associate each phrase with its most likely rhetorical move, by taking the ratio between frequency in each rhetorical class and the frequency of the rhetorical label itself into account.", "labels": [], "entities": []}, {"text": "If below a certain threshold, don't associate any move at all (e.g. \"paper ,\" in).", "labels": [], "entities": []}, {"text": "The manual meta-comment list, in contrast, was compiled in an extremely labour intensive manner and refined over the months.", "labels": [], "entities": []}, {"text": "It consists of 1791 metacomments (some of which are much longer than the maximum of 6 words that the automatic phrases consisted of), along with their most plausible rhetorical moves and quality scores.", "labels": [], "entities": []}], "tableCaptions": []}