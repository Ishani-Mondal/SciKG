{"title": [], "abstractContent": [{"text": "It is traditionally assumed that various sources of linguistic knowledge and their interaction should be formalised in order to be able to convert words into their phone-mic representations with reasonable accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 206, "end_pos": 214, "type": "METRIC", "confidence": 0.9839997887611389}]}, {"text": "We show that using supervised learning techniques, based on a corpus of transcribed words, the same and even better performance can be achieved, without explicit modeling of linguistic knowledge.", "labels": [], "entities": []}, {"text": "In this paper we present two instances of this approach.", "labels": [], "entities": []}, {"text": "A first model implements a variant of instance-based learning, in which a weighed similarity metric and a database of prototypical exemplars are used to predict new mappings.", "labels": [], "entities": []}, {"text": "In the second model, grapheme-to-phoneme mappings are looked up in a compressed text-to-speech lexicon (table lookup) enriched with default map-pings.", "labels": [], "entities": []}, {"text": "We compare performance and accuracy of these approaches to a connectionist (backpropagation) approach and to the linguistic knowledge-based approach.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 27, "end_pos": 35, "type": "METRIC", "confidence": 0.9992358684539795}]}], "introductionContent": [{"text": "Grapheme-to-phoneme conversion is a central task in any text-to-speech (reading aloud) system.", "labels": [], "entities": [{"text": "Grapheme-to-phoneme conversion", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.7816444337368011}]}, {"text": "Given an alphabet of spelling symbols (graphemes) and an alphabet of phonetic symbols, a mapping should be achieved transliterating strings of graphemes into strings of phonetic symbols.", "labels": [], "entities": []}, {"text": "It is well known that this mapping is difficult because in general, not all graphemes are realised in the phonetic transcription, and the same grapheme may correspond to different phonetic symbols, depending on context.", "labels": [], "entities": []}, {"text": "It is traditionally assumed that various sources of linguistic knowledge and their interaction should be formalised in order to be able to convert words into their phonemic representations with reasonable accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 205, "end_pos": 213, "type": "METRIC", "confidence": 0.9870851635932922}]}, {"text": "Although different researchers propose different knowledge structures, consensus seems to be that at least morphological and phonotactic knowledge should be incorporated in order to be able to find morphological and syllable structure.", "labels": [], "entities": []}, {"text": "These structures are deemed necessary to define the proper domains for phonological and phonetic rules.", "labels": [], "entities": []}, {"text": "As atypical architecture for grapheme-to-phoneme conversion in Dutch, consider the modules in shown in.", "labels": [], "entities": [{"text": "grapheme-to-phoneme conversion", "start_pos": 29, "end_pos": 59, "type": "TASK", "confidence": 0.7501843571662903}]}, {"text": "It contains most of the traditional datastructures and processing components proposed by computational linguists.", "labels": [], "entities": []}, {"text": "A problem with this approach is that the knowledge needed is highly language-dependent and requires a significant amount of linguistic engineering.", "labels": [], "entities": []}, {"text": "We argue that using data-oriented learning techniques on a corpus of transcribed words (information.", "labels": [], "entities": []}, {"text": "which is readily available in many machine-readable dictionaries), the same and even better performance can be achieved, without explicit modeling of linguistic knowledge.", "labels": [], "entities": []}, {"text": "The advantages of such an approach are that the technique is reusable for different sets of data (e.g. different languages or sublanguages), and that it is automatic (no explicit linguistic engineering is needed to handcraft the rules and knowledge structures necessary for implementing the target mapping).", "labels": [], "entities": []}, {"text": "In this paper we present two instances of this approach in the domain of Grapheme-to-Phoneme conversion.", "labels": [], "entities": [{"text": "Grapheme-to-Phoneme conversion", "start_pos": 73, "end_pos": 103, "type": "TASK", "confidence": 0.7881231904029846}]}, {"text": "A first model implements a variant of instance-based learning, in which a similarity metric (weighed by using a metric based on information entropy) and a database of prototypieal exemplars are used to predict new mappings.", "labels": [], "entities": []}, {"text": "Ina second model, grapheme-to-phoneme mappings are looked up in a compressed text-to-speech lexicon (table lookup) enriched with default mappings.", "labels": [], "entities": []}, {"text": "The most surprising result of our research is that the simplest method (based on tables and defaults) yields the best generalisation results, suggesting that previous knowledgebased approaches to the problem were overkill.", "labels": [], "entities": []}, {"text": "For the case of Dutch, we make a comparison of performance and accuracy of these approaches to a connectionist (backpropagation) approach and to a stateof-the-art linguistic knowledge-based approach.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 63, "end_pos": 71, "type": "METRIC", "confidence": 0.9991989731788635}]}, {"text": "To prove reusability of the method, we show how our approach can also be used for automatically generating French and English phonemisation modules.", "labels": [], "entities": [{"text": "generating French and English phonemisation modules", "start_pos": 96, "end_pos": 147, "type": "TASK", "confidence": 0.5741559962431589}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Example of the application of the 1-1-~ en- coding on the word < boek > (book). Underscores  represent spaces, a hyphen represents a phonetic null.", "labels": [], "entities": []}]}