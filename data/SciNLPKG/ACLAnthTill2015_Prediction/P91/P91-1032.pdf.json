{"title": [{"text": "FINITE-STATE APPROXIMATION OF PHRASE STRUCTURE GRAMMARS", "labels": [], "entities": [{"text": "FINITE-STATE APPROXIMATION", "start_pos": 0, "end_pos": 26, "type": "TASK", "confidence": 0.5771059840917587}, {"text": "PHRASE STRUCTURE GRAMMARS", "start_pos": 30, "end_pos": 55, "type": "METRIC", "confidence": 0.7741400400797526}]}], "abstractContent": [{"text": "Phrase-structure grammars are an effective representation for important syntactic and semantic aspects of natural languages, but are computa-tionally too demanding for use as language models in real-time speech recognition.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 204, "end_pos": 222, "type": "TASK", "confidence": 0.7213083356618881}]}, {"text": "An algorithm is described that computes finite-state approximations for context-free grammars and equivalent augmented phrase-structure grammar formalisms.", "labels": [], "entities": []}, {"text": "The approximation is exact for certain context-free grammars generating regular languages, including all left-linear and right-linear context-free grammars.", "labels": [], "entities": []}, {"text": "The algorithm has been used to construct finite-state language models for limited-domain speech recognition tasks.", "labels": [], "entities": [{"text": "limited-domain speech recognition tasks", "start_pos": 74, "end_pos": 113, "type": "TASK", "confidence": 0.6981462612748146}]}, {"text": "1 Motivation Grammars for spoken language systems are subject to the conflicting requirements of language modeling for recognition and of language analysis for sentence interpretation.", "labels": [], "entities": [{"text": "sentence interpretation", "start_pos": 160, "end_pos": 183, "type": "TASK", "confidence": 0.7160619646310806}]}, {"text": "Current recognition algorithms can most directly use finite-state ac-ceptor (FSA) language models.", "labels": [], "entities": []}, {"text": "However, these models are inadequate for language interpretation , since they cannot express the relevant syntactic and semantic regularities.", "labels": [], "entities": [{"text": "language interpretation", "start_pos": 41, "end_pos": 64, "type": "TASK", "confidence": 0.7652771770954132}]}, {"text": "Augmented phrase structure grammar (APSG) formalisms, such as unification-based grammars (Shieber, 1985a), can express many of those regularities, but they are computationally less suitable for language mod-eling, because of the inherent cost of computing state transitions in APSG parsers.", "labels": [], "entities": [{"text": "Augmented phrase structure grammar (APSG)", "start_pos": 0, "end_pos": 41, "type": "TASK", "confidence": 0.7575130845819201}]}, {"text": "The above problems might be circumvented by using separate grammars for language modeling and language interpretation.", "labels": [], "entities": [{"text": "language modeling", "start_pos": 72, "end_pos": 89, "type": "TASK", "confidence": 0.7089851051568985}, {"text": "language interpretation", "start_pos": 94, "end_pos": 117, "type": "TASK", "confidence": 0.7528199553489685}]}, {"text": "Ideally, the recognition grammar should not reject sentences acceptable by the interpretation grammar and it should contain as much as reasonable of the constraints built into the interpretation grammar.", "labels": [], "entities": []}, {"text": "However, if the two grammars are built independently , those goals are difficult to maintain.", "labels": [], "entities": []}, {"text": "For this reason, we have developed a method for constructing automatically a finite-state approximation for an APSG.", "labels": [], "entities": []}, {"text": "Since the approximation serves as language model fora speech-recognition front-end to the real parser, we require it to be sound in the sense that the it accepts all strings in the language defined by the APSG.", "labels": [], "entities": [{"text": "APSG", "start_pos": 205, "end_pos": 209, "type": "DATASET", "confidence": 0.9245923161506653}]}, {"text": "Without qualification , the term \"approximation\" will always mean here \"sound approximation.\"", "labels": [], "entities": []}, {"text": "If no further constraints were placed on the closeness of the approximation, the trivial algorithm that assigns to any APSG over alphabet E the regular language E* would do, but of course this language model is useless.", "labels": [], "entities": []}, {"text": "One possible criterion for \"goodness\" of approximation arises from the observation that many interesting phrase-structure grammars have substantial parts that accept regular languages.", "labels": [], "entities": []}, {"text": "That does not mean that the grammar rules are in the standard forms for defining regular languages (left-linear or right-linear), because syntactic and semantic considerations often require that strings in a regular set be assigned structural descriptions not definable by left-or right-linear rules.", "labels": [], "entities": []}, {"text": "A useful criterion is thus that if a grammar generates a regular language, the approximation algorithm yields an acceptor for that regular language.", "labels": [], "entities": []}, {"text": "In other words, one would like the algorithm to be exact for APSGs yielding regular languages.", "labels": [], "entities": []}, {"text": "1 While we have not proved that in general our method satisfies the above exactness criterion, we show in Section 3.2 that the method is exact for left-linear and right-linear grammars, two important classes of context-free grammars generating regular languages .", "labels": [], "entities": []}], "introductionContent": [], "datasetContent": [], "tableCaptions": []}