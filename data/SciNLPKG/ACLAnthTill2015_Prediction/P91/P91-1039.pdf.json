{"title": [{"text": "FACTORIZATION OF LANGUAGE CONSTRAINTS IN SPEECH RECOGNITION", "labels": [], "entities": [{"text": "FACTORIZATION", "start_pos": 0, "end_pos": 13, "type": "TASK", "confidence": 0.6287395358085632}, {"text": "SPEECH RECOGNITION", "start_pos": 41, "end_pos": 59, "type": "METRIC", "confidence": 0.8106639385223389}]}], "abstractContent": [{"text": "Integration of language constraints into a large vocabulary speech recognition system often leads to prohibitive complexity.", "labels": [], "entities": []}, {"text": "We propose to factor the constraints into two components.", "labels": [], "entities": []}, {"text": "The first is characterized by a covering grammar which is small and easily integrated into existing speech recognizers.", "labels": [], "entities": []}, {"text": "The recognized string is then decoded by means of an efficient language post-processor in which the full set of constraints is imposed to correct possible errors introduced by the speech recognizer.", "labels": [], "entities": []}], "introductionContent": [{"text": "In the past, speech recognition has mostly been applied to small domain tasks in which language constraints can be characterized by regular grammars.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 13, "end_pos": 31, "type": "TASK", "confidence": 0.8232287168502808}]}, {"text": "All the knowledge sources required to perform speech recognition and understanding, including acoustic, phonetic, lexical, syntactic and semantic levels of knowledge, are often encoded in an integrated manner using a finite state network (FSN) representation.", "labels": [], "entities": [{"text": "speech recognition and understanding", "start_pos": 46, "end_pos": 82, "type": "TASK", "confidence": 0.7198841571807861}]}, {"text": "Speech recognition is then performed by finding the most likely path through the FSN so that the acoustic distance between the input utterance and the recognized string decoded from the most likely path is minimized.", "labels": [], "entities": [{"text": "Speech recognition", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.7892358303070068}, {"text": "FSN", "start_pos": 81, "end_pos": 84, "type": "DATASET", "confidence": 0.6038104891777039}]}, {"text": "Such a procedure is also known as maximum likelihood decoding, and such systems are referred to as integrated systems.", "labels": [], "entities": []}, {"text": "Integrated systems can generally achieve high accuracy mainly due to the fact that the decisions are delayed until enough information, derived from the knowledge sources, is available to the decoder.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 46, "end_pos": 54, "type": "METRIC", "confidence": 0.9976077079772949}]}, {"text": "For example, in an integrated system there is no explicit segmentation into phonetic units or words during the decoding process.", "labels": [], "entities": []}, {"text": "All the segmentation hypotheses consistent with the introduced constraints are carried on until the final decision is made in order to maximize a global function.", "labels": [], "entities": []}, {"text": "An example of an integrated system was HARPY which integrated multiple levels of knowledge into a single FSN.", "labels": [], "entities": [{"text": "FSN", "start_pos": 105, "end_pos": 108, "type": "DATASET", "confidence": 0.7034048438072205}]}, {"text": "This produced relatively high performance for the time, but at the cost of multiplying out constraints in a manner that expanded the grammar beyond reasonable bounds for even moderately complex domains, and may not scale up to more complex tasks.", "labels": [], "entities": []}, {"text": "Other examples of integrated systems maybe found in and.", "labels": [], "entities": []}, {"text": "On the other hand modular systems clearly separate the knowledge sources.", "labels": [], "entities": []}, {"text": "Different from integrated systems, a modular system usually make an explicit use of the constraints at each level of knowledge for making hard decisions.", "labels": [], "entities": []}, {"text": "For instance, in modular systems there is an explicit segmentation into phones during an early stage of the decoding, generally followed by lexical access, and by syntactic/semantic parsing.", "labels": [], "entities": [{"text": "syntactic/semantic parsing", "start_pos": 163, "end_pos": 189, "type": "TASK", "confidence": 0.6299777254462242}]}, {"text": "While a modular system, like for instance HWIM or HEARSAY-II maybe the only solution for extremely large tasks when the size of the vocabulary is on the order of 10,000 words or more, it generally achieves lower performance than an integrated system in a restricted domain task.", "labels": [], "entities": []}, {"text": "The degradation in performance is mainly due to the way errors propagate through the system.", "labels": [], "entities": []}, {"text": "It is widely agreed that it is dangerous to make along series of hard decisions.", "labels": [], "entities": []}, {"text": "The system cannot recover from an error at any point along the chain.", "labels": [], "entities": []}, {"text": "One would want to avoid this chainarchitecture and look for an architecture which would enable modules to compensate for each other.", "labels": [], "entities": []}, {"text": "Integrated approaches have this compensation capability, but at the cost of multiplying the size of the grammar in such away that the computation becomes prohibitive for the recognizer.", "labels": [], "entities": []}, {"text": "A solution to the problem is to factorize the constraints so that the size of the grammar, used for maximum likelihood decoding, is kept within reasonable bounds without a loss in the performance.", "labels": [], "entities": []}, {"text": "In this paper we propose an approach in which speech recognition is still performed in an integrated fashion using a covering grammar with a smaller FSN representation.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 46, "end_pos": 64, "type": "TASK", "confidence": 0.8356972932815552}, {"text": "FSN", "start_pos": 149, "end_pos": 152, "type": "METRIC", "confidence": 0.6758449673652649}]}, {"text": "The decoded string of words is used as input to a second module in which the complete set of task constraints is imposed to correct possible errors introduced by the speech recognition module.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 166, "end_pos": 184, "type": "TASK", "confidence": 0.6985272318124771}]}], "datasetContent": [{"text": "The semantic postproeessor was tested using the speech recognizer arranged in different accuracy conditions.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 88, "end_pos": 96, "type": "METRIC", "confidence": 0.9960416555404663}]}, {"text": "Different word accuracies were simulated by using various phonetic unit models and the two covering grammars (i.e. NG and WP).", "labels": [], "entities": []}, {"text": "The experiments were performed on a set of 300 test sentences known as the February 89 test set (Pallett.", "labels": [], "entities": [{"text": "February 89 test set (Pallett.", "start_pos": 75, "end_pos": 105, "type": "DATASET", "confidence": 0.7629061681883675}]}, {"text": "1989) The word accuracy, defined as 1-insertions deletions'e substitutions xl00 (3) number of words uttered was computed using a standard program that provides an alignment of the recognized sentence with a reference string of words.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 15, "end_pos": 23, "type": "METRIC", "confidence": 0.9486701488494873}, {"text": "1-insertions deletions'e substitutions xl00 (3) number", "start_pos": 36, "end_pos": 90, "type": "METRIC", "confidence": 0.767932116985321}]}, {"text": "shows the word accuracy after the semantic postprocessing versus the original word accuracy of the recognizer using the word pair grammar.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 15, "end_pos": 23, "type": "METRIC", "confidence": 0.7863596677780151}, {"text": "word accuracy", "start_pos": 78, "end_pos": 91, "type": "METRIC", "confidence": 0.5477644354104996}]}, {"text": "With the worst recognizer, that gives a word accuracy of 61.3%, the effect of the semantic postprocessing is to increase the word accuracy to 70.4%.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 45, "end_pos": 53, "type": "METRIC", "confidence": 0.8860426545143127}, {"text": "accuracy", "start_pos": 130, "end_pos": 138, "type": "METRIC", "confidence": 0.8137805461883545}]}, {"text": "The best recognizer gives a word accuracy of 94.9% and, after the postprocessing, the corrected strings show a word accuracy of 97.7%, corresponding to a 55% reduction in the word error rate.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 33, "end_pos": 41, "type": "METRIC", "confidence": 0.7645286321640015}, {"text": "accuracy", "start_pos": 116, "end_pos": 124, "type": "METRIC", "confidence": 0.49940770864486694}, {"text": "word error rate", "start_pos": 175, "end_pos": 190, "type": "METRIC", "confidence": 0.7754701773325602}]}, {"text": "reports the semantic accuracy versus the original sentence accuracy of the various recognizers.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 21, "end_pos": 29, "type": "METRIC", "confidence": 0.9338734745979309}, {"text": "accuracy", "start_pos": 59, "end_pos": 67, "type": "METRIC", "confidence": 0.7804371118545532}]}, {"text": "Sentence accuracy is computed as the percent of correct sentences, namely the percent of sentences for which the recognized sequence of words corresponds the uttered sequence.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 9, "end_pos": 17, "type": "METRIC", "confidence": 0.784243643283844}]}, {"text": "Semantic accuracy is the percent of sentences for which both the sentence generation template and the values of the semantic variables are correctly decoded, after the semantic postprocessing.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 9, "end_pos": 17, "type": "METRIC", "confidence": 0.9798737168312073}]}, {"text": "With the best recognizer the sentence accuracy is 70.7% while the semantic accuracy is 94.7%.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 38, "end_pos": 46, "type": "METRIC", "confidence": 0.9662490487098694}, {"text": "accuracy", "start_pos": 75, "end_pos": 83, "type": "METRIC", "confidence": 0.7032645344734192}]}, {"text": "When using acoustic verification instead of simple phonetic verification, as described in section 3.2, better word and sentence accuracy can be obtained with the same test data.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 128, "end_pos": 136, "type": "METRIC", "confidence": 0.9254337549209595}]}, {"text": "Using a NG covering grammar, the final word accuracy is 97.7% and the sentence accuracy is 91.0% (instead of 92.3% and 67.0%, obtained using phonetic verification).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 44, "end_pos": 52, "type": "METRIC", "confidence": 0.8961771726608276}, {"text": "accuracy", "start_pos": 79, "end_pos": 87, "type": "METRIC", "confidence": 0.8250799775123596}]}, {"text": "With a WP covering grammar the word accuracy is 98.6% and the sentence accuracy is 92% (instead of 97.7% and 86.3% with phonetic verification).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 36, "end_pos": 44, "type": "METRIC", "confidence": 0.967913806438446}, {"text": "accuracy", "start_pos": 71, "end_pos": 79, "type": "METRIC", "confidence": 0.8577951788902283}]}, {"text": "The small difference in the accuracy between the NG and the WP case shows the rebusmess introduced into the system by the semantic postprocessing, especially when acoustic verification is peformed.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 28, "end_pos": 36, "type": "METRIC", "confidence": 0.9994245767593384}]}], "tableCaptions": []}