{"title": [{"text": "Polynomial Time and Space Shift-Reduce Parsing of Arbitrary Context-free Grammars.*", "labels": [], "entities": [{"text": "Polynomial Time and Space Shift-Reduce Parsing of Arbitrary Context-free Grammars", "start_pos": 0, "end_pos": 81, "type": "TASK", "confidence": 0.7373396039009095}]}], "abstractContent": [{"text": "We introduce an algorithm for designing a predictive left to right shift-reduce non-deterministic push-down machine corresponding to an arbitrary unrestricted context-free grammar and an algorithm for efficiently driving this machine in pseudo-parallel.", "labels": [], "entities": []}, {"text": "The performance of the resulting parser is formally proven to be superior to Earley's parser (1970).", "labels": [], "entities": []}, {"text": "The technique employed consists in constructing before run-time a parsing table that encodes a non-deterministic machine in the which the predictive behavior has been compiled out.", "labels": [], "entities": []}, {"text": "At run time, the machine is driven in pseudo-parallel with the help of a chart.", "labels": [], "entities": []}, {"text": "The recognizer behaves in the worst casein O(IGI2n3)-time and O(IGIn2)-space.", "labels": [], "entities": []}, {"text": "However in practice it is always superior to Earley's parser since the prediction steps have been compiled before run-time.", "labels": [], "entities": []}, {"text": "Finally, we explain how other more efficient variants of the basic parser can be obtained by deter-minizing portionsof the basic non-deterministic push-down machine while still using the same pseudo-parallel driver.", "labels": [], "entities": []}], "introductionContent": [{"text": "Predictive bottom-up parsers are often used for natural language processing because of their superior average performance compared to purely bottom-up parsers *We are extremely indebted to Fernando Pereira and Stuart Shleber for providing valuable technical comments during discussions about earlier versio/m of this algorithm.", "labels": [], "entities": [{"text": "natural language processing", "start_pos": 48, "end_pos": 75, "type": "TASK", "confidence": 0.6693299015363058}]}, {"text": "We are also grateful to Aravind Joehi for his support of this research.", "labels": [], "entities": []}, {"text": "We also thank Robert Frank.", "labels": [], "entities": []}, {"text": "All remaining errors are the author's responsibility alone.", "labels": [], "entities": []}, {"text": "This research wa~ partially funded by ARO grant DAAL03-89-C0031PRI and DARPA grant N00014-90-J-1863.", "labels": [], "entities": [{"text": "ARO grant DAAL03-89-C0031PRI", "start_pos": 38, "end_pos": 66, "type": "DATASET", "confidence": 0.6472736994425455}, {"text": "DARPA grant N00014-90-J-1863", "start_pos": 71, "end_pos": 99, "type": "DATASET", "confidence": 0.7631176511446635}]}, {"text": "Their practical superiority is mainly obtained because of the top-down filtering accomplished by the predictive component of the parser.", "labels": [], "entities": []}, {"text": "Compiling out as much as possible this predictive component before run-time will result in a more efficient parser so long as the worst case behavior is not deteriorated.", "labels": [], "entities": []}, {"text": "Approaches in this direction have been investigated, however none of them is satisfying, either because the worst case complexity is deteriorated (worse than Earley's parser) or because the technique is not general.", "labels": [], "entities": []}, {"text": "Furthermore, none of these approaches have been formally proven to have a behavior superior to well known parsers such as Earley's parser.", "labels": [], "entities": []}, {"text": "Earley himself ( pages 69-89) proposed to precompile the state sets generated by his algorithm to make it as efficient as LR(k) parsers when used on LR(k) grammars by precomputing all possible states sets that the parser could create.", "labels": [], "entities": []}, {"text": "However, some context-free grammars, including most likely most natural language grammars, cannot be compiled using his technique and the problem of knowing if a grammar can be compiled with this technique is undecidable, page 99).", "labels": [], "entities": []}, {"text": "proposed a technique for evaluating in pseudo-parallel non-deterministic push down automata.", "labels": [], "entities": []}, {"text": "Although this technique achieves a worst case complexity of O(n3)-time with respect to the length of input, it requires that at most two symbols are popped from the stack in a single move.", "labels": [], "entities": [{"text": "O(n3)-time", "start_pos": 60, "end_pos": 70, "type": "METRIC", "confidence": 0.8800329566001892}]}, {"text": "When the technique is used for shift-reduce parsing, this constraint requires that the context-free grammar is in Chomsky normal form (CNF).", "labels": [], "entities": []}, {"text": "As far as the grammar size is concerned, an exponential worst case behavior is reached when used with the characteristic LR(0) machine.", "labels": [], "entities": []}, {"text": "1 proposed to extend LR(0) parsers to non-deterministic context-free grammars by explicitly using a graph structured stack which represents the pseudo-parallel evaluation of the moves of a non-deterministic LR(0) push-down automaton.", "labels": [], "entities": []}, {"text": "Tomita's encoding of the non-deterministic pushdown automaton suffers from an exponential time and space worst case complexity with respect to the input length and also with respect to the grammar size and also page 72 in Tomita).", "labels": [], "entities": [{"text": "exponential time and space worst case complexity", "start_pos": 78, "end_pos": 126, "type": "METRIC", "confidence": 0.6640593366963523}]}, {"text": "Although Tomita reports experimental data that seem to show that the parser behaves in practice better than Earley's parser (which is proven to take in the worst case O([G[2n3)-time), the duplication of the same experiments shows no conclusive outcome.", "labels": [], "entities": []}, {"text": "Modifications to Tomita's algorithm have been proposed in order to alleviate the exponential complexity with respect to the input length but, according to Kipps, the modified algorithm does not lead to a practical parser.", "labels": [], "entities": []}, {"text": "Furthermore, the algorithm is doomed to behave in the worst casein exponential time with respect to the grammar size for some ambiguous grammars and inputs.", "labels": [], "entities": []}, {"text": "2 So far, there is no formal proof showing that the Tomita's parser can be superior for some grammars and inputs to Earley's parser, and its worst case complexity seems to contradict the experimental data.", "labels": [], "entities": []}, {"text": "As explained, the previous attempts to compile the predictive component are not general and achieve a worst case complexity (with respect to the grammar size and the input length) worse than standard parsers.", "labels": [], "entities": []}, {"text": "The methodology we follow in order to compile the predictive component of Earley's parser is to define a predictive bottom-up pushdown machine equivalent to the given grammar which we drive in pseudoparallel.", "labels": [], "entities": []}, {"text": "Following argument, any parsing algorithm based on the LR(0) characteristic machine is doomed to behave in exponential time with respect to the grammar size for some ambiguous grammars and inputs.", "labels": [], "entities": []}, {"text": "This is a result of the fact that the number of states of an LR(0) characteristic machine can be exponential and that there are some grammars and inputs for which an exponential number of states must be reached (See Johnson for examples of such grammars and inputs).", "labels": [], "entities": []}, {"text": "One must therefore design a different pushdown machine which can be driven efficiently in pseudo-parallel.", "labels": [], "entities": []}, {"text": "We construct a non-deterministic predictive pushdown machine given an arbitrary context-free grammar whose number of states is proportional to the size of the grammar.", "labels": [], "entities": []}, {"text": "Then at run time, we efficiently drive this machine in pseudo-parallel.", "labels": [], "entities": []}, {"text": "Even if all the states of the machine are reached for some grammars and inputs, a polynomial complexity will still be obtained since the number of states is bounded by the grammar size.", "labels": [], "entities": []}, {"text": "We therefore introduce a shift-reduce driver for this machine in which all of the predictive component has been compiled in the finite state control of the machine.", "labels": [], "entities": []}, {"text": "The technique makes no requirement on the form of the context-free grammar and it behaves in the worst case as well as Earley's parser.", "labels": [], "entities": []}, {"text": "The push-down machine is built before runtime and it is encoded as parsing tables in the which the predictive behavior has been compiled out.", "labels": [], "entities": []}, {"text": "In the worst case, the recognizer behaves in the same O([Gl2nS)-time and O([G[n2)-space as Earley's parser.", "labels": [], "entities": []}, {"text": "However in practice it is always superior to Earley's parser since the prediction steps have been eliminated before run-time.", "labels": [], "entities": []}, {"text": "We show that the items produced in the chart correspond to equivalence classes on the items produced for the same input by Earley's parser.", "labels": [], "entities": []}, {"text": "This mapping formally shows its practical superior behavior.", "labels": [], "entities": []}, {"text": "3 Finally, we explain how other more efficient variants of the basic parser can be obtained by determinizing portions of the basic non-deterministic pushdown machine while still using the same pseudoparallel driver.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": []}