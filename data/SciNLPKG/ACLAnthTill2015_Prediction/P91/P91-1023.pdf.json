{"title": [{"text": "A PROGRAM FOR ALIGNING SENTENCES IN BILINGUAL CORPORA", "labels": [], "entities": [{"text": "A PROGRAM FOR ALIGNING SENTENCES IN BILINGUAL CORPORA", "start_pos": 0, "end_pos": 53, "type": "METRIC", "confidence": 0.649208314716816}]}], "abstractContent": [{"text": "Researchers in both machine Iranslation (e.g., Brown et al., 1990) and bilingual lexicography (e.g., Klavans and Tzoukermann, 1990) have recently become interested in studying parallel texts, texts such as the Canadian Hansards (parliamentary proceedings) which are available in multiple languages (French and English).", "labels": [], "entities": [{"text": "Iranslation", "start_pos": 28, "end_pos": 39, "type": "TASK", "confidence": 0.5325921177864075}, {"text": "Canadian Hansards (parliamentary proceedings)", "start_pos": 210, "end_pos": 255, "type": "DATASET", "confidence": 0.8874155580997467}]}, {"text": "This paper describes a method for aligning sentences in these parallel texts, based on a simple statistical model of character lengths.", "labels": [], "entities": []}, {"text": "The method was developed and tested on a small trilingual sample of Swiss economic reports.", "labels": [], "entities": [{"text": "Swiss economic reports", "start_pos": 68, "end_pos": 90, "type": "DATASET", "confidence": 0.813721776008606}]}, {"text": "A much larger sample of 90 million words of Canadian Hansards has been aligned and donated to the ACL/DCI.", "labels": [], "entities": [{"text": "Canadian Hansards", "start_pos": 44, "end_pos": 61, "type": "DATASET", "confidence": 0.877447634935379}, {"text": "ACL/DCI", "start_pos": 98, "end_pos": 105, "type": "DATASET", "confidence": 0.8801616032918295}]}], "introductionContent": [{"text": "Researchers in both machine lranslation (e.g.,) and bilingual lexicography (e.g., have recently become interested in studying bilingual corpora, bodies of text such as the Canadian I-lansards (parliamentary debates) which are available in multiple languages (such as French and English).", "labels": [], "entities": []}, {"text": "The sentence alignment task is to identify correspondences between sentences in one language and sentences in the other language.", "labels": [], "entities": [{"text": "sentence alignment", "start_pos": 4, "end_pos": 22, "type": "TASK", "confidence": 0.7812186777591705}]}, {"text": "This task is a first step toward the more ambitious task finding correspondances among words.", "labels": [], "entities": []}, {"text": "I The input is a pair of texts such as 1.", "labels": [], "entities": []}, {"text": "In statistics, string matching problems are divided into two classes: alignment problems and correspondance problems.", "labels": [], "entities": [{"text": "string matching problems", "start_pos": 15, "end_pos": 39, "type": "TASK", "confidence": 0.7968389888604482}]}, {"text": "Crossing dependencies are possible in the latter, but not in the former.", "labels": [], "entities": []}], "datasetContent": [{"text": "To evaluate align, its results were compared with a human alignment.", "labels": [], "entities": []}, {"text": "All of the UBS sentences were aligned by a primary judge, a native speaker of English with a reading knowledge of French and German.", "labels": [], "entities": []}, {"text": "Two additional judges, a native speaker of French and a native speaker of German, respectively, were used to check the primary judge on 43 of the more difficult paragraphs having 230 sentences (out of 118 total paragraphs with 725 sentences).", "labels": [], "entities": []}, {"text": "Both of the additional judges were also fluent in English, having spent the last few years living and working in the United States, though they were both more comfortable with their native language than with English.", "labels": [], "entities": []}, {"text": "The materials were prepared in order to make the task somewhat less tedious for the judges.", "labels": [], "entities": []}, {"text": "Each paragraph was printed in three columns, one for each of the three languages: English, French and German.", "labels": [], "entities": []}, {"text": "Blank lines were inserted between sentences.", "labels": [], "entities": [{"text": "Blank", "start_pos": 0, "end_pos": 5, "type": "METRIC", "confidence": 0.9615906476974487}]}, {"text": "The judges were asked to draw lines between matching sentences.", "labels": [], "entities": []}, {"text": "The judges were also permitted to draw a line between a sentence and \"null\" if they thought that the sentence was not translated.", "labels": [], "entities": []}, {"text": "For the purposed of this evaluation, two sentences were defined to \"match\" if they shared a common clause.", "labels": [], "entities": []}, {"text": "(In a few cases, a pair of sentences shared only a phrase or a word, rather than a clause; these sentences did not count as a \"match\" for the purposes of this experiment.)", "labels": [], "entities": []}, {"text": "After checking the primary judge with the other two judges, it was decided that the primary judge's results were sufficiently reliable that they could be used as a standard for evaluating the program.", "labels": [], "entities": []}, {"text": "The primary judge made only two mistakes on the 43 hard paragraphs (one French mistake and one German mistake), whereas the program made 44 errors on the same materials.", "labels": [], "entities": []}, {"text": "Since the primary judge's error rate is so much lower than that of the program, it was decided that we needn't be concerned with the primary judge's error rate.", "labels": [], "entities": [{"text": "error rate", "start_pos": 26, "end_pos": 36, "type": "METRIC", "confidence": 0.9771007299423218}, {"text": "error rate", "start_pos": 149, "end_pos": 159, "type": "METRIC", "confidence": 0.9531321227550507}]}, {"text": "If the program and the judge disagree, we can assume that the program is probably wrong.", "labels": [], "entities": []}, {"text": "The 43 \"hard\" paragraphs were selected by looking for sentences that mapped to something other than themselves after going through both German and French.", "labels": [], "entities": []}, {"text": "Specifically, for each English sentence, we attempted to find the corresponding German sentences, and then for each of them, we attempted to find the corresponding French sentences, and then we attempted to find the corresponding English sentences, which should hopefully get us back to where we started.", "labels": [], "entities": []}, {"text": "The 43 paragraphs included all sentences in which this process could not be completed around the loop.", "labels": [], "entities": []}, {"text": "This relatively small group of paragraphs (23 percent of all paragraphs) contained a relatively large fraction of the program's errors (82 percent).", "labels": [], "entities": [{"text": "errors", "start_pos": 128, "end_pos": 134, "type": "METRIC", "confidence": 0.9757803678512573}]}, {"text": "Thus, there does seem to be some verification that this trilingual criterion does in fact succeed in distinguishing more difficult paragraphs from less difficult ones.", "labels": [], "entities": []}, {"text": "There are three pairs of languages: EnglishGerman, English-French and French-German.", "labels": [], "entities": []}, {"text": "We will report just the first two.", "labels": [], "entities": []}, {"text": "(The third pair is probably dependent on the first two.)", "labels": [], "entities": []}, {"text": "Errors are reported with respect to the judge's responses.", "labels": [], "entities": [{"text": "Errors", "start_pos": 0, "end_pos": 6, "type": "METRIC", "confidence": 0.9874750971794128}]}, {"text": "That is, for each of the \"matches\" that the primary judge found, we report the program as correct ff it found the \"match\" and incorrect ff it didn't This convention allows us to compare performance across different algorithms in a straightforward fashion.", "labels": [], "entities": []}, {"text": "The program made 36 errors out of 621 total alignments (5.8%) for English-French, and 19 errors out of 695 (2.7%) alignments for EnglishGerman.", "labels": [], "entities": [{"text": "EnglishGerman", "start_pos": 129, "end_pos": 142, "type": "DATASET", "confidence": 0.9567350745201111}]}, {"text": "Overall, there were 55 errors out of a total of 1316 alignments (4.2%).", "labels": [], "entities": [{"text": "errors", "start_pos": 23, "end_pos": 29, "type": "METRIC", "confidence": 0.9902666211128235}]}, {"text": "In addition, when the algorithm assigns a sentence to the 1-0 category, it is also always wrong.", "labels": [], "entities": []}, {"text": "Clearly, more work is needed to deal with the 1-0 category.", "labels": [], "entities": []}, {"text": "It maybe necessary to consider language-specific methods in order to deal adequately with this case.", "labels": [], "entities": []}, {"text": "We observe that the score is a good predictor of performance, and therefore the score can be used to extract a large subcorpus which has a much smaller error rate.", "labels": [], "entities": [{"text": "error rate", "start_pos": 152, "end_pos": 162, "type": "METRIC", "confidence": 0.9444006979465485}]}, {"text": "By selecting the best scoring 80% of the alignments, the error rate can be reduced from 4% to 0.7%.", "labels": [], "entities": [{"text": "error rate", "start_pos": 57, "end_pos": 67, "type": "METRIC", "confidence": 0.9933911561965942}]}, {"text": "In general, we can trade off the size of the subcorpus and the accuracy by setting a threshold, and rejecting alignments with a score above this threshold.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 63, "end_pos": 71, "type": "METRIC", "confidence": 0.9997016787528992}]}, {"text": "examines this trade-off in more detail.", "labels": [], "entities": []}, {"text": "breaks down the errors by category, illustrating that complex matches are more difficulL I-I alignments are by far the easiest.", "labels": [], "entities": []}, {"text": "The 2-I alignments, which come next, have four times the error rate for I-I.", "labels": [], "entities": [{"text": "error rate", "start_pos": 57, "end_pos": 67, "type": "METRIC", "confidence": 0.9789903163909912}]}, {"text": "The 2-2 alignments are harder still, but a majority of the alignments are found.", "labels": [], "entities": []}, {"text": "The 3-I and 3-2 alignments arc not even considered by the algorithm, so naturally all three are counted as errors.", "labels": [], "entities": []}, {"text": "The most embarrassing category is I-0, which was never.", "labels": [], "entities": [{"text": "I-0", "start_pos": 34, "end_pos": 37, "type": "TASK", "confidence": 0.41457051038742065}]}, {"text": "The fact that the score is such a good predictor of performance can be used to extract a large subcorpus which has a much smaller error rate.", "labels": [], "entities": [{"text": "error rate", "start_pos": 130, "end_pos": 140, "type": "METRIC", "confidence": 0.9586450457572937}]}, {"text": "In general, we can trade-off the size of the subcorpus and the accuracy by-setting a threshold, and rejecting alignments with a score above this threshold..", "labels": [], "entities": [{"text": "accuracy", "start_pos": 63, "end_pos": 71, "type": "METRIC", "confidence": 0.9995848536491394}]}, {"text": "However, we have found that words do not perform nearly as well as characters.", "labels": [], "entities": []}, {"text": "In fact, the \"words\" variation increases the number of errors dramatically (from 36 to 50 for English-French and from 19 to 35 for English-German).", "labels": [], "entities": [{"text": "number of errors", "start_pos": 45, "end_pos": 61, "type": "METRIC", "confidence": 0.935644527276357}]}, {"text": "The total errors were thereby increased from 55 to 85, or from 4.2% to 6.5%.", "labels": [], "entities": [{"text": "errors", "start_pos": 10, "end_pos": 16, "type": "METRIC", "confidence": 0.9724368453025818}]}, {"text": "We believe that characters are better because there are more of them, and therefore there is less uncertainty.", "labels": [], "entities": []}, {"text": "On the average, the~re are 117 characters per sentence (including white space) and only 17 words per sentence.", "labels": [], "entities": []}, {"text": "Recall that we have modeled variance as proportional to sentence length, V = s 2 I.", "labels": [], "entities": []}, {"text": "Using the character data, we found previously that s 2= 6.5.", "labels": [], "entities": []}, {"text": "The same argument applied to words yields s 2 = 1.9.", "labels": [], "entities": []}, {"text": "For comparison sake, it is useful to consider the ratio of ~/(V(m))lm (or equivalently, sl~m), where m is the mean sentence length.", "labels": [], "entities": []}, {"text": "We obtain ff(m)lm ratios of 0.22 for characters and 0.33 for words, indicating that characters are less noisy than words, and are therefore more suitable for use in align.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 5: Prob(mateh)  Category  Frequency  Prob(match)  1-1  1167  0.89  1-0 or 0-1  13  0.0099  2-1 or 1-2  117  0.089  2-2  15  0.011  1312  1.00", "labels": [], "entities": [{"text": "Prob(mateh)  Category  Frequency  Prob(match)  1-1  1167  0.89  1-0", "start_pos": 10, "end_pos": 77, "type": "METRIC", "confidence": 0.7088875664131982}]}, {"text": " Table 6: Complex Matches are More Difficult  category  English-French  English-German  total  N  err  %  N  err  %  N  err  %  l-0or0-1  1-1  2-1 or 1-2  2-2  3-1 or !-3  3-2 or 2-3", "labels": [], "entities": []}]}