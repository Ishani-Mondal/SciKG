{"title": [{"text": "FROM N-GRAMS TO COLLOCATIONS AN EVALUATION OF XTRACT", "labels": [], "entities": [{"text": "FROM N-GRAMS TO COLLOCATIONS AN EVALUATION", "start_pos": 0, "end_pos": 42, "type": "METRIC", "confidence": 0.6716778526703516}, {"text": "XTRACT", "start_pos": 46, "end_pos": 52, "type": "TASK", "confidence": 0.5539390444755554}]}], "abstractContent": [{"text": "In previous papers we presented methods for retrieving collocations from large samples of texts.", "labels": [], "entities": []}, {"text": "We described a tool, Xtract, that implements these methods and able to retrieve a wide range of collocations in a two stage process.", "labels": [], "entities": []}, {"text": "These methods a.s well as other related methods however have some limitations.", "labels": [], "entities": []}, {"text": "Mainly, the produced collocations do not include any kind of functional information and many of them are invalid.", "labels": [], "entities": []}, {"text": "In this paper we introduce methods that address these issues.", "labels": [], "entities": []}, {"text": "These methods are implemented in an added third stage to Xtract that examines the set of collocations retrieved during the previous two stages to both filter out a number of invalid col-locations and add useful syntactic information to the retained ones.", "labels": [], "entities": []}, {"text": "By combining parsing and statistical techniques the addition of this third stage has raised the overall precision level of Xtract from 40% to 80% With a precision of 94%.", "labels": [], "entities": [{"text": "parsing", "start_pos": 13, "end_pos": 20, "type": "TASK", "confidence": 0.9799759387969971}, {"text": "precision level", "start_pos": 104, "end_pos": 119, "type": "METRIC", "confidence": 0.984838455915451}, {"text": "Xtract", "start_pos": 123, "end_pos": 129, "type": "TASK", "confidence": 0.6591415405273438}, {"text": "precision", "start_pos": 153, "end_pos": 162, "type": "METRIC", "confidence": 0.9988076686859131}]}, {"text": "In the paper we describe the methods and the evaluation experiments.", "labels": [], "entities": []}], "introductionContent": [{"text": "In the past, several approaches have been proposed to retrieve various types of collocations from the analysis of large samples of textual data.", "labels": [], "entities": []}, {"text": "Pairwise associations (bigrams or 2-grams) (e.g.,,) as well as n-word (n > 2) associations (or n-grams) (e.g.,,) were retrieved.", "labels": [], "entities": []}, {"text": "These techniques automatically produced large numbers of collocations along with statistical figures intended to reflect their relevance.", "labels": [], "entities": []}, {"text": "However, none of these techniques provides functional information along with the collocation.", "labels": [], "entities": []}, {"text": "Also, the results produced often contained improper word associations reflecting some spurious aspect of the training corpus that did not stand for true collocations.", "labels": [], "entities": []}, {"text": "This paper addresses these two problems.", "labels": [], "entities": []}, {"text": "Previous papers (e.g.,) introduced a. set of tecl)niques and a. tool, Xtract, that produces various types of collocations from a twostage statistical analysis of large textual corpora briefly sketched in the next section.", "labels": [], "entities": []}, {"text": "In Sections 3 and 4, we show how robust parsing technology can be used to both filter out a number of invalid collocations as well as add useful syntactic information to the retained ones.", "labels": [], "entities": []}, {"text": "This filter/analyzer is implemented in a third stage of Xtract that automatically goes over a the output collocations to reject the invalid ones and label the valid ones with syntactic information.", "labels": [], "entities": []}, {"text": "For example, if the first two stages of Xtract produce the collocation \"make-decision,\" the goal of this third stage'is to identify it as a verb-object collocation.", "labels": [], "entities": []}, {"text": "If no such syntactic relation is observed, then the collocation is rejected.", "labels": [], "entities": []}, {"text": "In Section 5 we present an evaluation of Xtract as a collocation retrieval system.", "labels": [], "entities": []}, {"text": "The addition of the third stage of Xtract has been evaluated to raise the precision of Xtract from 40% to 80\u00b0\u00a3 and it has a recall of 94%.", "labels": [], "entities": [{"text": "precision", "start_pos": 74, "end_pos": 83, "type": "METRIC", "confidence": 0.9997637867927551}, {"text": "\u00b0\u00a3", "start_pos": 108, "end_pos": 110, "type": "METRIC", "confidence": 0.9873894453048706}, {"text": "recall", "start_pos": 124, "end_pos": 130, "type": "METRIC", "confidence": 0.9964904189109802}]}, {"text": "In this paper we use examples related to the word \"takeover\" from a 10 million word corpus containing stock market reports originating from the Associated Press newswire.", "labels": [], "entities": [{"text": "Associated Press newswire", "start_pos": 144, "end_pos": 169, "type": "DATASET", "confidence": 0.838053822517395}]}], "datasetContent": [{"text": "Deciding whether a given word combination is a valid or invahd collocation is actually a difficult task that is best done by a lexicographer.", "labels": [], "entities": [{"text": "Deciding whether a given word combination", "start_pos": 0, "end_pos": 41, "type": "TASK", "confidence": 0.7268222073713938}]}, {"text": "Jeffery Triggs is a lexicographer working for Oxford English Dictionary (OED) coordinating the North American Readers program of OED at Bell Communication Research.", "labels": [], "entities": [{"text": "Oxford English Dictionary (OED)", "start_pos": 46, "end_pos": 77, "type": "DATASET", "confidence": 0.90059166153272}, {"text": "Bell Communication Research", "start_pos": 136, "end_pos": 163, "type": "DATASET", "confidence": 0.8065016269683838}]}, {"text": "Jeffery Triggs agreed to manually go over several thousands collocations, a We randomly selected a subset of about 4,000 collocations that contained the information compiled by Xtract after the first 2 stages.", "labels": [], "entities": []}, {"text": "This data set was then the subject of the following experiment.", "labels": [], "entities": []}, {"text": "We gave the 4,000 collocations to evaluate to the lexicographer, asking him to select the ones that he 3I am grateful to Jeffery whose professionalism and kindness helped me understand some of the difficulty of lexicography.", "labels": [], "entities": []}, {"text": "Without him this evaluation would not have been possible.", "labels": [], "entities": []}, {"text": "Although this would seem like a poor precision, one should compare it with the much lower rates currently in practice in lexicography.", "labels": [], "entities": [{"text": "precision", "start_pos": 37, "end_pos": 46, "type": "METRIC", "confidence": 0.9992972612380981}]}, {"text": "For the OED, for example, the first stage roughly consists of reading numerous documents to identify new or interesting expressions.", "labels": [], "entities": [{"text": "OED", "start_pos": 8, "end_pos": 11, "type": "DATASET", "confidence": 0.7235206365585327}]}, {"text": "This task is performed by professional readers.", "labels": [], "entities": []}, {"text": "For the OED, the readers for the American program alone produce some 10,000 expressions a month.", "labels": [], "entities": [{"text": "OED", "start_pos": 8, "end_pos": 11, "type": "DATASET", "confidence": 0.8751833438873291}, {"text": "American program", "start_pos": 33, "end_pos": 49, "type": "DATASET", "confidence": 0.9271495938301086}]}, {"text": "These lists are then sent off to the dictionary and go through several rounds of careful analysis before actually being submitted to the dictionary.", "labels": [], "entities": []}, {"text": "The ratio of proposed candidates to good candidates is usually low.", "labels": [], "entities": []}, {"text": "For example, out of the 10,000 expressions proposed each month, less than 400 are serious candidate for the OED, which represents a current rate of 4%.", "labels": [], "entities": [{"text": "OED", "start_pos": 108, "end_pos": 111, "type": "METRIC", "confidence": 0.5385670065879822}]}, {"text": "Automatically producing lists of candidate expressions could actually be of great help to lexicographers and even a precision of 40% would be helpful.", "labels": [], "entities": [{"text": "precision", "start_pos": 116, "end_pos": 125, "type": "METRIC", "confidence": 0.9990971088409424}]}, {"text": "Such lexicographic tools could, for example, help readers retrieve sublanguage specific expressions by providing them with lists of candidate collocations.", "labels": [], "entities": []}, {"text": "The lexicographer then manually examines the list to remove the irrelevant data.", "labels": [], "entities": []}, {"text": "Even low precision is useful for lexicographers as manual filtering is much faster than manual scanning of the documents.", "labels": [], "entities": [{"text": "precision", "start_pos": 9, "end_pos": 18, "type": "METRIC", "confidence": 0.9968162178993225}]}, {"text": "Such techniques are notable to replace readers though, as they are not designed to identify low frequency expressions, whereas a human reader immediately identifies interesting expressions with as few as one occurrence.", "labels": [], "entities": []}, {"text": "The second stage of this experiment was to use Xtract Stage 3 to filter out and label the sample set of collocations.", "labels": [], "entities": []}, {"text": "As described in Section 3, there are several valid labels.", "labels": [], "entities": []}, {"text": "In this experiment, we grouped them under a single label: T.", "labels": [], "entities": []}, {"text": "There is only one non-valid label: U (for unlabeled}.", "labels": [], "entities": []}, {"text": "A T collocation is thus accepted by Xtract Stage 3, and a U collocation is rejected.", "labels": [], "entities": []}, {"text": "The results of the use of Stage 3 on the sample set of collocations are similar to the manual evaluation in terms of numbers: about 40% of the collocations were labeled (T) by Xtract Stage 3, and about 60% were rejected (U).", "labels": [], "entities": []}, {"text": "It shows that 94% of the collocations accepted by the lexicographer were also accepted by Xtract.", "labels": [], "entities": [{"text": "Xtract", "start_pos": 90, "end_pos": 96, "type": "DATASET", "confidence": 0.7793256044387817}]}, {"text": "In other words, this means that the recall ofthe third stage of Xtract is 94%.", "labels": [], "entities": [{"text": "recall", "start_pos": 36, "end_pos": 42, "type": "METRIC", "confidence": 0.999144434928894}]}, {"text": "The first column of the diagram on the right represents the lexicographic evaluation of the collocations automatically accepted by Xtract.", "labels": [], "entities": []}, {"text": "It shows that about 80% of the T collocations were accepted by the lexicographer and that about 20% were rejected.", "labels": [], "entities": []}, {"text": "This shows that precision was raised from 40% to 80% with the addition of Xtract Stage 3.", "labels": [], "entities": [{"text": "precision", "start_pos": 16, "end_pos": 25, "type": "METRIC", "confidence": 0.9997909665107727}]}, {"text": "In summary, these experiments allowed us to evaluate Stage 3 as a retrieval system.", "labels": [], "entities": []}, {"text": "The results are: I Precision = 80% Recall = 94% ]", "labels": [], "entities": [{"text": "I", "start_pos": 17, "end_pos": 18, "type": "METRIC", "confidence": 0.9941214919090271}, {"text": "Precision", "start_pos": 19, "end_pos": 28, "type": "METRIC", "confidence": 0.854155421257019}, {"text": "Recall", "start_pos": 35, "end_pos": 41, "type": "METRIC", "confidence": 0.9994070529937744}]}], "tableCaptions": [{"text": " Table 1: Output of Stage 1", "labels": [], "entities": [{"text": "Output", "start_pos": 10, "end_pos": 16, "type": "METRIC", "confidence": 0.9942131638526917}]}]}