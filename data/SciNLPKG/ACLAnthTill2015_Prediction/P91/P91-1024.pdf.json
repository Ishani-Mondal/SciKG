{"title": [{"text": "EXPERIMENTS AND PROSPECTS OF EXAMPLE-BASED MACHINE TRANSLATION", "labels": [], "entities": [{"text": "TRANSLATION", "start_pos": 51, "end_pos": 62, "type": "METRIC", "confidence": 0.7763202786445618}]}], "abstractContent": [{"text": "EBMT (Example-Based Machine Translation) is proposed.", "labels": [], "entities": [{"text": "EBMT", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.6936080455780029}, {"text": "Example-Based Machine Translation)", "start_pos": 6, "end_pos": 40, "type": "TASK", "confidence": 0.6856056526303291}]}, {"text": "EBMT retrieves similar examples (pairs of source phrases, sentences, or texts and their translations) from a d~t.hase of examples, adapting the examples to translate anew input.", "labels": [], "entities": [{"text": "EBMT retrieves similar examples (pairs of source phrases, sentences, or texts and their translations) from a d", "start_pos": 0, "end_pos": 110, "type": "Description", "confidence": 0.6944702594053178}]}, {"text": "EBMT has the following features: (1) It is easily upgraded simply by inputting appropriate examples to the database; (2) It assigns a reliability factcr to the translation result; (3) It is acoelerated effectively by both indexing and parallel computing; (4) It is robust because of best-match reasoning; ~d (5) It well utilizes translator expertise.", "labels": [], "entities": [{"text": "EBMT", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.853676974773407}]}, {"text": "A prototype system has been implemented to deal with a difficult translation problem for conventional Rule-Based Machine Translation (RBMT), i.e., translating Japanese noun phrases of the form \"N~ no N2\" into English.", "labels": [], "entities": [{"text": "Rule-Based Machine Translation (RBMT)", "start_pos": 102, "end_pos": 139, "type": "TASK", "confidence": 0.8099242250124613}]}, {"text": "The system has achieved about a 78% success rate on average.", "labels": [], "entities": []}, {"text": "This paper explains the basic idea of EBMT, illustrates the experiment in detail, explains the broad applicability of EBMT to several difficult translation problems for RBMT and discusses the advantages of integrating EBMT with RBMT.", "labels": [], "entities": [{"text": "RBMT", "start_pos": 169, "end_pos": 173, "type": "TASK", "confidence": 0.7973447442054749}]}], "introductionContent": [{"text": "Machine Translation requires handcmt~ and complicated large-scale knowledge.", "labels": [], "entities": [{"text": "Machine Translation", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.8501562774181366}, {"text": "handcmt", "start_pos": 29, "end_pos": 36, "type": "METRIC", "confidence": 0.9369083642959595}]}, {"text": "Conventional machine translation systems use rules as the knowledge.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 13, "end_pos": 32, "type": "TASK", "confidence": 0.7346337735652924}]}, {"text": "This framework is called Rule-Based Machine Translation (RBMT).", "labels": [], "entities": [{"text": "Rule-Based Machine Translation (RBMT)", "start_pos": 25, "end_pos": 62, "type": "TASK", "confidence": 0.7659850120544434}]}, {"text": "It is difficult to scale up from a toy program to a practical system because of the problem of building such a lurge-scale rule-base.", "labels": [], "entities": []}, {"text": "It is also difficult to improve translation performance because the effect of adding anew rule is hard to anticipate, and because translation using a large-scule rule-based system is time-consuming.", "labels": [], "entities": [{"text": "translation", "start_pos": 32, "end_pos": 43, "type": "TASK", "confidence": 0.9695567488670349}]}, {"text": "Moreover, it is difficult to make use of situational or domain-specific information for translation.", "labels": [], "entities": [{"text": "translation", "start_pos": 88, "end_pos": 99, "type": "TASK", "confidence": 0.9749091863632202}]}, {"text": "their translations) has been implemented as the knowledge.", "labels": [], "entities": []}, {"text": "The translation mechanism retrieves similar examples from the database, adapting the examples to Wanslate the new source text.", "labels": [], "entities": [{"text": "Wanslate", "start_pos": 97, "end_pos": 105, "type": "DATASET", "confidence": 0.8187820315361023}]}, {"text": "This framework is called Example-Based Machine Translation (EBMT).", "labels": [], "entities": [{"text": "Example-Based Machine Translation (EBMT)", "start_pos": 25, "end_pos": 65, "type": "TASK", "confidence": 0.7379322946071625}]}, {"text": "This paper focuses on ATR's linguistic database of spoken Japanese with English translations.", "labels": [], "entities": [{"text": "ATR's linguistic database of spoken Japanese", "start_pos": 22, "end_pos": 66, "type": "DATASET", "confidence": 0.7962844116347176}]}, {"text": "The corpus contains conversations about international conference registration ().", "labels": [], "entities": [{"text": "international conference registration", "start_pos": 40, "end_pos": 77, "type": "TASK", "confidence": 0.6896936297416687}]}, {"text": "Results of this study indicate that EBMT is a breakthrough in MT technology.", "labels": [], "entities": [{"text": "MT", "start_pos": 62, "end_pos": 64, "type": "TASK", "confidence": 0.996635377407074}]}, {"text": "Our pilot EBMT system translates Japanese noun phrases of the form '~1 x no N2\" into English noun phrases.", "labels": [], "entities": []}, {"text": "About a 78% success rate on average has been achieved in the experiment, which i s considered to outperform RBMT.", "labels": [], "entities": [{"text": "RBMT", "start_pos": 108, "end_pos": 112, "type": "TASK", "confidence": 0.5867915153503418}]}, {"text": "This rate cm be improved as discussed below.", "labels": [], "entities": []}, {"text": "Section 2 explains the basic idea of EBMT.", "labels": [], "entities": []}, {"text": "Section 3 discusses the broad applicability of EBMT and the advantages of integrating it with RBMT.", "labels": [], "entities": [{"text": "EBMT", "start_pos": 47, "end_pos": 51, "type": "DATASET", "confidence": 0.7258639335632324}]}, {"text": "Sections 4 and 5 give a rationale for section 3, i.e., section 4 illustrates the experiment of translating noun phrases of the form \"Nt no N2\" in detail, and section 5 studies other phenomena through actual dam from our corpus.", "labels": [], "entities": []}, {"text": "Section 6 concludes this paper with detailed comparisons between RBMT and EBMT.", "labels": [], "entities": [{"text": "RBMT", "start_pos": 65, "end_pos": 69, "type": "TASK", "confidence": 0.7284349799156189}, {"text": "EBMT", "start_pos": 74, "end_pos": 78, "type": "DATASET", "confidence": 0.8551328778266907}]}], "datasetContent": [{"text": "The current number of words in the corpus is about 300,000 and the number of examples is 2,550.", "labels": [], "entities": []}, {"text": "The collection of examples from another domain is in progress.", "labels": [], "entities": []}], "tableCaptions": []}