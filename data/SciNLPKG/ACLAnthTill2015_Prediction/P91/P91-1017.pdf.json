{"title": [{"text": "Two Languages Are More Informative Than One *", "labels": [], "entities": []}], "abstractContent": [{"text": "This paper presents anew approach for resolving lexical ambiguities in one language using statistical data on lexical relations in another language.", "labels": [], "entities": [{"text": "resolving lexical ambiguities", "start_pos": 38, "end_pos": 67, "type": "TASK", "confidence": 0.8207536141077677}]}, {"text": "This approach exploits the differences between mappings of words to senses in different languages.", "labels": [], "entities": []}, {"text": "We concentrate on the problem of target word selection in machine translation, for which the approach is directly applicable, and employ a statistical model for the selection mechanism.", "labels": [], "entities": [{"text": "target word selection in machine translation", "start_pos": 33, "end_pos": 77, "type": "TASK", "confidence": 0.6508654206991196}]}, {"text": "The model was evaluated using two sets of Hebrew and German examples and was found to be very useful for disambiguation.", "labels": [], "entities": [{"text": "disambiguation", "start_pos": 105, "end_pos": 119, "type": "TASK", "confidence": 0.9771109819412231}]}], "introductionContent": [{"text": "The resolution of hxical ambiguities in non-restricted text is one of the most difficult tasks of natural language processing.", "labels": [], "entities": [{"text": "resolution of hxical ambiguities in non-restricted text", "start_pos": 4, "end_pos": 59, "type": "TASK", "confidence": 0.8751854385648455}, {"text": "natural language processing", "start_pos": 98, "end_pos": 125, "type": "TASK", "confidence": 0.643992563088735}]}, {"text": "A related task in machine translation is target word selection -the task of deciding which target language word is the most appropriate equivalent of a source language word in context.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 18, "end_pos": 37, "type": "TASK", "confidence": 0.785188227891922}, {"text": "target word selection -the task of deciding which target language word is the most appropriate equivalent of a source language word in context", "start_pos": 41, "end_pos": 183, "type": "Description", "confidence": 0.7292361433307329}]}, {"text": "In addition to the alternatives introduced from the different word senses of the source language word, the target language may specify additional alternatives that differ mainly in their usages.", "labels": [], "entities": []}, {"text": "Traditionally various linguistic levels were used to deal with this problem: syntactic, semantic and pragmatic.", "labels": [], "entities": []}, {"text": "Computationally the syntactic methods are the easiest, but are of no avail in the frequent situation when the different senses of the word show *This research was partially supported by grant number 120-741 of the Iarael Council for Research and Development the same syntactic behavior, having the same part of speech and even the same subcategorization frame.", "labels": [], "entities": []}, {"text": "Substantial application of semantic or pragmatic knowledge about the word and its context for broad domains requires compiling huge amounts of knowledge, whose usefulness for practical applications has not yet been proven (.", "labels": [], "entities": [{"text": "Substantial application of semantic or pragmatic knowledge about the word and its context", "start_pos": 0, "end_pos": 89, "type": "TASK", "confidence": 0.6593731825168316}]}, {"text": "Moreover, such methods fail to reflect word usages.", "labels": [], "entities": []}, {"text": "It is known for many years that the use of a word in the language provides information about its meaning.", "labels": [], "entities": []}, {"text": "Also, statistical approaches which were popular few decades ago have recently reawakened and were found useful for computational linguistics.", "labels": [], "entities": [{"text": "computational linguistics", "start_pos": 115, "end_pos": 140, "type": "TASK", "confidence": 0.8234745264053345}]}, {"text": "Consequently, a possible (though partial) alternative to using manually constructed knowledge can be found in the use of statistical data on the occurrence of lexical relations in large corpora.", "labels": [], "entities": []}, {"text": "The use of such relations (mainly relations between verbs or nouns and their arguments and modifiers) for various purposes has received growing attention in recent research.", "labels": [], "entities": []}, {"text": "More specifically, two recent works have suggested to use statistical data on lexical relations for resolving ambiguity cases of PP-attachment) and pronoun references).", "labels": [], "entities": []}, {"text": "Clearly, statistical methods can be useful also for target word selection.", "labels": [], "entities": [{"text": "target word selection", "start_pos": 52, "end_pos": 73, "type": "TASK", "confidence": 0.6604603330294291}]}, {"text": "Consider, for example, the Hebrew sentence extracted from the foreign news section of the daily Haaretz, September 1990 (transcripted to Latin letters).", "labels": [], "entities": [{"text": "Hebrew sentence extracted from the foreign news section of the daily Haaretz, September 1990", "start_pos": 27, "end_pos": 119, "type": "DATASET", "confidence": 0.672424191236496}]}, {"text": "(1) Nose ze maria' mi-shtei ha-mdinot mi-lahtom 'al hoze shalom.", "labels": [], "entities": []}, {"text": "This sentence would translate into English as: (2) That issue prevented the two countries from signing a peace treaty.", "labels": [], "entities": []}, {"text": "The verb 'lab_tom' has four word senses: 'sign', 'seal', 'finish' and 'close'.", "labels": [], "entities": []}, {"text": "Whereas the noun 'hose' means both 'contract' and 'treaty'.", "labels": [], "entities": []}, {"text": "Here the difference is not in the meaning, but in usage.", "labels": [], "entities": []}, {"text": "One possible solution is to consult a Hebrew corpus tagged with word senses, from which we would probably learn that the sense 'sign' of 'lahtom' appears more frequently with 'hoze' as its object than all the other senses.", "labels": [], "entities": []}, {"text": "Thus we should prefer that sense.", "labels": [], "entities": []}, {"text": "However, the size of corpora required to identify lexical relations in abroad domain is huge (tens of millions of words) and therefore it is usually not feasible to have such corpora manually tagged with word senses.", "labels": [], "entities": []}, {"text": "The problem of choosing between 'treaty' and 'contract' cannot be solved using only information on Hebrew, because Hebrew does not distinguish between them.", "labels": [], "entities": []}, {"text": "The solution suggested in this paper is to identify the lexical relationships in corpora of the target language, instead of the source language.", "labels": [], "entities": []}, {"text": "Consulting English corpora of 150 million words, yields the following statistics on single word frequencies: 'sign' appeared 28674 times, 'seal' 2771 times, 'finish' appeared 15595 times, 'close' 38291 times, 'treaty' 7331 times and 'contract' 30757 times.", "labels": [], "entities": []}, {"text": "Using a naive approach of choosing the most frequent word yields (3) *That issue prevented the two countries from closing a peace contract.", "labels": [], "entities": []}, {"text": "This maybe improved upon if we use lexical relations.", "labels": [], "entities": []}, {"text": "We consider word combinations and count how often they appeared in the same syntactic relation as in the ambiguous sentence.", "labels": [], "entities": []}, {"text": "For the above example, among the successfully parsed sentences of the corpus, the noun compound 'peace treaty' appeared 49 times, whereas the compound 'peace contract' did not appear at all; 'to sign a treaty' appeared 79 times while none of the other three alternatives appeared more than twice.", "labels": [], "entities": []}, {"text": "Thus we first prefer 'treaty' to 'contract' because of the noun compound 'peace treaty' and then proceed to prefer 'sign' since it appears most frequently having the object 'treaty' (the order of selection is explained in section 3).", "labels": [], "entities": []}, {"text": "Thus in this case our method yielded the correct translation.", "labels": [], "entities": []}, {"text": "Using this method, we take the point of view that some ambiguity problems are easier to solve at the level of the target language instead of the source language.", "labels": [], "entities": []}, {"text": "The source language sentences are considered as a noisy source for target language sentences, and our task is to devise a target language model that prefers the most reasonable translation.", "labels": [], "entities": []}, {"text": "Machine translation (MT) is thus viewed in part as a recognition problem, and the statistical model we use specifically for target word selection maybe compared with other language models in recognition tasks (e.g. for speech recognition).", "labels": [], "entities": [{"text": "Machine translation (MT)", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.899210524559021}, {"text": "speech recognition", "start_pos": 219, "end_pos": 237, "type": "TASK", "confidence": 0.7943761348724365}]}, {"text": "In contrast to this view, previous approaches in MT typically resolved examples like (1) by stating various constraints in terms of the source language.", "labels": [], "entities": [{"text": "MT", "start_pos": 49, "end_pos": 51, "type": "TASK", "confidence": 0.9900758862495422}]}, {"text": "As explained before, such constraints cannot be acquired automatically and therefore are usually limited in their coverage.", "labels": [], "entities": [{"text": "coverage", "start_pos": 114, "end_pos": 122, "type": "METRIC", "confidence": 0.9256088733673096}]}, {"text": "The experiment conducted to test the statistical model clearly shows that the statistics on lexical relations are very useful for disambiguation.", "labels": [], "entities": []}, {"text": "Most notable is the result for the set of examples for Hebrew to English translation, which was picked randomly from foreign news sections in Israeli press.", "labels": [], "entities": [{"text": "Hebrew to English translation", "start_pos": 55, "end_pos": 84, "type": "TASK", "confidence": 0.6724259853363037}]}, {"text": "For this set, the statistical model was applicable for 70% of the ambiguous words, and its selection was then correct for 92% of the cases.", "labels": [], "entities": []}, {"text": "These results for target word selection in machine translation suggest to use a similar mechanism even if we are interested only in word sense disambiguation within a single language!", "labels": [], "entities": [{"text": "target word selection", "start_pos": 18, "end_pos": 39, "type": "TASK", "confidence": 0.6415152748425802}, {"text": "machine translation", "start_pos": 43, "end_pos": 62, "type": "TASK", "confidence": 0.6686117500066757}, {"text": "word sense disambiguation", "start_pos": 132, "end_pos": 157, "type": "TASK", "confidence": 0.6980141798655192}]}, {"text": "In order to select the right sense of a word, in abroad coverage application, it is useful to identify lexical relations between word senses.", "labels": [], "entities": []}, {"text": "However, within corpora of a single language it is possible to identify automatically only relations at the word level, which are of course not useful for selecting word senses in that language.", "labels": [], "entities": []}, {"text": "This is where other languages can supply the solution, exploiting the fact that the mapping between words and word senses varies significantly among different languages.", "labels": [], "entities": []}, {"text": "For instance, the English words 'sign' and 'seal' correspond to a very large extent to two distinct senses of the Hebrew word 'lab_tom' (from example (1)).", "labels": [], "entities": []}, {"text": "These senses should be distinguished by most applications of Hebrew understanding programs.", "labels": [], "entities": [{"text": "Hebrew understanding", "start_pos": 61, "end_pos": 81, "type": "TASK", "confidence": 0.7706267833709717}]}, {"text": "To make this distinction, it is possible to do the same process that is performed for target word selection, by producing all the English alternatives for the lexical relations involving 'lahtom'.", "labels": [], "entities": [{"text": "target word selection", "start_pos": 86, "end_pos": 107, "type": "TASK", "confidence": 0.699370265007019}]}, {"text": "Then the Hebrew sense which corresponds to the most plausible English lexical relations is preferred.", "labels": [], "entities": []}, {"text": "This process requires a bilingual lexicon which maps each Hebrew sense separately into its possible translations, similar to a Hebrew-Hebrew-English lexicon (like the Oxford English-English-Hebrew dictionary).", "labels": [], "entities": [{"text": "Oxford English-English-Hebrew dictionary", "start_pos": 167, "end_pos": 207, "type": "DATASET", "confidence": 0.8478760917981466}]}, {"text": "In some cases, different senses of a Hebrew word map to the same word also in English.", "labels": [], "entities": []}, {"text": "In these cases, the lexical relations of each sense cannot be identified in an English corpus, and a third language is required to distinguish among these senses.", "labels": [], "entities": []}, {"text": "As along term vision, one can imagine a multilingual corpora based system, which exploits the differences between languages to automatically acquire knowledge about word senses.", "labels": [], "entities": []}, {"text": "As explained above, this knowledge would be crucial for lexical disambiguation, and will also help to refine other types of knowledge acquired from large corpora 1 .", "labels": [], "entities": [{"text": "lexical disambiguation", "start_pos": 56, "end_pos": 78, "type": "TASK", "confidence": 0.7994145452976227}]}], "datasetContent": [{"text": "An experiment was conducted to test the performance of the statistical model in translation from Hebrew and German to English.", "labels": [], "entities": []}, {"text": "Two sets of paragraphs were extracted randomly from current Hebrew and German press.", "labels": [], "entities": []}, {"text": "The Hebrew set contained 10 paragraphs taken from foreign news sections, while the German set contained 12 paragraphs of text not restricted to a specific topic.", "labels": [], "entities": []}, {"text": "Within these paragraphs we have (manually) identified the target word selection ambiguities, using a bilingual dictionary.", "labels": [], "entities": []}, {"text": "Some of the alternative translations in the dictionary were omitted if it was judged that they will not be considered by an actual component of a machine translation program.", "labels": [], "entities": []}, {"text": "These cases included very rare or archaic translations (that would not be contained in an MT lexicon) and alternatives that could be eliminated using syntactic knowledge (as explained in section 2) 2 . For each of the remaining alternatives, it was judged if it can serve as an acceptable translation in the given context.", "labels": [], "entities": []}, {"text": "This a priori judgment was used later to decide whether the selection of the automatic procedure is correct.", "labels": [], "entities": []}, {"text": "As a result of this process, the Hebrew set contained 105 ambiguous words (which had at least one unacceptable translation) and the German set 54 ambiguous words.", "labels": [], "entities": []}, {"text": "Now it was necessary to identify the lexical relations within each of the sentences.", "labels": [], "entities": []}, {"text": "As explained before, this should be done using a source language parser, and then mapping the source relations to the target relations.", "labels": [], "entities": []}, {"text": "At this stage of the research, we still do not have the necessary resources to perform the entire process automatically s, therefore we have approximated it by translating the sentences into English and extracting the lexical relations using the English Slot Grammar (ESG) parser (mc2Due to some technicalities, we have also restricted the experiment to cases in which all the relevant translations of a word consists exactly one English word, which is the most frequent situaticm.", "labels": [], "entities": []}, {"text": "awe are currently integrating this process within GSG (German Slot Gr~nmm') and LMT-GE (the Germs~a to English MT prototype).", "labels": [], "entities": [{"text": "GSG", "start_pos": 50, "end_pos": 53, "type": "DATASET", "confidence": 0.8003714084625244}]}, {"text": "4. Using this parser we have classified the lexical relations to rather general classes of syntactic relations, based on the slot structure of ESG.", "labels": [], "entities": [{"text": "ESG", "start_pos": 143, "end_pos": 146, "type": "DATASET", "confidence": 0.9252969622612}]}, {"text": "The important syntactic relations used were between a verb and its arguments and modifiers (counting as one class all objects, indirect objects, complements and nouns in modifying prepositional phrases) and between a noun and its arguments and modifiers (counting as one class all noun objects, modifying nouns in compounds and nouns in modifying prepositional phrases).", "labels": [], "entities": []}, {"text": "The success of using this general level of syntactic relations indicates that even a rough mapping of source to target language relations would be useful for the statistical model.", "labels": [], "entities": []}, {"text": "The statistics for the alternative English relations in each sentence were extracted from three corpora: The Washington Post articles (about 40 million words), Associated Press news wire (24 million) and the Hansard corpus of the proceedings of the Canadian Parliament (85 million words).", "labels": [], "entities": [{"text": "Washington Post articles", "start_pos": 109, "end_pos": 133, "type": "DATASET", "confidence": 0.8919997215270996}, {"text": "Associated Press news wire", "start_pos": 160, "end_pos": 186, "type": "DATASET", "confidence": 0.8134841918945312}, {"text": "Hansard corpus of the proceedings of the Canadian Parliament", "start_pos": 208, "end_pos": 268, "type": "DATASET", "confidence": 0.9535872605111864}]}, {"text": "The statistics were extracted only from sentences of up to 25 words (to facilitate parsing) which contained altogether about 55 million words.", "labels": [], "entities": [{"text": "parsing", "start_pos": 83, "end_pos": 90, "type": "TASK", "confidence": 0.967777669429779}]}, {"text": "The lexical relations in the corpora were extracted by ESG, in the same way they were extracted for the English version of the example sentences (see fora discussion on using an automatic parser for extracting lexical relations from a corpus, and for the technique of acquiring the statistics).", "labels": [], "entities": [{"text": "ESG", "start_pos": 55, "end_pos": 58, "type": "DATASET", "confidence": 0.8177817463874817}]}, {"text": "The parser failed to produce any parse for about 35% of the sentences, which further reduced the actual size of the corpora which was used.", "labels": [], "entities": []}, {"text": "Two measurements, applicability and precision, are used to evaluate the performance of the statistical model.", "labels": [], "entities": [{"text": "applicability", "start_pos": 18, "end_pos": 31, "type": "METRIC", "confidence": 0.9674094915390015}, {"text": "precision", "start_pos": 36, "end_pos": 45, "type": "METRIC", "confidence": 0.9993674159049988}]}, {"text": "The applicability denotes the proportion of cases for which the model performed a selection, i.e. those cases for which the bound Bapassed the threshold.", "labels": [], "entities": [{"text": "Bapassed", "start_pos": 130, "end_pos": 138, "type": "METRIC", "confidence": 0.9623792767524719}]}, {"text": "The precision denotes the proportion of cases for which the model performed a correct selection out of all the applicable cases.", "labels": [], "entities": [{"text": "precision", "start_pos": 4, "end_pos": 13, "type": "METRIC", "confidence": 0.999030590057373}]}, {"text": "We compare the precision of the model to that of the \"word frequencies\" procedure, which always selects the most frequent target word.", "labels": [], "entities": [{"text": "precision", "start_pos": 15, "end_pos": 24, "type": "METRIC", "confidence": 0.9994010925292969}]}, {"text": "This naive \"straw-man\" is less sophisticated than other methods suggested in the literature but it is useful as a common benchmark (e.g.) since it can 4The parsing process was controlled manually to make sure that we do not get wrong relational representation of the exo amp]es due to parsing errors.", "labels": [], "entities": []}, {"text": "The success rate of the \"word frequencies\" procedure can serve as a measure for the degree of lexical ambiguity in a given set of examples, and thus different methods can be partly compared by their degree of success relative to this procedure.", "labels": [], "entities": []}, {"text": "Out of the 105 ambiguous Hebrew words, for 32 the bound Badid not pass the threshold (applicability of 70%", "labels": [], "entities": []}], "tableCaptions": []}