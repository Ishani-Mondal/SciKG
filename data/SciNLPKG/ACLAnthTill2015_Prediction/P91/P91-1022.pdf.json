{"title": [], "abstractContent": [{"text": "In this paper we describe a statistical technique for aligning sentences with their translations in two parallel corpora.", "labels": [], "entities": []}, {"text": "In addition to certain anchor points that are available in our da.ta, the only information about the sentences that we use for calculating alignments is the number of tokens that they contain.", "labels": [], "entities": [{"text": "calculating alignments", "start_pos": 127, "end_pos": 149, "type": "TASK", "confidence": 0.8545332551002502}]}, {"text": "Because we make no use of the lexical details of the sentence, the alignment computation is fast and therefore practical for application to very large collections of text.", "labels": [], "entities": []}, {"text": "We have used this technique to align several million sentences in the English-French Hans~trd corpora and have achieved an accuracy in excess of 99% in a random selected set of 1000 sentence pairs that we checked by hand.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 123, "end_pos": 131, "type": "METRIC", "confidence": 0.9992853999137878}]}, {"text": "We show that even without the benefit of anchor points the correlation between the lengths of aligned sentences is strong enough that we should expect to achieve an accuracy of between 96% and 97%.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 165, "end_pos": 173, "type": "METRIC", "confidence": 0.9994966983795166}]}, {"text": "Thus, the technique maybe applicable to a wider variety of texts than we have yet tried.", "labels": [], "entities": []}], "introductionContent": [{"text": "Recent work by Brown et al., has quickened anew the long dormant idea of using statistical techniques to carryout machine translation from one natural language to another.", "labels": [], "entities": [{"text": "machine translation from one natural language", "start_pos": 114, "end_pos": 159, "type": "TASK", "confidence": 0.83857528368632}]}, {"text": "The lynchpin of their approach is a. large collection of pairs of sentences that. are mutual translations.", "labels": [], "entities": []}, {"text": "Beyond providing grist to the sta.tistical mill, such pairs of sentences are valuable to researchers in bilingual lexicography and maybe usefifl in other approaches to machine translation.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 168, "end_pos": 187, "type": "TASK", "confidence": 0.7251484990119934}]}, {"text": "In this paper, we consider the problem of extra.cting from pa.raJlel French and F, nglish corpora pairs sentences that are translations of one another.", "labels": [], "entities": []}, {"text": "The task is not trivial because at times a single sentence in one language is translated as two or more sentences in the other language.", "labels": [], "entities": []}, {"text": "At other times a sentence, or even a whole passage, maybe missing from one or the other of the corpora.", "labels": [], "entities": []}, {"text": "If a person is given two parallel texts and asked to match up the sentences in them, it is na.tural for him to look at the words in the sentences.", "labels": [], "entities": []}, {"text": "Elaborating this intuitively appealing insight, researchers at Xerox and at ISSCO have developed alignment Mgodthms that pair sentences according to the words that they contain.", "labels": [], "entities": []}, {"text": "Any such algorithm is necessarily slow and, despite the potential for highly accurate alignment, maybe unsuitable for very large collections of text.", "labels": [], "entities": []}, {"text": "Our algorithm makes no use of the lexical details of the corpora, but deals only with the number of words in each sentence.", "labels": [], "entities": []}, {"text": "Although we have used it only to align parallel French and English corpora from the proceedings of the Canadian Parliament, we expect that our technique wouhl work on other French and English corpora and even on other pairs of languages.", "labels": [], "entities": []}, {"text": "The work of Gale and Church ,, who use a very similar method but measure sentence lengths in characters rather than in words, supports this promise of wider applica.bility.", "labels": [], "entities": []}, {"text": "Our Hansard corpora consist of the llansards from 1973 through 1986.", "labels": [], "entities": [{"text": "Hansard corpora", "start_pos": 4, "end_pos": 19, "type": "DATASET", "confidence": 0.9663910567760468}]}, {"text": "There are two files for each session of parliament: one English and one French.", "labels": [], "entities": []}, {"text": "After converting the obscure text markup language of the raw data.", "labels": [], "entities": []}, {"text": "to TEX , we combined all of the English files into a single, large English corpus and all of the French files into a single, large French corpus.", "labels": [], "entities": [{"text": "TEX", "start_pos": 3, "end_pos": 6, "type": "DATASET", "confidence": 0.8302446603775024}]}, {"text": "We then segmented the text of each corpus into tokens and combined the tokens into groups that we call sentences.", "labels": [], "entities": []}, {"text": "Generally, these conform to the grade-school notion of a sentence: they begin with a capital letter, contain a. verb, and end with some type of sentence-final punctuation.", "labels": [], "entities": []}, {"text": "Occasionally, they fall short of this ideal and so each corpus contains a number of sentence fragments and other groupings of words that we nonetheless refer to as sentences.", "labels": [], "entities": []}, {"text": "With this broad interpretation, the English corpus contains 85,016,286 tokens in 3,510,744 sentences, and the French corpus contains 97,857,452 tokens in 3,690,425 sentences.", "labels": [], "entities": [{"text": "English corpus", "start_pos": 36, "end_pos": 50, "type": "DATASET", "confidence": 0.9304536581039429}, {"text": "French corpus", "start_pos": 110, "end_pos": 123, "type": "DATASET", "confidence": 0.9386218190193176}]}, {"text": "The average English sentence has 24.2 tokens, while the average French sentence is about 9.5% longer with 26.5 tokens.", "labels": [], "entities": []}, {"text": "The left-hand side of shows the raw data fora portion of the English corpus, and the right-hand side shows the same portion after we converted it to TEX and divided it up into sentences.", "labels": [], "entities": [{"text": "English corpus", "start_pos": 61, "end_pos": 75, "type": "DATASET", "confidence": 0.8831765055656433}]}, {"text": "The sentence numbers do not advance regularly because we have edited the sample in order to display a variety of phenolnena.", "labels": [], "entities": []}, {"text": "In addition to a verbatim record of the proceedings and its translation, the ttansards include session numbers, names of speakers, time stamps, question numbers, and indications of the original language in which each speech was delivered.", "labels": [], "entities": []}, {"text": "We retain this auxiliary information in the form of comments sprinkled throughout the text.", "labels": [], "entities": []}, {"text": "Each comment has the form \\SCM{} ...", "labels": [], "entities": []}, {"text": "\\ECM{} as shown on the right-hand side of.", "labels": [], "entities": []}, {"text": "]n addition to these comments, which encode information explicitly present in the data, we inserted Paragraph comments as suggested by the space command of which we see aa example in the eighth line on the left-hand side of.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": []}