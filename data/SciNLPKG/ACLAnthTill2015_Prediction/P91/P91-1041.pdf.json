{"title": [], "abstractContent": [{"text": "Graph unification is the most expensive part of unification-based grammar parsing.", "labels": [], "entities": [{"text": "Graph unification", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.8644666373729706}, {"text": "unification-based grammar parsing", "start_pos": 48, "end_pos": 81, "type": "TASK", "confidence": 0.8347710967063904}]}, {"text": "It often takes over 90% of the total parsing time of a sentence.", "labels": [], "entities": []}, {"text": "We focus on two speed-up elements in the design of unification algorithms: 1) elimination of excessive copying by only copying successful unifications, 2) Finding unification failures as soon as possible.", "labels": [], "entities": [{"text": "unification", "start_pos": 51, "end_pos": 62, "type": "TASK", "confidence": 0.9731770157814026}]}, {"text": "We have developed a scheme to attain these two elements without expensive overhead through temporarily modifying graphs during unification to eliminate copying during unification.", "labels": [], "entities": []}, {"text": "We found that parsing relatively long sentences (requiring about 500 top-level unifications during a parse) using our algorithm is approximately twice as fast as parsing the same sentences using Wrob-lewski's algorithm.", "labels": [], "entities": []}, {"text": "1. Motivation Graph unification is the most expensive part of unification-based grammar parsing systems.", "labels": [], "entities": [{"text": "Motivation Graph unification", "start_pos": 3, "end_pos": 31, "type": "TASK", "confidence": 0.7982471187909445}, {"text": "unification-based grammar parsing", "start_pos": 62, "end_pos": 95, "type": "TASK", "confidence": 0.6732969880104065}]}, {"text": "For example , in the three types of parsing systems currently used at ATR ], all of which use graph unification algorithms based on [Wroblewski, 1987], unification operations consume 85 to 90 percent of the total cpu time devoted to a parse.", "labels": [], "entities": [{"text": "ATR", "start_pos": 70, "end_pos": 73, "type": "DATASET", "confidence": 0.7648819088935852}]}, {"text": "2 The number of unification operations per sentence tends to grow as the grammar gets larger and more complicated.", "labels": [], "entities": []}, {"text": "An unavoidable paradox is that when the natural language system gets larger and the coverage of linguistic phenomena increases the writers of natural language grammars tend to rely more on deeper and more complex path equations (cy-cles and frequent reentrancy) to lessen the complexity of writing the grammar.", "labels": [], "entities": []}, {"text": "As a result, we have seen that the number of unification operations increases rapidly as the coverage of the grammar grows in contrast to the parsing algorithm itself which does not seem to *Visiting Research Scientist.", "labels": [], "entities": []}, {"text": "Local email address: tomabech%al~-la.al~.co.jp@ uunet.UU.NET.", "labels": [], "entities": []}, {"text": "1The three parsing systems are based on: 1.", "labels": [], "entities": []}, {"text": "Earley's algorithm, 2.", "labels": [], "entities": []}, {"text": "2In the large-scale HPSG-based spoken Japanese analysis system developed at ATR, sometimes 98 percent of the elapsed time is devoted to graph unification ([Kogure, 1990]).", "labels": [], "entities": [{"text": "HPSG-based spoken Japanese analysis", "start_pos": 20, "end_pos": 55, "type": "TASK", "confidence": 0.7068073451519012}, {"text": "ATR", "start_pos": 76, "end_pos": 79, "type": "DATASET", "confidence": 0.8847242593765259}, {"text": "graph unification", "start_pos": 136, "end_pos": 153, "type": "TASK", "confidence": 0.7548726499080658}]}, {"text": "Thus, it makes sense to speedup the unification operations to improve the total speed performance of the natural language systems.", "labels": [], "entities": []}, {"text": "Our original unification algorithm was based on [Wroblewskl, 1987] which was chosen in 1988 as the then fastest algorithm available for our application (HPSG based unification grammar, three types of parsers (Earley, Tomita-LR, and active chart), unification with variables and cycles 3 combined with Kasper's ([Kasper, 1987]) scheme for handling disjunctions.", "labels": [], "entities": []}, {"text": "In designing the graph unification algorithm, we have made the following observation which influenced the basic design of the new algorithm described in this paper: Unification does not always succeed.", "labels": [], "entities": [{"text": "graph unification algorithm", "start_pos": 17, "end_pos": 44, "type": "TASK", "confidence": 0.8062184453010559}]}, {"text": "As we will see from the data presented in a later section, when our parsing system operates with a relatively small grammar, about 60 percent of the unifications attempted during a successful parse result in failure.", "labels": [], "entities": []}, {"text": "If a unification falls, any computation performed and memory consumed during the unification is wasted.", "labels": [], "entities": []}, {"text": "As the grammar size increases, the number of unification failures for each successful parse increases 4.", "labels": [], "entities": []}, {"text": "Without completely rewriting the grammar and the parser, it seems difficult to shift any significant amount of the computational burden to the parser in order to reduce the number of unification failures 5.", "labels": [], "entities": []}, {"text": "Another problem that we would like to address in our design, which seems to be well documented in the existing literature is that: Copying is an expensive operation.", "labels": [], "entities": [{"text": "Copying", "start_pos": 131, "end_pos": 138, "type": "TASK", "confidence": 0.9474833011627197}]}], "introductionContent": [], "datasetContent": [{"text": "19h maybe slightly slower becauseour unification recurses twice on a graph: once to unify and once to copy, whereas in incremental unification schemes copying is performed during the same recursion as unifying.", "labels": [], "entities": []}, {"text": "Additional bookkeeping for incremental copying and an additional set-difference operation (i.e, complementarcs(dgl,dg2)) during unify2 may offset this, however.", "labels": [], "entities": []}, {"text": "'Unifs' represents the total number of unifications during a parse (the number of calls to the top-level 'unifydg', and not 'unifyl').", "labels": [], "entities": []}, {"text": "'USrate' represents the ratio of successful unifications to the total number of unifications.", "labels": [], "entities": [{"text": "USrate", "start_pos": 1, "end_pos": 7, "type": "METRIC", "confidence": 0.8123983144760132}]}, {"text": "We parsed each sentence three times on a Symbolics 3620 using both unification methods and took the shortest elapsed time for both methods ('T' represents our scheme, 'W' represents Wroblewski's algorithm with a modification to handle cycles and variables2\u00b0).", "labels": [], "entities": []}, {"text": "Data structures are the same for both unification algorithms (except for additional fields fora node in our algorithm, i.e., comp-arc-list, comp-arcmark, and forward-mark).", "labels": [], "entities": []}, {"text": "Same functions are used to interface with Earley's parser and the same subfunctions are used wherever possible (such as creation and access of arcs) to minimize the differences that are not purely algorithmic.", "labels": [], "entities": []}, {"text": "'Number of copies' represents the number of nodes created during each parse (and does not include the number of arc structures that are created during a parse).", "labels": [], "entities": []}, {"text": "'Number of conses' represents the amount of structure words consed during a parse.", "labels": [], "entities": []}, {"text": "This number represents the real comparison of the amount of space being consumed by each unification algorithm 0ncluding added fields for nodes in our algorithm and arcs that are created in both algorithms).", "labels": [], "entities": []}, {"text": "We used Earley's parsing algorithm for the experiment.", "labels": [], "entities": []}, {"text": "The Japanese grammar is based on HPSG analysis () covering phenomena such as coordination, case adjunction, adjuncts, control, slash categories, zero-pronouns, interrogatives, WH constructs, and some pragmatics (speaker, hearer relations, politeness, etc.)", "labels": [], "entities": []}, {"text": "The grammar covers many of the important linguistic phenomena in conversational Japanese.", "labels": [], "entities": []}, {"text": "The grammar graphs which are converted from the path equations contain 2324 nodes.", "labels": [], "entities": []}, {"text": "We used 16 sentences from a sample telephone conversation dialog which range from very short sentences (one word, i.e., iie 'no') to relatively long ones (such as soredehakochirakarasochiranitourokuyoushiwoookuriitashimasu \" In that case, we [speaker] will send you [hearer] the registration form.').", "labels": [], "entities": []}, {"text": "Thus, the number of (top-level) unifications per sentence varied widely (from 6 to over 500).", "labels": [], "entities": []}, {"text": "~Cycles can be handled in Wroblewski's algorithm by checking whether an arc with the same label already exists when arcs are added to anode.", "labels": [], "entities": []}, {"text": "And ff such an arc already exists, we destructively unify the node which is the destination of the existing arc with the node which is the destination of the arc being added.", "labels": [], "entities": []}, {"text": "If such an arc does not exist, we simply add the arc.", "labels": [], "entities": []}, {"text": "Thus, cycles can be handled very cheaply in Wroblewski's algorithm.", "labels": [], "entities": []}, {"text": "Handling variables in Wroblewski's algorithm is basically the same as in our algorithm (i.e., Pereira's scheme), and the addition of this functionality can be ignored in terms of comparison to our algorithm.", "labels": [], "entities": []}, {"text": "Our algorithm does not require any additional scheme to handle cycles in input dgs.", "labels": [], "entities": []}], "tableCaptions": []}