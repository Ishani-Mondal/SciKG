{"title": [{"text": "Semantic Role Labeling: An Introduction to the Special Issue", "labels": [], "entities": [{"text": "Semantic Role Labeling", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.8173890113830566}]}], "abstractContent": [{"text": "Semantic role labeling, the computational identification and labeling of arguments in text, has become a leading task in computational linguistics today.", "labels": [], "entities": [{"text": "Semantic role labeling", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.7309074004491171}, {"text": "computational identification and labeling of arguments in text", "start_pos": 28, "end_pos": 90, "type": "TASK", "confidence": 0.8455670103430748}]}, {"text": "Although the issues for this task have been studied for decades, the availability of large resources and the development of statistical machine learning methods have heightened the amount of effort in this field.", "labels": [], "entities": []}, {"text": "This special issue presents selected and representative work in the field.", "labels": [], "entities": []}, {"text": "This overview describes linguistic background of the problem, the movement from linguistic theories to computational practice, the major resources that are being used, an overview of steps taken in computational systems, and a description of the key issues and results in semantic role labeling (as revealed in several international evaluations).", "labels": [], "entities": [{"text": "semantic role labeling", "start_pos": 272, "end_pos": 294, "type": "TASK", "confidence": 0.6283699770768484}]}, {"text": "We assess weaknesses in semantic role labeling and identify important challenges facing the field.", "labels": [], "entities": [{"text": "semantic role labeling", "start_pos": 24, "end_pos": 46, "type": "TASK", "confidence": 0.7708960175514221}]}, {"text": "Overall, the opportunities and the potential for useful further research in semantic role labeling are considerable.", "labels": [], "entities": [{"text": "semantic role labeling", "start_pos": 76, "end_pos": 98, "type": "TASK", "confidence": 0.8137660423914591}]}], "introductionContent": [{"text": "The sentence-level semantic analysis of text is concerned with the characterization of events, such as determining \"who\" did \"what\" to \"whom,\" \"where,\" \"when,\" and \"how.\"", "labels": [], "entities": [{"text": "sentence-level semantic analysis of text", "start_pos": 4, "end_pos": 44, "type": "TASK", "confidence": 0.7742427110671997}]}, {"text": "The predicate of a clause (typically a verb) establishes \"what\" took place, and other sentence constituents express the participants in the event (such as \"who\" and \"where\"), as well as further event properties (such as \"when\" and \"how\").", "labels": [], "entities": []}, {"text": "The primary task of semantic role labeling (SRL) is to indicate exactly what semantic relations hold among a predicate and its associated participants and properties, with these relations drawn from a pre-specified list of possible semantic roles for that predicate (or class of predicates).", "labels": [], "entities": [{"text": "semantic role labeling (SRL)", "start_pos": 20, "end_pos": 48, "type": "TASK", "confidence": 0.8042363027731577}]}, {"text": "In order to accomplish this, the role-bearing constituents in a clause must be identified and their correct semantic role labels assigned, as in: [The girl on the swing] [whispered] Pred to [the boy beside her] Recipient Typical roles used in SRL are labels such as Agent, Patient, and Location for the entities participating in an event, and Temporal and Manner for the characterization of other aspects of the event or participant relations.", "labels": [], "entities": [{"text": "Pred", "start_pos": 182, "end_pos": 186, "type": "METRIC", "confidence": 0.9664486646652222}, {"text": "SRL", "start_pos": 243, "end_pos": 246, "type": "TASK", "confidence": 0.9722983241081238}, {"text": "Manner", "start_pos": 356, "end_pos": 362, "type": "METRIC", "confidence": 0.8353162407875061}]}, {"text": "This type of role labeling thus yields a firstlevel semantic representation of the text that indicates the basic event properties and relations among relevant entities that are expressed in the sentence.", "labels": [], "entities": [{"text": "role labeling", "start_pos": 13, "end_pos": 26, "type": "TASK", "confidence": 0.730532169342041}]}, {"text": "Research has proceeded for decades on manually created lexicons, grammars, and other semantic resources in support of deep semantic analysis of language input, but such approaches have been labor-intensive and often restricted to narrow domains.", "labels": [], "entities": [{"text": "deep semantic analysis of language input", "start_pos": 118, "end_pos": 158, "type": "TASK", "confidence": 0.7664800882339478}]}, {"text": "The 1990s saw a growth in the development of statistical machine learning methods across the field of computational linguistics, enabling systems to learn complex linguistic knowledge rather than requiring manual encoding.", "labels": [], "entities": []}, {"text": "These methods were shown to be effective in acquiring knowledge necessary for semantic interpretation, such as the properties of predicates and the relations to their arguments-for example, learning subcategorization frames or classifying verbs according to argument structure properties ().", "labels": [], "entities": [{"text": "semantic interpretation", "start_pos": 78, "end_pos": 101, "type": "TASK", "confidence": 0.7351920157670975}]}, {"text": "Recently, medium-to-large corpora have been manually annotated with semantic roles in FrameNet,, and NomBank (), enabling the development of statistical approaches specifically for SRL.", "labels": [], "entities": [{"text": "FrameNet", "start_pos": 86, "end_pos": 94, "type": "DATASET", "confidence": 0.8945536613464355}, {"text": "SRL", "start_pos": 181, "end_pos": 184, "type": "TASK", "confidence": 0.9877079129219055}]}, {"text": "With the advent of supporting resources, SRL has become a well-defined task with a substantial body of work and comparative evaluation (see, among others, Gildea and Jurafsky, Surdeanu et al.,,, the CoNLL Shared Task in.", "labels": [], "entities": [{"text": "SRL", "start_pos": 41, "end_pos": 44, "type": "TASK", "confidence": 0.9715175628662109}]}, {"text": "The identification of event frames may potentially benefit many natural language processing (NLP) applications, such as information extraction (), question answering (Narayanan and Harabagiu 2004), summarization (), and machine translation.", "labels": [], "entities": [{"text": "information extraction", "start_pos": 120, "end_pos": 142, "type": "TASK", "confidence": 0.8210015892982483}, {"text": "question answering", "start_pos": 147, "end_pos": 165, "type": "TASK", "confidence": 0.9161674976348877}, {"text": "summarization", "start_pos": 198, "end_pos": 211, "type": "TASK", "confidence": 0.9903703331947327}, {"text": "machine translation", "start_pos": 220, "end_pos": 239, "type": "TASK", "confidence": 0.8182863593101501}]}, {"text": "Related work on classifying the semantic relations in noun phrases has also been encouraging for NLP tasks (.", "labels": [], "entities": [{"text": "classifying the semantic relations in noun phrases", "start_pos": 16, "end_pos": 66, "type": "TASK", "confidence": 0.8740409697805133}]}, {"text": "Although the use of SRL systems in real-world applications has thus far been limited, the outlook is promising for extending this type of analysis to many applications requiring some level of semantic interpretation.", "labels": [], "entities": [{"text": "SRL", "start_pos": 20, "end_pos": 23, "type": "TASK", "confidence": 0.9765560030937195}, {"text": "semantic interpretation", "start_pos": 192, "end_pos": 215, "type": "TASK", "confidence": 0.7236432135105133}]}, {"text": "SRL represents an excellent framework with which to perform research on computational techniques for acquiring and exploiting semantic relations among the different components of a text.", "labels": [], "entities": [{"text": "SRL", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.7386314868927002}]}, {"text": "This special issue of Computational Linguistics presents several articles representing the state-of-the-art in SRL, and this overview is intended to provide a broader context for that work.", "labels": [], "entities": [{"text": "Computational Linguistics", "start_pos": 22, "end_pos": 47, "type": "TASK", "confidence": 0.791080504655838}, {"text": "SRL", "start_pos": 111, "end_pos": 114, "type": "TASK", "confidence": 0.9743567109107971}]}, {"text": "First, we briefly discuss some of the linguistic views on semantic roles that have had the most influence on computational approaches to SRL and related NLP tasks.", "labels": [], "entities": [{"text": "SRL", "start_pos": 137, "end_pos": 140, "type": "TASK", "confidence": 0.9937289953231812}]}, {"text": "Next, we show how the linguistic notions have influenced the development of resources that support SRL.", "labels": [], "entities": [{"text": "SRL", "start_pos": 99, "end_pos": 102, "type": "TASK", "confidence": 0.9830896854400635}]}, {"text": "We then provide an overview of SRL methods and describe the state-of-the-art as well as current open problems in the field.", "labels": [], "entities": [{"text": "SRL", "start_pos": 31, "end_pos": 34, "type": "TASK", "confidence": 0.991323709487915}]}], "datasetContent": [{"text": "Many experimental studies have been conducted since the work of, including seven international evaluation tasks in ACL-related conferences and workshops: the SIGNLL CoNLL shared tasks in), the SIGLEX Senseval-3 in 2004), and four tasks in the SIGLEX SemEval in 2007 (.", "labels": [], "entities": [{"text": "SIGNLL CoNLL shared tasks", "start_pos": 158, "end_pos": 183, "type": "TASK", "confidence": 0.6226360946893692}]}, {"text": "In the subsequent sections, we summarize their main features, results, and conclusions, although note that the scores are not directly comparable across different exercises, due to differences in scoring and in the experimental methodologies.", "labels": [], "entities": []}, {"text": "The standard experiment in automatic SRL can be defined as follows: Given a sentence and a target predicate appearing in it, find the arguments of the predicate and label them with semantic roles.", "labels": [], "entities": [{"text": "SRL", "start_pos": 37, "end_pos": 40, "type": "TASK", "confidence": 0.7819073796272278}]}, {"text": "A system is evaluated in terms of precision, recall, and F 1 of the labeled arguments.", "labels": [], "entities": [{"text": "precision", "start_pos": 34, "end_pos": 43, "type": "METRIC", "confidence": 0.9996495246887207}, {"text": "recall", "start_pos": 45, "end_pos": 51, "type": "METRIC", "confidence": 0.9997177720069885}, {"text": "F 1", "start_pos": 57, "end_pos": 60, "type": "METRIC", "confidence": 0.9855509698390961}]}, {"text": "In evaluating a system, an argument is considered correct when both its boundaries and the semantic role label match a gold standard.", "labels": [], "entities": []}, {"text": "Performance can be divided into two components: (1) the precision, recall, and F 1 of unlabeled arguments, measuring the accuracy of the system at segmenting the sentence; and (2) the classification accuracy of assigning semantic roles to the arguments that have been correctly identified.", "labels": [], "entities": [{"text": "precision", "start_pos": 56, "end_pos": 65, "type": "METRIC", "confidence": 0.9995242357254028}, {"text": "recall", "start_pos": 67, "end_pos": 73, "type": "METRIC", "confidence": 0.9979841709136963}, {"text": "F 1", "start_pos": 79, "end_pos": 82, "type": "METRIC", "confidence": 0.9853302836418152}, {"text": "accuracy", "start_pos": 121, "end_pos": 129, "type": "METRIC", "confidence": 0.9980294108390808}, {"text": "accuracy", "start_pos": 199, "end_pos": 207, "type": "METRIC", "confidence": 0.9736294150352478}]}, {"text": "In calculating the metrics, the de facto standard is to give credit only when a proposed argument perfectly matches an argument in the reference solution; nonetheless, variants that give some credit for partial matching also exist.", "labels": [], "entities": []}, {"text": "To date, most experimental work has made use of English data annotated either with PropBank or FrameNet semantic roles.", "labels": [], "entities": [{"text": "PropBank", "start_pos": 83, "end_pos": 91, "type": "DATASET", "confidence": 0.8971797227859497}]}, {"text": "The CoNLL shared tasks in 2004 and 2005 were based on PropBank (Carreras and M` arquez), which is the largest evaluation benchmark available today, and also the most used by researchers-all articles in this special issue dealing with English use this benchmark.", "labels": [], "entities": [{"text": "PropBank", "start_pos": 54, "end_pos": 62, "type": "DATASET", "confidence": 0.7925726771354675}]}, {"text": "In the evaluation, the best systems obtained an F 1 score of \u223c80%, and have achieved only minimal improvements since then.", "labels": [], "entities": [{"text": "F 1 score", "start_pos": 48, "end_pos": 57, "type": "METRIC", "confidence": 0.9928407669067383}]}, {"text": "The articles in this issue by Punyakanok, Roth, and Yih; Toutanova, Haghighi, and Manning; and Pradhan, Ward, and Martin describe such efforts.", "labels": [], "entities": []}, {"text": "An analysis of the outputs in showed that argument identification accounts for most of the errors: a system will recall \u223c81% of the correct unlabeled arguments, and \u223c95% of those will be assigned the correct semantic role.", "labels": [], "entities": [{"text": "argument identification", "start_pos": 42, "end_pos": 65, "type": "TASK", "confidence": 0.7766744792461395}]}, {"text": "The analysis also showed that systems recognized core arguments better than adjuncts (with F 1 scores from the high 60s to the high 80s for the former, but below 60% for the latter).", "labels": [], "entities": [{"text": "F 1 scores", "start_pos": 91, "end_pos": 101, "type": "METRIC", "confidence": 0.9866592685381571}]}, {"text": "Finally, it was also observed that, although systems performed better on verbs appearing frequently in training, the best systems could recognize arguments of unseen verbs with an F 1 in the low 70s, not far from the overall performance.", "labels": [], "entities": [{"text": "F 1", "start_pos": 180, "end_pos": 183, "type": "METRIC", "confidence": 0.9674809873104095}]}, {"text": "SemEval-2007 included a task on semantic evaluation for English, combining word sense disambiguation and SRL based on PropBank (.", "labels": [], "entities": [{"text": "semantic evaluation", "start_pos": 32, "end_pos": 51, "type": "TASK", "confidence": 0.6994398534297943}, {"text": "word sense disambiguation", "start_pos": 75, "end_pos": 100, "type": "TASK", "confidence": 0.6170129974683126}, {"text": "PropBank", "start_pos": 118, "end_pos": 126, "type": "DATASET", "confidence": 0.9363871216773987}]}, {"text": "Unlike the CoNLL tasks, this task concentrated on 50 selected verbs.", "labels": [], "entities": []}, {"text": "Interestingly, the data was annotated using verb-independent roles using the PropBank/VerbNet mapping from.", "labels": [], "entities": [{"text": "PropBank/VerbNet mapping", "start_pos": 77, "end_pos": 101, "type": "DATASET", "confidence": 0.8662034124135971}]}, {"text": "The two participating systems could predict VerbNet roles as accurately as PropBank verb-dependent roles.", "labels": [], "entities": []}, {"text": "Experiments based on FrameNet usually concentrate on a selected list of frames.", "labels": [], "entities": [{"text": "FrameNet", "start_pos": 21, "end_pos": 29, "type": "DATASET", "confidence": 0.8051499724388123}]}, {"text": "In Senseval-3, 40 frames were selected for an SRL task with the goal of replicating and improving on them).", "labels": [], "entities": [{"text": "SRL task", "start_pos": 46, "end_pos": 54, "type": "TASK", "confidence": 0.911112517118454}]}, {"text": "Participants were evaluated on assigning semantic roles to given arguments, with best F 1 of 92%, and on the task of segmenting and labeling arguments, with best F 1 of 83%.", "labels": [], "entities": [{"text": "F 1", "start_pos": 86, "end_pos": 89, "type": "METRIC", "confidence": 0.9863777160644531}, {"text": "F 1", "start_pos": 162, "end_pos": 165, "type": "METRIC", "confidence": 0.9759231209754944}]}, {"text": "SemEval-2007 also included an SRL task based on FrameNet.", "labels": [], "entities": [{"text": "SRL task", "start_pos": 30, "end_pos": 38, "type": "TASK", "confidence": 0.9029483795166016}, {"text": "FrameNet", "start_pos": 48, "end_pos": 56, "type": "DATASET", "confidence": 0.9166969060897827}]}, {"text": "It was much more complete, realistic, and difficult than its predecessor in Senseval-3.", "labels": [], "entities": []}, {"text": "The goal was to perform complete analysis of semantic roles on unseen texts, first determining the appropriate frames of predicates, and then determining their arguments labeled with semantic roles.", "labels": [], "entities": []}, {"text": "It also involved creating a graph of the sentence representing part of its semantics, by means of frames and labeled arguments.", "labels": [], "entities": []}, {"text": "The test data of this task consisted of novel manually-annotated documents, containing a number of frames and roles not in the FrameNet lexicon.", "labels": [], "entities": [{"text": "FrameNet lexicon", "start_pos": 127, "end_pos": 143, "type": "DATASET", "confidence": 0.9179539084434509}]}, {"text": "Three teams submitted results, with precision percentages in the 60s, but recall percentages only in the 30s.", "labels": [], "entities": [{"text": "precision percentages", "start_pos": 36, "end_pos": 57, "type": "METRIC", "confidence": 0.9847332835197449}, {"text": "recall percentages", "start_pos": 74, "end_pos": 92, "type": "METRIC", "confidence": 0.9868341088294983}]}, {"text": "To our knowledge, there is no evidence to date on the relative difficulty of assigning FrameNet or PropBank roles.", "labels": [], "entities": []}], "tableCaptions": []}