{"title": [], "abstractContent": [{"text": "In computational linguistics, a reliability measurement of 0.8 on some statistic such as \u03ba is widely thought to guarantee that hand-coded data is fit for purpose, with 0.67 to 0.8 tolerable, and lower values suspect.", "labels": [], "entities": []}, {"text": "We demonstrate that the main use of such data, machine learning, can tolerate data with low reliability as long as any disagreement among human coders looks like random noise.", "labels": [], "entities": []}, {"text": "When the disagreement introduces patterns, however, the machine learner can pick these up just like it picks up the real patterns in the data, making the performance figures look better than they really are.", "labels": [], "entities": []}, {"text": "For the range of reliability measures that the field currently accepts, disagreement can appreciably inflate performance figures, and even a measure of 0.8 does not guarantee that what looks like good performance really is.", "labels": [], "entities": []}, {"text": "Although this is a commonsense result, it has implications for how we work.", "labels": [], "entities": []}, {"text": "At the very least, computational linguists should look for any patterns in the disagreement among coders and assess what impact they will have.", "labels": [], "entities": []}], "introductionContent": [{"text": "In computational linguistics, 0.8 is often regarded as some kind of magical reliability cut-off guaranteeing the quality of hand-coded data (e.g.,), with 0.67 to 0.8 tolerable-although it is as often honored in the breech as in the observance.", "labels": [], "entities": []}, {"text": "The argument for the meaning of 0.8 arises originally from, in a comment about practice in the field of content analysis.", "labels": [], "entities": [{"text": "content analysis", "start_pos": 104, "end_pos": 120, "type": "TASK", "confidence": 0.7391132265329361}]}, {"text": "He states that correlations found between two variables using their hand-coded values \"tend to be insignificant\" when the hand-codings have a reliability below 0.8.", "labels": [], "entities": []}, {"text": "He uses a specific reliability statistic, \u03b1, for his measurements, but implicitly assumes kappa-like metrics are similar enough in practice for the rule of thumb to apply to them as well.", "labels": [], "entities": []}, {"text": "A detailed discussion on the differences and similarities of these, and other, measures is provided by; in this article we will use Cohen's \u03ba to investigate the value of the 0.8 reliability cut-off for computational linguistics.", "labels": [], "entities": []}, {"text": "Modern computational linguists use data in a completely different way from 1970s content analysts.", "labels": [], "entities": []}, {"text": "Rather than correlating two variables, we use hand-coded data as training and test material for automatic classifiers.", "labels": [], "entities": []}, {"text": "The 0.8 rule of thumb is irrelevant for this purpose, because classifiers will be affected by disagreement differently than correlations.", "labels": [], "entities": []}, {"text": "Furthermore, Krippendorff's argument comes with a caveat: the disagreement must be due to random noise.", "labels": [], "entities": []}, {"text": "For his case of correlations, any patterns in the disagreement could accidentally bolster the relationship perceived in the data, leading to false results.", "labels": [], "entities": []}, {"text": "To be sure that data is fit for the intended purpose, Krippendorff advises the analyst to look for structure in the disagreement and consider how it might affect data use.", "labels": [], "entities": []}, {"text": "Although computational linguists have rarely followed this advice, it is just as relevant to us.", "labels": [], "entities": []}, {"text": "Machine-learning algorithms are designed specifically to look for, and predict, patterns in noisy data.", "labels": [], "entities": []}, {"text": "In theory, this makes random disagreement unimportant.", "labels": [], "entities": []}, {"text": "More data will yield more signal and the learner will ignore the noise.", "labels": [], "entities": []}, {"text": "However, as suggest, this also makes systematic disagreement dangerous, because it provides an unwanted pattern for the learner to detect.", "labels": [], "entities": []}, {"text": "We demonstrate that machine learning can tolerate data with a low reliability measurement as long as the disagreement looks like random noise, and that when it does not, data can have a reliability measure commonly held to be acceptable but produce misleading results.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": []}