{"title": [{"text": "Algorithms for Deterministic Incremental Dependency Parsing", "labels": [], "entities": [{"text": "Deterministic Incremental Dependency Parsing", "start_pos": 15, "end_pos": 59, "type": "TASK", "confidence": 0.5935956239700317}]}], "abstractContent": [{"text": "Parsing algorithms that process the input from left to right and construct a single derivation have often been considered inadequate for natural language parsing because of the massive ambiguity typically found in natural language grammars.", "labels": [], "entities": [{"text": "natural language parsing", "start_pos": 137, "end_pos": 161, "type": "TASK", "confidence": 0.6555949250857035}]}, {"text": "Nevertheless, it has been shown that such algorithms, combined with treebank-induced classifiers, can be used to build highly accurate disambiguating parsers, in particular for dependency-based syntactic representations.", "labels": [], "entities": []}, {"text": "In this article, we first present a general framework for describing and analyzing algorithms for deterministic incremental dependency parsing, formalized as transition systems.", "labels": [], "entities": [{"text": "deterministic incremental dependency parsing", "start_pos": 98, "end_pos": 142, "type": "TASK", "confidence": 0.5969068706035614}]}, {"text": "We then describe and analyze two families of such algorithms: stack-based and list-based algorithms.", "labels": [], "entities": []}, {"text": "In the former family, which is restricted to projective dependency structures, we describe an arc-eager and an arc-standard variant; in the latter family, we present a projective and a non-projective variant.", "labels": [], "entities": []}, {"text": "For each of the four algorithms, we give proofs of correctness and complexity.", "labels": [], "entities": [{"text": "correctness", "start_pos": 51, "end_pos": 62, "type": "METRIC", "confidence": 0.9579499959945679}]}, {"text": "In addition, we perform an experimental evaluation of all algorithms in combination with SVM classifiers for predicting the next parsing action, using data from thirteen languages.", "labels": [], "entities": [{"text": "predicting the next parsing action", "start_pos": 109, "end_pos": 143, "type": "TASK", "confidence": 0.7660829067230225}]}, {"text": "We show that all four algorithms give competitive accuracy, although the non-projective list-based algorithm generally outperforms the projective algorithms for languages with a non-negligible proportion of non-projective constructions.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 50, "end_pos": 58, "type": "METRIC", "confidence": 0.9970334768295288}]}, {"text": "However, the projective algorithms often produce comparable results when combined with the technique known as pseudo-projective parsing.", "labels": [], "entities": []}, {"text": "The linear time complexity of the stack-based algorithms gives them an advantage with respect to efficiency both in learning and in parsing, but the projective list-based algorithm turns out to be equally efficient in practice.", "labels": [], "entities": [{"text": "parsing", "start_pos": 132, "end_pos": 139, "type": "TASK", "confidence": 0.9703488945960999}]}, {"text": "Moreover, when the projective algorithms are used to implement pseudo-projective parsing, they sometimes become less efficient in parsing (but not in learning) than the non-projective list-based algorithm.", "labels": [], "entities": [{"text": "parsing", "start_pos": 130, "end_pos": 137, "type": "TASK", "confidence": 0.9622740745544434}]}, {"text": "Although most of the algorithms have been partially described in the literature before, this is the first comprehensive analysis and evaluation of the algorithms within a unified framework.", "labels": [], "entities": []}], "introductionContent": [{"text": "Because parsers for natural language have to cope with a high degree of ambiguity and nondeterminism, they are typically based on different techniques than the ones used for parsing well-defined formal languages-for example, in compilers for Nivre Deterministic Incremental Dependency Parsing of elementary parsing actions; a feature model, which defines a feature vector representation of the parser state at any given time; and a classifier, which maps parser states, as represented by the feature model, to parsing actions.", "labels": [], "entities": [{"text": "Nivre Deterministic Incremental Dependency Parsing of elementary parsing actions", "start_pos": 242, "end_pos": 322, "type": "TASK", "confidence": 0.7179764442973666}]}, {"text": "Although different types of parsing algorithms, feature models, and classifiers have been used for deterministic dependency parsing, there are very few studies that compare the impact of different components.", "labels": [], "entities": [{"text": "deterministic dependency parsing", "start_pos": 99, "end_pos": 131, "type": "TASK", "confidence": 0.6178566515445709}]}, {"text": "The notable exceptions are Cheng, Asahara, and, who compare two different algorithms and two types of classifier for parsing, who compare two types of classifiers and several types of feature models for parsing In this article, we focus on parsing algorithms.", "labels": [], "entities": [{"text": "parsing", "start_pos": 117, "end_pos": 124, "type": "TASK", "confidence": 0.9688137173652649}, {"text": "parsing", "start_pos": 240, "end_pos": 247, "type": "TASK", "confidence": 0.9724388122558594}]}, {"text": "More precisely, we describe two families of algorithms that can be used for deterministic dependency parsing, supported by classifiers for predicting the next parsing action.", "labels": [], "entities": [{"text": "deterministic dependency parsing", "start_pos": 76, "end_pos": 108, "type": "TASK", "confidence": 0.6162971059481303}, {"text": "predicting the next parsing action", "start_pos": 139, "end_pos": 173, "type": "TASK", "confidence": 0.735606849193573}]}, {"text": "The first family uses a stack to store partially processed tokens and is restricted to the derivation of projective dependency structures.", "labels": [], "entities": []}, {"text": "The algorithms of,, and Nivre) all belong to this family.", "labels": [], "entities": []}, {"text": "The second family, represented by the algorithms described by and recently explored for classifierbased parsing in , instead uses open lists for partially processed tokens, which allows arbitrary dependency structures to be processed (in particular, structures with non-projective dependencies).", "labels": [], "entities": [{"text": "classifierbased parsing", "start_pos": 88, "end_pos": 111, "type": "TASK", "confidence": 0.7358881235122681}]}, {"text": "We provide a detailed analysis of four different algorithms, two from each family, and give proofs of correctness and complexity for each algorithm.", "labels": [], "entities": [{"text": "correctness", "start_pos": 102, "end_pos": 113, "type": "METRIC", "confidence": 0.9749863743782043}]}, {"text": "In addition, we perform an experimental evaluation of accuracy and efficiency for the four algorithms, combined with state-of-the-art classifiers, using data from 13 different languages.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 54, "end_pos": 62, "type": "METRIC", "confidence": 0.9994136095046997}]}, {"text": "Although variants of these algorithms have been partially described in the literature before, this is the first comprehensive analysis and evaluation of the algorithms within a unified framework.", "labels": [], "entities": []}, {"text": "The remainder of the article is structured as follows.", "labels": [], "entities": []}, {"text": "Section 2 defines the task of dependency parsing and Section 3 presents a formal framework for the characterization of deterministic incremental parsing algorithms.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 30, "end_pos": 48, "type": "TASK", "confidence": 0.7654306590557098}, {"text": "deterministic incremental parsing algorithms", "start_pos": 119, "end_pos": 163, "type": "TASK", "confidence": 0.6726474463939667}]}, {"text": "Sections 4 and 5 contain the formal analysis of four different algorithms, defined within the formal framework, with proofs of correctness and complexity.", "labels": [], "entities": []}, {"text": "Section 6 presents the experimental evaluation; Section 7 reports on related work; and Section 8 contains our main conclusions.", "labels": [], "entities": []}], "datasetContent": [{"text": "We have defined four different transition systems for incremental dependency parsing, proven their correctness for different classes of dependency graphs, and analyzed their time and space complexity under the assumption that there exists a constant-time oracle for predicting the next transition.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 66, "end_pos": 84, "type": "TASK", "confidence": 0.7082564681768417}]}, {"text": "In this section, we present an experimental evaluation of the accuracy and efficiency that can be achieved with these systems in deterministic data-driven parsing, that is, when the oracle is approximated by a classifier trained on treebank data.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 62, "end_pos": 70, "type": "METRIC", "confidence": 0.9989709854125977}]}, {"text": "The purpose of the evaluation is to compare the performance of the four algorithms under realistic conditions, thereby complementing the purely formal analysis presented so far.", "labels": [], "entities": []}, {"text": "The purpose is not to produce state-of-the-art results for all algorithms on the data sets used, which would require extensive experimentation and optimization going well beyond the limits of this study.", "labels": [], "entities": []}, {"text": "The data sets used are taken from the CoNLL-X shared task on multilingual dependency parsing).", "labels": [], "entities": [{"text": "multilingual dependency parsing", "start_pos": 61, "end_pos": 92, "type": "TASK", "confidence": 0.5070864061514536}]}, {"text": "We have used all the available data sets, taken Data sets.", "labels": [], "entities": []}, {"text": "Tok = number of tokens (\u00d71000); Sen = number of sentences (\u00d71000); T/S = tokens per sentence (mean); Lem = lemmatization present; CPoS = number of coarse-grained part-of-speech tags; PoS = number of (fine-grained) part-of-speech tags; MSF = number of morphosyntactic features (split into atoms); Dep = number of dependency types; NPT = proportion of non-projective dependencies/tokens (%); NPS = proportion of non-projective dependency graphs/sentences (%). from treebanks of thirteen different languages with considerable typological variation.", "labels": [], "entities": []}, {"text": "gives an overview of the training data available for each language.", "labels": [], "entities": []}, {"text": "For data sets that include a non-negligible proportion of non-projective dependency graphs, it can be expected that the non-projective list-based algorithm will achieve higher accuracy than the strictly projective algorithms.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 176, "end_pos": 184, "type": "METRIC", "confidence": 0.9963483214378357}]}, {"text": "In order to make the comparison more fair, we therefore also evaluate pseudo-projective versions of the latter algorithms, making use of graph transformations in pre-and post-processing to recover nonprojective dependency arcs, following.", "labels": [], "entities": []}, {"text": "For each language, seven different parsers were therefore trained as follows:", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1  Data sets. Tok = number of tokens (\u00d71000); Sen = number of sentences (\u00d71000); T/S = tokens  per sentence (mean); Lem = lemmatization present; CPoS = number of coarse-grained  part-of-speech tags; PoS = number of (fine-grained) part-of-speech tags; MSF = number of  morphosyntactic features (split into atoms); Dep = number of dependency types; NPT =  proportion of non-projective dependencies/tokens (%); NPS = proportion of non-projective  dependency graphs/sentences (%).", "labels": [], "entities": []}, {"text": " Table 3  Parsing accuracy for 7 parsers on 13 languages, measured by labeled attachment score (LAS),  unlabeled attachment score (UAS) and label accuracy (LA). NP-L = non-projective list-based;  P-L = projective list-based; PP-L = pseudo-projective list-based; P-E = projective arc-eager  stack-based; PP-E = pseudo-projective arc-eager stack-based; P-S = projective arc-standard  stack-based; PP-S = pseudo-projective arc-standard stack-based; McD = McDonald, Lerman  and Pereira", "labels": [], "entities": [{"text": "accuracy", "start_pos": 18, "end_pos": 26, "type": "METRIC", "confidence": 0.9353090524673462}, {"text": "labeled attachment score (LAS)", "start_pos": 70, "end_pos": 100, "type": "METRIC", "confidence": 0.8275300016005834}, {"text": "unlabeled attachment score (UAS)", "start_pos": 103, "end_pos": 135, "type": "METRIC", "confidence": 0.8097135027249655}, {"text": "label accuracy (LA)", "start_pos": 140, "end_pos": 159, "type": "METRIC", "confidence": 0.8892278790473938}]}]}