{"title": [{"text": "Last Words On Becoming a Discipline", "labels": [], "entities": []}], "abstractContent": [{"text": "The title of this column, Last Words, reminds me of an occasion in 2005, when I had the privilege of attending the award ceremony for the prestigious Benjamin Franklin Medal, given annually to a few scientists who have made outstanding lifetime contributions to science.", "labels": [], "entities": [{"text": "Benjamin Franklin Medal", "start_pos": 150, "end_pos": 173, "type": "DATASET", "confidence": 0.8613676826159159}]}, {"text": "This time, a computational linguist, Aravind Joshi, was among them, so several past, present, and future presidents and officers of the ACL joined the Great and the Good at the ceremony at the Franklin Institute in Philadelphia.", "labels": [], "entities": []}, {"text": "The eight medal recipients were each represented by a short video presentation, which mostly consisted of voice-over by a narrator, interspersed with sound-bites from the recipients about their life and work, in the last of which they had clearly been asked to deliver as their last words a brief take-home message.", "labels": [], "entities": []}, {"text": "I couldn't help noticing that the warmest applause was reserved for the physicist, a distinguished pioneer of string theory.", "labels": [], "entities": []}, {"text": "I was initially puzzled by the enthusiasm on the part of a mostly lay audience for such theoretical work, which for all its elegance and beauty, could not (as far as I could see) be expected to have nearly as much impact on their everyday lives as that of some of the other recipients, who that year included not only Aravind, but another computer scientist whose impact on information processing will be obvious to the members of ACL, Andrew Viterbi.", "labels": [], "entities": [{"text": "information processing", "start_pos": 374, "end_pos": 396, "type": "TASK", "confidence": 0.767849862575531}]}, {"text": "But then I recalled that the physicist's take-home message had had nothing to do with string theory.", "labels": [], "entities": [{"text": "string theory", "start_pos": 86, "end_pos": 99, "type": "TASK", "confidence": 0.7007848918437958}]}, {"text": "This admirable man's last words to us had been the following: Everything is made of particles.", "labels": [], "entities": []}, {"text": "So physics is very important.", "labels": [], "entities": []}], "introductionContent": [], "datasetContent": [{"text": "So, how much progress have we made?", "labels": [], "entities": []}, {"text": "We can repeat the back-translation experiment with Google Language Tools Beta n-gram-and-finite-state-transducer-based Arabic SMT.", "labels": [], "entities": []}, {"text": "(The first line is the English input, the Arabic is its SMT translation, the third line is a gloss of the Arabic words, and the last line is the result of translating the Arabic back again by SMT.)", "labels": [], "entities": [{"text": "SMT translation", "start_pos": 56, "end_pos": 71, "type": "TASK", "confidence": 0.8994344472885132}, {"text": "SMT", "start_pos": 192, "end_pos": 195, "type": "TASK", "confidence": 0.8493042588233948}]}, {"text": "On the basis of the result of the back-translation, this looks OK, give or take a bit of morphology, but of course end-to-end back-translation is a very weak test, where you can just get lucky.", "labels": [], "entities": []}, {"text": "Readers of Arabic will notice that the translation of like is indeed a comparative, not a verb meaning enjoy, as in the legend.", "labels": [], "entities": []}, {"text": "However, they will also notice that flies translates as the noun, rather than the verb, just as the story foretold.", "labels": [], "entities": []}, {"text": "If we try the same test on Fruit flies like a banana, the flies are still insects, but like is still comparative, rather than a verb.", "labels": [], "entities": []}, {"text": "So the two sentences are analyzed the same way, as in the story.", "labels": [], "entities": []}, {"text": "Of course, all this is very unfair, and not at all surprising.", "labels": [], "entities": []}, {"text": "The examples are out of domain, so the language model doesn't help us at all.", "labels": [], "entities": []}, {"text": "So let's try an in-domain example of newswire text.", "labels": [], "entities": []}, {"text": "The following is almost the first text I found by searching Arabic Web pages for the Arabic for \"Google Machine Translation,\" simply because I had already read the English reference document, and I was pretty sure it would be out there somewhere.", "labels": [], "entities": [{"text": "Google Machine Translation", "start_pos": 97, "end_pos": 123, "type": "TASK", "confidence": 0.5553505718708038}]}, {"text": "It is a human-authored Arabic translation of a recent Reuters story about the launching of Google Language Tools, taken from Al Jazeera: Here is the SMT translation, delivered in about the time it would take a native speaker to read the original: The German Franz Ouch which leads efforts Google translation computer feeds hundreds of millions of words of parallel texts such as Arabic, English, using documents of the United Nations and the European Union key sources.", "labels": [], "entities": [{"text": "SMT translation", "start_pos": 149, "end_pos": 164, "type": "TASK", "confidence": 0.8890240490436554}]}, {"text": "And how anew translation Ouch said that although the quality would not be complete That was a good in the previous translation mechanism, and that the correct translation mostly might be good enough for some tasks.", "labels": [], "entities": []}, {"text": "He stated that more data be fed by the results were better.", "labels": [], "entities": []}, {"text": "He commended Miles Osborne Professor at the University of Edinburgh, who died last year at work in the company's efforts to Google, but he pointed out that the software will not prevail over people skilled in translations as they do in the game of chess and should use software to understand and not to complete documents.", "labels": [], "entities": []}, {"text": "The first thing to notice is that this is really very good.", "labels": [], "entities": []}, {"text": "It is quite clear what the story is, and you can even guess that what Franz Och actually said in the English reference text was: \"The more data we feed into the system, the better it gets.\"", "labels": [], "entities": []}, {"text": "It even seems to know that \"Google\" can be a verb.", "labels": [], "entities": []}, {"text": "However, it exhibits all the problems to which we have always known MT is heir.", "labels": [], "entities": [{"text": "MT", "start_pos": 68, "end_pos": 70, "type": "TASK", "confidence": 0.7815680503845215}]}, {"text": "Both pronouns \"he\" in the last paragraph will be understood as referring to Franz, whereas in the reference text it is Miles Osborne who does the commending and the pointing out.", "labels": [], "entities": []}, {"text": "Moreover, the alarming rumor of the latter's death has been greatly exaggerated by the English language-model: The reference text says he \"spent a sabbatical last year working on the Google project.\"", "labels": [], "entities": []}, {"text": "The human Arabic translation says much the same, but the Arabic words for spent and died are homographs, and the newswire-based model favors the latter.", "labels": [], "entities": []}, {"text": "And of course, our friends the Construction Grammarians will gleefully point out that the system makes a hash of the unbounded dependency in Franz's use of what they call the \"MORE-MORE\" construction.", "labels": [], "entities": []}, {"text": "We can specifically probe the disability with respect to other kinds of unbounded dependencies, using back-translation on artificially generated (but in-domain) examples: Comparing the examples that are translated correctly and those (labeled *) that are not, the generalization is already clear: even a 5-gram model can only handle root subject relative clauses.", "labels": [], "entities": []}, {"text": "Object relatives are beyond the horizon.", "labels": [], "entities": []}, {"text": "(These effects are robust under variation of the content words.)", "labels": [], "entities": []}, {"text": "Here are some more challenging embedded examples that confirm the diagnosis:", "labels": [], "entities": []}], "tableCaptions": []}