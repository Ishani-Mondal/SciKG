{"title": [{"text": "Tree Kernels for Semantic Role Labeling", "labels": [], "entities": [{"text": "Semantic Role Labeling", "start_pos": 17, "end_pos": 39, "type": "TASK", "confidence": 0.7372801899909973}]}], "abstractContent": [{"text": "The availability of large scale data sets of manually annotated predicate-argument structures has recently favored the use of machine learning approaches to the design of automated semantic role labeling (SRL) systems.", "labels": [], "entities": [{"text": "semantic role labeling (SRL)", "start_pos": 181, "end_pos": 209, "type": "TASK", "confidence": 0.795130322376887}]}, {"text": "The main research in this area relates to the design choices for feature representation and for effective decompositions of the task in different learning models.", "labels": [], "entities": [{"text": "feature representation", "start_pos": 65, "end_pos": 87, "type": "TASK", "confidence": 0.7586032748222351}]}, {"text": "Regarding the former choice, structural properties of full syntactic parses are largely employed as they represent ways to encode different principles suggested by the linking theory between syntax and semantics.", "labels": [], "entities": []}, {"text": "The latter choice relates to several learning schemes over global views of the parses.", "labels": [], "entities": []}, {"text": "For example, re-ranking stages operating over alternative predicate-argument sequences of the same sentence have shown to be very effective.", "labels": [], "entities": []}, {"text": "In this article, we propose several kernel functions to model parse tree properties in kernel-based machines, for example, perceptrons or support vector machines.", "labels": [], "entities": []}, {"text": "In particular, we define different kinds of tree kernels as general approaches to feature engineering in SRL.", "labels": [], "entities": [{"text": "SRL", "start_pos": 105, "end_pos": 108, "type": "TASK", "confidence": 0.8972182273864746}]}, {"text": "Moreover, we extensively experiment with such kernels to investigate their contribution to individual stages of an SRL architecture both in isolation and in combination with other traditional manually coded features.", "labels": [], "entities": [{"text": "SRL architecture", "start_pos": 115, "end_pos": 131, "type": "TASK", "confidence": 0.9149298071861267}]}, {"text": "The results for boundary recognition, classification, and re-ranking stages provide systematic evidence about the significant impact of tree kernels on the overall accuracy, especially when the amount of training data is small.", "labels": [], "entities": [{"text": "boundary recognition", "start_pos": 16, "end_pos": 36, "type": "TASK", "confidence": 0.7927897572517395}, {"text": "classification", "start_pos": 38, "end_pos": 52, "type": "TASK", "confidence": 0.8458187580108643}, {"text": "accuracy", "start_pos": 164, "end_pos": 172, "type": "METRIC", "confidence": 0.9992056488990784}]}, {"text": "As a conclusive result, tree kernels allow fora general and easily portable feature engineering method which is applicable to a large family of natural language processing tasks.", "labels": [], "entities": []}], "introductionContent": [{"text": "Much attention has recently been devoted to the design of systems for the automatic labeling of semantic roles (SRL) as defined in two important projects: FrameNet (Baker, Fillmore, and Lowe 1998), based on frame semantics, and PropBank, inspired by Levin's verb classes.", "labels": [], "entities": [{"text": "labeling of semantic roles (SRL)", "start_pos": 84, "end_pos": 116, "type": "TASK", "confidence": 0.8115770391055516}]}, {"text": "To annotate natural language sentences, such systems generally require (1) the detection of the target word embodying the predicate and (2) the detection and classification of the word sequences constituting the predicate's arguments.", "labels": [], "entities": []}, {"text": "Previous work has shown that these steps can be carried out by applying machine learning techniques), for which the most important features encoding predicate-argument relations are derived from (shallow or deep) syntactic information.", "labels": [], "entities": []}, {"text": "The outcome of this research brings wide empirical evidence in favor of the linking theories between semantics and syntax, for example,.", "labels": [], "entities": []}, {"text": "Nevertheless, as no such theory provides a sound and complete treatment, the choice and design of syntactic features to represent semantic structures requires remarkable research effort and intuition.", "labels": [], "entities": []}, {"text": "For example, earlier studies on feature design for semantic role labeling were carried out by and.", "labels": [], "entities": [{"text": "semantic role labeling", "start_pos": 51, "end_pos": 73, "type": "TASK", "confidence": 0.7205530206362406}]}, {"text": "Since then, researchers have proposed several syntactic feature sets, where the more recent sets slightly enhanced the older ones.", "labels": [], "entities": []}, {"text": "A careful analysis of such features reveals that most of them are syntactic tree fragments of training sentences, thus a viable way to alleviate the feature design complexity is the adoption of syntactic tree kernels.", "labels": [], "entities": []}, {"text": "For example, in, the predicate-argument relation is represented by means of the minimal subtree that includes both of them.", "labels": [], "entities": []}, {"text": "The similarity between two instances is evaluated by a tree kernel function in terms of common substructures.", "labels": [], "entities": []}, {"text": "Such an approach is inline with current research on kernels for natural language learning, for example, syntactic parsing re-ranking (, relation extraction (Zelenko, Aone, and, and named entity recognition (.", "labels": [], "entities": [{"text": "syntactic parsing re-ranking", "start_pos": 104, "end_pos": 132, "type": "TASK", "confidence": 0.7969265182813009}, {"text": "relation extraction", "start_pos": 136, "end_pos": 155, "type": "TASK", "confidence": 0.8324198722839355}, {"text": "named entity recognition", "start_pos": 181, "end_pos": 205, "type": "TASK", "confidence": 0.6579656402269999}]}, {"text": "Furthermore, recent work) has shown that, to achieve high labeling accuracy, joint inference should be applied on the whole predicate-argument structure.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 67, "end_pos": 75, "type": "METRIC", "confidence": 0.9383512735366821}]}, {"text": "For this purpose, we need to extract features from the sentence syntactic parse tree that encodes the relationships governing complex semantic structures.", "labels": [], "entities": []}, {"text": "This task is rather difficult because we do not exactly know which syntactic clues effectively capture the relation between the predicate and its arguments.", "labels": [], "entities": []}, {"text": "For example, to detect the interesting context, the modeling of syntax-/semantics-based features should take into account linguistic aspects like ancestor nodes or semantic dependencies.", "labels": [], "entities": []}, {"text": "In this scenario, the automatic feature generation/selection carried out by tree kernels can provide useful insights into the underlying linguistic phenomena.", "labels": [], "entities": [{"text": "feature generation/selection", "start_pos": 32, "end_pos": 60, "type": "TASK", "confidence": 0.7770184129476547}]}, {"text": "Other advantages coming from the use of tree kernels are the following.", "labels": [], "entities": []}, {"text": "First, we can implement them very quickly as the feature extractor module only requires the writing of a general procedure for subtree extraction.", "labels": [], "entities": [{"text": "subtree extraction", "start_pos": 127, "end_pos": 145, "type": "TASK", "confidence": 0.750592827796936}]}, {"text": "In contrast, traditional SRL systems use more than thirty features (e. g., Pradhan, Hacioglu,), each of which requires the writing of a dedicated procedure.", "labels": [], "entities": [{"text": "SRL", "start_pos": 25, "end_pos": 28, "type": "TASK", "confidence": 0.980119526386261}]}, {"text": "Second, their combination with traditional attribute-value models produces more accurate systems, also when using the same machine learning algorithm in the combination, because the feature spaces are very different.", "labels": [], "entities": []}, {"text": "Third, we can carryout feature engineering using kernel combinations and marking strategies (.", "labels": [], "entities": []}, {"text": "This allows us to boost the SRL accuracy in a relatively simple way.", "labels": [], "entities": [{"text": "SRL", "start_pos": 28, "end_pos": 31, "type": "METRIC", "confidence": 0.49830004572868347}, {"text": "accuracy", "start_pos": 32, "end_pos": 40, "type": "METRIC", "confidence": 0.9144291281700134}]}, {"text": "Next, tree kernels generate large tree fragment sets which constitute back-off models for important syntactic features.", "labels": [], "entities": []}, {"text": "Using them, the learning algorithm generalizes better and produces a more accurate classifier, especially when the amount of training data is scarce.", "labels": [], "entities": []}, {"text": "Finally, once the learning algorithm using tree kernels has converged, we can identify the most important structured features of the generated model.", "labels": [], "entities": []}, {"text": "One approach for such a reverse engineering process relies on the computation of the explicit feature space, at least for the highest-weighted features (.", "labels": [], "entities": []}, {"text": "Once the most relevant fragments are available, they can be used to design novel effective attribute-value features (which in turn can be used to design more efficient classifiers, e. g., with linear kernels) and inspire new linguistic theories.", "labels": [], "entities": []}, {"text": "These points suggest that tree kernels should always be applied, at least for an initial study of the problem.", "labels": [], "entities": []}, {"text": "Unfortunately, they suffer from two main limitations: (a) poor impact on boundary detection as, in this task, correct and incorrect arguments may share a large portion of the encoding trees); and (b) more expensive running time and limited contribution to the overall accuracy if compared with manually derived features (.", "labels": [], "entities": [{"text": "boundary detection", "start_pos": 73, "end_pos": 91, "type": "TASK", "confidence": 0.7184055894613266}, {"text": "accuracy", "start_pos": 268, "end_pos": 276, "type": "METRIC", "confidence": 0.9983377456665039}]}, {"text": "Point (a) has been addressed by by showing that a strategy of marking relevant parse-tree nodes makes correct and incorrect subtrees for boundary detection quite different.", "labels": [], "entities": [{"text": "boundary detection", "start_pos": 137, "end_pos": 155, "type": "TASK", "confidence": 0.7706538736820221}]}, {"text": "can be tackled by studying approaches to kernel engineering that allow for the design of efficient and effective kernels.", "labels": [], "entities": [{"text": "kernel engineering", "start_pos": 41, "end_pos": 59, "type": "TASK", "confidence": 0.8295288383960724}]}, {"text": "In this article, we provide a comprehensive study of the use of tree kernels for semantic role labeling.", "labels": [], "entities": [{"text": "semantic role labeling", "start_pos": 81, "end_pos": 103, "type": "TASK", "confidence": 0.7150400280952454}]}, {"text": "For this purpose, we define tree kernels based on the composition of two different feature functions: canonical mappings, which map sentence-parse trees in tree structures encoding semantic information, and feature extraction functions, which encode these trees in the actual feature space.", "labels": [], "entities": [{"text": "feature extraction", "start_pos": 207, "end_pos": 225, "type": "TASK", "confidence": 0.708828791975975}]}, {"text": "The latter functions explode the canonical trees into all their substructures and, in the literature, are usually referred to as tree kernels.", "labels": [], "entities": []}, {"text": "For instance, in,, and Moschitti (2006a) different tree kernels extract different types of tree fragments.", "labels": [], "entities": []}, {"text": "Given the heuristic nature of canonical mappings, we studied their properties by experimenting with them within support vector machines and with the data set provided by CoNLL shared tasks).", "labels": [], "entities": []}, {"text": "The results show that carefully engineered tree kernels always boost the accuracy of the basic systems.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 73, "end_pos": 81, "type": "METRIC", "confidence": 0.9991944432258606}]}, {"text": "Most importantly, in complex tasks such as the re-ranking of semantic role annotations, they provide an easy way to engineer new features which enhance the state-of-the-art in SRL.", "labels": [], "entities": [{"text": "SRL", "start_pos": 176, "end_pos": 179, "type": "TASK", "confidence": 0.9704675674438477}]}, {"text": "In the remainder of this article, Section 2 presents traditional architectures for SRL and the typical features proposed in literature.", "labels": [], "entities": [{"text": "SRL", "start_pos": 83, "end_pos": 86, "type": "TASK", "confidence": 0.9864537119865417}]}, {"text": "Tree kernels are formally introduced in Section 3, and Section 4 describes our modular architecture employing support vector machines along with manually designed features, tree kernels (feature extraction functions), and their combinations.", "labels": [], "entities": []}, {"text": "Section 5 presents our structured features (canonical mappings) inducing different kernels that we used for different SRL subtasks.", "labels": [], "entities": [{"text": "SRL subtasks", "start_pos": 118, "end_pos": 130, "type": "TASK", "confidence": 0.9149335622787476}]}, {"text": "The extensive experimental results obtained on the boundary recognition, role classification, and re-ranking stages are presented in Section 6.", "labels": [], "entities": [{"text": "boundary recognition", "start_pos": 51, "end_pos": 71, "type": "TASK", "confidence": 0.7870189249515533}, {"text": "role classification", "start_pos": 73, "end_pos": 92, "type": "TASK", "confidence": 0.9085160195827484}]}, {"text": "Finally, Section 7 summarizes the conclusions.", "labels": [], "entities": []}], "datasetContent": [{"text": "First, we converted the output of each nodeclassifier into a posterior probability conditioned by its output scores).", "labels": [], "entities": []}, {"text": "This method uses a parametric model to fit onto a sigmoid distribution the posterior probability P(y = 1, f ), where f is the output of the classifier and the parameters are dynamically adapted to give the best probability output.", "labels": [], "entities": [{"text": "posterior probability P", "start_pos": 75, "end_pos": 98, "type": "METRIC", "confidence": 0.8376020193099976}]}, {"text": "3 Second, we selected then most likely sequences of node labelings.", "labels": [], "entities": []}, {"text": "Given a predicate, the likelihood of a labeling scheme (or state) s for the K candidate argument nodes is given by: where pi (l) is the probability of node i being assigned the label l, and p \ud97b\udf59 i (l) is the same probability weighted by the probability pi (ARG) of the node being an argument.", "labels": [], "entities": [{"text": "ARG)", "start_pos": 256, "end_pos": 260, "type": "METRIC", "confidence": 0.9325012266635895}]}, {"text": "If l = NARG (not an argument) then both terms evaluate to (1 \u2212 pi (ARG)) and the likelihood of the NARG label assignment is given by (1 \u2212 pi (ARG)) 2 . To select then states associated with the highest probability, we cannot evaluate the likelihood of all possible states because they are exponential in number.", "labels": [], "entities": []}, {"text": "In order to reduce the search space we (a) limit the number of possible labelings of each node tom and (b) avoid traversing all the states by applying a Viterbi algorithm to search for the most likely labeling schemes.", "labels": [], "entities": []}, {"text": "From each state we generate the states in which a candidate argument is assigned different labels.", "labels": [], "entities": []}, {"text": "This operation is bound to output at most n states which are generated by traversing a maximum of n \u00d7 m states.", "labels": [], "entities": []}, {"text": "Therefore, in the worst case scenario the number of traversed states is V = n \u00d7 m \u00d7 k, k being the number of candidate argument nodes in the tree.", "labels": [], "entities": []}, {"text": "During the search we also enforce overlap resolution policies.", "labels": [], "entities": [{"text": "overlap resolution", "start_pos": 34, "end_pos": 52, "type": "TASK", "confidence": 0.8913012146949768}]}, {"text": "Indeed, for any given state in which anode n j is assigned a label l \ud97b\udf59 = NARG, we generate all; and only the states in which all the nodes that are dominated by n j are assigned the NARG label.", "labels": [], "entities": []}, {"text": "The experiments aim to measure the contribution and the effectiveness of our proposed kernel engineering models and of the diverse structured features that we designed (Section 5).", "labels": [], "entities": []}, {"text": "From this perspective, the role of feature extraction functions is not fundamental because the study carried out in Moschitti (2006a) strongly suggests that the SST (Collins and Duffy 2002) kernel produces higher accuracy than the PT kernel when dealing with constituent parse trees, which are adopted in our study.", "labels": [], "entities": [{"text": "feature extraction", "start_pos": 35, "end_pos": 53, "type": "TASK", "confidence": 0.7356591075658798}, {"text": "SST (Collins and Duffy 2002) kernel", "start_pos": 161, "end_pos": 196, "type": "DATASET", "confidence": 0.6393149122595787}, {"text": "accuracy", "start_pos": 213, "end_pos": 221, "type": "METRIC", "confidence": 0.9957600235939026}]}, {"text": "We then selected the SST kernel and designed the following experiments: (a) A study of canonical functions based on node marking for boundary detection and argument classification, that is, AST m 1 (Section 6.2).", "labels": [], "entities": [{"text": "SST", "start_pos": 21, "end_pos": 24, "type": "TASK", "confidence": 0.9455490112304688}, {"text": "boundary detection", "start_pos": 133, "end_pos": 151, "type": "TASK", "confidence": 0.7584055066108704}, {"text": "argument classification", "start_pos": 156, "end_pos": 179, "type": "TASK", "confidence": 0.7298640012741089}, {"text": "AST", "start_pos": 190, "end_pos": 193, "type": "TASK", "confidence": 0.8411438465118408}]}, {"text": "Moreover, as the standard features have shown to be effective, we combined them with AST m 1 based kernels on the boundary detection and classification tasks (Section 6.2).", "labels": [], "entities": [{"text": "boundary detection and classification", "start_pos": 114, "end_pos": 151, "type": "TASK", "confidence": 0.7460425868630409}]}, {"text": "(b) We varied the amount of training data to demonstrate the higher generalization ability of tree kernels (Section 6.3).", "labels": [], "entities": []}, {"text": "(c) Given the promising results of kernel engineering, we also applied it to solve a more complex task, namely, conflict resolution in SRL annotations (see Section 6.4).", "labels": [], "entities": [{"text": "kernel engineering", "start_pos": 35, "end_pos": 53, "type": "TASK", "confidence": 0.9078929722309113}, {"text": "conflict resolution", "start_pos": 112, "end_pos": 131, "type": "TASK", "confidence": 0.759456992149353}]}, {"text": "As this involves the complete predicate-argument structure, we could test advanced canonical functions generating AST n , AST ord n , and AST m n . (d) Previous work has shown that re-ranking is very important in boosting the accuracy of SRL.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 226, "end_pos": 234, "type": "METRIC", "confidence": 0.9991341233253479}, {"text": "SRL", "start_pos": 238, "end_pos": 241, "type": "TASK", "confidence": 0.9846182465553284}]}, {"text": "Therefore, we tested advanced canonical mappings, that is, those based on AST cm n , PAS, and PAS tl , on such tasks (Section 6.5).", "labels": [], "entities": [{"text": "AST cm n", "start_pos": 74, "end_pos": 82, "type": "DATASET", "confidence": 0.6742129226525625}, {"text": "PAS", "start_pos": 85, "end_pos": 88, "type": "METRIC", "confidence": 0.8436298370361328}]}], "tableCaptions": [{"text": " Table 2  Number of arguments (Arguments) and of unrecoverable arguments (Unrecoverable) due to  parse tree errors in Sections 2, 3, and 24 of the Penn TreeBank/PropBank.", "labels": [], "entities": [{"text": "Penn TreeBank/PropBank", "start_pos": 147, "end_pos": 169, "type": "DATASET", "confidence": 0.9223678112030029}]}, {"text": " Table 3  Comparison between different models on Boundary Detection and the complete Semantic Role  Labeling tasks. The training set is constituted by the first 1 million instances from Sections 02-06  for the boundary classifier and all arguments from Sections 02-21 for the role multiclassifier  (253,129 instances). The performance is measured against Section 24 (149,140 instances).", "labels": [], "entities": [{"text": "Boundary Detection", "start_pos": 49, "end_pos": 67, "type": "TASK", "confidence": 0.9073542058467865}, {"text": "Semantic Role  Labeling", "start_pos": 85, "end_pos": 108, "type": "TASK", "confidence": 0.8343223333358765}]}, {"text": " Table 5  SRL accuracy on different PropBank target sections in terms of F1 measure of the different  structured features employed for conflict resolution.", "labels": [], "entities": [{"text": "SRL", "start_pos": 10, "end_pos": 13, "type": "METRIC", "confidence": 0.5786482095718384}, {"text": "accuracy", "start_pos": 14, "end_pos": 22, "type": "METRIC", "confidence": 0.8623594641685486}, {"text": "PropBank target sections", "start_pos": 36, "end_pos": 60, "type": "DATASET", "confidence": 0.9023133317629496}, {"text": "F1", "start_pos": 73, "end_pos": 75, "type": "METRIC", "confidence": 0.9995763897895813}, {"text": "conflict resolution", "start_pos": 135, "end_pos": 154, "type": "TASK", "confidence": 0.8144364953041077}]}, {"text": " Table 6  Number of propositions, alternative annotations (as output by the Viterbi algorithm), and pair  comparisons (i. e., re-ranker input examples) for the PropBank sections used for the experiments.", "labels": [], "entities": []}, {"text": " Table 7  Summary of the proposition re-ranking experiments with different training sets.", "labels": [], "entities": []}]}