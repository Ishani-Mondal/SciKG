{"title": [{"text": "Less is more: Eliminating index terms from subordinate clauses", "labels": [], "entities": [{"text": "Eliminating index terms from subordinate clauses", "start_pos": 14, "end_pos": 62, "type": "TASK", "confidence": 0.8633084297180176}]}], "abstractContent": [{"text": "We perform a linguistic analysis of documents during indexing for information retrieval.", "labels": [], "entities": [{"text": "information retrieval", "start_pos": 66, "end_pos": 87, "type": "TASK", "confidence": 0.7494928240776062}]}, {"text": "By eliminating index terms that occur only insubordinate clauses, index size is reduced by approximately 30% without adversely affecting precision or recall.", "labels": [], "entities": [{"text": "index size", "start_pos": 66, "end_pos": 76, "type": "METRIC", "confidence": 0.7469315826892853}, {"text": "precision", "start_pos": 137, "end_pos": 146, "type": "METRIC", "confidence": 0.9990752935409546}, {"text": "recall", "start_pos": 150, "end_pos": 156, "type": "METRIC", "confidence": 0.9846503138542175}]}, {"text": "These results hold for two corpora: a sample of the worldwide web and an electronic encyclopedia.", "labels": [], "entities": []}], "introductionContent": [{"text": "Efforts to exploit natural language processing (NLP) to aid information retrieval (IR) have generally involved augmenting a standard index of lexical terms with more complex terms that reflect aspects of the linguistic structure of the indexed text.", "labels": [], "entities": [{"text": "information retrieval (IR)", "start_pos": 60, "end_pos": 86, "type": "TASK", "confidence": 0.8398903250694275}]}, {"text": "This paper shows that NLP can benefit information retrieval in a very different way: rather than increasing the size and complexity of an IR index, linguistic information can make it possible to store less information in the index.", "labels": [], "entities": [{"text": "information retrieval", "start_pos": 38, "end_pos": 59, "type": "TASK", "confidence": 0.7201105356216431}]}, {"text": "In particular, we demonstrate that robust NLP technology makes it possible to omit substantial portions of a text from the index without dramatically affecting precision or recall.", "labels": [], "entities": [{"text": "precision", "start_pos": 160, "end_pos": 169, "type": "METRIC", "confidence": 0.9986490607261658}, {"text": "recall", "start_pos": 173, "end_pos": 179, "type": "METRIC", "confidence": 0.9830953478813171}]}, {"text": "This research is motivated by insights from Rhetorical Structure Theory (RST)).", "labels": [], "entities": [{"text": "Rhetorical Structure Theory (RST))", "start_pos": 44, "end_pos": 78, "type": "TASK", "confidence": 0.7955717792113622}]}, {"text": "An RST analysis is a dependency analysis of the structure of a text, whose leaf nodes are the propositions encoded in clauses.", "labels": [], "entities": [{"text": "RST analysis", "start_pos": 3, "end_pos": 15, "type": "TASK", "confidence": 0.962154358625412}]}, {"text": "In this structural analysis, some propositions in the text, called \"nuclei,\" are more centrally important in realizing the writer's communicative goals, while other propositions, called \"satellites,\" are less central in realizing those goals, and instead provide additional information about the nuclei in a manner consistent with the discourse relation between the nucleus and the satellite.", "labels": [], "entities": []}, {"text": "This asymmetry has an analogue in sentence structure: main clauses tend to represent nuclei, while subordinate clauses tend to represent satellites (.", "labels": [], "entities": []}, {"text": "From the perspective of discourse analysis, the task of information retrieval can be viewed as attempting to identify the \"aboutness,\" or global topicality, of a document in order to determine the relevance of the document as a response to a user's query.", "labels": [], "entities": [{"text": "information retrieval", "start_pos": 56, "end_pos": 77, "type": "TASK", "confidence": 0.7508042454719543}]}, {"text": "Given an RST analysis of a document, we would expect that for the purposes of predicting document relevance, information that occurs in nucleic propositions ought to be more useful than information that occurs in satellite propositions.", "labels": [], "entities": [{"text": "RST analysis", "start_pos": 9, "end_pos": 21, "type": "TASK", "confidence": 0.8923742771148682}, {"text": "predicting document relevance", "start_pos": 78, "end_pos": 107, "type": "TASK", "confidence": 0.7814632852872213}]}, {"text": "To test this expectation, we experimented with eliminating from an IR index those terms that occurred in certain kinds of subordinate clauses.", "labels": [], "entities": []}], "datasetContent": [{"text": "We conducted experiments in which we eliminated terms from the NLM index, and then measured precision and recall.", "labels": [], "entities": [{"text": "precision", "start_pos": 92, "end_pos": 101, "type": "METRIC", "confidence": 0.9996566772460938}, {"text": "recall", "start_pos": 106, "end_pos": 112, "type": "METRIC", "confidence": 0.9989457726478577}]}, {"text": "The experiments were performed on two test corpora: web pages returned by the Alta Vista search service (section 3.2) and articles from the Encarta electronic encyclopedia (section 3.3).", "labels": [], "entities": []}, {"text": "We gathered 120 natural language queries from colleagues for submission to Alta Vista.", "labels": [], "entities": [{"text": "Alta Vista", "start_pos": 75, "end_pos": 85, "type": "DATASET", "confidence": 0.6172278225421906}]}, {"text": "2 The queries averaged 3.7 content words, with a standard deviation of 1.7. 3 Words like \"know\" and \"find\", which are common in natural language queries, are included in these counts.", "labels": [], "entities": []}, {"text": "We examined the first thirty documents returned by Alta Vista (or fewer documents for queries that did not return at least thirty documents).", "labels": [], "entities": [{"text": "Alta Vista", "start_pos": 51, "end_pos": 61, "type": "DATASET", "confidence": 0.8510254323482513}]}, {"text": "This document set comprised 3,440 documents.", "labels": [], "entities": []}, {"text": "Since we were notable to determine what percentage of the web Alta Vista accounted for, it was not possible to calculate the recall of this document set.", "labels": [], "entities": [{"text": "Alta Vista accounted", "start_pos": 62, "end_pos": 82, "type": "DATASET", "confidence": 0.8868234356244405}, {"text": "recall", "start_pos": 125, "end_pos": 131, "type": "METRIC", "confidence": 0.9994316697120667}]}, {"text": "In the discussion below, we calculate recall as a percentage of the relevant documents returned by Alta Vista.", "labels": [], "entities": [{"text": "recall", "start_pos": 38, "end_pos": 44, "type": "METRIC", "confidence": 0.9995031356811523}, {"text": "Alta Vista", "start_pos": 99, "end_pos": 109, "type": "DATASET", "confidence": 0.9108952283859253}]}, {"text": "Precision and recall are averaged across all queries submitted to Alta Vista.", "labels": [], "entities": [{"text": "Precision", "start_pos": 0, "end_pos": 9, "type": "METRIC", "confidence": 0.9950514435768127}, {"text": "recall", "start_pos": 14, "end_pos": 20, "type": "METRIC", "confidence": 0.9987660646438599}, {"text": "Alta Vista", "start_pos": 66, "end_pos": 76, "type": "DATASET", "confidence": 0.8574993908405304}]}, {"text": "The documents returned by Alta Vista were indexed using NLM (section 2) and filtered to retain only documents that contained matches.", "labels": [], "entities": []}, {"text": "contrasts the baseline NLM figures (indexing based on terms in all clauses) with the results of eliminating from the documents all terms that occurred insubordinate clauses.", "labels": [], "entities": []}, {"text": "To measure the trade-off between precision and recall, we calculated the F-measure (Van Rij sbergen 1980), defined as F -(f12 + 1.0)PR, where P is precision, R is fl2p + R recall and [3 is the relative weight assigned to precision and recall (for these experiments, 13= 1).", "labels": [], "entities": [{"text": "precision", "start_pos": 33, "end_pos": 42, "type": "METRIC", "confidence": 0.9988850951194763}, {"text": "recall", "start_pos": 47, "end_pos": 53, "type": "METRIC", "confidence": 0.9903479814529419}, {"text": "F-measure", "start_pos": 73, "end_pos": 82, "type": "METRIC", "confidence": 0.9851390719413757}, {"text": "F -(f12 + 1.0)PR", "start_pos": 118, "end_pos": 134, "type": "METRIC", "confidence": 0.9600270135062081}, {"text": "precision", "start_pos": 147, "end_pos": 156, "type": "METRIC", "confidence": 0.9983812570571899}, {"text": "recall", "start_pos": 172, "end_pos": 178, "type": "METRIC", "confidence": 0.6174626350402832}, {"text": "precision", "start_pos": 221, "end_pos": 230, "type": "METRIC", "confidence": 0.9978645443916321}, {"text": "recall", "start_pos": 235, "end_pos": 241, "type": "METRIC", "confidence": 0.9780724048614502}]}, {"text": "As shows, by eliminating terms from all subordinate clauses in the documents, the NLM index size was reduced by 31.4% with only a minor impact (-0.82%) on F-measure.", "labels": [], "entities": [{"text": "NLM index size", "start_pos": 82, "end_pos": 96, "type": "METRIC", "confidence": 0.6432396074136099}, {"text": "F-measure", "start_pos": 155, "end_pos": 164, "type": "METRIC", "confidence": 0.7680875062942505}]}, {"text": "Given unique indexing of terms per document, and a constant size per term (section 2), we can deduce that 31.4% of the terms in the NLM index occurred only insubordinate clauses.", "labels": [], "entities": []}, {"text": "Had they occurred even once in a main clause, they would not have been removed from the index.", "labels": [], "entities": []}, {"text": "We ran two comparison experiments.", "labels": [], "entities": []}, {"text": "In the first comparison, we deleted one third of all terms as they were produced.", "labels": [], "entities": []}, {"text": "gives the average results of three runs of this experiment.", "labels": [], "entities": []}, {"text": "In each run, a different set of one third of the terms was deleted.", "labels": [], "entities": []}, {"text": "Although fewer terms were omitted (28.8% 4 versus 31.4% when all terms in 4 TelTflS eliminated from a subordinate clause in one sentence might persist in the index if they occurred in the main clause of another sentence in the same document, hence a reduction of slightly less than 33.3%.", "labels": [], "entities": []}, {"text": "subordinate clauses were eliminated) the detrimental effect on F-measure was 5.3 times greater than when terms occuring insubordinate clauses were deleted.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 63, "end_pos": 72, "type": "METRIC", "confidence": 0.8083774447441101}]}, {"text": "In the second comparison experiment, we tested the converse of the operation described in the discussion of above: we eliminated all search terms from the main clauses of documents, leaving only search terms that occurred insubordinate clauses.", "labels": [], "entities": []}, {"text": "shows the dramatic effect of this operation: as we expected, the index size was greatly reduced (by 73.8%).", "labels": [], "entities": [{"text": "index size", "start_pos": 65, "end_pos": 75, "type": "METRIC", "confidence": 0.9214281737804413}]}, {"text": "However, Fmeasure was seriously affected, by more than two thirds, or -68.99%.", "labels": [], "entities": [{"text": "Fmeasure", "start_pos": 9, "end_pos": 17, "type": "METRIC", "confidence": 0.9892948269844055}]}, {"text": "The effect on Fmeasure is primarily due to the severe impact on recall, which fell from a tolerable baseline of 43.2% to an unacceptable 7.5%.", "labels": [], "entities": [{"text": "Fmeasure", "start_pos": 14, "end_pos": 22, "type": "METRIC", "confidence": 0.8285611867904663}, {"text": "recall", "start_pos": 64, "end_pos": 70, "type": "METRIC", "confidence": 0.9996691942214966}]}, {"text": "Comparing the reduction in index size to the reduction when subordinate clause information was eliminated (73.8% versus 31.4%, a factor of approximately 2:1) to the reduction in Fmeasure (-68.99 versus -0.82, a factor of approximately 84:1), it is clear that the impact on F-measure from eliminating terms in main clauses is disproportionate to the reduction in index size.", "labels": [], "entities": [{"text": "Fmeasure", "start_pos": 178, "end_pos": 186, "type": "METRIC", "confidence": 0.8388025164604187}]}, {"text": "isolates the effects of deleting each kind of subordinate clause.", "labels": [], "entities": []}, {"text": "Most remarkable is the fact that eliminating terms that only occur in relative clauses (RELCL) yields a 7.3% reduction in index size while actually improving F-measure.", "labels": [], "entities": [{"text": "RELCL", "start_pos": 88, "end_pos": 93, "type": "METRIC", "confidence": 0.9779226779937744}, {"text": "index size", "start_pos": 122, "end_pos": 132, "type": "METRIC", "confidence": 0.7837660610675812}, {"text": "F-measure", "start_pos": 158, "end_pos": 167, "type": "METRIC", "confidence": 0.9748494625091553}]}, {"text": "Also worthy of special note is the fact that two kinds of subordinate clauses can be eliminated with no perceptible effect on Fmeasure: eliminating complement clauses (COMPCL), yields a reduction in index size of 7.4%, and eliminating present participial clauses (PRPRTCL) yields a reduction in index size of 4.2%.", "labels": [], "entities": [{"text": "Fmeasure", "start_pos": 126, "end_pos": 134, "type": "DATASET", "confidence": 0.49709463119506836}]}, {"text": "5 F is calculated from the underlying figures, to minimise the effects of rounding errors.", "labels": [], "entities": [{"text": "F", "start_pos": 2, "end_pos": 3, "type": "METRIC", "confidence": 0.9933393597602844}]}, {"text": "Because of interactions among the different clause types, the effects illustrated in are not additive.", "labels": [], "entities": []}, {"text": "For example, an infinitival clause (INFCL) may contain a noun phrase with an embedded relative clause (RELCL).", "labels": [], "entities": [{"text": "RELCL", "start_pos": 103, "end_pos": 108, "type": "METRIC", "confidence": 0.9711893200874329}]}, {"text": "Elimination of all terms in the infinitival clause would therefore also lead to elimination of terms in the relative clause.", "labels": [], "entities": []}, {"text": "We gathered 348 queries from middleschool students for submission to Encarta, an electronic encyclopedia.", "labels": [], "entities": []}, {"text": "The queries averaged 3.4 content words, with a standard deviation of 1.", "labels": [], "entities": []}, {"text": "We indexed the text of the Encarta articles, approximately 33,000 files containing approximately 576,000 sentences, using a simple statistical indexing engine.", "labels": [], "entities": [{"text": "Encarta articles", "start_pos": 27, "end_pos": 43, "type": "DATASET", "confidence": 0.907087653875351}]}, {"text": "We then submitted each query and gathered the first thirty ranked documents, fora total of 5,218 documents.", "labels": [], "entities": []}, {"text": "We constructed an NLM index for the documents returned and, in a second pass, filtered documents using NLM.", "labels": [], "entities": []}, {"text": "In the discussion below, recall is calculated as a percentage of the relevant documents that the statistical search returned.", "labels": [], "entities": [{"text": "recall", "start_pos": 25, "end_pos": 31, "type": "METRIC", "confidence": 0.9995624423027039}]}, {"text": "compares the baseline NLM accuracy (indexing all terms) to the accuracy of eliminating terms that occurred insubordinate clauses.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 26, "end_pos": 34, "type": "METRIC", "confidence": 0.9432767033576965}, {"text": "accuracy", "start_pos": 63, "end_pos": 71, "type": "METRIC", "confidence": 0.9992852807044983}]}, {"text": "The reduction in index size (29.0%) is comparable to the reduction observed in the Alta Vista experiment (31.4%).", "labels": [], "entities": [{"text": "index size", "start_pos": 17, "end_pos": 27, "type": "METRIC", "confidence": 0.9618629515171051}]}, {"text": "However, the effect on F-measure of eliminating terms from subordinate clauses is more marked (-4.91%) than in the Alta Vista experiment (-0.82%).", "labels": [], "entities": [{"text": "F-measure", "start_pos": 23, "end_pos": 32, "type": "METRIC", "confidence": 0.9949851036071777}]}, {"text": "The impact on F-measure is still substantially less than the average of three runs during which arbitrary non-overlapping thirds of the terms were eliminated, as illustrated in.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 14, "end_pos": 23, "type": "METRIC", "confidence": 0.9176216125488281}]}, {"text": "This arbitrary deletion of terms results in an 11.57% reduction in F-measure compared to the baseline, approximately 2.4 times greater than the impact of eliminating material subordinate clauses.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 67, "end_pos": 76, "type": "METRIC", "confidence": 0.9987921118736267}]}, {"text": "in As shows, eliminating terms from main clauses and retaining information insubordinate clauses has a profound effect on recall for the Encarta corpus.", "labels": [], "entities": [{"text": "recall", "start_pos": 122, "end_pos": 128, "type": "METRIC", "confidence": 0.9927176237106323}, {"text": "Encarta corpus", "start_pos": 137, "end_pos": 151, "type": "DATASET", "confidence": 0.9304775893688202}]}, {"text": "As with the Alta Vista experiment (section 3.2), it is instructive to compare the results in to the results obtained when terms insubordinate clauses were deleted).", "labels": [], "entities": []}, {"text": "Approximately 2.7 times as many terms were eliminated from the index, yet the effect on F-measure is almost thirteen times worse.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 88, "end_pos": 97, "type": "METRIC", "confidence": 0.988283634185791}]}, {"text": "isolates the effects for Encarta of eliminating terms from each kind of subordinate clause.", "labels": [], "entities": []}, {"text": "It is interesting to compare the reduction in index size and the relative change in Fmeasure for Encarta, a relatively homogeneous corpus of academic articles, to the heterogeneous web sample of section 3.2.", "labels": [], "entities": [{"text": "index size", "start_pos": 46, "end_pos": 56, "type": "METRIC", "confidence": 0.8945431113243103}, {"text": "Fmeasure", "start_pos": 84, "end_pos": 92, "type": "DATASET", "confidence": 0.682711660861969}]}, {"text": "For both corpora, eliminating terms that only occur in abbreviated clauses (ABBCL) or present participial clauses (PRPRTCL) results in modest reductions in index size without negatively affecting F-measure.", "labels": [], "entities": [{"text": "index size", "start_pos": 156, "end_pos": 166, "type": "METRIC", "confidence": 0.8432498574256897}, {"text": "F-measure", "start_pos": 196, "end_pos": 205, "type": "METRIC", "confidence": 0.9398574829101562}]}, {"text": "Eliminating terms from adverbial clauses (ADVCL) or infinitival clauses (INFCL) also produces a similar effects on the two corpora: a reduction in index size with a modest (less than 1%) reduction in F-measure.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 200, "end_pos": 209, "type": "METRIC", "confidence": 0.9918507933616638}]}, {"text": "Relative clauses (RELCL) and complement clauses (COMPCL), however, behave differently across the two corpora.", "labels": [], "entities": []}, {"text": "In both cases, the effects on F-measure are positive for web documents and negative for Encarta articles.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 30, "end_pos": 39, "type": "METRIC", "confidence": 0.995537519454956}]}, {"text": "The negative impact of the elimination of material from relative clauses in Encarta can perhaps be attributed to the pervasive use of non-restrictive relative clauses in the definitional encyclopedia text, as illustrated by the underlined sections of the following examples: Sargon H (ruled 722-705 BC), who followed Tiglath-pileser's successor, Shalmaneser V (ruled 727-722 BC), to the throne, extended Assyrian domination in all directions, from southern Anatolia to the Persian Gulf Amaral, Tarsila do  Another peculiar characteristic of the Encarta corpus, namely the pervasive use of complement taking nominal expressions such as the belief that and the fact that, possibly explains the negative impact of the elimination of complement clause material in.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1 Alta Vista: Effects of eliminating subordinate clauses", "labels": [], "entities": [{"text": "Alta Vista", "start_pos": 9, "end_pos": 19, "type": "DATASET", "confidence": 0.8263199627399445}]}, {"text": " Table 2 Alta Vista: Average effect of eliminating one third of terms", "labels": [], "entities": [{"text": "Alta Vista", "start_pos": 9, "end_pos": 19, "type": "DATASET", "confidence": 0.8083173334598541}]}, {"text": " Table 3 Alta Vista: Effect of diminating main clauses", "labels": [], "entities": [{"text": "Alta Vista", "start_pos": 9, "end_pos": 19, "type": "DATASET", "confidence": 0.8362370133399963}]}, {"text": " Table 4 Alta Vista: Effect of eliminating different kinds of subordinate clauses", "labels": [], "entities": [{"text": "Alta Vista", "start_pos": 9, "end_pos": 19, "type": "DATASET", "confidence": 0.8035255968570709}]}, {"text": " Table 5 Encarta: Effects of eliminating subordinate clauses", "labels": [], "entities": []}, {"text": " Table 6. This arbitrary deletion of terms results  in an 11.57% reduction in F-measure compared  to the baseline, approximately 2.4 times greater", "labels": [], "entities": [{"text": "F-measure", "start_pos": 78, "end_pos": 87, "type": "METRIC", "confidence": 0.9995701909065247}]}, {"text": " Table 6 Encarta: Effects of eliminating one third of terms", "labels": [], "entities": []}, {"text": " Table 7 Encarta: Effect of eliminating main clauses", "labels": [], "entities": []}, {"text": " Table 8 Encarta: Effect of eliminating different kinds of subordinate clauses", "labels": [], "entities": []}]}