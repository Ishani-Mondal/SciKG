{"title": [{"text": "Corpus-Based Identification of Non-Anaphoric Noun Phrases", "labels": [], "entities": [{"text": "Corpus-Based Identification of Non-Anaphoric Noun Phrases", "start_pos": 0, "end_pos": 57, "type": "TASK", "confidence": 0.7443440010150274}]}], "abstractContent": [{"text": "Coreference resolution involves finding antecedents for anaphoric discourse entities, such as definite noun phrases.", "labels": [], "entities": [{"text": "Coreference resolution", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.9182106852531433}]}, {"text": "But many definite noun phrases are not anaphoric because their meaning can be understood from general world knowledge (e.g., \"the White House\" or \"the news media\").", "labels": [], "entities": []}, {"text": "We have developed a corpus-based algorithm for automatically identifying definite noun phrases that are non-anaphoric, which has the potential to improve the efficiency and accuracy of coreference resolution systems.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 173, "end_pos": 181, "type": "METRIC", "confidence": 0.9977624416351318}, {"text": "coreference resolution", "start_pos": 185, "end_pos": 207, "type": "TASK", "confidence": 0.9448847472667694}]}, {"text": "Our algorithm generates lists of non-anaphoric noun phrases and noun phrase patterns from a training corpus and uses them to recognize non-anaphoric noun phrases in new texts.", "labels": [], "entities": []}, {"text": "Using 1600 MUC-4 terrorism news articles as the training corpus, our approach achieved 78% recall and 87% precision at identifying such noun phrases in 50 test documents.", "labels": [], "entities": [{"text": "MUC-4 terrorism news articles", "start_pos": 11, "end_pos": 40, "type": "DATASET", "confidence": 0.8669474273920059}, {"text": "recall", "start_pos": 91, "end_pos": 97, "type": "METRIC", "confidence": 0.9996557235717773}, {"text": "precision", "start_pos": 106, "end_pos": 115, "type": "METRIC", "confidence": 0.9995589852333069}]}], "introductionContent": [{"text": "Most automated approaches to coreference resolution attempt to locate an antecedent for every potentially coreferent discourse entity (DE) in a text.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 29, "end_pos": 51, "type": "TASK", "confidence": 0.949243575334549}]}, {"text": "The problem with this approach is that a large number of DE's may not have antecedents.", "labels": [], "entities": []}, {"text": "While some discourse entities such as pronouns are almost always referential, definite descriptions I may not be.", "labels": [], "entities": []}, {"text": "Earlier work found that nearly 50% of definite descriptions had no prior referents), and we found that number to be even higher, 63%, in our corpus.", "labels": [], "entities": []}, {"text": "Some non-anaphoric definite descriptions can be identified by looking for syntactic clues like attached prepositional phrases or restrictive relative clauses.", "labels": [], "entities": []}, {"text": "But other definite descriptions are non-anaphoric because readers understand their meaning due to common knowledge.", "labels": [], "entities": []}, {"text": "For example, readers of this 1In this work, we define a definite description to be a noun phrase beginning with the.", "labels": [], "entities": []}, {"text": "paper will probably understand the real world referents of \"the F.B.I.,\" \"the White House,\" and \"the Golden Gate Bridge.\"", "labels": [], "entities": [{"text": "F.B.I.", "start_pos": 64, "end_pos": 70, "type": "DATASET", "confidence": 0.963653564453125}]}, {"text": "These are instances of definite descriptions that a coreference resolver does not need to resolve because they each fully specify a cognitive representation of the entity in the reader's mind.", "labels": [], "entities": [{"text": "coreference resolver", "start_pos": 52, "end_pos": 72, "type": "TASK", "confidence": 0.8088162243366241}]}, {"text": "One way to address this problem is to create a list of all non-anaphoric NPs that could be used as a filter prior to coreference resolution, but hand coding such a list is a daunting and intractable task.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 117, "end_pos": 139, "type": "TASK", "confidence": 0.9683108925819397}]}, {"text": "We propose a corpusbased mechanism to identify non-anaphoric NPs automatically.", "labels": [], "entities": []}, {"text": "We will refer to non-anaphoric definite noun phrases as existential NPs.", "labels": [], "entities": []}, {"text": "Our algorithm uses statistical methods to generate lists of existential noun phrases and noun phrase patterns from a training corpus.", "labels": [], "entities": []}, {"text": "These lists are then used to recognize existential NPs in new texts.", "labels": [], "entities": []}], "datasetContent": [{"text": "To evaluate the performance of our algorithm, we hand-tagged each definite NP in the 50 test texts as a syntactically independent existential, a semantically independent existential, an associative existential or a referential NP.", "labels": [], "entities": []}, {"text": "shows the distribution of definite NP types in the test texts.", "labels": [], "entities": []}, {"text": "Of the 1,001 definite NPs tested, 63% were independent existentials, so removing these NPs from the coreference resolution process could have substantial savings.", "labels": [], "entities": [{"text": "coreference resolution process", "start_pos": 100, "end_pos": 130, "type": "TASK", "confidence": 0.9257514874140421}]}, {"text": "We measured the accuracy of our classifications using recall and precision metrics.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 16, "end_pos": 24, "type": "METRIC", "confidence": 0.9994495511054993}, {"text": "recall", "start_pos": 54, "end_pos": 60, "type": "METRIC", "confidence": 0.99908447265625}, {"text": "precision", "start_pos": 65, "end_pos": 74, "type": "METRIC", "confidence": 0.99314945936203}]}, {"text": "As a baseline measurement, we considered the accuracy of classifying every definite NP as existential.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 45, "end_pos": 53, "type": "METRIC", "confidence": 0.9994245767593384}]}, {"text": "Given the distribution of definite NP types in our test set, this would result in recall of 100% and precision of 72%.", "labels": [], "entities": [{"text": "recall", "start_pos": 82, "end_pos": 88, "type": "METRIC", "confidence": 0.9997380375862122}, {"text": "precision", "start_pos": 101, "end_pos": 110, "type": "METRIC", "confidence": 0.999763548374176}]}, {"text": "Note that we are more interested in high measures of precision than recall because we view this method to be the precursor to a coreference resolution algorithm.", "labels": [], "entities": [{"text": "precision", "start_pos": 53, "end_pos": 62, "type": "METRIC", "confidence": 0.9977535605430603}, {"text": "recall", "start_pos": 68, "end_pos": 74, "type": "METRIC", "confidence": 0.9973515272140503}, {"text": "coreference resolution", "start_pos": 128, "end_pos": 150, "type": "TASK", "confidence": 0.9247021377086639}]}, {"text": "Incorrectly removing an anaphoric NP means that the coreference resolver would never have a chance to resolve it, on the other hand, non-anaphoric NPs that slip through can still be ruled as non-anaphoric by the coreference resolver.", "labels": [], "entities": [{"text": "coreference resolver", "start_pos": 52, "end_pos": 72, "type": "TASK", "confidence": 0.8361854553222656}]}, {"text": "We first evaluated our system using only the syntactic heuristics, which produced only 43% recall, but 92% precision.", "labels": [], "entities": [{"text": "recall", "start_pos": 91, "end_pos": 97, "type": "METRIC", "confidence": 0.9995934367179871}, {"text": "precision", "start_pos": 107, "end_pos": 116, "type": "METRIC", "confidence": 0.9990476965904236}]}, {"text": "Although the syntactic heuristics area reliable way to identify existential definite NPs, they miss 57% of the true existentials.", "labels": [], "entities": []}, {"text": "We expected the $1, EHP, and DO methods to increase coverage.", "labels": [], "entities": [{"text": "EHP", "start_pos": 20, "end_pos": 23, "type": "METRIC", "confidence": 0.9944721460342407}, {"text": "DO", "start_pos": 29, "end_pos": 31, "type": "METRIC", "confidence": 0.9758090376853943}, {"text": "coverage", "start_pos": 52, "end_pos": 60, "type": "METRIC", "confidence": 0.8985986709594727}]}, {"text": "First, we evaluated each method independently (on top of the syntactic heuristics).", "labels": [], "entities": []}, {"text": "The results appear in rows 2-4 of.", "labels": [], "entities": []}, {"text": "Each method increased recall to between 61-69%, but decreased precision to 84-87%.", "labels": [], "entities": [{"text": "recall", "start_pos": 22, "end_pos": 28, "type": "METRIC", "confidence": 0.9996685981750488}, {"text": "precision", "start_pos": 62, "end_pos": 71, "type": "METRIC", "confidence": 0.9997449517250061}]}, {"text": "All of these methods produced a substantial gain in recall at some cost in precision.", "labels": [], "entities": [{"text": "recall", "start_pos": 52, "end_pos": 58, "type": "METRIC", "confidence": 0.9992402791976929}, {"text": "precision", "start_pos": 75, "end_pos": 84, "type": "METRIC", "confidence": 0.9986718893051147}]}, {"text": "Next, we tried combining the methods to make sure that they were not identifying exactly the same set of existential NPs.", "labels": [], "entities": []}, {"text": "When we combined the S1 and EHP heuristics, recall increased to 80% with precision dropping only slightly to 82%.", "labels": [], "entities": [{"text": "recall", "start_pos": 44, "end_pos": 50, "type": "METRIC", "confidence": 0.999736487865448}, {"text": "precision", "start_pos": 73, "end_pos": 82, "type": "METRIC", "confidence": 0.9994955062866211}]}, {"text": "When we combined all three methods (S1, EHP, and DO), recall increased to 82% without any corresponding loss of precision.", "labels": [], "entities": [{"text": "EHP", "start_pos": 40, "end_pos": 43, "type": "METRIC", "confidence": 0.8590992093086243}, {"text": "DO", "start_pos": 49, "end_pos": 51, "type": "METRIC", "confidence": 0.9679649472236633}, {"text": "recall", "start_pos": 54, "end_pos": 60, "type": "METRIC", "confidence": 0.9997101426124573}, {"text": "precision", "start_pos": 112, "end_pos": 121, "type": "METRIC", "confidence": 0.9987443685531616}]}, {"text": "These experiments show that these heuristics substantially increase recall and are identifying different sets of existential NPs.", "labels": [], "entities": [{"text": "recall", "start_pos": 68, "end_pos": 74, "type": "METRIC", "confidence": 0.9989194869995117}]}, {"text": "Finally, we tested our vaccine algorithm to see if it could increase precision without sacrificing much recall.", "labels": [], "entities": [{"text": "precision", "start_pos": 69, "end_pos": 78, "type": "METRIC", "confidence": 0.9992914199829102}, {"text": "recall", "start_pos": 104, "end_pos": 110, "type": "METRIC", "confidence": 0.9984954595565796}]}, {"text": "We experimented with two variations: Va used an upper definite probability threshold of 70% and ~ used an upper definite probability threshold of 50%.", "labels": [], "entities": []}, {"text": "Both variations used a lower definite probability threshold of 25%.", "labels": [], "entities": [{"text": "definite probability threshold", "start_pos": 29, "end_pos": 59, "type": "METRIC", "confidence": 0.8130911191304525}]}, {"text": "The results are shown in rows 7-8 of.", "labels": [], "entities": []}, {"text": "Both vaccine variations increased precision by several percentage points with only a slight drop in recall.", "labels": [], "entities": [{"text": "precision", "start_pos": 34, "end_pos": 43, "type": "METRIC", "confidence": 0.9994910955429077}, {"text": "recall", "start_pos": 100, "end_pos": 106, "type": "METRIC", "confidence": 0.9994875192642212}]}, {"text": "In previous work, the system developed by Vieria & Poesio achieved 74% recall and 85% precision for identifying \"larger situation and unfamiliar use\" NPs.", "labels": [], "entities": [{"text": "recall", "start_pos": 71, "end_pos": 77, "type": "METRIC", "confidence": 0.9993818998336792}, {"text": "precision", "start_pos": 86, "end_pos": 95, "type": "METRIC", "confidence": 0.9994627833366394}]}, {"text": "This set of NPs does not correspond exactly to our definition of existential NPs because we consider associative NPs to be existential and they do not.", "labels": [], "entities": []}, {"text": "Even so, our results are slightly better than their previous results.", "labels": [], "entities": []}, {"text": "A more equitable comparison is to measure our system's performance on only the independent existential noun phrases.", "labels": [], "entities": []}, {"text": "Using this measure, our algorithm achieved 81.8% recall with 85.6% precision using Va, and achieved 82.9% recall with 83.5% precision using Vb.", "labels": [], "entities": [{"text": "recall", "start_pos": 49, "end_pos": 55, "type": "METRIC", "confidence": 0.9934717416763306}, {"text": "precision", "start_pos": 67, "end_pos": 76, "type": "METRIC", "confidence": 0.9958076477050781}, {"text": "recall", "start_pos": 106, "end_pos": 112, "type": "METRIC", "confidence": 0.993958592414856}, {"text": "precision", "start_pos": 124, "end_pos": 133, "type": "METRIC", "confidence": 0.993668258190155}]}], "tableCaptions": []}