{"title": [{"text": "Semantic Analysis of Japanese Noun Phrases : A New Approach to Dictionary-Based Understanding", "labels": [], "entities": [{"text": "Semantic Analysis of Japanese Noun Phrases", "start_pos": 0, "end_pos": 42, "type": "TASK", "confidence": 0.9040083984533945}, {"text": "Dictionary-Based Understanding", "start_pos": 63, "end_pos": 93, "type": "TASK", "confidence": 0.675489529967308}]}], "abstractContent": [{"text": "This paper presents anew method of analyzing Japanese noun phrases of the form N1 no 5/2.", "labels": [], "entities": []}, {"text": "The Japanese postposition no roughly corresponds to of, but it has much broader usage.", "labels": [], "entities": []}, {"text": "The method exploits a definition of N2 in a dictionary.", "labels": [], "entities": []}, {"text": "For example, rugby no coach can be interpreted as a person who teaches technique in rugby.", "labels": [], "entities": []}, {"text": "We illustrate the effectiveness of the method by the analysis of 300 test noun phrases.", "labels": [], "entities": []}], "introductionContent": [{"text": "The semantic analysis of Japanese noun phrases of the form N1 no N2 is one of the difficult problems which cannot be solved by the current efforts of many researchers.", "labels": [], "entities": [{"text": "semantic analysis of Japanese noun phrases", "start_pos": 4, "end_pos": 46, "type": "TASK", "confidence": 0.8877132336298624}]}, {"text": "Roughly speaking, Japanese noun phrase N1 no N2 corresponds to English noun phrase N2 of N1.", "labels": [], "entities": []}, {"text": "However, the Japanese postposition no has much broader usage than of as follows:  The conventional approach to this problem was to classify semantic relations, such as possession, whole-part, modification, and others.", "labels": [], "entities": []}, {"text": "Then, classification rules were crafted by hand, or detected from relation-tagged examples by a machine learning technique ().", "labels": [], "entities": []}, {"text": "The problem in such an approach is to setup the semantic relations.", "labels": [], "entities": []}, {"text": "For example, the above examples and their classification came from the IPA nominal dictionary (InformationTechnology Promotion Agency, Japan, 1996).", "labels": [], "entities": [{"text": "IPA nominal dictionary (InformationTechnology Promotion Agency, Japan, 1996)", "start_pos": 71, "end_pos": 147, "type": "DATASET", "confidence": 0.8037800664703051}]}, {"text": "Is it possible to find clear boundaries among subject, category, result, purpose, instrument, and others?", "labels": [], "entities": []}, {"text": "No matter how fine-grained relations we setup, we always encounter phrases which are on the boundary or belong to two or more relations.", "labels": [], "entities": []}, {"text": "This paper proposes a completely different approach to the task, which exploits semantic role information of nouns in an ordinary dictionary.", "labels": [], "entities": []}], "datasetContent": [{"text": "We have collected 300 test N1 no N2 phrases from EDR dictionary (Japan Electronic Dictionary Research Institute Ltd., 1995), IPA dictionary (Information-Technology Promotion Agency, Japan, 1996), and literatures on N1 no N2 phrases, paying attention so that they had enough diversity in their relations.", "labels": [], "entities": [{"text": "EDR dictionary (Japan Electronic Dictionary Research Institute Ltd., 1995)", "start_pos": 49, "end_pos": 123, "type": "DATASET", "confidence": 0.9217639217774073}, {"text": "IPA dictionary (Information-Technology Promotion Agency, Japan, 1996)", "start_pos": 125, "end_pos": 194, "type": "DATASET", "confidence": 0.882114215330644}]}, {"text": "Then, we analyzed the test phrases by our system, and checked the analysis results by hand.", "labels": [], "entities": []}, {"text": "shows the reasonably good result both of DBA and SBA.", "labels": [], "entities": [{"text": "DBA", "start_pos": 41, "end_pos": 44, "type": "METRIC", "confidence": 0.9798713326454163}, {"text": "SBA", "start_pos": 49, "end_pos": 52, "type": "METRIC", "confidence": 0.8700556755065918}]}, {"text": "The precision of DBA, the ratio of correct analyses to detected analyses, was 77% (=137/(137+19+21)); the recall of DBA, the ratio of correct analyses to potential semantic-role relations, was 78% (=137/(137+19+19)).", "labels": [], "entities": [{"text": "precision", "start_pos": 4, "end_pos": 13, "type": "METRIC", "confidence": 0.9996007084846497}, {"text": "recall of DBA", "start_pos": 106, "end_pos": 119, "type": "METRIC", "confidence": 0.7749203244845072}]}, {"text": "The result of SBA is also good, excepting modification relation.", "labels": [], "entities": [{"text": "SBA", "start_pos": 14, "end_pos": 17, "type": "TASK", "confidence": 0.7953947186470032}]}, {"text": "Some phrases were given two or more relations.", "labels": [], "entities": []}, {"text": "On average, 1.1 relations were given to one phrase.", "labels": [], "entities": []}, {"text": "The ratio that at least one correct relation was detected was 81% (=242/300); the ratio that all possibly correct relations were detected and no incorrect relation was detected was 73% (=219/300).", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Experimental results of N1 no N2 analysis.", "labels": [], "entities": []}]}