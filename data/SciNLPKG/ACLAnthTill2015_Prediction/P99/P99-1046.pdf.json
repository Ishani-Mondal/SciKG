{"title": [], "abstractContent": [{"text": "Most documents are about more than one subject, but many NLP and IR techniques implicitly assume documents have just one topic.", "labels": [], "entities": []}, {"text": "We describe new clues that mark shifts to new topics, novel algorithms for identifying topic boundaries and the uses of such boundaries once identified.", "labels": [], "entities": []}, {"text": "We report topic segmentation performance on several corpora as well as improvement on an IR task that benefits from good segmentation.", "labels": [], "entities": [{"text": "topic segmentation", "start_pos": 10, "end_pos": 28, "type": "TASK", "confidence": 0.7142422199249268}, {"text": "IR task", "start_pos": 89, "end_pos": 96, "type": "TASK", "confidence": 0.8882374167442322}]}], "introductionContent": [{"text": "Dividing documents into topically-coherent sections has many uses, but the primary motivation for this work comes from information retrieval (IR).", "labels": [], "entities": [{"text": "information retrieval (IR)", "start_pos": 119, "end_pos": 145, "type": "TASK", "confidence": 0.854951822757721}]}, {"text": "Documents in many collections vary widely in length and while the shortest may address one topic, modest length and long documents are likely to address multiple topics or be comprised of sections that address various aspects of the primary topic.", "labels": [], "entities": []}, {"text": "Despite this fact, most IR systems treat documents as indivisible units and index them in their entirety.", "labels": [], "entities": [{"text": "IR", "start_pos": 24, "end_pos": 26, "type": "TASK", "confidence": 0.9580831527709961}]}, {"text": "This is problematic for two reasons.", "labels": [], "entities": []}, {"text": "First, most relevance metrics are based on word frequency, which can be viewed as a function of the topic being discussed.", "labels": [], "entities": []}, {"text": "(For example, the word header is rare in general English, but it enjoys higher frequency in documents about soccer.)", "labels": [], "entities": []}, {"text": "In general, word frequency is a good indicator of whether a document is relevant to a query, but consider along document containing only one section relevant to a query.", "labels": [], "entities": []}, {"text": "If a keyword is used only in the pertinent section, its overall frequency in the document will below and, as a result, the document as a whole maybe judged irrelevant despite the relevance of one section.", "labels": [], "entities": [{"text": "frequency", "start_pos": 64, "end_pos": 73, "type": "METRIC", "confidence": 0.9431001543998718}]}, {"text": "The second reason it would be beneficial to index sections of documents is that, once a search engine has identified a relevant document, users would benefit from direct access to the relevant sections.", "labels": [], "entities": []}, {"text": "This problem is compounded when searching multimedia documents.", "labels": [], "entities": []}, {"text": "If a user wants to find a particular news item in a database of radio or television news programs, they may not have the patience to suffer through a 30 minute broadcast to find the one minute clip that interests them.", "labels": [], "entities": []}, {"text": "Dividing documents into sections based on topic addresses both of these problems.", "labels": [], "entities": []}, {"text": "IR engines can index the resulting sections just like documents and subsequently users can peruse those sections their search engine deems relevant.", "labels": [], "entities": []}, {"text": "In the next section we will discuss the nature of our approach, then briefly describe previous work, discuss various indicators of topic shifts, outline novel algorithms based on them and present our results.", "labels": [], "entities": []}], "datasetContent": [{"text": "We will present results for broadcast news data and for identifying chapter boundaries labelled by authors.", "labels": [], "entities": []}, {"text": "shows the results of segmenting the test portion of the HUB-4 coqgus, which consisted of transcribed broadcasts divided into segments by the LDC.", "labels": [], "entities": [{"text": "HUB-4 coqgus", "start_pos": 56, "end_pos": 68, "type": "DATASET", "confidence": 0.9656545519828796}, {"text": "LDC", "start_pos": 141, "end_pos": 144, "type": "DATASET", "confidence": 0.9398453235626221}]}, {"text": "We measured performance by comparing our segmentation to the gold standard annotation produced by the LDC.", "labels": [], "entities": [{"text": "segmentation", "start_pos": 41, "end_pos": 53, "type": "TASK", "confidence": 0.9653118252754211}, {"text": "LDC", "start_pos": 102, "end_pos": 105, "type": "DATASET", "confidence": 0.543602466583252}]}], "tableCaptions": [{"text": " Table 2: Conditional probabilities used to compute", "labels": [], "entities": [{"text": "compute", "start_pos": 44, "end_pos": 51, "type": "TASK", "confidence": 0.5849872827529907}]}, {"text": " Table 3: Performance on the HUB-4 English corpus.", "labels": [], "entities": [{"text": "HUB-4 English corpus", "start_pos": 29, "end_pos": 49, "type": "DATASET", "confidence": 0.9601352214813232}]}, {"text": " Table 4: Accuracy of the Word Frequency  algorithm on identifying chapter boundaries.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9769836068153381}]}, {"text": " Table 5: Performance on an IR task. Lower  numbers are better.", "labels": [], "entities": [{"text": "IR task", "start_pos": 28, "end_pos": 35, "type": "TASK", "confidence": 0.9257027208805084}]}]}