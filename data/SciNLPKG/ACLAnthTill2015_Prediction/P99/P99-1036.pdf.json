{"title": [{"text": "A Part of Speech Estimation Method for Japanese Unknown Words using a Statistical Model of Morphology and Context", "labels": [], "entities": [{"text": "Speech Estimation", "start_pos": 10, "end_pos": 27, "type": "TASK", "confidence": 0.7346709668636322}]}], "abstractContent": [{"text": "We present a statistical model of Japanese unknown words consisting of a set of length and spelling models classified by the character types that constitute a word.", "labels": [], "entities": []}, {"text": "The point is quite simple: different character sets should be treated differently and the changes between character types are very important because Japanese script has both ideograms like Chinese (kanji) and phonograms like English (katakana).", "labels": [], "entities": []}, {"text": "Both word segmentation accuracy and part of speech tagging accuracy are improved by the proposed model.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 5, "end_pos": 22, "type": "TASK", "confidence": 0.7262455523014069}, {"text": "accuracy", "start_pos": 23, "end_pos": 31, "type": "METRIC", "confidence": 0.9315047264099121}, {"text": "speech tagging", "start_pos": 44, "end_pos": 58, "type": "TASK", "confidence": 0.6914906948804855}, {"text": "accuracy", "start_pos": 59, "end_pos": 67, "type": "METRIC", "confidence": 0.9126225113868713}]}, {"text": "The model can achieve 96.6% tagging accuracy if unknown words are correctly segmented .", "labels": [], "entities": [{"text": "tagging", "start_pos": 28, "end_pos": 35, "type": "TASK", "confidence": 0.9327443242073059}, {"text": "accuracy", "start_pos": 36, "end_pos": 44, "type": "METRIC", "confidence": 0.9819908738136292}]}], "introductionContent": [{"text": "In Japanese, around 95% word segmentation accuracy is reported by using a word-based language model and the Viterbi-like dynamic programming procedures).", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 24, "end_pos": 41, "type": "TASK", "confidence": 0.7055701017379761}, {"text": "accuracy", "start_pos": 42, "end_pos": 50, "type": "METRIC", "confidence": 0.9388602375984192}]}, {"text": "About the same accuracy is reported in Chinese by statistical methods . But there has been relatively little improvement in recent years because most of the remaining errors are due to unknown words.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 15, "end_pos": 23, "type": "METRIC", "confidence": 0.999259889125824}]}, {"text": "There are two approaches to solve this problem: to increase the coverage of the dictionary and to design a better model for unknown words.", "labels": [], "entities": []}, {"text": "We take the latter approach.", "labels": [], "entities": []}, {"text": "To improve word segmentation accuracy,) used a single general purpose unknown word model, while ) used a set of specific word models such as for plurals, personal names, and transliterated foreign words.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 11, "end_pos": 28, "type": "TASK", "confidence": 0.7704010009765625}, {"text": "accuracy", "start_pos": 29, "end_pos": 37, "type": "METRIC", "confidence": 0.8920029401779175}]}, {"text": "The goal of our research is to assign a correct part of speech to unknown word as well as identifying it correctly.", "labels": [], "entities": [{"text": "assign a correct part of speech to unknown word", "start_pos": 31, "end_pos": 78, "type": "TASK", "confidence": 0.6949080328146616}]}, {"text": "In this paper, we present a novel statistical model for Japanese unknown words.", "labels": [], "entities": []}, {"text": "It consists of a set of word models for each part of speech and word type.", "labels": [], "entities": []}, {"text": "We classified Japanese words into nine orthographic types based on the character types that constitute a word.", "labels": [], "entities": []}, {"text": "We find that by making different models for each word type, we can better model the length and spelling of unknown words.", "labels": [], "entities": []}, {"text": "In the following sections, we first describe the language model used for Japanese word segmentation.", "labels": [], "entities": [{"text": "Japanese word segmentation", "start_pos": 73, "end_pos": 99, "type": "TASK", "confidence": 0.6149077415466309}]}, {"text": "We then describe a series of unknown word models, from the baseline model to the one we propose.", "labels": [], "entities": []}, {"text": "Finally, we prove the effectiveness of the proposed model by experiment.", "labels": [], "entities": []}], "datasetContent": [{"text": "We used the EDR Japanese Corpus Version 1.0 to train the language model.", "labels": [], "entities": [{"text": "EDR Japanese Corpus Version 1.0", "start_pos": 12, "end_pos": 43, "type": "DATASET", "confidence": 0.9631230354309082}]}, {"text": "It is a manually word segmented and tagged corpus of approximately 5.1 million words (208 thousand sentences).", "labels": [], "entities": []}, {"text": "It contains a variety of Japanese sentences taken from newspapers, magazines, dictionaries, encyclopedias, textbooks, etc..", "labels": [], "entities": []}, {"text": "In this experiment, we randomly selected two sets of 100 thousand sentences.", "labels": [], "entities": []}, {"text": "The first 100 thousand sentences are used for training the language model.", "labels": [], "entities": []}, {"text": "The second 100 thousand sentences are used for testing.", "labels": [], "entities": []}, {"text": "The remaining 8 thousand sentences are used as a heldout set for smoothing the parameters.", "labels": [], "entities": []}, {"text": "For the evaluation of the word segmentation accuracy, we randomly selected 5 thousand sentences from the test set of 100 thousand sentences.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 26, "end_pos": 43, "type": "TASK", "confidence": 0.6836012303829193}, {"text": "accuracy", "start_pos": 44, "end_pos": 52, "type": "METRIC", "confidence": 0.7167370915412903}]}, {"text": "We call the first test set (100 thousand sentences) \"test set-l\" and the second test set (5 thousand sentences) \"test set-T'.", "labels": [], "entities": []}, {"text": "shows the number of sentences, words, and characters of the training and test sets.", "labels": [], "entities": []}, {"text": "There were 94,680 distinct words in the training test.", "labels": [], "entities": []}, {"text": "We discarded the words whose frequency was one, and made a dictionary of 45,027 words.", "labels": [], "entities": []}, {"text": "After replacing the words whose frequency was one with the corresponding unknown word tags, there were 474,155 distinct word bigrams.", "labels": [], "entities": []}, {"text": "We discarded the bigrams with frequency one, and the remaining 175,527 bigrams were used in the word segmentation model.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 96, "end_pos": 113, "type": "TASK", "confidence": 0.7993284165859222}]}, {"text": "As for the unknown word model, word-based character bigrams are computed from the words with frequency one (49,653 words).", "labels": [], "entities": []}, {"text": "There were 3,120 distinct character unigrams and 55,486 distinct character bigrams.", "labels": [], "entities": []}, {"text": "We discarded the bigram with frequency one and remaining 20,775 bigrams were used.", "labels": [], "entities": []}, {"text": "There were 12,633 distinct character unigrams and 80,058 distinct character bigrams when we classified them for each word type and part of speech.", "labels": [], "entities": []}, {"text": "We discarded the bigrams with frequency one and remaining 26,633 bigrams were used in the unknown word model.", "labels": [], "entities": []}, {"text": "Average word lengths for each word type and part of speech were also computed from the words with frequency one in the training set.", "labels": [], "entities": []}, {"text": "shows the cross entropy per word and character perplexity of three unknown word model.", "labels": [], "entities": []}, {"text": "The first model is Equation, which is the combination of Poisson distribution and character zerogram (Poisson + zerogram).", "labels": [], "entities": [{"text": "Equation", "start_pos": 19, "end_pos": 27, "type": "METRIC", "confidence": 0.9618822932243347}]}, {"text": "The second model is the combination of Poisson distribution (Equation (6)) and character bigram (Equation) (Poisson + bigram).", "labels": [], "entities": []}, {"text": "The third model is Equation (11), which is a set of word models trained for each word type (WT + Poisson + bigram).", "labels": [], "entities": []}, {"text": "Cross entropy was computed over the words in test set-1 that were not found in the dictionary of the word segmentation model (56,121 words).", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 101, "end_pos": 118, "type": "TASK", "confidence": 0.7077473551034927}]}, {"text": "Character perplexity is more intuitive than cross entropy because it shows the average number of equally probable characters out of 6,879 characters in JIS-X-0208.", "labels": [], "entities": [{"text": "JIS-X-0208", "start_pos": 152, "end_pos": 162, "type": "DATASET", "confidence": 0.955115556716919}]}, {"text": "shows that by changing the word spelling model from zerogram to big-ram, character perplexity is greatly reduced.", "labels": [], "entities": [{"text": "word spelling", "start_pos": 27, "end_pos": 40, "type": "TASK", "confidence": 0.7180648148059845}]}, {"text": "It also shows that by making a separate model for each word type, character perplexity is reduced by an additional 45% (128 -~ 71).", "labels": [], "entities": []}, {"text": "This shows that the word type information is useful for modeling the morphology of Japanese words.", "labels": [], "entities": []}, {"text": "shows the part of speech prediction accuracy of two unknown word model without context.", "labels": [], "entities": [{"text": "speech prediction", "start_pos": 18, "end_pos": 35, "type": "TASK", "confidence": 0.6828182190656662}, {"text": "accuracy", "start_pos": 36, "end_pos": 44, "type": "METRIC", "confidence": 0.898082435131073}]}, {"text": "It shows the accuracies up to the top 10 candidates.", "labels": [], "entities": [{"text": "accuracies", "start_pos": 13, "end_pos": 23, "type": "METRIC", "confidence": 0.9867272973060608}]}, {"text": "The first model is Equation, which is a set of word models trained for each part of speech (POS + Poisson + bigram).", "labels": [], "entities": []}, {"text": "The second model is Equation (13), which is a set of word models trained for Since these unknown word models give the probability of spelling for each part of speech P(wlt), we used the empirical part of speech probability P(t) to compute the joint probability P(w, t).", "labels": [], "entities": []}, {"text": "The part of speech t that gives the highest joint probability is selected.", "labels": [], "entities": [{"text": "joint probability", "start_pos": 44, "end_pos": 61, "type": "METRIC", "confidence": 0.8325986564159393}]}], "tableCaptions": [{"text": " Table 1: Examples of word bigrams including un- known word tags", "labels": [], "entities": []}, {"text": " Table 2: Character type configuration of infrequent  words in the EDR corpus", "labels": [], "entities": [{"text": "EDR corpus", "start_pos": 67, "end_pos": 77, "type": "DATASET", "confidence": 0.8952176570892334}]}, {"text": " Table 3: Examples of common character bigrams for  each part of speech in the infrequent words", "labels": [], "entities": []}, {"text": " Table 4: The amount of training and test sets", "labels": [], "entities": []}, {"text": " Table 5: Cross entropy (CE) per word and character  perplexity (PP) of each unknown word model", "labels": [], "entities": [{"text": "Cross entropy (CE) per word", "start_pos": 10, "end_pos": 37, "type": "METRIC", "confidence": 0.8899168542453221}, {"text": "character  perplexity (PP)", "start_pos": 42, "end_pos": 68, "type": "METRIC", "confidence": 0.8707363247871399}]}, {"text": " Table 6: Word segmentation accuracy of all words", "labels": [], "entities": [{"text": "Word segmentation", "start_pos": 10, "end_pos": 27, "type": "TASK", "confidence": 0.7062651813030243}, {"text": "accuracy", "start_pos": 28, "end_pos": 36, "type": "METRIC", "confidence": 0.9461924433708191}]}, {"text": " Table 7: Word segmentation accuracy of unknown  words", "labels": [], "entities": [{"text": "Word segmentation", "start_pos": 10, "end_pos": 27, "type": "TASK", "confidence": 0.7192008644342422}, {"text": "accuracy", "start_pos": 28, "end_pos": 36, "type": "METRIC", "confidence": 0.9055691957473755}]}, {"text": " Table 8: Part of speech tagging accuracy of unknown words (the last column represents the percentage of  correctly tagged unknown words in the correctly segmented unknown words)", "labels": [], "entities": [{"text": "speech tagging", "start_pos": 18, "end_pos": 32, "type": "TASK", "confidence": 0.7492208182811737}, {"text": "accuracy", "start_pos": 33, "end_pos": 41, "type": "METRIC", "confidence": 0.9540834426879883}]}]}