{"title": [{"text": "Automatic Compensation for Parser Figure-of-Merit Flaws*", "labels": [], "entities": [{"text": "Parser Figure-of-Merit Flaws", "start_pos": 27, "end_pos": 55, "type": "TASK", "confidence": 0.4930693606535594}]}], "abstractContent": [{"text": "Best-first chart parsing utilises a figure of merit (FOM) to efficiently guide a parse by first attending to those edges judged better.", "labels": [], "entities": [{"text": "Best-first chart parsing", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.46954208612442017}, {"text": "figure of merit (FOM)", "start_pos": 36, "end_pos": 57, "type": "METRIC", "confidence": 0.6199117551247278}]}, {"text": "In the past it has usually been static; this paper will show that with some extra information , a parser can compensate for FOM flaws which otherwise slow it down.", "labels": [], "entities": []}, {"text": "Our results are faster than the prior best by a factor of 2.5; and the speedup is won with no significant decrease in parser accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 125, "end_pos": 133, "type": "METRIC", "confidence": 0.9765943884849548}]}], "introductionContent": [{"text": "Sentence parsing is a task which is traditionMly rather computationally intensive.", "labels": [], "entities": [{"text": "Sentence parsing", "start_pos": 0, "end_pos": 16, "type": "TASK", "confidence": 0.9502971470355988}]}, {"text": "The best known practical methods are still roughly cubic in the length of the sentence--less than ideM when deMing with nontriviM sentences of 30 or 40 words in length, as frequently found in the Penn Wall Street Journal treebank corpus.", "labels": [], "entities": [{"text": "Penn Wall Street Journal treebank corpus", "start_pos": 196, "end_pos": 236, "type": "DATASET", "confidence": 0.974172423283259}]}, {"text": "Fortunately, there is now a body of literature on methods to reduce parse time so that the exhaustive limit is never reached in practice.", "labels": [], "entities": []}, {"text": "1 For much of the work, the chosen vehicle is chart parsing.", "labels": [], "entities": [{"text": "chart parsing", "start_pos": 46, "end_pos": 59, "type": "TASK", "confidence": 0.7607314884662628}]}, {"text": "In this technique, the parser begins at the word or tag level and uses the rules of a context-free grammar to build larger and larger constituents.", "labels": [], "entities": []}, {"text": "Completed constituents are stored in the cells of a chart according to their location and * This research was funded in part by NSF Grant IRI-9319516 and ONR Grant N0014-96-1-0549.", "labels": [], "entities": [{"text": "NSF Grant IRI-9319516", "start_pos": 128, "end_pos": 149, "type": "DATASET", "confidence": 0.7176650365193685}, {"text": "ONR Grant N0014-96-1-0549", "start_pos": 154, "end_pos": 179, "type": "DATASET", "confidence": 0.8814307848612467}]}, {"text": "IAn exhaustive parse always \"overgenerates\" because the grammar contains thousands of extremely rarely applied rules; these are (correctly) rejected even by the simplest parsers, eventuMly, but it would be better to avoid them entirely. length.", "labels": [], "entities": [{"text": "length", "start_pos": 237, "end_pos": 243, "type": "METRIC", "confidence": 0.990192174911499}]}, {"text": "Incomplete constituents (\"edges\") are stored in an agenda.", "labels": [], "entities": []}, {"text": "The exhaustion of the agenda definitively marks the completion of the parsing algorithm, but the parse needn't take that long; Mready in the early work on chart parsing, suggests that by ordering the agenda one can find a parse without resorting to an exhaustive search.", "labels": [], "entities": [{"text": "parsing", "start_pos": 70, "end_pos": 77, "type": "TASK", "confidence": 0.9670729041099548}, {"text": "chart parsing", "start_pos": 155, "end_pos": 168, "type": "TASK", "confidence": 0.758506715297699}]}, {"text": "The introduction of statistical parsing brought with an obvious tactic for ranking the agenda: and) first used probabilistic context free grammars (PCFGs) to generate probabilities for use in a figure of merit (FOM).", "labels": [], "entities": [{"text": "statistical parsing", "start_pos": 20, "end_pos": 39, "type": "TASK", "confidence": 0.7267490029335022}]}, {"text": "Later work introduced other FOMs formed from PCFG data;.", "labels": [], "entities": [{"text": "FOMs", "start_pos": 28, "end_pos": 32, "type": "TASK", "confidence": 0.87647545337677}, {"text": "PCFG data", "start_pos": 45, "end_pos": 54, "type": "DATASET", "confidence": 0.7877483069896698}]}, {"text": "More recently, we have seen parse times lowered by several orders of magnitude.", "labels": [], "entities": [{"text": "parse times", "start_pos": 28, "end_pos": 39, "type": "METRIC", "confidence": 0.7839199006557465}]}, {"text": "The article considers a number of different figures of merit for ordering the agenda, and ultimately recommends one that reduces the number of edges required fora full parse into the thousands.", "labels": [], "entities": []}, {"text": "() introduces an edge-based technique, (instead of constituent-based), which drops the average edge count into the hundreds.", "labels": [], "entities": []}, {"text": "However, if we establish \"perfection\" as the minimum number of edges needed to generate the correct parse 47.5 edges on average in our corpus--we can hope for still more improvement.", "labels": [], "entities": [{"text": "perfection", "start_pos": 26, "end_pos": 36, "type": "METRIC", "confidence": 0.9734154343605042}]}, {"text": "This paper looks at two new figures of merit, both of which take the [Gold98] figure (of \"independent\" merit) as a starting point in cMculating anew figure of merit for each edge, taking into account some additional information.", "labels": [], "entities": [{"text": "Gold98] figure", "start_pos": 70, "end_pos": 84, "type": "DATASET", "confidence": 0.893406331539154}]}, {"text": "Our work further lowers the average edge count, bringing it from the hundreds into the dozens. and use a figure which indicates the merit of a given constituent or edge, relative only to itself and its children but independent of the progress of the parse we will call this the edge's independent merit (IM).", "labels": [], "entities": [{"text": "edge's independent merit (IM)", "start_pos": 278, "end_pos": 307, "type": "METRIC", "confidence": 0.7520639513220105}]}], "datasetContent": [{"text": "We hoped, however, that we might be able to find away to simplify the algorithm such that it would be easier to implement and/or . ....,.-\"'\"\"\"\"'\"i\"\"'\"'\".:, \u2022 .'\"\"'\" ...i. i \"'\"'..", "labels": [], "entities": []}, {"text": "line is not parallel to the competitor axis, but rather angled so that the low-IM lowcompetitor items pass the scan before the high-IM high-competitor items.", "labels": [], "entities": []}, {"text": "This can be simulated by multiplying each edge's independent merit by a demeriting factor 5 per competitor (thus a total of 5c).", "labels": [], "entities": []}, {"text": "Its exact value would determine the steepness of the scan line.", "labels": [], "entities": []}, {"text": "Each trial consisted of one run, an edgebased best-first parse of treebank section 22 (with sentences longer than 40 words thrown out, as before), using the new figure of merit: faster to run, without sacrificing accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 213, "end_pos": 221, "type": "METRIC", "confidence": 0.9950700998306274}]}, {"text": "To that end, we looked over the data, viewing it as (among other things) a series of \"planes\" seen by setting the amount of work constant (see).", "labels": [], "entities": []}, {"text": "Viewed like this, the original algorithm behaves like a scan line, parallel to the competitor axis, scanning for the one edge with the highest figure of (independent) merit.", "labels": [], "entities": []}, {"text": "However, one look at figure 2 dramatically confirms our postulate that an edge with zero competitors can have an IM orders of magnitude lower than an edge with many competitors, and still be more likely to be correct.", "labels": [], "entities": []}, {"text": "Effectively, then, under the table lookup algorithm, the scan 2previous work has shown that the parser performs better if it runs slightly past the first parse; so for every run referenced in this paper, the parser was allowed to run to first parse plus a tenth.", "labels": [], "entities": []}, {"text": "All reported final counts for popped edges are thus 1.1 times the count at first parse.", "labels": [], "entities": []}, {"text": "This idea works extremely well.", "labels": [], "entities": []}, {"text": "It is, predictably, easier to implement; somewhat surprisingly, though, it actually performs better than the method it approximates.", "labels": [], "entities": []}, {"text": "When 5 = .7, for instance, the accuracy loss is only .28%, comparable to the table lookup result, but the number of edges popped drops to just 91.23, or 39.7% of the prior result found in.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 31, "end_pos": 39, "type": "METRIC", "confidence": 0.9996521472930908}]}, {"text": "Using other demeriting factors gives similarly dramatic decreases in edge count, with varying effects on accuracy--see.", "labels": [], "entities": [{"text": "edge count", "start_pos": 69, "end_pos": 79, "type": "METRIC", "confidence": 0.85048907995224}, {"text": "accuracy", "start_pos": 105, "end_pos": 113, "type": "METRIC", "confidence": 0.9993659853935242}]}, {"text": "It is not immediately clear as to why demeriting improves performance so dramatically over the table lookup method.", "labels": [], "entities": []}, {"text": "One possibility is that the statistical method runs into too many sparse data problems around the fringe of the data set--were we able to use a larger data set, we might seethe statistics approach the curve defined by the demeriting.", "labels": [], "entities": []}, {"text": "Another is that the bucketing is too coarse, although the interpolation along the independent merit axis would seem to mitigate that problem.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Performance of various statistical schemata", "labels": [], "entities": []}]}