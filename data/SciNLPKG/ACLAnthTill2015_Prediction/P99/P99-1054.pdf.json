{"title": [{"text": "Efficient probabilistic top-down and left-corner parsingt", "labels": [], "entities": []}], "abstractContent": [{"text": "This paper examines efficient predictive broad-coverage parsing without dynamic programming.", "labels": [], "entities": [{"text": "predictive broad-coverage parsing", "start_pos": 30, "end_pos": 63, "type": "TASK", "confidence": 0.6922268768151602}]}, {"text": "In contrast to bottom-up methods, depth-first top-down parsing produces partial parses that are fully connected trees spanning the entire left context, from which any kind of non-local dependency or partial semantic interpretation can in principle be read.", "labels": [], "entities": []}, {"text": "We contrast two predictive parsing approaches, top-down and left-corner parsing, and find both to be viable.", "labels": [], "entities": [{"text": "predictive parsing", "start_pos": 16, "end_pos": 34, "type": "TASK", "confidence": 0.5813668072223663}, {"text": "left-corner parsing", "start_pos": 60, "end_pos": 79, "type": "TASK", "confidence": 0.6286494731903076}]}, {"text": "In addition, we find that enhancement with non-local information not only improves parser accuracy, but also substantially improves the search efficiency.", "labels": [], "entities": [{"text": "parser", "start_pos": 83, "end_pos": 89, "type": "TASK", "confidence": 0.9495236873626709}, {"text": "accuracy", "start_pos": 90, "end_pos": 98, "type": "METRIC", "confidence": 0.9282822012901306}]}], "introductionContent": [{"text": "Strong empirical evidence has been presented over the past 15 years indicating that the human sentence processing mechanism makes online use of contextual information in the preceding discourse and in the visual environment (.", "labels": [], "entities": []}, {"text": "These results lend support to Mark \"intuition\" that sentence interpretation takes place incrementally, and that partial interpretations are being built while the sentence is being perceived.", "labels": [], "entities": [{"text": "sentence interpretation", "start_pos": 52, "end_pos": 75, "type": "TASK", "confidence": 0.7319680154323578}]}, {"text": "This is a very commonly held view among psycholinguists today.", "labels": [], "entities": []}, {"text": "Many possible models of human sentence processing can be made consistent with the above view, but the general assumption that must underlie them all is that explicit relationships between lexical items in the sentence must be specified incrementally.", "labels": [], "entities": []}, {"text": "Such a processing mechatThis material is based on work supported by the National Science Foundation under Grant No. nism stands in marked contrast to dynamic programming parsers, which delay construction of a constituent until all of its sub-constituents have been completed, and whose partial parses thus consist of disconnected tree fragments.", "labels": [], "entities": []}, {"text": "For example, such parsers do not integrate a main verb into the same tree structure as its subject NP until the VP has been completely parsed, and in many cases this is the final step of the entire parsing process.", "labels": [], "entities": []}, {"text": "Without explicit on-line integration, it would be difficult (though not impossible) to produce partial interpretations on-line.", "labels": [], "entities": []}, {"text": "Similarly, it maybe difficult to use non-local statistical dependencies (e.g. between subject and main verb) to actively guide such parsers.", "labels": [], "entities": []}, {"text": "Our predictive parser does not use dynamic programming, but rather maintains fully connected trees spanning the entire left context, which make explicit the relationships between constituents required for partial interpretation.", "labels": [], "entities": [{"text": "predictive parser", "start_pos": 4, "end_pos": 21, "type": "TASK", "confidence": 0.8858622312545776}]}, {"text": "The parser uses probabilistic best-first parsing methods to pursue the most likely analyses first, and a beam-search to avoid the nontermination problems typical of non-statistical top-down predictive parsers.", "labels": [], "entities": []}, {"text": "There are two main results.", "labels": [], "entities": []}, {"text": "First, this approach works and, with appropriate attention to specific algorithmic details, is surprisingly efficient.", "labels": [], "entities": []}, {"text": "Second, not just accuracy but also efficiency improves as the language model is made more accurate.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 17, "end_pos": 25, "type": "METRIC", "confidence": 0.9994006156921387}]}, {"text": "This bodes well for future research into the use of other non-local (e.g. lexical and semantic) information to guide the parser.", "labels": [], "entities": []}, {"text": "In addition, we show that the improvement inaccuracy associated with left-corner parsing over top-down is attributable to the non-local information supplied by the strategy, and can thus be obtained through other methods that utilize that same information.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: The effect of different approaches to binarization", "labels": [], "entities": []}, {"text": " Table 2: Left Corner Results", "labels": [], "entities": [{"text": "Left Corner", "start_pos": 10, "end_pos": 21, "type": "TASK", "confidence": 0.6294955164194107}]}, {"text": " Table 3: Non-local annotation results", "labels": [], "entities": []}]}