{"title": [{"text": "Should we Translate the Documents or the Queries in Cross-language Information Retrieval?", "labels": [], "entities": [{"text": "Translate the Documents", "start_pos": 10, "end_pos": 33, "type": "TASK", "confidence": 0.8932207822799683}, {"text": "Cross-language Information Retrieval", "start_pos": 52, "end_pos": 88, "type": "TASK", "confidence": 0.7103614608446757}]}], "abstractContent": [{"text": "Previous comparisons of document and query translation suffered difficulty due to differing quality of machine translation in these two opposite directions.", "labels": [], "entities": [{"text": "query translation", "start_pos": 37, "end_pos": 54, "type": "TASK", "confidence": 0.7332205027341843}]}, {"text": "We avoid this difficulty by training identical statistical translation models for both translation directions using the same training data.", "labels": [], "entities": []}, {"text": "We investigate information retrieval between En-glish and French, incorporating both translations directions into both document translation and query translation-based information retrieval, as well as into hybrid systems.", "labels": [], "entities": [{"text": "information retrieval", "start_pos": 15, "end_pos": 36, "type": "TASK", "confidence": 0.7211473435163498}, {"text": "document translation", "start_pos": 119, "end_pos": 139, "type": "TASK", "confidence": 0.7112276554107666}, {"text": "query translation-based information retrieval", "start_pos": 144, "end_pos": 189, "type": "TASK", "confidence": 0.6010574027895927}]}, {"text": "We find that hybrids of document and query translation-based systems out-perform query translation systems, even human-quality query translation systems.", "labels": [], "entities": []}], "introductionContent": [{"text": "Should we translate the documents or the queries in cross-language information retrieval?", "labels": [], "entities": [{"text": "cross-language information retrieval", "start_pos": 52, "end_pos": 88, "type": "TASK", "confidence": 0.6299177507559458}]}, {"text": "The question is more subtle than the implied two alternatives.", "labels": [], "entities": []}, {"text": "The need for translation has itself been.", "labels": [], "entities": [{"text": "translation", "start_pos": 13, "end_pos": 24, "type": "TASK", "confidence": 0.9825657606124878}]}, {"text": "questioned : although non-translation based methods of cross-language information retrieval (CLIR), such as cognate-matching () and cross-language Latent Semantic Indexing () have been developed, the most common approaches have involved coupling information retrieval (IR) with machine translation (MT).", "labels": [], "entities": [{"text": "cross-language information retrieval (CLIR)", "start_pos": 55, "end_pos": 98, "type": "TASK", "confidence": 0.7550417880217234}, {"text": "cross-language Latent Semantic Indexing", "start_pos": 132, "end_pos": 171, "type": "TASK", "confidence": 0.5423199757933617}, {"text": "information retrieval (IR)", "start_pos": 246, "end_pos": 272, "type": "TASK", "confidence": 0.8509487867355346}, {"text": "machine translation (MT)", "start_pos": 278, "end_pos": 302, "type": "TASK", "confidence": 0.8095927357673645}]}, {"text": "(For convenience, we refer to dictionary-lookup techniques and interlingua () as \"translation\" even if these techniques make no attempt to produce coherent or sensibly-ordered language; this distinction is important in other areas, but a stream of words is adequate for IR.)", "labels": [], "entities": [{"text": "IR", "start_pos": 270, "end_pos": 272, "type": "TASK", "confidence": 0.9893839955329895}]}, {"text": "Translating the documents into the query's language(s) and translating the queries into the document's language(s) represent two extreme approaches to coupling MT and IR.", "labels": [], "entities": [{"text": "MT", "start_pos": 160, "end_pos": 162, "type": "TASK", "confidence": 0.9923566579818726}, {"text": "IR", "start_pos": 167, "end_pos": 169, "type": "TASK", "confidence": 0.7998253107070923}]}, {"text": "These two approaches are neither equivalent nor mutually exclusive.", "labels": [], "entities": []}, {"text": "They are not equivalent because machine translation is not an invertible operation.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 32, "end_pos": 51, "type": "TASK", "confidence": 0.7473736703395844}]}, {"text": "Query translation and document translation become equivalent only if each word in one language is translated into a unique word in the other languages.", "labels": [], "entities": [{"text": "Query translation", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.7870196402072906}, {"text": "document translation", "start_pos": 22, "end_pos": 42, "type": "TASK", "confidence": 0.7130553424358368}]}, {"text": "In fact machine translation tends to be a many-toone mapping in the sense that finer shades of meaner are distinguishable in the original text than in the translated text.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 8, "end_pos": 27, "type": "TASK", "confidence": 0.7873627245426178}]}, {"text": "This effect is readily observed, for example, by machine translating the translated text back into the original language.", "labels": [], "entities": []}, {"text": "These two approaches are not mutually exclusive, either.", "labels": [], "entities": []}, {"text": "We find that a hybrid approach combining both directions of translation produces superior performance than either direction alone.", "labels": [], "entities": []}, {"text": "Thus our answer to the question posed by the title is both.", "labels": [], "entities": []}, {"text": "Several arguments suggest that document translation should be competitive or superior to query translation.", "labels": [], "entities": [{"text": "document translation", "start_pos": 31, "end_pos": 51, "type": "TASK", "confidence": 0.8045288920402527}, {"text": "query translation", "start_pos": 89, "end_pos": 106, "type": "TASK", "confidence": 0.7139256447553635}]}, {"text": "First, MT is error-prone.", "labels": [], "entities": [{"text": "MT", "start_pos": 7, "end_pos": 9, "type": "TASK", "confidence": 0.9803748726844788}]}, {"text": "Typical queries are short and may contain key words and phrases only once.", "labels": [], "entities": []}, {"text": "When these are translated inappropriately, the IR engine has no chance to recover.", "labels": [], "entities": [{"text": "IR", "start_pos": 47, "end_pos": 49, "type": "TASK", "confidence": 0.9445787072181702}]}, {"text": "Translating along document offers the MT engine many more opportunities to translate key words and phrases.", "labels": [], "entities": [{"text": "MT", "start_pos": 38, "end_pos": 40, "type": "TASK", "confidence": 0.956892192363739}, {"text": "translate key words and phrases", "start_pos": 75, "end_pos": 106, "type": "TASK", "confidence": 0.856609559059143}]}, {"text": "If only some of these are translated appropriately, the IR engine has at least a chance of matching these to query terms.", "labels": [], "entities": []}, {"text": "The second argument is that the tendency of MT engines to produce fewer distinct words than were contained in the original document (the output vocabulary is smaller than the input vocabulary) also indicates that machine translation should preferably be applied to the documents.", "labels": [], "entities": [{"text": "MT", "start_pos": 44, "end_pos": 46, "type": "TASK", "confidence": 0.9706116318702698}, {"text": "machine translation", "start_pos": 213, "end_pos": 232, "type": "TASK", "confidence": 0.7308188378810883}]}, {"text": "Note the types of preprocessing in use by many monolingual IR engines: stemming (or morphological analysis) of documents and queries reduces the number of distinct words in the document index, while query expansion techniques increase the number of distinct words in the query.", "labels": [], "entities": []}, {"text": "Query translation is probably the most common approach to CLIR.", "labels": [], "entities": [{"text": "Query translation", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.8757080733776093}]}, {"text": "Since MT is frequently computationally expensive and the document sets in IR are large, query translation requires fewer computer resources than document translation.", "labels": [], "entities": [{"text": "MT", "start_pos": 6, "end_pos": 8, "type": "TASK", "confidence": 0.9850581884384155}, {"text": "query translation", "start_pos": 88, "end_pos": 105, "type": "TASK", "confidence": 0.8526865839958191}, {"text": "document translation", "start_pos": 145, "end_pos": 165, "type": "TASK", "confidence": 0.7403696626424789}]}, {"text": "Indeed, it has been asserted that document translation is simply impractical for large-scale retrieval problems (, or that document translation will only become practical in the future as computer speeds improve.", "labels": [], "entities": [{"text": "document translation", "start_pos": 34, "end_pos": 54, "type": "TASK", "confidence": 0.814907968044281}, {"text": "document translation", "start_pos": 123, "end_pos": 143, "type": "TASK", "confidence": 0.783697098493576}]}, {"text": "In fact, we have developed fast MT algorithms) expressly designed for translating large collections of documents and queries in IR.", "labels": [], "entities": [{"text": "MT", "start_pos": 32, "end_pos": 34, "type": "TASK", "confidence": 0.9840734601020813}, {"text": "translating large collections of documents and queries", "start_pos": 70, "end_pos": 124, "type": "TASK", "confidence": 0.8774306774139404}]}, {"text": "Additionally, we have used them successfully on the TREC CLIR task ().", "labels": [], "entities": [{"text": "TREC CLIR task", "start_pos": 52, "end_pos": 66, "type": "TASK", "confidence": 0.4024941722551982}]}, {"text": "Commercially available MT systems have also been used in large-scale document translation experiments.", "labels": [], "entities": [{"text": "MT", "start_pos": 23, "end_pos": 25, "type": "TASK", "confidence": 0.978534460067749}, {"text": "document translation", "start_pos": 69, "end_pos": 89, "type": "TASK", "confidence": 0.7071346342563629}]}, {"text": "Previously, large-scale attempts to compare query translation and document translation approaches to CLIR have suggested that document translation is preferable, but the results have been difficult to interpret.", "labels": [], "entities": [{"text": "query translation", "start_pos": 44, "end_pos": 61, "type": "TASK", "confidence": 0.752104640007019}, {"text": "document translation", "start_pos": 66, "end_pos": 86, "type": "TASK", "confidence": 0.7107044905424118}, {"text": "document translation", "start_pos": 126, "end_pos": 146, "type": "TASK", "confidence": 0.7659475207328796}]}, {"text": "Note that in order to compare query translation and document translation, two different translation systems must be involved.", "labels": [], "entities": [{"text": "query translation", "start_pos": 30, "end_pos": 47, "type": "TASK", "confidence": 0.7856321036815643}, {"text": "document translation", "start_pos": 52, "end_pos": 72, "type": "TASK", "confidence": 0.7147448360919952}]}, {"text": "For example, if queries are in English and document are in French, then the query translation IR system must incorporate English=~French translation, whereas the document translation IR system must incorporate French=~English.", "labels": [], "entities": []}, {"text": "Since familiar commercial MT systems are \"black box\" systems, the quality of translation is not known a priori.", "labels": [], "entities": [{"text": "MT", "start_pos": 26, "end_pos": 28, "type": "TASK", "confidence": 0.9804829359054565}, {"text": "translation", "start_pos": 77, "end_pos": 88, "type": "TASK", "confidence": 0.9742384552955627}]}, {"text": "The present work avoids this difficulty by using statistical machine translation systems for both directions that are trained on the same training data using identical procedures.", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 49, "end_pos": 80, "type": "TASK", "confidence": 0.6226738591988882}]}, {"text": "Our study of document translation is the largest comparative study of document and query translation of which we are currently aware.", "labels": [], "entities": [{"text": "document translation", "start_pos": 13, "end_pos": 33, "type": "TASK", "confidence": 0.7184547930955887}, {"text": "document and query translation", "start_pos": 70, "end_pos": 100, "type": "TASK", "confidence": 0.5978525653481483}]}, {"text": "We also investigate both query and document translation for both translation directions within a language pair.", "labels": [], "entities": [{"text": "document translation", "start_pos": 35, "end_pos": 55, "type": "TASK", "confidence": 0.7311998605728149}]}, {"text": "We built and compared three information retrieval systems : one based on document translation, one based on query translation, and a hybrid system that used both translation directions.", "labels": [], "entities": [{"text": "document translation", "start_pos": 73, "end_pos": 93, "type": "TASK", "confidence": 0.6933617889881134}, {"text": "query translation", "start_pos": 108, "end_pos": 125, "type": "TASK", "confidence": 0.7339526265859604}]}, {"text": "In fact, the \"score\" of a document in the hybrid system is simply the arithmetic mean of its scores in the query and document translation systems.", "labels": [], "entities": [{"text": "document translation", "start_pos": 117, "end_pos": 137, "type": "TASK", "confidence": 0.6920744478702545}]}, {"text": "We find that the hybrid system outperforms either one alone.", "labels": [], "entities": []}, {"text": "Many different hybrid systems are possible because of a tradeoff between computer resources and translation quality.", "labels": [], "entities": []}, {"text": "Given finite computer resources and a collection of documents much larger than the collection of queries, it might make sense to invest more computational resources into higher-quality query translation.", "labels": [], "entities": [{"text": "query translation", "start_pos": 185, "end_pos": 202, "type": "TASK", "confidence": 0.7395378053188324}]}, {"text": "We investigate this possibility in its limiting case: the quality of human translation exceeds that of MT; thus monolingual retrieval (queries and documents in the same language) represents the ultimate limit of query translation.", "labels": [], "entities": [{"text": "MT", "start_pos": 103, "end_pos": 105, "type": "TASK", "confidence": 0.9363581538200378}, {"text": "query translation", "start_pos": 212, "end_pos": 229, "type": "TASK", "confidence": 0.717451348900795}]}, {"text": "Surprisingly, we find that the hybrid system involving fast document translation and monolingual retrieval continues to outperform monolingual retrieval.", "labels": [], "entities": [{"text": "document translation", "start_pos": 60, "end_pos": 80, "type": "TASK", "confidence": 0.7396883964538574}]}, {"text": "We thus conclude that the hybrid system of query and document translation will outperform a pure query translation system no matter how high the quality of the query translation.", "labels": [], "entities": [{"text": "document translation", "start_pos": 53, "end_pos": 73, "type": "TASK", "confidence": 0.7049954533576965}]}], "datasetContent": [{"text": "The document sets used in our experiments were the English and French parts of the document set used in the TREC-6 and TREC-7 CLIR tracks.", "labels": [], "entities": [{"text": "TREC-6 and TREC-7 CLIR tracks", "start_pos": 108, "end_pos": 137, "type": "DATASET", "confidence": 0.7518255293369294}]}, {"text": "The English document set consisted of 3 years of AP newswire, comprising 242918 stories originally occupying 759 MB.", "labels": [], "entities": [{"text": "English document set", "start_pos": 4, "end_pos": 24, "type": "DATASET", "confidence": 0.9131255745887756}, {"text": "AP newswire", "start_pos": 49, "end_pos": 60, "type": "DATASET", "confidence": 0.9796761870384216}]}, {"text": "The French document set consisted of the same 3 years of SDA (a Swiss newswire service), comprising 141656 stories and originally occupying 257 MB.", "labels": [], "entities": [{"text": "French document set", "start_pos": 4, "end_pos": 23, "type": "DATASET", "confidence": 0.9548065861066183}]}, {"text": "Identical query sets and appropriate relevance judgments were available in both English and French.", "labels": [], "entities": []}, {"text": "The 22 topics from TREC-6 were originally constructed in English and translated by humans into French.", "labels": [], "entities": []}, {"text": "The 28 topics from TREC-7 were originally constructed (7 each from four different sites) in English, French, German, and Italian, and human translated into all four languages.", "labels": [], "entities": []}, {"text": "We have no knowledge of which TREC-7 queries were originally constructed in which language.", "labels": [], "entities": []}, {"text": "The queries contain three SGML fields (<topic>, <description>, <narrative>), which allows us to' contrast short (<description> field only) and long (all three fields) forms of the queries.", "labels": [], "entities": []}, {"text": "Queries from TREC-7 appear to be somewhat \"easier\" than queries from TREC-6, across both document sets.", "labels": [], "entities": [{"text": "TREC-7", "start_pos": 13, "end_pos": 19, "type": "DATASET", "confidence": 0.9051252007484436}]}, {"text": "This difference is not accounted for simply by the number of relevant documents, since there were considerably fewer relevant French documents per TREC-7 query than per TREC-6 query.", "labels": [], "entities": []}, {"text": "With this set of resources, we performed the two different sets of CLIR experiments, denoted EqFd (English queries retrieving French documents), and FqBd (French queries retrieving English documents.)", "labels": [], "entities": [{"text": "EqFd", "start_pos": 93, "end_pos": 97, "type": "METRIC", "confidence": 0.9408632516860962}, {"text": "FqBd", "start_pos": 149, "end_pos": 153, "type": "METRIC", "confidence": 0.9435163736343384}]}, {"text": "In both EqFd and' FqEd we employed both techniques (translating the queries, translating the documents).", "labels": [], "entities": [{"text": "FqEd", "start_pos": 18, "end_pos": 22, "type": "DATASET", "confidence": 0.8679186105728149}]}, {"text": "We emphasize that the query translation in EqFd was performed with the same English=~French translation system as the document translation in FqEd, and that the document translation EqFd was performed with the same French=~English translation system as the query translation in FqEd.", "labels": [], "entities": [{"text": "EqFd", "start_pos": 43, "end_pos": 47, "type": "DATASET", "confidence": 0.8532788157463074}, {"text": "FqEd", "start_pos": 142, "end_pos": 146, "type": "DATASET", "confidence": 0.9754568338394165}, {"text": "FqEd", "start_pos": 278, "end_pos": 282, "type": "DATASET", "confidence": 0.9887774586677551}]}, {"text": "We further emphasize that both translation systems were built from the same training data, and thus are as close to identical quality as can likely be attained.", "labels": [], "entities": [{"text": "translation", "start_pos": 31, "end_pos": 42, "type": "TASK", "confidence": 0.9626229405403137}]}, {"text": "Note also that the results presented are not the TREC-7 CLIR task, which involved both cross-language information retrieval and the merging of documents retrieved from sources in different languages.", "labels": [], "entities": [{"text": "TREC-7 CLIR task", "start_pos": 49, "end_pos": 65, "type": "TASK", "confidence": 0.524598240852356}, {"text": "cross-language information retrieval", "start_pos": 87, "end_pos": 123, "type": "TASK", "confidence": 0.6629196008046468}]}, {"text": "Preprocessing of documents includes partof-speech tagging and morphological analysis.", "labels": [], "entities": [{"text": "partof-speech tagging", "start_pos": 36, "end_pos": 57, "type": "TASK", "confidence": 0.8203778862953186}]}, {"text": "(The training data for the translation models was preprocessed identically, so that the translation models translated between morphological root words rather than between words.)", "labels": [], "entities": []}, {"text": "Our information retrieval systems consists of first pass scoring with the Okapi formula ( on unigrams and symmetrized bigrams (with en, des, de, and -allowed as connectors) followed by a second pass re-scoring using local context analysis (LCA) as a query expansion technique (.", "labels": [], "entities": [{"text": "information retrieval", "start_pos": 4, "end_pos": 25, "type": "TASK", "confidence": 0.7863781452178955}]}, {"text": "Our primary basis for comparison of the results of the experiments was TREC-style average precision after the second pass, although we have checked that our principal conclusions follow on the basis of first pass scores, and on the precision at rank 20.", "labels": [], "entities": [{"text": "TREC-style average precision after the second pass", "start_pos": 71, "end_pos": 121, "type": "METRIC", "confidence": 0.9004375338554382}, {"text": "precision", "start_pos": 232, "end_pos": 241, "type": "METRIC", "confidence": 0.9984186887741089}]}, {"text": "In the query translation experiments, our implementation of query expansion corresponds to the posttranslation expansion of,.", "labels": [], "entities": [{"text": "query translation", "start_pos": 7, "end_pos": 24, "type": "TASK", "confidence": 0.7797263264656067}]}, {"text": "All adjustable parameters in the IR system were left unchanged from their values in our TREC ad-hoc experiments (,,) or cited papers (, except for the number of documents used as the basis for the LCA, which was estimated at 15 from scaling considerations.", "labels": [], "entities": [{"text": "IR", "start_pos": 33, "end_pos": 35, "type": "TASK", "confidence": 0.9240936636924744}, {"text": "LCA", "start_pos": 197, "end_pos": 200, "type": "METRIC", "confidence": 0.6720923185348511}]}, {"text": "Average precision for both query and document translation were noted to be insensitive to this parameter (as previously observed in other contexts) and not to favor one or the other method of CLIR.", "labels": [], "entities": [{"text": "precision", "start_pos": 8, "end_pos": 17, "type": "METRIC", "confidence": 0.9990235567092896}, {"text": "document translation", "start_pos": 37, "end_pos": 57, "type": "TASK", "confidence": 0.6722018420696259}]}], "tableCaptions": [{"text": " Table 1: Experiment EqFd: English queries retrieving French documents  All numbers are TREC average precisions.  qt : query translation system  dt : document translation system  qt + dt : hybrid system combining qt and dt  ht : monolingual baseline (equivalent to human translation)  ht + dt : hybrid system combining ht and dt", "labels": [], "entities": [{"text": "TREC average precisions", "start_pos": 88, "end_pos": 111, "type": "METRIC", "confidence": 0.9386883775393168}]}, {"text": " Table 2: Experiment FqEd: French queries retrieving English documents  All numbers are TREC average precisions.", "labels": [], "entities": [{"text": "FqEd", "start_pos": 21, "end_pos": 25, "type": "DATASET", "confidence": 0.5855482816696167}, {"text": "TREC average precisions", "start_pos": 88, "end_pos": 111, "type": "METRIC", "confidence": 0.958127518494924}]}]}