{"title": [{"text": "Estimators for Stochastic \"Unification-Based\" Grammars*", "labels": [], "entities": []}], "abstractContent": [{"text": "Log-linear models provide a statistically sound framework for Stochastic \"Unification-Based\" Grammars (SUBGs) and stochastic versions of other kinds of grammars.", "labels": [], "entities": []}, {"text": "We describe two computationally-tractable ways of estimating the parameters of such grammars from a training corpus of syntactic analyses, and apply these to estimate a stochastic version of Lexical-Functional Grammar.", "labels": [], "entities": []}], "introductionContent": [{"text": "Probabilistic methods have revolutionized computational linguistics.", "labels": [], "entities": [{"text": "computational linguistics", "start_pos": 42, "end_pos": 67, "type": "TASK", "confidence": 0.7582065761089325}]}, {"text": "They can provide a systematic treatment of preferences in parsing.", "labels": [], "entities": [{"text": "parsing", "start_pos": 58, "end_pos": 65, "type": "TASK", "confidence": 0.9646621942520142}]}, {"text": "Given a suitable estimation procedure, stochastic models can be \"tuned\" to reflect the properties of a corpus.", "labels": [], "entities": []}, {"text": "On the other hand, \"Unification-Based\" Grammars (UBGs) can express a variety of linguistically-important syntactic and semantic constraints.", "labels": [], "entities": []}, {"text": "However, developing Stochastic \"Unification-based\" Grammars (SUBGs) has not proved as straightforward as might be hoped.", "labels": [], "entities": []}, {"text": "The simple \"relative frequency\" estimator for PCFGs yields the maximum likelihood parameter estimate, which is to say that it minimizes the Kulback-Liebler divergence between the training and estimated distributions.", "labels": [], "entities": [{"text": "maximum likelihood parameter estimate", "start_pos": 63, "end_pos": 100, "type": "METRIC", "confidence": 0.822923332452774}]}, {"text": "On the other hand, as points out, the context-sensitive dependencies that \"unification-based\" constraints introduce render the relative frequency estimator suboptimal: in general it does not maximize the likelihood and it is inconsistent.", "labels": [], "entities": []}, {"text": "* This research was supported by the National Science Foundation (SBR,-9720368), the US Army Research Office (DAAH04-96-BAA5), and Office of Naval Research (N00014-97-1-0249).", "labels": [], "entities": [{"text": "National Science Foundation (SBR,-9720368)", "start_pos": 37, "end_pos": 79, "type": "DATASET", "confidence": 0.928516335785389}, {"text": "US Army Research Office (DAAH04-96-BAA5)", "start_pos": 85, "end_pos": 125, "type": "DATASET", "confidence": 0.716466907943998}]}], "datasetContent": [{"text": "Ron Kaplan and Hadar Shemtov at Xerox PArtC provided us with two LFG parsed corpora.", "labels": [], "entities": [{"text": "Xerox PArtC", "start_pos": 32, "end_pos": 43, "type": "DATASET", "confidence": 0.8848372399806976}]}, {"text": "The Verbmobil corpus contains appointment planning dialogs, while the Homecentre corpus is drawn from Xerox printer documentation.", "labels": [], "entities": [{"text": "Verbmobil corpus", "start_pos": 4, "end_pos": 20, "type": "DATASET", "confidence": 0.898084819316864}, {"text": "Homecentre corpus", "start_pos": 70, "end_pos": 87, "type": "DATASET", "confidence": 0.9608703553676605}]}, {"text": "Table 1 summarizes the basic properties of these corpora.", "labels": [], "entities": []}, {"text": "These corpora contain packed c/fstructure representations of the grammatical parses of each sentence with respect to Lexical-Functional grammars.", "labels": [], "entities": []}, {"text": "The corpora also indicate which of these parses is in fact the correct parse (this information was manually entered).", "labels": [], "entities": []}, {"text": "Because slightly different grammars were used for each corpus we chose not to combine the two corpora, although we used the set of features described in section 2 for both in the experiments described below.", "labels": [], "entities": []}, {"text": "describes the properties of the features used for each corpus.", "labels": [], "entities": []}, {"text": "In addition to the two estimators described above we also present results from a baseline estimator in which all parses are treated as equally likely (this corresponds to setting all the parameters Oj to zero).", "labels": [], "entities": [{"text": "Oj", "start_pos": 198, "end_pos": 200, "type": "METRIC", "confidence": 0.9566349983215332}]}, {"text": "We evaluated our estimators using held-out test corpus ~test.", "labels": [], "entities": []}, {"text": "We used two evaluation measures.", "labels": [], "entities": []}, {"text": "In an actual parsing application a SUBG might be used to identify the correct parse from the set of grammatical parses, so our first evaluation measure counts the number Co(~test) of sentences in the test corpus ~test whose maximum likelihood parse under the estimated model 0 is actually the correct parse.", "labels": [], "entities": []}, {"text": "If a sentence has 1 most likely parses (i.e., all 1 parses have the same conditional probability) and one of these parses is the correct parse, then we score 1/l for this sentence.", "labels": [], "entities": []}, {"text": "The second evaluation measure is the pseudo-  The pseudolikelihood of the test corpus is the likelihood of the correct parses given their yields, so pseudolikelihood measures how much of the probability mass the model puts onto the correct analyses.", "labels": [], "entities": []}, {"text": "This metric seems more relevant to applications where the system needs to estimate how likely it is that the correct analysis lies in a certain set of possible parses; e.g., ambiguitypreserving translation and human-assisted disambiguation.", "labels": [], "entities": []}, {"text": "To make the numbers more manageable, we actually present the negative logarithm of the pseudo-likelihood rather than the pseudo-likelihood itself--so smaller is better.", "labels": [], "entities": []}, {"text": "Because of the small size of our corpora we evaluated our estimators using a 10-way crossvalidation paradigm.", "labels": [], "entities": []}, {"text": "We randomly assigned sentences of each corpus into 10 approximately equal-sized subcorpora, each of which was used in turn as the test corpus.", "labels": [], "entities": []}, {"text": "We evaluated on each subcorpus the parameters that were estimated from the 9 remaining subcorpora that served as the training corpus for this run.", "labels": [], "entities": []}, {"text": "The evaluation scores from each subcorpus were summed in order to provide the scores presented here.", "labels": [], "entities": []}, {"text": "presents the results of the empirical evaluation.", "labels": [], "entities": []}, {"text": "The superior performance of both estimators on the Verbmobil corpus probably reflects the fact that the non-rule features were designed to match both the grammar and content of that corpus.", "labels": [], "entities": [{"text": "Verbmobil corpus", "start_pos": 51, "end_pos": 67, "type": "DATASET", "confidence": 0.9568521976470947}]}, {"text": "The pseudolikelihood estimator performed better than the correct-parses estimator on both corpora under both evaluation metrics.", "labels": [], "entities": []}, {"text": "There seems to be substantial over learning in all these models; we routinely improved performance by discarding features.", "labels": [], "entities": []}, {"text": "With a small number of features the correct-parses estimator typically scores better than the pseudo-likelihood estimator on the correct-parses evaluation metric, but the pseudo-likelihood estimator always scores better on the pseudo-likelihood evaluation metric.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Properties of the two corpora used to evaluate the estimators.", "labels": [], "entities": []}, {"text": " Table 2: Properties of the features used in the stochastic LFG models. The numbers of pseudo- maximal and pseudo-minimal features do not include pseudo-constant features.", "labels": [], "entities": []}, {"text": " Table 3: An empirical evaluation of the estimators. C(~test) is the number of maximum likelihood", "labels": [], "entities": [{"text": "C(~test)", "start_pos": 53, "end_pos": 61, "type": "METRIC", "confidence": 0.7768907099962234}]}]}