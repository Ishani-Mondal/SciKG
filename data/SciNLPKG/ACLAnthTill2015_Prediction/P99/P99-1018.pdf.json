{"title": [], "abstractContent": [{"text": "We present a corpus-based study of the sequential ordering among premodifiers in noun phrases.", "labels": [], "entities": []}, {"text": "This information is important for the fluency of generated text in practical applications.", "labels": [], "entities": []}, {"text": "We propose and evaluate three approaches to identify sequential order among pre-modifiers: direct evidence, transitive closure, and clustering.", "labels": [], "entities": [{"text": "transitive closure", "start_pos": 108, "end_pos": 126, "type": "TASK", "confidence": 0.6917648613452911}]}, {"text": "Our implemented system can makeover 94% of such ordering decisions correctly , as evaluated on a large, previously unseen test corpus.", "labels": [], "entities": []}], "introductionContent": [{"text": "Sequential ordering among premodifiers affects the fluency of text, e.g., \"large foreign financial firms\" or \"zero-coupon global bonds\" are desirable, while \"foreign large financial firms\" or \"global zero-coupon bonds\" sound odd.", "labels": [], "entities": []}, {"text": "The difficulties in specifying a consistent ordering of adjectives have already been noted by linguists.", "labels": [], "entities": []}, {"text": "During the process of generating complex sentences by combining multiple clauses, there are situations where multiple adjectives or nouns modify the same head noun.", "labels": [], "entities": []}, {"text": "The text generation system must order these modifiers in a similar way as domain experts use them to ensure fluency of the text.", "labels": [], "entities": [{"text": "text generation", "start_pos": 4, "end_pos": 19, "type": "TASK", "confidence": 0.7076427042484283}]}, {"text": "For example, the description of the age of a patient precedes his ethnicity and gender in medical domain as in % 50 year-old white female patient\".", "labels": [], "entities": []}, {"text": "Yet, general lexicons such as WordNet] and COMLEX, do not store such information.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 30, "end_pos": 37, "type": "DATASET", "confidence": 0.9661802649497986}, {"text": "COMLEX", "start_pos": 43, "end_pos": 49, "type": "DATASET", "confidence": 0.9216890335083008}]}, {"text": "In this paper, we present automated techniques for addressing this problem of determining, given two premodifiers A and B, the preferred ordering between them.", "labels": [], "entities": []}, {"text": "Our methods rely on and generalize empirical evidence obtained from large corpora, and are evaluated objectively on such corpora.", "labels": [], "entities": []}, {"text": "They are informed and motivated by our practical need for ordering multiple premodifiers in the MAGIC system.", "labels": [], "entities": []}, {"text": "MAGIC utilizes co-ordinated text, speech, and graphics to convey information about a patient's status after coronary bypass surgery; it generates concise but complex descriptions that frequently involve four or more premodifiers in the same noun phrase.", "labels": [], "entities": []}, {"text": "To demonstrate that a significant portion of noun phrases have multiple premodifiers, we extracted all the noun phrases (NPs, excluding pronouns) in a two million word corpus of medical discharge summaries and a 1.5 million word Wall Street Journal (WSJ) corpus (see Section 4 fora more detailed description of the corpora).", "labels": [], "entities": [{"text": "Wall Street Journal (WSJ) corpus", "start_pos": 229, "end_pos": 261, "type": "DATASET", "confidence": 0.8845910344805036}]}, {"text": "In the medical corpus, out of 612,718 NPs, 12% have multiple premodifiers and 6% contain solely multiple adjectival premodifiers.", "labels": [], "entities": []}, {"text": "In the WSJ corpus, the percentages area little lower, 8% and 2%, respectively.", "labels": [], "entities": [{"text": "WSJ corpus", "start_pos": 7, "end_pos": 17, "type": "DATASET", "confidence": 0.8735235631465912}]}, {"text": "These percentages imply that one in ten NPs contains multiple premodifiers while one in 25 contains just multiple adjectives.", "labels": [], "entities": []}, {"text": "Traditionally, linguists study the premodifier ordering problem using a class-based approach.", "labels": [], "entities": []}, {"text": "Based on a corpus, they propose various semantic classes, such as color, size, or nationality, and specify a sequential order among the classes.", "labels": [], "entities": []}, {"text": "However, it is not always clear how to map premodifiers to these classes, especially in domain-specific applications.", "labels": [], "entities": []}, {"text": "This justifies the exploration of empirical, corpus-based alternatives, where the ordering between A and B is determined either from direct prior evidence in the corpus or indirectly through other words whose relative order to A and B has already been established.", "labels": [], "entities": []}, {"text": "The corpus-based approach lacks the ontological knowledge used by linguists, but uses a much larger amount of di-rect evidence, provides answers for many more premodifier orderings, and is portable to different domains.", "labels": [], "entities": []}, {"text": "In the next section, we briefly describe prior linguistic research on this topic.", "labels": [], "entities": []}, {"text": "Sections 3 and 4 describe the methodology and corpus used in our analysis, while the results of our experiments are presented in Section 5.", "labels": [], "entities": []}, {"text": "In Section 6, we demonstrate how we incorporated our ordering results in a general text generation system.", "labels": [], "entities": [{"text": "text generation", "start_pos": 83, "end_pos": 98, "type": "TASK", "confidence": 0.7030439972877502}]}, {"text": "Finally, Section 7 discusses possible improvements to our current approach.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": []}