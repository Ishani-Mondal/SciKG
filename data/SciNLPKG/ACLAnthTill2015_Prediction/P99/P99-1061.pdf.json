{"title": [{"text": "A Bag of Useful Techniques for Efficient and Robust Parsing", "labels": [], "entities": []}], "abstractContent": [{"text": "This paper describes new and improved techniques which help a unification-based parser to process input efficiently and robustly.", "labels": [], "entities": []}, {"text": "In combination these methods result in a speed-up in parsing time of more than an order of magnitude.", "labels": [], "entities": [{"text": "parsing", "start_pos": 53, "end_pos": 60, "type": "TASK", "confidence": 0.9811981320381165}]}, {"text": "The methods are correct in the sense that none of them rule out legal rule applications.", "labels": [], "entities": []}, {"text": "1 Introduction This paper describes several generally-applicable techniques which help a unification-based parser to process input efficiently and robustly.", "labels": [], "entities": []}, {"text": "As well as presenting a number of new methods, we also report significant improvements we have made to existing techniques.", "labels": [], "entities": []}, {"text": "The methods preserve correctness in the sense they do not rule out legal rule applications.", "labels": [], "entities": []}, {"text": "In particular, none of the techniques involve statistical or approximate processing.", "labels": [], "entities": []}, {"text": "We also claim that these methods are independent of the concrete parser and neutral with respect to a given unification-based grammar theory/formalism.", "labels": [], "entities": []}, {"text": "How can we gain reasonable efficiency in parsing when using large integrated grammars with several thousands of huge lexicon entries?", "labels": [], "entities": []}, {"text": "Our belief is that there is no single method which achieves this goal alone.", "labels": [], "entities": []}, {"text": "Instead, we have to develop and use a set of \"cheap\" filters which are correct in the above sense.", "labels": [], "entities": []}, {"text": "As we indicate in section 10, combining these methods leads to a speed-up in parsing time (and reduction of space consumption) of more than an order of magnitude when applied to a mature, well engineered unification-based parsing system.", "labels": [], "entities": [{"text": "parsing", "start_pos": 77, "end_pos": 84, "type": "TASK", "confidence": 0.9849648475646973}, {"text": "unification-based parsing", "start_pos": 204, "end_pos": 229, "type": "TASK", "confidence": 0.691113144159317}]}, {"text": "We have implemented our methods as extensions to a HPSG grammar development environment (Uszkoreit et al., 1994) which employs a sophisticated typed feature formalism (Krieger", "labels": [], "entities": []}], "introductionContent": [{"text": "This paper describes several generallyapplicable techniques which help a unificationbased parser to process input efficiently and robustly.", "labels": [], "entities": []}, {"text": "As well as presenting a number of new methods, we also report significant improvements we have made to existing techniques.", "labels": [], "entities": []}, {"text": "The methods preserve correctness in the sense they do not rule out legal rule applications.", "labels": [], "entities": []}, {"text": "In particular, none of the techniques involve statistical or approximate processing.", "labels": [], "entities": []}, {"text": "We also claim that these methods are independent of the concrete parser and neutral with respect to a given unification-based grammar theory/formalism.", "labels": [], "entities": []}, {"text": "How can we gain reasonable efficiency in parsing when using large integrated grammars with several thousands of huge lexicon entries?", "labels": [], "entities": []}, {"text": "Our belief is that there is no single method which achieves this goal alone.", "labels": [], "entities": []}, {"text": "Instead, we have to develop and use a set of \"cheap\" filters which are correct in the above sense.", "labels": [], "entities": []}, {"text": "As we indicate in section 10, combining these methods leads to a speed-up in parsing time (and reduction of space consumption) of more than an order of magnitude when applied to a mature, well engineered unification-based parsing system.", "labels": [], "entities": [{"text": "parsing", "start_pos": 77, "end_pos": 84, "type": "TASK", "confidence": 0.9849648475646973}, {"text": "unification-based parsing", "start_pos": 204, "end_pos": 229, "type": "TASK", "confidence": 0.691113144159317}]}, {"text": "We have implemented our methods as extensions to a HPSG grammar development environment ( which employs a sophisticated typed feature formalism and an advanced agenda-based bottom-up chart parser.", "labels": [], "entities": [{"text": "HPSG grammar development", "start_pos": 51, "end_pos": 75, "type": "TASK", "confidence": 0.7360938390096029}]}, {"text": "A specialized runtime version of this system is currently used in VERBMOBIL as the primary deep analysis component.", "labels": [], "entities": [{"text": "VERBMOBIL", "start_pos": 66, "end_pos": 75, "type": "DATASET", "confidence": 0.9155303239822388}]}, {"text": "I In the next three sections, we report on transformations we have applied to the knowledge base (grammar/lexicon) and on modifications in the core formalism (unifier, type system).", "labels": [], "entities": []}, {"text": "In Section 5-8, we describe how a given parser can be extended to filter out possible rule applications efficiently before performing \"expensive\" unification.", "labels": [], "entities": []}, {"text": "Section 9 shows how to compute best partial analyses in order to gain a certain level of robustness.", "labels": [], "entities": []}, {"text": "Finally, we present empirical results to demonstrate the efficiency gains, and speculate on extensions we intend to work on in the near future.", "labels": [], "entities": []}, {"text": "Within the different sections, we refer to three corpora we have used to measure the effects of our methods.", "labels": [], "entities": []}, {"text": "The reference corpora for English, German, and Japanese consist of 1200-5000 samples.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": []}