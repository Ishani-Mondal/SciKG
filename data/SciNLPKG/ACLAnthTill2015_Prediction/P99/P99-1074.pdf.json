{"title": [{"text": "Robust, Finite-State Parsing for Spoken Language Understanding", "labels": [], "entities": [{"text": "Spoken Language Understanding", "start_pos": 33, "end_pos": 62, "type": "TASK", "confidence": 0.811979353427887}]}], "abstractContent": [{"text": "Human understanding of spoken language appears to integrate the use of contextual expectations with acoustic level perception in a tightly-coupled, sequential fashion.", "labels": [], "entities": []}, {"text": "Yet computer speech understanding systems typically pass the transcript produced by a speech rec-ognizer into a natural language parser with no integration of acoustic and grammatical constraints.", "labels": [], "entities": []}, {"text": "One reason for this is the complexity of implementing that integration.", "labels": [], "entities": []}, {"text": "To address this issue we have created a robust, semantic parser as a single finite-state machine (FSM).", "labels": [], "entities": []}, {"text": "As such, its run-time action is less complex than other robust parsers that are based on either chart or generalized left-right (GLR) architectures.", "labels": [], "entities": []}, {"text": "Therefore, we believe it is ultimately more amenable to direct integration with a speech decoder.", "labels": [], "entities": []}], "introductionContent": [{"text": "An important goal in speech processing is to extract meaningful information: in this, the task is understanding rather than transcription.", "labels": [], "entities": [{"text": "speech processing", "start_pos": 21, "end_pos": 38, "type": "TASK", "confidence": 0.7612015902996063}]}, {"text": "For extracting meaning from spontaneous speech full coverage grammars tend to be too brittle.", "labels": [], "entities": [{"text": "extracting meaning from spontaneous speech full coverage grammars", "start_pos": 4, "end_pos": 69, "type": "TASK", "confidence": 0.86052405834198}]}, {"text": "In the 1992 DARPA ATIS task competition, CMU's Phoenix parser was the best scoring system.", "labels": [], "entities": [{"text": "1992 DARPA ATIS task competition", "start_pos": 7, "end_pos": 39, "type": "TASK", "confidence": 0.43819583058357237}]}, {"text": "Phoenix operates in a loosely-coupled architecture on the 1-best transcript produced by the recognizer.", "labels": [], "entities": []}, {"text": "Conceptually it is a semantic case-frame parser (.", "labels": [], "entities": []}, {"text": "As such, it allows slots within a particular ease-frame to be filled in any order, and allows out-of-grammar words between slots to be skipped over.", "labels": [], "entities": []}, {"text": "Thus it can return partial parses --as frames in which only some of the available slots have been filled.", "labels": [], "entities": []}, {"text": "Humans appear to perform robust understanding in a tightly-coupled fashion.", "labels": [], "entities": []}, {"text": "They build incremental, partial analyses of an utterance as it is being spoken, in away that helps them to meaningfully interpret the acoustic evidence.", "labels": [], "entities": []}, {"text": "To move toward machine understanding systems that tightly-couple acoustic features and structural knowledge, researchers like have argued for the use of finite-state acceptors (FSAs) as an efficient means of integrating structural knowledge into the recognition process for limited domain tasks.", "labels": [], "entities": []}, {"text": "We have constructed a parser for spontaneous speech that is at once both robust and finitestate.", "labels": [], "entities": []}, {"text": "It is called PROFER, for Predictive, RObust, Finite-state parsER.", "labels": [], "entities": []}, {"text": "Currently PROFER accepts a transcript as input.", "labels": [], "entities": [{"text": "PROFER", "start_pos": 10, "end_pos": 16, "type": "DATASET", "confidence": 0.6297674179077148}]}, {"text": "We are modifying it to accept a word-graph as input.", "labels": [], "entities": []}, {"text": "Our aim is to incorporate PROFER directly into a recognizer.", "labels": [], "entities": []}, {"text": "For example, using a grammar that defines sequences of numbers (each of which is less than ten thousand and greater than ninety-nine and contains the word \"hundred\"), inputs like the following string can be robustly parsed by PRO-FER: Input: first I've got twenty ahhh thirty yaaaaaa thirty ohh wait no twenty twenty nine hundred two errr three ahhh four and then two hundred ninety uhhhhh let me be sure here yaaaa ninety seven and last is five oh seven uhhh I mean six Parse-tree: [ There are two characteristically \"robust\" actions that are illustrated by this example.", "labels": [], "entities": [{"text": "Parse-tree", "start_pos": 471, "end_pos": 481, "type": "METRIC", "confidence": 0.9147117137908936}]}, {"text": "\u2022 For each \"slot\" (i.e., \"As\" element) filled in the parse-tree's case-frame structure, there were several words both before and after the required word, hundred, that had to be skipped-over.", "labels": [], "entities": []}, {"text": "This aspect of robust parsing is akin to phrase-spotting.", "labels": [], "entities": []}, {"text": "\u2022 In mapping the words, \"five oh seven uhhh I mean six,\" the parser had to choose a later-in-the-input parse (i.e., \"[five, hundred, six]\") over a heuristically equivalent earlier-in-the-input parse (i.e., \"[five, hundred, seven]\").", "labels": [], "entities": []}, {"text": "This aspect of robust parsing is akin to dynamic programming (i.e., finding all possible start and end points for all possible patterns and choosing the best).", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": []}