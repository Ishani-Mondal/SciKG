{"title": [{"text": "Automatic Identification of Word Translations from Unrelated English and German Corpora", "labels": [], "entities": [{"text": "Automatic Identification of Word Translations from Unrelated English and German Corpora", "start_pos": 0, "end_pos": 87, "type": "TASK", "confidence": 0.7817760543389753}]}], "abstractContent": [{"text": "Algorithms for the alignment of words in translated texts are well established.", "labels": [], "entities": [{"text": "alignment of words in translated texts", "start_pos": 19, "end_pos": 57, "type": "TASK", "confidence": 0.8559843103090922}]}, {"text": "However , only recently new approaches have been proposed to identify word translations from non-parallel or even unrelated texts.", "labels": [], "entities": [{"text": "identify word translations from non-parallel", "start_pos": 61, "end_pos": 105, "type": "TASK", "confidence": 0.7534841895103455}]}, {"text": "This task is more difficult, because most statistical clues useful in the processing of parallel texts cannot be applied to non-parallel texts.", "labels": [], "entities": []}, {"text": "Whereas for parallel texts in some studies up to 99% of the word alignments have been shown to be correct, the accuracy for non-parallel texts has been around 30% up to now.", "labels": [], "entities": [{"text": "word alignments", "start_pos": 60, "end_pos": 75, "type": "TASK", "confidence": 0.685801163315773}, {"text": "accuracy", "start_pos": 111, "end_pos": 119, "type": "METRIC", "confidence": 0.9993054866790771}]}, {"text": "The current study, which is based on the assumption that there is a correlation between the patterns of word co-occurrences in corpora of different languages , makes a significant improvement to about 72% of word translations identified correctly.", "labels": [], "entities": [{"text": "word translations identified", "start_pos": 208, "end_pos": 236, "type": "TASK", "confidence": 0.7735848923524221}]}], "introductionContent": [{"text": "Starting with the well-known paper of on statistical machine translation, there has been much scientific interest in the alignment of sentences and words in translated texts.", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 41, "end_pos": 72, "type": "TASK", "confidence": 0.6350416739781698}, {"text": "alignment of sentences and words in translated texts", "start_pos": 121, "end_pos": 173, "type": "TASK", "confidence": 0.840309239923954}]}, {"text": "Many studies show that for nicely parallel corpora high accuracy rates of up to 99% can be achieved for both sentence and word alignment.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 56, "end_pos": 64, "type": "METRIC", "confidence": 0.999092698097229}, {"text": "word alignment", "start_pos": 122, "end_pos": 136, "type": "TASK", "confidence": 0.6814958453178406}]}, {"text": "Of course, in practice -due to omissions, transpositions, insertions, and replacements in the process of translation -with real texts there maybe all kinds of problems, and therefore robustness is still an issue ().", "labels": [], "entities": []}, {"text": "Nevertheless, the results achieved with these algorithms have been found useful for the cornpilation of dictionaries, for checking the consistency of terminological usage in translations, for assisting the terminological work of translators and interpreters, and for example-based machine translation.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 281, "end_pos": 300, "type": "TASK", "confidence": 0.7820511758327484}]}, {"text": "By now, some alignment programs are offered commercially: Translation memory tools for translators, such as IBM's Translation Manager or Trados' Translator's Workbench, are bundled or can be upgraded with programs for sentence alignment.", "labels": [], "entities": [{"text": "sentence alignment", "start_pos": 218, "end_pos": 236, "type": "TASK", "confidence": 0.785771518945694}]}, {"text": "Most of the proposed algorithms first conduct an alignment of sentences, that is, they locate those pairs of sentences that are translations of each other.", "labels": [], "entities": []}, {"text": "Ina second step a word alignment is performed by analyzing the correspondences of words in each pair of sentences.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 18, "end_pos": 32, "type": "TASK", "confidence": 0.7208413779735565}]}, {"text": "The algorithms are usually based on one or several of the following statistical clues: 1.", "labels": [], "entities": []}, {"text": "correspondence of word and sentence order 2.", "labels": [], "entities": []}, {"text": "correlation between word frequencies 3.", "labels": [], "entities": []}, {"text": "cognates: similar spelling of words in related languages All these clues usually work well for parallel texts.", "labels": [], "entities": []}, {"text": "However, despite serious efforts in the compilation of parallel corpora, the availability of a large-enough parallel corpus in a specific domain and fora given pair of languages is still an exception.", "labels": [], "entities": []}, {"text": "Since the acquisition of monolingual corpora is much easier, it would be desirable to have a program that can determine the translations of words from comparable (same domain) or possibly unrelated monolingnal texts of two languages.", "labels": [], "entities": []}, {"text": "This is what translators and interpreters usually do when preparing terminology in a specific field: They read texts corresponding to this field in both languages and draw their conclusions on word correspondences from the usage of the terms.", "labels": [], "entities": []}, {"text": "Of course, the translators and interpreters can understand the texts, whereas our programs are only considering a few statistical clues.", "labels": [], "entities": []}, {"text": "For non-parallel texts the first clue, which is usually by far the strongest of the three mentioned above, is not applicable at all.", "labels": [], "entities": []}, {"text": "The second clue is generally less powerful than the first, since most words are ambiguous in natural languages, and many ambiguities are different across languages.", "labels": [], "entities": []}, {"text": "Nevertheless, this clue is applicable in the case of comparable texts, although with a lower reliability than for parallel texts.", "labels": [], "entities": [{"text": "reliability", "start_pos": 93, "end_pos": 104, "type": "METRIC", "confidence": 0.9911565780639648}]}, {"text": "However, in the case of unrelated texts, its usefulness maybe near zero.", "labels": [], "entities": []}, {"text": "The third clue is generally limited to the identification of word pairs with similar spelling.", "labels": [], "entities": []}, {"text": "For all other pairs, it is usually used in combination with the first clue.", "labels": [], "entities": []}, {"text": "Since the first clue does notwork with non-parallel texts, the third clue is useless for the identification of the majority of pairs.", "labels": [], "entities": []}, {"text": "For unrelated languages, it is not applicable anyway.", "labels": [], "entities": []}, {"text": "In this situation, proposed using a clue different from the three mentioned above: His co-occurrence clue is based on the assumption that there is a correlation between cooccurrence patterns in different languages.", "labels": [], "entities": []}, {"text": "For example, if the words teacher and school cooccur more often than expected by chance in a corpus of English, then the German translations of teacher and school, Lehrer and Schule, should also co-occur more often than expected in a corpus of German.", "labels": [], "entities": []}, {"text": "Ina feasibility study he showed that this assumption actually holds for the language pair English/German even in the case of unrelated texts.", "labels": [], "entities": []}, {"text": "When comparing an English and a German co-occurrence matrix of corresponding words, he found a high correlation between the co-occurrence patterns of the two matrices when the rows and columns of both matrices were in corresponding word order, and a low correlation when the rows and columns were in random order.", "labels": [], "entities": []}, {"text": "The validity of the co-occurrence clue is obvious for parallel corpora, but -as empirically shown by Rapp -it also holds for non-parallel corpora.", "labels": [], "entities": []}, {"text": "It can be expected that this clue will work best with parallel corpora, second-best with comparable corpora, and somewhat worse with unrelated corpora.", "labels": [], "entities": []}, {"text": "In all three cases, the problem of robustness -as observed when applying the word-order clue to parallel corpora-is not severe.", "labels": [], "entities": []}, {"text": "Transpositions of text segments have virtually no negative effect, and omissions or insertions are not critical.", "labels": [], "entities": []}, {"text": "However, the co-occurrence clue when applied to comparable corpora is much weaker than the word-order clue when applied to parallel corpora, so larger corpora and well-chosen statistical methods are required.", "labels": [], "entities": []}, {"text": "After an attempt with a context heterogeneity measure for identifying word translations, Fung based her later work also on the co-occurrence assumption.", "labels": [], "entities": [{"text": "identifying word translations", "start_pos": 58, "end_pos": 87, "type": "TASK", "confidence": 0.79586128393809}]}, {"text": "By presupposing a lexicon of seed words, she avoids the prohibitively expensive computational effort encountered by.", "labels": [], "entities": []}, {"text": "The method described here -although developed independently of Fung's work-goes in the same direction.", "labels": [], "entities": []}, {"text": "Conceptually, it is a trivial case of Rapp's matrix permutation method.", "labels": [], "entities": []}, {"text": "By simply assuming an initial lexicon the large number of permutations to be considered is reduced to a much smaller number of vector comparisons.", "labels": [], "entities": []}, {"text": "The main contribution of this paper is to describe a practical implementation based on the co-occurrence clue that yields good results.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Results for 20 of the 100 test words (for full list see http://www.fask.uni-mainz.de/user/rappl)", "labels": [], "entities": []}]}