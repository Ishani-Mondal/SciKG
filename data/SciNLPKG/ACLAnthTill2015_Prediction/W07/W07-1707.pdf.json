{"title": [{"text": "Unsupervised Methods of Topical Text Segmentation for Polish", "labels": [], "entities": [{"text": "Topical Text Segmentation", "start_pos": 24, "end_pos": 49, "type": "TASK", "confidence": 0.8600569566090902}]}], "abstractContent": [{"text": "This paper describes a study on performance of existing unsupervised algorithms of text documents topical segmentation when applied to Polish plain text documents.", "labels": [], "entities": [{"text": "topical segmentation", "start_pos": 98, "end_pos": 118, "type": "TASK", "confidence": 0.758179247379303}]}, {"text": "For performance measurement five existing topical segmentation algorithms were selected, three different Polish test collections were created and seven approaches to text pre-processing were implemented.", "labels": [], "entities": [{"text": "topical segmentation", "start_pos": 42, "end_pos": 62, "type": "TASK", "confidence": 0.7072602659463882}, {"text": "Polish test collections", "start_pos": 105, "end_pos": 128, "type": "DATASET", "confidence": 0.7096085747083029}]}, {"text": "Based on quantitative results (P k and WindowDiff metrics) use of specific algorithm was recommended and impact of pre-processing strategies was assessed.", "labels": [], "entities": []}, {"text": "Thanks to use of standardized metrics and application of previously described methodology for test collection development, comparative results for Polish and English were also obtained.", "labels": [], "entities": []}], "introductionContent": [{"text": "Rapid development of Internet-based information services is marked by a proliferation of information available on-line.", "labels": [], "entities": []}, {"text": "Even if the Web shifts towards multimedia content and structured documents, contents of the Web sources remains predominantly textual and poorly structured; an important fraction of this flood of plain text documents consists in multitopical documents.", "labels": [], "entities": []}, {"text": "This abundance of complex but plain text or just visually structured documents (as is in case of most HTML files) creates a strong need for intelligent text processing including robust and efficient information extraction and retrieval.", "labels": [], "entities": [{"text": "information extraction and retrieval", "start_pos": 199, "end_pos": 235, "type": "TASK", "confidence": 0.6727101728320122}]}, {"text": "One way of increasing efficiency of typical text processing tasks consists in processing separately text segments instead of whole documents.", "labels": [], "entities": []}, {"text": "While different text segmentation strategies can be applied including splitting text into segments of equal length, using moving windows of constant size or discourse units, division into topical segment is intuitively more justified.", "labels": [], "entities": [{"text": "text segmentation", "start_pos": 16, "end_pos": 33, "type": "TASK", "confidence": 0.7475762367248535}]}, {"text": "This approach is applicable in several IR and NLP areas including document indexing, automatic summarization and question answering).", "labels": [], "entities": [{"text": "document indexing", "start_pos": 66, "end_pos": 83, "type": "TASK", "confidence": 0.728257030248642}, {"text": "summarization", "start_pos": 95, "end_pos": 108, "type": "TASK", "confidence": 0.8115288615226746}, {"text": "question answering", "start_pos": 113, "end_pos": 131, "type": "TASK", "confidence": 0.8417340815067291}]}, {"text": "For Information Extraction domain, two main application of topical document segmentation are related to documents pre-processing and supporting some basic tasks widely used by IE tools.", "labels": [], "entities": [{"text": "Information Extraction domain", "start_pos": 4, "end_pos": 33, "type": "TASK", "confidence": 0.8258822162946066}, {"text": "topical document segmentation", "start_pos": 59, "end_pos": 88, "type": "TASK", "confidence": 0.6674255927403768}]}, {"text": "Topical segmentation applied to individual documents as well as documents streams (e.g. dialogues of radio broadcast transcripts) is an initial step for further IE processing; when combined with segments labelling, classification or clustering) it allows to pre-select ranges of text to be mined for mentions of events, entities and relations relevant to users needs and available IE resources.", "labels": [], "entities": [{"text": "Topical segmentation", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.7911067306995392}, {"text": "IE processing", "start_pos": 161, "end_pos": 174, "type": "TASK", "confidence": 0.9709464907646179}]}, {"text": "This limits significantly size of text to be processed by IE methods and thus influences significantly overall IE performance.", "labels": [], "entities": [{"text": "IE", "start_pos": 111, "end_pos": 113, "type": "TASK", "confidence": 0.9714944958686829}]}, {"text": "On the other hand, many basic tasks required by IE domain (both related to IE resources creation and document (pre-)processing) make use of sections rather than whole documents.", "labels": [], "entities": [{"text": "IE resources creation", "start_pos": 75, "end_pos": 96, "type": "TASK", "confidence": 0.7940687537193298}]}, {"text": "In these tasks including language modelling (esp. gathering of co-occurrences statistics for trigger-based language models), anaphora resolution, word sense disambiguation and coreference detection, definition of proper context is crucial.", "labels": [], "entities": [{"text": "language modelling", "start_pos": 25, "end_pos": 43, "type": "TASK", "confidence": 0.7328616678714752}, {"text": "anaphora resolution", "start_pos": 125, "end_pos": 144, "type": "TASK", "confidence": 0.7370806634426117}, {"text": "word sense disambiguation", "start_pos": 146, "end_pos": 171, "type": "TASK", "confidence": 0.6998293201128641}, {"text": "coreference detection", "start_pos": 176, "end_pos": 197, "type": "TASK", "confidence": 0.9694697558879852}, {"text": "definition of proper context", "start_pos": 199, "end_pos": 227, "type": "TASK", "confidence": 0.8602844476699829}]}, {"text": "To this extend entities discovered by topical segmentation are more reliable than document, paragraph or sentence contexts as they help avoid usage of unrelated parts of documents as well as minimize sparse data problems).", "labels": [], "entities": []}], "datasetContent": [{"text": "Segmentation algorithms performance was evaluated for 42 scenarios corresponding to different algorithms, pre-processing strategies and test collections.", "labels": [], "entities": []}, {"text": "For quantitative analysis and comparability with previous and future research results two standard segmentation metrics were applied in all scenarios.", "labels": [], "entities": []}, {"text": "A number of different measurement methods were applied to topical texts segmentation including recall-precision pair; Passonneau and Litman, 1997), edit distance), P \u00b5 (), P k () and.", "labels": [], "entities": [{"text": "topical texts segmentation", "start_pos": 58, "end_pos": 84, "type": "TASK", "confidence": 0.6173507074515024}, {"text": "recall-precision pair", "start_pos": 95, "end_pos": 116, "type": "METRIC", "confidence": 0.9631019532680511}, {"text": "edit distance", "start_pos": 148, "end_pos": 161, "type": "METRIC", "confidence": 0.8735593855381012}, {"text": "P \u00b5", "start_pos": 164, "end_pos": 167, "type": "METRIC", "confidence": 0.9512962698936462}]}, {"text": "P k is simplified version of probabilistic measure P \u00b5 based on assumption that any two consecutive boundaries are at distance of k sentences (k being parameter normally set to half of length of average segment in reference segmentation).", "labels": [], "entities": []}, {"text": "After some simplifications P k is defined by the following formula): where \u03b4 X (i, k) equals to one if ith and (i + k)th sentences are in the same segment of segmentation X, otherwise it is equal to zero; X = r corresponds to reference segmentation and X = h corresponds to hypothetical (algorithm-generated) segmentation.", "labels": [], "entities": []}, {"text": "In most publication instead of performance measurement using P k , probabilistic error metric (P = 1 \u2212 P k (r, h)) is applied.", "labels": [], "entities": [{"text": "probabilistic error metric", "start_pos": 67, "end_pos": 93, "type": "METRIC", "confidence": 0.6748714248339335}]}, {"text": "For easier comparison with previous results we calculated this measure for tested evaluation scenarios.", "labels": [], "entities": []}, {"text": "Based on a profound analysis of P k and probabilistic metric drawbacks more recently WindowDiff error measure was proposed based on counting number of boundaries within window of size of k sentences sliding parallelly over both hypothetical and reference segmentations.", "labels": [], "entities": [{"text": "WindowDiff error measure", "start_pos": 85, "end_pos": 109, "type": "METRIC", "confidence": 0.6217536826928457}]}, {"text": "WindowDiff can be calculated by the following formula: with b X (i, k) corresponding to the number of boundaries between positions i and i + kin segmentation X.", "labels": [], "entities": []}, {"text": "Both probabilistic error and WindowDiff measure the segmentation error; therefore, the lower is their value, the better is segmentation result.", "labels": [], "entities": []}, {"text": "Calculated values of P and WindowDiff (W D) measures were used to compare performance of different algorithms, collections and pre-processing strategies.", "labels": [], "entities": []}, {"text": "If not stated otherwise, results displayed in this Section correspond to P1 variant (no preprocessing) of test collections.", "labels": [], "entities": [{"text": "P1", "start_pos": 73, "end_pos": 75, "type": "METRIC", "confidence": 0.9167818427085876}]}], "tableCaptions": [{"text": " Table 1. Any two selected articles were as- sumed to cover two different topics; thus reference  segmentation boundaries corresponded to points of  concatenations.", "labels": [], "entities": []}, {"text": " Table 1: Artificial collection subcollections", "labels": [], "entities": []}, {"text": " Table 2: The average length of reference segments", "labels": [], "entities": []}, {"text": " Table 4: Comparison of methods not requiring num- ber of segments as input", "labels": [], "entities": []}, {"text": " Table 5: Comparison of methods requiring number  of segments as input", "labels": [], "entities": []}, {"text": " Table 6: Impact of segments count provided as input", "labels": [], "entities": []}, {"text": " Table 8: Impact of different pre-processing variants", "labels": [], "entities": []}]}