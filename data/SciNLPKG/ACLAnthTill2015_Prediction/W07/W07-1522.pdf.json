{"title": [{"text": "Annotating a Japanese Text Corpus with Predicate-Argument and Coreference Relations", "labels": [], "entities": [{"text": "Japanese Text Corpus", "start_pos": 13, "end_pos": 33, "type": "DATASET", "confidence": 0.6805740892887115}]}], "abstractContent": [{"text": "In this paper, we discuss how to annotate coreference and predicate-argument relations in Japanese written text.", "labels": [], "entities": []}, {"text": "There have been research activities for building Japanese text corpora annotated with coref-erence and predicate-argument relations as are done in the Kyoto Text Corpus version 4.0 (Kawahara et al., 2002) and the GDA-Tagged Corpus (Hasida, 2005).", "labels": [], "entities": [{"text": "Kyoto Text Corpus version 4.0 (Kawahara et al., 2002)", "start_pos": 151, "end_pos": 204, "type": "DATASET", "confidence": 0.9271509299675623}, {"text": "GDA-Tagged Corpus (Hasida, 2005)", "start_pos": 213, "end_pos": 245, "type": "DATASET", "confidence": 0.9443105033465794}]}, {"text": "However, there is still much room for refining their specifications.", "labels": [], "entities": []}, {"text": "For this reason, we discuss issues in annotating these two types of relations , and propose anew specification for each.", "labels": [], "entities": []}, {"text": "In accordance with the specification, we built a large-scaled annotated corpus, and examined its reliability.", "labels": [], "entities": []}, {"text": "As a result of our current work, we have released an annotated corpus named the NAIST Text Corpus 1 , which is used as the evaluation data set in the coreference and zero-anaphora resolution tasks in Iida et al.", "labels": [], "entities": [{"text": "NAIST Text Corpus 1", "start_pos": 80, "end_pos": 99, "type": "DATASET", "confidence": 0.9746197015047073}, {"text": "coreference and zero-anaphora resolution", "start_pos": 150, "end_pos": 190, "type": "TASK", "confidence": 0.6488693878054619}]}, {"text": "(2005) and Iida et al.", "labels": [], "entities": []}], "introductionContent": [{"text": "Coreference resolution and predicate-argument structure analysis has recently been a growing field of research due to the demands from NLP application such as information extraction and machine translation.", "labels": [], "entities": [{"text": "Coreference resolution", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.9262428283691406}, {"text": "predicate-argument structure analysis", "start_pos": 27, "end_pos": 64, "type": "TASK", "confidence": 0.7604820529619852}, {"text": "information extraction", "start_pos": 159, "end_pos": 181, "type": "TASK", "confidence": 0.829278975725174}, {"text": "machine translation", "start_pos": 186, "end_pos": 205, "type": "TASK", "confidence": 0.7926464974880219}]}, {"text": "With the research focus placed on these tasks, the specification of annotating corpora and the data sets used in supervised techniques () have also grown in sophistication.", "labels": [], "entities": []}, {"text": "For English, several annotation schemes have already been proposed for both coreference relation and argument structure, and annotated corpora have been developed accordingly).", "labels": [], "entities": [{"text": "coreference relation", "start_pos": 76, "end_pos": 96, "type": "TASK", "confidence": 0.9301778376102448}]}, {"text": "For instance, in the Coreference task on Message Understanding Conference (MUC) and the Entity Detection and Tracking (EDT) task in the Automatic Content Extraction (ACE) program, which is the successor of MUC, the details of specification of annotating coreference relation have been discussed for several years.", "labels": [], "entities": [{"text": "Coreference task on Message Understanding Conference (MUC)", "start_pos": 21, "end_pos": 79, "type": "TASK", "confidence": 0.8043261302842034}, {"text": "Entity Detection and Tracking (EDT) task", "start_pos": 88, "end_pos": 128, "type": "TASK", "confidence": 0.8114832118153572}, {"text": "MUC", "start_pos": 206, "end_pos": 209, "type": "DATASET", "confidence": 0.8827254772186279}]}, {"text": "On the other hand, the specification of predicate-argument structure analysis has mainly been discussed in the context of the CoNLL shared task 2 on the basis of the PropBank ().", "labels": [], "entities": [{"text": "predicate-argument structure analysis", "start_pos": 40, "end_pos": 77, "type": "TASK", "confidence": 0.8091048796971639}]}, {"text": "In parallel with these efforts, there have also been research activities for building Japanese text corpora annotated with coreference and predicate-argument relations such as the Kyoto Text Corpus version 4.0 () and the GDA 3 -Tagged Corpus ().", "labels": [], "entities": [{"text": "Kyoto Text Corpus version 4.0", "start_pos": 180, "end_pos": 209, "type": "DATASET", "confidence": 0.9577001571655274}, {"text": "GDA 3 -Tagged Corpus", "start_pos": 221, "end_pos": 241, "type": "DATASET", "confidence": 0.8351286053657532}]}, {"text": "However, as we discuss in this paper, there is still much room for arguing and refining the specification of such sorts of semantic annotation.", "labels": [], "entities": []}, {"text": "In fact, for neither of the above two corpora, the adequacy and reliability of the annotation scheme has been deeply examined.", "labels": [], "entities": [{"text": "reliability", "start_pos": 64, "end_pos": 75, "type": "METRIC", "confidence": 0.9681363105773926}]}, {"text": "In this paper, we discuss how to annotate coreference and predicate-argument relations in Japanese text.", "labels": [], "entities": []}, {"text": "In Section 2 to Section 4, we examine the annotation issues of coreference, predicate-argument relations, and event-nouns and their argument relations respectively, and define adequate specification of each annotation task.", "labels": [], "entities": []}, {"text": "Then, we report the results of actual annotation taking the Kyoto Corpus 3.0 as a starting point.", "labels": [], "entities": [{"text": "Kyoto Corpus 3.0", "start_pos": 60, "end_pos": 76, "type": "DATASET", "confidence": 0.9826634923617045}]}, {"text": "Section 6 discusses the open issues of each annotation task and we conclude in Section 7.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 3: Data size of each corpus", "labels": [], "entities": []}, {"text": " Table 4: Agreement of annotating each relation", "labels": [], "entities": [{"text": "Agreement", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9396426677703857}]}]}