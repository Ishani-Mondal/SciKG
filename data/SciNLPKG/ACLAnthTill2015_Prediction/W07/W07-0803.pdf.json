{"title": [{"text": "Person Name Entity Recognition for Arabic", "labels": [], "entities": [{"text": "Person Name Entity Recognition", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.6523498222231865}]}], "abstractContent": [{"text": "Named entity recognition (NER) is nowadays an important task, which is responsible for the identification of proper names in text and their classification as different types of named entity such as people, locations , and organizations.", "labels": [], "entities": [{"text": "Named entity recognition (NER)", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.8061270962158839}, {"text": "identification of proper names in text", "start_pos": 91, "end_pos": 129, "type": "TASK", "confidence": 0.8399691482385}]}, {"text": "In this paper, we present our attempt at the recognition and extraction of the most important proper name entity, that is, the person name, for the Arabic language.", "labels": [], "entities": [{"text": "recognition and extraction", "start_pos": 45, "end_pos": 71, "type": "TASK", "confidence": 0.7352194388707479}]}, {"text": "We developed the system, Person Name Entity Recognition for Arabic (PERA), using a rule-based approach.", "labels": [], "entities": [{"text": "Person Name Entity Recognition for Arabic (PERA)", "start_pos": 25, "end_pos": 73, "type": "TASK", "confidence": 0.7332620388931699}]}, {"text": "The system consists of a lexicon, in the form of gazetteer name lists, and a grammar, in the form of regular expressions , which are responsible for recognizing person name entities.", "labels": [], "entities": []}, {"text": "The PERA system is evaluated using a corpus that is tagged in a semi-automated way.", "labels": [], "entities": []}, {"text": "The system performance results achieved were satisfactory and confirm to the targets set forth for the precision, recall, and f-measure.", "labels": [], "entities": [{"text": "precision", "start_pos": 103, "end_pos": 112, "type": "METRIC", "confidence": 0.9997406601905823}, {"text": "recall", "start_pos": 114, "end_pos": 120, "type": "METRIC", "confidence": 0.9992181062698364}, {"text": "f-measure", "start_pos": 126, "end_pos": 135, "type": "METRIC", "confidence": 0.9848751425743103}]}], "introductionContent": [{"text": "The recognition and classification of proper names in text (e.g. persons, locations, and organizations) has recently become considered of major importance in Natural Language Processing (NLP) as it plays a significant role in various types of NLP applications, especially in Information Extraction, Information Retrieval, Machine Translation, Syntactic Parsing/Chunking, Question-Answering, among others.", "labels": [], "entities": [{"text": "recognition and classification of proper names in text (e.g. persons, locations, and organizations)", "start_pos": 4, "end_pos": 103, "type": "TASK", "confidence": 0.8862519544713637}, {"text": "Natural Language Processing (NLP)", "start_pos": 158, "end_pos": 191, "type": "TASK", "confidence": 0.7008398473262787}, {"text": "Information Extraction", "start_pos": 275, "end_pos": 297, "type": "TASK", "confidence": 0.7892682254314423}, {"text": "Information Retrieval", "start_pos": 299, "end_pos": 320, "type": "TASK", "confidence": 0.8202855885028839}, {"text": "Machine Translation", "start_pos": 322, "end_pos": 341, "type": "TASK", "confidence": 0.8465394675731659}, {"text": "Syntactic Parsing/Chunking", "start_pos": 343, "end_pos": 369, "type": "TASK", "confidence": 0.9062332510948181}]}, {"text": "The valuable information in text is usually located around proper names, to collect this information it should be found first.", "labels": [], "entities": []}, {"text": "In our presentation, we will concentrate on the role of NER in Information Extraction (IE).", "labels": [], "entities": [{"text": "NER in Information Extraction (IE)", "start_pos": 56, "end_pos": 90, "type": "TASK", "confidence": 0.7951111325195858}]}, {"text": "IE is the NLP task that retrieves relevant information from unstructured texts and produces as a result a structured set of data.", "labels": [], "entities": [{"text": "IE", "start_pos": 0, "end_pos": 2, "type": "TASK", "confidence": 0.9271788597106934}]}, {"text": "This paper describes work on recognizing and extracting the most important entities, that is, person names for the Arabic language.", "labels": [], "entities": []}, {"text": "We have adopted the rule-based approach using linguistic grammar-based techniques to develop PERA.", "labels": [], "entities": []}, {"text": "This approach provides flexibility and adaptability features in our system and it can be easily configured to work with different languages, NLP applications, and domains.", "labels": [], "entities": []}, {"text": "In order to determine the best rules for recognition of person names, various Arabic text corpora were analyzed.", "labels": [], "entities": [{"text": "recognition of person names", "start_pos": 41, "end_pos": 68, "type": "TASK", "confidence": 0.8838225454092026}]}, {"text": "Phrases containing person names were retrieved, the underlying pattern was learned and person indicators such as titles were identified.", "labels": [], "entities": []}, {"text": "Apart from this, person names were extracted from the available corpora and other resources to buildup a lexicon, in the form of gazetteer name lists, or gazetteer for short.", "labels": [], "entities": []}, {"text": "The various Arabic naming conventions and the person indicators identified helped in deriving fine rules that gave high-quality recognition of person names in Arabic text.", "labels": [], "entities": []}, {"text": "The recognition was done in two cycles using first the gazetteer and then the grammar rules.", "labels": [], "entities": []}, {"text": "The PERA system is evaluated using a reference corpus that is tagged with person names in a semi-automated way.", "labels": [], "entities": []}, {"text": "The achieved system performance results were satisfactory and confirm to the targets set forth for the precision, recall, and f-measure.", "labels": [], "entities": [{"text": "precision", "start_pos": 103, "end_pos": 112, "type": "METRIC", "confidence": 0.999748170375824}, {"text": "recall", "start_pos": 114, "end_pos": 120, "type": "METRIC", "confidence": 0.9992639422416687}, {"text": "f-measure", "start_pos": 126, "end_pos": 135, "type": "METRIC", "confidence": 0.9845277667045593}]}, {"text": "The paper is structured as follows.", "labels": [], "entities": []}, {"text": "Section 2 presents the related work.", "labels": [], "entities": []}, {"text": "Section 3 describes the naming conventions of person names used in Arabic language.", "labels": [], "entities": []}, {"text": "Section 4 presents methods of data collection used.", "labels": [], "entities": [{"text": "data collection", "start_pos": 30, "end_pos": 45, "type": "TASK", "confidence": 0.7516183853149414}]}, {"text": "Section 5 explains the system architecture and implementation.", "labels": [], "entities": []}, {"text": "Section 6 presents the experiment performed to evaluate the system and finally Section 7 concludes the paper, summarizes our achievements, and highlights our plans for future work..", "labels": [], "entities": []}, {"text": "have conducted a study that showed the importance of the proper names component in cross language tasks involving searching, tracking, retrieving, or extracting information.", "labels": [], "entities": [{"text": "searching, tracking, retrieving, or extracting information", "start_pos": 114, "end_pos": 172, "type": "TASK", "confidence": 0.7789923350016276}]}, {"text": "In particular, they have concluded that a combination of static proper name (English-Arabic) translation plus transliteration provides a successful solution.", "labels": [], "entities": [{"text": "static proper name (English-Arabic) translation", "start_pos": 57, "end_pos": 104, "type": "TASK", "confidence": 0.6106832070010049}]}], "datasetContent": [{"text": "In evaluating the PERA system we follow the standard practice in the IE field of comparing system output against a reference corpus and measuring the performance of the Arabic person named entity.", "labels": [], "entities": [{"text": "IE field", "start_pos": 69, "end_pos": 77, "type": "TASK", "confidence": 0.8422022461891174}]}, {"text": "We have adopted the evaluation measures that are standard in the IE community Precision indicates how many of the extracted entities are correct.", "labels": [], "entities": [{"text": "IE", "start_pos": 65, "end_pos": 67, "type": "TASK", "confidence": 0.8712518811225891}]}, {"text": "Recall indicates how many of the entities that should have been found, are effectively extracted.", "labels": [], "entities": [{"text": "Recall", "start_pos": 0, "end_pos": 6, "type": "METRIC", "confidence": 0.982521653175354}]}, {"text": "Usually there is a trade off of recall against precision.", "labels": [], "entities": [{"text": "recall", "start_pos": 32, "end_pos": 38, "type": "METRIC", "confidence": 0.9994876384735107}, {"text": "precision", "start_pos": 47, "end_pos": 56, "type": "METRIC", "confidence": 0.998441755771637}]}, {"text": "Therefore, often an average accuracy is reported in the form of the F-measure, a harmonic mean which weights recall and precision equally.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 28, "end_pos": 36, "type": "METRIC", "confidence": 0.9926803112030029}, {"text": "F-measure", "start_pos": 68, "end_pos": 77, "type": "METRIC", "confidence": 0.9929579496383667}, {"text": "recall", "start_pos": 109, "end_pos": 115, "type": "METRIC", "confidence": 0.998400866985321}, {"text": "precision", "start_pos": 120, "end_pos": 129, "type": "METRIC", "confidence": 0.9974445104598999}]}, {"text": "It was introduced to provide a single figure to compare different systems' performances.", "labels": [], "entities": []}, {"text": "The PERA system implemented within the FAST ESP pipeline was evaluated using an Information Extraction testing tool called 'hurricane' that applies these standard measures. is a snapshot of the evaluation performed by hurricane in terms of the above mentioned measure.", "labels": [], "entities": [{"text": "FAST ESP pipeline", "start_pos": 39, "end_pos": 56, "type": "DATASET", "confidence": 0.7210959196090698}]}, {"text": "The extraction quality of the pipeline created for the person name extractor confirms to the initial target set.", "labels": [], "entities": [{"text": "person name extractor", "start_pos": 55, "end_pos": 76, "type": "TASK", "confidence": 0.5761941969394684}]}, {"text": "The required degree of precision (80%) and recall (70%), for the Person name extractor, has been achieved with the hurricane evaluation.", "labels": [], "entities": [{"text": "precision", "start_pos": 23, "end_pos": 32, "type": "METRIC", "confidence": 0.9991292357444763}, {"text": "recall", "start_pos": 43, "end_pos": 49, "type": "METRIC", "confidence": 0.9997510313987732}, {"text": "Person name extractor", "start_pos": 65, "end_pos": 86, "type": "TASK", "confidence": 0.7121371825536092}]}, {"text": "Some of the entries within the gazetteers were extracted from the same corpus used also for creating the reference corpus for evaluation.", "labels": [], "entities": []}, {"text": "However, the results achieved are accurate since they indicated recognition of person entities not included in the gazetteers but being recognized by the grammar rules.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Evaluation result for 6 test sets.", "labels": [], "entities": []}]}