{"title": [{"text": "Experiments on the France Telecom 3000 Voice Agency corpus: academic research on an industrial spoken dialog system *", "labels": [], "entities": [{"text": "France Telecom 3000 Voice Agency corpus", "start_pos": 19, "end_pos": 58, "type": "DATASET", "confidence": 0.9783567587534586}]}], "abstractContent": [{"text": "The recent advances in speech recognition technologies, and the experience acquired in the development of WEB or Interactive Voice Response interfaces, have facilitated the integration of speech modules in robust Spoken Dialog Systems (SDS), leading to the deployment on a large scale of speech-enabled services.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 23, "end_pos": 41, "type": "TASK", "confidence": 0.708373412489891}]}, {"text": "With these services it is possible to obtain very large corpora of human-machine interactions by collecting system logs.", "labels": [], "entities": []}, {"text": "This new kinds of systems and dialogue corpora offer new opportunities for academic research while raising two issues: How can academic research take profit of the system logs of deployed SDS in order to build the next generation of SDS, although the dialogues collected have a dialogue flow constrained by the previous SDS generation?", "labels": [], "entities": []}, {"text": "On the other side, what immediate benefits can academic research offer for the improvement of deployed system?", "labels": [], "entities": []}, {"text": "This paper addresses these aspects in the framework of the deployed France Telecom 3000 Voice Agency service.", "labels": [], "entities": [{"text": "France Telecom 3000 Voice Agency service", "start_pos": 68, "end_pos": 108, "type": "DATASET", "confidence": 0.9753542244434357}]}], "introductionContent": [{"text": "Since the deployment on a very large scale of the AT&T How May I Help You?", "labels": [], "entities": [{"text": "AT&T How May I Help You?", "start_pos": 50, "end_pos": 74, "type": "DATASET", "confidence": 0.8389591111077203}]}, {"text": "(HMIHY) () service in 2000, Spoken Dialogue Systems (SDS) handling a very large number of calls are now developed from an industrial point of view.", "labels": [], "entities": []}, {"text": "Although a lot of the remaining problems (robustness, coverage, etc.) are still spoken language processing research problems, the conception and the deployment of such state-of-the-art systems mainly requires knowledge in user interfaces.", "labels": [], "entities": [{"text": "coverage", "start_pos": 54, "end_pos": 62, "type": "METRIC", "confidence": 0.9288513660430908}]}, {"text": "The recent advances in speech recognition technologies, and the experience acquired in the development of WEB or Interactive Voice Response interfaces have facilitated the integration of speech modules in robust SDS.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 23, "end_pos": 41, "type": "TASK", "confidence": 0.7261234074831009}]}, {"text": "These new SDS can be deployed on a very large scale, like the France Telecom 3000 Voice Agency service considered in this study.", "labels": [], "entities": [{"text": "France Telecom 3000 Voice Agency", "start_pos": 62, "end_pos": 94, "type": "DATASET", "confidence": 0.9713979601860047}]}, {"text": "With these services it is possible to obtain very large corpora of humanmachine interactions by collecting system logs.", "labels": [], "entities": []}, {"text": "The main differences between these corpora and those collected in the framework of evaluation programs like the DARPA ATIS () or the French Technolangue MEDIA () programs can be expressed through the following dimensions: \u2022 Size.", "labels": [], "entities": [{"text": "DARPA", "start_pos": 112, "end_pos": 117, "type": "DATASET", "confidence": 0.8320962190628052}, {"text": "ATIS", "start_pos": 118, "end_pos": 122, "type": "METRIC", "confidence": 0.551428496837616}, {"text": "French Technolangue MEDIA", "start_pos": 133, "end_pos": 158, "type": "DATASET", "confidence": 0.8205189903577169}]}, {"text": "There are virtually no limits in the amount of speakers available or the time needed for collecting the dialogues as thousands of dialogues are automatically processed everyday and the system logs are stored.", "labels": [], "entities": []}, {"text": "Therefore Dialog processing becomes similar to Broadcast News processing: the limit is not in the amount of data available, but rather in the amount of data that can be manually annotated.", "labels": [], "entities": [{"text": "Dialog processing", "start_pos": 10, "end_pos": 27, "type": "TASK", "confidence": 0.9637339115142822}, {"text": "Broadcast News processing", "start_pos": 47, "end_pos": 72, "type": "TASK", "confidence": 0.735458234945933}]}, {"text": "Data are from real users.", "labels": [], "entities": []}, {"text": "The speakers are not professional ones or have no reward for calling the system.", "labels": [], "entities": []}, {"text": "Therefore their behaviors are not biased by the acquisition protocols.", "labels": [], "entities": []}, {"text": "Spontaneous speech and speech affects can be observed.", "labels": [], "entities": []}, {"text": "The complexity of the services widely deployed is necessarily limited in order to guarantee robustness with a high automation rate.", "labels": [], "entities": []}, {"text": "Therefore the dialogues collected are often short dialogues.", "labels": [], "entities": []}, {"text": "The semantic model of such deployed system is task-oriented.", "labels": [], "entities": []}, {"text": "The interpretation of an utterance mostly consists in the detection of application-specific entities.", "labels": [], "entities": [{"text": "interpretation of an utterance", "start_pos": 4, "end_pos": 34, "type": "TASK", "confidence": 0.8135119676589966}]}, {"text": "In an application like the France Telecom 3000 Voice Agency service this detection is performed by hand-crafted specific knowledge.", "labels": [], "entities": [{"text": "France Telecom 3000 Voice Agency", "start_pos": 27, "end_pos": 59, "type": "DATASET", "confidence": 0.9683386445045471}]}, {"text": "The AT&T HMIHY corpus was the first large dialogue corpus, obtained from a deployed system, that has the above mentioned characteristics.", "labels": [], "entities": [{"text": "AT&T HMIHY corpus", "start_pos": 4, "end_pos": 21, "type": "DATASET", "confidence": 0.9320553421974183}]}, {"text": "A service like the France Telecom 3000 Voice Agency service has been developed by a user interface development lab.", "labels": [], "entities": [{"text": "France Telecom 3000 Voice Agency service", "start_pos": 19, "end_pos": 59, "type": "DATASET", "confidence": 0.9711334904034933}]}, {"text": "This new kind of systems and dialogue corpora offer new opportunities for academic research that can be summarized as follows: \u2022 How can academic research take profit of the system logs of deployed SDS in order to build the next generation of SDS, although the dialogues collected have a dialogue flow constrained by the previous SDS generation?", "labels": [], "entities": []}, {"text": "\u2022 On the other side, what immediate benefits can academic research offer for the improvement of deployed system, while waiting for the next SDS generation?", "labels": [], "entities": []}, {"text": "This paper addresses these aspects in the framework of the deployed FT 3000 Voice Agency service.", "labels": [], "entities": [{"text": "FT 3000 Voice Agency service", "start_pos": 68, "end_pos": 96, "type": "DATASET", "confidence": 0.9229910850524903}]}, {"text": "Section 3 presents how the ASR process can be modified in order to detect and reject Out-OfDomain utterances, leading to an improvement in the understanding performance without modifying the system.", "labels": [], "entities": [{"text": "ASR", "start_pos": 27, "end_pos": 30, "type": "TASK", "confidence": 0.9810652136802673}]}, {"text": "Section 4 shows how the FT 3000 corpus can be used in order to build stochastic models that are the basis of anew Spoken Language Understanding strategy, even if the current SLU system used in the FT 3000 service is not stochastic.", "labels": [], "entities": [{"text": "FT 3000 corpus", "start_pos": 24, "end_pos": 38, "type": "DATASET", "confidence": 0.9538585146268209}, {"text": "Spoken Language Understanding", "start_pos": 114, "end_pos": 143, "type": "TASK", "confidence": 0.7609567443529764}, {"text": "FT 3000 service", "start_pos": 197, "end_pos": 212, "type": "DATASET", "confidence": 0.9312492807706197}]}, {"text": "Section 5 presents experimental results obtained on this corpus justifying the need of a tighter integration between the ASR and the SLU models.", "labels": [], "entities": [{"text": "ASR", "start_pos": 121, "end_pos": 124, "type": "TASK", "confidence": 0.7106181979179382}]}], "datasetContent": [{"text": "The models presented are trained on a corpus collected thanks to the FT3000 service.", "labels": [], "entities": [{"text": "FT3000 service", "start_pos": 69, "end_pos": 83, "type": "DATASET", "confidence": 0.9718856513500214}]}, {"text": "It contains real dialogues from the deployed service.", "labels": [], "entities": []}, {"text": "The results presented are obtained on the test corpus described in section 2.", "labels": [], "entities": []}, {"text": "The results were evaluated according to 3 criteria: the Word Error Rate (WER), the Concept Error Rate (CER) and the Interpretation Error Rate (IER).", "labels": [], "entities": [{"text": "Word Error Rate (WER)", "start_pos": 56, "end_pos": 77, "type": "METRIC", "confidence": 0.8755828042825063}, {"text": "Concept Error Rate (CER)", "start_pos": 83, "end_pos": 107, "type": "METRIC", "confidence": 0.8351717392603556}, {"text": "Interpretation Error Rate (IER)", "start_pos": 116, "end_pos": 147, "type": "METRIC", "confidence": 0.7767686794201533}]}, {"text": "The CER is related to the correct translation of an utterance into a string of basic concepts.", "labels": [], "entities": [{"text": "CER", "start_pos": 4, "end_pos": 7, "type": "METRIC", "confidence": 0.8741188049316406}]}, {"text": "The IER is related to the global interpretation of an utterance in the context of the dialogue service considered.", "labels": [], "entities": [{"text": "global interpretation of an utterance", "start_pos": 26, "end_pos": 63, "type": "TASK", "confidence": 0.813897967338562}]}, {"text": "Therefore this last measure is the most significant one as it is directly linked to the performance of the dialogue system.", "labels": [], "entities": []}, {"text": "presents the IER results obtained with the strategy strat1 with 2 different LMs for obtaining\u02c6W obtaining\u02c6 obtaining\u02c6W : LM G which is the general word bigram model; and LM G + OOD which is the LM with the OOD comment model.", "labels": [], "entities": []}, {"text": "As one can see, a very significant improvement, 3.7% absolute, is achieved on the other dialogues, which are the ones containing most of the comments.", "labels": [], "entities": []}, {"text": "For the transit dialogues a small improvement (0.2%) is also obtained.", "labels": [], "entities": [{"text": "transit dialogues", "start_pos": 8, "end_pos": 25, "type": "TASK", "confidence": 0.749144971370697}]}], "tableCaptions": [{"text": " Table 1: Statistics on the transit and other dialogues", "labels": [], "entities": []}, {"text": " Table 2: Occurrence of Out-Of-Domain comments  on the transit and other dialogues", "labels": [], "entities": []}, {"text": " Table 3: Interpretation error rate according to the  Language Model", "labels": [], "entities": []}, {"text": " Table 4: Word Error Rate (WER), Concept Error  Rate (CER) and Interpretation Error Rate (IER) ac- cording to the SLU strategy", "labels": [], "entities": [{"text": "Word Error Rate (WER)", "start_pos": 10, "end_pos": 31, "type": "METRIC", "confidence": 0.7862945348024368}, {"text": "Concept Error  Rate (CER)", "start_pos": 33, "end_pos": 58, "type": "METRIC", "confidence": 0.8377331892649332}, {"text": "Interpretation Error Rate (IER) ac- cording", "start_pos": 63, "end_pos": 106, "type": "METRIC", "confidence": 0.812018182542589}]}, {"text": " Table 5: Error rates on words, concepts and interpre- tations for the 1-best hypothesis and for the Oracle  hypothesis of each level", "labels": [], "entities": [{"text": "Error", "start_pos": 10, "end_pos": 15, "type": "METRIC", "confidence": 0.9918864369392395}]}]}