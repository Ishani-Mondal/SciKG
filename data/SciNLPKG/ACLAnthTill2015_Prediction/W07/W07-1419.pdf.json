{"title": [{"text": "SVO triple based Latent Semantic Analysis for recognising textual entailment", "labels": [], "entities": [{"text": "Latent Semantic Analysis", "start_pos": 17, "end_pos": 41, "type": "TASK", "confidence": 0.5591956079006195}, {"text": "recognising textual entailment", "start_pos": 46, "end_pos": 76, "type": "TASK", "confidence": 0.6115425527095795}]}], "abstractContent": [{"text": "Latent Semantic Analysis has only recently been applied to textual entailment recognition.", "labels": [], "entities": [{"text": "Latent Semantic Analysis", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.7081408202648163}, {"text": "textual entailment recognition", "start_pos": 59, "end_pos": 89, "type": "TASK", "confidence": 0.8560519615809122}]}, {"text": "However, these efforts have suffered from inadequate bag of words vector representations.", "labels": [], "entities": []}, {"text": "Our prototype implementation for the Third Recognising Textual Entail-ment Challenge (RTE-3) improves the approach by applying it to vector representations that contain semi-structured representations of words.", "labels": [], "entities": [{"text": "Third Recognising Textual Entail-ment Challenge (RTE-3)", "start_pos": 37, "end_pos": 92, "type": "TASK", "confidence": 0.5609198622405529}]}, {"text": "It uses variable size n-grams of word stems to model independently verbs, subjects and objects displayed in textual statements.", "labels": [], "entities": []}, {"text": "The system performance shows positive results and provides insights about how to improve them further.", "labels": [], "entities": []}], "introductionContent": [{"text": "The Third Recognising Textual Entailment Challenge (RTE-3) task consists in developing a system for automatically determining whether or not a hypothesis (H) can be inferred from a text (T), which could be up to a paragraph long.", "labels": [], "entities": [{"text": "Recognising Textual Entailment Challenge (RTE-3) task", "start_pos": 10, "end_pos": 63, "type": "TASK", "confidence": 0.7636639550328255}]}, {"text": "Our entry to the RTE-3 challenge is a system that takes advantage of Latent Semantic Analysis (LSA).", "labels": [], "entities": [{"text": "RTE-3 challenge", "start_pos": 17, "end_pos": 32, "type": "TASK", "confidence": 0.7954413592815399}]}, {"text": "This numerical method for reducing noise generated byword choices within texts is extensively used for document indexing and word sense disambiguation.", "labels": [], "entities": [{"text": "document indexing", "start_pos": 103, "end_pos": 120, "type": "TASK", "confidence": 0.758076399564743}, {"text": "word sense disambiguation", "start_pos": 125, "end_pos": 150, "type": "TASK", "confidence": 0.7530613938967387}]}, {"text": "Recently, there have also been efforts to use techniques from LSA to recognise textual entailment).", "labels": [], "entities": [{"text": "recognise textual entailment", "start_pos": 69, "end_pos": 97, "type": "TASK", "confidence": 0.6893660724163055}]}, {"text": "However, we argue that these efforts (like most LSA approaches in the past) suffer from an inadequate vector representation for textual contexts as bags of words.", "labels": [], "entities": []}, {"text": "In contrast, we have applied LSA to vector representations of semi-structured text.", "labels": [], "entities": []}, {"text": "Our representation takes into account the grammatical role (i.e. subject, verb or object) a word occurs in.", "labels": [], "entities": []}, {"text": "Within this system report, we describe and discuss our methodology in section 2, our current implementation in section 3, and system results in section 4.", "labels": [], "entities": []}, {"text": "We conclude in section 5 with a discussion of the results obtained and with the presentation of possible steps to improve our system's performance.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Values computed for \u00af  s p", "labels": [], "entities": []}, {"text": " Table 2: Results on the test set", "labels": [], "entities": []}]}