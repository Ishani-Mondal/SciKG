{"title": [{"text": "Semantic and Logical Inference Model for Textual Entailment", "labels": [], "entities": [{"text": "Textual Entailment", "start_pos": 41, "end_pos": 59, "type": "TASK", "confidence": 0.7781741619110107}]}], "abstractContent": [{"text": "We compare two approaches to the problem of Textual Entailment: SLIM, a composi-tional approach modeling the task based on identifying relations in the entailment pair, and BoLI, a lexical matching algorithm.", "labels": [], "entities": [{"text": "Textual Entailment", "start_pos": 44, "end_pos": 62, "type": "TASK", "confidence": 0.8139051198959351}, {"text": "BoLI", "start_pos": 173, "end_pos": 177, "type": "METRIC", "confidence": 0.82535719871521}]}, {"text": "SLIM's framework incorporates a range of resources that solve local entailment problems.", "labels": [], "entities": []}, {"text": "A search-based inference procedure unifies these resources, permitting them to interact flexibly.", "labels": [], "entities": []}, {"text": "BoLI uses WordNet and other lexical similarity resources to detect correspondence between related words in the Hypothesis and the Text.", "labels": [], "entities": [{"text": "BoLI", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.9060564637184143}, {"text": "WordNet", "start_pos": 10, "end_pos": 17, "type": "DATASET", "confidence": 0.9265289902687073}]}, {"text": "In this paper we describe both systems in some detail and evaluate their performance on the 3rd PASCAL RTE Challenge.", "labels": [], "entities": [{"text": "3rd PASCAL RTE Challenge", "start_pos": 92, "end_pos": 116, "type": "DATASET", "confidence": 0.6353179663419724}]}, {"text": "While the lexical method outperforms the relation-based approach, we argue that the relation-based model offers better long-term prospects for entailment recognition.", "labels": [], "entities": [{"text": "entailment recognition", "start_pos": 143, "end_pos": 165, "type": "TASK", "confidence": 0.8771917819976807}]}], "introductionContent": [{"text": "We compare two Textual Entailment recognition systems applied to the 3rd PASCAL RTE challenge.", "labels": [], "entities": [{"text": "Textual Entailment recognition", "start_pos": 15, "end_pos": 45, "type": "TASK", "confidence": 0.8083449602127075}, {"text": "PASCAL RTE challenge", "start_pos": 73, "end_pos": 93, "type": "TASK", "confidence": 0.47789425651232403}]}, {"text": "Both systems model the entailment task in terms of determining whether the Hypothesis can be \"explained\" by the Text.", "labels": [], "entities": []}, {"text": "The first system, BoLI (Bag of Lexical Items) uses WordNet and (optionally) other word similarity resources to compare individual words in the Hypothesis with the words in the Text.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 51, "end_pos": 58, "type": "DATASET", "confidence": 0.9336981177330017}]}, {"text": "The second system, the Semantic and Logical Inference Model (SLIM) system, uses a relational model, and follows the model-theory-based approach of).", "labels": [], "entities": [{"text": "Semantic and Logical Inference Model (SLIM)", "start_pos": 23, "end_pos": 66, "type": "TASK", "confidence": 0.6874681934714317}]}, {"text": "SLIM uses a suite of resources to modify the original entailment pair by augmenting or simplifying either or both the Text and Hypothesis.", "labels": [], "entities": []}, {"text": "Terms relating to quantification, modality and negation are detected and removed from the graphical representation of the entailment pair and resolved with an entailment module that handles basic logic.", "labels": [], "entities": []}, {"text": "In this study we describe the BoLI and SLIM systems and evaluate their performance on the 3rd PAS-CAL RTE Challenge corpora.", "labels": [], "entities": [{"text": "BoLI", "start_pos": 30, "end_pos": 34, "type": "METRIC", "confidence": 0.716055154800415}, {"text": "PAS-CAL RTE Challenge corpora", "start_pos": 94, "end_pos": 123, "type": "DATASET", "confidence": 0.6339363604784012}]}, {"text": "We discuss some examples and possible improvements for each system.", "labels": [], "entities": []}], "datasetContent": [{"text": "To investigate the improvement of performance for the SLIM system relative to the available resources, we conducted a limited ablation study.", "labels": [], "entities": [{"text": "ablation", "start_pos": 126, "end_pos": 134, "type": "METRIC", "confidence": 0.9787797331809998}]}, {"text": "Table 2 shows the performance for different versions of the SLIM system on 100 entailment pairs each from the IE and QA subtasks of the Test corpus.", "labels": [], "entities": [{"text": "IE and QA subtasks of the Test corpus", "start_pos": 110, "end_pos": 147, "type": "DATASET", "confidence": 0.6369162686169147}]}, {"text": "The \"full\" (f) system includes all available resources.", "labels": [], "entities": []}, {"text": "The \"intermediate\" (i) system excludes the resources we consider most likely to introduce errors, the Multiword Expression module and the most general Nominalization rewrite rules in the Nominalization Rewriter.", "labels": [], "entities": []}, {"text": "The \"strict\" (s) system also omits the Apposition and Complex Noun Phrase  To give a sense of how well the complete SLIM system does on the Development corpus, the results for the full SLIM system on equal-sized subsets of the IE and QA subtasks of the Development corpus are also shown.", "labels": [], "entities": [{"text": "Apposition", "start_pos": 39, "end_pos": 49, "type": "METRIC", "confidence": 0.9971356391906738}, {"text": "IE and QA subtasks of the Development corpus", "start_pos": 227, "end_pos": 271, "type": "DATASET", "confidence": 0.5715052857995033}]}], "tableCaptions": [{"text": " Table 1: Accuracy and corresponding threshold for  versions of BoLI on the Development corpus.  TASK  Accuracy Threshold", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9991381168365479}, {"text": "Development corpus", "start_pos": 76, "end_pos": 94, "type": "DATASET", "confidence": 0.8193602859973907}, {"text": "TASK  Accuracy Threshold", "start_pos": 97, "end_pos": 121, "type": "METRIC", "confidence": 0.7552330493927002}]}, {"text": " Table 2: Results for different versions of SLIM on  subsets of the Test and Develoment corpora.  System  SLIM s SLIM i SLIM f", "labels": [], "entities": []}, {"text": " Table 3: Results for SLIM and BoLI on the Pascal Development and Test Corpora. Results marked with an  asterisk indicate not all system resources were available at the time the system was run.  Corpus  Development  Test", "labels": [], "entities": [{"text": "BoLI", "start_pos": 31, "end_pos": 35, "type": "DATASET", "confidence": 0.6322235465049744}, {"text": "Corpus  Development  Test", "start_pos": 195, "end_pos": 220, "type": "DATASET", "confidence": 0.9318899512290955}]}]}