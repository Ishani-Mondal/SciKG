{"title": [{"text": "Proceedings of SSST, NAACL-HLT 2007 / AMTA Workshop on Syntax and Structure in Statistical Inversion Transduction Grammar for Joint Phrasal Translation Modeling", "labels": [], "entities": [{"text": "SSST, NAACL-HLT 2007 / AMTA Workshop", "start_pos": 15, "end_pos": 51, "type": "TASK", "confidence": 0.6263478355748313}, {"text": "Statistical Inversion Transduction Grammar", "start_pos": 79, "end_pos": 121, "type": "TASK", "confidence": 0.743141308426857}, {"text": "Phrasal Translation Modeling", "start_pos": 132, "end_pos": 160, "type": "TASK", "confidence": 0.7811102867126465}]}], "abstractContent": [{"text": "We present a phrasal inversion trans-duction grammar as an alternative to joint phrasal translation models.", "labels": [], "entities": [{"text": "joint phrasal translation", "start_pos": 74, "end_pos": 99, "type": "TASK", "confidence": 0.7121228575706482}]}, {"text": "This syntactic model is similar to its flat-string phrasal predecessors, but admits polynomial-time algorithms for Viterbi alignment and EM training.", "labels": [], "entities": [{"text": "Viterbi alignment", "start_pos": 115, "end_pos": 132, "type": "TASK", "confidence": 0.6622687578201294}, {"text": "EM training", "start_pos": 137, "end_pos": 148, "type": "TASK", "confidence": 0.8886522650718689}]}, {"text": "We demonstrate that the consistency constraints that allow flat phrasal models to scale also help ITG algorithms, producing an 80-times faster inside-outside algorithm.", "labels": [], "entities": []}, {"text": "We also show that the phrasal translation tables produced by the ITG are superior to those of the flat joint phrasal model, producing up to a 2.5 point improvement in BLEU score.", "labels": [], "entities": [{"text": "ITG", "start_pos": 65, "end_pos": 68, "type": "DATASET", "confidence": 0.9309518337249756}, {"text": "BLEU score", "start_pos": 167, "end_pos": 177, "type": "METRIC", "confidence": 0.9810024499893188}]}, {"text": "Finally, we explore, for the first time, the utility of a joint phrasal translation model as a word alignment method.", "labels": [], "entities": [{"text": "joint phrasal translation", "start_pos": 58, "end_pos": 83, "type": "TASK", "confidence": 0.7378812829653422}, {"text": "word alignment", "start_pos": 95, "end_pos": 109, "type": "TASK", "confidence": 0.7825803160667419}]}], "introductionContent": [{"text": "Statistical machine translation benefits greatly from considering more than one word at a time.", "labels": [], "entities": [{"text": "Statistical machine translation", "start_pos": 0, "end_pos": 31, "type": "TASK", "confidence": 0.6591413815816244}]}, {"text": "One can put forward any number of non-compositional translations to support this point, such as the colloquial Canadian French-English pair, (Wo les moteurs, Hold your horses), where no clear word-toword connection can be drawn.", "labels": [], "entities": []}, {"text": "Nearly all current decoding methods have shifted to phrasal representations, gaining the ability to handle noncompositional translations, but also allowing the decoder to memorize phenomena such as monolingual agreement and short-range movement, taking pressure off of language and distortion models.", "labels": [], "entities": []}, {"text": "Despite the success of phrasal decoders, knowledge acquisition for translation generally begins with a word-level analysis of the training text, taking the form of a word alignment.", "labels": [], "entities": [{"text": "knowledge acquisition", "start_pos": 41, "end_pos": 62, "type": "TASK", "confidence": 0.7479158937931061}, {"text": "translation", "start_pos": 67, "end_pos": 78, "type": "TASK", "confidence": 0.8221741318702698}, {"text": "word alignment", "start_pos": 166, "end_pos": 180, "type": "TASK", "confidence": 0.6828781366348267}]}, {"text": "Attempts to apply the same statistical analysis used at the word level in a phrasal setting have met with limited success, held back by the sheer size of phrasal alignment space.", "labels": [], "entities": []}, {"text": "Hybrid methods that combine well-founded statistical analysis with high-confidence word-level alignments have made some headway (), but suffer from the daunting task of heuristically exploring a still very large alignment space.", "labels": [], "entities": []}, {"text": "In the meantime, synchronous parsing methods efficiently process the same bitext phrases while building their bilingual constituents, but continue to be employed primarily for word-to-word analysis.", "labels": [], "entities": [{"text": "word-to-word analysis", "start_pos": 176, "end_pos": 197, "type": "TASK", "confidence": 0.7188699245452881}]}, {"text": "In this paper we unify the probability models for phrasal translation with the algorithms for synchronous parsing, harnessing the benefits of both to create a statistically and algorithmically wellfounded method for phrasal analysis of bitext.", "labels": [], "entities": [{"text": "phrasal translation", "start_pos": 50, "end_pos": 69, "type": "TASK", "confidence": 0.7716352641582489}, {"text": "phrasal analysis", "start_pos": 216, "end_pos": 232, "type": "TASK", "confidence": 0.8018790483474731}]}, {"text": "Section 2 begins by outlining the phrase extraction system we intend to replace and the two methods we combine to do so: the joint phrasal translation model (JPTM) and inversion transduction grammar (ITG).", "labels": [], "entities": [{"text": "phrase extraction", "start_pos": 34, "end_pos": 51, "type": "TASK", "confidence": 0.772734135389328}, {"text": "joint phrasal translation", "start_pos": 125, "end_pos": 150, "type": "TASK", "confidence": 0.6748102009296417}, {"text": "inversion transduction grammar (ITG)", "start_pos": 168, "end_pos": 204, "type": "TASK", "confidence": 0.7504353125890096}]}, {"text": "Section 3 describes our proposed solution, a phrasal ITG.", "labels": [], "entities": []}, {"text": "Section 4 describes how to apply our phrasal ITG, both as a translation model and as a phrasal word-aligner.", "labels": [], "entities": []}, {"text": "Section 5 tests our system in both these capacities, while Section 6 concludes.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section, we first verify the effectiveness of fixed-link pruning, and then test our phrasal ITG, both as an aligner and as a translation model.", "labels": [], "entities": []}, {"text": "We train all translation models with a French-English Europarl corpus obtained by applying a 25 token sentence-length limit to the training set provided for the HLT-NAACL SMT Workshop Shared Task ().", "labels": [], "entities": [{"text": "Europarl corpus", "start_pos": 54, "end_pos": 69, "type": "DATASET", "confidence": 0.8545481562614441}, {"text": "HLT-NAACL SMT Workshop Shared Task", "start_pos": 161, "end_pos": 195, "type": "TASK", "confidence": 0.6072951436042786}]}, {"text": "The resulting corpus has 393,132 sentence pairs.", "labels": [], "entities": []}, {"text": "3,376 of these are omitted for ITG methods because their highconfidence alignments have ITG-incompatible constructions.", "labels": [], "entities": []}, {"text": "Like our predecessors (), we apply a lexicon constraint: no monolingual phrase can be used by any phrasal model unless it occurs at least five times.", "labels": [], "entities": []}, {"text": "High-confidence alignments are provided by intersecting GIZA++ alignments trained in each direction with 5 iterations each of Model 1, HMM, and Model 4.", "labels": [], "entities": []}, {"text": "All GIZA++ alignments are trained with no sentence-length limit, using the full 688K corpus.", "labels": [], "entities": [{"text": "688K corpus", "start_pos": 80, "end_pos": 91, "type": "DATASET", "confidence": 0.9084356129169464}]}, {"text": "To measure the speed-up provided by fixed-link pruning, we timed our phrasal inside-outside algorithm on the first 100 sentence pairs in our training set, with and without pruning.", "labels": [], "entities": []}, {"text": "The results are shown in.", "labels": [], "entities": []}, {"text": "Tic-tac-toe pruning is included for comparison.", "labels": [], "entities": []}, {"text": "With fixed-link pruning, on average 95% of the possible spans are pruned, reducing running time by two orders of magnitude.", "labels": [], "entities": []}, {"text": "This improvement makes ITG training feasible, even with large bitexts.", "labels": [], "entities": [{"text": "ITG training", "start_pos": 23, "end_pos": 35, "type": "TASK", "confidence": 0.8827585577964783}]}, {"text": "The goal of this experiment is to compare the Viterbi alignments from the phrasal ITG to gold standard human alignments.", "labels": [], "entities": []}, {"text": "We do this to validate our noncompositional constraint and to select good alignments for use with the surface heuristic.", "labels": [], "entities": []}, {"text": "Following the lead of), we hand-aligned the first 100 sentence pairs of our training set according to the Blinker annotation guidelines).", "labels": [], "entities": []}, {"text": "We did not differentiate between sure and possible links.", "labels": [], "entities": []}, {"text": "We report precision, recall and balanced F-measure.", "labels": [], "entities": [{"text": "precision", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9995172023773193}, {"text": "recall", "start_pos": 21, "end_pos": 27, "type": "METRIC", "confidence": 0.9997957348823547}, {"text": "F-measure", "start_pos": 41, "end_pos": 50, "type": "METRIC", "confidence": 0.9269328713417053}]}, {"text": "For comparison purposes, we include the results of three types of GIZA++ combination, including the grow-diag-final heuristic (GDF).", "labels": [], "entities": []}, {"text": "We tested our phrasal ITG with fixed link pruning, and then added the non-compositional constraint (NCC).", "labels": [], "entities": [{"text": "non-compositional constraint (NCC)", "start_pos": 70, "end_pos": 104, "type": "METRIC", "confidence": 0.8151147186756134}]}, {"text": "During development we determined that performance levels off for both of the ITG models after 3 EM iterations.", "labels": [], "entities": []}, {"text": "The results are shown in.", "labels": [], "entities": []}, {"text": "The first thing to note is that GIZA++ Intersection is indeed very high precision.", "labels": [], "entities": [{"text": "GIZA++ Intersection", "start_pos": 32, "end_pos": 51, "type": "METRIC", "confidence": 0.4944782654444377}, {"text": "precision", "start_pos": 72, "end_pos": 81, "type": "METRIC", "confidence": 0.9983046054840088}]}, {"text": "Our confidence in it as a constraint is not misplaced.", "labels": [], "entities": []}, {"text": "We also see that both phrasal models have significantly higher recall than any of the GIZA++ alignments, even higher than the permissive GIZA++ union.", "labels": [], "entities": [{"text": "recall", "start_pos": 63, "end_pos": 69, "type": "METRIC", "confidence": 0.9995323419570923}]}, {"text": "One factor contributing to this is the phrasal model's use of cepts: it completely interconnects any phrase pair, while GIZA++ union and GDF may not.", "labels": [], "entities": []}, {"text": "Its global view of phrases also helps in this regard: evidence fora phrase can be built up over multiple sentences.", "labels": [], "entities": []}, {"text": "Finally, we note that in terms of alignment quality, the non-compositional constraint is an unqualified success for the phrasal ITG.", "labels": [], "entities": []}, {"text": "It produces a 25 point improvement in precision, at the cost of 2 points of recall.", "labels": [], "entities": [{"text": "precision", "start_pos": 38, "end_pos": 47, "type": "METRIC", "confidence": 0.9997746348381042}, {"text": "recall", "start_pos": 76, "end_pos": 82, "type": "METRIC", "confidence": 0.9994239807128906}]}, {"text": "This produces the highest balanced Fmeasure observed on our test set, but the utility of its alignments will depend largely on one's desired precision-recall trade-off.", "labels": [], "entities": [{"text": "Fmeasure", "start_pos": 35, "end_pos": 43, "type": "METRIC", "confidence": 0.955917239189148}, {"text": "precision-recall", "start_pos": 141, "end_pos": 157, "type": "METRIC", "confidence": 0.9712664484977722}]}, {"text": "In this section, we compare a number of different methods for phrase table generation in a French to English translation task.", "labels": [], "entities": [{"text": "phrase table generation", "start_pos": 62, "end_pos": 85, "type": "TASK", "confidence": 0.7792547146479288}, {"text": "French to English translation task", "start_pos": 91, "end_pos": 125, "type": "TASK", "confidence": 0.7413109540939331}]}, {"text": "We are interested in answering three questions: 1.", "labels": [], "entities": []}, {"text": "Does the phrasal ITG improve on the C-JPTM?", "labels": [], "entities": []}, {"text": "2. Can phrasal translation models outperform the surface heuristic?", "labels": [], "entities": []}, {"text": "3. Do Viterbi phrasal alignments provide better input for the surface heuristic?", "labels": [], "entities": []}, {"text": "With this in mind, we test five phrase tables.", "labels": [], "entities": []}, {"text": "Two are conditionalized phrasal models, each EM trained until performance degrades: \u2022 C-JPTM 3 as described in) \u2022 Phrasal ITG as described in Section 4.1 Three provide alignments for the surface heuristic: \u2022 GIZA++ with grow-diag-final (GDF) \u2022 Viterbi Phrasal ITG with and without the noncompositional constraint We use the Pharaoh decoder ( with the SMT Shared Task baseline system ().", "labels": [], "entities": [{"text": "SMT Shared Task", "start_pos": 351, "end_pos": 366, "type": "TASK", "confidence": 0.8440702756245931}]}, {"text": "Weights for the log-linear model are set using the 500-sentence tuning set provided for the shared task with minimum error rate training as implemented by.", "labels": [], "entities": []}, {"text": "Results on the provided 2000-sentence development set are reported using the BLEU metric ().", "labels": [], "entities": [{"text": "BLEU", "start_pos": 77, "end_pos": 81, "type": "METRIC", "confidence": 0.996956467628479}]}, {"text": "For all methods, we report performance with and without IBM Model 1 features (M1), along with the size of the resulting tables in millions of phrase pairs.", "labels": [], "entities": []}, {"text": "The results of all experiments are shown in.", "labels": [], "entities": []}, {"text": "We see that the Phrasal ITG surpasses the C-JPTM by more than 2.5 BLEU points.", "labels": [], "entities": [{"text": "Phrasal ITG", "start_pos": 16, "end_pos": 27, "type": "DATASET", "confidence": 0.9105238914489746}, {"text": "BLEU", "start_pos": 66, "end_pos": 70, "type": "METRIC", "confidence": 0.9989325404167175}]}, {"text": "A large component of this improvement is due to the ITG's use of inside-outside for expectation calculation, though Although ITG+M1 comes close, neither phrasal model matches the performance of the surface heuristic.", "labels": [], "entities": [{"text": "ITG", "start_pos": 52, "end_pos": 55, "type": "DATASET", "confidence": 0.9037854671478271}]}, {"text": "Whatever the surface heuristic lacks in sophistication, it makes up for in sheer coverage, as demonstrated by its huge table sizes.", "labels": [], "entities": [{"text": "coverage", "start_pos": 81, "end_pos": 89, "type": "METRIC", "confidence": 0.9555124044418335}]}, {"text": "Even the Phrasal ITG Viterbi alignments, which over-commit wildly and have horrible precision, score slightly higher than the best phrasal model.", "labels": [], "entities": [{"text": "Phrasal ITG Viterbi alignments", "start_pos": 9, "end_pos": 39, "type": "DATASET", "confidence": 0.8680519908666611}, {"text": "precision", "start_pos": 84, "end_pos": 93, "type": "METRIC", "confidence": 0.9991278052330017}]}, {"text": "The surface heuristic benefits from capturing as much context as possible, while still covering smaller translation events with its flat counts.", "labels": [], "entities": []}, {"text": "It is not held back by any lexicon constraints.", "labels": [], "entities": []}, {"text": "When GIZA++ GDF+M1 is forced to conform to a lexicon constraint by dropping any phrase with a frequency lower than 5 from its table, it scores only 29.26, fora reduction of 1.35 BLEU points.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 178, "end_pos": 182, "type": "METRIC", "confidence": 0.998708963394165}]}, {"text": "Phrases extracted from our non-compositional Viterbi alignments receive the highest BLEU score, but they are not significantly better than GIZA++ GDF.", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 84, "end_pos": 94, "type": "METRIC", "confidence": 0.9890791773796082}, {"text": "GIZA++ GDF", "start_pos": 139, "end_pos": 149, "type": "DATASET", "confidence": 0.7244053681691488}]}, {"text": "The two methods also produce similarly-sized tables, despite the ITG's higher recall.", "labels": [], "entities": [{"text": "ITG", "start_pos": 65, "end_pos": 68, "type": "DATASET", "confidence": 0.9213610291481018}, {"text": "recall", "start_pos": 78, "end_pos": 84, "type": "METRIC", "confidence": 0.9990088939666748}]}], "tableCaptions": [{"text": " Table 1: Inside-outside run-time comparison.", "labels": [], "entities": []}]}