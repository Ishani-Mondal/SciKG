{"title": [{"text": "Shallow Semantics in Fast Textual Entailment Rule Learners", "labels": [], "entities": [{"text": "Fast Textual Entailment Rule Learners", "start_pos": 21, "end_pos": 58, "type": "TASK", "confidence": 0.7285569429397583}]}], "abstractContent": [{"text": "In this paper, we briefly describe two enhancements of the cross-pair similarity model for learning textual entailment rules: 1) the typed anchors and 2) a faster computation of the similarity.", "labels": [], "entities": []}, {"text": "We will report and comment on the preliminary experiments and on the submission results.", "labels": [], "entities": []}], "introductionContent": [{"text": "Results of the second RTE challenge) have suggested that both deep semantic models and machine learning approaches can successfully be applied to solve textual entailment.", "labels": [], "entities": [{"text": "RTE challenge", "start_pos": 22, "end_pos": 35, "type": "TASK", "confidence": 0.535150021314621}, {"text": "solve textual entailment", "start_pos": 146, "end_pos": 170, "type": "TASK", "confidence": 0.6895801424980164}]}, {"text": "The only problem seems to be the size of the knowledge bases.", "labels": [], "entities": []}, {"text": "The two best systems (), which are significantly above all the others (more than +10% accuracy), use implicit or explicit knowledge bases larger than all the other systems.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 86, "end_pos": 94, "type": "METRIC", "confidence": 0.9987842440605164}]}, {"text": "In (), a deep semantic representation is paired with a large amount of general and task specific semantic rules (explicit knowledge).", "labels": [], "entities": []}, {"text": "In (, the machine learning model is trained over a large amounts of examples (implicit knowledge).", "labels": [], "entities": []}, {"text": "In contrast, Zanzotto&Moschitti (2006) proposed a machine-learning based approach which reaches a high accuracy by only using the available RTE data.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 103, "end_pos": 111, "type": "METRIC", "confidence": 0.9942864775657654}]}, {"text": "The key idea is the cross-pair similarity, i.e. a similarity applied to two text and hypothesis pairs which considers the relations between the words in the two texts and between the words in the two hypotheses.", "labels": [], "entities": []}, {"text": "This is obtained by using placeholders to link the related words.", "labels": [], "entities": []}, {"text": "Results in) are comparable with the best machine learning system when this latter is trained only on the RTE examples.", "labels": [], "entities": [{"text": "RTE", "start_pos": 105, "end_pos": 108, "type": "DATASET", "confidence": 0.7632285356521606}]}, {"text": "Given the high potential of the cross-pair similarity model, for the RTE3 challenge, we built on it by including some features of the two best systems: 1) we go towards a deeper semantic representation of learning pairs including shallow semantic information in the syntactic trees using typed placeholders; 2) we reduce the computational cost of the cross-pair similarity computation algorithm to allow the learning over larger training sets.", "labels": [], "entities": [{"text": "RTE3 challenge", "start_pos": 69, "end_pos": 83, "type": "TASK", "confidence": 0.5503226816654205}]}, {"text": "The paper is organized as follows: in Sec.", "labels": [], "entities": []}, {"text": "2 we review the cross-pair similarity model and its limits; in Sec.", "labels": [], "entities": []}, {"text": "3, we introduce our model for typed anchors; in Sec.", "labels": [], "entities": [{"text": "typed anchors", "start_pos": 30, "end_pos": 43, "type": "TASK", "confidence": 0.7075809836387634}]}, {"text": "4 we describe how we limit the computational cost of the similarity; in Sec.", "labels": [], "entities": []}, {"text": "5 we present the two submission experiments, and in Sec.", "labels": [], "entities": []}, {"text": "6 we draw some conclusions.", "labels": [], "entities": []}], "datasetContent": [{"text": "We implemented the novel cross-similarity kernel in the SVM-light-TK) that encodes the basic syntactic kernel K T in SVM-light.", "labels": [], "entities": []}, {"text": "To assess the validity of the typed anchor model (tap), we evaluated two sets of systems: the plain and lexical-boosted systems.", "labels": [], "entities": []}, {"text": "The plain systems are: -tap: our tree-kernel approach using typed placeholders with climbing in the syntactic tree; -tree: the cross-similarity model described in Sec.2.", "labels": [], "entities": []}, {"text": "Its comparison with tap indicates the effectiveness of our approaches; The lexical-boosted systems are: -lex: a standard approach based on lexical overlap.", "labels": [], "entities": []}, {"text": "The classifier uses as the only feature the lexical overlap similarity score described in); -lex+tap: these configurations mix lexical overlap and our typed anchor approaches; -lex+tree: the comparison of this configuration with lex+tap should further support the validity of our intuition on typed anchors; Preliminary experiments have been performed using two datasets: RTE2 (the 1600 entailment pairs from the RTE-2 challenge) and RTE3d (the development dataset of this challenge).", "labels": [], "entities": [{"text": "RTE2", "start_pos": 372, "end_pos": 376, "type": "DATASET", "confidence": 0.8950452208518982}, {"text": "RTE3d", "start_pos": 434, "end_pos": 439, "type": "DATASET", "confidence": 0.8915042877197266}]}, {"text": "We randomly divided this latter in two halves: RT E3d 0 and RT E3d 1 . reports the results of the experiments.", "labels": [], "entities": [{"text": "RT E3d 0", "start_pos": 47, "end_pos": 55, "type": "DATASET", "confidence": 0.5321571628252665}, {"text": "RT E3d 1", "start_pos": 60, "end_pos": 68, "type": "METRIC", "confidence": 0.5330514311790466}]}, {"text": "The first column indicates the training set whereas the second one specifies the used test set.", "labels": [], "entities": []}, {"text": "The third and the forth columns represent the accuracy of basic models: the original tree model and the enhanced tap model.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 46, "end_pos": 54, "type": "METRIC", "confidence": 0.9995193481445312}]}, {"text": "The latter three columns report the basic lex model and the two combined models, lex+tree and lex+tap.", "labels": [], "entities": []}, {"text": "The second and the third rows represent the accuracy of the models with respect to the first randomly selected half of RT E3d whilst the last two rows are related to the second half.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 44, "end_pos": 52, "type": "METRIC", "confidence": 0.9994890689849854}, {"text": "RT E3d", "start_pos": 119, "end_pos": 125, "type": "DATASET", "confidence": 0.8889911770820618}]}, {"text": "The experimental results show some interesting facts.", "labels": [], "entities": []}, {"text": "In the case of the plain systems (tree and tap), we have the following observations: -The use of the typed anchors in the model seems to be effective.", "labels": [], "entities": []}, {"text": "All the tap model results are higher than the corresponding tree model results.", "labels": [], "entities": []}, {"text": "This suggests that the method used to integrate this kind of information in the syntactic tree is effective.", "labels": [], "entities": []}, {"text": "-The claim that using more training material helps seems not to be supported by these experiments.", "labels": [], "entities": []}, {"text": "The gap between tree and tap is higher when learning with RT E2 + RT E3d 0 than when learning with RT E3 0 . This supports the claim.", "labels": [], "entities": [{"text": "RT E2 + RT E3d 0", "start_pos": 58, "end_pos": 74, "type": "DATASET", "confidence": 0.7495057980219523}]}, {"text": "However, the result is not kept when learning with RT E2 + RT E3d 1 with respect to when learning with RT E3 1 . This suggests that adding not very specific information, i.e. derived from corpora different from the target one (RTE3), may not help the learning of accurate rules.", "labels": [], "entities": [{"text": "RT E2 + RT E3d 1", "start_pos": 51, "end_pos": 67, "type": "DATASET", "confidence": 0.7668183247248331}]}], "tableCaptions": [{"text": " Table 2: Accuracy of the systems on two folds of RTE3 development", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9977173805236816}]}]}