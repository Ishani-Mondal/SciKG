{"title": [{"text": "ConText: An Algorithm for Identifying Contextual Features from Clinical Text", "labels": [], "entities": [{"text": "Identifying Contextual Features from Clinical Text", "start_pos": 26, "end_pos": 76, "type": "TASK", "confidence": 0.8731416463851929}]}], "abstractContent": [{"text": "Applications using automatically indexed clinical conditions must account for con-textual features such as whether a condition is negated, historical or hypothetical, or experienced by someone other than the patient.", "labels": [], "entities": []}, {"text": "We developed and evaluated an algorithm called ConText, an extension of the NegEx negation algorithm, which relies on trigger terms, pseudo-trigger terms, and termination terms for identifying the values of three contextual features.", "labels": [], "entities": []}, {"text": "In spite of its simplicity, ConText performed well at identifying negation and hypothetical status.", "labels": [], "entities": [{"text": "identifying negation", "start_pos": 54, "end_pos": 74, "type": "TASK", "confidence": 0.6995035409927368}]}, {"text": "ConText performed moderately at identifying whether a condition was experienced by someone other than the patient and whether the condition occurred historically.", "labels": [], "entities": [{"text": "ConText", "start_pos": 0, "end_pos": 7, "type": "DATASET", "confidence": 0.8485114574432373}]}], "introductionContent": [{"text": "Natural language processing (NLP) techniques can extract variables from free-text clinical records important for medical informatics applications performing decision support, quality assurance, and biosurveillance.", "labels": [], "entities": [{"text": "Natural language processing (NLP)", "start_pos": 0, "end_pos": 33, "type": "TASK", "confidence": 0.7390321890513102}, {"text": "decision support", "start_pos": 157, "end_pos": 173, "type": "TASK", "confidence": 0.8846379816532135}]}, {"text": "Many applications have focused on identifying individual clinical conditions in textual records, which is the first step in making the conditions available to computerized applications.", "labels": [], "entities": []}, {"text": "However, identifying individual instances of clinical conditions is not sufficient for many medical informatics tasks-the context surrounding the condition is crucial for integrating the information within the text to determine the clinical state of a patient.", "labels": [], "entities": []}, {"text": "For instance, it is important to understand whether a condition is affirmed or negated, acute or chronic, or mentioned hypothetically.", "labels": [], "entities": []}, {"text": "We refer to these as contextual features, because the information is not usually contained in the lexical representation of the clinical condition itself but in the context surrounding the clinical condition.", "labels": [], "entities": []}, {"text": "We developed an algorithm called ConText for identifying three contextual features relevant for biosurveillance from emergency department (ED) reports and evaluated its performance compared to physician annotation of the features.", "labels": [], "entities": []}], "datasetContent": [{"text": "We evaluated ConText's ability to assign correct values to the three contextual features by comparing ConText's annotations with annotations made by a physician.", "labels": [], "entities": []}, {"text": "The study was conducted on reports for patients presenting to the University of Pittsburgh Medical Center Presbyterian Hospital ED during 2002.", "labels": [], "entities": [{"text": "Pittsburgh Medical Center Presbyterian Hospital ED during 2002", "start_pos": 80, "end_pos": 142, "type": "DATASET", "confidence": 0.78415547311306}]}, {"text": "The study was approved by the University of Pittsburgh's Institutional Review Board.", "labels": [], "entities": []}, {"text": "We randomly selected 120 reports for patients with respiratory-related ICD-9 discharge diagnoses for manual annotation.", "labels": [], "entities": [{"text": "ICD-9 discharge diagnoses", "start_pos": 71, "end_pos": 96, "type": "TASK", "confidence": 0.5629690090815226}]}, {"text": "For this study, we used 30 reports as a development set and 90 reports as a test set.", "labels": [], "entities": []}, {"text": "In addition to the annotated development set, we used a separate set of 100 unannotated ED reports to informally validate our term lists.", "labels": [], "entities": []}, {"text": "A physician board-certified in internal medicine and infectious diseases with 30 years of experience generated manual annotations for the development and test reports.", "labels": [], "entities": []}, {"text": "He used GATE (http://gate.ac.uk/) to highlight every indi-vidual annotation in the text referring to any of the 55 clinical conditions.", "labels": [], "entities": [{"text": "GATE", "start_pos": 8, "end_pos": 12, "type": "DATASET", "confidence": 0.6233835220336914}]}, {"text": "For every annotation, he assigned values to the three contextual features, as shown in.", "labels": [], "entities": []}, {"text": "Previous experience in annotating the 55 conditions showed that a single physician was inadequate for generating a reliable reference standard.", "labels": [], "entities": []}, {"text": "The main mistake made by a single physician was not marking a concept that existed in the text.", "labels": [], "entities": []}, {"text": "We used NLP-assisted review to improve physician annotations by comparing the single physician's annotations to those made by SySTR.", "labels": [], "entities": []}, {"text": "The physician reviewed disagreements and made changes to his original annotations if he felt his original annotation was incorrect.", "labels": [], "entities": []}, {"text": "A study by Meystre and Haug used a similar NLP-assisted review methodology and showed that compared to a reference standard not using NLP-assisted review, their system had higher recall and the same precision.", "labels": [], "entities": [{"text": "recall", "start_pos": 179, "end_pos": 185, "type": "METRIC", "confidence": 0.9996709823608398}, {"text": "precision", "start_pos": 199, "end_pos": 208, "type": "METRIC", "confidence": 0.9986360669136047}]}, {"text": "For each contextual feature assigned to an annotation, we compared ConText's value to the value assigned by the reference standard.", "labels": [], "entities": []}, {"text": "We classified the feature as a true positive (TP) if ConText correctly changed the condition's default value and a true negative (TN) if ConText correctly left the default value.", "labels": [], "entities": []}, {"text": "We then calculated recall and precision using the following formulas: For the Temporality feature, we calculated recall and precision separately for the values historical and hypothetical.", "labels": [], "entities": [{"text": "recall", "start_pos": 19, "end_pos": 25, "type": "METRIC", "confidence": 0.9988850951194763}, {"text": "precision", "start_pos": 30, "end_pos": 39, "type": "METRIC", "confidence": 0.9982181191444397}, {"text": "Temporality", "start_pos": 78, "end_pos": 89, "type": "TASK", "confidence": 0.8196569681167603}, {"text": "recall", "start_pos": 113, "end_pos": 119, "type": "METRIC", "confidence": 0.9989578723907471}, {"text": "precision", "start_pos": 124, "end_pos": 133, "type": "METRIC", "confidence": 0.995997428894043}]}, {"text": "We calculated the 95% confidence intervals (CI) for all outcome measures.", "labels": [], "entities": [{"text": "95% confidence intervals (CI)", "start_pos": 18, "end_pos": 47, "type": "METRIC", "confidence": 0.8263386232512338}]}], "tableCaptions": [{"text": " Table 3. Outcome measures for ConText on test set of 90 ED reports.", "labels": [], "entities": [{"text": "Outcome", "start_pos": 10, "end_pos": 17, "type": "METRIC", "confidence": 0.9964050054550171}, {"text": "ConText on test set of 90 ED reports", "start_pos": 31, "end_pos": 67, "type": "DATASET", "confidence": 0.7537079378962517}]}]}