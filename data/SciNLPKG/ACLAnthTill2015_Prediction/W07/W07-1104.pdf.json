{"title": [], "abstractContent": [{"text": "This paper describes a fully unsupervised and automated method for large-scale extraction of multiword expressions (MWEs) from large corpora.", "labels": [], "entities": [{"text": "large-scale extraction of multiword expressions (MWEs) from large corpora", "start_pos": 67, "end_pos": 140, "type": "TASK", "confidence": 0.841894193129106}]}, {"text": "The method aims at capturing the non-compositionality of MWEs; the intuition is that a noun within a MWE cannot easily be replaced by a semantically similar noun.", "labels": [], "entities": []}, {"text": "To implement this intuition , a noun clustering is automatically extracted (using distributional similarity measures), which gives us clusters of semantically related nouns.", "labels": [], "entities": [{"text": "noun clustering", "start_pos": 32, "end_pos": 47, "type": "TASK", "confidence": 0.7034678310155869}]}, {"text": "Next, a number of statistical measures-based on selectional preferences is developed that formalize the intuition of non-compositionality.", "labels": [], "entities": []}, {"text": "Our approach has been tested on Dutch, and automatically evaluated using Dutch lexical resources.", "labels": [], "entities": []}], "introductionContent": [{"text": "MWEs are expressions whose linguistic behaviour is not predictable from the linguistic behaviour of their component words.", "labels": [], "entities": []}, {"text": "characterizes the idiosyncratic behavior of MWEs as \"a lack of compositionality manifest at different levels of analysis, namely, lexical, morphological, syntactic, semantic, pragmatic and statistical\".", "labels": [], "entities": []}, {"text": "Some MWEs show productive morphology and/or syntactic flexibility.", "labels": [], "entities": []}, {"text": "Therefore, these two aspects are not sufficient conditions to discriminate actual MWEs from productive expressions.", "labels": [], "entities": []}, {"text": "Nonetheless, the mentioned characteristics are useful indicators to distinguish literal and idiomatic expressions).", "labels": [], "entities": []}, {"text": "One property that seems to affect MWEs the most is semantic non-compositionality.", "labels": [], "entities": [{"text": "MWEs", "start_pos": 34, "end_pos": 38, "type": "TASK", "confidence": 0.9078472852706909}]}, {"text": "As a consequence, it is not possible to replace the noun of a MWE by semantically related nouns.", "labels": [], "entities": []}, {"text": "Take for example the expressions in and: a. break the vase b. break the cup c. break the dish (2) a. break the ice b.", "labels": [], "entities": []}, {"text": "*break the snow c.", "labels": [], "entities": [{"text": "break the snow c", "start_pos": 1, "end_pos": 17, "type": "DATASET", "confidence": 0.6319690048694611}]}, {"text": "*break the hail Expression (1-a) is fully compositional.", "labels": [], "entities": []}, {"text": "Therefore, vase can easily be replaced with semantically related nouns such as cup and dish.", "labels": [], "entities": []}, {"text": "Expression (2-a), on the contrary, is non-compositional; ice cannot be replaced with semantically related words, such as snow and hail without loss of the original meaning.", "labels": [], "entities": []}, {"text": "Due to the idiosyncratic behavior, current proposals argue that MWEs need to be described in the lexicon ().", "labels": [], "entities": [{"text": "MWEs", "start_pos": 64, "end_pos": 68, "type": "TASK", "confidence": 0.9342186450958252}]}, {"text": "In most languages, electronic lexical resources (such as dictionaries, thesauri, ontologies) suffer from a limited coverage of To facilitate the update and expansion of language resources, the NLP community would clearly benefit from automated methods that extract MWEs from large text collections.", "labels": [], "entities": []}, {"text": "This is the main motivation to pursue an automated and fully unsupervised MWE extraction method.", "labels": [], "entities": [{"text": "MWE extraction", "start_pos": 74, "end_pos": 88, "type": "TASK", "confidence": 0.9810666143894196}]}], "datasetContent": [{"text": "In this section, we quantitatively evaluate our method, and compare it to the lexical and syntactic fixedness measures proposed by.", "labels": [], "entities": []}, {"text": "More information about Fazly and Stevenson's measures can be found in their paper.", "labels": [], "entities": []}, {"text": "The potential MWEs that are extracted with the fully unsupervised method described above and with Fazly and Stevenson's (2006) method (FS from here onwards) are automatically evaluated by comparing the extracted list to handcrafted MWE databases.", "labels": [], "entities": [{"text": "FS", "start_pos": 135, "end_pos": 137, "type": "METRIC", "confidence": 0.9784076809883118}]}, {"text": "Since we have extracted Dutch MWEs, we are using the two Dutch resources available: the Referentie Bestand Nederlands) and the Van Dale Lexicographical Information System (VLIS) database.", "labels": [], "entities": [{"text": "Van Dale Lexicographical Information System (VLIS) database", "start_pos": 127, "end_pos": 186, "type": "DATASET", "confidence": 0.8057346343994141}]}, {"text": "Evaluation scores are calculated with regard to the MWEs that are present in our evaluation resources.", "labels": [], "entities": []}, {"text": "Among the MWEs in our reference data, we consider only those expressions that are present in our frequency matrix: if the verb is not among the 5,000 most frequent verbs, or the noun is not among the 10,000 most frequent nouns, the frequency information is not present in our input data.", "labels": [], "entities": []}, {"text": "Consequently, our algorithm would never be able to find those MWEs show precision, recall and f-measure for various parameter thresholds with regard to the measures A v\u2192n , R v\u2192n , A n\u2192v and R n\u2192v , together with the number of candidates found (n).", "labels": [], "entities": [{"text": "precision", "start_pos": 72, "end_pos": 81, "type": "METRIC", "confidence": 0.9995007514953613}, {"text": "recall", "start_pos": 83, "end_pos": 89, "type": "METRIC", "confidence": 0.9996328353881836}, {"text": "f-measure", "start_pos": 94, "end_pos": 103, "type": "METRIC", "confidence": 0.95563143491745}]}, {"text": "The last 3 rows show the highest values we were able to reach by using FS's fixedness scores.", "labels": [], "entities": [{"text": "FS", "start_pos": 71, "end_pos": 73, "type": "DATASET", "confidence": 0.7512568831443787}]}, {"text": "Using only two parameters -A v\u2192n and R v\u2192n -gives the highest f-measure (\u00b1 14%), with a precision and recall of about 17% and about 12% respectively.", "labels": [], "entities": [{"text": "f-measure", "start_pos": 62, "end_pos": 71, "type": "METRIC", "confidence": 0.9812929034233093}, {"text": "precision", "start_pos": 88, "end_pos": 97, "type": "METRIC", "confidence": 0.9996740818023682}, {"text": "recall", "start_pos": 102, "end_pos": 108, "type": "METRIC", "confidence": 0.9995728135108948}]}, {"text": "Adding parameter R n\u2192v increases precision but degrades recall, and this tendency continues when adding both parameters A n\u2192v and R n\u2192v . In all cases, a higher threshold increases precision but degrades recall.", "labels": [], "entities": [{"text": "precision", "start_pos": 33, "end_pos": 42, "type": "METRIC", "confidence": 0.9991812109947205}, {"text": "recall", "start_pos": 56, "end_pos": 62, "type": "METRIC", "confidence": 0.9988951086997986}, {"text": "precision", "start_pos": 181, "end_pos": 190, "type": "METRIC", "confidence": 0.9987252354621887}, {"text": "recall", "start_pos": 204, "end_pos": 210, "type": "METRIC", "confidence": 0.9962620139122009}]}, {"text": "When using a high threshold for all parameters, the algorithm is able to reach a precision of \u00b1 38%, but recall is low (\u00b1 4%).", "labels": [], "entities": [{"text": "precision", "start_pos": 81, "end_pos": 90, "type": "METRIC", "confidence": 0.9986976385116577}, {"text": "recall", "start_pos": 105, "end_pos": 111, "type": "METRIC", "confidence": 0.9995957016944885}]}, {"text": "Lexical fixedness reaches an f-measure of \u00b1 12% (threshold of 3.00).", "labels": [], "entities": [{"text": "f-measure", "start_pos": 29, "end_pos": 38, "type": "METRIC", "confidence": 0.9851211309432983}]}, {"text": "These scores show the best performance that we reached using lexical fixedness.", "labels": [], "entities": []}, {"text": "Following FS, we evaluated the syntactic fixedness scores of expressions falling above a frequency cutoff.", "labels": [], "entities": [{"text": "FS", "start_pos": 10, "end_pos": 12, "type": "METRIC", "confidence": 0.5417628884315491}]}, {"text": "Since our corpus is much larger than that used by FS, a frequency cutoff of 50 was chosen.", "labels": [], "entities": [{"text": "FS", "start_pos": 50, "end_pos": 52, "type": "TASK", "confidence": 0.49230584502220154}]}, {"text": "The precision, recall and f-measure of the syntactic fixedness measure (shown on table 3) are \u00b1 10%, 41% and 16% respectively, showing worse precision than our method but much better recall and f-measure.", "labels": [], "entities": [{"text": "precision", "start_pos": 4, "end_pos": 13, "type": "METRIC", "confidence": 0.9995423555374146}, {"text": "recall", "start_pos": 15, "end_pos": 21, "type": "METRIC", "confidence": 0.9977405071258545}, {"text": "f-measure", "start_pos": 26, "end_pos": 35, "type": "METRIC", "confidence": 0.9234842658042908}, {"text": "precision", "start_pos": 141, "end_pos": 150, "type": "METRIC", "confidence": 0.9980071187019348}, {"text": "recall", "start_pos": 183, "end_pos": 189, "type": "METRIC", "confidence": 0.9988937973976135}]}, {"text": "As shown by FS, syntactic fixedness performs better than lexical fixedness; F ixedness overall improves on the syntactic fixedness results and also reaches better overall performance than our method.", "labels": [], "entities": [{"text": "FS", "start_pos": 12, "end_pos": 14, "type": "DATASET", "confidence": 0.7474302649497986}]}, {"text": "The compared methods show a different behavior.", "labels": [], "entities": []}, {"text": "FS's method favours high recall whereas our method prefers the best trade-off between precision and recall.", "labels": [], "entities": [{"text": "FS", "start_pos": 0, "end_pos": 2, "type": "DATASET", "confidence": 0.723817765712738}, {"text": "recall", "start_pos": 25, "end_pos": 31, "type": "METRIC", "confidence": 0.9992986917495728}, {"text": "precision", "start_pos": 86, "end_pos": 95, "type": "METRIC", "confidence": 0.9992671608924866}, {"text": "recall", "start_pos": 100, "end_pos": 106, "type": "METRIC", "confidence": 0.9952132701873779}]}, {"text": "We wish to highlight that our method reaches better precision than FS's method while handling many low frequency candidates (minimum frequency is 3); this makes our method preferable in some NLP tasks.", "labels": [], "entities": [{"text": "precision", "start_pos": 52, "end_pos": 61, "type": "METRIC", "confidence": 0.9962661862373352}, {"text": "FS", "start_pos": 67, "end_pos": 69, "type": "DATASET", "confidence": 0.7067302465438843}]}, {"text": "It is possible that the two methods are capturing different properties of MWEs; in future work, we want to analyse whether the expressions extracted by the two methods differ.", "labels": [], "entities": []}, {"text": "Next, we elaborate upon advantages and disadvantages of our semantics-based MWE extraction algorithm by examining the output of the procedure, and looking at the characteristics of the MWEs found and the errors made by the algorithm.", "labels": [], "entities": [{"text": "MWE extraction", "start_pos": 76, "end_pos": 90, "type": "TASK", "confidence": 0.8968620300292969}]}, {"text": "First of all, our algorithm is able to filter out grammatical collocations that cause problems in traditional MWE extraction paradigms.", "labels": [], "entities": [{"text": "MWE extraction paradigms", "start_pos": 110, "end_pos": 134, "type": "TASK", "confidence": 0.9682765205701193}]}, {"text": "An example is given in (5).", "labels": [], "entities": []}, {"text": "In traditional MWE extraction algorithms, based on collocations, highly frequent expressions like the ones in (5) often get classified as a MWE, even though they are fully compositional.", "labels": [], "entities": [{"text": "MWE extraction", "start_pos": 15, "end_pos": 29, "type": "TASK", "confidence": 0.9869242012500763}]}, {"text": "Such algorithms correctly identify a strong lexical affinity between two component words, which makeup a grammatical collocation; however, they fail to capture the fact that the noun maybe filled in by a semantic class of nouns.", "labels": [], "entities": []}, {"text": "Our algorithm filters out those expressions, because semantic similarity between nouns that fill in the object slot is taken into account.", "labels": [], "entities": []}, {"text": "Our quantitative evaluation shows that the algorithm reaches the best results (i.e. the highest fmeasures) when using only two parameters (A v\u2192n and R v\u2192n ).", "labels": [], "entities": [{"text": "fmeasures", "start_pos": 96, "end_pos": 105, "type": "METRIC", "confidence": 0.9771994948387146}]}, {"text": "Upon closer inspection of the output, we noticed that A n\u2192v and R n\u2192v are often able to filter out non-MWEs like the expressions bin and.", "labels": [], "entities": []}, {"text": "a It is only when the two other measures (a unique preference of the noun for the verb) are taken into account that the b expressions are filtered out -either because the noun preference for the verb is very low, or because it is more evenly distributed among the cluster.", "labels": [], "entities": []}, {"text": "The b expressions, which are non-MWEs, result from the combination of a verb with a highly frequent PP.", "labels": [], "entities": []}, {"text": "These PPs are typically locative, directional or predicative PPs, that may combine with numerous verbs.", "labels": [], "entities": []}, {"text": "Also, expressions like the ones in, where the fixedness of the expression lies not so much in the verb-noun combination, but more in the noun part (naar school, naar huis) are filtered out by the latter two measures.", "labels": [], "entities": []}, {"text": "These preposition-noun combinations seem to be institutionalized PPs, so-called determinerless PPs.", "labels": [], "entities": []}, {"text": "We will now look at some errors made by our algorithm.", "labels": [], "entities": []}, {"text": "First of all, our algorithm highly depends on the quality of the noun clustering.", "labels": [], "entities": [{"text": "noun clustering", "start_pos": 65, "end_pos": 80, "type": "TASK", "confidence": 0.7277683764696121}]}, {"text": "If a noun appears in a cluster with unrelated words, the measures will overrate the semantic uniqueness of the expressions in which the noun appears.", "labels": [], "entities": []}, {"text": "Secondly, syntax might play an important role.", "labels": [], "entities": []}, {"text": "Sometimes, there are syntactic restrictions between the preposition and the noun.", "labels": [], "entities": []}, {"text": "A noun like pagina 'page' can only appear with the preposition op 'on', as in lees op pagina 'read on page'.", "labels": [], "entities": []}, {"text": "Other, semantically related nouns, such as hoofdstuk 'chapter', prefer in 'in'.", "labels": [], "entities": []}, {"text": "Due to these restrictions, the measures will again overrate the semantic uniqueness of the noun (pagina in the example).", "labels": [], "entities": []}, {"text": "Finally, our hard clustering method does not take polysemous nouns into account.", "labels": [], "entities": [{"text": "hard clustering", "start_pos": 13, "end_pos": 28, "type": "TASK", "confidence": 0.6517661809921265}]}, {"text": "A noun may only occur in one cluster, ignoring other possible meanings.", "labels": [], "entities": []}, {"text": "Schaal, for example, means 'dish' as well as 'scale'.", "labels": [], "entities": []}, {"text": "In our clustering, it only appears in a cluster of dish-related nouns.", "labels": [], "entities": []}, {"text": "Therefore, expressions like maak gebruik op [grote] schaal 'make use of [sth.] on a [large] scale', receive again overrated measures of semantic uniqueness, because the 'scale' sense of the noun is compared to nouns related to the 'dish' sense.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Scores for MWE candidate in de smaak  vallen and other nouns in the same cluster.", "labels": [], "entities": [{"text": "MWE", "start_pos": 21, "end_pos": 24, "type": "TASK", "confidence": 0.8196941614151001}]}, {"text": " Table 2: Scores for MWE candidate in de put vallen  and other nouns in same cluster.", "labels": [], "entities": [{"text": "MWE", "start_pos": 21, "end_pos": 24, "type": "TASK", "confidence": 0.7917880415916443}]}, {"text": " Table 3: Evaluation results compared to RBN & VLIS", "labels": [], "entities": [{"text": "Evaluation", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.9448739290237427}, {"text": "RBN", "start_pos": 41, "end_pos": 44, "type": "TASK", "confidence": 0.5400416851043701}, {"text": "VLIS", "start_pos": 47, "end_pos": 51, "type": "DATASET", "confidence": 0.33731725811958313}]}]}