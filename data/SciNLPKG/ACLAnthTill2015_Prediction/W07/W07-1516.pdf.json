{"title": [{"text": "Active Learning for Part-of-Speech Tagging: Accelerating Corpus Annotation", "labels": [], "entities": [{"text": "Part-of-Speech Tagging", "start_pos": 20, "end_pos": 42, "type": "TASK", "confidence": 0.7635239064693451}, {"text": "Accelerating", "start_pos": 44, "end_pos": 56, "type": "METRIC", "confidence": 0.9611799716949463}]}], "abstractContent": [{"text": "In the construction of a part-of-speech annotated corpus, we are constrained by a fixed budget.", "labels": [], "entities": []}, {"text": "A fully annotated corpus is required, but we can afford to label only a subset.", "labels": [], "entities": []}, {"text": "We train a Maximum Entropy Mar-kov Model tagger from a labeled subset and automatically tag the remainder.", "labels": [], "entities": []}, {"text": "This paper addresses the question of whereto focus our manual tagging efforts in order to deliver an annotation of highest quality.", "labels": [], "entities": []}, {"text": "In this context, we find that active learning is always helpful.", "labels": [], "entities": []}, {"text": "We focus on Query by Uncertainty (QBU) and Query by Committee (QBC) and report on experiments with several baselines and new variations of QBC and QBU, inspired by weaknesses particular to their use in this application.", "labels": [], "entities": [{"text": "Query by Uncertainty (QBU)", "start_pos": 12, "end_pos": 38, "type": "TASK", "confidence": 0.8094913264115652}]}, {"text": "Experiments on English prose and poetry test these approaches and evaluate their robust-ness.", "labels": [], "entities": []}, {"text": "The results allow us to make recommendations for both types of text and raise questions that will lead to further inquiry.", "labels": [], "entities": []}], "introductionContent": [{"text": "We are operating (as many do) on a fixed budget and need annotated text in the context of a larger project.", "labels": [], "entities": []}, {"text": "We need a fully annotated corpus but can afford to annotate only a subset.", "labels": [], "entities": []}, {"text": "To address our budgetary constraint, we train a model from a manually annotated subset of the corpus and automatically annotate the remainder.", "labels": [], "entities": []}, {"text": "At issue is whereto focus manual annotation efforts in order to produce a complete annotation of highest possible quality.", "labels": [], "entities": []}, {"text": "A follow-up question is whether these techniques work equally well on different types of text.", "labels": [], "entities": []}, {"text": "In particular, we require part-of-speech (POS) annotations.", "labels": [], "entities": []}, {"text": "In this paper we employ a state-of-theart tagger on both prose and poetry, and we examine multiple known and novel active learning (or sampling) techniques in order to determine which work best in this context.", "labels": [], "entities": []}, {"text": "We show that the results obtained by a state-of-the-art tagger trained on a small portion of the data selected through active learning can approach the accuracy attained by human annotators and are on par with results from exhaustively trained automatic taggers.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 152, "end_pos": 160, "type": "METRIC", "confidence": 0.9986036419868469}]}, {"text": "Ina study based on English language data presented here, we identify several active learning techniques and make several recommendations that we hope will be portable for application to other text types and to other languages.", "labels": [], "entities": []}, {"text": "In section 2 we briefly review the state of the art approach to POS tagging.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 64, "end_pos": 75, "type": "TASK", "confidence": 0.891569048166275}]}, {"text": "In section 3, we survey the approaches to active learning employed in this study, including variations on commonly known techniques.", "labels": [], "entities": []}, {"text": "Section 4 introduces the experimental regime and presents results and their implications.", "labels": [], "entities": []}, {"text": "Section 5 draws conclusions and identifies opportunities for follow-up research.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section, we examine the experimental setup, the prose and poetry data sets, and the results from using the various active learning algorithms on these corpora.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1. The best models (on PTB WSJ data) with various  amounts of annotation (columns).", "labels": [], "entities": [{"text": "PTB WSJ data", "start_pos": 30, "end_pos": 42, "type": "DATASET", "confidence": 0.925652801990509}]}]}