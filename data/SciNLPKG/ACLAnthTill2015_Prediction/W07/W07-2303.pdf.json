{"title": [{"text": "Stochastic Realisation Ranking fora Free Word Order Language", "labels": [], "entities": [{"text": "Stochastic Realisation", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.77745521068573}]}], "abstractContent": [{"text": "We present a log-linear model that is used for ranking the string realisations produced forgiven corpus f-structures by a reversible broad-coverage LFG for German and compare its results with the ones achieved by the application of a language model (LM).", "labels": [], "entities": []}, {"text": "Like other authors that have developed log-linear models for reali-sation ranking, we use a hybrid model that uses linguistically motivated learning features and a LM (whose score is simply integrated into the log-linear model as an additional feature) for the task of realisation ranking.", "labels": [], "entities": [{"text": "realisation ranking", "start_pos": 269, "end_pos": 288, "type": "TASK", "confidence": 0.9445829093456268}]}, {"text": "We carryout a large evaluation of the model, training on over 8,600 structures and testing on 323.", "labels": [], "entities": []}, {"text": "We observe that the contribution that the structural features make to the quality of the output is slightly greater in the case of a free word order language like German than it is in the case of English.", "labels": [], "entities": []}, {"text": "The exact match metric improves from 27% to 37% when going from the LM-based re-alisation ranking to the hybrid model, BLEU score improves from 0.7306 to 0.7939.", "labels": [], "entities": [{"text": "exact match metric", "start_pos": 4, "end_pos": 22, "type": "METRIC", "confidence": 0.8201562364896139}, {"text": "BLEU score", "start_pos": 119, "end_pos": 129, "type": "METRIC", "confidence": 0.9813680350780487}]}], "introductionContent": [{"text": "Most traditional approaches to stochastic realisation ranking involve applying language model n-gram statistics to rank alternatives;).", "labels": [], "entities": [{"text": "stochastic realisation ranking", "start_pos": 31, "end_pos": 61, "type": "TASK", "confidence": 0.7334233721097311}]}, {"text": "Much work has been carried out into statistical realisation ranking for English.", "labels": [], "entities": [{"text": "statistical realisation ranking", "start_pos": 36, "end_pos": 67, "type": "TASK", "confidence": 0.7471602559089661}]}, {"text": "However, n-grams alone (even if they are efficiently implemented) may not be a good enough measure for ranking candidate strings, particularly in free-word order languages.", "labels": [], "entities": []}, {"text": "moves away from n-gram models of generation and trains a generator on a generation treebank, achieving similar results to a bigram model but at much lower computational cost.", "labels": [], "entities": []}, {"text": "do not use a language model, but rather rely on treebank-based automatically derived LFG generation grammars to determine the most likely surface order.", "labels": [], "entities": []}, {"text": "Ohkuma writes an LFG generation grammar for Japanese separate from the Japanese LFG parsing grammar in order to enforce canonical word order by symbolic means.", "labels": [], "entities": [{"text": "Japanese LFG parsing grammar", "start_pos": 71, "end_pos": 99, "type": "TASK", "confidence": 0.683653362095356}]}, {"text": "In another purely symbolic approach,) describes a wide-coverage system and the author argues that there are several advantages to a symbolic system over a statistical one.", "labels": [], "entities": []}, {"text": "We argue that a reversible symbolic system, which is desirable for maintainability and modularity reasons, augmented with a statistical ranking component can produce systematically ranked, high quality surface realisations while maintaining the flexibility associated with hand-crafted systems. and present discriminative disambiguation models using a hand-crafted HPSG grammar for generation from MRS (Minimal Recursion Semantics) structures.", "labels": [], "entities": []}, {"text": "They describe three statistical models for realization ranking: The first is a simple n-gram language model, the second uses structural features in a maximum entropy model for disambiguation and a third uses a combination of the two models.", "labels": [], "entities": [{"text": "realization ranking", "start_pos": 43, "end_pos": 62, "type": "TASK", "confidence": 0.9403806924819946}]}, {"text": "Their results show that the third model where the n-gram language model is combined with the structural features in the maximum entropy disambiguation model performs best.", "labels": [], "entities": []}, {"text": "present similar probabilistic models fora chart generator using a HPSG grammar acquired from the Penn-II Treebank (the Enju HPSG), with the difference that, in their experiments, the model that only uses structural features outperformed the hybrid model.", "labels": [], "entities": [{"text": "Penn-II Treebank (the Enju HPSG)", "start_pos": 97, "end_pos": 129, "type": "DATASET", "confidence": 0.9029613648142133}]}, {"text": "We present a model for realisation ranking similar to the models just mentioned.", "labels": [], "entities": []}, {"text": "The main differences between our work and theirs is that we are working within the LFG framework and concentrating on a less configurational language: German.", "labels": [], "entities": [{"text": "LFG framework", "start_pos": 83, "end_pos": 96, "type": "DATASET", "confidence": 0.9421454668045044}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Number of structures and average sen- tence length according to ambiguity classes in  the training set", "labels": [], "entities": [{"text": "sen- tence length", "start_pos": 43, "end_pos": 60, "type": "METRIC", "confidence": 0.5283493995666504}]}, {"text": " Table 2: Number of structures and average sen- tence length according to ambiguity classes in  the test set", "labels": [], "entities": [{"text": "average sen- tence length", "start_pos": 35, "end_pos": 60, "type": "METRIC", "confidence": 0.5926651358604431}]}, {"text": " Table 3: Results with the language model", "labels": [], "entities": []}, {"text": " Table 5: Evaluating the ranking", "labels": [], "entities": []}]}