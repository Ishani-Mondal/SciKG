{"title": [{"text": "Machine Learning with Semantic-Based Distances Between Sentences for Textual Entailment", "labels": [], "entities": [{"text": "Textual Entailment", "start_pos": 69, "end_pos": 87, "type": "TASK", "confidence": 0.7132680416107178}]}], "abstractContent": [{"text": "This paper describes our experiments on Textual Entailment in the context of the Third Pascal Recognising Textual Entail-ment (RTE-3) Evaluation Challenge.", "labels": [], "entities": [{"text": "Textual Entailment", "start_pos": 40, "end_pos": 58, "type": "TASK", "confidence": 0.7673601508140564}, {"text": "Third Pascal Recognising Textual Entail-ment (RTE-3) Evaluation Challenge", "start_pos": 81, "end_pos": 154, "type": "TASK", "confidence": 0.5525072365999222}]}, {"text": "Our system uses a Machine Learning approach with Support Vector Machines and Ad-aBoost to deal with the RTE challenge.", "labels": [], "entities": [{"text": "RTE challenge", "start_pos": 104, "end_pos": 117, "type": "TASK", "confidence": 0.8199650347232819}]}, {"text": "We perform a lexical, syntactic, and semantic analysis of the entailment pairs.", "labels": [], "entities": []}, {"text": "From this information we compute a set of semantic-based distances between sentences.", "labels": [], "entities": []}, {"text": "The results look promising specially for the QA en-tailment task.", "labels": [], "entities": [{"text": "QA en-tailment task", "start_pos": 45, "end_pos": 64, "type": "TASK", "confidence": 0.8335246642430624}]}], "introductionContent": [{"text": "This paper describes our participation in the RTE-3 challenge.", "labels": [], "entities": [{"text": "RTE-3 challenge", "start_pos": 46, "end_pos": 61, "type": "TASK", "confidence": 0.6226143836975098}]}, {"text": "It is our first attempt to RTE and we have taken profit of an analysis of the approaches followed in previous challenges (see), and () for overviews of RTE-1 and RTE-2).", "labels": [], "entities": [{"text": "RTE", "start_pos": 27, "end_pos": 30, "type": "TASK", "confidence": 0.9810305833816528}, {"text": "RTE-2", "start_pos": 162, "end_pos": 167, "type": "DATASET", "confidence": 0.778256893157959}]}, {"text": "Our approach, however, is based on a set of semantic-based distance measures between sentences used by our group in previous contests in Question Answering, and)) , and Automatic Summarization).", "labels": [], "entities": [{"text": "Question Answering", "start_pos": 137, "end_pos": 155, "type": "TASK", "confidence": 0.8320169746875763}, {"text": "Automatic Summarization", "start_pos": 169, "end_pos": 192, "type": "TASK", "confidence": 0.6138772368431091}]}, {"text": "Although the use of such measures (distance between question and sentences in passages candidates to contain the answer, distance between query and sentences candidates to be included in the summary, ...) is different for RTE task, our claim is that with some modifications the approach can be useful in this new scenario.", "labels": [], "entities": [{"text": "RTE task", "start_pos": 222, "end_pos": 230, "type": "TASK", "confidence": 0.8546657860279083}]}, {"text": "The organization of this paper is as follows.", "labels": [], "entities": []}, {"text": "After this introduction we present in section 2 a description of the measures upon which our approach is built.", "labels": [], "entities": []}, {"text": "Section 3 describes in detail our proposal.", "labels": [], "entities": []}, {"text": "Results are discussed in section 4.", "labels": [], "entities": []}, {"text": "Conclusions and further work is finally included in section 5.", "labels": [], "entities": []}], "datasetContent": [{"text": "Before the submission we have performed a set of experiments in order to choose the Machine Learning algorithms and the training sets to apply in the final submission.: System Architecture.", "labels": [], "entities": []}, {"text": "We used the WEKA 3 ML platform) to perform the experiments.", "labels": [], "entities": [{"text": "WEKA 3 ML platform", "start_pos": 12, "end_pos": 30, "type": "DATASET", "confidence": 0.8627444207668304}]}, {"text": "We tested 9 different ML algorithms: AdaBoostM1, Bayes Networks, Logistic Regression, MultiBoostAB, Naive Bayes, RBF Network, LogitBoost (Simple Logistic in WEKA), Support Vector Machines (SMO in WEKA), and Voted Perceptron.", "labels": [], "entities": []}, {"text": "We used the previous corpora of the RTE Challenge (RTE-1 and RTE-2) and the RTE-3 development test.", "labels": [], "entities": [{"text": "RTE Challenge", "start_pos": 36, "end_pos": 49, "type": "DATASET", "confidence": 0.8622306883335114}, {"text": "RTE-1", "start_pos": 51, "end_pos": 56, "type": "DATASET", "confidence": 0.6609085202217102}, {"text": "RTE-2", "start_pos": 61, "end_pos": 66, "type": "DATASET", "confidence": 0.6926249265670776}, {"text": "RTE-3 development test", "start_pos": 76, "end_pos": 98, "type": "DATASET", "confidence": 0.8896936774253845}]}, {"text": "A filtering process has been applied removing pairs with more than two sentences in the text or hypothesis, resulting a total of 3335 Textual Entailment (TE) pairs.", "labels": [], "entities": []}, {"text": "The results over 10-fold-Cross-Validation using a data set composed by RTE-1, RTE-2, and RTE-3 development set are shown in.", "labels": [], "entities": [{"text": "RTE-1", "start_pos": 71, "end_pos": 76, "type": "DATASET", "confidence": 0.9276911020278931}, {"text": "RTE-2", "start_pos": 78, "end_pos": 83, "type": "DATASET", "confidence": 0.8316909670829773}, {"text": "RTE-3 development set", "start_pos": 89, "end_pos": 110, "type": "DATASET", "confidence": 0.9502997795740763}]}, {"text": "The results shown that AdaBoost, LogitBoost, and SVM obtain the best results.", "labels": [], "entities": [{"text": "AdaBoost", "start_pos": 23, "end_pos": 31, "type": "DATASET", "confidence": 0.9014021754264832}]}, {"text": "Then we selected AdaBoost and SVM to perform the classification of the RTE-3 test set.", "labels": [], "entities": [{"text": "AdaBoost", "start_pos": 17, "end_pos": 25, "type": "DATASET", "confidence": 0.9618490934371948}, {"text": "SVM", "start_pos": 30, "end_pos": 33, "type": "DATASET", "confidence": 0.8442310094833374}, {"text": "RTE-3 test set", "start_pos": 71, "end_pos": 85, "type": "DATASET", "confidence": 0.8905302882194519}]}, {"text": "The SVM algorithm tries to compute the hyperplane that best separates the set of training examples (the hyperplane with maximum margin): Results over 10-fold-Cross-Validation using a filtered data set composed by RTE-1, RTE-2, and RTE-3 (a total of 3335 entailment pairs).", "labels": [], "entities": [{"text": "RTE-3", "start_pos": 231, "end_pos": 236, "type": "DATASET", "confidence": 0.8152419924736023}]}, {"text": "bines a set of weak classifiers into a strong one using lineal combination.", "labels": [], "entities": []}, {"text": "The idea is combining many moderately accurate rules into a highly accurate prediction rule.", "labels": [], "entities": []}, {"text": "A weak learning algorithm is used to find the weak rules.", "labels": [], "entities": []}, {"text": "We designed two experiments in order to decide the best training set to apply in the RTE-3 challenge.", "labels": [], "entities": [{"text": "RTE-3 challenge", "start_pos": 85, "end_pos": 100, "type": "TASK", "confidence": 0.5626569986343384}]}, {"text": "We performed an experiment using RTE-1 and RTE-2 data sets as a training set and the RTE-3 development set filtered (541 TE pairs) as a test set.", "labels": [], "entities": [{"text": "RTE-2 data sets", "start_pos": 43, "end_pos": 58, "type": "DATASET", "confidence": 0.9007695913314819}, {"text": "RTE-3 development set filtered", "start_pos": 85, "end_pos": 115, "type": "DATASET", "confidence": 0.8783509731292725}]}, {"text": "In this experiment AdaBoost and SVM obtained accuracies of 0.6672 and 0.6396 respectively (see results in Table 3.", "labels": [], "entities": [{"text": "AdaBoost", "start_pos": 19, "end_pos": 27, "type": "DATASET", "confidence": 0.8927805423736572}]}, {"text": "We performed the same experiment joining the Answer Validation Exercise 4 (AVE) 2006 English data set) and the Microsoft Research Paraphrase Corpus 5 (MSRPC) () to the previous corpora (RTE-1 and RTE-2) resulting a total of 8585 entailment pairs filtering pairs with a text or a hypothesis with more than 1 sentence.", "labels": [], "entities": [{"text": "Answer Validation Exercise 4 (AVE) 2006 English data set", "start_pos": 45, "end_pos": 101, "type": "TASK", "confidence": 0.8748265992511403}, {"text": "Microsoft Research Paraphrase Corpus 5 (MSRPC)", "start_pos": 111, "end_pos": 157, "type": "DATASET", "confidence": 0.7937315925955772}]}, {"text": "In our approach we considered that paraphrases were bidirectional entailments.", "labels": [], "entities": []}, {"text": "The paraphrases of the MSRPC have been used as textual entailments in only one direction: the first sentence in the paraphrase has been considered the hypothesis and the second one has been considered the text.", "labels": [], "entities": [{"text": "MSRPC", "start_pos": 23, "end_pos": 28, "type": "DATASET", "confidence": 0.8354604840278625}]}, {"text": "Using the second corpus for training and the RTE-3 development set as test set resulted in a notable degradation of accuracy (see).", "labels": [], "entities": [{"text": "RTE-3 development set", "start_pos": 45, "end_pos": 66, "type": "DATASET", "confidence": 0.9340145389238993}, {"text": "accuracy", "start_pos": 116, "end_pos": 124, "type": "METRIC", "confidence": 0.9992973804473877}]}, {"text": "Finally, we performed a set of experiments to detect the contribution of the different features used for Machine Learning.", "labels": [], "entities": [{"text": "Machine Learning", "start_pos": 105, "end_pos": 121, "type": "TASK", "confidence": 0.892827570438385}]}, {"text": "These experiments revealed that the three most relevant features were: Strict overlapping of unary predicates, Semantic content of Hypothesis, and Loose overlapping of unary predicates.", "labels": [], "entities": [{"text": "Loose overlapping of unary predicates", "start_pos": 147, "end_pos": 184, "type": "TASK", "confidence": 0.763959777355194}]}], "tableCaptions": [{"text": " Table 1: Features used for classification with Machine Learning algorithms.", "labels": [], "entities": []}, {"text": " Table 2: Results over 10-fold-Cross-Validation us- ing a filtered data set composed by RTE-1, RTE-2,  and RTE-3 (a total of 3335 entailment pairs).", "labels": [], "entities": [{"text": "RTE-1", "start_pos": 88, "end_pos": 93, "type": "DATASET", "confidence": 0.892389714717865}, {"text": "RTE-2", "start_pos": 95, "end_pos": 100, "type": "DATASET", "confidence": 0.8017373085021973}, {"text": "RTE-3", "start_pos": 107, "end_pos": 112, "type": "DATASET", "confidence": 0.8908942937850952}]}, {"text": " Table 3: Results over the RTE-3 development set  filtered (541 TE pairs) using as training set corpus A  (RTE-1 and RTE-2) and corpus B (RTE-1, RTE-2,  MSRPC, and AVE2006 English)", "labels": [], "entities": [{"text": "RTE-3 development set", "start_pos": 27, "end_pos": 48, "type": "DATASET", "confidence": 0.7443938851356506}]}, {"text": " Table 4: RTE-3 official results.", "labels": [], "entities": [{"text": "RTE-3", "start_pos": 10, "end_pos": 15, "type": "METRIC", "confidence": 0.8654724359512329}]}]}