{"title": [{"text": "Viterbi Based Alignment between Text Images and their Transcripts *", "labels": [], "entities": [{"text": "Viterbi Based Alignment between Text Images and their Transcripts", "start_pos": 0, "end_pos": 65, "type": "TASK", "confidence": 0.8319424721929762}]}], "abstractContent": [{"text": "An alignment method based on the Viterbi algorithm is proposed to find mappings between word images of a given handwritten document and their respective (ASCII) words on its transcription.", "labels": [], "entities": []}, {"text": "The approach takes advantage of the underlying segmen-tation made by Viterbi decoding in handwritten text recognition based on Hidden Markov Models (HMMs).", "labels": [], "entities": [{"text": "handwritten text recognition", "start_pos": 89, "end_pos": 117, "type": "TASK", "confidence": 0.6345548729101816}]}, {"text": "Two HMMs modelling schemes are evaluated: one using 78-HMMs (one HMM per character class) and other using a unique HMM to model all the characters and another to model blank spaces.", "labels": [], "entities": [{"text": "HMMs modelling", "start_pos": 4, "end_pos": 18, "type": "TASK", "confidence": 0.8411640822887421}]}, {"text": "According to various metrics used to measure the quality of the alignments, encouraging results are obtained.", "labels": [], "entities": []}], "introductionContent": [{"text": "Recently, many on-line digital libraries have been publishing large quantities of digitized ancient handwritten documents, which allows the general public to access this kind of cultural heritage resources.", "labels": [], "entities": []}, {"text": "This is anew, comfortable way of consulting and querying this material.", "labels": [], "entities": []}, {"text": "The Biblioteca Valenciana Digital (BiValDi) is an example of one such digital library, which provides an interesting collection of handwritten documents.", "labels": [], "entities": []}, {"text": "Several of these handwritten documents include both, the handwritten material and its proper transcription (in ASCII format).", "labels": [], "entities": []}, {"text": "This fact has motivated the development of methodologies to align these documents and their transcripts; i.e. to generate a mapping between each word image on a document page with its respective ASCII word on its transcript.", "labels": [], "entities": []}, {"text": "This word byword alignment would allow users to easily find the place of a word in the manuscript when reading the corresponding transcript.", "labels": [], "entities": [{"text": "word byword alignment", "start_pos": 5, "end_pos": 26, "type": "TASK", "confidence": 0.608964870373408}]}, {"text": "For example, one could display both the handwritten page and the transcript and whenever the mouse is held over a word in the transcript, the corresponding word in the handwritten image would be outlined using a box.", "labels": [], "entities": []}, {"text": "Ina similar way, whenever the mouse is held over a word in the handwritten image, the corresponding word in the transcript would be highlighted (see).", "labels": [], "entities": []}, {"text": "This kind of alignment can help paleography experts to quickly locate image text while reading a transcript, with useful applications to editing, indexing, etc.", "labels": [], "entities": []}, {"text": "In the opposite direction, the alignment can also be useful for people trying to read the image text directly, when arriving to complex or damaged parts of the document.", "labels": [], "entities": []}, {"text": "Creating such alignments is challenging since the transcript is an ASCII text file while the manuscript page is an image.", "labels": [], "entities": []}, {"text": "Some recent works address this problem by relying on a previous explicit imageprocessing based word pre-segmentation of the page image, before attempting the transcription alignments.", "labels": [], "entities": []}, {"text": "For example, in), the set of previously segmented word images and their corresponding transcriptions are transformed into two different times series, which are aligned: Screen-shot of the alignment prototype interface displaying an outlined word (using a box) in the manuscript (left) and the corresponding highlighted word in the transcript (right).", "labels": [], "entities": []}, {"text": "using dynamic time warping (DTW).", "labels": [], "entities": []}, {"text": "In this same direction,), in addition to the word pre-segmentation, attempt a (rough) recognition of the word images.", "labels": [], "entities": []}, {"text": "The resulting word string is then aligned with the transcription using dynamic programming.", "labels": [], "entities": []}, {"text": "The alignment method presented here (henceforward called Viterbi alignment), relies on the Viterbi decoding approach to handwritten text recognition (HTR) based on Hidden Markov Models (HMMs) ().", "labels": [], "entities": [{"text": "handwritten text recognition (HTR)", "start_pos": 120, "end_pos": 154, "type": "TASK", "confidence": 0.7857922414938608}]}, {"text": "These techniques are based on methods originally introduced for speech recognition.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 64, "end_pos": 82, "type": "TASK", "confidence": 0.8181649446487427}]}, {"text": "In such HTR systems, the alignment is actually a byproduct of the proper recognition process, i.e. an implicit segmentation of each text image line is obtained where each segment successively corresponds to one recognized word.", "labels": [], "entities": []}, {"text": "In our case, word recognition is not actually needed, as we do already have the correct transcription.", "labels": [], "entities": [{"text": "word recognition", "start_pos": 13, "end_pos": 29, "type": "TASK", "confidence": 0.9243508279323578}]}, {"text": "Therefore, to obtain the segmentations for the given word sequences, the socalled \"forced-recognition\" approach is employed (see section 2.2).", "labels": [], "entities": []}, {"text": "This idea has been previously explored in ().", "labels": [], "entities": []}, {"text": "Alignments can be computed line byline in cases where the beginning and end positions of lines are known or, in a more general case, for whole pages.", "labels": [], "entities": [{"text": "Alignments", "start_pos": 0, "end_pos": 10, "type": "TASK", "confidence": 0.9613565802574158}]}, {"text": "We show line-by-line results on a set of 53 pages from the \"Cristo-Salvador\" handwritten document (see section 5.2).", "labels": [], "entities": [{"text": "Cristo-Salvador\" handwritten document", "start_pos": 60, "end_pos": 97, "type": "DATASET", "confidence": 0.7258337587118149}]}, {"text": "To evaluate the quality of the obtained alignments, two metrics were used which give information at different alignment levels: one measures the accuracy of alignment mark placements and the other measures the amount of erroneous as- signments produced between word images and transcriptions (see section 4).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 145, "end_pos": 153, "type": "METRIC", "confidence": 0.998524010181427}]}, {"text": "The remainder of this paper is organized as follows.", "labels": [], "entities": []}, {"text": "First, the alignment framework is introduced and formalized in section 2.", "labels": [], "entities": [{"text": "alignment", "start_pos": 11, "end_pos": 20, "type": "TASK", "confidence": 0.9801399111747742}]}, {"text": "Then, an implemented prototype is described in section 3.", "labels": [], "entities": []}, {"text": "The alignment evaluation metrics are presented in section 4.", "labels": [], "entities": [{"text": "alignment evaluation", "start_pos": 4, "end_pos": 24, "type": "TASK", "confidence": 0.9576717615127563}]}, {"text": "The experiments and results are commented in section 5.", "labels": [], "entities": []}, {"text": "Finally, some conclusions are drawn in section 6.", "labels": [], "entities": []}], "datasetContent": [{"text": "Two kinds of measures have been adopted to evaluate the quality of alignments.", "labels": [], "entities": []}, {"text": "On the one hand, the average value and standard deviation (henceforward called MEAN-STD) of the absolute differences between the system-proposed word alignment marks and their corresponding (correct) references.", "labels": [], "entities": [{"text": "standard deviation", "start_pos": 39, "end_pos": 57, "type": "METRIC", "confidence": 0.9381816685199738}, {"text": "MEAN-STD", "start_pos": 79, "end_pos": 87, "type": "METRIC", "confidence": 0.9797006249427795}]}, {"text": "This gives us an idea of the geometrical accuracy of the alignments obtained.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 41, "end_pos": 49, "type": "METRIC", "confidence": 0.9878978133201599}]}, {"text": "On the other hand, the alignment error rate (AER), which measures the amount of erroneous assignments produced between word images and transcriptions.", "labels": [], "entities": [{"text": "alignment error rate (AER)", "start_pos": 23, "end_pos": 49, "type": "METRIC", "confidence": 0.9121442834536234}]}, {"text": "Given a reference mark sequence r = r 0 , r 1 , . .", "labels": [], "entities": []}, {"text": ", r n along with an associated tokens sequence w = w 1 , w 2 , . .", "labels": [], "entities": []}, {"text": ", w n , and a segmentation marks sequence b = b 0 , b 1 , . .", "labels": [], "entities": []}, {"text": ", b n (with r 0 = b 0 \u2227 r n = b n ), we define the MEAN-STD and AER metrics as follows: MEAN-STD: The average value and standard deviation of absolute differences between reference and proposed alignment marks, are given by: where: Example of AER computation.", "labels": [], "entities": [{"text": "MEAN-STD", "start_pos": 51, "end_pos": 59, "type": "METRIC", "confidence": 0.6298460960388184}, {"text": "AER", "start_pos": 64, "end_pos": 67, "type": "METRIC", "confidence": 0.9625200629234314}, {"text": "MEAN-STD", "start_pos": 88, "end_pos": 96, "type": "METRIC", "confidence": 0.7974345684051514}]}, {"text": "In this case N = 4 (only no word-space are considered: w 1 , w 3 , w 5 , w 7 ) and w 5 is erroneously aligned with the subsequence AER: Defined as: where b stands for the blank-space token, N < n is the number of real words (i.e., tokens which are not b, and m j = (r j\u22121 + r j )/2.", "labels": [], "entities": [{"text": "AER", "start_pos": 131, "end_pos": 134, "type": "METRIC", "confidence": 0.9767345786094666}]}, {"text": "A good alignment will have a \u00b5 value close to 0 and small \u03c3.", "labels": [], "entities": [{"text": "\u00b5", "start_pos": 29, "end_pos": 30, "type": "METRIC", "confidence": 0.9500136375427246}]}, {"text": "Thus, MEAN-STD gives us an idea of how accurate are the automatically computed alignment marks.", "labels": [], "entities": [{"text": "MEAN-STD", "start_pos": 6, "end_pos": 14, "type": "METRIC", "confidence": 0.6863749623298645}]}, {"text": "On the other hand, AER assesses alignments at a higher level; that is, it measures mismatches between word-images and ASCII transcriptions (tokens), excluding word-space tokens.", "labels": [], "entities": [{"text": "AER", "start_pos": 19, "end_pos": 22, "type": "METRIC", "confidence": 0.953624963760376}]}, {"text": "This is illustrated in, where the AER would be 25%.", "labels": [], "entities": [{"text": "AER", "start_pos": 34, "end_pos": 37, "type": "METRIC", "confidence": 0.9997134804725647}]}, {"text": "In order to test the effectiveness of the presented alignment approach, different experiments were carried out.", "labels": [], "entities": []}, {"text": "The corpus used, as well as the experiments carried out and the obtained results, are reported in the following subsections.", "labels": [], "entities": []}, {"text": "As mentioned above, experiments were carried out computing the alignments line-by-line.", "labels": [], "entities": [{"text": "alignments line-by-line", "start_pos": 63, "end_pos": 86, "type": "TASK", "confidence": 0.8652679026126862}]}, {"text": "Two different HMM modeling schemes were employed.", "labels": [], "entities": [{"text": "HMM modeling", "start_pos": 14, "end_pos": 26, "type": "TASK", "confidence": 0.8563951849937439}]}, {"text": "The first one models each of the 78 character classes using a different HMM per class.", "labels": [], "entities": []}, {"text": "The second scheme uses 2 HMMs, one to model all the 77 no-blank character classes, and the other to model only the blank \"character\" class.", "labels": [], "entities": []}, {"text": "The HMM topology was identical for all HMMs in both schemes: left-toright with 6 states and 64 Gaussian mixture com-: Examples page images of the corpus \"Cristo-Salvador\", which show backgrounds of big variations and uneven illumination, spots due to the humidity, marks resulting from the ink that goes through the paper (called bleed-through), etc.", "labels": [], "entities": []}, {"text": "As has been explained in section 4, two different measures have been adopted to evaluate the quality of the obtained alignments: the MEAN-STD and the AER.", "labels": [], "entities": [{"text": "MEAN-STD", "start_pos": 133, "end_pos": 141, "type": "METRIC", "confidence": 0.972148597240448}, {"text": "AER", "start_pos": 150, "end_pos": 153, "type": "METRIC", "confidence": 0.996982753276825}]}, {"text": "From the results we can see that using the 78 HMMs scheme the best AER is obtained (7.20%).", "labels": [], "entities": [{"text": "AER", "start_pos": 67, "end_pos": 70, "type": "METRIC", "confidence": 0.9997156262397766}]}, {"text": "Moreover, the relative low values of \u00b5 and \u03c3 (in millimeters) show that the quality of the obtained alignments (marks) is quite acceptable, that is they are very close to their respective references.", "labels": [], "entities": []}, {"text": "This is illustrated on the left histogram of.", "labels": [], "entities": []}, {"text": "The two typical alignment errors are known as over-segmentation and under-segmentation respectively.", "labels": [], "entities": []}, {"text": "The over-segmentation error is when one word image is separated into two or more fragments.", "labels": [], "entities": []}, {"text": "The under-segmentation error occurs when two or more images are grouped together and returned as one word.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1 summarized the basic statistics of this cor- pus and its reference pages.", "labels": [], "entities": []}, {"text": " Table 2: Alignment evaluation results 78-HMMs  and 2-HMMs.", "labels": [], "entities": [{"text": "Alignment", "start_pos": 10, "end_pos": 19, "type": "TASK", "confidence": 0.7184686064720154}]}]}