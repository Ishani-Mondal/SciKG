{"title": [{"text": "Generation of Repeated References to Discourse Entities", "labels": [], "entities": [{"text": "Generation of Repeated References to Discourse Entities", "start_pos": 0, "end_pos": 55, "type": "TASK", "confidence": 0.8729787383760724}]}], "abstractContent": [{"text": "Generation of Referring Expressions is a thriving subfield of Natural Language Generation which has traditionally focused on the task of selecting a set of attributes that unambiguously identify a given ref-erent.", "labels": [], "entities": [{"text": "Generation of Referring Expressions", "start_pos": 0, "end_pos": 35, "type": "TASK", "confidence": 0.7926277220249176}, {"text": "Natural Language Generation", "start_pos": 62, "end_pos": 89, "type": "TASK", "confidence": 0.6784001986185709}]}, {"text": "In this paper, we address the complementary problem of generating repeated, potentially different referential expressions that refer to the same entity in the context of apiece of discourse longer than a sentence.", "labels": [], "entities": []}, {"text": "We describe a corpus of short ency-clopaedic texts we have compiled and annotated for reference to the main subject of the text, and report results for our experiments in which we set human subjects and automatic methods the task of selecting a referential expression from a wide range of choices in a full-text context.", "labels": [], "entities": []}, {"text": "We find that our human subjects agree on choice of expression to a considerable degree, with three identical expressions selected in 50% of cases.", "labels": [], "entities": []}, {"text": "We tested automatic selection strategies based on most frequent choice heuris-tics, involving different combinations of information about syntactic MSR type and domain type.", "labels": [], "entities": []}, {"text": "We find that more information generally produces better results, achieving a best overall test set accuracy of 53.9% when both syntactic MSR type and domain type are known.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 99, "end_pos": 107, "type": "METRIC", "confidence": 0.9680003523826599}]}], "introductionContent": [{"text": "Generation of Referring Expressions (GRE) is one of the most lively and thriving subfields of Natural Language Generation (NLG).", "labels": [], "entities": [{"text": "Generation of Referring Expressions (GRE)", "start_pos": 0, "end_pos": 41, "type": "TASK", "confidence": 0.6998392598969596}, {"text": "Natural Language Generation (NLG)", "start_pos": 94, "end_pos": 127, "type": "TASK", "confidence": 0.8148459990819296}]}, {"text": "GRE has traditionally addressed the following question:iven a symbol corresponding to an intended referent, how do we workout the semantic content of a referring expression that uniquely identifies the entity in question?", "labels": [], "entities": [{"text": "GRE", "start_pos": 0, "end_pos": 3, "type": "TASK", "confidence": 0.4880307912826538}]}, {"text": "This view of GRE is mainly concerned with ruling out 'distractors' to achieve unique identification of the target referent.", "labels": [], "entities": [{"text": "GRE", "start_pos": 13, "end_pos": 16, "type": "TASK", "confidence": 0.9437868595123291}]}, {"text": "Our research is concerned with a complementary question: given an intended referent and a discourse context, how do we generate appropriate referential expressions (REs) to refer to the referent at different points in the discourse?", "labels": [], "entities": []}, {"text": "While existing GRE research has taken discourse context into account to some extent (see Section 2), the question why people choose different REs in different contexts has not really been addressed: Not only do different people use different referring expressions for the same object, but the same person may use different expressions for the same object on different occasions.", "labels": [], "entities": []}, {"text": "Although this may seem like a rather unsurprising observation, it has never, as far as we are aware, been taken into account in the development of any algorithm for generation of referring expressions.", "labels": [], "entities": []}, {"text": "( Selection of a particular RE in a particular context is likely to be affected by a range of factors in addition to discourse-familiarity and unique identification.", "labels": [], "entities": []}, {"text": "In our research we ultimately aim to (i) investigate the factors that influence choice of RE in context, (ii) determine what information is needed fora GRE module to be able to generate appropriate REs in context, and (iii) develop reliable methods for automatically generating REs in context.", "labels": [], "entities": []}, {"text": "Our basic approach is to annotate occurrences of MSR in naturally occurring texts, analyse the texts in various ways, and obtain multiple, human-produced alternatives to the REs in the texts.", "labels": [], "entities": [{"text": "MSR in naturally occurring texts", "start_pos": 49, "end_pos": 81, "type": "TASK", "confidence": 0.7786930561065674}]}, {"text": "The results are used to inform the design of automatic methods for RE selection.", "labels": [], "entities": [{"text": "RE selection", "start_pos": 67, "end_pos": 79, "type": "TASK", "confidence": 0.9732564389705658}]}, {"text": "The success of such methods can in turn be evaluated in terms of similarity of output REs with the human-produced In our current work we are focusing on a text type that has a single, easily identifiable main subject for which we can therefore expect to find a range of different REs: encyclopaedic entries.", "labels": [], "entities": []}, {"text": "In this paper, we describe a corpus of such texts we have compiled and annotated (Section 3), and report first insights from our analysis of the corpus data (Section 4).", "labels": [], "entities": []}, {"text": "We further report the results of an experiment where subjects selected REs in context (Section 5), and establish baseline results for automatic methods of selection (Section 6).", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: (Dis)agreement among subjects in Choos- ing MSR Experiment.", "labels": [], "entities": [{"text": "agreement", "start_pos": 15, "end_pos": 24, "type": "METRIC", "confidence": 0.7825199961662292}, {"text": "Choos- ing MSR Experiment", "start_pos": 43, "end_pos": 68, "type": "TASK", "confidence": 0.6039536833763123}]}, {"text": " Table 2: (Dis)agreement between subjects in  Choosing MSR Experiment and corpus texts.", "labels": [], "entities": []}, {"text": " Table 3: Training set frequencies of different RE types, computed for entire training set, subdomains and  syntactic MSR types; d = length of default name.", "labels": [], "entities": []}]}