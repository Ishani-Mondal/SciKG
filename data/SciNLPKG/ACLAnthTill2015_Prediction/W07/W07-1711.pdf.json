{"title": [{"text": "Multilingual Word Sense Discrimination: A Comparative Cross-Linguistic Study", "labels": [], "entities": [{"text": "Multilingual Word Sense Discrimination", "start_pos": 0, "end_pos": 38, "type": "TASK", "confidence": 0.7698562443256378}]}], "abstractContent": [{"text": "We describe a study that evaluates an approach to Word Sense Discrimination on three languages with different linguistic structures, English, Hebrew, and Russian.", "labels": [], "entities": [{"text": "Word Sense Discrimination", "start_pos": 50, "end_pos": 75, "type": "TASK", "confidence": 0.8001168966293335}]}, {"text": "The goal of the study is to determine whether there are significant performance differences for the languages and to identify language-specific problems.", "labels": [], "entities": []}, {"text": "The algorithm is tested on semantically ambiguous words using data from Wikipedia, an online encyclopedia.", "labels": [], "entities": []}, {"text": "We evaluate the induced clusters against sense clusters created manually.", "labels": [], "entities": []}, {"text": "The results suggest a correlation between the algorithm's performance and morphological complexity of the language.", "labels": [], "entities": []}, {"text": "In particular, we obtain FScores of 0.68 , 0.66 and 0.61 for English, Hebrew, and Russian, respectively.", "labels": [], "entities": [{"text": "FScores", "start_pos": 25, "end_pos": 32, "type": "METRIC", "confidence": 0.9640626311302185}]}, {"text": "Moreover, we perform an experiment on Russian, in which the context terms are lem-matized.", "labels": [], "entities": []}, {"text": "The lemma-based approach significantly improves the results over the word-based approach, by increasing the FScore by 16%.", "labels": [], "entities": [{"text": "FScore", "start_pos": 108, "end_pos": 114, "type": "METRIC", "confidence": 0.9314402937889099}]}, {"text": "This result demonstrates the importance of morphological analysis for the task for morphologically rich languages like Rus-sian.", "labels": [], "entities": [{"text": "morphological analysis", "start_pos": 43, "end_pos": 65, "type": "TASK", "confidence": 0.7357642948627472}]}], "introductionContent": [{"text": "Ambiguity is pervasive in natural languages and creates an additional challenge for Natural Language applications.", "labels": [], "entities": [{"text": "Ambiguity", "start_pos": 0, "end_pos": 9, "type": "METRIC", "confidence": 0.6635879874229431}]}, {"text": "Determining the sense of an ambiguous word in a given context may benefit many NLP tasks, such as Machine Translation, Question Answering, or Text-to-Speech synthesis.", "labels": [], "entities": [{"text": "Machine Translation", "start_pos": 98, "end_pos": 117, "type": "TASK", "confidence": 0.8558991849422455}, {"text": "Question Answering", "start_pos": 119, "end_pos": 137, "type": "TASK", "confidence": 0.8855085372924805}, {"text": "Text-to-Speech synthesis", "start_pos": 142, "end_pos": 166, "type": "TASK", "confidence": 0.7869770526885986}]}, {"text": "The Word Sense Discrimination (WSD) or Word Sense Induction task consists of grouping together the occurrences of a semantically ambiguous term according to its senses.", "labels": [], "entities": [{"text": "Word Sense Discrimination (WSD) or Word Sense Induction task", "start_pos": 4, "end_pos": 64, "type": "TASK", "confidence": 0.7003756842829965}]}, {"text": "Word Sense Discrimination is similar to Word Sense Disambiguation, but allows fora more unsupervised approach to the problem, since it does not require a pre-defined set of senses.", "labels": [], "entities": [{"text": "Word Sense Discrimination", "start_pos": 0, "end_pos": 25, "type": "TASK", "confidence": 0.7378054261207581}, {"text": "Word Sense Disambiguation", "start_pos": 40, "end_pos": 65, "type": "TASK", "confidence": 0.6953637798627218}]}, {"text": "This is important, given the number of potentially ambiguous words in a language.", "labels": [], "entities": []}, {"text": "Moreover, labeling an occurrence with its sense is not always necessary.", "labels": [], "entities": []}, {"text": "For example, in Information Retrieval WSD would be useful for the identification of documents relevant to a query containing an ambiguous term.", "labels": [], "entities": [{"text": "Information Retrieval WSD", "start_pos": 16, "end_pos": 41, "type": "TASK", "confidence": 0.8087394038836161}, {"text": "identification of documents relevant to a query containing an ambiguous term", "start_pos": 66, "end_pos": 142, "type": "TASK", "confidence": 0.7227435111999512}]}, {"text": "Different approaches to WSD have been proposed, but the evaluation is often conducted using a single language, so it is difficult to predict performance on another language.", "labels": [], "entities": [{"text": "WSD", "start_pos": 24, "end_pos": 27, "type": "TASK", "confidence": 0.989879846572876}]}, {"text": "To the best of our knowledge, there has not been a systematic comparative analysis of WSD systems on different languages.", "labels": [], "entities": [{"text": "WSD", "start_pos": 86, "end_pos": 89, "type": "TASK", "confidence": 0.9726428389549255}]}, {"text": "Yet, it is interesting to see whether there are significant differences in performance when a method is applied to several languages that have different linguistic structures.", "labels": [], "entities": []}, {"text": "Identifying the reasons for performance differences might suggest what features are useful for the task.", "labels": [], "entities": []}, {"text": "The present project adopts an approach to WSD that is based on similarity measure between context terms of an ambiguous word.", "labels": [], "entities": [{"text": "WSD", "start_pos": 42, "end_pos": 45, "type": "TASK", "confidence": 0.9542699456214905}]}, {"text": "We compare the performance of an algorithm for WSD on English, Hebrew, and Russian, using lexically ambiguous words and corpora of similar sizes.", "labels": [], "entities": [{"text": "WSD", "start_pos": 47, "end_pos": 50, "type": "TASK", "confidence": 0.9311624765396118}]}, {"text": "We believe that testing on the above languages might give an idea about how accuracy of an algorithm for WSD is affected by language choice.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 76, "end_pos": 84, "type": "METRIC", "confidence": 0.9985910058021545}, {"text": "WSD", "start_pos": 105, "end_pos": 108, "type": "TASK", "confidence": 0.9441937208175659}]}, {"text": "Russian is a member of the Slavic language group and is morphologically rich.", "labels": [], "entities": []}, {"text": "Verbs, nouns, and adjectives are characterized by a developed inflectional system, which results in a large number of wordforms.", "labels": [], "entities": []}, {"text": "Hebrew is a Semitic language, and is complex in a different way.", "labels": [], "entities": []}, {"text": "In addition to the root-pattern morphology that affects the word stem, it also has a complex verb declination system.", "labels": [], "entities": []}, {"text": "Moreover, function words, such as prepositions and determiners, cliticize, thereby increasing the number of wordforms.", "labels": [], "entities": []}, {"text": "Lastly, cliticization, coupled with the absence of short vowels in text, introduces an additional level of ambiguity for Hebrew.", "labels": [], "entities": []}, {"text": "There are two main findings to this study.", "labels": [], "entities": []}, {"text": "First, we show that the morphological complexity of the language affects the performance of the algorithm for WSD.", "labels": [], "entities": [{"text": "WSD", "start_pos": 110, "end_pos": 113, "type": "TASK", "confidence": 0.8697234392166138}]}, {"text": "Second, the lemma-based approach to Russian WSD significantly improves the results over the word-based approach.", "labels": [], "entities": [{"text": "WSD", "start_pos": 44, "end_pos": 47, "type": "TASK", "confidence": 0.570405900478363}]}, {"text": "The rest of the paper is structured as follows: first, we describe previous work that is related to the project.", "labels": [], "entities": []}, {"text": "Section 3 provides details about the algorithm for WSD that we use.", "labels": [], "entities": [{"text": "WSD", "start_pos": 51, "end_pos": 54, "type": "TASK", "confidence": 0.856168270111084}]}, {"text": "We then describe the experiments and the evaluation methodology in Sections 4 and 5, respectively.", "labels": [], "entities": []}, {"text": "We conclude with a discussion of the results and directions for future work.", "labels": [], "entities": []}], "datasetContent": [{"text": "The algorithm is evaluated on 9 ambiguous words with two-sense distinctions.", "labels": [], "entities": []}, {"text": "We select words that (i) have the same two-sense distinction in all three languages or (ii) are ambiguous in one of the languages, but each of their senses corresponds to an unambiguous translation in the other two languages.", "labels": [], "entities": []}, {"text": "In the latter case, the translations are merged together to create an artificially ambiguous word.", "labels": [], "entities": []}, {"text": "We believe that this selection approach allows fora collection of a comparable set of ambiguous words for the three languages.", "labels": [], "entities": []}, {"text": "An example of an ambiguous word is the English word table, that corresponds to two gross sense distinctions (tabular array, and apiece of furniture).", "labels": [], "entities": []}, {"text": "This word has two translations into Russian and Hebrew, that correspond to the two senses.", "labels": [], "entities": []}, {"text": "The selected words are presented in.", "labels": [], "entities": []}, {"text": "The words display different types of ambiguity.", "labels": [], "entities": []}, {"text": "In particular, disambiguating the Hebrew word gishah (access; approach) or the Russian word mir (peace; world) would be useful in Machine Translation, while determining the sense of a word like language would benefit an Information Retrieval system.", "labels": [], "entities": [{"text": "Machine Translation", "start_pos": 130, "end_pos": 149, "type": "TASK", "confidence": 0.822063684463501}, {"text": "Information Retrieval", "start_pos": 220, "end_pos": 241, "type": "TASK", "confidence": 0.7585753500461578}]}, {"text": "It should also be noted that several words possess additional senses, which were ignored because they rarely occurred in the corpus.", "labels": [], "entities": []}, {"text": "For example, the Russian word yazyk (language) also has the meaning of tongue (body part).", "labels": [], "entities": []}, {"text": "number of clusters exceeds the number of senses of the ambiguous word in the test data.", "labels": [], "entities": []}, {"text": "The corpus for each language consists of 15M word tokens, and for the same ambiguous word the same number of training examples is selected from each language.", "labels": [], "entities": []}, {"text": "For each ambiguous word, a set of 100-150 examples together with 50 words of context is selected from the section of the corpus not used for training.", "labels": [], "entities": []}, {"text": "These examples are manually annotated for senses and used as the test set for each language.", "labels": [], "entities": []}, {"text": "The evaluation is conducted by comparing the induced sentence clusters to clusters created manually.", "labels": [], "entities": []}, {"text": "We use three evaluation measures : cluster purity, entropy, and FScore.", "labels": [], "entities": [{"text": "FScore", "start_pos": 64, "end_pos": 70, "type": "METRIC", "confidence": 0.9926300048828125}]}, {"text": "For a cluster Cr of size qr , where the size is the number of examples in that cluster, the dominating sense Si in that cluster is selected and cluster purity is computed as follows: where n i r is the number of examples in cluster Cr with sense Si . For an ambiguous word w, cluster purity P(w) is the weighted average of purities of the clusters for that word.", "labels": [], "entities": [{"text": "cluster purity", "start_pos": 144, "end_pos": 158, "type": "METRIC", "confidence": 0.8505173623561859}, {"text": "cluster purity P(w)", "start_pos": 276, "end_pos": 295, "type": "METRIC", "confidence": 0.8445242593685786}]}, {"text": "Higher cluster purity score corresponds to a better clustering outcome.", "labels": [], "entities": [{"text": "cluster purity score", "start_pos": 7, "end_pos": 27, "type": "METRIC", "confidence": 0.8647820949554443}]}, {"text": "Entropy and FScore measures are described in detail in.", "labels": [], "entities": [{"text": "Entropy", "start_pos": 0, "end_pos": 7, "type": "METRIC", "confidence": 0.8957821130752563}, {"text": "FScore", "start_pos": 12, "end_pos": 18, "type": "METRIC", "confidence": 0.9907931685447693}]}, {"text": "Entropy indicates how distinct senses are distributed between the two clusters.", "labels": [], "entities": [{"text": "Entropy", "start_pos": 0, "end_pos": 7, "type": "METRIC", "confidence": 0.9076572060585022}]}, {"text": "The perfect distribution is the assignment of all examples with sense 1 to one cluster and all examples with sense 2 to the other cluster.", "labels": [], "entities": []}, {"text": "In such case, the entropy is 0.", "labels": [], "entities": [{"text": "entropy", "start_pos": 18, "end_pos": 25, "type": "METRIC", "confidence": 0.9858296513557434}]}, {"text": "In general, a lower value indicates a better cluster quality.", "labels": [], "entities": []}, {"text": "Entropy is computed for each cluster.", "labels": [], "entities": [{"text": "Entropy", "start_pos": 0, "end_pos": 7, "type": "METRIC", "confidence": 0.9853137135505676}]}, {"text": "Entropy for word w is the weighted average of the entropies of the clusters for that word.", "labels": [], "entities": [{"text": "Entropy", "start_pos": 0, "end_pos": 7, "type": "METRIC", "confidence": 0.9567518830299377}]}, {"text": "Finally, FScore considers both the coverage of the algorithm and its ability to discriminate between the two senses.", "labels": [], "entities": [{"text": "FScore", "start_pos": 9, "end_pos": 15, "type": "DATASET", "confidence": 0.7408071756362915}]}, {"text": "FScore is computed as the harmonic: Ambiguous words for testing: The first column indicates the senses; unambiguous translations that were merged to create an ambiguous word are indicated by a semicolon mean of Precision and Recall, where recall and precision for sense Si with respect to cluster Cr are computed by treating cluster Cr as the output of a retrieval system for sense Si .", "labels": [], "entities": [{"text": "FScore", "start_pos": 0, "end_pos": 6, "type": "METRIC", "confidence": 0.6773433685302734}, {"text": "Precision", "start_pos": 211, "end_pos": 220, "type": "METRIC", "confidence": 0.9926300048828125}, {"text": "Recall", "start_pos": 225, "end_pos": 231, "type": "METRIC", "confidence": 0.9637826681137085}, {"text": "recall", "start_pos": 239, "end_pos": 245, "type": "METRIC", "confidence": 0.9978031516075134}, {"text": "precision", "start_pos": 250, "end_pos": 259, "type": "METRIC", "confidence": 0.998365581035614}]}], "tableCaptions": [{"text": " Table 2: Results: Baseline is the most frequent sense; coverage is the number of occurrences on which the  decision was made by the algorithm", "labels": [], "entities": [{"text": "coverage", "start_pos": 56, "end_pos": 64, "type": "METRIC", "confidence": 0.9960136413574219}]}]}