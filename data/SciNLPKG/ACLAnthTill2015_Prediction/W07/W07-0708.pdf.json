{"title": [], "abstractContent": [{"text": "In order to simultaneously translate speech into multiple languages an extension of stochastic finite-state transducers is proposed.", "labels": [], "entities": []}, {"text": "In this approach the speech translation model consists of a single network where acoustic models (in the input) and the multilingual model (in the output) are embedded.", "labels": [], "entities": [{"text": "speech translation", "start_pos": 21, "end_pos": 39, "type": "TASK", "confidence": 0.7548010647296906}]}, {"text": "The multi-target model has been evaluated in a practical situation, and the results have been compared with those obtained using several mono-target models.", "labels": [], "entities": []}, {"text": "Experimental results show that the multi-target one requires less amount of memory.", "labels": [], "entities": []}, {"text": "In addition, a single decoding is enough to get the speech translated into multiple languages.", "labels": [], "entities": []}], "introductionContent": [{"text": "In this work we deal with finite-state models which constitute an important framework in syntactic pattern recognition for language and speech processing applications (;).", "labels": [], "entities": [{"text": "syntactic pattern recognition", "start_pos": 89, "end_pos": 118, "type": "TASK", "confidence": 0.6985910932223002}]}, {"text": "One of their outstanding characteristics is the availability of efficient algorithms for both optimization and decoding purposes.", "labels": [], "entities": []}, {"text": "Specifically, stochastic finite-state transducers (SFSTs) have proved to be useful for machine translation tasks within restricted domains.", "labels": [], "entities": [{"text": "stochastic finite-state transducers (SFSTs", "start_pos": 14, "end_pos": 56, "type": "TASK", "confidence": 0.63458651304245}, {"text": "machine translation tasks", "start_pos": 87, "end_pos": 112, "type": "TASK", "confidence": 0.8232007026672363}]}, {"text": "There are several approaches implemented over SFSTs which range from word-based systems) to phrase-based systems (.", "labels": [], "entities": [{"text": "SFSTs", "start_pos": 46, "end_pos": 51, "type": "TASK", "confidence": 0.9236775040626526}]}, {"text": "SFSTs usually offer high speed during the decoding step and they provide competitive results in terms of error rates.", "labels": [], "entities": [{"text": "SFSTs", "start_pos": 0, "end_pos": 5, "type": "TASK", "confidence": 0.9108166694641113}]}, {"text": "In addition, SFSTs have proved to be versatile models, which can be easily integrated with other finite-state models, such as a speech recognition system for speech-input translation purposes.", "labels": [], "entities": [{"text": "SFSTs", "start_pos": 13, "end_pos": 18, "type": "TASK", "confidence": 0.9527327418327332}, {"text": "speech recognition", "start_pos": 128, "end_pos": 146, "type": "TASK", "confidence": 0.7268009185791016}, {"text": "speech-input translation", "start_pos": 158, "end_pos": 182, "type": "TASK", "confidence": 0.7017988413572311}]}, {"text": "In fact, the integrated architecture has proved to work better than the decoupled one.", "labels": [], "entities": []}, {"text": "Our main goal is, hence, to extend and assess these methodologies to accomplish spoken language multi-target translation.", "labels": [], "entities": [{"text": "spoken language multi-target translation", "start_pos": 80, "end_pos": 120, "type": "TASK", "confidence": 0.6003359481692314}]}, {"text": "As far as multilingual translation is concerned, there are two main trends in machine translation devoted to translate an input string simultaneously into m languages: interlingua and parallel transfer.", "labels": [], "entities": [{"text": "multilingual translation", "start_pos": 10, "end_pos": 34, "type": "TASK", "confidence": 0.721620574593544}, {"text": "machine translation", "start_pos": 78, "end_pos": 97, "type": "TASK", "confidence": 0.7232739180326462}]}, {"text": "The former has historically been a knowledge-based technique that requires a deep-analysis effort, and the latter consists on m decoupled translators in a parallel architecture.", "labels": [], "entities": []}, {"text": "These translators can be either knowledge or example-based.", "labels": [], "entities": []}, {"text": "On the other hand, in) an example based technique consisting of a single SFST that cope with multiple target languages was presented.", "labels": [], "entities": [{"text": "SFST", "start_pos": 73, "end_pos": 77, "type": "TASK", "confidence": 0.6772375702857971}]}, {"text": "In that approach, when translating an input sentence, only one search through the multi-target SFST is required, instead of them independent decoding processes required by the mono-target translators.", "labels": [], "entities": [{"text": "translating an input sentence", "start_pos": 23, "end_pos": 52, "type": "TASK", "confidence": 0.8331576585769653}]}, {"text": "The classical layout for speech-input multi-target translation includes a speech recognition system in a serial architecture with m decoupled text-to-text translators.", "labels": [], "entities": [{"text": "speech-input multi-target translation", "start_pos": 25, "end_pos": 62, "type": "TASK", "confidence": 0.6456043521563212}]}, {"text": "Thus, this architecture entails a decoding stage of the speech signal into the source language text, and m further decoding stages to translate the source text into each of them target lan-guages.", "labels": [], "entities": []}, {"text": "If we supplant them translators with the multi-target SFST, the problem would be reduced to 2 searching stages.", "labels": [], "entities": [{"text": "SFST", "start_pos": 54, "end_pos": 58, "type": "TASK", "confidence": 0.47029951214790344}]}, {"text": "Nevertheless, in this paper we propose a natural way for acoustic models to be integrated in the multilingual network itself, in such away that the input speech signal can be simultaneously decoded and translated into m target languages.", "labels": [], "entities": []}, {"text": "As a result, due to the fact that there is just a single searching stage, this novel approach entails less computational cost.", "labels": [], "entities": []}, {"text": "The remainder of the present paper is structured as follows: section 2 describes both multi-target SFSTs and the inference algorithm from training examples; in section 3 a novel integrated architecture for speech-input multi-target translation is proposed; section 4 presents a practical application of these methods, including the experimental setup and the results they produced; finally, section 5 summarizes the main conclusions of this work.", "labels": [], "entities": [{"text": "SFSTs", "start_pos": 99, "end_pos": 104, "type": "TASK", "confidence": 0.8573992252349854}, {"text": "speech-input multi-target translation", "start_pos": 206, "end_pos": 243, "type": "TASK", "confidence": 0.6762587229410807}]}], "datasetContent": [{"text": "The performance obtained by the acoustic integration has been experimentally tested for both multitarget and mono-target devices.", "labels": [], "entities": []}, {"text": "As a matter of comparison, text-input translation results are also reported.", "labels": [], "entities": [{"text": "text-input translation", "start_pos": 27, "end_pos": 49, "type": "TASK", "confidence": 0.5386757403612137}]}, {"text": "The multi-target SFST was learned from the training set described in using the previously described GIAMTI algorithm.", "labels": [], "entities": [{"text": "SFST", "start_pos": 17, "end_pos": 21, "type": "TASK", "confidence": 0.899640679359436}]}, {"text": "The 500 test sentences were then translated by the multi-target SFST.", "labels": [], "entities": [{"text": "SFST", "start_pos": 64, "end_pos": 68, "type": "DATASET", "confidence": 0.6115281581878662}]}, {"text": "The translation provided by the system in each language was compared to the corresponding reference sentence.", "labels": [], "entities": []}, {"text": "Additionally, two mono-target SFSTs were inferred with their outputs for the aforementioned test to betaken as baseline.", "labels": [], "entities": [{"text": "SFSTs", "start_pos": 30, "end_pos": 35, "type": "TASK", "confidence": 0.7649771571159363}]}, {"text": "The evaluation includes both computational cost and performance of the system.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Main features of the METEUS corpus.", "labels": [], "entities": [{"text": "METEUS corpus", "start_pos": 31, "end_pos": 44, "type": "DATASET", "confidence": 0.9218353033065796}]}, {"text": " Table 2: Features of multi-target model and the two  decoupled mono-target models (one for Spanish to  Basque translation, referred to as S2B, and the sec- ond for Spanish to English, S2E).", "labels": [], "entities": []}, {"text": " Table 3: Average time needed to translate each input  sentence into two languages.", "labels": [], "entities": []}, {"text": " Table 4: Text-input and speech-input translation re- sults for Spanish into Basque (S2B) and Spanish into  English (S2E) using a multi-target SFST (columns  on the left) or two mono-target SFSTs (columns on  the right). The last row shows Spanish speech de- coding results using each of the three devices.", "labels": [], "entities": [{"text": "speech-input translation re- sults", "start_pos": 25, "end_pos": 59, "type": "TASK", "confidence": 0.7702295303344726}, {"text": "Spanish speech de- coding", "start_pos": 240, "end_pos": 265, "type": "TASK", "confidence": 0.6771481812000275}]}]}