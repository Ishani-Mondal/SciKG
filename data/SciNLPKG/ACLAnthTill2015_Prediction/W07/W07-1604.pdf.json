{"title": [{"text": "Detection of Grammatical Errors Involving Prepositions", "labels": [], "entities": [{"text": "Detection of Grammatical Errors Involving Prepositions", "start_pos": 0, "end_pos": 54, "type": "TASK", "confidence": 0.9060005843639374}]}], "abstractContent": [{"text": "This paper presents ongoing work on the detection of preposition errors of non-native speakers of English.", "labels": [], "entities": [{"text": "detection of preposition errors", "start_pos": 40, "end_pos": 71, "type": "TASK", "confidence": 0.7624325007200241}]}, {"text": "Since prepositions account fora substantial proportion of all grammatical errors by ESL (English as a Second Language) learners, developing an NLP application that can reliably detect these types of errors will provide an invaluable learning resource to ESL students.", "labels": [], "entities": []}, {"text": "To address this problem, we use a maximum entropy classifier combined with rule-based filters to detect preposition errors in a corpus of student essays.", "labels": [], "entities": []}, {"text": "Although our work is preliminary , we achieve a precision of 0.8 with a recall of 0.3.", "labels": [], "entities": [{"text": "precision", "start_pos": 48, "end_pos": 57, "type": "METRIC", "confidence": 0.999024510383606}, {"text": "recall", "start_pos": 72, "end_pos": 78, "type": "METRIC", "confidence": 0.9995031356811523}]}], "introductionContent": [{"text": "The National Clearinghouse for English Language Acquisition (2002) estimates that 9.6% of the students in the US public school population speak a language other than English and have limited English proficiency.", "labels": [], "entities": [{"text": "English Language Acquisition", "start_pos": 31, "end_pos": 59, "type": "TASK", "confidence": 0.6351481676101685}]}, {"text": "Clearly, there is a substantial and increasing need for tools for instruction in English as a Second Language (ESL).", "labels": [], "entities": []}, {"text": "In particular, preposition usage is one of the most difficult aspects of English grammar for non-native speakers to master.", "labels": [], "entities": [{"text": "preposition usage", "start_pos": 15, "end_pos": 32, "type": "TASK", "confidence": 0.8967106342315674}]}, {"text": "Preposition errors account fora significant proportion of all ESL grammar errors.", "labels": [], "entities": [{"text": "Preposition errors", "start_pos": 0, "end_pos": 18, "type": "METRIC", "confidence": 0.9255906343460083}, {"text": "ESL grammar errors", "start_pos": 62, "end_pos": 80, "type": "TASK", "confidence": 0.8631043831507365}]}, {"text": "They represented the largest category, about 29%, of all the errors by 53 intermediate to advanced ESL students, and 18% of all errors reported in an intensive analysis of one Japanese writer ().", "labels": [], "entities": []}, {"text": "Preposition errors are not only prominent among error types, they are also quite frequent in ESL writing.", "labels": [], "entities": [{"text": "Preposition errors", "start_pos": 0, "end_pos": 18, "type": "METRIC", "confidence": 0.9385588467121124}, {"text": "ESL writing", "start_pos": 93, "end_pos": 104, "type": "TASK", "confidence": 0.7799409627914429}]}, {"text": "analyzed the essays of 350 ESL college students representing 15 different native languages and reported that preposition errors were present in 18% of sentences in a sample of text produced by writers from first languages as diverse as Korean, Greek, and Spanish.", "labels": [], "entities": []}, {"text": "The goal of the research described here is to provide software for detecting common grammar and usage errors in the English writing of non-native English speakers.", "labels": [], "entities": [{"text": "detecting common grammar and usage errors in the English writing of non-native English speakers", "start_pos": 67, "end_pos": 162, "type": "TASK", "confidence": 0.6914207765034267}]}, {"text": "Our work targets errors involving prepositions, specifically those of incorrect preposition selection, such as arrive to the town, and those of extraneous prepositions, as inmost of people.", "labels": [], "entities": []}, {"text": "We present an approach that combines machine learning with rule-based filters to detect preposition errors in a corpus of ESL essays.", "labels": [], "entities": []}, {"text": "Even though this is work in progress, we achieve precision of 0.8 with a recall of 0.3.", "labels": [], "entities": [{"text": "precision", "start_pos": 49, "end_pos": 58, "type": "METRIC", "confidence": 0.9995431900024414}, {"text": "recall", "start_pos": 73, "end_pos": 79, "type": "METRIC", "confidence": 0.9992275238037109}]}, {"text": "The paper is structured as follows: in the next section, we describe the difficulty in learning English preposition usage; in Section 3, we discuss related work; in Sections 4-7 we discuss our methodology and evaluation.", "labels": [], "entities": [{"text": "learning English preposition usage", "start_pos": 87, "end_pos": 121, "type": "TASK", "confidence": 0.5406903028488159}]}], "datasetContent": [{"text": "The model was tested on 18,157 preposition contexts extracted from 12 files randomly selected from a portion of 1100 Lexile text (11th grade) that had not been used for training.", "labels": [], "entities": [{"text": "Lexile text (11th grade)", "start_pos": 117, "end_pos": 141, "type": "DATASET", "confidence": 0.8970118761062622}]}, {"text": "For each context, the model predicted the probability of each preposition given the contextual representation.", "labels": [], "entities": []}, {"text": "The highest probability preposition was then compared to the preposition that had actually been used by the writer.", "labels": [], "entities": []}, {"text": "Because the test corpus consisted of published, edited text, we assumed that this material contained few, if any, errors.", "labels": [], "entities": []}, {"text": "In this and subsequent tests, the model was used to classify each context as one of 34 classes.", "labels": [], "entities": []}, {"text": "Results of the comparison between the classifier and the test set showed that the overall proportion of agreement between the text and the classifier was 0.69.", "labels": [], "entities": [{"text": "agreement", "start_pos": 104, "end_pos": 113, "type": "METRIC", "confidence": 0.6847267746925354}]}, {"text": "The value of kappa was 0.64.", "labels": [], "entities": [{"text": "kappa", "start_pos": 13, "end_pos": 18, "type": "METRIC", "confidence": 0.8310738801956177}]}, {"text": "When we examined the errors, we discovered that, frequently, the classifier's most probable preposition (the one it assigned) differed from the second most probable by just a few percentage points.", "labels": [], "entities": []}, {"text": "This corresponded to a situation in which two or more prepositions were likely to be found in a given context.", "labels": [], "entities": []}, {"text": "Consider the context They thanked him for his consideration this matter, where either of or in could fill the blank.", "labels": [], "entities": []}, {"text": "Because the classifier was forced to make a choice in this and other close cases, it incurred a high probability of making an error.", "labels": [], "entities": []}, {"text": "To avoid this situation, we re-ran the test allowing the classifier to skip any preposition if its top ranked and second ranked choices differed by less than a specified amount.", "labels": [], "entities": []}, {"text": "In other words, we permitted it to respond only when it was confident of its decision.", "labels": [], "entities": []}, {"text": "When the difference between the first and second ranked choices was 0.60 or greater, 50% of the cases received no decision, but for the remaining half of the test cases, the proportion of agreement was 0.90 and kappa was 0.88.", "labels": [], "entities": [{"text": "agreement", "start_pos": 188, "end_pos": 197, "type": "METRIC", "confidence": 0.8106767535209656}, {"text": "kappa", "start_pos": 211, "end_pos": 216, "type": "METRIC", "confidence": 0.9960572719573975}]}, {"text": "This suggests that a considerable improvement in performance can be achieved by using a more conservative approach based on a higher confidence level for the classifier.", "labels": [], "entities": []}, {"text": "To evaluate the ME model's suitability for analyzing ungrammatical text, 2,000 preposition contexts were extracted from randomly selected essays written on ESL tests by native speakers of Chinese, Japanese, and Russian.", "labels": [], "entities": []}, {"text": "This set of materials was used to look for problems that were likely to arise as a conse-   The student essays contained many misspelled words.", "labels": [], "entities": []}, {"text": "Because misspellings were not in the training, the model was unable to use the features associated with them (e.g., FHword#frinzy) in its decision making.", "labels": [], "entities": [{"text": "FHword#frinzy", "start_pos": 116, "end_pos": 129, "type": "DATASET", "confidence": 0.7953357100486755}]}, {"text": "The tagger was also affected by spelling errors, so to avoid these problems, the classifier was allowed to skip any context that contained misspelled words in positions adjacent to the preposition or in its adjacent phrasal heads.", "labels": [], "entities": []}, {"text": "A second problem resulted from punctuation errors in the student writing.", "labels": [], "entities": []}, {"text": "This usually took the form of missing commas, as in I disagree because from my point of view there is no evidence.", "labels": [], "entities": []}, {"text": "In the training corpus, commas generally separated parenthetical expressions, such as from my point of view, from the rest of the sentence.", "labels": [], "entities": []}, {"text": "Without the comma, the model selected of as the most probable preposition following because, instead of from.", "labels": [], "entities": []}, {"text": "A set of heuristics was used to locate common sites of comma errors and skip these contexts.", "labels": [], "entities": []}, {"text": "There were two other common sources of classification error: antonyms and benefactives.", "labels": [], "entities": []}, {"text": "The model very often confused prepositions with opposite meanings (like with/without and from/to), so when the highest probability preposition was an antonym of the one produced by the writer, we blocked the classifier from marking the usage as an error.", "labels": [], "entities": []}, {"text": "Benefactive phrases of the form for + person/organization (for everyone, for my school) were also difficult for the model to learn, most likely because, as adjuncts, they are free to appear in many different places in a sentence and the preposition is not constrained by its object, resulting in their frequency being divided among many different contexts.", "labels": [], "entities": []}, {"text": "When a benefactive appeared in an argument position, the model's most probable preposition was generally not the preposition for.", "labels": [], "entities": []}, {"text": "In the sentence They described apart fora kid, the preposition of has a higher probability.", "labels": [], "entities": []}, {"text": "The classifier was prevented from marking for + person/organization as a usage error in such contexts.", "labels": [], "entities": []}, {"text": "To summarize, the classifier consisted of the ME model plus a program that blocked its application: Classifer vs. Rater Statistics in cases of misspelling, likely punctuation errors, antonymous prepositions, and benefactives.", "labels": [], "entities": []}, {"text": "Another difference between the training corpus and the testing corpus was that the latter contained grammatical errors.", "labels": [], "entities": []}, {"text": "In the sentence, This was my first experience about choose friends, there is a verb error immediately following the preposition.", "labels": [], "entities": []}, {"text": "Arguably, the preposition is also wrong since the sequence about choose is ill-formed.", "labels": [], "entities": []}, {"text": "When the classifier marked the preposition as incorrect in an ungrammatical context, it was credited with correctly detecting a preposition error.", "labels": [], "entities": []}, {"text": "Next, the classifier was tested on the set of 2,000 preposition contexts, with the confidence threshold set at 0.9.", "labels": [], "entities": []}, {"text": "Each preposition in these essays was judged for correctness of usage by one or two human raters.", "labels": [], "entities": []}, {"text": "The judged rate of occurrence of preposition errors was 0.109 for Rater 1 and 0.098 for Rater 2, i.e., about 1 out of every 10 prepositions was judged to be incorrect.", "labels": [], "entities": []}, {"text": "The overall proportion of agreement between Rater1 and Rater 2 was 0.926, and kappa was 0.599.", "labels": [], "entities": [{"text": "agreement", "start_pos": 26, "end_pos": 35, "type": "METRIC", "confidence": 0.8295122981071472}, {"text": "Rater1", "start_pos": 44, "end_pos": 50, "type": "DATASET", "confidence": 0.8979660272598267}, {"text": "kappa", "start_pos": 78, "end_pos": 83, "type": "METRIC", "confidence": 0.9192661643028259}]}, {"text": "(second column) shows the results for the Classifier vs. Rater 1, using Rater 1 as the gold standard.", "labels": [], "entities": []}, {"text": "Note that this is not a blind test of the classifier inasmuch as the classifier's confidence threshold was adjusted to maximize performance on this set.", "labels": [], "entities": []}, {"text": "The overall proportion of agreement was 0.942, but kappa was only 0.365 due to the high level of agreement expected by chance, as the Classifier used the response category of \"correct\" more than 97% of the time.", "labels": [], "entities": [{"text": "agreement", "start_pos": 26, "end_pos": 35, "type": "METRIC", "confidence": 0.7444266080856323}, {"text": "kappa", "start_pos": 51, "end_pos": 56, "type": "METRIC", "confidence": 0.99524986743927}]}, {"text": "We found similar results when comparing the judgements of the Classifier to Rater 2: agreement was high and kappa was low.", "labels": [], "entities": [{"text": "agreement", "start_pos": 85, "end_pos": 94, "type": "METRIC", "confidence": 0.9978057742118835}]}, {"text": "In addition, for both raters, precision was much higher than recall.", "labels": [], "entities": [{"text": "precision", "start_pos": 30, "end_pos": 39, "type": "METRIC", "confidence": 0.9997968077659607}, {"text": "recall", "start_pos": 61, "end_pos": 67, "type": "METRIC", "confidence": 0.9993377327919006}]}, {"text": "As noted earlier, the table does not include the cases that the classifier skipped due to misspelling, antonymous prepositions, and benefactives.", "labels": [], "entities": []}, {"text": "Both precision and recall are low in these comparisons to the human raters.", "labels": [], "entities": [{"text": "precision", "start_pos": 5, "end_pos": 14, "type": "METRIC", "confidence": 0.9996985197067261}, {"text": "recall", "start_pos": 19, "end_pos": 25, "type": "METRIC", "confidence": 0.9997082352638245}]}, {"text": "We are particularly concerned about precision because the feedback that students receive from an automated writing analysis system should, above all, avoid false positives, i.e., marking correct usage as incorrect.", "labels": [], "entities": [{"text": "precision", "start_pos": 36, "end_pos": 45, "type": "METRIC", "confidence": 0.9976125955581665}]}, {"text": "We tried to improve precision by adding to the system a naive Bayesian classifier that uses the same features found in.", "labels": [], "entities": [{"text": "precision", "start_pos": 20, "end_pos": 29, "type": "METRIC", "confidence": 0.9989448189735413}]}, {"text": "As expected, its performance is not as good as the ME model (e.g., precision = 0.57 and recall = 0.29 compared to Rater 1 as the gold standard), but when the Bayesian classifier was given a veto over the decision of the ME classifier, overall precision did increase substantially (to 0.88), though with a reduction in recall (to 0.16).", "labels": [], "entities": [{"text": "precision", "start_pos": 67, "end_pos": 76, "type": "METRIC", "confidence": 0.9995025396347046}, {"text": "recall", "start_pos": 88, "end_pos": 94, "type": "METRIC", "confidence": 0.9994497895240784}, {"text": "precision", "start_pos": 243, "end_pos": 252, "type": "METRIC", "confidence": 0.9993802309036255}, {"text": "recall", "start_pos": 318, "end_pos": 324, "type": "METRIC", "confidence": 0.9995858073234558}]}, {"text": "To address the problem of low recall, we have targeted another type of ESL preposition error: extraneous prepositions.", "labels": [], "entities": [{"text": "recall", "start_pos": 30, "end_pos": 36, "type": "METRIC", "confidence": 0.9970942735671997}]}], "tableCaptions": [{"text": " Table 3: Classifer vs. Rater Statistics", "labels": [], "entities": []}]}