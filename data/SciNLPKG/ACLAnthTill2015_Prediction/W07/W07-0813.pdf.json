{"title": [{"text": "Smoothing a Lexicon-based POS Tagger for Arabic and Hebrew", "labels": [], "entities": []}], "abstractContent": [{"text": "We propose an enhanced Part-of-Speech (POS) tagger of Semitic languages that treats Modern Standard Arabic (hence-forth Arabic) and Modern Hebrew (henceforth Hebrew) using the same probabilistic model and architectural setting.", "labels": [], "entities": []}, {"text": "We start out by porting an existing Hidden Markov Model POS tagger for Hebrew to Arabic by exchanging a morphological analyzer for Hebrew with Buckwalter's (2002) morphological ana-lyzer for Arabic.", "labels": [], "entities": []}, {"text": "This gives state-of-the-art accuracy (96.12%), comparable to Ha-bash and Rambow's (2005) analyzer-based POS tagger on the same Arabic datasets.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 28, "end_pos": 36, "type": "METRIC", "confidence": 0.9995937943458557}]}, {"text": "However, further improvement of such analyzer-based tagging methods is hindered by the incomplete coverage of standard morphological analyzer (Bar Haim et al., 2005).", "labels": [], "entities": []}, {"text": "To overcome this coverage problem we supplement the output of Buckwalter's analyzer with synthetically constructed analyses that are proposed by a model which uses character information (Diab et al., 2004) in away that is similar to Nakagawa's (2004) system for Chinese and Japanese.", "labels": [], "entities": []}, {"text": "A version of this extended model that (unlike Naka-gawa) incorporates synthetically constructed analyses also for known words achieves 96.28% accuracy on the standard Arabic test set.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 142, "end_pos": 150, "type": "METRIC", "confidence": 0.9992615580558777}, {"text": "Arabic test set", "start_pos": 167, "end_pos": 182, "type": "DATASET", "confidence": 0.7760042945543925}]}], "introductionContent": [{"text": "Part-of-Speech tagging for Semitic languages has been an active topic of research in recent years.", "labels": [], "entities": [{"text": "Part-of-Speech tagging for Semitic languages", "start_pos": 0, "end_pos": 44, "type": "TASK", "confidence": 0.8510910153388977}]}, {"text": "() are some examples for this line of work on Modern Standard Arabic and Modern Hebrew.", "labels": [], "entities": []}, {"text": "POS tagging systems aim at classifying input sequences of lexemes by assigning each such sequence a corresponding sequence of most probable POS tags.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 0, "end_pos": 11, "type": "TASK", "confidence": 0.801565557718277}]}, {"text": "It is often assumed that for each input lexeme there is a set of a priori possible POS tag categories, or a probability function over them, and the tagger has to choose from this limited set of candidate categories.", "labels": [], "entities": []}, {"text": "We henceforth use the term lexicon to refer to the set of lexemes in a language and the mapping that assigns each of them candidate POS tags, possibly with additional probabilities.", "labels": [], "entities": []}, {"text": "Two ways to obtain a lexicon can be distinguished in recent works on POS tagging in Semitic languages.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 69, "end_pos": 80, "type": "TASK", "confidence": 0.8740363419055939}]}, {"text": "Data-driven approaches like () employ the lexicon only implicitly when extracting features on possible POS tags from annotated corpora that are used for training the POS tagger.", "labels": [], "entities": [{"text": "POS tagger", "start_pos": 166, "end_pos": 176, "type": "TASK", "confidence": 0.5792871713638306}]}, {"text": "Lexicon-based approaches) use a lexicon that is extracted from a manually constructed morphological analyzer.", "labels": [], "entities": []}, {"text": "In this paper we show that although lexiconbased taggers for Arabic and Hebrew may initially outperform data-driven taggers, they do not exhaust the advantages of data-driven approaches.", "labels": [], "entities": []}, {"text": "Consequently, we propose a hybrid model of datadriven methods and lexicon-based methods, and show its advantages over both models, in away that is reminiscent of results for Chinese and Japanese.", "labels": [], "entities": []}, {"text": "As a first step, we develop a Part-of-Speech tagger that treats Arabic and Hebrew using the same probabilistic model and architectural setting.", "labels": [], "entities": []}, {"text": "We start out from MorphTagger, a lexicon-based tagger for Hebrew developed by, which uses standard Hidden Markov Model techniques.", "labels": [], "entities": []}, {"text": "We port the existing MorphTagger implementation to Arabic by exchanging morphological analyzer with Buckwalter's (2002) morphological analyzer, and then training the tagger on the Arabic Treebank ().", "labels": [], "entities": [{"text": "Arabic Treebank", "start_pos": 180, "end_pos": 195, "type": "DATASET", "confidence": 0.8745767772197723}]}, {"text": "Remarkably, this gives state-of-the-art accuracy (96.12%) on the same Arabic datasets as.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 40, "end_pos": 48, "type": "METRIC", "confidence": 0.9994041919708252}]}, {"text": "To the best of our knowledge, this is the first time the same POS tagging architecture is used both for Arabic and Hebrew texts with comparable accuracy.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 62, "end_pos": 73, "type": "TASK", "confidence": 0.6852865517139435}, {"text": "accuracy", "start_pos": 144, "end_pos": 152, "type": "METRIC", "confidence": 0.9948908090591431}]}, {"text": "Despite the initial advantages of this setting, our empirical study shows that in both languages, further improvement inaccuracy is hindered by the incompleteness of the morphological analyzer.", "labels": [], "entities": []}, {"text": "By \"incompleteness\" we refer not only to the wellstudied problem of unknown words (out-ofvocabulary).", "labels": [], "entities": []}, {"text": "Our results show that for both Arabic and Hebrew, a more serious problem involves words for which the analyzer provides a set of analyses that does not contain the correct one.", "labels": [], "entities": []}, {"text": "We find out that this is the case for 3% of the words in the development set.", "labels": [], "entities": []}, {"text": "This obviously sets an upper bound on tagger accuracy using methods that are purely based on a manually constructed lexicon.", "labels": [], "entities": [{"text": "tagger", "start_pos": 38, "end_pos": 44, "type": "TASK", "confidence": 0.9651728868484497}, {"text": "accuracy", "start_pos": 45, "end_pos": 53, "type": "METRIC", "confidence": 0.9107264280319214}]}, {"text": "We refer to this problem as the \"incomplete lexicon\" problem.", "labels": [], "entities": []}, {"text": "We focus on devising a solution to the incomplete lexicon problem by smoothing.", "labels": [], "entities": []}, {"text": "We supplement the output of Buckwalter's analyzer with synthetically constructed analyses that are proposed by a model which uses character information () in away that is similar to Nakagawa's (2004) system for Japanese.", "labels": [], "entities": []}, {"text": "Unlike Nakagawa's method, however, our smoothing method incorporates synthetically constructed analyses also for known words, though only when all available taggings of the sentence have low probabilities according to our model.", "labels": [], "entities": []}, {"text": "A version of this extended model achieves a modest improvement (96.28%) inaccuracy over the baseline on the standard Arabic test set.", "labels": [], "entities": [{"text": "Arabic test set", "start_pos": 117, "end_pos": 132, "type": "DATASET", "confidence": 0.804037481546402}]}, {"text": "This paper is structured as follows.", "labels": [], "entities": []}, {"text": "In section 2 we start with a brief discussion of previous work.", "labels": [], "entities": []}, {"text": "Section 3 describes our adaptation of Bar Haim et al.'s POS tagging system to Arabic.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 56, "end_pos": 67, "type": "TASK", "confidence": 0.6325578987598419}]}, {"text": "In section 4 we show that an architecture like Bar Haim et al.'s, which relies on a morphological analyzer, is likely to suffer from coverage problems under any configuration where it is used as a stand-alone.", "labels": [], "entities": []}, {"text": "In section 5 we present our new architecture and the method of combining the models.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": []}