{"title": [{"text": "Analysis of statistical and morphological classes to generate weighted reordering hypotheses on a Statistical Machine Translation system", "labels": [], "entities": [{"text": "Statistical Machine Translation", "start_pos": 98, "end_pos": 129, "type": "TASK", "confidence": 0.6378781000773112}]}], "abstractContent": [{"text": "One main challenge of statistical machine translation (SMT) is dealing with word order.", "labels": [], "entities": [{"text": "statistical machine translation (SMT)", "start_pos": 22, "end_pos": 59, "type": "TASK", "confidence": 0.8157946715752283}]}, {"text": "The main idea of the statistical machine reordering (SMR) approach is to use the powerful techniques of SMT systems to generate a weighted reordering graph for SMT systems.", "labels": [], "entities": [{"text": "statistical machine reordering (SMR)", "start_pos": 21, "end_pos": 57, "type": "TASK", "confidence": 0.8152181208133698}, {"text": "SMT", "start_pos": 104, "end_pos": 107, "type": "TASK", "confidence": 0.9743877053260803}, {"text": "SMT", "start_pos": 160, "end_pos": 163, "type": "TASK", "confidence": 0.9844840168952942}]}, {"text": "This technique supplies reordering constraints to an SMT system, using statistical criteria.", "labels": [], "entities": [{"text": "SMT", "start_pos": 53, "end_pos": 56, "type": "TASK", "confidence": 0.994587779045105}]}, {"text": "In this paper, we experiment with different graph pruning which guarantees the translation quality improvement due to reordering at a very low increase of computational cost.", "labels": [], "entities": []}, {"text": "The SMR approach is capable of generalizing re-orderings, which have been learned during training , by using word classes instead of words themselves.", "labels": [], "entities": [{"text": "SMR", "start_pos": 4, "end_pos": 7, "type": "TASK", "confidence": 0.9907222986221313}, {"text": "generalizing re-orderings", "start_pos": 31, "end_pos": 56, "type": "TASK", "confidence": 0.8743457496166229}]}, {"text": "We experiment with statistical and morphological classes in order to choose those which capture the most probable reorderings.", "labels": [], "entities": []}, {"text": "Satisfactory results are reported in the WMT07 Es/En task.", "labels": [], "entities": [{"text": "Satisfactory", "start_pos": 0, "end_pos": 12, "type": "METRIC", "confidence": 0.9743606448173523}, {"text": "WMT07 Es/En task", "start_pos": 41, "end_pos": 57, "type": "TASK", "confidence": 0.42602130174636843}]}, {"text": "Our system outperforms in terms of BLEU the WMT07 Official baseline system.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 35, "end_pos": 39, "type": "METRIC", "confidence": 0.9979709982872009}, {"text": "WMT07 Official baseline system", "start_pos": 44, "end_pos": 74, "type": "DATASET", "confidence": 0.8636124134063721}]}], "introductionContent": [{"text": "Nowadays, statistical machine translation is mainly based on phrases (.", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 10, "end_pos": 41, "type": "TASK", "confidence": 0.7456088066101074}]}, {"text": "In parallel to this phrasebased approach, the use of bilingual n-grams gives comparable results, as shown by.", "labels": [], "entities": []}, {"text": "Two basic issues differentiate the n-gram-based system from the phrase-based: training data is monotonically segmented into bilingual units; and, the model considers ngram probabilities rather than relative frequencies.", "labels": [], "entities": []}, {"text": "The n-gram-based system follows a maximum entropy approach, in which a log-linear combination of multiple models is implemented ), as an alternative to the source-channel approach.", "labels": [], "entities": []}, {"text": "Introducing reordering capabilities is important in both systems.", "labels": [], "entities": []}, {"text": "Recently, new reordering strategies have been proposed such as the reordering of each source sentence to match the word order in the corresponding target sentence, see and . These approaches are applied in the training set and they lack of reordering generalization.", "labels": [], "entities": []}, {"text": "Applied both in the training and decoding step, describe a method for introducing syntactic information for reordering in SMT.", "labels": [], "entities": [{"text": "SMT", "start_pos": 122, "end_pos": 125, "type": "TASK", "confidence": 0.9718574285507202}]}, {"text": "This approach is applied as a pre-processing step.", "labels": [], "entities": []}, {"text": "Differently,  presents a reordering approach based on reordering patterns which is coupled with decoding.", "labels": [], "entities": []}, {"text": "The reordering patterns are learned directly from word alignment and all reorderings have the same probability.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 50, "end_pos": 64, "type": "TASK", "confidence": 0.6722403317689896}]}, {"text": "In our previous work ) we presented the SMR approach which is based on using the powerful SMT techniques to generate a reordered source input for an SMT system both in training and decoding steps.", "labels": [], "entities": [{"text": "SMR", "start_pos": 40, "end_pos": 43, "type": "TASK", "confidence": 0.9948821067810059}, {"text": "SMT", "start_pos": 90, "end_pos": 93, "type": "TASK", "confidence": 0.9724361896514893}, {"text": "SMT", "start_pos": 149, "end_pos": 152, "type": "TASK", "confidence": 0.964553952217102}]}, {"text": "One step further, shows how the SMR system can generate a weighted reordering graph, allowing the SMT system to make the final reordering decision.", "labels": [], "entities": [{"text": "SMR", "start_pos": 32, "end_pos": 35, "type": "TASK", "confidence": 0.9520400762557983}, {"text": "SMT", "start_pos": 98, "end_pos": 101, "type": "TASK", "confidence": 0.9559609293937683}]}, {"text": "In this paper, the SMR approach is used to train the SMT system and to generate a weighted reordering graph for the decoding step.", "labels": [], "entities": [{"text": "SMR", "start_pos": 19, "end_pos": 22, "type": "TASK", "confidence": 0.9824093580245972}, {"text": "SMT", "start_pos": 53, "end_pos": 56, "type": "TASK", "confidence": 0.9919365644454956}]}, {"text": "The SMR system uses word classes instead of words themselves and we analyze both statistical and morphological classes.", "labels": [], "entities": [{"text": "SMR", "start_pos": 4, "end_pos": 7, "type": "TASK", "confidence": 0.9878729581832886}]}, {"text": "Moreover, we present experiments regarding the reordering graph efficiency: we analyze different graph pruning and we show the very low increase in computational cost (compared to a monotonic translation).", "labels": [], "entities": []}, {"text": "Finally, we compare the performance our system in terms of BLEU with the WMT07 baseline system.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 59, "end_pos": 63, "type": "METRIC", "confidence": 0.9985931515693665}, {"text": "WMT07 baseline", "start_pos": 73, "end_pos": 87, "type": "DATASET", "confidence": 0.9412924647331238}]}, {"text": "This paper is organized as follows.", "labels": [], "entities": []}, {"text": "The first two sections explain the SMT and the SMR baseline systems, respectively.", "labels": [], "entities": [{"text": "SMT", "start_pos": 35, "end_pos": 38, "type": "TASK", "confidence": 0.9750481247901917}, {"text": "SMR", "start_pos": 47, "end_pos": 50, "type": "TASK", "confidence": 0.8681556582450867}]}, {"text": "Section 4 reports the study of statistical and morphological classes.", "labels": [], "entities": []}, {"text": "Section 5 describes the experimental framework and discusses the results.", "labels": [], "entities": []}, {"text": "Finally, Section 6 presents the conclusions and some further work.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 2: Performance in BLEU in the test set of different  graph pruning (b stands for beam and s for states); the  use of reordering feature function (W r indicates its use);  and the time increase related to T m (monotonic transla- tion time).", "labels": [], "entities": [{"text": "BLEU", "start_pos": 25, "end_pos": 29, "type": "METRIC", "confidence": 0.9905095100402832}]}]}