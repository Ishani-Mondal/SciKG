{"title": [{"text": "Experiments with an Annotation Scheme fora Knowledge-rich Noun Phrase Interpretation System", "labels": [], "entities": [{"text": "Knowledge-rich Noun Phrase Interpretation", "start_pos": 43, "end_pos": 84, "type": "TASK", "confidence": 0.5979842096567154}]}], "abstractContent": [{"text": "This paper presents observations on our experience with an annotation scheme that was used in the training of a state-of-the-art noun phrase semantic interpretation system.", "labels": [], "entities": [{"text": "noun phrase semantic interpretation", "start_pos": 129, "end_pos": 164, "type": "TASK", "confidence": 0.709781251847744}]}, {"text": "The system relies on cross-linguistic evidence from a set of five Romance languages: Span-ish, Italian, French, Portuguese, and Roma-nian.", "labels": [], "entities": []}, {"text": "Given a training set of English noun phrases in context along with their translations in the five Romance languages, our algorithm automatically learns a classification function that is later on applied to unseen test instances for semantic interpretation.", "labels": [], "entities": [{"text": "semantic interpretation", "start_pos": 232, "end_pos": 255, "type": "TASK", "confidence": 0.7982505261898041}]}, {"text": "As training and test data we used two text collections of different genre: Europarl and CLUVI.", "labels": [], "entities": [{"text": "Europarl", "start_pos": 75, "end_pos": 83, "type": "DATASET", "confidence": 0.9802415370941162}]}, {"text": "The training data was annotated with contextual features based on two state-of-the-art classification tag sets.", "labels": [], "entities": []}], "introductionContent": [{"text": "Linguistically annotated corpora are valuable resources for both theoretical and computational linguistics.", "labels": [], "entities": []}, {"text": "They have played an important role in any aspect of natural language processing research, from supervised learning to evaluation, and have been used in many applications such as Syntactic and Semantic Parsing, Information Extraction, and Question Answering.", "labels": [], "entities": [{"text": "natural language processing research", "start_pos": 52, "end_pos": 88, "type": "TASK", "confidence": 0.7037687003612518}, {"text": "Syntactic and Semantic Parsing", "start_pos": 178, "end_pos": 208, "type": "TASK", "confidence": 0.7743389755487442}, {"text": "Information Extraction", "start_pos": 210, "end_pos": 232, "type": "TASK", "confidence": 0.8317047655582428}, {"text": "Question Answering", "start_pos": 238, "end_pos": 256, "type": "TASK", "confidence": 0.8634002804756165}]}, {"text": "A long-term research topic in linguistics, computational linguistics , and artificial intelligence has In the past few years at many workshops, tutorials, and competitions this research topic has received considerable interbeen the semantic interpretation of noun phrases (NPs).", "labels": [], "entities": [{"text": "semantic interpretation of noun phrases (NPs)", "start_pos": 232, "end_pos": 277, "type": "TASK", "confidence": 0.851012222468853}]}, {"text": "The basic problem is simple to define: given a noun phrase constructed out of a pair of concepts expressed by words or phrases, c 1 -c 2 , one representing the head and the other the modifier, determine the semantic relationship between the two concepts.", "labels": [], "entities": []}, {"text": "For example, a compound family estate should be interpreted as the estate OWNED BY the family; an NP such as dress of silk should be interpreted as denoting a dress MADE FROM silk.", "labels": [], "entities": [{"text": "OWNED BY", "start_pos": 74, "end_pos": 82, "type": "METRIC", "confidence": 0.8243976533412933}, {"text": "MADE FROM", "start_pos": 165, "end_pos": 174, "type": "METRIC", "confidence": 0.7499408423900604}]}, {"text": "The problem, while simple to state is hard to solve.", "labels": [], "entities": []}, {"text": "The reason is that the meaning of these constructions is most of the time ambiguous or implicit.", "labels": [], "entities": []}, {"text": "Currently, the best-performing English NP interpretation methods in computational linguistics focus mostly on two consecutive noun instances (noun compounds) and are either (weakly) supervised, knowledge-intensive (,),), ), ),),), (), or use statistical models on large collections of unlabeled data),,,).", "labels": [], "entities": [{"text": "NP interpretation", "start_pos": 39, "end_pos": 56, "type": "TASK", "confidence": 0.8092929422855377}]}, {"text": "Unlike unsupervised models, supervised knowledge-rich approaches rely heavily on large sets of annotated training data.", "labels": [], "entities": []}, {"text": "For example, we previously showed () that, forest from the computational linguistics community: Workshop on Multiword Expressions at COLING; Computational Lexical Semantics Workshop at ACL 2004; Tutorial on Knowledge Discovery from Text at ACL 2003; Shared task on Semantic Role Labeling at the task of automatic detection of part-whole relations, our system's learning curve reached a plateau at 74% F-measure when trained on approximatively 10,000 positive and negative examples.", "labels": [], "entities": [{"text": "COLING", "start_pos": 133, "end_pos": 139, "type": "DATASET", "confidence": 0.7848692536354065}, {"text": "Tutorial on Knowledge Discovery from Text at ACL 2003", "start_pos": 195, "end_pos": 248, "type": "TASK", "confidence": 0.7266979813575745}, {"text": "Semantic Role Labeling", "start_pos": 265, "end_pos": 287, "type": "TASK", "confidence": 0.7744846343994141}, {"text": "F-measure", "start_pos": 401, "end_pos": 410, "type": "METRIC", "confidence": 0.9985755681991577}]}, {"text": "Interpreting NPs correctly requires various types of information from world knowledge to complex context features.", "labels": [], "entities": []}, {"text": "Since the training data needs to be as accurate as possible, many of such features are manually identified and annotated.", "labels": [], "entities": []}, {"text": "Thus, the annotation process is an important task that requires not only considerable amount of time, but also experience with various annotation schemas and tools, and a good understanding of the research topic.", "labels": [], "entities": []}, {"text": "Moreover, the extension of the noun phrase interpretation task to other natural languages brings forward new annotation issues.", "labels": [], "entities": [{"text": "noun phrase interpretation task", "start_pos": 31, "end_pos": 62, "type": "TASK", "confidence": 0.7373513132333755}]}, {"text": "This paper presents observations on our experience with an annotation scheme that was used in the training of a state-of-the-art noun phrase semantic interpretation system (Girju, 2007).", "labels": [], "entities": [{"text": "noun phrase semantic interpretation", "start_pos": 129, "end_pos": 164, "type": "TASK", "confidence": 0.6949263662099838}]}, {"text": "The system relies on cross-linguistic evidence from a set of five Romance languages: Spanish, Italian, French, Portuguese, and Romanian.", "labels": [], "entities": []}, {"text": "Given a training set of English noun phrases in context along with their translations in the five Romance languages, our algorithm automatically learns a classification function that is later on applied to unseen test instances for semantic interpretation.", "labels": [], "entities": [{"text": "semantic interpretation", "start_pos": 232, "end_pos": 255, "type": "TASK", "confidence": 0.7982505261898041}]}, {"text": "As training and test data we used two text collections of different genre: Europarl 2 and CLUVI 3 . The training data was annotated with contextual features based on two state-ofthe-art classification tag sets: Lauer's set of 8 prepositions and our list of 22 semantic relations.", "labels": [], "entities": [{"text": "Europarl", "start_pos": 75, "end_pos": 83, "type": "DATASET", "confidence": 0.9709092378616333}]}, {"text": "The system achieved an accuracy of 77.9% (Europarl) and 74.31% (CLUVI).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 23, "end_pos": 31, "type": "METRIC", "confidence": 0.9997724890708923}, {"text": "Europarl", "start_pos": 42, "end_pos": 50, "type": "DATASET", "confidence": 0.9125415086746216}, {"text": "CLUVI)", "start_pos": 64, "end_pos": 70, "type": "METRIC", "confidence": 0.8774370551109314}]}, {"text": "The paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 presents a summary of linguistic considerations of noun phrases.", "labels": [], "entities": []}, {"text": "In Section 3 we describe the list of semantic interpretation categories used along with observations regarding their distribution on the two dif-2 http://www.isi.edu/koehn/europarl/ This corpus contains over 20 million words in eleven official languages of the European Union covering the proceedings of the European Parliament from 1996 to 2001.", "labels": [], "entities": []}, {"text": "3 CLUVI -Linguistic Corpus of the University of Vigo Parallel Corpus 2.1 -http://sli.uvigo.es/CLUVI/.", "labels": [], "entities": [{"text": "CLUVI -Linguistic Corpus of the University of Vigo Parallel Corpus 2.1", "start_pos": 2, "end_pos": 72, "type": "DATASET", "confidence": 0.7731183593471845}]}, {"text": "CLUVI is an open text repository of parallel corpora of contemporary oral and written texts in some of the Romance languages, such as Galician, French, Spanish, Portuguese, Basque parallel text collections.", "labels": [], "entities": [{"text": "CLUVI", "start_pos": 0, "end_pos": 5, "type": "DATASET", "confidence": 0.8762515783309937}]}, {"text": "Section 4 presents the data used along with observations on corpus annotation and inter-annotator agreement.", "labels": [], "entities": []}, {"text": "Finally, Section 5 offers some discussion and conclusions.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: The set of 22 semantic relations along with examples interpreted in context and the semantic  argument frame.", "labels": [], "entities": []}, {"text": " Table 2: The inter-annotator agreement on the NP annotation", "labels": [], "entities": []}]}