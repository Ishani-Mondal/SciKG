{"title": [], "abstractContent": [{"text": "This paper investigates improvement of automatic biomedical named-entity recognition by applying a reranking method to the COLING 2004 JNLPBA shared task of bio-entity recognition.", "labels": [], "entities": [{"text": "biomedical named-entity recognition", "start_pos": 49, "end_pos": 84, "type": "TASK", "confidence": 0.6183417638142904}, {"text": "COLING 2004 JNLPBA shared task", "start_pos": 123, "end_pos": 153, "type": "DATASET", "confidence": 0.7844654679298401}, {"text": "bio-entity recognition", "start_pos": 157, "end_pos": 179, "type": "TASK", "confidence": 0.6819447576999664}]}, {"text": "Our system has a common reranking architecture that consists of a pipeline of two statistical classifiers which are based on log-linear models.", "labels": [], "entities": []}, {"text": "The architecture enables the reranker to take advantage of features which are globally dependent on the label sequences, and features from the labels of other sentences than the target sentence.", "labels": [], "entities": []}, {"text": "The experimental results show that our system achieves the labeling accuracies that are comparable to the best performance reported for the same task, thanks to the 1.55 points of F-score improvement by the reranker.", "labels": [], "entities": [{"text": "F-score", "start_pos": 180, "end_pos": 187, "type": "METRIC", "confidence": 0.998471200466156}]}], "introductionContent": [{"text": "Difficulty and potential application of biomedical named-entity recognition has attracted many researchers of both natural language processing and bioinformatics.", "labels": [], "entities": [{"text": "biomedical named-entity recognition", "start_pos": 40, "end_pos": 75, "type": "TASK", "confidence": 0.6275629699230194}, {"text": "natural language processing", "start_pos": 115, "end_pos": 142, "type": "TASK", "confidence": 0.6795168121655782}]}, {"text": "The difficulty of the task largely stems from a wide variety of named entity expressions used in the domain.", "labels": [], "entities": []}, {"text": "It is common for practical protein or gene databases to contain hundreds of thousands of items.", "labels": [], "entities": []}, {"text": "Such a large variety of vocabulary naturally leads to long names with productive use of general words, making the task difficult to be solved by systems with naive Markov assumption of label sequences, because such systems must perform their prediction without seeing the entire string of the entities.", "labels": [], "entities": []}, {"text": "Importance of the treatment of long names might be implicitly indicated in the performance comparison of the participants of JNLPBA shared task (), where the best performing system ( attains their scores by extensive post-processing, which enabled the system to make use of global information of the entity labels.", "labels": [], "entities": []}, {"text": "After the shared task, many researchers tackled the task by using conditional random fields (CRFs) (), which seemed to promise improvement over locally optimized models like maximum entropy Markov models (MEMMs) ().", "labels": [], "entities": []}, {"text": "However, many of the CRF systems developed after the shared task failed to reach the best performance achieved by Zhou et al.", "labels": [], "entities": []}, {"text": "One of the reasons maybe the deficiency of the dynamic programming-based systems, that the global information of sequences cannot be incorporated as features of the models.", "labels": [], "entities": []}, {"text": "Another reason maybe that the computational complexity of the models prevented the developers to invent effective features for the task.", "labels": [], "entities": []}, {"text": "We had to wait until, who combine pattern-based postprocessing with CRFs, for CRF-based systems to achieve the same level of performance as Zhou et al.", "labels": [], "entities": []}, {"text": "As such, a key to further improvement of the performance of bio-entity recognition has been to employ global features, which are effective to capture the features of long names appearing in the bio domain.", "labels": [], "entities": [{"text": "bio-entity recognition", "start_pos": 60, "end_pos": 82, "type": "TASK", "confidence": 0.7155569493770599}]}, {"text": "In this paper, we use reranking architecture, which was successfully applied to the task of natural language parsing, to address the problem.", "labels": [], "entities": [{"text": "natural language parsing", "start_pos": 92, "end_pos": 116, "type": "TASK", "confidence": 0.6475949585437775}]}, {"text": "Reranking enables us to incorporate truly global features to the model of named entity tagging, and we aim to realize the state-of-the-art performance without depending on rule-based post-processes.", "labels": [], "entities": []}, {"text": "Use of global features in named-entity recognition systems is widely studied for sequence labeling including general named-entity tasks like CoNLL 2003 shared task.", "labels": [], "entities": [{"text": "sequence labeling", "start_pos": 81, "end_pos": 98, "type": "TASK", "confidence": 0.6492330133914948}, {"text": "CoNLL 2003 shared task", "start_pos": 141, "end_pos": 163, "type": "DATASET", "confidence": 0.811062827706337}]}, {"text": "Such systems maybe classified into two kinds, one of them uses a single classifier which is optimized incorporating non-local features, and the other consists of pipeline of more than one classifiers.", "labels": [], "entities": []}, {"text": "The former includes Relational Markov Networks by and skip-edge CRFs by.", "labels": [], "entities": []}, {"text": "A major drawback of this kind of systems maybe heavy computational cost of inference both for training and running the systems, because non-local dependency forces such models to use expensive approximate inference instead of dynamic-programming-based exact inference.", "labels": [], "entities": []}, {"text": "The latter, pipelined systems include a recent study by, as well as our reranking system.", "labels": [], "entities": []}, {"text": "Their method is a two stage model of CRFs, where the second CRF uses the global information of the output of the first CRF.", "labels": [], "entities": []}, {"text": "Though their method is effective in capturing various non-local dependencies of named entities like consistency of labels, we maybe allowed to claim that reranking is likely to be more effective in bioentity tagging, where the treatment of long entity names is also a problem.", "labels": [], "entities": [{"text": "consistency", "start_pos": 100, "end_pos": 111, "type": "METRIC", "confidence": 0.9764463901519775}, {"text": "bioentity tagging", "start_pos": 198, "end_pos": 215, "type": "TASK", "confidence": 0.8165241777896881}]}, {"text": "This paper is organized as follows.", "labels": [], "entities": []}, {"text": "First, we briefly overview the JNLPBA shared task of bioentity recognition and its related work.", "labels": [], "entities": [{"text": "bioentity recognition", "start_pos": 53, "end_pos": 74, "type": "TASK", "confidence": 0.8298259079456329}]}, {"text": "Then we explain the components of our system, one of which is an MEMM n-best tagger, and the other is a reranker based on log-linear models.", "labels": [], "entities": [{"text": "MEMM n-best tagger", "start_pos": 65, "end_pos": 83, "type": "TASK", "confidence": 0.49243879318237305}]}, {"text": "Then we show the experiments to tune the performance of the system using the development set.", "labels": [], "entities": []}, {"text": "Finally, we compare our results with the existing systems, and conclude the paper with the discussion for further improvement of the system.", "labels": [], "entities": []}], "datasetContent": [{"text": "We evaluated the performance of the system on the data set provided by the COLING 2004 JNLPBA shared-task.", "labels": [], "entities": [{"text": "COLING 2004 JNLPBA shared-task", "start_pos": 75, "end_pos": 105, "type": "DATASET", "confidence": 0.8682406544685364}]}, {"text": "which consists of 2000 abstracts from the MEDLINE articles.", "labels": [], "entities": [{"text": "MEDLINE articles", "start_pos": 42, "end_pos": 58, "type": "DATASET", "confidence": 0.9634754359722137}]}, {"text": "GENIA tagger 2 , a biomedical text processing tool which automatically anno-  tates POS tags, shallow parses and named-entity tags is used to preprocess the corpus, and POS and shallow parse information is used in our experiments.", "labels": [], "entities": [{"text": "GENIA tagger", "start_pos": 0, "end_pos": 12, "type": "TASK", "confidence": 0.7370120584964752}]}, {"text": "We divided the data into 20 contiguous and equally-sized sections, and used the first 18 sections for training, and the last 2 sections for testing while development (henceforth the training and development sets, respectively).", "labels": [], "entities": []}, {"text": "The training data of the reranker is created by the n-best tagger, and every set of 17 sections from the training set is used to train the n-best tagger for the remaining section (The same technique is used by previous studies to avoid the n-best tagger's 'unrealistically good' performance on the training set).", "labels": [], "entities": []}, {"text": "Among the n-best sequences output by the MEMM tagger, the sequence with the highest F-score is used as the 'correct' sequence for training the reranker.", "labels": [], "entities": [{"text": "MEMM tagger", "start_pos": 41, "end_pos": 52, "type": "TASK", "confidence": 0.6604640185832977}, {"text": "F-score", "start_pos": 84, "end_pos": 91, "type": "METRIC", "confidence": 0.9959890246391296}]}, {"text": "The two log-linear models for the MEMM tagger and reranker are estimated using a limited-memory BFGS algorithm implemented in an open-source software Amis . In both models, Gaussian prior distributions are used to avoid overfitting, and the standard deviations of the Gaussian distributions are optimized to maximize the performance on the development set.", "labels": [], "entities": [{"text": "MEMM tagger", "start_pos": 34, "end_pos": 45, "type": "TASK", "confidence": 0.6900422275066376}]}, {"text": "We also used a thresholding technique which discards features with low frequency.", "labels": [], "entities": []}, {"text": "This is also optimized using the development set, and the best threshold was 4 for the MEMM tagger, and 50 for the reranker . For both of the MEMM tagger and reranker, combinations of feature classes are manually selected to improve the accuracies on the development set.", "labels": [], "entities": []}, {"text": "Our final models include 49 and 148 feature class combinations for the MEMM tagger and reranker, respectively.", "labels": [], "entities": [{"text": "MEMM tagger", "start_pos": 71, "end_pos": 82, "type": "TASK", "confidence": 0.5683008134365082}]}, {"text": "shows the performance of the MEMM tagger on the development set.", "labels": [], "entities": [{"text": "MEMM tagger", "start_pos": 29, "end_pos": 40, "type": "TASK", "confidence": 0.6202328503131866}]}, {"text": "As reported in many  of the previous studies (), features of shallow parsers had a large contribution to the performance.", "labels": [], "entities": []}, {"text": "The information of the previous labels was also quite effective, which indicates that label unigram models (i.e. 0th order Markov models, so to speak) would have been insufficient for good performance.", "labels": [], "entities": []}, {"text": "Then we developed the reranker, using the results of 50-best taggers as training data.", "labels": [], "entities": []}, {"text": "shows the performance of the reranker pipelined with the 50-best MEMM tagger, where the 'oracle' row shows the upper bound of reranker performance.", "labels": [], "entities": []}, {"text": "Here, we can observe that the reranker successfully improved the performance by 1.43 points from the baseline (i.e. the one-best of the MEMM tagger).", "labels": [], "entities": []}, {"text": "It is also shown that the global features that depend on two adjacent entities, and the n-best distribution features from the outside of the target sentences, are both contributing to this performance improvement.", "labels": [], "entities": []}, {"text": "We also conducted experimental comparison of two thresholding methods which are described in Section 3.", "labels": [], "entities": []}, {"text": "Since we can train and test the reranker with MEMM taggers that use different thresholding methods, we could make a table of the performance of the reranker, changing the MEMM tagger used for both training and evaluation . show the F-scores obtained by various MEMM taggers, where the 'oracle' column again shows the performance upper bound.", "labels": [], "entities": [{"text": "F-scores", "start_pos": 232, "end_pos": 240, "type": "METRIC", "confidence": 0.9838834404945374}]}, {"text": "(All of the \u03b8-best methods are combined with 200-best thresholding.)", "labels": [], "entities": []}, {"text": "Though we can roughly state that the reranker can work better with n-best taggers which are more ambiguous than those used for their training, the differences are so slight to see clear tendencies (For example, the columns for the reranker trained using the 10-best MEMM tagger seems to be a counterexample against the statement).", "labels": [], "entities": []}, {"text": "We may also be able to say that the \u03b8-best methods are generally performing slightly better, and it could be explained by the fact that we have better oracle performance with less ambiguity in \u03b8-best methods.", "labels": [], "entities": []}, {"text": "However, the scores in the column corresponding to the 50-best training seems to be as high as any of the scores of the \u03b8-best methods, and the best score is also achieved in that column.", "labels": [], "entities": []}, {"text": "The reason maybe because our performance tuning is done exclusively using the 50-best-trained reranker.", "labels": [], "entities": [{"text": "performance tuning", "start_pos": 29, "end_pos": 47, "type": "TASK", "confidence": 0.6698436290025711}]}, {"text": "Though we could have achieved better performance by doing feature selection and hyper-parameter tuning again using \u03b8-best MEMMs, we use the reranker trained on 50-best tags run with 70-best MEMM tagger as the best performing system in the following.", "labels": [], "entities": [{"text": "feature selection", "start_pos": 58, "end_pos": 75, "type": "TASK", "confidence": 0.7126539051532745}]}, {"text": "shows the performance of our n-best tagger and reranker on the official test set, and the best reported results on the same task.", "labels": [], "entities": []}, {"text": "As naturally expected, our system outperformed the systems that cannot accommodate truly global features (Note that one point of F-score improvement is valuable in this task, because inter-annotator agreement rate of human experts in bio-entity recognition is likely to be about 80%.", "labels": [], "entities": [{"text": "F-score", "start_pos": 129, "end_pos": 136, "type": "METRIC", "confidence": 0.9932938814163208}, {"text": "bio-entity recognition", "start_pos": 234, "end_pos": 256, "type": "TASK", "confidence": 0.7278652489185333}]}, {"text": "For example, report the inter-annotater agreement rate of 77.6% for the three way bio-entity classification task.) and the performance can be said to beat the same level as the best systems.", "labels": [], "entities": [{"text": "bio-entity classification task.", "start_pos": 82, "end_pos": 113, "type": "TASK", "confidence": 0.7486591637134552}]}, {"text": "However, in spite of our effort, our system could not outperform the best result achieved by Tsai et al.", "labels": [], "entities": []}, {"text": "What makes Tsai et al.'s system perform better than ours might be the careful treatment of numeric expressions.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 5: Comparison of the F-scores of rerankers trained and evaluated with various N -best taggers.", "labels": [], "entities": [{"text": "F-scores", "start_pos": 28, "end_pos": 36, "type": "METRIC", "confidence": 0.9896508455276489}]}, {"text": " Table 6: Comparison of the F-scores of rerankers trained and evaluated with various \u03b8-best taggers.", "labels": [], "entities": [{"text": "F-scores", "start_pos": 28, "end_pos": 36, "type": "METRIC", "confidence": 0.9912257790565491}]}]}